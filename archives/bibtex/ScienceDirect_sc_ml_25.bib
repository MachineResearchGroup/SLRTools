@article{PENG2019427,
title = {Learning multi-region features for vehicle re-identification with context-based ranking method},
journal = {Neurocomputing},
volume = {359},
pages = {427-437},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219308409},
author = {Jinjia Peng and Huibing Wang and Tongtong Zhao and Xianping Fu},
keywords = {Vehicle Re-identification, Multi-region model, Context-based ranking},
abstract = {Vehicle re-identification is to identify a target vehicle in different cameras with non-overlapping views. It is a challenging task due to various viewpoints of vehicles, diversified illuminations and complicated environments. Most existing vehicle re-identification methods focus on learning global features, while neglecting the importance of local features. In this paper, we propose a Multi-Region Model (MRM) to learn powerful features for vehicle re-identification. In addition to extracting global region features, MRM also extracts features from a series of local regions. For each local region, instead of utilizing the rigid part to extract features directly, a Spatial Transformer Network (STN) based localization model is introduced to localize local regions which contain more distinctive visual cues. In order to further improve the performance of re-identification, we design a context-based ranking method which generates the ranking list by taking context and content into consideration to measure the similarity between neighbors. Experimental results clearly demonstrate that our method achieves excellent performance on both VehicleID dataset and VeRi-776 dataset.}
}
@article{YANG2021389,
title = {Multi-source transfer regression via source-target pairwise segment},
journal = {Information Sciences},
volume = {556},
pages = {389-403},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.09.074},
url = {https://www.sciencedirect.com/science/article/pii/S0020025520309804},
author = {Kai Yang and Jie Lu and Wanggen Wan and Guangquan Zhang},
keywords = {Machine learning, Data mining, Transfer learning, Multi-source domain adaptation},
abstract = {Transfer learning addresses the problem of how to leverage acquired knowledge from a source domain to improve the learning efficiency and accuracy of the target domain that has insufficient labeled data. Instead of one source domain, multiple domains could be the source domains that are available for knowledge transfer in practice. However, there are large differences between the source and target domains, how to extract the useful knowledge from these different source domains remains a problem. To solve this problem, we propose a source-target pairwise segment method for multi-source transfer regression (STPS-MTR). The STPS-MTR method adaptively segments the different source domains and the target domain into different similar parts, and it extracts the most similar part in different source domains as the transfer knowledge. The STPS-MTR method can effectively extract the transfer knowledge from different source domains even when the source domain and the target domain have relatively low similarity, and it can avoid the negative influence between different source domains to ensure the transfer performance. Experimental results using synthetic datasets and real-world datasets demonstrate that the proposed method has better performance than existing methods, particularly when there are significant differences between different source domains and the target domain.}
}
@article{KO2020102256,
title = {Smart home energy strategy based on human behaviour patterns for transformative computing},
journal = {Information Processing & Management},
volume = {57},
number = {5},
pages = {102256},
year = {2020},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2020.102256},
url = {https://www.sciencedirect.com/science/article/pii/S0306457320300662},
author = {Hoon Ko and Jong Hyuk Kim and Kyungjin An and Libor Mesicek and Goreti Marreiros and Sung Bum Pan and Pankoo Kim},
keywords = {Energy strategy, Ecg (electrocardiography), Human behaviour pattern, Transformative computing},
abstract = {Summary
Transformative computing in the fourth-generation industrialization, receives all signals and all sequences from sensing devices under artificial intelligence in wireless networking. Then the system has to combine them and make a useful information for human. In an industrial building or in a home, many electronic devices would be using and they make various energy signals and sequences. The devices can find out the energy wastage in the absence of a smart energy management system to monitor the energy flow, and it causes a blackout. Once the energy flow is analysed, it is possible to realize the special-time or the rush-time, which will require a large amount of energy. Because the existing systems have no monitor to see the energy flow, a large amount of energy can be wasted. To distribute the energy efficiently, a smart energy management system should have the necessary special functions that can monitor the energy flow. Following the analysis result, the system can create a special strategy to plan energy distribution. In this study, the smart energy management system defines a special strategy based on the analysis result of the consumed energy by arranging more or less usage of energy. Moreover, the system can decrease the energy supply to idle devices and the connected extra devices by analysing how many IoT will be used in a service. This smart control system can detect human behaviour when they move and turn in activation automatically, so finally, the system can use the energy efficiently.}
}
@article{KUSHWAHA2021100017,
title = {Applications of big data in emerging management disciplines: A literature review using text mining},
journal = {International Journal of Information Management Data Insights},
volume = {1},
number = {2},
pages = {100017},
year = {2021},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2021.100017},
url = {https://www.sciencedirect.com/science/article/pii/S2667096821000100},
author = {Amit Kumar Kushwaha and Arpan Kumar Kar and Yogesh K. Dwivedi},
keywords = {Big data, Artificial intelligence, Data science, Marketing, Operations management, Services management, Finance},
abstract = {The importance of data-driven decisions and support is increasing day by day in every management area. The constant access to volume, variety, and veracity of data has made big data an integral part of management studies. New sub-management areas are emerging day by day with the support of big data to drive businesses. This study takes a systematic literature review approach to uncover the emerging management areas supported by big data in contemporary times. For this, we have analyzed the research papers published in the reputed management journals in the last ten years, fir using network analysis followed by natural language processing summarization techniques to find the emerging new management areas which are yet to get much attention. Furthermore, we ran the same exercise in each of these management areas to uncover these areas better. This research will act as a reference for future information systems (IS) scholars who want to perform analysis that is deep-dive in nature on each of these management areas, which in the coming times will get all the due attention to become dedicated research domains in the management area. We finally conclude the study by identifying the scope of future research in each of these management areas, which will be a true value addition for IS researchers.}
}
@article{MODGIL2022121415,
title = {Has Covid-19 accelerated opportunities for digital entrepreneurship? An Indian perspective},
journal = {Technological Forecasting and Social Change},
volume = {175},
pages = {121415},
year = {2022},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.121415},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521008465},
author = {Sachin Modgil and Yogesh K. Dwivedi and Nripendra P. Rana and Shivam Gupta and Sachin Kamble},
keywords = {Digital entrepreneurship, Diffusion of innovations, Emerging Technologies, Covid-19},
abstract = {Covid-19 has challenged many businesses to orient themselves towards digital solutions for their survival. Due to the rising digital wave during Covid-19, there has been a plethora of opportunities for aspiring entrepreneurs to enter the market. Hence, this study focuses on understanding emerging areas and technologies for digital entrepreneurship. This study adopted a qualitative approach with semi-structured interviews through the lens of the diffusion of innovations theory. A total of 23 entrepreneurs responded and presented their views on Covid-19-induced opportunities for digital entrepreneurship. A structured process of open, axial, and selective coding was adopted for the thematic analysis. The study presents a framework based on four promising propositions. Results of the thematic analysis indicate the emergence of digital entrepreneurship opportunities in technology (EdTech, FinTech, cybersecurity), healthcare (diagnostics, virtual care, fitness), entertainment (over the top, gaming, social media), and e-commerce (contactless delivery, payment methods, augmented reality). In this study, entrepreneurs presented their views based on their experience with the platform or technology they operated. To this end, the present study offers implications both for scholars and entrepreneurs working in and aspiring to digital entrepreneurship along with future scope of research.}
}
@article{CINQUE2022315,
title = {Virtualizing mixed-criticality systems: A survey on industrial trends and issues},
journal = {Future Generation Computer Systems},
volume = {129},
pages = {315-330},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21004787},
author = {Marcello Cinque and Domenico Cotroneo and Luigi {De Simone} and Stefano Rosiello},
keywords = {Virtualization, Real-time applications, Mixed-criticality systems, Resource isolation, Safety certification, Dependability},
abstract = {Virtualization is gaining attraction in the industry as it promises a flexible way to integrate, manage, and re-use heterogeneous software components with mixed-criticality levels, on a shared hardware platform, while obtaining isolation guarantees. This work surveys the state-of-the-practice of real-time virtualization technologies by discussing common issues in the industry. In particular, we analyze how different virtualization approaches and solutions can impact isolation guarantees and testing/certification activities, and how they deal with dependability challenges. The aim is to highlight current industry trends and support industrial practitioners to choose the most suitable solution according to their application domains.}
}
@article{SARAOGLU201882,
title = {Fault-Tolerant Path Planning in Networked Vehicle Systems in Presence of Communication Failures},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {23},
pages = {82-87},
year = {2018},
note = {7th IFAC Workshop on Distributed Estimation and Control in Networked Systems NECSYS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S240589631833547X},
author = {Mustafa Saraoglu and Fabian Hart and Andrey Morozov and Klaus Janschek},
keywords = {Autonomous Vehicles, Decision Making, Fault Tolerance, Estimation Algorithms, Game Theory},
abstract = {This paper proposes a fault-tolerant path planning algorithm for autonomous and connected vehicle networks in urban traffic scenarios. Multiple vehicles try to reach their destinations in the shortest time, evaluating the information gathered by front sensors and vehicle-to-vehicle (V2V) communication. The algorithm uses an estimator and an embedded decision maker unit in order to choose safe and time-saving routes. The decision making part relies on the path plans of other vehicles received through the V2V communication. If the path plan of a vehicle is missing due to a communication failure, the algorithm makes the decision by solving a Bayesian game, taking the latest known position of the faulty vehicle into account. A dedicated simulator is developed in order to implement the algorithm and verify the results. It is shown that reasonable route decisions can be made in the presence of communication failures. Analytical solution of the Bayesian game is evaluated and the results are verified by simulations.}
}
@article{MA201991,
title = {Atrous convolutions spatial pyramid network for crowd counting and density estimation},
journal = {Neurocomputing},
volume = {350},
pages = {91-101},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.03.065},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219304059},
author = {Junjie Ma and Yaping Dai and Yap-Peng Tan},
keywords = {Crowd counting, Crowd density estimation, Multi-scale, Atrous convolutions},
abstract = {Scale variation because of perspective distortion is still a challenge for crowd analysis. To address this problem, an atrous convolutions spatial pyramid network (ACSPNet) is proposed to perform crowd counts and density maps for both sparse and congested scenarios. Atrous Convolutions sequenced with increasing atrous rates are utilized to exaggerate the receptive field and maintain the resolution of extracted features. Different rates of atrous convolution blocks in the pyramid are skip-connected to integrate multi-scale information and extent scale perception ability. Atrous Spatial Pyramid Pooling (ASPP) is employed to resample information at different scales and contain global context. We evaluate our ACSPNet on five challenging benchmark crowd counting datasets and our method achieves state-of-the-art mean absolute error (MAE) and mean squared error (MSE) performances.}
}
@article{CHEN2021104141,
title = {Metaheuristic model for the interface shear strength between granular soil and structure considering surface morphology},
journal = {Computers and Geotechnics},
volume = {135},
pages = {104141},
year = {2021},
issn = {0266-352X},
doi = {https://doi.org/10.1016/j.compgeo.2021.104141},
url = {https://www.sciencedirect.com/science/article/pii/S0266352X21001452},
author = {Wei-Bin Chen and Wan-Huan Zhou and Łukasz Sadowski and Zhen-Yu Yin},
keywords = {Random surface, Morphology, Soil-structure interface, Shear strength, Metaheuristic model},
abstract = {A complete set of 13 morphological parameters in accordance with standard ISO 4287 was applied to quantifying a series of random profiles. These profiles were imported into a discrete numerical model to perform 480 interface shear tests on coarse-grained soils. The relevant morphological parameters were selected using Spearman’s rank correlation coefficient for model selection. An optimal metaheuristic model was developed using a genetic algorithm and was further compared with the existing predicted formulas. The 2D discrete element method (DEM) results indicate that the highest correlation with shear strength was obtained for the hybrid parameter Pdq which represents not only the amplitude information but also the surface slope information on a random surface. The optimal model with one significant input variable (Pdq) was effectively selected through the Bayesian nonparametric general regression analysis. For irregular interface shearing widely existing in most geotechnical engineering, Pdq is more efficient and accurate to quantify the surface morphology or estimate the interface shear strength compared with relative roughness.}
}
@article{PICCAROZZI2021414,
title = {Industry 4.0 tools in innovative European firms: exploring their adoption and communication features through content analysis},
journal = {Procedia Computer Science},
volume = {180},
pages = {414-423},
year = {2021},
note = {Proceedings of the 2nd International Conference on Industry 4.0 and Smart Manufacturing (ISM 2020)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.01.257},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921003008},
author = {Michela Piccarozzi and Cecilia Silvestri and Barbara Aquilani and Chiara Cagnetti},
keywords = {Industry 4.0, innovative firms, content analysis, Annual Report},
abstract = {Industry 4.0 is a popular topic in management literature, but it is also an interdisciplinary subject, maintaining a strong engineering connotation. Firm decision-making processes are more and more affected by Industry 4.0 which has introduced numerous tools that benefit and greatly support business activities. In this domain, the focus of this paper is the information made available to stakeholders on Industry 4.0 tools in use through a content analysis of the Annual Reports of the main European innovative firms (from the top ten of the Boston Consulting Group ranking). The analysis seeks to highlight how firms describe and qualify these tools in terms of impact (risk, strategy or environmental), the perspective used in illustrating them (managerial or engineering) as well as the temporal orientation of the information provided (present, past, future or none). Results show that innovative European firms pay attention and use these tools, in different ways and for different purposes. The paper has both theoretical and managerial implications. From a theoretical point of view, it contributes to study and further the literature on Industry 4.0 and its instruments, while from a managerial perspective, it gives a better understanding of how these innovative tools can be communicated to external stakeholders, especially investors.}
}
@article{GULATI2020102222,
title = {A game theoretic approach for conflict resolution in argumentation enabled social IoT networks},
journal = {Ad Hoc Networks},
volume = {107},
pages = {102222},
year = {2020},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2020.102222},
url = {https://www.sciencedirect.com/science/article/pii/S1570870520303206},
author = {Nancy Gulati and Pankaj Deep Kaur},
keywords = {Social IoT, Argumentation, Speaking objects, Game theory, Weighted voting game, Conflict resolution, Smart home,},
abstract = {The notion of socially enabled Internet of Things (IoT) termed as Social IoT, emphasized on social interactions among smart objects in an IoT network. Moreover, the concept of speaking and hearing objects further advanced the level of interactions occurring among the IoT devices by empowering them with conversational abilities. Researchers are constantly working to practically realize this vision, keeping in mind the potential benefits of the integration of technologies like argumentation, logical reasoning and artificial intelligence into IoT. Moving along the same lines, this paper investigates the emerging concept of speaking objects and proposes novel reference architecture for argumentation enabled Social IoT systems. The proposed framework lays out a theoretical foundation for development of future applications in the said domain. Further, to overcome the challenges of conflict resolution in argumentation-based decision making, a game theoretic weighted voting scheme is deployed. To ascertain the validity the proposed model, a smart home assisted living use-case scenario is simulated in MATLAB. The simulations are conducted for both weighted and non-weighted voting schemes in a 4-player cooperative game and their performance is evaluated. Experimental results revealed that the proposed scheme outperforms the existing non-weighted voting schemes in terms of throughput which is improved by 35% for quota, q = 0.5. For higher quota values, a minimum improvement of at least 15% is observed. Therefore, the proposed approach confirms to be an effective scheme for decision making in argumentation enabled Social IoT systems.}
}
@article{CALVO2022102612,
title = {A Model For risk-Based adaptive security controls},
journal = {Computers & Security},
volume = {115},
pages = {102612},
year = {2022},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2022.102612},
url = {https://www.sciencedirect.com/science/article/pii/S0167404822000116},
author = {Miguel Calvo and Marta Beltrán},
keywords = {Adaptive security, Context-aware decision making, Dynamic security controls, MAPE Loop, Risk-based security},
abstract = {Security controls and countermeasures have shifted from static desktop-based and corporate network environments to heterogeneous, distributed and dynamic environments (e.g., cloud and mobile computing or Internet of Things). Due to this paradigm shift, adaptive and risk-based approaches have gained significant importance. These approaches allow security managers to perform context-aware decision making, adapting controls’ deployment, configuration or use to every specific situation, depending on the current value of risk indicators or scores and on the level of risk tolerated by the organisation at any given time. This paper proposes a model to automatically adapt security controls to different risk scenarios in almost real-time (if required). This model is based on a three-layer architecture and a three-step flow (measurement-decision-adaptation), relying on a scalable policies&rules framework capable of integrating with different kinds of controls. Furthermore, the proposed model is validated and evaluated with an actual use case.}
}
@article{KHAN2019100808,
title = {Predicted mobility based profitable relay selection in cooperative cellular network with mobile relays},
journal = {Physical Communication},
volume = {37},
pages = {100808},
year = {2019},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2019.100808},
url = {https://www.sciencedirect.com/science/article/pii/S1874490719301454},
author = {Benish Sharfeen Khan and Sobia Jangsher and Hassaan Khaliq Qureshi and Syed Hassan Ahmed},
keywords = {Cooperative cellular network, Mobile relays, Mobility model},
abstract = {Cooperative cellular networks is productive approach to improve network system capacity, network reliability, data rate, and also increases the hold of spectrum resources in the fifth generation (5G) networks. For this purpose, selection of a relay in cooperative communication has been widely investigated in the past few years and with research in vehicular network, the selection of mobile relay has been studied. In cooperative communication, operator (base station) assigns mobile relay to each mobile user in order to minimize total transmission power and cost with improved data rates. The relay selection is based upon the utilities or benefits provided to three players, i.e. operator, mobile user (MU) and mobile relay (MR). Incentives must be given to mobile relays to make them cooperate for their utilized resources. Despite much effort that has been made in cooperative communication, mobility of a mobile relay along with selection and defining utility gains for three players involved is still left as an open research problem. In this paper, we propose an auction based scheme for relay selection in cooperative communication. For this purpose, we formulate utilities of three players while considering mobility of a mobile relay. Based on the random waypoint mobility model, a centralized Predicted Mobility Based Profitable Relay Selection Algorithm (PMPRSA) is proposed by using auction theory to select a mobile relay. Performance analysis shows that the proposed PMPRSA selects a mobile relay while providing higher data rate and incentives to all three players for their shared resources.}
}
@article{HAGHANI2021173,
title = {Structural anatomy and temporal trends of road accident research: Full-scope analyses of the field},
journal = {Journal of Safety Research},
volume = {79},
pages = {173-198},
year = {2021},
issn = {0022-4375},
doi = {https://doi.org/10.1016/j.jsr.2021.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0022437521001158},
author = {Milad Haghani and Ali Behnood and Oscar Oviedo-Trespalacios and Michiel C.J. Bliemer},
keywords = {Road trauma, Road crashes, Traffic safety, Road safety, Scientometrics},
abstract = {Introduction: Scholarly research on road accidents over the past 50 years has generated substantial literature. We propose a robust search strategy to retrieve and analyze this literature. Method: Analyses was focused on estimating the size of this literature and examining its intellectual anatomy and temporal trends using bibliometric indicators of its articles. Results: The size of the literature is estimated to have exceeded N = 25,000 items as of 2020. At the highest level of aggregation, patterns of term co-occurrence in road accident articles point to the presence of six major divisions: (i) law, legislation & road trauma statistics; (ii) vehicular safety technology; (iii) statistical modelling; (iv) driving simulator experiments of driving behavior; (v) driver style and personality (social psychology); and (vi) vehicle crashworthiness and occupant protection division. Analyses identify the emergence of various research clusters and their progress over time along with their respective influential entities. For example, driver injury severity ” and crash frequency show distinct characteristics of trending topics, with research activities in those areas notably intensified since 2015 Also, two developing clusters labelled autonomous vehicle and automated vehicle show distinct signs of becoming emerging streams of road accident literature. Conclusions: By objectively documenting temporal patterns in the development of the field, these analyses could offer new levels of insight into the intellectual composition of this field, its future directions, and knowledge gaps. Practical Applications: The proposed search strategy can be modified to generate specific subsets of this literature and assist future conventional reviews. The findings of temporal analyses could also be instrumental in informing and enriching literature review sections of original research articles. Analyses of authorships can facilitate collaborations, particularly across various divisions of accident research field.}
}
@article{DAIM2020120329,
title = {Forecasting technological positioning through technology knowledge redundancy: Patent citation analysis of IoT, cybersecurity, and Blockchain},
journal = {Technological Forecasting and Social Change},
volume = {161},
pages = {120329},
year = {2020},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2020.120329},
url = {https://www.sciencedirect.com/science/article/pii/S0040162520311550},
author = {Tugrul Daim and Kuei Kuei Lai and Haydar Yalcin and Fayez Alsoubie and Vimal Kumar},
keywords = {Internet of things, Cybersecurity, Blockchain, Patent citation analysis, Technology knowledge redundancy, Technology knowledge status},
abstract = {Researchers and organizations are becoming increasingly interested in Internet of Things (IoT) cybersecurity and blockchain technology due to its ability to provide solutions to problems of classical centralized architecture. This research approaches the relative locations of a company in the technological network based on patent citations of the IoT cybersecurity and blockchain. To understand how the blockchain and IoT can be merged, it is important to have a better understanding of the emerging technologies of IoT, cybersecurity, and blockchain. We used patent analysis, and merged the patent co-citation analysis (PCA) approach with the patent family to obtain a complete data set analysis. After that, we generated the data using multiple software technologies such as CiteSpace, Pajek, and VOSViewer. We applied the Technology Knowledge Redundancy method for the patent citation network, used the main two indicators TKS (Technology Knowledge Status) and TKR (Technology Knowledge Reliability for the analysis, and then used the Derwent Innovations Index patent data.}
}
@article{KANAKARAJA20213143,
title = {An implementation of advanced IoT in the car parking system},
journal = {Materials Today: Proceedings},
volume = {37},
pages = {3143-3147},
year = {2021},
note = {International Conference on Newer Trends and Innovation in Mechanical Engineering: Materials Science},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2020.09.042},
url = {https://www.sciencedirect.com/science/article/pii/S2214785320367304},
author = {P. Kanakaraja and L.S.P. Sairam Nadipalli and S.V. Aswin Kumer and K. Sarat Kumar and K. Ch. Sri Kavya},
keywords = {Mobile application, WIFI module, IoT, Sensors, Wireless communication},
abstract = {A number of vehicle clients in this quickly developing economy are rising exponentially, requiring all the more parking spots.Unavoidable Smartphone nearness permits buyers to pick approaches concentrated on portable applications. IoT advancement has made ready for cell phones, remote systems administration, and portable applications to be incorporated. This paper proposes a keen stopping system dependent on IoT the Smartphone Device controls this. It gives both the suburbanite and the vehicle leave proprietor a robust leave response. Administrations are entrusted with holding a parking space, verifying a saved client, recognizing the nearby free space determined by the length of the vehicle, and exploring the leaving opening and figure day by day, week by week and month to month accounts data. IR sensors are utilized to decide if there is a free parking spot. Utilizing Wi-Fi module innovation, microcontroller, and remote correspondence innovation, the accessibility of a free opening with its area data is transmitted to the server and recovered by means of versatile application. RFID label appended to a vehicle is utilized to validate an individual who involves a customary, day by day, week by week, or month to a monthly parking spot. A planning calculation is utilized to decide the closest free space, in Light of scale of the engine. The parking spot owner can measure the amount of free and open spaces for a given time, the rate of occupancy on weekdays and ends of the week and the sum earned for a given period and can utilize it to alter variable stopping expenses. The Mobile App is intended to offer a rich client experience.}
}
@article{CHUANG2019102882,
title = {Pavement performance monitoring and anomaly recognition based on crowdsourcing spatiotemporal data},
journal = {Automation in Construction},
volume = {106},
pages = {102882},
year = {2019},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2019.102882},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519302298},
author = {Tzu-Yi Chuang and Nei-Hao Perng and Jen-Yu Han},
keywords = {Pavement performance, Crowdsourcing data, Cloud computing, Spatiotemporal analysis, Road anomaly recognition},
abstract = {Pavement performance is a critical factor toward riding comfort experience and drastically affect traffic management and the safety of road users. Since road quality declines over time and current periodic inspection on a vast road network is laborious and costly to the authority. This paper proposes a participatory system to conduct pavement performance monitoring of a country-wide road network based on crowdsourcing spatiotemporal data. By conducting cloud computing of a statistical grading mechanism with respect to the vertical and lateral acceleration behavior, the perception of riding comfort, which has a high correlation with pavement quality, can be reflected faithfully based on the spatiotemporal data acquired from a smartphone-driven progressive web application. Moreover, a deep learning technique is leveraged to identify road anomalies from the on-site images for a cross-check mechanism, which ensures the reliability of the monitoring pavement conditions and facilitates the automation level of road anomaly labeling and documenting. The proposed pavement performance monitoring was validated by the road network of Taipei city, Taiwan, which rendered promising results with an accuracy up to 98% and a false positive rate smaller than 1.3% showing the practicality and adaptability in a complex road network.}
}
@article{SUN2020164816,
title = {Indoor intelligent lighting control method based on distributed multi-agent framework},
journal = {Optik},
volume = {213},
pages = {164816},
year = {2020},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2020.164816},
url = {https://www.sciencedirect.com/science/article/pii/S0030402620306525},
author = {Fukang Sun and Junqi Yu},
keywords = {Indoor intelligent lighting system, Distributed multi-agent framework, Control method, Event-trigger, Task coordination},
abstract = {In this paper, an indoor intelligent lighting control method based on distributed multi-agent framework is proposed. The distributed multi-agent framework adopts the decentralized star-network architecture, contains multiple heterogeneous agents, and provides the intelligent computation ability via the interaction and coordination among the agents. Furthermore, aiming to achieve optimal visual comfort and energy-saving of luminaires, the proposed method can conduct the control of luminaires and blinds according to the occupancy’s presence, and indoor and outdoor light environment. The simulation experiments are implemented to study the control procedure and effects of luminaires and blinds. The research demonstrates the proposed method has the advantage of more intelligence and efficiency, and can benefit the development of smart lighting technology.}
}
@article{RAO2021116309,
title = {Robust optical flow estimation via edge preserving filtering},
journal = {Signal Processing: Image Communication},
volume = {96},
pages = {116309},
year = {2021},
issn = {0923-5965},
doi = {https://doi.org/10.1016/j.image.2021.116309},
url = {https://www.sciencedirect.com/science/article/pii/S0923596521001314},
author = {Sana Rao and Hanzi Wang},
keywords = {Robust optical flow estimation, Motion estimation, Edge-preserving, Weighted guided filtering, NLTV- model},
abstract = {It is known that optical flow estimation techniques suffer from the issues of ill-defined edges and boundaries of the moving objects. Traditional variational methods for optical flow estimation are not robust to handle these issues since the local filters in these methods do not hold the robustness near the edges. In this paper, we propose a non-local total variation NLTV-L1 optical flow estimation method based on robust weighted guided filtering. Specifically, first, the robust weighted guided filtering objective function is proposed to preserve motion edges. The proposed objective function is based on the linear model which is computationally efficient and edge-preserving in complex natural scenarios. Second, the proposed weighted guided filtering objective function is incorporated into the non-local total variation NLTV-L1 energy function. Finally, the novel NLTV-L1 optical flow method is performed using the coarse-to-fine process. Additionally, we modify some state-of-the-art variational optical flow estimation methods by the robust weighted guided filtering objective function to verify the performance on Middlebury, MPI-Sintel, and Foggy Zurich sequences. Experimental results show that the proposed method can preserve edges and improve the accuracy of optical flow estimation compared with several state-of-the-art methods.}
}
@article{ALDAKHEEL2020102328,
title = {Smart buildings features and key performance indicators: A review},
journal = {Sustainable Cities and Society},
volume = {61},
pages = {102328},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102328},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720305497},
author = {Joud {Al Dakheel} and Claudio {Del Pero} and Niccolò Aste and Fabrizio Leonforte},
keywords = {Smart retrofitting, Smart readiness indicator, Smart grid, Smart buildings, Climate response, Grid response, User response, BEMS, Key performance indicators},
abstract = {The concept of Smart Buildings was introduced by the Energy Performance Building Directive, with the aim to promote energy flexibility, renewable energy production and user interaction. A wide range of definitions have been introduced in the literature to characterize smart buildings yet, at present, its’ concept and features are not clearly and uniquely defined. Simultaneously, building energy retrofit concept has been introduced to facilitate achieving the nearly Zero-Energy Building target and reduce energy consumption in existing buildings. Up to 90 % of the existing European building stock will still be standing and in use in 2050. Thus, there is a need to upgrade the existing retrofitting strategies into Smart Retrofitting, to achieve the nearly Zero Energy Building target and be able to respond to external dynamic conditions such as the weather and the grid. The aim of this research is first to review the concept of smartness in the built environment, highlighting the main features, functions, and technologies of smart buildings, also discussing the possible challenges for smart retrofit applications. The second part of the paper reviews the existing Key Performance Indicators that measure the performance and success in achieving goals in smart buildings. The need to develop a quantified guideline to improve energy and technological innovation is the basis for the increase of the smartness in buildings. Consequently, a set of nine groups of representative performance indicators for smart buildings is developed. This work shows current gaps in the literature and highlights the space for foreseeable future research.}
}
@article{ZHAO201819,
title = {Improving the approaches of traffic demand forecasting in the big data era},
journal = {Cities},
volume = {82},
pages = {19-26},
year = {2018},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2018.04.015},
url = {https://www.sciencedirect.com/science/article/pii/S0264275117315081},
author = {Yongmei Zhao and Hongmei Zhang and Li An and Quan Liu},
keywords = {Big data, Travel demand management, Transport modeling, Traffic demand forecasting},
abstract = {Since the 2000s, an era of big data has emerged. Since then, urban planners have increasingly applied the theory and methods of big data in planning practice. Recent decades illustrate a rapid increase of the application of big data approaches in transportation, bringing new opportunities for innovation in transport modeling. This article analyzes the theories and methods of big data in traffic demand forecasting. In view of theory, the new models and algorithms are proposed in order to adapt to new big data and response to the limitations of traditional disaggregated approaches. In such approaches, three traffic demand-forecasting methods, the full sample-demand distribution model, the traffic integration model, the model organism protein expression database model, are discussed. Undoubtedly, the development of big data also presents new challenges to travel-demand forecasting methods regarding data acquisition, data processing, data analysis, and application of results. In particular, identifying how to improve approaches to traffic-demand forecasting in the big data era in the Third World will be a challenge to the researchers in the field.}
}
@article{DONG2021106882,
title = {Adaptive optimal fuzzy logic based energy management in multi-energy microgrid considering operational uncertainties},
journal = {Applied Soft Computing},
volume = {98},
pages = {106882},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106882},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620308206},
author = {Wei Dong and Qiang Yang and Xinli Fang and Wei Ruan},
keywords = {Microgrid energy management system, Fuzzy inference system, Meta-heuristic algorithm, Operational uncertainty},
abstract = {The intelligent decision making of multi-energy management in a microgrid is a non-trivial task due to the intermittent and stochastic nature of highly penetrated renewable energy sources and demand. To address such a challenge, the energy management system often adopts the prediction based day-ahead energy scheduling and real-time energy dispatch to optimally coordinate the operation of dispatchable components, e.g., battery-based energy storage and thermal units. This paper presents an adaptive optimal fuzzy logic based energy management solution to develop appropriate day-ahead fuzzy rules for real-time energy dispatch adaptively in the presence of operational uncertainties. The solution determines the optimal fuzzy inference system (e.g., the membership function shape and the inference rules set) based on the predicted information over a certain period through a novel offline meta-heuristic optimization algorithm. The real-time energy dispatch based on the obtained optimal fuzzy logic rules can be further carried out to meet the various operational criteria, e.g., minimal power fluctuation and operational cost. The proposed solution is extensively evaluated through simulation experiments in comparison with two existing approaches: the online rule-based dispatch method and the meta-heuristic optimization-based offline scheduling method. The numerical results demonstrate the superior performance of the proposed energy management solution.}
}
@article{FU2022104540,
title = {Learning latent features with local channel drop network for vehicle re-identification},
journal = {Engineering Applications of Artificial Intelligence},
volume = {107},
pages = {104540},
year = {2022},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104540},
url = {https://www.sciencedirect.com/science/article/pii/S0952197621003882},
author = {Xianping Fu and Jinjia Peng and Guangqi Jiang and Huibing Wang},
keywords = {Local channel drop network, Batch ranking loss, Vehicle re-identification},
abstract = {Vehicle re-identification targets to find the target vehicle images in a large dataset which is composed of vehicle images from multiple non-overlapping cameras. Due to the various illumination, viewpoints and resolutions, it is challenging to find the right vehicle images accurately. Most existing works put emphasis on learning strong features by exploiting the attention parts in vehicle images, which leads to some small important cues being suppressed by these significant parts. Hence, a local channel drop network (LCDNet) is proposed in this paper, which focuses on seeking the latent features by releasing the constraint of most attentive features. Specially, besides the normal local feature learning network, LCDNet consists of an attentive local feature learning branch that drops some regions to promote learning the attentive features of local regions. Besides, the batch ranking loss is introduced to split the samples into two groups in a batch and regularize them by enforcing a margin, which ensures the model to learn meaningful features to distinct vehicles. Moreover, to further calculate the similarity of various images, the paper proposes a multi-distance based ranking method to achieve more accurate results. Experiments on several benchmark datasets validate the effectiveness of the proposed method.}
}
@article{KARIM2020942,
title = {Big data management in participatory sensing: Issues, trends and future directions},
journal = {Future Generation Computer Systems},
volume = {107},
pages = {942-955},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17311627},
author = {Ahmad Karim and Aisha Siddiqa and Zanab Safdar and Maham Razzaq and Syeda Anum Gillani and Huma Tahir and Sana Kiran and Ejaz Ahmed and Muhammad Imran},
keywords = {Participatory sensing, Big data, Big data management, Big data analytics, Mobile cloud computing},
abstract = {Participatory sensing has become an emerging technology of this era owing to its low cost in big sensor data collection. Prior to participatory sensing, large-scale deployment complexities were found in wireless sensor networks when collecting data from widespread resources. Participatory sensing systems employ handheld devices as sensors to collect data from communities and transmit to the cloud, where data are further analyzed by expert systems. The processes involved in participatory sensing, such as data collection, transmission, analysis, and visualization, exhibit certain management issues. This study aims to identify big data management issues that must be addressed at the cloud side during data processing and storing and at the participant side during data collection and visualization. It then proposes a framework for big data management in participatory sensing to resolve the contemporary big data management issues on the basis of suggested principles. Moreover, this work presents case studies to elaborate the existence of the highlighted issues. Finally, the limitations, recommendations, and future research directions for academia and industry in the domain of participatory sensing are discussed.}
}
@article{KANNANGARA202258,
title = {Surface settlements induced by twin tunneling in silty sand},
journal = {Underground Space},
volume = {7},
number = {1},
pages = {58-75},
year = {2022},
issn = {2467-9674},
doi = {https://doi.org/10.1016/j.undsp.2021.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2467967421000398},
author = {K.K. Pabodha M. Kannangara and Zhi Ding and Wan-Huan Zhou},
keywords = {Surface settlement, Earth pressure balance shield, Filed measurement, Shield operational parameters},
abstract = {Surface settlements caused by twin tunneling are a major interest in underground space engineering. Most prevailing studies have investigated the surface settlements observed over twin tunnels constructed in clay. Yet, less attention is given to the twin tunnels excavated in silty sand, which is the focus of this study. A comprehensive field monitoring scheme was designed in the Hangzhou metro line six project to measure the surface settlements during twin tunneling by adopting earth pressure balance shields. The influence of four shield operational parameters, namely, face pressure, tail grouting pressure, penetration rate, and pitching angle on the surface settlements due to twin tunneling are explored. In general, the total settlement profiles observed over twin tunnels follow an inverted bimodal shape. The post-settlement observed over the 1st tunnel due to the 2nd tunnel excavation is non-trivial when the twin tunnels are spaced closely. Low face pressure and tail grouting pressure can induce excessive peak surface settlements during twin tunneling in silty sand.}
}
@article{GALAR201598,
title = {A survey of fingerprint classification Part II: Experimental analysis and ensemble proposal},
journal = {Knowledge-Based Systems},
volume = {81},
pages = {98-116},
year = {2015},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2015.02.015},
url = {https://www.sciencedirect.com/science/article/pii/S0950705115000581},
author = {Mikel Galar and Joaquín Derrac and Daniel Peralta and Isaac Triguero and Daniel Paternain and Carlos Lopez-Molina and Salvador García and José M. Benítez and Miguel Pagola and Edurne Barrenechea and Humberto Bustince and Francisco Herrera},
keywords = {Fingerprint classification, Feature extraction, Classification, Fingerprint recognition, SVM, Neural networks, Ensembles, Orientation map, Singular points, Experimental evaluation},
abstract = {In the first part of this paper we reviewed the fingerprint classification literature from two different perspectives: the feature extraction and the classifier learning. Aiming at answering the question of which among the reviewed methods would perform better in a real implementation we ended up in a discussion which showed the difficulty in answering this question. No previous comparison exists in the literature and comparisons among papers are done with different experimental frameworks. Moreover, the difficulty in implementing published methods was stated due to the lack of details in their description, parameters and the fact that no source code is shared. For this reason, in this paper we will go through a deep experimental study following the proposed double perspective. In order to do so, we have carefully implemented some of the most relevant feature extraction methods according to the explanations found in the corresponding papers and we have tested their performance with different classifiers, including those specific proposals made by the authors. Our aim is to develop an objective experimental study in a common framework, which has not been done before and which can serve as a baseline for future works on the topic. This way, we will not only test their quality, but their reusability by other researchers and will be able to indicate which proposals could be considered for future developments. Furthermore, we will show that combining different feature extraction models in an ensemble can lead to a superior performance, significantly increasing the results obtained by individual models.}
}
@article{NJOYA2022212,
title = {Lifetime optimization of dense wireless sensor networks using continuous ring-sector model},
journal = {Future Generation Computer Systems},
volume = {129},
pages = {212-224},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21004684},
author = {Arouna Ndam Njoya and Christopher Thron and Marah Nana Awa and Ado Adamou Abba Ari and Abdelhak Mourad Gueroui},
keywords = {Dense wireless sensor network, Data aggregation, Lifetime extension, Linear programming, Data compression},
abstract = {Wireless sensor networks (WSNs) are becoming increasingly utilized in applications that require remote collection of data on environmental conditions. In particular dense WSNs are emerging as an important sensing platforms for the Internet of Things (IoT). WSNs are able to generate huge volumes of raw data, which require network structuring and efficient collaboration between nodes to ensure efficient transmission. In order to reduce the amount of data carried in the network, data aggregation is used in WSNs to define a policy of data fusion and compression. In this paper, we investigate a model for data aggregation in a dense WSN with a single sink. The model divides a circular coverage region centered at the sink into patches which are intersections of sectors of concentric rings, and data in each patch is aggregated at a single node before transmission. Nodes only communicate with other nodes in the same sector. Based on these assumptions, we formulate a linear programming problem to maximize system lifetime by minimizing the maximum proportionate energy consumption over all nodes. Under a wide variety of conditions, the optimal solution employs two transmissions mechanisms: direct transmission, in which nodes send information directly to the sink; and stepwise transmission, in which nodes transmit information to adjacent nodes. An exact formula is given for the proportionate energy consumption rate of the network. Asymptotic forms of this exact solution are also derived, and are verified to agree with the linear programming solution. We investigate three strategies for improving system lifetime: nonuniform energy and information density; iterated compression; and modifications of rings. We conclude that iterated compression brings the greatest increase in system lifetime, but at the cost of possible information loss.}
}
@article{ISLAM2021103008,
title = {Context-aware scheduling in Fog computing: A survey, taxonomy, challenges and future directions},
journal = {Journal of Network and Computer Applications},
volume = {180},
pages = {103008},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103008},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521000357},
author = {Mir Salim Ul Islam and Ashok Kumar and Yu-Chen Hu},
keywords = {Fog computing, Context-awareness, Scheduling, Resource management, Resource estimation, Resource provisioning, Contextual information},
abstract = {Fog computing extends Cloud-based facilities and stays in the vicinity of the end-users to provide an attractive solution to a diverse range of latency-sensitive applications. The applications are becoming more sophisticated, context-aware, and computation-intensive due to varying situational and environmental conditions in order to meet the ever-increasing users’ demands. Further, resource heterogeneity, dynamic nature, resource limitations, and unpredictability of the Fog environment make scheduling of application tasks while satisfying Quality of Service (QoS) requirements a challenging job. To overcome these issues various scheduling strategies have been proposed considering contextual information of different entities involved in Fog computing. This survey represents a comprehensive literature analysis pertaining to context-aware scheduling in Fog computing. It provides detailed comparison of existing scheduling approaches based on important factors such as context-aware parameters, case studies, performance metrics, and evaluation tools along with advantages and limitations. It also presents detailed taxonomy, performance metrics, and context-aware parameter analysis. Further, it list several issues and challenges. This study will aid the research community in exploring future research directions and essential aspects of scheduling approaches using different types of contextual information.}
}
@article{PARK2016126,
title = {Recent advancements in the Internet-of-Things related standards: A oneM2M perspective},
journal = {ICT Express},
volume = {2},
number = {3},
pages = {126-129},
year = {2016},
note = {Special Issue on ICT Convergence in the Internet of Things (IoT)},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2016.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S2405959516300911},
author = {Hyuncheol Park and Hoichang Kim and Hotaek Joo and JaeSeung Song},
keywords = {OneM2M, Internet of Things, Interoperability, Interworking},
abstract = {Internet of Things (IoT) devices are likely to be developed by using different technologies and standards. Such IoT devices are being deployed in large numbers in various domains; thus, collaboration between standards bodies to provide interoperability is a key to the success of IoT. This paper describes a recent effort in oneM2M to broaden the IoT ecosystem. Semanticsenabled IoT platforms allow IoT devices to understand the meaning of IoT data in a standard way. oneM2M interoperability specifications guarantee that IoT devices from different vendors can communicate with each other. Additionally, an interworking framework bridges different IoT technologies.}
}
@article{HASSIJA2020102145,
title = {BitFund: A blockchain-based crowd funding platform for future smart and connected nation},
journal = {Sustainable Cities and Society},
volume = {60},
pages = {102145},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102145},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720301323},
author = {Vikas Hassija and Vinay Chamola and Sherali Zeadally},
keywords = {Blockchain, Crowd funding, Distributed systems, Game theory, Nash equilibrium, Smart contracts},
abstract = {The rapid growth in information technology and related talent has let to a competition among the investors to look for the best available talent. Additionally, the diverse range of directions in technology, gives a lot of options to the applicants to choose from. In such a scenario, it is imperative to link the most appropriate investors and developers in a secure and cost optimal way. Blockchain technology helps in creating a decentralized network of users where the transactions are recorded in an open distributed ledger. These features of blockchain enable a transparent and cost-effective platform for different applications. Based on the need to an effective crowdfunding platform for developing smart nation and the inherent features of blockchain technology, we propose a global crowdfunding platform called BitFund. Investors and developers can act as different nodes of the network. The investors can request a specific project and they can give their initial bid value in terms of time, cost and maintenance required. Different developers can bid with different values of the same parameters to get the project ownership. A smart contract is deployed between the investors and the developers to reach an optimal solution for the investors. Multiple iterations of bidding are carried out between the developers until the optimal solution or equilibrium is reached. The experimental results show that the proposed model yields better results as compared to other generic algorithms for crowdfunding.}
}
@article{SALAZARCABRERA2020729,
title = {Sustainable transit vehicle tracking service, using intelligent transportation system services and emerging communication technologies: A review},
journal = {Journal of Traffic and Transportation Engineering (English Edition)},
volume = {7},
number = {6},
pages = {729-747},
year = {2020},
issn = {2095-7564},
doi = {https://doi.org/10.1016/j.jtte.2020.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2095756420301409},
author = {Ricardo Salazar-Cabrera and Álvaro {Pachón de la Cruz} and Juan Manuel {Madrid Molina}},
keywords = {Transportation engineering, Intelligent transportation systems, Transit vehicle, ITS architecture, Tracking, Long range},
abstract = {The most salient problems of transit vehicle service in Latin American intermediate cities include: the high number of passengers involved in traffic accidents; traffic congestion caused by transit vehicles, and pollution generated by these vehicles, which increases in high congestion scenarios. To improve upon this situation, a research was conducted on the transit vehicle tracking service, which is a basic service for implementing mobility solutions for the aforementioned problems, the most relevant characteristics of this service for the context of Latin American intermediate cities were identified, and an implementation was proposed. This paper presents the four stages of the study: (a) a review of the state-of-the-art of services or systems related to vehicle tracking, including wireless communications technologies, implemented sustainability approaches, usage of special algorithms for efficiency improvement, and the intelligent transportation system (ITS) architecture used as a basis; (b) the process of identifying relevant characteristics of the service for a given context; (c) proposal of an ITS architecture for this service in an intermediate city, its requirements and the suggested technologies; and (d) development of experiments for validating usage of the key suggested technologies. The review allowed to identify the main service characteristics, with regard to vehicle positioning technologies, the recommended wireless communication technology (long range, LoRa), energy consumption considerations, and use of artificial intelligence (AI) to calculate waiting time of users at bus stops. Finally, an ITS architecture for the city of Popayán (Colombian city) considering the aforementioned characteristics is proposed, and the experiments related to the use of these technologies are described in detail.}
}
@article{UNIYAL2020107297,
title = {5GUK Exchange: Towards sustainable end-to-end multi-domain orchestration of softwarized 5G networks},
journal = {Computer Networks},
volume = {178},
pages = {107297},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107297},
url = {https://www.sciencedirect.com/science/article/pii/S1389128619316287},
author = {Navdeep Uniyal and Abubakar Siddique Muqaddas and Dimitrios Gkounis and Anderson Bravalheri and Shadi Moazzeni and Fragkiskos Sardis and Mischa Dohler and Reza Nejabati and Dimitra Simeonidou},
keywords = {5G Networks, Orchestration, MANO, Multi-domain network service orchestration},
abstract = {5G networks envisage to support a range of vertical industries, circumventing any potential barriers from converging various network technologies and administrative domains. Current solutions focus only on provisioning services within single administrative domains. There is also lack of standards for sustainable end-to-end multi-domain solutions that can use existing Network Function Virtualization (NFV) Management and Orchestration (MANO) systems. This is important to enable operators to collaborate and create innovative end-to-end services in a sustainable environment, where stakeholders can benefit without compromises. In this article, we present the 5GUK Exchange (5GUKEx), a novel hierarchical architecture to enable end-to-end orchestration with minimum overhead in complexity and performance while also allowing operators to maintain full control of their infrastructure. 5GUKEx allows operators to use their existing MANO systems for the single domain orchestration and build a multi-domain API based on standardized models exposed by service catalogues to coordinate the end-to-end service orchestration and interconnection. We built a prototype of the 5GUKEx and evaluated its performance through emulations showing that the 5GUKEx introduces minimum overhead. We also discuss the use-cases and trials using 5GUKEx in addition to the experiments focusing on the flexible nature of architecture, allowing us to use 5GUKEx to provide connectivity among multi domains over optical transport network.}
}
@article{LYU2021105,
title = {Affine particle-in-cell method for two-phase liquid simulation},
journal = {Virtual Reality & Intelligent Hardware},
volume = {3},
number = {2},
pages = {105-117},
year = {2021},
note = {Special issue on simulation and interaction of fluid and solid dynamics},
issn = {2096-5796},
doi = {https://doi.org/10.1016/j.vrih.2020.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S2096579621000152},
author = {Luan Lyu and Wei Cao and Enhua Wu and Zhixin Yang},
keywords = {Fluid simulation, Two-Phase flow, Affine particle-in-cell method},
abstract = {Background
The interaction of gas and liquid can produce many interesting phenomena, such as bubbles rising from the bottom of the liquid. The simulation of two-phase fluids is a challenging topic in computer graphics. To animate the interaction of a gas and liquid, MultiFLIP samples the two types of particles, and a Euler grid is used to track the interface of the liquid and gas. However, MultiFLIP uses the fluid implicit particle (FLIP) method to interpolate the velocities of particles into the Euler grid, which suffer from additional noise and instability.
Methods
To solve the problem caused by fluid implicit particles (FLIP), we present a novel velocity transport technique for two individual particles based on the affine particle-in-cell (APIC) method. First, we design a weighed coupling method for interpolating the velocities of liquid and gas particles to the Euler grid such that we can apply the APIC method to the simulation of a two-phase fluid. Second, we introduce a narrowband method to our system because MultiFLIP is a time-consuming approach owing to the large number of particles.
Results
Experiments show that our method is well integrated with the APIC method and provides a visually credible two-phase fluid animation.
Conclusions
The proposed method can successfully handle the simulation of a twophase fluid.}
}
@article{LI2021113,
title = {Distance constraint between features for unsupervised domain adaptive person re-identification},
journal = {Neurocomputing},
volume = {462},
pages = {113-122},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.07.061},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221011371},
author = {Zhihao Li and Bing Han and Xinbo Gao and Biao Hou and Zongyuan Liu},
keywords = {Person re-ID, Domain adaptation, Distance constraint, Self-supervised learning},
abstract = {Many superior person re-identification (re-ID) approaches face a challenge: their performance show disastrous when all supervised models are generalized to a new domain. Some researchers have recently proposed domain adaptive person re-ID methods to address this difficulty, whereas they directly leveraged the target-domain data that would generate lots of noisy pseudo labels. Hence, this paper proposes a distance constraint between features (DCF) method, which clusters the feature distribution fitted the real target-domain data. We assemble different parts of one person for multi-scale self-supervised learning. After introducing domain invariance and designing the inter-image and inter-class distance constraint to regulate distances between target samples, the feature distribution extracted from the encoder trained by the source data can fit the real target data distribution, which leads our domain adaptive model to enjoy the more reliable clustering results and thus obtain a great identification performance in target domain. Extensive experiments demonstrate our approach outperforms state-of-the-art methods on three large-scale released datasets.}
}
@article{SABA2019189,
title = {Development of new ontological solution for an energy intelligent management in Adrar city},
journal = {Sustainable Computing: Informatics and Systems},
volume = {21},
pages = {189-203},
year = {2019},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2019.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S221053791830341X},
author = {Djamel Saba and Youcef Sahli and Fonbeyin Henry Abanda and Rachid Maouedj and Boudjemaa Tidjar},
keywords = {Energy efficient, Ontology, Semantic web rule language, Smart home, Web ontology language},
abstract = {Currently, the growth in building energy consumption presents raises concerns with greenhouse gases and environmental pollution. The building occupants face significant difficulties to control the consumed power due to several instabilities such as climate change and human behavior. Therefore, it is necessary to have a decision tool that optimizes the consumed energy and ensures an acceptable comfort for the occupants. This article presents an intelligent solution based on an ontology that presents knowledge about the internal and external environment of a residence, as well as the occupants’ behavior and activities. The system openness with the external environment, the knowledge presentation flexibility built on Web Ontology Language (OWL) and the possibility of intelligent reasoning using Semantic Web Rule Language (SWRL) are the main reasons for choosing the ontological approach. The proposed ontology is applied to a real home located in the Adrar city, in the Algerian Sahara. A comparison between two scenarios (with and without the proposed system, Ontological Solution for Energy Intelligent Management (OSEIM) revealed the effectiveness of the proposed solution. The obtained results present a significant energy saving of 4.58%.}
}
@article{LIU2021102256,
title = {Special issue editorial: Smart supply chains and intelligent logistics services},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {147},
pages = {102256},
year = {2021},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2021.102256},
url = {https://www.sciencedirect.com/science/article/pii/S1366554521000326},
author = {Weihua Liu and J. {George Shanthikumar} and Paul {Tae-Woo Lee} and Xiang Li and Li Zhou},
keywords = {Smart supply chain, Intelligent logistics services, Research progress},
abstract = {This special issue explores original practices and applications in Smart Supply Chains (SSCs) and Intelligent Logistics Services (ILSs), inviting academics to contribute a better understanding of SSCs and ILSs in tandem with advanced OR methods. This editorial summarizes discussions and major findings from the featured papers in SSCs and ILSs, including the studies exploring the impacts of government policy, process optimization, system design, and the choice of strategies and so on.}
}
@article{HENG2021102454,
title = {Understanding AI ecosystems in the Global South: The cases of Senegal and Cambodia},
journal = {International Journal of Information Management},
pages = {102454},
year = {2021},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2021.102454},
url = {https://www.sciencedirect.com/science/article/pii/S026840122100147X},
author = {Samedi Heng and Konstantinos Tsilionis and Christelle Scharff and Yves Wautelet},
keywords = {Global South, AI readiness, AI ecosystems, Digital transformation},
abstract = {The Global South (GS) refers to a block of countries in the process of rapidly catching up with the industrialization of their economies. GS countries are trying to leverage their growing demand for innovative products and services to negotiate the uptake of novel technologies such as Artificial Intelligence (AI). The latter can help such countries further stimulate their economic growth and become influential in dictating policies that could advance global development. However, a misaligned AI-adoption strategy entails the risk of alienating the social, economic, and even cultural requirements of such countries, ultimately leading to the incorporation of technologies not serving the needs of their users. Subsequently, we conduct a study whose goal is to provide guidelines on how to perform a comprehensive analysis of the AI ecosystems in GS countries, to determine their readiness to adopt and utilize beneficially these technologies. For this, we performed a qualitative case study of two GS countries, namely Senegal and Cambodia. The depiction of their AI ecosystems unveiled the need to stimulate their societies (i.e., by media exposure, education, etc.) in discerning the practical effects of AI. However, an impactful AI implementation requires a reciprocated satisfaction of the needs of multiple contributing actors. Finally, particular recommendations are offered at the level of these countries’ academic, industrial, and governmental constitutions, suggesting to focalize their resources in order to better energize (and optimally disperse) their research and entrepreneurial capabilities that could help identify the ways in which AI solutions can be of added-value within the premises of these two countries.}
}
@article{BULU20145625,
title = {Algorithm-embedded IT applications for an emerging knowledge city: Istanbul, Turkey},
journal = {Expert Systems with Applications},
volume = {41},
number = {12},
pages = {5625-5635},
year = {2014},
note = {EMPIRICAL APPROACHES IN KNOWLEDGE CITY RESEARCH},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2014.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0957417414000761},
author = {Melih Bulu and Muhammed Ali Önder and Vural Aksakalli},
keywords = {Algorithm-embedded information technology application, Information technology, Decision support system, Expert system, Knowledge city, Istanbul},
abstract = {As city resources around the world begin to stretch beyond capacity due to ever-increasing population, a major challenge for an emerging knowledge city is to maintain high-quality living conditions for its residents. It is therefore imperative existing city infrastructural resources are used in an optimal manner by minimizing cost and maximizing utility. Such infrastructural resources include transportation networks, electricity, water and natural gas lines, sewers, and waste sites. To that end, algorithm-embedded information technology tools have proven to be tremendously useful for city decision makers, and technologies using algorithm-embedded systems are being used more frequently than ever before. In particular, as one of the emerging knowledge cities in the world, Istanbul has been deploying such applications at various levels for better use of the city’s resources. The purpose of this study is two-fold: classify algorithm-embedded information technology application areas related to management of infrastructural resources in a city in a systematic way, and; provide an up-to-date review of each application area and investigate the level of algorithm-embedded information technology use in Istanbul. The study has implications for the city officials as well as officials of other emerging world knowledge cities regarding the use of existing algorithm-embedded information technology tools in their cities.}
}
@article{TOMAR2018451,
title = {Traffic Management using Logistic Regression with Fuzzy Logic},
journal = {Procedia Computer Science},
volume = {132},
pages = {451-460},
year = {2018},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.05.159},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918308937},
author = {Anurag Singh Tomar and Mridula Singh and Girish Sharma and K.V. Arya},
keywords = {Logistic regression, Traffic management, congestion, fuzzy logic, optimization algorithm, fuzzy controller},
abstract = {Traffic congestion is one of the major problems in most of the cities across the globe and it leads to several other problems like pollution, time wastage, long traffic queues on roads and may cause accidents. Improvement of Road infrastructure is not always the feasible solution to resolve the problem. In real life scenario shorter distance route towards the destination attracts majority of people and at times it may aggravate traffic jam conditions. Therefore, a real time traffic information for intelligent decision making to decide the route preference is required. Moreover, a system which considers the factor of distance towards the destination along with real time traffic situation on that route will add to the solution to the congestion problem. certain parameters such as distance, weather condition, road location, day of week and time are considered to formulate the problem and to find solutions to these problems This paper outlines a combination of logistic regression with fuzzy logic such that a smart decision to preferred path can be taken. It is used to compute the probability of each possible path by considering the real time traffic information, distance and road condition and later is used to take decisions in an uncertain scenario. Proposed Method considers the number of parameters like distance, weather condition, road location, day of week and time.}
}
@article{HASEEB2020101129,
title = {EBDS: An energy-efficient big data-based secure framework using Internet of Things for green environment},
journal = {Environmental Technology & Innovation},
volume = {20},
pages = {101129},
year = {2020},
issn = {2352-1864},
doi = {https://doi.org/10.1016/j.eti.2020.101129},
url = {https://www.sciencedirect.com/science/article/pii/S2352186420314292},
author = {Khalid Haseeb and Soojeong Lee and Gwanggil Jeon},
keywords = {Big data, Data security, Energy efficient, Internet of Things, Routing},
abstract = {The Internet of Things (IoT) has a rapid growth in the development of smart and green environments. The IoT-based physical objects are interconnected with sensors, actuators, and data centers to gather, process and store the environmental data. The collected data is further utilized for post analysis and smarter decisions by the Base Station (BS). However, the limited resources of IoT-based sensors in terms of energy, processing, and transmission power place pressure on the development of green societies. Moreover, the IoT-based network also connects with big data using the Internet to manipulate and store a huge amount of data on the cloud. Therefore, along with the decreasing of energy consumption, security, and data integrity is other research concerns. Accordingly, an energy-efficient and big data-based secure framework using the Internet of Things for a green environment is presented. Firstly, the IoT-based sensors are connecting for data gathering and perform data routing using the Dijkstra-based optimal algorithm. Such a proposed algorithm imposes lower overheads and minimizes energy consumption in finding the most reliable and least transmission distance routes. Secondly, it also secures the generated big data from network attackers and maintains the consistency of the green environment. The experimental results reveal the EBDS framework increases the performance of green environment for energy consumption by 16%, packet drop ratio by 33%, network throughput by 13%, end-to-end delay by 15.5%, and route stability by 16% in non-uniform data traffic as compared to other work.}
}
@article{XU202023,
title = {ARVMEC: Adaptive Recommendation of Virtual Machines for IoT in Edge–Cloud Environment},
journal = {Journal of Parallel and Distributed Computing},
volume = {141},
pages = {23-34},
year = {2020},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2020.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0743731520302045},
author = {Yajing Xu and Junnan Li and Zhihui Lu and Jie Wu and Patrick C.K. Hung and Abdulhameed Alelaiwi},
keywords = {Edge computing, Cloud computing, Internet of Things, Ensemble learning, VM recommendation},
abstract = {Edge–cloud services provide heterogeneous virtual machine types to run various IoT workloads. Choosing the appropriate VM configuration for each workload can effectively improve performance and reduce costs. This article proposes ARVMEC, Adaptive Recommendation of Virtual Machines for IoT in Edge-Cloud Environment, which can always provide users with the best VM recommendation according to their own budget or deadline constraints. ARVMEC uses a tree-based ensemble learning algorithm to make accurate predictions on workload performance for all VM types. It can abstract user purposes in a more flexible and general mode, thus offer reasonable recommendations accordingly. Compared to state-of-art methods, ARVMEC can make better predictions with a 15% improvement in accuracy.}
}
@article{JACOBSON201910,
title = {Distributed intelligence: A critical piece of the microgrid puzzle},
journal = {The Electricity Journal},
volume = {32},
number = {5},
pages = {10-13},
year = {2019},
issn = {1040-6190},
doi = {https://doi.org/10.1016/j.tej.2019.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1040619019301241},
author = {Dan Jacobson and Larry Dickerman},
keywords = {Distributed computing, Analytics, Utility IoT, DER, Sensor networks, Microgrid, Load management, Capacity management, Grid intelligence, AMI},
abstract = {Electric utilities are adding distributed computing capabilities across distribution systems at an accelerated rate. In fact, IDC predicts that the industrial IoT market – which includes utility applications – will exceed $745 billion in 2019, with $61 billion of that serving the utilities sector. Utility IoT applications involve an array of sensors from the substation down to customer premises that provide data and automated controls. As microgrids draw more interest to promote grid stability and DER integration, intelligent sensor networks – and the analytics they support – will become an increasingly important management tool. This article explores some ways sensor data, analytics and distributed computing can and are supporting new distributed energy resource strategies and initiatives.}
}
@article{SUN2021103223,
title = {Multi-objective optimisation of a graphite-slag conductive composite applying a BAS-SVR based model},
journal = {Journal of Building Engineering},
volume = {44},
pages = {103223},
year = {2021},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2021.103223},
url = {https://www.sciencedirect.com/science/article/pii/S2352710221010810},
author = {Junbo Sun and Xiangyu Wang and Junfei Zhang and Fan Xiao and Yuantian Sun and Zhenhua Ren and Genbao Zhang and Shukui Liu and Yufei Wang},
keywords = {Multi-objective optimisation, Graphite, Waste slag, Mechanical strength, Electrical resistivity},
abstract = {Electrically conductive cementitious composites (ECCC) possesses numerous virtues including low resistivity and high strain sensitivity, which can be applied as a conductive sensor to monitor structural health. This study produced ECCC with three conductive ingredients, consisting of graphite powder (GP), ground granulated blast-furnace slag (GGBS), and steel slag (SS). The uniaxial compressive strength (UCS), flexural strength (FS), and electrical conductivity were investigated, which showed that the GP enhanced the conductivity more remarkably than the other conductive materials. However, it simultaneously reduced the UCS and FS of ECCC. Also, ECCC samples containing SS had higher FS and conductivity than that containing GGBS. To overcome the challenge of excessive variables, this study introduced an artificial-intelligence (AI) based multi-objective optimisation (MOO) model with 252 samples for the FS test and 336 samples for the resistivity experiment. The support vector regression (SVR) was trained with hyperparameters tuned by the beetle antennae search (BAS). The high correlation coefficients (0.981) were achieved on both test sets. The BAS-SVR model acted as the objective function to develop the multi-objective beetle antennae search algorithm (MOBAS-SVR). The Pareto front of a tri-objective mixture optimisation design for ECCC (cost, FS, and resistivity) was successfully obtained as a design reference. Furthermore, sensitivity research was implemented to comprehend the importance of the variables for the FS and electrical resistivity.}
}
@article{KIGUCHI2021121438,
title = {Predicting winners and losers under time-of-use tariffs using smart meter data},
journal = {Energy},
volume = {236},
pages = {121438},
year = {2021},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2021.121438},
url = {https://www.sciencedirect.com/science/article/pii/S0360544221016868},
author = {Y. Kiguchi and M. Weeks and R. Arakawa},
keywords = {Time-of-use pricing, Demand-side management, Smart meters, Electricity consumption modelling, Load shifting, Residential electricity demand},
abstract = {Time-of-use electricity tariffs may become more widespread as smart meters are installed across deregulated domestic electricity markets. Time-of-use tariffs and other methods of time-dependant pricing can be mutually beneficial, realising a cost reduction for both energy companies and customers if the customer responds to the price signalling. However, such tariffs are likely to create positive and negative financial outcomes for individuals because of customer engagement and potential peak shifting capacity. Identifying potential reducers or non-reducers beforehand can optimise a time-of-use programme design, in turn maximising the outcome of the programme. This paper provides a statistical model to identify the characteristics of so-called winners and losers - or households that would be better or worse off under a time-of-use tariff - using only ex ante information. The model's accuracy reaches a reliable level using historical electricity load and basic household characteristics. This accuracy can be further improved if online activity data is available - providing justification for digital interaction and gamification in time-of-use programmes. This paper also publishes a new public dataset of 1423 households in Japan, including historical smart meter data, household characteristics and online activity variables during the time-of-use intervention period in 2017 and 2018.}
}
@article{HALDER2021103186,
title = {Monitoring the effect of urban development on urban heat island based on remote sensing and geo-spatial approach in Kolkata and adjacent areas, India},
journal = {Sustainable Cities and Society},
volume = {74},
pages = {103186},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103186},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721004649},
author = {Bijay Halder and Jatisankar Bandyopadhyay and Papiya Banik},
keywords = {Climate change impact, Urban Heat Island (UHI), Land Surface Temperature (LST), Remote Sensing, Kolkata and surrounding area},
abstract = {Climate change and the rapid urbanization process can trigger the current urban heat island effect. An urban heat island is categorized by temperature variation between urban and rural environments. Urban areas are mostly hotter than rural areas due to urbanization, population pressure, industrialization, vegetation insufficiency, and transportation system. Thermal remote sensing was used to carry out the exploration of urban heat islands over Kolkata municipality and surrounding urban and rural-urban fringe areas, India. This study was identify the land use/land cover change dynamics and land surface temperature analysis as well as the correlation analysis of LST, LULC, NDVI, and NDBI. Built-up areas were located 22.01% (1990), 31.44% (2000), 44.21% (2010) and 55.768% (2020). The Annual temperature was increased 0.157 °C per year. The relationship between LST and NDVI was showing a negative correlation because of the vegetated area affected due to urban expansion. The relation between LST and NDBI resulted in a positive correlation because of anthropogenic activities. The CA-ANN was used for LULC prediction of the year 2030 and 2050 for future urban expansion and environmental degradation. Those areas need proper planning for better healthy livelihood and also protect our environment otherwise climate change will affect the entire location.}
}
@article{IQBAL2019345,
title = {A taxonomic overview and pilot study for evaluation of Augmented Reality based posture matching technique using Technology Acceptance Model},
journal = {Procedia Computer Science},
volume = {163},
pages = {345-351},
year = {2019},
note = {16th Learning and Technology Conference 2019Artificial Intelligence and Machine Learning: Embedding the Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.12.117},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919321568},
author = {Javid Iqbal and Manjit Singh Sidhu},
keywords = {Augmented Reality, Kinect, Dance learning, pose matching},
abstract = {Motor skill training, posture matching and Augmented Reality (AR) based learning technology are considered to be the cornerstones of dance learning paradigm. In this paper, an AR based posture matching technique is presented based upon skeletal mapping and movement matching where each posture is modelled by a sequence of pivotal movements and continuous data frames. An extension of the previously published work by the authors, this paper aims to provide a taxonomic overview of dance learning/ training technologies with respect to existing learning theories. Furthermore, the proposed system is evaluated using the Technology Acceptance Model (TAM) and a pilot study is carried out to assess the acceptability of the system. The results of the pilot study are also utilized for identifying flaws and to calculate the sample size for further evaluation using a larger group of subjects. This research also aims at providing a taxonomical knowledge and categorization of the proposed Augmented Reality Dance Training System (ARDTS) in the state-of-art hierarchical structure of learning theories.}
}
@article{MARIANI2019102317,
title = {Coordination in Socio-technical Systems: Where are we now? Where do we go next?},
journal = {Science of Computer Programming},
volume = {184},
pages = {102317},
year = {2019},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2019.102317},
url = {https://www.sciencedirect.com/science/article/pii/S0167642319301157},
author = {Stefano Mariani},
keywords = {Socio-technical gap, Coordination, Socio-technical systems, Social machines, Observation-based coordination},
abstract = {Despite Socio-Technical Systems (STS) have been defined and described long ago, and dedicated software engineering techniques and guidelines have been designed and assessed in different application domains, the issue of coordinating people and software artefacts in these STS has been widely recognised only recently, and gained momentum to generate some promising engineering approaches. In this paper, we aim to shed some light into the current status of the research landscape concerned with engineering coordination within STS. Accordingly, we highlight the main challenges yet to be tackled as stemming from real world problems, present the opportunities to deal with them as arising from different research threads, and delve into a few selected coordination approaches for specific STS application domains.}
}
@article{DABBAGHJAMANESH202015,
title = {Real-time monitoring and operation of microgrid using distributed cloud–fog architecture},
journal = {Journal of Parallel and Distributed Computing},
volume = {146},
pages = {15-24},
year = {2020},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2020.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0743731520303130},
author = {Morteza Dabbaghjamanesh and Amirhossein Moeini and Abdollah Kavousi-Fard and Alireza Jolfaei},
keywords = {Microgrid, Energy management, Fog computing, Consensus, Distributed optimization},
abstract = {In this paper, a new distributed multi-agent framework based on the three layers’ fog computing architecture is developed for real-time microgrid economic dispatch and monitoring. To this end, the changes of load at any time will be tracked by the proposed technique, considering unit sudden exits and entries. Moreover, to make the system more realistic, different renewable energies, including photovoltaics (PVs), wind turbines (WTs), fuel cells (FCs), and microturbines (MT) are considered in the proposed technique. To overcome the complexity of the problem, by using advantages of fog computing, a new fast consensus-based optimization algorithm is used, which is modified based on the fuzzy adaptive leader technique. Finally, the proposed technique is simulated and tested on microgrids with 6 and 14 buses, respectively. Simulation results demonstrate and validate the effectiveness of the proposed technique, as well as the capability to track the changes of load with the interactions in real-time and the fast convergence rate.}
}
@article{GARCIAVICO202060,
title = {E2PAMEA: A fast evolutionary algorithm for extracting fuzzy emerging patterns in big data environments},
journal = {Neurocomputing},
volume = {415},
pages = {60-73},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220311139},
author = {Ángel Miguel García-Vico and Francisco Charte and Pedro González and David Elizondo and Cristóbal José Carmona},
keywords = {Emerging pattern mining, Evolutionary fuzzy systems, Multi-objective evolutionary algorithm, Big data},
abstract = {In this paper, a cooperative-competitive multi-objective evolutionary fuzzy system called E2PAMEA is presented for the extraction of emerging patterns in big data environments. E2PAMEA follows an adaptive schema to automatically employ different genetic operators according to the learning needs, which avoid the tuning of some parameters. It also employs a token-competition-based procedure for updating an elite population where the best set of patterns found so far is stored. In addition, a novel MapReduce procedure for an efficient computation of the evaluation function employed for guiding the search process is proposed. The method, called Bit-LUT employs a pre-evaluation stage where data is represented as a look-up table made of bit sets. This look-up table can be employed later in the chromosome evaluation by means of bitwise operations, reducing the computational complexity of the process. The experimental study carried out shows that E2PAMEA is a promising alternative for the extraction of high-quality emerging patterns in big data. In addition, the proposed Bit-LUT evaluation shows a significant improvement on efficiency with a great scalability capacity on both dimensions of data, which enables the processing of massive datasets faster than other alternatives.}
}
@article{BELLINI2021100276,
title = {High level control of chemical plant by industry 4.0 solutions},
journal = {Journal of Industrial Information Integration},
pages = {100276},
year = {2021},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2021.100276},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X2100073X},
author = {Pierfrancesco Bellini and Daniele Cenni and Nicola Mitolo and Paolo Nesi and Gianni Pantaleo and Mirco Soderi},
keywords = {IoT, Industry 4.0, Data driven, Synoptics},
abstract = {The push towards Industry 4.0 is constraining the industries to work in integrated supply chains. This implies to be open to the integration their production plants with other plants, and to provide access to their data and processes. In most cases, this also means to give access at data and flows to their customers to perform some synchronizations, permit supervision, and to create integrated control rooms, with synoptics and dashboards. This activity is also facilitated by the introduction of IoT solutions with IoT Devices, IoT Brokers, etc., which have a completely different approach with respect to DCS and SCADA solutions usually adopted in the industry for controlling their local productions. In this paper, Snap4Industry with its IoT development environment and framework for implementing the Control and Supervision of complex plant with multiple DCS and/or chains in the view of Industry 4.0 is presented. In particular, the paper describes the motivations/requirements and the actions performed to extend IoT Snap4City 100% open-source platform to comply with Industry 4.0 requirements. The main additions for creating Snap4Industry solution have been on: (i) industry protocols, (ii) custom widgets and synoptics Dashboards, (iii) new MicroServices for Node-RED for enabling the usage of synoptics as event driven devices, (iv) usage of WebSocket secure for the communication with custom Synoptics and Widgets for dashboards, automatized process for producing synoptics templates according to GDPR, and (v) the possibility of creating integrated workflows from data ingestion to synoptics. The paper also presents the assessment of the solution in terms of volume data and messages exchanged. The research has been founded into SODA R&D project founded by Regional Tuscany Gov.}
}
@article{KHALIL2020100293,
title = {Resource discovery techniques in the internet of things: A review},
journal = {Internet of Things},
volume = {12},
pages = {100293},
year = {2020},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2020.100293},
url = {https://www.sciencedirect.com/science/article/pii/S2542660520301256},
author = {Kasem Khalil and Khalid Elgazzar and Mohamed Seliem and Magdy Bayoumi},
keywords = {Internet of things, Resource discovery, Survey of resource discovery, Security, Privacy, CoAP protocol, UPnP protocol, MQTT protocol, AMQP protocol},
abstract = {The Internet of Things (IoT) has become a hot research topic in recent years to extend Internet connectivity to physical devices in our day-to-day activities. The high diversity of IoT objects, their properties, and capabilities pose significant challenges on the realization of open and interoperable IoT platforms. Resource discovery is a key concept that enables smarter interactions and communications between different IoT artifacts. The ultimate objective of resource discovery in IoT environments is to find devices and services of interest to the requesting entity. The unique characteristics of IoT environments such as limited resources and heterogeneity pose additional challenges on resource discovery. This paper investigates different resource discovery approaches, associated challenges, and state-of-the-art solutions, as well as providing a comprehensive study of the technological landscape related to resource discovery in IoT scenarios. It also presents the communication protocols that are used for resource discovery and outlines their advantages and drawbacks. Lastly, the paper describes the evaluation parameters of discovery methods in the IoT ecosystem.}
}
@article{ETEMADI2020109,
title = {Resource provisioning for IoT services in the fog computing environment: An autonomic approach},
journal = {Computer Communications},
volume = {161},
pages = {109-131},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.07.028},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420318405},
author = {Masoumeh Etemadi and Mostafa Ghobaei-Arani and Ali Shahidinejad},
keywords = {Fog computing, Resource provisioning, Autonomic computing, Bayesian learning},
abstract = {In the recent years, the Internet of Things (IoT) services has been increasingly applied to promote the quality of the human life and this trend is predicted to stretch for into future. With the recent advancements in IoT technology, fog computing is emerging as a distributed computing model to support IoT functionality. Since the IoT services will experience workload fluctuations over time, it is important to automatically provide the proper number of sufficient fog resources to address the workload changes of IoT services to avoid the over- or under-provisioning problems, meeting the QoS requirements at the same time. In this paper, an efficient resource provisioning approach is presented. This approach is inspired by autonomic computing model using Bayesian learning technique to make decisions about the increase and decrease in the dynamic scaling fog resources to accommodate the workload from IoT services in the fog computing environment. Also, we design an autonomous resource provisioning framework based on the generic fog environment three-tier architecture. Finally, we validate the effectiveness of our solution under three workload traces. The simulation results indicate that the proposed solution reduces the total cost and delay violation, and increases the fog node utilization compared with the other methods.}
}
@article{POPOVA2021470,
title = {Bus route network planning in cities beyond the Arctic Circle},
journal = {Transportation Research Procedia},
volume = {57},
pages = {470-478},
year = {2021},
note = {International conference of Arctic transport accessibility: networks and systems},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2021.09.074},
url = {https://www.sciencedirect.com/science/article/pii/S235214652100702X},
author = {Olga Popova and Andrey Gorev and Aleksandr Solodkij},
keywords = {route network planning, optimization, public passenger transport, demand for transportation, passenger traffic, transport zoning, route network duplication},
abstract = {In the context of the constantly increasing number of vehicles, growing population, and intensifying mobility, it is especially important to ensure the development of public transport and reasonable planning of the route network. Based on the studied foreign and domestic experience, the paper offers a method of bus route network planning, tested in Norilsk municipal entity. In cities beyond the Arctic Circle, transportation is characterized by complex natural and climatic conditions, a large spread of industrial enterprises, a significant increase in passenger traffic during rush hours, and difficult road conditions. The proposed method is based on a simulation model of bus transport planning, which makes it possible to assess the quality of public transport services, the route network performance, and the consequences of managerial and organizational decisions. The minimization of the time spent to reach work or other public places is proposed as the criterion to determine the route network option. The calculation results show that using mathematical simulation when planning the bus route network in Norilsk municipal entity, we can significantly reduce the total time spent by passengers on transportation (which is the main indicator of the quality of transport services), with a slight decrease in the density of the route network, and also reduce the operating costs of transportation.}
}
@article{BREGU2021107051,
title = {Online mixture-based clustering for high dimensional count data using Neerchal–Morel distribution},
journal = {Knowledge-Based Systems},
volume = {225},
pages = {107051},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107051},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121003142},
author = {Ornela Bregu and Nuha Zamzami and Nizar Bouguila},
keywords = {Count data, Overdispersion, Minorization–Maximization, Finite mixture models, Neerchal–Morel distribution, Minimum message length},
abstract = {In this paper, we propose an online learning technique for unsupervised clustering based on a mixture of Neerchal–Morel distributions (NMD). Online learning is able to overcome the drawbacks of batch learning in such a way that the mixture’s parameters can be updated instantly for any new data instances. Then, we use a novel Minorization–Maximization framework to address the issue of high dimensional optimization and the mixture’s parameters estimation. Finally, by implementing a minimum message length model selection criterion, the weights of irrelevant mixture components are driven towards zero, which resolves the problem of knowing the number of clusters beforehand. To evaluate the performance of our proposed model, we have considered 3 challenging real-world applications that involve high-dimensional count vectors, namely, topic clustering, medical diagnosis and human action recognition. The results show that the mixture model based on the NMD performs better than other similar models.}
}
@article{MIAO2020925,
title = {Intelligent task prediction and computation offloading based on mobile-edge cloud computing},
journal = {Future Generation Computer Systems},
volume = {102},
pages = {925-931},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.09.035},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19320862},
author = {Yiming Miao and Gaoxiang Wu and Miao Li and Ahmed Ghoneim and Mabrook Al-Rakhami and M. Shamim Hossain},
keywords = {Artificial intelligence, Computation offloading, Edge computing, LSTM, Task migration},
abstract = {Edge computing overcomes the high communication delay shortcoming of traditional cloud computing and provides computing services with high reliability and high bandwidth for mobile devices. At present, edge computing has become the forefront and hotspot of mobile-edge cloud computing (MEC) research. However, with the increasing requirements and services of mobile users, offloading strategy of simple edge computing is no longer applicable to MEC architecture. This paper puts forward a new intelligent computation offloading based MEC architecture in combination with artificial intelligence (AI) technology. According to the data size of computation task from mobile users and the performance features of edge computing nodes, a computation offloading and task migration algorithm based on task prediction is proposed. The computation task prediction based on LSTM algorithm, computation offloading strategy for mobile device based on task prediction, and task migration for edge cloud scheduling scheme are used to assist in optimizing the edge computing offloading model. Experiments show that our proposed architecture and algorithm can effectively reduce the total task delay with the increasing data and subtasks.}
}
@article{RANA2021,
title = {Accelerating IoT applications new wave with 5G: A review},
journal = {Materials Today: Proceedings},
year = {2021},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.03.292},
url = {https://www.sciencedirect.com/science/article/pii/S2214785321023427},
author = {Ankita Rana and Ashu Taneja and Nitin Saluja},
keywords = {5G, Wireless communication, IoT, Heterogeneous Network, IOT layers, mm wave, MIMO system},
abstract = {Wireless technologies are growing at a rapid speed in all around the world. In wireless technologies domain 5G is the next big thing to research. This topic elaborates about internet of things in 5G system which is definitely a game changer in upcoming generations. It’ll enhance the wireless services in upcoming times and will open the sea of opportunities as well as services. Recent 4G LTE technology is insufficient in matching up the data transfer speed, AI, self-driven vehicles, health systems, space technology and multiple instruments connectivity for next times. For these concerns 5G is going to be the pristine technology to meet our demands in future. Health systems and space technologies are changing at a superfast speed and these are currently on 4G technology. All the futuristic applications will require high band width, faster connectivity at multiple devices and latency with data rates. We’ll have an elaborative detailing about the obstacles and possibilities in 5G IOT systems.}
}
@article{GU2020102459,
title = {Survey of the low power wide area network technologies},
journal = {Journal of Network and Computer Applications},
volume = {149},
pages = {102459},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.102459},
url = {https://www.sciencedirect.com/science/article/pii/S1084804519303194},
author = {Fei Gu and Jianwei Niu and Landu Jiang and Xue Liu and Mohammed Atiquzzaman},
keywords = {Low power, Wide area, Long range, Internet of things (IoT)},
abstract = {With the number of connected devices in Internet of Things (IoT) increasing, the requirements for connectivity (e.g., battery life, deployment cost and coverage) are evolving to ensure effective communication between these devices. The emerging low power wide area (LPWA) technologies pave a way to address the problem as they can provide affordable connectivity to the low power devices over very large areas. In this paper, we first review the state-of-the-art wireless communication approaches in IoT and introduce the LPWA technologies by evaluating their performance in different metrics including coverage, bandwidth, cost, and so on. Then we survey different LPWA technologies and analyze their features by undertaking a detailed comparison. Furthermore, a number of challenges in developing different LPWA technologies are investigated and potential solutions are proposed to address these challenges. By exploring the characteristics of these LPWA technologies in different application domains, this paper provides guidance for efficiently solving the problems of the long-range communication between IoT devices, which have grown exponentially with people's growing demand for network applications.}
}
@article{SAVAGLIO20201038,
title = {Agent-based Internet of Things: State-of-the-art and research challenges},
journal = {Future Generation Computer Systems},
volume = {102},
pages = {1038-1053},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19312282},
author = {Claudio Savaglio and Maria Ganzha and Marcin Paprzycki and Costin Bădică and Mirjana Ivanović and Giancarlo Fortino},
keywords = {Software agents, Internet of Things, IoT},
abstract = {The disruptive potentials of the Internet of Things (IoT) entails multifaceted requirements and development issues (large scale deployments, heterogeneity, cyberphysicality, interoperability, distributed smartness, self-management, etc.). To adequately tackle them and to comprehensively support the development of the IoT ecosystem, the Agent-Based Computing (ABC) represents a proper and solid modeling, programming and simulation paradigm. Indeed, abstractions, design methods, technology and frameworks related to the ABC have been widely exploited, possibly jointly with other well-established/emerging computing paradigms, to actually develop advanced IoT ecosystem. This survey, an extension of our previous work, reports most relevant contemporary contributions in the field, aiming at assessing suitability of the ABC paradigm for the (current and future) IoT development.}
}
@article{LAMNABHILAGARRIGUE20171,
title = {Systems & Control for the future of humanity, research agenda: Current and future roles, impact and grand challenges},
journal = {Annual Reviews in Control},
volume = {43},
pages = {1-64},
year = {2017},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2017.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1367578817300573},
author = {Francoise Lamnabhi-Lagarrigue and Anuradha Annaswamy and Sebastian Engell and Alf Isaksson and Pramod Khargonekar and Richard M. Murray and Henk Nijmeijer and Tariq Samad and Dawn Tilbury and Paul {Van den Hof}},
keywords = {Systems & Control, Research challenges, Critical societal challenges},
abstract = {Following in the footsteps of the renowned report “Control in an Information Rich World,” Report of the Panel on “Future Directions in Control, Dynamics, and Systems” chaired by Richard Murray (2002), this paper aims to demonstrate that Systems & Control is at the heart of the Information and Communication Technologies to most application domains. As such, Systems & Control should be acknowledged as a priority by funding agencies and supported at the levels necessary to enable technologies addressing critical societal challenges. A second intention of this paper is to present to the industrials and the young research generation, a global picture of the societal and research challenges where the discipline of Systems & Control will play a key role. Throughout, this paper demonstrates the extremely rich, current and future, cross-fertilization between five critical societal challenges and seven key research and innovation Systems & Control scientific challenges. This paper is authored by members of the IFAC Task Road Map Committee, established following the 19th IFAC World Congress in Cape Town. Other experts who authored specific parts are listed below.}
}
@article{ZHAO2020107277,
title = {Person re-identification by integrating metric learning and support vector machine},
journal = {Signal Processing},
volume = {166},
pages = {107277},
year = {2020},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2019.107277},
url = {https://www.sciencedirect.com/science/article/pii/S0165168419303317},
author = {Dandan Zhao and Hongbin Wang and Hongpeng Yin and Zhengtao Yu and Huafeng Li},
keywords = {Person re-identification, Metric learning, Support vector machine, Latent identity},
abstract = {Person re-identification (PRID) refers to a technology of matching person across non-overlapping camera views. Metric learning is one of the most commonly used methods in PRID. However, most of them do not explore the label information carried by the labeled training samples, which limits the improvement of recognition performance. To this end, we propose a joint learning method by integrating the discriminative metric learning, the support vector machine (SVM) and the identity discriminator into one model, so as to realize joint construction of metric learning and identity discriminator. In this process, the label information carried by the training samples is fully exploited and the latent identify space of pedestrians is constructed by predicting the person’s identity. To mitigate the appearance ambiguity caused by the variations in camera views, body poses, illumination and occlusion, we develop an extreme distance regularization term and introduce it into the joint learning framework to refine the solution spaces of the metric learning and discriminator. Finally, we present a similarity measure method by combining the advantages of the metric learning and the identity discriminator. Experimental results on several benchmark datasets show that the proposed method significantly outperforms some state-of-the-art methods.}
}
@article{NING202067,
title = {Heterogeneous edge computing open platforms and tools for internet of things},
journal = {Future Generation Computer Systems},
volume = {106},
pages = {67-76},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.12.036},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19312841},
author = {Huansheng Ning and Yunfei Li and Feifei Shi and Laurence T. Yang},
keywords = {Edge computing, Cloud computing, Platform, Internet of Things(ioT), Architecture, Application},
abstract = {With the continuous development of Internet of Things (IoT) and the overwhelming explosion of Big Data, edge computing serves as an efficient computing mode for time stringent data processing, which can bypass the constraints of network bandwidth and delay, and has been one of the foundation of interconnected applications. Although edge computing has gradually become one of bridges between cloud computing centers and mobile terminals, the literature still lacks a thorough review on the recent advances in edge computing platforms. In this paper, we firstly introduce the definition of edge computing and advantages of edge computing platform. And then, we summarize the key technologies of constructing an edge computing platform, and propose a general framework for edge computing platform. The role of distributed storage management systems in building edge computing platform is elaborated in detail. Furthermore, we give some applications to illustrate how to use third-party edge computing platforms to build specific applications. Finally, we briefly outline current open issues of edge computing platform based on our literature survey.}
}
@article{MULLER20211607,
title = {Real-time combination of material flow simulation, digital twins of manufacturing cells, an AGV and a mixed-reality application},
journal = {Procedia CIRP},
volume = {104},
pages = {1607-1612},
year = {2021},
note = {54th CIRP CMS 2021 - Towards Digitalized Manufacturing 4.0},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.11.271},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121011690},
author = {Marcel Müller and Jonas Mielke and Yurii Pavlovskyi and Andreas Pape and Steffen Masik and Tobias Reggelin and Sebastian Häberer},
keywords = {material flow simulation, digital twin, mixed-reality, digital manufacturing system, online simulation, DES, MQTT, AGV},
abstract = {The integration of material flow simulation and digital planning solutions raises new challenges for the methodology and technical implementation of simulation models. The paper describes the use of a material flow simulation, which is controlling an AGV and interacting with digital twins of manufacturing cells. The digital twins determine the exact machining times. In addition, a mixed-reality application visualizes the entire system, while the communication via MQTT ensures a quasi-synchronous behavior of the different models and the AGV. The paper provides a literature review on similar solutions, describes the concept of our approach and specifies the technical implementation.}
}
@article{OZKAN2019208,
title = {Criminology in the age of data explosion: New directions},
journal = {The Social Science Journal},
volume = {56},
number = {2},
pages = {208-219},
year = {2019},
issn = {0362-3319},
doi = {https://doi.org/10.1016/j.soscij.2018.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S0362331918301514},
author = {Turgut Ozkan},
keywords = {Social science, Big data, Crime, Social media, Data-driven social science},
abstract = {This review discusses practical benefits and limitations of novel data-driven research for social scientists in general and criminologists in particular by providing a comprehensive examination of the matter. Specifically, this study is an attempt to critically evaluate ‘big data’, data-driven perspectives, and their epistemological value for both scholars and practitioners, particularly those working on crime. It serves as guidance for those who are interested in data-driven research by pointing out new research avenues. In addition to the benefits, the drawbacks associated with data-driven approaches are also discussed. Finally, critical problems that are emerging in this era, such as privacy and ethical concerns are highlighted.}
}
@article{ZHANG2021107946,
title = {Learn to abstract via concept graph for weakly-supervised few-shot learning},
journal = {Pattern Recognition},
volume = {117},
pages = {107946},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.107946},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321001333},
author = {Baoquan Zhang and Ka-Cheong Leung and Xutao Li and Yunming Ye},
keywords = {Few-shot learning, Weakly-supervised learning, Meta-learning, Concept graph},
abstract = {In recent years, a large number of meta-learning methods have been proposed to address few-shot learning problems and have shown superior performance. However, the explicit prior knowledge (e.g., concept graph) and weakly-supervised information are rarely explored in existing methods, which are usually free or cheap to collect. In this paper, we introduce a concept graph for the weakly-supervised few-shot learning, and propose a novel meta-learning framework, namely, MetaConcept. Our key idea is to learn a universal meta-learner inferring any-level classifier, so as to boost the classification performance of meta-learning on the novel classes. Specifically, we firstly propose a novel regularization with multi-level conceptual abstraction to train a universal meta-learner to infer not only an entity classifier but also a concept classifier at different levels via the concept graph (i.e., learn to abstract). Then, we propose a meta concept inference network as the universal meta-learner for the base learner, aiming to quickly adapt to a novel task by the joint inference of the abstract concepts and a few annotated samples. We have conducted extensive experiments on two weakly-supervised few-shot learning benchmarks, namely, WS-ImageNet-Pure and WS-ImageNet-Mix. Our experimental results show that (1) the proposed MetaConcept outperforms state-of-the-art methods with an improvement of 2% to 6% in classification accuracy; (2) the proposed MetaConcept is able to yield a good performance though merely training with weakly-labeled datasets.}
}
@article{ALZOUBI2022129,
title = {Blockchain technology as a Fog computing security and privacy solution: An overview},
journal = {Computer Communications},
volume = {182},
pages = {129-152},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421004321},
author = {Yehia Ibrahim Alzoubi and Ahmad Al-Ahmad and Hasan Kahtan},
keywords = {FC, BC, Challenge, Security, Privacy},
abstract = {The emergent of Fog computing as an extension of Cloud computing, from the center of the internet architecture to the IoT end user’s devices, aims to enhance the processing power of the resource-constraint IoT devices and deliver them other services since it locates close to these devices. This extension was also suggested to boost the standard of IoT system implementations thus decreasing energy consumption and latency for those applications that need fast responses. However, as stated in recent literature, Fog computing may have some important security and privacy challenges. On the other hand, Blockchain, which was generated and used in crypto-currencies, has been applied in a wider range of applications due to the security, privacy, distributed trust management, and reliability features provided. Among the applications, which have recently been attractive about blockchain is Fog computing. Blockchain in Fog computing may achieve a distributed and trusted, identity management, secure data, reputation, and payment systems. This survey discusses the state-of-the-art impact of the blockchain on the security and privacy of Fog computing. The findings elucidate the vision of blockchain in Fog computing-security and privacy-based enhancement and draw attention to open challenges and future research directions.}
}
@article{CARTER2022102430,
title = {Analyzing e-government design science artifacts: A systematic literature review},
journal = {International Journal of Information Management},
volume = {62},
pages = {102430},
year = {2022},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2021.102430},
url = {https://www.sciencedirect.com/science/article/pii/S0268401221001237},
author = {Lemuria Carter and Victoria Yoon and Dapeng Liu},
keywords = {E-government, Design science, E-government designs, Digital government, Literature review, Relevance, Rigor},
abstract = {Design science as a research paradigm is gaining popularity in the information systems (IS) discipline. E-government research explores IS artifacts designed to improve the quality and efficiency of public administration and service. This paper utilizes the E-government Design Research Model (EgovDR Model) to review e-government designs. Through a comprehensive literature review, this paper identifies prototypical e-government tasks for design science implementation and the corresponding solutions. We demonstrate whether and how the development and evolution of e-government designs continue to gain relevance in design science research. Additionally, this paper identifies and analyzes the theories employed in the literature to illustrate how the EgovDR Model has facilitated e-government designs in increasing rigor over time. Our findings indicate the majority of the workpractice tasks in existing e-government designs are decision-support tasks.}
}
@article{BASKAR2019144,
title = {An energy persistent Range-dependent Regulated Transmission Communication model for vehicular network applications},
journal = {Computer Networks},
volume = {152},
pages = {144-153},
year = {2019},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2019.01.027},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618306777},
author = {S. Baskar and S. Periyanayagi and P. Mohamed Shakeel and V.R. Sarma Dhulipala},
keywords = {Range-dependent Regulated Transmission, Direct short range communication, On-board unit, Road-side unit, VANET data dissemination},
abstract = {Multi Point Relays (MPRs) are engaged for supporting road-side communication by sharing traffic information, road conditions and additional notifications. Vehicular Networks (VNs) gather round information from these relay points for ease of information access and monitoring purpose. Managing the operation hours of relay sensors becomes vital as they cannot be frequently recharged but has to meet the vehicle requirements over a protracted time. MPR is a tiny sensor mote with built-in power source that is placed along the roadways for the allotment of useful information. The operation hours of the sensors depends on its battery power for which maintenance is important. To assurance uninterrupted communication and information sharing from MPR sensors, we propose a Range-dependent Regulated Transmission (RRT) with doze formulation. In a RRT, the assortment and power of the sensor nodes are modifiable with respect to vehicular density and type of information. The type of information is pre-informed by the nearest Road-Side Unit (RSU) from which the transmit power level of the MPR is decided. Similarly, the MPRs remain in sleep state when vehicle density is nil. The MPRs switch to operation state when it listens to a Vehicle Request (VR) packet from withers RSU or On-Board unit (OBU). RRT with doze formulation improves the communication time and rate of the road side relay units but adjusting the communication factors with respect to the vehicle requirements.}
}
@article{SALVINI2018278,
title = {Urban robotics: Towards responsible innovations for our cities},
journal = {Robotics and Autonomous Systems},
volume = {100},
pages = {278-286},
year = {2018},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2017.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0921889016303505},
author = {Pericle Salvini}
}
@article{CHOURASIA202110,
title = {Optimizing the performance of vehicular delay tolerant networks using multi-objective PSO and artificial intelligence},
journal = {Computer Communications},
volume = {177},
pages = {10-23},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421002309},
author = {Vishakha Chourasia and Sudhakar Pandey and Sanjay Kumar},
keywords = {VDTN, PSO, Multi-objective optimization, Artificial intelligence (AI), Forwarding algorithm, Social network parameters},
abstract = {Vehicular delay tolerant network (VDTN) technology uses vehicles on the road as moving nodes to deliver data from source to destination using several intermediate nodes. Efficient data dissemination in VDTN is a difficult problem due to existing trade-offs between several metric variables such as delivery ratio, delay, and overhead ratio. Inclusion of important social network parameters (like community, social strength, trust, friendship, and selfishness) in computation of forwarding probability may help to improve the performance of a routing algorithm. However, different tuning of these parameters results in different outcomes for the metric variables. A proper balancing of these parameters may result in an optimized outcome solving the trade-off between the metric variables. Nonetheless, dependency of the variables on a number of social network parameters and their mutual trade-offs makes this a non-trivial optimization problem. In this paper, we propose a novel approach to optimize these trade-offs using multi-objective particle swarm optimization (MOPSO). The proposed approach provides a set of pareto-optimal solutions also known as non-dominating solutions. Further, based on the requirements of a target application scenario, a specific optimal solution out of the pareto-optimal solution set is delivered using artificial intelligence (AI) technique. The proposed methodology is simulated in a VDTN scenario using the opportunistic network environment (ONE) simulator and Matlab. Furthermore, based on the experimental results, an exhaustive analysis is provided about how the metric variables are affected by the involvement of the social-based parameters. The capabilities of the proposed approach are validated using a statistical comparative analysis of the results. In future, the outcome of the study may play a helpful role to decide the priorities of the network parameters while designing new data dissemination algorithms for VDTN.}
}
@article{VESTENICKY2019579,
title = {Simple method of photovoltaic panel power characteristic measurement based on Arduino hardware platform},
journal = {Transportation Research Procedia},
volume = {40},
pages = {579-585},
year = {2019},
note = {TRANSCOM 2019 13th International Scientific Conference on Sustainable, Modern and Safe Transport},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2019.07.083},
url = {https://www.sciencedirect.com/science/article/pii/S2352146519302479},
author = {Martin Vestenicky and Slavomir Matuska and Robert Hudec},
keywords = {Arduino, photovoltaic panel, power characteristic, maximum power point},
abstract = {This paper deals with simple measurement method for low power photovoltaic panel power characteristic measurement. Proposed method is based on the characteroscope principle, which utilizes simple controlled current sink and measurement circuitry for current and voltage measurements ranging from no load to short circuit conditions on the photovoltaic cell. Emphasis was placed to design the simplest possible hardware based on Arduino platform. The maximum power point of measured panel is obtained by mathematical calculation which is carried out by the firmware of Arduino Central Processing Unit (CPU). Simulation of proposed hardware design and experimental results taken on prototype was shown.}
}
@article{YAMASHITA2020109523,
title = {A review of hierarchical control for building microgrids},
journal = {Renewable and Sustainable Energy Reviews},
volume = {118},
pages = {109523},
year = {2020},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2019.109523},
url = {https://www.sciencedirect.com/science/article/pii/S1364032119307312},
author = {Daniela Yassuda Yamashita and Ionel Vechiu and Jean-Paul Gaubert},
keywords = {Electricity market, Energy management system, Optimisation algorithms, Renewable energy source, Prosumer},
abstract = {Building microgrids have emerged as an advantageous alternative for tackling environmental issues while enhancing the electricity distribution system. However, uncertainties in power generation, electricity prices and power consumption, along with stringent requirements concerning power quality restrain the wider development of building microgrids. This is due to the complexity of designing a reliable and robust energy management system. Within this context, hierarchical control has proved suitable for handling different requirements simultaneously so that it can satisfactorily adapt to building environments. In this paper, a comprehensive literature review of the main hierarchical control algorithms for building microgrids is discussed and compared, emphasising their most important strengths and weaknesses. Accordingly, a detailed explanation of the primary, secondary and tertiary levels is presented, highlighting the role of each control layer in adapting building microgrids to current and future electrical grid structures. Finally, some insights for forthcoming building prosumers are outlined, identifying certain barriers when dealing with building microgrid communities.}
}
@article{DANGELO2020210,
title = {Decentralized learning for self-adaptive QoS-aware service assembly},
journal = {Future Generation Computer Systems},
volume = {108},
pages = {210-227},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.02.027},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19312439},
author = {Mirko D’Angelo and Mauro Caporuscio and Vincenzo Grassi and Raffaela Mirandola},
keywords = {Service assembly, Quality of service, Decentralized learning, Self-adaptive systems},
abstract = {The highly dynamic nature of future computing systems, where applications dynamically emerge as opportunistic aggregation of autonomous and independent resources available at any given time, requires a radical shift in the adopted computing paradigms. Indeed, they should fully reflect the decentralized perspective of the execution environment and consider QoS, scalability and resilience as key objectives. In this context, the everything-as-a-service (XaaS) paradigm, which envisions the creation of new services as an assembly of independent services available within the environment, can greatly help in tackling the challenges of developing future applications. However, in order to be effective, XaaS paradigm requires self-adaptive service assembly solutions able to cope with the unpredictable variability and scalability of the execution environment, the lack of global knowledge, and the QoS requirements of services to be built. We contribute in this direction by designing a fully decentralized and collective self-adaptive service assembly framework whose main features are: (i) self-assembly, i.e., the ability to operate autonomously, (ii) online-learning, i.e., the ability to dynamically learn from experience, (iii) QoS-awareness, i.e., the inclusion of QoS requirements as driving forces for self-assembly, (iv) scalability, i.e., the ability to cope with a large number of services, and (v) resilience, i.e., the ability to maintain the persistence of service delivery when facing unexpected changes (e.g., in the number and/or QoS of services). Simulation experiments show that our solution makes the system able to quickly converge to viable assemblies that improve and maintain over time the social welfare of the system, despite the local perspective of each participating service.}
}
@article{CANTUORTIZ2014781,
title = {Advancing artificial intelligence research and dissemination through conference series: Benchmark, scientific impact and the MICAI experience},
journal = {Expert Systems with Applications},
volume = {41},
number = {3},
pages = {781-785},
year = {2014},
note = {Methods and Applications of Artificial and Computational Intelligence},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2013.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0957417413006209},
author = {Francisco Javier Cantu-Ortiz},
keywords = {Artificial intelligence, AI research and development, Scientific impact of AI},
abstract = {This article presents an overview, analysis and benchmark of the best-known artificial intelligence (AI) conferences, including the Mexican International Conference on Artificial Intelligence (MICAI) conference series, and describes how MICAI has contributed to both the growth of artificial intelligence (AI) research in Mexico and the advancement of AI research worldwide. Among the prestigious AI conferences examined are the IJCAI, AAAI, ECAI, IBERAMIA, AAJCAI and PRICAI. Features analyzed include number of papers, acceptance rate and the h index as a measure of the scientific impact. The MICAI has been held in Mexico since 2000, when the National Meeting on AI, held by the Mexican Society for Artificial Intelligence (SMIA) since 1983, and the International Symposium on Artificial Intelligence (ISAI), organized by Tecnológico de Monterrey (ITESM) since 1988, merged into a single conference. Conference trends and future developments are also explained.}
}
@article{GAO2016109,
title = {Possibility and Challenge of Smart Community in Japan},
journal = {Procedia - Social and Behavioral Sciences},
volume = {216},
pages = {109-118},
year = {2016},
note = {Urban Planning and Architectural Design for Sustainable Development (UPADSD)},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815061959},
author = {Weijun Gao and Liyang Fan and Yoshiaki Ushifusa and Qunyin Gu and Jianxing Ren},
keywords = {Smart community, Greenhouse gas, Distributed energy resource, Kitakyushu},
abstract = {Under the Kyoto Protocol, Japan was supposed to reduce six percent of the Greenhouse Gas (GHG) emission. However, in the year 2012, the statistics suggested that the GHG emission increased 9% compared with the year 1990. Even with the leading energy saving technologies and a lot of experience on handling with environmental issues, Japan still could not meet the target set by Kyoto Protocol. The demonstration area of “smart community” suggests Japanese exploration for low carbon strategies. It is the shift toward the emphasis on the GHG emission control in civil sector. The Japanese version of smart communities also suggests the promotion on the use of renewable and untapped energy resource as well as the collaborative energy to be used in the district level. Much more important than the technology itself, the concept of smart community in Japan makes the community and the city as a whole, setting up a system of cooperation between the industry, government and residents. Taking the city of Kitakyushu as case study, this paper introduces the current development of smart community in Japan, focusing on analyzing its potential and challenges.}
}
@article{SHI2020291,
title = {A dual channel class hierarchy based recurrent language modeling},
journal = {Neurocomputing},
volume = {418},
pages = {291-299},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.07.112},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220313114},
author = {Libin Shi and Wenge Rong and Shijie Zhou and Nan Jiang and Zhang Xiong},
keywords = {Recurrent language modeling, Class hierarchy, Over-large vocabulary},
abstract = {In recurrent language models the usage of the class hierarchy of vocabulary is a major direction to overcome over-large vocabulary issue, yet the hierarchy is not aligned within the models, including the embedding, hidden and softmax layer. Currently most methods employ the hierarchical information in embedding and/or softmax layers. It is interesting to ask if incorporating such information into hidden layer will be beneficial to the overall language modeling performance. Therefore, in this research we propose a dual channel class hierarchy (DCCH) model that utilizes two channels of RNNs to form a class hierarchy within the model, where class-channel is used to capture class sequence’s information. Furthermore, we study two auxiliary techniques in class organization: word hierarchy initialization and class exchange, to boost the overall performance. Finally, experiments on the PTB, WikiText-103, Wiki-fr and OBW datasets evaluate the potential of proposed model and our observation.}
}
@article{STOCCHI20185,
title = {Fast wavelet transform assisted predictors of streaming time series},
journal = {Digital Signal Processing},
volume = {77},
pages = {5-12},
year = {2018},
note = {Digital Signal Processing & SoftwareX - Joint Special Issue on Reproducible Research in Signal Processing},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2017.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S1051200417302178},
author = {Marco Stocchi and Michele Marchesi},
keywords = {Streaming datasets, Time series forecast, Fast Wavelet Transform, Shift variance theorem},
abstract = {We explore the shift variance of the decimated, convolutional Discrete Wavelet Transform, also known as Fast Wavelet Transform. We prove a novel theorem improving the FWT algorithm and implement a new prediction method suitable to the multiresolution analysis of streaming univariate datasets using compactly supported Daubechies Wavelets. An effective real value forecast is obtained synthesizing the one step ahead crystal and performing its inverse DWT, using an integrated group of estimating machines. We call Wa.R.P. (Wavelet transform Reduced Predictor) the new prediction method. A case study, testing a cryptocurrency exchange price series, shows that the proposed system can outperform the benchmark methods in terms of forecasting accuracy achieved. This result is confirmed by further tests performed on other time series. Developed in C++, Standard 2014 conformant, the code implementing the FWT and the novel Shift Variance Theorem is available to research purposes and to build efficient industrial applications.}
}
@article{KOUICEM2018199,
title = {Internet of things security: A top-down survey},
journal = {Computer Networks},
volume = {141},
pages = {199-221},
year = {2018},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618301208},
author = {Djamel Eddine Kouicem and Abdelmadjid Bouabdallah and Hicham Lakhlef},
keywords = {Internet of Things, Security, Privacy, Cryptography, Blockchain, Software defined networking},
abstract = {Internet of Things (IoT) is one of the promising technologies that has attracted a lot of attention in both industrial and academic fields these years. It aims to integrate seamlessly both physical and digital worlds in one single ecosystem that makes up a new intelligent era of Internet. This technology offers a huge business value for organizations and provides opportunities for many existing applications such as energy, healthcare and other sectors. However, as new emergent technology, IoT suffers from several security issues which are most challenging than those from other fields regarding its complex environment and resources-constrained IoT devices. A lot of researches have been initiated in order to provide efficient security solutions in IoT, particularly to address resources constraints and scalability issues. Furthermore, some technologies related to networking and cryptocurrency fields such as Software Defined Networking (SDN) and Blockchain are revolutionizing the world of the Internet of Things thanks to their efficiency and scalability. In this paper, we provide a comprehensive top down survey of the most recent proposed security and privacy solutions in IoT. We discuss particularly the benefits that new approaches such as blockchain and Software Defined Networking can bring to the security and the privacy in IoT in terms of flexibility and scalability. Finally, we give a general classification of existing solutions and comparison based on important parameters.}
}
@article{MEHTA2020,
title = {A review for IOT authentication – Current research trends and open challenges},
journal = {Materials Today: Proceedings},
year = {2020},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2020.10.859},
url = {https://www.sciencedirect.com/science/article/pii/S2214785320384960},
author = {Mihir Mehta and Kajal Patel},
keywords = {IOT, Authentication, Authorization, Encryption, Spoofing attack, MITM attack},
abstract = {Internet of things is becoming the prime technology currently. By the utilization of IOT, different types of gadgets can interface, link and dialogue data without any interruption. IOT brings intelligence and automation in different areas like agriculture, transportation, industry, health and many more. The end point intention of the IOT operations is to extend opulence and productiveness of the stakeholders. IOT composition includes different sensors and other things which are associated with the web. As Web is open architecture, it lay out favourable ground to Intruders for performing different kinds of security threats. Security and Protection are the symbolic point of view for IOT system. IOT gadgets have limitation in terms of storage and also computational efficiency. So, existing traditional approaches can not be deployed directly into IOT Network. Confidentiality, Integrity and Authentication are pillars for IOT Security. Among them, Authentication service is prime nature because it validates identity of gadgets into the network. If Authentication approach is not secured enough than adversary can gain network control and also can launch various other kinds of attacks into the network. In this review article, a detailed analysis of the security related challenges specially related to Authentication and source of threats in IOT applications is discussed. A brief comparison of recent advancements in various domains of IOT Authentication security is also summarized with suggested enhancements. After doing critical review of existing algorithms; we have derived research gap which can provide opportunity for doing research work in IOT Authentication domain.}
}
@article{LI2020100608,
title = {Network analysis of big data research in tourism},
journal = {Tourism Management Perspectives},
volume = {33},
pages = {100608},
year = {2020},
issn = {2211-9736},
doi = {https://doi.org/10.1016/j.tmp.2019.100608},
url = {https://www.sciencedirect.com/science/article/pii/S2211973619301400},
author = {Xin Li and Rob Law},
keywords = {Big data, Tourism studies, Co-citation analysis, Network analysis, Research trends},
abstract = {This study aims to provide a comprehensive network analysis to understand the current state of big data research in tourism by investigating multi-disciplinary contributions relevant to big data. A comprehensive network analytical method, which includes co-citation, clustering and trend analysis, is applied to systematically analyse publications from 2008 to 2017. Two unique data sets from Web of Science are collected. The first data set focuses on big data research in tourism and hospitality. The second data set involves other disciplines, such as computer science, for a comparison with tourism. Results suggest that applications of social media and user-generated content are gaining momentum, whereas theory-based studies on big data in tourism remain limited. Tourism and other relevant domains have similar concerns with the challenges involved in big data, such as privacy, data quality and appropriate data use. This comparative network analysis has implications for future big data research in tourism.}
}
@article{MUHURI2019218,
title = {Industry 4.0: A bibliometric analysis and detailed overview},
journal = {Engineering Applications of Artificial Intelligence},
volume = {78},
pages = {218-235},
year = {2019},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2018.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0952197618302458},
author = {Pranab K. Muhuri and Amit K. Shukla and Ajith Abraham},
keywords = {Bibliometric study, Web of science, SCOPUS, Survey, Industry 4.0, Cyber–physical systems (CPS), Internet of Things (IoT)},
abstract = {With the arrival of Industry 4.0, the overall transformation using digital integration and intelligent engineering has taken a giant leap towards futuristic technology. All devices today are equipped with machine learning, automation has become a priority and thus another industrial revolution is in the making. In this state-of-the-art paper, we have performed bibliometric analysis and an extensive survey on recent developments in the field of “Industry 4.0”. In bibliometric analysis, different performance metrics are extracted, such as: total papers, total citations, and citation per paper. Further, top 10 of the most productive and highly cited authors, major subject areas, sources or journals, countries, and institutions are evaluated. A list of highly influential papers is also assessed. Later on, a detailed discussion of the most cited papers is analysed and a sectional classification is provided. This paper summarizes the growth structure of Industry 4.0 during the last 5 years and provides the concise background overview of Industry 4.0 related works and various application areas.}
}
@article{ARFAOUI2019106870,
title = {Game-based adaptive anomaly detection in wireless body area networks},
journal = {Computer Networks},
volume = {163},
pages = {106870},
year = {2019},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2019.106870},
url = {https://www.sciencedirect.com/science/article/pii/S1389128619300015},
author = {Amel Arfaoui and Ali Kribeche and Sidi Mohammed Senouci and Mohamed Hamdi},
keywords = {IoT, Health, WBAN, Game theory, Adaptive anomaly detection},
abstract = {Wireless Body Area Network (WBAN) is a quite suitable communication tool for medical IoT devices that are deployed to collect physiological parameters and forecast real-time events in order to facilitate the diagnostic decision-making for the medical staff. However, sensor readings may be inaccurate due to resource-constrained devices, sensor misplacement, hardware faults, and other environmental factors. Therefore, anomaly detection is envisioned as a promising approach to deal with unreliable and malicious data injection to improve remote patient monitoring systems and reduce false medical diagnosis. In this context, several data analysis and machine learning tools have been proposed to detect abnormal deviations in WBAN. Nevertheless, no one considers the dynamic context changes of WBAN to provide adaptive and dynamic outlier detection. In addition, most of them ignore the co-existence of strong spatial and temporal correlations between monitored physiological attributes. To this end, we propose a two-level lightweight and adaptive anomaly detection approach to discard false alarms caused by faulty measurements and raise alarms only when a patient seems to be in emergency situations. In the first level, a game-theoretic technique is introduced wherein body-worn sensor nodes exploit the spatiotemporal correlation among readings to locally and adaptively detect anomalous events according to the dynamic context changes of WBAN. In the second level, we apply the Mahalanobis distance in the Local Processing Unit (LPU) which has a global view for multivariate analysis. Our main objective is to ensure a tradeoff between detection accuracy, false positive rates, and network performance while considering the WBAN environment constraints. The proposed approach is evaluated through numerical simulations on a real physiological data set. Simulation results prove the effectiveness of the proposed approach in terms of achieving high detection accuracy with low false alarm rate and energy consumption.}
}
@article{MONTECINOS2018932,
title = {Forecasting multiple waste collecting sites for the agro-food industry},
journal = {Journal of Cleaner Production},
volume = {187},
pages = {932-939},
year = {2018},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2018.03.127},
url = {https://www.sciencedirect.com/science/article/pii/S0959652618307881},
author = {Julio Montecinos and Mustapha Ouhimmou and Satyaveer Chauhan and Marc Paquet},
keywords = {Waste management, Agro-food industry, Forecasting, Time series, Theil-Sen},
abstract = {The agro-food industry wastes tons of oil and grease not suitable for immediate consumption. Their collection mostly relies on the experience of managers and this results in inaccurate visits by truck drivers and operations teams. Indeed, the measurement of by-products waste is complex and thus information is imprecise, making the collecting operations inefficient. In this paper, we propose a model that forecasts the daily input of thousands of industrial and commercial sites of the agro-food industry based on historical data. The algorithm rejects errors and mistakes in the routing-collection-measuring process. In our model, the site container capacity is known and remains constant. The main contribution of this study is to propose a model based on the Theil-Sen constrained regression (Theil-Sen CR) that rejects errors and outliers to simplify the forecast of future collections. We apply this method to a real case study and compare its performance at different collecting sites. The forecasting error is significant compared to Linear Regression (LR). We have calculated, for our industrial partner, based on 12.2 km between sites and a fleet of 200 trucks, a potential reduction of 940 tCO2 equivalent per year.}
}
@article{LACINAK20191441,
title = {Implementation of Safe City Concept – Procedure of Choosing New Safety Measures},
journal = {Transportation Research Procedia},
volume = {40},
pages = {1441-1448},
year = {2019},
note = {TRANSCOM 2019 13th International Scientific Conference on Sustainable, Modern and Safe Transport},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2019.07.199},
url = {https://www.sciencedirect.com/science/article/pii/S2352146519303692},
author = {Maroš Lacinák},
keywords = {safe city, support of decision making, identifying suitable solutions},
abstract = {Over the studies of Smart and Safe City concepts number of solutions increasing the safety and security in cities were identified. However, as every city faces different problems in different circumstances, the same solution will not bring the same results everywhere. Individualistic planning of safety and security enhancements is needed. The aim of this paper is to help with decision-making processes - to identify, which safety and security solutions are the most fitting for the specific situation of the specific city. For this purpose, part of the methodological procedure of implementation of Safe City concept solutions is presented within this paper for discussion. In this paper, I decided to deal with the part of procedure that seems to be the least addressed of them – with decision support for choosing new safety measures for implementation. The whole methodological procedure is to be created within an interactive webpage guide.}
}
@article{ZHANG2019118198,
title = {Barriers to smart waste management for a circular economy in China},
journal = {Journal of Cleaner Production},
volume = {240},
pages = {118198},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.118198},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619330689},
author = {Abraham Zhang and V.G. Venkatesh and Yang Liu and Ming Wan and Ting Qu and Donald Huisingh},
keywords = {Smart enabling technologies, Internet of things, IoT, Smart waste management, Circular economy, Circular supply chain management},
abstract = {Waste management requires a new vision and drastic improvements for a transition to a zero-waste circular economy. In reality, however, many economies are producing more and more waste, which poses a serious challenge to environmental sustainability. The problem is enormously complex as it involves a variety of stakeholders, demands behavioral changes, and requires a complete rethinking of the current waste management systems and the dominant linear economic model. Smart enabling technologies can aid in a transformation of waste management toward a circular economy, but many barriers persist. This study first shortlists twelve important barriers to smart waste management in China based on interviews with experienced practitioners. It then prioritizes these barriers through a scientific prioritization technique, fuzzy Decision-Making Trial and Evaluation Laboratory (DEMATEL), based on the survey data from three representative stakeholders. It identified three key causal barriers: the lack of regulatory pressures, the lack of environmental education and culture of environmental protection, and the lack of market pressures and demands. Practical and theoretical implications were discussed based on the research results and findings.}
}
@article{ULISLAM2019106814,
title = {Leveraging utilization as performance metric for CDN enabled energy efficient internet of things},
journal = {Measurement},
volume = {147},
pages = {106814},
year = {2019},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2019.07.042},
url = {https://www.sciencedirect.com/science/article/pii/S0263224119306712},
author = {Saif {Ul Islam} and Hasan Ali Khattak and Jean-Marc Pierson and Ikram Ud Din and Ahmad Almogren and Mohsen Guizani and Mansour Zuair},
keywords = {Content Distribution Networks, CDN utility, CDN utilization, CDN Security, Confidentiality, Authentication},
abstract = {The exponential increase in the Internet of Things (IoT) has drastically augmented the need for computing and storage resources. IoT devices generate massive data that requires to be efficiently stored and disseminated for further processing and decision making. Given this, Content Distribution Networks (CDN) play a vital role to store and serve contents through geographically distributed surrogate servers in an IoT environment. Thanks to the explosive rise in IoT devices, CDN installations are also significantly increasing, hence, consuming a substantial amount of energy. The dynamic energy consumption of CDN resources is proportional to their utilization. Therefore, it is very crucial to design and develop utilization aware policies and strategies for sustainable content distribution. In the literature, different approaches have been proposed to improve the CDN performance by improving CDN utility in terms of security, authentication, and confidentiality, etc. Whereas, these works largely neglect the efficient utilization of CDN resources. In this perspective, this paper investigates the fact that CDN utility does not reflect the utilization of CDN resources. For this purpose, a comprehensive analysis is performed by comparing both metrics - CDN utility and CDN utilization, under various CDN scenarios. The results show that CDN utilization exhibits lower values even if the CDN utility is showing promising results. Hence, we recommend to consider utilization as a major metric to evaluate the performance of a CDN policy.}
}
@article{ZENG2022209,
title = {Relation construction for aspect-level sentiment classification},
journal = {Information Sciences},
volume = {586},
pages = {209-223},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.11.081},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521012032},
author = {Jiandian Zeng and Tianyi Liu and Weijia Jia and Jiantao Zhou},
keywords = {Aspect-level, Sentiment analysis, Aspect relations, Graph convolutional network},
abstract = {Aspect-level sentiment classification aims to obtain fine-grained sentiment polarities of different aspects in one sentence. Most existing approaches handle the classification by acquiring the importance of context words towards each given aspect individually, and ignore the benefits brought by aspect relations. Since the sentiment of one aspect can be deduced through their relationship according to other aspects, in this paper, we propose a novel relation construction multi-task learning network (RMN), which is the first attempt to extract aspect relations as an auxiliary classification task. RMN generates aspect representations through graph convolution networks with a semantic dependency graph and utilizes the bi-attention mechanism to capture the relevance between the aspect and the context. Unlike conventional multi-task learning methods that need extra datasets, we construct an auxiliary relation-level classification task that extracts aspect relations from the original dataset with shared parameters. Extensive experiments on five public datasets from SemEval 14, 15, 16 and MAMS show that our RMN improves about 0.09% to 0.8% on accuracy and about 0.04% to 1.19% on F1 score, compared to several comparative baselines.}
}
@article{NAMBIAR20202734,
title = {Modeling Access Control on Streaming Data in Apache Storm},
journal = {Procedia Computer Science},
volume = {171},
pages = {2734-2739},
year = {2020},
note = {Third International Conference on Computing and Network Communications (CoCoNet'19)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.04.297},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920312904},
author = {Seema Nambiar and Subramaniam Kalambur and Dinkar Sitaram},
keywords = {Access control, stream, Apache Storm},
abstract = {Streaming analytics on real-time data is very important in the IOT world since analytics, decisions and operations have to be done in real-time for practical applicability. In such scenarios, one key consideration is the security of the real-time stream. Stream security as in other network security can be modeled using the CIA (Confidentiality/Integrity/Availability) model [1]. However, most practical implementations just take care of the first two aspects viz Confidentiality and Integrity using standard techniques such as encryption and signatures. In this paper, we introduce an access control mechanism on the stream that annotates the stream with additional security metadata. This metadata can be used to allow/deny access to elements in the stream and also protect the privacy of the data. We demonstrate a work in progress implementation of the access control mechanism on the popular streaming engine Apache Storm [2] and demonstrate how access control can be modeled and implemented on streaming data.}
}
@article{SILVANO2020307,
title = {Iota Tangle: A cryptocurrency to communicate Internet-of-Things data},
journal = {Future Generation Computer Systems},
volume = {112},
pages = {307-319},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.05.047},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19329048},
author = {Wellington Fernandes Silvano and Roderval Marcelino},
keywords = {Iota Tangle, IoT, DLT, Iota, Distributed computing},
abstract = {The emergence of distributed ledger technologies (DLT) and design limitations of Blockchain systems for some types of applications led to the development of cryptocurrency alternatives for various purposes. Iota is a cryptocurrency with a new architecture called Tangle, which promises high scalability, no fees, and near-instant transfers, focused on the Internet-of-Things (IoT) solutions. This paper aims to present a systematic community’s visions of this new technology and to provide minimum background to understand the Iota Tangle and ecosystem generated by this distributed Ledger. The first parts of this article describe the ecosystem behind Iota, theoretical mathematical foundation, and its challenges and solutions for implementation. In the second part, we presented systematic research about Iota Tangle in academic databases: IEEE, ScienceDirect, Scopus, and Research Gate. We select the articles those of high impact which can be filtered with the H5-index indicator. This criterion aims to guarantee that the papers analyzed underwent a careful selection process, evaluated by peers. The methodology used helped have a global vision of Iota, including that this innovation is not only understood as a cryptocurrency but can be considered as a “distributed communication protocol”, absence of fees, low latency, and low computational cost for sending transactions. However, there exist several challenges in the vanguard of development of this ledger. It could also be identified that this technology enables many possibilities, however, it is fundamental to understand the potentials and limitations of this ecosystem to generate the best use cases.}
}
@article{CUI2020101403,
title = {Information Metamaterial Systems},
journal = {iScience},
volume = {23},
number = {8},
pages = {101403},
year = {2020},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2020.101403},
url = {https://www.sciencedirect.com/science/article/pii/S2589004220305939},
author = {Tie Jun Cui and Lianlin Li and Shuo Liu and Qian Ma and Lei Zhang and Xiang Wan and Wei Xiang Jiang and Qiang Cheng},
keywords = {Electromagnetic Waves, Information Systems, Metamaterials},
abstract = {Summary
Metamaterials have great capabilities and flexibilities in controlling electromagnetic (EM) waves because their subwavelength meta-atoms can be designed and tailored in desired ways. However, once the structure-only metamaterials (i.e., passive metamaterials) are fabricated, their functions will be fixed. To control the EM waves dynamically, active devices are integrated into the meta-atoms, yielding active metamaterials. Traditionally, the active metamaterials include tunable metamaterials and reconfigurable metamaterials, which have either small-range tunability or a few numbers of reconfigurability. Recently, a special kind of active metamaterials, digital coding and programmable metamaterials, have been presented, which can realize a large number of distinct functionalities and switch them in real time with the aid of field programmable gate array (FPGA). More importantly, the digital coding representations of metamaterials make it possible to bridge the digital world and physical world using the metamaterial platform and make the metamaterials process digital information directly, resulting in information metamaterials. In this review article, we firstly introduce the evolution of metamaterials and then present the concepts and basic principles of digital coding metamaterials and information metamaterials. With more details, we discuss a series of information metamaterial systems, including the programmable metamaterial systems, software metamaterial systems, intelligent metamaterial systems, and space-time-coding metamaterial systems. Finally, we introduce the current progress and predict the future trends of information metamaterials.}
}
@article{ROBINSON2020101421,
title = {Trust, transparency, and openness: How inclusion of cultural values shapes Nordic national public policy strategies for artificial intelligence (AI)},
journal = {Technology in Society},
volume = {63},
pages = {101421},
year = {2020},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2020.101421},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X20303766},
author = {Stephen Cory Robinson},
keywords = {Digital trust, Openness, Transparency, Artificial Intelligence policy, Technology policy, Cultural values},
abstract = {Using textual analysis methodology with Hofstede's cultural dimensions as basis for cross-national comparison, the manuscript explores the influence of cultural values of trust, transparency, and openness in Nordic national artificial intelligence (AI) policy documents. Where many AI processes are technologies hidden from view of the citizen, how can public institutions support and ensure these high levels of trust, transparency, and openness in Nordic culture and extend these concepts of “digital trust” to AI? One solution is by authoring national policy that upholds cultural values and personal rights, ultimately reinforcing these values in their societies. The paper highlights differences in how Nordic nations position themselves using cultural values as organizing principles, with the author showing these values (i.e., trust through clear information and information security, transparency through AI literacy education and clear algorithmic decision making, and openness by creating data lakes and data trusts) support the development of AI technology in society. The analysis shows that three cultural values are upheld and influence Nordic national AI strategies, while themes of privacy, ethics, and autonomy are present, and democracy, a societal building block in the Nordics, is especially prominent in the policies. For policy development, policy leaders must understand that without citizen involvement in AI implementation or lacking citizen AI education, we risk alienating those for who these services are meant to utilize and improve access for.}
}
@article{BRUNESE20191795,
title = {Radiomic Features for Medical Images Tamper Detection by Equivalence Checking},
journal = {Procedia Computer Science},
volume = {159},
pages = {1795-1802},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.351},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919315522},
author = {Luca Brunese and Francesco Mercaldo and Alfonso Reginelli and Antonella Santone},
keywords = {Formal Methods, Equivalence Checking, Radiomic},
abstract = {Digital medical images are very easy to be modified for illegal purposes. An attacker may perform this act in order to stop a political candidate, sabotage research, commit insurance fraud, perform an act of terrorism, or even commit murder. Between the machine that performs medical scans and the radiologist monitor, medical images pass through different devices: in this chain an attacker can perform its malicious action. In this paper we propose a method aimed to avoid medical images modifications by means of equivalence checking. Magnetic images are represented as finite state automata and equivalence checking is exploited to check whether the medical resource have been subject to illegal modifications.}
}
@article{ELMOULAT2020480,
title = {Edge Computing and Artificial Intelligence for Landslides Monitoring},
journal = {Procedia Computer Science},
volume = {177},
pages = {480-487},
year = {2020},
note = {The 11th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2020) / The 10th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH 2020) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.10.066},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920323358},
author = {Meryem Elmoulat and Olivier Debauche and Saïd Mahmoudi and Sidi Ahmed Mahmoudi and Pierre Manneback and Frédéric Lebeau},
keywords = {Landslides susceptibility, Internet of Things, Artificial Intelligence, early warning system, landslides monitoring},
abstract = {Landslides are phenomena widely present around the world and responsible each year of numerous life loss and extensive property damage. Researchers have developed various methodologies to identify area of high susceptibility of landslides. However, these methodologies cannot predict ‘when’ landslides are going to take place. Indeed, Wireless Sensors Network (WSN), Internet of Things (IoT) and Artificial Intelligence (AI) offer the possibility to monitor in real-time parameters causing the triggering factors of rapid landslides. In this paper, we suggest a real-time monitoring of landslides in order to precociously alert population in dangerous situation by means of a warning system. The novelty of this paper is the coupling of wireless sensors network and a multi-agent system deployed on an edge AI-IoT architecture by means of Kubernetes and Docker.}
}
@article{SEYOUM2017452,
title = {A Shazam-like Household Water Leakage Detection Method},
journal = {Procedia Engineering},
volume = {186},
pages = {452-459},
year = {2017},
note = {XVIII International Conference on Water Distribution Systems, WDSA2016},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.03.253},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817314066},
author = {Solomon Seyoum and Leonardo Alfonso and Schalk Jan van Andel and Wouter Koole and Ad Groenewegen and Nick {van de Giesen}},
keywords = {Leak detection, sound signals, sensor},
abstract = {Waternomics is a European Union-funded research project aspiring to develop and introduce Information and Communication Technology (ICT) as an enabling technology to manage water as a resource, increase end-user conservation awareness, affect behavioural changes and avoid water losses through leak detection. Existing leakage detection methods are generally focused on scrutinising large diameter pipes in water supply distribution networks or transmission pipes. However, it has been estimated that the average household's leaks can be as much as 35m3 of water per year. In order to solve the problem, analysis of different types of data in the household piping system is required, including detection and identification. One conventional approach is to use flow sensors installed at several locations within the household piping system and perform a mass balance approach to detect leakage. However, this method is expensive and difficult to implement. This research proposes a novel approach to household leakage detection by means of sound signal recordings. The approach consists of recording the sound signals that are produced by water fixtures and appliances, and then use these recordings to detect any abnormal situation which may be an indication of a leak. The method comprises three major steps: recording, storing and processing of sound signals. The recording step is done by means of a non-intrusive sound sensor that sends records remotely; the storage step is made in a database of sound signals for different types of uses; finally, the processing step is made through a sound signal identification software tool that is able to search the database libraries for related sounds, in a similar way as the Shazam app for music. Tests of the leak detection method are presented for data collected in laboratory conditions. Results show that this detection method has a potential to help reducing leakages through an easy-to-install and non-intrusive sensor.}
}
@article{HUANG202280,
title = {Hybrid market-based resources allocation in Mobile Edge Computing systems under stochastic information},
journal = {Future Generation Computer Systems},
volume = {127},
pages = {80-91},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.08.029},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X2100337X},
author = {Xiaowen Huang and Shimin Gong and Jingmin Yang and Wenjie Zhang and Liwei Yang and Chai Kiat Yeo},
keywords = {Resources allocation, Mobile Edge Computing, Futures market, Spot market, Stochastic information},
abstract = {In order to deal with the problem of user diversity in Mobile Edge Computing (MEC) resource trading market, in this paper, we propose a hybrid market-based resource transaction mechanism consisting of futures market and spot market. Two different types of users have been taken into consideration. One is registered users and another is unregistered users. In futures market, registered users pay a registration fee to the agent and use the reserved resources according to the contract signed exclusively. We design optimal contracts for the registered users by adjusting the registration fee in order to maximize the servers’ utility. In spot market, unregistered users compete with one another to purchase the resources on demand. We model the trading process as a multi-seller and multi-buyer market, and propose auction algorithms to match the asking price from servers and the bidding price from unregistered users by assigning computation resources to the users. The agent acts as the auctioneer to host the auction, and the unregistered users bid on computation resources based on the estimated valuation. We study the optimal solution under both complete and incomplete information scenarios, depending on whether the agent can observe the users’ private information. Simulation results demonstrate the existences of the asking price and registration fee for the servers to maximize utility.}
}
@article{LIU2020123,
title = {A novel data augmentation scheme for pedestrian detection with attribute preserving GAN},
journal = {Neurocomputing},
volume = {401},
pages = {123-132},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.02.094},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220302903},
author = {Songyan Liu and Haiyun Guo and Jian-Guo Hu and Xu Zhao and Chaoyang Zhao and Tong Wang and Yousong Zhu and Jinqiao Wang and Ming Tang},
keywords = {Generative Adversarial Networks, Pedestrian detection, Data augmentation},
abstract = {Recently pedestrian detection has progressed significantly. However, detecting pedestrians of small scale or in heavy occlusions is still notoriously difficult. Besides, the generalization ability of pre-trained detectors across different datasets remains to be improved. Both of these issues can be attributed to insufficient training data coverage. To cope with this, we present an efficient data augmentation scheme by transferring pedestrians from other datasets into the target scene with a novel Attribute Preserving Generative Adversarial Networks (APGAN). The proposed methodology consists of two steps: pedestrian embedding and style transfer. The former step can simulate pedestrian images of various scale and occlusion, in any pose or background, thus greatly promoting the data variation. The latter step aims to make the generated samples more realistic while guarantee the data coverage. To achieve this goal, we propose APGAN, which pursues both good visual quality and attribute preserving after style transfer. With the proposed method, we can make effective sample augmentations to improve the generalization ability of the trained detectors and enhance its robustness to scale change and occlusions. Extensive experiment results validate the effectiveness and advantages of our method.}
}
@article{KUMAR2021101390,
title = {Blockchain for securing aerial communications: Potentials, solutions, and research directions},
journal = {Physical Communication},
volume = {47},
pages = {101390},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101390},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721001270},
author = {R. Lakshmana Kumar and Quoc-Viet Pham and Firoz Khan and Md. Jalil Piran and Kapal Dev},
keywords = {Unmanned Aerial Vehicles (UAVs), Aerial communication, Blockchain, Cryptography, Public-key encryption, Security management},
abstract = {Most natural disasters are consequences of hurricanes, floods, volcano eruptions, and earthquakes, and can severely disturb traditional communications networks and interrupt infrastructure of physical interconnection. After a disaster, communication failures are one of the essential causes of sufferers. To deal with this problem, offering “connectivity from the sky” is a novel and creative development. Aerial communications have been examined through the assessment and the design of the stratospheric platform capable of providing numerous types of wireless services. Drones, low and high-altitude platforms, airships, aircraft, and unmanned aerial vehicles (UAVs) are regarded as applicants for organizing aerial communications supplementing the infrastructure of global interaction. Aerial communication devices are vulnerable to being physically hijacked, destroyed, or lost. Therefore, security is a crucial issue in aerial communication networks. The blockchain technology is a potential solution candidate to tackle this issue. Blockchain is a decentralized and disseminated ledger, guards the distributed information using methods of cryptography, for example, public-key encryption and hash functions. It can use for guaranteeing the reliability of the data stored and for enhancing the transparency and security of aerial communication networks. This paper presents a survey on the integration of Blockchain with Aerial Communications (BAC). First, we study aerial communication networks and their current security issues, blockchain and its advantages, the feasibility and opportunity of applying the blockchain to resolve the current security issue in aerial communication networks. Next, we discuss current related solutions for applying the blockchain to resolve the current security issue in aerial communication networks in detail. We classify the solutions, compare and analyze their advantages and disadvantages. Finally, we recommend some research directions for future investigations.}
}
@article{JAYACHANDRAN2022101329,
title = {Operational concerns and solutions in smart electricity distribution systems},
journal = {Utilities Policy},
volume = {74},
pages = {101329},
year = {2022},
issn = {0957-1787},
doi = {https://doi.org/10.1016/j.jup.2021.101329},
url = {https://www.sciencedirect.com/science/article/pii/S0957178721001624},
author = {M. Jayachandran and K. Prasada Rao and Ranjith Kumar Gatla and C. Kalaivani and C. Kalaiarasy and C. Logasabarirajan},
keywords = {Smart grids, Blockchain technology, Distributed energy storage system, Energy trading, Cyber-physical security, Wide-area monitoring, Protection and control},
abstract = {Interfacing high penetration of Renewable Energy Sources (RES) with energy storage and microgrid control systems is an essential feature of future distribution grids for optimal utilization and management of Distributed Energy Resources (DERs). This feature allows distributed system operators to follow the right path to transform their traditional grids into smart grids. With the continued expansion of DERs, the current distribution grid is moving toward a carbon-free electricity system and greener energy-transportation applications. However, there are some practical concerns as well as technical and operational challenges in an interconnected power network. Therefore, this paper reviews the most prominent issues associated with smart grid, such as large-scale distributed generation integration, energy storage, energy trading, operational planning, service reliability, and cyber resiliency, in light of recent technological advancements. Through reviewing several emerging technologies, this study shows the necessary methodologies for establishing smart energy distribution. Finally, this study highlights future research prospects for a fully functional smart grid system.}
}
@article{VEHLKEN2020725,
title = {Traffic life: temporal dynamics and regulatory dimensions in agent-based transport simulations},
journal = {Mobilities},
volume = {15},
number = {5},
pages = {725-739},
year = {2020},
issn = {1745-0101},
doi = {https://doi.org/10.1080/17450101.2020.1806509},
url = {https://www.sciencedirect.com/science/article/pii/S1745010122002958},
author = {Sebastian Vehlken},
keywords = {Agent-based computer simulation, ABM, cellular automata, TRANSIMS, traffic simulation, theory guidance, methodological individualism, smartness},
abstract = {ABSTRACT
The article discusses the interplay of normative and temporal dynamics in agent-based traffic simulations (ABM). From a media-historical perspective, it focuses on the  TRANSIMS simulation system as a seminal example for an ABM ‘mindset’ in transportation and infrastructure simulation. ABM explicitly links traffic simulation with the broader focus of mobility studies by connecting the mere physicality of transport dynamics with a sociality of agents claiming to be descriptive of real-life structures. First, TRANSIMS elevates the examination of traffic dynamics to a meta-level of urban infrastructure design where individual timing and purposeful agent behaviors are placed at the heart of traffic systems. Second, TRANSIMS provides a ‘virtual testbed’ by generating traffic scenarios which eventually lead to situations that meet certain normative limits or regulatory guidelines. And third, ABM often display a strong tendency towards a methodological individualism which requires a ‘theory guidance’ by disciplines like sociology, media theory, or political science to challenge the oftentimes oversimplifying parameters of their ‘artificial sociality’. Consequently, with regard to the scope of mobility studies, ABM can be understood as a medium which negotiates conceptual and interdisciplinary differences and thereby transcends the solely pragmatist notion of ‘virtual testbeds’ as unmitigated optimization tools.}
}
@article{WANG2019541,
title = {Improved Kalman filter based differentially private streaming data release in cognitive computing},
journal = {Future Generation Computer Systems},
volume = {98},
pages = {541-549},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.03.050},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18330838},
author = {Jun Wang and Jing Luo and Xiaozhu Liu and Yongkai Li and Shubo Liu and Rongbo Zhu and Ashiq Anjum},
keywords = {Cognitive computing, Improved Kalman filter, Differential privacy, Streaming data},
abstract = {Cognitive computing works well based on volumes of data, which offers the guarantee of unlocking novel insights and data-driven decisions. Steaming data is a major component of aggregated data, and sharing these real-time aggregated statistics has gained a lot of benefits in decision analysis, such as traffic heat map and disease outbreaks. However, original streaming data sharing will bring users the risk of privacy disclosure. In this paper, differential privacy technology is introduced into cognitive system, and an improved Kalman filter based differentially private streaming data release scheme is proposed for privacy requirement of cognitive computing system. The feasibility of the proposed scheme has been demonstrated through analysis of the utility of sanitized data from four real datasets, and the experimental results show that the proposed scheme outperforms the Kalman filter-based method at the same level of privacy preserving.}
}
@article{YOUSEFPOUR2019289,
title = {All one needs to know about fog computing and related edge computing paradigms: A complete survey},
journal = {Journal of Systems Architecture},
volume = {98},
pages = {289-330},
year = {2019},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2019.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S1383762118306349},
author = {Ashkan Yousefpour and Caleb Fung and Tam Nguyen and Krishna Kadiyala and Fatemeh Jalali and Amirreza Niakanlahiji and Jian Kong and Jason P. Jue},
keywords = {Fog computing, Edge computing, Cloud computing, Internet of things (IoT), Cloudlet, Mobile edge computing, Multi-access edge computing, Mist computing},
abstract = {With the Internet of Things (IoT) becoming part of our daily life and our environment, we expect rapid growth in the number of connected devices. IoT is expected to connect billions of devices and humans to bring promising advantages for us. With this growth, fog computing, along with its related edge computing paradigms, such as multi-access edge computing (MEC) and cloudlet, are seen as promising solutions for handling the large volume of security-critical and time-sensitive data that is being produced by the IoT. In this paper, we first provide a tutorial on fog computing and its related computing paradigms, including their similarities and differences. Next, we provide a taxonomy of research topics in fog computing, and through a comprehensive survey, we summarize and categorize the efforts on fog computing and its related computing paradigms. Finally, we provide challenges and future directions for research in fog computing.}
}
@article{XUE2021101245,
title = {Semantic enrichment of building and city information models: A ten-year review},
journal = {Advanced Engineering Informatics},
volume = {47},
pages = {101245},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2020.101245},
url = {https://www.sciencedirect.com/science/article/pii/S1474034620302147},
author = {Fan Xue and Liupengfei Wu and Weisheng Lu},
keywords = {Building Information Model, City Information Model, Geographic Information System, Semantic enrichment, Smart city, Intelligent building},
abstract = {Building Information Models (BIMs) and City Information Models (CIMs) have flourished in building and urban studies independently over the past decade. Semantic enrichment is an indispensable process that adds new semantics such as geometric, non-geometric, and topological information into existing BIMs or CIMs to enable multidisciplinary applications in fields such as construction management, geoinformatics, and urban planning. These two paths are now coming to a juncture for integration and juxtaposition. However, a critical review of the semantic enrichment of BIM and CIM is missing in the literature. This research aims to probe into semantic enrichment by comparing its similarities and differences between BIM and CIM over a ten-year time span. The research methods include establishing a uniform conceptual model, and sourcing and analyzing 44 pertinent cases in the literature. The findings plot the terminologies, methods, scopes, and trends for the semantic enrichment approaches in the two domains. With the increasing availability of data sources, algorithms, and computing power, they cross the border to enter each other’s domain. Future research will likely gain new momentums from the demands of value-added applications, development of remote sensing devices, intelligent data processing algorithms, interoperability between BIM and CIM software platforms, and emerging technologies such as big data analytics.}
}
@article{HE2019792,
title = {Optimal privacy control for transport network data sharing},
journal = {Transportation Research Procedia},
volume = {38},
pages = {792-811},
year = {2019},
note = {Journal of Transportation and Traffic Theory},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2019.05.041},
url = {https://www.sciencedirect.com/science/article/pii/S235214651930050X},
author = {Brian Yueshuai He and Joseph Y.J. Chow},
keywords = {privacy, k-anonymity, open data, tour generation, entropy maximization},
abstract = {In the era of smart cities, Internet of Things, and Mobility-as-a-Service, the need for private operators to willingly share data with public agencies is greater than ever before. However, it is still problematic for private operators to share data with the public due to risks to competitive advantages. A privacy control algorithm is proposed to overcome this key obstacle for private operators sharing complex network-oriented data objects. The algorithm is based on information-theoretic k-anonymity where an operator’s tour data is used in conjunction with performance measure accuracy controls to synthesize a set of alternative tours with diffused probabilities for sampling during a query. The algorithm is proven to converge sublinearly toward constrained maximum entropy under certain asymptotic conditions with measurable optimality gap. Computational experiments verify the applicability to multi-vehicle fleet tour data; confirm that reverse engineered parameters from the diffused data results in controllable sampling error; and tests conducted on a set of realistic routing records from travel data in Long Island, NY, demonstrate the use of the methodology from both the adversary and user perspectives.}
}
@article{DIN2020106731,
title = {Smart embedded system based on demosaicking for enhancement of surveillance systems},
journal = {Computers & Electrical Engineering},
volume = {86},
pages = {106731},
year = {2020},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2020.106731},
url = {https://www.sciencedirect.com/science/article/pii/S0045790620305863},
author = {Sadia Din and Anand Paul and Awais Ahmad},
keywords = {Smart cities, Low power energy, Demosaicking, Cnn, Noise, Surveillance},
abstract = {Demosaicking and denoising are essential elements in digital photography pipelines. The use of convolutional neural networks (CNN)-based image demosaicking and denoising methods has been very successful. However, still there is a room for improvement in the network performance in terms of efficiency and accuracy. The main challenge that remains to be addressed is to guarantee the visual quality of reconstructed images, particularly in the presence of noise. To address these challenges, this paper introduces a novel demosaicking and denoising conjunct strategy using deep adaptive residual learning. The proposed framework has three stages. Initially, zero padding is performed to increase processing speed and preserve the edges of the image. In the second phase, we perform demosaicking using interpolation in order to find missing values using information about neighboring pixels. Finally, the reconstructed image is created using the original image. To evaluate the feasibility of the proposed scheme, we used Pytorch and Google Colab with 400 images for training and 100 images for validation The outcomes show that the proposed scheme beats cutting edge joint demosaicking and denoising schemes regarding both structural similarity index metrics (SSIM) and peak signal-to-noise ratio (PSNR) and basic similitude record measurements (SSIM).}
}
@article{EINI2021102222,
title = {Smart building management system: Performance specifications and design requirements},
journal = {Journal of Building Engineering},
volume = {39},
pages = {102222},
year = {2021},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2021.102222},
url = {https://www.sciencedirect.com/science/article/pii/S2352710221000784},
author = {Roja Eini and Lauren Linkous and Nasibeh Zohrabi and Sherif Abdelwahed},
keywords = {Smart building management system, Occupant comfort, Building operational costs, Machine learning, Model-based control},
abstract = {In a smart building, physical and computational elements are integrated to create an environment that is energy-efficient, comfortable, and safe for its occupants. The design and development of smart buildings is a complicated task. Every smart building is a unique structure from the requirements and characteristics standpoints. Therefore, achieving reliability and real-time adaptation to environmental conditions are some of the challenges involved in smart building development. Resolving these issues requires deep insights into control theory, machine learning, system specifications, and design requirements. To address this need, this paper proposes a real-time management system for controlling various aspects of smart buildings (indoor conditions, comfort criteria, security, safety, and costs), and also presents the performance specifications, design requirements, and operating constraints for these systems. The study aims to address two less-attended problems in the related literature of building management and control. First, only a few studies have attempted to include real-time learning of buildings' subjective parameters in the model-based control design. Second, to the best of the authors' knowledge, smart building management studies are primarily focused on optimizing thermal or visual aspects of buildings, and little attention is given to the simultaneous management of all building subsystems and objectives; i.e., considering buildings' physical models, environmental conditions, comfort specifications, and occupants’ preferences and safety in the design. Accordingly, in this paper, we combine machine learning with model-based control approaches to incorporate subjective environmental parameters into the building management structure. In addition, another benefit of this study is that it integrates model-based and learning-based control schemes in a unified management structure for controlling various aspects of building performance. The proposed building management system can be applied to a variety of smart buildings in which the building parameters can be monitored and self-tuned using a well-defined set of control inputs.}
}
@article{ZHANG2021102253,
title = {A survey on data center cooling systems: Technology, power consumption modeling and control strategy optimization},
journal = {Journal of Systems Architecture},
volume = {119},
pages = {102253},
year = {2021},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2021.102253},
url = {https://www.sciencedirect.com/science/article/pii/S1383762121001739},
author = {Qingxia Zhang and Zihao Meng and Xianwen Hong and Yuhao Zhan and Jia Liu and Jiabao Dong and Tian Bai and Junyu Niu and M. Jamal Deen},
keywords = {CPSS, Cooling system, Data center, Power consumption management, Optimization strategy},
abstract = {Data center is a fundamental infrastructure of computers and networking equipment to collect, store, process, and distribute huge amounts of data for a variety of applications such as Cyber–Physical–Social Systems, business enterprises and social networking. As the demands of remote data services keep increasing, both the workload of the data center and its power consumption are rapidly rising. An indispensable part of a data center is the cooling system which provides a suitable operation environment, and accounts for around 30% of the power consumption of the data center. Therefore, optimized energy management of data center’s cooling system is a highly profitable research area. Generally, a cooling system is made up of a mechanical refrigeration sub-system and a terminal cooling sub-system. Heat generated during operation of the data center will be absorbed by the latter one, and transferred into the outdoor environment via the former one. Depending on the cooling principle, current cooling solutions can be classified into air-cooling, liquid-cooling or free cooling technology. Although air-cooling is widely used in most existing data centers, the other two solutions have attracted more interests due to their excellent cooling effectiveness and higher energy efficiencies. Among the different cooling equipment, the chillers and fans are the major power consumers of the entire cooling system. Therefore, modeling of their power consumption is important for energy management of the cooling system, which can be classified into mechanism-based methods and data-driven methods. Based on the aforementioned models, optimization strategies for the operation management of cooling equipment are proposed to reduce the power consumption of the cooling system, which mainly includes the model predictive control-based methods and reinforcement learning-based methods. This paper is an overview of the data center’s cooling system, which mainly includes the mainstream cooling solutions, the power consumption modeling methods and the optimization control strategies. In addition, several current challenges and future work in the data center’s cooling system are described.}
}
@article{ALOQAILY2020254,
title = {A multi-stage resource-constrained spectrum access mechanism for cognitive radio IoT networks: Time-spectrum block utilization},
journal = {Future Generation Computer Systems},
volume = {110},
pages = {254-266},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19324860},
author = {Moayad Aloqaily and Haythem {Bany Salameh} and Ismaeel {Al Ridhawi} and Khalaf Batieha and Jalel Ben Othman},
keywords = {Frequency–time blocks, Resource-constrained, IoT, Cognitive radio networks, SDNs},
abstract = {Extravagant demands for wireless communications have resulted in the shortage of spectrum, such that unlicensed spectrum bands are overcrowded, whereas licensed bands are not utilized efficiently. Moreover, content discovery and retrieval using the traditional host-centric approach of IP-based networks adds more burden on the wireless spectrum, such that, each time a request is initiated by the mobile service requester, a new routing path is discovered to retrieve the service from the service provider. Cognitive radio (CR) technology has been proposed to enable efficient and opportunistic spectrum band usage through the utilization of vacant licensed channels. This can offer huge spectrum to enable efficient large-scale deployment for IoT networks. Moreover, Information Centric Networking (ICN) has been proposed to decouple the service requester from the provider such that in-network content caching is used to allow for the retrieval of services within a mobile node’s proximity. The integration of CR and ICN will be essential for enabling envisioned IoT services within smart cities. In this article, we consider the multi-user single-transceiver coordinated spectrum access problem in CR-IoT networks under the overlay spectrum sharing model. We formulate the spectrum access problem as a multi-stage rate/channel assignment optimization problem. The objective is to maximize the overall network throughput by maximizing the achieved sum-rate over all contending CR-IoT devices. Specifically, we propose a novel resource-constrained channel assignment policy that provides a proper utilization of the available time–frequency units. The proposed policy also exploits the packet fragmentation capability to further enhance network throughput. Moreover, we envision a scenario where our proposed solution can be adapted to information-centric cognitive radio-based networking for IoT smart city applications. We showcase the significant improvement achieved by our proposed solution over state-of-the-art schemes through simulation results.}
}
@article{MISHRA2022108346,
title = {Deep Architectures for Image Compression: A Critical Review},
journal = {Signal Processing},
volume = {191},
pages = {108346},
year = {2022},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2021.108346},
url = {https://www.sciencedirect.com/science/article/pii/S0165168421003832},
author = {Dipti Mishra and Satish Kumar Singh and Rajat Kumar Singh},
keywords = {Image compression, Deep learning, DNN, Review, CNN, Survey},
abstract = {Deep learning architectures are now pervasive and filled almost all applications under image processing, computer vision, and biometrics. The attractive property of feature extraction of CNN has solved a lot of conventional image processing problems with much-improved performance & efficiency. The paper aimed to review over a hundred recent state-of-the-art techniques exploiting mostly lossy image compression using deep learning architectures. These deep learning algorithms consists of various architectures like CNN, RNN, GAN, autoencoders and variational autoencoders. We have classified all the algorithms under certain categories for the better and deep understanding. The review is written keeping in mind the contributions of researchers & the challenges faced by them. Various findings for the researchers along with some future directions for a new researcher have been significantly highlighted. Most of the papers reviewed in the compression domain are from the last four years using different methodologies. The review has been summarized by dropping a new outlook for researchers in the realm of image compression.}
}
@article{ASHFAQ2022101660,
title = {A review of enabling technologies for Internet of Medical Things (IoMT) Ecosystem},
journal = {Ain Shams Engineering Journal},
volume = {13},
number = {4},
pages = {101660},
year = {2022},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2021.101660},
url = {https://www.sciencedirect.com/science/article/pii/S209044792100438X},
author = {Zarlish Ashfaq and Abdur Rafay and Rafia Mumtaz and Syed Mohammad {Hassan Zaidi} and Hadia Saleem and Syed Ali {Raza Zaidi} and Sadaf Mumtaz and Ayesha Haque},
keywords = {IoT, Embedded Devices, Body Area Networks, Remote Monitoring, eHealth and mHealth, Real-Time Systems},
abstract = {The goal of Internet of Medical Things (IoMT) and digital healthcare systems is to provide people with the ease of receiving quality healthcare at the comfort of their homes. Hence, the aim of IoMT is the ubiquitous deployment of home-based healthcare systems. Making such systems intelligent and efficient for timely prediction of critical diseases can save millions of lives while simultaneously reducing the burden on the traditional healthcare systems e.g., hospitals. The advancement in IoT has enabled both patients and doctors to access real time data. This advancement has reduced the cost and energy consumption of digital healthcare systems by using efficient sensors and communication technologies. This paper provides a comprehensive review of various studies conducted for the development and improvement of IoMT. It analyses different sensors used for measurement of various parameters ranging from physiological to emotional signals. It also provides a detailed investigation of different communication technologies being used, their advantages, and limitations. Moreover, digital healthcare systems are now deploying machine learning technology for the prediction of health status of patients. These techniques and algorithms are also discussed. Data security and prediction accuracy are the main concerns in the development of this area. In conclusion, this paper reviews the various digital system designs in the context of healthcare, their methodology, limitations, and the present challenges faced by the e-health sector.}
}
@article{TRIPATHI2021108183,
title = {Self-supervised learning for Environmental Sound Classification},
journal = {Applied Acoustics},
volume = {182},
pages = {108183},
year = {2021},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2021.108183},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X21002772},
author = {Achyut Mani Tripathi and Aakansha Mishra},
keywords = {Environmental Sound Classification, Data Augmentation, Residual Network, Self-Supervised Learning, Sound, Transfer Learning},
abstract = {Environmental Sound Classification (ESC) is one of the most challenging tasks in signal processing, digital forensic and machine learning. Numerous methods have been proposed to perform ESC. The conventional models’ training depends on an enormous amount of annotated data, specifically while training the deep models. This paper presents a self-supervised learning (SSL)-based deep classifier for ESC, which is an under-explored method in the field of ESC. SSL mechanism directs the model to effectively learn prototypical features from the data itself by solving a pretext task. The model proposed in this paper takes spectrogram images as input. A pretext or an auxiliary task is defined as identification of the type of data augmentation applied to the signal. The model learned by solving the pretext task is further fine-tuned for developing the deep model for ESC. The model’s performance is evaluated on two benchmark sound classification datasets, i.e. ESC-10 and DCASE 2019 Task-1(A) datasets. The experiments and results show that the SSL model attains an improvement of 12.59% and 11.17% in accuracy compared to the baseline models of the DCASE 2019 Task-1(A) and ESC-10 datasets respectively. Moreover, the model also shows competitive performance to state-of-the-art methods.}
}
@article{LI2022103597,
title = {Spatiotemporal patterns and mechanisms of street vending from the social sensing perspective: A comparison between law-enforcement reported and residents complain events},
journal = {Cities},
volume = {124},
pages = {103597},
year = {2022},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2022.103597},
url = {https://www.sciencedirect.com/science/article/pii/S0264275122000361},
author = {Chunjiang Li and Yongyuan Huang and Yao Shen and Liyan Xu},
keywords = {Street vending, Social sensing, Smart urban governance, High-frequency, Spatiotemporal big data, Perception bias},
abstract = {Street vending is an important part of the urban informal economy, especially in developing countries. How to control its negative externalities while augmenting its positive roles in the urban socio-economic system poses challenges to urban planning and governance. Existing studies have insufficiently addressed the issue largely due to the lack of high-frequent observation data for street vending events. By introducing socially sensed big data from the smart urban governance platform, as well as records from the “12345” urban problem complaint hotline of Jiangbei District, Ningbo, China, this paper examines and compares the spatiotemporal patterns and occurrence mechanisms of street vending events from both the urban managers' “top-down” and the urban residents' “bottom-up” points of view. Statistical and machine learning models show that the distribution of street vending activities as sensed by the two subjects does not overlap. The former concentrates in central urban areas and work times, while the latter is scattered distributed in everyday life-related places and times. The findings reaffirm the existence of perception bias in social sensing data and show the potential for utilizing such bias to nudge better urban governance practices. Theoretically and empirically, this research has contributed to promoting the people-oriented transformation of urban governance.}
}
@article{CHEN2020485,
title = {Intelligent resource allocation management for vehicles network: An A3C learning approach},
journal = {Computer Communications},
volume = {151},
pages = {485-494},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.12.054},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419314215},
author = {Miaojiang Chen and Tian Wang and Kaoru Ota and Mianxiong Dong and Ming Zhao and Anfeng Liu},
keywords = {Deep reinforcement learning, Vehicular networks, Markov decision process, Quality of service, Artificial intelligence, Asynchronous advantage actor–critic (A3C)},
abstract = {With the increasing demand of users for high-speed, low-delay and high-reliability services in connected vehicles network, wireless networks with communication, caching and computing convergence become the trend of network development in the future. To improve the quality of services of vehicles network, we propose a virtualized framework for mobile vehicle services, which using a learning-based resource allocation scheme. The dynamic change processes are modeled as Markov chains without making assumptions about the optimization goal and reducing the complexity of resource allocation computing. A high performance asynchronous advantage actor–critic learning algorithm is proposed to solve the complex dynamic resource allocation problem. Base on software-defined networking and information-centric networking, the method can dynamic orchestration of computing and communication resources to enhance the performance of virtual wireless networks. Simulation results verify that the proposed scheme can converge at a fast speed and improve the network operator’s total rewards.}
}
@article{DEFREITASBEZERRA2021102194,
title = {Towards a control-as-a-service architecture for smart environments},
journal = {Simulation Modelling Practice and Theory},
volume = {107},
pages = {102194},
year = {2021},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2020.102194},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X20301337},
author = {Diego {de Freitas Bezerra} and Victor Wanderley Costa {de Medeiros} and Glauco Estácio Gonçalves},
keywords = {Discrete control synthesis, Computing infrastructures, Environment control, Context-aware control},
abstract = {The popularization of the Internet of Things has opened opportunities for applications in various economic sectors, allowing them to monitor and control various types of environments. However, with the increasing number of data sent by devices, applications have come to demand increased availability and Internet bandwidth, but these demands are still a bottleneck in regions farther from large urban centers and with less economic development. In this work, we examine how bandwidth limitations can affect cloud-based applications and propose a Fog Computing-based Control-as-a-Service architecture to dynamically process events in the context of Internet of Things and Smart Environments. The architecture is composed of a Rules Engine and a Complex Event Processor based on Supervisory Control techniques for Discrete Event Systems. The Rules Engine allows defining dynamic rules conditioning control from different types of input data. The Complex Event Processor with automatic synthesis and reconfiguration capability allows performing control actions to established rules. Finally, we present scenarios where this solution can be applied, such as Smart Farm, Smart Home, Smart City, and Smart Healthcare.}
}
@article{TOM2020100653,
title = {Agent negotiation in an IoT-Fog based power distribution system for demand reduction},
journal = {Sustainable Energy Technologies and Assessments},
volume = {38},
pages = {100653},
year = {2020},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2020.100653},
url = {https://www.sciencedirect.com/science/article/pii/S2213138819307696},
author = {Rijo Jackson Tom and Suresh Sankaranarayanan and Joel J.P.C. Rodrigues},
keywords = {Internet of Things, Multi-agent system, Negotiation, Distribution automation, Smart grid},
abstract = {Growing energy demand is calling for an effective energy management. In smart homes all devices are connected to Internet by means of Internet of Things. There is a possible means of studying the consumer usage pattern and accordingly forecast their energy demand. Multi Agents has been used in computer science for a long time and applied for lot of applications for replicating the job of human. So towards monitoring and controlling the cyber physical systems, these multi agent system has been applied in smart transportation, smart cities, Smart Grid and so. This paper proposes a Multi-agent System (MAS) for smart energy management in an IoT based system. Inspired by the competition in human societies for accepting best proposals: this work proposes an Agent Negotiation system for demand reduction. The Agents in IoT system negotiate with the meter agent for accepting a proposal which will reduce the peak hour usage. The negotiation agent also negotiates with the meter agent for using energy when the availability of renewables are surplus. This negotiation is done with hundreds and thousands of homes thus helping Utilities to meet the supply-demand effectively. Consumers get the best pricing based on the accepted policies.}
}
@article{CHOWDHURY2020115958,
title = {A new Fractal Series Expansion based enhancement model for license plate recognition},
journal = {Signal Processing: Image Communication},
volume = {89},
pages = {115958},
year = {2020},
issn = {0923-5965},
doi = {https://doi.org/10.1016/j.image.2020.115958},
url = {https://www.sciencedirect.com/science/article/pii/S0923596520301375},
author = {Pinaki Nath Chowdhury and Palaiahnakote Shivakumara and Hamid A. Jalab and Rabha W. Ibrahim and Umapada Pal and Tong Lu},
keywords = {Enhancement, License plate detection, Fractional calculus, Fractal Series, License plate recognition},
abstract = {License plate recognition is an emerging topic for real-time applications in smart city development because of automatic systems for toll fee-paying, traffic controlling, and vehicle detection. Speed of vehicles, unpredictable weather conditions such as night/low light/limited light images, and capturing images at different angles make recognition harder. This paper presents a new Fractal Series Expansion (FSE) model for license plate image enhancement. The proposed FSE model is justified because it estimates the high probability for the pixels which represent the license plate compared to the pixels which represent background irrespective of the above challenges, resulting in enhanced image. Besides, since the FSE model considers local information for estimating probability, the model has the ability to tackle non-uniform degradations as well as distortion affected multiple adverse factors. In addition to qualitative results, to validate the effectiveness of the proposed enhancement, quantitatively, recognition rates of the different methods before and after enhancement are computed. For this purpose, we have considered different datasets like dataset of Night License Plate Images (NLPI), which consists of images captured in the night and low lights environment, the UCSD benchmark dataset which provides poor and high quality day license plate images, etc. It is noted that recognition results after enhancement is higher than that of before enhancement, and hence our enhancement is useful and effective.}
}
@article{WU2020418,
title = {Smart data driven quality prediction for urban water source management},
journal = {Future Generation Computer Systems},
volume = {107},
pages = {418-432},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.02.022},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19302687},
author = {Di Wu and Hao Wang and Razak Seidu},
keywords = {Water supply system, Smart data analysis, Water quality control, Correlation analysis, Adaptive learning rate BP neural network (ALBP), 2 Step isolation and random forest (2sIRF)},
abstract = {A water supply system that integrates water source management, treatment and distribution is a critical infrastructure in urban areas. Traditional water quality research mostly focused on separate aspects, lacking a comprehensive coverage of all aspects, which undermines the prediction accuracies. In this paper, we propose a smart data analysis scheme to analyze and predict the water quality, considering all the water quality standard indicators. Instead of data output from water treatment, we collect the raw water data directly from water sources. We design two models to predict the water quality: (1) adaptive learning rate BP neural network (ALBP) and (2) 2-step isolation and random forest (2sIRF). We applied these models in the practical urban water supply systems of Oslo and Bergen in Norway. The results show that ALBP is theoretically simple and easy to implement. 2sIRF considers the risk distribution and shows higher prediction accuracy. In addition, we perform the correlation analysis of all the indicators and the importance analysis over different indicators. The domain experts have confirmed that this work is meaningful for future risk control and decision support in urban water supply systems.}
}
@article{HUOTARI2021107670,
title = {Comparing seven methods for state-of-health time series prediction for the lithium-ion battery packs of forklifts},
journal = {Applied Soft Computing},
volume = {111},
pages = {107670},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107670},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621005913},
author = {Matti Huotari and Shashank Arora and Avleen Malhi and Kary Främling},
keywords = {Electrical vehicles, State-of-health for lithium-ion batteries, Machine learning, Neural networks, Timeseries prediction},
abstract = {A key aspect for the forklifts is the state-of-health (SoH) assessment to ensure the safety and the reliability of uninterrupted power source. Forecasting the battery SoH well is imperative to enable preventive maintenance and hence to reduce the costs. This paper demonstrates the capabilities of gradient boosting regression for predicting the SoH timeseries under circumstances when there is little prior information available about the batteries. We compared the gradient boosting method with light gradient boosting, extra trees, extreme gradient boosting, random forests, long short-term memory networks and with combined convolutional neural network and long short-term memory networks methods. We used multiple predictors and lagged target signal decomposition results as additional predictors and compared the yielded prediction results with different sets of predictors for each method. For this work, we are in possession of a unique data set of 45 lithium-ion battery packs with large variation in the data. The best model that we derived was validated by a novel walk-forward algorithm that also calculates point-wise confidence intervals for the predictions; we yielded reasonable predictions and confidence intervals for the predictions. Furthermore, we verified this model against five other lithium-ion battery packs; the best model generalised to greater extent to this set of battery packs. The results about the final model suggest that we were able to enhance the results in respect to previously developed models. Moreover, we further validated the model for extracting cycle counts presented in our previous work with data from new forklifts; their battery packs completed around 3000 cycles in a 10-year service period, which corresponds to the cycle life for commercial Nickel–Cobalt–Manganese (NMC) cells.}
}
@article{BAN2020608,
title = {Energy decision making of steel company based on energy management system},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {5},
pages = {608-613},
year = {2020},
note = {3rd IFAC Workshop on Cyber-Physical & Human Systems CPHS 2020},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.04.151},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321002846},
author = {Yunqi Ban},
keywords = {energy management system, energy prediction, energy consumption, decision making},
abstract = {With the promotion of the concept of smart city, every industry in the city needs to become more intelligent. As a pillar industry of economic development, the energy-intensive steel plant has brought challenges to the city environment. Factories in cities also need to be more intelligent. The application of artificial intelligence and data technology has become one of the important meaning to improve the management level of steel plant and to improve the city environment. As a modern management tool, energy management system provides a new way of intelligent management for iron and steel companies. The energy management system can be used to monitor the energy consumption in real time, master the energy consumption of the company and allocate the energy consumption of the company. So we can get better production plan, reduce the energy consumption of the company, and improve the competitiveness of the company. Two functions, energy allocation and energy consumption prediction, are developed in the energy management system. According to the formula of iron balance and the relationship between iron and energy consumption in each production unit, the mathematical model of energy allocation is established and applied in the energy management system. Another one of the functions of the energy management system is to predict the energy consumption of steel companies with maximum prediction error is about 5%, which provides the basis for the auxiliary decision-making of energy management. The forecasted results can be used to better understand the trend of energy consumption of the whole company, so as to do a good decision of energy reserve and reduce unnecessary waste.}
}
@article{ESKANDARNIA2022103618,
title = {An embedded deep-clustering-based load profiling framework},
journal = {Sustainable Cities and Society},
volume = {78},
pages = {103618},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103618},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721008829},
author = {Elham Eskandarnia and Hesham M. Al-Ammal and Riadh Ksantini},
keywords = {Smart grid, Deep clustering, Deep learning, Load profiling},
abstract = {Load profiling is an essential step in several smart meter analytics tasks, such as forecasting and planning, that directly impact sustainable energy management. As most real-world smart meter data are unlabeled, the unsupervised learning clustering-driven load profiling approach aims to group related customers based on usage trends. However, due to the curse of dimensionality, conventional clustering algorithms perform poorly and often lead to inadequate load curves. The proposed load profiling framework’s novelty is twofold. First, using an autoencoder the framework represents data as a hierarchy within the layers of the deep network, allowing for dimensionality reduction and highly nonlinear decision separation between clusters at the autoencoder bottleneck level. This is achieved by implementing autoencoder-based clustering that automatically converts smart meter data into more clustering-friendly representations that retain the original data characteristics. Second, the framework integrates dimensionality reduction and clustering into a single end-to-end unsupervised learning framework. The deep clustering framework is then tested on two real-world smart meter datasets, and the experimental results show that the proposed framework produces significantly better load profiles when compared to classical clustering algorithms as well as previous hybrid frameworks proposed in the literature. The paper concludes with a discussion of the results and a set of future directions for improving the load profiling task.}
}
@article{SALEHI2019259,
title = {Data mining methodology employing artificial intelligence and a probabilistic approach for energy-efficient structural health monitoring with noisy and delayed signals},
journal = {Expert Systems with Applications},
volume = {135},
pages = {259-272},
year = {2019},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.05.051},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419303860},
author = {Hadi Salehi and Saptarshi Das and Subir Biswas and Rigoberto Burgueño},
keywords = {Structural health monitoring, Data mining, Artificial intelligence, Probabilistic approach, Signal time delay},
abstract = {Numerous methods have been developed in the context of expert and intelligent systems for structural health monitoring (SHM) with wireless sensor networks (WSNs). However, these techniques have been proven to be efficient when dealing with continuous signals, and the applicability of such expert systems with discrete noisy signals has not yet been explored. This study presents an intelligent data mining methodology as part of an expert system developed for SHM with noisy and delayed signals, which are generated by a through-substrate self-powered sensor network. The noted sensor network has been demonstrated as an effective means for minimizing energy consumption in WSNs for SHM. Experimental vibration tests were conducted on a cantilever plate to evaluate the developed expert system for SHM. The proposed data mining method is based on the integration of pattern recognition, an innovative probabilistic approach, and machine learning. The novelty of the proposed system for SHM with data interpretation methodology lies in the integration of the noted intelligent techniques on discrete, binary, noisy, and delayed patterns of signals collected from self-powered sensing technology in the application to a practical engineering problem, i.e., data-driven energy-efficient SHM. Results confirm that the proposed data mining method employing a probabilistic approach can be effectively used to reconstruct delayed and missing signals, thereby addressing the important issue of energy availability for intelligent SHM systems being used for damage identification in civil and aerospace structures. The applicability and effectiveness of the expert system with the data mining approach in detecting damage with noisy signals was demonstrated for plate-like structures with an accuracy of 97%. The present study successfully contributes to advance data mining and signal processing techniques in the SHM domain, indicating a practical application of expert and intelligent systems applied to damage detection in SHM platforms. Findings from this research pave a way for development of the data analysis techniques that can be employed for interpreting noisy and incomplete signals collected from various expert systems such as those being used in intelligent infrastructure monitoring systems and smart cities.}
}
@article{VRABLECOVA2018102,
title = {Smart grid load forecasting using online support vector regression},
journal = {Computers & Electrical Engineering},
volume = {65},
pages = {102-117},
year = {2018},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2017.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0045790617320645},
author = {Petra Vrablecová and Anna {Bou Ezzeddine} and Viera Rozinajová and Slavomír Šárik and Arun Kumar Sangaiah},
keywords = {Smart grid, Short term load forecasting, Support vector regression, Online processing},
abstract = {Smart grid, an integral part of a smart city, provides new opportunities for efficient energy management, possibly leading to big cost savings and a great contribution to the environment. Grid innovations and liberalization of the electricity market have significantly changed the character of data analysis in power engineering. Online processing of large amounts of data continuously generated by the smart grid can deliver timely and precise power load forecasts – an important input for interactions on the market where the energy can be contracted even minutes ahead of its consumption to minimize the grid imbalances. We demonstrate the suitability of online support vector regression (SVR) method to short term power load forecasting and thoroughly explore its pros and cons. We present a comparison of ten state-of-the-art forecasting methods in terms of accuracy on public Irish CER dataset. Online SVR achieved accuracy of complex tree-based ensemble methods and advanced online methods.}
}
@article{ZHANG20211,
title = {A survey on attack detection, estimation and control of industrial cyber–physical systems},
journal = {ISA Transactions},
volume = {116},
pages = {1-16},
year = {2021},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2021.01.036},
url = {https://www.sciencedirect.com/science/article/pii/S001905782100046X},
author = {Dan Zhang and Qing-Guo Wang and Gang Feng and Yang Shi and Athanasios V. Vasilakos},
keywords = {Cyber–physical systems, Security, DoS attack, Deception attack, Attack detection, Secure estimation, Secure control},
abstract = {Cyber–physical systems (CPSs) are complex systems that involve technologies such as control, communication, and computing. Nowadays, CPSs have a wide range of applications in smart cities, smart grids, smart manufacturing and intelligent transportation. However, with integration of industrial control systems with modern communication technologies, CPSs would be inevitably exposed to increasing security threats, which could lead to severe degradation of the system performance and even destruction of CPSs. This paper presents a survey on recent advances on security issues of industrial cyber–physical systems (ICPSs). We specifically discuss two typical kinds of attacks, i.e., Denial-of-Service (DoS) attack and Deception attack, and present recent results in terms of attack detection, estimation, and control of ICPSs. Classifications of current studies are analyzed and summarized based on different system modeling and analysis methods. In addition, advantages and disadvantage of various methodologies are also discussed. Finally, the paper concludes with some potential future research directions on secure ICPSs.}
}
@article{WANG2020175,
title = {Towards cost-effective service migration in mobile edge: A Q-learning approach},
journal = {Journal of Parallel and Distributed Computing},
volume = {146},
pages = {175-188},
year = {2020},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2020.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0743731520303488},
author = {Yang Wang and Shan Cao and Hongshuai Ren and Jianjun Li and Kejiang Ye and Chengzhong Xu and Xi Chen},
keywords = {Mobile edge computing, Dynamic service migration, Reinforcement learning, Q-learning, Software-defined networking},
abstract = {Service migration in mobile edge computing is a promising approach to improving the quality of service (QoS) for mobile users and reducing the network operational cost for service providers as well. However, these benefits are not free, coming at costs of bulk-data transfer, and likely service disruption, which could consequently increase the overall service costs. To gain the benefits of service migration while minimizing its cost across the edge nodes, in this paper, we leverage reinforcement learning (RL) method to design a cost-effective framework, called Mig-RL, for the service migration with a reduction of total service costs as a goal in a mobile edge environment. The Mig-RL leverages the infrastructure of edge network and deploys a migration agent through Q-learning to learn the optimal policy with respect to the service migration status. We distinguish the Mig-RL from other existing works in several major aspects. First, we fully exploit the nature of this problem in a modest migration space, which allows us to constrain the number of service replicas whereby a defined state–action space could be effectively handled, as opposed to those methods that need to always approximate a huge state–action space for policy optimality. Second, we advocate a migration policy-base as a cache to save the learning process by retrieving the most effective policy whenever a similar migration pattern is encountered as time goes on. Finally, by exploiting the idea of software defined network, we also investigate the efficient implementation of Mig-RL in mobile edge network. Experimental results based on some real and synthesized access sequences show that Mig-RL, compared with the selected existing algorithms, can substantially minimize the service costs, and in the meantime, efficiently improve the QoS by adapting to the changes of mobile access patterns.}
}
@article{CHAUHAN2020106746,
title = {IoT Enabled real-Time urban transport management system},
journal = {Computers & Electrical Engineering},
volume = {86},
pages = {106746},
year = {2020},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2020.106746},
url = {https://www.sciencedirect.com/science/article/pii/S0045790620306017},
author = {Vatsal Chauhan and Meetu Patel and Sudeep Tanwar and Sudhanshu Tyagi and Neeraj Kumar},
keywords = {Smart parking system, Raspberry pi, Arduino, Internet of things, Sensors, Logistic regression},
abstract = {With the popularity of smart transportation in smart cities, there is an exponential increase in the number of vehicles on the road, which in turn increases the congestion in the network traffic. Therefore, it is becoming a challenging task to find parking slots in modern societies around the globe. To tackle the aforementioned issues, in this paper, we propose a system named iERS, which reduces the user’s effort to locate the nearest available parking slots in real-time. It reduces individual efforts to locate a suitable parking slot. iERS helps the user to find an available parking slot and also provides direction towards the slot. iERS uses the Internet of Things (IoT)-based infrastructure to monitor and signal the availability of different parking slots around the smart communities. The simulation and testbed results demonstrate that iERS provides better guidance to the users to reserve the available parking slot in comparison to the other existing solutions.}
}
@article{THIBAUD201879,
title = {Internet of Things (IoT) in high-risk Environment, Health and Safety (EHS) industries: A comprehensive review},
journal = {Decision Support Systems},
volume = {108},
pages = {79-95},
year = {2018},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2018.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167923618300344},
author = {Montbel Thibaud and Huihui Chi and Wei Zhou and Selwyn Piramuthu},
keywords = {Internet of Things (IoT), Environment Health and Safety (EHS), Healthcare, Food supply chain, Connected vehicles, Smart city},
abstract = {The rise of ubiquitous systems is sustained by the development and progressive adoption of the Internet of Things (IoT) devices and their enabling technologies. IoT has been shown to have significant potential in high-risk Environment, Health, and Safety (EHS) industries. In these industries, human lives are at stake and IoT-based applications are primed to offer safe, reliable, and efficient solutions due to their ability to operate at a fine granular level and provide rich low-level information. We review existing published research on IoT-based applications in high-risk EHS industries with specific emphasis on healthcare industry, food supply chain (FSC), mining and energy industries (oil & gas and nuclear), intelligent transportation (e.g., connected vehicles), and building & infrastructure management for emergency response operations until 2016. We also highlight IoT-related challenges and proposed solutions in high risk EHS industries. We then conclude by presenting research challenges and expected trends for IoT in these industries.}
}
@article{TONG2020116,
title = {Adaptive computation offloading and resource allocation strategy in a mobile edge computing environment},
journal = {Information Sciences},
volume = {537},
pages = {116-131},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.05.057},
url = {https://www.sciencedirect.com/science/article/pii/S0020025520304655},
author = {Zhao Tong and Xiaomei Deng and Feng Ye and Sunitha Basodi and Xueli Xiao and Yi Pan},
keywords = {Deep reinforcement learning, Energy consumption, Mobile edge computing, Response time, Task offloading},
abstract = {With the popularity of smart mobile equipment, the amount of data requested by users is growing rapidly. The traditional centralized processing method represented by the cloud computing model can no longer satisfy the effective processing of large amounts of data. Therefore, the mobile edge computing (MEC) is used as a new computing model to process the big growing data, which can better meet the service requirements. Similar to the task scheduling problem in cloud computing, an important issue in the MEC environment is task offloading and resource allocation. In this paper, we propose an adaptive task offloading and resource allocation algorithm in the MEC environment. The proposed algorithm uses the deep reinforcement learning (DRL) method to determine whether the task needs to be offloaded and allocates computing resources for the task. We simulate the generation of tasks in the form of Poisson distribution, and all tasks are submitted to be processed in the form of task flow. Besides, we consider the mobility of mobile user equipment (UE) between base stations (BSs), which is closer to the actual application environment. The DRL method is used to select the suitable computing node for each task according to the optimization objective, and the optimal strategy for solving the objective problem is learned in the algorithm training process. Compared with other comparison algorithms in different MEC environments, our proposed algorithm has the best performance in reducing the task average response time and the total system energy consumption, improving the system utility, which meets the profits of users and service providers.}
}
@article{MUJEEB2019101642,
title = {ESAENARX and DE-RELM: Novel schemes for big data predictive analytics of electricity load and price},
journal = {Sustainable Cities and Society},
volume = {51},
pages = {101642},
year = {2019},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2019.101642},
url = {https://www.sciencedirect.com/science/article/pii/S2210670718326234},
author = {Sana Mujeeb and Nadeem Javaid},
keywords = {Big Data, Predictive Analytics, Electricity Load and Price, Deep Recurrent Neural Networks, Efficient Sparse Autoencoder Nonlinear Autoregressive Network, Differential Evolution, Recurrent Extreme Learning Machine},
abstract = {Accurate forecasting of the electricity price and load is an essential and challenging task in smart grids. Since electricity load and price have a strong correlation, the forecast accuracy degrades when bidirectional relation of price and load is not considered. Therefore, this paper considers price and load relationship and proposes two Multiple Inputs Multiple Outputs (MIMO) Deep Recurrent Neural Networks (DRNNs) models for price and load forecasting. The first proposed model, Efficient Sparse Autoencoder Nonlinear Autoregressive Network with eXogenous inputs (ESAENARX) comprises of feature engineering and forecasting. For feature engineering, we propose ESAE and performed forecasting using existing method NARX. The second proposed model: Differential Evolution Recurrent Extreme Learning Machine (DE-RELM) is based on RELM model and the meta-heuristic DE optimization technique. The descriptive and predictive analyses are performed on two well-known electricity markets’ big data, i.e., ISO NE and PJM. The proposed models outperform their sub models and a benchmark model. The refined and informative features extracted by ESAE improve the forecasting accuracy in ESANARX and optimization improves the DE-RELM's accuracy. As compared to cascade Elman network, ESAENARX has reduced MAPE upto 16% for load forecasting, 7% for price forecasting. DE-RELM reduce 1% MAPE for both load and price forecasting.}
}
@article{MA2019724,
title = {Graph-based and scenario-driven microservice analysis, retrieval, and testing},
journal = {Future Generation Computer Systems},
volume = {100},
pages = {724-735},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.05.048},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19302614},
author = {Shang-Pin Ma and Chen-Yuan Fan and Yen Chuang and I-Hsiu Liu and Ci-Wei Lan},
keywords = {Microservice retrieval, Microservice testing, Microservice analysis, Service dependency graph, Behavior-driven development},
abstract = {The microservice architecture (MSA) differs fundamentally from the monolithic, layered architecture. The use of microservices provides a high degree of autonomy, composability, scalability, and fault-tolerance. MSA is regarded by many as a promising architecture for smart-city applications; however, a number of issues remain, including (1) the management of complex call relationships among microservices; (2) ensuring the quality of the overall software system even as new microservices are added and existing ones are modified, and (3) locating existing microservices that satisfy new requirements. In this paper, we propose a novel approach to the development of microservice-based systems, referred to as GSMART (Graph-based and Scenario-driven Microservice Analysis, Retrieval and Testing). GSMART enables the automatic generation of a “Service Dependency Graph (SDG)” by which to visualize and analyze dependency relationships between microservices as well as between services and scenarios. It also enables the automatic retrieval of test cases required for system changes to reduce the time and costs associated with regression testing. A microservice retrieval method using VSM and word2vec accelerates the development of new microservices tailored specifically to the needs of users based on user-provided scenarios. Experiment results demonstrate the feasibility, effectiveness, and efficiency of all of the main features of GSMART.}
}
@article{CHEN2021102849,
title = {Low power convolutional architectures: Three operator switching systems based on forgetting memristor bridge},
journal = {Sustainable Cities and Society},
volume = {69},
pages = {102849},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.102849},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721001396},
author = {Ling Chen and Chencheng Gong and Chuandong Li and Junjian Huang},
keywords = {Long- and short-term memory, Forgetting memristor bridge, Operator switching system, Image processing},
abstract = {With the development of technology and society, artificial intelligence has entered the era of deep learning neural networks. Convolution operation and image processing are fundamental technologies for deep neural networks and artificial intelligence, so reducing the energy consumption of convolution operation and increasing the speed of image processing will promote the development of a sustainable intelligent society. Traditional image processing technologies are based on the Von Neumann architecture, which is slow and not convenient for the hardware implementation of neural networks. Therefore, this paper breaks through the Von Neumann architecture, and uses the forgetting memristor bridge to realize the parallel image processing on the neumorphic chips. We use the forgetting characteristics of the memristor bridge to switch operators, and design single-operator switching, double-operator switching and K-operator switching three system architectures. The image operator switching systems designed in this paper not only have the similar processing effect of the traditional way, but also have the advantages of easy control, fast running speed (the processing speed is reduced from ms to μs), and low power consumption (the power consumption is reduced by nearly half), which will bring immeasurable benefits to the sustainable intelligent society.}
}
@article{SINGH2020283,
title = {An integrated fog and Artificial Intelligence smart health framework to predict and prevent COVID-19},
journal = {Global Transitions},
volume = {2},
pages = {283-292},
year = {2020},
issn = {2589-7918},
doi = {https://doi.org/10.1016/j.glt.2020.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2589791820300244},
author = {Prabhdeep Singh and Rajbir Kaur},
keywords = {Smart city, Quality of service framework, Ensemble model, Cloud/fog computing, Artificial intelligence, COVID-19},
abstract = {Nowadays, COVID-19 is spreading at a rapid rate in almost all the continents of the world. It has already affected many people who are further spreading it day by day. Hence, it is the most essential to alert nearby people to be aware of it due to its communicable behavior. Till May 2020, no vaccine is available for the treatment of this COVID-19, but the existing technologies can be used to minimize its effect. Cloud/fog computing could be used to monitor and control this rapidly spreading infection in a cost-effective and time-saving manner. To strengthen COVID-19 patient prediction, Artificial Intelligence(AI) can be integrated with cloud/fog computing for practical solutions. In this paper, fog assisted the internet of things based quality of service framework is presented to prevent and protect from COVID-19. It provides real-time processing of users’ health data to predict the COVID-19 infection by observing their symptoms and immediately generates an emergency alert, medical reports, and significant precautions to the user, their guardian as well as doctors/experts. It collects sensitive information from the hospitals/quarantine shelters through the patient IoT devices for taking necessary actions/decisions. Further, it generates an alert message to the government health agencies for controlling the outbreak of chronic illness and for tanking quick and timely actions.}
}
@article{QI2021328,
title = {Privacy-preserving blockchain-based federated learning for traffic flow prediction},
journal = {Future Generation Computer Systems},
volume = {117},
pages = {328-337},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X2033065X},
author = {Yuanhang Qi and M. Shamim Hossain and Jiangtian Nie and Xuandi Li},
keywords = {Federated learning, Blockchain, Local differential privacy, Traffic flow prediction, Intelligent transportation systems},
abstract = {As accurate and timely traffic flow information is extremely important for traffic management, traffic flow prediction has become a vital component of intelligent transportation systems. However, existing traffic flow prediction methods based on centralized machine learning need to gather raw data for model training, which involves serious privacy exposure risks. To address these problems, federated learning that shares model updates without exchanging raw data, has recently been introduced as an efficient solution for achieving privacy protection. However, the existing federated learning frameworks are based on a centralized model coordinator that still suffers from severe security challenges, such as a single point of failure. Thereby, a consortium blockchain-based federated learning framework is proposed to enable decentralized, reliable, and secure federated learning without a centralized model coordinator. In the proposed framework, the model updates from distributed vehicles are verified by miners to prevent unreliable model updates and are then stored on the blockchain. In addition, to further protect model privacy on the blockchain, a differential privacy method with a noise-adding mechanism is applied for the blockchain-based federated learning framework. Numerical results illustrate that the proposed schemes can effectively prevent data poisoning attacks and improve the privacy protection of model updates for secure and privacy-preserving traffic flow prediction.}
}
@article{MAZOKHA2021101475,
title = {MobIntel: Sensing and analytics infrastructure for urban mobility intelligence},
journal = {Pervasive and Mobile Computing},
volume = {77},
pages = {101475},
year = {2021},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2021.101475},
url = {https://www.sciencedirect.com/science/article/pii/S1574119221001097},
author = {Stepan Mazokha and Fanchen Bao and Jiannan Zhai and Jason O. Hallstrom},
keywords = {Localization, Mobility monitoring, Occupancy estimation, WiFi probe requests, IoT, Smart cities},
abstract = {Mobility monitoring in urban environments provides valuable insights into pedestrian and vehicle movement. Understanding the causes and effects of changing mobility patterns can help city officials and businesses optimize operations and support economic development. In this paper, we introduce MobIntel, a privacy-centric alternative to visual surveillance for mobility monitoring. We present the design, implementation, and evaluation of the MobIntel sensor network, the associated cloud-based processing system, and the web-based visualization portal. We evaluate system capacity and accuracy based on real-life data collected from a deployment in downtown West Palm Beach, FL, spanning 14 months. We offer sample use cases where pedestrian activity patterns revealed by MobIntel can be helpful to the city government. Finally, we discuss several obstacles that must be overcome to transition from pedestrian counting to trajectory monitoring.}
}
@article{ALMEIDA2019598,
title = {A critical analysis of an IoT—aware AAL system for elderly monitoring},
journal = {Future Generation Computer Systems},
volume = {97},
pages = {598-619},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.03.019},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18321769},
author = {Aitor Almeida and Rubén Mulero and Piercosimo Rametta and Vladimir Urošević and Marina Andrić and Luigi Patrono},
keywords = {Ambient assisted living, BLE, Internet of things, Big data, Data analytics, Performance},
abstract = {A growing number of elderly people (65+ years old) are affected by particular conditions, such as Mild Cognitive Impairment (MCI) and frailty, which are characterized by a gradual cognitive and physical decline. Early symptoms may spread across years and often they are noticed only at late stages, when the outcomes remain irrevocable and require costly intervention plans. Therefore, the clinical utility of early detecting these conditions is of substantial importance in order to avoid hospitalization and lessen the socio-economic costs of caring, while it may also significantly improve elderly people’s quality of life. This work deals with a critical performance analysis of an Internet of Things aware Ambient Assisted Living (AAL) system for elderly monitoring. The analysis is focused on three main system components: (i) the City-wide data capturing layer, (ii) the Cloud-based centralized data management repository, and (iii) the risk analysis and prediction module. Each module can provide different operating modes, therefore the critical analysis aims at defining which are the best solutions according to context’s needs. The proposed system architecture is used by the H2020 City4Age project to support geriatricians for the early detection of MCI and frailty conditions.}
}
@article{MOZAFFARI2019100124,
title = {Practical fall detection based on IoT technologies: A survey},
journal = {Internet of Things},
volume = {8},
pages = {100124},
year = {2019},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2019.100124},
url = {https://www.sciencedirect.com/science/article/pii/S2542660519302355},
author = {Nassim Mozaffari and Javad Rezazadeh and Reza Farahbakhsh and Samaneh Yazdani and Kumbesan Sandrasegaran},
keywords = {Internet of Things (IoT), Fall Prediction, Fall Prevention, Fall Detection, Machine Learning},
abstract = {Fall is the second incident that leads to death over the world. Fall event happens to numerous groups of people consist of elderly, babies and also younger people. Admittedly, fall-related research must be considered as one of the most important aspects of a healthy lifestyle. For this reason, Internet of Things(IoT) is the emerging technology and a powerful candidate to develop fall diagnosis system. In this paper, we have discussed the three stages of fall as Prediction, Prevention, and Detection. We have illustrated Edge, Fog, and Cloud layers as IoT layers to develop a fall diagnosis system. At the end of the paper, we have considered the challenges of fall diagnosis systems and suggested future aspects.}
}
@article{TURABIEH2018575,
title = {Dynamic L-RNN recovery of missing data in IoMT applications},
journal = {Future Generation Computer Systems},
volume = {89},
pages = {575-583},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18307490},
author = {Hamza Turabieh and Amer {Abu Salem} and Noor Abu-El-Rub},
keywords = {Missing data, Deep learning, IoMT},
abstract = {One of the most important factors of success of the Internet of Medical Things (IoMT) applications is reliable data delivery. The high quality of data delivery is a vital issue for IoMT applications to provide a high-quality of services to the end users. However, IoMT applications may suffer from low quality of data delivery due to several reasons, such as sensing errors, bad connections or outside attacks. As a result, the collected data is incomplete. IoMT applications require a complete data to provide a high-quality of services to the end users; otherwise, the performance will decrease and not meet the main requirements of IoMT applications. In reality, missing data should be intelligently recovered to save time and cost. In this paper, we propose a Dynamic Layered-Recurrent Neural Network (Dynamic L-RNN) approach to recover missing data from IoMT applications. The main idea is to perform a dynamic L-RNN to predict any missing value in a simple fast manner to save time and cost. The collected data is divided into two categories, complete and incomplete data. A dynamic L-RNN is trained based on complete data, which is used to predict the missing data from incomplete data. This proposed method is able to recover the missing data for IoMT applications with high AUC value when applied to two different datasets. The obtained results show great enhancement in the AUC values after recovering the missing data.}
}
@article{WANG2022108616,
title = {LightLog: A lightweight temporal convolutional network for log anomaly detection on the edge},
journal = {Computer Networks},
volume = {203},
pages = {108616},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108616},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621005119},
author = {Zumin Wang and Jiyu Tian and Hui Fang and Liming Chen and Jing Qin},
keywords = {Log anomaly detection, Temporal convolutional network, Global average pooling, Pointwise-convolution, Edge computing},
abstract = {Log anomaly detection on edge devices is the key to enhance edge security when deploying IoT systems. Despite the success of many newly proposed deep learning based log anomaly detection methods, handling large-scale logs on edge devices is still a bottleneck due to the limited computational power on these devices to fulfil the real-time processing requirement for accurate anomaly detection. In this work, we propose a novel lightweight log anomaly detection algorithm, named LightLog, to tackle this research gap. In specific, we achieve real-time processing speed on the task via two aspects: (i) creation of a low-dimensional semantic vector space based on word2vec and post-processing algorithms (PPA); and (ii) design of a lightweight temporal convolutional network (TCN) for the detection. These two components significantly reduce the number of parameters and computations of a standard TCN while improving the detection performance. Experimental results show that our LightLog outperforms several benchmarking methods, namely DeepLog, LogAnomaly and RobustLog, by achieving 97.0 F1 score on HDFS Dataset and 97.2 F1 score on BGL with smallest model size. This effective yet efficient method paves the way to the deployment of log anomaly detection on the edge. Our source code and datasets are freely available on https://github.com/Aquariuaa/LightLog.}
}
@article{FAN2021102049,
title = {Disaster City Digital Twin: A vision for integrating artificial and human intelligence for disaster management},
journal = {International Journal of Information Management},
volume = {56},
pages = {102049},
year = {2021},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2019.102049},
url = {https://www.sciencedirect.com/science/article/pii/S0268401219302956},
author = {Chao Fan and Cheng Zhang and Alex Yahja and Ali Mostafavi},
keywords = {Digital twin, Machine learning, Information flow, Disaster management},
abstract = {This paper presents a vision for a Disaster City Digital Twin paradigm that can: (i) enable interdisciplinary convergence in the field of crisis informatics and information and communication technology (ICT) in disaster management; (ii) integrate artificial intelligence (AI) algorithms and approaches to improve situation assessment, decision making, and coordination among various stakeholders; and (iii) enable increased visibility into network dynamics of complex disaster management and humanitarian actions. The number of humanitarian relief actions is growing due to the increased frequency of natural and man-made crises. Various streams of research across different disciplines have focused on ICT and AI solutions for enhancing disaster management processes. However, most of the existing research is fragmented without a common vision towards a converging paradigm. Recognizing this, this paper presents the Disaster City Digital Twin as a unifying paradigm. The four main components of the proposed Digital Twin paradigm include: multi-data sensing for data collection, data integration and analytics, multi-actor game-theoretic decision making, and dynamic network analysis. For each component, the current state of the art related to AI methods and approaches are examined and gaps are identified.}
}
@article{NISHANT2020102104,
title = {Artificial intelligence for sustainability: Challenges, opportunities, and a research agenda},
journal = {International Journal of Information Management},
volume = {53},
pages = {102104},
year = {2020},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2020.102104},
url = {https://www.sciencedirect.com/science/article/pii/S0268401220300967},
author = {Rohit Nishant and Mike Kennedy and Jacqueline Corbett},
keywords = {Agenda for practice, AI, Artificial intelligence, Climate change, Environmental governance, Natural environment, Research agenda, Sustainability},
abstract = {Artificial intelligence (AI) will transform business practices and industries and has the potential to address major societal problems, including sustainability. Degradation of the natural environment and the climate crisis are exceedingly complex phenomena requiring the most advanced and innovative solutions. Aiming to spur groundbreaking research and practical solutions of AI for environmental sustainability, we argue that AI can support the derivation of culturally appropriate organizational processes and individual practices to reduce the natural resource and energy intensity of human activities. The true value of AI will not be in how it enables society to reduce its energy, water, and land use intensities, but rather, at a higher level, how it facilitates and fosters environmental governance. A comprehensive review of the literature indicates that research regarding AI for sustainability is challenged by (1) overreliance on historical data in machine learning models, (2) uncertain human behavioral responses to AI-based interventions, (3) increased cybersecurity risks, (4) adverse impacts of AI applications, and (5) difficulties in measuring effects of intervention strategies. The review indicates that future studies of AI for sustainability should incorporate (1) multilevel views, (2) systems dynamics approaches, (3) design thinking, (4) psychological and sociological considerations, and (5) economic value considerations to show how AI can deliver immediate solutions without introducing long-term threats to environmental sustainability.}
}
@article{GONG202090,
title = {A Frustum-based probabilistic framework for 3D object detection by fusion of LiDAR and camera data},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {159},
pages = {90-100},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.10.015},
url = {https://www.sciencedirect.com/science/article/pii/S0924271619302539},
author = {Zheng Gong and Haojia Lin and Dedong Zhang and Zhipeng Luo and John Zelek and Yiping Chen and Abdul Nurunnabi and Cheng Wang and Jonathan Li},
keywords = {3D object detection, CNN, Deep learning, LiDAR point clouds, MLS, SLAM},
abstract = {This paper presents a real-time 3D object detector based on LiDAR based Simultaneous Localization and Mapping (LiDAR-SLAM). The 3D point clouds acquired by mobile LiDAR systems, within the environment of buildings, are usually highly sparse, irregularly distributed, and often contain occlusion and structural ambiguity. Existing 3D object detection methods based on Convolutional Neural Networks (CNNs) rely heavily on both the stability of the 3D features and a large amount of labelling. A key challenge is efficient detection of 3D objects in point clouds of large-scale building environments without pre-training the 3D CNN model. To project image-based object detection results and LiDAR-SLAM results onto a 3D probability map, we combine visual and range information into a frustum-based probabilistic framework. As such, we solve the sparse and noise problem in LiDAR-SLAM data, in which any point cloud descriptor can hardly be applied. The 3D object detection results, obtained using both backpack LiDAR dataset and the well-known KITTI Vision Benchmark Suite, show that our method outperforms the state-of-the-art methods for object localization and bounding box estimation.}
}
@article{ALI2021127904,
title = {Intelligent energy management: Evolving developments, current challenges, and research directions for sustainable future},
journal = {Journal of Cleaner Production},
volume = {314},
pages = {127904},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.127904},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621021223},
author = {Muhammad Ali and Krishneel Prakash and Md Alamgir Hossain and Hemanshu R. Pota},
keywords = {Intelligent energy management systems, Systematic literature review (SLR), VOS viewer experiments},
abstract = {In the last decade, there have been significant developments in the field of intelligent energy management systems (IEMSs), with various methods and new solutions proposed for managing the energy resources intelligently. An important issue related to finding the desired outcomes remains unexplored, i.e., how to determine key insights from the sparse academic literature in the age of digital publishing. To mitigate the issue, this study proposes a novel strategy to systematically survey the relevant studies by converting the sparse literature into visual presentations. We first apply a systematic approach called a PRISMA (Preferred Reporting Items for Systematic reviews and Meta-analyses) statement to provide the insights from the published literature of the past decade (2010–2020). Then, VOSviewer experiments are conducted to transform these sparse scholarly data into visual representations. In total, eighty-one papers published in high-impact journals are identified based on their scientific soundness and relevance, and a VOSviewer analysis is applied. The analysis revealed the existence of three research clusters focused on the following main thematic areas: the energy management in smart homes and smart grids (35 journal papers); the emerging concept of context-awareness (26 journal papers); and the role of privacy preservation in IEMSs (20 journal papers). This analysis uncovers the current state of IEMSs and explores existing issues, methods, findings, and gaps. Thus, future research directions have been recommended to fill the existing gaps. This systematic literature review is to assist both researchers and industry practitioners to understand the research gaps of previous studies.}
}
@article{PONCE2019170,
title = {An indoor predicting climate conditions approach using Internet-of-Things and artificial hydrocarbon networks},
journal = {Measurement},
volume = {135},
pages = {170-179},
year = {2019},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2018.11.043},
url = {https://www.sciencedirect.com/science/article/pii/S0263224118310972},
author = {Hiram Ponce and Sebastián Gutiérrez},
keywords = {Artificial intelligence, Distributed services architecture, EnOcean, Internet of Things, Machine learning, Predictive, Raspberry Pi, Sensors, Weather station, Web service},
abstract = {The prediction and understanding of environmental conditions are of great importance to prevent and analyze changes in environment, supporting meteorological based sectors, such as agriculture or smart cities. In that sense, this paper presents an Internet of Things (IoT) system for predicting climate conditions inside enclosures, i.e. temperature, using artificial intelligence by means of a supervised learning method, the artificial hydrocarbon networks model. It allows predicting the temperature of remote locations using information from a web service comparing it with field temperature sensors. Experimental results of the supervised learning model are presented in two modes: offline training to detect the suitable parameters of the model and testing to validate the model with new data retrieval from the web service. Experimental results over ten days of data conclude that artificial hydrocarbon networks model helps to predict remote temperatures with root-mean square error of 2.7 °C in testing mode.}
}
@article{KOVACS201640,
title = {Intelligent control for energy-positive street lighting},
journal = {Energy},
volume = {114},
pages = {40-51},
year = {2016},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2016.07.156},
url = {https://www.sciencedirect.com/science/article/pii/S0360544216310891},
author = {András Kovács and Roland Bátai and Balázs Csanád Csáji and Péter Dudás and Borbála Háy and Gianfranco Pedone and Tibor Révész and József Váncza},
keywords = {Street lighting, Renewable energy, Energy management, Smart cities},
abstract = {The paper investigates the application of solar energy in public lighting for realizing a street lighting sub-grid with positive yearly energy balance. The focus is given to the central controller, which ensures the adaptive behavior of the overall system and provides smart city services to the end users via its web-based user interface. A functionality of the controller of special interest is the optimization of the energy management of the system, i.e., determining when to sell and buy electricity to/from the grid, in order to minimize the cost of electricity (or to maximize the profit) subject to a given, time-of-use variable energy tariff. This requires precise forecasts of the energy produced and consumed, as well as appropriate robust optimization techniques that guarantee that the system bridges potential power outages of moderate duration in island mode. The algorithms implemented in the controller are presented in detail, together with the evaluation of the operation of a deployed physical prototype with 191 luminaries over a horizon of six months, based on the monitoring data collected by the proposed controller.}
}
@article{FOUNTAIN2021101645,
title = {The moon, the ghetto and artificial intelligence: Reducing systemic racism in computational algorithms},
journal = {Government Information Quarterly},
pages = {101645},
year = {2021},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2021.101645},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X21000812},
author = {Jane E. Fountain},
keywords = {Digital government, Public management, Systemic racism, Discrimination, Artificial intelligence, Machine learning, Computational algorithms},
abstract = {Computational algorithms and automated decision making systems that include them offer potential to improve public policy and organizations. But computational algorithms based on biased data encode those biases into algorithms, models and their outputs. Systemic racism is institutionalized bias with respect to race, ethnicity and related attributes. Such bias is located in data that encode the results and outputs of decisions that have been discriminatory, in procedures and processes that may intentionally or unintentionally disadvantage people based on race, and in policies that may discriminate by race. Computational algorithms may exacerbate systemic racism if they are not designed, developed, and used–that is, enacted–with attention to identifying and remedying bias specific to race. Advancing social equity in digital governance requires systematic, ongoing efforts to assure that automated decision making systems, and their enactment in complex public organizational arrangements, are free from bias.}
}
@article{CORREIA2021103310,
title = {Last-mile-as-a-service (LMaaS): An innovative concept for the disruption of the supply chain},
journal = {Sustainable Cities and Society},
volume = {75},
pages = {103310},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103310},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721005862},
author = {Diogo Correia and Leonor Teixeira and João Lourenço Marques},
keywords = {Last-mile-as-a-service, Industry 4.0, Smart cities, Smart logistics, Smart manufacturing, Smart supply chain},
abstract = {Recent events such as Covid-19 vaccine distribution issues and the blockage of the Ever Given ship in the Suez Canal raised concerns about how fragile the traditional supply chain is. Last-mile personalized fulfillment can have a catalyst role in the proliferation of the Industry 4.0. This growing trend will reduce standard production, bringing manufacturing closer to the client and, ultimately, boiling down the supply chain to the last mile. However, the literature is not clear about the breakdown of the supply chain to enhance cities’ sustainability and reducing the number of transports and circulating vehicles. Stemming from an empirical study to simulate the existing gap in the market and the development of a case study through structured interviews with privileged interlocutors complemented by the document analysis, this paper highlights how the integration of local stakeholders can efficiently enhance a personalized service based on dynamic collaborations to set up the supply chain, by introducing the Last-Mile-as-a-Service (LMaaS) concept. This concept relies on a revenue-sharing framework based on an open marketplace composed by last-mile manufacturing, transport, and storage assets and stakeholders to disrupt the supply chain, enabling any company to provide personalized products in almost real-time to any location.}
}
@article{HOSEINZADEH2020101518,
title = {Quality of location-based crowdsourced speed data on surface streets: A case study of Waze and Bluetooth speed data in Sevierville, TN},
journal = {Computers, Environment and Urban Systems},
volume = {83},
pages = {101518},
year = {2020},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2020.101518},
url = {https://www.sciencedirect.com/science/article/pii/S0198971520302519},
author = {Nima Hoseinzadeh and Yuandong Liu and Lee D. Han and Candace Brakewood and Amin Mohammadnazar},
keywords = {Location-based data, Crowdsourced data, Waze, Bluetooth, Big data, Smart cities, Surface streets},
abstract = {Obtaining accurate speed and travel time information is a challenge for researchers, geographers, and transportation agencies. In the past, traffic data were usually acquired and disseminated by government agencies through fixed-location sensors. High costs, infrastructure demands, and low coverage levels of these sensor devices require agencies and researchers to look beyond the traditional approaches. With the emergence of smartphones and navigation apps, location-based and crowdsourced Big Data are receiving increased attention. In this regard, location-based big data (LocBigData) collected from probe vehicles and road users can be used to provide speed and travel time information in different locations. Examining the quality of crowdsourced data is essential for researchers and agencies before using them. This study assessed the quality of Waze speed data from surface streets and conducted a case study in Sevierville, Tennessee. Typically, examining the quality of these data in surface streets and arterials is more challenging than freeways data. This research used Bluetooth speed data as the ground truth, which is independent of Waze data. In this study, three steps of methodology were used. In the first step, Waze speed data was compared to Bluetooth data in terms of accuracy, mean difference, and distribution similarity. In the second step, a k-means algorithm was used to categorize Waze data quality, and a multinomial logistics regression model was performed to explore the significant factors that impact data quality. Finally, in the third step, machine learning techniques were conducted to predict the data quality in different conditions. The result of the comparison showed a similar pattern and a slight difference between datasets, which verified the quality of Waze speed data. The statistical model indicates that that Waze speed data are more accurate in peak hours than in night hours. Also, the traffic speed, traffic volume, and segment length have a significant association on the accuracy of Waze data on surface streets. Finally, the result of machine learning prediction showed that a KNN method performed the highest prediction accuracy of 84.5% and 82.9% of the time for training and test datasets, respectively. Overall, the study results suggest that Waze speed data is a promising data source for surface streets.}
}
@article{ALI2021102355,
title = {Integration of blockchain and federated learning for Internet of Things: Recent advances and future challenges},
journal = {Computers & Security},
volume = {108},
pages = {102355},
year = {2021},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2021.102355},
url = {https://www.sciencedirect.com/science/article/pii/S0167404821001796},
author = {Mansoor Ali and Hadis Karimipour and Muhammad Tariq},
keywords = {Federated learning, The Internet of Things, BLockchains, Privacy, Dispersed federated learning},
abstract = {The role of the Internet of Things (IoT) in the revolutionized society cannot be overlooked. The IoT can leverage advanced machine learning (ML) algorithms for its applications. However, given the fact of massive data, which is stored at a central cloud server, adopting centralized machine learning algorithms is not a viable option due to immense computation cost and privacy leakage issues. Given such conditions, blockchain can be leveraged to enhance the privacy of IoT networks by making them decentralized without any central authority. Nevertheless, the sensitive and massive data that is stored in distributive fashion, leveraged it for application purpose, is still a challenging task. To overcome this challenging task, federated learning (FL), which is a new breed of ML is the most promising solution that brings learning to the end devices without sharing the private data to the central server. In the FL mechanism, the central server act as an orchestrator to start the FL learning process, and only model parameters' updates are shared between end devices and the central orchestrator. Although FL can provide better privacy and data management, it is still in the development phase and has not been adopted by various communities due to its unknown privacy issues. In this paper first, we present the notion of blockchain and its application in IoT systems. Then we describe the privacy issues related to the implementation of blockchain in IoT and present privacy preservation techniques to cope with the privacy issues. Second, we introduce the FL application in IoT systems, devise a taxonomy, and present privacy threats in FL. Afterward, we present IoT-based use cases on envisioned dispersed federated learning and introduce blockchain-based traceability functions to improve privacy. Finally, open research gaps are addressed for future work.}
}
@article{ABOUBAKAR2021,
title = {A review of IoT network management: Current status and perspectives},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821000707},
author = {Moussa Aboubakar and Mounir Kellil and Pierre Roux},
keywords = {IoT, Network management, Device management, IoT network management protocols, IoT networks management frameworks},
abstract = {During this last past decade, the Internet of Things (IoT) has gained much attention because it encompass intelligent devices such as smart sensors and actuators, which enable a wide range of applications that improve our daily life (e.g. smart agriculture). However, due to the presence of an important number of heterogeneous and resources constrained devices (in terms of memory, CPU and bandwidth) communicating over error-prone and lossy radio channels and often deployed in hostile environments (e.g. war zone), IoT networks are experiencing various network performance problems (e.g. excessive energy consumption resulting from network device failure). In this context, an efficient management of IoT networks is needed in order to ensure good network performances. This has fueled the development of different protocols and frameworks for management of IoT networks. In this paper we present a comprehensive study of representative works on IoT network management. The paper analyzes existing solutions for IoT low power networks management and presents a taxonomy of those solutions. Moreover, this paper also compares existing research proposals on management of IoT low power networks based on different requirements. At the end, this survey identifies remaining challenges for an efficient mangement of IoT low power networks.}
}
@article{VIJAI2018258,
title = {Performance comparison of techniques for water demand forecasting},
journal = {Procedia Computer Science},
volume = {143},
pages = {258-266},
year = {2018},
note = {8th International Conference on Advances in Computing & Communications (ICACC-2018)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.10.394},
url = {https://www.sciencedirect.com/science/article/pii/S187705091832091X},
author = {Praveen Vijai and P {Bagavathi Sivakumar}},
keywords = {Smart Water Management, Forecasting, Artificial Neural Network, Deep Neural Network, Extreme Learning Machines, Least Square Support Vector Machine, Gaussian process regression, Random Forest, Multiple Regression},
abstract = {There is an ever growing demand of water due to the factors like global warming, urbanization and population growth. The situation demands to use more efficient planning which can be attained by technological advancement like Internet of things and smart systems. The cost related to water management system can be optimized by using prediction. The future demand for water could be better modeled with forecasting techniques. A collection of techniques (Artificial Neural Network (ANN), Deep Neural Network (DNN), Extreme Learning Machines (ELM), Least Square Support Vector Machine (LSSVM), Gaussian process regression (GPR), Random Forest (RF), multiple regression have been applied to analyze the performance in water demand forecasting using the common evaluation criteria. The work is aimed at short term prediction using hourly and daily intervals. A good performance was obtained through the ANN model for all short term predictions.}
}
@article{YU2021135,
title = {Deep spatio-temporal graph convolutional network for traffic accident prediction},
journal = {Neurocomputing},
volume = {423},
pages = {135-147},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.09.043},
url = {https://www.sciencedirect.com/science/article/pii/S092523122031451X},
author = {Le Yu and Bowen Du and Xiao Hu and Leilei Sun and Liangzhe Han and Weifeng Lv},
keywords = {Traffic accident prediction, Spatio-temporal data, Graph convolutional network, Deep learning},
abstract = {Traffic accidents usually lead to severe human casualties and huge economic losses in real-world scenarios. Timely accurate prediction of traffic accidents has great potential to protect public safety and reduce economic losses. However, it is challenging to predict traffic accidents due to the complex causality of traffic accidents with multiple factors, including spatial correlations, temporal dynamic interactions and external influences in traffic-relevant heterogeneous data. To overcome the above issues, this paper proposes a novel Deep Spatio-Temporal Graph Convolutional Network, namely DSTGCN, to predict traffic accidents. The proposed model is composed of three components: the first component is the spatial learning layer which performs graph convolutional operations on spatial information to learn the correlations in space. The second component is the spatio-temporal learning layer which utilizes graph and standard convolutions to capture the dynamic variations in both spatial and temporal perspective. The third component is the embedding layer which aims to obtain meaningful and semantic representations of external information. To evaluate the proposed model, we collect large-scale real-world data, including accident records, citi-wide vehicle speeds, road networks, meteorological conditions, and Point-of-Interest distributions. Experimental results on real-world datasets demonstrate that DSTGCN outperforms both classical and state-of-the-art methods.}
}
@article{BABAR2019398,
title = {Urban data management system: Towards Big Data analytics for Internet of Things based smart urban environment using customized Hadoop},
journal = {Future Generation Computer Systems},
volume = {96},
pages = {398-409},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.02.035},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18321095},
author = {Muhammad Babar and Fahim Arif and Mian Ahmad Jan and Zhiyuan Tan and Fazlullah Khan},
keywords = {Big Data analytics, Smart city, Internet of Things, Hadoop},
abstract = {The unbroken amplification of a versatile urban setup is challenged by huge Big Data processing. Understanding the voluminous data generated in a smart urban environment for decision making is a challenging task. Big Data analytics is performed to obtain useful insights about the massive data. The existing conventional techniques are not suitable to get a useful insight due to the huge volume of data. Big Data analytics has attracted significant attention in the context of large-scale data computation and processing. This paper presents a Hadoop-based architecture to deal with Big Data loading and processing. The proposed architecture is composed of two different modules, i.e., Big Data loading and Big Data processing. The performance and efficiency of data loading is tested to propose a customized methodology for loading Big Data to a distributed and processing platform, i.e., Hadoop. To examine data ingestion into Hadoop, data loading is performed and compared repeatedly against different decisions. The experimental results are recorded for various attributes along with manual and traditional data loading to highlight the efficiency of our proposed solution. On the other hand, the processing is achieved using YARN cluster management framework with specific customization of dynamic scheduling. In addition, the effectiveness of our proposed solution regarding processing and computation is also highlighted and decorated in the context of throughput.}
}
@article{AGGARWAL201913,
title = {Blockchain for smart communities: Applications, challenges and opportunities},
journal = {Journal of Network and Computer Applications},
volume = {144},
pages = {13-48},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.06.018},
url = {https://www.sciencedirect.com/science/article/pii/S1084804519302231},
author = {Shubhani Aggarwal and Rajat Chaudhary and Gagangeet Singh Aujla and Neeraj Kumar and Kim-Kwang Raymond Choo and Albert Y. Zomaya},
keywords = {Blockchain, Communication infrastructure, Consensus mechanism, Distributed applications, Process models, Smart communities},
abstract = {Since the success of Bitcoin, there have been increased focus of studying the application of blockchain in a broad range of applications, such as in solutions facilitating identity privacy and transaction security using a decentralized architecture via different consensus mechanisms (e.g. proof-of-work) between different geo-located IoT devices/nodes in our increasingly digitalized society (e.g. smart city). In this paper, we survey the usage of blockchain technology for smart communities, focusing on key components of the blockchain applications. We also study the various process models used in the execution of secure transactions. Specifically, we present a detailed taxonomy on the applications, process models used, and communication infrastructure support needed to execute various applications.}
}
@article{KHAN2022101574,
title = {Performance evaluation of regression models for COVID-19: A statistical and predictive perspective},
journal = {Ain Shams Engineering Journal},
volume = {13},
number = {2},
pages = {101574},
year = {2022},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2021.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S2090447921003385},
author = {Mohammad Ayoub Khan and Rijwan Khan and Fahad Algarni and Indrajeet Kumar and Akshika Choudhary and Aditi Srivastava},
keywords = {COVID-19, Machine learning, Regression, Prediction, Non-linear},
abstract = {Research is very important in the pandemic situation of COVID-19 to deliver a speedy solution to this problem. COVID-19 has presented governments, corporations and ordinary citizens around the world with technology playing an essential role to tackle the crisis. Moderate and flexible innovation arrangements that can speed up progress towards giving critical well-being ability are proved hourly. Knowledge with the aid of creativity must be obtained, accepted and analysed in a short time frame. In this example, the machine learning model has a major role to play in predicting the number of next positive COVID-19 cases to come. For government departments to take effective and strengthened future COVID-19 planning and innovation. The ongoing global pandemic of COVID-19 has been non-linear and dynamic. Due to the especially perplexing nature of the COVID-19 episode and its diversity from country to country, this study recommends machine learning as a convincing means to demonstrate flare-up. In this linear regression, polynomial regression, ridge regression, polynomial ridgeregression, support vector regression models, the COVID-19 data set from multiple on-line tools have been evaluated. During the work process comprehensive experiments were performed and each test was evaluated with the parameters mean square error (MSE), medium absolute error (MAE), root mean square error (RMSE) and R2 score. This study also offers a path for future research using regression models based on machine learning. Precise validation and data analysis can contribute to strategies for healing and disease prevention at an early stage. A systematic comprehensive strategy is a new philosophy in which statistical data for government agencies and community can be forecast.}
}
@article{HALHOULMERABET2021110969,
title = {Intelligent building control systems for thermal comfort and energy-efficiency: A systematic review of artificial intelligence-assisted techniques},
journal = {Renewable and Sustainable Energy Reviews},
volume = {144},
pages = {110969},
year = {2021},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2021.110969},
url = {https://www.sciencedirect.com/science/article/pii/S1364032121002616},
author = {Ghezlane {Halhoul Merabet} and Mohamed Essaaidi and Mohamed {Ben Haddou} and Basheer Qolomany and Junaid Qadir and Muhammad Anan and Ala Al-Fuqaha and Mohamed Riduan Abid and Driss Benhaddou},
keywords = {Buildings, Occupants, Control, Thermal comfort, Energy saving, Energy efficiency, Artificial intelligence, Machine learning, Heating ventilation and air-conditioning systems, Systematic literature review},
abstract = {Building operations represent a significant percentage of the total primary energy consumed in most countries due to the proliferation of Heating, Ventilation and Air-Conditioning (HVAC) installations in response to the growing demand for improved thermal comfort. Reducing the associated energy consumption while maintaining comfortable conditions in buildings are conflicting objectives and represent a typical optimization problem that requires intelligent system design. Over the last decade, different methodologies based on the Artificial Intelligence (AI) techniques have been deployed to find the sweet spot between energy use in HVAC systems and suitable indoor comfort levels to the occupants. This paper performs a comprehensive and an in-depth systematic review of AI-based techniques used for building control systems by assessing the outputs of these techniques, and their implementations in the reviewed works, as well as investigating their abilities to improve the energy-efficiency, while maintaining thermal comfort conditions. This enables a holistic view of (1) the complexities of delivering thermal comfort to users inside buildings in an energy-efficient way, and (2) the associated bibliographic material to assist researchers and experts in the field in tackling such a challenge. Among the 20 AI tools developed for both energy consumption and comfort control, functions such as identification and recognition patterns, optimization, predictive control. Based on the findings of this work, the application of AI technology in building control is a promising area of research and still an ongoing, i.e., the performance of AI-based control is not yet completely satisfactory. This is mainly due in part to the fact that these algorithms usually need a large amount of high-quality real-world data, which is lacking in the building or, more precisely, the energy sector. Based on the current study, from 1993 to 2020, the application of AI techniques and personalized comfort models has enabled energy savings on average between 21.81 and 44.36%, and comfort improvement on average between 21.67 and 85.77%. Finally, this paper discusses the challenges faced in the use of AI for energy productivity and comfort improvement, and opens main future directions in relation with AI-based building control systems for human comfort and energy-efficiency management.}
}
@article{LU2019398,
title = {A real-time object detection algorithm for video},
journal = {Computers & Electrical Engineering},
volume = {77},
pages = {398-408},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618319682},
author = {Shengyu Lu and Beizhan Wang and Hongji Wang and Lihao Chen and Ma Linjian and Xiaoyan Zhang},
keywords = {Object detection, GoogleNet, YOLO, Real-time, Video},
abstract = {Deep learning technology has been widely used in object detection. Although the deep learning technology greatly improves the accuracy of object detection, we also have the challenge of a high computational time. You Only Look Once (YOLO) is a network for object detection in images. In this paper, we propose a real-time object detection algorithm for videos based on the YOLO network. We eliminate the influence of the image background by image preprocessing, and then we train the Fast YOLO model for object detection to obtain the object information. Based on the Google Inception Net (GoogLeNet) architecture, we improve the YOLO network by using a small convolution operation to replace the original convolution operation, which can reduce the number of parameters and greatly shorten the time for object detection. Our Fast YOLO algorithm can be applied to real-time object detection in video.}
}
@article{SARAVANAN2021,
title = {IoT based improved air quality index prediction using hybrid FA-ANN-ARMA model},
journal = {Materials Today: Proceedings},
year = {2021},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.10.474},
url = {https://www.sciencedirect.com/science/article/pii/S2214785321069819},
author = {D. Saravanan and K. Santhosh Kumar},
keywords = {Air Quality Index (AQI), Internet of Things (IoT), Factor Analysis (FA), Artificial Neural Networks (ANN), Auto Regressive Moving Average (ARMA), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), Root Mean Square Error (RMSE)},
abstract = {Airpollutionhasbeenamajorissueinrecentdecadesowingtoincreasingindustrial,agricultural,andurbanwastedisposal.Thefastriseinpollutingmaterialintheatmosphereaffectstheclimaticcondition,alterstheatmosphere,andharmshumanhealth.ThenegativeconsequencesofairpollutionhavepromptedacademicstoanticipateandcalculatetheAirQualityIndex(AQI)usingfactorextractionandregressionmethods.Tosolvethisissue,thisstudyproposesanIoT-basedhybridmodelthatcombinesFactorAnalysis(FA),ArtificialNeuralNetworks(ANN),andAuto-RegressiveMovingAverage(ARMA)methods.TheFactorAnalysis(FA)modelisusedtoextractpollutingcomponents,followedbyArtificialNeuralNetworks(ANN)toregresstheprojectedrate.Thesuggestedhybridmodel'squantitativeanalysisshowsanincreaseinaccuracyfrom76.2percentto94.8percentwhilesimplifyingtheprocedure.ThesuggestedIoT-basedhybridmodelmaybeusedtoestimatetheproportionofpollutingcomponentsintheair.}
}
@article{BANGUI2021516,
title = {A Hybrid Data-driven Model for Intrusion Detection in VANET},
journal = {Procedia Computer Science},
volume = {184},
pages = {516-523},
year = {2021},
note = {The 12th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 4th International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.03.065},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921006967},
author = {Hind Bangui and Mouzhi Ge and Barbora Buhnova},
keywords = {VANET, Clustering, IDS, Coreset, Security, Data Approximation},
abstract = {Nowadays, VANET (Vehicular Ad-hoc NETwork) has gained increasing attention from many researchers with its various applications, such as enhancing traffic safety by collecting and disseminating traffic event information. This increased interest in VANET has necessitated greater scrutiny of machine learning (ML) methods used for improving the security capabilities of intrusion detection systems (IDSs), such as the need to solve computationally intensive ML problems due to the increased vehicular data. Therefore, in this paper, we propose a hybrid ML model to enhance the performance of IDSs by dealing with the explosive growth in computing power and the need for detecting malicious incidents timely. The proposed approach mainly uses the advantages of Random Forest to detect known network intrusions. Besides, there is a post-detection phase to detect possible novel intruders by using the advantages of coresets and clustering algorithms. Our approach is evaluated over a very recent IDS dataset named CICIDS2017. The preliminary results show that the proposed hybrid model can increase the utility of IDSs.}
}
@article{WAN2022108671,
title = {Privacy-preserving blockchain-enabled federated learning for B5G-Driven edge computing},
journal = {Computer Networks},
volume = {204},
pages = {108671},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108671},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621005454},
author = {Yichen Wan and Youyang Qu and Longxiang Gao and Yong Xiang},
keywords = {Blockchain, Federated learning, Differential privacy protection, Wasserstein generative adversarial nets},
abstract = {The arrival of the fifth-generation technology standard for broadband cellular networks (5G) and beyond 5G networks (B5G) rises the speed and robustness ceiling of communicating networks and thereby empowers the rapid popularization of edge computing. Consequently, B5G-Driven edge computing allows a growing volume of data to be collected from and transmitted among pervasive edge devices for big data analytics. The collected big data becomes the driving force of artificial intelligence (AI) by training high-quality machine learning (ML) models, which is followed by severe individual privacy leakage. Federated learning(FL) is then proposed to achieve privacy-preserving machine learning by avoiding the exchange of raw data. Unfortunately, several major issues remain outstanding. Centralized processing costs significant communication resources between cloud and edge while data falsification problems persist. In addition, the private data may be reconstructed by malicious participants by exploiting the context of model parameters in FL. To solve the identified problems, we propose to integrate blockchain-enabled FL with Wasserstein generative adversarial network (WGAN) enabled differential privacy (DP) to protect the model parameters of edge devices in B5G networks. Blockchain enables decentralized FL to reduce communication costs between cloud and edge while alleviating the data falsification issues, and it also provides an incentive mechanism to alleviate the data island issue in B5G-Driven edge computing. WGAN is used to generate controllable random noise complying with DP requirements, which is then injected to model parameters. WGAN-enabled DP is able to achieve an optimized trade-off between differential privacy protection and improved data utility of model parameters. Time delay analysis is conducted to show the efficiency of the proposed model. Extensive evaluation results from simulations demonstrate superior performances from aspects of convergence efficiency, accuracy, and data utility.}
}
@article{STAVINOVA2021333,
title = {Forecasting railway ticket dynamic price with Google Trends open data},
journal = {Procedia Computer Science},
volume = {193},
pages = {333-342},
year = {2021},
note = {10th International Young Scientists Conference in Computational Science, YSC2021, 28 June – 2 July, 2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.10.034},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921020755},
author = {Elizaveta Stavinova and Petr Chunaev and Klavdiya Bochenina},
keywords = {Dynamic pricing, Search query, Price forecasting, Railways},
abstract = {Dynamic pricing is a modern tool of railways, airline and bus transportation companies that aims at the revenue increase due to timely passenger demand accounting and successive adjusting ticket prices. From the passengers’ side, it is therefore useful in these dynamic settings to decide when it is better to buy the desired ticket in order to save money. It brings one to the problem of forecasting ticket dynamic prices. This problem is usually solved by using historical price data and the chosen train/airplane/bus departure features (e.g. the number of days before the departure and the departure week day) as predictor variables. The purpose of our study is to investigate whether search engine query open data can improve the ticket price forecast quality for statistical and artificial neural network-based models. Our experiments with the Spanish Renfe Railways dataset and certain train ticket-related search engine query data from Google Trends show that this is indeed so for railway ticket dynamic prices.}
}
@article{ZOU2022108402,
title = {AdaNFF: A new method for adaptive nonnegative multi-feature fusion to scene classification},
journal = {Pattern Recognition},
volume = {123},
pages = {108402},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.108402},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321005781},
author = {Zhiyuan Zou and Weibin Liu and Weiwei Xing},
keywords = {Scene classification, Adaptive feature fusion, Nonnegative matrix factorization, Feature fusion boosting},
abstract = {Scene classification is an important basis for many modern intelligent applications, however the performance of pattern recognition or deep learning-based methods are still not sufficient since complicated structure and context of scene images. In this paper, we propose a novel fusion framework of adaptive nonnegative feature fusion (AdaNFF) for scene classification. The AdaNFF integrates nonnegative matrix factorization, adaptive feature fusion and feature fusion boosting into an end-to-end process. Firstly, feature fusion is known as a general strategy to strengthen weak features, and we observe that pixel values and most hand-craft features of the scene image are naturally nonnegative. Therefore we are motivated to build a fusion method based on nonnegative matrix factorization, which can preserve features nonnegative properties and improve their representation performance. Secondly, with the results of fused single or multiple features fusion, we develop an adaptive feature fusion and boosting algorithm to improve the efficiency of image features. Finally, a normalized l2-norm classifier and a deep-learning like multilayer perceptron (MLP) classifier are trained to predict label of scene image. Under this framework, there are two versions of the proposed feature fusion method for nonnegative single-feature fusion and multi-feature fusion. All methods were validated on scene classification benchmarks. Experiment results suggest that the proposed methods can deal with multi-class scene problems and achieve remarkable classification performance.}
}
@article{AHMAD2021102783,
title = {Using the internet of things in smart energy systems and networks},
journal = {Sustainable Cities and Society},
volume = {68},
pages = {102783},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.102783},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721000755},
author = {Tanveer Ahmad and Dongdong Zhang},
keywords = {IoT, Smart energy systems, Businesses applications and networks, Energy policy, Energy planning and management},
abstract = {Private businesses and policymakers are accelerating the deployment and advancement of smart grid technology innovations that can support smart energy systems. Technological advances such as the Internet of Things (IoT) provide a broad range of energy sector applications, such as transmission and distribution, energy supply, power generation, renewable energy integration, load demand management, etc. We have conducted a comprehensive and critical IoT study on business applications and smart energy systems for this objective. Four main areas of smart energy systems have been chosen, including: i) the use of IoT in business; (ii) the use of IoT in smart energy applications; (iii) the use of IoT in data transmission networks; and (iv) the use of IoT in power generation and terminal hardware/devices. Each research area is further divided into different sub-areas; for example, IoT business includes energy operational policy, energy management and planning, energy management systems, business models, and customer services. Energy forecasting, state monitoring and estimation, anomaly detection, data mining and visualization are among the IoT applications in smart energy systems. Cloud computing, edge computing, and quantum computing are provided using IoT in data transmission networks. A variety of renewable sources, pricing, and load management strategies involve the use of IoT in energy generation. Many new solutions for smart energy systems are provided with critical thinking and clear vision, and key industries for IoT revenue generation and application development are described. This study aimed to provide a clear insight into IoT devices' recent developments in smart energy systems, supported by high-quality published literature. It is noted that in 2015, the IoT worldwide energy market exceeded USD 6.8 billion and is projected to reach USD 26.5 billion by 2023, with a compound annual growth rate of 15.5 % in 2016−23.}
}
@article{FERNANDEZARES201722,
title = {Wireless monitoring and tracking system for vehicles: A study case in an urban scenario},
journal = {Simulation Modelling Practice and Theory},
volume = {73},
pages = {22-42},
year = {2017},
note = {Smart Cities and Internet of Things},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2016.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X16302568},
author = {A.J. Fernández-Ares and A.M. Mora and S.M. Odeh and P. García-Sánchez and M.G. Arenas},
keywords = {Smart city, Smart Traffic, Urban traffic monitoring, Wireless monitoring systems, Traffic tracking systems, Traffic forecast, Traffic analysis},
abstract = {This paper describes the application of a Wireless Traffic Monitoring and Tracking system in the Spanish city of Granada, as an approach for addressing important tasks in the field of Smart Traffic. To this end, several nodes of the so-called MOBYWIT system have been deployed at important urban points. They collect real-time vehicles’ movement information based on Bluetooth signals detection. The gathered data have been processed in several ways, showing some of the applications that the system has, such as the composition of Origin/Destination matrices, the computation of accurate displacement times, or the estimation of real traffic in short terms by means of Time Series Forecast. The obtained results validate the system and proves its value as a tool for the urban traffic flow monitoring, analysis and prediction, which could be used as a part of an intelligent transportation system.}
}
@article{JI2022108332,
title = {An attention based dual learning approach for video captioning},
journal = {Applied Soft Computing},
volume = {117},
pages = {108332},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.108332},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621011200},
author = {Wanting Ji and Ruili Wang and Yan Tian and Xun Wang},
keywords = {Attention mechanism, Deep neural network, Dual learning, Encoder–decoder, Video captioning},
abstract = {Video captioning aims to generate sentences/captions to describe video contents. It is one of the key tasks in the field of multimedia processing. However, most of the current video captioning approaches utilize only the visual information of a video to generate captions. Recently, a new encoder–decoder–reconstructorarchitecture was developed for video captioning, which can capture the information in both raw videos and the generated captions through dual learning. Based on this architecture, this paper proposes a novel attention based dual learning approach (ADL) for video captioning. Specifically, ADL is composed of a caption generation module and a video reconstruction module. The caption generation module builds a translatable mapping between raw video frames and the generated video captions, i.e., using the visual features extracted from videos by an Inception-V4 network to produce video captions. Then the video reconstruction module reproduces raw video frames using the generated video captions, i.e., using the hidden states of the decoder in the caption generation module to reproduce/synthesize raw visual features. A multi-head attention mechanism is adopted to help the two modules focus on the most effective information in videos and captions, and a dual learning mechanism is adopted to fine-tune the performance of the two modules to generate final video captions. Therefore, ADL can minimize the semantic gap between raw videos and the generated captions by minimizing the differences between the reproduced and the raw videos, thereby improving the quality of the generated video captions. Experimental results demonstrate that ADL is superior to the state-of-the-art video captioning approaches on benchmark datasets.}
}
@article{JAMIL2022106573,
title = {Optimal smart contract for autonomous greenhouse environment based on IoT blockchain network in agriculture},
journal = {Computers and Electronics in Agriculture},
volume = {192},
pages = {106573},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106573},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921005901},
author = {Faisal Jamil and Muhammad Ibrahim and Israr Ullah and Suyeon Kim and Hyun Kook Kahng and Do-Hyeun Kim},
keywords = {Agriculture, Blockchain, Greenhouse, Smart contract, Internet of things},
abstract = {The Internet of Things (IoT) has been widely adopted in many smart applications such as smart cities, healthcare, smart farms, industry etc. In recent few years, the greenhouse industry has earned significant consideration from the agriculture community due to its ability to produce fresh agricultural products with immense growth and production rate. However, labour and energy consumption costs increase the production cost of the greenhouse by 40–50% approximately. Moreover, the security and authenticity of agriculture data, particularly for yield monitoring and analysis, is also a challenging issue in current greenhouse systems.The greenhouse require optimal parameter settings with controlled environment to produce increase food production. Therefore, slight advancement can bring remarkable improvements concerning the increase in production with reduced overall cost. In this work, we contributed blockchain enabled optimization approach for greenhouse system. The proposed approach works in three steps to provide optimal greenhouse environment that are; prediction, optimization, and finally controlling. Initially, the Kalman filter algorithm is employed for predicting the greenhouse sensor data. In next step, the optimal parameters are computed for the indoor greenhouse environment. Finally, the optimized parameters are utilized by the control module to operate and regulate the actuator’s state to meet the desired settings in the indoor environment. To evaluate the performance of our proposed greenhouse system, we have developed an emulation tool. The proposed system has been investigated and compared against baseline approach concerning production rate and energy consumption. The obtained results reveal that the proposed optimization approach has improved the energy consumption by 19% against the prediction based approach and 41% against the Baseline scheme. Furthermore, the proof-of-concept based on the Hyperledger Fabric network is implemented on the top of the proposed greenhouse platform. For experimental analysis, we have conducted a series of experiments using Hyperledger calliper concerning throughput, latency, and resource utilization. These results advocates the efficiency of the proposed optimal greenhouse system.}
}
@article{WOO2021120852,
title = {Understanding the long-term emergence of autonomous vehicles technologies},
journal = {Technological Forecasting and Social Change},
volume = {170},
pages = {120852},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.120852},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521002845},
author = {Seokkyun Woo and Jan Youtie and Ingrid Ott and Fenja Scheu},
keywords = {Autonomous vehicles, Emerging technologies, Technology emergence indicator, Word-embedding},
abstract = {Identifying emerging technologies has been of long-standing interest to many scholars and practitioners. Previous studies have introduced methods to capture the concept of emergence from bibliographic records, including the recently proposed Technology Emergence Indicator (Carley et al. 2018). This indicator method has shown to be applicable to various technological fields. However, the indicator uses a limited time window, which can overlook the potential long-term evolution of emerging technologies. Moreover, the existing method suffers from interpretability, because it can be difficult to understand the context in which identified emerging terms are used. In this paper, we propose an improved version of the Technology Emergence Indicator that addresses these issues. In doing so, we examine emerging topics within the field of autonomous vehicles technologies during the period of 1991-2018, guided by a proposition about the long-term diffusion of an emerging technology topic. The results show that different autonomous vehicle technology topics emerge during each of the three 10-year periods under analysis, including an initial period of understanding the surrounding environment and path planning, a second period marked by DARPA Grand Challenge motivated factors associated with the urban environment and communication technologies, and a third period relating to machine learning and object detection. This association with certain emerging technology topics in each decade is also characterized by different trajectories of continued or cyclical carryover across the decades. The results suggest a methodology that practitioners can use in examining research areas to understand which topics are likely to persist into the future.}
}
@article{DONASCIMENTO2017161,
title = {FIoT: An agent-based framework for self-adaptive and self-organizing applications based on the Internet of Things},
journal = {Information Sciences},
volume = {378},
pages = {161-176},
year = {2017},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2016.10.031},
url = {https://www.sciencedirect.com/science/article/pii/S0020025516313664},
author = {Nathalia Moraes {do Nascimento} and Carlos José Pereira {de Lucena}},
keywords = {Internet of things (IoT), Multi-agent system, Machine learning, Self-organizing, Self-adaptive, Quantified things},
abstract = {Billions of resources, such as cars, clothes, household appliances and even food are being connected to the Internet forming the Internet of Things (IoT). Subsets of these resources can work together to create new self-regulating IoT applications such as smart health, smart communities and smart homes. However, several challenging issues need to be addressed before this vision of applications based on IoT concepts becomes a reality. Because many IoT applications will be distributed over a large number of interacting devices, centralized control will not be possible and so open problems will need to be solved that relate to building locally operating self-organizing and self-adaptive systems. As an initial step in creating IoT applications with these features, this paper presents a Framework for IoT (FIoT). The approach is based on Multi-Agent Systems (MAS) and Machine Learning Techniques, such as neural networks and evolutionary algorithms. To illustrate the use of FIoT, the paper contains two different IoT applications: (i) Quantified Things and (ii) Smart traffic control. We show how flexible points of our framework are instantiated to generate these IoT application.}
}
@article{GAUTAM2022,
title = {Smart solution for leaf stress detection and classification a research pattern},
journal = {Materials Today: Proceedings},
year = {2022},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.12.524},
url = {https://www.sciencedirect.com/science/article/pii/S2214785321082869},
author = {Vinay Gautam and Jyoti Rani},
keywords = {Internet of Things(IoT), Plant stress, Agriculture, Leaf stress},
abstract = {IoT is a global infrastructure that is used successfully in different sectors such as health care, smart agriculture, smart city, and industrial production, etc. This paper illustrates the smart solutions for plant leaf stress detection and classification. Firstly, the paper explores different types of IoT frameworks in different sectors and laid down their pros and cons. This paper explains different types of frameworks such as cloud-based and object-based IoT frameworks. Secondly, the paper explores different type’s stress which affects agriculture. Here this paper categorizes leaf stress into two parts as Biotic and Abiotic leaf stress. Later on, it describes how both can be linked to getting the proper information to identify stress in crops using leaf images. Also, laid-down analysis to detect stress in crops by visualizing plant leaves. This framework visualizes images continuously and predicts the reason for stress in the plant.}
}
@article{LI2020106449,
title = {A transfer learning method using speech data as the source domain for micro-Doppler classification tasks},
journal = {Knowledge-Based Systems},
volume = {209},
pages = {106449},
year = {2020},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2020.106449},
url = {https://www.sciencedirect.com/science/article/pii/S0950705120305785},
author = {Yuxin Li and Kunling He and Danlei Xu and Dingli Luo},
keywords = {Micro-Doppler, Transfer learning, Deep learning},
abstract = {In recent years, micro-Doppler target classification technology has been widely used for radar target recognition. However, due to the lack of sufficient data, it has become a challenge to train a model with excellent performance using the transfer learning method. Most of the existing transfer learning methods for micro-Doppler tasks use optical image data or simulation data as the source domain, and the use of fine-tuning as the transfer method makes it difficult to obtain good results. This paper proposes a transfer learning method using speech data as the source domain for micro-Doppler classification tasks. The proposed method uses speech data as the source domain and improves the accuracy of micro-Doppler classification through TCA and deep learning models used jointly. After experimental verification, the proposed method can use the 2.8 M parameters to improve accuracy by more than 5% compared with common methods in the case of a small number of frames, and the proposed method achieves better results with a small number of points.}
}
@article{STOKKENES2021186,
title = {Validation of a Predictive Fire Risk Indication Model using Cloud-based Weather Data Services},
journal = {Procedia Computer Science},
volume = {184},
pages = {186-193},
year = {2021},
note = {The 12th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 4th International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.03.029},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921006554},
author = {S. Stokkenes and R.D. Strand and L.M. Kristensen and T. Log},
keywords = {Climate related risks, Mitigating urban fire risk, Reducing vulnerability in cities, Smart city, cloud data services},
abstract = {The high and dense representation of wooden homes in Norway, combined with periods of dry and cold climate during the winter season resulting in very dry indoor conditions, have historically resulted in severe fires. Thus, it is important to have an accurate estimate of the current and near future fire risk to take proper planning precautions. Cloud computing services providing access to weather data in the form of measurements and forecasts combined with recent developments in fire risk modelling may enable smart and fine-grained fire risk predication services. The main contribution of this study is implementation and experimental validation of a predictive fire risk indication model, which exploits cloud-provided measurements from weather stations and weather forecasts to predict the current and future fire risk for wooden homes at a given geographical location. The basic idea of the model is to estimate the indoor climate using measured and forecasted outdoor climate for computing indoor wooden fuel moisture content and an estimated time to flashover as indication of the fire risk. The model implementation was integrated into a micro-service based software system and experimentally validated during one winter at selected geographical locations, relying on weather data provided by the RESTful API of the Norwegian Meteorological Institute. Additionally, weather data from several historical fires were considered to relate our predictions to known fire incidents. Our evaluation demonstrates the ability to provide trustworthy and accurate fire risk indications using a combination of weather data measurements and forecast data. Furthermore, our cloud-and micro-service based software system implementation is efficient with respect to data storage and computation time.}
}
@article{LEI2020100171,
title = {BIM based cyber-physical systems for intelligent disaster prevention},
journal = {Journal of Industrial Information Integration},
volume = {20},
pages = {100171},
year = {2020},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2020.100171},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X20300467},
author = {Ying Lei and Yongping Rao and Jiamin Wu and Chao-Hsiu Lin},
keywords = {Cyber-physical systems, Physical layer, Information layer, Communication layer, Intelligent disaster prevention and mitigation structure system, Building information model (BIM)},
abstract = {The cyber-physical systems (CPS) has emerged in the last decade and become one of the most cutting-edge research fields. CPS is a highly integrated system of communication, computing, and control strategies. Although CPS has been studied and applied in some fields such as intelligent transportation, intelligent manufacturing, intelligent buildings, and smart cities, there is a lack of research on CPS based intelligent disaster prevention and mitigation structural system. Because structural disaster prevention and reduction have their own characteristics, it is necessary to investigate CPS based technology and system for intelligent structural disaster prevention and reduction. In this paper, a preliminary study is conducted on cyber-physical based intelligent structural disaster prevention technologies and structural systems using the Building Information Model (BIM) platform. The proposed CPS consists of the multi-source data precision sensing and intelligent control technology in the physical subsystem/layer, reliable data transmission network in the communication subsystem/layer, and real-time identification algorithm of structural state and adaptive control strategy in the information subsystem/layer. Moreover, BIM platform and Internet of things (IoT) technology are adopted for constructing the cloud architecture of CPS to achieve a high degree of integration of monitoring, identification and control, and to improve the real-time and accurate intelligent monitoring of structural disaster prevention and mitigation.}
}
@article{LOPEZ2022351,
title = {Short-term wind speed forecasting over complex terrain using linear regression models and multivariable LSTM and NARX networks in the Andes Mountains, Ecuador},
journal = {Renewable Energy},
volume = {183},
pages = {351-368},
year = {2022},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2021.10.070},
url = {https://www.sciencedirect.com/science/article/pii/S0960148121015299},
author = {Germánico López and Pablo Arboleya},
keywords = {Ecuadorian Andes, Wind speed forecasting, NARX network, Dynamic Neural Networks, LSTM network},
abstract = {Wind speed forecasting systems over complex terrain at high altitude are very complex and conventional forecasting systems are unable to be applied due to wind variability. This study proposes an approach developed specifically for this study with application of linear regression models as baseline, and Recurrent Neural Networks (RNN): Long Short Term Memory (LSTM) network, and Dynamic Neural Networks (DNN): Nonlinear Autoregressive Exogenous (NARX) network to perform accurate wind speed forecasting in complex terrain in the Ecuadorian Andes to identify feasible places for wind energy applications. This work starts with the installation of two meteorological stations within of the mountainous zone of study to collect measured variables during 2018. Later on, the measured variables were evaluated by using statistical tools and Pearson Correlation Coefficient (PCC) to determine the input variables. Finally, the proposed forecasting models were trained, validated, and tested by using measured data. The DNN and RNN models were compared to determine the best performance through the statistical error forecast measurements as follows, Mean Absolute Percentage Error (MAPE), Mean Squared Error (MSE), and correlation coefficient. The comparison results of the proposed models indicated that the most precise values were for multivariable LSTM network, suggesting this model as a powerful approach to forecast wind speed over complex terrain, demonstrating the importance by using measured variables. Furthermore, the forecasted wind speed showed high values which are suitable for high wind power generation.}
}
@article{LIU2022102503,
title = {Privacy-Preserving cloud-Aided broad learning system},
journal = {Computers & Security},
volume = {112},
pages = {102503},
year = {2022},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2021.102503},
url = {https://www.sciencedirect.com/science/article/pii/S0167404821003278},
author = {Haiyang Liu and Hanlin Zhang and Li Guo and Jia Yu and Jie Lin},
keywords = {Broad learning system (BLS), Deep learning, Secure outsourcing computations, Privacy preserving},
abstract = {Broad Learning System (BLS) is a new deep learning model proposed recently, which shows its effectiveness in many fields, such as image recognition and fault detection. In this paper, we propose a secure, efficient, and verifiable outsourcing algorithm for BLS. This algorithm enables resource constrained devices to outsource BLS algorithm to untrusted cloud server to complete model training, which is of great significance for the promotion and application of BLS algorithm. Compared with the original BLS algorithm, this algorithm not only improves the efficiency of the algorithm on the client, but also ensures that the sensitive information of the client will not be leaked to the cloud server. In addition, in our algorithm, the client can verify the correctness of returned results with a probability of almost 1. Finally, we analyze the security and efficiency of our algorithm in theory and prove our algorithms feasibility through experiments.}
}
@article{CHEN202123,
title = {A mutual information based federated learning framework for edge computing networks},
journal = {Computer Communications},
volume = {176},
pages = {23-30},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421001973},
author = {Naiyue Chen and Yinglong Li and Xuejun Liu and Zhenjiang Zhang},
keywords = {Intelligent edge computing, Federated learning, Mutual information},
abstract = {With the application of artificial intelligence in all field of life, people pay more attention to user privacy and data security. Under the condition of protecting user privacy, the federated learning model has become a popular research technology to solve the data islands problems. The edge computing network can be applied to smart city, Internet of vehicles and so on. Federated learning is a framework in which multiple hosts jointly learn a machine learning model. Each work device maintains the local model of its local training dataset, while the master device maintains the global model by aggregating the local models from the work devices. However, it cannot ensure that every local work device is an honest user because of a phenomenon that the hosts has been operated by attacker interferes in the process of local model training. In this paper, we assume that malicious nodes upload unreal learning parameters in the federated learning framework, which the global model will have high error rate. We propose a federated learning parameter aggregating algorithm based on mutual information. We introduced the relevance of model training learning rate to determine the consistency of the training direction of the local and central models at coarse granularity. We aggregated the parameters of the models at fine granularity based on the correlation of the gradients based on the mutual information. The mutual information method is used to calculate the similarity of the gradient trend between the local training model and overall model. We set the trust weight of each work device to reduce the negative impact of malicious nodes. The evaluation results show that the classification accuracy of the MIFL model is improved as compared with the average federated learning without malicious node. Especially, in the case of existing malicious nodes, the proposed algorithm can defend against malicious node attacks and sustain the robustness of Federated learning.}
}
@article{RODRIGUEZLOPEZ2021583,
title = {Prediction of container filling for the selective waste collection in Algeciras (Spain)},
journal = {Transportation Research Procedia},
volume = {58},
pages = {583-590},
year = {2021},
note = {XIV Conference on Transport Engineering, CIT2021},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2021.11.077},
url = {https://www.sciencedirect.com/science/article/pii/S235214652100836X},
author = {Juana Carmen {Rodríguez López} and M. Inmaculada Rodríguez-García and Jose Antonio {Moscoso Lopez} and Juan Jesus {Ruíz Aguilar} and Jose Manuel {Alcántara Pérez} and Ignacio J. {Turias Domínguez}},
keywords = {prediction, waste collection, artificial neural networks},
abstract = {The aim of this study is to create an intelligent system that improves the efficiency of garbage collection, (cardboard waste, in this particular case). The number of cardboard containers to be collected each day will be determined based on a prediction made on the filled volume recorded in each container. It will be reflected in the cost and fuel savings, reducing emissions and contributing to environmental sustainability. These results will allow planning the sequence of waste removal, which means the optimal collection route considering restrictive parameters such as the type of truck, the location of containers, collection times by zones, and the availability of working staff. A filling prediction system is proposed based on real historical data provided by the current waste collection company in Algeciras (ARCGISA). To achieve this objective, an intelligent system is designed using predictive analytics and several methods based on machine learning, modelling the collection system as a classification model, comparing the results from a statistical point of view (using sensitivity, specificity, etc.). The results obtained with the best-tested method indicate an improvement average rate of 26% in sensitivity performance index and 67% in specificity performance index. Currently, waste collection is carried out without predictive analysis. The relevance of an efficient waste collection system is becoming increasingly important. Achieving optimal waste collection will result in improved service to citizens, cost savings for the administration, and significant environmental improvements.}
}
@article{LI2022104533,
title = {Multi-camera joint spatial self-organization for intelligent interconnection surveillance},
journal = {Engineering Applications of Artificial Intelligence},
volume = {107},
pages = {104533},
year = {2022},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104533},
url = {https://www.sciencedirect.com/science/article/pii/S095219762100381X},
author = {Congcong Li and Jing Li and Yuguang Xie and Jiayang Nie and Tao Yang and Zhaoyang Lu},
keywords = {Intelligent interconnection surveillance, Multi-camera spatial self-organization, Multi-camera joint optimization, Sequence complementary integration},
abstract = {The construction of smart city makes information interconnection play an increasingly important role in intelligent surveillance systems. Especially the interconnection among massive cameras is the key to realizing the evolution from current fragmented monitoring to interconnection surveillance. However, it remains a challenging problem in practical systems due to large sensor quantity, various camera types, and complex spatial layout. Aimed at this problem, this paper proposes a novel multi-camera joint spatial self-organization approach, which realizes interconnection surveillance by unifying cameras into one imaging space. Differing from existing back-end data association strategy, our method takes front-end data calibration as a breakthrough to relate surveillance data. Specifically, this paper first initials camera spatial parameter by sequence complementary feature integration. Through integrating complementarity and redundancy among sequence features, our method has robustness under scene dynamic changes and noise. Then, we propose a multi-camera joint optimization method based on common monitoring coverage correlation analysis to estimate a more accurate relative relationship. By leveraging the two strategies, the spatial relationship and visual data association across monitoring cameras are returned finally. Our system organizes all cameras into a unified imaging space by itself. Extensive experimental evaluations on an actual campus environment demonstrate our method achieves remarkable performance.}
}
@article{HAN2022121242,
title = {Towards a data science platform for improving SME collaboration through Industry 4.0 technologies},
journal = {Technological Forecasting and Social Change},
volume = {174},
pages = {121242},
year = {2022},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.121242},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521006752},
author = {Hui Han and Silvana Trimi},
keywords = {Industry 4.0, SME, Data science, Collaboration, Trust, Cloud computing},
abstract = {Industry 4.0 (I4.0) is about realizing digital transformation by linking machines to plants, fleets, and humans through sensors and control elements in order to create smart networks, smart factories, smart manufacturing, and smart value chains. By leveraging I4.0 technologies, a small and medium enterprise (SME) can increase its organizational agility, adaptability, and resilience to cope with today's competitive environment by becoming a valuable and innovative partner in the power dynamics with its large buyer counterparts. However, SMEs face technology, trust, and big data challenges when they adopt I4.0 technologies. This study provides new solutions for SMEs to overcome these three challenges in implementing I4.0. Specifically, the paper proposes the following: (1) a roadmap for the application of I4.0 technologies to enhance the collaboration capabilities of SMEs; (2) a structure for I4.0 standardization to develop and sustain trust among partners; and (3) an improved data science platform for systematizing big data to extract critical information for collaboration solutions for SMEs. Additionally, the solutions are evaluated based on an application case of a Greek SME, demonstrating their potentials for practical implementation.}
}
@article{ZHANG2020107556,
title = {Towards artificial intelligence enabled 6G: State of the art, challenges, and opportunities},
journal = {Computer Networks},
volume = {183},
pages = {107556},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107556},
url = {https://www.sciencedirect.com/science/article/pii/S138912862031207X},
author = {Shunliang Zhang and Dali Zhu},
keywords = {6G, Artificial intelligence, Radio technology, Traffic control, Management and orchestration, Network security, Network optimization, Network architecture},
abstract = {6G is expected to support the unprecedented Internet of everything scenarios with extremely diverse and challenging requirements. To fulfill such diverse requirements efficiently, 6G is envisioned to be space-aerial-terrestrial-ocean integrated three-dimension networks with different types of slices enabled by new technologies and paradigms to make the system more intelligent and flexible. As 6G networks are increasingly complex, heterogeneous and dynamic, it is very challenging to achieve efficient resource utilization, seamless user experience, automatic management and orchestration. With the advancement of big data processing technology, computing power and the availability of rich data, it is natural to tackle complex 6G network issues by leveraging artificial intelligence (AI). In this paper, we make a comprehensive survey about AI-empowered networks evolving towards 6G. We first present the vision of AI-enabled 6G system, the driving forces of introducing AI into 6G and the state of the art in machine learning. Then applying machine learning techniques to major 6G network issues including advanced radio interface, intelligent traffic control, security protection, management and orchestration, and network optimization is extensively discussed. Moreover, the latest progress of major standardization initiatives and industry research programs on applying machine learning to mobile networks evolving towards 6G are reviewed. Finally, we identify important open issues to inspire further studies towards an intelligent, efficient and secure 6G system.}
}
@article{LI2021100669,
title = {Design and operation of hybrid renewable energy systems: current status and future perspectives},
journal = {Current Opinion in Chemical Engineering},
volume = {31},
pages = {100669},
year = {2021},
issn = {2211-3398},
doi = {https://doi.org/10.1016/j.coche.2021.100669},
url = {https://www.sciencedirect.com/science/article/pii/S2211339821000010},
author = {Lanyu Li and Xiaonan Wang},
abstract = {Hybrid renewable energy systems, as the combination of different energy systems, provide a promising way to harvest maximum renewable energy. In the past decade, it has been a popular and rising topic in the research field. In this paper, the emerging application as well as the recent development in the design and operation of hybrid renewable energy systems are reviewed. The remaining challenges and future perspectives in the field are also discussed.}
}
@article{CHEN2021317,
title = {Towards asynchronous federated learning for heterogeneous edge-powered internet of things},
journal = {Digital Communications and Networks},
volume = {7},
number = {3},
pages = {317-326},
year = {2021},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2021.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2352864821000195},
author = {Zheyi Chen and Weixian Liao and Kun Hua and Chao Lu and Wei Yu},
keywords = {Asynchronous federated learning, Internet of Things (IoT), Mobile edge computing},
abstract = {The advancement of the Internet of Things (IoT) brings new opportunities for collecting real-time data and deploying machine learning models. Nonetheless, an individual IoT device may not have adequate computing resources to train and deploy an entire learning model. At the same time, transmitting continuous real-time data to a central server with high computing resource incurs enormous communication costs and raises issues in data security and privacy. Federated learning, a distributed machine learning framework, is a promising solution to train machine learning models with resource-limited devices and edge servers. Yet, the majority of existing works assume an impractically synchronous parameter update manner with homogeneous IoT nodes under stable communication connections. In this paper, we develop an asynchronous federated learning scheme to improve training efficiency for heterogeneous IoT devices under unstable communication network. Particularly, we formulate an asynchronous federated learning model and develop a lightweight node selection algorithm to carry out learning tasks effectively. The proposed algorithm iteratively selects heterogeneous IoT nodes to participate in the global learning aggregation while considering their local computing resource and communication condition. Extensive experimental results demonstrate that our proposed asynchronous federated learning scheme outperforms the state-of-the-art schemes in various settings on independent and identically distributed (i.i.d.) and non-i.i.d. data distribution.}
}
@article{OLIVA2021129768,
title = {Next-generation of instrumental odour monitoring system (IOMS) for the gaseous emissions control in complex industrial plants},
journal = {Chemosphere},
volume = {271},
pages = {129768},
year = {2021},
issn = {0045-6535},
doi = {https://doi.org/10.1016/j.chemosphere.2021.129768},
url = {https://www.sciencedirect.com/science/article/pii/S004565352100237X},
author = {G. Oliva and T. Zarra and G. Pittoni and V. Senatore and M.G. Galang and M. Castellani and V. Belgiorno and V. Naddeo},
keywords = {Environmental odour, Odour classification, Smart city, Training procedure, Validation procedure},
abstract = {Odour emissions from complex industrial plants may cause potential impacts on the surrounding areas. Consequently, the validation of effective tools for the control of the associated environmental pressures, without hindering economic growth, is strongly needed. Nowadays, senso-instrumental methods by using Instrumental Odour Emissions Systems (IOMSs) is among the most attractive tool for the continuous monitoring of environmental odours, allowing the possibility of obtaining real-time information to support the decision-making process and proactive approach. The systems complexity and scarcity of real data limited their wider full-scale employment. The study presents an advanced prototype of IOMS for the continuous classification and quantification of the odours emitted in ambient air by complex industrial plants, to continuously control the plants emissions with backwards approach. The IOMS device was designed and optimized and included the system for the automatic control of the conditions inside the measurement chamber. The designed operational procedures were presented and discussed. Results highlighted the influence of temperature and air flow rate for the measurement repeatability. Accurate prediction model was created and optimized and resulted able to distinguish 3 different industrial odour sources with accuracy approximately equal to 96%. The models were optimized thanks to the software features, which allowed to automatically apply the designed statistical procedures on the identified dataset with different pre-processing approach. The usefulness of having a fully-developed and user-friendly flexible system that allowed to select and automatically compare different settings options, including the different feature extraction methods, was demonstrated in order to identify the best prediction model.}
}
@article{SEIDITA2016185,
title = {A Biologically Inspired Representation of the Intelligence of a University Campus},
journal = {Procedia Computer Science},
volume = {88},
pages = {185-190},
year = {2016},
note = {7th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2016, held July 16 to July 19, 2016 in New York City, NY, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.423},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916316799},
author = {Valeria Seidita and Antonio Chella and Maurizio Carta},
keywords = {Smart cities, Brain representation},
abstract = {Intelligence or smartness in an urban environment implies several factors directed to improve quality of life and efficiency. It is important to note that in this context the inclusion of citizens and their devices is a key factor for reaching smartness. Data from mobile devices are increasingly used in everyday activities and have to be considered a useful means for handling and analyzing knowledge and communications. This paper shows how to represent important data when dealing with smartness by creating an analogy between the representation of human brain areas, activated when specific tasks are performed, and groups of students when behaviors or needs arise. The brain traffic concepts have been used for representing data and information exchanged in the University of Palermo campus.}
}
@article{CANOVAS2020102498,
title = {A robust multimedia traffic SDN-Based management system using patterns and models of QoE estimation with BRNN},
journal = {Journal of Network and Computer Applications},
volume = {150},
pages = {102498},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.102498},
url = {https://www.sciencedirect.com/science/article/pii/S1084804519303583},
author = {Alejandro Canovas and Albert Rego and Oscar Romero and Jaime Lloret},
keywords = {Software defined network (SDN), Machine learning, QoE, Traffic multimedia pattern},
abstract = {Nowadays, network infrastructures such as Software Defined Networks (SDN) achieve a huge computational power. This allows to add a high processing on the network nodes. In this paper, a multimedia traffic management system is presented. This system is based on estimation models of Quality of Experience (QoE) and also on the traffic patterns classification. In order to achieve this, a QoE estimation method has been modeled. This method allows for classifying the multimedia traffic from multimedia transmission patterns. In order to do this, the SDN controller gathers statistics from the network. The patterns used have been defined from a lineal combination of objective QoE measurements. The model has been defined by Bayesian regularized neural networks (BRNN). From this model, the system is able to classify several kind of traffic according to the quality perceived by the users. Then, a model has been developed to determine which video characteristics need to be changed to provide the user with the best possible quality in the critical moments of the transmission. The choice of these characteristics is based on the quality of service (QoS) parameters, such as delay, jitter, loss rate and bandwidth. Moreover, it is also based on subpatterns defined by clusters from the dataset and which represents network and video characteristics. When a critical network situation is given, the model selects, by using network parameters as entries, the subpattern with the most similar network condition. The minimum Euclidean distance between these entries and the network parameters of the subpatters is calculated to perform this selection. Both models work together to build a reliable multimedia traffic management system perfectly integrated into current network infrastructures, which is able to classify the traffic and solve critical situations changing the video characteristics, by using the SDN architecture.}
}
@article{RAMAKRISHNA2020101760,
title = {Dynamic-weighted simplex strategy for learning enabled cyber physical systems},
journal = {Journal of Systems Architecture},
volume = {111},
pages = {101760},
year = {2020},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2020.101760},
url = {https://www.sciencedirect.com/science/article/pii/S1383762120300540},
author = {Shreyas Ramakrishna and Charles Harstell and Matthew P. Burruss and Gabor Karsai and Abhishek Dubey},
keywords = {Convolutional Neural Networks, Learning Enabled Components, Reinforcement Learning, Simplex Architecture},
abstract = {Cyber Physical Systems (CPS) have increasingly started using Learning Enabled Components (LECs) for performing perception-based control tasks. The simple design approach, and their capability to continuously learn has led to their widespread use in different autonomous applications. Despite their simplicity and impressive capabilities, these components are difficult to assure, which makes their use challenging. The problem of assuring CPS with untrusted controllers has been achieved using the Simplex Architecture. This architecture integrates the system to be assured with a safe controller and provides a decision logic to switch between the decisions of these controllers. However, the key challenges in using the Simplex Architecture are: (1) designing an effective decision logic, and (2) sudden transitions between controller decisions lead to inconsistent system performance. To address these research challenges, we make three key contributions: (1) dynamic-weighted simplex strategy – we introduce “weighted simplex strategy” as the weighted ensemble extension of the classical Simplex Architecture. We then provide a reinforcement learning based mechanism to find dynamic ensemble weights, (2) middleware framework – we design a framework that allows the use of the dynamic-weighted simplex strategy, and provides a resource manager to monitor the computational resources, and (3) hardware testbed – we design a remote-controlled car testbed called DeepNNCar to test and demonstrate the aforementioned key concepts. Using the hardware, we show that the dynamic-weighted simplex strategy has 60% fewer out-of-track occurrences (soft constraint violations), while demonstrating higher optimized speed (performance) of 0.4 m/s during indoor driving than the original LEC driven system.}
}
@article{CHEN2019106961,
title = {Global-connected network with generalized ReLU activation},
journal = {Pattern Recognition},
volume = {96},
pages = {106961},
year = {2019},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2019.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0031320319302584},
author = {Zhi Chen and Pin-Han Ho},
keywords = {CNN, Computer vision, Deep learning, Activation},
abstract = {Recent Progress has shown that exploitation of hidden layer neurons in convolutional neural networks (CNN) incorporating with a carefully designed activation function can yield better classification results in the field of computer vision. The paper firstly introduces a novel deep learning (DL) architecture aiming to mitigate the gradient-vanishing problem, in which the earlier hidden layer neurons could be directly connected with the last hidden layer and fed into the softmax layer for classification. We then design a generalized linear rectifier function as the activation function that can approximate arbitrary complex functions via training of the parameters. We will show that our design can achieve similar performance in a number of object recognition and video action benchmark tasks, such as MNIST, CIFAR-10/100, SVHN, Fashion-MNIST, STL-10, and UCF YoutTube Action Video datasets, under significantly less number of parameters and shallower network infrastructure, which is not only promising in training in terms of computation burden and memory usage, but is also applicable to low-computation, low-memory mobile scenarios for inference.}
}
@article{DAS2022101540,
title = {Building of an edge enabled drone network ecosystem for bird species identification},
journal = {Ecological Informatics},
volume = {68},
pages = {101540},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101540},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121003319},
author = {Nabanita Das and Neelamadhab Padhy and Nilanjan Dey and Amartya Mukherjee and Ananjan Maiti},
keywords = {Edge computing, Random forest, Songbird, Drone network, Bioacoustics monitoring},
abstract = {The behavioral study of animals and especially avians, and the way of their immunization are highly needed to understand the environment in a better way. Automatically classifying bird species by their vocalization is of crucial relevance for the research of ornithologists and ecologists. It was observed that impartial survey information for songbird species is inherently challenging due to observer biases, habitat insurance biases, and logistical constraints. To get to the bottom of all the challenges, ecologists are trying a machine that let them decide the distribution and density of species, which are essential baseline facts for conservation. For this reason, the utilization of a network of unmanned aerial vehicles is introduced for monitoring and capturing the data of a wide variety of terrestrial and aquatic species. In this study, an edge-enabled drone network has been engineered that amalgamated with the mobile edge computing framework within the drone network and the machine learning models to predict the bird species. The experiment has been performed in two geographic regions. The research reported 98.2% and 96.9% accuracy of random forest classifier with the, 0.07 and 0.4 log loss by utilizing 1.4% of CPU and 329.14 Mb of buffer memory of the edge device with an execution time of 45 milliseconds.}
}
@article{AHMAD2017552,
title = {Developments in xEVs charging infrastructure and energy management system for smart microgrids including xEVs},
journal = {Sustainable Cities and Society},
volume = {35},
pages = {552-564},
year = {2017},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2017.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S2210670717310557},
author = {Furkan Ahmad and Mohammad Saad Alam and Mohammad Asaad},
keywords = {Electric vehicles, Hybrid electric vehicles, Microgrid, Energy storage system (ESS), Charging levels},
abstract = {The swiftly growing structure of urbanization and smart cities facilitating the transportation era at peak. Thus, the rising pattern of conventional automobiles leading to the high contribution of greenhouse gas (GHG) emission. To mitigate the hazardous profile of GHG emissions, the electric vehicles (xEVs) as the part of smart cities, are gaining immense consideration. However, the unscheduled EVs connectivity with conventional grid system leading unreliable and interrupted power supply, which may lead to the grid failure. In such state of affairs (i.e. GHG emission and rising power demand), the smart microgrids including Renewable Energy Sources (RESs) based charging infrastructure are becoming the most viable paradigm. In this paper, two most emerging technologies belonging to smart cities i.e. xEVs and RESs based smart Microgrid has been covered. The xEVs part of the presented manuscript discusses the detailed study of rising advancement in xEVs charging infrastructure, enhancement in international standards for proper xEVs deployment, and state of art in the xEVs application such as the vehicle to grid (V2G) and vehicle to home (V2H). The second part of the presented work elaborates the state of art in research of smart microgrids energy management system (EMS) including xEVs to enhance the reliability of charging infrastructure.}
}
@article{BOURELOS2020644,
title = {Smart heating in collaborative and reasoning-enabled housing units},
journal = {Future Generation Computer Systems},
volume = {109},
pages = {644-656},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18306009},
author = {P. Bourelos and G. Kousiouris and O. Voutyras and A. Marinakis and T. Varvarigou and V. Moulos},
keywords = {Smart cities, Heating management, Case-based reasoning, Social learning, Big data},
abstract = {In aiming to create added intelligence for Things interfacing with IoT principles in the form of Services, Smart Heating Management is consistently a field of promising research. In the currently demonstrated work, an approach will be described for an operational software framework of modular components that can create intelligence in Housing Units as those presented in our scenario. The framework is based on the lightweight Case Based Reasoning approach and principles in order to describe the Problem and Solution of heating management, as well as to extract knowledge from generic historical data. Collaboration between houses is included through the sharing of anonymized high level problem-solution data, as an instantiation of the same social learning principles that govern human behavior and enable Knowledge diffusion. The approach is validated through historical data acquired in two time periods from the Camden (London) community residencies and demonstrates an average of 22% savings in boiler active time. Knowledge sharing is also analyzed along with the benefits and pitfalls it might produce.}
}
@article{SITTONCANDANEDO2019278,
title = {A review of edge computing reference architectures and a new global edge proposal},
journal = {Future Generation Computer Systems},
volume = {99},
pages = {278-294},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X1930264X},
author = {Inés Sittón-Candanedo and Ricardo S. Alonso and Juan M. Corchado and Sara Rodríguez-González and Roberto Casado-Vara},
keywords = {Edge computing, Internet of Things, Blockchain, Reference architecture, Industry 4.0, Agroindustry},
abstract = {Edge Computing represents the activities of IoT (Internet of Things) devices at the border or limit of the network connected to the remote Cloud. The latest research in this field has intended to demonstrate that Edge Computing architectures are the optimal solution to minimising latency, improving privacy and reducing bandwidth costs in IoT-based scenarios. This article is a review of the Edge Computing technology and its reference architectures proposed by the Edge Computing Consortium, Intel-SAP, the FAR-Edge Project and the Industrial Internet Consortium for Industry 4.0. Moreover, this article presents a proposal for a tiered architecture with a modular approach that allows to manage the complexity of solutions not only for Industry 4.0 environments but also for other scenarios such as smart cities, smart energy, healthcare or precision agrotechnology. The main contributions of the proposed architecture reside in the security and privacy provided by blockchain technologies. Finally, the proposed reference architecture is tested by building an IoT platform in a smart agroindustry scenario to reduce bandwidth costs between the Edge and the Cloud.}
}
@article{LI2022105329,
title = {Air quality forecasting with artificial intelligence techniques: A scientometric and content analysis},
journal = {Environmental Modelling & Software},
pages = {105329},
year = {2022},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2022.105329},
url = {https://www.sciencedirect.com/science/article/pii/S1364815222000354},
author = {Yanzhao Li and Ju-e Guo and Shaolong Sun and Jianing Li and Shouyang Wang and Chengyuan Zhang},
keywords = {Air quality forecasting, Artificial intelligence, Machine learning, Scientometrics, Content analysis},
abstract = {Artificial intelligence (AI) techniques have substantially changed the research paradigm in the field of air quality forecasting due to their powerful performance. Considering the improvement in the availability of air quality data and the rapid proliferation of AI techniques, it is necessary to comprehensively and quantitatively review the development of air quality forecasting with AI techniques during the last two decades (2000–2019) by scientometric and content analysis. First, an overview of the relevant countries, institutions, authors, journals, and papers is presented. Then, the research hotspots and frontier evolution are explored by adopting reference co-citation analysis and keyword co-occurrence analysis. Furthermore, this study conducts a content analysis to investigate current topical interests to identify research gaps and propose future research directions. The analytical framework and the findings provide helpful insights into the prospects in air quality forecasting with AI techniques.}
}
@article{MA2021112,
title = {Unbalanced abnormal traffic detection based on improved Res-BIGRU and integrated dynamic ELM optimization},
journal = {Computer Communications},
volume = {179},
pages = {112-130},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421002991},
author = {Wengang Ma and Yadong Zhang and Jin Guo and Kehong Li},
keywords = {Unbalanced traffic, Vanishing gradient, Improved Res-BIGRU, Integrated dynamic ELM, Classification},
abstract = {Problems such as a vanishing gradient and overfitting will occur when a recurrent neural network (RNN) is exploited to detect abnormal network traffic. In addition, some network traffic is unbalanced, which leads to low detection accuracy. Therefore, an unbalanced abnormal traffic detection method has been proposed. It is composed of the improved bidirectional residual gated recurrent unit (Res-BIGRU) and integrated dynamic extreme learning machine (IDELM). First, the candidate hidden state activation function of the GRU is changed into an unsaturated activation function. The residual connection is used to avoid the vanishing gradient. The purpose of alleviating network degradation is achieved, and the traffic features extracted are better. Second, an IDELM is proposed to solve the unbalanced classification. The minority samples are generated by the IDELM model. The set model in game theory is used to compute the combined weight, which improves the fitting effect. Third, two IDELMs are used to update the final classification results. Fourth, four network datasets and IoT datasets are used to verify the performance. The average accuracy on four network datasets is 91.11% when samples are unbalanced. Furthermore, it can be concluded that the improved Res-BIGRU and IDELM strategy is effective. Better classification results can be achieved when network traffic is unbalanced. In particular, the performance is better in unbalanced NSL-KDD datasets. The index values obtained are the best compared with other methods. It is also suitable for intrusion detection of the Internet of Things, which has good performance. The further advantage lies in that the robustness is better when there are other sample interferences.}
}
@article{CHEN2021203,
title = {Mapping essential urban land use categories with open big data: Results for five metropolitan areas in the United States of America},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {178},
pages = {203-218},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621001684},
author = {Bin Chen and Ying Tu and Yimeng Song and David M. Theobald and Tao Zhang and Zhehao Ren and Xuecao Li and Jun Yang and Jie Wang and Xi Wang and Peng Gong and Yuqi Bai and Bing Xu},
keywords = {Land use classification, Block-level mapping, Geospatial big data, Ensemble learning, NAIP, Sentinel-1/2},
abstract = {Urban land-use maps outlining the distribution, pattern, and composition of various land use types are critically important for urban planning, environmental management, disaster control, health protection, and biodiversity conservation. Recent advances in remote sensing and social sensing data and methods have shown great potentials in mapping urban land use categories, but they are still constrained by mixed land uses, limited predictors, non-localized models, and often relatively low accuracies. To inform these issues, we proposed a robust and cost-effective framework for mapping urban land use categories using openly available multi-source geospatial “big data”. With street blocks generated from OpenStreetMap (OSM) data as the minimum classification unit, we integrated an expansive set of multi-scale spatially explicit information on land surface, vertical height, socio-economic attributes, social media, demography, and topography. We further proposed to apply the automatic ensemble learning that leverages a bunch of machine learning algorithms in deriving optimal urban land use classification maps. Results of block-level urban land use classification in five metropolitan areas of the United States found the overall accuracies of major-class (Level-I) and minor-class (Level-II) classification could be high as 91% and 86%, respectively. A multi-model comparison revealed that for urban land use classification with high-dimensional features, the multi-layer stacking ensemble models achieved better performance than base models such as random forest, extremely randomized trees, LightGBM, CatBoost, and neural networks. We found without very-high-resolution National Agriculture Imagery Program imagery, the classification results derived from Sentinel-1, Sentinel-2, and other open big data based features could achieve plausible overall accuracies of Level-I and Level-II classification at 88% and 81%, respectively. We also found that model transferability depended highly on the heterogeneity in characteristics of different regions. The methods and findings in this study systematically elucidate the role of data sources, classification methods, and feature transferability in block-level land use classifications, which have important implications for mapping multi-scale essential urban land use categories.}
}
@article{LAROUI2021210,
title = {Edge and fog computing for IoT: A survey on current research activities & future directions},
journal = {Computer Communications},
volume = {180},
pages = {210-231},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421003327},
author = {Mohammed Laroui and Boubakr Nour and Hassine Moungla and Moussa A. Cherif and Hossam Afifi and Mohsen Guizani},
keywords = {Internet of Things (IoT), Edge computing, Cloud computing},
abstract = {The Internet of Things (IoT) allows communication between devices, things, and any digital assets that send and receive data over a network without requiring interaction with a human. The main characteristic of IoT is the enormous quantity of data created by end-user’s devices that needs to be processed in a short time in the cloud. The current cloud-computing concept is not efficient to analyze very large data in a very short time and satisfy the users’ requirements. Analyzing the enormous quantity of data by the cloud will take a lot of time, which affects the quality of service (QoS) and negatively influences the IoT applications and the overall network performance. To overcome such challenges, a new architecture called edge computing — that allows to decentralize the process of data from the cloud to the network edge has been proposed to solve the problems occurred by using the cloud computing approach. Furthermore, edge computing supports IoT applications that require a short response time and consequently enhances the consumption of energy, resource utilization, etc. Motivated by the extensive research efforts in the edge computing and IoT applications, in this paper, we present a comprehensive review of edge and fog computing research in the IoT. We investigate the role of cloud, fog, and edge computing in the IoT environment. Subsequently, we cover in detail, different IoT use cases with edge and fog computing, the task scheduling in edge computing, the merger of software-defined networks (SDN) and network function virtualization (NFV) with edge computing, security and privacy efforts. Furthermore, the Blockchain in edge computing. Finally, we identify open research challenges and highlight future research directions.}
}
@article{ARIYALURANHABEEB2019289,
title = {Real-time big data processing for anomaly detection: A Survey},
journal = {International Journal of Information Management},
volume = {45},
pages = {289-307},
year = {2019},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2018.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0268401218301658},
author = {Riyaz Ahamed {Ariyaluran Habeeb} and Fariza Nasaruddin and Abdullah Gani and Ibrahim Abaker {Targio Hashem} and Ejaz Ahmed and Muhammad Imran},
keywords = {Real-time, Big data processing, Anomaly detection and machine learning algorithms},
abstract = {The advent of connected devices and omnipresence of Internet have paved way for intruders to attack networks, which leads to cyber-attack, financial loss, information theft in healthcare, and cyber war. Hence, network security analytics has become an important area of concern and has gained intensive attention among researchers, off late, specifically in the domain of anomaly detection in network, which is considered crucial for network security. However, preliminary investigations have revealed that the existing approaches to detect anomalies in network are not effective enough, particularly to detect them in real time. The reason for the inefficacy of current approaches is mainly due the amassment of massive volumes of data though the connected devices. Therefore, it is crucial to propose a framework that effectively handles real time big data processing and detect anomalies in networks. In this regard, this paper attempts to address the issue of detecting anomalies in real time. Respectively, this paper has surveyed the state-of-the-art real-time big data processing technologies related to anomaly detection and the vital characteristics of associated machine learning algorithms. This paper begins with the explanation of essential contexts and taxonomy of real-time big data processing, anomalous detection, and machine learning algorithms, followed by the review of big data processing technologies. Finally, the identified research challenges of real-time big data processing in anomaly detection are discussed.}
}
@article{AFYOUNI2021223,
title = {Passive BLE Sensing for Indoor Pattern Recognition and Tracking},
journal = {Procedia Computer Science},
volume = {191},
pages = {223-229},
year = {2021},
note = {The 18th International Conference on Mobile Systems and Pervasive Computing (MobiSPC), The 16th International Conference on Future Networks and Communications (FNC), The 11th International Conference on Sustainable Energy Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.07.028},
url = {https://www.sciencedirect.com/science/article/pii/S187705092101423X},
author = {Imad Afyouni and Mashaal Musleh and Anas Basalamah and Zaid Bin Tariq},
keywords = {Indoor tracking, pattern recognition, BLE-based positioning, power consumption},
abstract = {Crowd-centric sensing using smart phones enables a diverse range of applications evolving from large outdoor environments (e.g., smart cities) to small-scale indoor environments (e.g., smart homes, smart buildings). Tracking users’ patterns in indoor environments is a valuable and challenging aspect that is not yet fully addressed. Active indoor localization systems are generally energy-inefficient and cannot be applied to crowd monitoring applications. This paper focuses on the development of a passive and energy-efficient indoor tracking and pattern recognition technique on top of a managed Bluetooth Low-Energy (BLE) network. Particularly, our system model is based on a passive monitoring of a network of BLE tags, which continuously broadcast their unique identifiers, and the current timestamp. Multiple protocols were implemented to extract moving objects’ locations in indoors. The trajectory building process consists of different phases: 1) data sampling, 2) outlier detection and removal, 3) location estimation with a weighted centroid approach, 4) spatio-temporal map matching, and finally 5) trajectory smoothing. A series of experiments was conducted to demonstrate the efficiency and accuracy of the proposed approach, with respect to active triggering approaches and BLE-based localization systems.}
}
@article{SKOWRONEK2022100124,
title = {Inclusive STEAM education in diverse disciplines of sustainable energy and AI},
journal = {Energy and AI},
volume = {7},
pages = {100124},
year = {2022},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2021.100124},
url = {https://www.sciencedirect.com/science/article/pii/S2666546821000720},
author = {Michelle Skowronek and Renée M. Gilberti and Michael Petro and Christopher Sancomb and Stacy Maddern and Jasna Jankovic},
keywords = {STEM, STEAM, Sustainability, Energy, AI},
abstract = {This perspective article explores challenges of traditional education in science, technology, engineering and math (STEM) as it relates to emerging sustainable energy and artificial intelligence development. A special perspective is given for education of underrepresented and minority students in STEM. We discuss the existing issues and suggest that, for an equitable sustainable education in the area of energy, artificial intelligence and sustainable society in general, science and technology knowledge should be acquired in conjunction with humanities and arts, through a multidisciplinary STEM+Art (STEAM) approach and special programming that supports inclusion of diverse professional, socio-economical, racial and gender groups. We underscore that infusing technical training with social sciences, arts, ethics, and business prepares future leaders to creatively participate in solving identifiable barriers towards a sustainable society. Whether these are challenges caused by climate change, social tensions, or systematic inequalities, such holistic and sustainable education has the power to ease complex global crises, empower and dignify all people, as well as interrupt environmental degradation.}
}
@article{RATHORE201879,
title = {Semi-supervised learning based distributed attack detection framework for IoT},
journal = {Applied Soft Computing},
volume = {72},
pages = {79-89},
year = {2018},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2018.05.049},
url = {https://www.sciencedirect.com/science/article/pii/S1568494618303508},
author = {Shailendra Rathore and Jong Hyuk Park},
keywords = {Internet of Things, Fog computing, Machine learning, Cyber security, Security attack detection},
abstract = {Alongside the development of Internet of Things (IoT), security attacks are also increasing day by day. A number of centralized attack detection mechanisms have been proposed to detect attacks in IoT, wherein an attack detection system is deployed at the central point in the network that collects data from the network and classifies it as “attack” or “normal” using a supervised machine learning algorithm. Note, however, that these mechanisms have failed to achieve significant results due to the distinct requirements of IoT devices, such as scalability, distribution, resource limitations, and low latency. Moreover, the application of supervised machine learning for classification needs a significant amount of labeled data. In this paper, we introduce a fog-based attack detection framework that relies on the fog computing paradigm and a newly proposed ELM-based Semi-supervised Fuzzy C-Means (ESFCM) method. As an extension of cloud computing, fog computing enables attack detection at the network edge and supports distributed attack detection. The ESFCM method uses a semi-supervised fuzzy c-means algorithm to handle the labeled data issue and an Extreme Learning Machine (ELM) algorithm to provide good generalization performance at a faster detection rate. The evaluation was performed on the NSL-KDD dataset, demonstrating that the proposed framework achieved better performance than the centralized attack detection framework. More specifically, it recorded a lower detection time of 11 milliseconds and an accuracy rate of 86.53%.}
}
@article{M2022103416,
title = {Human identification system using 3D skeleton-based gait features and LSTM model},
journal = {Journal of Visual Communication and Image Representation},
volume = {82},
pages = {103416},
year = {2022},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2021.103416},
url = {https://www.sciencedirect.com/science/article/pii/S1047320321002807},
author = {Rashmi M. and Ram Mohana Reddy Guddeti},
keywords = {Biometric, Deep learning, Gait recognition, Human identification, Long Short Term Memory (LSTM), Smart surveillance},
abstract = {Vision-based gait emerged as the preferred biometric in smart surveillance systems due to its unobtrusive nature. Recent advancements in low-cost depth sensors resulted in numerous 3D skeleton-based gait analysis techniques. For spatial–temporal analysis, existing state-of-the-art algorithms use frame-level information as the timestamp. This paper proposes gait event-level spatial–temporal features and LSTM-based deep learning model that treats each gait event as a timestamp to identify individuals from walking patterns observed in single and multi-view scenarios. On four publicly available datasets, the proposed system stands superior to state-of-the-art approaches utilizing a variety of conventional benchmark protocols. The proposed system achieved a recognition rate of greater than 99% in low-level ranks during the CMC test, making it suitable for practical applications. The statistical study of gait event-level features demonstrated retrieved features’ discriminating capacity in classification. Additionally, the ANOVA test performed on findings from K folds demonstrated the proposed system’s significance in human identification.}
}
@article{WU2019477,
title = {Bigdata logs analysis based on seq2seq networks for cognitive Internet of Things},
journal = {Future Generation Computer Systems},
volume = {90},
pages = {477-488},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.08.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18309233},
author = {Pin Wu and Zhihui Lu and Quan Zhou and Zhidan Lei and Xiaoqiang Li and Meikang Qiu and Patrick C.K. Hung},
keywords = {Cognitive computing, Internet of Things, Bigdata, Recurrent neural network, Log analysis},
abstract = {While bigdata system processes high-volume data at high speed, it also generates a large amount of logs. However, it is hard for people to predict future events based on massive, multi-source, heterogeneous bigdata logs. This paper proposes a comprehensive method for smart computation and prediction of massive logs in the internet of things (IoT). Traditional machine learning, Hidden Markov Model (HMM) and Autoregressive Integrated Moving Average Model (ARIMA) methods are not accurate enough to predict time series based data over time. In this work we first elaborate the distributed collection and storage, event location, and vectorized representations of bigdata logs. Next, we present a log fusion algorithm to convert the logs (unstructured text data) of each component of bigdata into structured data by removing noise, adding timestamps and classification labels. Then, we introduce a predictive model for bigdata system. We use an attention mechanism to improve sequence to sequence (seq2seq) algorithm and add an adjustor to globally fit the data distribution. Our experimental results show that the neural network model trained by our method has a good performance with the real-world data. Compared with the previous predictive method, the root mean square error (RMSE) is reduced by 46.65% and the R-squared (R2) fitting degree is improved by 14.28%.}
}
@article{ZULKARNAIN2021e08615,
title = {Intelligent transportation systems (ITS): A systematic review using a Natural Language Processing (NLP) approach},
journal = {Heliyon},
volume = {7},
number = {12},
pages = {e08615},
year = {2021},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2021.e08615},
url = {https://www.sciencedirect.com/science/article/pii/S2405844021027183},
author = { Zulkarnain and Tsarina Dwi Putri},
keywords = {Intelligent transportation system, Natural language processing, Custom named entity recognition, Latent dirichlet allocation, Word embedding, Continuous skip-gram, Systematic review},
abstract = {Intelligent Transportation Systems (ITS) is not a new concept. Notably, ITS has been cited in various journal articles and proceedings papers around the world, and it has become increasingly popular. Additionally, ITS involves multidisciplinary science. The growing number of journal articles makes ITS reviews complicated, and research gaps can be difficult to identify. The existing software for systematic reviews still relies on highly laborious tasks, manual reading, and a homogeneous dataset of research articles. This study proposes a framework that can address these issues, return a comprehensive systematic review of ITS, and promote efficient systematic reviews. The proposed framework consists of Natural Language Processing (NLP) methods i.e., Named Entity Recognition (NER), Latent Dirichlet Allocation (LDA), and word embedding (continuous skip-gram). It enables this study to explore the context of research articles and their overall interpretation to determine and define the directions of knowledge growth and ITS development. The framework can systematically separate unrelated documents and simplify the review process for large dataset. To our knowledge, compared to prior research regarding systematic review of ITS, this study offers more thorough review.}
}
@article{KUOK2020106738,
title = {Model-free data reconstruction of structural response and excitation via sequential broad learning},
journal = {Mechanical Systems and Signal Processing},
volume = {141},
pages = {106738},
year = {2020},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2020.106738},
url = {https://www.sciencedirect.com/science/article/pii/S0888327020301242},
author = {Sin-Chi Kuok and Ka-Veng Yuen},
keywords = {Data reconstruction, Sequential broad learning, Structural response and excitation, Linear and nonlinear, Stationary and nonstationary},
abstract = {In this study, a novel sequential broad learning (SBL) approach is proposed to reconstruct the missing signal of damaged sensors in structural health monitoring (SHM) sensory networks. It is capable to reconstruct the structural response and external excitation of linear/nonlinear time-varying dynamical systems under stationary/nonstationary excitation for sensory networks. The proposed approach is a model-free data-driven machine learning methodology and the data reconstruction is executed sequentially with moving time windows. The learning algorithm is developed by adopting the recently developed broad learning system (BLS) (Chen and Liu, 2018). In contrast to deep learning that suffers from excessive computational cost for training the stacks of hierarchical layers, BLS is established with a broadly expandable network and can be modified incrementally based on the inherited results from the previous trained architecture. Therefore, BLS provides a computationally very efficient alternative to deep learning. Taking the benefit of BLS, the proposed SBL approach can efficiently handle the massive data stream generated in long-term monitoring. To demonstrate the efficacy and applicability of the proposed approach, simulated examples that cover linear and nonlinear time-varying dynamical systems subjected to stationary/nonstationary wind-load/base excitation with different types of sensing devices are discussed. Moreover, the SHM database of the field measurement monitored from the MIT Green Building is utilized to examine the performance of the proposed approach in realistic application. It is demonstrated that the proposed approach offers a powerful data reconstruction tool for challenging data missing situations encountered in SHM.}
}
@article{HAO2020788,
title = {New insights on ground control in intelligent mining with Internet of Things},
journal = {Computer Communications},
volume = {150},
pages = {788-798},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.12.032},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419315002},
author = {Yang Hao and Yu Wu and Ranjith P.G. and Kai Zhang and Houquan Zhang and Yanlong Chen and Ming Li and Pan Li},
keywords = {Ground control, Intelligence Mining, Mine safety, Internet of Things},
abstract = {The conception of Smart city has been gaining momentum in recent years. Coal mines as a part of city should be characterized with smart or intelligent features. Production and safety are two major themes in coal mining. With the development of automation, Internet of Things (IoT), big data, artificial intelligence, and cloud computing in Fourth Industrial Revolution, Intelligence Mining has been put forward by Chinese Academy of Engineering to achieve the goal of unmanned workface production. However, safety is not highlighted in the novel idea. In this paper, ground control in intelligent mining with IoT is studied. An architecture of ground control with IoT is proposed. The previous research on theoretical modeling and on-site monitoring methods are reviewed. Then the IoT based ground control method is proposed. An on-going dynamic platform on ground control are proposed based on our research of nondestructive testing (NDT) on rock bolt anchorage quality assessment. The research progress is introduced with equipment introduction, principles, and an on-site experiment. Future developments on combination of NDT and IoT of ground control is discussed. The ideas, frameworks, and results in this paper can make efforts on safety control and spark new ideas in the much-anticipated Intelligence Mining.}
}
@article{KHAN202150,
title = {SPICE-IT: Smart COVID-19 pandemic controlled eradication over NDN-IoT},
journal = {Information Fusion},
volume = {74},
pages = {50-64},
year = {2021},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2021.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S1566253521000609},
author = {Muhammad Toaha Raza Khan and Malik Muhammad Saad and Muhammad Ashar Tariq and Junaid Akram and Dongkyun Kim},
keywords = {Health care, Named data networking of things, Content Caching, Internet of Things (IoT)},
abstract = {Internet of things (IoT) application in e-health can play a vital role in countering rapidly spreading diseases that can effectively manage health emergency scenarios like pandemics. Efficient disease control also requires monitoring of Standard operating procedure (SOP) follow-up of the population in the disease-prone area with a cost-effective reporting and responding mechanism to register any violation. However, the IoT devices have limited resources and the application requires delay-sensitive data transmission. Named Data Networking (NDN) can significantly reduce content retrieval delays but inherits cache overflow and network congestion challenges. Therefore, we are motivated to present a novel smart COVID-19 pandemic-controlled eradication over NDN-IoT (SPICE-IT) mechanism. SPICE-IT introduces autonomous monitoring in indoor environments with efficient pull-based reporting mechanism that records violations at local servers and cloud server. Intelligent face mask detection and temperature monitoring mechanism examines every person. Cloud server controls the response action from the centre with an adaptive decision-making mechanism. Long short-term memory (LSTM) based caching mechanism reduces the cache overflow and overall network congestion problem.}
}
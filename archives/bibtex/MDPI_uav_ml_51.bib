
@Article{s21217270,
AUTHOR = {Bielecki, Andrzej and Śmigielski, Piotr},
TITLE = {Three-Dimensional Outdoor Analysis of Single Synthetic Building Structures by an Unmanned Flying Agent Using Monocular Vision},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7270},
URL = {https://www.mdpi.com/1424-8220/21/21/7270},
PubMedID = {34770577},
ISSN = {1424-8220},
ABSTRACT = {An algorithm designed for analysis and understanding a 3D urban-type environment by an autonomous flying agent, equipped only with a monocular vision, is presented. The algorithm is hierarchical and is based on the structural representation of the analyzed scene. Firstly, the robot observes the scene from a high altitude to build a 2D representation of a single object and a graph representation of the 2D scene. The 3D representation of each object arises as a consequence of the robot’s actions, as a result of which it projects the object’s solid on different planes. The robot assigns the obtained representations to the corresponding vertex of the created graph. The algorithm was tested by using the embodied robot operating on the real scene. The tests showed that the robot equipped with the algorithm was able not only to localize the predefined object, but also to perform safe, collision-free maneuvers close to the structures in the scene.},
DOI = {10.3390/s21217270}
}



@Article{rs13214415,
AUTHOR = {Filippi, Margaux and Hanlon, Regina and Rypina, Irina I. and Hodges, Benjamin A. and Peacock, Thomas and Schmale, David G.},
TITLE = {Tracking a Surrogate Hazardous Agent (Rhodamine Dye) in a Coastal Ocean Environment Using In Situ Measurements and Concentration Estimates Derived from Drone Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4415},
URL = {https://www.mdpi.com/2072-4292/13/21/4415},
ISSN = {2072-4292},
ABSTRACT = {New tools and technology are needed to track hazardous agents such as oil and red tides in our oceans. Rhodamine dye (a surrogate hazardous agent) was released into the Atlantic ocean in August 2018, and experiments were conducted to track the movement of the dye near the water surface within three hours following the release. A DrOne Water Sampling SystEm (DOWSE), consisting of a 3D-printed sampling device tethered to a drone, was used to collect 26 water samples at different locations around the dye plume. Rhodamine concentrations were measured from the drone water samples using a fluorometer and ranged from 1 to 93 ppb. Dye images were taken during the drone-sampling of surface water containing dye and at about 10 m above the sampling point. These images were post-processed to estimate dye concentrations across the sampling domain. A comparison of calibrated heat maps showed that the altitude images yielded dye distributions that were qualitatively similar to those from images taken near the ocean surface. Moreover, the association between red ratios and dye concentrations yielded trendlines explaining up to 67% of the variation. Drones may be used to detect, track and assist in mitigating hazardous agents in the future.},
DOI = {10.3390/rs13214415}
}



@Article{app112110310,
AUTHOR = {Jang, Keunyoung and Kim, Jong-Woo and Ju, Ki-Beom and An, Yun-Kyu},
TITLE = {Infrastructure BIM Platform for Lifecycle Management},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {10310},
URL = {https://www.mdpi.com/2076-3417/11/21/10310},
ISSN = {2076-3417},
ABSTRACT = {Recently, the application of the BIM technique to infrastructure lifecycle management has increased rapidly to improve the efficiency of infrastructure management systems. Research on the lifecycle management of infrastructure, from planning and design to construction and management, has been carried out. Therefore, a systematic review of the literature on recent research is performed to analyze the current state of the BIM technique. State-of-the-art techniques for infrastructure lifecycle management, such as unmanned robots, sensors and processing techniques, artificial intelligence, etc., are also reviewed. An infrastructure BIM platform framework composed of BIM and state-of-the-art techniques is then proposed. The proposed platform is a web-based platform that contains quantity, schedule (4D), and cost (5D) construction management, and the monitoring systems enable collaboration with stakeholders in a Common Data Environment (CDE). The lifecycle management methodology, after infrastructure construction, is then completed and is developed using state-of-the-art techniques using unmanned robots, scan-to-BIM, and deep learning networks, etc. It is confirmed that collaboration with stakeholders in the CDE in construction management is possible using an infrastructure BIM platform. Moreover, lifecycle management of infrastructure is possible by systematic management, such as time history analysis, damage growth prediction, decision of repair and demolition, etc., using a regular inspection database based on an infrastructure BIM platform.},
DOI = {10.3390/app112110310}
}



@Article{s21217314,
AUTHOR = {Hou, Huiling and Yang, Zhiliang and Pang, Cunsuo},
TITLE = {Rotor UAV’s Micro-Doppler Signal Detection and Parameter Estimation Based on FRFT-FSST},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7314},
URL = {https://www.mdpi.com/1424-8220/21/21/7314},
PubMedID = {34770622},
ISSN = {1424-8220},
ABSTRACT = {The micro-Doppler signal generated by the rotors of an Unmanned Aerial Vehicle (UAV) contains the structural features and motion information of the target, which can be used for detection and classification of the target, however, the standard STFT has the problems such as the lower time-frequency resolution and larger error in rotor parameter estimation, an FRFT (Fractional Fourier Transform)-FSST (STFT based synchrosqueezing)-based method for micro-Doppler signal detection and parameter estimation is proposed in this paper. Firstly, the FRFT is used in the proposed method to eliminate the influence of the velocity and acceleration of the target on the time-frequency features of the echo signal from the rotors. Secondly, the higher time-frequency resolution of FSST is used to extract the time-frequency features of micro-Doppler signals. Moreover, the specific solution methodologies for the selection of window length in STFT and the estimation of rotor parameters are given in the proposed method. Finally, the effectiveness and accuracy of the proposed method for target detection and rotor parameter estimation are verified through simulation and measured data.},
DOI = {10.3390/s21217314}
}



@Article{rs13214430,
AUTHOR = {Bizjak, Marko and Žalik, Borut and Lukač, Niko},
TITLE = {Parameter-Free Half-Spaces Based 3D Building Reconstruction Using Ground and Segmented Building Points from Airborne LiDAR Data with 2D Outlines},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4430},
URL = {https://www.mdpi.com/2072-4292/13/21/4430},
ISSN = {2072-4292},
ABSTRACT = {This paper aims to automatically reconstruct 3D building models on a large scale using a new approach on the basis of half-spaces, while making no assumptions about the building layout and keeping the number of input parameters to a minimum. The proposed algorithm is performed in two stages. First, the airborne LiDAR data and buildings’ outlines are preprocessed to generate buildings’ base models and the corresponding half-spaces. In the second stage, the half-spaces are analysed and used for shaping the final 3D building model using 3D Boolean operations. In experiments, the proposed algorithm was applied on a large scale, and its’ performance was inspected on a city level and on a single building level. Accurate reconstruction of buildings with various layouts were demonstrated and limitations were identified for large-scale applications. Finally, the proposed algorithm was validated on an ISPRS benchmark dataset, where a RMSE of 1.31 m and completeness of 98.9% were obtained.},
DOI = {10.3390/rs13214430}
}



@Article{w13213115,
AUTHOR = {Farhadi, Hadi and Najafzadeh, Mohammad},
TITLE = {Flood Risk Mapping by Remote Sensing Data and Random Forest Technique},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {3115},
URL = {https://www.mdpi.com/2073-4441/13/21/3115},
ISSN = {2073-4441},
ABSTRACT = {Detecting effective parameters in flood occurrence is one of the most important issues that has drawn more attention in recent years. Remote Sensing (RS) and Geographical Information System (GIS) are two efficient ways to spatially predict Flood Risk Mapping (FRM). In this study, a web-based platform called the Google Earth Engine (GEE) (Google Company, Mountain View, CA, USA) was used to obtain flood risk indices for the Galikesh River basin, Northern Iran. With the aid of Landsat 8 satellite imagery and the Shuttle Radar Topography Mission (SRTM) Digital Elevation Model (DEM), 11 risk indices (Elevation (El), Slope (Sl), Slope Aspect (SA), Land Use (LU), Normalized Difference Vegetation Index (NDVI), Normalized Difference Water Index (NDWI), Topographic Wetness Index (TWI), River Distance (RD), Waterway and River Density (WRD), Soil Texture (ST]), and Maximum One-Day Precipitation (M1DP)) were provided. In the next step, all of these indices were imported into ArcMap 10.8 (Esri, West Redlands, CA, USA) software for index normalization and to better visualize the graphical output. Afterward, an intelligent learning machine (Random Forest (RF)), which is a robust data mining technique, was used to compute the importance degree of each index and to obtain the flood hazard map. According to the results, the indices of WRD, RD, M1DP, and El accounted for about 68.27 percent of the total flood risk. Among these indices, the WRD index containing about 23.8 percent of the total risk has the greatest impact on floods. According to FRM mapping, about 21 and 18 percent of the total areas stood at the higher and highest risk areas, respectively.},
DOI = {10.3390/w13213115}
}



@Article{app112110370,
AUTHOR = {Duarte-Vidal, Luz and Herrera, Rodrigo F. and Atencio, Edison and Muñoz-La Rivera, Felipe},
TITLE = {Interoperability of Digital Tools for the Monitoring and Control of Construction Projects},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {10370},
URL = {https://www.mdpi.com/2076-3417/11/21/10370},
ISSN = {2076-3417},
ABSTRACT = {Monitoring the progress on a construction site during the construction phase is crucial. An inadequate understanding of the project status can lead to mistakes and inappropriate actions, causing delays and increased costs. Monitoring and controlling projects via digital tools would reduce the risk of error and enable timely corrective actions. Although there is currently a wide range of technologies for these purposes, these technologies and interoperability between them are still limited. Because of this, it is important to know the possibilities of integration and interoperability regarding their implementation. This article presents a bibliographic synthesis and interpretation of 30 nonconventional digital tools for monitoring progress in terms of field data capture technologies (FDCT) and communication and collaborative technologies (CT) that are responsible for information processing and management. This research aims to perform an integration and interoperability analysis of technologies to demonstrate their potential for monitoring and controlling construction projects during the execution phase. A network analysis was conducted, and the results suggest that the triad formed by building information modeling (BIM), unmanned aerial vehicles (UAVs) and photogrammetry is an effective tool; the use of this set extends not only to monitoring and control, but also to all phases of a project.},
DOI = {10.3390/app112110370}
}



@Article{rs13214445,
AUTHOR = {Nazeri, Behrokh and Crawford, Melba},
TITLE = {Detection of Outliers in LiDAR Data Acquired by Multiple Platforms over Sorghum and Maize},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4445},
URL = {https://www.mdpi.com/2072-4292/13/21/4445},
ISSN = {2072-4292},
ABSTRACT = {High-resolution point cloud data acquired with a laser scanner from any platform contain random noise and outliers. Therefore, outlier detection in LiDAR data is often necessary prior to analysis. Applications in agriculture are particularly challenging, as there is typically no prior knowledge of the statistical distribution of points, plant complexity, and local point densities, which are crop-dependent. The goals of this study were first to investigate approaches to minimize the impact of outliers on LiDAR acquired over agricultural row crops, and specifically for sorghum and maize breeding experiments, by an unmanned aerial vehicle (UAV) and a wheel-based ground platform; second, to evaluate the impact of existing outliers in the datasets on leaf area index (LAI) prediction using LiDAR data. Two methods were investigated to detect and remove the outliers from the plant datasets. The first was based on surface fitting to noisy point cloud data via normal and curvature estimation in a local neighborhood. The second utilized the PointCleanNet deep learning framework. Both methods were applied to individual plants and field-based datasets. To evaluate the method, an F-score was calculated for synthetic data in the controlled conditions, and LAI, the variable being predicted, was computed both before and after outlier removal for both scenarios. Results indicate that the deep learning method for outlier detection is more robust than the geometric approach to changes in point densities, level of noise, and shapes. The prediction of LAI was also improved for the wheel-based vehicle data based on the coefficient of determination (R2) and the root mean squared error (RMSE) of the residuals before and after the removal of outliers.},
DOI = {10.3390/rs13214445}
}



@Article{sym13112097,
AUTHOR = {Fu, Chengcai and Lu, Fengli and Zhang, Xiaoxiao and Zhang, Guoying},
TITLE = {Joint Dedusting and Enhancement of Top-Coal Caving Face via Single-Channel Retinex-Based Method with Frequency Domain Prior Information},
JOURNAL = {Symmetry},
VOLUME = {13},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2097},
URL = {https://www.mdpi.com/2073-8994/13/11/2097},
ISSN = {2073-8994},
ABSTRACT = {Affected by the uneven concentration of coal dust and low illumination, most of the images captured in the top-coal caving face have low definition, high haze and serious noise. In order to improve the visual effect of underground images captured in the top-coal caving face, a novel single-channel Retinex dedusting algorithm with frequency domain prior information is proposed to solve the problem that Retinex defogging algorithm cannot effectively defog and denoise, simultaneously, while preserving image details. Our work is inspired by the simple and intuitive observation that the low frequency component of dust-free image will be amplified in the symmetrical spectrum after adding dusts. A single-channel multiscale Retinex algorithm with color restoration (MSRCR) in YIQ space is proposed to restore the foggy approximate component in wavelet domain. After that the multiscale convolution enhancement and fast non-local means (FNLM) filter are used to minimize noise of detail components while retaining sufficient details. Finally, a dust-free image is reconstructed to the spatial domain and the color is restored by white balance. By comparing with the state-of-the-art image dedusting and defogging algorithms, the experimental results have shown that the proposed algorithm has higher contrast and visibility in both subjective and objective analysis while retaining sufficient details.},
DOI = {10.3390/sym13112097}
}



@Article{en14217360,
AUTHOR = {Mayer, Zoe and Heuer, Julia and Volk, Rebekka and Schultmann, Frank},
TITLE = {Aerial Thermographic Image-Based Assessment of Thermal Bridges Using Representative Classifications and Calculations},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7360},
URL = {https://www.mdpi.com/1996-1073/14/21/7360},
ISSN = {1996-1073},
ABSTRACT = {Since the middle of the 20th century many any buildings were built without any energy standards and still have a comparably poor energy quality. To obtain an overview of the current thermal quality of buildings in a whole city district, it may be promising to work with thermographic images obtained by unmanned aerial vehicles (UAV). Aerial thermography represents a fast and cost-efficient approach compared to traditional terrestrial thermography. In this paper, we describe an approach to finding thermal bridges on aerial thermographic images and characterizing them in terms of their risk of mold formation, energy losses, retrofit costs, and retrofit benefits. To identify thermal bridge types that can be detected reliably on aerial thermographic images, we use a dataset collected with a UAV in an urban district of the German city of Karlsruhe. We classify and characterize 14 relevant thermal bridge types for the German building cohorts of the 1950s and 1960s. Concerning the criterion of mold formation, thermal bridges of window components, basement ceiling slabs, balcony slabs, floor slabs, and attics are found to be particularly relevant to retrofit projects. Regarding energy savings, the retrofit of thermal bridges of window sills, window lintels, and attics shows high potential. The retrofit of attics seems to be less attractive, when also taking into account the necessary retrofit costs.},
DOI = {10.3390/en14217360}
}



@Article{s21217365,
AUTHOR = {Muñoz, Javier and López, Blanca and Quevedo, Fernando and Monje, Concepción A. and Garrido, Santiago and Moreno, Luis E.},
TITLE = {Multi UAV Coverage Path Planning in Urban Environments},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7365},
URL = {https://www.mdpi.com/1424-8220/21/21/7365},
PubMedID = {34770670},
ISSN = {1424-8220},
ABSTRACT = {Coverage path planning (CPP) is a field of study which objective is to find a path that covers every point of a certain area of interest. Recently, the use of Unmanned Aerial Vehicles (UAVs) has become more proficient in various applications such as surveillance, terrain coverage, mapping, natural disaster tracking, transport, and others. The aim of this paper is to design efficient coverage path planning collision-avoidance capable algorithms for single or multi UAV systems in cluttered urban environments. Two algorithms are developed and explored: one of them plans paths to cover a target zone delimited by a given perimeter with predefined coverage height and bandwidth, using a boustrophedon flight pattern, while the other proposed algorithm follows a set of predefined viewpoints, calculating a smooth path that ensures that the UAVs pass over the objectives. Both algorithms have been developed for a scalable number of UAVs, which fly in a triangular deformable leader-follower formation with the leader at its front. In the case of an even number of UAVs, there is no leader at the front of the formation and a virtual leader is used to plan the paths of the followers. The presented algorithms also have collision avoidance capabilities, powered by the Fast Marching Square algorithm. These algorithms are tested in various simulated urban and cluttered environments, and they prove capable of providing safe and smooth paths for the UAV formation in urban environments.},
DOI = {10.3390/s21217365}
}



@Article{rs13214466,
AUTHOR = {Eischeid, Isabell and Soininen, Eeva M. and Assmann, Jakob J. and Ims, Rolf A. and Madsen, Jesper and Pedersen, Åshild Ø. and Pirotti, Francesco and Yoccoz, Nigel G. and Ravolainen, Virve T.},
TITLE = {Disturbance Mapping in Arctic Tundra Improved by a Planning Workflow for Drone Studies: Advancing Tools for Future Ecosystem Monitoring},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4466},
URL = {https://www.mdpi.com/2072-4292/13/21/4466},
ISSN = {2072-4292},
ABSTRACT = {The Arctic is under great pressure due to climate change. Drones are increasingly used as a tool in ecology and may be especially valuable in rapidly changing and remote landscapes, as can be found in the Arctic. For effective applications of drones, decisions of both ecological and technical character are needed. Here, we provide our method planning workflow for generating ground-cover maps with drones for ecological monitoring purposes. The workflow includes the selection of variables, layer resolutions, ground-cover classes and the development and validation of models. We implemented this workflow in a case study of the Arctic tundra to develop vegetation maps, including disturbed vegetation, at three study sites in Svalbard. For each site, we generated a high-resolution map of tundra vegetation using supervised random forest (RF) classifiers based on four spectral bands, the normalized difference vegetation index (NDVI) and three types of terrain variables—all derived from drone imagery. Our classifiers distinguished up to 15 different ground-cover classes, including two classes that identify vegetation state changes due to disturbance caused by herbivory (i.e., goose grubbing) and winter damage (i.e., ‘rain-on-snow’ and thaw-freeze). Areas classified as goose grubbing or winter damage had lower NDVI values than their undisturbed counterparts. The predictive ability of site-specific RF models was good (macro-F1 scores between 83% and 85%), but the area of the grubbing class was overestimated in parts of the moss tundra. A direct transfer of the models between study sites was not possible (macro-F1 scores under 50%). We show that drone image analysis can be an asset for studying future vegetation state changes on local scales in Arctic tundra ecosystems and encourage ecologists to use our tailored workflow to integrate drone mapping into long-term monitoring programs.},
DOI = {10.3390/rs13214466}
}



@Article{s21217397,
AUTHOR = {Wang, Yanjun and Li, Shaochun and Lin, Yunhao and Wang, Mengjie},
TITLE = {Lightweight Deep Neural Network Method for Water Body Extraction from High-Resolution Remote Sensing Images with Multisensors},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7397},
URL = {https://www.mdpi.com/1424-8220/21/21/7397},
PubMedID = {34770701},
ISSN = {1424-8220},
ABSTRACT = {Rapid and accurate extraction of water bodies from high-spatial-resolution remote sensing images is of great value for water resource management, water quality monitoring and natural disaster emergency response. For traditional water body extraction methods, it is difficult to select image texture and features, the shadows of buildings and other ground objects are in the same spectrum as water bodies, the existing deep convolutional neural network is difficult to train, the consumption of computing resources is large, and the methods cannot meet real-time requirements. In this paper, a water body extraction method based on lightweight MobileNetV2 is proposed and applied to multisensor high-resolution remote sensing images, such as GF-2, WorldView-2 and UAV orthoimages. This method was validated in two typical complex geographical scenes: water bodies for farmland irrigation, which have a broken shape and long and narrow area and are surrounded by many buildings in towns and villages; and water bodies in mountainous areas, which have undulating topography, vegetation coverage and mountain shadows all over. The results were compared with those of the support vector machine, random forest and U-Net models and also verified by generalization tests and the influence of spatial resolution changes. First, the results show that the F1-score and Kappa coefficients of the MobileNetV2 model extracting water bodies from three different high-resolution images were 0.75 and 0.72 for GF-2, 0.86 and 0.85 for Worldview-2 and 0.98 and 0.98 for UAV, respectively, which are higher than those of traditional machine learning models and U-Net. Second, the training time, number of parameters and calculation amount of the MobileNetV2 model were much lower than those of the U-Net model, which greatly improves the water body extraction efficiency. Third, in other more complex surface areas, the MobileNetV2 model still maintained relatively high accuracy of water body extraction. Finally, we tested the effects of multisensor models and found that training with lower and higher spatial resolution images combined can be beneficial, but that using just lower resolution imagery is ineffective. This study provides a reference for the efficient automation of water body classification and extraction under complex geographical environment conditions and can be extended to water resource investigation, management and planning.},
DOI = {10.3390/s21217397}
}



@Article{s21217396,
AUTHOR = {Kim, Bubryur and Choi, Se-Woon and Hu, Gang and Lee, Dong-Eun and Serfa Juan, Ronnie O.},
TITLE = {Multivariate Analysis of Concrete Image Using Thermography and Edge Detection},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7396},
URL = {https://www.mdpi.com/1424-8220/21/21/7396},
PubMedID = {34770702},
ISSN = {1424-8220},
ABSTRACT = {With the growing demand for structural health monitoring system applications, data imaging is an ideal method for performing regular routine maintenance inspections. Image analysis can provide invaluable information about the health conditions of a structure’s existing infrastructure by recording and analyzing exterior damages. Therefore, it is desirable to have an automated approach that reports defects on images reliably and robustly. This paper presents a multivariate analysis approach for images, specifically for assessing substantial damage (such as cracks). The image analysis provides graph representations that are related to the image, such as the histogram. In addition, image-processing techniques such as grayscale are also implemented, which enhance the object’s information present in the image. In addition, this study uses image segmentation and a neural network, for transforming an image to analyze it more easily and as a classifier, respectively. Initially, each concrete structure image is preprocessed to highlight the crack. A neural network is used to calculate and categorize the visual characteristics of each region, and it shows an accuracy for classification of 98%. Experimental results show that thermal image extraction yields better histogram and cumulative distribution function features. The system can promote the development of various thermal image applications, such as nonphysical visual recognition and fault detection analysis.},
DOI = {10.3390/s21217396}
}



@Article{e23111470,
AUTHOR = {Luan, Zhirong and Jia, Hongtao and Wang, Ping and Jia, Rong and Chen, Badong},
TITLE = {Joint UAVs’ Load Balancing and UEs’ Data Rate Fairness Optimization by Diffusion UAV Deployment Algorithm in Multi-UAV Networks},
JOURNAL = {Entropy},
VOLUME = {23},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {1470},
URL = {https://www.mdpi.com/1099-4300/23/11/1470},
PubMedID = {34828168},
ISSN = {1099-4300},
ABSTRACT = {Unmanned aerial vehicles (UAVs) can be deployed as base stations (BSs) for emergency communications of user equipments (UEs) in 5G/6G networks. In multi-UAV communication networks, UAVs’ load balancing and UEs’ data rate fairness are two challenging problems and can be optimized by UAV deployment strategies. In this work, we found that these two problems are related by the same performance metric, which makes it possible to optimize the two problems simultaneously. To solve this joint optimization problem, we propose a UAV diffusion deployment algorithm based on the virtual force field method. Firstly, according to the unique performance metric, we define two new virtual forces, which are the UAV-UAV force and UE-UAV force defined by FU and FV, respectively. FV is the main contributor to load balancing and UEs’ data rate fairness, and FU contributes to fine tuning the UEs’ data rate fairness performance. Secondly, we propose a diffusion control stratedy to the update UAV-UAV force, which optimizes FV in a distributed manner. In this diffusion strategy, each UAV optimizes the local parameter by exchanging information with neighbor UAVs, which achieve global load balancing in a distributed manner. Thirdly, we adopt the successive convex optimization method to update FU, which is a non-convex problem. The resultant force of FV and FU is used to control the UAVs’ motion. Simulation results show that the proposed algorithm outperforms the baseline algorithm on UAVs’ load balancing and UEs’ data rate fairness.},
DOI = {10.3390/e23111470}
}



@Article{su132112291,
AUTHOR = {Wu, Li-Ya and Weng, Sung-Shun},
TITLE = {Ensemble Learning Models for Food Safety Risk Prediction},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {12291},
URL = {https://www.mdpi.com/2071-1050/13/21/12291},
ISSN = {2071-1050},
ABSTRACT = {Ensemble learning was adopted to design risk prediction models with the aim of improving border inspection methods for food imported into Taiwan. Specifically, we constructed a set of prediction models to enhance the hit rate of non-conforming products, thus strengthening the border control of food products to safeguard public health. Using five algorithms, we developed models to provide recommendations for the risk assessment of each imported food batch. The models were evaluated by constructing a confusion matrix to calculate predictive performance indicators, including the positive prediction value (PPV), recall, harmonic mean of PPV and recall (F1 score), and area under the curve. Our results showed that ensemble learning achieved better and more stable prediction results than any single algorithm. When the results of comparable data periods were examined, the non-conformity hit rate was found to increase significantly after online implementation of the ensemble learning models, indicating that ensemble learning was effective at risk prediction. In addition to enhancing the inspection hit rate of non-conforming food, the results of this study can serve as a reference for the improvement of existing random inspection methods, thus strengthening capabilities in food risk management.},
DOI = {10.3390/su132112291}
}



@Article{rs13214476,
AUTHOR = {Traore, Adama and Ata-Ul-Karim, Syed Tahir and Duan, Aiwang and Soothar, Mukesh Kumar and Traore, Seydou and Zhao, Ben},
TITLE = {Predicting Equivalent Water Thickness in Wheat Using UAV Mounted Multispectral Sensor through Deep Learning Techniques},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4476},
URL = {https://www.mdpi.com/2072-4292/13/21/4476},
ISSN = {2072-4292},
ABSTRACT = {The equivalent water thickness (EWT) is an important biophysical indicator of water status in crops. The effective monitoring of EWT in wheat under different nitrogen and water treatments is important for irrigation management in precision agriculture. This study aimed to investigate the performances of machine learning (ML) algorithms in retrieving wheat EWT. For this purpose, a rain shelter experiment (Exp. 1) with four irrigation quantities (0, 120, 240, 360 mm) and two nitrogen levels (75 and 255 kg N/ha), and field experiments (Exps. 2–3) with the same irrigation and rainfall water levels (360 mm) but different nitrogen levels (varying from 75 to 255 kg N/ha) were conducted in the North China Plain. The canopy reflectance was measured for all plots at 30 m using an unmanned aerial vehicle (UAV)-mounted multispectral camera. Destructive sampling was conducted immediately after the UAV flights to measure total fresh and dry weight. Deep Neural Network (DNN) is a special type of neural network, which has shown performance in regression analysis is compared with other machine learning (ML) models. A feature selection (FS) algorithm named the decision tree (DT) was used as the automatic relevance determination method to obtain the relative relevance of 5 out of 67 vegetation indices (Vis), which were used for estimating EWT. The selected VIs were used to estimate EWT using multiple linear regression (MLR), deep neural network multilayer perceptron (DNN-MLP), artificial neural networks multilayer perceptron (ANN-MLP), boosted tree regression (BRT), and support vector machines (SVMs). The results show that the DNN-MLP with R2 = 0.934, NSE = 0.933, RMSE = 0.028 g/cm2, and MAE of 0.017 g/cm2 outperformed other ML algorithms (ANN-MPL, BRT, and SVM- Polynomial) owing to its high capacity for estimating EWT as compared to other ML methods. Our findings support the conclusion that ML can potentially be applied in combination with VIs for retrieving EWT. Despite the complexity of the ML models, the EWT map should help farmers by improving the real-time irrigation efficiency of wheat by quantifying field water content and addressing variability.},
DOI = {10.3390/rs13214476}
}



@Article{rs13214486,
AUTHOR = {Rakhmatuiln, Ildar and Kamilaris, Andreas and Andreasen, Christian},
TITLE = {Deep Neural Networks to Detect Weeds from Crops in Agricultural Environments in Real-Time: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4486},
URL = {https://www.mdpi.com/2072-4292/13/21/4486},
ISSN = {2072-4292},
ABSTRACT = {Automation, including machine learning technologies, are becoming increasingly crucial in agriculture to increase productivity. Machine vision is one of the most popular parts of machine learning and has been widely used where advanced automation and control have been required. The trend has shifted from classical image processing and machine learning techniques to modern artificial intelligence (AI) and deep learning (DL) methods. Based on large training datasets and pre-trained models, DL-based methods have proven to be more accurate than previous traditional techniques. Machine vision has wide applications in agriculture, including the detection of weeds and pests in crops. Variation in lighting conditions, failures to transfer learning, and object occlusion constitute key challenges in this domain. Recently, DL has gained much attention due to its advantages in object detection, classification, and feature extraction. DL algorithms can automatically extract information from large amounts of data used to model complex problems and is, therefore, suitable for detecting and classifying weeds and crops. We present a systematic review of AI-based systems to detect weeds, emphasizing recent trends in DL. Various DL methods are discussed to clarify their overall potential, usefulness, and performance. This study indicates that several limitations obstruct the widespread adoption of AI/DL in commercial applications. Recommendations for overcoming these challenges are summarized.},
DOI = {10.3390/rs13214486}
}



@Article{rs13214489,
AUTHOR = {Chancia, Robert and Bates, Terry and Vanden Heuvel, Justine and van Aardt, Jan},
TITLE = {Assessing Grapevine Nutrient Status from Unmanned Aerial System (UAS) Hyperspectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4489},
URL = {https://www.mdpi.com/2072-4292/13/21/4489},
ISSN = {2072-4292},
ABSTRACT = {This study aimed to identify the optimal sets of spectral bands for monitoring multiple grapevine nutrients in vineyards. We used spectral data spanning 400–2500 nm and leaf samples from 100 Concord grapevine canopies, lab-analyzed for six key nutrient values, to select the optimal bands for the nutrient regression models. The canopy spectral data were obtained with unmanned aerial systems (UAS), using push-broom imaging spectrometers (hyperspectral sensors). The novel use of UAS-based hyperspectral imagery to assess the grapevine nutrient status fills the gap between in situ spectral sampling and UAS-based multispectral imaging, avoiding their inherent trade-offs between spatial and spectral resolution. We found that an ensemble feature ranking method, utilizing six different machine learning feature selection methods, produced similar regression results as the standard PLSR feature selection and regression while generally selecting fewer wavelengths. We identified a set of biochemically consistent bands (606, 641, and 1494 nm) to predict the nitrogen content with an RMSE of 0.17% (using leave-one-out cross-validation) in samples with nitrogen contents ranging between 2.4 and 3.6%. Further studying is needed to confirm the relevance and consistency of the wavelengths selected for each nutrient model, but ensemble feature selection showed promise in identifying stable sets of wavelengths for assessing grapevine nutrient contents from canopy spectra.},
DOI = {10.3390/rs13214489}
}



@Article{rs13224500,
AUTHOR = {He, Yixin and Wang, Dawei and Huang, Fanghui and Zhang, Yufei and Zhang, Ruonan and Yan, Xiaohong},
TITLE = {A RFID-Integrated Framework for Tag Anti-Collision in UAV-Aided VANETs},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4500},
URL = {https://www.mdpi.com/2072-4292/13/22/4500},
ISSN = {2072-4292},
ABSTRACT = {In this paper, we investigate tags in anti-collision applications of radio frequency identification (RFID) technology in unmanned aerial vehicle (UAV)-aided vehicular ad hoc networks (VANETs). The integration of RFID technology in UAV-aided VANETs can provide reliable traffic-related services for vehicles. However, multiple tags’ simultaneous responses to a reader mounted on a UAV, denoted as tag collision, gravely affect the correct tag detection on each vehicle. Therefore, in order to decrease the collision probability and improve the throughput, we propose a multi-frequency tag identification method. In the proposed scheme, we devise a tag grouping method based on adaptive power control to make the reader dynamically match the optimal frame length. Based on the above matching results, we introduce a tag estimation method using the optimal weight to improve the accuracy of tag estimation. We theoretically analyze the closed-form expression of the security outage probability expression. Finally, our simulation results demonstrate that the proposed tag anti-collision scheme achieved significant performance superiority in terms of the throughput and identification time slots.},
DOI = {10.3390/rs13224500}
}



@Article{app112210595,
AUTHOR = {Zhao, Wenlong and Meng, Zhijun and Wang, Kaipeng and Zhang, Jiahui and Lu, Shaoze},
TITLE = {Hierarchical Active Tracking Control for UAVs via Deep Reinforcement Learning},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10595},
URL = {https://www.mdpi.com/2076-3417/11/22/10595},
ISSN = {2076-3417},
ABSTRACT = {Active tracking control is essential for UAVs to perform autonomous operations in GPS-denied environments. In the active tracking task, UAVs take high-dimensional raw images as input and execute motor actions to actively follow the dynamic target. Most research focuses on three-stage methods, which entail perception first, followed by high-level decision-making based on extracted spatial information of the dynamic target, and then UAV movement control, using a low-level dynamic controller. Perception methods based on deep neural networks are powerful but require considerable effort for manual ground truth labeling. Instead, we unify the perception and decision-making stages using a high-level controller and then leverage deep reinforcement learning to learn the mapping from raw images to the high-level action commands in the V-REP-based environment, where simulation data are infinite and inexpensive. This end-to-end method also has the advantages of a small parameter size and reduced effort requirements for parameter turning in the decision-making stage. The high-level controller, which has a novel architecture, explicitly encodes the spatial and temporal features of the dynamic target. Auxiliary segmentation and motion-in-depth losses are introduced to generate denser training signals for the high-level controller’s fast and stable training. The high-level controller and a conventional low-level PID controller constitute our hierarchical active tracking control framework for the UAVs’ active tracking task. Simulation experiments show that our controller trained with several augmentation techniques sufficiently generalizes dynamic targets with random appearances and velocities, and achieves significantly better performance, compared with three-stage methods.},
DOI = {10.3390/app112210595}
}



@Article{ijgi10110762,
AUTHOR = {Jaalama, Kaisa and Kauhanen, Heikki and Keitaanniemi, Aino and Rantanen, Toni and Virtanen, Juho-Pekka and Julin, Arttu and Vaaja, Matti and Ingman, Matias and Ahlavuo, Marika and Hyyppä, Hannu},
TITLE = {3D Point Cloud Data in Conveying Information for Local Green Factor Assessment},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {762},
URL = {https://www.mdpi.com/2220-9964/10/11/762},
ISSN = {2220-9964},
ABSTRACT = {The importance of ensuring the adequacy of urban ecosystem services and green infrastructure has been widely highlighted in multidisciplinary research. Meanwhile, the consolidation of cities has been a dominant trend in urban development and has led to the development and implementation of the green factor tool in cities such as Berlin, Melbourne, and Helsinki. In this study, elements of the green factor tool were monitored with laser-scanned and photogrammetrically derived point cloud datasets encompassing a yard in Espoo, Finland. The results show that with the support of 3D point clouds, it is possible to support the monitoring of the local green infrastructure, including elements of smaller size in green areas and yards. However, point clouds generated by distinct means have differing abilities in conveying information on green elements, and canopy covers, for example, might hinder these abilities. Additionally, some green factor elements are more promising for 3D measurement-based monitoring than others, such as those with clear geometrical form. The results encourage the involvement of 3D measuring technologies for monitoring local urban green infrastructure (UGI), also of small scale.},
DOI = {10.3390/ijgi10110762}
}



@Article{agronomy11112277,
AUTHOR = {Jensen, Signe M. and Akhter, Muhammad Javaid and Azim, Saiful and Rasmussen, Jesper},
TITLE = {The Predictive Power of Regression Models to Determine Grass Weed Infestations in Cereals Based on Drone Imagery—Statistical and Practical Aspects},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2277},
URL = {https://www.mdpi.com/2073-4395/11/11/2277},
ISSN = {2073-4395},
ABSTRACT = {Site-specific weed management (SSWM) may reduce herbicide use by identifying weed patches and weed-free areas. However, one major constraint is robust weed detection algorithms that are able to predict weed infestations outside of the training data. This study investigates the predictive power of regression models trained on drone imagery that are used within fields to predict infestations of annual grass weeds in the late growth stages of cereals. The main objective was to identify the optimum sampling strategy for training regression models based on aerial RGB images. The study showed that training based on sampling from the whole range of weed infestations or the extreme values in the field provided better prediction accuracy than random sampling. Prediction models based on vegetation indices (VIs) offered a useful alternative to a more complex random forest machine-learning algorithm. For binary decision-making, linear regression utilizing weed density information resulted in higher accuracy than a logistic regression approach that only relied on information regarding the presence/absence of weeds. Across six fields, the average balanced accuracy based on linear regression was in the range of 75–83%, with the highest accuracy found when the sampling was from the extreme values in the field, and with the lowest accuracy found for random sampling. For future work on training weed prediction models, choosing training sets covering the entire sample space is recommended in favor of random sampling.},
DOI = {10.3390/agronomy11112277}
}



@Article{agronomy11112290,
AUTHOR = {Sadgrove, Edmund J. and Falzon, Greg and Miron, David and Lamb, David W.},
TITLE = {The Segmented Colour Feature Extreme Learning Machine: Applications in Agricultural Robotics},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2290},
URL = {https://www.mdpi.com/2073-4395/11/11/2290},
ISSN = {2073-4395},
ABSTRACT = {This study presents the Segmented Colour Feature Extreme Learning Machine (SCF-ELM). The SCF-ELM is inspired by the Extreme Learning Machine (ELM) which is known for its rapid training and inference times. The ELM is therefore an ideal candidate for an ensemble learning algorithm. The Colour Feature Extreme Learning Machine (CF-ELM) is used in this study due to its additional ability to extract colour image features. The SCF-ELM is an ensemble learner that utilizes feature mapping via k-means clustering, a decision matrix and majority voting. It has been evaluated on a range of challenging agricultural object classification scenarios including weed, livestock and machinery detection. SCF-ELM model performance results were excellent both in terms of detection, 90 to 99% accuracy, and also inference times, around 0.01(s) per image. The SCF-ELM was able to compete or improve upon established algorithms in its class, indicating its potential for remote computing applications in agriculture.},
DOI = {10.3390/agronomy11112290}
}



@Article{electronics10222764,
AUTHOR = {Hassan, Syed-Ali and Rahim, Tariq and Shin, Soo-Young},
TITLE = {An Improved Deep Convolutional Neural Network-Based Autonomous Road Inspection Scheme Using Unmanned Aerial Vehicles},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {2764},
URL = {https://www.mdpi.com/2079-9292/10/22/2764},
ISSN = {2079-9292},
ABSTRACT = {Recent advancements in the field of machine learning (ML) provide opportunity to conduct research on autonomous devices for a variety of applications. Intelligent decision-making is a critical task for self-driving systems. An attempt is made in this study to use a deep learning (DL) approach for the early detection of road cracks, potholes, and the yellow lane. The accuracy is not sufficient after training with the default model. To enhance accuracy, a convolutional neural network (CNN) model with 13 convolutional layers, a softmax layer as an output layer, and two fully connected layers (FCN) are constructed. In order to achieve the deeper propagation and to prevent saturation in the training phase, mish activation is employed in the first 12 layers with a rectified linear unit (ReLU) activation function. The upgraded CNN model performs better than the default CNN model in terms of accuracy. For the varied situation, a revised and enriched dataset for road cracks, potholes, and the yellow lane is created. The yellow lane is detected and tracked in order to move the unmanned aerial vehicle (UAV) autonomously by following yellow lane. After identifying a yellow lane, the UAV performs autonomous navigation while concurrently detecting road cracks and potholes using the robot operating system within the UAV. The performance model is benchmarked using performance measures, such as accuracy, sensitivity, F1-score, F2-score, and dice-coefficient, which demonstrate that the suggested technique produces better outcomes.},
DOI = {10.3390/electronics10222764}
}



@Article{rs13224548,
AUTHOR = {Guffogg, Jenna A. and Blades, Samantha M. and Soto-Berelov, Mariela and Bellman, Chris J. and Skidmore, Andrew K. and Jones, Simon D.},
TITLE = {Quantifying Marine Plastic Debris in a Beach Environment Using Spectral Analysis},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4548},
URL = {https://www.mdpi.com/2072-4292/13/22/4548},
ISSN = {2072-4292},
ABSTRACT = {Marine plastic debris (MPD) is a globally relevant environmental challenge, with an estimated 8 million tons of synthetic debris entering the marine environment each year. Plastic has been found in all parts of the marine environment, including the surface layers of the ocean, within the water column, in coastal waters, on the benthic layer and on beaches. While research on detecting MPD using remote sensing is increasing, most of it focuses on detecting floating debris in open waters, rather than detecting MPD on beaches. However, beaches present challenges that are unique from other parts of the marine environment. In order to better understand the spectral properties of beached MPD, we present the SWIR reflectance of weathered MPD and virgin plastics over a sandy substrate. We conducted spectral feature analysis on the different plastic groups to better understand the impact that polymers have on our ability to detect synthetic debris at sub-pixel surface covers that occur on beaches. Our results show that the minimum surface cover required to detect MPD on a sandy surface varies between 2–8% for different polymer types. Furthermore, plastic composition affects the magnitude of spectral absorption. This suggests that variation in both surface cover and polymer type will inform the efficacy of beach litter detection methods.},
DOI = {10.3390/rs13224548}
}



@Article{app112210701,
AUTHOR = {Rosle, Rhushalshafira and Che’Ya, Nik Norasma and Ang, Yuhao and Rahmat, Fariq and Wayayok, Aimrun and Berahim, Zulkarami and Fazlil Ilahi, Wan Fazilah and Ismail, Mohd Razi and Omar, Mohamad Husni},
TITLE = {Weed Detection in Rice Fields Using Remote Sensing Technique: A Review},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10701},
URL = {https://www.mdpi.com/2076-3417/11/22/10701},
ISSN = {2076-3417},
ABSTRACT = {This paper reviewed the weed problems in agriculture and how remote sensing techniques can detect weeds in rice fields. The comparison of weed detection between traditional practices and automated detection using remote sensing platforms is discussed. The ideal stage for controlling weeds in rice fields was highlighted, and the types of weeds usually found in paddy fields were listed. This paper will discuss weed detection using remote sensing techniques, and algorithms commonly used to differentiate them from crops are deliberated. However, weed detection in rice fields using remote sensing platforms is still in its early stages; weed detection in other crops is also discussed. Results show that machine learning (ML) and deep learning (DL) remote sensing techniques have successfully produced a high accuracy map for detecting weeds in crops using RS platforms. Therefore, this technology positively impacts weed management in many aspects, especially in terms of the economic perspective. The implementation of this technology into agricultural development could be extended further.},
DOI = {10.3390/app112210701}
}



@Article{rs13224560,
AUTHOR = {Luo, Lili and Chang, Qingrui and Wang, Qi and Huang, Yong},
TITLE = {Identification and Severity Monitoring of Maize Dwarf Mosaic Virus Infection Based on Hyperspectral Measurements},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4560},
URL = {https://www.mdpi.com/2072-4292/13/22/4560},
ISSN = {2072-4292},
ABSTRACT = {Prompt monitoring of maize dwarf mosaic virus (MDMV) is critical for the prevention and control of disease and to ensure high crop yield and quality. Here, we first analyzed the spectral differences between MDMV-infected red leaves and healthy leaves and constructed a sensitive index (SI) for measurements. Next, based on the characteristic bands (Rλ) associated with leaf anthocyanins (Anth), we determined vegetation indices (VIs) commonly used in plant physiological and biochemical parameter inversion and established a vegetation index (VIc) by utilizing the combination of two arbitrary bands following the construction principles of NDVI, DVI, RVI, and SAVI. Furthermore, we developed classification models based on linear discriminant analysis (LDA) and support vector machine (SVM) in order to distinguish the red leaves from healthy leaves. Finally, we performed UR, MLR, PLSR, PCR, and SVM simulations on Anth based on Rλ, VIs, VIc, and Rλ + VIs + VIc and indirectly estimated the severity of MDMV infection based on the relationship between the reflection spectra and Anth. Distinct from those of the normal leaves, the spectra of red leaves showed strong reflectance characteristics at 640 nm, and SI increased with increasing Anth. Moreover, the accuracy of the two VIc-based classification models was 100%, which is significantly higher than that of the VIs and Rλ-based models. Among the Anth regression models, the accuracy of the MLR model based on Rλ + VIs + VIc was the highest (R2c = 0.85; R2v = 0.74). The developed models could accurately identify MDMV and estimate the severity of its infection, laying the theoretical foundation for large-scale remote sensing-based monitoring of this virus in the future.},
DOI = {10.3390/rs13224560}
}



@Article{rs13224562,
AUTHOR = {Lei, Shuhan and Luo, Jianbiao and Tao, Xiaojun and Qiu, Zixuan},
TITLE = {Remote Sensing Detecting of Yellow Leaf Disease of Arecanut Based on UAV Multisource Sensors},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4562},
URL = {https://www.mdpi.com/2072-4292/13/22/4562},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle (UAV) remote sensing technology can be used for fast and efficient monitoring of plant diseases and pests, but these techniques are qualitative expressions of plant diseases. However, the yellow leaf disease of arecanut in Hainan Province is similar to a plague, with an incidence rate of up to 90% in severely affected areas, and a qualitative expression is not conducive to the assessment of its severity and yield. Additionally, there exists a clear correlation between the damage caused by plant diseases and pests and the change in the living vegetation volume (LVV). However, the correlation between the severity of the yellow leaf disease of arecanut and LVV must be demonstrated through research. Therefore, this study aims to apply the multispectral data obtained by the UAV along with the high-resolution UAV remote sensing images to obtain five vegetation indexes such as the normalized difference vegetation index (NDVI), optimized soil adjusted vegetation index (OSAVI), leaf chlorophyll index (LCI), green normalized difference vegetation index (GNDVI), and normalized difference red edge (NDRE) index, and establish five algorithm models such as the back-propagation neural network (BPNN), decision tree, naïve Bayes, support vector machine (SVM), and k-nearest-neighbor classification to determine the severity of the yellow leaf disease of arecanut, which is expressed by the proportion of the yellowing area of a single areca crown (in percentage). The traditional qualitative expression of this disease is transformed into the quantitative expression of the yellow leaf disease of arecanut per plant. The results demonstrate that the classification accuracy of the test set of the BPNN algorithm and SVM algorithm is the highest, at 86.57% and 86.30%, respectively. Additionally, the UAV structure from motion technology is used to measure the LVV of a single areca tree and establish a model of the correlation between the LVV and the severity of the yellow leaf disease of arecanut. The results show that the relative root mean square error is between 34.763% and 39.324%. This study presents the novel quantitative expression of the severity of the yellow leaf disease of arecanut, along with the correlation between the LVV of areca and the severity of the yellow leaf disease of arecanut. Significant development is expected in the degree of integration of multispectral software and hardware, observation accuracy, and ease of use of UAVs owing to the rapid progress of spectral sensing technology and the image processing and analysis algorithms.},
DOI = {10.3390/rs13224562}
}



@Article{aerospace8110343,
AUTHOR = {Majeed, Abdul and Hwang, Seong Oun},
TITLE = {A Multi-Objective Coverage Path Planning Algorithm for UAVs to Cover Spatially Distributed Regions in Urban Environments},
JOURNAL = {Aerospace},
VOLUME = {8},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {343},
URL = {https://www.mdpi.com/2226-4310/8/11/343},
ISSN = {2226-4310},
ABSTRACT = {This paper presents a multi-objective coverage flight path planning algorithm that finds minimum length, collision-free, and flyable paths for unmanned aerial vehicles (UAV) in three-dimensional (3D) urban environments inhabiting multiple obstacles for covering spatially distributed regions. In many practical applications, UAVs are often required to fully cover multiple spatially distributed regions located in the 3D urban environments while avoiding obstacles. This problem is relatively complex since it requires the optimization of both inter (e.g., traveling from one region/city to another) and intra-regional (e.g., within a region/city) paths. To solve this complex problem, we find the traversal order of each area of interest (AOI) in the form of a coarse tour (i.e., graph) with the help of an ant colony optimization (ACO) algorithm by formulating it as a traveling salesman problem (TSP) from the center of each AOI, which is subsequently optimized. The intra-regional path finding problem is solved with the integration of fitting sensors’ footprints sweeps (SFS) and sparse waypoint graphs (SWG) in the AOI. To find a path that covers all accessible points of an AOI, we fit fewer, longest, and smooth SFSs in such a way that most parts of an AOI can be covered with fewer sweeps. Furthermore, the low-cost traversal order of each SFS is computed, and SWG is constructed by connecting the SFSs while respecting the global and local constraints. It finds a global solution (i.e., inter + intra-regional path) without sacrificing the guarantees on computing time, number of turning maneuvers, perfect coverage, path overlapping, and path length. The results obtained from various representative scenarios show that proposed algorithm is able to compute low-cost coverage paths for UAV navigation in urban environments.},
DOI = {10.3390/aerospace8110343}
}



@Article{app112210733,
AUTHOR = {Papadopoulou, Ermioni-Eirini and Papakonstantinou, Apostolos and Zouros, Nikolaos and Soulakellis, Nikolaos},
TITLE = {Scale-Variant Flight Planning for the Creation of 3D Geovisualization and Augmented Reality Maps of Geosites: The Case of Voulgaris Gorge, Lesvos, Greece},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10733},
URL = {https://www.mdpi.com/2076-3417/11/22/10733},
ISSN = {2076-3417},
ABSTRACT = {The purpose of this paper was to study the influence of cartographic scale and flight design on data acquisition using unmanned aerial systems (UASs) to create augmented reality 3D geovisualization of geosites. The relationship between geographical and cartographic scales, the spatial resolution of UAS-acquired images, along with their relationship with the produced 3D models of geosites, were investigated. Additionally, the lighting of the produced 3D models was examined as a key visual variable in the 3D space. Furthermore, the adaptation of the 360° panoramas as environmental lighting parameters was considered. The geosite selected as a case study was the gorge of the river Voulgaris in the western part of the island of Lesvos, which is located in the northeastern part of the Aegean Sea in Greece. The methodology applied consisted of four pillars: (i) scale-variant flight planning, (ii) data acquisition, (iii) data processing, (iv) AR, 3D geovisualization. Based on the geographic and cartographic scales, the flight design calculates the most appropriate flight parameters (height, speed, and image overlaps) to achieve the desired spatial resolution (3 cm) capable of illustrating all the scale-variant details of the geosite when mapped in 3D. High-resolution oblique aerial images and 360° panoramic aerial images were acquired using scale-variant flight plans. The data were processed using image processing algorithms to produce 3D models and create mosaic panoramas. The 3D geovisualization of the geosite selected was created using the textured 3D model produced from the aerial images. The panoramic images were converted to high-dynamic-range image (HDRI) panoramas and used as a background to the 3D model. The geovisualization was transferred and displayed in the virtual space where the panoramas were used as a light source, thus enlightening the model. Data acquisition and flight planning were crucial scale-variant steps in the 3D geovisualization. These two processes comprised the most important factors in 3D geovisualization creation embedded in the virtual space as they designated the geometry of the 3D model. The use of panoramas as the illumination parameter of an outdoor 3D scene of a geosite contributed significantly to its photorealistic performance into the 3D augmented reality and virtual space.},
DOI = {10.3390/app112210733}
}



@Article{agriculture11111142,
AUTHOR = {Song, Huan and Hu, Yongguang and Lu, Yongzong and Wang, Jizhang and Pan, Qingmin and Li, Pingping},
TITLE = {A Review of Methods and Techniques for Detecting Frost on Plant Surfaces},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {1142},
URL = {https://www.mdpi.com/2077-0472/11/11/1142},
ISSN = {2077-0472},
ABSTRACT = {Severe frost usually has adverse impacts on agricultural production, resulting in crop freeze injury, poor crop yield, and crop quality reduction. Timely and accurate detection of frost plays an important role in cold damage warnings, prevention, and control. Current frost detection methods mostly use physical properties such as light, electricity, and heat, or the judge and quantify using environmental factors such as temperature and wind speed. However, it is difficult to detect and accurately identify the frosting phenomenon in real time during field trials because of the complex environment, different plant types, and interference by many factors during observation. To provide an overview of the analytical tools for scientists, researchers, and product developers, a review and comparative analysis of the available literature on frost mechanisms, correlations, and characteristics are presented in this study. First, the mechanisms of the frost formation process, frost level, and the significance of detection, are introduced. Then, the methods and techniques used to measure frost on plant surfaces are synthetically classified and further compared. Moreover, the key points and difficulties are summarized and discussed. Finally, some constructive methods of frost detection are proposed to improve the frost detection process.},
DOI = {10.3390/agriculture11111142}
}



@Article{computers10110153,
AUTHOR = {Tashtoush, Yahya and Haj-Mahmoud, Israa and Darwish, Omar and Maabreh, Majdi and Alsinglawi, Belal and Elkhodr, Mahmoud and Alsaedi, Nasser},
TITLE = {Enhancing Robots Navigation in Internet of Things Indoor Systems},
JOURNAL = {Computers},
VOLUME = {10},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {153},
URL = {https://www.mdpi.com/2073-431X/10/11/153},
ISSN = {2073-431X},
ABSTRACT = {In this study, an effective local minima detection and definition algorithm is introduced for a mobile robot navigating through unknown static environments. Furthermore, five approaches are presented and compared with the popular approach wall-following to pull the robot out of the local minima enclosure namely; Random Virtual Target, Reflected Virtual Target, Global Path Backtracking, Half Path Backtracking, and Local Path Backtracking. The proposed approaches mainly depend on changing the target location temporarily to avoid the original target&rsquo;s attraction force effect on the robot. Moreover, to avoid getting trapped in the same location, a virtual obstacle is placed to cover the local minima enclosure. To include the most common shapes of deadlock situations, the proposed approaches were evaluated in four different environments; V-shaped, double U-shaped, C-shaped, and cluttered environments. The results reveal that the robot, using any of the proposed approaches, requires fewer steps to reach the destination, ranging from 59 to 73 m on average, as opposed to the wall-following strategy, which requires an average of 732 m. On average, the robot with a constant speed and reflected virtual target approach takes 103 s, whereas the identical robot with a wall-following approach takes 907 s to complete the tasks. Using a fuzzy-speed robot, the duration for the wall-following approach is greatly reduced to 507 s, while the reflected virtual target may only need up to 20% of that time. More results and detailed comparisons are embedded in the subsequent sections.},
DOI = {10.3390/computers10110153}
}



@Article{rs13224606,
AUTHOR = {Eide, Austin and Koparan, Cengiz and Zhang, Yu and Ostlie, Michael and Howatt, Kirk and Sun, Xin},
TITLE = {UAV-Assisted Thermal Infrared and Multispectral Imaging of Weed Canopies for Glyphosate Resistance Detection},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4606},
URL = {https://www.mdpi.com/2072-4292/13/22/4606},
ISSN = {2072-4292},
ABSTRACT = {The foundation of contemporary weed management practices in many parts of the world is glyphosate. However, dependency on the effectiveness of herbicide practices has led to overuse through continuous growth of crops resistant to a single mode of action. In order to provide a cost-effective weed management strategy that does not promote glyphosate-resistant weed biotypes, differences between resistant and susceptible biotypes have to be identified accurately in the field conditions. Unmanned Aerial Vehicle (UAV)-assisted thermal and multispectral remote sensing has potential for detecting biophysical characteristics of weed biotypes during the growing season, which includes distinguishing glyphosate-susceptible and glyphosate-resistant weed populations based on canopy temperature and deep learning driven weed identification algorithms. The objective of this study was to identify herbicide resistance after glyphosate application in true field conditions by analyzing the UAV-acquired thermal and multispectral response of kochia, waterhemp, redroot pigweed, and common ragweed. The data were processed in ArcGIS for raster classification as well as spectral comparison of glyphosate-resistant and glyphosate-susceptible weeds. The classification accuracy between the sensors and classification methods of maximum likelihood, random trees, and Support Vector Machine (SVM) were compared. The random trees classifier performed the best at 4 days after application (DAA) for kochia with 62.9% accuracy. The maximum likelihood classifier provided the highest performing result out of all classification methods with an accuracy of 75.2%. A commendable classification was made at 8 DAA where the random trees classifier attained an accuracy of 87.2%. However, thermal reflectance measurements as a predictor for glyphosate resistance within weed populations in field condition was unreliable due to its susceptibility to environmental conditions. Normalized Difference Vegetation Index (NDVI) and a composite reflectance of 842 nm, 705 nm, and 740 nm wavelength managed to provide better classification results than thermal in most cases.},
DOI = {10.3390/rs13224606}
}



@Article{rs13224609,
AUTHOR = {Pan, Baihong and Zheng, Yi and Shen, Ruoque and Ye, Tao and Zhao, Wenzhi and Dong, Jie and Ma, Hanqing and Yuan, Wenping},
TITLE = {High Resolution Distribution Dataset of Double-Season Paddy Rice in China},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4609},
URL = {https://www.mdpi.com/2072-4292/13/22/4609},
ISSN = {2072-4292},
ABSTRACT = {Although China is the largest producer of rice, accounting for about 25% of global production, there are no high-resolution maps of paddy rice covering the entire country. Using time-weighted dynamic time warping (TWDTW), this study developed a pixel- and phenology-based method to identify planting areas of double-season paddy rice in China, by comparing temporal variations of synthetic aperture radar (SAR) signals of unknown pixels to those of known double-season paddy rice fields. We conducted a comprehensive evaluation of the method’s performance at pixel and regional scales. Based on 145,210 field surveyed samples from 2018 to 2020, the producer’s and user’s accuracy are 88.49% and 87.02%, respectively. Compared to county-level statistical data from 2016 to 2019, the relative mean absolute errors are 34.11%. This study produced distribution maps of double-season rice at 10 m spatial resolution from 2016 to 2020 over nine provinces in South China, which account for more than 99% of the planting areas of double-season paddy rice of China. The maps are expected to contribute to timely monitoring and evaluating rice growth and yield.},
DOI = {10.3390/rs13224609}
}



@Article{jimaging7110241,
AUTHOR = {Moussaid, Abdellatif and Fkihi, Sanaa El and Zennayi, Yahya},
TITLE = {Tree Crowns Segmentation and Classification in Overlapping Orchards Based on Satellite Images and Unsupervised Learning Algorithms},
JOURNAL = {Journal of Imaging},
VOLUME = {7},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {241},
URL = {https://www.mdpi.com/2313-433X/7/11/241},
PubMedID = {34821872},
ISSN = {2313-433X},
ABSTRACT = {Smart agriculture is a new concept that combines agriculture and new technologies to improve the yield’s quality and quantity as well as facilitate many tasks for farmers in managing orchards. An essential factor in smart agriculture is tree crown segmentation, which helps farmers automatically monitor their orchards and get information about each tree. However, one of the main problems, in this case, is when the trees are close to each other, which means that it would be difficult for the algorithm to delineate the crowns correctly. This paper used satellite images and machine learning algorithms to segment and classify trees in overlapping orchards. The data used are images from the Moroccan Mohammed VI satellite, and the study region is the OUARGHA citrus orchard located in Morocco. Our approach starts by segmenting the rows inside the parcel and finding all the trees there, getting their canopies, and classifying them by size. In general, the model inputs the parcel’s image and other field measurements to classify the trees into three classes: missing/weak, normal, or big. Finally, the results are visualized in a map containing all the trees with their classes. For the results, we obtained a score of 0.93 F-measure in rows segmentation. Additionally, several field comparisons were performed to validate the classification, dozens of trees were compared and the results were very good. This paper aims to help farmers to quickly and automatically classify trees by crown size, even if there are overlapping orchards, in order to easily monitor each tree’s health and understand the tree’s distribution in the field.},
DOI = {10.3390/jimaging7110241}
}



@Article{sym13112190,
AUTHOR = {Hashim, Wahidah and Eng, Lim Soon and Alkawsi, Gamal and Ismail, Rozita and Alkahtani, Ammar Ahmed and Dzulkifly, Sumayyah and Baashar, Yahia and Hussain, Azham},
TITLE = {A Hybrid Vegetation Detection Framework: Integrating Vegetation Indices and Convolutional Neural Network},
JOURNAL = {Symmetry},
VOLUME = {13},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2190},
URL = {https://www.mdpi.com/2073-8994/13/11/2190},
ISSN = {2073-8994},
ABSTRACT = {Vegetation inspection and monitoring is a time-consuming task. In the era of industrial revolution 4.0 (IR 4.0), unmanned aerial vehicles (UAV), commercially known as drones, are in demand, being adopted for vegetation inspection and monitoring activities. However, most off-the-shelf drones are least favoured by vegetation maintenance departments for on-site inspection due to limited spectral bands camera restricting advanced vegetation analysis. Most of these drones are normally equipped with a normal red, green, and blue (RGB) camera. Additional spectral bands are found to produce more accurate analysis during vegetation inspection, but at the cost of advanced camera functionalities, such as multispectral camera. Vegetation indices (VI) is a technique to maximize detection sensitivity related to vegetation characteristics while minimizing other factors which are not categorised otherwise. The emergence of machine learning has slowly influenced the existing vegetation analysis technique in order to improve detection accuracy. This study focuses on exploring VI techniques in identifying vegetation objects. The selected VIs investigated are Visible Atmospheric Resistant Index (VARI), Green Leaf Index (GLI), and Vegetation Index Green (VIgreen). The chosen machine learning technique is You Only Look Once (YOLO), which is a clever convolutional neural network (CNN) offering object detection in real time. The CNN model has a symmetrical structure along the direction of the tensor flow. Several series of data collection have been conducted at identified locations to obtain aerial images. The proposed hybrid methods were tested on captured aerial images to observe vegetation detection performance. Segmentation in image analysis is a process to divide the targeted pixels for further detection testing. Based on our findings, more than 70% of the vegetation objects in the images were accurately detected, which reduces the misdetection issue faced by previous VI techniques. On the other hand, hybrid segmentation methods perform best with the combination of VARI and YOLO at 84% detection accuracy.},
DOI = {10.3390/sym13112190}
}



@Article{s21227629,
AUTHOR = {Ahmad, Muhammad Ikmal and Ab. Rahim, Mohd Hafizi and Nordin, Rosdiadee and Mohamed, Faizal and Abu-Samah, Asma’ and Abdullah, Nor Fadzilah},
TITLE = {Ionizing Radiation Monitoring Technology at the Verge of Internet of Things},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7629},
URL = {https://www.mdpi.com/1424-8220/21/22/7629},
PubMedID = {34833705},
ISSN = {1424-8220},
ABSTRACT = {As nuclear technology evolves, and continues to be used in various fields since its discovery less than a century ago, radiation safety has become a major concern to humans and the environment. Radiation monitoring plays a significant role in preventive radiological nuclear detection in nuclear facilities, hospitals, or in any activities associated with radioactive materials by acting as a tool to measure the risk of being exposed to radiation while reaping its benefit. Apart from in occupational settings, radiation monitoring is required in emergency responses to radiation incidents as well as outdoor radiation zones. Several radiation sensors have been developed, ranging from as simple as a Geiger-Muller counter to bulkier radiation systems such as the High Purity Germanium detector, with different functionality for use in different settings, but the inability to provide real-time data makes radiation monitoring activities less effective. The deployment of manned vehicles equipped with these radiation sensors reduces the scope of radiation monitoring operations significantly, but the safety of radiation monitoring operators is still compromised. Recently, the Internet of Things (IoT) technology has been introduced to the world and offered solutions to these limitations. This review elucidates a systematic understanding of the fundamental usage of the Internet of Drones for radiation monitoring purposes. The extension of essential functional blocks in IoT can be expanded across radiation monitoring industries, presenting several emerging research opportunities and challenges. This article offers a comprehensive review of the evolutionary application of IoT technology in nuclear and radiation monitoring. Finally, the security of the nuclear industry is discussed.},
DOI = {10.3390/s21227629}
}



@Article{app112210848,
AUTHOR = {Koteleva, Natalia and Khokhlov, Sergei and Frenkel, Ilia},
TITLE = {Digitalization in Open-Pit Mining: A New Approach in Monitoring and Control of Rock Fragmentation},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10848},
URL = {https://www.mdpi.com/2076-3417/11/22/10848},
ISSN = {2076-3417},
ABSTRACT = {Mining enterprises are widely introducing digital technologies and automation is one of such tools. Granularity monitoring, namely, the size determination of rock mass pieces is a common operational component of the processes that extract minerals by open-pit mining. The article proposes an approach that, in addition to the lump size distribution, makes it possible to estimate the lump form distribution as well. To investigate the effectiveness of monitoring the form of blasted rock mass lumps, the authors conducted experiments in four stages related to the rock condition. They include geological occurrence, explosive crushing, trommelling, and mill crushing. The relationship between these stages is presented and the change in the lumps fragment form is traced. The present article proposes an informational and analytical model of the processes at mining enterprises, extracting minerals by open-pit mining, as well as an algorithm for determining the lumps form and obtaining their distribution in the rock mass.},
DOI = {10.3390/app112210848}
}



@Article{rs13224632,
AUTHOR = {Teodoro, Paulo Eduardo and Teodoro, Larissa Pereira Ribeiro and Baio, Fábio Henrique Rojo and da Silva Junior, Carlos Antonio and dos Santos, Regimar Garcia and Ramos, Ana Paula Marques and Pinheiro, Mayara Maezano Faita and Osco, Lucas Prado and Gonçalves, Wesley Nunes and Carneiro, Alexsandro Monteiro and Junior, José Marcato and Pistori, Hemerson and Shiratsuchi, Luciano Shozo},
TITLE = {Predicting Days to Maturity, Plant Height, and Grain Yield in Soybean: A Machine and Deep Learning Approach Using Multispectral Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4632},
URL = {https://www.mdpi.com/2072-4292/13/22/4632},
ISSN = {2072-4292},
ABSTRACT = {In soybean, there is a lack of research aiming to compare the performance of machine learning (ML) and deep learning (DL) methods to predict more than one agronomic variable, such as days to maturity (DM), plant height (PH), and grain yield (GY). As these variables are important to developing an overall precision farming model, we propose a machine learning approach to predict DM, PH, and GY for soybean cultivars based on multispectral bands. The field experiment considered 524 genotypes of soybeans in the 2017/2018 and 2018/2019 growing seasons and a multitemporal–multispectral dataset collected by embedded sensor in an unmanned aerial vehicle (UAV). We proposed a multilayer deep learning regression network, trained during 2000 epochs using an adaptive subgradient method, a random Gaussian initialization, and a 50% dropout in the first hidden layer for regularization. Three different scenarios, including only spectral bands, only vegetation indices, and spectral bands plus vegetation indices, were adopted to infer each variable (PH, DM, and GY). The DL model performance was compared against shallow learning methods such as random forest (RF), support vector machine (SVM), and linear regression (LR). The results indicate that our approach has the potential to predict soybean-related variables using multispectral bands only. Both DL and RF models presented a strong (r surpassing 0.77) prediction capacity for the PH variable, regardless of the adopted input variables group. Our results demonstrated that the DL model (r = 0.66) was superior to predict DM when the input variable was the spectral bands. For GY, all machine learning models evaluated presented similar performance (r ranging from 0.42 to 0.44) for each tested scenario. In conclusion, this study demonstrated an efficient approach to a computational solution capable of predicting multiple important soybean crop variables based on remote sensing data. Future research could benefit from the information presented here and be implemented in subsequent processes related to soybean cultivars or other types of agronomic crops.},
DOI = {10.3390/rs13224632}
}



@Article{rs13224643,
AUTHOR = {Liu, Jinhua and Ding, Jianli and Ge, Xiangyu and Wang, Jingzhe},
TITLE = {Evaluation of Total Nitrogen in Water via Airborne Hyperspectral Data: Potential of Fractional Order Discretization Algorithm and Discrete Wavelet Transform Analysis},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4643},
URL = {https://www.mdpi.com/2072-4292/13/22/4643},
ISSN = {2072-4292},
ABSTRACT = {Controlling and managing surface source pollution depends on the rapid monitoring of total nitrogen in water. However, the complex factors affecting water quality (plant shading and suspended matter in water) make direct estimation extremely challenging. Considering the spectral response mechanisms of emergent plants, we coupled discrete wavelet transform (DWT) and fractional order discretization (FOD) techniques with three machine learning models (random forest (RF), bagging algorithm (bagging), and eXtreme Gradient Boosting (XGBoost)) to mine this potential spectral information. A total of 567 models were developed, and airborne hyperspectral data processed with various DWT scales and FOD techniques were compared. The effective information in the hyperspectral reflectance data were better emphasized after DWT processing. After DWT processing the original spectrum (OR), its sensitivity to TN in water was maximally improved by 0.22, and the correlation between FOD and TN in water was optimally increased by 0.57. The transformed spectral information enhanced the TN model accuracy, especially for FOD after DWT. For RF, 82% of the model R2 values improved by 0.02~0.72 compared to the model using FOD spectra; 78.8% of the bagging values improved by 0.01~0.53 and 65.0% of the XGBoost values improved by 0.01~0.64. The XGBoost model with DWT coupled with grey relation analysis (GRA) yielded the best estimation accuracy, with the highest precision of R2 = 0.91 for L6. In conclusion, appropriately scaled DWT analysis can substantially improve the accuracy of extracting TN from UAV hyperspectral images. These outcomes may facilitate the further development of accurate water quality monitoring in sophisticated global waters from drone or satellite hyperspectral data.},
DOI = {10.3390/rs13224643}
}



@Article{rs13224645,
AUTHOR = {Pu, Ge and Quackenbush, Lindi J. and Stehman, Stephen V.},
TITLE = {Identifying Factors That Influence Accuracy of Riparian Vegetation Classification and River Channel Delineation Mapped Using 1 m Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4645},
URL = {https://www.mdpi.com/2072-4292/13/22/4645},
ISSN = {2072-4292},
ABSTRACT = {Riparian vegetation delineation includes both the process of delineating the riparian zone and classifying vegetation within that zone. We developed a holistic framework to assess riparian vegetation delineation that includes evaluating channel boundary delineation accuracy using a combination of pixel- and object-based metrics. We also identified how stream order, riparian zone width, riparian land use, and image shadow influenced the accuracy of delineation and classification. We tested the framework by evaluating vegetation vs. non-vegetation riparian zone maps produced by applying random forest classification to aerial photographs with a 1 m pixel size. We assessed accuracy of the riparian vegetation classification and channel boundary delineation for two rivers in the northeastern United States. Overall accuracy for the channel boundary delineation was generally above 80% for both sites, while object-based accuracy revealed that 50% of delineated channel was less than 5 m away from the reference channel. Stream order affected channel boundary delineation accuracy while land use and image shadows influenced riparian vegetation classification accuracy; riparian zone width had little impact on observed accuracy. The holistic approach to quantification of accuracy that considers both channel boundary delineation and vegetation classification developed in this study provides an important tool to inform riparian management.},
DOI = {10.3390/rs13224645}
}



@Article{asi4040094,
AUTHOR = {Kim, In Bae and Cho, Jun Sang and Zi, Goang Seup and Cho, Beom Seok and Lee, Seon Min and Kim, Hyoung Uk},
TITLE = {Detection and Identification of Expansion Joint Gap of Road Bridges by Machine Learning Using Line-Scan Camera Images},
JOURNAL = {Applied System Innovation},
VOLUME = {4},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {94},
URL = {https://www.mdpi.com/2571-5577/4/4/94},
ISSN = {2571-5577},
ABSTRACT = {Recently, the lack of expansion joint gaps on highway bridges in Korea has been increasing. In particular, with the increase in the number of days during the summer heatwave, the narrowing of the expansion joint gap causes symptoms such as expansion joint damage and pavement blow-up, which threaten traffic safety and structural safety. Therefore, in this study, we developed a machine vision (M/V)-technique-based inspection system that can monitor the expansion joint gap through image analysis while driving at high speed (100 km/h), replacing the current manual method that uses an inspector to inspect the expansion joint gap. To fix the error factors of image analysis that happened during the trial application, a machine learning method was used to improve the accuracy of measuring the gap between the expansion joint device. As a result, the expansion gap identification accuracy was improved by 27.5%, from 67.5% to 95.0%, and the use of the system reduces the survey time by more than 95%, from an average of approximately 1 h/bridge (existing manual inspection method) to approximately 3 min/bridge. We assume, in the future, maintenance practitioners can contribute to preventive maintenance that prepares countermeasures before problems occur.},
DOI = {10.3390/asi4040094}
}



@Article{math9222947,
AUTHOR = {Romanov, Anton A. and Filippov, Aleksey A. and Voronina, Valeria V. and Guskov, Gleb and Yarushkina, Nadezhda G.},
TITLE = {Modeling the Context of the Problem Domain of Time Series with Type-2 Fuzzy Sets},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {2947},
URL = {https://www.mdpi.com/2227-7390/9/22/2947},
ISSN = {2227-7390},
ABSTRACT = {Data analysis in the context of the features of the problem domain and the dynamics of processes are significant in various industries. Uncertainty modeling based on fuzzy logic allows building approximators for solving a large class of problems. In some cases, type-2 fuzzy sets in the model are used. The article describes constructing fuzzy time series models of the analyzed processes within the context of the problem domain. An algorithm for fuzzy modeling of the time series was developed. A new time series forecasting scheme is proposed. An illustrative example of the time series modeling is presented. The benefits of contextual modeling are demonstrated.},
DOI = {10.3390/math9222947}
}



@Article{rs13224657,
AUTHOR = {Hologa, Rafael and Scheffczyk, Konstantin and Dreiser, Christoph and Gärtner, Stefanie},
TITLE = {Tree Species Classification in a Temperate Mixed Mountain Forest Landscape Using Random Forest and Multiple Datasets},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4657},
URL = {https://www.mdpi.com/2072-4292/13/22/4657},
ISSN = {2072-4292},
ABSTRACT = {For monitoring protected forest landscapes over time it is essential to follow changes in tree species composition and forest dynamics. Data driven remote sensing methods provide valuable options if terrestrial approaches for forest inventories and monitoring activities cannot be applied efficiently due to restrictions or the size of the study area. We demonstrate how species can be detected at a single tree level utilizing a Random Forest (RF) model using the Black Forest National Park as an example of a Central European forest landscape with complex relief. The classes were European silver fir (Abies alba, AA), Norway spruce (Picea abies, PA), Scots pine (Pinus sylvestris, PS), European larch (Larix decidua including Larix kampferii, LD), Douglas fir (Pseudotsuga menziesii, PM), deciduous broadleaved species (DB) and standing dead trees (snags, WD). Based on a multi-temporal (leaf-on and leaf-off phenophase) and multi-spectral mosaic (R-G-B-NIR) with 10 cm spatial resolution, digital elevation models (DTM, DSM, CHM) with 40 cm spatial resolution and a LiDAR dataset with 25 pulses per m2, 126 variables were derived and used to train the RF algorithm with 1130 individual trees. The main objective was to determine a subset of meaningful variables for the RF model classification on four heterogeneous test sites. Using feature selection techniques, mainly passive optical variables from the leaf-off phenophase were considered due to their ability to differentiate between conifers and the two broader classes. An examination of the two phenological phases (using the difference of the respective NDVIs) is important to clearly distinguish deciduous trees from other classes including snags (WD). We also found that the variables of the first derivation of NIR and the tree metrics play a crucial role in discriminating PA und PS. With this unique set of variables some classes can be differentiated more reliably, especially LD and DB but also AA, PA and WD, whereas difficulties exist in identifying PM and PS. Overall, the non-parametric object-based approach has proved to be highly suitable for accurately detecting (OA: 89.5%) of the analyzed classes. Finally, the successful classification of complex 265 km2 study area substantiates our findings.},
DOI = {10.3390/rs13224657}
}



@Article{rs13224666,
AUTHOR = {Wei, Haodong and Hu, Qiong and Cai, Zhiwen and Yang, Jingya and Song, Qian and Yin, Gaofei and Xu, Baodong},
TITLE = {An Object- and Topology-Based Analysis (OTBA) Method for Mapping Rice-Crayfish Fields in South China},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4666},
URL = {https://www.mdpi.com/2072-4292/13/22/4666},
ISSN = {2072-4292},
ABSTRACT = {The rice-crayfish field (i.e., RCF), a newly emerging rice cultivation pattern, has greatly expanded in China in the last decade due to its significant ecological and economic benefits. The spatial distribution of RCFs is an important dataset for crop planting pattern adjustment, water resource management and yield estimation. Here, an object- and topology-based analysis (OTBA) method, which considers spectral-spatial features and the topological relationship between paddy fields and their enclosed ditches, was proposed to identify RCFs. First, we employed an object-based method to extract crayfish breeding ditches using very high-resolution images. Subsequently, the paddy fields that provide fodder for crayfish were identified according to the topological relationship between the paddy field and circumjacent crayfish ditch. The extracted ditch objects together with those paddy fields were merged to derive the final RCFs. The performance of the OTBA method was carefully evaluated using the RCF and non-RCF samples. Moreover, the effects of different spatial resolutions, spectral bands and temporal information on RCF identification were comprehensively investigated. Our results suggest the OTBA method performed well in extracting RCFs, with an overall accuracy of 91.77%. Although the mapping accuracies decreased as the image spatial resolution decreased, satisfactory RCF mapping results (&gt;80%) can be achieved at spatial resolutions greater than 2 m. Additionally, we demonstrated that the mapping accuracy can be improved by more than 10% when near-infrared (NIR) band information was involved, indicating the necessity of the NIR band when selecting images to derive reliable RCF maps. Furthermore, the images acquired in the rice growth phase are recommended to maximize the differences of spectral characteristics between paddy fields and ditches. These promising findings suggest that the OTBA approach performs well for mapping RCFs in areas with fragmented agricultural landscapes, which provides fundamental information for further agricultural land use and water resources management.},
DOI = {10.3390/rs13224666}
}



@Article{app112211067,
AUTHOR = {Sun, Hui and Jia, Hongguang and Wang, Lina and Xu, Fang and Liu, Jinghong},
TITLE = {Systematic Error Correction for Geo-Location of Airborne Optoelectronic Platforms},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {11067},
URL = {https://www.mdpi.com/2076-3417/11/22/11067},
ISSN = {2076-3417},
ABSTRACT = {In order to improve the geo-location accuracy of the airborne optoelectronic platform and eliminate the influence of assembly systematic error on the accuracy, a systematic geo-location error correction method is proposed. First, based on the kinematic characteristics of the airborne optoelectronic platform, the geo-location model was established. Then, the error items that affect the geo-location accuracy were analyzed. The installation error between the platform and the POS was considered, and the installation error of platform&rsquo;s pitch and azimuth was introduced. After ignoring higher-order infinitesimals, the least square form of systematic error is obtained. Therefore, the systematic error can be obtained through a series of measurements. Both Monte Carlo simulation analysis and in-flight experiment results show that this method can effectively obtain the systematic error. Through correction, the root-mean-square value of the geo-location error have reduced from 45.65 m to 12.62 m, and the mean error from 16.60 m to 1.24 m. This method can be widely used in systematic error correction of relevant photoelectric equipment.},
DOI = {10.3390/app112211067}
}



@Article{math9222984,
AUTHOR = {Joshi, Gyanendra Prasad and Alenezi, Fayadh and Thirumoorthy, Gopalakrishnan and Dutta, Ashit Kumar and You, Jinsang},
TITLE = {Ensemble of Deep Learning-Based Multimodal Remote Sensing Image Classification Model on Unmanned Aerial Vehicle Networks},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {2984},
URL = {https://www.mdpi.com/2227-7390/9/22/2984},
ISSN = {2227-7390},
ABSTRACT = {Recently, unmanned aerial vehicles (UAVs) have been used in several applications of environmental modeling and land use inventories. At the same time, the computer vision-based remote sensing image classification models are needed to monitor the modifications over time such as vegetation, inland water, bare soil or human infrastructure regardless of spectral, spatial, temporal, and radiometric resolutions. In this aspect, this paper proposes an ensemble of DL-based multimodal land cover classification (EDL-MMLCC) models using remote sensing images. The EDL-MMLCC technique aims to classify remote sensing images into the different cloud, shades, and land cover classes. Primarily, median filtering-based preprocessing and data augmentation techniques take place. In addition, an ensemble of DL models, namely VGG-19, Capsule Network (CapsNet), and MobileNet, is used for feature extraction. In addition, the training process of the DL models can be enhanced by the use of hosted cuckoo optimization (HCO) algorithm. Finally, the salp swarm algorithm (SSA) with regularized extreme learning machine (RELM) classifier is applied for land cover classification. The design of the HCO algorithm for hyperparameter optimization and SSA for parameter tuning of the RELM model helps to increase the classification outcome to a maximum level considerably. The proposed EDL-MMLCC technique is tested using an Amazon dataset from the Kaggle repository. The experimental results pointed out the promising performance of the EDL-MMLCC technique over the recent state of art approaches.},
DOI = {10.3390/math9222984}
}



@Article{rs13234729,
AUTHOR = {Shashikant, Veena and Mohamed Shariff, Abdul Rashid and Wayayok, Aimrun and Kamal, Md Rowshon and Lee, Yang Ping and Takeuchi, Wataru},
TITLE = {Comparison of Field and SAR-Derived Descriptors in the Retrieval of Soil Moisture from Oil Palm Crops Using PALSAR-2},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4729},
URL = {https://www.mdpi.com/2072-4292/13/23/4729},
ISSN = {2072-4292},
ABSTRACT = {Synthetic-aperture radar&rsquo;s (SAR&rsquo;s) capacity to resolve the cloud cover concerns encountered while gathering optical data has tremendous potential for soil moisture data retrieval using SAR data. It is possible to use SAR data to recover soil moisture because the backscatter coefficient is sensitive to both soil and vegetation by penetrating through the vegetation layer. This study investigated the feasibility of employing a SAR-derived radar vegetation index (RVI), the ratios of the backscatter coefficients using polarizations of HH/HV (RHH/HV) and HV/HH (RHH/HV) to an oil palm crops as vegetation indicators in the water cloud model (WCM) using phased-array L-band SAR-2 (PALSAR-2). These data were compared to the manual leaf area index (LAI) and a physical soil sampling method for computing soil moisture. The field data included the LAI input parameters and, more importantly, physical soil samples from which to calculate the soil moisture. The fieldwork was carried out in Chuping District, Perlis State, Malaysia. Corresponding PALSAR-2 data were collected on three observation dates in 2019: 17 January, 16 April, and 9 July. The results showed that the WCM modeled using the LAI under HV polarization demonstrated promising accuracy, with the root mean square error recorded as 0.033 m3/m3. This was comparable to the RVI and RHH/HV under HV polarization, which had accuracies of 0.031 and 0.049 m3/m3, respectively. The findings of this study suggest that SAR-based indicators, RHH/HV and RVI using PALSAR-2, can be used to reduce field-related input in the retrieval of soil moisture data using the WCM for oil palm crop.},
DOI = {10.3390/rs13234729}
}



@Article{earth2040060,
AUTHOR = {Contreras, Diana and Wilkinson, Sean and James, Philip},
TITLE = {Earthquake Reconnaissance Data Sources, a Literature Review},
JOURNAL = {Earth},
VOLUME = {2},
YEAR = {2021},
NUMBER = {4},
PAGES = {1006--1037},
URL = {https://www.mdpi.com/2673-4834/2/4/60},
ISSN = {2673-4834},
ABSTRACT = {Earthquakes are one of the most catastrophic natural phenomena. After an earthquake, earthquake reconnaissance enables effective recovery by collecting data on building damage and other impacts. This paper aims to identify state-of-the-art data sources for building damage assessment and provide guidance for more efficient data collection. We have reviewed 39 articles that indicate the sources used by different authors to collect data related to damage and post-disaster recovery progress after earthquakes between 2014 and 2021. The current data collection methods have been grouped into seven categories: fieldwork or ground surveys, omnidirectional imagery (OD), terrestrial laser scanning (TLS), remote sensing (RS), crowdsourcing platforms, social media (SM) and closed-circuit television videos (CCTV). The selection of a particular data source or collection technique for earthquake reconnaissance includes different criteria depending on what questions are to be answered by these data. We conclude that modern reconnaissance missions cannot rely on a single data source. Different data sources should complement each other, validate collected data or systematically quantify the damage. The recent increase in the number of crowdsourcing and SM platforms used to source earthquake reconnaissance data demonstrates that this is likely to become an increasingly important data source.},
DOI = {10.3390/earth2040060}
}



@Article{electronics10232893,
AUTHOR = {Kakhani, Nafiseh and Mokhtarzade, Mehdi and Valadan Zoej, Mohammad Javad},
TITLE = {Deep Learning Spatial-Spectral Classification of Remote Sensing Images by Applying Morphology-Based Differential Extinction Profile (DEP)},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {2893},
URL = {https://www.mdpi.com/2079-9292/10/23/2893},
ISSN = {2079-9292},
ABSTRACT = {Since the technology of remote sensing has been improved recently, the spatial resolution of satellite images is getting finer. This enables us to precisely analyze the small complex objects in a scene through remote sensing images. Thus, the need to develop new, efficient algorithms like spatial-spectral classification methods is growing. One of the most successful approaches is based on extinction profile (EP), which can extract contextual information from remote sensing data. Moreover, deep learning classifiers have drawn attention in the remote sensing community in the past few years. Recent progress has shown the effectiveness of deep learning at solving different problems, particularly segmentation tasks. This paper proposes a novel approach based on a new concept, which is differential extinction profile (DEP). DEP makes it possible to have an input feature vector with both spectral and spatial information. The input vector is then fed into a proposed straightforward deep-learning-based classifier to produce a thematic map. The approach is carried out on two different urban datasets from Pleiades and World-View 2 satellites. In order to prove the capabilities of the suggested approach, we compare the final results to the results of other classification strategies with different input vectors and various types of common classifiers, such as support vector machine (SVM) and random forests (RF). It can be concluded that the proposed approach is significantly improved in terms of three kinds of criteria, which are overall accuracy, Kappa coefficient, and total disagreement.},
DOI = {10.3390/electronics10232893}
}



@Article{s21237790,
AUTHOR = {Chen, Hang and Zhang, Weiguo and Yan, Danghui},
TITLE = {Learning Geometry Information of Target for Visual Object Tracking with Siamese Networks},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7790},
URL = {https://www.mdpi.com/1424-8220/21/23/7790},
PubMedID = {34883790},
ISSN = {1424-8220},
ABSTRACT = {Recently, Siamese architecture has been widely used in the field of visual tracking, and has achieved great success. Most Siamese network based trackers aggregate the target information of two branches by cross-correlation. However, since the location of the sampling points in the search feature area is pre-fixed in cross-correlation operation, these trackers suffer from either background noise influence or missing foreground information. Moreover, the cross-correlation between the template and the search area neglects the geometry information of the target. In this paper, we propose a Siamese deformable cross-correlation network to model the geometric structure of target and improve the performance of visual tracking. We propose to learn an offset field end-to-end in cross-correlation. With the guidance of the offset field, the sampling in the search image area can adapt to the deformation of the target, and realize the modeling of the geometric structure of the target. We further propose an online classification sub-network to model the variation of target appearance and enhance the robustness of the tracker. Extensive experiments are conducted on four challenging benchmarks, including OTB2015, VOT2018, VOT2019 and UAV123. The results demonstrate that our tracker achieves state-of-the-art performance.},
DOI = {10.3390/s21237790}
}



@Article{rs13234742,
AUTHOR = {Gawehn, Matthijs and de Vries, Sierd and Aarninkhof, Stefan},
TITLE = {A Self-Adaptive Method for Mapping Coastal Bathymetry On-The-Fly from Wave Field Video},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4742},
URL = {https://www.mdpi.com/2072-4292/13/23/4742},
ISSN = {2072-4292},
ABSTRACT = {Mapping coastal bathymetry from remote sensing becomes increasingly more attractive for the coastal community. It is facilitated by a rising availability of drone and satellite data, advances in data science, and an open-source mindset. Coastal bathymetry, but also wave directions, celerity and near-surface currents can simultaneously be derived from aerial video of a wave field. However, the required video processing is usually extensive, requires skilled supervision, and is tailored to a fieldsite. This study proposes a video-processing algorithm that resolves these issues. It automatically adapts to the video data and continuously returns mapping updates and thereby aims to make wave-based remote sensing more inclusive to the coastal community. The code architecture for the first time includes the dynamic mode decomposition (DMD) to reduce the data complexity of wavefield video. The DMD is paired with loss-functions to handle spectral noise and a novel spectral storage system and Kalman filter to achieve fast converging measurements. The algorithm is showcased for fieldsites in the USA, the UK, the Netherlands, and Australia. The performance with respect to mapping bathymetry was validated using ground truth data. It was demonstrated that merely 32 s of video footage is needed for a first mapping update with average depth errors of 0.9&ndash;2.6 m. These further reduced to 0.5&ndash;1.4 m as the videos continued and more mapping updates were returned. Simultaneously, coherent maps for wave direction and celerity were achieved as well as maps of local near-surface currents. The algorithm is capable of mapping the coastal parameters on-the-fly and thereby offers analysis of video feeds, such as from drones or operational camera installations. Hence, the innovative application of analysis techniques like the DMD enables both accurate and unprecedentedly fast coastal reconnaissance. The source code and data of this article are openly available.},
DOI = {10.3390/rs13234742}
}



@Article{rs13234735,
AUTHOR = {Appeltans, Simon and Apolo-Apolo, Orly Enrique and Rodríguez-Vázquez, Jaime Nolasco and Pérez-Ruiz, Manuel and Pieters, Jan and Mouazen, Abdul M.},
TITLE = {The Automation of Hyperspectral Training Library Construction: A Case Study for Wheat and Potato Crops},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4735},
URL = {https://www.mdpi.com/2072-4292/13/23/4735},
ISSN = {2072-4292},
ABSTRACT = {The potential of hyperspectral measurements for early disease detection has been investigated by many experts over the last 5 years. One of the difficulties is obtaining enough data for training and building a hyperspectral training library. When the goal is to detect disease at a previsible stage, before the pathogen has manifested either its first symptoms or in the area surrounding the existing symptoms, it is impossible to objectively delineate the regions of interest containing the previsible pathogen growth from the areas without the pathogen growth. To overcome this, we propose an image labelling and segmentation algorithm that is able to (a) more objectively label the visible symptoms for the construction of a training library and (b) extend this labelling to the pre-visible symptoms. This algorithm is used to create hyperspectral training libraries for late blight disease (Phytophthora infestans) in potatoes and two types of leaf rust (Puccinia triticina and Puccinia striiformis) in wheat. The model training accuracies were compared between the automatic labelling algorithm and the classic visual delineation of regions of interest using a logistic regression machine learning approach. The modelling accuracies of the automatically labelled datasets were higher than those of the manually labelled ones for both potatoes and wheat, at 98.80% for P. infestans in potato, 97.69% for P. striiformis in soft wheat, and 96.66% for P. triticina in durum wheat.},
DOI = {10.3390/rs13234735}
}



@Article{rs13234750,
AUTHOR = {Chen, Jianchang and Chen, Yiming and Liu, Zhengjun},
TITLE = {Classification of Typical Tree Species in Laser Point Cloud Based on Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4750},
URL = {https://www.mdpi.com/2072-4292/13/23/4750},
ISSN = {2072-4292},
ABSTRACT = {We propose the Point Cloud Tree Species Classification Network (PCTSCN) to overcome challenges in classifying tree species from laser data with deep learning methods. The network is mainly composed of two parts: a sampling component in the early stage and a feature extraction component in the later stage. We used geometric sampling to extract regions with local features from the tree contours since these tend to be species-specific. Then we used an improved Farthest Point Sampling method to extract the features from a global perspective. We input the intensity of the tree point cloud as a dimensional feature and spatial information into the neural network and mapped it to higher dimensions for feature extraction. We used the data obtained by Terrestrial Laser Scanning (TLS) and Unmanned Aerial Vehicle Laser Scanning (UAVLS) to conduct tree species classification experiments of white birch and larch. The experimental results showed that in both the TLS and UAVLS datasets, the input tree point cloud density and the highest feature dimensionality of the mapping had an impact on the classification accuracy of the tree species. When the single tree sample obtained by TLS consisted of 1024 points and the highest dimension of the network mapping was 512, the classification accuracy of the trained model reached 96%. For the individual tree samples obtained by UAVLS, which consisted of 2048 points and had the highest dimension of the network mapping of 1024, the classification accuracy of the trained model reached 92%. TLS data tree species classification accuracy of PCTSCN was improved by 2&ndash;9% compared with other models using the same point density, amount of data and highest feature dimension. The classification accuracy of tree species obtained by UAVLS was up to 8% higher. We propose PCTSCN to provide a new strategy for the intelligent classification of forest tree species.},
DOI = {10.3390/rs13234750}
}



@Article{math9233006,
AUTHOR = {Yang, Junqiang and Tang, Wenbing and Ding, Zuohua},
TITLE = {Long-Term Target Tracking of UAVs Based on Kernelized Correlation Filter},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {3006},
URL = {https://www.mdpi.com/2227-7390/9/23/3006},
ISSN = {2227-7390},
ABSTRACT = {During the target tracking process of unmanned aerial vehicles (UAVs), the target may disappear from view or be fully occluded by other objects, resulting in tracking failure. Therefore, determining how to identify tracking failure and re-detect the target is the key to the long-term target tracking of UAVs. Kernelized correlation filter (KCF) has been very popular for its satisfactory speed and accuracy since it was proposed. It is very suitable for UAV target tracking systems with high real-time requirements. However, it cannot detect tracking failure, so it is not suitable for long-term target tracking. Based on the above research, we propose an improved KCF to match long-term target tracking requirements. Firstly, we introduce a confidence mechanism to evaluate the target tracking results to determine the status of target tracking. Secondly, the tracking model update strategy is designed to make the model suffer from less background information interference, thereby improving the robustness of the algorithm. Finally, the Normalized Cross Correlation (NCC) template matching is used to make a regional proposal first, and then the tracking model is used for target re-detection. Then, we successfully apply the algorithm to the UAV system. The system uses binocular cameras to estimate the target position accurately, and we design a control method to keep the target in the UAV&rsquo;s field of view. Our algorithm has achieved the best results in both short-term and long-term evaluations of experiments on tracking benchmarks, which proves that the algorithm is superior to the baseline algorithm and has quite good performance. Outdoor experiments show that the developed UAV system can achieve long-term, autonomous target tracking.},
DOI = {10.3390/math9233006}
}



@Article{drones5040140,
AUTHOR = {Taddia, Yuri and Corbau, Corinne and Buoninsegni, Joana and Simeoni, Umberto and Pellegrinelli, Alberto},
TITLE = {UAV Approach for Detecting Plastic Marine Debris on the Beach: A Case Study in the Po River Delta (Italy)},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {140},
URL = {https://www.mdpi.com/2504-446X/5/4/140},
ISSN = {2504-446X},
ABSTRACT = {Anthropogenic marine debris (AMD) represent a global threat for aquatic environments. It is important to locate and monitor the distribution and presence of macroplastics along beaches to prevent degradation into microplastics (MP), which are potentially more harmful and more difficult to remove. UAV imaging represents a quick method for acquiring pictures with a ground spatial resolution of a few centimeters. In this work, we investigate strategies for AMD mapping on beaches with different ground resolutions and with elevation and multispectral data in support of RGB orthomosaics. Operators with varying levels of expertise and knowledge of the coastal environment map the AMD on four to five transects manually, using a range of photogrammetric tools. The initial survey was repeated after one year; in both surveys, beach litter was collected and further analyzed in the laboratory. Operators assign three levels of confidence when recognizing and describing AMD. Preliminary validation of results shows that items identified with high confidence were almost always classified properly. Approaching the detected items in terms of surface instead of a simple count increased the percentage of mapped litter significantly when compared to those collected. Multispectral data in near-infrared (NIR) wavelengths and digital surface models (DSMs) did not significantly improve the efficiency of manual mapping, even if vegetation features were removed using NDVI maps. In conclusion, this research shows that a good solution for performing beach AMD mapping can be represented by using RGB imagery with a spatial resolution of about 200 pix/m for detecting macroplastics and, in particular, focusing on the largest items. From the point of view of assessing and monitoring potential sources of MP, this approach is not only feasible but also quick, practical, and sustainable.},
DOI = {10.3390/drones5040140}
}



@Article{su132312980,
AUTHOR = {Wang, Zhenhua and Zhang, Xinyue and Li, Jing and Luan, Kuifeng},
TITLE = {A YOLO-Based Target Detection Model for Offshore Unmanned Aerial Vehicle Data},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {12980},
URL = {https://www.mdpi.com/2071-1050/13/23/12980},
ISSN = {2071-1050},
ABSTRACT = {Target detection in offshore unmanned aerial vehicle data is still a challenge due to the complex characteristics of targets, such as multi-sizes, alterable orientation, and complex backgrounds. Herein, a YOLO-based detection model (YOLO-D) was proposed for target detection in offshore unmanned aerial vehicle data. Based on the YOLOv3 network, the residual module was improved by establishing dense connections and adding a dual-attention mechanism (CBAM) to enhance the use of features and global information. Then, the loss function of the YOLO-D model was added to the weight coefficients to increase detection accuracy for small-size targets. Finally, the feature pyramid network (FPN) was replaced by the secondary recursive feature pyramid network to reduce the impacts of a complicated environment. Taking the car, boat, and deposit near the coastline as the targets, the proposed YOLO-D model was compared against other models, including the faster R-CNN, SSD, YOLOv3, and YOLOv5, to evaluate its detection performance. The results showed that the evaluation metrics of the YOLO-D model, including precision (Pr), recall (Re), average precision (AP), and the mean of average precision (mAP), had the highest values. The mAP of the YOLO-D model increased by 37.95%, 39.44%, 28.46%, and 5.08% compared to the faster R-CNN, SSD, YOLOv3, and YOLOv5, respectively. The AP of the car, boat, and deposit reached 96.24%, 93.70%, and 96.79% respectively. Moreover, the YOLO-D model had a higher detection accuracy than other models, especially in the detection of small-size targets. Collectively, the proposed YOLO-D model is a suitable model for target detection in offshore unmanned aerial vehicle data.},
DOI = {10.3390/su132312980}
}



@Article{rs13234757,
AUTHOR = {Sekrecka, Aleksandra},
TITLE = {Application of the XBoost Regressor for an A Priori Prediction of UAV Image Quality},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4757},
URL = {https://www.mdpi.com/2072-4292/13/23/4757},
ISSN = {2072-4292},
ABSTRACT = {In general, the quality of imagery from Unmanned Aerial Vehicles (UAVs) is evaluated after the flight, and then a decision is made on the further value and use of the acquired data. In this paper, an a priori (preflight) image quality prediction methodology is proposed to estimate the preflight image quality and to avoid unfavourable flights, which is extremely important from a time and cost management point of view. The XBoost Regressor model and cross-validation were used for machine learning of the model and image quality prediction. The model was learned on a rich database of real-world images acquired from UAVs under conditions varying in both sensor type, UAV type, exposure parameters, weather, topography, and land cover. Radiometric quality indices (SNR, Entropy, PIQE, NIQE, BRISQUE, and NRPBM) were calculated for each image to train and test the model and to assess the accuracy of image quality prediction. Different variants of preflight parameter knowledge were considered in the study. The proposed methodology offers the possibility of predicting image quality with high accuracy. The correlation coefficient between the actual and predicted image quality, depending on the number of parameters known a priori, ranged from 0.90 to 0.96. The methodology was designed for data acquired from a UAV. Similar prediction accuracy is expected for other low-altitude or close-range photogrammetric data.},
DOI = {10.3390/rs13234757}
}



@Article{telecom2040027,
AUTHOR = {Singh, Simran and Kumbhar, Abhaykumar and Güvenç, İsmail and Sichitiu, Mihail L.},
TITLE = {Intelligent Interference Management in UAV-Based HetNets},
JOURNAL = {Telecom},
VOLUME = {2},
YEAR = {2021},
NUMBER = {4},
PAGES = {472--488},
URL = {https://www.mdpi.com/2673-4001/2/4/27},
ISSN = {2673-4001},
ABSTRACT = {Unmanned aerial vehicles (UAVs) can play a key role in meeting certain demands of cellular networks. UAVs can be used not only as user equipment (UE) in cellular networks but also as mobile base stations (BSs) wherein they can either augment conventional BSs by adapting their position to serve the changing traffic and connectivity demands or temporarily replace BSs that are damaged due to natural disasters. The flexibility of UAVs allows them to provide coverage to UEs in hot-spots, at cell-edges, in coverage holes, or regions with scarce cellular infrastructure. In this work, we study how UAV locations and other cellular parameters may be optimized in such scenarios to maximize the spectral efficiency (SE) of the network. We compare the performance of machine learning (ML) techniques with conventional optimization approaches. We found that, on an average, a double deep Q learning approach can achieve 93.46% of the optimal median SE and 95.83% of the optimal mean SE. A simple greedy approach, which tunes the parameters of each BS and UAV independently, performed very well in all the cases that we tested. These computationally efficient approaches can be utilized to enhance the network performance in existing cellular networks.},
DOI = {10.3390/telecom2040027}
}



@Article{aerospace8120363,
AUTHOR = {Elmeseiry, Nourhan and Alshaer, Nancy and Ismail, Tawfik},
TITLE = {A Detailed Survey and Future Directions of Unmanned Aerial Vehicles (UAVs) with Potential Applications},
JOURNAL = {Aerospace},
VOLUME = {8},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {363},
URL = {https://www.mdpi.com/2226-4310/8/12/363},
ISSN = {2226-4310},
ABSTRACT = {Recently, unmanned aerial vehicles (UAVs), also known as drones, have gained widespread interest in civilian and military applications, which has led to the development of novel UAVs that can perform various operations. UAVs are aircraft that can fly without the need of a human pilot onboard, meaning they can fly either autonomously or be remotely piloted. They can be equipped with multiple sensors, including cameras, inertial measurement units (IMUs), LiDAR, and GPS, to collect and transmit data in real time. Due to the demand for UAVs in various applications such as precision agriculture, search and rescue, wireless communications, and surveillance, several types of UAVs have been invented with different specifications for their size, weight, range and endurance, engine type, and configuration. Because of this variety, the design process and analysis are based on the type of UAV, with the availability of several control techniques that could be used to improve the flight of the UAV in order to avoid obstacles and potential collisions, as well as find the shortest path to save the battery life with the support of optimization techniques. However, UAVs face several challenges in order to fly smoothly, including collision avoidance, battery life, and intruders. This review paper presents UAVs&rsquo; classification, control applications, and future directions in industry and research interest. For the design process, fabrication, and analysis, various control approaches are discussed in detail. Furthermore, the challenges for UAVs, including battery charging, collision avoidance, and security, are also presented and discussed.},
DOI = {10.3390/aerospace8120363}
}



@Article{buildings11120579,
AUTHOR = {Amândio, Margarida and Parente, Manuel and Neves, José and Fonseca, Paulo},
TITLE = {Integration of Smart Pavement Data with Decision Support Systems: A Systematic Review},
JOURNAL = {Buildings},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {579},
URL = {https://www.mdpi.com/2075-5309/11/12/579},
ISSN = {2075-5309},
ABSTRACT = {Nowadays, pavement management systems (PMS) are mainly based on monitoring processes that have been established for a long time, and strongly depend on acquired experience. However, with the emergence of smart technologies, such as internet of things and artificial intelligence, PMS could be improved by applying these new smart technologies to their decision support systems, not just by updating their data collection methodologies, but also their data analysis tools. The application of these smart technologies to the field of pavement monitoring and condition evaluation will undoubtedly contribute to more efficient, less costly, safer, and environmentally friendly methodologies. Thus, the main drive of the present work is to provide insight for the development of future decision support systems for smart pavement management by conducting a systematic literature review of the developed works that apply smart technologies to this field. The conclusions drawn from the analysis allowed for the identification of a series of future direction recommendations for researchers. In fact, future PMS should tend to be capable of collecting and analyzing data at different levels, both externally at the surface or inside the pavement, as well as to detect and predict all types of functional and structural flaws and defects.},
DOI = {10.3390/buildings11120579}
}



@Article{electronics10232915,
AUTHOR = {Sadique, Joarder Jafor and Ullah, Shaikh Enayet and Raad, Raad and Islam, Md. Rabiul and Rahman, Md. Mahbubar and Kouzani, Abbas Z. and Mahmud, M. A. Parvez},
TITLE = {Gyre Precoding and T-Transformation-Based GFDM System for UAV-Aided mMTC Network},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {2915},
URL = {https://www.mdpi.com/2079-9292/10/23/2915},
ISSN = {2079-9292},
ABSTRACT = {In this paper, an unmanned aerial vehicle (UAV)-aided multi-antenna configured downlink mmWave cooperative generalized frequency division multiplexing (GFDM) system is proposed. To provide physical layer security (PLS), a 3D controlled Lorenz mapping system is introduced. Furthermore, the combination of T-transformation spreading codes, walsh Hadamard transform, and discrete Fourier transform (DFT) techniques are integrated with a novel linear multi-user multiple-input multiple-output (MU-MIMO) gyre precoding (GP) for multi-user interference reduction. Furthermore, concatenated channel-coding with multi-user beamforming weighting-aided maximum-likelihood and zero forcing (ZF) signal detection schemes for an improved bit error rate (BER) are also used. The system is then simulated with a single base station (BS), eight massive machine-type communications (mMTC) users, and two UAV relay stations (RSs). Numerical results reveal the robustness of the proposed system in terms of PLS and an achievable ergodic rate with signal-to-interference-plus-noise ratio (SINR) under the implementation of T-transformation scheme. By incorporating the 3D mobility model, brownian perturbations of the UAVs are also analyzed. An out-of-band (OOB) reduction of 320 dB with an improved BER of 1&times;10&minus;4 in 16-QAM for a signal-to-noise ratio, Eb/N0, of 20 dB is achieved.},
DOI = {10.3390/electronics10232915}
}



@Article{electronics10232918,
AUTHOR = {Mohamed, Nader and Al-Jaroodi, Jameela and Lazarova-Molnar, Sanja and Jawhar, Imad},
TITLE = {Applications of Integrated IoT-Fog-Cloud Systems to Smart Cities: A Survey},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {2918},
URL = {https://www.mdpi.com/2079-9292/10/23/2918},
ISSN = {2079-9292},
ABSTRACT = {Several cities have recently moved towards becoming smart cities for better services and quality of life for residents and visitors, with: optimized resource utilization; increased environmental protection; enhanced infrastructure operations and maintenance; and strong safety and security measures. Smart cities depend on deploying current and new technologies and different optimization methods to enhance services and performance in their different sectors. Some of the technologies assisting smart city applications are the Internet of Things (IoT), fog computing, and cloud computing. Integrating these three to serve one system (we will refer to it as integrated IoT-fog-cloud system (iIFC)) creates an advanced platform to develop and operate various types of smart city applications. This platform will allow applications to use the best features from the IoT devices, fog nodes, and cloud services to deliver best capabilities and performance. Utilizing this powerful platform will provide many opportunities for enhancing and optimizing applications in energy, transportation, healthcare, and other areas. In this paper we survey various applications of iIFCs for smart cities. We identify different common issues associated with utilizing iIFCs for smart city applications. These issues arise due to the characteristics of iIFCs on the one side and the requirements of different smart city applications on the other. In addition, we outline the main requirements to effectively utilize iIFCs for smart city applications. These requirements are related to optimization, networking, and security.},
DOI = {10.3390/electronics10232918}
}



@Article{agriculture11121190,
AUTHOR = {Fang, Lifa and Wu, Yanqiang and Li, Yuhua and Guo, Hongen and Zhang, Hua and Wang, Xiaoyu and Xi, Rui and Hou, Jialin},
TITLE = {Using Channel and Network Layer Pruning Based on Deep Learning for Real-Time Detection of Ginger Images},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1190},
URL = {https://www.mdpi.com/2077-0472/11/12/1190},
ISSN = {2077-0472},
ABSTRACT = {Consistent ginger shoot orientation helps to ensure consistent ginger emergence and meet shading requirements. YOLO v3 is used to recognize ginger images in response to the current ginger seeder&rsquo;s difficulty in meeting the above agronomic problems. However, it is not suitable for direct application on edge computing devices due to its high computational cost. To make the network more compact and to address the problems of low detection accuracy and long inference time, this study proposes an improved YOLO v3 model, in which some redundant channels and network layers are pruned to achieve real-time determination of ginger shoots and seeds. The test results showed that the pruned model reduced its model size by 87.2% and improved the detection speed by 85%. Meanwhile, its mean average precision (mAP) reached 98.0% for ginger shoots and seeds, only 0.1% lower than the model before pruning. Moreover, after deploying the model to the Jetson Nano, the test results showed that its mAP was 97.94%, the recognition accuracy could reach 96.7%, and detection speed could reach 20 frames&middot;s&minus;1. The results showed that the proposed method was feasible for real-time and accurate detection of ginger images, providing a solid foundation for automatic and accurate ginger seeding.},
DOI = {10.3390/agriculture11121190}
}



@Article{w13233349,
AUTHOR = {Merlino, Silvia and Paterni, Marco and Locritani, Marina and Andriolo, Umberto and Gonçalves, Gil and Massetti, Luciano},
TITLE = {Citizen Science for Marine Litter Detection and Classification on Unmanned Aerial Vehicle Images},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {3349},
URL = {https://www.mdpi.com/2073-4441/13/23/3349},
ISSN = {2073-4441},
ABSTRACT = {Unmanned aerial vehicles (UAV, aka drones) are being used for mapping macro-litter in the environment. As drone images require a manual processing task for detecting marine litter, it is of interest to evaluate the accuracy of non-expert citizen science operators (CSO) in performing this task. Students from Italian secondary schools (in this work, the CSO) were invited to identify, mark, and classify stranded litter items on a UAV orthophoto collected on an Italian beach. A specific training program and working tools were developed for the aim. The comparison with the standard in situ visual census survey returned a general underestimation (50%) of items. However, marine litter bulk categorisation was fairly in agreement with the in situ survey, especially for sources classification. The concordance level among CSO ranged between 60% and 91%, depending on the item properties considered (type, material, and colour). As the assessment accuracy was in line with previous works developed by experts, remote detection of marine litter on UAV images can be improved through citizen science programs, upon an appropriate training plan and provision of specific tools.},
DOI = {10.3390/w13233349}
}



@Article{app112311234,
AUTHOR = {Yeom, Seokwon},
TITLE = {Long Distance Moving Vehicle Tracking with a Multirotor Based on IMM-Directional Track Association},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {11234},
URL = {https://www.mdpi.com/2076-3417/11/23/11234},
ISSN = {2076-3417},
ABSTRACT = {The multirotor has the capability to capture distant objects. Because the computing resources of the multirotor are limited, efficiency is an important factor to consider. In this paper, multiple target tracking with a multirotor at a long distance (~400 m) is addressed; the interacting multiple model (IMM) estimator combined with the directional track-to-track association (abbreviated as track association) is proposed. The previous work of the Kalman estimator with the track association approach is extended to the IMM estimator with the directional track association. The IMM estimator can handle multiple targets with various maneuvers. The track association scheme is modified in consideration of the direction of the target movement. The overall system is composed of moving object detection for measurement generation and multiple target tracking for state estimation. The moving object detection consists of frame-to-frame subtraction of three-color layers and thresholding, morphological operation, and false alarm removing based on the object size and shape properties. The centroid of the detected object is input into the next tracking stage. The track is initialized using the difference between two nearest points measured in consecutive frames. The measurement nearest to the state prediction is used to update the state of the target for measurement-to-track association. The directional track association tests both the hypothesis and the maximum deviation between the displacement and directions of two tracks followed by track selection, fusion, and termination. In the experiment, a multirotor flying at an altitude of 400 m captured 55 moving vehicles around a highway interchange for about 20 s. The tracking performance is evaluated for the IMMs using constant velocity (CV) and constant acceleration (CA) motion models. The IMM-CA with the directional track association scheme outperforms other methods with an average total track life of 91.7% and an average mean track life of 84.2%.},
DOI = {10.3390/app112311234}
}



@Article{rs13234803,
AUTHOR = {Ojogbane, Sani Success and Mansor, Shattri and Kalantar, Bahareh and Khuzaimah, Zailani Bin and Shafri, Helmi Zulhaidi Mohd and Ueda, Naonori},
TITLE = {Automated Building Detection from Airborne LiDAR and Very High-Resolution Aerial Imagery with Deep Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4803},
URL = {https://www.mdpi.com/2072-4292/13/23/4803},
ISSN = {2072-4292},
ABSTRACT = {The detection of buildings in the city is essential in several geospatial domains and for decision-making regarding intelligence for city planning, tax collection, project management, revenue generation, and smart cities, among other areas. In the past, the classical approach used for building detection was by using the imagery and it entailed human&ndash;computer interaction, which was a daunting proposition. To tackle this task, a novel network based on an end-to-end deep learning framework is proposed to detect and classify buildings features. The proposed CNN has three parallel stream channels: the first is the high-resolution aerial imagery, while the second stream is the digital surface model (DSM). The third was fixed on extracting deep features using the fusion of channel one and channel two, respectively. Furthermore, the channel has eight group convolution blocks of 2D convolution with three max-pooling layers. The proposed model&rsquo;s efficiency and dependability were tested on three different categories of complex urban building structures in the study area. Then, morphological operations were applied to the extracted building footprints to increase the uniformity of the building boundaries and produce improved building perimeters. Thus, our approach bridges a significant gap in detecting building objects in diverse environments; the overall accuracy (OA) and kappa coefficient of the proposed method are greater than 80% and 0.605, respectively. The findings support the proposed framework and methodologies&rsquo; efficacy and effectiveness at extracting buildings from complex environments.},
DOI = {10.3390/rs13234803}
}



@Article{s21237889,
AUTHOR = {Sott, Michele Kremer and Nascimento, Leandro da Silva and Foguesatto, Cristian Rogério and Furstenau, Leonardo B. and Faccin, Kadígia and Zawislak, Paulo Antônio and Mellado, Bruce and Kong, Jude Dzevela and Bragazzi, Nicola Luigi},
TITLE = {A Bibliometric Network Analysis of Recent Publications on Digital Agriculture to Depict Strategic Themes and Evolution Structure},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7889},
URL = {https://www.mdpi.com/1424-8220/21/23/7889},
PubMedID = {34883903},
ISSN = {1424-8220},
ABSTRACT = {The agriculture sector is one of the backbones of many countries&rsquo; economies. Its processes have been changing to enable technology adoption to increase productivity, quality, and sustainable development. In this research, we present a scientific mapping of the adoption of precision techniques and breakthrough technologies in agriculture, so-called Digital Agriculture. To do this, we used 4694 documents from the Web of Science database to perform a Bibliometric Performance and Network Analysis of the literature using SciMAT software with the support of the PICOC protocol. Our findings presented 22 strategic themes related to Digital Agriculture, such as Internet of Things (IoT), Unmanned Aerial Vehicles (UAV) and Climate-smart Agriculture (CSA), among others. The thematic network structure of the nine most important clusters (motor themes) was presented and an in-depth discussion was performed. The thematic evolution map provides a broad perspective of how the field has evolved over time from 1994 to 2020. In addition, our results discuss the main challenges and opportunities for research and practice in the field of study. Our findings provide a comprehensive overview of the main themes related to Digital Agriculture. These results show the main subjects analyzed on this topic and provide a basis for insights for future research.},
DOI = {10.3390/s21237889}
}



@Article{rs13234811,
AUTHOR = {Štroner, Martin and Urban, Rudolf and Línková, Lenka},
TITLE = {A New Method for UAV Lidar Precision Testing Used for the Evaluation of an Affordable DJI ZENMUSE L1 Scanner},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4811},
URL = {https://www.mdpi.com/2072-4292/13/23/4811},
ISSN = {2072-4292},
ABSTRACT = {Lately, affordable unmanned aerial vehicle (UAV)-lidar systems have started to appear on the market, highlighting the need for methods facilitating proper verification of their accuracy. However, the dense point cloud produced by such systems makes the identification of individual points that could be used as reference points difficult. In this paper, we propose such a method utilizing accurately georeferenced targets covered with high-reflectivity foil, which can be easily extracted from the cloud; their centers can be determined and used for the calculation of the systematic shift of the lidar point cloud. Subsequently, the lidar point cloud is cleaned of such systematic shift and compared with a dense SfM point cloud, thus yielding the residual accuracy. We successfully applied this method to the evaluation of an affordable DJI ZENMUSE L1 scanner mounted on the UAV DJI Matrice 300 and found that the accuracies of this system (3.5 cm in all directions after removal of the global georeferencing error) are better than manufacturer-declared values (10/5 cm horizontal/vertical). However, evaluation of the color information revealed a relatively high (approx. 0.2 m) systematic shift.},
DOI = {10.3390/rs13234811}
}



@Article{s21237888,
AUTHOR = {Lo, Li-Yu and Yiu, Chi Hao and Tang, Yu and Yang, An-Shik and Li, Boyang and Wen, Chih-Yung},
TITLE = {Dynamic Object Tracking on Autonomous UAV System for Surveillance Applications},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7888},
URL = {https://www.mdpi.com/1424-8220/21/23/7888},
PubMedID = {34883913},
ISSN = {1424-8220},
ABSTRACT = {The ever-burgeoning growth of autonomous unmanned aerial vehicles (UAVs) has demonstrated a promising platform for utilization in real-world applications. In particular, a UAV equipped with a vision system could be leveraged for surveillance applications. This paper proposes a learning-based UAV system for achieving autonomous surveillance, in which the UAV can be of assistance in autonomously detecting, tracking, and following a target object without human intervention. Specifically, we adopted the YOLOv4-Tiny algorithm for semantic object detection and then consolidated it with a 3D object pose estimation method and Kalman filter to enhance the perception performance. In addition, UAV path planning for a surveillance maneuver is integrated to complete the fully autonomous system. The perception module is assessed on a quadrotor UAV, while the whole system is validated through flight experiments. The experiment results verified the robustness, effectiveness, and reliability of the autonomous object tracking UAV system in performing surveillance tasks. The source code is released to the research community for future reference.},
DOI = {10.3390/s21237888}
}



@Article{rs13234853,
AUTHOR = {Wei, Dawei and Xi, Ning and Ma, Jianfeng and He, Lei},
TITLE = {UAV-Assisted Privacy-Preserving Online Computation Offloading for Internet of Things},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4853},
URL = {https://www.mdpi.com/2072-4292/13/23/4853},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle (UAV) plays a more and more important role in Internet of Things (IoT) for remote sensing and device interconnecting. Due to the limitation of computing capacity and energy, the UAV cannot handle complex tasks. Recently, computation offloading provides a promising way for the UAV to handle complex tasks by deep reinforcement learning (DRL)-based methods. However, existing DRL-based computation offloading methods merely protect usage pattern privacy and location privacy. In this paper, we consider a new privacy issue in UAV-assisted IoT, namely computation offloading preference leakage, which lacks through study. To cope with this issue, we propose a novel privacy-preserving online computation offloading method for UAV-assisted IoT. Our method integrates the differential privacy mechanism into deep reinforcement learning (DRL), which can protect UAV&rsquo;s offloading preference. We provide the formal analysis on security and utility loss of our method. Extensive real-world experiments are conducted. Results demonstrate that, compared with baseline methods, our method can learn cost-efficient computation offloading policy without preference leakage and a priori knowledge of the wireless channel model.},
DOI = {10.3390/rs13234853}
}



@Article{fi13120306,
AUTHOR = {Dirir, Ahmed and Ignatious, Henry and Elsayed, Hesham and Khan, Manzoor and Adib, Mohammed and Mahmoud, Anas and Al-Gunaid, Moatasem},
TITLE = {An Advanced Deep Learning Approach for Multi-Object Counting in Urban Vehicular Environments},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {306},
URL = {https://www.mdpi.com/1999-5903/13/12/306},
ISSN = {1999-5903},
ABSTRACT = {Object counting is an active research area that gained more attention in the past few years. In smart cities, vehicle counting plays a crucial role in urban planning and management of the Intelligent Transportation Systems (ITS). Several approaches have been proposed in the literature to address this problem. However, the resulting detection accuracy is still not adequate. This paper proposes an efficient approach that uses deep learning concepts and correlation filters for multi-object counting and tracking. The performance of the proposed system is evaluated using a dataset consisting of 16 videos with different features to examine the impact of object density, image quality, angle of view, and speed of motion towards system accuracy. Performance evaluation exhibits promising results in normal traffic scenarios and adverse weather conditions. Moreover, the proposed approach outperforms the performance of two recent approaches from the literature.},
DOI = {10.3390/fi13120306}
}



@Article{ijgi10120805,
AUTHOR = {Fang, Xuan and Li, Jincheng and Zhu, Ying and Cao, Jianjun and Na, Jiaming and Jiang, Sheng and Ding, Hu},
TITLE = {OBIA-Based Extraction of Artificial Terrace Damages in the Loess Plateau of China from UAV Photogrammetry},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {805},
URL = {https://www.mdpi.com/2220-9964/10/12/805},
ISSN = {2220-9964},
ABSTRACT = {Terraces, which are typical artificial landforms found around world, are of great importance for agricultural production and soil and water conservation. However, due to the lack of maintenance, terrace damages often occur and affect the local flow process, which will influence soil erosion. Automatic high-accuracy mapping of terrace damages is the basis of monitoring and related studies. Researchers have achieved artificial terrace damage mapping mainly via manual field investigation, but an automatic method is still lacking. In this study, given the success of high-resolution unmanned aerial vehicle (UAV) photogrammetry and object-based image analysis (OBIA) for image processing tasks, an integrated framework based on OBIA and UAV photogrammetry is proposed for terrace damage mapping. The Pujiawa terrace in the Loess Plateau of China was selected as the study area. Firstly, the segmentation process was optimised by considering the spectral features and the terrains and corresponding textures obtained from high-resolution images and digital surface models. The feature selection was implemented via correlation analysis, and the optimised segmentation parameter was achieved using the estimation of scale parameter algorithm. Then, a supervised k-nearest neighbourhood classifier was used to identify the terrace damages in the segmented objects, and additional geometric features at the object level were considered for classification. The comparison with the ground truth, as delineated by the image and field survey, showed that proposed classification can be adequately performed. The F-measures of extraction on three terrace damages were 92.07% (terrace sinkhole), 81.95% (ridge sinkhole), and 85.17% (collapse), and the Kappa coefficient was 85.34%. Finally, the potential application and spatial distribution of the terrace damages in this study were determined. We believe that this work can provide a credible framework for mapping terrace damages in the Loess Plateau of China.},
DOI = {10.3390/ijgi10120805}
}



@Article{ijgi10120813,
AUTHOR = {de Carvalho, Osmar Luiz Ferreira and de Moura, Rebeca dos Santos and de Albuquerque, Anesmar Olino and de Bem, Pablo Pozzobon and de Castro Pereira, Rubens and Weigang, Li and Borges, Dibio Leandro and Guimarães, Renato Fontes and Gomes, Roberto Arnaldo Trancoso and de Carvalho Júnior, Osmar Abílio},
TITLE = {Instance Segmentation for Governmental Inspection of Small Touristic Infrastructure in Beach Zones Using Multispectral High-Resolution WorldView-3 Imagery},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {813},
URL = {https://www.mdpi.com/2220-9964/10/12/813},
ISSN = {2220-9964},
ABSTRACT = {Misappropriation of public lands is an ongoing government concern. In Brazil, the beach zone is public property, but many private establishments use it for economic purposes, requiring constant inspection. Among the undue targets, the individual mapping of straw beach umbrellas (SBUs) attached to the sand is a great challenge due to their small size, high presence, and agglutinated appearance. This study aims to automatically detect and count SBUs on public beaches using high-resolution images and instance segmentation, obtaining pixel-wise semantic information and individual object detection. This study is the first instance segmentation application on coastal areas and the first using WorldView-3 (WV-3) images. We used the Mask-RCNN with some modifications: (a) multispectral input for the WorldView3 imagery (eight channels), (b) improved the sliding window algorithm for large image classification, and (c) comparison of different image resizing ratios to improve small object detection since the SBUs are small objects (&lt;322 pixels) even using high-resolution images (31 cm). The accuracy analysis used standard COCO metrics considering the original image and three scale ratios (2&times;, 4&times;, and 8&times; resolution increase). The average precision (AP) results increased proportionally to the image resolution: 30.49% (original image), 48.24% (2&times;), 53.45% (4&times;), and 58.11% (8&times;). The 8&times; model presented 94% AP50, classifying nearly all SBUs correctly. Moreover, the improved sliding window approach enables the classification of large areas providing automatic counting and estimating the size of the objects, proving to be effective for inspecting large coastal areas and providing insightful information for public managers. This remote sensing application impacts the inspection cost, tribute, and environmental conditions.},
DOI = {10.3390/ijgi10120813}
}



@Article{futuretransp1030039,
AUTHOR = {Mahlberg, Justin A. and Cheng, Yi-Ting and Bullock, Darcy M. and Habib, Ayman},
TITLE = {Leveraging LiDAR Intensity to Evaluate Roadway Pavement Markings},
JOURNAL = {Future Transportation},
VOLUME = {1},
YEAR = {2021},
NUMBER = {3},
PAGES = {720--736},
URL = {https://www.mdpi.com/2673-7590/1/3/39},
ISSN = {2673-7590},
ABSTRACT = {The United States has over 8.8 million lane miles nationwide, which require regular maintenance and evaluations of sign retroreflectivity, pavement markings, and other pavement information. Pavement markings convey crucial information to drivers as well as connected and autonomous vehicles for lane delineations. Current means of evaluation are by human inspection or semi-automated dedicated vehicles, which often capture one to two pavement lines at a time. Mobile LiDAR is also frequently used by agencies to map signs and infrastructure as well as assess pavement conditions and drainage profiles. This paper presents a case study where over 70 miles of US-52 and US-41 in Indiana were assessed, utilizing both a mobile retroreflectometer and a LiDAR mobile mapping system. Comparing the intensity data from LiDAR data and the retroreflective readings, there was a linear correlation for right edge pavement markings with an R2 of 0.87 and for the center skip line a linear correlation with an R2 of 0.63. The p-values were 0.000 and 0.000, respectively. Although there are no published standards for using LiDAR to evaluate pavement marking retroreflectivity, these results suggest that mobile LiDAR is a viable tool for network level monitoring of retroreflectivity.},
DOI = {10.3390/futuretransp1030039}
}



@Article{s21238022,
AUTHOR = {Kartal, Serkan and Choudhary, Sunita and Masner, Jan and Kholová, Jana and Stočes, Michal and Gattu, Priyanka and Schwartz, Stefan and Kissel, Ewaut},
TITLE = {Machine Learning-Based Plant Detection Algorithms to Automate Counting Tasks Using 3D Canopy Scans},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {8022},
URL = {https://www.mdpi.com/1424-8220/21/23/8022},
PubMedID = {34884027},
ISSN = {1424-8220},
ABSTRACT = {This study tested whether machine learning (ML) methods can effectively separate individual plants from complex 3D canopy laser scans as a prerequisite to analyzing particular plant features. For this, we scanned mung bean and chickpea crops with PlantEye (R) laser scanners. Firstly, we segmented the crop canopies from the background in 3D space using the Region Growing Segmentation algorithm. Then, Convolutional Neural Network (CNN) based ML algorithms were fine-tuned for plant counting. Application of the CNN-based (Convolutional Neural Network) processing architecture was possible only after we reduced the dimensionality of the data to 2D. This allowed for the identification of individual plants and their counting with an accuracy of 93.18% and 92.87% for mung bean and chickpea plants, respectively. These steps were connected to the phenotyping pipeline, which can now replace manual counting operations that are inefficient, costly, and error-prone. The use of CNN in this study was innovatively solved with dimensionality reduction, addition of height information as color, and consequent application of a 2D CNN-based approach. We found there to be a wide gap in the use of ML on 3D information. This gap will have to be addressed, especially for more complex plant feature extractions, which we intend to implement through further research.},
DOI = {10.3390/s21238022}
}



@Article{buildings11120602,
AUTHOR = {Hammad, Ahmed W. A. and da Costa, Bruno B. F. and Soares, Carlos A. P. and Haddad, Assed N.},
TITLE = {The Use of Unmanned Aerial Vehicles for Dynamic Site Layout Planning in Large-Scale Construction Projects},
JOURNAL = {Buildings},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {602},
URL = {https://www.mdpi.com/2075-5309/11/12/602},
ISSN = {2075-5309},
ABSTRACT = {Construction sites are increasingly complex, and their layout have an impact on productivity, safety, and efficiency of construction operations. Dynamic site layout planning (DSLP) considers the adjustment of construction facilities on-site, on an evolving basis, allowing the relocation of temporary facilities according to the stages of the project. The main objective of this study is to develop a framework for integrating unmanned aerial vehicles (UAVs) and their capacity for effective photogrammetry with site layout planning optimisation and Building Information Modelling (BIM) for automating site layout planning in large construction projects. The mathematical model proposed is based on a mixed integer programming (MIP) model, which was employed to validate the framework on a realistic case study provided by an industry partner. Allocation constraints were formulated to ensure the placement of the facilities in feasible regions. Using information from the UAV, several parameters could be considered, including proximity to access ways, distances between the facilities, and suitability of locations. Based on the proposed framework, a layout was developed for each stage of the project, adapting the location of temporary facilities according to current progress on-site. As a result, the use of space was optimised, and internal transport costs were progressively reduced.},
DOI = {10.3390/buildings11120602}
}



@Article{rs13234880,
AUTHOR = {Chen, Jundong and Sasaki, Jun},
TITLE = {Mapping of Subtidal and Intertidal Seagrass Meadows via Application of the Feature Pyramid Network to Unmanned Aerial Vehicle Orthophotos},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4880},
URL = {https://www.mdpi.com/2072-4292/13/23/4880},
ISSN = {2072-4292},
ABSTRACT = {Seagrass meadows are one of the blue carbon ecosystems that continue to decline worldwide. Frequent mapping is essential to monitor seagrass meadows for understanding change processes including seasonal variations and influences of meteorological and oceanic events such as typhoons and cyclones. Such mapping approaches may also enhance seagrass blue carbon strategy and management practices. Although unmanned aerial vehicle (UAV) aerial photography has been widely conducted for this purpose, there have been challenges in mapping accuracy, efficiency, and applicability to subtidal water meadows. In this study, a novel method was developed for mapping subtidal and intertidal seagrass meadows to overcome such challenges. Ground truth seagrass orthophotos in four seasons were created from the Futtsu tidal flat of Tokyo Bay, Japan, using vertical and oblique UAV photography. The feature pyramid network (FPN) was first applied for automated seagrass classification by adjusting the spatial resolution and normalization parameters and by considering the combinations of seasonal input data sets. The FPN classification results ensured high performance with the validation metrics of 0.957 overall accuracy (OA), 0.895 precision, 0.942 recall, 0.918 F1-score, and 0.848 IoU, which outperformed the conventional U-Net results. The FPN classification results highlighted seasonal variations in seagrass meadows, exhibiting an extension from winter to summer and demonstrating a decline from summer to autumn. Recovery of the meadows was also detected after the occurrence of Typhoon No. 19 in October 2019, a phenomenon which mainly happened before summer 2020.},
DOI = {10.3390/rs13234880}
}



@Article{app112311382,
AUTHOR = {Osman, Radwa Ahmed and Saleh, Sherine Nagy and Saleh, Yasmine N. M. and Elagamy, Mazen Nabil},
TITLE = {Enhancing the Reliability of Communication between Vehicle and Everything (V2X) Based on Deep Learning for Providing Efficient Road Traffic Information},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {11382},
URL = {https://www.mdpi.com/2076-3417/11/23/11382},
ISSN = {2076-3417},
ABSTRACT = {Developing efficient communication between vehicles and everything (V2X) is a challenging task, mainly due to the characteristics of vehicular networks, which include rapid topology changes, large-scale sizes, and frequent link disconnections. This article proposes a deep learning model to enhance V2X communication. Various channel conditions such as interference, channel noise, and path loss affect the communication between a vehicle (V) and everything (X). Thus, the proposed model aims to determine the required optimum interference power to enhance connectivity, comply with the quality of service (QoS) constraints, and improve the communication link reliability. The proposed model fulfills the best QoS in terms of four metrics, namely, achievable data rate (Rb), packet delivery ratio (PDR), packet loss rate (PLR), and average end-to-end delay (E2E). The factors to be considered are the distribution and density of vehicles, average length, and minimum safety distance between vehicles. A mathematical formulation of the optimum required interference power is presented to achieve the given objectives as a constrained optimization problem, and accordingly, the proposed deep learning model is trained. The obtained results show the ability of the proposed model to enhance the connectivity between V2X for improving road traffic information efficiency and increasing road traffic safety.},
DOI = {10.3390/app112311382}
}



@Article{smartcities4040077,
AUTHOR = {Hurst, William and Mendoza, Frida Ruiz and Tekinerdogan, Bedir},
TITLE = {Augmented Reality in Precision Farming: Concepts and Applications},
JOURNAL = {Smart Cities},
VOLUME = {4},
YEAR = {2021},
NUMBER = {4},
PAGES = {1454--1468},
URL = {https://www.mdpi.com/2624-6511/4/4/77},
ISSN = {2624-6511},
ABSTRACT = {The amount of arable land is limited, yet the demand for agricultural food products is increasing. This issue has led to the notion of precision farming, where smart city-based technologies (e.g., Internet of Things, digital twins, artificial intelligence) are employed in combination to cater for increased production with fewer resources. Widely used in manufacturing, augmented reality has demonstrated impactful solutions for information communication, remote monitoring and increased interaction. Yet, the technology has only recently begun to find a footing alongside precision farming solutions, despite the many benefits possible to farmers through augmenting the physical world with digital objects. Therefore, this article reflects on literature discussing current applied solutions within agriculture, where augmented realty has demonstrated a significant impact for monitoring and production. The findings discuss that augmented reality must be coupled with other technologies (e.g., simultaneous localization and mapping algorithms, global positioning systems, and sensors), specifically 9 are identified across 2 application domains (livestock and crop farming) to be beneficial. Attention is also provided on how augmented reality should be employed within agriculture, where related-work examples are drawn from in order to discuss suitable hardware approaches and constraints (e.g., mobility).},
DOI = {10.3390/smartcities4040077}
}



@Article{rs13234889,
AUTHOR = {Velasquez-Camacho, Luisa and Cardil, Adrián and Mohan, Midhun and Etxegarai, Maddi and Anzaldi, Gabriel and de-Miguel, Sergio},
TITLE = {Remotely Sensed Tree Characterization in Urban Areas: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4889},
URL = {https://www.mdpi.com/2072-4292/13/23/4889},
ISSN = {2072-4292},
ABSTRACT = {Urban trees and forests provide multiple ecosystem services (ES), including temperature regulation, carbon sequestration, and biodiversity. Interest in ES has increased amongst policymakers, scientists, and citizens given the extent and growth of urbanized areas globally. However, the methods and techniques used to properly assess biodiversity and ES provided by vegetation in urban environments, at large scales, are insufficient. Individual tree identification and characterization are some of the most critical issues used to evaluate urban biodiversity and ES, given the complex spatial distribution of vegetation in urban areas and the scarcity or complete lack of systematized urban tree inventories at large scales, e.g., at the regional or national levels. This often limits our knowledge on their contributions toward shaping biodiversity and ES in urban areas worldwide. This paper provides an analysis of the state-of-the-art studies and was carried out based on a systematic review of 48 scientific papers published during the last five years (2016&ndash;2020), related to urban tree and greenery characterization, remote sensing techniques for tree identification, processing methods, and data analysis to classify and segment trees. In particular, we focused on urban tree and forest characterization using remotely sensed data and identified frontiers in scientific knowledge that may be expanded with new developments in the near future. We found advantages and limitations associated with both data sources and processing methods, from which we drew recommendations for further development of tree inventory and characterization in urban forestry science. Finally, a critical discussion on the current state of the methods, as well as on the challenges and directions for future research, is presented.},
DOI = {10.3390/rs13234889}
}



@Article{agronomy11122458,
AUTHOR = {Crimaldi, Mariano and Cartenì, Fabrizio and Giannino, Francesco},
TITLE = {VISmaF: Synthetic Tree for Immersive Virtual Visualization in Smart Farming. Part I: Scientific Background Review and Model Proposal},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2458},
URL = {https://www.mdpi.com/2073-4395/11/12/2458},
ISSN = {2073-4395},
ABSTRACT = {Computer-Generated Imagery (CGI) has received increasing interest in both research and the entertainment industry. Recent advancements in computer graphics allowed researchers and companies to create large-scale virtual environments with growing resolution and complexity. Among the different applications, the generation of biological assets is a relevant task that implies challenges due to the extreme complexity associated with natural structures. An example is represented by trees, whose composition made by thousands of leaves, branches, branchlets, and stems with oriented directions is hard to be modeled. Realistic 3D models of trees can be exploited for a wide range of applications including decision-making support, visualization of ecosystem changes over time, and for simple visualization purposes. In this review, we give an overview of the most common approaches used to generate 3D tree models, discussing both methodologies and available commercial software. We focus on strategies for modeling and rendering of plants, highlighting their accordance or not with botanical knowledge and biological models. We also present a proof of concept to link biological models and 3D rendering engines through Ordinary Differential Equations.},
DOI = {10.3390/agronomy11122458}
}



@Article{rs13234912,
AUTHOR = {Yu, Yang and Ma, Yong and Mei, Xiaoguang and Fan, Fan and Huang, Jun and Ma, Jiayi},
TITLE = {A Spatial-Spectral Feature Descriptor for Hyperspectral Image Matching},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4912},
URL = {https://www.mdpi.com/2072-4292/13/23/4912},
ISSN = {2072-4292},
ABSTRACT = {Hyperspectral Images (HSIs) have been utilized in many fields which contain spatial and spectral features of objects simultaneously. Hyperspectral image matching is a fundamental and critical problem in a wide range of HSI applications. Feature descriptors for grayscale image matching are well studied, but few descriptors are elaborately designed for HSI matching. HSI descriptors, which should have made good use of the spectral feature, are essential in HSI matching tasks. Therefore, this paper presents a descriptor for HSI matching, called HOSG-SIFT, which ensembles spectral features with spatial features of objects. First, we obtain the grayscale image by dimensional reduction from HSI and apply it to extract keypoints and descriptors of spatial features. Second, the descriptors of spectral features are designed based on the histogram of the spectral gradient (HOSG), which effectively preserves the physical significance of the spectral profile. Third, we concatenate the spatial descriptors and spectral descriptors with the same weights into a new descriptor and apply it for HSI matching. Experimental results demonstrate that the proposed HOSG-SIFT performs superior against traditional feature descriptors.},
DOI = {10.3390/rs13234912}
}



@Article{app112311494,
AUTHOR = {Alvarado-Robles, Gilberto and Solís-Muñoz, Francisco J. and Garduño-Ramón, Marco A. and Osornio-Ríos, Roque A. and Morales-Hernández, Luis A.},
TITLE = {A Novel Shadow Removal Method Based upon Color Transfer and Color Tuning in UAV Imaging},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {11494},
URL = {https://www.mdpi.com/2076-3417/11/23/11494},
ISSN = {2076-3417},
ABSTRACT = {Through the increasing use of unmanned aerial vehicles as remote sensing tools, shadows become evident in aerial imaging; this fact, alongside the higher spatial resolution obtained by high-resolution mounted cameras, presents a challenging issue when performing different image processing tasks related to urban areas monitoring. Accordingly, the state-of-the-art reported works can correct the shadow regions, but the heterogeneity between the corrected shadow and non-shadow areas is still evident and especially noticeable in concrete and asphalt regions. The present work introduces a local color transfer methodology to shadow removal which is based on the CIE L*a*b (Lightness, a and b) color space that considers chromatic differences in urban regions, and it is followed by a color tuning using the HSV color space. The quantitative comparison was executed by using the shadow standard deviation index (SSDI), where the proposed work provided low values that improve up to 19 units regarding other tested methods. The qualitative comparison was visually realized and proved that the proposed method enhances the color correspondence without losing texture information. Quantitative and qualitative results validate the results of color correction and texture preservation accuracy of the proposed method against other published methodologies.},
DOI = {10.3390/app112311494}
}



@Article{s21238128,
AUTHOR = {Al-Okby, Mohammed Faeik Ruzaij and Neubert, Sebastian and Roddelkopf, Thomas and Thurow, Kerstin},
TITLE = {Mobile Detection and Alarming Systems for Hazardous Gases and Volatile Chemicals in Laboratories and Industrial Locations},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {8128},
URL = {https://www.mdpi.com/1424-8220/21/23/8128},
PubMedID = {34884132},
ISSN = {1424-8220},
ABSTRACT = {The leakage of hazardous gases and chemical vapors is considered one of the dangerous accidents that can occur in laboratories, workshops, warehouses, and industrial sites that use or store these substances. The early detection and alarming of hazardous gases and volatile chemicals are significant to keep the safety conditions for the people and life forms who are work in and live around these places. In this paper, we investigate the available mobile detection and alarming systems for toxic, hazardous gases and volatile chemicals, especially in the laboratory environment. We included papers from January 2010 to August 2021 which may have the newest used sensors technologies and system components. We identified (236) papers from Clarivate Web of Science (WoS), IEEE, ACM Library, Scopus, and PubMed. Paper selection has been done based on a fast screening of the title and abstract, then a full-text reading was applied to filter the selected papers that resulted in (42) eligible papers. The main goal of this work is to discuss the available mobile hazardous gas detection and alarming systems based on several technical details such as the used gas detection technology (simple element, integrated, smart, etc.), sensor manufacturing technology (catalytic bead, MEMS, MOX, etc.) the sensor specifications (warm-up time, lifetime, response time, precision, etc.), processor type (microprocessor, microcontroller, PLC, etc.), and type of the used communication technology (Bluetooth/BLE, Wi-Fi/RF, ZigBee/XBee, LoRa, etc.). In this review, attention will be focused on the improvement of the detection and alarming system of hazardous gases with the latest invention in sensors, processors, communication, and battery technologies.},
DOI = {10.3390/s21238128}
}



@Article{s21238136,
AUTHOR = {Hu, Shuang and Liu, Jin and Kang, Zhiwei},
TITLE = {DeepLabV3+/Efficientnet Hybrid Network-Based Scene Area Judgment for the Mars Unmanned Vehicle System},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {8136},
URL = {https://www.mdpi.com/1424-8220/21/23/8136},
PubMedID = {34884140},
ISSN = {1424-8220},
ABSTRACT = {Due to the complexity and danger of Mars&rsquo;s environment, traditional Mars unmanned ground vehicles cannot efficiently perform Mars exploration missions. To solve this problem, the DeepLabV3+/Efficientnet hybrid network is proposed and applied to the scene area judgment for the Mars unmanned vehicle system. Firstly, DeepLabV3+ is used to extract the feature information of the Mars image due to its high accuracy. Then, the feature information is used as the input for Efficientnet, and the categories of scene areas are obtained, including safe area, report area, and dangerous area. Finally, according to three categories, the Mars unmanned vehicle system performs three operations: pass, report, and send. Experimental results show the effectiveness of the DeepLabV3+/Efficientnet hybrid network in the scene area judgment. Compared with the Efficientnet network, the accuracy of the DeepLabV3+/Efficientnet hybrid network is improved by approximately 18% and reaches 99.84%, which ensures the safety of the exploration mission for the Mars unmanned vehicle system.},
DOI = {10.3390/s21238136}
}



@Article{s21238160,
AUTHOR = {Gao, Meijing and Bai, Yang and Li, Zhilong and Li, Shiyu and Zhang, Bozhi and Chang, Qiuyue},
TITLE = {Real-Time Jellyfish Classification and Detection Based on Improved YOLOv3 Algorithm},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {8160},
URL = {https://www.mdpi.com/1424-8220/21/23/8160},
PubMedID = {34884161},
ISSN = {1424-8220},
ABSTRACT = {In recent years, jellyfish outbreaks have frequently occurred in offshore areas worldwide, posing a significant threat to the marine fishery, tourism, coastal industry, and personal safety. Effective monitoring of jellyfish is a vital method to solve the above problems. However, the optical detection method for jellyfish is still in the primary stage. Therefore, this paper studies a jellyfish detection method based on convolution neural network theory and digital image processing technology. This paper studies the underwater image preprocessing algorithm because the quality of underwater images directly affects the detection results. The results show that the image quality is better after applying the three algorithms namely prior defogging, adaptive histogram equalization, and multi-scale retinal enhancement, which is more conducive to detection. We establish a data set containing seven species of jellyfishes and fish. A total of 2141 images are included in the data set. The YOLOv3 algorithm is used to detect jellyfish, and its feature extraction network Darknet53 is optimized to ensure it is conducted in real-time. In addition, we introduce label smoothing and cosine annealing learning rate methods during the training process. The experimental results show that the improved algorithms improve the detection accuracy of jellyfish on the premise of ensuring the detection speed. This paper lays a foundation for the construction of an underwater jellyfish optical imaging real-time monitoring system.},
DOI = {10.3390/s21238160}
}



@Article{agriengineering3040061,
AUTHOR = {Fan, Dongliang and Su, Xiaoyun and Weng, Bo and Wang, Tianshu and Yang, Feiyun},
TITLE = {Research Progress on Remote Sensing Classification Methods for Farmland Vegetation},
JOURNAL = {AgriEngineering},
VOLUME = {3},
YEAR = {2021},
NUMBER = {4},
PAGES = {971--989},
URL = {https://www.mdpi.com/2624-7402/3/4/61},
ISSN = {2624-7402},
ABSTRACT = {Crop planting area and spatial distribution information have important practical significance for food security, global change, and sustainable agricultural development. How to efficiently and accurately identify crops in a timely manner by remote sensing in order to determine the crop planting area and its temporal&ndash;spatial dynamic change information is a core issue of monitoring crop growth and estimating regional crop yields. Based on hundreds of relevant documents from the past 25 years, in this paper, we summarize research progress in relation to farmland vegetation identification and classification by remote sensing. The classification and identification of farmland vegetation includes classification based on vegetation index, spectral bands, multi-source data fusion, artificial intelligence learning, and drone remote sensing. Representative studies of remote sensing methods are collated, the main content of each technology is summarized, and the advantages and disadvantages of each method are analyzed. Current problems related to crop remote sensing identification are then identified and future development directions are proposed.},
DOI = {10.3390/agriengineering3040061}
}



@Article{rs13244985,
AUTHOR = {Kilwenge, Regina and Adewopo, Julius and Sun, Zhanli and Schut, Marc},
TITLE = {UAV-Based Mapping of Banana Land Area for Village-Level Decision-Support in Rwanda},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {4985},
URL = {https://www.mdpi.com/2072-4292/13/24/4985},
ISSN = {2072-4292},
ABSTRACT = {Crop monitoring is crucial to understand crop production changes, agronomic practice decision-support, pests/diseases mitigation, and developing climate change adaptation strategies. Banana, an important staple food and cash crop in East Africa, is threatened by Banana Xanthomonas Wilt (BXW) disease. Yet, there is no up-to-date information about the spatial distribution and extent of banana lands, especially in Rwanda, where banana plays a key role in food security and livelihood. Therefore, delineation of banana-cultivated lands is important to prioritize resource allocation for optimal productivity. We mapped the spatial extent of smallholder banana farmlands by acquiring and processing high-resolution (25 cm/px) multispectral unmanned aerial vehicles (UAV) imageries, across four villages in Rwanda. Georeferenced ground-truth data on different land cover classes were combined with reflectance data and vegetation indices (NDVI, GNDVI, and EVI2) and compared using pixel-based supervised multi-classifiers (support vector models-SVM, classification and regression trees-CART, and random forest&ndash;RF), based on varying ground-truth data richness. Results show that RF consistently outperformed other classifiers regardless of data richness, with overall accuracy above 95%, producer&rsquo;s/user&rsquo;s accuracies above 92%, and kappa coefficient above 0.94. Estimated banana farmland areal coverage provides concrete baseline for extension-delivery efforts in terms of targeting banana farmers relative to their scale of production, and highlights opportunity to combine UAV-derived data with machine-learning methods for rapid landcover classification.},
DOI = {10.3390/rs13244985}
}



@Article{rs13244995,
AUTHOR = {Li, Zhipeng and Ding, Jie and Zhang, Heyu and Feng, Yiming},
TITLE = {Classifying Individual Shrub Species in UAV Images&mdash;A Case Study of the Gobi Region of Northwest China},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {4995},
URL = {https://www.mdpi.com/2072-4292/13/24/4995},
ISSN = {2072-4292},
ABSTRACT = {Shrublands are the main vegetation component in the Gobi region and contribute considerably to its ecosystem. Accurately classifying individual shrub vegetation species to understand their spatial distributions and to effectively monitor species diversity in the Gobi ecosystem is essential. High-resolution remote sensing data create vegetation type inventories over large areas. However, high spectral similarity between shrublands and surrounding areas remains a challenge. In this study, we provide a case study that integrates object-based image analysis (OBIA) and the random forest (RF) model to classify shrubland species automatically. The Gobi region on the southern slope of the Tian Shan Mountains in Northwest China was analyzed using readily available unmanned aerial vehicle (UAV) RGB imagery (1.5 cm spatial resolution). Different spectral and texture index images were derived from UAV RGB images as variables for species classification. Principal component analysis (PCA) extracted features from different types of variable sets (original bands, original bands + spectral indices, and original bands + spectral indices + texture indices). We tested the ability of several non-parametric decision tree models and different types of variable sets to classify shrub species. Moreover, we analyzed three main shrubland areas comprising different shrub species and compared the prediction accuracies of the optimal model in combination with different types of variable sets. We found that the RF model could generate higher accuracy compared with the other two models. The best results were obtained using a combination of the optimal variable set and the RF model with an 88.63% overall accuracy and 0.82 kappa coefficient. Integrating OBIA and RF in the species classification process provides a promising method for automatic mapping of individual shrub species in the Gobi region and can reduce the workload of individual shrub species classification.},
DOI = {10.3390/rs13244995}
}



@Article{electronics10243067,
AUTHOR = {Al-Absi, Mohammed Abdulhakim and Fu, Rui and Kim, Ki-Hwan and Lee, Young-Sil and Al-Absi, Ahmed Abdulhakim and Lee, Hoon-Jae},
TITLE = {Tracking Unmanned Aerial Vehicles Based on the Kalman Filter Considering Uncertainty and Error Aware},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {3067},
URL = {https://www.mdpi.com/2079-9292/10/24/3067},
ISSN = {2079-9292},
ABSTRACT = {Recently, Unmanned Aerial Vehicles (UAVs) have made significant impacts on our daily lives with the advancement of technologies and their applications. Tracking UAVs have become more important because they not only provide location-based services, but are also faced with serious security threats and vulnerabilities. UAVs are smaller in nature, move with high speed, and operate in a low-altitude environment, which makes it conceivable to track UAVs using fixed or mobile radars. Kalman Filter (KF)-based methodologies are widely used for extracting valuable trajectory information from samples composed of noisy information. As UAVs&rsquo; trajectories resemble uncertain behavior, the traditional KF-based methodologies have poor tracking accuracy. Recently, the Diffusion-Map-based KF (DMK) was introduced for modeling uncertainties in the environment without prior knowledge. However, the model has poor accuracy when operating in environments with higher noise. In order to achieve better tracking performance, this paper presents the Uncertainty and Error-Aware KF (UEAKF) for tracking UAVs. The UEAKF-based tracking method provides a good tradeoff among preceding estimate confidence and forthcoming measurement under dynamic environments; the resulting filter is robust and nonlinear in nature. The experimental results showed that the UEAKF-based UAV tracking model achieves much better Root Mean Square Error (RMSE) performance compared to the existing particle filter-based and DMK-based UAV tracking models.},
DOI = {10.3390/electronics10243067}
}



@Article{rs13244999,
AUTHOR = {He, Boyong and Li, Xianjiang and Huang, Bo and Gu, Enhui and Guo, Weijie and Wu, Liaoni},
TITLE = {UnityShip: A Large-Scale Synthetic Dataset for Ship Recognition in Aerial Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {4999},
URL = {https://www.mdpi.com/2072-4292/13/24/4999},
ISSN = {2072-4292},
ABSTRACT = {As a data-driven approach, deep learning requires a large amount of annotated data for training to obtain a sufficiently accurate and generalized model, especially in the field of computer vision. However, when compared with generic object recognition datasets, aerial image datasets are more challenging to acquire and more expensive to label. Obtaining a large amount of high-quality aerial image data for object recognition and image understanding is an urgent problem. Existing studies show that synthetic data can effectively reduce the amount of training data required. Therefore, in this paper, we propose the first synthetic aerial image dataset for ship recognition, called UnityShip. This dataset contains over 100,000 synthetic images and 194,054 ship instances, including 79 different ship models in ten categories and six different large virtual scenes with different time periods, weather environments, and altitudes. The annotations include environmental information, instance-level horizontal bounding boxes, oriented bounding boxes, and the type and ID of each ship. This provides the basis for object detection, oriented object detection, fine-grained recognition, and scene recognition. To investigate the applications of UnityShip, the synthetic data were validated for model pre-training and data augmentation using three different object detection algorithms and six existing real-world ship detection datasets. Our experimental results show that for small-sized and medium-sized real-world datasets, the synthetic data achieve an improvement in model pre-training and data augmentation, showing the value and potential of synthetic data in aerial image recognition and understanding tasks.},
DOI = {10.3390/rs13244999}
}



@Article{plants10122707,
AUTHOR = {Gardiner, Laura-Jayne and Krishna, Ritesh},
TITLE = {Bluster or Lustre: Can AI Improve Crops and Plant Health?},
JOURNAL = {Plants},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2707},
URL = {https://www.mdpi.com/2223-7747/10/12/2707},
PubMedID = {34961177},
ISSN = {2223-7747},
ABSTRACT = {In a changing climate where future food security is a growing concern, researchers are exploring new methods and technologies in the effort to meet ambitious crop yield targets. The application of Artificial Intelligence (AI) including Machine Learning (ML) methods in this area has been proposed as a potential mechanism to support this. This review explores current research in the area to convey the state-of-the-art as to how AI/ML have been used to advance research, gain insights, and generally enable progress in this area. We address the question&mdash;Can AI improve crops and plant health? We further discriminate the bluster from the lustre by identifying the key challenges that AI has been shown to address, balanced with the potential issues with its usage, and the key requisites for its success. Overall, we hope to raise awareness and, as a result, promote usage, of AI related approaches where they can have appropriate impact to improve practices in agricultural and plant sciences.},
DOI = {10.3390/plants10122707}
}



@Article{f12121736,
AUTHOR = {Ma, Minfei and Liu, Jianhong and Liu, Mingxing and Zeng, Jingchao and Li, Yuanhui},
TITLE = {Tree Species Classification Based on Sentinel-2 Imagery and Random Forest Classifier in the Eastern Regions of the Qilian Mountains},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1736},
URL = {https://www.mdpi.com/1999-4907/12/12/1736},
ISSN = {1999-4907},
ABSTRACT = {Obtaining accurate forest coverage of tree species is an important basis for the rational use and protection of existing forest resources. However, most current studies have mainly focused on broad tree classification, such as coniferous vs. broadleaf tree species, and a refined tree classification with tree species information is urgently needed. Although airborne LiDAR data or unmanned aerial vehicle (UAV) images can be used to acquire tree information even at the single tree level, this method will encounter great difficulties when applied to a large area. Therefore, this study takes the eastern regions of the Qilian Mountains as an example to explore the possibility of tree species classification with satellite-derived images. We used Sentinel-2 images to classify the study area&rsquo;s major vegetation types, particularly four tree species, i.e., Sabina przewalskii (S.P.), Picea crassifolia (P.C.), Betula spp. (Betula), and Populus spp. (Populus). In addition to the spectral features, we also considered terrain and texture features in this classification. The results show that adding texture features can significantly increase the separation between tree species. The final classification result of all categories achieved an accuracy of 86.49% and a Kappa coefficient of 0.83. For trees, the classification accuracy was 90.31%, and their producer&rsquo;s accuracy (PA) and user&rsquo;s (UA) were all higher than 84.97%. We found that altitude, slope, and aspect all affected the spatial distribution of these four tree species in our study area. This study confirms the potential of Sentinel-2 images for the fine classification of tree species. Moreover, this can help monitor ecosystem biological diversity and provide references for inventory estimation.},
DOI = {10.3390/f12121736}
}



@Article{smartcities4040078,
AUTHOR = {Shinde, Swapnil Sadashiv and Tarchi, Daniele},
TITLE = {Towards a Novel Air&ndash;Ground Intelligent Platform for Vehicular Networks: Technologies, Scenarios, and Challenges},
JOURNAL = {Smart Cities},
VOLUME = {4},
YEAR = {2021},
NUMBER = {4},
PAGES = {1469--1495},
URL = {https://www.mdpi.com/2624-6511/4/4/78},
ISSN = {2624-6511},
ABSTRACT = {Modern cities require a tighter integration with Information and Communication Technologies (ICT) for bringing new services to the citizens. The Smart City is the revolutionary paradigm aiming at integrating the ICT with the citizen life; among several urban services, transports are one of the most important in modern cities, introducing several challenges to the Smart City paradigm. In order to satisfy the stringent requirements of new vehicular applications and services, Edge Computing (EC) is one of the most promising technologies when integrated into the Vehicular Networks (VNs). EC-enabled VNs can facilitate new latency-critical and data-intensive applications and services. However, ground-based EC platforms (i.e., Road Side Units&mdash;RSUs, 5G Base Stations&mdash;5G BS) can only serve a reduced number of Vehicular Users (VUs), due to short coverage ranges and resource shortage. In the recent past, several new aerial platforms with integrated EC facilities have been deployed for achieving global connectivity. Such air-based EC platforms can complement the ground-based EC facilities for creating a futuristic VN able to deploy several new applications and services. The goal of this work is to explore the possibility of creating a novel joint air-ground EC platform within a VN architecture for helping VUs with new intelligent applications and services. By exploiting most modern technologies, with particular attention towards network softwarization, vehicular edge computing, and machine learning, we propose here three possible layered air-ground EC-enabled VN scenarios. For each of the discussed scenarios, a list of the possible challenges is considered, as well possible solutions allowing to overcome all or some of the considered challenges. A proper comparison is also done, through the use of tables, where all the proposed scenarios, and the proposed solutions, are discussed.},
DOI = {10.3390/smartcities4040078}
}



@Article{s21248253,
AUTHOR = {Balestrieri, Eulalia and Daponte, Pasquale and De Vito, Luca and Picariello, Francesco and Tudosa, Ioan},
TITLE = {Sensors and Measurements for UAV Safety: An Overview},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {8253},
URL = {https://www.mdpi.com/1424-8220/21/24/8253},
PubMedID = {34960347},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles&rsquo; (UAVs) safety has gained great research interest due to the increase in the number of UAVs in circulation and their applications, which has inevitably also led to an increase in the number of accidents in which these vehicles are involved. The paper presents a classification of UAV safety solutions that can be found in the scientific literature, putting in evidence the fundamental and critical role of sensors and measurements in the field. Proposals from research on each proposed class concerning flight test procedures, in-flight solutions including soft propeller use, fault and damage detection, collision avoidance and safe landing, as well as ground solution including testing and injury and damage quantification measurements are discussed.},
DOI = {10.3390/s21248253}
}



@Article{land10121365,
AUTHOR = {Agapiou, Athos and Vionis, Athanasios and Papantoniou, Giorgos},
TITLE = {Detection of Archaeological Surface Ceramics Using Deep Learning Image-Based Methods and Very High-Resolution UAV Imageries},
JOURNAL = {Land},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1365},
URL = {https://www.mdpi.com/2073-445X/10/12/1365},
ISSN = {2073-445X},
ABSTRACT = {Mapping surface ceramics through systematic pedestrian archaeological survey is considered a consistent method to recover the cultural biography of sites within a micro-region. Archaeologists nowadays conduct surface survey equipped with navigation devices counting, documenting, and collecting surface archaeological potsherds within a set of plotted grids. Recent advancements in unmanned aerial vehicles (UAVs) and image processing analysis can be utilised to support such surface archaeological investigations. In this study, we have implemented two different artificial intelligence image processing methods over two areas of interest near the present-day village of Kophinou in Cyprus, in the Xeros River valley. We have applied a random forest classifier through the Google Earth Engine big data cloud platform and a Single Shot Detector neural network in the ArcGIS Pro environment. For the first case study, the detection was based on red&ndash;green&ndash;blue (RGB) high-resolution orthophotos. In contrast, a multispectral camera covering both the visible and the near-infrared parts of the spectrum was used in the second area of investigation. The overall results indicate that such an approach can be used in the future as part of ongoing archaeological pedestrian surveys to detect scattered potsherds in areas of archaeological interest, even if pottery shares a very high spectral similarity with the surface.},
DOI = {10.3390/land10121365}
}



@Article{rs13245024,
AUTHOR = {Pan, Jiao and Li, Liang and Yamaguchi, Hiroshi and Hasegawa, Kyoko and Thufail, Fadjar I. and Brahmantara and Tanaka, Satoshi},
TITLE = {Integrated High-Definition Visualization of Digital Archives for Borobudur Temple},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5024},
URL = {https://www.mdpi.com/2072-4292/13/24/5024},
ISSN = {2072-4292},
ABSTRACT = {The preservation and analysis of tangible cultural heritage sites have attracted enormous interest worldwide. Recently, establishing three-dimensional (3D) digital archives has emerged as a critical strategy for the permanent preservation and digital analysis of cultural sites. For extant parts of cultural sites, 3D scanning is widely used for efficient and accurate digitization. However, in many historical sites, many parts that have been damaged or lost by natural or artificial disasters are unavailable for 3D scanning. The remaining available data sources for these destroyed parts are photos, computer-aided design (CAD) drawings, written descriptions, etc. In this paper, we achieve an integrated digital archive of a UNESCO World Heritage site, namely, the Borobudur temple, in which buried reliefs and internal foundations are not available for 3D scanning. We introduce a digitizing framework to integrate three different kinds of data sources and to create a unified point-cloud-type digital archive. This point-based integration enables us to digitally record the entire 3D structure of the target cultural heritage site. Then, the whole site is visualized by stochastic point-based rendering (SPBR) precisely and comprehensibly. The proposed framework is widely applicable to other large-scale cultural sites.},
DOI = {10.3390/rs13245024}
}



@Article{f12121747,
AUTHOR = {Liu, Wenjian and Li, Yanjie and Liu, Jun and Jiang, Jingmin},
TITLE = {Estimation of Plant Height and Aboveground Biomass of Toona sinensis under Drought Stress Using RGB-D Imaging},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1747},
URL = {https://www.mdpi.com/1999-4907/12/12/1747},
ISSN = {1999-4907},
ABSTRACT = {Rapid and accurate plant growth and biomass estimation is essential for formulating and implementing targeted forest cultivation measures. In this study, RGB-D imaging technology was used to obtain the RGB and depth imaging data for a Toona sinensis seedling canopy to estimate plant growth and aboveground biomass (AGB). Three hundred T. sinensis seedlings from 20 varieties were planted under five different drought stress treatments. The U-Net model was applied first to achieve highly accurate segmentation of plants from complex backgrounds. Simple linear regression (SLR) was used for plant height prediction, and the other three models, including multivariate linear (ML), random forest (RF) and multilayer perceptron (MLP) regression, were applied to predict the AGB and compared for optimal model selection. The results showed that the SLR model yields promising and reliable results for the prediction of plant height, with R2 and RMSE values of 0.72 and 1.89 cm, respectively. All three regression methods perform well in the prediction of AGB estimation. MLP yields the highest accuracy in predicting dry and fresh aboveground biomass compared to the other two regression models, with R2 values of 0.77 and 0.83, respectively. The combination of Gray, Green minus red (GMR) and Excess green index (ExG) was identified as the key predictor by RReliefF for predicting dry AGB. GMR was the most important in predicting fresh AGB. This study demonstrated that the merits of RGB-D and machine learning models are effective phenotyping techniques for plant height and AGB prediction, and can be used to assist dynamic responses to drought stress for breeding selection.},
DOI = {10.3390/f12121747}
}



@Article{mti5120081,
AUTHOR = {Rakkolainen, Ismo and Farooq, Ahmed and Kangas, Jari and Hakulinen, Jaakko and Rantala, Jussi and Turunen, Markku and Raisamo, Roope},
TITLE = {Technologies for Multimodal Interaction in Extended Reality&mdash;A Scoping Review},
JOURNAL = {Multimodal Technologies and Interaction},
VOLUME = {5},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {81},
URL = {https://www.mdpi.com/2414-4088/5/12/81},
ISSN = {2414-4088},
ABSTRACT = {When designing extended reality (XR) applications, it is important to consider multimodal interaction techniques, which employ several human senses simultaneously. Multimodal interaction can transform how people communicate remotely, practice for tasks, entertain themselves, process information visualizations, and make decisions based on the provided information. This scoping review summarized recent advances in multimodal interaction technologies for head-mounted display-based (HMD) XR systems. Our purpose was to provide a succinct, yet clear, insightful, and structured overview of emerging, underused multimodal technologies beyond standard video and audio for XR interaction, and to find research gaps. The review aimed to help XR practitioners to apply multimodal interaction techniques and interaction researchers to direct future efforts towards relevant issues on multimodal XR. We conclude with our perspective on promising research avenues for multimodal interaction technologies.},
DOI = {10.3390/mti5120081}
}



@Article{drones5040148,
AUTHOR = {Yazid, Yassine and Ez-Zazi, Imad and Guerrero-González, Antonio and El Oualkadi, Ahmed and Arioua, Mounir},
TITLE = {UAV-Enabled Mobile Edge-Computing for IoT Based on AI: A Comprehensive Review},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {148},
URL = {https://www.mdpi.com/2504-446X/5/4/148},
ISSN = {2504-446X},
ABSTRACT = {Unmanned aerial vehicles (UAVs) are becoming integrated into a wide range of modern IoT applications. The growing number of networked IoT devices generates a large amount of data. However, processing and memorizing this massive volume of data at local nodes have been deemed critical challenges, especially when using artificial intelligence (AI) systems to extract and exploit valuable information. In this context, mobile edge computing (MEC) has emerged as a way to bring cloud computing (CC) processes within reach of users, to address computation-intensive offloading and latency issues. This paper provides a comprehensive review of the most relevant research works related to UAV technology applications in terms of enabled or assisted MEC architectures. It details the utility of UAV-enabled MEC architecture regarding emerging IoT applications and the role of both deep learning (DL) and machine learning (ML) in meeting various limitations related to latency, task offloading, energy demand, and security. Furthermore, throughout this article, the reader gains an insight into the future of UAV-enabled MEC, the advantages and the critical challenges to be tackled when using AI.},
DOI = {10.3390/drones5040148}
}



@Article{infrastructures6120176,
AUTHOR = {Mousa, Mohammed Abbas and Yussof, Mustafasanie M. and Udi, Ufuoma Joseph and Nazri, Fadzli Mohamed and Kamarudin, Mohd Khairul and Parke, Gerard A. R. and Assi, Lateef N. and Ghahari, Seyed Ali},
TITLE = {Application of Digital Image Correlation in Structural Health Monitoring of Bridge Infrastructures: A Review},
JOURNAL = {Infrastructures},
VOLUME = {6},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {176},
URL = {https://www.mdpi.com/2412-3811/6/12/176},
ISSN = {2412-3811},
ABSTRACT = {A vision-based approach has been employed in Structural Health Monitoring (SHM) of bridge infrastructure. The approach has many advantages: non-contact, non-destructive, long-distance, high precision, immunity from electromagnetic interference, and multiple-target monitoring. This review aims to summarise the vision- and Digital Image Correlation (DIC)-based SHM methods for bridge infrastructure because of their strategic significance and security concerns. Four different bridge types were studied: concrete, suspension, masonry, and steel bridge. DIC applications in SHM have recently garnered attention in aiding to assess the bridges&rsquo; structural response mechanisms under loading. Different non-destructive diagnostics methods for SHM in civil infrastructure have been used; however, vision-based techniques like DIC were only developed over the last two decades, intending to facilitate damage detection in bridge systems with prompt and accurate data for efficient and sustainable operation of the bridge structure throughout its service life. Research works reviewed in this article demonstrated the DIC capability to detect damage such as cracks, spalling, and structural parameters such as deformation, strains, vibration, deflection, and rotation. In addition, the reviewed works indicated that the DIC as an efficient and reliable technique could provide sustainable monitoring solutions for different bridge infrastructures.},
DOI = {10.3390/infrastructures6120176}
}



@Article{sym13122417,
AUTHOR = {Zhu, Pengxing and Fang, Xi},
TITLE = {Multi-UAV Cooperative Task Assignment Based on Half Random Q-Learning},
JOURNAL = {Symmetry},
VOLUME = {13},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2417},
URL = {https://www.mdpi.com/2073-8994/13/12/2417},
ISSN = {2073-8994},
ABSTRACT = {Unmanned aerial vehicle (UAV) clusters usually face problems such as complex environments, heterogeneous combat subjects, and realistic interference factors in the course of mission assignment. In order to reduce resource consumption and improve the task execution rate, it is very important to develop a reasonable allocation plan for the tasks. Therefore, this paper constructs a heterogeneous UAV multitask assignment model based on several realistic constraints and proposes an improved half-random Q-learning (HR Q-learning) algorithm. The algorithm is based on the Q-learning algorithm under reinforcement learning, and by changing the way the Q-learning algorithm selects the next action in the process of random exploration, the probability of obtaining an invalid action in the random case is reduced, and the exploration efficiency is improved, thus increasing the possibility of obtaining a better assignment scheme, this also ensures symmetry and synergy in the distribution process of the drones. Simulation experiments show that compared with Q-learning algorithm and other heuristic algorithms, HR Q-learning algorithm can improve the performance of task execution, including the ability to improve the rationality of task assignment, increasing the value of gains by 12.12%, this is equivalent to an average of one drone per mission saved, and higher success rate of task execution. This improvement provides a meaningful attempt for UAV task assignment.},
DOI = {10.3390/sym13122417}
}



@Article{rs13245092,
AUTHOR = {Qin, Qiming and Wu, Zihua and Zhang, Tianyuan and Sagan, Vasit and Zhang, Zhaoxu and Zhang, Yao and Zhang, Chengye and Ren, Huazhong and Sun, Yuanheng and Xu, Wei and Zhao, Cong},
TITLE = {Optical and Thermal Remote Sensing for Monitoring Agricultural Drought},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5092},
URL = {https://www.mdpi.com/2072-4292/13/24/5092},
ISSN = {2072-4292},
ABSTRACT = {By effectively observing the land surface and obtaining farmland conditions, satellite remote sensing has played an essential role in agricultural drought monitoring over past decades. Among all remote sensing techniques, optical and thermal remote sensing have the most extended history of being utilized in drought monitoring. The primary goal of this paper is to illustrate how optical and thermal remote sensing have been and will be applied in the monitoring, assessment, and prediction of agricultural drought. We group the methods into four categories: optical, thermal, optical and thermal, and multi-source. For each category, a concise explanation is given to show the inherent mechanisms. We pay special attention to solar-induced chlorophyll fluorescence, which has great potential in early drought detection. Finally, we look at the future directions of agricultural drought monitoring, including (1) early detection; (2) spatio-temporal resolution; (3) organic combination of multi-source data; and (4) smart prediction and assessment based on deep learning and cloud computing.},
DOI = {10.3390/rs13245092}
}



@Article{en14248493,
AUTHOR = {Khalid, Adnan and Jaffery, Mujtaba Hussain and Javed, Muhammad Yaqoob and Yousaf, Adnan and Arshad, Jehangir and Ur Rehman, Ateeq and Haider, Aun and Althobaiti, Maha M. and Shafiq, Muhammad and Hamam, Habib},
TITLE = {Performance Analysis of Mars-Powered Descent-Based Landing in a Constrained Optimization Control Framework},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {8493},
URL = {https://www.mdpi.com/1996-1073/14/24/8493},
ISSN = {1996-1073},
ABSTRACT = {It is imperative to find new places other than Earth for the survival of human beings. Mars could be the alternative to Earth in the future for us to live. In this context, many missions have been performed to examine the planet Mars. For such missions, planetary precision landing is a major challenge for the precise landing on Mars. Mars landing consists of different phases (hypersonic entry, parachute descent, terminal descent comprising gravity turn, and powered descent). However, the focus of this work is the powered descent phase of landing. Firstly, the main objective of this study is to minimize the landing error during the powered descend landing phase. The second objective involves constrained optimization in a predictive control framework for landing at non-cooperative sites. Different control algorithms like PID and LQR have been developed for the stated problem; however, the predictive control algorithm with constraint handling&rsquo;s ability has not been explored much. This research discusses the Model Predictive Control algorithm for the powered descent phase of landing. Model Predictive Control (MPC) considers input/output constraints in the calculation of the control law and thus it is very useful for the stated problem as shown in the results. The main novelty of this work is the implementation of Explicit MPC, which gives comparatively less computational time than MPC. A comparison is done among MPC variants in terms of feasibility, constraints handling, and computational time. Moreover, other conventional control algorithms like PID and LQR are compared with the proposed predictive algorithm. These control algorithms are implemented on quadrotor UAV (which emulates the dynamics of a planetary lander) to verify the feasibility through simulations in MATLAB.},
DOI = {10.3390/en14248493}
}



@Article{rs13245119,
AUTHOR = {Laugier, Elise Jakoby and Casana, Jesse},
TITLE = {Integrating Satellite, UAV, and Ground-Based Remote Sensing in Archaeology: An Exploration of Pre-Modern Land Use in Northeastern Iraq},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5119},
URL = {https://www.mdpi.com/2072-4292/13/24/5119},
ISSN = {2072-4292},
ABSTRACT = {Satellite remote sensing is well demonstrated to be a powerful tool for investigating ancient land use in Southwest Asia. However, few regional studies have systematically integrated satellite-based observations with more intensive remote sensing technologies, such as drone-deployed multispectral sensors and ground-based geophysics, to explore off-site areas. Here, we integrate remote sensing data from a variety of sources and scales including historic aerial photographs, modern satellite imagery, drone-deployed sensors, and ground-based geophysics to explore pre-modern land use along the Upper Diyala/Sirwan River in the Kurdistan Region of Iraq. Our analysis reveals an incredible diversity of land use features, including canals, qanats, trackways, and field systems, most of which likely date to the first millennium CE, and demonstrate the potential of more intensive remote sensing methods to resolve land use features. Our results align with broader trends across ancient Southwest Asia that document the most intensive land use in the first millennium BCE through the first millennium CE. Land use features dating to the earlier Bronze Age (fourth through second millennium BCE) remain elusive and will likely require other investigative approaches.},
DOI = {10.3390/rs13245119}
}



@Article{machines9120360,
AUTHOR = {Yang, Pu and Wen, Chenwan and Geng, Huilin and Liu, Peng},
TITLE = {Intelligent Fault Diagnosis Method for Blade Damage of Quad-Rotor UAV Based on Stacked Pruning Sparse Denoising Autoencoder and Convolutional Neural Network},
JOURNAL = {Machines},
VOLUME = {9},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {360},
URL = {https://www.mdpi.com/2075-1702/9/12/360},
ISSN = {2075-1702},
ABSTRACT = {This paper introduces a new intelligent fault diagnosis method based on stack pruning sparse denoising autoencoder and convolutional neural network (sPSDAE-CNN). This method processes the original input data by using a stack denoising autoencoder. Different from the traditional autoencoder, stack pruning sparse denoising autoencoder includes a fully connected autoencoding network, the features extracted from the front layer of the network are used for the operation of the subsequent layer, which means that some new connections will appear between the front and rear layers of the network, reduce the loss of information, and obtain more effective features. Firstly, a one-dimensional sliding window is introduced for data enhancement. In addition, transforming one-dimensional time-domain data into the two-dimensional gray image can further improve the deep learning (DL) ability of models. At the same time, pruning operation is introduced to improve the training efficiency and accuracy of the network. The convolutional neural network model with sPSDAE has a faster training speed, strong adaptability to noise interference signals, and can also suppress the over-fitting problem of the convolutional neural network to a certain extent. Actual experiments show that for the fault of unmanned aerial vehicle (UAV) blade damage, the sPSDAE-CNN model we use has better stability and reliable prediction accuracy than traditional convolutional neural networks. At the same time, For noise signals, better results can be obtained. The experimental results show that the sPSDAE-CNN model still has a good diagnostic accuracy rate in a high-noise environment. In the case of a signal-to-noise ratio of &minus;4, it still has an accuracy rate of 90%.},
DOI = {10.3390/machines9120360}
}



@Article{photonics8120582,
AUTHOR = {Kior, Anastasiia and Sukhov, Vladimir and Sukhova, Ekaterina},
TITLE = {Application of Reflectance Indices for Remote Sensing of Plants and Revealing Actions of Stressors},
JOURNAL = {Photonics},
VOLUME = {8},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {582},
URL = {https://www.mdpi.com/2304-6732/8/12/582},
ISSN = {2304-6732},
ABSTRACT = {Environmental conditions are very changeable; fluctuations in temperature, precipitation, illumination intensity, and other factors can decrease a plant productivity and crop. The remote sensing of plants under these conditions is the basis for the protection of plants and increases their survivability. This problem can be solved through measurements of plant reflectance and calculation of reflectance indices. Reflectance indices are related to the vegetation biomass, specific physiological processes, and biochemical compositions in plants; the indices can be used for both short-term and long-term plant monitoring. In our review, we considered the applications of reflectance indices in plant remote sensing. In Optical Methods and Platforms of Remote Sensing of Plants, we briefly discussed multi- and hyperspectral imaging, including descriptions of multispectral and hyperspectral cameras with different principles and their efficiency for the remote sensing of plants. In Main Reflectance Indices, we described the main reflectance indices, including vegetation, water, and pigment reflectance indices, as well as the photochemical reflectance index and its modifications. We focused on the relationships of leaf reflectance and reflectance indices to plant biomass, development, and physiological and biochemical characteristics. In Problems of Measurement and Analysis of Reflectance Indices, we discussed the methods of the correction of the reflectance indices that can be used for decreasing the influence of environmental conditions (mainly illumination, air, and soil) and plant characteristics (orientation of leaves, their thickness, and others) on their measurements and the analysis of the plant remote sensing. Additionally, the variability of plants was also considered as an important factor that influences the results of measurement and analysis.},
DOI = {10.3390/photonics8120582}
}



@Article{s21248425,
AUTHOR = {Garbouge, Hadhami and Rasti, Pejman and Rousseau, David},
TITLE = {Enhancing the Tracking of Seedling Growth Using RGB-Depth Fusion and Deep Learning},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {8425},
URL = {https://www.mdpi.com/1424-8220/21/24/8425},
PubMedID = {34960519},
ISSN = {1424-8220},
ABSTRACT = {The use of high-throughput phenotyping with imaging and machine learning to monitor seedling growth is a tough yet intriguing subject in plant research. This has been recently addressed with low-cost RGB imaging sensors and deep learning during day time. RGB-Depth imaging devices are also accessible at low-cost and this opens opportunities to extend the monitoring of seedling during days and nights. In this article, we investigate the added value to fuse RGB imaging with depth imaging for this task of seedling growth stage monitoring. We propose a deep learning architecture along with RGB-Depth fusion to categorize the three first stages of seedling growth. Results show an average performance improvement of 5% correct recognition rate by comparison with the sole use of RGB images during the day. The best performances are obtained with the early fusion of RGB and Depth. Also, Depth is shown to enable the detection of growth stage in the absence of the light.},
DOI = {10.3390/s21248425}
}



@Article{rs13245129,
AUTHOR = {Zhang, Xinyu and Yuan, Yaxin and Zhu, Zequn and Ma, Qingshan and Yu, Hongyan and Li, Meng and Ma, Jianhai and Yi, Shuhua and He, Xiongzhao and Sun, Yi},
TITLE = {Predicting the Distribution of Oxytropis ochrocephala Bunge in the Source Region of the Yellow River (China) Based on UAV Sampling Data and Species Distribution Model},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5129},
URL = {https://www.mdpi.com/2072-4292/13/24/5129},
ISSN = {2072-4292},
ABSTRACT = {Oxytropis ochrocephala Bunge is an herbaceous perennial poisonous weed. It severely affects the production of local animal husbandry and ecosystem stability in the source region of Yellow River (SRYR), China. To date, however, the spatiotemporal distribution of O. ochrocephala is still unclear, mainly due to lack of high-precision observation data and effective methods at a regional scale. In this study, an efficient sampling method, based on unmanned aerial vehicle (UAV), was proposed to supply basic sampling data for species distribution models (SDMs, BIOMOD in this study). A total of 3232 aerial photographs were obtained, from 2018 to 2020, in SRYR, and the potential and future distribution of O. ochrocephala were predicted by an ensemble model, consisting of six basic models of BIOMOD. The results showed that: (1) O. ochrocephala mainly distributed in the southwest, middle, and northeast of the SRYR, and the high suitable habitat of O. ochrocephala accounted for 3.19%; (2) annual precipitation and annual mean temperature were the two most important factors that affect the distribution of O. ochrocephala, with a cumulative importance of 60.45%; and (3) the distribution probability of O. ochrocephala tends to increase from now to the 2070s, while spatial distribution ranges will remain in the southwest, middle, and northeast of the SRYR. This study shows that UAVs can potentially be used to obtain the basic data for species distribution modeling; the results are both beneficial to establishing reasonable management practices and animal husbandry in alpine grassland systems.},
DOI = {10.3390/rs13245129}
}



@Article{app112412093,
AUTHOR = {Pérez-González, Andrés and Benítez-Montoya, Nelson and Jaramillo-Duque, Álvaro and Cano-Quintero, Juan Bernardo},
TITLE = {Coverage Path Planning with Semantic Segmentation for UAV in PV Plants},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {12093},
URL = {https://www.mdpi.com/2076-3417/11/24/12093},
ISSN = {2076-3417},
ABSTRACT = {Solar energy is one of the most strategic energy sources for the world&rsquo;s economic development. This has caused the number of solar photovoltaic plants to increase around the world; consequently, they are installed in places where their access and manual inspection are arduous and risky tasks. Recently, the inspection of photovoltaic plants has been conducted with the use of unmanned aerial vehicles (UAV). Although the inspection with UAVs can be completed with a drone operator, where the UAV flight path is purely manual or utilizes a previously generated flight path through a ground control station (GCS). However, the path generated in the GCS has many restrictions that the operator must supply. Due to these restrictions, we present a novel way to develop a flight path automatically with coverage path planning (CPP) methods. Using a DL server to segment the region of interest (RoI) within each of the predefined PV plant images, three CPP methods were also considered and their performances were assessed with metrics. The UAV energy consumption performance in each of the CPP methods was assessed using two different UAVs and standard metrics. Six experiments were performed by varying the CPP width, and the consumption metrics were recorded in each experiment. According to the results, the most effective and efficient methods are the exact cellular decomposition boustrophedon and grid-based wavefront coverage, depending on the CPP width and the area of the PV plant. Finally, a relationship was established between the size of the photovoltaic plant area and the best UAV to perform the inspection with the appropriate CPP width. This could be an important result for low-cost inspection with UAVs, without high-resolution cameras on the UAV board, and in small plants.},
DOI = {10.3390/app112412093}
}



@Article{s21248477,
AUTHOR = {Mohammadi, Roozbeh and Roncoli, Claudio},
TITLE = {Towards Data-Driven Vehicle Estimation for Signalised Intersections in a Partially Connected Environment},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {8477},
URL = {https://www.mdpi.com/1424-8220/21/24/8477},
PubMedID = {34960571},
ISSN = {1424-8220},
ABSTRACT = {Connected vehicles (CVs) have the potential to collect and share information that, if appropriately processed, can be employed for advanced traffic control strategies, rendering infrastructure-based sensing obsolete. However, before we reach a fully connected environment, where all vehicles are CVs, we have to deal with the challenge of incomplete data. In this paper, we develop data-driven methods for the estimation of vehicles approaching a signalised intersection, based on the availability of partial information stemming from an unknown penetration rate of CVs. In particular, we build machine learning models with the aim of capturing the nonlinear relations between the inputs (CV data) and the output (number of non-connected vehicles), which are characterised by highly complex interactions and may be affected by a large number of factors. We show that, in order to train these models, we may use data that can be easily collected with modern technologies. Moreover, we demonstrate that, if the available real data is not deemed sufficient, training can be performed using synthetic data, produced via microscopic simulations calibrated with real data, without a significant loss of performance. Numerical experiments, where the estimation methods are tested using real vehicle data simulating the presence of various penetration rates of CVs, show very good performance of the estimators, making them promising candidates for applications in the near future.},
DOI = {10.3390/s21248477}
}



@Article{machines9120371,
AUTHOR = {Wang, Wu and Guo, Junyou and Tian, Guoqing and Chen, Yutao and Huang, Jie},
TITLE = {Event-Triggered Intervention Framework for UAV-UGV Coordination Systems},
JOURNAL = {Machines},
VOLUME = {9},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {371},
URL = {https://www.mdpi.com/2075-1702/9/12/371},
ISSN = {2075-1702},
ABSTRACT = {Air-ground coordination systems are usually composed of unmanned aerial vehicles (UAV) and unmanned ground vehicles (UGV). In such a system, UAVs can utilize their much more perceptive information to plan the path for UGVs. However, the correctness and accuracy of the planned route are often not guaranteed, and the communication and computation burdens increase with more sophisticated algorithms. This paper proposes a new type of air-ground coordination framework to enable UAVs intervention into UGVs tasks. An event-triggered mechanism in the null space behavior control (NSBC) framework is proposed to decide if an intervention is necessary and the timing of the intervention. Then, the problem of whether to accept the intervention is formulated as an integer programming problem and is solved using model predictive control (MPC). Simulation results show that the UAV can intervene in UGVs accurately and on time, and the UGVs can effectively decide whether to accept the intervention to get rid of troubles, thereby improving the intelligence of the air-ground coordination system.},
DOI = {10.3390/machines9120371}
}



@Article{rs13245182,
AUTHOR = {Etienne, Aaron and Ahmad, Aanis and Aggarwal, Varun and Saraswat, Dharmendra},
TITLE = {Deep Learning-Based Object Detection System for Identifying Weeds Using UAS Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5182},
URL = {https://www.mdpi.com/2072-4292/13/24/5182},
ISSN = {2072-4292},
ABSTRACT = {Current methods of broadcast herbicide application cause a negative environmental and economic impact. Computer vision methods, specifically those related to object detection, have been reported to aid in site-specific weed management procedures for targeted herbicide application within a field. However, a major challenge to developing a weed detection system is the requirement for a properly annotated database to differentiate between weeds and crops under field conditions. This research involved creating an annotated database of 374 red, green, and blue (RGB) color images organized into monocot and dicot weed classes. The images were acquired from corn and soybean research plots located in north-central Indiana using an unmanned aerial system (UAS) flown at 30 and 10 m heights above ground level (AGL). A total of 25,560 individual weed instances were manually annotated. The annotated database consisted of four different subsets (Training Image Sets 1&ndash;4) to train the You Only Look Once version 3 (YOLOv3) deep learning model for five separate experiments. The best results were observed with Training Image Set 4, consisting of images acquired at 10 m AGL. For monocot and dicot weeds, respectively, an average precision (AP) score of 91.48 % and 86.13% was observed at a 25% IoU threshold (AP @ T = 0.25), as well as 63.37% and 45.13% at a 50% IoU threshold (AP @ T = 0.5). This research has demonstrated a need to develop large, annotated weed databases to evaluate deep learning models for weed identification under field conditions. It also affirms the findings of other limited research studies utilizing object detection for weed identification under field conditions.},
DOI = {10.3390/rs13245182}
}



@Article{app112412164,
AUTHOR = {Li, Changchun and Wang, Yilin and Ma, Chunyan and Chen, Weinan and Li, Yacong and Li, Jingbo and Ding, Fan and Xiao, Zhen},
TITLE = {Improvement of Wheat Grain Yield Prediction Model Performance Based on Stacking Technique},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {12164},
URL = {https://www.mdpi.com/2076-3417/11/24/12164},
ISSN = {2076-3417},
ABSTRACT = {Crop growth and development is a dynamic and complex process, and the essence of yield formation is the continuous accumulation of photosynthetic products from multiple fertility stages. In this study, a new stacking method for integrating multiple growth stages information was proposed to improve the performance of the winter wheat grain yield (GY) prediction model. For this purpose, crop canopy hyperspectral reflectance and leaf area index (LAI) data were obtained at the jointing, flagging, anthesis and grain filling stages. In this case, 15 vegetation indices and LAI were used as input features of the elastic network to construct GY prediction models for single growth stage. Based on Stacking technique, the GY prediction results of four single growth stages were integrated to construct the ensemble learning framework. The results showed that vegetation indices coupled LAI could effectively overcome the spectral saturation phenomenon, the validated R2 of each growth stage was improved by 10%, 22.5%, 3.6% and 10%, respectively. The stacking method provided more stable information with higher prediction accuracy than the individual fertility results (R2 = 0.74), and the R2 of the model validation phase improved by 236%, 51%, 27.6%, and 12.1%, respectively. The study can provide a reference for GY prediction of other crops.},
DOI = {10.3390/app112412164}
}



@Article{jmse10010003,
AUTHOR = {Zhu, Zhongxian and Lyu, Hongguang and Zhang, Jundong and Yin, Yong},
TITLE = {An Efficient Ship Automatic Collision Avoidance Method Based on Modified Artificial Potential Field},
JOURNAL = {Journal of Marine Science and Engineering},
VOLUME = {10},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {3},
URL = {https://www.mdpi.com/2077-1312/10/1/3},
ISSN = {2077-1312},
ABSTRACT = {A novel collision avoidance (CA) algorithm was proposed based on the modified artificial potential field (APF) method, to construct a practical ship automatic CA system. Considering the constraints of both the International Regulations for Preventing Collisions at Sea (COLREGS) and the motion characteristics of the ship, the multi-ship CA algorithm was realized by modifying the repulsive force model in the APF method. Furthermore, the distance from the closest point of approach-time to the closest point of approach (DCPA-TCPA) criterion was selected as the unique adjustable parameter from the perspective of navigation practice. Collaborative CA experiments were designed and conducted to validate the proposed algorithm. The results of the experiments revealed that the actual DCPA and TCPA agree well with the parameter setup that keeps the ship at a safe distance from other ships in complex encountering situations. Consequently, the algorithm proposed in this study can achieve efficient automatic CA with minimal parameter settings. Moreover, the navigators can easily accept and comprehend the adjustable parameters, enabling the algorithm to satisfy the demand of the engineering applications.},
DOI = {10.3390/jmse10010003}
}



@Article{info13010002,
AUTHOR = {Avola, Danilo and Cinque, Luigi and Di Mambro, Angelo and Diko, Anxhelo and Fagioli, Alessio and Foresti, Gian Luca and Marini, Marco Raoul and Mecca, Alessio and Pannone, Daniele},
TITLE = {Low-Altitude Aerial Video Surveillance via One-Class SVM Anomaly Detection from Textural Features in UAV Images},
JOURNAL = {Information},
VOLUME = {13},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {2},
URL = {https://www.mdpi.com/2078-2489/13/1/2},
ISSN = {2078-2489},
ABSTRACT = {In recent years, small-scale Unmanned Aerial Vehicles (UAVs) have been used in many video surveillance applications, such as vehicle tracking, border control, dangerous object detection, and many others. Anomaly detection can represent a prerequisite of many of these applications thanks to its ability to identify areas and/or objects of interest without knowing them a priori. In this paper, a One-Class Support Vector Machine (OC-SVM) anomaly detector based on customized Haralick textural features for aerial video surveillance at low-altitude is presented. The use of a One-Class SVM, which is notoriously a lightweight and fast classifier, enables the implementation of real-time systems even when these are embedded in low-computational small-scale UAVs. At the same time, the use of textural features allows a vision-based system to detect micro and macro structures of an analyzed surface, thus allowing the identification of small and large anomalies, respectively. The latter aspect plays a key role in aerial video surveillance at low-altitude, i.e., 6 to 15 m, where the detection of common items, e.g., cars, is as important as the detection of little and undefined objects, e.g., Improvised Explosive Devices (IEDs). Experiments obtained on the UAV Mosaicking and Change Detection (UMCD) dataset show the effectiveness of the proposed system in terms of accuracy, precision, recall, and F1-score, where the model achieves a 100% precision, i.e., never misses an anomaly, but at the expense of a reasonable trade-off in its recall, which still manages to reach up to a 71.23% score. Moreover, when compared to classical Haralick textural features, the model obtains significantly higher performances, i.e., &asymp;20% on all metrics, further demonstrating the approach effectiveness.},
DOI = {10.3390/info13010002}
}



@Article{su14010071,
AUTHOR = {Kumar, Arun and Sharma, Sharad and Singh, Aman and Alwadain, Ayed and Choi, Bong-Jun and Manual-Brenosa, Jose and Ortega-Mansilla, Arturo and Goyal, Nitin},
TITLE = {Revolutionary Strategies Analysis and Proposed System for Future Infrastructure in Internet of Things},
JOURNAL = {Sustainability},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {71},
URL = {https://www.mdpi.com/2071-1050/14/1/71},
ISSN = {2071-1050},
ABSTRACT = {The Internet of Things (IoT) has changed the worldwide network of people, smart devices, intelligent things, data, and information as an emergent technology. IoT development is still in its early stages, and numerous interrelated challenges must be addressed. IoT is the unifying idea of embedding everything. The Internet of Things offers a huge opportunity to improve the world&rsquo;s accessibility, integrity, availability, scalability, confidentiality, and interoperability. However, securing the Internet of Things is a difficult issue. The IoT aims to connect almost everything within the framework of a common infrastructure. This helps in controlling devices and, will allow device status to be updated everywhere and at any time. To develop technology via IoT, several critical scientific studies and inquiries have been carried out. However, many obstacles and problems remain to be tackled in order to reach IoT&rsquo;s maximum potential. These problems and concerns must be taken into consideration in different areas of the IoT, such as implementation in remote areas, threats to the system, development support, social and environmental impacts, etc. This paper reviews the current state of the art in different IoT architectures, with a focus on current technologies, applications, challenges, IoT protocols, and opportunities. As a result, a detailed taxonomy of IoT is presented here which includes interoperability, scalability, security and energy efficiency, among other things. Moreover, the significance of blockchains and big data as well as their analysis in relation to IoT, is discussed. This article aims to help readers and researchers understand the IoT and its applicability to the real world.},
DOI = {10.3390/su14010071}
}



@Article{s22010031,
AUTHOR = {Feng, Ziheng and Song, Li and Duan, Jianzhao and He, Li and Zhang, Yanyan and Wei, Yongkang and Feng, Wei},
TITLE = {Monitoring Wheat Powdery Mildew Based on Hyperspectral, Thermal Infrared, and RGB Image Data Fusion},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {31},
URL = {https://www.mdpi.com/1424-8220/22/1/31},
PubMedID = {35009575},
ISSN = {1424-8220},
ABSTRACT = {Powdery mildew severely affects wheat growth and yield; therefore, its effective monitoring is essential for the prevention and control of the disease and global food security. In the present study, a spectroradiometer and thermal infrared cameras were used to obtain hyperspectral signature and thermal infrared images data, and thermal infrared temperature parameters (TP) and texture features (TF) were extracted from the thermal infrared images and RGB images of wheat with powdery mildew, during the wheat flowering and filling periods. Based on the ten vegetation indices from the hyperspectral data (VI), TF and TP were integrated, and partial least square regression, random forest regression (RFR), and support vector machine regression (SVR) algorithms were used to construct a prediction model for a wheat powdery mildew disease index. According to the results, the prediction accuracy of RFR was higher than in other models, under both single data source modeling and multi-source data modeling; among the three data sources, VI was the most suitable for powdery mildew monitoring, followed by TP, and finally TF. The RFR model had stable performance in multi-source data fusion modeling (VI&amp;TP&amp;TF), and had the optimal estimation performance with 0.872 and 0.862 of R2 for calibration and validation, respectively. The application of multi-source data collaborative modeling could improve the accuracy of remote sensing monitoring of wheat powdery mildew, and facilitate the achievement of high-precision remote sensing monitoring of crop disease status.},
DOI = {10.3390/s22010031}
}



@Article{s22010059,
AUTHOR = {Huang, Heqing and Huang, Tongbin and Li, Zhen and Lyu, Shilei and Hong, Tao},
TITLE = {Design of Citrus Fruit Detection System Based on Mobile Platform and Edge Computer Device},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {59},
URL = {https://www.mdpi.com/1424-8220/22/1/59},
PubMedID = {35009602},
ISSN = {1424-8220},
ABSTRACT = {Citrus fruit detection can provide technical support for fine management and yield determination of citrus orchards. Accurate detection of citrus fruits in mountain orchards is challenging because of leaf occlusion and citrus fruit mutual occlusion of different fruits. This paper presents a citrus detection task that combines UAV data collection, AI embedded device, and target detection algorithm. The system used a small unmanned aerial vehicle equipped with a camera to take full-scale pictures of citrus trees; at the same time, we extended the state-of-the-art model target detection algorithm, added the attention mechanism and adaptive fusion feature method, improved the model&rsquo;s performance; to facilitate the deployment of the model, we used the pruning method to reduce the amount of model calculation and parameters. The improved target detection algorithm is ported to the edge computing end to detect the data collected by the unmanned aerial vehicle. The experiment was performed on the self-made citrus dataset, the detection accuracy was 93.32%, and the processing speed at the edge computing device was 180 ms/frame. This method is suitable for citrus detection tasks in the mountainous orchard environment, and it can help fruit growers to estimate their yield.},
DOI = {10.3390/s22010059}
}



@Article{rs14010050,
AUTHOR = {He, Haiqing and Yu, Jing and Cheng, Penggen and Wang, Yuqian and Zhu, Yufeng and Lin, Taiqing and Dai, Guoqiang},
TITLE = {Automatic, Multiview, Coplanar Extraction for CityGML Building Model Texture Mapping},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {50},
URL = {https://www.mdpi.com/2072-4292/14/1/50},
ISSN = {2072-4292},
ABSTRACT = {Most 3D CityGML building models in street-view maps (e.g., Google, Baidu) lack texture information, which is generally used to reconstruct real-scene 3D models by photogrammetric techniques, such as unmanned aerial vehicle (UAV) mapping. However, due to its simplified building model and inaccurate location information, the commonly used photogrammetric method using a single data source cannot satisfy the requirement of texture mapping for the CityGML building model. Furthermore, a single data source usually suffers from several problems, such as object occlusion. We proposed a novel approach to achieve CityGML building model texture mapping by multiview coplanar extraction from UAV remotely sensed or terrestrial images to alleviate these problems. We utilized a deep convolutional neural network to filter out object occlusion (e.g., pedestrians, vehicles, and trees) and obtain building-texture distribution. Point-line-based features are extracted to characterize multiview coplanar textures in 2D space under the constraint of a homography matrix, and geometric topology is subsequently conducted to optimize the boundary of textures by using a strategy combining Hough-transform and iterative least-squares methods. Experimental results show that the proposed approach enables texture mapping for building fa&ccedil;ades to use 2D terrestrial images without the requirement of exterior orientation information; that is, different from the photogrammetric method, a collinear equation is not an essential part to capture texture information. In addition, the proposed approach can significantly eliminate blurred and distorted textures of building models, so it is suitable for automatic and rapid texture updates.},
DOI = {10.3390/rs14010050}
}



@Article{machines10010012,
AUTHOR = {Andrade, Fabio A. A. and Guedes, Ihannah P. and Carvalho, Guilherme F. and Zachi, Alessandro R. L. and Haddad, Diego B. and Almeida, Luciana F. and de Melo, Aurélio G. and Pinto, Milena F.},
TITLE = {Unmanned Aerial Vehicles Motion Control with Fuzzy Tuning of Cascaded-PID Gains},
JOURNAL = {Machines},
VOLUME = {10},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {12},
URL = {https://www.mdpi.com/2075-1702/10/1/12},
ISSN = {2075-1702},
ABSTRACT = {One of the main challenges of maneuvering an Unmanned Aerial Vehicle (UAV) to keep a stabilized flight is dealing with its fast and highly coupled nonlinear dynamics. There are several solutions in the literature, but most of them require fine-tuning of the parameters. In order to avoid the exhaustive tuning procedures, this work employs a Fuzzy Logic strategy for online tuning of the PID gains of the UAV motion controller. A Cascaded-PID scheme is proposed, in which velocity commands are calculated and sent to the flight control unit from a given target desired position (waypoint). Therefore, the flight control unit is responsible for the lower control loop. The main advantage of the proposed method is that it can be applied to any UAV without the need of its formal mathematical model. Robot Operating System (ROS) is used to integrate the proposed system and the flight control unit. The solution was evaluated through flight tests and simulations, which were conducted using Unreal Engine 4 with the Microsoft AirSim plugin. In the simulations, the proposed method is compared with the traditional Ziegler-Nichols tuning method, another Fuzzy Logic approach, and the ArduPilot built-in PID controller. The simulation results show that the proposed method, compared to the ArduPilot controller, drives the UAV to reach the desired setpoint faster. When compared to Ziegler-Nichols and another different Fuzzy Logic approach, the proposed method demonstrates to provide a faster accommodation and yield smaller errors amplitudes.},
DOI = {10.3390/machines10010012}
}



@Article{electronics11010047,
AUTHOR = {Kouhalvandi, Lida and Matekovits, Ladislau and Peter, Ildiko},
TITLE = {Deep Learning Assisted Automatic Methodology for Implanted MIMO Antenna Designs on Large Ground Plane},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {47},
URL = {https://www.mdpi.com/2079-9292/11/1/47},
ISSN = {2079-9292},
ABSTRACT = {This paper provides a novel methodology for designing implanted multiple-input and multiple-output (MIMO) antennas in the automatic fashion. The proposed optimization consists of two sequential phases for firstly configuring the geometry of an implanted MIMO antenna and then sizing the design parameters through the hierarchy top-down optimization (TDO) and regression deep neural network (DNN), respectively. It tackles the difficulty in constructing the structure of antennas and also provides optimal values for the determined variables, sufficiently. This methodology results in valid electromagnetic (EM)-verified post-layout generation that is ready-to-fabricate. The effectiveness of the proposed optimization-oriented method is verified by designing and optimizing the implanted MIMO antenna in the frequency band of 4.34&ndash;4.61 GHz and 5.86&ndash;6.64 GHz suitable for medical applications at the emerging wireless band. For our design, we employ the actual biological tissues as bone, liquid (%1 sodium chloride, %40 sugar in distilled water), and plexiglass surroundings with a bio-compatible substrate, as aluminium oxide on a large ground plane, that is suitable to be used in a particular biomedical applications involving smart implants.},
DOI = {10.3390/electronics11010047}
}



@Article{infrastructures7010002,
AUTHOR = {Olayode, Isaac Oyeyemi and Severino, Alessandro and Tartibu, Lagouge Kwanda and Arena, Fabio and Cakici, Ziya},
TITLE = {Performance Evaluation of a Hybrid PSO Enhanced ANFIS Model in Prediction of Traffic Flow of Vehicles on Freeways: Traffic Data Evidence from South Africa},
JOURNAL = {Infrastructures},
VOLUME = {7},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {2},
URL = {https://www.mdpi.com/2412-3811/7/1/2},
ISSN = {2412-3811},
ABSTRACT = {In the last few years, there has been a significant rise in the number of private vehicles ownership, migration of people from rural areas to urban cities, and the rise in the number of under-maintained freeways; all these have added to the perennial problem of traffic congestion. Traffic flow prediction has been recognized as the solution in alleviating and reducing the problem of traffic congestion. In this research, we developed an adaptive neuro-fuzzy inference system trained by particle swarm optimization (ANFIS-PSO) by performing an evaluative performance of the model through traffic flow modelling of vehicles on five freeways (N1,N3,N12,N14&nbsp;and&nbsp;N17) using South Africa Transportation System as a case study. Six hundred and fifty (650) traffic data were collected using inductive loop detectors and video cameras from the five freeways. The traffic data used for developing these models comprises traffic volume, traffic density, speed of vehicles, time, and different types of vehicles. The traffic data were divided into 70% and 30% for the training and validation of the model. The model results show a positively correlated optimal performance between the inputs and the output with a regression value R2&nbsp; of 0.9978 and 0.9860 for the training and testing. The result of this research shows that the soft computing model ANFIS-PSO used in this research can model vehicular traffic flow on freeways. Furthermore, the evidence from this research suggests that the on-peak and off-peak hours are significant determinants of vehicular traffic flow on freeways. The modelling approach developed in this research will assist urban planners in developing practical ways to tackle traffic congestion and assist motorists and pedestrians in travel behaviour decision-making. Finally, the approach used in this study will assist transportation engineers in making constructive and safety dependent guidelines for drivers and pedestrians on freeways.},
DOI = {10.3390/infrastructures7010002}
}



@Article{rs14010075,
AUTHOR = {Reder, Stefan and Mund, Jan-Peter and Albert, Nicole and Waßermann, Lilli and Miranda, Luis},
TITLE = {Detection of Windthrown Tree Stems on UAV-Orthomosaics Using U-Net Convolutional Networks},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {75},
URL = {https://www.mdpi.com/2072-4292/14/1/75},
ISSN = {2072-4292},
ABSTRACT = {The increasing number of severe storm events is threatening European forests. Besides the primary damages directly caused by storms, there are secondary damages such as bark beetle outbreaks and tertiary damages due to negative effects on the market. These subsequent damages can be minimized if a detailed overview of the affected area and the amount of damaged wood can be obtained quickly and included in the planning of clearance measures. The present work utilizes UAV-orthophotos and an adaptation of the U-Net architecture for the semantic segmentation and localization of windthrown stems. The network was pre-trained with generic datasets, randomly combining stems and background samples in a copy&ndash;paste augmentation, and afterwards trained with a specific dataset of a particular windthrow. The models pre-trained with generic datasets containing 10, 50 and 100 augmentations per annotated windthrown stems achieved F1-scores of 73.9% (S1Mod10), 74.3% (S1Mod50) and 75.6% (S1Mod100), outperforming the baseline model (F1-score 72.6%), which was not pre-trained. These results emphasize the applicability of the method to correctly identify windthrown trees and suggest the collection of training samples from other tree species and windthrow areas to improve the ability to generalize. Further enhancements of the network architecture are considered to improve the classification performance and to minimize the calculative costs.},
DOI = {10.3390/rs14010075}
}



@Article{rs14010088,
AUTHOR = {Zhao, Xin and Liu, Rongjie and Ma, Yi and Xiao, Yanfang and Ding, Jing and Liu, Jianqiang and Wang, Quanbin},
TITLE = {Red Tide Detection Method for HY&minus;1D Coastal Zone Imager Based on U&minus;Net Convolutional Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {88},
URL = {https://www.mdpi.com/2072-4292/14/1/88},
ISSN = {2072-4292},
ABSTRACT = {Existing red tide detection methods have mainly been developed for ocean color satellite data with low spatial resolution and high spectral resolution. Higher spatial resolution satellite images are required for red tides with fine scale and scattered distribution. However, red tide detection methods for ocean color satellite data cannot be directly applied to medium&ndash;high spatial resolution satellite data owing to the shortage of red tide responsive bands. Therefore, a new red tide detection method for medium&ndash;high spatial resolution satellite data is required. This study proposes the red tide detection U&minus;Net (RDU&minus;Net) model by considering the HY&minus;1D Coastal Zone Imager (HY&minus;1D CZI) as an example. RDU&minus;Net employs the channel attention model to derive the inter&minus;channel relationship of red tide information in order to reduce the influence of the marine environment on red tide detection. Moreover, the boundary and binary cross entropy (BBCE) loss function, which incorporates the boundary loss, is used to obtain clear and accurate red tide boundaries. In addition, a multi&minus;feature dataset including the HY&minus;1D CZI radiance and Normalized Difference Vegetation Index (NDVI) is employed to enhance the spectral difference between red tides and seawater and thus improve the accuracy of red tide detection. Experimental results show that RDU&minus;Net can detect red tides accurately without a precedent threshold. Precision and Recall of 87.47% and 86.62%, respectively, are achieved, while the F1&minus;score and Kappa are 0.87. Compared with the existing method, the F1&minus;score is improved by 0.07&ndash;0.21. Furthermore, the proposed method can detect red tides accurately even under interference from clouds and fog, and it shows good performance in the case of red tide edges and scattered distribution areas. Moreover, it shows good applicability and can be successfully applied to other satellite data with high spatial resolution and large bandwidth, such as GF&minus;1 Wide Field of View 2 (WFV2) images.},
DOI = {10.3390/rs14010088}
}



@Article{agronomy12010043,
AUTHOR = {Ponce, Juan Manuel and Aquino, Arturo and Tejada, Diego and Al-Hadithi, Basil Mohammed and Andújar, José Manuel},
TITLE = {A Methodology for the Automated Delineation of Crop Tree Crowns from UAV-Based Aerial Imagery by Means of Morphological Image Analysis},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {43},
URL = {https://www.mdpi.com/2073-4395/12/1/43},
ISSN = {2073-4395},
ABSTRACT = {The popularisation of aerial remote sensing using unmanned aerial vehicles (UAV), has boosted the capacities of agronomists and researchers to offer farmers valuable data regarding the status of their crops. This paper describes a methodology for the automated detection and individual delineation of tree crowns in aerial representations of crop fields by means of image processing and analysis techniques, providing accurate information about plant population and canopy coverage in intensive-farming orchards with a row-based plant arrangement. To that end, after pre-processing initial aerial captures by means of photogrammetry and morphological image analysis, a resulting binary representation of the land plot surveyed is treated at connected component-level in order to separate overlapping tree crown projections. Then, those components are morphologically transformed into a set of seeds with which tree crowns are finally delineated, establishing the boundaries between them when they appear overlapped. This solution was tested on images from three different orchards, achieving semantic segmentations in which more than 94% of tree canopy-belonging pixels were correctly classified, and more than 98% of trees were successfully detected when assessing the methodology capacities for estimating the overall plant population. According to these results, the methodology represents a promising tool for automating the inventorying of plants and estimating individual tree-canopy coverage in intensive tree-based orchards.},
DOI = {10.3390/agronomy12010043}
}



@Article{rs14010102,
AUTHOR = {Li, Xin and Li, Tao and Chen, Ziqi and Zhang, Kaiwen and Xia, Runliang},
TITLE = {Attentively Learning Edge Distributions for Semantic Segmentation of Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {102},
URL = {https://www.mdpi.com/2072-4292/14/1/102},
ISSN = {2072-4292},
ABSTRACT = {Semantic segmentation has been a fundamental task in interpreting remote sensing imagery (RSI) for various downstream applications. Due to the high intra-class variants and inter-class similarities, inflexibly transferring natural image-specific networks to RSI is inadvisable. To enhance the distinguishability of learnt representations, attention modules were developed and applied to RSI, resulting in satisfactory improvements. However, these designs capture contextual information by equally handling all the pixels regardless of whether they around edges. Therefore, blurry boundaries are generated, rising high uncertainties in classifying vast adjacent pixels. Hereby, we propose an edge distribution attention module (EDA) to highlight the edge distributions of leant feature maps in a self-attentive fashion. In this module, we first formulate and model column-wise and row-wise edge attention maps based on covariance matrix analysis. Furthermore, a hybrid attention module (HAM) that emphasizes the edge distributions and position-wise dependencies is devised combing with non-local block. Consequently, a conceptually end-to-end neural network, termed as EDENet, is proposed to integrate HAM hierarchically for the detailed strengthening of multi-level representations. EDENet implicitly learns representative and discriminative features, providing available and reasonable cues for dense prediction. The experimental results evaluated on ISPRS Vaihingen, Potsdam and DeepGlobe datasets show the efficacy and superiority to the state-of-the-art methods on overall accuracy (OA) and mean intersection over union (mIoU). In addition, the ablation study further validates the effects of EDA.},
DOI = {10.3390/rs14010102}
}



@Article{agriculture12010026,
AUTHOR = {Zhang, Di and Pan, Feng and Diao, Qi and Feng, Xiaoxue and Li, Weixing and Wang, Jiacheng},
TITLE = {Seeding Crop Detection Framework Using Prototypical Network Method in UAV Images},
JOURNAL = {Agriculture},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {26},
URL = {https://www.mdpi.com/2077-0472/12/1/26},
ISSN = {2077-0472},
ABSTRACT = {With the development of unmanned aerial vehicle (UAV), obtaining high-resolution aerial images has become easier. Identifying and locating specific crops from aerial images is a valuable task. The location and quantity of crops are important for agricultural insurance businesses. In this paper, the problem of locating chili seedling crops in large-field UAV images is processed. Two problems are encountered in the location process: a small number of samples and objects in UAV images are similar on a small scale, which increases the location difficulty. A detection framework based on a prototypical network to detect crops in UAV aerial images is proposed. In particular, a method of subcategory slicing is applied to solve the problem, in which objects in aerial images have similarities at a smaller scale. The detection framework is divided into two parts: training and detection. In the training process, crop images are sliced into subcategories, and then these subcategory patch images and background category images are used to train the prototype network. In the detection process, a simple linear iterative clustering superpixel segmentation method is used to generate candidate regions in the UAV image. The location method uses a prototypical network to recognize nine patch images extracted simultaneously. To train and evaluate the proposed method, we construct an evaluation dataset by collecting the images of chilies in a seedling stage by an UAV. We achieve a location accuracy of 96.46%. This study proposes a seedling crop detection framework based on few-shot learning that does not require the use of labeled boxes. It reduces the workload of manual annotation and meets the location needs of seedling crops.},
DOI = {10.3390/agriculture12010026}
}



@Article{w14010057,
AUTHOR = {Wang, Zixiong and Sun, Ya and Li, Chunhui and Jin, Ling and Sun, Xinguo and Liu, Xiaoli and Wang, Tianxiang},
TITLE = {Analysis of Small and Medium&ndash;Scale River Flood Risk in Case of Exceeding Control Standard Floods Using Hydraulic Model},
JOURNAL = {Water},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {57},
URL = {https://www.mdpi.com/2073-4441/14/1/57},
ISSN = {2073-4441},
ABSTRACT = {Exceeding control standard floods pose threats to the management of small and medium&ndash;scale rivers. Taking Fuzhouhe river as an example, this paper analyzes the submerged depth, submerged area and arrival time of river flood risk in the case of exceeding control standard floods (with return period of 20, 50, 100 and 200 years) through a coupled one&ndash; and two&ndash;dimensional hydrodynamic model, draws the flood risk maps and proposes emergency plans. The simulation results of the one&ndash;dimensional model reveal that the dikes would be at risk of overflowing for different frequencies of floods, with a higher level of risk on the left bank. The results of the coupled model demonstrate that under all scenarios, the inundation area gradually increases with time until the flood peak subsides, and the larger the flood peak, the faster the inundation area increases. The maximum submerged areas are 42.73 km2, 65.95 km2, 74.86 km2 and 82.71 km2 for four frequencies of flood, respectively. The change of submerged depth under different frequency floods shows a downward&ndash;upward&ndash;downward trend and the average submerged depth of each frequency floods is about 1.4 m. The flood risk maps of different flood frequencies are created by GIS to analyze flood arrival time, submerged area and submerged depth to plan escape routes and resettlement units. The migration distances are limited within 4 km, the average migration distance is about 2 km, the vehicle evacuation time is less than 20 min, and the walking evacuation time is set to about 70 min. It is concluded that the flood risk of small and medium&ndash;scale rivers is a dynamic change process, and dynamic flood assessment, flood warning and embankment modification scheme should be further explored.},
DOI = {10.3390/w14010057}
}



@Article{s22010189,
AUTHOR = {Besada, Juan A. and Campaña, Ivan and Carramiñana, David and Bergesio, Luca and de Miguel, Gonzalo},
TITLE = {Review and Simulation of Counter-UAS Sensors for Unmanned Traffic Management},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {189},
URL = {https://www.mdpi.com/1424-8220/22/1/189},
PubMedID = {35009730},
ISSN = {1424-8220},
ABSTRACT = {Noncollaborative surveillance of airborne UAS (Unmanned Aerial System) is a key enabler to the safe integration of UAS within a UTM (Unmanned Traffic Management) ecosystem. Thus, a wide variety of new sensors (known as Counter-UAS sensors) are being developed to provide real-time UAS tracking, ranging from radar, RF analysis and image-based detection to even sound-based sensors. This paper aims to discuss the current state-of-the art technology in this wide variety of sensors (both academically and commercially) and to propose a set of simulation models for them. Thus, the review is focused on identifying the key parameters and processes that allow modeling their performance and operation, which reflect the variety of measurement processes. The resulting simulation models are designed to help evaluate how sensors&rsquo; performances affect UTM systems, and specifically the implications in their tracking and tactical services (i.e., tactical conflicts with uncontrolled drones). The simulation models cover probabilistic detection (i.e., false alarms and probability of detection) and measurement errors, considering equipment installation (i.e., monostatic vs. multistatic configurations, passive sensing, etc.). The models were integrated in a UTM simulation platform and simulation results are included in the paper for active radars, passive radars, and acoustic sensors.},
DOI = {10.3390/s22010189}
}



@Article{rs14010123,
AUTHOR = {Yao, Xin and Shi, Xiaoran and Li, Yaxin and Wang, Li and Wang, Han and Ren, Shijie and Zhou, Feng},
TITLE = {GMT-WGAN: An Adversarial Sample Expansion Method for Ground Moving Targets Classification},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {123},
URL = {https://www.mdpi.com/2072-4292/14/1/123},
ISSN = {2072-4292},
ABSTRACT = {In the field of target classification, detecting a ground moving target that is easily covered in clutter has been a challenge. In addition, traditional feature extraction techniques and classification methods usually rely on strong subjective factors and prior knowledge, which affect their generalization capacity. Most existing deep-learning-based methods suffer from insufficient feature learning due to the lack of data samples, which makes it difficult for the training process to converge to a steady-state. To overcome these limitations, this paper proposes a Wasserstein generative adversarial network (WGAN) sample enhancement method for ground moving target classification (GMT-WGAN). First, the micro-Doppler characteristics of ground moving targets are analyzed. Next, a WGAN is constructed to generate effective time&ndash;frequency images of ground moving targets and thereby enrich the sample database used to train the classification network. Then, image quality evaluation indexes are introduced to evaluate the generated spectrogram samples, with an aim to verify the distribution similarity of generated and real samples. Afterward, by feeding augmented samples to the deep convolutional neural networks with good generalization capacity, the classification performance of the GMT-WGAN is improved. Finally, experiments conducted on different datasets validate the effectiveness and robustness of the proposed method.},
DOI = {10.3390/rs14010123}
}



@Article{s22010207,
AUTHOR = {Chen, Qi and Zhang, Yuanyi and Li, Xinyuan and Tao, Pengjie},
TITLE = {Extracting Rectified Building Footprints from Traditional Orthophotos: A New Workflow},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {207},
URL = {https://www.mdpi.com/1424-8220/22/1/207},
PubMedID = {35009755},
ISSN = {1424-8220},
ABSTRACT = {Deep learning techniques such as convolutional neural networks have largely improved the performance of building segmentation from remote sensing images. However, the images for building segmentation are often in the form of traditional orthophotos, where the relief displacement would cause non-negligible misalignment between the roof outline and the footprint of a building; such misalignment poses considerable challenges for extracting accurate building footprints, especially for high-rise buildings. Aiming at alleviating this problem, a new workflow is proposed for generating rectified building footprints from traditional orthophotos. We first use the facade labels, which are prepared efficiently at low cost, along with the roof labels to train a semantic segmentation network. Then, the well-trained network, which employs the state-of-the-art version of EfficientNet as backbone, extracts the roof segments and the facade segments of buildings from the input image. Finally, after clustering the classified pixels into instance-level building objects and tracing out the roof outlines, an energy function is proposed to drive the roof outline to maximally align with the building footprint; thus, the rectified footprints can be generated. The experiments on the aerial orthophotos covering a high-density residential area in Shanghai demonstrate that the proposed workflow can generate obviously more accurate building footprints than the baseline methods, especially for high-rise buildings.},
DOI = {10.3390/s22010207}
}



@Article{app12010294,
AUTHOR = {Gromada, Krzysztof Andrzej and Stecz, Wojciech Marcin},
TITLE = {Designing a Reliable UAV Architecture Operating in a Real Environment},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {294},
URL = {https://www.mdpi.com/2076-3417/12/1/294},
ISSN = {2076-3417},
ABSTRACT = {The article presents a method of designing a selected unmanned aerial platform flight scenario based on the principles of designing a reliable (Unmanned Aerial Vehicle) UAV architecture operating in an environment in which other platforms operate. The models and results presented relate to the medium-range aerial platform, subject to certification under the principles set out in aviation regulations. These platforms are subject to the certification process requirements, but their restrictions are not as restrictive as in the case of manned platforms. Issues related to modeling scenarios implemented by the platform in flight are discussed. The article describes the importance of Functional Hazard Analysis (FHA) and Fault Trees Analysis (FTA) of elements included in the hardware and software architecture of the system. The models in Unified Modeling Language (UML) used by the authors in the project are described, supporting the design of a reliable architecture of flying platforms. Examples of the transformations from user requirements modeled in the form of Use Cases to platform operation models based on State Machines and then to the final UAV operation algorithms are shown. Principles of designing system test plans and designing individual test cases to verify the system&rsquo;s operation in emergencies in flight are discussed. Methods of integrating flight simulators with elements of the air platform in the form of Software-in-the-Loop (SIL) models based on selected algorithms for avoiding dangerous situations have been described. The presented results are based on a practical example of an algorithm for detecting an air collision situation of two platforms.},
DOI = {10.3390/app12010294}
}



@Article{en15010217,
AUTHOR = {Velusamy, Parthasarathy and Rajendran, Santhosh and Mahendran, Rakesh Kumar and Naseer, Salman and Shafiq, Muhammad and Choi, Jin-Ghoo},
TITLE = {Unmanned Aerial Vehicles (UAV) in Precision Agriculture: Applications and Challenges},
JOURNAL = {Energies},
VOLUME = {15},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {217},
URL = {https://www.mdpi.com/1996-1073/15/1/217},
ISSN = {1996-1073},
ABSTRACT = {Agriculture is the primary source of income in developing countries like India. Agriculture accounts for 17 percent of India&rsquo;s total GDP, with almost 60 percent of the people directly or indirectly employed. While researchers and planters focus on a variety of elements to boost productivity, crop loss due to disease is one of the most serious issues they confront. Crop growth monitoring and early detection of pest infestations are still a problem. With the expansion of cultivation to wider fields, manual intervention to monitor and diagnose insect and pest infestations is becoming increasingly difficult. Failure to apply on time fertilizers and pesticides results in more crop loss and so lower output. Farmers are putting in greater effort to conserve crops, but they are failing most of the time because they are unable to adequately monitor the crops when they are infected by pests and insects. Pest infestation is also difficult to predict because it is not evenly distributed. In the recent past, modern equipment, tools, and approaches have been used to replace manual involvement. Unmanned aerial vehicles serve a critical role in crop disease surveillance and early detection in this setting. This research attempts to give a review of the most successful techniques to have precision-based crop monitoring and pest management in agriculture fields utilizing unmanned aerial vehicles (UAVs) or unmanned aircraft. The researchers&rsquo; reports on the various types of UAVs and their applications to early detection of agricultural diseases are rigorously assessed and compared. This paper also discusses the deployment of aerial, satellite, and other remote sensing technologies for disease detection, as well as their Quality of Service (QoS).},
DOI = {10.3390/en15010217}
}



@Article{drones6010008,
AUTHOR = {Basan, Elena and Basan, Alexandr and Nekrasov, Alexey and Fidge, Colin and Sushkin, Nikita and Peskova, Olga},
TITLE = {GPS-Spoofing Attack Detection Technology for UAVs Based on Kullback&ndash;Leibler Divergence},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {8},
URL = {https://www.mdpi.com/2504-446X/6/1/8},
ISSN = {2504-446X},
ABSTRACT = {Here, we developed a method for detecting cyber security attacks aimed at spoofing the Global Positioning System (GPS) signal of an Unmanned Aerial Vehicle (UAV). Most methods for detecting UAV anomalies indicative of an attack use machine learning or other such methods that compare normal behavior with abnormal behavior. Such approaches require large amounts of data and significant &ldquo;training&rdquo; time to prepare and implement the system. Instead, we consider a new approach based on other mathematical methods for detecting UAV anomalies without the need to first collect a large amount of data and describe normal behavior patterns. Doing so can simplify the process of creating an anomaly detection system, which can further facilitate easier implementation of intrusion detection systems in UAVs. This article presents issues related to ensuring the information security of UAVs. Development of the GPS spoofing detection method for UAVs is then described, based on a preliminary study that made it possible to form a mathematical apparatus for solving the problem. We then explain the necessary analysis of parameters and methods of data normalization, and the analysis of the Kullback&mdash;Leibler divergence measure needed to detect anomalies in UAV systems.},
DOI = {10.3390/drones6010008}
}



@Article{agronomy12010081,
AUTHOR = {Sinde-González, Izar and Gómez-López, Josselyn Paola and Tapia-Navarro, Stalin Alejandro and Murgueitio, Erika and Falconí, César and Benítez, Fatima L. and Toulkeridis, Theofilos},
TITLE = {Determining the Effects of Nanonutrient Application in Cabbage (Brassica oleracea var. capitate L.) Using Spectrometry and Biomass Estimation with UAV},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {81},
URL = {https://www.mdpi.com/2073-4395/12/1/81},
ISSN = {2073-4395},
ABSTRACT = {Geospatial technologies are presented as an alternative for the monitoring and control of crops, as demonstrated through the analysis of spectral responses (SR) of each species. In this study, it was intended to determine the effects of the application of nanonutrients (Zn and Mn) in cabbage (Brassica oleracea var. capitate L.) by analyzing the relationship between the vegetation indices (VI) NDVI, GNDVI, NGRDI, RVI, GVI, CCI RARSa and the content of chlorophyll (CC), from two trials established in the field and in the greenhouse, together with the calculation of dry biomass production in the field through the use of digital models and its further validation. The results indicated that for greenhouse experiments no significant differences were found between the VIs in the implemented treatments, rather for their phenological states. Whereas in the field assays it was evidenced that there were significant differences between the VIs for the treatments, as well as for the phenological states. The SR issued in the field allowed the evaluation of the behavior of the crop due to the application of nanonutrients, which did not occur in the greenhouse, in the same way. The SR also enabled the spectral characterization of the crop in its phenological states in the two trials. All this information was stored in a digital format, which allowed the creation of a spectral library which was published on a web server. The validation of the dry biomass allowed, by statistical analysis, the efficiency of the method used for its estimation to be confirmed.},
DOI = {10.3390/agronomy12010081}
}



@Article{s22010270,
AUTHOR = {Domingo, Mari Carmen},
TITLE = {Power Allocation and Energy Cooperation for UAV-Enabled MmWave Networks: A Multi-Agent Deep Reinforcement Learning Approach},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {270},
URL = {https://www.mdpi.com/1424-8220/22/1/270},
PubMedID = {35009812},
ISSN = {1424-8220},
ABSTRACT = {Unmanned Aerial Vehicle (UAV)-assisted cellular networks over the millimeter-wave (mmWave) frequency band can meet the requirements of a high data rate and flexible coverage in next-generation communication networks. However, higher propagation loss and the use of a large number of antennas in mmWave networks give rise to high energy consumption and UAVs are constrained by their low-capacity onboard battery. Energy harvesting (EH) is a viable solution to reduce the energy cost of UAV-enabled mmWave networks. However, the random nature of renewable energy makes it challenging to maintain robust connectivity in UAV-assisted terrestrial cellular networks. Energy cooperation allows UAVs to send their excessive energy to other UAVs with reduced energy. In this paper, we propose a power allocation algorithm based on energy harvesting and energy cooperation to maximize the throughput of a UAV-assisted mmWave cellular network. Since there is channel-state uncertainty and the amount of harvested energy can be treated as a stochastic process, we propose an optimal multi-agent deep reinforcement learning algorithm (DRL) named Multi-Agent Deep Deterministic Policy Gradient (MADDPG) to solve the renewable energy resource allocation problem for throughput maximization. The simulation results show that the proposed algorithm outperforms the Random Power (RP), Maximal Power (MP) and value-based Deep Q-Learning (DQL) algorithms in terms of network throughput.},
DOI = {10.3390/s22010270}
}



@Article{ijgi11010023,
AUTHOR = {Akcay, Ozgun and Kinaci, Ahmet Cumhur and Avsar, Emin Ozgur and Aydar, Umut},
TITLE = {Semantic Segmentation of High-Resolution Airborne Images with Dual-Stream DeepLabV3+},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {23},
URL = {https://www.mdpi.com/2220-9964/11/1/23},
ISSN = {2220-9964},
ABSTRACT = {In geospatial applications such as urban planning and land use management, automatic detection and classification of earth objects are essential and primary subjects. When the significant semantic segmentation algorithms are considered, DeepLabV3+ stands out as a state-of-the-art CNN. Although the DeepLabV3+ model is capable of extracting multi-scale contextual information, there is still a need for multi-stream architectural approaches and different training approaches of the model that can leverage multi-modal geographic datasets. In this study, a new end-to-end dual-stream architecture that considers geospatial imagery was developed based on the DeepLabV3+ architecture. As a result, the spectral datasets other than RGB provided increments in semantic segmentation accuracies when they were used as additional channels to height information. Furthermore, both the given data augmentation and Tversky loss function which is sensitive to imbalanced data accomplished better overall accuracies. Also, it has been shown that the new dual-stream architecture using Potsdam and Vaihingen datasets produced 88.87% and 87.39% overall semantic segmentation accuracies, respectively. Eventually, it was seen that enhancement of the traditional significant semantic segmentation networks has a great potential to provide higher model performances, whereas the contribution of geospatial data as the second stream to RGB to segmentation was explicitly shown.},
DOI = {10.3390/ijgi11010023}
}



@Article{rs14010166,
AUTHOR = {Zhang, Xuan and Zhu, Chun and He, Manchao and Dong, Menglong and Zhang, Guangcheng and Zhang, Faming},
TITLE = {Failure Mechanism and Long Short-Term Memory Neural Network Model for Landslide Risk Prediction},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {166},
URL = {https://www.mdpi.com/2072-4292/14/1/166},
ISSN = {2072-4292},
ABSTRACT = {Rockslides along a stepped failure surface have characteristics of stepped deformation characteristic and it is difficult to predict the failure time. In this study, the deformation characteristics and disaster prediction model of the Fengning granite rockslide were analyzed based on field surveys and monitoring data. To evaluate the stability, the shear strength parameters of the sliding surface were determined based on the back-propagation neural network and three-dimensional discrete element numerical method. Through the correlation analysis of deformation monitoring results with rainfall and blasting, it is shown that the landslide was triggered by excavation, rainfall, and blasting vibrations. The landslide displacement prediction model was established by using long short-term memory neural network (LSTM) based on the monitoring data, and the prediction results are compared with those using the BP model, SVM model and ARMA model. Results show that the LSTM model has strong advantages and good reliability for the stepped landslide deformation with short-term influence, and the predicted LSTM values were very consistent with the measured values, with a correlation coefficient of 0.977. Combined with the distribution characteristics of joints, the damage influence scope of the landslide was simulated by three-dimensional discrete element, which provides decision-making basis for disaster warning after slope instability. The method proposed in this paper can provide references for early warning and treatment of geological disasters.},
DOI = {10.3390/rs14010166}
}



@Article{electronics11010128,
AUTHOR = {Tehseen, Aqsa and Zafar, Nazir Ahmad and Ali, Tariq and Jameel, Fatima and Alkhammash, Eman H.},
TITLE = {Formal Modeling of IoT and Drone-Based Forest Fire Detection and Counteraction System},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {128},
URL = {https://www.mdpi.com/2079-9292/11/1/128},
ISSN = {2079-9292},
ABSTRACT = {Forests are an enduring component of the natural world and perform a vital role in protecting the environment. Forests are valuable resources to control global warming and provide oxygen for the survival of human life, including wood for households. Forest fires have recently emerged as a major threat to biological processes and the ecosystem. Unfortunately, almost every year, fire damages millions of hectares of forest land due to late and inefficient detection of fire. However, it is important to identify the forest fire at the initial level before it spreads to vast areas and destroys natural resources. In this paper, a formal model of the Internet of Things (IoT) and drone-based forest fire detection and counteraction system is presented. The proposed system comprises network maintenance. Sensor deployment is on trees, the ground, and animals in the form of subnets to transmit sensed data to the control room. All subnets are connected to the control room through gateway nodes. Alarms are being used to alert human beings and animals to save their lives, which will help to initially protect them from fire. The embedded sensors collect the information and transfer it to the gateways. Drones are being used for real-time visualization of fire-affected areas and to perform actions to control fires because they play a vital role in disasters. Graph theory is used to construct an efficient model and to show the connectivity of the network. To identify failures and develop recovery procedures, the algorithm is designed through the graph-based model. The model is developed by the Vienna Development Method-Specification Language (VDM-SL), and the correctness of the model is ensured using various VDM-SL toolbox facilities.},
DOI = {10.3390/electronics11010128}
}



@Article{rs14010170,
AUTHOR = {Rodríguez-Puerta, Francisco and Gómez-García, Esteban and Martín-García, Saray and Pérez-Rodríguez, Fernando and Prada, Eva},
TITLE = {UAV-Based LiDAR Scanning for Individual Tree Detection and Height Measurement in Young Forest Permanent Trials},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {170},
URL = {https://www.mdpi.com/2072-4292/14/1/170},
ISSN = {2072-4292},
ABSTRACT = {The installation of research or permanent plots is a very common task in growth and forest yield research. At young ages, tree height is the most commonly measured variable, so the location of individuals is necessary when repeated measures are taken and if spatial analysis is required. Identifying the coordinates of individual trees and re-measuring the height of all trees is difficult and particularly costly (in time and money). The data used comes from three Pinus pinaster Ait. and three Pinus radiata D. Don plantations of 0.8 ha, with an age ranging between 2 and 5 years and mean heights between 1 and 5 m. Five individual tree detection (ITD) methods are evaluated, based on the Canopy Height Model (CHM), where the height of each tree is identified, and its crown is segmented. Three CHM resolutions are used for each method. All algorithms used for individual tree detection (ITD) tend to underestimate the number of trees. The best results are obtained with the R package, ForestTools and rLiDAR. The best CHM resolution for identifying trees was always 10 cm. We did not detect any differences in the relative error (RE) between Pinus pinaster and Pinus radiata. We found a pattern in the ITD depending on the height of the trees to be detected: the accuracy is lower when detecting trees less than 1 m high than when detecting larger trees (RE close to 12% versus 1% for taller trees). Regarding the estimation of tree height, we can conclude that the use of the CHM to estimate height tends to underestimate its value, while the use of the point cloud presents practically unbiased results. The stakeout of forestry research plots and the re-measurement of individual tree heights is an operation that can be performed by UAV-based LiDAR scanning sensors. The individual geolocation of each tree and the measurement of heights versus pole and/or hypsometer measurement is highly accurate and cost-effective, especially when tree height reaches 1&ndash;1.5 m.},
DOI = {10.3390/rs14010170}
}



@Article{app12010395,
AUTHOR = {Wang, Ying and Koo, Ki-Young},
TITLE = {Vegetation Removal on 3D Point Cloud Reconstruction of Cut-Slopes Using U-Net},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {395},
URL = {https://www.mdpi.com/2076-3417/12/1/395},
ISSN = {2076-3417},
ABSTRACT = {The 3D point cloud reconstruction from photos taken by an unmanned aerial vehicle (UAV) is a promising tool for monitoring and managing risks of cut-slopes. However, surface changes on cut-slopes are likely to be hidden by seasonal vegetation variations on the cut-slopes. This paper proposes a vegetation removal method for 3D reconstructed point clouds using (1) a 2D image segmentation deep learning model and (2) projection matrices available from photogrammetry. For a given point cloud, each 3D point of it is reprojected into the image coordinates by the projection matrices to determine if it belongs to vegetation or not using the 2D image segmentation model. The 3D points belonging to vegetation in the 2D images are deleted from the point cloud. The effort to build a 2D image segmentation model was significantly reduced by using U-Net with the dataset prepared by the colour index method complemented by manual trimming. The proposed method was applied to a cut-slope in Doam Dam in South Korea, and showed that vegetation from the two point clouds of the cut-slope at winter and summer was removed successfully. The M3C2 distance between the two vegetation-removed point clouds showed a feasibility of the proposed method as a tool to reveal actual change of cut-slopes without the effect of vegetation.},
DOI = {10.3390/app12010395}
}



@Article{machines10010028,
AUTHOR = {Piratelo, Paulo Henrique Martinez and de Azeredo, Rodrigo Negri and Yamao, Eduardo Massashi and Bianchi Filho, Jose Francisco and Maidl, Gabriel and Lisboa, Felipe Silveira Marques and de Jesus, Laercio Pereira and Penteado Neto, Renato de Arruda and Coelho, Leandro dos Santos and Leandro, Gideon Villar},
TITLE = {Blending Colored and Depth CNN Pipelines in an Ensemble Learning Classification Approach for Warehouse Application Using Synthetic and Real Data},
JOURNAL = {Machines},
VOLUME = {10},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {28},
URL = {https://www.mdpi.com/2075-1702/10/1/28},
ISSN = {2075-1702},
ABSTRACT = {Electric companies face flow control and inventory obstacles such as reliability, outlays, and time-consuming tasks. Convolutional Neural Networks (CNNs) combined with computational vision approaches can process image classification in warehouse management applications to tackle this problem. This study uses synthetic and real images applied to CNNs to deal with classification of inventory items. The results are compared to seek the neural networks that better suit this application. The methodology consists of fine-tuning several CNNs on Red&ndash;Green&ndash;Blue (RBG) and Red&ndash;Green&ndash;Blue-Depth (RGB-D) synthetic and real datasets, using the best architecture of each domain in a blended ensemble approach. The proposed blended ensemble approach was not yet explored in such an application, using RGB and RGB-D data, from synthetic and real domains. The use of a synthetic dataset improved accuracy, precision, recall and f1-score in comparison with models trained only on the real domain. Moreover, the use of a blend of DenseNet and Resnet pipelines for colored and depth images proved to outperform accuracy, precision and f1-score performance indicators over single CNNs, achieving an accuracy measurement of 95.23%. The classification task is a real logistics engineering problem handled by computer vision and artificial intelligence, making full use of RGB and RGB-D images of synthetic and real domains, applied in an approach of blended CNN pipelines.},
DOI = {10.3390/machines10010028}
}



@Article{mi13010072,
AUTHOR = {Li, Dengshan and Wang, Rujing and Chen, Peng and Xie, Chengjun and Zhou, Qiong and Jia, Xiufang},
TITLE = {Visual Feature Learning on Video Object and Human Action Detection: A Systematic Review},
JOURNAL = {Micromachines},
VOLUME = {13},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {72},
URL = {https://www.mdpi.com/2072-666X/13/1/72},
ISSN = {2072-666X},
ABSTRACT = {Video object and human action detection are applied in many fields, such as video surveillance, face recognition, etc. Video object detection includes object classification and object location within the frame. Human action recognition is the detection of human actions. Usually, video detection is more challenging than image detection, since video frames are often more blurry than images. Moreover, video detection often has other difficulties, such as video defocus, motion blur, part occlusion, etc. Nowadays, the video detection technology is able to implement real-time detection, or high-accurate detection of blurry video frames. In this paper, various video object and human action detection approaches are reviewed and discussed, many of them have performed state-of-the-art results. We mainly review and discuss the classic video detection methods with supervised learning. In addition, the frequently-used video object detection and human action recognition datasets are reviewed. Finally, a summarization of the video detection is represented, e.g., the video object and human action detection methods could be classified into frame-by-frame (frame-based) detection, extracting-key-frame detection and using-temporal-information detection; the methods of utilizing temporal information of adjacent video frames are mainly the optical flow method, Long Short-Term Memory and convolution among adjacent frames.},
DOI = {10.3390/mi13010072}
}



@Article{rs14010199,
AUTHOR = {Carbonell-Rivera, Juan Pedro and Torralba, Jesús and Estornell, Javier and Ruiz, Luis Ángel and Crespo-Peremarch, Pablo},
TITLE = {Classification of Mediterranean Shrub Species from UAV Point Clouds},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {199},
URL = {https://www.mdpi.com/2072-4292/14/1/199},
ISSN = {2072-4292},
ABSTRACT = {Modelling fire behaviour in forest fires is based on meteorological, topographical, and vegetation data, including species&rsquo; type. To accurately parameterise these models, an inventory of the area of analysis with the maximum spatial and temporal resolution is required. This study investigated the use of UAV-based digital aerial photogrammetry (UAV-DAP) point clouds to classify tree and shrub species in Mediterranean forests, and this information is key for the correct generation of wildfire models. In July 2020, two test sites located in the Natural Park of Sierra Calderona (eastern Spain) were analysed, registering 1036 vegetation individuals as reference data, corresponding to 11 shrub and one tree species. Meanwhile, photogrammetric flights were carried out over the test sites, using a UAV DJI Inspire 2 equipped with a Micasense RedEdge multispectral camera. Geometrical, spectral, and neighbour-based features were obtained from the resulting point cloud generated. Using these features, points belonging to tree and shrub species were classified using several machine learning methods, i.e., Decision Trees, Extra Trees, Gradient Boosting, Random Forest, and MultiLayer Perceptron. The best results were obtained using Gradient Boosting, with a mean cross-validation accuracy of 81.7% and 91.5% for test sites 1 and 2, respectively. Once the best classifier was selected, classified points were clustered based on their geometry and tested with evaluation data, and overall accuracies of 81.9% and 96.4% were obtained for test sites 1 and 2, respectively. Results showed that the use of UAV-DAP allows the classification of Mediterranean tree and shrub species. This technique opens a wide range of possibilities, including the identification of species as a first step for further extraction of structure and fuel variables as input for wildfire behaviour models.},
DOI = {10.3390/rs14010199}
}



@Article{rs14010201,
AUTHOR = {Lin, Qigen and Ci, Tianyu and Wang, Leibin and Mondal, Sanjit Kumar and Yin, Huaxiang and Wang, Ying},
TITLE = {Transfer Learning for Improving Seismic Building Damage Assessment},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {201},
URL = {https://www.mdpi.com/2072-4292/14/1/201},
ISSN = {2072-4292},
ABSTRACT = {The rapid assessment of building damage in earthquake-stricken areas is of paramount importance for emergency response. The development of remote sensing technology has aided in deriving reliable and precise building damage assessments of extensive areas following disasters. It is well documented that convolutional neural network methods have superior performance in earthquake building damage assessment compared with traditional machine learning methods. However, deep learning models require a large number of samples, and sufficient numbers of samples are usually not available in the newly earthquake-stricken areas rapidly enough. At the same time, the historical samples inevitably differ from the new earthquake-affected areas due to the discrepancy of regional building characteristics. For this purpose, this study proposes a data transfer algorithm for evaluating the impact of a single historical training sample on the model performance. Then, beneficial samples are selected to transfer knowledge from the historical data for facilitating the calibration of the new model. Four models are designed with two earthquake damage building datasets and the performance of the models is compared and evaluated. The results show that the data transfer algorithm proposed in this work improves the reliability of the building damage assessment model significantly by filtering samples from the historical data that are suitable for the new task. The performance of the model built based on the data transfer method on the test set of new earthquakes task is approximately 8% higher in overall accuracy compared with the model trained directly with the new earthquake samples when the training data for the new task is only 10% of the historical data and is operating under the objective of four classes of building damage. The proposed data transfer algorithm has effectively enhanced the precision of the seismic building damage assessment in a data-limited context. Thus, it could be applicable to the building damage assessment of new disasters.},
DOI = {10.3390/rs14010201}
}



@Article{f13010048,
AUTHOR = {Kamarulzaman, Aisyah Marliza Muhmad and Wan Mohd Jaafar, Wan Shafrina and Abdul Maulud, Khairul Nizam and Saad, Siti Nor Maizah and Omar, Hamdan and Mohan, Midhun},
TITLE = {Integrated Segmentation Approach with Machine Learning Classifier in Detecting and Mapping Post Selective Logging Impacts Using UAV Imagery},
JOURNAL = {Forests},
VOLUME = {13},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {48},
URL = {https://www.mdpi.com/1999-4907/13/1/48},
ISSN = {1999-4907},
ABSTRACT = {Selective logging can cause significant impacts on the residual stands, affecting biodiversity and leading to environmental changes. Proper monitoring and mapping of the impacts from logging activities, such as the stumps, felled logs, roads, skid trails, and forest canopy gaps, are crucial for sustainable forest management operations. The purpose of this study is to assess the indicators of selective logging impacts by detecting the individual stumps as the main indicators, evaluating the performance of classification methods to assess the impacts and identifying forest gaps from selective logging activities. The combination of forest inventory field plots and unmanned aerial vehicle (UAV) RGB and overlapped imaged were used in this study to assess these impacts. The study area is located in Ulu Jelai Forest Reserve in the central part of Peninsular Malaysia, covering an experimental study area of 48 ha. The study involved the integration of template matching (TM), object-based image analysis (OBIA), and machine learning classification&mdash;support vector machine (SVM) and artificial neural network (ANN). Forest features and tree stumps were classified, and the canopy height model was used for detecting forest canopy gaps in the post selective logging region. Stump detection using the integration of TM and OBIA produced an accuracy of 75.8% when compared with the ground data. Forest classification using SVM and ANN methods were adopted to extract other impacts from logging activities such as skid trails, felled logs, roads and forest canopy gaps. These methods provided an overall accuracy of 85% and kappa coefficient value of 0.74 when compared with conventional classifier. The logging operation also caused an 18.6% loss of canopy cover. The result derived from this study highlights the potential use of UAVs for efficient post logging impact analysis and can be used to complement conventional forest inventory practices.},
DOI = {10.3390/f13010048}
}



@Article{electronics11010148,
AUTHOR = {Sharma, Mayuri and Nath, Keshab and Sharma, Rupam Kumar and Kumar, Chandan Jyoti and Chaudhary, Ankit},
TITLE = {Ensemble Averaging of Transfer Learning Models for Identification of Nutritional Deficiency in Rice Plant},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {148},
URL = {https://www.mdpi.com/2079-9292/11/1/148},
ISSN = {2079-9292},
ABSTRACT = {Computer vision-based automation has become popular in detecting and monitoring plants&rsquo; nutrient deficiencies in recent times. The predictive model developed by various researchers were so designed that it can be used in an embedded system, keeping in mind the availability of computational resources. Nevertheless, the enormous popularity of smart phone technology has opened the door of opportunity to common farmers to have access to high computing resources. To facilitate smart phone users, this study proposes a framework of hosting high end systems in the cloud where processing can be done, and farmers can interact with the cloud-based system. With the availability of high computational power, many studies have been focused on applying convolutional Neural Networks-based Deep Learning (CNN-based DL) architectures, including Transfer learning (TL) models on agricultural research. Ensembling of various TL architectures has the potential to improve the performance of predictive models by a great extent. In this work, six TL architectures viz. InceptionV3, ResNet152V2, Xception, DenseNet201, InceptionResNetV2, and VGG19 are considered, and their various ensemble models are used to carry out the task of deficiency diagnosis in rice plants. Two publicly available datasets from Mendeley and Kaggle are used in this study. The ensemble-based architecture enhanced the highest classification accuracy to 100% from 99.17% in the Mendeley dataset, while for the Kaggle dataset; it was enhanced to 92% from 90%.},
DOI = {10.3390/electronics11010148}
}



@Article{app12010458,
AUTHOR = {Amaral, Julyanne Braga Cruz and Lopes, Fernando Bezerra and Magalhães, Ana Caroline Messias de and Kujawa, Sebastian and Taniguchi, Carlos Alberto Kenji and Teixeira, Adunias dos Santos and Lacerda, Claudivan Feitosa de and Queiroz, Thales Rafael Guimarães and Andrade, Eunice Maia de and Araújo, Isabel Cristina da Silva and Niedbała, Gniewko},
TITLE = {Quantifying Nutrient Content in the Leaves of Cowpea Using Remote Sensing},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {458},
URL = {https://www.mdpi.com/2076-3417/12/1/458},
ISSN = {2076-3417},
ABSTRACT = {Although hyperspectral remote sensing techniques have increasingly been used in the nutritional quantification of plants, it is important to understand whether the method shows a satisfactory response during the various phenological stages of the crop. The aim of this study was to quantify the levels of phosphorus (P), potassium (K), calcium (Ca) and zinc (Zn) in the leaves of Vigna Unguiculata (L.) Walp using spectral data obtained by a spectroradiometer. A randomised block design was used, with three treatments and twenty-five replications. The crop was evaluated at three growth stages: V4, R6 and R9. Single-band models were fitted using simple correlations. For the band ratio models, the wavelengths were selected by 2D correlation. For the models using partial least squares regression (PLSR), the stepwise method was used. The model showing the best fit was used to estimate the phosphorus content in the single-band (R&sup2; = 0.62; RMSE = 0.54 and RPD = 1.61), band ratio (R&sup2; = 0.66; RMSE = 0.65 and RPD = 1.52) and PLSR models, using data from each of the phenological stages (R&sup2; = 0.80; RMSE = 0.47 and RPD = 1.66). Accuracy in modelling leaf nutrients depends on the phenological stage, as well as the amount of data used, and is more accurate with a larger number of samples.},
DOI = {10.3390/app12010458}
}



@Article{rs14010215,
AUTHOR = {Niu, Xuerui and Zeng, Qiaolin and Luo, Xiaobo and Chen, Liangfu},
TITLE = {FCAU-Net for the Semantic Segmentation of Fine-Resolution Remotely Sensed Images},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {215},
URL = {https://www.mdpi.com/2072-4292/14/1/215},
ISSN = {2072-4292},
ABSTRACT = {The semantic segmentation of fine-resolution remotely sensed images is an urgent issue in satellite image processing. Solving this problem can help overcome various obstacles in urban planning, land cover classification, and environmental protection, paving the way for scene-level landscape pattern analysis and decision making. Encoder-decoder structures based on attention mechanisms have been frequently used for fine-resolution image segmentation. In this paper, we incorporate a coordinate attention (CA) mechanism, adopt an asymmetric convolution block (ACB), and design a refinement fusion block (RFB), forming a network named the fusion coordinate and asymmetry-based U-Net (FCAU-Net). Furthermore, we propose novel convolutional neural network (CNN) architecture to fully capture long-term dependencies and fine-grained details in fine-resolution remotely sensed imagery. This approach has the following advantages: (1) the CA mechanism embeds position information into a channel attention mechanism to enhance the feature representations produced by the network while effectively capturing position information and channel relationships; (2) the ACB enhances the feature representation ability of the standard convolution layer and captures and refines the feature information in each layer of the encoder; and (3) the RFB effectively integrates low-level spatial information and high-level abstract features to eliminate background noise when extracting feature information, reduces the fitting residuals of the fused features, and improves the ability of the network to capture information flows. Extensive experiments conducted on two public datasets (ZY-3 and DeepGlobe) demonstrate the effectiveness of the FCAU-Net. The proposed FCAU-Net transcends U-Net, Attention U-Net, the pyramid scene parsing network (PSPNet), DeepLab v3+, the multistage attention residual U-Net (MAResU-Net), MACU-Net, and the Transformer U-Net (TransUNet). Specifically, the FCAU-Net achieves a 97.97% (95.05%) pixel accuracy (PA), a 98.53% (91.27%) mean PA (mPA), a 95.17% (85.54%) mean intersection over union (mIoU), and a 96.07% (90.74%) frequency-weighted IoU (FWIoU) on the ZY-3 (DeepGlobe) dataset.},
DOI = {10.3390/rs14010215}
}



@Article{agriculture12010062,
AUTHOR = {Sun, Zhu and Guo, Xiangyu and Xu, Yang and Zhang, Songchao and Cheng, Xiaohui and Hu, Qiong and Wang, Wenxiang and Xue, Xinyu},
TITLE = {Image Recognition of Male Oilseed Rape (Brassica napus) Plants Based on Convolutional Neural Network for UAAS Navigation Applications on Supplementary Pollination and Aerial Spraying},
JOURNAL = {Agriculture},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {62},
URL = {https://www.mdpi.com/2077-0472/12/1/62},
ISSN = {2077-0472},
ABSTRACT = {To ensure the hybrid oilseed rape (OSR, Brassica napus) seed production, two important things are necessary, the stamen sterility on the female OSR plants and the effective pollen spread onto the pistil from the OSR male plants to the OSR female plants. The unmanned agricultural aerial system (UAAS) has developed rapidly in China. It has been used on supplementary pollination and aerial spraying during the hybrid OSR seed production. This study developed a new method to rapidly recognize the male OSR plants and extract the row center line for supporting the UAAS navigation. A male OSR plant recognition model was constructed based on the convolutional neural network (CNN). The sequence images of male OSR plants were extracted, the feature regions and points were obtained from the images through morphological and boundary process methods and horizontal segmentation, respectively. The male OSR plant image recognition accuracies of different CNN structures and segmentation sizes were discussed. The male OSR plant row center lines were fitted using the least-squares method (LSM) and Hough transform. The results showed that the segmentation algorithm could segment the male OSR plants from the complex background. The highest average recognition accuracy was 93.54%, and the minimum loss function value was 0.2059 with three convolutional layers, one fully connected layer, and a segmentation size of 40 pix &times; 40 pix. The LSM is better for center line fitting. The average recognition model accuracies of original input images were 98% and 94%, and the average root mean square errors (RMSE) of angle were 3.22&deg; and 1.36&deg; under cloudy day and sunny day lighting conditions, respectively. The results demonstrate the potential of using digital imaging technology to recognize the male OSR plant row for UAAS visual navigation on the applications of hybrid OSR supplementary pollination and aerial spraying, which would be a meaningful supplement in precision agriculture.},
DOI = {10.3390/agriculture12010062}
}



@Article{agronomy12010127,
AUTHOR = {Rehman, Amjad and Saba, Tanzila and Kashif, Muhammad and Fati, Suliman Mohamed and Bahaj, Saeed Ali and Chaudhry, Huma},
TITLE = {A Revisit of Internet of Things Technologies for Monitoring and Control Strategies in Smart Agriculture},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {127},
URL = {https://www.mdpi.com/2073-4395/12/1/127},
ISSN = {2073-4395},
ABSTRACT = {With the rise of new technologies, such as the Internet of Things, raising the productivity of agricultural and farming activities is critical to improving yields and cost-effectiveness. IoT, in particular, can improve the efficiency of agriculture and farming processes by eliminating human intervention through automation. The fast rise of Internet of Things (IoT)-based tools has changed nearly all life sectors, including business, agriculture, surveillance, etc. These radical developments are upending traditional agricultural practices and presenting new options in the face of various obstacles. IoT aids in collecting data that is useful in the farming sector, such as changes in climatic conditions, soil fertility, amount of water required for crops, irrigation, insect and pest detection, bug location disruption of creatures to the sphere, and horticulture. IoT enables farmers to effectively use technology to monitor their forms remotely round the clock. Several sensors, including distributed WSNs (wireless sensor networks), are utilized for agricultural inspection and control, which is very important due to their exact output and utilization. In addition, cameras are utilized to keep an eye on the field from afar. The goal of this research is to evaluate smart agriculture using IoT approaches in depth. The paper demonstrates IoT applications, benefits, current obstacles, and potential solutions in smart agriculture. This smart agricultural system aims to find existing techniques that may be used to boost crop yield and save time, such as water, pesticides, irrigation, crop, and fertilizer management.},
DOI = {10.3390/agronomy12010127}
}



@Article{rs14010228,
AUTHOR = {Khan, Asim and Asim, Warda and Ulhaq, Anwaar and Robinson, Randall W.},
TITLE = {A Multiview Semantic Vegetation Index for Robust Estimation of Urban Vegetation Cover},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {228},
URL = {https://www.mdpi.com/2072-4292/14/1/228},
ISSN = {2072-4292},
ABSTRACT = {Urban vegetation growth is vital for developing sustainable and liveable cities in the contemporary era since it directly helps people&rsquo;s health and well-being. Estimating vegetation cover and biomass is commonly done by calculating various vegetation indices for automated urban vegetation management and monitoring. However, most of these indices fail to capture robust estimation of vegetation cover due to their inherent focus on colour attributes with limited viewpoint and ignore seasonal changes. To solve this limitation, this article proposed a novel vegetation index called the Multiview Semantic Vegetation Index (MSVI), which is robust to color, viewpoint, and seasonal variations. Moreover, it can be applied directly to RGB images. This Multiview Semantic Vegetation Index (MSVI) is based on deep semantic segmentation and multiview field coverage and can be integrated into any vegetation management platform. This index has been tested on Google Street View (GSV) imagery of Wyndham City Council, Melbourne, Australia. The experiments and training achieved an overall pixel accuracy of 89.4% and 92.4% for FCN and U-Net, respectively. Thus, the MSVI can be a helpful instrument for analysing urban forestry and vegetation biomass since it provides an accurate and reliable objective method for assessing the plant cover at street level.},
DOI = {10.3390/rs14010228}
}



@Article{s22010404,
AUTHOR = {Chang, Ching-Wei and Lo, Li-Yu and Cheung, Hiu Ching and Feng, Yurong and Yang, An-Shik and Wen, Chih-Yung and Zhou, Weifeng},
TITLE = {Proactive Guidance for Accurate UAV Landing on a Dynamic Platform: A Visual&ndash;Inertial Approach},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {404},
URL = {https://www.mdpi.com/1424-8220/22/1/404},
PubMedID = {35009946},
ISSN = {1424-8220},
ABSTRACT = {This work aimed to develop an autonomous system for unmanned aerial vehicles (UAVs) to land on moving platforms such as an automobile or a marine vessel, providing a promising solution for a long-endurance flight operation, a large mission coverage range, and a convenient recharging ground station. Unlike most state-of-the-art UAV landing frameworks that rely on UAV onboard computers and sensors, the proposed system fully depends on the computation unit situated on the ground vehicle/marine vessel to serve as a landing guidance system. Such a novel configuration can therefore lighten the burden of the UAV, and the computation power of the ground vehicle/marine vessel can be enhanced. In particular, we exploit a sensor fusion-based algorithm for the guidance system to perform UAV localization, whilst a control method based upon trajectory optimization is integrated. Indoor and outdoor experiments are conducted, and the results show that precise autonomous landing on a 43 cm &times; 43 cm platform can be performed.},
DOI = {10.3390/s22010404}
}



@Article{rs14020244,
AUTHOR = {Guo, Yahui and Chen, Shouzhi and Fu, Yongshuo H. and Xiao, Yi and Wu, Wenxiang and Wang, Hanxi and Beurs, Kirsten de},
TITLE = {Comparison of Multi-Methods for Identifying Maize Phenology Using PhenoCams},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {244},
URL = {https://www.mdpi.com/2072-4292/14/2/244},
ISSN = {2072-4292},
ABSTRACT = {Accurately identifying the phenology of summer maize is crucial for both cultivar breeding and fertilizer controlling in precision agriculture. In this study, daily RGB images covering the entire growth of summer maize were collected using phenocams at sites in Shangqiu (2018, 2019 and 2020) and Nanpi (2020) in China. Four phenological dates, including six leaves, booting, heading and maturity of summer maize, were pre-defined and extracted from the phenocam-based images. The spectral indices, textural indices and integrated spectral and textural indices were calculated using the improved adaptive feature-weighting method. The double logistic function, harmonic analysis of time series, Savitzky&ndash;Golay and spline interpolation were applied to filter these indices and pre-defined phenology was identified and compared with the ground observations. The results show that the DLF achieved the highest accuracy, with the coefficient of determination (R2) and the root-mean-square error (RMSE) being 0.86 and 9.32 days, respectively. The new index performed better than the single usage of spectral and textural indices, of which the R2 and RMSE were 0.92 and 9.38 days, respectively. The phenological extraction using the new index and double logistic function based on the PhenoCam data was effective and convenient, obtaining high accuracy. Therefore, it is recommended the adoption of the new index by integrating the spectral and textural indices for extracting maize phenology using PhenoCam data.},
DOI = {10.3390/rs14020244}
}



@Article{app12020545,
AUTHOR = {Liu, Yicheng and Li, Zhipeng and Zhan, Bixiong and Han, Ju and Liu, Yan},
TITLE = {A Super-Resolution Reconstruction Driven Helmet Detection Workflow},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {545},
URL = {https://www.mdpi.com/2076-3417/12/2/545},
ISSN = {2076-3417},
ABSTRACT = {The degrading of input images due to the engineering environment decreases the performance of helmet detection models so as to prevent their application in practice. To overcome this problem, we propose an end-to-end helmet monitoring system, which implements a super-resolution (SR) reconstruction driven helmet detection workflow to detect helmets for monitoring tasks. The monitoring system consists of two modules, the super-resolution reconstruction module and the detection module. The former implements the SR algorithm to produce high-resolution images, the latter performs the helmet detection. Validations are performed on both a public dataset as well as the realistic dataset obtained from a practical construction site. The results show that the proposed system achieves a promising performance and surpasses the competing methods. It will be a promising tool for construction monitoring and is easy to be extended to corresponding tasks.},
DOI = {10.3390/app12020545}
}



@Article{rs14020255,
AUTHOR = {Gao, Xin and Ram, Sundaresh and Philip, Rohit C. and Rodríguez, Jeffrey J. and Szep, Jeno and Shao, Sicong and Satam, Pratik and Pacheco, Jesús and Hariri, Salim},
TITLE = {Selecting Post-Processing Schemes for Accurate Detection of Small Objects in Low-Resolution Wide-Area Aerial Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {255},
URL = {https://www.mdpi.com/2072-4292/14/2/255},
ISSN = {2072-4292},
ABSTRACT = {In low-resolution wide-area aerial imagery, object detection algorithms are categorized as feature extraction and machine learning approaches, where the former often requires a post-processing scheme to reduce false detections and the latter demands multi-stage learning followed by post-processing. In this paper, we present an approach on how to select post-processing schemes for aerial object detection. We evaluated combinations of each of ten vehicle detection algorithms with any of seven post-processing schemes, where the best three schemes for each algorithm were determined using average F-score metric. The performance improvement is quantified using basic information retrieval metrics as well as the classification of events, activities and relationships (CLEAR) metrics. We also implemented a two-stage learning algorithm using a hundred-layer densely connected convolutional neural network for small object detection and evaluated its degree of improvement when combined with the various post-processing schemes. The highest average F-scores after post-processing are 0.902, 0.704 and 0.891 for the Tucson, Phoenix and online VEDAI datasets, respectively. The combined results prove that our enhanced three-stage post-processing scheme achieves a mean average precision (mAP) of 63.9% for feature extraction methods and 82.8% for the machine learning approach.},
DOI = {10.3390/rs14020255}
}



@Article{s22020423,
AUTHOR = {Tomita, Ko and Chew, Michael Yit Lin},
TITLE = {A Review of Infrared Thermography for Delamination Detection on Infrastructures and Buildings},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {423},
URL = {https://www.mdpi.com/1424-8220/22/2/423},
ISSN = {1424-8220},
ABSTRACT = {This paper provides a comprehensive review on the use of infrared thermography to detect delamination on infrastructures and buildings. Approximately 200 pieces of relevant literature were evaluated, and their findings were summarized. The factors affecting the accuracy and detectability of infrared thermography were consolidated and discussed. Necessary measures to effectively capture latent defects at the early stage of delamination before crack formation were investigated. The results of this study could be used as the benchmarks for setting standardized testing criteria as well as for comparison of results for future works on the use of infrared thermography for detection of delamination on infrastructures and buildings.},
DOI = {10.3390/s22020423}
}



@Article{rs14020265,
AUTHOR = {Wang, Yanjun and Li, Shaochun and Teng, Fei and Lin, Yunhao and Wang, Mengjie and Cai, Hengfan},
TITLE = {Improved Mask R-CNN for Rural Building Roof Type Recognition from UAV High-Resolution Images: A Case Study in Hunan Province, China},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {265},
URL = {https://www.mdpi.com/2072-4292/14/2/265},
ISSN = {2072-4292},
ABSTRACT = {Accurate roof information of buildings can be obtained from UAV high-resolution images. The large-scale accurate recognition of roof types (such as gabled, flat, hipped, complex and mono-pitched roofs) of rural buildings is crucial for rural planning and construction. At present, most UAV high-resolution optical images only have red, green and blue (RGB) band information, which aggravates the problems of inter-class similarity and intra-class variability of image features. Furthermore, the different roof types of rural buildings are complex, spatially scattered, and easily covered by vegetation, which in turn leads to the low accuracy of roof type identification by existing methods. In response to the above problems, this paper proposes a method for identifying roof types of complex rural buildings based on visible high-resolution remote sensing images from UAVs. First, the fusion of deep learning networks with different visual features is investigated to analyze the effect of the different feature combinations of the visible difference vegetation index (VDVI) and Sobel edge detection features and UAV visible images on model recognition of rural building roof types. Secondly, an improved Mask R-CNN model is proposed to learn more complex features of different types of images of building roofs by using the ResNet152 feature extraction network with migration learning. After we obtained roof type recognition results in two test areas, we evaluated the accuracy of the results using the confusion matrix and obtained the following conclusions: (1) the model with RGB images incorporating Sobel edge detection features has the highest accuracy and enables the model to recognize more and more accurately the roof types of different morphological rural buildings, and the model recognition accuracy (Kappa coefficient (KC)) compared to that of RGB images is on average improved by 0.115; (2) compared with the original Mask R-CNN, U-Net, DeeplabV3 and PSPNet deep learning models, the improved Mask R-CNN model has the highest accuracy in recognizing the roof types of rural buildings, with F1-score, KC and OA averaging 0.777, 0.821 and 0.905, respectively. The method can obtain clear and accurate profiles and types of rural building roofs, and can be extended for green roof suitability evaluation, rooftop solar potential assessment, and other building roof surveys, management and planning.},
DOI = {10.3390/rs14020265}
}



@Article{s22020448,
AUTHOR = {Kim, Yumi and Paik, Mincheol and Kim, Bokyeong and Ko, Haneul and Kim, Seung-Yeon},
TITLE = {Neighbor-Aware Non-Orthogonal Multiple Access Scheme for Energy Harvesting Internet of Things},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {448},
URL = {https://www.mdpi.com/1424-8220/22/2/448},
ISSN = {1424-8220},
ABSTRACT = {In a non-orthogonal multiple access (NOMA) environment, an Internet of Things (IoT) device achieves a high data rate by increasing its transmission power. However, excessively high transmission power can cause an energy outage of an IoT device and have a detrimental effect on the signal-to-interference-plus-noise ratio of neighbor IoT devices. In this paper, we propose a neighbor-aware NOMA scheme (NA-NOMA) where each IoT device determines whether to transmit data to the base station and the transmission power at each time epoch in a distributed manner with the consideration of its energy level and other devices&rsquo; transmission powers. To maximize the aggregated data rate of IoT devices while keeping an acceptable average energy outage probability, a constrained stochastic game model is formulated, and the solution of the model is obtained using a best response dynamics-based algorithm. Evaluation results show that NA-NOMA can increase the average data rate up to 22% compared with a probability-based scheme while providing a sufficiently low energy outage probability (e.g., 0.05).},
DOI = {10.3390/s22020448}
}



@Article{rs14020269,
AUTHOR = {Wang, Yong and Zeng, Xiangqiang and Liao, Xiaohan and Zhuang, Dafang},
TITLE = {B-FGC-Net: A Building Extraction Network from High Resolution Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {269},
URL = {https://www.mdpi.com/2072-4292/14/2/269},
ISSN = {2072-4292},
ABSTRACT = {Deep learning (DL) shows remarkable performance in extracting buildings from high resolution remote sensing images. However, how to improve the performance of DL based methods, especially the perception of spatial information, is worth further study. For this purpose, we proposed a building extraction network with feature highlighting, global awareness, and cross level information fusion (B-FGC-Net). The residual learning and spatial attention unit are introduced in the encoder of the B-FGC-Net, which simplifies the training of deep convolutional neural networks and highlights the spatial information representation of features. The global feature information awareness module is added to capture multiscale contextual information and integrate the global semantic information. The cross level feature recalibration module is used to bridge the semantic gap between low and high level features to complete the effective fusion of cross level information. The performance of the proposed method was tested on two public building datasets and compared with classical methods, such as UNet, LinkNet, and SegNet. Experimental results demonstrate that B-FGC-Net exhibits improved profitability of accurate extraction and information integration for both small and large scale buildings. The IoU scores of B-FGC-Net on WHU and INRIA Building datasets are 90.04% and 79.31%, respectively. B-FGC-Net is an effective and recommended method for extracting buildings from high resolution remote sensing images.},
DOI = {10.3390/rs14020269}
}



@Article{rs14020274,
AUTHOR = {Anuar, Mohamed Marzhar and Halin, Alfian Abdul and Perumal, Thinagaran and Kalantar, Bahareh},
TITLE = {Aerial Imagery Paddy Seedlings Inspection Using Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {274},
URL = {https://www.mdpi.com/2072-4292/14/2/274},
ISSN = {2072-4292},
ABSTRACT = {In recent years complex food security issues caused by climatic changes, limitations in human labour, and increasing production costs require a strategic approach in addressing problems. The emergence of artificial intelligence due to the capability of recent advances in computing architectures could become a new alternative to existing solutions. Deep learning algorithms in computer vision for image classification and object detection can facilitate the agriculture industry, especially in paddy cultivation, to alleviate human efforts in laborious, burdensome, and repetitive tasks. Optimal planting density is a crucial factor for paddy cultivation as it will influence the quality and quantity of production. There have been several studies involving planting density using computer vision and remote sensing approaches. While most of the studies have shown promising results, they have disadvantages and show room for improvement. One of the disadvantages is that the studies aim to detect and count all the paddy seedlings to determine planting density. The defective paddy seedlings&rsquo; locations are not pointed out to help farmers during the sowing process. In this work we aimed to explore several deep convolutional neural networks (DCNN) models to determine which one performs the best for defective paddy seedling detection using aerial imagery. Thus, we evaluated the accuracy, robustness, and inference latency of one- and two-stage pretrained object detectors combined with state-of-the-art feature extractors such as EfficientNet, ResNet50, and MobilenetV2 as a backbone. We also investigated the effect of transfer learning with fine-tuning on the performance of the aforementioned pretrained models. Experimental results showed that our proposed methods were capable of detecting the defective paddy rice seedlings with the highest precision and an F1-Score of 0.83 and 0.77, respectively, using a one-stage pretrained object detector called EfficientDet-D1 EficientNet.},
DOI = {10.3390/rs14020274}
}



@Article{s22020452,
AUTHOR = {Yang, Qun and Shen, Dejian},
TITLE = {Learning Damage Representations with Sequence-to-Sequence Models},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {452},
URL = {https://www.mdpi.com/1424-8220/22/2/452},
ISSN = {1424-8220},
ABSTRACT = {Natural hazards have caused damages to structures and economic losses worldwide. Post-hazard responses require accurate and fast damage detection and assessment. In many studies, the development of data-driven damage detection within the research community of structural health monitoring has emerged due to the advances in deep learning models. Most data-driven models for damage detection focus on classifying different damage states and hence damage states cannot be effectively quantified. To address such a deficiency in data-driven damage detection, we propose a sequence-to-sequence (Seq2Seq) model to quantify a probability of damage. The model was trained to learn damage representations with only undamaged signals and then quantify the probability of damage by feeding damaged signals into models. We tested the validity of our proposed Seq2Seq model with a signal dataset which was collected from a two-story timber building subjected to shake table tests. Our results show that our Seq2Seq model has a strong capability of distinguishing damage representations and quantifying the probability of damage in terms of highlighting the regions of interest.},
DOI = {10.3390/s22020452}
}



@Article{rs14020285,
AUTHOR = {Zhang, Tao and Jiang, Xiaodong and Jiang, Linlin and Li, Xuran and Yang, Shenbin and Li, Yingxue},
TITLE = {Hyperspectral Reflectance Characteristics of Rice Canopies under Changes in Diffuse Radiation Fraction},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {285},
URL = {https://www.mdpi.com/2072-4292/14/2/285},
ISSN = {2072-4292},
ABSTRACT = {To analyze the hyperspectral reflectance characteristics of rice canopies under changes in diffuse radiation fraction, experiments using different cover materials were performed in Nanjing, China, during 2016 and 2017. Each year, two treatments with different reduction ratios of diffuse radiation fraction but with similar shading rates were set in the field experiment: In T1, total solar radiation shading rate was 14.10%, and diffuse radiation fraction was 31.09%; in T2, total solar radiation shading rate was 14.42%, and diffuse radiation fraction was 39.98%, respectively. A non-shading treatment was included as a control (CK). Canopy hyperspectral reflectance, soil and plant analyzer development (SPAD), and leaf area index (LAI) were measured under shading treatments on different days after heading. The red-edge parameters (position, &lambda;0; maximum amplitude, D&lambda;; area, &alpha;0; width, &sigma;) were calculated, as well as the area, depth, and width of three absorption bands. The location of the first absorption band appeared in the range of 553&ndash;788 nm, and the second and third absorption bands appeared in the range of 874&ndash;1257 nm. The results show that the shading treatment had a significant effect on the rice canopy&rsquo;s hyperspectral reflectance. Compared with CK, the canopy reflectance of T1 (the diffuse radiation fraction was 31.09%) and T2 (the diffuse radiation fraction was 39.98%) decreased in the visible light range (350&ndash;760 nm) and increased in the near-infrared range (800&ndash;1350 nm), while the red-edge parameters (&lambda;0, D&lambda;, &alpha;0), SPAD, and LAI increased. On the other hand, under shading treatment, the increase in diffuse radiation fraction also had a significant impact on the hyperspectral spectra of the rice canopy, especially at 14 days after heading. Compared with T1, the green peak (550 nm) of T2 reduced by 16.12%, and the average reflectance at 800&ndash;900 nm increased by 10%. Based on correlation analysis, it was found that these hyperspectral reflectance characteristics were mainly due to the increase in SPAD (2.31%) and LAI (7.62%), which also led to the increase in D&lambda; (8.70%) and &alpha;0 (13.89%). Then, the second and third absorption features of T2 were significantly different from that of T1, which suggests that the change in diffuse radiation fraction could affect the process of water vapor absorption by rice.},
DOI = {10.3390/rs14020285}
}



@Article{ijgi11010043,
AUTHOR = {Cira, Calimanut-Ionut and Kada, Martin and Manso-Callejo, Miguel-Ángel and Alcarria, Ramón and Bordel Sanchez, Borja},
TITLE = {Improving Road Surface Area Extraction via Semantic Segmentation with Conditional Generative Learning for Deep Inpainting Operations},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {43},
URL = {https://www.mdpi.com/2220-9964/11/1/43},
ISSN = {2220-9964},
ABSTRACT = {The road surface area extraction task is generally carried out via semantic segmentation over remotely-sensed imagery. However, this supervised learning task is often costly as it requires remote sensing images labelled at the pixel level, and the results are not always satisfactory (presence of discontinuities, overlooked connection points, or isolated road segments). On the other hand, unsupervised learning does not require labelled data and can be employed for post-processing the geometries of geospatial objects extracted via semantic segmentation. In this work, we implement a conditional Generative Adversarial Network to reconstruct road geometries via deep inpainting procedures on a new dataset containing unlabelled road samples from challenging areas present in official cartographic support from Spain. The goal is to improve the initial road representations obtained with semantic segmentation models via generative learning. The performance of the model was evaluated on unseen data by conducting a metrical comparison where a maximum Intersection over Union (IoU) score improvement of 1.3% was observed when compared to the initial semantic segmentation result. Next, we evaluated the appropriateness of applying unsupervised generative learning using a qualitative perceptual validation to identify the strengths and weaknesses of the proposed method in very complex scenarios and gain a better intuition of the model&rsquo;s behaviour when performing large-scale post-processing with generative learning and deep inpainting procedures and observed important improvements in the generated data.},
DOI = {10.3390/ijgi11010043}
}



@Article{pr10010131,
AUTHOR = {Luo, Wei and Han, Wenlong and Fu, Ping and Wang, Huijuan and Zhao, Yunfeng and Liu, Ke and Liu, Yuyan and Zhao, Zihui and Zhu, Mengxu and Xu, Ruopeng and Wei, Guosheng},
TITLE = {A Water Surface Contaminants Monitoring Method Based on Airborne Depth Reasoning},
JOURNAL = {Processes},
VOLUME = {10},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {131},
URL = {https://www.mdpi.com/2227-9717/10/1/131},
ISSN = {2227-9717},
ABSTRACT = {Water surface plastic pollution turns out to be a global issue, having aroused rising attention worldwide. How to monitor water surface plastic waste in real time and accurately collect and analyze the relevant numerical data has become a hotspot in water environment research. (1) Background: Over the past few years, unmanned aerial vehicles (UAVs) have been progressively adopted to conduct studies on the monitoring of water surface plastic waste. On the whole, the monitored data are stored in the UAVS to be subsequently retrieved and analyzed, thereby probably causing the loss of real-time information and hindering the whole monitoring process from being fully automated. (2) Methods: An investigation was conducted on the relationship, function and relevant mechanism between various types of plastic waste in the water surface system. On that basis, this study built a deep learning-based lightweight water surface plastic waste detection model, which was capable of automatically detecting and locating different water surface plastic waste. Moreover, a UAV platform-based edge computing architecture was built. (3) Results: The delay of return task data and UAV energy consumption were effectively reduced, and computing and network resources were optimally allocated. (4) Conclusions: The UAV platform based on airborne depth reasoning is expected to be the mainstream means of water environment monitoring in the future.},
DOI = {10.3390/pr10010131}
}



@Article{en15020455,
AUTHOR = {Zhang, Bowen and Song, Zaixin and Zhao, Fei and Liu, Chunhua},
TITLE = {Overview of Propulsion Systems for Unmanned Aerial Vehicles},
JOURNAL = {Energies},
VOLUME = {15},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {455},
URL = {https://www.mdpi.com/1996-1073/15/2/455},
ISSN = {1996-1073},
ABSTRACT = {Unmanned Aerial Vehicle (UAV) propulsion technology is significantly related to the flight performance of UAVs, which has become one of the most important development directions of aviation. It should be noted that UAVs have three types of propulsion systems, namely the fuel, hybrid fuel-electric, and pure electric, respectively. This paper presents and discusses the classification, working principles, characteristics, and critical technologies of these three types of propulsion systems. It is helpful to establish the development framework of the UAV propulsion system and provide the essential information on electric propulsion UAVs. Additionally, future technologies and development, including the high-power density motors, converters, power supplies, are discussed for the electric propulsion UAVs. In the near future, the electric propulsion system would be widely used in UAVs. The high-power density system would become the development trend of electric UAVs. Thus, this review article provides comprehensive views and multiple comparisons of propulsion systems for UAVs.},
DOI = {10.3390/en15020455}
}



@Article{aerospace9010031,
AUTHOR = {Samadzadegan, Farhad and Dadrass Javan, Farzaneh and Ashtari Mahini, Farnaz and Gholamshahi, Mehrnaz},
TITLE = {Detection and Recognition of Drones Based on a Deep Convolutional Neural Network Using Visible Imagery},
JOURNAL = {Aerospace},
VOLUME = {9},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {31},
URL = {https://www.mdpi.com/2226-4310/9/1/31},
ISSN = {2226-4310},
ABSTRACT = {Drones are becoming increasingly popular not only for recreational purposes but also in a variety of applications in engineering, disaster management, logistics, securing airports, and others. In addition to their useful applications, an alarming concern regarding physical infrastructure security, safety, and surveillance at airports has arisen due to the potential of their use in malicious activities. In recent years, there have been many reports of the unauthorized use of various types of drones at airports and the disruption of airline operations. To address this problem, this study proposes a novel deep learning-based method for the efficient detection and recognition of two types of drones and birds. Evaluation of the proposed approach with the prepared image dataset demonstrates better efficiency compared to existing detection systems in the literature. Furthermore, drones are often confused with birds because of their physical and behavioral similarity. The proposed method is not only able to detect the presence or absence of drones in an area but also to recognize and distinguish between two types of drones, as well as distinguish them from birds. The dataset used in this work to train the network consists of 10,000 visible images containing two types of drones as multirotors, helicopters, and also birds. The proposed deep learning method can directly detect and recognize two types of drones and distinguish them from birds with an accuracy of 83%, mAP of 84%, and IoU of 81%. The values of average recall, average accuracy, and average F1-score were also reported as 84%, 83%, and 83%, respectively, in three classes.},
DOI = {10.3390/aerospace9010031}
}



@Article{drones6010016,
AUTHOR = {Aldao, Enrique and González-deSantos, Luis M. and Michinel, Humberto and González-Jorge, Higinio},
TITLE = {UAV Obstacle Avoidance Algorithm to Navigate in Dynamic Building Environments},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {16},
URL = {https://www.mdpi.com/2504-446X/6/1/16},
ISSN = {2504-446X},
ABSTRACT = {In this work, a real-time collision avoidance algorithm was presented for autonomous navigation in the presence of fixed and moving obstacles in building environments. The current implementation is designed for autonomous navigation between waypoints of a predefined flight trajectory that would be performed by an UAV during tasks such as inspections or construction progress monitoring. It uses a simplified geometry generated from a point cloud of the scenario. In addition, it also employs information from 3D sensors to detect and position obstacles such as people or other UAVs, which are not registered in the original cloud. If an obstacle is detected, the algorithm estimates its motion and computes an evasion path considering the geometry of the environment. The method has been successfully tested in different scenarios, offering robust results in all avoidance maneuvers. Execution times were measured, demonstrating that the algorithm is computationally feasible to be implemented onboard an UAV.},
DOI = {10.3390/drones6010016}
}



@Article{rs14020295,
AUTHOR = {Yu, Kunyong and Hao, Zhenbang and Post, Christopher J. and Mikhailova, Elena A. and Lin, Lili and Zhao, Gejin and Tian, Shangfeng and Liu, Jian},
TITLE = {Comparison of Classical Methods and Mask R-CNN for Automatic Tree Detection and Mapping Using UAV Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {295},
URL = {https://www.mdpi.com/2072-4292/14/2/295},
ISSN = {2072-4292},
ABSTRACT = {Detecting and mapping individual trees accurately and automatically from remote sensing images is of great significance for precision forest management. Many algorithms, including classical methods and deep learning techniques, have been developed and applied for tree crown detection from remote sensing images. However, few studies have evaluated the accuracy of different individual tree detection (ITD) algorithms and their data and processing requirements. This study explored the accuracy of ITD using local maxima (LM) algorithm, marker-controlled watershed segmentation (MCWS), and Mask Region-based Convolutional Neural Networks (Mask R-CNN) in a young plantation forest with different test images. Manually delineated tree crowns from UAV imagery were used for accuracy assessment of the three methods, followed by an evaluation of the data processing and application requirements for three methods to detect individual trees. Overall, Mask R-CNN can best use the information in multi-band input images for detecting individual trees. The results showed that the Mask R-CNN model with the multi-band combination produced higher accuracy than the model with a single-band image, and the RGB band combination achieved the highest accuracy for ITD (F1 score = 94.68%). Moreover, the Mask R-CNN models with multi-band images are capable of providing higher accuracies for ITD than the LM and MCWS algorithms. The LM algorithm and MCWS algorithm also achieved promising accuracies for ITD when the canopy height model (CHM) was used as the test image (F1 score = 87.86% for LM algorithm, F1 score = 85.92% for MCWS algorithm). The LM and MCWS algorithms are easy to use and lower computer computational requirements, but they are unable to identify tree species and are limited by algorithm parameters, which need to be adjusted for each classification. It is highlighted that the application of deep learning with its end-to-end-learning approach is very efficient and capable of deriving the information from multi-layer images, but an additional training set is needed for model training, robust computer resources are required, and a large number of accurate training samples are necessary. This study provides valuable information for forestry practitioners to select an optimal approach for detecting individual trees.},
DOI = {10.3390/rs14020295}
}



@Article{app12020670,
AUTHOR = {Tursunboev, Jamshid and Kang, Yong-Sung and Huh, Sung-Bum and Lim, Dong-Woo and Kang, Jae-Mo and Jung, Heechul},
TITLE = {Hierarchical Federated Learning for Edge-Aided Unmanned Aerial Vehicle Networks},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {670},
URL = {https://www.mdpi.com/2076-3417/12/2/670},
ISSN = {2076-3417},
ABSTRACT = {Federated learning (FL) allows UAVs to collaboratively train a globally shared machine learning model while locally preserving their private data. Recently, the FL in edge-aided unmanned aerial vehicle (UAV) networks has drawn an upsurge of research interest due to a bursting increase in heterogeneous data acquired by UAVs and the need to build the global model with privacy; however, a critical issue is how to deal with the non-independent and identically distributed (non-i.i.d.) nature of heterogeneous data while ensuring the convergence of learning. To effectively address this challenging issue, this paper proposes a novel and high-performing FL scheme, namely, the hierarchical FL algorithm, for the edge-aided UAV network, which exploits the edge servers located in base stations as intermediate aggregators with employing commonly shared data. Experiment results demonstrate that the proposed hierarchical FL algorithm outperforms several baseline FL algorithms and exhibits better convergence behavior.},
DOI = {10.3390/app12020670}
}



@Article{rs14020317,
AUTHOR = {Hardy, Andy and Oakes, Gregory and Hassan, Juma and Yussuf, Yussuf},
TITLE = {Improved Use of Drone Imagery for Malaria Vector Control through Technology-Assisted Digitizing (TAD)},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {317},
URL = {https://www.mdpi.com/2072-4292/14/2/317},
ISSN = {2072-4292},
ABSTRACT = {Drones have the potential to revolutionize malaria vector control initiatives through rapid and accurate mapping of potential malarial mosquito larval habitats to help direct field Larval Source Management (LSM) efforts. However, there are no clear recommendations on how these habitats can be extracted from drone imagery in an operational context. This paper compares the results of two mapping approaches: supervised image classification using machine learning and Technology-Assisted Digitising (TAD) mapping that employs a new region growing tool suitable for non-experts. These approaches were applied concurrently to drone imagery acquired at seven sites in Zanzibar, United Republic of Tanzania. Whilst the two approaches were similar in processing time, the TAD approach significantly outperformed the supervised classification approach at all sites (t = 5.1, p &lt; 0.01). Overall accuracy scores (mean overall accuracy 62%) suggest that a supervised classification approach is unsuitable for mapping potential malarial mosquito larval habitats in Zanzibar, whereas the TAD approach offers a simple and accurate (mean overall accuracy 96%) means of mapping these complex features. We recommend that this approach be used alongside targeted ground-based surveying (i.e., in areas inappropriate for drone surveying) for generating precise and accurate spatial intelligence to support operational LSM programmes.},
DOI = {10.3390/rs14020317}
}



@Article{app12020691,
AUTHOR = {Zhong, Jiwei and Xiang, Ziru and Li, Cheng},
TITLE = {Synchronized Assessment of Bridge Structural Damage and Moving Force via Truncated Load Shape Function},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {691},
URL = {https://www.mdpi.com/2076-3417/12/2/691},
ISSN = {2076-3417},
ABSTRACT = {Moving load and structural damage assessment has always been a crucial topic in bridge health monitoring, as it helps analyze the daily operating status of bridges and provides fundamental information for bridge safety evaluation. However, most studies and research consider these issues as two separate problems. In practice, unknown moving loads and damage usually coexist and influence the bridge vibration synergically. This paper proposes an innovative synchronized assessment method that determines structural damages and moving forces simultaneously. The method firstly improves the virtual distortion method, which shifts the structural damage into external virtual forces and hence transforms the damage assessment as well as the moving force identification to a multi-force reconstruction problem. Secondly, a truncated load shape function (TLSF) technique is developed to solve the forces in the time domain. As the technique smoothens the pulse function via a limited number of TLSF, the singularity and dimension of the system matrix in the force reconstruction is largely reduced. A continuous beam and a three-dimensional truss bridge are simulated as examples. Case studies show that the method can effectively identify various speeds and numbers of moving loads, as well as different levels of structural damages. The calculation efficiency and robustness to white noise are also impressive.},
DOI = {10.3390/app12020691}
}



@Article{aerospace9010035,
AUTHOR = {Bakar, Abu and Li, Ke and Liu, Haobo and Xu, Ziqi and Alessandrini, Marco and Wen, Dongsheng},
TITLE = {Multi-Objective Optimization of Low Reynolds Number Airfoil Using Convolutional Neural Network and Non-Dominated Sorting Genetic Algorithm},
JOURNAL = {Aerospace},
VOLUME = {9},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {35},
URL = {https://www.mdpi.com/2226-4310/9/1/35},
ISSN = {2226-4310},
ABSTRACT = {The airfoil is the prime component of flying vehicles. For low-speed flights, low Reynolds number airfoils are used. The characteristic of low Reynolds number airfoils is a laminar separation bubble and an associated drag rise. This paper presents a framework for the design of a low Reynolds number airfoil. The contributions of the proposed research are twofold. First, a convolutional neural network (CNN) is designed for the aerodynamic coefficient prediction of low Reynolds number airfoils. Data generation is discussed in detail and XFOIL is selected to obtain aerodynamic coefficients. The performance of the CNN is evaluated using different learning rate schedulers and adaptive learning rate optimizers. The trained model can predict the aerodynamic coefficients with high accuracy. Second, the trained model is used with a non-dominated sorting genetic algorithm (NSGA-II) for multi-objective optimization of the low Reynolds number airfoil at a specific angle of attack. A similar optimization is performed using NSGA-II directly calling XFOIL, to obtain the aerodynamic coefficients. The Pareto fronts of both optimizations are compared, and it is concluded that the proposed CNN can replicate the actual Pareto in considerably less time.},
DOI = {10.3390/aerospace9010035}
}



@Article{s22020562,
AUTHOR = {Kociołek, Marcin and Kozłowski, Michał and Cardone, Antonio},
TITLE = {A Convolutional Neural Networks-Based Approach for Texture Directionality Detection},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {562},
URL = {https://www.mdpi.com/1424-8220/22/2/562},
ISSN = {1424-8220},
ABSTRACT = {The perceived texture directionality is an important, not fully explored image characteristic. In many applications texture directionality detection is of fundamental importance. Several approaches have been proposed, such as the fast Fourier-based method. We recently proposed a method based on the interpolated grey-level co-occurrence matrix (iGLCM), robust to image blur and noise but slower than the Fourier-based method. Here we test the applicability of convolutional neural networks (CNNs) to texture directionality detection. To obtain the large amount of training data required, we built a training dataset consisting of synthetic textures with known directionality and varying perturbation levels. Subsequently, we defined and tested shallow and deep CNN architectures. We present the test results focusing on the CNN architectures and their robustness with respect to image perturbations. We identify the best performing CNN architecture, and compare it with the iGLCM, the Fourier and the local gradient orientation methods. We find that the accuracy of CNN is lower, yet comparable to the iGLCM, and it outperforms the other two methods. As expected, the CNN method shows the highest computing speed. Finally, we demonstrate the best performing CNN on real-life images. Visual analysis suggests that the learned patterns generalize to real-life image data. Hence, CNNs represent a promising approach for texture directionality detection, warranting further investigation.},
DOI = {10.3390/s22020562}
}



@Article{rs14020339,
AUTHOR = {Berg, Paul and Santana Maia, Deise and Pham, Minh-Tan and Lefèvre, Sébastien},
TITLE = {Weakly Supervised Detection of Marine Animals in High Resolution Aerial Images},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {339},
URL = {https://www.mdpi.com/2072-4292/14/2/339},
ISSN = {2072-4292},
ABSTRACT = {Human activities in the sea, such as intensive fishing and exploitation of offshore wind farms, may impact negatively on the marine mega fauna. As an attempt to control such impacts, surveying, and tracking of marine animals are often performed on the sites where those activities take place. Nowadays, thank to high resolution cameras and to the development of machine learning techniques, tracking of wild animals can be performed remotely and the analysis of the acquired images can be automatized using state-of-the-art object detection models. However, most state-of-the-art detection methods require lots of annotated data to provide satisfactory results. Since analyzing thousands of images acquired during a flight survey can be a cumbersome and time consuming task, we focus in this article on the weakly supervised detection of marine animals. We propose a modification of the patch distribution modeling method (PaDiM), which is currently one of the state-of-the-art approaches for anomaly detection and localization for visual industrial inspection. In order to show its effectiveness and suitability for marine animal detection, we conduct a comparative evaluation of the proposed method against the original version, as well as other state-of-the-art approaches on two high-resolution marine animal image datasets. On both tested datasets, the proposed method yielded better F1 and recall scores (75% recall/41% precision, and 57% recall/60% precision, respectively) when trained on images known to contain no object of interest. This shows a great potential of the proposed approach to speed up the marine animal discovery in new flight surveys. Additionally, such a method could be adopted for bounding box proposals to perform faster and cheaper annotation within a fully-supervised detection framework.},
DOI = {10.3390/rs14020339}
}



@Article{drones6010021,
AUTHOR = {Zhang, Ruohao and Condomines, Jean-Philippe and Lochin, Emmanuel},
TITLE = {A Multifractal Analysis and Machine Learning Based Intrusion Detection System with an Application in a UAS/RADAR System},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {21},
URL = {https://www.mdpi.com/2504-446X/6/1/21},
ISSN = {2504-446X},
ABSTRACT = {The rapid development of Internet of Things (IoT) technology, together with mobile network technology, has created a never-before-seen world of interconnection, evoking research on how to make it vaster, faster, and safer. To support the ongoing fight against the malicious misuse of networks, in this paper we propose a novel algorithm called AMDES (unmanned aerial system multifractal analysis intrusion detection system) for spoofing attack detection. This novel algorithm is based on both wavelet leader multifractal analysis (WLM) and machine learning (ML) principles. In earlier research on unmanned aerial systems (UAS), intrusion detection systems (IDS) based on multifractal (MF) spectral analysis have been used to provide accurate MF spectrum estimations of network traffic. Such an estimation is then used to detect and characterize flooding anomalies that can be observed in an unmanned aerial vehicle (UAV) network. However, the previous contributions have lacked the consideration of other types of network intrusions commonly observed in UAS networks, such as the man in the middle attack (MITM). In this work, this promising methodology has been accommodated to detect a spoofing attack within a UAS. This methodology highlights a robust approach in terms of false positive performance in detecting intrusions in a UAS location reporting system.},
DOI = {10.3390/drones6010021}
}



@Article{rs14020349,
AUTHOR = {Abdi, Omid and Uusitalo, Jori and Kivinen, Veli-Pekka},
TITLE = {Logging Trail Segmentation via a Novel U-Net Convolutional Neural Network and High-Density Laser Scanning Data},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {349},
URL = {https://www.mdpi.com/2072-4292/14/2/349},
ISSN = {2072-4292},
ABSTRACT = {Logging trails are one of the main components of modern forestry. However, spotting the accurate locations of old logging trails through common approaches is challenging and time consuming. This study was established to develop an approach, using cutting-edge deep-learning convolutional neural networks and high-density laser scanning data, to detect logging trails in different stages of commercial thinning, in Southern Finland. We constructed a U-Net architecture, consisting of encoder and decoder paths with several convolutional layers, pooling and non-linear operations. The canopy height model (CHM), digital surface model (DSM), and digital elevation models (DEMs) were derived from the laser scanning data and were used as image datasets for training the model. The labeled dataset for the logging trails was generated from different references as well. Three forest areas were selected to test the efficiency of the algorithm that was developed for detecting logging trails. We designed 21 routes, including 390 samples of the logging trails and non-logging trails, covering all logging trails inside the stands. The results indicated that the trained U-Net using DSM (k = 0.846 and IoU = 0.867) shows superior performance over the trained model using CHM (k = 0.734 and IoU = 0.782), DEMavg (k = 0.542 and IoU = 0.667), and DEMmin (k = 0.136 and IoU = 0.155) in distinguishing logging trails from non-logging trails. Although the efficiency of the developed approach in young and mature stands that had undergone the commercial thinning is approximately perfect, it needs to be improved in old stands that have not received the second or third commercial thinning.},
DOI = {10.3390/rs14020349}
}



@Article{drones6010022,
AUTHOR = {Tuli, Esmot Ara and Golam, Mohtasin and Kim, Dong-Seong and Lee, Jae-Min},
TITLE = {Performance Enhancement of Optimized Link State Routing Protocol by Parameter Configuration for UANET},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {22},
URL = {https://www.mdpi.com/2504-446X/6/1/22},
ISSN = {2504-446X},
ABSTRACT = {The growing need for wireless communication has resulted in the widespread usage of unmanned aerial vehicles (UAVs) in a variety of applications. Designing a routing protocol for UAVs is paramount as well as challenging due to its dynamic attributes. The difficulty stems from features other than mobile ad hoc networks (MANET), such as aerial mobility in 3D space and frequently changing topology. This paper analyzes the performance of four topology-based routing protocols, dynamic source routing (DSR), ad hoc on-demand distance vector (AODV), geographic routing protocol (GRP), and optimized link state routing (OLSR), by using practical simulation software OPNET 14.5. Performance evaluation carries out various metrics such as throughput, delay, and data drop rate. Moreover, the performance of the OLSR routing protocol is enhanced and named &ldquo;E-OLSR&rdquo; by tuning parameters and reducing holding time. The optimized E-OLSR settings provide better performance than the conventional request for comments (RFC 3626) in the experiment, making it suitable for use in UAV ad hoc network (UANET) environments. Simulation results indicate the proposed E-OLSR outperforms the existing OLSR and achieves supremacy over other protocols mentioned in this paper.},
DOI = {10.3390/drones6010022}
}



@Article{s22020601,
AUTHOR = {Sharma, Prakriti and Leigh, Larry and Chang, Jiyul and Maimaitijiang, Maitiniyazi and Caffé, Melanie},
TITLE = {Above-Ground Biomass Estimation in Oats Using UAV Remote Sensing and Machine Learning},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {601},
URL = {https://www.mdpi.com/1424-8220/22/2/601},
ISSN = {1424-8220},
ABSTRACT = {Current strategies for phenotyping above-ground biomass in field breeding nurseries demand significant investment in both time and labor. Unmanned aerial vehicles (UAV) can be used to derive vegetation indices (VIs) with high throughput and could provide an efficient way to predict forage yield with high accuracy. The main objective of the study is to investigate the potential of UAV-based multispectral data and machine learning approaches in the estimation of oat biomass. UAV equipped with a multispectral sensor was flown over three experimental oat fields in Volga, South Shore, and Beresford, South Dakota, USA, throughout the pre- and post-heading growth phases of oats in 2019. A variety of vegetation indices (VIs) derived from UAV-based multispectral imagery were employed to build oat biomass estimation models using four machine-learning algorithms: partial least squares (PLS), support vector machine (SVM), Artificial neural network (ANN), and random forest (RF). The results showed that several VIs derived from the UAV collected images were significantly positively correlated with dry biomass for Volga and Beresford (r = 0.2&ndash;0.65), however, in South Shore, VIs were either not significantly or weakly correlated with biomass. For Beresford, approximately 70% of the variance was explained by PLS, RF, and SVM validation models using data collected during the post-heading phase. Likewise for Volga, validation models had lower coefficient of determination (R2 = 0.20&ndash;0.25) and higher error (RMSE = 700&ndash;800 kg/ha) than training models (R2 = 0.50&ndash;0.60; RMSE = 500&ndash;690 kg/ha). In South Shore, validation models were only able to explain approx. 15&ndash;20% of the variation in biomass, which is possibly due to the insignificant correlation values between VIs and biomass. Overall, this study indicates that airborne remote sensing with machine learning has potential for above-ground biomass estimation in oat breeding nurseries. The main limitation was inconsistent accuracy in model prediction across locations. Multiple-year spectral data, along with the inclusion of textural features like crop surface model (CSM) derived height and volumetric indicators, should be considered in future studies while estimating biophysical parameters like biomass.},
DOI = {10.3390/s22020601}
}



@Article{rs14020382,
AUTHOR = {Jing, Yafei and Ren, Yuhuan and Liu, Yalan and Wang, Dacheng and Yu, Linjun},
TITLE = {Automatic Extraction of Damaged Houses by Earthquake Based on Improved YOLOv5: A Case Study in Yangbi},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {382},
URL = {https://www.mdpi.com/2072-4292/14/2/382},
ISSN = {2072-4292},
ABSTRACT = {Efficiently and automatically acquiring information on earthquake damage through remote sensing has posed great challenges because the classical methods of detecting houses damaged by destructive earthquakes are often both time consuming and low in accuracy. A series of deep-learning-based techniques have been developed and recent studies have demonstrated their high intelligence for automatic target extraction for natural and remote sensing images. For the detection of small artificial targets, current studies show that You Only Look Once (YOLO) has a good performance in aerial and Unmanned Aerial Vehicle (UAV) images. However, less work has been conducted on the extraction of damaged houses. In this study, we propose a YOLOv5s-ViT-BiFPN-based neural network for the detection of rural houses. Specifically, to enhance the feature information of damaged houses from the global information of the feature map, we introduce the Vision Transformer into the feature extraction network. Furthermore, regarding the scale differences for damaged houses in UAV images due to the changes in flying height, we apply the Bi-Directional Feature Pyramid Network (BiFPN) for multi-scale feature fusion to aggregate features with different resolutions and test the model. We took the 2021 Yangbi earthquake with a surface wave magnitude (Ms) of 6.4 in Yunan, China, as an example; the results show that the proposed model presents a better performance, with the average precision (AP) being increased by 9.31% and 1.23% compared to YOLOv3 and YOLOv5s, respectively, and a detection speed of 80 FPS, which is 2.96 times faster than YOLOv3. In addition, the transferability test for five other areas showed that the average accuracy was 91.23% and the total processing time was 4 min, while 100 min were needed for professional visual interpreters. The experimental results demonstrate that the YOLOv5s-ViT-BiFPN model can automatically detect damaged rural houses due to destructive earthquakes in UAV images with a good performance in terms of accuracy and timeliness, as well as being robust and transferable.},
DOI = {10.3390/rs14020382}
}



@Article{quat5010005,
AUTHOR = {Howland, Matthew D. and Tamberino, Anthony and Liritzis, Ioannis and Levy, Thomas E.},
TITLE = {Digital Deforestation: Comparing Automated Approaches to the Production of Digital Terrain Models (DTMs) in Agisoft Metashape},
JOURNAL = {Quaternary},
VOLUME = {5},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {5},
URL = {https://www.mdpi.com/2571-550X/5/1/5},
ISSN = {2571-550X},
ABSTRACT = {This paper tests the suitability of automated point cloud classification tools provided by the popular image-based modeling (IBM) software package Agisoft Metashape for the generation of digital terrain models (DTMs) at moderately-vegetated archaeological sites. DTMs are often required for various forms of archaeological mapping and analysis. The suite of tools provided by Agisoft are relatively user-friendly as compared to many point cloud classification algorithms and do not require the use of additional software. Based on a case study from the Mycenaean site of Kastrouli, Greece, the mostly-automated, geometric classification tool &ldquo;Classify Ground Points&rdquo; provides the best results and produces a quality DTM that is sufficient for mapping and analysis. Each of the methods tested in this paper can likely be improved through manual editing of point cloud classification.},
DOI = {10.3390/quat5010005}
}



@Article{agronomy12010202,
AUTHOR = {Li, Zongpeng and Chen, Zhen and Cheng, Qian and Duan, Fuyi and Sui, Ruixiu and Huang, Xiuqiao and Xu, Honggang},
TITLE = {UAV-Based Hyperspectral and Ensemble Machine Learning for Predicting Yield in Winter Wheat},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {202},
URL = {https://www.mdpi.com/2073-4395/12/1/202},
ISSN = {2073-4395},
ABSTRACT = {Winter wheat is a widely-grown cereal crop worldwide. Using growth-stage information to estimate winter wheat yields in a timely manner is essential for accurate crop management and rapid decision-making in sustainable agriculture, and to increase productivity while reducing environmental impact. UAV remote sensing is widely used in precision agriculture due to its flexibility and increased spatial and spectral resolution. Hyperspectral data are used to model crop traits because of their ability to provide continuous rich spectral information and higher spectral fidelity. In this study, hyperspectral image data of the winter wheat crop canopy at the flowering and grain-filling stages was acquired by a low-altitude unmanned aerial vehicle (UAV), and machine learning was used to predict winter wheat yields. Specifically, a large number of spectral indices were extracted from the spectral data, and three feature selection methods, recursive feature elimination (RFE), Boruta feature selection, and the Pearson correlation coefficient (PCC), were used to filter high spectral indices in order to reduce the dimensionality of the data. Four major basic learner models, (1) support vector machine (SVM), (2) Gaussian process (GP), (3) linear ridge regression (LRR), and (4) random forest (RF), were also constructed, and an ensemble machine learning model was developed by combining the four base learner models. The results showed that the SVM yield prediction model, constructed on the basis of the preferred features, performed the best among the base learner models, with an R2 between 0.62 and 0.73. The accuracy of the proposed ensemble learner model was higher than that of each base learner model; moreover, the R2 (0.78) for the yield prediction model based on Boruta&rsquo;s preferred characteristics was the highest at the grain-filling stage.},
DOI = {10.3390/agronomy12010202}
}



@Article{rs14020396,
AUTHOR = {Shi, Yue and Han, Liangxiu and Kleerekoper, Anthony and Chang, Sheng and Hu, Tongle},
TITLE = {Novel CropdocNet Model for Automated Potato Late Blight Disease Detection from Unmanned Aerial Vehicle-Based Hyperspectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {396},
URL = {https://www.mdpi.com/2072-4292/14/2/396},
ISSN = {2072-4292},
ABSTRACT = {The accurate and automated diagnosis of potato late blight disease, one of the most destructive potato diseases, is critical for precision agricultural control and management. Recent advances in remote sensing and deep learning offer the opportunity to address this challenge. This study proposes a novel end-to-end deep learning model (CropdocNet) for accurate and automated late blight disease diagnosis from UAV-based hyperspectral imagery. The proposed method considers the potential disease-specific reflectance radiation variance caused by the canopy&rsquo;s structural diversity and introduces multiple capsule layers to model the part-to-whole relationship between spectral&ndash;spatial features and the target classes to represent the rotation invariance of the target classes in the feature space. We evaluate the proposed method with real UAV-based HSI data under controlled and natural field conditions. The effectiveness of the hierarchical features is quantitatively assessed and compared with the existing representative machine learning/deep learning methods on both testing and independent datasets. The experimental results show that the proposed model significantly improves accuracy when considering the hierarchical structure of spectral&ndash;spatial features, with average accuracies of 98.09% for the testing dataset and 95.75% for the independent dataset, respectively.},
DOI = {10.3390/rs14020396}
}



@Article{rs14020397,
AUTHOR = {Zhang, Fangfang and Wang, Changkun and Pan, Kai and Guo, Zhiying and Liu, Jie and Xu, Aiai and Ma, Haiyi and Pan, Xianzhang},
TITLE = {The Simultaneous Prediction of Soil Properties and Vegetation Coverage from Vis-NIR Hyperspectral Data with a One-Dimensional Convolutional Neural Network: A Laboratory Simulation Study},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {397},
URL = {https://www.mdpi.com/2072-4292/14/2/397},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing of land surface mostly obtains a mixture of spectral information of soil and vegetation. It is thus of great value if soil and vegetation information can be acquired simultaneously from one model. In this study, we designed a laboratory experiment to simulate land surface compositions, including various soil types with varying soil moisture and vegetation coverage. A model of a one-dimensional convolutional neural network (1DCNN) was established to simultaneously estimate soil properties (organic matter, soil moisture, clay, and sand) and vegetation coverage based on the hyperspectral data measured in the experiment. The results showed that the model achieved excellent predictions for soil properties (R2 = 0.88&ndash;0.91, RPIQ = 4.01&ndash;5.78) and vegetation coverage (R2 = 0.95, RPIQ = 7.75). Compared with the partial least-squares regression (PLSR), the prediction accuracy of 1DCNN improved 42.20%, 45.82%, 43.32%, and 36.46% in terms of the root-mean-squared error (RMSE) for predicting soil organic matter, sand, clay, and soil moisture, respectively. The improvement might be caused by the fact that the spectral preprocessing and spectral features useful for predicting soil properties were successfully identified in the 1DCNN model. For the prediction of vegetation coverage, although the prediction accuracy by 1DCNN was excellent, its performance (R2 = 0.95, RPIQ = 7.75, RMSE = 3.92%) was lower than the PLSR model (R2 = 0.98, RPIQ = 12.57, RMSE = 2.41%). These results indicate that 1DCNN can simultaneously predict soil properties and vegetation coverage. However, the factors such as surface roughness and vegetation type that could affect the prediction accuracy should be investigated in the future.},
DOI = {10.3390/rs14020397}
}



@Article{en15020614,
AUTHOR = {Ding, Zhenhuan and Huang, Xiaoge and Liu, Zhao},
TITLE = {Active Exploration by Chance-Constrained Optimization for Voltage Regulation with Reinforcement Learning},
JOURNAL = {Energies},
VOLUME = {15},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {614},
URL = {https://www.mdpi.com/1996-1073/15/2/614},
ISSN = {1996-1073},
ABSTRACT = {Voltage regulation in distribution networks encounters a challenge of handling uncertainties caused by the high penetration of photovoltaics (PV). This research proposes an active exploration (AE) method based on reinforcement learning (RL) to respond to the uncertainties by regulating the voltage of a distribution network with battery energy storage systems (BESS). The proposed method integrates engineering knowledge to accelerate the training process of RL. The engineering knowledge is the chance-constrained optimization. We formulate the problem in a chance-constrained optimization with a linear load flow approximation. The optimization results are used to guide the action selection of the exploration for improving training efficiency and reducing the conserveness characteristic. The comparison of methods focuses on how BESSs are used, training efficiency, and robustness under varying uncertainties and BESS sizes. We implement the proposed algorithm, a chance-constrained optimization, and a traditional Q-learning in the IEEE 13 Node Test Feeder. Our evaluation shows that the proposed AE method has a better response to the training efficiency compared to traditional Q-learning. Meanwhile, the proposed method has advantages in BESS usage in conserveness compared to the chance-constrained optimization.},
DOI = {10.3390/en15020614}
}



@Article{s22020682,
AUTHOR = {Xu, Zhibo and Huang, Xiaopeng and Huang, Yuan and Sun, Haobo and Wan, Fangxin},
TITLE = {A Real-Time Zanthoxylum Target Detection Method for an Intelligent Picking Robot under a Complex Background, Based on an Improved YOLOv5s Architecture},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {682},
URL = {https://www.mdpi.com/1424-8220/22/2/682},
ISSN = {1424-8220},
ABSTRACT = {The target recognition algorithm is one of the core technologies of Zanthoxylum pepper-picking robots. However, most existing detection algorithms cannot effectively detect Zanthoxylum fruit covered by branches, leaves and other fruits in natural scenes. To improve the work efficiency and adaptability of the Zanthoxylum-picking robot in natural environments, and to recognize and detect fruits in complex environments under different lighting conditions, this paper presents a Zanthoxylum-picking-robot target detection method based on improved YOLOv5s. Firstly, an improved CBF module based on the CBH module in the backbone is raised to improve the detection accuracy. Secondly, the Specter module based on CBF is presented to replace the bottleneck CSP module, which improves the speed of detection with a lightweight structure. Finally, the Zanthoxylum fruit algorithm is checked by the improved YOLOv5 framework, and the differences in detection between YOLOv3, YOLOv4 and YOLOv5 are analyzed and evaluated. Through these improvements, the recall rate, recognition accuracy and mAP of the YOLOv5s are 4.19%, 28.7% and 14.8% higher than those of the original YOLOv5s, YOLOv3 and YOLOv4 models, respectively. Furthermore, the model is transferred to the computing platform of the robot with the cutting-edge NVIDIA Jetson TX2 device. Several experiments are implemented on the TX2, yielding an average time of inference of 0.072, with an average GPU load in 30 s of 20.11%. This method can provide technical support for pepper-picking robots to detect multiple pepper fruits in real time.},
DOI = {10.3390/s22020682}
}



@Article{biology11010149,
AUTHOR = {Paux, Etienne and Lafarge, Stéphane and Balfourier, François and Derory, Jérémy and Charmet, Gilles and Alaux, Michael and Perchet, Geoffrey and Bondoux, Marion and Baret, Frédéric and Barillot, Romain and Ravel, Catherine and Sourdille, Pierre and Le Gouis, Jacques and on behalf of the BREEDWHEAT Consortium},
TITLE = {Breeding for Economically and Environmentally Sustainable Wheat Varieties: An Integrated Approach from Genomics to Selection},
JOURNAL = {Biology},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {149},
URL = {https://www.mdpi.com/2079-7737/11/1/149},
ISSN = {2079-7737},
ABSTRACT = {There is currently a strong societal demand for sustainability, quality, and safety in bread wheat production. To address these challenges, new and innovative knowledge, resources, tools, and methods to facilitate breeding are needed. This starts with the development of high throughput genomic tools including single nucleotide polymorphism (SNP) arrays, high density molecular marker maps, and full genome sequences. Such powerful tools are essential to perform genome-wide association studies (GWAS), to implement genomic and phenomic selection, and to characterize the worldwide diversity. This is also useful to breeders to broaden the genetic basis of elite varieties through the introduction of novel sources of genetic diversity. Improvement in varieties particularly relies on the detection of genomic regions involved in agronomical traits including tolerance to biotic (diseases and pests) and abiotic (drought, nutrient deficiency, high temperature) stresses. When enough resolution is achieved, this can result in the identification of candidate genes that could further be characterized to identify relevant alleles. Breeding must also now be approached through in silico modeling to simulate plant development, investigate genotype &times; environment interactions, and introduce marker&ndash;trait linkage information in the models to better implement genomic selection. Breeders must be aware of new developments and the information must be made available to the world wheat community to develop new high-yielding varieties that can meet the challenge of higher wheat production in a sustainable and fluctuating agricultural context. In this review, we compiled all knowledge and tools produced during the BREEDWHEAT project to show how they may contribute to face this challenge in the coming years.},
DOI = {10.3390/biology11010149}
}



@Article{rs14020420,
AUTHOR = {Qi, Guanqiu and Zhang, Yuanchuan and Wang, Kunpeng and Mazur, Neal and Liu, Yang and Malaviya, Devanshi},
TITLE = {Small Object Detection Method Based on Adaptive Spatial Parallel Convolution and Fast Multi-Scale Fusion},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {420},
URL = {https://www.mdpi.com/2072-4292/14/2/420},
ISSN = {2072-4292},
ABSTRACT = {As one type of object detection, small object detection has been widely used in daily-life-related applications with many real-time requirements, such as autopilot and navigation. Although deep-learning-based object detection methods have achieved great success in recent years, they are not effective in small object detection and most of them cannot achieve real-time processing. Therefore, this paper proposes a single-stage small object detection network (SODNet) that integrates the specialized feature extraction and information fusion techniques. An adaptively spatial parallel convolution module (ASPConv) is proposed to alleviate the lack of spatial information for target objects and adaptively obtain the corresponding spatial information through multi-scale receptive fields, thereby improving the feature extraction ability. Additionally, a split-fusion sub-module (SF) is proposed to effectively reduce the time complexity of ASPConv. A fast multi-scale fusion module (FMF) is proposed to alleviate the insufficient fusion of both semantic and spatial information. FMF uses two fast upsampling operators to first unify the resolution of the multi-scale feature maps extracted by the network and then fuse them, thereby effectively improving the small object detection ability. Comparative experimental results prove that the proposed method considerably improves the accuracy of small object detection on multiple benchmark datasets and achieves a high real-time performance.},
DOI = {10.3390/rs14020420}
}



@Article{rs14020425,
AUTHOR = {Chen, Ting and Liu, Mengni and Gao, Tao and Cheng, Peng and Mei, Shaohui and Li, Yonghui},
TITLE = {A Fusion-Based Defogging Algorithm},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {425},
URL = {https://www.mdpi.com/2072-4292/14/2/425},
ISSN = {2072-4292},
ABSTRACT = {To solve the problem that traditional dark channel is not suitable for a large sky area and can easyily distort defogged images, we propose a novel fusion-based defogging algorithm. Firstly, an improved remote sensing image segmentation algorithm is introduced to mix the dark channel. Secondly, we establish a dark-light channel fusion model to calculate the atmospheric light map. Furthermore, in order to refine the transmittance image without reducing restoration quality, the grayscale image corresponding to the original image is selected as a guide image. Meanwhile, we optimize the set value of the defogging intensity parameter &omega; in the transmission estimation formula as the value of atmospheric light. Finally, a brightness/color compensation model based on visual perception is generated for image correction. Experimental results demonstrate that the proposed algorithm achieves superior performance on UAV foggy images in both subjective and objective evaluation, which verifies the effectiveness of the proposed algorithm.},
DOI = {10.3390/rs14020425}
}



@Article{rs14030433,
AUTHOR = {Wang, Jingru and Wang, Cheng and Xi, Xiaohuan and Wang, Pu and Du, Meng and Nie, Sheng},
TITLE = {Location and Extraction of Telegraph Poles from Image Matching-Based Point Clouds},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {433},
URL = {https://www.mdpi.com/2072-4292/14/3/433},
ISSN = {2072-4292},
ABSTRACT = {The monitoring of telegraph poles as essential features supporting overhead distribution network lines is the primary subject of this work. This paper proposes a method for locating and extracting telegraph poles from an image matching-based point cloud. Firstly, the point cloud of the poles is extracted using the planar grid segmentation clustering algorithm and the connected component analysis algorithm of the region grows according to the isolated features of the poles perpendicular to the ground. Secondly, the candidate telegraph poles are located based on the suspension point of the buffer, considering that the top of the pole is connected to the power suspension line. Thirdly, the horizontal projection method of the backbone area is utilized to eliminate the interference of vegetation in the buffer area. Finally, the point cloud of the telegraph pole is extracted through the density-based spatial clustering of applications with noise (DBSCAN) algorithm. The experimental results demonstrate that the average values of Recall, Precision, and F1-score in telegraph pole detection can reach 91.09%, 90.82%, and 90.90%, respectively. The average RMSE value of location deviation is 0.51m. The average value of the F1-score in the telegraph pole extraction is 91.83%, and the average extraction time of a single pole is 0.27s. Accordingly, this method has strong adaptability to areas with lush vegetation and can automatically locate and extract the telegraph pole point cloud with high accuracy, and it can still achieve very high accuracy even under the holes in the data.},
DOI = {10.3390/rs14030433}
}



@Article{buildings12020090,
AUTHOR = {Na, Seunguk and Heo, Seokjae and Han, Sehee and Shin, Yoonsoo and Roh, Youngsook},
TITLE = {Acceptance Model of Artificial Intelligence (AI)-Based Technologies in Construction Firms: Applying the Technology Acceptance Model (TAM) in Combination with the Technology&ndash;Organisation&ndash;Environment (TOE) Framework},
JOURNAL = {Buildings},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {90},
URL = {https://www.mdpi.com/2075-5309/12/2/90},
ISSN = {2075-5309},
ABSTRACT = {In the era of the Fourth Industrial Revolution, artificial intelligence (AI) is a core technology, and AI-based applications are expanding in various fields. This research explored the influencing factors on end-user&rsquo;s intentions and acceptance of AI-based technology in construction companies using the technology acceptance model (TAM) and technology&ndash;organisation&ndash;environment (TOE) framework. The analysis of end-users&rsquo; intentions for accepting AI-based technology was verified by applying the structure equation model. According to the research results, the technological factors along with external variables and an individual&rsquo;s personality had a positive influence (+) on the perceived usefulness and the perceived ease of use of end-users of AI-based technology. Conversely, environmental factors such as suggestions from others appeared to be disruptive to users&rsquo; technology acceptance. In order to effectively utilise AI-based technology, organisational factors such as the support, culture, and participation of the company as a whole were indicated as important factors for AI-based technology implementation.},
DOI = {10.3390/buildings12020090}
}



@Article{app12031047,
AUTHOR = {Aslan, Muhammet Fatih and Durdu, Akif and Sabanci, Kadir and Ropelewska, Ewa and Gültekin, Seyfettin Sinan},
TITLE = {A Comprehensive Survey of the Recent Studies with UAV for Precision Agriculture in Open Fields and Greenhouses},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {1047},
URL = {https://www.mdpi.com/2076-3417/12/3/1047},
ISSN = {2076-3417},
ABSTRACT = {The increasing world population makes it necessary to fight challenges such as climate change and to realize production efficiently and quickly. However, the minimum cost, maximum income, environmental pollution protection and the ability to save water and energy are all factors that should be taken into account in this process. The use of information and communication technologies (ICTs) in agriculture to meet all of these criteria serves the purpose of precision agriculture. As unmanned aerial vehicles (UAVs) can easily obtain real-time data, they have a great potential to address and optimize solutions to the problems faced by agriculture. Despite some limitations, such as the battery, load, weather conditions, etc., UAVs will be used frequently in agriculture in the future because of the valuable data that they obtain and their efficient applications. According to the known literature, UAVs have been carrying out tasks such as spraying, monitoring, yield estimation, weed detection, etc. In recent years, articles related to agricultural UAVs have been presented in journals with high impact factors. Most precision agriculture applications with UAVs occur in outdoor environments where GPS access is available, which provides more reliable control of the UAV in both manual and autonomous flights. On the other hand, there are almost no UAV-based applications in greenhouses where all-season crop production is available. This paper emphasizes this deficiency and provides a comprehensive review of the use of UAVs for agricultural tasks and highlights the importance of simultaneous localization and mapping (SLAM) for a UAV solution in the greenhouse.},
DOI = {10.3390/app12031047}
}



@Article{f13020153,
AUTHOR = {Krisanski, Sean and Taskhiri, Mohammad Sadegh and Montgomery, James and Turner, Paul},
TITLE = {Design and Testing of a Novel Unoccupied Aircraft System for the Collection of Forest Canopy Samples},
JOURNAL = {Forests},
VOLUME = {13},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {153},
URL = {https://www.mdpi.com/1999-4907/13/2/153},
ISSN = {1999-4907},
ABSTRACT = {Unoccupied Aircraft Systems (UAS) are beginning to replace conventional forest plot mensuration through their use as low-cost and powerful remote sensing tools for monitoring growth, estimating biomass, evaluating carbon stocks and detecting weeds; however, physical samples remain mostly collected through time-consuming, expensive and potentially dangerous conventional techniques. Such conventional techniques include the use of arborists to climb the trees to retrieve samples, shooting branches with firearms from the ground, canopy cranes or the use of pole-mounted saws to access lower branches. UAS hold much potential to improve the safety, efficiency, and reduce the cost of acquiring canopy samples. In this work, we describe and demonstrate four iterations of 3D printed canopy sampling UAS. This work includes detailed explanations of designs and how each iteration informed the design decisions in the subsequent iteration. The fourth iteration of the aircraft was tested for the collection of 30 canopy samples from three tree species: eucalyptus pulchella, eucalyptus globulus and acacia dealbata trees. The collection times ranged from 1 min and 23 s, up to 3 min and 41 s for more distant and challenging to capture samples. A vision for the next iteration of this design is also provided. Future work may explore the integration of advanced remote sensing techniques with UAS-based canopy sampling to progress towards a fully-automated and holistic forest information capture system.},
DOI = {10.3390/f13020153}
}



@Article{rs14030492,
AUTHOR = {Yang, Qichi and Wang, Lihui and Huang, Jinliang and Lu, Lijie and Li, Yang and Du, Yun and Ling, Feng},
TITLE = {Mapping Plant Diversity Based on Combined SENTINEL-1/2 Data&mdash;Opportunities for Subtropical Mountainous Forests},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {492},
URL = {https://www.mdpi.com/2072-4292/14/3/492},
ISSN = {2072-4292},
ABSTRACT = {Plant diversity is an important parameter in maintaining forest ecosystem services, functions and stability. Timely and accurate monitoring and evaluation of large-area wall-to-wall maps on plant diversity and its spatial heterogeneity are crucial for the conservation and management of forest resources. However, traditional botanical field surveys designed to estimate plant diversity are usually limited in their spatiotemporal resolutions. Using Sentinel-1 (S-1) and Sentinel-2 (S-2) data at high spatiotemporal scales, combined with and referenced to botanical field surveys, may be the best choice to provide accurate plant diversity distribution information over a large area. In this paper, we predicted and mapped plant diversity in a subtropical forest using 24 months of freely and openly available S-1 and S-2 images (10 m &times; 10 m) data over a large study area (15,290 km2). A total of 448 quadrats (10 m &times; 10 m) of forestry field surveys were captured in a subtropical evergreen-deciduous broad-leaved mixed forest to validate a machine learning algorithm. The objective was to link the fine Sentinel spectral and radar data to several ground-truthing plant diversity indices in the forests. The results showed that: (1) The Simpson and Shannon-Wiener diversity indices were the best predicted indices using random forest regression, with &#531;2 of around 0.65; (2) The use of S-1 radar data can enhance the accuracy of the predicted heterogeneity indices in the forests by approximately 0.2; (3) As for the mapping of Simpson and Shannon-Wiener, the overall accuracy was 67.4% and 64.2% respectively, while the texture diversity&rsquo;s overall accuracy was merely 56.8%; (4) From the evaluation and prediction map information, the Simpson, Shannon-Wiener and texture diversity values (and its confidence interval values) indicate spatial heterogeneity in pixel level. The large-area forest plant diversity indices maps add spatially explicit information to the ground-truthing data. Based on the results, we conclude that using the time-series of S-1 and S-2 radar and spectral characteristics, when coupled with limited ground-truthing data, can provide reasonable assessments of plant spatial heterogeneity and diversity across wide areas. It could also help promote forest ecosystem and resource conservation activities in the forestry sector.},
DOI = {10.3390/rs14030492}
}



@Article{rs14030522,
AUTHOR = {Peng, Baochai and Ren, Dong and Zheng, Cheng and Lu, Anxiang},
TITLE = {TRDet: Two-Stage Rotated Detection of Rural Buildings in Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {522},
URL = {https://www.mdpi.com/2072-4292/14/3/522},
ISSN = {2072-4292},
ABSTRACT = {Fast and accurate acquisition of the outline of rural buildings on remote sensing images is an efficient method to monitor illegal rural buildings. The traditional object detection method produces useless background information when detecting rural buildings; the semantic segmentation method cannot accurately segment the contours between buildings; the instance segmentation method cannot obtain regular building contours. The rotated object detection methods can effectively solve the problem that the traditional artificial intelligence method cannot accurately extract the outline of buildings. However, the rotated object detection methods are easy to lose location information of small objects in advanced feature maps and are sensitive to noise. To resolve these problems, this paper proposes a two-stage rotated object detection network for rural buildings (TRDet) by using a deep feature fusion network (DFF-Net) and a pixel attention module (PAM). Specifically, TRDet first fuses low-level location and high-level semantic information through the DFF-Net and then reduces the interference of noise information to the network through the PAM. The experimental results show that the mean average precession (mAP), precision, recall rate, and F1 score of the proposed TRDet are 83.57%, 91.11%, 86.5%, and 88.74%, respectively, which outperform the R2CNN model by 15%, 15.54%, 4.01%, and 9.87%. The results demonstrate that the TRDet can achieve better detection in small rural buildings and dense rural buildings.},
DOI = {10.3390/rs14030522}
}



@Article{s22030840,
AUTHOR = {Deng, Chao and Wang, Chung-Hung John and Low, Kin Huat},
TITLE = {Investigation of Using Sky Openness Ratio as Predictor for Navigation Performance in Urban-like Environment to Support PBN in UTM},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {840},
URL = {https://www.mdpi.com/1424-8220/22/3/840},
ISSN = {1424-8220},
ABSTRACT = {One of the causes of positioning inaccuracies in the Unmanned Aircraft System (UAS) is navigation error. In urban environment operations, multipaths could be the dominant contributor to navigation errors. This paper presents a study on how the operation environment affects the lateral (horizontal) navigation performance when a self-built UAS is going near different types of urban obstructions in real flight tests. Selected test sites are representative of urban environments, including open carparks, flight paths obstructed by buildings along one or both sides, changing sky access when flying towards corners formed by two buildings or dead ends, and buildings with reflective glass-clad surfaces. The data was analysed to obtain the horizontal position error between Global Positioning System (GPS) position and ground truth derived from Real Time Kinematics (RTK), with considerations for (1) horizontal position uncertainty estimate (EPH) reported by the GPS receiver, (2) no. of visible satellites, and (3) percentage of sky visible (or sky openness ratio, SOR) at various altitudes along the flight paths inside the aforementioned urban environments. The investigation showed that there is no direct correlation between the measured horizontal position error and the reported EPH; thus, the EPH could not be used for the purpose of monitoring navigation performance. The investigation further concluded that there is no universal correlation between the sky openness ratio (SOR) seen by the UAS and the resulting horizontal position error, and a more complex model would need to be considered to translate 3D urban models to expected horizontal navigation uncertainty for the UAS Traffic Management (UTM) airspace.},
DOI = {10.3390/s22030840}
}



@Article{aerospace9020056,
AUTHOR = {Perk, Baris Eren and Inalhan, Gokhan},
TITLE = {Safe Motion Planning and Learning for Unmanned Aerial Systems},
JOURNAL = {Aerospace},
VOLUME = {9},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {56},
URL = {https://www.mdpi.com/2226-4310/9/2/56},
ISSN = {2226-4310},
ABSTRACT = {To control unmanned aerial systems, we rarely have a perfect system model. Safe and aggressive planning is also challenging for nonlinear and under-actuated systems. Expert pilots, however, demonstrate maneuvers that are deemed at the edge of plane envelope. Inspired by biological systems, in this paper, we introduce a framework that leverages methods in the field of control theory and reinforcement learning to generate feasible, possibly aggressive, trajectories. For the control policies, Dynamic Movement Primitives (DMPs) imitate pilot-induced primitives, and DMPs are combined in parallel to generate trajectories to reach original or different goal points. The stability properties of DMPs and their overall systems are analyzed using contraction theory. For reinforcement learning, Policy Improvement with Path Integrals (PI2) was used for the maneuvers. The results in this paper show that PI2 updated policies are a feasible and parallel combination of different updated primitives transfer the learning in the contraction regions. Our proposed methodology can be used to imitate, reshape, and improve feasible, possibly aggressive, maneuvers. In addition, we can exploit trajectories generated by optimization methods, such as Model Predictive Control (MPC), and a library of maneuvers can be instantly generated. For application, 3-DOF (degrees of freedom) Helicopter and 2D-UAV (unmanned aerial vehicle) models are utilized to demonstrate the main results.},
DOI = {10.3390/aerospace9020056}
}




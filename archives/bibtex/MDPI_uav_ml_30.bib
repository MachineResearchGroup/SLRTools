
@Article{app11188698,
AUTHOR = {Cao, Minghe and Wang, Jianzhong and Ming, Li},
TITLE = {Multi-Templates Based Robust Tracking for Robot Person-Following Tasks},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {18},
ARTICLE-NUMBER = {8698},
URL = {https://www.mdpi.com/2076-3417/11/18/8698},
ISSN = {2076-3417},
ABSTRACT = {While the robotics techniques have not developed to full automation, robot following is common and crucial in robotic applications to reduce the need for dedicated teleoperation. To achieve this task, the target must first be robustly and consistently perceived. In this paper, a robust visual tracking approach is proposed. The approach adopts a scene analysis module (SAM) to identify the real target and similar distractors, leveraging statistical characteristics of cross-correlation responses. Positive templates are collected based on the tracking confidence constructed by the SAM, and negative templates are gathered by the recognized distractors. Based on the collected templates, response fusion is performed. As a result, the responses of the target are enhanced and the false responses are suppressed, leading to robust tracking results. The proposed approach is validated on an outdoor robot-person following dataset and a collection of public person tracking datasets. The results show that our approach achieved state-of-the-art tracking performance in terms of both the robustness and AUC score.},
DOI = {10.3390/app11188698}
}



@Article{molecules26185671,
AUTHOR = {Kim, Chang Jo and Jeong, Won Tae and Kyung, Kee Sung and Lee, Hee-Dong and Kim, Danbi and Song, Ho Sung and Kang, Younkoo and Noh, Hyun Ho},
TITLE = {Dissipation and Distribution of Picarbutrazox Residue Following Spraying with an Unmanned Aerial Vehicle on Chinese Cabbage (Brassica campestris var. pekinensis)},
JOURNAL = {Molecules},
VOLUME = {26},
YEAR = {2021},
NUMBER = {18},
ARTICLE-NUMBER = {5671},
URL = {https://www.mdpi.com/1420-3049/26/18/5671},
PubMedID = {34577141},
ISSN = {1420-3049},
ABSTRACT = {We assessed the residual distribution and temporal trend of picarbutrazox sprayed by agricultural multicopters on Chinese cabbage and considered fortification levels and flying speeds. In plot 2, 14 days after the last spraying, the residues decreased by ~91.3% compared with those in the samples on day 0. The residues in the crops decreased by ~40.8% of the initial concentration owing to growth (dilution effect) and by ~50.6% after excluding the dilution effect. As the flight speed increased, picarbutrazox residues decreased (p &lt; 0.05, least significant deviation [LSD]). At 2 m s−1 flight speed, the residual distribution differed from the dilution rate of the spraying solution. The average range of picarbutrazox residues at all sampling points was 0.007 to 0.486, below the limit of quantitation −0.395, 0.005–0.316, and 0.005–0.289 mg kg−1 in plots 1, 2, 3, and 4, respectively, showing significant differences (p &lt; 0.05, LSD). These results indicated that the residual distribution of picarbutrazox sprayed by using a multicopter on the Chinese cabbages was not uniform. However, the residues were less than the maximum residue limit in all plots. Accordingly, picarbutrazox was considered to have a low risk to human health if it was sprayed on cabbage according to the recommended spraying conditions.},
DOI = {10.3390/molecules26185671}
}



@Article{rs13183750,
AUTHOR = {Shao, Ruizhe and Du, Chun and Chen, Hao and Li, Jun},
TITLE = {SUNet: Change Detection for Heterogeneous Remote Sensing Images from Satellite and UAV Using a Dual-Channel Fully Convolution Network},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {18},
ARTICLE-NUMBER = {3750},
URL = {https://www.mdpi.com/2072-4292/13/18/3750},
ISSN = {2072-4292},
ABSTRACT = {Change Detection in heterogeneous remote sensing images plays an increasingly essential role in many real-world applications, e.g., urban growth tracking, land use monitoring, disaster evaluation and damage assessment. The objective of change detection is to identify changes of geo-graphical entities or phenomena through two or more bitemporal images. Researchers have invested a lot in the homologous change detection and yielded fruitful results. However, change detection between heterogenous remote sensing images is still a great challenge, especially for change detection of heterogenous remote sensing images obtained from satellites and Unmanned Aerial Vehicles (UAV). The main challenges in satellite-UAV change detection tasks lie in the intensive difference of color for the same ground objects, various resolutions, the parallax effect and image distortion caused by different shooting angles and platform altitudes. To address these issues, we propose a novel method based on dual-channel fully convolution network. First, in order to alleviate the influence of differences between heterogeneous images, we employ two different channels to map heterogeneous remote sensing images from satellite and UAV, respectively, to a mutual high dimension latent space for the downstream change detection task. Second, we adopt Hough method to extract the edge of ground objects as auxiliary information to help the change detection model to pay more attention to shapes and contours, instead of colors. Then, IoU-WCE loss is designed to deal with the problem of imbalanced samples in change detection task. Finally, we conduct extensive experiments to verify the proposed method using a new Satellite-UAV heterogeneous image data set, named HTCD, which is annotated by us and has been open to public. The experimental results show that our method significantly outperforms the state-of-the-art change detection methods.},
DOI = {10.3390/rs13183750}
}



@Article{s21186302,
AUTHOR = {Zhang, Xupei and He, Zhanzhuang and Ma, Zhong and Jun, Peng and Yang, Kun},
TITLE = {VIAE-Net: An End-to-End Altitude Estimation through Monocular Vision and Inertial Feature Fusion Neural Networks for UAV Autonomous Landing},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {18},
ARTICLE-NUMBER = {6302},
URL = {https://www.mdpi.com/1424-8220/21/18/6302},
PubMedID = {34577508},
ISSN = {1424-8220},
ABSTRACT = {Altitude estimation is one of the fundamental tasks of unmanned aerial vehicle (UAV) automatic navigation, where it aims to accurately and robustly estimate the relative altitude between the UAV and specific areas. However, most methods rely on auxiliary signal reception or expensive equipment, which are not always available, or applicable owing to signal interference, cost or power-consuming limitations in real application scenarios. In addition, fixed-wing UAVs have more complex kinematic models than vertical take-off and landing UAVs. Therefore, an altitude estimation method which can be robustly applied in a GPS denied environment for fixed-wing UAVs must be considered. In this paper, we present a method for high-precision altitude estimation that combines the vision information from a monocular camera and poses information from the inertial measurement unit (IMU) through a novel end-to-end deep neural network architecture. Our method has numerous advantages over existing approaches. First, we utilize the visual-inertial information and physics-based reasoning to build an ideal altitude model that provides general applicability and data efficiency for neural network learning. A further advantage is that we have designed a novel feature fusion module to simplify the tedious manual calibration and synchronization of the camera and IMU, which are required for the standard visual or visual-inertial methods to obtain the data association for altitude estimation modeling. Finally, the proposed method was evaluated, and validated using real flight data obtained during a fixed-wing UAV landing phase. The results show the average estimation error of our method is less than 3% of the actual altitude, which vastly improves the altitude estimation accuracy compared to other visual and visual-inertial based methods.},
DOI = {10.3390/s21186302}
}



@Article{en14185967,
AUTHOR = {Benbouzid, Mohamed and Berghout, Tarek and Sarma, Nur and Djurović, Siniša and Wu, Yueqi and Ma, Xiandong},
TITLE = {Intelligent Condition Monitoring of Wind Power Systems: State of the Art Review},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {18},
ARTICLE-NUMBER = {5967},
URL = {https://www.mdpi.com/1996-1073/14/18/5967},
ISSN = {1996-1073},
ABSTRACT = {Modern wind turbines operate in continuously transient conditions, with varying speed, torque, and power based on the stochastic nature of the wind resource. This variability affects not only the operational performance of the wind power system, but can also affect its integrity under service conditions. Condition monitoring continues to play an important role in achieving reliable and economic operation of wind turbines. This paper reviews the current advances in wind turbine condition monitoring, ranging from conventional condition monitoring and signal processing tools to machine-learning-based condition monitoring and usage of big data mining for predictive maintenance. A systematic review is presented of signal-based and data-driven modeling methodologies using intelligent and machine learning approaches, with the view to providing a critical evaluation of the recent developments in this area, and their applications in diagnosis, prognosis, health assessment, and predictive maintenance of wind turbines and farms.},
DOI = {10.3390/en14185967}
}



@Article{land10100995,
AUTHOR = {Emeka, Okoli Jude and Nahazanan, Haslinda and Kalantar, Bahareh and Khuzaimah, Zailani and Sani, Ojogbane Success},
TITLE = {Evaluation of the Effect of Hydroseeded Vegetation for Slope Reinforcement},
JOURNAL = {Land},
VOLUME = {10},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {995},
URL = {https://www.mdpi.com/2073-445X/10/10/995},
ISSN = {2073-445X},
ABSTRACT = {A landslide is a significant environmental hazard that results in an enormous loss of lives and properties. Studies have revealed that rainfall, soil characteristics, and human errors, such as deforestation, are the leading causes of landslides, reducing soil water infiltration and increasing the water runoff of a slope. This paper introduces vegetation establishment as a low-cost, practical measure for slope reinforcement through the ground cover and the root of the vegetation. This study reveals the level of complexity of the terrain with regards to the evaluation of high and low stability areas and has produced a landslide susceptibility map. For this purpose, 12 conditioning factors, namely slope, aspect, elevation, curvature, hill shade, stream power index (SPI), topographic wetness index (TWI), terrain roughness index (TRI), distances to roads, distance to lakes, distance to trees, and build-up, were used through the analytic hierarchy process (AHP) model to produce landslide susceptibility map. Receiver operating characteristics (ROC) was used for validation of the results. The area under the curve (AUC) values obtained from the ROC method for the AHP model was 0.865. Four seed samples, namely ryegrass, rye corn, signal grass, and couch, were hydroseeded to determine the vegetation root and ground cover’s effectiveness on stabilization and reinforcement on a high-risk susceptible 65° slope between August and December 2020. The observed monthly vegetation root of couch grass gave the most acceptable result. With a spreading and creeping vegetation ground cover characteristic, ryegrass showed the most acceptable monthly result for vegetation ground cover effectiveness. The findings suggest that the selection of couch species over other species is justified based on landslide control benefits.},
DOI = {10.3390/land10100995}
}



@Article{plants10101977,
AUTHOR = {Yee-Rendon, Arturo and Torres-Pacheco, Irineo and Trujillo-Lopez, Angelica Sarahy and Romero-Bringas, Karen Paola and Millan-Almaraz, Jesus Roberto},
TITLE = {Analysis of New RGB Vegetation Indices for PHYVV and TMV Identification in Jalapeño Pepper (Capsicum annuum) Leaves Using CNNs-Based Model},
JOURNAL = {Plants},
VOLUME = {10},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {1977},
URL = {https://www.mdpi.com/2223-7747/10/10/1977},
ISSN = {2223-7747},
ABSTRACT = {Recently, deep-learning techniques have become the foundations for many breakthroughs in the automated identification of plant diseases. In the agricultural sector, many recent visual-computer approaches use deep-learning models. In this approach, a novel predictive analytics methodology to identify Tobacco Mosaic Virus (TMV) and Pepper Huasteco Yellow Vein Virus (PHYVV) visual symptoms on Jalapeño pepper (Capsicum annuum L.) leaves by using image-processing and deep-learning classification models is presented. The proposed image-processing approach is based on the utilization of Normalized Red-Blue Vegetation Index (NRBVI) and Normalized Green-Blue Vegetation Index (NGBVI) as new RGB-based vegetation indices, and its subsequent Jet pallet colored version NRBVI-Jet NGBVI-Jet as pre-processing algorithms. Furthermore, four standard pre-trained deep-learning architectures, Visual Geometry Group-16 (VGG-16), Xception, Inception v3, and MobileNet v2, were implemented for classification purposes. The objective of this methodology was to find the most accurate combination of vegetation index pre-processing algorithms and pre-trained deep- learning classification models. Transfer learning was applied to fine tune the pre-trained deep- learning models and data augmentation was also applied to prevent the models from overfitting. The performance of the models was evaluated using Top-1 accuracy, precision, recall, and F1-score using test data. The results showed that the best model was an Xception-based model that uses the NGBVI dataset. This model reached an average Top-1 test accuracy of 98.3%. A complete analysis of the different vegetation index representations using models based on deep-learning architectures is presented along with the study of the learning curves of these deep-learning models during the training phase.},
DOI = {10.3390/plants10101977}
}



@Article{rs13193806,
AUTHOR = {Cotugno, Angela and Smith, Virginia and Baker, Tracy and Srinivasan, Raghavan},
TITLE = {A Framework for Calculating Peak Discharge and Flood Inundation in Ungauged Urban Watersheds Using Remotely Sensed Precipitation Data: A Case Study in Freetown, Sierra Leone},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3806},
URL = {https://www.mdpi.com/2072-4292/13/19/3806},
ISSN = {2072-4292},
ABSTRACT = {As the human population increases, land cover is converted from vegetation to urban development, causing increased runoff from precipitation events. Additional runoff leads to more frequent and more intense floods. In urban areas, these flood events are often catastrophic due to infrastructure built along the riverbank and within the floodplains. Sufficient data allow for flood modeling used to implement proper warning signals and evacuation plans, however, in least developed countries (LDC), the lack of field data for precipitation and river flows makes hydrologic and hydraulic modeling difficult. Within the most recent data revolution, the availability of remotely sensed data for land use/land cover (LULC), flood mapping, and precipitation estimates has increased, however, flood mapping in urban areas of LDC is still limited due to low resolution of remotely sensed data (LULC, soil properties, and terrain), cloud cover, and the lack of field data for model calibration. This study utilizes remotely sensed precipitation, LULC, soil properties, and digital elevation model data to estimate peak discharge and map simulated flood extents of urban rivers in ungauged watersheds for current and future LULC scenarios. A normalized difference vegetation index (NDVI) analysis was proposed to predict a future LULC. Additionally, return period precipitation events were calculated using the theoretical extreme value distribution approach with two remotely sensed precipitation datasets. Three calculation methods for peak discharge (curve number and lag method, curve number and graphical TR-55 method, and the rational equation) were performed and compared to a separate Soil and Water Assessment Tool (SWAT) analysis to determine the method that best represents urban rivers. HEC-RAS was then used to map the simulated flood extents from the peak discharges and ArcGIS helped to determine infrastructure and population affected by the floods. Finally, the simulated flood extents from HEC-RAS were compared to historic flood event points, images of flood events, and global surface water maximum water extent data. This analysis indicates that where field data are absent, remotely sensed monthly precipitation data from Integrated Multi-satellitE Retrievals for GPM (IMERG) where GPM is the Global Precipitation Mission can be used with the curve number and lag method to approximate peak discharges and input into HEC-RAS to represent the simulated flood extents experienced. This work contains a case study for seven urban rivers in Freetown, Sierra Leone.},
DOI = {10.3390/rs13193806}
}



@Article{s21196350,
AUTHOR = {Barber, Nastassia and Alvarado, Ernesto and Kane, Van R. and Mell, William E. and Moskal, L. Monika},
TITLE = {Estimating Fuel Moisture in Grasslands Using UAV-Mounted Infrared and Visible Light Sensors},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {6350},
URL = {https://www.mdpi.com/1424-8220/21/19/6350},
PubMedID = {34640670},
ISSN = {1424-8220},
ABSTRACT = {Predicting wildfire behavior is a complex task that has historically relied on empirical models. Physics-based fire models could improve predictions and have broad applicability, but these models require more detailed inputs, including spatially explicit estimates of fuel characteristics. One of the most critical of these characteristics is fuel moisture. Obtaining moisture measurements with traditional destructive sampling techniques can be prohibitively time-consuming and extremely limited in spatial resolution. This study seeks to assess how effectively moisture in grasses can be estimated using reflectance in six wavelengths in the visible and infrared ranges. One hundred twenty 1 m-square field samples were collected in a western Washington grassland as well as overhead imagery in six wavelengths for the same area. Predictive models of vegetation moisture using existing vegetation indices and components from principal component analysis of the wavelengths were generated and compared. The best model, a linear model based on principal components and biomass, showed modest predictive power (r² = 0.45). This model performed better for the plots with both dominant grass species pooled than it did for each species individually. The presence of this correlation, especially given the limited moisture range of this study, suggests that further research using samples across the entire fire season could potentially produce effective models for estimating moisture in this type of ecosystem using unmanned aerial vehicles, even when more than one major species of grass is present. This approach would be a fast and flexible approach compared to traditional moisture measurements.},
DOI = {10.3390/s21196350}
}



@Article{plants10101989,
AUTHOR = {Kaur, Balwinder and Sandhu, Karansher S. and Kamal, Roop and Kaur, Kawalpreet and Singh, Jagmohan and Röder, Marion S. and Muqaddasi, Quddoos H.},
TITLE = {Omics for the Improvement of Abiotic, Biotic, and Agronomic Traits in Major Cereal Crops: Applications, Challenges, and Prospects},
JOURNAL = {Plants},
VOLUME = {10},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {1989},
URL = {https://www.mdpi.com/2223-7747/10/10/1989},
ISSN = {2223-7747},
ABSTRACT = {Omics technologies, namely genomics, transcriptomics, proteomics, metabolomics, and phenomics, are becoming an integral part of virtually every commercial cereal crop breeding program, as they provide substantial dividends per unit time in both pre-breeding and breeding phases. Continuous advances in omics assure time efficiency and cost benefits to improve cereal crops. This review provides a comprehensive overview of the established omics methods in five major cereals, namely rice, sorghum, maize, barley, and bread wheat. We cover the evolution of technologies in each omics section independently and concentrate on their use to improve economically important agronomic as well as biotic and abiotic stress-related traits. Advancements in the (1) identification, mapping, and sequencing of molecular/structural variants; (2) high-density transcriptomics data to study gene expression patterns; (3) global and targeted proteome profiling to study protein structure and interaction; (4) metabolomic profiling to quantify organ-level, small-density metabolites, and their composition; and (5) high-resolution, high-throughput, image-based phenomics approaches are surveyed in this review.},
DOI = {10.3390/plants10101989}
}



@Article{math9192367,
AUTHOR = {Yañez-Badillo, Hugo and Beltran-Carbajal, Francisco and Tapia-Olvera, Ruben and Favela-Contreras, Antonio and Sotelo, Carlos and Sotelo, David},
TITLE = {Adaptive Robust Motion Control of Quadrotor Systems Using Artificial Neural Networks and Particle Swarm Optimization},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {2367},
URL = {https://www.mdpi.com/2227-7390/9/19/2367},
ISSN = {2227-7390},
ABSTRACT = {Most of the mechanical dynamic systems are subjected to parametric uncertainty, unmodeled dynamics, and undesired external vibrating disturbances while are motion controlled. In this regard, new adaptive and robust, advanced control theories have been developed to efficiently regulate the motion trajectories of these dynamic systems while dealing with several kinds of variable disturbances. In this work, a novel adaptive robust neural control design approach for efficient motion trajectory tracking control tasks for a considerably disturbed non-linear under-actuated quadrotor system is introduced. Self-adaptive disturbance signal modeling based on Taylor-series expansions to handle dynamic uncertainty is adopted. Dynamic compensators of planned motion tracking errors are then used for designing a baseline controller with adaptive capabilities provided by three layers B-spline artificial neural networks (Bs-ANN). In the presented adaptive robust control scheme, measurements of position signals are only required. Moreover, real-time accurate estimation of time-varying disturbances and time derivatives of error signals are unnecessary. Integral reconstructors of velocity error signals are properly integrated in the output error signal feedback control scheme. In addition, the appropriate combination of several mathematical tools, such as particle swarm optimization (PSO), Bézier polynomials, artificial neural networks, and Taylor-series expansions, are advantageously exploited in the proposed control design perspective. In this fashion, the present contribution introduces a new adaptive desired motion tracking control solution based on B-spline neural networks, along with dynamic tracking error compensators for quadrotor non-linear systems. Several numeric experiments were performed to assess and highlight the effectiveness of the adaptive robust motion tracking control for a quadrotor unmanned aerial vehicle while subjected to undesired vibrating disturbances. Experiments include important scenarios that commonly face the quadrotors as path and trajectory tracking, take-off and landing, variations of the quadrotor nominal mass and basic navigation. Obtained results evidence a satisfactory quadrotor motion control while acceptable attenuation levels of vibrating disturbances are exhibited.},
DOI = {10.3390/math9192367}
}



@Article{rs13193826,
AUTHOR = {Wen, Xiang and Li, Xing and Zhang, Ce and Han, Wenquan and Li, Erzhu and Liu, Wei and Zhang, Lianpeng},
TITLE = {ME-Net: A Multi-Scale Erosion Network for Crisp Building Edge Detection from Very High Resolution Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3826},
URL = {https://www.mdpi.com/2072-4292/13/19/3826},
ISSN = {2072-4292},
ABSTRACT = {The detection of building edges from very high resolution (VHR) remote sensing imagery is essential to various geo-related applications, including surveying and mapping, urban management, etc. Recently, the rapid development of deep convolutional neural networks (DCNNs) has achieved remarkable progress in edge detection; however, there has always been the problem of edge thickness due to the large receptive field of DCNNs. In this paper, we proposed a multi-scale erosion network (ME-Net) for building edge detection to crisp the building edge through two innovative approaches: (1) embedding an erosion module (EM) in the network to crisp the edge and (2) adding the Dice coefficient and local cross entropy of edge neighbors into the loss function to increase its sensitivity to the receptive field. In addition, a new metric, Ene, to measure the crispness of the predicted building edge was proposed. The experiment results show that ME-Net not only detects the clearest and crispest building edges, but also achieves the best OA of 98.75%, 95.00% and 95.51% on three building edge datasets, and exceeds other edge detection networks 3.17% and 0.44% at least in strict F1-score and Ene. In a word, the proposed ME-Net is an effective and practical approach for detecting crisp building edges from VHR remote sensing imagery.},
DOI = {10.3390/rs13193826}
}



@Article{rs13193841,
AUTHOR = {Neupane, Krishna and Baysal-Gurel, Fulya},
TITLE = {Automatic Identification and Monitoring of Plant Diseases Using Unmanned Aerial Vehicles: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3841},
URL = {https://www.mdpi.com/2072-4292/13/19/3841},
ISSN = {2072-4292},
ABSTRACT = {Disease diagnosis is one of the major tasks for increasing food production in agriculture. Although precision agriculture (PA) takes less time and provides a more precise application of agricultural activities, the detection of disease using an Unmanned Aerial System (UAS) is a challenging task. Several Unmanned Aerial Vehicles (UAVs) and sensors have been used for this purpose. The UAVs’ platforms and their peripherals have their own limitations in accurately diagnosing plant diseases. Several types of image processing software are available for vignetting and orthorectification. The training and validation of datasets are important characteristics of data analysis. Currently, different algorithms and architectures of machine learning models are used to classify and detect plant diseases. These models help in image segmentation and feature extractions to interpret results. Researchers also use the values of vegetative indices, such as Normalized Difference Vegetative Index (NDVI), Crop Water Stress Index (CWSI), etc., acquired from different multispectral and hyperspectral sensors to fit into the statistical models to deliver results. There are still various drifts in the automatic detection of plant diseases as imaging sensors are limited by their own spectral bandwidth, resolution, background noise of the image, etc. The future of crop health monitoring using UAVs should include a gimble consisting of multiple sensors, large datasets for training and validation, the development of site-specific irradiance systems, and so on. This review briefly highlights the advantages of automatic detection of plant diseases to the growers.},
DOI = {10.3390/rs13193841}
}



@Article{robotics10040110,
AUTHOR = {Dworakowski, Daniel and Thompson, Christopher and Pham-Hung, Michael and Nejat, Goldie},
TITLE = {A Robot Architecture Using ContextSLAM to Find Products in Unknown Crowded Retail Environments},
JOURNAL = {Robotics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {110},
URL = {https://www.mdpi.com/2218-6581/10/4/110},
ISSN = {2218-6581},
ABSTRACT = {Grocery shoppers must negotiate cluttered, crowded, and complex store layouts containing a vast variety of products to make their intended purchases. This complexity may prevent even experienced shoppers from finding their grocery items, consuming a lot of their time and resulting in monetary loss for the store. To address these issues, we present a generic grocery robot architecture for the autonomous search and localization of products in crowded dynamic unknown grocery store environments using a unique context Simultaneous Localization and Mapping (contextSLAM) method. The contextSLAM method uniquely creates contextually rich maps through the online fusion of optical character recognition and occupancy grid information to locate products and aid in robot localization in an environment. The novelty of our robot architecture is in its ability to intelligently use geometric and contextual information within the context map to direct robot exploration in order to localize products in unknown environments in the presence of dynamic people. Extensive experiments were conducted with a mobile robot to validate the overall architecture and contextSLAM, including in a real grocery store. The results of the experiments showed that our architecture was capable of searching for and localizing all products in various grocery lists in different unknown environments.},
DOI = {10.3390/robotics10040110}
}



@Article{rs13193856,
AUTHOR = {Chen, Xiaolong and Guan, Jian and Mu, Xiaoqian and Wang, Zhigao and Liu, Ningbo and Wang, Guoqing},
TITLE = {Multi-Dimensional Automatic Detection of Scanning Radar Images of Marine Targets Based on Radar PPInet},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3856},
URL = {https://www.mdpi.com/2072-4292/13/19/3856},
ISSN = {2072-4292},
ABSTRACT = {Traditional radar target detection algorithms are mostly based on statistical theory. They have weak generalization capabilities for complex sea clutter environments and diverse target characteristics, and their detection performance would be significantly reduced. In this paper, the range-azimuth-frame information obtained by scanning radar is converted into plain position indicator (PPI) images, and a novel Radar-PPInet is proposed and used for marine target detection. The model includes CSPDarknet53, SPP, PANet, power non-maximum suppression (P-NMS), and multi-frame fusion section. The prediction frame coordinates, target category, and corresponding confidence are directly given through the feature extraction network. The network structure strengthens the receptive field and attention distribution structure, and further improves the efficiency of network training. P-NMS can effectively improve the problem of missed detection of multi-targets. Moreover, the false alarms caused by strong sea clutter are reduced by the multi-frame fusion, which is also a benefit for weak target detection. The verification using the X-band navigation radar PPI image dataset shows that compared with the traditional cell-average constant false alarm rate detector (CA-CFAR) and the two-stage Faster R-CNN algorithm, the proposed method significantly improved the detection probability by 15% and 10% under certain false alarm probability conditions, which is more suitable for various environment and target characteristics. Moreover, the computational burden is discussed showing that the Radar-PPInet detection model is significantly lower than the Faster R-CNN in terms of parameters and calculations.},
DOI = {10.3390/rs13193856}
}



@Article{rs13193859,
AUTHOR = {Czarnecki, Joby M. Prince and Samiappan, Sathishkumar and Zhou, Meilun and McCraine, Cary Daniel and Wasson, Louis L.},
TITLE = {Real-Time Automated Classification of Sky Conditions Using Deep Learning and Edge Computing},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3859},
URL = {https://www.mdpi.com/2072-4292/13/19/3859},
ISSN = {2072-4292},
ABSTRACT = {The radiometric quality of remotely sensed imagery is crucial for precision agriculture applications because estimations of plant health rely on the underlying quality. Sky conditions, and specifically shadowing from clouds, are critical determinants in the quality of images that can be obtained from low-altitude sensing platforms. In this work, we first compare common deep learning approaches to classify sky conditions with regard to cloud shadows in agricultural fields using a visible spectrum camera. We then develop an artificial-intelligence-based edge computing system to fully automate the classification process. Training data consisting of 100 oblique angle images of the sky were provided to a convolutional neural network and two deep residual neural networks (ResNet18 and ResNet34) to facilitate learning two classes, namely (1) good image quality expected, and (2) degraded image quality expected. The expectation of quality stemmed from the sky condition (i.e., density, coverage, and thickness of clouds) present at the time of the image capture. These networks were tested using a set of 13,000 images. Our results demonstrated that ResNet18 and ResNet34 classifiers produced better classification accuracy when compared to a convolutional neural network classifier. The best overall accuracy was obtained by ResNet34, which was 92% accurate, with a Kappa statistic of 0.77. These results demonstrate a low-cost solution to quality control for future autonomous farming systems that will operate without human intervention and supervision.},
DOI = {10.3390/rs13193859}
}



@Article{app11198996,
AUTHOR = {Cao, Yuwei and Scaioni, Marco},
TITLE = {3DLEB-Net: Label-Efficient Deep Learning-Based Semantic Segmentation of Building Point Clouds at LoD3 Level},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {8996},
URL = {https://www.mdpi.com/2076-3417/11/19/8996},
ISSN = {2076-3417},
ABSTRACT = {In current research, fully supervised Deep Learning (DL) techniques are employed to train a segmentation network to be applied to point clouds of buildings. However, training such networks requires large amounts of fine-labeled buildings’ point-cloud data, presenting a major challenge in practice because they are difficult to obtain. Consequently, the application of fully supervised DL for semantic segmentation of buildings’ point clouds at LoD3 level is severely limited. In order to reduce the number of required annotated labels, we proposed a novel label-efficient DL network that obtains per-point semantic labels of LoD3 buildings’ point clouds with limited supervision, named 3DLEB-Net. In general, it consists of two steps. The first step (Autoencoder, AE) is composed of a Dynamic Graph Convolutional Neural Network (DGCNN) encoder and a folding-based decoder. It is designed to extract discriminative global and local features from input point clouds by faithfully reconstructing them without any label. The second step is the semantic segmentation network. By supplying a small amount of task-specific supervision, a segmentation network is proposed for semantically segmenting the encoded features acquired from the pre-trained AE. Experimentally, we evaluated our approach based on the Architectural Cultural Heritage (ArCH) dataset. Compared to the fully supervised DL methods, we found that our model achieved state-of-the-art results on the unseen scenes, with only 10% of labeled training data from fully supervised methods as input. Moreover, we conducted a series of ablation studies to show the effectiveness of the design choices of our model.},
DOI = {10.3390/app11198996}
}



@Article{met11101537,
AUTHOR = {Sharma, Vinamra Bhushan and Tewari, Saurabh and Biswas, Susham and Lohani, Bharat and Dwivedi, Umakant Dhar and Dwivedi, Deepak and Sharma, Ashutosh and Jung, Jae Pil},
TITLE = {Recent Advancements in AI-Enabled Smart Electronics Packaging for Structural Health Monitoring},
JOURNAL = {Metals},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {1537},
URL = {https://www.mdpi.com/2075-4701/11/10/1537},
ISSN = {2075-4701},
ABSTRACT = {Real-time health monitoring of civil infrastructures is performed to maintain their structural integrity, sustainability, and serviceability for a longer time. With smart electronics and packaging technology, large amounts of complex monitoring data are generated, requiring sophisticated artificial intelligence (AI) techniques for their processing. With the advancement of technology, more complex AI models have been applied, from simple models to sophisticated deep learning (DL) models, for structural health monitoring (SHM). In this article, a comprehensive review is performed, primarily on the applications of AI models for SHM to maintain the sustainability of diverse civil infrastructures. Three smart data capturing methods of SHM, namely, camera-based, smartphone-based, and unmanned aerial vehicle (UAV)-based methods, are also discussed, having made the utilization of intelligent paradigms easier. UAV is found to be the most promising smart data acquisition technology, whereas convolution neural networks are the most impressive DL model reported for SHM. Furthermore, current challenges and future perspectives of AI-based SHM systems are also described separately. Moreover, the Internet of Things (IoT) and smart city concepts are explained to elaborate on the contributions of intelligent SHM systems. The integration of SHM with IoT and cloud-based computing is leading us towards the evolution of future smart cities.},
DOI = {10.3390/met11101537}
}



@Article{rs13193874,
AUTHOR = {Ma, Xu and Lu, Lei and Ding, Jianli and Zhang, Fei and He, Baozhong},
TITLE = {Estimating Fractional Vegetation Cover of Row Crops from High Spatial Resolution Image},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3874},
URL = {https://www.mdpi.com/2072-4292/13/19/3874},
ISSN = {2072-4292},
ABSTRACT = {With high spatial resolution remote sensing images being increasingly used in precision agriculture, more details of the row structure of row crops are captured in the corresponding images. This phenomenon is a challenge for the estimation of the fractional vegetation cover (FVC) of row crops. Previous studies have found that there is an overestimation of FVC for the early growth stage of vegetation in the current algorithms. When the row crops are a form in the early stage of vegetation, their FVC may also have overestimation. Therefore, developing an algorithm to address this problem is necessary. This study used World-View 3 images as data sources and attempted to use the canopy reflectance model of row crops, coupling backward propagation neural networks (BPNNs) to estimate the FVC of row crops. Compared to the prevailing algorithms, i.e., empirical method, spectral mixture analysis, and continuous crop model coupling BPNNs, the results showed that the calculated accuracy of the canopy reflectance model of row crops coupling with BPNNs is the highest performing (RMSE = 0.0305). Moreover, when the structure is obvious, we found that the FVC of row crops was about 0.5–0.6, and the relationship between estimated FVC of row crops and NDVI presented a strong exponential relationship. The results reinforced the conclusion that the canopy reflectance model of row crops coupled with BPNNs is more suitable for estimating the FVC of row crops in high-resolution images.},
DOI = {10.3390/rs13193874}
}



@Article{rs13193878,
AUTHOR = {Montgomery, Joshua and Mahoney, Craig and Brisco, Brian and Boychuk, Lyle and Cobbaert, Danielle and Hopkinson, Chris},
TITLE = {Remote Sensing of Wetlands in the Prairie Pothole Region of North America},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3878},
URL = {https://www.mdpi.com/2072-4292/13/19/3878},
ISSN = {2072-4292},
ABSTRACT = {The Prairie Pothole Region (PPR) of North America is an extremely important habitat for a diverse range of wetland ecosystems that provide a wealth of socio-economic value. This paper describes the ecological characteristics and importance of PPR wetlands and the use of remote sensing for mapping and monitoring applications. While there are comprehensive reviews for wetland remote sensing in recent publications, there is no comprehensive review about the use of remote sensing in the PPR. First, the PPR is described, including the wetland classification systems that have been used, the water regimes that control the surface water and water levels, and the soil and vegetation characteristics of the region. The tools and techniques that have been used in the PPR for analyses of geospatial data for wetland applications are described. Field observations for ground truth data are critical for good validation and accuracy assessment of the many products that are produced. Wetland classification approaches are reviewed, including Decision Trees, Machine Learning, and object versus pixel-based approaches. A comprehensive description of the remote sensing systems and data that have been employed by various studies in the PPR is provided. A wide range of data can be used for various applications, including passive optical data like aerial photographs or satellite-based, Earth-observation data. Both airborne and spaceborne lidar studies are described. A detailed description of Synthetic Aperture RADAR (SAR) data and research are provided. The state of the art is the use of multi-source data to achieve higher accuracies and hybrid approaches. Digital Surface Models are also being incorporated in geospatial analyses to separate forest and shrub and emergent systems based on vegetation height. Remote sensing provides a cost-effective mechanism for mapping and monitoring PPR wetlands, especially with the logistical difficulties and cost of field-based methods. The wetland characteristics of the PPR dictate the need for high resolution in both time and space, which is increasingly possible with the numerous and increasing remote sensing systems available and the trend to open-source data and tools. The fusion of multi-source remote sensing data via state-of-the-art machine learning is recommended for wetland applications in the PPR. The use of such data promotes flexibility for sensor addition, subtraction, or substitution as a function of application needs and potential cost restrictions. This is important in the PPR because of the challenges related to the highly dynamic nature of this unique region.},
DOI = {10.3390/rs13193878}
}



@Article{bdcc5040050,
AUTHOR = {Gouiaa, Rafik and Akhloufi, Moulay A. and Shahbazi, Mozhdeh},
TITLE = {Advances in Convolution Neural Networks Based Crowd Counting and Density Estimation},
JOURNAL = {Big Data and Cognitive Computing},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {50},
URL = {https://www.mdpi.com/2504-2289/5/4/50},
ISSN = {2504-2289},
ABSTRACT = {Automatically estimating the number of people in unconstrained scenes is a crucial yet challenging task in different real-world applications, including video surveillance, public safety, urban planning, and traffic monitoring. In addition, methods developed to estimate the number of people can be adapted and applied to related tasks in various fields, such as plant counting, vehicle counting, and cell microscopy. Many challenges and problems face crowd counting, including cluttered scenes, extreme occlusions, scale variation, and changes in camera perspective. Therefore, in the past few years, tremendous research efforts have been devoted to crowd counting, and numerous excellent techniques have been proposed. The significant progress in crowd counting methods in recent years is mostly attributed to advances in deep convolution neural networks (CNNs) as well as to public crowd counting datasets. In this work, we review the papers that have been published in the last decade and provide a comprehensive survey of the recent CNNs based crowd counting techniques. We briefly review detection-based, regression-based, and traditional density estimation based approaches. Then, we delve into detail regarding the deep learning based density estimation approaches and recently published datasets. In addition, we discuss the potential applications of crowd counting and in particular its applications using unmanned aerial vehicle (UAV) images.},
DOI = {10.3390/bdcc5040050}
}



@Article{rs13193892,
AUTHOR = {Zhang, Tianxiang and Xu, Zhiyong and Su, Jinya and Yang, Zhifang and Liu, Cunjia and Chen, Wen-Hua and Li, Jiangyun},
TITLE = {Ir-UNet: Irregular Segmentation U-Shape Network for Wheat Yellow Rust Detection by UAV Multispectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3892},
URL = {https://www.mdpi.com/2072-4292/13/19/3892},
ISSN = {2072-4292},
ABSTRACT = {Crop disease is widely considered as one of the most pressing challenges for food crops, and therefore an accurate crop disease detection algorithm is highly desirable for its sustainable management. The recent use of remote sensing and deep learning is drawing increasing research interests in wheat yellow rust disease detection. However, current solutions on yellow rust detection are generally addressed by RGB images and the basic semantic segmentation algorithms (e.g., UNet), which do not consider the irregular and blurred boundary problems of yellow rust area therein, restricting the disease segmentation performance. Therefore, this work aims to develop an automatic yellow rust disease detection algorithm to cope with these boundary problems. An improved algorithm entitled Ir-UNet by embedding irregular encoder module (IEM), irregular decoder module (IDM) and content-aware channel re-weight module (CCRM) is proposed and compared against the basic UNet while with various input features. The recently collected dataset by DJI M100 UAV equipped with RedEdge multispectral camera is used to evaluate the algorithm performance. Comparative results show that the Ir-UNet with five raw bands outperforms the basic UNet, achieving the highest overall accuracy (OA) score (97.13%) among various inputs. Moreover, the use of three selected bands, Red-NIR-RE, in the proposed Ir-UNet can obtain a comparable result (OA: 96.83%) while with fewer spectral bands and less computation load. It is anticipated that this study by seamlessly integrating the Ir-UNet network and UAV multispectral images can pave the way for automated yellow rust detection at farmland scales.},
DOI = {10.3390/rs13193892}
}



@Article{drones5040106,
AUTHOR = {Nooralishahi, Parham and Ibarra-Castanedo, Clemente and Deane, Shakeb and López, Fernando and Pant, Shashank and Genest, Marc and Avdelidis, Nicolas P. and Maldague, Xavier P. V.},
TITLE = {Drone-Based Non-Destructive Inspection of Industrial Sites: A Review and Case Studies},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {106},
URL = {https://www.mdpi.com/2504-446X/5/4/106},
ISSN = {2504-446X},
ABSTRACT = {Using aerial platforms for Non-Destructive Inspection (NDI) of large and complex structures is a growing field of interest in various industries. Infrastructures such as: buildings, bridges, oil and gas, etc. refineries require regular and extensive inspections. The inspection reports are used to plan and perform required maintenance, ensuring their structural health and the safety of the workers. However, performing these inspections can be challenging due to the size of the facility, the lack of easy access, the health risks for the inspectors, or several other reasons, which has convinced companies to invest more in drones as an alternative solution to overcome these challenges. The autonomous nature of drones can assist companies in reducing inspection time and cost. Moreover, the employment of drones can lower the number of required personnel for inspection and can increase personnel safety. Finally, drones can provide a safe and reliable solution for inspecting hard-to-reach or hazardous areas. Despite the recent developments in drone-based NDI to reliably detect defects, several limitations and challenges still need to be addressed. In this paper, a brief review of the history of unmanned aerial vehicles, along with a comprehensive review of studies focused on UAV-based NDI of industrial and commercial facilities, are provided. Moreover, the benefits of using drones in inspections as an alternative to conventional methods are discussed, along with the challenges and open problems of employing drones in industrial inspections, are explored. Finally, some of our case studies conducted in different industrial fields in the field of Non-Destructive Inspection are presented.},
DOI = {10.3390/drones5040106}
}



@Article{land10101022,
AUTHOR = {Ma, Weidong and Jia, Wei and Su, Peng and Feng, Xingyun and Liu, Fenggui and Wang, Jing’ai},
TITLE = {Mapping Highland Barley on the Qinghai–Tibet Combing Landsat OLI Data and Object-Oriented Classification Method},
JOURNAL = {Land},
VOLUME = {10},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {1022},
URL = {https://www.mdpi.com/2073-445X/10/10/1022},
ISSN = {2073-445X},
ABSTRACT = {In this paper, we use the extraction method of multi-factors fusion to extract the Highland barley cultivation area on Qinghai–Tibet Plateau. The study results indicate that: (1) the method (extracting through multi-factors fusion) is efficient during the extracting process and is highly accurate in extraction results. This extraction scheme allows for not only the spatial heterogeneity of different physical geographic units, but also the impact of multi-factors on crop cultivation; (2) according to our research, the total Highland barley cultivation area on Qinghai–Tibet Plateau is about 2.74 × 105 ha. Based on the statistics, we draw the first distribution map of the Highland barley cultivation area on Qinghai–Tibet Plateau, which upgrades its spatial distribution pattern from administrative unit to patch unit; (3) Highland barley in various divisions has a distinct spatial heterogeneity in elevation. On the whole, the Highland barley on the plateau is planted at an elevation of 2500–4500 m, up to 5200 m. Due to the impact of topography diversity, temperature, moisture, light, arable land and irrigation conditions, its cultivation area at the same elevation varies in different divisions.},
DOI = {10.3390/land10101022}
}



@Article{act10100255,
AUTHOR = {Xia, Shuang and Zhang, Xiangyin},
TITLE = {Constrained Path Planning for Unmanned Aerial Vehicle in 3D Terrain Using Modified Multi-Objective Particle Swarm Optimization},
JOURNAL = {Actuators},
VOLUME = {10},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {255},
URL = {https://www.mdpi.com/2076-0825/10/10/255},
ISSN = {2076-0825},
ABSTRACT = {This paper considered the constrained unmanned aerial vehicle (UAV) path planning problem as the multi-objective optimization problem, in which both costs and constraints are treated as the objective functions. A novel multi-objective particle swarm optimization algorithm based on the Gaussian distribution and the Q-Learning technique (GMOPSO-QL) is proposed and applied to determine the feasible and optimal path for UAV. In GMOPSO-QL, the Gaussian distribution based updating operator is adopted to generate new particles, and the exploration and exploitation modes are introduced to enhance population diversity and convergence speed, respectively. Moreover, the Q-Learning based mode selection logic is introduced to balance the global search with the local search in the evolution process. Simulation results indicate that our proposed GMOPSO-QL can deal with the constrained UAV path planning problem and is superior to existing optimization algorithms in terms of efficiency and robustness.},
DOI = {10.3390/act10100255}
}



@Article{s21196520,
AUTHOR = {Novkovic, Ivan and Markovic, Goran B. and Lukic, Djordje and Dragicevic, Slavoljub and Milosevic, Marko and Djurdjic, Snezana and Samardzic, Ivan and Lezaic, Tijana and Tadic, Marija},
TITLE = {GIS-Based Forest Fire Susceptibility Zonation with IoT Sensor Network Support, Case Study—Nature Park Golija, Serbia},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {6520},
URL = {https://www.mdpi.com/1424-8220/21/19/6520},
PubMedID = {34640837},
ISSN = {1424-8220},
ABSTRACT = {The territory of the Republic of Serbia is vulnerable to various natural disasters, among which forest fires stand out. In relation with climate changes, the number of forest fires in Serbia has been increasing from year to year. Protected natural areas are especially endangered by wildfires. For Nature Park Golija, as the second largest in Serbia, with an area of 75,183 ha, and with MaB Reserve Golija-Studenica on part of its territory (53,804 ha), more attention should be paid in terms of forest fire mitigation. GIS and multi-criteria decision analysis are indispensable when it comes to spatial analysis for the purpose of natural disaster risk management. Index-based and fuzzy AHP methods were used, together with TOPSIS method for forest fire susceptibility zonation. Very high and high forest fire susceptibility zone were recorded on 26.85% (Forest Fire Susceptibility Index) and 25.75% (fuzzy AHP). The additional support for forest fire prevention is realized through an additional Internet of Thing (IoT)-based sensor network that enables the continuous collection of local meteorological and environmental data, which enables low-cost and reliable real-time fire risk assessment and detection and the improved long-term and short-term forest fire susceptibility assessment. Obtained results can be applied for adequate forest fire risk management, improvement of the monitoring, and early warning systems in the Republic of Serbia, but are also important for relevant authorities at national, regional, and local level, which will be able to coordinate and intervene in a case of emergency events.},
DOI = {10.3390/s21196520}
}



@Article{rs13193898,
AUTHOR = {Cao, Duanguang and Xing, Hanfa and Wong, Man Sing and Kwan, Mei-Po and Xing, Huaqiao and Meng, Yuan},
TITLE = {A Stacking Ensemble Deep Learning Model for Building Extraction from Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3898},
URL = {https://www.mdpi.com/2072-4292/13/19/3898},
ISSN = {2072-4292},
ABSTRACT = {Automatically extracting buildings from remote sensing images with deep learning is of great significance to urban planning, disaster prevention, change detection, and other applications. Various deep learning models have been proposed to extract building information, showing both strengths and weaknesses in capturing the complex spectral and spatial characteristics of buildings in remote sensing images. To integrate the strengths of individual models and obtain fine-scale spatial and spectral building information, this study proposed a stacking ensemble deep learning model. First, an optimization method for the prediction results of the basic model is proposed based on fully connected conditional random fields (CRFs). On this basis, a stacking ensemble model (SENet) based on a sparse autoencoder integrating U-NET, SegNet, and FCN-8s models is proposed to combine the features of the optimized basic model prediction results. Utilizing several cities in Hebei Province, China as a case study, a building dataset containing attribute labels is established to assess the performance of the proposed model. The proposed SENet is compared with three individual models (U-NET, SegNet and FCN-8s), and the results show that the accuracy of SENet is 0.954, approximately 6.7%, 6.1%, and 9.8% higher than U-NET, SegNet, and FCN-8s models, respectively. The identification of building features, including colors, sizes, shapes, and shadows, is also evaluated, showing that the accuracy, recall, F1 score, and intersection over union (IoU) of the SENet model are higher than those of the three individual models. This suggests that the proposed ensemble model can effectively depict the different features of buildings and provides an alternative approach to building extraction with higher accuracy.},
DOI = {10.3390/rs13193898}
}



@Article{jlpea11040039,
AUTHOR = {Saddik, Amine and Latif, Rachid and El Ouardi, Abdelhafid},
TITLE = {Low-Power FPGA Architecture Based Monitoring Applications in Precision Agriculture},
JOURNAL = {Journal of Low Power Electronics and Applications},
VOLUME = {11},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {39},
URL = {https://www.mdpi.com/2079-9268/11/4/39},
ISSN = {2079-9268},
ABSTRACT = {Today’s on-chip systems technology has grounded impressive advances in computing power and energy consumption. The choice of the right architecture depends on the application. In our case, we were studying vegetation monitoring algorithms in precision agriculture. This study presents a system based on a monitoring algorithm for agricultural fields, an electronic architecture based on a CPU-FPGA SoC system and the OpenCL parallel programming paradigm. We focused our study on our own dataset of agricultural fields to validate the results. The fields studied in our case are in the Guelmin-Oued noun region in the south of Morocco. These fields are divided into two areas, with a total surface of 3.44 Ha2 for the first field and 3.73 Ha2 for the second. The images were collected using a DJI-type unmanned aerial vehicle and an RGB camera. Performance evaluation showed that the system could process up to 86 fps versus 12 fps or 20 fps in C/C++ and OpenMP implementations, respectively. Software optimizations have increased the performance to 107 fps, which meets real-time constraints.},
DOI = {10.3390/jlpea11040039}
}



@Article{rs13193913,
AUTHOR = {Zawadzka, Joanna and Truckell, Ian and Khouakhi, Abdou and Rivas Casado, Mónica},
TITLE = {Detection of Flood Damage in Urban Residential Areas Using Object-Oriented UAV Image Analysis Coupled with Tree-Based Classifiers},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3913},
URL = {https://www.mdpi.com/2072-4292/13/19/3913},
ISSN = {2072-4292},
ABSTRACT = {Timely clearing-up interventions are essential for effective recovery of flood-damaged housing, however, time-consuming door-to-door inspections for insurance purposes need to take place before major repairs can be done to adequately assess the losses caused by flooding. With the increased probability of flooding, there is a heightened need for rapid flood damage assessment methods. High resolution imagery captured by unmanned aerial vehicles (UAVs) offers an opportunity for accelerating the time needed for inspections, either through visual interpretation or automated image classification. In this study, object-oriented image segmentation coupled with tree-based classifiers was implemented on a 10 cm resolution RGB orthoimage, captured over the English town of Cockermouth a week after a flood triggered by storm Desmond, to automatically detect debris associated with damages predominantly to residential housing. Random forests algorithm achieved a good level of overall accuracy of 74%, with debris being correctly classified at the rate of 58%, and performing well for small debris (67%) and skips (64%). The method was successful at depicting brightly-colored debris, however, was prone to misclassifications with brightly-colored vehicles. Consequently, in the current stage, the methodology could be used to facilitate visual interpretation of UAV images. Methods to improve accuracy have been identified and discussed.},
DOI = {10.3390/rs13193913}
}



@Article{jne2040029,
AUTHOR = {Proctor, Philippe and Teuscher, Christof and Hecht, Adam and Osiński, Marek},
TITLE = {Proximal Policy Optimization for Radiation Source Search},
JOURNAL = {Journal of Nuclear Engineering},
VOLUME = {2},
YEAR = {2021},
NUMBER = {4},
PAGES = {368--397},
URL = {https://www.mdpi.com/2673-4362/2/4/29},
ISSN = {2673-4362},
ABSTRACT = {Rapid search and localization for nuclear sources can be an important aspect in preventing human harm from illicit material in dirty bombs or from contamination. In the case of a single mobile radiation detector, there are numerous challenges to overcome such as weak source intensity, multiple sources, background radiation, and the presence of obstructions, i.e., a non-convex environment. In this work, we investigate the sequential decision making capability of deep reinforcement learning in the nuclear source search context. A novel neural network architecture (RAD-A2C) based on the advantage actor critic (A2C) framework and a particle filter gated recurrent unit for localization is proposed. Performance is studied in a randomized 20×20 m convex and non-convex simulation environment across a range of signal-to-noise ratio (SNR)s for a single detector and single source. RAD-A2C performance is compared to both an information-driven controller that uses a bootstrap particle filter and to a gradient search (GS) algorithm. We find that the RAD-A2C has comparable performance to the information-driven controller across SNR in a convex environment. The RAD-A2C far outperforms the GS algorithm in the non-convex environment with greater than 95% median completion rate for up to seven obstructions.},
DOI = {10.3390/jne2040029}
}



@Article{rs13193928,
AUTHOR = {Lu, Qikai and Si, Wei and Wei, Lifei and Li, Zhongqiang and Xia, Zhihong and Ye, Song and Xia, Yu},
TITLE = {Retrieval of Water Quality from UAV-Borne Hyperspectral Imagery: A Comparative Study of Machine Learning Algorithms},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3928},
URL = {https://www.mdpi.com/2072-4292/13/19/3928},
ISSN = {2072-4292},
ABSTRACT = {The rapidly increasing world population and human activities accelerate the crisis of the limited freshwater resources. Water quality must be monitored for the sustainability of freshwater resources. Unmanned aerial vehicle (UAV)-borne hyperspectral data can capture fine features of water bodies, which have been widely used for monitoring water quality. In this study, nine machine learning algorithms are systematically evaluated for the inversion of water quality parameters including chlorophyll-a (Chl-a) and suspended solids (SS) with UAV-borne hyperspectral data. In comparing the experimental results of the machine learning model on the water quality parameters, we can observe that the prediction performance of the Catboost regression (CBR) model is the best. However, the prediction performances of the Multi-layer Perceptron regression (MLPR) and Elastic net (EN) models are very unsatisfactory, indicating that the MLPR and EN models are not suitable for the inversion of water quality parameters. In addition, the water quality distribution map is generated, which can be used to identify polluted areas of water bodies.},
DOI = {10.3390/rs13193928}
}



@Article{buildings11100450,
AUTHOR = {Nepal, Madhav Prasad and Hon, Carol and Lee, Jinwoo (Brian) and Xiang, Ziru},
TITLE = {Towards an Integrated Approach to Infrastructure Damage Assessment in the Aftermath of Natural Hazards},
JOURNAL = {Buildings},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {450},
URL = {https://www.mdpi.com/2075-5309/11/10/450},
ISSN = {2075-5309},
ABSTRACT = {The world has witnessed an alarmingly increasing number of serious natural hazards. In the aftermath of a hazard, relevant authorities/agencies face, among others, the challenging tasks of rapidly evaluating and assessing the damages to infrastructures and restoring their essential functionality and operation. The availability of reliable, high-quality structural and operational/maintenance data of a structure and its health, before and after a natural hazard, can be instrumental in the rapid assessment of a damaged structure. We collectively refer, in this paper, to the existing as-built and facility operational information about a structure or an infrastructure asset represented respectively in Building Information Modeling (BIM) and Infrastructure Asset Management (IAM) systems as Product Lifecycle Data (PLD). Arguably, PLD combined with other post-hazard condition assessment data can provide a more reliable and integrated solution for a rapid damage assessment of buildings and other critical infrastructures. Unfortunately, the application of PLD in this critical area has been unexplored in the literature, and the mapping between PLD and damage assessment methods is loosely investigated. In an effort to address this research gap, this paper provides a critical analysis of the most common structural damage assessment methods and explores the potential of combining them with PLD to provide more reliable, comprehensive, and integrated solution for damage assessment. Findings from this study could be useful for practitioners in selecting the most appropriate and effective methods to conduct damage and safety assessments of critical infrastructures. The study will also assist the further theoretical developments in the integration of PLD with different damage assessment methods.},
DOI = {10.3390/buildings11100450}
}



@Article{app11199173,
AUTHOR = {Rodriguez-Conde, Ivan and Campos, Celso and Fdez-Riverola, Florentino},
TITLE = {On-Device Object Detection for More Efficient and Privacy-Compliant Visual Perception in Context-Aware Systems},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {9173},
URL = {https://www.mdpi.com/2076-3417/11/19/9173},
ISSN = {2076-3417},
ABSTRACT = {Ambient Intelligence (AmI) encompasses technological infrastructures capable of sensing data from environments and extracting high-level knowledge to detect or recognize users’ features and actions, as well as entities or events in their surroundings. Visual perception, particularly object detection, has become one of the most relevant enabling factors for this context-aware user-centered intelligence, being the cornerstone of relevant but complex tasks, such as object tracking or human action recognition. In this context, convolutional neural networks have proven to achieve state-of-the-art accuracy levels. However, they typically result in large and highly complex models that typically demand computation offloading onto remote cloud platforms. Such an approach has security- and latency-related limitations and may not be appropriate for some AmI use cases where the system response time must be as short as possible, and data privacy must be guaranteed. In the last few years, the on-device paradigm has emerged in response to those limitations, yielding more compact and efficient neural networks able to address inference directly on client machines, thus providing users with a smoother and better-tailored experience, with no need of sharing their data with an outsourced service. Framed in that novel paradigm, this work presents a review of the recent advances made along those lines in object detection, providing a comprehensive study of the most relevant lightweight CNN-based detection frameworks, discussing the most paradigmatic AmI domains where such an approach has been successfully applied, the different challenges arisen, the key strategies and techniques adopted to create visual solutions for image-based object classification and localization, as well as the most relevant factors to bear in mind when assessing or comparing those techniques, such as the evaluation metrics or the hardware setups used.},
DOI = {10.3390/app11199173}
}



@Article{rs13193948,
AUTHOR = {Sunoj, S. and Cho, Jason and Guinness, Joe and van Aardt, Jan and Czymmek, Karl J. and Ketterings, Quirine M.},
TITLE = {Corn Grain Yield Prediction and Mapping from Unmanned Aerial System (UAS) Multispectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3948},
URL = {https://www.mdpi.com/2072-4292/13/19/3948},
ISSN = {2072-4292},
ABSTRACT = {Harvester-mounted yield monitor sensors are expensive and require calibration and data cleaning. Therefore, we evaluated six vegetation indices (VI) from unmanned aerial system (Quantix™ Mapper) imagery for corn (Zea mays L.) yield prediction. A field trial was conducted with N sidedress treatments applied at four growth stages (V4, V6, V8, or V10) compared against zero-N and N-rich controls. Normalized difference vegetation index (NDVI) and enhanced vegetation index 2 (EVI2), based on flights at R4, resulted in the most accurate yield estimations, as long as sidedressing was performed before V6. Yield estimations based on earlier flights were less accurate. Estimations were most accurate when imagery from both N-rich and zero-N control plots were included, but elimination of the zero-N data only slightly reduced the accuracy. Use of a ratio approach (VITrt/VIN-rich and YieldTrt/YieldN-rich) enables the extension of findings across fields and only slightly reduced the model performance. Finally, a smaller plot size (9 or 75 m2 compared to 150 m2) resulted in a slightly reduced model performance. We concluded that accurate yield estimates can be obtained using NDVI and EVI2, as long as there is an N-rich strip in the field, sidedressing is performed prior to V6, and sensing takes place at R3 or R4.},
DOI = {10.3390/rs13193948}
}



@Article{app11199199,
AUTHOR = {Andrushia, A. Diana and Sagayam, K. Martin and Dang, Hien and Pomplun, Marc and Quach, Lien},
TITLE = {Visual-Saliency-Based Abnormality Detection for MRI Brain Images—Alzheimer’s Disease Analysis},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {9199},
URL = {https://www.mdpi.com/2076-3417/11/19/9199},
ISSN = {2076-3417},
ABSTRACT = {In recent years, medical image analysis has played a vital role in detecting diseases in their early stages. Medical images are rapidly becoming available for various applications to solve human problems. Therefore, complex medical features are needed to develop a diagnostic system for physicians to provide better treatment. Traditional methods of abnormality detection suffer from misidentification of abnormal regions in the given data. Visual-saliency detection methods are used to locate abnormalities to improve the accuracy of the proposed work. This study explores the role of a visual saliency map in the classification of Alzheimer’s disease (AD). Bottom-up saliency corresponds to image features, whereas top-down saliency uses domain knowledge in magnetic resonance imaging (MRI) brain images. The novelty of the proposed method lies in the use of an elliptical local binary pattern descriptor for low-level MRI characterization. Ellipse-like topologies help to obtain feature information from different orientations. Extensively directional features at different orientations cover the micro patterns. The brain regions of the Alzheimer’s disease stages were classified from the saliency maps. Multiple-kernel learning (MKL) and simple and efficient MKL (SEMKL) were used to classify Alzheimer’s disease from normal controls. The proposed method used the OASIS dataset and experimental results were compared with eight state-of-the-art methods. The proposed visual saliency-based abnormality detection produces reliable results in terms of accuracy, sensitivity, specificity, and f-measure.},
DOI = {10.3390/app11199199}
}



@Article{en14196316,
AUTHOR = {Berghout, Tarek and Benbouzid, Mohamed and Bentrcia, Toufik and Ma, Xiandong and Djurović, Siniša and Mouss, Leïla-Hayet},
TITLE = {Machine Learning-Based Condition Monitoring for PV Systems: State of the Art and Future Prospects},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {6316},
URL = {https://www.mdpi.com/1996-1073/14/19/6316},
ISSN = {1996-1073},
ABSTRACT = {To ensure the continuity of electric power generation for photovoltaic systems, condition monitoring frameworks are subject to major enhancements. The continuous uniform delivery of electric power depends entirely on a well-designed condition maintenance program. A just-in-time task to deal with several naturally occurring faults can be correctly undertaken via the cooperation of effective detection, diagnosis, and prognostic analyses. Therefore, the present review first outlines different failure modes to which all photovoltaic systems are subjected, in addition to the essential integrated detection methods and technologies. Then, data-driven paradigms, and their contribution to solving this prediction problem, are also explored. Accordingly, this review primarily investigates the different learning architectures used (i.e., ordinary, hybrid, and ensemble) in relation to their learning frameworks (i.e., traditional and deep learning). It also discusses the extension of machine learning to knowledge-driven approaches, including generative models such as adversarial networks and transfer learning. Finally, this review provides insights into different works to highlight various operating conditions and different numbers and types of failures, and provides links to some publicly available datasets in the field. The clear organization of the abundant information on this subject may result in rigorous guidelines for the trends adopted in the future.},
DOI = {10.3390/en14196316}
}



@Article{s21196612,
AUTHOR = {Grosinger, Patrik and Rybář, Jan and Dunaj, Štefan and Ďuriš, Stanislav and Hučko, Branislav},
TITLE = {A New Payload Swing Angle Sensing Device and Its Accuracy},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {6612},
URL = {https://www.mdpi.com/1424-8220/21/19/6612},
PubMedID = {34640932},
ISSN = {1424-8220},
ABSTRACT = {Measuring the swing angle of a crane load is a relatively well-known but unsatisfactorily solved problem in technical practice. This measurement is necessary for the automatic stabilization of load swing without human intervention. This article describes a technically simple and new approach to solving this problem. The focus of this work is to determine the accuracy of the measuring device. The focus of this work remains on the design, the principle of operation of the equipment, and the determination of accuracy. The basic idea is to apply the strain gauge on an elastic, easily deformable component that is part of the device. One part of the elastic component is fixedly connected to the frame; the other part is connected to the crane rope by means of pulleys close to the rope. In this way, the bending of the elastic component in proportion to the swing angle of the payload is ensured.},
DOI = {10.3390/s21196612}
}



@Article{rs13193979,
AUTHOR = {Zhuang, Jiedong and Dai, Ming and Chen, Xuruoyan and Zheng, Enhui},
TITLE = {A Faster and More Effective Cross-View Matching Method of UAV and Satellite Images for UAV Geolocalization},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3979},
URL = {https://www.mdpi.com/2072-4292/13/19/3979},
ISSN = {2072-4292},
ABSTRACT = {Cross-view geolocalization matches the same target in different images from various views, such as views of unmanned aerial vehicles (UAVs) and satellites, which is a key technology for UAVs to autonomously locate and navigate without a positioning system (e.g., GPS and GNSS). The most challenging aspect in this area is the shifting of targets and nonuniform scales among different views. Published methods focus on extracting coarse features from parts of images, but neglect the relationship between different views, and the influence of scale and shifting. To bridge this gap, an effective network is proposed with well-designed structures, referred to as multiscale block attention (MSBA), based on a local pattern network. MSBA cuts images into several parts with different scales, among which self-attention is applied to make feature extraction more efficient. The features of different views are extracted by a multibranch structure, which was designed to make different branches learn from each other, leading to a more subtle relationship between views. The method was implemented with the newest UAV-based geolocalization dataset. Compared with the existing state-of-the-art (SOTA) method, MSBA accuracy improved by almost 10% when the inference time was equal to that of the SOTA method; when the accuracy of MSBA was the same as that of the SOTA method, inference time was shortened by 30%.},
DOI = {10.3390/rs13193979}
}



@Article{rs13193993,
AUTHOR = {Zhang, Zheng and Tang, Ping and Zhang, Weixiong and Tang, Liang},
TITLE = {Satellite Image Time Series Clustering via Time Adaptive Optimal Transport},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3993},
URL = {https://www.mdpi.com/2072-4292/13/19/3993},
ISSN = {2072-4292},
ABSTRACT = {Satellite Image Time Series (SITS) have become more accessible in recent years and SITS analysis has attracted increasing research interest. Given that labeled SITS training samples are time and effort consuming to acquire, clustering or unsupervised analysis methods need to be developed. Similarity measure is critical for clustering, however, currently established methods represented by Dynamic Time Warping (DTW) still exhibit several issues when coping with SITS, such as pathological alignment, sensitivity to spike noise, and limitation on capacity. In this paper, we introduce a new time series similarity measure method named time adaptive optimal transport (TAOT) to the application of SITS clustering. TAOT inherits several promising properties of optimal transport for the comparing of time series. Statistical and visual results on two real SITS datasets with two different settings demonstrate that TAOT can effectively alleviate the issues of DTW and further improve the clustering accuracy. Thus, TAOT can serve as a usable tool to explore the potential of precious SITS data.},
DOI = {10.3390/rs13193993}
}



@Article{bdcc5040053,
AUTHOR = {Jamil, Sonain and Rahman, MuhibUr and Haider, Amir},
TITLE = {Bag of Features (BoF) Based Deep Learning Framework for Bleached Corals Detection},
JOURNAL = {Big Data and Cognitive Computing},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {53},
URL = {https://www.mdpi.com/2504-2289/5/4/53},
ISSN = {2504-2289},
ABSTRACT = {Coral reefs are the sub-aqueous calcium carbonate structures collected by the invertebrates known as corals. The charm and beauty of coral reefs attract tourists, and they play a vital role in preserving biodiversity, ceasing coastal erosion, and promoting business trade. However, they are declining because of over-exploitation, damaging fishery, marine pollution, and global climate changes. Also, coral reefs help treat human immune-deficiency virus (HIV), heart disease, and coastal erosion. The corals of Australia’s great barrier reef have started bleaching due to the ocean acidification, and global warming, which is an alarming threat to the earth’s ecosystem. Many techniques have been developed to address such issues. However, each method has a limitation due to the low resolution of images, diverse weather conditions, etc. In this paper, we propose a bag of features (BoF) based approach that can detect and localize the bleached corals before the safety measures are applied. The dataset contains images of bleached and unbleached corals, and various kernels are used to support the vector machine so that extracted features can be classified. The accuracy of handcrafted descriptors and deep convolutional neural networks is analyzed and provided in detail with comparison to the current method. Various handcrafted descriptors like local binary pattern, a histogram of an oriented gradient, locally encoded transform feature histogram, gray level co-occurrence matrix, and completed joint scale local binary pattern are used for feature extraction. Specific deep convolutional neural networks such as AlexNet, GoogLeNet, VGG-19, ResNet-50, Inception v3, and CoralNet are being used for feature extraction. From experimental analysis and results, the proposed technique outperforms in comparison to the current state-of-the-art methods. The proposed technique achieves 99.08% accuracy with a classification error of 0.92%. A novel bleached coral positioning algorithm is also proposed to locate bleached corals in the coral reef images.},
DOI = {10.3390/bdcc5040053}
}



@Article{rs13194017,
AUTHOR = {Harvey, Winthrop and Rainwater, Chase and Cothren, Jackson},
TITLE = {Direct Aerial Visual Geolocalization Using Deep Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {4017},
URL = {https://www.mdpi.com/2072-4292/13/19/4017},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicles (UAVs) must keep track of their location in order to maintain flight plans. Currently, this task is almost entirely performed by a combination of Inertial Measurement Units (IMUs) and reference to GNSS (Global Navigation Satellite System). Navigation by GNSS, however, is not always reliable, due to various causes both natural (reflection and blockage from objects, technical fault, inclement weather) and artificial (GPS spoofing and denial). In such GPS-denied situations, it is desirable to have additional methods for aerial geolocalization. One such method is visual geolocalization, where aircraft use their ground facing cameras to localize and navigate. The state of the art in many ground-level image processing tasks involve the use of Convolutional Neural Networks (CNNs). We present here a study of how effectively a modern CNN designed for visual classification can be applied to the problem of Absolute Visual Geolocalization (AVL, localization without a prior location estimate). An Xception based architecture is trained from scratch over a &gt;1000 km2 section of Washington County, Arkansas to directly regress latitude and longitude from images from different orthorectified high-altitude survey flights. It achieves average localization accuracy on unseen image sets over the same region from different years and seasons with as low as 115 m average error, which localizes to 0.004% of the training area, or about 8% of the width of the 1.5 × 1.5 km input image. This demonstrates that CNNs are expressive enough to encode robust landscape information for geolocalization over large geographic areas. Furthermore, discussed are methods of providing uncertainty for CNN regression outputs, and future areas of potential improvement for use of deep neural networks in visual geolocalization.},
DOI = {10.3390/rs13194017}
}



@Article{ijgi10100680,
AUTHOR = {Yang, Annan and Wang, Chunmei and Pang, Guowei and Long, Yongqing and Wang, Lei and Cruse, Richard M. and Yang, Qinke},
TITLE = {Gully Erosion Susceptibility Mapping in Highly Complex Terrain Using Machine Learning Models},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {680},
URL = {https://www.mdpi.com/2220-9964/10/10/680},
ISSN = {2220-9964},
ABSTRACT = {Gully erosion is the most severe type of water erosion and is a major land degradation process. Gully erosion susceptibility mapping (GESM)’s efficiency and interpretability remains a challenge, especially in complex terrain areas. In this study, a WoE-MLC model was used to solve the above problem, which combines machine learning classification algorithms and the statistical weight of evidence (WoE) model in the Loess Plateau. The three machine learning (ML) algorithms utilized in this research were random forest (RF), gradient boosted decision trees (GBDT), and extreme gradient boosting (XGBoost). The results showed that: (1) GESM were well predicted by combining both machine learning regression models and WoE-MLC models, with the area under the curve (AUC) values both greater than 0.92, and the latter was more computationally efficient and interpretable; (2) The XGBoost algorithm was more efficient in GESM than the other two algorithms, with the strongest generalization ability and best performance in avoiding overfitting (averaged AUC = 0.947), followed by the RF algorithm (averaged AUC = 0.944), and GBDT algorithm (averaged AUC = 0.938); and (3) slope gradient, land use, and altitude were the main factors for GESM. This study may provide a possible method for gully erosion susceptibility mapping at large scale.},
DOI = {10.3390/ijgi10100680}
}



@Article{agriculture11100981,
AUTHOR = {Wu, Yang and Xu, Lihong},
TITLE = {Image Generation of Tomato Leaf Disease Identification Based on Adversarial-VAE},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {981},
URL = {https://www.mdpi.com/2077-0472/11/10/981},
ISSN = {2077-0472},
ABSTRACT = {The deep neural network-based method requires a lot of data for training. Aiming at the problem of a lack of training images in tomato leaf disease identification, an Adversarial-VAE network model for generating images of 10 tomato leaf diseases is proposed, which is used to expand the training set for training an identification model. First, an Adversarial-VAE model is designed to generate tomato leaf disease images. Then, a multi-scale residual learning module is used to replace single-size convolution kernels to enrich extracted features, and a dense connection strategy is integrated into the Adversarial-VAE networks to further enhance the image generation ability. The training set is expanded by the proposed model, which generates the same number of images by training 10,892 images of 10 leaves. The generated images are superior to those of InfoGAN, WAE, VAE, and VAE-GAN measured by the Frechet Inception Distance (FID). The experimental results show that using the extension dataset that is generated by the Adversarial-VAE model to train the Resnet identification model could improve the accuracy of identification effectively. The model proposed in this paper could generate enough images of tomato leaf diseases and provide a feasible solution for data expansion of tomato leaf disease images.},
DOI = {10.3390/agriculture11100981}
}



@Article{rs13204029,
AUTHOR = {Zhao, Jianghong and Wang, Yinrui and Cao, Yuee and Guo, Ming and Huang, Xianfeng and Zhang, Ruiju and Dou, Xintong and Niu, Xinyu and Cui, Yuanyuan and Wang, Jun},
TITLE = {The Fusion Strategy of 2D and 3D Information Based on Deep Learning: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4029},
URL = {https://www.mdpi.com/2072-4292/13/20/4029},
ISSN = {2072-4292},
ABSTRACT = {Recently, researchers have realized a number of achievements involving deep-learning-based neural networks for the tasks of segmentation and detection based on 2D images, 3D point clouds, etc. Using 2D and 3D information fusion for the advantages of compensation and accuracy improvement has become a hot research topic. However, there are no critical reviews focusing on the fusion strategies of 2D and 3D information integration based on various data for segmentation and detection, which are the basic tasks of computer vision. To boost the development of this research domain, the existing representative fusion strategies are collected, introduced, categorized, and summarized in this paper. In addition, the general structures of different kinds of fusion strategies were firstly abstracted and categorized, which may inspire researchers. Moreover, according to the methods included in this paper, the 2D information and 3D information of different methods come from various kinds of data. Furthermore, suitable datasets are introduced and comparatively summarized to support the relative research. Last but not least, we put forward some open challenges and promising directions for future research.},
DOI = {10.3390/rs13204029}
}



@Article{rs13204032,
AUTHOR = {Khun, Kosal and Tremblay, Nicolas and Panneton, Bernard and Vigneault, Philippe and Lord, Etienne and Cavayas, François and Codjia, Claude},
TITLE = {Use of Oblique RGB Imagery and Apparent Surface Area of Plants for Early Estimation of Above-Ground Corn Biomass},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4032},
URL = {https://www.mdpi.com/2072-4292/13/20/4032},
ISSN = {2072-4292},
ABSTRACT = {Estimating above-ground biomass in the context of fertilization management requires the monitoring of crops at early stages. Conventional remote sensing techniques make use of vegetation indices such as the normalized difference vegetation index (NDVI), but they do not exploit the high spatial resolution (ground sampling distance &lt; 5 mm) now achievable with the introduction of unmanned aerial vehicles (UAVs) in agriculture. The aim of this study was to compare image mosaics to single images for the estimation of corn biomass and the influence of viewing angles in this estimation. Nadir imagery was captured by a high spatial resolution camera mounted on a UAV to generate orthomosaics of corn plots at different growth stages (from V2 to V7). Nadir and oblique images (30° and 45° with respect to the vertical) were also acquired from a zip line platform and processed as single images. Image segmentation was performed using the difference color index Excess Green-Excess Red, allowing for the discrimination between vegetation and background pixels. The apparent surface area of plants was then extracted and compared to biomass measured in situ. An asymptotic total least squares regression was performed and showed a strong relationship between the apparent surface area of plants and both dry and fresh biomass. Mosaics tended to underestimate the apparent surface area in comparison to single images because of radiometric degradation. It is therefore conceivable to process only single images instead of investing time and effort in acquiring and processing data for orthomosaic generation. When comparing oblique photography, an angle of 30° yielded the best results in estimating corn biomass, with a low residual standard error of orthogonal distance (RSEOD = 0.031 for fresh biomass, RSEOD = 0.034 for dry biomass). Since oblique imagery provides more flexibility in data acquisition with fewer constraints on logistics, this approach might be an efficient way to monitor crop biomass at early stages.},
DOI = {10.3390/rs13204032}
}



@Article{s21206705,
AUTHOR = {Farkhani, Sadaf and Skovsen, Søren Kelstrup and Dyrmann, Mads and Jørgensen, Rasmus Nyholm and Karstoft, Henrik},
TITLE = {Weed Classification Using Explainable Multi-Resolution Slot Attention},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {6705},
URL = {https://www.mdpi.com/1424-8220/21/20/6705},
PubMedID = {34695919},
ISSN = {1424-8220},
ABSTRACT = {In agriculture, explainable deep neural networks (DNNs) can be used to pinpoint the discriminative part of weeds for an imagery classification task, albeit at a low resolution, to control the weed population. This paper proposes the use of a multi-layer attention procedure based on a transformer combined with a fusion rule to present an interpretation of the DNN decision through a high-resolution attention map. The fusion rule is a weighted average method that is used to combine attention maps from different layers based on saliency. Attention maps with an explanation for why a weed is or is not classified as a certain class help agronomists to shape the high-resolution weed identification keys (WIK) that the model perceives. The model is trained and evaluated on two agricultural datasets that contain plants grown under different conditions: the Plant Seedlings Dataset (PSD) and the Open Plant Phenotyping Dataset (OPPD). The model represents attention maps with highlighted requirements and information about misclassification to enable cross-dataset evaluations. State-of-the-art comparisons represent classification developments after applying attention maps. Average accuracies of 95.42% and 96% are gained for the negative and positive explanations of the PSD test sets, respectively. In OPPD evaluations, accuracies of 97.78% and 97.83% are obtained for negative and positive explanations, respectively. The visual comparison between attention maps also shows high-resolution information.},
DOI = {10.3390/s21206705}
}



@Article{rs13204025,
AUTHOR = {Mirmazloumi, S. Mohammad and Moghimi, Armin and Ranjgar, Babak and Mohseni, Farzane and Ghorbanian, Arsalan and Ahmadi, Seyed Ali and Amani, Meisam and Brisco, Brian},
TITLE = {Status and Trends of Wetland Studies in Canada Using Remote Sensing Technology with a Focus on Wetland Classification: A Bibliographic Analysis},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4025},
URL = {https://www.mdpi.com/2072-4292/13/20/4025},
ISSN = {2072-4292},
ABSTRACT = {A large portion of Canada is covered by wetlands; mapping and monitoring them is of great importance for various applications. In this regard, Remote Sensing (RS) technology has been widely employed for wetland studies in Canada over the past 45 years. This study evaluates meta-data to investigate the status and trends of wetland studies in Canada using RS technology by reviewing the scientific papers published between 1976 and the end of 2020 (300 papers in total). Initially, a meta-analysis was conducted to analyze the status of RS-based wetland studies in terms of the wetland classification systems, methods, classes, RS data usage, publication details (e.g., authors, keywords, citations, and publications time), geographic information, and level of classification accuracies. The deep systematic review of 128 peer-reviewed articles illustrated the rising trend in using multi-source RS datasets along with advanced machine learning algorithms for wetland mapping in Canada. It was also observed that most of the studies were implemented over the province of Ontario. Pixel-based supervised classifiers were the most popular wetland classification algorithms. This review summarizes different RS systems and methodologies for wetland mapping in Canada to outline how RS has been utilized for the generation of wetland inventories. The results of this review paper provide the current state-of-the-art methods and datasets for wetland studies in Canada and will provide direction for future wetland mapping research.},
DOI = {10.3390/rs13204025}
}



@Article{rs13204036,
AUTHOR = {Lin, Feng-Cheng and Chuang, Yung-Chung},
TITLE = {Interoperability Study of Data Preprocessing for Deep Learning and High-Resolution Aerial Photographs for Forest and Vegetation Type Identification},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4036},
URL = {https://www.mdpi.com/2072-4292/13/20/4036},
ISSN = {2072-4292},
ABSTRACT = {When original aerial photographs are combined with deep learning to classify forest vegetation cover, these photographs are often hindered by the interlaced composition of complex backgrounds and vegetation types as well as the influence of different deep learning calculation processes, resulting in unpredictable training and test results. The purpose of this research is to evaluate (1) data preprocessing, (2) the number of classification targets, and (3) convolutional neural network (CNN) approaches combined with deep learning’s effects on high-resolution aerial photographs to identify forest and vegetation types. Data preprocessing is mainly composed of principal component analysis and content simplification (noise elimination). The number of classification targets is divided into 14 types of forest vegetation that are more complex and difficult to distinguish and seven types of forest vegetation that are simpler. We used CNN approaches to compare three CNN architectures: VGG19, ResNet50, and SegNet. This study found that the models had the best execution efficiency and classification accuracy after data preprocessing using principal component analysis. However, an increase in the number of classification targets significantly reduced the classification accuracy. The algorithm analysis showed that VGG19 achieved the best classification accuracy, but SegNet achieved the best performance and overall stability of relative convergence. This proves that data preprocessing helps identify forest and plant categories in aerial photographs with complex backgrounds. If combined with the appropriate CNN algorithm, these architectures will have great potential to replace high-cost on-site forestland surveys. At the end of this study, a user-friendly classification system for practical application is proposed, and its testing showed good results.},
DOI = {10.3390/rs13204036}
}



@Article{en14206507,
AUTHOR = {G. M. Abdolrasol, Maher and Hannan, Mahammad Abdul and Hussain, S. M. Suhail and Ustun, Taha Selim and Sarker, Mahidur R. and Ker, Pin Jern},
TITLE = {Energy Management Scheduling for Microgrids in the Virtual Power Plant System Using Artificial Neural Networks},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {6507},
URL = {https://www.mdpi.com/1996-1073/14/20/6507},
ISSN = {1996-1073},
ABSTRACT = {This study uses an artificial neural network (ANN) as an intelligent controller for the management and scheduling of a number of microgrids (MGs) in virtual power plants (VPP). Two ANN-based scheduling control approaches are presented: the ANN-based backtracking search algorithm (ANN-BBSA) and ANN-based binary practical swarm optimization (ANN-BPSO) algorithm. Both algorithms provide the optimal schedule for every distribution generation (DG) to limit fuel consumption, reduce CO2 emission, and increase the system efficiency towards smart and economic VPP operation as well as grid decarbonization. Different test scenarios are executed to evaluate the controllers’ robustness and performance under changing system conditions. The test cases are different load curves to evaluate the ANN’s performance on untrained data. The untrained and trained load models used are real-load parameter data recorders in northern parts of Malaysia. The test results are analyzed to investigate the performance of these controllers under varying power system conditions. Additionally, a comparative study is performed to compare their performances with other solutions available in the literature based on several parameters. Results show the superiority of the ANN-based controllers in terms of cost reduction and efficiency.},
DOI = {10.3390/en14206507}
}



@Article{rs13204057,
AUTHOR = {Zhao, Liya and Yang, Qi and Zhao, Qiang and Wu, Jingwei},
TITLE = {Assessing the Long-Term Evolution of Abandoned Salinized Farmland via Temporal Remote Sensing Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4057},
URL = {https://www.mdpi.com/2072-4292/13/20/4057},
ISSN = {2072-4292},
ABSTRACT = {Salinization in arid or semiarid regions with water logging limits cropland yield, threatening food security. The highest level of farmland salinization, that is, abandoned salinized farmland, is a tradeoff between inadequate drainage facilities and sustainable farming. The evolution of abandoned salinized farmlands is closely related to the development of cropping systems. However, detecting abandoned salinized farmland using time-series remote sensing data has not been investigated well by previous studies. In this study, a novel approach was proposed to detect the dynamics of abandoned salinized farmland using time-series multispectral and thermal imagery. Thirty-two years of temporal Landsat imagery (from 1988 to 2019) was used to assess the evolution of salinization in Hetao, a two-thousand-year-old irrigation district in northern China. As intermediate variables of the proposed method, the crop-specific planting area was retrieved via its unique temporal vegetation index (VI) pattern, in which the shape-model-fitting technology and the K-means cluster algorithm were used. The desert area was stripped from the clustered non-vegetative area using its distinct features in the thermal band. Subsequently, the abandoned salinized farmland was distinguished from the urban area by the threshold-based saline index (SI). In addition, a regression model between electrical conductance (EC) and SI was established, and the spatial saline degree was evaluated by the SI map in uncropped and unfrozen seasons. The results show that the cropland has constantly been expanding in recent decades (from 4.7 × 105 ha to 7.1 × 105 ha), while the planting area of maize and sunflower has grown and the area of wheat has decreased. Significant desalinization progress was observed in Hetao, where both the area of salt-affected land (salt-free area increased approximately 4 × 105 ha) and the abandoned salinized farmland decreased (reduced from 0.45 × 105 ha to 0.19 × 105 ha). This could be mainly attributed to three reasons: the popularization of water-saving irrigation technology, the construction of artificial drainage facilities, and a shift in cropping patterns. The decrease in irrigation and the increase in drainage have deepened the groundwater table in Hetao, which weakens the salt collection capacity of the abandoned salinized farmland. The results demonstrate the promising possibility of reutilizing abandoned salinized farmland via a leaching campaign where the groundwater table is sufficiently deep to stop salinization.},
DOI = {10.3390/rs13204057}
}



@Article{rs13204065,
AUTHOR = {Yu, Run and Luo, Youqing and Li, Haonan and Yang, Liyuan and Huang, Huaguo and Yu, Linfeng and Ren, Lili},
TITLE = {Three-Dimensional Convolutional Neural Network Model for Early Detection of Pine Wilt Disease Using UAV-Based Hyperspectral Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4065},
URL = {https://www.mdpi.com/2072-4292/13/20/4065},
ISSN = {2072-4292},
ABSTRACT = {As one of the most devastating disasters to pine forests, pine wilt disease (PWD) has caused tremendous ecological and economic losses in China. An effective way to prevent large-scale PWD outbreaks is to detect and remove the damaged pine trees at the early stage of PWD infection. However, early infected pine trees do not show obvious changes in morphology or color in the visible wavelength range, making early detection of PWD tricky. Unmanned aerial vehicle (UAV)-based hyperspectral imagery (HI) has great potential for early detection of PWD. However, the commonly used methods, such as the two-dimensional convolutional neural network (2D-CNN), fail to simultaneously extract and fully utilize the spatial and spectral information, whereas the three-dimensional convolutional neural network (3D-CNN) is able to collect this information from raw hyperspectral data. In this paper, we applied the residual block to 3D-CNN and constructed a 3D-Res CNN model, the performance of which was then compared with that of 3D-CNN, 2D-CNN, and 2D-Res CNN in identifying PWD-infected pine trees from the hyperspectral images. The 3D-Res CNN model outperformed the other models, achieving an overall accuracy (OA) of 88.11% and an accuracy of 72.86% for detecting early infected pine trees (EIPs). Using only 20% of the training samples, the OA and EIP accuracy of 3D-Res CNN can still achieve 81.06% and 51.97%, which is superior to the state-of-the-art method in the early detection of PWD based on hyperspectral images. Collectively, 3D-Res CNN was more accurate and effective in early detection of PWD. In conclusion, 3D-Res CNN is proposed for early detection of PWD in this paper, making the prediction and control of PWD more accurate and effective. This model can also be applied to detect pine trees damaged by other diseases or insect pests in the forest.},
DOI = {10.3390/rs13204065}
}



@Article{electronics10202474,
AUTHOR = {Nguyen, Lanh Van and Phung, Manh Duong and Ha, Quang Phuc},
TITLE = {Iterative Learning Sliding Mode Control for UAV Trajectory Tracking},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {2474},
URL = {https://www.mdpi.com/2079-9292/10/20/2474},
ISSN = {2079-9292},
ABSTRACT = {This paper presents a novel iterative learning sliding mode controller (ILSMC) that can be applied to the trajectory tracking of quadrotor unmanned aerial vehicles (UAVs) subject to model uncertainties and external disturbances. Here, the proposed ILSMC is integrated in the outer loop of a controlled system. The control development, conducted in the discrete-time domain, does not require a priori information of the disturbance bound as with conventional SMC techniques. It only involves an equivalent control term for the desired dynamics in the closed loop and an iterative learning term to drive the system state toward the sliding surface to maintain robust performance. By learning from previous iterations, the ILSMC can yield very accurate tracking performance when a sliding mode is induced without control chattering. The design is then applied to the attitude control of a 3DR Solo UAV with a built-in PID controller. The simulation results and experimental validation with real-time data demonstrate the advantages of the proposed control scheme over existing techniques.},
DOI = {10.3390/electronics10202474}
}



@Article{rs13204069,
AUTHOR = {Liu, Hong and Yu, Tao and Hu, Bingliang and Hou, Xingsong and Zhang, Zhoufeng and Liu, Xiao and Liu, Jiacheng and Wang, Xueji and Zhong, Jingjing and Tan, Zhengxuan and Xia, Shaoxia and Qian, Bao},
TITLE = {UAV-Borne Hyperspectral Imaging Remote Sensing System Based on Acousto-Optic Tunable Filter for Water Quality Monitoring},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4069},
URL = {https://www.mdpi.com/2072-4292/13/20/4069},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle (UAV) hyperspectral remote sensing technologies have unique advantages in high-precision quantitative analysis of non-contact water surface source concentration. Improving the accuracy of non-point source detection is a difficult engineering problem. To facilitate water surface remote sensing, imaging, and spectral analysis activities, a UAV-based hyperspectral imaging remote sensing system was designed. Its prototype was built, and laboratory calibration and a joint air–ground water quality monitoring activity were performed. The hyperspectral imaging remote sensing system of UAV comprised a light and small UAV platform, spectral scanning hyperspectral imager, and data acquisition and control unit. The spectral principle of the hyperspectral imager is based on the new high-performance acousto-optic tunable (AOTF) technology. During laboratory calibration, the spectral calibration of the imaging spectrometer and image preprocessing in data acquisition were completed. In the UAV air–ground joint experiment, combined with the typical water bodies of the Yangtze River mainstream, the Three Gorges demonstration area, and the Poyang Lake demonstration area, the hyperspectral data cubes of the corresponding water areas were obtained, and geometric registration was completed. Thus, a large field-of-view mosaic and water radiation calibration were realized. A chlorophyl-a (Chl-a) sensor was used to test the actual water control points, and 11 traditional Chl-a sensitive spectrum selection algorithms were analyzed and compared. A random forest algorithm was used to establish a prediction model of water surface spectral reflectance and water quality parameter concentration. Compared with the back propagation neural network, partial least squares, and PSO-LSSVM algorithms, the accuracy of the RF algorithm in predicting Chl-a was significantly improved. The determination coefficient of the training samples was 0.84; root mean square error, 3.19 μg/L; and mean absolute percentage error, 5.46%. The established Chl-a inversion model was applied to UAV hyperspectral remote sensing images. The predicted Chl-a distribution agreed with the field observation results, indicating that the UAV-borne hyperspectral remote sensing water quality monitoring system based on AOTF is a promising remote sensing imaging spectral analysis tool for water.},
DOI = {10.3390/rs13204069}
}



@Article{min11101118,
AUTHOR = {Mishra, Amit Kumar},
TITLE = {AI4R2R (AI for Rock to Revenue): A Review of the Applications of AI in Mineral Processing},
JOURNAL = {Minerals},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {1118},
URL = {https://www.mdpi.com/2075-163X/11/10/1118},
ISSN = {2075-163X},
ABSTRACT = {In the last few years, jargon, such as machine learning (ML) and artificial intelligence (AI), have been ubiquitous in both popular science media as well as the academic literature. Many industries have tried the current suite of ML and AI algorithms with various degrees of success. Mineral processing, as an industry, is looking at AI for two reasons. First of all, as with other industries, it is pertinent to know if AI algorithms can be used to enhance productivity. The second reason is specific to the mining industry. Of late, the grade of ores is reducing, and the demand for ethical mining (with as little effect on ecology as possible) is increasing. Thus, mineral processing industries also want to explore the possible use of AI in solving these challenges. In this review paper, first, the challenges in mineral processing that can potentially be solved by AI are presented. Then, some of the most pertinent developments in the domain of ML and AI (applied in the domain of mineral processing) are discussed. Lastly, a top-level modus operandi is presented for a mineral processing industry that might want to explore the possibilities of using AI in its processes. Following are some of the new paradigms added by this review. This review presents a holistic view of the domain of mineral processing with an AI lens. It is also one of the first reviews in this domain to thoroughly discuss the use of AI in ethical, green, and sustainable mineral processing. The AI process proposed in this paper is a comprehensive one. To ensure the relevance to industry, the flow was made agile with the spiral system engineering flow. This is expected to drive rapid and agile investigation of the potential of applying ML and AI in different mineral processing industries.},
DOI = {10.3390/min11101118}
}



@Article{electronics10202488,
AUTHOR = {Ge, Daohui and Liu, Ruyi and Li, Yunan and Miao, Qiguang},
TITLE = {Reliable Memory Model for Visual Tracking},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {2488},
URL = {https://www.mdpi.com/2079-9292/10/20/2488},
ISSN = {2079-9292},
ABSTRACT = {Effectively learning the appearance change of a target is the key point of an online tracker. When occlusion and misalignment occur, the tracking results usually contain a great amount of background information, which heavily affects the ability of a tracker to distinguish between targets and backgrounds, eventually leading to tracking failure. To solve this problem, we propose a simple and robust reliable memory model. In particular, an adaptive evaluation strategy (AES) is proposed to assess the reliability of tracking results. AES combines the confidence of the tracker predictions and the similarity distance, which is between the current predicted result and the existing tracking results. Based on the reliable results of AES selection, we designed an active–frozen memory model to store reliable results. Training samples stored in active memory are used to update the tracker, while frozen memory temporarily stores inactive samples. The active–frozen memory model maintains the diversity of samples while satisfying the limitation of storage. We performed comprehensive experiments on five benchmarks: OTB-2013, OTB-2015, UAV123, Temple-color-128, and VOT2016. The experimental results show that our tracker achieves state-of-the-art performance.},
DOI = {10.3390/electronics10202488}
}



@Article{su132011264,
AUTHOR = {Hegedűs, Tamás and Fényes, Dániel and Németh, Balázs and Gáspár, Péter},
TITLE = {Improving Sustainable Safe Transport via Automated Vehicle Control with Closed-Loop Matching},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {11264},
URL = {https://www.mdpi.com/2071-1050/13/20/11264},
ISSN = {2071-1050},
ABSTRACT = {The concept of vehicle automation is a promising approach to achieve sustainable transport systems, especially in an urban context. Automation requires the integration of learning-based approaches and methods in control theory. Through the integration, a high amount of information in automation can be incorporated. Thus, a sustainable operation, i.e., energy-efficient and safe motion with automated vehicles, can be achieved. Despite the advantages of integration with learning-based approaches, enhanced vehicle automation poses crucial safety challenges. In this paper, a novel closed-loop matching method for control-oriented purposes in the context of vehicle control systems is presented. The goal of the method is to match the nonlinear vehicle dynamics to the dynamics of a linear system in a predefined structure; thus, a control-oriented model is obtained. The matching is achieved by an additional control input from a neural network, which is designed based on the input–output signals of the nonlinear vehicle system. In this paper, the process of closed-loop matching, i.e., the dataset generation, the training, and the evaluation of the neural network, is proposed. The evaluation process of the neural network through data-driven reachability analysis and statistical performance analysis methods is carried out. The proposed method is applied to achieve the path following functionality, in which the nonlinearities of the lateral vehicle dynamics are handled. The effectiveness of the closed-loop matching and the designed control functionality through high fidelity CarMaker simulations is illustrated.},
DOI = {10.3390/su132011264}
}



@Article{agriculture11100997,
AUTHOR = {Peng, Yun and Wang, Aichen and Liu, Jizhan and Faheem, Muhammad},
TITLE = {A Comparative Study of Semantic Segmentation Models for Identification of Grape with Different Varieties},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {997},
URL = {https://www.mdpi.com/2077-0472/11/10/997},
ISSN = {2077-0472},
ABSTRACT = {Accurate fruit segmentation in images is the prerequisite and key step for precision agriculture. In this article, aiming at the segmentation of grape cluster with different varieties, 3 state-of-the-art semantic segmentation networks, i.e., Fully Convolutional Network (FCN), U-Net, and DeepLabv3+ applied on six different datasets were studied. We investigated: (1) the segmentation performance difference of the 3 studied networks; (2) The impact of different input representations on segmentation performance; (3) The effect of image enhancement method to improve the poor illumination of images and further improve the segmentation performance; (4) The impact of the distance between grape clusters and camera on segmentation performance. The experiment results show that compared with FCN and U-Net the DeepLabv3+ combined with transfer learning is more suitable for the task with an intersection over union (IoU) of 84.26%. Five different input representations, namely RGB, HSV, L*a*b, HHH, and YCrCb obtained different IoU, ranging from 81.5% to 88.44%. Among them, the L*a*b got the highest IoU. Besides, the adopted Histogram Equalization (HE) image enhancement method could improve the model’s robustness against poor illumination conditions. Through the HE preprocessing, the IoU of the enhanced dataset increased by 3.88%, from 84.26% to 88.14%. The distance between the target and camera also affects the segmentation performance, no matter in which dataset, the closer the distance, the better the segmentation performance was. In a word, the conclusion of this research provides some meaningful suggestions for the study of grape or other fruit segmentation.},
DOI = {10.3390/agriculture11100997}
}



@Article{ijerph182010765,
AUTHOR = {Leite, Gleidson Sobreira and Albuquerque, Adriano Bessa and Pinheiro, Plácido Rogerio},
TITLE = {Applications of Technological Solutions in Primary Ways of Preventing Transmission of Respiratory Infectious Diseases—A Systematic Literature Review},
JOURNAL = {International Journal of Environmental Research and Public Health},
VOLUME = {18},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {10765},
URL = {https://www.mdpi.com/1660-4601/18/20/10765},
PubMedID = {34682511},
ISSN = {1660-4601},
ABSTRACT = {With the growing concern about the spread of new respiratory infectious diseases, several studies involving the application of technology in the prevention of these diseases have been carried out. Among these studies, it is worth highlighting the importance of those focused on the primary forms of prevention, such as social distancing, mask usage, quarantine, among others. This importance arises because, from the emergence of a new disease to the production of immunizers, preventive actions must be taken to reduce contamination and fatalities rates. Despite the considerable number of studies, no records of works aimed at the identification, registration, selection, and rigorous analysis and synthesis of the literature were found. For this purpose, this paper presents a systematic review of the literature on the application of technological solutions in the primary ways of respiratory infectious diseases transmission prevention. From the 1139 initially retrieved, 219 papers were selected for data extraction, analysis, and synthesis according to predefined inclusion and exclusion criteria. Results enabled the identification of a general categorization of application domains, as well as mapping of the adopted support mechanisms. Findings showed a greater trend in studies related to pandemic planning and, among the support mechanisms adopted, data and mathematical application-related solutions received greater attention. Topics for further research and improvement were also identified such as the need for a better description of data analysis and evidence.},
DOI = {10.3390/ijerph182010765}
}



@Article{s21206826,
AUTHOR = {Yang, Baohua and Zhu, Yue and Zhou, Shuaijun},
TITLE = {Accurate Wheat Lodging Extraction from Multi-Channel UAV Images Using a Lightweight Network Model},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {6826},
URL = {https://www.mdpi.com/1424-8220/21/20/6826},
PubMedID = {34696038},
ISSN = {1424-8220},
ABSTRACT = {The extraction of wheat lodging is of great significance to post-disaster agricultural production management, disaster assessment and insurance subsidies. At present, the recognition of lodging wheat in the actual complex field environment still has low accuracy and poor real-time performance. To overcome this gap, first, four-channel fusion images, including RGB and DSM (digital surface model), as well as RGB and ExG (excess green), were constructed based on the RGB image acquired from unmanned aerial vehicle (UAV). Second, a Mobile U-Net model that combined a lightweight neural network with a depthwise separable convolution and U-Net model was proposed. Finally, three data sets (RGB, RGB + DSM and RGB + ExG) were used to train, verify, test and evaluate the proposed model. The results of the experiment showed that the overall accuracy of lodging recognition based on RGB + DSM reached 88.99%, which is 11.8% higher than that of original RGB and 6.2% higher than that of RGB + ExG. In addition, our proposed model was superior to typical deep learning frameworks in terms of model parameters, processing speed and segmentation accuracy. The optimized Mobile U-Net model reached 9.49 million parameters, which was 27.3% and 33.3% faster than the FCN and U-Net models, respectively. Furthermore, for RGB + DSM wheat lodging extraction, the overall accuracy of Mobile U-Net was improved by 24.3% and 15.3% compared with FCN and U-Net, respectively. Therefore, the Mobile U-Net model using RGB + DSM could extract wheat lodging with higher accuracy, fewer parameters and stronger robustness.},
DOI = {10.3390/s21206826}
}



@Article{rs13204112,
AUTHOR = {Massari, Christian and Modanesi, Sara and Dari, Jacopo and Gruber, Alexander and De Lannoy, Gabrielle J. M. and Girotto, Manuela and Quintana-Seguí, Pere and Le Page, Michel and Jarlan, Lionel and Zribi, Mehrez and Ouaadi, Nadia and Vreugdenhil, Mariëtte and Zappa, Luca and Dorigo, Wouter and Wagner, Wolfgang and Brombacher, Joost and Pelgrum, Henk and Jaquot, Pauline and Freeman, Vahid and Volden, Espen and Fernandez Prieto, Diego and Tarpanelli, Angelica and Barbetta, Silvia and Brocca, Luca},
TITLE = {A Review of Irrigation Information Retrievals from Space and Their Utility for Users},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4112},
URL = {https://www.mdpi.com/2072-4292/13/20/4112},
ISSN = {2072-4292},
ABSTRACT = {Irrigation represents one of the most impactful human interventions in the terrestrial water cycle. Knowing the distribution and extent of irrigated areas as well as the amount of water used for irrigation plays a central role in modeling irrigation water requirements and quantifying the impact of irrigation on regional climate, river discharge, and groundwater depletion. Obtaining high-quality global information about irrigation is challenging, especially in terms of quantification of the water actually used for irrigation. Here, we review existing Earth observation datasets, models, and algorithms used for irrigation mapping and quantification from the field to the global scale. The current observation capacities are confronted with the results of a survey on user requirements on satellite-observed irrigation for agricultural water resources’ management. Based on this information, we identify current shortcomings of irrigation monitoring capabilities from space and phrase guidelines for potential future satellite missions and observation strategies.},
DOI = {10.3390/rs13204112}
}



@Article{agriculture11101004,
AUTHOR = {Mohidem, Nur Adibah and Che’Ya, Nik Norasma and Juraimi, Abdul Shukor and Fazlil Ilahi, Wan Fazilah and Mohd Roslim, Muhammad Huzaifah and Sulaiman, Nursyazyla and Saberioon, Mohammadmehdi and Mohd Noor, Nisfariza},
TITLE = {How Can Unmanned Aerial Vehicles Be Used for Detecting Weeds in Agricultural Fields?},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {1004},
URL = {https://www.mdpi.com/2077-0472/11/10/1004},
ISSN = {2077-0472},
ABSTRACT = {Weeds are among the most harmful abiotic factors in agriculture, triggering significant yield loss worldwide. Remote sensing can detect and map the presence of weeds in various spectral, spatial, and temporal resolutions. This review aims to show the current and future trends of UAV applications in weed detection in the crop field. This study systematically searched the original articles published from 1 January 2016 to 18 June 2021 in the databases of Scopus, ScienceDirect, Commonwealth Agricultural Bureaux (CAB) Direct, and Web of Science (WoS) using Boolean string: “weed” AND “Unmanned Aerial Vehicle” OR “UAV” OR “drone”. Out of the papers identified, 144 eligible studies did meet our inclusion criteria and were evaluated. Most of the studies (i.e., 27.42%) on weed detection were carried out during the seedling stage of the growing cycle for the crop. Most of the weed images were captured using red, green, and blue (RGB) camera, i.e., 48.28% and main classification algorithm was machine learning techniques, i.e., 47.90%. This review initially highlighted articles from the literature that includes the crops’ typical phenology stage, reference data, type of sensor/camera, classification methods, and current UAV applications in detecting and mapping weed for different types of crop. This study then provides an overview of the advantages and disadvantages of each sensor and algorithm and tries to identify research gaps by providing a brief outlook at the potential areas of research concerning the benefit of this technology in agricultural industries. Integrated weed management, coupled with UAV application improves weed monitoring in a more efficient and environmentally-friendly way. Overall, this review demonstrates the scientific information required to achieve sustainable weed management, so as to implement UAV platform in the real agricultural contexts.},
DOI = {10.3390/agriculture11101004}
}



@Article{su132011359,
AUTHOR = {Aliyari, Mostafa and Droguett, Enrique Lopez and Ayele, Yonas Zewdu},
TITLE = {UAV-Based Bridge Inspection via Transfer Learning},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {11359},
URL = {https://www.mdpi.com/2071-1050/13/20/11359},
ISSN = {2071-1050},
ABSTRACT = {As bridge inspection becomes more advanced and more ubiquitous, artificial intelligence (AI) techniques, such as machine and deep learning, could offer suitable solutions to the nation’s problems of overdue bridge inspections. AI coupling with various data that can be captured by unmanned aerial vehicles (UAVs) enables fully automated bridge inspections. The key to the success of automated bridge inspection is a model capable of detecting failures from UAV data like images and films. In this context, this paper investigates the performances of state-of-the-art convolutional neural networks (CNNs) through transfer learning for crack detection in UAV-based bridge inspection. The performance of different CNN models is evaluated via UAV-based inspection of Skodsberg Bridge, located in eastern Norway. The low-level features are extracted in the last layers of the CNN models and these layers are trained using 19,023 crack and non-crack images. There is always a trade-off between the number of trainable parameters that CNN models need to learn for each specific task and the number of non-trainable parameters that come from transfer learning. Therefore, selecting the optimized amount of transfer learning is a challenging task and, as there is not enough research in this area, it will be studied in this paper. Moreover, UAV-based bridge inception images require specific attention to establish a suitable dataset as the input of CNN models that are trained on homogenous images. However, in the real implementation of CNN models in UAV-based bridge inspection images, there are always heterogeneities and noises, such as natural and artificial effects like different luminosities, spatial positions, and colors of the elements in an image. In this study, the effects of such heterogeneities on the performance of CNN models via transfer learning are examined. The results demonstrate that with a simplified image cropping technique and with minimum effort to preprocess images, CNN models can identify crack elements from non-crack elements with 81% accuracy. Moreover, the results show that heterogeneities inherent in UAV-based bridge inspection data significantly affect the performance of CNN models with an average 32.6% decrease of accuracy of the CNN models. It is also found that deeper CNN models do not provide higher accuracy compared to the shallower CNN models when the number of images for adoption to a specific task, in this case crack detection, is not large enough; in this study, 19,023 images and shallower models outperform the deeper models.},
DOI = {10.3390/su132011359}
}



@Article{rs13204122,
AUTHOR = {Guo, Xuzhan and Liu, Qingwang and Sharma, Ram P. and Chen, Qiao and Ye, Qiaolin and Tang, Shouzheng and Fu, Liyong},
TITLE = {Tree Recognition on the Plantation Using UAV Images with Ultrahigh Spatial Resolution in a Complex Environment},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4122},
URL = {https://www.mdpi.com/2072-4292/13/20/4122},
ISSN = {2072-4292},
ABSTRACT = {The survival rate of seedlings is a decisive factor of afforestation assessment. Generally, ground checking is more accurate than any other methods. However, the survival rate of seedlings can be higher in the growing season, and this can be estimated in a larger area at a relatively lower cost by extracting the tree crown from the unmanned aerial vehicle (UAV) images, which provides an opportunity for monitoring afforestation in an extensive area. At present, studies on extracting individual tree crowns under the complex ground vegetation conditions are limited. Based on the afforestation images obtained by airborne consumer-grade cameras in central China, this study proposes a method of extracting and fusing multiple radii morphological features to obtain the potential crown. A random forest (RF) was used to identify the regions extracted from the images, and then the recognized crown regions were fused selectively according to the distance. A low-cost individual crown recognition framework was constructed for rapid checking of planted trees. The method was tested in two afforestation areas of 5950 m2 and 5840 m2, with a population of 2418 trees (Koelreuteria) in total. Due to the complex terrain of the sample plot, high weed coverage, the crown width of trees, and spacing of saplings vary greatly, which increases both the difficulty and complexity of crown extraction. Nevertheless, recall and F-score of the proposed method reached 93.29%, 91.22%, and 92.24% precisions, respectively, and 2212 trees were correctly recognized and located. The results show that the proposed method is robust to the change of brightness and to splitting up of a multi-directional tree crown, and is an automatic solution for afforestation verification.},
DOI = {10.3390/rs13204122}
}



@Article{engproc2021007032,
AUTHOR = {Puente-Castro, Alejandro and Rivero, Daniel and Pazos, Alejandro and Fernandez-Blanco, Enrique},
TITLE = {Using Reinforcement Learning in the Path Planning of Swarms of UAVs for the Photographic Capture of Terrains},
JOURNAL = {Engineering Proceedings},
VOLUME = {7},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {32},
URL = {https://www.mdpi.com/2673-4591/7/1/32},
ISSN = {2673-4591},
ABSTRACT = {The number of applications using unmanned aerial vehicles (UAVs) is increasing. The use of UAVs in swarms makes many operators see more advantages than the individual use of UAVs, thus reducing operational time and costs. The main objective of this work is to design a system that, using Reinforcement Learning (RL) and Artificial Neural Networks (ANNs) techniques, can obtain a good path for each UAV in the swarm and distribute the flight environment in such a way that the combination of the captured images is as simple as possible. To determine whether it is better to use a global ANN or multiple local ANNs, experiments have been done over the same map and with different numbers of UAVs at different altitudes. The results are measured based on the time taken to find a solution. The results show that the system works with any number of UAVs if the map is correctly partitioned. On the other hand, using local ANNs seems to be the option that can find solutions faster, ensuring better trajectories than using a single global network. There is no need to use additional map information other than the current state of the environment, like targets or distance maps.},
DOI = {10.3390/engproc2021007032}
}



@Article{agronomy11102068,
AUTHOR = {Joshua, Vinson and Priyadharson, Selwin Mich and Kannadasan, Raju},
TITLE = {Exploration of Machine Learning Approaches for Paddy Yield Prediction in Eastern Part of Tamilnadu},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {2068},
URL = {https://www.mdpi.com/2073-4395/11/10/2068},
ISSN = {2073-4395},
ABSTRACT = {Agriculture is the principal basis of livelihood that acts as a mainstay of any country. There are several changes faced by the farmers due to various factors such as water shortage, undefined price owing to demand–supply, weather uncertainties, and inaccurate crop prediction. The prediction of crop yield, notably paddy yield, is an intricate assignment owing to its dependency on several factors such as crop genotype, environmental factors, management practices, and their interactions. Researchers are used to predicting the paddy yield using statistical approaches, but they failed to attain higher accuracy due to several factors. Therefore, machine learning methods such as support vector regression (SVR), general regression neural networks (GRNNs), radial basis functional neural networks (RBFNNs), and back-propagation neural networks (BPNNs) are demonstrated to predict the paddy yield accurately for the Cauvery Delta Zone (CDZ), which lies in the eastern part of Tamil Nadu, South India. The performance of each developed model is examined using assessment metrics such as coefficient of determination (R2), root mean square error (RMSE), mean absolute error (MAE), mean squared error (MSE), mean absolute percentage error (MAPE), coefficient of variance (CV), and normalized mean squared error (NMSE). The observed results show that the GRNN algorithm delivers superior evaluation metrics such as R2, RMSE, MAE, MSE, MAPE, CV, and NSME values about 0.9863, 0.2295 and 0.1290, 0.0526, 1.3439, 0.0255, and 0.0136, respectively, which ensures accurate crop yield prediction compared with other methods. Finally, the performance of the GRNN model is compared with other available models from several studies in the literature, and it is found to be high while comparing the prediction accuracy using evaluation metrics.},
DOI = {10.3390/agronomy11102068}
}



@Article{rs13204134,
AUTHOR = {Bao, Wenxia and Ren, Yangxun and Wang, Nian and Hu, Gensheng and Yang, Xianjun},
TITLE = {Detection of Abnormal Vibration Dampers on Transmission Lines in UAV Remote Sensing Images with PMA-YOLO},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4134},
URL = {https://www.mdpi.com/2072-4292/13/20/4134},
ISSN = {2072-4292},
ABSTRACT = {The accurate detection and timely replacement of abnormal vibration dampers on transmission lines are critical for the safe and stable operation of power systems. Recently, unmanned aerial vehicles (UAVs) have become widely used to inspect transmission lines. In this paper, we constructed a data set of abnormal vibration dampers (DAVDs) on transmission lines in images obtained by UAVs. There are four types of vibration dampers in this data set, and each vibration damper may be rusty, defective, or normal. The challenges in the detection of abnormal vibration dampers on transmission lines in the images captured by UAVs were as following: the images had a high resolution as well as the objects of vibration dampers were relatively small and sparsely distributed, and the backgrounds of cross stage partial networks of the images were complex due to the fact that the transmission lines were erected in a variety of outdoor environments. Existing methods of ground-based object detection significantly reduced the accuracy when dealing with complex backgrounds and small objects of abnormal vibration dampers detection. To address these issues, we proposed an end-to-end parallel mixed attention You Only Look Once (PMA-YOLO) network to improve the detection performance for abnormal vibration dampers. The parallel mixed attention (PMA) module was introduced and integrated into the YOLOv4 network. This module combines a channel attention block and a spatial attention block, and the convolution results of the input feature maps in parallel, allowing the network to pay more attention to critical regions of abnormal vibration dampers in complex background images. Meanwhile, in view of the problem that abnormal vibration dampers are prone to missing detections, we analyzed the scale and ratio of the ground truth boxes and used the K-means algorithm to re-cluster new anchors for abnormal vibration dampers in images. In addition, we introduced a multi-stage transfer learning strategy to improve the efficiency of the original training method and prevent overfitting by the network. The experimental results showed that the mAP@0.5 for PMA-YOLO in the detection of abnormal vibration dampers reached 93.8% on the test set of DAVD, 3.5% higher than that of YOLOv4. When the multi-stage transfer learning strategy was used, the mAP@0.5 was improved by a further 0.2%.},
DOI = {10.3390/rs13204134}
}



@Article{bdcc5040056,
AUTHOR = {Hao, Yixue and Miao, Yiming and Chen, Min and Gharavi, Hamid and Leung, Victor C. M.},
TITLE = {6G Cognitive Information Theory: A Mailbox Perspective},
JOURNAL = {Big Data and Cognitive Computing},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {56},
URL = {https://www.mdpi.com/2504-2289/5/4/56},
ISSN = {2504-2289},
ABSTRACT = {With the rapid development of 5G communications, enhanced mobile broadband, massive machine type communications and ultra-reliable low latency communications are widely supported. However, a 5G communication system is still based on Shannon’s information theory, while the meaning and value of information itself are not taken into account in the process of transmission. Therefore, it is difficult to meet the requirements of intelligence, customization, and value transmission of 6G networks. In order to solve the above challenges, we propose a 6G mailbox theory, namely a cognitive information carrier to enable distributed algorithm embedding for intelligence networking. Based on Mailbox, a 6G network will form an intelligent agent with self-organization, self-learning, self-adaptation, and continuous evolution capabilities. With the intelligent agent, redundant transmission of data can be reduced while the value transmission of information can be improved. Then, the features of mailbox principle are introduced, including polarity, traceability, dynamics, convergence, figurability, and dependence. Furthermore, key technologies with which value transmission of information can be realized are introduced, including knowledge graph, distributed learning, and blockchain. Finally, we establish a cognitive communication system assisted by deep learning. The experimental results show that, compared with a traditional communication system, our communication system performs less data transmission quantity and error.},
DOI = {10.3390/bdcc5040056}
}



@Article{s21206880,
AUTHOR = {Chang, Cheng and Feng, Lina and Zhou, Hui and Zhao, Zilong and Gu, Xin},
TITLE = {Efficient Non-Uniform Pilot Design for TDCS},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {6880},
URL = {https://www.mdpi.com/1424-8220/21/20/6880},
PubMedID = {34696092},
ISSN = {1424-8220},
ABSTRACT = {The Internet of Things (IoT) leads the era of interconnection, where numerous sensors and devices are being introduced and interconnected. To support such an amount of data traffic, wireless communication technologies have to overcome available spectrum shortage and complex fading channels. The transform domain communication system (TDCS) is a cognitive anti-interference communication system with a low probability of detection and dynamic spectrum sensing and accessing. However, the non-continuous and asymmetric spectrum brings new challenges to the traditional TDCS block-type pilot, which uses a series of discrete symbols in the time domain as pilots. Low efficiency and poor adaptability in fast-varying channels are the main drawbacks for the block-type pilot in TDCS. In this study, a frequency domain non-uniform pilot design method was proposed with intersecting, skewing, and edging of three typical non-uniform pilots. Some numerical examples are also presented with multipath model COST207RAx4 to verify the proposed methods in the bit error ratio and the mean square error. Compared with traditional block-type pilot, the proposed method can adapt to the fast-varying channels, as well as the non-continuous and asymmetric spectrum conditions with much higher efficiency.},
DOI = {10.3390/s21206880}
}



@Article{app11209680,
AUTHOR = {Zhou, Xuan and Ke, Ruimin and Yang, Hao and Liu, Chenxi},
TITLE = {When Intelligent Transportation Systems Sensing Meets Edge Computing: Vision and Challenges},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {9680},
URL = {https://www.mdpi.com/2076-3417/11/20/9680},
ISSN = {2076-3417},
ABSTRACT = {The widespread use of mobile devices and sensors has motivated data-driven applications that can leverage the power of big data to benefit many aspects of our daily life, such as health, transportation, economy, and environment. Under the context of smart city, intelligent transportation systems (ITS), as a main building block of modern cities, and edge computing (EC), as an emerging computing service that targets addressing the limitations of cloud computing, have attracted increasing attention in the research community in recent years. It is well believed that the application of EC in ITS will have considerable benefits to transportation systems regarding efficiency, safety, and sustainability. Despite the growing trend in ITS and EC research, a big gap in the existing literature is identified: the intersection between these two promising directions has been far from well explored. In this paper, we focus on a critical part of ITS, i.e., sensing, and conducting a review on the recent advances in ITS sensing and EC applications in this field. The key challenges in ITS sensing and future directions with the integration of edge computing are discussed.},
DOI = {10.3390/app11209680}
}



@Article{drones5040120,
AUTHOR = {Muñoz, Javier and López, Blanca and Quevedo, Fernando and Monje, Concepción A. and Garrido, Santiago and Moreno, Luis E.},
TITLE = {Coverage Strategy for Target Location in Marine Environments Using Fixed-Wing UAVs},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {120},
URL = {https://www.mdpi.com/2504-446X/5/4/120},
ISSN = {2504-446X},
ABSTRACT = {In this paper, we propose a coverage method for the search of lost targets or debris on the ocean surface. The OSCAR data set is used to determine the marine currents and the differential evolution genetic filter is used to optimize the sweep direction of the lawnmower coverage and get the sweep angle for the maximum probability of containment. The position of the target is determined by a particle filter, where the particles are moved by the ocean currents and the final probabilistic distribution is obtained by fitting the particle positions to a Gaussian probability distribution. The differential evolution algorithm is then used to optimize the sweep direction that covers the highest probability of containment cells before the less probable ones. The algorithm is tested with a variety of parameters of the differential evolution algorithm and compared to other popular optimization algorithms.},
DOI = {10.3390/drones5040120}
}



@Article{s21206884,
AUTHOR = {Dębski, Roman and Dreżewski, Rafał},
TITLE = {Adaptive Segmentation of Streaming Sensor Data on Edge Devices},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {6884},
URL = {https://www.mdpi.com/1424-8220/21/20/6884},
PubMedID = {34696096},
ISSN = {1424-8220},
ABSTRACT = {Sensor data streams often represent signals/trajectories which are twice differentiable (e.g., to give a continuous velocity and acceleration), and this property must be reflected in their segmentation. An adaptive streaming algorithm for this problem is presented. It is based on the greedy look-ahead strategy and is built on the concept of a cubic splinelet. A characteristic feature of the proposed algorithm is the real-time simultaneous segmentation, smoothing, and compression of data streams. The segmentation quality is measured in terms of the signal approximation accuracy and the corresponding compression ratio. The numerical results show the relatively high compression ratios (from 135 to 208, i.e., compressed stream sizes up to 208 times smaller) combined with the approximation errors comparable to those obtained from the state-of-the-art global reference algorithm. The proposed algorithm can be applied to various domains, including online compression and/or smoothing of data streams coming from sensors, real-time IoT analytics, and embedded time-series databases.},
DOI = {10.3390/s21206884}
}



@Article{rs13204155,
AUTHOR = {Ahmad, Uzair and Alvino, Arturo and Marino, Stefano},
TITLE = {A Review of Crop Water Stress Assessment Using Remote Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4155},
URL = {https://www.mdpi.com/2072-4292/13/20/4155},
ISSN = {2072-4292},
ABSTRACT = {Currently, the world is facing high competition and market risks in improving yield, crop illness, and crop water stress. This could potentially be addressed by technological advancements in the form of precision systems, improvements in production, and through ensuring the sustainability of development. In this context, remote-sensing systems are fully equipped to address the complex and technical assessment of crop production, security, and crop water stress in an easy and efficient way. They provide simple and timely solutions for a diverse set of ecological zones. This critical review highlights novel methods for evaluating crop water stress and its correlation with certain measurable parameters, investigated using remote-sensing systems. Through an examination of previous literature, technologies, and data, we review the application of remote-sensing systems in the analysis of crop water stress. Initially, the study presents the relationship of relative water content (RWC) with equivalent water thickness (EWT) and soil moisture crop water stress. Evapotranspiration and sun-induced chlorophyll fluorescence are then analyzed in relation to crop water stress using remote sensing. Finally, the study presents various remote-sensing technologies used to detect crop water stress, including optical sensing systems, thermometric sensing systems, land-surface temperature-sensing systems, multispectral (spaceborne and airborne) sensing systems, hyperspectral sensing systems, and the LiDAR sensing system. The study also presents the future prospects of remote-sensing systems in analyzing crop water stress and how they could be further improved.},
DOI = {10.3390/rs13204155}
}



@Article{app11209691,
AUTHOR = {Muhadi, Nur Atirah and Abdullah, Ahmad Fikri and Bejo, Siti Khairunniza and Mahadi, Muhammad Razif and Mijic, Ana},
TITLE = {Deep Learning Semantic Segmentation for Water Level Estimation Using Surveillance Camera},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {9691},
URL = {https://www.mdpi.com/2076-3417/11/20/9691},
ISSN = {2076-3417},
ABSTRACT = {The interest in visual-based surveillance systems, especially in natural disaster applications, such as flood detection and monitoring, has increased due to the blooming of surveillance technology. In this work, semantic segmentation based on convolutional neural networks (CNN) was proposed to identify water regions from the surveillance images. This work presented two well-established deep learning algorithms, DeepLabv3+ and SegNet networks, and evaluated their performances using several evaluation metrics. Overall, both networks attained high accuracy when compared to the measurement data but the DeepLabv3+ network performed better than the SegNet network, achieving over 90% for overall accuracy and IoU metrics, and around 80% for boundary F1 score (BF score), respectively. When predicting new images using both trained networks, the results show that both networks successfully distinguished water regions from the background but the outputs from DeepLabv3+ were more accurate than the results from the SegNet network. Therefore, the DeepLabv3+ network was used for practical application using a set of images captured at five consecutive days in the study area. The segmentation result and water level markers extracted from light detection and ranging (LiDAR) data were overlaid to estimate river water levels and observe the water fluctuation. River water levels were predicted based on the elevation from the predefined markers. The proposed water level framework was evaluated according to Spearman’s rank-order correlation coefficient. The correlation coefficient was 0.91, which indicates a strong relationship between the estimated water level and observed water level. Based on these findings, it can be concluded that the proposed approach has high potential as an alternative monitoring system that offers water region information and water level estimation for flood management and related activities.},
DOI = {10.3390/app11209691}
}



@Article{app11209714,
AUTHOR = {Jeong, Hoseong and Jeong, Baekeun and Han, Myounghee and Cho, Dooyong},
TITLE = {Analysis of Fine Crack Images Using Image Processing Technique and High-Resolution Camera},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {9714},
URL = {https://www.mdpi.com/2076-3417/11/20/9714},
ISSN = {2076-3417},
ABSTRACT = {Visual inspections are performed to investigate cracks in concrete infrastructure. These activities require manpower or equipment such as articulated ladders. Additionally, there are health and safety issues because some structures have low accessibility. To deal with these problems, crack measurement with digital images and digital image processing (DIP) techniques have been adopted in various studies. The objective of this experimental study is to evaluate the optical limit of digital camera lenses as working distance increases. Three different lenses and two digital cameras were used to capture images of lines ranging from 0.1 to 0.5 mm in thickness. As a result of the experiments, it was found that many elements affect width measurement. However, crack width measurement is dependent on the measured pixel values. To accurately measure width, the measured pixel values must be in decimal units, but that is theoretically impossible. According to the results, in the case of 0.3 mm wide or wider cracks, a working distance of 1 m was secured when the focal length was 50 mm, and working distances of 3 m and 4 m were secured when the focal length was 100 mm and 135 mm, respectively. However, for cracks not wider than 0.1 mm, focal lengths of 100 mm and 135 mm showed measurability within 1 m, but a focal length of 50 mm was judged to hardly enable measurement except for certain working positions. Field measurement tests were conducted to verify measurement parameters identified by the results of the indoor experiment. The widths of actual cracks were measured through visual inspection and used for the analysis. From the evaluation, it was confirmed that the number of pixels corresponding to the working distance had a great influence on crack width measurement accuracy when using image processing. Therefore, the optimal distance and measurement guidelines required for the measurement of the size of certain objects was presented for the imaging equipment and optical equipment applied in this study.},
DOI = {10.3390/app11209714}
}



@Article{jimaging7100217,
AUTHOR = {Nguyen, Tran Xuan Bach and Rosser, Kent and Chahl, Javaan},
TITLE = {A Review of Modern Thermal Imaging Sensor Technology and Applications for Autonomous Aerial Navigation},
JOURNAL = {Journal of Imaging},
VOLUME = {7},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {217},
URL = {https://www.mdpi.com/2313-433X/7/10/217},
PubMedID = {34677303},
ISSN = {2313-433X},
ABSTRACT = {Limited navigation capabilities of many current robots and UAVs restricts their applications in GPS denied areas. Large aircraft with complex navigation systems rely on a variety of sensors including radio frequency aids and high performance inertial systems rendering them somewhat resistant to GPS denial. The rapid development of computer vision has seen cameras incorporated into small drones. Vision-based systems, consisting of one or more cameras, could arguably satisfy both size and weight constraints faced by UAVs. A new generation of thermal sensors is available that are lighter, smaller and widely available. Thermal sensors are a solution to enable navigation in difficult environments, including in low-light, dust or smoke. The purpose of this paper is to present a comprehensive literature review of thermal sensors integrated into navigation systems. Furthermore, the physics and characteristics of thermal sensors will also be presented to provide insight into challenges when integrating thermal sensors in place of conventional visual spectrum sensors.},
DOI = {10.3390/jimaging7100217}
}



@Article{educsci11110661,
AUTHOR = {Alhalabi, Marah and Ghazal, Mohammed and Haneefa, Fasila and Yousaf, Jawad and El-Baz, Ayman},
TITLE = {Smartphone Handwritten Circuits Solver Using Augmented Reality and Capsule Deep Networks for Engineering Education},
JOURNAL = {Education Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {661},
URL = {https://www.mdpi.com/2227-7102/11/11/661},
ISSN = {2227-7102},
ABSTRACT = {Resolving circuit diagrams is a regular part of learning for school and university students from engineering backgrounds. Simulating circuits is usually done manually by creating circuit diagrams on circuit tools, which is a time-consuming and tedious process. We propose an innovative method of simulating circuits from hand-drawn diagrams using smartphones through an image recognition system. This method allows students to use their smartphones to capture images instead of creating circuit diagrams before simulation. Our contribution lies in building a circuit recognition system using a deep learning capsule networks algorithm. The developed system receives an image captured by a smartphone that undergoes preprocessing, region proposal, classification, and node detection to get a Netlist and exports it to a circuit simulator program for simulation. We aim to improve engineering education using smartphones by (1) achieving higher accuracy using less training data with capsule networks and (2) developing a comprehensive system that captures hand-drawn circuit diagrams and produces circuit simulation results. We use 400 samples per class and report an accuracy of 96% for stratified 5-fold cross-validation. Through testing, we identify the optimum distance for taking circuit images to be 10 to 20 cm. Our proposed model can identify components of different scales and rotations.},
DOI = {10.3390/educsci11110661}
}



@Article{rs13214196,
AUTHOR = {Koay, Hong Vin and Chuah, Joon Huang and Chow, Chee-Onn and Chang, Yang-Lang and Yong, Keh Kok},
TITLE = {YOLO-RTUAV: Towards Real-Time Vehicle Detection through Aerial Images with Low-Cost Edge Devices},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4196},
URL = {https://www.mdpi.com/2072-4292/13/21/4196},
ISSN = {2072-4292},
ABSTRACT = {Object detection in aerial images has been an active research area thanks to the vast availability of unmanned aerial vehicles (UAVs). Along with the increase of computational power, deep learning algorithms are commonly used for object detection tasks. However, aerial images have large variations, and the object sizes are usually small, rendering lower detection accuracy. Besides, real-time inferencing on low-cost edge devices remains an open-ended question. In this work, we explored the usage of state-of-the-art deep learning object detection on low-cost edge hardware. We propose YOLO-RTUAV, an improved version of YOLOv4-Tiny, as the solution. We benchmarked our proposed models with various state-of-the-art models on the VAID and COWC datasets. Our proposed model can achieve higher mean average precision (mAP) and frames per second (FPS) than other state-of-the-art tiny YOLO models, especially on a low-cost edge device such as the Jetson Nano 2 GB. It was observed that the Jetson Nano 2 GB can achieve up to 12.8 FPS with a model size of only 5.5 MB.},
DOI = {10.3390/rs13214196}
}



@Article{rs13214214,
AUTHOR = {Yermolaev, Oleg and Usmanov, Bulat and Gafurov, Artur and Poesen, Jean and Vedeneeva, Evgeniya and Lisetskii, Fedor and Nicu, Ionut Cristi},
TITLE = {Assessment of Shoreline Transformation Rates and Landslide Monitoring on the Bank of Kuibyshev Reservoir (Russia) Using Multi-Source Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4214},
URL = {https://www.mdpi.com/2072-4292/13/21/4214},
ISSN = {2072-4292},
ABSTRACT = {This study focuses on the Kuibyshev reservoir (Volga River basin, Russia)—the largest in Eurasia and the third in the world by area (6150 km2). The objective of this paper is to quantitatively assess the dynamics of reservoir bank landslides and shoreline abrasion at active zones based on the integrated use of modern instrumental methods (i.e., terrestrial laser scanning—TLS, unmanned aerial vehicle—UAV, and a global navigation satellite system—GNSS) and GIS analysis of historical imagery. A methodology for the application of different methods of instrumental assessment of abrasion and landslide processes is developed. Different approaches are used to assess the intensity of landslide and abrasion processes: the specific volume and material loss index, the planar displacement of the bank scarp, and the planar-altitude analysis of displaced soil material based on the analysis of slope profiles. Historical shoreline position (1958, 1985, and 1987) was obtained from archival aerial photo data, whereas data for 1975, 1993, 2010, 2011, and 2012 were obtained from high-resolution satellite image interpretation. Field surveys of the geomorphic processes from 2002, 2003, 2005, 2006, 2014 were carried out using Trimble M3 and Trimble VX total stations; in 2012–2014 and 2019 TLS and UAV surveys were made, respectively. The monitoring of landslide processes showed that the rate of volumetric changes at Site 1 remained rather stable during the measurement period with net material losses of 0.03–0.04 m−3 m−2 yr−1. The most significant contribution to the average annual value of the material loss was snowmelt runoff. The landslide scarp retreat rate at Site 2 showed a steady decreasing trend, due to partial overgrowth of the landslide accumulation zone resulting in its relative stabilization. The average long-term landslide scarp retreat rate is—2.3 m yr−1. In 2019 earthworks for landscaping at this site have reduced the landslide intensity by more than 2.5 times to—0.84 m yr−1.},
DOI = {10.3390/rs13214214}
}



@Article{app11219830,
AUTHOR = {Wang, Qipeng and Zhao, Shulong and Wang, Xiangke},
TITLE = {Distributed Control for Coordinated Tracking of Fixed-Wing Unmanned Aerial Vehicles under Model Uncertainty and Disturbances},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {9830},
URL = {https://www.mdpi.com/2076-3417/11/21/9830},
ISSN = {2076-3417},
ABSTRACT = {In this paper, we consider a control problem where a group of fixed-wing unmanned aerial vehicles (UAVs) with uncertain dynamics tracks the target vehicle cooperatively in the case of external disturbance. Based on the Gaussian process regression, a data-driven model is established, whose uniform error is bounded with probability. Then a learning-based consensus protocol for multi-UAVs is designed. The stability of the system is proven via Lyapunov function, and the tracking error is guaranteed to be bounded with a high probability. Finally, the effectiveness of the proposed method is shown in the numerical simulation.},
DOI = {10.3390/app11219830}
}



@Article{mi12111285,
AUTHOR = {Cai, Qi and Zhao, Fanjing and Kang, Qiang and Luo, Zhaoqian and Hu, Duo and Liu, Jiwen and Cao, Huiliang},
TITLE = {A Novel Parallel Processing Model for Noise Reduction and Temperature Compensation of MEMS Gyroscope},
JOURNAL = {Micromachines},
VOLUME = {12},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {1285},
URL = {https://www.mdpi.com/2072-666X/12/11/1285},
ISSN = {2072-666X},
ABSTRACT = {To eliminate the noise and temperature drift in an Micro-Electro-Mechanical Systems (MEMS) gyroscope’s output signal for improving measurement accuracy, a parallel processing model based on Multi-objective particle swarm optimization based on variational modal decomposition-time-frequency peak filter (MOVMD–TFPF) and Beetle antennae search algorithm- Elman neural network (BAS–Elman NN) is established. Firstly, variational mode decomposition (VMD) is optimized by multi-objective particle swarm optimization (MOPSO); then, the best decomposition parameters [kbest,abest] can be obtained. Secondly, the gyroscope output signals are decomposed by VMD optimized by MOPSO (MOVMD); then, the intrinsic mode functions (IMFs) obtained after decomposition are classified into a noise segment, mixed segment, and drift segment by sample entropy (SE). According to the idea of a parallel model, the noise segment can be discarded directly, the mixed segment is denoised by time-frequency peak filtering (TFPF), and the drift segment is compensated at the same time. In the compensation part, the beetle antennae search algorithm (BAS) is adopted to optimize the network parameters of the Elman neural network (Elman NN). Subsequently, the double-input/single-output temperature compensation model based on the BAS-Elman NN is established to compensate the drift segment, and these processed segments are reconstructed to form the final gyroscope output signal. Experimental results demonstrate the superiority of this parallel processing model; the angle random walk of the compensated gyroscope output is decreased from 0.531076 to 5.22502 × 10−3°/h/√Hz, and its bias stability is decreased from 32.7364°/h to 0.140403°/h, respectively.},
DOI = {10.3390/mi12111285}
}



@Article{app11219844,
AUTHOR = {Yuan, Xinzhe and Tanksley, Dustin and Li, Liujun and Zhang, Haibin and Chen, Genda and Wunsch, Donald},
TITLE = {Faster Post-Earthquake Damage Assessment Based on 1D Convolutional Neural Networks},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {9844},
URL = {https://www.mdpi.com/2076-3417/11/21/9844},
ISSN = {2076-3417},
ABSTRACT = {Contemporary deep learning approaches for post-earthquake damage assessments based on 2D convolutional neural networks (CNNs) require encoding of ground motion records to transform their inherent 1D time series to 2D images, thus requiring high computing time and resources. This study develops a 1D CNN model to avoid the costly 2D image encoding. The 1D CNN model is compared with a 2D CNN model with wavelet transform encoding and a feedforward neural network (FNN) model to evaluate prediction performance and computational efficiency. A case study of a benchmark reinforced concrete (r/c) building indicated that the 1D CNN model achieved a prediction accuracy of 81.0%, which was very close to the 81.6% prediction accuracy of the 2D CNN model and much higher than the 70.8% prediction accuracy of the FNN model. At the same time, the 1D CNN model reduced computing time by more than 90% and reduced resources used by more than 69%, as compared to the 2D CNN model. Therefore, the developed 1D CNN model is recommended for rapid and accurate resultant damage assessment after earthquakes.},
DOI = {10.3390/app11219844}
}



@Article{rs13214235,
AUTHOR = {Jia, Jianxin and Sun, Haibin and Jiang, Changhui and Karila, Kirsi and Karjalainen, Mika and Ahokas, Eero and Khoramshahi, Ehsan and Hu, Peilun and Chen, Chen and Xue, Tianru and Wang, Tinghuai and Chen, Yuwei and Hyyppä, Juha},
TITLE = {Review on Active and Passive Remote Sensing Techniques for Road Extraction},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4235},
URL = {https://www.mdpi.com/2072-4292/13/21/4235},
ISSN = {2072-4292},
ABSTRACT = {Digital maps of road networks are a vital part of digital cities and intelligent transportation. In this paper, we provide a comprehensive review on road extraction based on various remote sensing data sources, including high-resolution images, hyperspectral images, synthetic aperture radar images, and light detection and ranging. This review is divided into three parts. Part 1 provides an overview of the existing data acquisition techniques for road extraction, including data acquisition methods, typical sensors, application status, and prospects. Part 2 underlines the main road extraction methods based on four data sources. In this section, road extraction methods based on different data sources are described and analysed in detail. Part 3 presents the combined application of multisource data for road extraction. Evidently, different data acquisition techniques have unique advantages, and the combination of multiple sources can improve the accuracy of road extraction. The main aim of this review is to provide a comprehensive reference for research on existing road extraction technologies.},
DOI = {10.3390/rs13214235}
}



@Article{rs13214272,
AUTHOR = {Omarzadeh, Davoud and Karimzadeh, Sadra and Matsuoka, Masashi and Feizizadeh, Bakhtiar},
TITLE = {Earthquake Aftermath from Very High-Resolution WorldView-2 Image and Semi-Automated Object-Based Image Analysis (Case Study: Kermanshah, Sarpol-e Zahab, Iran)},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4272},
URL = {https://www.mdpi.com/2072-4292/13/21/4272},
ISSN = {2072-4292},
ABSTRACT = {This study aimed to classify an urban area and its surrounding objects after the destructive M7.3 Kermanshah earthquake (12 November 2017) in the west of Iran using very high-resolution (VHR) post-event WorldView-2 images and object-based image analysis (OBIA) methods. The spatial resolution of multispectral (MS) bands (~2 m) was first improved using a pan-sharpening technique that provides a solution by fusing the information of the panchromatic (PAN) and MS bands to generate pan-sharpened images with a spatial resolution of about 50 cm. After applying a segmentation procedure, the classification step was considered as the main process of extracting the aimed features. The aforementioned classification method includes applying spectral and shape indices. Then, the classes were defined as follows: type 1 (settlement area) was collapsed areas, non-collapsed areas, and camps; type 2 (vegetation area) was orchards, cultivated areas, and urban green spaces; and type 3 (miscellaneous area) was rocks, rivers, and bare lands. As OBIA results in the integration of the spatial characteristics of the image object, we also aimed to evaluate the efficiency of object-based features for damage assessment within the semi-automated approach. For this goal, image context assessment algorithms (e.g., textural parameters, shape, and compactness) together with spectral information (e.g., brightness and standard deviation) were applied within the integrated approach. The classification results were satisfactory when compared with the reference map for collapsed buildings provided by UNITAR (the United Nations Institute for Training and Research). In addition, the number of temporary camps was counted after applying OBIA, indicating that 10,249 tents or temporary shelters were established for homeless people up to 17 November 2018. Based on the total damaged population, the essential resources such as emergency equipment, canned food and water bottles can be estimated. The research makes a significant contribution to the development of remote sensing science by means of applying different object-based image-analyzing techniques and evaluating their efficiency within the semi-automated approach, which, accordingly, supports the efficient application of these methods to other worldwide case studies.},
DOI = {10.3390/rs13214272}
}



@Article{jsan10040061,
AUTHOR = {Alrubayyi, Hadeel and Goteng, Gokop and Jaber, Mona and Kelly, James},
TITLE = {Challenges of Malware Detection in the IoT and a Review of Artificial Immune System Approaches},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {10},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {61},
URL = {https://www.mdpi.com/2224-2708/10/4/61},
ISSN = {2224-2708},
ABSTRACT = {The fast growth of the Internet of Things (IoT) and its diverse applications increase the risk of cyberattacks, one type of which is malware attacks. Due to the IoT devices’ different capabilities and the dynamic and ever-evolving environment, applying complex security measures is challenging, and applying only basic security standards is risky. Artificial Immune Systems (AIS) are intrusion-detecting algorithms inspired by the human body’s adaptive immune system techniques. Most of these algorithms imitate the human’s body B-cell and T-cell defensive mechanisms. They are lightweight, adaptive, and able to detect malware attacks without prior knowledge. In this work, we review the recent advances in employing AIS for the improved detection of malware in IoT networks. We present a critical analysis that highlights the limitations of the state-of-the-art in AIS research and offer insights into promising new research directions.},
DOI = {10.3390/jsan10040061}
}



@Article{rs13214294,
AUTHOR = {Nitze, Ingmar and Heidler, Konrad and Barth, Sophia and Grosse, Guido},
TITLE = {Developing and Testing a Deep Learning Approach for Mapping Retrogressive Thaw Slumps},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4294},
URL = {https://www.mdpi.com/2072-4292/13/21/4294},
ISSN = {2072-4292},
ABSTRACT = {In a warming Arctic, permafrost-related disturbances, such as retrogressive thaw slumps (RTS), are becoming more abundant and dynamic, with serious implications for permafrost stability and bio-geochemical cycles on local to regional scales. Despite recent advances in the field of earth observation, many of these have remained undetected as RTS are highly dynamic, small, and scattered across the remote permafrost region. Here, we assessed the potential strengths and limitations of using deep learning for the automatic segmentation of RTS using PlanetScope satellite imagery, ArcticDEM and auxiliary datasets. We analyzed the transferability and potential for pan-Arctic upscaling and regional cross-validation, with independent training and validation regions, in six different thaw slump-affected regions in Canada and Russia. We further tested state-of-the-art model architectures (UNet, UNet++, DeepLabv3) and encoder networks to find optimal model configurations for potential upscaling to continental scales. The best deep learning models achieved mixed results from good to very good agreement in four of the six regions (maxIoU: 0.39 to 0.58; Lena River, Horton Delta, Herschel Island, Kolguev Island), while they failed in two regions (Banks Island, Tuktoyaktuk). Of the tested architectures, UNet++ performed the best. The large variance in regional performance highlights the requirement for a sufficient quantity, quality and spatial variability in the training data used for segmenting RTS across diverse permafrost landscapes, in varying environmental conditions. With our highly automated and configurable workflow, we see great potential for the transfer to active RTS clusters (e.g., Peel Plateau) and upscaling to much larger regions.},
DOI = {10.3390/rs13214294}
}



@Article{agriculture11111049,
AUTHOR = {Chang, Chung-Liang and Xie, Bo-Xuan and Chung, Sheng-Cheng},
TITLE = {Mechanical Control with a Deep Learning Method for Precise Weeding on a Farm},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {1049},
URL = {https://www.mdpi.com/2077-0472/11/11/1049},
ISSN = {2077-0472},
ABSTRACT = {This paper presents a mechanical control method for precise weeding based on deep learning. Deep convolutional neural network was used to identify and locate weeds. A special modular weeder was designed, which can be installed on the rear of a mobile platform. An inverted pyramid-shaped weeding tool equipped in the modular weeder can shovel out weeds without being contaminated by soil. The weed detection and control method was implemented on an embedded system with a high-speed graphics processing unit and integrated with the weeder. The experimental results showed that even if the speed of the mobile platform reaches 20 cm/s, the weeds can still be accurately detected and the position of the weeds can be located by the system. Moreover, the weeding mechanism can successfully shovel out the roots of the weeds. The proposed weeder has been tested in the field, and its performance and weed coverage have been verified to be precise for weeding.},
DOI = {10.3390/agriculture11111049}
}



@Article{agronomy11112145,
AUTHOR = {Gao, Peng and Xie, Jiaxing and Yang, Mingxin and Zhou, Ping and Liang, Gaotian and Chen, Yufeng and Sun, Daozong and Han, Xiongzhe and Wang, Weixing},
TITLE = {Predicting the Photosynthetic Rate of Chinese Brassica Using Deep Learning Methods},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2145},
URL = {https://www.mdpi.com/2073-4395/11/11/2145},
ISSN = {2073-4395},
ABSTRACT = {Water stress is a significant element impacting photosynthesis, which is one of the major physiological activities governing crop growth and development. In this study, the photosynthetic rate of Brassica chinensis L. var. parachinensis (Bailey) (referred to as Chinese Brassica hereafter) was predicted using the deep learning method. Five sets of Chinese Brassica were created, each with a different water stress gradient. Air temperature (Ta), relative humidity (RH), canopy temperature (Tc), transpiration rate (Tr), photosynthetic rate (Pn), and photosynthetically available radiation (PAR) were measured in different growth stages. The upper limit and lower limit equations were built using the non-water-stress baseline (NWSB) and hierarchical density-based spatial clustering of applications with noise (HDBSCAN) methods. The crop water stress index (CWSI) was then calculated using these built equations. The multivariate long short-term memory (MLSTM) model was proposed to predict Pn based on CWSI and other parameters. At the same time, the support vector regression (SVR) method was applied to provide a comparison to the MSLTM model. The results show that water stress had an important effect on the growth of Chinese Brassica. The more serious the water stress, the lower the growth range (GR). The HDBSCAN method had a lower root mean square error (RMSE) in calculating CWSI. Furthermore, the CWSI had a significant effect on predicting Pn. The regression fitting between measured Pn and predicted Pn showed that the determination coefficient (R2) and RMSE were 0.899 and 0.108 μmol·m−2·s−1, respectively. In this study, we successfully developed a method for the reliable prediction of Pn in Chinese Brassica, which can serve as a useful reference for application in water saving.},
DOI = {10.3390/agronomy11112145}
}



@Article{rs13214302,
AUTHOR = {Rodríguez, Andrés C. and Daudt, Rodrigo Caye and D’Aronco, Stefano and Schindler, Konrad and Wegner, Jan D.},
TITLE = {Robust Damage Estimation of Typhoon Goni on Coconut Crops with Sentinel-2 Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4302},
URL = {https://www.mdpi.com/2072-4292/13/21/4302},
ISSN = {2072-4292},
ABSTRACT = {Typhoon Goni crossed several provinces in the Philippines where agriculture has high socioeconomic importance, including the top-3 provinces in terms of planted coconut trees. We have used a computational model to infer coconut tree density from satellite images before and after the typhoon’s passage, and in this way estimate the number of damaged trees. Our area of study around the typhoon’s path covers 15.7 Mha, and includes 47 of the 87 provinces in the Philippines. In validation areas our model predicts coconut tree density with a Mean Absolute Error of 5.9 Trees/ha. In Camarines Sur we estimated that 3.5 M of the 4.6 M existing coconut trees were damaged by the typhoon. Overall we estimated that 14.1 M coconut trees were affected by the typhoon inside our area of study. Our validation images confirm that trees are rarely uprooted and damages are largely due to reduced canopy cover of standing trees. On validation areas, our model was able to detect affected coconut trees with 88.6% accuracy, 75% precision and 90% recall. Our method delivers spatially fine-grained change maps for coconut plantations in the area of study, including unchanged, damaged and new trees. Beyond immediate damage assessment, gradual changes in coconut density may serve as a proxy for future changes in yield.},
DOI = {10.3390/rs13214302}
}



@Article{math9212721,
AUTHOR = {Zhu, Jian and Huang, Da and Jiang, Haijun and Bian, Jicheng and Yu, Zhiyong},
TITLE = {Synchronizability of Multi-Layer Variable Coupling Windmill-Type Networks},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {2721},
URL = {https://www.mdpi.com/2227-7390/9/21/2721},
ISSN = {2227-7390},
ABSTRACT = {The system model on synchronizability problem of complex networks with multi-layer structure is closer to the real network than the usual single-layer case. Based on the master stability equation (MSF), this paper studies the eigenvalue spectrum of two k-layer variable coupling windmill-type networks. In the case of bounded and unbounded synchronization domain, the relationships between the synchronizability of the layered windmill-type networks and network parameters, such as the numbers of nodes and layers, inter-layers coupling strength, are studied. The simulation of the synchronizability of the layered windmill-type networks are given, and they verify the theoretical results well. Finally, the optimization schemes of the synchronizability are given from the perspective of single-layer and multi-layer networks, and it was found that the synchronizability of the layered windmill-type networks can be improved by changing the parameters appropriately.},
DOI = {10.3390/math9212721}
}



@Article{rs13214312,
AUTHOR = {Zhao, Genping and Zhang, Weiguang and Peng, Yeping and Wu, Heng and Wang, Zhuowei and Cheng, Lianglun},
TITLE = {PEMCNet: An Efficient Multi-Scale Point Feature Fusion Network for 3D LiDAR Point Cloud Classification},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4312},
URL = {https://www.mdpi.com/2072-4292/13/21/4312},
ISSN = {2072-4292},
ABSTRACT = {Point cloud classification plays a significant role in Light Detection and Ranging (LiDAR) applications. However, most available multi-scale feature learning networks for large-scale 3D LiDAR point cloud classification tasks are time-consuming. In this paper, an efficient deep neural architecture denoted as Point Expanded Multi-scale Convolutional Network (PEMCNet) is developed to accurately classify the 3D LiDAR point cloud. Different from traditional networks for point cloud processing, PEMCNet includes successive Point Expanded Grouping (PEG) units and Absolute and Relative Spatial Embedding (ARSE) units for representative point feature learning. The PEG unit enables us to progressively increase the receptive field for each observed point and aggregate the feature of a point cloud at different scales but without increasing computation. The ARSE unit following the PEG unit furthermore realizes representative encoding of points relationship, which effectively preserves the geometric details between points. We evaluate our method on both public datasets (the Urban Semantic 3D (US3D) dataset and Semantic3D benchmark dataset) and our new collected Unmanned Aerial Vehicle (UAV) based LiDAR point cloud data of the campus of Guangdong University of Technology. In comparison with four available state-of-the-art methods, our methods ranked first place regarding both efficiency and accuracy. It was observed on the public datasets that with a 2% increase in classification accuracy, over 26% improvement of efficiency was achieved at the same time compared to the second efficient method. Its potential value is also tested on the newly collected point cloud data with over 91% of classification accuracy and 154 ms of processing time.},
DOI = {10.3390/rs13214312}
}



@Article{jmse9111189,
AUTHOR = {Hu, Kai and Chen, Xu and Xia, Qingfeng and Jin, Junlan and Weng, Liguo},
TITLE = {A Control Algorithm for Sea&ndash;Air Cooperative Observation Tasks Based on a Data-Driven Algorithm},
JOURNAL = {Journal of Marine Science and Engineering},
VOLUME = {9},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {1189},
URL = {https://www.mdpi.com/2077-1312/9/11/1189},
ISSN = {2077-1312},
ABSTRACT = {There is tremendous demand for marine environmental observation, which requires the development of a multi-agent cooperative observation algorithm to guide Unmanned Surface Vehicles (USVs) and Unmanned Aerial Vehicles (UAVs) to observe isotherm data of the mesoscale vortex. The task include two steps: firstly, USVs search out the isotherm, navigate independently along the isotherm, and collect marine data; secondly, a UAV takes off, and in its one round trip, the UAV and USVs jointly perform the task of the UAV reading the observation data from USVs. In this paper, aiming at the first problem of the USV following the isotherm in an unknown environment, a data-driven Deep Deterministic Policy Gradient (DDPG) control algorithm is designed that allows USVs to navigate independently along isotherms in unknown environments. In addition, a hybrid cooperative control algorithm based on a multi-agent DDPG is adopted to solve the second problem, which enables USVs and a UAV to complete data reading tasks with the shortest flight distance of the UAV. The experimental simulation results show that the trained system can complete this tas, with good stability and accuracy.},
DOI = {10.3390/jmse9111189}
}



@Article{rs13214325,
AUTHOR = {Li, Xingdong and Gao, Hewei and Zhang, Mingxian and Zhang, Shiyu and Gao, Zhiming and Liu, Jiuqing and Sun, Shufa and Hu, Tongxin and Sun, Long},
TITLE = {Prediction of Forest Fire Spread Rate Using UAV Images and an LSTM Model Considering the Interaction between Fire and Wind},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4325},
URL = {https://www.mdpi.com/2072-4292/13/21/4325},
ISSN = {2072-4292},
ABSTRACT = {Modeling forest fire spread is a very complex problem, and the existing models usually need some input parameters which are hard to get. How to predict the time series of forest fire spread rate based on passed series may be a key problem to break through the current technical bottleneck. In the process of forest fire spreading, spread rate and wind speed would affect each other. In this paper, three kinds of network models based on Long Short-Term Memory (LSTM) are designed to predict fire spread rate, exploring the interaction between fire and wind. In order to train these LSTM-based models and validate their effectiveness of prediction, several outdoor combustion experiments are designed and carried out. Process data sets of forest fire spreading are collected with an infrared camera mounted on a UAV, and wind data sets are recorded using a anemometer simultaneously. According to the close relationship between wind and fire, three progressive LSTM based models are constructed, which are called CSG-LSTM, MDG-LSTM and FNU-LSTM, respectively. A Cross-Entropy Loss equation is employed to measure the model training quality, and then prediction accuracy is computed and analyzed by comparing with the true fire spread rate and wind speed. According to the performance of training and prediction stage, FNU-LSTM is determined as the best model for the general case. The advantage of FNU-LSTM is further demonstrated by doing comparison experiments with the normal LSTM and other LSTM based models which predict both fire spread rate and wind speed separately. The experiment has also demonstrated the ability of the model to the real fire prediction on the basis of two historical wildland fires.},
DOI = {10.3390/rs13214325}
}



@Article{electronics10212633,
AUTHOR = {Ramadan, Rabie A. and Emara, Abdel-Hamid and Al-Sarem, Mohammed and Elhamahmy, Mohamed},
TITLE = {Internet of Drones Intrusion Detection Using Deep Learning},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {2633},
URL = {https://www.mdpi.com/2079-9292/10/21/2633},
ISSN = {2079-9292},
ABSTRACT = {Flying Ad Hoc Network (FANET) or drones’ technologies have gained much attraction in the last few years due to their critical applications. Therefore, various studies have been conducted on facilitating FANET applications in different fields. In fact, civil airspaces have gradually adopted FANET technology in their systems. However, FANET’s special roles made it complex to support emerging security threats, especially intrusion detection. This paper is a step forward towards the advances in FANET intrusion detection techniques. It investigates FANET intrusion detection threats by introducing a real-time data analytics framework based on deep learning. The framework consists of Recurrent Neural Networks (RNN) as a base. It also involves collecting data from the network and analyzing it using big data analytics for anomaly detection. The data collection is performed through an agent working inside each FANET. The agent is assumed to log the FANET real-time information. In addition, it involves a stream processing module that collects the drones’ communication information, including intrusion detection-related information. This information is fed into two RNN modules for data analysis, trained for this purpose. One of the RNN modules resides inside the FANET itself, and the second module resides at the base station. An extensive set of experiments were conducted based on various datasets to examine the efficiency of the proposed framework. The results showed that the proposed framework is superior to other recent approaches.},
DOI = {10.3390/electronics10212633}
}



@Article{make3040043,
AUTHOR = {Xiang, Xuanchen and Foo, Simon and Zang, Huanyu},
TITLE = {Recent Advances in Deep Reinforcement Learning Applications for Solving Partially Observable Markov Decision Processes (POMDP) Problems Part 2—Applications in Transportation, Industries, Communications and Networking and More Topics},
JOURNAL = {Machine Learning and Knowledge Extraction},
VOLUME = {3},
YEAR = {2021},
NUMBER = {4},
PAGES = {863--878},
URL = {https://www.mdpi.com/2504-4990/3/4/43},
ISSN = {2504-4990},
ABSTRACT = {The two-part series of papers provides a survey on recent advances in Deep Reinforcement Learning (DRL) for solving partially observable Markov decision processes (POMDP) problems. Reinforcement Learning (RL) is an approach to simulate the human’s natural learning process, whose key is to let the agent learn by interacting with the stochastic environment. The fact that the agent has limited access to the information of the environment enables AI to be applied efficiently in most fields that require self-learning. It’s essential to have an organized investigation—we can make good comparisons and choose the best structures or algorithms when applying DRL in various applications. The first part of the overview introduces Markov Decision Processes (MDP) problems and Reinforcement Learning and applications of DRL for solving POMDP problems in games, robotics, and natural language processing. In part two, we continue to introduce applications in transportation, industries, communications and networking, etc. and discuss the limitations of DRL.},
DOI = {10.3390/make3040043}
}



@Article{agriengineering3040053,
AUTHOR = {Bulanon, Duke M. and Burr, Colton and DeVlieg, Marina and Braddock, Trevor and Allen, Brice},
TITLE = {Development of a Visual Servo System for Robotic Fruit Harvesting},
JOURNAL = {AgriEngineering},
VOLUME = {3},
YEAR = {2021},
NUMBER = {4},
PAGES = {840--852},
URL = {https://www.mdpi.com/2624-7402/3/4/53},
ISSN = {2624-7402},
ABSTRACT = {One of the challenges in the future of food production, amidst increasing population and decreasing resources, is developing a sustainable food production system. It is anticipated that robotics will play a significant role in maintaining the food production system, specifically in labor-intensive operations. Therefore, the main goal of this project is to develop a robotic fruit harvesting system, initially focused on the harvesting of apples. The robotic harvesting system is composed of a six-degrees-of-freedom (DOF) robotic manipulator, a two-fingered gripper, a color camera, a depth sensor, and a personal computer. This paper details the development and performance of a visual servo system that can be used for fruit harvesting. Initial test evaluations were conducted in an indoor laboratory using plastic fruit and artificial trees. Subsequently, the system was tested outdoors in a commercial fruit orchard. Evaluation parameters included fruit detection performance, response time of the visual servo, and physical time to harvest a fruit. Results of the evaluation showed that the developed visual servo system has the potential to guide the robot for fruit harvesting.},
DOI = {10.3390/agriengineering3040053}
}



@Article{rs13214347,
AUTHOR = {Khan, Rabia Munsaf and Salehi, Bahram and Mahdianpari, Masoud and Mohammadimanesh, Fariba and Mountrakis, Giorgos and Quackenbush, Lindi J.},
TITLE = {A Meta-Analysis on Harmful Algal Bloom (HAB) Detection and Monitoring: A Remote Sensing Perspective},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4347},
URL = {https://www.mdpi.com/2072-4292/13/21/4347},
ISSN = {2072-4292},
ABSTRACT = {Algae serves as a food source for a wide range of aquatic species; however, a high concentration of inorganic nutrients under favorable conditions can result in the development of harmful algal blooms (HABs). Many studies have addressed HAB detection and monitoring; however, no global scale meta-analysis has specifically explored remote sensing-based HAB monitoring. Therefore, this manuscript elucidates and visualizes spatiotemporal trends in HAB detection and monitoring using remote sensing methods and discusses future insights through a meta-analysis of 420 journal articles. The results indicate an increase in the quantity of published articles which have facilitated the analysis of sensors, software, and HAB proxy estimation methods. The comparison across multiple studies highlighted the need for a standardized reporting method for HAB proxy estimation. Research gaps include: (1) atmospheric correction methods, particularly for turbid waters, (2) the use of analytical-based models, (3) the application of machine learning algorithms, (4) the generation of harmonized virtual constellation and data fusion for increased spatial and temporal resolutions, and (5) the use of cloud-computing platforms for large scale HAB detection and monitoring. The planned hyperspectral satellites will aid in filling these gaps to some extent. Overall, this review provides a snapshot of spatiotemporal trends in HAB monitoring to assist in decision making for future studies.},
DOI = {10.3390/rs13214347}
}



@Article{app112110139,
AUTHOR = {Aguilar, Fernando J. and Nemmaoui, Abderrahim and Aguilar, Manuel A. and Peñalver, Alberto},
TITLE = {Building Tree Allometry Relationships Based on TLS Point Clouds and Machine Learning Regression},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {10139},
URL = {https://www.mdpi.com/2076-3417/11/21/10139},
ISSN = {2076-3417},
ABSTRACT = {Most of the allometric models used to estimate tree aboveground biomass rely on tree diameter at breast height (DBH). However, it is difficult to measure DBH from airborne remote sensors, and is common to draw upon traditional least squares linear regression models to relate DBH with dendrometric variables measured from airborne sensors, such as tree height (H) and crown diameter (CD). This study explores the usefulness of ensemble-type supervised machine learning regression algorithms, such as random forest regression (RFR), categorical boosting (CatBoost), gradient boosting (GBoost), or AdaBoost regression (AdaBoost), as an alternative to linear regression (LR) for modelling the allometric relationships DBH = Φ(H) and DBH = Ψ(H, CD). The original dataset was made up of 2272 teak trees (Tectona grandis Linn. F.) belonging to three different plantations located in Ecuador. All teak trees were digitally reconstructed from terrestrial laser scanning point clouds. The results showed that allometric models involving both H and CD to estimate DBH performed better than those based solely on H. Furthermore, boosting machine learning regression algorithms (CatBoost and GBoost) outperformed RFR (bagging) and LR (traditional linear regression) models, both in terms of goodness-of-fit (R2) and stability (variations in training and testing samples).},
DOI = {10.3390/app112110139}
}



@Article{drones5040127,
AUTHOR = {Raza, Wamiq and Osman, Anas and Ferrini, Francesco and Natale, Francesco De},
TITLE = {Energy-Efficient Inference on the Edge Exploiting TinyML Capabilities for UAVs},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {127},
URL = {https://www.mdpi.com/2504-446X/5/4/127},
ISSN = {2504-446X},
ABSTRACT = {In recent years, the proliferation of unmanned aerial vehicles (UAVs) has increased dramatically. UAVs can accomplish complex or dangerous tasks in a reliable and cost-effective way but are still limited by power consumption problems, which pose serious constraints on the flight duration and completion of energy-demanding tasks. The possibility of providing UAVs with advanced decision-making capabilities in an energy-effective way would be extremely beneficial. In this paper, we propose a practical solution to this problem that exploits deep learning on the edge. The developed system integrates an OpenMV microcontroller into a DJI Tello Micro Aerial Vehicle (MAV). The microcontroller hosts a set of machine learning-enabled inference tools that cooperate to control the navigation of the drone and complete a given mission objective. The goal of this approach is to leverage the new opportunistic features of TinyML through OpenMV including offline inference, low latency, energy efficiency, and data security. The approach is successfully validated on a practical application consisting of the onboard detection of people wearing protection masks in a crowded environment.},
DOI = {10.3390/drones5040127}
}



@Article{rs13214357,
AUTHOR = {Hou, Yu and Chen, Meida and Volk, Rebekka and Soibelman, Lucio},
TITLE = {An Approach to Semantically Segmenting Building Components and Outdoor Scenes Based on Multichannel Aerial Imagery Datasets},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4357},
URL = {https://www.mdpi.com/2072-4292/13/21/4357},
ISSN = {2072-4292},
ABSTRACT = {As-is building modeling plays an important role in energy audits and retrofits. However, in order to understand the source(s) of energy loss, researchers must know the semantic information of the buildings and outdoor scenes. Thermal information can potentially be used to distinguish objects that have similar surface colors but are composed of different materials. To utilize both the red–green–blue (RGB) color model and thermal information for the semantic segmentation of buildings and outdoor scenes, we deployed and adapted various pioneering deep convolutional neural network (DCNN) tools that combine RGB information with thermal information to improve the semantic and instance segmentation processes. When both types of information are available, the resulting DCNN models allow us to achieve better segmentation performance. By deploying three case studies, we experimented with our proposed DCNN framework, deploying datasets of building components and outdoor scenes, and testing the models to determine whether the segmentation performance had improved or not. In our observation, the fusion of RGB and thermal information can help the segmentation task in specific cases, but it might also make the neural networks hard to train or deteriorate their prediction performance in some cases. Additionally, different algorithms perform differently in semantic and instance segmentation.},
DOI = {10.3390/rs13214357}
}



@Article{rs13214370,
AUTHOR = {Lan, Yubin and Huang, Kanghua and Yang, Chang and Lei, Luocheng and Ye, Jiahang and Zhang, Jianling and Zeng, Wen and Zhang, Yali and Deng, Jizhong},
TITLE = {Real-Time Identification of Rice Weeds by UAV Low-Altitude Remote Sensing Based on Improved Semantic Segmentation Model},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4370},
URL = {https://www.mdpi.com/2072-4292/13/21/4370},
ISSN = {2072-4292},
ABSTRACT = {Real-time analysis of UAV low-altitude remote sensing images at airborne terminals facilitates the timely monitoring of weeds in the farmland. Aiming at the real-time identification of rice weeds by UAV low-altitude remote sensing, two improved identification models, MobileNetV2-UNet and FFB-BiSeNetV2, were proposed based on the semantic segmentation models U-Net and BiSeNetV2, respectively. The MobileNetV2-UNet model focuses on reducing the amount of calculation of the original model parameters, and the FFB-BiSeNetV2 model focuses on improving the segmentation accuracy of the original model. In this study, we first tested and compared the segmentation accuracy and operating efficiency of the models before and after the improvement on the computer platform, and then transplanted the improved models to the embedded hardware platform Jetson AGX Xavier, and used TensorRT to optimize the model structure to improve the inference speed. Finally, the real-time segmentation effect of the two improved models on rice weeds was further verified through the collected low-altitude remote sensing video data. The results show that on the computer platform, the MobileNetV2-UNet model reduced the amount of network parameters, model size, and floating point calculations by 89.12%, 86.16%, and 92.6%, and the inference speed also increased by 2.77 times, when compared with the U-Net model. The FFB-BiSeNetV2 model improved the segmentation accuracy compared with the BiSeNetV2 model and achieved the highest pixel accuracy and mean Intersection over Union ratio of 93.09% and 80.28%. On the embedded hardware platform, the optimized MobileNetV2-UNet model and FFB-BiSeNetV2 model inferred 45.05 FPS and 40.16 FPS for a single image under the weight accuracy of FP16, respectively, both meeting the performance requirements of real-time identification. The two methods proposed in this study realize the real-time identification of rice weeds under low-altitude remote sensing by UAV, which provide a reference for the subsequent integrated operation of plant protection drones in real-time rice weed identification and precision spraying.},
DOI = {10.3390/rs13214370}
}



@Article{rs13214372,
AUTHOR = {Xie, Yi and Huang, Jianxi},
TITLE = {Integration of a Crop Growth Model and Deep Learning Methods to Improve Satellite-Based Yield Estimation of Winter Wheat in Henan Province, China},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4372},
URL = {https://www.mdpi.com/2072-4292/13/21/4372},
ISSN = {2072-4292},
ABSTRACT = {Timely and accurate regional crop-yield estimates are crucial for guiding agronomic practices and policies to improve food security. In this study, a crop-growth model was integrated with time series of remotely sensed data through deep learning (DL) methods to improve the accuracy of regional wheat-yield estimations in Henan Province, China. Firstly, the time series of moderate-resolution imaging spectroradiometer (MODIS) normalized difference vegetation index (NDVI) were input into the long short-term memory network (LSTM) model to identify the wheat-growing region, which was further used to estimate wheat areas at the municipal and county levels. Then, the leaf area index (LAI) and grain-yield time series simulated by the Crop Environment REsource Synthesis for Wheat (CERES-Wheat) model were used to train and evaluate the LSTM, one-dimensional convolutional neural network (1-D CNN) and random forest (RF) models, respectively. Finally, an exponential model of the relationship between the field-measured LAI and MODIS NDVI was applied to obtain the regional LAI, which was input into the trained LSTM, 1-D CNN and RF models to estimate wheat yields within the wheat-growing region. The results showed that the linear correlations between the estimated wheat areas and the statistical areas were significant at both the municipal and county levels. The LSTM model provided more accurate estimates of wheat yields, with higher R2 values and lower root mean square error (RMSE) and mean relative error (MRE) values than the 1-D CNN and RF models. The LSTM model has an inherent advantage in capturing phenological information contained in the time series of the MODIS-derived LAI, which is important for satellite-based crop-yield estimates.},
DOI = {10.3390/rs13214372}
}



@Article{rs13214377,
AUTHOR = {Sun, Long and Chen, Jie and Feng, Dazheng and Xing, Mengdao},
TITLE = {Parallel Ensemble Deep Learning for Real-Time Remote Sensing Video Multi-Target Detection},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4377},
URL = {https://www.mdpi.com/2072-4292/13/21/4377},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle (UAV) is one of the main means of information warfare, such as in battlefield cruises, reconnaissance, and military strikes. Rapid detection and accurate recognition of key targets in UAV images are the basis of subsequent military tasks. The UAV image has characteristics of high resolution and small target size, and in practical application, the detection speed is often required to be fast. Existing algorithms are not able to achieve an effective trade-off between detection accuracy and speed. Therefore, this paper proposes a parallel ensemble deep learning framework for unmanned aerial vehicle video multi-target detection, which is a global and local joint detection strategy. It combines a deep learning target detection algorithm with template matching to make full use of image information. It also integrates multi-process and multi-threading mechanisms to speed up processing. Experiments show that the system has high detection accuracy for targets with focal lengths varying from one to ten times. At the same time, the real-time and stable display of detection results is realized by aiming at the moving UAV video image.},
DOI = {10.3390/rs13214377}
}



@Article{rs13214381,
AUTHOR = {Zhao, Lidong and Zhang, Ting and Fu, Jun and Li, Jianzhu and Cao, Zhengxiong and Feng, Ping},
TITLE = {Risk Assessment of Urban Floods Based on a SWMM-MIKE21-Coupled Model Using GF-2 Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4381},
URL = {https://www.mdpi.com/2072-4292/13/21/4381},
ISSN = {2072-4292},
ABSTRACT = {Global climate change and rapid urbanization have caused increases in urban floods. Urban flood risk assessment is a vital method for preventing and controlling such disasters. This paper takes the central region of Cangzhou city in Hebei Province as an example. Detailed topographical information, such as the buildings and roads in the study area, was extracted from GF-2 data. By coupling the two models, the SWMM and MIKE21, the spatial distribution of the inundation region, and the water depth in the study area under different return periods, were simulated in detail. The results showed that, for the different return periods, the inundation region was generally consistent. However, there was a large increase in the mean inundation depth within a 10-to-30-year return period, and the increase in the maximum inundation depth and inundation area remained steady. The comprehensive runoff coefficient in all of the scenarios exceeded 0.8, indicating that the drainage system in the study area is insufficient and has a higher flood risk. The flood risk of the study area was evaluated based on the damage curve, which was obtained from field investigations. The results demonstrate that the loss per unit area was less than CNY 250/m2 in each return period in the majority of the damaged areas. Additionally, the total loss was mainly influenced by the damaged area, but, in commercial areas, the total loss was highly sensitive to the inundation depth.},
DOI = {10.3390/rs13214381}
}



@Article{s21217270,
AUTHOR = {Bielecki, Andrzej and Śmigielski, Piotr},
TITLE = {Three-Dimensional Outdoor Analysis of Single Synthetic Building Structures by an Unmanned Flying Agent Using Monocular Vision},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7270},
URL = {https://www.mdpi.com/1424-8220/21/21/7270},
PubMedID = {34770577},
ISSN = {1424-8220},
ABSTRACT = {An algorithm designed for analysis and understanding a 3D urban-type environment by an autonomous flying agent, equipped only with a monocular vision, is presented. The algorithm is hierarchical and is based on the structural representation of the analyzed scene. Firstly, the robot observes the scene from a high altitude to build a 2D representation of a single object and a graph representation of the 2D scene. The 3D representation of each object arises as a consequence of the robot’s actions, as a result of which it projects the object’s solid on different planes. The robot assigns the obtained representations to the corresponding vertex of the created graph. The algorithm was tested by using the embodied robot operating on the real scene. The tests showed that the robot equipped with the algorithm was able not only to localize the predefined object, but also to perform safe, collision-free maneuvers close to the structures in the scene.},
DOI = {10.3390/s21217270}
}



@Article{en14217182,
AUTHOR = {Krishnasarma, Anand and Mostafavi Yazdi, Seyed Jamaleddin and Taylor, Allan and Ludwigsen, Daniel and Baqersad, Javad},
TITLE = {Acoustic Signature Analysis and Sound Source Localization for a Three-Phase AC Induction Motor},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7182},
URL = {https://www.mdpi.com/1996-1073/14/21/7182},
ISSN = {1996-1073},
ABSTRACT = {As part of the recent electrification of the transportation industry, internal combustion engines are being coupled with or replaced by electric motors. This movement towards an electrified drivetrain poses new noise, vibration, and harshness (NVH) challenges related to electric motors. In this paper, the acoustic signature of an electric motor was analyzed to obtain a better understanding of the sound generated by these motors. This work provides an insight into an acoustic measurement technique that can be used to identify certain frequency bands that significantly contribute to the perceived sound. In the first part, the structural response of the motor was correlated with its acoustic spectra. Furthermore, data from acoustic and structural measurements were used to analyze the order content of the signal and identify critical contributors to the overall perceived sound. The differences between data captured by microphones in different positions around the motor helped to localize components of the overall sound. The results provide some discussion about techniques to decrease the overall sound. The technique described in this paper can be extended to fan-cooled motors that are used in vehicles such as golf carts or as auxiliary motors in electric/hybrid vehicles, as well as across a wide range of industrial applications.},
DOI = {10.3390/en14217182}
}



@Article{su132112088,
AUTHOR = {Han, Cheng and Lu, Jilong and Chen, Shengbo and Xu, Xitong and Wang, Zibo and Pei, Zheng and Zhang, Yu and Li, Fengxuan},
TITLE = {Estimation of Heavy Metal(Loid) Contents in Agricultural Soil of the Suzi River Basin Using Optimal Spectral Indices},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {12088},
URL = {https://www.mdpi.com/2071-1050/13/21/12088},
ISSN = {2071-1050},
ABSTRACT = {For agricultural production and food safety, it is important to accurately and extensively estimate the heavy metal(loid) pollution contents in farmland soil. Remote sensing technology provides a feasible method for the rapid determination of heavy metal(loid) contents. In this study, the contents of Ni, Hg, Cr, Cu, and As in the agricultural soil of the Suzi River Basin in Liaoning Province were taken as an example. The spectral data, with Savitzky–Golay smoothing, were taken as the original spectra (OR), and the spectral transformation was achieved by continuum removal (CR), reciprocal (1/R), root means square (R), first-order differential (FDR), and second-order differential (SDR) methods. Then the spectral indices were calculated by the optimal band combination algorithm. The correlation between Ni, Hg, Cr, Cu, and As contents and spectral indices was analyzed, and the optimal spectral indices were selected. Then, multiple linear regression (MLR), partial least squares regression (PLSR), random forest regression (RFR), and adaptive neuro-fuzzy reasoning system (ANFIS) were used to establish the estimation model based on the combined optimal spectral indices method. The results show that the combined optimal spectral indices method improves the correlation between spectra and heavy metal(loid), the MLR model produces the best estimation effect for Ni and Cu (R2=0.713&nbsp;and&nbsp;0.855, RMSE = 5.053 and 8.113, RPD = 1.908 and 2.688, respectively), and the PLSR model produces the best effect for Hg, Cr, and As (R2= 0.653, 0.603, and 0.775, RMSE = 0.074, 23.777, and 1.923, RPD = 1.733, 1.621, and 2.154, respectively). Therefore, the combined optimal spectral indices method is feasible for heavy metal(loid) estimation in soils and could provide technical support for large-scale soil heavy metal(loid) content estimation and pollution assessment.},
DOI = {10.3390/su132112088}
}



@Article{inventions6040080,
AUTHOR = {Manin, Alexander A. and Sokolov, Sergey V. and Novikov, Arthur I. and Polyakova, Marianna V. and Demidov, Dmitriy N. and Novikova, Tatyana P.},
TITLE = {Kalman Filter Adaptation to Disturbances of the Observer’s Parameters},
JOURNAL = {Inventions},
VOLUME = {6},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {80},
URL = {https://www.mdpi.com/2411-5134/6/4/80},
ISSN = {2411-5134},
ABSTRACT = {Currently, one of the most effective algorithms for state estimation of stochastic systems is a Kalman filter. This filter provides an optimal root-mean-square error in state vector estimation only when the parameters of the dynamic system and its observer are precisely known. In real conditions, the observer’s parameters are often inaccurately known; moreover, they change randomly over time. This in turn leads to the divergence of the Kalman estimation process. The problem is currently being solved in a variety of ways. They include the use of interval observers, the use of an extended Kalman filter, the introduction of an additional evaluating observer by nonlinear programming methods, robust scaling of the observer’s transmission coefficient, etc. At the same time, it should be borne in mind that, firstly, all of the above ways are focused on application in specific technical systems and complexes, and secondly, they fundamentally do not allow estimating errors in determining the parameters of the observer themselves in order to compensate them for further improving the accuracy and stability of the filtration process of the state vector. To solve this problem, this paper proposes the use of accurate observations that are irregularly received in a complex measuring system (for example, navigation) for adaptive evaluation of the observer’s true parameters of the stochastic system state vector. The development of the proposed algorithm is based on the analytical dependence of the Kalman estimate variation on the observer’s parameters disturbances obtained using the mathematical apparatus for the study of perturbed multidimensional dynamical systems. The developed algorithm for observer’s parameters adaptive estimation makes it possible to significantly increase the accuracy and stability of the stochastic estimation process as a whole in the time intervals between accurate observations, which is illustrated by the corresponding numerical example.},
DOI = {10.3390/inventions6040080}
}



@Article{rs13214415,
AUTHOR = {Filippi, Margaux and Hanlon, Regina and Rypina, Irina I. and Hodges, Benjamin A. and Peacock, Thomas and Schmale, David G.},
TITLE = {Tracking a Surrogate Hazardous Agent (Rhodamine Dye) in a Coastal Ocean Environment Using In Situ Measurements and Concentration Estimates Derived from Drone Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4415},
URL = {https://www.mdpi.com/2072-4292/13/21/4415},
ISSN = {2072-4292},
ABSTRACT = {New tools and technology are needed to track hazardous agents such as oil and red tides in our oceans. Rhodamine dye (a surrogate hazardous agent) was released into the Atlantic ocean in August 2018, and experiments were conducted to track the movement of the dye near the water surface within three hours following the release. A DrOne Water Sampling SystEm (DOWSE), consisting of a 3D-printed sampling device tethered to a drone, was used to collect 26 water samples at different locations around the dye plume. Rhodamine concentrations were measured from the drone water samples using a fluorometer and ranged from 1 to 93 ppb. Dye images were taken during the drone-sampling of surface water containing dye and at about 10 m above the sampling point. These images were post-processed to estimate dye concentrations across the sampling domain. A comparison of calibrated heat maps showed that the altitude images yielded dye distributions that were qualitatively similar to those from images taken near the ocean surface. Moreover, the association between red ratios and dye concentrations yielded trendlines explaining up to 67% of the variation. Drones may be used to detect, track and assist in mitigating hazardous agents in the future.},
DOI = {10.3390/rs13214415}
}



@Article{s21217307,
AUTHOR = {Li, Mingjun and Cai, Zhihao and Zhao, Jiang and Wang, Yibo and Wang, Yingxun and Lu, Kelin},
TITLE = {MNNMs Integrated Control for UAV Autonomous Tracking Randomly Moving Target Based on Learning Method},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7307},
URL = {https://www.mdpi.com/1424-8220/21/21/7307},
PubMedID = {34770614},
ISSN = {1424-8220},
ABSTRACT = {In this paper, we investigate the problem of unmanned aerial vehicles (UAVs) autonomous tracking moving target with only an airborne camera sensor. We proposed a novel integrated controller framework for this problem based on multi-neural-network modules (MNNMs). In this framework, two neural networks are designed for target perception and guidance control, respectively. The deep learning method and reinforcement learning method are applied to train the integrated controller. The training result demonstrates that the integrated controller can be trained more quickly and efficiently than the end-to-end controller trained by the deep reinforcement learning method. The flight tests with the integrated controller are implemented in simulated and realistic environments, the results show that the integrated controller trained in simulation can easily be transferred to the realistic environment and achieve the UAV tracking randomly moving target, which has a faster motion velocity. The integrated controller based on the MNNMs structure has a better performance on an autonomous tracking target than the control mode that combines with a perception network and a proportional integral derivative controller.},
DOI = {10.3390/s21217307}
}



@Article{app112110310,
AUTHOR = {Jang, Keunyoung and Kim, Jong-Woo and Ju, Ki-Beom and An, Yun-Kyu},
TITLE = {Infrastructure BIM Platform for Lifecycle Management},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {10310},
URL = {https://www.mdpi.com/2076-3417/11/21/10310},
ISSN = {2076-3417},
ABSTRACT = {Recently, the application of the BIM technique to infrastructure lifecycle management has increased rapidly to improve the efficiency of infrastructure management systems. Research on the lifecycle management of infrastructure, from planning and design to construction and management, has been carried out. Therefore, a systematic review of the literature on recent research is performed to analyze the current state of the BIM technique. State-of-the-art techniques for infrastructure lifecycle management, such as unmanned robots, sensors and processing techniques, artificial intelligence, etc., are also reviewed. An infrastructure BIM platform framework composed of BIM and state-of-the-art techniques is then proposed. The proposed platform is a web-based platform that contains quantity, schedule (4D), and cost (5D) construction management, and the monitoring systems enable collaboration with stakeholders in a Common Data Environment (CDE). The lifecycle management methodology, after infrastructure construction, is then completed and is developed using state-of-the-art techniques using unmanned robots, scan-to-BIM, and deep learning networks, etc. It is confirmed that collaboration with stakeholders in the CDE in construction management is possible using an infrastructure BIM platform. Moreover, lifecycle management of infrastructure is possible by systematic management, such as time history analysis, damage growth prediction, decision of repair and demolition, etc., using a regular inspection database based on an infrastructure BIM platform.},
DOI = {10.3390/app112110310}
}



@Article{s21217312,
AUTHOR = {Fuentes, Sigfredo and Gonzalez Viejo, Claudia and Hall, Chelsea and Tang, Yidan and Tongson, Eden},
TITLE = {Berry Cell Vitality Assessment and the Effect on Wine Sensory Traits Based on Chemical Fingerprinting, Canopy Architecture and Machine Learning Modelling},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7312},
URL = {https://www.mdpi.com/1424-8220/21/21/7312},
PubMedID = {34770618},
ISSN = {1424-8220},
ABSTRACT = {Berry cell death assessment can become one of the most objective parameters to assess important berry quality traits, such as aroma profiles that can be passed to the wine in the winemaking process. At the moment, the only practical tool to assess berry cell death in the field is using portable near-infrared spectroscopy (NIR) and machine learning (ML) models. This research tested the NIR and ML approach and developed supervised regression ML models using Shiraz and Chardonnay berries and wines from a vineyard located in Yarra Valley, Victoria, Australia. An ML model was developed using NIR measurements from intact berries as inputs to estimate berry cell death (BCD), living tissue (LT) (Model 1). Furthermore, canopy architecture parameters obtained from cover photography of grapevine canopies and computer vision analysis were also tested as inputs to develop ML models to assess BCD and LT (Model 2) and the intensity of sensory descriptors based on visual and aroma profiles of wines for Chardonnay (Model 3) and Shiraz (Model 4). The results showed high accuracy and performance of models developed based on correlation coefficient (R) and slope (b) (M1: R = 0.87; b = 0.82; M2: R = 0.98; b = 0.93; M3: R = 0.99; b = 0.99; M4: R = 0.99; b = 1.00). Models developed based on canopy architecture, and computer vision can be used to automatically estimate the vigor and berry and wine quality traits using proximal remote sensing and with visible cameras as the payload of unmanned aerial vehicles (UAV).},
DOI = {10.3390/s21217312}
}



@Article{su132112144,
AUTHOR = {Xue, Yun and Wen, Yi-Min and Duan, Zhong-Man and Zhang, Wei and Liu, Fen-Liang},
TITLE = {Retrieval of Chlorophyll a Concentration in Water Considering High-Concentration Samples and Spectral Absorption Characteristics},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {12144},
URL = {https://www.mdpi.com/2071-1050/13/21/12144},
ISSN = {2071-1050},
ABSTRACT = {The envelope removal method has the advantage of suppressing the background spectrum and expanding the weak absorption characteristic information. However, for second-class water bodies with a relatively complex water quality, there are few studies on the inversion of chlorophyll a (Chl-a) concentration in water bodies that consider the spectral absorption characteristics. In addition, the current research on the inversion of the Chl-a concentration was carried out under the condition of sample concentration equilibrium. For areas with a highly variable Chl-a concentration, it is still challenging to establish a highly applicable and accurate Chl-a concentration inversion model. Taking Dongting Lake in China as an example, this study used high-concentration samples and spectral absorption characteristics to invert the Chl-a concentration. The decap method was used to preprocess the high-concentration samples with large deviations, and the envelope removal method was used to extract the spectral absorption characteristic parameters of the water body. On the basis of the correlation analysis between the water Chl-a concentration and the spectral absorption characteristics, the water Chl-a concentration was inverted. The results showed the following: (1) The bands that were significantly related to the Chl-a concentration and had a large correlation coefficient were mainly located in the three absorption valleys (400–580, 580–650, and 650–710 nm) of the envelope removal curve. Moreover, the correlation between the Chl-a concentration and the absorption characteristic parameters at 650–710 nm was better than that at 400–580 nm and 580–650 nm. (2) Compared with the conventional inversion model, the uncapped inversion model had a higher RP2 and a lower RMSEP, and was closer to the predicted value of the 1:1 line. Moreover, the performance of the uncapped inversion model was better than that of the conventional inversion model, indicating that the uncapped method is an effective preprocessing method for high-concentration samples with large deviations. (3) The predictive capabilities of the ER_New model were significantly better than those of the R_New model. This shows that the envelope removal method can significantly amplify the absorption characteristics of the original spectrum, which can significantly improve the performance of the prediction model. (4) From the inversion models for the absorption characteristic parameters, the prediction models of A650–710 nm_New and D650–710 nm_New exhibited the best performance. The three combined models (A650–710 nm&amp;D650–710 nm_New, A650–710 nm&amp;NI_New, A650–710 nm&amp;DI_New) also demonstrated good predictive capabilities. This demonstrates the feasibility of using the spectral absorption feature to retrieve the chlorophyll concentration.},
DOI = {10.3390/su132112144}
}



@Article{rs13214430,
AUTHOR = {Bizjak, Marko and Žalik, Borut and Lukač, Niko},
TITLE = {Parameter-Free Half-Spaces Based 3D Building Reconstruction Using Ground and Segmented Building Points from Airborne LiDAR Data with 2D Outlines},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4430},
URL = {https://www.mdpi.com/2072-4292/13/21/4430},
ISSN = {2072-4292},
ABSTRACT = {This paper aims to automatically reconstruct 3D building models on a large scale using a new approach on the basis of half-spaces, while making no assumptions about the building layout and keeping the number of input parameters to a minimum. The proposed algorithm is performed in two stages. First, the airborne LiDAR data and buildings’ outlines are preprocessed to generate buildings’ base models and the corresponding half-spaces. In the second stage, the half-spaces are analysed and used for shaping the final 3D building model using 3D Boolean operations. In experiments, the proposed algorithm was applied on a large scale, and its’ performance was inspected on a city level and on a single building level. Accurate reconstruction of buildings with various layouts were demonstrated and limitations were identified for large-scale applications. Finally, the proposed algorithm was validated on an ISPRS benchmark dataset, where a RMSE of 1.31 m and completeness of 98.9% were obtained.},
DOI = {10.3390/rs13214430}
}



@Article{rs13214434,
AUTHOR = {Zhao, Chunhui and Zhang, Chi and Yan, Yiming and Su, Nan},
TITLE = {A 3D Reconstruction Framework of Buildings Using Single Off-Nadir Satellite Image},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4434},
URL = {https://www.mdpi.com/2072-4292/13/21/4434},
ISSN = {2072-4292},
ABSTRACT = {A novel framework for 3D reconstruction of buildings based on a single off-nadir satellite image is proposed in this paper. Compared with the traditional methods of reconstruction using multiple images in remote sensing, recovering 3D information that utilizes the single image can reduce the demands of reconstruction tasks from the perspective of input data. It solves the problem that multiple images suitable for traditional reconstruction methods cannot be acquired in some regions, where remote sensing resources are scarce. However, it is difficult to reconstruct a 3D model containing a complete shape and accurate scale from a single image. The geometric constraints are not sufficient as the view-angle, size of buildings, and spatial resolution of images are different among remote sensing images. To solve this problem, the reconstruction framework proposed consists of two convolutional neural networks: Scale-Occupancy-Network (Scale-ONet) and model scale optimization network (Optim-Net). Through reconstruction using the single off-nadir satellite image, Scale-Onet can generate water-tight mesh models with the exact shape and rough scale of buildings. Meanwhile, the Optim-Net can reduce the error of scale for these mesh models. Finally, the complete reconstructed scene is recovered by Model-Image matching. Profiting from well-designed networks, our framework has good robustness for different input images, with different view-angle, size of buildings, and spatial resolution. Experimental results show that an ideal reconstruction accuracy can be obtained both on the model shape and scale of buildings.},
DOI = {10.3390/rs13214434}
}



@Article{w13213115,
AUTHOR = {Farhadi, Hadi and Najafzadeh, Mohammad},
TITLE = {Flood Risk Mapping by Remote Sensing Data and Random Forest Technique},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {3115},
URL = {https://www.mdpi.com/2073-4441/13/21/3115},
ISSN = {2073-4441},
ABSTRACT = {Detecting effective parameters in flood occurrence is one of the most important issues that has drawn more attention in recent years. Remote Sensing (RS) and Geographical Information System (GIS) are two efficient ways to spatially predict Flood Risk Mapping (FRM). In this study, a web-based platform called the Google Earth Engine (GEE) (Google Company, Mountain View, CA, USA) was used to obtain flood risk indices for the Galikesh River basin, Northern Iran. With the aid of Landsat 8 satellite imagery and the Shuttle Radar Topography Mission (SRTM) Digital Elevation Model (DEM), 11 risk indices (Elevation (El), Slope (Sl), Slope Aspect (SA), Land Use (LU), Normalized Difference Vegetation Index (NDVI), Normalized Difference Water Index (NDWI), Topographic Wetness Index (TWI), River Distance (RD), Waterway and River Density (WRD), Soil Texture (ST]), and Maximum One-Day Precipitation (M1DP)) were provided. In the next step, all of these indices were imported into ArcMap 10.8 (Esri, West Redlands, CA, USA) software for index normalization and to better visualize the graphical output. Afterward, an intelligent learning machine (Random Forest (RF)), which is a robust data mining technique, was used to compute the importance degree of each index and to obtain the flood hazard map. According to the results, the indices of WRD, RD, M1DP, and El accounted for about 68.27 percent of the total flood risk. Among these indices, the WRD index containing about 23.8 percent of the total risk has the greatest impact on floods. According to FRM mapping, about 21 and 18 percent of the total areas stood at the higher and highest risk areas, respectively.},
DOI = {10.3390/w13213115}
}



@Article{app112110370,
AUTHOR = {Duarte-Vidal, Luz and Herrera, Rodrigo F. and Atencio, Edison and Muñoz-La Rivera, Felipe},
TITLE = {Interoperability of Digital Tools for the Monitoring and Control of Construction Projects},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {10370},
URL = {https://www.mdpi.com/2076-3417/11/21/10370},
ISSN = {2076-3417},
ABSTRACT = {Monitoring the progress on a construction site during the construction phase is crucial. An inadequate understanding of the project status can lead to mistakes and inappropriate actions, causing delays and increased costs. Monitoring and controlling projects via digital tools would reduce the risk of error and enable timely corrective actions. Although there is currently a wide range of technologies for these purposes, these technologies and interoperability between them are still limited. Because of this, it is important to know the possibilities of integration and interoperability regarding their implementation. This article presents a bibliographic synthesis and interpretation of 30 nonconventional digital tools for monitoring progress in terms of field data capture technologies (FDCT) and communication and collaborative technologies (CT) that are responsible for information processing and management. This research aims to perform an integration and interoperability analysis of technologies to demonstrate their potential for monitoring and controlling construction projects during the execution phase. A network analysis was conducted, and the results suggest that the triad formed by building information modeling (BIM), unmanned aerial vehicles (UAVs) and photogrammetry is an effective tool; the use of this set extends not only to monitoring and control, but also to all phases of a project.},
DOI = {10.3390/app112110370}
}



@Article{rs13214445,
AUTHOR = {Nazeri, Behrokh and Crawford, Melba},
TITLE = {Detection of Outliers in LiDAR Data Acquired by Multiple Platforms over Sorghum and Maize},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4445},
URL = {https://www.mdpi.com/2072-4292/13/21/4445},
ISSN = {2072-4292},
ABSTRACT = {High-resolution point cloud data acquired with a laser scanner from any platform contain random noise and outliers. Therefore, outlier detection in LiDAR data is often necessary prior to analysis. Applications in agriculture are particularly challenging, as there is typically no prior knowledge of the statistical distribution of points, plant complexity, and local point densities, which are crop-dependent. The goals of this study were first to investigate approaches to minimize the impact of outliers on LiDAR acquired over agricultural row crops, and specifically for sorghum and maize breeding experiments, by an unmanned aerial vehicle (UAV) and a wheel-based ground platform; second, to evaluate the impact of existing outliers in the datasets on leaf area index (LAI) prediction using LiDAR data. Two methods were investigated to detect and remove the outliers from the plant datasets. The first was based on surface fitting to noisy point cloud data via normal and curvature estimation in a local neighborhood. The second utilized the PointCleanNet deep learning framework. Both methods were applied to individual plants and field-based datasets. To evaluate the method, an F-score was calculated for synthetic data in the controlled conditions, and LAI, the variable being predicted, was computed both before and after outlier removal for both scenarios. Results indicate that the deep learning method for outlier detection is more robust than the geometric approach to changes in point densities, level of noise, and shapes. The prediction of LAI was also improved for the wheel-based vehicle data based on the coefficient of determination (R2) and the root mean squared error (RMSE) of the residuals before and after the removal of outliers.},
DOI = {10.3390/rs13214445}
}



@Article{en14217355,
AUTHOR = {Baba, Sebastian and Bachman, Serafin and Jasinski, Marek and Li, Hong},
TITLE = {Evaluation of Modular Power Converter Integrated with 5G Network},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7355},
URL = {https://www.mdpi.com/1996-1073/14/21/7355},
ISSN = {1996-1073},
ABSTRACT = {This paper focuses on two key technical concepts, which may have a tremendous impact on future generations of power electronic converters: the Power Electronic Building Block (PEBB) concept, and the 5G/6G wireless data transfer. It is expected that these two trends may induce development of new cognitive of power electronic converters: Power Electronics 4.0. To investigate this concept, a Proof of Concept (PoC) of PEBB-based power converter integrated with a 5G network, was designed and tested. Study confirmed that power converter assembled from PEBB modules can compete with state-of-the-art devices. Moreover, test results indicates that several challenges related to PEBB and integration of power electronic equipment with 5G network has to be resolved, to enable growth of augmented power electronic converters, especially if wireless data transfer is meant for communication between PEBB modules.},
DOI = {10.3390/en14217355}
}



@Article{agriculture11111104,
AUTHOR = {Rokhafrouz, Mohammad and Latifi, Hooman and Abkar, Ali A. and Wojciechowski, Tomasz and Czechlowski, Mirosław and Naieni, Ali Sadeghi and Maghsoudi, Yasser and Niedbała, Gniewko},
TITLE = {Simplified and Hybrid Remote Sensing-Based Delineation of Management Zones for Nitrogen Variable Rate Application in Wheat},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {1104},
URL = {https://www.mdpi.com/2077-0472/11/11/1104},
ISSN = {2077-0472},
ABSTRACT = {Enhancing digital and precision agriculture is currently inevitable to overcome the economic and environmental challenges of the agriculture in the 21st century. The purpose of this study was to generate and compare management zones (MZ) based on the Sentinel-2 satellite data for variable rate application of mineral nitrogen in wheat production, calculated using different remote sensing (RS)-based models under varied soil, yield and crop data availability. Three models were applied, including (1) a modified “RS- and threshold-based clustering”, (2) a “hybrid-based, unsupervised clustering”, in which data from different sources were combined for MZ delineation, and (3) a “RS-based, unsupervised clustering”. Various data processing methods including machine learning were used in the model development. Statistical tests such as the Paired Sample T-test, Kruskal–Wallis H-test and Wilcoxon signed-rank test were applied to evaluate the final delineated MZ maps. Additionally, a procedure for improving models based on information about phenological phases and the occurrence of agricultural drought was implemented. The results showed that information on agronomy and climate enables improving and optimizing MZ delineation. The integration of prior knowledge on new climate conditions (drought) in image selection was tested for effective use of the models. Lack of this information led to the infeasibility of obtaining optimal results. Models that solely rely on remote sensing information are comparatively less expensive than hybrid models. Additionally, remote sensing-based models enable delineating MZ for fertilizer recommendations that are temporally closer to fertilization times.},
DOI = {10.3390/agriculture11111104}
}



@Article{agronomy11112244,
AUTHOR = {Yang, Mingxin and Gao, Peng and Zhou, Ping and Xie, Jiaxing and Sun, Daozong and Han, Xiongzhe and Wang, Weixing},
TITLE = {Simulating Canopy Temperature Using a Random Forest Model to Calculate the Crop Water Stress Index of Chinese Brassica},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2244},
URL = {https://www.mdpi.com/2073-4395/11/11/2244},
ISSN = {2073-4395},
ABSTRACT = {The determination of crop water status has positive effects on the Chinese Brassica industry and irrigation decisions. Drought can decrease the production of Chinese Brassica, whereas over-irrigation can waste water. It is desirable to schedule irrigation when the crop suffers from water stress. In this study, a random forest model was developed using sample data derived from meteorological measurements including air temperature (Ta), relative humidity (RH), wind speed (WS), and photosynthetic active radiation (Par) to predict the lower baseline (Twet) and upper baseline (Tdry) canopy temperatures for Chinese Brassica from 27 November to 31 December 2020 (E1) and from 25 May to 20 June 2021 (E2). Crop water stress index (CWSI) values were determined based on the predicted canopy temperature and used to assess the crop water status. The study demonstrated the viability of using a random forest model to forecast Twet and Tdry. The coefficients of determination (R2) in E1 were 0.90 and 0.88 for development and 0.80 and 0.77 for validation, respectively. The R2 values in E2 were 0.91 and 0.89 for development and 0.83 and 0.80 for validation, respectively. Our results reveal that the measured and predicted CWSI values had similar R2 values related to stomatal conductance (~0.5 in E1, ~0.6 in E2), whereas the CWSI showed a poor correlation with transpiration rate (~0.25 in E1, ~0.2 in E2). Finally, the methodology used to calculate the daily CWSI for Chinese Brassica in this study showed that both Twet and Tdry, which require frequent measuring and design experiment due to the trial site and condition changes, have the potential to simulate environmental parameters and can therefore be applied to conveniently calculate the CWSI.},
DOI = {10.3390/agronomy11112244}
}



@Article{s21217397,
AUTHOR = {Wang, Yanjun and Li, Shaochun and Lin, Yunhao and Wang, Mengjie},
TITLE = {Lightweight Deep Neural Network Method for Water Body Extraction from High-Resolution Remote Sensing Images with Multisensors},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7397},
URL = {https://www.mdpi.com/1424-8220/21/21/7397},
PubMedID = {34770701},
ISSN = {1424-8220},
ABSTRACT = {Rapid and accurate extraction of water bodies from high-spatial-resolution remote sensing images is of great value for water resource management, water quality monitoring and natural disaster emergency response. For traditional water body extraction methods, it is difficult to select image texture and features, the shadows of buildings and other ground objects are in the same spectrum as water bodies, the existing deep convolutional neural network is difficult to train, the consumption of computing resources is large, and the methods cannot meet real-time requirements. In this paper, a water body extraction method based on lightweight MobileNetV2 is proposed and applied to multisensor high-resolution remote sensing images, such as GF-2, WorldView-2 and UAV orthoimages. This method was validated in two typical complex geographical scenes: water bodies for farmland irrigation, which have a broken shape and long and narrow area and are surrounded by many buildings in towns and villages; and water bodies in mountainous areas, which have undulating topography, vegetation coverage and mountain shadows all over. The results were compared with those of the support vector machine, random forest and U-Net models and also verified by generalization tests and the influence of spatial resolution changes. First, the results show that the F1-score and Kappa coefficients of the MobileNetV2 model extracting water bodies from three different high-resolution images were 0.75 and 0.72 for GF-2, 0.86 and 0.85 for Worldview-2 and 0.98 and 0.98 for UAV, respectively, which are higher than those of traditional machine learning models and U-Net. Second, the training time, number of parameters and calculation amount of the MobileNetV2 model were much lower than those of the U-Net model, which greatly improves the water body extraction efficiency. Third, in other more complex surface areas, the MobileNetV2 model still maintained relatively high accuracy of water body extraction. Finally, we tested the effects of multisensor models and found that training with lower and higher spatial resolution images combined can be beneficial, but that using just lower resolution imagery is ineffective. This study provides a reference for the efficient automation of water body classification and extraction under complex geographical environment conditions and can be extended to water resource investigation, management and planning.},
DOI = {10.3390/s21217397}
}



@Article{s21217396,
AUTHOR = {Kim, Bubryur and Choi, Se-Woon and Hu, Gang and Lee, Dong-Eun and Serfa Juan, Ronnie O.},
TITLE = {Multivariate Analysis of Concrete Image Using Thermography and Edge Detection},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7396},
URL = {https://www.mdpi.com/1424-8220/21/21/7396},
PubMedID = {34770702},
ISSN = {1424-8220},
ABSTRACT = {With the growing demand for structural health monitoring system applications, data imaging is an ideal method for performing regular routine maintenance inspections. Image analysis can provide invaluable information about the health conditions of a structure’s existing infrastructure by recording and analyzing exterior damages. Therefore, it is desirable to have an automated approach that reports defects on images reliably and robustly. This paper presents a multivariate analysis approach for images, specifically for assessing substantial damage (such as cracks). The image analysis provides graph representations that are related to the image, such as the histogram. In addition, image-processing techniques such as grayscale are also implemented, which enhance the object’s information present in the image. In addition, this study uses image segmentation and a neural network, for transforming an image to analyze it more easily and as a classifier, respectively. Initially, each concrete structure image is preprocessed to highlight the crack. A neural network is used to calculate and categorize the visual characteristics of each region, and it shows an accuracy for classification of 98%. Experimental results show that thermal image extraction yields better histogram and cumulative distribution function features. The system can promote the development of various thermal image applications, such as nonphysical visual recognition and fault detection analysis.},
DOI = {10.3390/s21217396}
}



@Article{su132112291,
AUTHOR = {Wu, Li-Ya and Weng, Sung-Shun},
TITLE = {Ensemble Learning Models for Food Safety Risk Prediction},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {12291},
URL = {https://www.mdpi.com/2071-1050/13/21/12291},
ISSN = {2071-1050},
ABSTRACT = {Ensemble learning was adopted to design risk prediction models with the aim of improving border inspection methods for food imported into Taiwan. Specifically, we constructed a set of prediction models to enhance the hit rate of non-conforming products, thus strengthening the border control of food products to safeguard public health. Using five algorithms, we developed models to provide recommendations for the risk assessment of each imported food batch. The models were evaluated by constructing a confusion matrix to calculate predictive performance indicators, including the positive prediction value (PPV), recall, harmonic mean of PPV and recall (F1 score), and area under the curve. Our results showed that ensemble learning achieved better and more stable prediction results than any single algorithm. When the results of comparable data periods were examined, the non-conformity hit rate was found to increase significantly after online implementation of the ensemble learning models, indicating that ensemble learning was effective at risk prediction. In addition to enhancing the inspection hit rate of non-conforming food, the results of this study can serve as a reference for the improvement of existing random inspection methods, thus strengthening capabilities in food risk management.},
DOI = {10.3390/su132112291}
}



@Article{rs13214472,
AUTHOR = {Zhang, Tianyu and Shi, Cuiping and Liao, Diling and Wang, Liguo},
TITLE = {Deep Spectral Spatial Inverted Residual Network for Hyperspectral Image Classification},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4472},
URL = {https://www.mdpi.com/2072-4292/13/21/4472},
ISSN = {2072-4292},
ABSTRACT = {Convolutional neural networks (CNNs) have been widely used in hyperspectral image classification in recent years. The training of CNNs relies on a large amount of labeled sample data. However, the number of labeled samples of hyperspectral data is relatively small. Moreover, for hyperspectral images, fully extracting spectral and spatial feature information is the key to achieve high classification performance. To solve the above issues, a deep spectral spatial inverted residuals network (DSSIRNet) is proposed. In this network, a data block random erasing strategy is introduced to alleviate the problem of limited labeled samples by data augmentation of small spatial blocks. In addition, a deep inverted residuals (DIR) module for spectral spatial feature extraction is proposed, which locks the effective features of each layer while avoiding network degradation. Furthermore, a global 3D attention module is proposed, which can realize the fine extraction of spectral and spatial global context information under the condition of the same number of input and output feature maps. Experiments are carried out on four commonly used hyperspectral datasets. A large number of experimental results show that compared with some state-of-the-art classification methods, the proposed method can provide higher classification accuracy for hyperspectral images.},
DOI = {10.3390/rs13214472}
}



@Article{rs13214476,
AUTHOR = {Traore, Adama and Ata-Ul-Karim, Syed Tahir and Duan, Aiwang and Soothar, Mukesh Kumar and Traore, Seydou and Zhao, Ben},
TITLE = {Predicting Equivalent Water Thickness in Wheat Using UAV Mounted Multispectral Sensor through Deep Learning Techniques},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4476},
URL = {https://www.mdpi.com/2072-4292/13/21/4476},
ISSN = {2072-4292},
ABSTRACT = {The equivalent water thickness (EWT) is an important biophysical indicator of water status in crops. The effective monitoring of EWT in wheat under different nitrogen and water treatments is important for irrigation management in precision agriculture. This study aimed to investigate the performances of machine learning (ML) algorithms in retrieving wheat EWT. For this purpose, a rain shelter experiment (Exp. 1) with four irrigation quantities (0, 120, 240, 360 mm) and two nitrogen levels (75 and 255 kg N/ha), and field experiments (Exps. 2–3) with the same irrigation and rainfall water levels (360 mm) but different nitrogen levels (varying from 75 to 255 kg N/ha) were conducted in the North China Plain. The canopy reflectance was measured for all plots at 30 m using an unmanned aerial vehicle (UAV)-mounted multispectral camera. Destructive sampling was conducted immediately after the UAV flights to measure total fresh and dry weight. Deep Neural Network (DNN) is a special type of neural network, which has shown performance in regression analysis is compared with other machine learning (ML) models. A feature selection (FS) algorithm named the decision tree (DT) was used as the automatic relevance determination method to obtain the relative relevance of 5 out of 67 vegetation indices (Vis), which were used for estimating EWT. The selected VIs were used to estimate EWT using multiple linear regression (MLR), deep neural network multilayer perceptron (DNN-MLP), artificial neural networks multilayer perceptron (ANN-MLP), boosted tree regression (BRT), and support vector machines (SVMs). The results show that the DNN-MLP with R2 = 0.934, NSE = 0.933, RMSE = 0.028 g/cm2, and MAE of 0.017 g/cm2 outperformed other ML algorithms (ANN-MPL, BRT, and SVM- Polynomial) owing to its high capacity for estimating EWT as compared to other ML methods. Our findings support the conclusion that ML can potentially be applied in combination with VIs for retrieving EWT. Despite the complexity of the ML models, the EWT map should help farmers by improving the real-time irrigation efficiency of wheat by quantifying field water content and addressing variability.},
DOI = {10.3390/rs13214476}
}



@Article{app112110481,
AUTHOR = {Zhao, Haoran and Yang, Wenjie and Zhu, Huibin},
TITLE = {Unmanned Aerial Vehicles Rescue System Design and Traffic Model Planning},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {10481},
URL = {https://www.mdpi.com/2076-3417/11/21/10481},
ISSN = {2076-3417},
ABSTRACT = {Unmanned Aerial Vehicles (UAV) are widely used in disaster relief and road exploration in recent years. This paper mainly studied the emergency response of UAVs after disasters. The UAV response system is mainly suitable for the distribution of necessities and road exploration after geological disasters and tsunamis in coastal areas. By analyzing the problem and making reasonable assumptions, the optimization model was established with the traffic planning theory, and MATLAB software was used to program and solve the problem. An optimal scheduling scheme was presented to solve these problems. The normalization method was used to select a highly capable UAV. Taking the minimum volume of idle space buffer material as the objective function and taking into account the constraints, such as payload of unmanned aerial vehicle, a single objective programming model was established. The results are as follows: Each International Standards Organization (ISO) cargo container has five UAVs B, one UAV C, one UAV F and one UAV H. It provides 188 days of relief requirements with ISO cargo containers’ space utilization of 71.4%. The research shows that the UAV response system has the functions of necessities distribution and road exploration after disasters, and can be used to deal with the emergency response after disasters in coastal areas, and has a wide range of applicability.},
DOI = {10.3390/app112110481}
}



@Article{rs13214486,
AUTHOR = {Rakhmatuiln, Ildar and Kamilaris, Andreas and Andreasen, Christian},
TITLE = {Deep Neural Networks to Detect Weeds from Crops in Agricultural Environments in Real-Time: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4486},
URL = {https://www.mdpi.com/2072-4292/13/21/4486},
ISSN = {2072-4292},
ABSTRACT = {Automation, including machine learning technologies, are becoming increasingly crucial in agriculture to increase productivity. Machine vision is one of the most popular parts of machine learning and has been widely used where advanced automation and control have been required. The trend has shifted from classical image processing and machine learning techniques to modern artificial intelligence (AI) and deep learning (DL) methods. Based on large training datasets and pre-trained models, DL-based methods have proven to be more accurate than previous traditional techniques. Machine vision has wide applications in agriculture, including the detection of weeds and pests in crops. Variation in lighting conditions, failures to transfer learning, and object occlusion constitute key challenges in this domain. Recently, DL has gained much attention due to its advantages in object detection, classification, and feature extraction. DL algorithms can automatically extract information from large amounts of data used to model complex problems and is, therefore, suitable for detecting and classifying weeds and crops. We present a systematic review of AI-based systems to detect weeds, emphasizing recent trends in DL. Various DL methods are discussed to clarify their overall potential, usefulness, and performance. This study indicates that several limitations obstruct the widespread adoption of AI/DL in commercial applications. Recommendations for overcoming these challenges are summarized.},
DOI = {10.3390/rs13214486}
}



@Article{robotics10040122,
AUTHOR = {David, Jennifer and Rögnvaldsson, Thorsteinn},
TITLE = {Multi-Robot Routing Problem with Min–Max Objective},
JOURNAL = {Robotics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {122},
URL = {https://www.mdpi.com/2218-6581/10/4/122},
ISSN = {2218-6581},
ABSTRACT = {In this paper, we study the “Multi-Robot Routing problem” with min–max objective (MRR-MM) in detail. It involves the assignment of sequentially ordered tasks to robots such that the maximum cost of the slowest robot is minimized. The problem description, the different types of formulations, and the methods used across various research communities are discussed in this paper. We propose a new problem formulation by treating this problem as a permutation matrix. A comparative study is done between three methods: Stochastic simulated annealing, deterministic mean-field annealing, and a heuristic-based graph search method. Each method is investigated in detail with several data sets (simulation and real-world), and the results are analysed and compared with respect to scalability, computational complexity, optimality, and its application to real-world scenarios. The paper shows that the heuristic method produces results very quickly with good scalability. However, the solution quality is sub-optimal. On the other hand, when optimal or near-optimal results are required with considerable computational resources, the simulated annealing method proves to be more efficient. However, the results show that the optimal choice of algorithm depends on the dataset size and the available computational budget. The contribution of the paper is three-fold: We study the MRR-MM problem in detail across various research communities. This study also shows the lack of inter-research terminology that has led to different names for the same problem. Secondly, formulating the task allocation problem as a permutation matrix formulation has opened up new approaches to solve this problem. Thirdly, we applied our problem formulation to three different methods and conducted a detailed comparative study using real-world and simulation data.},
DOI = {10.3390/robotics10040122}
}



@Article{s21227436,
AUTHOR = {Rojas-Perez, Leticia Oyuki and Martinez-Carranza, Jose},
TITLE = {Towards Autonomous Drone Racing without GPU Using an OAK-D Smart Camera},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7436},
URL = {https://www.mdpi.com/1424-8220/21/22/7436},
PubMedID = {34833511},
ISSN = {1424-8220},
ABSTRACT = {Recent advances have shown for the first time that it is possible to beat a human with an autonomous drone in a drone race. However, this solution relies heavily on external sensors, specifically on the use of a motion capture system. Thus, a truly autonomous solution demands performing computationally intensive tasks such as gate detection, drone localisation, and state estimation. To this end, other solutions rely on specialised hardware such as graphics processing units (GPUs) whose onboard hardware versions are not as powerful as those available for desktop and server computers. An alternative is to combine specialised hardware with smart sensors capable of processing specific tasks on the chip, alleviating the need for the onboard processor to perform these computations. Motivated by this, we present the initial results of adapting a novel smart camera, known as the OpenCV AI Kit or OAK-D, as part of a solution for the ADR running entirely on board. This smart camera performs neural inference on the chip that does not use a GPU. It can also perform depth estimation with a stereo rig and run neural network models using images from a 4K colour camera as the input. Additionally, seeking to limit the payload to 200 g, we present a new 3D-printed design of the camera’s back case, reducing the original weight 40%, thus enabling the drone to carry it in tandem with a host onboard computer, the Intel Stick compute, where we run a controller based on gate detection. The latter is performed with a neural model running on an OAK-D at an operation frequency of 40 Hz, enabling the drone to fly at a speed of 2 m/s. We deem these initial results promising toward the development of a truly autonomous solution that will run intensive computational tasks fully on board.},
DOI = {10.3390/s21227436}
}



@Article{electronics10222736,
AUTHOR = {Sun, Biao and Gu, Zhou and Xiong, Tianyi},
TITLE = {Event-Triggered Formation Tracking Control for Unmanned Aerial Vehicles Subjected to Deception Attacks},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {2736},
URL = {https://www.mdpi.com/2079-9292/10/22/2736},
ISSN = {2079-9292},
ABSTRACT = {This study investigates the time-varying formation tracking (TVFT) control problem for multiple unmanned aerial vehicle (multi-UAV) systems under deception attacks by utilizing an event-triggered mechanism (ETM). First, for the sake of alleviating the communication burden, an effective ETM is designed in this paper. Second, to deal with deception attacks in the communication network, a random deception attack model under the designed ETM is constructed. Finally, a novel formation tracking control scheme for multi-UAV systems under deception attack combining the ETM is proposed to achieve the expected TVFT. The stability analysis of the formation control system is given by using the Lyapunov stability theory and linear matrix inequality (LMI) technique. Simulations are conducted to verify the effectiveness of the proposed formation control scheme.},
DOI = {10.3390/electronics10222736}
}



@Article{rs13224518,
AUTHOR = {Zhao, Xin and Guo, Jiayi and Zhang, Yueting and Wu, Yirong},
TITLE = {Memory-Augmented Transformer for Remote Sensing Image Semantic Segmentation},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4518},
URL = {https://www.mdpi.com/2072-4292/13/22/4518},
ISSN = {2072-4292},
ABSTRACT = {The semantic segmentation of remote sensing images requires distinguishing local regions of different classes and exploiting a uniform global representation of the same-class instances. Such requirements make it necessary for the segmentation methods to extract discriminative local features between different classes and to explore representative features for all instances of a given class. While common deep convolutional neural networks (DCNNs) can effectively focus on local features, they are limited by their receptive field to obtain consistent global information. In this paper, we propose a memory-augmented transformer (MAT) to effectively model both the local and global information. The feature extraction pipeline of the MAT is split into a memory-based global relationship guidance module and a local feature extraction module. The local feature extraction module mainly consists of a transformer, which is used to extract features from the input images. The global relationship guidance module maintains a memory bank for the consistent encoding of the global information. Global guidance is performed by memory interaction. Bidirectional information flow between the global and local branches is conducted by a memory-query module, as well as a memory-update module, respectively. Experiment results on the ISPRS Potsdam and ISPRS Vaihingen datasets demonstrated that our method can perform competitively with state-of-the-art methods.},
DOI = {10.3390/rs13224518}
}



@Article{app112210595,
AUTHOR = {Zhao, Wenlong and Meng, Zhijun and Wang, Kaipeng and Zhang, Jiahui and Lu, Shaoze},
TITLE = {Hierarchical Active Tracking Control for UAVs via Deep Reinforcement Learning},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10595},
URL = {https://www.mdpi.com/2076-3417/11/22/10595},
ISSN = {2076-3417},
ABSTRACT = {Active tracking control is essential for UAVs to perform autonomous operations in GPS-denied environments. In the active tracking task, UAVs take high-dimensional raw images as input and execute motor actions to actively follow the dynamic target. Most research focuses on three-stage methods, which entail perception first, followed by high-level decision-making based on extracted spatial information of the dynamic target, and then UAV movement control, using a low-level dynamic controller. Perception methods based on deep neural networks are powerful but require considerable effort for manual ground truth labeling. Instead, we unify the perception and decision-making stages using a high-level controller and then leverage deep reinforcement learning to learn the mapping from raw images to the high-level action commands in the V-REP-based environment, where simulation data are infinite and inexpensive. This end-to-end method also has the advantages of a small parameter size and reduced effort requirements for parameter turning in the decision-making stage. The high-level controller, which has a novel architecture, explicitly encodes the spatial and temporal features of the dynamic target. Auxiliary segmentation and motion-in-depth losses are introduced to generate denser training signals for the high-level controller’s fast and stable training. The high-level controller and a conventional low-level PID controller constitute our hierarchical active tracking control framework for the UAVs’ active tracking task. Simulation experiments show that our controller trained with several augmentation techniques sufficiently generalizes dynamic targets with random appearances and velocities, and achieves significantly better performance, compared with three-stage methods.},
DOI = {10.3390/app112210595}
}



@Article{s21227484,
AUTHOR = {Hu, Aihua and Deng, Zhongliang and Yang, Hui and Zhang, Yao and Gao, Yuhui and Zhao, Di},
TITLE = {An Optimal Geometry Configuration Algorithm of Hybrid Semi-Passive Location System Based on Mayfly Optimization Algorithm},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7484},
URL = {https://www.mdpi.com/1424-8220/21/22/7484},
PubMedID = {34833560},
ISSN = {1424-8220},
ABSTRACT = {In view of the demand of location awareness in a special complex environment, for an unmanned aerial vehicle (UAV) airborne multi base-station semi-passive positioning system, the hybrid positioning solutions and optimized site layout in the positioning system can effectively improve the positioning accuracy for a specific region. In this paper, the geometric dilution of precision (GDOP) formula of a time difference of arrival (TDOA) and angles of arrival (AOA) hybrid location algorithm is deduced. Mayfly optimization algorithm (MOA) which is a new swarm intelligence optimization algorithm is introduced, and a method to find the optimal station of the UAV airborne multiple base station’s semi-passive positioning system using MOA is proposed. The simulation and analysis of the optimization of the different number of base stations, compared with other station layout methods, such as particle swarm optimization (PSO), genetic algorithm (GA), and artificial bee colony (ABC) algorithm. MOA is less likely to fall into local optimum, and the error of regional target positioning is reduced. By simulating the deployment of four base stations and five base stations in various situations, MOA can achieve a better deployment effect. The dynamic station configuration capability of the multi-station semi-passive positioning system has been improved with the UAV.},
DOI = {10.3390/s21227484}
}



@Article{sym13112160,
AUTHOR = {Zheng, Aoyu and Li, Bingjie and Zheng, Mingfa and Zhong, Haitao},
TITLE = {Multi-Objective UAV Trajectory Planning in Uncertain Environment},
JOURNAL = {Symmetry},
VOLUME = {13},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2160},
URL = {https://www.mdpi.com/2073-8994/13/11/2160},
ISSN = {2073-8994},
ABSTRACT = {UAV trajectory planning is one of the research focuses in artificial intelligence and UAV technology. The asymmetric information, however, will lead to the uncertainty of the UAV trajectory planning; the probability theory as the most commonly used method to solve the trajectory planning problem in uncertain environment will lead to unrealistic conclusions under the condition of lacking samples, while the uncertainty theory based on uncertain measures is an efficient method to solve such problems. Firstly, the uncertainties in trajectory planning are sufficiently considered in this paper; the fuel consumption, concealment and threat degree with uncertain variables are taken as the objective functions; the constraints are analyzed according to the maneuverability; and the uncertain multi-objective trajectory planning (UMOTP) model is established. After that, this paper takes both the long-term benefits and its stability into account, and then, the expected-value and standard-deviation efficient trajectory model is established. What is more, this paper solves the Pareto front of the trajectory planning, satisfying various preferences, which avoids the defects of the trajectory obtained by traditional model only applicable to a certain specific situation. In order to obtain a better solution set, this paper proposes an improved backbones particle swarm optimization algorithm based on PSO and NSGA-II, which overcomes the shortcomings of the traditional algorithm such as premature convergence and poor robustness, and the efficiency of the algorithm is tested. Finally, the algorithm is applied to the UMOTP problem; then, the optimal trajectory set is obtained, and the effectiveness and reliability of the model is verified.},
DOI = {10.3390/sym13112160}
}



@Article{electronics10222752,
AUTHOR = {Sagar, Md. Samiul Islam and Ouassal, Hassna and Omi, Asif I. and Wisniewska, Anna and Jalajamony, Harikrishnan M. and Fernandez, Renny E. and Sekhar, Praveen K.},
TITLE = {Application of Machine Learning in Electromagnetics: Mini-Review},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {2752},
URL = {https://www.mdpi.com/2079-9292/10/22/2752},
ISSN = {2079-9292},
ABSTRACT = {As an integral part of the electromagnetic system, antennas are becoming more advanced and versatile than ever before, thus making it necessary to adopt new techniques to enhance their performance. Machine Learning (ML), a branch of artificial intelligence, is a method of data analysis that automates analytical model building with minimal human intervention. The potential for ML to solve unpredictable and non-linear complex challenges is attracting researchers in the field of electromagnetics (EM), especially in antenna and antenna-based systems. Numerous antenna simulations, synthesis, and pattern recognition of radiations as well as non-linear inverse scattering-based object identifications are now leveraging ML techniques. Although the accuracy of ML algorithms depends on the availability of sufficient data and expert handling of the model and hyperparameters, it is gradually becoming the desired solution when researchers are aiming for a cost-effective solution without excessive time consumption. In this context, this paper aims to present an overview of machine learning, and its applications in Electromagnetics, including communication, radar, and sensing. It extensively discusses recent research progress in the development and use of intelligent algorithms for antenna design, synthesis and analysis, electromagnetic inverse scattering, synthetic aperture radar target recognition, and fault detection systems. It also provides limitations of this emerging field of study. The unique aspect of this work is that it surveys the state-of the art and recent advances in ML techniques as applied to EM.},
DOI = {10.3390/electronics10222752}
}



@Article{app112210628,
AUTHOR = {Chauvin, John and Duran, Ray and Tavakolian, Kouhyar and Akhbardeh, Alireza and MacKinnon, Nicholas and Qin, Jianwei and Chan, Diane E. and Hwang, Chansong and Baek, Insuck and Kim, Moon S. and Isaacs, Rachel B. and Yilmaz, Ayse Gamze and Roungchun, Jiahleen and Hellberg, Rosalee S. and Vasefi, Fartash},
TITLE = {Simulated Annealing-Based Hyperspectral Data Optimization for Fish Species Classification: Can the Number of Measured Wavelengths Be Reduced?},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10628},
URL = {https://www.mdpi.com/2076-3417/11/22/10628},
ISSN = {2076-3417},
ABSTRACT = {Relative to standard red/green/blue (RGB) imaging systems, hyperspectral imaging systems offer superior capabilities but tend to be expensive and complex, requiring either a mechanically complex push-broom line scanning method, a tunable filter, or a large set of light emitting diodes (LEDs) to collect images in multiple wavelengths. This paper proposes a new methodology to support the design of a hypothesized system that uses three imaging modes—fluorescence, visible/near-infrared (VNIR) reflectance, and shortwave infrared (SWIR) reflectance—to capture narrow-band spectral data at only three to seven narrow wavelengths. Simulated annealing is applied to identify the optimal wavelengths for sparse spectral measurement with a cost function based on the accuracy provided by a weighted k-nearest neighbors (WKNN) classifier, a common and relatively robust machine learning classifier. Two separate classification approaches are presented, the first using a multi-layer perceptron (MLP) artificial neural network trained on sparse data from the three individual spectra and the second using a fusion of the data from all three spectra. The results are compared with those from four alternative classifiers based on common machine learning algorithms. To validate the proposed methodology, reflectance and fluorescence spectra in these three spectroscopic modes were collected from fish fillets and used to classify the fillets by species. Accuracies determined from the two classification approaches are compared with benchmark values derived by training the classifiers with the full resolution spectral data. The results of the single-layer classification study show accuracies ranging from ~68% for SWIR reflectance to ~90% for fluorescence with just seven wavelengths. The results of the fusion classification study show accuracies of about 95% with seven wavelengths and more than 90% even with just three wavelengths. Reducing the number of required wavelengths facilitates the creation of rapid and cost-effective spectral imaging systems that can be used for widespread analysis in food monitoring/food fraud, agricultural, and biomedical applications.},
DOI = {10.3390/app112210628}
}



@Article{math9222873,
AUTHOR = {Khan, Anusha and Sargano, Allah Bux and Habib, Zulfiqar},
TITLE = {DSTnet: Deformable Spatio-Temporal Convolutional Residual Network for Video Super-Resolution},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {2873},
URL = {https://www.mdpi.com/2227-7390/9/22/2873},
ISSN = {2227-7390},
ABSTRACT = {Video super-resolution (VSR) aims at generating high-resolution (HR) video frames with plausible and temporally consistent details using their low-resolution (LR) counterparts, and neighboring frames. The key challenge for VSR lies in the effective exploitation of intra-frame spatial relation and temporal dependency between consecutive frames. Many existing techniques utilize spatial and temporal information separately and compensate motion via alignment. These methods cannot fully exploit the spatio-temporal information that significantly affects the quality of resultant HR videos. In this work, a novel deformable spatio-temporal convolutional residual network (DSTnet) is proposed to overcome the issues of separate motion estimation and compensation methods for VSR. The proposed framework consists of 3D convolutional residual blocks decomposed into spatial and temporal (2+1) D streams. This decomposition can simultaneously utilize input video’s spatial and temporal features without a separate motion estimation and compensation module. Furthermore, the deformable convolution layers have been used in the proposed model that enhances its motion-awareness capability. Our contribution is twofold; firstly, the proposed approach can overcome the challenges in modeling complex motions by efficiently using spatio-temporal information. Secondly, the proposed model has fewer parameters to learn than state-of-the-art methods, making it a computationally lean and efficient framework for VSR. Experiments are conducted on a benchmark Vid4 dataset to evaluate the efficacy of the proposed approach. The results demonstrate that the proposed approach achieves superior quantitative and qualitative performance compared to the state-of-the-art methods.},
DOI = {10.3390/math9222873}
}



@Article{math9222874,
AUTHOR = {Atanassov, Krassimir T. and Vassilev, Peter and Atanassova, Vassia and Roeva, Olympia and Iliev, Rosen and Zoteva, Dafina and Bureva, Veselina and Mavrov, Deyan and Alexandrov, Alexander},
TITLE = {Generalized Net Model of Forest Zone Monitoring by UAVs},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {2874},
URL = {https://www.mdpi.com/2227-7390/9/22/2874},
ISSN = {2227-7390},
ABSTRACT = {The paper presents a generalized net (GN) model of the process of terrain observation with the help of unmanned aerial vehicles (UAVs) for the prevention and rapid detection of wildfires. Using a GN, the process of monitoring a zone (through a UAV, which is further called a reconnaissance drone) and the localization of forest fires is described. For a more indepth study of the terrain, the reconnaissance drone needs to coordinate with a second UAV, called a specialized drone, so that video and sensory information is provided to the supervising fire command operational center. The proposed GN model was developed to assist in the decision-making process related to the coordination of the operation of both UAVs under dynamically changing terrain circumstances, such as those related to preventing or quickly containing wildfires. It describes the stages (transitions), logical determinants (transition predicate matrices), and directions of information flow (token characteristics) within the process of localization of fires using the pair of reconnaissance and specialized drones.},
DOI = {10.3390/math9222874}
}



@Article{agronomy11112290,
AUTHOR = {Sadgrove, Edmund J. and Falzon, Greg and Miron, David and Lamb, David W.},
TITLE = {The Segmented Colour Feature Extreme Learning Machine: Applications in Agricultural Robotics},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2290},
URL = {https://www.mdpi.com/2073-4395/11/11/2290},
ISSN = {2073-4395},
ABSTRACT = {This study presents the Segmented Colour Feature Extreme Learning Machine (SCF-ELM). The SCF-ELM is inspired by the Extreme Learning Machine (ELM) which is known for its rapid training and inference times. The ELM is therefore an ideal candidate for an ensemble learning algorithm. The Colour Feature Extreme Learning Machine (CF-ELM) is used in this study due to its additional ability to extract colour image features. The SCF-ELM is an ensemble learner that utilizes feature mapping via k-means clustering, a decision matrix and majority voting. It has been evaluated on a range of challenging agricultural object classification scenarios including weed, livestock and machinery detection. SCF-ELM model performance results were excellent both in terms of detection, 90 to 99% accuracy, and also inference times, around 0.01(s) per image. The SCF-ELM was able to compete or improve upon established algorithms in its class, indicating its potential for remote computing applications in agriculture.},
DOI = {10.3390/agronomy11112290}
}



@Article{electronics10222764,
AUTHOR = {Hassan, Syed-Ali and Rahim, Tariq and Shin, Soo-Young},
TITLE = {An Improved Deep Convolutional Neural Network-Based Autonomous Road Inspection Scheme Using Unmanned Aerial Vehicles},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {2764},
URL = {https://www.mdpi.com/2079-9292/10/22/2764},
ISSN = {2079-9292},
ABSTRACT = {Recent advancements in the field of machine learning (ML) provide opportunity to conduct research on autonomous devices for a variety of applications. Intelligent decision-making is a critical task for self-driving systems. An attempt is made in this study to use a deep learning (DL) approach for the early detection of road cracks, potholes, and the yellow lane. The accuracy is not sufficient after training with the default model. To enhance accuracy, a convolutional neural network (CNN) model with 13 convolutional layers, a softmax layer as an output layer, and two fully connected layers (FCN) are constructed. In order to achieve the deeper propagation and to prevent saturation in the training phase, mish activation is employed in the first 12 layers with a rectified linear unit (ReLU) activation function. The upgraded CNN model performs better than the default CNN model in terms of accuracy. For the varied situation, a revised and enriched dataset for road cracks, potholes, and the yellow lane is created. The yellow lane is detected and tracked in order to move the unmanned aerial vehicle (UAV) autonomously by following yellow lane. After identifying a yellow lane, the UAV performs autonomous navigation while concurrently detecting road cracks and potholes using the robot operating system within the UAV. The performance model is benchmarked using performance measures, such as accuracy, sensitivity, F1-score, F2-score, and dice-coefficient, which demonstrate that the suggested technique produces better outcomes.},
DOI = {10.3390/electronics10222764}
}



@Article{electronics10222772,
AUTHOR = {Dubosarskii, Gleb and Primak, Serguei},
TITLE = {Jamming and Anti-Jamming Strategies of Mobile Vehicles},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {2772},
URL = {https://www.mdpi.com/2079-9292/10/22/2772},
ISSN = {2079-9292},
ABSTRACT = {Anti-jamming games have become a popular research topic. However, there are not many publications devoted to such games in the case of vehicular ad hoc networks (VANETs). We considered a VANET anti-jamming game on the road using a realistic driving model. Further, we assumed the quadratic power function in both vehicle and jammer utility functions instead of the standard linear term. This makes the game model more realistic. Using mathematical methods, we expressed the Nash equilibrium through the system parameters in single-channel and multi-channel cases. Since the network parameters are usually unknown, we also compared the performance of several reinforcement learning algorithms that iteratively converge to the Nash equilibrium predicted analytically without having any information about the environment in the static and dynamic scenarios.},
DOI = {10.3390/electronics10222772}
}



@Article{app112210689,
AUTHOR = {Molina-Leal, Alejandra and Gómez-Espinosa, Alfonso and Escobedo Cabello, Jesús Arturo and Cuan-Urquizo, Enrique and Cruz-Ramírez, Sergio R.},
TITLE = {Trajectory Planning for a Mobile Robot in a Dynamic Environment Using an LSTM Neural Network},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10689},
URL = {https://www.mdpi.com/2076-3417/11/22/10689},
ISSN = {2076-3417},
ABSTRACT = {Autonomous mobile robots are an important focus of current research due to the advantages they bring to the industry, such as performing dangerous tasks with greater precision than humans. An autonomous mobile robot must be able to generate a collision-free trajectory while avoiding static and dynamic obstacles from the specified start location to the target location. Machine learning, a sub-field of artificial intelligence, is applied to create a Long Short-Term Memory (LSTM) neural network that is implemented and executed to allow a mobile robot to find the trajectory between two points and navigate while avoiding a dynamic obstacle. The input of the network is the distance between the mobile robot and the obstacles thrown by the LiDAR sensor, the desired target location, and the mobile robot’s location with respect to the odometry reference frame. Using the model to learn the mapping between input and output in the sample data, the linear and angular velocity of the mobile robot are obtained. The mobile robot and its dynamic environment are simulated in Gazebo, which is an open-source 3D robotics simulator. Gazebo can be synchronized with ROS (Robot Operating System). The computational experiments show that the network model can plan a safe navigation path in a dynamic environment. The best test accuracy obtained was 99.24%, where the model can generalize other trajectories for which it was not specifically trained within a 15&nbsp;cm radius of a trained destination position.},
DOI = {10.3390/app112210689}
}



@Article{drones5040134,
AUTHOR = {Ming, Zhenxing and Huang, Hailong},
TITLE = {A 3D Vision Cone Based Method for Collision Free Navigation of a Quadcopter UAV among Moving Obstacles},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {134},
URL = {https://www.mdpi.com/2504-446X/5/4/134},
ISSN = {2504-446X},
ABSTRACT = {In the near future, it’s expected that unmanned aerial vehicles (UAVs) will become ubiquitous surrogates for human-crewed vehicles in the field of border patrol, package delivery, etc. Therefore, many three-dimensional (3D) navigation algorithms based on different techniques, e.g., model predictive control (MPC)-based, navigation potential field-based, sliding mode control-based, and reinforcement learning-based, have been extensively studied in recent years to help achieve collision-free navigation. The vast majority of the 3D navigation algorithms perform well when obstacles are sparsely spaced, but fail when facing crowd-spaced obstacles, which causes a potential threat to UAV operations. In this paper, a 3D vision cone-based reactive navigation algorithm is proposed to enable small quadcopter UAVs to seek a path through crowd-spaced 3D obstacles to the destination without collisions. The proposed algorithm is simulated in MATLAB with different 3D obstacles settings to demonstrate its feasibility and compared with the other two existing 3D navigation algorithms to exhibit its superiority. Furthermore, a modified version of the proposed algorithm is also introduced and compared with the initially proposed algorithm to lay the foundation for future work.},
DOI = {10.3390/drones5040134}
}



@Article{app112210701,
AUTHOR = {Rosle, Rhushalshafira and Che’Ya, Nik Norasma and Ang, Yuhao and Rahmat, Fariq and Wayayok, Aimrun and Berahim, Zulkarami and Fazlil Ilahi, Wan Fazilah and Ismail, Mohd Razi and Omar, Mohamad Husni},
TITLE = {Weed Detection in Rice Fields Using Remote Sensing Technique: A Review},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10701},
URL = {https://www.mdpi.com/2076-3417/11/22/10701},
ISSN = {2076-3417},
ABSTRACT = {This paper reviewed the weed problems in agriculture and how remote sensing techniques can detect weeds in rice fields. The comparison of weed detection between traditional practices and automated detection using remote sensing platforms is discussed. The ideal stage for controlling weeds in rice fields was highlighted, and the types of weeds usually found in paddy fields were listed. This paper will discuss weed detection using remote sensing techniques, and algorithms commonly used to differentiate them from crops are deliberated. However, weed detection in rice fields using remote sensing platforms is still in its early stages; weed detection in other crops is also discussed. Results show that machine learning (ML) and deep learning (DL) remote sensing techniques have successfully produced a high accuracy map for detecting weeds in crops using RS platforms. Therefore, this technology positively impacts weed management in many aspects, especially in terms of the economic perspective. The implementation of this technology into agricultural development could be extended further.},
DOI = {10.3390/app112210701}
}



@Article{s21227541,
AUTHOR = {da Silva, José Roberto Cândido and Pacheco, Gefeson Mendes},
TITLE = {An Extended Methodology for Sizing Solar Unmanned Aerial Vehicles: Theory and Development of a Python Framework for Design Assist},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7541},
URL = {https://www.mdpi.com/1424-8220/21/22/7541},
PubMedID = {34833617},
ISSN = {1424-8220},
ABSTRACT = {There is a growing interest in using unmanned aerial vehicles (UAVs) in the most diverse application areas from agriculture to remote sensing, that determine the need to project and define mission profiles of the UAVs. In addition, solar photovoltaic energy increases the flight autonomy of this type of aircraft, forming the term Solar UAV. This study proposes an extended methodology for sizing Solar UAVs that take off from a runway. This methodology considers mission parameters such as operating location, altitude, flight speed, flight endurance, and payload to sizing the aircraft parameters, such as wingspan, area of embedded solar cells panels, runway length required for takeoff and landing, battery weight, and the total weight of the aircraft. Using the Python language, we developed a framework to apply the proposed methodology and assist in designing a Solar UAV. With this framework, it was possible to perform a sensitivity analysis of design parameters and constraints. Finally, we performed a simulation of a mission, checking the output parameters.},
DOI = {10.3390/s21227541}
}



@Article{rs13224562,
AUTHOR = {Lei, Shuhan and Luo, Jianbiao and Tao, Xiaojun and Qiu, Zixuan},
TITLE = {Remote Sensing Detecting of Yellow Leaf Disease of Arecanut Based on UAV Multisource Sensors},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4562},
URL = {https://www.mdpi.com/2072-4292/13/22/4562},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle (UAV) remote sensing technology can be used for fast and efficient monitoring of plant diseases and pests, but these techniques are qualitative expressions of plant diseases. However, the yellow leaf disease of arecanut in Hainan Province is similar to a plague, with an incidence rate of up to 90% in severely affected areas, and a qualitative expression is not conducive to the assessment of its severity and yield. Additionally, there exists a clear correlation between the damage caused by plant diseases and pests and the change in the living vegetation volume (LVV). However, the correlation between the severity of the yellow leaf disease of arecanut and LVV must be demonstrated through research. Therefore, this study aims to apply the multispectral data obtained by the UAV along with the high-resolution UAV remote sensing images to obtain five vegetation indexes such as the normalized difference vegetation index (NDVI), optimized soil adjusted vegetation index (OSAVI), leaf chlorophyll index (LCI), green normalized difference vegetation index (GNDVI), and normalized difference red edge (NDRE) index, and establish five algorithm models such as the back-propagation neural network (BPNN), decision tree, naïve Bayes, support vector machine (SVM), and k-nearest-neighbor classification to determine the severity of the yellow leaf disease of arecanut, which is expressed by the proportion of the yellowing area of a single areca crown (in percentage). The traditional qualitative expression of this disease is transformed into the quantitative expression of the yellow leaf disease of arecanut per plant. The results demonstrate that the classification accuracy of the test set of the BPNN algorithm and SVM algorithm is the highest, at 86.57% and 86.30%, respectively. Additionally, the UAV structure from motion technology is used to measure the LVV of a single areca tree and establish a model of the correlation between the LVV and the severity of the yellow leaf disease of arecanut. The results show that the relative root mean square error is between 34.763% and 39.324%. This study presents the novel quantitative expression of the severity of the yellow leaf disease of arecanut, along with the correlation between the LVV of areca and the severity of the yellow leaf disease of arecanut. Significant development is expected in the degree of integration of multispectral software and hardware, observation accuracy, and ease of use of UAVs owing to the rapid progress of spectral sensing technology and the image processing and analysis algorithms.},
DOI = {10.3390/rs13224562}
}



@Article{app112210736,
AUTHOR = {Sánchez-Rojas, José Armando and Arias-Aguilar, José Aníbal and Takemura, Hiroshi and Petrilli-Barceló, Alberto Elías},
TITLE = {Staircase Detection, Characterization and Approach Pipeline for Search and Rescue Robots},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10736},
URL = {https://www.mdpi.com/2076-3417/11/22/10736},
ISSN = {2076-3417},
ABSTRACT = {Currently, most rescue robots are mainly teleoperated and integrate some level of autonomy to reduce the operator&rsquo;s workload, allowing them to focus on the primary mission tasks. One of the main causes of mission failure are human errors and increasing the robot&rsquo;s autonomy can increase the probability of success. For this reason, in this work, a stair detection and characterization pipeline is presented. The pipeline is tested on a differential drive robot using the ROS middleware, YOLOv4-tiny and a region growing based clustering algorithm. The pipeline&rsquo;s staircase detector was implemented using the Neural Compute Engines (NCEs) of the OpenCV AI Kit with Depth (OAK-D) RGB-D camera, which allowed the implementation using the robot&rsquo;s computer without a GPU and, thus, could be implemented in similar robots to increase autonomy. Furthermore, by using this pipeline we were able to implement a Fuzzy controller that allows the robot to align itself, autonomously, with the staircase. Our work can be used in different robots running the ROS middleware and can increase autonomy, allowing the operator to focus on the primary mission tasks. Furthermore, due to the design of the pipeline, it can be used with different types of RGB-D cameras, including those that generate noisy point clouds from low disparity depth images.},
DOI = {10.3390/app112210736}
}



@Article{bdcc5040067,
AUTHOR = {Dora, Shirin and Kasabov, Nikola},
TITLE = {Spiking Neural Networks for Computational Intelligence: An Overview},
JOURNAL = {Big Data and Cognitive Computing},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {67},
URL = {https://www.mdpi.com/2504-2289/5/4/67},
ISSN = {2504-2289},
ABSTRACT = {Deep neural networks with rate-based neurons have exhibited tremendous progress in the last decade. However, the same level of progress has not been observed in research on spiking neural networks (SNN), despite their capability to handle temporal data, energy-efficiency and low latency. This could be because the benchmarking techniques for SNNs are based on the methods used for evaluating deep neural networks, which do not provide a clear evaluation of the capabilities of SNNs. Particularly, the benchmarking of SNN approaches with regards to energy efficiency and latency requires realization in suitable hardware, which imposes additional temporal and resource constraints upon ongoing projects. This review aims to provide an overview of the current real-world applications of SNNs and identifies steps to accelerate research involving SNNs in the future.},
DOI = {10.3390/bdcc5040067}
}



@Article{agriculture11111142,
AUTHOR = {Song, Huan and Hu, Yongguang and Lu, Yongzong and Wang, Jizhang and Pan, Qingmin and Li, Pingping},
TITLE = {A Review of Methods and Techniques for Detecting Frost on Plant Surfaces},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {1142},
URL = {https://www.mdpi.com/2077-0472/11/11/1142},
ISSN = {2077-0472},
ABSTRACT = {Severe frost usually has adverse impacts on agricultural production, resulting in crop freeze injury, poor crop yield, and crop quality reduction. Timely and accurate detection of frost plays an important role in cold damage warnings, prevention, and control. Current frost detection methods mostly use physical properties such as light, electricity, and heat, or the judge and quantify using environmental factors such as temperature and wind speed. However, it is difficult to detect and accurately identify the frosting phenomenon in real time during field trials because of the complex environment, different plant types, and interference by many factors during observation. To provide an overview of the analytical tools for scientists, researchers, and product developers, a review and comparative analysis of the available literature on frost mechanisms, correlations, and characteristics are presented in this study. First, the mechanisms of the frost formation process, frost level, and the significance of detection, are introduced. Then, the methods and techniques used to measure frost on plant surfaces are synthetically classified and further compared. Moreover, the key points and difficulties are summarized and discussed. Finally, some constructive methods of frost detection are proposed to improve the frost detection process.},
DOI = {10.3390/agriculture11111142}
}



@Article{computers10110153,
AUTHOR = {Tashtoush, Yahya and Haj-Mahmoud, Israa and Darwish, Omar and Maabreh, Majdi and Alsinglawi, Belal and Elkhodr, Mahmoud and Alsaedi, Nasser},
TITLE = {Enhancing Robots Navigation in Internet of Things Indoor Systems},
JOURNAL = {Computers},
VOLUME = {10},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {153},
URL = {https://www.mdpi.com/2073-431X/10/11/153},
ISSN = {2073-431X},
ABSTRACT = {In this study, an effective local minima detection and definition algorithm is introduced for a mobile robot navigating through unknown static environments. Furthermore, five approaches are presented and compared with the popular approach wall-following to pull the robot out of the local minima enclosure namely; Random Virtual Target, Reflected Virtual Target, Global Path Backtracking, Half Path Backtracking, and Local Path Backtracking. The proposed approaches mainly depend on changing the target location temporarily to avoid the original target&rsquo;s attraction force effect on the robot. Moreover, to avoid getting trapped in the same location, a virtual obstacle is placed to cover the local minima enclosure. To include the most common shapes of deadlock situations, the proposed approaches were evaluated in four different environments; V-shaped, double U-shaped, C-shaped, and cluttered environments. The results reveal that the robot, using any of the proposed approaches, requires fewer steps to reach the destination, ranging from 59 to 73 m on average, as opposed to the wall-following strategy, which requires an average of 732 m. On average, the robot with a constant speed and reflected virtual target approach takes 103 s, whereas the identical robot with a wall-following approach takes 907 s to complete the tasks. Using a fuzzy-speed robot, the duration for the wall-following approach is greatly reduced to 507 s, while the reflected virtual target may only need up to 20% of that time. More results and detailed comparisons are embedded in the subsequent sections.},
DOI = {10.3390/computers10110153}
}



@Article{rs13224587,
AUTHOR = {Liang, Gui-Chou and Ouyang, Yen-Chieh and Dai, Shu-Mei},
TITLE = {Detection and Classification of Rice Infestation with Rice Leaf Folder (Cnaphalocrocis medinalis) Using Hyperspectral Imaging Techniques},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4587},
URL = {https://www.mdpi.com/2072-4292/13/22/4587},
ISSN = {2072-4292},
ABSTRACT = {The detection of rice leaf folder (RLF) infestation usually depends on manual monitoring, and early infestations cannot be detected visually. To improve detection accuracy and reduce human error, we use push-broom hyperspectral sensors to scan rice images and use machine learning and deep neural learning methods to detect RLF-infested rice leaves. Different from traditional image processing methods, hyperspectral imaging data analysis is based on pixel-based classification and target recognition. Since the spectral information itself is a feature and can be considered a vector, deep learning neural networks do not need to use convolutional neural networks to extract features. To correctly detect the spectral image of rice leaves infested by RLF, we use the constrained energy minimization (CEM) method to suppress the background noise of the spectral image. A band selection method was utilized to reduce the computational energy consumption of using the full-band process, and six bands were selected as candidate bands. The following method is the band expansion process (BEP) method, which is utilized to expand the vector length to improve the problem of compressed spectral information for band selection. We use CEM and deep neural networks to detect defects in the spectral images of infected rice leaves and compare the performance of each in the full frequency band, frequency band selection, and frequency BEP. A total of 339 hyperspectral images were collected in this study; the results showed that six bands were sufficient for detecting early infestations of RLF, with a detection accuracy of 98% and a Dice similarity coefficient of 0.8, which provides advantages of commercialization of this field.},
DOI = {10.3390/rs13224587}
}



@Article{info12110474,
AUTHOR = {Wang, Jun and Yu, Liya and Yang, Jing and Dong, Hao},
TITLE = {DBA_SSD: A Novel End-to-End Object Detection Algorithm Applied to Plant Disease Detection},
JOURNAL = {Information},
VOLUME = {12},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {474},
URL = {https://www.mdpi.com/2078-2489/12/11/474},
ISSN = {2078-2489},
ABSTRACT = {In response to the difficulty of plant leaf disease detection and classification, this study proposes a novel plant leaf disease detection method called deep block attention SSD (DBA_SSD) for disease identification and disease degree classification of plant leaves. We propose three plant leaf detection methods, namely, squeeze-and-excitation SSD (Se_SSD), deep block SSD (DB_SSD), and DBA_SSD. Se_SSD fuses SSD feature extraction network and attention mechanism channel, DB_SSD improves VGG feature extraction network, and DBA_SSD fuses the improved VGG network and channel attention mechanism. To reduce the training time and accelerate the training process, the convolutional layers trained in the Image Net image dataset by the VGG model are migrated to this model, whereas the collected plant leaves disease image dataset is randomly divided into training set, validation set, and test set in the ratio of 8:1:1. We chose the PlantVillage dataset after careful consideration because it contains images related to the domain of interest. This dataset consists of images of 14 plants, including images of apples, tomatoes, strawberries, peppers, and potatoes, as well as the leaves of other plants. In addition, data enhancement methods, such as histogram equalization and horizontal flip were used to expand the image data. The performance of the three improved algorithms is compared and analyzed in the same environment and with the classical target detection algorithms YOLOv4, YOLOv3, Faster RCNN, and YOLOv4 tiny. Experiments show that DBA_SSD outperforms the two other improved algorithms, and its performance in comparative analysis is superior to other target detection algorithms.},
DOI = {10.3390/info12110474}
}



@Article{jimaging7110241,
AUTHOR = {Moussaid, Abdellatif and Fkihi, Sanaa El and Zennayi, Yahya},
TITLE = {Tree Crowns Segmentation and Classification in Overlapping Orchards Based on Satellite Images and Unsupervised Learning Algorithms},
JOURNAL = {Journal of Imaging},
VOLUME = {7},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {241},
URL = {https://www.mdpi.com/2313-433X/7/11/241},
PubMedID = {34821872},
ISSN = {2313-433X},
ABSTRACT = {Smart agriculture is a new concept that combines agriculture and new technologies to improve the yield’s quality and quantity as well as facilitate many tasks for farmers in managing orchards. An essential factor in smart agriculture is tree crown segmentation, which helps farmers automatically monitor their orchards and get information about each tree. However, one of the main problems, in this case, is when the trees are close to each other, which means that it would be difficult for the algorithm to delineate the crowns correctly. This paper used satellite images and machine learning algorithms to segment and classify trees in overlapping orchards. The data used are images from the Moroccan Mohammed VI satellite, and the study region is the OUARGHA citrus orchard located in Morocco. Our approach starts by segmenting the rows inside the parcel and finding all the trees there, getting their canopies, and classifying them by size. In general, the model inputs the parcel’s image and other field measurements to classify the trees into three classes: missing/weak, normal, or big. Finally, the results are visualized in a map containing all the trees with their classes. For the results, we obtained a score of 0.93 F-measure in rows segmentation. Additionally, several field comparisons were performed to validate the classification, dozens of trees were compared and the results were very good. This paper aims to help farmers to quickly and automatically classify trees by crown size, even if there are overlapping orchards, in order to easily monitor each tree’s health and understand the tree’s distribution in the field.},
DOI = {10.3390/jimaging7110241}
}



@Article{sym13112190,
AUTHOR = {Hashim, Wahidah and Eng, Lim Soon and Alkawsi, Gamal and Ismail, Rozita and Alkahtani, Ammar Ahmed and Dzulkifly, Sumayyah and Baashar, Yahia and Hussain, Azham},
TITLE = {A Hybrid Vegetation Detection Framework: Integrating Vegetation Indices and Convolutional Neural Network},
JOURNAL = {Symmetry},
VOLUME = {13},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2190},
URL = {https://www.mdpi.com/2073-8994/13/11/2190},
ISSN = {2073-8994},
ABSTRACT = {Vegetation inspection and monitoring is a time-consuming task. In the era of industrial revolution 4.0 (IR 4.0), unmanned aerial vehicles (UAV), commercially known as drones, are in demand, being adopted for vegetation inspection and monitoring activities. However, most off-the-shelf drones are least favoured by vegetation maintenance departments for on-site inspection due to limited spectral bands camera restricting advanced vegetation analysis. Most of these drones are normally equipped with a normal red, green, and blue (RGB) camera. Additional spectral bands are found to produce more accurate analysis during vegetation inspection, but at the cost of advanced camera functionalities, such as multispectral camera. Vegetation indices (VI) is a technique to maximize detection sensitivity related to vegetation characteristics while minimizing other factors which are not categorised otherwise. The emergence of machine learning has slowly influenced the existing vegetation analysis technique in order to improve detection accuracy. This study focuses on exploring VI techniques in identifying vegetation objects. The selected VIs investigated are Visible Atmospheric Resistant Index (VARI), Green Leaf Index (GLI), and Vegetation Index Green (VIgreen). The chosen machine learning technique is You Only Look Once (YOLO), which is a clever convolutional neural network (CNN) offering object detection in real time. The CNN model has a symmetrical structure along the direction of the tensor flow. Several series of data collection have been conducted at identified locations to obtain aerial images. The proposed hybrid methods were tested on captured aerial images to observe vegetation detection performance. Segmentation in image analysis is a process to divide the targeted pixels for further detection testing. Based on our findings, more than 70% of the vegetation objects in the images were accurately detected, which reduces the misdetection issue faced by previous VI techniques. On the other hand, hybrid segmentation methods perform best with the combination of VARI and YOLO at 84% detection accuracy.},
DOI = {10.3390/sym13112190}
}



@Article{w13223250,
AUTHOR = {Zhang, Fei and Chan, Ngai Weng and Liu, Changjiang and Wang, Xiaoping and Shi, Jingchao and Kung, Hsiang-Te and Li, Xinguo and Guo, Tao and Wang, Weiwei and Cao, Naixin},
TITLE = {Water Quality Index (WQI) as a Potential Proxy for Remote Sensing Evaluation of Water Quality in Arid Areas},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {3250},
URL = {https://www.mdpi.com/2073-4441/13/22/3250},
ISSN = {2073-4441},
ABSTRACT = {Water Resource Sustainability Management plays a vitally important role in ensuring sustainable development, especially in water-stressed arid regions throughout the world. In order to achieve sustainable development, it is necessary to study and monitor the water quality in the arid region of Central Asia, an area that is increasingly affected by climate change. In recent decades, the rapid deterioration of water quality in the Ebinur Lake basin in Xinjiang (China) has severely threatened sustainable economic development. This study selected the Ebinur Lake basin as the study target, with the purpose of revealing the response between the water quality index and water body reflectivity, and to describe the relationship between the water quality index and water reflectivity. The methodology employed remote sensing techniques that establish a water quality index monitoring model to monitor water quality. The results of our study include: (1) the Water Quality Index (WQI) that was used to evaluate the water environment in Ebinur Lake indicates a lower water quality of Ebinur Lake, with a WQI value as high as 4000; (2) an introduction of the spectral derivative method that realizes the extraction of spectral information from a water body to better mine the information of spectral data through remote sensing, and the results also prove that the spectral derivative method can improve the relationship between the water body spectral and WQI, whereby R2 is 0.6 at the most sensitive wavelengths; (3) the correlation between the spectral sensitivity index and WQI was greater than 0.6 at the significance level of 0.01 when multi-source spectral data were integrated with the spectral index (DI, RI and NDI) and fluorescence baseline; and (4) the distribution map of WQI in Ebinur Lake was obtained by the optimal model, which was constructed based on the third derivative data of Sentinel 2 data. We concluded that the water quality in the northwest of Ebinur Lake was the lowest in the region. In conclusion, we found that remote sensing techniques were highly effective and laid a foundation for water quality detection in arid areas.},
DOI = {10.3390/w13223250}
}



@Article{s21227629,
AUTHOR = {Ahmad, Muhammad Ikmal and Ab. Rahim, Mohd Hafizi and Nordin, Rosdiadee and Mohamed, Faizal and Abu-Samah, Asma’ and Abdullah, Nor Fadzilah},
TITLE = {Ionizing Radiation Monitoring Technology at the Verge of Internet of Things},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7629},
URL = {https://www.mdpi.com/1424-8220/21/22/7629},
PubMedID = {34833705},
ISSN = {1424-8220},
ABSTRACT = {As nuclear technology evolves, and continues to be used in various fields since its discovery less than a century ago, radiation safety has become a major concern to humans and the environment. Radiation monitoring plays a significant role in preventive radiological nuclear detection in nuclear facilities, hospitals, or in any activities associated with radioactive materials by acting as a tool to measure the risk of being exposed to radiation while reaping its benefit. Apart from in occupational settings, radiation monitoring is required in emergency responses to radiation incidents as well as outdoor radiation zones. Several radiation sensors have been developed, ranging from as simple as a Geiger-Muller counter to bulkier radiation systems such as the High Purity Germanium detector, with different functionality for use in different settings, but the inability to provide real-time data makes radiation monitoring activities less effective. The deployment of manned vehicles equipped with these radiation sensors reduces the scope of radiation monitoring operations significantly, but the safety of radiation monitoring operators is still compromised. Recently, the Internet of Things (IoT) technology has been introduced to the world and offered solutions to these limitations. This review elucidates a systematic understanding of the fundamental usage of the Internet of Drones for radiation monitoring purposes. The extension of essential functional blocks in IoT can be expanded across radiation monitoring industries, presenting several emerging research opportunities and challenges. This article offers a comprehensive review of the evolutionary application of IoT technology in nuclear and radiation monitoring. Finally, the security of the nuclear industry is discussed.},
DOI = {10.3390/s21227629}
}



@Article{rs13224632,
AUTHOR = {Teodoro, Paulo Eduardo and Teodoro, Larissa Pereira Ribeiro and Baio, Fábio Henrique Rojo and da Silva Junior, Carlos Antonio and dos Santos, Regimar Garcia and Ramos, Ana Paula Marques and Pinheiro, Mayara Maezano Faita and Osco, Lucas Prado and Gonçalves, Wesley Nunes and Carneiro, Alexsandro Monteiro and Junior, José Marcato and Pistori, Hemerson and Shiratsuchi, Luciano Shozo},
TITLE = {Predicting Days to Maturity, Plant Height, and Grain Yield in Soybean: A Machine and Deep Learning Approach Using Multispectral Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4632},
URL = {https://www.mdpi.com/2072-4292/13/22/4632},
ISSN = {2072-4292},
ABSTRACT = {In soybean, there is a lack of research aiming to compare the performance of machine learning (ML) and deep learning (DL) methods to predict more than one agronomic variable, such as days to maturity (DM), plant height (PH), and grain yield (GY). As these variables are important to developing an overall precision farming model, we propose a machine learning approach to predict DM, PH, and GY for soybean cultivars based on multispectral bands. The field experiment considered 524 genotypes of soybeans in the 2017/2018 and 2018/2019 growing seasons and a multitemporal–multispectral dataset collected by embedded sensor in an unmanned aerial vehicle (UAV). We proposed a multilayer deep learning regression network, trained during 2000 epochs using an adaptive subgradient method, a random Gaussian initialization, and a 50% dropout in the first hidden layer for regularization. Three different scenarios, including only spectral bands, only vegetation indices, and spectral bands plus vegetation indices, were adopted to infer each variable (PH, DM, and GY). The DL model performance was compared against shallow learning methods such as random forest (RF), support vector machine (SVM), and linear regression (LR). The results indicate that our approach has the potential to predict soybean-related variables using multispectral bands only. Both DL and RF models presented a strong (r surpassing 0.77) prediction capacity for the PH variable, regardless of the adopted input variables group. Our results demonstrated that the DL model (r = 0.66) was superior to predict DM when the input variable was the spectral bands. For GY, all machine learning models evaluated presented similar performance (r ranging from 0.42 to 0.44) for each tested scenario. In conclusion, this study demonstrated an efficient approach to a computational solution capable of predicting multiple important soybean crop variables based on remote sensing data. Future research could benefit from the information presented here and be implemented in subsequent processes related to soybean cultivars or other types of agronomic crops.},
DOI = {10.3390/rs13224632}
}



@Article{s21227668,
AUTHOR = {Kumari, Niharika and Ruf, Verena and Mukhametov, Sergey and Schmidt, Albrecht and Kuhn, Jochen and Küchemann, Stefan},
TITLE = {Mobile Eye-Tracking Data Analysis Using Object Detection via YOLO v4},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7668},
URL = {https://www.mdpi.com/1424-8220/21/22/7668},
PubMedID = {34833742},
ISSN = {1424-8220},
ABSTRACT = {Remote eye tracking has become an important tool for the online analysis of learning processes. Mobile eye trackers can even extend the range of opportunities (in comparison to stationary eye trackers) to real settings, such as classrooms or experimental lab courses. However, the complex and sometimes manual analysis of mobile eye-tracking data often hinders the realization of extensive studies, as this is a very time-consuming process and usually not feasible for real-world situations in which participants move or manipulate objects. In this work, we explore the opportunities to use object recognition models to assign mobile eye-tracking data for real objects during an authentic students&rsquo; lab course. In a comparison of three different Convolutional Neural Networks (CNN), a Faster Region-Based-CNN, you only look once (YOLO) v3, and YOLO v4, we found that YOLO v4, together with an optical flow estimation, provides the fastest results with the highest accuracy for object detection in this setting. The automatic assignment of the gaze data to real objects simplifies the time-consuming analysis of mobile eye-tracking data and offers an opportunity for real-time system responses to the user&rsquo;s gaze. Additionally, we identify and discuss several problems in using object detection for mobile eye-tracking data that need to be considered.},
DOI = {10.3390/s21227668}
}



@Article{rs13224662,
AUTHOR = {Qiao, Zhi and Sun, Siyang and Jiang, Qun’ou and Xiao, Ling and Wang, Yunqi and Yan, Haiming},
TITLE = {Retrieval of Total Phosphorus Concentration in the Surface Water of Miyun Reservoir Based on Remote Sensing Data and Machine Learning Algorithms},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4662},
URL = {https://www.mdpi.com/2072-4292/13/22/4662},
ISSN = {2072-4292},
ABSTRACT = {Some essential water conservation areas in China have continuously suffered from various serious problems such as water pollution and water quality deterioration in recent decades and thus called for real-time water pollution monitoring system underwater resources management. On the basis of the remote sensing data and ground monitoring data, this study firstly constructed a more accurate retrieval model for total phosphorus (TP) concentration by comparing 12 machine learning algorithms, including support vector machine (SVM), artificial neural network (ANN), Bayesian ridge regression (BRR), lasso regression (Lasso), elastic net (EN), linear regression (LR), decision tree regressor (DTR), K neighbor regressor (KNR), random forest regressor (RFR), extra trees regressor (ETR), AdaBoost regressor (ABR) and gradient boosting regressor (GBR). Then, this study applied the constructed retrieval model to explore the spatial-temporal evolution of the Miyun Reservoir and finally assessed the water quality. The results showed that the model of TP concentration built by the ETR algorithm had the best accuracy, with the coefficient R2 reaching over 85% and the mean absolute error lower than 0.000433. The TP concentration in Miyun Reservoir was between 0.0380 and 0.1298 mg/L, and there was relatively significant spatial and temporal heterogeneity. It changed remarkably during the periods of the flood season, winter tillage, planting, and regreening, and it was lower in summer than in other seasons. Moreover, the TP in the southwest part of the reservoir was generally lower than in the northeast, as there was less human activities interference. According to the Environmental Quality Standard for the surface water environment, the water quality of Miyun Reservoir was overall safe, except only for an over-standard case occurrence in the spring and September. These conclusions can provide a significant scientific reference for water quality monitoring and management in Miyun Reservoir.},
DOI = {10.3390/rs13224662}
}



@Article{sym13112208,
AUTHOR = {Jiang, Kunyi and Mao, Lei and Su, Yumin and Zheng, Yuxin},
TITLE = {Trajectory Tracking Control for Underactuated USV with Prescribed Performance and Input Quantization},
JOURNAL = {Symmetry},
VOLUME = {13},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2208},
URL = {https://www.mdpi.com/2073-8994/13/11/2208},
ISSN = {2073-8994},
ABSTRACT = {This paper is devoted to the problem of prescribed performance trajectory tracking control for symmetrical underactuated unmanned surface vessels (USVs) in the presence of model uncertainties and input quantization. By combining backstepping filter mechanisms and adaptive algorithms, two robust control architectures are investigated for surge motion and yaw motion. To guarantee the prespecified performance requirements for position tracking control, the constrained error dynamics are transformed to unconstrained ones by virtue of a tangent-type nonlinear mapping function. On the other hand, the inaccurate model can be identified through radial basis neural networks (RBFNNs), where the minimum learning parameter (MLP) algorithm is employed with a low computational complexity. Furthermore, quantization errors can be effectively reduced even when the parameters of the quantizer remain unavailable to designers. Finally, the effectiveness of the proposed controllers is verified via theoretical analyses and numerical simulations.},
DOI = {10.3390/sym13112208}
}



@Article{rs13224671,
AUTHOR = {Lu, Bing and He, Yuhong},
TITLE = {Assessing the Impacts of Species Composition on the Accuracy of Mapping Chlorophyll Content in Heterogeneous Ecosystems},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4671},
URL = {https://www.mdpi.com/2072-4292/13/22/4671},
ISSN = {2072-4292},
ABSTRACT = {Chlorophyll is an essential vegetation pigment influencing plant photosynthesis rate and growth conditions. Remote sensing images have been widely used for mapping vegetation chlorophyll content in different ecosystems (e.g., farmlands, forests, grasslands, and wetlands) for evaluating vegetation growth status and productivity of these ecosystems. Compared to farmlands and forests that are more homogeneous in terms of species composition, grasslands and wetlands are more heterogeneous with highly mixed species (e.g., various grass, forb, and shrub species). Different species contribute differently to the ecosystem services, thus, monitoring species-specific chlorophyll content is critical for better understanding their growth status, evaluating ecosystem functions, and supporting ecosystem management (e.g., control invasive species). However, previous studies in mapping chlorophyll content in heterogeneous ecosystems have rarely estimated species-specific chlorophyll content, which was partially due to the limited spatial resolution of remote sensing images commonly used in the past few decades for recognizing different species. In addition, many previous studies have used one universal model built with data of all species for mapping chlorophyll of the entire study area, which did not fully consider the impacts of species composition on the accuracy of chlorophyll estimation (i.e., establishing species-specific chlorophyll estimation models may generate higher accuracy). In this study, helicopter-acquired high-spatial resolution hyperspectral images were acquired for species classification and species-specific chlorophyll content estimation. Four estimation models, including a universal linear regression (LR) model (i.e., built with data of all species), species-specific LR models (i.e., built with data of each species, respectively), a universal random forest regression (RFR) model, and species-specific RFR models, were compared to determine their performance in mapping chlorophyll and to evaluate the impacts of species composition. The results show that species-specific models performed better than the universal models, especially for species with fewer samples in the dataset. The best performed species-specific models were then used to generate species-specific chlorophyll content maps using the species classification results. Impacts of species composition on the retrieval of chlorophyll content were further assessed to support future chlorophyll mapping in heterogeneous ecosystems and ecosystem management.},
DOI = {10.3390/rs13224671}
}



@Article{drones5040137,
AUTHOR = {Yasentsev, Dmitry and Shevgunov, Timofey and Efimov, Evgeny and Tatarskiy, Boris},
TITLE = {Using Ground-Based Passive Reflectors for Improving UAV Landing},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {137},
URL = {https://www.mdpi.com/2504-446X/5/4/137},
ISSN = {2504-446X},
ABSTRACT = {The article reviews the problem of landing on hard-to-reach and poorly developed territories, especially in the case of unmanned aerial vehicles. Various landing systems and approaches are analyzed, and their key advantages and disadvantages are summarized; afterwards, an approach with passive reflectors is considered. A formal definition is provided for the main factors relative to the accuracy analysis, and a model is presented. The way to improve the landing procedure, while simultaneously meeting various practical constraints, is analyzed; the results of numerical simulation are presented, followed by the detailed conclusion describing still remaining challenges and subjects for further research.},
DOI = {10.3390/drones5040137}
}



@Article{rs13224677,
AUTHOR = {Krisanski, Sean and Taskhiri, Mohammad Sadegh and Gonzalez Aracil, Susana and Herries, David and Muneri, Allie and Gurung, Mohan Babu and Montgomery, James and Turner, Paul},
TITLE = {Forest Structural Complexity Tool—An Open Source, Fully-Automated Tool for Measuring Forest Point Clouds},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4677},
URL = {https://www.mdpi.com/2072-4292/13/22/4677},
ISSN = {2072-4292},
ABSTRACT = {Forest mensuration remains critical in managing our forests sustainably, however, capturing such measurements remains costly, time-consuming and provides minimal amounts of information such as diameter at breast height (DBH), location, and height. Plot scale remote sensing techniques show great promise in extracting detailed forest measurements rapidly and cheaply, however, they have been held back from large-scale implementation due to the complex and time-consuming workflows required to utilize them. This work is focused on describing and evaluating an approach to create a robust, sensor-agnostic and fully automated forest point cloud measurement tool called the Forest Structural Complexity Tool (FSCT). The performance of FSCT is evaluated using 49 forest plots of terrestrial laser scanned (TLS) point clouds and 7022 destructively sampled manual diameter measurements of the stems. FSCT was able to match 5141 of the reference diameter measurements fully automatically with mean, median and root mean squared errors (RMSE) of 0.032 m, 0.02 m, and 0.103 m respectively. A video demonstration is also provided to qualitatively demonstrate the diversity of point cloud datasets that the tool is capable of measuring. FSCT is provided as open source, with the goal of enabling plot scale remote sensing techniques to replace most structural forest mensuration in research and industry. Future work on this project will seek to make incremental improvements to this methodology to further improve the reliability and accuracy of this tool in most high-resolution forest point clouds.},
DOI = {10.3390/rs13224677}
}



@Article{fire4040087,
AUTHOR = {Deligiannakis, Georgios and Pallikarakis, Aggelos and Papanikolaou, Ioannis and Alexiou, Simoni and Reicherter, Klaus},
TITLE = {Detecting and Monitoring Early Post-Fire Sliding Phenomena Using UAV&ndash;SfM Photogrammetry and t-LiDAR-Derived Point Clouds},
JOURNAL = {Fire},
VOLUME = {4},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {87},
URL = {https://www.mdpi.com/2571-6255/4/4/87},
ISSN = {2571-6255},
ABSTRACT = {Soil changes, including landslides and erosion, are some of the most prominent post-fire effects in Mediterranean ecosystems. Landslide detection and monitoring play an essential role in mitigation measures. We tested two different methodologies in five burned sites with different characteristics in Central Greece. We compared Unmanned Aerial Vehicles (UAV)-derived high-resolution Digital Surface Models and point clouds with terrestrial Light Detection and Ranging (LiDAR)-derived point clouds to reveal new cracks and monitor scarps of pre-existing landslides. New cracks and scarps were revealed at two sites after the wildfire, measuring up to 27 m in length and up to 25 &plusmn; 5 cm in depth. Pre-existing scarps in both Kechries sites appeared to be active, with additional vertical displacements ranging from 5&ndash;15 &plusmn; 5 cm. In addition, the pre-existing landslide in Magoula expanded by 8%. Due to vegetation regrowth, no changes could be detected in the Agios Stefanos pre-existing landslide. This high-spatial-resolution mapping of slope deformations can be used as landslide precursor, assisting prevention measures. Considering the lack of vegetation after wildfires, UAV photogrammetry has great potential for tracing such early landslide indicators and is more efficient for accurately recording soil changes.},
DOI = {10.3390/fire4040087}
}



@Article{rs13224700,
AUTHOR = {Sun, Xiaoyu and Zhao, Wufan and Maretto, Raian V. and Persello, Claudio},
TITLE = {Building Polygon Extraction from Aerial Images and Digital Surface Models with a Frame Field Learning Framework},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4700},
URL = {https://www.mdpi.com/2072-4292/13/22/4700},
ISSN = {2072-4292},
ABSTRACT = {Deep learning-based models for building delineation from remotely sensed images face the challenge of producing precise and regular building outlines. This study investigates the combination of normalized digital surface models (nDSMs) with aerial images to optimize the extraction of building polygons using the frame field learning method. Results are evaluated at pixel, object, and polygon levels. In addition, an analysis is performed to assess the statistical deviations in the number of vertices of building polygons compared with the reference. The comparison of the number of vertices focuses on finding the output polygons that are the easiest to edit by human analysts in operational applications. It can serve as guidance to reduce the post-processing workload for obtaining high-accuracy building footprints. Experiments conducted in Enschede, the Netherlands, demonstrate that by introducing nDSM, the method could reduce the number of false positives and prevent missing the real buildings on the ground. The positional accuracy and shape similarity was improved, resulting in better-aligned building polygons. The method achieved a mean intersection over union (IoU) of 0.80 with the fused data (RGB + nDSM) against an IoU of 0.57 with the baseline (using RGB only) in the same area. A qualitative analysis of the results shows that the investigated model predicts more precise and regular polygons for large and complex structures.},
DOI = {10.3390/rs13224700}
}



@Article{rs13224704,
AUTHOR = {Aneece, Itiya and Thenkabail, Prasad S.},
TITLE = {Classifying Crop Types Using Two Generations of Hyperspectral Sensors (Hyperion and DESIS) with Machine Learning on the Cloud},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4704},
URL = {https://www.mdpi.com/2072-4292/13/22/4704},
ISSN = {2072-4292},
ABSTRACT = {Advances in spaceborne hyperspectral (HS) remote sensing, cloud-computing, and machine learning can help measure, model, map and monitor agricultural crops to address global food and water security issues, such as by providing accurate estimates of crop area and yield to model agricultural productivity. Leveraging these advances, we used the Earth Observing-1 (EO-1) Hyperion historical archive and the new generation DLR Earth Sensing Imaging Spectrometer (DESIS) data to evaluate the performance of hyperspectral narrowbands in classifying major agricultural crops of the U.S. with machine learning (ML) on Google Earth Engine (GEE). EO-1 Hyperion images from the 2010&ndash;2013 growing seasons and DESIS images from the 2019 growing season were used to classify three world crops (corn, soybean, and winter wheat) along with other crops and non-crops near Ponca City, Oklahoma, USA. The supervised classification algorithms: Random Forest (RF), Support Vector Machine (SVM), and Naive Bayes (NB), and the unsupervised clustering algorithm WekaXMeans (WXM) were run using selected optimal Hyperion and DESIS HS narrowbands (HNBs). RF and SVM returned the highest overall producer&rsquo;s, and user&rsquo;s accuracies, with the performances of NB and WXM being substantially lower. The best accuracies were achieved with two or three images throughout the growing season, especially a combination of an earlier month (June or July) and a later month (August or September). The narrow 2.55 nm bandwidth of DESIS provided numerous spectral features along the 400&ndash;1000 nm spectral range relative to smoother Hyperion spectral signatures with 10 nm bandwidth in the 400&ndash;2500 nm spectral range. Out of 235 DESIS HNBs, 29 were deemed optimal for agricultural study. Advances in ML and cloud-computing can greatly facilitate HS data analysis, especially as more HS datasets, tools, and algorithms become available on the Cloud.},
DOI = {10.3390/rs13224704}
}



@Article{drones5040138,
AUTHOR = {Javidsharifi, Mahshid and Pourroshanfekr Arabani, Hamoun and Kerekes, Tamas and Sera, Dezso and Spataru, Sergiu Viorel and Guerrero, Josep M.},
TITLE = {Optimum Sizing of Photovoltaic-Battery Power Supply for Drone-Based Cellular Networks},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {138},
URL = {https://www.mdpi.com/2504-446X/5/4/138},
ISSN = {2504-446X},
ABSTRACT = {In order to provide Internet access to rural areas and places without a reliable economic electricity grid, self-sustainable drone-based cellular networks have recently been presented. However, the difficulties of power consumption and mission planning lead to the challenge of optimal sizing of the power supply for future cellular telecommunication networks. In order to deal with this challenge, this paper presents an optimal approach for sizing the photovoltaic (PV)-battery power supply for drone-based cellular networks in remote areas. The main objective of the suggested approach is to minimize the total cost, including the capital and operational expenditures. The suggested framework is applied to an off-grid cellular telecommunication network with drone-based base stations that are powered by PV-battery systems-based recharging sites in a rural location. The PV-battery system is optimally designed for three recharging sites with three different power consumption profiles with different peak and cumulative loads. Results show that the optimal design of the PV-battery system is dependent on geographical data, solar irradiation, and ambient temperature, which affect the output power of the PV system, as well as the power consumption profile, which affects the required number of PV panels and battery capacity.},
DOI = {10.3390/drones5040138}
}



@Article{jmse9121320,
AUTHOR = {Li, Xunmeng and Wang, Kai and Chen, Jianqu and Zhang, Shouyu},
TITLE = {Allometric Growth of Sargassum fusiforme (Ochrophyta, Fucales) Organs in the Maturation Period Based on Biomass Analysis of Samples from Gouqi Island},
JOURNAL = {Journal of Marine Science and Engineering},
VOLUME = {9},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1320},
URL = {https://www.mdpi.com/2077-1312/9/12/1320},
ISSN = {2077-1312},
ABSTRACT = {Sargassum fusiforme is a seaweed species that plays an important role in the diverse communities of the flora and fauna of coastal food webs. Assessments of its biomass and energy allocation in addition to allometric organ growth have important ecological value for understanding the community structure, carbon storage, and resource assessment of seaweed beds during periods in which they thrive. In this study, the morphology of Sargassum fusiforme and the biomass of organs and total organisms in the maturation period were studied, and the allometric relationships for different organs of Sargassum fusiforme were analyzed using the standardized major axis (SMA). In the maturation period of Sargassum fusiforme, branch number, height &times; stem diameter were the prior independent variables, and the optimum biomass was y = 0.002x1.107 (R2 = 0.923). The biomass allocation ratio of blades was the highest (38.33%), followed by stems (32.90%) and receptacles (28.77%). The growth rates of the various organs were found to differ, and the rate of biomass increase for the blades and stems tended to converge. The rate of receptacle biomass growth of Sargassum fusiforme was the highest in the maturation period, and the rate of organ biomass increase was Wb &lt; Ws &lt; Wt &lt; Wr, which reflects the trade-off with energy allocation as a strategy used by Sargassum fusiforme.},
DOI = {10.3390/jmse9121320}
}



@Article{machines9120304,
AUTHOR = {Zhang, Houzhong and Yang, Xiangtian and Liang, Jiasheng and Xu, Xing and Sun, Xiaoqiang},
TITLE = {GPS Path Tracking Control of Military Unmanned Vehicle Based on Preview Variable Universe Fuzzy Sliding Mode Control},
JOURNAL = {Machines},
VOLUME = {9},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {304},
URL = {https://www.mdpi.com/2075-1702/9/12/304},
ISSN = {2075-1702},
ABSTRACT = {In the process of the continuous development and improvement of modern military systems, military unmanned vehicles play an important role in field reconnaissance and strategic deployment. In this paper, the precise tracking algorithm of a military unmanned vehicle, based on GPS navigation, is studied. Firstly, the optimal preview point is obtained according to the data points of a differential GPS signal. Secondly, the pure tracking algorithm is used to calculate the demand steering angle, and a variable universe fuzzy sliding mode controller is designed to control the lateral motion of the vehicle, which is verified by the joint simulation platform of Simulink and CarSim, under multiple working conditions. Finally, the actual vehicle is verified by using the Autobox platform. The results show that the lateral motion control of path tracking designed in this paper can achieve an accurate and effective control effect, and has real-time performance for engineering applications.},
DOI = {10.3390/machines9120304}
}



@Article{app112311090,
AUTHOR = {Aguilar-Mejía, Omar and Minor-Popocatl, Hertwin and Pacheco-García, Prudencio Fidel and Tapia-Olvera, Ruben},
TITLE = {Neuroadaptive Robust Speed Control for PMSM Servo Drives with Rotor Failure},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {11090},
URL = {https://www.mdpi.com/2076-3417/11/23/11090},
ISSN = {2076-3417},
ABSTRACT = {In this paper, a neuroadaptive robust trajectory tracking controller is utilized to reduce speed ripples of permanent magnet synchronous machine (PMSM) servo drive under the presence of a fracture or fissure in the rotor and external disturbances. The dynamics equations of PMSM servo drive with the presence of a fracture and unknown frictions are described in detail. Due to inherent nonlinearities in PMSM dynamic model, in addition to internal and external disturbances; a traditional PI controller with fixed parameters cannot correctly regulate the PMSM performance under these scenarios. Hence, a neuroadaptive robust controller (NRC) based on a category of on-line trained artificial neural network is used for this purpose to enhance the robustness and adaptive abilities of traditional PI controller. In this paper, the moth-flame optimization algorithm provides the optimal weight parameters of NRC and three PI controllers (off-line) for a PMSM servo drive. The performance of the NRC is evaluated in the presence of a fracture, unknown frictions, and load disturbances, likewise the result outcomes are contrasted with a traditional optimized PID controller and an optimal linear state feedback method.},
DOI = {10.3390/app112311090}
}



@Article{electronics10232893,
AUTHOR = {Kakhani, Nafiseh and Mokhtarzade, Mehdi and Valadan Zoej, Mohammad Javad},
TITLE = {Deep Learning Spatial-Spectral Classification of Remote Sensing Images by Applying Morphology-Based Differential Extinction Profile (DEP)},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {2893},
URL = {https://www.mdpi.com/2079-9292/10/23/2893},
ISSN = {2079-9292},
ABSTRACT = {Since the technology of remote sensing has been improved recently, the spatial resolution of satellite images is getting finer. This enables us to precisely analyze the small complex objects in a scene through remote sensing images. Thus, the need to develop new, efficient algorithms like spatial-spectral classification methods is growing. One of the most successful approaches is based on extinction profile (EP), which can extract contextual information from remote sensing data. Moreover, deep learning classifiers have drawn attention in the remote sensing community in the past few years. Recent progress has shown the effectiveness of deep learning at solving different problems, particularly segmentation tasks. This paper proposes a novel approach based on a new concept, which is differential extinction profile (DEP). DEP makes it possible to have an input feature vector with both spectral and spatial information. The input vector is then fed into a proposed straightforward deep-learning-based classifier to produce a thematic map. The approach is carried out on two different urban datasets from Pleiades and World-View 2 satellites. In order to prove the capabilities of the suggested approach, we compare the final results to the results of other classification strategies with different input vectors and various types of common classifiers, such as support vector machine (SVM) and random forests (RF). It can be concluded that the proposed approach is significantly improved in terms of three kinds of criteria, which are overall accuracy, Kappa coefficient, and total disagreement.},
DOI = {10.3390/electronics10232893}
}



@Article{rs13234742,
AUTHOR = {Gawehn, Matthijs and de Vries, Sierd and Aarninkhof, Stefan},
TITLE = {A Self-Adaptive Method for Mapping Coastal Bathymetry On-The-Fly from Wave Field Video},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4742},
URL = {https://www.mdpi.com/2072-4292/13/23/4742},
ISSN = {2072-4292},
ABSTRACT = {Mapping coastal bathymetry from remote sensing becomes increasingly more attractive for the coastal community. It is facilitated by a rising availability of drone and satellite data, advances in data science, and an open-source mindset. Coastal bathymetry, but also wave directions, celerity and near-surface currents can simultaneously be derived from aerial video of a wave field. However, the required video processing is usually extensive, requires skilled supervision, and is tailored to a fieldsite. This study proposes a video-processing algorithm that resolves these issues. It automatically adapts to the video data and continuously returns mapping updates and thereby aims to make wave-based remote sensing more inclusive to the coastal community. The code architecture for the first time includes the dynamic mode decomposition (DMD) to reduce the data complexity of wavefield video. The DMD is paired with loss-functions to handle spectral noise and a novel spectral storage system and Kalman filter to achieve fast converging measurements. The algorithm is showcased for fieldsites in the USA, the UK, the Netherlands, and Australia. The performance with respect to mapping bathymetry was validated using ground truth data. It was demonstrated that merely 32 s of video footage is needed for a first mapping update with average depth errors of 0.9&ndash;2.6 m. These further reduced to 0.5&ndash;1.4 m as the videos continued and more mapping updates were returned. Simultaneously, coherent maps for wave direction and celerity were achieved as well as maps of local near-surface currents. The algorithm is capable of mapping the coastal parameters on-the-fly and thereby offers analysis of video feeds, such as from drones or operational camera installations. Hence, the innovative application of analysis techniques like the DMD enables both accurate and unprecedentedly fast coastal reconnaissance. The source code and data of this article are openly available.},
DOI = {10.3390/rs13234742}
}



@Article{rs13234735,
AUTHOR = {Appeltans, Simon and Apolo-Apolo, Orly Enrique and Rodríguez-Vázquez, Jaime Nolasco and Pérez-Ruiz, Manuel and Pieters, Jan and Mouazen, Abdul M.},
TITLE = {The Automation of Hyperspectral Training Library Construction: A Case Study for Wheat and Potato Crops},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4735},
URL = {https://www.mdpi.com/2072-4292/13/23/4735},
ISSN = {2072-4292},
ABSTRACT = {The potential of hyperspectral measurements for early disease detection has been investigated by many experts over the last 5 years. One of the difficulties is obtaining enough data for training and building a hyperspectral training library. When the goal is to detect disease at a previsible stage, before the pathogen has manifested either its first symptoms or in the area surrounding the existing symptoms, it is impossible to objectively delineate the regions of interest containing the previsible pathogen growth from the areas without the pathogen growth. To overcome this, we propose an image labelling and segmentation algorithm that is able to (a) more objectively label the visible symptoms for the construction of a training library and (b) extend this labelling to the pre-visible symptoms. This algorithm is used to create hyperspectral training libraries for late blight disease (Phytophthora infestans) in potatoes and two types of leaf rust (Puccinia triticina and Puccinia striiformis) in wheat. The model training accuracies were compared between the automatic labelling algorithm and the classic visual delineation of regions of interest using a logistic regression machine learning approach. The modelling accuracies of the automatically labelled datasets were higher than those of the manually labelled ones for both potatoes and wheat, at 98.80% for P. infestans in potato, 97.69% for P. striiformis in soft wheat, and 96.66% for P. triticina in durum wheat.},
DOI = {10.3390/rs13234735}
}



@Article{agronomy11122373,
AUTHOR = {Hashim, Izrahayu Che and Shariff, Abdul Rashid Mohamed and Bejo, Siti Khairunniza and Muharam, Farrah Melissa and Ahmad, Khairulmazmi},
TITLE = {Classification of Non-Infected and Infected with Basal Stem Rot Disease Using Thermal Images and Imbalanced Data Approach},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2373},
URL = {https://www.mdpi.com/2073-4395/11/12/2373},
ISSN = {2073-4395},
ABSTRACT = {Basal stem rot (BSR) disease occurs due to the most aggressive and threatening fungal attack of the oil palm plant known as Ganoderma boninense (G. boninense). BSR is a disease that has a significant impact on oil palm crops in Malaysia and Indonesia. Currently, the only sustainable strategy available is to extend the life of oil palm trees, as there is no effective treatment for BSR disease. This study used thermal imagery to identify the thermal features to classify non-infected and BSR-infected trees. The aims of this study were to (1) identify the potential temperature features and (2) examine the performance of machine learning (ML) classifiers (na&iuml;ve Bayes (NB), multilayer perceptron (MLP), and random forest (RF) to classify oil palm trees that are non-infected and BSR-infected. The sample size consisted of 55 uninfected trees and 37 infected trees. We used the imbalance data approaches such as random undersampling (RUS), random oversampling (ROS) and synthetic minority oversampling (SMOTE) in these classifications due to the different sample sizes. The study found that the Tmax feature is the most beneficial temperature characteristic for classifying non-infected or infected BSR trees. Meanwhile, the ROS approach improves the curve region (AUC) and PRC results compared to a single approach. The result showed that the temperature feature Tmax and combination feature TmaxTmin had a higher correct classification for the G. boninense non-infected and infected oil palm trees for the ROS-RF and had a robust success rate, classifying correctly 87.10% for non-infected and 100% for infected by G. boninense. In terms of model performance using the most significant variables, Tmax, the ROS-RF model had an excellent receiver operating characteristics (ROC) curve region (AUC) of 0.921, and the precision&ndash;recall curve (PRC) region gave a value of 0.902. Therefore, it can be concluded that the ROS-RF, using the Tmax, can be used to predict BSR disease with relatively high accuracy.},
DOI = {10.3390/agronomy11122373}
}



@Article{rs13234750,
AUTHOR = {Chen, Jianchang and Chen, Yiming and Liu, Zhengjun},
TITLE = {Classification of Typical Tree Species in Laser Point Cloud Based on Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4750},
URL = {https://www.mdpi.com/2072-4292/13/23/4750},
ISSN = {2072-4292},
ABSTRACT = {We propose the Point Cloud Tree Species Classification Network (PCTSCN) to overcome challenges in classifying tree species from laser data with deep learning methods. The network is mainly composed of two parts: a sampling component in the early stage and a feature extraction component in the later stage. We used geometric sampling to extract regions with local features from the tree contours since these tend to be species-specific. Then we used an improved Farthest Point Sampling method to extract the features from a global perspective. We input the intensity of the tree point cloud as a dimensional feature and spatial information into the neural network and mapped it to higher dimensions for feature extraction. We used the data obtained by Terrestrial Laser Scanning (TLS) and Unmanned Aerial Vehicle Laser Scanning (UAVLS) to conduct tree species classification experiments of white birch and larch. The experimental results showed that in both the TLS and UAVLS datasets, the input tree point cloud density and the highest feature dimensionality of the mapping had an impact on the classification accuracy of the tree species. When the single tree sample obtained by TLS consisted of 1024 points and the highest dimension of the network mapping was 512, the classification accuracy of the trained model reached 96%. For the individual tree samples obtained by UAVLS, which consisted of 2048 points and had the highest dimension of the network mapping of 1024, the classification accuracy of the trained model reached 92%. TLS data tree species classification accuracy of PCTSCN was improved by 2&ndash;9% compared with other models using the same point density, amount of data and highest feature dimension. The classification accuracy of tree species obtained by UAVLS was up to 8% higher. We propose PCTSCN to provide a new strategy for the intelligent classification of forest tree species.},
DOI = {10.3390/rs13234750}
}



@Article{rs13234751,
AUTHOR = {Wang, Jionghua and Luo, Haowen and Li, Wenyu and Huang, Bo},
TITLE = {Building Function Mapping Using Multisource Geospatial Big Data: A Case Study in Shenzhen, China},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4751},
URL = {https://www.mdpi.com/2072-4292/13/23/4751},
ISSN = {2072-4292},
ABSTRACT = {Building function labelling plays an important role in understanding human activities inside buildings. This study develops a method of function label classification using integrated features derived from remote sensing and crowdsensing data with an extreme gradient boosting tree (XGBoost). The classification framework is verified based on a dataset from Shenzhen, China. An extended label system for six building types (residential, commercial, office, industrial, public facilities, and others) was applied, and various social functions were considered. The overall classification accuracies were 88.15% (kappa index = 0.72) and 85.56% (kappa index = 0.69). The importance of features was evaluated using the occurrence frequency of features at decision nodes. In the six-category classification system, the basic building attributes (22.99%) and POIs (46.74%) contributed most to the classification process; moreover, the building footprint (7.40%) and distance to roads (11.76%) also made notable contributions. The result shows that it is feasible to extract building environments from POI labels and building footprint geometry with a dimensional reduction model using an autoencoder. Additionally, crowdsensing data (e.g., POI and distance to roads) will become increasingly important as classification tasks become more complicated and the importance of basic building attributes declines.},
DOI = {10.3390/rs13234751}
}



@Article{su132312980,
AUTHOR = {Wang, Zhenhua and Zhang, Xinyue and Li, Jing and Luan, Kuifeng},
TITLE = {A YOLO-Based Target Detection Model for Offshore Unmanned Aerial Vehicle Data},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {12980},
URL = {https://www.mdpi.com/2071-1050/13/23/12980},
ISSN = {2071-1050},
ABSTRACT = {Target detection in offshore unmanned aerial vehicle data is still a challenge due to the complex characteristics of targets, such as multi-sizes, alterable orientation, and complex backgrounds. Herein, a YOLO-based detection model (YOLO-D) was proposed for target detection in offshore unmanned aerial vehicle data. Based on the YOLOv3 network, the residual module was improved by establishing dense connections and adding a dual-attention mechanism (CBAM) to enhance the use of features and global information. Then, the loss function of the YOLO-D model was added to the weight coefficients to increase detection accuracy for small-size targets. Finally, the feature pyramid network (FPN) was replaced by the secondary recursive feature pyramid network to reduce the impacts of a complicated environment. Taking the car, boat, and deposit near the coastline as the targets, the proposed YOLO-D model was compared against other models, including the faster R-CNN, SSD, YOLOv3, and YOLOv5, to evaluate its detection performance. The results showed that the evaluation metrics of the YOLO-D model, including precision (Pr), recall (Re), average precision (AP), and the mean of average precision (mAP), had the highest values. The mAP of the YOLO-D model increased by 37.95%, 39.44%, 28.46%, and 5.08% compared to the faster R-CNN, SSD, YOLOv3, and YOLOv5, respectively. The AP of the car, boat, and deposit reached 96.24%, 93.70%, and 96.79% respectively. Moreover, the YOLO-D model had a higher detection accuracy than other models, especially in the detection of small-size targets. Collectively, the proposed YOLO-D model is a suitable model for target detection in offshore unmanned aerial vehicle data.},
DOI = {10.3390/su132312980}
}



@Article{rs13234757,
AUTHOR = {Sekrecka, Aleksandra},
TITLE = {Application of the XBoost Regressor for an A Priori Prediction of UAV Image Quality},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4757},
URL = {https://www.mdpi.com/2072-4292/13/23/4757},
ISSN = {2072-4292},
ABSTRACT = {In general, the quality of imagery from Unmanned Aerial Vehicles (UAVs) is evaluated after the flight, and then a decision is made on the further value and use of the acquired data. In this paper, an a priori (preflight) image quality prediction methodology is proposed to estimate the preflight image quality and to avoid unfavourable flights, which is extremely important from a time and cost management point of view. The XBoost Regressor model and cross-validation were used for machine learning of the model and image quality prediction. The model was learned on a rich database of real-world images acquired from UAVs under conditions varying in both sensor type, UAV type, exposure parameters, weather, topography, and land cover. Radiometric quality indices (SNR, Entropy, PIQE, NIQE, BRISQUE, and NRPBM) were calculated for each image to train and test the model and to assess the accuracy of image quality prediction. Different variants of preflight parameter knowledge were considered in the study. The proposed methodology offers the possibility of predicting image quality with high accuracy. The correlation coefficient between the actual and predicted image quality, depending on the number of parameters known a priori, ranged from 0.90 to 0.96. The methodology was designed for data acquired from a UAV. Similar prediction accuracy is expected for other low-altitude or close-range photogrammetric data.},
DOI = {10.3390/rs13234757}
}



@Article{telecom2040027,
AUTHOR = {Singh, Simran and Kumbhar, Abhaykumar and Güvenç, İsmail and Sichitiu, Mihail L.},
TITLE = {Intelligent Interference Management in UAV-Based HetNets},
JOURNAL = {Telecom},
VOLUME = {2},
YEAR = {2021},
NUMBER = {4},
PAGES = {472--488},
URL = {https://www.mdpi.com/2673-4001/2/4/27},
ISSN = {2673-4001},
ABSTRACT = {Unmanned aerial vehicles (UAVs) can play a key role in meeting certain demands of cellular networks. UAVs can be used not only as user equipment (UE) in cellular networks but also as mobile base stations (BSs) wherein they can either augment conventional BSs by adapting their position to serve the changing traffic and connectivity demands or temporarily replace BSs that are damaged due to natural disasters. The flexibility of UAVs allows them to provide coverage to UEs in hot-spots, at cell-edges, in coverage holes, or regions with scarce cellular infrastructure. In this work, we study how UAV locations and other cellular parameters may be optimized in such scenarios to maximize the spectral efficiency (SE) of the network. We compare the performance of machine learning (ML) techniques with conventional optimization approaches. We found that, on an average, a double deep Q learning approach can achieve 93.46% of the optimal median SE and 95.83% of the optimal mean SE. A simple greedy approach, which tunes the parameters of each BS and UAV independently, performed very well in all the cases that we tested. These computationally efficient approaches can be utilized to enhance the network performance in existing cellular networks.},
DOI = {10.3390/telecom2040027}
}



@Article{rs13234759,
AUTHOR = {Kim, Junwoo and Kim, Hwisong and Jeon, Hyungyun and Jeong, Seung-Hwan and Song, Juyoung and Vadivel, Suresh Krishnan Palanisamy and Kim, Duk-jin},
TITLE = {Synergistic Use of Geospatial Data for Water Body Extraction from Sentinel-1 Images for Operational Flood Monitoring across Southeast Asia Using Deep Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4759},
URL = {https://www.mdpi.com/2072-4292/13/23/4759},
ISSN = {2072-4292},
ABSTRACT = {Deep learning is a promising method for image classification, including satellite images acquired by various sensors. However, the synergistic use of geospatial data for water body extraction from Sentinel-1 data using deep learning and the applicability of existing deep learning models have not been thoroughly tested for operational flood monitoring. Here, we present a novel water body extraction model based on a deep neural network that exploits Sentinel-1 data and flood-related geospatial datasets. For the model, the U-Net was customised and optimised to utilise Sentinel-1 data and other flood-related geospatial data, including digital elevation model (DEM), Slope, Aspect, Profile Curvature (PC), Topographic Wetness Index (TWI), Terrain Ruggedness Index (TRI), and Buffer for the Southeast Asia region. Testing and validation of the water body extraction model was applied to three Sentinel-1 images for Vietnam, Myanmar, and Bangladesh. By segmenting 384 Sentinel-1 images, model performance and segmentation accuracy for all of the 128 cases that the combination of stacked layers had determined were evaluated following the types of combined input layers. Of the 128 cases, 31 cases showed improvement in Overall Accuracy (OA), and 19 cases showed improvement in both averaged intersection over union (IOU) and F1 score for the three Sentinel-1 images segmented for water body extraction. The averaged OA, IOU, and F1 scores of the &lsquo;Sentinel-1 VV&rsquo; band are 95.77, 80.35, and 88.85, respectively, whereas those of &lsquo;band combination VV, Slope, PC, and TRI&rsquo; are 96.73, 85.42, and 92.08, showing improvement by exploiting geospatial data. Such improvement was further verified with water body extraction results for the Chindwin river basin, and quantitative analysis of &lsquo;band combination VV, Slope, PC, and TRI&rsquo; showed an improvement of the F1 score by 7.68 percent compared to the segmentation output of the &lsquo;Sentinel-1 VV&rsquo; band. Through this research, it was demonstrated that the accuracy of deep learning-based water body extraction from Sentinel-1 images can be improved up to 7.68 percent by employing geospatial data. To the best of our knowledge, this is the first work of research that demonstrates the synergistic use of geospatial data in deep learning-based water body extraction over wide areas. It is anticipated that the results of this research could be a valuable reference when deep neural networks are applied for satellite image segmentation for operational flood monitoring and when geospatial layers are employed to improve the accuracy of deep learning-based image segmentation.},
DOI = {10.3390/rs13234759}
}



@Article{s21237829,
AUTHOR = {Pina, Rafael and Tibebu, Haileleol and Hook, Joosep and De Silva, Varuna and Kondoz, Ahmet},
TITLE = {Overcoming Challenges of Applying Reinforcement Learning for Intelligent Vehicle Control},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7829},
URL = {https://www.mdpi.com/1424-8220/21/23/7829},
PubMedID = {34883832},
ISSN = {1424-8220},
ABSTRACT = {Reinforcement learning (RL) is a booming area in artificial intelligence. The applications of RL are endless nowadays, ranging from fields such as medicine or finance to manufacturing or the gaming industry. Although multiple works argue that RL can be key to a great part of intelligent vehicle control related problems, there are many practical problems that need to be addressed, such as safety related problems that can result from non-optimal training in RL. For instance, for an RL agent to be effective it should first cover all the situations during training that it may face later. This is often difficult when applied to the real-world. In this work we investigate the impact of RL applied to the context of intelligent vehicle control. We analyse the implications of RL in path planning tasks and we discuss two possible approaches to overcome the gap between the theorical developments of RL and its practical applications. Specifically, firstly this paper discusses the role of Curriculum Learning (CL) to structure the learning process of intelligent vehicle control in a gradual way. The results show how CL can play an important role in training agents in such context. Secondly, we discuss a method of transferring RL policies from simulation to reality in order to make the agent experience situations in simulation, so it knows how to react to them in reality. For that, we use Arduino Y&uacute;n controlled robots as our platforms. The results enhance the effectiveness of the presented approach and show how RL policies can be transferred from simulation to reality even when the platforms are resource limited.},
DOI = {10.3390/s21237829}
}



@Article{aerospace8120363,
AUTHOR = {Elmeseiry, Nourhan and Alshaer, Nancy and Ismail, Tawfik},
TITLE = {A Detailed Survey and Future Directions of Unmanned Aerial Vehicles (UAVs) with Potential Applications},
JOURNAL = {Aerospace},
VOLUME = {8},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {363},
URL = {https://www.mdpi.com/2226-4310/8/12/363},
ISSN = {2226-4310},
ABSTRACT = {Recently, unmanned aerial vehicles (UAVs), also known as drones, have gained widespread interest in civilian and military applications, which has led to the development of novel UAVs that can perform various operations. UAVs are aircraft that can fly without the need of a human pilot onboard, meaning they can fly either autonomously or be remotely piloted. They can be equipped with multiple sensors, including cameras, inertial measurement units (IMUs), LiDAR, and GPS, to collect and transmit data in real time. Due to the demand for UAVs in various applications such as precision agriculture, search and rescue, wireless communications, and surveillance, several types of UAVs have been invented with different specifications for their size, weight, range and endurance, engine type, and configuration. Because of this variety, the design process and analysis are based on the type of UAV, with the availability of several control techniques that could be used to improve the flight of the UAV in order to avoid obstacles and potential collisions, as well as find the shortest path to save the battery life with the support of optimization techniques. However, UAVs face several challenges in order to fly smoothly, including collision avoidance, battery life, and intruders. This review paper presents UAVs&rsquo; classification, control applications, and future directions in industry and research interest. For the design process, fabrication, and analysis, various control approaches are discussed in detail. Furthermore, the challenges for UAVs, including battery charging, collision avoidance, and security, are also presented and discussed.},
DOI = {10.3390/aerospace8120363}
}



@Article{buildings11120579,
AUTHOR = {Amândio, Margarida and Parente, Manuel and Neves, José and Fonseca, Paulo},
TITLE = {Integration of Smart Pavement Data with Decision Support Systems: A Systematic Review},
JOURNAL = {Buildings},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {579},
URL = {https://www.mdpi.com/2075-5309/11/12/579},
ISSN = {2075-5309},
ABSTRACT = {Nowadays, pavement management systems (PMS) are mainly based on monitoring processes that have been established for a long time, and strongly depend on acquired experience. However, with the emergence of smart technologies, such as internet of things and artificial intelligence, PMS could be improved by applying these new smart technologies to their decision support systems, not just by updating their data collection methodologies, but also their data analysis tools. The application of these smart technologies to the field of pavement monitoring and condition evaluation will undoubtedly contribute to more efficient, less costly, safer, and environmentally friendly methodologies. Thus, the main drive of the present work is to provide insight for the development of future decision support systems for smart pavement management by conducting a systematic literature review of the developed works that apply smart technologies to this field. The conclusions drawn from the analysis allowed for the identification of a series of future direction recommendations for researchers. In fact, future PMS should tend to be capable of collecting and analyzing data at different levels, both externally at the surface or inside the pavement, as well as to detect and predict all types of functional and structural flaws and defects.},
DOI = {10.3390/buildings11120579}
}



@Article{s21237831,
AUTHOR = {Lewicka, Oktawia and Specht, Mariusz and Stateczny, Andrzej and Specht, Cezary and Brčić, David and Jugović, Alen and Widźgowski, Szymon and Wiśniewska, Marta},
TITLE = {Analysis of GNSS, Hydroacoustic and Optoelectronic Data Integration Methods Used in Hydrography},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7831},
URL = {https://www.mdpi.com/1424-8220/21/23/7831},
PubMedID = {34883835},
ISSN = {1424-8220},
ABSTRACT = {The integration of geospatial data in hydrography, performed using different measurement systems, involves combining several study results to provide a comprehensive analysis. Each of the hydroacoustic and optoelectronic systems is characterised by a different spatial reference system and the method for technical implementation of the measurement. Therefore, the integration of hydrographic data requires that problems in selected fields of electronics, geodesy and physics (acoustics and optics) be solved. The aim of this review is to present selected fusion methods applying the data derived from Global Navigation Satellite System (GNSS), Real Time Kinematic (RTK) measurements, hydrographic surveys, a photogrammetric pass using unmanned vehicles and Terrestrial Laser Scanning (TLS) and compare their accuracy. An additional goal is the evalution of data integration methods according to the International Hydrographic Organization (IHO) S-44 standard. The publication is supplemented by implementation examples of the integration of geospatial data in the Geographic Information System (GIS). The methods described indicate the lack of a uniform methodology for data fusion due to differences in both the spatial reference systems and the techniques used. However, the integration of hydroacoustic and optoelectronic data allows for high accuracy geospatial data to be obtained. This is confirmed by the methods cited, in which the accuracy of integrated geospatial data was in the order of several centimetres.},
DOI = {10.3390/s21237831}
}



@Article{agriculture11121190,
AUTHOR = {Fang, Lifa and Wu, Yanqiang and Li, Yuhua and Guo, Hongen and Zhang, Hua and Wang, Xiaoyu and Xi, Rui and Hou, Jialin},
TITLE = {Using Channel and Network Layer Pruning Based on Deep Learning for Real-Time Detection of Ginger Images},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1190},
URL = {https://www.mdpi.com/2077-0472/11/12/1190},
ISSN = {2077-0472},
ABSTRACT = {Consistent ginger shoot orientation helps to ensure consistent ginger emergence and meet shading requirements. YOLO v3 is used to recognize ginger images in response to the current ginger seeder&rsquo;s difficulty in meeting the above agronomic problems. However, it is not suitable for direct application on edge computing devices due to its high computational cost. To make the network more compact and to address the problems of low detection accuracy and long inference time, this study proposes an improved YOLO v3 model, in which some redundant channels and network layers are pruned to achieve real-time determination of ginger shoots and seeds. The test results showed that the pruned model reduced its model size by 87.2% and improved the detection speed by 85%. Meanwhile, its mean average precision (mAP) reached 98.0% for ginger shoots and seeds, only 0.1% lower than the model before pruning. Moreover, after deploying the model to the Jetson Nano, the test results showed that its mAP was 97.94%, the recognition accuracy could reach 96.7%, and detection speed could reach 20 frames&middot;s&minus;1. The results showed that the proposed method was feasible for real-time and accurate detection of ginger images, providing a solid foundation for automatic and accurate ginger seeding.},
DOI = {10.3390/agriculture11121190}
}



@Article{math9233033,
AUTHOR = {Filatov, Anton and Zaslavskiy, Mark and Krinkin, Kirill},
TITLE = {Multi-Drone 3D Building Reconstruction Method},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {3033},
URL = {https://www.mdpi.com/2227-7390/9/23/3033},
ISSN = {2227-7390},
ABSTRACT = {In the recent decade, the rapid development of drone technologies has made many spatial problems easier to solve, including the problem of 3D reconstruction of large objects. A review of existing solutions has shown that most of the works lack the autonomy of drones because of nonscalable mapping techniques. This paper presents a method for centralized multi-drone 3D reconstruction, which allows performing a data capturing process autonomously and requires drones equipped only with an RGB camera. The essence of the method is a multiagent approach&mdash;the control center performs the workload distribution evenly and independently for all drones, allowing simultaneous flights without a high risk of collision. The center continuously receives RGB data from drones and performs each drone localization (using visual odometry estimations) and rough online mapping of the environment (using image descriptors for estimating the distance to the building). The method relies on a set of several user-defined parameters, which allows the tuning of the method for different task-specific requirements such as the number of drones, 3D model detalization, data capturing time, and energy consumption. By numerical experiments, it is shown that method parameters can be estimated by performing a set of computations requiring characteristics of drones and the building that are simple to obtain. Method performance was evaluated by an experiment with virtual building and emulated drone sensors. Experimental evaluation showed that the precision of the chosen algorithms for online localization and mapping is enough to perform simultaneous flights and the amount of captured RGB data is enough for further reconstruction.},
DOI = {10.3390/math9233033}
}



@Article{app112311229,
AUTHOR = {Park, Sung-Sik and Tran, Van-Than and Lee, Dong-Eun},
TITLE = {Application of Various YOLO Models for Computer Vision-Based Real-Time Pothole Detection},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {11229},
URL = {https://www.mdpi.com/2076-3417/11/23/11229},
ISSN = {2076-3417},
ABSTRACT = {Pothole repair is one of the paramount tasks in road maintenance. Effective road surface monitoring is an ongoing challenge to the management agency. The current pothole detection, which is conducted image processing with a manual operation, is labour-intensive and time-consuming. Computer vision offers a mean to automate its visual inspection process using digital imaging, hence, identifying potholes from a series of images. The goal of this study is to apply different YOLO models for pothole detection. Three state-of-the-art object detection frameworks (i.e., YOLOv4, YOLOv4-tiny, and YOLOv5s) are experimented to measure their performance involved in real-time responsiveness and detection accuracy using the image set. The image set is identified by running the deep convolutional neural network (CNN) on several deep learning pothole detectors. After collecting a set of 665 images in 720 &times; 720 pixels resolution that captures various types of potholes on different road surface conditions, the set is divided into training, testing, and validation subsets. A mean average precision at 50% Intersection-over-Union threshold (mAP_0.5) is used to measure the performance of models. The study result shows that the mAP_0.5 of YOLOv4, YOLOv4-tiny, and YOLOv5s are 77.7%, 78.7%, and 74.8%, respectively. It confirms that the YOLOv4-tiny is the best fit model for pothole detection.},
DOI = {10.3390/app112311229}
}



@Article{rs13234803,
AUTHOR = {Ojogbane, Sani Success and Mansor, Shattri and Kalantar, Bahareh and Khuzaimah, Zailani Bin and Shafri, Helmi Zulhaidi Mohd and Ueda, Naonori},
TITLE = {Automated Building Detection from Airborne LiDAR and Very High-Resolution Aerial Imagery with Deep Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4803},
URL = {https://www.mdpi.com/2072-4292/13/23/4803},
ISSN = {2072-4292},
ABSTRACT = {The detection of buildings in the city is essential in several geospatial domains and for decision-making regarding intelligence for city planning, tax collection, project management, revenue generation, and smart cities, among other areas. In the past, the classical approach used for building detection was by using the imagery and it entailed human&ndash;computer interaction, which was a daunting proposition. To tackle this task, a novel network based on an end-to-end deep learning framework is proposed to detect and classify buildings features. The proposed CNN has three parallel stream channels: the first is the high-resolution aerial imagery, while the second stream is the digital surface model (DSM). The third was fixed on extracting deep features using the fusion of channel one and channel two, respectively. Furthermore, the channel has eight group convolution blocks of 2D convolution with three max-pooling layers. The proposed model&rsquo;s efficiency and dependability were tested on three different categories of complex urban building structures in the study area. Then, morphological operations were applied to the extracted building footprints to increase the uniformity of the building boundaries and produce improved building perimeters. Thus, our approach bridges a significant gap in detecting building objects in diverse environments; the overall accuracy (OA) and kappa coefficient of the proposed method are greater than 80% and 0.605, respectively. The findings support the proposed framework and methodologies&rsquo; efficacy and effectiveness at extracting buildings from complex environments.},
DOI = {10.3390/rs13234803}
}



@Article{s21237889,
AUTHOR = {Sott, Michele Kremer and Nascimento, Leandro da Silva and Foguesatto, Cristian Rogério and Furstenau, Leonardo B. and Faccin, Kadígia and Zawislak, Paulo Antônio and Mellado, Bruce and Kong, Jude Dzevela and Bragazzi, Nicola Luigi},
TITLE = {A Bibliometric Network Analysis of Recent Publications on Digital Agriculture to Depict Strategic Themes and Evolution Structure},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7889},
URL = {https://www.mdpi.com/1424-8220/21/23/7889},
PubMedID = {34883903},
ISSN = {1424-8220},
ABSTRACT = {The agriculture sector is one of the backbones of many countries&rsquo; economies. Its processes have been changing to enable technology adoption to increase productivity, quality, and sustainable development. In this research, we present a scientific mapping of the adoption of precision techniques and breakthrough technologies in agriculture, so-called Digital Agriculture. To do this, we used 4694 documents from the Web of Science database to perform a Bibliometric Performance and Network Analysis of the literature using SciMAT software with the support of the PICOC protocol. Our findings presented 22 strategic themes related to Digital Agriculture, such as Internet of Things (IoT), Unmanned Aerial Vehicles (UAV) and Climate-smart Agriculture (CSA), among others. The thematic network structure of the nine most important clusters (motor themes) was presented and an in-depth discussion was performed. The thematic evolution map provides a broad perspective of how the field has evolved over time from 1994 to 2020. In addition, our results discuss the main challenges and opportunities for research and practice in the field of study. Our findings provide a comprehensive overview of the main themes related to Digital Agriculture. These results show the main subjects analyzed on this topic and provide a basis for insights for future research.},
DOI = {10.3390/s21237889}
}



@Article{logistics5040084,
AUTHOR = {Abideen, Ahmed Zainul and Sundram, Veera Pandiyan Kaliani and Pyeman, Jaafar and Othman, Abdul Kadir and Sorooshian, Shahryar},
TITLE = {Digital Twin Integrated Reinforced Learning in Supply Chain and Logistics},
JOURNAL = {Logistics},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {84},
URL = {https://www.mdpi.com/2305-6290/5/4/84},
ISSN = {2305-6290},
ABSTRACT = {Background: As the Internet of Things (IoT) has become more prevalent in recent years, digital twins have attracted a lot of attention. A digital twin is a virtual representation that replicates a physical object or process over a period of time. These tools directly assist in reducing the manufacturing and supply chain lead time to produce a lean, flexible, and smart production and supply chain setting. Recently, reinforced machine learning has been introduced in production and logistics systems to build prescriptive decision support platforms to create a combination of lean, smart, and agile production setup. Therefore, there is a need to cumulatively arrange and systematize the past research done in this area to get a better understanding of the current trend and future research directions from the perspective of Industry 4.0. Methods: Strict keyword selection, search strategy, and exclusion criteria were applied in the Scopus database (2010 to 2021) to systematize the literature. Results: The findings are snowballed as a systematic review and later the final data set has been conducted to understand the intensity and relevance of research work done in different subsections related to the context of the research agenda proposed. Conclusion: A framework for data-driven digital twin generation and reinforced learning has been proposed at the end of the paper along with a research paradigm.},
DOI = {10.3390/logistics5040084}
}



@Article{s21237888,
AUTHOR = {Lo, Li-Yu and Yiu, Chi Hao and Tang, Yu and Yang, An-Shik and Li, Boyang and Wen, Chih-Yung},
TITLE = {Dynamic Object Tracking on Autonomous UAV System for Surveillance Applications},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7888},
URL = {https://www.mdpi.com/1424-8220/21/23/7888},
PubMedID = {34883913},
ISSN = {1424-8220},
ABSTRACT = {The ever-burgeoning growth of autonomous unmanned aerial vehicles (UAVs) has demonstrated a promising platform for utilization in real-world applications. In particular, a UAV equipped with a vision system could be leveraged for surveillance applications. This paper proposes a learning-based UAV system for achieving autonomous surveillance, in which the UAV can be of assistance in autonomously detecting, tracking, and following a target object without human intervention. Specifically, we adopted the YOLOv4-Tiny algorithm for semantic object detection and then consolidated it with a 3D object pose estimation method and Kalman filter to enhance the perception performance. In addition, UAV path planning for a surveillance maneuver is integrated to complete the fully autonomous system. The perception module is assessed on a quadrotor UAV, while the whole system is validated through flight experiments. The experiment results verified the robustness, effectiveness, and reliability of the autonomous object tracking UAV system in performing surveillance tasks. The source code is released to the research community for future reference.},
DOI = {10.3390/s21237888}
}



@Article{electronics10232953,
AUTHOR = {Gopi, Sudheesh Puthenveettil and Magarini, Maurizio},
TITLE = {Reinforcement Learning Aided UAV Base Station Location Optimization for Rate Maximization},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {2953},
URL = {https://www.mdpi.com/2079-9292/10/23/2953},
ISSN = {2079-9292},
ABSTRACT = {The application of unmanned aerial vehicles (UAV) as base station (BS) is gaining popularity. In this paper, we consider maximization of the overall data rate by intelligent deployment of UAV BS in the downlink of a cellular system. We investigate a reinforcement learning (RL)-aided approach to optimize the position of flying BSs mounted on board UAVs to support a macro BS (MBS). We propose an algorithm to avoid collision between multiple UAVs undergoing exploratory movements and to restrict UAV BSs movement within a predefined area. Q-learning technique is used to optimize UAV BS position, where the reward is equal to sum of user equipment (UE) data rates. We consider a framework where the UAV BSs carry out exploratory movements in the beginning and exploitary movements in later stages to maximize the overall data rate. Our results show that a cellular system with three UAV BSs and one MBS serving 72 UE reaches 69.2% of the best possible data rate, which is identified by brute force search. Finally, the RL algorithm is compared with a K-means algorithm to study the need of accurate UE locations. Our results show that the RL algorithm outperforms the K-means clustering algorithm when the measure of imperfection is higher. The proposed algorithm can be made use of by a practical MBS&ndash;UAV BSs&ndash;UEs system to provide protection to UAV BSs while maximizing data rate.},
DOI = {10.3390/electronics10232953}
}



@Article{rs13234827,
AUTHOR = {Georgopoulos, Nikos and Gitas, Ioannis Z. and Stefanidou, Alexandra and Korhonen, Lauri and Stavrakoudis, Dimitris},
TITLE = {Estimation of Individual Tree Stem Biomass in an Uneven-Aged Structured Coniferous Forest Using Multispectral LiDAR Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4827},
URL = {https://www.mdpi.com/2072-4292/13/23/4827},
ISSN = {2072-4292},
ABSTRACT = {Stem biomass is a fundamental component of the global carbon cycle that is essential for forest productivity estimation. Over the last few decades, Light Detection and Ranging (LiDAR) has proven to be a useful tool for accurate carbon stock and biomass estimation in various biomes. The aim of this study was to investigate the potential of multispectral LiDAR data for the reliable estimation of single-tree total and barkless stem biomass (TSB and BSB) in an uneven-aged structured forest with complex topography. Destructive and non-destructive field measurements were collected for a total of 67 dominant and co-dominant Abies borisii-regis trees located in a mountainous area in Greece. Subsequently, two allometric equations were constructed to enrich the reference data with non-destructively sampled trees. Five different regression algorithms were tested for single-tree BSB and TSB estimation using height (height percentiles and bicentiles, max and average height) and intensity (skewness, standard deviation and average intensity) LiDAR-derived metrics: Generalized Linear Models (GLMs), Gaussian Process (GP), Random Forest (RF), Support Vector Regression (SVR) and Extreme Gradient Boosting (XGBoost). The results showcased that the RF algorithm provided the best overall predictive performance in both BSB (i.e., RMSE = 175.76 kg and R2 = 0.78) and TSB (i.e., RMSE = 211.16 kg and R2 = 0.65) cases. Our work demonstrates that BSB can be estimated with moderate to high accuracy using all the tested algorithms, contrary to the TSB, where only three algorithms (RF, SVR and GP) can adequately provide accurate TSB predictions due to bark irregularities along the stems. Overall, the multispectral LiDAR data provide accurate stem biomass estimates, the general applicability of which should be further tested in different biomes and ecosystems.},
DOI = {10.3390/rs13234827}
}



@Article{rs13234832,
AUTHOR = {Schratz, Patrick and Muenchow, Jannes and Iturritxa, Eugenia and Cortés, José and Bischl, Bernd and Brenning, Alexander},
TITLE = {Monitoring Forest Health Using Hyperspectral Imagery: Does Feature Selection Improve the Performance of Machine-Learning Techniques?},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4832},
URL = {https://www.mdpi.com/2072-4292/13/23/4832},
ISSN = {2072-4292},
ABSTRACT = {This study analyzed highly correlated, feature-rich datasets from hyperspectral remote sensing data using multiple statistical and machine-learning methods. The effect of filter-based feature selection methods on predictive performance was compared. In addition, the effect of multiple expert-based and data-driven feature sets, derived from the reflectance data, was investigated. Defoliation of trees (%), derived from in situ measurements from fall 2016, was modeled as a function of reflectance. Variable importance was assessed using permutation-based feature importance. Overall, the support vector machine (SVM) outperformed other algorithms, such as random forest (RF), extreme gradient boosting (XGBoost), and lasso (L1) and ridge (L2) regressions by at least three percentage points. The combination of certain feature sets showed small increases in predictive performance, while no substantial differences between individual feature sets were observed. For some combinations of learners and feature sets, filter methods achieved better predictive performances than using no feature selection. Ensemble filters did not have a substantial impact on performance. The most important features were located around the red edge. Additional features in the near-infrared region (800&ndash;1000 nm) were also essential to achieve the overall best performances. Filter methods have the potential to be helpful in high-dimensional situations and are able to improve the interpretation of feature effects in fitted models, which is an essential constraint in environmental modeling studies. Nevertheless, more training data and replication in similar benchmarking studies are needed to be able to generalize the results.},
DOI = {10.3390/rs13234832}
}



@Article{rs13234839,
AUTHOR = {Zheng, Lianming and Lin, Rui and Wang, Xuemei and Chen, Weihua},
TITLE = {The Development and Application of Machine Learning in Atmospheric Environment Studies},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4839},
URL = {https://www.mdpi.com/2072-4292/13/23/4839},
ISSN = {2072-4292},
ABSTRACT = {Machine learning (ML) plays an important role in atmospheric environment prediction, having been widely applied in atmospheric science with significant progress in algorithms and hardware. In this paper, we present a brief overview of the development of ML models as well as their application to atmospheric environment studies. ML model performance is then compared based on the main air pollutants (i.e., PM2.5, O3, and NO2) and model type. Moreover, we identify the key driving variables for ML models in predicting particulate matter (PM) pollutants by quantitative statistics. Additionally, a case study for wet nitrogen deposition estimation is carried out based on ML models. Finally, the prospects of ML for atmospheric prediction are discussed.},
DOI = {10.3390/rs13234839}
}



@Article{rs13234844,
AUTHOR = {Shin, Jisun and Lee, Jong-Seok and Jang, Lee-Hyun and Lim, Jinwook and Khim, Boo-Keun and Jo, Young-Heon},
TITLE = {Sargassum Detection Using Machine Learning Models: A Case Study with the First 6 Months of GOCI-II Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4844},
URL = {https://www.mdpi.com/2072-4292/13/23/4844},
ISSN = {2072-4292},
ABSTRACT = {A record-breaking agglomeration of Sargassum was packed along the northern Jeju coast in Korea in 2021, and laborers suffered from removing them from the beach. If remote sensing can be used to detect the locations at which Sargassum accumulated in a timely and accurate manner, we could remove them before their arrival and reduce the damage caused by Sargassum. This study aims to detect Sargassum distribution on the coast of Jeju Island using the Geostationary KOMPSAT 2B (GK2B) Geostationary Ocean Color Imager-II (GOCI-II) imagery that was launched in February 2020, with measurements available since October 2020. For this, we used GOCI-II imagery during the first 6 months and machine learning models including Fine Tree, a Fine Gaussian support vector machine (SVM), and Gentle adaptive boosting (GentleBoost). We trained the models with the GOCI-II Rayleigh-corrected reflectance (RhoC) image and a ground truth map extracted from high-resolution images as input and output, respectively. Qualitative and quantitative assessments were carried out using the three machine learning models and traditional methods such as Sargassum indexes. We found that GentleBoost showed a lower false positive (6.2%) and a high F-measure level (0.82), and a more appropriate Sargassum distribution compared to other methods. The application of the machine learning model to GOCI-II images in various atmospheric conditions is therefore considered successful for mapping Sargassum extent quickly, enabling reduction of laborers&rsquo; efforts to remove them.},
DOI = {10.3390/rs13234844}
}



@Article{electronics10232977,
AUTHOR = {Li, Yan and Zhao, Mengyu and Zhang, Huazhi and Yang, Fuling and Wang, Suyu},
TITLE = {An Interactive Self-Learning Game and Evolutionary Approach Based on Non-Cooperative Equilibrium},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {2977},
URL = {https://www.mdpi.com/2079-9292/10/23/2977},
ISSN = {2079-9292},
ABSTRACT = {Most current studies on multi-agent evolution based on deep learning take a cooperative equilibrium strategy, while interactive self-learning is not always considered. An interactive self-learning game and evolution method based on non-cooperative equilibrium (ISGE-NCE) is proposed to take the benefits of both game theory and interactive learning for multi-agent confrontation evolution. A generative adversarial network (GAN) is designed combining with multi-agent interactive self-learning, and the non-cooperative equilibrium strategy is well adopted within the framework of interactive self-learning, aiming for high evolution efficiency and interest. For assessment, three typical multi-agent confrontation experiments are designed and conducted. The results show that, first, in terms of training speed, the ISGE-NCE produces a training convergence rate of at least 46.3% higher than that of the method without considering interactive self-learning. Second, the evolution rate of the interference and detection agents reaches 60% and 80%, respectively, after training by using our method. In the three different experiment scenarios, compared with the DDPG, our ISGE-NCE method improves the multi-agent evolution effectiveness by 43.4%, 50%, and 20%, respectively, with low training costs. The performances demonstrate the significant superiority of our ISGE-NCE method in swarm intelligence.},
DOI = {10.3390/electronics10232977}
}



@Article{land10121316,
AUTHOR = {Saad, Felipe and Biswas, Sumalika and Huang, Qiongyu and Corte, Ana Paula Dalla and Coraiola, Márcio and Macey, Sarah and Carlucci, Marcos Bergmann and Leimgruber, Peter},
TITLE = {Detectability of the Critically Endangered Araucaria angustifolia Tree Using Worldview-2 Images, Google Earth Engine and UAV-LiDAR},
JOURNAL = {Land},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1316},
URL = {https://www.mdpi.com/2073-445X/10/12/1316},
ISSN = {2073-445X},
ABSTRACT = {The Brazilian Atlantic Forest is a global biodiversity hotspot and has been extensively mapped using satellite remote sensing. However, past mapping focused on overall forest cover without consideration of keystone plant resources such as Araucaria angustifolia.&nbsp;A. angustifolia is a critically endangered coniferous tree that is essential for supporting overall biodiversity in the Atlantic Forest. A. angustifolia&rsquo;s distribution has declined dramatically because of overexploitation and land-use changes. Accurate detection and rapid assessments of the distribution and abundance of this species are urgently needed. We compared two approaches for mapping Araucaria angustifolia across two scales (stand vs. individual tree) at three study sites in Brazil. The first approach used Worldview-2 images and Random Forest in Google Earth Engine to detect A. angustifolia at the stand level, with an accuracy of &gt;90% across all three study sites. The second approach relied on object identification using UAV-LiDAR and successfully mapped individual trees (producer&rsquo;s/user&rsquo;s accuracy = 94%/64%) at one study site. Both approaches can be employed in tandem to map remaining stands and to determine the exact location of A. angustifolia trees. Each approach has its own strengths and weaknesses, and we discuss their adoptability by managers to inform conservation of A. angustifolia.},
DOI = {10.3390/land10121316}
}



@Article{app112311335,
AUTHOR = {Grzelczak, Maciej and Duch, Piotr},
TITLE = {Deep Reinforcement Learning Algorithms for Path Planning Domain in Grid-like Environment},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {11335},
URL = {https://www.mdpi.com/2076-3417/11/23/11335},
ISSN = {2076-3417},
ABSTRACT = {Recently, more and more solutions have utilised artificial intelligence approaches in order to enhance or optimise processes to achieve greater sustainability. One of the most pressing issues is the emissions caused by cars; in this paper, the problem of optimising the route of delivery cars is tackled. In this paper, the applicability of the deep reinforcement learning algorithms with regards to the aforementioned problem is tested on a simulation game designed and implemented to pose various challenges such as constant change of delivery locations. The algorithms chosen for this task are Advantage Actor-Critic (A2C) with and without Proximal Policy Optimisation (PPO). These novel and advanced reinforcement learning algorithms have yet not been utilised in similar scenarios. The differences in performance and learning process of those are visualised and discussed. It is demonstrated that both of those algorithms present a slow but steady learning curve, which is an expected effect of reinforcement learning algorithms, leading to a conclusion that the algorithms would discover an optimal policy with an adequately long learning process. Additionally, the benefits of the Proximal Policy Optimisation algorithm are proven by the enhanced learning curve with comparison to the Advantage Actor-Critic approach, as the learning process is characterised by faster growth with a significantly smaller variation. Finally, the applicability of such algorithms in the described scenarios is discussed, alongside the possible improvements and future work.},
DOI = {10.3390/app112311335}
}



@Article{fi13120306,
AUTHOR = {Dirir, Ahmed and Ignatious, Henry and Elsayed, Hesham and Khan, Manzoor and Adib, Mohammed and Mahmoud, Anas and Al-Gunaid, Moatasem},
TITLE = {An Advanced Deep Learning Approach for Multi-Object Counting in Urban Vehicular Environments},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {306},
URL = {https://www.mdpi.com/1999-5903/13/12/306},
ISSN = {1999-5903},
ABSTRACT = {Object counting is an active research area that gained more attention in the past few years. In smart cities, vehicle counting plays a crucial role in urban planning and management of the Intelligent Transportation Systems (ITS). Several approaches have been proposed in the literature to address this problem. However, the resulting detection accuracy is still not adequate. This paper proposes an efficient approach that uses deep learning concepts and correlation filters for multi-object counting and tracking. The performance of the proposed system is evaluated using a dataset consisting of 16 videos with different features to examine the impact of object density, image quality, angle of view, and speed of motion towards system accuracy. Performance evaluation exhibits promising results in normal traffic scenarios and adverse weather conditions. Moreover, the proposed approach outperforms the performance of two recent approaches from the literature.},
DOI = {10.3390/fi13120306}
}




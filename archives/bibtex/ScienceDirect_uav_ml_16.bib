@article{VILBIG2020102509,
title = {Archaeological surveying with airborne LiDAR and UAV photogrammetry: A comparative analysis at Cahokia Mounds},
journal = {Journal of Archaeological Science: Reports},
volume = {33},
pages = {102509},
year = {2020},
issn = {2352-409X},
doi = {https://doi.org/10.1016/j.jasrep.2020.102509},
url = {https://www.sciencedirect.com/science/article/pii/S2352409X2030300X},
author = {Justin M. Vilbig and Vasit Sagan and Christopher Bodine},
keywords = {Cahokia Mounds, Remote sensing, Drones, LiDAR, Photogrammetry, Landscape archaeology, Local binary pattern analysis, Pattern recognition},
abstract = {Remote sensing technologies are becoming indispensable for archaeological fieldwork, helping archaeologists be more efficient and focused in their excavations. Assessing technological feasibility and capability is therefore an essential skill for archaeologists. This research compares digital elevation models from publicly available airplane Light Detection and Ranging (LiDAR) data and unpiloted aerial vehicle (UAV or drone) images to analyze the quality, costs, and benefits of both. Data were collected at the Grand Plaza, which served as the ceremonial center for the civilization at Cahokia Mounds, Illinois, USA, a UNESCO World Heritage Site. GPS elevation data and the Local Binary Pattern (LBP) texture operator were applied to evaluate topographical fidelity in the DEM imagery. We find that photogrammetry is a suitable replacement for LiDAR in specific areas, namely areas with low-lying vegetation. Thus, archaeologists have multiple surveying options and must carefully weigh the technologies available to them based on time and resource constraints.}
}
@article{QIAO2021106143,
title = {Intelligent perception for cattle monitoring: A review for cattle identification, body condition score evaluation, and weight estimation},
journal = {Computers and Electronics in Agriculture},
volume = {185},
pages = {106143},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106143},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921001617},
author = {Yongliang Qiao and He Kong and Cameron Clark and Sabrina Lomax and Daobilige Su and Stuart Eiffert and Salah Sukkarieh},
keywords = {Precision livestock farming, Intelligent perception, Deep learning, Computer vision, Cattle welfare},
abstract = {There has been an increasing demand for animal protein due to several factors such as global population growth, rising incomes, etc. However, farming productivity is stagnating due to a mix of traditional practice, climate change, socio-economic, and environmental phenomena. Precision livestock farming, with intelligent perception tools at its core, and vast amounts of data being acquired from different sensors or platforms, has the ability to analyse individual animal for improved management, and the potential to dramatically enhance farm productivity. In order to facilitate research and promote the development of related areas, this review summarises and analyses the main existing techniques used in precision cattle farming, focusing on those related to identification, body condition score evaluation, and live weight estimation. More than 100 relevant papers have been discussed in a cohesive manner. From this review and extensive discussions of recent trends, we anticipate that intelligent perception for precision cattle farming will develop through non-contact, high precision, automated technologies, combined with emerging 3D model reconstruction and deep learning technologies. Existing challenges and future research opportunities will also be highlighted and discussed.}
}
@article{KONG2020105442,
title = {Automatic identification and characterization of discontinuities in rock masses from 3D point clouds},
journal = {Engineering Geology},
volume = {265},
pages = {105442},
year = {2020},
issn = {0013-7952},
doi = {https://doi.org/10.1016/j.enggeo.2019.105442},
url = {https://www.sciencedirect.com/science/article/pii/S0013795219305848},
author = {Deheng Kong and Faquan Wu and Charalampos Saroglou},
keywords = {3D point cloud, Rock mass, Automatic, Discontinuity, LiDAR, UAV},
abstract = {The routine application of remote surveying techniques which can quickly acquire 3D digital data with high resolution, in particular digital photogrammetry, light detection and ranging (LiDAR) and unmanned aerial vehicle (UAV) for rock mass characterization has rapidly grown over the past decade. In this paper, a new method for automatic identification and interpretation of rock mass discontinuities, clustering of discontinuity sets and characterization of discontinuity orientation, persistence and spacing using 3D point clouds, is presented. The proposed method is based on a four-stage procedure consisting of: (1) normal vector calculation using the iterative reweighted plane fitting (IRPF) method, (2) discontinuity sets clustering by fast search and find of density peaks (CFSFDP) algorithm, and Fisher’s K value iterative calculation to eliminate noise points, (3) discontinuity segmentation using density-ratio based method, and discontinuity plane fitting using the random sample consensus (RANSAC) algorithm, (4) persistence and spacing calculation using the theory of analytic geometry. The method is applied to two case studies (i.e. rock slopes) and compared with the results from previous studies and from manual survey. It is concluded that the proposed method is reliable and yields a great accuracy for automatic identification of discontinuities in rock masses.}
}
@article{YANG202012,
title = {Adaptive robust servo constraint tracking control for an underactuated quadrotor UAV with mismatched uncertainties},
journal = {ISA Transactions},
volume = {106},
pages = {12-30},
year = {2020},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2020.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0019057820302809},
author = {Siyang Yang and Jiang Han and Lian Xia and Ye-Hwa Chen},
keywords = {Adaptive robust control, Mismatched uncertainties, Udwadia–Kalaba theory, Quadrotor UAV},
abstract = {In this research, to achieve the altitude and attitude tracking control of an underactuated quadrotor UAV with mismatched uncertainties, based upon Udwadia–Kalaba theory, a novel adaptive robust tracking control approach is proposed and which will be designed in two steps. First, aiming at the uncertain and underactuated quadrotor UAV, regardless of initial constraint deviation and mismatched uncertainties, a nominal control is constructed through transforming the desired trajectories into corresponding servo constraints; second, for the mismatched uncertainties, we decompose them into two parts, i.e. the matched part and mismatched part, and the mismatched part will “vanish” during the stability analysis of proposed adaptive robust controller. Eventually, with such a decomposition technique, the large mismatched uncertainties can be addressed properly and the burden of controller design will be reduced to a certain degree. In addition, two deterministic robust control performances are also guaranteed by our proposed approach. The simulation results have shown a good robustness and tracking precision of our proposed scheme for quadrotor UAV.}
}
@article{CAVALIERE2019163,
title = {A human-like description of scene events for a proper UAV-based video content analysis},
journal = {Knowledge-Based Systems},
volume = {178},
pages = {163-175},
year = {2019},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2019.04.026},
url = {https://www.sciencedirect.com/science/article/pii/S0950705119301996},
author = {Danilo Cavaliere and Vincenzo Loia and Alessia Saggese and Sabrina Senatore and Mario Vento},
keywords = {Activity detection, Semantic Web technologies, Activity composition, Object classification, Video tracking, OWL},
abstract = {In Video Surveillance age, the monitoring activity, especially from unmanned vehicles, needs some degree of autonomy in the scenario interpretation. Video Analysis tasks are crucial for the target tracking and recognition; anyway, it would be desirable if a further level of understanding could provide a comprehensive, high-level scene description, by reflecting that human cognitive capability of providing a concise scene description that comes from the analysis of involved objects relationships and actions. This paper presents a smart system to identify mobile scene objects, such as people, vehicles, automatically, by analyzing the videos acquired by drones in flight, along with the activities they carried out, so as to depict what it happens in the scene from a high-level perspective. The system uses Artificial Vision methods to detect and track the mobile objects and the area where they move, and Semantic Web technologies to provide a high-level description of the scenario. Spatio/temporal relations among the tracked objects as well as simple object activities (events) are described. By semantic reasoning, the system is able to connect the simple activities into more complex activities, that better reflect a human-like description of a scenario portion. Tests conducted on several videos, showing scenarios set in different environments, return convincing results which affirm the effectiveness of the proposed approach.}
}
@article{XU2019185,
title = {Inversion of rice canopy chlorophyll content and leaf area index based on coupling of radiative transfer and Bayesian network models},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {150},
pages = {185-196},
year = {2019},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0924271619300450},
author = {X.Q. Xu and J.S. Lu and N. Zhang and T.C. Yang and J.Y. He and X. Yao and T. Cheng and Y. Zhu and W.X. Cao and Y.C. Tian},
keywords = {UAV-multispectral image, Rice, Radiative transfer model, Bayesian network, Leaf area index, Canopy chlorophyll content},
abstract = {The radiative transfer model (RTM) simulates forward spectral reflectance of vegetation and is used to estimate physical parameters using backwards inversion. However, differentiation of spectral reflectances may be hampered due to model parameter combinations, and the cost function within RTM that calculates statistical distance may lead to inconsistent inversions. Bayesian network (BN) is a probabilistic model that is used to solve problems of model ambiguity and incompleteness. Here, we constructed a model to estimate rice growth parameters using data collected by an unmanned aerial vehicle (UAV). We collected rice canopy spectral information using a MiniMCA-6 multispectral camera fitted to an UAV that was used to determine BN structure using parameters derived from the PROSAIL model. We calculated conditional probability distributions of different observed combinations of rice canopy chlorophyll content (CCC) and leaf area index (LAI) and a look up table of maximum conditional probabilities of rice growth parameters based on BN was developed. Results indicated that most accurate inversions of LAI and CCC as BN nodes were achieved at reflectances of 720 nm, 800 nm under the red normalized difference vegetation index and at reflectances of 550, 720, 800 nm under the modified simple ratio index, respectively. Compared with the cost function inversion method, the BN method mitigated the ill-posed problem of inversion and obtained higher inversion accuracy with model test R2, RRMSE, and RE values of 0.81, 0.31, and 0.38, and 0.83, 0.36, and 0.43 for LAI and CCC, respectively. We conclude that application of the BN method to the inversion process of crop RTM could improve inversion accuracy of estimation of crop parameters.}
}
@article{ZHOU2020105398,
title = {Detection of phenology using an improved shape model on time-series vegetation index in wheat},
journal = {Computers and Electronics in Agriculture},
volume = {173},
pages = {105398},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105398},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919324494},
author = {Meng Zhou and Xue Ma and Kangkang Wang and Tao Cheng and Yongchao Tian and Jing Wang and Yan Zhu and Yongqiang Hu and Qingsong Niu and Lijuan Gui and Chunyu Yue and Xia Yao},
keywords = {Accumulated growing degree days (AGDD), Shape model (SM), Time-series VI, Crop phenology, Winter wheat},
abstract = {Accurate information about the growth period can guide us to fertilize, irrigate and harvest. Much progress has been achieved in detecting the phenology with the unique features of the time-series vegetation index (VI). However, these features only reflect information about specific stages (e.g., tillering, heading, and maturity stages), ignoring the information from other important stages (e.g., jointing, booting, and filling stages). In this study, a new approach for the phenology detection of winter wheat at the whole phenological stages is described, whereby the integrated accumulated growing degree days (AGDD) combined with the shape model (SM) method (SM-AGDD) is used to detect important phenology stages of winter wheat using five classic time-series VIs derived from three sensors at the field scale. Two proximal sensors (ASD FieldSpec Pro spectrometer and a Greenseeker RT 100) and a digital camera mounted on an unmanned aerial vehicle (UAV-DC) are used to acquire the above time-series VI. The results show that the newly developed SM-AGDD with the normalized difference vegetation index (NDVI) from ASD is the best predictor of crop phenology with an average RMSE ranging from 1.0 day at maturity to 10.3 days at tillering, followed by CI, EVI, and VARI, respectively. Among the three different spectral sensors, ASD has the best performance for detecting the whole targeted stages, while UAV-DC was the worst. In particular, the accuracy of EVI has the highest improvement on all growth stages. Compared with the previous SM constructed with the days after sowing (DAS) produced by Sakamoto et al. (2010), the newly developed SM-AGDD improves the accuracy of detecting the critical stages for winter wheat phenology for all VIs. We also find that SM-AGDD has a higher accuracy to the SM constructed with accumulated photothermal time (APTT) by Zeng et al. (2016). While, it also greatly simplified the calculation. This study shows that the accuracy of the shape model method is affected by the form and characteristics of the constructed shape, which could provide the theoretical basis for accurate detection of critical phenology dates for crops.}
}
@article{KIRSCHSTEIN2021100322,
title = {Energy demand of parcel delivery services with a mixed fleet of electric vehicles},
journal = {Cleaner Engineering and Technology},
volume = {5},
pages = {100322},
year = {2021},
issn = {2666-7908},
doi = {https://doi.org/10.1016/j.clet.2021.100322},
url = {https://www.sciencedirect.com/science/article/pii/S2666790821002822},
author = {Thomas Kirschstein},
keywords = {Unmanned aerial vehicles, Parcel delivery, Electric trucks, Energy consumption},
abstract = {Drone logistics is considered as a disruptive business model reshaping logistics in the next decades. Most prominent potential advantages of drone delivery are cost savings, high speed, and high flexibility. Additionally, drones are also considered as a means of green transportation as they are electric vehicles which are potentially emission-free. To which extent these claimed potentials exist depends on the application scenario as well as the environmental and technological conditions. In this study a stationary drone delivery system is considered where parcels are delivered from a central depot to customers either by drone or electric truck. The minimal total energy consumption for serving all customers is determined when using only an electric truck or a mixed fleet of electric trucks and drones. In a simulation study the effects of structural characteristics (like numbers of customers and customer density) and environmental conditions (like wind speed and traffic conditions) on potential energy savings using drones are estimated. The results indicate that structural characteristics and environmental conditions heavily affect the energy saving potential of drones. In urban settings with high customer density, the energy saving potential is limited to at most 1% while in rural settings drones can help to save 5% of total energy. Under drone-favoring conditions like calm winds and heavy traffic, the energy saving potential can double.}
}
@article{FENG2021107176,
title = {A taxonomical review on recent artificial intelligence applications to PV integration into power grids},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {132},
pages = {107176},
year = {2021},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2021.107176},
url = {https://www.sciencedirect.com/science/article/pii/S0142061521004154},
author = {Cong Feng and Yuanzhi Liu and Jie Zhang},
keywords = {Solar forecasting, Solar array and fault detection, Optimization, Solar optimal control, Text mining review},
abstract = {The exponential growth of solar power has been witnessed in the past decade and is projected by the ambitious policy targets. Nevertheless, the proliferation of solar energy poses challenges to power system operations, mostly due to its uncertainty, locational specificity, and variability. The prevalence of smart grids enables artificial intelligence (AI) techniques to mitigate solar integration problems with massive amounts of solar energy data. Different AI subfields (e.g., machine learning, deep learning, ensemble learning, and metaheuristic learning) have brought breakthroughs in solar energy, especially in its grid integration. However, AI research in solar integration is still at the preliminary stage, and is lagging behind the AI mainstream. Aiming to inspire deep AI involvement in the solar energy domain, this paper presents a taxonomical overview of AI applications in solar photovoltaic (PV) systems. Text mining techniques are first used as an assistive tool to collect, analyze, and categorize a large volume of literature in this field. Then, based on the constructed literature infrastructure, recent advancements in AI applications to solar forecasting, PV array detection, PV system fault detection, design optimization, and maximum power point tracking control problems are comprehensively reviewed. Current challenges and future trends of AI applications in solar integration are also discussed for each application theme.}
}
@article{ZHENG2020154,
title = {Cross-regional oil palm tree counting and detection via a multi-level attention domain adaptation network},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {167},
pages = {154-177},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620301830},
author = {Juepeng Zheng and Haohuan Fu and Weijia Li and Wenzhao Wu and Yi Zhao and Runmin Dong and Le Yu},
keywords = {Oil palm tree detection, Attention mechanism, Domain adaptation, Deep learning, Adversarial neural networks},
abstract = {Providing an accurate evaluation of palm tree plantation in a large region can bring meaningful impacts in both economic and ecological aspects. However, the enormous spatial scale and the variety of geological features across regions has made it a grand challenge with limited solutions based on manual human monitoring efforts. Although deep learning based algorithms have demonstrated potential in forming an automated approach in recent years, the labelling efforts needed for covering different features in different regions largely constrain its effectiveness in large-scale problems. In this paper, we propose a novel domain adaptive oil palm tree detection method, i.e., a Multi-level Attention Domain Adaptation Network (MADAN) to reap cross-regional oil palm tree counting and detection. MADAN consists of 4 procedures: First, we adopted a batch-instance normalization network (BIN) based feature extractor for improving the generalization ability of the model, integrating batch normalization and instance normalization. Second, we embedded a multi-level attention mechanism (MLA) into our architecture for enhancing the transferability, including a feature level attention and an entropy level attention. Then we designed a minimum entropy regularization (MER) to increase the confidence of the classifier predictions through assigning the entropy level attention value to the entropy penalty. Finally, we employed a sliding window-based prediction and an IOU based post-processing approach to attain the final detection results. We conducted comprehensive ablation experiments using three different satellite images of large-scale oil palm plantation area with six transfer tasks. MADAN improves the detection accuracy by 14.98% in terms of average F1-score compared with the Baseline method (without DA), and performs 3.55–14.49% better than existing domain adaptation methods. Experimental results demonstrate the great potential of our MADAN for large-scale and cross-regional oil palm tree counting and detection, guaranteeing a high detection accuracy as well as saving the manual annotation efforts.}
}
@article{ZOU2015286,
title = {A compound control method based on the adaptive neural network and sliding mode control for inertial stable platform},
journal = {Neurocomputing},
volume = {155},
pages = {286-294},
year = {2015},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2014.12.074},
url = {https://www.sciencedirect.com/science/article/pii/S092523121401738X},
author = {Ying Zou and Xusheng Lei},
keywords = {Inertial stable platform, Nonlinear dynamic model, Sliding mode control, Adaptive radial basis function neural network, Disturbances},
abstract = {To improve the control performance of the inertial stable platform (ISP), a compound control method based on the adaptive neural network and sliding mode control method is proposed to deal with the system model uncertainties and the disturbances. A sliding mode control is designed for the ISP system to achieve the initial stability. Moreover, an adaptive neural network is proposed to approximate the system uncertainties and unknown disturbances to argument the control performance. Based on the current state error information, the weight matrix of adaptive neural network can be updated on line. Therefore, the adaptive neural network can be constructed directly without priori training. The applicability of the proposed method is validated by a series of simulations and flight tests. The control method can improve the attitude stabilization accuracy of payloads effectively during the flight process.}
}
@article{TIAN20201,
title = {Computer vision technology in agricultural automation —A review},
journal = {Information Processing in Agriculture},
volume = {7},
number = {1},
pages = {1-19},
year = {2020},
issn = {2214-3173},
doi = {https://doi.org/10.1016/j.inpa.2019.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S2214317319301751},
author = {Hongkun Tian and Tianhai Wang and Yadong Liu and Xi Qiao and Yanzhou Li},
keywords = {Computer vision, Image processing, Agricultural automation, Intelligent detection},
abstract = {Computer vision is a field that involves making a machine “see”. This technology uses a camera and computer instead of the human eye to identify, track and measure targets for further image processing. With the development of computer vision, such technology has been widely used in the field of agricultural automation and plays a key role in its development. This review systematically summarizes and analyzes the technologies and challenges over the past three years and explores future opportunities and prospects to form the latest reference for researchers. Through the analyses, it is found that the existing technology can help the development of agricultural automation for small field farming to achieve the advantages of low cost, high efficiency and high precision. However, there are still major challenges. First, the technology will continue to expand into new application areas in the future, and there will be more technological issues that need to be overcome. It is essential to build large-scale data sets. Second, with the rapid development of agricultural automation, the demand for professionals will continue to grow. Finally, the robust performance of related technologies in various complex environments will also face challenges. Through analysis and discussion, we believe that in the future, computer vision technology will be combined with intelligent technology such as deep learning technology, be applied to every aspect of agricultural production management based on large-scale datasets, be more widely used to solve the current agricultural problems, and better improve the economic, general and robust performance of agricultural automation systems, thus promoting the development of agricultural automation equipment and systems in a more intelligent direction.}
}
@article{VASUKI201422,
title = {Semi-automatic mapping of geological Structures using UAV-based photogrammetric data: An image analysis approach},
journal = {Computers & Geosciences},
volume = {69},
pages = {22-32},
year = {2014},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2014.04.012},
url = {https://www.sciencedirect.com/science/article/pii/S0098300414000892},
author = {Yathunanthan Vasuki and Eun-Jung Holden and Peter Kovesi and Steven Micklethwaite},
keywords = {Semi-automated fault mapping, Photogrammetric data analysis, Automated image feature detection, Contrast invariant feature detection},
abstract = {Recent advances in data acquisition technologies, such as Unmanned Aerial Vehicles (UAVs), have led to a growing interest in capturing high-resolution rock surface images. However, due to the large volumes of data that can be captured in a short flight, efficient analysis of this data brings new challenges, especially the time it takes to digitise maps and extract orientation data. We outline a semi-automated method that allows efficient mapping of geological faults using photogrammetric data of rock surfaces, which was generated from aerial photographs collected by a UAV. Our method harnesses advanced automated image analysis techniques and human data interaction to rapidly map structures and then calculate their dip and dip directions. Geological structures (faults, joints and fractures) are first detected from the primary photographic dataset and the equivalent three dimensional (3D) structures are then identified within a 3D surface model generated by structure from motion (SfM). From this information the location, dip and dip direction of the geological structures are calculated. A structure map generated by our semi-automated method obtained a recall rate of 79.8% when compared against a fault map produced using expert manual digitising and interpretation methods. The semi-automated structure map was produced in 10min whereas the manual method took approximately 7h. In addition, the dip and dip direction calculation, using our automated method, shows a mean±standard error of 1.9°±2.2° and 4.4°±2.6° respectively with field measurements. This shows the potential of using our semi-automated method for accurate and efficient mapping of geological structures, particularly from remote, inaccessible or hazardous sites.}
}
@article{GE2018162,
title = {Modeling alpine grassland cover based on MODIS data and support vector machine regression in the headwater region of the Huanghe River, China},
journal = {Remote Sensing of Environment},
volume = {218},
pages = {162-173},
year = {2018},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2018.09.019},
url = {https://www.sciencedirect.com/science/article/pii/S0034425718304309},
author = {Jing Ge and Baoping Meng and Tiangang Liang and Qisheng Feng and Jinlong Gao and Shuxia Yang and Xiaodong Huang and Hongjie Xie},
keywords = {Tibetan Plateau, Unmanned aerial vehicle, Pixel dichotomy model, Multivariate regression, Accuracy assessment, Trend analysis},
abstract = {Monitoring changes in grassland cover is essential in assessment of grassland health as well as the effects of anthropogenic interventions and global climate change on grassland ecosystems. Remote sensing is an effective approach for providing rapid and dynamic monitoring of vegetation cover over large grassland areas. In this study, four types of remote sensing retrieval models (i.e., pixel dichotomy models, univariate vegetation index (VI) regression models, multivariate regression models, and a support vector machine (SVM) model) are built to derive grassland cover based on moderate resolution imaging spectroradiometer (MODIS) data and the measured grassland cover data collected by unmanned aerial vehicle during the grassland peak growing season from 2014 to 2016. The optimal model is then used to map the spatial distribution of grassland cover and its dynamic change in the headwater region of the Huanghe River (Yellow River) (HRHR) of the northeastern Tibetan Plateau over the 16 years period (2001 to 2016). The results show that (1) the pixel dichotomy models based on MODIS VI data are inappropriate for estimating grassland cover in the HRHR when their endmembers (VIsoil and VIveg) are determined based only on the MODIS data; (2) the multivariate regression models present better performance than the univariate VI (normalized difference vegetation index (NDVI) or enhanced vegetation index (EVI)) models; (3) MODIS NDVI outperforms MODIS EVI for modeling grassland cover in the study area; (4) the SVM model based on nine factors is the optimal model (R2: 0. 75 and RMSE: 6.85%) for monitoring alpine grassland cover in the study area; and (5) majority of the grassland area (59.9%) of the HRHR showed increase in yearly maximum grassland cover from 2001 to 2016, while the average yearly maximum grassland cover for the 16 years exhibited a generally increasing trend from west to east and from north to south. This study provides a more suitable remote sensing inversion model to greatly improve the accuracy of modeling alpine grassland cover in the HRHR, and to better assess grassland health status and the impacts of warming climate to grasslands in regions of remote and harsh environments.}
}
@article{PINEDA2017828,
title = {Expedited generation of terrain digital classes in flat areas from UAV images for precision agriculture purposes},
journal = {Advances in Animal Biosciences},
volume = {8},
number = {2},
pages = {828-832},
year = {2017},
issn = {2040-4700},
doi = {https://doi.org/10.1017/S2040470017000322},
url = {https://www.sciencedirect.com/science/article/pii/S2040470017000322},
author = {M.C. Pineda and C. Perdomo and R. Caballero and A. Valera and J.A. Martínez-Casasnovas and J. Viloria}
}
@article{AZNAR201724,
title = {A swarm behaviour for jellyfish bloom detection},
journal = {Ocean Engineering},
volume = {134},
pages = {24-34},
year = {2017},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2017.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0029801817300665},
author = {Fidel Aznar and Mar Pujol and Ramón Rizo},
keywords = {Swarm behaviour, Jellyfish detection, Unmanned aerial vehicles},
abstract = {In this paper we will deal with the issue of swarm behaviour for jellyfish detection using UAVs (unmanned aerial vehicles). Swarm behaviour is inspired by the functioning of biological swarms. They are characterized by being fully distributed, scalable and fault-tolerant. Initially, we will study the behaviour of jellyfish and their impact and interaction with industry. Motivated by the need to improve current detection systems, we will propose a swarm behaviour that will be formalized with a microscopic model. We will discuss both the convergence and the scalability of the model. Finally, a macroscopic model will be provided to predict the probability that an individual is placed in a position at a given moment.}
}
@article{NEDJAH201639,
title = {A massively parallel pipelined reconfigurable design for M-PLN based neural networks for efficient image classification},
journal = {Neurocomputing},
volume = {183},
pages = {39-55},
year = {2016},
note = {Weightless Neural Systems},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.05.138},
url = {https://www.sciencedirect.com/science/article/pii/S092523121501989X},
author = {Nadia Nedjah and Felipe P. da Silva and Alan O. de Sá and Luiza M. Mourelle and Diana A. Bonilla},
keywords = {Neural networks, Hardware, Multi-valued probabilistic node, Weightless neural network},
abstract = {Weightless Neural Networks (WNNs) are a powerful mechanism for pattern recognition. Aiming at enhancing their learning capabilities, Multi-valued Probabilistic Logic Nodes (M-PLN) are used, instead of crisp neurons with a 0/1 based RAM-nodes. An M-PLN stores a mapping of, or possibly, the triggering probability, for each input pattern that needs to be recognized. The M-PLN model attempts to strengthen the discrepancies between distinct patterns used during the training process and those that have not yet been processed. In this paper, an efficient yet customizable hardware architecture for M-PLN based neural network is proposed. It implements the learning and operation processes of a pyramidal network structure, augmented by a probabilistic rewarding/punishing search algorithm. The training algorithm can adapt itself to the overall hit ratio so far achieved by the network. Using class-dedicated layers, the hardware is able to handle image classification in parallel and thus, very efficiently. Furthermore, the classification process is performed in a pipelined manner so its stages never stop working until all input images are classified. Nonetheless, during network training, only one of these layers is activated. Last but not least, the architecture is customizable as its structure can be tailored in accordance to the application characteristics in terms of class number, pattern tuple size and image resolution. In order to evaluate the time and cost requirements of the proposed design, its underlying architecture was specified in VHDL and functionally tested. The presented results are two-fold: first, based on many functional simulations, estimated time and cost requirements are analyzed; second, to further assess the performance of the proposed the design, the VHDL model was synthesized to produce a semi-custom implementation on FPGAs. We also give an assessment of the quality of the entailed classification process. The architecture exhibits performance and reconfiguration capabilities that are very promising and encouraging towards the fabrication of a prototype on ASIC.}
}
@article{WANG2012423,
title = {Identification of shaft orbit for hydraulic generator unit using chain code and probability neural network},
journal = {Applied Soft Computing},
volume = {12},
number = {1},
pages = {423-429},
year = {2012},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2011.08.028},
url = {https://www.sciencedirect.com/science/article/pii/S1568494611003115},
author = {Changqing Wang and Jianzhong Zhou and Pangao Kou and Zhimeng Luo and Yongchuan Zhang},
keywords = {Chain code, Probability neural network, Shaft orbit, Fault diagnosis},
abstract = {Shaft orbit identification plays an important role in the hydraulic generator unit fault diagnosis. In this paper, a novel shaft orbit identification method based on chain code and probability neural network (PNN) is proposed. For this approach, firstly, a modified chain code histogram and shape numbers are used to represent the feature of the shaft orbit contour. It has properties of less data, easy to calculate, and invariance to rotation, scaling and translation. Then, the feature vectors are input to PNN to identify various kinds of shaft orbit for hydraulic generator unit. In comparison with previous methods, the experimental results show the proposed method is effective and training the network is faster, and identifying the shaft orbit achieves satisfactory accuracy.}
}
@article{ALSHAWARGHI2019285,
title = {Predictive models and detection methods applicable in water detection framework for industrial electric arc furnaces},
journal = {Computers & Chemical Engineering},
volume = {128},
pages = {285-300},
year = {2019},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2019.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S0098135418313528},
author = {Hamzah Alshawarghi and Ali Elkamel and Behzad Moshiri and Farzad Hourfar},
keywords = {EAF water detection framework, Fingerprinting, Artificial Neural Network (ANN), Multiway Projection to Latent Structures (MPLS), Model fusion, Fault detection},
abstract = {This paper introduces the development of empirical predictive models and detection methods that are incorporated into a water detection framework for an industrial steelmaking electric arc furnace (EAF). The predictive models investigated in this work are designed based on different techniques such as statistical fingerprinting, artificial neural network (ANN), and multiway projection to latent structures (MPLS). Robustness issues related to each method are discussed and performance comparisons have been done for the presented techniques. Furthermore, model fusion theory has been applied to improve the prediction accuracy of the developed models’ defined output- the value of off-gas water vapor- which is known as one the most vital variables to guarantee a safe and reliable operation. Finally based on the proposed predictive models, a water leak detection methodology is introduced and implemented on an industrial AC EAF and a comprehensive discussion has been done to evaluate the performance of the developed algorithm. To this aim, two fault detection methods have been applied. Fault detection method #1 has been designed using statistical fingerprinting technique, while the other one has been developed based on machine learning-based models and also fusion of the models’ outputs.}
}
@article{CAPELLO2013226,
title = {A Randomized Approach for Robust Control of Uncertain UAVs},
journal = {IFAC Proceedings Volumes},
volume = {46},
number = {30},
pages = {226-231},
year = {2013},
note = {2nd IFAC Workshop on Research, Education and Development of Unmanned Aerial Systems},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20131120-3-FR-4045.00046},
url = {https://www.sciencedirect.com/science/article/pii/S1474667015402988},
author = {Elisa Capello and Roberto Tempo},
keywords = {UAVs, robust control, randomized control, simulation methods},
abstract = {The objective of this paper is the development of a randomized LQR algorithm for UAVs subject to uncertainty. A controller gain is synthesized using a Lyapunov approach dealing with a formation of two mini-UAV systems in the classical Leader/Wingman configuration. Our contribution is to demonstrate that the proposed sequential algorithm provides a randomized controller which stabilizes the uncertain system. This probabilistic technique is then validated with an extensive a posteriori analysis. We show that the UAV reaches the desired altitude without an additional PID channel, and therefore tuning of the controller gains is avoided.}
}
@article{YANG2016192,
title = {Neural network approximation-based nonsingular terminal sliding mode control for trajectory tracking of robotic airships},
journal = {Aerospace Science and Technology},
volume = {54},
pages = {192-197},
year = {2016},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2016.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S1270963816301511},
author = {Yueneng Yang and Ye Yan},
keywords = {Trajectory tracking, Terminal sliding mode, Neural network, Lump uncertainty, Approximation, Robotic airship},
abstract = {This paper proposes a neural network approximation-based nonsingular terminal sliding mode control (NN-NTSMC) approach to address the problem of trajectory tracking for robotic airships. First, dynamics model of an airship and control problem of trajectory tracking are formulated. Second, a nonsingular terminal sliding mode controller (NTSMC) combined with neural network (NN) approximation is designed to track the commanded trajectory. Finally, the effectiveness and robustness of the designed controller are illustrated through simulation results. Simulation results indicate that NN-NTSMC reduces chattering effectively and ensures faster convergence and better tacking precision against linear hyperplane-based sliding mode control (LSMC).}
}
@article{RISTIC20171183,
title = {Integration of modern remote sensing technologies for faster utility mapping and data extraction},
journal = {Construction and Building Materials},
volume = {154},
pages = {1183-1198},
year = {2017},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2017.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S0950061817313648},
author = {Aleksandar Ristić and Željko Bugarinović and Milan Vrtunski and Miro Govedarica and Dušan Petrovački},
keywords = {District heating network, GPR, Aerial thermography, Neural networks, Edge detection, Automated data extraction},
abstract = {The aim of the research presented in this paper is to analyze the benefits of integrating a mobile system capable of very fast, reliable and relatively inexpensive detection, identification and status examination of district heating network. Thermal imaging using unmanned aerial vehicle is used for pipeline route detection, inspection of validity of cadastral data and for locating possible leakages. Ground Penetrating Radar – GPR technology is used for control sampling of radargrams on specific locations of routes in order to achieve following: identification of the geometric characteristics of district heating pipelines and structure, prevention and registration of damage, as well as automated data extraction. The main part of the paper is dedicated to the algorithm for automated data extraction, based on artificial neural networks and pattern recognition. Radargrams of district heating pipeline were used as input data for the extraction algorithm, while the results are geometric characteristics such as pipe depth, distance between pipes and diameter.}
}
@article{HE2014783,
title = {State of charge estimation for Li-ion batteries using neural network modeling and unscented Kalman filter-based error cancellation},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {62},
pages = {783-791},
year = {2014},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2014.04.059},
url = {https://www.sciencedirect.com/science/article/pii/S0142061514002646},
author = {Wei He and Nicholas Williard and Chaochao Chen and Michael Pecht},
keywords = {Neural networks, Unscented Kalman filter, State of charge estimation, Lithium ion batteries, Electric vehicles, Battery management systems},
abstract = {Lithium-ion batteries have been widely used as the energy storage systems in personal portable electronics (e.g. cell phones, laptop computers), telecommunication systems, electric vehicles and in various aerospace applications. To prevent the sudden loss of power of battery-powered systems, there are various approaches to estimate and manage the battery's state of charge (SOC). In this paper, an artificial neural network–based battery model is developed to estimate the SOC, based on the measured current and voltage. An unscented Kalman filter is used to reduce the errors in the neural network-based SOC estimation. The method is validated using LiFePO4 battery data collected from the Federal Driving Schedule and dynamical stress testing.}
}
@article{DREES2021106415,
title = {Temporal prediction and evaluation of Brassica growth in the field using conditional generative adversarial networks},
journal = {Computers and Electronics in Agriculture},
volume = {190},
pages = {106415},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106415},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921004324},
author = {Lukas Drees and Laura Verena Junker-Frohn and Jana Kierdorf and Ribana Roscher},
keywords = {Generative adversarial networks, Agriculture, Cauliflower, Prediction, Plant growth},
abstract = {Farmers frequently assess plant growth and performance as basis for making decisions when to take action in the field, such as fertilization, weed control, or harvesting. The prediction of plant growth is a major challenge, as it is affected by numerous and highly variable environmental factors. This paper proposes a novel monitoring approach that comprises high-throughput imaging sensor measurements and their automatic analysis to predict future plant growth. Our approach’s core is a novel machine learning-based generative growth model based on conditional generative adversarial networks, which is able to predict the future appearance of individual plants. In experiments with RGB time series images of laboratory-grown Arabidopsis thaliana and field-grown cauliflower plants, we show that our approach produces realistic, reliable, and reasonable images of future growth stages. The automatic interpretation of the generated images through neural network-based instance segmentation allows the derivation of various phenotypic traits that describe plant growth.}
}
@article{ALIABADI2021111016,
title = {ARTINALI++: Multi-dimensional Specification Mining for Complex Cyber-Physical System Security},
journal = {Journal of Systems and Software},
volume = {180},
pages = {111016},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111016},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221001138},
author = {Maryam Raiyat Aliabadi and Mojtaba Vahidi Asl and Ramak Ghavamizadeh},
keywords = {Program analysis, Specification mining, Intrusion Detection Systems, Cyber-Physical Systems, Security, Safety},
abstract = {Cyber-Physical Systems (CPSes) have been investigated as a key area of research since they are the core of Internet of Things. CPSs integrate computing and communication with control and monitoring of entities in the physical world. Due to the tight coupling of cyber and physical domains, and to the possible catastrophic consequences of the malicious attacks on critical infrastructures, security is one of the key concerns. However, the exponential growth of IoT has led to deployment of CPSes without support for enforcing important security properties. Specification-based Intrusion Detection Systems (IDS) have been shown to be effective for securing these systems. Mining the specifications of CPSes by experts is a cumbersome and error-prone task. Therefore, it is essential to dynamically monitor the CPS to learn its common behaviors and formulate specifications for detecting malicious bugs and security attacks. Existing solutions for specification mining only combine data and events, but not time. However, time is a semantic property in CPS systems, and hence incorporating time in addition to data and events, is essential for obtaining high accuracy. This paper proposes ARTINALI++, which dynamically mines specifications in CPS systems with arbitrary size and complexity. ARTINALI++ captures the security properties by incorporating time as a substantial property of the system, and generate a multi-dimensional model for the general CPS systems. Moreover, it enhances the model through discovering invariants that represent the physical motions and distinct operational modes in complex CPS systems. We build Intrusion Detection Systems based on ARTINALI++ for three CPSes with various levels of complexity including smart meter, smart artificial pancreas and unmanned aerial vehicle, and measure their detection accuracy. We find that the ARTINALI++ significantly reduces the ratio of false positives and false negatives by 23.45% and 73.6% on average, respectively, over other dynamic specification mining tools on the three CPS platforms.}
}
@article{WHITELEY2021106189,
title = {Rapid characterisation of landslide heterogeneity using unsupervised classification of electrical resistivity and seismic refraction surveys},
journal = {Engineering Geology},
volume = {290},
pages = {106189},
year = {2021},
issn = {0013-7952},
doi = {https://doi.org/10.1016/j.enggeo.2021.106189},
url = {https://www.sciencedirect.com/science/article/pii/S0013795221002003},
author = {J.S. Whiteley and A. Watlet and S. Uhlemann and P. Wilkinson and J.P. Boyd and C. Jordan and J.M. Kendall and J.E. Chambers},
keywords = {Landslide, Geophysics, Resistivity, Seismic, Machine learning, UAV},
abstract = {The characterisation of the subsurface of a landslide is a critical step in developing ground models that inform planned mitigation measures, remediation works or future early-warning of instability. When a landslide failure may be imminent, the time pressures on producing such models may be great. Geoelectrical and seismic geophysical surveys are able to rapidly acquire volumetric data across large areas of the subsurface at the slope-scale. However, analysis of the individual model derived from each survey is typically undertaken in isolation, and a robust, accurate interpretation is highly dependent on the experience and skills of the operator. We demonstrate a machine learning process for constructing a rapid reconnaissance ground model, by integrating several sources of geophysical data in to a single ground model in a rapid and objective manner. Firstly, we use topographic data acquired by a UAV survey to co-locate three geophysical surveys of the Hollin Hill Landslide Observatory in the UK. The data are inverted using a joint 2D mesh, resulting in a set of co-located models of resistivity, P-wave velocity and S-wave velocity. Secondly, we analyse the relationships and trends present between the variables for each point in the mesh (resistivity, P-wave velocity, S-wave velocity, depth) to identify correlations. Thirdly, we use a Gaussian Mixture Model (GMM), a form of unsupervised machine learning, to classify the geophysical data into cluster groups with similar ranges and trends in measurements. The resulting model created from probabilistically assigning each subsurface point to a cluster group characterises the heterogeneity of landslide materials based on their geophysical properties, identifying the major subsurface discontinuities at the site. Finally, we compare the results of the cluster groups to intrusive borehole data, which show good agreement with the spatial variations in lithology. We demonstrate the applicability of integrated geophysical surveys coupled with simple unsupervised machine learning for producing rapid reconnaissance ground models in time-critical situations with minimal prior knowledge about the subsurface.}
}
@article{LOUKAS2019124,
title = {A taxonomy and survey of cyber-physical intrusion detection approaches for vehicles},
journal = {Ad Hoc Networks},
volume = {84},
pages = {124-147},
year = {2019},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2018.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1570870518307091},
author = {George Loukas and Eirini Karapistoli and Emmanouil Panaousis and Panagiotis Sarigiannidis and Anatolij Bezemskij and Tuan Vuong},
keywords = {Vehicles, Cyber-physical systems, Intrusion detection, Vehicular networks, VANET, Cyber security, Aircraft, Unmanned aerial vehicles, Robotic land vehicles, Automobiles, Driverless pods},
abstract = {With the growing threat of cyber and cyber-physical attacks against automobiles, drones, ships, driverless pods and other vehicles, there is also a growing need for intrusion detection approaches that can facilitate defence against such threats. Vehicles tend to have limited processing resources and are energy-constrained. So, any security provision needs to abide by these limitations. At the same time, attacks against vehicles are very rare, often making knowledge-based intrusion detection systems less practical than behaviour-based ones, which is the reverse of what is seen in conventional computing systems. Furthermore, vehicle design and implementation can differ wildly between different types or different manufacturers, which can lead to intrusion detection designs that are vehicle-specific. Equally importantly, vehicles are practically defined by their ability to move, autonomously or not. Movement, as well as other physical manifestations of their operation may allow cyber security breaches to lead to physical damage, but can also be an opportunity for detection. For example, physical sensing can contribute to more accurate or more rapid intrusion detection through observation and analysis of physical manifestations of a security breach. This paper presents a classification and survey of intrusion detection systems designed and evaluated specifically on vehicles and networks of vehicles. Its aim is to help identify existing techniques that can be adopted in the industry, along with their advantages and disadvantages, as well as to identify gaps in the literature, which are attractive and highly meaningful areas of future research.}
}
@article{KOLANOWSKI2018236,
title = {Multisensor data fusion using Elman neural networks},
journal = {Applied Mathematics and Computation},
volume = {319},
pages = {236-244},
year = {2018},
note = {Recent Advances in Computing},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2017.02.031},
url = {https://www.sciencedirect.com/science/article/pii/S0096300317301352},
author = {Krzysztof Kolanowski and Aleksandra Świetlicka and Rafał Kapela and Janusz Pochmara and Andrzej Rybarczyk},
keywords = {AHRS, IMU, Sensor fusion, Neural network, Inertial navigation},
abstract = {The paper presents a navigation system based on Elman Artificial Neural Network (ANN). The task of data fusion from different sensors is realized by trained ANN. Determining position in space is an issue of nonlinear hence. Not every type of ANN is used for such a task. Choice of Elman ANN was dictated by its construction and successfully applications to nonlinear problems requiring prediction. Elman network is composed of three layers. Comprises a layer of hidden layer units context which is connected to the hidden layer. Context-sensitive layer allows for store the values of previous hidden units. With this layer prediction is possible in sequential order. This is the effect of contextual memory where information is stored about what it was before. This kind of functionality is not able to provide any other standard neural network unidirectional. The system consists of MEMS (Micro Electro-Mechanical Systems) sensors, which are based on IMU (Inertial Measurement Unit). IMU is composed from gyroscopes, accelerometers and magnetometers which provide three dimensional linear accelerations and angular rates. This is a classic set of sensors for determining the position in space. The study presents the results of the implementation of algorithms for determining the position in space using trained Elman ANN. The data samples to train ANN were collected during the test flight of Quadrocopter. Paper presents the performance for different configurations of Elman ANN. Presented system provides easy addition of other sensors e.g. GPS/GLONASS receiver.}
}
@article{TZELEPI2020107407,
title = {Improving the performance of lightweight CNNs for binary classification using quadratic mutual information regularization},
journal = {Pattern Recognition},
volume = {106},
pages = {107407},
year = {2020},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107407},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320302107},
author = {Maria Tzelepi and Anastasios Tefas},
keywords = {Hinge loss, Cross entropy loss, Binary classification problems, Quadratic mutual information, Regularizer, Lightweight models, Real-time, Convolutional neural networks, Deep learning},
abstract = {In this paper, we propose regularized lightweight deep convolutional neural network models, capable of effectively operating in real-time on-drone for high-resolution video input. Furthermore, we study the impact of hinge loss against the cross entropy loss on the classification performance, mainly in binary classification problems. Finally, we propose a novel regularization method motivated by the Quadratic Mutual Information, in order to improve the generalization ability of the utilized models. Extensive experiments on various binary classification problems involved in autonomous systems are performed, indicating the effectiveness of the proposed models. The experimental evaluation on four datasets indicates that hinge loss is the optimal choice for binary classification problems, considering lightweight deep models. Finally, the effectiveness of the proposed regularizer in enhancing the generalization ability of the proposed models is also validated.}
}
@article{AKRAM2019116319,
title = {CNN based automatic detection of photovoltaic cell defects in electroluminescence images},
journal = {Energy},
volume = {189},
pages = {116319},
year = {2019},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2019.116319},
url = {https://www.sciencedirect.com/science/article/pii/S0360544219320146},
author = {M. Waqar Akram and Guiqiang Li and Yi Jin and Xiao Chen and Changan Zhu and Xudong Zhao and Abdul Khaliq and M. Faheem and Ashfaq Ahmad},
keywords = {photovoltaic (PV) modules, Automatic defect detection, Electroluminescence, Deep learning, Convolutional neural network (CNN), PV cell cracking},
abstract = {Automatic defect detection is gaining huge importance in photovoltaic (PV) field due to limited application of manual/visual inspection and rising production quantities of PV modules. This study is conducted for automatic detection of PV module defects in electroluminescence (EL) images. We presented a novel approach using light convolutional neural network architecture for recognizing defects in EL images which achieves state of the art results of 93.02% on solar cell dataset of EL images. It requires less computational power and time. It can work on an ordinary CPU computer while maintaining real time speed. It takes only 8.07 ms for predicting one image. For proposing light architecture, we perform extensive experimentation on series of architectures. Moreover, we evaluate data augmentation operations to deal with data scarcity. Overfitting appears a significant problem; thus, we adopt appropriate strategies to generalize model. The impact of each strategy is presented. In addition, cracking patterns and defects that can appear in EL images are reviewed; which will help to label new images appropriately for predicting specific defect types upon availability of large data. The proposed framework is experimentally applied in lab and can help for automatic defect detection in field and industry.}
}
@article{CHOI2017158,
title = {Two-layer obstacle collision avoidance with machine learning for more energy-efficient unmanned aircraft trajectories},
journal = {Robotics and Autonomous Systems},
volume = {98},
pages = {158-173},
year = {2017},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2017.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0921889015301421},
author = {Youngjun Choi and Hernando Jimenez and Dimitri N. Mavris},
keywords = {Obstacle avoidance, Optimal trajectory, Clustering algorithm, Model predictive control, UAV, Path-planning},
abstract = {This paper proposes a new two-layer obstacle avoidance algorithm that allows an unmanned aircraft system to avoid multiple obstacles with minimal effort. The algorithm includes a global-path optimization that identifies the number of obstacles resulting from a clustering technique based on obstacle information from an airborne sensor, and specifies a potential threat. A local-path trajectory optimization employs a model predictive control structure based on a multi-phase optimal trajectory resulting from approximated dynamics, vehicle constraints, and the result of the global-path optimization. Numerical flight simulations are conducted with a conventional one-layer obstacle avoidance algorithm and the two-layer obstacle avoidance algorithm. The results of the numerical simulation show that the proposed two-layer optimal obstacle avoidance algorithm generates more energy-efficient avoidance trajectories when an unmanned aircraft meets multiple obstacles.}
}
@article{INNOCENTE201980,
title = {Self-organising swarms of firefighting drones: Harnessing the power of collective intelligence in decentralised multi-robot systems},
journal = {Journal of Computational Science},
volume = {34},
pages = {80-101},
year = {2019},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2019.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S1877750318310238},
author = {Mauro S. Innocente and Paolo Grasso},
keywords = {Self-organisation, Particle swarm, Fire spread modelling, Swarm robotics, Autonomous unmanned aerial vehicles},
abstract = {Swarm intelligence (SI) is concerned with the collective behaviour that emerges from decentralised self-organising systems, whilst swarm robotics (SR) is an approach to the self-coordination of large numbers of simple robots which emerged as the application of SI to multi-robot systems. Given the increasing severity and frequency of occurrence of wildfires and the hazardous nature of fighting their propagation, the use of disposable inexpensive robots in place of humans is of special interest. This paper demonstrates the feasibility and potential of employing SR to fight fires autonomously, with a focus on the self-coordination mechanisms for the desired firefighting behaviour to emerge. Thus, an efficient physics-based model of fire propagation and a self-organisation algorithm for swarms of firefighting drones are developed and coupled, with the collaborative behaviour based on a particle swarm algorithm adapted to individuals operating within physical dynamic environments of high severity and frequency of change. Numerical experiments demonstrate that the proposed self-organising system is effective, scalable and fault-tolerant, comprising a promising approach to dealing with the suppression of wildfires – one of the world's most pressing challenges of our time.}
}
@article{FAN2021102049,
title = {Disaster City Digital Twin: A vision for integrating artificial and human intelligence for disaster management},
journal = {International Journal of Information Management},
volume = {56},
pages = {102049},
year = {2021},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2019.102049},
url = {https://www.sciencedirect.com/science/article/pii/S0268401219302956},
author = {Chao Fan and Cheng Zhang and Alex Yahja and Ali Mostafavi},
keywords = {Digital twin, Machine learning, Information flow, Disaster management},
abstract = {This paper presents a vision for a Disaster City Digital Twin paradigm that can: (i) enable interdisciplinary convergence in the field of crisis informatics and information and communication technology (ICT) in disaster management; (ii) integrate artificial intelligence (AI) algorithms and approaches to improve situation assessment, decision making, and coordination among various stakeholders; and (iii) enable increased visibility into network dynamics of complex disaster management and humanitarian actions. The number of humanitarian relief actions is growing due to the increased frequency of natural and man-made crises. Various streams of research across different disciplines have focused on ICT and AI solutions for enhancing disaster management processes. However, most of the existing research is fragmented without a common vision towards a converging paradigm. Recognizing this, this paper presents the Disaster City Digital Twin as a unifying paradigm. The four main components of the proposed Digital Twin paradigm include: multi-data sensing for data collection, data integration and analytics, multi-actor game-theoretic decision making, and dynamic network analysis. For each component, the current state of the art related to AI methods and approaches are examined and gaps are identified.}
}
@article{LABBADI2020290,
title = {Robust adaptive nonsingular fast terminal sliding-mode tracking control for an uncertain quadrotor UAV subjected to disturbances},
journal = {ISA Transactions},
volume = {99},
pages = {290-304},
year = {2020},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2019.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S0019057819304665},
author = {Moussa Labbadi and Mohamed Cherkaoui},
keywords = {Nonsingular fast terminal sliding-mode, Quadrotor UAVs, Attitude and position control, Uncertainties and disturbances, Adaptive laws},
abstract = {This paper investigates the design of a robust controller for the trajectory tracking problem of an under-actuated quadrotor UAV subject to the modeling uncertainties and unknown external disturbances. A new robust nonlinear adaptive controller is proposed for orientation and translation tracking by using the Adaptive Nonsingular Fast Terminal Sliding-Mode Control (ANFTSMC) algorithms. The ANFTSM control law: (i) ensures fast convergence, i.e. the quadrotor outputs achieve to the original values in a short finite-time; (ii) avoids singularities; (iii) solves the chattering effect; (iv) offers robustness against the unknown external disturbances and uncertainties. Furthermore, the system unknown uncertainty and external disturbances upper bound are coped by the proposed control approach. Online estimation of these upper bounds is only introduced by velocity and position measurements. In addition, the control law applies the Lyapunov theory, guarantees the closed-loop stability of the quadrotor system. Finally, various simulations under different scenarios in terms of external disturbances and parametric uncertainties are carried out to evaluate/emphasize the effectiveness of the ANFTSMC strategy proposed in this work. Moreover, a comparative study is accomplished at the end of the present paper and shows clearly the outperformance of the proposed control scheme.}
}
@article{MALEKZADEH2022476,
title = {AKF-SR: Adaptive Kalman filtering-based successor representation},
journal = {Neurocomputing},
volume = {467},
pages = {476-490},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221014867},
author = {Parvin Malekzadeh and Mohammad Salimibeni and Ming Hou and Arash Mohammadi and Konstantinos N. Plataniotis},
keywords = {Reinforcement Learning, Successor representation, Kalman filter, Kalman temporal difference, Multiple model adaptive estimation, Radial basis function},
abstract = {To understand animals’ behavior in finding relations between similar tasks and adapting themselves to changes in the tasks, it is necessary to know how the brain generalizes the learned knowledge from a previous task to unseen tasks. Recent studies in neuroscience suggest that Successor Representation (SR)-based models provide adaptation to changes in the goal locations or reward function faster than model-free algorithms, together with lower computational cost compared to that of model-based algorithms. However, it is not known how such representation might help animals to manage uncertainty in their decision making. Existing methods for the SR learning based on standard temporal difference methods (e.g., deep neural network-based algorithms) do not capture uncertainty about the estimated SR. In order to address this issue, the paper presents a Kalman filter-based SR framework, referred to as Adaptive Kalman Filtering-based Successor Representation (AKF–SR). First, Kalman temporal difference approach, which is a combination of Kalman filter and the temporal difference method, is used within the AKF–SR framework to cast the SR learning procedure into a filtering problem to benefit from uncertainty estimation of the SR, and also decreases in memory requirement and sensitivity to model’s parameters in comparison to deep neural network-based algorithms. An adaptive Kalman filtering approach is then applied within the proposed AKF–SR framework in order to tune the measurement noise covariance and measurement mapping function of Kalman filter as the most important parameters affecting the filter’s performance. Moreover, an active learning method that exploits the estimated uncertainty of the SR to form the behaviour policy leading to more visits to less certain values is proposed to improve the overall performance of an agent in terms of received rewards while interacting with its environment. Experimental results based on three reinforcement learning environments illustrate the efficacy of the proposed AKF–SR framework over state-of-the-art frameworks in terms of cumulative reward, reliability, time and computational cost, and speed of convergence to changes in the reward function.}
}
@article{CARVALHO2020103840,
title = {Computation offloading in Edge Computing environments using Artificial Intelligence techniques},
journal = {Engineering Applications of Artificial Intelligence},
volume = {95},
pages = {103840},
year = {2020},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2020.103840},
url = {https://www.sciencedirect.com/science/article/pii/S0952197620302050},
author = {Gonçalo Carvalho and Bruno Cabral and Vasco Pereira and Jorge Bernardino},
keywords = {Artificial Intelligence, Computation offloading, Edge Computing, Machine Learning},
abstract = {Edge Computing (EC) is a recent architectural paradigm that brings computation close to end-users with the aim of reducing latency and bandwidth bottlenecks, which 5G technologies are committed to further reduce, while also achieving higher reliability. EC enables computation offloading from end devices to edge nodes. Deciding whether a task should be offloaded, or not, is not trivial. Moreover, deciding when and where to offload a task makes things even harder and making inadequate or off-time decisions can undermine the EC approach. Recently, Artificial Intelligence (AI) techniques, such as Machine Learning (ML), have been used to help EC systems cope with this problem. AI promises accurate decisions, higher adaptability and portability, thus diminishing the cost of decision-making and the probability of error. In this work, we perform a literature review on computation offloading in EC systems with and without AI techniques. We analyze several AI techniques, especially ML-based, that display promising results, overcoming the shortcomings of current approaches for computing offloading coordination We sorted the ML algorithms into classes for better analysis and provide an in-depth analysis on the use of AI for offloading, in particular, in the use case of offloading in Vehicular Edge Computing Networks, actually one technology that gained more relevance in the last years, enabling a vast amount of solutions for computation and data offloading. We also discuss the main advantages and limitations of offloading, with and without the use of AI techniques.}
}
@article{WANG201114307,
title = {Fault diagnosis based on pulse coupled neural network and probability neural network},
journal = {Expert Systems with Applications},
volume = {38},
number = {11},
pages = {14307-14313},
year = {2011},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2011.05.095},
url = {https://www.sciencedirect.com/science/article/pii/S0957417411008797},
author = {Changqing Wang and Jianzhong Zhou and Hui Qin and Chaoshun Li and Yongchuan Zhang},
keywords = {Fault diagnosis, Pulse coupled neural network, Probability neural network, Shaft orbit},
abstract = {In operation of mechanical equipment, fault diagnosis plays an important role. In this paper, a novel fault diagnosis method based on pulse coupled neural network (PCNN) and probability neural network (PNN) is presented. The shape information of shaft orbit provides an important basis for fault diagnosis. However, the feature extraction and classification of shaft orbit is difficult to realize automation. The PCNN technique has excellent performance in the feature extraction. In the present study, a PCNN combined with roundness method is used to extract the feature vector of shaft orbit, because time signature from a PCNN has the property of insensitive to rotation, scaling and translation. Meanwhile, roundness is also with the same properties. Further, the PNN is used to train the feature vectors and classify the vibration fault. By comparison with the back-propagation (BP) network and radial-basic function (RBF) network, the experimental result indicated the proposed approach achieved fast and efficient fault diagnosis.}
}
@article{ZHANG2021112724,
title = {Transfer-learning-based approach for leaf chlorophyll content estimation of winter wheat from hyperspectral data},
journal = {Remote Sensing of Environment},
volume = {267},
pages = {112724},
year = {2021},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112724},
url = {https://www.sciencedirect.com/science/article/pii/S0034425721004442},
author = {Yao Zhang and Jian Hui and Qiming Qin and Yuanheng Sun and Tianyuan Zhang and Hong Sun and Minzan Li},
keywords = {Hyperspectral, Chlorophyll, PROSAIL, Transfer learning, UAV experiment, Ground-based measurement},
abstract = {Leaf chlorophyll, as a key factor for carbon circulation in the ecosystem, is significant for the photosynthetic productivity estimation and crop growth monitoring in agricultural management. Hyperspectral remote sensing (RS) provides feasible solutions for obtaining crop leaf chlorophyll content (LCC) by the advantages of its repeated and high throughput observations. However, the data redundancy and the poor robustness of the inversion models are still major obstacles that prevent the widespread application of hyperspectral RS for crop LCC evaluation. For winter wheat LCC inversion from hyperspectral observations, this study described a novel hybrid method, which is based on the combination of amplitude- and shape- enhanced 2D correlation spectrum (2DCOS) and transfer learning. The innovative feature selection method, amplitude- and shape- enhanced 2DCOS, which originated from 2DCOS, additionally considered the relationships between external perturbations and hyperspectral amplitude and shape characteristics to enhance the dynamic spectrum response. To extract the representative LCC featured wavelengths, the amplitude- and shape- enhanced 2DCOS was conducted on the leaf optical PROperties SPECTra (PROSPECT) + Scattering from Arbitrarily Inclined Leaves (SAIL) (PROSAIL) simulated dataset, which covered most possible winter wheat canopy spectra. Nine wavelengths (i.e., 455, 545, 571, 615, 641, 662, 706, 728, and 756 nm) were then extracted as the sensitive wavelengths of LCC with the amplitude- and shape- enhanced 2DCOS. These wavelengths had specificity to LCC and showed good correlation with LCC from the aspect of photosynthesis mechanism, molecular structure, and optical properties. The transfer learning techniques based on the deep neural network was then introduced to transfer the knowledge learned from the PROSAIL simulated dataset to the inversion tasks of field measured LCC. Parts of the labeled samples in field observations were used to finetune the model pre-trained by the simulated dataset to improve the inversion accuracy of the winter wheat LCC in different field scenes, aiming to reduce the need for the field measured and labeled sample size. To further ascertain the universality, transferability and predictive ability of the proposed hybrid method, field samples collected from different locations at different phenological phases, including the jointing and heading stages in 2013, 2014, and 2018, were utilized as target tasks to validate the proposed hybrid method. Moreover, the LCC of winter wheat estimated with the proposed method was evaluated with the ground-based platform and the UAV-based platform to verify the model versatility for different monitoring platforms. Various validations demonstrated that the hybrid inversion method combining the amplitude- and shape- enhanced 2DCOS and the fine-tuned transfer learning model could effectively estimate winter wheat LCC with good accuracy and robustness, and can be extended to the detection and inversion of other key variables of crops.}
}
@article{ROZAS2018200,
title = {Residual-based scheme for detection and characterization of faults in lithium-ion batteries},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {24},
pages = {200-207},
year = {2018},
note = {10th IFAC Symposium on Fault Detection, Supervision and Safety for Technical Processes SAFEPROCESS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.09.578},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318322870},
author = {Heraldo Rozas and Ruben M. Claveria and Marcos E. Orchard and Kamal Medjaher},
keywords = {Analytical redundancy relation, Bond graph, Fault detection, isolation, Lithium-ion batteries},
abstract = {This work proposes a real-time scheme to monitor the occurrence of faults and perform fault characterization. Faults, in this context, correspond to changes in the parameters of the system being monitored. The method relies on the concept of Analytical Redundancy Relation (ARR), which can be defined as the evaluation of the mathematical constraints of the physical model of the system given the real, noisy measurements. The algorithm consists of two modules: a detection strategy that relies on the regular application of an ARR-based hypothesis test in discrete time-steps; and an optimization procedure to estimate the changes undergone after a fault. By selecting a set of feasible solutions from the output of the optimization algorithm, the method also sheds some light on the uncertainty associated to the estimated quantities. The methodology is tested on simulated data of lithium-ion batteries in unmanned aerial vehicles.}
}
@article{WU2018735,
title = {A hybrid algorithm of particle swarm optimization, metropolis criterion and RTS smoother for path planning of UAVs},
journal = {Applied Soft Computing},
volume = {73},
pages = {735-747},
year = {2018},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2018.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S1568494618305283},
author = {Xiande Wu and Wenbin Bai and Yaen Xie and Xinzhu Sun and Chengchen Deng and Hongtao Cui},
keywords = {Path planning, Particle Swarm Optimization, Metropolis criterion, Rauch–Tung–Striebel, Hybrid algorithm},
abstract = {Particle Swarm Optimization (PSO) algorithm is a simple approach with premature convergence and stagnation prone. The loss of efficiency and sub-optimal solution occur frequently while solving path planning problem with PSO. Therefore, a method is proposed to optimize parameters which affect performance of the PSO algorithm by using Rauch–Tung–Striebel (RTS) smoother. Moreover the Metropolis Criterion is applied as acceptance policy, which can prevent the PSO algorithm from falling into local minimums in the proposed method. The RTS smoother is applied to eliminate the irregular error of the PSO updated position, and to smooth the produced path. Experimental results show the proposed method which is based on the fusion of the PSO, Metropolis Criterion and RTS performs better than the existing methods in terms of solution’s quality and robustness in the path planning problem for UAVs.}
}
@article{KIM2016188,
title = {Slack Variables Generation via QR Decomposition for Adaptive Nonlinear Control of Affine Underactuated Systems},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {17},
pages = {188-193},
year = {2016},
note = {20th IFAC Symposium on Automatic Control in AerospaceACA 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.09.033},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316315051},
author = {Mingu Kim and Youkyung Hong and Seokwon Lee and Youdan Kim},
keywords = {Adaptive Control, Underactuated System, Slack Variables},
abstract = {This paper presents a slack variable generation method utilizing QR decomposition for an adaptive nonlinear controller of affine underactuated systems. Slack variables are adopted to overcome nonsquare properties of underactuated systems. QR decomposition has an advantage of fast and accurate calculation to compute least square solution of underdetermined systems. In this paper, the slack variable generation using the QR decomposition is proposed to guarantee the stability of the closed-loop system with an adaptive nonlinear controller. Numerical simulations are performed to verify the performance of the adaptive nonlinear controller with the proposed slack variable generation method for a quadrotor unmanned aerial vehicle and an unmanned helicopter.}
}
@article{HOSSEINI2021106880,
title = {Artificial intelligence for resilience enhancement of power distribution systems},
journal = {The Electricity Journal},
volume = {34},
number = {1},
pages = {106880},
year = {2021},
note = {Special Issue: Machine Learning Applications To Power System Planning And Operation},
issn = {1040-6190},
doi = {https://doi.org/10.1016/j.tej.2020.106880},
url = {https://www.sciencedirect.com/science/article/pii/S104061902030172X},
author = {Mohammad Mehdi Hosseini and Masood Parvania},
keywords = {Artificial intelligence, Power distribution systems, Resilience enhancement, Intelligent operation},
abstract = {The threat of high impact low probability (HILP) events on power distribution system is substantial but quite unpredictable. Enhancing the resilience of power distribution grids against such events requires solving combinatorial planning and operational problems in stochastic spaces, as well as classifying system conditions based on high-dimensional input data. Since traditional mathematical solutions struggle with both uncertainty and the curse of dimensionality, data-driven techniques based on artificial intelligence (AI) are gaining momentum for solving those problems. This paper reviews AI capabilities for decision making in uncertain and high-dimensional spaces in general, and their particular application in resilient enhancement problems such as damage detection and estimation, cyber-physical anomaly detection, stochastic operation, and cyber security enhancement. Efficient data structures and AI approaches are suggested for each problem, which depend on the type of input signals, search-based or game-based structure of the problem, as well as the uncertainty sources involved. In particular, potential applications of supervised and unsupervised deep learning combined with Monte Carlo Tree Search and ε-greedy search is explored to find near optimal operational decisions that help enhance the resilience of power distribution systems.}
}
@article{REGO20191695,
title = {Suspended load path tracking control using a tilt-rotor UAV based on zonotopic state estimation},
journal = {Journal of the Franklin Institute},
volume = {356},
number = {4},
pages = {1695-1729},
year = {2019},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2018.08.028},
url = {https://www.sciencedirect.com/science/article/pii/S0016003218306926},
author = {Brenner S. Rego and Guilherme V. Raffo},
abstract = {This work addresses the problem of path tracking control of a suspended load using a tilt-rotor UAV. The main challenge in controlling this kind of system arises from the dynamic behavior imposed by the load, which is usually coupled to the UAV by means of a rope, adding unactuated degrees of freedom to the whole system. Furthermore, to perform the load transportation it is often needed the knowledge of the load position to accomplish the task. Since available sensors are commonly embedded in the mobile platform, information on the load position may not be directly available. To solve this problem in this work, initially, the kinematics of the multi-body mechanical system are formulated from the load’s perspective, from which a detailed dynamic model is derived using the Euler–Lagrange approach, yielding a highly coupled, nonlinear state-space representation of the system, affine in the inputs, with the load’s position and orientation directly represented by state variables. A zonotopic state estimator is proposed to solve the problem of estimating the load position and orientation, which is formulated based on sensors located at the aircraft, with different sampling times, and unknown-but-bounded measurement noise. To solve the path tracking problem, a discrete-time mixed H2/H∞ controller with pole-placement constraints is designed with guaranteed time-response properties and robust to unmodeled dynamics, parametric uncertainties, and external disturbances. Results from numerical experiments, performed in a platform based on the Gazebo simulator and on a Computer Aided Design (CAD) model of the system, are presented to corroborate the performance of the zonotopic state estimator along with the designed controller.}
}
@article{PARTEL2019328,
title = {Automated vision-based system for monitoring Asian citrus psyllid in orchards utilizing artificial intelligence},
journal = {Computers and Electronics in Agriculture},
volume = {162},
pages = {328-336},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S016816991930554X},
author = {Victor Partel and Leon Nunes and Phil Stansly and Yiannis Ampatzidis},
keywords = {Huanglongbing (HLB), Asian citrus psyllid (ACP), Insect detection, Machine vision, Deep learning, Neural networks},
abstract = {Specialty crop growers face challenges from numerous diseases and pests. For example, the Asian citrus psyllid (ACP) is a key pest of citrus due to its role as vector of huanglongbing (HLB) (greening disease). There is no known cure for HLB, but vector management is critical, both for slowing spread and attenuating symptoms in infected trees. Therefore, monitoring ACP population, as well as other pest populations, is an essential management component for timing and assessment of control actions. Manual crop scouting is often labor intensive and time consuming. In this work, an automated system was developed and evaluated utilizing machine vision and artificial intelligence to monitor ACP in groves. This system comprised a tapping mechanism to collect insects from the tree’s branches and a board with a grid of cameras for image acquisition. A software was developed using two convolutional neural-networks to accurately detect and distinguish psyllids from other insects and debris fallen from the tree. A GPS was utilized to automatically record individual tree position to facilitate data assessment on large groves. A precision and recall of 80% and 95%, respectively, was obtained on detecting ACPs on a sample of 90 young citrus trees. The system proved a great potential to automate scouting procedures in citrus and to be extended to other crop insects.}
}
@article{DING2021,
title = {An Internet of Things Based Scalable Framework for Disaster Data Management},
journal = {Journal of Safety Science and Resilience},
year = {2021},
issn = {2666-4496},
doi = {https://doi.org/10.1016/j.jnlssr.2021.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S2666449621000542},
author = {Zhiming Ding and Shan Jiang and Xinrun Xu and Yanbo Han},
keywords = {Disaster Data Management, IoT, Disaster Detection, Big data, Artificial Intelligence},
abstract = {In recent years, undesirable disasters attacked the cities frequently, leaving heavy casualties and serious economic losses. Meanwhile, disaster detection based on the Internet of Things(IoT) has become a hot spot benefited by the established development of smart city construction. And the IoT is visibly sensitive to the management and monitor of disasters, but massive amounts of monitoring data have brought huge challenges to data storage and data analysis. This article develops a new and much more general framework for disaster emergency management under the IoT environment. The framework is a bottom-up integration of highly scalable Raw Data Storages(RD-Stores) technology, hybrid indexing and queries technology, and machine learning technology for emergency disasters. Experimental results show that hybrid index and query technology have better performance under the condition of supporting multi-modal retrieval, and providing a better solution to offer real-time retrieval for the massive sensor sampling data in the IoT. In addition, further works to evaluate the top-level sub-application system in this framework were performed based on the GPS trajectory data of 35,000 Beijing taxis and the volumetric ground truth data of 7,500 images. The results show that the framework has desirable scalability and higher utility.}
}
@article{NOWAKOWSKI2021102313,
title = {Crop type mapping by using transfer learning},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {98},
pages = {102313},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102313},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421000209},
author = {Artur Nowakowski and John Mrziglod and Dario Spiller and Rogerio Bonifacio and Irene Ferrari and Pierre Philippe Mathieu and Manuel Garcia-Herranz and Do-Hyung Kim},
keywords = {Crop detection, Transfer learning, Convolutional neural networks, Drone images},
abstract = {Crop type mapping currently represents an important problem in remote sensing. Accurate information on the extent and types of crops derived from remote sensing can help managing and improving agriculture especially for developing countries where such information is scarce. In this paper, high-resolution RGB drone images are the input data for the classification performed using a transfer learning (TL) approach. VGG16 and GoogLeNet, which are pre-trained convolutional neural networks (CNNs) used for classification tasks coming from computer vision, are considered for the mapping of the crop types. Thanks to the transferred knowledge, the proposed models can successfully classify the studied crop types with high overall accuracy for two considered cases, achieving up to almost 83% for the Malawi dataset and up to 90% for the Mozambique dataset. Notably, these results are comparable to the ones achieved by the same deep CNN architectures in many computer vision tasks. With regard to drone data analysis, application of deep CNN is very limited so far due to high requirements on the number of samples needed to train such complicated architectures. Our results demonstrate that the transfer learning is an efficient way to overcome this problem and take full advantage of the benefits of deep CNN architectures for drone-based crop type mapping. Moreover, based on experiments with different TL approaches we show that the number of frozen layers is an important parameter of TL and a fine-tuning of all the CNN weights results in significantly better performance than the approaches that apply fine-tuning only on some numbers of last layers.}
}
@article{REZAEI2019807,
title = {Numerical evaluation of gamma radiation monitoring},
journal = {Nuclear Engineering and Technology},
volume = {51},
number = {3},
pages = {807-817},
year = {2019},
issn = {1738-5733},
doi = {https://doi.org/10.1016/j.net.2018.12.020},
url = {https://www.sciencedirect.com/science/article/pii/S1738573318305370},
author = {Mohsen Rezaei and Mansour Ashoor and Leila Sarkhosh},
keywords = {Artificial neural networks, BFGS training algorithm, Airborne gamma ray spectrometry, Nuclear site surveillance},
abstract = {Airborne Gamma Ray Spectrometry (AGRS) with its important applications such as gathering radiation information of ground surface, geochemistry measuring of the abundance of Potassium, Thorium and Uranium in outer earth layer, environmental and nuclear site surveillance has a key role in the field of nuclear science and human life. The Broyden–Fletcher–Goldfarb–Shanno (BFGS), with its advanced numerical unconstrained nonlinear optimization in collaboration with Artificial Neural Networks (ANNs) provides a noteworthy opportunity for modern AGRS. In this study a new AGRS system empowered by ANN-BFGS has been proposed and evaluated on available empirical AGRS data. To that effect different architectures of adaptive ANN-BFGS were implemented for a sort of published experimental AGRS outputs. The selected approach among of various training methods, with its low iteration cost and non-diagonal scaling allocation is a new powerful algorithm for AGRS data due to its inherent stochastic properties. Experiments were performed by different architectures and trainings, the selected scheme achieved the smallest number of epochs, the minimum Mean Square Error (MSE) and the maximum performance in compare with different types of optimization strategies and algorithms. The proposed method is capable to be implemented on a cost effective and minimum electronic equipment to present its real-time process, which will let it to be used on board a light Unmanned Aerial Vehicle (UAV). The advanced adaptation properties and models of neural network, the training of stochastic process and its implementation on DSP outstands an affordable, reliable and low cost AGRS design. The main outcome of the study shows this method increases the quality of curvature information of AGRS data while cost of the algorithm is reduced in each iteration so the proposed ANN-BFGS is a trustworthy appropriate model for Gamma-ray data reconstruction and analysis based on advanced novel artificial intelligence systems.}
}
@article{YU2021403,
title = {Finite-horizon robust formation-containment control of multi-agent networks with unknown dynamics},
journal = {Neurocomputing},
volume = {458},
pages = {403-415},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.01.063},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221000916},
author = {Di Yu and Shuzhi Sam Ge and Dongyu Li and Peng Wang},
keywords = {Finite-horizon, Multi-agent networks, Formation-containment, Integral reinforcement learning},
abstract = {In the paper, data-driven finite-horizon robust formation-containment control scheme is developed based on integral reinforcement learning and zero-sum game for perturbed multi-agent networks with completely unknown nonlinear dynamics. At first, distributed finite-time sliding mode estimators are designed to obtain the desired states of leaders and followers, respectively. Then finite-horizon robust leader formation control and follower containment control are achieved based on proposed model-free integral reinforcement learning algorithms implemented by critic-actor-disturbance structure, in the framework of multi-player zero-sum game where the non-quadratic performance index for each agent considers the influence of saturated inputs and disturbances of local neighbors thoroughly. Furthermore, it is proved that the whole network has bounded L2 gain robust stability and Nash equilibrium of zero-sum game exists. Simulation results are provided to demonstrate the effectiveness of the proposed scheme.}
}
@article{LIU2021114603,
title = {Fault diagnosis approach for photovoltaic array based on the stacked auto-encoder and clustering with I-V curves},
journal = {Energy Conversion and Management},
volume = {245},
pages = {114603},
year = {2021},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2021.114603},
url = {https://www.sciencedirect.com/science/article/pii/S0196890421007792},
author = {Yongjie Liu and Kun Ding and Jingwei Zhang and Yuanliang Li and Zenan Yang and Wenming Zheng and Xiang Chen},
keywords = {Photovoltaic array, Fault diagnosis, Stacked auto-encoder, Clustering, Photovoltaic modeling, I-V and P-V curves},
abstract = {Photovoltaic arrays are usually installed outdoors in harsh environments and prone to various faults, which will seriously affect the efficiency of photovoltaic arrays. Therefore, the effective fault detection and diagnosis plays an important role in the safe, operation, and maintenance of the photovoltaic plant. In recent years, machine learning methods have made remarkable achievements in fault diagnosis. However, there still exist some limitations: (1) feature extraction relies on expert experience and lacks automation. (2) artificial feature extraction easily ignores some potential useful features. (3) the nonlinear characteristics of current–voltage curves cannot be effectively learned by the shallow network structure. In order to address the above issues, the supervised deep learning methods with automatic feature extraction capability are applied, but a lot of labeled data are required for pre-training. Therefore,a fault diagnosis method is proposed for photovoltaic array based on stacked auto-encoder and clustering algorithm in this paper, which can automatically extract features and use a small number of labeled data samples to mine data sample features for fault diagnosis. Firstly, the effective features are automatically extracted by the stacked auto-encoder from the current–voltage curves. Secondly, the dimension of the features is reduced and visualized by the t-distributed stochastic neighbor embedding to improve the performance of the clustering algorithm. Finally, clustering centers and clusters are obtained by clustering algorithm and membership function is used for fault diagnosis. Moreover, the simulation and experimental data are used to verify the performance of the proposed fault diagnosis method. The 97.3% and 98.3% classification accuracies are obtained in the simulation and experimental results.}
}
@article{HERNANDEZ201411872,
title = {Formation Control of UGVs using an UAV as Remote Vision Sensor},
journal = {IFAC Proceedings Volumes},
volume = {47},
number = {3},
pages = {11872-11877},
year = {2014},
note = {19th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20140824-6-ZA-1003.01660},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016435056},
author = {Andres Hernandez and Cosmin Copot and Juan Cerquera and Harold Murcia and Robin {De Keyser}},
keywords = {Autonomous vehicles, Closed-loop control, computer vision, flight control},
abstract = {A leader-follower formation control scheme based on SRV-1 UGVs and an AR.DRONE 2.0 UAV as remote vision sensor is presented in this paper. The main advantage of the proposed strategy lies on the flexibility obtained from a flight remote sensor, as it makes possible to locate the agents at larger distances between them or to extend more easily the number of agents in the formation. A full description of the internal control designed for the UGVs and the UAV is presented, including the image processing procedure implemented to robustly measure the pose of the vehicles in the formation. Finally, experimental results using a triangular formation of three ground robots illustrates the effectiveness of the proposed control scheme.}
}
@article{POURASIABI2012782,
title = {Development a multi-layer perceptron artificial neural network model to estimate the Vickers hardness of Mn–Ni–Cu–Mo austempered ductile iron},
journal = {Materials & Design},
volume = {35},
pages = {782-789},
year = {2012},
note = {New Rubber Materials, Test Methods and Processes},
issn = {0261-3069},
doi = {https://doi.org/10.1016/j.matdes.2011.09.052},
url = {https://www.sciencedirect.com/science/article/pii/S0261306911006777},
author = {HaMiD PourAsiabi and Hamed PourAsiabi and Zhila AmirZadeh and Mohammad BabaZadeh},
keywords = {A. Ferrous metals and alloys, C. Casting, C. Heat treatments},
abstract = {The hardness of austempered ductile irons is relative to its microstructure, strength, ductility, machinability and wear resistance properties. Therefore, hardness measurement can be used as a simple tool to control the heat treatment, chemical composition and mechanical properties of ADI parts during the production process. The aim of this study is to develop an Artificial Neural Network (ANN) model for estimating the Vickers hardness of ADIs after austempering treatment. A Multi-Layer Perceptron model (MLP–ANN) was used with Mo%, Cu%, austempering time and temperature as inputs and the Vickers hardness of samples after austempering as the output of the model. A variety of samples were prepared in different conditions of chemical composition and heat treatment cycle. The obtained experimental results were used for training the neural network. Efficiency test of the model showed reasonably good agreement between experimental and numerical results, so the synthesized ANN model can estimate the hardness of the castings with a small error in the range of the experimental results standard deviation.}
}
@article{OPROMOLLA2021107167,
title = {Visual-based obstacle detection and tracking, and conflict detection for small UAS sense and avoid},
journal = {Aerospace Science and Technology},
volume = {119},
pages = {107167},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107167},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821006775},
author = {Roberto Opromolla and Giancarmine Fasano},
keywords = {Small unmanned aircraft systems, Sense and avoid, Machine vision, Deep learning, Visual detection and tracking, Conflict detection},
abstract = {This paper proposes an original approach for visual-based obstacle detection and tracking, and conflict detection, suitable to endow small Unmanned Aircraft Systems with non-cooperative Sense and Avoid capabilities. Specifically, it is designed to detect and track an uncooperative flying object (intruder), and to establish whether or not it represents a collision threat. It is based on three main algorithmic steps, each aided by the use of ownship navigation data. First, visual detection is carried out using two Deep Learning based neural networks (operating above and below the horizon, respectively) followed by local image analysis to improve the accuracy in the detected intruder position on the image plane. Second, tentative track generation and firm tracking are executed exploiting local association, multi-temporal frame differencing, and Kalman filtering. Finally, conflict detection is applied to each firm track based on the estimate of line of sight and line of sight rate in stabilized coordinates. An experimental dataset, which reproduces realistic low-altitude encounter geometries with two customized quadcopters, is collected to assess proposed approach performance. The two vehicles, equipped with high-resolution color cameras, are flown at slightly different altitudes so that the intruder is located above and below the horizon in the two respective image subsets. The proposed approach allows the target to be declared at relatively long range and to be tracked with a line of sight rate accuracy of the order of tenths of degrees per second, which is effective for conflict detection.}
}
@article{KAMNIK2020105391,
title = {Using the scanners and drone for comparison of point cloud accuracy at traffic accident analysis},
journal = {Accident Analysis & Prevention},
volume = {135},
pages = {105391},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105391},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519303811},
author = {Rok Kamnik and Matjaž {Nekrep Perc} and Darja Topolšek},
keywords = {Accident analysis, 3D model, Point cloud analysis, Accuracy, Scanner, UAV, Photogrammetry, SfM, TLS, Super resolution, Colour detection},
abstract = {The purpose of the paper is to describe, compare and analyse the instruments used, time needed and accuracy of gathered data, sketches, 3D models and to enhance the extracted information about the accident. Simple sketches and tape measurements were performed. Also complex 3D measurements and 3D modelling of the scene with Terrestrial Laser Scanners (TLS) and Unmanned Aerial Vehicle (UAV) technology were used. A classical police work dealing with a simulated traffic accident was compared to sketches obtained from 3D models from Riegl VZ-400i 3D, Faro Focus S70, Geoslam ZebRevo 3D TLS and Topcon Falcon 8 drone. For 3D modelling an orthophoto from drone photos and point clouds were obtained. 3D models were graphically compared in CloudCompare software. Sketches were made for each measuring method and their accuracies were also compared one to each other. The graphical distance accuracy in scene measurements ranged up to 17 cm in comparison to police measurement but in the most course point cloud. Average absolute difference in compared distances amounts up to 6 cm. As expected, more points in the cloud means better 3D model and easier analysis. There is considerable reduction of time needed for collecting the accident scene data. The obtained 3D model is a permanent archive of the scene of a traffic accident. From the cadre, both visual and dimensional information subsequently can be obtained.}
}
@article{DONGJUAN2013171,
title = {Adaptive neural network control for continuous stirred tank reactor process},
journal = {IFAC Proceedings Volumes},
volume = {46},
number = {20},
pages = {171-175},
year = {2013},
note = {3rd IFAC Conference on Intelligent Control and Automation Science ICONS 2013},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20130902-3-CN-3020.00148},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016315270},
author = {Li Dong-Juan},
keywords = {Adaptive control, neural networks, continuous stirred tank reactor process, nonlinear systems},
abstract = {In this paper, an adaptive control algorithm is proposed for a two continuous stirred tank reactor (CSTR) with unknown functions based on the approximation property of the neural networks. Because the considered reactor contains the nonlinear property and the unknown functions are included in the subsystem, it is a completed system and is very difficult to be controlled. In order to avoid the difficulties, novel recursive design method is used to remove the interconnection term and special approximated functions are defined to be approximated by using the neural networks. Using the Lyapunov stability analysis method, the proposed algorithm ensures that all the signals in the closed-loop system are bounded and the system output can converge to a neighborhood of zero.}
}
@article{KILIC2021,
title = {Drone classification using RF signal based spectral features},
journal = {Engineering Science and Technology, an International Journal},
year = {2021},
issn = {2215-0986},
doi = {https://doi.org/10.1016/j.jestch.2021.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S2215098621001403},
author = {Rabiye Kılıç and Nida Kumbasar and Emin Argun Oral and Ibrahim Yucel Ozbek},
keywords = {Drone detection, Classification, RF signal, PSD, MFCC, LFCC, SVM},
abstract = {Drone detection and classification, important in military and civilian applications, are performed using different sensor signals. Proposed study handles this task using Radio Frequency (RF) signals utilizing basic machine learning methods. It is composed of two main stages as feature extraction succeeded by training/testing of the model. In feature extraction stage, valuable information for classification, contained in the RF signal, is obtained. For this purpose, spectral features, frequently used in speech processing applications, are employed. Specifically, Power Spectral Density (PSD), Mel-Frequency Cepstral Coefficients (MFCC) and Linear Frequency Cepstral Coefficients (LFCC) are adopted by adjusting filter bank margins and parameters for this task. In the second stage, a Support Vector Machine (SVM) classifier is first trained based on the obtained features and finally tested to measure its performance. All experimental studies are carried out using publicly available DroneRF dataset. This dataset contains 2-Class, 4-Class and 10-Class samples for drone existence vs. background (BG), drone types and drone operation modes, respectively. The best classification results are obtained using, PSD, MFCC and LFCC based features for 2-Class, MFCC and LFCC based features for 4-Class and LFCC based features for 10-Class. Accuracy rates for 2-Class, 4-Class and 10-Class are 100%, 98.67% and 95.15%, respectively. These results show that the proposed method outperforms the results given in the literature for DroneRF dataset.}
}
@article{CHEN2021107760,
title = {Constructing a stock-price forecast CNN model with gold and crude oil indicators},
journal = {Applied Soft Computing},
volume = {112},
pages = {107760},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107760},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621006815},
author = {Yu-Chen Chen and Wen-Chen Huang},
keywords = {Stock price forecast, Deep learning, Convolutional neural networks, Long short-term memory, Bayesian optimization},
abstract = {In this study, we propose algorithms to predict future stock market trends based on 8 different input features, including financial technology indicators, gold prices, a gold price volatility index, crude oil price, a crude oil price volatility index, and other characteristic data using two different labeling methods with separate classification algorithms of two and three output categories, respectively including predicted stock price changes (up and down) and recommended trading actions (buy, sell, and hold), and analyze the validity of these characteristic data in terms of their ability to predict future trends. The S&P 500 (GSPC) is the target of these forecasts. Sample data from 2010 to 2018 are divided 8:2, between training and verification data, while data from 2019 are used to test the proposed approach. CNN and LSTM models are used for comparison of classification accuracy and investment returns, respectively. Bayesian optimization (BO) hyperparameters are used to improve the accuracy of the model and increase the return on investment (ROI) of the output predictions. The purpose of this study is to verify whether using gold prices, a gold volatility index, crude oil price, and a crude oil price volatility indices as input features can enable a deep learning model accurately to predict future stock price trends, and to discuss separately the applicability of CNN and LSTM models to the abovementioned characteristics and financial indicators. We also present the results of experiments conducted to evaluate the proposed method in terms of classification accuracy and confusion matrix. In the case of three-category classification, the model takes feature data as input to outputs a predicted trading order on whether to buy, sell, or hold a given set of stocks tomorrow as well as the timing of entry and exit from each position, and also backtests the data outside the sample to find the combination of characteristics and indicators best maximizing ROI. Using this three-category method, we obtain a comprehensive ROI for a given set of individual stocks and assess whether each type of stock is suitable for the prediction model based on input features such as gold and crude oil or the fields that are suitable for the given feature. Experimental results show that the proposed approach as able to predict whether stock price will rise or fall in the next 10 days, and the model accuracy rate can reach 67%. The results of experiments on the proposed combined CNN model with eight features, referred to as CNN8, achieved an ROI on 2019 data outside the sample period of up to 13.23%, which was superior to the 12.08% and 11.06% obtained by the models designed CNN4 (CNN with four input features) and LSTM8(LSTM with eight input features), respectively. The F1 score increased from 0.75 0.79 as a result of applying BO. The results indicate that considering the price of gold, the gold volatility index, crude oil price, and crude oil price volatility index can help obtain better ROI for companies in certain fields, such as the semiconductor, petroleum, and automotive industries, rather than merely considering financial indicators. However, for companies related to apparel, fast food, and copy processing, the input characteristics of purely financial technical indicators were found to be suitable.}
}
@article{BAI2021110047,
title = {An intelligent water level monitoring method based on SSD algorithm},
journal = {Measurement},
volume = {185},
pages = {110047},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.110047},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121009726},
author = {Ganggang Bai and Jingming Hou and Yangwei Zhang and Bingyao Li and Hao Han and Tian Wang and Reinhard Hinkelmann and Dawei Zhang and Leiqiang Guo},
keywords = {Deep learning, Water level monitoring, Convolutional Neural Network, SSD},
abstract = {Water levels are essential components for the observation and management of water resources. However, the existing water level monitoring methods either require manpower, which is inefficient, or are restricted to a certain environment. This paper proposes a novel approach that can automatically monitor, recognize and calculate the water level based on deep learning. First, a series of experiments were performed in a physical pool to obtain images from real scenes. Then, the original Single Shot MultiBox Detector (SSD) preprocessing model was trained and optimized. Subsequently, a trained and verified staff gauge detection model was obtained, which was applied to extract the staff gauge information from images. Finally, a 24-hour time series of water level changes was simulated and analyzed using photographic images principle, and the NSE and R2 were 0.98 and 0.99, respectively. These results indicate that the proposed method is more accurate in practice and can provide a relatively accurate and reliable measurement technique.}
}
@article{LEI2019379,
title = {Intelligent fault detection of high voltage line based on the Faster R-CNN},
journal = {Measurement},
volume = {138},
pages = {379-385},
year = {2019},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2019.01.072},
url = {https://www.sciencedirect.com/science/article/pii/S0263224119300831},
author = {Xusheng Lei and Zhehao Sui},
keywords = {Power line fault detection, Insulator, Bird nest, Convolution neural network, Faster R-CNN},
abstract = {To realize intelligent fault detection of high voltage line, a deep convolution neural network method based on Faster R-CNN method is proposed to locate the broken insulators and bird nests. With the region proposal network, the Faster R-CNN chooses a random region in the features of the image as the proposal region, and trains them to get the corresponding category and location for a certain component in the image. Since the internal and regional features of the image can be learned, the Faster R-CNN method transforms the problem of target classification into the problem of target detection and recognition. Based on the ResNet-101 network model, the damage of insulators and bird nests in the electric power line can be located effectively.}
}
@article{CONDOMINES2019101759,
title = {Network intrusion detection system for UAV ad-hoc communication: From methodology design to real test validation},
journal = {Ad Hoc Networks},
volume = {90},
pages = {101759},
year = {2019},
note = {Recent advances on security and privacy in Intelligent Transportation Systems},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2018.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S1570870518306541},
author = {Jean-Philippe Condomines and Ruohao Zhang and Nicolas Larrieu},
keywords = {UAV, FANET, Intrusion detection system, Spectral analysis, Robust estimator, Drone ad hoc network},
abstract = {The use of a swarm of low-cost, mission-specific drones to form a Flying Ad-hoc Network (FANET) has literally become a ’hotspot’ in the drone community. A number of studies have been conducted on how to achieve a FANET, but few have considered the security perspectives of this subject. FANET’s unique features have made it difficult to strengthen its defense against ever-changing security threats. Today, more and more FANET applications are implemented into civil airspace, but the development of FANET security has remained unsatisfactory. In this paper, we try to address this issue by proposing a new Intrusion Detection System (IDS), an hybrid method based on both spectral traffic analysis and a robust controller / observer for anomaly estimation inside UAV networks. The proposed hybrid method considers, as a preliminary step, a statistical signature of the traffic exchanged in the network. By examining the resulted signatures, the differences are used to select the accurate model for accurate estimation of that abnormal traffic. The proposed IDS design has been successfully applied to some relevant practical problems such as ad hoc networks for aerial vehicles, and the effectiveness is illustrated by using real traffic traces including Distributed Denial of Service (DDoS) attacks. Our first results show promising perspectives for Intrusion Detection System (IDS) in UAV communication networks. Indeed, different types of anomaly have been considered and they are all accurately detected by the intrusion detection process we propose in this paper. Finally, both simulation-based validation and real-time real-world based implementation of our IDS are described in this article.}
}
@article{BEVILACQUA20143,
title = {Artificial neural networks for feedback control of a human elbow hydraulic prosthesis},
journal = {Neurocomputing},
volume = {137},
pages = {3-11},
year = {2014},
note = {Advanced Intelligent Computing Theories and Methodologies},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2013.05.066},
url = {https://www.sciencedirect.com/science/article/pii/S0925231214002707},
author = {Vitoantonio Bevilacqua and Mariagrazia Dotoli and Mario Massimo Foglia and Francesco Acciani and Giacomo Tattoli and Marcello Valori},
keywords = {Human prosthesis, Forward kinematics, Artificial neural networks, Simulation, Control, Parallel mechanism},
abstract = {The paper addresses feedback control of actuated prostheses based on the Stewart platform parallel mechanism. In such a problem it is essential to apply a feasible numerical method to determine in real time the solution of the forward kinematics, which is highly nonlinear and characterized by analytical indetermination. In this paper, the forward kinematics problem for a human elbow hydraulic prosthesis developed by the research group of Polytechnic of Bari is solved using artificial neural networks as an effective and simple method to obtain in real time the solution of the problem while limiting the computational effort. We show the effectiveness of the technique by designing a PID controller that governs the arm motion thanks to the provided neural computation of the forward kinematics.}
}
@article{PARK2012498,
title = {Bird strike event monitoring in a composite UAV wing using high speed optical fiber sensing system},
journal = {Composites Science and Technology},
volume = {72},
number = {4},
pages = {498-505},
year = {2012},
issn = {0266-3538},
doi = {https://doi.org/10.1016/j.compscitech.2011.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S0266353811004349},
author = {Chan Yik Park and Byeong-Wook Jang and Jong Heon Kim and Chun-Gon Kim and Seung-Moon Jun},
keywords = {A. Composite structures, A. Fiber Bragg Grating (FBG) sensor, B. Bird impact, C. Neural network},
abstract = {In this study, high speed bird strikes on a composite structure were successfully monitored using optical fiber sensors. Four multiplexed optical fiber sensors in a single cable were surface-bonded on the leading edge of a composite UAV wing box. In order to acquire those high frequency signals, a newly developed interrogation system was used to process strain signals from four sensors simultaneously at a sampling frequency of 100kHz. Before the bird strike tests, pre-impact tests using a rubber hammer were performed to verify the suitability of the FBG signal acquisitions. The pre-test data were used in the neural network training procedures to estimate the bird strike locations. Then, the bird strike tests were accomplished using dummy projectiles and a pneumatic gun. The one-pound dummy birds, made of gelatin, hit the leading edge with a maximum speed of 201km/h. The impact signals were successfully recorded during the tests and their frequency characteristics were then analyzed. Finally, the strike locations were estimated with the neural network which was trained through the pre-tests. The average error was 33.6mm.}
}
@article{WITCZAK201765,
title = {A neural network approach to simultaneous state and actuator fault estimation under unknown input decoupling},
journal = {Neurocomputing},
volume = {250},
pages = {65-75},
year = {2017},
note = {Applications in Computational Intelligence (Selected an improved papers of the 13th International Work-Conference on Artificial Neural Networks, IWANN2015)},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2016.10.076},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217302278},
author = {Piotr Witczak and Krzysztof Patan and Marcin Witczak and Marcin Mrugalski},
keywords = {State-space neural networks, Linear parameter-varying systems, Fault estimation, State estimation, Robustness, Fault diagnosis},
abstract = {The paper deals with the problem of a neural network-based robust state and actuator fault estimator design for non-linear discrete-time systems. It starts from a review of recent developments in the area of robust estimators and observers for non-linear discrete-time systems and proposes less restrictive procedure for designing a neural network-based H∞ observer. The proposed approach guaranties a predefined disturbance attenuation level and convergence of the observer, as well as unknown input decoupling and state and actuator fault estimation. The main advantage of the design procedure is its simplicity. The paper presents an observer design procedure that is reduced to solving a set of linear matrix inequalities. The final part of the paper presents an illustrative example concerning an application of the proposed approach to the multi-tank system benchmark.}
}
@article{MIRHAJI2021106533,
title = {Fruit detection and load estimation of an orange orchard using the YOLO models through simple approaches in different imaging and illumination conditions},
journal = {Computers and Electronics in Agriculture},
volume = {191},
pages = {106533},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106533},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921005500},
author = {Hamzeh Mirhaji and Mohsen Soleymani and Abbas Asakereh and Saman {Abdanan Mehdizadeh}},
keywords = {Deep learning, Precision Agriculture (PA), Fruit load estimation, Orange fruit detection, Yield map},
abstract = {Fruit load estimation is an essential step toward Precision Agriculture (PA) as it helps growers more accurately predict market planning, worker planning, purchase of appropriate equipment and so on. Reliable and accurate estimation of fruit yield in an orchard with hundreds of trees needs automatic methods. In recent years, Deep Learning (DL) has been studied widely and applied in various fields of agriculture. Accordingly, the YOLO detection models were applied to detect and count ripe Dezful native orange in an orchard in southwestern Iran. The models were adapted through transfer learning and trained by Google Colaboratory in the RGB images to detect and count orange fruits. Models performance and accuracy of yield estimation for an orchard with 1115 trees were examined. The process was conducted in 3 steps, including training and testing the different versions of the YOLO models by creating an image dataset of orange trees in different illumination conditions, evaluating the models on 100 sample trees, and finally extracting the yield variation map of the orchard after detecting and counting the oranges on images taken from all the trees in the orchard. The precision, recall, F1-score and mAP of the YOLO-V4 as the best model for orange detection over the test images were 91.23%, 92.8%, 92%, and 90.8%, respectively. The overall performance of the models in nighttime and daytime imaging was not significantly different. The YOLO-V4 model was chosen to use for yield estimation in the orchard. The promising results show that the YOLO models can effectively provide researchers and agricultural activists with a simple and practical method for detecting and estimating the yield of orange fruits in an orchard. Significant differences were observed in yield estimation for two-side and four-side imaging. Accordingly, a combined imaging method including two-side and four-side imaging was proposed for thin and dense canopy, respectively. The map of fruit yield changes showed the spatial distribution of tree yield with a +9.19% error.}
}
@article{MA2019132,
title = {A novel autonomous aerial refueling drogue detection and pose estimation method based on monocular vision},
journal = {Measurement},
volume = {136},
pages = {132-142},
year = {2019},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2018.12.060},
url = {https://www.sciencedirect.com/science/article/pii/S0263224118312053},
author = {Yuebo Ma and Rujin Zhao and Enhai Liu and Zhuang Zhang and Kun Yan},
keywords = {Autonomous aerial refueling, Drogue detection, Drogue pose estimate, Monocular machine vision},
abstract = {This paper proposes a novel drogue measurement method based on monocular vision for autonomous aerial refueling task in unmanned aerial vehicles (UAV). Firstly, to solve the problem of detecting the drogue without artificial features, an arc-level drogue detection and recognition algorithm is proposed. Secondly, a pose estimation algorithm based on the structural features of the drogue is proposed measuring the pose of the drogue’s 3D space. Finally, the proposed method is proved to be valid according to the real air refueling task data set, ground acquisition data, and simulation experiments.}
}
@article{VALLEJO2020103243,
title = {Multi-agent architecture for information retrieval and intelligent monitoring by UAVs in known environments affected by catastrophes},
journal = {Engineering Applications of Artificial Intelligence},
volume = {87},
pages = {103243},
year = {2020},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2019.103243},
url = {https://www.sciencedirect.com/science/article/pii/S0952197619302258},
author = {D. Vallejo and J.J. Castro-Schez and C. Glez-Morcillo and J. Albusac},
keywords = {Multi-agent architecture, Smart UAVs, Intelligent monitoring, Expert Systems, Crisis Management},
abstract = {The consequences of natural or man-made catastrophes can be devastating. To minimize its impact, it is crucial to carry out a rapid analysis of the affected environment in the moments after they occur, especially from the perspective of alert notification or crisis management. In this context, the use of UAVs, understood as the technological basis on which intelligent systems capable of providing support to rescue teams is built, has positively contributed to face this challenge. In this article the design of a multi-agent architecture which enables the deployment of systems made up of intelligent agents that can monitor environments affected by a catastrophe and provide support to human staff in the decision-making process is proposed. These environments, known in advance, are characterized through a set of points of interests that are critical from the point of view of aerial surveillance and monitoring. To conduct an intelligent information analysis, a formal model of normality analysis is employed, which makes possible the definition of surveillance components. These represent the knowledge bases of the agents responsible for monitoring environments. Likewise, the architecture envisages communication and cooperation mechanisms between the different agents, as the basis for fusing information to assess the overall level of risk of the monitored environment. A case study is presented in which the spread of toxic smoke in an industrial complex which has just suffered a hypothetical earthquake is monitored.}
}
@article{XU2021108204,
title = {A comprehensive yield evaluation indicator based on an improved fuzzy comprehensive evaluation method and hyperspectral data},
journal = {Field Crops Research},
volume = {270},
pages = {108204},
year = {2021},
issn = {0378-4290},
doi = {https://doi.org/10.1016/j.fcr.2021.108204},
url = {https://www.sciencedirect.com/science/article/pii/S0378429021001507},
author = {Xiaobin Xu and Chenwei Nie and Xiuliang Jin and Zhenhai Li and Hongchun Zhu and Haigang Xu and Jianwen Wang and Yu Zhao and Haikuan Feng},
keywords = {Wheat growth status and trend (GST), Yield, Comprehensive yield evaluation indicator (CYEI), Fuzzy comprehensive evaluation},
abstract = {The accurate and timely estimation of winter-wheat yield at the field and regional scales is critical to developing agricultural management strategies and reducing the effect of changes in environmental conditions on crop yield. Growth status and trend (GST) monitoring has been widely applied to estimate agronomic parameters using remote sensing methods. Many studies have employed GST monitoring, however, most of them were based on a single agronomic parameter and can therefore only represent one-sided or local GST information. Additionally, each agronomic parameter is interactive. Meanwhile, little studies have systemically combined multiple agronomic parameters into one comprehensive indicator to estimate crop yield using remote sensing data. Thus, the objectives of the current research were to build a comprehensive yield evaluation indicator (CYEI) using the improved fuzzy comprehensive evaluation (FCE) method and evaluate the performance of CYEI to monitor GST and estimate yield. The results showed that the CYEI can fully reflect the information of the leaf area index, leaf biomass, leaf water content, and leaf nitrogen content. Compared with various agronomic parameters, the CYEI based on the improved FCE method was more closely correlated with the yield (the R2 values of the validation set were 0.63, 0.69, and 0.63 at the booting stage, anthesis stage, and milk development stage.). The CYEI was estimated using a linear model constructed using the optimal VIs, and the results for the three growth stages achieved a higher precision (R2 = 0.74, 0.74, and 0.68 for the booting, anthesis, and milk development stages, respectively) than the traditional single agronomic parameter. The CYEI and Bayesian information criterion were then used to select VIs and then build a partial least squares regression model to estimate the yield. The estimation accuracy was found to be satisfactory, with R2 values of 0.55, 0.64, and 0.66 at the booting, anthesis, and milk development stages, respectively. Finally, a more intuitive image-scale yield monitoring method was obtained based on unmanned aerial vehicle remote sensing hyperspectral imagery. In the future, the proposed method can be used to obtain wheat growth information and provide a new prediction indicator to better estimate yield in precision agriculture.}
}
@article{CLARK2012232,
title = {Flight test results for UAVs using boid guidance algorithms},
journal = {Procedia Computer Science},
volume = {8},
pages = {232-238},
year = {2012},
note = {Conference on Systems Engineering Research},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2012.01.048},
url = {https://www.sciencedirect.com/science/article/pii/S187705091200049X},
author = {Jason B. Clark and David R. Jacques},
keywords = {Agents, swarm guidance, multi-vehicle control, boid},
abstract = {A critical technology for operating groups of Uninhabited Aerial Vehicles (UAVs) is distributed guidance. Distributed guidance allows an operator to command several vehicles at the same time, reduces operator workload, and adds redundancy to the system. Some of the leading software candidates for achieving distributed guidance are known as Boid Guidance Algorithms (BGAs), which are agent-based techniques relying on the interactions of simple behaviors. Flight tests are crucial to the advancement of flight technologies such as BGAs, and this was identified as an important area for development. This paper presents the results from the 2005 flight tests of BGAs at NASA Dryden Flight Research Center with two RnR Products’ APV-3 UAVs employing CloudCap Technology's Piccolo autopilot system. Major challenges in these flight tests include the use of a waypoint-following system, limited computation resources, and management of safety procedures. The conclusions of this work include the need for using a path-following platform and completion of a full system optimization. This work is an important step in the development of a deployable distributed guidance system.}
}
@article{CARLUCHO2019292,
title = {Double Q-PID algorithm for mobile robot control},
journal = {Expert Systems with Applications},
volume = {137},
pages = {292-307},
year = {2019},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.06.066},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419304749},
author = {Ignacio Carlucho and Mariano {De Paula} and Gerardo G. Acosta},
keywords = {Reinforcement learning, Double -learning, Incremental learning, Double Q-PID, Mobile robots, Multi-platforms},
abstract = {Many expert systems have been developed for self-adaptive PID controllers of mobile robots. However, the high computational requirements of the expert systems layers, developed for the tuning of the PID controllers, still require previous expert knowledge and high efficiency in algorithmic and software execution for real-time applications. To address these problems, in this paper we propose an expert agent-based system, based on a reinforcement learning agent, for self-adapting multiple low-level PID controllers in mobile robots. For the formulation of the artificial expert agent, we develop an incremental model-free algorithm version of the double Q-Learning algorithm for fast on-line adaptation of multiple low-level PID controllers. Fast learning and high on-line adaptability of the artificial expert agent is achieved by means of a proposed incremental active-learning exploration-exploitation procedure, for a non-uniform state space exploration, along with an experience replay mechanism for multiple value functions updates in the double Q-learning algorithm. A comprehensive comparative simulation study and experiments in a real mobile robot demonstrate the high performance of the proposed algorithm for a real-time simultaneous tuning of multiple adaptive low-level PID controllers of mobile robots in real world conditions.}
}
@article{SMITH2021107122,
title = {Constructing vertical measurement logs using UAV-based photogrammetry: Applications for multiscale high-resolution analysis of coarse-grained volcaniclastic stratigraphy},
journal = {Journal of Volcanology and Geothermal Research},
volume = {409},
pages = {107122},
year = {2021},
issn = {0377-0273},
doi = {https://doi.org/10.1016/j.jvolgeores.2020.107122},
url = {https://www.sciencedirect.com/science/article/pii/S0377027320303449},
author = {Zachary D. Smith and David J. Maxwell},
keywords = {UAV, Photogrammetry, Grain-size measurements, GIS, Structure from Motion, Remote Sensing},
abstract = {Volcaniclastic stratigraphy can be difficult to map and describe due to its complex nature. However, such stratigraphy preserves information about fluctuations in volcanic activity and sedimentation and is vital to understanding volcanic systems. Uncrewed aerial vehicle (UAV) based analysis of volcanic stratigraphy can enhance mapping and analysis, especially on vertical surfaces where outcrop exposure is greatest. Here we present a method for using small UAVs to produce vertical grain size and bedding measurement logs, or quantitative stratigraphic columns, of vertical volcaniclastic stratigraphy. We demonstrate the range of high-accuracy measurements and parameters that can be collected for building measurement logs using consumer grade UAVs through a case study in the Marysvale volcanic field where we collected 34,422 grain measurements from 21 individual units. The purpose of producing such measurement logs is to enhance lithofacies analysis through the use of large quantitative datasets and improve the reproducibility of data reporting. Whereas descriptions of volcaniclastic units such as those describing grading are often reported qualitatively, we describe methods for calculating numerical parameters for enhanced lithologic analysis including grain size, grading, clast to matrix ratios, and shape characteristics. The methods described in this paper can enhance field data acquisition, mapping, and quantitative analysis of volcaniclastic deposits and are applicable to a wide range of other geologic settings where coarse-grained clastic sedimentary deposits exist.}
}
@article{NETO2019213,
title = {Control of air-ground convoy subject to communication time delay},
journal = {Computers & Electrical Engineering},
volume = {76},
pages = {213-224},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618319451},
author = {Armando Alves Neto and Leonardo A. Mozelli and Fernando O. Souza},
keywords = {Autonomous convoy, Heterogeneous robots, Time-delay communication, Ground vehicles, Aerial vehicles, Cooperative robotics},
abstract = {The problem associated with line formation (convoy) control among a team of aerial and ground vehicles is addressed by considering the fact that the vehicles share information with each other via communication channels that can be corrupted because of time delay. Among other results, we present rules for designing a decentralized control law that provides convoy stability, ensuring null formation error at steady state under the condition of constant speed, for the leader, compensating time-delay effects on the communication flow among the following vehicles. The results have been verified for convoy designs based on “look-ahead” topologies, in which each agent knows only the states of the preceding vehicles in the formation. The effectiveness of the proposed rules is finally illustrated by a simulation experiment involving a team of Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs), executing a scouting mission.}
}
@article{KIM2022104136,
title = {Automated concrete crack evaluation using stereo vision with two different focal lengths},
journal = {Automation in Construction},
volume = {135},
pages = {104136},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104136},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522000097},
author = {Hyunjun Kim and Sung-Han Sim and Billie F. Spencer},
keywords = {Computer vision, Concrete crack, Crack evaluation, Deep learning, Stereo vision},
abstract = {Surface cracks in concrete structures are an important indicator of the soundness of a structure. Stereo vision, consisting of two identical cameras, has been suggested to quantify crack characteristics using derived depth information. However, because high measurement resolution is required, zoom lenses are often used, making simultaneously crack localization and characterization difficult. This study presents a framework for the use of stereo vision employing one wide-angle lens and one telephoto lens, enabling accurate crack quantification as well as efficient 3D reconstruction. Furthermore, a robust depth estimation strategy is proposed for planar surfaces, such as are found in most concrete bridges. The performance of the proposed approach is field validated using an in-service concrete bridge. The 3D reconstruction model generated by a set of wide-angle images, including crack information extracted from the telephoto images using deep learning, can enable the improved inspection of concrete structures.}
}
@article{ZEINALI2016868,
title = {Structural Impairment Detection Using Deep Counter Propagation Neural Networks},
journal = {Procedia Engineering},
volume = {145},
pages = {868-875},
year = {2016},
note = {ICSDEC 2016 – Integrating Data Science, Construction and Sustainability},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2016.04.113},
url = {https://www.sciencedirect.com/science/article/pii/S1877705816301199},
author = {Yasha Zeinali and Brett Story},
keywords = {Structural Impairment Detection Systems, Deep Counter Propagation Neural Networks, Truss Structures ;},
abstract = {Structural systems may deteriorate under normal operating conditions during their service life. In many situations, damage is not easily observed through traditional visual inspection techniques. The need for detecting subtle structural damage and assessing the level of impairment presents opportunities to develop innovative solutions beyond typical inspections. One method for monitoring and evaluating structures is to measure responses and assess the impairment condition of structures using those responses. This paper presents an inverse static assessment method for evaluating structures using this concept. Solutions to such an inverse problem are difficult; data streams from structural measurements may be noisy and sometimes incomplete. Additionally, finding an exact, explicit, closed-form solution to this problem is often impossible. This paper details a neural network approach to solve the inverse impairment detection problem. The approach presented utilizes a deep counter propagation neural network that is capable of modeling input-output functional relations even when mathematically explicit formulas are unavailable or data is noisy and/or corrupt.}
}
@article{KENNEDY2020111694,
title = {Assessment of Landsat-based terricolous macrolichen cover retrieval and change analysis over caribou ranges in northern Canada and Alaska},
journal = {Remote Sensing of Environment},
volume = {240},
pages = {111694},
year = {2020},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2020.111694},
url = {https://www.sciencedirect.com/science/article/pii/S0034425720300638},
author = {Blair Kennedy and Darren Pouliot and Micheline Manseau and Robert Fraser and Jason Duffe and Jon Pasher and Wenjun Chen and Ian Olthof},
keywords = {Machine learning, Lichen, Landsat, North, Canada, Alaska},
abstract = {Terricolous macrolichens are an important food source for caribou (Rangifer tarandus) and can greatly influence their movement, distribution and demography over time. Mapping the spatial distribution and cover of macrolichens with remote sensing can serve as an important approach for assessing the impact of disturbances (e.g. fire, grazing, trampling) on lichen cover at the landscape scale and for monitoring post-disturbance rates of recovery. Previous remote sensing-based efforts to retrieve the distribution and abundance of lichen have been restricted to particular regions and thus are not indicative of the potential for large extent mapping and monitoring. In this study, we assessed the effectiveness of machine learning methods for retrieving lichen cover and change across different regions in northern Canada and Alaska using Landsat-5 images, topographic and climate data. Global and regional-scale models were evaluated to assess whether regionally specific analyses would improve performance. Of the models tested, the deep neural network was the most accurate for predicting lichen cover (model efficiency (ME) = 0.58, mean absolute error (MAE) < 7%). For the regional analysis, the performance was the best in north-central Canada (ME = 0.56, MAE = 8%) and the worst in north-eastern Canada (ME = 0.22, MAE < 4%) due to lower lichen cover, more exposed ground, and reduced sample quality and distribution. Analysis of trend-based change detection from 1984 to 2011 in the three regional test areas showed the expected directional response with declining lichen cover in north-western Canada in response to climate-induced shrub expansion, slow recovery to wildfire in north-central Canada, and declining lichen cover in north-eastern Canada related to caribou foraging/trampling and shrub expansion.}
}
@article{SADDIK2021100506,
title = {Real-time evaluation of different indexes in precision agriculture using a heterogeneous embedded system},
journal = {Sustainable Computing: Informatics and Systems},
volume = {30},
pages = {100506},
year = {2021},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2020.100506},
url = {https://www.sciencedirect.com/science/article/pii/S2210537920302286},
author = {Amine Saddik and Rachid Latif and Mohamed Elhoseny and Abdelhafid {El Ouardi}},
keywords = {Precision agriculture, NDVI, NDWI, Real-time, Heterogeneous system, Hardware/software co-design, OpenMP},
abstract = {In this work, we present a real-time embedded implementation of an algorithm dedicated to monitoring agricultural fields. This algorithm is based on normalized indices, such as the Normalized Difference Vegetation Index (NDVI) and the Normalized Difference Water Index (NDWI). The problem of most algorithms in this context is real-time processing, especially when we talk about applications that require time precision. The proposed implementation is based on the application of a Hardware/Software Co-design approach. For the embedded platform, we used the heterogeneous system contains CPU and GPU type XU4 and TX1. In this context, we used the parallel programming language OpenMP to have an optimal embedded implementation. The results showed that we could process 66 images/s using a desktop, 20 images/s in the XU4, and 17 images/s for TX1.}
}
@article{ZHAO201822,
title = {A robust extreme learning machine for modeling a small-scale turbojet engine},
journal = {Applied Energy},
volume = {218},
pages = {22-35},
year = {2018},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2018.02.175},
url = {https://www.sciencedirect.com/science/article/pii/S0306261918303088},
author = {Yong-Ping Zhao and Qian-Kun Hu and Jian-Guo Xu and Bing Li and Gong Huang and Ying-Ting Pan},
keywords = {Extreme learning machine, Small-scale turbojet engine, System modeling, Machine learning},
abstract = {In this paper, a robust extreme learning machine is proposed. In comparison with the original extreme learning machine and the regularized extreme learning machine, this robust algorithm minimizes both the mean and variance of modeling errors in the objective function to overcome the bias-variance dilemma. As a result, its generalization performance and robustness are enhanced, and these merits are further proved theoretically. In addition, this proposed algorithm can keep the same computational efficiency as the original extreme learning machine and the regularized extreme learning machine. Then, several benchmark data sets are used to test the effectiveness and soundness of the proposed algorithm. Finally, it is employed to model a real small-scale turbojet engine. This engine is fit well. Especially, on the idle phase, where the signal-to-noise ratio is low and it is very hard to model, the proposed algorithm performs well and its robustness is sufficiently showcased. All in all, the proposed algorithm provides a candidate technique for modeling real systems.}
}
@article{MANSOURI20181,
title = {2D visual area coverage and path planning coupled with camera footprints},
journal = {Control Engineering Practice},
volume = {75},
pages = {1-16},
year = {2018},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2018.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S0967066118300546},
author = {Sina Sharif Mansouri and Christoforos Kanellakis and George Georgoulas and Dariusz Kominiak and Thomas Gustafsson and George Nikolakopoulos},
keywords = {Area coverage, Path planning, Visual inspection, UAVs, Camera footprint},
abstract = {Unmanned Aerial Vehicles (UAVs) equipped with visual sensors are widely used in area coverage missions. Guaranteeing full coverage coupled with camera footprint is one of the most challenging tasks, thus, in the presented novel approach a coverage path planner for the inspection of 2D areas is established, a 3 Degree of Freedom (DoF) camera movement is considered and the shortest path from the taking off to the landing station is generated, while covering the target area. The proposed scheme requires a priori information about the boundaries of the target area and generates the paths in an offline process. The efficacy and the overall performance of the proposed method has been experimentally evaluated in multiple indoor inspection experiments with convex and non convex areas. Furthermore, the image streams collected during the coverage tasks were post-processed using image stitching for obtaining a single overview of the covered scene.}
}
@article{YU2021107875,
title = {Online and energy-efficient task-processing for distributed edge networks},
journal = {Computer Networks},
volume = {193},
pages = {107875},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.107875},
url = {https://www.sciencedirect.com/science/article/pii/S138912862100044X},
author = {Li Yu and Zongpeng Li and Jiangchuan Liu and Ruiting Zhou},
keywords = {Online learning, Internet of Things, Task offloading, Energy efficiency, Mobile edge computing},
abstract = {User equipment produces a series of tasks that are processed locally or remotely, falling into three categories: (i) local computing only, (ii) a fraction of the task is computed locally and the remaining task unprocessed is offloaded for remote computation, and (iii) the entire task is offloaded. Each case has attracted substantial attention in recent studies, where a delay-constrained non-linear optimization problem is often formulated. The solutions employed are either based on Lagrange duality, heuristic search, or dynamic programming. To our knowledge, there is no unifying task-processing orchestrator that is an online tailored solver for learning the model-free problems, encapsulating the three cases above. We fill this gap and present the first attempt on an innovative actor-critic reinforcement learning approach in consideration of the energy-efficiency, to compute the asymptotically optimal solutions via decomposing the comprehensive optimization into sub-problems. Rigorous theoretical analyses and experience-driven simulations demonstrate significant advantages over the benchmark approaches, in terms of task-processing delay, power efficiency, and convergence time.}
}
@article{WANG2018232,
title = {A GNSS/INS Integrated Navigation Algorithm Based on Kalman Filter},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {17},
pages = {232-237},
year = {2018},
note = {6th IFAC Conference on Bio-Robotics BIOROBOTICS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.08.151},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318312692},
author = {Guangqi Wang and Yu Han and Jian Chen and Shubo Wang and Zichao Zhang and Nannan Du and Yongjun Zheng},
keywords = {GNSS/INS integrated navigation, feedback emendation, centralized filter, loose coupling, discrete Kalman filter},
abstract = {GNSS/INS (Global Navigation Satellite System/ Inertial Navigation System) integrated navigation system can be applied to agricultural UAV (unmanned aerial vehicle) with the following two requirements: (1) After working for a long time, the precision of navigation parameters will not decrease; (2) The integrated navigation algorithm is simple and reliable, which requires low processing capacity for airborne chips. Aiming at satisfying above two requirements, firstly, the centralized Kalman filter method is used to fuse GPS (Global Position System) and INS systems under the premise of loose coupling. The combination is compact, which greatly reduces the amount of computing in the system and simplifies the complexity of the system. Secondly, the error of INS system navigation parameters estimated by discrete Kalman filter algorithm is fed back into INS system by feedback emendation method, which overcomes the problem that the navigation accuracy will decline after long time work. Finally, the simulations of velocity and position error after filtering are demonstrated respectively. The stability and effectiveness of proposed algorithms are verified.}
}
@article{ANDREW2021106133,
title = {Visual identification of individual Holstein-Friesian cattle via deep metric learning},
journal = {Computers and Electronics in Agriculture},
volume = {185},
pages = {106133},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106133},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921001514},
author = {William Andrew and Jing Gao and Siobhan Mullan and Neill Campbell and Andrew W. Dowsey and Tilo Burghardt},
keywords = {Automated agriculture, Computer vision, Deep learning, Metric learning, Animal biometrics},
abstract = {Holstein-Friesian cattle exhibit individually-characteristic black and white coat patterns visually akin to those arising from Turing’s reaction-diffusion systems. This work takes advantage of these natural markings in order to automate visual detection and biometric identification of individual Holstein-Friesians via convolutional neural networks and deep metric learning techniques. Existing approaches rely on markings, tags or wearables with a variety of maintenance requirements, whereas we present a totally hands-off method for the automated detection, localisation, and identification of individual animals from overhead imaging in an open herd setting, i.e. where new additions to the herd are identified without re-training. We find that deep metric learning systems show strong performance even when many cattle unseen during system training are to be identified and re-identified – achieving 93.8% accuracy when trained on just half of the population. This work paves the way for facilitating the non-intrusive monitoring of cattle applicable to precision farming and surveillance for automated productivity, health and welfare monitoring, and to veterinary research such as behavioural analysis, disease outbreak tracing, and more. Key parts of the source code, network weights and underpinning datasets are available publicly (OpenCows2020).}
}
@article{CAO2019206,
title = {Pedestrian detection with unsupervised multispectral feature learning using deep neural networks},
journal = {Information Fusion},
volume = {46},
pages = {206-217},
year = {2019},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2018.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S1566253517305948},
author = {Yanpeng Cao and Dayan Guan and Weilin Huang and Jiangxin Yang and Yanlong Cao and Yu Qiao},
keywords = {Multispectral pedestrian detection, Deep neural networks, Auto-annotation, Semantic feature fusion, Unsupervised learning},
abstract = {Multispectral pedestrian detection is an important functionality in various computer vision applications such as robot sensing, security surveillance, and autonomous driving. In this paper, our motivation is to automatically adapt a generic pedestrian detector trained in a visible source domain to a new multispectral target domain without any manual annotation efforts. For this purpose, we present an auto-annotation framework to iteratively label pedestrian instances in visible and thermal channels by leveraging the complementary information of multispectral data. A distinct target is temporally tracked through image sequences to generate more confident labels. The predicted pedestrians in two individual channels are merged through a label fusion scheme to generate multispectral pedestrian annotations. The obtained annotations are then fed to a two-stream region proposal network (TS-RPN) to learn the multispectral features on both visible and thermal images for robust pedestrian detection. Experimental results on KAIST multispectral dataset show that our proposed unsupervised approach using auto-annotated training data can achieve performance comparable to state-of-the-art deep neural networks (DNNs) based pedestrian detectors trained using manual labels.}
}
@article{BEMIS2014163,
title = {Ground-based and UAV-Based photogrammetry: A multi-scale, high-resolution mapping tool for structural geology and paleoseismology},
journal = {Journal of Structural Geology},
volume = {69},
pages = {163-178},
year = {2014},
issn = {0191-8141},
doi = {https://doi.org/10.1016/j.jsg.2014.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0191814114002429},
author = {Sean P. Bemis and Steven Micklethwaite and Darren Turner and Mike R. James and Sinan Akciz and Sam T. Thiele and Hasnain Ali Bangash},
keywords = {Photogrammetry, Structural geology, Neotectonics, 3D surface modelling, UAVs, Structure-from-Motion},
abstract = {This contribution reviews the use of modern 3D photo-based surface reconstruction techniques for high fidelity surveys of trenches, rock exposures and hand specimens to highlight their potential for paleoseismology and structural geology. We outline the general approach to data acquisition and processing using ground-based photographs acquired from standard DSLR cameras, and illustrate the use of similar processing approaches on imagery from Unmanned Aerial Vehicles (UAVs). It is shown that digital map and trench data can be acquired at ultra-high resolution and in much shorter time intervals than would be normally achievable through conventional grid mapping. The resulting point clouds and textured models are inherently multidimensional (x, y, z, point orientation, colour, texture), archival and easily transformed into orthorectified photomosaics or digital elevation models (DEMs). We provide some examples for the use of such techniques in structural geology and paleoseismology while pointing the interested reader to free and commercial software packages for data processing, visualization and 3D interpretation. Photogrammetric models serve to act as an ideal electronic repository for critical outcrops and observations, similar to the electronic lab book approach employed in the biosciences. This paper also highlights future possibilities for rapid semi-automatic to automatic interpretation of the data and advances in technology.}
}
@article{BAYLISS2020106280,
title = {A learnheuristic approach for the team orienteering problem with aerial drone motion constraints},
journal = {Applied Soft Computing},
volume = {92},
pages = {106280},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106280},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620302209},
author = {Christopher Bayliss and Angel A. Juan and Christine S.M. Currie and Javier Panadero},
keywords = {Team orienteering problem, Metaheuristics, Machine learning, Learnheuristics, Aerial drones, Route-dependent edge times},
abstract = {This work proposes a learnheuristic approach (combination of heuristics with machine learning) to solve an aerial-drone team orienteering problem. The goal is to maximise the total reward collected from information gathering or surveillance observations of a set of known targets within a fixed amount of time. The aerial drone team orienteering problem has the complicating feature that the travel times between targets depend on a drone’s flight path between previous targets. This path-dependence is caused by the aerial surveillance drones flying under the influence of air-resistance, gravity, and the laws of motion. Sharp turns slow drones down and the angle of ascent and air-resistance influence the acceleration a drone is capable of. The route dependence of inter-target travel times motivates the consideration of a learnheuristic approach, in which the prediction of travel times is outsourced to a machine learning algorithm. This work proposes an instance-based learning algorithm with interpolated predictions as the learning module. We show that a learnheuristic approach can lead to higher quality solutions in a shorter amount of time than those generated from an equivalent metaheuristic algorithm, an effect attributed to the search-diversity enhancing consequence of the online learning process.}
}
@article{DHUNGANA2020102029,
title = {Peer-to-peer energy sharing in mobile networks: Applications, challenges, and open problems},
journal = {Ad Hoc Networks},
volume = {97},
pages = {102029},
year = {2020},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2019.102029},
url = {https://www.sciencedirect.com/science/article/pii/S1570870519306018},
author = {Aashish Dhungana and Eyuphan Bulut},
keywords = {Mobile social networks, Wireless sensor networks, Vehicular ad hoc networks, Delay tolerant networks, Unmanned aerial vehicles, Peer-to-peer, Energy sharing, Wireless power transfer},
abstract = {Energy is a scarce resource in mobile wireless networks that consist of devices mainly powered by their batteries. Providing energy ubiquitously to these devices for making them functional for a long time is a challenging task. With the advent of energy sharing techniques, either by wired or wireless mediums, it is possible to extend the lifetime of such networks by utilizing the energy from other energy sources (e.g., chargers, other devices) within the network. In this paper, we explore the utilization of peer-to-peer energy sharing in various applications of mobile networks that consist of agents from low-power devices such as sensors to high-power ones such as electric vehicles. We provide an overview of the current research directions and developments of new protocols and algorithms that exploit the energy sharing techniques to solve the scarce energy problem in mobile networks. For each mobile networking domain, we highlight the specific challenges and describe the approaches followed to address them under various research problems. We also discuss open problems yet to be solved in each specific application.}
}
@article{SHI2020183,
title = {Adaptive neuro-fuzzy PID controller based on twin delayed deep deterministic policy gradient algorithm},
journal = {Neurocomputing},
volume = {402},
pages = {183-194},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.03.063},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220304367},
author = {Qian Shi and Hak-Keung Lam and Chengbin Xuan and Ming Chen},
keywords = {Twin delayed deep deterministic policy gradient algorithm, Reinforcement learning, Fuzzy PID controller, Cart-pole system},
abstract = {This paper presents an adaptive neuro-fuzzy PID controller based on twin delayed deep deterministic policy gradient (TD3) algorithm for nonlinear systems. In this approach, the observation of the environment is embedded with information of a multiple input single output (MISO) fuzzy inference system (FIS) and have a specially defined fuzzy PID controller in neural network (NN) formation acting as the actor in the TD3 algorithm, which achieves automatic tuning of gains of fuzzy PID controller. From the control perspective, the controller combines the merits of both FIS and PID controller and utilizes reinforcement learning algorithm for optimizing parameters. From the reinforcement learning point of view, embedding the prior knowledge into the fuzzy PID controller incorporated in the actor network helps reduce the learning difficulty in the training process. The proposed method was tested on the cart-pole system in simulation environment with comparison of a linear PID controller, which demonstrates the robustness and generalization of the proposed approach.}
}
@article{LIU2021119505,
title = {Hyperspectral evidence of early-stage pine shoot beetle attack in Yunnan pine},
journal = {Forest Ecology and Management},
volume = {497},
pages = {119505},
year = {2021},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2021.119505},
url = {https://www.sciencedirect.com/science/article/pii/S0378112721005958},
author = {Yujie Liu and Zhongyi Zhan and Lili Ren and Sangzi Ze and Linfeng Yu and Qi Jiang and Youqing Luo},
keywords = {Pine shoot beetle, Shoot-feeding phase, Hyperspectral analysis, Physiological parameters, Random forest},
abstract = {Pine shoot beetle (PSB, Tomicus spp.) outbreaks cause widespread Yunnan pine (Pinus yunnanensis Franch) mortality in southwestern China. Early identification of PSB attacks could help forest managers mitigate the infestation before it turns into an outbreak. However, the subtle spectral changes and complex process of PSB-induced crown discoloration make the remote sensing approach difficult. This study employed a manipulated insect infestation experiment to reveal suitable monitoring indicators. Healthy Yunnan pine crowns were infested with PSB adults at different preset densities (light, moderate, and severe) using the bagging method. The crown damage parameters, physiological properties, and corresponding spectral data were systematically measured in time series. Partial least squares regression (PLSR) was used to retrieve crown chlorophylla+b (Cab) and relative water content (RWC) via band reflectance. Random forest (RF) was used to determine the optimum spectral variables capable of capturing dynamic variations in crown shoot damage ratio (SDR). Results showed that (1) after four weeks’ PSB shoot feeding attack, SDR reached saturated (26%-50%) for all damage levels, indicating a crown discoloration “switch point”. (2) A continuous decline was found in Cab and RWC at both shoot and crown levels during the whole infestation process, and the crown level decrease was smaller than the shoot level due to crown heterogeneous discoloration. (3) For PLSR retrieving crown Cab and RWC, estimation accuracy of healthy crowns could reach R2 = 0.70, RMSEcv = 14.60 mg/m2 for Cab, and R2 = 0.82, RMSEcv = 1.25% for RWC, respectively. However, PSB early attack impacted these retrieval accuracies. (4) Spectral differences were evident in the visible region (530–600 nm) and near-infrared (NIR) plateau (780–1300 nm) among the preset damage levels. Significant differences in spectral variables (AMP, CI, OSAVI, RD, and SR) were observed between healthy and moderately damaged crowns. (5) In RF modeling, the importance of spectral variables for SDR estimation varied throughout the shoot feeding process. OSAVI, CI, MSI, PSRI, and SR2 were the top indicators that were suitable for identifying SDR ranging from 5% to 50%. SDR could be estimated with an accuracy of R2 = 0.71, RMSEcv = 8.92%, after 4 weeks’ infestation. Simultaneously, with the RF model, 4 preset damage levels could be differentiated with an out-of-bag error of 14.94% and a kappa coefficient of 0.8835. In conclusion, this study mainly examined the physiological and spectral signatures of PSB early attacked crowns, and provided optimum spectral variables and models which will further help unmanned aerial vehicle (UAV) and satellite remote sensing identify PSB infestation at the early stages.}
}
@article{BRAUN2020103210,
title = {Improving progress monitoring by fusing point clouds, semantic data and computer vision},
journal = {Automation in Construction},
volume = {116},
pages = {103210},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103210},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519309975},
author = {Alex Braun and Sebastian Tuttas and André Borrmann and Uwe Stilla},
keywords = {Construction progress monitoring, BIM, Point clouds, Semantic and temporal knowledge, Deep learning},
abstract = {Automated construction-progress monitoring enables the required transparency for improved process control, and is thus being increasingly adopted by the construction industry. Many recent approaches use Scan-to/vs-BIM methods for capturing the as-built status of large construction sites. However, they often lack accuracy or are incomplete due to occluded elements and reconstruction inaccuracies. To overcome these limitations and exploit the rich project knowledge from the design phase, the authors propose taking advantage of the extensive geometric-semantic information provided by Building Information Models. In particular, valuable knowledge on the construction processes is inferred from BIM objects and their precedence relationships. SfM methods enable 3D building elements to be located and projected into the picture's 2D coordinate system. On this basis, the paper presents a machine-learning-based object-detection approach that supports progress monitoring by verifying element categories compared to the expected data from the digital model. The results show that, depending on the type of construction and the type of occlusions, the detection of built elements can rise by up to 50% compared to an SfM-based, purely geometric as-planned vs. as-built comparison.}
}
@article{MAMMARELLA2021,
title = {Cooperation of unmanned systems for agricultural applications: A theoretical framework},
journal = {Biosystems Engineering},
year = {2021},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2021.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S1537511021002750},
author = {Martina Mammarella and Lorenzo Comba and Alessandro Biglia and Fabrizio Dabbene and Paolo Gay},
keywords = {Precision farming, Unmanned vehicles cooperation, Unmanned Aerial Vehicles, Unmanned Ground Vehicles, Control logic, Path and mission planning},
abstract = {Agriculture 4.0 comprises a set of technologies that combines sensors, information systems, enhanced machinery, and informed management with the objective of optimising production by accounting for variabilities and uncertainties within agricultural systems. Autonomous ground and aerial vehicles can lead to favourable improvements in management by performing in-field tasks in a time-effective way. In particular, greater benefits can be achieved by allowing cooperation and collaborative action among unmanned vehicles, both aerial and ground, to perform in-field operations in precise and time-effective ways. In this work, the preliminary and crucial step of analysing and understanding the technical and methodological challenges concerning the main problems involved is performed. An overview of the agricultural scenarios that can benefit from using collaborative machines and the corresponding cooperative schemes typically adopted in this framework are presented. A collection of kinematic and dynamic models for different categories of autonomous aerial and ground vehicles is provided, which represents a crucial step in understanding the vehicles behaviour when full autonomy is desired. Last, a collection of the state-of-the-art technologies for the autonomous guidance of drones is provided, summarising their peculiar characteristics, and highlighting their advantages and shortcomings with a specific focus on the Agriculture 4.0 framework. A companion paper reports the application of some of these techniques in a complete case study in sloped vineyards, applying the proposed multi-phase collaborative scheme introduced here.}
}
@article{TOPALOV201094,
title = {Neuro-adaptive Approach for Controlling a Quad-rotor Helicopter Using Sliding Mode Learning Algorithm},
journal = {IFAC Proceedings Volumes},
volume = {43},
number = {10},
pages = {94-99},
year = {2010},
note = {10th IFAC Workshop on the Adaptation and Learning in Control and Signal Processing},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20100826-3-TR-4015.00020},
url = {https://www.sciencedirect.com/science/article/pii/S1474667015323466},
author = {Andon V. Topalov and Nikola G. Shakev and Okyay Kaynak and Erdal Kayacan},
keywords = {unmanned aerial vehicles, helicopter control, neural networks, variable structure systems, adaptive systems},
abstract = {The interest into the autonomous aerial vehicles has largely increased recently. With the advancement of the technology in the area it has become possible to test efficiently and cost-effectively different autonomous flight control concepts and design variations using small-scale aircrafts. The paper presents a new neuro-adaptive approach for controlling the altitude and yaw angle of a miniature rotorcraft having four rotors. The adaptive structures in the proposed control schemes are comprised of radial basis functions neural networks using a new stable on-line learning algorithm. The latter is based on the variable structure systems theory and establishes a sliding motion in term of the network parameters, leading the learning error toward zero. The pitch and roll movements of the rotorcraft are controlled by an algorithm that employs the principles of the well known nested saturation control strategy. The results obtained from flight simulations with an accurate dynamic model of the DraganFlyer V Ti miniature quad-rotor helicopter demonstrate that the proposed neuro-adaptive control approach can deal successfully with the existing uncertainties and variations in the model parameters and/or changes in the environmental conditions.}
}
@article{SUN2022191,
title = {Advances in optical phenotyping of cereal crops},
journal = {Trends in Plant Science},
volume = {27},
number = {2},
pages = {191-208},
year = {2022},
issn = {1360-1385},
doi = {https://doi.org/10.1016/j.tplants.2021.07.015},
url = {https://www.sciencedirect.com/science/article/pii/S1360138521002028},
author = {Dawei Sun and Kelly Robbins and Nicolas Morales and Qingyao Shu and Haiyan Cen},
keywords = {cereal crops, high-throughput phenotyping, optical sensors, traits},
abstract = {Optical sensors and sensing-based phenotyping techniques have become mainstream approaches in high-throughput phenotyping for improving trait selection and genetic gains in crops. We review recent progress and contemporary applications of optical sensing-based phenotyping (OSP) techniques in cereal crops and highlight optical sensing principles for spectral response and sensor specifications. Further, we group phenotypic traits determined by OSP into four categories – morphological, biochemical, physiological, and performance traits – and illustrate appropriate sensors for each extraction. In addition to the current status, we discuss the challenges of OSP and provide possible solutions. We propose that optical sensing-based traits need to be explored further, and that standardization of the language of phenotyping and worldwide collaboration between phenotyping researchers and other fields need to be established.}
}
@article{DEVIVO2021106574,
title = {Infra-red line camera data-driven edge detector in UAV forest fire monitoring},
journal = {Aerospace Science and Technology},
volume = {111},
pages = {106574},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.106574},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821000857},
author = {Francesco {De Vivo} and Manuela Battipede and Eric Johnson},
keywords = {Edge detection, Canny method, Contour algorithm, Forest fire, UAV, Infrared image},
abstract = {The accurate prediction of the wildfire spread-rate is a challenging task, due to the high number of parameters involved and the underlying complex dynamic multi-physics processes which drive the phenomenon. For these reasons, data-driven prediction tools could be useful to provide a more accurate prediction of the fire front. In this scenario, systematic fire data gathering becomes crucial and using an Unmanned Aircraft Vehicle (UAV) is strategic to reduce considerably the risk associated with flying a manned aircraft into low visibility and extremely turbulent air, sustained by the fire-induced convective motions. Moreover the employment of the UAV is beneficial, as the possibility of flying at very low altitudes maximizes the on-board Electro-Optical (EO) sensor effectiveness. The aim is to develop a real time data-driven fire propagator to support wildfire fighting operations and to facilitate the risk assessment and decision making process. In order to collect data, the fire front position has to be measured using an infra-red (IR) camera so as to overcome the limitations associated to a visible camera in low visibility (smoky)conditions and night operations. To reduce the computational cost associated to the image processing, a Line Camera (LC) configuration has been preferred. Because of the mono-dimensionality of the measure, classical edge detector, like the Canny method, or contour algorithms, developed for 2D images, can not be applied. In this paper, a mono-dimensional noise-resistant algorithm for edge detection is presented. The generality of the proposed method opens the possibility to a variety of heterogeneous problems of different nature. The robustness of this algorithm resides in the use of known physical characteristics of the target of interest, to increase the feature edge discontinuity. Its straightforwardness guarantees fast computation, making it very attractive for real time image processing, remote sensing applications and for UAV surveillance tasks.}
}
@article{VAEGAE2016240,
title = {Development of an intelligent pressure measuring technique for bellows using radial basis function neural network},
journal = {Sensors and Actuators A: Physical},
volume = {238},
pages = {240-248},
year = {2016},
issn = {0924-4247},
doi = {https://doi.org/10.1016/j.sna.2015.12.017},
url = {https://www.sciencedirect.com/science/article/pii/S0924424715302697},
author = {Naveen Kumar Vaegae and Venkata Lakshmi Narayana Komanapalli and Srikanth Malla},
keywords = {Artificial neural network, Bellow, Inductive transducer, Pressure measurement, Radial basis function, Signal conditioning circuit},
abstract = {This paper presents the implementation of an intelligent pressure transmitter to measure pressure using a bellow sensor. In industrial applications, the deflection of the bellow due to applied pressure must be translated into an efficient electrical readout for monitoring, transmission and control. An inductive pick-up is used to convert the deflection of the bellow into the change in self-inductance of a coil. The signal conditioning circuit designed for the bellow sensor with the inductive coil is an inductance to voltage conversion circuit (ITVCC). The stray inductances, component tolerances and ambient factors introduce errors in the output of the ITVCC. The voltage–pressure relation exhibits a considerable nonlinearity and limits the measurement to local operations. In this aspect, we propose an artificial neural network (ANN) using a radial basis function to estimate and compensate the nonlinearity of the ITVCC. The intelligence of ANN modeling is incorporated into an embedded plug-in-module (EPIM). The output voltage of the EPIM is converted into a 4–20mA current signal for further processing. The performance of the proposed technique is experimentally verified. The nonlinearity expressed as maximum deviation from the desired response is within ±0.6% of full scale reading. The design aspects, simulation analysis and experimental results of the technique are reported.}
}
@article{BRIECHLE2020345,
title = {Detection of radioactive waste sites in the Chornobyl exclusion zone using UAV-based lidar data and multispectral imagery},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {167},
pages = {345-362},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620301738},
author = {S. Briechle and N. Molitor and P. Krzystek and G. Vosselman},
keywords = {UAV, Lidar, Multispectral imagery, Radioactive waste sites, 3D vegetation mapping, Machine learning},
abstract = {The severe accident at the Chornobyl Nuclear Power Plant (ChNPP) in 1986 resulted in extraordinary contamination of the surrounding territory, which necessitated the creation of the Chornobyl Exclusion Zone (ChEZ). During the accident, liquidation materials contaminated by radioactive fallout (e.g., contaminated soil and trees) were buried in so-called Radioactive Waste Temporary Storage Places (RWTSPs). The exact locations of these burials were not always sufficiently documented. However, for safety management, including eventual remediation works, it is crucial to know their locations and rely on precise hazard maps. Over the past 34 years, most of these so-called trenches and clamps have been exposed to natural processes. In addition to settlement and erosion, they have been overgrown with dense vegetation. To date, more than 700 burials have been thoroughly investigated, but a large number of burial sites (approximately 300) are still unknown. In the past, numerous burials were identified based on settlement or elevation in the decimeter range, and vegetation anomalies that tend to appear in the immediate vicinity. Nevertheless, conventional detection methods are time-, effort- and radiation dose-intensive. Airborne gamma spectrometry and visual ground inspection of morphology and vegetation can provide useful complementary information, but it is insufficient for precisely localizing unknown burial sites in many cases. Therefore, sensor technologies, such as UAV-based lidar and multispectral imagery, have been identified as potential alternative solutions. This paper presents a novel method to detect radioactive waste sites based on a set of prominent features generated from high-resolution remote sensing data in combination with a random forest (RF) classifier. Initially, we generate a digital terrain model (DTM) and 3D vegetation map from the data and derive tree-based features, including tree density, tree height, and tree species. Feature subsets compiled from normalized DTM height, fast point feature histograms (FPFH), and lidar metrics are then incorporated. Next, an RF classifier is trained on reference areas defined by visual interpretation of the DTM grid. A backward feature selection strategy reduces the feature space significantly and avoids overfitting. Feature relevance assessment clearly demonstrates that the members of all feature subsets represent a final list of the most prominent features. For three representative study areas, the mean overall accuracy (OA) is 98.2% when using area-wide test data. Cohens’ kappa coefficient κ ranges from 0.609 to 0.758. Additionally, we demonstrate the transferability of a trained classifier to an adjacent study area (OA = 93.6%, κ = 0.452). As expected, when utilizing the classifier on geometrically incorrect and incomplete reference data, which were generated from old maps and orthophotos based on visual inspection, the OA decreases significantly to 65.1% (κ = 0.481). Finally, detection is verified through 38 borings that successfully confirm the existence of previously unknown buried nuclear materials in classified areas. These results demonstrate that the proposed methodology is applicable to detecting area-wide unknown radioactive biomass burials in the ChEZ.}
}
@article{IKENO2021101380,
title = {An enhanced 3D model and generative adversarial network for automated generation of horizontal building mask images and cloudless aerial photographs},
journal = {Advanced Engineering Informatics},
volume = {50},
pages = {101380},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101380},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621001336},
author = {Kazunosuke Ikeno and Tomohiro Fukuda and Nobuyoshi Yabuki},
keywords = {Deep learning, Generative adversarial network, Semantic segmentation, Mask image, Training data, Urban planning and design},
abstract = {Information extracted from aerial photographs is widely used in the fields of urban planning and design. An effective method for detecting buildings in aerial photographs is to use deep learning to understand the current state of a target region. However, the building mask images used to train the deep learning model must be manually generated in many cases. To overcome this challenge, a method has been proposed for automatically generating mask images by using textured three-dimensional (3D) virtual models with aerial photographs. Some aerial photographs include clouds, which degrade image quality. These clouds can be removed by using a generative adversarial network (GAN), which leads to improvements in training quality. Therefore, the objective of this research was to propose a method for automatically generating building mask images by using 3D virtual models with textured aerial photographs. In this study, using GAN to remove clouds in aerial photographs improved training quality. A model trained on datasets generated by the proposed method was able to detect buildings in aerial photographs with IoU = 0.651.}
}
@article{FARRE202079,
title = {Remote and in situ devices for the assessment of marine contaminants of emerging concern and plastic debris detection},
journal = {Current Opinion in Environmental Science & Health},
volume = {18},
pages = {79-94},
year = {2020},
note = {Environmental Chemistry: Innovative Approaches and Instrumentation in Environmental Chemistry},
issn = {2468-5844},
doi = {https://doi.org/10.1016/j.coesh.2020.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S2468584420300659},
author = {Marinella Farré},
keywords = {Contaminants of merging concern, Microplastics, UAV, ASV, AUV, Sensors, Biosensors},
abstract = {There is an increasing sense of alarm due to the constant accumulation of contaminants of emerging concern in the oceans. This fact was reflected in one of the significant challenges that are included in the United Nations Sustainable Development Goals which refer to climate change, conservation, and use of forests and oceans. Autonomous environmental monitoring techniques are required to set effective measures to conserve oceans. These detection systems are crucial tools for ambient data acquisition, remote monitoring, and mapping of the spatial extent of contaminants spills and plastic litter. Among the different technological operations that can be supported by these systems, the localisation of pollution sources has drawn increasing interest during recent years. This paper surveys recent advances in the new technologies for detection, mapping and new environmental monitoring strategies to detect marine contaminants of emerging concern and plastic litter.}
}
@article{PHANDEN2021269,
title = {An experimental study on the flight time of quadcopter using solar energy},
journal = {Materials Today: Proceedings},
volume = {38},
pages = {269-273},
year = {2021},
note = {2nd International Conference on Future Learning Aspects of Mechanical Engineering},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2020.07.199},
url = {https://www.sciencedirect.com/science/article/pii/S2214785320352925},
author = {Rakesh Kumar Phanden and Jatinder Chhabra and Basant Singh Sikarwar and Karan Arora and Kush Asawa and Shiwang Das},
keywords = {Quadcopter, Flight time, Solar energy, DC battery, Discharge rate},
abstract = {The unmanned aerial vehicles are getting popular day by day owing to its ability to hover, low cost of maintenance, ease of deployment as well as high mobility. A quadcopter has limited mobility and payload, but they are highly capable to fly in any direction and to stay stationary in the air. Therefore, the battery lifetime is an important aspect to study which help to travel for a long distance and to increase the flight time. In this direction, the present work focuses on the flight time, which is being analyzed experimentally through the integration of solar panels in the quadcopter for utilization of solar energy as a power source along with the conventional DC battery and by efficient weight reduction of the quadcopter. The proposed quadcopter has been designed in SolidWorks© software and analyzed in Ansys© software as well as it has been fabricated successfully to test for flight time.}
}
@article{XING2020105343,
title = {Comparison of different models for evaluating vehicle collision risks at upstream diverging area of toll plaza},
journal = {Accident Analysis & Prevention},
volume = {135},
pages = {105343},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2019.105343},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519307584},
author = {Lu Xing and Jie He and Ye Li and Yina Wu and Jinghui Yuan and Xin Gu},
keywords = {Collision risk, Trajectory data, Toll plaza, Diverging area, Logistic regression, Non-Parametric model},
abstract = {Toll plazas with both Electronic Toll Collection (ETC) lane(s) and Manual Toll Collection (MTC) lane(s) could increase crash risks especially at upstream diverging areas because of frequency lane-change behaviors. This study develops the logistic regression (LR) model and five typical non-parametric models including, K-Nearest Neighbor (KNN), Artificial Neural Networks (ANN), Support Vector Machines (SVM), Decision Trees (DT), and Random Forest (RF) to examine the relationship between influencing factors and vehicle collision risk. Based on the vehicle trajectory data extracted from unmanned aerial vehicle (UAV) videos using an automated video analysis system, the unconstrained vehicle motion’s collision risk can be evaluated by the extended time to collision (ETTC). Results of model performance comparison indicate that not all non-parametric models have a better prediction performance than the LR model. Specifically, the KNN, SVM, DT and RF models have better model performance than LR model in model training, while the ANN model has the worst model performance. In model prediction, the accuracy of LR model is higher than that of other five non-parametric models under various ETTC thresholds conditions. The LR model implies a pretty good performance and its results also indicate that vehicle yields the higher collision risk when it drives on the left side of toll plaza diverging area and more dangerous situations could be found for an ETC vehicle. Moreover, the vehicle collision risks are positively associated with the speed of the following vehicle and the angle between the leading vehicle speed vector and X axis. Furthermore, the results of DT model show that three factors play important roles in classifying vehicle collision risk and the effects of them on collision risk are consistent with the results of LR model. These findings provide valuable information for accurate assessment of collision risk, which is a key step toward improving safety performance of the toll plaza diverging area.}
}
@article{MIR201817,
title = {Optimal morphing – augmented dynamic soaring maneuvers for unmanned air vehicle capable of span and sweep morphologies},
journal = {Aerospace Science and Technology},
volume = {79},
pages = {17-36},
year = {2018},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2018.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S1270963818300427},
author = {Imran Mir and Adnan Maqsood and Sameh A. Eisa and Haitham Taha and Suhail Akhtar},
abstract = {This paper investigates autonomous dynamic soaring maneuvers for a small Unmanned Aerial Vehicle (sUAV) having the capability to morph. Dynamic soaring for UAVs have mostly been confined in literature to fixed configurations. In order to analyze the extent to which dynamic soaring is influenced by different morphologies, an innovative concept of integrating dynamic soaring with morphing capabilities is introduced. Moreover, optimal soaring trajectories are generated for two basic wing morphologies: variable sweep and variable span. Three-dimensional point-mass UAV equations of motion and nonlinear wind gradient profile are used to model the flight dynamics. Parametric characterization of the key performance parameters is performed to determine the optimal platform configuration during various phases of the maneuver. Results presented in this paper indicate 15% lesser required wind shear by the proposed span morphology and 14% lesser required wind shear by the proposed sweep morphology, in comparison to their respective fixed wing counterparts. This shows that the morphing UAV can perform dynamic soaring in an environment, where fixed configuration UAVs might not, because of lesser available wind shears. Apart from this, span morphology reduced drag by 15%, lift requirement by 11% and angle of attack requirement by 20%, whereas increased the maximum velocity by 6.2%, normalized energies by 9% and improved loitering parameters (approximately 10%), in comparison to fixed span configurations. Similarly, sweep morphology guaranteed 20% drag reduction, 16% lesser angle of attack requirement and improved loitering performance over the fixed sweep configurations. The results achieved from this study strongly support the idea of integrating dynamic soaring with morphing capabilities and its potential benefits.}
}
@article{SUBRAMANIAN2021103132,
title = {A deep genetic algorithm for human activity recognition leveraging fog computing frameworks},
journal = {Journal of Visual Communication and Image Representation},
volume = {77},
pages = {103132},
year = {2021},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2021.103132},
url = {https://www.sciencedirect.com/science/article/pii/S1047320321000857},
author = {R. Raja Subramanian and V. Vasudevan},
keywords = {Deep genetic algorithm, Human activity recognition, Fog computing, Ambulatory healthcare},
abstract = {With modern e-healthcare developments, ambulatory healthcare has become a prominent requirement for physical or mental ailed, elderly, childhood people. One of the major challenges in such applications is timing and precision. A potential solution to this problem is the fog-assisted cloud computing architecture. The activity recognition task is performed with the hybrid advantages of deep learning and genetic algorithms. The video frames captured from vision cameras are subjected to the genetic change detection algorithm, which detects changes in activities of subsequent frames. Consequently, the deep learning algorithm recognizes the activity of the changed frame. This hybrid algorithm is run on top of fog-assisted cloud framework, fogbus and the performance measures including latency, execution time, arbitration time and jitter are observed. Empirical evaluations of the proposed model against three activity data sets shows that the proposed deep genetic algorithm exhibits higher accuracy in inferring human activities as compared to the state-of-the-art algorithms.}
}
@article{HU2018141,
title = {Neuro-adaptive tracking control of a hypersonic flight vehicle with uncertainties using reinforcement synthesis},
journal = {Neurocomputing},
volume = {285},
pages = {141-153},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.01.031},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218300493},
author = {Lin Hu and Renfu Li and Tao Xue and Yifang Liu},
keywords = {Adaptive optimization, Nonlinear control, Neural networks, Reinforcement learning, Air-breathing hypersonic aircraft, Uncertainty},
abstract = {In this paper, the neuro-adaptive optimal nonlinear control approach and algorithm are proposed for the tracking control of an air-breathing hypersonic aircraft considering uncertainties. Based on the reinforcement learning mechanism, the neuro-adaptive control agent is constructed using actor-critic architecture, which consists of two interacting neural networks, one for optimal control protocol, known as the actor NN, and the other for policy evaluation, known as critic NN. The optimality conditions for this adaptive controller are derived by using the discrete minimum principle. In the meanwhile, the parametric and mismatched uncertainty and unmodeled nonlinearity are handled by using another neural network named as UNN with aid of the concept of a virtual plant. The output of the network in the virtual plant helps to estimate the optimal control with varying dynamics of air-breathing hypersonic flight aircraft. Simulation results are presented to verify the effectiveness of this design method for the tracking control of the air-breathing hypersonic aircraft in the presence of uncertainties.}
}
@article{GUO20211,
title = {Real-time automated identification of algal bloom species for fisheries management in subtropical coastal waters},
journal = {Journal of Hydro-environment Research},
volume = {36},
pages = {1-32},
year = {2021},
issn = {1570-6443},
doi = {https://doi.org/10.1016/j.jher.2021.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S1570644321000216},
author = {Jiuhao Guo and Yaoyao Ma and Joseph H.W. Lee},
keywords = {Eutrophication, Harmful algal blooms, Fisheries management, Red tide, IFCB, Real-time system, Random forest, Feature selection, Machine learning, water quality monitoring},
abstract = {Harmful Algal Blooms (HAB) pose significant challenges to fisheries management and food and water security. The onset of a HAB is notoriously difficult to predict. Traditional methods of algal species identification under a microscope are also laborious and time consuming. A real-time system for identification and concentration measurement of algal bloom species has been developed at a marine fish culture zone (FCZ) in the subtropical coastal waters of Hong Kong. The system is based on analysis of high frequency algal cell images obtained from an underwater Imaging FlowCytobot (IFCB) deployed on the fish farm. An explainable supervised machine learning technique has been successfuly developed. The algal species classifier is trained by presenting a wide range of extracted image features to a random forest algorithm. An optimized set of 25 features is identified by a recursive feature elimination technique. The random forest (RF) classifier can identify 15 target HAB classes with an overall out-of-bag accuracy of 94.2%, with individual F1 score ranging from 0.8 to 1.0. The classifier performs equally well as a Convolution Neural Network (CNN) developed using transfer learning techniques. Based on the classifier, an automated real-time species identification and cell counting protocol has been developed, with a response time of 10 min after data collection. This work represents the first successful attempt of continuous algal species monitoring by IFCB and artificial intelligence (AI) – based detection of HAB in subtropical coastal waters.}
}

@Article{s21010274,
AUTHOR = {Elouni, Maha and Abdelghaffar, Hossam M. and Rakha, Hesham A.},
TITLE = {Adaptive Traffic Signal Control: Game-Theoretic Decentralized vs. Centralized Perimeter Control},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {274},
URL = {https://www.mdpi.com/1424-8220/21/1/274},
PubMedID = {33401615},
ISSN = {1424-8220},
ABSTRACT = {This paper compares the operation of a decentralized Nash bargaining traffic signal controller (DNB) to the operation of state-of-the-art adaptive and gating traffic signal control. Perimeter control (gating), based on the network fundamental diagram (NFD), was applied on the borders of a protected urban network (PN) to prevent and/or disperse traffic congestion. The operation of gating control and local adaptive controllers was compared to the operation of the developed DNB traffic signal controller. The controllers were implemented and their performance assessed on a grid network in the INTEGRATION microscopic simulation software. The results show that the DNB controller, although not designed to solve perimeter control problems, successfully prevents congestion from building inside the PN and improves the performance of the entire network. Specifically, the DNB controller outperforms both gating and non-gating controllers, with reductions in the average travel time ranging between 21% and 41%, total delay ranging between 40% and 55%, and emission levels/fuel consumption ranging between 12% and 20%. The results demonstrate statistically significant benefits of using the developed DNB controller over other state-of-the-art centralized and decentralized gating/adaptive traffic signal controllers.},
DOI = {10.3390/s21010274}
}



@Article{pr9010092,
AUTHOR = {Shahbazi, Zeinab and Byun, Yung-Cheol},
TITLE = {Improving Transactional Data System Based on an Edge Computing–Blockchain–Machine Learning Integrated Framework},
JOURNAL = {Processes},
VOLUME = {9},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {92},
URL = {https://www.mdpi.com/2227-9717/9/1/92},
ISSN = {2227-9717},
ABSTRACT = {The modern industry, production, and manufacturing core is developing based on smart manufacturing (SM) systems and digitalization. Smart manufacturing&rsquo;s practical and meaningful design follows data, information, and operational technology through the blockchain, edge computing, and machine learning to develop and facilitate the smart manufacturing system. This process&rsquo;s proposed smart manufacturing system considers the integration of blockchain, edge computing, and machine learning approaches. Edge computing makes the computational workload balanced and similarly provides a timely response for the devices. Blockchain technology utilizes the data transmission and the manufacturing system&rsquo;s transactions, and the machine learning approach provides advanced data analysis for a huge manufacturing dataset. Regarding smart manufacturing systems&rsquo; computational environments, the model solves the problems using a swarm intelligence-based approach. The experimental results present the edge computing mechanism and similarly improve the processing time of a large number of tasks in the manufacturing system.},
DOI = {10.3390/pr9010092}
}



@Article{s21020359,
AUTHOR = {Honar Pajooh, Houshyar and Rashid, Mohammad and Alam, Fakhrul and Demidenko, Serge},
TITLE = {Hyperledger Fabric Blockchain for Securing the Edge Internet of Things},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {359},
URL = {https://www.mdpi.com/1424-8220/21/2/359},
PubMedID = {33430274},
ISSN = {1424-8220},
ABSTRACT = {Providing security and privacy to the Internet of Things (IoT) networks while achieving it with minimum performance requirements is an open research challenge. Blockchain technology, as a distributed and decentralized ledger, is a potential solution to tackle the limitations of the current peer-to-peer IoT networks. This paper presents the development of an integrated IoT system implementing the permissioned blockchain Hyperledger Fabric (HLF) to secure the edge computing devices by employing a local authentication process. In addition, the proposed model provides traceability for the data generated by the IoT devices. The presented solution also addresses the IoT systems&rsquo; scalability challenges, the processing power and storage issues of the IoT edge devices in the blockchain network. A set of built-in queries is leveraged by smart-contracts technology to define the rules and conditions. The paper validates the performance of the proposed model with practical implementation by measuring performance metrics such as transaction throughput and latency, resource consumption, and network use. The results show that the proposed platform with the HLF implementation is promising for the security of resource-constrained IoT devices and is scalable for deployment in various IoT scenarios.},
DOI = {10.3390/s21020359}
}



@Article{su13020751,
AUTHOR = {Andronie, Mihai and Lăzăroiu, George and Iatagan, Mariana and Hurloiu, Iulian and Dijmărescu, Irina},
TITLE = {Sustainable Cyber-Physical Production Systems in Big Data-Driven Smart Urban Economy: A Systematic Literature Review},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {751},
URL = {https://www.mdpi.com/2071-1050/13/2/751},
ISSN = {2071-1050},
ABSTRACT = {In this article, we cumulate previous research findings indicating that cyber-physical production systems bring about operations shaping social sustainability performance technologically. We contribute to the literature on sustainable cyber-physical production systems by showing that the technological and operations management features of cyber-physical systems constitute the components of data-driven sustainable smart manufacturing. Throughout September 2020, we performed a quantitative literature review of the Web of Science, Scopus, and ProQuest databases, with search terms including &ldquo;sustainable industrial value creation&rdquo;, &ldquo;cyber-physical production systems&rdquo;, &ldquo;sustainable smart manufacturing&rdquo;, &ldquo;smart economy&rdquo;, &ldquo;industrial big data analytics&rdquo;, &ldquo;sustainable Internet of Things&rdquo;, and &ldquo;sustainable Industry 4.0&rdquo;. As we inspected research published only in 2019 and 2020, only 323 articles satisfied the eligibility criteria. By eliminating controversial findings, outcomes unsubstantiated by replication, too imprecise material, or having similar titles, we decided upon 119, generally empirical, sources. Future research should investigate whether Industry 4.0-based manufacturing technologies can ensure the sustainability of big data-driven production systems by use of Internet of Things sensing networks and deep learning-assisted smart process planning.},
DOI = {10.3390/su13020751}
}



@Article{g12010008,
AUTHOR = {Chica-Pedraza, Gustavo and Mojica-Nava, Eduardo and Cadena-Muñoz, Ernesto},
TITLE = {Boltzmann Distributed Replicator Dynamics: Population Games in a Microgrid Context},
JOURNAL = {Games},
VOLUME = {12},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {8},
URL = {https://www.mdpi.com/2073-4336/12/1/8},
ISSN = {2073-4336},
ABSTRACT = {Multi-Agent Systems (MAS) have been used to solve several optimization problems in control systems. MAS allow understanding the interactions between agents and the complexity of the system, thus generating functional models that are closer to reality. However, these approaches assume that information between agents is always available, which means the employment of a full-information model. Some tendencies have been growing in importance to tackle scenarios where information constraints are relevant issues. In this sense, game theory approaches appear as a useful technique that use a strategy concept to analyze the interactions of the agents and achieve the maximization of agent outcomes. In this paper, we propose a distributed control method of learning that allows analyzing the effect of the exploration concept in MAS. The dynamics obtained use Q-learning from reinforcement learning as a way to include the concept of exploration into the classic exploration-less Replicator Dynamics equation. Then, the Boltzmann distribution is used to introduce the Boltzmann-Based Distributed Replicator Dynamics as a tool for controlling agents behaviors. This distributed approach can be used in several engineering applications, where communications constraints between agents are considered. The behavior of the proposed method is analyzed using a smart grid application for validation purposes. Results show that despite the lack of full information of the system, by controlling some parameters of the method, it has similar behavior to the traditional centralized approaches.},
DOI = {10.3390/g12010008}
}



@Article{info12010040,
AUTHOR = {Taherizadeh, Salman and Apostolou, Dimitris and Verginadis, Yiannis and Grobelnik, Marko and Mentzas, Gregoris},
TITLE = {A Semantic Model for Interchangeable Microservices in Cloud Continuum Computing},
JOURNAL = {Information},
VOLUME = {12},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {40},
URL = {https://www.mdpi.com/2078-2489/12/1/40},
ISSN = {2078-2489},
ABSTRACT = {The rapid growth of new computing models that exploit the cloud continuum has a big impact on the adoption of microservices, especially in dynamic environments where the amount of workload varies over time or when Internet of Things (IoT) devices dynamically change their geographic location. In order to exploit the true potential of cloud continuum computing applications, it is essential to use a comprehensive set of various intricate technologies together. This complex blend of technologies currently raises data interoperability problems in such modern computing frameworks. Therefore, a semantic model is required to unambiguously specify notions of various concepts employed in cloud applications. The goal of the present paper is therefore twofold: (i) offering a new model, which allows an easier understanding of microservices within adaptive fog computing frameworks, and (ii) presenting the latest open standards and tools which are now widely used to implement each class defined in our proposed model.},
DOI = {10.3390/info12010040}
}



@Article{electronics10030227,
AUTHOR = {Neelakantam, Gone and Onthoni, Djeane Debora and Sahoo, Prasan Kumar},
TITLE = {Fog Computing Enabled Locality Based Product Demand Prediction and Decision Making Using Reinforcement Learning},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {227},
URL = {https://www.mdpi.com/2079-9292/10/3/227},
ISSN = {2079-9292},
ABSTRACT = {Wastage of perishable and non-perishable products due to manual monitoring in shopping malls creates huge revenue loss in supermarket industry. Besides, internal and external factors such as calendar events and weather condition contribute to excess wastage of products in different regions of supermarket. It is a challenging job to know about the wastage of the products manually in different supermarkets region-wise. Therefore, the supermarket management needs to take appropriate decision and action to prevent the wastage of products. The fog computing data centers located in each region can collect, process and analyze data for demand prediction and decision making. In this paper, a product-demand prediction model is designed using integrated Principal Component Analysis (PCA) and K-means Unsupervised Learning (UL) algorithms and a decision making model is developed using State-Action-Reward-State-Action (SARSA) Reinforcement Learning (RL) algorithm. Our proposed method can cluster the products into low, medium, and high-demand product by learning from the designed features. Taking the derived cluster model, decision making for distributing low-demand to high-demand product can be made using SARSA. Experimental results show that our proposed method can cluster the datasets well with a Silhouette score of &ge;60%. Besides, our adopted SARSA-based decision making model outperforms over Q-Learning, Monte-Carlo, Deep Q-Network (DQN), and Actor-Critic algorithms in terms of maximum cumulative reward, average cumulative reward and execution time.},
DOI = {10.3390/electronics10030227}
}



@Article{su13031210,
AUTHOR = {Limsoonthrakul, Somphop and Dailey, Matthew N. and Marikhu, Ramesh and Timtong, Vasan and Chairat, Aphinya and Suphavilai, Anant and Seetamanotch, Wiwat and Ekpanyapong, Mongkol},
TITLE = {Design and Implementation of a Highly Scalable, Low-Cost Distributed Traffic Violation Enforcement System in Phuket, Thailand},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {1210},
URL = {https://www.mdpi.com/2071-1050/13/3/1210},
ISSN = {2071-1050},
ABSTRACT = {The number of global road traffic accidents is rising every year and remains undesirably high. One of the main reasons for this trend is that, in many countries, road users violate road safety regulations and traffic laws. Despite improvements in road safety legislation, enforcement is still a major challenge in low- and middle-income countries. Information technology solutions have emerged for automated traffic enforcement systems in the last decade. They have been tested on a small scale, but until now, the cost of deployment of these systems is generally too high for nation-wide adoption in low- and middle-income countries that need them the most. We present the architectural design of a traffic violation enforcement system that can optimize the cost of deployment and resource utilization. Based on the proposed architecture, we describe the implementation and deployment of the system, and perform a comparison of two different versions of the video-based enforcement system, one using classical computer vision methods and another using deep learning techniques. Finally, we analyze the impact of the system deployed in Phuket, Thailand from 2017 to the present in terms of local road users&rsquo; compliance and the road safety situation. We conclude that the system has had a positive impact on road safety in Phuket at a moderate cost.},
DOI = {10.3390/su13031210}
}



@Article{app11031109,
AUTHOR = {Xiong, Gang and Li, Zhishuai and Wu, Huaiyu and Chen, Shichao and Dong, Xisong and Zhu, Fenghua and Lv, Yisheng},
TITLE = {Building Urban Public Traffic Dynamic Network Based on CPSS: An Integrated Approach of Big Data and AI},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {1109},
URL = {https://www.mdpi.com/2076-3417/11/3/1109},
ISSN = {2076-3417},
ABSTRACT = {The extensive proliferation of urban transit cards and smartphones has witnessed the feasibility of the collection of citywide travel behaviors and the estimation of traffic status in real-time. In this paper, an urban public traffic dynamic network based on the cyber-physical-social system (CPSS-UPTDN) is proposed as a universal framework for advanced public transportation systems, which can optimize the urban public transportation based on big data and AI methods. Firstly, we introduce three modules and two loops which composes of the novel framework. Then, the key technologies in CPSS-UPTDN are studied, especially collecting and analyzing traffic information by big data and AI methods, and a particular implementation of CPSS-UPTDN is discussed, namely the artificial system, computational experiments, and parallel execution (ACP) method. Finally, a case study is performed. The data sources include both traffic congestion data from physical space and cellular data from social space, which can improve the prediction performance for traffic status. Furthermore, the service quality of urban public transportation can be promoted by optimizing the bus dispatching based on the parallel execution in our framework.},
DOI = {10.3390/app11031109}
}



@Article{bdcc5010006,
AUTHOR = {Asaithambi, Suriya Priya R. and Venkatraman, Sitalakshmi and Venkatraman, Ramanathan},
TITLE = {Big Data and Personalisation for Non-Intrusive Smart Home Automation},
JOURNAL = {Big Data and Cognitive Computing},
VOLUME = {5},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {6},
URL = {https://www.mdpi.com/2504-2289/5/1/6},
ISSN = {2504-2289},
ABSTRACT = {With the advent of the Internet of Things (IoT), many different smart home technologies are commercially available. However, the adoption of such technologies is slow as many of them are not cost-effective and focus on specific functions such as energy efficiency. Recently, IoT devices and sensors have been designed to enhance the quality of personal life by having the capability to generate continuous data streams that can be used to monitor and make inferences by the user. While smart home devices connect to the home Wi-Fi network, there are still compatibility issues between devices from different manufacturers. Smart devices get even smarter when they can communicate with and control each other. The information collected by one device can be shared with others for achieving an enhanced automation of their operations. This paper proposes a non-intrusive approach of integrating and collecting data from open standard IoT devices for personalised smart home automation using big data analytics and machine learning. We demonstrate the implementation of our proposed novel technology instantiation approach for achieving non-intrusive IoT based big data analytics with a use case of a smart home environment. We employ open-source frameworks such as Apache Spark, Apache NiFi and FB-Prophet along with popular vendor tech-stacks such as Azure and DataBricks.},
DOI = {10.3390/bdcc5010006}
}



@Article{smartcities4010014,
AUTHOR = {Gomez-Rosero, Santiago and Capretz, Miriam A. M. and Mir, Syed},
TITLE = {Transfer Learning by Similarity Centred Architecture Evolution for Multiple Residential Load Forecasting},
JOURNAL = {Smart Cities},
VOLUME = {4},
YEAR = {2021},
NUMBER = {1},
PAGES = {217--240},
URL = {https://www.mdpi.com/2624-6511/4/1/14},
ISSN = {2624-6511},
ABSTRACT = {The development from traditional low voltage grids to smart systems has become extensive and adopted worldwide. Expanding the demand response program to cover the residential sector raises a wide range of challenges. Short term load forecasting for residential consumers in a neighbourhood could lead to a better understanding of low voltage consumption behaviour. Nevertheless, users with similar characteristics can present diversity in consumption patterns. Consequently, transfer learning methods have become a useful tool to tackle differences among residential time series. This paper proposes a method combining evolutionary algorithms for neural architecture search with transfer learning to perform short term load forecasting in a neighbourhood with multiple household load consumption. The approach centres its efforts on neural architecture search using evolutionary algorithms. The neural architecture evolution process retains the patterns of the centre-most house, and later the architecture weights are adjusted for each house in a multihouse set from a neighbourhood. In addition, a sensitivity analysis was conducted to ensure model performance. Experimental results on a large dataset containing hourly load consumption for ten houses in London, Ontario showed that the performance of the proposed approach performs better than the compared techniques. Moreover, the proposed method presents the average accuracy performance of 3.17 points higher than the state-of-the-art LSTM one shot method.},
DOI = {10.3390/smartcities4010014}
}



@Article{su13041821,
AUTHOR = {Islam, Nahina and Rashid, Md Mamunur and Pasandideh, Faezeh and Ray, Biplob and Moore, Steven and Kadel, Rajan},
TITLE = {A Review of Applications and Communication Technologies for Internet of Things (IoT) and Unmanned Aerial Vehicle (UAV) Based Sustainable Smart Farming},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1821},
URL = {https://www.mdpi.com/2071-1050/13/4/1821},
ISSN = {2071-1050},
ABSTRACT = {To reach the goal of sustainable agriculture, smart farming is taking advantage of the Unmanned Aerial Vehicles (UAVs) and Internet of Things (IoT) paradigm. These smart farms are designed to be run by interconnected devices and vehicles. Some enormous potentials can be achieved by the integration of different IoT technologies to achieve automated operations with minimum supervision. This paper outlines some major applications of IoT and UAV in smart farming, explores the communication technologies, network functionalities and connectivity requirements for Smart farming. The connectivity limitations of smart agriculture and it’s solutions are analysed with two case studies. In case study-1, we propose and evaluate meshed Long Range Wide Area Network (LoRaWAN) gateways to address connectivity limitations of Smart Farming. While in case study-2, we explore satellite communication systems to provide connectivity to smart farms in remote areas of Australia. Finally, we conclude the paper by identifying future research challenges on this topic and outlining directions to address those challenges.},
DOI = {10.3390/su13041821}
}



@Article{technologies9010014,
AUTHOR = {Gadze, James Dzisi and Bamfo-Asante, Akua Acheampomaa and Agyemang, Justice Owusu and Nunoo-Mensah, Henry and Opare, Kwasi Adu-Boahen},
TITLE = {An Investigation into the Application of Deep Learning in the Detection and Mitigation of DDOS Attack on SDN Controllers},
JOURNAL = {Technologies},
VOLUME = {9},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {14},
URL = {https://www.mdpi.com/2227-7080/9/1/14},
ISSN = {2227-7080},
ABSTRACT = {Software-Defined Networking (SDN) is a new paradigm that revolutionizes the idea of a software-driven network through the separation of control and data planes. It addresses the problems of traditional network architecture. Nevertheless, this brilliant architecture is exposed to several security threats, e.g., the distributed denial of service (DDoS) attack, which is hard to contain in such software-based networks. The concept of a centralized controller in SDN makes it a single point of attack as well as a single point of failure. In this paper, deep learning-based models, long-short term memory (LSTM) and convolutional neural network (CNN), are investigated. It illustrates their possibility and efficiency in being used in detecting and mitigating DDoS attack. The paper focuses on TCP, UDP, and ICMP flood attacks that target the controller. The performance of the models was evaluated based on the accuracy, recall, and true negative rate. We compared the performance of the deep learning models with classical machine learning models. We further provide details on the time taken to detect and mitigate the attack. Our results show that RNN LSTM is a viable deep learning algorithm that can be applied in the detection and mitigation of DDoS in the SDN controller. Our proposed model produced an accuracy of 89.63%, which outperformed linear-based models such as SVM (86.85%) and Naive Bayes (82.61%). Although KNN, which is a linear-based model, outperformed our proposed model (achieving an accuracy of 99.4%), our proposed model provides a good trade-off between precision and recall, which makes it suitable for DDoS classification. In addition, it was realized that the split ratio of the training and testing datasets can give different results in the performance of a deep learning algorithm used in a specific work. The model achieved the best performance when a split of 70/30 was used in comparison to 80/20 and 60/40 split ratios.},
DOI = {10.3390/technologies9010014}
}



@Article{s21041302,
AUTHOR = {Solano-Rojas, Braulio and Villalón-Fonseca, Ricardo},
TITLE = {A Low-Cost Three-Dimensional DenseNet Neural Network for Alzheimer’s Disease Early Discovery},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1302},
URL = {https://www.mdpi.com/1424-8220/21/4/1302},
PubMedID = {33670317},
ISSN = {1424-8220},
ABSTRACT = {Alzheimer’s disease is the most prevalent dementia among the elderly population. Early detection is critical because it can help with future planning for those potentially affected. This paper uses a three-dimensional DenseNet architecture to detect Alzheimer’s disease in magnetic resonance imaging. Our work is restricted to the use of freely available tools. We constructed a deep neural network classifier with metrics of 0.86¯ mean accuracy, 0.86¯ mean sensitivity (micro-average), 0.86¯ mean specificity (micro-average), and 0.91¯ area under the receiver operating characteristic curve (micro-average) for the task of discriminating between five different disease stages or classes. The use of tools available for free ensures the reproducibility of the study and the applicability of the classification system in developing countries.},
DOI = {10.3390/s21041302}
}



@Article{atmos12020261,
AUTHOR = {Jeong, Chang Hoo and Kim, Wonsu and Joo, Wonkyun and Jang, Dongmin and Yi, Mun Yong},
TITLE = {Enhancing the Encoding-Forecasting Model for Precipitation Nowcasting by Putting High Emphasis on the Latest Data of the Time Step},
JOURNAL = {Atmosphere},
VOLUME = {12},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {261},
URL = {https://www.mdpi.com/2073-4433/12/2/261},
ISSN = {2073-4433},
ABSTRACT = {Nowcasting is an important technique for weather forecasting because sudden weather changes significantly affect human life. The encoding-forecasting model, which is a state-of-the-art architecture in the field of data-driven radar extrapolation, does not particularly focus on the latest data when forecasting natural phenomena. This paper proposes a weighted broadcasting method that emphasizes the latest data of the time step to improve the nowcasting performance. This weighted broadcasting method allows the most recent rainfall patterns to have a greater impact on the forecasting network by extending the architecture of the existing encoding-forecasting model. Experimental results show that the proposed model is 1.74% and 2.20% better than the existing encoding-forecasting model in terms of mean absolute error and critical success index, respectively. In the case of heavy rainfall with an intensity of 30 mm/h or higher, the proposed model was more than 30% superior to the existing encoding-forecasting model. Therefore, applying the weighted broadcasting method, which explicitly places a high emphasis on the latest information, to the encoding-forecasting model is considered as an improvement that is applicable to the state-of-the-art implementation of data-driven radar-based precipitation nowcasting.},
DOI = {10.3390/atmos12020261}
}



@Article{en14041045,
AUTHOR = {Bhatt, Dhowmya and D, Danalakshmi and Hariharasudan, A. and Lis, Marcin and Grabowska, Marlena},
TITLE = {Forecasting of Energy Demands for Smart Home Applications},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1045},
URL = {https://www.mdpi.com/1996-1073/14/4/1045},
ISSN = {1996-1073},
ABSTRACT = {The utilization of energy is on the rise in current trends due to increasing consumptions by households. Smart buildings, on the other hand, aim to optimize energy, and hence, the aim of the study is to forecast the cost of energy consumption in smart buildings by effectively addressing the minimal energy consumption. However, smart buildings are restricted, with limited power access and capacity associated with Heating, Ventilation and Air Conditioning (HVAC) units. It further suffers from low communication capability due to device limitations. In this paper, a balanced deep learning architecture is used to offer solutions to address these constraints. The deep learning algorithm considers three constraints, such as a multi-objective optimization problem and a fitness function, to resolve the price management problem and high-level energy consumption in HVAC systems. The study analyzes and optimizes the consumption of power in smart buildings by the HVAC systems in terms of power loss, price management and reactive power. Experiments are conducted over various scenarios to check the integrity of the system over various smart buildings and in high-rise buildings. The results are compared in terms of various HVAC devices on various metrics and communication protocols, where the proposed system is considered more effective than other methods. The results of the Li-Fi communication protocols show improved results compared to the other communication protocols.},
DOI = {10.3390/en14041045}
}



@Article{app11041900,
AUTHOR = {Aljohani, Sarah L. and Alenazi, Mohammed J. F.},
TITLE = {MPResiSDN: Multipath Resilient Routing Scheme for SDN-Enabled Smart Cities Networks},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1900},
URL = {https://www.mdpi.com/2076-3417/11/4/1900},
ISSN = {2076-3417},
ABSTRACT = {The number of smart cities is increasing rapidly around the world with the continuous increase of governments’ interest in exploiting Information and Communication Technologies (ICT) to solve issues arising from rapid urbanization. Most smart city services rely fundamentally on ubiquitous sensing, enabled by Wireless Sensor Network (WSN) technologies. However, WSNs in smart cities are naturally vulnerable to unavoidable external challenges like storms, fires, and other natural disasters. Such challenges pose a great threat to smart city infrastructure, including WSNs, as they might affect network connectivity or result in complete blockages of network services. However, some particular smart city services are critical, to the point where they must remain available in all situations, especially during disasters; to monitor the disaster and obtain sensory information needed for controlling it, limiting its danger, or for decision-making during rescue operations. Thus, it is crucial to design a smart-city network to maintain connectivity against such challenges. In this paper, we introduce MPResiSDN, a MultiPath Resilient routing system based on Software Defined Networking (SDN). The system introduced exploits SDN’s capabilities and aided-multipath routing to reactively provide connectivity in smart city networks in the presence of challenges. We evaluated our proposed system under simulations of different natural disasters. The results demonstrate that the system improved data delivery under the challenges by as much as 100% compared to the Spanning Tree Protocol when a suitable value for k diverse paths was selected.},
DOI = {10.3390/app11041900}
}



@Article{atmos12030312,
AUTHOR = {Iskandaryan, Ditsuhi and Ramos, Francisco and Trilles, Sergio},
TITLE = {Features Exploration from Datasets Vision in Air Quality Prediction Domain},
JOURNAL = {Atmosphere},
VOLUME = {12},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {312},
URL = {https://www.mdpi.com/2073-4433/12/3/312},
ISSN = {2073-4433},
ABSTRACT = {Air pollution and its consequences are negatively impacting on the world population and the environment, which converts the monitoring and forecasting air quality techniques as essential tools to combat this problem. To predict air quality with maximum accuracy, along with the implemented models and the quantity of the data, it is crucial also to consider the dataset types. This study selected a set of research works in the field of air quality prediction and is concentrated on the exploration of the datasets utilised in them. The most significant findings of this research work are: (1) meteorological datasets were used in 94.6% of the papers leaving behind the rest of the datasets with a big difference, which is complemented with others, such as temporal data, spatial data, and so on; (2) the usage of various datasets combinations has been commenced since 2009; and (3) the utilisation of open data have been started since 2012, 32.3% of the studies used open data, and 63.4% of the studies did not provide the data.},
DOI = {10.3390/atmos12030312}
}



@Article{electronics10050578,
AUTHOR = {Chataut, Robin and Akl, Robert and Dey, Utpal Kumar and Robaei, Mohammadreza},
TITLE = {SSOR Preconditioned Gauss-Seidel Detection and Its Hardware Architecture for 5G and beyond Massive MIMO Networks},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {578},
URL = {https://www.mdpi.com/2079-9292/10/5/578},
ISSN = {2079-9292},
ABSTRACT = {With the limitedness of the sub-6 GHz bandwidth, the world is exploring a thrilling wireless technology known as massive MIMO. This wireless access technology is swiftly becoming key for 5G, B5G, and 6G network deployment. The massive MIMO system brings together antennas at both base stations and the user terminals to provide high spectral service. Despite the fact that massive MIMO offers astronomical benefits such as low latency, high data rate, improved array gain, and far better reliability, it faces several implementation challenges due to the hundreds of antennas at the base station. The signal detection at the base station during the uplink is one of the critical issues in this technology. Detection of user signal becomes computationally complex with a multitude of antennas present in the massive MIMO systems. This paper proposes a novel preconditioned and accelerated Gauss–Siedel algorithm referred to as Symmetric Successive Over-relaxation Preconditioned Gauss-Seidel (SSORGS). The proposed algorithm will address the signal detection challenges associated with massive MIMO technology. Furthermore, we enhance the convergence rate of the proposed algorithm by introducing a novel Symmetric Successive Over-relaxation preconditioner (SSOR) scheme and an initialization scheme based on the instantaneous channel condition between the base station and the user. The simulation results show that the proposed algorithm referred to as Symmetric Successive Over-relaxation Preconditioned Gauss-Seidel (SSORGS) provides optimal BER performance. At BER =10−3, over the range of SNR, the SSORGS algorithm performs better than the traditional algorithms. Additionally, the proposed algorithm is computationally more efficient than the traditional algorithms. Furthermore, we designed a comprehensive hardware architecture for the SSORGS algorithm to find the interrelated components necessary to build the actual physical system.},
DOI = {10.3390/electronics10050578}
}



@Article{math9050508,
AUTHOR = {Almagrabi, Alaa Omran and Ali, Rashid and Alghazzawi, Daniyal and AlBarakati, Abdullah and Khurshaid, Tahir},
TITLE = {A Poisson Process-Based Random Access Channel for 5G and Beyond Networks},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {508},
URL = {https://www.mdpi.com/2227-7390/9/5/508},
ISSN = {2227-7390},
ABSTRACT = {The 5th generation (5G) wireless networks propose to address a variety of usage scenarios, such as enhanced mobile broadband (eMBB), massive machine-type communications (mMTC), and ultra-reliable low-latency communications (URLLC). Due to the exponential increase in the user equipment (UE) devices of wireless communication technologies, 5G and beyond networks (B5G) expect to support far higher user density and far lower latency than currently deployed cellular technologies, like long-term evolution-Advanced (LTE-A). However, one of the critical challenges for B5G is finding a clever way for various channel access mechanisms to maintain dense UE deployments. Random access channel (RACH) is a mandatory procedure for the UEs to connect with the evolved node B (eNB). The performance of the RACH directly affects the performance of the entire network. Currently, RACH uses a uniform distribution-based (UD) random access to prevent a possible network collision among multiple UEs attempting to access channel resources. However, in a UD-based channel access, every UE has an equal chance to choose a similar contention preamble close to the expected value, which causes an increase in the collision among the UEs. Therefore, in this paper, we propose a Poisson process-based RACH (2PRACH) alternative to a UD-based RACH. A Poisson process-based distribution, such as exponential distribution, disperses the random preambles between two bounds in a Poisson point method, where random variables occur continuously and independently with a constant parametric rate. In this way, our proposed 2PRACH approach distributes the UEs in a probability distribution of a parametric collection. Simulation results show that the shift of RACH from UD-based channel access to a Poisson process-based distribution enhances the reliability and lowers the network’s latency.},
DOI = {10.3390/math9050508}
}



@Article{en14051380,
AUTHOR = {Mohammadi, Fazel},
TITLE = {Emerging Challenges in Smart Grid Cybersecurity Enhancement: A Review},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {1380},
URL = {https://www.mdpi.com/1996-1073/14/5/1380},
ISSN = {1996-1073},
ABSTRACT = {In this paper, a brief survey of measurable factors affecting the adoption of cybersecurity enhancement methods in the smart grid is provided. From a practical point of view, it is a key point to determine to what degree the cyber resilience of power systems can be improved using cost-effective resilience enhancement methods. Numerous attempts have been made to the vital resilience of the smart grid against cyber-attacks. The recently proposed cybersecurity methods are considered in this paper, and their accuracies, computational time, and robustness against external factors in detecting and identifying False Data Injection (FDI) attacks are evaluated. There is no all-inclusive solution to fit all power systems requirements. Therefore, the recently proposed cyber-attack detection and identification methods are quantitatively compared and discussed.},
DOI = {10.3390/en14051380}
}



@Article{s21051809,
AUTHOR = {Malhotra, Parushi and Singh, Yashwant and Anand, Pooja and Bangotra, Deep Kumar and Singh, Pradeep Kumar and Hong, Wei-Chiang},
TITLE = {Internet of Things: Evolution, Concerns and Security Challenges},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {1809},
URL = {https://www.mdpi.com/1424-8220/21/5/1809},
PubMedID = {33807724},
ISSN = {1424-8220},
ABSTRACT = {The escalated growth of the Internet of Things (IoT) has started to reform and reshape our lives. The deployment of a large number of objects adhered to the internet has unlocked the vision of the smart world around us, thereby paving a road towards automation and humongous data generation and collection. This automation and continuous explosion of personal and professional information to the digital world provides a potent ground to the adversaries to perform numerous cyber-attacks, thus making security in IoT a sizeable concern. Hence, timely detection and prevention of such threats are pre-requisites to prevent serious consequences. The survey conducted provides a brief insight into the technology with prime attention towards the various attacks and anomalies and their detection based on the intelligent intrusion detection system (IDS). The comprehensive look-over presented in this paper provides an in-depth analysis and assessment of diverse machine learning and deep learning-based network intrusion detection system (NIDS). Additionally, a case study of healthcare in IoT is presented. The study depicts the architecture, security, and privacy issues and application of learning paradigms in this sector. The research assessment is finally concluded by listing the results derived from the literature. Additionally, the paper discusses numerous research challenges to allow further rectifications in the approaches to deal with unusual complications.},
DOI = {10.3390/s21051809}
}



@Article{s21061960,
AUTHOR = {Fotouhi, Azade and Ding, Ming and Hassan, Mahbub},
TITLE = {Deep Q-Learning for Two-Hop Communications of Drone Base Stations},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1960},
URL = {https://www.mdpi.com/1424-8220/21/6/1960},
PubMedID = {33799546},
ISSN = {1424-8220},
ABSTRACT = {In this paper, we address the application of the flying Drone Base Stations (DBS) in order to improve the network performance. Given the high degrees of freedom of a DBS, it can change its position and adapt its trajectory according to the users movements and the target environment. A two-hop communication model, between an end-user and a macrocell through a DBS, is studied in this work. We propose Q-learning and Deep Q-learning based solutions to optimize the drone’s trajectory. Simulation results show that, by employing our proposed models, the drone can autonomously fly and adapts its mobility according to the users’ movements. Additionally, the Deep Q-learning model outperforms the Q-learning model and can be applied in more complex environments.},
DOI = {10.3390/s21061960}
}



@Article{s21061995,
AUTHOR = {Sun, Danshi and Wei, Erhu and Ma, Zhuoxi and Wu, Chenxi and Xu, Shiyi},
TITLE = {Optimized CNNs to Indoor Localization through BLE Sensors Using Improved PSO},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1995},
URL = {https://www.mdpi.com/1424-8220/21/6/1995},
PubMedID = {33808972},
ISSN = {1424-8220},
ABSTRACT = {Indoor navigation has attracted commercial developers and researchers in the last few decades. The development of localization tools, methods and frameworks enables current communication services and applications to be optimized by incorporating location data. For clinical applications such as workflow analysis, Bluetooth Low Energy (BLE) beacons have been employed to map the positions of individuals in indoor environments. To map locations, certain existing methods use the received signal strength indicator (RSSI). Devices need to be configured to allow for dynamic interference patterns when using the RSSI sensors to monitor indoor positions. In this paper, our objective is to explore an alternative method for monitoring a moving user’s indoor position using BLE sensors in complex indoor building environments. We developed a Convolutional Neural Network (CNN) based positioning model based on the 2D image composed of the received number of signals indicator from both x and y-axes. In this way, like a pixel, we interact with each 10 × 10 matrix holding the spatial information of coordinates and suggest the possible shift of a sensor, adding a sensor and removing a sensor. To develop CNN we adopted a neuro-evolution approach to optimize and create several layers in the network dynamically, through enhanced Particle Swarm Optimization (PSO). For the optimization of CNN, the global best solution obtained by PSO is directly given to the weights of each layer of CNN. In addition, we employed dynamic inertia weights in the PSO, instead of a constant inertia weight, to maintain the CNN layers’ length corresponding to the RSSI signals from BLE sensors. Experiments were conducted in a building environment where thirteen beacon devices had been installed in different locations to record coordinates. For evaluation comparison, we further adopted machine learning and deep learning algorithms for predicting a user’s location in an indoor environment. The experimental results indicate that the proposed optimized CNN-based method shows high accuracy (97.92% with 2.8% error) for tracking a moving user’s locations in a complex building without complex calibration as compared to other recent methods.},
DOI = {10.3390/s21061995}
}



@Article{logistics5010017,
AUTHOR = {Muñoz-Villamizar, Andrés and Solano-Charris, Elyn L. and Reyes-Rubiano, Lorena and Faulin, Javier},
TITLE = {Measuring Disruptions in Last-Mile Delivery Operations},
JOURNAL = {Logistics},
VOLUME = {5},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {17},
URL = {https://www.mdpi.com/2305-6290/5/1/17},
ISSN = {2305-6290},
ABSTRACT = {The rapid growth of urbanisation and e-commerce has increased the number of home deliveries that need to be made in retail operations. Consequently, there is also an increase in unexpected incidents, such as adverse traffic, unavailability of parking space, and vehicle breakdowns. These disruptions result in delays, higher costs, and lower service levels in the last-mile delivery operation. Motivated by free, innovative, and efficient tools, such as the Google application programming interface (API) and Google OR, we built a model to measure the impact of disruptions in the last-mile delivery operation. Our model considers customers’ geographic information, speed estimation between nodes, routing optimisation, and disruption evaluation. Disruptions are considered here as external factors such as accidents and road works that imply the closure of or slow access to certain roads. Computational experiments, based on a set of real data from three different cities around the world, which contrast in size and characteristics (i.e., Boston, US; Bogotá, Colombia; and Pamplona, Spain), were conducted to validate our approach. The tests consider 50 different instances of up to 100 customers per city and analyse the impact of disruptions in terms of travelled time and distance. Our results provide managerial insights for key stakeholders (i.e., carriers, consumers, and government) to define policies and development plans that improve the resilience and capabilities of cities’ transportation systems.},
DOI = {10.3390/logistics5010017}
}



@Article{s21062143,
AUTHOR = {Paiva, Sara and Ahad, Mohd Abdul and Tripathi, Gautami and Feroz, Noushaba and Casalino, Gabriella},
TITLE = {Enabling Technologies for Urban Smart Mobility: Recent Trends, Opportunities and Challenges},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2143},
URL = {https://www.mdpi.com/1424-8220/21/6/2143},
PubMedID = {33803903},
ISSN = {1424-8220},
ABSTRACT = {The increasing population across the globe makes it essential to link smart and sustainable city planning with the logistics of transporting people and goods, which will significantly contribute to how societies will face mobility in the coming years. The concept of smart mobility emerged with the popularity of smart cities and is aligned with the sustainable development goals defined by the United Nations. A reduction in traffic congestion and new route optimizations with reduced ecological footprint are some of the essential factors of smart mobility; however, other aspects must also be taken into account, such as the promotion of active mobility and inclusive mobility, encouraging the use of other types of environmentally friendly fuels and engagement with citizens. The Internet of Things (IoT), Artificial Intelligence (AI), Blockchain and Big Data technology will serve as the main entry points and fundamental pillars to promote the rise of new innovative solutions that will change the current paradigm for cities and their citizens. Mobility-as-a-service, traffic flow optimization, the optimization of logistics and autonomous vehicles are some of the services and applications that will encompass several changes in the coming years with the transition of existing cities into smart cities. This paper provides an extensive review of the current trends and solutions presented in the scope of smart mobility and enabling technologies that support it. An overview of how smart mobility fits into smart cities is provided by characterizing its main attributes and the key benefits of using smart mobility in a smart city ecosystem. Further, this paper highlights other various opportunities and challenges related to smart mobility. Lastly, the major services and applications that are expected to arise in the coming years within smart mobility are explored with the prospective future trends and scope.},
DOI = {10.3390/s21062143}
}



@Article{s21062152,
AUTHOR = {Yaïci, Wahiba and Krishnamurthy, Karthik and Entchev, Evgueniy and Longo, Michela},
TITLE = {Recent Advances in Internet of Things (IoT) Infrastructures for Building Energy Systems: A Review},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2152},
URL = {https://www.mdpi.com/1424-8220/21/6/2152},
PubMedID = {33808558},
ISSN = {1424-8220},
ABSTRACT = {This paper summarises a literature review on the applications of Internet of Things (IoT) with the aim of enhancing building energy use and reducing greenhouse gas emissions (GHGs). A detailed assessment of contemporary practical reviews and works was conducted to understand how different IoT systems and technologies are being developed to increase energy efficiencies in both residential and commercial buildings. Most of the reviewed works were invariably related to the dilemma of efficient heating systems in buildings. Several features of the central components of IoT, namely, the hardware and software needed for building controls, are analysed. Common design factors across the many IoT systems comprise the selection of sensors and actuators and their powering techniques, control strategies for collecting information and activating appliances, monitoring of actual data to forecast prospect energy consumption and communication methods amongst IoT components. Some building energy applications using IoT are provided. It was found that each application presented has the potential for significant energy reduction and user comfort improvement. This is confirmed in two case studies summarised, which report the energy savings resulting from implementing IoT systems. Results revealed that a few elements are user-specific that need to be considered in the decision processes. Last, based on the studies reviewed, a few aspects of prospective research were recommended.},
DOI = {10.3390/s21062152}
}



@Article{app11072925,
AUTHOR = {Cortés Gallardo Medina, Edgar and Velazquez Espitia, Victor Miguel and Chípuli Silva, Daniela and Fernández Ruiz de las Cuevas, Sebastián and Palacios Hirata, Marco and Zhu Chen, Alfredo and González González, José Ángel and Bustamante-Bello, Rogelio and Moreno-García, Carlos Francisco},
TITLE = {Object Detection, Distributed Cloud Computing and Parallelization Techniques for Autonomous Driving Systems},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {2925},
URL = {https://www.mdpi.com/2076-3417/11/7/2925},
ISSN = {2076-3417},
ABSTRACT = {Autonomous vehicles are increasingly becoming a necessary trend towards building the smart cities of the future. Numerous proposals have been presented in recent years to tackle particular aspects of the working pipeline towards creating a functional end-to-end system, such as object detection, tracking, path planning, sentiment or intent detection, amongst others. Nevertheless, few efforts have been made to systematically compile all of these systems into a single proposal that also considers the real challenges these systems will have on the road, such as real-time computation, hardware capabilities, etc. This paper reviews the latest techniques towards creating our own end-to-end autonomous vehicle system, considering the state-of-the-art methods on object detection, and the possible incorporation of distributed systems and parallelization to deploy these methods. Our findings show that while techniques such as convolutional neural networks, recurrent neural networks, and long short-term memory can effectively handle the initial detection and path planning tasks, more efforts are required to implement cloud computing to reduce the computational time that these methods demand. Additionally, we have mapped different strategies to handle the parallelization task, both within and between the networks.},
DOI = {10.3390/app11072925}
}



@Article{electronics10070799,
AUTHOR = {Castillo Ossa, Luis Fernando and Chamoso, Pablo and Arango-López, Jeferson and Pinto-Santos, Francisco and Isaza, Gustavo Adolfo and Santa-Cruz-González, Cristina and Ceballos-Marquez, Alejandro and Hernández, Guillermo and Corchado, Juan M.},
TITLE = {A Hybrid Model for COVID-19 Monitoring and Prediction},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {799},
URL = {https://www.mdpi.com/2079-9292/10/7/799},
ISSN = {2079-9292},
ABSTRACT = {COVID-19 is caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and has a case-fatality rate of 2–3%, with higher rates among elderly patients and patients with comorbidities. Radiologically, COVID-19 is characterised by multifocal ground-glass opacities, even for patients with mild disease. Clinically, patients with COVID-19 present respiratory symptoms, which are very similar to other respiratory virus infections. Our knowledge regarding the SARS-CoV-2 virus is still very limited. These facts make it vitally important to establish mechanisms that allow to model and predict the evolution of the virus and to analyze the spread of cases under different circumstances. The objective of this article is to present a model developed for the evolution of COVID in the city of Manizales, capital of the Department of Caldas, Colombia, focusing on the methodology used to allow its application to other cases, as well as on the monitoring tools developed for this purpose. This methodology is based on a hybrid model which combines the population dynamics of the SIR model of differential equations with extrapolations based on recurrent neural networks. This combination provides self-explanatory results in terms of a coefficient that fluctuates with the restraint measures, which may be further refined by expert rules that capture the expected changes in such measures.},
DOI = {10.3390/electronics10070799}
}



@Article{diagnostics11040607,
AUTHOR = {El-Rashidy, Nora and El-Sappagh, Shaker and Islam, S. M. Riazul and M. El-Bakry, Hazem and Abdelrazek, Samir},
TITLE = {Mobile Health in Remote Patient Monitoring for Chronic Diseases: Principles, Trends, and Challenges},
JOURNAL = {Diagnostics},
VOLUME = {11},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {607},
URL = {https://www.mdpi.com/2075-4418/11/4/607},
PubMedID = {33805471},
ISSN = {2075-4418},
ABSTRACT = {Chronic diseases are becoming more widespread. Treatment and monitoring of these diseases require going to hospitals frequently, which increases the burdens of hospitals and patients. Presently, advancements in wearable sensors and communication protocol contribute to enriching the healthcare system in a way that will reshape healthcare services shortly. Remote patient monitoring (RPM) is the foremost of these advancements. RPM systems are based on the collection of patient vital signs extracted using invasive and noninvasive techniques, then sending them in real-time to physicians. These data may help physicians in taking the right decision at the right time. The main objective of this paper is to outline research directions on remote patient monitoring, explain the role of AI in building RPM systems, make an overview of the state of the art of RPM, its advantages, its challenges, and its probable future directions. For studying the literature, five databases have been chosen (i.e., science direct, IEEE-Explore, Springer, PubMed, and science.gov). We followed the (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) PRISMA, which is a standard methodology for systematic reviews and meta-analyses. A total of 56 articles are reviewed based on the combination of a set of selected search terms including RPM, data mining, clinical decision support system, electronic health record, cloud computing, internet of things, and wireless body area network. The result of this study approved the effectiveness of RPM in improving healthcare delivery, increase diagnosis speed, and reduce costs. To this end, we also present the chronic disease monitoring system as a case study to provide enhanced solutions for RPMs.},
DOI = {10.3390/diagnostics11040607}
}



@Article{en14072004,
AUTHOR = {Izdebski, Mariusz and Jacyna, Marianna},
TITLE = {An Efficient Hybrid Algorithm for Energy Expenditure Estimation for Electric Vehicles in Urban Service Enterprises},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {2004},
URL = {https://www.mdpi.com/1996-1073/14/7/2004},
ISSN = {1996-1073},
ABSTRACT = {The article deals with the decision problems of estimating the energy expenditure of low-emission fleets in urban service companies due to environmental safety. One of the most important problems of today’s transport policy of many city authorities is the ecological safety of its inhabitants. The basic measures are aimed at banning high-emission vehicles from city centers and promoting the introduction of zero-emission vehicles, such as electric or hybrid cars. The authors proposed an original approach to the decision model, in which the energy expenditure from the use of electric vehicles was defined as a criterion function. The boundary conditions took into account limitations typical of an electric vehicle, e.g., maximum range or battery charging time. To solve the problem, the authors proposed an efficient hybrid algorithm based on ant colony algorithm and genetic algorithm. The verification was made for the example of a utility company serving a medium-sized city in the eastern part of Poland.},
DOI = {10.3390/en14072004}
}



@Article{jsan10020026,
AUTHOR = {Khosroabadi, Fariba and Fotouhi-Ghazvini, Faranak and Fotouhi, Hossein},
TITLE = {SCATTER: Service Placement in Real-Time Fog-Assisted IoT Networks},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {10},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {26},
URL = {https://www.mdpi.com/2224-2708/10/2/26},
ISSN = {2224-2708},
ABSTRACT = {Internet of Things (IoT) networks dependent on cloud services usually fail in supporting real-time applications as there is no response time guarantees. The fog computing paradigm has been used to alleviate this problem by executing tasks at the edge of the network, where it is possible to provide time bounds. One of the challenging topics in a fog-assisted architecture is to task placement on edge devices in order to obtain a good performance. The process of task mapping into computational devices is known as Service Placement Problem (SPP). In this paper, we present a heuristic algorithm to solve SPP, dubbed as clustering of fog devices and requirement-sensitive service first (SCATTER). We provide simulations using iFogSim toolkit and experimental evaluations using real hardware to verify the feasibility of the SCATTER algorithm by considering a smart home application. We compared the SCATTER with two existing works: edge-ward and cloud-only approaches, in terms of Quality of Service (QoS) metrics. Our experimental results have demonstrated that SCATTER approach has better performance compared with the edge-ward and cloud-only, 42.1% and 60.2% less application response times, 22% and 27.8% less network usage, 45% and 65.7% less average application loop delays, and 2.33% and 3.2% less energy consumption.},
DOI = {10.3390/jsan10020026}
}



@Article{electronics10080880,
AUTHOR = {Imran and Ghaffar, Zeba and Alshahrani, Abdullah and Fayaz, Muhammad and Alghamdi, Ahmed Mohammed and Gwak, Jeonghwan},
TITLE = {A Topical Review on Machine Learning, Software Defined Networking, Internet of Things Applications: Research Limitations and Challenges},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {880},
URL = {https://www.mdpi.com/2079-9292/10/8/880},
ISSN = {2079-9292},
ABSTRACT = {In recent years, rapid development has been made to the Internet of Things communication technologies, infrastructure, and physical resources management. These developments and research trends address challenges such as heterogeneous communication, quality of service requirements, unpredictable network conditions, and a massive influx of data. One major contribution to the research world is in the form of software-defined networking applications, which aim to deploy rule-based management to control and add intelligence to the network using high-level policies to have integral control of the network without knowing issues related to low-level configurations. Machine learning techniques coupled with software-defined networking can make the networking decision more intelligent and robust. The Internet of Things application has recently adopted virtualization of resources and network control with software-defined networking policies to make the traffic more controlled and maintainable. However, the requirements of software-defined networking and the Internet of Things must be aligned to make the adaptations possible. This paper aims to discuss the possible ways to make software-defined networking enabled Internet of Things application and discusses the challenges solved using the Internet of Things leveraging the software-defined network. We provide a topical survey of the application and impact of software-defined networking on the Internet of things networks. We also study the impact of machine learning techniques applied to software-defined networking and its application perspective. The study is carried out from the different perspectives of software-based Internet of Things networks, including wide-area networks, edge networks, and access networks. Machine learning techniques are presented from the perspective of network resources management, security, classification of traffic, quality of experience, and quality of service prediction. Finally, we discuss challenges and issues in adopting machine learning and software-defined networking for the Internet of Things applications.},
DOI = {10.3390/electronics10080880}
}



@Article{en14082120,
AUTHOR = {Ji, Ying and Wang, Jianhui and Xu, Jiacan and Li, Donglin},
TITLE = {Data-Driven Online Energy Scheduling of a Microgrid Based on Deep Reinforcement Learning},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2120},
URL = {https://www.mdpi.com/1996-1073/14/8/2120},
ISSN = {1996-1073},
ABSTRACT = {The proliferation of distributed renewable energy resources (RESs) poses major challenges to the operation of microgrids due to uncertainty. Traditional online scheduling approaches relying on accurate forecasts become difficult to implement due to the increase of uncertain RESs. Although several data-driven methods have been proposed recently to overcome the challenge, they generally suffer from a scalability issue due to the limited ability to optimize high-dimensional continuous control variables. To address these issues, we propose a data-driven online scheduling method for microgrid energy optimization based on continuous-control deep reinforcement learning (DRL). We formulate the online scheduling problem as a Markov decision process (MDP). The objective is to minimize the operating cost of the microgrid considering the uncertainty of RESs generation, load demand, and electricity prices. To learn the optimal scheduling strategy, a Gated Recurrent Unit (GRU)-based network is designed to extract temporal features of uncertainty and generate the optimal scheduling decisions in an end-to-end manner. To optimize the policy with high-dimensional and continuous actions, proximal policy optimization (PPO) is employed to train the neural network-based policy in a data-driven fashion. The proposed method does not require any forecasting information on the uncertainty or a prior knowledge of the physical model of the microgrid. Simulation results using realistic power system data of California Independent System Operator (CAISO) demonstrate the effectiveness of the proposed method.},
DOI = {10.3390/en14082120}
}



@Article{s21082839,
AUTHOR = {Poudel, Sabitri and Moh, Sangman},
TITLE = {Hybrid Path Planning for Efficient Data Collection in UAV-Aided WSNs for Emergency Applications},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2839},
URL = {https://www.mdpi.com/1424-8220/21/8/2839},
PubMedID = {33920627},
ISSN = {1424-8220},
ABSTRACT = {In unmanned aerial vehicle (UAV)-aided wireless sensor networks (UWSNs), a UAV is employed as a mobile sink to gather data from sensor nodes. Incorporating UAV helps prolong the network lifetime and avoid the energy-hole problem faced by sensor networks. In emergency applications, timely data collection from sensor nodes and transferal of the data to the base station (BS) is a prime requisite. The timely and safe path of UAV is one of the fundamental premises for effective UWSN operations. It is essential and challenging to identify a suitable path in an environment comprising various obstacles and to ensure that the path can efficiently reach the target point. This paper proposes a hybrid path planning (HPP) algorithm for efficient data collection by assuring the shortest collision-free path for UAV in emergency environments. In the proposed HPP scheme, the probabilistic roadmap (PRM) algorithm is used to design the shortest trajectory map and the optimized artificial bee colony (ABC) algorithm to improve different path constraints in a three-dimensional environment. Our simulation results show that the proposed HPP outperforms the PRM and conventional ABC schemes significantly in terms of flight time, energy consumption, convergence time, and flight path.},
DOI = {10.3390/s21082839}
}



@Article{jsan10020028,
AUTHOR = {Pourroostaei Ardakani, Saeid},
TITLE = {MINDS: Mobile Agent Itinerary Planning Using Named Data Networking in Wireless Sensor Networks},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {10},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {28},
URL = {https://www.mdpi.com/2224-2708/10/2/28},
ISSN = {2224-2708},
ABSTRACT = {Mobile agents have the potential to offer benefits, as they are able to either independently or cooperatively move throughout networks and collect/aggregate sensory data samples. They are programmed to autonomously move and visit sensory data stations through optimal paths, which are established according to the application requirements. However, mobile agent routing protocols still suffer heavy computation/communication overheads, lack of route planning accuracy and long-delay mobile agent migrations. For this, mobile agent route planning protocols aim to find the best-fitted paths for completing missions (e.g., data collection) with minimised delay, maximised performance and minimised transmitted traffic. This article proposes a mobile agent route planning protocol for sensory data collection called MINDS. The key goal of this MINDS is to reduce network traffic, maximise data robustness and minimise delay at the same time. This protocol utilises the Hamming distance technique to partition a sensor network into a number of data-centric clusters. In turn, a named data networking approach is used to form the cluster-heads as a data-centric, tree-based communication infrastructure. The mobile agents utilise a modified version of the Depth-First Search algorithm to move through the tree infrastructure according to a hop-count-aware fashion. As the simulation results show, MINDS reduces path length, reduces network traffic and increases data robustness as compared with two conventional benchmarks (ZMA and TBID) in dense and large wireless sensor networks.},
DOI = {10.3390/jsan10020028}
}



@Article{jsan10020030,
AUTHOR = {Abujassar, Radwan S. and Yaseen, Husam and Al-Adwan, Ahmad Samed},
TITLE = {A Highly Effective Route for Real-Time Traffic Using an IoT Smart Algorithm for Tele-Surgery Using 5G Networks},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {10},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {30},
URL = {https://www.mdpi.com/2224-2708/10/2/30},
ISSN = {2224-2708},
ABSTRACT = {Nowadays, networks use many different paths to exchange data. However, our research will construct a reliable path in the networks among a huge number of nodes for use in tele-surgery using medical applications such as healthcare tracking applications, including tele-surgery which lead to optimizing medical quality of service (m-QoS) during the COVID-19 situation. Many people could not travel due to the current issues, for fear of spreading the covid-19 virus. Therefore, our paper will provide a very trusted and reliable method of communication between a doctor and his patient so that the latter can do his operation even from a far distance. The communication between the doctor and his/her patient will be monitored by our proposed algorithm to make sure that the data will be received without delay. We test how we can invest buffer space that can be used efficiently to reduce delays between source and destination, avoiding loss of high-priority data packets. The results are presented in three stages. First, we show how to obtain the greatest possible reduction in rate variability when the surgeon begins an operation using live streaming. Second, the proposed algorithm reduces congestion on the determined path used for the online surgery. Third, we have evaluated the affection of optimal smoothing algorithm on the network parameters such as peak-to-mean ratio and delay to optimize m-QoS. We propose a new Smart-Rout Control algorithm (s-RCA) for creating a virtual smart path between source and destination to transfer the required data traffic between them, considering the number of hops and link delay. This provides a reliable connection that can be used in healthcare surgery to guarantee that all instructions are received without any delay, to be executed instantly. This idea can improve m-QoS in distance surgery, with trusted paths. The new s-RCA can be adapted with an existing routing protocol to track the primary path and monitor emergency packets received in node buffers, for direct forwarding via the demand path, with extended features.},
DOI = {10.3390/jsan10020030}
}



@Article{smartcities4020029,
AUTHOR = {Omitaomu, Olufemi A. and Niu, Haoran},
TITLE = {Artificial Intelligence Techniques in Smart Grid: A Survey},
JOURNAL = {Smart Cities},
VOLUME = {4},
YEAR = {2021},
NUMBER = {2},
PAGES = {548--568},
URL = {https://www.mdpi.com/2624-6511/4/2/29},
ISSN = {2624-6511},
ABSTRACT = {The smart grid is enabling the collection of massive amounts of high-dimensional and multi-type data about the electric power grid operations, by integrating advanced metering infrastructure, control technologies, and communication technologies. However, the traditional modeling, optimization, and control technologies have many limitations in processing the data; thus, the applications of artificial intelligence (AI) techniques in the smart grid are becoming more apparent. This survey presents a structured review of the existing research into some common AI techniques applied to load forecasting, power grid stability assessment, faults detection, and security problems in the smart grid and power systems. It also provides further research challenges for applying AI technologies to realize truly smart grid systems. Finally, this survey presents opportunities of applying AI to smart grid problems. The paper concludes that the applications of AI techniques can enhance and improve the reliability and resilience of smart grid systems.},
DOI = {10.3390/smartcities4020029}
}



@Article{electronics10091012,
AUTHOR = {Sharma, Himanshu and Haque, Ahteshamul and Blaabjerg, Frede},
TITLE = {Machine Learning in Wireless Sensor Networks for Smart Cities: A Survey},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1012},
URL = {https://www.mdpi.com/2079-9292/10/9/1012},
ISSN = {2079-9292},
ABSTRACT = {Artificial intelligence (AI) and machine learning (ML) techniques have huge potential to efficiently manage the automated operation of the internet of things (IoT) nodes deployed in smart cities. In smart cities, the major IoT applications are smart traffic monitoring, smart waste management, smart buildings and patient healthcare monitoring. The small size IoT nodes based on low power Bluetooth (IEEE 802.15.1) standard and wireless sensor networks (WSN) (IEEE 802.15.4) standard are generally used for transmission of data to a remote location using gateways. The WSN based IoT (WSN-IoT) design problems include network coverage and connectivity issues, energy consumption, bandwidth requirement, network lifetime maximization, communication protocols and state of the art infrastructure. In this paper, the authors propose machine learning methods as an optimization tool for regular WSN-IoT nodes deployed in smart city applications. As per the author’s knowledge, this is the first in-depth literature survey of all ML techniques in the field of low power consumption WSN-IoT for smart cities. The results of this unique survey article show that the supervised learning algorithms have been most widely used (61%) as compared to reinforcement learning (27%) and unsupervised learning (12%) for smart city applications.},
DOI = {10.3390/electronics10091012}
}



@Article{s21093092,
AUTHOR = {Yu, Hyona and Bae, Jihyun and Choi, Jiyeon and Kim, Hyungseok},
TITLE = {LUX: Smart Mirror with Sentiment Analysis for Mental Comfort},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {3092},
URL = {https://www.mdpi.com/1424-8220/21/9/3092},
PubMedID = {33946700},
ISSN = {1424-8220},
ABSTRACT = {As COVID-19 solidifies its presence in everyday life, the interest in mental health is growing, resulting in the necessity of sentiment analysis. A smart mirror is suitable for encouraging mental comfort due to its approachability and scalability as an in-home AI device. From the aspect of natural language processing (NLP), sentiment analysis for Korean lacks an emotion dataset regarding everyday conversation. Its significant differences from English in terms of language structure make implementation challenging. The proposed smart mirror LUX provides Korean text sentiment analysis with the deep learning model, which examines GRU, LSTM, CNN, Bi-LSTM, and Bi-GRU networks. There are four emotional labels: anger, sadness, neutral, and happiness. For each emotion, there are three possible interactive responses: reciting wise sayings, playing music, and sympathizing. The implemented smart mirror also includes more-typical functions, such as a wake-up prompt, a weather reporting function, a calendar, a news reporting function, and a clock.},
DOI = {10.3390/s21093092}
}



@Article{electronics10091068,
AUTHOR = {Memon, Imran and Hasan, Mohammad Kamrul and Shaikh, Riaz Ahmed and Nebhen, Jamel and Bakar, Khairul Azmi Abu and Hossain, Eklas and Tunio, Muhammad Hanif},
TITLE = {Energy-Efficient Fuzzy Management System for Internet of Things Connected Vehicular Ad Hoc Networks},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1068},
URL = {https://www.mdpi.com/2079-9292/10/9/1068},
ISSN = {2079-9292},
ABSTRACT = {Many algorithms use clustering to improve vehicular ad hoc network performance. The expected points of many of these approaches support multiple rounds of data to the roadside unit and constantly include clustering in every round of single-hop data transmission towards the road side unit; however, the clustering in every round maximizes the number of control messages and there could be the possibility of collision and decreases in network energy. Multi-hop transmission prolongs the cluster head node’s lifetime and boosts the network’s efficiency. Accordingly, this article proposes a new fuzzy-clustering-based routing algorithm to benefit from multi-hop transmission clustering simultaneously. This research has analyzed the limitation of clustering in each round, different algorithms were used to perform the clustering, and multi-hop routing was used to transfer the data of every cluster to the road side unit. The fuzzy logic was used to choose the head node of each cluster. Three parameters, (1) distance of each node, (2) remaining energy, and (3) number of neighbors of every node, were considered as fuzzy criteria. The results of this research were compared to various other algorithms in relation to parameters like dead node in every round, first node expire, half node expire, last node expire, and the network lifetime. The simulation results show that the proposed approach outperforms other methods. On the other hand, the vehicular ad hoc network (VANET) environment is vulnerable at the time of data transmission. The NS-2 software tool was used to simulate and evaluate the proposed fuzzy logic opportunistic routing’s performance results concerning end-to-end delay, packet delivery, and network throughput. We compare to the existing protocols, such as fuzzy Internet of Things (IoT), two fuzzy, and Fuzzy-Based Driver Monitoring System (FDMS). The performance comparison also emphasizes an effective utilization of the resources. Simulations on the highway environment show that the suggested protocol has an improved Quality of Service (QoS) efficiency compared to the above published methods in the literature.},
DOI = {10.3390/electronics10091068}
}



@Article{electronics10091104,
AUTHOR = {Popoola, Segun I. and Adebisi, Bamidele and Ande, Ruth and Hammoudeh, Mohammad and Atayero, Aderemi A.},
TITLE = {Memory-Efficient Deep Learning for Botnet Attack Detection in IoT Networks},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1104},
URL = {https://www.mdpi.com/2079-9292/10/9/1104},
ISSN = {2079-9292},
ABSTRACT = {Cyber attackers exploit a network of compromised computing devices, known as a botnet, to attack Internet-of-Things (IoT) networks. Recent research works have recommended the use of Deep Recurrent Neural Network (DRNN) for botnet attack detection in IoT networks. However, for high feature dimensionality in the training data, high network bandwidth and a large memory space will be needed to transmit and store the data, respectively in IoT back-end server or cloud platform for Deep Learning (DL). Furthermore, given highly imbalanced network traffic data, the DRNN model produces low classification performance in minority classes. In this paper, we exploit the joint advantages of Long Short-Term Memory Autoencoder (LAE), Synthetic Minority Oversampling Technique (SMOTE), and DRNN to develop a memory-efficient DL method, named LS-DRNN. The effectiveness of this method is evaluated with the Bot-IoT dataset. Results show that the LAE method reduced the dimensionality of network traffic features in the training set from 37 to 10, and this consequently reduced the memory space required for data storage by 86.49%. SMOTE method helped the LS-DRNN model to achieve high classification performance in minority classes, and the overall detection rate increased by 10.94%. Furthermore, the LS-DRNN model outperformed state-of-the-art models.},
DOI = {10.3390/electronics10091104}
}



@Article{en14092732,
AUTHOR = {Molokomme, Daisy Nkele and Chabalala, Chabalala S. and Bokoro, Pitshou N.},
TITLE = {Enhancement of Advanced Metering Infrastructure Performance Using Unsupervised K-Means Clustering Algorithm},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {2732},
URL = {https://www.mdpi.com/1996-1073/14/9/2732},
ISSN = {1996-1073},
ABSTRACT = {Data aggregation may be considered as the technique through which streams of data gathered from Smart Meters (SMs) can be processed and transmitted to a Utility Control Center (UCC) in a reliable and cost-efficient manner without compromising the Quality of Service (QoS) requirements. In a typical Smart Grid (SG) paradigm, the UCC is usually located far away from the consumers (SMs), which has led to a degradation in network performance. Although the data aggregation technique has been recognized as a favorable solution to optimize the network performance of the SG, the underlying issue to date is to determine the optimal locations for the Data Aggregation Points (DAPs), where network coverage and full connectivity for all SMs deployed within the network are achieved. In addition, the main concern of the aggregation technique is to minimize transmission and computational costs. In this sense, the number of DAPs deployed should be as minimal as possible while satisfying the QoS requirements of the SG. This paper presents a Neighborhood Area Network (NAN) placement scheme based on the unsupervised K-means clustering algorithm with silhouette index method to determine the efficient number of DAPs required under different SM densities and find the best locations for the deployment of DAPs. Poisson Point Process (PPP) has been deployed to model the locations of the SMs. The simulation results presented in this paper indicate that the NAN placement scheme based on the ageless unsupervised K-means clustering algorithm not only improves the accuracy in determining the number of DAPs required and their locations but may also improve the network performance significantly in terms of network coverage and full connectivity.},
DOI = {10.3390/en14092732}
}



@Article{s21103411,
AUTHOR = {Ostrowski, Bartłomiej and Pióro, Michał and Tomaszewski, Artur},
TITLE = {Multicast Traffic Throughput Maximization through Joint Dynamic Modulation and Coding Schemes Assignment, and Transmission Power Control in Wireless Sensor Networks},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {3411},
URL = {https://www.mdpi.com/1424-8220/21/10/3411},
PubMedID = {34068410},
ISSN = {1424-8220},
ABSTRACT = {The paper concerns multicast packet traffic throughput maximization in multi-hop wireless sensor networks with time division multiple access to radio channel. We assume that the modulation and coding schemes (MCSs) that are used by the (broadcasting) nodes as well as the transmission power of the nodes are adjustable. This leads to the main research question studied in this paper: to what extent traffic throughput can be increased by proper MCSs assignment and transmission power control (TPC) at the nodes? To answer this question, we introduce mixed-integer programming formulations for joint MCSs assignment and TPC optimization, together with a solution algorithm. Finally, we present a numerical study illustrating the considerations of the paper. The numerical results show a significant gain being achieved by proper MCSs assignment, which is further increased by applying TPC.},
DOI = {10.3390/s21103411}
}



@Article{atmos12050629,
AUTHOR = {Kim, Sun-Ho and Yoon, Young-Ran and Kim, Jeong-Won and Moon, Hyeun-Jun},
TITLE = {Novel Integrated and Optimal Control of Indoor Environmental Devices for Thermal Comfort Using Double Deep Q-Network},
JOURNAL = {Atmosphere},
VOLUME = {12},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {629},
URL = {https://www.mdpi.com/2073-4433/12/5/629},
ISSN = {2073-4433},
ABSTRACT = {Maintaining a pleasant indoor environment with low energy consumption is important for healthy and comfortable living in buildings. In previous studies, we proposed the integrated comfort control (ICC) algorithm, which integrates several indoor environmental control devices, including an air conditioner, a ventilation system, and a humidifier. The ICC algorithm is operated by simple on/off control to maintain indoor temperature and relative humidity within a defined comfort range. This simple control method can cause inefficient building operation because it does not reflect the changes in indoor–outdoor environmental conditions and the status of the control devices. To overcome this limitation, we suggest the artificial intelligence integrated comfort control (AI2CC) algorithm using a double deep Q-network(DDQN), which uses a data-driven approach to find the optimal control of several environmental control devices to maintain thermal comfort with low energy consumption. The suggested AI2CC showed a good ability to learn how to operate devices optimally to improve indoor thermal comfort while reducing energy consumption. Compared to the previous approach (ICC), the AI2CC reduced energy consumption by 14.8%, increased the comfort ratio by 6.4%, and decreased the time to reach the comfort zone by 54.1 min.},
DOI = {10.3390/atmos12050629}
}



@Article{smartcities4020040,
AUTHOR = {Englund, Cristofer and Aksoy, Eren Erdal and Alonso-Fernandez, Fernando and Cooney, Martin Daniel and Pashami, Sepideh and Åstrand, Björn},
TITLE = {AI Perspectives in Smart Cities and Communities to Enable Road Vehicle Automation and Smart Traffic Control},
JOURNAL = {Smart Cities},
VOLUME = {4},
YEAR = {2021},
NUMBER = {2},
PAGES = {783--802},
URL = {https://www.mdpi.com/2624-6511/4/2/40},
ISSN = {2624-6511},
ABSTRACT = {Smart cities and communities (SCC) constitute a new paradigm in urban development. SCC ideate a data-centered society aimed at improving efficiency by automating and optimizing activities and utilities. Information and communication technology along with Internet of Things enables data collection and with the help of artificial intelligence (AI) situation awareness can be obtained to feed the SCC actors with enriched knowledge. This paper describes AI perspectives in SCC and gives an overview of AI-based technologies used in traffic to enable road vehicle automation and smart traffic control. Perception, smart traffic control and driver modeling are described along with open research challenges and standardization to help introduce advanced driver assistance systems and automated vehicle functionality in traffic. To fully realize the potential of SCC, to create a holistic view on a city level, availability of data from different stakeholders is necessary. Further, though AI technologies provide accurate predictions and classifications, there is an ambiguity regarding the correctness of their outputs. This can make it difficult for the human operator to trust the system. Today there are no methods that can be used to match function requirements with the level of detail in data annotation in order to train an accurate model. Another challenge related to trust is explainability: models can have difficulty explaining how they came to certain conclusions, so it is difficult for humans to trust them.},
DOI = {10.3390/smartcities4020040}
}



@Article{en14102933,
AUTHOR = {Deltetto, Davide and Coraci, Davide and Pinto, Giuseppe and Piscitelli, Marco Savino and Capozzoli, Alfonso},
TITLE = {Exploring the Potentialities of Deep Reinforcement Learning for Incentive-Based Demand Response in a Cluster of Small Commercial Buildings},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {2933},
URL = {https://www.mdpi.com/1996-1073/14/10/2933},
ISSN = {1996-1073},
ABSTRACT = {Demand Response (DR) programs represent an effective way to optimally manage building energy demand while increasing Renewable Energy Sources (RES) integration and grid reliability, helping the decarbonization of the electricity sector. To fully exploit such opportunities, buildings are required to become sources of energy flexibility, adapting their energy demand to meet specific grid requirements. However, in most cases, the energy flexibility of a single building is typically too small to be exploited in the flexibility market, highlighting the necessity to perform analysis at a multiple-building scale. This study explores the economic benefits associated with the implementation of a Reinforcement Learning (RL) control strategy for the participation in an incentive-based demand response program of a cluster of commercial buildings. To this purpose, optimized Rule-Based Control (RBC) strategies are compared with a RL controller. Moreover, a hybrid control strategy exploiting both RBC and RL is proposed. Results show that the RL algorithm outperforms the RBC in reducing the total energy cost, but it is less effective in fulfilling DR requirements. The hybrid controller achieves a reduction in energy consumption and energy costs by respectively 7% and 4% compared to a manually optimized RBC, while fulfilling DR constraints during incentive-based events.},
DOI = {10.3390/en14102933}
}



@Article{electronics10101208,
AUTHOR = {Alonso, Francisco and Faus, Mireia and Esteban, Cristina and Useche, Sergio A.},
TITLE = {Is There a Predisposition towards the Use of New Technologies within the Traffic Field of Emerging Countries? The Case of the Dominican Republic},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {1208},
URL = {https://www.mdpi.com/2079-9292/10/10/1208},
ISSN = {2079-9292},
ABSTRACT = {Technological devices are becoming more and more integrated in the management and control of traffic in big cities. The population perceives the benefits provided by these systems, and, therefore, citizens usually have a favorable opinion of them. However, emerging countries, which have fewer available infrastructures, could present a certain lack of trust. The objective of this work is to detect the level of knowledge and predisposition towards the use of new technologies in the transportation field of the Dominican Republic. For this study, the National Survey on Mobility was administered to a sample of Dominican citizens, proportional to the ONE census and to sex, age and province. The knowledge of ITS topics, as well as the use of mobile applications for mobility, are scarce; however, there was a significant increase that can be observed in only one year. Moreover, technology is, in general, positively assessed for what concerns the improvement of the traffic field, even though there is a lack of predisposition to provide one’s personal data, which is necessary for these devices. The process of technological development in the country must be backed up by laws that protect the citizens’ privacy. Thus, technologies that can improve road safety, mobility and sustainability can be implemented in the country.},
DOI = {10.3390/electronics10101208}
}



@Article{smartcities4020042,
AUTHOR = {Elvas, Luís B. and Mataloto, Bruno Miguel and Martins, Ana Lúcia and Ferreira, João C.},
TITLE = {Disaster Management in Smart Cities},
JOURNAL = {Smart Cities},
VOLUME = {4},
YEAR = {2021},
NUMBER = {2},
PAGES = {819--839},
URL = {https://www.mdpi.com/2624-6511/4/2/42},
ISSN = {2624-6511},
ABSTRACT = {The smart city concept, in which data from different systems are available, contains a multitude of critical infrastructures. This data availability opens new research opportunities in the study of the interdependency between those critical infrastructures and cascading effects solutions and focuses on the smart city as a network of critical infrastructures. This paper proposes an integrated resilience system linking interconnected critical infrastructures in a smart city to improve disaster resilience. A data-driven approach is considered, using artificial intelligence and methods to minimize cascading effects and the destruction of failing critical infrastructures and their components (at a city level). The proposed approach allows rapid recovery of infrastructures’ service performance levels after disasters while keeping the coverage of the assessment of risks, prevention, detection, response, and mitigation of consequences. The proposed approach has the originality and the practical implication of providing a decision support system that handles the infrastructures that will support the city disaster management system—make the city prepare, adapt, absorb, respond, and recover from disasters by taking advantage of the interconnections between its various critical infrastructures to increase the overall resilience capacity. The city of Lisbon (Portugal) is used as a case to show the practical application of the approach.},
DOI = {10.3390/smartcities4020042}
}



@Article{en14102959,
AUTHOR = {Floris, Alessandro and Porcu, Simone and Girau, Roberto and Atzori, Luigi},
TITLE = {An IoT-Based Smart Building Solution for Indoor Environment Management and Occupants Prediction},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {2959},
URL = {https://www.mdpi.com/1996-1073/14/10/2959},
ISSN = {1996-1073},
ABSTRACT = {Smart buildings use Internet of Things (IoT) sensors for monitoring indoor environmental parameters, such as temperature, humidity, luminosity, and air quality. Due to the huge amount of data generated by these sensors, data analytics and machine learning techniques are needed to extract useful and interesting insights, which provide the input for the building optimization in terms of energy-saving, occupants’ health and comfort. In this paper, we propose an IoT-based smart building (SB) solution for indoor environment management, which aims to provide the following main functionalities: monitoring of the room environmental parameters; detection of the number of occupants in the room; a cloud platform where virtual entities collect the data acquired by the sensors and virtual super entities perform data analysis tasks using machine learning algorithms; a control dashboard for the management and control of the building. With our prototype, we collected data for 10 days, and we built two prediction models: a classification model that predicts the number of occupants based on the monitored environmental parameters (average accuracy of 99.5%), and a regression model that predicts the total volatile organic compound (TVOC) values based on the environmental parameters and the number of occupants (Pearson correlation coefficient of 0.939).},
DOI = {10.3390/en14102959}
}



@Article{electronics10101219,
AUTHOR = {Guru, Divya and Perumal, Supraja and Varadarajan, Vijayakumar},
TITLE = {Approaches towards Blockchain Innovation: A Survey and Future Directions},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {1219},
URL = {https://www.mdpi.com/2079-9292/10/10/1219},
ISSN = {2079-9292},
ABSTRACT = {A blockchain is a decentralized peer to peer platform which provides security services based on some key concepts, namely authentication, confidentiality, integrity and authorization. It is the process of recording and keeping track of the resources without the intervention of a centralized authority. This paper provides an overview of blockchains, the structure of blockchains, consensus algorithms, etc., It compares the algorithms based on their utility and limitations. Though blockchains provide secure communication, there are some minimal data leaks which are discussed. Various security issues in blockchains are discussed such as denial of service attacks, etc., In addition to security, some other blockchain challenges are presented like scalability, reliability, interoperability, privacy and consensus mechanisms for integration with AI, IoT and edge computing. This paper also explains about the importance of blockchains in the fields of smart healthcare, smart grid, and smart financial systems. Overall, this paper gives the glimpse of various protocols, algorithms, applications, challenges and opportunities that are found in the blockchain domain.},
DOI = {10.3390/electronics10101219}
}



@Article{app11114719,
AUTHOR = {Machado, Romulos da S. and Pires, Fabiano dos S. and Caldeira, Giovanni R. and Giuntini, Felipe T. and Santos, Flávia de S. and Fonseca, Paulo R.},
TITLE = {Towards Energy Efficiency in Data Centers: An Industrial Experience Based on Reuse and Layout Changes},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {4719},
URL = {https://www.mdpi.com/2076-3417/11/11/4719},
ISSN = {2076-3417},
ABSTRACT = {Data centers are widely recognized for demanding many energy resources. The greater the computational demand, the greater the use of resources operating together. Consequently, the greater the heat, the greater the need for cooling power, and the greater the energy consumption. In this context, this article aims to report an industrial experience of achieving energy efficiency in a data center through a new layout proposal, reuse of previously existing resources, and air conditioning. We used the primary resource to adopt a cold corridor confinement, the increase of the raised floor’s height, and a better direction of the cold airflow for the aspiration at the servers’ entrance. We reused the three legacy refrigeration machines from the old data center, and no new ones were purchased. In addition to 346 existing devices, 80 new pieces of equipment were added (between servers and network assets) as a load to be cooled. Even with the increase in the amount of equipment, the implementations contributed to energy efficiency compared to the old data center, still reducing approximately 41% of the temperature and, consequently, energy-saving.},
DOI = {10.3390/app11114719}
}



@Article{app11114741,
AUTHOR = {Otala, Jacqueline and Minard, Alden and Madraki, Golshan and Mousavian, Seyedamirabbas},
TITLE = {Graph-Based Modeling in Shop Scheduling Problems: Review and Extensions},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {4741},
URL = {https://www.mdpi.com/2076-3417/11/11/4741},
ISSN = {2076-3417},
ABSTRACT = {Graphs are powerful tools to model manufacturing systems and scheduling problems. The complexity of these systems and their scheduling problems has been substantially increased by the ongoing technological development. Thus, it is essential to generate sustainable graph-based modeling approaches to deal with these excessive complexities. Graphs employ nodes and edges to represent the relationships between jobs, machines, operations, etc. Despite the significant volume of publications applying graphs to shop scheduling problems, the literature lacks a comprehensive survey study. We proposed the first comprehensive review paper which (1) systematically studies the overview and the perspective of this field, (2) highlights the gaps and potential hotspots of the literature, and (3) suggests future research directions towards sustainable graphs modeling the new intelligent/complex systems. We carefully examined 143 peer-reviewed journal papers published from 2015 to 2020. About 70% of our dataset were published in top-ranked journals which confirms the validity of our data and can imply the importance of this field. After discussing our generic data collection methodology, we proposed categorizations over the properties of the scheduling problems and their solutions. Then, we discussed our novel categorization over the variety of graphs modeling scheduling problems. Finally, as the most important contribution, we generated a creative graph-based model from scratch to represent the gaps and hotspots of the literature accompanied with statistical analysis on our dataset. Our analysis showed a significant attention towards job shop systems (56%) and Un/Directed Graphs (52%) where edges can be either directed, or undirected, or both, Whereas 14% of our dataset applied only Undirected Graphs and 11% targeted hybrid systems, e.g., mixed shop, flexible, and cellular manufacturing systems, which shows potential future research directions.},
DOI = {10.3390/app11114741}
}



@Article{s21113638,
AUTHOR = {Tropea, Mauro and De Rango, Floriano and Nevigato, Nicolas and Bitonti, Luigi and Pupo, Francesco},
TITLE = {SCARE: A Novel Switching and Collision Avoidance pRocEss for Connected Vehicles Using Virtualization and Edge Computing Paradigm},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {3638},
URL = {https://www.mdpi.com/1424-8220/21/11/3638},
PubMedID = {34073726},
ISSN = {1424-8220},
ABSTRACT = {In this paper, some collision avoidance systems based on MEC in a VANET environment are proposed and investigated. Micro services at edge are considered to support service continuity in vehicle communication and advertising. This considered system makes use of cloud and edge computing, allowing to switch communication from edge to cloud server and vice versa when possible, trying to guarantee the required constraints and balancing the communication among the servers. Simulation results were used to evaluate the performance of three considered mechanisms: the first one considering only edge with load balancing, the second one using edge/cloud switching and the third one using edge with load balancing and collision avoidance advertising.},
DOI = {10.3390/s21113638}
}



@Article{data6060055,
AUTHOR = {Ciaburro, Giuseppe and Iannace, Gino},
TITLE = {Machine Learning-Based Algorithms to Knowledge Extraction from Time Series Data: A Review},
JOURNAL = {Data},
VOLUME = {6},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {55},
URL = {https://www.mdpi.com/2306-5729/6/6/55},
ISSN = {2306-5729},
ABSTRACT = {To predict the future behavior of a system, we can exploit the information collected in the past, trying to identify recurring structures in what happened to predict what could happen, if the same structures repeat themselves in the future as well. A time series represents a time sequence of numerical values observed in the past at a measurable variable. The values are sampled at equidistant time intervals, according to an appropriate granular frequency, such as the day, week, or month, and measured according to physical units of measurement. In machine learning-based algorithms, the information underlying the knowledge is extracted from the data themselves, which are explored and analyzed in search of recurring patterns or to discover hidden causal associations or relationships. The prediction model extracts knowledge through an inductive process: the input is the data and, possibly, a first example of the expected output, the machine will then learn the algorithm to follow to obtain the same result. This paper reviews the most recent work that has used machine learning-based techniques to extract knowledge from time series data.},
DOI = {10.3390/data6060055}
}



@Article{en14113060,
AUTHOR = {Navarro, Gustavo and Torres, Jorge and Blanco, Marcos and Nájera, Jorge and Santos-Herran, Miguel and Lafoz, Marcos},
TITLE = {Present and Future of Supercapacitor Technology Applied to Powertrains, Renewable Generation and Grid Connection Applications},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {3060},
URL = {https://www.mdpi.com/1996-1073/14/11/3060},
ISSN = {1996-1073},
ABSTRACT = {Energy storage systems (ESS) are becoming essential as a solution for troublesome industrial systems. This study focuses on the application of a type of ESS, a high-power technology known in the literature as supercapacitors or electric double layer capacitors (EDLC). This technology has had a huge impact during the last decade on research related to the electric traction drives, renewable sources and powergrids. Related to this aspect, this paper summarizes the most relevant scientific publications in the last five years that study the use of supercapacitor technology (SCs) in electric traction applications (drives for rail vehicles and drives for road vehicles), generation systems for renewable energy (wind, solar and wave energy), and connection systems to the electric grid (voltage and frequency regulation and microgrids). The technology based on EDLC and the practical aspects that must be taken into account in the op-eration of these systems in industrial applications are briefly described. For each of the aforementioned applications, it is described how the problems are solved by using the energy storage technology, drawing the solutions proposed by different authors. Special attention is paid to the control strategies when combining SCs with other technologies, such as batteries. As a summary, some conclusions are collected drawn from the publications analyzed, evaluating the aspects in which it is necessary to conduct further research in order to facilitate the integration of EDLC technology.},
DOI = {10.3390/en14113060}
}



@Article{s21113702,
AUTHOR = {Kulikajevas, Audrius and Maskeliūnas, Rytis and Damaševičius, Robertas and Wlodarczyk-Sielicka, Marta},
TITLE = {Auto-Refining Reconstruction Algorithm for Recreation of Limited Angle Humanoid Depth Data},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {3702},
URL = {https://www.mdpi.com/1424-8220/21/11/3702},
PubMedID = {34073427},
ISSN = {1424-8220},
ABSTRACT = {With the majority of research, in relation to 3D object reconstruction, focusing on single static synthetic object reconstruction, there is a need for a method capable of reconstructing morphing objects in dynamic scenes without external influence. However, such research requires a time-consuming creation of real world object ground truths. To solve this, we propose a novel three-staged deep adversarial neural network architecture capable of denoising and refining real-world depth sensor input for full human body posture reconstruction. The proposed network has achieved Earth Mover and Chamfer distances of 0.059 and 0.079 on synthetic datasets, respectively, which indicates on-par experimental results with other approaches, in addition to the ability of reconstructing from maskless real world depth frames. Additional visual inspection to the reconstructed pointclouds has shown that the suggested approach manages to deal with the majority of the real world depth sensor noise, with the exception of large deformities to the depth field.},
DOI = {10.3390/s21113702}
}



@Article{su13116165,
AUTHOR = {Kim, Jaekyeong and Choi, Ilyoung and Li, Qinglong},
TITLE = {Customer Satisfaction of Recommender System: Examining Accuracy and Diversity in Several Types of Recommendation Approaches},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {6165},
URL = {https://www.mdpi.com/2071-1050/13/11/6165},
ISSN = {2071-1050},
ABSTRACT = {Information technology and the popularity of mobile devices allow for various types of customer data, such as purchase history and behavior patterns, to be collected. As customer data accumulate, the demand for recommender systems that provide customized services to customers is growing. Global e-commerce companies offer recommender systems to gain a sustainable competitive advantage. Research on recommender systems has consistently suggested that customer satisfaction will be highest when the recommendation algorithm is accurate and recommends a diversity of items. However, few studies have investigated the impact of accuracy and diversity on customer satisfaction. In this research, we seek to identify the factors determining customer satisfaction when using the recommender system. To this end, we develop several recommender systems and measure their ability to deliver accurate and diverse recommendations and their ability to generate customer satisfaction with diverse data sets. The results show that accuracy and diversity positively affect customer satisfaction when applying a deep learning-based recommender system. By contrast, only accuracy positively affects customer satisfaction when applying traditional recommender systems. These results imply that developers or managers of recommender systems need to identify factors that further improve customer satisfaction with the recommender system and promote the sustainable development of e-commerce.},
DOI = {10.3390/su13116165}
}



@Article{buildings11060237,
AUTHOR = {Nazemi, Seyyed Danial and Jafari, Mohsen A. and Zaidan, Esmat},
TITLE = {An Incentive-Based Optimization Approach for Load Scheduling Problem in Smart Building Communities},
JOURNAL = {Buildings},
VOLUME = {11},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {237},
URL = {https://www.mdpi.com/2075-5309/11/6/237},
ISSN = {2075-5309},
ABSTRACT = {The impact of load growth on electricity peak demand is becoming a vital concern for utilities. To prevent the need to build new power plants or upgrade transmission lines, power companies are trying to design new demand response programs. These programs can reduce the peak demand and be beneficial for both energy consumers and suppliers. One of the most popular demand response programs is the building load scheduling for energy-saving and peak-shaving. This paper presents an autonomous incentive-based multi-objective nonlinear optimization approach for load scheduling problems (LSP) in smart building communities. This model’s objectives are three-fold: minimizing total electricity costs, maximizing assigned incentives for each customer, and minimizing inconvenience level. In this model, two groups of assets are considered: time-shiftable assets, including electronic appliances and plug-in electric vehicle (PEV) charging facilities, and thermal assets such as heating, ventilation, and air conditioning (HVAC) systems and electric water heaters. For each group, specific energy consumption and inconvenience level models were developed. The designed model assigned the incentives to the participants based on their willingness to reschedule their assets. The LSP is a discrete–continuous problem and is formulated based on a mixed-integer nonlinear programming approach. Zoutendijk’s method is used to solve the nonlinear optimization model. This formulation helps capture the building collaboration to achieve the objectives. Illustrative case studies are demonstrated to assess the proposed model’s effect on building communities consisting of residential and commercial buildings. The results show the efficiency of the proposed model in reducing the total energy cost as well as increasing the participants’ satisfaction. The findings also reveal that we can shave the peak demand by 53% and have a smooth aggregate load profile in a large-scale building community containing 500 residential and commercial buildings.},
DOI = {10.3390/buildings11060237}
}



@Article{su13116199,
AUTHOR = {Yousaf, Adnan and Asif, Rao Muhammad and Shakir, Mustafa and Rehman, Ateeq Ur and S. Adrees, Mohmmed},
TITLE = {An Improved Residential Electricity Load Forecasting Using a Machine-Learning-Based Feature Selection Approach and a Proposed Integration Strategy},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {6199},
URL = {https://www.mdpi.com/2071-1050/13/11/6199},
ISSN = {2071-1050},
ABSTRACT = {Load forecasting (LF) has become the main concern in decentralized power generation systems with the smart grid revolution in the 21st century. As an intriguing research topic, it facilitates generation systems by providing essential information for load scheduling, demand-side integration, and energy market pricing and reducing cost. An intelligent LF model of residential loads using a novel machine learning (ML)-based approach, achieved by assembling an integration strategy model in a smart grid context, is proposed. The proposed model improves the LF by optimizing the mean absolute percentage error (MAPE). The time-series-based autoregression schemes were carried out to collect historical data and set the objective functions of the proposed model. An algorithm consisting of seven different autoregression models was also developed and validated through a feedforward adaptive-network-based fuzzy inference system (ANFIS) model, based on the ML approach. Moreover, a binary genetic algorithm (BGA) was deployed for the best feature selection, and the best fitness score of the features was obtained with principal component analysis (PCA). A unique decision integration strategy is presented that led to a remarkably improved transformation in reducing MAPE. The model was tested using a one-year Pakistan Residential Electricity Consumption (PRECON) dataset, and the attained results verify that the proposed model obtained the best feature selection and achieved very promising values of MAPE of 1.70%, 1.77%, 1.80%, and 1.67% for summer, fall, winter, and spring seasons, respectively. The overall improvement percentage is 17%, which represents a substantial increase for small-scale decentralized generation units.},
DOI = {10.3390/su13116199}
}



@Article{su13116230,
AUTHOR = {Gutierrez-Franco, Edgar and Mejia-Argueta, Christopher and Rabelo, Luis},
TITLE = {Data-Driven Methodology to Support Long-Lasting Logistics and Decision Making for Urban Last-Mile Operations},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {6230},
URL = {https://www.mdpi.com/2071-1050/13/11/6230},
ISSN = {2071-1050},
ABSTRACT = {Last-mile operations in forward and reverse logistics are responsible for a large part of the costs, emissions, and times in supply chains. These operations have increased due to the growth of electronic commerce and direct-to-consumer strategies. We propose a novel data- and model-driven framework to support decision making for urban distribution. The methodology is composed of diverse, hybrid, and complementary techniques integrated by a decision support system. This approach focuses on key elements of megacities such as socio-demographic diversity, portfolio mix, logistics fragmentation, high congestion factors, and dense commercial areas. The methodological framework will allow decision makers to create early warning systems and, with the implementation of optimization, machine learning, and simulation models together, make the best utilization of resources. The advantages of the system include flexibility in decision making, social welfare, increased productivity, and reductions in cost and environmental impacts. A real-world illustrative example is presented under conditions in one of the most congested cities: the megacity of Bogota, Colombia. Data come from a retail organization operating in the city. A network of stakeholders is analyzed to understand the complex urban distribution. The execution of the methodology was capable of solving a complex problem reducing the number of vehicles utilized, increasing the resource capacity utilization, and reducing the cost of operations of the fleet, meeting all constraints. These constraints included the window of operations and accomplishing the total number of deliveries. Furthermore, the methodology could accomplish the learning function using deep reinforcement learning in reasonable computational times. This preliminary analysis shows the potential benefits, especially in understudied metropolitan areas from emerging markets, supporting a more effective delivery process, and encouraging proactive, dynamic decision making during the execution stage.},
DOI = {10.3390/su13116230}
}



@Article{app11115303,
AUTHOR = {Huh, Eui-Nam and Hossain, Md Imtiaz},
TITLE = {Brainware Computing: Concepts, Scopes and Challenges},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {5303},
URL = {https://www.mdpi.com/2076-3417/11/11/5303},
ISSN = {2076-3417},
ABSTRACT = {Over the decades, robotics technology has acquired sufficient advancement through the progression of 5G Internet, Artificial Intelligence (AI), Internet of Things (IoT), Cloud, and Edge Computing. Though nowadays, Cobot and Service Oriented Architecture (SOA) supported robots with edge computing paradigms have achieved remarkable performances in diverse applications, the existing SOA robotics technology fails to develop a multi-domain expert with high performing robots and demands improvement to Service-Oriented Brain, SOB (including AI model, driving service application and metadata) enabling robot for deploying brain and a new computing model with more scalability and flexibility. In this paper, instead of focusing on SOA and Robot as a Service (RaaS) model, we propose a novel computing architecture, addressed as Brainware Computing, for driving multiple domain-specific brains one-at-a-time in a single hardware robot according to the service, addressed as Brain as a Service (BaaS). In Brainware Computing, each robot can install and remove the virtual machine, which contains SOB and operating applications from the nearest edge cloud. Secondly, we provide an extensive explanation of the scope and possibilities of Brainware Computing. Finally, we demonstrate several challenges and opportunities and then concluded with future research directions in the field of Brainware Computing.},
DOI = {10.3390/app11115303}
}



@Article{app11125320,
AUTHOR = {Al-amri, Redhwan and Murugesan, Raja Kumar and Man, Mustafa and Abdulateef, Alaa Fareed and Al-Sharafi, Mohammed A. and Alkahtani, Ammar Ahmed},
TITLE = {A Review of Machine Learning and Deep Learning Techniques for Anomaly Detection in IoT Data},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {5320},
URL = {https://www.mdpi.com/2076-3417/11/12/5320},
ISSN = {2076-3417},
ABSTRACT = {Anomaly detection has gained considerable attention in the past couple of years. Emerging technologies, such as the Internet of Things (IoT), are known to be among the most critical sources of data streams that produce massive amounts of data continuously from numerous applications. Examining these collected data to detect suspicious events can reduce functional threats and avoid unseen issues that cause downtime in the applications. Due to the dynamic nature of the data stream characteristics, many unresolved problems persist. In the existing literature, methods have been designed and developed to evaluate certain anomalous behaviors in IoT data stream sources. However, there is a lack of comprehensive studies that discuss all the aspects of IoT data processing. Thus, this paper attempts to fill this gap by providing a complete image of various state-of-the-art techniques on the major problems and core challenges in IoT data. The nature of data, anomaly types, learning mode, window model, datasets, and evaluation criteria are also presented. Research challenges related to data evolving, feature-evolving, windowing, ensemble approaches, nature of input data, data complexity and noise, parameters selection, data visualizations, heterogeneity of data, accuracy, and large-scale and high-dimensional data are investigated. Finally, the challenges that require substantial research efforts and future directions are summarized.},
DOI = {10.3390/app11125320}
}



@Article{s21123968,
AUTHOR = {Pauca, Ovidiu and Maxim, Anca and Caruntu, Constantin-Florin},
TITLE = {Multivariable Optimisation for Waiting-Time Minimisation at Roundabout Intersections in a Cyber-Physical Framework},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {3968},
URL = {https://www.mdpi.com/1424-8220/21/12/3968},
PubMedID = {34207511},
ISSN = {1424-8220},
ABSTRACT = {The evolution of communication networks offers new possibilities for development in the automotive industry. Smart vehicles will benefit from the possibility of connecting with the infrastructure and from an extensive exchange of data between them. Furthermore, new control strategies can be developed that benefit the advantages of these communication networks. In this endeavour, the main purposes considered by the automotive industry and researchers from academia are defined by: (i) ensuring people’s safety; (ii) reducing the overall costs, and (iii) improving the traffic by maximising the fluidity. In this paper, a cyber-physical framework (CPF) to control the access of vehicles in roundabout intersections composed of two levels is proposed. Both levels correspond to the cyber part of the CPF, while the physical part is composed of the vehicles crossing the roundabout. The first level, i.e., the edge-computing layer, is based on an analytical solution that uses multivariable optimisation to minimise the waiting times of the vehicles entering a roundabout intersection and to ensure a safe crossing. The second level, i.e., the cloud-computing layer, stores information about the waiting times and trajectories of all the vehicles that cross the roundabout and uses them for long-term analysis and prediction. The simulated results show the efficacy of the proposed method, which can be easily implemented on an embedded device for real-time operation.},
DOI = {10.3390/s21123968}
}



@Article{su13126567,
AUTHOR = {Narvaez Rojas, Carolina and Alomia Peñafiel, Gustavo Adolfo and Loaiza Buitrago, Diego Fernando and Tavera Romero, Carlos Andrés},
TITLE = {Society 5.0: A Japanese Concept for a Superintelligent Society},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {6567},
URL = {https://www.mdpi.com/2071-1050/13/12/6567},
ISSN = {2071-1050},
ABSTRACT = {This document discusses the Japanese context of Society 5.0. Based on a society-centered approach, Society 5.0 seeks to take advantage of technological advances to finally solve the problems that currently threaten Japan, such as aging, birth rates and lack of competitiveness, among others. Additionally, another objective is to contribute to the progress of the country and develop the foundations for a better world, in which no individual can be excluded from the technological advances of our current society, to achieve this goal, the Sustainable Development Goals (SDG) have been developed. SDGs seek to assess the methods of use of modern technology and thus find the best strategies and tools to use it in a way that guarantees sustainability within the framework of a new society that demands constant renovations.},
DOI = {10.3390/su13126567}
}



@Article{en14123431,
AUTHOR = {Li, Lin and Coskun, Serdar and Wang, Jiaze and Fan, Youming and Zhang, Fengqi and Langari, Reza},
TITLE = {Velocity Prediction Based on Vehicle Lateral Risk Assessment and Traffic Flow: A Brief Review and Application Examples},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {3431},
URL = {https://www.mdpi.com/1996-1073/14/12/3431},
ISSN = {1996-1073},
ABSTRACT = {Forecasting future driving conditions such as acceleration, velocity, and driver behaviors can greatly contribute to safety, mobility, and sustainability issues in the development of new energy vehicles (NEVs). In this brief, a review of existing velocity prediction techniques is studied from the perspective of traffic flow and vehicle lateral dynamics for the first time. A classification framework for velocity prediction in NEVs is presented where various state-of-the-art approaches are put forward. Firstly, we investigate road traffic flow models, under which a driving-scenario-based assessment is introduced. Secondly, vehicle speed prediction methods for NEVs are given where an extensive discussion on traffic flow model classification based on traffic big data and artificial intelligence is carried out. Thirdly, the influence of vehicle lateral dynamics and correlation control methods for vehicle speed prediction are reviewed. Suitable applications of each approach are presented according to their characteristics. Future trends and questions in the development of NEVs from different angles are discussed. Finally, different from existing review papers, we introduce application examples, demonstrating the potential applications of the highlighted concepts in next-generation intelligent transportation systems. To sum up, this review not only gives the first comprehensive analysis and review of road traffic network, vehicle handling stability, and velocity prediction strategies, but also indicates possible applications of each method to prospective designers, where researchers and scholars can better choose the right method on velocity prediction in the development of NEVs.},
DOI = {10.3390/en14123431}
}



@Article{app11125523,
AUTHOR = {Ye, Qian and Lu, Minyan},
TITLE = {s2p: Provenance Research for Stream Processing System},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {5523},
URL = {https://www.mdpi.com/2076-3417/11/12/5523},
ISSN = {2076-3417},
ABSTRACT = {The main purpose of our provenance research for DSP (distributed stream processing) systems is to analyze abnormal results. Provenance for these systems is not nontrivial because of the ephemerality of stream data and instant data processing mode in modern DSP systems. Challenges include but are not limited to an optimization solution for avoiding excessive runtime overhead, reducing provenance-related data storage, and providing it in an easy-to-use fashion. Without any prior knowledge about which kinds of data may finally lead to the abnormal, we have to track all transformations in detail, which potentially causes hard system burden. This paper proposes s2p (Stream Process Provenance), which mainly consists of online provenance and offline provenance, to provide fine- and coarse-grained provenance in different precision. We base our design of s2p on the fact that, for a mature online DSP system, the abnormal results are rare, and the results that require a detailed analysis are even rarer. We also consider state transition in our provenance explanation. We implement s2p on Apache Flink named as s2p-flink and conduct three experiments to evaluate its scalability, efficiency, and overhead from end-to-end cost, throughput, and space overhead. Our evaluation shows that s2p-flink incurs a 13% to 32% cost overhead, 11% to 24% decline in throughput, and few additional space costs in the online provenance phase. Experiments also demonstrates the s2p-flink can scale well. A case study is presented to demonstrate the feasibility of the whole s2p solution.},
DOI = {10.3390/app11125523}
}



@Article{s21124153,
AUTHOR = {Signoretti, Gabriel and Silva, Marianne and Andrade, Pedro and Silva, Ivanovitch and Sisinni, Emiliano and Ferrari, Paolo},
TITLE = {An Evolving TinyML Compression Algorithm for IoT Environments Based on Data Eccentricity},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {4153},
URL = {https://www.mdpi.com/1424-8220/21/12/4153},
PubMedID = {34204300},
ISSN = {1424-8220},
ABSTRACT = {Currently, the applications of the Internet of Things (IoT) generate a large amount of sensor data at a very high pace, making it a challenge to collect and store the data. This scenario brings about the need for effective data compression algorithms to make the data manageable among tiny and battery-powered devices and, more importantly, shareable across the network. Additionally, considering that, very often, wireless communications (e.g., low-power wide-area networks) are adopted to connect field devices, user payload compression can also provide benefits derived from better spectrum usage, which in turn can result in advantages for high-density application scenarios. As a result of this increase in the number of connected devices, a new concept has emerged, called TinyML. It enables the use of machine learning on tiny, computationally restrained devices. This allows intelligent devices to analyze and interpret data locally and in real time. Therefore, this work presents a new data compression solution (algorithm) for the IoT that leverages the TinyML perspective. The new approach is called the Tiny Anomaly Compressor (TAC) and is based on data eccentricity. TAC does not require previously established mathematical models or any assumptions about the underlying data distribution. In order to test the effectiveness of the proposed solution and validate it, a comparative analysis was performed on two real-world datasets with two other algorithms from the literature (namely Swing Door Trending (SDT) and the Discrete Cosine Transform (DCT)). It was found that the TAC algorithm showed promising results, achieving a maximum compression rate of 98.33%. Additionally, it also surpassed the two other models regarding the compression error and peak signal-to-noise ratio in all cases.},
DOI = {10.3390/s21124153}
}



@Article{electronics10121460,
AUTHOR = {Xu, Rongxu and Jin, Wenquan and Hong, Yonggeun and Kim, Do-Hyeun},
TITLE = {Intelligent Optimization Mechanism Based on an Objective Function for Efficient Home Appliances Control in an Embedded Edge Platform},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1460},
URL = {https://www.mdpi.com/2079-9292/10/12/1460},
ISSN = {2079-9292},
ABSTRACT = {In recent years the ever-expanding internet of things (IoT) is becoming more empowered to revolutionize our world with the advent of cutting-edge features and intelligence in an IoT ecosystem. Thanks to the development of the IoT, researchers have devoted themselves to technologies that convert a conventional home into an intelligent occupants-aware place to manage electric resources with autonomous devices to deal with excess energy consumption and providing a comfortable living environment. There are studies to supplement the innate shortcomings of the IoT and improve intelligence by using cloud computing and machine learning. However, the machine learning-based autonomous control devices lack flexibility, and cloud computing is challenging with latency and security. In this paper, we propose a rule-based optimization mechanism on an embedded edge platform to provide dynamic home appliance control and advanced intelligence in a smart home. To provide actional control ability, we design and developed a rule-based objective function in the EdgeX edge computing platform to control the temperature states of the smart home. Compared to cloud computing, edge computing can provide faster response and higher quality of services. The edge computing paradigm provides better analysis, processing, and storage abilities to the data generated from the IoT sensors to enhance the capability of IoT devices concerning computing, storage, and network resources. In order to satisfy the paradigm of distributed edge computing, all the services are implemented as microservices. The microservices are connected to each other through REST APIs based on the constrained IoT devices to provide all the functionalities that accomplish a trade-off between energy consumption and occupant-desired environment setting for the smart home appliances. We simulated our proposed system to control the temperature of a smart home; through experimental findings, we investigated the application against the delay time and overall memory consumption by the embedded edge system of EdgeX. The result of this research work suggests that the implemented services operated efficiently in the raspberry pi 3 hardware of IoT devices.},
DOI = {10.3390/electronics10121460}
}



@Article{inventions6030045,
AUTHOR = {Churi, Prathamesh and Pawar, Ambika and Moreno-Guerrero, Antonio-José},
TITLE = {A Comprehensive Survey on Data Utility and Privacy: Taking Indian Healthcare System as a Potential Case Study},
JOURNAL = {Inventions},
VOLUME = {6},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {45},
URL = {https://www.mdpi.com/2411-5134/6/3/45},
ISSN = {2411-5134},
ABSTRACT = {Background: According to the renowned and Oscar award-winning American actor and film director Marlon Brando, “privacy is not something that I am merely entitled to, it is an absolute prerequisite.” Privacy threats and data breaches occur daily, and countries are mitigating the consequences caused by privacy and data breaches. The Indian healthcare industry is one of the largest and rapidly developing industry. Overall, healthcare management is changing from disease-centric into patient-centric systems. Healthcare data analysis also plays a crucial role in healthcare management, and the privacy of patient records must receive equal attention. Purpose: This paper mainly presents the utility and privacy factors of the Indian healthcare data and discusses the utility aspect and privacy problems concerning Indian healthcare systems. It defines policies that reform Indian healthcare systems. The case study of the NITI Aayog report is presented to explain how reformation occurs in Indian healthcare systems. Findings: It is found that there have been numerous research studies conducted on Indian healthcare data across all dimensions; however, privacy problems in healthcare, specifically in India, are caused by prevalent complacency, culture, politics, budget limitations, large population, and existing infrastructures. This paper reviews the Indian healthcare system and the applications that drive it. Additionally, the paper also maps that how privacy issues are happening in every healthcare sector in India. Originality/Value: To understand these factors and gain insights, understanding Indian healthcare systems first is crucial. To the best of our knowledge, we found no recent papers that thoroughly reviewed the Indian healthcare system and its privacy issues. The paper is original in terms of its overview of the healthcare system and privacy issues. Social Implications: Privacy has been the most ignored part of the Indian healthcare system. With India being a country with a population of 130 billion, much healthcare data are generated every day. The chances of data breaches and other privacy violations on such sensitive data cannot be avoided as they cause severe concerns for individuals. This paper segregates the healthcare system’s advances and lists the privacy that needs to be addressed first.},
DOI = {10.3390/inventions6030045}
}



@Article{app11135861,
AUTHOR = {Li, Gen and Nguyen, Tri-Hai and Jung, Jason J.},
TITLE = {Traffic Incident Detection Based on Dynamic Graph Embedding in Vehicular Edge Computing},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {5861},
URL = {https://www.mdpi.com/2076-3417/11/13/5861},
ISSN = {2076-3417},
ABSTRACT = {With a large of time series dataset from the Internet of Things in Ambient Intelligence-enabled smart environments, many supervised learning-based anomaly detection methods have been investigated but ignored the correlation among the time series. To address this issue, we present a new idea for anomaly detection based on dynamic graph embedding, in which the dynamic graph comprises the multiple time series and their correlation in each time interval. We propose an entropy for measuring a graph’s information injunction with a correlation matrix to define similarity between graphs. A dynamic graph embedding model based on the graph similarity is proposed to cluster the graphs for anomaly detection. We implement the proposed model in vehicular edge computing for traffic incident detection. The experiments are carried out using traffic data produced by the Simulation of Urban Mobility framework. The experimental findings reveal that the proposed method achieves better results than the baselines by 14.5% and 18.1% on average with respect to F1-score and accuracy, respectively.},
DOI = {10.3390/app11135861}
}



@Article{en14133900,
AUTHOR = {Mohapatra, Sunil Kumar and Mishra, Sushruta and Tripathy, Hrudaya Kumar and Bhoi, Akash Kumar and Barsocchi, Paolo},
TITLE = {A Pragmatic Investigation of Energy Consumption and Utilization Models in the Urban Sector Using Predictive Intelligence Approaches},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {3900},
URL = {https://www.mdpi.com/1996-1073/14/13/3900},
ISSN = {1996-1073},
ABSTRACT = {Energy consumption is a crucial domain in energy system management. Recently, it was observed that there has been a rapid rise in the consumption of energy throughout the world. Thus, almost every nation devises its strategies and models to limit energy usage in various areas, ranging from large buildings to industrial firms and vehicles. With technological advancements, computational intelligence models have been successfully contributing to the prediction of the consumption of energy. Machine learning and deep learning-based models enhance the precision and robustness compared to traditional approaches, making it more reliable. This article performs a review analysis of the various computational intelligence approaches currently being utilized to predict energy consumption. An extensive survey procedure is conducted and presented in this study, and relevant works are discussed. Different criteria are considered during the aggregation of the relevant studies relating to the work. The author’s perspective, future trends and various novel approaches are also presented as a part of the discussion. This article thereby lays a foundation stone for further research works to be undertaken for energy prediction.},
DOI = {10.3390/en14133900}
}



@Article{app11136112,
AUTHOR = {Mbiydzenyuy, Gideon and Nowaczyk, Sławomir and Knutsson, Håkan and Vanhoudt, Dirk and Brage, Jens and Calikus, Ece},
TITLE = {Opportunities for Machine Learning in District Heating},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {6112},
URL = {https://www.mdpi.com/2076-3417/11/13/6112},
ISSN = {2076-3417},
ABSTRACT = {The district heating (DH) industry is facing an important transformation towards more efficient networks that utilise significantly lower water temperatures to distribute the heat. This change requires taking advantage of new technologies, and Machine Learning (ML) is a popular direction. In the last decade, we have witnessed an extreme growth in the number of published research papers that focus on applying ML techniques to the DH domain. However, based on our experience in the field, and an extensive review of the state-of-the-art, we perceive a mismatch between the most popular research directions, such as forecasting, and the challenges faced by the DH industry. In this work, we present our findings, explain and demonstrate the key gaps between the two communities and suggest a road-map ahead towards increasing the impact of ML research in the DH industry.},
DOI = {10.3390/app11136112}
}



@Article{s21134511,
AUTHOR = {Bauer, Martin and Sanchez, Luis and Song, JaeSeung},
TITLE = {IoT-Enabled Smart Cities: Evolution and Outlook},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4511},
URL = {https://www.mdpi.com/1424-8220/21/13/4511},
PubMedID = {34209436},
ISSN = {1424-8220},
ABSTRACT = {For the last decade the Smart City concept has been under development, fostered by the growing urbanization of the world’s population and the need to handle the challenges that such a scenario raises. During this time many Smart City projects have been executed–some as proof-of-concept, but a growing number resulting in permanent, production-level deployments, improving the operation of the city and the quality of life of its citizens. Thus, Smart Cities are still a highly relevant paradigm which needs further development before it reaches its full potential and provides robust and resilient solutions. In this paper, the focus is set on the Internet of Things (IoT) as an enabling technology for the Smart City. In this sense, the paper reviews the current landscape of IoT-enabled Smart Cities, surveying relevant experiences and city initiatives that have embedded IoT within their city services and how they have generated an impact. The paper discusses the key technologies that have been developed and how they are contributing to the realization of the Smart City. Moreover, it presents some challenges that remain open ahead of us and which are the initiatives and technologies that are under development to tackle them.},
DOI = {10.3390/s21134511}
}



@Article{fi13070174,
AUTHOR = {Li, Xiaohui and Savkin, Andrey V.},
TITLE = {Networked Unmanned Aerial Vehicles for Surveillance and Monitoring: A Survey},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {174},
URL = {https://www.mdpi.com/1999-5903/13/7/174},
ISSN = {1999-5903},
ABSTRACT = {As a typical cyber-physical system, networked unmanned aerial vehicles (UAVs) have received much attention in recent years. Emerging communication technologies and high-performance control methods enable networked UAVs to operate as aerial sensor networks to collect more complete and consistent information with significantly improved mobility and flexibility than traditional sensing platforms. One of the main applications of networked UAVs is surveillance and monitoring, which constitute essential components of a well-functioning public safety system and many industrial applications. Although the existing literature on surveillance and monitoring UAVs is extensive, a comprehensive survey on this topic is lacking. This article classifies publications on networked UAVs for surveillance and monitoring using the targets of interest and analyzes several typical problems on this topic, including the control, navigation, and deployment optimization of UAVs. The related research gaps and future directions are also presented.},
DOI = {10.3390/fi13070174}
}



@Article{s21134553,
AUTHOR = {Moon, Junhyung and Yang, Minyeol and Jeong, Jongpil},
TITLE = {A Novel Approach to the Job Shop Scheduling Problem Based on the Deep Q-Network in a Cooperative Multi-Access Edge Computing Ecosystem},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4553},
URL = {https://www.mdpi.com/1424-8220/21/13/4553},
PubMedID = {34283102},
ISSN = {1424-8220},
ABSTRACT = {In this study, based on multi-access edge computing (MEC), we provided the possibility of cooperating manufacturing processes. We tried to solve the job shop scheduling problem by applying DQN (deep Q-network), a reinforcement learning model, to this method. Here, to alleviate the overload of computing resources, an efficient DQN was used for the experiments using transfer learning data. Additionally, we conducted scheduling studies in the edge computing ecosystem of our manufacturing processes without the help of cloud centers. Cloud computing, an environment in which scheduling processing is performed, has issues sensitive to the manufacturing process in general, such as security issues and communication delay time, and research is being conducted in various fields, such as the introduction of an edge computing system that can replace them. We proposed a method of independently performing scheduling at the edge of the network through cooperative scheduling between edge devices within a multi-access edge computing structure. The proposed framework was evaluated, analyzed, and compared with existing frameworks in terms of providing solutions and services.},
DOI = {10.3390/s21134553}
}



@Article{rs13132611,
AUTHOR = {Qin, Huaiyu and Zhao, Buhui and Xu, Leijun and Bai, Xue},
TITLE = {Petri-Net Based Multi-Objective Optimization in Multi-UAV Aided Large-Scale Wireless Power and Information Transfer Networks},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2611},
URL = {https://www.mdpi.com/2072-4292/13/13/2611},
ISSN = {2072-4292},
ABSTRACT = {Power consumption in wireless sensor networks is high, and the lifetime of a battery has become a bottleneck, restricting network performance. Wireless power transfer with a ground mobile charger is vulnerable to interference from the terrain and other factors, and hence it is difficult to deploy in practice. Accordingly, a novel paradigm is adopted where a multi-UAV (unmanned aerial vehicle) with batteries can transfer power and information to SDs (sensor devices) in a large-scale sensor network. However, there are discrete events, continuous process, time delay, and decisions in such a complicated system. From the perspective of a hybrid system, a hybrid colored cyber Petri net system is proposed here to depict and analyze this problem. Furthermore, the energy utilization rate and information collection time delay are conflict with each other; therefore, UAV-aided wireless power and information transfer is formulated as a multi-objective optimization problem. For this reason, the MAC-NSGA II (multiple ant colony-nondominated sorting genetic algorithm II) is proposed in this work. Firstly, the optimal trajectory of multiple UAVs was obtained, and on this basis, the above two objectives were optimized simultaneously. Large-scale simulation results show that the proposed algorithm is superior to NSGA II and MOEA/D in terms of energy efficiency and information collection delay.},
DOI = {10.3390/rs13132611}
}



@Article{electronics10131606,
AUTHOR = {Senanayake, Janaka and Kalutarage, Harsha and Al-Kadri, Mhd Omar},
TITLE = {Android Mobile Malware Detection Using Machine Learning: A Systematic Review},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {1606},
URL = {https://www.mdpi.com/2079-9292/10/13/1606},
ISSN = {2079-9292},
ABSTRACT = {With the increasing use of mobile devices, malware attacks are rising, especially on Android phones, which account for 72.2% of the total market share. Hackers try to attack smartphones with various methods such as credential theft, surveillance, and malicious advertising. Among numerous countermeasures, machine learning (ML)-based methods have proven to be an effective means of detecting these attacks, as they are able to derive a classifier from a set of training examples, thus eliminating the need for an explicit definition of the signatures when developing malware detectors. This paper provides a systematic review of ML-based Android malware detection techniques. It critically evaluates 106 carefully selected articles and highlights their strengths and weaknesses as well as potential improvements. Finally, the ML-based methods for detecting source code vulnerabilities are discussed, because it might be more difficult to add security after the app is deployed. Therefore, this paper aims to enable researchers to acquire in-depth knowledge in the field and to identify potential future research and development directions.},
DOI = {10.3390/electronics10131606}
}



@Article{w13131875,
AUTHOR = {Val Ledesma, Jorge and Wisniewski, Rafał and Kallesøe, Carsten Skovmose},
TITLE = {Smart Water Infrastructures Laboratory: Reconfigurable Test-Beds for Research in Water Infrastructures Management},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {1875},
URL = {https://www.mdpi.com/2073-4441/13/13/1875},
ISSN = {2073-4441},
ABSTRACT = {The smart water infrastructures laboratory is a research facility at Aalborg University, Denmark. The laboratory enables experimental research in control and management of water infrastructures in a realistic environment. The laboratory is designed as a modular system that can be configured to adapt the test-bed to the desired network. The water infrastructures recreated in this laboratory are district heating, drinking water supply, and waste water collection systems. This paper focuses on the first two types of infrastructure. In the scaled-down network the researchers can reproduce different scenarios that affect its management and validate new control strategies. This paper presents four study-cases where the laboratory is configured to represent specific water distribution and waste collection networks allowing the researcher to validate new management solutions in a safe environment. Thus, without the risk of affecting the consumers in a real network. The outcome of this research facilitates the sustainable deployment of new technology in real infrastructures.},
DOI = {10.3390/w13131875}
}



@Article{electronics10141609,
AUTHOR = {Bevacqua, Martina T. and Bellizzi, Gennaro G. and Merenda, Massimo},
TITLE = {An Efficient Far-Field Wireless Power Transfer via Field Intensity Shaping Techniques},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {1609},
URL = {https://www.mdpi.com/2079-9292/10/14/1609},
ISSN = {2079-9292},
ABSTRACT = {Radiative (or far-field) energy replenishment for devices such as smartphones, laptops, robots, and small electric appliances paves the way to autonomous and continuous devices functioning, thus bypassing the need of operation interruptions, human maintenance activities, and replenishment by wired transformers. In this work, we investigate the feasibility of using a properly engineered antenna array able to deliver radiative power to devices in need of energy replenishment during their normal and unsupervised activity, whose locations are unknown. Both the case of single and multiple devices needing energy replenishment are addressed. A quantitative proof-of-concept study is carried out to validate the proposed approach. A 3D scenario is simulated to study the case of devices in need of energy replenishment within a standard office environment. Different antenna array configurations are investigated and the corresponding performances benchmarked against a standard installation of recharging antennas. Results confirm the outstanding capability of the proposed approach in terms of confinement and maximization of power transfer. Finally, in this framework, we also propose an efficient communication protocol that is able to manage multiple recharge demand given different operational rules.},
DOI = {10.3390/electronics10141609}
}



@Article{s21144772,
AUTHOR = {Rudd-Orthner, Richard N. M. and Mihaylova, Lyudmila},
TITLE = {Deep ConvNet: Non-Random Weight Initialization for Repeatable Determinism, Examined with FSGM},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {4772},
URL = {https://www.mdpi.com/1424-8220/21/14/4772},
PubMedID = {34300512},
ISSN = {1424-8220},
ABSTRACT = {A repeatable and deterministic non-random weight initialization method in convolutional layers of neural networks examined with the Fast Gradient Sign Method (FSGM). Using the FSGM approach as a technique to measure the initialization effect with controlled distortions in transferred learning, varying the dataset numerical similarity. The focus is on convolutional layers with induced earlier learning through the use of striped forms for image classification. Which provided a higher performing accuracy in the first epoch, with improvements of between 3–5% in a well known benchmark model, and also ~10% in a color image dataset (MTARSI2), using a dissimilar model architecture. The proposed method is robust to limit optimization approaches like Glorot/Xavier and He initialization. Arguably the approach is within a new category of weight initialization methods, as a number sequence substitution of random numbers, without a tether to the dataset. When examined under the FGSM approach with transferred learning, the proposed method when used with higher distortions (numerically dissimilar datasets), is less compromised against the original cross-validation dataset, at ~31% accuracy instead of ~9%. This is an indication of higher retention of the original fitting in transferred learning.},
DOI = {10.3390/s21144772}
}



@Article{su13147925,
AUTHOR = {Munawar, Hafiz Suliman and Hammad, Ahmed W. A. and Waller, S. Travis and Thaheem, Muhammad Jamaluddin and Shrestha, Asheem},
TITLE = {An Integrated Approach for Post-Disaster Flood Management Via the Use of Cutting-Edge Technologies and UAVs: A Review},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {7925},
URL = {https://www.mdpi.com/2071-1050/13/14/7925},
ISSN = {2071-1050},
ABSTRACT = {Rapid advances that improve flood management have facilitated the disaster response by providing first aid services, finding safe routes, maintaining communication and developing flood maps. Different technologies such as image processing, satellite imagery, synthetic imagery and integrated approaches have been extensively analysed in the literature for disaster operations. There is a need to review cutting-edge technologies for flood management. This paper presents a review of the latest advancements in the flood management domain based on image processing, artificial intelligence and integrated approaches with a focus on post-disaster. It answers the following research questions: (1) What are the latest developments in image processing for flood management in a post-disaster scenario? (2) What are the latest techniques for flood management based on artificial intelligence in a post-disaster scenario? (3) What are the existing gaps in the selected technologies for post-disaster? (4) How can the authorities improve the existing post-disaster management operation with cutting-edge technologies? A novel framework has been proposed to optimise flood management with the application of a holistic approach.},
DOI = {10.3390/su13147925}
}



@Article{electronics10141744,
AUTHOR = {Wazirali, Raniyah and Ahmad, Rami and Al-Amayreh, Ahmed and Al-Madi, Mohammad and Khalifeh, Ala’},
TITLE = {Secure Watermarking Schemes and Their Approaches in the IoT Technology: An Overview},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {1744},
URL = {https://www.mdpi.com/2079-9292/10/14/1744},
ISSN = {2079-9292},
ABSTRACT = {Information security is considered one of the most important issues in various infrastructures related to the field of data communication where most of the modern studies focus on finding effective and low-weight secure approaches. Digital watermarking is a trend in security techniques that hides data by using data embedding and data extraction processes. Watermarking technology is integrated into different frames without adding an overheard as in the conventional encryption. Therefore, it is efficient to be used in data encryption for applications that run over limited resources such as the Internet of Things (IoT). In this paper, different digital watermarking algorithms and approaches are presented. Additionally, watermarking requirements and challenges are illustrated in detail. Moreover, the common architecture of the watermarking system is described. Furthermore, IoT technology and its challenges are highlighted. Finally, the paper provides the motivations, objectives and applications of the recent secure watermarking techniques in IoT and summarises them into one table. In addition, the paper highlights the potential to apply the modified watermark algorithms to secure IoT networks.},
DOI = {10.3390/electronics10141744}
}



@Article{su13158141,
AUTHOR = {Rehman Khan, Haseeb Ur and Lim, Chen Kim and Ahmed, Minhaz Farid and Tan, Kian Lam and Bin Mokhtar, Mazlin},
TITLE = {Systematic Review of Contextual Suggestion and Recommendation Systems for Sustainable e-Tourism},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {8141},
URL = {https://www.mdpi.com/2071-1050/13/15/8141},
ISSN = {2071-1050},
ABSTRACT = {Agenda 2030 of Sustainable Development Goals (SDGs) 9 and 11 recognizes tourism as one of the central industries to global development to tackle global challenges. With the transformation of information and communication technologies (ICT), e-tourism has evolved globally to establish commercial relationships using the Internet for offering tourism-related products, including giving personalised suggestions. The contextual suggestion has emerged as a modified recommendation system that is integrated with information-retrieval techniques within large databases to provide tourists with a list of suggestions based on contexts, such as location, time of day, or day of the week (weekdays or weekends). This study surveyed literature in the field of contextual suggestion and recommendation systems with a focus on e-tourism. The concerns linked with approaches used in contextual suggestion and recommendation systems are highlighted in this systematic review, while motivations, recommendations, and practical implications in e-tourism are also discussed in this paper. A query search using the keywords “contextual suggestion system”, “recommendation system”, and “tourism” identified 143 relevant articles published from 2012 to 2020. Four major repositories are considered for searching, namely, (i) Science Direct, (ii) Scopus, (iii) IEEE, and (iv) Web of Science. This review was carried out under the protocols of four phases, namely, (i) query searching in major article repositories, (ii) removal of duplicates, (iii) scan of title and abstract, and (iv) complete reading of articles. To identify the gaps in current research, a taxonomy analysis was exemplified into categories and subcategories. The main categories were highlighted as (i) review articles, (ii) model/framework, and (iii) applications. Critical analysis was carried out on the basis of the available literature on the limitations of approaches used in contextual suggestion and recommendation systems. In conclusion, the approaches used are mainly based on content-based filtering, collaborative filtering, preference-based product ranking, and language modelling. The evaluation measures for the contextual suggestion system include precision, normalized discounted cumulative, and mean reciprocal rank, while test collections comprise Internet resources. Given that the tourism industry contributed to the environmental and social-economic development, contextual suggestion and recommendation systems have presented themselves to be relevant in integrating and achieving SDG 9 and SDG 11 in many ways such as web-based e-services by the government sector and smart gadgets based on reliable and real-time data and information for city planners as well as law enforcement personnel in a sustainable city.},
DOI = {10.3390/su13158141}
}



@Article{s21154999,
AUTHOR = {Khan, Manzoor Ahmed and Alkaabi, Najla},
TITLE = {Rebirth of Distributed AI—A Review of eHealth Research},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {4999},
URL = {https://www.mdpi.com/1424-8220/21/15/4999},
PubMedID = {34372236},
ISSN = {1424-8220},
ABSTRACT = {The envisioned smart city domains are expected to rely heavily on artificial intelligence and machine learning (ML) approaches for their operations, where the basic ingredient is data. Privacy of the data and training time have been major roadblocks to achieving the specific goals of each application domain. Policy makers, the research community, and the industrial sector have been putting their efforts into addressing these issues. Federated learning, with its distributed and local training approach, stands out as a potential solution to these challenges. In this article, we discuss the potential interplay of different technologies and AI for achieving the required features of future smart city services. Having discussed a few use-cases for future eHealth, we list design goals and technical requirements of the enabling technologies. The paper confines its focus on federated learning. After providing the tutorial on federated learning, we analyze the Federated Learning research literature. We also highlight the challenges. A solution sketch and high-level research directions may be instrumental in addressing the challenges.},
DOI = {10.3390/s21154999}
}



@Article{en14154477,
AUTHOR = {Vodovozov, Valery and Raud, Zoja and Petlenkov, Eduard},
TITLE = {Review on Braking Energy Management in Electric Vehicles},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {4477},
URL = {https://www.mdpi.com/1996-1073/14/15/4477},
ISSN = {1996-1073},
ABSTRACT = {The adoption of electric vehicles promises numerous benefits for modern society. At the same time, there remain significant hurdles to their wide distribution, primarily related to battery-based energy sources. This review concerns the systematization of knowledge in one of the areas of the electric vehicle control, namely, the energy management issues when using braking controllers. The braking process optimization is summarized from two aspects. First, the advantageous solutions are presented that were identified in the field of gradual and urgent braking. Second, several findings discovered in adjacent fields of automation are debated as prospects for their possible application in braking control. Following the specific classification of braking methods, a generalized braking system composition is offered, and all publications are evaluated primarily in terms of their energy recovery abilities as a global target. Then, conventional and intelligent classes of braking controllers are compared. In the first category, classic PID, threshold, and sliding-mode controllers are reviewed in terms of their energy management restrictions. The second group relates to the issues of the tire friction-slip identification and braking torque allocation between the hydraulic and electrical brakes. From this perspective, several intelligent systems are analyzed in detail, especially fuzzy logic, neural network, and their numerous associations.},
DOI = {10.3390/en14154477}
}



@Article{s21155044,
AUTHOR = {Behjati, Mehran and Mohd Noh, Aishah Binti and Alobaidy, Haider A. H. and Zulkifley, Muhammad Aidiel and Nordin, Rosdiadee and Abdullah, Nor Fadzilah},
TITLE = {LoRa Communications as an Enabler for Internet of Drones towards Large-Scale Livestock Monitoring in Rural Farms},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {5044},
URL = {https://www.mdpi.com/1424-8220/21/15/5044},
PubMedID = {34372281},
ISSN = {1424-8220},
ABSTRACT = {Currently, smart farming is considered an effective solution to enhance the productivity of farms; thereby, it has recently received broad interest from service providers to offer a wide range of applications, from pest identification to asset monitoring. Although the emergence of digital technologies, such as the Internet of Things (IoT) and low-power wide-area networks (LPWANs), has led to significant advances in the smart farming industry, farming operations still need more efficient solutions. On the other hand, the utilization of unmanned aerial vehicles (UAVs), also known as drones, is growing rapidly across many civil application domains. This paper aims to develop a farm monitoring system that incorporates UAV, LPWAN, and IoT technologies to transform the current farm management approach and aid farmers in obtaining actionable data from their farm operations. In this regard, an IoT-based water quality monitoring system was developed because water is an essential aspect in livestock development. Then, based on the Long-Range Wide-Area Network (LoRaWAN®) technology, a multi-channel LoRaWAN® gateway was developed and integrated into a vertical takeoff and landing drone to convey collected data from the sensors to the cloud for further analysis. In addition, to develop LoRaWAN®-based aerial communication, a series of measurements and simulations were performed under different configurations and scenarios. Finally, to enhance the efficiency of aerial-based data collection, the UAV path planning was optimized. Measurement results showed that the maximum achievable LoRa coverage when operating on-air via the drone is about 10 km, and the Longley–Rice irregular terrain model provides the most suitable path loss model for the scenario of large-scale farms, and a multi-channel gateway with a spreading factor of 12 provides the most reliable communication link at a high drone speed (up to 95 km/h). Simulation results showed that the developed system can overcome the coverage limitation of LoRaWAN® and it can establish a reliable communication link over large-scale wireless sensor networks. In addition, it was shown that by optimizing flight paths, aerial data collection could be performed in a much shorter time than industrial mission planning (up to four times in our case).},
DOI = {10.3390/s21155044}
}



@Article{iot2030022,
AUTHOR = {Ullah, Imtiaz and Ullah, Ayaz and Sajjad, Mazhar},
TITLE = {Towards a Hybrid Deep Learning Model for Anomalous Activities Detection in Internet of Things Networks},
JOURNAL = {IoT},
VOLUME = {2},
YEAR = {2021},
NUMBER = {3},
PAGES = {428--448},
URL = {https://www.mdpi.com/2624-831X/2/3/22},
ISSN = {2624-831X},
ABSTRACT = {The tremendous number of Internet of Things (IoT) applications, with their ubiquity, has provided us with unprecedented productivity and simplified our daily life. At the same time, the insecurity of these technologies ensures that our daily lives are surrounded by vulnerable computers, allowing for the launch of multiple attacks via large-scale botnets through the IoT. These attacks have been successful in achieving their heinous objectives. A strong identification strategy is essential to keep devices secured. This paper proposes and implements a model for anomaly-based intrusion detection in IoT networks that uses a convolutional neural network (CNN) and gated recurrent unit (GRU) to detect and classify binary and multiclass IoT network data. The proposed model is validated using the BoT-IoT, IoT Network Intrusion, MQTT-IoT-IDS2020, and IoT-23 intrusion detection datasets. Our proposed binary and multiclass classification model achieved an exceptionally high level of accuracy, precision, recall, and F1 score.},
DOI = {10.3390/iot2030022}
}



@Article{ijfs9030039,
AUTHOR = {Mhlanga, David},
TITLE = {Financial Inclusion in Emerging Economies: The Application of Machine Learning and Artificial Intelligence in Credit Risk Assessment},
JOURNAL = {International Journal of Financial Studies},
VOLUME = {9},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {39},
URL = {https://www.mdpi.com/2227-7072/9/3/39},
ISSN = {2227-7072},
ABSTRACT = {In banking and finance, credit risk is among the important topics because the process of issuing a loan requires a lot of attention to assessing the possibilities of getting the loaned money back. At the same time in emerging markets, the underbanked individuals cannot access traditional forms of collateral or identification that is required by financial institutions for them to be granted loans. Using the literature review approach through documentary and conceptual analysis to investigate the impact of machine learning and artificial intelligence in credit risk assessment, this study discovered that artificial intelligence and machine learning have a strong impact on credit risk assessments using alternative data sources such as public data to deal with the problems of information asymmetry, adverse selection, and moral hazard. This allows lenders to do serious credit risk analysis, to assess the behaviour of the customer, and subsequently to verify the ability of the clients to repay the loans, permitting less privileged people to access credit. Therefore, this study recommends that financial institutions such as banks and credit lending institutions invest more in artificial intelligence and machine learning to ensure that financially excluded households can obtain credit.},
DOI = {10.3390/ijfs9030039}
}



@Article{s21155111,
AUTHOR = {Kim, Youngboo and Kwon, Lam and Park, Eun-Chan},
TITLE = {OFDMA Backoff Control Scheme for Improving Channel Efficiency in the Dynamic Network Environment of IEEE 802.11ax WLANs},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {5111},
URL = {https://www.mdpi.com/1424-8220/21/15/5111},
PubMedID = {34372346},
ISSN = {1424-8220},
ABSTRACT = {IEEE 802.11ax uplink orthogonal frequency division multiple access (OFDMA)-based random access (UORA) is a new feature for random channel access in wireless local area networks (WLANs). Similar to the legacy random access scheme in WLANs, UORA performs the OFDMA backoff (OBO) procedure to access the channel and decides on a random OBO counter within the OFDMA contention window (OCW) value. An access point (AP) can determine the OCW range and inform each station (STA) of it. However, how to determine a reasonable OCW range is beyond the scope of the IEEE 802.11ax standard. The OCW range is crucial to the UORA performance, and it primarily depends on the number of contending STAs, but it is challenging for the AP to accurately and quickly estimate or keep track of the number of contending STAs without the aid of a specific signaling mechanism. In addition, the one for this purpose incurs an additional delay and overhead in the channel access procedure. Therefore, the performance of a UORA scheme can be degraded by an improper OCW range, especially when the number of contending STAs changes dynamically. We first observed the effect of OCW values on channel efficiency and derived its optimal value from an analytical model. Next, we proposed a simple yet effective OBO control scheme where each STA determines its own OBO counter in a distributed manner rather than adjusting the OCW value globally. In the proposed scheme, each STA determines an appropriate OBO counter depending on whether the previous transmission was successful or not so that collisions can be mitigated without leaving OFDMA resource units unnecessarily idle. The results of a simulation study confirm that the throughput of the proposed scheme is comparable to the optimal OCW-based scheme and is improved by up to 15 times compared to the standard UORA scheme.},
DOI = {10.3390/s21155111}
}



@Article{en14164776,
AUTHOR = {Miraftabzadeh, Seyed Mahdi and Longo, Michela and Foiadelli, Federica and Pasetti, Marco and Igual, Raul},
TITLE = {Advances in the Application of Machine Learning Techniques for Power System Analytics: A Survey},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {4776},
URL = {https://www.mdpi.com/1996-1073/14/16/4776},
ISSN = {1996-1073},
ABSTRACT = {The recent advances in computing technologies and the increasing availability of large amounts of data in smart grids and smart cities are generating new research opportunities in the application of Machine Learning (ML) for improving the observability and efficiency of modern power grids. However, as the number and diversity of ML techniques increase, questions arise about their performance and applicability, and on the most suitable ML method depending on the specific application. Trying to answer these questions, this manuscript presents a systematic review of the state-of-the-art studies implementing ML techniques in the context of power systems, with a specific focus on the analysis of power flows, power quality, photovoltaic systems, intelligent transportation, and load forecasting. The survey investigates, for each of the selected topics, the most recent and promising ML techniques proposed by the literature, by highlighting their main characteristics and relevant results. The review revealed that, when compared to traditional approaches, ML algorithms can handle massive quantities of data with high dimensionality, by allowing the identification of hidden characteristics of (even) complex systems. In particular, even though very different techniques can be used for each application, hybrid models generally show better performances when compared to single ML-based models.},
DOI = {10.3390/en14164776}
}



@Article{asi4030052,
AUTHOR = {Manzoor, Bilal and Othman, Idris and Durdyev, Serdar and Ismail, Syuhaida and Wahab, Mohammad Hussaini},
TITLE = {Influence of Artificial Intelligence in Civil Engineering toward Sustainable Development—A Systematic Literature Review},
JOURNAL = {Applied System Innovation},
VOLUME = {4},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {52},
URL = {https://www.mdpi.com/2571-5577/4/3/52},
ISSN = {2571-5577},
ABSTRACT = {The widespread use of artificial intelligence (AI) in civil engineering has provided civil engineers with various benefits and opportunities, including a rich data collection, sustainable assessment, and productivity. The trend of construction is diverted toward sustainability with the aid of digital technologies. In this regard, this paper presents a systematic literature review (SLR) in order to explore the influence of AI in civil engineering toward sustainable development. In addition, SLR was carried out by using academic publications from Scopus (i.e., 3478 publications). Furthermore, screening is carried out, and eventually, 105 research publications in the field of AI were selected. Keywords were searched through Boolean operation “Artificial Intelligence” OR “Machine intelligence” OR “Machine Learning” OR “Computational intelligence” OR “Computer vision” OR “Expert systems” OR “Neural networks” AND “Civil Engineering” OR “Construction Engineering” OR “Sustainable Development” OR “Sustainability”. According to the findings, it was revealed that the trend of publications received its high intention of researchers in 2020, the most important contribution of publications on AI toward sustainability by the Automation in Construction, the United States has the major influence among all the other countries, the main features of civil engineering toward sustainability are interconnectivity, functionality, unpredictability, and individuality. This research adds to the body of knowledge in civil engineering by visualizing and comprehending trends and patterns, as well as defining major research goals, journals, and countries. In addition, a theoretical framework has been proposed in light of the results for prospective researchers and scholars.},
DOI = {10.3390/asi4030052}
}



@Article{electronics10161910,
AUTHOR = {Arif, Syed Muhammad and Lie, Tek Tjing and Seet, Boon Chong and Ayyadi, Soumia and Jensen, Kristian},
TITLE = {Review of Electric Vehicle Technologies, Charging Methods, Standards and Optimization Techniques},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {1910},
URL = {https://www.mdpi.com/2079-9292/10/16/1910},
ISSN = {2079-9292},
ABSTRACT = {This paper presents a state-of-the-art review of electric vehicle technology, charging methods, standards, and optimization techniques. The essential characteristics of Hybrid Electric Vehicle (HEV) and Electric Vehicle (EV) are first discussed. Recent research on EV charging methods such as Battery Swap Station (BSS), Wireless Power Transfer (WPT), and Conductive Charging (CC) are then presented. This is followed by a discussion of EV standards such as charging levels and their configurations. Next, some of the most used optimization techniques for the sizing and placement of EV charging stations are analyzed. Finally, based on the insights gained, several recommendations are put forward for future research.},
DOI = {10.3390/electronics10161910}
}



@Article{su13169092,
AUTHOR = {Rehman, Amjad and Haseeb, Khalid and Saba, Tanzila and Lloret, Jaime and Ahmed, Zara},
TITLE = {Mobility Support 5G Architecture with Real-Time Routing for Sustainable Smart Cities},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {9092},
URL = {https://www.mdpi.com/2071-1050/13/16/9092},
ISSN = {2071-1050},
ABSTRACT = {The Internet of Things (IoT) is an emerging technology and provides connectivity among physical objects with the support of 5G communication. In recent decades, there have been a lot of applications based on IoT technology for the sustainability of smart cities, such as farming, e-healthcare, education, smart homes, weather monitoring, etc. These applications communicate in a collaborative manner between embedded IoT devices and systematize daily routine tasks. In the literature, many solutions facilitate remote users to gather the observed data by accessing the stored information on the cloud network and lead to smart systems. However, most of the solutions raise significant research challenges regarding information sharing in mobile IoT networks and must be able to stabilize the performance of smart operations in terms of security and intelligence. Many solutions are based on 5G communication to support high user mobility and increase the connectivity among a huge number of IoT devices. However, such approaches lack user and data privacy against anonymous threats and incur resource costs. In this paper, we present a mobility support 5G architecture with real-time routing for sustainable smart cities that aims to decrease the loss of data against network disconnectivity and increase the reliability for 5G-based public healthcare networks. The proposed architecture firstly establishes a mutual relationship among the nodes and mobile sink with shared secret information and lightweight processing. Secondly, multi-secured levels are proposed to protect the interaction with smart transmission systems by increasing the trust threshold over the insecure channels. The conducted experiments are analyzed, and it is concluded that their performance significantly increases the information sustainability for mobile networks in terms of security and routing.},
DOI = {10.3390/su13169092}
}



@Article{s21165491,
AUTHOR = {Gupta, Divya and Rani, Shalli and Ahmed, Syed Hassan and Verma, Sahil and Ijaz, Muhammad Fazal and Shafi, Jana},
TITLE = {Edge Caching Based on Collaborative Filtering for Heterogeneous ICN-IoT Applications},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5491},
URL = {https://www.mdpi.com/1424-8220/21/16/5491},
PubMedID = {34450933},
ISSN = {1424-8220},
ABSTRACT = {The substantial advancements offered by the edge computing has indicated serious evolutionary improvements for the internet of things (IoT) technology. The rigid design philosophy of the traditional network architecture limits its scope to meet future demands. However, information centric networking (ICN) is envisioned as a promising architecture to bridge the huge gaps and maintain IoT networks, mostly referred as ICN-IoT. The edge-enabled ICN-IoT architecture always demands efficient in-network caching techniques for supporting better user’s quality of experience (QoE). In this paper, we propose an enhanced ICN-IoT content caching strategy by enabling artificial intelligence (AI)-based collaborative filtering within the edge cloud to support heterogeneous IoT architecture. This collaborative filtering-based content caching strategy would intelligently cache content on edge nodes for traffic management at cloud databases. The evaluations has been conducted to check the performance of the proposed strategy over various benchmark strategies, such as LCE, LCD, CL4M, and ProbCache. The analytical results demonstrate the better performance of our proposed strategy with average gain of 15% for cache hit ratio, 12% reduction in content retrieval delay, and 28% reduced average hop count in comparison to best considered LCD. We believe that the proposed strategy will contribute an effective solution to the related studies in this domain.},
DOI = {10.3390/s21165491}
}



@Article{app11167502,
AUTHOR = {Gharahighehi, Alireza and Pliakos, Konstantinos and Vens, Celine},
TITLE = {Recommender Systems in the Real Estate Market—A Survey},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {7502},
URL = {https://www.mdpi.com/2076-3417/11/16/7502},
ISSN = {2076-3417},
ABSTRACT = {The shift to e-commerce has changed many business areas. Real estate is one of the applications that has been affected by this modern technological wave. Recommender systems are intelligent models that assist users of real estate platforms in finding the best possible properties that fulfill their needs. However, the recommendation task is substantially more challenging in the real estate domain due to the many domain-specific limitations that impair typical recommender systems. For instance, real estate recommender systems usually face the clod-start problem where there are no historical logs for new users or new items, and the recommender system should provide recommendations for these new entities. Therefore, the recommender systems in the real estate market are different and substantially less studied than in other domains. In this article, we aim at providing a comprehensive and systematic literature review on applications of recommender systems in the real estate market. We evaluate a set of research articles (13 journal and 13 conference papers) which represent the majority of research and commercial solutions proposed in the field of real estate recommender systems. These papers have been reviewed and categorized based on their methodological approaches, the main challenges that they addressed, and their evaluation procedures. Based on these categorizations, we outlined some possible directions for future research.},
DOI = {10.3390/app11167502}
}



@Article{fi13080210,
AUTHOR = {Ghorpade, Sheetal and Zennaro, Marco and Chaudhari, Bharat},
TITLE = {Survey of Localization for Internet of Things Nodes: Approaches, Challenges and Open Issues},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {210},
URL = {https://www.mdpi.com/1999-5903/13/8/210},
ISSN = {1999-5903},
ABSTRACT = {With exponential growth in the deployment of Internet of Things (IoT) devices, many new innovative and real-life applications are being developed. IoT supports such applications with the help of resource-constrained fixed as well as mobile nodes. These nodes can be placed in anything from vehicles to the human body to smart homes to smart factories. Mobility of the nodes enhances the network coverage and connectivity. One of the crucial requirements in IoT systems is the accurate and fast localization of its nodes with high energy efficiency and low cost. The localization process has several challenges. These challenges keep changing depending on the location and movement of nodes such as outdoor, indoor, with or without obstacles and so on. The performance of localization techniques greatly depends on the scenarios and conditions from which the nodes are traversing. Precise localization of nodes is very much required in many unique applications. Although several localization techniques and algorithms are available, there are still many challenges for the precise and efficient localization of the nodes. This paper classifies and discusses various state-of-the-art techniques proposed for IoT node localization in detail. It includes the different approaches such as centralized, distributed, iterative, ranged based, range free, device-based, device-free and their subtypes. Furthermore, the different performance metrics that can be used for localization, comparison of the different techniques, some prominent applications in smart cities and future directions are also covered.},
DOI = {10.3390/fi13080210}
}



@Article{electronics10161974,
AUTHOR = {Lakhan, Abdullah and Mastoi, Qurat-ul-ain and Dootio, Mazhar Ali and Alqahtani, Fehaid and Alzahrani, Ibrahim R. and Baothman, Fatmah and Shah, Syed Yaseen and Shah, Syed Aziz and Anjum, Nadeem and Abbasi, Qammer Hussain and Khokhar, Muhammad Saddam},
TITLE = {Hybrid Workload Enabled and Secure Healthcare Monitoring Sensing Framework in Distributed Fog-Cloud Network},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {1974},
URL = {https://www.mdpi.com/2079-9292/10/16/1974},
ISSN = {2079-9292},
ABSTRACT = {The Internet of Medical Things (IoMT) workflow applications have been rapidly growing in practice. These internet-based applications can run on the distributed healthcare sensing system, which combines mobile computing, edge computing and cloud computing. Offloading and scheduling are the required methods in the distributed network. However, a security issue exists and it is hard to run different types of tasks (e.g., security, delay-sensitive, and delay-tolerant tasks) of IoMT applications on heterogeneous computing nodes. This work proposes a new healthcare architecture for workflow applications based on heterogeneous computing nodes layers: an application layer, management layer, and resource layer. The goal is to minimize the makespan of all applications. Based on these layers, the work proposes a secure offloading-efficient task scheduling (SEOS) algorithm framework, which includes the deadline division method, task sequencing rules, homomorphic security scheme, initial scheduling, and the variable neighbourhood searching method. The performance evaluation results show that the proposed plans outperform all existing baseline approaches for healthcare applications in terms of makespan.},
DOI = {10.3390/electronics10161974}
}



@Article{a14080242,
AUTHOR = {Kousis, Anestis and Tjortjis, Christos},
TITLE = {Data Mining Algorithms for Smart Cities: A Bibliometric Analysis},
JOURNAL = {Algorithms},
VOLUME = {14},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {242},
URL = {https://www.mdpi.com/1999-4893/14/8/242},
ISSN = {1999-4893},
ABSTRACT = {Smart cities connect people and places using innovative technologies such as Data Mining (DM), Machine Learning (ML), big data, and the Internet of Things (IoT). This paper presents a bibliometric analysis to provide a comprehensive overview of studies associated with DM technologies used in smart cities applications. The study aims to identify the main DM techniques used in the context of smart cities and how the research field of DM for smart cities evolves over time. We adopted both qualitative and quantitative methods to explore the topic. We used the Scopus database to find relative articles published in scientific journals. This study covers 197 articles published over the period from 2013 to 2021. For the bibliometric analysis, we used the Biliometrix library, developed in R. Our findings show that there is a wide range of DM technologies used in every layer of a smart city project. Several ML algorithms, supervised or unsupervised, are adopted for operating the instrumentation, middleware, and application layer. The bibliometric analysis shows that DM for smart cities is a fast-growing scientific field. Scientists from all over the world show a great interest in researching and collaborating on this interdisciplinary scientific field.},
DOI = {10.3390/a14080242}
}



@Article{app11167561,
AUTHOR = {Iqbal, Umair and Barthelemy, Johan and Li, Wanqing and Perez, Pascal},
TITLE = {Automating Visual Blockage Classification of Culverts with Deep Learning},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {7561},
URL = {https://www.mdpi.com/2076-3417/11/16/7561},
ISSN = {2076-3417},
ABSTRACT = {Blockage of culverts by transported debris materials is reported as the salient contributor in originating urban flash floods. Conventional hydraulic modeling approaches had no success in addressing the problem primarily because of the unavailability of peak floods hydraulic data and the highly non-linear behavior of debris at the culvert. This article explores a new dimension to investigate the issue by proposing the use of intelligent video analytics (IVA) algorithms for extracting blockage related information. The presented research aims to automate the process of manual visual blockage classification of culverts from a maintenance perspective by remotely applying deep learning models. The potential of using existing convolutional neural network (CNN) algorithms (i.e., DarkNet53, DenseNet121, InceptionResNetV2, InceptionV3, MobileNet, ResNet50, VGG16, EfficientNetB3, NASNet) is investigated over a dataset from three different sources (i.e., images of culvert openings and blockage (ICOB), visual hydrology-lab dataset (VHD), synthetic images of culverts (SIC)) to predict the blockage in a given image. Models were evaluated based on their performance on the test dataset (i.e., accuracy, loss, precision, recall, F1 score, Jaccard Index, region of convergence (ROC) curve), floating point operations per second (FLOPs) and response times to process a single test instance. Furthermore, the performance of deep learning models was benchmarked against conventional machine learning algorithms (i.e., SVM, RF, xgboost). In addition, the idea of classifying deep visual features extracted by CNN models (i.e., ResNet50, MobileNet) using conventional machine learning approaches was also implemented in this article. From the results, NASNet was reported most efficient in classifying the blockage images with the 5-fold accuracy of 85%; however, MobileNet was recommended for the hardware implementation because of its improved response time with 5-fold accuracy comparable to NASNet (i.e., 78%). Comparable performance to standard CNN models was achieved for the case where deep visual features were classified using conventional machine learning approaches. False negative (FN) instances, false positive (FP) instances and CNN layers activation suggested that background noise and oversimplified labelling criteria were two contributing factors in the degraded performance of existing CNN algorithms. A framework for partial automation of the visual blockage classification process was proposed, given that none of the existing models was able to achieve high enough accuracy to completely automate the manual process. In addition, a detection-classification pipeline with higher blockage classification accuracy (i.e., 94%) has been proposed as a potential future direction for practical implementation.},
DOI = {10.3390/app11167561}
}



@Article{electronics10162001,
AUTHOR = {Liagkou, Vasiliki and Stylios, Chrysostomos and Pappa, Lamprini and Petunin, Alexander},
TITLE = {Challenges and Opportunities in Industry 4.0 for Mechatronics, Artificial Intelligence and Cybernetics},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {2001},
URL = {https://www.mdpi.com/2079-9292/10/16/2001},
ISSN = {2079-9292},
ABSTRACT = {Industry 4.0 has risen as an integrated digital manufacturing environment, and it has created a novel research perspective that has thrust research to interdisciplinarity and exploitation of ICT advances. This work presents and discusses the main aspects of Industry 4.0 and how intelligence can be embedded in manufacturing to create the smart factory. It briefly describes the main components of Industry 4.0, and it focuses on the security challenges that the fully interconnected ecosystem of Industry 4.0 has to meet and the threats for each component. Preserving security has a crucial role in Industry 4.0, and it is vital for its existence, so the main research directions on how to ensure the confidentiality and integrity of the information shared among the Industry 4.0 components are presented. Another view is in light of the security issues that come as a result of enabling new technologies.},
DOI = {10.3390/electronics10162001}
}



@Article{a14080245,
AUTHOR = {Albeshri, Aiiad},
TITLE = {SVSL: A Human Activity Recognition Method Using Soft-Voting and Self-Learning},
JOURNAL = {Algorithms},
VOLUME = {14},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {245},
URL = {https://www.mdpi.com/1999-4893/14/8/245},
ISSN = {1999-4893},
ABSTRACT = {Many smart city and society applications such as smart health (elderly care, medical applications), smart surveillance, sports, and robotics require the recognition of user activities, an important class of problems known as human activity recognition (HAR). Several issues have hindered progress in HAR research, particularly due to the emergence of fog and edge computing, which brings many new opportunities (a low latency, dynamic and real-time decision making, etc.) but comes with its challenges. This paper focuses on addressing two important research gaps in HAR research: (i) improving the HAR prediction accuracy and (ii) managing the frequent changes in the environment and data related to user activities. To address this, we propose an HAR method based on Soft-Voting and Self-Learning (SVSL). SVSL uses two strategies. First, to enhance accuracy, it combines the capabilities of Deep Learning (DL), Generalized Linear Model (GLM), Random Forest (RF), and AdaBoost classifiers using soft-voting. Second, to classify the most challenging data instances, the SVSL method is equipped with a self-training mechanism that generates training data and retrains itself. We investigate the performance of our proposed SVSL method using two publicly available datasets on six human activities related to lying, sitting, and walking positions. The first dataset consists of 562 features and the second dataset consists of five features. The data are collected using the accelerometer and gyroscope smartphone sensors. The results show that the proposed method provides 6.26%, 1.75%, 1.51%, and 4.40% better prediction accuracy (average over the two datasets) compared to GLM, DL, RF, and AdaBoost, respectively. We also analyze and compare the class-wise performance of the SVSL methods with that of DL, GLM, RF, and AdaBoost.},
DOI = {10.3390/a14080245}
}



@Article{su13169351,
AUTHOR = {Cho, Yunji and Song, Jaein and Kang, Minhee and Hwang, Keeyeon},
TITLE = {An Application of a Deep Q-Network Based Dynamic Fare Bidding System to Improve the Use of Taxi Services during Off-Peak Hours in Seoul},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {9351},
URL = {https://www.mdpi.com/2071-1050/13/16/9351},
ISSN = {2071-1050},
ABSTRACT = {The problem of structural imbalance in terms of supply and demand due to changes in traffic patterns by time zone has been continuously raised in the mobility market. In Korea, unlike large overseas cities, the waiting time tolerance increases during the daytime when supply far exceeds demand, resulting in a large loss of operating profit. The purpose of this study is to increase taxi demand and further improve driver’s profits through real-time fare discounts during off-peak daytime hours in Seoul, Korea. To this end, we propose a real-time fare bidding system among taxi drivers based on a dynamic pricing scheme and simulate the appropriate fare discount level for each regional time zone. The driver-to-driver fare competition system consists of simulating fare competition based on the multi-agent Deep Q-Network method after developing a fare discount index that reflects the supply and demand level of each region in 25 districts in Seoul. According to the optimal fare discount level analysis in the off-peak hours, the lower the OI Index, which means the level of demand relative to supply, the higher the fare discount rate. In addition, an analysis of drivers’ profits and matching rates according to the distance between the origin and destination of each region showed up to 89% and 65% of drivers who actively offered discounts on fares. The results of this study in the future can serve as the foundation of a fare adjustment system for varying demand and supply situations in the Korean mobility market.},
DOI = {10.3390/su13169351}
}



@Article{fi13080218,
AUTHOR = {Ghazal, Taher M. and Hasan, Mohammad Kamrul and Alshurideh, Muhammad Turki and Alzoubi, Haitham M. and Ahmad, Munir and Akbar, Syed Shehryar and Al Kurdi, Barween and Akour, Iman A.},
TITLE = {IoT for Smart Cities: Machine Learning Approaches in Smart Healthcare—A Review},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {218},
URL = {https://www.mdpi.com/1999-5903/13/8/218},
ISSN = {1999-5903},
ABSTRACT = {Smart city is a collective term for technologies and concepts that are directed toward making cities efficient, technologically more advanced, greener and more socially inclusive. These concepts include technical, economic and social innovations. This term has been tossed around by various actors in politics, business, administration and urban planning since the 2000s to establish tech-based changes and innovations in urban areas. The idea of the smart city is used in conjunction with the utilization of digital technologies and at the same time represents a reaction to the economic, social and political challenges that post-industrial societies are confronted with at the start of the new millennium. The key focus is on dealing with challenges faced by urban society, such as environmental pollution, demographic change, population growth, healthcare, the financial crisis or scarcity of resources. In a broader sense, the term also includes non-technical innovations that make urban life more sustainable. So far, the idea of using IoT-based sensor networks for healthcare applications is a promising one with the potential of minimizing inefficiencies in the existing infrastructure. A machine learning approach is key to successful implementation of the IoT-powered wireless sensor networks for this purpose since there is large amount of data to be handled intelligently. Throughout this paper, it will be discussed in detail how AI-powered IoT and WSNs are applied in the healthcare sector. This research will be a baseline study for understanding the role of the IoT in smart cities, in particular in the healthcare sector, for future research works.},
DOI = {10.3390/fi13080218}
}



@Article{s21165660,
AUTHOR = {Santos, Brena and Soares, André and Nguyen, Tuan-Anh and Min, Dug-Ki and Lee, Jae-Woo and Silva, Francisco-Airton},
TITLE = {IoT Sensor Networks in Smart Buildings: A Performance Assessment Using Queuing Models},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5660},
URL = {https://www.mdpi.com/1424-8220/21/16/5660},
PubMedID = {34451103},
ISSN = {1424-8220},
ABSTRACT = {Smart buildings in big cities are now equipped with an internet of things (IoT) infrastructure to constantly monitor different aspects of people’s daily lives via IoT devices and sensor networks. The malfunction and low quality of service (QoS) of such devices and networks can severely cause property damage and perhaps loss of life. Therefore, it is important to quantify different metrics related to the operational performance of the systems that make up such computational architecture even in advance of the building construction. Previous studies used analytical models considering different aspects to assess the performance of building monitoring systems. However, some critical points are still missing in the literature, such as (i) analyzing the capacity of computational resources adequate to the data demand, (ii) representing the number of cores per machine, and (iii) the clustering of sensors by location. This work proposes a queuing network based message exchange architecture to evaluate the performance of an intelligent building infrastructure associated with multiple processing layers: edge and fog. We consider an architecture of a building that has several floors and several rooms in each of them, where all rooms are equipped with sensors and an edge device. A comprehensive sensitivity analysis of the model was performed using the Design of Experiments (DoE) method to identify bottlenecks in the proposal. A series of case studies were conducted based on the DoE results. The DoE results allowed us to conclude, for example, that the number of cores can have more impact on the response time than the number of nodes. Simulations of scenarios defined through DoE allow observing the behavior of the following metrics: average response time, resource utilization rate, flow rate, discard rate, and the number of messages in the system. Three scenarios were explored: (i) scenario A (varying the number of cores), (ii) scenario B (varying the number of fog nodes), and (iii) scenario C (varying the nodes and cores simultaneously). Depending on the number of resources (nodes or cores), the system can become so overloaded that no new requests are supported. The queuing network based message exchange architecture and the analyses carried out can help system designers optimize their computational architectures before building construction.},
DOI = {10.3390/s21165660}
}



@Article{info12090343,
AUTHOR = {Hu, Chunyang and Li, Jingchen and Shi, Haobin and Ning, Bin and Gu, Qiong},
TITLE = {Decentralized Offloading Strategies Based on Reinforcement Learning for Multi-Access Edge Computing},
JOURNAL = {Information},
VOLUME = {12},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {343},
URL = {https://www.mdpi.com/2078-2489/12/9/343},
ISSN = {2078-2489},
ABSTRACT = {Using reinforcement learning technologies to learn offloading strategies for multi-access edge computing systems has been developed by researchers. However, large-scale systems are unsuitable for reinforcement learning, due to their huge state spaces and offloading behaviors. For this reason, this work introduces the centralized training and decentralized execution mechanism, designing a decentralized reinforcement learning model for multi-access edge computing systems. Considering a cloud server and several edge servers, we separate the training and execution in the reinforcement learning model. The execution happens in edge devices of the system, and edge servers need no communication. Conversely, the training process occurs at the cloud device, which causes a lower transmission latency. The developed method uses a deep deterministic policy gradient algorithm to optimize offloading strategies. The simulated experiment shows that our method can learn the offloading strategy for each edge device efficiently.},
DOI = {10.3390/info12090343}
}



@Article{electronics10172098,
AUTHOR = {Kasi, Mumraiz Khan and Abu Ghazalah, Sarah and Akram, Raja Naeem and Sauveron, Damien},
TITLE = {Secure Mobile Edge Server Placement Using Multi-Agent Reinforcement Learning},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {17},
ARTICLE-NUMBER = {2098},
URL = {https://www.mdpi.com/2079-9292/10/17/2098},
ISSN = {2079-9292},
ABSTRACT = {Mobile edge computing is capable of providing high data processing capabilities while ensuring low latency constraints of low power wireless networks, such as the industrial internet of things. However, optimally placing edge servers (providing storage and computation services to user equipment) is still a challenge. To optimally place mobile edge servers in a wireless network, such that network latency is minimized and load balancing is performed on edge servers, we propose a multi-agent reinforcement learning (RL) solution to solve a formulated mobile edge server placement problem. The RL agents are designed to learn the dynamics of the environment and adapt a joint action policy resulting in the minimization of network latency and balancing the load on edge servers. To ensure that the action policy adapted by RL agents maximized the overall network performance indicators, we propose the sharing of information, such as the latency experienced from each server and the load of each server to other RL agents in the network. Experiment results are obtained to analyze the effectiveness of the proposed solution. Although the sharing of information makes the proposed solution obtain a network-wide maximation of overall network performance at the same time it makes it susceptible to different kinds of security attacks. To further investigate the security issues arising from the proposed solution, we provide a detailed analysis of the types of security attacks possible and their countermeasures.},
DOI = {10.3390/electronics10172098}
}



@Article{en14175459,
AUTHOR = {Battula, Amrutha Raju and Vuddanti, Sandeep and Salkuti, Surender Reddy},
TITLE = {Review of Energy Management System Approaches in Microgrids},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {17},
ARTICLE-NUMBER = {5459},
URL = {https://www.mdpi.com/1996-1073/14/17/5459},
ISSN = {1996-1073},
ABSTRACT = {To sustain the complexity of growing demand, the conventional grid (CG) is incorporated with communication technology like advanced metering with sensors, demand response (DR), energy storage systems (ESS), and inclusion of electric vehicles (EV). In order to maintain local area energy balance and reliability, microgrids (MG) are proposed. Microgrids are low or medium voltage distribution systems with a resilient operation, that control the exchange of power between the main grid, locally distributed generators (DGs), and consumers using intelligent energy management techniques. This paper gives a brief introduction to microgrids, their operations, and further, a review of different energy management approaches. In a microgrid control strategy, an energy management system (EMS) is the key component to maintain the balance between energy resources (CG, DG, ESS, and EVs) and loads available while contributing the profit to utility. This article classifies the methodologies used for EMS based on the structure, control, and technique used. The untapped areas which have scope for investigation are also mentioned.},
DOI = {10.3390/en14175459}
}



@Article{s21175968,
AUTHOR = {Draz, Umar and Yasin, Sana and Ali, Tariq and Ali, Amjad and Faheem, Zaid Bin and Zhang, Ning and Jamal, Muhammad Hasan and Suh, Dong-Young},
TITLE = {ROBINA: Rotational Orbit-Based Inter-Node Adjustment for Acoustic Routing Path in the Internet of Underwater Things (IoUTs)},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {17},
ARTICLE-NUMBER = {5968},
URL = {https://www.mdpi.com/1424-8220/21/17/5968},
PubMedID = {34502859},
ISSN = {1424-8220},
ABSTRACT = {The Internet of Underwater Things (IoUTs) enables various underwater objects be connected to accommodate a wide range of applications, such as oil and mineral exportations, disaster detection, and tracing tracking systems. As about 71% of our earth is covered by water and one-fourth of the population lives around this, the IoUT expects to play a vital role. It is imperative to pursue reliable communication in this vast domain, as human beings’ future depends on water activities and resources. Therefore, there is a urgent need for underwater communication to be reliable, end-to-end secure, and collision/void node-free, especially when the routing path is established between sender and sonobuoys. The foremost issue discussed in this area is its routing path, which has high security and bandwidth without simultaneous multiple reflections. Short communication range is also a problem (because of an absence of inter-node adjustment); the acoustic signals have short ranges and maximum-scaling factors that cause a delay in communication. Therefore, we proposed Rotational Orbit-Based Inter Node Adjustment (ROBINA) with variant Path-Adjustment (PA-ROBINA) and Path Loss (PL-ROBINA) for IoUTs to achive reliable communication between the sender and sonobuoys. Additionally, the mathematical-based path loss model was discussed to cover the PL-ROBINA strategy. Extensive simulations were conducted with various realistic parameters and the results were compared with state-of-the-art routing protocols. Extensive simulations proved that the proposed routing scheme outperformed different realistic parameters; for example, packet transmission 45% increased with an average end-to-end delay of only 0.3% respectively. Furthermore, the transmission loss and path loss (measured in dB) were 25 and 46 dB, respectively, compared with other algorithms, for example, EBER2 54%, WDFAD-BDR 54%, AEDG 49%, ASEGD 55%, AVH-AHH-VBF 54.5%, and TANVEER 39%, respectively. In addition, the individual parameters with ROBINA and TANVEER were also compared, in which ROBINA achieved a 98% packet transmission ratio compared with TANVEER, which was only 82%.},
DOI = {10.3390/s21175968}
}



@Article{fi13090232,
AUTHOR = {Jaramillo-Ramirez, Daniel and Perez, Manuel},
TITLE = {Spectrum Demand Forecasting for IoT Services},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {232},
URL = {https://www.mdpi.com/1999-5903/13/9/232},
ISSN = {1999-5903},
ABSTRACT = {The evolution of IoT has come with the challenge of connecting not only a massive number of devices, but also providing an always wider variety of services. In the next few years, a big increase in the number of connected devices is expected, together with an important increase in the amount of traffic generated. Never before have wireless communications permeated so deeply in all industries and economic sectors. Therefore, it is crucial to correctly forecast the spectrum needs, which bands should be used for which services, and the economic potential of its utilization. This paper proposes a methodology for spectrum forecasting consisting of two phases: a market study and a spectrum forecasting model. The market study determines the main drivers of the IoT industry for any country: services, technologies, frequency bands, and the number of devices that will require IoT connectivity. The forecasting model takes the market study as the input and calculates the spectrum demand in 5 steps: Defining scenarios for spectrum contention, calculating the offered traffic load, calculating a capacity for some QoS requirements, finding the spectrum required, and adjusting according to key spectral efficiency determinants. This methodology is applied for Colombia’s IoT spectrum forecast. We provide a complete step-by-step implementation in fourteen independent spectrum contention scenarios, calculating offered traffic, required capacity, and spectrum for cellular licensed bands and non-cellular unlicensed bands in a 10-year period. Detailed results are presented specifying coverage area requirements per economic sector, frequency band, and service. The need for higher teledensity and higher spectral efficiency turns out to be a determining factor for spectrum savings.},
DOI = {10.3390/fi13090232}
}



@Article{s21186023,
AUTHOR = {Shah, Sayed Khushal and Tariq, Zeenat and Lee, Jeehwan and Lee, Yugyung},
TITLE = {Event-Driven Deep Learning for Edge Intelligence (EDL-EI)},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {18},
ARTICLE-NUMBER = {6023},
URL = {https://www.mdpi.com/1424-8220/21/18/6023},
PubMedID = {34577228},
ISSN = {1424-8220},
ABSTRACT = {Edge intelligence (EI) has received a lot of interest because it can reduce latency, increase efficiency, and preserve privacy. More significantly, as the Internet of Things (IoT) has proliferated, billions of portable and embedded devices have been interconnected, producing zillions of gigabytes on edge networks. Thus, there is an immediate need to push AI (artificial intelligence) breakthroughs within edge networks to achieve the full promise of edge data analytics. EI solutions have supported digital technology workloads and applications from the infrastructure level to edge networks; however, there are still many challenges with the heterogeneity of computational capabilities and the spread of information sources. We propose a novel event-driven deep-learning framework, called EDL-EI (event-driven deep learning for edge intelligence), via the design of a novel event model by defining events using correlation analysis with multiple sensors in real-world settings and incorporating multi-sensor fusion techniques, a transformation method for sensor streams into images, and lightweight 2-dimensional convolutional neural network (CNN) models. To demonstrate the feasibility of the EDL-EI framework, we presented an IoT-based prototype system that we developed with multiple sensors and edge devices. To verify the proposed framework, we have a case study of air-quality scenarios based on the benchmark data provided by the USA Environmental Protection Agency for the most polluted cities in South Korea and China. We have obtained outstanding predictive accuracy (97.65% and 97.19%) from two deep-learning models on the cities’ air-quality patterns. Furthermore, the air-quality changes from 2019 to 2020 have been analyzed to check the effects of the COVID-19 pandemic lockdown.},
DOI = {10.3390/s21186023}
}



@Article{su131810155,
AUTHOR = {Trauer, Jakob and Pfingstl, Simon and Finsterer, Markus and Zimmermann, Markus},
TITLE = {Improving Production Efficiency with a Digital Twin Based on Anomaly Detection},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {18},
ARTICLE-NUMBER = {10155},
URL = {https://www.mdpi.com/2071-1050/13/18/10155},
ISSN = {2071-1050},
ABSTRACT = {Industry 4.0, cyber-physical systems, and digital twins are generating ever more data. This opens new opportunities for companies, as they can monitor development and production processes, improve their products, and offer additional services. However, companies are often overwhelmed by Big Data, as they cannot handle its volume, velocity, and variety. Additionally, they mostly do not follow a strategy in the collection and usage of data, which leads to unexploited business potentials. This paper presents the implementation of a Digital Twin module in an industrial case study, applying a concept for guiding companies on their way from data to value. A standardized use case template and a procedure model support the companies in (1) formulating a value proposition, (2) analyzing the current process, and (3) conceptualizing a target process. The presented use case entails an anomaly detection algorithm based on Gaussian processes to detect defective products in real-time for the extrusion process of aluminum profiles. The module was initially tested in a relevant environment; however, full implementation is still missing. Therefore, technology readiness level 6 (TRL6) was reached. Furthermore, the effect of the target process on production efficiency is evaluated, leading to significant cost reduction, energy savings, and quality improvements.},
DOI = {10.3390/su131810155}
}



@Article{en14185713,
AUTHOR = {Rabinowitz, Aaron and Araghi, Farhang Motallebi and Gaikwad, Tushar and Asher, Zachary D. and Bradley, Thomas H.},
TITLE = {Development and Evaluation of Velocity Predictive Optimal Energy Management Strategies in Intelligent and Connected Hybrid Electric Vehicles},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {18},
ARTICLE-NUMBER = {5713},
URL = {https://www.mdpi.com/1996-1073/14/18/5713},
ISSN = {1996-1073},
ABSTRACT = {In this study, a thorough and definitive evaluation of Predictive Optimal Energy Management Strategy (POEMS) applications in connected vehicles using 10 to 20 s predicted velocity is conducted for a Hybrid Electric Vehicle (HEV). The presented methodology includes synchronous datasets gathered in Fort Collins, Colorado using a test vehicle equipped with sensors to measure ego vehicle position and motion and that of surrounding objects as well as receive Infrastructure to Vehicle (I2V) information. These datasets are utilized to compare the effect of different signal categories on prediction fidelity for different prediction horizons within a POEMS framework. Multiple artificial intelligence (AI) and machine learning (ML) algorithms use the collected data to output future vehicle velocity prediction models. The effects of different combinations of signals and different models on prediction fidelity in various prediction windows are explored. All of these combinations are ultimately addressed where the rubber meets the road: fuel economy (FE) enabled from POEMS. FE optimization is performed using Model Predictive Control (MPC) with a Dynamic Programming (DP) optimizer. FE improvements from MPC control at various prediction time horizons are compared to that of full-cycle DP. All FE results are determined using high-fidelity simulations of an Autonomie 2010 Toyota Prius model. The full-cycle DP POEMS provides the theoretical upper limit on fuel economy (FE) improvement achievable with POEMS but is not currently practical for real-world implementation. Perfect prediction MPC (PP-MPC) represents the upper limit of FE improvement practically achievable with POEMS. Real-Prediction MPC (RP-MPC) can provide nearly equivalent FE improvement when used with high-fidelity predictions. Constant-Velocity MPC (CV-MPC) uses a constant speed prediction and serves as a “null” POEMS. Results showed that RP-MPC, enabled by high-fidelity ego future speed prediction, led to significant FE improvement over baseline nearly matching that of PP-MPC.},
DOI = {10.3390/en14185713}
}



@Article{vehicles3030036,
AUTHOR = {Dixit, Aditya and Kumar Chidambaram, Ramesh and Allam, Zaheer},
TITLE = {Safety and Risk Analysis of Autonomous Vehicles Using Computer Vision and Neural Networks},
JOURNAL = {Vehicles},
VOLUME = {3},
YEAR = {2021},
NUMBER = {3},
PAGES = {595--617},
URL = {https://www.mdpi.com/2624-8921/3/3/36},
ISSN = {2624-8921},
ABSTRACT = {The autonomous vehicle (AVs) market is expanding at a rapid pace due to the advancement of information, communication, and sensor technology applications, offering a broad range of opportunities in terms of energy efficiency and addressing climate change concerns and safety. With regard to this last point, the rate of reduction in accidents is considerable when switching safety control tasks to machines from humans, which can be noted as having significantly slower response rates. This paper explores this thematic by focusing on the safety of AVs by thorough analysis of previously collected AV crash statistics and further discusses possible solutions for achieving increased autonomous vehicle safety. To achieve this, this technical paper develops a dynamic run-time safe assessment system, using the standard autonomous drive system (ADS), which is developed and simulated in case studies further in the paper. OpenCV methods for lane detection are developed and applied as robust control frameworks, which introduces the factor of vehicle crash predictability for the ego vehicle. The developed system is made to predict possible crashes by using a combination of machine learning and neural network methods, providing useful information for response mechanisms in risk scenarios. In addition, this paper explores the operational design domain (ODD) of the AV’s system and provides possible solutions to extend the domain in order to render vehicle operationality, even in safe mode. Additionally, three case studies are explored to supplement a discussion on the implementation of algorithms aimed at increasing curved lane detection ability and introducing trajectory predictability of neighbouring vehicles for an ego vehicle, resulting in lower collisions and increasing the safety of the AV overall. This paper thus explores the technical development of autonomous vehicles and is aimed at researchers and practitioners engaging in the conceptualisation, design, and implementation of safer AV systems focusing on lane detection and expanding AV safe state domains and vehicle trajectory predictability.},
DOI = {10.3390/vehicles3030036}
}



@Article{act10090241,
AUTHOR = {Xu, Rongxu and Jin, Wenquan and Kim, Dohyeun},
TITLE = {Environment Optimization Scheme Based on Edge Computing Using PSO for Efficient Thermal Comfort Control in Resident Space},
JOURNAL = {Actuators},
VOLUME = {10},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {241},
URL = {https://www.mdpi.com/2076-0825/10/9/241},
ISSN = {2076-0825},
ABSTRACT = {With the fast development of infrastructure and communication technology, the Internet of Things (IoT) has become a promising field. Ongoing research is looking at the smart home environment as the most promising sector that adopts IoT and cloud computing to improve resident live experiences. The IoT and cloud-dependent smart home services related to recent researches have security, bandwidth issues, and a lack of concerning thermal comfort of residents. In this paper, we propose an environment optimization scheme based on edge computing using Particle Swarm Optimization (PSO) for efficient thermal comfort control in resident space to overcome the aforementioned limitations of researches on smart homes. The comfort level of a resident in a smart home is evaluated by Predicted Mean Vote (PMV) that represents the thermal response of occupants. The PSO algorithm combined with PMV to improve the accuracy of the optimization results for efficient thermal comfort control in a smart home environment. We integrate IoT with edge computing to upgrade the capabilities of IoT nodes in computing power, storage space, and reliable connectivity. We use EdgeX as an edge computing platform to develop a thermal comfort considering PMV-based optimization engine with a PSO algorithm to generate the resident’s friendly environment parameters and rules engine to detects the environmental change of the smart home in real-time to maintain the indoor environment thermal comfortable. For evaluating our proposed system that maintenance resident environment with thermal comfort index based on PSO optimization scheme in smart homes, we conduct the comparison between the real data with optimized data, and measure the execution times of optimization function. From the experimental results, when our proposed system is applied, it satisfies thermal comfort and consumes energy more stably.},
DOI = {10.3390/act10090241}
}



@Article{s21196340,
AUTHOR = {Huang, Ziqi and Shen, Yang and Li, Jiayi and Fey, Marcel and Brecher, Christian},
TITLE = {A Survey on AI-Driven Digital Twins in Industry 4.0: Smart Manufacturing and Advanced Robotics},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {6340},
URL = {https://www.mdpi.com/1424-8220/21/19/6340},
PubMedID = {34640660},
ISSN = {1424-8220},
ABSTRACT = {Digital twin (DT) and artificial intelligence (AI) technologies have grown rapidly in recent years and are considered by both academia and industry to be key enablers for Industry 4.0. As a digital replica of a physical entity, the basis of DT is the infrastructure and data, the core is the algorithm and model, and the application is the software and service. The grounding of DT and AI in industrial sectors is even more dependent on the systematic and in-depth integration of domain-specific expertise. This survey comprehensively reviews over 300 manuscripts on AI-driven DT technologies of Industry 4.0 used over the past five years and summarizes their general developments and the current state of AI-integration in the fields of smart manufacturing and advanced robotics. These cover conventional sophisticated metal machining and industrial automation as well as emerging techniques, such as 3D printing and human–robot interaction/cooperation. Furthermore, advantages of AI-driven DTs in the context of sustainable development are elaborated. Practical challenges and development prospects of AI-driven DTs are discussed with a respective focus on different levels. A route for AI-integration in multiscale/fidelity DTs with multiscale/fidelity data sources in Industry 4.0 is outlined.},
DOI = {10.3390/s21196340}
}



@Article{infrastructures6100138,
AUTHOR = {Borges, Fábio de Souza Pereira and Fonseca, Adelayda Pallavicini and Garcia, Reinaldo Crispiniano},
TITLE = {Deep Reinforcement Learning Model to Mitigate Congestion in Real-Time Traffic Light Networks},
JOURNAL = {Infrastructures},
VOLUME = {6},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {138},
URL = {https://www.mdpi.com/2412-3811/6/10/138},
ISSN = {2412-3811},
ABSTRACT = {Urban traffic congestion has a significant detrimental impact on the environment, public health and the economy, with at a high cost to society worldwide. Moreover, it is not possible to continually modify urban road infrastructure in order to mitigate increasing traffic demand. Therefore, it is important to develop traffic control models that can handle high-volume traffic data and synchronize traffic lights in an urban network in real time, without interfering with other initiatives. Within this context, this study proposes a model, based on deep reinforcement learning, for synchronizing the traffic signals of an urban traffic network composed of two intersections. The calibration of this model, including training of its neural network, was performed using real traffic data collected at the approach to each intersection. The results achieved through simulations were very promising, yielding significant improvements in indicators measured in relation to the pre-existing conditions in the network. The model was able to deal with a broad spectrum of traffic flows and, in peak demand periods, reduced delays and queue lengths by more than 28% and 42%, respectively.},
DOI = {10.3390/infrastructures6100138}
}



@Article{ijgi10100653,
AUTHOR = {Dou, Zixin and Sun, Yanming and Wu, Zhidong and Wang, Tao and Fan, Shiqi and Zhang, Yuxuan},
TITLE = {The Architecture of Mass Customization-Social Internet of Things System: Current Research Profile},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {653},
URL = {https://www.mdpi.com/2220-9964/10/10/653},
ISSN = {2220-9964},
ABSTRACT = {In the era of big data, mass customization (MC) systems are faced with the complexities associated with information explosion and management control. Thus, it has become necessary to integrate the mass customization system and Social Internet of Things, in order to effectively connecting customers with enterprises. We should not only allow customers to participate in MC production throughout the whole process, but also allow enterprises to control all links throughout the whole information system. To gain a better understanding, this paper first describes the architecture of the proposed system from organizational and technological perspectives. Then, based on the nature of the Social Internet of Things, the main technological application of the mass customization–Social Internet of Things (MC–SIOT) system is introduced in detail. On this basis, the key problems faced by the mass customization–Social Internet of Things system are listed. Our findings are as follows: (1) MC–SIOT can realize convenient information queries and clearly understand the user’s intentions; (2) the system can predict the changing relationships among different technical fields and help enterprise R&amp;D personnel to find technical knowledge; and (3) it can interconnect deep learning technology and digital twin technology to better maintain the operational state of the system. However, there exist some challenges relating to data management, knowledge discovery, and human–computer interaction, such as data quality management, few data samples, a lack of dynamic learning, labor consumption, and task scheduling. Therefore, we put forward possible improvements to be assessed, as well as privacy issues and emotional interactions to be further discussed, in future research. Finally, we illustrate the behavior and evolutionary mechanism of this system, both qualitatively and quantitatively. This provides some idea of how to address the current issues pertaining to mass customization systems.},
DOI = {10.3390/ijgi10100653}
}



@Article{electronics10192377,
AUTHOR = {Khan, Mohammad Zubair and Alhazmi, Omar H. and Javed, Muhammad Awais and Ghandorh, Hamza and Aloufi, Khalid S.},
TITLE = {Reliable Internet of Things: Challenges and Future Trends},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {2377},
URL = {https://www.mdpi.com/2079-9292/10/19/2377},
ISSN = {2079-9292},
ABSTRACT = {The Internet of Things (IoT) is a vital component of many future industries. By intelligent integration of sensors, wireless communications, computing techniques, and data analytics, IoT can increase productivity and efficiency of industries. Reliability of data transmission is key to realize several applications offered by IoT. In this paper, we present an overview of future IoT applications, and their major communication requirements. We provide a brief survey of recent work in four major areas of reliable IoT including resource allocation, latency management, security, and reliability metrics. Finally, we highlight some of the important challenges for reliable IoT related to machine learning techniques, 6G communications and blockchain based security that need further investigation and discuss related future directions.},
DOI = {10.3390/electronics10192377}
}



@Article{s21196499,
AUTHOR = {Li, Shuyang and Hu, Xiaohui and Du, Yongwen},
TITLE = {Deep Reinforcement Learning for Computation Offloading and Resource Allocation in Unmanned-Aerial-Vehicle Assisted Edge Computing},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {6499},
URL = {https://www.mdpi.com/1424-8220/21/19/6499},
PubMedID = {34640820},
ISSN = {1424-8220},
ABSTRACT = {Computation offloading technology extends cloud computing to the edge of the access network close to users, bringing many benefits to terminal devices with limited battery and computational resources. Nevertheless, the existing computation offloading approaches are challenging to apply to specific scenarios, such as the dense distribution of end-users and the sparse distribution of network infrastructure. The technological revolution in the unmanned aerial vehicle (UAV) and chip industry has granted UAVs more computing resources and promoted the emergence of UAV-assisted mobile edge computing (MEC) technology, which could be applied to those scenarios. However, in the MEC system with multiple users and multiple servers, making reasonable offloading decisions and allocating system resources is still a severe challenge. This paper studies the offloading decision and resource allocation problem in the UAV-assisted MEC environment with multiple users and servers. To ensure the quality of service for end-users, we set the weighted total cost of delay, energy consumption, and the size of discarded tasks as our optimization objective. We further formulate the joint optimization problem as a Markov decision process and apply the soft actor–critic (SAC) deep reinforcement learning algorithm to optimize the offloading policy. Numerical simulation results show that the offloading policy optimized by our proposed SAC-based dynamic computing offloading (SACDCO) algorithm effectively reduces the delay, energy consumption, and size of discarded tasks for the UAV-assisted MEC system. Compared with the fixed local-UAV scheme in the specific simulation setting, our proposed approach reduces system delay and energy consumption by approximately 50% and 200%, respectively.},
DOI = {10.3390/s21196499}
}



@Article{s21196588,
AUTHOR = {Kamal, Muhammad Ayoub and Raza, Hafiz Wahab and Alam, Muhammad Mansoor and Su’ud, Mazliham Mohd and Sajak, Aznida binti Abu Bakar},
TITLE = {Resource Allocation Schemes for 5G Network: A Systematic Review},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {6588},
URL = {https://www.mdpi.com/1424-8220/21/19/6588},
PubMedID = {34640908},
ISSN = {1424-8220},
ABSTRACT = {Fifth-generation (5G) communication technology is intended to offer higher data rates, outstanding user exposure, lower power consumption, and extremely short latency. Such cellular networks will implement a diverse multi-layer model comprising device-to-device networks, macro-cells, and different categories of small cells to assist customers with desired quality-of-service (QoS). This multi-layer model affects several studies that confront utilizing interference management and resource allocation in 5G networks. With the growing need for cellular service and the limited resources to provide it, capably handling network traffic and operation has become a problem of resource distribution. One of the utmost serious problems is to alleviate the jamming in the network in support of having a better QoS. However, although a limited number of review papers have been written on resource distribution, no review papers have been written specifically on 5G resource allocation. Hence, this article analyzes the issue of resource allocation by classifying the various resource allocation schemes in 5G that have been reported in the literature and assessing their ability to enhance service quality. This survey bases its discussion on the metrics that are used to evaluate network performance. After consideration of the current evidence on resource allocation methods in 5G, the review hopes to empower scholars by suggesting future research areas on which to focus.},
DOI = {10.3390/s21196588}
}



@Article{en14196309,
AUTHOR = {Peyman, Mohammad and Copado, Pedro J. and Tordecilla, Rafael D. and Martins, Leandro do C. and Xhafa, Fatos and Juan, Angel A.},
TITLE = {Edge Computing and IoT Analytics for Agile Optimization in Intelligent Transportation Systems},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {6309},
URL = {https://www.mdpi.com/1996-1073/14/19/6309},
ISSN = {1996-1073},
ABSTRACT = {With the emergence of fog and edge computing, new possibilities arise regarding the data-driven management of citizens’ mobility in smart cities. Internet of Things (IoT) analytics refers to the use of these technologies, data, and analytical models to describe the current status of the city traffic, to predict its evolution over the coming hours, and to make decisions that increase the efficiency of the transportation system. It involves many challenges such as how to deal and manage real and huge amounts of data, and improving security, privacy, scalability, reliability, and quality of services in the cloud and vehicular network. In this paper, we review the state of the art of IoT in intelligent transportation systems (ITS), identify challenges posed by cloud, fog, and edge computing in ITS, and develop a methodology based on agile optimization algorithms for solving a dynamic ride-sharing problem (DRSP) in the context of edge/fog computing. These algorithms allow us to process, in real time, the data gathered from IoT systems in order to optimize automatic decisions in the city transportation system, including: optimizing the vehicle routing, recommending customized transportation modes to the citizens, generating efficient ride-sharing and car-sharing strategies, create optimal charging station for electric vehicles and different services within urban and interurban areas. A numerical example considering a DRSP is provided, in which the potential of employing edge/fog computing, open data, and agile algorithms is illustrated.},
DOI = {10.3390/en14196309}
}



@Article{app11199210,
AUTHOR = {Do, Nguyet Quang and Selamat, Ali and Krejcar, Ondrej and Yokoi, Takeru and Fujita, Hamido},
TITLE = {Phishing Webpage Classification via Deep Learning-Based Algorithms: An Empirical Study},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {9210},
URL = {https://www.mdpi.com/2076-3417/11/19/9210},
ISSN = {2076-3417},
ABSTRACT = {Phishing detection with high-performance accuracy and low computational complexity has always been a topic of great interest. New technologies have been developed to improve the phishing detection rate and reduce computational constraints in recent years. However, one solution is insufficient to address all problems caused by attackers in cyberspace. Therefore, the primary objective of this paper is to analyze the performance of various deep learning algorithms in detecting phishing activities. This analysis will help organizations or individuals select and adopt the proper solution according to their technological needs and specific applications’ requirements to fight against phishing attacks. In this regard, an empirical study was conducted using four different deep learning algorithms, including deep neural network (DNN), convolutional neural network (CNN), Long Short-Term Memory (LSTM), and gated recurrent unit (GRU). To analyze the behaviors of these deep learning architectures, extensive experiments were carried out to examine the impact of parameter tuning on the performance accuracy of the deep learning models. In addition, various performance metrics were measured to evaluate the effectiveness and feasibility of DL models in detecting phishing activities. The results obtained from the experiments showed that no single DL algorithm achieved the best measures across all performance metrics. The empirical findings from this paper also manifest several issues and suggest future research directions related to deep learning in the phishing detection domain.},
DOI = {10.3390/app11199210}
}



@Article{s21196647,
AUTHOR = {Tan, Soo Fun and Samsudin, Azman},
TITLE = {Recent Technologies, Security Countermeasure and Ongoing Challenges of Industrial Internet of Things (IIoT): A Survey},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {6647},
URL = {https://www.mdpi.com/1424-8220/21/19/6647},
PubMedID = {34640967},
ISSN = {1424-8220},
ABSTRACT = {The inherent complexities of Industrial Internet of Things (IIoT) architecture make its security and privacy issues becoming critically challenging. Numerous surveys have been published to review IoT security issues and challenges. The studies gave a general overview of IIoT security threats or a detailed analysis that explicitly focuses on specific technologies. However, recent studies fail to analyze the gap between security requirements of these technologies and their deployed countermeasure in the industry recently. Whether recent industry countermeasure is still adequate to address the security challenges of IIoT environment are questionable. This article presents a comprehensive survey of IIoT security and provides insight into today’s industry countermeasure, current research proposals and ongoing challenges. We classify IIoT technologies into the four-layer security architecture, examine the deployed countermeasure based on CIA+ security requirements, report the deficiencies of today’s countermeasure, and highlight the remaining open issues and challenges. As no single solution can fix the entire IIoT ecosystem, IIoT security architecture with a higher abstraction level using the bottom-up approach is needed. Moving towards a data-centric approach that assures data protection whenever and wherever it goes could potentially solve the challenges of industry deployment.},
DOI = {10.3390/s21196647}
}



@Article{fi13100260,
AUTHOR = {Qiao, Wenxin and Lu, Hao and Lu, Yu and Meng, Lijie and Liu, Yicen},
TITLE = {A Dynamic Service Reconfiguration Method for Satellite–Terrestrial Integrated Networks},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {260},
URL = {https://www.mdpi.com/1999-5903/13/10/260},
ISSN = {1999-5903},
ABSTRACT = {Satellite–terrestrial integrated networks (STINs) are regarded as a promising solution to meeting the demands of global high-speed seamless network access in the future. Software-defined networking and network function virtualization (SDN/NFV) are two complementary technologies that can be used to ensure that the heterogeneous resources in STINs can be easily managed and deployed. Considering the dual mobility of satellites and ubiquitous users, along with the dynamic requirements of user requests and network resource states, it is challenging to maintain service continuity and high QoE performance in STINs. Thus, we investigate the service migration and reconfiguration scheme, which are of great significance to the guarantee of continuous service provisioning. Specifically, this paper proposes a dynamic service reconfiguration method that can support flexible service configurations on integrated networks, including LEO satellites and ground nodes. We first model the migration cost as an extra delay incurred by service migration and reconfiguration and then formulate the selection processes of the location and migration paths of virtual network functions (VNFs) as an integer linear programming (ILP) optimization problem. Then, we propose a fuzzy logic and quantum genetic algorithm (FQGA) to obtain an approximate optimal solution that can accelerate the solving process efficiently with the benefits of the high-performance computing capacity of QGA. The simulation results validate the effectiveness and improved performance of the scheme proposed in this paper.},
DOI = {10.3390/fi13100260}
}



@Article{min11101118,
AUTHOR = {Mishra, Amit Kumar},
TITLE = {AI4R2R (AI for Rock to Revenue): A Review of the Applications of AI in Mineral Processing},
JOURNAL = {Minerals},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {1118},
URL = {https://www.mdpi.com/2075-163X/11/10/1118},
ISSN = {2075-163X},
ABSTRACT = {In the last few years, jargon, such as machine learning (ML) and artificial intelligence (AI), have been ubiquitous in both popular science media as well as the academic literature. Many industries have tried the current suite of ML and AI algorithms with various degrees of success. Mineral processing, as an industry, is looking at AI for two reasons. First of all, as with other industries, it is pertinent to know if AI algorithms can be used to enhance productivity. The second reason is specific to the mining industry. Of late, the grade of ores is reducing, and the demand for ethical mining (with as little effect on ecology as possible) is increasing. Thus, mineral processing industries also want to explore the possible use of AI in solving these challenges. In this review paper, first, the challenges in mineral processing that can potentially be solved by AI are presented. Then, some of the most pertinent developments in the domain of ML and AI (applied in the domain of mineral processing) are discussed. Lastly, a top-level modus operandi is presented for a mineral processing industry that might want to explore the possibilities of using AI in its processes. Following are some of the new paradigms added by this review. This review presents a holistic view of the domain of mineral processing with an AI lens. It is also one of the first reviews in this domain to thoroughly discuss the use of AI in ethical, green, and sustainable mineral processing. The AI process proposed in this paper is a comprehensive one. To ensure the relevance to industry, the flow was made agile with the spiral system engineering flow. This is expected to drive rapid and agile investigation of the potential of applying ML and AI in different mineral processing industries.},
DOI = {10.3390/min11101118}
}



@Article{iot2040031,
AUTHOR = {Ajayi, Oluwashina Joseph and Rafferty, Joseph and Santos, Jose and Garcia-Constantino, Matias and Cui, Zhan},
TITLE = {BECA: A Blockchain-Based Edge Computing Architecture for Internet of Things Systems},
JOURNAL = {IoT},
VOLUME = {2},
YEAR = {2021},
NUMBER = {4},
PAGES = {610--632},
URL = {https://www.mdpi.com/2624-831X/2/4/31},
ISSN = {2624-831X},
ABSTRACT = {The scale of Internet of Things (IoT) systems has expanded in recent times and, in tandem with this, IoT solutions have developed symbiotic relationships with technologies, such as edge Computing. IoT has leveraged edge computing capabilities to improve the capabilities of IoT solutions, such as facilitating quick data retrieval, low latency response, and advanced computation, among others. However, in contrast with the benefits offered by edge computing capabilities, there are several detractors, such as centralized data storage, data ownership, privacy, data auditability, and security, which concern the IoT community. This study leveraged blockchain&rsquo;s inherent capabilities, including distributed storage system, non-repudiation, privacy, security, and immutability, to provide a novel, advanced edge computing architecture for IoT systems. Specifically, this blockchain-based edge computing architecture addressed centralized data storage, data auditability, privacy, data ownership, and security. Following implementation, the performance of this solution was evaluated to quantify performance in terms of response time and resource utilization. The results show the viability of the proposed and implemented architecture, characterized by improved privacy, device data ownership, security, and data auditability while implementing decentralized storage.},
DOI = {10.3390/iot2040031}
}



@Article{ijgi10100703,
AUTHOR = {You, Lan and Guan, Zhengyi and Li, Na and Zhang, Jiahe and Cui, Haibo and Claramunt, Christophe and Cao, Rui},
TITLE = {A Spatio-Temporal Schedule-Based Neural Network for Urban Taxi Waiting Time Prediction},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {703},
URL = {https://www.mdpi.com/2220-9964/10/10/703},
ISSN = {2220-9964},
ABSTRACT = {Taxi waiting times is an important criterion for taxi passengers to choose appropriate pick-up locations in urban environments. How to predict the taxi waiting time accurately at a certain time and location is the key solution for the imbalance between the taxis’ supplies and demands. Considering the life schedule of urban residents and the different functions of geogrid regions, the research developed in this paper introduces a spatio-temporal schedule-based neural network for urban taxi waiting time prediction. The approach integrates a series of multi-source data from taxi trajectories to city points of interest, different time frames and human behaviors in the city. We apply a grid-based and functional structuration of an urban space that provides a lower-level data representation. Overall, the neural network model can dynamically predict the waiting time of taxi passengers in real time under some given spatio-temporal constraints. The experimental results show that the granular-based grids and spatio-temporal neural network can effectively predict and optimize the accuracy of taxi waiting times. This work provides a decision support for intelligent travel predictions of taxi waiting time in a smart city.},
DOI = {10.3390/ijgi10100703}
}



@Article{bdcc5040056,
AUTHOR = {Hao, Yixue and Miao, Yiming and Chen, Min and Gharavi, Hamid and Leung, Victor C. M.},
TITLE = {6G Cognitive Information Theory: A Mailbox Perspective},
JOURNAL = {Big Data and Cognitive Computing},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {56},
URL = {https://www.mdpi.com/2504-2289/5/4/56},
ISSN = {2504-2289},
ABSTRACT = {With the rapid development of 5G communications, enhanced mobile broadband, massive machine type communications and ultra-reliable low latency communications are widely supported. However, a 5G communication system is still based on Shannon’s information theory, while the meaning and value of information itself are not taken into account in the process of transmission. Therefore, it is difficult to meet the requirements of intelligence, customization, and value transmission of 6G networks. In order to solve the above challenges, we propose a 6G mailbox theory, namely a cognitive information carrier to enable distributed algorithm embedding for intelligence networking. Based on Mailbox, a 6G network will form an intelligent agent with self-organization, self-learning, self-adaptation, and continuous evolution capabilities. With the intelligent agent, redundant transmission of data can be reduced while the value transmission of information can be improved. Then, the features of mailbox principle are introduced, including polarity, traceability, dynamics, convergence, figurability, and dependence. Furthermore, key technologies with which value transmission of information can be realized are introduced, including knowledge graph, distributed learning, and blockchain. Finally, we establish a cognitive communication system assisted by deep learning. The experimental results show that, compared with a traditional communication system, our communication system performs less data transmission quantity and error.},
DOI = {10.3390/bdcc5040056}
}



@Article{app11209680,
AUTHOR = {Zhou, Xuan and Ke, Ruimin and Yang, Hao and Liu, Chenxi},
TITLE = {When Intelligent Transportation Systems Sensing Meets Edge Computing: Vision and Challenges},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {9680},
URL = {https://www.mdpi.com/2076-3417/11/20/9680},
ISSN = {2076-3417},
ABSTRACT = {The widespread use of mobile devices and sensors has motivated data-driven applications that can leverage the power of big data to benefit many aspects of our daily life, such as health, transportation, economy, and environment. Under the context of smart city, intelligent transportation systems (ITS), as a main building block of modern cities, and edge computing (EC), as an emerging computing service that targets addressing the limitations of cloud computing, have attracted increasing attention in the research community in recent years. It is well believed that the application of EC in ITS will have considerable benefits to transportation systems regarding efficiency, safety, and sustainability. Despite the growing trend in ITS and EC research, a big gap in the existing literature is identified: the intersection between these two promising directions has been far from well explored. In this paper, we focus on a critical part of ITS, i.e., sensing, and conducting a review on the recent advances in ITS sensing and EC applications in this field. The key challenges in ITS sensing and future directions with the integration of edge computing are discussed.},
DOI = {10.3390/app11209680}
}



@Article{smartcities4040072,
AUTHOR = {Carneiro, Davide and Amaral, António and Carvalho, Mariana and Barreto, Luís},
TITLE = {An Anthropocentric and Enhanced Predictive Approach to Smart City Management},
JOURNAL = {Smart Cities},
VOLUME = {4},
YEAR = {2021},
NUMBER = {4},
PAGES = {1366--1390},
URL = {https://www.mdpi.com/2624-6511/4/4/72},
ISSN = {2624-6511},
ABSTRACT = {Cities are becoming increasingly complex to manage, as they increase in size and must provide higher living standards for their populations. New technology-based solutions must be developed towards attending this growth and ensuring that it is socially sustainable. This paper puts forward the notion that these solutions must share some properties: they should be anthropocentric, holistic, horizontal, multi-dimensional, multi-modal, and predictive. We propose an architecture in which streaming data sources that characterize the city context are used to feed a real-time graph of the city’s assets and states, as well as to train predictive models that hint into near future states of the city. This allows human decision-makers and automated services to take decisions, both for the present and for the future. To achieve this, multiple data sources about a city were gradually connected to a message broker, that enables increasingly rich decision-support. Results show that it is possible to predict future states of a city, in aspects such as traffic, air pollution, and other ambient variables. The key innovative aspect of this work is that, as opposed to the majority of existing approaches which focus on a real-time view of the city, we also provide insights into the near-future state of the city, thus allowing city services to plan ahead and adapt accordingly. The main goal is to optimize decision-making by anticipating future states of the city and make decisions accordingly.},
DOI = {10.3390/smartcities4040072}
}



@Article{app11219850,
AUTHOR = {Joo, Hyunjin and Lim, Yujin},
TITLE = {Traffic Signal Time Optimization Based on Deep Q-Network},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {9850},
URL = {https://www.mdpi.com/2076-3417/11/21/9850},
ISSN = {2076-3417},
ABSTRACT = {Because cities worldwide have high population concentration, traffic congestion is a key problem that needs to be addressed. As modern technology advances, smart traffic management is able to collect data from the environment and uses a contextual signal assignment to determine the traffic flow at intersections and improve the traffic conditions. In this paper, we propose a green signal time allocation system based on a deep Q-network (DQN) that can maximize the capacity at intersections and assign the green light time according to the traffic conditions. The proposed system also aims to reduce the standard deviation of each lane at an intersection by considering the standard deviation of the waiting time. As a result, selfish green signal allocations can be reduced. Thus, the proposed system can achieve better experimental results in a dynamic environment than those of the green signal phase sequence allocation system.},
DOI = {10.3390/app11219850}
}



@Article{a14110302,
AUTHOR = {Atli, İbrahim and Ozturk, Metin and Valastro, Gianluca C. and Asghar, Muhammad Zeeshan},
TITLE = {Multi-Objective UAV Positioning Mechanism for Sustainable Wireless Connectivity in Environments with Forbidden Flying Zones},
JOURNAL = {Algorithms},
VOLUME = {14},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {302},
URL = {https://www.mdpi.com/1999-4893/14/11/302},
ISSN = {1999-4893},
ABSTRACT = {A communication system based on unmanned aerial vehicles (UAVs) is a viable alternative for meeting the coverage and capacity needs of future wireless networks. However, because of the limitations of UAV-enabled communications in terms of coverage, energy consumption, and flying laws, the number of studies focused on the sustainability element of UAV-assisted networking in the literature was limited thus far. We present a solution to this problem in this study; specifically, we design a Q-learning-based UAV placement strategy for long-term wireless connectivity while taking into account major constraints such as altitude regulations, nonflight zones, and transmit power. The goal is to determine the best location for the UAV base station (BS) while reducing energy consumption and increasing the number of users covered. Furthermore, a weighting method is devised, allowing energy usage and the number of users served to be prioritized based on network/battery circumstances. The suggested Q-learning-based solution is contrasted to the standard k-means clustering method, in which the UAV BS is positioned at the centroid location with the shortest cumulative distance between it and the users. The results demonstrate that the proposed solution outperforms the baseline k-means clustering-based method in terms of the number of users covered while achieving the desired minimization of the energy consumption.},
DOI = {10.3390/a14110302}
}



@Article{s21217053,
AUTHOR = {Mobasheri, Motahareh and Kim, Yangwoo and Kim, Woongsup},
TITLE = {Toward an Adaptive Threshold on Cooperative Bandwidth Management Based on Hierarchical Reinforcement Learning},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7053},
URL = {https://www.mdpi.com/1424-8220/21/21/7053},
PubMedID = {34770360},
ISSN = {1424-8220},
ABSTRACT = {With the increase in Internet of Things (IoT) devices and network communications, but with less bandwidth growth, the resulting constraints must be overcome. Due to the network complexity and uncertainty of emergency distribution parameters in smart environments, using predetermined rules seems illogical. Reinforcement learning (RL), as a powerful machine learning approach, can handle such smart environments without a trainer or supervisor. Recently, we worked on bandwidth management in a smart environment with several fog fragments using limited shared bandwidth, where IoT devices may experience uncertain emergencies in terms of the time and sequence needed for more bandwidth for further higher-level communication. We introduced fog fragment cooperation using an RL approach under a predefined fixed threshold constraint. In this study, we promote this approach by removing the fixed level of restriction of the threshold through hierarchical reinforcement learning (HRL) and completing the cooperation qualification. At the first learning hierarchy level of the proposed approach, the best threshold level is learned over time, and the final results are used by the second learning hierarchy level, where the fog node learns the best device for helping an emergency device by temporarily lending the bandwidth. Although equipping the method to the adaptive threshold and restricting fog fragment cooperation make the learning procedure more difficult, the HRL approach increases the method’s efficiency in terms of time and performance.},
DOI = {10.3390/s21217053}
}



@Article{su132111772,
AUTHOR = {Nawaz, Afifa and Zafar, Nazir Ahmad and Alkhammash, Eman H.},
TITLE = {Formal Modeling of Responsive Traffic Signaling System Using Graph Theory and VDM-SL},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {11772},
URL = {https://www.mdpi.com/2071-1050/13/21/11772},
ISSN = {2071-1050},
ABSTRACT = {Internet of things (IoT) is playing a major role in smart cities to make a digital environment. Traffic congestion is a serious road issue because of an increasing number of vehicles in urban areas. Some crucial traffic problems include accidents and traffic jams that cause waste of fuel, health diseases, and a waste of time. Present traffic signaling systems are not efficient in resolving congestion problems because of the lack of traffic signals. Nowadays, traffic signaling systems are modeled with fixed time intervals in which no proper mechanism for emergency vehicles is available. Such traffic mechanisms failed to deal with traffic problems effectively. The major objective is to establish a robust traffic monitoring and signaling system that improves signal efficiency by providing a responsive scheme; appropriate routes; a mechanism for emergency vehicles and pedestrians in real-time using Vienna Development Method Specification Language (VDM-SL) formal method and graph theory. A formal model is constructed by considering objects, such as wireless sensors and cameras that are used for collecting information. Graph theory is used to represent the network and find appropriate routes. Unified Modeling Language is used to design the system requirements. The graph-based framework is converted into a formal model by using VDM-SL. The model has been validated and analyzed using many facilities available in the VDM-SL toolbox.},
DOI = {10.3390/su132111772}
}



@Article{app11219993,
AUTHOR = {Ahad, Abdul and Tahir, Mohammad and Sheikh, Muhammad Aman and Ahmed, Kazi Istiaque and Mughees, Amna},
TITLE = {An Intelligent Clustering-Based Routing Protocol (CRP-GR) for 5G-Based Smart Healthcare Using Game Theory and Reinforcement Learning},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {9993},
URL = {https://www.mdpi.com/2076-3417/11/21/9993},
ISSN = {2076-3417},
ABSTRACT = {With advantages such as short and long transmission ranges, D2D communication, low latency, and high node density, the 5G communication standard is a strong contender for smart healthcare. Smart healthcare networks based on 5G are expected to have heterogeneous energy and mobility, requiring them to adapt to the connected environment. As a result, in 5G-based smart healthcare, building a routing protocol that optimizes energy consumption, reduces transmission delay, and extends network lifetime remains a challenge. This paper presents a clustering-based routing protocol to improve the Quality of services (QoS) and energy optimization in 5G-based smart healthcare. QoS and energy optimization are achieved by selecting an energy-efficient clustering head (CH) with the help of game theory (GT) and best multipath route selection with reinforcement learning (RL). The cluster head selection is modeled as a clustering game with a mixed strategy considering various attributes to find equilibrium conditions. The parameters such as distance between nodes, the distance between nodes and base station, the remaining energy and speed of mobility of the nodes were used for cluster head (CH) selection probability. An energy-efficient multipath routing based on reinforcement learning (RL) having (Q-learning) is proposed. The simulation result shows that our proposed clustering-based routing approach improves the QoS and energy optimization compared to existing approaches. The average performances of the proposed schemes CRP-GR and CRP-G are 78% and 71%, respectively, while the existing schemes, such as FBCFP, TEEN and LEACH have average performances of 63%, 48% and 35% accordingly.},
DOI = {10.3390/app11219993}
}



@Article{su132111840,
AUTHOR = {Khanna, Abhirup and Sah, Anushree and Bolshev, Vadim and Jasinski, Michal and Vinogradov, Alexander and Leonowicz, Zbigniew and Jasiński, Marek},
TITLE = {Blockchain: Future of e-Governance in Smart Cities},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {11840},
URL = {https://www.mdpi.com/2071-1050/13/21/11840},
ISSN = {2071-1050},
ABSTRACT = {In recent times, Blockchain has emerged as a transformational technology with the ability to disrupt and evolve multiple domains. As a decentralized, immutable distributed ledger, Blockchain technology is one of the most recent entrants to the comprehensive ideology of Smart Cities. The rise of urbanization and increased citizen participation have led to various technology integrations in our present-day cities. For cities to become smart, we need standard frameworks and procedures for integrating technology, citizens and governments. In this paper, we explore the potential of Blockchain technology as an enabler for e-governance in smart cities. We examine the daily challenges of citizens and compare them with the benefits being offered by Blockchain integration. On the basis of a comprehensive literature review, we identified four key areas of e-governance wherein Blockchain can provide monumental advantages. In the context of Blockchain integration for e-governance, the paper presents a survey of prominent published works discussing various urban applications.},
DOI = {10.3390/su132111840}
}



@Article{make3040043,
AUTHOR = {Xiang, Xuanchen and Foo, Simon and Zang, Huanyu},
TITLE = {Recent Advances in Deep Reinforcement Learning Applications for Solving Partially Observable Markov Decision Processes (POMDP) Problems Part 2—Applications in Transportation, Industries, Communications and Networking and More Topics},
JOURNAL = {Machine Learning and Knowledge Extraction},
VOLUME = {3},
YEAR = {2021},
NUMBER = {4},
PAGES = {863--878},
URL = {https://www.mdpi.com/2504-4990/3/4/43},
ISSN = {2504-4990},
ABSTRACT = {The two-part series of papers provides a survey on recent advances in Deep Reinforcement Learning (DRL) for solving partially observable Markov decision processes (POMDP) problems. Reinforcement Learning (RL) is an approach to simulate the human’s natural learning process, whose key is to let the agent learn by interacting with the stochastic environment. The fact that the agent has limited access to the information of the environment enables AI to be applied efficiently in most fields that require self-learning. It’s essential to have an organized investigation—we can make good comparisons and choose the best structures or algorithms when applying DRL in various applications. The first part of the overview introduces Markov Decision Processes (MDP) problems and Reinforcement Learning and applications of DRL for solving POMDP problems in games, robotics, and natural language processing. In part two, we continue to introduce applications in transportation, industries, communications and networking, etc. and discuss the limitations of DRL.},
DOI = {10.3390/make3040043}
}



@Article{sym13112040,
AUTHOR = {Serey, Joel and Quezada, Luis and Alfaro, Miguel and Fuertes, Guillermo and Vargas, Manuel and Ternero, Rodrigo and Sabattin, Jorge and Duran, Claudia and Gutierrez, Sebastian},
TITLE = {Artificial Intelligence Methodologies for Data Management},
JOURNAL = {Symmetry},
VOLUME = {13},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2040},
URL = {https://www.mdpi.com/2073-8994/13/11/2040},
ISSN = {2073-8994},
ABSTRACT = {This study analyses the main challenges, trends, technological approaches, and artificial intelligence methods developed by new researchers and professionals in the field of machine learning, with an emphasis on the most outstanding and relevant works to date. This literature review evaluates the main methodological contributions of artificial intelligence through machine learning. The methodology used to study the documents was content analysis; the basic terminology of the study corresponds to machine learning, artificial intelligence, and big data between the years 2017 and 2021. For this study, we selected 181 references, of which 120 are part of the literature review. The conceptual framework includes 12 categories, four groups, and eight subgroups. The study of data management using AI methodologies presents symmetry in the four machine learning groups: supervised learning, unsupervised learning, semi-supervised learning, and reinforced learning. Furthermore, the artificial intelligence methods with more symmetry in all groups are artificial neural networks, Support Vector Machines, K-means, and Bayesian Methods. Finally, five research avenues are presented to improve the prediction of machine learning.},
DOI = {10.3390/sym13112040}
}



@Article{drones5040128,
AUTHOR = {Gopi, Sudheesh Puthenveettil and Magarini, Maurizio and Alsamhi, Saeed Hamood and Shvetsov, Alexey V.},
TITLE = {Machine Learning-Assisted Adaptive Modulation for Optimized Drone-User Communication in B5G},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {128},
URL = {https://www.mdpi.com/2504-446X/5/4/128},
ISSN = {2504-446X},
ABSTRACT = {The fundamental issue for Beyond fifth Generation (B5G) is providing a pervasive connection to heterogeneous and various devices in smart environments. Therefore, Drones play a vital role in the B5G, allowing for wireless broadcast and high-speed communications. In addition, the drone offers several advantages compared to fixed terrestrial communications, including flexible deployment, robust Line of Sight (LoS) connections, and more design degrees of freedom due to controlled mobility. Drones can provide reliable and high data rate connectivity to users irrespective of their location. However, atmospheric disturbances impact the signal quality between drones and users and degrade the system performance. Considering practical implementation, the location of drones makes the drone–user communication susceptible to several environmental disturbances. In this paper, we evaluate the performance of drone-user connectivity during atmospheric disturbances. Further, a Machine Learning (ML)-assisted algorithm is proposed to adapt to a modulation technique that offers optimal performance during atmospheric disturbances. The results show that, with the algorithm, the system switches to a lower order modulation scheme during higher rain rate and provides reliable communication with optimized data rate and error performance.},
DOI = {10.3390/drones5040128}
}



@Article{en14217144,
AUTHOR = {Dorokhova, Marina and Vianin, Jérémie and Alder, Jean-Marie and Ballif, Christophe and Wyrsch, Nicolas and Wannier, David},
TITLE = {A Blockchain-Supported Framework for Charging Management of Electric Vehicles},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7144},
URL = {https://www.mdpi.com/1996-1073/14/21/7144},
ISSN = {1996-1073},
ABSTRACT = {Profound changes driven by decarbonization, decentralization, and digitalization are disrupting the energy industry, bringing new challenges to its key stakeholders. In the attempt to address the climate change issue, increasing penetration of renewables and mobility electrification augment the complexity of the electric grid, thus calling for new management approaches to govern energy exchanges while ensuring reliable and secure operations. The emerging blockchain technology is regarded as one of the most promising solutions to respond to the matter in a decentralized, efficient, fast, and secure way. In this work, we propose an Ethereum-based charging management framework for electric vehicles (EVs), tightly interlinked with physical and software infrastructure and implemented in a real-world demonstration site. With a specifically designed solidity-based smart contract governing the charging process, the proposed framework enables secure and reliable accounting of energy exchanges in a network of trustless peers, thus facilitating the EVs’ deployment and encouraging the adoption of blockchain technology for everyday tasks such as EV charging through private and semi-private charging infrastructure. The results of a multi-actor implementation case study in Switzerland demonstrate the feasibility of the proposed blockchain framework and highlight its potential to reduce costs in a typical EV charging business model. Moreover, the study shows that the suggested framework can speed up the charging and billing processes for EV users, simplify the access to energy markets for charging station owners, and facilitate the interaction between the two through specifically designed mobile and web applications. The implementation presented in this paper can be used as a guideline for future blockchain applications for EV charging and other smart grid projects.},
DOI = {10.3390/en14217144}
}



@Article{s21217330,
AUTHOR = {Zhang, Le and Khalgui, Mohamed and Li, Zhiwu},
TITLE = {Predictive Intelligent Transportation: Alleviating Traffic Congestion in the Internet of Vehicles},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7330},
URL = {https://www.mdpi.com/1424-8220/21/21/7330},
PubMedID = {34770637},
ISSN = {1424-8220},
ABSTRACT = {Due to the limitations of data transfer technologies, existing studies on urban traffic control mainly focused on isolated dimension control such as traffic signal control or vehicle route guidance to alleviate traffic congestion. However, in real traffic, the distribution of traffic flow is the result of multiple dimensions whose future state is influenced by each dimension’s decisions. Presently, the development of the Internet of Vehicles enables an integrated intelligent transportation system. This paper proposes an integrated intelligent transportation model that can optimize predictive traffic signal control and predictive vehicle route guidance simultaneously to alleviate traffic congestion based on their feedback regulation relationship. The challenges of this model lie in that the formulation of the nonlinear feedback relationship between various dimensions is hard to describe and the design of a corresponding solving algorithm that can obtain Pareto optimality for multi-dimension control is complex. In the integrated model, we introduce two medium variables—predictive traffic flow and the predictive waiting time—to two-way link the traffic signal control and vehicle route guidance. Inspired by game theory, an asymmetric information exchange framework-based updating distributed algorithm is designed to solve the integrated model. Finally, an experimental study in two typical traffic scenarios shows that more than 73.33% of the considered cases adopting the integrated model achieve Pareto optimality.},
DOI = {10.3390/s21217330}
}



@Article{computers10110147,
AUTHOR = {Giannoutakis, Konstantinos M. and Filelis-Papadopoulos, Christos K. and Gravvanis, George A. and Tzovaras, Dimitrios},
TITLE = {On the Optimization of Self-Organization and Self-Management Hardware Resource Allocation for Heterogeneous Clouds},
JOURNAL = {Computers},
VOLUME = {10},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {147},
URL = {https://www.mdpi.com/2073-431X/10/11/147},
ISSN = {2073-431X},
ABSTRACT = {There is a tendency, during the last years, to migrate from the traditional homogeneous clouds and centralized provisioning of resources to heterogeneous clouds with specialized hardware governed in a distributed and autonomous manner. The CloudLightning architecture proposed recently introduced a dynamic way to provision heterogeneous cloud resources, by shifting the selection of underlying resources from the end-user to the system in an efficient way. In this work, an optimized Suitability Index and assessment function are proposed, along with their theoretical analysis, for improving the computational efficiency, energy consumption, service delivery and scalability of the distributed orchestration. The effectiveness of the proposed scheme is being evaluated with the use of simulation, by comparing the optimized methods with the original approach and the traditional centralized resource management, on real and synthetic High Performance Computing applications. Finally, numerical results are presented and discussed regarding the improvements over the defined evaluation criteria.},
DOI = {10.3390/computers10110147}
}



@Article{app112210517,
AUTHOR = {Sivasankarareddy, V. and Sundari, G. and Rami Reddy, Ch. and Aymen, Flah and Bortoni, Edson C.},
TITLE = {Grid-Based Routing Model for Energy Efficient and Secure Data Transmission in WSN for Smart Building Applications},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10517},
URL = {https://www.mdpi.com/2076-3417/11/22/10517},
ISSN = {2076-3417},
ABSTRACT = {Presently, due to the establishment of a sensor network, residual buildings in urban areas are being converted into smart buildings. Many sensors are deployed in various buildings to perform different functions, such as water quality monitoring and temperature monitoring. However, the major concern faced in smart building Wireless Sensor Networks (WSNs) is energy depletion and security threats. Many researchers have attempted to solve these issues by various authors in different applications of WSNs. However, limited research has been conducted on smart buildings. Thus, the present research is focused on designing an energy-efficient and secure routing protocol for smart building WSNs. The process in the proposed framework is carried out in two stages. The first stage is the design of the optimal routing protocol based on the grid-clustering approach. In the grid-based model, a grid organizer was selected based on the sailfish optimization algorithm. Subsequently, a fuzzy expert system is used to select the relay node to reach the shortest path for data transmission. The second stage involves designing a trust model for secure data transmission using the two-fish algorithm. A simulation study of the proposed framework was conducted to evaluate its performance. Some metrics, such as the packet delivery ratio, end-end delay, and average residual energy, were calculated for the proposed model. The average residual energy for the proposed framework was 96%, which demonstrates the effectiveness of the proposed routing design.},
DOI = {10.3390/app112210517}
}



@Article{s21227439,
AUTHOR = {Mishra, Mukesh and Gupta, Gourab Sen and Gui, Xiang},
TITLE = {Network Lifetime Improvement through Energy-Efficient Hybrid Routing Protocol for IoT Applications},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7439},
URL = {https://www.mdpi.com/1424-8220/21/22/7439},
PubMedID = {34833516},
ISSN = {1424-8220},
ABSTRACT = {The application of the Internet of Things (IoT) in wireless sensor networks (WSNs) poses serious challenges in preserving network longevity since the IoT necessitates a considerable amount of energy usage for sensing, processing, and data communication. As a result, there are several conventional algorithms that aim to enhance the performance of WSN networks by incorporating various optimization strategies. These algorithms primarily focus on the network layer by developing routing protocols to perform reliable communication in an energy-efficient manner, thus leading to an enhanced network life. For increasing the network lifetime in WSNs, clustering has been widely accepted as an important method that groups sensor nodes (SNs) into clusters. Additionally, numerous researchers have been focusing on devising various methods to increase the network lifetime. The prime factor that helps to maximize the network lifetime is the minimization of energy consumption. The authors of this paper propose a multi-objective optimization approach. It selects the optimal route for transmitting packets from source to sink or the base station (BS). The proposed model employs a two-step approach. The first step employs a trust model to select the cluster heads (CHs) that manage the data communication between the BS and nodes in the cluster. Further, a novel hybrid algorithm, combining a particle swarm optimization (PSO) algorithm and a genetic algorithm (GA), is proposed to determine the routes for data transmission. To validate the efficacy of the proposed hybrid algorithm, named PSOGA, simulations were conducted and the results were compared with the existing LEACH method and PSO, with a random route selection for five different cases. The obtained results establish the efficiency of the proposed approach, as it outperforms existing methods with increased energy efficiency, increased network throughput, high packet delivery rate, and high residual energy throughout the entire iterations.},
DOI = {10.3390/s21227439}
}



@Article{su132212693,
AUTHOR = {Yousaf, Adnan and Asif, Rao Muhammad and Shakir, Mustafa and Rehman, Ateeq Ur and Alassery, Fawaz and Hamam, Habib and Cheikhrouhou, Omar},
TITLE = {A Novel Machine Learning-Based Price Forecasting for Energy Management Systems},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {12693},
URL = {https://www.mdpi.com/2071-1050/13/22/12693},
ISSN = {2071-1050},
ABSTRACT = {Price forecasting (PF) is the primary concern in distributed power generation. This paper presents a novel and improved technique to forecast electricity prices. The data of various power producers, Capacity Purchase Price (CPP), Power Purchase Price (PPP), Tariff rates, and load demand from National Electric Power Regulatory Authority (NEPRA) are considered for MAPE reduction in PF. Eight time-series and auto-regression algorithms are developed for data fetching and setting the objective function. The feed-forward ANFIS based on the ML approach and space vector regression (SVR) is introduced to PF by taking the input from time series and auto-regression (AR) algorithms. Best-feature selection is conducted by adopting the Binary Genetic Algorithm (BGA)-Principal Component Analysis (PCA) approach that ultimately minimizes the complexity and computational time of the model. The proposed integration strategy computes the mean absolute percentage error (MAPE), and the overall improvement percentage is 9.24%, which is valuable in price forecasting of the energy management system (EMS). In the end, EMS based on the Firefly algorithm (FA) has been presented, and by implementing FA, the cost of electricity has been reduced by 21%, 19%, and 20% for building 1, 2, and 3, respectively.},
DOI = {10.3390/su132212693}
}



@Article{fi13110287,
AUTHOR = {Hota, Lopamudra and Nayak, Biraja Prasad and Kumar, Arun and Ali, G. G. Md. Nawaz and Chong, Peter Han Joo},
TITLE = {An Analysis on Contemporary MAC Layer Protocols in Vehicular Networks: State-of-the-Art and Future Directions},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {287},
URL = {https://www.mdpi.com/1999-5903/13/11/287},
ISSN = {1999-5903},
ABSTRACT = {Traffic density around the globe is increasing on a day-to-day basis, resulting in more accidents, congestion, and pollution. The dynamic vehicular environment induces challenges in designing an efficient and reliable protocol for communication. Timely delivery of safety and non-safety messages is necessary for traffic congestion control and for avoiding road mishaps. For efficient resource sharing and optimized channel utilization, the media access control (MAC) protocol plays a vital role. An efficient MAC protocol design can provide fair channel access and can delay constraint safety message dissemination, improving road safety. This paper reviews the applications, characteristics, and challenges faced in the design of MAC protocols. A classification of the MAC protocol is presented based on contention mechanisms and channel access. The classification based on contention is oriented as contention-based, contention-free, and hybrid, whereas the classification based on channel access is categorized as distributed, centralized, cluster-based, cooperative, token-based, and random access. These are further sub-classified as single-channel and multi-channel, based on the type of channel resources they utilize. This paper gives an analysis of the objectives, mechanisms, advantages/disadvantages, and simulators used in specified protocols. Finally, the paper concludes with a discussion on the future scope and open challenges for improving the MAC protocol design.},
DOI = {10.3390/fi13110287}
}



@Article{en14227719,
AUTHOR = {Dymora, Paweł and Mazurek, Mirosław and Sudek, Bartosz},
TITLE = {Comparative Analysis of Selected Open-Source Solutions for Traffic Balancing in Server Infrastructures Providing WWW Service},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7719},
URL = {https://www.mdpi.com/1996-1073/14/22/7719},
ISSN = {1996-1073},
ABSTRACT = {As the number of users increased over the years, pioneering technologies and solutions in given areas ceased to be sufficient even in terms of performance. Therefore, there was a need for their development or even redesign and redefinition. One of the issues that undoubtedly has a huge impact on the current shape of the global network and the way information is processed in it is the issue of traffic balancing, especially the one in the server infrastructure related to the WWW service, providing users with the possibility of efficient and reliable web browsing. The paper presents a comparative analysis of selected open-source solutions used for traffic balancing in server infrastructures providing WWW service based on selected criteria. The designed architecture of the test environment and the test results of selected tools implementing the traffic-balancing functionality are presented. Methodologies, test plans, and comparison criteria are proposed. A comparative analysis of results based on specific criteria was performed. The balance between network traffic optimization and load balancing distribution among servers is crucial for the development of energy-efficient data processing centers.},
DOI = {10.3390/en14227719}
}



@Article{su132212757,
AUTHOR = {Ertek, Gürdal and Kailas, Lakshmi},
TITLE = {Analyzing a Decade of Wind Turbine Accident News with Topic Modeling},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {12757},
URL = {https://www.mdpi.com/2071-1050/13/22/12757},
ISSN = {2071-1050},
ABSTRACT = {Despite the significance and growth of wind energy as a major source of renewable energy, research on the risks of wind turbines in the form of accidents and failures has attracted limited attention. Research that applies data analytics methodologically in this context is scarce. The research presented here, upon construction of a text corpus of 721 selected wind turbine accident and failure news reports, develops and applies a custom-developed data analytics framework that integrates tabular analysis, visualization, text mining, and machine learning. Topic modeling was applied for the first time to identify and classify recurring themes in wind turbine accident news, and association mining was applied to identify contextual terms associated with death and injury. The tabular and visual analyses relate accidents to location (offshore vs. onshore), wind turbine life cycle phases (transportation, construction, operation, and maintenance), and the incidence of death and injury. As one of the insights, more incidents were found to occur during operation and transportation. Through topic modeling, topics associated most with deaths and injuries were revealed. The results could benefit wind turbine manufacturers, service providers, energy companies, insurance companies, government bodies, non-profit organizations, researchers, and other stakeholders in the wind energy sector.},
DOI = {10.3390/su132212757}
}



@Article{en14227756,
AUTHOR = {Zhong , Liang and Zhang , Shizhong and Zhang , Yidu and Chen , Guang and Liu , Yong},
TITLE = {Joint Acquisition Time Design and Sensor Association for Wireless Sensor Networks in Microgrids},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7756},
URL = {https://www.mdpi.com/1996-1073/14/22/7756},
ISSN = {1996-1073},
ABSTRACT = {Wireless sensor networks are used to monitor the operating status of the microgrids, which can effectively improve the stability of power supplies. The topology control is a critical issue of wireless sensor networks, which affects monitoring data transmission reliability and lifetime of wireless sensor networks. Meanwhile, the data acquisition accuracy of wireless sensor networks has a great impact on the quality of monitoring. Therefore, this paper focuses on improving wireless sensor networks data acquisition satisfaction and energy efficiency. A joint acquisition time design and sensor association optimization algorithm is proposed to prolong the lifetime of wireless sensor networks and enhance the stability of monitoring, which considers the cluster heads selection, data collection satisfaction and sensor association. First, a multi-constrained mixed-integer programming problem, which combines acquisition time design and sensor association, is formulated to maximize data acquisition satisfaction and minimize energy consumption. To solve this problem, we propose an iterative algorithm based on block coordinate descent technology. In each iteration, the acquisition time is obtained by Lagrangian duality. After that, the sensor association is modeled as a 0–1 knapsack problem, and the three different methods are proposed to solve it. Finally, the simulations are provided to demonstrate the efficiency of the algorithm proposed in this paper.},
DOI = {10.3390/en14227756}
}



@Article{info12110480,
AUTHOR = {Viktoratos, Iosif and Tsadiras, Athanasios},
TITLE = {Personalized Advertising Computational Techniques: A Systematic Literature Review, Findings, and a Design Framework},
JOURNAL = {Information},
VOLUME = {12},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {480},
URL = {https://www.mdpi.com/2078-2489/12/11/480},
ISSN = {2078-2489},
ABSTRACT = {This work conducts a systematic literature review about the domain of personalized advertisement, and more specifically, about the techniques that are used for this purpose. State-of-the-art publications and techniques are presented in detail, and the relationship of this domain with other related domains such as artificial intelligence (AI), semantic web, etc., is investigated. Important issues such as (a) business data utilization in personalized advertisement models, (b) the cold start problem in the domain, (c) advertisement visualization issues, (d) psychological factors in the personalization models, (e) the lack of rich datasets, and (f) user privacy are highlighted and are pinpointed to help and inspire researchers for future work. Finally, a design framework for personalized advertisement systems has been designed based on these findings.},
DOI = {10.3390/info12110480}
}



@Article{s21227712,
AUTHOR = {Abdelkader, Ghadeer and Elgazzar, Khalid and Khamis, Alaa},
TITLE = {Connected Vehicles: Technology Review, State of the Art, Challenges and Opportunities},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7712},
URL = {https://www.mdpi.com/1424-8220/21/22/7712},
PubMedID = {34833782},
ISSN = {1424-8220},
ABSTRACT = {In an effort to reach accident-free milestones or drastically reduce/eliminate road fatalities rates and traffic congestion and to create disruptive, transformational mobility systems and services, different parties (e.g., automakers, universities, governments, and road traffic regulators) have collaborated to research, develop, and test connected vehicle (CV) technologies. CVs create new data-rich environments and are considered key enablers for many applications and services that will make our roads safer, less congested, and more eco-friendly. A deeper understanding of the CV technologies will pave the way to avoid setbacks and will help in developing more innovative applications and breakthroughs. In the CV paradigm, vehicles become smarter by communicating with nearby vehicles, connected infrastructure, and the surroundings. This connectivity will be substantial to support different features and systems, such as adaptive routing, real-time navigation, and slow and near real-time infrastructure. Further examples include environmental sensing, advanced driver-assistance systems, automated driving systems, mobility on demand, and mobility as a service. This article provides a comprehensive review on CV technologies including fundamental challenges, state-of-the-art enabling technologies, innovative applications, and potential opportunities that can benefit automakers, customers, and businesses. The current standardization efforts of the forefront enabling technologies, such as Wi-Fi 6 and 5G-cellular technologies are also reviewed. Different challenges in terms of cooperative computation, privacy/security, and over-the-air updates are discussed. Safety and non-safety applications are described and possible future opportunities that CV technology brings to our life are also highlighted.},
DOI = {10.3390/s21227712}
}



@Article{s21227705,
AUTHOR = {Reza, Selim and Oliveira, Hugo S. and Machado, José J. M. and Tavares, João Manuel R. S.},
TITLE = {Urban Safety: An Image-Processing and Deep-Learning-Based Intelligent Traffic Management and Control System},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7705},
URL = {https://www.mdpi.com/1424-8220/21/22/7705},
PubMedID = {34833794},
ISSN = {1424-8220},
ABSTRACT = {With the rapid growth and development of cities, Intelligent Traffic Management and Control (ITMC) is becoming a fundamental component to address the challenges of modern urban traffic management, where a wide range of daily problems need to be addressed in a prompt and expedited manner. Issues such as unpredictable traffic dynamics, resource constraints, and abnormal events pose difficulties to city managers. ITMC aims to increase the efficiency of traffic management by minimizing the odds of traffic problems, by providing real-time traffic state forecasts to better schedule the intersection signal controls. Reliable implementations of ITMC improve the safety of inhabitants and the quality of life, leading to economic growth. In recent years, researchers have proposed different solutions to address specific problems concerning traffic management, ranging from image-processing and deep-learning techniques to forecasting the traffic state and deriving policies to control intersection signals. This review article studies the primary public datasets helpful in developing models to address the identified problems, complemented with a deep analysis of the works related to traffic state forecast and intersection-signal-control models. Our analysis found that deep-learning-based approaches for short-term traffic state forecast and multi-intersection signal control showed reasonable results, but lacked robustness for unusual scenarios, particularly during oversaturated situations, which can be resolved by explicitly addressing these cases, potentially leading to significant improvements of the systems overall. However, there is arguably a long path until these models can be used safely and effectively in real-world scenarios.},
DOI = {10.3390/s21227705}
}



@Article{en14227810,
AUTHOR = {Abdelaziz, Ahmed and Santos, Vitor and Dias, Miguel Sales},
TITLE = {Machine Learning Techniques in the Energy Consumption of Buildings: A Systematic Literature Review Using Text Mining and Bibliometric Analysis},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7810},
URL = {https://www.mdpi.com/1996-1073/14/22/7810},
ISSN = {1996-1073},
ABSTRACT = {The high level of energy consumption of buildings is significantly influencing occupant behavior changes towards improved energy efficiency. This paper introduces a systematic literature review with two objectives: to understand the more relevant factors affecting energy consumption of buildings and to find the best intelligent computing (IC) methods capable of classifying and predicting energy consumption of different types of buildings. Adopting the PRISMA method, the paper analyzed 822 manuscripts from 2013 to 2020 and focused on 106, based on title and abstract screening and on manuscripts with experiments. A text mining process and a bibliometric map tool (VOS viewer) were adopted to find the most used terms and their relationships, in the energy and IC domains. Our approach shows that the terms &ldquo;consumption,&rdquo; &ldquo;residential,&rdquo; and &ldquo;electricity&rdquo; are the more relevant terms in the energy domain, in terms of the ratio of important terms (TITs), whereas &ldquo;cluster&rdquo; is the more commonly used term in the IC domain. The paper also shows that there are strong relations between &ldquo;Residential Energy Consumption&rdquo; and &ldquo;Electricity Consumption,&rdquo; &ldquo;Heating&rdquo; and &ldquo;Climate. Finally, we checked and analyzed 41 manuscripts in detail, summarized their major contributions, and identified several research gaps that provide hints for further research.},
DOI = {10.3390/en14227810}
}



@Article{en14237833,
AUTHOR = {Deb, Sanchari},
TITLE = {Machine Learning for Solving Charging Infrastructure Planning Problems: A Comprehensive Review},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7833},
URL = {https://www.mdpi.com/1996-1073/14/23/7833},
ISSN = {1996-1073},
ABSTRACT = {As a result of environmental pollution and the ever-growing demand for energy, there has been a shift from conventional vehicles towards electric vehicles (EVs). Public acceptance of EVs and their large-scale deployment raises requires a fully operational charging infrastructure. Charging infrastructure planning is an intricate process involving various activities, such as charging station placement, charging demand prediction, and charging scheduling. This planning process involves interactions between power distribution and the road network. The advent of machine learning has made data-driven approaches a viable means for solving charging infrastructure planning problems. Consequently, researchers have started using machine learning techniques to solve the aforementioned problems associated with charging infrastructure planning. This work aims to provide a comprehensive review of the machine learning applications used to solve charging infrastructure planning problems. Furthermore, three case studies on charging station placement and charging demand prediction are presented. This paper is an extension of: Deb, S. (2021, June). Machine Learning for Solving Charging Infrastructure Planning: A Comprehensive Review. In the 2021 5th International Conference on Smart Grid and Smart Cities (ICSGSC) (pp. 16&ndash;22). IEEE. I would like to confirm that the paper has been extended by more than 50%.},
DOI = {10.3390/en14237833}
}



@Article{s21237793,
AUTHOR = {K, Arumugam and J, Srimathi and Maurya, Sudhanshu and Joseph, Senoj and Asokan, Anju and M, Poongodi and Algethami, Abdullah A. and Hamdi, Mounir and Rauf, Hafiz Tayyab},
TITLE = {Federated Transfer Learning for Authentication and Privacy Preservation Using Novel Supportive Twin Delayed DDPG (S-TD3) Algorithm for IIoT},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7793},
URL = {https://www.mdpi.com/1424-8220/21/23/7793},
PubMedID = {34883794},
ISSN = {1424-8220},
ABSTRACT = {The Industrial Internet of Things (IIoT) has led to the growth and expansion of various new opportunities in the new Industrial Transformation. There have been notable challenges regarding the security of data and challenges related to privacy when collecting real-time and automatic data while observing applications in the industry. This paper proposes an Federated Transfer Learning for Authentication and Privacy Preservation Using Novel Supportive Twin Delayed DDPG (S-TD3) Algorithm for IIoT. In FT-Block (Federated transfer learning blockchain), several blockchains are applied to preserve privacy and security for all types of industrial applications. Additionally, by introducing the authentication mechanism based on transfer learning, blockchains can enhance the preservation and security standards for industrial applications. Specifically, Novel Supportive Twin Delayed DDPG trains the user model to authenticate specific regions. As it is considered one of the most open and scalable interacting platforms of information, it successfully helps in the positive transfer of different kinds of data between devices in more significant and local operations of the industry. It is mainly due to a single authentication factor, and the poor adaptation to regular increases in the number of users and different requirements that make the current authentication mechanism suffer a lot in IIoT. As a result, it has been very clearly observed that the given solutions are very useful.},
DOI = {10.3390/s21237793}
}



@Article{electronics10232918,
AUTHOR = {Mohamed, Nader and Al-Jaroodi, Jameela and Lazarova-Molnar, Sanja and Jawhar, Imad},
TITLE = {Applications of Integrated IoT-Fog-Cloud Systems to Smart Cities: A Survey},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {2918},
URL = {https://www.mdpi.com/2079-9292/10/23/2918},
ISSN = {2079-9292},
ABSTRACT = {Several cities have recently moved towards becoming smart cities for better services and quality of life for residents and visitors, with: optimized resource utilization; increased environmental protection; enhanced infrastructure operations and maintenance; and strong safety and security measures. Smart cities depend on deploying current and new technologies and different optimization methods to enhance services and performance in their different sectors. Some of the technologies assisting smart city applications are the Internet of Things (IoT), fog computing, and cloud computing. Integrating these three to serve one system (we will refer to it as integrated IoT-fog-cloud system (iIFC)) creates an advanced platform to develop and operate various types of smart city applications. This platform will allow applications to use the best features from the IoT devices, fog nodes, and cloud services to deliver best capabilities and performance. Utilizing this powerful platform will provide many opportunities for enhancing and optimizing applications in energy, transportation, healthcare, and other areas. In this paper we survey various applications of iIFCs for smart cities. We identify different common issues associated with utilizing iIFCs for smart city applications. These issues arise due to the characteristics of iIFCs on the one side and the requirements of different smart city applications on the other. In addition, we outline the main requirements to effectively utilize iIFCs for smart city applications. These requirements are related to optimization, networking, and security.},
DOI = {10.3390/electronics10232918}
}



@Article{electronics10232953,
AUTHOR = {Gopi, Sudheesh Puthenveettil and Magarini, Maurizio},
TITLE = {Reinforcement Learning Aided UAV Base Station Location Optimization for Rate Maximization},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {2953},
URL = {https://www.mdpi.com/2079-9292/10/23/2953},
ISSN = {2079-9292},
ABSTRACT = {The application of unmanned aerial vehicles (UAV) as base station (BS) is gaining popularity. In this paper, we consider maximization of the overall data rate by intelligent deployment of UAV BS in the downlink of a cellular system. We investigate a reinforcement learning (RL)-aided approach to optimize the position of flying BSs mounted on board UAVs to support a macro BS (MBS). We propose an algorithm to avoid collision between multiple UAVs undergoing exploratory movements and to restrict UAV BSs movement within a predefined area. Q-learning technique is used to optimize UAV BS position, where the reward is equal to sum of user equipment (UE) data rates. We consider a framework where the UAV BSs carry out exploratory movements in the beginning and exploitary movements in later stages to maximize the overall data rate. Our results show that a cellular system with three UAV BSs and one MBS serving 72 UE reaches 69.2% of the best possible data rate, which is identified by brute force search. Finally, the RL algorithm is compared with a K-means algorithm to study the need of accurate UE locations. Our results show that the RL algorithm outperforms the K-means clustering algorithm when the measure of imperfection is higher. The proposed algorithm can be made use of by a practical MBS&ndash;UAV BSs&ndash;UEs system to provide protection to UAV BSs while maximizing data rate.},
DOI = {10.3390/electronics10232953}
}



@Article{app112311335,
AUTHOR = {Grzelczak, Maciej and Duch, Piotr},
TITLE = {Deep Reinforcement Learning Algorithms for Path Planning Domain in Grid-like Environment},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {11335},
URL = {https://www.mdpi.com/2076-3417/11/23/11335},
ISSN = {2076-3417},
ABSTRACT = {Recently, more and more solutions have utilised artificial intelligence approaches in order to enhance or optimise processes to achieve greater sustainability. One of the most pressing issues is the emissions caused by cars; in this paper, the problem of optimising the route of delivery cars is tackled. In this paper, the applicability of the deep reinforcement learning algorithms with regards to the aforementioned problem is tested on a simulation game designed and implemented to pose various challenges such as constant change of delivery locations. The algorithms chosen for this task are Advantage Actor-Critic (A2C) with and without Proximal Policy Optimisation (PPO). These novel and advanced reinforcement learning algorithms have yet not been utilised in similar scenarios. The differences in performance and learning process of those are visualised and discussed. It is demonstrated that both of those algorithms present a slow but steady learning curve, which is an expected effect of reinforcement learning algorithms, leading to a conclusion that the algorithms would discover an optimal policy with an adequately long learning process. Additionally, the benefits of the Proximal Policy Optimisation algorithm are proven by the enhanced learning curve with comparison to the Advantage Actor-Critic approach, as the learning process is characterised by faster growth with a significantly smaller variation. Finally, the applicability of such algorithms in the described scenarios is discussed, alongside the possible improvements and future work.},
DOI = {10.3390/app112311335}
}



@Article{fi13120306,
AUTHOR = {Dirir, Ahmed and Ignatious, Henry and Elsayed, Hesham and Khan, Manzoor and Adib, Mohammed and Mahmoud, Anas and Al-Gunaid, Moatasem},
TITLE = {An Advanced Deep Learning Approach for Multi-Object Counting in Urban Vehicular Environments},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {306},
URL = {https://www.mdpi.com/1999-5903/13/12/306},
ISSN = {1999-5903},
ABSTRACT = {Object counting is an active research area that gained more attention in the past few years. In smart cities, vehicle counting plays a crucial role in urban planning and management of the Intelligent Transportation Systems (ITS). Several approaches have been proposed in the literature to address this problem. However, the resulting detection accuracy is still not adequate. This paper proposes an efficient approach that uses deep learning concepts and correlation filters for multi-object counting and tracking. The performance of the proposed system is evaluated using a dataset consisting of 16 videos with different features to examine the impact of object density, image quality, angle of view, and speed of motion towards system accuracy. Performance evaluation exhibits promising results in normal traffic scenarios and adverse weather conditions. Moreover, the proposed approach outperforms the performance of two recent approaches from the literature.},
DOI = {10.3390/fi13120306}
}



@Article{electronics10232997,
AUTHOR = {Hurbean, Luminita and Danaiata, Doina and Militaru, Florin and Dodea, Andrei-Mihail and Negovan, Ana-Maria},
TITLE = {Open Data Based Machine Learning Applications in Smart Cities: A Systematic Literature Review},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {2997},
URL = {https://www.mdpi.com/2079-9292/10/23/2997},
ISSN = {2079-9292},
ABSTRACT = {Machine learning (ML) has already gained the attention of the researchers involved in smart city (SC) initiatives, along with other advanced technologies such as IoT, big data, cloud computing, or analytics. In this context, researchers also realized that data can help in making the SC happen but also, the open data movement has encouraged more research works using machine learning. Based on this line of reasoning, the aim of this paper is to conduct a systematic literature review to investigate open data-based machine learning applications in the six different areas of smart cities. The results of this research reveal that: (a) machine learning applications using open data came out in all the SC areas and specific ML techniques are discovered for each area, with deep learning and supervised learning being the first choices. (b) Open data platforms represent the most frequently used source of data. (c) The challenges associated with open data utilization vary from quality of data, to frequency of data collection, to consistency of data, and data format. Overall, the data synopsis as well as the in-depth analysis may be a valuable support and inspiration for the future smart city projects.},
DOI = {10.3390/electronics10232997}
}



@Article{su132313322,
AUTHOR = {Ponnusamy, Vinoth Kumar and Kasinathan, Padmanathan and Madurai Elavarasan, Rajvikram and Ramanathan, Vinoth and Anandan, Ranjith Kumar and Subramaniam, Umashankar and Ghosh, Aritra and Hossain, Eklas},
TITLE = {A Comprehensive Review on Sustainable Aspects of Big Data Analytics for the Smart Grid},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {13322},
URL = {https://www.mdpi.com/2071-1050/13/23/13322},
ISSN = {2071-1050},
ABSTRACT = {The role of energy is cardinal for achieving the Sustainable Development Goals (SDGs) through the enhancement and modernization of energy generation and management practices. The smart grid enables efficient communication between utilities and the end- users, and enhances the user experience by monitoring and controlling the energy transmission. The smart grid deals with an enormous amount of energy data, and the absence of proper techniques for data collection, processing, monitoring and decision-making ultimately makes the system ineffective. Big data analytics, in association with the smart grid, enable better grid visualization and contribute toward the attainment of sustainability. The current research work deals with the achievement of sustainability in the smart grid and efficient data management using big data analytics, that has social, economic, technical and political impacts. This study provides clear insights into energy data generated in the grid and the possibilities of energy theft affecting the sustainable future. The paper provides insights about the importance of big data analytics, with their effects on the smart grids&rsquo; performance towards the achievement of SDGs. The work highlights efficient real-time energy data management involving artificial intelligence and machine learning for a better future, to short out the effects of the conventional smart grid without big data analytics. Finally, the work discusses the challenges and future directions to improve smart grid technologies with big data analytics in action.},
DOI = {10.3390/su132313322}
}



@Article{telecom2040028,
AUTHOR = {Gomes, Eliza and Costa, Felipe and De Rolt, Carlos and Plentz, Patricia and Dantas, Mario},
TITLE = {A Survey from Real-Time to Near Real-Time Applications in Fog Computing Environments},
JOURNAL = {Telecom},
VOLUME = {2},
YEAR = {2021},
NUMBER = {4},
PAGES = {489--517},
URL = {https://www.mdpi.com/2673-4001/2/4/28},
ISSN = {2673-4001},
ABSTRACT = {In this article, we present a comprehensive survey on time-sensitive applications implemented in fog computing environments. The goal is to research what applications are being implemented in fog computing architectures and how the temporal requirements of these applications are being addressed. We also carried out a comprehensive analysis of the articles surveyed and separate them into categories, according to a pattern found in them. Our research is important for the area of real-time systems since the concept of systems that respond in real time has presented various understandings and concepts. This variability of concept has been due to the growing requirements for fast data communication and processing. Therefore, we present different concepts of real-time and near real-time systems found in the literature and currently accepted by the academic-scientific community. Finally, we conduct an analytical discussion of the characteristics and proposal of articles.},
DOI = {10.3390/telecom2040028}
}



@Article{pr9122205,
AUTHOR = {Jafari, Sadiqa and Shahbazi, Zeinab and Byun, Yung-Cheol},
TITLE = {Traffic Control Prediction Design Based on Fuzzy Logic and Lyapunov Approaches to Improve the Performance of Road Intersection},
JOURNAL = {Processes},
VOLUME = {9},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2205},
URL = {https://www.mdpi.com/2227-9717/9/12/2205},
ISSN = {2227-9717},
ABSTRACT = {Due to the increasing use of private cars for urbanization and urban transport, the travel time of urban transportation is increasing. People spend a lot of time in the streets, and the queue length of waiting increases accordingly; this has direct effects on fuel consumption too. Traffic flow forecasts and traffic light schedules were studied separately in the urban traffic system. This paper presents a new stable TS (Takagi&ndash;Sugeno) fuzzy controller for urban traffic. The state-space dynamics are utilized to formulate both the vehicle&rsquo;s average waiting time at an isolated intersection and the length of queues. A fuzzy intelligent controller is designed for light control based upon the length of the queue, and eventually, the system&rsquo;s stability is proved using the Lyapunov theorem. Moreover, the input variables are the length of queue and number of input or output vehicles from each lane. The simulation results describe the appearance of the proposed controller. An illustrative example is also given to show the proposed method&rsquo;s effectiveness; the suggested method is more efficient than both the conventional fuzzy traffic controllers and the fixed time controller.},
DOI = {10.3390/pr9122205}
}



@Article{s21248178,
AUTHOR = {Azhar, Irfan and Sharif, Muhammad and Raza, Mudassar and Khan, Muhammad Attique and Yong, Hwan-Seung},
TITLE = {A Decision Support System for Face Sketch Synthesis Using Deep Learning and Artificial Intelligence},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {8178},
URL = {https://www.mdpi.com/1424-8220/21/24/8178},
PubMedID = {34960274},
ISSN = {1424-8220},
ABSTRACT = {The recent development in the area of IoT technologies is likely to be implemented extensively in the next decade. There is a great increase in the crime rate, and the handling officers are responsible for dealing with a broad range of cyber and Internet issues during investigation. IoT technologies are helpful in the identification of suspects, and few technologies are available that use IoT and deep learning together for face sketch synthesis. Convolutional neural networks (CNNs) and other constructs of deep learning have become major tools in recent approaches. A new-found architecture of the neural network is anticipated in this work. It is called Spiral-Net, which is a modified version of U-Net fto perform face sketch synthesis (the phase is known as the compiler network C here). Spiral-Net performs in combination with a pre-trained Vgg-19 network called the feature extractor F. It first identifies the top n matches from viewed sketches to a given photo. F is again used to formulate a feature map based on the cosine distance of a candidate sketch formed by C from the top n matches. A customized CNN configuration (called the discriminator D) then computes loss functions based on differences between the candidate sketch and the feature. Values of these loss functions alternately update C and F. The ensemble of these nets is trained and tested on selected datasets, including CUFS, CUFSF, and a part of the IIT photo&ndash;sketch dataset. Results of this modified U-Net are acquired by the legacy NLDA (1998) scheme of face recognition and its newer version, OpenBR (2013), which demonstrate an improvement of 5% compared with the current state of the art in its relevant domain.},
DOI = {10.3390/s21248178}
}



@Article{w13243488,
AUTHOR = {Jeon, Minsu and Guerra, Heidi B. and Choi, Hyeseon and Kwon, Donghyun and Kim, Hayong and Kim, Lee-Hyung},
TITLE = {Stormwater Runoff Treatment Using Rain Garden: Performance Monitoring and Development of Deep Learning-Based Water Quality Prediction Models},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {3488},
URL = {https://www.mdpi.com/2073-4441/13/24/3488},
ISSN = {2073-4441},
ABSTRACT = {Twenty-three rainfall events were monitored to determine the characteristics of the stormwater runoff entering a rain garden facility and evaluate its performance in terms of pollutant removal and volume reduction. Data gathered during the five-year monitoring period were utilized to develop a deep learning-based model that can predict the concentrations of Total Suspended Solids (TSS), Chemical Oxygen Demand (COD), Total Nitrogen (TN), and Total Phosphorus (TP). Findings revealed that the rain garden was capable of effectively reducing solids, organics, nutrients, and heavy metals from stormwater runoff during the five-year period when hydrologic and climate conditions have changed. Volume reduction was also high but can decrease over time due to the accumulation of solids in the facility which reduced the infiltration capacity and increased ponding and overflows especially during heavy rainfalls. A preliminary development of a water quality prediction model based on long short-term memory (LSTM) architecture was also developed to be able to potentially reduce the labor and costs associated with on-site monitoring in the future. The LSTM model predicted pollutant concentrations that are close to the actual values with a mean square error of 0.36 during calibration and a less than 10% difference from the measured values during validation. The study showed the potential of using deep learning architecture for the prediction of stormwater quality parameters entering rain gardens. While this study is still in the preliminary stage, it can potentially be improved for use in performance monitoring, decision-making regarding maintenance, and design of similar technologies in the future.},
DOI = {10.3390/w13243488}
}



@Article{math9243162,
AUTHOR = {Zakria and Deng, Jianhua and Hao, Yang and Khokhar, Muhammad Saddam and Kumar, Rajesh and Cai, Jingye and Kumar, Jay and Aftab, Muhammad Umar},
TITLE = {Trends in Vehicle Re-Identification Past, Present, and Future: A Comprehensive Review},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {3162},
URL = {https://www.mdpi.com/2227-7390/9/24/3162},
ISSN = {2227-7390},
ABSTRACT = {Vehicle Re-identification (re-id) over surveillance camera network with non-overlapping field of view is an exciting and challenging task in intelligent transportation systems (ITS). Due to its versatile applicability in metropolitan cities, it gained significant attention. Vehicle re-id matches targeted vehicle over non-overlapping views in multiple camera network. However, it becomes more difficult due to inter-class similarity, intra-class variability, viewpoint changes, and spatio-temporal uncertainty. In order to draw a detailed picture of vehicle re-id research, this paper gives a comprehensive description of the various vehicle re-id technologies, applicability, datasets, and a brief comparison of different methodologies. Our paper specifically focuses on vision-based vehicle re-id approaches, including vehicle appearance, license plate, and spatio-temporal characteristics. In addition, we explore the main challenges as well as a variety of applications in different domains. Lastly, a detailed comparison of current state-of-the-art methods performances over VeRi-776 and VehicleID datasets is summarized with future directions. We aim to facilitate future research by reviewing the work being done on vehicle re-id till to date.},
DOI = {10.3390/math9243162}
}



@Article{smartcities4040078,
AUTHOR = {Shinde, Swapnil Sadashiv and Tarchi, Daniele},
TITLE = {Towards a Novel Air&ndash;Ground Intelligent Platform for Vehicular Networks: Technologies, Scenarios, and Challenges},
JOURNAL = {Smart Cities},
VOLUME = {4},
YEAR = {2021},
NUMBER = {4},
PAGES = {1469--1495},
URL = {https://www.mdpi.com/2624-6511/4/4/78},
ISSN = {2624-6511},
ABSTRACT = {Modern cities require a tighter integration with Information and Communication Technologies (ICT) for bringing new services to the citizens. The Smart City is the revolutionary paradigm aiming at integrating the ICT with the citizen life; among several urban services, transports are one of the most important in modern cities, introducing several challenges to the Smart City paradigm. In order to satisfy the stringent requirements of new vehicular applications and services, Edge Computing (EC) is one of the most promising technologies when integrated into the Vehicular Networks (VNs). EC-enabled VNs can facilitate new latency-critical and data-intensive applications and services. However, ground-based EC platforms (i.e., Road Side Units&mdash;RSUs, 5G Base Stations&mdash;5G BS) can only serve a reduced number of Vehicular Users (VUs), due to short coverage ranges and resource shortage. In the recent past, several new aerial platforms with integrated EC facilities have been deployed for achieving global connectivity. Such air-based EC platforms can complement the ground-based EC facilities for creating a futuristic VN able to deploy several new applications and services. The goal of this work is to explore the possibility of creating a novel joint air-ground EC platform within a VN architecture for helping VUs with new intelligent applications and services. By exploiting most modern technologies, with particular attention towards network softwarization, vehicular edge computing, and machine learning, we propose here three possible layered air-ground EC-enabled VN scenarios. For each of the discussed scenarios, a list of the possible challenges is considered, as well possible solutions allowing to overcome all or some of the considered challenges. A proper comparison is also done, through the use of tables, where all the proposed scenarios, and the proposed solutions, are discussed.},
DOI = {10.3390/smartcities4040078}
}



@Article{electronics10243079,
AUTHOR = {Sengan, Sudhakar and Kotecha, Ketan and Vairavasundaram, Indragandhi and Velayutham, Priya and Varadarajan, Vijayakumar and Ravi, Logesh and Vairavasundaram, Subramaniyaswamy},
TITLE = {Real-Time Automatic Investigation of Indian Roadway Animals by 3D Reconstruction Detection Using Deep Learning for R-3D-YOLOv3 Image Classification and Filtering},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {3079},
URL = {https://www.mdpi.com/2079-9292/10/24/3079},
ISSN = {2079-9292},
ABSTRACT = {Statistical reports say that, from 2011 to 2021, more than 11,915 stray animals, such as cats, dogs, goats, cows, etc., and wild animals were wounded in road accidents. Most of the accidents occurred due to negligence and doziness of drivers. These issues can be handled brilliantly using stray and wild animals-vehicle interaction and the pedestrians&rsquo; awareness. This paper briefs a detailed forum on GPU-based embedded systems and ODT real-time applications. ML trains machines to recognize images more accurately than humans. This provides a unique and real-time solution using deep-learning real 3D motion-based YOLOv3 (DL-R-3D-YOLOv3) ODT of images on mobility. Besides, it discovers methods for multiple views of flexible objects using 3D reconstruction, especially for stray and wild animals. Computer vision-based IoT devices are also besieged by this DL-R-3D-YOLOv3 model. It seeks solutions by forecasting image filters to find object properties and semantics for object recognition methods leading to closed-loop ODT.},
DOI = {10.3390/electronics10243079}
}



@Article{fi13120313,
AUTHOR = {Kapassa, Evgenia and Themistocleous, Marinos and Christodoulou, Klitos and Iosif, Elias},
TITLE = {Blockchain Application in Internet of Vehicles: Challenges, Contributions and Current Limitations},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {313},
URL = {https://www.mdpi.com/1999-5903/13/12/313},
ISSN = {1999-5903},
ABSTRACT = {Blockchain technology is highly coupled with cryptocurrencies; however, it provides several other potential use cases, related to energy and sustainability, Internet of Things (IoT), smart cities, smart mobility and more. Blockchain can offer security for Electric Vehicle (EV) transactions in the Internet of Vehicles (IoV) concept, allowing electricity trading to be performed in a decentralized, transparent and secure way. Additionally, blockchain provides the necessary functionalities for IoV decentralized application development, such as data exchange, personal digital identity, sharing economy and optimized charging pattern. Moreover, blockchain technology has the potential to significantly increase energy efficiency, decrease management costs and guarantee the effective use of the energy recourses. Therefore, its application in the IoV concept provides secure, autonomous and automated energy trading between EVs. While several studies on blockchain technology in smart grids have been conducted, insufficient attention has been given to conducting a detailed review and state-of-the-art analysis of blockchain application in the IoV domain. To this end, this work provides a systematic literature review of blockchain-based applications in the IoV domain. The aim is to investigate the current challenges of IoV and to highlight how blockchain characteristics can contribute to this emerging paradigm. In addition, limitations and future research directions related to the integration of blockchain technology within the IoV are discussed. To this end, this study incorporates the theoretical foundations of several research articles published in scientific publications over the previous five years, as a method of simplifying our assessment and capturing the ever-expanding blockchain area. We present a comprehensive taxonomy of blockchain-enabled applications in the IoV domain, such as privacy and security, data protection and management, vehicle management, charging optimization and P2P energy trading, based on a structured, systematic review and content analysis of the discovered literature, and we identify key trends and emerging areas for research. The contribution of this article is two-fold: (a) we highlight the limitations presented in the relevant literature, particularly the barriers of blockchain technology and how they influence its integration into the IoV and (b) we present a number of research gaps and suggest future exploratory areas.},
DOI = {10.3390/fi13120313}
}



@Article{s21248262,
AUTHOR = {Mary, Delphin Raj Kesari and Ko, Eunbi and Kim, Seung-Geun and Yum, Sun-Ho and Shin, Soo-Young and Park, Soo-Hyun},
TITLE = {A Systematic Review on Recent Trends, Challenges, Privacy and Security Issues of Underwater Internet of Things},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {8262},
URL = {https://www.mdpi.com/1424-8220/21/24/8262},
PubMedID = {34960366},
ISSN = {1424-8220},
ABSTRACT = {Owing to the hasty growth of communication technologies in the Underwater Internet of Things (UIoT), many researchers and industries focus on enhancing the existing technologies of UIoT systems for developing numerous applications such as oceanography, diver networks monitoring, deep-sea exploration and early warning systems. In a constrained UIoT environment, communication media such as acoustic, infrared (IR), visible light, radiofrequency (RF) and magnet induction (MI) are generally used to transmit information via digitally linked underwater devices. However, each medium has its technical limitations: for example, the acoustic medium has challenges such as narrow-channel bandwidth, low data rate, high cost, etc., and optical medium has challenges such as high absorption, scattering, long-distance data transmission, etc. Moreover, the malicious node can steal the underwater data by employing blackhole attacks, routing attacks, Sybil attacks, etc. Furthermore, due to heavyweight, the existing privacy and security mechanism of the terrestrial internet of things (IoT) cannot be applied directly to UIoT environment. Hence, this paper aims to provide a systematic review of recent trends, applications, communication technologies, challenges, security threats and privacy issues of UIoT system. Additionally, this paper highlights the methods of preventing the technical challenges and security attacks of the UIoT environment. Finally, this systematic review contributes much to the profit of researchers to analyze and improve the performance of services in UIoT applications.},
DOI = {10.3390/s21248262}
}



@Article{drones5040148,
AUTHOR = {Yazid, Yassine and Ez-Zazi, Imad and Guerrero-González, Antonio and El Oualkadi, Ahmed and Arioua, Mounir},
TITLE = {UAV-Enabled Mobile Edge-Computing for IoT Based on AI: A Comprehensive Review},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {148},
URL = {https://www.mdpi.com/2504-446X/5/4/148},
ISSN = {2504-446X},
ABSTRACT = {Unmanned aerial vehicles (UAVs) are becoming integrated into a wide range of modern IoT applications. The growing number of networked IoT devices generates a large amount of data. However, processing and memorizing this massive volume of data at local nodes have been deemed critical challenges, especially when using artificial intelligence (AI) systems to extract and exploit valuable information. In this context, mobile edge computing (MEC) has emerged as a way to bring cloud computing (CC) processes within reach of users, to address computation-intensive offloading and latency issues. This paper provides a comprehensive review of the most relevant research works related to UAV technology applications in terms of enabled or assisted MEC architectures. It details the utility of UAV-enabled MEC architecture regarding emerging IoT applications and the role of both deep learning (DL) and machine learning (ML) in meeting various limitations related to latency, task offloading, energy demand, and security. Furthermore, throughout this article, the reader gains an insight into the future of UAV-enabled MEC, the advantages and the critical challenges to be tackled when using AI.},
DOI = {10.3390/drones5040148}
}



@Article{s21248467,
AUTHOR = {Elsisi, Mahmoud and Tran, Minh-Quang},
TITLE = {Development of an IoT Architecture Based on a Deep Neural Network against Cyber Attacks for Automated Guided Vehicles},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {8467},
URL = {https://www.mdpi.com/1424-8220/21/24/8467},
PubMedID = {34960561},
ISSN = {1424-8220},
ABSTRACT = {This paper introduces an integrated IoT architecture to handle the problem of cyber attacks based on a developed deep neural network (DNN) with a rectified linear unit in order to provide reliable and secure online monitoring for automated guided vehicles (AGVs). The developed IoT architecture based on a DNN introduces a new approach for the online monitoring of AGVs against cyber attacks with a cheap and easy implementation instead of the traditional cyber attack detection schemes in the literature. The proposed DNN is trained based on experimental AGV data that represent the real state of the AGV and different types of cyber attacks including a random attack, ramp attack, pulse attack, and sinusoidal attack that is injected by the attacker into the internet network. The proposed DNN is compared with different deep learning and machine learning algorithms such as a one dimension convolutional neural network (1D-CNN), a supported vector machine model (SVM), random forest, extreme gradient boosting (XGBoost), and a decision tree for greater validation. Furthermore, the proposed IoT architecture based on a DNN can provide an effective detection for the AGV status with an excellent accuracy of 96.77% that is significantly greater than the accuracy based on the traditional schemes. The AGV status based on the proposed IoT architecture with a DNN is visualized by an advanced IoT platform named CONTACT Elements for IoT. Different test scenarios with a practical setup of an AGV with IoT are carried out to emphasize the performance of the suggested IoT architecture based on a DNN. The results approve the usefulness of the proposed IoT to provide effective cybersecurity for data visualization and tracking of the AGV status that enhances decision-making and improves industrial productivity.},
DOI = {10.3390/s21248467}
}



@Article{app112412155,
AUTHOR = {Bagarella, Giacomo and Busato, Filippo and Castellotti, Francesco and D’Ascanio, Andrea and Lazzarin, Renato and Minchio, Fabio and Nardotto, Daniele and Noro, Marco and Zamboni, Lorenzo},
TITLE = {Research in Sustainable Energy Systems at the Department of Management and Engineering during the First 15 Years of 2000},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {12155},
URL = {https://www.mdpi.com/2076-3417/11/24/12155},
ISSN = {2076-3417},
ABSTRACT = {At the Department of Management and Engineering (DTG) of the University of Padova (Italy), the research team led by Prof. Renato Lazzarin, formed by the authors, worked during the first fifteen years of the millennium on different topics focused on sustainable technologies for energy production and utilization in buildings. Both experimental and theoretical/modeling studies were carried out, all sharing the evaluation of energy performance and sustainability: From the life cycle assessment and life cycle cost of building insulation materials in Italy, to the measurement of energy performance of a green roof, to the experimental measurement of different photovoltaic/thermal modules, to the development of a simulation software for direct and indirect evaporative cooling techniques, to the evaluation of different energy savings techniques for refrigeration and air conditioning in supermarkets, to an extensive analysis of the urban heat island effect in the city of Padova. The paper summarizes the main theoretical and experimental approaches, providing the methods adopted in each line of research. The main results of the studies conducted during the fifteen-year period are described and commented on, some of which were a well-established reference for the following literature.},
DOI = {10.3390/app112412155}
}



@Article{s22010020,
AUTHOR = {Šumak, Boštjan and Brdnik, Saša and Pušnik, Maja},
TITLE = {Sensors and Artificial Intelligence Methods and Algorithms for Human&ndash;Computer Intelligent Interaction: A Systematic Mapping Study},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {20},
URL = {https://www.mdpi.com/1424-8220/22/1/20},
PubMedID = {35009562},
ISSN = {1424-8220},
ABSTRACT = {To equip computers with human communication skills and to enable natural interaction between the computer and a human, intelligent solutions are required based on artificial intelligence (AI) methods, algorithms, and sensor technology. This study aimed at identifying and analyzing the state-of-the-art AI methods and algorithms and sensors technology in existing human&ndash;computer intelligent interaction (HCII) research to explore trends in HCII research, categorize existing evidence, and identify potential directions for future research. We conduct a systematic mapping study of the HCII body of research. Four hundred fifty-four studies published in various journals and conferences between 2010 and 2021 were identified and analyzed. Studies in the HCII and IUI fields have primarily been focused on intelligent recognition of emotion, gestures, and facial expressions using sensors technology, such as the camera, EEG, Kinect, wearable sensors, eye tracker, gyroscope, and others. Researchers most often apply deep-learning and instance-based AI methods and algorithms. The support sector machine (SVM) is the most widely used algorithm for various kinds of recognition, primarily an emotion, facial expression, and gesture. The convolutional neural network (CNN) is the often-used deep-learning algorithm for emotion recognition, facial recognition, and gesture recognition solutions.},
DOI = {10.3390/s22010020}
}



@Article{s22010026,
AUTHOR = {Dangi, Ramraj and Lalwani, Praveen and Choudhary, Gaurav and You, Ilsun and Pau, Giovanni},
TITLE = {Study and Investigation on 5G Technology: A Systematic Review},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {26},
URL = {https://www.mdpi.com/1424-8220/22/1/26},
PubMedID = {35009569},
ISSN = {1424-8220},
ABSTRACT = {In wireless communication, Fifth Generation (5G) Technology is a recent generation of mobile networks. In this paper, evaluations in the field of mobile communication technology are presented. In each evolution, multiple challenges were faced that were captured with the help of next-generation mobile networks. Among all the previously existing mobile networks, 5G provides a high-speed internet facility, anytime, anywhere, for everyone. 5G is slightly different due to its novel features such as interconnecting people, controlling devices, objects, and machines. 5G mobile system will bring diverse levels of performance and capability, which will serve as new user experiences and connect new enterprises. Therefore, it is essential to know where the enterprise can utilize the benefits of 5G. In this research article, it was observed that extensive research and analysis unfolds different aspects, namely, millimeter wave (mmWave), massive multiple-input and multiple-output (Massive-MIMO), small cell, mobile edge computing (MEC), beamforming, different antenna technology, etc. This article&rsquo;s main aim is to highlight some of the most recent enhancements made towards the 5G mobile system and discuss its future research objectives.},
DOI = {10.3390/s22010026}
}



@Article{s22010108,
AUTHOR = {Ali, Abid and Iqbal, Muhammad Munawar and Jamil, Harun and Akbar, Habib and Muthanna, Ammar and Ammi, Meryem and Althobaiti, Maha M.},
TITLE = {Multilevel Central Trust Management Approach for Task Scheduling on IoT-Based Mobile Cloud Computing},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {108},
URL = {https://www.mdpi.com/1424-8220/22/1/108},
PubMedID = {35009649},
ISSN = {1424-8220},
ABSTRACT = {With the increasing number of mobile devices and IoT devices across a wide range of real-life applications, our mobile cloud computing devices will not cope with this growing number of audiences soon, which implies and demands the need to shift to fog computing. Task scheduling is one of the most demanding scopes after the trust computation inside the trustable nodes. The mobile devices and IoT devices transfer the resource-intensive tasks towards mobile cloud computing. Some tasks are resource-intensive and not trustable to allocate to the mobile cloud computing resources. This consequently gives rise to trust evaluation and data sync-up of devices joining and leaving the network. The resources are more intensive for cloud computing and mobile cloud computing. Time, energy, and resources are wasted due to the nontrustable nodes. This research article proposes a multilevel trust enhancement approach for efficient task scheduling in mobile cloud environments. We first calculate the trustable tasks needed to offload towards the mobile cloud computing. Then, an efficient and dynamic scheduler is added to enhance the task scheduling after trust computation using social and environmental trust computation techniques. To improve the time and energy efficiency of IoT and mobile devices using the proposed technique, the energy computation and time request computation are compared with the existing methods from literature, which identified improvements in the results. Our proposed approach is centralized to tackle constant SyncUPs of incoming devices&rsquo; trust values with mobile cloud computing. With the benefits of mobile cloud computing, the centralized data distribution method is a positive approach.},
DOI = {10.3390/s22010108}
}



@Article{en15010125,
AUTHOR = {Gao, Jianwei and Yang, Yu and Gao, Fangjie and Wu, Haoyu},
TITLE = {Collaborative Optimization of Electric Vehicles Based on MultiAgent Variant Roth&ndash;Erev Algorithm},
JOURNAL = {Energies},
VOLUME = {15},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {125},
URL = {https://www.mdpi.com/1996-1073/15/1/125},
ISSN = {1996-1073},
ABSTRACT = {With the implementation of the carbon neutral policy, the number of electric vehicles (EVs) is increasing. Thus, it is urgently needed to manage the charging and discharging behavior of EVs scientifically. In this paper, EVs are regarded as agents, and a multiagent cooperative optimization scheduling model based on Roth&ndash;Erev (RE) algorithm is proposed. The charging and discharging behaviors of EVs will influence each other. The charging and discharging strategy of one EV owner will affect the choice of others. Therefore, the RE algorithm is selected to obtain the optimal charging and discharging strategy of the EV group, with the utility function of the prospect theory proposed to describe EV owners&rsquo; different risk preferences. The utility function of the prospect theory has superior effectiveness in describing consumers&rsquo; utility. Finally, in the case of residential electricity, the effectiveness of the proposed method is verified. Compared with that of random charging, this method reduces the total EV group cost of EVs by 52.4%, with the load variance reduced by 26.4%.},
DOI = {10.3390/en15010125}
}



@Article{machines10010023,
AUTHOR = {Fujii, Tiago Yukio and Hayashi, Victor Takashi and Arakaki, Reginaldo and Ruggiero, Wilson Vicente and Bulla, Romeo and Hayashi, Fabio Hirotsugu and Khalil, Khalil Ahmad},
TITLE = {A Digital Twin Architecture Model Applied with MLOps Techniques to Improve Short-Term Energy Consumption Prediction},
JOURNAL = {Machines},
VOLUME = {10},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {23},
URL = {https://www.mdpi.com/2075-1702/10/1/23},
ISSN = {2075-1702},
ABSTRACT = {Using extensive databases and known algorithms to predict short-term energy consumption comprises most computational solutions based on artificial intelligence today. State-of-the-art approaches validate their prediction models in offline environments that disregard automation, quality monitoring, and retraining challenges present in online scenarios. The existing demand response initiatives lack personalization, thus not engaging consumers. Obtaining specific and valuable recommendations is difficult for most digital platforms due to their solution pattern: extensive database, specialized algorithms, and using profiles with similar aspects. The challenges and present personalization tactics have been researched by adopting a digital twin model. This study creates a different approach by adding structural topology to build a new category of recommendation platform using the digital twin model with real-time data collected by IoT sensors to improve machine learning methods. A residential study case with 31 IoT smart meter and smart plug devices with 19-month data (measurements performed each second) validated Digital Twin MLOps architecture for personalized demand response suggestions based on online short-term energy consumption prediction.},
DOI = {10.3390/machines10010023}
}



@Article{jsan11010003,
AUTHOR = {Benjbara, Chaimae and Habbani, Ahmed and Mouchfiq, Nada},
TITLE = {New Multipath OLSR Protocol Version for Heterogeneous Ad Hoc Networks},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {3},
URL = {https://www.mdpi.com/2224-2708/11/1/3},
ISSN = {2224-2708},
ABSTRACT = {From a basic refrigerator to a self-driving car, emerging technologies are increasingly involving various facets of our daily lives. These bring together many regularly used devices, each with its own characteristics, to communicate and collaborate within the same system. Computer network experts regard this so-called structure as a heterogeneous network made up of several connected objects that do not speak the same language. Communication is therefore ensured by additional types of nodes, such as gateways or converters. In this case, we can detect an increased complexity and a decreased level of security. And thus, the need to adopt a common slang for these kinds of networks has been brought to life. In this work, we compare two different routing protocols: optimized link-state routing (OLSR) and the multipath heterogeneous ad hoc network OLSR (MHAR-OLSR). The latter is an OLSR extension with new functionalities: nodes identification, paths calculation, paths classification, and paths choice that we designed for heterogeneous ad hoc networks composed of MANET, VANET, and FANET devices; it ensures direct communication between these diverse components. We verify and explain all the elements of our solution using colored Petri nets. We also present a global evaluation of Packet Delivery Ratio (PDR), End-To-End Delay, and energy consumption as QoS measures with different numbers of nodes in a heterogeneous scenario. To do this, we use NS-3 and BonnMotion as a tool-set of simulation. Experimental results show improvement in performance when compared to the classical routing protocol.},
DOI = {10.3390/jsan11010003}
}



@Article{math10010101,
AUTHOR = {Attanasio, Barbara and Mazayev, Andriy and du Plessis, Shani and Correia, Noélia},
TITLE = {Cognitive Load Balancing Approach for 6G MEC Serving IoT Mashups},
JOURNAL = {Mathematics},
VOLUME = {10},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {101},
URL = {https://www.mdpi.com/2227-7390/10/1/101},
ISSN = {2227-7390},
ABSTRACT = {The sixth generation (6G) of communication networks represents more of a revolution than an evolution of the previous generations, providing new directions and innovative approaches to face the network challenges of the future. A crucial aspect is to make the best use of available resources for the support of an entirely new generation of services. From this viewpoint, the Web of Things (WoT), which enables Things to become Web Things to chain, use and re-use in IoT mashups, allows interoperability among IoT platforms. At the same time, Multi-access Edge Computing (MEC) brings computing and data storage to the edge of the network, which creates the so-called distributed and collective edge intelligence. Such intelligence is created in order to deal with the huge amount of data to be collected, analyzed and processed, from real word contexts, such as smart cities, which are evolving into dynamic and networked systems of people and things. To better exploit this architecture, it is crucial to break monolithic applications into modular microservices, which can be executed independently. Here, we propose an approach based on complex network theory and two weighted and interdependent multiplex networks to address the Microservices-compliant Load Balancing (McLB) problem in MEC infrastructure. Our findings show that the multiplex network representation represents an extra dimension of analysis, allowing to capture the complexity in WoT mashup organization and its impact on the organizational aspect of MEC servers. The impact of this extracted knowledge on the cognitive organization of MEC is quantified, through the use of heuristics that are engineered to guarantee load balancing and, consequently, QoS.},
DOI = {10.3390/math10010101}
}



@Article{e24010058,
AUTHOR = {Balicki, Jerzy},
TITLE = {Many-Objective Quantum-Inspired Particle Swarm Optimization Algorithm for Placement of Virtual Machines in Smart Computing Cloud},
JOURNAL = {Entropy},
VOLUME = {24},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {58},
URL = {https://www.mdpi.com/1099-4300/24/1/58},
ISSN = {1099-4300},
ABSTRACT = {Particle swarm optimization algorithm (PSO) is an effective metaheuristic that can determine Pareto-optimal solutions. We propose an extended PSO by introducing quantum gates in order to ensure the diversity of particle populations that are looking for efficient alternatives. The quality of solutions was verified in the issue of assignment of resources in the computing cloud to improve the live migration of virtual machines. We consider the multi-criteria optimization problem of deep learning-based models embedded into virtual machines. Computing clouds with deep learning agents can support several areas of education, smart city or economy. Because deep learning agents require lots of computer resources, seven criteria are studied such as electric power of hosts, reliability of cloud, CPU workload of the bottleneck host, communication capacity of the critical node, a free RAM capacity of the most loaded memory, a free disc memory capacity of the most busy storage, and overall computer costs. Quantum gates modify an accepted position for the current location of a particle. To verify the above concept, various simulations have been carried out on the laboratory cloud based on the OpenStack platform. Numerical experiments have confirmed that multi-objective quantum-inspired particle swarm optimization algorithm provides better solutions than the other metaheuristics.},
DOI = {10.3390/e24010058}
}



@Article{s22010208,
AUTHOR = {Muntean, Maria Viorela},
TITLE = {Multi-Agent System for Intelligent Urban Traffic Management Using Wireless Sensor Networks Data},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {208},
URL = {https://www.mdpi.com/1424-8220/22/1/208},
PubMedID = {35009750},
ISSN = {1424-8220},
ABSTRACT = {Intelligent traffic management is an important issue for smart cities. City councils try to implement the newest techniques and performant technologies in order to avoid traffic congestion, to optimize the use of traffic lights, to efficiently use car parking, etc. To find the best solution to this problem, Birmingham City Council decided to allow open-source predictive traffic forecasting by making the real-time datasets available. This paper proposes a multi-agent system (MAS) approach for intelligent urban traffic management in Birmingham using forecasting and classification techniques. The designed agents have the following tasks: forecast the occupancy rates for traffic flow, road junctions and car parking; classify the faults; control and monitor the entire process. The experimental results show that k-nearest neighbor forecasts with high accuracy rates for the traffic data and decision trees build the most accurate model for classifying the faults for their detection and repair in the shortest possible time. The whole learning process is coordinated by a monitoring agent in order to automate Birmingham city&rsquo;s traffic management.},
DOI = {10.3390/s22010208}
}



@Article{electronics11010121,
AUTHOR = {Tanveer, Jawad and Haider, Amir and Ali, Rashid and Kim, Ajung},
TITLE = {Machine Learning for Physical Layer in 5G and beyond Wireless Networks: A Survey},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {121},
URL = {https://www.mdpi.com/2079-9292/11/1/121},
ISSN = {2079-9292},
ABSTRACT = {Fifth-generation (5G) technology will play a vital role in future wireless networks. The breakthrough 5G technology will unleash a massive Internet of Everything (IoE), where billions of connected devices, people, and processes will be simultaneously served. The services provided by 5G include several use cases enabled by the enhanced mobile broadband, massive machine-type communications, and ultra-reliable low-latency communication. Fifth-generation networks potentially merge multiple networks on a single platform, providing a landscape for seamless connectivity, particularly for high-mobility devices. With their enhanced speed, 5G networks are prone to various research challenges. In this context, we provide a comprehensive survey on 5G technologies that emphasize machine learning-based solutions to cope with existing and future challenges. First, we discuss 5G network architecture and outline the key performance indicators compared to the previous and upcoming network generations. Second, we discuss next-generation wireless networks and their characteristics, applications, and use cases for fast connectivity to billions of devices. Then, we confer physical layer services, functions, and issues that decrease the signal quality. We also present studies on 5G network technologies, 5G propelling trends, and architectures that help to achieve the goals of 5G. Moreover, we discuss signaling techniques for 5G massive multiple-input and multiple-output and beam-forming techniques to enhance data rates with efficient spectrum sharing. Further, we review security and privacy concerns in 5G and standard bodies&rsquo; actionable recommendations for policy makers. Finally, we also discuss emerging challenges and future directions.},
DOI = {10.3390/electronics11010121}
}



@Article{app12010384,
AUTHOR = {Koo, Seolwon and Lim, Yujin},
TITLE = {A Cluster-Based Optimal Computation Offloading Decision Mechanism Using RL in the IIoT Field},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {384},
URL = {https://www.mdpi.com/2076-3417/12/1/384},
ISSN = {2076-3417},
ABSTRACT = {In the Industrial Internet of Things (IIoT), various tasks are created dynamically because of the small quantity batch production. Hence, it is difficult to execute tasks only with devices that have limited battery lives and computation capabilities. To solve this problem, we adopted the mobile edge computing (MEC) paradigm. However, if there are numerous tasks to be processed on the MEC server (MECS), it may not be suitable to deal with all tasks in the server within a delay constraint owing to the limited computational capability and high network overhead. Therefore, among cooperative computing techniques, we focus on task offloading to nearby devices using device-to-device (D2D) communication. Consequently, we propose a method that determines the optimal offloading strategy in an MEC environment with D2D communication. We aim to minimize the energy consumption of the devices and task execution delay under certain delay constraints. To solve this problem, we adopt a Q-learning algorithm that is part of reinforcement learning (RL). However, if one learning agent determines whether to offload tasks from all devices, the computing complexity of that agent increases tremendously. Thus, we cluster the nearby devices that comprise the job shop, where each cluster&rsquo;s head determines the optimal offloading strategy for the tasks that occur within its cluster. Simulation results show that the proposed algorithm outperforms the compared methods in terms of device energy consumption, task completion rate, task blocking rate, and throughput.},
DOI = {10.3390/app12010384}
}



@Article{s22010301,
AUTHOR = {Chéour, Rym and Jmal, Mohamed Wassim and Khriji, Sabrine and El Houssaini, Dhouha and Trigona, Carlo and Abid, Mohamed and Kanoun, Olfa},
TITLE = {Towards Hybrid Energy-Efficient Power Management in Wireless Sensor Networks},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {301},
URL = {https://www.mdpi.com/1424-8220/22/1/301},
PubMedID = {35009838},
ISSN = {1424-8220},
ABSTRACT = {Wireless Sensor Networks (WSNs) are prone to highly constrained resources, as a result ensuring the proper functioning of the network is a requirement. Therefore, an effective WSN management system has to be integrated for the network efficiency. Our objective is to model, design, and propose a homogeneous WSN hybrid architecture. This work features a dedicated power utilization optimization strategy specifically for WSNs application. It is entitled Hybrid Energy-Efficient Power manager Scheduling (HEEPS). The pillars of this strategy are based on the one hand on time-out Dynamic Power Management (DPM) Intertask and on the other hand on Dynamic Voltage and Frequency Scaling (DVFS). All tasks are scheduled under Global Earliest Deadline First (GEDF) with new scheduling tests to overcome the Dhall effect. To minimize the energy consumption, the HEEPS predicts, defines and models the behavior adapted to each sensor node, as well as the associated energy management mechanism. HEEPS&rsquo;s performance evaluation and analysis are performed using the STORM simulator. A comparison to the results obtained with the various state of the art approaches is presented. Results show that the power manager proposed effectively schedules tasks to use dynamically the available energy estimated gain up to 50%.},
DOI = {10.3390/s22010301}
}



@Article{app12010425,
AUTHOR = {Joo, Hyunjin and Lim, Yujin},
TITLE = {Intelligent Traffic Signal Phase Distribution System Using Deep Q-Network},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {425},
URL = {https://www.mdpi.com/2076-3417/12/1/425},
ISSN = {2076-3417},
ABSTRACT = {Traffic congestion is a worsening problem owing to an increase in traffic volume. Traffic congestion increases the driving time and wastes fuel, generating large amounts of fumes and accelerating environmental pollution. Therefore, traffic congestion is an important problem that needs to be addressed. Smart transportation systems manage various traffic problems by utilizing the infrastructure and networks available in smart cities. The traffic signal control system used in smart transportation analyzes and controls traffic flow in real time. Thus, traffic congestion can be effectively alleviated. We conducted preliminary experiments to analyze the effects of throughput, queue length, and waiting time on the system performance according to the signal allocation techniques. Based on the results of the preliminary experiment, the standard deviation of the queue length is interpreted as an important factor in an order allocation technique. A smart traffic signal control system using a deep Q-network, which is a type of reinforcement learning, is proposed. The proposed algorithm determines the optimal order of a green signal. The goal of the proposed algorithm is to maximize the throughput and efficiently distribute the signals by considering the throughput and standard deviation of the queue length as reward parameters.},
DOI = {10.3390/app12010425}
}



@Article{s22010341,
AUTHOR = {Tsai, Pei-Hsuan and Zhang, Jun-Bin and Tsai, Meng-Hsun},
TITLE = {An Efficient Probe-Based Routing for Content-Centric Networking},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {341},
URL = {https://www.mdpi.com/1424-8220/22/1/341},
PubMedID = {35009883},
ISSN = {1424-8220},
ABSTRACT = {With the development of new technologies and applications, such as the Internet of Things, smart cities, 5G, and edge computing, traditional Internet Protocol-based (IP-based) networks have been exposed as having many problems. Information-Centric Networking (ICN), Named Data Networking (NDN), and Content-Centric Networking (CCN) are therefore proposed as an alternative for future networks. However, unlike IP-based networks, CCN routing is non-deterministic and difficult to optimize due to frequent in-network caching replacement. This paper presents a novel probe-based routing algorithm that explores real-time in-network caching to ensure the routing table storing the optimal paths to the nearest content provider is up to date. Effective probe-selections, Pending Interest Table (PIT) probe, and Forwarding Information Base (FIB) probe are discussed and analyzed by simulation with different performance measurements. Compared with the basic CCN, in terms of qualitative analysis, the additional computational overhead of our approach is O(NCS + Nrt + NFIB &lowast; NSPT) and O(NFIB) on processing interest packets and data packets, respectively. However, in terms of quantitative analysis, our approach reduces the number of timeout interests by 6% and the average response time by 0.6 s. Furthermore, although basic CCN and our approach belong to the same Quality of Service (QoS) category, our approach outperforms basic CCN in terms of real values. Additionally, our probe-based approach performs better than RECIF+PIF and EEGPR. Owing to speedup FIB updating by probes, our approach provides more reliable interest packet routing when accounting for router failures. In summary, the results demonstrate that compared to basic CCN, our probe-based routing approach raises FIB accuracy and reduces network congestion and response time, resulting in efficient routing.},
DOI = {10.3390/s22010341}
}



@Article{s22020411,
AUTHOR = {Awan, Saba and Javaid, Nadeem and Ullah, Sameeh and Khan, Asad Ullah and Qamar, Ali Mustafa and Choi, Jin-Ghoo},
TITLE = {Blockchain Based Secure Routing and Trust Management in Wireless Sensor Networks},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {411},
URL = {https://www.mdpi.com/1424-8220/22/2/411},
ISSN = {1424-8220},
ABSTRACT = {In this paper, an encryption and trust evaluation model is proposed on the basis of a blockchain in which the identities of the Aggregator Nodes (ANs) and Sensor Nodes (SNs) are stored. The authentication of ANs and SNs is performed in public and private blockchains, respectively. However, inauthentic nodes utilize the network&rsquo;s resources and perform malicious activities. Moreover, the SNs have limited energy, transmission range and computational capabilities, and are attacked by malicious nodes. Afterwards, the malicious nodes transmit wrong information of the route and increase the number of retransmissions due to which the SNs&rsquo; energy is rapidly consumed. The lifespan of the wireless sensor network is reduced due to the rapid energy dissipation of the SNs. Furthermore, the throughput increases and packet loss increase with the presence of malicious nodes in the network. The trust values of SNs are computed to eradicate the malicious nodes from the network. Secure routing in the network is performed considering residual energy and trust values of the SNs. Moreover, the Rivest&ndash;Shamir&ndash;Adleman (RSA), a cryptosystem that provides asymmetric keys, is used for securing data transmission. The simulation results show the effectiveness of the proposed model in terms of high packet delivery ratio.},
DOI = {10.3390/s22020411}
}



@Article{app12020544,
AUTHOR = {Abdulrab, Hakim and Hussin, Fawnizu Azmadi and Abd Aziz, Azrina and Awang, Azlan and Ismail, Idris and Devan, P. Arun Mozhi},
TITLE = {Reliable Fault Tolerant-Based Multipath Routing Model for Industrial Wireless Control Systems},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {544},
URL = {https://www.mdpi.com/2076-3417/12/2/544},
ISSN = {2076-3417},
ABSTRACT = {Communication in industrial wireless networks necessitates reliability and precision. Besides, the existence of interference or traffic in the network must not affect the estimated network properties. Therefore, data packets have to be sent within a certain time frame and over a reliable connection. However, the working scenarios and the characteristics of the network itself make it vulnerable to node or link faults, which impact the transmission reliability and overall performance. This article aims to introduce a developed multipath routing model, which leads to cost-effective planning, low latency and high reliability of industrial wireless mesh networks, such as the WirelessHART networks. The multipath routing model has three primary paths, and each path has a backup node. The backup node stores the data transmitted by the parent node to grant communication continuity when primary nodes fail. The multipath routing model is developed based on optimal network planning and deployment algorithm. Simulations were conducted on a WirelessHART simulator using Network Simulator (NS2). The performance of the developed model is compared with the state-of-the-art. The obtained results reveal a significant reduction in the average network latency, low power consumption, better improvement in expected network lifetime, and enhanced packet delivery ratio which improve network reliability.},
DOI = {10.3390/app12020544}
}



@Article{s22020451,
AUTHOR = {Latif, Shahzad and Akraam, Suhail and Karamat, Tehmina and Khan, Muhammad Attique and Altrjman, Chadi and Mey, Senghour and Nam, Yunyoung},
TITLE = {An Efficient Pareto Optimal Resource Allocation Scheme in Cognitive Radio-Based Internet of Things Networks},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {451},
URL = {https://www.mdpi.com/1424-8220/22/2/451},
ISSN = {1424-8220},
ABSTRACT = {The high data rates detail that internet-connected devices have been increasing exponentially. Cognitive radio (CR) is an auspicious technology used to address the resource shortage issue in wireless IoT networks. Resource optimization is considered a non-convex and nondeterministic polynomial (NP) complete problem within CR-based Internet of Things (IoT) networks (CR-IoT). Moreover, the combined optimization of conflicting objectives is a challenging issue in CR-IoT networks. In this paper, energy efficiency (EE) and spectral efficiency (SE) are considered as conflicting optimization objectives. This research work proposed a hybrid tabu search-based stimulated algorithm (HTSA) in order to achieve Pareto optimality between EE and SE. In addition, the fuzzy-based decision is employed to achieve better Pareto optimality. The performance of the proposed HTSA approach is analyzed using different resource allocation parameters and validated through simulation results.},
DOI = {10.3390/s22020451}
}



@Article{s22020456,
AUTHOR = {Bustamante-Bello, Rogelio and García-Barba, Alec and Arce-Saenz, Luis A. and Curiel-Ramirez, Luis A. and Izquierdo-Reyes, Javier and Ramirez-Mendoza, Ricardo A.},
TITLE = {Visualizing Street Pavement Anomalies through Fog Computing V2I Networks and Machine Learning},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {456},
URL = {https://www.mdpi.com/1424-8220/22/2/456},
ISSN = {1424-8220},
ABSTRACT = {Analyzing data related to the conditions of city streets and avenues could help to make better decisions about public spending on mobility. Generally, streets and avenues are fixed as soon as they have a citizen report or when a major incident occurs. However, it is uncommon for cities to have real-time reactive systems that detect the different problems they have to fix on the pavement. This work proposes a solution to detect anomalies in streets through state analysis using sensors within the vehicles that travel daily and connecting them to a fog-computing architecture on a V2I network. The system detects and classifies the main road problems or abnormal conditions in streets and avenues using Machine Learning Algorithms (MLA), comparing roughness against a flat reference. An instrumented vehicle obtained the reference through accelerometry sensors and then sent the data through a mid-range communication system. With these data, the system compared an Artificial Neural Network (supervised MLA) and a K-Nearest Neighbor (Supervised MLA) to select the best option to handle the acquired data. This system makes it desirable to visualize the streets&rsquo; quality and map the areas with the most significant anomalies.},
DOI = {10.3390/s22020456}
}



@Article{s22020468,
AUTHOR = {Avina-Bravo, Eli Gabriel and Cassirame, Johan and Escriba, Christophe and Acco, Pascal and Fourniols, Jean-Yves and Soto-Romero, Georges},
TITLE = {Smart Electrically Assisted Bicycles as Health Monitoring Systems: A Review},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {468},
URL = {https://www.mdpi.com/1424-8220/22/2/468},
ISSN = {1424-8220},
ABSTRACT = {This paper aims to provide a review of the electrically assisted bicycles (also known as e-bikes) used for recovery of the rider&rsquo;s physical and physiological information, monitoring of their health state, and adjusting the &ldquo;medical&rdquo; assistance accordingly. E-bikes have proven to be an excellent way to do physical activity while commuting, thus improving the user&rsquo;s health and reducing air pollutant emissions. Such devices can also be seen as the first step to help unhealthy sedentary people to start exercising with reduced strain. Based on this analysis, the need to have e-bikes with artificial intelligence (AI) systems that recover and processe a large amount of data is discussed in depth. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines were used to complete the relevant papers&rsquo; search and selection in this systematic review.},
DOI = {10.3390/s22020468}
}



@Article{electronics11020198,
AUTHOR = {Abdullahi, Mujaheed and Baashar, Yahia and Alhussian, Hitham and Alwadain, Ayed and Aziz, Norshakirah and Capretz, Luiz Fernando and Abdulkadir, Said Jadid},
TITLE = {Detecting Cybersecurity Attacks in Internet of Things Using Artificial Intelligence Methods: A Systematic Literature Review},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {198},
URL = {https://www.mdpi.com/2079-9292/11/2/198},
ISSN = {2079-9292},
ABSTRACT = {In recent years, technology has advanced to the fourth industrial revolution (Industry 4.0), where the Internet of things (IoTs), fog computing, computer security, and cyberattacks have evolved exponentially on a large scale. The rapid development of IoT devices and networks in various forms generate enormous amounts of data which in turn demand careful authentication and security. Artificial intelligence (AI) is considered one of the most promising methods for addressing cybersecurity threats and providing security. In this study, we present a systematic literature review (SLR) that categorize, map and survey the existing literature on AI methods used to detect cybersecurity attacks in the IoT environment. The scope of this SLR includes an in-depth investigation on most AI trending techniques in cybersecurity and state-of-art solutions. A systematic search was performed on various electronic databases (SCOPUS, Science Direct, IEEE Xplore, Web of Science, ACM, and MDPI). Out of the identified records, 80 studies published between 2016 and 2021 were selected, surveyed and carefully assessed. This review has explored deep learning (DL) and machine learning (ML) techniques used in IoT security, and their effectiveness in detecting attacks. However, several studies have proposed smart intrusion detection systems (IDS) with intelligent architectural frameworks using AI to overcome the existing security and privacy challenges. It is found that support vector machines (SVM) and random forest (RF) are among the most used methods, due to high accuracy detection another reason may be efficient memory. In addition, other methods also provide better performance such as extreme gradient boosting (XGBoost), neural networks (NN) and recurrent neural networks (RNN). This analysis also provides an insight into the AI roadmap to detect threats based on attack categories. Finally, we present recommendations for potential future investigations.},
DOI = {10.3390/electronics11020198}
}



@Article{sym14010161,
AUTHOR = {Han, Hyojoon and Kim, Hyukho and Kim, Yangwoo},
TITLE = {An Efficient Hyperparameter Control Method for a Network Intrusion Detection System Based on Proximal Policy Optimization},
JOURNAL = {Symmetry},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {161},
URL = {https://www.mdpi.com/2073-8994/14/1/161},
ISSN = {2073-8994},
ABSTRACT = {The complexity of network intrusion detection systems (IDSs) is increasing due to the continuous increases in network traffic, various attacks and the ever-changing network environment. In addition, network traffic is asymmetric with few attack data, but the attack data are so complex that it is difficult to detect one. Many studies on improving intrusion detection performance using feature engineering have been conducted. These studies work well in the dataset environment; however, it is challenging to cope with a changing network environment. This paper proposes an intrusion detection hyperparameter control system (IDHCS) that controls and trains a deep neural network (DNN) feature extractor and k-means clustering module as a reinforcement learning model based on proximal policy optimization (PPO). An IDHCS controls the DNN feature extractor to extract the most valuable features in the network environment, and identifies intrusion through k-means clustering. Through iterative learning using the PPO-based reinforcement learning model, the system is optimized to improve performance automatically according to the network environment, where the IDHCS is used. Experiments were conducted to evaluate the system performance using the CICIDS2017 and UNSW-NB15 datasets. In CICIDS2017, an F1-score of 0.96552 was achieved and UNSW-NB15 achieved an F1-score of 0.94268. An experiment was conducted by merging the two datasets to build a more extensive and complex test environment. By merging datasets, the attack types in the experiment became more diverse and their patterns became more complex. An F1-score of 0.93567 was achieved in the merged dataset, indicating 97% to 99% performance compared with CICIDS2017 and UNSW-NB15. The results reveal that the proposed IDHCS improved the performance of the IDS by automating learning new types of attacks by managing intrusion detection features regardless of the network environment changes through continuous learning.},
DOI = {10.3390/sym14010161}
}



@Article{app12030943,
AUTHOR = {Kiani, Farzad and Seyyedabbasi, Amir and Nematzadeh, Sajjad and Candan, Fuat and Çevik, Taner and Anka, Fateme Aysin and Randazzo, Giovanni and Lanza, Stefania and Muzirafuti, Anselme},
TITLE = {Adaptive Metaheuristic-Based Methods for Autonomous Robot Path Planning: Sustainable Agricultural Applications},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {943},
URL = {https://www.mdpi.com/2076-3417/12/3/943},
ISSN = {2076-3417},
ABSTRACT = {The increasing need for food in recent years means that environmental protection and sustainable agriculture are necessary. For this, smart agricultural systems and autonomous robots have become widespread. One of the most significant and persistent problems related to robots is 3D path planning, which is an NP-hard problem, for mobile robots. In this paper, efficient methods are proposed by two metaheuristic algorithms (Incremental Gray Wolf Optimization (I-GWO) and Expanded Gray Wolf Optimization (Ex-GWO)). The proposed methods try to find collision-free optimal paths between two points for robots without human intervention in an acceptable time with the lowest process costs and efficient use of resources in large-scale and crowded farmlands. Thanks to the methods proposed in this study, various tasks such as tracking crops can be performed efficiently by autonomous robots. The simulations are carried out using three methods, and the obtained results are compared with each other and analyzed. The relevant results show that in the proposed methods, the mobile robots avoid the obstacles successfully and obtain the optimal path cost from source to destination. According to the simulation results, the proposed method based on the Ex-GWO algorithm has a better success rate of 55.56% in optimal path cost.},
DOI = {10.3390/app12030943}
}



@Article{electronics11030313,
AUTHOR = {Osamy, Walid and Khedr, Ahmed M. and Salim, Ahmed and AlAli, Amal Ibrahim and El-Sawy, Ahmed A.},
TITLE = {Recent Studies Utilizing Artificial Intelligence Techniques for Solving Data Collection, Aggregation and Dissemination Challenges in Wireless Sensor Networks: A Review},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {313},
URL = {https://www.mdpi.com/2079-9292/11/3/313},
ISSN = {2079-9292},
ABSTRACT = {The growing importance and widespread adoption of Wireless Sensor Network (WSN) technologies have helped the enhancement of smart environments in numerous sectors such as manufacturing, smart cities, transportation and Internet of Things by providing pervasive real-time applications. In this survey, we analyze the existing research trends with respect to Artificial Intelligence (AI) methods in WSN and the possible use of these methods for WSN enhancement. The main goal of data collection, aggregation and dissemination algorithms is to gather and aggregate data in an energy efficient manner so that network lifetime is enhanced. In this paper, we highlight data collection, aggregation and dissemination challenges in WSN and present a comprehensive discussion on the recent studies that utilized various AI methods to meet specific objectives of WSN, during the span of 2010 to 2021. We compare and contrast different algorithms on the basis of optimization criteria, simulation/real deployment, centralized/distributed kind, mobility and performance parameters. We conclude with possible future research directions. This would guide the reader towards an understanding of up-to-date applications of AI methods with respect to data collection, aggregation and dissemination challenges in WSN. Then, we provide a general evaluation and comparison of different AI methods used in WSNs, which will be a guide for the research community in identifying the mostly adapted methods and the benefits of using various AI methods for solving the challenges related to WSNs. Finally, we conclude the paper stating the open research issues and new possibilities for future studies.},
DOI = {10.3390/electronics11030313}
}



@Article{sym14020195,
AUTHOR = {Ma, Xiaohang and Liao, Lingxia and Li, Zhi and Lai, Roy Xiaorong and Zhang, Miao},
TITLE = {Applying Federated Learning in Software-Defined Networks: A Survey},
JOURNAL = {Symmetry},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {195},
URL = {https://www.mdpi.com/2073-8994/14/2/195},
ISSN = {2073-8994},
ABSTRACT = {Federated learning (FL) is a type of distributed machine learning approacs that trains global models through the collaboration of participants. It protects data privacy as participants only contribute local models instead of sharing private local data. However, the performance of FL highly relies on the number of participants and their contributions. When applying FL over conventional computer networks, attracting more participants, encouraging participants to contribute more local resources, and enabling efficient and effective collaboration among participants become very challenging. As software-defined networks (SDNs) enable open and flexible networking architecture with separate control and data planes, SDNs provide standardized protocols and specifications to enable fine-grained collaborations among devices. Applying FL approaches over SDNs can take use such advantages to address challenges. A SDN control plane can have multiple controllers organized in layers; the controllers in the lower layer can be placed in the network edge to deal with the asymmetries in the attached switches and hosts, and the controller in the upper layer can supervise the whole network centrally and globally. Applying FL in SDNs with a layered-distributed control plane may be able to protect the data privacy of each participant while improving collaboration among participants to produce higher-quality models over asymmetric networks. Accordingly, this paper aims to make a comprehensive survey on the related mechanisms and solutions that enable FL in SDNs. It highlights three major challenges, an incentive mechanism, privacy and security, and model aggregation, which affect the quality and quantity of participants, the security and privacy in model transferring, and the performance of the global model, respectively. The state of the art in mechanisms and solutions that can be applied to address such challenges in the current literature are categorized based on the challenges they face, followed by suggestions of future research directions. To the best of our knowledge, this work is the first effort in surveying the state of the art in combining FL with SDNs.},
DOI = {10.3390/sym14020195}
}



@Article{en15030828,
AUTHOR = {Ge, Leijiao and Li, Yuanliang and Li, Yuanliang and Yan, Jun and Sun, Yonghui},
TITLE = {Smart Distribution Network Situation Awareness for High-Quality Operation and Maintenance: A Brief Review},
JOURNAL = {Energies},
VOLUME = {15},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {828},
URL = {https://www.mdpi.com/1996-1073/15/3/828},
ISSN = {1996-1073},
ABSTRACT = {In order to meet the requirements of high-tech enterprises for high power quality, high-quality operation and maintenance (O&amp;M) in smart distribution networks (SDN) is becoming increasingly important. As a significant element in enhancing the high-quality O&amp;M of SDN, situation awareness (SA) began to excite the significant interest of scholars and managers, especially after the integration of intermittent renewable energy into SDN. Specific to high-quality O&amp;M, the paper decomposes SA into three stages: detection, comprehension, and projection. In this paper, the state-of-the-art knowledge of SND SA is discussed, a review of critical technologies is presented, and a five-layer visualization framework of the SDN SA is constructed. SA detection aims to improve the SDN observability, SA comprehension is associated with the SDN operating status, and SA projection pertains to the analysis of the future SDN situation. The paper can provide researchers and utility engineers with insights into the technical achievements, barriers, and future research directions of SDN SA.},
DOI = {10.3390/en15030828}
}



@Article{s22030879,
AUTHOR = {Antonić, Martina and Antonić, Aleksandar and Podnar Žarko, Ivana},
TITLE = {Bloom Filter Approach for Autonomous Data Acquisition in the Edge-Based MCS Scenario},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {879},
URL = {https://www.mdpi.com/1424-8220/22/3/879},
ISSN = {1424-8220},
ABSTRACT = {Mobile crowdsensing (MCS) is a sensing paradigm that allows ordinary citizens to use mobile and wearable technologies and become active observers of their surroundings. MCS services generate a massive amount of data due to the vast number of devices engaging in MCS tasks, and the intrinsic mobility of users can quickly make information obsolete, requiring efficient data processing. Our previous work shows that the Bloom filter (BF) is a promising technique to reduce the quantity of redundant data in a hierarchical edge-based MCS ecosystem, allowing users engaging in MCS tasks to make autonomous informed decisions on whether or not to transmit data. This paper extends the proposed BF algorithm to accept multiple data readings of the same type at an exact location if the MCS task requires such functionality. In addition, we thoroughly evaluate the overall behavior of our approach by taking into account the overhead generated in communication between edge servers and end-user devices on a real-world dataset. Our results indicate that using the proposed algorithm makes it possible to significantly reduce the amount of transmitted data and achieve energy savings up to 62% compared to a baseline approach.},
DOI = {10.3390/s22030879}
}




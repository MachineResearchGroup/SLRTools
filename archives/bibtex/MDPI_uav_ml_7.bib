
@Article{rs12162578,
AUTHOR = {Li, Daoliang and Zhang, Pan and Chen, Tao and Qin, Wei},
TITLE = {Recent Development and Challenges in Spectroscopy and Machine Vision Technologies for Crop Nitrogen Diagnosis: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {2578},
URL = {https://www.mdpi.com/2072-4292/12/16/2578},
ISSN = {2072-4292},
ABSTRACT = {Recent development of non-destructive optical techniques, such as spectroscopy and machine vision technologies, have laid a good foundation for real-time monitoring and precise management of crop N status. However, their advantages and disadvantages have not been systematically summarized and evaluated. Here, we reviewed the state-of-the-art of non-destructive optical methods for monitoring the N status of crops, and summarized their advantages and disadvantages. We mainly focused on the contribution of spectral and machine vision technology to the accurate diagnosis of crop N status from three aspects: system selection, data processing, and estimation methods. Finally, we discussed the opportunities and challenges of the application of these technologies, followed by recommendations for future work to address the challenges.},
DOI = {10.3390/rs12162578}
}



@Article{ijgi9080485,
AUTHOR = {Ding, Kaimeng and Liu, Yueming and Xu, Qin and Lu, Fuqiang},
TITLE = {A Subject-Sensitive Perceptual Hash Based on MUM-Net for the Integrity Authentication of High Resolution Remote Sensing Images},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {9},
YEAR = {2020},
NUMBER = {8},
ARTICLE-NUMBER = {485},
URL = {https://www.mdpi.com/2220-9964/9/8/485},
ISSN = {2220-9964},
ABSTRACT = {Data security technology is of great significance to the application of high resolution remote sensing image (HRRS) images. As an important data security technology, perceptual hash overcomes the shortcomings of cryptographic hashing that is not robust and can achieve integrity authentication of HRRS images based on perceptual content. However, the existing perceptual hash does not take into account whether the user focuses on certain types of information of the HRRS image. In this paper, we introduce the concept of subject-sensitive perceptual hash, which can be seen as a special case of conventional perceptual hash, for the integrity authentication of HRRS image. To achieve subject-sensitive perceptual hash, we propose a new deep convolutional neural network architecture, named MUM-Net, for extracting robust features of HRRS images. MUM-Net is the core of perceptual hash algorithm, and it uses focal loss as the loss function to overcome the imbalance between the positive and negative samples in the training samples. The robust features extracted by MUM-Net are further compressed and encoded to obtain the perceptual hash sequence of HRRS image. Experiments show that our algorithm has higher tamper sensitivity to subject-related malicious tampering, and the robustness is improved by about 10% compared to the existing U-net-based algorithm; compared to other deep learning-based algorithms, this algorithm achieves a better balance between robustness and tampering sensitivity, and has better overall performance.},
DOI = {10.3390/ijgi9080485}
}



@Article{app10165564,
AUTHOR = {Hu, Dada and Pei, Zhongcai and Tang, Zhiyong},
TITLE = {Single-Parameter-Tuned Attitude Control for Quadrotor with Unknown Disturbance},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {5564},
URL = {https://www.mdpi.com/2076-3417/10/16/5564},
ISSN = {2076-3417},
ABSTRACT = {In this paper, methods are presented for designing a quadrotor attitude control system with disturbance rejection ability, wherein only one parameter needs to be tuned for each axis. The core difference between quadrotor platforms are extracted as critical gain parameters (CGPs). Reinforcement learning (RL) technology is introduced in order to automatically optimize the controlling law for quadrotors with different CGPs, and the CGPs are used to extend the RL state list. A deterministic policy gradient (DPG) algorithm that is based on an actor-critic structure in a model-free style is used as the learning algorithm. Mirror sampling and reward shaping methods are designed in order to eliminate the steady-state errors of the RL controller and accelerate the training process. Active disturbance rejection control (ADRC) is applied to reject unknown external disturbances. A set of extended state observers (ESOs) is designed to estimate the total disturbance to the roll and pitch axes. The covariance matrix adaptation evolution strategy (CMA-ES) algorithm is used to automatically tune the ESO parameters and improve the final performance. The complete controller is tested on an F550 quadrotor in both simulation and real flight environments. The quadrotor can hover and move around stably and accurately in the air, even with a severe disturbance.},
DOI = {10.3390/app10165564}
}



@Article{rs12162599,
AUTHOR = {Gonçalves, Gil and Andriolo, Umberto and Gonçalves, Luísa and Sobral, Paula and Bessa, Filipa},
TITLE = {Quantifying Marine Macro Litter Abundance on a Sandy Beach Using Unmanned Aerial Systems and Object-Oriented Machine Learning Methods},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {2599},
URL = {https://www.mdpi.com/2072-4292/12/16/2599},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial systems (UASs) have recently been proven to be valuable remote sensing tools for detecting marine macro litter (MML), with the potential of supporting pollution monitoring programs on coasts. Very low altitude images, acquired with a low-cost RGB camera onboard a UAS on a sandy beach, were used to characterize the abundance of stranded macro litter. We developed an object-oriented classification strategy for automatically identifying the marine macro litter items on a UAS-based orthomosaic. A comparison is presented among three automated object-oriented machine learning (OOML) techniques, namely random forest (RF), support vector machine (SVM), and k-nearest neighbor (KNN). Overall, the detection was satisfactory for the three techniques, with mean F-scores of 65% for KNN, 68% for SVM, and 72% for RF. A comparison with manual detection showed that the RF technique was the most accurate OOML macro litter detector, as it returned the best overall detection quality (F-score) with the lowest number of false positives. Because the number of tuning parameters varied among the three automated machine learning techniques and considering that the three generated abundance maps correlated similarly with the abundance map produced manually, the simplest KNN classifier was preferred to the more complex RF. This work contributes to advances in remote sensing marine litter surveys on coasts, optimizing the automated detection on UAS-derived orthomosaics. MML abundance maps, produced by UAS surveys, assist coastal managers and authorities through environmental pollution monitoring programs. In addition, they contribute to search and evaluation of the mitigation measures and improve clean-up operations on coastal environments.},
DOI = {10.3390/rs12162599}
}



@Article{rs12162610,
AUTHOR = {Viinikka, Arto and Hurskainen, Pekka and Keski-Saari, Sarita and Kivinen, Sonja and Tanhuanpää, Topi and Mäyrä, Janne and Poikolainen, Laura and Vihervaara, Petteri and Kumpula, Timo},
TITLE = {Detecting European Aspen (Populus tremula L.) in Boreal Forests Using Airborne Hyperspectral and Airborne Laser Scanning Data},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {2610},
URL = {https://www.mdpi.com/2072-4292/12/16/2610},
ISSN = {2072-4292},
ABSTRACT = {Sustainable forest management increasingly highlights the maintenance of biological diversity and requires up-to-date information on the occurrence and distribution of key ecological features in forest environments. European aspen (Populus tremula L.) is one key feature in boreal forests contributing significantly to the biological diversity of boreal forest landscapes. However, due to their sparse and scattered occurrence in northern Europe, the explicit spatial data on aspen remain scarce and incomprehensive, which hampers biodiversity management and conservation efforts. Our objective was to study tree-level discrimination of aspen from other common species in northern boreal forests using airborne high-resolution hyperspectral and airborne laser scanning (ALS) data. The study contained multiple spatial analyses: First, we assessed the role of different spectral wavelengths (455&ndash;2500 nm), principal component analysis, and vegetation indices (VI) in tree species classification using two machine learning classifiers&mdash;support vector machine (SVM) and random forest (RF). Second, we tested the effect of feature selection for best classification accuracy achievable and third, we identified the most important spectral features to discriminate aspen from the other common tree species. SVM outperformed the RF model, resulting in the highest overall accuracy (OA) of 84% and Kappa value (0.74). The used feature set affected SVM performance little, but for RF, principal component analysis was the best. The most important common VI for deciduous trees contained Conifer Index (CI), Cellulose Absorption Index (CAI), Plant Stress Index 3 (PSI3), and Vogelmann Index 1 (VOG1), whereas Green Ratio (GR), Red Edge Inflection Point (REIP), and Red Well Position (RWP) were specific for aspen. Normalized Difference Red Edge Index (NDRE) and Modified Normalized Difference Index (MND705) were important for coniferous trees. The most important wavelengths for discriminating aspen from other species included reflectance bands of red edge range (724&ndash;727 nm) and shortwave infrared (1520&ndash;1564 nm and 1684&ndash;1706 nm). The highest classification accuracy of 92% (F1-score) for aspen was achieved using the SVM model with mean reflectance values combined with VI, which provides a possibility to produce a spatially explicit map of aspen occurrence that can contribute to biodiversity management and conservation efforts in boreal forests.},
DOI = {10.3390/rs12162610}
}



@Article{smartcities3030046,
AUTHOR = {Ahmadi-Assalemi, Gabriela and Al-Khateeb, Haider and Epiphaniou, Gregory and Maple, Carsten},
TITLE = {Cyber Resilience and Incident Response in Smart Cities: A Systematic Literature Review},
JOURNAL = {Smart Cities},
VOLUME = {3},
YEAR = {2020},
NUMBER = {3},
PAGES = {894--927},
URL = {https://www.mdpi.com/2624-6511/3/3/46},
ISSN = {2624-6511},
ABSTRACT = {The world is experiencing a rapid growth of smart cities accelerated by Industry 4.0, including the Internet of Things (IoT), and enhanced by the application of emerging innovative technologies which in turn create highly fragile and complex cyber&ndash;physical&ndash;natural ecosystems. This paper systematically identifies peer-reviewed literature and explicitly investigates empirical primary studies that address cyber resilience and digital forensic incident response (DFIR) aspects of cyber&ndash;physical systems (CPSs) in smart cities. Our findings show that CPSs addressing cyber resilience and support for modern DFIR are a recent paradigm. Most of the primary studies are focused on a subset of the incident response process, the &ldquo;detection and analysis&rdquo; phase whilst attempts to address other parts of the DFIR process remain limited. Further analysis shows that research focused on smart healthcare and smart citizen were addressed only by a small number of primary studies. Additionally, our findings identify a lack of available real CPS-generated datasets limiting the experiments to mostly testbed type environments or in some cases authors relied on simulation software. Therefore, contributing this systematic literature review (SLR), we used a search protocol providing an evidence-based summary of the key themes and main focus domains investigating cyber resilience and DFIR addressed by CPS frameworks and systems. This SLR also provides scientific evidence of the gaps in the literature for possible future directions for research within the CPS cybersecurity realm. In total, 600 papers were surveyed from which 52 primary studies were included and analysed.},
DOI = {10.3390/smartcities3030046}
}



@Article{app10165608,
AUTHOR = {Yaghoubi, Ehsan and Khezeli, Farhad and Borza, Diana and Kumar, SV Aruna and Neves, João and Proença, Hugo},
TITLE = {Human Attribute Recognition— A Comprehensive Survey},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {5608},
URL = {https://www.mdpi.com/2076-3417/10/16/5608},
ISSN = {2076-3417},
ABSTRACT = {Human Attribute Recognition (HAR) is a highly active research field in computer vision and pattern recognition domains with various applications such as surveillance or fashion. Several approaches have been proposed to tackle the particular challenges in HAR. However, these approaches have dramatically changed over the last decade, mainly due to the improvements brought by deep learning solutions. To provide insights for future algorithm design and dataset collections, in this survey, (1) we provide an in-depth analysis of existing HAR techniques, concerning the advances proposed to address the HAR&rsquo;s main challenges; (2) we provide a comprehensive discussion over the publicly available datasets for the development and evaluation of novel HAR approaches; (3) we outline the applications and typical evaluation metrics used in the HAR context.},
DOI = {10.3390/app10165608}
}



@Article{rs12162623,
AUTHOR = {König, Marcel and Birnbaum, Gerit and Oppelt, Natascha},
TITLE = {Mapping the Bathymetry of Melt Ponds on Arctic Sea Ice Using Hyperspectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {2623},
URL = {https://www.mdpi.com/2072-4292/12/16/2623},
ISSN = {2072-4292},
ABSTRACT = {Hyperspectral remote-sensing instruments on unmanned aerial vehicles (UAVs), aircraft and satellites offer new opportunities for sea ice observations. We present the first study using airborne hyperspectral imagery of Arctic sea ice and evaluate two atmospheric correction approaches (ATCOR-4 (Atmospheric and Topographic Correction version 4; v7.0.0) and empirical line calibration). We apply an existing, field data-based model to derive the depth of melt ponds, to airborne hyperspectral AisaEAGLE imagery and validate results with in situ measurements. ATCOR-4 results roughly match the shape of field spectra but overestimate reflectance resulting in high root-mean-square error (RMSE) (between 0.08 and 0.16). Noisy reflectance spectra may be attributed to the low flight altitude of 200 ft and Arctic atmospheric conditions. Empirical line calibration resulted in smooth, accurate spectra (RMSE &lt; 0.05) that enabled the assessment of melt pond bathymetry. Measured and modeled pond bathymetry are highly correlated (r = 0.86) and accurate (RMSE = 4.04 cm), and the model explains a large portion of the variability (R2 = 0.74). We conclude that an accurate assessment of melt pond bathymetry using airborne hyperspectral data is possible subject to accurate atmospheric correction. Furthermore, we see the necessity to improve existing approaches with Arctic-specific atmospheric profiles and aerosol models and/or by using multiple reference targets on the ground.},
DOI = {10.3390/rs12162623}
}



@Article{rs12162640,
AUTHOR = {Vlachopoulos, Odysseas and Leblon, Brigitte and Wang, Jinfei and Haddadi, Ataollah and LaRocque, Armand and Patterson, Greg},
TITLE = {Delineation of Crop Field Areas and Boundaries from UAS Imagery Using PBIA and GEOBIA with Random Forest Classification},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {2640},
URL = {https://www.mdpi.com/2072-4292/12/16/2640},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aircraft systems (UAS) have been proven cost- and time-effective remote-sensing platforms for precision agriculture applications. This study presents a method for automatic delineation of field areas and boundaries that uses UAS multispectral orthomosaics acquired over 7 vegetated fields having a variety of crops in Prince Edward Island (PEI). This information is needed by crop insurance agencies and growers for an accurate determination of crop insurance premiums. The field areas and boundaries were delineated by applying both a pixel-based and an object-based supervised random forest (RF) classifier applied to reflectance and vegetation index images, followed by a vectorization pipeline. Both methodologies performed exceptionally well, resulting in a mean area goodness of fit (AGoF) for the field areas greater than 98% and a mean boundary mean positional error (BMPE) lower than 0.8 m for the seven surveyed fields.},
DOI = {10.3390/rs12162640}
}



@Article{agronomy10081206,
AUTHOR = {Jayasinghe, Chinthaka and Badenhorst, Pieter and Jacobs, Joe and Spangenberg, German and Smith, Kevin},
TITLE = {High-Throughput Ground Cover Classification of Perennial Ryegrass (Lolium Perenne L.) for the Estimation of Persistence in Pasture Breeding},
JOURNAL = {Agronomy},
VOLUME = {10},
YEAR = {2020},
NUMBER = {8},
ARTICLE-NUMBER = {1206},
URL = {https://www.mdpi.com/2073-4395/10/8/1206},
ISSN = {2073-4395},
ABSTRACT = {Perennial ryegrass (Lolium perenne L.) is one of the most important forage grass species in temperate regions of Australia and New Zealand. However, it can have poor persistence due to a low tolerance to both abiotic and biotic stresses. A major challenge in measuring persistence in pasture breeding is that the assessment of pasture survival depends on ranking populations based on manual ground cover estimation. Ground cover measurements may include senescent and living tissues and can be measured as percentages or fractional units. The amount of senescent pasture present in a sward may indicate changes in plant growth, development, and resistance to abiotic and biotic stresses. The existing tools to estimate perennial ryegrass ground cover are not sensitive enough to discriminate senescent ryegrass from soil. This study aimed to develop a more precise sensor-based phenomic method to discriminate senescent pasture from soil. Ground-based RGB images, airborne multispectral images, ground-based hyperspectral data, and ground truth samples were taken from 54 perennial ryegrass plots three years after sowing. Software packages and machine learning scripts were used to develop a pipeline for high-throughput data extraction from sensor-based platforms. Estimates from the high-throughput pipeline were positively correlated with the ground truth data (p &lt; 0.05). Based on the findings of this study, we conclude that the RGB-based high-throughput approach offers a precision tool to assess perennial ryegrass persistence in pasture breeding programs. Improvements in the spatial resolution of hyperspectral and multispectral techniques would then be used for persistence estimation in mixed swards and other monocultures.},
DOI = {10.3390/agronomy10081206}
}



@Article{bdcc4030020,
AUTHOR = {Ciaburro, Giuseppe},
TITLE = {Sound Event Detection in Underground Parking Garage Using Convolutional Neural Network},
JOURNAL = {Big Data and Cognitive Computing},
VOLUME = {4},
YEAR = {2020},
NUMBER = {3},
ARTICLE-NUMBER = {20},
URL = {https://www.mdpi.com/2504-2289/4/3/20},
ISSN = {2504-2289},
ABSTRACT = {Parking is a crucial element in urban mobility management. The availability of parking areas makes it easier to use a service, determining its success. Proper parking management allows economic operators located nearby to increase their business revenue. Underground parking areas during off-peak hours are uncrowded places, where user safety is guaranteed by company overseers. Due to the large size, ensuring adequate surveillance would require many operators to increase the costs of parking fees. To reduce costs, video surveillance systems are used, in which an operator monitors many areas. However, some activities are beyond the control of this technology. In this work, a procedure to identify sound events in an underground garage is developed. The aim of the work is to detect sounds identifying dangerous situations and to activate an automatic alert that draws the attention of surveillance in that area. To do this, the sounds of a parking sector were detected with the use of sound sensors. These sounds were analyzed by a sound detector based on convolutional neural networks. The procedure returned high accuracy in identifying a car crash in an underground parking area.},
DOI = {10.3390/bdcc4030020}
}



@Article{rs12162657,
AUTHOR = {Stereńczak, Krzysztof and Zapłata, Rafał and Wójcik, Jarosław and Kraszewski, Bartłomiej and Mielcarek, Miłosz and Mitelsztedt, Krzysztof and Białczak, Małgorzata and Krok, Grzegorz and Kuberski, Łukasz and Markiewicz, Anna and Modzelewska, Aneta and Parkitna, Karolina and Piasecka, Żaneta and Pilch, Kamil and Rzeczycki, Karol and Sadkowski, Rafał and Wietecha, Martyna and Rysiak, Piotr and von Gadow, Klaus and Cieszewski, Chris J.},
TITLE = {ALS-Based Detection of Past Human Activities in the Białowieża Forest—New Evidence of Unknown Remains of Past Agricultural Systems},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {2657},
URL = {https://www.mdpi.com/2072-4292/12/16/2657},
ISSN = {2072-4292},
ABSTRACT = {The Białowieża Forest (BF), a unique ecosystem of historical significance in central Europe, has a long history of assumed human settlement, with at least 200 known archaeological sites (until 2016). This study uncovers new evidence of the cultural heritage of this unique forest area using Airborne Laser Scanning (ALS) technology combined with traditional archaeological field assessment methods to verify the ALS data interpretations and to provide additional evidence about the function and origin of the newly detected archaeological sites. The results of this study include (1) a scientific approach for an improved identification of archaeological resources in forest areas; (2) new evidence about the history of the human use of the BF based on ALS data, covering the entire Polish part of the BF; and (3) an improved remote sensing infrastructure, supporting existing GIS (Geographic Information System) systems for the BF, a famous UNESCO Heritage site. Our study identified numerous locations with evidence of past human agricultural activities known in the literature as &ldquo;field systems&rdquo;, &ldquo;lynchets&rdquo; and &ldquo;Celtic fields&rdquo;. The initial identification included more than 300 km of possible field boundaries and plough headlands, many of which we have verified on the ground. Various past human activities creating those boundaries have existed since the (pre-) Roman Period up to the 13th century AD. The results of this study demonstrate that past human activities in the Polish part of the Białowieża Forest had been more prevalent than previously believed. As a practical result of the described activities, a geodatabase was created; this has practical applications for the system of monument protection in Poland, as well as for local communities and the BF&rsquo;s management and conservation. The more widely achieved results are in line with the implementation of the concept of a cultural heritage inventory in forested and protected areas&mdash;the actions taken specify (built globally) the forms of protection and management of cultural and environmental goods.},
DOI = {10.3390/rs12162657}
}



@Article{drones4030045,
AUTHOR = {Musci, Maria Angela and Mazzara, Luigi and Lingua, Andrea Maria},
TITLE = {Ice Detection on Aircraft Surface Using Machine Learning Approaches Based on Hyperspectral and Multispectral Images},
JOURNAL = {Drones},
VOLUME = {4},
YEAR = {2020},
NUMBER = {3},
ARTICLE-NUMBER = {45},
URL = {https://www.mdpi.com/2504-446X/4/3/45},
ISSN = {2504-446X},
ABSTRACT = {Aircraft ground de-icing operations play a critical role in flight safety. However, to handle the aircraft de-icing, a considerable quantity of de-icing fluids is commonly employed. Moreover, some pre-flight inspections are carried out with engines running; thus, a large amount of fuel is wasted, and CO2 is emitted. This implies substantial economic and environmental impacts. In this context, the European project (reference call: MANUNET III 2018, project code: MNET18/ICT-3438) called SEI (Spectral Evidence of Ice) aims to provide innovative tools to identify the ice on aircraft and improve the efficiency of the de-icing process. The project includes the design of a low-cost UAV (uncrewed aerial vehicle) platform and the development of a quasi-real-time ice detection methodology to ensure a faster and semi-automatic activity with a reduction of applied operating time and de-icing fluids. The purpose of this work, developed within the activities of the project, is defining and testing the most suitable sensor using a radiometric approach and machine learning algorithms. The adopted methodology consists of classifying ice through spectral imagery collected by two different sensors: multispectral and hyperspectral camera. Since the UAV prototype is under construction, the experimental analysis was performed with a simulation dataset acquired on the ground. The comparison among the two approaches, and their related algorithms (random forest and support vector machine) for image processing, was presented: practical results show that it is possible to identify the ice in both cases. Nonetheless, the hyperspectral camera guarantees a more reliable solution reaching a higher level of accuracy of classified iced surfaces.},
DOI = {10.3390/drones4030045}
}



@Article{jmse8090624,
AUTHOR = {Singh, Yogang and Bibuli, Marco and Zereik, Enrica and Sharma, Sanjay and Khan, Asiya and Sutton, Robert},
TITLE = {A Novel Double Layered Hybrid Multi-Robot Framework for Guidance and Navigation of Unmanned Surface Vehicles in a Practical Maritime Environment},
JOURNAL = {Journal of Marine Science and Engineering},
VOLUME = {8},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {624},
URL = {https://www.mdpi.com/2077-1312/8/9/624},
ISSN = {2077-1312},
ABSTRACT = {Formation control and cooperative motion planning are two major research areas currently being used in multi robot motion planning and coordination. The current study proposes a hybrid framework for guidance and navigation of swarm of unmanned surface vehicles (USVs) by combining the key characteristics of formation control and cooperative motion planning. In this framework, two layers of offline planning and online planning are integrated and applied on a practical marine environment. In offline planning, an optimal path is generated from a constrained A* path planning approach, which is later smoothed using a spline. This optimal trajectory is fed as an input for the online planning where virtual target (VT) based multi-agent guidance framework is used to navigate the swarm of USVs. This VT approach combined with a potential theory based swarm aggregation technique provides a robust methodology of global and local collision avoidance based on known positions of the USVs. The combined approach is evaluated with the different number of USVs to understand the effectiveness of the approach from the perspective of practicality, safety and robustness.},
DOI = {10.3390/jmse8090624}
}



@Article{drones4030046,
AUTHOR = {Adamopoulos, Efstathios and Rinaudo, Fulvio},
TITLE = {UAS-Based Archaeological Remote Sensing: Review, Meta-Analysis and State-of-the-Art},
JOURNAL = {Drones},
VOLUME = {4},
YEAR = {2020},
NUMBER = {3},
ARTICLE-NUMBER = {46},
URL = {https://www.mdpi.com/2504-446X/4/3/46},
ISSN = {2504-446X},
ABSTRACT = {Over the last decade, we have witnessed momentous technological developments in unmanned aircraft systems (UAS) and in lightweight sensors operating at various wavelengths, at and beyond the visible spectrum, which can be integrated with unmanned aerial platforms. These innovations have made feasible close-range and high-resolution remote sensing for numerous archaeological applications, including documentation, prospection, and monitoring bridging the gap between satellite, high-altitude airborne, and terrestrial sensing of historical sites and landscapes. In this article, we track the progress made so far, by systematically reviewing the literature relevant to the combined use of UAS platforms with visible, infrared, multi-spectral, hyper-spectral, laser, and radar sensors to reveal archaeological features otherwise invisible to archaeologists with applied non-destructive techniques. We review, specific applications and their global distribution, as well as commonly used platforms, sensors, and data-processing workflows. Furthermore, we identify the contemporary state-of-the-art and discuss the challenges that have already been overcome, and those that have not, to propose suggestions for future research.},
DOI = {10.3390/drones4030046}
}



@Article{rs12172683,
AUTHOR = {Jimenez-Sierra, David Alejandro and Benítez-Restrepo, Hernán Darío and Vargas-Cardona, Hernán Darío and Chanussot, Jocelyn},
TITLE = {Graph-Based Data Fusion Applied to: Change Detection and Biomass Estimation in Rice Crops},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {2683},
URL = {https://www.mdpi.com/2072-4292/12/17/2683},
ISSN = {2072-4292},
ABSTRACT = {The complementary nature of different modalities and multiple bands used in remote sensing data is helpful for tasks such as change detection and the prediction of agricultural variables. Nonetheless, correctly processing a multi-modal dataset is not a simple task, owing to the presence of different data resolutions and formats. In the past few years, graph-based methods have proven to be a useful tool in capturing inherent data similarity, in spite of different data formats, and preserving relevant topological and geometric information. In this paper, we propose a graph-based data fusion algorithm for remotely sensed images applied to (i) data-driven semi-unsupervised change detection and (ii) biomass estimation in rice crops. In order to detect the change, we evaluated the performance of four competing algorithms on fourteen datasets. To estimate biomass in rice crops, we compared our proposal in terms of root mean squared error (RMSE) concerning a recent approach based on vegetation indices as features. The results confirm that the proposed graph-based data fusion algorithm outperforms state-of-the-art methods for change detection and biomass estimation in rice crops.},
DOI = {10.3390/rs12172683}
}



@Article{s20174691,
AUTHOR = {Bisagno, Niccolò and Xamin, Alberto and De Natale, Francesco and Conci, Nicola and Rinner, Bernhard},
TITLE = {Dynamic Camera Reconfiguration with Reinforcement Learning and Stochastic Methods for Crowd Surveillance},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {4691},
URL = {https://www.mdpi.com/1424-8220/20/17/4691},
ISSN = {1424-8220},
ABSTRACT = {Crowd surveillance plays a key role to ensure safety and security in public areas. Surveillance systems traditionally rely on fixed camera networks, which suffer from limitations, as coverage of the monitored area, video resolution and analytic performance. On the other hand, a smart camera network provides the ability to reconfigure the sensing infrastructure by incorporating active devices such as pan-tilt-zoom (PTZ) cameras and UAV-based cameras, thus enabling the network to adapt over time to changes in the scene. We propose a new decentralised approach for network reconfiguration, where each camera dynamically adapts its parameters and position to optimise scene coverage. Two policies for decentralised camera reconfiguration are presented: a greedy approach and a reinforcement learning approach. In both cases, cameras are able to locally control the state of their neighbourhood and dynamically adjust their position and PTZ parameters. When crowds are present, the network balances between global coverage of the entire scene and high resolution for the crowded areas. We evaluate our approach in a simulated environment monitored with fixed, PTZ and UAV-based cameras.},
DOI = {10.3390/s20174691}
}



@Article{app10175773,
AUTHOR = {Alparslan, Onur and Arakawa, Shin’ichi and Murata, Masayuki},
TITLE = {SDN-Based Control of IoT Network by Brain-Inspired Bayesian Attractor Model and Network Slicing},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {5773},
URL = {https://www.mdpi.com/2076-3417/10/17/5773},
ISSN = {2076-3417},
ABSTRACT = {One of the models in the literature for modeling the behavior of the brain is the Bayesian attractor model, which is a kind of machine-learning algorithm. According to this model, the brain assigns stochastic variables to possible decisions (attractors) and chooses one of them when enough evidence is collected from sensory systems to achieve a confidence level high enough to make a decision. In this paper, we introduce a software defined networking (SDN) application based on a brain-inspired Bayesian attractor model for identification of the current traffic pattern for the supervision and automation of Internet of things (IoT) networks that exhibit a limited number of traffic patterns. In a real SDN testbed, we demonstrate that our SDN application can identify the traffic patterns using a limited set of fluctuating network statistics of edge link utilization. Moreover, we show that our application can improve core link utilization and the power efficiency of IoT networks by immediately applying a pre-calculated network configuration optimized by traffic engineering with network slicing for the identified pattern.},
DOI = {10.3390/app10175773}
}



@Article{s20174709,
AUTHOR = {Wang, Bin and Gu, Yinjuan},
TITLE = {An Improved FBPN-Based Detection Network for Vehicles in Aerial Images},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {4709},
URL = {https://www.mdpi.com/1424-8220/20/17/4709},
ISSN = {1424-8220},
ABSTRACT = {With the development of artificial intelligence and big data analytics, an increasing number of researchers have tried to use deep-learning technology to train neural networks and achieved great success in the field of vehicle detection. However, as a special domain of object detection, vehicle detection in aerial images still has made limited progress because of low resolution, complex backgrounds and rotating objects. In this paper, an improved feature-balanced pyramid network (FBPN) has been proposed to enhance the network&rsquo;s ability to detect small objects. By combining FBPN with modified faster region convolutional neural network (faster-RCNN), a vehicle detection framework for aerial images is proposed. The focal loss function is adopted in the proposed framework to reduce the imbalance between easy and hard samples. The experimental results based on the VEDIA, USCAS-AOD, and DOTA datasets show that the proposed framework outperforms other state-of-the-art vehicle detection algorithms for aerial images.},
DOI = {10.3390/s20174709}
}



@Article{robotics9030064,
AUTHOR = {Wilson, Callum and Marchetti, Francesco and Di Carlo, Marilena and Riccardi, Annalisa and Minisci, Edmondo},
TITLE = {Classifying Intelligence in Machines: A Taxonomy of Intelligent Control},
JOURNAL = {Robotics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {3},
ARTICLE-NUMBER = {64},
URL = {https://www.mdpi.com/2218-6581/9/3/64},
ISSN = {2218-6581},
ABSTRACT = {The quest to create machines that can solve problems as humans do leads us to intelligent control. This field encompasses control systems that can adapt to changes and learn to improve their actions&mdash;traits typically associated with human intelligence. In this work we seek to determine how intelligent these classes of control systems are by quantifying their level of adaptability and learning. First we describe the stages of development towards intelligent control and present a definition based on literature. Based on the key elements of this definition, we propose a novel taxonomy of intelligent control methods, which assesses the extent to which they handle uncertainties in three areas: the environment, the controller, and the goals. This taxonomy is applicable to a variety of robotic and other autonomous systems, which we demonstrate through several examples of intelligent control methods and their classifications. Looking at the spread of classifications based on this taxonomy can help researchers identify where control systems can be made more intelligent.},
DOI = {10.3390/robotics9030064}
}



@Article{ijgi9090499,
AUTHOR = {Brauchler, Melanie and Stoffels, Johannes},
TITLE = {Leveraging OSM and GEOBIA to Create and Update Forest Type Maps},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {9},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {499},
URL = {https://www.mdpi.com/2220-9964/9/9/499},
ISSN = {2220-9964},
ABSTRACT = {Up-to-date information about the type and spatial distribution of forests is an essential element in both sustainable forest management and environmental monitoring and modelling. The OpenStreetMap (OSM) database contains vast amounts of spatial information on natural features, including forests (landuse=forest). The OSM data model includes describing tags for its contents, i.e., leaf type for forest areas (i.e., leaf_type=broadleaved). Although the leaf type tag is common, the vast majority of forest areas are tagged with the leaf type mixed, amounting to a total area of 87% of landuse=forests from the OSM database. These areas comprise an important information source to derive and update forest type maps. In order to leverage this information content, a methodology for stratification of leaf types inside these areas has been developed using image segmentation on aerial imagery and subsequent classification of leaf types. The presented methodology achieves an overall classification accuracy of 85% for the leaf types needleleaved and broadleaved in the selected forest areas. The resulting stratification demonstrates that through approaches, such as that presented, the derivation of forest type maps from OSM would be feasible with an extended and improved methodology. It also suggests an improved methodology might be able to provide updates of leaf type to the OSM database with contributor participation.},
DOI = {10.3390/ijgi9090499}
}



@Article{app10175799,
AUTHOR = {Yang, Yuanwei and Ran, Shuhao and Gao, Xianjun and Wang, Mingwei and Li, Xi},
TITLE = {An Automatic Shadow Compensation Method via a New Model Combined Wallis Filter with LCC Model in High Resolution Remote Sensing Images},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {5799},
URL = {https://www.mdpi.com/2076-3417/10/17/5799},
ISSN = {2076-3417},
ABSTRACT = {Current automatic shadow compensation methods often suffer because their contrast improvement processes are not self-adaptive and, consequently, the results they produce do not adequately represent the real objects. The study presented in this paper designed a new automatic shadow compensation framework based on improvements to the Wallis principle, which included an intensity coefficient and a stretching coefficient to enhance contrast and brightness more efficiently. An automatic parameter calculation strategy also is a part of this framework, which is based on searching for and matching similar feature points around shadow boundaries. Finally, a final compensation combination strategy combines the regional compensation with the local window compensation of the pixels in each shadow to improve the shaded information in a balanced way. All these strategies in our method work together to provide a better measurement for customizing suitable compensation depending on the condition of each region and pixel. The intensity component I also is automatically strengthened through the customized compensation model. Color correction is executed in a way that avoids the color bias caused by over-compensated component values, thereby better reflecting shaded information. Images with clouds shadows and ground objects shadows were utilized to test our method and six other state-of-the-art methods. The comparison results indicate that our method compensated for shaded information more effectively, accurately, and evenly than the other methods for customizing suitable models for each shadow and pixel with reasonable time-cost. Its brightness, contrast, and object color in shaded areas were approximately equalized with non-shaded regions to present a shadow-free image.},
DOI = {10.3390/app10175799}
}



@Article{jmse8090647,
AUTHOR = {Rende, Sante Francesco and Bosman, Alessandro and Di Mento, Rossella and Bruno, Fabio and Lagudi, Antonio and Irving, Andrew D. and Dattola, Luigi and Giambattista, Luca Di and Lanera, Pasquale and Proietti, Raffaele and Parlagreco, Luca and Stroobant, Mascha and Cellini, Emilio},
TITLE = {Ultra-High-Resolution Mapping of Posidonia oceanica (L.) Delile Meadows through Acoustic, Optical Data and Object-based Image Classification},
JOURNAL = {Journal of Marine Science and Engineering},
VOLUME = {8},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {647},
URL = {https://www.mdpi.com/2077-1312/8/9/647},
ISSN = {2077-1312},
ABSTRACT = {In this study, we present a framework for seagrass habitat mapping in shallow (5&ndash;50 m) and very shallow water (0&ndash;5 m) by combining acoustic, optical data and Object-based Image classification. The combination of satellite multispectral images-acquired from 2017 to 2019, together with Unmanned Aerial Vehicle (UAV) photomosaic maps, high-resolution multibeam bathymetry/backscatter and underwater photogrammetry data, provided insights on the short-term characterization and distribution of Posidonia oceanica (L.) Delile, 1813 meadows in the Calabrian Tyrrhenian Sea. We used a supervised Object-based Image Analysis (OBIA) processing and classification technique to create a high-resolution thematic distribution map of P. oceanica meadows from multibeam bathymetry, backscatter data, drone photogrammetry and multispectral images that can be used as a model for classification of marine and coastal areas. As a part of this work, within the SIC CARLIT project, a field application was carried out in a Site of Community Importance (SCI) on Cirella Island in Calabria (Italy); different multiscale mapping techniques have been performed and integrated: the optical and acoustic data were processed and classified by different OBIA algorithms, i.e., k-Nearest Neighbors&rsquo; algorithm (k-NN), Random Tree algorithm (RT) and Decision Tree algorithm (DT). These acoustic and optical data combinations were shown to be a reliable tool to obtain high-resolution thematic maps for the preliminary characterization of seagrass habitats. These thematic maps can be used for time-lapse comparisons aimed to quantify changes in seabed coverage, such as those caused by anthropogenic impacts (e.g., trawl fishing activities and boat anchoring) to assess the blue carbon sinks and might be useful for future seagrass habitats conservation strategies.},
DOI = {10.3390/jmse8090647}
}



@Article{rs12172722,
AUTHOR = {Wang, Yuxuan and Wu, Guangming and Guo, Yimin and Huang, Yifei and Shibasaki, Ryosuke},
TITLE = {Learn to Extract Building Outline from Misaligned Annotation through Nearest Feature Selector},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {2722},
URL = {https://www.mdpi.com/2072-4292/12/17/2722},
ISSN = {2072-4292},
ABSTRACT = {For efficient building outline extraction, many algorithms, including unsupervised or supervised, have been proposed over the past decades. In recent years, due to the rapid development of the convolutional neural networks, especially fully convolutional networks, building extraction is treated as a semantic segmentation task that deals with the extremely biased positive pixels. The state-of-the-art methods, either through direct or indirect approaches, are mainly focused on better network design. The shifts and rotations, which are coarsely presented in manually created annotations, have long been ignored. Due to the limited number of positive samples, the misalignment will significantly reduce the correctness of pixel-to-pixel loss that might lead to a gradient explosion. To overcome this, we propose a nearest feature selector (NFS) to dynamically re-align the prediction and slightly misaligned annotations. The NFS can be seamlessly appended to existing loss functions and prevent misleading by the errors or misalignment of annotations. Experiments on a large scale aerial image dataset with centered buildings and corresponding building outlines indicate that the additional NFS brings higher performance when compared to existing naive loss functions. In the classic L1 loss, the addition of NFS gains increments of 8.8% of f1-score, 8.9% of kappa coefficient, and 9.8% of Jaccard index, respectively.},
DOI = {10.3390/rs12172722}
}



@Article{ijgi9090507,
AUTHOR = {Arjasakusuma, Sanjiwana and Swahyu Kusuma, Sandiaga and Phinn, Stuart},
TITLE = {Evaluating Variable Selection and Machine Learning Algorithms for Estimating Forest Heights by Combining Lidar and Hyperspectral Data},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {9},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {507},
URL = {https://www.mdpi.com/2220-9964/9/9/507},
ISSN = {2220-9964},
ABSTRACT = {Machine learning has been employed for various mapping and modeling tasks using input variables from different sources of remote sensing data. For feature selection involving high- spatial and spectral dimensionality data, various methods have been developed and incorporated into the machine learning framework to ensure an efficient and optimal computational process. This research aims to assess the accuracy of various feature selection and machine learning methods for estimating forest height using AISA (airborne imaging spectrometer for applications) hyperspectral bands (479 bands) and airborne light detection and ranging (lidar) height metrics (36 metrics), alone and combined. Feature selection and dimensionality reduction using Boruta (BO), principal component analysis (PCA), simulated annealing (SA), and genetic algorithm (GA) in combination with machine learning algorithms such as multivariate adaptive regression spline (MARS), extra trees (ET), support vector regression (SVR) with radial basis function, and extreme gradient boosting (XGB) with trees (XGbtree and XGBdart) and linear (XGBlin) classifiers were evaluated. The results demonstrated that the combinations of BO-XGBdart and BO-SVR delivered the best model performance for estimating tropical forest height by combining lidar and hyperspectral data, with R2 = 0.53 and RMSE = 1.7 m (18.4% of nRMSE and 0.046 m of bias) for BO-XGBdart and R2 = 0.51 and RMSE = 1.8 m (15.8% of nRMSE and &minus;0.244 m of bias) for BO-SVR. Our study also demonstrated the effectiveness of BO for variables selection; it could reduce 95% of the data to select the 29 most important variables from the initial 516 variables from lidar metrics and hyperspectral data.},
DOI = {10.3390/ijgi9090507}
}



@Article{rs12172732,
AUTHOR = {Abdulridha, Jaafar and Ampatzidis, Yiannis and Qureshi, Jawwad and Roberts, Pamela},
TITLE = {Laboratory and UAV-Based Identification and Classification of Tomato Yellow Leaf Curl, Bacterial Spot, and Target Spot Diseases in Tomato Utilizing Hyperspectral Imaging and Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {2732},
URL = {https://www.mdpi.com/2072-4292/12/17/2732},
ISSN = {2072-4292},
ABSTRACT = {Tomato crops are susceptible to multiple diseases, several of which may be present during the same season. Therefore, rapid disease identification could enhance crop management consequently increasing the yield. In this study, nondestructive methods were developed to detect diseases that affect tomato crops, such as bacterial spot (BS), target spot (TS), and tomato yellow leaf curl (TYLC) for two varieties of tomato (susceptible and tolerant to TYLC only) by using hyperspectral sensing in two conditions: a) laboratory (benchtop scanning), and b) in field using an unmanned aerial vehicle (UAV-based). The stepwise discriminant analysis (STDA) and the radial basis function were applied to classify the infected plants and distinguish them from noninfected or healthy (H) plants. Multiple vegetation indices (VIs) and the M statistic method were utilized to distinguish and classify the diseased plants. In general, the classification results between healthy and diseased plants were highly accurate for all diseases; for instance, when comparing H vs. BS, TS, and TYLC in the asymptomatic stage and laboratory conditions, the classification rates were 94%, 95%, and 100%, respectively. Similarly, in the symptomatic stage, the classification rates between healthy and infected plants were 98% for BS, and 99&ndash;100% for TS and TYLC diseases. The classification results in the field conditions also showed high values of 98%, 96%, and 100%, for BS, TS, and TYLC, respectively. The VIs that could best identify these diseases were the renormalized difference vegetation index (RDVI), and the modified triangular vegetation index 1 (MTVI 1) in both laboratory and field. The results were promising and suggest the possibility to identify these diseases using remote sensing.},
DOI = {10.3390/rs12172732}
}



@Article{insects11090565,
AUTHOR = {Zhang, Zhiliang and Zhan, Wei and He, Zhangzhang and Zou, Yafeng},
TITLE = {Application of Spatio-Temporal Context and Convolution Neural Network (CNN) in Grooming Behavior of Bactrocera minax (Diptera: Trypetidae) Detection and Statistics},
JOURNAL = {Insects},
VOLUME = {11},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {565},
URL = {https://www.mdpi.com/2075-4450/11/9/565},
PubMedID = {32846918},
ISSN = {2075-4450},
ABSTRACT = {Statistical analysis and research on insect grooming behavior can find more effective methods for pest control. Traditional manual insect grooming behavior statistical methods are time-consuming, labor-intensive, and error-prone. Based on computer vision technology, this paper uses spatio-temporal context to extract video features, uses self-built Convolution Neural Network (CNN) to train the detection model, and proposes a simple and effective Bactrocera minax grooming behavior detection method, which automatically detects the grooming behaviors of the flies and analysis results by a computer program. Applying the method training detection model proposed in this paper, the videos of 22 adult flies with a total of 1320 min of grooming behavior were detected and analyzed, and the total detection accuracy was over 95%, the standard error of the accuracy of the behavior detection of each adult flies was less than 3%, and the difference was less than 15% when compared with the results of manual observation. The experimental results show that the method in this paper greatly reduces the time of manual observation and at the same time ensures the accuracy of insect behavior detection and analysis, which proposes a new informatization analysis method for the behavior statistics of Bactrocera minax and also provides a new idea for related insect behavior identification research.},
DOI = {10.3390/insects11090565}
}



@Article{math8091415,
AUTHOR = {Li, Juan and Lei, Hong and Alavi, Amir H. and Wang, Gai-Ge},
TITLE = {Elephant Herding Optimization: Variants, Hybrids, and Applications},
JOURNAL = {Mathematics},
VOLUME = {8},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1415},
URL = {https://www.mdpi.com/2227-7390/8/9/1415},
ISSN = {2227-7390},
ABSTRACT = {Elephant herding optimization (EHO) is a nature-inspired metaheuristic optimization algorithm based on the herding behavior of elephants. EHO uses a clan operator to update the distance of the elephants in each clan with respect to the position of a matriarch elephant. The superiority of the EHO method to several state-of-the-art metaheuristic algorithms has been demonstrated for many benchmark problems and in various application areas. A comprehensive review for the EHO-based algorithms and their applications are presented in this paper. Various aspects of the EHO variants for continuous optimization, combinatorial optimization, constrained optimization, and multi-objective optimization are reviewed. Future directions for research in the area of EHO are further discussed.},
DOI = {10.3390/math8091415}
}



@Article{rs12172733,
AUTHOR = {Devadoss, Jashvina and Falco, Nicola and Dafflon, Baptiste and Wu, Yuxin and Franklin, Maya and Hermes, Anna and Hinckley, Eve-Lyn S. and Wainwright, Haruko},
TITLE = {Remote Sensing-Informed Zonation for Understanding Snow, Plant and Soil Moisture Dynamics within a Mountain Ecosystem},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {2733},
URL = {https://www.mdpi.com/2072-4292/12/17/2733},
ISSN = {2072-4292},
ABSTRACT = {In the headwater catchments of the Rocky Mountains, plant productivity and its dynamics are largely dependent upon water availability, which is influenced by changing snowmelt dynamics associated with climate change. Understanding and quantifying the interactions between snow, plants and soil moisture is challenging, since these interactions are highly heterogeneous in mountainous terrain, particularly as they are influenced by microtopography within a hillslope. Recent advances in satellite remote sensing have created an opportunity for monitoring snow and plant dynamics at high spatiotemporal resolutions that can capture microtopographic effects. In this study, we investigate the relationships among topography, snowmelt, soil moisture and plant dynamics in the East River watershed, Crested Butte, Colorado, based on a time series of 3-meter resolution PlanetScope normalized difference vegetation index (NDVI) images. To make use of a large volume of high-resolution time-lapse images (17 images total), we use unsupervised machine learning methods to reduce the dimensionality of the time lapse images by identifying spatial zones that have characteristic NDVI time series. We hypothesize that each zone represents a set of similar snowmelt and plant dynamics that differ from other identified zones and that these zones are associated with key topographic features, plant species and soil moisture. We compare different distance measures (Ward and complete linkage) to understand the effects of their influence on the zonation map. Results show that the identified zones are associated with particular microtopographic features; highly productive zones are associated with low slopes and high topographic wetness index, in contrast with zones of low productivity, which are associated with high slopes and low topographic wetness index. The zones also correspond to particular plant species distributions; higher forb coverage is associated with zones characterized by higher peak productivity combined with rapid senescence in low moisture conditions, while higher sagebrush coverage is associated with low productivity and similar senescence patterns between high and low moisture conditions. In addition, soil moisture probe and sensor data confirm that each zone has a unique soil moisture distribution. This cluster-based analysis can tractably analyze high-resolution time-lapse images to examine plant-soil-snow interactions, guide sampling and sensor placements and identify areas likely vulnerable to ecological change in the future.},
DOI = {10.3390/rs12172733}
}



@Article{rs12172748,
AUTHOR = {Julin, Arttu and Kurkela, Matti and Rantanen, Toni and Virtanen, Juho-Pekka and Maksimainen, Mikko and Kukko, Antero and Kaartinen, Harri and Vaaja, Matti T. and Hyyppä, Juha and Hyyppä, Hannu},
TITLE = {Evaluating the Quality of TLS Point Cloud Colorization},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {2748},
URL = {https://www.mdpi.com/2072-4292/12/17/2748},
ISSN = {2072-4292},
ABSTRACT = {Terrestrial laser scanning (TLS) enables the efficient production of high-density colored 3D point clouds of real-world environments. An increasing number of applications from visual and automated interpretation to photorealistic 3D visualizations and experiences rely on accurate and reliable color information. However, insufficient attention has been put into evaluating the colorization quality of the 3D point clouds produced applying TLS. We have developed a method for the evaluation of the point cloud colorization quality of TLS systems with integrated imaging sensors. Our method assesses the capability of several tested systems to reproduce colors and details of a scene by measuring objective image quality metrics from 2D images that were rendered from 3D scanned test charts. The results suggest that the detected problems related to color reproduction (i.e., measured differences in color, white balance, and exposure) could be mitigated in data processing while the issues related to detail reproduction (i.e., measured sharpness and noise) are less in the control of a scanner user. Despite being commendable 3D measuring instruments, improving the colorization tools and workflows, and automated image processing pipelines would potentially increase not only the quality and production efficiency but also the applicability of colored 3D point clouds.},
DOI = {10.3390/rs12172748}
}



@Article{s20174800,
AUTHOR = {Fabre, Sophie and Gimenez, Rollin and Elger, Arnaud and Rivière, Thomas},
TITLE = {Unsupervised Monitoring Vegetation after the Closure of an Ore Processing Site with Multi-Temporal Optical Remote Sensing},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {4800},
URL = {https://www.mdpi.com/1424-8220/20/17/4800},
ISSN = {1424-8220},
ABSTRACT = {Ore processing is a source of soil heavy metal pollution. Vegetation traits (structural characteristics such as spatial cover and repartition; biochemical parameters&mdash;pigment and water contents, growth rate, phenological cycle&hellip;) and plant species identity are indirect and powerful indicators of residual contamination detection in soil. Multi-temporal multispectral satellite imagery, such as the Sentinel-2 time series, is an operational environment monitoring system widely used to access vegetation traits and ensure vegetation surveillance across large areas. For this purpose, methodology based on a multi-temporal fusion method at the feature level is applied to vegetation monitoring for several years from the closure and revegetation of an ore processing site. Features are defined by 26 spectral indices from the literature and seasonal and annual change detection maps are inferred. Three indices&mdash;CIred-edge (CIREDEDGE), IRECI (Inverted Red-Edge Chlorophyll Index) and PSRI (Plant Senescence Reflectance Index)&mdash;are particularly suitable for detecting changes spatially and temporally across the study area. The analysis is conducted separately for phyto-stabilized vegetation zones and natural vegetation zones. Global and specific changes are emphasized and explained by information provided by the site operator or meteorological conditions.},
DOI = {10.3390/s20174800}
}



@Article{rs12172760,
AUTHOR = {Misra, Gourav and Cawkwell, Fiona and Wingler, Astrid},
TITLE = {Status of Phenological Research Using Sentinel-2 Data: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {2760},
URL = {https://www.mdpi.com/2072-4292/12/17/2760},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing of plant phenology as an indicator of climate change and for mapping land cover has received significant scientific interest in the past two decades. The advancing of spring events, the lengthening of the growing season, the shifting of tree lines, the decreasing sensitivity to warming and the uniformity of spring across elevations are a few of the important indicators of trends in phenology. The Sentinel-2 satellite sensors launched in June 2015 (A) and March 2017 (B), with their high temporal frequency and spatial resolution for improved land mapping missions, have contributed significantly to knowledge on vegetation over the last three years. However, despite the additional red-edge and short wave infra-red (SWIR) bands available on the Sentinel-2 multispectral instruments, with improved vegetation species detection capabilities, there has been very little research on their efficacy to track vegetation cover and its phenology. For example, out of approximately every four papers that analyse normalised difference vegetation index (NDVI) or enhanced vegetation index (EVI) derived from Sentinel-2 imagery, only one mentions either SWIR or the red-edge bands. Despite the short duration that the Sentinel-2 platforms have been operational, they have proved their potential in a wide range of phenological studies of crops, forests, natural grasslands, and other vegetated areas, and in particular through fusion of the data with those from other sensors, e.g., Sentinel-1, Landsat and MODIS. This review paper discusses the current state of vegetation phenology studies based on the first five years of Sentinel-2, their advantages, limitations, and the scope for future developments.},
DOI = {10.3390/rs12172760}
}



@Article{s20174807,
AUTHOR = {Zhang, Dawei and Zheng, Zhonglong and Wang, Tianxiang and He, Yiran},
TITLE = {HROM: Learning High-Resolution Representation and Object-Aware Masks for Visual Object Tracking},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {4807},
URL = {https://www.mdpi.com/1424-8220/20/17/4807},
ISSN = {1424-8220},
ABSTRACT = {Siamese network-based trackers consider tracking as features cross-correlation between the target template and the search region. Therefore, feature representation plays an important role for constructing a high-performance tracker. However, all existing Siamese networks extract the deep but low-resolution features of the entire patch, which is not robust enough to estimate the target bounding box accurately. In this work, to address this issue, we propose a novel high-resolution Siamese network, which connects the high-to-low resolution convolution streams in parallel as well as repeatedly exchanges the information across resolutions to maintain high-resolution representations. The resulting representation is semantically richer and spatially more precise by a simple yet effective multi-scale feature fusion strategy. Moreover, we exploit attention mechanisms to learn object-aware masks for adaptive feature refinement, and use deformable convolution to handle complex geometric transformations. This makes the target more discriminative against distractors and background. Without bells and whistles, extensive experiments on popular tracking benchmarks containing OTB100, UAV123, VOT2018 and LaSOT demonstrate that the proposed tracker achieves state-of-the-art performance and runs in real time, confirming its efficiency and effectiveness.},
DOI = {10.3390/s20174807}
}



@Article{rs12172767,
AUTHOR = {Chen, Yu and Wei, Yongming and Wang, Qinjun and Chen, Fang and Lu, Chunyan and Lei, Shaohua},
TITLE = {Mapping Post-Earthquake Landslide Susceptibility: A U-Net Like Approach},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {2767},
URL = {https://www.mdpi.com/2072-4292/12/17/2767},
ISSN = {2072-4292},
ABSTRACT = {A serious earthquake could trigger thousands of landslides and produce some slopes more sensitive to slide in future. Landslides could threaten human&rsquo;s lives and properties, and thus mapping the post-earthquake landslide susceptibility is very valuable for a rapid response to landslide disasters in terms of relief resource allocation and posterior earthquake reconstruction. Previous researchers have proposed many methods to map landslide susceptibility but seldom considered the spatial structure information of the factors that influence a slide. In this study, we first developed a U-net like model suitable for mapping post-earthquake landslide susceptibility. The post-earthquake high spatial airborne images were used for producing a landslide inventory. Pre-earthquake Landsat TM (Thematic Mapper) images and the influencing factors such as digital elevation model (DEM), slope, aspect, multi-scale topographic position index (mTPI), lithology, fault, road network, streams network, and macroseismic intensity (MI) were prepared as the input layers of the model. Application of the model to the heavy-hit area of the destructive 2008 Wenchuan earthquake resulted in a high validation accuracy (precision 0.77, recall 0.90, F1 score 0.83, and AUC 0.90). The performance of this U-net like model was also compared with those of traditional logistic regression (LR) and support vector machine (SVM) models on both the model area and independent testing area with the former being stronger than the two traditional models. The U-net like model introduced in this paper provides us the inspiration that balancing the environmental influence of a pixel itself and its surrounding pixels to perform a better landslide susceptibility mapping (LSM) task is useful and feasible when using remote sensing and GIS technology.},
DOI = {10.3390/rs12172767}
}



@Article{app10175928,
AUTHOR = {Oheka, Olivier and Tu, Chunling},
TITLE = {Fast and Improved Real-Time Vehicle Anti-Tracking System},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {5928},
URL = {https://www.mdpi.com/2076-3417/10/17/5928},
ISSN = {2076-3417},
ABSTRACT = {Safety on roads and the prevention of accidents have become major problems in the world. Intelligent cars are now a standard in the future of transportation. Drivers will benefit from the increased support for driving assistance. This means relying on the development of integrated systems that can provide real-time information to help drivers make decisions. Therefore, computer vision systems and algorithms are needed to detect and track vehicles. This helps traffic management and driving assistance. This paper focuses on developing a reliable vehicle tracking system to detect the vehicle that is following the host vehicle. The proposed system uses a unique approach consisting of a mixture of background removal techniques, Haar features in a modified Adaboost algorithm in a cascade configuration, and SURF descriptors for tracking. From the camera mounted at the rear of the host vehicle, videos are captured. The results presented in this paper demonstrate the potential and efficiency of the system.},
DOI = {10.3390/app10175928}
}



@Article{sym12091424,
AUTHOR = {Alabdulwahab, Saleh and Moon, BongKyo},
TITLE = {Feature Selection Methods Simultaneously Improve the Detection Accuracy and Model Building Time of Machine Learning Classifiers},
JOURNAL = {Symmetry},
VOLUME = {12},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1424},
URL = {https://www.mdpi.com/2073-8994/12/9/1424},
ISSN = {2073-8994},
ABSTRACT = {The detection accuracy and model building time of machine learning (ML) classifiers are vital aspects for an intrusion detection system (IDS) to predict attacks in real life. Recently, researchers have introduced feature selection methods to increase the detection accuracy and minimize the model building time of a limited number of ML classifiers. Therefore, identifying more ML classifiers with very high detection accuracy and the lowest possible model building time is necessary. In this study, the authors tested six supervised classifiers on a full NSL-KDD training dataset (a benchmark record for Internet traffic) using 10-fold cross-validation in the Weka tool with and without feature selection/reduction methods. The authors aimed to identify more options to outperform and secure classifiers with the highest detection accuracy and lowest model building time. The results show that the feature selection/reduction methods, including the wrapper method in combination with the discretize filter, the filter method in combination with the discretize filter, and the discretize filter, can significantly decrease model building time without compromising detection accuracy. The suggested ML algorithms and feature selection/reduction methods are automated pattern recognition approaches to detect network attacks, which are within the scope of the Symmetry journal.},
DOI = {10.3390/sym12091424}
}



@Article{f11090941,
AUTHOR = {Waśniewski, Adam and Hościło, Agata and Zagajewski, Bogdan and Moukétou-Tarazewicz, Dieudonné},
TITLE = {Assessment of Sentinel-2 Satellite Images and Random Forest Classifier for Rainforest Mapping in Gabon},
JOURNAL = {Forests},
VOLUME = {11},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {941},
URL = {https://www.mdpi.com/1999-4907/11/9/941},
ISSN = {1999-4907},
ABSTRACT = {This study is focused on the assessment of the potential of Sentinel-2 satellite images and the Random Forest classifier for mapping forest cover and forest types in northwest Gabon. The main goal was to investigate the impact of various spectral bands collected by the Sentinel-2 satellite, normalized difference vegetation index (NDVI) and digital elevation model (DEM), and their combination on the accuracy of the classification of forest cover and forest type. Within the study area, five classes of forest type were delineated: semi-evergreen moist forest, lowland forest, freshwater swamp forest, mangroves, and disturbed natural forest. The classification was performed using the Random Forest (RF) classifier. The overall accuracy for the forest cover ranged between 92.6% and 98.5%, whereas for forest type, the accuracy was 83.4 to 97.4%. The highest accuracy for forest cover and forest type classifications were obtained using a combination of spectral bands at spatial resolutions of 10 m and 20 m and DEM. In both cases, the use of the NDVI did not increase the classification accuracy. The DEM was shown to be the most important variable in distinguishing the forest type. Among the Sentinel-2 spectral bands, the red-edge followed by the SWIR contributed the most to the accuracy of the forest type classification. Additionally, the Random Forest model for forest cover classification was successfully transferred from one master image to other images. In contrast, the transferability of the forest type model was more complex, because of the heterogeneity of the forest type and environmental conditions across the study area.},
DOI = {10.3390/f11090941}
}



@Article{drones4030050,
AUTHOR = {Bennett, Mary K. and Younes, Nicolas and Joyce, Karen},
TITLE = {Automating Drone Image Processing to Map Coral Reef Substrates Using Google Earth Engine},
JOURNAL = {Drones},
VOLUME = {4},
YEAR = {2020},
NUMBER = {3},
ARTICLE-NUMBER = {50},
URL = {https://www.mdpi.com/2504-446X/4/3/50},
ISSN = {2504-446X},
ABSTRACT = {While coral reef ecosystems hold immense biological, ecological, and economic value, frequent anthropogenic and environmental disturbances have caused these ecosystems to decline globally. Current coral reef monitoring methods include in situ surveys and analyzing remotely sensed data from satellites. However, in situ methods are often expensive and inconsistent in terms of time and space. High-resolution satellite imagery can also be expensive to acquire and subject to environmental conditions that conceal target features. High-resolution imagery gathered from remotely piloted aircraft systems (RPAS or drones) is an inexpensive alternative; however, processing drone imagery for analysis is time-consuming and complex. This study presents the first semi-automatic workflow for drone image processing with Google Earth Engine (GEE) and free and open source software (FOSS). With this workflow, we processed 230 drone images of Heron Reef, Australia and classified coral, sand, and rock/dead coral substrates with the Random Forest classifier. Our classification achieved an overall accuracy of 86% and mapped live coral cover with 92% accuracy. The presented methods enable efficient processing of drone imagery of any environment and can be useful when processing drone imagery for calibrating and validating satellite imagery.},
DOI = {10.3390/drones4030050}
}



@Article{app10175995,
AUTHOR = {An, Chao and Xie, Changchuan and Meng, Yang and Shi, Xiaofei and Yang, Chao},
TITLE = {Large Deformation Modeling of Wing-Like Structures Based on Support Vector Regression},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {5995},
URL = {https://www.mdpi.com/2076-3417/10/17/5995},
ISSN = {2076-3417},
ABSTRACT = {Large flexible aircrafts produce large deformation during flight, leading to obvious geometric nonlinearities. Large deformation modeling is essential for modern aircraft design. Calculation of large deformation based on a full-order model often carries an unbearable computing burden. The reduced-order model (ROM) can be efficient in calculation but requires lots of test datasets. This study investigates support vector regression (SVR) to build a regression model to calculate the static large deformation of wing-like structures. The correlation coefficient (R) and root mean square error (RMSE) are used to evaluate the performance of the regression models. In contrast to the ROM that has been proposed, the regression model based on SVR requires far fewer training cases, with almost the same accuracy in this research. Meanwhile, comparison with another prediction model built based on random forest regression (RFR) has also been reported. The results reveal that the SVR algorithm has better accuracy on this issue. Finally, ground test results of a real large flexible wing model show that the regression model proposed here reaches a good agreement with measurement data under applied load. This work illustrates that the machine learning algorithm is an efficient and accurate way to predict large deformation of aircrafts.},
DOI = {10.3390/app10175995}
}



@Article{math8091456,
AUTHOR = {Martinez-Soltero, Gabriel and Alanis, Alma Y. and Arana-Daniel, Nancy and Lopez-Franco, Carlos},
TITLE = {Semantic Segmentation for Aerial Mapping},
JOURNAL = {Mathematics},
VOLUME = {8},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1456},
URL = {https://www.mdpi.com/2227-7390/8/9/1456},
ISSN = {2227-7390},
ABSTRACT = {Mobile robots commonly have to traverse rough terrains. One way to find the easiest traversable path is by determining the types of terrains in the environment. The result of this process can be used by the path planning algorithms to find the best traversable path. In this work, we present an approach for terrain classification from aerial images while using a Convolutional Neural Networks at the pixel level. The segmented images can be used in robot mapping and navigation tasks. The performance of two different Convolutional Neural Networks is analyzed in order to choose the best architecture.},
DOI = {10.3390/math8091456}
}



@Article{rs12172823,
AUTHOR = {Xu, Jing-Xian and Ma, Jun and Tang, Ya-Nan and Wu, Wei-Xiong and Shao, Jin-Hua and Wu, Wan-Ben and Wei, Shu-Yun and Liu, Yi-Fei and Wang, Yuan-Chen and Guo, Hai-Qiang},
TITLE = {Estimation of Sugarcane Yield Using a Machine Learning Approach Based on UAV-LiDAR Data},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {2823},
URL = {https://www.mdpi.com/2072-4292/12/17/2823},
ISSN = {2072-4292},
ABSTRACT = {Sugarcane is a multifunctional crop mainly used for sugar and renewable bioenergy production. Accurate and timely estimation of the sugarcane yield before harvest plays a particularly important role in the management of agroecosystems. The rapid development of remote sensing technologies, especially Light Detecting and Ranging (LiDAR), significantly enhances aboveground fresh weight (AFW) estimations. In our study, we evaluated the capability of LiDAR mounted on an Unmanned Aerial Vehicle (UAV) in estimating the sugarcane AFW in Fusui county, Chongzuo city of Guangxi province, China. We measured the height and the fresh weight of sugarcane plants in 105 sampling plots, and eight variables were extracted from the field-based measurements. Six regression algorithms were used to build the sugarcane AFW model: multiple linear regression (MLR), stepwise multiple regression (SMR), generalized linear model (GLM), generalized boosted model (GBM), kernel-based regularized least squares (KRLS), and random forest regression (RFR). The results demonstrate that RFR (R2 = 0.96, RMSE = 1.27 kg m&minus;2) performs better than other models in terms of prediction accuracy. The final fitted sugarcane AFW distribution maps exhibited good agreement with the observed values (R2 = 0.97, RMSE = 1.33 kg m&minus;2). Canopy cover, the distance to the road, and tillage methods all have an impact on sugarcane AFW. Our study provides guidance for calculating the optimum planting density, reducing the negative impact of human activities, and selecting suitable tillage methods in actual cultivation and production.},
DOI = {10.3390/rs12172823}
}



@Article{rs12172833,
AUTHOR = {Arabameri, Alireza and Asadi Nalivan, Omid and Chandra Pal, Subodh and Chakrabortty, Rabin and Saha, Asish and Lee, Saro and Pradhan, Biswajeet and Tien Bui, Dieu},
TITLE = {Novel Machine Learning Approaches for Modelling the Gully Erosion Susceptibility},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {2833},
URL = {https://www.mdpi.com/2072-4292/12/17/2833},
ISSN = {2072-4292},
ABSTRACT = {The extreme form of land degradation caused by the formation of gullies is a major challenge for the sustainability of land resources. This problem is more vulnerable in the arid and semi-arid environment and associated damage to agriculture and allied economic activities. Appropriate modeling of such erosion is therefore needed with optimum accuracy for estimating vulnerable regions and taking appropriate initiatives. The Golestan Dam has faced an acute problem of gully erosion over the last decade and has adversely affected society. Here, the artificial neural network (ANN), general linear model (GLM), maximum entropy (MaxEnt), and support vector machine (SVM) machine learning algorithm with 90/10, 80/20, 70/30, 60/40, and 50/50 random partitioning of training and validation samples was selected purposively for estimating the gully erosion susceptibility. The main objective of this work was to predict the susceptible zone with the maximum possible accuracy. For this purpose, random partitioning approaches were implemented. For this purpose, 20 gully erosion conditioning factors were considered for predicting the susceptible areas by considering the multi-collinearity test. The variance inflation factor (VIF) and tolerance (TOL) limit were considered for multi-collinearity assessment for reducing the error of the models and increase the efficiency of the outcome. The ANN with 50/50 random partitioning of the sample is the most optimal model in this analysis. The area under curve (AUC) values of receiver operating characteristics (ROC) in ANN (50/50) for the training and validation data are 0.918 and 0.868, respectively. The importance of the causative factors was estimated with the help of the Jackknife test, which reveals that the most important factor is the topography position index (TPI). Apart from this, the prioritization of all predicted models was estimated taking into account the training and validation data set, which should help future researchers to select models from this perspective. This type of outcome should help planners and local stakeholders to implement appropriate land and water conservation measures.},
DOI = {10.3390/rs12172833}
}



@Article{electronics9091416,
AUTHOR = {Qamar, Faizan and Siddiqui, Maraj Uddin Ahmed and Hindia, MHD Nour and Hassan, Rosilah and Nguyen, Quang Ngoc},
TITLE = {Issues, Challenges, and Research Trends in Spectrum Management: A Comprehensive Overview and New Vision for Designing 6G Networks},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1416},
URL = {https://www.mdpi.com/2079-9292/9/9/1416},
ISSN = {2079-9292},
ABSTRACT = {With an extensive growth in user demand for high throughput, large capacity, and low latency, the ongoing deployment of Fifth-Generation (5G) systems is continuously exposing the inherent limitations of the system, as compared with its original premises. Such limitations are encouraging researchers worldwide to focus on next-generation 6G wireless systems, which are expected to address the constraints. To meet the above demands, future radio network architecture should be effectively designed to utilize its maximum radio spectrum capacity. It must simultaneously utilize various new techniques and technologies, such as Carrier Aggregation (CA), Cognitive Radio (CR), and small cell-based Heterogeneous Networks (HetNet), high-spectrum access (mmWave), and Massive Multiple-Input-Multiple-Output (M-MIMO), to achieve the desired results. However, the concurrent operations of these techniques in current 5G cellular networks create several spectrum management issues; thus, a comprehensive overview of these emerging technologies is presented in detail in this study. Then, the problems involved in the concurrent operations of various technologies for the spectrum management of the current 5G network are highlighted. The study aims to provide a detailed review of cooperative communication among all the techniques and potential problems associated with the spectrum management that has been addressed with the possible solutions proposed by the latest researches. Future research challenges are also discussed to highlight the necessary steps that can help achieve the desired objectives for designing 6G wireless networks.},
DOI = {10.3390/electronics9091416}
}



@Article{ijgi9090527,
AUTHOR = {Liu, Jiantao and Feng, Quanlong and Wang, Ying and Batsaikhan, Bayartungalag and Gong, Jianhua and Li, Yi and Liu, Chunting and Ma, Yin},
TITLE = {Urban Green Plastic Cover Mapping Based on VHR Remote Sensing Images and a Deep Semi-Supervised Learning Framework},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {9},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {527},
URL = {https://www.mdpi.com/2220-9964/9/9/527},
ISSN = {2220-9964},
ABSTRACT = {With the rapid process of both urban sprawl and urban renewal, large numbers of old buildings have been demolished in China, leading to wide spread construction sites, which could cause severe dust contamination. To alleviate the accompanied dust pollution, green plastic mulch has been widely used by local governments of China. Therefore, timely and accurate mapping of urban green plastic covered regions is of great significance to both urban environmental management and the understanding of urban growth status. However, the complex spatial patterns of the urban landscape make it challenging to accurately identify these areas of green plastic cover. To tackle this issue, we propose a deep semi-supervised learning framework for green plastic cover mapping using very high resolution (VHR) remote sensing imagery. Specifically, a multi-scale deformable convolution neural network (CNN) was exploited to learn representative and discriminative features under complex urban landscapes. Afterwards, a semi-supervised learning strategy was proposed to integrate the limited labeled data and massive unlabeled data for model co-training. Experimental results indicate that the proposed method could accurately identify green plastic-covered regions in Jinan with an overall accuracy (OA) of 91.63%. An ablation study indicated that, compared with supervised learning, the semi-supervised learning strategy in this study could increase the OA by 6.38%. Moreover, the multi-scale deformable CNN outperforms several classic CNN models in the computer vision field. The proposed method is the first attempt to map urban green plastic-covered regions based on deep learning, which could serve as a baseline and useful reference for future research.},
DOI = {10.3390/ijgi9090527}
}



@Article{s20174959,
AUTHOR = {García-Sánchez, José Rafael and Tavera-Mosqueda, Salvador and Silva-Ortigoza, Ramón and Hernández-Guzmán, Victor Manuel and Marciano-Melchor, Magdalena and Rubio, José de Jesús and Ponce-Silva, Mario and Hernández-Bolaños, Miguel and Martínez-Martínez, Jesús},
TITLE = {A Novel Dynamic Three-Level Tracking Controller for Mobile Robots Considering Actuators and Power Stage Subsystems: Experimental Assessment},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {4959},
URL = {https://www.mdpi.com/1424-8220/20/17/4959},
ISSN = {1424-8220},
ABSTRACT = {In order to solve the trajectory tracking task in a wheeled mobile robot (WMR), a dynamic three-level controller is presented in this paper. The controller considers the mechanical structure, actuators, and power stage subsystems. Such a controller is designed as follows: At the high level is a dynamic control for the WMR (differential drive type). At the medium level is a PI current control for the actuators (DC motors). Lastly, at the low level is a differential flatness-based control for the power stage (DC/DC Buck power converters). The feasibility, robustness, and performance in closed-loop of the proposed controller are validated on a DDWMR prototype through Matlab-Simulink, the real-time interface ControlDesk, and a DS1104 board. The obtained results are experimentally assessed with a hierarchical tracking controller, recently reported in literature, that was also designed on the basis of the mechanical structure, actuators, and power stage subsystems. Although both controllers are robust when parametric disturbances are taken into account, the dynamic three-level tracking controller presented in this paper is better than the hierarchical tracking controller reported in literature.},
DOI = {10.3390/s20174959}
}



@Article{s20174962,
AUTHOR = {Liu, Bohan and Liu, Zhaojun and Men, Shaojie and Li, Yongfu and Ding, Zhongjun and He, Jiahao and Zhao, Zhigang},
TITLE = {Underwater Hyperspectral Imaging Technology and Its Applications for Detecting and Mapping the Seafloor: A Review},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {4962},
URL = {https://www.mdpi.com/1424-8220/20/17/4962},
ISSN = {1424-8220},
ABSTRACT = {Common methods of ocean remote sensing and seafloor surveying are mainly carried out by airborne and spaceborne hyperspectral imagers. However, the water column hinders the propagation of sunlight to deeper areas, thus limiting the scope of observation. As an emerging technology, underwater hyperspectral imaging (UHI) is an extension of hyperspectral imaging technology in air conditions, and is undergoing rapid development for applications in shallow and deep-sea environments. It is a close-range, high-resolution approach for detecting and mapping the seafloor. In this paper, we focus on the concepts of UHI technology, covering imaging systems and the correction methods of eliminating the water column&rsquo;s influence. The current applications of UHI, such as deep-sea mineral exploration, benthic habitat mapping, and underwater archaeology, are highlighted to show the potential of this technology. This review can provide an introduction and overview for those working in the field and offer a reference for those searching for literature on UHI technology.},
DOI = {10.3390/s20174962}
}



@Article{app10186147,
AUTHOR = {Li, Jin and Yan, Daifu and Luan, Kuan and Li, Zeyu and Liang, Hong},
TITLE = {Deep Learning-Based Bird’s Nest Detection on Transmission Lines Using UAV Imagery},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {6147},
URL = {https://www.mdpi.com/2076-3417/10/18/6147},
ISSN = {2076-3417},
ABSTRACT = {In order to ensure the safety of transmission lines, the use of unmanned aerial vehicle (UAV) images for automatic object detection has important application prospects, such as the detection of birds&rsquo; nests. The traditional bird&rsquo;s nest detection methods mainly include the study of morphological characteristics of the bird&rsquo;s nest. These methods have poor applicability and low accuracy. In this work, we propose a deep learning-based birds&rsquo; nests automatic detection framework&mdash;region of interest (ROI) mining faster region-based convolutional neural networks (RCNN). First, the prior dimensions of anchors are obtained by using k-means clustering to improve the accuracy of coordinate boxes generation. Second, in order to balance the number of foreground and background samples in the training process, the focal loss function is introduced in the region proposal network (RPN) classification stage. Finally, the ROI mining module is added to solve the class imbalance problem in the classification stage, combined with the characteristics of difficult-to-classify bird&rsquo;s nest samples in the UAV images. After parameter optimization and experimental verification, the deep learning-based bird&rsquo;s nest automatic detection framework proposed in this work achieves high detection accuracy. In addition, the mean average precision (mAP) and formula 1 (F1) score of the proposed method are higher than the original faster RCNN and cascade RCNN. Our comparative analysis verifies the effectiveness of the proposed method.},
DOI = {10.3390/app10186147}
}



@Article{math8091499,
AUTHOR = {Tran, Huu Khoa and Chiou, Juing-Shian and Dang, Viet-Hung},
TITLE = {New Fusion Algorithm-Reinforced Pilot Control for an Agricultural Tricopter UAV},
JOURNAL = {Mathematics},
VOLUME = {8},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1499},
URL = {https://www.mdpi.com/2227-7390/8/9/1499},
ISSN = {2227-7390},
ABSTRACT = {Currently, fuzzy proportional integral derivative (PID) controller schemes, which include simplified fuzzy reasoning decision methodologies and PID parameters, are broadly and efficaciously practiced in various fields from industrial applications, military service, to rescue operations, civilian information and also horticultural observation and agricultural surveillance. A fusion particle swarm optimization (PSO)&ndash;evolutionary programming (EP) algorithm, which is an improved version of the stochastic optimization strategy PSO, was presented for designing and optimizing controller gains in this study. The mathematical calculations of this study include the reproduction of EP with PSO. By minimizing the integral of the absolute error (IAE) criterion that is used for estimating the system response as a fitness function, the obtained integrated design of the fusion PSO&ndash;EP algorithm generated and updated the new elite parameters for proposed controller schemes. This progression was used for the complicated non-linear systems of the attitude-control pilot models of a tricopter unmanned aerial vehicle (UAV) to demonstrate an improvement on the performance in terms of rapid response, precision, reliability, and stability.},
DOI = {10.3390/math8091499}
}



@Article{app10186151,
AUTHOR = {Hung, Sheng-Chieh and Wu, Hui-Ching and Tseng, Ming-Hseng},
TITLE = {Remote Sensing Scene Classification and Explanation Using RSSCNet and LIME},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {6151},
URL = {https://www.mdpi.com/2076-3417/10/18/6151},
ISSN = {2076-3417},
ABSTRACT = {Classification is needed in disaster investigation, traffic control, and land-use resource management. How to quickly and accurately classify such remote sensing imagery has become a popular research topic. However, the application of large, deep neural network models for the training of classifiers in the hope of obtaining good classification results is often very time-consuming. In this study, a new CNN (convolutional neutral networks) architecture, i.e., RSSCNet (remote sensing scene classification network), with high generalization capability was designed. Moreover, a two-stage cyclical learning rate policy and the no-freezing transfer learning method were developed to speed up model training and enhance accuracy. In addition, the manifold learning t-SNE (t-distributed stochastic neighbor embedding) algorithm was used to verify the effectiveness of the proposed model, and the LIME (local interpretable model, agnostic explanation) algorithm was applied to improve the results in cases where the model made wrong predictions. Comparing the results of three publicly available datasets in this study with those obtained in previous studies, the experimental results show that the model and method proposed in this paper can achieve better scene classification more quickly and more efficiently.},
DOI = {10.3390/app10186151}
}



@Article{s20185055,
AUTHOR = {Guo, Yahui and Wang, Hanxi and Wu, Zhaofei and Wang, Shuxin and Sun, Hongyong and Senthilnath, J. and Wang, Jingzhe and Robin Bryant, Christopher and Fu, Yongshuo},
TITLE = {Modified Red Blue Vegetation Index for Chlorophyll Estimation and Yield Prediction of Maize from Visible Images Captured by UAV},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5055},
URL = {https://www.mdpi.com/1424-8220/20/18/5055},
ISSN = {1424-8220},
ABSTRACT = {The vegetation index (VI) has been successfully used to monitor the growth and to predict the yield of agricultural crops. In this paper, a long-term observation was conducted for the yield prediction of maize using an unmanned aerial vehicle (UAV) and estimations of chlorophyll contents using SPAD-502. A new vegetation index termed as modified red blue VI (MRBVI) was developed to monitor the growth and to predict the yields of maize by establishing relationships between MRBVI- and SPAD-502-based chlorophyll contents. The coefficients of determination (R2s) were 0.462 and 0.570 in chlorophyll contents&rsquo; estimations and yield predictions using MRBVI, and the results were relatively better than the results from the seven other commonly used VI approaches. All VIs during the different growth stages of maize were calculated and compared with the measured values of chlorophyll contents directly, and the relative error (RE) of MRBVI is the lowest at 0.355. Further, machine learning (ML) methods such as the backpropagation neural network model (BP), support vector machine (SVM), random forest (RF), and extreme learning machine (ELM) were adopted for predicting the yields of maize. All VIs calculated for each image captured during important phenological stages of maize were set as independent variables and the corresponding yields of each plot were defined as dependent variables. The ML models used the leave one out method (LOO), where the root mean square errors (RMSEs) were 2.157, 1.099, 1.146, and 1.698 (g/hundred grain weight) for BP, SVM, RF, and ELM. The mean absolute errors (MAEs) were 1.739, 0.886, 0.925, and 1.356 (g/hundred grain weight) for BP, SVM, RF, and ELM, respectively. Thus, the SVM method performed better in predicting the yields of maize than the other ML methods. Therefore, it is strongly suggested that the MRBVI calculated from images acquired at different growth stages integrated with advanced ML methods should be used for agricultural- and ecological-related chlorophyll estimation and yield predictions.},
DOI = {10.3390/s20185055}
}



@Article{su12187303,
AUTHOR = {Fabbri, Carolina and Napoli, Marco and Verdi, Leonardo and Mancini, Marco and Orlandini, Simone and Dalla Marta, Anna},
TITLE = {A Sustainability Assessment of the Greenseeker N Management Tool: A Lysimetric Experiment on Barley},
JOURNAL = {Sustainability},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {7303},
URL = {https://www.mdpi.com/2071-1050/12/18/7303},
ISSN = {2071-1050},
ABSTRACT = {A preliminary study was conducted to analyze the sustainability of barley production through: (i) investigating sensor-based nitrogen (N) application on barley performance, compared with conventional N management (CT); (ii) assessing the potential of the Normalized Difference Vegetation Index (NDVI) at different growth stages for within-season predictions of crop parameters; and (iii) evaluating sensor-based fertilization benefits in the form of greenhouse gasses mitigation. Barley was grown under CT, sensor-based management (RF) and with no N fertilization (Control). NDVI measurements and RF fertilization were performed using a GreenSeeker&trade; 505 hand-held optical sensor. Gas emissions were measured using a static chamber method with a portable gas analyzer. Results showed that barley yield was not statistically different under RF and CF, while they both differed significantly from Control. Highly significant positive correlations were observed between NDVI and production parameters at harvesting from the middle of stem elongation to the medium milk stage across treatments. Our findings suggest that RF is able to decrease CO2 emission in comparison with CF. The relationship between N fertilization and CH4 emission showed high variability. These preliminary results provide an indication of the benefits achieved using a simple proximal sensing methodology to support N fertilization.},
DOI = {10.3390/su12187303}
}



@Article{electronics9091456,
AUTHOR = {Ismail, Rifky and Taqriban, Rilo Berdin and Ariyanto, Mochammad and Atmaja, Ali Tri and Sugiyanto and Caesarendra, Wahyu and Glowacz, Adam and Irfan, Muhammad and Glowacz, Witold},
TITLE = {Affordable and Faster Transradial Prosthetic Socket Production Using Photogrammetry and 3D Printing},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1456},
URL = {https://www.mdpi.com/2079-9292/9/9/1456},
ISSN = {2079-9292},
ABSTRACT = {This study aims to invent a new, low-cost, and faster method of prosthetic socket fabrication, especially in Indonesia. In this paper, the photogrammetry with the 3D printing method is introduced as the new applicative way for transradial prosthetic making. Photogrammetry is used to retrieve a 3D model of the amputated hand stump using a digital camera. A digital camera is used for photogrammetry technique and the resulting 3D model is printed using a circular 3D printer with Polylactic acid (PLA) material. The conventional casting socket fabrication method was also conducted in this study as a comparison. Both prosthetic sockets were analyzed for usability, and sectional area conformities to determine the size deviation using the image processing method. This study concludes that the manufacturing of transradial prosthetic sockets incorporating the photogrammetry technique reduces the total man-hour production. Based on the results, it can be implied that the photogrammetry technique is a more efficient and economical method compared to the conventional casting method. The 3D printed socket resulting from the photogrammetry method has a 5&ndash;19% area deviation to the casting socket but it is still preferable and adjustable for the transradial amputee when applied to the stump of the remaining hand.},
DOI = {10.3390/electronics9091456}
}



@Article{f11090969,
AUTHOR = {Abad-Segura, Emilio and González-Zamar, Mariana-Daniela and Vázquez-Cano, Esteban and López-Meneses, Eloy},
TITLE = {Remote Sensing Applied in Forest Management to Optimize Ecosystem Services: Advances in Research},
JOURNAL = {Forests},
VOLUME = {11},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {969},
URL = {https://www.mdpi.com/1999-4907/11/9/969},
ISSN = {1999-4907},
ABSTRACT = {Research Highlights: the wide variety of multispectral sensors that currently exist make it possible to improve the study of forest systems and ecosystem services. Background and Objectives: this study aims to analyze the current usefulness of remote sensing in forest management and ecosystem services sciences, and to identify future lines of research on these issues worldwide during the period 1976&ndash;2019. Materials and Methods: a bibliometric technique is applied to 2066 articles published between 1976 and 2019 on these topics to find findings on scientific production and key subject areas. Results: scientific production has increased annually, so that in the last five years, 50.34% of all articles have been published. The thematic areas in which more articles were linked were environmental science, agricultural, and biological sciences, and earth and planetary sciences. Seven lines of research have been identified that generate contributions on this topic. In addition, the analysis of the relevance of the keywords has detected the ten main future directions of research. The growing worldwide trend of scientific production shows interest in developing aspects of this field of study. Conclusions: this study contributes to the academic, scientific, and institutional discussion to improve decision-making, and proposes new scenarios and uses of this technology to improve the administration and management of forest resources.},
DOI = {10.3390/f11090969}
}



@Article{electronics9091459,
AUTHOR = {Kundid Vasić, Mirela and Papić, Vladan},
TITLE = {Multimodel Deep Learning for Person Detection in Aerial Images},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1459},
URL = {https://www.mdpi.com/2079-9292/9/9/1459},
ISSN = {2079-9292},
ABSTRACT = {In this paper, we propose a novel method for person detection in aerial images of nonurban terrain gathered by an Unmanned Aerial Vehicle (UAV), which plays an important role in Search And Rescue (SAR) missions. The UAV in SAR operations contributes significantly due to the ability to survey a larger geographical area from an aerial viewpoint. Because of the high altitude of recording, the object of interest (person) covers a small part of an image (around 0.1%), which makes this task quite challenging. To address this problem, a multimodel deep learning approach is proposed. The solution consists of two different convolutional neural networks in region proposal, as well as in the classification stage. Additionally, contextual information is used in the classification stage in order to improve the detection results. Experimental results tested on the HERIDAL dataset achieved precision of 68.89% and a recall of 94.65%, which is better than current state-of-the-art methods used for person detection in similar scenarios. Consequently, it may be concluded that this approach is suitable for usage as an auxiliary method in real SAR operations.},
DOI = {10.3390/electronics9091459}
}



@Article{s20185073,
AUTHOR = {Khan, Khalil and Albattah, Waleed and Khan, Rehan Ullah and Qamar, Ali Mustafa and Nayab, Durre},
TITLE = {Advances and Trends in Real Time Visual Crowd Analysis},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5073},
URL = {https://www.mdpi.com/1424-8220/20/18/5073},
ISSN = {1424-8220},
ABSTRACT = {Real time crowd analysis represents an active area of research within the computer vision community in general and scene analysis in particular. Over the last 10 years, various methods for crowd management in real time scenario have received immense attention due to large scale applications in people counting, public events management, disaster management, safety monitoring an so on. Although many sophisticated algorithms have been developed to address the task; crowd management in real time conditions is still a challenging problem being completely solved, particularly in wild and unconstrained conditions. In the proposed paper, we present a detailed review of crowd analysis and management, focusing on state-of-the-art methods for both controlled and unconstrained conditions. The paper illustrates both the advantages and disadvantages of state-of-the-art methods. The methods presented comprise the seminal research works on crowd management, and monitoring and then culminating state-of-the-art methods of the newly introduced deep learning methods. Comparison of the previous methods is presented, with a detailed discussion of the direction for future research work. We believe this review article will contribute to various application domains and will also augment the knowledge of the crowd analysis within the research community.},
DOI = {10.3390/s20185073}
}



@Article{rs12182894,
AUTHOR = {John, Aji and Ong, Justin and Theobald, Elli J. and Olden, Julian D. and Tan, Amanda and HilleRisLambers, Janneke},
TITLE = {Detecting Montane Flowering Phenology with CubeSat Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {2894},
URL = {https://www.mdpi.com/2072-4292/12/18/2894},
ISSN = {2072-4292},
ABSTRACT = {Shifts in wildflower phenology in response to climate change are well documented in the scientific literature. The majority of studies have revealed phenological shifts using in-situ observations, some aided by citizen science efforts (e.g., National Phenology Network). Such investigations have been instrumental in quantifying phenological shifts but are challenged by the fact that limited resources often make it difficult to gather observations over large spatial scales and long-time frames. However, recent advances in finer scale satellite imagery may provide new opportunities to detect changes in phenology. These approaches have documented plot level changes in vegetation characteristics and leafing phenology, but it remains unclear whether they can also detect flowering in natural environments. Here, we test whether fine-resolution imagery (&lt;10 m) can detect flowering and whether combining multiple sources of imagery improves the detection process. Examining alpine wildflowers at Mt. Rainier National Park (MORA), we found that high-resolution Random Forest (RF) classification from 3-m resolution PlanetScope (from Planet Labs) imagery was able to delineate the flowering season captured by ground-based phenological surveys with an accuracy of 70% (Cohen&rsquo;s kappa = 0.25). We then combined PlanetScope data with coarser resolution but higher quality imagery from Sentinel and Landsat satellites (10-m Sentinel and 30-m Landsat), resulting in higher accuracy predictions (accuracy = 77%, Cohen&rsquo;s kappa = 0.39). The model was also able to identify the timing of peak flowering in a particularly warm year (2015), despite being calibrated on normal climate years. Our results suggest PlanetScope imagery holds utility in global change ecology where temporal frequency is important. Additionally, we suggest that combining imagery may provide a new approach to cross-calibrate sensors to account for radiometric irregularity inherent in fine resolution PlanetScope imagery. The development of this approach for wildflower phenology predictions provides new possibilities to monitor climate change effects on flowering communities at broader spatiotemporal scales. In protected and tourist areas where the flowering season draws large numbers of visitors, such as Mt. Rainier National Park, the modeling framework presented here could be a useful tool to manage and prioritize park resources.},
DOI = {10.3390/rs12182894}
}



@Article{telecom1020010,
AUTHOR = {Karavolos, Michail and Nomikos, Nikolaos and Vouyioukas, Demosthenes},
TITLE = {Enhanced Integrated Satellite-Terrestrial NOMA with Cooperative Device-to-Device Communication},
JOURNAL = {Telecom},
VOLUME = {1},
YEAR = {2020},
NUMBER = {2},
PAGES = {126--149},
URL = {https://www.mdpi.com/2673-4001/1/2/10},
ISSN = {2673-4001},
ABSTRACT = {The currently deployed terrestrial wireless networks experience difficulties while coping with the massive connectivity demands of coexisting users and devices. The addition of satellite segments has been proposed as a viable way of providing improved coverage and capacity, leading to the formation of integrated satellite-terrestrial networks. In such topologies, non-orthogonal multiple access (NOMA) can further enhance the efficient use of wireless resources by simultaneously serving multiple users. In this paper, an integrated satellite-terrestrial NOMA network is studied where cooperation between ground users is allowed, following the device-to-device (D2D) paradigm. More specifically, the proposed satellite NOMA cooperative (SANOCO) D2D scheme optimally selects pairs of users, by considering the channel conditions of the satellite and the terrestrial D2D links. In SANOCO-D2D users are served through NOMA in the satellite link, and then, if the weak user fails to decode its signal, terrestrial D2D communication is activated to maintain the total sum rate of the system. Comparisons with conventional orthogonal multiple access (OMA) and an alternative NOMA optimal user pairing scheme show that significant sum rate and spectral efficiency gains can be harvested through SANOCO-D2D under varying channel conditions and terrestrial D2D bandwidth.},
DOI = {10.3390/telecom1020010}
}



@Article{app10186210,
AUTHOR = {Zheng, Ruihao and Xiong, Chen and Deng, Xiangbin and Li, Qiangsheng and Li, Yi},
TITLE = {Assessment of Earthquake Destructive Power to Structures Based on Machine Learning Methods},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {6210},
URL = {https://www.mdpi.com/2076-3417/10/18/6210},
ISSN = {2076-3417},
ABSTRACT = {This study presents a machine learning-based method for the destructive power assessment of earthquake to structures. First, the analysis procedure of the method is presented, and the backpropagation neural network (BPNN) and convolutional neural network (CNN) are used as the machine learning algorithms. Second, the optimized BPNN architecture is obtained by discussing the influence of a different number of hidden layers and nodes. Third, the CNN architecture is proposed based on several classical deep learning networks. To build the machine learning models, 50,570 time-history analysis results of a structural system subjected to different ground motions are used as training, validation, and test samples. The results of the BPNN indicate that the features extraction method based on the short-time Fourier transform (STFT) can well reflect the frequency-/time-domain characteristics of ground motions. The results of the CNN indicate that the CNN exhibits better accuracy (R2 = 0.8737) compared with that of the BPNN (R2 = 0.6784). Furthermore, the CNN model exhibits remarkable computational efficiency, the prediction of 1000 structures based on the CNN model takes 0.762 s, while 507.81 s are required for the conventional time-history analysis (THA)-based simulation. Feature visualization of different layers of the CNN reveals that the shallow to deep layers of the CNN can extract the high to low-frequency features of ground motions. The proposed method can assist in the fast prediction of engineering demand parameters of large-number structures, which facilitates the damage or loss assessments of regional structures for timely emergency response and disaster relief after earthquake.},
DOI = {10.3390/app10186210}
}



@Article{hydrology7030065,
AUTHOR = {Rozos, Evangelos and Dimitriadis, Panayiotis and Mazi, Katerina and Lykoudis, Spyridon and Koussis, Antonis},
TITLE = {On the Uncertainty of the Image Velocimetry Method Parameters},
JOURNAL = {Hydrology},
VOLUME = {7},
YEAR = {2020},
NUMBER = {3},
ARTICLE-NUMBER = {65},
URL = {https://www.mdpi.com/2306-5338/7/3/65},
ISSN = {2306-5338},
ABSTRACT = {Image velocimetry is a popular remote sensing method mainly because of the very modest cost of the necessary equipment. However, image velocimetry methods employ parameters that require high expertise to select appropriate values in order to obtain accurate surface flow velocity estimations. This introduces considerations regarding the subjectivity introduced in the definition of the parameter values and its impact on the estimated surface velocity. Alternatively, a statistical approach can be employed instead of directly selecting a value for each image velocimetry parameter. First, probability distribution should be defined for each model parameter, and then Monte Carlo simulations should be employed. In this paper, we demonstrate how this statistical approach can be used to simultaneously produce the confidence intervals of the estimated surface velocity, reduce the uncertainty of some parameters (more specifically, the size of the interrogation area), and reduce the subjectivity. Since image velocimetry algorithms are CPU-intensive, an alternative random number generator that allows obtaining the confidence intervals with a limited number of iterations is suggested. The case study indicated that if the statistical approach is applied diligently, one can achieve the previously mentioned threefold objective.},
DOI = {10.3390/hydrology7030065}
}



@Article{s20185130,
AUTHOR = {Guo, Yahui and Yin, Guodong and Sun, Hongyong and Wang, Hanxi and Chen, Shouzhi and Senthilnath, J. and Wang, Jingzhe and Fu, Yongshuo},
TITLE = {Scaling Effects on Chlorophyll Content Estimations with RGB Camera Mounted on a UAV Platform Using Machine-Learning Methods},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5130},
URL = {https://www.mdpi.com/1424-8220/20/18/5130},
ISSN = {1424-8220},
ABSTRACT = {Timely monitoring and precise estimation of the leaf chlorophyll contents of maize are crucial for agricultural practices. The scale effects are very important as the calculated vegetation index (VI) were crucial for the quantitative remote sensing. In this study, the scale effects were investigated by analyzing the linear relationships between VI calculated from red&ndash;green&ndash;blue (RGB) images from unmanned aerial vehicles (UAV) and ground leaf chlorophyll contents of maize measured using SPAD-502. The scale impacts were assessed by applying different flight altitudes and the highest coefficient of determination (R2) can reach 0.85. We found that the VI from images acquired from flight altitude of 50 m was better to estimate the leaf chlorophyll contents using the DJI UAV platform with this specific camera (5472 &times; 3648 pixels). Moreover, three machine-learning (ML) methods including backpropagation neural network (BP), support vector machine (SVM), and random forest (RF) were applied for the grid-based chlorophyll content estimation based on the common VI. The average values of the root mean square error (RMSE) of chlorophyll content estimations using ML methods were 3.85, 3.11, and 2.90 for BP, SVM, and RF, respectively. Similarly, the mean absolute error (MAE) were 2.947, 2.460, and 2.389, for BP, SVM, and RF, respectively. Thus, the ML methods had relative high precision in chlorophyll content estimations using VI; in particular, the RF performed better than BP and SVM. Our findings suggest that the integrated ML methods with RGB images of this camera acquired at a flight altitude of 50 m (spatial resolution 0.018 m) can be perfectly applied for estimations of leaf chlorophyll content in agriculture.},
DOI = {10.3390/s20185130}
}



@Article{pr8091123,
AUTHOR = {Park, You-Jin and Fan, Shu-Kai S. and Hsu, Chia-Yu},
TITLE = {A Review on Fault Detection and Process Diagnostics in Industrial Processes},
JOURNAL = {Processes},
VOLUME = {8},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1123},
URL = {https://www.mdpi.com/2227-9717/8/9/1123},
ISSN = {2227-9717},
ABSTRACT = {The main roles of fault detection and diagnosis (FDD) for industrial processes are to make an effective indicator which can identify faulty status of a process and then to take a proper action against a future failure or unfavorable accidents. In order to enhance many process performances (e.g., quality and throughput), FDD has attracted great attention from various industrial sectors. Many traditional FDD techniques have been developed for checking the existence of a trend or pattern in the process or whether a certain process variable behaves normally or not. However, they might fail to produce several hidden characteristics of the process or fail to discover the faults in processes due to underlying process dynamics. In this paper, we present current research and developments of FDD approaches for process monitoring as well as a broad literature review of many useful FDD approaches.},
DOI = {10.3390/pr8091123}
}



@Article{s20185135,
AUTHOR = {Chen, Xueshen and Mao, Yuanyang and Ma, Xu and Qi, Long},
TITLE = {A Tactile Method for Rice Plant Recognition Based on Machine Learning},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5135},
URL = {https://www.mdpi.com/1424-8220/20/18/5135},
ISSN = {1424-8220},
ABSTRACT = {Accurate and real-time recognition of rice plants is the premise underlying the implementation of precise weed control. However, achieving desired results in paddy fields using the traditional visual method is difficult due to the occlusion of rice leaves and the interference of weeds. The objective of this study was to develop a novel rice plant recognition sensor based on a tactile method which acquires tactile information through physical touch. The tactile sensor would be mounted on the paddy field weeder to provide identification information for the actuator. First, a flexible gasbag filled with air was developed, where vibration features produced by tactile and sliding feedback were acquired when this apparatus touched rice plants or weeds, allowing the subtle vibration data with identification features to be reflected through the voltage value of an air-pressured sensor mounted inside the gasbag. Second, voltage data were preprocessed by three algorithms to optimize recognition features, including dimensional feature, dimensionless feature, and fractal dimension. The three types of features were used to train and test a neural network classifier. To maximize classification accuracy, an optimum set of features (b (variance), f (kurtosis), h (waveform factor), l (box dimension), and m (Hurst exponent)) were selected using a genetic algorithm. Finally, the feature-optimized classifier was trained, and the actual performances of the sensor at different contact positions were tested. Experimental results showed that the recognition rates of the end, middle, and root of the sensor were 90.67%, 98%, and 96% respectively. A tactile-based method with intelligence could produce high accuracy for rice plant recognition, as demonstrated in this study.},
DOI = {10.3390/s20185135}
}



@Article{app10186259,
AUTHOR = {Kozłowski, Tomasz and Wodecki, Jacek and Zimroz, Radosław and Błażej, Ryszard and Hardygóra, Monika},
TITLE = {A Diagnostics of Conveyor Belt Splices},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {6259},
URL = {https://www.mdpi.com/2076-3417/10/18/6259},
ISSN = {2076-3417},
ABSTRACT = {Damage detection in complex mechanical structures is important for cost-effective and safe operation. Conveyor belts with steel cords are used for bulk material transport in mining companies. Due to harsh environmental conditions, both covers and cords are subjected to damage. As lengths of conveyors may vary from dozens of meters to kilometers, a belt loop consists of many connected belt pieces. Thus, the condition of splices between belt pieces is also critical. For both steel cord damage/wear detection and splice condition evaluations the NDT techniques based on magnetic field measurement and variability analysis are used. To obtain appropriate resolution, multi-channel data are collected. Here we propose a pre-processing technique developed for signal synchronization for biased splices data. The biased splices mean a phase shift between signals from a multi-channel sensor due to the design technology of the splice. As the quality of the splice is related to the appropriate precision of splice production, splice evaluation is defined as a similarity analysis of each signal with respect to the estimated pattern. Due to the mentioned phase shift, signals should be "synchronized" first, before final analysis. In industrial conditions, many factors may influence the signal shape. Thus, the problem of automated synchronization by shifting the signals may be defined as a multidimensional optimization problem. Here, we proposed to use a genetic algorithm with an algorithmically simple cost function for that purpose. In this paper, the authors propose an automated procedure applied to real measurement data and final results. A multidimensional optimization has been compared to simple signal shifting according to several criteria, and GA-based results were the best.},
DOI = {10.3390/app10186259}
}



@Article{sym12091486,
AUTHOR = {Tarjan, Laslo and Šenk, Ivana and Erić Obućina, Jelena and Stankovski, Stevan and Ostojić, Gordana},
TITLE = {Extending Legacy Industrial Machines by a Low-Cost Easy-to-Use IoT Module for Data Acquisition},
JOURNAL = {Symmetry},
VOLUME = {12},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1486},
URL = {https://www.mdpi.com/2073-8994/12/9/1486},
ISSN = {2073-8994},
ABSTRACT = {Industry 4.0 is a paradigm that enhances industrial automation systems with the recent advances in the domain of the Internet of Things (IoT), gaining new possibilities and providing new services. Traditional industrial machines do not have IoT capabilities, and in order to integrate such a machine into Industry 4.0, there is a need for an intermediary device or system that communicates with the machine through its supported communication interfaces and protocols and forwards the communication to the global network. This paper presents the development and experimental validation of a low-cost hardware module that can easily integrate the machine&rsquo;s existing control unit into the IoT and enable synchronization of the measurements and states of the variables of the machine and its environment with a cloud server. The developed module is universal, can connect to any control unit that is able to communicate through basic RS232 serial communication, and does not require the control unit to have any higher level communication protocol implemented. On the other end, the presented solution uses a dedicated smartphone application to provide remote monitoring and control of the machine through the cloud by using the synchronized variable states, as well as further possibilities for storing, processing, and analyzing the historical data from the system. The developed solution was experimentally validated on an experimental setup consisting of a conveyor belt driven by a three-phase asynchronous electromotor controlled by a programmable logic controller through a variable-frequency drive.},
DOI = {10.3390/sym12091486}
}



@Article{rs12182929,
AUTHOR = {Gao, Jinlong and Liu, Jie and Liang, Tiangang and Hou, Mengjing and Ge, Jing and Feng, Qisheng and Wu, Caixia and Li, Wenlong},
TITLE = {Mapping the Forage Nitrogen-Phosphorus Ratio Based on Sentinel-2 MSI Data and a Random Forest Algorithm in an Alpine Grassland Ecosystem of the Tibetan Plateau},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {2929},
URL = {https://www.mdpi.com/2072-4292/12/18/2929},
ISSN = {2072-4292},
ABSTRACT = {Nondestructive and accurate estimating of the forage nitrogen&ndash;phosphorus (N:P) ratio is conducive to the real-time diagnosis of nutrient limitation and the formulation of a management scheme during the growth and development of forage. New-generation high-resolution remote sensors equipped with strategic red-edge wavebands offer opportunities and challenges for estimating and mapping forage N:P ratio in support of the sustainable utilization of alpine grassland resources. This study aims to detect the forage N:P ratio as an ecological indicator of grassland nutrient content by employing Sentinel-2 multispectral instrument (MSI) data and a random forest (RF) algorithm. The results showed that the estimation accuracy (R2) of the forage N:P ratio model established by combining the optimized spectral bands and vegetation indices (VIs) is 0.49 and 0.59 in the vigorous growth period (July) and the senescing period (November) of forage, respectively. Moreover, Sentinel-2 MSI B9 and B12 bands contributed greatly to the estimation of the forage N:P ratio, and the VIs (RECI2) constructed by B5 and B8A bands performed well in the estimation of the forage N:P ratio. Overall, it is promising to map the spatial distribution of the forage N:P ratio in alpine grassland using Sentinel-2 MSI data at regional scales. This study will be potentially beneficial in implementing precise positioning of vegetation nutrient deficiency and scientific fertilization management of grassland.},
DOI = {10.3390/rs12182929}
}



@Article{rs12182934,
AUTHOR = {Xu, Jin and Quackenbush, Lindi J. and Volk, Timothy A. and Im, Jungho},
TITLE = {Forest and Crop Leaf Area Index Estimation Using Remote Sensing: Research Trends and Future Directions},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {2934},
URL = {https://www.mdpi.com/2072-4292/12/18/2934},
ISSN = {2072-4292},
ABSTRACT = {Leaf area index (LAI) is an important vegetation leaf structure parameter in forest and agricultural ecosystems. Remote sensing techniques can provide an effective alternative to field-based observation of LAI. Differences in canopy structure result in different sensor types (active or passive), platforms (terrestrial, airborne, or satellite), and models being appropriate for the LAI estimation of forest and agricultural systems. This study reviews the application of remote sensing-based approaches across different system configurations (passive, active, and multisource sensors on different collection platforms) that are used to estimate forest and crop LAI and explores uncertainty analysis in LAI estimation. A comparison of the difference in LAI estimation for forest and agricultural applications given the different structure of these ecosystems is presented, particularly as this relates to spatial scale. The ease of use of empirical models supports these as the preferred choice for forest and crop LAI estimation. However, performance variation among different empirical models for forest and crop LAI estimation limits the broad application of specific models. The development of models that facilitate the strategic incorporation of local physiology and biochemistry parameters for specific forests and crop growth stages from various temperature zones could improve the accuracy of LAI estimation models and help develop models that can be applied more broadly. In terms of scale issues, both spectral and spatial scales impact the estimation of LAI. Exploration of the quantitative relationship between scales of data from different sensors could help forest and crop managers more appropriately and effectively apply different data sources. Uncertainty coming from various sources results in reduced accuracy in estimating LAI. While Bayesian approaches have proven effective to quantify LAI estimation uncertainty based on the uncertainty of model inputs, there is still a need to quantify uncertainty from remote sensing data source, ground measurements and related environmental factors to mitigate the impacts of model uncertainty and improve LAI estimation.},
DOI = {10.3390/rs12182934}
}



@Article{jimaging6090094,
AUTHOR = {Trujillo-Jiménez, Magda Alexandra and Navarro, Pablo and Pazos, Bruno and Morales, Leonardo and Ramallo, Virginia and Paschetta, Carolina and De Azevedo, Soledad and Ruderman, Anahí and Pérez, Orlando and Delrieux, Claudio and Gonzalez-José, Rolando},
TITLE = {body2vec: 3D Point Cloud Reconstruction for Precise Anthropometry with Handheld Devices},
JOURNAL = {Journal of Imaging},
VOLUME = {6},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {94},
URL = {https://www.mdpi.com/2313-433X/6/9/94},
ISSN = {2313-433X},
ABSTRACT = {Current point cloud extraction methods based on photogrammetry generate large amounts of spurious detections that hamper useful 3D mesh reconstructions or, even worse, the possibility of adequate measurements. Moreover, noise removal methods for point clouds are complex, slow and incapable to cope with semantic noise. In this work, we present body2vec, a model-based body segmentation tool that uses a specifically trained Neural Network architecture. Body2vec is capable to perform human body point cloud reconstruction from videos taken on hand-held devices (smartphones or tablets), achieving high quality anthropometric measurements. The main contribution of the proposed workflow is to perform a background removal step, thus avoiding the spurious points generation that is usual in photogrammetric reconstruction. A group of 60 persons were taped with a smartphone, and the corresponding point clouds were obtained automatically with standard photogrammetric methods. We used as a 3D silver standard the clean meshes obtained at the same time with LiDAR sensors post-processed and noise-filtered by expert anthropological biologists. Finally, we used as gold standard anthropometric measurements of the waist and hip of the same people, taken by expert anthropometrists. Applying our method to the raw videos significantly enhanced the quality of the results of the point cloud as compared with the LiDAR-based mesh, and of the anthropometric measurements as compared with the actual hip and waist perimeter measured by the anthropometrists. In both contexts, the resulting quality of body2vec is equivalent to the LiDAR reconstruction.},
DOI = {10.3390/jimaging6090094}
}



@Article{s20185204,
AUTHOR = {Nkemeni, Valery and Mieyeville, Fabien and Tsafack, Pierre},
TITLE = {A Distributed Computing Solution Based on Distributed Kalman Filter for Leak Detection in WSN-Based Water Pipeline Monitoring},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5204},
URL = {https://www.mdpi.com/1424-8220/20/18/5204},
ISSN = {1424-8220},
ABSTRACT = {Wireless Sensor Network (WSN) applications that favor more local computations and less communication can contribute to solving the problem of high power consumption and performance issues plaguing most centralized WSN applications. In this study, we present a fully distributed solution, where leaks are detected in a water distribution network via only local collaborations between a sensor node and its close neighbors, without the need for long-distance transmissions via several hops to a centralized fusion center. A complete approach that includes the design, simulation, and physical measurements, showing how distributed computing implemented via a distributed Kalman filter improves the accuracy of leak detection and the power consumption is presented. The results from the physical implementation show that distributed data fusion increases the accuracy of leak detection while preserving WSN lifetime.},
DOI = {10.3390/s20185204}
}



@Article{polym12092071,
AUTHOR = {Bleszynski, Monika and Mann, Shaun and Kumosa, Maciej},
TITLE = {Visualizing Polymer Damage Using Hyperspectral Imaging},
JOURNAL = {Polymers},
VOLUME = {12},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {2071},
URL = {https://www.mdpi.com/2073-4360/12/9/2071},
PubMedID = {32932698},
ISSN = {2073-4360},
ABSTRACT = {Silicone rubbers (SIRs) are common industrial materials which are often used for electrical insulation including weather sheds on non-ceramic insulators (NCIs). While SIRs are typically resilient to outside environments, aging can damage SIRs&rsquo; favorable properties such as hydrophobicity and electrical resistance. Detecting SIR aging and damage, however, can be difficult, especially in service. In this study we used hyperspectral imaging (HSI) and previously investigated aging methods as a proof of concept to show how HSI may be used to detect various types of aging damage in different SIR materials. The spectral signature changes in four different SIRs subjected to four different in-service aging environments all occurred between 400&ndash;&ndash;650 nm. Therefore, remote sensing of NCIs using HSI could concentrate on bands below 700 nm to successfully detect in service SIR damage.},
DOI = {10.3390/polym12092071}
}



@Article{rs12182977,
AUTHOR = {Sapkota, Bishwa and Singh, Vijay and Neely, Clark and Rajan, Nithya and Bagavathiannan, Muthukumar},
TITLE = {Detection of Italian Ryegrass in Wheat and Prediction of Competitive Interactions Using Remote-Sensing and Machine-Learning Techniques},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {2977},
URL = {https://www.mdpi.com/2072-4292/12/18/2977},
ISSN = {2072-4292},
ABSTRACT = {Italian ryegrass (Lolium perenne ssp. multiflorum (Lam) Husnot) is a troublesome weed species in wheat (Triticum aestivum) production in the United States, severely affecting grain yields. Spatial mapping of ryegrass infestation in wheat fields and early prediction of its impact on yield can assist management decision making. In this study, unmanned aerial systems (UAS)-based red, green and blue (RGB) imageries acquired at an early wheat growth stage in two different experimental sites were used for developing predictive models. Deep neural networks (DNNs) coupled with an extensive feature selection method were used to detect ryegrass in wheat and estimate ryegrass canopy coverage. Predictive models were developed by regressing early-season ryegrass canopy coverage (%) with end-of-season (at wheat maturity) biomass and seed yield of ryegrass, as well as biomass and grain yield reduction (%) of wheat. Italian ryegrass was detected with high accuracy (precision = 95.44 &plusmn; 4.27%, recall = 95.48 &plusmn; 5.05%, F-score = 95.56 &plusmn; 4.11%) using the best model which included four features: hue, saturation, excess green index, and visible atmospheric resistant index. End-of-season ryegrass biomass was predicted with high accuracy (R2 = 0.87), whereas the other variables had moderate to high accuracy levels (R2 values of 0.74 for ryegrass seed yield, 0.73 for wheat biomass reduction, and 0.69 for wheat grain yield reduction). The methodology demonstrated in the current study shows great potential for mapping and quantifying ryegrass infestation and predicting its competitive response in wheat, allowing for timely management decisions.},
DOI = {10.3390/rs12182977}
}



@Article{rs12182981,
AUTHOR = {Oh, Sungchan and Chang, Anjin and Ashapure, Akash and Jung, Jinha and Dube, Nothabo and Maeda, Murilo and Gonzalez, Daniel and Landivar, Juan},
TITLE = {Plant Counting of Cotton from UAS Imagery Using Deep Learning-Based Object Detection Framework},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {2981},
URL = {https://www.mdpi.com/2072-4292/12/18/2981},
ISSN = {2072-4292},
ABSTRACT = {Assessing plant population of cotton is important to make replanting decisions in low plant density areas, prone to yielding penalties. Since the measurement of plant population in the field is labor intensive and subject to error, in this study, a new approach of image-based plant counting is proposed, using unmanned aircraft systems (UAS; DJI Mavic 2 Pro, Shenzhen, China) data. The previously developed image-based techniques required a priori information of geometry or statistical characteristics of plant canopy features, while also limiting the versatility of the methods in variable field conditions. In this regard, a deep learning-based plant counting algorithm was proposed to reduce the number of input variables, and to remove requirements for acquiring geometric or statistical information. The object detection model named You Only Look Once version 3 (YOLOv3) and photogrammetry were utilized to separate, locate, and count cotton plants in the seedling stage. The proposed algorithm was tested with four different UAS datasets, containing variability in plant size, overall illumination, and background brightness. Root mean square error (RMSE) and R2 values of the optimal plant count results ranged from 0.50 to 0.60 plants per linear meter of row (number of plants within 1 m distance along the planting row direction) and 0.96 to 0.97, respectively. The object detection algorithm, trained with variable plant size, ground wetness, and lighting conditions generally resulted in a lower detection error, unless an observable difference of developmental stages of cotton existed. The proposed plant counting algorithm performed well with 0&ndash;14 plants per linear meter of row, when cotton plants are generally separable in the seedling stage. This study is expected to provide an automated methodology for in situ evaluation of plant emergence using UAS data.},
DOI = {10.3390/rs12182981}
}



@Article{s20185231,
AUTHOR = {Ibarreche, José and Aquino, Raúl and Edwards, R. M. and Rangel, Víctor and Pérez, Ismael and Martínez, Miguel and Castellanos, Esli and Álvarez, Elisa and Jimenez, Saul and Rentería, Raúl and Edwards, Arthur and Álvarez, Omar},
TITLE = {Flash Flood Early Warning System in Colima, Mexico},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5231},
URL = {https://www.mdpi.com/1424-8220/20/18/5231},
ISSN = {1424-8220},
ABSTRACT = {This paper presents a system of sensors used in flash flood prediction that offers critical real-time information used to provide early warnings that can provide the minutes needed for persons to evacuate before imminent events. Flooding is one of the most serious natural disasters humans confront in terms of loss of life and results in long-term effects, which often have severely adverse social consequences. However, flash floods are potentially more dangerous to life because there is often little or no forewarning of the impending disaster. The Emergency Water Information Network (EWIN) offers a solution that integrates an early warning system, notifications, and real-time monitoring of flash flood risks. The platform has been implemented in Colima, Mexico covering the Colima and Villa de Alvarez metropolitan area. This platform consists of eight fixed riverside hydrological monitoring stations, eight meteorological stations, nomadic mobile monitoring stations called &ldquo;drifters&rdquo; used in the flow, and a sniffer with data muling capability. The results show that this platform effectively compiles and forwards information to decision-makers, government officials, and the general public, potentially providing valuable minutes for people to evacuate dangerous areas.},
DOI = {10.3390/s20185231}
}



@Article{info11090442,
AUTHOR = {Almeshal, Abdullah M. and Alenezi, Mohammad R. and Alshatti, Abdullah K.},
TITLE = {Accuracy Assessment of Small Unmanned Aerial Vehicle for Traffic Accident Photogrammetry in the Extreme Operating Conditions of Kuwait},
JOURNAL = {Information},
VOLUME = {11},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {442},
URL = {https://www.mdpi.com/2078-2489/11/9/442},
ISSN = {2078-2489},
ABSTRACT = {This study presents the first accuracy assessment of a low cost small unmanned aerial vehicle (sUAV) in reconstructing three dimensional (3D) models of traffic accidents at extreme operating environments. To date, previous studies have focused on the feasibility of adopting sUAVs in traffic accidents photogrammetry applications as well as the accuracy at normal operating conditions. In this study, 3D models of simulated accident scenes were reconstructed using a low-cost sUAV and cloud-based photogrammetry platform. Several experiments were carried out to evaluate the measurements accuracy at different flight altitudes during high temperature, low light, scattered rain and dusty high wind environments. Quantitative analyses are presented to highlight the precision range of the reconstructed traffic accident 3D model. Reported results range from highly accurate to fairly accurate represented by the root mean squared error (RMSE) range between 0.97 and 4.66 and a mean percentage absolute error (MAPE) between 1.03% and 20.2% at normal and extreme operating conditions, respectively. The findings offer an insight into the robustness and generalizability of UAV-based photogrammetry method for traffic accidents at extreme environments.},
DOI = {10.3390/info11090442}
}



@Article{rs12182982,
AUTHOR = {Gée, Christelle and Denimal, Emmanuel},
TITLE = {RGB Image-Derived Indicators for Spatial Assessment of the Impact of Broadleaf Weeds on Wheat Biomass},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {2982},
URL = {https://www.mdpi.com/2072-4292/12/18/2982},
ISSN = {2072-4292},
ABSTRACT = {In precision agriculture, the development of proximal imaging systems embedded in autonomous vehicles allows to explore new weed management strategies for site-specific plant application. Accurate monitoring of weeds while controlling wheat growth requires indirect measurements of leaf area index (LAI) and above-ground dry matter biomass (BM) at early growth stages. This article explores the potential of RGB images to assess crop-weed competition in a wheat (Triticum aestivum L.) crop by generating two new indicators, the weed pressure (WP) and the local wheat biomass production (&delta;BMc). The fractional vegetation cover (FVC) of the crop and the weeds was automatically determined from the images with a SVM-RBF classifier, using bag of visual word vectors as inputs. It is based on a new vegetation index called MetaIndex, defined as a vote of six indices widely used in the literature. Beyond a simple map of weed infestation, the map of WP describes the crop-weed competition. The map of &delta;BMc, meanwhile, evaluates the local wheat above-ground biomass production and informs us about a potential stress. It is generated from the wheat FVC because it is highly correlated with LAI (r2 = 0.99) and BM (r2 = 0.93) obtained by destructive methods. By combining these two indicators, we aim at determining whether the origin of the wheat stress is due to weeds or not. This approach opens up new perspectives for the monitoring of weeds and the monitoring of their competition during crop growth with non-destructive and proximal sensing technologies in the early stages of development.},
DOI = {10.3390/rs12182982}
}



@Article{s20185245,
AUTHOR = {Kammerer, Klaus and Pryss, Rüdiger and Hoppenstedt, Burkhard and Sommer, Kevin and Reichert, Manfred},
TITLE = {Process-Driven and Flow-Based Processing of Industrial Sensor Data},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5245},
URL = {https://www.mdpi.com/1424-8220/20/18/5245},
ISSN = {1424-8220},
ABSTRACT = {For machine manufacturing companies, besides the production of high quality and reliable machines, requirements have emerged to maintain machine-related aspects through digital services. The development of such services in the field of the Industrial Internet of Things (IIoT) is dealing with solutions such as effective condition monitoring and predictive maintenance. However, appropriate data sources are needed on which digital services can be technically based. As many powerful and cheap sensors have been introduced over the last years, their integration into complex machines is promising for developing digital services for various scenarios. It is apparent that for components handling recorded data of these sensors they must usually deal with large amounts of data. In particular, the labeling of raw sensor data must be furthered by a technical solution. To deal with these data handling challenges in a generic way, a sensor processing pipeline (SPP) was developed, which provides effective methods to capture, process, store, and visualize raw sensor data based on a processing chain. Based on the example of a machine manufacturing company, the SPP approach is presented in this work. For the company involved, the approach has revealed promising results.},
DOI = {10.3390/s20185245}
}



@Article{land9090326,
AUTHOR = {Hartfield, Kyle and Leeuwen, Willem J.D. van and Gillan, Jeffrey K.},
TITLE = {Remotely Sensed Changes in Vegetation Cover Distribution and Groundwater along the Lower Gila River},
JOURNAL = {Land},
VOLUME = {9},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {326},
URL = {https://www.mdpi.com/2073-445X/9/9/326},
ISSN = {2073-445X},
ABSTRACT = {Introduced as a soil erosion deterrent, salt cedar has become a menace along riverbeds in the desert southwest. Salt cedar replaces native species, permanently altering the structure, composition, function, and natural processes of the landscape. Remote sensing technologies have the potential to monitor the level of invasion and its impacts on ecosystem services. In this research, we developed a species map by segmenting and classifying various species along a stretch of the Lower Gila River. We calculated metrics from high-resolution multispectral imagery and light detection and ranging (LiDAR) data to identify salt cedar, mesquite, and creosote. Analysts derived training and validation information from drone-acquired orthophotos to achieve an overall accuracy of 94%. It is clear from the results that salt cedar completely dominates the study area with small numbers of mesquite and creosote present. We also show that vegetation has declined in the study area over the last 25 years. We discuss how water usage may be influencing the plant health and biodiversity in the region. An examination of ground well, stream gauge, and Gravity Recovery and Climate Experiment (GRACE) groundwater storage data indicates a decline in water levels near the study area over the last 25 years.},
DOI = {10.3390/land9090326}
}



@Article{atmos11090987,
AUTHOR = {Kim, Hyun Il and Han, Kun Yeun},
TITLE = {Linking Hydraulic Modeling with a Machine Learning Approach for Extreme Flood Prediction and Response},
JOURNAL = {Atmosphere},
VOLUME = {11},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {987},
URL = {https://www.mdpi.com/2073-4433/11/9/987},
ISSN = {2073-4433},
ABSTRACT = {An emergency action plan (EAP) for reservoirs and urban areas downstream of dams can alleviate damage caused by extreme flooding. An EAP is a disaster action plan that can designate evacuation paths for vulnerable districts. Generally, calculation of dam-break discharge in accordance with dam inflow conditions, calculation of maximum water surface elevation as per hydraulic channel routing, and flood map generation using topographical data are prepared for the purposes of creating an EAP. However, rainfall and flood patterns exhibited in the context of climate change can be extremely diverse. In order to prepare an efficient flood response, techniques should be considered that are capable of generating flood maps promptly while taking dam inflow conditions into account. Therefore, this study aims to propose methodology that is capable of generating flood maps rapidly for any dam inflow conditions. The proposed methodology was performed by linking a dynamic numerical analysis model (DAMBRK) with a random forest regression technique. The previous standard method of drawing flood maps often requires a significant amount of time depending on accuracy and personnel availability; however, the technique proposed here is capable of generating a flood map within one minute. Through use of this methodology, the time taken to prepare flood maps in large-scale water-disaster situations can be reduced. Moreover, methodology for estimating flood risk via use of flood mapping has been proposed. This study would provide assistance in establishing disaster countermeasures that take various flood scenarios into account by promptly providing flood inundation information to disaster-related agencies.},
DOI = {10.3390/atmos11090987}
}



@Article{s20185262,
AUTHOR = {Li, Meizhu and Huang, Shaoguang and De Bock, Jasper and de Cooman, Gert and Pižurica, Aleksandra},
TITLE = {A Robust Dynamic Classifier Selection Approach for Hyperspectral Images with Imprecise Label Information},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5262},
URL = {https://www.mdpi.com/1424-8220/20/18/5262},
ISSN = {1424-8220},
ABSTRACT = {Supervised hyperspectral image (HSI) classification relies on accurate label information. However, it is not always possible to collect perfectly accurate labels for training samples. This motivates the development of classifiers that are sufficiently robust to some reasonable amounts of errors in data labels. Despite the growing importance of this aspect, it has not been sufficiently studied in the literature yet. In this paper, we analyze the effect of erroneous sample labels on probability distributions of the principal components of HSIs, and provide in this way a statistical analysis of the resulting uncertainty in classifiers. Building on the theory of imprecise probabilities, we develop a novel robust dynamic classifier selection (R-DCS) model for data classification with erroneous labels. Particularly, spectral and spatial features are extracted from HSIs to construct two individual classifiers for the dynamic selection, respectively. The proposed R-DCS model is based on the robustness of the classifiers&rsquo; predictions: the extent to which a classifier can be altered without changing its prediction. We provide three possible selection strategies for the proposed model with different computational complexities and apply them on three benchmark data sets. Experimental results demonstrate that the proposed model outperforms the individual classifiers it selects from and is more robust to errors in labels compared to widely adopted approaches.},
DOI = {10.3390/s20185262}
}



@Article{rs12182998,
AUTHOR = {Jackisch, Robert and Lorenz, Sandra and Kirsch, Moritz and Zimmermann, Robert and Tusa, Laura and Pirttijärvi, Markku and Saartenoja, Ari and Ugalde, Hernan and Madriz, Yuleika and Savolainen, Mikko and Gloaguen, Richard},
TITLE = {Integrated Geological and Geophysical Mapping of a Carbonatite-Hosting Outcrop in Siilinjärvi, Finland, Using Unmanned Aerial Systems},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {2998},
URL = {https://www.mdpi.com/2072-4292/12/18/2998},
ISSN = {2072-4292},
ABSTRACT = {Mapping geological outcrops is a crucial part of mineral exploration, mine planning and ore extraction. With the advent of unmanned aerial systems (UASs) for rapid spatial and spectral mapping, opportunities arise in fields where traditional ground-based approaches are established and trusted, but fail to cover sufficient area or compromise personal safety. Multi-sensor UAS are a technology that change geoscientific research, but they are still not routinely used for geological mapping in exploration and mining due to lack of trust in their added value and missing expertise and guidance in the selection and combination of drones and sensors. To address these limitations and highlight the potential of using UAS in exploration settings, we present an UAS multi-sensor mapping approach based on the integration of drone-borne photography, multi- and hyperspectral imaging and magnetics. Data are processed with conventional methods as well as innovative machine learning algorithms and validated by geological field mapping, yielding a comprehensive and geologically interpretable product. As a case study, we chose the northern extension of the Siilinj&auml;rvi apatite mine in Finland, in a brownfield exploration setting with plenty of ground truth data available and a survey area that is partly covered by vegetation. We conducted rapid UAS surveys from which we created a multi-layered data set to investigate properties of the ore-bearing carbonatite-glimmerite body. Our resulting geologic map discriminates between the principal lithologic units and distinguishes ore-bearing from waste rocks. Structural orientations and lithological units are deduced based on high-resolution, hyperspectral image-enhanced point clouds. UAS-based magnetic data allow an insight into their subsurface geometry through modeling based on magnetic interpretation. We validate our results via ground survey including rock specimen sampling, geochemical and mineralogical analysis and spectroscopic point measurements. We are convinced that the presented non-invasive, data-driven mapping approach can complement traditional workflows in mineral exploration as a flexible tool. Mapping products based on UAS data increase efficiency and maximize safety of the resource extraction process, and reduce expenses and incidental wastes.},
DOI = {10.3390/rs12182998}
}



@Article{s20185270,
AUTHOR = {Ohashi, Yuta and Ishigami, Yasuhiro and Goto, Eiji},
TITLE = {Monitoring the Growth and Yield of Fruit Vegetables in a Greenhouse Using a Three-Dimensional Scanner},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5270},
URL = {https://www.mdpi.com/1424-8220/20/18/5270},
ISSN = {1424-8220},
ABSTRACT = {Monitoring the growth of fruit vegetables is essential for the automation of cultivation management, and harvest. The objective of this study is to demonstrate that the current sensor technology can monitor the growth and yield of fruit vegetables such as tomato, cucumber, and paprika. We estimated leaf area, leaf area index (LAI), and plant height using coordinates of polygon vertices from plant and canopy surface models constructed using a three-dimensional (3D) scanner. A significant correlation was observed between the measured and estimated leaf area, LAI, and plant height (R2 &gt; 0.8, except for tomato LAI). The canopy structure of each fruit vegetable was predicted by integrating the estimated leaf area at each height of the canopy surface models. A linear relationship was observed between the measured total leaf area and the total dry weight of each fruit vegetable; thus, the dry weight of the plant can be predicted using the estimated leaf area. The fruit weights of tomato and paprika were estimated using the fruit solid model constructed by the fruit point cloud data extracted using the RGB value. A significant correlation was observed between the measured and estimated fruit weights (tomato: R2 = 0.739, paprika: R2 = 0.888). Therefore, it was possible to estimate the growth parameters (leaf area, plant height, canopy structure, and yield) of different fruit vegetables non-destructively using a 3D scanner.},
DOI = {10.3390/s20185270}
}



@Article{rs12183007,
AUTHOR = {Liu, Bo and Du, Shihong and Du, Shouji and Zhang, Xiuyuan},
TITLE = {Incorporating Deep Features into GEOBIA Paradigm for Remote Sensing Imagery Classification: A Patch-Based Approach},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {3007},
URL = {https://www.mdpi.com/2072-4292/12/18/3007},
ISSN = {2072-4292},
ABSTRACT = {The fast and accurate creation of land use/land cover maps from very-high-resolution (VHR) remote sensing imagery is crucial for urban planning and environmental monitoring. Geographic object-based image analysis methods (GEOBIA) provide an effective solution using image objects instead of individual pixels in VHR remote sensing imagery analysis. Simultaneously, convolutional neural networks (CNN) have been widely used in the image processing field because of their powerful feature extraction capabilities. This study presents a patch-based strategy for integrating deep features into GEOBIA for VHR remote sensing imagery classification. To extract deep features from irregular image objects through CNN, a patch-based approach is proposed for representing image objects and learning patch-based deep features, and a deep features aggregation method is proposed for aggregating patch-based deep features into object-based deep features. Finally, both object and deep features are integrated into a GEOBIA paradigm for classifying image objects. We explored the influences of segmentation scales and patch sizes in our method and explored the effectiveness of deep and object features in classification. Moreover, we performed 5-fold stratified cross validations 50 times to explore the uncertainty of our method. Additionally, we explored the importance of deep feature aggregation, and we evaluated our method by comparing it with three state-of-the-art methods in a Beijing dataset and Zurich dataset. The results indicate that smaller segmentation scales were more conducive to VHR remote sensing imagery classification, and it was not appropriate to select too large or too small patches as the patch size should be determined by imagery and its resolution. Moreover, we found that deep features are more effective than object features, while object features still matter for image classification, and deep feature aggregation is a critical step in our method. Finally, our method can achieve the highest overall accuracies compared with the state-of-the-art methods, and the overall accuracies are 91.21% for the Beijing dataset and 99.05% for the Zurich dataset.},
DOI = {10.3390/rs12183007}
}



@Article{geosciences10090369,
AUTHOR = {Starková, Lenka},
TITLE = {Toward a High-Definition Remote Sensing Approach to the Study of Deserted Medieval Cities in the Near East},
JOURNAL = {Geosciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {369},
URL = {https://www.mdpi.com/2076-3263/10/9/369},
ISSN = {2076-3263},
ABSTRACT = {The variability of currently available remote sensing datasets raises the question of which specific processing methods should be used for feature detection and feature extraction in both large and small-scale overhead images. In some cases, particular analyses allow us to carry out feature detection much more easily and effectively. The high-definition approach enables enhanced analysis of remote sensing data using all the spectral and graphical potential of multi-temporal ordered components. The deserted urban site of Kona Makhmūr, Iraqi Kurdistan, is taken as a case study to demonstrate this fine-grained approach. The analysis described in this paper is based on the complementary use of a variety of overlayed imagery, augmented by data from terrestrial surveys. The resulting map substantially enhances our knowledge of the built environment and the economic and environmental conditions of this early Islamic-period site. Spectral analysis of raster images allowed us to detect the real shapes of features, and with the addition of digital elevation model (DEM) (created via unmanned aerial system (UAV)) we were also able to interpret the state of preservation of the overground relics and the diachronic dynamics of their degradation.},
DOI = {10.3390/geosciences10090369}
}



@Article{jimaging6090097,
AUTHOR = {Bhuiyan, Md Abul Ehsan and Witharana, Chandi and Liljedahl, Anna K. and Jones, Benjamin M. and Daanen, Ronald and Epstein, Howard E. and Kent, Kelcy and Griffin, Claire G. and Agnew, Amber},
TITLE = {Understanding the Effects of Optimal Combination of Spectral Bands on Deep Learning Model Predictions: A Case Study Based on Permafrost Tundra Landform Mapping Using High Resolution Multispectral Satellite Imagery},
JOURNAL = {Journal of Imaging},
VOLUME = {6},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {97},
URL = {https://www.mdpi.com/2313-433X/6/9/97},
ISSN = {2313-433X},
ABSTRACT = {Deep learning (DL) convolutional neural networks (CNNs) have been rapidly adapted in very high spatial resolution (VHSR) satellite image analysis. DLCNN-based computer visions (CV) applications primarily aim for everyday object detection from standard red, green, blue (RGB) imagery, while earth science remote sensing applications focus on geo object detection and classification from multispectral (MS) imagery. MS imagery includes RGB and narrow spectral channels from near- and/or middle-infrared regions of reflectance spectra. The central objective of this exploratory study is to understand to what degree MS band statistics govern DLCNN model predictions. We scaffold our analysis on a case study that uses Arctic tundra permafrost landform features called ice-wedge polygons (IWPs) as candidate geo objects. We choose Mask RCNN as the DLCNN architecture to detect IWPs from eight-band Worldview-02 VHSR satellite imagery. A systematic experiment was designed to understand the impact on choosing the optimal three-band combination in model prediction. We tasked five cohorts of three-band combinations coupled with statistical measures to gauge the spectral variability of input MS bands. The candidate scenes produced high model detection accuracies for the F1 score, ranging between 0.89 to 0.95, for two different band combinations (coastal blue, blue, green (1,2,3) and green, yellow, red (3,4,5)). The mapping workflow discerned the IWPs by exhibiting low random and systematic error in the order of 0.17&ndash;0.19 and 0.20&ndash;0.21, respectively, for band combinations (1,2,3). Results suggest that the prediction accuracy of the Mask-RCNN model is significantly influenced by the input MS bands. Overall, our findings accentuate the importance of considering the image statistics of input MS bands and careful selection of optimal bands for DLCNN predictions when DLCNN architectures are restricted to three spectral channels.},
DOI = {10.3390/jimaging6090097}
}



@Article{rs12183032,
AUTHOR = {Pádua, Luís and Marques, Pedro and Martins, Luís and Sousa, António and Peres, Emanuel and Sousa, Joaquim J.},
TITLE = {Monitoring of Chestnut Trees Using Machine Learning Techniques Applied to UAV-Based Multispectral Data},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {3032},
URL = {https://www.mdpi.com/2072-4292/12/18/3032},
ISSN = {2072-4292},
ABSTRACT = {Phytosanitary conditions can hamper the normal development of trees and significantly impact their yield. The phytosanitary condition of chestnut stands is usually evaluated by sampling trees followed by a statistical extrapolation process, making it a challenging task, as it is labor-intensive and requires skill. In this study, a novel methodology that enables multi-temporal analysis of chestnut stands using multispectral imagery acquired from unmanned aerial vehicles is presented. Data were collected in different flight campaigns along with field surveys to identify the phytosanitary issues affecting each tree. A random forest classifier was trained with sections of each tree crown using vegetation indices and spectral bands. These were first categorized into two classes: (i) absence or (ii) presence of phytosanitary issues. Subsequently, the class with phytosanitary issues was used to identify and classify either biotic or abiotic factors. The comparison between the classification results, obtained by the presented methodology, with ground-truth data, allowed us to conclude that phytosanitary problems were detected with an accuracy rate between 86% and 91%. As for determining the specific phytosanitary issue, rates between 80% and 85% were achieved. Higher accuracy rates were attained in the last flight campaigns, the stage when symptoms are more prevalent. The proposed methodology proved to be effective in automatically detecting and classifying phytosanitary issues in chestnut trees throughout the growing season. Moreover, it is also able to identify decline or expansion situations. It may be of help as part of decision support systems that further improve on the efficient and sustainable management practices of chestnut stands.},
DOI = {10.3390/rs12183032}
}



@Article{rs12183035,
AUTHOR = {Lai, Ying-Chih and Huang, Zong-Ying},
TITLE = {Detection of a Moving UAV Based on Deep Learning-Based Distance Estimation},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {3035},
URL = {https://www.mdpi.com/2072-4292/12/18/3035},
ISSN = {2072-4292},
ABSTRACT = {Distance information of an obstacle is important for obstacle avoidance in many applications, and could be used to determine the potential risk of object collision. In this study, the detection of a moving fixed-wing unmanned aerial vehicle (UAV) with deep learning-based distance estimation to conduct a feasibility study of sense and avoid (SAA) and mid-air collision avoidance of UAVs is proposed by using a monocular camera to detect and track an incoming UAV. A quadrotor is regarded as an owned UAV, and it is able to estimate the distance of an incoming fixed-wing intruder. The adopted object detection method is based on the you only look once (YOLO) object detector. Deep neural network (DNN) and convolutional neural network (CNN) methods are applied to exam their performance in the distance estimation of moving objects. The feature extraction of fixed-wing UAVs is based on the VGG-16 model, and then its result is applied to the distance network to estimate the object distance. The proposed model is trained by using synthetic images from animation software and validated by using both synthetic and real flight videos. The results show that the proposed active vision-based scheme is able to detect and track a moving UAV with high detection accuracy and low distance errors.},
DOI = {10.3390/rs12183035}
}



@Article{s20185340,
AUTHOR = {Xu, Haocheng and Li, Shenghong and Lee, Caroline and Ni, Wei and Abbott, David and Johnson, Mark and Lea, Jim M. and Yuan, Jinhong and Campbell, Dana L. M.},
TITLE = {Analysis of Cattle Social Transitional Behaviour: Attraction and Repulsion},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5340},
URL = {https://www.mdpi.com/1424-8220/20/18/5340},
ISSN = {1424-8220},
ABSTRACT = {Understanding social interactions in livestock groups could improve management practices, but this can be difficult and time-consuming using traditional methods of live observations and video recordings. Sensor technologies and machine learning techniques could provide insight not previously possible. In this study, based on the animals&rsquo; location information acquired by a new cooperative wireless localisation system, unsupervised machine learning approaches were performed to identify the social structure of a small group of cattle yearlings (n=10) and the social behaviour of an individual. The paper first defined the affinity between an animal pair based on the ranks of their distance. Unsupervised clustering algorithms were then performed, including K-means clustering and agglomerative hierarchical clustering. In particular, K-means clustering was applied based on logical and physical distance. By comparing the clustering result based on logical distance and physical distance, the leader animals and the influence of an individual in a herd of cattle were identified, which provides valuable information for studying the behaviour of animal herds. Improvements in device robustness and replication of this work would confirm the practical application of this technology and analysis methodologies.},
DOI = {10.3390/s20185340}
}



@Article{rs12183046,
AUTHOR = {Xiao, Yingxin and Dong, Yingying and Huang, Wenjiang and Liu, Linyi and Ma, Huiqin and Ye, Huichun and Wang, Kun},
TITLE = {Dynamic Remote Sensing Prediction for Wheat Fusarium Head Blight by Combining Host and Habitat Conditions},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {3046},
URL = {https://www.mdpi.com/2072-4292/12/18/3046},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing technology provides a feasible option for early prediction for wheat Fusarium head blight (FHB). This study presents a methodology for the dynamic prediction of this classic meteorological crop disease. Host and habitat conditions were comprehensively considered as inputs of the FHB prediction model, and the advantages, accuracy, and generalization ability of the model were evaluated. Firstly, multi-source satellite images were used to predict growth stages and to obtain remote sensing features, then weather features around the predicted stages were extracted. Then, with changes in the inputting features, the severity of FHB was dynamically predicted on February 18, March 6, April 23, and May 9, 2017. Compared to the results obtained by the Logistic model, the prediction with the Relevance Vector Machine performed better, with the overall accuracy on these four dates as 0.71, 0.78, 0.85, and 0.93, and with the area under the receiver operating characteristic curve as 0.66, 0.67, 0.72, and 0.75. Additionally, compared with the prediction with only one factor, the integration of multiple factors was more accurate. The results showed that when the date of the remote sensing features was closer to the heading or flowering stage, the prediction was more accurate, especially in severe areas. Though the habitat conditions were suitable for FHB, the infection can be inhibited when the host&rsquo;s growth meets certain requirements.},
DOI = {10.3390/rs12183046}
}



@Article{s20185343,
AUTHOR = {Opiela, Miroslav and Galčík, František},
TITLE = {Grid-Based Bayesian Filtering Methods for Pedestrian Dead Reckoning Indoor Positioning Using Smartphones},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5343},
URL = {https://www.mdpi.com/1424-8220/20/18/5343},
ISSN = {1424-8220},
ABSTRACT = {Indoor positioning systems for smartphones are often based on Pedestrian Dead Reckoning, which computes the current position from the previously estimated location. Noisy sensor measurements, inaccurate step length estimations, faulty direction detections, and a demand on the real-time calculation introduce the error which is suppressed using a map model and a Bayesian filtering. The main focus of this paper is on grid-based implementations of Bayes filters as an alternative to commonly used Kalman and particle filters. Our previous work regarding grid-based filters is elaborated and enriched with convolution mask calculations. More advanced implementations, the centroid grid filter, and the advanced point-mass filter are introduced. These implementations are analyzed and compared using different configurations on the same raw sensor recordings. The evaluation is performed on three sets of experiments: a custom simple path in faculty building in Slovakia, and on datasets from IPIN competitions from a shopping mall in France, 2018 and a research institute in Italy, 2019. Evaluation results suggests that proposed methods are qualified alternatives to the particle filter. Advantages, drawbacks and proper configurations of these filters are discussed in this paper.},
DOI = {10.3390/s20185343}
}



@Article{computers9030075,
AUTHOR = {Contreras, Ruben and Ayala, Angel and Cruz, Francisco},
TITLE = {Unmanned Aerial Vehicle Control through Domain-Based Automatic Speech Recognition},
JOURNAL = {Computers},
VOLUME = {9},
YEAR = {2020},
NUMBER = {3},
ARTICLE-NUMBER = {75},
URL = {https://www.mdpi.com/2073-431X/9/3/75},
ISSN = {2073-431X},
ABSTRACT = {Currently, unmanned aerial vehicles, such as drones, are becoming a part of our lives and extend to many areas of society, including the industrialized world. A common alternative for controlling the movements and actions of the drone is through unwired tactile interfaces, for which different remote control devices are used. However, control through such devices is not a natural, human-like communication interface, which sometimes is difficult to master for some users. In this research, we experimented with a domain-based speech recognition architecture to effectively control an unmanned aerial vehicle such as a drone. The drone control was performed in a more natural, human-like way to communicate the instructions. Moreover, we implemented an algorithm for command interpretation using both Spanish and English languages, as well as to control the movements of the drone in a simulated domestic environment. We conducted experiments involving participants giving voice commands to the drone in both languages in order to compare the effectiveness of each, considering the mother tongue of the participants in the experiment. Additionally, different levels of distortion were applied to the voice commands to test the proposed approach when it encountered noisy input signals. The results obtained showed that the unmanned aerial vehicle was capable of interpreting user voice instructions. Speech-to-action recognition improved for both languages with phoneme matching in comparison to only using the cloud-based algorithm without domain-based instructions. Using raw audio inputs, the cloud-based approach achieves 74.81% and 97.04% accuracy for English and Spanish instructions, respectively. However, with our phoneme matching approach the results are improved, yielding 93.33% accuracy for English and 100.00% accuracy for Spanish.},
DOI = {10.3390/computers9030075}
}



@Article{s20185374,
AUTHOR = {Zhao, Long and Ishag Mahmoud, Mubarak Adam and Ren, Honge and Zhu, Meng},
TITLE = {A Visual Tracker Offering More Solutions},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5374},
URL = {https://www.mdpi.com/1424-8220/20/18/5374},
ISSN = {1424-8220},
ABSTRACT = {Most trackers focus solely on robustness and accuracy. Visual tracking, however, is a long-term problem with a high time limitation. A tracker that is robust, accurate, with long-term sustainability and real-time processing, is of high research value and practical significance. In this paper, we comprehensively consider these requirements in order to propose a new, state-of-the-art tracker with an excellent performance. EfficientNet-B0 is adopted for the first time via neural architecture search technology as the backbone network for the tracking task. This improves the network feature extraction ability and significantly reduces the number of parameters required for the tracker backbone network. In addition, maximal Distance Intersection-over-Union is set as the target estimation method, enhancing network stability and increasing the offline training convergence rate. Channel and spatial dual attention mechanisms are employed in the target classification module to improve the discrimination of the trackers. Furthermore, the conjugate gradient optimization strategy increases the speed of the online learning target classification module. A two-stage search method combined with a screening module is proposed to enable the tracker to cope with sudden target movement and reappearance following a brief disappearance. Our proposed method has an obvious speed advantage compared with pure global searching and achieves an optimal performance on OTB2015, VOT2016, VOT2018-LT, UAV-123 and LaSOT while running at over 50 FPS.},
DOI = {10.3390/s20185374}
}



@Article{agriculture10090416,
AUTHOR = {Chen, Pei-Chun and Chiang, Yen-Cheng and Weng, Pei-Yi},
TITLE = {Imaging Using Unmanned Aerial Vehicles for Agriculture Land Use Classification},
JOURNAL = {Agriculture},
VOLUME = {10},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {416},
URL = {https://www.mdpi.com/2077-0472/10/9/416},
ISSN = {2077-0472},
ABSTRACT = {An unmanned aerial vehicle (UAV) was used to capture high-resolution aerial images of crop fields. Software-based image analysis was performed to classify land uses. The purpose was to help relevant agencies use aerial imaging in managing agricultural production. This study involves five townships in the Chianan Plain of Chiayi County, Taiwan. About 100 ha of farmland in each township was selected as a sample area, and a quadcopter and a handheld fixed-wing drone were used to capture visible-light images and multispectral images. The survey was carried out from August to October 2018 and aerial photographs were captured in clear and dry weather. This study used high-resolution images captured from a UAV to classify the uses of agricultural land, and then employed information from multispectral images and elevation data from a digital surface model. The results revealed that visible-light images led to low interpretation accuracy. However, multispectral images and elevation data increased the accuracy rate to nearly 90%. Accordingly, such images and data can effectively enhance the accuracy of land use classification. The technology can reduce costs that are associated with labor and time and can facilitate the establishment of a real-time mapping database.},
DOI = {10.3390/agriculture10090416}
}



@Article{rs12183104,
AUTHOR = {An, Gangqiang and Xing, Minfeng and He, Binbin and Liao, Chunhua and Huang, Xiaodong and Shang, Jiali and Kang, Haiqi},
TITLE = {Using Machine Learning for Estimating Rice Chlorophyll Content from In Situ Hyperspectral Data},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {3104},
URL = {https://www.mdpi.com/2072-4292/12/18/3104},
ISSN = {2072-4292},
ABSTRACT = {Chlorophyll is an essential pigment for photosynthesis in crops, and leaf chlorophyll content can be used as an indicator for crop growth status and help guide nitrogen fertilizer applications. Estimating crop chlorophyll content plays an important role in precision agriculture. In this study, a variable, rate of change in reflectance between wavelengths &lsquo;a&rsquo; and &lsquo;b&rsquo; (RCRWa-b), derived from in situ hyperspectral remote sensing data combined with four advanced machine learning techniques, Gaussian process regression (GPR), random forest regression (RFR), support vector regression (SVR), and gradient boosting regression tree (GBRT), were used to estimate the chlorophyll content (measured by a portable soil&ndash;plant analysis development meter) of rice. The performances of the four machine learning models were assessed and compared using root mean square error (RMSE), mean absolute error (MAE), and coefficient of determination (R2). The results revealed that four features of RCRWa-b, RCRW551.0&ndash;565.6, RCRW739.5&ndash;743.5, RCRW684.4&ndash;687.1 and RCRW667.9&ndash;672.0, were effective in estimating the chlorophyll content of rice, and the RFR model generated the highest prediction accuracy (training set: RMSE = 1.54, MAE =1.23 and R2 = 0.95; validation set: RMSE = 2.64, MAE = 1.99 and R2 = 0.80). The GPR model was found to have the strongest generalization (training set: RMSE = 2.83, MAE = 2.16 and R2 = 0.77; validation set: RMSE = 2.97, MAE = 2.30 and R2 = 0.76). We conclude that RCRWa-b is a useful variable to estimate chlorophyll content of rice, and RFR and GPR are powerful machine learning algorithms for estimating the chlorophyll content of rice.},
DOI = {10.3390/rs12183104}
}



@Article{rs12193134,
AUTHOR = {Hu, Guanghui and Dai, Wen and Li, Sijin and Xiong, Liyang and Tang, Guoan},
TITLE = {A Vector Operation to Extract Second-Order Terrain Derivatives from Digital Elevation Models},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3134},
URL = {https://www.mdpi.com/2072-4292/12/19/3134},
ISSN = {2072-4292},
ABSTRACT = {Terrain derivatives exhibit surface morphology in various aspects. However, existing spatial change calculation methods for terrain derivatives are based on a mathematical scalar operating system, which may disregard the directional property of the original data to a certain extent. This situation is particularly true in second-order terrain derivatives, in which original data can be terrain derivatives with clear directional properties, such as slope or aspect. Thus, this study proposes a mathematical vector operation method for the calculation of second-order terrain derivatives. Given the examples of the first-order terrain derivatives of slope and aspect, their second-order terrain derivatives are calculated using the proposed vector method. Directional properties are considered and vectorized using the following steps: rotation-type judgment, standardization of initial direction, and vector representation. The proposed vector method is applied to one mathematical Gaussian surface and three different ground landform areas using digital elevation models (DEMs) with 5 and 1 m resolutions. Comparison analysis results between the vector and scalar methods show that the former achieves more reasonable and accurate second-order terrain derivatives than the latter. Moreover, the vector method avoids overexpression or even exaggeration errors. This vector operation concept and its expanded methods can be applied in calculating other terrain derivatives in geomorphometry.},
DOI = {10.3390/rs12193134}
}



@Article{drones4040064,
AUTHOR = {Raoult, Vincent and Colefax, Andrew P and Allan, Blake M. and Cagnazzi, Daniele and Castelblanco-Martínez, Nataly and Ierodiaconou, Daniel and Johnston, David W. and Landeo-Yauri, Sarah and Lyons, Mitchell and Pirotta, Vanessa and Schofield, Gail and Butcher, Paul A},
TITLE = {Operational Protocols for the Use of Drones in Marine Animal Research},
JOURNAL = {Drones},
VOLUME = {4},
YEAR = {2020},
NUMBER = {4},
ARTICLE-NUMBER = {64},
URL = {https://www.mdpi.com/2504-446X/4/4/64},
ISSN = {2504-446X},
ABSTRACT = {The use of drones to study marine animals shows promise for the examination of numerous aspects of their ecology, behaviour, health and movement patterns. However, the responses of some marine phyla to the presence of drones varies broadly, as do the general operational protocols used to study them. Inconsistent methodological approaches could lead to difficulties comparing studies and can call into question the repeatability of research. This review draws on current literature and researchers with a wealth of practical experience to outline the idiosyncrasies of studying various marine taxa with drones. We also outline current best practice for drone operation in marine environments based on the literature and our practical experience in the field. The protocols outlined herein will be of use to researchers interested in incorporating drones as a tool into their research on marine animals and will help form consistent approaches for drone-based studies in the future.},
DOI = {10.3390/drones4040064}
}



@Article{drones4040063,
AUTHOR = {Steup, Christoph and Parlow, Simon and Mai, Sebastian and Mostaghim, Sanaz},
TITLE = {Generic Component-Based Mission-Centric Energy Model for Micro-Scale Unmanned Aerial Vehicles},
JOURNAL = {Drones},
VOLUME = {4},
YEAR = {2020},
NUMBER = {4},
ARTICLE-NUMBER = {63},
URL = {https://www.mdpi.com/2504-446X/4/4/63},
ISSN = {2504-446X},
ABSTRACT = {The trend towards the usage of battery-electric unmanned aerial vehicles needs new strategies in mission planning and in the design of the systems themselves. To create an optimal mission plan and take appropriate decisions during the mission, a reliable, accurate and adaptive energy model is of utmost importance. However, most existing approaches either use very generic models or ones that are especially tailored towards a specific UAV. We present a generic energy model that is based on decomposing a robotic system into multiple observable components. The generic model is applied to a swarm of quadcopters and evaluated in multiple flights with different manoeuvres. We additionally use the data from practical experiments to learn and generate a mission-agnostic energy model which can match the typical behaviour of our quadcopters such as hovering; movement in x, y and z directions; landing; communication; and illumination. The learned energy model concurs with the overall energy consumption with an accuracy over 95% compared to the training flights for the indoor use case. An extended model reduces the error to less than 1.4%. Consequently, the proposed model enables an estimation of the energy used in flight and on the ground, which can be easily incorporated in autonomous systems and enhance decision-making with reliable input. The used learning mechanism allows to deploy the approach with minimal effort to new platforms needing only some representative test missions, which was shown using additional outdoor validation flights with a different quadcopter of the same build and the originally trained models. This set-up increased the prediction error of our model to 4.46%.},
DOI = {10.3390/drones4040063}
}



@Article{s20195495,
AUTHOR = {El Boudani, Brahim and Kanaris, Loizos and Kokkinis, Akis and Kyriacou, Michalis and Chrysoulas, Christos and Stavrou, Stavros and Dagiuklas, Tasos},
TITLE = {Implementing Deep Learning Techniques in 5G IoT Networks for 3D Indoor Positioning: DELTA (DeEp Learning-Based Co-operaTive Architecture)},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {5495},
URL = {https://www.mdpi.com/1424-8220/20/19/5495},
ISSN = {1424-8220},
ABSTRACT = {In the near future, the fifth-generation wireless technology is expected to be rolled out, offering low latency, high bandwidth and multiple antennas deployed in a single access point. This ecosystem will help further enhance various location-based scenarios such as assets tracking in smart factories, precise smart management of hydroponic indoor vertical farms and indoor way-finding in smart hospitals. Such a system will also integrate existing technologies like the Internet of Things (IoT), WiFi and other network infrastructures. In this respect, 5G precise indoor localization using heterogeneous IoT technologies (Zigbee, Raspberry Pi, Arduino, BLE, etc.) is a challenging research area. In this work, an experimental 5G testbed has been designed integrating C-RAN and IoT networks. This testbed is used to improve both vertical and horizontal localization (3D Localization) in a 5G IoT environment. To achieve this, we propose the DEep Learning-based co-operaTive Architecture (DELTA) machine learning model implemented on a 3D multi-layered fingerprint radiomap. The DELTA begins by estimating the 2D location. Then, the output is recursively used to predict the 3D location of a mobile station. This approach is going to benefit use cases such as 3D indoor navigation in multi-floor smart factories or in large complex buildings. Finally, we have observed that the proposed model has outperformed traditional algorithms such as Support Vector Machine (SVM) and K-Nearest Neighbor (KNN).},
DOI = {10.3390/s20195495}
}



@Article{rs12193152,
AUTHOR = {Courtrai, Luc and Pham, Minh-Tan and Lefèvre, Sébastien},
TITLE = {Small Object Detection in Remote Sensing Images Based on Super-Resolution with Auxiliary Generative Adversarial Networks},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3152},
URL = {https://www.mdpi.com/2072-4292/12/19/3152},
ISSN = {2072-4292},
ABSTRACT = {This article tackles the problem of detecting small objects in satellite or aerial remote sensing images by relying on super-resolution to increase image spatial resolution, thus the size and details of objects to be detected. We show how to improve the super-resolution framework starting from the learning of a generative adversarial network (GAN) based on residual blocks and then its integration into a cycle model. Furthermore, by adding to the framework an auxiliary network tailored for object detection, we considerably improve the learning and the quality of our final super-resolution architecture, and more importantly increase the object detection performance. Besides the improvement dedicated to the network architecture, we also focus on the training of super-resolution on target objects, leading to an object-focused approach. Furthermore, the proposed strategies do not depend on the choice of a baseline super-resolution framework, hence could be adopted for current and future state-of-the-art models. Our experimental study on small vehicle detection in remote sensing data conducted on both aerial and satellite images (i.e., ISPRS Potsdam and xView datasets) confirms the effectiveness of the improved super-resolution methods to assist with the small object detection tasks.},
DOI = {10.3390/rs12193152}
}



@Article{rs12193164,
AUTHOR = {Banerjee, Bikram Pratap and Spangenberg, German and Kant, Surya},
TITLE = {Fusion of Spectral and Structural Information from Aerial Images for Improved Biomass Estimation},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3164},
URL = {https://www.mdpi.com/2072-4292/12/19/3164},
ISSN = {2072-4292},
ABSTRACT = {Efficient, precise and timely measurement of plant traits is important in the assessment of a breeding population. Estimating crop biomass in breeding trials using high-throughput technologies is difficult, as reproductive and senescence stages do not relate to reflectance spectra, and multiple growth stages occur concurrently in diverse genotypes. Additionally, vegetation indices (VIs) saturate at high canopy coverage, and vertical growth profiles are difficult to capture using VIs. A novel approach was implemented involving a fusion of complementary spectral and structural information, to calculate intermediate metrics such as crop height model (CHM), crop coverage (CC) and crop volume (CV), which were finally used to calculate dry (DW) and fresh (FW) weight of above-ground biomass in wheat. The intermediate metrics, CHM (R2 = 0.81, SEE = 4.19 cm) and CC (OA = 99.2%, &Kappa; = 0.98) were found to be accurate against equivalent ground truth measurements. The metrics CV and CV&times;VIs were used to develop an effective and accurate linear regression model relationship with DW (R2 = 0.96 and SEE = 69.2 g/m2) and FW (R2 = 0.89 and SEE = 333.54 g/m2). The implemented approach outperformed commonly used VIs for estimation of biomass at all growth stages in wheat. The achieved results strongly support the applicability of the proposed approach for high-throughput phenotyping of germplasm in wheat and other crop species.},
DOI = {10.3390/rs12193164}
}



@Article{s20195529,
AUTHOR = {Barzilov, Alexander and Kazemeini, Monia},
TITLE = {Unmanned Aerial System Integrated Sensor for Remote Gamma and Neutron Monitoring},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {5529},
URL = {https://www.mdpi.com/1424-8220/20/19/5529},
ISSN = {1424-8220},
ABSTRACT = {Tools for remote radiation sensing are essential for environmental safety and nuclear power applications. The use of unmanned aerial systems (UASs) equipped with sensors allows for substantially reducing the radiation exposure of personnel. An ambient temperature Cs2LiYCl6:Ce3+ (CLYC) elpasolite scintillation sensor for simultaneous gamma and neutron measurements was designed as a user-friendly &ldquo;plug and fly&rdquo; module integrated into an octocopter robotic platform. Robot Operating System (ROS) was used to analyze the sensor&rsquo;s data. The measured CLYC&rsquo;s energy resolution was &lt;5% at 662 keV gamma rays; neutron flux was measured using 6Li(n,&alpha;)t reaction. Time and GPS data were combined with radiation data in the ROS, supporting real time monitoring and assessment tasks, as well as radiation source search missions. Because UASs can be irradiated, radiation damage of the sensor and robot&rsquo;s electronics was estimated using FLUKA code.},
DOI = {10.3390/s20195529}
}



@Article{agriculture10100436,
AUTHOR = {Niazian, Mohsen and Niedbała, Gniewko},
TITLE = {Machine Learning for Plant Breeding and Biotechnology},
JOURNAL = {Agriculture},
VOLUME = {10},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {436},
URL = {https://www.mdpi.com/2077-0472/10/10/436},
ISSN = {2077-0472},
ABSTRACT = {Classical univariate and multivariate statistics are the most common methods used for data analysis in plant breeding and biotechnology studies. Evaluation of genetic diversity, classification of plant genotypes, analysis of yield components, yield stability analysis, assessment of biotic and abiotic stresses, prediction of parental combinations in hybrid breeding programs, and analysis of in vitro-based biotechnological experiments are mainly performed by classical statistical methods. Despite successful applications, these classical statistical methods have low efficiency in analyzing data obtained from plant studies, as the genotype, environment, and their interaction (G &times; E) result in nondeterministic and nonlinear nature of plant characteristics. Large-scale data flow, including phenomics, metabolomics, genomics, and big data, must be analyzed for efficient interpretation of results affected by G &times; E. Nonlinear nonparametric machine learning techniques are more efficient than classical statistical models in handling large amounts of complex and nondeterministic information with &ldquo;multiple-independent variables versus multiple-dependent variables&rdquo; nature. Neural networks, partial least square regression, random forest, and support vector machines are some of the most fascinating machine learning models that have been widely applied to analyze nonlinear and complex data in both classical plant breeding and in vitro-based biotechnological studies. High interpretive power of machine learning algorithms has made them popular in the analysis of plant complex multifactorial characteristics. The classification of different plant genotypes with morphological and molecular markers, modeling and predicting important quantitative characteristics of plants, the interpretation of complex and nonlinear relationships of plant characteristics, and predicting and optimizing of in vitro breeding methods are the examples of applications of machine learning in conventional plant breeding and in vitro-based biotechnological studies. Precision agriculture is possible through accurate measurement of plant characteristics using imaging techniques and then efficient analysis of reliable extracted data using machine learning algorithms. Perfect interpretation of high-throughput phenotyping data is applicable through coupled machine learning-image processing. Some applied and potentially applicable capabilities of machine learning techniques in conventional and in vitro-based plant breeding studies have been discussed in this overview. Discussions are of great value for future studies and could inspire researchers to apply machine learning in new layers of plant breeding.},
DOI = {10.3390/agriculture10100436}
}



@Article{s20195538,
AUTHOR = {Zhang, Yunsheng and Zhu, Yaochen and Li, Haifeng and Chen, Siyang and Peng, Jian and Zhao, Ling},
TITLE = {Automatic Changes Detection between Outdated Building Maps and New VHR Images Based on Pre-Trained Fully Convolutional Feature Maps},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {5538},
URL = {https://www.mdpi.com/1424-8220/20/19/5538},
ISSN = {1424-8220},
ABSTRACT = {Detecting changes between the existing building basemaps and newly acquired high spatial resolution remotely sensed (HRS) images is a time-consuming task. This is mainly because of the data labeling and poor performance of hand-crafted features. In this paper, for efficient feature extraction, we propose a fully convolutional feature extractor that is reconstructed from the deep convolutional neural network (DCNN) and pre-trained on the Pascal VOC dataset. Our proposed method extract pixel-wise features, and choose salient features based on a random forest (RF) algorithm using the existing basemaps. A data cleaning method through cross-validation and label-uncertainty estimation is also proposed to select potential correct labels and use them for training an RF classifier to extract the building from new HRS images. The pixel-wise initial classification results are refined based on a superpixel-based graph cuts algorithm and compared to the existing building basemaps to obtain the change map. Experiments with two simulated and three real datasets confirm the effectiveness of our proposed method and indicate high accuracy and low false alarm rate.},
DOI = {10.3390/s20195538}
}



@Article{rs12193171,
AUTHOR = {Park, Jinseok and Jang, Seongju and Hong, Rokgi and Suh, Kyo and Song, Inhong},
TITLE = {Development of Land Cover Classification Model Using AI Based FusionNet Network},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3171},
URL = {https://www.mdpi.com/2072-4292/12/19/3171},
ISSN = {2072-4292},
ABSTRACT = {Prompt updates of land cover maps are important, as spatial information of land cover is widely used in many areas. However, current manual digitizing methods are time consuming and labor intensive, hindering rapid updates of land cover maps. The objective of this study was to develop an artificial intelligence (AI) based land cover classification model that allows for rapid land cover classification from high-resolution remote sensing (HRRS) images. The model comprises of three modules: pre-processing, land cover classification, and post-processing modules. The pre-processing module separates the HRRS image into multiple aspects by overlapping 75% using the sliding window algorithm. The land cover classification module was developed using the convolutional neural network (CNN) concept, based the FusionNet network and used to assign a land cover type to the separated HRRS images. Post-processing module determines ultimate land cover types by summing up the separated land cover result from the land cover classification module. Model training and validation were conducted to evaluate the performance of the developed model. The land cover maps and orthographic images of 547.29 km2 in area from the Jeonnam province in Korea were used to train the model. For model validation, two spatial and temporal different sites, one from Subuk-myeon of Jeonnam province in 2018 and the other from Daseo-myeon of Chungbuk province in 2016, were randomly chosen. The model performed reasonably well, demonstrating overall accuracies of 0.81 and 0.71, and kappa coefficients of 0.75 and 0.64, for the respective validation sites. The model performance was better when only considering the agricultural area by showing overall accuracy of 0.83 and kappa coefficients of 0.73. It was concluded that the developed model may assist rapid land cover update especially for agricultural areas and incorporation field boundary lineation is suggested as future study to further improve the model accuracy.},
DOI = {10.3390/rs12193171}
}



@Article{rs12193182,
AUTHOR = {Sobejano-Paz, Verónica and Mikkelsen, Teis Nørgaard and Baum, Andreas and Mo, Xingguo and Liu, Suxia and Köppl, Christian Josef and Johnson, Mark S. and Gulyas, Lorant and García, Mónica},
TITLE = {Hyperspectral and Thermal Sensing of Stomatal Conductance, Transpiration, and Photosynthesis for Soybean and Maize under Drought},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3182},
URL = {https://www.mdpi.com/2072-4292/12/19/3182},
ISSN = {2072-4292},
ABSTRACT = {During water stress, crops undertake adjustments in functional, structural, and biochemical traits. Hyperspectral data and machine learning techniques (PLS-R) can be used to assess water stress responses in plant physiology. In this study, we investigated the potential of hyperspectral optical (VNIR) measurements supplemented with thermal remote sensing and canopy height (hc) to detect changes in leaf physiology of soybean (C3) and maize (C4) plants under three levels of soil moisture in controlled environmental conditions. We measured canopy evapotranspiration (ET), leaf transpiration (Tr), leaf stomatal conductance (gs), leaf photosynthesis (A), leaf chlorophyll content and morphological properties (hc and LAI), as well as vegetation cover reflectance and radiometric temperature (TL,Rad). Our results showed that water stress caused significant ET decreases in both crops. This reduction was linked to tighter stomatal control for soybean plants, whereas LAI changes were the primary control on maize ET. Spectral vegetation indices (VIs) and TL,Rad were able to track these different responses to drought, but only after controlling for confounding changes in phenology. PLS-R modeling of gs, Tr, and A using hyperspectral data was more accurate when pooling data from both crops together rather than individually. Nonetheless, separated PLS-R crop models are useful to identify the most relevant variables in each crop such as TL,Rad for soybean and hc for maize under our experimental conditions. Interestingly, the most important spectral bands sensitive to drought, derived from PLS-R analysis, were not exactly centered at the same wavelengths of the studied VIs sensitive to drought, highlighting the benefit of having contiguous narrow spectral bands to predict leaf physiology and suggesting different wavelength combinations based on crop type. Our results are only a first but a promising step towards larger scale remote sensing applications (e.g., airborne and satellite). PLS-R estimates of leaf physiology could help to parameterize canopy level GPP or ET models and to identify different photosynthetic paths or the degree of stomatal closure in response to drought.},
DOI = {10.3390/rs12193182}
}



@Article{rs12193184,
AUTHOR = {Camarretta, Nicolò and A. Harrison, Peter and Lucieer, Arko and M. Potts, Brad and Davidson, Neil and Hunt, Mark},
TITLE = {From Drones to Phenotype: Using UAV-LiDAR to Detect Species and Provenance Variation in Tree Productivity and Structure},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3184},
URL = {https://www.mdpi.com/2072-4292/12/19/3184},
ISSN = {2072-4292},
ABSTRACT = {The use of unmanned aerial vehicles (UAVs) for remote sensing of natural environments has increased over the last decade. However, applications of this technology for high-throughput individual tree phenotyping in a quantitative genetic framework are rare. We here demonstrate a two-phased analytical pipeline that rapidly phenotypes and filters for genetic signals in traditional and novel tree productivity and architectural traits derived from ultra-dense light detection and ranging (LiDAR) point clouds. The goal of this study was rapidly phenotype individual trees to understand the genetic basis of ecologically and economically significant traits important for guiding the management of natural resources. Individual tree point clouds were acquired using UAV-LiDAR captured over a multi-provenance common-garden restoration field trial located in Tasmania, Australia, established using two eucalypt species (Eucalyptus pauciflora and Eucalyptus tenuiramis). Twenty-five tree productivity and architectural traits were calculated for each individual tree point cloud. The first phase of the analytical pipeline found significant species differences in 13 of the 25 derived traits, revealing key structural differences in productivity and crown architecture between species. The second phase investigated the within species variation in the same 25 structural traits. Significant provenance variation was detected for 20 structural traits in E. pauciflora and 10 in E. tenuiramis, with signals of divergent selection found for 11 and 7 traits, respectively, putatively driven by the home-site environment shaping the observed variation. Our results highlight the genetic-based diversity within and between species for traits important for forest structure, such as crown density and structural complexity. As species and provenances are being increasingly translocated across the landscape to mitigate the effects of rapid climate change, our results that were achieved through rapid phenotyping using UAV-LiDAR, raise the need to understand the functional value of productivity and architectural traits reflecting species and provenance differences in crown structure and the interplay they have on the dependent biotic communities.},
DOI = {10.3390/rs12193184}
}



@Article{fishes5040031,
AUTHOR = {Ruiz-García, David and Adams, Kye and Brown, Heidi and Davis, Andrew R.},
TITLE = {Determining Stingray Movement Patterns in a Wave-Swept Coastal Zone Using a Blimp for Continuous Aerial Video Surveillance},
JOURNAL = {Fishes},
VOLUME = {5},
YEAR = {2020},
NUMBER = {4},
PAGES = {31--0},
URL = {https://www.mdpi.com/2410-3888/5/4/31},
ISSN = {2410-3888},
ABSTRACT = {Stingrays play a key role in the regulation of nearshore ecosystems. However, their movement ecology in high-energy surf areas remains largely unknown due to the notorious difficulties in conducting research in these environments. Using a blimp as an aerial platform for video surveillance, we overcame some of the limitations of other tracking methods, such as the use of tags and drones. This novel technology offered near-continuous coverage to characterise the fine-scale movements of stingrays in a surf area in Kiama, Australia, without any invasive procedures. A total of 98 stingray tracks were recorded, providing 6 h 27 min of movement paths. The tracking data suggest that stingrays may use a depth gradient located in the sandflat area of the bay for orientating their movements and transiting between locations within their home range. Our research also indicates that stingray behaviour was influenced by diel periods and tidal states. We observed a higher stingray occurrence during the afternoon, potentially related to foraging and anti-predatory strategies. We also saw a reduced route fidelity during low tide, when the bathymetric reference was less accessible due to stranding risk. Considering the increasing threat of anthropogenic development to nearshore coastal environments, the identification of these patterns can better inform the management and mitigation of threats.},
DOI = {10.3390/fishes5040031}
}



@Article{app10196881,
AUTHOR = {Ciaburro, Giuseppe and Iannace, Gino and Puyana-Romero, Virginia and Trematerra, Amelia},
TITLE = {A Comparison between Numerical Simulation Models for the Prediction of Acoustic Behavior of Giant Reeds Shredded},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {6881},
URL = {https://www.mdpi.com/2076-3417/10/19/6881},
ISSN = {2076-3417},
ABSTRACT = {Giant reeds represent a natural fiber widely available in some areas of the world. Its use can be particularly useful as the uncontrolled growth of giant reeds can be a problem because large areas are invaded by them and the crops are damaged. In this study, two models of numerical simulation of the acoustic behavior of giant reeds were put in comparison: the Hamet model and a model based on artificial neural networks. First, the characteristics of the reeds were examined and the procedures for the preparation of the samples to be analyzed were described. Then air flow resistance, porosity and sound absorption coefficient were measured and analyzed in detail. Finally, the results of the numerical modeling of the acoustic coefficient were compared. The neural network-based model showed high Pearson correlation coefficient value, indicating a large number of correct predictions.},
DOI = {10.3390/app10196881}
}



@Article{agriculture10100451,
AUTHOR = {López-Calderón, Magali J. and Estrada-Ávalos, Juan and Rodríguez-Moreno, Víctor M. and Mauricio-Ruvalcaba, Jorge E. and Martínez-Sifuentes, Aldo R. and Delgado-Ramírez, Gerardo and Miguel-Valle, Enrique},
TITLE = {Estimation of Total Nitrogen Content in Forage Maize (Zea mays L.) Using Spectral Indices: Analysis by Random Forest},
JOURNAL = {Agriculture},
VOLUME = {10},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {451},
URL = {https://www.mdpi.com/2077-0472/10/10/451},
ISSN = {2077-0472},
ABSTRACT = {Knowing the total Nitrogen content (Nt) of forage maize (Zea mays) is important so that decisions can be made quickly and efficiently to adjust the timing and amount of both irrigation and fertilizer. In 2017 and 2018 during three growing cycles in two study plots, leaf samples were collected and the Dumas method was used to estimate Nt. During the same growing seasons and on the same sampling plots, a Parrot Sequoia camera mounted on an unmanned aerial vehicle (UAV) was used to collect high resolution images of forage maize study plots. Thirteen multispectral indices were generated and, from these, a Random Forest (RF) algorithm was used to estimate Nt. RF is a machine-learning technique and is designed to work with extremely large datasets. Overall analysis showed five of the 13 indices as the most important. One of these five, the Transformed Chlorophyll Absorption in Reflectance Index/Optimized Soil-Adjusted Vegetation Index, was found to be the most important for estimation of Nt in forage maize (R2 = 0.76). RF handled the complex dataset in a time-efficient manner and Nt did not differ significantly when compared between traditional methods of evaluating Nt at the canopy level and using UAVs and RF to estimate Nt in forage maize. This result is an opportunity to explore many new research options in precision farming and digital agriculture.},
DOI = {10.3390/agriculture10100451}
}



@Article{rs12193206,
AUTHOR = {Esfandiari, Morteza and Abdi, Ghasem and Jabari, Shabnam and McGrath, Heather and Coleman, David},
TITLE = {Flood Hazard Risk Mapping Using a Pseudo Supervised Random Forest},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3206},
URL = {https://www.mdpi.com/2072-4292/12/19/3206},
ISSN = {2072-4292},
ABSTRACT = {Devastating floods occur regularly around the world. Recently, machine learning models have been used for flood susceptibility mapping. However, even when these algorithms are provided with adequate ground truth training samples, they can fail to predict flood extends reliably. On the other hand, the height above nearest drainage (HAND) model can produce flood prediction maps with limited accuracy. The objective of this research is to produce an accurate and dynamic flood modeling technique to produce flood maps as a function of water level by combining the HAND model and machine learning. In this paper, the HAND model was utilized to generate a preliminary flood map; then, the predictions of the HAND model were used to produce pseudo training samples for a R.F. model. To improve the R.F. training stage, five of the most effective flood mapping conditioning factors are used, namely, Altitude, Slope, Aspect, Distance from River and Land use/cover map. In this approach, the R.F. model is trained to dynamically estimate the flood extent with the pseudo training points acquired from the HAND model. However, due to the limited accuracy of the HAND model, a random sample consensus (RANSAC) method was used to detect outliers. The accuracy of the proposed model for flood extent prediction, was tested on different flood events in the city of Fredericton, NB, Canada in 2014, 2016, 2018, 2019. Furthermore, to ensure that the proposed model can produce accurate flood maps in other areas as well, it was also tested on the 2019 flood in Gatineau, QC, Canada. Accuracy assessment metrics, such as overall accuracy, Cohen&rsquo;s kappa coefficient, Matthews correlation coefficient, true positive rate (TPR), true negative rate (TNR), false positive rate (FPR) and false negative rate (FNR), were used to compare the predicted flood extent of the study areas, to the extent estimated by the HAND model and the extent imaged by Sentinel-2 and Landsat satellites. The results confirm that the proposed model can improve the flood extent prediction of the HAND model without using any ground truth training data.},
DOI = {10.3390/rs12193206}
}



@Article{rs12193208,
AUTHOR = {Chen, Jian and Zhang, Zichao and Zhang, Kai and Wang, Shubo and Han, Yu},
TITLE = {UAV-Borne LiDAR Crop Point Cloud Enhancement Using Grasshopper Optimization and Point Cloud Up-Sampling Network},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3208},
URL = {https://www.mdpi.com/2072-4292/12/19/3208},
ISSN = {2072-4292},
ABSTRACT = {Because of low accuracy and density of crop point clouds obtained by the Unmanned Aerial Vehicle (UAV)-borne Light Detection and Ranging (LiDAR) scanning system of UAV, an integrated navigation and positioning optimization method based on the grasshopper optimization algorithm (GOA) and a point cloud density enhancement method were proposed. Firstly, a global positioning system (GPS)/inertial navigation system (INS) integrated navigation and positioning information fusion method based on a Kalman filter was constructed. Then, the GOA was employed to find the optimal solution by iterating the system noise variance matrix Q and measurement noise variance matrix R of Kalman filter. By feeding the optimal solution into the Kalman filter, the error variances of longitude were reduced to 0.00046 from 0.0091, and the error variances of latitude were reduced to 0.00034 from 0.0047. Based on the integrated navigation, an UAV-borne LiDAR scanning system was built for obtaining the crop point. During offline processing, the crop point cloud was filtered and transformed into WGS-84, the density clustering algorithm improved by the particle swarm optimization (PSO) algorithm was employed to the clustering segment. After the clustering segment, the pre-trained Point Cloud Up-Sampling Network (PU-net) was used for density enhancement of point cloud data and to carry out three-dimensional reconstruction. The features of the crop point cloud were kept under the processing of reconstruction model; meanwhile, the density of the crop point cloud was quadrupled.},
DOI = {10.3390/rs12193208}
}



@Article{s20195630,
AUTHOR = {Xie, Jingyi and Peng, Xiaodong and Wang, Haijiao and Niu, Wenlong and Zheng, Xiao},
TITLE = {UAV Autonomous Tracking and Landing Based on Deep Reinforcement Learning Strategy},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {5630},
URL = {https://www.mdpi.com/1424-8220/20/19/5630},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicle (UAV) autonomous tracking and landing is playing an increasingly important role in military and civil applications. In particular, machine learning has been successfully introduced to robotics-related tasks. A novel UAV autonomous tracking and landing approach based on a deep reinforcement learning strategy is presented in this paper, with the aim of dealing with the UAV motion control problem in an unpredictable and harsh environment. Instead of building a prior model and inferring the landing actions based on heuristic rules, a model-free method based on a partially observable Markov decision process (POMDP) is proposed. In the POMDP model, the UAV automatically learns the landing maneuver by an end-to-end neural network, which combines the Deep Deterministic Policy Gradients (DDPG) algorithm and heuristic rules. A Modular Open Robots Simulation Engine (MORSE)-based reinforcement learning framework is designed and validated with a continuous UAV tracking and landing task on a randomly moving platform in high sensor noise and intermittent measurements. The simulation results show that when the moving platform is moving in different trajectories, the average landing success rate of the proposed algorithm is about 10% higher than that of the Proportional-Integral-Derivative (PID) method. As an indirect result, a state-of-the-art deep reinforcement learning-based UAV control method is validated, where the UAV can learn the optimal strategy of a continuously autonomous landing and perform properly in a simulation environment.},
DOI = {10.3390/s20195630}
}



@Article{land9100368,
AUTHOR = {Esmali Ouri, Abazar and Golshan, Mohammad and Janizadeh, Saeid and Cerdà, Artemi and Melesse, Assefa M.},
TITLE = {Soil Erosion Susceptibility Mapping in Kozetopraghi Catchment, Iran: A Mixed Approach Using Rainfall Simulator and Data Mining Techniques},
JOURNAL = {Land},
VOLUME = {9},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {368},
URL = {https://www.mdpi.com/2073-445X/9/10/368},
ISSN = {2073-445X},
ABSTRACT = {Soil erosion determines landforms, soil formation and distribution, soil fertility, and land degradation processes. In arid and semiarid ecosystems, soil erosion is a key process to understand, foresee, and prevent desertification. Addressing soil erosion throughout watersheds scales requires basic information to develop soil erosion control strategies and to reduce land degradation. To assess and remediate the non-sustainable soil erosion rates, restoration programs benefit from the knowledge of the spatial distribution of the soil losses to develop maps of soil erosion. This study presents Support Vector Machine (SVM), Random Forest (RF), and adaptive boosting (AdaBoost) data mining models to map soil erosion susceptibility in Kozetopraghi watershed, Iran. A soil erosion inventory map was prepared from field rainfall simulation experiments on 174 randomly selected points along the Kozetopraghi watershed. In previous studies, this map has been prepared using indirect methods such as the Universal Soil Loss Equation to assess soil erosion. Direct field measurements for mapping soil erosion susceptibility have so far not been carried out in our study site in the past. The soil erosion rate data generated by simulated rainfall in 1 m2 plots at rainfall rate of 40 mmh&minus;1 was used to develop the soil erosion map. Of the available data, 70% and 30% were randomly classified to calibrate and validate the models, respectively. As a result, the RF model with the highest area under the curve (AUC) value in a receiver operating characteristics (ROC) curve (0.91), and the lowest mean square error (MSE) value (0.09), has the most concordance and spatial differentiation. Sensitivity analysis by Jackknife and IncNodePurity methods indicates that the slope angle is the most important factor within the soil erosion susceptibility map. The RF susceptibility map showed that the areas located in the center and near the watershed outlet have the most susceptibility to soil erosion. This information can be used to support the development of sustainable restoration plans with more accuracy. Our methodology has been evaluated and can be also applied in other regions.},
DOI = {10.3390/land9100368}
}



@Article{rs12193216,
AUTHOR = {Maimaitiyiming, Matthew and Sagan, Vasit and Sidike, Paheding and Maimaitijiang, Maitiniyazi and Miller, Allison J. and Kwasniewski, Misha},
TITLE = {Leveraging Very-High Spatial Resolution Hyperspectral and Thermal UAV Imageries for Characterizing Diurnal Indicators of Grapevine Physiology},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3216},
URL = {https://www.mdpi.com/2072-4292/12/19/3216},
ISSN = {2072-4292},
ABSTRACT = {Efficient and accurate methods to monitor crop physiological responses help growers better understand crop physiology and improve crop productivity. In recent years, developments in unmanned aerial vehicles (UAV) and sensor technology have enabled image acquisition at very-high spectral, spatial, and temporal resolutions. However, potential applications and limitations of very-high-resolution (VHR) hyperspectral and thermal UAV imaging for characterization of plant diurnal physiology remain largely unknown, due to issues related to shadow and canopy heterogeneity. In this study, we propose a canopy zone-weighting (CZW) method to leverage the potential of VHR (&le;9 cm) hyperspectral and thermal UAV imageries in estimating physiological indicators, such as stomatal conductance (Gs) and steady-state fluorescence (Fs). Diurnal flights and concurrent in-situ measurements were conducted during grapevine growing seasons in 2017 and 2018 in a vineyard in Missouri, USA. We used neural net classifier and the Canny edge detection method to extract pure vine canopy from the hyperspectral and thermal images, respectively. Then, the vine canopy was segmented into three canopy zones (sunlit, nadir, and shaded) using K-means clustering based on the canopy shadow fraction and canopy temperature. Common reflectance-based spectral indices, sun-induced chlorophyll fluorescence (SIF), and simplified canopy water stress index (siCWSI) were computed as image retrievals. Using the coefficient of determination (R2) established between the image retrievals from three canopy zones and the in-situ measurements as a weight factor, weighted image retrievals were calculated and their correlation with in-situ measurements was explored. The results showed that the most frequent and the highest correlations were found for Gs and Fs, with CZW-based Photochemical reflectance index (PRI), SIF, and siCWSI (PRICZW, SIFCZW, and siCWSICZW), respectively. When all flights combined for the given field campaign date, PRICZW, SIFCZW, and siCWSICZW significantly improved the relationship with Gs and Fs. The proposed approach takes full advantage of VHR hyperspectral and thermal UAV imageries, and suggests that the CZW method is simple yet effective in estimating Gs and Fs.},
DOI = {10.3390/rs12193216}
}



@Article{rs12193222,
AUTHOR = {Gargiulo, Juan and Clark, Cameron and Lyons, Nicolas and de Veyrac, Gaspard and Beale, Peter and Garcia, Sergio},
TITLE = {Spatial and Temporal Pasture Biomass Estimation Integrating Electronic Plate Meter, Planet CubeSats and Sentinel-2 Satellite Data},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3222},
URL = {https://www.mdpi.com/2072-4292/12/19/3222},
ISSN = {2072-4292},
ABSTRACT = {There is a substantial opportunity to lift feed utilization and profitability on pasture-based dairy systems through both increased pasture monitoring accuracy and frequency. The first objective of this experiment was to determine the impact of the number of electronic rising plate meter (RPM) readings and walking pattern on the accuracy of the RPM to determine pasture biomass. The second objective was to evaluate current satellite technology (i.e., small CubeSats and traditional large satellites) in combination with the electronic RPM as an accurate tool for systematic pasture monitoring. The experiment was conducted from October to December 2019 at Camden, Australia. Two experimental paddocks, each of 1.1 ha, were sown with annual ryegrass and monitored with an electronic RPM integrated with Global Navigation Satellite System and with two different satellites (Planet CubeSats and Sentinel-2 satellite). Here we show that 70 RPM readings achieve a &plusmn; 5% error in the pasture biomass estimations (kg DM/ha), with no effect of the walking pattern on accuracy. The normalized difference vegetation index (NDVI) derived from satellites showed a good correlation with pasture biomass estimated using the electronic RPM (R2 0.74&ndash;0.94). Satellite pasture biomass and growth rate estimations were similar to RPM in one regrowth period but underestimated by &asymp;20% in the other. Our results also reveal that the accuracy of uncalibrated satellites (i.e., biomass estimated using NDVI to kg DM/ha standard equations) is low (R2 0.61, RMSE 566&ndash;1307 kg DM/ha). However, satellites calibrated with a RPM showed greater accuracy in the estimations (R2 0.72, RMSE 255 kg DM/ha). Current satellite technology, when used with the electronic RPM, has the potential to not only reduce the time required to monitor pasture biomass manually but provide finer scale measurements of pasture biomass within paddocks. Further work is required to test this hypothesis, both spatially and temporally.},
DOI = {10.3390/rs12193222}
}



@Article{rs12193228,
AUTHOR = {Qiu, Zhengchao and Xiang, Haitao and Ma, Fei and Du, Changwen},
TITLE = {Qualifications of Rice Growth Indicators Optimized at Different Growth Stages Using Unmanned Aerial Vehicle Digital Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3228},
URL = {https://www.mdpi.com/2072-4292/12/19/3228},
ISSN = {2072-4292},
ABSTRACT = {The accurate estimation of the key growth indicators of rice is conducive to rice production, and the rapid monitoring of these indicators can be achieved through remote sensing using the commercial RGB cameras of unmanned aerial vehicles (UAVs). However, the method of using UAV RGB images lacks an optimized model to achieve accurate qualifications of rice growth indicators. In this study, we established a correlation between the multi-stage vegetation indices (VIs) extracted from UAV imagery and the leaf dry biomass, leaf area index, and leaf total nitrogen for each growth stage of rice. Then, we used the optimal VI (OVI) method and object-oriented segmentation (OS) method to remove the noncanopy area of the image to improve the estimation accuracy. We selected the OVI and the models with the best correlation for each growth stage to establish a simple estimation model database. The results showed that the OVI and OS methods to remove the noncanopy area can improve the correlation between the key growth indicators and VI of rice. At the tillering stage and early jointing stage, the correlations between leaf dry biomass (LDB) and the Green Leaf Index (GLI) and Red Green Ratio Index (RGRI) were 0.829 and 0.881, respectively; at the early jointing stage and late jointing stage, the coefficient of determination (R2) between the Leaf Area Index (LAI) and Modified Green Red Vegetation Index (MGRVI) was 0.803 and 0.875, respectively; at the early stage and the filling stage, the correlations between the leaf total nitrogen (LTN) and UAV vegetation index and the Excess Red Vegetation Index (ExR) were 0.861 and 0.931, respectively. By using the simple estimation model database established using the UAV-based VI and the measured indicators at different growth stages, the rice growth indicators can be estimated for each stage. The proposed estimation model database for monitoring rice at the different growth stages is helpful for improving the estimation accuracy of the key rice growth indicators and accurately managing rice production.},
DOI = {10.3390/rs12193228}
}



@Article{rs12193233,
AUTHOR = {Meng, Ran and Lv, Zhengang and Yan, Jianbing and Chen, Gengshen and Zhao, Feng and Zeng, Linglin and Xu, Binyuan},
TITLE = {Development of Spectral Disease Indices for Southern Corn Rust Detection and Severity Classification},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3233},
URL = {https://www.mdpi.com/2072-4292/12/19/3233},
ISSN = {2072-4292},
ABSTRACT = {Southern Corn Rust (SCR) is one of the most destructive diseases in corn production, significantly affecting corn quality and yields globally. Field-based fast, nondestructive diagnosis of SCR is critical for smart agriculture applications to reduce pesticide use and ensure food safety. The development of spectral disease indices (SDIs), based on in situ leaf reflectance spectra, has proven to be an effective method in detecting plant diseases in the field. However, little is known about leaf spectral signatures that can assist in the accurate diagnosis of SCR, and no SDIs-based model has been reported for the field-based SCR monitoring. Here, to address those issues, we developed SDIs-based monitoring models to detect SCR-infected leaves and classify SCR damage severity. In detail, we first collected in situ leaf reflectance spectra (350&ndash;2500 nm) of healthy and infected corn plants with three severity levels (light, medium, and severe) using a portable spectrometer. Then, the RELIEF-F algorithm was performed to select the most discriminative features (wavelengths) and two band normalized differences for developing SDIs (i.e., health index and severity index) in SCR detection and severity classification, respectively. The leaf reflectance spectra, most sensitive to SCR detection and severity classification, were found in the 572 nm, 766 nm, and 1445 nm wavelength and 575 nm, 640 nm, and 1670 nm wavelength, respectively. These spectral features were associated with leaf pigment and leaf water content. Finally, by employing a support vector machine (SVM), the performances of developed SCR-SDIs were assessed and compared with 38 stress-related vegetation indices (VIs) identified in the literature. The SDIs-based models developed in this study achieved an overall accuracy of 87% and 70% in SCR detection and severity classification, 1.1% and 8.3% higher than the other best VIs-based model under study, respectively. Our results thus suggest that the SCR-SDIs is a promising tool for fast, nondestructive diagnosis of SCR in the field over large areas. To our knowledge, this study represents one of the first few efforts to provide a theoretical basis for remote sensing of SCR at field and larger scales. With the increasing use of unmanned aerial vehicles (UAVs) with hyperspectral measurement capability, more studies should be conducted to expand our developed SCR-SDIs for SCR monitoring at different study sites and growing stages in the future.},
DOI = {10.3390/rs12193233}
}



@Article{electronics9101640,
AUTHOR = {Khan, Usman Ali and Lee, Sang Sun},
TITLE = {Distance-Based Resource Allocation for Vehicle-to-Pedestrian Safety Communication},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {1640},
URL = {https://www.mdpi.com/2079-9292/9/10/1640},
ISSN = {2079-9292},
ABSTRACT = {Cellular Vehicle to Everything (V2X) has redefined the vehicular communication architecture as something that needs an ultra-reliable link, high capacity, and fast message delivery in vehicular networks. The V2X scenarios are broadly categorized as Vehicle to Vehicle (V2V), Vehicle to Infrastructure (V2I), Vehicle to Pedestrians (V2P), and Vehicle to Network (V2N). Vulnerable pedestrians belong to the V2P category and hence require an ultra-reliable link and a fast message delivery in case the moving vehicle is in the close proximity of the pedestrian. However, congestion in the network calls for an optimized resource allocation that would allow a fast and secure connection between a vehicle and the pedestrian. In this paper, we have proposed a distance-based resource allocation that classifies the pedestrians in different categories, performs a one-to-many weighted bipartite matching, and finally a reinforcement learning based power allocation.},
DOI = {10.3390/electronics9101640}
}



@Article{s20195676,
AUTHOR = {Kim, Jisung and Jeong, Youngdo and Lee, Hyojin and Yun, Hongsik},
TITLE = {Marker-Based Structural Displacement Measurement Models with Camera Movement Error Correction Using Image Matching and Anomaly Detection},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {5676},
URL = {https://www.mdpi.com/1424-8220/20/19/5676},
ISSN = {1424-8220},
ABSTRACT = {To prevent collapse accidents at construction sites, the marker-based displacement measurement method was developed. However, it has difficulty in obtaining accurate measurements at long distances (&gt;50 m) in an outdoor environment because of camera movements. To overcome this problem, marker-based structural displacement measurement models using image matching and anomaly detection were designed in this study. Then, the performance of each model in terms of camera movement error correction was verified through comparison with that of a conventional model. The results show that the systematic errors due to camera movements (&lt;1.7&deg;) were corrected. The detection rate of markers with displacement reached 95%, and the probability that the error size would be less than 10 mm was &ge; 95% with a 95% confidence interval at a distance of more than 100 m. Moreover, the normalized mean square error was less than 0.1. The models developed in this study can measure the pure displacement of an object without the systematic errors caused by camera movements. Furthermore, these models can be used to measure the displacements of distant structures using closed-circuit television cameras and markers in an outdoor environment with high accuracy.},
DOI = {10.3390/s20195676}
}



@Article{rs12193237,
AUTHOR = {Osco, Lucas Prado and Junior, José Marcato and Ramos, Ana Paula Marques and Furuya, Danielle Elis Garcia and Santana, Dthenifer Cordeiro and Teodoro, Larissa Pereira Ribeiro and Gonçalves, Wesley Nunes and Baio, Fábio Henrique Rojo and Pistori, Hemerson and Junior, Carlos Antonio da Silva and Teodoro, Paulo Eduardo},
TITLE = {Leaf Nitrogen Concentration and Plant Height Prediction for Maize Using UAV-Based Multispectral Imagery and Machine Learning Techniques},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3237},
URL = {https://www.mdpi.com/2072-4292/12/19/3237},
ISSN = {2072-4292},
ABSTRACT = {Under ideal conditions of nitrogen (N), maize (Zea mays L.) can grow to its full potential, reaching maximum plant height (PH). As a rapid and nondestructive approach, the analysis of unmanned aerial vehicles (UAV)-based imagery may be of assistance to estimate N and height. The main objective of this study is to present an approach to predict leaf nitrogen concentration (LNC, g kg&minus;1) and PH (m) with machine learning techniques and UAV-based multispectral imagery in maize plants. An experiment with 11 maize cultivars under two rates of N fertilization was carried during the 2017/2018 and 2018/2019 crop seasons. The spectral vegetation indices (VI) normalized difference vegetation index (NDVI), normalized difference red-edge index (NDRE), green normalized difference vegetation (GNDVI), and the soil adjusted vegetation index (SAVI) were extracted from the images and, in a computational system, used alongside the spectral bands as input parameters for different machine learning models. A randomized 10-fold cross-validation strategy, with a total of 100 replicates, was used to evaluate the performance of 9 supervised machine learning (ML) models using the Pearson&rsquo;s correlation coefficient (r), mean absolute error (MAE), coefficient of regression (R&sup2;), and root mean square error (RMSE) metrics. The results indicated that the random forest (RF) algorithm performed better, with r and RMSE, respectively, of 0.91 and 1.9 g.kg&minus;&sup1; for LNC, and 0.86 and 0.17 m for PH. It was also demonstrated that VIs contributed more to the algorithm&rsquo;s performances than individual spectral bands. This study concludes that the RF model is appropriate to predict both agronomic variables in maize and may help farmers to monitor their plants based upon their LNC and PH diagnosis and use this knowledge to improve their production rates in the subsequent seasons.},
DOI = {10.3390/rs12193237}
}



@Article{rs12193265,
AUTHOR = {Sonobe, Rei and Yamashita, Hiroto and Mihara, Harumi and Morita, Akio and Ikka, Takashi},
TITLE = {Estimation of Leaf Chlorophyll a, b and Carotenoid Contents and Their Ratios Using Hyperspectral Reflectance},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {3265},
URL = {https://www.mdpi.com/2072-4292/12/19/3265},
ISSN = {2072-4292},
ABSTRACT = {Japanese horseradish (wasabi) grows in very specific conditions, and recent environmental climate changes have damaged wasabi production. In addition, the optimal culture methods are not well known, and it is becoming increasingly difficult for incipient farmers to cultivate it. Chlorophyll a, b and carotenoid contents, as well as their allocation, could be an adequate indicator in evaluating its production and environmental stress; thus, developing an in situ method to monitor photosynthetic pigments based on reflectance could be useful for agricultural management. Besides original reflectance (OR), five pre-processing techniques, namely, first derivative reflectance (FDR), continuum-removed (CR), de-trending (DT), multiplicative scatter correction (MSC), and standard normal variate transformation (SNV), were compared to assess the accuracy of the estimation. Furthermore, five machine learning algorithms&mdash;random forest (RF), support vector machine (SVM), kernel-based extreme learning machine (KELM), Cubist, and Stochastic Gradient Boosting (SGB)&mdash;were considered. To classify the samples under different pH or sulphur ion concentration conditions, the end of the red edge bands was effective for OR, FDR, DT, MSC, and SNV, while a green-peak band was effective for CR. Overall, KELM and Cubist showed high performance and incorporating pre-processing techniques was effective for obtaining estimated values with high accuracy. The best combinations were found to be DT&ndash;KELM for chl a (RPD = 1.511&ndash;5.17, RMSE = 1.23&ndash;3.62 &mu;g cm&minus;2) and chl a:b (RPD = 0.73&ndash;3.17, RMSE = 0.13&ndash;0.60); CR&ndash;KELM for chl b (RPD = 1.92&ndash;5.06, RMSE = 0.41&ndash;1.03 &mu;g cm&minus;2) and chl a:car (RPD = 1.31&ndash;3.23, RMSE = 0.26&ndash;0.50); SNV&ndash;Cubist for car (RPD = 1.63&ndash;3.32, RMSE = 0.31&ndash;1.89 &mu;g cm&minus;2); and DT&ndash;Cubist for chl:car (RPD = 1.53&ndash;3.96, RMSE = 0.27&ndash;0.74).},
DOI = {10.3390/rs12193265}
}



@Article{drones4040067,
AUTHOR = {Humpe, Andreas},
TITLE = {Bridge Inspection with an Off-the-Shelf 360° Camera Drone},
JOURNAL = {Drones},
VOLUME = {4},
YEAR = {2020},
NUMBER = {4},
ARTICLE-NUMBER = {67},
URL = {https://www.mdpi.com/2504-446X/4/4/67},
ISSN = {2504-446X},
ABSTRACT = {The author proposes a new approach for bridge crack detection by a 360&deg; camera on top of a drone. Traditionally, bridge inspection is performed manually and although the use of drones has been implemented before, researchers used standard high definition cameras underneath the drone. To make the approach comparable to the conventional approach, two bridges were selected in Germany and inspected for cracks and defects by applying both methods. The author follows an engineering design process and after developing a prototype of the drone with a 360&deg; camera above the body of the drone, the system is built, tested, and the bridges are inspected. First, the critical parts of the bridges are inspected with an off-the-shelf drone with a high definition camera underneath the drone. The results provide a benchmark for comparison. Next, the new approach to bridge inspection by using a 360&deg; camera on top of the drone is tested. The images of the critical parts of the bridge that were taken with the 360&deg; camera on top of the drone are analyzed and compared to the images of the conventional approach with the camera underneath the drone. The results show that a 360&deg; camera can be used for crack and defect detection with similar results to a standard high definition camera. Furthermore, the 360&deg; camera is more suitable for inspecting corners or the ceiling of, e.g., an arch bridge.},
DOI = {10.3390/drones4040067}
}



@Article{s20205762,
AUTHOR = {Santos, André A. and Rocha, Filipe A. S. and Reis, Agnaldo J. da R. and Guimarães, Frederico G.},
TITLE = {Automatic System for Visual Detection of Dirt Buildup on Conveyor Belts Using Convolutional Neural Networks},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {5762},
URL = {https://www.mdpi.com/1424-8220/20/20/5762},
ISSN = {1424-8220},
ABSTRACT = {Conveyor belts are the most widespread means of transportation for large quantities of materials in the mining sector. Therefore, autonomous methods that can help human beings to perform the inspection of the belt conveyor system is a major concern for companies. In this context, we present in this work a novel and automatic visual detector that recognizes dirt buildup on the structures of conveyor belts, which is one of the tasks of the maintenance inspectors. This visual detector can be embedded as sensors in autonomous robots for the inspection activity. The proposed system involves training a convolutional neural network from RGB images. The use of the transfer learning technique, i.e., retraining consolidated networks for image classification with our collected images has shown very effective. Two different approaches for transfer learning have been analyzed. The best one presented an average accuracy of 0.8975 with an F-1 Score of 0.8773 for the dirt recognition. A field validation experiment served to evaluate the performance of the proposed system in a real time classification task.},
DOI = {10.3390/s20205762}
}



@Article{rs12203328,
AUTHOR = {Imangholiloo, Mohammad and Saarinen, Ninni and Holopainen, Markus and Yu, Xiaowei and Hyyppä, Juha and Vastaranta, Mikko},
TITLE = {Using Leaf-Off and Leaf-On Multispectral Airborne Laser Scanning Data to Characterize Seedling Stands},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {3328},
URL = {https://www.mdpi.com/2072-4292/12/20/3328},
ISSN = {2072-4292},
ABSTRACT = {Information from seedling stands in time and space is essential for sustainable forest management. To fulfil these informational needs with limited resources, remote sensing is seen as an intriguing alternative for forest inventorying. The structure and tree species composition in seedling stands have created challenges for capturing this information using sensors providing sparse point densities that do not have the ability to penetrate canopy gaps or provide spectral information. Therefore, multispectral airborne laser scanning (mALS) systems providing dense point clouds coupled with multispectral intensity data theoretically offer advantages for the characterization of seedling stands. The aim of this study was to investigate the capability of Optech Titan mALS data to characterize seedling stands in leaf-off and leaf-on conditions, as well as to retrieve the most important forest inventory attributes, such as distinguishing deciduous from coniferous trees, and estimating tree density and height. First, single-tree detection approaches were used to derive crown boundaries and tree heights from which forest structural attributes were aggregated for sample plots. To predict tree species, a random forests classifier was trained using features from two single-channel intensities (SCIs) with wavelengths of 1550 (SCI-Ch1) and 1064 nm (SCI-Ch2), and multichannel intensity (MCI) data composed of three mALS channels. The most important and uncorrelated features were analyzed and selected from 208 features. The highest overall accuracies in classification of Norway spruce, birch, and nontree class in leaf-off and leaf-on conditions obtained using SCI-Ch1 and SCI-Ch2 were 87.36% and 69.47%, respectively. The use of MCI data improved classification by up to 96.55% and 92.54% in leaf-off and leaf-on conditions, respectively. Overall, leaf-off data were favorable for distinguishing deciduous from coniferous trees and tree density estimation with a relative root mean square error (RMSE) of 37.9%, whereas leaf-on data provided more accurate height estimations, with a relative RMSE of 10.76%. Determining the canopy threshold for separating ground returns from vegetation returns was found to be critical, as mapped trees might have a height below one meter. The results showed that mALS data provided benefits for characterizing seedling stands compared to single-channel ALS systems.},
DOI = {10.3390/rs12203328}
}



@Article{app10207120,
AUTHOR = {Mohammed, Thaha and Albeshri, Aiiad and Katib, Iyad and Mehmood, Rashid},
TITLE = {UbiPriSEQ—Deep Reinforcement Learning to Manage Privacy, Security, Energy, and QoS in 5G IoT HetNets},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {7120},
URL = {https://www.mdpi.com/2076-3417/10/20/7120},
ISSN = {2076-3417},
ABSTRACT = {5G networks and Internet of Things (IoT) offer a powerful platform for ubiquitous environments with their ubiquitous sensing, high speeds and other benefits. The data, analytics, and other computations need to be optimally moved and placed in these environments, dynamically, such that energy-efficiency and QoS demands are best satisfied. A particular challenge in this context is to preserve privacy and security while delivering quality of service (QoS) and energy-efficiency. Many works have tried to address these challenges but without a focus on optimizing all of them and assuming fixed models of environments and security threats. This paper proposes the UbiPriSEQ framework that uses Deep Reinforcement Learning (DRL) to adaptively, dynamically, and holistically optimize QoS, energy-efficiency, security, and privacy. UbiPriSEQ is built on a three-layered model and comprises two modules. UbiPriSEQ devises policies and makes decisions related to important parameters including local processing and offloading rates for data and computations, radio channel states, transmit power, task priority, and selection of fog nodes for offloading, data migration, and so forth. UbiPriSEQ is implemented in Python over the TensorFlow platform and is evaluated using a real-life application in terms of SINR, privacy metric, latency, and utility function, manifesting great promise.},
DOI = {10.3390/app10207120}
}



@Article{rs12203360,
AUTHOR = {Esteban, Jessica and McRoberts, Ronald E. and Fernández-Landa, Alfredo and Tomé, José Luis and Marchamalo, Miguel},
TITLE = {A Model-Based Volume Estimator that Accounts for Both Land Cover Misclassification and Model Prediction Uncertainty},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {3360},
URL = {https://www.mdpi.com/2072-4292/12/20/3360},
ISSN = {2072-4292},
ABSTRACT = {Forest/non-forest and forest species maps are often used by forest inventory programs in the forest estimation process. For example, some inventory programs establish field plots only on lands corresponding to the forest portion of a forest/non-forest map and use species-specific area estimates obtained from those maps to support the estimation of species-specific volume (V) totals. Despite the general use of these maps, the effects of their uncertainties are commonly ignored with the result that estimates might be unreliable. The goal of this study is to estimate the effects of the uncertainty of forest species maps used in the sampling and estimation processes. Random forest (RF) per-pixel predictions were used with model-based inference to estimate V per unit area for the six main forest species of La Rioja, Spain. RF models for predicting V were constructed using field plot information from the Spanish National Forest Inventory and airborne laser scanning data. To limit the prediction of V to pixels classified as one of the main forest species assessed, a forest species map was constructed using Landsat and auxiliary information. Bootstrapping techniques were implemented to estimate the total uncertainty of the V estimates and accommodated both the effects of uncertainty in the Landsat forest species map and the effects of plot-to-plot sampling variability on training data used to construct the RF V models. Standard errors of species-specific total V estimates increased from 2&ndash;9% to 3&ndash;22% when the effects of map uncertainty were incorporated into the uncertainty assessment. The workflow achieved satisfactory results and revealed that the effects of map uncertainty are not negligible, especially for open-grown and less frequently occurring forest species for which greater variability was evident in the mapping and estimation process. The effects of forest map uncertainty are greater for species-specific area estimation than for the selection of field plots used to calibrate the RF model. Additional research to generalize the conclusions beyond Mediterranean to other forest environments is recommended.},
DOI = {10.3390/rs12203360}
}



@Article{rs12203364,
AUTHOR = {Collins, Adam M. and Brodie, Katherine L. and Bak, Andrew Spicer and Hesser, Tyler J. and Farthing, Matthew W. and Lee, Jonghyun and Long, Joseph W.},
TITLE = {Bathymetric Inversion and Uncertainty Estimation from Synthetic Surf-Zone Imagery with Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {3364},
URL = {https://www.mdpi.com/2072-4292/12/20/3364},
ISSN = {2072-4292},
ABSTRACT = {Resolving surf-zone bathymetry from high-resolution imagery typically involves measuring wave speeds and performing a physics-based inversion process using linear wave theory, or data assimilation techniques which combine multiple remotely sensed parameters with numerical models. In this work, we explored what types of coastal imagery can be best utilized in a 2-dimensional fully convolutional neural network to directly estimate nearshore bathymetry from optical expressions of wave kinematics. Specifically, we explored utilizing time-averaged images (timex) of the surf-zone, which can be used as a proxy for wave dissipation, as well as including a single-frame image input, which has visible patterns of wave refraction and instantaneous expressions of wave breaking. Our results show both types of imagery can be used to estimate nearshore bathymetry. However, the single-frame imagery provides more complete information across the domain, decreasing the error over the test set by approximately 10% relative to using timex imagery alone. A network incorporating both inputs had the best performance, with an overall root-mean-squared-error of 0.39 m. Activation maps demonstrate the additional information provided by the single-frame imagery in non-breaking wave areas which aid in prediction. Uncertainty in model predictions is explored through three techniques (Monte Carlo (MC) dropout, infer-transformation, and infer-noise) to provide additional actionable information about the spatial reliability of each bathymetric prediction.},
DOI = {10.3390/rs12203364}
}



@Article{rs12203392,
AUTHOR = {Dong, Xiancong and Li, Xiaojie and Zheng, Xingming and Jiang, Tao and Li, Xiaofeng},
TITLE = {Effect of Saline Soil Cracks on Satellite Spectral Inversion Electrical Conductivity},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {3392},
URL = {https://www.mdpi.com/2072-4292/12/20/3392},
ISSN = {2072-4292},
ABSTRACT = {The dehydration cracking of saline soil is a kind of common natural phenomenon, and the cracks of saline soil will affect the satellite spectrum, and then affect the accuracy of satellite spectral inversion of electrical conductivity (EC). This study introduces the concept of crack rate (CR) to describe the crack information of saline soil, and quantifies the influence of saline soil crack on the EC of satellite spectral inversion. In 2014 and 2020, the satellite-ground synchronous observation experiments of soda-type inland saline soil and coastal chlorinated-type saline soil were carried out, and the CR of surface cracked saline soil was extracted by an image processing algorithm. For the saline soil spectrum data, the correlation analysis method is used to establish the best band combination that characterizes the relationship between the different saline soil spectrum data and salinity, and the EC inversion model is established using the BP neural network method. The results show that: after the CR is introduced, the determination coefficient (R2) for the EC of soda-type saline soil satellite spectral inversion increased from 0.59 to 0.67, with an increase of 14.42%, and the mean square error (MSE) reduced from 0.20 to 0.16, with a decrease of 19.49%. The R2 for the EC of coastal chlorinated-type saline soil satellite spectral inversion increased from 0.64 to 0.75, an increase of 17.73%, and the MSE decreased from 0.16 to 0.12, a decrease of 25.15%. The study proved the influence of the cracks in the saline soil on the satellite spectrum and provided a new way to improve the accuracy of the satellite spectrum inversion of the EC of the cracked saline soil.},
DOI = {10.3390/rs12203392}
}



@Article{rs12203396,
AUTHOR = {Colorado, Julian D. and Cera-Bornacelli, Natalia and Caldas, Juan S. and Petro, Eliel and Rebolledo, Maria C. and Cuellar, David and Calderon, Francisco and Mondragon, Ivan F. and Jaramillo-Botero, Andres},
TITLE = {Estimation of Nitrogen in Rice Crops from UAV-Captured Images},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {3396},
URL = {https://www.mdpi.com/2072-4292/12/20/3396},
ISSN = {2072-4292},
ABSTRACT = {Leaf nitrogen (N) directly correlates to chlorophyll production, affecting crop growth and yield. Farmers use soil plant analysis development (SPAD) devices to calculate the amount of chlorophyll present in plants. However, monitoring large-scale crops using SPAD is prohibitively time-consuming and demanding. This paper presents an unmanned aerial vehicle (UAV) solution for estimating leaf N content in rice crops, from multispectral imagery. Our contribution is twofold: (i) a novel trajectory control strategy to reduce the angular wind-induced perturbations that affect image sampling accuracy during UAV flight, and (ii) machine learning models to estimate the canopy N via vegetation indices (VIs) obtained from the aerial imagery. This approach integrates an image processing algorithm using the GrabCut segmentation method with a guided filtering refinement process, to calculate the VIs according to the plots of interest. Three machine learning methods based on multivariable linear regressions (MLR), support vector machines (SVM), and neural networks (NN), were applied and compared through the entire phonological cycle of the crop: vegetative (V), reproductive (R), and ripening (Ri). Correlations were obtained by comparing our methods against an assembled ground-truth of SPAD measurements. The higher N correlations were achieved with NN: 0.98 (V), 0.94 (R), and 0.89 (Ri). We claim that the proposed UAV stabilization control algorithm significantly improves on the N-to-SPAD correlations by minimizing wind perturbations in real-time and reducing the need for offline image corrections.},
DOI = {10.3390/rs12203396}
}



@Article{rs12203416,
AUTHOR = {Temitope Yekeen, Shamsudeen and Balogun, Abdul-Lateef},
TITLE = {Advances in Remote Sensing Technology, Machine Learning and Deep Learning for Marine Oil Spill Detection, Prediction and Vulnerability Assessment},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {3416},
URL = {https://www.mdpi.com/2072-4292/12/20/3416},
ISSN = {2072-4292},
ABSTRACT = {Although advancements in remote sensing technology have facilitated quick capture and identification of the source and location of oil spills in water bodies, the presence of other biogenic elements (lookalikes) with similar visual attributes hinder rapid detection and prompt decision making for emergency response. To date, different methods have been applied to distinguish oil spills from lookalikes with limited success. In addition, accurately modeling the trajectory of oil spills remains a challenge. Thus, we aim to provide further insights on the multi-faceted problem by undertaking a holistic review of past and current approaches to marine oil spill disaster reduction as well as explore the potentials of emerging digital trends in minimizing oil spill hazards. The scope of previous reviews is extended by covering the inter-related dimensions of detection, discrimination, and trajectory prediction of oil spills for vulnerability assessment. Findings show that both optical and microwave airborne and satellite remote sensors are used for oil spill monitoring with microwave sensors being more widely used due to their ability to operate under any weather condition. However, the accuracy of both sensors is affected by the presence of biogenic elements, leading to false positive depiction of oil spills. Statistical image segmentation has been widely used to discriminate lookalikes from oil spills with varying levels of accuracy but the emergence of digitalization technologies in the fourth industrial revolution (IR 4.0) is enabling the use of Machine learning (ML) and deep learning (DL) models, which are more promising than the statistical methods. The Support Vector Machine (SVM) and Artificial Neural Network (ANN) are the most used machine learning algorithms for oil spill detection, although the restriction of ML models to feed forward image classification without support for the end-to-end trainable framework limits its accuracy. On the other hand, deep learning models&rsquo; strong feature extraction and autonomous learning capability enhance their detection accuracy. Also, mathematical models based on lagrangian method have improved oil spill trajectory prediction with higher real time accuracy than the conventional worst case, average and survey-based approaches. However, these newer models are unable to quantify oil droplets and uncertainty in vulnerability prediction. Considering that there is yet no single best remote sensing technique for unambiguous detection and discrimination of oil spills and lookalikes, it is imperative to advance research in the field in order to improve existing technology and develop specialized sensors for accurate oil spill detection and enhanced classification, leveraging emerging geospatial computer vision initiatives.},
DOI = {10.3390/rs12203416}
}



@Article{rs12203417,
AUTHOR = {Lantini, Livia and Tosti, Fabio and Giannakis, Iraklis and Zou, Lilong and Benedetto, Andrea and Alani, Amir M.},
TITLE = {An Enhanced Data Processing Framework for Mapping Tree Root Systems Using Ground Penetrating Radar},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {3417},
URL = {https://www.mdpi.com/2072-4292/12/20/3417},
ISSN = {2072-4292},
ABSTRACT = {The preservation of natural assets is nowadays an essential commitment. In this regard, root systems are endangered by fungal diseases which can undermine the health and stability of trees. Within this framework, ground penetrating radar (GPR) is emerging as a reliable non-destructive method for root investigation. A coherent GPR-based root-detection framework is presented in this paper. The proposed methodology is a multi-stage data analysis system that is applied to semi-circular measurements collected around the investigated tree. In the first step, the raw data are processed by applying several standard and advanced signal processing techniques in order to reduce noise-related information. In the second stage, the presence of any discontinuity element within the survey area is investigated by analysing the signal reflectivity. Then, a tracking algorithm aimed at identifying patterns compatible with tree roots is implemented. Finally, the mass density of roots is estimated by means of continuous functions in order to achieve a more realistic representation of the root paths and to identify their length in a continuous and more realistic domain. The method was validated in a case study in London (UK), where the root system of a real tree was surveyed using GPR and a soil test pit was excavated for validation purposes. Results support the feasibility of the data processing framework implemented in this study.},
DOI = {10.3390/rs12203417}
}



@Article{electronics9101714,
AUTHOR = {Park, JiWoong and Nam, SungChan and Choi, HongBeom and Ko, YoungEun and Ko, Young-Bae},
TITLE = {Improving Deep Learning-Based UWB LOS/NLOS Identification with Transfer Learning: An Empirical Approach},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {1714},
URL = {https://www.mdpi.com/2079-9292/9/10/1714},
ISSN = {2079-9292},
ABSTRACT = {This paper presents an improved ultra-wideband (UWB) line of sight (LOS)/non-line of sight (NLOS) identification scheme based on a hybrid method of deep learning and transfer learning. Previous studies have limitations, in that the classification accuracy significantly decreases in an unknown place. To solve this problem, we propose a transfer learning-based NLOS identification method for classifying the NLOS conditions of the UWB signal in an unmeasured environment. Both the multilayer perceptron and convolutional neural network (CNN) are introduced as classifiers for NLOS conditions. We evaluate the proposed scheme by conducting experiments in both measured and unmeasured environments. Channel data were measured using a Decawave EVK1000 in two similar indoor office environments. In the unmeasured environment, the existing CNN method showed an accuracy of approximately 44%, but when the proposed scheme was applied to the CNN, it showed an accuracy of up to 98%. The training time of the proposed scheme was measured to be approximately 48 times faster than that of the existing CNN. When comparing the proposed scheme with learning a new CNN in an unmeasured environment, the proposed scheme demonstrated an approximately 10% higher accuracy and approximately five times faster training time.},
DOI = {10.3390/electronics9101714}
}



@Article{agronomy10101600,
AUTHOR = {Astor, Thomas and Dayananda, Supriya and Nautiyal, Sunil and Wachendorf, Michael},
TITLE = {Vegetable Crop Biomass Estimation Using Hyperspectral and RGB 3D UAV Data},
JOURNAL = {Agronomy},
VOLUME = {10},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {1600},
URL = {https://www.mdpi.com/2073-4395/10/10/1600},
ISSN = {2073-4395},
ABSTRACT = {Remote sensing (RS) has been an effective tool to monitor agricultural production systems, but for vegetable crops, precision agriculture has received less interest to date. The objective of this study was to test the predictive performance of two types of RS data&mdash;crop height information derived from point clouds based on RGB UAV data, and reflectance information from terrestrial hyperspectral imagery&mdash;to predict fresh matter yield (FMY) for three vegetable crops (eggplant, tomato, and cabbage). The study was conducted in an experimental layout in Bengaluru, India, at five dates in summer 2017. The prediction accuracy varied strongly depending on the RS dataset used. For all crops, a good predictive performance with cross-validated prediction error &lt; 10% was achieved. The growth stage of the crops had no significant effect on the prediction accuracy, although increasing trends of an underestimation of FMY with later sampling dates for eggplant and tomato were found. The study proves that an estimation of vegetable FMY using RS data is successful throughout the growing season. Different RS datasets were best for biomass prediction of the three vegetables, indicating that multi-sensory data collection should be preferred to single sensor use, as no one sensor system is superior.},
DOI = {10.3390/agronomy10101600}
}



@Article{s20205904,
AUTHOR = {Digulescu, Angela and Despina-Stoian, Cristina and Stănescu, Denis and Popescu, Florin and Enache, Florin and Ioana, Cornel and Rădoi, Emanuel and Rîncu, Iulian and Șerbănescu, Alexandru},
TITLE = {New Approach of UAV Movement Detection and Characterization Using Advanced Signal Processing Methods Based on UWB Sensing},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {5904},
URL = {https://www.mdpi.com/1424-8220/20/20/5904},
ISSN = {1424-8220},
ABSTRACT = {In the last years, the commercial drone/unmanned aerial vehicles market has grown due to their technological performances (provided by the multiple onboard available sensors), low price, and ease of use. Being very attractive for an increasing number of applications, their presence represents a major issue for public or classified areas with a special status, because of the rising number of incidents. Our paper proposes a new approach for the drone movement detection and characterization based on the ultra-wide band (UWB) sensing system and advanced signal processing methods. This approach characterizes the movement of the drone using classical methods such as correlation, envelope detection, time-scale analysis, but also a new method, the recurrence plot analysis. The obtained results are compared in terms of movement map accuracy and required computation time in order to offer a future starting point for the drone intrusion detection.},
DOI = {10.3390/s20205904}
}



@Article{s20205940,
AUTHOR = {Klaer, Peter and Huang, Andi and Sévigny, Pascale and Rajan, Sreeraman and Pant, Shashank and Patnaik, Prakash and Balaji, Bhashyam},
TITLE = {An Investigation of Rotary Drone HERM Line Spectrum under Manoeuvering Conditions},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {5940},
URL = {https://www.mdpi.com/1424-8220/20/20/5940},
ISSN = {1424-8220},
ABSTRACT = {Detecting and identifying drones is of great interest due to the proliferation of highly manoeuverable drones with on-board sensors of increasing sensing capabilities. In this paper, we investigate the use of radars for tackling this problem. In particular, we focus on the problem of detecting rotary drones and distinguishing between single-propeller and multi-propeller drones using a micro-Doppler analysis. Two different radars were used, an ultra wideband (UWB) continuous wave (CW) C-band radar and an automotive frequency modulated continuous wave (FMCW) W-band radar, to collect micro-Doppler signatures of the drones. By taking a closer look at HElicopter Rotor Modulation (HERM) lines, the spool and chopping lines are identified for the first time in the context of drones to determine the number of propeller blades. Furthermore, a new multi-frequency analysis method using HERM lines is developed, which allows the detection of propeller rotation rates (spool and chopping frequencies) of single and multi-propeller drones. Therefore, the presented method is a promising technique to aid in the classification of drones.},
DOI = {10.3390/s20205940}
}



@Article{rs12213471,
AUTHOR = {Dado, Walter T. and Deines, Jillian M. and Patel, Rinkal and Liang, Sang-Zi and Lobell, David B.},
TITLE = {High-Resolution Soybean Yield Mapping Across the US Midwest Using Subfield Harvester Data},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {3471},
URL = {https://www.mdpi.com/2072-4292/12/21/3471},
ISSN = {2072-4292},
ABSTRACT = {Cloud computing and freely available, high-resolution satellite data have enabled recent progress in crop yield mapping at fine scales. However, extensive validation data at a matching resolution remain uncommon or infeasible due to data availability. This has limited the ability to evaluate different yield estimation models and improve understanding of key features useful for yield estimation in both data-rich and data-poor contexts. Here, we assess machine learning models&rsquo; capacity for soybean yield prediction using a unique ground-truth dataset of high-resolution (5 m) yield maps generated from combine harvester yield monitor data for over a million field-year observations across the Midwestern United States from 2008 to 2018. First, we compare random forest (RF) implementations, testing a range of feature engineering approaches using Sentinel-2 and Landsat spectral data for 20- and 30-m scale yield prediction. We find that Sentinel-2-based models can explain up to 45% of out-of-sample yield variability from 2017 to 2018 (r2 = 0.45), while Landsat models explain up to 43% across the longer 2008&ndash;2018 period. Using discrete Fourier transforms, or harmonic regressions, to capture soybean phenology improved the Landsat-based model considerably. Second, we compare RF models trained using this ground-truth data to models trained on available county-level statistics. We find that county-level models rely more heavily on just a few predictors, namely August weather covariates (vapor pressure deficit, rainfall, temperature) and July and August near-infrared observations. As a result, county-scale models perform relatively poorly on field-scale validation (r2 = 0.32), especially for high-yielding fields, but perform similarly to field-scale models when evaluated at the county scale (r2 = 0.82). Finally, we test whether our findings on variable importance can inform a simple, generalizable framework for regions or time periods beyond ground data availability. To do so, we test improvements to a Scalable Crop Yield Mapper (SCYM) approach that uses crop simulations to train statistical models for yield estimation. Based on findings from our RF models, we employ harmonic regressions to estimate peak vegetation index (VI) and a VI observation 30 days later, with August rainfall as the sole weather covariate in our new SCYM model. Modifications improved SCYM&rsquo;s explained variance (r2 = 0.27 at the 30 m scale) and provide a new, parsimonious model.},
DOI = {10.3390/rs12213471}
}



@Article{agronomy10111624,
AUTHOR = {Husin, Nur A. and Khairunniza-Bejo, Siti and Abdullah, Ahmad F. and Kassim, Muhamad S. M. and Ahmad, Desa and Aziz, Mohd H. A.},
TITLE = {Classification of Basal Stem Rot Disease in Oil Palm Plantations Using Terrestrial Laser Scanning Data and Machine Learning},
JOURNAL = {Agronomy},
VOLUME = {10},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {1624},
URL = {https://www.mdpi.com/2073-4395/10/11/1624},
ISSN = {2073-4395},
ABSTRACT = {The oil palm industry is vital for the Malaysian economy. However, it is threatened by the Ganoderma boninense fungus, which causes basal stem rot (BSR) disease. Foliar symptoms of the disease include the appearance of several unopened spears, flat crowns, and small crown size. The effect of this disease depends on the severity of the infection. Currently, the disease can be detected manually by analyzing the oil palm tree&rsquo;s physical structure. Terrestrial laser scanning (TLS) is an active ranging method that uses laser light, which can directly represent the tree&rsquo;s external structure. This study aimed to classify the healthiness levels of the BSR disease using a machine learning (ML) approach. A total of 80 oil palm trees with four different healthiness levels were pre-determined by the experts during data collection with 40 each for training and testing. The four healthiness levels are T0 (healthy), T1 (mildly infected), T2 (moderately infected), and T3 (severely infected), with 10 trees in each level. A terrestrial scanner was mounted at a height of 1 m, and each oil palm was scanned at four positions at a distance of 1.5 m around the tree. Five tree features were extracted from the TLS data: C200 (crown slice at 200 cm from the top), C850 (crown slice at 850 cm from the top), crown area (number of pixels inside the crown), frond angle, and frond number. C200 and C850 were obtained using the crown stratification method, while the other three features were obtained from the top-down image. The obtained features were then analyzed by principal component analysis (PCA) to reduce the dimensionality of the dataset and increase its interpretability while at the same time minimizing information loss. The results showed that the kernel na&iuml;ve Bayes (KNB) model developed using the input parameters of the principal components (PCs) 1 and 2 had the best performance among 90 other models with a multiple level accuracy of 85% and a Kappa coefficient of 0.80. Furthermore, the combination of the two highest PC variance with the most weighted to frond number, frond angle, crown area, and C200 significantly contributed to the classification success. The model also could classify healthy and mildly infected trees with 100% accuracy. Therefore, it can be concluded that the ML approach using TLS data can be used to predict early BSR infection with high accuracy.},
DOI = {10.3390/agronomy10111624}
}



@Article{atmos11111145,
AUTHOR = {Chen, Hsiu-Ling and Li, Chi-Pei and Tang, Chin-Sheng and Lung, Shih-Chun Candice and Chuang, Hsiao-Chi and Chou, Da-Wei and Chang, Li-Te},
TITLE = {Risk Assessment for People Exposed to PM2.5 and Constituents at Different Vertical Heights in an Urban Area of Taiwan},
JOURNAL = {Atmosphere},
VOLUME = {11},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {1145},
URL = {https://www.mdpi.com/2073-4433/11/11/1145},
ISSN = {2073-4433},
ABSTRACT = {Environmental epidemiological studies have consistently reported associations between ambient particulate matter (PM) concentrations and everyday mortality/morbidity. Many urban dwellers in Asia live in high-rise apartment buildings; thus, the pollutant concentrations of their immediate outdoor environments are affected by the vertical distribution of pollutants in the atmosphere. The vertical distributions of pollutants provide unique information about their sources and dynamic transport in urban areas, as well as their relationship to people&rsquo;s exposure at ground level, while the vertical distributions of pollutants have rarely been considered in exposure assessment. In the current study, PM concentrations (with aerodynamic diameters less than 1.0 &mu;m (PM1), 2.5 &mu;m (PM2.5), and 10 &mu;m (PM10)), nanoparticles, black carbon (BC), and particle-bound polycyclic aromatic hydrocarbons (p-PAHs) were measured at different residential heights&mdash;6 m, 16 m, and 27 m&mdash;at Feng Chia University near a popular night market in Western Taiwan. PM2.5 data were further adopted for health risk estimations. In winter, the magnitude of PM1, PM2.5, and PM10 concentrations were 16 m &gt; 6 m &gt; 27 m; nanoparticle concentrations were 6 m &gt; 27 m &gt; 16 m; and BC and p-PAHs concentrations were 27 m &gt; 16 m &gt; 6 m. In summer, PM1, PM2.5, and PM10 concentrations ranged from 6 m &gt; 16 m &gt; 27 m; nanoparticle concentrations were 6 m &gt; 16 m; and BC and p-PAHs concentrations were from 27 m &gt; 16 m. PM and constituents concentrations during winter were significantly higher in the nighttime than those in daytime, and levels of PM1, PM2.5, and PM10 increased rapidly on 6 m and 16 m heights (but did not increase at 27 m) after 5 pm, whereas these trends became less significant in summer. Health risk analysis for PM2.5 concentrations showed a decrease in lung cancer mortality rate and an extended lifespan for residents living at 27 m. Overall, the current study investigated the vertical profile of particulate matters and analyzed health impacts of PM2.5 at different residential heights in urban area of Taiwan. As the distributions of PM and the constituents varied at different residential heights, exposure and risk assessment of particle concentrations with multiple sizes and various components at broader vertical heights should be further investigated.},
DOI = {10.3390/atmos11111145}
}



@Article{s20216006,
AUTHOR = {Cheng, Zhiqiang and Meng, Jihua and Shang, Jiali and Liu, Jiangui and Huang, Jianxi and Qiao, Yanyou and Qian, Budong and Jing, Qi and Dong, Taifeng and Yu, Lihong},
TITLE = {Generating Time-Series LAI Estimates of Maize Using Combined Methods Based on Multispectral UAV Observations and WOFOST Model},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {6006},
URL = {https://www.mdpi.com/1424-8220/20/21/6006},
ISSN = {1424-8220},
ABSTRACT = {Green leaf area index (LAI) is an important variable related to crop growth. Accurate and timely information on LAI is essential for developing suitable field management strategies to mitigate risk and boost yield. Several remote sensing (RS) based methods have been recently developed to estimate LAI at the regional scale. However, the performance of these methods tends to be affected by the quality of RS data, especially when time-series LAI are required. For crop LAI estimation, supplementary growth information from crop model is helpful to address this issue. In this study, we focus on the regional-scale LAI estimations of spring maize for the entire growth season. Using time-series multispectral RS data acquired by an unmanned aerial vehicle (UAV) and the World Food Studies (WOFOST) crop model, three methods were applied at different crop growth stages: empirical method using vegetation index (VI), data assimilation method and hybrid method. The VI-based method and assimilation method were used to generate time-series LAI estimations for the whole crop growth season. Then, a hybrid method specially for the late-stage LAI retrieval was developed by integrating WOFOST model and data assimilation. Using field-collected LAI data in Hongxing Farm in 2014, the performances of these three methods were evaluated. At the early stage, the VI-based method (R2 = 0.63, RMSE = 0.16, n = 36) achieved higher accuracy than the assimilation method (R2 = 0.54, RMSE = 0.52, n = 36), whereas at the mid stage, the assimilation method (R2 = 0.63, RMSE = 0.46, n = 28) showed higher accuracy than the VI-based method (R2 = 0.41, RMSE = 0.51, n = 28). At the late stage, the hybrid method yielded the highest accuracy (R2 = 0.63, RMSE = 0.46, n = 29), compared with the VI-based method (R2 = 0.19, RMSE = 0.43, n = 28) and the assimilation method (R2 = 0.20, RMSE = 0.44, n = 29). Based on the results above, we considered a combination of the three methods, i.e., the VI-based method for the early stage, the assimilation method for the mid stage, and the hybrid method for the late stage, as an ideal strategy for spring-maize LAI estimation for the entire growth season of 2014 in Hongxing Farm, and the accuracy of the combined method over the whole growth season is higher than that of any single method.},
DOI = {10.3390/s20216006}
}



@Article{agronomy10111638,
AUTHOR = {Gonzalez-de-Santos, Pablo and Fernández, Roemi and Sepúlveda, Delia and Navas, Eduardo and Emmi, Luis and Armada, Manuel},
TITLE = {Field Robots for Intelligent Farms—Inhering Features from Industry},
JOURNAL = {Agronomy},
VOLUME = {10},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {1638},
URL = {https://www.mdpi.com/2073-4395/10/11/1638},
ISSN = {2073-4395},
ABSTRACT = {Estimations of world population growth urgently require improving the efficiency of agricultural processes, as well as improving safety for people and environmental sustainability, which can be opposing characteristics. Industry is pursuing these objectives by developing the concept of the &ldquo;intelligent factory&rdquo; (also referred to as the &ldquo;smart factory&rdquo;) and, by studying the similarities between industry and agriculture, we can exploit the achievements attained in industry for agriculture. This article focuses on studying those similarities regarding robotics to advance agriculture toward the concept of &ldquo;intelligent farms&rdquo; (smart farms). Thus, this article presents some characteristics that agricultural robots should gain from industrial robots to attain the intelligent farm concept regarding robot morphologies and features as well as communication, computing, and data management techniques. The study, restricted to robotics for outdoor farms due to the fact that robotics for greenhouse farms deserves a specific study, reviews different structures for robot manipulators and mobile robots along with the latest techniques used in intelligent factories to advance the characteristics of robotics for future intelligent farms. This article determines similarities, contrasts, and differences between industrial and field robots and identifies some techniques proven in the industry with an extraordinary potential to be used in outdoor farms such as those derived from methods based on artificial intelligence, cyber-physical systems, Internet of Things, Big Data techniques, and cloud computing procedures. Moreover, different types of robots already in use in industry and services are analyzed and their advantages in agriculture reported (parallel, soft, redundant, and dual manipulators) as well as ground and aerial unmanned robots and multi-robot systems.},
DOI = {10.3390/agronomy10111638}
}



@Article{rs12213504,
AUTHOR = {Li, Xingrong and Yang, Chenghai and Huang, Wenjiang and Tang, Jia and Tian, Yanqin and Zhang, Qing},
TITLE = {Identification of Cotton Root Rot by Multifeature Selection from Sentinel-2 Images Using Random Forest},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {3504},
URL = {https://www.mdpi.com/2072-4292/12/21/3504},
ISSN = {2072-4292},
ABSTRACT = {Cotton root rot is a destructive cotton disease and significantly affects cotton quality and yield, and accurate identification of its distribution within fields is critical for cotton growers to control the disease effectively. In this study, Sentinel-2 images were used to explore the feasibility of creating classification maps and prescription maps for site-specific fungicide application. Eight cotton fields with different levels of root rot were selected and random forest (RF) was used to identify the optimal spectral indices and texture features of the Sentinel-2 images. Five optimal spectral indices (plant senescence reflectance index (PSRI), normalized difference vegetation index (NDVI), normalized difference water index (NDWI1), moisture stressed index (MSI), and renormalized difference vegetation index (RDVI)) and seven optimal texture features (Contrast 1, Dissimilarity 1, Entory 2, Mean 1, Variance 1, Homogeneity 1, and Second moment 2) were identified. Three binary logistic regression (BLR) models, including a spectral model, a texture model, and a spectral-texture model, were constructed for cotton root rot classification and prescription map creation. The results were compared with classification maps and prescription maps based on airborne imagery. Accuracy assessment showed that the accuracies of the classification maps for the spectral, texture, and spectral-texture models were 92.95%, 84.81%, and 91.87%, respectively, and the accuracies of the prescription maps for the three respective models were 90.83%, 87.14%, and 91.40%. These results confirmed that it was feasible to identify cotton root rot and create prescription maps using different features of Sentinel-2 imagery. The addition of texture features had little effect on the overall accuracy, but it could improve the ability to identify root rot areas. The producer&rsquo;s accuracy (PA) for infested cotton in the classification maps for the texture model and the spectral-texture model was 2.82% and 1.07% higher, respectively, than that of the spectral model, and the PA for treatment zones in the prescription maps for the two respective models was 8.6% and 8.22% higher than that of the spectral model. Results based on the eight cotton fields showed that the spectral model was appropriate for the cotton fields with relatively severe infestation and the spectral-texture model was more appropriate for the cotton fields with low or moderate infestation.},
DOI = {10.3390/rs12213504}
}



@Article{agronomy10111648,
AUTHOR = {Demestichas, Konstantinos and Daskalakis, Emmanouil},
TITLE = {Data Lifecycle Management in Precision Agriculture Supported by Information and Communication Technology},
JOURNAL = {Agronomy},
VOLUME = {10},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {1648},
URL = {https://www.mdpi.com/2073-4395/10/11/1648},
ISSN = {2073-4395},
ABSTRACT = {The role of agriculture in environmental degradation and climate change has been at the center of a long-lasting and controversial debate. This situation combined with the expected growth in crop demand and the increasing prices of fertilizers and pesticides has made the need for a more resource-efficient and environmentally sustainable agriculture more evident than ever. Precision agriculture (PA), as a relatively new farming management concept, aims to improve crop performance as well as to reduce the environmental footprint by utilizing information about the temporal and the spatial variability of crops. Information and communication technology (ICT) systems have influenced and shaped every part of modern life, and PA is no exception. The current paper conducts a literature review of prominent ICT solutions, focusing on their role in supporting different phases of the lifecycle of PA-related data. In addition to this, a data lifecycle model was developed as part of a novel categorization approach for the analyzed solutions.},
DOI = {10.3390/agronomy10111648}
}



@Article{rs12213511,
AUTHOR = {Eskandari, Roghieh and Mahdianpari, Masoud and Mohammadimanesh, Fariba and Salehi, Bahram and Brisco, Brian and Homayouni, Saeid},
TITLE = {Meta-analysis of Unmanned Aerial Vehicle (UAV) Imagery for Agro-environmental Monitoring Using Machine Learning and Statistical Models},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {3511},
URL = {https://www.mdpi.com/2072-4292/12/21/3511},
ISSN = {2072-4292},
ABSTRACT = {Unmanned Aerial Vehicle (UAV) imaging systems have recently gained significant attention from researchers and practitioners as a cost-effective means for agro-environmental applications. In particular, machine learning algorithms have been applied to UAV-based remote sensing data for enhancing the UAV capabilities of various applications. This systematic review was performed on studies through a statistical meta-analysis of UAV applications along with machine learning algorithms in agro-environmental monitoring. For this purpose, a total number of 163 peer-reviewed articles published in 13 high-impact remote sensing journals over the past 20 years were reviewed focusing on several features, including study area, application, sensor type, platform type, and spatial resolution. The meta-analysis revealed that 62% and 38% of the studies applied regression and classification models, respectively. Visible sensor technology was the most frequently used sensor with the highest overall accuracy among classification articles. Regarding regression models, linear regression and random forest were the most frequently applied models in UAV remote sensing imagery processing. Finally, the results of this study confirm that applying machine learning approaches on UAV imagery produces fast and reliable results. Agriculture, forestry, and grassland mapping were found as the top three UAV applications in this review, in 42%, 22%, and 8% of the studies, respectively.},
DOI = {10.3390/rs12213511}
}



@Article{rs12213515,
AUTHOR = {Moghimi, Ali and Pourreza, Alireza and Zuniga-Ramirez, German and Williams, Larry E. and Fidelibus, Matthew W.},
TITLE = {A Novel Machine Learning Approach to Estimate Grapevine Leaf Nitrogen Concentration Using Aerial Multispectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {3515},
URL = {https://www.mdpi.com/2072-4292/12/21/3515},
ISSN = {2072-4292},
ABSTRACT = {Assessment of the nitrogen status of grapevines with high spatial, temporal resolution offers benefits in fertilizer use efficiency, crop yield and quality, and vineyard uniformity. The primary objective of this study was to develop a robust predictive model for grapevine nitrogen estimation at bloom stage using high-resolution multispectral images captured by an unmanned aerial vehicle (UAV). Aerial imagery and leaf tissue sampling were conducted from 150 grapevines subjected to five rates of nitrogen applications. Subsequent to appropriate pre-processing steps, pixels representing the canopy were segmented from the background per each vine. First, we defined a binary classification problem using pixels of three vines with the minimum (low-N class) and two vines with the maximum (high-N class) nitrogen concentration. Following optimized hyperparameters configuration, we trained five machine learning classifiers, including support vector machine (SVM), random forest, XGBoost, quadratic discriminant analysis (QDA), and deep neural network (DNN) with fully-connected layers. Among the classifiers, SVM offered the highest F1-score (82.24%) on the test dataset at the cost of a very long training time compared to the other classifiers. Alternatively, QDA and XGBoost required the minimum training time with promising F1-score of 80.85% and 80.27%, respectively. Second, we transformed the classification into a regression problem by averaging the posterior probability of high-N class for all pixels within each of 150 vines. XGBoost exhibited a slightly larger coefficient of determination (R2 = 0.56) and lower root mean square error (RMSE) (0.23%) compared to other learning methods in the prediction of nitrogen concentration of all vines. The proposed approach provides values in (i) leveraging high-resolution imagery, (ii) investigating spatial distribution of nitrogen across a vine&rsquo;s canopy, and (iii) defining spatial zones for nitrogen application and smart sampling.},
DOI = {10.3390/rs12213515}
}



@Article{s20216098,
AUTHOR = {Just, Gilson E. and E. Pellenz, Marcelo and Lima, Luiz A. de Paula and S. Chang, Bruno and Demo Souza, Richard and Montejo-Sánchez, Samuel},
TITLE = {UAV Path Optimization for Precision Agriculture Wireless Sensor Networks},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {6098},
URL = {https://www.mdpi.com/1424-8220/20/21/6098},
ISSN = {1424-8220},
ABSTRACT = {The use of monitoring sensors is increasingly present in the context of precision agriculture. Usually, these sensor nodes (SNs) alternate their states between periods of activation and hibernation to reduce battery usage. When employing unmanned aerial vehicles (UAVs) to collect data from SNs distributed over a large agricultural area, we must synchronize the UAV route with the activation period of each SN. In this article, we address the problem of optimizing the UAV path through all the SNs to reduce its flight time, while also maximizing the SNs&rsquo; lifetime. Using the concept of timeslots for time base management combined with the idea of flight prohibition list, we propose an efficient algorithm for discovering and reconfiguring the activation time of the SNs. Experimental results were obtained through the development of our own simulator&mdash;UAV Simulator. These results demonstrate a considerable reduction in the distance traveled by the UAV and also in its flight time. In addition, the model provides a reduction in transmission time by SNs after reconfiguration, thus ensuring a longer lifetime for the SNs in the monitoring environment, as well as improving the freshness and continuity of the gathered data, which support the decision-making process.},
DOI = {10.3390/s20216098}
}



@Article{s20216097,
AUTHOR = {Gardner, Marcus and Mancero Castillo, C. Sebastian and Wilson, Samuel and Farina, Dario and Burdet, Etienne and Khoo, Boo Cheong and Atashzar, S. Farokh and Vaidyanathan, Ravi},
TITLE = {A Multimodal Intention Detection Sensor Suite for Shared Autonomy of Upper-Limb Robotic Prostheses},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {6097},
URL = {https://www.mdpi.com/1424-8220/20/21/6097},
ISSN = {1424-8220},
ABSTRACT = {Neurorobotic augmentation (e.g., robotic assist) is now in regular use to support individuals suffering from impaired motor functions. A major unresolved challenge, however, is the excessive cognitive load necessary for the human&ndash;machine interface (HMI). Grasp control remains one of the most challenging HMI tasks, demanding simultaneous, agile, and precise control of multiple degrees-of-freedom (DoFs) while following a specific timing pattern in the joint and human&ndash;robot task spaces. Most commercially available systems use either an indirect mode-switching configuration or a limited sequential control strategy, limiting activation to one DoF at a time. To address this challenge, we introduce a shared autonomy framework centred around a low-cost multi-modal sensor suite fusing: (a) mechanomyography (MMG) to estimate the intended muscle activation, (b) camera-based visual information for integrated autonomous object recognition, and (c) inertial measurement to enhance intention prediction based on the grasping trajectory. The complete system predicts user intent for grasp based on measured dynamical features during natural motions. A total of 84 motion features were extracted from the sensor suite, and tests were conducted on 10 able-bodied and 1 amputee participants for grasping common household objects with a robotic hand. Real-time grasp classification accuracy using visual and motion features obtained 100%, 82.5%, and 88.9% across all participants for detecting and executing grasping actions for a bottle, lid, and box, respectively. The proposed multimodal sensor suite is a novel approach for predicting different grasp strategies and automating task performance using a commercial upper-limb prosthetic device. The system also shows potential to improve the usability of modern neurorobotic systems due to the intuitive control design.},
DOI = {10.3390/s20216097}
}



@Article{w12113010,
AUTHOR = {Wang, Ruimeng and Xia, Haoming and Qin, Yaochen and Niu, Wenhui and Pan, Li and Li, Rumeng and Zhao, Xiaoyang and Bian, Xiqing and Fu, Pinde},
TITLE = {Dynamic Monitoring of Surface Water Area during 1989–2019 in the Hetao Plain Using Landsat Data in Google Earth Engine},
JOURNAL = {Water},
VOLUME = {12},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {3010},
URL = {https://www.mdpi.com/2073-4441/12/11/3010},
ISSN = {2073-4441},
ABSTRACT = {The spatio-temporal change of the surface water is very important to agricultural, economic, and social development in the Hetao Plain, as well as the structure and function of the ecosystem. To understand the long-term changes of the surface water area in the Hetao Plain, we used all available Landsat images (7534 scenes) and adopted the modified Normalized Difference Water Index (mNDWI), Enhanced Vegetation Index (EVI), and Normalized Difference Vegetation Index (NDVI) to map the open-surface water from 1989 to 2019 in the Google Earth Engine (GEE) cloud platform. We further analyzed precipitation, temperature, and irrigated area, revealing the impact of climate change and human activities on long-term surface water changes. The results show the following. (1) In the last 31 years, the maximum, seasonal, and annual average water body area values in the Hetao Plain have exhibited a downward trend. Meanwhile, the number of maximum, seasonal, and permanent water bodies displayed a significant upward trend. (2) The variation of the surface water area in the Hetao Plain is mainly affected by the maximum water body area, while the variation of the water body number is mainly affected by the number of minimum water bodies. (3) Precipitation has statistically significant positive effects on the water body area and water body number, which has statistically significant negative effects with temperature and irrigation. The findings of this study can be used to help the policy-makers and farmers understand changing water resources and its driving mechanism and provide a reference for water resources management, agricultural irrigation, and ecological protection.},
DOI = {10.3390/w12113010}
}



@Article{rs12213533,
AUTHOR = {Pedro, Dário and Matos-Carvalho, João P. and Azevedo, Fábio and Sacoto-Martins, Ricardo and Bernardo, Luís and Campos, Luís and Fonseca, José M. and Mora, André},
TITLE = {FFAU—Framework for Fully Autonomous UAVs},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {3533},
URL = {https://www.mdpi.com/2072-4292/12/21/3533},
ISSN = {2072-4292},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs), although hardly a new technology, have recently gained a prominent role in many industries being widely used not only among enthusiastic consumers, but also in high demanding professional situations, and will have a massive societal impact over the coming years. However, the operation of UAVs is fraught with serious safety risks, such as collisions with dynamic obstacles (birds, other UAVs, or randomly thrown objects). These collision scenarios are complex to analyze in real-time, sometimes being computationally impossible to solve with existing State of the Art (SoA) algorithms, making the use of UAVs an operational hazard and therefore significantly reducing their commercial applicability in urban environments. In this work, a conceptual framework for both stand-alone and swarm (networked) UAVs is introduced, with a focus on the architectural requirements of the collision avoidance subsystem to achieve acceptable levels of safety and reliability. The SoA principles for collision avoidance against stationary objects are reviewed and a novel approach is described, using deep learning techniques to solve the computational intensive problem of real-time collision avoidance with dynamic objects. The proposed framework includes a web-interface allowing the full control of UAVs as remote clients with a supervisor cloud-based platform. The feasibility of the proposed approach was demonstrated through experimental tests using a UAV, developed from scratch using the proposed framework. Test flight results are presented for an autonomous UAV monitored from multiple countries across the world.},
DOI = {10.3390/rs12213533}
}



@Article{rs12213534,
AUTHOR = {Liang, Liang and Geng, Di and Yan, Juan and Qiu, Siyi and Di, Liping and Wang, Shuguo and Xu, Lu and Wang, Lijuan and Kang, Jianrong and Li, Li},
TITLE = {Estimating Crop LAI Using Spectral Feature Extraction and the Hybrid Inversion Method},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {3534},
URL = {https://www.mdpi.com/2072-4292/12/21/3534},
ISSN = {2072-4292},
ABSTRACT = {The leaf area index (LAI) is an essential indicator used in crop growth monitoring. In the study, a hybrid inversion method, which combined a physical model with a statistical method, was proposed to estimate the crop LAI. The simulated compact high-resolution imaging spectrometer (CHRIS) canopy spectral crop reflectance datasets were generated using the PROSAIL model (the coupling of PROSPECT leaf optical properties model and Scattering by Arbitrarily Inclined Leaves model) and the CHRIS band response function. Partial least squares (PLS) was then used to reduce the dimension of the simulated spectral data. Using the principal components (PCs) of PLS as the model inputs, the hybrid inversion models were built using various modeling algorithms, including the backpropagation artificial neural network (BP-ANN), least squares support vector regression (LS-SVR), and random forest regression (RFR). Finally, remote sensing mapping of the CHRIS data was achieved with the hybrid model to test the inversion accuracy of LAI estimates. The validation result yielded an accuracy of R2 = 0.939 and normalized root-mean-square error (NRMSE) = 6.474% for the PLS_RFR model, which indicated that the crops LAI could be estimated accurately by using spectral feature extraction and a hybrid inversion strategy. The results showed that the model based on principal components extracted by PLS had a good estimation accuracy and noise immunity and was the preferred method for LAI estimation. Furthermore, the comparative analysis results of various datasets showed that prior knowledge could improve the precision of the retrieved LAI, and using this information to constrain parameters (e.g., chlorophyll content or LAI), which make important contributions to the spectra, is the key to this improvement. In addition, among the PLS, BP-ANN, LS-SVR, and RFR methods, RFR was the optimal modeling algorithm in the paper, as indicated by the high R2 and low NRMSE in various datasets.},
DOI = {10.3390/rs12213534}
}



@Article{app10217622,
AUTHOR = {Vujasinović, Stéphane and Becker, Stefan and Breuer, Timo and Bullinger, Sebastian and Scherer-Negenborn, Norbert and Arens, Michael},
TITLE = {Integration of the 3D Environment for UAV Onboard Visual Object Tracking},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {7622},
URL = {https://www.mdpi.com/2076-3417/10/21/7622},
ISSN = {2076-3417},
ABSTRACT = {Single visual object tracking from an unmanned aerial vehicle (UAV) poses fundamental challenges such as object occlusion, small-scale objects, background clutter, and abrupt camera motion. To tackle these difficulties, we propose to integrate the 3D structure of the observed scene into a detection-by-tracking algorithm. We introduce a pipeline that combines a model-free visual object tracker, a sparse 3D reconstruction, and a state estimator. The 3D reconstruction of the scene is computed with an image-based Structure-from-Motion (SfM) component that enables us to leverage a state estimator in the corresponding 3D scene during tracking. By representing the position of the target in 3D space rather than in image space, we stabilize the tracking during ego-motion and improve the handling of occlusions, background clutter, and small-scale objects. We evaluated our approach on prototypical image sequences, captured from a UAV with low-altitude oblique views. For this purpose, we adapted an existing dataset for visual object tracking and reconstructed the observed scene in 3D. The experimental results demonstrate that the proposed approach outperforms methods using plain visual cues as well as approaches leveraging image-space-based state estimations. We believe that our approach can be beneficial for trafficmonitoring, video surveillance, and navigation.},
DOI = {10.3390/app10217622}
}



@Article{min10110967,
AUTHOR = {Krupnik, Diana and Khan, Shuhab D.},
TITLE = {High-Resolution Hyperspectral Mineral Mapping: Case Studies in the Edwards Limestone, Texas, USA and Sulfide-Rich Quartz Veins from the Ladakh Batholith, Northern Pakistan},
JOURNAL = {Minerals},
VOLUME = {10},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {967},
URL = {https://www.mdpi.com/2075-163X/10/11/967},
ISSN = {2075-163X},
ABSTRACT = {The study of hand samples is a significant aspect of geoscience. This work showcases a technique for relatively quick and inexpensive mineral characterization, applied to a Cretaceous limestone formation and for sulfide-rich quartz vein samples from Northern Pakistan. Spectral feature parameters are derived from mineral mixtures of known abundance and are used for mineral mapping. Additionally, three well-known classification techniques&mdash;Spectral Angle Mapper (SAM), Support Vector Machine (SVM), and Neural Network&mdash;are compared. Point counting results from petrographic thin sections are used for validation the limestone samples, and QEMSCAN mineral maps for the sulfide samples. For classifying the carbonates, the SVM classifier produced results that are closest to the training set&mdash;with 84.4% accuracy and a kappa coefficient of 0.8. For classifying sulfides, SAM produced mineral abundances that were closest to the validation data, possibly due to the low reflectance of sulfides throughout the short-wave infrared spectrum with some differences in the overall spectral shape.},
DOI = {10.3390/min10110967}
}



@Article{s20216187,
AUTHOR = {F. Pinto, Milena and G. Melo, Aurelio and M. Honório, Leonardo and L. M. Marcato, André and G. S. Conceição, André and O. Timotheo, Amanda},
TITLE = {Deep Learning Applied to Vegetation Identification and Removal Using Multidimensional Aerial Data},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {6187},
URL = {https://www.mdpi.com/1424-8220/20/21/6187},
ISSN = {1424-8220},
ABSTRACT = {When performing structural inspection, the generation of three-dimensional (3D) point clouds is a common resource. Those are usually generated from photogrammetry or through laser scan techniques. However, a significant drawback for complete inspection is the presence of covering vegetation, hiding possible structural problems, and making difficult the acquisition of proper object surfaces in order to provide a reliable diagnostic. Therefore, this research&rsquo;s main contribution is developing an effective vegetation removal methodology through the use of a deep learning structure that is capable of identifying and extracting covering vegetation in 3D point clouds. The proposed approach uses pre and post-processing filtering stages that take advantage of colored point clouds, if they are available, or operate independently. The results showed high classification accuracy and good effectiveness when compared with similar methods in the literature. After this step, if color is available, then a color filter is applied, enhancing the results obtained. Besides, the results are analyzed in light of real Structure From Motion (SFM) reconstruction data, which further validates the proposed method. This research also presented a colored point cloud library of bushes built for the work used by other studies in the field.},
DOI = {10.3390/s20216187}
}



@Article{rs12213552,
AUTHOR = {Yoo, Cheolhee and Lee, Yeonsu and Cho, Dongjin and Im, Jungho and Han, Daehyeon},
TITLE = {Improving Local Climate Zone Classification Using Incomplete Building Data and Sentinel 2 Images Based on Convolutional Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {3552},
URL = {https://www.mdpi.com/2072-4292/12/21/3552},
ISSN = {2072-4292},
ABSTRACT = {Recent studies have enhanced the mapping performance of the local climate zone (LCZ), a standard framework for evaluating urban form and function for urban heat island research, through remote sensing (RS) images and deep learning classifiers such as convolutional neural networks (CNNs). The accuracy in the urban-type LCZ (LCZ1-10), however, remains relatively low because RS data cannot provide vertical or horizontal building components in detail. Geographic information system (GIS)-based building datasets can be used as primary sources in LCZ classification, but there is a limit to using them as input data for CNN due to their incompleteness. This study proposes novel methods to classify LCZ using Sentinel 2 images and incomplete building data based on a CNN classifier. We designed three schemes (S1, S2, and a scheme fusion; SF) for mapping 50 m LCZs in two megacities: Berlin and Seoul. S1 used only RS images, and S2 used RS and building components such as area and height (or the number of stories). SF combined two schemes (S1 and S2) based on three conditions, mainly focusing on the confidence level of the CNN classifier. When compared to S1, the overall accuracies for all LCZ classes (OA) and the urban-type LCZ (OAurb) of SF increased by about 4% and 7&ndash;9%, respectively, for the two study areas. This study shows that SF can compensate for the imperfections in the building data, which causes misclassifications in S2. The suggested approach can be excellent guidance to produce a high accuracy LCZ map for cities where building databases can be obtained, even if they are incomplete.},
DOI = {10.3390/rs12213552}
}



@Article{drones4040069,
AUTHOR = {Garzon-Lopez, Carol X. and Lasso, Eloisa},
TITLE = {Species Classification in a Tropical Alpine Ecosystem Using UAV-Borne RGB and Hyperspectral Imagery},
JOURNAL = {Drones},
VOLUME = {4},
YEAR = {2020},
NUMBER = {4},
ARTICLE-NUMBER = {69},
URL = {https://www.mdpi.com/2504-446X/4/4/69},
ISSN = {2504-446X},
ABSTRACT = {P&aacute;ramos host more than 3500 vascular plant species and are crucial water providers for millions of people in the northern Andes. Monitoring species distribution at large scales is an urgent conservation priority in the face of ongoing climatic changes and increasing anthropogenic pressure on this ecosystem. For the first time in this ecosystem, we explored the potential of unoccupied aerial vehicles (UAV)-borne red, green, and blue wavelengths (RGB) and hyperspectral imagery for p&aacute;ramo species classification by collecting both types of images in a 10-ha area, and ground vegetation cover data from 10 plots within this area. Five plots were used for calibration and the other five for validation. With the hyperspectral data, we tested our capacity to detect five representative p&aacute;ramo species with different growth forms using support vector machine (SVM) and random forest (RF) classifiers in combination with three feature selection methods and two class groups. Using RGB images, we could classify 21 species with an accuracy greater than 97%. From hyperspectral imaging, the highest accuracy (89%) was found using models built with RF or SVM classifiers combined with a binary grouping method and the sequential floating forward selection feature. Our results demonstrate that p&aacute;ramo species can be accurately mapped using both RGB and hyperspectral imagery.},
DOI = {10.3390/drones4040069}
}



@Article{rs12213587,
AUTHOR = {Masjedi, Ali and Crawford, Melba M. and Carpenter, Neal R. and Tuinstra, Mitchell R.},
TITLE = {Multi-Temporal Predictive Modelling of Sorghum Biomass Using UAV-Based Hyperspectral and LiDAR Data},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {3587},
URL = {https://www.mdpi.com/2072-4292/12/21/3587},
ISSN = {2072-4292},
ABSTRACT = {High-throughput phenotyping using high spatial, spectral, and temporal resolution remote sensing (RS) data has become a critical part of the plant breeding chain focused on reducing the time and cost of the selection process for the &ldquo;best&rdquo; genotypes with respect to the trait(s) of interest. In this paper, the potential of accurate and reliable sorghum biomass prediction using visible and near infrared (VNIR) and short-wave infrared (SWIR) hyperspectral data as well as light detection and ranging (LiDAR) data acquired by sensors mounted on UAV platforms is investigated. Predictive models are developed using classical regression-based machine learning methods for nine experiments conducted during the 2017 and 2018 growing seasons at the Agronomy Center for Research and Education (ACRE) at Purdue University, Indiana, USA. The impact of the regression method, data source, timing of RS and field-based biomass reference data acquisition, and the number of samples on the prediction results are investigated. R2 values for end-of-season biomass ranged from 0.64 to 0.89 for different experiments when features from all the data sources were included. Geometry-based features derived from the LiDAR point cloud to characterize plant structure and chemistry-based features extracted from hyperspectral data provided the most accurate predictions. Evaluation of the impact of the time of data acquisition during the growing season on the prediction results indicated that although the most accurate and reliable predictions of final biomass were achieved using remotely sensed data from mid-season to end-of-season, predictions in mid-season provided adequate results to differentiate between promising varieties for selection. The analysis of variance (ANOVA) of the accuracies of the predictive models showed that both the data source and regression method are important factors for a reliable prediction; however, the data source was more important with 69% significance, versus 28% significance for the regression method.},
DOI = {10.3390/rs12213587}
}



@Article{s20216247,
AUTHOR = {Calvario, Gabriela and Alarcón, Teresa E. and Dalmau, Oscar and Sierra, Basilio and Hernandez, Carmen},
TITLE = {An Agave Counting Methodology Based on Mathematical Morphology and Images Acquired through Unmanned Aerial Vehicles},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {6247},
URL = {https://www.mdpi.com/1424-8220/20/21/6247},
ISSN = {1424-8220},
ABSTRACT = {Blue agave is an important commercial crop in Mexico, and it is the main source of the traditional mexican beverage known as tequila. The variety of blue agave crop known as Tequilana Weber is a crucial element for tequila agribusiness and the agricultural economy in Mexico. The number of agave plants in the field is one of the main parameters for estimating production of tequila. In this manuscript, we describe a mathematical morphology-based algorithm that addresses the agave automatic counting task. The proposed methodology was applied to a set of real images collected using an Unmanned Aerial Vehicle equipped with a digital Red-Green-Blue (RGB) camera. The number of plants automatically identified in the collected images was compared to the number of plants counted by hand. Accuracy of the proposed algorithm depended on the size heterogeneity of plants in the field and illumination. Accuracy ranged from 0.8309 to 0.9806, and performance of the proposed algorithm was satisfactory.},
DOI = {10.3390/s20216247}
}



@Article{informatics7040050,
AUTHOR = {Kazllarof, Vangjel and Karlos, Stamatis and Kotsiantis, Sotiris},
TITLE = {Investigation of Combining Logitboost(M5P) under Active Learning Classification Tasks},
JOURNAL = {Informatics},
VOLUME = {7},
YEAR = {2020},
NUMBER = {4},
ARTICLE-NUMBER = {50},
URL = {https://www.mdpi.com/2227-9709/7/4/50},
ISSN = {2227-9709},
ABSTRACT = {Active learning is the category of partially supervised algorithms that is differentiated by its strategy to combine both the predictive ability of a base learner and the human knowledge so as to exploit adequately the existence of unlabeled data. Its ambition is to compose powerful learning algorithms which otherwise would be based only on insufficient labelled samples. Since the latter kind of information could raise important monetization costs and time obstacles, the human contribution should be seriously restricted compared with the former. For this reason, we investigate the use of the Logitboost wrapper classifier, a popular variant of ensemble algorithms which adopts the technique of boosting along with a regression base learner based on Model trees into 3 different active learning query strategies. We study its efficiency against 10 separate learners under a well-described active learning framework over 91 datasets which have been split to binary and multi-class problems. We also included one typical Logitboost variant with a separate internal regressor for discriminating the benefits of adopting a more accurate regression tree than one-node trees, while we examined the efficacy of one hyperparameter of the proposed algorithm. Since the application of the boosting technique may provide overall less biased predictions, we assume that the proposed algorithm, named as Logitboost(M5P), could provide both accurate and robust decisions under active learning scenarios that would be beneficial on real-life weakly supervised classification tasks. Its smoother weighting stage over the misclassified cases during training as well as the accurate behavior of M5P are the main factors that lead towards this performance. Proper statistical comparisons over the metric of classification accuracy verify our assumptions, while adoption of M5P instead of weak decision trees was proven to be more competitive for the majority of the examined problems. We present our results through appropriate summarization approaches and explanatory visualizations, commenting our results per case.},
DOI = {10.3390/informatics7040050}
}



@Article{aerospace7110158,
AUTHOR = {Weinert, Andrew},
TITLE = {Method to Characterize Potential UAS Encounters Using Open Source Data},
JOURNAL = {Aerospace},
VOLUME = {7},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {158},
URL = {https://www.mdpi.com/2226-4310/7/11/158},
ISSN = {2226-4310},
ABSTRACT = {As unmanned aerial systems (UASs) increasingly integrate into the US national airspace system, there is an increasing need to characterize how commercial and recreational UASs may encounter each other. To inform the development and evaluation of safety critical technologies, we demonstrate a methodology to analytically calculate all potential relative geometries between different UAS operations performing inspection missions. This method is based on a previously demonstrated technique that leverages open source geospatial information to generate representative unmanned aircraft trajectories. Using open source data and parallel processing techniques, we performed trillions of calculations to estimate the relative horizontal distance between geospatial points across sixteen locations.},
DOI = {10.3390/aerospace7110158}
}



@Article{iot1020020,
AUTHOR = {Kontogiannis, Sotirios and Asiminidis, Christodoulos},
TITLE = {A Proposed Low-Cost Viticulture Stress Framework for Table Grape Varieties},
JOURNAL = {IoT},
VOLUME = {1},
YEAR = {2020},
NUMBER = {2},
PAGES = {337--359},
URL = {https://www.mdpi.com/2624-831X/1/2/20},
ISSN = {2624-831X},
ABSTRACT = {Climate change significantly affects viticulture by reducing the production yield and the quality characteristics of its final products. In some observed cases, the consequences of climate outages such as droughts, hail and floods are absolutely devastating for the farmers and the sustained local economies. Hence, it is essential to develop new in implementation monitoring solutions that offer remote real-time surveillance, alert triggering, minimum maintenance and automated generation of incident alerts with precision responses. This paper presents a new framework and a system for vine stress monitoring called Vity-stress. The Vity-stress framework combines field measurements with precise viticulture suggestions and stress avoidance planning. The key points of the proposed framework&rsquo;s system are that it is easy to develop, easy to maintain and cheap to implement applicability. Focusing on the Mediterranean cultivated table grape varieties that are strongly affected by climate change, we propose a new stress conditions monitoring system to support our framework. The proposition includes distributed field located sensors and a novel camera module implementing deep neural network algorithms to detect stress indicators. Additionally, a new wireless sensor network supported by the iBeacon protocol has been developed. The results of the sensory measurements&rsquo; data logging and imposed image detection process&rsquo;s evaluation shows that the proposed system can successfully detect different stress levels in vineyards, which in turn can allow producers to identify specific areas for irrigation, thereby saving water, energy and time.},
DOI = {10.3390/iot1020020}
}



@Article{rs12213617,
AUTHOR = {Trevisan, Rodrigo and Pérez, Osvaldo and Schmitz, Nathan and Diers, Brian and Martin, Nicolas},
TITLE = {High-Throughput Phenotyping of Soybean Maturity Using Time Series UAV Imagery and Convolutional Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {3617},
URL = {https://www.mdpi.com/2072-4292/12/21/3617},
ISSN = {2072-4292},
ABSTRACT = {Soybean maturity is a trait of critical importance for the development of new soybean cultivars, nevertheless, its characterization based on visual ratings has many challenges. Unmanned aerial vehicles (UAVs) imagery-based high-throughput phenotyping methodologies have been proposed as an alternative to the traditional visual ratings of pod senescence. However, the lack of scalable and accurate methods to extract the desired information from the images remains a significant bottleneck in breeding programs. The objective of this study was to develop an image-based high-throughput phenotyping system for evaluating soybean maturity in breeding programs. Images were acquired twice a week, starting when the earlier lines began maturation until the latest ones were mature. Two complementary convolutional neural networks (CNN) were developed to predict the maturity date. The first using a single date and the second using the five best image dates identified by the first model. The proposed CNN architecture was validated using more than 15,000 ground truth observations from five trials, including data from three growing seasons and two countries. The trained model showed good generalization capability with a root mean squared error lower than two days in four out of five trials. Four methods of estimating prediction uncertainty showed potential at identifying different sources of errors in the maturity date predictions. The architecture developed solves limitations of previous research and can be used at scale in commercial breeding programs.},
DOI = {10.3390/rs12213617}
}



@Article{rs12213621,
AUTHOR = {Bi, Luning and Hu, Guiping and Raza, Muhammad Mohsin and Kandel, Yuba and Leandro, Leonor and Mueller, Daren},
TITLE = {A Gated Recurrent Units (GRU)-Based Model for Early Detection of Soybean Sudden Death Syndrome through Time-Series Satellite Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {3621},
URL = {https://www.mdpi.com/2072-4292/12/21/3621},
ISSN = {2072-4292},
ABSTRACT = {In general, early detection and timely management of plant diseases are essential for reducing yield loss. Traditional manual inspection of fields is often time-consuming and laborious. Automated imaging techniques have recently been successfully applied to detect plant diseases. However, these methods mostly focus on the current state of the crop. This paper proposes a gated recurrent unit (GRU)-based model to predict soybean sudden death syndrome (SDS) disease development. To detect SDS at a quadrat level, the proposed method uses satellite images collected from PlanetScope as the training set. The pixel image data include the spectral bands of red, green, blue and near-infrared (NIR). Data collected during the 2016 and 2017 soybean-growing seasons were analyzed. Instead of using individual static imagery, the GRU-based model converts the original imagery into time-series data. SDS predictions were made on different data scenarios and the results were compared with fully connected deep neural network (FCDNN) and XGBoost methods. The overall test accuracy of classifying healthy and diseased quadrates in all methods was above 76%. The test accuracy of the FCDNN and XGBoost were 76.3&ndash;85.5% and 80.6&ndash;89.2%, respectively, while the test accuracy of the GRU-based model was 82.5&ndash;90.4%. The calculation results show that the proposed method can improve the detection accuracy by up to 7% with time-series imagery. Thus, the proposed method has the potential to predict SDS at a future time.},
DOI = {10.3390/rs12213621}
}



@Article{s20216292,
AUTHOR = {Di Pietra, Vincenzo and Dabove, Paolo and Piras, Marco},
TITLE = {Loosely Coupled GNSS and UWB with INS Integration for Indoor/Outdoor Pedestrian Navigation},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {6292},
URL = {https://www.mdpi.com/1424-8220/20/21/6292},
ISSN = {1424-8220},
ABSTRACT = {The growth of location-based services (LBS) has increased rapidly in last years, mainly due to the possibility to exploit low-cost sensors installed in portable devices, such as smartphones and tablets. This work aims to show a low-cost multi-sensor platform developed by the authors in which an ultra-wideband (UWB) indoor positioning system is added to a classical global navigation satellite systems&ndash;inertial navigation system (GNSS-INS) integration, in order to acquire different synchronized data for further data fusion analysis in order to exploit seamless positioning. The data fusion is based on an extended Kalman filter (EKF) and on a geo-fencing approach which allows the navigation solution to be provided continuously. In particular, the proposed algorithm aims to solve a navigation task of a pedestrian user moving from an outdoor space to an indoor environment. The methodology and the system setup is presented with more details in the paper. The data acquired and the real-time positioning estimation are analysed in depth and compared with ground truth measurements. Particular attention is given to the UWB positioning system and its behaviour with respect to the environment. The proposed data fusion algorithm provides an overall horizontal and 3D accuracy of 35 cm and 45 cm, respectively, obtained considering 5 different measurement campaigns.},
DOI = {10.3390/s20216292}
}



@Article{s20216299,
AUTHOR = {Bhowmick, Sutanu and Nagarajaiah, Satish and Veeraraghavan, Ashok},
TITLE = {Vision and Deep Learning-Based Algorithms to Detect and Quantify Cracks on Concrete Surfaces from UAV Videos},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {6299},
URL = {https://www.mdpi.com/1424-8220/20/21/6299},
ISSN = {1424-8220},
ABSTRACT = {Immediate assessment of structural integrity of important civil infrastructures, like bridges, hospitals, or dams, is of utmost importance after natural disasters. Currently, inspection is performed manually by engineers who look for local damages and their extent on significant locations of the structure to understand its implication on its global stability. However, the whole process is time-consuming and prone to human errors. Due to their size and extent, some regions of civil structures are hard to gain access for manual inspection. In such situations, a vision-based system of Unmanned Aerial Vehicles (UAVs) programmed with Artificial Intelligence algorithms may be an effective alternative to carry out a health assessment of civil infrastructures in a timely manner. This paper proposes a framework of achieving the above-mentioned goal using computer vision and deep learning algorithms for detection of cracks on the concrete surface from its image by carrying out image segmentation of pixels, i.e., classification of pixels in an image of the concrete surface and whether it belongs to cracks or not. The image segmentation or dense pixel level classification is carried out using a deep neural network architecture named U-Net. Further, morphological operations on the segmented images result in dense measurements of crack geometry, like length, width, area, and crack orientation for individual cracks present in the image. The efficacy and robustness of the proposed method as a viable real-life application was validated by carrying out a laboratory experiment of a four-point bending test on an 8-foot-long concrete beam of which the video is recorded using a camera mounted on a UAV-based, as well as a still ground-based, video camera. Detection, quantification, and localization of damage on a civil infrastructure using the proposed framework can directly be used in the prognosis of the structure&rsquo;s ability to withstand service loads.},
DOI = {10.3390/s20216299}
}



@Article{rs12213632,
AUTHOR = {Abd-Elrahman, Amr and Guan, Zhen and Dalid, Cheryl and Whitaker, Vance and Britt, Katherine and Wilkinson, Benjamin and Gonzalez, Ali},
TITLE = {Automated Canopy Delineation and Size Metrics Extraction for Strawberry Dry Weight Modeling Using Raster Analysis of High-Resolution Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {3632},
URL = {https://www.mdpi.com/2072-4292/12/21/3632},
ISSN = {2072-4292},
ABSTRACT = {Capturing high spatial resolution imagery is becoming a standard operation in many agricultural applications. The increased capacity for image capture necessitates corresponding advances in analysis algorithms. This study introduces automated raster geoprocessing methods to automatically extract strawberry (Fragaria &times; ananassa) canopy size metrics using raster image analysis and utilize the extracted metrics in statistical modeling of strawberry dry weight. Automated canopy delineation and canopy size metrics extraction models were developed and implemented using ArcMap software v 10.7 and made available by the authors. The workflows were demonstrated using high spatial resolution (1 mm resolution) orthoimages and digital surface models (2 mm) of 34 strawberry plots (each containing 17 different plant genotypes) planted on raised beds. The images were captured on a weekly basis throughout the strawberry growing season (16 weeks) between early November and late February. The results of extracting four canopy size metrics (area, volume, average height, and height standard deviation) using automatically delineated and visually interpreted canopies were compared. The trends observed in the differences between canopy metrics extracted using the automatically delineated and visually interpreted canopies showed no significant differences. The R2 values of the models were 0.77 and 0.76 for the two datasets and the leave-one-out (LOO) cross validation root mean square error (RMSE) of the two models were 9.2 g and 9.4 g, respectively. The results show the feasibility of using automated methods for canopy delineation and canopy metric extraction to support plant phenotyping applications.},
DOI = {10.3390/rs12213632}
}



@Article{agriengineering2040035,
AUTHOR = {Barnetson, Jason and Phinn, Stuart and Scarth, Peter},
TITLE = {Estimating Plant Pasture Biomass and Quality from UAV Imaging across Queensland’s Rangelands},
JOURNAL = {AgriEngineering},
VOLUME = {2},
YEAR = {2020},
NUMBER = {4},
PAGES = {523--543},
URL = {https://www.mdpi.com/2624-7402/2/4/35},
ISSN = {2624-7402},
ABSTRACT = {The aim of this research was to test recent developments in the use of Remotely Piloted Aircraft Systems or Unmanned Aerial Vehicles (UAV)/drones to map both pasture quantity as biomass yield and pasture quality as the proportions of key pasture nutrients, across a selected range of field sites throughout the rangelands of Queensland. Improved pasture management begins with an understanding of the state of the resource base, UAV based methods can potentially achieve this at improved spatial and temporal scales. This study developed machine learning based predictive models of both pasture measures. UAV-based structure from motion photogrammetry provided a measure of yield from overlapping high resolution visible colour imagery. Pasture nutrient composition was estimated from the spectral signatures of visible near infrared hyperspectral UAV sensing. An automated pasture height surface modelling technique was developed, tested and used along with field site measurements to predict further estimates across each field site. Both prior knowledge and automated predictive modelling techniques were employed to predict yield and nutrition. Pasture height surface modelling was assessed against field measurements using a rising plate meter, results reported correlation coefficients (R2) ranging from 0.2 to 0.4 for both woodland and grassland field sites. Accuracy of the predictive modelling was determined from further field measurements of yield and on average indicated an error of 0.8 t ha&minus;1 in grasslands and 1.3 t ha&minus;1 in mixed woodlands across both modelling approaches. Correlation analyses between measures of pasture quality, acid detergent fibre and crude protein (ADF, CP), and spectral reflectance data indicated the visible red (651 nm) and red-edge (759 nm) regions were highly correlated (ADF R2 = 0.9 and CP R2 = 0.5 mean values). These findings agreed with previous studies linking specific absorption features with grass chemical composition. These results conclude that the practical application of such techniques, to efficiently and accurately map pasture yield and quality, is possible at the field site scale; however, further research is needed, in particular further field sampling of both yield and nutrient elements across such a diverse landscape, with the potential to scale up to a satellite platform for broader scale monitoring.},
DOI = {10.3390/agriengineering2040035}
}



@Article{app10217851,
AUTHOR = {Ignaciuk, Przemysław and Wieczorek, Łukasz},
TITLE = {Continuous Genetic Algorithms in the Optimization of Logistic Networks: Applicability Assessment and Tuning},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {7851},
URL = {https://www.mdpi.com/2076-3417/10/21/7851},
ISSN = {2076-3417},
ABSTRACT = {Globalization opens up new perspectives for handling goods distribution in logistic networks. However, establishing an efficient inventory policy is challenging by virtue of the analytical and computational complexity. In this study, the goods distribution process that was governed by the order-up-to policy, implemented in either a distributed or centralized way, was investigated in the logistic systems with complex interconnection topologies. Uncertain demand may be imposed at any node, not just at conveniently chosen contact points, with a lost-sales assumption that introduces a non-linearity into the node dynamics. In order to adjust the policy parameters, the continuous genetic algorithm (CGA) was applied, with the fitness function incorporating both the operational costs and customer satisfaction level. This study investigated how to select the parameters of the popular inventory management policy when operating in the non-trivial networked structures. Moreover, precise guidelines for the CGA tuning in the considered class of problems were provided and evaluated in extensive numerical experiments.},
DOI = {10.3390/app10217851}
}



@Article{e22111261,
AUTHOR = {Sanenga, Abraham and Mapunda, Galefang Allycan and Jacob, Tshepiso Merapelo Ludo and Marata, Leatile and Basutli, Bokamoso and Chuma, Joseph Monamati},
TITLE = {An Overview of Key Technologies in Physical Layer Security},
JOURNAL = {Entropy},
VOLUME = {22},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {1261},
URL = {https://www.mdpi.com/1099-4300/22/11/1261},
ISSN = {1099-4300},
ABSTRACT = {The open nature of radio propagation enables ubiquitous wireless communication. This allows for seamless data transmission. However, unauthorized users may pose a threat to the security of the data being transmitted to authorized users. This gives rise to network vulnerabilities such as hacking, eavesdropping, and jamming of the transmitted information. Physical layer security (PLS) has been identified as one of the promising security approaches to safeguard the transmission from eavesdroppers in a wireless network. It is an alternative to the computationally demanding and complex cryptographic algorithms and techniques. PLS has continually received exponential research interest owing to the possibility of exploiting the characteristics of the wireless channel. One of the main characteristics includes the random nature of the transmission channel. The aforesaid nature makes it possible for confidential and authentic signal transmission between the sender and the receiver in the physical layer. We start by introducing the basic theories of PLS, including the wiretap channel, information-theoretic security, and a brief discussion of the cryptography security technique. Furthermore, an overview of multiple-input multiple-output (MIMO) communication is provided. The main focus of our review is based on the existing key-less PLS optimization techniques, their limitations, and challenges. The paper also looks into the promising key research areas in addressing these shortfalls. Lastly, a comprehensive overview of some of the recent PLS research in 5G and 6G technologies of wireless communication networks is provided.},
DOI = {10.3390/e22111261}
}



@Article{electronics9111864,
AUTHOR = {Sobb, Theresa and Turnbull, Benjamin and Moustafa, Nour},
TITLE = {Supply Chain 4.0: A Survey of Cyber Security Challenges, Solutions and Future Directions},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {1864},
URL = {https://www.mdpi.com/2079-9292/9/11/1864},
ISSN = {2079-9292},
ABSTRACT = {Supply chain 4.0 denotes the fourth revolution of supply chain management systems, integrating manufacturing operations with telecommunication and Information Technology processes. Although the overarching aim of supply chain 4.0 is the enhancement of production systems within supply chains, making use of global reach, increasing agility and emerging technology, with the ultimate goal of increasing efficiency, timeliness and profitability, Supply chain 4.0 suffers from unique and emerging operational and cyber risks. Supply chain 4.0 has a lack of semantic standards, poor interoperability, and a dearth of security in the operation of its manufacturing and Information Technology processes. The technologies that underpin supply chain 4.0 include blockchain, smart contracts, applications of Artificial Intelligence, cyber-physical systems, Internet of Things and Industrial Internet of Things. Each of these technologies, individually and combined, create cyber security issues that should be addressed. This paper explains the nature of the military supply chains 4.0 and how it uniquely differs from the commercial supply chain, revealing their strengths, weaknesses, dependencies and the fundamental technologies upon which they are built. This encompasses an assessment of the cyber risks and opportunities for research in the field, including consideration of connectivity, sensing and convergence of systems. Current and emerging semantic models related to the standardization, development and safety assurance considerations for implementing new technologies into military supply chains 4.0 are also discussed. This is examined from a holistic standpoint and through technology-specific lenses to determine current states and implications for future research directions.},
DOI = {10.3390/electronics9111864}
}



@Article{app10217930,
AUTHOR = {Vintimilla-Tapia, Paúl and Bravo-Torres, Jack and López-Nores, Martín and Gallegos-Segovia, Pablo and Ordóñez-Morales, Esteban and Ramos-Cabrer, Manuel},
TITLE = {VaNetChain: A Framework for Trustworthy Exchanges of Information in VANETs Based on Blockchain and a Virtualization Layer},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {7930},
URL = {https://www.mdpi.com/2076-3417/10/21/7930},
ISSN = {2076-3417},
ABSTRACT = {Vehicular ad hoc networks (VANETs) face challenges related to the reliability of the data exchanged and the unstability of the communication links. These shortcomings have hampered the development of the long-awaited applications that would turn roads into a smart environment. We present a framework to deploy such services, in which a virtualization layer ensures means to efficiently deliver messages between vehicles and roadside units (RSUs) and, on top of that, blockchain technology is used to enable features of data integrity, traceability, and reliability that cannot be furnished by existing consensus and reputation mechanisms. A simulation experiment is included to determine the optimal number of RSUs to be installed as supporting infrastructure in a city.},
DOI = {10.3390/app10217930}
}



@Article{rs12213666,
AUTHOR = {Lei, Tsu Chiang and Wan, Shiuan and Wu, Shih-Chieh and Wang, Hsin-Ping},
TITLE = {A New Approach of Ensemble Learning Technique to Resolve the Uncertainties of Paddy Area through Image Classification},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {3666},
URL = {https://www.mdpi.com/2072-4292/12/21/3666},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing technology has rendered lots of information in agriculture. It has usually been used to monitor paddy growing ecosystems in the past few decades. However, there are uncertainties in data fusion techniques which can be resolved in image classification on paddy rice. In this study, a series of learning concepts integrated by a probability progress Fuzzy Dempster-Shafer (FDS) analysis is presented to upgrade various models and different types of image data which is the goal of this study. More specifically, the study utilized the FDS to generate a series of probability models in the classification of the system. In addition, Logistic Regression (LR), Support Vector Machine (SVM), and Neural Network (NN) approaches are employed into the developed FDS system. Furthermore, two different image types are Satellite Image and Aerial Photo used as the analysis material. The overall classification accuracy has been improved to 97.27%, and the kappa value is 0.93. The overall accuracy of the paddy field image classification for a multi-period of mid-scale satellite images is between 85% and 90%. The overall accuracy of the classification using multi-spectral numerical aerial photos can be between 91% and 95%. The FDS improves the accuracy of the above image classification results.},
DOI = {10.3390/rs12213666}
}



@Article{w12113135,
AUTHOR = {Liang, Zhongwei and Liu, Xiaochu and Xiong, Jianbin and Xiao, Jinrui},
TITLE = {Water Allocation and Integrative Management of Precision Irrigation: A Systematic Review},
JOURNAL = {Water},
VOLUME = {12},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {3135},
URL = {https://www.mdpi.com/2073-4441/12/11/3135},
ISSN = {2073-4441},
ABSTRACT = {Precision irrigation, defined as an efficient water allocation technique characterized by the optimal management and best collaboration of various factors of the irrigation process, attracts considerable attention in agricultural production and crop cultivation. This paper reviews the latest research developments in water allocation mechanism and integrative management effectiveness of precision irrigation, and highlights how irrigation water allocation and integrative management contribute to the high-efficiency performance of precision irrigation techniques; the irrigation models, irrigation infrastructure, and management strategies currently being used are emphasized. Thereafter, the future development prospects in water allocation and integrative management could be systematically analyzed and subsequently explored. Some frontier techniques such as data-oriented irrigation management, performance-proven water allocation, and cloud-based irrigation control are among the critical technologies capable of building a sustainable, integrative, and evolutionary irrigation system while providing the higher quality and efficiency needed for a full application of precision irrigation. This review could be used as an effective reference to study the complicated correlations between precision irrigation and its constructive influences in different environmental conditions, and to facilitate the practical promotion of irrigation productivity with higher accuracy and increased reliability of returns.},
DOI = {10.3390/w12113135}
}



@Article{s20226405,
AUTHOR = {Aldosari, Waleed and Moinuddin, Muhammad and Aljohani, Abdulah Jeza and Al-Saggaf, Ubaid M.},
TITLE = {Distributed Extended Kalman Filtering Based Techniques for 3-D UAV Jamming Localization},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {6405},
URL = {https://www.mdpi.com/1424-8220/20/22/6405},
ISSN = {1424-8220},
ABSTRACT = {Wireless networks are vulnerable to jamming attacks. Jamming in wireless communication becomes a major research problem due to ease in Unmanned Aerial Vehicle (UAV) launching and blocking of communication channels. Jamming is a subset of Denial of Service Attack (DoS) and an intentional interference where the malicious node disrupts the wireless communication by increasing the noise at the receiver node through transmission interference signal towards the target channel. In this work, the considered jammer is a UAV hovering around the target area to block the communication channel between two transceivers. We proposed a three-dimensional (3-D) UAV jamming localization scheme to track and detect the jammer position at each time step by employing a single boundary node observer. For this purpose, we developed two distributed Extended Kalman Filter (EKF) based schemes: (1) the Distributed EKF (DEKF) scheme using the information of the received power from the jammer at a single nearby boundary node only and (2) Distance Ratio aided Distributed EKF (DEKF-DR) based scheme utilizing an edge node in addition to a single boundary node. Extensive simulations are conducted in order to evaluate the performance of the proposed distributed algorithms for a 3-D trajectory and compared with that of the conventional Centralized EKF (EKF-Centr) based method (which is also modified for the 3-D scenario). The results show the clear supremacy of the proposed distributed algorithms with much lesser complexity in contrast to the conventional EKF-Centr technique.},
DOI = {10.3390/s20226405}
}



@Article{jcp1010002,
AUTHOR = {B. Rawat, Danda and Chaudhary, Vijay and Doku, Ronald},
TITLE = {Blockchain Technology: Emerging Applications and Use Cases for Secure and Trustworthy Smart Systems},
JOURNAL = {Journal of Cybersecurity and Privacy},
VOLUME = {1},
YEAR = {2021},
NUMBER = {1},
PAGES = {4--18},
URL = {https://www.mdpi.com/2624-800X/1/1/2},
ISSN = {2624-800X},
ABSTRACT = {Blockchain, also known as a distributed ledger technology, stores different transactions/operations in a chain of blocks in a distributed manner without needing a trusted third-party. Blockchain is proven to be immutable, which helps with integrity and accountability, and, to some extent, confidentiality through a pair of public and private keys. Blockchain has been in the spotlight after successful boom of the Bitcoin. There have been efforts to leverage salient features of Blockchain for different applications and use cases. This paper presents a comprehensive survey of applications and use cases of Blockchain technology for making smart systems secure and trustworthy. Specifically, readers of this paper can have thorough understanding of applications and use cases of Blockchain technology.},
DOI = {10.3390/jcp1010002}
}



@Article{s20226427,
AUTHOR = {Niu, Haoyu and Hollenbeck, Derek and Zhao, Tiebiao and Wang, Dong and Chen, YangQuan},
TITLE = {Evapotranspiration Estimation with Small UAVs in Precision Agriculture},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {6427},
URL = {https://www.mdpi.com/1424-8220/20/22/6427},
ISSN = {1424-8220},
ABSTRACT = {Estimating evapotranspiration (ET) has been one of the most critical research areas in agriculture because of water scarcity, the growing population, and climate change. The accurate estimation and mapping of ET are necessary for crop water management. Traditionally, researchers use water balance, soil moisture, weighing lysimeters, or an energy balance approach, such as Bowen ratio or eddy covariance towers to estimate ET. However, these ET methods are point-specific or area-weighted measurements and cannot be extended to a large scale. With the advent of satellite technology, remote sensing images became able to provide spatially distributed measurements. However, the spatial resolution of multispectral satellite images is in the range of meters, tens of meters, or hundreds of meters, which is often not enough for crops with clumped canopy structures, such as trees and vines. Unmanned aerial vehicles (UAVs) can mitigate these spatial and temporal limitations. Lightweight cameras and sensors can be mounted on the UAVs and take high-resolution images. Unlike satellite imagery, the spatial resolution of the UAV images can be at the centimeter-level. UAVs can also fly on-demand, which provides high temporal imagery. In this study, the authors examined different UAV-based approaches of ET estimation at first. Models and algorithms, such as mapping evapotranspiration at high resolution with internalized calibration (METRIC), the two-source energy balance (TSEB) model, and machine learning (ML) are analyzed and discussed herein. Second, challenges and opportunities for UAVs in ET estimation are also discussed, such as uncooled thermal camera calibration, UAV image collection, and image processing. Then, the authors share views on ET estimation with UAVs for future research and draw conclusive remarks.},
DOI = {10.3390/s20226427}
}



@Article{rs12223690,
AUTHOR = {Lausch, Angela and Schaepman, Michael E. and Skidmore, Andrew K. and Truckenbrodt, Sina C. and Hacker, Jörg M. and Baade, Jussi and Bannehr, Lutz and Borg, Erik and Bumberger, Jan and Dietrich, Peter and Gläßer, Cornelia and Haase, Dagmar and Heurich, Marco and Jagdhuber, Thomas and Jany, Sven and Krönert, Rudolf and Möller, Markus and Mollenhauer, Hannes and Montzka, Carsten and Pause, Marion and Rogass, Christian and Salepci, Nesrin and Schmullius, Christiane and Schrodt, Franziska and Schütze, Claudia and Schweitzer, Christian and Selsam, Peter and Spengler, Daniel and Vohland, Michael and Volk, Martin and Weber, Ute and Wellmann, Thilo and Werban, Ulrike and Zacharias, Steffen and Thiel, Christian},
TITLE = {Linking the Remote Sensing of Geodiversity and Traits Relevant to Biodiversity—Part II: Geomorphology, Terrain and Surfaces},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3690},
URL = {https://www.mdpi.com/2072-4292/12/22/3690},
ISSN = {2072-4292},
ABSTRACT = {The status, changes, and disturbances in geomorphological regimes can be regarded as controlling and regulating factors for biodiversity. Therefore, monitoring geomorphology at local, regional, and global scales is not only necessary to conserve geodiversity, but also to preserve biodiversity, as well as to improve biodiversity conservation and ecosystem management. Numerous remote sensing (RS) approaches and platforms have been used in the past to enable a cost-effective, increasingly freely available, comprehensive, repetitive, standardized, and objective monitoring of geomorphological characteristics and their traits. This contribution provides a state-of-the-art review for the RS-based monitoring of these characteristics and traits, by presenting examples of aeolian, fluvial, and coastal landforms. Different examples for monitoring geomorphology as a crucial discipline of geodiversity using RS are provided, discussing the implementation of RS technologies such as LiDAR, RADAR, as well as multi-spectral and hyperspectral sensor technologies. Furthermore, data products and RS technologies that could be used in the future for monitoring geomorphology are introduced. The use of spectral traits (ST) and spectral trait variation (STV) approaches with RS enable the status, changes, and disturbances of geomorphic diversity to be monitored. We focus on the requirements for future geomorphology monitoring specifically aimed at overcoming some key limitations of ecological modeling, namely: the implementation and linking of in-situ, close-range, air- and spaceborne RS technologies, geomorphic traits, and data science approaches as crucial components for a better understanding of the geomorphic impacts on complex ecosystems. This paper aims to impart multidimensional geomorphic information obtained by RS for improved utilization in biodiversity monitoring.},
DOI = {10.3390/rs12223690}
}



@Article{en13225875,
AUTHOR = {Ren, Yuan and Zhang, Xuewei and Lu, Guangyue},
TITLE = {The Wireless Solution to Realize Green IoT: Cellular Networks with Energy Efficient and Energy Harvesting Schemes},
JOURNAL = {Energies},
VOLUME = {13},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {5875},
URL = {https://www.mdpi.com/1996-1073/13/22/5875},
ISSN = {1996-1073},
ABSTRACT = {With the tremendous increase of heterogeneous Internet of Things (IoT) devices and the different service requirements of these IoT applications, machine-type communication (MTC) has attracted considerable attention from both industry and academia. Owing to the prominent advantages of supporting pervasive connectivity and wide area coverage, the cellular network is advocated as the potential wireless solution to realize IoT deployment for MTC, and this creative network paradigm is called the cellular IoT (C-IoT). In this paper, we propose the three-layer structured C-IoT architecture for MTC and review the challenges for deploying green C-IoT. Then, effective strategies for realizing green C-IoT are presented, including the energy efficient and energy harvesting schemes. We put forward several strategies to make the C-IoT run in an energy-saving manner, such as efficient random access and barring mechanisms, self-adapting machine learning predictions, scheduling optimization, resource allocation, fog computing, and group-oriented transmission. As for the energy harvesting schemes, the ambient and dedicated energy harvesting strategies are investigated. Afterwards, we give a detailed case study, which shows the effectiveness of reducing power consumption for the proposed layered C-IoT architecture. Additionally, for real-time and non-real-time applications, the power consumption of different on-off states for MTC devices is discussed.},
DOI = {10.3390/en13225875}
}



@Article{s20226439,
AUTHOR = {Xu, Wei and Bao, Xiangyu and Chen, Genglin and Neumann, Ingo},
TITLE = {Intelligent Calibration of Static FEA Computations Based on Terrestrial Laser Scanning Reference},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {6439},
URL = {https://www.mdpi.com/1424-8220/20/22/6439},
ISSN = {1424-8220},
ABSTRACT = {The demand for efficient and accurate finite element analysis (FEA) is becoming more prevalent with the increase in advanced calibration technologies and sensor-based monitoring methods. The current research explores a deep learning-based methodology to calibrate FEA results. The utilization of monitoring reference results from measurements, e.g., terrestrial laser scanning, can help to capture the actual features in the static loading process. We learn the deviation sequence results between the standard FEA computations with the simplified geometry and refined reference values by the long short-term memory method. The complex changing principles in different deviations are trained and captured effectively in the training process of deep learning. Hence, we generate the FEA sequence results corresponding to next adjacent loading steps. The final FEA computations are calibrated by the threshold control. The calibration reduces the mean square errors of the FEA future sequence results significantly. This strengthens the calibration depth. Consequently, the calibration of FEA computations with deep learning can play a helpful role in the prediction and monitoring problems regarding the future structural behaviors.},
DOI = {10.3390/s20226439}
}



@Article{s20226442,
AUTHOR = {Barmpoutis, Panagiotis and Papaioannou, Periklis and Dimitropoulos, Kosmas and Grammalidis, Nikos},
TITLE = {A Review on Early Forest Fire Detection Systems Using Optical Remote Sensing},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {6442},
URL = {https://www.mdpi.com/1424-8220/20/22/6442},
ISSN = {1424-8220},
ABSTRACT = {The environmental challenges the world faces nowadays have never been greater or more complex. Global areas covered by forests and urban woodlands are threatened by natural disasters that have increased dramatically during the last decades, in terms of both frequency and magnitude. Large-scale forest fires are one of the most harmful natural hazards affecting climate change and life around the world. Thus, to minimize their impacts on people and nature, the adoption of well-planned and closely coordinated effective prevention, early warning, and response approaches are necessary. This paper presents an overview of the optical remote sensing technologies used in early fire warning systems and provides an extensive survey on both flame and smoke detection algorithms employed by each technology. Three types of systems are identified, namely terrestrial, airborne, and spaceborne-based systems, while various models aiming to detect fire occurrences with high accuracy in challenging environments are studied. Finally, the strengths and weaknesses of fire detection systems based on optical remote sensing are discussed aiming to contribute to future research projects for the development of early warning fire systems.},
DOI = {10.3390/s20226442}
}



@Article{f11111190,
AUTHOR = {Lebedev, Vadim G. and Lebedeva, Tatyana N. and Chernodubov, Aleksey I. and Shestibratov, Konstantin A.},
TITLE = {Genomic Selection for Forest Tree Improvement: Methods, Achievements and Perspectives},
JOURNAL = {Forests},
VOLUME = {11},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {1190},
URL = {https://www.mdpi.com/1999-4907/11/11/1190},
ISSN = {1999-4907},
ABSTRACT = {The breeding of forest trees is only a few decades old, and is a much more complicated, longer, and expensive endeavor than the breeding of agricultural crops. One breeding cycle for forest trees can take 20&ndash;30 years. Recent advances in genomics and molecular biology have revolutionized traditional plant breeding based on visual phenotype assessment: the development of different types of molecular markers has made genotype selection possible. Marker-assisted breeding can significantly accelerate the breeding process, but this method has not been shown to be effective for selection of complex traits on forest trees. This new method of genomic selection is based on the analysis of all effects of quantitative trait loci (QTLs) using a large number of molecular markers distributed throughout the genome, which makes it possible to assess the genomic estimated breeding value (GEBV) of an individual. This approach is expected to be much more efficient for forest tree improvement than traditional breeding. Here, we review the current state of the art in the application of genomic selection in forest tree breeding and discuss different methods of genotyping and phenotyping. We also compare the accuracies of genomic prediction models and highlight the importance of a prior cost-benefit analysis before implementing genomic selection. Perspectives for the further development of this approach in forest breeding are also discussed: expanding the range of species and the list of valuable traits, the application of high-throughput phenotyping methods, and the possibility of using epigenetic variance to improve of forest trees.},
DOI = {10.3390/f11111190}
}



@Article{app10228008,
AUTHOR = {Kim, Byunghyun and Cho, Soojin},
TITLE = {Automated Multiple Concrete Damage Detection Using Instance Segmentation Deep Learning Model},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {8008},
URL = {https://www.mdpi.com/2076-3417/10/22/8008},
ISSN = {2076-3417},
ABSTRACT = {In many developed countries with a long history of urbanization, there is an increasing need for automated computer vision (CV)-based inspection to replace conventional labor-intensive visual inspection. This paper proposes a technique for the automated detection of multiple concrete damage based on a state-of-the-art deep learning framework, Mask R-CNN, developed for instance segmentation. The structure of Mask R-CNN, which consists of three stages (region proposal, classification, and segmentation) is optimized for multiple concrete damage detection. The optimized Mask R-CNN is trained with 765 concrete images including cracks, efflorescence, rebar exposure, and spalling. The performance of the trained Mask R-CNN is evaluated with 25 actual test images containing damage as well as environmental objects. Two types of metrics are proposed to measure localization and segmentation performance. On average, 90.41% precision and 90.81% recall are achieved for localization and 87.24% precision and 87.58% recall for segmentation, which indicates the excellent field applicability of the trained Mask R-CNN. This paper also qualitatively discusses the test results by explaining that the architecture of Mask R-CNN that is optimized for general object detection purposes, can be modified to detect long and slender shapes of cracks, rebar exposure, and efflorescence in further research.},
DOI = {10.3390/app10228008}
}



@Article{rs12223708,
AUTHOR = {Feng, Ziyi and Huang, Guanhua and Chi, Daocai},
TITLE = {Classification of the Complex Agricultural Planting Structure with a Semi-Supervised Extreme Learning Machine Framework},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3708},
URL = {https://www.mdpi.com/2072-4292/12/22/3708},
ISSN = {2072-4292},
ABSTRACT = {Many approaches have been developed to analyze remote sensing images. However, for the classification of large-scale problems, most algorithms showed low computational efficiency and low accuracy. In this paper, the newly developed semi-supervised extreme learning machine (SS-ELM) framework with k-means clustering algorithm for image segmentation and co-training algorithm to enlarge the sample sets was used to classify the agricultural planting structure at large-scale areas. Data sets collected from a small-scale area within the Hetao Irrigation District (HID) at the upper reaches of the Yellow River basin were used to evaluate the SS-ELM framework. The results of the SS-ELM algorithm were compared with those of the random forest (RF), ELM, support vector machine (SVM) and semi-supervised support vector machine (S-SVM) algorithms. Then the SS-ELM algorithm was applied to analyze the complex planting structure of HID in 1986&ndash;2010 by comparing the remote sensing estimated results with the statistical data. In the small-scale case, the SS-ELM algorithm performed better than the RF, ELM, SVM, and S-SVM algorithms. For the SS-ELM algorithm, the average overall accuracy (OA) was in a range of 83.00&ndash;92.17%. On the contrary, for the other four algorithms, their average OA values ranged from 56.97% to 92.84%. Whereas, in the classification of planting structure in HID, the SS-ELM algorithm had an excellent performance in classification accuracy and computational efficiency for three major planting crops including maize, wheat, and sunflowers. The estimated areas by using the SS-ELM algorithm based on the remote sensing images were consistent with the statistical data, and their difference was within a range of 3&ndash;25%. This implied that the SS-ELM framework could be served as an effective method for the classification of complex planting structures with relatively fast training, good generalization, universal approximation capability, and reasonable learning accuracy.},
DOI = {10.3390/rs12223708}
}



@Article{agronomy10111762,
AUTHOR = {Zhao, Biquan and Li, Jiating and Baenziger, P. Stephen and Belamkar, Vikas and Ge, Yufeng and Zhang, Jian and Shi, Yeyin},
TITLE = {Automatic Wheat Lodging Detection and Mapping in Aerial Imagery to Support High-Throughput Phenotyping and In-Season Crop Management},
JOURNAL = {Agronomy},
VOLUME = {10},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {1762},
URL = {https://www.mdpi.com/2073-4395/10/11/1762},
ISSN = {2073-4395},
ABSTRACT = {Latest advances in unmanned aerial vehicle (UAV) technology and convolutional neural networks (CNNs) allow us to detect crop lodging in a more precise and accurate way. However, the performance and generalization of a model capable of detecting lodging when the plants may show different spectral and morphological signatures have not been investigated much. This study investigated and compared the performance of models trained using aerial imagery collected at two growth stages of winter wheat with different canopy phenotypes. Specifically, three CNN-based models were trained with aerial imagery collected at early grain filling stage only, at physiological maturity only, and at both stages. Results show that the multi-stage model trained by images from both growth stages outperformed the models trained by images from individual growth stages on all testing data. The mean accuracy of the multi-stage model was 89.23% for both growth stages, while the mean of the other two models were 52.32% and 84.9%, respectively. This study demonstrates the importance of diversity of training data in big data analytics, and the feasibility of developing a universal decision support system for wheat lodging detection and mapping multi-growth stages with high-resolution remote sensing imagery.},
DOI = {10.3390/agronomy10111762}
}



@Article{rs12223715,
AUTHOR = {Park, Minsoo and Tran, Dai Quoc and Jung, Daekyo and Park, Seunghee},
TITLE = {Wildfire-Detection Method Using DenseNet and CycleGAN Data Augmentation-Based Remote Camera Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3715},
URL = {https://www.mdpi.com/2072-4292/12/22/3715},
ISSN = {2072-4292},
ABSTRACT = {To minimize the damage caused by wildfires, a deep learning-based wildfire-detection technology that extracts features and patterns from surveillance camera images was developed. However, many studies related to wildfire-image classification based on deep learning have highlighted the problem of data imbalance between wildfire-image data and forest-image data. This data imbalance causes model performance degradation. In this study, wildfire images were generated using a cycle-consistent generative adversarial network (CycleGAN) to eliminate data imbalances. In addition, a densely-connected-convolutional-networks-based (DenseNet-based) framework was proposed and its performance was compared with pre-trained models. While training with a train set containing an image generated by a GAN in the proposed DenseNet-based model, the best performance result value was realized among the models with an accuracy of 98.27% and an F1 score of 98.16, obtained using the test dataset. Finally, this trained model was applied to high-quality drone images of wildfires. The experimental results showed that the proposed framework demonstrated high wildfire-detection accuracy.},
DOI = {10.3390/rs12223715}
}



@Article{s20226485,
AUTHOR = {Stuparu, Delia-Georgiana and Ciobanu, Radu-Ioan and Dobre, Ciprian},
TITLE = {Vehicle Detection in Overhead Satellite Images Using a One-Stage Object Detection Model},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {6485},
URL = {https://www.mdpi.com/1424-8220/20/22/6485},
ISSN = {1424-8220},
ABSTRACT = {In order to improve the traffic in large cities and to avoid congestion, advanced methods of detecting and predicting vehicle behaviour are needed. Such methods require complex information regarding the number of vehicles on the roads, their positions, directions, etc. One way to obtain this information is by analyzing overhead images collected by satellites or drones, and extracting information from them through intelligent machine learning models. Thus, in this paper we propose and present a one-stage object detection model for finding vehicles in satellite images using the RetinaNet architecture and the Cars Overhead With Context dataset. By analyzing the results obtained by the proposed model, we show that it has a very good vehicle detection accuracy and a very low detection time, which shows that it can be employed to successfully extract data from real-time satellite or drone data.},
DOI = {10.3390/s20226485}
}



@Article{make2040030,
AUTHOR = {Combey, Théo and Loison, António and Faucher, Maxime and Hajri, Hatem},
TITLE = {Probabilistic Jacobian-Based Saliency Maps Attacks},
JOURNAL = {Machine Learning and Knowledge Extraction},
VOLUME = {2},
YEAR = {2020},
NUMBER = {4},
PAGES = {558--578},
URL = {https://www.mdpi.com/2504-4990/2/4/30},
ISSN = {2504-4990},
ABSTRACT = {Neural network classifiers (NNCs) are known to be vulnerable to malicious adversarial perturbations of inputs including those modifying a small fraction of the input features named sparse or L0 attacks. Effective and fast L0 attacks, such as the widely used Jacobian-based Saliency Map Attack (JSMA) are practical to fool NNCs but also to improve their robustness. In this paper, we show that penalising saliency maps of JSMA by the output probabilities and the input features of the NNC leads to more powerful attack algorithms that better take into account each input&rsquo;s characteristics. This leads us to introduce improved versions of JSMA, named Weighted JSMA (WJSMA) and Taylor JSMA (TJSMA), and demonstrate through a variety of white-box and black-box experiments on three different datasets (MNIST, CIFAR-10 and GTSRB), that they are both significantly faster and more efficient than the original targeted and non-targeted versions of JSMA. Experiments also demonstrate, in some cases, very competitive results of our attacks in comparison with the Carlini-Wagner (CW) L0 attack, while remaining, like JSMA, significantly faster (WJSMA and TJSMA are more than 50 times faster than CW L0 on CIFAR-10). Therefore, our new attacks provide good trade-offs between JSMA and CW for L0 real-time adversarial testing on datasets such as the ones previously cited.},
DOI = {10.3390/make2040030}
}



@Article{smartcities3040065,
AUTHOR = {Thakker, Dhavalkumar and Mishra, Bhupesh Kumar and Abdullatif, Amr and Mazumdar, Suvodeep and Simpson, Sydney},
TITLE = {Explainable Artificial Intelligence for Developing Smart Cities Solutions},
JOURNAL = {Smart Cities},
VOLUME = {3},
YEAR = {2020},
NUMBER = {4},
PAGES = {1353--1382},
URL = {https://www.mdpi.com/2624-6511/3/4/65},
ISSN = {2624-6511},
ABSTRACT = {Traditional Artificial Intelligence (AI) technologies used in developing smart cities solutions, Machine Learning (ML) and recently Deep Learning (DL), rely more on utilising best representative training datasets and features engineering and less on the available domain expertise. We argue that such an approach to solution development makes the outcome of solutions less explainable, i.e., it is often not possible to explain the results of the model. There is a growing concern among policymakers in cities with this lack of explainability of AI solutions, and this is considered a major hindrance in the wider acceptability and trust in such AI-based solutions. In this work, we survey the concept of &lsquo;explainable deep learning&rsquo; as a subset of the &lsquo;explainable AI&rsquo; problem and propose a new solution using Semantic Web technologies, demonstrated with a smart cities flood monitoring application in the context of a European Commission-funded project. Monitoring of gullies and drainage in crucial geographical areas susceptible to flooding issues is an important aspect of any flood monitoring solution. Typical solutions for this problem involve the use of cameras to capture images showing the affected areas in real-time with different objects such as leaves, plastic bottles etc., and building a DL-based classifier to detect such objects and classify blockages based on the presence and coverage of these objects in the images. In this work, we uniquely propose an Explainable AI solution using DL and Semantic Web technologies to build a hybrid classifier. In this hybrid classifier, the DL component detects object presence and coverage level and semantic rules designed with close consultation with experts carry out the classification. By using the expert knowledge in the flooding context, our hybrid classifier provides the flexibility on categorising the image using objects and their coverage relationships. The experimental results demonstrated with a real-world use case showed that this hybrid approach of image classification has on average 11% improvement (F-Measure) in image classification performance compared to DL-only classifier. It also has the distinct advantage of integrating experts&rsquo; knowledge on defining the decision-making rules to represent the complex circumstances and using such knowledge to explain the results.},
DOI = {10.3390/smartcities3040065}
}



@Article{s20226521,
AUTHOR = {Qi, Guanghui and Zhao, Gengxing and Xi, Xue},
TITLE = {Soil Salinity Inversion of Winter Wheat Areas Based on Satellite-Unmanned Aerial Vehicle-Ground Collaborative System in Coastal of the Yellow River Delta},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {6521},
URL = {https://www.mdpi.com/1424-8220/20/22/6521},
ISSN = {1424-8220},
ABSTRACT = {Soil salinization is an important factor affecting winter wheat growth in coastal areas. The rapid, accurate and efficient estimation of soil salt content is of great significance for agricultural production. The Kenli area in the Yellow River Delta was taken as the research area. Three machine learning inversion models, namely, BP neural network (BPNN), support vector machine (SVM) and random forest (RF) were constructed using ground-measured data and UAV images, and the optimal model is applied to UAV images to obtain the salinity inversion result, which is used as the true salt value of the Sentinel-2A image to establish BPNN, SVM and RF collaborative inversion models, and apply the optimal model to the study area. The results showed that the RF collaborative inversion model is optimal, R2 = 0.885. The inversion results are verified by using the measured soil salt data in the study area, which is significantly better than the directly satellite remote sensing inversion method. This study integrates the advantages of multi-scale data and proposes an effective &ldquo;Satellite-UAV-Ground&rdquo; collaborative inversion method for soil salinity, so as to obtain more accurate soil information, and provide more effective technical support for agricultural production.},
DOI = {10.3390/s20226521}
}



@Article{w12113195,
AUTHOR = {Park, Jungsu and Park, Jae-Hyeoung and Choi, June-Seok and Joo, Jin Chul and Park, Kihak and Yoon, Hyeon Cheol and Park, Cheol Young and Lee, Woo Hyoung and Heo, Tae-Young},
TITLE = {Ensemble Model Development for the Prediction of a Disaster Index in Water Treatment Systems},
JOURNAL = {Water},
VOLUME = {12},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {3195},
URL = {https://www.mdpi.com/2073-4441/12/11/3195},
ISSN = {2073-4441},
ABSTRACT = {The quantitative analysis of the disaster effect on water supply systems can provide useful information for water supply system management. In this study, a total disaster index (TDI) was developed using open-source public data in 419 water treatment plants in Korea with 23 input variables. The TDI quantifies the possible effects or damage caused by three major disasters (typhoons, heavy rain, and earthquakes) on water supply systems. The four components (regional factor, risk factor, urgency factor, and response and recovery factor) were calculated using input variables to determine the disaster index (DI) of each disaster. The weight of the input variables was determined using principal component analysis (PCA), and the weights of the DI of three natural disasters and four components used to calculate the TDI were determined by the analytical hierarchy process (AHP). Specifically, two ensemble machine learning models, random forest (RF) and XGBoost (XGB), were used to develop models to predict the TDI. Both models predicted the TDI with the coefficient of determination and root-mean-square error-observations standard deviation ratio of 0.8435 and 0.3957 for the RF model and 0.8629 and 0.3703 for the XGB model, respectively. The relative importance analysis suggests that the number of input variables can be minimized, which improves the models&rsquo; practical applicability.},
DOI = {10.3390/w12113195}
}



@Article{app10228105,
AUTHOR = {Kim, Jung Jin and Kim, Ah-Ram and Lee, Seong-Won},
TITLE = {Artificial Neural Network-Based Automated Crack Detection and Analysis for the Inspection of Concrete Structures},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {8105},
URL = {https://www.mdpi.com/2076-3417/10/22/8105},
ISSN = {2076-3417},
ABSTRACT = {The damage investigation and inspection methods for infrastructures performed in small-scale (type III) facilities usually involve a visual examination by an inspector using surveying tools (e.g., cracking, crack microscope, etc.) in the field. These methods can interfere with the subjectivity of the inspector, which may reduce the objectivity and reliability of the record. Therefore, a new image analysis technique is needed to automatically detect cracks and analyze the characteristics of the cracks objectively. In this study, an image analysis technique using deep learning is developed to detect cracks and analyze characteristics (e.g., length, and width) in images for small-scale facilities. Three stages of image processing pipeline are proposed to obtain crack detection and its characteristics. In the first and second stages, two-dimensional convolutional neural networks are used for crack image detection (e.g., classification and segmentation). Based on convolution neural network for the detection, hierarchical feature learning architecture is applied into our deep learning network. After deep learning-based detection, in the third stage, thinning and tracking algorithms are applied to analyze length and width of crack in the image. The performance of the proposed method was tested using various crack images with label and the results showed good performance of crack detection and its measurement.},
DOI = {10.3390/app10228105}
}



@Article{rs12223764,
AUTHOR = {Zhang, Peng and Du, Peijun and Lin, Cong and Wang, Xin and Li, Erzhu and Xue, Zhaohui and Bai, Xuyu},
TITLE = {A Hybrid Attention-Aware Fusion Network (HAFNet) for Building Extraction from High-Resolution Imagery and LiDAR Data},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3764},
URL = {https://www.mdpi.com/2072-4292/12/22/3764},
ISSN = {2072-4292},
ABSTRACT = {Automated extraction of buildings from earth observation (EO) data has long been a fundamental but challenging research topic. Combining data from different modalities (e.g., high-resolution imagery (HRI) and light detection and ranging (LiDAR) data) has shown great potential in building extraction. Recent studies have examined the role that deep learning (DL) could play in both multimodal data fusion and urban object extraction. However, DL-based multimodal fusion networks may encounter the following limitations: (1) the individual modal and cross-modal features, which we consider both useful and important for final prediction, cannot be sufficiently learned and utilized and (2) the multimodal features are fused by a simple summation or concatenation, which appears ambiguous in selecting cross-modal complementary information. In this paper, we address these two limitations by proposing a hybrid attention-aware fusion network (HAFNet) for building extraction. It consists of RGB-specific, digital surface model (DSM)-specific, and cross-modal streams to sufficiently learn and utilize both individual modal and cross-modal features. Furthermore, an attention-aware multimodal fusion block (Att-MFBlock) was introduced to overcome the fusion problem by adaptively selecting and combining complementary features from each modality. Extensive experiments conducted on two publicly available datasets demonstrated the effectiveness of the proposed HAFNet for building extraction.},
DOI = {10.3390/rs12223764}
}



@Article{s20226545,
AUTHOR = {Liu, Huan and Li, Shiyong and Sun, Wei},
TITLE = {Resource Allocation for Edge Computing without Using Cloud Center in Smart Home Environment: A Pricing Approach},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {6545},
URL = {https://www.mdpi.com/1424-8220/20/22/6545},
ISSN = {1424-8220},
ABSTRACT = {Recently, more and more smart homes have become one of important parts of home infrastructure. However, most of the smart home applications are not interconnected and remain isolated. They use the cloud center as the control platform, which increases the risk of link congestion and data security. Thus, in the future, smart homes based on edge computing without using cloud center become an important research area. In this paper, we assume that all applications in a smart home environment are composed of edge nodes and users. In order to maximize the utility of users, we assume that all users and edge nodes are placed in a market and formulate a pricing resource allocation model with utility maximization. We apply the Lagrangian method to analyze the model, so an edge node (provider in the market) allocates its resources to a user (customer in the market) based on the prices of resources and the utility related to the preference of users. To obtain the optimal resource allocation, we propose a pricing-based resource allocation algorithm by using low-pass filtering scheme and conform that the proposed algorithm can achieve an optimum within reasonable convergence times through some numerical examples.},
DOI = {10.3390/s20226545}
}



@Article{rs12223776,
AUTHOR = {Tassi, Andrea and Vizzari, Marco},
TITLE = {Object-Oriented LULC Classification in Google Earth Engine Combining SNIC, GLCM, and Machine Learning Algorithms},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3776},
URL = {https://www.mdpi.com/2072-4292/12/22/3776},
ISSN = {2072-4292},
ABSTRACT = {Google Earth Engine (GEE) is a versatile cloud platform in which pixel-based (PB) and object-oriented (OO) Land Use&ndash;Land Cover (LULC) classification approaches can be implemented, thanks to the availability of the many state-of-art functions comprising various Machine Learning (ML) algorithms. OO approaches, including both object segmentation and object textural analysis, are still not common in the GEE environment, probably due to the difficulties existing in concatenating the proper functions, and in tuning the various parameters to overcome the GEE computational limits. In this context, this work is aimed at developing and testing an OO classification approach combining the Simple Non-Iterative Clustering (SNIC) algorithm to identify spatial clusters, the Gray-Level Co-occurrence Matrix (GLCM) to calculate cluster textural indices, and two ML algorithms (Random Forest (RF) or Support Vector Machine (SVM)) to perform the final classification. A Principal Components Analysis (PCA) is applied to the main seven GLCM indices to synthesize in one band the textural information used for the OO classification. The proposed approach is implemented in a user-friendly, freely available GEE code useful to perform the OO classification, tuning various parameters (e.g., choose the input bands, select the classification algorithm, test various segmentation scales) and compare it with a PB approach. The accuracy of OO and PB classifications can be assessed both visually and through two confusion matrices that can be used to calculate the relevant statistics (producer&rsquo;s, user&rsquo;s, overall accuracy (OA)). The proposed methodology was broadly tested in a 154 km2 study area, located in the Lake Trasimeno area (central Italy), using Landsat 8 (L8), Sentinel 2 (S2), and PlanetScope (PS) data. The area was selected considering its complex LULC mosaic mainly composed of artificial surfaces, annual and permanent crops, small lakes, and wooded areas. In the study area, the various tests produced interesting results on the different datasets (OA: PB RF (L8 = 72.7%, S2 = 82%, PS = 74.2), PB SVM (L8 = 79.1%, S2 = 80.2%, PS = 74.8%), OO RF (L8 = 64%, S2 = 89.3%, PS = 77.9), OO SVM (L8 = 70.4, S2 = 86.9%, PS = 73.9)). The broad code application demonstrated very good reliability of the whole process, even though the OO classification process resulted, sometimes, too demanding on higher resolution data, considering the available computational GEE resources.},
DOI = {10.3390/rs12223776}
}



@Article{s20226585,
AUTHOR = {Zhang, Zichen and Boubin, Jayson and Stewart, Christopher and Khanal, Sami},
TITLE = {Whole-Field Reinforcement Learning: A Fully Autonomous Aerial Scouting Method for Precision Agriculture},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {6585},
URL = {https://www.mdpi.com/1424-8220/20/22/6585},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial systems (UAS) are increasingly used in precision agriculture to collect crop health related data. UAS can capture data more often and more cost-effectively than sending human scouts into the field. However, in large crop fields, flight time, and hence data collection, is limited by battery life. In a conventional UAS approach, human operators are required to exchange depleted batteries many times, which can be costly and time consuming. In this study, we developed a novel, fully autonomous aerial scouting approach that preserves battery life by sampling sections of a field for sensing and predicting crop health for the whole field. Our approach uses reinforcement learning (RL) and convolutional neural networks (CNN) to accurately and autonomously sample the field. To develop and test the approach, we ran flight simulations on an aerial image dataset collected from an 80-acre corn field. The excess green vegetation Index was used as a proxy for crop health condition. Compared to the conventional UAS scouting approach, the proposed scouting approach sampled 40% of the field, predicted crop health with 89.8% accuracy, reduced labor cost by 4.8&times; and increased agricultural profits by 1.36&times;.},
DOI = {10.3390/s20226585}
}



@Article{rs12223778,
AUTHOR = {Fu, Yuanyuan and Yang, Guijun and Li, Zhenhai and Song, Xiaoyu and Li, Zhenhong and Xu, Xingang and Wang, Pei and Zhao, Chunjiang},
TITLE = {Winter Wheat Nitrogen Status Estimation Using UAV-Based RGB Imagery and Gaussian Processes Regression},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3778},
URL = {https://www.mdpi.com/2072-4292/12/22/3778},
ISSN = {2072-4292},
ABSTRACT = {Predicting the crop nitrogen (N) nutrition status is critical for optimizing nitrogen fertilizer application. The present study examined the ability of multiple image features derived from unmanned aerial vehicle (UAV) RGB images for winter wheat N status estimation across multiple critical growth stages. The image features consisted of RGB-based vegetation indices (VIs), color parameters, and textures, which represented image features of different aspects and different types. To determine which N status indicators could be well-estimated, we considered two mass-based N status indicators (i.e., the leaf N concentration (LNC) and plant N concentration (PNC)) and two area-based N status indicators (i.e., the leaf N density (LND) and plant N density (PND)). Sixteen RGB-based VIs associated with crop growth were selected. Five color space models, including RGB, HSV, L*a*b*, L*c*h*, and L*u*v*, were used to quantify the winter wheat canopy color. The combination of Gaussian processes regression (GPR) and Gabor-based textures with four orientations and five scales was proposed to estimate the winter wheat N status. The gray level co-occurrence matrix (GLCM)-based textures with four orientations were extracted for comparison. The heterogeneity in the textures of different orientations was evaluated using the measures of mean and coefficient of variation (CV). The variable importance in projection (VIP) derived from partial least square regression (PLSR) and a band analysis tool based on Gaussian processes regression (GPR-BAT) were used to identify the best performing image features for the N status estimation. The results indicated that (1) the combination of RGB-based VIs or color parameters only could produce reliable estimates of PND and the GPR model based on the combination of color parameters yielded a higher accuracy for the estimation of PND (R2val = 0.571, RMSEval = 2.846 g/m2, and RPDval = 1.532), compared to that based on the combination of RGB-based VIs; (2) there was no significant heterogeneity in the textures of different orientations and the textures of 45 degrees were recommended in the winter wheat N status estimation; (3) compared with the RGB-based VIs and color parameters, the GPR model based on the Gabor-based textures produced a higher accuracy for the estimation of PND (R2val = 0.675, RMSEval = 2.493 g/m2, and RPDval = 1.748) and the PLSR model based on the GLCM-based textures produced a higher accuracy for the estimation of PNC (R2val = 0.612, RMSEval = 0.380%, and RPDval = 1.601); and (4) the combined use of RGB-based VIs, color parameters, and textures produced comparable estimation results to using textures alone. Both VIP-PLSR and GPR-BAT analyses confirmed that image textures contributed most to the estimation of winter wheat N status. The experimental results reveal the potential of image textures derived from high-definition UAV-based RGB images for the estimation of the winter wheat N status. They also suggest that a conventional low-cost digital camera mounted on a UAV could be well-suited for winter wheat N status monitoring in a fast and non-destructive way.},
DOI = {10.3390/rs12223778}
}



@Article{rs12223789,
AUTHOR = {Li, Bo and Gan, Zhigang and Chen, Daqing and Sergey Aleksandrovich, Dyachenko},
TITLE = {UAV Maneuvering Target Tracking in Uncertain Environments Based on Deep Reinforcement Learning and Meta-Learning},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3789},
URL = {https://www.mdpi.com/2072-4292/12/22/3789},
ISSN = {2072-4292},
ABSTRACT = {This paper combines deep reinforcement learning (DRL) with meta-learning and proposes a novel approach, named meta twin delayed deep deterministic policy gradient (Meta-TD3), to realize the control of unmanned aerial vehicle (UAV), allowing a UAV to quickly track a target in an environment where the motion of a target is uncertain. This approach can be applied to a variety of scenarios, such as wildlife protection, emergency aid, and remote sensing. We consider a multi-task experience replay buffer to provide data for the multi-task learning of the DRL algorithm, and we combine meta-learning to develop a multi-task reinforcement learning update method to ensure the generalization capability of reinforcement learning. Compared with the state-of-the-art algorithms, namely the deep deterministic policy gradient (DDPG) and twin delayed deep deterministic policy gradient (TD3), experimental results show that the Meta-TD3 algorithm has achieved a great improvement in terms of both convergence value and convergence rate. In a UAV target tracking problem, Meta-TD3 only requires a few steps to train to enable a UAV to adapt quickly to a new target movement mode more and maintain a better tracking effectiveness.},
DOI = {10.3390/rs12223789}
}



@Article{rs12223783,
AUTHOR = {Khanal, Sami and KC, Kushal and Fulton, John P. and Shearer, Scott and Ozkan, Erdal},
TITLE = {Remote Sensing in Agriculture—Accomplishments, Limitations, and Opportunities},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3783},
URL = {https://www.mdpi.com/2072-4292/12/22/3783},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing (RS) technologies provide a diagnostic tool that can serve as an early warning system, allowing the agricultural community to intervene early on to counter potential problems before they spread widely and negatively impact crop productivity. With the recent advancements in sensor technologies, data management and data analytics, currently, several RS options are available to the agricultural community. However, the agricultural sector is yet to implement RS technologies fully due to knowledge gaps on their sufficiency, appropriateness and techno-economic feasibilities. This study reviewed the literature between 2000 to 2019 that focused on the application of RS technologies in production agriculture, ranging from field preparation, planting, and in-season applications to harvesting, with the objective of contributing to the scientific understanding on the potential for RS technologies to support decision-making within different production stages. We found an increasing trend in the use of RS technologies in agricultural production over the past 20 years, with a sharp increase in applications of unmanned aerial systems (UASs) after 2015. The largest number of scientific papers related to UASs originated from Europe (34%), followed by the United States (20%) and China (11%). Most of the prior RS studies have focused on soil moisture and in-season crop health monitoring, and less in areas such as soil compaction, subsurface drainage, and crop grain quality monitoring. In summary, the literature highlighted that RS technologies can be used to support site-specific management decisions at various stages of crop production, helping to optimize crop production while addressing environmental quality, profitability, and sustainability.},
DOI = {10.3390/rs12223783}
}



@Article{app10228189,
AUTHOR = {Lee, Sunmin and Baek, Won-Kyung and Jung, Hyung-Sup and Lee, Saro},
TITLE = {Susceptibility Mapping on Urban Landslides Using Deep Learning Approaches in Mt. Umyeon},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {8189},
URL = {https://www.mdpi.com/2076-3417/10/22/8189},
ISSN = {2076-3417},
ABSTRACT = {In recent years, the incidence of localized heavy rainfall has increased as abnormal weather events occur more frequently. In densely populated urban areas, this type of heavy rain can cause extreme landslide damage, so that it is necessary to estimate and analyze the susceptibility of future landslides. In this regard, deep learning (DL) methodologies have been used to identify areas prone to landslides recently. Therefore, in this study, DL methodologies, including a deep neural network (DNN), kernel-based DNN, and convolutional neural network (CNN) were used to identify areas where landslides could occur. As a detailed step for this purpose, landslide occurrence was first determined as landslide inventory through aerial photographs with comparative analysis using field survey data; a training set was built for model training through oversampling based on the landslide inventory. A total of 17 landslide influencing variables that influence the frequency of landslides by topography and geomorphology, as well as soil and forest variables, were selected to establish a landslide inventory. Then models were built using DNN, kernel-based DNN, and CNN models, and the susceptibility of landslides in the study area was determined. Model performance was evaluated through the average precision (AP) score and root mean square error (RMSE) for each of the three models. Finally, DNN, kernel-based DNN, and CNN models showed performances of 99.45%, 99.44%, and 99.41%, and RMSE values of 0.1694, 0.1806, and 0.1747, respectively. As a result, all three models showed similar performance, indicating excellent predictive ability of the models developed in this study. The information of landslides occurring in urban areas, which cause a great damage even with a small number of occurrences, can provide a basis for reference to the government and local authorities for urban landslide management.},
DOI = {10.3390/app10228189}
}



@Article{rs12223797,
AUTHOR = {Radke, David and Radke, Daniel and Radke, John},
TITLE = {Beyond Measurement: Extracting Vegetation Height from High Resolution Imagery with Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3797},
URL = {https://www.mdpi.com/2072-4292/12/22/3797},
ISSN = {2072-4292},
ABSTRACT = {Measuring and monitoring the height of vegetation provides important insights into forest age and habitat quality. These are essential for the accuracy of applications that are highly reliant on up-to-date and accurate vegetation data. Current vegetation sensing practices involve ground survey, photogrammetry, synthetic aperture radar (SAR), and airborne light detection and ranging sensors (LiDAR). While these methods provide high resolution and accuracy, their hardware and collection effort prohibits highly recurrent and widespread collection. In response to the limitations of current methods, we designed Y-NET, a novel deep learning model to generate high resolution models of vegetation from highly recurrent multispectral aerial imagery and elevation data. Y-NET&rsquo;s architecture uses convolutional layers to learn correlations between different input features and vegetation height, generating an accurate vegetation surface model (VSM) at 1&times;1 m resolution. We evaluated Y-NET on 235 km2 of the East San Francisco Bay Area and find that Y-NET achieves low error from LiDAR when tested on new locations. Y-NET also achieves an R2 of 0.83 and can effectively model complex vegetation through side-by-side visual comparisons. Furthermore, we show that Y-NET is able to identify instances of vegetation growth and mitigation by comparing aerial imagery and LiDAR collected at different times.},
DOI = {10.3390/rs12223797}
}



@Article{rs12223796,
AUTHOR = {Rashidi, Maria and Mohammadi, Masoud and Sadeghlou Kivi, Saba and Abdolvand, Mohammad Mehdi and Truong-Hong, Linh and Samali, Bijan},
TITLE = {A Decade of Modern Bridge Monitoring Using Terrestrial Laser Scanning: Review and Future Directions},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3796},
URL = {https://www.mdpi.com/2072-4292/12/22/3796},
ISSN = {2072-4292},
ABSTRACT = {Over the last decade, particular interest in using state-of-the-art emerging technologies for inspection, assessment, and management of civil infrastructures has remarkably increased. Advanced technologies, such as laser scanners, have become a suitable alternative for labor intensive, expensive, and unsafe traditional inspection and maintenance methods, which encourage the increasing use of this technology in construction industry, especially in bridges. This paper aims to provide a thorough mixed scientometric and state-of-the-art review on the application of terrestrial laser scanners (TLS) in bridge engineering and explore investigations and recommendations of researchers in this area. Following the review, more than 1500 research publications were collected, investigated and analyzed through a two-fold literature search published within the last decade from 2010 to 2020. Research trends, consisting of dominated sub-fields, co-occurrence of keywords, network of researchers and their institutions, along with the interaction of research networks, were quantitatively analyzed. Moreover, based on the collected papers, application of TLS in bridge engineering and asset management was reviewed according to four categories including (1) generation of 3D model, (2) quality inspection, (3) structural assessment, and (4) bridge information modeling (BrIM). Finally, the paper identifies the current research gaps, future directions obtained from the quantitative analysis, and in-depth discussions of the collected papers in this area.},
DOI = {10.3390/rs12223796}
}



@Article{app10228224,
AUTHOR = {Naranjo, Jose E. and Sanchez, Diego G. and Robalino-Lopez, Angel and Robalino-Lopez, Paola and Alarcon-Ortiz, Andrea and Garcia, Marcelo V.},
TITLE = {A Scoping Review on Virtual Reality-Based Industrial Training},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {8224},
URL = {https://www.mdpi.com/2076-3417/10/22/8224},
ISSN = {2076-3417},
ABSTRACT = {The fourth industrial revolution has forced most companies to technologically evolve, applying new digital tools, so that their workers can have the necessary skills to face changing work environments. This article presents a scoping review of the literature on virtual reality-based training systems. The methodology consisted of four steps, which pose research questions, document search, paper selection, and data extraction. From a total of 350 peer-reviewed database articles, such as SpringerLink, IEEEXplore, MDPI, Scopus, and ACM, 44 were eventually chosen, mostly using the virtual reality haptic glasses and controls from Oculus Rift and HTC VIVE. It was concluded that, among the advantages of using this digital tool in the industry, is the commitment, speed, measurability, preservation of the integrity of the workers, customization, and cost reduction. Even though several research gaps were found, virtual reality is presented as a present and future alternative for the efficient training of human resources in the industrial field.},
DOI = {10.3390/app10228224}
}



@Article{electronics9111961,
AUTHOR = {Thanh, Pham Duy and Hoan, Tran Nhut Khai and Giang, Hoang Thi Huong and Koo, Insoo},
TITLE = {Cache-Enabled Data Rate Maximization for Solar-Powered UAV Communication Systems},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {1961},
URL = {https://www.mdpi.com/2079-9292/9/11/1961},
ISSN = {2079-9292},
ABSTRACT = {Currently, deploying fixed terrestrial infrastructures is not cost-effective in temporary circumstances, such as natural disasters, hotspots, and so on. Thus, we consider a system of caching-based UAV-assisted communications between multiple ground users (GUs) and a local station (LS). Specifically, a UAV is exploited to cache data from the LS and then serve GUs&rsquo; requests to handle the issue of unavailable or damaged links from the LS to the GUs. The UAV can harvest solar energy for its operation. We investigate joint cache scheduling and power allocation schemes by using the non-orthogonal multiple access (NOMA) technique to maximize the long-term downlink rate. Two scenarios for the network are taken into account. In the first, the harvested energy distribution of the GUs is assumed to be known, and we propose a partially observable Markov decision process framework such that the UAV can allocate optimal transmission power for each GU based on proper content caching over each flight period. In the second scenario where the UAV does not know the environment&rsquo;s dynamics in advance, an actor-critic-based scheme is proposed to achieve a solution by learning with a dynamic environment. Afterwards, the simulation results verify the effectiveness of the proposed methods, compared to baseline approaches.},
DOI = {10.3390/electronics9111961}
}



@Article{rs12223808,
AUTHOR = {Su, Jinhua and Bai, Yanbing and Wang, Xingrui and Lu, Dong and Zhao, Bo and Yang, Hanfang and Mas, Erick and Koshimura, Shunichi},
TITLE = {Technical Solution Discussion for Key Challenges of Operational Convolutional Neural Network-Based Building-Damage Assessment from Satellite Imagery: Perspective from Benchmark xBD Dataset},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3808},
URL = {https://www.mdpi.com/2072-4292/12/22/3808},
ISSN = {2072-4292},
ABSTRACT = {Earth Observation satellite imaging helps building diagnosis during a disaster. Several models are put forward on the xBD dataset, which can be divided into two levels: the building level and the pixel level. Models from two levels evolve into several versions that will be reviewed in this paper. There are four key challenges hindering researchers from moving forward on this task, and this paper tries to give technical solutions. First, metrics on different levels could not be compared directly. We put forward a fairer metric and give a method to convert between metrics of two levels. Secondly, drone images may be another important source, but drone data may have only a post-disaster image. This paper shows and compares methods of directly detecting and generating. Thirdly, the class imbalance is a typical feature of the xBD dataset and leads to a bad F1 score for minor damage and major damage. This paper provides four specific data resampling strategies, which are Main-Label Over-Sampling (MLOS), Discrimination After Cropping (DAC), Dilation of Area with Minority (DAM) and Synthetic Minority Over-Sampling Technique (SMOTE), as well as cost-sensitive re-weighting schemes. Fourthly, faster prediction meets the need for a real-time situation. This paper recommends three specific methods, feature-map subtraction, parameter sharing, and knowledge distillation. Finally, we developed our AI-driven Damage Diagnose Platform (ADDP). This paper introduces the structure of ADDP and technical details. Customized settings, interface preview, and upload and download satellite images are major services our platform provides.},
DOI = {10.3390/rs12223808}
}




@article{TSAVE2019100244,
title = {The anatomy of bacteria-inspired nanonetworks: Molecular nanomachines in message dissemination},
journal = {Nano Communication Networks},
volume = {21},
pages = {100244},
year = {2019},
issn = {1878-7789},
doi = {https://doi.org/10.1016/j.nancom.2019.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S187877891830139X},
author = {Olga Tsave and Ioannis Kavakiotis and Konstantinos Kantelis and Stathis Mavridopoulos and Petros Nicopolitidis and Georgios Papadimitriou and Ioannis Vlahavas and Athanasios Salifoglou},
keywords = {Nanocommunication networks, Biological communication systems, Message dissemination, Bacteria communication system modeling, Bacteria nanonetworks},
abstract = {Nanotechnology is an emerging field devoted to providing new insight into a vast range of subjects interfacing sciences and engineering. As advances in nanotechnology emerge continuously, new areas of applications in nanoscale communication also emerge that involve biological systems. By definition, nanocommunication is the exchange of information at nanoscale level and constitutes the basis of any wireless interconnection of individual nanomachines comprising a nanonetwork. Such systems have unique properties that must be taken into account, when trying to delve into new communication paradigms based on micro-biological communication systems. In this context, development of bio-inspired nanonetworks is a fledgling yet fast growing area of scientific interest with a significant impact on future applications in multiple fields. A representative family of such systems includes bacterial nanonetworks, where specific key parameters of bacterial physiology can be utilized to model and develop appropriate information dissemination in nano level frameworks. Hence, the aim of this work is to conduct a systematic review of the approaches used to investigate bacterial nanonetworks with respect to (a) potential applications, (b) techniques and tools employed, and (c) parameters modeled. The results of this investigation project the salient features of parametrically-driven modeling approaches that could act as potential ground breakers in the future development of bacteria-inspired nanonetworks. In that sense, the title approaches in the surveyed literature project the usefulness of extracting valuable knowledge for deeper understanding of functional nanosystems. That, in turn, gives rise to new hypotheses on the development of future functionally selective bio-inspired nanoscale networks.}
}
@article{ALI2011556,
title = {A case for on-machine load balancing},
journal = {Journal of Parallel and Distributed Computing},
volume = {71},
number = {4},
pages = {556-564},
year = {2011},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2010.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0743731510002352},
author = {Shoukat Ali and Behdis Eslamnour and Zehra Shah},
keywords = {Load balancing and task assignment, Application studies resulting in better multiple-processor systems, Measurement, evaluation, modeling, simulation of multiple-processor systems, Resource allocation},
abstract = {This paper diverges from the traditional load balancing, and introduces a new principle called the on-machine load balance rule. The on-machine load balance rule leads to resource allocations that are better in tolerating uncertainties in the processing times of the tasks allocated to the resources when compared to other resource allocations that are derived using the conventional “across-the-machines” load balancing rule. The on-machine load balance rule calls for the resource allocation algorithms to allocate similarly sized tasks on a machine (in addition to optimizing some primary performance measures such as estimated makespan and average response time). The on-machine load balance rule is very different from the usual across-the-machines load balance rule that strives to balance load across resources so that all resources have similar finishing times. We give a mathematical justification for the on-machine load balance rule requiring only liberal assumptions about task processing times. Then we validate with extensive simulations that the resource allocations derived using on-machine load balance rule are indeed more tolerant of uncertain task processing times.}
}
@article{APILETTI201753,
title = {A Parallel MapReduce Algorithm to Efficiently Support Itemset Mining on High Dimensional Data},
journal = {Big Data Research},
volume = {10},
pages = {53-69},
year = {2017},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2017.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S2214579616301046},
author = {Daniele Apiletti and Elena Baralis and Tania Cerquitelli and Paolo Garza and Fabio Pulvirenti and Pietro Michiardi},
keywords = {High-dimensional data, Frequent closed itemset mining, Hadoop framework},
abstract = {In today's world, large volumes of data are being continuously generated by many scientific applications, such as bioinformatics or networking. Since each monitored event is usually characterized by a variety of features, high-dimensional datasets have been continuously generated. To extract value from these complex collections of data, different exploratory data mining algorithms can be used to discover hidden and non-trivial correlations among data. Frequent closed itemset mining is an effective but computational expensive technique that is usually used to support data exploration. Thanks to the spread of distributed and parallel frameworks, the development of scalable approaches able to deal with the so called Big Data has been extended to frequent itemset mining. Unfortunately, most of the current algorithms are designed to cope with low-dimensional datasets, delivering poor performances in those use cases characterized by high-dimensional data. This work introduces PaMPa-HD, a MapReduce-based frequent closed itemset mining algorithm for high dimensional datasets. An efficient solution has been proposed to parallelize and speed up the mining process. Furthermore, different strategies have been proposed to easily configure the algorithm parameter. The experimental results, performed on real-life high-dimensional use cases, show the efficiency of the proposed approach in terms of execution time, load balancing and robustness to memory issues.}
}
@article{ZOU2018698,
title = {Mining and updating association rules based on fuzzy concept lattice},
journal = {Future Generation Computer Systems},
volume = {82},
pages = {698-706},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.11.018},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17312451},
author = {Caifeng Zou and Huifang Deng and Jiafu Wan and Zhongren Wang and Pan Deng},
keywords = {Association rule, Fuzzy concept lattice, Construction algorithm, Data mining},
abstract = {An algorithm for mining and updating association rules based on fuzzy concept lattice is proposed. When a new attribute is added into the fuzzy concept lattice, it is not necessary to calculate all the frequent nodes and association rules. According to the incremental construction algorithm of fuzzy concept lattice, it is only necessary to deal with the new nodes that have changed. Therefore, the amount of calculation is reduced. The existing incremental construction algorithm of precise concept lattices based on attributes is extended so that it can be applied to fuzzy concept lattices. The pruning technology is used to improve the construction algorithm. The steps for generating and updating association rules are added. According to the extended algorithm, the fuzzy concept lattice can be constructed, and the corresponding association rules can be generated and updated at the same time. The experimental results show that the algorithm proposed in this paper greatly reduces the computational workload, and shortens the running time.}
}
@article{ROKNI2018222,
title = {Optimum energy resource scheduling in a microgrid using a distributed algorithm framework},
journal = {Sustainable Cities and Society},
volume = {37},
pages = {222-231},
year = {2018},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2017.11.016},
url = {https://www.sciencedirect.com/science/article/pii/S2210670717307886},
author = {Seyed Ghasem Mirbabaee Rokni and Masoud Radmehr and Alireza Zakariazadeh},
keywords = {Distributed algorithms, Micro-grid, Optimization, Energy management system, Dual decomposition, Energy scheduling},
abstract = {Smart Energy Management System (SEMS) as the mastermind of microgrid is a robust software to manage both demands and generation units. Moreover, SEMS sets optimal regulations between different energy resources. A centralized solution for MG energy management system requires high computational capabilities due to a non-linear and discrete nature of the problem. In this paper, a distributed energy management system called Alternating Direction Method of the multiplier (ADMM) has been proposed in order to jointly schedule the central controller as well as local controllers. The algorithm considers optimal power flow equations within the distributed energy management problem. The proposed distributed algorithm has been investigated on a typical MG and the efficiency of the algorithm has been evidenced through case studies. Our findings show that the proposed method decrease the operational cost of MG.}
}
@article{FASOULAKIS2019135,
title = {Satisfy instead of maximize: Improving operation efficiency in wireless communication networks},
journal = {Computer Networks},
volume = {159},
pages = {135-146},
year = {2019},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2019.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618313896},
author = {Michail Fasoulakis and Eirini Eleni Tsiropoulou and Symeon Papavassiliou},
keywords = {Game theory, QoS Satisfaction, Satisfaction equilibrium, Network efficiency, Gaussian interference channel},
abstract = {Spectrum scarcity, combined with the tremendous increase of mobile users and their need for personalized services with different Quality of Service (QoS) requirements, fuel the necessity for the design of resource management approaches that ensure operation efficiency, flexibility and scalability. In this paper, we provide a novel theoretical framework to study several forms of efficient and stable system operation points, stemming from the concept of Satisfaction Equilibria, in the context of wireless communication networks. Considering a wireless communication environment under the presence of the Gaussian Interference Channel (GIC), a non-cooperative game among the users is studied, where the users aim in a selfish manner to meet their Quality of Service (QoS) prerequisite, in terms of data rate. We argue that instead of maximizing the QoS which is generally energy costly, better energy-efficiency is achieved by targeting satisfactory QoS levels only, thus obtaining Satisfaction Equilibria solutions. The sufficient and necessary conditions that lead to the Satisfaction Equilibrium are initially provided for the two-user case and the Efficient Satisfaction Equilibrium (ESE) is determined, where the users satisfy their QoS constraints with the lowest possible cost (i.e., power). An algorithmic approach following the best-response dynamics is provided to treat the multi-user case. To study and evaluate these equilibria operation points in a formal and quantitative manner, we coin some new theoretical concepts, namely the Price of Efficiency, Max Price of Efficiency and Max Price of Satisfaction, expressing the tradeoff of the achieved utility and the corresponding cost or the distance between the Satisfaction Equilibria of a given objective function. Finally, the performance evaluation of the proposed framework is obtained via modeling and simulation.}
}
@article{XIA202073,
title = {Resource scheduling for piano teaching system of internet of things based on mobile edge computing},
journal = {Computer Communications},
volume = {158},
pages = {73-84},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.04.056},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420302930},
author = {Yu Xia},
keywords = {Edge computing, Internet of things, Piano teaching, System resources, Resource scheduling},
abstract = {The effective operation of the piano teaching system of the Internet of Things requires the effective support of virtualization technology. In particular, on the basis that the edge computing standards and systems are not yet mature, the resource scheduling problem of edge computing needs to be studied from the actual point of view. In order to improve the effective operation of the piano teaching system of Internet of Things, this study analyzes the resource scheduling of delay-sensitive applications, sets the resource scheduling mode based on the space–time difference of the edge container load in a multi-cluster environment, and proposes a cross-cluster scheduling strategy. Simultaneously, this study uses simulation experiments to analyze the performance of the strategy proposed in this paper. The research results show that the strategy proposed in this paper can perform delay-insensitive application scheduling during system operation, achieve multi-cluster collaborative scheduling goals, and make the load between clusters more balanced.}
}
@article{VUCETIC2020103395,
title = {Fuzzy functional dependencies and linguistic interpretations employed in knowledge discovery tasks from relational databases},
journal = {Engineering Applications of Artificial Intelligence},
volume = {88},
pages = {103395},
year = {2020},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2019.103395},
url = {https://www.sciencedirect.com/science/article/pii/S0952197619303136},
author = {Miljan Vučetić and Miroslav Hudec and Boško Božilović},
keywords = {Knowledge discovery, Data mining, Fuzzy functional dependency, Linguistic interpretation, Fuzzy logic, Fuzzy adverb},
abstract = {Knowledge discovery from databases copes with several problems including the heterogeneity of data and interpreting the solution in an understandable and convenient form for domain experts. Fuzzy logic approaches based on the computing with words paradigm are very appealing since they offer the possibility to express useful knowledge from a large volume of data by linguistic terms, which are easily understandable for diverse users. In this paper, the novel descriptive data mining algorithm based on fuzzy functional dependencies has been proposed. In the first step, data are fuzzified, which ensures the same manipulation of crisp and fuzzy data. The data mining step is based on revealing fuzzy functional dependencies among considered attributes. In the final step, the mined knowledge is interpreted linguistically by the fuzzy modifiers and quantifiers. The proposed algorithm has been explained on illustrative data and tested on real-world dataset. Finally, its benefits, weak points and possible future research topics are discussed.}
}
@article{LI201860,
title = {Fault-Tolerant Cooperative Motion Planning of Connected and Automated Vehicles at a Signal-Free and Lane-Free Intersection},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {24},
pages = {60-67},
year = {2018},
note = {10th IFAC Symposium on Fault Detection, Supervision and Safety for Technical Processes SAFEPROCESS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.09.529},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318322201},
author = {Bai Li and Youmin Zhang},
keywords = {Motion planning, connected, automated vehicles, intersection management, fault-tolerant cooperative control, computational optimal control},
abstract = {Compared with a conventional intersection, a signal-free and lane-free intersection enables the vehicles to drive more flexibly, thereby to promote the throughput and to reduce congestions. This work proposes a fault-tolerant cooperative motion planning method for a number of connected and automated vehicles (CAVs) which are passing through a signal-free and lane-free intersection. Partial loss of actuator effectiveness is considered as the fault type. Even a subtle fault may significantly affect the overall team performance. Thus correctly judging whether each faulty/healthy CAV can still achieve its original goal is impossible until a corresponding motion replanning problem turns out to be solvable or not. To maximize the completeness of the original task, we propose a parallel computation framework, wherein the fault-recovery motion replanning problems in multiple levels of task completeness are tried simultaneously. Concretely, i) each faulty/healthy CAV should accomplish its original goal; ii) only each healthy CAV is required to accomplish its original goal; and iii) all the faulty/healthy CAVs try to stop safely without the need to achieve any original goals. Problems iii), ii), and i) are ranking with increasing computational difficulty. Among all the three problems, the achievable solution to the most difficult one is implemented as the fault-recovery strategy.}
}
@article{ZHONG2016572,
title = {Big Data for supply chain management in the service and manufacturing sectors: Challenges, opportunities, and future perspectives},
journal = {Computers & Industrial Engineering},
volume = {101},
pages = {572-591},
year = {2016},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2016.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0360835216302388},
author = {Ray Y. Zhong and Stephen T. Newman and George Q. Huang and Shulin Lan},
keywords = {Big Data, Service applications, Manufacturing sector, Supply Chain Management (SCM)},
abstract = {Data from service and manufacturing sectors is increasing sharply and lifts up a growing enthusiasm for the notion of Big Data. This paper investigates representative Big Data applications from typical services like finance & economics, healthcare, Supply Chain Management (SCM), and manufacturing sector. Current technologies from key aspects of storage technology, data processing technology, data visualization technique, Big Data analytics, as well as models and algorithms are reviewed. This paper then provides a discussion from analyzing current movements on the Big Data for SCM in service and manufacturing world-wide including North America, Europe, and Asia Pacific region. Current challenges, opportunities, and future perspectives such as data collection methods, data transmission, data storage, processing technologies for Big Data, Big Data-enabled decision-making models, as well as Big Data interpretation and application are highlighted. Observations and insights from this paper could be referred by academia and practitioners when implementing Big Data analytics in the service and manufacturing sectors.}
}
@article{CORRALPLAZA2020103426,
title = {A stream processing architecture for heterogeneous data sources in the Internet of Things},
journal = {Computer Standards & Interfaces},
volume = {70},
pages = {103426},
year = {2020},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2020.103426},
url = {https://www.sciencedirect.com/science/article/pii/S092054891930008X},
author = {David Corral-Plaza and Inmaculada Medina-Bulo and Guadalupe Ortiz and Juan Boubeta-Puig},
keywords = {Heterogeneous data, Stream processing, Internet of Things, Complex event processing, Software architecture},
abstract = {The number of Internet of Things (IoT) and smart devices capable of producing, consuming and exchanging information is constantly increasing. It is estimated there will be around 30 billion of them in 2020. In most cases, the structures of the information produced by such devices are completely different, thus providing heterogeneous information. This is becoming a challenge for researchers working on IoT, who need to perform homogenisation and pre-processing tasks before using the IoT data. This paper aims to provide an architecture for processing and analysing data from heterogeneous sources with different structures in IoT scopes, allowing researchers to focus on data analysis, without having to worry about the structure of the data sources. This architecture combines the real-time stream processing paradigm for information processing and transforming, together with the complex event processing for information analysis. This provides us with capability of processing, transforming and analysing large amounts of information in real time. The results obtained from the evaluation of a real-world case study about water supply network management show that the architecture can be applied to an IoT water management scenario to analyse the information in real time. Additionally, the stress tests successfully conducted for this architecture highlight that a large incoming rate of input events could be processed without latency, resulting in efficient performance of the proposed architecture. This novel software architecture is adequate for automatically detecting situations of interest in the IoT through the processing, transformation and analysis of large amounts of heterogeneous information in real time.}
}
@article{DEOMANDRE2020100254,
title = {Towards participatory sensing of regions of interest with adaptive sampling rate},
journal = {Vehicular Communications},
volume = {25},
pages = {100254},
year = {2020},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2020.100254},
url = {https://www.sciencedirect.com/science/article/pii/S2214209620300255},
author = {Carlos Henrique {de O.M. André} and Dianne S.V. Medeiros and Miguel Elias M. Campista},
keywords = {Participatory sensing, VANET, Adaptive sampling},
abstract = {Participatory Sensing (PS) is a known paradigm of collaborative networks which provides incentives for users to participate in sensing tasks of Regions of Interest (RoIs). A challenge in wireless networking, however, is to balance the amount of data collected by users without imposing excessive load to the network. In this direction, this paper proposes a centralized system to adapt the sampling rate assigned to each crowdsourcing participant sensor. The sampling rate is computed based on the standard deviation of samples collected from a given RoI. The results obtained via simulations show a tradeoff between the sampling rate and the number of crowdsourcing participants. The more crowdsourcing participants, the lower must be the individual sampling rate and the amount of data transferred. This strategy can increase the data delivery rate taking into account the available short contact times, even though it requires a larger number of sensors.}
}
@article{WANG2022107499,
title = {Challenges of blockchain in new generation energy systems and future outlooks},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {135},
pages = {107499},
year = {2022},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2021.107499},
url = {https://www.sciencedirect.com/science/article/pii/S0142061521007389},
author = {Tonghe Wang and Haochen Hua and Zhiqian Wei and Junwei Cao},
keywords = {Blockchain, Consensus, Energy blockchain, Energy internet, Energy system},
abstract = {Recently, the blockchain technology has attracted widespread attention due to its advantageous features, e.g., decentralization, transparency, traceability, and immutability. To make full use of renewable energy resources, new generation energy systems advocate the deep integration of information technology in real-world energy projects, among which blockchain has become one of the most used technologies. However, with the continuous development of related studies and projects, blockchain has begun to expose more and more limitations. As a result, the application of energy blockchain, i.e., blockchain applied in energy systems, is facing various challenges caused by these limitations. This paper briefly reviews popular application scenarios of energy blockchain, analyzes generic limitations of blockchain and their impacts on energy systems, and looks into possible directions that could deal with these limitations for future blockchain-based energy systems. We argue that blockchain is not a panacea for energy systems because blockchain’s component technologies have their own generic issues, and that the application of energy blockchain should be accompanied with improvement measures that conform to practical requirements of energy systems. As far as we know, this paper is one of the few works that deeply analyze the shortcomings of the blockchain technology and potential countermeasures in the energy field.}
}
@article{MINAROVA201887,
title = {Modifying the gravitational search algorithm: A functional study},
journal = {Information Sciences},
volume = {430-431},
pages = {87-103},
year = {2018},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.11.033},
url = {https://www.sciencedirect.com/science/article/pii/S0020025517310964},
author = {M. Minárová and D. Paternain and A. Jurio and J. Ruiz-Aranguren and Z. Takáč and H. Bustince},
keywords = {Gravitational search algorithm, Aggregation function, t-norm, overlap function},
abstract = {In this paper we replace the product of the masses in the Gravitational search algorithm introduced by [17] by other bivariate functions with specific properties. We analyze the properties of these functions to guarantee convergence in the algorithm and we discuss an application to justify our theoretical study and the need of using functions other than the product.}
}
@article{GRAVINA2017158,
title = {Cloud-based Activity-aaService cyber–physical framework for human activity monitoring in mobility},
journal = {Future Generation Computer Systems},
volume = {75},
pages = {158-171},
year = {2017},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16303016},
author = {Raffaele Gravina and Congcong Ma and Pasquale Pace and Gianluca Aloi and Wilma Russo and Wenfeng Li and Giancarlo Fortino},
keywords = {Cloud computing, Activity monitoring, Wearable sensors, Programming framework, Software as a service},
abstract = {This paper proposes Activity as a Service (Activity-aaService), a full-fledged cyber–physical framework to support community, on-line and off-line human activity recognition and monitoring in mobility. Activity-aaService is able to address the current lack of Cloud-Assisted Body Area Networks platforms and applications supporting monitoring and analysis of human activity for single individuals and communities. Activity-aaService is built atop the BodyCloud platform so enabling efficient BSN-based sensor data collection and local processing (Body-side), high performance computing of collected sensor data and data storing on the Cloud (Cloud-side), workflow-based programming of data analysis (Analyst-side), and advanced visualization of results (Viewer-side). Specifically, it provides specific, powerful and flexible programming abstractions for the rapid prototyping of efficient human activity-oriented applications. The effectiveness of the proposed framework has been demonstrated through the development of several prototypes related to physical activity monitoring, step counting, physical energy estimation, automatic fall detection, and smart wheelchair support. Finally, performance evaluation of the proposed framework at the Body-side of the activity classification has been carried out by analyzing processing load, data transmission time, CPU usage, memory footprint, and battery consumption using four heterogeneous mobile devices representing low, medium and high performance mobile platforms.}
}
@article{DURANPOLANCO2021465,
title = {Crowd management COVID-19},
journal = {Annual Reviews in Control},
volume = {52},
pages = {465-478},
year = {2021},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2021.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S1367578821000249},
author = {Liliana Durán-Polanco and Mario Siller},
keywords = {COVID-19, Agent-based model, POI recommendation, Mitigation strategy},
abstract = {Crowds are a source of transmission in the COVID-19 spread. Contention and mitigation measures have focused on reducing people’s mass gathering. Such efforts have led to a drop in the economy. The application of a vaccine at a world level represents a grand challenge for humanity, and it is not likely to accomplish even within months. In the meantime, we still need tools to allow the people integration into their regular routines reducing the risk of infection. In this context, this paper presents a solution for crowd management. The aim is to monitor and manage crowd levels in interior places or point-of-interests (POI), particularly shopping centers or stores. The solution is based on a POI recommendation system that suggests the nearest safe options upon request of a particular POI to visit by the user. In this sense, it recommends places near the user location with the least estimated crowd. The recommendation algorithm uses a top-K approach and behavioral game theory to predict the user’s choice and estimate the crowd level for the requested POI. To evaluate the efficiency of this technological intervention in terms of the potential number of contacts of possible COVID-19 infections and the recommendation quality, we have developed an agent-based model (ABM). The adoption level of new technologies can be related to the end-user experience and trust in such technologies. As the end-user follows a recommendation that leads to uncrowded places, both the end-user experience and trust increased. We study and model this process using the OCEAN model of personality. The results from the studied scenarios showed that the proposed solution is widely adopted by the agents, as the trust factor increased from 0.5 (initial set value) to 0.76. In terms of crowd level, these are effectively managed and reduced on average by 40%. The mobility contacts were reduced by 40%, decreasing the risk of COVID-19 infection. An APP has been designed to support the described crowd management and contact tracing functionality. This APP is available on GitHub.}
}
@article{PANCAROGLU2021102491,
title = {Load balancing for RPL-based Internet of Things: A review},
journal = {Ad Hoc Networks},
volume = {116},
pages = {102491},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102491},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521000548},
author = {Doruk Pancaroglu and Sevil Sen},
keywords = {Internet of Things (IoT), Low-Power and Lossy Networks (LLN), Routing protocol for LLNs (RPL), Routing, Load balancing},
abstract = {Low-Power and Lossy networks are an integral part of the IoT ecosystem. These networks are defined by their shared features such as having limited resources and high occurrence of packet loss. A routing protocol for such networks called Routing Protocol for Low-Power and Lossy Networks (RPL) was proposed in 2012. Even though RPL is now standardized and well-accepted by the community, it still has areas to be improved such as load balancing, stability, and support for mobility. This study focuses particularly on approaches proposed for the load balancing problem in RPL. In the literature, many researchers aimed to tackle this problem by creating different routing metrics that handle different objectives. This review makes a thorough assessment of these works, their strengths and shortcomings, and provides future directions on the issue.}
}
@article{REHAN2020102212,
title = {A novel dynamic confidence interval based secure channel prediction approach for stream-based multichannel wireless sensor networks},
journal = {Ad Hoc Networks},
volume = {108},
pages = {102212},
year = {2020},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2020.102212},
url = {https://www.sciencedirect.com/science/article/pii/S1570870518308242},
author = {Waqas Rehan and Stefan Fischer and Omer Chughtai and Maaz Rehan and Mohamed Hail and Shahzad Saleem},
keywords = {Multichannel, MAC, wireless sensor networks, multichannel wireless sensor networks, cognitive radio wireless sensor networks, multimedia wireless sensor networks, secure communication, channel prediction, channel blacklisting, anti-jamming mechanism, micro-electro-mechanical systems},
abstract = {Considering both channel quality and stability may enhance the likelihood of optimum channel decision for stream-based communication. Good quality stable channels may maintain a particular quality level during data stream transmission and thereby minimize channel switching overheads such as switching delay, energy consumption, and the associated data loss. Among the published multichannel MAC protocols for WSNs, only a few consider channel quality before assigning wireless channels. Whereas to the best of our knowledge, only few contemplates both channel quality and stability during stream-based communication, however, not very suitable for varying (noisy) environment. To bridge this gap, this work proposes a novel dynamic Multichannel Adaptive approach for Grading Immediate Channels (MAGIC). The MAGIC protocol may predict and classify the available channels under channel quality and stability assessment methodology and determines Local Preferred Channels (LPCs) in a noisy environment. Afterwards, the best among those channels may be selected (under some QoS criteria) for stream-based communication in WSNs. The proposed MAGIC algorithm minimizes channel processing overheads by considering only non-blacklisted channels during a communication session. Simulation results show that the MAGIC algorithm achieves better performance than the counterparts in terms of channel switching delay, energy consumption, and the associated throughput loss.}
}
@article{LEE2019434,
title = {What roles should the government play in fostering the advancement of the internet of things?},
journal = {Telecommunications Policy},
volume = {43},
number = {5},
pages = {434-444},
year = {2019},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2018.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0308596118303951},
author = {Gwanhoo Lee},
keywords = {Internet of things, Role of government, Policy, Regulation, Governance, Process, Public comments, Content analysis, Qualitative research},
abstract = {The Internet of Things (IoT) has the potential to transform the way we live, work, do business, and meet the needs of the public. While IoT's potential benefits for economic growth and social welfare appear to be indisputable, IoT faces several technological, social, legal, and regulatory policy challenges, ranging from interoperability and spectrum availability to cybersecurity and privacy. These challenges can and should be addressed by the joint efforts of a wide range of stakeholders from the public and private sector. The advancement of IoT depends in part on how policymakers respond to the opportunities and challenges associated with it. This research aims to identify the potential roles for the government in fostering the advancement of IoT innovation and adoption. To this end, we analyze data collected from 177 documents of public comments submitted to the U.S. National Telecommunications and Information Administration and from a focus group discussion with senior managers. Our content data analysis results in a set of recommendations for the government in terms of general policy principles, specific policy prescriptions, and governance and process approach that facilitate policy development.}
}
@article{LOHACHAB20191,
title = {ECC based inter-device authentication and authorization scheme using MQTT for IoT networks},
journal = {Journal of Information Security and Applications},
volume = {46},
pages = {1-12},
year = {2019},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2019.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S2214212618306513},
author = {Ankur Lohachab and  Karambir},
keywords = {Iot, Authentication, Authorization, ECC, MQTT, Cloud, Fog},
abstract = {Internet of Things (IoT) has emerged from the proliferation of smart and inter-connected devices ranging from tiny sensors to complex Fog and Cloud nodes, various networking technologies, and communication protocols. These IoT devices permeate in our lives through various applications including smart homes, healthcare, defence, transportation, and so forth. Although IoT provides a way of interaction among the physical world objects and the Internet, these connected devices have created a new dimension of security challenges associated with the vulnerabilities present in them. These challenges can be tackled to some extent by deploying a rigid authentication and access control model. In this paper, we propose a novel light-weight authentication and authorization framework suitable for distributed IoT environment using Elliptical Curve Cryptography (ECC) and Message Queuing Telemetry Transport (MQTT). Moreover, we implement the scheme, and analyse and compare its various security and performance aspects with other schemes.}
}
@article{YANG2021103184,
title = {Publicly verifiable outsourced data migration scheme supporting efficient integrity checking},
journal = {Journal of Network and Computer Applications},
volume = {192},
pages = {103184},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103184},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521001910},
author = {Changsong Yang and Feng Zhao and Xiaoling Tao and Yong Wang},
keywords = {Cloud computing, Data migration, Data integrity, Blockchain},
abstract = {With the rapid development of cloud storage, an increasing number of data owners prefer to store their large-scale data on the remote cloud for greatly reducing the burden of maintaining the data by themselves. Since different cloud storage service providers offer distinct quality of data storage services, secure outsourced data migration becomes a fundamental requirement for data owners to change their cloud storage service providers. As a result, how to guarantee the correctness and integrity of the outsourced data blocks when they are being migrated from one semi-trusted cloud host to another becomes a primary concern of data owners. To solve this problem, we propose a blockchain-based publicly verifiable data migration scheme supporting efficient data integrity checking for cloud storage in this paper. Specifically, the data owner can dynamically change the cloud storage service providers and securely migrate the outsourced data from one cloud host to another, without retrieving the transferred data from the original cloud host, and checking the transferred data integrity in the target cloud host. By making use of blockchain, our proposed scheme can simultaneously achieve data migration and integrity checking without interacting with a third party auditor, thus avoiding the problems of service interruption and privacy leakage caused by the single-point-of-failure of the third party auditor, which is much better than the previous schemes. Meanwhile, our proposed scheme is provable secure in the random oracle model. Finally, we also develop a prototype implementation of our proposed scheme and compare the efficiency with some existing schemes. The experimental result demonstrates that our proposed scheme is more efficient and practical.}
}
@article{YANG2019755,
title = {How big data enriches maritime research – a critical review of Automatic Identification System (AIS) data applications},
journal = {Transport Reviews},
volume = {39},
number = {6},
pages = {755-773},
year = {2019},
issn = {0144-1647},
doi = {https://doi.org/10.1080/01441647.2019.1649315},
url = {https://www.sciencedirect.com/science/article/pii/S0144164722001568},
author = {Dong Yang and Lingxiao Wu and Shuaian Wang and Haiying Jia and Kevin X. Li},
keywords = {AIS data, data mining, navigation safety, ship behaviour analysis, environmental evaluation, advanced applications of AIS data},
abstract = {ABSTRACT
The information-rich vessel movement data provided by the Automatic Identification System (AIS) has gained much popularity over the past decade, during which the employment of satellite-based receivers has enabled wide coverage and improved data quality. The application of AIS data has developed from simply navigation-oriented research to now include trade flow estimation, emission accounting, and vessel performance monitoring. The AIS now provides high frequency, real-time positioning and sailing patterns for almost the whole world's commercial fleet, and therefore, in combination with supplementary databases and analyses, AIS data has arguably kickstarted the era of digitisation in the shipping industry. In this study, we conduct a comprehensive review of the literature regarding AIS applications by dividing it into three development stages, namely, basic application, extended application, and advanced application. Each stage contains two to three application fields, and in total we identified seven application fields, including (1) AIS data mining, (2) navigation safety, (3) ship behaviour analysis, (4) environmental evaluation, (5) trade analysis, (6) ship and port performance, and (7) Arctic shipping. We found that the original application of AIS data to navigation safety has, with the improvement of data accessibility, evolved into diverse applications in various directions. Moreover, we summarised the major methodologies in the literature into four categories, these being (1) data processing and mining, (2) index measurement, (3) causality analysis, and (4) operational research. Undoubtedly, the applications of AIS data will be further expanded in the foreseeable future. This will not only provide a more comprehensive understanding of voyage performance and allow researchers to examine shipping market dynamics from the micro level, but also the abundance of AIS data may also open up the rather opaque aspect of how shipping companies release information to external authorities, including the International Maritime Organization, port states, scientists and researchers. It is expected that more multi-disciplinary AIS studies will emerge in the coming years. We believe that this study will shed further light on the future development of AIS studies.}
}
@article{RHAHLA2021102896,
title = {Guidelines for GDPR compliance in Big Data systems},
journal = {Journal of Information Security and Applications},
volume = {61},
pages = {102896},
year = {2021},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2021.102896},
url = {https://www.sciencedirect.com/science/article/pii/S221421262100123X},
author = {Mouna Rhahla and Sahar Allegue and Takoua Abdellatif},
keywords = {The General Data Protection Regulation (GDPR), Big Data analytics, Privacy, Security},
abstract = {The implementation of the GDPR that aims at protecting European citizens’ privacy is still a real challenge. In particular, in Big Data systems where data are voluminous and heterogeneous, it is hard to track data evolution through its complex life cycle ranging from collection, ingestion, storage and analytics. In this context, from 2016 to 2021 research has been conducted and several security tools designed. However, they are either specific to particular applications or address partially the regulation articles. To identify the covered parts, the missed ones and the necessary metrics for comparing different works, we propose a framework for GDPR compliance. The framework identifies the main components for the regulation implementation by mapping requirements aligned with GDPR’s provisions to IT design requirements. Based on this framework, we compare the main GDPR solutions in the Big Data domain and we propose a guideline for GDPR verification and implementation in Big Data systems.}
}
@article{JIN2021102059,
title = {Bus network assisted drone scheduling for sustainable charging of wireless rechargeable sensor network},
journal = {Journal of Systems Architecture},
volume = {116},
pages = {102059},
year = {2021},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2021.102059},
url = {https://www.sciencedirect.com/science/article/pii/S1383762121000497},
author = {Yong Jin and Jia Xu and Sixu Wu and Lijie Xu and Dejun Yang and Kaijian Xia},
keywords = {Wireless rechargeable sensor network, Bus network, Drone scheduling, Traveling salesman path problem, Submodular orienteering problem},
abstract = {Wireless Rechargeable Sensor Network (WRSN) is largely used in monitoring of environment and traffic, video surveillance and medical care, etc., and helps to improve the quality of urban life. However, it is challenging to provide the sustainable energy for sensors deployed in buildings, soil or other places, where it is hard to harvest the energy from environment. To address this issue, we design a new wireless charging system, which levers the bus network assisted drone in urban areas. We formulate the drone scheduling problem based on this new wireless charging system to minimize the total time cost of drone subject to all sensors can be charged under the energy constraint of drone. Then, we propose an approximation algorithm DSA for the energy tightened drone scheduling problem. To make the tasks of WRSN sustainable, we further formulate the drone scheduling problem with deadlines of sensors, and present the approximation algorithm DDSA to find the drone schedule with the maximal number of sensors charged by the drone before deadlines. Through the extensive simulations, we demonstrate that DSA can reduce the total time cost by 84.83% compared with Greedy Replenished Energy algorithm, and uses at most 5.98 times of the total time cost of optimal solution on average. Then, we also demonstrate that DDSA can increase the survival rate of sensors by 51.95% compared with Deadline Greedy Replenished Energy algorithm, and can obtain 77.54% survival rate of optimal solution on average.}
}
@article{MARKOVSKA20161504,
title = {Addressing the main challenges of energy security in the twenty-first century – Contributions of the conferences on Sustainable Development of Energy, Water and Environment Systems},
journal = {Energy},
volume = {115},
pages = {1504-1512},
year = {2016},
note = {Sustainable Development of Energy, Water and Environment Systems},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2016.10.086},
url = {https://www.sciencedirect.com/science/article/pii/S0360544216315201},
author = {Natasa Markovska and Neven Duić and Brian Vad Mathiesen and Zvonimir Guzović and Antonio Piacentino and Holger Schlör and Henrik Lund},
keywords = {Energy security, Decrabonization, Renewable energy sources, Energy efficiency, Smart energy systems, SDEWES},
abstract = {Climate change and fossil fuel reserve depletion both pose challenges for energy security and for wellbeing in general. The top ten among them include: Decarbonising the world economy; Enhancing the energy efficiency and energy savings in buildings; Advancing the energy technologies; Moving towards energy systems based on variable renewables; Electrifying the transport and some industrial processes; Liberalizing and extending the energy markets; Integrating energy sectors to Smart Energy Systems; Making the cities and communities smart; Diversifying the energy sources; and Building more biorefineries. Presenting the contributions of selected conference papers published in the special issues of leading scientific journals (including all the papers from the current Energy special issue), this review demonstrates the capacity of the Conferences on Sustainable Development of Energy, Water and Environment Systems for generation of knowledge which could serve as the centrepiece of a pertinent response to those challenges.}
}
@article{HUANG2021107736,
title = {Multi-scale covering rough sets with applications to data classification},
journal = {Applied Soft Computing},
volume = {110},
pages = {107736},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107736},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621006578},
author = {Zhehuang Huang and Jinjin Li},
keywords = {Covering rough sets, Multi-scale, Optimal scale selection, Optimal rule acquisition},
abstract = {When facing with a complex problem, one often needs to consider dealing with it at what level of granularity. Multi-scale knowledge representation provides us an opportunity to analyze problems from different granularity. However, as well as traditional rough sets model, most of existing multi-scale rough set models are based on partitions generated from equivalence relations, which limits their application in real data. In this paper, we set forth a new data analysis model with multi-scale coverings by extending partitions to coverings. To this end, a new type of decision tables, i.e., multi-scale covering decision tables are formalized to deal with knowledge representation under multi-scale framework. Optimal scale selection for consistent and inconsistent covering decision tables are then proposed to obtain acceptable decisions under coarser scales. Furthermore, the acquisition of optimal rules with higher accuracy and covering rate are discussed. Extensive experiments on some real-world data sets are set up to examine the effectiveness and feasibility of the proposed model. Experimental results show that the multi-scale covering theory gives a new way to enhance the generalization ability of the classification model.}
}
@article{SOVACOOL2020109663,
title = {Smart home technologies in Europe: A critical review of concepts, benefits, risks and policies},
journal = {Renewable and Sustainable Energy Reviews},
volume = {120},
pages = {109663},
year = {2020},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2019.109663},
url = {https://www.sciencedirect.com/science/article/pii/S1364032119308688},
author = {Benjamin K. Sovacool and Dylan D. {Furszyfer Del Rio}},
keywords = {Smart homes, Smart home technologies, Smart meters, Energy and buildings, Energy feedback, Smart grids, Digital society},
abstract = {Smart home technologies refer to devices that provide some degree of digitally connected, automated, or enhanced services to building occupants. Smart homes have become central in recent technology and policy discussions about energy efficiency, climate change, and the sustainability of buildings. Nevertheless, do they truly promote sustainability goals? In addition, what sorts of benefits, risks, and policies do they entail? Based on an extensive original dataset involving expert interviews, site visits to retailers, and a comprehensive review of the literature, this study critically examines the promise and peril of smart home technologies. Drawing on original data collected in the United Kingdom, which has access to European markets, the study first examines definitions of smart homes before offering a new classification involving 13 categories of smart technology covering 267 specific options commercially available from 113 companies. It situates these different technology classes alongside six degrees or levels of smartness, from the basic or traditional home to the fully automated and sentient home. It then elaborates on the 13 distinct benefits smart homes may offer alongside potential 17 risks and barriers, before introducing seven policy recommendations from the material. It lastly suggests three areas of future research on the demographics and behavior of actual smart home adopters, rethinking the duality of “control,” and looking beyond “homes” towards socio-technical systems, practices, and justice.}
}
@article{DEANGELIS202016581,
title = {Vehicle fleet electrification: impacts on energy demand, air quality and GHG emissions. An integrated assessment approach},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {16581-16586},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.784},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320311083},
author = {E. {De Angelis} and E. Turrini and C. Carnevale and M. Volta},
keywords = {Integrated Assessment Modelling, environmental decision support systems, Air quality planning, control, Impact evaluation},
abstract = {Transport sector is responsible for 25% of European GHG emissions, furthermore it has high impacts on air pollution at various scales. electric mobility is growing fast and it could be effective in reducing road transport GHGs and pollutant emissions, but its potential depends on the energy mix used to produce electricity. In this paper an Integrated Assessment Model is proposed to analyze the energetic transition to an electric vehicle fleet at regional scale. Two scenarios are proposed to assess at the same time which are the impacts of the electric power sources and of the reduced road transport emissions. Results are presented in terms of CO2 emissions, air quality indexes, energy savings and health impacts.}
}
@article{BENZIDIA2021120819,
title = {Impact of ambidexterity of blockchain technology and social factors on new product development: A supply chain and Industry 4.0 perspective},
journal = {Technological Forecasting and Social Change},
volume = {169},
pages = {120819},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.120819},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521002511},
author = {Smaïl Benzidia and Naouel Makaoui and Nachiappan Subramanian},
keywords = {Buyer innovation, Blockchain technology, Supply chain ambidexterity, Relational capital, Industry 4.0, Sustainability},
abstract = {This study develops a technology and social capital process aided product innovation conceptual model based on dynamic capability and supply chain ambidexterity theory. The strategy of organisational ambidexterity in balancing technological and relational social capital factors between buyers and suppliers leads to a higher level of digital manufacturing capabilities and enhances buyers’ innovation potential, considering the sustainable practices in their processes to cope with Industry 4.0 manufacturing processes and sustainability challenges. The study empirically validates the model using data collected from 379 French manufacturing companies. This is the first study that examines how buyers perceive the role of blockchain technology in exploring and exploiting innovation management in the Industry 4.0 era. The study advances understanding on the theory of ambidexterity of supply chains in buyer–supplier relationships. The study results show the positive effect between internal integration and blockchain technology as well as relational social capital factors in buyer–supplier relationships. The findings underscore the critical role of relational and technological capital in buyer–supplier relationships, specifically to act as a catalyst for exploiting internal capabilities to achieve the innovation targets. The unique findings state blockchain technology mediation is dominant in exploiting the internal capabilities and benefits buyers' innovation orientation.}
}
@article{AHELEROFF2021101438,
title = {Mass Personalisation as a Service in Industry 4.0: A Resilient Response Case Study},
journal = {Advanced Engineering Informatics},
volume = {50},
pages = {101438},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101438},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621001907},
author = {Shohin Aheleroff and Naser Mostashiri and Xun Xu and Ray Y. Zhong},
keywords = {Industry 4.0, Internet of Things, Cloud Manufacturing, Additive Manufacturing, Personalisation, Service Oriented Architecture},
abstract = {The Fourth Industrial Revolution (Industry 4.0) leads to mass personalisation as an emerging manufacturing paradigm. Mass personalisation focuses on uniquely made products to individuals at scale. Global challenges encourage mass personalisation manufacturing with efficiency competitive to mass production. Driven by individualisation as a trend and enabled by increasing digitalisation, mass personalisation can go beyond today’s mass customisation. This paper aims to introduce Mass Personalisation as a Service (MPaaS) to address unique and complex requirements at scale by harnessing Industry 4.0 technologies, including Internet of Things, Additive Manufacturing, Big Data, Cloud Manufacturing, Digital Twin, and Blockchain. A case study for the implementation of MPaaS in personalised face masks is presented. The workforce with constant exposure to contaminants requires personal protective equipment (PPE), such as facemasks, for longer hours resulting in pressure-related ulcers. This prolonged use of PPE highlights the importance of personalisation to avoid ulcers and other related health concerns. Most studies have used Additive Manufacturing for individualisation and cloud capabilities for large-scale manufacturing. This study develops a framework and mathematical model to demonstrate the capability of the proposed solution to address one of the most critical challenges by making personalised face masks as an essential PPE in the critical industrial environment.}
}
@article{BOKKISAM2022107719,
title = {Framework of transactive energy market pool for community energy trading and demand response management using an auction-theoretic approach},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {137},
pages = {107719},
year = {2022},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2021.107719},
url = {https://www.sciencedirect.com/science/article/pii/S0142061521009455},
author = {Hanumantha Rao Bokkisam and Ritesh Mohan Acharya and Selvan M.P.},
keywords = {Auction-theory, Demand response management, Locality electricity markets, Energy trading, Smart grid, Transactive energy},
abstract = {This paper presents a transactive energy market pool framework for facilitating energy trading, with demand response consideration, among a group of participants in a community microgrid using an auction-theoretic approach. The auction theory is used to design the pricing mechanism in the market pool. In the market, the self-interested participants (consumers and prosumers) directly trade their net demand to the neighborhood with a transactive energy market pool operator using the existing infrastructure of the distribution utility. The market operator determines the pool market-clearing price & quantity by optimizing the received power bids and offers from the participants using a periodic iterative double auction pricing mechanism. The optimally traded price & quantity are broadcast to all the participants to perform demand response management and optimize their electricity bill. The optimal positions of schedulable loads in the market time-line are achieved using a binary genetic algorithm while minimizing the electricity bill. A comparative analysis between different pricing mechanisms is provided in terms of performance indices namely self-sufficiency and self-consumption through various case studies. It is found that the proposed auction-theoretic approach improves the rate of community self-sufficiency, rate of community self-consumption, and savings in electricity bills for the market participants compared to previously proposed pricing methods in the literature.}
}
@article{COELHO2017820,
title = {Multi-agent systems applied for energy systems integration: State-of-the-art applications and trends in microgrids},
journal = {Applied Energy},
volume = {187},
pages = {820-832},
year = {2017},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2016.10.056},
url = {https://www.sciencedirect.com/science/article/pii/S0306261916315008},
author = {Vitor N. Coelho and Miri {Weiss Cohen} and Igor M. Coelho and Nian Liu and Frederico Gadelha Guimarães},
keywords = {Multi-agent systems, Smart grid, Microgrid, Smart-microgrids, Integrated energy systems},
abstract = {Mini/microgrids are a potential solution being studied for future systems relying on distributed generation. Given the distributed topology of the emerging smart grid systems, different solutions have been proposed for integrating the new components ensuring communication between existing ones. The multi-agent systems paradigm has been advocated as a useful and promising tool for a wide range of applications. In this paper, the major issues and challenges in multi-agent system and smart microgrids are discussed. We present a review of state-of-the-art applications and trends. By discussing the possibilities considering what has been done, future applications, with attention to renewable energy resources integration in emerging scenarios, are placed on the agenda. It is suggested that further studies keep growing in this direction, which will be able to decentralize the high complex energy system, allowing users to participate in the system more actively. This step may decentralize the infrastructure, giving more weight to society wishes, as well as facilitating maintenance, reducing costs and opening a the door for innovative ideas for low-cost based equipment. On the other hand, letting several combinatorial optimization problems opened to be improved and discussed along the next coming years.}
}
@article{FENG2018167,
title = {AAoT: Lightweight attestation and authentication of low-resource things in IoT and CPS},
journal = {Computer Networks},
volume = {134},
pages = {167-182},
year = {2018},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.01.039},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618300471},
author = {Wei Feng and Yu Qin and Shijun Zhao and Dengguo Feng},
keywords = {IoT security, CPS security, Remote attestation, Authentication, Embedded security, Physically unclonable function (PUF)},
abstract = {With the rise of Internet of Things (IoT) and Cyber-Physical Systems (CPS), the need for smart embedded devices is rapidly increasing, and so does the security and privacy risk. This paper focuses on enabling both remote attestation and authentication of current commodity low-resource embedded devices to enhance security in the IoT and CPS contexts. We demonstrate a detailed design and prototype implementation of AAoT, a lightweight and practical mechanism for Attestation and Authentication of Things, that can provide software integrity, mutual authentication and tamper-proof feature for smart embedded devices. AAoT is based on physical unclonable functions (PUFs), random memory filling and software attestation without requiring any changes in existing micro-controller units (MCUs). We show how to obtain efficient implementations and optimizations for each of the building blocks of AAoT, including a PUF-based memory filling, a checksum function with block-based traversal, a pseudorandom function, a reverse fuzzy extractor and a random number generator. The prototype is implemented on a low-end MCU platform (TI MSP430) by using onboard SRAM, registers and Flash resources.}
}
@article{LIU201797,
title = {Practical-oriented protocols for privacy-preserving outsourced big data analysis: Challenges and future research directions},
journal = {Computers & Security},
volume = {69},
pages = {97-113},
year = {2017},
note = {Security Data Science and Cyber Threat Management},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2016.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167404816301778},
author = {Zhe Liu and Kim-Kwang Raymond Choo and Minghao Zhao},
keywords = {Big data analysis, Privacy-preserving, Outsourced big data, Oblivious RAM, Security, Practical-oriented, Secure query},
abstract = {With the significant increase in the volume, variety, velocity and veracity of data generated, collected and transmitted through computing and networking systems, it is of little surprise that big data analysis and processing is the subject of focus from enterprise, academia and government. Outsourcing is one popular solution considered in big data processing, although security and privacy are two key concerns often attributed to the underutilization of outsourcing and other promising big data analysis and processing technologies. In this paper, we survey the state-of-the-art literature on cryptographic solutions designed to ensure the security and/or privacy in big data outsourcing. For example, we provide concrete examples to explain how these cryptographic solutions can be deployed. We summarize the existing state-of-play before discussing research opportunities.}
}
@article{ZHAO201968,
title = {Software-defined unmanned aerial vehicles networking for video dissemination services},
journal = {Ad Hoc Networks},
volume = {83},
pages = {68-77},
year = {2019},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2018.08.023},
url = {https://www.sciencedirect.com/science/article/pii/S1570870518306231},
author = {Zhongliang Zhao and Pedro Cumino and Arnaldo Souza and Denis Rosário and Torsten Braun and Eduardo Cerqueira and Mario Gerla},
keywords = {SDN, UAVNet, Video surveillance, Relay placement, Quality of experience},
abstract = {Unmanned Aerial Vehicles (UAVs) empower people to reach endangered areas under emergency situations. By collaborating with each other, multiple UAVs forming a UAV network (UAVNet) could work together to perform specific tasks in a more efficient and intelligent way than having a single UAV. UAVNets pose special characteristics of high dynamics, unstable aerial wireless links, and UAV collision probabilities. To address these challenges, we propose a Software-Defined UAV Networking (SD-UAVNet) architecture, which facilitates the management of UAV networks through a centralized SDN UAV controller. In addition, we introduce a use case scenario to evaluate the optimal UAV relay node placement for life video surveillance services with the proposed architecture. In the SD-UAVNet architecture, the controller considers the global UAV relevant context information to optimize the UAVs’ movements, selects proper routing paths, and prevents UAVs from collisions to determine the relay nodes deployment and guarantee satisfactory video quality. The experimental results show that the proposed SD-UAVNet architecture can effectively mitigate the challenges of UAVNet and it provides suitable Quality of Experience (QoE) to end-users.}
}
@article{CASOLA2019100080,
title = {A security monitoring system for internet of things},
journal = {Internet of Things},
volume = {7},
pages = {100080},
year = {2019},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2019.100080},
url = {https://www.sciencedirect.com/science/article/pii/S2542660519300289},
author = {Valentina Casola and Alessandra {De Benedictis} and Antonio Riccio and Diego Rivera and Wissam Mallouli and Edgardo Montes {de Oca}},
keywords = {IoT monitoring, IoT security, IoT threats},
abstract = {The wide adoption of the Internet of Things (IoT) paradigm in several application domains has raised new security issues, which should be carefully taken into account to achieve a real benefit from the indisputable innovation potential of IoT. In fact, the heterogeneity of involved technologies, including the integration of different resource-constrained devices and networks, has led to the introduction of new threats affecting all architectural layers and urging for the design and enforcement of adequate security countermeasures, including effective monitoring capabilities. In this paper, we present a monitoring tool for IoT systems based on the extension of the Montimage network monitoring tools. The proposed solution, validated within the H2020 ANASTACIA project, proved to be well suited to monitor IoT-level networks thanks to the exploitation of protocol-specific plugins.}
}
@article{LI201855,
title = {A sparse representation-based image resolution improvement method by processing multiple dictionary pairs with latent Dirichlet allocation model for street view images},
journal = {Sustainable Cities and Society},
volume = {38},
pages = {55-69},
year = {2018},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2017.12.020},
url = {https://www.sciencedirect.com/science/article/pii/S2210670717310995},
author = {Hu Li and Xiaomin Yang and Lihua Jian and Kai Liu and Yuan Yuan and Wei Wu},
keywords = {Image resolution improvement method, Latent Dirichlet allocation, Semantic information, Sparse representation},
abstract = {Street view applications are widely used in many situations. However, the resolution of the street view image is not high enough. Users always desire high resolution street view images. Image resolution improvement methods can effectively generate a high resolution street view image from a single low resolution street view image. The sparse representation-based image resolution improvement method is a promising way to improve the resolution of an image. However, only one dictionary pair, which fails to represent the diverse structures in images, is used in conventional sparse representation-based methods This may lead to poor performances in many circumstances. In this paper, we propose a new sparse representation-based method with multiple dictionary pairs. To capture the various structures at the semantic level, our method adopts latent Dirichlet allocation model to divide the patches into clusters. Then we learn a dictionary pair for each cluster. Finally, these dictionary pairs are used to reconstruct high resolution images. Experimental results validate that our method is superior over the compared methods in both visual perception and objective quantitation.}
}
@article{ABDALGADER2021114313,
title = {Context expansion approach for graph-based word sense disambiguation},
journal = {Expert Systems with Applications},
volume = {168},
pages = {114313},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.114313},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420310095},
author = {Khaled Abdalgader and Aysha {Al Shibli}},
keywords = {Semantic connectivity, Semantic similarity, Graph expansion, Graph centrality measure},
abstract = {Word sense disambiguation is a process to correctly identify the meanings of words in a given context. Being important in many natural language processing applications, this process is crucial in automatically understanding natural language expressions. Herein, we propose a variation of a well-known unsupervised graph-based word sense disambiguation method that utilizes all possible semantic information from a used lexical resource to increase graph-semantic connectivity for identifying the intended meanings of words in a given context. If the words have multiple potential meanings (senses) based on context, the proposed method builds an expanded graph representing most relevant semantic information of the words to be disambiguated. Nodes in the graph correspond to the context expansion set, which contains all associated information of each possible meaning of the word (word sense), and edges represent the semantic similarity between the expanded sets (nodes). Simultaneously, actual meaning is assigned to each target word using a locate graph centrality measure, which provides the degree of importance between graph nodes. Unlike most existing graph-based word sense disambiguation methods, wherein semantic relations (edges) between nodes are measured at the word level, the proposed method measures graph node semantic relations at the sentence level by expanding the words’ context, which contains all associated information for each possible word sense. Consequently, the proposed method can capture a higher degree of semantic information than existing approaches, thereby increasing semantic connectivity through a graph’s edges. Empirical results on benchmark datasets demonstrate that the proposed method outperforms all compared state-of-the-art graph-based word sense disambiguation approaches reported herein. We also report results obtained by applying the proposed method to a sentiment analysis task. These results demonstrate that the proposed method can determine the overall sentiment orientation of a given textual context.}
}
@article{CASOLA2019100056,
title = {Toward the automation of threat modeling and risk assessment in IoT systems},
journal = {Internet of Things},
volume = {7},
pages = {100056},
year = {2019},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2019.100056},
url = {https://www.sciencedirect.com/science/article/pii/S2542660519300290},
author = {Valentina Casola and Alessandra {De Benedictis} and Massimiliano Rak and Umberto Villano},
keywords = {IoT automated threat modeling, IoT automated risk assessment, IoT secure design},
abstract = {The Internet of Things (IoT) has recently become one of the most relevant emerging technologies in the IT landscape. IoT systems are characterized by the high heterogeneity of involved architectural components (e.g., device platforms, services, networks, architectures) and involve a multiplicity of application domains. In the IoT scenario, the identification of specific security requirements and the security design are very complex and expensive tasks, since they heavily depend on the configuration deployment actually in place and require security experts. In order to overcome these issues, we propose an approach aimed at supporting the security analysis of an IoT system by means of an almost completely automated process for threat modeling and risk assessment, which also helps identify the security controls to implement in order to mitigate existing security risks. We demonstrate the effectiveness of the approach by discussing its application to a home automation system, built on top of commercial IoT products.}
}
@article{KHIATI2018263,
title = {Adaptive learning-enforced broadcast policy for solar energy harvesting wireless sensor networks},
journal = {Computer Networks},
volume = {143},
pages = {263-274},
year = {2018},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618305218},
author = {Mustapha Khiati and Djamel Djenouri},
keywords = {Wireless sensor networks, Energy harvesting, Green communication, Broadcast, HMM},
abstract = {The problem of message broadcast from the base station (BS) to sensor nodes (SNs) in solar energy harvesting enabled wireless sensor networks is considered in this paper. The aim is to ensure fast and reliable broadcast without disturbing upstream communications (from SNs to BS), while taking into account constraints related to the energy harvesting (EH) environment. A new policy is proposed where from the one hand, the BS first selects the broadcast time-slots adaptively with the SNs schedules (to meet active periods that are constrained by EH conditions), and from the other hand, SNs adapt their schedules to enable optimal selection of the broadcast time-slots that minimizes the number of broadcasts per message and the latency. Compared to the existing solutions, this enables fast broadcast and eliminates the need of adding message overhead to the broadcast message. For this purpose, an analytical energy model, a Hidden Markov Model(HMM), Baum–Welch learning algorithm, and a heuristic algorithm of the minimum covering set problem (MCS) are proposed and combined in a unique solution. The proposed solution is analyzed and compared with a state-of-the-art approach. The results confirm that the former has the advantage of performing the broadcast operation more reliably and in lower delay.}
}
@article{FATIMA2020178,
title = {National strategic artificial intelligence plans: A multi-dimensional analysis},
journal = {Economic Analysis and Policy},
volume = {67},
pages = {178-194},
year = {2020},
issn = {0313-5926},
doi = {https://doi.org/10.1016/j.eap.2020.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0313592620304021},
author = {Samar Fatima and Kevin C. Desouza and Gregory S. Dawson},
keywords = {Artificial intelligence, Strategic plans, Technological innovation, Public agencies, Autonomous systems, Intelligent systems, Science and technology policy},
abstract = {Nations have recognized the transformational potential of artificial intelligence (AI). Advances in AI will impact all facets of society. A spate of recently released national strategic AI plans provides valuable insights into how nations are considering their future trajectories. These strategic plans offer a rich source of evidence to understand national-level strategic actions, both proactive and reactive, in the face of rapid technological innovation. Based on a comprehensive content analysis of thirty-four national strategic plans, this article reports on (1) opportunities for AI to modernize the public sector and enhance industry competitiveness, (2) the role of the public sector in ensuring that the two most critical elements of AI systems, data and algorithms, are managed responsibly, (3) the role of the public sector in the governance of AI systems, and (4) how nations plan to invest in capacity development initiatives to strengthen their AI capabilities.}
}
@article{ELSAYED2020100227,
title = {Design and evaluation of a novel hierarchical trust assessment approach for vehicular networks},
journal = {Vehicular Communications},
volume = {24},
pages = {100227},
year = {2020},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2019.100227},
url = {https://www.sciencedirect.com/science/article/pii/S2214209619302748},
author = {Hesham {El Sayed} and Sherali Zeadally and Deepak Puthal},
keywords = {Intelligent transportation systems, Trust management, Vehicular networks},
abstract = {In vehicular networks, vehicles communicate with each other and transfer messages to enhance the safety of both commuters and vehicles. Trust management in these networks has become a key issue because of the selfish behavior that is frequently exhibited by some vehicles. Most of the existing trust management schemes for vehicular networks schemes have adopted cryptographic techniques, which require high computation time and high network resource utilization. We propose a Hierarchical Trust Management System (HTMS) that relies on the trust metric computation for every individual vehicle. We also propose a systematic approach based on trust evaluation, trust propagation and trust aggregation to compute the trustworthiness of vehicles. Initially, the trust evaluation scheme computes a local trust score based on a behavioral analysis. Next, the proposed trust propagation model shares the computed local trust score to neighboring vehicles using a platoon-based dissemination technique. Based on the local trust score and propagated trust opinions, our aggregation technique computes a Global Trust score (GTS) using Dempster-Shafer theory. Finally, based on the computed GTS score, the proposed system invokes an action module to reward or punish vehicles. The simulation results obtained show that the proposed system is highly resilient to trust-based attacks and enables trustworthy peers to generate a higher number of data transfers within the network.}
}
@article{CHEN2019252,
title = {Development of city buildings dataset for urban building energy modeling},
journal = {Energy and Buildings},
volume = {183},
pages = {252-265},
year = {2019},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2018.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0378778818316852},
author = {Yixing Chen and Tianzhen Hong and Xuan Luo and Barry Hooper},
keywords = {City building dataset, CityGML, Urban building energy modeling, Data standards, Data mapping},
abstract = {Urban building energy modeling (UBEM) is becoming a proven tool to support energy efficiency programs for buildings in cities. Development of a city-scale dataset of the existing building stock is a critical step of UBEM to automatically generate energy models of urban buildings and simulate their performance. This study introduces data needs, data standards, and data sources to develop city building datasets for UBEM. First, a literature review of data needs for UBEM was conducted. Then, the capabilities of the current data standards for city building datasets were reviewed. Moreover, the existing public data sources from several pioneer cites were studied to evaluate whether they are adequate to support UBEM. The results show that most cities have adequate public data to support UBEM; however, the data are represented in different formats without standardization, and there is a lack of common keys to make the data mapping easier. Finally, a case study is presented to integrate the diverse data sources from multiple city departments of San Francisco. The data mapping process is introduced and discussed. It is recommended to use the unique building identifiers as the common keys in the data sources to simplify the data mapping process. The integration methods and workflow are applied to other U.S. cities for developing the city-scale datasets of their existing building stock, including San Jose, Los Angeles, and Boston.}
}
@article{HENNING2021100209,
title = {Theodolite: Scalability Benchmarking of Distributed Stream Processing Engines in Microservice Architectures},
journal = {Big Data Research},
volume = {25},
pages = {100209},
year = {2021},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2021.100209},
url = {https://www.sciencedirect.com/science/article/pii/S2214579621000265},
author = {Sören Henning and Wilhelm Hasselbring},
keywords = {Stream processing, Microservices, Benchmarking, Scalability},
abstract = {Distributed stream processing engines are designed with a focus on scalability to process big data volumes in a continuous manner. We present the Theodolite method for benchmarking the scalability of distributed stream processing engines. Core of this method is the definition of use cases that microservices implementing stream processing have to fulfill. For each use case, our method identifies relevant workload dimensions that might affect the scalability of a use case. We propose to design one benchmark per use case and relevant workload dimension. We present a general benchmarking framework, which can be applied to execute the individual benchmarks for a given use case and workload dimension. Our framework executes an implementation of the use case's dataflow architecture for different workloads of the given dimension and various numbers of processing instances. This way, it identifies how resources demand evolves with increasing workloads. Within the scope of this paper, we present 4 identified use cases, derived from processing Industrial Internet of Things data, and 7 corresponding workload dimensions. We provide implementations of 4 benchmarks with Kafka Streams and Apache Flink as well as an implementation of our benchmarking framework to execute scalability benchmarks in cloud environments. We use both for evaluating the Theodolite method and for benchmarking Kafka Streams' and Flink's scalability for different deployment options.}
}
@article{PRINSLOO2018263,
title = {Synthesis of an intelligent rural village microgrid control strategy based on smartgrid multi-agent modelling and transactive energy management principles},
journal = {Energy},
volume = {147},
pages = {263-278},
year = {2018},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2018.01.056},
url = {https://www.sciencedirect.com/science/article/pii/S0360544218300677},
author = {Gerro Prinsloo and Robert Dobson and Andrea Mammoli},
keywords = {Smart villages, Transactive energy management, Energy market price forecast, Multi-agent system, Community energy system, Smart energy system, Purdue automation hierarchy},
abstract = {Humanitarian and other development organisations are calling for replicable self-sustaining solutions to shared micro-utilities to ensure equitable modern energy delivery to energy-deprived village communities. Distributed smart microgrid technology allows for the efficient integration of sustainable resources to provide localised energy delivery at improved levels of reliability and resilience. Smart energy management in decentralised renewable systems requires computational intelligence to implement pivotal energy-aware/cost-aware procedures in decision-making for a conceptualised next generation Smart Village microgrid platform. Smart Village microgrid control automation aims at offering pragmatic and, intelligent control capabilities to perform price-based demand response energy management. This paper proposes the use of cascaded control abstraction in the implementation of a price-sensitive cyber-physical Smart Grid approach in a rural off-grid microgrid environment. The modular microgrid design integrates renewable energy resources through an adaptive control algorithm developed in a model-based design approach. The solution is based on distributed market-based control, using multi-agent transactive principles to navigate automated demand response. Multi-priority load clusters with the selective parallel control of non-intelligent device groups allow for prioritised supply/demand resource coordination. The proposed Smart Village solution operates as a self-regulating smart microgrid energy management system and by virtue of its market-based transactive reasoning approach is able to meet multiple operating requirements of rural village energy systems. Simulation results for this value-based control technique highlight the value of customer engagement combined with supply-, demand- and economic cost optimisation for hybrid renewable distributed energy microgrids.}
}
@article{PAGARE2022168573,
title = {Analytical modeling and impact analysis on multichannel symmetric optical and wireless NG-PON2 networks of CD, SPM, XPM and FWM impairments},
journal = {Optik},
volume = {252},
pages = {168573},
year = {2022},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2022.168573},
url = {https://www.sciencedirect.com/science/article/pii/S0030402622000055},
author = {Rajendraprasad A. Pagare and Abhilasha Mishra and Santosh Kumar},
keywords = {PON, GPON, XGS-PON, WDM-PON, NG-PON2, OW, FSO},
abstract = {A conceptual model for optical wireless (OW) interfacing with NG-PON2 access network is analyzed using N1-class backbone optical distribution and OW free-space optics (FSO) channels in the frontend to connect ONUs to symmetric 1.25/2.5/10 Gbps channels incorporating Time and Wavelength Division Multiplexing (TWDM) technique to deliver applications and services based on Fiber-to-the-X (FTTX), IoT and 5 G technologies. We successfully demonstrated the design and analysis of ODN channel attributes supporting coexistence approach in contiguous with fiber channel linear and nonlinear impairments (LNI), and atmospheric attenuations β due to haze, dry particles inside the premises for high-speed OW channel for indoor applications along with optimization of hybrid N1-power budget class distributing configuration propagating multi-channel (MC) OW-FSO TWDM NG-PON2 configurations supporting symmetric configuration. Multichannel input power is calculated to optimize up/down link spectrum ODN power to 4 and 3 dBm respectively at worst-case scenario accommodating eight symmetric channels. Simulation results achieved at 50.011 km in either direction are − 41.85/− 36.67/− 39.04/ dBm and − 33.63/− 42.78/− 37.92 dBm receiver sensitivities supporting 448 splitter configuration at 50.011 km, FWM efficiency is 1.65e-52 and FWM component power at as low as − 53 to − 54 dB in conjunction with CD, SPM, XPM, and FWM LNI for spectrum in either directions.}
}
@article{KHELIFA2020106621,
title = {A holonic intelligent decision support system for urban project planning by ant colony optimization algorithm},
journal = {Applied Soft Computing},
volume = {96},
pages = {106621},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106621},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620305597},
author = {Boudjemaa Khelifa and Mohamed Ridda Laouar},
keywords = {Intelligent decision support system, Holonic multi-agent system, Urban project planning, Ant colony optimization algorithm, Bounded knapsack problem},
abstract = {Hitherto, urbanization reached unprecedented spreading, various problems in the field increase from day to day, and makes the urban phenomena more dynamic and more complex. Therefore, it is important to call in experts and provide all stuff to establish urban projects’ plans, which often need to be achieved in a brief time. Actually, decision-makers need more and more updated plans and even sustainable solutions to convey eventual urban changes with maintaining intrinsic features of urban areas, such as coverage, inter-dependency, and coherency. Due to decision-makers yearnings and the short time allocated to planners, urban project planning remains an exhausting task; it resorts to arbitrary choices to find a good match of projects according to the intended situations. On the other hand, it should take care of the available resources like funds, land, water, energy, underground, and raw materials, which ought to be rationally exploited, and preserved for future generations. In this paper, the proposed intelligent decision support system (IDSS) aims to find out the best urban plans that fit urban projects to appropriate areas. It also employs the holonic approach to model complex and large-scale urban systems, where agents of each level apply a new multi-objective ant colony optimization algorithm called BKPACS for the urban project planning problem, which is viewed as a bounded knapsack problem (BKP). To produce global optimal urban plans, the main algorithm called H-MACO coordinates between the different levels of this holonic system. The experimental results on a set of urban projects about a province of Algeria show good quality plans produced in less time.}
}
@article{SERGEEV2021134,
title = {Identification of Integrated Rating Mechanisms As An Approach To Discrete Data Analysis},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {13},
pages = {134-139},
year = {2021},
note = {20th IFAC Conference on Technology, Culture, and International Stability TECIS 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.10.433},
url = {https://www.sciencedirect.com/science/article/pii/S240589632101870X},
author = {V.A. Sergeev and N.A. Korgin},
keywords = {Identification, model reduction, Production planning, control, Modelling, decision making in complex systems, Integrated assessment, One-hot encoding, Incomplete data, Discrete data analysis},
abstract = {We present an approach to discrete datasets analysis on the basis of integrated rating mechanisms identification approaches, developed recently. On the basis of three data sets, the results of the work of the method for identifying integrated rating mechanisms on incomplete data are demonstrated. The results obtained and the benefits from the application of the technique are presented.}
}
@article{ARFI2021120688,
title = {The role of trust in intention to use the IoT in eHealth: Application of the modified UTAUT in a consumer context},
journal = {Technological Forecasting and Social Change},
volume = {167},
pages = {120688},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.120688},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521001207},
author = {Wissal Ben Arfi and Imed Ben Nasr and Galina Kondrateva and Lubica Hikkerova},
keywords = {Internet of Things, Healthcare, Risk, Trust, UTAUT},
abstract = {The Internet of Things (IoT) has emerged over the last few decades in many fields, and healthcare can significantly benefit from the IoT. This study aims to examine factors influencing patients’ adoption of the IoT for eHealth. To reach this objective, a research framework was developed that applies the United Theory of Acceptance and Use of Technology (UTAUT) model and includes the risk−trust relationship to predicting intention to use IoT in the medical context. Partial Least Approach - Structural Equation Modeling was conducted with a sample of 267 French users. The findings highlight the key role of the risk−trust relationship for IoT adoption. An unexpected result indicates that performance expectancy has no impact on intention to use the IoT for eHealth. The contributions of this study can enable developers, medical professionals, and marketers to improve the design of connected devices, optimize patient communication, and target potential users more accurately, respectively.}
}
@article{CARREIRO20171160,
title = {Energy management systems aggregators: A literature survey},
journal = {Renewable and Sustainable Energy Reviews},
volume = {73},
pages = {1160-1172},
year = {2017},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2017.01.179},
url = {https://www.sciencedirect.com/science/article/pii/S1364032117301776},
author = {Andreia M. Carreiro and Humberto M. Jorge and Carlos Henggeler Antunes},
keywords = {Energy efficiency, Energy management systems, Energy management systems aggregators, Optimization ,dels, Ancillary services},
abstract = {In the Smart Grid context, the involvement of end-users is a key element for the implementation of demand response, as a way to enhance the energy efficiency of the electricity infrastructure also enabling to cope with the intermittency of renewable energy sources. Although the participation of end-users may result in higher complexity of system management, it may have a positive impact on mitigating the volatility of electricity prices. End-users may also be a key component in the provision of ancillary services using demand side resources to offer the system operator additional means to enhance system flexibility, robust planning, constraint management and operation scheduling, contributing to the balance between load and supply under a load follows supply paradigm. Demand response is seen as an effective and reliable strategy for the successful integration of renewable energy sources, in a perspective of integrated energy resource management, handling the demand curve using load flexibility whenever the system requires it. This embodies the possibility of changing/controlling the load profile by optimally time deferring the use of some equipment. This paper focuses on the role of energy management systems aggregators, both concerning actual practice in industry as well as research, which can be seen as relevant players contributing to that endeavour. A review of recent literature and projects is made, putting in perspective the role of energy management systems aggregators in the Smart Grid context, in association with demand response programs and technologies, involving the participation of end-users in the provision of ancillary services. The aim is recognizing trends, opportunities, challenges and potential barriers regarding the creation of energy management systems aggregators to improve overall system performance, characterizing the services provided by aggregators and identifying potential research gaps.}
}
@article{AGHAMOLAEI2020793,
title = {Feasibility analysis of community-based PV systems for residential districts: A comparison of on-site centralized and distributed PV installations},
journal = {Renewable Energy},
volume = {157},
pages = {793-808},
year = {2020},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2020.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S0960148120307229},
author = {Reihaneh Aghamolaei and Mohammad Haris Shamsi and James O’Donnell},
keywords = {PV Panels, Techno-economic, Feasibility analysis, Homer, Economic performance, Optimization},
abstract = {Photovoltaic systems are one of the most promising renewable energy technologies for on-site generation. Most of the techno-economic studies consider distributed standalone photovoltaic generation with little consideration of community-based standalone photovoltaic systems. Location-based case studies are required to provide economic and reliable photovoltaic systems to meet the peak loads of residential neighbourhoods in an optimized manner. This paper devises an integrated evaluation methodology; a combination of white-box energy modelling and black box photovoltaic design optimization. This research uses optimization methods to develop a quantitative optimized model for analysing the opportunities of centralized systems to adequately meet the demands of a residential neighbourhood and support the grid. This analysis includes three metrics including the level of the energy production, reliability of system for peak power and finally the capital cost of implementation in residential districts. Results indicate that the size of a centralized photovoltaic installation is less when compared to distributed installations to support a similar single peak load. The required converter size is reduced for the centralized system owing to the reduced system size. Centralized installations require fewer batteries to store surplus energy produced due to increased interaction of energy flows. Centralized installations are economically more viable than distributed ones.}
}
@article{GANI2020A133,
title = {A multi-layered view of chemical and biochemical engineering},
journal = {Chemical Engineering Research and Design},
volume = {155},
pages = {A133-A145},
year = {2020},
issn = {0263-8762},
doi = {https://doi.org/10.1016/j.cherd.2020.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0263876220300101},
author = {Rafiqul Gani and Jerzy Bałdyga and Béatrice Biscans and Elisabetta Brunazzi and Jean-Claude Charpentier and Enrico Drioli and Hermann Feise and Andrew Furlong and Kevin M. {Van Geem} and Jean-Charles {de Hemptinne} and Antoon J.B. {ten Kate} and Georgios M. Kontogeorgis and Flavio Manenti and Guy B. Marin and Seyed Soheil Mansouri and Patrick M. Piccione and Ana Povoa and Manuel Andres Rodrigo and Bent Sarup and Eva Sorensen and Isuru A. Udugama and John M. Woodley},
keywords = {Chemical and biochemical engineering, Research, Education, Practice, Multi-layered view},
abstract = {The contents of this article are based on the results of discussions the corresponding author has had since 2015 with the co-authors, who are members of academia and industry in Europe, on the scope and significance of chemical and biochemical engineering as a discipline. The result is a multi-layered view of chemical and biochemical engineering where the inner-layer deals with the fundamental principles and their application; the middle-layer deals with consolidation and expansion of the principles through a combination of science and engineering, leading to the development of sustainable technologies; and the outer-layer deals with integration of knowledge and collaboration with other disciplines to achieve a more sustainable society. Through this multi-layered view several important issues with respect to education, research and practice are highlighted together with current and future challenges and opportunities.}
}
@article{ALSHAIBA2020103110,
title = {Automatic manhole extraction from MMS data to update basemaps},
journal = {Automation in Construction},
volume = {113},
pages = {103110},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103110},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519301037},
author = {Omar Alshaiba and M. Amparo Núñez-Andrés and Nieves Lantada},
keywords = {Mobile mapping, LiDAR, Basemap updating, Geospatial data processing, Municipalities, Feature extraction, Vectorization, Point cloud classification},
abstract = {Basemaps are the main resource used in urban planning, building and infrastructure asset management. Therefore, they must be accurate and up to date to better serve citizens, contractors, property owners and town planning departments. Traditionally, they have been updated by aerial photogrammetry, but this is not always possible and alternatives need to be sought. In such cases, a useful option for large scales is the mobile mapping system (MMS). However, automatic extraction from MMS point clouds is limited by the complexity of the urban environment. Therefore, the influence of the urban pattern is analysed in three zones with varied urban characteristics: areas with high buildings, open areas, and areas with a low level of urbanization. In these areas, the capture and automatic extraction of 3D urban elements is performed using commercial software, which is useful for some elements but not for manholes. The objective of this study is to establish a methodology for extracting manholes automatically and completing hidden buildings' corners, in order to update urban basemaps. Shape and intensity are the main detection parameters for manholes, whereas additional information from satellite image Quickbird is used to complete the buildings. The worst rate of detection for all the extracted urban elements was found in areas of high buildings. Finally, the article analyses the computing cost for manhole extraction, and the economic cost and time consume of the entire process, including the proposed methodology using an MMS point cloud and the traditional survey in this case.}
}
@article{MICHAILIDOU2022101953,
title = {EQUALITY: Quality-aware intensive analytics on the edge},
journal = {Information Systems},
volume = {105},
pages = {101953},
year = {2022},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2021.101953},
url = {https://www.sciencedirect.com/science/article/pii/S0306437921001496},
author = {Anna-Valentini Michailidou and Anastasios Gounaris and Moysis Symeonides and Demetris Trihinas},
keywords = {Fog computing, Optimization, Sensors, Data quality},
abstract = {Our work is motivated by the fact that there is an increasing need to perform complex analytics jobs over streaming data as close to the edge devices as possible and, in parallel, it is important that data quality is considered as an optimization objective along with performance metrics. In this work, we develop a solution that trades latency for an increased fraction of incoming data, for which data quality-related measurements and operations are performed, in jobs running over geo-distributed heterogeneous and constrained resources. Our solution is hybrid: on the one hand, we perform search heuristics over locally optimal partial solutions to yield an enhanced global solution regarding task allocations; on the other hand, we employ a spring relaxation algorithm to avoid unnecessarily increased degree of partitioned parallelism. Through thorough experiments, we show that we can improve upon state-of-the-art solutions in terms of our objective function that combines latency and extent of quality checks by up to 2.56X. Moreover, we implement our solution within Apache Storm, and we perform experiments in an emulated setting. The results show that we can reduce the latency in 86.9% of the cases examined, while latency is up to 8 times lower compared to the built-in Storm scheduler, with the average latency reduction being 52.5%.}
}
@article{FAYOSJORDAN2020102788,
title = {Performance comparison of container orchestration platforms with low cost devices in the fog, assisting Internet of Things applications},
journal = {Journal of Network and Computer Applications},
volume = {169},
pages = {102788},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102788},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520302605},
author = {Rafael Fayos-Jordan and Santiago Felici-Castell and Jaume Segura-Garcia and Jesus Lopez-Ballester and Maximo Cobos},
keywords = {Fog computing, Docker swarm, Kubernetes, Containers, Container orchestration platforms, Performance comparison},
abstract = {In the last decade there has been an increasing interest and demand on the Internet of Things (IoT) and its applications. But, when a high level of computing and/or real time processing is required for these applications, different problems arise due to their requirements. In this context, low cost autonomous and distributed Small Board Computers (SBC) devices, with processing, storage capabilities and wireless communications can assist these IoT networks. Usually, these SBC devices run an operating system based on Linux. In this scenario, container-based technologies and fog computing are an interesting approach and both have led to a new paradigm in how devices cooperate, improving overall capacity in a cluster of these SBC devices. The use of containers is considered a lightweight virtualization, allowing an application to be broken into small tasks as services, enabling load balancing, flexibility and scalability. Nevertheless when the number of devices and containers increases in the cluster, it is required an orchestration layer. There are not many solutions and available alternatives using these technologies applied on these networks, and less an assessment of their performances. This paper focuses on these technologies when we use fog computing with low cost SBC devices in a context of IoT. We use Linux containers and different available orchestration platforms (in particular Docker Swarm and Kubernetes), to run on the top of the cluster of commercial SBC devices. Thus, we carry out a thorough functional and performance comparison with different real topologies (wired and wireless) and using both homogeneous and heterogeneous clusters of SBC devices, showing their results. We conclude that with the collected experimental results, Docker Swarm orchestration platform outperforms its counterparts in the scenarios shown.}
}
@article{RINGWOOD20147678,
title = {Control, forecasting and optimisation for wave energy conversion},
journal = {IFAC Proceedings Volumes},
volume = {47},
number = {3},
pages = {7678-7689},
year = {2014},
note = {19th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20140824-6-ZA-1003.00517},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016428235},
author = {John V. Ringwood and Giorgio Bacelli and Francesco Fusco},
keywords = {Wave energy, control, optimisation, power maximisation, wave forecasting},
abstract = {This paper presents an overview of the motivation, background to and state-of-the-art in energy maximising control of wave energy devices. The underpinning mathematical modelling is described and the control fundamentals established. Two example control schemes are presented, along with some algorithms for wave forecasting, which can be a necessary requirement, due to the non-causal nature of some optimal control strategies. One of the control schemes is extended to show how cooperative control of devices in a wave farm can be beneficial. The paper also includes perspectives on the interaction between control and the broader objectives of optimal wave energy device geometry and full techno-economic optimisation of wave energy converters.}
}
@article{KUMAR2021100313,
title = {A novel Software-Defined Drone Network (SDDN)-based collision avoidance strategies for on-road traffic monitoring and management},
journal = {Vehicular Communications},
volume = {28},
pages = {100313},
year = {2021},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2020.100313},
url = {https://www.sciencedirect.com/science/article/pii/S221420962030084X},
author = {Adarsh Kumar and Rajalakshmi Krishnamurthi and Anand Nayyar and Ashish Kr. Luhach and Mohammad S. Khan and Anuraj Singh},
keywords = {Collision avoidance, Collision detection, Drones, Performance analysis, SDDN, Simulation, Traffic monitoring},
abstract = {In present road traffic system, drone-network based traffic monitoring using the Internet of Vehicles (IoVs) is a promising solution. However, camera-based traffic monitoring does not collect complete data, cover all areas, provide quick medical services, or take vehicle follow-ups in case of an incident. Drone-based system helps to derive important information (such as commuter's behavior, traffic patterns, vehicle follow-ups) and sends this information to centralized or distributed authorities for making traffic diversions or necessary decisions as per laws. The present approaches fail to meet the requirements such as (i) collision free, (ii) drone navigation, and (iii) less computational and communicational overheads. This work has considered the collision-free drone-based movement strategies for road traffic monitoring using Software Defined Networking (SDN). The SDN controllable drone network results in lesser overhead over drones and provide efficient drone-device management. In simulation, two case studies are simulated using JaamSim simulator. Results show that the zones-based strategy covers a large area in few hours and consume 5 kWs to 25 kWs energy for 150 drones (Case study 1). Zone-less based strategies (case study-2) show that the energy consumption lies between 5 kWs to 18 kWs for 150 drones. Further, the use of SDN-based drones controller reduces the overhead over drone-network and increases the area coverage with a minimum of 1.2% and maximum of 2.6%. Simulation (using AnyLogic simulator) shows the 3D view of successful implementation of collision free strategies.}
}
@article{LIU2020101187,
title = {Joint power and subcarrier allocation for SWIPT in cognitive relay system},
journal = {Physical Communication},
volume = {43},
pages = {101187},
year = {2020},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2020.101187},
url = {https://www.sciencedirect.com/science/article/pii/S1874490720302640},
author = {Zhixin Liu and Motong Liu and Yazhou Yuan and Kit Yan Chan and Xinbin Li},
keywords = {Energy harvesting, Energy efficiency, Subcarrier allocation, Simultaneous wireless information and power transfer (SWIPT), Power allocation},
abstract = {In this paper, we study power and subcarrier allocation in decode-and-forward (DF) cognitive relay network based on orthogonal frequency division multiple access (OFDMA) technology, in which power splitting (PS) is used for the secondary users (SUs) supporting simultaneous wireless information and the power transfer (SWIPT). We attempt to maximize the energy efficiency (EE) of the secondary system subject to the constraints of minimum system rate, maximum transmission power and minimum harvested energy. The optimal power allocation (OPA) algorithm is proposed to determine the optimal solution of relay transmission power, power splitting ratio and subcarrier allocation. To tackle the original non-convex optimization problem, the Dinkelbach method is used for fractional programming and the problem is decomposed into two solvable sub-problems. The Lagrangian dual algorithm is utilized to determine the optimal transmission power and the power splitting ratio. The Hungarian algorithm is then introduced to determine the optimal subcarrier allocation. Compared with some existing algorithms, the simulation results show that the proposed OPA scheme is able to achieve higher energy efficiency when certain communication quality is required.}
}
@article{KOCH2016473,
title = {Optimising resource costs of cloud computing for education},
journal = {Future Generation Computer Systems},
volume = {55},
pages = {473-479},
year = {2016},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2015.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X15000758},
author = {Fernando Koch and Marcos D. Assunção and Carlos Cardonha and Marco A.S. Netto},
keywords = {Cloud computing, Education, Resource allocation, QoS},
abstract = {There is a growing interest around the utilisation of cloud computing in education. As organisations involved in the area typically face severe budget restrictions, there is a need for cost optimisation mechanisms that explore unique features of digital learning environments. In this work, we introduce a method based on Maximum Likelihood Estimation that considers heterogeneity of IT infrastructure in order to devise resource allocation plans that maximise platform utilisation for educational environments. We performed experiments using modelled datasets from real digital teaching solutions and obtained cost reductions of up to 30%, compared with conservative resource allocation strategies.}
}
@article{GALLE2021127099,
title = {Mapping the diversity of street tree inventories across eight cities internationally using open data},
journal = {Urban Forestry & Urban Greening},
volume = {61},
pages = {127099},
year = {2021},
issn = {1618-8667},
doi = {https://doi.org/10.1016/j.ufug.2021.127099},
url = {https://www.sciencedirect.com/science/article/pii/S1618866721001242},
author = {Nadina J. Galle and Dylan Halpern and Sophie Nitoslawski and Fábio Duarte and Carlo Ratti and Francesco Pilla},
keywords = {Urban forest, Biodiversity, Open data, Resilience, Street trees, Urban density},
abstract = {Tree diversity, on a species-, genus-, and family-level, is an important factor in securing healthy urban forests and providing ecosystem services for billions of city dwellers. Using open-source data on global tree inventories, this study examines (1) the diversity of species, genera, and family of urban street trees in eight cities internationally; (2) how they score on diversity benchmarks and indices; and (3) the diversity variation inside and outside of cities’ centers. We hypothesized most cities would score poorly on diversity benchmarks and spatial patterns in species composition would exist, as illustrated by established relationships between urban density and urban tree diversity. Results indicate city centers were less likely to approach the proposed diversity benchmarks than outside the city center. Overall, both Shannon and Simpson diversity indices show greater diversity outside of the city center, especially at the species-level. Understanding street tree diversity and spatial variation patterns across cities internationally can offer needed evidence to back up heuristic benchmarks. The methodology and open-source data used in this study are intended to enable practitioners better target tree diversity efforts.}
}
@article{FONSECA2017229,
title = {Unsupervised load shape clustering for urban building performance assessment},
journal = {Energy Procedia},
volume = {122},
pages = {229-234},
year = {2017},
note = {CISBAT 2017 International ConferenceFuture Buildings & Districts – Energy Efficiency from Nano to Urban Scale},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2017.07.350},
url = {https://www.sciencedirect.com/science/article/pii/S1876610217329545},
author = {Jimeno A. Fonseca and Clayton Miller and Arno Schlueter},
keywords = {Building performance, Data mining, Daily Profile Extraction},
abstract = {This paper presents a method to automatically cluster typical days of energy consumption in one or several buildings. The method is based on an optimized version of the Symbolic Aggregate approXimation (SAX) method. SAX is a data mining technique for clustering time series with recent applications in building fault detection and building performance assessment. The number of clusters and accuracy of SAX highly depends on two highly sensitive input variables, i.e., the word size and the alphabet size. We propose the use of the genetic algorithm NSGA-II to optimize the number of words and alphabet size of SAX subjected to three fitness objectives, i.e., maximize data accuracy and compression and minimize complexity. In addition, we propose the use of MAVT as selection method of the optimal solution. The methodology is applied to measured energy consumption data of three representative buildings on a university campus in Singapore. Potential future uses of the approach include advanced studies in fault detection and calibration of urban building performance models.}
}
@article{KUBLER2019817,
title = {Benefit-cost model for comparing data center performance from a biomimicry perspective},
journal = {Journal of Cleaner Production},
volume = {231},
pages = {817-834},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.05.183},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619317111},
author = {Sylvain Kubler and Éric Rondeau and Jean-Philippe Georges and Phoebe Lembi Mutua and Marta Chinnici},
keywords = {Green computing, Green networking, Sustainability, Multiple criteria decision-making, Analytic hierarchy process (AHP), Biomimicry},
abstract = {Data centers are estimated to have the fastest growing carbon footprint from across the whole information and communication technology (ICT) sector. Evaluating the performance of data centers in terms of energy efficiency and sustainability is becoming an increasingly important matter for organizations and governments (e.g., for regulation or reputation purposes). It nonetheless remains difficult to achieve such evaluation, as data centers imply to take into consideration a wide range of dimensions and stakeholders. Even though a wide range of sustainability performance indicators exist in the literature, there is still a lack of frameworks to help data center stakeholders (spanning from data center owners, governmental regulators to engineers/field operators) to evaluate and understand how a data center performs in terms of sustainable development/behavior. Our research work proposes such a framework, whose originality lies in the combination of state-of-the-art sustainability metrics with the biomimicry commandments of eco-mature system, which enables holistic sustainability assessment of data centres. From a theoretical perspective, the proposed model is designed based on a benefit-cost analysis using the Analytic Hierarchy Process (AHP) technique. This approach allows data center stakeholders for specifying their own preferences and/or expertise in the comparison process, whose practicability is demonstrated in this paper considering three data center candidates, which are respectively located in France, Germany and Sweden.}
}
@article{TEKBIYIK2019100700,
title = {Terahertz band communication systems: Challenges, novelties and standardization efforts},
journal = {Physical Communication},
volume = {35},
pages = {100700},
year = {2019},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2019.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S1874490718307766},
author = {Kürşat Tekbıyık and Ali Rıza Ekti and Güneş Karabulut Kurt and Ali Görçin},
keywords = {Terahertz, Beyond 5G wireless communication, Nanonetworks, Terahertz hardware, Graphene},
abstract = {Wireless data rates are expected to be around 10Gbps or even more within the upcoming decade. The realization of such high data rates is unlikely with the currently licensed bands in the spectrum. Therefore, it is clear that such high rates could only be achieved by employing more bandwidth with the state-of-the-art technology. Considering the fact that bands in the range of 275GHz–3000GHz, which are known as Terahertz (THz) bands, are not yet allocated for specific active services around the globe, there can be a true potential to achieve the desired data rates at THz bands. However, due to the characteristics of these bands, there are many open issues in terms of THz radio communication system design. In this study, open issues and the state-of-the-art solutions to these issues for THz communication system design are discussed. Moreover, standardization efforts up to date are elaborated. This study concludes that the actual implementation of fully operational THz communication systems obliges to carry out a multi-disciplinary effort including statistical propagation and channel characterizations, adaptive transceiver designs (including both baseband and radio frequency (RF) front-end portions), reconfigurable platforms, advanced signal processing algorithms and techniques along with upper layer protocols equipped with various security and privacy levels.}
}
@article{CHEN2018172,
title = {A swarm intelligence based distributed decision approach for transactive operation of networked building clusters},
journal = {Energy and Buildings},
volume = {169},
pages = {172-184},
year = {2018},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2018.03.047},
url = {https://www.sciencedirect.com/science/article/pii/S0378778817337763},
author = {Yang Chen and Mengqi Hu},
keywords = {Building clusters, Smart grid, Swarm intelligence, Marginal price, Transactive operation},
abstract = {Recently, existing research has demonstrated that more benefits of energy cost saving, environmental sustainability and reliable power supply can be achieved by clustering buildings together to freely exchange information and energy. To enable efficient transactive operation among buildings in the cluster, both centralized and distributed decision approaches were developed in the recent decades. However, most of the existing approaches are only applicable for small scale building clusters and/or the privacy of each stakeholder (e.g., building) is not well protected. To bridge these research gaps, we propose a swarm intelligence based bi-level distributed decision approach. A particle swarm optimizer is employed at the system level to coordinate the transactive operations among buildings, and a mixed integer programming model is developed for each building to simultaneously obtain operation decisions for its energy systems. The only information exchanged between the system level and building level is the marginal price of transactive energy which can protect the private information for each building. The performance of the proposed decision approach in terms of accuracy, scalability, and robustness is evaluated using various building clusters with the number of buildings from 2 to 256. It is demonstrated that our proposed approach is very computationally efficient, scalable and robust, and the computational complexity is O(n) where n is the number of buildings in the cluster.}
}
@article{PRAJAPATI2021111703,
title = {An overview of municipal solid waste management in Jaipur city, India - Current status, challenges and recommendations},
journal = {Renewable and Sustainable Energy Reviews},
volume = {152},
pages = {111703},
year = {2021},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2021.111703},
url = {https://www.sciencedirect.com/science/article/pii/S1364032121009771},
author = {Kishan Kumar Prajapati and Monika Yadav and Rao Martand Singh and Priti Parikh and Nidhi Pareek and Vivekanand Vivekanand},
keywords = {Municipal solid waste, Waste to energy, Landfill, Anaerobic digestion, Optimization models, Life cycle assessment},
abstract = {In developing countries, urbanization and rapid population growth has resulted in a substantial increase in generation of Municipal Solid Waste (MSW). Safe collection, transportation and treatment of MSW are among the major issues for Indian cities. Poor MSW management practices have negative impact on public health, environment and climate change. India currently only treats 21% of MSW while the remainder disposed in unsanitary landfill sites with no recycling and treatment technologies. This paper reviews the existing MSW management practices, challenges and provides recommendations for improving MSW management for the city of Jaipur in Rajasthan, India. Despite being the state capital as well as the top tourist destination in northern part of India, there is no detailed study which reviews the waste management strategies of this city along with identifying the key challenges. The study reveals that the major challenges for MSW management in Jaipur include uncontrolled landfilling, inadequate public participation as well as failings of implementation of MSW legislation and waste conversion. Recommendations for improvement include public awareness campaigns, public-private partnership, investment in lined landfills, recycling and waste to energy techniques. Optimization models and life cycle assessment tools should be employed to minimize cost and the environmental impact of MSW management. This study will provide policy makers and private sector stakeholders to develop strategies for future planning, investment and execution of improved MSW management in Indian cities.}
}
@article{FERNANDEZ2016108,
title = {Enhancing evolutionary fuzzy systems for multi-class problems: Distance-based relative competence weighting with truncated confidences (DRCW-TC)},
journal = {International Journal of Approximate Reasoning},
volume = {73},
pages = {108-122},
year = {2016},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2016.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X16300068},
author = {Alberto Fernández and Mikel Elkano and Mikel Galar and José Antonio Sanz and Saleh Alshomrani and Humberto Bustince and Francisco Herrera},
keywords = {Multi-class classification, Pairwise learning, One-vs-One, Classifier selection, Evolutionary fuzzy systems, Fuzzy rule based classification systems},
abstract = {Classification problems with multiple classes suppose a challenge in Data Mining tasks. There is a difficulty inherent to the learning process when trying to find the most adequate discrimination functions among the different concepts within the dataset. Using Fuzzy Rule Based Classification Systems in general, and Evolutionary Fuzzy Systems in particular, provide the advantage of describing smoother borderline areas, thanks to the linguistic label-based representation. In multi-classification, the pairwise learning approach (One-vs-One) has gained a notorious attention. However, there is certain dependence between the goodness of the confidence degrees or scores of binary classifiers, and the final performance shown by the global model. Regarding this fact, the problem of non-competent classifiers is of special relevance. It occurs when a binary classifier outputs a positive score for a couple of classes unrelated with the input example, which may degrade the final accuracy. Precisely, the previously exposed properties of fuzzy classifiers make them more prone to the former condition. In this paper, we propose an extension of the distance-based combination strategy to overcome this non-competence problem. It is based on the truncation of the confidence degrees of the classes prior to the distance-based tuning. This allows taking advantage of the good classification abilities of Evolutionary Fuzzy Systems, while diminishing the adverse effect of the aforementioned non-competence. Experimental results, using FARC-HD with overlap functions as the fuzzy learning algorithm, show that this new adaptation of the Distance-based Relative Competence Weighting model outperforms both the OVO and standard distance-based approaches, and it is competitive with robust classifiers such as Support Vector Machines.}
}
@article{SIRI2021109655,
title = {Freeway traffic control: A survey},
journal = {Automatica},
volume = {130},
pages = {109655},
year = {2021},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2021.109655},
url = {https://www.sciencedirect.com/science/article/pii/S0005109821001758},
author = {Silvia Siri and Cecilia Pasquale and Simona Sacone and Antonella Ferrara},
keywords = {Freeway traffic networks, Traffic models, Control methods and algorithms, Integrated traffic management, Large scale complex systems},
abstract = {Freeway traffic control is a broad research area, not only interesting for its applicative perspective, but also highly motivating for theoretical investigations. This research topic has been developed in the last decades by different research groups worldwide and still offers open problems and issues to tackle which may be a source of inspiration for the community of control engineers and scientists. Since the recent technological advances towards autonomous and connected vehicles suggest that a new era for road traffic is around the corner, a survey on well-established control methods for freeway traffic networks seems particularly useful now, to fix a milestone for all the researchers in the area, in order to be ready to face the challenges of the future traffic scenarios. In this survey paper, the control approaches developed in the last decades for freeway traffic control are reviewed and a bibliometric analysis on recent scientific works addressing this topic is reported.}
}
@article{SURACI2021107604,
title = {A stakeholder-oriented security analysis in virtualized 5G cellular networks},
journal = {Computer Networks},
volume = {184},
pages = {107604},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107604},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620312366},
author = {Chiara Suraci and Giuseppe Araniti and Andrea Abrardo and Giuseppe Bianchi and Antonio Iera},
keywords = {5G, Security, Virtualization, Stakeholders, Business models},
abstract = {Besides significantly outperforming past generations in terms of capacity and throughput, 5G networks and systems will provide an infrastructure for the support of highly diversified services and “verticals”. Indeed, the major paradigm shift with respect to previous cellular network generations, specifically oriented to one class of terminals (namely, people’s cell phones), is the largely heterogeneous nature of the multiplicity of end systems supported. Within a 5G infrastructure, playing the role of “network of networks”, traditionally independent technical and business stakeholders are now called to cooperate in the deployment of crucial infrastructure components relying on innovative (for the Telecom world) technologies such as virtualization, not in the traditional operators’ portfolio, and eventually placed in security-critical parts of the network — think e.g. to Multi Access Edge Computing systems. Goal of this survey is to analyze the complex threat landscape of 5G systems, by taking the point of view of the involved stakeholders. The motivation behind our proposed analysis revolves on the observation that, in complex and virtualized systems such as the 5G infrastructure, an attack to a system component under the responsibility of a given stakeholder may yield a dramatic impact to a completely different player. Therefore, while reviewing the many 5G security risks and relevant threats which the main stakeholders operating in virtualized 5G cellular networks are exposed to, we will try to showcase the sometimes non-obvious relation between impact and responsibility, as well as identify shared responsibilities.}
}
@article{RINALDI2020120762,
title = {Optimised allocation of PV and storage capacity among different consumer types and urban settings: A prospective analysis for Switzerland},
journal = {Journal of Cleaner Production},
volume = {259},
pages = {120762},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2020.120762},
url = {https://www.sciencedirect.com/science/article/pii/S095965262030809X},
author = {Arthur Rinaldi and Martin Christoph Soini and Martin K. Patel and David Parra},
keywords = {Storage, PV, Dispatch model, Sub-national nodes, Consumer types, Distribution capacity constraints},
abstract = {This paper discusses the optimal configuration of PV and electricity storage in a detailed representation of the Swiss power system. The sensitivity of storage deployment with respect to distribution network capacity is also investigated. We propose an open-source dispatch model to optimise the electricity supply of Switzerland and its four neighbouring countries with hourly time resolution. Moreover, our representation of the Swiss power system includes various types of consumers, namely, the residential (single-family house and multi-family house), service and industrial sectors, with a differentiation by rural, suburban and urban settings, resulting in 12 sub-national nodes. We then use monitored electricity demand load data for each sector. We find that the achievement of the Swiss federal target of 13.8 GWp PV capacity by 2050, which corresponds to 30% of the annual production, requires an additional storage capacity of 11 GWh (corresponding to 1.6 h of average consumption) in order to minimise total costs. However, when letting the optimisation model choose both the PV capacity and the size of energy storage, then minimal costs are achieved by a system with 24.6 GWp of PV (corresponding to 53% of the annual production) combined with 29.2 GWh (4.1 h of average consumption) of storage capacity. Our results show that storage plays an important role in minimising the total cost for energy systems with large PV capacity as well as satisfying the distribution capacity constraints. The detailed results and mechanisms at the level of sub-national nodes are discussed. The model and the methodology presented in this study with a focus the Swiss case can be applied to any country/region.}
}
@article{KANNISTO2021100253,
title = {Plant-wide interoperability and decoupled, data-driven process control with message bus communication},
journal = {Journal of Industrial Information Integration},
pages = {100253},
year = {2021},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2021.100253},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X21000522},
author = {Petri Kannisto and David Hästbacka and Teresa Gutiérrez and Olli Suominen and Matti Vilkko and Peter Craamer},
keywords = {Systems integration, Service-oriented architecture, Industrial cyber–physical systems, Industry 4.0, Publish–subscribe communication pattern},
abstract = {Conventional industrial communication systems suffer from rigidness, inflexibility and lack of scalability. The environment is heterogeneous as the systems exchange data with a variety communication protocols, some of which are proprietary. This makes it laborious and expensive to reconfigure or upgrade the systems. As the solution, this article proposes a message-bus-based communication architecture to enable information exchange between systems regardless of their geographical location and position within the functional hierarchy of the plant. The architecture not only enables communication to cross the conventional physical borders but also provides scalability to growing data volumes and network sizes. As proofs of concept, the article presents a prototype in three environments: a copper smelter, a steel plant and a distillation column. The results suggest that the message-bus-based approach has potential to renew industrial communications, a core part of the fourth industrial revolution.}
}
@article{VASUDEV2021107989,
title = {P2-SHARP: Privacy Preserving Secure Hash based Authentication and Revelation Protocol in IoVs},
journal = {Computer Networks},
volume = {191},
pages = {107989},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.107989},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621001146},
author = {Harsha Vasudev and Debasis Das},
keywords = {Vehicular networking, Internet of Vehicles (IoVs), Security, Privacy, Authentication, Communication},
abstract = {In the near future, one of the promising concepts that are going to change undoubtedly the whole automobile industry, vehicular networking, and transportation sector is the Internet of Vehicles (IoVs). IoVs open new opportunities in different services and applications to enhance road conditions, driver/passenger safety, transportation issues, non-safety applications, and especially for the avoidance of accidents. For reducing accidents, timely warning messages play an important role. For that, lightweight protocols are needed. Another important criterion to be ensured is ‘security’. Because the attackers always try to convey false warning messages that may result in serious issues or attacks. However, in the existing research, secure and lightweight protocols in IoVs are missing. Hence, in this paper, we designed a protocol, P2-SHARP (Privacy-Preserving Secure Hash-based Authentication and Revelation Protocol) using IoVs. In this scheme, secure transmission of local and global warning messages is done. For ensuring security, we have used several cryptographic operations. Security and performance analysis reveals the efficiency of P2-SHARP.}
}
@article{MS201932,
title = {Social Internet of Things (SIoT): Foundations, thrust areas, systematic review and future directions},
journal = {Computer Communications},
volume = {139},
pages = {32-57},
year = {2019},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S0140366418307655},
author = {Roopa M.S. and Santosh Pattar and Rajkumar Buyya and Venugopal K.R. and S.S. Iyengar and L.M. Patnaik},
keywords = {Network navigability, Relationship management, Service composition, Service discovery, Social Internet of Things, Trust management},
abstract = {Internet of Things (IoT) paradigm connects physical world and cyberspace via physical objects and facilitate the development of smart applications and infrastructures. A physical object is the basic constituent of IoT, often called as smart object, that interact with other objects and possess the information processing abilities. The smart objects when deployed in the real world, collect information from the surrounding environment and this is abstracted as a service. IoT has established a universe where humans are provided smart data services by the fusion of physical objects and information networks. This approach has been extended to include social networking aspects in the IoT that autonomously build social relationships to discover objects and their services viz; Social Internet of Things (SIoT). SIoT enhances information sharing, supports new applications and provide a reliable and trustworthy networking solutions utilizing the social network of friend objects. In this paper, we present the fundamentals of SIoT, identify thrust areas of it (as service discovery and composition, network navigability, relationship management, and trustworthiness management) and present several prerequisites, challenges and use case scenarios based on them. State-of-the-art research publications are reviewed on service discovery, relationship management, service composition and trust management constituents of the SIoT environment. Finally, we identify and discuss the future research directions that serves as a reference for the next generation discovery techniques to improve service provisioning, find the optimal solution for the link selection in the SIoT structure, develop large scale platforms and provide a smart mechanism for trust evaluation.}
}
@article{JIANG201935,
title = {Outage probability optimization for UAV-enabled wireless relay networks in fading channels},
journal = {Physical Communication},
volume = {33},
pages = {35-45},
year = {2019},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2018.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S1874490718304658},
author = {Xu Jiang and Zhendong Yin and Zhilu Wu and Zhutian Yang and Jinlong Sun},
keywords = {Decode-and-forward (DF), Mobile relay, Outage probability, Time and power allocation, Unmanned aerial vehicle (UAV)},
abstract = {In this paper, we consider a mobile wireless relaying system, where a fixed-wing unmanned aerial vehicle (UAV) flies in a circular manner to provide continuous relaying between two disconnected ground stations. The system employs a UAV to ferry data from source to destination in a time division (TD) manner with limited energy budget. To improve the outage performance of this system in fading channels, we develop time and power allocation schemes for the source and relay nodes. Our approach does not depend on instantaneous channel state information. Instead, we assume that only channel statistics (i.e., mean and variance) are known at the transmitters. In Rayleigh fading channel, we show that the outage probability optimization problem is a convex optimization problem, which can be solved by standard convex optimization techniques. In Rician fading channel, we develop an asymptotic optimal time and power allocation scheme to minimize the outage probability in high signal-to-noise ratio (SNR) regime. Our derivation indicates that the proposed time and power allocation schemes in Rayleigh channel and Rician channel are identical. Numerical results show that significant improvement can be obtained through the proposed time and power allocation schemes.}
}
@article{ALI2018290,
title = {A zero-watermarking algorithm for privacy protection in biomedical signals},
journal = {Future Generation Computer Systems},
volume = {82},
pages = {290-303},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17322975},
author = {Zulfiqar Ali and Muhammad Imran and Mansour Alsulaiman and Tanveer Zia and Muhammad Shoaib},
keywords = {E-healthcare, Privacy protection, Zero-watermarking, Visual cryptography, Local binary pattern, MFCC, SVM},
abstract = {Confidentiality of health information is indispensable to protect privacy of an individual. However, recent advances in electronic healthcare systems allow transmission of sensitive information through the Internet, which is prone to various vulnerabilities, attacks and may leads to unauthorized disclosure. Such situations may not only create adverse effects for individuals but may also cause severe consequences such as hefty regulatory fines, bad publicity, legal fees, and forensics. To avoid such predicaments, a privacy protected healthcare system is proposed in this study that protects the identity of an individual as well as detects vocal fold disorders. The privacy of the developed healthcare system is based on the proposed zero-watermarking algorithm, which embeds a watermark in a secret key instead of the signals to avoid the distortion in an audio sample. The identity is protected by the generation of its secret shares through visual cryptography. The generated shares are embedded by finding the patterns into the audio with the application of one-dimensional local binary pattern. The proposed zero-watermarking algorithm is evaluated by using audio samples taken from the Massachusetts Eye and Ear Infirmary voice disorder database. Experimental results demonstrate that the proposed algorithm achieves imperceptibility and is reliable in its extraction of identity. In addition, the proposed algorithm does not affect the results of disorder detection and it is robust against noise attacks of various signal-to-noise ratios.}
}
@article{ANNARELLI2020106829,
title = {Understanding the management of cyber resilient systems},
journal = {Computers & Industrial Engineering},
volume = {149},
pages = {106829},
year = {2020},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2020.106829},
url = {https://www.sciencedirect.com/science/article/pii/S0360835220305325},
author = {Alessandro Annarelli and Fabio Nonino and Giulia Palombi},
keywords = {Resilience, Cyber security, Cyber resilient systems, Cyber resilience framework, Multiple case study},
abstract = {The digital age characterizes the 21-century by the widespread and conscious use of Information Technology, originating the need for organizations to protect one of the most critical and valuable resources: information. Cyber security was born to protect information systems from cyber-attacks. Organizational resilience refers to the ability of a system to adapt to a change: a very contemporary concept that is finding more and more importance in our continuously changing society, assuming also a greater relevance in the cyber context. Therefore, the ability of organizations to react to cyber-attacks and to evolve to a new robustness after successful outbreaks recalls the concept of resilience and brings to the evolution of this concept into that of cyber resilience. In order to offer a deep insight on the management of cyber resilient systems and to propose a Managerial Cyber Resilience Framework, clarifying the role of context in the correct selection and implementation of different tools and practices, we conducted an exploratory multiple case study analysis in six companies operating in three different industries: consultancy, public administration and banking. The results provide interesting managerial actions to undertake for the management of cyber resilient systems also in consideration of specific contextual factors.}
}
@article{SRIVASTAVA2020102760,
title = {Energy efficient transmission trends towards future green cognitive radio networks (5G): Progress, taxonomy and open challenges},
journal = {Journal of Network and Computer Applications},
volume = {168},
pages = {102760},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102760},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520302344},
author = {Akanksha Srivastava and Mani Shekhar Gupta and Gurjit Kaur},
keywords = {Green communication, Carbon dioxide emissions, Carrier aggregation, Massive MIMO, D2D communications, Green IoT, Cognitive radio network},
abstract = {With the growing cognizance about environmental concern and global warming-related to communication technologies, the researchers have been seeking some solutions to diminish the consumption of energy in the telecommunication industry. There is a remarkable advancement in mobile communication from simple voice-based devices to ubiquitous data-hungry smartphones. Nearly, 8 billion mobile subscribers are expected to be added by 2030 and also required an extra spectrum to serve. The existing static spectrum allocation-based technologies are not in a position to fulfill this extra spectrum requirement and handle this future traffic load. This volatile evolution of global traffic data urges research attention globally and can be handled by future cognitive radio networks. There is also a demand for providing fast speed and seamless services for which operators need to deploy more base stations continuously and increase the transmitting antenna power. As a result, a drastic hike in emissions of carbon dioxide into the environment, and exposure to harmful radiations in large amounts which is also authentically harmful to humans, animals, and birds. This increased energy consumption and scarcity of resources have made the energy as a geopolitical issue for 21 century. In this direction, this work contributes by introducing cognitive-based green communication technology to ensure the environmental and health concerns caused due to hike in the CO2 level. In the second phase, an enlightening survey on futuristic approaches for making the future wireless networks green is covered with pros and cons. In the third phase, this paper provides a framework of research challenges with ongoing project activities on green communication which further requires attention from the research community.}
}
@article{BITTENCOURT2018134,
title = {The Internet of Things, Fog and Cloud continuum: Integration and challenges},
journal = {Internet of Things},
volume = {3-4},
pages = {134-155},
year = {2018},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2018.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S2542660518300635},
author = {Luiz Bittencourt and Roger Immich and Rizos Sakellariou and Nelson Fonseca and Edmundo Madeira and Marilia Curado and Leandro Villas and Luiz DaSilva and Craig Lee and Omer Rana},
keywords = {Internet of Things (IoT), Fog computing, Edge computing, Cloud computing},
abstract = {The Internet of Things needs for computing power and storage are expected to remain on the rise in the next decade. Consequently, the amount of data generated by devices at the edge of the network will also grow. While cloud computing has been an established and effective way of acquiring computation and storage as a service to many applications, it may not be suitable to handle the myriad of data from IoT devices and fulfill largely heterogeneous application requirements. Fog computing has been developed to lie between IoT and the cloud, providing a hierarchy of computing power that can collect, aggregate, and process data from/to IoT devices. Combining fog and cloud may reduce data transfers and communication bottlenecks to the cloud and also contribute to reduced latencies, as fog computing resources exist closer to the edge. This paper examines this IoT-Fog-Cloud ecosystem and provides a literature review from different facets of it: how it can be organized, how management is being addressed, and how applications can benefit from it. Lastly, we present challenging issues yet to be addressed in IoT-Fog-Cloud infrastructures.}
}
@article{HAIDER201921,
title = {DABFS: A robust routing protocol for warning messages dissemination in VANETs},
journal = {Computer Communications},
volume = {147},
pages = {21-34},
year = {2019},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419304761},
author = {Shahab Haider and Ghulam Abbas and Ziaul Haq Abbas and Thar Baker},
keywords = {Vehicular ad hoc networks, Routing protocols, Direction-based Greedy forwarding, Bi-directional traffic, Warning message dissemination},
abstract = {Vehicular ad hoc networks play a pivotal role in the enrichment of transportation systems by making them intelligent and capable of avoiding road accidents. For transmission of warning messages, direction-based Greedy protocols select the next hop based on the current location of relay nodes toward the destination node, which is an efficient approach for uni-directional traffic. However, such protocols experience performance degradation by neglecting the movement directions of nodes in bi-directional traffic where topological changes occur dynamically. This paper pioneers the use of movement direction and relative positions of source and destination nodes to cater to the dynamic nature of bi-directional highway environments for efficient and robust routing of warning messages. A novel routing protocol, namely, Direction Aware Best Forwarder Selection (DABFS), is presented in this paper. DABFS takes into account directions and relative positions of nodes, besides the distance parameter, to determine a node’s movement direction using Hamming distance and forwards warning messages through neighbor and best route discovery. Analytical and simulation results demonstrate that DABFS offers improved throughput and reduced packet loss rate and end-to-end delay, as compared with eminent routing protocols.}
}
@article{WRIGHT2020119972,
title = {Policy scenarios as an instrument for policymakers},
journal = {Technological Forecasting and Social Change},
volume = {154},
pages = {119972},
year = {2020},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2020.119972},
url = {https://www.sciencedirect.com/science/article/pii/S0040162519308753},
author = {David Wright and Bernd Stahl and Tally Hatzakis},
keywords = {Policy scenarios, Scenario construction process, Ethical, Privacy, Social and economic aspects, Stakeholder engagement, Participatory},
abstract = {Scenarios are a methodology of futures and foresight research that has been established for more than half a century. Despite the rich literature on scenarios and ways of constructing them, the current scenario methodologies, current approaches to scenario constructions are often not well aligned with the needs of policymakers. Emerging technologies that are likely to achieve high social relevance in the short to mid-term future and that call for quick policy interventions are difficult to reflect using current scenario approaches. We have therefore developed a new type of scenario that we call a policy scenario. This paper develops the principles and justification for policy scenarios. We provide a detailed description of how they can be constructed, focusing on their key characteristics of policy requirements, plausibility, probability, credibility, expertise, objectivity and legitimacy. Following our stakeholder-based approach allows researchers to construct scenarios that are uniquely suited to inform policymakers and, in effect, the policy development process.}
}
@article{ALMEIDA201827,
title = {Energy monitoring as an essential building block towards sustainable ultrascale systems},
journal = {Sustainable Computing: Informatics and Systems},
volume = {17},
pages = {27-42},
year = {2018},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2017.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S2210537916301536},
author = {Francisco Almeida and Marcos D. Assunção and Jorge Barbosa and Vicente Blanco and Ivona Brandic and Georges {Da Costa} and Manuel F. Dolz and Anne C. Elster and Mateusz Jarus and Helen D. Karatza and Laurent Lefèvre and Ilias Mavridis and Ariel Oleksiak and Anne-Cécile Orgerie and Jean-Marc Pierson},
keywords = {Ultra large-scale systems, Energy-awareness, Energy-efficiency, Monitoring},
abstract = {An ultrascale system (USS) joins parallel and distributed computing systems that will be two to three orders of magnitude larger than today's infrastructure regarding scale, performance, the number of components and their complexity. For such systems to become a reality, however, advances must be made in high performance computing (HPC), large-scale distributed systems, and big data solutions, also tackling challenges such as improving the energy efficiency of the IT infrastructure. Monitoring the power consumed by underlying IT resources is essential towards optimising the manner IT resources are used and hence improve the sustainability of such systems. Nevertheless, monitoring the energy consumed by USSs is a challenging endeavour as the system can comprise thousands of heterogeneous server resources spanning multiple data centres. Moreover, the amount of monitoring data, its gathering, and processing, should never become a bottleneck nor profoundly impact the energy efficiency of the overall system. This work surveys state of the art on energy monitoring of large-scale systems and methodologies for monitoring the power consumed by large systems and discusses some of the challenges to be addressed towards monitoring and improving the energy efficiency of USSs. Next, we present efforts made on designing monitoring solutions. Finally, we discuss potential gaps in existing solutions when tackling emerging large-scale monitoring scenarios and present some directions for future research on the topic.}
}
@article{PETROVIC2020102033,
title = {SMADA-Fog: Semantic model driven approach to deployment and adaptivity in fog computing},
journal = {Simulation Modelling Practice and Theory},
volume = {101},
pages = {102033},
year = {2020},
note = {Modeling and Simulation of Fog Computing},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2019.102033},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X19301649},
author = {Nenad Petrovic and Milorad Tosic},
keywords = {DevOps, Fog Computing, Infrastructure as code, Linear optimization, Model-driven engineering, Semantic technology},
abstract = {The deployment, monitoring and configuration of applications in Fog Computing are becoming quite challenging, due to heterogeneity of mobile and IoT devices involved, data movement constraints imposed by legal regulations as well as frequent changes in the execution environment that may affect quality of service. As a consequence, the system administration procedures are becoming more complex and time-consuming, especially if done manually. In this paper, a Semantic Model driven Approach to Deployment and Adaptivity of container-based applications in Fog Computing (SMADA-Fog) is proposed. Modeling tools, semantic framework, linear optimization model, simulation environment and infrastructure management code generator leveraging the semantic annotations are implemented and presented. According to results of the two experimentally tested scenarios, the proposed approach improves the application performance, while the time required for deployment as well as service adaptation is reduced for at least an order of magnitude.}
}
@article{DANIELLO2015430,
title = {A multi-agent fuzzy consensus model in a Situation Awareness framework},
journal = {Applied Soft Computing},
volume = {30},
pages = {430-440},
year = {2015},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2015.01.061},
url = {https://www.sciencedirect.com/science/article/pii/S1568494615000824},
author = {Giuseppe D’Aniello and Vincenzo Loia and Francesco Orciuoli},
keywords = {Fuzzy consensus model, Situation Awareness, Semantic web, Intelligent agents, Group decision making},
abstract = {In order to define systems enabling the automatic identification of occurring situations, numerous approaches employing intelligent software agents to analyse data coming from deployed sensors have been proposed. Thus, it is possible that more agents are committed to monitor the same phenomenon in the same environment. Redundancy of sensors and agents is needed, for instance, in real world applications in order to mitigate the risk of faults and threats. One of the possible side effects produced by redundancy is that agents, observing the same phenomenon, could provide discordant opinions. Indeed, solid mechanisms for reaching an agreement among these agents and produce a shared consensus on the same observations are needed. This paper proposes an approach to integrate a fuzzy-based consensus model into a Situation Awareness framework. The main idea is to consider intelligent agents as experts claiming their opinions (preferences) on a phenomenon of interest.}
}
@article{MORSCHHEUSER20197,
title = {Cooperation or competition – When do people contribute more? A field experiment on gamification of crowdsourcing},
journal = {International Journal of Human-Computer Studies},
volume = {127},
pages = {7-24},
year = {2019},
note = {Strengthening gamification studies: critical challenges and new opportunities},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2018.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S1071581918305822},
author = {Benedikt Morschheuser and Juho Hamari and Alexander Maedche},
keywords = {Gamification, Crowdsourcing, Augmented reality, Goal setting, Social interdependence, Collaboration},
abstract = {Information technology is being increasingly employed to harness under-utilized resources via more effective coordination. This progress has manifested in different developments, for instance, crowdsourcing (e.g. Wikipedia, Amazon Mechanical Turk, and Waze), crowdfunding (e.g. Kickstarter, Indiegogo, and RocketHub) or the sharing economy (e.g. Uber, Airbnb, and Didi Chuxing). Since the sustainability of these IT-enabled forms of resource coordination do not commonly rely merely on direct economic benefits of the participants, but also on other non-monetary, intrinsic gratifications, such systems are increasingly gamified that is, designers use features of games to induce enjoyment and general autotelicy of the activity. However, a key problem in gamification design has been whether it is better to use competition-based or cooperation-based designs. We examine this question through a field experiment in a gamified crowdsourcing system, employing three versions of gamification: competitive, cooperative, and inter-team competitive gamification. We study these gamified conditions’ effects on users’ perceived enjoyment and usefulness of the system as well as on their behaviors (system usage, crowdsourcing participation, engagement with the gamification feature, and willingness to recommend the crowdsourcing application). The results reveal that inter-team competitions are most likely to lead to higher enjoyment and crowdsourcing participation, as well as to a higher willingness to recommending a system. Further, the findings indicate that designers should consider cooperative instead of competitive approaches to increase users’ willingness to recommend crowdsourcing systems. These insights add relevant findings to the ongoing discourse on the roles of different types of competitions in gamification designs and suggest that crowdsourcing system designers and operators should implement gamification with competing teams instead of typically used competitions between individuals.}
}
@article{CHAUDHRY2021107999,
title = {GCACS-IoD: A certificate based generic access control scheme for Internet of drones},
journal = {Computer Networks},
volume = {191},
pages = {107999},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.107999},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621001195},
author = {Shehzad Ashraf Chaudhry and Khalid Yahya and Marimuthu Karuppiah and Rupak Kharel and Ali Kashif Bashir and Yousaf Bin Zikria},
keywords = {IoD, UAV, Key establishment, Device access control, Stolen IoT device},
abstract = {Internet of drones (IoD) has gained significant importance in recent times due to its applications in several critical domains ranging from commercial to defense and rescue operations. With several drones flying in different zones to carry out specified tasks, the IoD can be beneficial to gather the real time data for interpretation by the users. However, the data access is carried out through an open channel and battery operated drones. Therefore, the drones’ security and privacy are crucial for accomplishing mission-critical, safety-critical, or surveillance operations. In 2020, Bera et al. presented a certificate based access control scheme for securing the IoD access and argued the scheme’s security through formal and informal methods. However, the analysis presented in this paper shows that the scheme of Bera et al. does not provide anonymity and is insecure against multiple threats, including drone impersonation, the man in the middle, and replay attacks. We then designed a generic certificate based access control scheme to provide inter-drone and drone to ground station access control/authentication in the IoD domain (GCACS-IoD). The GCACS-IoD is provably secure against the known attacks and provides anonymity. GCACS-IoD extends security while preserving computation and communication efficiencies.}
}
@article{POZZA2020100002,
title = {The science of Soil Security and Food Security},
journal = {Soil Security},
volume = {1},
pages = {100002},
year = {2020},
issn = {2667-0062},
doi = {https://doi.org/10.1016/j.soisec.2020.100002},
url = {https://www.sciencedirect.com/science/article/pii/S2667006220300022},
author = {Liana E. Pozza and Damien J. Field},
keywords = {Soil security, Food security, Nutrition, Soil management, Sustainability},
abstract = {There is a nexus of seven inter-linked global existential challenges; Soil Security and Food Security are two of these. The established concept of Food Security is well defined and researched, whereas the emerging concept of Soil Security is building its currency globally. Addressing Soil Security provides the means to improve food, fibre and water quality in a sustainable manner, through enhanced soil care and development of best land-management practices. Soil is a fragile resource which is degraded in many parts of the world. The rapidly growing global population has placed further pressure on the soil resource to accommodate increased demand for food, fibre and soil-derived materials. Such pressures are accelerating degradation and so novel approaches are needed. Literature search within this review demonstrated Soil Security and Food Security to be a convergence of disciplines. To truly identify solutions to challenges faced in either realm, an interdisciplinary approach seeking to understand deeper interactions between the two concepts is needed. Driven by this need, our review sought to investigate such interactions between the challenges faced in Soil Security and Food Security. Following assessment of these interactions, four potential solutions were discussed and included sustainable intensification and management, digital agriculture, circularisation and reducing the food demand trajectory through enhanced soil care. Soil Security and Food Security are interconnected concepts which will help facilitate implementation of the above solutions, and so approaches are needed which take this connection into account.}
}
@article{CUI2017250,
title = {A hierarchical combinatorial testing method for smart phone software in wearable IoT systems},
journal = {Computers & Electrical Engineering},
volume = {61},
pages = {250-265},
year = {2017},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2017.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0045790617316221},
author = {Kai Cui and Kuanjiu Zhou and Tie Qiu and Mingchu Li and Leiming Yan},
keywords = {Hierarchical combinatorial testing, User manipulation model, Semantic tree, Group state},
abstract = {As the Internet of Things technology is finding more wide applications; wearable smart systems such as smart phones have gradually come into our lives. The smart wearable systems with numerous states usually lead to various unanticipated problems. A connective and semantic similarity clustering algorithm (CSSCA) and a hierarchical combinatorial test model based on finite state machine (FSM) are proposed to solve the problem. The FSM model of user manipulations is usually used to model the system design specification of a smart phone for black-box testing, and then it is converted into a regular expression, and some testing cases are generated according to the regular expression. Many experiments show that a large in scale and complicated in structure smart phone software can be tested using our innovative algorithms to discover more deep hidden logical errors efficiently and effectively.}
}
@article{MILEVA2021102207,
title = {Comprehensive analysis of MQTT 5.0 susceptibility to network covert channels},
journal = {Computers & Security},
volume = {104},
pages = {102207},
year = {2021},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2021.102207},
url = {https://www.sciencedirect.com/science/article/pii/S0167404821000316},
author = {Aleksandra Mileva and Aleksandar Velinov and Laura Hartmann and Steffen Wendzel and Wojciech Mazurczyk},
keywords = {MQTT, Network covert channels, Network steganography, IoT steganography, Information hiding, Network security},
abstract = {Message Queuing Telemetry Transport (MQTT) is a publish-subscribe protocol which is currently popular in Internet of Things (IoT) applications. Recently its 5.0 version has been introduced and ensuring that it is capable of providing services in a secure manner is of great importance. It must be noted that holistic security analysis should also evaluate protocol’s susceptibility to network covert channels. That is why in this paper we present a systematic overview of potential data hiding techniques that can be applied to MQTT 5.0. We are especially focusing on network covert channels that, in order to exchange secrets, exploit characteristic features of this MQTT version. Finally, we develop proof-of-concept implementations of the chosen data hiding techniques and conduct their performance evaluation in order to assess their feasibility in practical setups.}
}
@article{DZIYAUDDIN2021108228,
title = {Computation offloading and content caching and delivery in Vehicular Edge Network: A survey},
journal = {Computer Networks},
volume = {197},
pages = {108228},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108228},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621002723},
author = {Rudzidatul Akmam Dziyauddin and Dusit Niyato and Nguyen Cong Luong and Ahmad Ariff Aizuddin {Mohd Atan} and Mohd Azri {Mohd Izhar} and Marwan Hadri Azmi and Salwani {Mohd Daud}},
keywords = {Vehicular edge network, Vehicular edge computing, Offloading, Caching, Delivery, Resource management},
abstract = {The past decade has witnessed the widespread adoption of Cloud Computing (CC) across automotive industries for a myriad of vehicular applications. A vehicular network that solely relies on CC, however, is susceptible to end-to-end latency due to the round-trip between data sources and cloud servers. Alternatively, the computing capability has been considered at the edge of vehicular network to achieve real-time analytics. Despite that, such consideration poses new questions on how data is offloaded and cached among the edge nodes and Autonomous Vehicles (AVs) in the environment of Vehicular Edge Network (VEN). In this paper, we outlined the aspects of VEN, particularly Vehicular Edge Computing (VEC), together with its architecture, layers, communications, and applications that are involved in the computation offloading (ComOf) and content caching and delivery (CachDel) scenarios. We extensively reviewed the existing approaches in solving ComOf and CachDel problems for the respective VEC architecture. The security aspect in ComOf and CachDel were critically discussed as well in the paper. Finally, we highlighted some key challenges, open issues, and future works of ComOf and CachDel in VEC.}
}
@article{KOCHOVSKI2019747,
title = {Trust management in a blockchain based fog computing platform with trustless smart oracles},
journal = {Future Generation Computer Systems},
volume = {101},
pages = {747-759},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19301281},
author = {Petar Kochovski and Sandi Gec and Vlado Stankovski and Marko Bajec and Pavel D. Drobintsev},
keywords = {Trust, Fog, Blockchain, Smart contract, Smart oracle},
abstract = {Trust is a crucial aspect when cyber-physical systems have to rely on resources and services under ownership of various entities, such as in the case of Edge, Fog and Cloud computing. The DECENTER’s Fog Computing Platform is developed to support Big Data pipelines, which start from the Internet of Things (IoT), such as cameras that provide video-streams for subsequent analysis. It is used to implement Artificial Intelligence (AI) algorithms across the Edge-Fog-Cloud computing continuum which provide benefits to applications, including high Quality of Service (QoS), improved privacy and security, lower operational costs and similar. In this article, we present a trust management architecture for DECENTER that relies on the use of blockchain-based Smart Contracts (SCs) and specifically designed trustless Smart Oracles. The architecture is implemented on Ethereum ledger (testnet) and three trust management scenarios are used for illustration. The scenarios (trust management for cameras, trusted data flow and QoS based computing node selection) are used to present the benefits of establishing trust relationships among entities, services and stakeholders of the platform.}
}
@article{DIVAN2021106871,
title = {Metadata-based measurements transmission verified by a Merkle Tree},
journal = {Knowledge-Based Systems},
volume = {219},
pages = {106871},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.106871},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121001349},
author = {Mario José Diván and María Laura Sánchez-Reynoso},
keywords = {Measurement, Metadata-guided transmission, Brief data message, Integrity record, Data streaming},
abstract = {The Data Stream Processing Strategy (DSPS) is focused on the automatization of measurement projects based on a measurement framework. The measurement adapter (MA) is an architecture component located on mobile devices aims to integrate heterogeneous data sources (i.e., sensors). The Gathering Function (GF) is the component responsible for interacting and receiving measures from the MAs, and it resides on the Stream Processing Engine (SPE). MA and GF share the project definition based on a measurement framework to foster data interoperability, while MA regulates the frequency, size, and route related to data transmission. As contributions (i) The brief data message is introduced to optimize the data transmission keeping immutable the hierarchical data organization based on the project definition, and (ii) The integrity record for mobile and SPE environments is described based on a Merkle Tree. This allows optimizing each data transaction, incorporating a historical integrity record both MA and SPE. The proposals and simulations have been implemented on the cincamimis, cincamipd, mair, and pabmmcommons libraries, which are freely available on GitHub under the terms of the Apache 2.0 licence. Four simulations are explained to detail how to measures were obtained. Interesting results show that the brief data message consumes 17.50 KB to transmit 1000 measures (2.4 times smaller than JSON), while a message with 200 measures could be generated and compressed using GZIP in 25.12 ms (2.43 times faster than JSON). 196 KB is required to keep 17 min of the integrity history in a MA, being created in 4.85 ms.}
}
@article{MORATO201814,
title = {Ransomware early detection by the analysis of file sharing traffic},
journal = {Journal of Network and Computer Applications},
volume = {124},
pages = {14-32},
year = {2018},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2018.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S108480451830300X},
author = {Daniel Morato and Eduardo Berrueta and Eduardo Magaña and Mikel Izal},
keywords = {Ransomware, Malware detection, Traffic analysis, Network security},
abstract = {Crypto ransomware is a type of malware that locks access to user files by encrypting them and demands a ransom in order to obtain the decryption key. This type of malware has become a serious threat for most enterprises. In those cases where the infected computer has access to documents in network shared volumes, a single host can lock access to documents across several departments in the company. We propose an algorithm that can detect ransomware action and prevent further activity over shared documents. The algorithm is based on the analysis of passively monitored traffic by a network probe. 19 different ransomware families were used for testing the algorithm in action. The results show that it can detect ransomware activity in less than 20 s, before more than 10 files are lost. Recovery of even those files was also possible because their content was stored in the traffic monitored by the network probe. Several days of traffic from real corporate networks were used to validate a low rate of false alarms. This paper offers also analytical models for the probability of early detection and the probability of false alarms for an arbitrarily large population of users.}
}
@article{GU2021102522,
title = {Strategic sourcing selection for bike-sharing rebalancing: An evolutionary game approach},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {156},
pages = {102522},
year = {2021},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2021.102522},
url = {https://www.sciencedirect.com/science/article/pii/S1366554521002829},
author = {Wei Gu and Meng Li and Chen Wang and Jennifer Shang and Lirong Wei},
keywords = {Reverse logistics, Evolutionary game theory, Bike-sharing systems, Sourcing strategy},
abstract = {Bike-sharing systems (BSSs) offer convenient transportation services with environmental and social benefits. However, they also bring operational complexity, with rebalancing bikes being a very challenging one. The importance and difficulty of building the reverse logistics for BSSs are evident from the data obtained from Mobike, one of the largest dockless bike-sharing platforms in China. This paper proposes an evolutionary game theoretic approach to identify the best bike-sharing sourcing strategies, including self-operation, joint venture, and outsourcing. We show that the self-operation mode is an evolutionary stable strategy to rebalance Mobike. However, if bike-sharing firms cannot achieve economies of scale and significantly reduce the variable costs of the self-operation mode, the outsourcing mode will become the optimal choice. From a long-term perspective, the joint venture mode is never an attractive strategy for the bike-sharing firms under study. Our model can select the optimal sourcing strategy to rebalance bikes in BSS to maximize profit when competition and cooperation are jointly considered.}
}
@article{ZHENG2020117775,
title = {Electricity plan recommender system with electrical instruction-based recovery},
journal = {Energy},
volume = {203},
pages = {117775},
year = {2020},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2020.117775},
url = {https://www.sciencedirect.com/science/article/pii/S0360544220308823},
author = {Junjie Zheng and Chun Sing Lai and Haoliang Yuan and Zhao Yang Dong and Ke Meng and Loi Lei Lai},
keywords = {Matrix recovery, Low-rank recovery, Electricity plan recommender system},
abstract = {Several electricity tariffs have emerged for Demand Side Management (DSM) and residential customers are faced with challenges to choose the plan satisfying their personal needs. Electricity Plan Recommender System (EPRS) can alleviate the problem. This paper proposes a novel EPRS model named EPRS with Electrical Instruction-based Recovery (EPRS-EI), which is a dual-stage model consisting of feature formulation stage and recommender stage. In the feature formulation stage, matrix recovery with electrical instructions is applied to recover appliance usages, and the recovered data is set as features representing customers’ living patterns. In the recommender stage, Collaborative Filtering Recommender System (CFRS) based on K-Nearest Neighbors (KNN) and adjusted similarity is applied to recommend personal electricity plans to customers based on the above features. Different from other EPRS models, EPRS-EI is the first model utilizing matrix recovery methods and similarity computation with electrical instructions. With these electrical instructions, the proposed model is able to utilize more explicit features and recommend more personalized plans. We then apply EPRS-EI to predict the testing customers’ preference for electricity plans. Simulation results on recovering electricity data and their applications in EPRS confirm the effectiveness of the proposed methods in comparison to state-of-the-art methods, with 93.56%–94.85% customers correctly recommended.}
}
@article{CASINI20201269,
title = {A positive energy building for the Middle East climate: ReStart4Smart Solar House at Solar Decathlon Middle East 2018},
journal = {Renewable Energy},
volume = {159},
pages = {1269-1296},
year = {2020},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2020.06.055},
url = {https://www.sciencedirect.com/science/article/pii/S0960148120309654},
author = {Marco Casini},
keywords = {Solar decathlon, Positive energy building, Smart home, Building energy strategies, Building energy simulation, Arab architecture},
abstract = {The city of Dubai (UAE), in accordance with its program of transformation into one of the most smart and sustainable cities, hosted the 2018 edition of Solar Decathlon, the first in the Middle East (SDME 2018). The harsh climate of UAE, along with the booming construction industry and energy consumptions and CO2 emissions among the world’s highest, tasked participating university teams to find innovative solutions able to drive the region building sector towards a more sustainable future. Sapienza University of Rome participated, representing Italy, to SDME 2018 with the project ReStart4Smart, a full scale prototype of a single family energy positive smart home specifically designed for the Middle East climate and fully consistent with the Arab culture. This article examines the ReStart4Smart project in terms of energy strategies, architectural concept and technological solutions adopted, in order to verify, through a detailed analysis of energy simulations and monitoring carried out on the prototype built in Dubai, the expected performance levels. Results achieved demonstrate how the Restart4 Smart project represents, consistently with the Arab tradition, a valid proposal for zero-energy intelligent housing, perfectly responsive to the social demand emerging from the populations of the Middle East.}
}
@article{KAMIENSKI20171,
title = {Application development for the Internet of Things: A context-aware mixed criticality systems development platform},
journal = {Computer Communications},
volume = {104},
pages = {1-16},
year = {2017},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2016.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0140366416303863},
author = {Carlos Kamienski and Marc Jentsch and Markus Eisenhauer and Jussi Kiljander and Enrico Ferrera and Peter Rosengren and Jesper Thestrup and Eduardo Souto and Walter S. Andrade and Djamel Sadok},
keywords = {Internet of Things, System development platform, Smart building, Context-aware management, Mixed–criticality systems, Energy-efficiency management},
abstract = {The Internet of Things (IoT) is gaining momentum and may positively influence the automation of energy-efficiency management of smart buildings. However, the development of IoT-enabled applications still takes tremendous efforts due to the lack of proper tools. Many software components have to be developed from scratch, thus requiring huge amounts of effort, as developers must have a deep understanding of the technologies, the new application domain, and the interplay with legacy systems. In this paper we introduce the IMPReSS Systems Development Platform (SDP) that aims at reducing the complexity of developing IoT-enabled applications for supporting sensor data collection in buildings, managing automated system changes according to the context, and real-time prioritization of devices for controlling energy usage. The effectiveness of the SDP for the development of IoT-based context-aware and mixed-criticality applications was assessed by using it in four scenarios involving energy efficiency management in public buildings. Qualitative studies were undertaken with application developers in order to evaluate their perception of five key components of the SDP with regard to usability. The study revealed significant and encouraging results. Further, a quantitative performance analysis explored the scalability limits of the IMPReSS communication components.}
}
@article{ZENG20201028,
title = {A survey: Cyber-physical-social systems and their system-level design methodology},
journal = {Future Generation Computer Systems},
volume = {105},
pages = {1028-1042},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.06.034},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X1630228X},
author = {Jing Zeng and Laurence T. Yang and Man Lin and Huansheng Ning and Jianhua Ma},
keywords = {Cyber-physical-social systems, System-level design, Design methodology},
abstract = {The emergence of cyber-physical-social systems (CPSS) as a novel paradigm has revolutionized the relationship between humans, computers and the physical environment. In this paper, we survey the advancement of CPSS through cyber-physical systems (CPS), cyber-social ​systems (CSS) and CPSS, as well as related techniques. CPSS are still at their infancy, most recent studies are application-specific and lack of systematic design methodology. To exploit the design methodology for CPSS, we review the existing system-level design methodologies in multiple application domains and further compare their performance characteristics and applicability for CPSS. Finally, we introduce our latest research advancement on system-level design methodology for CPSS and summarize future challenges for designing CPSS.}
}
@article{HINZE2022100225,
title = {Wearable technology for hazardous remote environments: Smart shirt and Rugged IoT network for forestry worker health},
journal = {Smart Health},
volume = {23},
pages = {100225},
year = {2022},
issn = {2352-6483},
doi = {https://doi.org/10.1016/j.smhl.2021.100225},
url = {https://www.sciencedirect.com/science/article/pii/S2352648321000465},
author = {A. Hinze and J. Bowen and J.L. König},
keywords = {IoT network, Wearable technology, Mobile health technology, Streaming data, Rule-based system, Data sovereignty},
abstract = {This paper introduces the architecture and details of our wearable IoT solution for workplace health and safety in rugged outdoor environments. We focus on the specific requirements defined by the New Zealand forestry environment as it is the industry with the most fatalities and highest accident rate in New Zealand. Neither consumer-level products nor professional wearables have been found to be suitable for forestry conditions. Furthermore, forestry workplaces cannot rely on existing networking infrastructure, and due to their remote and rugged nature, no permanent setup is possible. We describe the Hakituri project in which we integrate wearable devices, networking, data analytics, and a buddy system into a novel monitoring solution for worker health and safety. Our wearable IoT solution includes a dynamic network set-up, wearables suitable for forestry conditions, contextual rule-based data analytics, and real-time alerts. A wearable smart shirt carries sensors for collecting personal data from forestry workers, while further environmental sensors capture contextual data. The IoT network is set up for communication in unreliable and rugged outdoor environments. We explore a variety of setups to achieve the best quality outcomes for health and safety in the forestry domain.}
}
@article{BORKAR2019120,
title = {A novel clustering approach and adaptive SVM classifier for intrusion detection in WSN: A data mining concept},
journal = {Sustainable Computing: Informatics and Systems},
volume = {23},
pages = {120-135},
year = {2019},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2019.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S2210537918303196},
author = {Gautam M. Borkar and Leena H. Patil and Dilip Dalgade and Ankush Hutke},
keywords = {Wireless sensor network (WSN), Intrusion detection system (IDS), Security, Chicken swarm optimization (CSO), Rotated random forest (RRF), Support vector machine (SVM), Clustering, High–level security},
abstract = {Nowadays Wireless Sensor Network (WSN) mainly faces security issue during packet transmission between different sensor nodes in network combined with data mining. To overcome this challenge an efficient clustering technique called adaptive chicken swarm optimization algorithm is proposed for cluster head (CH) selection. By this adaptive method the time consumption is reduced to a greater extend along with that the lifetime of the network and the scalability is improved alternatively. Additionally a two stage classification technique known as adaptive SVM classification a supervised learning technique is proposed with Intrusion Detection System (IDS) where an acknowledgement based method is utilized for reporting the malicious sensor nodes. By this acknowledgement different types of attacks such as DOS, probe, U2R, R2L are detected incorporation with Intrusion Detection System (IDS). Once detected a high level security mechanism along with intrusion response is provided to other sensor nodes by which a secure packet transmission occurs between different sensor nodes. The proposed methodology is implemented in python platform and the comparison results provided with existing methods proves a better result.}
}
@article{ALSHAYEA2019106813,
title = {A hybridized methodology of different wavelet transformations targeting medical images in IoT infrastructure},
journal = {Measurement},
volume = {148},
pages = {106813},
year = {2019},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2019.07.041},
url = {https://www.sciencedirect.com/science/article/pii/S0263224119306700},
author = {Tamara K. Al-Shayea and Constandinos X. Mavromoustakis and Jordi Mongay Batalla and George Mastorakis},
keywords = {Medical image watermarking, Biorthogonal wavelet, Reverse biorthogonal wavelet, Discrete meyer wavelet, Symlets wavelet, Coiflets wavelet},
abstract = {The Internet of Things (IoT) paradigm has become a vital part of all significant scientific sectors, including the healthcare domain. Medical images in the healthcare sector are indispensable items that are usually susceptible to distortion once they are shared and transferred via the Internet. The sector faces the distinct and constant challenge of preserving medical data, which can be manipulated by various malicious attacks, in turn potentially compromising the patients’ diagnostic data. In this situation, such medical data ought to be private, with access only granted to patients and physicians. This paper elaborates on a hybrid measurement technique for digital image watermarking that utilizes medical images (X-ray, MRA, and CT), which are an extremely robust method for protecting clinical information. The authors explore various different wavelet families, in addition to hybridization between these wavelets. These are carried out on three levels decomposition of Discrete wavelet transformation (biorthogonal 6.8 wavelets, biorthogonal 3.5 wavelets, biorthogonal 5.5 wavelets, reverse biorthogonal 6.8, reverse biorthogonal 3.5, reverse biorthogonal 5.5, discrete meyer, symlets 5, symlets 8 coiflets 4 wavelet, and coiflets 5 wavelet transform). Each level uses various types of wavelet transformation to present the watermarked image, and then extracts the medical watermark from the original watermarked image. The results of diverse types of attack have been compared, while the proposed measurement technique's performance is evaluated using statistical parameters (MSE, PSNR, SSIM, and NC). This in turn measures the quality of the image, which so far shows promising results.}
}
@article{SINGHAL2021106126,
title = {One-dollar microfluidic paper-based analytical devices: Do-It-Yourself approaches},
journal = {Microchemical Journal},
volume = {165},
pages = {106126},
year = {2021},
issn = {0026-265X},
doi = {https://doi.org/10.1016/j.microc.2021.106126},
url = {https://www.sciencedirect.com/science/article/pii/S0026265X21002101},
author = {Hardik Ramesh Singhal and Anusha Prabhu and M.S. {Giri Nandagopal} and Thangaraju Dheivasigamani and Naresh Kumar Mani},
keywords = {Analytical devices, Do-It-Yourself, Microfluidics, Paper-based, Stationeries},
abstract = {Paper-based devices for an analytical application have gained great interest among researchers due to their portability, versatility and facile interpretation. The popularity of these analytical devices is supplemented by their myriad of applications, in point-of-care health systems, environmental monitoring and food safety. However, relatively sophisticated manufacturing techniques used to create complex multiplexed systems, pose barrier between the widespread adoption of the such methods in low-cost settings. Recently, researchers have taken significant efforts towards the development of paper-based analytical devices with more emphasis on novel fabrication approaches costing <1$. Such an approach was achieved by implementing Do-It-Yourself (DIY) path by employing readily available stationaries for fabrication. Here in this review, we categorise such Do-It-Yourself (DIY) approaches and explore their further developments and challenges. Moreover, we discuss the use of various low cost or off-the-shelf equipments for the fabrication of (i) hydrophobic barriers on plain paper (ii) electrodes in detection devices, and (iii) devices porting old detection techniques on to more DIY friendly housings. Additionally, this paper also explores amalgamation of multiple DIY fabrication methods, emerging trends and prospects in the past five years.}
}
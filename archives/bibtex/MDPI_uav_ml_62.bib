
@Article{aerospace8050125,
AUTHOR = {Shauqee, Mohamad Norherman and Rajendran, Parvathy and Suhadis, Nurulasikin Mohd},
TITLE = {An Explosion Based Algorithm to Solve the Optimization Problem in Quadcopter Control},
JOURNAL = {Aerospace},
VOLUME = {8},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {125},
URL = {https://www.mdpi.com/2226-4310/8/5/125},
ISSN = {2226-4310},
ABSTRACT = {This paper presents an optimization algorithm named Random Explosion Algorithm (REA). The fundamental idea of this algorithm is based on a simple concept of the explosion of an object. This object is commonly known as a particle: when exploded, it will randomly disperse fragments around the particle within the explosion radius. The fragment that will be considered as a search agent will fill the local space and search that particular region for the best fitness solution. The proposed algorithm was tested on 23 benchmark test functions, and the results are validated by a comparative study with eight well-known algorithms, which are Particle Swarm Optimization (PSO), Artificial Bee Colony (ABC), Genetic Algorithm (GA), Differential Evolution (DE), Multi-Verse Optimizer (MVO), Moth Flame Optimizer (MFO), Firefly Algorithm (FA), and Sooty Tern Optimization Algorithm (STOA). After that, the algorithm was implemented and analyzed for a quadrotor control application. Similarly, a comparative study with the other algorithms stated was done. The findings reveal that the REA can yield very competitive results. It also shows that the convergence analysis has proved that the REA can converge more quickly toward the global optimum than the other metaheuristic algorithms. For the control application result, the REA controller can better track the desired reference input with shorter rise time and settling time, lower percentage overshoot, and minimal steady-state error and root mean square error (RMSE).},
DOI = {10.3390/aerospace8050125}
}



@Article{ani11051263,
AUTHOR = {Wang, Zhaojun and Wang, Jiangning and Lin, Congtian and Han, Yan and Wang, Zhaosheng and Ji, Liqiang},
TITLE = {Identifying Habitat Elements from Bird Images Using Deep Convolutional Neural Networks},
JOURNAL = {Animals},
VOLUME = {11},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {1263},
URL = {https://www.mdpi.com/2076-2615/11/5/1263},
PubMedID = {33925654},
ISSN = {2076-2615},
ABSTRACT = {With the rapid development of digital technology, bird images have become an important part of ornithology research data. However, due to the rapid growth of bird image data, it has become a major challenge to effectively process such a large amount of data. In recent years, deep convolutional neural networks (DCNNs) have shown great potential and effectiveness in a variety of tasks regarding the automatic processing of bird images. However, no research has been conducted on the recognition of habitat elements in bird images, which is of great help when extracting habitat information from bird images. Here, we demonstrate the recognition of habitat elements using four DCNN models trained end-to-end directly based on images. To carry out this research, an image database called Habitat Elements of Bird Images (HEOBs-10) and composed of 10 categories of habitat elements was built, making future benchmarks and evaluations possible. Experiments showed that good results can be obtained by all the tested models. ResNet-152-based models yielded the best test accuracy rate (95.52%); the AlexNet-based model yielded the lowest test accuracy rate (89.48%). We conclude that DCNNs could be efficient and useful for automatically identifying habitat elements from bird images, and we believe that the practical application of this technology will be helpful for studying the relationships between birds and habitat elements.},
DOI = {10.3390/ani11051263}
}



@Article{rs13091704,
AUTHOR = {de Camargo, Tibor and Schirrmann, Michael and Landwehr, Niels and Dammer, Karl-Heinz and Pflanz, Michael},
TITLE = {Optimized Deep Learning Model as a Basis for Fast UAV Mapping of Weed Species in Winter Wheat Crops},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1704},
URL = {https://www.mdpi.com/2072-4292/13/9/1704},
ISSN = {2072-4292},
ABSTRACT = {Weed maps should be available quickly, reliably, and with high detail to be useful for site-specific management in crop protection and to promote more sustainable agriculture by reducing pesticide use. Here, the optimization of a deep residual convolutional neural network (ResNet-18) for the classification of weed and crop plants in UAV imagery is proposed. The target was to reach sufficient performance on an embedded system by maintaining the same features of the ResNet-18 model as a basis for fast UAV mapping. This would enable online recognition and subsequent mapping of weeds during UAV flying operation. Optimization was achieved mainly by avoiding redundant computations that arise when a classification model is applied on overlapping tiles in a larger input image. The model was trained and tested with imagery obtained from a UAV flight campaign at low altitude over a winter wheat field, and classification was performed on species level with the weed species Matricaria chamomilla L., Papaver rhoeas L., Veronica hederifolia L., and Viola arvensis ssp. arvensis observed in that field. The ResNet-18 model with the optimized image-level prediction pipeline reached a performance of 2.2 frames per second with an NVIDIA Jetson AGX Xavier on the full resolution UAV image, which would amount to about 1.78 ha h−1 area output for continuous field mapping. The overall accuracy for determining crop, soil, and weed species was 94%. There were some limitations in the detection of species unknown to the model. When shifting from 16-bit to 32-bit model precision, no improvement in classification accuracy was observed, but a strong decline in speed performance, especially when a higher number of filters was used in the ResNet-18 model. Future work should be directed towards the integration of the mapping process on UAV platforms, guiding UAVs autonomously for mapping purpose, and ensuring the transferability of the models to other crop fields.},
DOI = {10.3390/rs13091704}
}



@Article{f12050550,
AUTHOR = {Xu, Dandan and Wang, Haobin and Xu, Weixin and Luan, Zhaoqing and Xu, Xia},
TITLE = {LiDAR Applications to Estimate Forest Biomass at Individual Tree Scale: Opportunities, Challenges and Future Perspectives},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {550},
URL = {https://www.mdpi.com/1999-4907/12/5/550},
ISSN = {1999-4907},
ABSTRACT = {Accurate forest biomass estimation at the individual tree scale is the foundation of timber industry and forest management. It plays an important role in explaining ecological issues and small-scale processes. Remotely sensed images, across a range of spatial and temporal resolutions, with their advantages of non-destructive monitoring, are widely applied in forest biomass monitoring at global, ecoregion or community scales. However, the development of remote sensing applications for forest biomass at the individual tree scale has been relatively slow due to the constraints of spatial resolution and evaluation accuracy of remotely sensed data. With the improvements in platforms and spatial resolutions, as well as the development of remote sensing techniques, the potential for forest biomass estimation at the single tree level has been demonstrated. However, a comprehensive review of remote sensing of forest biomass scaled at individual trees has not been done. This review highlights the theoretical bases, challenges and future perspectives for Light Detection and Ranging (LiDAR) applications of individual trees scaled to whole forests. We summarize research on estimating individual tree volume and aboveground biomass (AGB) using Terrestrial Laser Scanning (TLS), Airborne Laser Scanning (ALS), Unmanned Aerial Vehicle Laser Scanning (UAV-LS) and Mobile Laser Scanning (MLS, including Vehicle-borne Laser Scanning (VLS) and Backpack Laser Scanning (BLS)) data.},
DOI = {10.3390/f12050550}
}



@Article{rs13091723,
AUTHOR = {Kuzmin, Anton and Korhonen, Lauri and Kivinen, Sonja and Hurskainen, Pekka and Korpelainen, Pasi and Tanhuanpää, Topi and Maltamo, Matti and Vihervaara, Petteri and Kumpula, Timo},
TITLE = {Detection of European Aspen (Populus tremula L.) Based on an Unmanned Aerial Vehicle Approach in Boreal Forests},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1723},
URL = {https://www.mdpi.com/2072-4292/13/9/1723},
ISSN = {2072-4292},
ABSTRACT = {European aspen (Populus tremula L.) is a keystone species for biodiversity of boreal forests. Large-diameter aspens maintain the diversity of hundreds of species, many of which are threatened in Fennoscandia. Due to a low economic value and relatively sparse and scattered occurrence of aspen in boreal forests, there is a lack of information of the spatial and temporal distribution of aspen, which hampers efficient planning and implementation of sustainable forest management practices and conservation efforts. Our objective was to assess identification of European aspen at the individual tree level in a southern boreal forest using high-resolution photogrammetric point cloud (PPC) and multispectral (MSP) orthomosaics acquired with an unmanned aerial vehicle (UAV). The structure-from-motion approach was applied to generate RGB imagery-based PPC to be used for individual tree-crown delineation. Multispectral data were collected using two UAV cameras: Parrot Sequoia and MicaSense RedEdge-M. Tree-crown outlines were obtained from watershed segmentation of PPC data and intersected with multispectral mosaics to extract and calculate spectral metrics for individual trees. We assessed the role of spectral data features extracted from PPC and multispectral mosaics and a combination of it, using a machine learning classifier—Support Vector Machine (SVM) to perform two different classifications: discrimination of aspen from the other species combined into one class and classification of all four species (aspen, birch, pine, spruce) simultaneously. In the first scenario, the highest classification accuracy of 84% (F1-score) for aspen and overall accuracy of 90.1% was achieved using only RGB features from PPC, whereas in the second scenario, the highest classification accuracy of 86 % (F1-score) for aspen and overall accuracy of 83.3% was achieved using the combination of RGB and MSP features. The proposed method provides a new possibility for the rapid assessment of aspen occurrence to enable more efficient forest management as well as contribute to biodiversity monitoring and conservation efforts in boreal forests.},
DOI = {10.3390/rs13091723}
}



@Article{rs13091741,
AUTHOR = {Hobley, Brandon and Arosio, Riccardo and French, Geoffrey and Bremner, Julie and Dolphin, Tony and Mackiewicz, Michal},
TITLE = {Semi-Supervised Segmentation for Coastal Monitoring Seagrass Using RPA Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1741},
URL = {https://www.mdpi.com/2072-4292/13/9/1741},
ISSN = {2072-4292},
ABSTRACT = {Intertidal seagrass plays a vital role in estimating the overall health and dynamics of coastal environments due to its interaction with tidal changes. However, most seagrass habitats around the globe have been in steady decline due to human impacts, disturbing the already delicate balance in the environmental conditions that sustain seagrass. Miniaturization of multi-spectral sensors has facilitated very high resolution mapping of seagrass meadows, which significantly improves the potential for ecologists to monitor changes. In this study, two analytical approaches used for classifying intertidal seagrass habitats are compared—Object-based Image Analysis (OBIA) and Fully Convolutional Neural Networks (FCNNs). Both methods produce pixel-wise classifications in order to create segmented maps. FCNNs are an emerging set of algorithms within Deep Learning. Conversely, OBIA has been a prominent solution within this field, with many studies leveraging in-situ data and multiresolution segmentation to create habitat maps. This work demonstrates the utility of FCNNs in a semi-supervised setting to map seagrass and other coastal features from an optical drone survey conducted at Budle Bay, Northumberland, England. Semi-supervision is also an emerging field within Deep Learning that has practical benefits of achieving state of the art results using only subsets of labelled data. This is especially beneficial for remote sensing applications where in-situ data is an expensive commodity. For our results, we show that FCNNs have comparable performance with the standard OBIA method used by ecologists.},
DOI = {10.3390/rs13091741}
}



@Article{s21093152,
AUTHOR = {Liang, Peng and Shi, Wenzhong and Ding, Yixing and Liu, Zhiqiang and Shang, Haolv},
TITLE = {Road Extraction from High Resolution Remote Sensing Images Based on Vector Field Learning},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {3152},
URL = {https://www.mdpi.com/1424-8220/21/9/3152},
PubMedID = {34062917},
ISSN = {1424-8220},
ABSTRACT = {Accurate and up-to-date road network information is very important for the Geographic Information System (GIS) database, traffic management and planning, automatic vehicle navigation, emergency response and urban pollution sources investigation. In this paper, we use vector field learning to extract roads from high resolution remote sensing imaging. This method is usually used for skeleton extraction in nature image, but seldom used in road extraction. In order to improve the accuracy of road extraction, three vector fields are constructed and combined respectively with the normal road mask learning by a two-task network. The results show that all the vector fields are able to significantly improve the accuracy of road extraction, no matter the field is constructed in the road area or completely outside the road. The highest F1 score is 0.7618, increased by 0.053 compared with using only mask learning.},
DOI = {10.3390/s21093152}
}



@Article{rs13091776,
AUTHOR = {Geng, Xiurui and Wang, Lei and Ji, Luyan},
TITLE = {Identify Informative Bands for Hyperspectral Target Detection Using the Third-Order Statistic},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1776},
URL = {https://www.mdpi.com/2072-4292/13/9/1776},
ISSN = {2072-4292},
ABSTRACT = {Constrained energy minimization (CEM) has been proposed and widely researched in the field of hyperspectral target detection. Generally, it selects one of the target spectra as the representative and then keeps its output constant while minimizing the average filter output energy of the data. However, it has been proven that as the number of bands (L) increases, CEM will gradually lower the average filter output energy when keeping the representative’s output constant. Unavoidably, due to the inherent spatial and temporal variation of the spectra, this will lead to an unreasonable phenomenon, i.e., if L is particularly large, when adding more bands, CEM will suppress more and more pixels, even including the target pixels. This means that the optimal solution of CEM may not correspond to the target detection result that we desire. To deal with this, in this paper, we introduce the third-order statistic (skewness) of the CEM model, served as an auxiliary index to determine whether a band is beneficial to target detection or not. Theoretically, we prove that the skewness index can always exclude the noisy bands with Gaussian distribution. In addition, experiments on several widely used remote sensing data indicate that the index can also efficiently identify informative bands for a better target detection performance.},
DOI = {10.3390/rs13091776}
}



@Article{rs13091792,
AUTHOR = {Wang, Li and Chen, Shuisen and Peng, Zhiping and Huang, Jichuan and Wang, Chongyang and Jiang, Hao and Zheng, Qiong and Li, Dan},
TITLE = {Phenology Effects on Physically Based Estimation of Paddy Rice Canopy Traits from UAV Hyperspectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1792},
URL = {https://www.mdpi.com/2072-4292/13/9/1792},
ISSN = {2072-4292},
ABSTRACT = {Radiation transform models such as PROSAIL are widely used for crop canopy reflectance simulation and biophysical parameter inversion. The PROSAIL model basically assumes that the canopy is turbid homogenous media with a bare soil background. However, the canopy structure changes when crop growth stages develop, which is more or less a departure from this assumption. In addition, a paddy rice field is inundated most of the time with flooded soil background. In this study, field-scale paddy rice leaf area index (LAI), leaf cholorphyll content (LCC), and canopy chlorophyll content (CCC) were retrieved from unmanned-aerial-vehicle-based hyperspectral images by the PROSAIL radiation transform model using a lookup table (LUT) strategy, with a special focus on the effects of growth-stage development and soil-background signature selection. Results show that involving flooded soil reflectance as background reflectance for PROSAIL could improve estimation accuracy. When using a LUT with the flooded soil reflectance signature (LUTflooded) the coefficients of determination (R2) between observed and estimation variables are 0.70, 0.11, and 0.79 for LAI, LCC, and CCC, respectively, for the entire growing season (from tillering to heading growth stages), and the corresponding mean absolute errors (MAEs) are 21.87%, 16.27%, and 12.52%. For LAI and LCC, high model bias mainly occurred in tillering growth stages. There is an obvious overestimation of LAI and underestimation of LCC for in the tillering growth stage. The estimation accuracy of CCC is relatively consistent from tillering to heading growth stages.},
DOI = {10.3390/rs13091792}
}



@Article{rs13091809,
AUTHOR = {Feroz, Sainab and Abu Dabous, Saleh},
TITLE = {UAV-Based Remote Sensing Applications for Bridge Condition Assessment},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1809},
URL = {https://www.mdpi.com/2072-4292/13/9/1809},
ISSN = {2072-4292},
ABSTRACT = {Deterioration of bridge infrastructure is a serious concern to transport and government agencies as it declines serviceability and reliability of bridges and jeopardizes public safety. Maintenance and rehabilitation needs of bridge infrastructure are periodically monitored and assessed, typically every two years. Existing inspection techniques, such as visual inspection, are time-consuming, subjective, and often incomplete. Non-destructive testing (NDT) using Unmanned Aerial Vehicles (UAVs) have been gaining momentum for bridge monitoring in the recent years, particularly due to enhanced accessibility and cost efficiency, deterrence of traffic closure, and improved safety during inspection. The primary objective of this study is to conduct a comprehensive review of the application of UAVs in bridge condition monitoring, used in conjunction with remote sensing technologies. Remote sensing technologies such as visual imagery, infrared thermography, LiDAR, and other sensors, integrated with UAVs for data acquisition are analyzed in depth. This study compiled sixty-five journal and conference papers published in the last two decades scrutinizing NDT-based UAV systems. In addition to comparison of stand-alone and integrated NDT-UAV methods, the facilitation of bridge inspection using UAVs is thoroughly discussed in the present article in terms of ease of use, accuracy, cost-efficiency, employed data collection tools, and simulation platforms. Additionally, challenges and future perspectives of the reviewed UAV-NDT technologies are highlighted.},
DOI = {10.3390/rs13091809}
}



@Article{agriculture11050420,
AUTHOR = {Chen, Shuo and Zhang, Kefei and Zhao, Yindi and Sun, Yaqin and Ban, Wei and Chen, Yu and Zhuang, Huifu and Zhang, Xuewei and Liu, Jinxiang and Yang, Tao},
TITLE = {An Approach for Rice Bacterial Leaf Streak Disease Segmentation and Disease Severity Estimation},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {420},
URL = {https://www.mdpi.com/2077-0472/11/5/420},
ISSN = {2077-0472},
ABSTRACT = {Rice bacterial leaf streak (BLS) is a serious disease in rice leaves and can seriously affect the quality and quantity of rice growth. Automatic estimation of disease severity is a crucial requirement in agricultural production. To address this, a new method (termed BLSNet) was proposed for rice and BLS leaf lesion recognition and segmentation based on a UNet network in semantic segmentation. An attention mechanism and multi-scale extraction integration were used in BLSNet to improve the accuracy of lesion segmentation. We compared the performance of the proposed network with that of DeepLabv3+ and UNet as benchmark models used in semantic segmentation. It was found that the proposed BLSNet model demonstrated higher segmentation and class accuracy. A preliminary investigation of BLS disease severity estimation was carried out based on our BLS segmentation results, and it was found that the proposed BLSNet method has strong potential to be a reliable automatic estimator of BLS disease severity.},
DOI = {10.3390/agriculture11050420}
}



@Article{drones5020035,
AUTHOR = {Bollas, Nikolaos and Kokinou, Eleni and Polychronos, Vassilios},
TITLE = {Comparison of Sentinel-2 and UAV Multispectral Data for Use in Precision Agriculture: An Application from Northern Greece},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {35},
URL = {https://www.mdpi.com/2504-446X/5/2/35},
ISSN = {2504-446X},
ABSTRACT = {The scope of this work is to compare Sentinel-2 and unmanned aerial vehicles (UAV) imagery from northern Greece for use in precision agriculture by implementing statistical analysis and 2D visualization. Surveys took place on five dates with a difference between the sensing dates for the two techniques ranging from 1 to 4 days. Using the acquired images, we initially computed the maps of the Normalized Difference Vegetation Index (NDVI), then the values of this index for fifteen points and four polygons (areas). The UAV images were not resampled, aiming to compare both techniques based on their initial standards, as they are used by the farmers. Similarities between the two techniques are depicted on the trend of the NDVI means for both satellite and UAV techniques, considering the points and the polygons. The differences are in the a) mean NDVI values of the points and b) range of the NDVI values of the polygons probably because of the difference in the spatial resolution of the two techniques. The correlation coefficient of the NDVI values, considering both points and polygons, ranges between 83.5% and 98.26%. In conclusion, both techniques provide important information in precision agriculture depending on the spatial extent, resolution, and cost, as well as the requirements of the survey.},
DOI = {10.3390/drones5020035}
}



@Article{s21093262,
AUTHOR = {Mahmud, Md Sultan and Zahid, Azlan and He, Long and Martin, Phillip},
TITLE = {Opportunities and Possibilities of Developing an Advanced Precision Spraying System for Tree Fruits},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {3262},
URL = {https://www.mdpi.com/1424-8220/21/9/3262},
PubMedID = {34066785},
ISSN = {1424-8220},
ABSTRACT = {Reducing risk from pesticide applications has been gaining serious attention in the last few decades due to the significant damage to human health, environment, and ecosystems. Pesticide applications are an essential part of current agriculture, enhancing cultivated crop productivity and quality and preventing losses of up to 45% of the world food supply. However, inappropriate and excessive use of pesticides is a major rising concern. Precision spraying addresses these concerns by precisely and efficiently applying pesticides to the target area and substantially reducing pesticide usage while maintaining efficacy at preventing crop losses. This review provides a systematic summary of current technologies used for precision spraying in tree fruits and highlights their potential, briefly discusses factors affecting spraying parameters, and concludes with possible solutions to reduce excessive agrochemical uses. We conclude there is a critical need for appropriate sensing techniques that can accurately detect the target. In addition, air jet velocity, travel speed, wind speed and direction, droplet size, and canopy characteristics need to be considered for successful droplet deposition by the spraying system. Assessment of terrain is important when field elevation has significant variability. Control of airflow during spraying is another important parameter that needs to be considered. Incorporation of these variables in precision spraying systems will optimize spray decisions and help reduce excessive agrochemical applications.},
DOI = {10.3390/s21093262}
}



@Article{rs13091853,
AUTHOR = {Jin, Xing and Tang, Ping and Zhang, Zheng},
TITLE = {Sequence Image Datasets Construction via Deep Convolution Networks},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1853},
URL = {https://www.mdpi.com/2072-4292/13/9/1853},
ISSN = {2072-4292},
ABSTRACT = {Remote-sensing time-series datasets are significant for global change research and a better understanding of the Earth. However, remote-sensing acquisitions often provide sparse time series due to sensor resolution limitations and environmental factors such as cloud noise for optical data. Image transformation is the method that is often used to deal with this issue. This paper considers the deep convolution networks to learn the complex mapping between sequence images, called adaptive filter generation network (AdaFG), convolution long short-term memory network (CLSTM), and cycle-consistent generative adversarial network (CyGAN) for construction of sequence image datasets. AdaFG network uses a separable 1D convolution kernel instead of 2D kernels to capture the spatial characteristics of input sequence images and then is trained end-to-end using sequence images. CLSTM network can map between different images using the state information of multiple time-series images. CyGAN network can map an image from a source domain to a target domain without additional information. Our experiments, which were performed with unmanned aerial vehicle (UAV) and Landsat-8 datasets, show that the deep convolution networks are effective to produce high-quality time-series image datasets, and the data-driven deep convolution networks can better simulate complex and diverse nonlinear data information.},
DOI = {10.3390/rs13091853}
}



@Article{agriculture11050431,
AUTHOR = {Cheng, Zhenzhen and Qi, Lijun and Cheng, Yifan},
TITLE = {Cherry Tree Crown Extraction from Natural Orchard Images with Complex Backgrounds},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {431},
URL = {https://www.mdpi.com/2077-0472/11/5/431},
ISSN = {2077-0472},
ABSTRACT = {Highly effective pesticide applications require a continual adjustment of the pesticide spray flow rate that attends to different canopy characterizations. Real-time image processing with rapid target detection and data-processing technologies is vital for precision pesticide application. However, the extant studies do not provide an efficient and reliable method of extracting individual trees with irregular tree-crown shapes and complicated backgrounds. This paper on our study proposes a Mahalanobis distance and conditional random field (CRF)-based segmentation model to extract cherry trees accurately in a natural orchard environment. This study computed Mahalanobis distance from the image’s color, brightness and location features to acquire an initial classification of the canopy and background. A CRF was then created by using the Mahalanobis distance calculations as unary potential energy and the Gaussian kernel function based on the image color and pixels distance as binary potential energy. Finally, the study completed image segmentation using mean-field approximation. The results show that the proposed method displays a higher accuracy rate than the traditional algorithms K-means and GrabCut algorithms and lower labeling and training costs than the deep learning algorithm DeepLabv3+, with 92.1%, 94.5% and 93.3% of the average P, R and F1-score, respectively. Moreover, experiments on datasets with different overlap conditions and image acquisition times, as well as in different years and seasons, show that this method performs well under complex background conditions, with an average F1-score higher than 87.7%.},
DOI = {10.3390/agriculture11050431}
}



@Article{rs13091854,
AUTHOR = {Bashir, Syed Muhammad Arsalan and Wang, Yi},
TITLE = {Small Object Detection in Remote Sensing Images with Residual Feature Aggregation-Based Super-Resolution and Object Detector Network},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1854},
URL = {https://www.mdpi.com/2072-4292/13/9/1854},
ISSN = {2072-4292},
ABSTRACT = {This paper deals with detecting small objects in remote sensing images from satellites or any aerial vehicle by utilizing the concept of image super-resolution for image resolution enhancement using a deep-learning-based detection method. This paper provides a rationale for image super-resolution for small objects by improving the current super-resolution (SR) framework by incorporating a cyclic generative adversarial network (GAN) and residual feature aggregation (RFA) to improve detection performance. The novelty of the method is threefold: first, a framework is proposed, independent of the final object detector used in research, i.e., YOLOv3 could be replaced with Faster R-CNN or any object detector to perform object detection; second, a residual feature aggregation network was used in the generator, which significantly improved the detection performance as the RFA network detected complex features; and third, the whole network was transformed into a cyclic GAN. The image super-resolution cyclic GAN with RFA and YOLO as the detection network is termed as SRCGAN-RFA-YOLO, which is compared with the detection accuracies of other methods. Rigorous experiments on both satellite images and aerial images (ISPRS Potsdam, VAID, and Draper Satellite Image Chronology datasets) were performed, and the results showed that the detection performance increased by using super-resolution methods for spatial resolution enhancement; for an IoU of 0.10, AP of 0.7867 was achieved for a scale factor of 16.},
DOI = {10.3390/rs13091854}
}



@Article{su13095323,
AUTHOR = {Ioannou, Konstantinos and Myronidis, Dimitrios},
TITLE = {Automatic Detection of Photovoltaic Farms Using Satellite Imagery and Convolutional Neural Networks},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {5323},
URL = {https://www.mdpi.com/2071-1050/13/9/5323},
ISSN = {2071-1050},
ABSTRACT = {The number of solar photovoltaic (PV) arrays in Greece has increased rapidly during the recent years. As a result, there is an increasing need for high quality updated information regarding the status of PV farms. This information includes the number of PV farms, power capacity and the energy generated. However, access to this data is obsolete, mainly due to the fact that there is a difficulty tracking PV investment status (from licensing to investment completion and energy production). This article presents a novel approach, which uses free access high resolution satellite imagery and a deep learning algorithm (a convolutional neural network—CNN) for the automatic detection of PV farms. Furthermore, in an effort to create an algorithm capable of generalizing better, all the current locations with installed PV farms (data provided from the Greek Energy Regulator Authority) in the Greek Territory (131,957 km2) were used. According to our knowledge this is the first time such an algorithm is used in order to determine the existence of PV farms and the results showed satisfying accuracy.},
DOI = {10.3390/su13095323}
}



@Article{app11104332,
AUTHOR = {Park, Gun and Lee, Jae Hyuk and Yoon, Hyungchul},
TITLE = {Semantic Structure from Motion for Railroad Bridges Using Deep Learning},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {4332},
URL = {https://www.mdpi.com/2076-3417/11/10/4332},
ISSN = {2076-3417},
ABSTRACT = {Current maintenance practices consume significant time, cost, and manpower. Thus, a new technique for maintenance is required. Construction information technologies, including building information modeling (BIM), have recently been applied to the field to carry out systematic and productive planning, design, construction, and maintenance. Although BIM is increasingly being applied to new structures, its application to existing structures has been limited. To apply BIM to an existing structure, a three-dimensional (3D) model of the structure that accurately represents the as-is status should be constructed and each structural component should be specified manually. This study proposes a method that constructs a 3D model and specifies the structural component automatically using photographic data with a camera installed on an unmanned aerial vehicle. This procedure is referred to as semantic structure from motion because it constructs a 3D point cloud model together with semantic information. A validation test was carried out on a railroad bridge to validate the performance of the proposed system. The average precision, intersection over union, and BF scores were 80.87%, 66.66%, and 56.33%, respectively. The proposed method could improve the current scan-to-BIM procedure by generating the as-is 3D point cloud model by specifying the structural component automatically.},
DOI = {10.3390/app11104332}
}



@Article{rs13101869,
AUTHOR = {Mattivi, Pietro and Pappalardo, Salvatore Eugenio and Nikolić, Nebojša and Mandolesi, Luca and Persichetti, Antonio and De Marchi, Massimo and Masin, Roberta},
TITLE = {Can Commercial Low-Cost Drones and Open-Source GIS Technologies Be Suitable for Semi-Automatic Weed Mapping for Smart Farming? A Case Study in NE Italy},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {1869},
URL = {https://www.mdpi.com/2072-4292/13/10/1869},
ISSN = {2072-4292},
ABSTRACT = {Weed management is a crucial issue in agriculture, resulting in environmental in-field and off-field impacts. Within Agriculture 4.0, adoption of UASs combined with spatially explicit approaches may drastically reduce doses of herbicides, increasing sustainability in weed management. However, Agriculture 4.0 technologies are barely adopted in small-medium size farms. Recently, small and low-cost UASs, together with open-source software packages, may represent a low-cost spatially explicit system to map weed distribution in crop fields. The general aim is to map weed distribution by a low-cost UASs and a replicable workflow, completely based on open GIS software and algorithms: OpenDroneMap, QGIS, SAGA and OpenCV classification algorithms. Specific objectives are: (i) testing a low-cost UAS for weed mapping; (ii) assessing open-source packages for semi-automatic weed classification; (iii) performing a sustainable management scenario by prescription maps. Results showed high performances along the whole process: in orthomosaic generation at very high spatial resolution (0.01 m/pixel), in testing weed detection (Matthews Correlation Coefficient: 0.67–0.74), and in the production of prescription maps, reducing herbicide treatment to only 3.47% of the entire field. This study reveals the feasibility of low-cost UASs combined with open-source software, enabling a spatially explicit approach for weed management in small-medium size farmlands.},
DOI = {10.3390/rs13101869}
}



@Article{s21103394,
AUTHOR = {Xie, Xiuchuan and Yang, Tao and Ning, Yajia and Zhang, Fangbing and Zhang, Yanning},
TITLE = {A Monocular Visual Odometry Method Based on Virtual-Real Hybrid Map in Low-Texture Outdoor Environment},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {3394},
URL = {https://www.mdpi.com/1424-8220/21/10/3394},
PubMedID = {34068098},
ISSN = {1424-8220},
ABSTRACT = {With the extensive application of robots, such as unmanned aerial vehicle (UAV) in exploring unknown environments, visual odometry (VO) algorithms have played an increasingly important role. The environments are diverse, not always textured, or low-textured with insufficient features, making them challenging for mainstream VO. However, for low-texture environment, due to the structural characteristics of man-made scene, the lines are usually abundant. In this paper, we propose a virtual-real hybrid map based monocular visual odometry algorithm. The core idea is that we reprocess line segment features to generate the virtual intersection matching points, which can be used to build the virtual map. Introducing virtual map can improve the stability of the visual odometry algorithm in low-texture environment. Specifically, we first combine unparallel matched line segments to generate virtual intersection matching points, then, based on the virtual intersection matching points, we triangulate to get a virtual map, combined with the real map built upon the ordinary point features to form a virtual-real hybrid 3D map. Finally, using the hybrid map, the continuous camera pose estimation can be solved. Extensive experimental results have demonstrated the robustness and effectiveness of the proposed method in various low-texture scenes.},
DOI = {10.3390/s21103394}
}



@Article{s21103389,
AUTHOR = {Quan, Longzhe and Wu, Bing and Mao, Shouren and Yang, Chunjie and Li, Hengda},
TITLE = {An Instance Segmentation-Based Method to Obtain the Leaf Age and Plant Centre of Weeds in Complex Field Environments},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {3389},
URL = {https://www.mdpi.com/1424-8220/21/10/3389},
PubMedID = {34068108},
ISSN = {1424-8220},
ABSTRACT = {Leaf age and plant centre are important phenotypic information of weeds, and accurate identification of them plays an important role in understanding the morphological structure of weeds, guiding precise targeted spraying and reducing the use of herbicides. In this work, a weed segmentation method based on BlendMask is proposed to obtain the phenotypic information of weeds under complex field conditions. This study collected images from different angles (front, side, and top views) of three kinds of weeds (Solanum nigrum, barnyard grass (Echinochloa crus-galli), and Abutilon theophrasti Medicus) in a maize field. Two datasets (with and without data enhancement) and two backbone networks (ResNet50 and ResNet101) were replaced to improve model performance. Finally, seven evaluation indicators are used to evaluate the segmentation results of the model under different angles. The results indicated that data enhancement and ResNet101 as the backbone network could enhance the model performance. The F1 value of the plant centre is 0.9330, and the recognition accuracy of leaf age can reach 0.957. The mIOU value of the top view is 0.642. Therefore, deep learning methods can effectively identify weed leaf age and plant centre, which is of great significance for variable spraying.},
DOI = {10.3390/s21103389}
}



@Article{ijgi10050329,
AUTHOR = {Li, Jing and Liu, Yong and Zhang, Yindan and Zhang, Yang},
TITLE = {Cascaded Attention DenseUNet (CADUNet) for Road Extraction from Very-High-Resolution Images},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {329},
URL = {https://www.mdpi.com/2220-9964/10/5/329},
ISSN = {2220-9964},
ABSTRACT = {The use of very-high-resolution images to extract urban, suburban and rural roads has important application value. However, it is still a problem to effectively extract the road area occluded by roadside tree canopy or high-rise buildings to maintain the integrity of the extracted road area, the smoothness of the sideline and the connectivity of the road network. This paper proposes an innovative Cascaded Attention DenseUNet (CADUNet) semantic segmentation model by embedding two attention modules, such as global attention and core attention modules, in the DenseUNet framework. First, a set of cascaded global attention modules are introduced to obtain the contextual information of the road; secondly, a set of cascaded core attention modules are embedded to ensure that the road information is transmitted to the greatest extent among the dense blocks in the network, and further assist the global attention module in acquiring multi-scale road information, thereby improving the connectivity of the road network while restoring the integrity of the road area shaded by the tree canopy and high-rise buildings. Based on binary cross entropy, an adaptive loss function is proposed for network parameter tuning. Experiments on the Massachusetts road dataset and the DeepGlobe-CVPR 2018 road dataset show that this semantic segmentation model can effectively extract the road area shaded by tree canopy and improve the connectivity of the road network.},
DOI = {10.3390/ijgi10050329}
}



@Article{app11104493,
AUTHOR = {Jo, Yongwon and Lee, Soobin and Lee, Youngjae and Kahng, Hyungu and Park, Seonghun and Bae, Seounghun and Kim, Minkwan and Han, Sungwon and Kim, Seoungbum},
TITLE = {Semantic Segmentation of Cabbage in the South Korea Highlands with Images by Unmanned Aerial Vehicles},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {4493},
URL = {https://www.mdpi.com/2076-3417/11/10/4493},
ISSN = {2076-3417},
ABSTRACT = {Identifying agricultural fields that grow cabbage in the highlands of South Korea is critical for accurate crop yield estimation. Only grown for a limited time during the summer, highland cabbage accounts for a significant proportion of South Korea’s annual cabbage production. Thus, it has a profound effect on the formation of cabbage prices. Traditionally, labor-extensive and time-consuming field surveys are manually carried out to derive agricultural field maps of the highlands. Recently, high-resolution overhead images of the highlands have become readily available with the rapid development of unmanned aerial vehicles (UAV) and remote sensing technology. In addition, deep learning-based semantic segmentation models have quickly advanced by recent improvements in algorithms and computational resources. In this study, we propose a semantic segmentation framework based on state-of-the-art deep learning techniques to automate the process of identifying cabbage cultivation fields. We operated UAVs and collected 2010 multispectral images under different spatiotemporal conditions to measure how well semantic segmentation models generalize. Next, we manually labeled these images at a pixel-level to obtain ground truth labels for training. Our results demonstrate that our framework performs well in detecting cabbage fields not only in areas included in the training data but also in unseen areas not included in the training data. Moreover, we analyzed the effects of infrared wavelengths on the performance of identifying cabbage fields. Based on the results of our framework, we expect agricultural officials to reduce time and manpower when identifying information about highlands cabbage fields by replacing field surveys.},
DOI = {10.3390/app11104493}
}



@Article{ijgi10050338,
AUTHOR = {Nguyen, Dinh Dung and Rohacs, Jozsef and Rohacs, Daniel},
TITLE = {Autonomous Flight Trajectory Control System for Drones in Smart City Traffic Management},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {338},
URL = {https://www.mdpi.com/2220-9964/10/5/338},
ISSN = {2220-9964},
ABSTRACT = {With the exponential growth of numerous drone operations ranging from infrastructure monitoring to even package delivery services, the integration of UAS in the smart city transportation systems is an actual task that requires radically new, sustainable (safe, secure, with minimum environmental impact and life cycle cost) solutions. The primary objective of this proposed option is the definition of routes as desired and commanded trajectories and their autonomous execution. The airspace structure and fixed routes are given in the global GPS reference system with supporting GIS mapping. The concept application requires a series of further studies and solutions as drone trajectory (or corridor) following by an autonomous trajectory tracking control system, coupled with autonomous conflict detection, resolution, safe drone following, and formation flight options. The second part of the paper introduces such possible models and shows some results of their verification tests. Drones will be connected with the agency, designed trajectories to support them with factual information on trajectories and corridors. While the agency will use trajectory elements to design fixed or desired trajectories, drones may use the conventional GPS, infrared, acoustic, and visual sensors for positioning and advanced navigation. The accuracy can be improved by unique markers integrated into the infrastructure.},
DOI = {10.3390/ijgi10050338}
}



@Article{app11104618,
AUTHOR = {Wang, Xun and Cai, Libing and Kong, Longxing and Wang, Binfeng and Huang, Shaohua and Lin, Chengdi},
TITLE = {Path Following and Obstacle Avoidance for Unmanned Aerial Vehicles Using a Virtual-Force-Based Guidance Law},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {4618},
URL = {https://www.mdpi.com/2076-3417/11/10/4618},
ISSN = {2076-3417},
ABSTRACT = {This paper presents a virtual-force-based guidance law (VFGL) for path following and obstacle avoidance in unmanned aerial vehicles. First, a virtual spring force and a virtual drag force are designed for straight-line following; then, the dynamic of the cross-track-error is equivalent to a spring mass system, which is easy to tune to acquire stability and non-overshoot convergence. Secondly, an additional virtual centripetal force is designed to counteract the influence of the curvature of the planned path so that the guidance law can accurately track a curve with a time-varying curvature. Thirdly, an extra virtual repulsive force is designed directly according to the sensor inputs; the virtual repulsive force pushes the vehicle away to move around obstacles. The use of artificial physics means the guidance law is founded on solid physical theory and is computationally simple. The physical meanings of the parameters are definite, and the VFGL has a large parameter adaptation. These make the guidance law easy to tune in application. Both the numerical and hardware-in-the-loop simulation results demonstrated the effectiveness of the proposed guidance law for path following and obstacle avoidance in unmanned aerial vehicles.},
DOI = {10.3390/app11104618}
}



@Article{rs13101975,
AUTHOR = {Wang, Lin and Zhou, Yuzhen and Hu, Qiao and Tang, Zhenghong and Ge, Yufeng and Smith, Adam and Awada, Tala and Shi, Yeyin},
TITLE = {Early Detection of Encroaching Woody Juniperus virginiana and Its Classification in Multi-Species Forest Using UAS Imagery and Semantic Segmentation Algorithms},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {1975},
URL = {https://www.mdpi.com/2072-4292/13/10/1975},
ISSN = {2072-4292},
ABSTRACT = {Woody plant encroachment into grasslands ecosystems causes significantly ecological destruction and economic losses. Effective and efficient management largely benefits from accurate and timely detection of encroaching species at an early development stage. Recent advances in unmanned aircraft systems (UAS) enabled easier access to ultra-high spatial resolution images at a centimeter level, together with the latest machine learning based image segmentation algorithms, making it possible to detect small-sized individuals of target species at early development stage and identify them when mixed with other species. However, few studies have investigated the optimal practical spatial resolution of early encroaching species detection. Hence, we investigated the performance of four popular semantic segmentation algorithms (decision tree, DT; random forest, RF; AlexNet; and ResNet) on a multi-species forest classification case with UAS-collected RGB images in original and down-sampled coarser spatial resolutions. The objective of this study was to explore the optimal segmentation algorithm and spatial resolution for eastern redcedar (Juniperus virginiana, ERC) early detection and its classification within a multi-species forest context. To be specific, firstly, we implemented and compared the performance of the four semantic segmentation algorithms with images in the original spatial resolution (0.694 cm). The highest overall accuracy was 0.918 achieved by ResNet with a mean interaction over union at 85.0%. Secondly, we evaluated the performance of ResNet algorithm with images in down-sampled spatial resolutions (1 cm to 5 cm with 0.5 cm interval). When applied on the down-sampled images, ERC segmentation performance decreased with decreasing spatial resolution, especially for those images coarser than 3 cm spatial resolution. The UAS together with the state-of-the-art semantic segmentation algorithms provides a promising tool for early-stage detection and localization of ERC and the development of effective management strategies for mixed-species forest management.},
DOI = {10.3390/rs13101975}
}



@Article{jimaging7050090,
AUTHOR = {Hamdi, Slim and Bouindour, Samir and Snoussi, Hichem and Wang, Tian and Abid, Mohamed},
TITLE = {End-to-End Deep One-Class Learning for Anomaly Detection in UAV Video Stream},
JOURNAL = {Journal of Imaging},
VOLUME = {7},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {90},
URL = {https://www.mdpi.com/2313-433X/7/5/90},
ISSN = {2313-433X},
ABSTRACT = {In recent years, the use of drones for surveillance tasks has been on the rise worldwide. However, in the context of anomaly detection, only normal events are available for the learning process. Therefore, the implementation of a generative learning method in an unsupervised mode to solve this problem becomes fundamental. In this context, we propose a new end-to-end architecture capable of generating optical flow images from original UAV images and extracting compact spatio-temporal characteristics for anomaly detection purposes. It is designed with a custom loss function as a sum of three terms, the reconstruction loss (Rl), the generation loss (Gl) and the compactness loss (Cl) to ensure an efficient classification of the “deep-one” class. In addition, we propose to minimize the effect of UAV motion in video processing by applying background subtraction on optical flow images. We tested our method on very complex datasets called the mini-drone video dataset, and obtained results surpassing existing techniques’ performances with an AUC of 85.3.},
DOI = {10.3390/jimaging7050090}
}



@Article{app11104647,
AUTHOR = {Liu, Chuanyang and Wu, Yiquan and Liu, Jingjing and Sun, Zuo and Xu, Huajie},
TITLE = {Insulator Faults Detection in Aerial Images from High-Voltage Transmission Lines Based on Deep Learning Model},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {4647},
URL = {https://www.mdpi.com/2076-3417/11/10/4647},
ISSN = {2076-3417},
ABSTRACT = {Insulator fault detection is one of the essential tasks for high-voltage transmission lines’ intelligent inspection. In this study, a modified model based on You Only Look Once (YOLO) is proposed for detecting insulator faults in aerial images with a complex background. Firstly, aerial images with one fault or multiple faults are collected in diverse scenes, and then a novel dataset is established. Secondly, to increase feature reuse and propagation in the low-resolution feature layers, a Cross Stage Partial Dense YOLO (CSPD-YOLO) model is proposed based on YOLO-v3 and the Cross Stage Partial Network. The feature pyramid network and improved loss function are adopted to the CSPD-YOLO model, improving the accuracy of insulator fault detection. Finally, the proposed CSPD-YOLO model and compared models are trained and tested on the established dataset. The average precision of CSPD-YOLO model is 4.9% and 1.8% higher than that of YOLO-v3 and YOLO-v4, and the running time of CSPD-YOLO (0.011 s) model is slightly longer than that of YOLO-v3 (0.01 s) and YOLO-v4 (0.01 s). Compared with the excellent object detection models YOLO-v3 and YOLO-v4, the experimental results and analysis demonstrate that the proposed CSPD-YOLO model performs better in insulator fault detection from high-voltage transmission lines with a complex background.},
DOI = {10.3390/app11104647}
}



@Article{app11104706,
AUTHOR = {Tullu, Abera and Endale, Bedada and Wondosen, Assefinew and Hwang, Ho-Yon},
TITLE = {Machine Learning Approach to Real-Time 3D Path Planning for Autonomous Navigation of Unmanned Aerial Vehicle},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {4706},
URL = {https://www.mdpi.com/2076-3417/11/10/4706},
ISSN = {2076-3417},
ABSTRACT = {The need for civilian use of Unmanned Aerial Vehicles (UAVs) has drastically increased in recent years. Their potential applications for civilian use include door-to-door package delivery, law enforcement, first aid, and emergency services in urban areas, which put the UAVs into obstacle collision risk. Therefore, UAVs are required to be equipped with sensors so as to acquire Artificial Intelligence (AI) to avoid potential risks during mission execution. The AI comes with intensive training of an on-board machine that is responsible to autonomously navigate the UAV. The training enables the UAV to develop humanoid perception of the environment it is to be navigating in. During the mission, this perception detects and localizes objects in the environment. It is based on this AI that this work proposes a real-time three-dimensional (3D) path planner that maneuvers the UAV towards destination through obstacle-free path. The proposed path planner has a heuristic sense of A⋆ algorithm, but requires no frontier nodes to be stored in a memory unlike A⋆. The planner relies on relative locations of detected objects (obstacles) and determines collision-free paths. This path planner is light-weight and hence a fast guidance method for real-time purposes. Its performance efficiency is proved through rigorous Software-In-The-Loop (SITL) simulations in constrained-environment and preliminary real flight tests.},
DOI = {10.3390/app11104706}
}



@Article{ijms22115423,
AUTHOR = {Mores, Antonia and Borrelli, Grazia Maria and Laidò, Giovanni and Petruzzino, Giuseppe and Pecchioni, Nicola and Amoroso, Luca Giuseppe Maria and Desiderio, Francesca and Mazzucotelli, Elisabetta and Mastrangelo, Anna Maria and Marone, Daniela},
TITLE = {Genomic Approaches to Identify Molecular Bases of Crop Resistance to Diseases and to Develop Future Breeding Strategies},
JOURNAL = {International Journal of Molecular Sciences},
VOLUME = {22},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {5423},
URL = {https://www.mdpi.com/1422-0067/22/11/5423},
PubMedID = {34063853},
ISSN = {1422-0067},
ABSTRACT = {Plant diseases are responsible for substantial crop losses each year and affect food security and agricultural sustainability. The improvement of crop resistance to pathogens through breeding represents an environmentally sound method for managing disease and minimizing these losses. The challenge is to breed varieties with a stable and broad-spectrum resistance. Different approaches, from markers to recent genomic and ‘post-genomic era’ technologies, will be reviewed in order to contribute to a better understanding of the complexity of host–pathogen interactions and genes, including those with small phenotypic effects and mechanisms that underlie resistance. An efficient combination of these approaches is herein proposed as the basis to develop a successful breeding strategy to obtain resistant crop varieties that yield higher in increasing disease scenarios.},
DOI = {10.3390/ijms22115423}
}




@article{CHENG2021,
title = {6G service-oriented space-air-ground integrated network: A survey},
journal = {Chinese Journal of Aeronautics},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121004738},
author = {Nan CHENG and Jingchao HE and Zhisheng YIN and Conghao ZHOU and Huaqing WU and Feng LYU and Haibo ZHOU and Xuemin SHEN},
keywords = {Mobile Edge Computing (MEC), Network Function Virtualization (NFV), Network slicing, Service-oriented network, Software Defined Networking (SDN), Space-Air-Ground Integrated Networks (SAGINs)},
abstract = {As an indispensable component of the emerging 6G networks, Space-Air-Ground Integrated Networks (SAGINs) are envisioned to provide ubiquitous network connectivity and services by integrating satellite networks, aerial networks, and terrestrial networks. In 6G SAGINs, a wide variety of network services with the features of diverse requirements, complex mobility, and multi-dimensional resources will pose great challenges to service provisioning, which urges the development of service-oriented SAGINs. In this paper, we conduct a comprehensive review of 6G SAGINs from a new perspective of service-oriented network. First, we present the requirements of service-oriented networks, and then propose a service-oriented SAGINs management architecture. Two categories of critical technologies are presented and discussed, i.e., heterogeneous resource orchestration technologies and the cloud-edge synergy technologies, which facilitate the interoperability of different network segments and cooperatively orchestrate heterogeneous resources across different domains, according to the service features and requirements. In addition, the potential future research directions are also presented and discussed.}
}
@article{WANG2021104486,
title = {Progressive structure network-based multiscale feature fusion for object detection in real-time application},
journal = {Engineering Applications of Artificial Intelligence},
volume = {106},
pages = {104486},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104486},
url = {https://www.sciencedirect.com/science/article/pii/S0952197621003341},
author = {Haifeng Wang and Lvjiyuan Jiang and Qian Zhao and Hao Li and Kai Yan and Yang Yang and Songlin Li and Yungang Zhang and Lianliu Qiao and Cuilian Fu and Hong Yin and Yun Hu and Haibin Yu},
keywords = {Feature fusion, Deep learning, Object detection, Machine learning},
abstract = {Deep learning-based target detection techniques have already made a wide-range impact on our daily life. Currently, a feature pyramid is a widely utilized technique for multiscale target detection, the effectiveness of the technique has already been proved. Nevertheless, in the pyramid structure, problems, such as multiscale feature alignment, model turmoil after fusion, feature redundancy, and no-local feature fusion, exist. In this paper, we propose a novel progressive structure network to solve the aforementioned problems. The proposed structure contains three modules: multiscale feature alignment fusion, different scale channels & spatial location adaptive weighted fusion, and multiscale global and local feature fusion. The proposed structure is capable of fusing information from different feature layers more effectively. Subsequently, the semantic gaps among different scales can be reduced. Furthermore, the proposed structure can maintain the stability of the detection network and its performance has been proved by comparing with other state-of-art feature fusion method. The proposed progressive network structure has also been applied to actual target detection tasks and the practical application effectiveness of our method has been verified.}
}
@article{ESPEL2020116353,
title = {Submerged macrophyte assessment in rivers: An automatic mapping method using Pléiades imagery},
journal = {Water Research},
volume = {186},
pages = {116353},
year = {2020},
issn = {0043-1354},
doi = {https://doi.org/10.1016/j.watres.2020.116353},
url = {https://www.sciencedirect.com/science/article/pii/S0043135420308897},
author = {Diane Espel and Stephanie Courty and Yves Auda and David Sheeren and Arnaud Elger},
keywords = {Aquatic vegetation, Remote sensing, Machine learning, Fluvial ecosystem, Random Forest, Support Vector Regression},
abstract = {Submerged macrophyte monitoring is a major concern for hydrosystem management, particularly for understanding and preventing the potential impacts of global change on ecological functions and services. Macrophyte distribution assessments in rivers are still primarily realized using field monitoring or manual photo-interpretation of aerial images. Considering the lack of applications in fluvial environments, developing operational, low-cost and less time-consuming tools able to automatically map and monitor submerged macrophyte distribution is therefore crucial to support effective management programs. In this study, the suitability of very fine-scale resolution (50 cm) multispectral Pléiades satellite imagery to estimate submerged macrophyte cover, at the scale of a 1 km river section, was investigated. The performance of nonparametric regression methods (based on two reliable and well-known machine learning algorithms for remote sensing applications, Random Forest and Support Vector Regression) were compared for several spectral datasets, testing the relevance of 4 spectral bands (red, green, blue and near-infrared) and two vegetation indices (the Normalized Difference Vegetation Index, NDVI, and the Green-Red Vegetation Index, GRVI), and for several field sampling configurations. Both machine learning algorithms applied to a Pléiades image were able to reasonably well predict macrophyte cover in river ecosystems with promising performance metrics (R² above 0.7 and RMSE around 20%). The Random Forest algorithm combined to the 4 spectral bands from Pléiades image was the most efficient, particularly for extreme cover values (0% and 100%). Our study also demonstrated that a larger number of fine-scale field sampling entities clearly involved better cover predictions than a smaller number of larger sampling entities.}
}
@article{MIRZAEINIA2019105398,
title = {Energy conservation of V-shaped swarming fixed-wing drones through position reconfiguration},
journal = {Aerospace Science and Technology},
volume = {94},
pages = {105398},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.105398},
url = {https://www.sciencedirect.com/science/article/pii/S1270963819320310},
author = {A. Mirzaeinia and M. Hassanalian and K. Lee and M. Mirzaeinia},
keywords = {Drag, Swarm, Drones, Leader, Energy, Reconfiguration},
abstract = {There is currently a growing interest in the area of drag reduction of unmanned aerial vehicles. In this paper, the swarming flight of the fixed-wing drones and a load balancing mechanism during the swarm is investigated. As an example, the swarm flight of EBee Sensfly flying wings is analyzed through the proposed methodology. The aerodynamic drag forces of each individual drone and the swarm are modeled theoretically. It is shown that drones through the swarming flight can save up to 70% of their energy and consequently improve their performance. As swarming drones have different loads and consume a different level of energy depending on their positions, there is a need to replace them during the flight in order to enhance their efficiency. To this end, regarding the number of drones, a replacement algorithm is defined for them so that they will be able to save more energy during their mission. It is shown that there is more than 21 percent improvement in flight time and distance of swarming drones after replacement. This method of replacement and formation can be considered as one of the effective factors in a drag reduction of swarming aerial vehicles.}
}
@article{WU2021165262,
title = {Peak-searching method for low count rate γ spectrum under short-time measurement based on a generative adversarial network},
journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
volume = {1002},
pages = {165262},
year = {2021},
issn = {0168-9002},
doi = {https://doi.org/10.1016/j.nima.2021.165262},
url = {https://www.sciencedirect.com/science/article/pii/S0168900221002461},
author = {Sunci Wu and Xiaobin Tang and Pin Gong and Peng Wang and Dajian Liang and Yong Li and Cheng Zhou and Xiaoxiang Zhu},
keywords = {Gamma spectrum analysis, Peak searching, Generative adversarial network, Symmetric zero-area, Nuclide identification},
abstract = {In scenarios such as vehicle radioactivity monitoring and unmanned aerial vehicle radioactivity monitoring, the count rate of the γ spectrum detected by the NaI(Tl) detector is low, the characteristic peak is weak, and the statistical fluctuation is large. When such a γ spectrum is processed with the conventional peak-searching method, the characteristic peak recognition accuracy is low and the nuclide identification rate is reduced. A peak-searching method based on the generative adversarial network (GAN) is proposed in this study for low count rate and short-time measurement of a single nuclide γ spectrum. Compared with the symmetric zero-area (SZA) method, the characteristic peak recognition accuracy of the GAN method is improved, the occurrence probability of false peaks is reduced, and the number of false peaks is decreased. Furthermore, the peak position offset with different time measurement conditions of the GAN method is stable. And the performance under shielding conditions of the GAN method is also better than that of the SZA method.}
}
@article{RAZA20201057,
title = {Establishing effective communications in disaster affected areas and artificial intelligence based detection using social media platform},
journal = {Future Generation Computer Systems},
volume = {112},
pages = {1057-1069},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.06.040},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20302727},
author = {Mohsin Raza and Muhammad Awais and Kamran Ali and Nauman Aslam and Vishnu Vardhan Paranthaman and Muhammad Imran and Farman Ali},
keywords = {Ad hoc networks, Heterogeneous networks (HetNets), Social sensors, Infrastructure less communications, Machine learning. 5G, Device to device (d2d), Boosting classifiers},
abstract = {Floods, earthquakes, storm surges and other natural disasters severely affect the communication infrastructure and thus compromise the effectiveness of communications dependent rescue and warning services. In this paper, a user centric approach is proposed to establish communications in disaster affected and communication outage areas. The proposed scheme forms ad hoc clusters to facilitate emergency communications and connect end-users/ User Equipment (UE) to the core network. A novel cluster formation with single and multi-hop communication framework is proposed. The overall throughput in the formed clusters is maximized using convex optimization. In addition, an intelligent system is designed to label different clusters and their localities into affected and non-affected areas. As a proof of concept, the labeling is achieved on flooding dataset where region specific social media information is used in proposed machine learning techniques to classify the disaster-prone areas as flooded or unflooded. The suitable results of the proposed machine learning schemes suggest its use along with proposed clustering techniques to revive communications in disaster affected areas and to classify the impact of disaster for different locations in disaster-prone areas.}
}
@article{HWANG2021187,
title = {A fuzzy CMAC learning approach to image based visual servoing system},
journal = {Information Sciences},
volume = {576},
pages = {187-203},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.06.029},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521006204},
author = {Maxwell Hwang and Yu-Jen Chen and Ming-Yi Ju and Wei-Cheng Jiang},
keywords = {Cerebellar model, Online compensator, Articulation controller, Takagi-Sugeno framework, Reinforcement learning},
abstract = {This study presents a fuzzy robotic joint controller using a cerebellar model articulation controller (CMAC) integrating a Takagi-Sugeno (T-S) framework with an online compensator for an articulated manipulator. The proposed controller is applied to image-based visual servoing (IBVS), including closed-loop feedback control and the kinematic Jacobian calculation. This approach learns a mapping from image feature errors for each joint’s velocity instead of the classical kinematics, thereby reducing the computational complexity and improving the self-regulation ability of the control system. These connecting weights of the cerebellar model learn offline, and an online compensator that uses reinforcement learning is developed to resolve system noise and uncertainties in an unknown environment. Compared with the classical inverse kinematics model, this approach does not need an excessive computational expense so that this proportional controller can be implemented in general scenarios with an eye-in-hand configuration. Experimental results show the proposed method can outperform the classical IBVS controller.}
}
@article{BENHAMAID2022103257,
title = {Recent advances in energy management for Green-IoT: An up-to-date and comprehensive survey},
journal = {Journal of Network and Computer Applications},
volume = {198},
pages = {103257},
year = {2022},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103257},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521002551},
author = {Sana Benhamaid and Abdelmadjid Bouabdallah and Hicham Lakhlef},
keywords = {Internet-of-Things (IoT), Green-IoT, Energy management, Energy harvesting, Energy saving},
abstract = {Internet-of-Things (IoT) refers to the massive network interconnection of objects often equipped with ubiquitous intelligence employed to provide smart services to end users. However, one of the substantial issues of IoT is the limited energy of IoT devices that are expected to run consistently for a long period of time without battery replacement. Moreover, in the wake of pervasive IoT, the number of IoT devices has exploded and lead to a tremendous rise in IoT networks carbon footprint. In this regard, Green-IoT and energy management of IoT emerged as challenging and attractive research topics for both academia and industry. In this paper, we conduct a comprehensive and an up-to-date survey on recent energy management techniques in IoT networks. We start by presenting the challenges of energy consumption in IoT networks. Then, we will present novel and well-known energy management approaches for IoT but focus on the most recent solutions proposed in each approach. Next, we will provide a comprehensive survey of the most recent energy management solutions for IoT ecosystem. We will also present recent trends and new research perspectives that can be exploited for energy conservation in IoT networks. Finally, we will give recommendations on how to exploit the techniques presented in our survey to achieve the IoT applications QoS requirements.}
}
@article{YANG2013166,
title = {Defect detection and evaluation of ultrasonic infrared thermography for aerospace CFRP composites},
journal = {Infrared Physics & Technology},
volume = {60},
pages = {166-173},
year = {2013},
issn = {1350-4495},
doi = {https://doi.org/10.1016/j.infrared.2013.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S1350449513001011},
author = {Bo Yang and Yaoda Huang and Long Cheng},
keywords = {Carbon Fiber Reinforced Polymer (CFRP), Ultrasonic infrared thermography, Non-destructive Testing (NDT), Defect detection and merging, Quantitative analysis},
abstract = {The ultrasonic infrared thermography Non-destructive Testing is introduced for detecting the impact damage of a CFRP specimen for Unmanned Aerial Vehicles. The characteristics of thermal images with damage are particularly analyzed. A Local Binary Fitting (LBF) model based on a non-Gaussian kernel function is used to segment the defect edge. In view of the discontinuity of defect in thermal images due to multilayered structure of composite materials, defect merging algorithms are proposed including time domain and space domain methods by using a few thermal images, and the defect geometric distortion during camera imaging is also compensated. The defect in the composite material can be quantitatively analyzed after the defect reconstruction. The experimental result has shown that the proposed algorithm can effectively detect and evaluate the impact damage of thermal images and the accuracy of quantitative assessment is correspondingly increased.}
}
@article{XING2020105539,
title = {Time-varying Analysis of Traffic Conflicts at the Upstream Approach of Toll Plaza},
journal = {Accident Analysis & Prevention},
volume = {141},
pages = {105539},
year = {2020},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2020.105539},
url = {https://www.sciencedirect.com/science/article/pii/S0001457519316537},
author = {Lu Xing and Jie He and Mohamed Abdel-Aty and Yina Wu and Jinghui Yuan},
keywords = {Toll Plaza, Diverging Area, Traffic Conflicts Risk, Time-varying Effects, Mixed Logit Model},
abstract = {This study investigates the traffic conflict risks at the upstream approach of toll plaza during the vehicles’ diverging period from the time of arrival at the diverging area to that of entering the tollbooths. Based on the vehicle’s trajectory data extracted from unmanned aerial vehicle (UAV) videos using an automated video analysis system, vehicles’ collision risk is computed by extended time to collision (TTC). Then, two time-varying mixed logit models including time-varying random effects logistic regression (T-RELR) model and time-varying random parameters logistic regression (T-RPLR) are developed to examine the time varying effects of influencing factors on vehicle collision risk, and four models including the standard random effects logistic regression (S-RELR) model, standard random parameters logistic regression (S-RPLR) model, distance-varying random effects logistic regression (D-RELR) model and distance-varying random parameters logistic regression (D-RPLR) are developed for model performance comparison. The results indicate that the T-RPLR model has the highest prediction accuracy. Eight influencing factors including following vehicle’s travel distance, following vehicle’s initial lane, following vehicle’s toll collection type, leading vehicle’s toll collection type, distance between two vehicles’ centroids, and following vehicle’s speed, are found to have time-varying effects on collision risk. Meanwhile, the first six factors are found to exhibit heterogeneous effects over the travel time. Another important finding is that the vehicle that comes from the innermost lane has an increasing trend to be involved in traffic conflicts, whereas the collision risks of other vehicles decrease as the travel time increases. Moreover, vehicles with higher speed have a decreasing probability to be involved in crashes over the travel time. Interestingly, the results of D-RPLR model are similar with that of T-RPLR model. These findings provide helpful information for accurate assessment of collision risk, which is a key step toward improving safety performance of the toll plazas’ diverging areas.}
}
@article{MATIKAINEN201610,
title = {Remote sensing methods for power line corridor surveys},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {119},
pages = {10-31},
year = {2016},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2016.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0924271616300697},
author = {Leena Matikainen and Matti Lehtomäki and Eero Ahokas and Juha Hyyppä and Mika Karjalainen and Anttoni Jaakkola and Antero Kukko and Tero Heinonen},
keywords = {Power line, Review, Satellite/aerial image, Laser scanning, Lidar, UAV},
abstract = {To secure uninterrupted distribution of electricity, effective monitoring and maintenance of power lines are needed. This literature review article aims to give a wide overview of the possibilities provided by modern remote sensing sensors in power line corridor surveys and to discuss the potential and limitations of different approaches. Monitoring of both power line components and vegetation around them is included. Remotely sensed data sources discussed in the review include synthetic aperture radar (SAR) images, optical satellite and aerial images, thermal images, airborne laser scanner (ALS) data, land-based mobile mapping data, and unmanned aerial vehicle (UAV) data. The review shows that most previous studies have concentrated on the mapping and analysis of network components. In particular, automated extraction of power line conductors has achieved much attention, and promising results have been reported. For example, accuracy levels above 90% have been presented for the extraction of conductors from ALS data or aerial images. However, in many studies datasets have been small and numerical quality analyses have been omitted. Mapping of vegetation near power lines has been a less common research topic than mapping of the components, but several studies have also been carried out in this field, especially using optical aerial and satellite images. Based on the review we conclude that in future research more attention should be given to an integrated use of various data sources to benefit from the various techniques in an optimal way. Knowledge in related fields, such as vegetation monitoring from ALS, SAR and optical image data should be better exploited to develop useful monitoring approaches. Special attention should be given to rapidly developing remote sensing techniques such as UAVs and laser scanning from airborne and land-based platforms. To demonstrate and verify the capabilities of automated monitoring approaches, large tests in various environments and practical monitoring conditions are needed. These should include careful quality analyses and comparisons between different data sources, methods and individual algorithms.}
}
@article{ZHANG2022171,
title = {Information fusion for edge intelligence: A survey},
journal = {Information Fusion},
volume = {81},
pages = {171-186},
year = {2022},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2021.11.018},
url = {https://www.sciencedirect.com/science/article/pii/S1566253521002438},
author = {Yin Zhang and Chi Jiang and Binglei Yue and Jiafu Wan and Mohsen Guizani},
keywords = {Information fusion, Multisource, Real-time, Event-driven, Context-aware},
abstract = {Edge intelligence capability is expected to enable the development of a new paradigm integrated with edge computing and artificial intelligence. However, due to the multisource nature, heterogeneity, and a large scale of the sensory data, it is necessary to improve the data processing and decision-making capacity for the edges. Hence, this paper asserts that information fusion is an important technique to power the capacity of edge intelligence in terms of collection, communication, computing, caching, control and collaboration. Specifically, it provides a comprehensive investigation of four representative scenarios assisted by information fusion at the edge, i.e., multisource information fusion, real-time information fusion, event-driven information fusion, and context-aware information fusion. Moreover, it discusses the future directions and open issues in this field.}
}
@article{SONG2021633,
title = {High-throughput phenotyping: Breaking through the bottleneck in future crop breeding},
journal = {The Crop Journal},
volume = {9},
number = {3},
pages = {633-645},
year = {2021},
note = {Rice as a model crop: genetics, genomics and breeding},
issn = {2214-5141},
doi = {https://doi.org/10.1016/j.cj.2021.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S2214514121000829},
author = {Peng Song and Jinglu Wang and Xinyu Guo and Wanneng Yang and Chunjiang Zhao},
keywords = {High-throughput phenotyping, Crop breeding, Crop phenomics, Phenotyping platform, Data analysis},
abstract = {With the rapid development of genetic analysis techniques and crop population size, phenotyping has become the bottleneck restricting crop breeding. Breaking through this bottleneck will require phenomics, defined as the accurate, high-throughput acquisition and analysis of multi-dimensional phenotypes during crop growth at organism-wide levels, ranging from cells to organs, individual plants, plots, and fields. Here we offer an overview of crop phenomics research from technological and platform viewpoints at various scales, including microscopic, ground-based, and aerial phenotyping and phenotypic data analysis. We describe recent applications of high-throughput phenotyping platforms for abiotic/biotic stress and yield assessment. Finally, we discuss current challenges and offer perspectives on future phenomics research.}
}
@article{IACONO201838,
title = {Path following and obstacle avoidance for an autonomous UAV using a depth camera},
journal = {Robotics and Autonomous Systems},
volume = {106},
pages = {38-46},
year = {2018},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2018.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0921889018301027},
author = {Massimiliano Iacono and Antonio Sgorbissa},
keywords = {UAV, MAV, Flying vehicle, Obstacle avoidance, Path planning},
abstract = {The main focus of this work is the development of a software architecture to autonomously navigate a flying vehicle in an indoor environment in presence of obstacles. The hardware platform used to test the developed algorithms is the AscTec Firefly equipped with a RGB-D camera (Microsoft Kinect): the sensor output is used to incrementally build a map of the environment and generate a collision-free path. Specifically, we introduce a novel approach to analytically compute the path in an efficient and effective manner. An initial path, given by the intersection of two 3D surfaces, is shaped around the obstacles by adding to either of the two surfaces a radial function at every obstacle location. The intersection between the deformed surfaces is guaranteed not to intersect obstacles, hence it is a safe path for the robot to follow. The entire computation runs on-board and the path is computed in real-time. In this article we present the developed algorithms, the software architecture as well as the results of our experiments, showing that the method can adapt in real time the robot’s path in order to avoid several types of obstacles, while producing a map of the surroundings.}
}
@article{HU2020127,
title = {Blurred lines: integrating emerging technologies to advance plant biosecurity},
journal = {Current Opinion in Plant Biology},
volume = {56},
pages = {127-134},
year = {2020},
note = {Biotic interactions ● AGRI 2019},
issn = {1369-5266},
doi = {https://doi.org/10.1016/j.pbi.2020.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S1369526620300510},
author = {Yiheng Hu and Salome Wilson and Benjamin Schwessinger and John P Rathjen},
abstract = {Plant diseases threaten global food security and biodiversity. Rapid dispersal of pathogens particularly via human means has accelerated in recent years. Timely detection of plant pathogens is essential to limit their spread. At the same time, international regulations must keep abreast of advances in plant disease diagnostics. In this review we describe recent progress in developing modern plant disease diagnostics based on detection of pathogen components, high-throughput image analysis, remote sensing, and machine learning. We discuss how different diagnostic approaches can be integrated in detection frameworks that can work at different scales and account for sampling biases. Lastly, we briefly discuss the requirements to apply these advances under regulatory settings to improve biosecurity measures globally.}
}
@article{LI2020106854,
title = {A review of applications in federated learning},
journal = {Computers & Industrial Engineering},
volume = {149},
pages = {106854},
year = {2020},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2020.106854},
url = {https://www.sciencedirect.com/science/article/pii/S0360835220305532},
author = {Li Li and Yuxi Fan and Mike Tse and Kuo-Yi Lin},
keywords = {Federated learning, Literature review, Citation analysis, Research front},
abstract = {Federated Learning (FL) is a collaboratively decentralized privacy-preserving technology to overcome challenges of data silos and data sensibility. Exactly what research is carrying the research momentum forward is a question of interest to research communities as well as industrial engineering. This study reviews FL and explores the main evolution path for issues exist in FL development process to advance the understanding of FL. This study aims to review prevailing application in industrial engineering to guide for the future landing application. This study also identifies six research fronts to address FL literature and help advance our understanding of FL for future optimization. This study contributes to conclude application in industrial engineering and computer science and summarize a review of applications in FL.}
}
@article{GUO2020383,
title = {Automatic crack distress classification from concrete surface images using a novel deep-width network architecture},
journal = {Neurocomputing},
volume = {397},
pages = {383-392},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.08.107},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220304112},
author = {Li Guo and Runze Li and Bin Jiang and Xing Shen},
keywords = {Concrete surface image, Crack distress, Automatic classification, Deep-width network},
abstract = {The condition monitoring of concrete surface plays a significant role in civil infrastructure management system. Crack is the main threat to concrete surface of buildings, bridges, roads and pavements. This issue has been researched for several decades, however, it is still a challenge to classify crack since there are many inferior factors, e.g., intense inhomogeneity, structure complexity and background noise of concrete surface. In this paper, a novel deep-width network (DWN) architecture is used for binary and multi-label concrete surface crack classification without handcraft feature extraction. It intelligently learns cracking structures from input raw images by linear and nonlinear mapping process, flexible dynamically updates new weights and efficiently constructs the network by adding new incremental samples. The presented crack distress classification method is tested on two concrete surface crack image datasets and compared with many popular classification methods like sparse autoencoder (SAE), convolution neural network (CNN), and broad learn system (BLS). Experimental results demonstrate that it obviously outperforms those methods both in accuracy and efficiency.}
}
@article{BANSAL2021107998,
title = {Next generation stock exchange: Recurrent neural learning model for distributed ledger transactions},
journal = {Computer Networks},
volume = {193},
pages = {107998},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.107998},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621001183},
author = {Gaurang Bansal and Vinay Chamola and Georges Kaddoum and Md. Jalil Piran and Mubarak Alrashoud},
keywords = {Blockchain, Machine learning, Commerce, IOTA, Stock exchange, LSTM, FinTech},
abstract = {A distributed stock exchange system encompasses multiple network hosts that participate in the sharing and exchange of resources. In such exchanges, the mediator or stock exchange must manage and delineate all operations in a cohesive manner. Stock exchange (SE) also acts as the transaction manager to provide consistent, isolated, durable, and atomic transactions for participating entities. However, the work for the stock exchange is not so straightforward as it may sound. With multiple transactions happening per second, the global serializability and concurrency control becomes an issue resulting in multiple threats and vulnerabilities. We propose a novel stock exchange that integrates time series prediction to distributed transactions and understanding the rapid global transactions and limitations of resources at the stock exchange. We use distributed acyclic graph (DAG) based distributed ledger technology IOTA to provide security and consensus for independent users. The paper proposes a time-variant model that adjusts its predictions based on transactions, moments of observations, participating entities, and history. We show that our model outcasts other state-of-art schemes in terms of prediction accuracy. Also, the model is fair, fast, and scalable to handle millions of transactions per second.}
}
@article{TRIPATHI201618,
title = {Autonomous Landing for UAVs using T-MPSP Guidance and Dynamic Inversion Autopilot},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {1},
pages = {18-23},
year = {2016},
note = {4th IFAC Conference on Advances in Control and Optimization of Dynamical Systems ACODS 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.03.022},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316300222},
author = {Amit K. Tripathi and Radhakant Padhi},
keywords = {T-MPSP, dynamic-inversion, Six-DOF, autolanding, glideslope, flare, tracking},
abstract = {This paper presents the autonomous landing performance of UAVs using Tracking-Model Predictive Static Programming(T-MPSP) guidance and dynamic inversion autopilot. T-MPSP guidance uses state constraint and control deviation across the landing trajectory and optimizes the control requirement in the outer loop whereas the dynamic inversion technique is implemented in the inner loop control computation. The landing phase is divided into approach, glideslope and flare. Approach is considered as a circular trajectory as well as a straight line level flying phase. Glideslope and flare are ramp with a constant flight path angle and exponential trajectories respectively. T-MPSP technique uses a suitable control guess history computed from a standard reference for its first iteration and then provides correction in the guess history in the successive iterations and updates the control law until tracking reaches closer to the desired output. The control command with T-MPSP algorithm is computed at grid points across the trajectory. A sliding window approach is implemented in T-MPSP to compute the control wherein once the control is computed at a grid point the window slides forward. The nonlinear Six-DOF aerodynamic model of AE2 UAV have been used for validation.}
}
@article{YU202067,
title = {Orientation guided anchoring for geospatial object detection from remote sensing imagery},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {160},
pages = {67-82},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0924271619302904},
author = {Yongtao Yu and Haiyan Guan and Dilong Li and Tiannan Gu and E. Tang and Aixia Li},
keywords = {Object detection, Orientation guided anchoring, Oriented anchor, Region proposal network, Convolutional neural network, Remote sensing imagery},
abstract = {Object detection from remote sensing imagery plays a significant role in a wide range of applications, including urban planning, intelligent transportation systems, ecology and environment analysis, etc. However, scale variations, orientation variations, illumination changes, and partial occlusions, as well as image qualities, bring great challenges for accurate geospatial object detection. In this paper, we propose an efficient orientation guided anchoring based geospatial object detection network based on convolutional neural networks. To handle objects of varying sizes, the feature extraction subnetwork extracts a pyramid of semantically strong features at different scales. Based on orientation guided anchoring, the anchor generation subnetwork generates a small set of high-quality, oriented anchors as object proposals. After orientation region of interest pooling, objects of interest are detected from the object proposals through the object detection subnetwork. The proposed method has been tested on a large geospatial object detection dataset. Quantitative evaluations show that an overall completeness, correctness, quality, and F1-measure of 0.9232, 0.9648, 0.8931, and 0.9435, respectively, are obtained. In addition, the proposed method achieves a processing speed of 8 images per second on a GPU on the cloud computing platform. Comparative studies with the existing object detection methods also demonstrate the advantageous detection accuracy and computational efficiency of our proposed method.}
}
@article{ZHANG202149,
title = {Assessing soil thickness in a black soil watershed in northeast China using random forest and field observations},
journal = {International Soil and Water Conservation Research},
volume = {9},
number = {1},
pages = {49-57},
year = {2021},
issn = {2095-6339},
doi = {https://doi.org/10.1016/j.iswcr.2020.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S2095633920300721},
author = {Shuai Zhang and Gang Liu and Shuli Chen and Craig Rasmussen and Baoyuan Liu},
keywords = {Soil thickness, Random forest, Black soils, Northeast China, Soil geomorphology},
abstract = {Soil thickness determines the soil productivity in the black soil region of northeast China, which is important for national food security. Existing information on the spatial variation of black soil thickness is inadequate. In this paper, we propose a model framework for spatial estimation of the black soil thickness at the watershed scale by integrating field observations, unmanned aerial vehicle variations of topography, and satellite variations of vegetation with the aid of random forest. We sampled 141 sample profiles over a watershed and identified the black soil thickness based on indices of the mollic epipedon. Topographic variables were derived from a digital elevation model and vegetation variables were derived from Landsat 8 imagery. Random forest was used to determine the relationship between black soil thickness and environmental variables. The resulting model explained 61% of the black soil thickness spatial variation, which was more than twice that of traditional interpolation methods (ordinary kriging, universal kriging and inverse distance weighting). Topographic variables contributed the most toward explaining the thickness, followed by vegetation indices. The black soil thickness over the watershed had a clear catenary soil pattern, with thickest black soil in the low depositional areas and thinnest at the higher elevations that drain into the low areas. The proposed model framework will improve estimates of soil thickness in the region of our study.}
}
@article{XIA2021100999,
title = {Sky view factor estimation from street view images based on semantic segmentation},
journal = {Urban Climate},
volume = {40},
pages = {100999},
year = {2021},
issn = {2212-0955},
doi = {https://doi.org/10.1016/j.uclim.2021.100999},
url = {https://www.sciencedirect.com/science/article/pii/S2212095521002297},
author = {Yixi Xia and Nobuyoshi Yabuki and Tomohiro Fukuda},
keywords = {Urban planning, Urban environment, Sky view factor (SVF), Semantic segmentation, Street view images (SVIs)},
abstract = {The sky view factor (SVF) has been recognized as an indicator to evaluate the openness of streets in the field of urban planning. It represents the ratio of the visible sky area to the total sky area at one point in space. However, due to the time-consuming and laborious acquisition of data and manual detection in traditional measurement methods, the SVF measurement in large-scale space has been greatly restricted. With the development of street view images (SVIs), some SVI services provide panorama data of the urban street level that can be used to estimate the SVF. In this research, we developed a method to measure street-level SVF based on semantic segmentation processing to extract sky area data from SVIs and estimated the fisheye photographic-based sky view factor (SVFf). Comparison with the previous research proves the reliability and efficiency of the SVF value estimated by this method. We further generated street-level SVFf maps, which served as a design base for creating more comfortable pedestrian street spaces. In the future, using our method, we can evaluate the urban thermal environment more comprehensively and accurately, and propose more targeted urban planning measures to alleviate the urban heat island effect.}
}
@article{RENDON2017325,
title = {Path Following Control Tuning for an Autonomous Unmanned Quadrotor Using Particle Swarm Optimization},
journal = {IFAC-PapersOnLine},
volume = {50},
number = {1},
pages = {325-330},
year = {2017},
note = {20th IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2017.08.054},
url = {https://www.sciencedirect.com/science/article/pii/S240589631730071X},
author = {Manuel A. Rendón and Felipe F. Martins},
keywords = {UAVs, autonomous robotic, trajectory & planning, trajectory tracking & path following},
abstract = {The goal of this work is to present the particle swarm optimization application for quadrotor attitude and path following control tuning. To perform this task a path following feed-forward plus proportional-derivative control strategy was implemented, using particle swarm for tuning gains, and root mean square error for validating. The basic of quadrotor kinematics and dynamics model will be presented. Path planning will be executed through Euler-Lagrange equations to minimize the snap cost function and guarantee a soft trajectory through a set of intermediary waypoints. The reliability of this approach will be tested through several simulations.}
}
@article{ZHONG2019207,
title = {Pipeline leakage detection for district heating systems using multisource data in mid- and high-latitude regions},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {151},
pages = {207-222},
year = {2019},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.02.021},
url = {https://www.sciencedirect.com/science/article/pii/S0924271619300607},
author = {Yanfei Zhong and Yao Xu and Xinyu Wang and Tianyi Jia and Guisong Xia and Ailong Ma and Liangpei Zhang},
keywords = {Pipeline leakage detection, Multisource data, Infrared imaging, Unmanned aerial vehicles, Mid- and high-latitude regions},
abstract = {In mid- and high-latitude regions, district heating systems (DHSs) are major heat supply solutions to both local industry and citizens. Pipeline leakage detection is therefore important for monitoring the condition of DHSs and promoting energy efficiency. In this paper, a saliency analysis method is presented for DHS pipeline leakage detection using remotely sensed infrared imagery, visible imagery, and geographic information system (GIS) data. In the saliency-based DHS leakage detection method, the infrared saliency map is created to enhance the leakage targets, and the pipeline location information extracted from the GIS data or the visible imagery acts as a distribution prior to reject false alarms. Finally, adaptive target segmentation by maximum entropy permits the automatic detection of potential leakage targets in the final fused saliency map. The approach was validated on three data sets acquired in Gävle in Sweden and Datong in China, with the heating leakages indicated by human analysts and field validation. The leakage detection accuracy of the new approach with a reduced false alarm rate is better than the previous methods. The results suggest that the proposed approach for DHS leakage detection from remotely sensed thermal infrared data has great potential for monitoring DHS conditions in mid- and high-latitude regions.}
}
@article{DEBAUCHE2021,
title = {Cloud and distributed architectures for data management in agriculture 4.0 : Review and future trends},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821002664},
author = {Olivier Debauche and Saïd Mahmoudi and Pierre Manneback and Frédéric Lebeau},
keywords = {Agriculture 4.0, Smart farming, Smart agriculture, Lambda architecture, Kappa architecture, Edge computing, Fog computing, Micro-service architecture, Data lake, Data house, Blockchain, Osmotic computing, Dew computing},
abstract = {The Agriculture 4.0, also called Smart Agriculture or Smart Farming, is at the origin of the production of a huge amount of data that must be collected, stored, and processed in a very short time. Processing this massive quantity of data needs to use specific infrastructure that use adapted IoT architectures. Our review offers a comparative panorama of Central Cloud, Distributed Cloud Architectures, Collaborative Computing Strategies, and new trends used in the context of Agriculture 4.0. In this review, we try to answer 4 research questions: (1) Which storage and processing architectures are best suited to Agriculture 4.0 applications and respond to its peculiarities? (2) Can generic architectures meet the needs of Agriculture 4.0 application cases? (3) What are the horizontal development possibilities that allow the transition from research to industrialization? (4) What are the vertical valuations possibilities to move from algorithms trained in the cloud to embedded or stand-alone products? For this, we compare architectures with 8 criteria (User Proximity, Latency & Jitter, Network stability, high throughput, Reliability, Scalability, Cost Effectiveness, Maintainability), and analyze the advantages and disadvantages of each of them.}
}
@article{HU2022108063,
title = {Prognostics and health management: A review from the perspectives of design, development and decision},
journal = {Reliability Engineering & System Safety},
volume = {217},
pages = {108063},
year = {2022},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2021.108063},
url = {https://www.sciencedirect.com/science/article/pii/S0951832021005652},
author = {Yang Hu and Xuewen Miao and Yong Si and Ershun Pan and Enrico Zio},
keywords = {Prognostics and health management (PHM), PHM Design, PHM Development, PHM Decision, PHM practical prospects},
abstract = {Prognostics and health management (PHM) is an enabling technology used to maintain the reliable, efficient, economic and safe operation of engineering equipment, systems and structures. In the last 5 years, many PHM review works have been published for discussing and summarizing the state-of-the-art of different approaches and methods, usage modes and applications of PHM. This paper intends to enrich the PHM state-of-the-art by reviewing the PHM works from three different points of view: DEsign, DEvelopment and DEcision (DE3). We dig into the problem essence of the DE3 of PHM by reviewing the research work, extracting the research conclusions from 235 related publications, and exposing the current methodologies and solution frameworks for addressing the DE3 issues. We identify the gaps and challenges of existing PHM concerning the DE3, and point out issues and opportunities of future PHM researches. We expect this review work to provide clear directions for assisting the researchers and practitioners in advancing the PHM methodologies and maturing them into practical PHM technologies.}
}
@article{ZHANG2022106617,
title = {Two-step ResUp&Down generative adversarial network to reconstruct multispectral image from aerial RGB image},
journal = {Computers and Electronics in Agriculture},
volume = {192},
pages = {106617},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106617},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006347},
author = {Yanchao Zhang and Wen Yang and Wenbo Zhang and Jiya Yu and Jianxin Zhang and Yongjie Yang and Yongliang Lu and Wei Tang},
keywords = {Multispectral image reconstruction, Images registration, Generative adversarial network, UAV, ResNet},
abstract = {Convolutional neural network has brought breakthroughs on multispectral image reconstruction research. Previous work has largely focused on reconstructing MSI using the R-G-B channels from the MSI as inputs of the model. However, it’s image manipulation rather than practical use. In real application, to reconstruct multispectral image using images from RGB camera is a research that has hardly been studied. In this research, high resolution aerial RGB images are collected by drone with RGB camera and multispectral images are collected by drone with RedEdge-M multispectral Camera. Then a new two-step Generative Adversarial Network (GAN)-based reconstruction method was proposed as follows: At first, MSI and RGB images are carefully registered to make sure that pixels are one–one correspondent. Then two data sources are cropped to form dataset. After that, a novel R-MSI GAN using is proposed. It uses a ResUp&Down block to replace the ResNet block of the Generator network and it outperforms ResNet-based GAN. The experimental results show that: (1) the combination of Mean Square Error and Discriminator (MSE-D) can alleviate the problem of the high-frequency loss of generated images. (2) The root means square error (RMSE), mean relative absolute error (MRAE) and Structural Similarity (SSIM) can only reflect overall error but can’t reflect details in reconstructed images, while different bands' statistical histogram can present the total high-frequency loss of generated bands. (3) 3 indexes, which are intersection over union (IoU) based normalized difference vegetation index (NDVI)-IoU, normalized difference red edge (NDRE)-IoU and enhance vegetation index (EVI)-IoU, were defined to verify the effect of the generated MSI and they show good consistence with vegetation index map. 4 In comparisons among ResNet-based GAN, single step ResUp&Down GAN and two-step ResUp&Down GAN(T-GAN) with 3 loss functions (L1, MSE, Discriminator), the two-step ResUp&Down GAN(T-GAN) with MSE-D loss function performs best in reconstructing RGB bands. The T-GAN with L1loss-D (mean absolute error loss) performs best in reconstructing NIR and rededge bands. In summary, the proposed methods can effectively reconstruct MSI using images from RGB camera at drone based remote sensing.}
}
@article{ZHAO2022206,
title = {L1-norm constraint kernel adaptive filtering framework for precise and robust indoor localization under the internet of things},
journal = {Information Sciences},
volume = {587},
pages = {206-225},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.12.026},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521012470},
author = {Xin Zhao and Xifeng Li and Dongjie Bi and Haojie Wang and Yongle Xie and Adi Alhudhaif and Fayadh Alenezi},
keywords = {Kernel adaptive filter, Indoor localization, Internet of Things, Abrupt noise, Positioning accuracy},
abstract = {The mixed noise such as Gaussian noise together with the abrupt noise widely exists in the indoor environment, which always leads to the problem of performance degradation of the positioning system under the Internet of Things (IoT). In this paper, a novel kernel function named generalized Student’s t kernel (GSt) and a resulting sparse generalized Student’s t kernel adaptive filter (SGStKAF) is proposed to attack this problem. The proposed SGStKAF utilizes the kernel mean p-power error criterion (KMPE) with the L1-norm penalty. The proposed SGStKAF has three significant features. Firstly, the generalized Student’s t kernel can suppress the abrupt noise effectively. Secondly, the L1-norm penalty guarantees that the fixed-point sub-iteration is available so that the more precise solution can be obtained in a few iterations. At last, a sparse structure of neural networks for the implementation of the proposed method can also be obtained via the L1 constraint. Three experiments and comparisons are carried out to prove the effectiveness of the proposed positioning framework in terms of accuracy and robustness in both the simulation situation and the real-world indoor environments.}
}
@article{SADGROVE2018183,
title = {Real-time object detection in agricultural/remote environments using the multiple-expert colour feature extreme learning machine (MEC-ELM)},
journal = {Computers in Industry},
volume = {98},
pages = {183-191},
year = {2018},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2018.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S016636151730533X},
author = {Edmund J. Sadgrove and Greg Falzon and David Miron and David W. Lamb},
keywords = {Extreme learning machine, Object detection, Machine vision, Unmanned aerial vehicle, Agriculture, Robotics},
abstract = {It is necessary for autonomous robotics in agriculture to provide real time feedback, but due to a diverse array of objects and lack of landscape uniformity this objective is inherently complex. The current study presents two implementations of the multiple-expert colour feature extreme learning machine (MEC-ELM). The MEC-ELM is a cascading algorithm that has been implemented along side a summed area table (SAT) for fast feature extraction and object classification, for a fully functioning object detection algorithm. The MEC-ELM is an implementation of the colour feature extreme learning machine (CF-ELM), which is an extreme learning machine (ELM) with a partially connected hidden layer; taking three colour bands as inputs. The colour implementation used with the SAT enable the MEC-ELM to find and classify objects quickly, with 84% precision and 91% recall in weed detection in the Y’UV colour space and in 0.5 s per frame. The colour implementation is however limited to low resolution images and for this reason a colour level co-occurrence matrix (CLCM) variant of the MEC-ELM is proposed. This variant uses the SAT to produce a CLCM and texture analyses, with texture values processed as an input to the MEC-ELM. This enabled the MEC-ELM to achieve 78–85% precision and 81–93% recall in cattle, weed and quad bike detection and in times between 1 and 2 s per frame. Both implementations were benchmarked on a standard i7 mobile processor. Thus the results presented in this paper demonstrated that the MEC-ELM with SAT grid and CLCM makes an ideal candidate for fast object detection in complex and/or agricultural landscapes.}
}
@article{ABIOYE2020105441,
title = {A review on monitoring and advanced control strategies for precision irrigation},
journal = {Computers and Electronics in Agriculture},
volume = {173},
pages = {105441},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105441},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919314826},
author = {Emmanuel Abiodun Abioye and Mohammad Shukri Zainal Abidin and Mohd Saiful Azimi Mahmud and Salinda Buyamin and Mohamad Hafis Izran Ishak and Muhammad Khairie Idham Abd Rahman and Abdulrahaman Okino Otuoze and Patrick Onotu and Muhammad Shahrul Azwan Ramli},
keywords = {Monitoring, Advanced control, Precision irrigation, Internet of things, Sensors, Water-saving},
abstract = {The demand for freshwater is on the increase due to the rapid growth in the world’s population while the effect of global warming and climate change cause severe threat to water use and food security. Consequently, irrigation systems are tremendously utilized by many farmers all over the world with its associated high amount of water consumption from various sources posing a major concern. This necessitates the increased focus on improving the efficiency of water usage in irrigation agriculture. The advent and rapid successes of the Internet of Things (IoT) and advanced control strategies are being leveraged to achieve improved monitoring and control of irrigation farming. In this review, a thorough search for literature on irrigation monitoring and advanced control systems highlighting the research works within the past ten years are presented. Attention is paid on recent research works related to the monitoring and advance control concepts for precision irrigation. It is expected that this review paper will serve as a useful reference to enhance reader’s knowledge on monitoring and advanced control opportunities related to irrigation agriculture as well as assist researchers in identifying directions and gaps to future research works in this field.}
}
@article{GOMEZ2016367,
title = {Assuring safety in air traffic control systems with argumentation and model checking},
journal = {Expert Systems with Applications},
volume = {44},
pages = {367-385},
year = {2016},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2015.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S0957417415006557},
author = {Sergio Alejandro Gómez and Anca Goron and Adrian Groza and Ioan Alfred Letia},
keywords = {Safety systems, Defeasible argumentation, Model checking, Hybrid Logics, Defeasible Logic Programming, Hybrid Logic Model Checker},
abstract = {Although the continuous safety technology advances in fields like air traffic control (ATC) systems or medical devices, the crux of safety assurance still comes down to human decision makers, which, within the context of having to define priorities while simultaneously considering different contextual criteria, present a constant high risk of erroneous decisions. We illustrate in this article a recommender framework for assisting flight controllers, which combines argumentation theory and model checking in the evaluation of trade-offs and compromises to be made in the presence of incomplete and potentially inconsistent information. We view a Hybrid Kripke model as a description of an ATC domain and we apply a rational decision strategy based on Hybrid Logics and Defeasible Reasoning to assist the process of model update when the system has to accommodate new properties or norm constraints. When the model fails to verify a property, a defeasible logic program is used to analyze the current state and perform updating operations on the model. The introduced decision making framework is tested on a recommender system in ATC and model update is demonstrated with respect to the verification and adaption of unmanned aerial vehicles routes in the air traffic space. The results show an important potential for the presented framework to be integrated directly into existing decision-making routines for achieving higher accuracy in recommender system methods.}
}
@article{RUSTIA202128,
title = {Online semi-supervised learning applied to an automated insect pest monitoring system},
journal = {Biosystems Engineering},
volume = {208},
pages = {28-44},
year = {2021},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2021.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S1537511021001069},
author = {Dan Jeric Arcega Rustia and Chen-Yi Lu and Jun-Jee Chao and Ya-Fang Wu and Jui-Yung Chung and Ju-Chun Hsu and Ta-Te Lin},
keywords = {semi-supervised learning, image recognition, feature extraction, insect monitoring, integrated pest management},
abstract = {The unavailability and variability of training samples are the two essential concerns in the training of deep neural network models for image classification. For automated image monitoring systems, these problems are difficult when training a model through supervised learning methods because of the time and effort required. This paper proposes an adaptive solution to this problem by applying online semi-supervised learning to an automated insect pest monitoring system. The method used includes unsupervised pseudo-labelling of insect images and the training of semi-supervised classifier models for insect image recognition. The pseudo-labelling algorithm includes three major components: image labelling, label reconfirmation, and sample cleaning. Experiments were conducted on two unlabelled 1-year insect image datasets to evaluate the efficacy of the proposed method. It was found that the pseudo-labelling algorithm could achieve accuracy up to 0.963, hence enabling automated training data collection. The temporal improvement of the insect recognition performance by including new training data to retrain the classifier model was comparable in performance to the supervised learning approach as evaluated by cluster density, silhouette score, and F1-score. The proposed method was also able to automatically collect quality samples and train models regardless of the complexity of the images, making it a good alternative to replace laborious supervised learning. The proposed method can prevent contamination of a training dataset when images from new locations are collected. The presented techniques may also be used in other continuous learning applications that require automated training data collection and online model update.}
}
@article{NIAN2021103838,
title = {Civil engineering stability inspection based on computer vision and sensors},
journal = {Microprocessors and Microsystems},
volume = {82},
pages = {103838},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2021.103838},
url = {https://www.sciencedirect.com/science/article/pii/S0141933121000181},
author = {Hongfen Nian},
keywords = {Monitoring applications, Computer vision, Accelerometer, Non-destructive evaluation, Conventional-contact displacement sensors},
abstract = {A computer that combines the purchase of vision technology and remote cameras and drones offers a promising non-contact solution for the state evaluation of civil infrastructure. This system's ultimate goal is too automatically and reliably converted to actionable information image or video data. This white paper provides an overview of computer vision technology's latest development and applies it to the state evaluation of private infrastructure. Deep learning has been applied to various computer vision; deep learning course covers most of the application. Each application has its architecture, such as the input image and labels data loss function. To explain computer vision architecture in the following figure. Review of the work can be divided into two types: application checks and application monitoring. Review inspection applications include context identifiers, local and global features, visible damage, and changes in the reference image. Monitoring applications described herein include static and dynamic strain modal analysis measurement and displacement measurement. Next, several key challenges continue to move towards civilian infrastructure automation and monitoring of vision-based. Finally, aim to address some of the ongoing challenges in our work.}
}
@article{SUN2020107360,
title = {AUV path following controlled by modified Deep Deterministic Policy Gradient},
journal = {Ocean Engineering},
volume = {210},
pages = {107360},
year = {2020},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2020.107360},
url = {https://www.sciencedirect.com/science/article/pii/S0029801820303917},
author = {Yushan Sun and Xiangrui Ran and Guocheng Zhang and Xiangbin Wang and Hao Xu},
keywords = {AUV, Path following control, Deep deterministic policy gradient, Sample pools, Average motion critic},
abstract = {This study proposes a Deep Deterministic Policy Gradient algorithm based on optimized sample pools and average motion critic network (OSAM-DDPG) to realize the path following control of autonomous underwater vehicles (AUVs). The ideas of optimizing the sampling mode and the evaluation of motion are proposed to improve the efficiency of algorithm. OSAM-DDPG is used to train the force-to-state mapping of an AUV's dynamical model to realize its control. In the simulation test, the OSAM-DDPG algorithm only needs some episodes to obtain the complete control strategy. Based on the experience gained from the training, the problems of various paths following in the interference environment can be addressed, and the results demonstrate that the effect of path following control based on OSAM-DDPG is better than S-plane.}
}
@article{CHEN2020104134,
title = {Characteristic analysis and optimal survey area definition for semi-airborne transient electromagnetics},
journal = {Journal of Applied Geophysics},
volume = {180},
pages = {104134},
year = {2020},
issn = {0926-9851},
doi = {https://doi.org/10.1016/j.jappgeo.2020.104134},
url = {https://www.sciencedirect.com/science/article/pii/S0926985120301324},
author = {Chengdong Chen and Huaifeng Sun},
keywords = {Semi-airborne, Transient electromagnetics, Characteristics analysis, Optimal survey area},
abstract = {Semi-airborne transient electromagnetics (SATEM) is a versatile tool in quick geophysical surveys at a low cost. This method usually uses a grounded-wire source on the surface to transmit electromagnetic field into the earth and a receiver hanging on unmanned aerial vehicles to acquire the secondary field in the air. Compared to conventional transient electromagnetic methods, the grounded-wire system has complications caused by the combined effects of the transmitter wire and the grounding points, with complications affecting the simplicity of the secondary response. In this study, we use the electric dipole integral algorithm to simulate the SATEM responses in a layered earth model and compare the responses with different offsets, receiver heights, and geometry positions of the receiver. With these analyses, we define the optimal survey area for a layered earth to be the area with a monotonic decay rate of the secondary field. We establish an ellipse boundary distribution function to determine the suitable and unsuitable survey areas, and areas outside the ellipse are the suitable or optimal survey areas. Two examples with short and long line sources are used to test the definition and demonstrate the usefulness of the definition. The ellipse boundary function can be used in real SATEM survey designs.}
}
@article{HABIBNIA2021107141,
title = {Active control assessments towards optimizing the performance of a cycloidal rotor at hover},
journal = {Aerospace Science and Technology},
volume = {119},
pages = {107141},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107141},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821006519},
author = {M. Habibnia and J. Pascoa},
keywords = {Cycloidal rotor, Hover state, CFD simulations, Neural network optimization, Active control, Performance analysis},
abstract = {The present study demonstrates an improved performance of cycloidal rotors by actively controlling the pitching oscillations and rotational speeds. The computational fluid dynamics (CFD) coupled with artificial neural network (ANN) were the methodologies used in the optimization analysis for the hover-state operation rather than the take-off mode under ground effects [1]. The former is carried out to obtain numerical predictions at various operating conditions for an UAV-scale cyclorotor. The oscillating-rotating blades and the corresponding flowfield is computed unsteadily along the complete circular trace for performance considerations. From CFD simulations, the optimum operational state is predicted for a 30∘ and 500 (rpm) pitch angle and rotating speed, respectively. On a second step, by training the ANN with the CFD database at various operating conditions and parameters, the ANN was then capable of analyzing the optimum states for operating at different conditions. The pitching oscillation schedule is then optimized for each rotational speed by using ANN and for each azimuthal location over the traversing trace. This will imply to perform on-board control in active mode for the blades, rather than assigning constant pitching oscillations for all operating states. This active control concept showed to be a potential approach to enhance the cyclorotor efficiency by 12 percent in average.}
}
@article{TARDAGUILA2021100005,
title = {Smart applications and digital technologies in viticulture: A review},
journal = {Smart Agricultural Technology},
volume = {1},
pages = {100005},
year = {2021},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2021.100005},
url = {https://www.sciencedirect.com/science/article/pii/S2772375521000058},
author = {Javier Tardaguila and Manfred Stoll and Salvador Gutiérrez and Tony Proffitt and Maria P. Diago},
keywords = {Digital viticulture, Precision viticulture, Vineyard monitoring, Remote and proximal sensing, Vineyard app, Vineyard robotics, Artificial intelligence},
abstract = {It is important to continuously monitor the long-term impact of viticultural management practices and assess opportunities for improving the environmental footprint of vineyard operations. This is particularly relevant to the wine industry as growers face disruptive challenges caused by climate change, shortages of labour and escalating production costs. In recent years there has been considerable development and testing of non-invasive digital technologies, some of which have already demonstrated an improvement in the way that wine grapes are grown, managed and harvested to produce quality wines in a manner that is both environmentally and economically sustainable. In this paper, we describe a number of sensing technologies including spectroscopy, multispectral and hyperspectral imaging, chlorophyll fluorescence, thermography, electrical resistivity, laser imaging detection and ranging, and computer vision and the platforms where they are generally mounted or embedded for either proximal or remote monitoring. Artificial intelligence is also discussed as it is useful as a means of transforming data into different pieces of information used by the grape grower for making informed decisions. A key objective of using these technologies is to obtain and supply data and information to grape growers and wine producers as a basis for improving land and vine management through a more-informed decision-making process. The current and future application of these technologies and artificial intelligence in vineyards are discussed in relation to soil properties and topography, vegetative growth, canopy architecture, nutrient and water status, pests and diseases, crop forecasting, yield and fruit composition, vineyard sampling, targeted management and selective harvesting. The principles behind how these technologies operate are also described. While the technologies have enormous potential for growers, their adoption and use will depend on user-friendly software and devices, together with affordable costs, at the field scale.}
}
@article{SIMAK2020271,
title = {Real time light-sport aircraft tracking using SRD860 band},
journal = {Transportation Research Procedia},
volume = {51},
pages = {271-282},
year = {2020},
note = {INAIR 2020 - CHALLENGES OF AVIATION DEVELOPMENT},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2020.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S2352146520308875},
author = {Vojtech Šimák and Filip Škultéty},
keywords = {light-sport aircraft, tracking, flight parameters, on board unit, FLARM},
abstract = {This paper examines the purpose of light-sport aircraft (LSA) tracking using our proposed electronic on board unit. LSA are attracting an increasing interest due to their affordability and technological advancement. Increasing the volume of this traffic, however, can lead to dangerous situations, such as mid-air collisions. Previous studies indicate that despite the commonly used concept "see and avoid", there are dozens of collisions in general aviation every year. The paper presents innovative methods of tracking the position of light aircraft. It is mainly focused on the well-known technology FLARM – the traffic awareness and collision avoidance system for gliders, LSA, and UAVs. The main goal is to design and build an on board FLARM compatible device that will transmit aircraft position, which can be observed on an online map in real-time. The major drawback of this approach is the need for ground infrastructure such as receivers which have limited coverage and must be constantly online. The advantage of the proposed device is the implementation of a system for logging flight parameters on an SD card. The distinguishing feature of the OBU is the ripple from the 28V mains, which can be used to diagnose the aircraft’s electrical system. In order to identify the overall functionality and capabilities of the device, preliminary flight tests were performed. The overall results and limitations are summarized in the discussion. The OBU is designed and tailored mostly for declared training organizations and aeroplane rentals.}
}
@article{LUO2020101100,
title = {Real-time smart video surveillance to manage safety: A case study of a transport mega-project},
journal = {Advanced Engineering Informatics},
volume = {45},
pages = {101100},
year = {2020},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2020.101100},
url = {https://www.sciencedirect.com/science/article/pii/S1474034620300690},
author = {Hanbin Luo and Jiajing Liu and Weili Fang and Peter E.D. Love and Qunzhou Yu and Zhenchuan Lu},
keywords = {Computer vision, Construction safety, Video surveillance, Stuck-by accident},
abstract = {There is a tendency for accidents and even fatalities to arise when people enter hazardous work areas during the construction of projects in urban areas. A limited amount of research has been devoted to developing vision-based proximity warning systems that can determine when people enter a hazardous area automatically. Such systems, however, are unable to identify specific hazards and the status of a piece of plant (e.g., excavator) in real-time. In this paper, we address this limitation and develop a real-time smart video surveillance system that can detect people and the status of plant (i.e. moving or stationary) in a hazardous area. The application of this approach is demonstrated during the construction of a mega-project, the Wuhan Rail Transit System in China. We reveal that our combination of computer vision and deep learning can accurately recognize people in a hazardous work area in real-time during the construction of transport projects. Our developed systems can provide instant feedback concerning unsafe behavior and thus enable appropriate actions to be put in place to prevent their re-occurrence.}
}
@article{RAHMAN2021103083,
title = {A secure, private, and explainable IoHT framework to support sustainable health monitoring in a smart city},
journal = {Sustainable Cities and Society},
volume = {72},
pages = {103083},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103083},
url = {https://www.sciencedirect.com/science/article/pii/S221067072100367X},
author = {Md Abdur Rahman and M. Shamim Hossain and Ahmad J. Showail and Nabil A. Alrajeh and Mohammed F. Alhamid},
keywords = {Sustainable cities, Blockchain, Off-chain, Connected living, 5G healthcare vertical, Internet of health things, Explainable AI},
abstract = {Internet of Health Things (IoHT) have allowed connected health paradigm ubiquitous. 5 G supported healthcare vertical allows IoHT to offer connected health monitoring with quality of service and ultra-low latency. Deep learning has shown potential in processing massive amount of IoHT data that are generated daily, automate connected healthcare workflows, and help in decision making processes. However, three important challenges need to be addressed to attain long term healthcare-related sustainability – data security, data privacy, and social acceptance of deep learning process. In this paper, we propose a framework that will allow healthcare sustainability through the following contributions 1) ensure privacy of training dataset, 2) support the aggregation of the global model gradients through a private Blockchain-brokered entity, 3) support trustworthiness and provenance of the federated clients by blockchain and off-chain, 4) share the dataset, train the model and share trained model among the federated clients in an encrypted fashion, and 5) add explainability and reasoning of deep learning process to make the model acceptable by the society. We will present the detailed design of our proposed sustainable system, the implementation details and test results. The test results show promising prospect of achieving sustainability of IoHT-enabled connected health applications.}
}
@article{CHUNG2021102455,
title = {Applications of smart technologies in logistics and transport: A review},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {153},
pages = {102455},
year = {2021},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2021.102455},
url = {https://www.sciencedirect.com/science/article/pii/S1366554521002192},
author = {Sai-Ho Chung},
keywords = {Smart Technologies, Autonomous, Logistics, Transport},
abstract = {The emergence of smart technologies (STs) is inducing significant transformation in logistics and transport nowadays. STs refer to the applications of artificial intelligence and data science technologies, such as machine learning, big data, to create cognitive awareness (autonomous) of an object with the support of information and communication technologies such as IoT and Blockchain. Currently, many applications of STs have demonstrated potential promise in enhancing the efficiency and effectiveness in various logistics operations and transportation systems. Further, these new advanced technologies create huge modelling challenges to traditional optimization approaches and thus create rich new research opportunities for developing new optimization methodologies in the field of logistics and transport studies. As such, our aim is to conduct a comprehensive review on noteworthy contributions made in the applications of STs in improving logistics operations and transportation network efficiency. More importantly, we explore and discuss the technical difficulties encountered by researchers in the development of optimization methodologies caused by the applications of STs. Finally, we conclude the studies with suggestions for future research.}
}
@article{NASSER2021103048,
title = {n-Gram based language processing using Twitter dataset to identify COVID-19 patients},
journal = {Sustainable Cities and Society},
volume = {72},
pages = {103048},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103048},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721003322},
author = {Nidal Nasser and Lutful Karim and Ahmed {El Ouadrhiri} and Asmaa Ali and Nargis Khan},
keywords = {Language categorization, Character -gram, Word -gram, TFIDF, LSVM, Natural language processing},
abstract = {Due to the rapid growth of electronic documents, e.g., tweets, blogs, Facebook posts, snaps in different languages that use the same writing script, language categorization, and processing have great importance. For instance, to identify COVID-19 positive patients or people’s emotions on COVID-19 pandemic from tweets written in 35 different languages faster and accurate, language categorization and processing of tweets is significantly essential. Among many language categorization and processing techniques, character and word n-gram based techniques are very popular and simple but very efficient for categorizing and processing both short and large documents. One of the fundamental problems of language processing is the efficient use of memory space in implementing a technique so that a vast collection of documents can be easily categorized and processed. In this paper, we introduce a framework that categorizes the language of tweets using n-gram based language categorization technique and further processes the tweets using the machine-learning approach, Linear Support Vector Machine (LSVM), that may be able to identify COVID-19 positive patients. We evaluate and compare the performance of the proposed framework in terms of language categorization accuracy, precession, recall, and F-measure over n-gram length. The proposed framework is scalable as many other applications that involve extracting features and classifying languages collected from social media, and different types of networks may use this framework. This proposed framework, also being a part of health monitoring and improvement, tends to achieve the goal of having a sustainable society.}
}
@article{RAN2021389,
title = {Scene perception based visual navigation of mobile robot in indoor environment},
journal = {ISA Transactions},
volume = {109},
pages = {389-400},
year = {2021},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2020.10.023},
url = {https://www.sciencedirect.com/science/article/pii/S0019057820304183},
author = {T. Ran and L. Yuan and J.b. Zhang},
keywords = {Indoor mobile robot, Visual navigation, Convolution neural networks, Scene perception, Obstacle avoidance},
abstract = {Only vision-based navigation is the key of cost reduction and widespread application of indoor mobile robot. Consider the unpredictable nature of artificial environments, deep learning techniques can be used to perform navigation with its strong ability to abstract image features. In this paper, we proposed a low-cost way of only vision-based perception to realize indoor mobile robot navigation, converting the problem of visual navigation to scene classification. Existing related research based on deep scene classification network has lower accuracy and brings more computational burden. Additionally, the navigation system has not yet been fully assessed in the previous work. Therefore, we designed a shallow convolutional neural network (CNN) with higher scene classification accuracy and efficiency to process images captured by a monocular camera. Besides, we proposed an adaptive weighted control (AWC) algorithm and combined with regular control (RC) to improve the robot’s motion performance. We demonstrated the capability and robustness of the proposed navigation method by performing extensive experiments in both static and dynamic unknown environments. The qualitative and quantitative results showed that the system performs better compared to previous related work in unknown environments.}
}
@article{POCAS2017177,
title = {Hyperspectral-based predictive modelling of grapevine water status in the Portuguese Douro wine region},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {58},
pages = {177-190},
year = {2017},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2017.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0303243417300399},
author = {Isabel Pôças and João Gonçalves and Patrícia Malva Costa and Igor Gonçalves and Luís S. Pereira and Mario Cunha},
keywords = {Handheld spectroradiometer, Statistical and machine learning techniques, Reflectance data, Vegetation indices, Vineyard, Crop water deficit},
abstract = {In this study, hyperspectral reflectance (HySR) data derived from a handheld spectroradiometer were used to assess the water status of three grapevine cultivars in two sub-regions of Douro wine region during two consecutive years. A large set of potential predictors derived from the HySR data were considered for modelling/predicting the predawn leaf water potential (Ψpd) through different statistical and machine learning techniques. Three HySR vegetation indices were selected as final predictors for the computation of the models and the in-season time trend was removed from data by using a time predictor. The vegetation indices selected were the Normalized Reflectance Index for the wavelengths 554nm and 561nm (NRI554;561), the water index (WI) for the wavelengths 900nm and 970nm, and the D1 index which is associated with the rate of reflectance increase in the wavelengths of 706nm and 730nm. These vegetation indices covered the green, red edge and the near infrared domains of the electromagnetic spectrum. A large set of state-of-the-art analysis and statistical and machine-learning modelling techniques were tested. Predictive modelling techniques based on generalized boosted model (GBM), bagged multivariate adaptive regression splines (B-MARS), generalized additive model (GAM), and Bayesian regularized neural networks (BRNN) showed the best performance for predicting Ψpd, with an average determination coefficient (R2) ranging between 0.78 and 0.80 and RMSE varying between 0.11 and 0.12MPa. When cultivar Touriga Nacional was used for training the models and the cultivars Touriga Franca and Tinta Barroca for testing (independent validation), the models performance was good, particularly for GBM (R2=0.85; RMSE=0.09MPa). Additionally, the comparison of Ψpd observed and predicted showed an equitable dispersion of data from the various cultivars. The results achieved show a good potential of these predictive models based on vegetation indices to support irrigation scheduling in vineyard.}
}
@article{KALIN2019143,
title = {Defoliation estimation of forest trees from ground-level images},
journal = {Remote Sensing of Environment},
volume = {223},
pages = {143-153},
year = {2019},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2018.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S0034425718305741},
author = {Ursula Kälin and Nico Lang and Christian Hug and Arthur Gessler and Jan Dirk Wegner},
abstract = {In this paper, we propose to estimate tree defoliation from ground-level RGB photos with convolutional neural networks (CNN). Tree defoliation is usually assessed with field campaigns, where experts estimate multiple tree health indicators per sample site. Campaigns span entire countries to come up with a holistic, nationwide picture of forest health. Surveys are very laborious, expensive, time-consuming and need a large number of experts. We aim at making the monitoring process more efficient by casting tree defoliation estimation as an image interpretation problem. What makes this task challenging is the strong variance in lighting, viewpoint, scale, tree species, and defoliation types. Instead of accounting for each factor separately through explicit modeling, we learn a joint distribution directly from a large set of annotated training images following the end-to-end learning paradigm of deep learning. The proposed workflow works as follows: (i) Human experts visit individual trees in forests distributed all over Switzerland, (ii) acquire one photo per tree with an off-the-shelf, hand-held RGB camera, and (iii) assign a defoliation value. The CNN approach is (iv) trained on a subset of the images with expert defoliation assessments and (v) tested on a hold-out part to check predicted values against ground truth. We evaluate our supervised method on three data sets with different level of difficulty acquired in Swiss forests and achieve an average mean absolute error (avgMAE) of 7.6% for the joint data set after cross-validation. Comparison to a group of human experts on one of the data sets shows that our CNN approach performs only 0.9% points worse. We show that tree defoliation estimation from ground-level RGB images with a CNN works well and achieves performance close to human experts.}
}
@article{VAYSSADE2019767,
title = {Automatic activity tracking of goats using drone camera},
journal = {Computers and Electronics in Agriculture},
volume = {162},
pages = {767-772},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918312894},
author = {Jehan-Antoine Vayssade and Rémy Arquet and Mathieu Bonneau},
keywords = {Creole goats, Automatic detection, Drone, Unmanned aerial vehicle, Image analysis, Monitoring, Animal activity},
abstract = {Monitoring the position of animals in the outdoors can provide useful information in ecology and in agriculture. A common method is to use active sensors, such as GPS, to record their positions at constant intervals of time. But using active sensors can rapidly become expensive when several animals have to be monitored at the same time. Another method is to use a passive sensor to monitor the entire flock of animals. In this article, we propose a method to process images taken by a commercial drone in order to automate the tracking of animal activities. We developed a method that automatically detects goats from the images and tracks their activity using a combination of thresholding and supervised classification methods. We tested our method on 571 drone images taken over 11 days and found a sensitivity of 74% for animal detection and 78.3% for activity detection.}
}
@article{BOSQUET2020103615,
title = {STDnet: Exploiting high resolution feature maps for small object detection},
journal = {Engineering Applications of Artificial Intelligence},
volume = {91},
pages = {103615},
year = {2020},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2020.103615},
url = {https://www.sciencedirect.com/science/article/pii/S0952197620300828},
author = {Brais Bosquet and Manuel Mucientes and Víctor M. Brea},
keywords = {Small object detection, Convolution neural networks (ConvNets), Deep learning},
abstract = {The accuracy of small object detection with convolutional neural networks (ConvNets) lags behind that of larger objects. This can be observed in popular contests like MS COCO. This is in part caused by the lack of specific architectures and datasets with a sufficiently large number of small objects. Our work aims at these two issues. First, this paper introduces STDnet, a convolutional neural network focused on the detection of small objects that we defined as those under 16 × 16 pixels. The high performance of STDnet is built on a novel early visual attention mechanism, called Region Context Network (RCN), to choose the most promising regions, while discarding the rest of the input image. Processing only specific areas allows STDnet to keep high resolution feature maps in deeper layers providing low memory overhead and higher frame rates. High resolution feature maps were proved to be key to increasing localization accuracy in such small objects. Second, we also present USC-GRAD-STDdb, a video dataset with more than 56,000 annotated small objects in challenging scenarios. Experimental results over USC-GRAD-STDdb show that STDnet improves the AP@.5 of the best state-of-the-art object detectors for small target detection from 50.8% to 57.4%. Performance has also been tested in MS COCO for objects under 16 × 16 pixels. In addition, a spatio-temporal baseline network, STDnet-bST, has been proposed to make use of the information of successive frames, increasing the AP@.5 of STDnet in 2.3%. Finally, optimizations have been carried out to be fit on embedded devices such as Jetson TX2.}
}
@article{SHUKLA2016490,
title = {Application of robotics in onshore oil and gas industry—A review Part I},
journal = {Robotics and Autonomous Systems},
volume = {75},
pages = {490-507},
year = {2016},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2015.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0921889015002006},
author = {Amit Shukla and Hamad Karki},
keywords = {Robotics, Automation, In-pipe inspection robots, Tank inspection robots, NDT, UAV, Wireless sensor networks (WSN), Oil and gas exploration},
abstract = {With ever increasing global demand and depleting resources for fossil fuels, oil and gas industry is now positively looking for advanced robotic solutions to increase their productivity and safety. With time easy resources of the fossil fuels are shrinking and newly searched reservoirs, to feed supply demands of global consumption, are mostly located in extreme environmental conditions such as hot deserts, deep water and arctic zone etc. Production of the fossil fuels, in such inhospitable environmental conditions, poses difficult challenges to health, safety and environment (HSE). Tragic incidents like Exxon Valdez and Deepwater Horizon oil spills are examples of such challenges. Therefore, oil and gas industry has lot to learn from successful implementation of robotics and automation for dull, dirty and dangerous (3D) tasks of manufacturing industry. Most of the robotics technologies, currently used in the oil and gas industry, are mainly focused on inspection, maintenance and repair (IMR) of plant facilities with higher frequency and accuracy. Fundamental idea, involved in the automatization of these processes, is based on the principle of teleoperation with skilled operator. Automation of 3D tasks not only improves HSE standards but also lead to much needed economic efficiency by reducing production cycle, floor space and number of staff members required for continuous inspection and manipulation of plant facilities. Considering the risks involved in this industry usage of completely autonomous robots, first without achieving very high reliability, is still a far fetch choice. Therefore, semi-autonomous robots, where actions are performed by robots but cognitive decisions are still taken by skilled operator, is an excellent choice for this industry as a near future solution. In the onshore oil and gas industry robotic solutions are used both in upstream and downstream processes, such as site survey, drilling, production and transportation, mainly focused in the form of in-pipe inspection robots (IPIRs), tank inspection robots (TIRs), unmanned aerial vehicles (UAVs) and wireless sensor networks (WSNs) etc. This paper presents the state of art robotic solutions currently used in onshore oil and gas facilities.}
}
@article{BROOK2020111679,
title = {A smart multiple spatial and temporal resolution system to support precision agriculture from satellite images: Proof of concept on Aglianico vineyard},
journal = {Remote Sensing of Environment},
volume = {240},
pages = {111679},
year = {2020},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2020.111679},
url = {https://www.sciencedirect.com/science/article/pii/S0034425720300481},
author = {A. Brook and V. {De Micco} and G. Battipaglia and A. Erbaggio and G. Ludeno and I. Catapano and A. Bonfante},
keywords = {CNN image reconstruction, Pan-sharpening, Vineyard plant status, Dendro-ecological analysis, Plant hydraulics, Precision agriculture, Sentinel-2A, UAV, Wood anatomy, And isotopes},
abstract = {In this century, one of the main objectives of agriculture is sustainability addressed to achieve food security, based on the improvement of use efficiency of farm resources, the increasing of crop yield and quality, under climate change conditions. The optimization of farm resources, as well as the control of soil degradation processes (e.g., soil erosion), can be realized through crop monitoring in the field, aiming to manage the local spatial variability (time and space) with a high resolution. In the case of high profitability crops, as the case of vineyards for high-quality wines, the capability to manage and follow spatial behavior of plants during the season represents an opportunity to improve farmer incomes and preserve the environmental health. However, any field monitoring represents an additional cost for the farmer, which slows down the objective of a diffuse sustainable agriculture. Satellite multispectral images have been widely used for production management in large areas. However, their observation is limited by the pre-defined and fixed scale with relatively coarse spatial resolution, resulting in limitations in their application. In this paper, encouraged by recent achievements in convolutional neural network (CNN), a multiscale full-connected CNN is constructed for the pan-sharpening of Sentinel-2A images by UAV images. The reconstructed data are validated by independent multispectral UAV images and in-situ spectral measurements. The reconstructed Sentinel-2A images provide a temporal evaluation of plant responses using selected vegetation indices. The proposed methodology has been tested on plant measurements taken either in-vivo and through the retrospective reconstruction of the eco-physiological vine behavior, by the evaluation of water conductivity and water use efficiency indexes from anatomical and isotopic traits recorded in vine trunk wood. In this study, the use of such a methodology able to combine the pro and cons of space-borne and UAVs data to evaluate plant responses, with high spatial and temporal resolution, has been applied in a vineyard of southern Italy by analyzing the period from 2015 to 2018. The obtained results have shown a good correspondence between the vegetation indexes obtained from reconstructed Sentinel-2A data and plant hydraulic traits obtained from tree-ring based retrospective reconstruction of vine eco-physiological behavior.}
}
@article{BAEK2021103915,
title = {A critical review of text-based research in construction: Data source, analysis method, and implications},
journal = {Automation in Construction},
volume = {132},
pages = {103915},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103915},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521003666},
author = {Seungwon Baek and Wooyong Jung and Seung H. Han},
keywords = {Construction, Review, Text-based research, Natural language processing, Text mining, Unstructured text data, Data source, Text analysis method},
abstract = {The advancement of natural language processing and text mining techniques facilitate automatic non-trivial pattern extraction and knowledge discovery from text data. However, text-based research has received less attention compared to image- and sensor-based research in the construction industry. Hence, this paper performs a comprehensive review to understand the current state and future insights of text analytics focusing on the data source and analysis method. This study identifies various kinds of text data sources from project documents as well as open data in the websites. In addition, the review finds that the ontology- and rule-based approach has been dominant, at the same time, recent research has attempted to apply the state-of-the-art machine learning methods. It is envisioned that there are potential advancements in construction engineering and management based on the latest text analysis methods along with the enriched data by the digital transformation.}
}
@article{LI2021106054,
title = {A high-precision detection method of hydroponic lettuce seedlings status based on improved Faster RCNN},
journal = {Computers and Electronics in Agriculture},
volume = {182},
pages = {106054},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106054},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921000727},
author = {Zhenbo Li and Ye Li and Yongbo Yang and Ruohao Guo and Jinqi Yang and Jun Yue and Yizhe Wang},
keywords = {Hydroponic lettuce seedlings, Deep learning, Object detection, Faster RCNN},
abstract = {In order to improve the efficiency and reduce high cost for seedlings sorting in the raising process of hydroponic lettuce seedlings, we propose an automatic detection method for hydroponic lettuce seedlings based on improved Faster RCNN framework, taking the dead and double-planting status of seedlings growing in a single hole as our research objects. Since the characteristics of hydroponic lettuce seedlings are dense and small in the images, our model uses High Resolution Network (HRNet) as the backbone network for image feature extraction so as to obtain reliable and high- resolution feature expressions. Besides, we adopt focal loss as the classification loss in the Region Proposal Network (RPN) stage to address the imbalance between difficult and easy samples in seedlings classification. We also employ the Region of Interest (RoI) Align instead of the RoI Pooling layer to improve the detection accuracy of seedlings in the different status. The results show that the mean average precision of our method for the hydroponic lettuce seedlings is 86.2%, which is higher than RetinaNet, SSD, Cascade RCNN, FCOS and other detectors. Compared with different feature extraction networks, the detection accuracy of adopting HRNet performs nicely. Therefore, our method presented for the detection of hydroponic lettuce seedlings status can achieve high accuracy and identify seedlings in a problematic status well, which will provide technical support for automatic seedlings detection of hydroponic lettuce.}
}
@article{SPINOSA2021104180,
title = {Data-driven order reduction in Hammerstein–Wiener models of plasma dynamics},
journal = {Engineering Applications of Artificial Intelligence},
volume = {100},
pages = {104180},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104180},
url = {https://www.sciencedirect.com/science/article/pii/S0952197621000270},
author = {Angelo Giuseppe Spinosa and Arturo Buscarino and Luigi Fortuna and Matteo Iafrati and Giuseppe Mazzitelli},
keywords = {Dimensionality reduction, Machine learning, System identification, System modelling, Tokamak},
abstract = {The problem of identifying and therefore modelling a complex system makes use of various techniques and strategies whose computational efforts change drastically. It is not straightforward to analyse the complexity of a system as a whole because of myriads of factors, such as the way of arranging its constituent items and how they interact mutually. Intuitively, the bigger the set of sub-parts is, the more numerous the degrees of freedom are. Additionally there is not a specific and global criterion for optimally determining an always-working method that makes the identification procedure easier, especially in those contexts where the number of unknown variables can make the difference. In this sense, plasma physics is not an exception, being a field where complex phenomena, such as plasma instabilities, easily arise. From a systemic, high-level perspective, the possibility of employing a model that can describe these behaviours is particularly appealing, since it can be exploited for control applications that have not to neglect the underlying physical nature. So far, most of the work published in literature has focused on more physically-grounded models, which could describe how plasma physics works in detail, but very little has been done as mentioned before, with the aim of providing a computational, yet system-oriented, insight of these physical systems. Starting from real flux measurements recorded thanks to suitable sensors installed inside Tokamak machines, the paper attempts to provide a solution based on already known tools available in literature to solve the aforementioned problem, by combining both machine learning-based strategies for dimensionality reduction and control theory. More in detail, the whole architecture presented in this work is founded on the use of auto-encoders, which are intrinsically capable of compressing input features thanks to their structure, and Hammerstein–Wiener models, which are structurally endowed with both linear and non-linear sub-modellers for better capturing the whole dynamics to identify. By merging these functional blocks, it is possible to address both the issue of establishing the most relevant sub-set of variables for identification and the identification problem itself, resulting in a fully customisable approach to data-driven modelling.}
}
@article{SHARIQ2020109979,
title = {Revolutionising building inspection techniques to meet large-scale energy demands: A review of the state-of-the-art},
journal = {Renewable and Sustainable Energy Reviews},
volume = {130},
pages = {109979},
year = {2020},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2020.109979},
url = {https://www.sciencedirect.com/science/article/pii/S1364032120302707},
author = {M. Hasan Shariq and Ben Richard Hughes},
keywords = {Infrared thermography, Building inspection, Building energy audit, Real-time thermal modelling, Photogrammetry, Drone 3D mapping},
abstract = {The building sector is responsible for 40% of the overall energy consumption in the EU. Building defects, such as heat losses, moisture, and air leakages, inevitably causes inefficient space heating or cooling, which accounts considerably towards this high energy consumption and associated greenhouse gas emissions. In order to meet the EU's 2050 carbon reduction targets, building inspection techniques need to be revolutionised. Current methods rely on terrestrial or hand-held infrared thermography (IRT) to detect building defects. However, for a large-scale inspection, these methods are generally labour-intensive, time-consuming, costly and often inefficient. The aim of this paper is to highlight the possibility of integrating various state-of-the-art technologies and computational methods with IRT including drones, photogrammetry and AI. This paper presents a comprehensive review of relevant scientific papers and recent developments in such technologies that can retrofit the existing manually intensive methods. Among the findings of this research, feasibility of monocular thermographic photogrammetry integrated on a drone (quadcopter) promises a time-efficient, cost-effective and near-autonomous solution to large-scale building inspections.}
}
@article{MONDEJAR2021148539,
title = {Digitalization to achieve sustainable development goals: Steps towards a Smart Green Planet},
journal = {Science of The Total Environment},
volume = {794},
pages = {148539},
year = {2021},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2021.148539},
url = {https://www.sciencedirect.com/science/article/pii/S0048969721036111},
author = {Maria E. Mondejar and Ram Avtar and Heyker Lellani Baños Diaz and Rama Kant Dubey and Jesús Esteban and Abigail Gómez-Morales and Brett Hallam and Nsilulu Tresor Mbungu and Chukwuebuka Christopher Okolo and Kumar Arun Prasad and Qianhong She and Sergi Garcia-Segura},
keywords = {Digitalization, Food-water-energy nexus, Internet of things, Geographic information system (GIS), Sustainable development},
abstract = {Digitalization provides access to an integrated network of unexploited big data with potential benefits for society and the environment. The development of smart systems connected to the internet of things can generate unique opportunities to strategically address challenges associated with the United Nations Sustainable Development Goals (SDGs) to ensure an equitable, environmentally sustainable, and healthy society. This perspective describes the opportunities that digitalization can provide towards building the sustainable society of the future. Smart technologies are envisioned as game-changing tools, whereby their integration will benefit the three essential elements of the food-water-energy nexus: (i) sustainable food production; (ii) access to clean and safe potable water; and (iii) green energy generation and usage. It then discusses the benefits of digitalization to catalyze the transition towards sustainable manufacturing practices and enhance citizens' health wellbeing by providing digital access to care, particularly for the underserved communities. Finally, the perspective englobes digitalization benefits by providing a holistic view on how it can contribute to address the serious challenges of endangered planet biodiversity and climate change.}
}
@article{YANG2022104118,
title = {Intelligent bridge management via big data knowledge engineering},
journal = {Automation in Construction},
volume = {135},
pages = {104118},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.104118},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521005690},
author = {Jianxi Yang and Fangyue Xiang and Ren Li and Luyi Zhang and Xiaoxia Yang and Shixin Jiang and Hongyi Zhang and Di Wang and Xinlong Liu},
keywords = {Intelligent bridge management, Artificial intelligence, Big data knowledge engineering, Knowledge graph, Framework},
abstract = {Fully combining the emerging intelligent technologies, such as big data and artificial intelligence, to realize the effective data fusion of bridge management with multi-source, autonomous, massive, heterogeneous features, and to further improve the capability of domain knowledge sharing and services have become the urgent demand and future development trend in the field of bridge engineering. This paper summarizes the business background and big data characteristics of bridge management, and represents a brief review of related work. According to the big data knowledge engineering paradigm, this paper proposes a novel BigKE-based intelligent bridge management and maintenance framework consisting of the layers of data-sources, storage and computing, knowledge representation, knowledge computing, and knowledge services. The corresponding main research contents involved in each layer are discussed as well. Finally, we point out some possible application scenarios and main challenges of the proposed framework, which elaborate on areas for future research.}
}
@article{ESTEBAN2015120,
title = {Singular Perturbation Control of the Lateral-Directional Flight Dynamics of an UAV},
journal = {IFAC-PapersOnLine},
volume = {48},
number = {9},
pages = {120-125},
year = {2015},
note = {1st IFAC Workshop on Advanced Control and Navigation for Autonomous Aerospace Vehicles ACNAAV’15},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2015.08.070},
url = {https://www.sciencedirect.com/science/article/pii/S2405896315009374},
author = {S. Esteban and F. Gavilan and J.A. Acosta},
keywords = {control strategies, singular perturbations, time scales, lateral-directional, UAV},
abstract = {This paper presents a singular perturbation control strategy for regulating the lateral-directional flight dynamics of an Unmanned Air Vehicle (UAV). The proposed control strategy is based on a four-time-scale (4TS) decomposition that includes the side-slip velocity, bank angle, yaw rate and roll rate dynamics, with the control signals being the aileron and rudder deflection. The nonlinear control strategy drives the system to follow a reference in load factor which in return provides references in bank angle, side-slip velocity and yaw rate. In addition, the control strategy permits to select the desired dynamics for all the singularly perturbed subsystems. Numerical results are included for a realistic nonlinear UAV model, including saturation on the control signals, and unmodeled dynamics.}
}
@article{ALLEN2019174,
title = {A real-time framework for kinodynamic planning in dynamic environments with application to quadrotor obstacle avoidance},
journal = {Robotics and Autonomous Systems},
volume = {115},
pages = {174-193},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2018.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S0921889017308692},
author = {Ross E. Allen and Marco Pavone},
keywords = {Motion planning, Kinodynamic, Real-time, Obstacle avoidance, Quadrotor, Unmanned aerial vehicle, Machine learning, Human–robot interaction},
abstract = {The objective of this paper is to present a full-stack, real-time motion planning framework for kinodynamic robots and then show how it is applied and demonstrated on a physical quadrotor system operating in a laboratory environment. The proposed framework utilizes an offline–online computation paradigm, neighborhood classification through machine learning, sampling-based motion planning with an optimal cost distance metric, and trajectory smoothing to achieve real-time planning for aerial vehicles. This framework accounts for dynamic obstacles with an event-based replanning structure and a locally reactive control layer that minimizes replanning events. The approach is demonstrated on a quadrotor navigating moving obstacles in an indoor space and stands as, arguably, one of the first demonstrations of full-online kinodynamic motion planning, with execution cycles of 3 Hz to 5 Hz. For the quadrotor, a simplified dynamics model is used during the planning phase to accelerate online computation. A trajectory smoothing phase, which leverages the differentially flat nature of quadrotor dynamics, is then implemented to guarantee a dynamically feasible trajectory.}
}
@article{BUSACCA2021108330,
title = {Designing a multi-layer edge-computing platform for energy-efficient and delay-aware offloading in vehicular networks},
journal = {Computer Networks},
volume = {198},
pages = {108330},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108330},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621003315},
author = {Fabio Busacca and Giuseppe Faraci and Christian Grasso and Sergio Palazzo and Giovanni Schembra},
keywords = {5G, Edge Computing, Vehicular Networks, Reinforcement Learning, Markov Models},
abstract = {Vehicular networks are expected to support many time-critical services requiring huge amounts of computation resources with very low delay. However, such requirements may not be fully met by vehicle on-board devices due to their limited processing and storage capabilities. The solution provided by 5G is the application of the Multi-Access Edge Computing (MEC) paradigm, which represents a low-latency alternative to remote clouds. Accordingly, we envision a multi-layer job-offloading scheme based on three levels, i.e., the Vehicular Domain, the MEC Domain and Backhaul Network Domain. In such a view, jobs can be offloaded from the Vehicular Domain to the MEC Domain, and even further offloaded between MEC Servers for load balancing purposes. We also propose a framework based on a Markov Decision Process (MDP) to model the interactions among stakeholders working at the three different layers. Such a MDP model allows a Reinforcement Learning (RL) algorithm to take optimal decisions on both the number of jobs to offload between MEC Servers, and on the amount of computing power to allocate to each job. An extensive numerical analysis is presented to demonstrate the effectiveness of our algorithm in comparison with static policies not applying RL.}
}
@article{DONG2022127452,
title = {Simulation of dew point temperature in different time scales based on grasshopper algorithm optimized extreme gradient boosting},
journal = {Journal of Hydrology},
volume = {606},
pages = {127452},
year = {2022},
issn = {0022-1694},
doi = {https://doi.org/10.1016/j.jhydrol.2022.127452},
url = {https://www.sciencedirect.com/science/article/pii/S0022169422000270},
author = {Jianhua Dong and Wenzhi Zeng and Guoqing Lei and Lifeng Wu and Haorui Chen and Jingwei Wu and Jiesheng Huang and Thomas Gaiser and Amit Kumar Srivastava},
keywords = {Dew point temperature, Grasshopper optimization algorithm, Extreme gradient boosting, Time scale, Cross-validation},
abstract = {Dew point temperature (Tdew) plays an important role in hydrology, meteorology, and other related research. This study evaluated the ability of a new machine learning model (hybrid extreme gradient boosting with grasshopper optimization algorithm (GOA-XGBoost)) to estimate Tdew and compared it with two other tree-based models (XGBoost and random forest (RF)). We collected meteorological data namely actual vapor pressure (ea), maximum air temperature (Tmax), minimum air temperature (Tmin), maximum relative humidity (RHmax), minimum relative humidity (RHmin), atmospheric pressure (Pa), 2 m high wind speed (Ud), during 2016–2019 on daily and hourly time scales from the Sijiqinglin station in China to train, test, and validate each model. The results showed that the GOA-XGBoost model performed best, and the RF model had severe over-fitting problems during the validation phase at daily time scale. The models showed the best accuracy and stability when the input was ea (on average R2 = 1.000, RMSE = 0.296℃, MBE = 0.001℃, MAE = 0.167℃, and KGE = 0.991). The models had more significant errors when the inputs were Tmax, Tmin (on average R2 = 0.721, RMSE = 6.756℃, MBE = -0.101℃, MAE = 5.071℃, and KGE = 0.771). The estimation loss exhibited by the models were similar for the hourly and daily scale patterns. T and RH were the most basic meteorological factors and adding extraneous factors would affect the estimation accuracy of the model. The variability of meteorological data varied less on an hourly scale than on a daily scale. Therefore, the accuracy of the models was higher, but the data set and the volume of operations became larger. This led to a possible reduction in model stability, but the hourly scales are better suited for assessing the effects of simulations in extreme situations. Taking accuracy and stability into account, the GOA-XGBoost model was the best model and the most practical input for both time scales was ea. Therefore, in subsequent studies, the GOA-XGBoost model can be combined with the input ea to estimate Tdew accurately.}
}
@article{BERRI2021103523,
title = {Computational framework for real-time diagnostics and prognostics of aircraft actuation systems},
journal = {Computers in Industry},
volume = {132},
pages = {103523},
year = {2021},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2021.103523},
url = {https://www.sciencedirect.com/science/article/pii/S0166361521001305},
author = {Pier Carlo Berri and Matteo D.L. {Dalla Vedova} and Laura Mainini},
keywords = {Estimation of remaining useful life (RUL), Prognostics and health management (PHM), Aircraft actuation systems, Multifidelity modeling, Machine learning},
abstract = {Prognostics and health management (PHM) are emerging approaches to product life cycle that will maintain system safety and improve reliability, while reducing operating and maintenance costs. This is particularly relevant for aerospace systems, where high levels of integrity and high performances are required at the same time. We propose a novel strategy for the nearly real-time fault detection and identification (FDI) of a dynamical assembly, and for the estimation of remaining useful life (RUL) of the system. The availability of a timely estimate of the health status of the system will allow for an informed adaptive planning of maintenance and a dynamical reconfiguration of the mission profile, reducing operating costs and improving reliability. This work addresses the three phases of the prognostic flow – namely (1) signal acquisition, (2) fault detection and identification, and (3) remaining useful life estimation – and introduces a computationally efficient procedure suitable for real-time, on-board execution. To achieve this goal, we propose to combine information from physical models of different fidelity with machine learning techniques to obtain efficient representations (surrogate models) suitable for nearly real-time applications. Additionally, we propose an importance sampling strategy and a novel approach to model damage propagation for dynamical systems. The methodology is assessed for the FDI and RUL estimation of an aircraft electromechanical actuator (EMA) for secondary flight controls. The results show that the proposed method allows for a high precision in the evaluation of the system RUL, while outperforming common model-based techniques in terms of computational time.}
}
@article{CHIAN2021103862,
title = {Computer vision approaches for detecting missing barricades},
journal = {Automation in Construction},
volume = {131},
pages = {103862},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103862},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521003137},
author = {Eugene Chian and Weili Fang and Yang Miang Goh and Jing Tian},
keywords = {Falls from height, Safety, Computer vision, Unsafe behavior, Deep learning},
abstract = {The installation of barricades effectively prevents falls from height (FFH) on construction sites. Common approaches for detecting missing barricades (e.g., manual inspection of the site or three-dimensional models) are not practical due to two inherent challenges: (1) these approaches are labor-intensive and time-consuming; and (2) FFH hazards are dynamic and changing as construction work progresses. To address these challenges, two computer vision-based detection approaches, including Masks Comparison Approach (MCA) and Missing Object Detection Approach (MODA), are developed in this study to automatically detect missing barricade. The performance of the proposed approaches and their benefits and implementation challenges were evaluated through a case study. The results demonstrate that MODA can achieve better performance and have several implementation advantages over MCA. The average precision and average recall for MODA were 57.9% and 73.6%, respectively. These two approaches can help site managers take action promptly to reduce the risks of FFH accidents.}
}
@article{MA2017277,
title = {A review of supervised object-based land-cover image classification},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {130},
pages = {277-293},
year = {2017},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2017.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S092427161630661X},
author = {Lei Ma and Manchun Li and Xiaoxue Ma and Liang Cheng and Peijun Du and Yongxue Liu},
keywords = {OBIA, GEOBIA, Meta-analysis, Supervised object-based classification, Land-cover mapping, Review},
abstract = {Object-based image classification for land-cover mapping purposes using remote-sensing imagery has attracted significant attention in recent years. Numerous studies conducted over the past decade have investigated a broad array of sensors, feature selection, classifiers, and other factors of interest. However, these research results have not yet been synthesized to provide coherent guidance on the effect of different supervised object-based land-cover classification processes. In this study, we first construct a database with 28 fields using qualitative and quantitative information extracted from 254 experimental cases described in 173 scientific papers. Second, the results of the meta-analysis are reported, including general characteristics of the studies (e.g., the geographic range of relevant institutes, preferred journals) and the relationships between factors of interest (e.g., spatial resolution and study area or optimal segmentation scale, accuracy and number of targeted classes), especially with respect to the classification accuracy of different sensors, segmentation scale, training set size, supervised classifiers, and land-cover types. Third, useful data on supervised object-based image classification are determined from the meta-analysis. For example, we find that supervised object-based classification is currently experiencing rapid advances, while development of the fuzzy technique is limited in the object-based framework. Furthermore, spatial resolution correlates with the optimal segmentation scale and study area, and Random Forest (RF) shows the best performance in object-based classification. The area-based accuracy assessment method can obtain stable classification performance, and indicates a strong correlation between accuracy and training set size, while the accuracy of the point-based method is likely to be unstable due to mixed objects. In addition, the overall accuracy benefits from higher spatial resolution images (e.g., unmanned aerial vehicle) or agricultural sites where it also correlates with the number of targeted classes. More than 95.6% of studies involve an area less than 300ha, and the spatial resolution of images is predominantly between 0 and 2m. Furthermore, we identify some methods that may advance supervised object-based image classification. For example, deep learning and type-2 fuzzy techniques may further improve classification accuracy. Lastly, scientists are strongly encouraged to report results of uncertainty studies to further explore the effects of varied factors on supervised object-based image classification.}
}
@article{NALDI2010975,
title = {Modeling and control of the interaction between flying robots and the environment},
journal = {IFAC Proceedings Volumes},
volume = {43},
number = {14},
pages = {975-980},
year = {2010},
note = {8th IFAC Symposium on Nonlinear Control Systems},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20100901-3-IT-2016.00306},
url = {https://www.sciencedirect.com/science/article/pii/S1474667015370919},
author = {Roberto Naldi and Luca Gentili and Lorenzo Marconi},
abstract = {This work considers the problem of modeling and controlling a class of underactuated aerial robots considering explicitly the interaction deriving from contacts with the environment and the resulting constraints which affect the system dynamics. The goal is to address a scenario in which unmanned aerial vehicles are allowed to accomplish tasks which may require contacts between the aerial vehicle and the environment, such as inspection of infrastructures or even remote manipulation. To this aim a novel control framework, based on a path following approach, is shown to succeed in achieving tasks such as docking / undocking to a certain working area by governing directly the contact dynamics of the system with the only help of vehicle's own internal forces.}
}
@article{GAO2021104161,
title = {ThickSeg: Efficient semantic segmentation of large-scale 3D point clouds using multi-layer projection},
journal = {Image and Vision Computing},
volume = {108},
pages = {104161},
year = {2021},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2021.104161},
url = {https://www.sciencedirect.com/science/article/pii/S0262885621000664},
author = {Qian Gao and Xukun Shen},
keywords = {3D point cloud, Semantic segmentation, Convolutional neural network, Large scale},
abstract = {Efficient semantic segmentation of large-scale three-dimensional (3D) point clouds is an essential approach for intelligent robots to perceive the surrounding environment. However, due to the expensive sampling process or time-consuming pre/post-processing steps, most of the current solutions are inefficient or limited in scale. In this paper, we propose a novel framework, ThickSeg, to efficiently assign semantic labels for large-scale point clouds. ThickSeg contains three main steps: Firstly, it projects raw point clouds onto a multi-layer image with a random-hit strategy to efficiently preserve more local geometric features. Secondly, the projected multi-layer image is fed into a Self-Sorting 3D Convolutional Neural Network (SS-3DCNN) to predict grid-wise semantics and subsequently project them back to their corresponding 3D points. Finally, the labels of occluded points are determined by an iterative and accumulative post-processing mechanism, avoiding time-consuming explicit 3D neighborhood searching. We validate our approach on two well-known public benchmarks (SemanticKITTI and KITTI), where ThickSeg gets state-of-the-art results and more efficient than previous methods. Our detailed ablation study shows how each component contributes to the final performance.}
}
@article{HAN2020107027,
title = {Robust Visual Tracking based on Adversarial Unlabeled Instance Generation with Label Smoothing Loss Regularization},
journal = {Pattern Recognition},
volume = {97},
pages = {107027},
year = {2020},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2019.107027},
url = {https://www.sciencedirect.com/science/article/pii/S0031320319303309},
author = {Yamin Han and Peng Zhang and Wei Huang and Yufei Zha and Garth Douglas Cooper and Yanning Zhang},
keywords = {Visual tracking, Sample-level generative adversarial network, Feature-level generative adversarial network, Label smoothing loss regularization, Re-detection correlation filter},
abstract = {Recent studies have shown that deep neural networks have pushed visual tracking accuracy to new heights, but finding more robust long-term tracking is still challenging because of the dynamic foreground and background changes. This phenomenon affects the overall performance via online training sample generation. The dense sampling strategy has been widely used for its convenience, the appearance variation is severely limited by its highly spatial overlapping mechanism. The sample candidate evaluation with a classification score metric is not always reliable throughout the entire process, therefore, tracking failure is inevitable. As an effective solution, this paper proposes a novel sample-level generative adversarial network (GAN) to enrich the training data by generating massive amounts of sample-level GAN samples. These samples are not only similar to the real-life scenarios, but also could carry more diversity of deformation and motion blur to a certain degree. For occlusion invariance, a feature-level GAN is incorporated to generate more challenging feature-level GAN data by creating random occlusion masks in deep feature space. To facilitate the online learning process, a label smoothing loss regularization is introduced to achieve model regularization and over-fitting reduction by integrating the unlabeled GAN-generated training data with the realistically labeled ones. In addition, a re-detection correlation filter conservatively trained with reliable training data is employed to integrate a classification score metric to perform reliable model updates and avoid heavy degradation. Furthermore, we also carry out the re-detection correlation filter on the candidate region proposals to handle the tracking failures. The proposed tracker has shown superior performance in comparison to the other state-of-the-art tracking approaches on the OTB-2013, OTB-100, UAV123, UAV20L, and VOT2016 benchmark datasets.}
}
@article{YIN2021103874,
title = {Automated semantic segmentation of industrial point clouds using ResPointNet++},
journal = {Automation in Construction},
volume = {130},
pages = {103874},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103874},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521003253},
author = {Chao Yin and Boyu Wang and Vincent J.L. Gan and Mingzhu Wang and Jack C.P. Cheng},
keywords = {As-built BIM, Deep learning, Industrial object recognition, Local aggregation operator, PointNet++, Point clouds, Residual learning, Semantic segmentation, Laser scanning},
abstract = {Currently, as-built building information modeling (BIM) models from point clouds show great potential in managing building information. The automatic creation of as-built BIM models from point clouds is important yet challenging due to the inefficiency of semantic segmentation. To overcome this challenge, this paper proposes a novel deep learning-based approach, ResPointNet++, by integrating deep residual learning with conventional PointNet++ network. To unleash the power of deep learning methods, this study firstly builds an expert-labeled high-quality industrial LiDAR dataset containing 80 million data points collected from four different industrial scenes covering nearly 4000 m2. Our dataset consists of five typical semantic categories of plumbing and structural components (i.e., pipes, pumps, tanks, I-shape and rectangular beams). Second, we introduce two effective neural modules including local aggregation operator and residual bottleneck modules to learn complex local structures from neighborhood regions and build up deeper point cloud networks with residual settings. Based on these two neural modules, we construct our proposed network, ResPointNet++, with a U-Net style encoder-decoder structure. To validate the proposed method, comprehensive experiments are conducted to compare the robustness and efficiency of our ResPointNet++ with two representative baseline methods (PointNet and PointNet++) on our benchmark dataset. The experimental results demonstrate that ResPointNet++ outperforms two baselines with a remarkable overall segmentation accuracy of 94% and mIoU of 87%, which is 23% and 42% higher than that of conventional PointNet++, respectively. Finally, ablation studies are performed to evaluate the influence of design choices of the local aggregation operator module including input feature type and aggregation function type. This study contributes to automated 3D scene interpretation of industrial point clouds as well as the as-built BIM creation for industrial components such as pipes and beams.}
}
@article{AULETTA2021105,
title = {Human-inspired strategies to solve complex joint tasks in multi agent systems},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {17},
pages = {105-110},
year = {2021},
note = {6th IFAC Conference on Analysis and Control of Chaotic Systems CHAOS 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.11.033},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321020528},
author = {Fabrizia Auletta and Mario {di Bernardo} and Michael J. Richardson},
keywords = {Nonlinear Time Series, Identification, Multi-agent Systems, Multi-agent Coordination, Herding problem},
abstract = {In this paper we propose a methodology to integrate human expertise with effective control laws to drive artificial agents in a complex joint task. We use Supervised Machine Learning to derive human-inspired strategies that succeed in task performance independently from the operating conditions of the samples provided in the training phase. Numerical simulations validate the efficiency of the proposed human-inspired strategies against simpler yet computationally expensive rule-based strategies.}
}
@article{ALI20208840,
title = {Control System Analysis and Design of Quadcopter in the Presence of Unmodelled Dynamics and Disturbances},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {8840-8846},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.1397},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320318073},
author = {Muhammad Z. Ali and Aftab Ahmed and Hamad K. Afridi},
keywords = {Nonlinear Control, Feedback Linearization, Quadcopter, Unmodelled Dynamics, Disturbances},
abstract = {UAVs especially quadcopters have recently caught the attention of researchers and manufacturers due to their various commercial and military applications like surveillance, photography and many others. They have small sizes since have low cost, easy manufacturing, extreme maneuverability and VTOL capabilities. This paper addresses the problem of unmod-elled dynamics and disturbances while designing an appropriate control law for the quadcopter UAV having very coupled nonlinear dynamics. Most of the controllers available in the literature ignore Coriolis terms in the model and small signal approximations are made to linearize or simplify the model about certain operating conditions. But such control system has a very limited performance and fails to deliver the desired results even for small disturbances and parametric variations since the assumptions no longer remain valid. We have derived an extensive nonlinear model of quadcopter with least approximations in terms of linear velocities in body frame, position in the inertial frame, the Euler angles and their rates. We have designed a feedback linearization based nonlinear controller using a novel approach. This has further been cascaded with sliding mode control and backstepping based control to handle uncertainties. The simulation results of this controller have also been included for a known quadcopter model.}
}
@article{YANMAZ20181,
title = {Drone networks: Communications, coordination, and sensing},
journal = {Ad Hoc Networks},
volume = {68},
pages = {1-15},
year = {2018},
note = {Advances in Wireless Communication and Networking for Cooperating Autonomous Systems},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2017.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1570870517301671},
author = {Evşen Yanmaz and Saeed Yahyanejad and Bernhard Rinner and Hermann Hellwagner and Christian Bettstetter},
keywords = {Drones, Unmanned aerial vehicle networks, Wireless sensor networks, Vehicular communications, Cooperative aerial imaging, Search and rescue},
abstract = {Small drones are being utilized in monitoring, transport, safety and disaster management, and other domains. Envisioning that drones form autonomous networks incorporated into the air traffic, we describe a high-level architecture for the design of a collaborative aerial system consisting of drones with on-board sensors and embedded processing, coordination, and networking capabilities. We implement a multi-drone system consisting of quadcopters and demonstrate its potential in disaster assistance, search and rescue, and aerial monitoring. Furthermore, we illustrate design challenges and present potential solutions based on the lessons learned so far.}
}
@article{INADA2010386,
title = {Flight-Formation Control of Air Vehicles Based on Collective Motion Control of Organisms},
journal = {IFAC Proceedings Volumes},
volume = {43},
number = {15},
pages = {386-391},
year = {2010},
note = {18th IFAC Symposium on Automatic Control in Aerospace},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20100906-5-JP-2022.00066},
url = {https://www.sciencedirect.com/science/article/pii/S1474667015318711},
author = {Yoshinobu Inada and Hideaki Takanobu},
keywords = {Flight-formation control, Unmanned air vehicle, Collective motion, Fish school, Bird flock, Loitering control, Shape control},
abstract = {Abstract
Collective motion control in nature such as bird flock or fish school shows conspicuous stability and flexibility in the motion of a large quantity of individuals, thus providing a feasible model of a flight-formation control of air vehicles. The application of such biologically-inspired collective motion control to UAV is proposed here to upgrade its performance and reliability by combining different functions of multiple UAVs and by utilizing high degree of redundancy. The simple rule-based model based on a fish school realizes a feasible method of loitering or group shape control, thus showing a promising application to the flight-formation control of air vehicles or other artificial collective systems.}
}
@article{ANDRIOLO2021112542,
title = {Drones for litter mapping: An inter-operator concordance test in marking beached items on aerial images},
journal = {Marine Pollution Bulletin},
volume = {169},
pages = {112542},
year = {2021},
issn = {0025-326X},
doi = {https://doi.org/10.1016/j.marpolbul.2021.112542},
url = {https://www.sciencedirect.com/science/article/pii/S0025326X21005762},
author = {Umberto Andriolo and Gil Gonçalves and Nelson Rangel-Buitrago and Marco Paterni and Filipa Bessa and Luisa M.S. Gonçalves and Paula Sobral and Monica Bini and Diogo Duarte and Ángela Fontán-Bouzas and Diogo Gonçalves and Tomoya Kataoka and Marco Luppichini and Luis Pinto and Konstantinos Topouzelis and Anubis Vélez-Mendoza and Silvia Merlino},
keywords = {Plastics, Unmanned aerial vehicle (UAV), Remote sensing, Waste management, Coastal pollution},
abstract = {Unmanned aerial systems (UAS, aka drones) are being used to map macro-litter on the environment. Sixteen qualified researchers (operators), with different expertise and nationalities, were invited to identify, mark and categorize the litter items (manual image screening, MS) on three UAS images collected at two beaches. The coefficient of concordance (W) among operators varied between 0.5 and 0.7, depending on the litter parameter (type, material and colour) considered. Highest agreement was obtained for the type of items marked on the highest resolution image, among experts in litter surveys (W = 0.86), and within territorial subgroups (W = 0.85). Therefore, for a detailed categorization of litter on the environment, the MS should be performed by experienced and local operators, familiar with the most common type of litter present in the target area. This work provides insights for future operational improvements and optimizations of UAS-based images analysis to survey environmental pollution.}
}
@article{YANG2022106508,
title = {Reforestation improves vegetation coverage and biomass, but not spatial structure, on semi-arid mine dumps},
journal = {Ecological Engineering},
volume = {175},
pages = {106508},
year = {2022},
issn = {0925-8574},
doi = {https://doi.org/10.1016/j.ecoleng.2021.106508},
url = {https://www.sciencedirect.com/science/article/pii/S0925857421003633},
author = {Yongjun Yang and Jiajia Tang and Yiyan Zhang and Shaoliang Zhang and Yongli Zhou and Huping Hou and Run Liu},
keywords = {Reforestation, Diversity, Spatial structure, Restoration success, Remote sensing, WorldView-2, Mining},
abstract = {Modern mine rehabilitation aims at thorough restoration of an ecosystem with emphasis on not only land area covered by vegetation but also the structure and function of that vegetation. However, assessment of current restoration success reveals a lack of attention to the spatial structure and its relationships with vegetation coverage and biomass. A forest's spatial structure is an important attribute of structural diversity. Complex spatial structures mean diverse species composition and spatial dissimilarity, which can provide a base for self-sustaining and regeneration. This study uses WorldView-2 images and field data to train the mind evolutionary algorithm-back propagation neural network (MEA-BP) model for the purpose of mapping three parameters (coverage, biomass, and spatial structure) across mine dumps. The results show that the spectral and textural features could effectively assess the coverage, biomass, and spatial structure, with an R2 of 0.91, 0.86, and 0.62, respectively. The coverage is positively correlated with biomass, while the spatial structure is negatively correlated with coverage and biomass. Pure Hippophae rhamnoides L. had high coverage but very low spatial structure, while the mixed community dominated by Populus L. and Pinus tabulaeformis Carr had high coverage, high biomass, and medium structure at around 10 years. The results suggested that the artificial reforestation improves vegetation coverage and biomass but did not synchronously increase spatial structure. The initially planted species composition, substrates, and succession process have a significant influence on the forest parameter relationships. The future reforestation and optimization of community assemblages should take the relationships and their influence factors and effects on ecosystem services into account. The remote sensing-based data and model has potential and advantages in dynamically guiding the rehabilitation and monitoring of the restored ecosystem.}
}
@article{LIANG2021100003,
title = {Landing route planning method for micro drones based on hybrid optimization algorithm},
journal = {Biomimetic Intelligence and Robotics},
volume = {1},
pages = {100003},
year = {2021},
issn = {2667-3797},
doi = {https://doi.org/10.1016/j.birob.2021.100003},
url = {https://www.sciencedirect.com/science/article/pii/S2667379721000036},
author = {Shaoran Liang and Bifeng Song and Dong Xue},
keywords = {Route planning, Micro drones, Dragonfly optimization, Hybrid optimization},
abstract = {Aiming at the obstacle avoidance trajectory planning problem in the landing process of the micro drone, this paper proposes a swarm optimization algorithm that combines the dragonfly optimization method and the differential evolution method. The orthogonal learning mechanism is adopted to realize the adaptive switch between the two algorithms. In the process of landing route planning, the planning plane is first obtained by making the gliding plane tangent to the obstacle. In the planning plane, the projection of obstacle is transformed into multiple unreachable line segments. By designing an optimization model, the 3D landing route planning problem is transformed into a 2D obstacle avoidance route optimization problem. Taking the shortest route as the optimization objective, the penalty factor is introduced into the cost function to avoid the intersection of the landing route and obstacle. During the optimization process, through the orthogonal learning of the intermediate iterative results, the hybrid algorithm can adaptively select the next iterative algorithm, so it can give full play to the respective advantages of the two algorithms. The optimization results show that, compared with the single optimization algorithm, the hybrid optimization algorithm proposed in this paper can better solve the problem of landing route planning for micro-small UAVs.}
}
@article{ZHAI2021107861,
title = {Optical flow and scene flow estimation: A survey},
journal = {Pattern Recognition},
volume = {114},
pages = {107861},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.107861},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321000480},
author = {Mingliang Zhai and Xuezhi Xiang and Ning Lv and Xiangdong Kong},
keywords = {Motion analysis, Optical flow, Scene flow, Variational model, Deep learning, Convolutional neural networks (CNNs)},
abstract = {Motion analysis is one of the most fundamental and challenging problems in the field of computer vision, which can be widely applied in many areas, such as autonomous driving, action recognition, scene understanding, and robotics. In general, the displacement field between subsequent frames can be divided into two types: optical flow and scene flow. The optical flow represents the pixel motion of adjacent frames. In contrast, the scene flow is a 3D motion field of the dynamic scene between two frames. Traditional approaches for the estimation of optical flow and scene flow usually leverage the variational technique, which can be solved as an energy minimization process. In recent years, deep learning has emerged as a powerful technique for learning feature representations directly from data. It has led to remarkable progress in the field of optical flow and scene flow estimation. In this paper, we provide a comprehensive survey of optical flow and scene flow estimation. First, we briefly review the pioneering approaches that use variational technique and then we delve in detail into the deep learning-based approaches. Furthermore, we present insightful observations on evaluation issues, specifically benchmark datasets, evaluation metrics, and state-of-the-art performance. Finally, we give the promising directions for future research. To the best of our knowledge, we are the first to review both optical flow and scene flow estimation, and the first to cover both traditional and deep learning-based approaches.}
}
@article{ISLAM2020101863,
title = {Improving disasters preparedness and response for coastal communities using AIS ship tracking data},
journal = {International Journal of Disaster Risk Reduction},
volume = {51},
pages = {101863},
year = {2020},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2020.101863},
url = {https://www.sciencedirect.com/science/article/pii/S2212420920313650},
author = {Samsul Islam and Floris Goerlandt and Xuran Feng and Mohammad Jasim Uddin and Yangyan Shi and Casey Hilliard},
keywords = {Emergency management, Disaster relief operations, Maritime risk, Humanitarian logistics, Maritime transportation, AIS data, Ship tracking data, Disaster management, Machine learning, Coastal community, Neural network},
abstract = {Many coastal communities are heavily dependent on maritime transportation for the ingress and egress of people and goods. Any major transportation disruption can have a significant negative impact on the safety, health and wellbeing of affected communities, this is due to the interruption in the availability of food and the supply medicines and fuel. Therefore, preparedness and the forward planning of an effective response are essential for successful emergency and recovery management. Accordingly, in this study, the concept of using AIS (Automatic Identification System) vessel tracking data has been applied for the study of disaster management in coastal communities. The AIS vessel tracking system has been an important development in navigational safety; this is because it continuously transmits important information to all other vessels about a particular vessel (including its position, identity, speed and route). One of the limitations of the AIS tracking system is that AIS data does not indicate commodity specifications: that is, the quantity of essential goods that each vessel is carrying to specified coastal communities. To overcome the limitation of the current AIS tracking system, we use an artificial neural network as an estimation tool. In the current study, AIS data are assessed and analyzed in addition to the augmentation of the capacity information of vessels; thus, the study develops a predictive model so that a relief manager can determine the actual needs of affected residents and thus be able to make responsible relief decisions (e.g., how much relief a disaster-affected community is likely to need). The study makes a unique contribution as its focus seeks to remedy the total lack of research on how to use AIS data in disaster operations.}
}
@article{TAMIMINIA2020152,
title = {Google Earth Engine for geo-big data applications: A meta-analysis and systematic review},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {164},
pages = {152-170},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620300927},
author = {Haifa Tamiminia and Bahram Salehi and Masoud Mahdianpari and Lindi Quackenbush and Sarina Adeli and Brian Brisco},
keywords = {Google Earth Engine, Geo-big data, Cloud-based platform, Remote sensing, Planetary-scale, Geospatial, Machine learning, Environmental monitoring},
abstract = {Google Earth Engine (GEE) is a cloud-based geospatial processing platform for large-scale environmental monitoring and analysis. The free-to-use GEE platform provides access to (1) petabytes of publicly available remote sensing imagery and other ready-to-use products with an explorer web app; (2) high-speed parallel processing and machine learning algorithms using Google’s computational infrastructure; and (3) a library of Application Programming Interfaces (APIs) with development environments that support popular coding languages, such as JavaScript and Python. Together these core features enable users to discover, analyze and visualize geospatial big data in powerful ways without needing access to supercomputers or specialized coding expertise. The development of GEE has created much enthusiasm and engagement in the remote sensing and geospatial data science fields. Yet after a decade since GEE was launched, its impact on remote sensing and geospatial science has not been carefully explored. Thus, a systematic review of GEE that can provide readers with the “big picture” of the current status and general trends in GEE is needed. To this end, the decision was taken to perform a meta-analysis investigation of recent peer-reviewed GEE articles focusing on several features, including data, sensor type, study area, spatial resolution, application, strategy, and analytical methods. A total of 349 peer-reviewed articles published in 146 different journals between 2010 and October 2019 were reviewed. Publications and geographical distribution trends showed a broad spectrum of applications in environmental analyses at both regional and global scales. Remote sensing datasets were used in 90% of studies while 10% of the articles utilized ready-to-use products for analyses. Optical satellite imagery with medium spatial resolution, particularly Landsat data with an archive exceeding 40 years, has been used extensively. Linear regression and random forest were the most frequently used algorithms for satellite imagery processing. Among ready-to-use products, the normalized difference vegetation index (NDVI) was used in 27% of studies for vegetation, crop, land cover mapping and drought monitoring. The results of this study confirm that GEE has and continues to make substantive progress on global challenges involving process of geo-big data.}
}
@article{KOUTSOUDIS20211,
title = {Multispectral aerial imagery-based 3D digitisation, segmentation and annotation of large scale urban areas of significant cultural value},
journal = {Journal of Cultural Heritage},
volume = {49},
pages = {1-9},
year = {2021},
issn = {1296-2074},
doi = {https://doi.org/10.1016/j.culher.2021.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S1296207421000650},
author = {Anestis Koutsoudis and George Ioannakis and Petros Pistofidis and Fotis Arnaoutoglou and Nikolaos Kazakis and George Pavlidis and Chistodoulos Chamzas and Nestor Tsirliganis},
keywords = {multispectral, machine learning, 3D digitisation, 3D segmentation, annotation, structure from motion, urban, architecture, disaster management},
abstract = {Disaster risk management of movable and immovable cultural heritage is a highly significant research topic. In this work, we present a pipeline for 3D digitisation, segmentation and annotation of large scale urban areas in order to produce data that can be exploited in disaster management simulators (e.g fire spreading, crowd movement, firefighting training, evacuation planning, etc.). We have selected the old town of Xanthi (Greece) as a challenging case study. We developed a custom multispectral camera to be carried by a commercial drone. Using the structure from motion / multiview stereo (SFM/MVS) approach, we produced a 3D model of the urban area covering 0.5km2 that is followed by a multilayer texture map which carries information from visible and near-infrared regions of the electromagnetic spectrum. We developed a set of machine learning approaches based on logistic regression, support vector machines and artificial neural networks that allow 3D model segmentation by exploiting not only morphological and structural features but also the multispectral behaviour of different material surfaces. We objectively evaluate the performance of the proposed segmentation approaches on six significant material-based classes (cobbled-roads granite kilns, building walls, ceramic roof-tiles, low-vegetation, high-vegetation and metal surfaces) that are used in simulating fire propagation and crowd movement. The experiments revealed that the segmentation accuracy can be enhanced by taking into consideration surface material multispectral properties as well as morphological features. A Web-based multi-user annotation tool complements our proposed pipeline by enabling further 3D model segmentation, fine tuning and semantics annotation (e.g. usage-based building classification and evacuation priorities, escape paths and gathering points).}
}
@article{ALFEO201819,
title = {Design and simulation of the emergent behavior of small drones swarming for distributed target localization},
journal = {Journal of Computational Science},
volume = {29},
pages = {19-33},
year = {2018},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2018.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S1877750318302898},
author = {Antonio L. Alfeo and Mario G.C.A. Cimino and Nicoletta {De Francesco} and Massimiliano Lega and Gigliola Vaglini},
keywords = {Swarm intelligence, Drone, Stigmergy, Flocking, Differential evolution, Target search},
abstract = {A swarm of autonomous drones with self-coordination and environment adaptation can offer a robust, scalable and flexible manner to localize objects in an unexplored, dangerous or unstructured environment. We design a novel coordination algorithm combining three biologically inspired processes: stigmergy, flocking and evolution. Stigmergy, a form of coordination exhibited by social insects, is exploited to attract drones in areas with potential targets. Flocking enables efficient cooperation between flock mates upon target detection, while keeping an effective scan. The two mechanisms can interoperate if their structural parameters are correctly tuned for a given scenario. Differential evolution adapts the swarm coordination according to environmental conditions. The performance of the proposed algorithm is examined with synthetic and real-world scenarios.}
}
@article{ALBIERO2022106608,
title = {Swarm robots in mechanized agricultural operations: A review about challenges for research},
journal = {Computers and Electronics in Agriculture},
volume = {193},
pages = {106608},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106608},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006256},
author = {Daniel Albiero and Angel {Pontin Garcia} and Claudio {Kiyoshi Umezu} and Rodrigo {Leme de Paulo}},
keywords = {Agriculture, Operational cost, Electric tractor, Artificial intelligence, Plowing, Forestry, Multi-robot},
abstract = {Agricultural mechanization is an area of knowledge that has evolved a lot over the past century, its main actors being agricultural tractors that, in 100 years, have increased their powers by 3,300%. This evolution has resulted in an exponential increase in the field capacity of such machines. However, it has also generated negative results such as excessive consumption of fossil fuel, excessive weight on the soil, very high operating costs, and millionaire acquisition value. The objective of this paper aims at exploring the upcoming challenges of employing swarm robot tractors that together have the same field capacity as a large tractor with an internal combustion engine. A systematic literature review technique is used to survey 32 representative papers that report research about swarm robots in agriculture. These papers are analyzed in an organized manner concerning the operationalization of swarm robots to fulfill agricultural mechanization missions. A comprehensive evaluation is conducted from the aspects of technology readiness level (TRL), configurability, adaptability, dependability, motion ability, perception ability and decision autonomy. Based on the evaluation result, upcoming challenges are detected and summarized, suggesting the development of a roadmap for future research. Another systematic review was done for these challenges by assessing the distance between what is being studied and the needs for a commercial operation of a robotic tractor swarm.}
}
@article{HE2022108577,
title = {A combined global-local approach for delamination assessment of composites using vibrational frequencies and FBGs},
journal = {Mechanical Systems and Signal Processing},
volume = {167},
pages = {108577},
year = {2022},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2021.108577},
url = {https://www.sciencedirect.com/science/article/pii/S0888327021009122},
author = {Mengyue He and Karthik Ram Ramakrishnan and Yishou Wang and Zhifang Zhang and Jiyang Fu},
keywords = {Delamination detection, Fiber reinforced polymer, Scanning laser Doppler vibration, Fiber Bragg grating, Support vector machine, Extreme learning machine},
abstract = {In this paper, a combined global-local strategy was developed for structural health monitoring (SHM) of fiber reinforced polymer (FRP) composites to assess the internal delamination damage, which has combined vibrational frequency shifts as the global index and the fiber Bragg grating (FBG) wavelength shifts as the local index. The delamination detection was carried out in two steps. The first step was based on the global damage index, which is the changes in multiple modes of frequencies measured by a non-contact scanning laser Doppler vibrometer (SLDV) system. Machine learning (ML) algorithms including support vector machine (SVM) and extreme learning machine (ELM) algorithms were used to initially predict the delamination interface, location, and size through frequency shifts. Numerical and experimental verification results show that SVM has a higher prediction accuracy than ELM when only a small number of samples exist, and the classification of SVM is better than its regression function to be used in the prediction of discrete delamination interfaces. To verify the damaged area predicted by frequency changes and further update the delamination edges with better accuracy, the second step has taken the changes in the wavelength of multiple FBG sensors as the local damage index. Multistage loads were applied at equidistant positions of the FRP specimens to induce deformations and the wavelength shifts in FBGs were used to determine the boundary of delamination. The results showed that delamination in FRP composites can be assessed more precisely using the global-local two-step SHM strategy, which can compensate for the shortcomings of only using vibration-based or FBG-based monitoring techniques. Besides, the SVM algorithm showed excellent predictive performance in both steps and had great potential in delamination damage monitoring.}
}
@article{MASHHADI2020107527,
title = {Optimal auction for delay and energy constrained task offloading in mobile edge computing},
journal = {Computer Networks},
volume = {183},
pages = {107527},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107527},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620311841},
author = {Farshad Mashhadi and Sergio A. Salinas Monroy and Arash Bozorgchenani and Daniele Tarchi},
keywords = {Mobile edge computing, Deep learning, Auction, Delay and energy sensitive tasks},
abstract = {Mobile edge computing has emerged as a promising paradigm to complement the computing and energy resources of mobile devices. In this computing paradigm, mobile devices offload their computing tasks to nearby edge servers, which can potentially reduce their energy consumption and task completion delay. In exchange for processing the computing tasks, edge servers expect to receive a payment that covers their operating costs and allows them to make a profit. Unfortunately, existing works either ignore the payments to the edge servers, or ignore the task processing delay and energy consumption of the mobile devices. To bridge this gap, we propose an auction to allocate edge servers to mobile devices that is executed by a pair of deep neural networks. Our proposed auction maximizes the profit of the edge servers, and satisfies the task processing delay and energy consumption constraints of the mobile devices. The proposed deep neural networks also guarantee that the mobile devices are unable to unfairly affect the results of the auctions. Our extensive simulations show that our proposed auction mechanism increases the profit of the edge servers by at least 50% compared to randomized auctions, and satisfies the task processing delay and energy consumption constraints of mobile devices.}
}
@article{LABBADI20214822,
title = {Fractional-order global sliding mode controller for an uncertain quadrotor UAVs subjected to external disturbances},
journal = {Journal of the Franklin Institute},
volume = {358},
number = {9},
pages = {4822-4847},
year = {2021},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2021.04.032},
url = {https://www.sciencedirect.com/science/article/pii/S0016003221002386},
author = {Moussa Labbadi and Yassine Boukal and Mohamed Cherkaoui and Mohamed Djemai},
abstract = {In the present paper, the problem of designing a global sliding mode control scheme based on fractional operators for tracking a quadrotor trajectory is investigated. The model of the quadrotor system is given with disturbances and uncertainties. To converge in short finite time of the sliding manifold, a classical quadratic Lyapunov function was used and also a global stabilization of the quadrotor system is ensured. The proposed controller can be ensured the robustness against external disturbances and model uncertainties. Some scenarios are illustrated in this paper. Finally, a comparative study to three other controllers is provided to show the validity and feasibility of the proposed method.}
}
@article{VARMASAGI2020241,
title = {Multi-UAS Formation Recognition in Dynamic Environments},
journal = {Procedia Computer Science},
volume = {168},
pages = {241-248},
year = {2020},
note = {“Complex Adaptive Systems”Malvern, PennsylvaniaNovember 13-15, 2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.02.260},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920303999},
author = {Surya Vamsi {Varma Sagi} and Leonard Petnga},
keywords = {Type your keywords here, separated by semicolons},
abstract = {As Unmanned Aircraft Systems (UAS) are becoming ubiquitous, more and more use cases will be relying on multi-UAS systems for mission-oriented applications (e.g., surveillance, reconnaissance, and package delivery). The multi-UAS formation has been shown to play a critical role in the ability of the system to conserve energy and reduce travel time thus, greatly impacting mission success. The need to identify, recognize and create such formations is critical for effective control of multi-UAS platforms, especially in challenging dynamic environmental conditions. In this paper, we propose and describe a framework for off-line identification and categorization of various types of multi-UAS formations based on the relative position of UAS in a two-dimensional space using machine learning techniques. The formation algorithm is trained with simulation trace data of different formations so that it is capable of accurately recognizing one that is materialized in the world. This information is proven crucial to enable formation-based adaptation of multi-UAS in highly dynamic environment thus, contributing to the resilience of the system. A prototype implementation and simulation are currently in development which will illustrate the capabilities of our approach.}
}
@article{MCCLURE2020100109,
title = {Artificial Intelligence Meets Citizen Science to Supercharge Ecological Monitoring},
journal = {Patterns},
volume = {1},
number = {7},
pages = {100109},
year = {2020},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2020.100109},
url = {https://www.sciencedirect.com/science/article/pii/S2666389920301434},
author = {Eva C. McClure and Michael Sievers and Christopher J. Brown and Christina A. Buelow and Ellen M. Ditria and Matthew A. Hayes and Ryan M. Pearson and Vivitskaia J.D. Tulloch and Richard K.F. Unsworth and Rod M. Connolly},
keywords = {CS, AI, biological conservation, automation, machine learning, deep learning, data processing, big data},
abstract = {Summary
The development and uptake of citizen science and artificial intelligence (AI) techniques for ecological monitoring is increasing rapidly. Citizen science and AI allow scientists to create and process larger volumes of data than possible with conventional methods. However, managers of large ecological monitoring projects have little guidance on whether citizen science, AI, or both, best suit their resource capacity and objectives. To highlight the benefits of integrating the two techniques and guide future implementation by managers, we explore the opportunities, challenges, and complementarities of using citizen science and AI for ecological monitoring. We identify project attributes to consider when implementing these techniques and suggest that financial resources, engagement, participant training, technical expertise, and subject charisma and identification are important project considerations. Ultimately, we highlight that integration can supercharge outcomes for ecological monitoring, enhancing cost-efficiency, accuracy, and multi-sector engagement.}
}
@article{ADELUYI2022126411,
title = {Exploiting centimetre resolution of drone-mounted sensors for estimating mid-late season above ground biomass in rice},
journal = {European Journal of Agronomy},
volume = {132},
pages = {126411},
year = {2022},
issn = {1161-0301},
doi = {https://doi.org/10.1016/j.eja.2021.126411},
url = {https://www.sciencedirect.com/science/article/pii/S1161030121001829},
author = {Oluseun Adeluyi and Angela Harris and Timothy Foster and Gareth D. Clay},
keywords = {Drone, Above ground biomass, Sensors, Plant height, Texture metrics, Vegetation indices, Rice},
abstract = {Above ground biomass (AGB) is an important indicator of rice for improving agronomic management efficiency and yield monitoring in crops. In particular, rice AGB during the mid (reproductive) and late (ripening) stages are responsible for the panicles per given area, the number of spikelets or grains per panicle, the percentage of filled kernels and grains; and the weight of each grain. Consequently, proper monitoring of rice AGB, particularly during the mid to late growth stages, are important for accurate estimation of rice yield. To this end, monitoring AGB at centimetre scale has become implementable by using sensors onboard Unmanned Aerial Vehicles (UAVs) or drones. The RGB sensors capable of generating plant height estimations from digital surface models provide a viable option for monitoring rice AGB. The advancement in miniature Multi-Spectral Imager (MSI) sensors capable of generating vegetation indices (VIs) and texture metrics (TM) also provides the opportunity to ascertain the capability of the sensor to estimate rice AGB, particularly during the growth stages. The study compares the potential and relative merits of using drone-mounted consumer-grade RGB imagery and/ or scientific-grade multispectral imagery for estimating rice mid-late season above ground biomass. Plant height estimates generated from digital surface model derived from the RGB sensor were compared with in-situ measurements of biomass using a simple linear regression (SLM) model. On the other hand, VIs, TM and their combination were accessed using the Random Forest model for estimating rice AGB. We also accessed the combination of both sensors for estimating rice AGB. Results testing model quality statistically showed plant height (R2 = 0.72; RMSE = 1.07 t/ha; MAE = 0.93 t/ha) estimates from the RGB camera performed better than VIs (R2 = 0.59; RMSE = 1.31 t/ha; MAE = 1.06 t/ha), TM (R2 = 0.43; RMSE = 1.58 t/ha; MAE = 1.22 t/ha) and the combination of VIs and TM when estimating rice AGB at the mid to late growing stages. When combining plant height and VIs from both cameras to estimate AGB, results suggest that the combination using random forest models improve the estimation of rice AGB. The combination of TM, VIs and Plant Height (PH) estimates produced the most statistically accurate estimates (R2 = 0.74; RMSE = 1.02 t/ha; MAE = 0.82 t/ha). Our findings suggest that the Plant height estimates from the RGB sensor produce a more accurate estimation of AGB compared to the MSI camera. However, the most accurate estimations are seen when both sensors are combined to estimate rice AGB at the mid to late growth stage.}
}
@article{ABBAS2021204,
title = {Characterizing and classifying urban tree species using bi-monthly terrestrial hyperspectral images in Hong Kong},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {177},
pages = {204-216},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621001283},
author = {Sawaid Abbas and Qian Peng and Man Sing Wong and Zhilin Li and Jicheng Wang and Kathy Tze Kwun Ng and Coco Yin Tung Kwok and Karena Ka Wai Hui},
keywords = {Urban tree, Hyperspectral library, Tree species, Seasonality, Deep learning, SPECIM-IQ},
abstract = {Urban trees exhibit a wide range of ecosystem services that have long been unveiled and increasingly reported. The ability to map tree species and analyze tree health conditions would become vividly essential. Remote sensing techniques, especially hyperspectral imaging, are being evolved for species identification and vegetation monitoring from spectral reponse patterns. In this study, a hyperspectral library for urban tree species in Hong Kong was established comprising 75 urban trees belonging to 19 species. 450 bi-monthly images were acquired by a terrestrial hyperspectral camera (SPECIM-IQ) from November 2018 to October 2019. A Deep Neural Network classification model was developed to identify tree species from the hyperspectral imagery with an overall accuracy ranging from 85% to 96% among different seasons. Representative spectral reflectance curves of healthy and unhealthy conditions for each species were extracted and analyzed. The hyperspectral phenology models were developed to achieve high accuracy and optimization of data acquisition. The bi-monthly canopy signatures and vegetation indices revealed different seasonality patterns of evergreen and deciduous species in Hong Kong. We explored the utility of terrestrial hyperspectral remote sensing and Deep Neural Network for urban tree species identification and characterizing. This provides a unique baseline to understand hyperspectral characteristics and seasonality of urban tree species in Hong Kong that can also contribute to hyperspectral imaging and database development elsewhere in the world.}
}
@article{ZHANG2019104943,
title = {Monitoring plant diseases and pests through remote sensing technology: A review},
journal = {Computers and Electronics in Agriculture},
volume = {165},
pages = {104943},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.104943},
url = {https://www.sciencedirect.com/science/article/pii/S016816991930290X},
author = {Jingcheng Zhang and Yanbo Huang and Ruiliang Pu and Pablo Gonzalez-Moreno and Lin Yuan and Kaihua Wu and Wenjiang Huang},
keywords = {Remote sensing, Plant diseases and pests, Features, Models, Algorithms},
abstract = {Plant diseases and pests endanger agriculture and forestry significantly around the world. The implementation of non-contact, highly-efficient, and affordable methods for detecting and monitoring plant diseases and pests over vast areas could greatly facilitate plant protection. In this respect, different forms of remote sensing methods have been introduced for detecting and monitoring plant diseases and pests in many ways. This review outlines the state-of-the-art research achievements in relation to sensing technologies, feature extraction, and monitoring algorithms that have been conducted at multiple scales. Based on their characteristics and maturity in detecting and monitoring plant diseases and pests, sensing systems are classified into groups that include: visible & near-infrared spectral sensors (VIS-NIR); fluorescence and thermal sensors; and synthetic aperture radar (SAR) and light detection and ranging (Lidar) systems. Based on the data acquired from these remote sensing systems and sensitivity analysis, a variety of remote sensing features are proposed and identified as surrogates in the detection and monitoring processes. They include (1) optical, fluorescence, and thermal parameters; (2) image-based landscape features; and (3) features associated with habitat suitability. We also review the algorithms that link the remote sensing features with the occurrence of plant diseases and pests for identifying, differentiating and determining severity of diseases and pests over large areas. The algorithms including statistical discriminant analyses, machine learning algorithms, regression-based models and spectral unmixing algorithms using data collected at a single time or multiple times. Finally, according to the review, we provide a general framework to facilitate the monitoring of an unknown disease or pest highlighting future challenges and trends.}
}
@article{BRIECHLE2021102292,
title = {Silvi-Net – A dual-CNN approach for combined classification of tree species and standing dead trees from remote sensing data},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {98},
pages = {102292},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2020.102292},
url = {https://www.sciencedirect.com/science/article/pii/S0303243420309351},
author = {S. Briechle and P. Krzystek and G. Vosselman},
keywords = {ALS, Multispectral imagery, 3D vegetation mapping, Dead trees, CNN, Transfer learning},
abstract = {Forest managers and nature conservationists rely on precise mapping of single trees from remote sensing data for efficient estimation of forest attributes. In recent years, additional quantification of dead wood in particular has garnered interest. However, tree-level approaches utilizing segmented single trees are still limited in accuracy and their application is therefore mostly restricted to research studies. Furthermore, the combined classification of presegmented single trees with respect to tree species and health status is important for practical use but has been insufficiently investigated so far. Therefore, we introduce Silvi-Net, an approach based on convolutional neural networks (CNNs) fusing airborne lidar data and multispectral (MS) images for 3D object classification. First, we segment single 3D trees from the lidar point cloud, render multiple silhouette-like side-view images, and enrich them with calibrated laser echo characteristics. Second, projected outlines of the segmented trees are used to crop and mask the MS orthomosaic and to generate MS image patches for each tree. Third, we independently train two ResNet-18 networks to learn meaningful features from both datasets. This optimization process is based on pretrained CNN weights and recursive retraining of model parameters. Finally, the extracted features are fused for a final classification step based on a standard multi-layer perceptron and majority voting. We analyzed the network’s performance on data captured in two study areas, the Chernobyl Exclusion Zone (ChEZ) and the Bavarian Forest National Park (BFNP). For both study areas, the lidar point density was approximately 55 points/m2 and the ground sampling distance values of the true orthophotos were 10 cm (ChEZ) and 20 cm (BFNP). In general, the trained models showed high generalization capacity on independent test data, achieving an overall accuracy (OA) of 96.1% for the classification of pines, birches, alders, and dead trees (ChEZ) - and 91.5% for coniferous, deciduous, snags, and dead trees (BFNP). Interestingly, lidar-based imagery increased the OA by 2.5% (ChEZ) and 5.9% (BFNP) compared to experiments only utilizing MS imagery. Moreover, Silvi-Net also demonstrated superior OA compared to the baseline method PointNet++ by 11.3% (ChEZ) and 2.2% (BFNP). Overall, the effectiveness of our approach was proven using 2D and 3D datasets from two natural forest areas (400–530 trees/ha), acquired with different sensor models, and varying geometric and spectral resolution. Using the technique of transfer learning, Silvi-Net facilitates fast model convergence, even for datasets with a reduced number of samples. Consequently, operators can generate reliable maps that are of major importance in applications such as automated inventory and monitoring projects.}
}
@article{LEE2021103847,
title = {Semantic segmentation of bridge components based on hierarchical point cloud model},
journal = {Automation in Construction},
volume = {130},
pages = {103847},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103847},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521002983},
author = {Jun S. Lee and Jeongjun Park and Young-Moo Ryu},
keywords = {Point cloud, Semantic segmentation, Hierarchical graph neural network, Bridge components},
abstract = {Geometric information such as the volumetric dimensions and type of a bridge can be retrieved by means of a terrestrial laser scanner, and the point cloud (PC) data thus obtained can be used to build 3-dimensional (3D) objects such as bridge components in the Building Information Modeling (BIM) framework. For modeling of PC data, PointNet (Qi et al., 2018) and a graph-based convolutional neural network (GCNN) model known as dynamic GCNN (DGCNN; Wang et al., 2019) have been widely employed. In this study, a graph-based hierarchical DGCNN (HGCNN) model is proposed for more accurate and realistic representation of railway bridges having electric poles. The model obtains detailed local features by incrementally considering neighboring points while the total number of neighbors remains the same. Field application reveals that the proposed HGCNN model can represent tall components such as electric poles more precisely, while the overall accuracy of semantic segmentation is dominated by bulky components such as decks, so that the differences among the models (PointNet, DGCNN and HGCNN) are not significant. Specifically, the recall and intersection over union (IoU) rate of the electric pole were improved by about 3% when using the proposed model. A few parametric studies were also performed, and it was demonstrated that the proposed model with its expanded local features provides more precise information near the object boundaries.}
}
@article{GUNAWAN2021648,
title = {Lightweight End to end Pose-Robust face recognition system with Deep Residual Equivariant Mapping},
journal = {Procedia Computer Science},
volume = {179},
pages = {648-655},
year = {2021},
note = {5th International Conference on Computer Science and Computational Intelligence 2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.01.051},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921000594},
author = {Kevin William Gunawan and Noptovius Halimawan and  Suharjito},
keywords = {face recognition, pose-robust, lightweight, deep learning},
abstract = {In the face recognition field of study, pose-robustness and lightness of a model are few of the critical improvement factors of face recognition. However, these fields are still providing challenge for researchers. Even though pose variance is proven to drop the accuracy of deep learning-based models, pose-robustness is not studied often in lightweight face recognition models. Existing pose-robust models have heavier implementation costs compared to lightweight models. We propose a deep learning architecture that implements Deep Residual Equivariant Mapping (DREAM) to improve pose-robustness of a lightweight MobileFaceNets model as a solution to the underlying issue. In the proposed model, the DREAM block is stitched to the MobileFaceNets stem CNN architecture. The evaluation process compares the speed, file size, and accuracy on pose diverse datasets, such as the CFP and IJB-A dataset. The evaluation results of the proposed model show an accuracy improvement of 0.07% with verification speed difference of 0.17 ms. Both of the results show a better performance compared to the baseline naive model.}
}
@article{TANVINEWAZ2022105618,
title = {A review and assessment of technologies for addressing the risk of falling from height on construction sites},
journal = {Safety Science},
volume = {147},
pages = {105618},
year = {2022},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2021.105618},
url = {https://www.sciencedirect.com/science/article/pii/S0925753521004586},
author = {Mohammad {Tanvi Newaz} and Mahmoud Ershadi and Luke Carothers and Marcus Jefferies and Peter Davis},
keywords = {Falling from height, Safety technology, Construction industry, Feasibility assessment},
abstract = {Falling from height (FFH) is blamed for causing significant injuries and deaths on construction sites. Previous research has outlined a broad range of technological advances facilitating the management of the FFH safety risk. However, the extant literature lacks a comprehensive assessment to investigate the contribution of various FFH technologies, as well as their implementation feasibility on construction sites, which provides rationale for this study. The study aims to assess recent safety technologies which can be used to control the risk of FFH on construction sites, especially in urban building construction projects. A scoping review was conducted to identify such technologies and provide insight into their application in the construction industry. As a result of searching Scopus, Web of Science, and Google Scholar databases between 2010 and 2021, a total of 86 representative studies were selected and reviewed. Following this stage, an assessment of their feasibility was carried out based on a set of criteria from the literature. A total of 7 FFH technologies were identified, characterising the contribution of recent technologies to the prediction, prevention, and mitigation of FFH risks. These technologies include (1) Safety risk assessment and propagation, (2) real-time sensing and monitoring, (3) automated prevention through design, (4) ontology and knowledge modelling, (5) virtual reality for FFH training, (6) personal fall arrest systems, and (7) collective fall protection systems. This research contributes to an improved understanding of the status of FFH technologies. The feasibility assessment provides insight into suitable technologies for construction projects of various sizes and features.}
}
@article{SUN2020508,
title = {Non-intrusive reduced-order model for predicting transonic flow with varying geometries},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {2},
pages = {508-519},
year = {2020},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2019.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120300352},
author = {Zhiwei SUN and Chen WANG and Yu ZHENG and Junqiang BAI and Zheng LI and Qiang XIA and Qiujun FU},
keywords = {Artificial Neural Network, Domain decomposition, Geometric parameters, Non-Intrusive Reduced-Order Model, Proper Orthogonal Decomposition, Transonic flow},
abstract = {A Non-Intrusive Reduced-Order Model (NIROM) based on Proper Orthogonal Decomposition (POD) has been proposed for predicting the flow fields of transonic airfoils with geometry parameters. To provide a better reduced-order subspace to approximate the real flow field, a domain decomposition method has been used to separate the hard-to-predict regions from the full field and POD has been adopted in the regions individually. An Artificial Neural Network (ANN) has replaced the Radial Basis Function (RBF) to interpolate the coefficients of the POD modes, aiming at improving the approximation accuracy of the NIROM for non-samples. When predicting the flow fields of transonic airfoils, the proposed NIROM has demonstrated a high performance.}
}
@article{KUMAR2021109558,
title = {Recent developments on target tracking problems: A review},
journal = {Ocean Engineering},
volume = {236},
pages = {109558},
year = {2021},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2021.109558},
url = {https://www.sciencedirect.com/science/article/pii/S0029801821009471},
author = {Manav Kumar and Sharifuddin Mondal},
keywords = {AUV, UAV, AUAV, PUAV, MTT},
abstract = {Recent progresses in the target tracking technology have changed current unmanned systems into a realistic substitute to the conventional tracking systems. In this paper, existing algorithms on target tracking for both aerial and underwater application scenario are classified based on the active and passive modes of target tracking. These algorithms are analysed and compared in the form of mode, tracking technology and respective validation algorithm available in the literature. From this survey, the future directions and major challenges are edged to obtain higher level of tracking performance.}
}
@article{SEKARAN2021100522,
title = {Multivariate regressive deep stochastic artificial learning for energy and cost efficient 6G communication},
journal = {Sustainable Computing: Informatics and Systems},
volume = {30},
pages = {100522},
year = {2021},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2021.100522},
url = {https://www.sciencedirect.com/science/article/pii/S2210537921000159},
author = {Ramesh Sekaran and Manikandan Ramachandran and Rizwan Patan and Fadi Al-Turjman},
keywords = {6G wireless networks, Energy and cost-efficient reliable communication, Deep stochastic artificial structure learning, Multivariate regression function, Soft step activation},
abstract = {In recent years, with the development of 6G networks in mobile computing, the energy consumption of data centers has increased significantly. Therefore, energy saving in data centers has become an important research direction for sustainable computing. High-energy consumption is not only detrimental to the environment but also raises the operating costs. In order to improve the energy and cost aware communication, a new technique called Multivariate Regressive Deep Stochastic Artificial Structure Learning (MRDSASL) is introduced in the 6G network. The input layer of deep stochastic artificial Structure Learning receives the several nodes and it transferred into the next layer called hidden layer where the node energy levels are estimated. Followed by, the received signal strength of the nodes is evaluated in the next consecutive hidden layer. Then the spectrum utilization is also measured in the third hidden layer. At last hidden layer, the multivariate regression function is employed to analyze the estimated node status with the threshold. Finally, the soft step activation function finds the efficient nodes through the regression analysis. Based on the deep analysis, the 6G architecture is designed with the efficient nodes. By selecting the node with higher energy, signal strength and spectrum utilization, data communication performance can be improved with minimum cost in 6G network. The simulation assessment of proposal technique and other related works are carried out in terms of metrics namely energy consumption, cost and packet delivery ratio. The simulation result illustrates that the MRDSASL technique improves the packet delivery ratio 12 %, minimizes the energy consumption by 12 %, and reduces the delay 12 % as compared to state-of-the-art works. The assessment and conferred results reveal the improvement of proposed technique in the 6G network.}
}
@article{MOSHREFJAVADI2021114854,
title = {Applications and Research avenues for drone-based models in logistics: A classification and review},
journal = {Expert Systems with Applications},
volume = {177},
pages = {114854},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114854},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421002955},
author = {Mohammad Moshref-Javadi and Matthias Winkenbach},
keywords = {Drone logistics, Routing optimization, Last-mile delivery, Unmanned aerial vehicle},
abstract = {The operational design and planning of drone-based logistics models is a rapidly growing area of scientific research. In this paper, we present a structured, comprehensive, and scalable framework for classifying drone-based delivery systems and their associated routing problems along with a comprehensive review and synthesis of the extant academic literature in this domain. While our proposed classification defines the boundaries and facilitates the comparison between a wide variety of possible drone-based logistics systems, our comprehensive literature review helps to identify and prioritize research gaps that need to be addressed by future work. Our review shows that the extant research reasonably considers some relevant real-world operational constraints. Although the multi-visit multi-drone Pure-play Drone-based (PD) delivery models are popular, the majority of the Synchronized Multi-modal (SM) delivery models focus on formulating and evaluating single-truck, single-drone models. Moreover, the Resupply Multi-modal (RM) models have not received the due attention for research compared to other drone-based delivery models. Our comprehensive review of use cases of drones for delivery indicates that most of the reviewed models are designed for applications in e-commerce and healthcare/emergency services. Other applications, such as food and mail deliveries are still underrepresented in the academic discussion.}
}
@article{GARCIARUIZ20151,
title = {Sugar beet (Beta vulgaris L.) and thistle (Cirsium arvensis L.) discrimination based on field spectral data},
journal = {Biosystems Engineering},
volume = {139},
pages = {1-15},
year = {2015},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2015.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S1537511015001270},
author = {Francisco J. Garcia-Ruiz and Dvoralai Wulfsohn and Jesper Rasmussen},
keywords = {Crop-weed discrimination, Multispectral imaging, Partial Least Squares Discriminant Analysis (PLS-DA), Smooth fractionator, UAV},
abstract = {Creeping thistle (Cirsium arvensis (L.) Scop.) is a perennial weed that causes yield loss in sugar beet (Beta vulgaris L.) crops. The weeds are usually mapped for site specific weed management because they tend to grow in patches. Remote sensing techniques have shown promising results in species discrimination and therefore provide potential for weed mapping. In this study we examined the feasibility of high-resolution imaging for sugar beet and thistle discrimination and proposed a protocol to select multispectral camera filters. Spectral samples from sugar beet and thistle were acquired with a field portable spectroradiometer under field conditions and Partial Least Squares Discriminant Analysis (PLS-DA) classification models were developed with 211 and 36 spectral features of 1.56 and 10 nm bandwidths, respectively. The classification rates obtained using these models were regarded as the maximum obtainable. Then, spectral responses of a multi-band camera equipped with the filter configuration proposed by the PLS-DA models were simulated. Finally, a simulation of crop-weed discrimination was made using small unmanned aerial vehicles (UAV)-based multispectral images. More than 95% of the thistles and 89% of the sugar beets were correctly classified when continuous spectral data were used with 1.56 and 10 nm bandwidths. Accuracy dropped to 93% of thistles identified and 84% of sugar beets correctly classified when only the four best bands were used. The validation based on aerial images showed that sugar beets and thistle plants could be discriminated in images if sufficient pure pixels containing leaf spectra were available, that is with spatial resolutions of 6 mm pixel−1 or finer.}
}
@article{DINIZ2017261,
title = {An FPGA-based architecture for embedded systems performance acceleration applied to Optimum-Path Forest classifier},
journal = {Microprocessors and Microsystems},
volume = {52},
pages = {261-271},
year = {2017},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2017.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S0141933116302290},
author = {Wendell F.S. Diniz and Vincent Fremont and Isabelle Fantoni and Eurípedes G.O. Nóbrega},
keywords = {FPGA Implementation, Machine learning, Classification, Optimum-Path Forest},
abstract = {Classification techniques development constitutes a foundation for machine learning evolution, which has become a major part of the current mainstream of Artificial Intelligence research lines. However, the computational cost associated with these techniques limits their use in resource constrained embedded platforms. As the classification task is often combined with other high computational cost functions, efficient performance of the main modules is fundamental requirements to achieve hard real-time speed for the whole system. Graph-based machine learning techniques offer a powerful framework for building classifiers. Optimum-Path Forest (OPF) is a graph-based classifier presenting the interesting ability to provide nonlinear classes separation surfaces. This work proposes a SoC/FPGA based design and implementation of an architecture for embedded applications, presenting a hardware converted algorithm for an OPF classifier. Comparison of the achieved results with an embedded processor software implementation shows accelerations of the OPF classification from 2.18 to 9 times, which permits to expect real-time performance to embedded applications.}
}
@article{RAMCHURN2021102891,
title = {Trustworthy human-AI partnerships},
journal = {iScience},
volume = {24},
number = {8},
pages = {102891},
year = {2021},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2021.102891},
url = {https://www.sciencedirect.com/science/article/pii/S2589004221008592},
author = {Sarvapali D. Ramchurn and Sebastian Stein and Nicholas R. Jennings},
keywords = {Artificial intelligence, Human-computer interaction, Sociology},
abstract = {Summary
In this paper, we foreground some of the key research challenges that arise in the design of trustworthy human-AI partnerships. In particular, we focus on the challenges in designing human-AI partnerships that need to be addressed to help humans and organizations trust their machine counterparts individually or as a collective (e.g., as robot teams or groups of software agents). We also aim to identify the risks associated with human-AI partnerships and therefore determine the associated measures to mitigate these risks. By so doing, we will trigger new avenues of research that will address the key barriers to the adoption of AI-based systems more widely in our daily lives and in industry.}
}
@article{NOUSI2020115969,
title = {Re-identification framework for long term visual object tracking based on object detection and classification},
journal = {Signal Processing: Image Communication},
volume = {88},
pages = {115969},
year = {2020},
issn = {0923-5965},
doi = {https://doi.org/10.1016/j.image.2020.115969},
url = {https://www.sciencedirect.com/science/article/pii/S0923596520301429},
author = {Paraskevi Nousi and Danai Triantafyllidou and Anastasios Tefas and Ioannis Pitas},
keywords = {Visual object tracking, Long-term tracking, Re-detection, Deep learning},
abstract = {In this paper, we address the problem of long-term visual object tracking and we present an efficient real-time single object tracking system suitable for integration in autonomous platforms that need to encompass intelligent capabilities. We propose a novel long-term tracking framework for classification based re-detection and tracking, that incorporates state estimation, object re-identification and automated management of tracking and detection results. Our method integrates a novel object re-identification technique which efficiently filters a number of detection candidates and systematically corrects the tracking results. Through extensive experimental validation on the UAV123, UAV20L and TLP datasets, we demonstrate the effectiveness of the proposed system and its advantage over several state-of-the art trackers. The results furthermore highlight the proposed tracker’s ability to handle challenges arising from real-world and long-term scenarios, such as variations in pose, scale, occlusions and out-of-view situations. Furthermore, we propose a variant that is suitable for deployment on autonomous robots, such as Unmanned Aerial Vehicles.}
}
@article{HBAIEB2022108558,
title = {A survey of trust management in the Internet of Vehicles},
journal = {Computer Networks},
volume = {203},
pages = {108558},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108558},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621004758},
author = {Amal Hbaieb and Samiha Ayed and Lamia Chaari},
keywords = {Vehicular networks, VANET, IoV, V2X, Trust management, Security, Blockchain},
abstract = {In recent years, the emergence of the Internet of Vehicles (IoV) aims to enhance the users’ quality of experience through proposing more sophisticated services ranging from guaranteeing the user safety to improving his comfort. The IoV ecosystem is complex, heterogeneous, and evolving. Many entities participate to compose its architecture (such as vehicles, humans, roadside units, ITS). Moreover, different communication types co-exist to ensure the IoV connectivity and continuity. This diversity leads to new security requirements that seem more complex to take into account and enlarge the attack surface of such ecosystem. Many security mechanisms should be considered to enforce the security of IoV environment at many levels: data, entities, communications, storage, etc.. Trust management is one of the potential security mechanisms that aims to increase the reliability within the IoV environment. The topic has been widely explored within the vehicular ad hoc networks (VANETs). However, the VANET represents only one component of the IoV ecosystem. Thus, the approaches proposed for the VANET should be adapted to be applied for the IoV. Moreover, the advent of the emerging technologies like blockchain, cloud, SDN as well as artificial intelligence bring new opportunities to propose more relevant approaches within the trust management mechanisms within the IoV context. Accordingly, this survey deals with the literature about the trust management topic in vehicular environments. The scope considers the IoV environment as well as the relevant approaches proposed for the VANET context since it is one of the important component of the IoV ecosystem. We start by quickly reviewing the existing surveys about security of the vehicular environments. Then, we give a general overview about trust concepts. Afterwards, we present the security and trust challenges and attacks in the vehicular context. Later, we classify and compare the most relevant approaches related to the trust management for the IoV proposing a new taxonomy. We complete this survey by highlighting the open future directions and perspectives for research.}
}
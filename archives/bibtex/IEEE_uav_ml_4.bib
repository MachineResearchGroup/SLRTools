@INPROCEEDINGS{7438508,
author={Braga, José R. G. and Velho, Haroldo F. de C. and Shiguemori, Élcio H.},
booktitle={2015 9th International Conference on Sensing Technology (ICST)}, title={Estimation of UAV position using LiDAR images for autonomous navigation over the ocean},
year={2015},
volume={},
number={},
pages={811-816},
abstract={The use of autonomous navigation in Unmanned Aerial Vehicles is growing every day, in many areas, due to the low cost of its deployment and also does not require a pilot in a ground station. The most applied technique for autonomous navigation of Unmanned Aerial Vehicles is the joint use of Global Navigation Satellite System with Inertial Navigation System, an alternative for this technique is the autonomous navigation through image processing. To perform the autonomous navigation of Unmanned Aerial Vehicles through image processing are used usually images that has landmarks in the ground to guide the trajectory. But, still is a challenge perform the autonomous navigation of Unmanned Aerial Vehicles through image processing, without Global Navigation Satellite System combined with Inertial Navigation System, over regions without landmarks, such as the ocean. Therefore, this research presents a methodology to perform the estimation of Unmanned Aerial Vehicles position in LiDAR images to allow that it performs the autonomous navigation over the ocean.},
keywords={Laser radar;Trajectory;Artificial neural networks;Image edge detection;Neurons;Oceans;Training},
doi={10.1109/ICSensT.2015.7438508},
ISSN={2156-8073},
month={Dec},}
@INPROCEEDINGS{9172808,
author={Sandino, Juan and Vanegas, Fernando and Gonzalez, Felipe and Maire, Frederic},
booktitle={2020 IEEE Aerospace Conference}, title={Autonomous UAV Navigation for Active Perception of Targets in Uncertain and Cluttered Environments},
year={2020},
volume={},
number={},
pages={1-12},
abstract={The use of Small Unmanned Aerial Vehicles (sUAVs) has grown exponentially owing to an increasing number of autonomous capabilities. Automated functions include the return to home at critical energy levels, collision avoidance, take-off and landing, and target tracking. However, sUAVs applications in real-world and time-critical scenarios, such as Search and Rescue (SAR) is still limited. In SAR applications, the overarching aim of autonomous sUAV navigation is the quick localisation, identification and quantification of victims to prioritise emergency response in affected zones. Traditionally, sUAV pilots are exposed to prolonged use of visual systems to interact with the environment, which causes fatigue and sensory overloads. Nevertheless, the search for victims onboard a sUAV is challenging because of noise in the data, low image resolution, illumination conditions, and partial (or full) occlusion between the victims and surrounding structures. This paper presents an autonomous Sequential Decision Process (SDP) for sUAV navigation that incorporates target detection uncertainty from vision-based cameras. The SDP is modelled as a Partially Observable Markov Decision Process (POMDP) and solved online using the Adaptive Belief Tree (ABT) algorithm. In particular, a detailed model of target detection uncertainty from deep learning-based models is shown. The presented formulation is tested under Software in the Loop (SITL) through Gazebo, Robot Operating System (ROS), and PX4 firmware. A Hardware in the Loop (HITL) implementation is also presented using an Intel Myriad Vision Processing Unit (VPU) device and ROS. Tests are conducted in a simulated SAR GPS-denied scenario, aimed to find a person at different levels of location and pose uncertainty.},
keywords={},
doi={10.1109/AERO47225.2020.9172808},
ISSN={1095-323X},
month={March},}
@INPROCEEDINGS{9588681,
author={Bhat, Manohar and Mahto, Gopikishan and Kesaria, Smit and Femandes, Vikrant and Arya, Kavi},
booktitle={2021 International Symposium of Asian Control Association on Intelligent Robotics and Industrial Automation (IRIA)}, title={Real-time gesture control UAV with a low resource framework},
year={2021},
volume={},
number={},
pages={19-24},
abstract={This study showcases a low-resource framework that enables people with no technical know-how to interact with drones, it also explores the capabilities of 2D- computer vision and deep learning techniques for gesture based interface systems on a low-cost micro drone with an onboard RGB camera. This Human-Robot Interaction system processes the real-time human pose to allow a user to command the drone, i.e., by providing direction to move and execute actions. A linear PD controller and image processing techniques are implemented to track humans whilst maintaining a safe distance from the user by perceiving depth information through pose estimation. We incorporated the gesture recognition results into a drone using the Robot Operating System (ROS) and evaluated system performance indoor and outdoor. This low computation framework can be applied further to control robotic arms or mobile robots.},
keywords={Service robots;Tracking;System performance;Operating systems;Pose estimation;Manipulators;Real-time systems;AUV control;Robotic control;AI and ML in robotics;Human Robot Interaction;gesture recognition;Robot Operating System;DJI Tello drone},
doi={10.1109/IRIA53009.2021.9588681},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9042120,
author={Rădescu, Radu and Dragu, Mihaela},
booktitle={2019 11th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)}, title={Automatic Analysis of Potential Hazard Events Using Unmanned Aerial Vehicles},
year={2019},
volume={},
number={},
pages={1-6},
abstract={This paper is motivated by the possibility of developing a wide variety of applications and domains in which Unmanned Aerial Vehicles (UAVs) can be used globally for various purposes. UAVs are currently used by public administrations and security forces such as police, fire brigades, civil protection, research institutions, construction, and agriculture entities. The purpose of this paper is to facilitate the handling of UAVs to retrieve various data from the environment. The drone (UAV) visits some points to collect data (image and/or video input) from sensors like GPS, camera, gyroscope, and accelerometer. GPS sensor coordinates are used to compare the data taken with subsequent results through processing with specialized software. The drone is used as an access gate with built-in sensors. Certain hazard events (fires, floods, avalanches, landslides) are not limited to narrow geographical areas, but can impact the environment by triggering negative chain events. 3D modeling offers a wide range of possibilities to prevent potential hazard events, or, if such an event has occurred, makes it possible to monitor the affected area and assess the damage by comparing the area in the pre-event configuration with the after-event one. After image processing and data acquisition, a report is generated that includes the map and the 3D model of the analyzed object. A hazard is an agent that has the potential to cause damage to a particular target. Terms such as risk or danger can be used in similar contexts. TensorFlow is an open source software library in high-performance computing. Flexible architecture allows easy deployment of computing on a variety of platforms (CPU, GPU, TPU), from desktop to server or mobile devices. We used the learning transfer: at first we used a model that was already prepared for another problem, and then we re-qualified it on a similar problem. Deep learning from scratch can take several days, but learning transfer can be done shortly. We applied Python along with TensorFlow to train an image classifier and classify images with it. We formed a consistent set of training pictures, using three labels: fire, flood (detectable hazards) and nature (non-hazard images). We then re-qualified an efficient, small-sized neural network by (re)training the image set in order to get the best results in the hazards prediction selection process with a progressive higher accuracy as (re) training evolves at optimal rating. With Python and OpenCV technologies, we used four decision algorithms to generate prediction of hazard: Support Vector Machine, Naive Bayes, Logistic Regression, and Decision Tree Classifier. Each generated report includes precision, recall, f1-score, and support indices, depending on the class and intervals used. We also used the confusion matrix as an alternative method to evaluate the classification accuracy. Analyzing the 4 algorithms we noticed that they behave differently. Training using TensorFlow generated better results than the other methods. For the main classes tested hazard is recognized up to 99%.},
keywords={UAV;hazard;classifiers;decision;prediction},
doi={10.1109/ECAI46879.2019.9042120},
ISSN={},
month={June},}
@INPROCEEDINGS{8705853,
author={Liu, Kaikai and Chauhan, Shivam and Devaraj, Revathy and Shahi, Sneha and Sreekumar, Unnikrishnan},
booktitle={2019 IEEE International Conference on Service-Oriented System Engineering (SOSE)}, title={Enabling Autonomous Unmanned Aerial Systems via Edge Computing},
year={2019},
volume={},
number={},
pages={374-3745},
abstract={Unmanned Aerial Systems (UASs) have continuously demonstrated incredible value assisting with disasters such as wildfires and hurricanes. For example, UASs can help reduce risk in firefighting and increase useful data that can aid in developing a more informed strategy. Yet, performing tasks safely through tight spaces and accurately detecting nearby objects remains a major challenge facing fully autonomous flying. Due to the safety concern, CAL Fire has resisted the use of fire service UASs due to the unreliability of collision avoidance. Realizing the full potential of UASs for assisting with disasters will call for autonomous UASs that must be autonomous, taskable, and adaptive to incident situations, and respect safety, privacy, and regulatory concerns. In this paper, we propose the development of autonomous UASs capable of autonomous navigation, localization, 3-D mapping, and achieve on-board data processing and decision making. The UAS will fly and make decision using only on-board sensors and processors. Our contribution covers hardware design and embedded programming to multi-modal sensing, vision-based navigation, and hybrid mapping. We developed a new edge computing and sensing system for UASs which is compatible with existing open source autopilot software and deep-learning frameworks. We proposed a multi-modal sensing based hybrid localization and obstacle detection approach that runs in real time on board. The output of the localization and obstacle detection results is fused with high-level understanding and is used to control the UASs locally without rely on the link to a ground station. Our evaluation results demonstrate an autonomous UAS flying based on pre-defined destinations with on-board deep learning for perception and obstacle avoidance.},
keywords={Drones;Cameras;Navigation;Sensors;Edge computing;Software;Hardware;autonomous drones;unmanned aerial vehicle;multi-sensor perception},
doi={10.1109/SOSE.2019.00063},
ISSN={2642-6587},
month={April},}
@INPROCEEDINGS{8751810,
author={Celen, Burak and Oniz, Yesim},
booktitle={2018 6th International Conference on Control Engineering Information Technology (CEIT)}, title={Trajectory Tracking of a Quadcopter Using Fuzzy Logic and Neural Network Controllers},
year={2018},
volume={},
number={},
pages={1-6},
abstract={In this work, the trajectory tracking control of an Unmanned Aerial Vehicle (UAV) has been realised using fuzzy logic and neural network based controllers. Parrot AR.Drone 2.0 has been selected as the test platform. For simulated and real-time experimental studies, a square shaped reference trajectory has been generated, and the discrepancies from this trajectory in x-and y-directions along with their derivatives have been employed as the input signals to the proposed controllers. The update rules for the neural network have been derived based on the variable structure systems theory to enable stable online tuning of the parameters. The obtained results indicate that both fuzzy logic and neural network controllers can be applied effectively to the trajectory tracking of a drone, and particularly neural networks with variable structure systems theory based learning algorithms exhibit a highly robust behaviour against disturbances.},
keywords={Drones;Fuzzy logic;Neural networks;Trajectory;Mathematical model;Trajectory tracking;Simulation},
doi={10.1109/CEIT.2018.8751810},
ISSN={},
month={Oct},}
@ARTICLE{9615114,
author={Yang, Zhong and Chen, Mingzhe and Liu, Xiao and Liu, Yuanwei and Chen, Yue and Cui, Shuguang and Poor, H. Vincent},
journal={IEEE Wireless Communications}, title={AI-Driven UAV-NOMA-MEC in Next Generation Wireless Networks},
year={2021},
volume={28},
number={5},
pages={66-73},
abstract={Driven by the unprecedented high throughput and low latency requirements anticipated for next generation wireless networks, this article introduces an artificial intelligence (AI)-enabled framework in which unmanned aerial vehicles use non-orthogonal multiple access and mobile edge computing techniques to serve terrestrial mobile users (MUs). The proposed framework enables terrestrial MUs to offload their computational tasks simultaneously, intelligently, and flexibly, thus enhancing their connectivity as well as reducing their transmission latency and energy consumption. In particular, the fundamentals of this framework are first introduced. Then a number of communication and AI techniques are proposed to improve the quality of experience of terrestrial MUs. In particular, federated learning and reinforcement learning are introduced for intelligent task offloading and computing resource allocation. For each learning technique, motivations, challenges, and representative results are introduced. Finally, several key technical challenges and open research issues of the proposed framework are summarized.},
keywords={NOMA;Wireless networks;Reinforcement learning;Throughput;Unmanned aerial vehicles;Resource management;Quality of experience},
doi={10.1109/MWC.121.2100058},
ISSN={1558-0687},
month={October},}
@INPROCEEDINGS{9597861,
author={González, Fidel and Caballero, Rafael and Pérez-Grau, Francisco J. and Viguria, Antidio},
booktitle={2021 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)}, title={Vision-based UAV Detection for Air-to-Air Neutralization},
year={2021},
volume={},
number={},
pages={236-241},
abstract={The widespread availability of Unmanned Aerial Vehicles (UAVs) poses potential threats for people and properties on the ground, and other airspace users. This work introduces the design, development and validation of a UAV neutralization system that is based on another UAV with a capture device. The operation is fully autonomous, and only relies on data captured by two cameras onboard the captor UAV: one for long-range detections up to 40m, and another one for short-range accurate estimations prior to the actual capture. The approach has been extensively validated in field experiments, proving robustness and computational efficiency.},
keywords={Training;Uncertainty;Neural networks;Estimation;Robot sensing systems;Unmanned aerial vehicles;Robustness},
doi={10.1109/SSRR53300.2021.9597861},
ISSN={2475-8426},
month={Oct},}
@INPROCEEDINGS{9653332,
author={Mokhtari, Mohammed and Bajčetić, Jovan and Sazdić-Jotić, Boban and Pavlović, Boban},
booktitle={2021 29th Telecommunications Forum (TELFOR)}, title={RF-based drone detection and classification system using convolutional neural network},
year={2021},
volume={},
number={},
pages={1-4},
abstract={This paper presents an effort towards developing a detection and classification information system based on the RF signature of several commercial drones. The developed application implements a Convolutional Neural Network which was trained and tested using data from a publically accessible database. The tested neural network reached an accuracy of almost 100% (4-classes), which is considered as a significant contribution to the development of a functional drone detection system. Moreover, the developed interface allows the user to supervise the spectral activity in the 2.4 GHz ISM band, notifies him about the presence and the nature of a potential threat, and stores the event log in a database for later exploitation.},
keywords={Radio frequency;Databases;Neural networks;User interfaces;Real-time systems;Telecommunications;Convolutional neural networks;Classification;Convolutional Neural Network;Detection;Graphical User Interface;UAV},
doi={10.1109/TELFOR52709.2021.9653332},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8587026,
author={Avramović, Aleksej and Jovanović, Vedran and Pilipović, Ratko and Stojnić, Vladan and Risojević, Vladimir and Gajić, Slavica and Simić, Mitar and Ševo, Igor and Muštra, Mario and Babić, Zdenka and Filipi, Janja},
booktitle={2018 14th Symposium on Neural Networks and Applications (NEUREL)}, title={Automatic monitoring of honeybees’ activity outside of the hive from UHD video},
year={2018},
volume={},
number={},
pages={1-4},
abstract={Studying the behavior of social insect using computer vision algorithms is an interesting topic for both biological and signal processing communities. One of the most interesting aspects in the field is tracking of honeybees. Regarding computer vision method, honeybees' behavior has been mostly monitored inside and at the entrance of the hive. In this research we are proposing the method for automatic monitoring of honeybees' activity outside of the hive. Experiments showed that the activity of honeybees outside the hive can estimated using an ultra-high definition video captured with UAV from distance of 10 meters. Specific spots where honeybees are gathered can be detected using heat maps which represent the density of their occurrence in the observed time interval.},
keywords={Gaussian distribution;Electrical engineering;Cameras;Computer vision;Monitoring;Meters;Unmanned aerial vehicles;Moving object tracking;ultra-high definition video;UAV;mixture of Gaussians},
doi={10.1109/NEUREL.2018.8587026},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9551637,
author={le Fevre Sejersen, Jonas and Pimentel De Figueiredo, Rui and Kayacan, Erdal},
booktitle={2021 IEEE 17th International Conference on Automation Science and Engineering (CASE)}, title={Safe Vessel Navigation Visually Aided by Autonomous Unmanned Aerial Vehicles in Congested Harbors and Waterways},
year={2021},
volume={},
number={},
pages={1901-1907},
abstract={In the maritime sector, safe vessel navigation is of great importance, particularly in congested harbors and waterways. The focus of this work is to estimate the distance between an object of interest and potential obstacles using a companion UAV. The proposed approach fuses global positioning system (GPS) data with long-range aerial images. First, we employ semantic segmentation deep neural networks (DNNs) for discriminating the vessel of interest, water, and potential solid objects using raw image data. The network is trained with both real and images generated and automatically labeled from a realistic AirSim simulation environment. Then, the distances between the extracted vessel and non-water obstacle blobs are computed using a novel ground sample distance (GSD) estimation algorithm. To the best of our knowledge, this work is the first attempt to detect and estimate distances to unknown objects from long-range visual data captured with conventional RGB cameras and auxiliary absolute positioning systems (e.g. GPS). The simulation results illustrate the accuracy and efficacy of the proposed method for visually aided navigation of vessels assisted by unmanned aerial vehicles (UAVs).},
keywords={Image segmentation;Visualization;Navigation;Magnetometers;Simulation;Semantics;Estimation},
doi={10.1109/CASE49439.2021.9551637},
ISSN={2161-8089},
month={Aug},}
@INPROCEEDINGS{8795855,
author={Eslamiat, Hossein and Li, Yilan and Wang, Ningshan and Sanyal, Amit K. and Qiu, Qinru},
booktitle={2019 18th European Control Conference (ECC)}, title={Autonomous Waypoint Planning, Optimal Trajectory Generation and Nonlinear Tracking Control for Multi-rotor UAVs},
year={2019},
volume={},
number={},
pages={2695-2700},
abstract={A framework for autonomous waypoint planning, trajectory generation through waypoints, and trajectory tracking for multi-rotor unmanned aerial vehicles (UAVs) is proposed in this work. Safe and effective operations of these UAVs is a problem that demands obstacle avoidance strategies and advanced trajectory planning and control schemes for stability and energy efficiency. To address this problem, a two-level optimization strategy is used for trajectory generation, then the trajectory is tracked in a stable manner. The framework given here consists of the following components: (a) a deep reinforcement learning (DRL)-based algorithm for optimal waypoint planning while minimizing control energy and avoiding obstacles in a given environment; (b) an optimal, smooth trajectory generation algorithm through waypoints, that minimizes a combination of velocity, acceleration, jerk and snap; and (c) a stable tracking control law that determines a control thrust force for an UAV to track the generated trajectory.},
keywords={},
doi={10.23919/ECC.2019.8795855},
ISSN={},
month={June},}
@INPROCEEDINGS{8098659,
author={Pinard, Clement and Chevalley, Laure and Manzanera, Antoine and Filliat, David},
booktitle={2017 European Conference on Mobile Robots (ECMR)}, title={Multi range real-time depth inference from a monocular stabilized footage using a fully convolutional neural network},
year={2017},
volume={},
number={},
pages={1-6},
abstract={We propose a neural network architecture for depth map inference from monocular stabilized videos with application to UAV videos in rigid scenes. Training is based on a novel synthetic dataset for navigation that mimics aerial footage from gimbal stabilized monocular camera in rigid scenes. Based on this network, we propose a multi-range architecture for unconstrained UAV flight, leveraging flight data from sensors to make accurate depth maps for uncluttered outdoor environment. We try our algorithm on both synthetic scenes and real UAV flight data. Quantitative results are given for synthetic scenes with a slightly noisy orientation, and show that our multi-range architecture improves depth inference. Along with this article is a video that present our results more thoroughly.},
keywords={Cameras;Training;Neural networks;Sensors;Computer architecture;Videos;Drones},
doi={10.1109/ECMR.2017.8098659},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8647288,
author={Bisio, Igor and Garibotto, Chiara and Lavagetto, Fabio and Sciarrone, Andrea and Zappatore, Sandro},
booktitle={2018 IEEE Global Communications Conference (GLOBECOM)}, title={Improving WiFi Statistical Fingerprint-Based Detection Techniques Against UAV Stealth Attacks},
year={2018},
volume={},
number={},
pages={1-6},
abstract={The increasing popularity of low-cost aerial vehicles that can be remotely piloted by amateurs, is giving rise to a number of issues related to public safety and privacy. At the same time, the need for surveillance methods able to detect the presence of unauthorized drones meets the ubiquitous connectivity and pervasive technology typical of the big data era. This dualism drives the research community towards the design of monitoring systems able to integrate machine learning methods and data mining techniques in this evolving environment. In this framework, we consider a WiFi based approach aimed at detecting nearby unmanned aerial vehicles, by performing statistical fingerprint analysis on wireless traffic. We study the inherent vulnerabilities of the considered method through real-life experimental tests by setting up specific attack scenarios, and we devise and test a solution in order to improve the efficiency of the proposed technique in the presence of malicious countermeasures. Results show that the proposed improved detection technique is indeed robust to stealth attacks, and it is able to achieve very good recognition performance in different real-life testing scenarios.},
keywords={Drones;Wireless fidelity;Surveillance;Feature extraction;Data mining;Streaming media;Wireless communication},
doi={10.1109/GLOCOM.2018.8647288},
ISSN={2576-6813},
month={Dec},}
@INPROCEEDINGS{9498879,
author={Titouna, Chafiq and Naït-Abdesselam, Farid},
booktitle={2021 International Wireless Communications and Mobile Computing (IWCMC)}, title={Securing Unmanned Aerial Systems Using Mobile Agents and Artificial Neural Networks},
year={2021},
volume={},
number={},
pages={825-830},
abstract={Advances in wireless networks and the rapid development of electronic components have actively contributed to the emergence of new communication and surveillance systems known as Unmanned Aerial Systems (UASs). In such systems, unmanned aerial vehicles (UAVs) can be used as a wireless ad hoc network and thus provide a communications infrastructure for diverse military or civil applications. For more efficiency, a swarm of drones can be deployed in an area of interest (e.g. disaster areas, battlefields) by forming a flying ad hoc network (FANET) capable of communicating wirelessly with a ground control station (GCS) in a more secure manner. In this work, we particularly focus on the detection of False Data Injection (FDI) attacks in Unmanned Aerial Systems. We propose a new approach based on mobile agents to collect data and an artificial neural network model to identify injected false data. Our approach is validated using realistic datasets, provided by the University of Minnesota UAS Laboratories, and our results show that our proposal outperforms the compared approach by demonstrating higher detection rates (>94%) and lower false positive rates (<; 2.2%).},
keywords={Military communication;Wireless networks;Surveillance;Simulation;Mobile agents;Artificial neural networks;Data models;Unmanned aerial vehicles;False data injection attack;Artificial neural network},
doi={10.1109/IWCMC51323.2021.9498879},
ISSN={2376-6506},
month={June},}
@ARTICLE{9130679,
author={Ayyad, Abdulla and Chehadeh, Mohamad and Awad, Mohammad I. and Zweiri, Yahya},
journal={IEEE Access}, title={Real-Time System Identification Using Deep Learning for Linear Processes With Application to Unmanned Aerial Vehicles},
year={2020},
volume={8},
number={},
pages={122539-122553},
abstract={System identification is a key discipline within the field of automation that deals with inferring mathematical models of dynamic systems based on input-output measurements. Conventional identification methods require extensive data generation and are thus not suitable for real-time applications. In this paper, a novel real-time approach for the parametric identification of linear systems using Deep Learning (DL) and the Modified Relay Feedback Test (MRFT) is proposed. The proposed approach requires only a single steady-state cycle of MRFT, and guarantees stability and performance in the identification and control phases. The MRFT output is passed to a trained DL model that identifies the underlying process parameters in milliseconds. A novel modification to the Softmax function is derived to better conform the DL model for the process identification task. Quadrotor Unmanned Aerial Vehicle (UAV) attitude and altitude dynamics were used in simulation and experimentation to verify the presented approach. Results show the effectiveness and real-time capabilities of the proposed approach, which outperforms the conventional Prediction Error Method in terms of accuracy, robustness to biases, computational efficiency and data requirements.},
keywords={Real-time systems;Tuning;Unmanned aerial vehicles;Dynamical systems;Oscillators;Stability analysis;Computational modeling;System identification;unmanned aerial vehicles;learning systems;sliding mode control;process control},
doi={10.1109/ACCESS.2020.3006277},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8417685,
author={Min, Minghui and Xiao, Liang and Xu, Dongjin and Huang, Lianfen and Peng, Mugen},
booktitle={2018 IEEE 87th Vehicular Technology Conference (VTC Spring)}, title={Learning-Based Defense against Malicious Unmanned Aerial Vehicles},
year={2018},
volume={},
number={},
pages={1-5},
abstract={Adversary unmanned aerial vehicles (UAVs) seriously threaten public security and user privacy. In this paper, we propose a reinforcement learning (RL) based defense framework to address malicious UAVs close to a target estate such as a company or an institute. This framework uses Q-learning to choose the defense policy such as jamming the global positioning system signals (GPS) and hacking, and laser shooting. According to the defense history and the current security status of the target estate, this scheme can improve the UAV defense performance in the dynamic game without being aware of the UAV attack policy and environment model in the area of interests. Simulation results show that this scheme can reduce the risk rate of the estate and improve the utility compared with the benchmark scheme against malicious UAVs.},
keywords={Global Positioning System;Unmanned aerial vehicles;Jamming;Games;Learning (artificial intelligence);Computer crime},
doi={10.1109/VTCSpring.2018.8417685},
ISSN={2577-2465},
month={June},}
@INPROCEEDINGS{9637777,
author={Hsieh, Yung-Ting and Anjum, Khizar and Huang, Songjun and Kulkarni, Indraneel and Pompili, Dario},
booktitle={2021 IEEE 18th International Conference on Mobile Ad Hoc and Smart Systems (MASS)}, title={Hybrid Analog-Digital Sensing Approach for Low-power Real-time Anomaly Detection in Drones},
year={2021},
volume={},
number={},
pages={446-454},
abstract={With the rapid growth of the use of Machine Learning (ML) techniques in Unmanned Aerial Vehicles (UAVs), there is an opportunity to use ML techniques to detect and prevent anomalous behavior in drones. However, limited drone power thwarts successful implementation of contemporary power-hungry ML techniques. Therefore, we propose a hybrid analog-digital system to solve the problem of continuous anomaly detection. In this paper, a series of pure analog ML methods including SVMs (linear, polynomial, Radial Basis Function (RBF) and Sigmoid kernels) as well as pure analog fully-connected Neural Network (NN) are presented. We validate our method with sensor data from a series of drone experiments to detect and identify causes of failure in real-time. The results show that RBF kernel provides at least 88.17 % and at most 99.99 % accuracy under different time window and crash-like scenarios with an extremely low False Negative (FN) ratio with sensor data especially in the z-axis.},
keywords={Conferences;Machine learning;Artificial neural networks;Autonomous aerial vehicles;Real-time systems;Sensors;Kernel;Analog;Digital;FPGA;Neural Networks;Anomaly Detection},
doi={10.1109/MASS52906.2021.00062},
ISSN={2155-6814},
month={Oct},}
@INPROCEEDINGS{9286009,
author={Xu, Jia and Liu, Xiao and Li, Xuejun and Zhang, Lei and Yang, Yun},
booktitle={2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, title={EXPRESS: An Energy-Efficient and Secure Framework for Mobile Edge Computing and Blockchain based Smart Systems},
year={2020},
volume={},
number={},
pages={1283-1286},
abstract={As most smart systems such as smart logistic and smart manufacturing are delay sensitive, the current mainstream cloud computing based system architecture is facing the critical issue of high latency over the Internet. Meanwhile, as huge amount of data is generated by smart devices with limited battery and computing power, the increasing demand for energy-efficient machine learning and secure data communication at the network edge has become a hurdle to the success of smart systems. To address these challenges with using smart UAV (Unmanned Aerial Vehicle) delivery system as an example, we propose EXPRESS, a novel energy-efficient and secure framework based on mobile edge computing and blockchain technologies. We focus on computation and data (resource) management which are two of the most prominent components in this framework. The effectiveness of the EXPRESS framework is demonstrated through the implementation of a real-world UAV delivery system. As an open-source framework, EXPRESS can help researchers implement their own prototypes and test their computation and data management strategies in different smart systems. The demo video can be found at https://youtu.be/r3U1iU8tSmk.},
keywords={Systems architecture;Blockchain;Unmanned aerial vehicles;Energy efficiency;Edge computing;Software engineering;Smart manufacturing;Smart System Framework;Mobile Edge Computing;Blockchain;Computation Management;Data Management},
doi={},
ISSN={2643-1572},
month={Sep.},}
@ARTICLE{8255752,
author={Zheng, Zhigao and Sangaiah, Arun Kumar and Wang, Tao},
journal={IEEE Communications Magazine}, title={Adaptive Communication Protocols in Flying Ad Hoc Network},
year={2018},
volume={56},
number={1},
pages={136-142},
abstract={The flying ad hoc network (FANET) is a new paradigm of wireless communication that governs the autonomous movement of UAVs and supports UAV-to-UAV communication. A FANET can provide an effective real-time communication solution for the multiple UAV systems considering each flying UAV as a router. However, existing mobile ad hoc protocols cannot meet the needs of FANETs due to high-speed mobility and frequent topology change. In addition, the complicated flight environment and varied flight tasks lead to the traditional built-in-rules protocols no longer meeting the demands of autonomy. Hence, we have proposed adaptive hybrid communication protocols including a novel position-prediction-based directional MAC protocol (PPMAC) and a self-learning routing protocol based on reinforcement learning (RLSRP). The performance results show that the proposed PPMAC overcomes the directional deafness problem with directional antennas, and RLSRP provides an automatically evolving and more effective routing scheme. Our proposed hybrid adaptive communication protocols have the potential to provide an intelligent and highly autonomous communication solution for FANETs, and indicate the main research orientation of FANET protocols.},
keywords={Routing protocols;Media Access Protocol;Routing;Unmanned aerial vehicles;Directional antennas;Ad hoc networks},
doi={10.1109/MCOM.2017.1700323},
ISSN={1558-1896},
month={Jan},}
@INPROCEEDINGS{7487169,
author={Faust, Aleksandra and Chiang, Hao-Tien and Rackley, Nathanael and Tapia, Lydia},
booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)}, title={Avoiding moving obstacles with stochastic hybrid dynamics using PEARL: PrEference Appraisal Reinforcement Learning},
year={2016},
volume={},
number={},
pages={484-490},
abstract={Manual derivation of optimal robot motions for task completion is difficult, especially when a robot is required to balance its actions between opposing preferences. One solution has been proposed to automatically learn near optimal motions with Reinforcement Learning (RL). This has been successful for several tasks including swing-free UAV flight, table tennis, and autonomous driving. However, high-dimensional problems remain a challenge. We address this dimensionality constraint with PrEference Appraisal Reinforcement Learning (PEARL), which solves tasks with opposing preferences for acceleration controlled robots. PEARL projects the high-dimensional continuous robot state space to a low dimensional preference feature space resulting in efficient and adaptable planning. We demonstrate that on a dynamic obstacle avoidance robotic task, a single learning on a much simpler problem performs real-time decision-making for significantly larger, high-dimensional problems working in unbounded continuous states and actions. We trained the agent with 4 static obstacles, while the trained agent avoids up to 900 moving obstacles with complex hybrid stochastic obstacle dynamics in a highly constrained space using only limited information about the environment. We compare these tasks to traditional, often manually tuned solutions for these high-dimensional problems.},
keywords={Dynamics;Planning;Robot kinematics;Collision avoidance;Aerospace electronics;Acceleration},
doi={10.1109/ICRA.2016.7487169},
ISSN={},
month={May},}
@INPROCEEDINGS{8615853,
author={Le, Xuesong and Wang, Yufei and Jo, Jun},
booktitle={2018 Digital Image Computing: Techniques and Applications (DICTA)}, title={Combining Deep and Handcrafted Image Features for Vehicle Classification in Drone Imagery},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Using unmanned aerial vehicles (UAVs) as devices for traffic data collection exhibits many advantages in collecting traffic information. This paper presents an efficient method based on the deep learning and handcrafted features to classify vehicles taken from drone imagery. Experimental results show that compared to classification algorithms based on pre-trained CNN or hand-crafted features, the proposed algorithm exhibits higher accuracy in vehicle recognition at different UAV altitudes with different view scopes, which can be used in future traffic monitoring and control in metropolitan areas.},
keywords={Feature extraction;Histograms;Training;Drones;Visualization;Image recognition;Deep learning;deep feature;handcrafted features;classification},
doi={10.1109/DICTA.2018.8615853},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8491460,
author={Lucas, Pedro and Loayza, Kleber and Peláez, Enrique},
booktitle={2018 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, title={A Distributed Control of Movements and Fuzzy Logic-Based Task Allocation for a Swarm of Autonomous Agents},
year={2018},
volume={},
number={},
pages={1-8},
abstract={This paper proposes a decentralized method for controlling a swarm of autonomous agents represented as Unmanned Aerial Vehicles (UAVs) to accomplish a set of tasks cooperatively. The task commissioning is carried out by a Fuzzy Logic-based task allocation strategy, and the movement behavior is based on the internal state of the agent as well as the external data from its neighbors through local communications. The solution was modified from a centralized strategy developed in a previous work in order to be enhanced, so the proposed distributed strategy was tested considering the same experiments, configurations and conditions applied to the centralized approach in a simulated environment. To test the strategy, the planned activity to be performed was planting seeds, in a field composed by a grid of points that represents the places to be sown. Completion times and collision avoidance attempts were measured to test the effectiveness, as well as to perform a comparison between the distributed and centralized methods. Important improvements were found considering the size of agents in a swarm.},
keywords={Task analysis;Fuzzy logic;Resource management;Biological system modeling;Mathematical model;Collision avoidance;Particle swarm optimization;swarm intelligence;fuzzy logic;agents behavior;task allocation;farming automation;UAVs},
doi={10.1109/FUZZ-IEEE.2018.8491460},
ISSN={},
month={July},}
@INPROCEEDINGS{8927923,
author={Yuan, Danni and Zhu, Xiaoyan and Mao, Yaoru and Zheng, Binwen and Wu, Tao},
booktitle={2019 11th International Conference on Wireless Communications and Signal Processing (WCSP)}, title={Privacy-Preserving Pedestrian Detection for Smart City with Edge Computing},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Edge computing is an ideal platform for pedestrian detection in smart city because of low latency and location awareness. In edge computing, data collected by IoT devices are processed on edge servers rather than being transported to cloud server. Compared with cloud computing, edge computing could avoid the possibility of pedestrians' privacy being leaked from cloud server or being stolen in the process of transmission. However, edge servers are not always safe. For instance, there are researches show that 89% of WiFi hotspots are unsecured. Hence, it is possible for attackers to know where you go at a given time of the day, which places you prefer to visit from images collected by IoT devices, such as camera, UAVs. Considering the data collected by IoT devices could include the sensitive information about users, we propose a scheme that applies differential privacy to protect the collected data. We experiment on the INRIA Person Dataset and use three deep learning networks. Results show that even though adding differential privacy makes images blurred, the deep learning network on edge servers can detect pedestrians in the images with accuracy as high as 97.3%.},
keywords={Cloud computing;Servers;Machine learning;Edge computing;Image edge detection;Smart cities;Pedestrian detection;differential privacy;smart city;deep learning;edge computing},
doi={10.1109/WCSP.2019.8927923},
ISSN={2472-7628},
month={Oct},}
@INPROCEEDINGS{9553713,
author={Carrillo, Juan and Borda, Katherine},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Recent Advances in Artificial Intelligence and Computer Vision for Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={7959-7962},
abstract={In recent years we have seen an accelerated development in the technologies enabling advanced navigation and control of Unmanned Aerial Vehicles (UAVs). Such progress has been fueled by the combination of improved hardware as well as breakthrough advances in Artificial Intelligence methods to accomplish tasks that were previously though extremely difficult to automate. In this document we present a brief summary of some of the most representative methods focused on enabling advanced perception, collision avoidance, flight planning and control, as well as some key industry applications of these capabilities.},
keywords={Navigation;Image processing;Industry applications;Geoscience and remote sensing;Unmanned aerial vehicles;Hardware;Planning;UAVs;Artificial Intelligence;Computer Vision;Deep Learning},
doi={10.1109/IGARSS47720.2021.9553713},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{8899321,
author={Hoxha, Genc and Melgani, Farid and Demir, Begüm},
booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium}, title={Retrieving Images with Generated Textual Descriptions},
year={2019},
volume={},
number={},
pages={5812-5815},
abstract={This paper presents a novel remote sensing (RS) image retrieval system that is defined based on generation and exploitation of textual descriptions that model the content of RS images. The proposed RS image retrieval system is composed of three main steps. The first one generates textual descriptions of the content of the RS images combining a convolutional neural network (CNN) and a recurrent neural network (RNN) to extract the features of the images and to generate the descriptions of their content, respectively. The second step encodes the semantic content of the generated descriptions using word embedding techniques able to produce semantically rich word vectors. The third step retrieves the most similar images with respect to the query image by measuring the similarity between the encoded generated textual descriptions of the query image and those of the archive. Experimental results on RS image archive composed of RS images acquired by unmanned aerial vehicles (UAVs) are reported and discussed.},
keywords={Semantics;Image retrieval;Feature extraction;Remote sensing;Recurrent neural networks;Unmanned aerial vehicles;Image coding;Image retrieval;image textual description generation;semantic gap;unmanned aerial vehicles (UAV)},
doi={10.1109/IGARSS.2019.8899321},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{8372049,
author={Lelerre, Mathieu and Mouaddib, Abdel-Illah and Jeanpierre, Laurent},
booktitle={2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)}, title={Robust Inverse Planning Approaches for Policy Estimation of Semi-autonomous Agents},
year={2017},
volume={},
number={},
pages={951-958},
abstract={Most of existing coordination techniques for autonomous agents assume the knowledge or the estimation of the other agents' policy. However, this assumption is not valid in semi-autonomous agents because an external entity can take the control and modify the behavior of the agent. We face this problem in applications where an operator can take the control of the system (Robot/UAV). Many human factors may affect this behavior, such as stress, hesitations and preferences. Estimating the policy in such contexts is a difficult problem. Many existing algorithms using Inverse Reinforcement learning or imitation have been developed. However most of them have weak performance when non-optimal policy is followed. In this paper, we investigate techniques for estimating the followed policies of semi-autonomous agents that could be nonoptimal due to critical situations We extend some prediction methods and algorithms based on Factored MDPs and Inverse Reinforcement Learning to improve their stability and their efficiency during the execution of a mission. Then, we develop various experiments showing the performance on efficiency and stability of our approach in different conditions and comparing with it.},
keywords={Estimation;Markov processes;Learning (artificial intelligence);Linear programming;Force;Autonomous agents;Mathematical model;MDP;inverse reinforcement learning;Activity and Plan Recognition},
doi={10.1109/ICTAI.2017.00146},
ISSN={2375-0197},
month={Nov},}
@INPROCEEDINGS{9642199,
author={Shang, Erzhen and Gao, Yang and Li, Yang and Yu, Bo and Sun, Jiasen and Jia, Yilin and Zhong, Cheng and Zhu, Guoqiang and Zhang, Xiuyu},
booktitle={2021 11th International Conference on Intelligent Control and Information Processing (ICICIP)}, title={Event-Triggered Based Adaptive Dynamic Surface Control for a Class of Quadrotor UAVs*},
year={2021},
volume={},
number={},
pages={398-403},
abstract={A hybrid adaptive control scheme for quadrotor control system based on event-triggered mechanism is proposed for the trajectory tracking control problem of quadrotor UAV. The high-gain state observer is constructed to estimate the unmeasurable states, then the adaptive radial basis function neural networks (RBFNNs) dynamic surface control strategy is designed to achieve precise tracking control. The event-triggered mechanism is introduced, which is effective reduces the update frequency of the system control signal. The simulation results show that the proposed control scheme can achieve more accurate tracking performance than the traditional backstepping sliding mode control (BSMC) scheme without sacrificing the tracking performance of the control system.},
keywords={Backstepping;Trajectory tracking;Heuristic algorithms;Simulation;Radial basis function networks;Observers;Trajectory;Quadrotor UAVs;Output-feedback;Dynamic surface control;Event-triggered control},
doi={10.1109/ICICIP53388.2021.9642199},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9183674,
author={Fragkos, Georgios and Tsiropoulou, Eirini Eleni and Papavassiliou, Symeon},
booktitle={2020 16th International Conference on Distributed Computing in Sensor Systems (DCOSS)}, title={Artificial Intelligence Enabled Distributed Edge Computing for Internet of Things Applications},
year={2020},
volume={},
number={},
pages={450-457},
abstract={Artificial Intelligence (AI) based techniques are typically used to model decision making in terms of strategies and mechanisms that can result in optimal payoffs for a number of interacting entities, often presenting antagonistic behaviors. In this paper, we propose an AI-enabled multi-access edge computing (MEC) framework, supported by computing-equipped Unmanned Aerial Vehicles (UAVs) to facilitate IoT applications. Initially, the problem of determining the IoT nodes optimal data offloading strategies to the UAV-mounted MEC servers, while accounting for the IoT nodes' communication and computation overhead, is formulated based on a game-theoretic model. The existence of at least one Pure Nash Equilibrium (PNE) point is shown by proving that the game is submodular. Furthermore, different operation points (i.e. offloading strategies) are obtained and studied, based either on the outcome of Best Response Dynamics (BRD) algorithm, or via alternative reinforcement learning approaches (i.e. gradient ascent, log-linear, and Q-learning algorithms), which explore and learn the environment towards determining the users' stable data offloading strategies. The corresponding outcomes and inherent features of these approaches are critically compared against each other, via modeling and simulation.},
keywords={Servers;Edge computing;Task analysis;Computational modeling;Distributed databases;Artificial intelligence;Games;Edge Computing;Game Theory;Reinforcement Learning;Internet of Things},
doi={10.1109/DCOSS49796.2020.00077},
ISSN={2325-2944},
month={May},}
@ARTICLE{8672604,
author={Cheng, Nan and Lyu, Feng and Quan, Wei and Zhou, Conghao and He, Hongli and Shi, Weisen and Shen, Xuemin},
journal={IEEE Journal on Selected Areas in Communications}, title={Space/Aerial-Assisted Computing Offloading for IoT Applications: A Learning-Based Approach},
year={2019},
volume={37},
number={5},
pages={1117-1129},
abstract={Internet of Things (IoT) computing offloading is a challenging issue, especially in remote areas where common edge/cloud infrastructure is unavailable. In this paper, we present a space-air-ground integrated network (SAGIN) edge/cloud computing architecture for offloading the computation-intensive applications considering remote energy and computation constraints, where flying unmanned aerial vehicles (UAVs) provide near-user edge computing and satellites provide access to the cloud computing. First, for UAV edge servers, we propose a joint resource allocation and task scheduling approach to efficiently allocate the computing resources to virtual machines (VMs) and schedule the offloaded tasks. Second, we investigate the computing offloading problem in SAGIN and propose a learning-based approach to learn the optimal offloading policy from the dynamic SAGIN environments. Specifically, we formulate the offloading decision making as a Markov decision process where the system state considers the network dynamics. To cope with the system dynamics and complexity, we propose a deep reinforcement learning-based computing offloading approach to learn the optimal offloading policy on-the-fly, where we adopt the policy gradient method to handle the large action space and actor-critic method to accelerate the learning process. Simulation results show that the proposed edge VM allocation and task scheduling approach can achieve near-optimal performance with very low complexity and the proposed learning-based computing offloading algorithm not only converges fast but also achieves a lower total cost compared with other offloading approaches.},
keywords={Task analysis;Servers;Internet of Things;Edge computing;Delays;Resource management;Computer architecture;Computing offloading;edge computing;space-air-ground;IoT;reinforcement learning},
doi={10.1109/JSAC.2019.2906789},
ISSN={1558-0008},
month={May},}
@INPROCEEDINGS{8463154,
author={Mansard, N. and DelPrete, A. and Geisert, M. and Tonneau, S. and Stasse, O.},
booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)}, title={Using a Memory of Motion to Efficiently Warm-Start a Nonlinear Predictive Controller},
year={2018},
volume={},
number={},
pages={2986-2993},
abstract={Predictive control is an efficient model-based methodology to control complex dynamical systems. In general, it boils down to the resolution at each control cycle of a large nonlinear optimization problem. A critical issue is then to provide a good guess to initialize the nonlinear solver so as to speed up convergence. This is particularly important when disturbances or changes in the environment prevent the use of the trajectory computed at the previous control cycle as initial guess. In this paper, we introduce an original and very efficient solution to automatically build this initial guess. We propose to rely on off-line computation to build an approximation of the optimal trajectories, that can be used on-line to initialize the predictive controller. To that end, we combined the use of sampling-based planning, policy learning with generic representations (such as neural networks), and direct optimal control. We first propose an algorithm to simultaneously build a kinodynamic probabilistic roadmap (PRM) and approximate value function and control policy. This algorithm quickly converges toward an approximation of the optimal state-control trajectories (along with an optimal PRM). Then, we propose two methods to store the optimal trajectories and use them to initialize the predictive controller. We experimentally show that directly storing the state-control trajectories leads the predictive controller to quickly converges (2 to 5 iterations) toward the (global) optimal solution. The results are validated in simulation with an unmanned aerial vehicle (UAV) and other dynamical systems.},
keywords={Computational modeling;Approximation algorithms;Optimal control;Planning;Robots;Trajectory optimization},
doi={10.1109/ICRA.2018.8463154},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{8645103,
author={Bayerlein, Harald and Gangula, Rajeev and Gesbert, David},
booktitle={2018 52nd Asilomar Conference on Signals, Systems, and Computers}, title={Learning to Rest: A Q-Learning Approach to Flying Base Station Trajectory Design with Landing Spots},
year={2018},
volume={},
number={},
pages={724-728},
abstract={We consider the problem of trajectory optimization for an autonomous UAV-mounted base station that provides communication services to ground users with the aid of landing spots (LSs). Recently, the concept of LSs was introduced to alleviate the problem of short mission durations arising from the limited on-board battery budget of the UAV, which severely limits network performance. In this work, using Q-learning, a model-free reinforcement learning (RL) technique, we train a neural network (NN) to make movement decisions for the UAV that maximize the data collected from the ground users while minimizing power consumption by exploiting the landing spots. We show that the system intelligently integrates landing spots into the trajectory to extend flying time and is able to learn the topology of the network over several flying epochs without any explicit information about the environment.},
keywords={Artificial neural networks;Training;Batteries;Drones;Power demand;Quality of service;Trajectory},
doi={10.1109/ACSSC.2018.8645103},
ISSN={2576-2303},
month={Oct},}
@INPROCEEDINGS{8489157,
author={Yang, Wei and Wang, Wei and Gao, Yang and Jin, Zhanpeng},
booktitle={2018 International Joint Conference on Neural Networks (IJCNN)}, title={An Embedded Tracking System with Neural Network Accelerator},
year={2018},
volume={},
number={},
pages={1-7},
abstract={With robots and unmanned aerial vehicles (UAVs) being more and more employed in real-life scenarios for monitoring and surveillance, there is a increasing demand for deploying various video processing applications in mobile systems. However, with limited on-board computational resources and power consumption, the application in this domain requires that the tracking platforms equipped should have outstanding computing power to handle the tasks in real-time with high-accuracy, while at the same time, fit the highly constrained environment of small size, light weight, and low power consumption (SWaP) for the purpose of long-term surveillance. In this paper, we proposed a new autonomous object tracking system based on an embedded platform, leveraging the emerging neural network hardware which is capable of massive parallel pattern recognition processing and demands only a low level power consumption. Further, a prototype of the tracking system that combines a low-power neural network chip, CogniMem, and an embedded development board, BeagleBone, is developed. Our experimental results show that the power consumption for the entire system is only about 2. 25W, which signifies a promising future of applying ultra-low-power neuromorphic hardware as a accelerator in recognition tasks.},
keywords={Target tracking;Biological neural networks;Object tracking;Neurons;Power demand;Hardware;object tracking;embedded tracking system;hardware accelerator;low-power implementation},
doi={10.1109/IJCNN.2018.8489157},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{8431659,
author={Ghanavati, Meysam and Chakravarthy, Animesh and Menon, Prathyush P.},
booktitle={2018 Annual American Control Conference (ACC)}, title={PDE-based Swarm Control for Contaminant Tracking Applications},
year={2018},
volume={},
number={},
pages={937-942},
abstract={In this paper, the problem of guiding a swarm of UAVs to monitor the spatio-temporal evolution of a contaminant moving on a plane is addressed. The contaminant and the UAV swarm are both modeled using Partial Differential Equations (PDEs). The spread of the contaminant is modeled using an advection PDE, while the PDE model of the UAV swarm has its foundations in gas dynamics, and these PDEs govern the density, average velocity and speed variance of the swarm. A Lyapunov-based approach, combined with an optimization formulation, is used to design suitable control laws that enable the UAV swarm to track the contaminant as it moves in 2-dimensional space. The robustness of the control laws to interaction effects among the UAVs within the swarm are evaluated. The efficacy of the designed control laws are demonstrated through simulations.},
keywords={Mathematical model;Unmanned aerial vehicles;Adaptation models;Vehicle dynamics;Dispersion;Lyapunov methods;Partial differential equations},
doi={10.23919/ACC.2018.8431659},
ISSN={2378-5861},
month={June},}
@INPROCEEDINGS{8001185,
author={Okafor, Emmanuel and Smit, Rik and Schomaker, Lambert and Wiering, Marco},
booktitle={2017 IEEE International Conference on INnovations in Intelligent SysTems and Applications (INISTA)}, title={Operational data augmentation in classifying single aerial images of animals},
year={2017},
volume={},
number={},
pages={354-360},
abstract={In deep learning, data augmentation is important to increase the amount of training images to obtain higher classification accuracies. Most data-augmentation methods adopt the use of the following techniques: cropping, mirroring, color casting, scaling and rotation for creating additional training images. In this paper, we propose a novel data-augmentation method that transforms an image into a new image containing multiple rotated copies of the original image in the operational classification stage. The proposed method creates a grid of n×n cells, in which each cell contains a different randomly rotated image and introduces a natural background in the newly created image. This algorithm is used for creating new training and testing images, and enhances the amount of information in an image. For the experiments, we created a novel dataset with aerial images of cows and natural scene backgrounds using an unmanned aerial vehicle, resulting in a binary classification problem. To classify the images, we used a convolutional neural network (CNN) architecture and compared two loss functions (Hinge loss and cross-entropy loss). Additionally, we compare the CNN to classical feature-based techniques combined with a k-nearest neighbor classifier or a support vector machine. The results show that the pre-trained CNN with our proposed data-augmentation technique yields significantly higher accuracies than all other approaches.},
keywords={Cows;Unmanned aerial vehicles;Training;Neural networks;Computer architecture;Agriculture;Fasteners;Data Augmentation;Convolutional Neural Networks;Classical Feature Descriptors;Supervised Learning;Aerial Image Classification},
doi={10.1109/INISTA.2017.8001185},
ISSN={},
month={July},}
@INPROCEEDINGS{9331171,
author={Yao, Haonan and Liu, Yang and Zhang, Xiaoyi},
booktitle={2020 7th International Conference on Dependable Systems and Their Applications (DSA)}, title={Developing deep LSTM model for real-time path planning in unknown environments},
year={2020},
volume={},
number={},
pages={219-225},
abstract={This paper proposed a real-time path planning approach based on deep LSTM model, in which the model was constructed by Long Short-Term Memory (LSTM). By collecting various scenarios and paths generated by the existing static path planning algorithm, we form the dataset including the UAV's optimal behaviors and the current observed threats at each time step, which is utilized for training the deep LSTM model. Thus, through learning the training dataset, the model can make optimal decisions in real-time according to the threat around at the current time. Experimental results show that the proposed approach has the ability to fulfill the real-time path planning requirements, including environment unknown, navigation to the target and collision-free. Moreover, our real-time path planning approach can improve the global optimization quality of the path.},
keywords={Training;Prediction algorithms;Real-time systems;Path planning;Security;Optimization;Testing;deep learning;path planning;real-time;LSTM},
doi={10.1109/DSA51864.2020.00039},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8962428,
author={Wang, Enyi and Qiu, Dehui},
booktitle={2019 IEEE 7th International Conference on Computer Science and Network Technology (ICCSNT)}, title={Acceleration and Implementation of Convolutional Neural Network Based on FPGA},
year={2019},
volume={},
number={},
pages={321-325},
abstract={Aiming at the problem of high power consumption and slow operation speed of neural network in embedded system, this paper presents an automatic design method of convolutional neural network (CNN) accelerator based on field programmable gate array (FPGA) to meet the requirements of embedded terminal for operation performance and power consumption. Firstly, in order to reduce the storage resources of the FPGA and the time required for network computing, the weight quantization method is used to convert network parameters from floating-point data to binary data. Secondly, in order to improve the speed and throughput of the whole system, coarse-grained and fine-grained parallel computing optimization methods are used. In this paper, the above acceleration scheme will be applied to the scene of unmanned aerial vehicle (UAV) object detection. The test results shows that the power consumption of the system is 2.38W and the calculated power consumption ratio is 29.3GOPS/W. Compared with the work of related literature in recent years, the proposed scheme can provide higher speed and efficiency. The experimental results show that the accuracy of the IOU is 21% and the speed is 7FPS.},
keywords={Field programmable gate arrays;Convolution;Optimization;Convolutional neural networks;Power demand;Hardware;Convolutional Neural Network;Field Programmable Gate Array;Weight quantization;Parallel computing;Object detection},
doi={10.1109/ICCSNT47585.2019.8962428},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8850811,
author={Hossain, F M Anim and Zhang, Youmin and Yuan, Chi and Su, Chun-Yi},
booktitle={2019 1st International Conference on Industrial Artificial Intelligence (IAI)}, title={Wildfire Flame and Smoke Detection Using Static Image Features and Artificial Neural Network},
year={2019},
volume={},
number={},
pages={1-6},
abstract={If forest fires are not contained quickly, they can spread wide very fast and cause devastating environmental, social and economic damages. The best method to minimize wildfire loss is to be able to detect it in its early stages for rapid containment and suppression. Fire comes with some distinguishable signatures such as flame, smoke and heat that can be used for early detection using computer vision based remote sensing techniques. Each signature has its own merits and demerits that vary under different environmental conditions and circumstances. Therefore, it is not always enough to form a detection algorithm based on a single signature. Keeping that in mind, this paper presents a novel algorithm that is capable of detecting both flame and smoke from a single image using block-based color features, texture features and a single artificial neural network (ANN). Such an algorithm is capable of providing reliable, rapid and continuous detection under any circumstances and can be incorporated into the existing unmanned aerial vehicle (UAV) based fire monitoring system.},
keywords={Fires;Image color analysis;Feature extraction;Artificial neural networks;Forestry;Classification algorithms;Computer vision;Forest fire;flame detection;smoke detection;neural network;computer vision;remote sensing},
doi={10.1109/ICIAI.2019.8850811},
ISSN={},
month={July},}
@INPROCEEDINGS{8123422,
author={Jing, Chan Shi and Pebrianti, Dwi and Qian, Goh Ming and Bayuaji, Luhur},
booktitle={2017 7th IEEE International Conference on System Engineering and Technology (ICSET)}, title={Fault detection in quadrotor MAV},
year={2017},
volume={},
number={},
pages={65-70},
abstract={Unmanned Aerial Vehicle (UAV) is being used in a wide range of human life. Researcher preferred quadrotor as it can be brought into the first generation of simulator map of an aircraft. It can be developed into larger manned flight. In this regard, extensive research in Fault detection (FD) is necessary, so that it can enhance its safety features. FD is designed to respond and to exclude the wrong information and to quickly perceive and shoulder important regulation. The proposed method for the fault detection in this study uses hybrid technique which combines the Kalman filter and Artificial Neural Network (ANN). Two classes of approaches are analyzed: the system identification approach using ANN and the observer-based approach using Kalman filter. A representative Artificial Neural Network (ANN) model has been designed and used to simulate the system behaviors under various failure conditions. The Kalman filter recognizes data from sensors and indicates the fault of the system in sensor reading. Error prediction is based on the fault magnitude and the time occurrence of fault. The information will then be fed to ANN, which consists of a bank of parameter estimation that generates failure state. The result of the residual signal before filtered and after filtered showed that Kalman-ANN is able to identify multi fault and immediately correct the system to the normal state. The accuracy of the detection is 85 percent. The proposed method is able to detect fault in a short time with delay of 9.23E-05 seconds.},
keywords={Artificial neural networks;Fault detection;Kalman filters;Sensors;Fault diagnosis;Complex systems;Mathematical model;Kalman filter;Artificial Neural Network;Fault detection;Fault Isolation;Kalman-ANN;Nonlinear Autoregressive Network with Exogenous Inputs},
doi={10.1109/ICSEngT.2017.8123422},
ISSN={2470-640X},
month={Oct},}
@INPROCEEDINGS{8486395,
author={Rezaee, Mohammad and Zhang, Yun and Mishra, Rakesh and Tong, Fei and Tong, Hengjian},
booktitle={2018 10th IAPR Workshop on Pattern Recognition in Remote Sensing (PRRS)}, title={Using a VGG-16 Network for Individual Tree Species Detection with an Object-Based Approach},
year={2018},
volume={},
number={},
pages={1-7},
abstract={Acquiring information about forest stands such as individual tree species is crucial for monitoring forests. To date, such information is assessed by human interpreters using airborne or an Unmanned Aerial Vehicle (UAV), which is time/cost consuming. The recent advancement in remote sensing image acquisition, such as WorldView-3, has increased the spatial resolution up to 30 cm and spectral resolution up to 16 bands. This advancement has significantly increased the potential for Individual Tree Species Detection (ITSD). In order to use the single source Worldview-3 images, our proposed method first segments the image to delineate trees, and then detects trees using a VGG-16 network. We developed a pipeline for feeding the deep CNN network using the information from all the 8 visible-near infrareds' bands and trained it. The result is compared with two state-of-the-art ensemble classifiers namely Random Forest (RF) and Gradient Boosting (GB). Results demonstrate that the VGG-16 outperforms all the other methods reaching an accuracy of about 92.13%.},
keywords={Vegetation;Radio frequency;Forestry;Image segmentation;Training;Hyperspectral imaging;Deep Learning;Convolutional Neural Network;VGG-16;Individual Tree Species Detection;Random Forest;Gradient Boosting},
doi={10.1109/PRRS.2018.8486395},
ISSN={2377-0198},
month={Aug},}
@INPROCEEDINGS{7260573,
author={Guanyu, Lai and Zhi, Liu and Yun, Zhang},
booktitle={2015 34th Chinese Control Conference (CCC)}, title={Image-based adaptive neural control of underactuated aerial mobile robot without direct position measurement},
year={2015},
volume={},
number={},
pages={5965-5969},
abstract={This paper proposes a new image-based adaptive neural controller for the position tracking control of the underactuated aerial mobile robots without the realtime position measurement. To realize this point, a relationship between the position tracking error and the image projection error is first established. One challenging difficulty in stabilization is the fact that the dynamics of the aerial robot is physically underactuated. To address this challenge, a new designed methodology is proposed in this work. In addition, the proposed adaptive controller does not require the explicit inertia information and has a simplified structure because of the inclusion of a new inertia estimator and an optimized structure neural network. Based on the Lyapunov synthesis, the asymptotic convergence of the position tracking error as well as the image projection error to an adjustable region of zero is proved. Lastly, the performance results are provided to verify the effectiveness of the proposed adaptive control scenario.},
keywords={Mobile robots;Visual servoing;Visualization;Position measurement;Cameras;Adaptive control;neural networks;underactuated mobile robots;visual servoing;unmanned aerial vehicle;nonlinear systems},
doi={10.1109/ChiCC.2015.7260573},
ISSN={1934-1768},
month={July},}
@INPROCEEDINGS{7967422,
author={Wang, Xuerao and Lin, Xiaobo and Yu, Yao and Wang, Qing and Sun, Changyin},
booktitle={2017 32nd Youth Academic Annual Conference of Chinese Association of Automation (YAC)}, title={Backstepping control for quadrotor with BP neural network based thrust model},
year={2017},
volume={},
number={},
pages={292-297},
abstract={This paper presents a nonlinear backstepping control scheme for quadrotor with BP neural network based thrust model. The thrust in quadrotor system is difficult to calculate or measure, so the paper build a BP based thrust model to approximate the mapping between thrust with factors of altitude, voltage and the high level time of PWM. Through the model, the control input for each rotor can be calculate accurately to gain the desired thrust. The controller is designed by backstepping method and verified by Lyapunov stability theorem. Hovering experimental results are presented to show the effectiveness of the proposed controller.},
keywords={Backstepping;Pulse width modulation;Rotors;Lyapunov methods;Biological neural networks;Stability analysis;Mathematical model;Thrust model;BP nerual network;backstepping;quadrotor;hovering},
doi={10.1109/YAC.2017.7967422},
ISSN={},
month={May},}
@INPROCEEDINGS{9255509,
author={Shmelova, Tetiana and Shmelov, Yurii and Vladov, Serhii},
booktitle={2020 IEEE 6th International Conference on Methods and Systems of Navigation and Motion Control (MSNMC)}, title={Concept of Building Intelligent Control Systems for Aircraft, Unmanned Aerial Vehicles and Aircraft Engines},
year={2020},
volume={},
number={},
pages={14-19},
abstract={The work is devoted to the development of the concept of building intelligent control systems for complex dynamic objects, based on the vertical and horizontal decomposition of management processes within the architecture of open information systems. The proposed concept is applicable in the development of control systems for aircraft, unmanned aerial vehicles, and aircraft engines.},
keywords={Aircraft propulsion;Unmanned aerial vehicles;Intelligent control;Aircraft;Aerospace control;Control systems;Biological neural networks;aircraft;unmanned aerial vehicle;aircraft engine;neural network controller;automatic control system;perceptron},
doi={10.1109/MSNMC50359.2020.9255509},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9560756,
author={Fu, Changhong and Cao, Ziang and Li, Yiming and Ye, Junjie and Feng, Chen},
booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, title={Siamese Anchor Proposal Network for High-Speed Aerial Tracking},
year={2021},
volume={},
number={},
pages={510-516},
abstract={In the domain of visual tracking, most deep learning-based trackers highlight the accuracy but casting aside efficiency. Therefore, their real-world deployment on mobile platforms like the unmanned aerial vehicle (UAV) is impeded. In this work, a novel two-stage Siamese network-based method is proposed for aerial tracking, i.e., stage-1 for high-quality anchor proposal generation, stage-2 for refining the anchor proposal. Different from anchor-based methods with numerous pre-defined fixed-sized anchors, our no-prior method can 1) increase the robustness and generalization to different objects with various sizes, especially to small, occluded, and fast-moving objects, under complex scenarios in light of the adaptive anchor generation, 2) make calculation feasible due to the substantial decrease of anchor numbers. In addition, compared to anchor-free methods, our framework has better performance owing to refinement at stage-2. Comprehensive experiments on three benchmarks have proven the superior performance of our approach, with a speed of ∼200 frames/s.},
keywords={Visualization;Casting;Automation;Conferences;Semantics;Refining;Benchmark testing},
doi={10.1109/ICRA48506.2021.9560756},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{9607735,
author={Zheng, Xiaochen and Kellenberger, Benjamin and Gong, Rui and Hajnsek, Irena and Tuia, Devis},
booktitle={2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}, title={Self-Supervised Pretraining and Controlled Augmentation Improve Rare Wildlife Recognition in UAV Images},
year={2021},
volume={},
number={},
pages={732-741},
abstract={Automated animal censuses with aerial imagery are a vital ingredient towards wildlife conservation. Recent models are generally based on deep learning and thus require vast amounts of training data. Due to their scarcity and minuscule size, annotating animals in aerial imagery is a highly tedious process. In this project, we present a methodology to reduce the amount of required training data by resorting to self-supervised pretraining. In detail, we examine a combination of recent contrastive learning methodologies like Momentum Contrast (MoCo) and Cross-Level Instance-Group Discrimination (CLD) to condition our model on the aerial images without the requirement for labels. We show that a combination of MoCo, CLD, and geometric augmentations outperforms conventional models pretrained on ImageNet by a large margin. Crucially, our method still yields favorable results even if we reduce the number of training animals to just 10%, at which point our best model scores double the recall of the baseline at similar precision. This effectively allows reducing the number of required annotations to a fraction while still being able to train highaccuracy models in such highly challenging settings.},
keywords={Training;Deep learning;Image recognition;Annotations;Conferences;Wildlife;Supervised learning},
doi={10.1109/ICCVW54120.2021.00087},
ISSN={2473-9944},
month={Oct},}
@INPROCEEDINGS{8486236,
author={Beleznai, Csaba and Steininger, Daniel and Croonen, Gerardus and Broneder, Elisabeth},
booktitle={2018 10th IAPR Workshop on Pattern Recognition in Remote Sensing (PRRS)}, title={Multi-Modal Human Detection from Aerial Views by Fast Shape-Aware Clustering and Classification},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Recognizing humans from aerial views represents an increasingly relevant endeavor; a trend mainly driven by the widespread use of unmanned aerial vehicles (UAVs). An accurate and real-time visual human recognition task, however, represents a scientific challenge because typical UAV imaging and computational capabilities and conditions introduce complexities and constraints. Motion blur, the non-specific top-view appearance of humans, low-image resolution and limited onboard computational resources are among the most important limiting factors to be considered. In this paper we propose a run-time-efficient multi-modal detection framework performing clustering and recognition on thermal infrared, passive stereo depth and intensity channels in order to cope with the above complexities and to achieve accurate human detection results. Thermal infrared and depth data are used to generate proposals in combination with an explicit, tree-structured shape representation driven clustering scheme. Generated proposals are used as an input for a discriminatively trained deep classification step to recognize humans. The proposed clustering and classification scheme is validated in qualitative and quantitative terms on four large aerial datasets representing complex (small objects, clutter, occlusions) situations.},
keywords={Shape;Proposals;Image resolution;Unmanned aerial vehicles;Real-time systems;Image recognition;Convolutional neural networks;human detection;multi-modal image analysis;clustering;image classification;UAV surveillance},
doi={10.1109/PRRS.2018.8486236},
ISSN={2377-0198},
month={Aug},}
@ARTICLE{9113305,
author={Pham, Quoc-Viet and Fang, Fang and Ha, Vu Nguyen and Piran, Md. Jalil and Le, Mai and Le, Long Bao and Hwang, Won-Joo and Ding, Zhiguo},
journal={IEEE Access}, title={A Survey of Multi-Access Edge Computing in 5G and Beyond: Fundamentals, Technology Integration, and State-of-the-Art},
year={2020},
volume={8},
number={},
pages={116974-117017},
abstract={Driven by the emergence of new compute-intensive applications and the vision of the Internet of Things (IoT), it is foreseen that the emerging 5G network will face an unprecedented increase in traffic volume and computation demands. However, end users mostly have limited storage capacities and finite processing capabilities, thus how to run compute-intensive applications on resource-constrained users has recently become a natural concern. Mobile edge computing (MEC), a key technology in the emerging fifth generation (5G) network, can optimize mobile resources by hosting compute-intensive applications, process large data before sending to the cloud, provide the cloud-computing capabilities within the radio access network (RAN) in close proximity to mobile users, and offer context-aware services with the help of RAN information. Therefore, MEC enables a wide variety of applications, where the real-time response is strictly required, e.g., driverless vehicles, augmented reality, robotics, and immerse media. Indeed, the paradigm shift from 4G to 5G could become a reality with the advent of new technological concepts. The successful realization of MEC in the 5G network is still in its infancy and demands for constant efforts from both academic and industry communities. In this survey, we first provide a holistic overview of MEC technology and its potential use cases and applications. Then, we outline up-to-date researches on the integration of MEC with the new technologies that will be deployed in 5G and beyond. We also summarize testbeds and experimental evaluations, and open source activities, for edge computing. We further summarize lessons learned from state-of-the-art research works as well as discuss challenges and potential future directions for MEC research.},
keywords={Cloud computing;5G mobile communication;Edge computing;Internet of Things;Radio access networks;NOMA;Wireless communication;5G and beyond network;heterogeneous networks;Internet of Things;machine learning;edge computing;non-orthogonal multiple access;testbeds;unmanned aerial vehicle;wireless power transfer and energy harvesting},
doi={10.1109/ACCESS.2020.3001277},
ISSN={2169-3536},
month={},}
@ARTICLE{8721047,
author={Cajo, Ricardo and Mac, Thi Thoa and Plaza, Douglas and Copot, Cosmin and De Keyser, Robain and Ionescu, Clara},
journal={IEEE Access}, title={A Survey on Fractional Order Control Techniques for Unmanned Aerial and Ground Vehicles},
year={2019},
volume={7},
number={},
pages={66864-66878},
abstract={In recent years, numerous applications of science and engineering for modeling and control of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) systems based on fractional calculus have been realized. The extra fractional order derivative terms allow to optimizing the performance of the systems. The review presented in this paper focuses on the control problems of the UAVs and UGVs that have been addressed by the fractional order techniques over the last decade.},
keywords={Land vehicles;Trajectory tracking;Biological neural networks;Unmanned aerial vehicles;Fractional calculus;Frequency control;Indexes;Fractional calculus;fractional order control techniques;unmanned aerial vehicles (UAVs);unmanned ground vehicles (UGVs)},
doi={10.1109/ACCESS.2019.2918578},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9391260,
author={Semkin, Vasilii and Yin, Mingsheng and Hu, Yaqi and Mezzavilla, Marco and Rangan, Sundeep},
booktitle={2020 International Symposium on Antennas and Propagation (ISAP)}, title={Drone Detection and Classification Based on Radar Cross Section Signatures},
year={2021},
volume={},
number={},
pages={223-224},
abstract={In this work, we show how drone detection and classification can be enabled by leveraging a database of radar cross section (RCS) signatures. First, we present a set of measurement results of the RCS of a carbon fiber drone model at 28 GHz. The measurements were performed in an anechoic chamber and provide essential information about the RCS signature of the specific drone. Then, we assess the RCS-based detection probability and the range error by running simulations in urban environments. The drones were positioned at different distances, from 30m to 90m, and the RCS signatures used for the detection and classification were obtained experimentally.},
keywords={Antenna measurements;Radar cross-sections;Databases;Urban areas;Machine learning;Detection algorithms;Drones;Propagation;radar;detection;UAV;RCS},
doi={10.23919/ISAP47053.2021.9391260},
ISSN={},
month={Jan},}
@ARTICLE{8447264,
author={James, Jasmin and Ford, Jason J. and Molloy, Timothy L.},
journal={IEEE Robotics and Automation Letters}, title={Learning to Detect Aircraft for Long-Range Vision-Based Sense-and-Avoid Systems},
year={2018},
volume={3},
number={4},
pages={4383-4390},
abstract={The commercial use of unmanned aerial vehicles (UAVs) would be enhanced by an ability to sense and avoid potential mid-air collision threats. In this letter, we propose a new approach to aircraft detection for long-range vision-based sense and avoid. We first train a deep convolutional neural network to learn aircraft visual features using flight data of mid-air head-on near-collision course encounters between two fixed-wing aircraft. We then propose an approach that fuses these learnt aircraft features with hand-crafted features that are used by the current state of the art. Finally, we evaluate the performance of our proposed approach on real flight data captured from a UAV, where it achieves a mean detection range of 2527 m and a mean detection range improvement of 299 m (or 13.4%) compared to the current state of the art with no additional false alarms.},
keywords={Aircraft;Computer vision;Machine learning;Feature extraction;Collision avoidance;Object detection;Unmanned aerial vehicles;Aerial systems: perception and autonomy, computer vision for automation;deep learning in robotics and automation},
doi={10.1109/LRA.2018.2867237},
ISSN={2377-3766},
month={Oct},}
@ARTICLE{9435362,
author={Zeng, Zhiguo and Chen, Xihong and Song, Zhihua},
journal={IEEE Access}, title={MGFN: A Multi-Granularity Fusion Convolutional Neural Network for Remote Sensing Scene Classification},
year={2021},
volume={9},
number={},
pages={76038-76046},
abstract={Convolutional neural networks (CNNs) have been successfully used in remote sensing scene classification and identification due to their ability to capture deep spatial feature representations. However, the performance of deep models inevitably encounters a bottleneck when multimodality-dominated scene classification rather than single-modality-dominated scene classification is performed, due to the high similarity among different categories. In this study, we propose a novel multi-granularity fusion convolutional neural network (MGFN) to automatically capture the latent ontological features of remote sensing images. We firstly design a multigranularity module that can progressively crop input images to learn multigrained features, which can describe images to different degrees. Based on a comparison of different granularities, we then design a maxout-based module to learn the corresponding Gaussian covariance matrices of different granularities, which can extract second-order features to express the latent ontological essence of inputs and select the most distinguished inputs. We thirdly provide an adaptive fusion module to fuse all features via normalization to combine features of different degrees using the adaptive fused module. Finally, an SVM classifier is used to classify the fused matrix of every input image. Extensive experimentation and evaluations, particularly for multimodality-dominated scenes, demonstrate that the proposed network can achieve promising results for public remote sensing datasets.},
keywords={Feature extraction;Remote sensing;Covariance matrices;Convolutional neural networks;Training;Rail transportation;Sensors;Convolutional neural network;multi-granularity fusion;Gaussian covariance matrix;remote sensing scene classification},
doi={10.1109/ACCESS.2021.3081922},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7354309,
author={Zermas, Dimitris and Teng, Da and Stanitsas, Panagiotis and Bazakos, Michael and Kaiser, Daniel and Morellas, Vassilios and Mulla, David and Papanikolopoulos, Nikolaos},
booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Automation solutions for the evaluation of plant health in corn fields},
year={2015},
volume={},
number={},
pages={6521-6527},
abstract={The continuously growing need for increasing the production of food and reducing the degradation of water supplies, has led to the development of several precision agriculture systems over the past decade so as to meet the needs of modern societies. The present study describes a methodology for the detection and characterization of Nitrogen (N) deficiencies in corn fields. Current methods of field surveillance are either completed manually or with the assistance of satellite imaging, which offer infrequent and costly information to the farmers about the state of their fields. The proposed methodology promotes the use of small-scale Unmanned Aerial Vehicles (UAVs) and Computer Vision algorithms that operate with information in the visual (RGB) spectrum. Through this implementation, a lower cost solution for identifying N deficiencies is promoted. We provide extensive results on the use of commercial RGB sensors for delivering the essential information to farmers regarding the condition of their field, targeting the reduction of N fertilizers and the increase of the crop performance. Data is first collected by a UAV that hovers over a stressed area and collects high resolution RGB images at a low altitude. A recommendation algorithm identifies potential segments of the images that are candidates exhibiting N deficiency. Based on the feedback from experts in the area a training set is constructed utilizing the initial suggestions of the recommendation algorithm. Supervised learning methods are then used to characterize crop leaves that exhibit signs of N deficiency. The performance of 84.2% strongly supports the potential of this scheme to identify N-deficient leaves even in the case of images where the unhealthy leaves are heavily occluded by other healthy or stressed leaves.},
keywords={Soil;Image color analysis;Sensors;Fertilizers;Image segmentation;Imaging;Precision Agriculture;UAV;Machine Learning},
doi={10.1109/IROS.2015.7354309},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8215300,
author={da Silva, B. R. F. and Nogueira, M. B. and Alsina, P. J. and de Albuquerque, G. L. A. and Dantas, J. B. D. and de Medeiros, A. A. D. and Santiago, G. Santos},
booktitle={2017 Latin American Robotics Symposium (LARS) and 2017 Brazilian Symposium on Robotics (SBR)}, title={Study on detection of boats using satellite imagery for use on unmanned aerial vehicles},
year={2017},
volume={},
number={},
pages={1-5},
abstract={This work presents the development of a system that performs the detection of boats from aerial images acquired by satellites. This will serve as a knowledge base for the implementation of a system to be implemented in a fleet of unmanned aerial vehicle. The main purpose of the system is to detect ships that are in the risk zone of rocket trajectory launched from Barreira do Inferno Launch Center - CLBI. In previous work the authors proposed an algorithm to perform boat detection, however the results showed a high incidence of false positives. In order to improve those results, we propose the use of the Histogram of Oriented Gradients descriptor in candidate images followed by machine learning teachniques such as Suport Vector Machine and K Nearest Neighbours to classify them. To validate the system some experimental results are shown using satellite images, since the aerial vehicle is under constuctions and there is no image database yet.},
keywords={Boats;Histograms;Support vector machines;Rockets;Airplanes;Unmanned aerial vehicles;Databases},
doi={10.1109/SBR-LARS-R.2017.8215300},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9616354,
author={Souidene Mseddi, Wided and Sedrine, Mohamed Ali and Attia, Rabah},
booktitle={2021 29th European Signal Processing Conference (EUSIPCO)}, title={YOLOv5 Based Visual Localization For Autonomous Vehicles},
year={2021},
volume={},
number={},
pages={746-750},
abstract={In this paper, we use the advances brought by neural networks for the implementation of a vision based localization framework for autonomous vehicles namely UAVs. We base our work on monocular visual odometry. It is used for incremental localization of autonomous vehicles. This method suffers from drift. Loop closure detection is a way to improve its accuracy. Thus, we introduce a Siamese network able to perform binary classification in order to detect the visited places and the loop closures. This gives us an accurate, light and fast vision based localization framework.},
keywords={Location awareness;Adaptation models;Visualization;Protocols;Neural networks;Signal processing;Real-time systems;Autonomous vehicle;Visual odometry;Loop closure;Neural networks;YOLOv5;Deep Learning},
doi={10.23919/EUSIPCO54536.2021.9616354},
ISSN={2076-1465},
month={Aug},}
@INPROCEEDINGS{9584727,
author={Niccolai, Alessandro and Grimaccia, Francesco and Leva, Sonia and Eleftheriadis, Panagiotis},
booktitle={2021 IEEE International Conference on Environment and Electrical Engineering and 2021 IEEE Industrial and Commercial Power Systems Europe (EEEIC / I CPS Europe)}, title={Photovoltaic Plant Inspection by means of UAV: current practices and future perspectives},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Recent trends show the importance of photovoltaic (PV) system inspection: in fact, it allows the increase in their performance and profitability. Moreover, it represents an important step for the safety and asset management of PV plants. Among all the possible inspection techniques, the use of Unmanned Aerial Vehicles (UAVs) has proven to be very effective in obtaining excellent results with a competitive cost: in particular, this type of inspection allows to drastically reduce inspection times with good quality of the results obtained. Finally, this inspection technique has been well combined with the development of image processing techniques capable of analyzing and processing the data acquired in the field quickly and reliably. The aim of this paper is to review the current practice in UAV-based PV plant inspection and to analyse future perspectives.},
keywords={Photovoltaic systems;Productivity;Profitability;Manuals;Inspection;Market research;Unmanned aerial vehicles;Unmanned Aerial Vehicles;Photovoltaic Inspection;Deep Learning;Image Processing},
doi={10.1109/EEEIC/ICPSEurope51590.2021.9584727},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9231433,
author={Perdana, Muhammad Ilham and Risnumawan, Anhar and Sulistijono, Indra Adji},
booktitle={2020 International Symposium on Community-centric Systems (CcS)}, title={Automatic Aerial Victim Detection on Low-Cost Thermal Camera Using Convolutional Neural Network},
year={2020},
volume={},
number={},
pages={1-5},
abstract={The first thing to do by the search-and-rescue (SAR) team after the disaster occurred is to find the location of the victim quickly. Thus the loss of lives can be reduced. After the disaster, the environment usually very messy, containing debris from building, soil, and gravel, which makes it harder to find the victims. By detecting the temperature using a thermal camera, it can easily be distinguished between the victims and the other background. Previous work, the technology to detect a person using a thermal camera from aerial has been developed, but it is only working with the most nearly uniform background. In this paper, we developed an automatic aerial (drones) victim detection using a thermal camera. A low-cost thermal camera has been used so that anyone can quickly implement in the real situation. By combining CNN as its algorithm that widely uses for its excellent performance on object detection, it can easily detect victims from the low-cost thermal camera and distinguished from complex background. Experiments show very well that the proposed method able to detect victims from aerial thermal view with accuracy AP = 82.49%. We believe it could bring benefits for future work with the related field and able to help search-and-rescue team to find and evacuate the victims quickly.},
keywords={Cameras;Deep learning;Training;Detectors;Servers;Ocean temperature;Object detection;Victims detection;low-cost thermal camera;UAV image;deep learning method;real-time detector},
doi={10.1109/CcS49175.2020.9231433},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8215283,
author={Carrijo, Gabriel L. A. and Oliveira, Danilo E. and de Assis, Gleice A. and Carneiro, Murillo G. and Guizilini, Vitor C. and Souza, Jefferson R.},
booktitle={2017 Latin American Robotics Symposium (LARS) and 2017 Brazilian Symposium on Robotics (SBR)}, title={Automatic detection of fruits in coffee crops from aerial images},
year={2017},
volume={},
number={},
pages={1-6},
abstract={A big challenge in the precision agriculture is the detection of fruits in coffee crops on agricultural environments. This paper presents a comparison of four features set to detect the red fruits (mature) in Coffee plants. An Unmanned Aerial Vehicle (UAV) is used to obtain high-resolution RGB images of a coffee hall. The proposed methodology enables the extraction of visual features from image regions and uses supervised Machine Learning (ML) techniques to classify areas as coffee fruits and non-fruits (e.g. branches and leaves). Several ML methods were compared using the test data achieved from a Coffee plantation. Experimental results show that the ANN model is more reliable than other ML methods for accurately identifying coffee fruits.},
keywords={Feature extraction;Agriculture;Training;Image color analysis;Visualization;Robots;Testing},
doi={10.1109/SBR-LARS-R.2017.8215283},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9010236,
author={Kakamoukas, G. and Sariciannidis, P. and Livanos, G. and Zervakis, M. and Ramnalis, D. and Polychronos, V. and Karamitsou, T. and Folinas, A. and Tsitsiokas, N.},
booktitle={2019 IEEE International Conference on Imaging Systems and Techniques (IST)}, title={A Multi-collective, IoT-enabled, Adaptive Smart Farming Architecture},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Smart Farming (SF) or Precision Agriculture (PA) use precise and efficient approaches for monitoring and processing information from farms, crops, forestry, and livestock aiming at more productive and sustainable rural development. Internet of Things (IoT) is the ecosystem that can provide effective real-time information gathering and processing mechanisms, while supporting cloud access and decision-making mechanisms. Despite the notable progress in the SF field, the ability of these systems to adapt into different types of crops in order to constitute a ready-to-use tool for agricultural stakeholders remains a challenge. In this paper we present a flexible and easy-to-adopt architecture for applying modern IoT-enabled technologies in the context of SF. The proposed architecture encloses Wireless Sensor Networks (WSNs), meteorological stations and Unmanned Aerial Vehicles (UAVs) along with an information processing system that leverages machine learning and computing technologies. The innovation of the proposed architecture lies in the creation of an integrated monitoring and decision support system aiming at production increasing, efficient allocation of resources and protection of plant capital from exogenous (weather and pests) and endogenous (diseases) factors.},
keywords={Agriculture;Wireless sensor networks;Computer architecture;Peer-to-peer computing;Cameras;Monitoring;Machine learning;smart farming;precision agriculture;unmanned aerial vehicles;wireless sensor networks;multi-spectral cameras;computer vision;machine learning},
doi={10.1109/IST48021.2019.9010236},
ISSN={1558-2809},
month={Dec},}
@INPROCEEDINGS{8995948,
author={Wang, Changqing and Liang, Xinkai and Zhang, Shan and Shen, Chao},
booktitle={2019 IEEE International Conference on Unmanned Systems (ICUS)}, title={Motion Parallax Estimation for Ultra Low Altitude Obstacle Avoidance},
year={2019},
volume={},
number={},
pages={463-468},
abstract={By making full use of the curvature of the earth and ground clutter, the ultra-low altitude flight technique can significantly increase the difficulty of detecting and intercepting unmanned aerial vehicles (UAVs), and improve their penetration probabilities. However, unpredicted static/dynamic obstacles seriously threaten the flight safety of the ultra-low altitude UAVs. Therefore, fine autonomous spatial perception capability is essential for ultra-low altitude UAVs with limited loads and computing resources to avoid obstacles. To solve the difficult problem of spatial perception for ultra-low altitude obstacle avoidance, a motion parallax estimation algorithm is proposed by combing the deep learning and the epipolar geometry in this paper. By utilizing the deep neural network, the end-to-end mapping relationship from sequence images to depth values of pixels is constructed for spatial perception. At the same time, to overcome the interference caused by the image consistency hypothesis, the loss function is constructed based on the 3D geometric information of the scene rather than the re-projection error between images. Finally, the proposed algorithm is evaluated on the KITTI dataset and infrared image dataset to verify its effectiveness and generalization.},
keywords={Motion Parallax;Deep Learning;Epipolar Geometry component},
doi={10.1109/ICUS48101.2019.8995948},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9647121,
author={Javed, Muhammad Gohar and Raza, Minahil and Ghaffar, Muhammad Mohsin and Weis, Christian and Wehn, Norbert and Shahzad, Muhammad and Shafait, Faisal},
booktitle={2021 Digital Image Computing: Techniques and Applications (DICTA)}, title={QuantYOLO: A High-Throughput and Power-Efficient Object Detection Network for Resource and Power Constrained UAVs},
year={2021},
volume={},
number={},
pages={01-08},
abstract={Convolutional Neural Networks (CNNs) are producing state-of-the-art results in the object detection field. However, deep topologies of CNN are computationally intensive and typically require excessive resources (i.e. high-end GPUs), which hinder their deployment on resource and power constrained UAVs. In this work, we present a high-throughput and power efficient quantized object detection network, QuantYOLO, which is based on the Tiny-YOLOv2 topology. We conduct a detailed exploration of precision and filter pruning vs. accuracy, throughput and power consumption trade-off for the object detection task. As a result of these explorations, we select a network with binarized weights and 4-bit activations (except the output layer), which is 21.8× smaller than the Tiny-YOLOv2 achieving a mean Average Precision (mAP) of 51.5% on the PASCAL-VOC dataset. Finally, we present an FPGA based accelerator, which achieves 1.6× higher throughput (FPS) and is 3.1× more power efficient as compared to prior FPGA architectures.},
keywords={Quantization (signal);Power demand;Network topology;Object detection;Computer architecture;Throughput;Topology;Quantized Convolutional Neural Networks;Object Detection;Pruning;Depthwise Separable Convolutions;Real-Time and Power-Efficient Architecture},
doi={10.1109/DICTA52665.2021.9647121},
ISSN={},
month={Nov},}
@ARTICLE{9435072,
author={Li, Xianghui and Li, Xinde and Li, Zhijun and Xiong, Xinran and Khyam, Mohammad Omar and Sun, Changyin},
journal={IEEE Transactions on Artificial Intelligence}, title={Robust Vehicle Detection in High-Resolution Aerial Images With Imbalanced Data},
year={2021},
volume={2},
number={3},
pages={238-250},
abstract={Vehicle detection in images from unmanned aerial vehicles (UAVs) plays an important role in traffic surveillance and urban planning due to the popularity of UAVs. However, the class imbalance problem is an important factor that restricts the performance of vehicle detectors. There are two types of class imbalance in UAV images, i.e., foreground-background imbalance and foreground–foreground imbalance. For anchor-based single stage detector, as many ground truths cannot be assigned to corresponding anchors because of low intersection over union, it makes the foreground-background imbalance problem more severe. Therefore, we propose a novel bag-based single-stage detector, which treats each position on the feature map as a bag. A simple and adaptive definition of bags is proposed along with the positive sample definition method, which is utilized to ensure more ground truths can be assigned to proper bags. In addition, we utilize online hard example mining method to control the proportion of positive and negative samples during the training process. To address the foreground–foreground imbalance, we propose a novel data augmentation algorithm, which allows us to create appropriate visual context for under-represented class. Extensive experiments demonstrate the superiority of the proposed algorithm, compared with other state-of-the-art solutions.
Impact Statement—Recently, unmanned aerial vehicles (UAVs) are widely used in intelligent transportation due to their low price and high flexibility, which makes vehicle detection in UAV images important for automatically gathering of traffic information. However, the class imbalance problem, which is common in object detection where some classes have far fewer frequencies in the dataset, has an adverse effect on the performance of vehicle detectors. The data augmentation method and deep learning based vehicle detector proposed in this article are able to reduce the negative impact and improve detection performance by at least 1.27% in mean average precision index. In addition, compared with algorithms with similar detection performance, our method is at least 15 ms faster. The proposed method can benefit users in a wide variety of applications including UAV transportation, traffic surveillance, and urban planning.

},
keywords={Detectors;Vehicle detection;Training;Drones;Artificial intelligence;Surveillance;Semantics;Bag-based single-stage detector (BSSD);class imbalance problem;data augmentation;vehicle detection},
doi={10.1109/TAI.2021.3081057},
ISSN={2691-4581},
month={June},}
@INPROCEEDINGS{8511379,
author={Thompson, Brad},
booktitle={2018 IEEE Conference on Control Technology and Applications (CCTA)}, title={System State Variable Discovery Counter Example},
year={2018},
volume={},
number={},
pages={1532-1539},
abstract={The stability of an existing non-linear system model of a Dubins vehicle is investigated. The discovery of the system state variables and their dynamics from simulation data is attempted, using machine learning (ML) techniques. The results show that there is at least one case in which system state-space discovery through a ML approach is unsuccessful. Technology which relies upon state abstraction from inferential learning techniques may be vulnerable to failure if the cases are not well understood.},
keywords={Mathematical model;Data models;Angular velocity;Computational modeling;Adaptation models;Vehicle dynamics;System dynamics;nonlinear systems;sparse identification;state abstraction},
doi={10.1109/CCTA.2018.8511379},
ISSN={},
month={Aug},}
@INPROCEEDINGS{7870903,
author={Mattingly, Marshall and Barnas, Andrew and Ellis-Felege, Susan and Newman, Robert and Iles, David and Desell, Travis},
booktitle={2016 IEEE 12th International Conference on e-Science (e-Science)}, title={Developing a citizen science web portal for manual and automated ecological image detection},
year={2016},
volume={},
number={},
pages={223-232},
abstract={Image recognition is challenging in the field of wildlife ecology as samples of a specific species can be rare, making manual detection cumbersome. With over 2,060,000 images taken from motion-sensor trail cameras and unmanned aerial vehicle flights, a touch enabled web interface has been developed to allow citizen scientists and ecologists to categorize positive samples. To minimize categorization errors, the same images are shown to multiple separate users. The observations of each user are then compared using two novel validation strategies: percentage of overlapping area and maximum corner distance. Two novel methods for the extraction of final images from validated results are presented and compared as well: average corner points and area intersection. These methods were evaluated using a set of 142 images with a total of 811 observations of objects generated by citizen scientists that were manually inspected for ground truth. Results show that for this research a maximum corner distance of 10 pixels and the use of area intersection provided the best extracted imagery for future use as training and testing data by computer vision methods.},
keywords={Cameras;Snow;Wildlife;Machine learning algorithms;Monitoring;Libraries;Training},
doi={10.1109/eScience.2016.7870903},
ISSN={},
month={Oct},}
@ARTICLE{8720236,
author={Wei, Ye and Jiao, Licheng and Liu, Fang and Yang, Shuyuan and Wu, Qian and Sanga, Gustaph},
journal={IEEE Access}, title={Fast DDL Classification for SAR Images With ${l}_{1,\infty}$ Constraint},
year={2019},
volume={7},
number={},
pages={68991-69006},
abstract={Synthetic aperture radar (SAR) image classification aims at labeling pixels with different categories and this is both, a fundamental step for automatic target recognition (ATR) and a prerequisite for further interpretation. In the past decades, various methods have been proposed for the classification of SAR targets and among them are discriminative dictionary learning (DDL) methods. These DDL methods have recently gained attention from researchers' community due to the fact that they are very powerful on both, representation and discrimination during the classification process of SAR images. However, most of the existing DDL methods adopt l0-norm or l1-norm to ensure the sparsity, but in general, these DDL methods suffer from a high computational burden. Furthermore, it is important to minimize the execution time in the phase of online testing for the scenario of onboard real-time or near real-time SAR automatic target recognition such as modern unmanned aerial vehicle SAR platforms. That said, on reducing execution time, we are confronted with the problem of enhancing recognition efficiency while maintaining its accuracy. In order to solve this problem, our paper proposes a fast DDL method (named as FaDDL) based on a nonlinear analysis co-sparse model by adopting an l1,∞-norm ball as a constraint to replace l0-norm or l1-norm on the coding coefficient matrix. The experimental results show that our proposed method significantly reduces execution time, without losing the classification accuracy.},
keywords={Radar polarimetry;Machine learning;Encoding;Feature extraction;Training;Synthetic aperture radar;Target recognition;Discriminative dictionary learning;synthetic aperture radar;automatic target recognition;l₁∞-norm;nonlinear analysis co-sparse model},
doi={10.1109/ACCESS.2019.2918352},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9523704,
author={Zerrouk, Ilham and Moumen, Younes and Khiati, Wassim and Habchi, Ali El and Berrich, Jamal and Bouchentouf, Toumi},
booktitle={2020 International Symposium on Advanced Electrical and Communication Technologies (ISAECT)}, title={CNN Adaptations for Boat Detection in Aerial Images Tested on Yolo v2},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this article, we focus on boat real-time detection in aerial images taken by UAVs Unmanned Aerial Vehicles. Several methods dealing with this problem are based on convolutional networks. Generally, they start from existing networks that have demonstrated their effectiveness with datasets like COCO Common Object in Context [1] and adapt them to improve their performance on aerial images. The adaptations made should not cause a higher execution time than the initial network, especially if the image processing and detection must be done in real-time. They must also participate in the increase in Recall by detecting even small objects on aerial images which is the case of most objects present in photos taken at high altitude. The purpose of this article is to test the effectiveness of certain adaptations with our boat dataset. We will also propose new adaptations. The tests will be performed using the Yolo v2 neural network [2].},
keywords={Image processing;Neural networks;Boats;Real-time systems;Unmanned aerial vehicles;Communications technology;Convolutional neural networks;ship detection;target detection;aerial imagery;UAV;ConvNet},
doi={10.1109/ISAECT50560.2020.9523704},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9594321,
author={Fraser, Benjamin and Al-Rubaye, Saba and Aslam, Sohaib and Tsourdos, Antonios},
booktitle={2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC)}, title={Enhancing the Security of Unmanned Aerial Systems using Digital-Twin Technology and Intrusion Detection},
year={2021},
volume={},
number={},
pages={1-10},
abstract={In this paper the general susceptibilities of Unmanned Aerial Vehicles (UAVs) against modern-cyber threats are explored and potential solutions proposed. This is achieved by applying digital-twin architectures and data-driven methods to UAVs to facilitate identification of real-time intrusions and anomalies. These concepts are validated by performing novelty detection on open access UAV flight data with GPS spoofing attacks, which represents a typical system use-case. Multiple machine learning models are trained to demonstrate the feasibility of detecting modern cyber-intrusions and anomalies using the digital-twin architecture. This includes both classical and deep learning techniques to help identify the most suitable model types for the proposed design. The overall results are positive and help highlight the potential of digital-twin architectures for the UAV contexts.},
keywords={Adaptation models;Analytical models;Prototypes;Unmanned aerial vehicles;Data models;Real-time systems;Security;Digital-twin;Machine Learning;Novelty Detection;UAV;UAS;Intrusion Detection;Cyber-security},
doi={10.1109/DASC52595.2021.9594321},
ISSN={2155-7209},
month={Oct},}
@ARTICLE{9015998,
author={Gao, Qian and Shen, Xukun and Niu, Wensheng},
journal={IEEE Access}, title={Large-Scale Synthetic Urban Dataset for Aerial Scene Understanding},
year={2020},
volume={8},
number={},
pages={42131-42140},
abstract={The geometric extraction and semantic understanding in bird's eye view plays an important role in cyber-physical-social systems (CPSS), because it can help human or intelligent agents (IAs) to perceive larger range of environment. Moreover, due to lack of comprehensive dataset from oblique perspective, fog-end deep learning algorithms for this purpose is still in blank. In this paper, we propose a novel method to generate synthetic large-scale dataset for geometric and semantic urban scene understanding from bird's eye view. There are two main steps involved, one is modeling and the other is rendering, which are processed by CityEngine and UnrealEngine4 respectively. In this way, synthetic aligned multi-model data are obtained efficiently, including spectral images, semantic labels, depth and normal maps. Specifically, terrain elevation, street graph, building style and trees distribution are all randomly generated according realistic situation, a few of handcrafted semantic labels annotated by colors spread throughout the scene, virtual cameras moved according to realistic trajectories of unmanned aerial vehicles (UAVs). For evaluation of practicability of our dataset, we manually labeled tens of aerial images downloaded from internet. And the experiment result show that, in both pure and combined mode, the dataset can improve the performance significantly.},
keywords={Buildings;Semantics;Roads;Urban areas;Machine learning;Three-dimensional displays;Rendering (computer graphics);Deep learning;environment understanding;geometric extraction;large-scale urban scene;semantic segmentation;synthetic data set},
doi={10.1109/ACCESS.2020.2976686},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8567273,
author={Körez, Atakan and Bariş÷i, Necaattin},
booktitle={2018 2nd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)}, title={İnsansız Hava Aracı (İHA) Görüntülerindeki Yayaların Faster R-CNN Algoritması ile Otomatik Tespiti},
year={2018},
volume={},
number={},
pages={1-4},
abstract={Drone or Unmanned Aerial Vehicles (UAVs) are now actively used by many different sectors. In particular, the drone who have gained popularity in recent years; From advertising to cargo transportation, various tasks can be undertaken. Detection of objects in unmanned aerial images is often done by the operator using the vehicle. In this study, the Faster R-CNN algorithm, which is used frequently in the object detection application literature, was modified to automate this situation and was used for automatic detection of bounces in images taken by unmanned aerial photographs.},
keywords={Drones;Conferences;Object detection;Computer vision;Unmanned Air Vehicle;Object Detection;Deep Learning;Faster RCNN;Convolutional Neural Networks},
doi={10.1109/ISMSIT.2018.8567273},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8556745,
author={Mekky, Ahmed and Alberts, Thomas E.},
booktitle={NAECON 2018 - IEEE National Aerospace and Electronics Conference}, title={Design of a Stochastic Basis Function Artificial Neural Network Controller for Quadrotors Flight in the Presence of Model and Aerodynamic Uncertainties},
year={2018},
volume={},
number={},
pages={395-402},
abstract={In this paper, a learning-controller is presented that addresses the issue of flying quadrotors in confined environments. This controller utilizes Artificial Neural Networks to adjust for unknown aerodynamics and model uncertainties on-line. A novel Artificial Neural Network structure, and a novel learning law are provided, accompanied with the corresponding stability proof. The developed controller is validated via numerical simulation.},
keywords={Uncertainty;Stochastic processes;Artificial neural networks;Aerodynamics;Numerical simulation;Stability analysis;Robustness;Artificial Neural Networks Control;Stochastic Basis Function;Quadrotor Control;Nonlinear Control;Robust Control;UAV},
doi={10.1109/NAECON.2018.8556745},
ISSN={2379-2027},
month={July},}
@INPROCEEDINGS{8909830,
author={Nalamati, Mrunalini and Kapoor, Ankit and Saqib, Muhammed and Sharma, Nabin and Blumenstein, Michael},
booktitle={2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)}, title={Drone Detection in Long-Range Surveillance Videos},
year={2019},
volume={},
number={},
pages={1-6},
abstract={The usage of small drones/UAVs has significantly increased recently. Consequently, there is a rising potential of small drones being misused for illegal activities such as terrorism, smuggling of drugs, etc. posing high-security risks. Hence, tracking and surveillance of drones are essential to prevent security breaches. The similarity in the appearance of small drone and birds in complex background makes it challenging to detect drones in surveillance videos. This paper addresses the challenge of detecting small drones in surveillance videos using popular and advanced deep learning-based object detection methods. Different CNN-based architectures such as ResNet-101 and Inception with Faster-RCNN, as well as Single Shot Detector (SSD) model was used for experiments. Due to sparse data available for experiments, pre-trained models were used while training the CNNs using transfer learning. Best results were obtained from experiments using Faster-RCNN with the base architecture of ResNet-101. Experimental analysis on different CNN architectures is presented in the paper, along with the visual analysis of the test dataset.},
keywords={Drones;Training;Videos;Object detection;Detectors;Proposals;Birds;Drone detection;Deep learning;Faster R-CNN},
doi={10.1109/AVSS.2019.8909830},
ISSN={2643-6213},
month={Sep.},}
@INPROCEEDINGS{9445313,
author={A, Fathimath Shahina C. and Kabeer, Saifudeen},
booktitle={2021 2nd International Conference on Intelligent Engineering and Management (ICIEM)}, title={‘Covid-Proof’ Smart World},
year={2021},
volume={},
number={},
pages={347-352},
abstract={The rare corona virus epidemic has placed communities all over the world in perilous situations. This paper proposed a systematic approach to survive the any kind of pandemic more efficiently by merging the concept of Internet of Things (IoT), Augmented Reality (AR), Unmanned Aerial Vehicles (UAVs), and machine learning (ML). We have designed technology systems and scientific solutions for various smart sectors including Education, Health, Residents, Food and safety, Transportation, Agricultural, Occupation and Finance, Recreation and fitness, and Law and enforcement, which will work in convergence to develop `pandemic-proof' future smart world. Smart emerging innovations are playing a critical role in the world's survival at the time of lockdown and social distancing. This smart application can be a potential tool for supporting remote service delivery, ensuring uninterrupted education, food and medicine delivery, mitigating the crises' impact on businesses and urban citizens and empowering new types of local governance.},
keywords={COVID-19;Technological innovation;Systematics;Education;Transportation;Tools;Unmanned aerial vehicles;COVID-19;UAV;IoT;Machine Learning;AR;AI},
doi={10.1109/ICIEM51511.2021.9445313},
ISSN={},
month={April},}
@INPROCEEDINGS{9473729,
author={Zhu, Zheqi and Wan, Shuo and Fan, Pingyi and Letaief, Khaled B.},
booktitle={2021 IEEE International Conference on Communications Workshops (ICC Workshops)}, title={An Edge Federated MARL Approach for Timeliness Maintenance in MEC Collaboration},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Mobile edge computing (MEC) has been widely studied to provide new schemes for communication-computing systems such as industrial Internet of Things (IoTs), vehicular networks, smart city applications, etc. In this work, we mainly investigate on the timeliness maintenance of the MEC systems where the freshness of the data and computation tasks plays a significant role. We firstly formulate the average age of information (AoI) minimization problem of the UAV-assisted MEC systems. To maintain the system timeliness, we propose a novel multi-agent reinforcement learning (MARL) approach, called edge federated multi-agent actor-critic (MAAC), for joint trajectory planning, data scheduling and resource management in the investigated MEC systems. Through the proposed online learning method, edge devices and center controller learn the interactive policies through local observations and carry out the model-wise communication. We build up a simulation platform for time sensitive MEC systems as a gym environment module and implement the proposed algorithm. Furthermore, the comparisons with a popular MARL solution, MADDPG, show that the proposed approach achieves better performance in terms of data freshness and system stability.},
keywords={Job shop scheduling;Trajectory planning;Conferences;Collaboration;Maintenance engineering;Channel allocation;Stability analysis;MEC collaboration;multi-agent deep reinforcement learning;actor-critic;federated learning},
doi={10.1109/ICCWorkshops50388.2021.9473729},
ISSN={2694-2941},
month={June},}
@INPROCEEDINGS{9533859,
author={Ahmad, Touqeer and Emami, Ebrahim and Čadík, Martin and Bebis, George},
booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, title={Resource Efficient Mountainous Skyline Extraction using Shallow Learning},
year={2021},
volume={},
number={},
pages={1-9},
abstract={Skyline plays a pivotal role in mountainous visual geo-localization and localization/navigation of planetary rovers/UAVs and virtual/augmented reality applications. We present a novel mountainous skyline detection approach where we adapt a shallow learning approach to learn a set of filters to discriminate between edges belonging to sky-mountain boundary and others coming from different regions. Unlike earlier approaches, which either rely on extraction of explicit feature descriptors and their classification, or fine-tuning general scene parsing deep networks for sky segmentation, our approach learns linear filters based on local structure analysis. At test time, for every candidate edge pixel, a single filter is chosen from the set of learned filters based on pixel's structure tensor, and then applied to the patch around it. We then employ dynamic programming to solve the shortest path problem for the resultant multistage graph to get the sky-mountain boundary. The proposed approach is computationally faster than earlier methods while providing comparable performance and is more suitable for resource constrained platforms e.g., mobile devices, planetary rovers and UAVs. We compare our proposed approach against earlier skyline detection methods using four different data sets. Our code is available at https://github.com/TouqeerAhmad/skyline_detection.},
keywords={Performance evaluation;Deep learning;Training;Space vehicles;Maximum likelihood detection;Visualization;Tensors},
doi={10.1109/IJCNN52387.2021.9533859},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{8453318,
author={Kim, Inwook and Morrison, James R.},
booktitle={2018 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Learning Based Framework for Joint Task Allocation and System Design in Stochastic Multi-UAV Systems},
year={2018},
volume={},
number={},
pages={324-334},
abstract={We consider a system of UAVs, depots, service stations and tasks in a stochastic environment. Our goal is to jointly determine the system resources (system design), task allocation and waypoint selection. To our knowledge, none have studied this joint decision problem in the stochastic context. We formulate the problem as a Markov decision process (MDP) and resort to deep reinforcement learning (DRL) to obtain state-based decisions. Numerical studies are conducted to assess the performance of the proposed approach. In small examples for which an optimal policy can be found, the DRL based approach is much faster than value iteration and obtained nearly optimal solutions. In large examples, the DRL based approach can find efficient designs and policies.},
keywords={Task analysis;Resource management;Fuels;Stochastic processes;Loading;Robots},
doi={10.1109/ICUAS.2018.8453318},
ISSN={2575-7296},
month={June},}
@ARTICLE{9369397,
author={Najla, Mehyar and Becvar, Zdenek and Mach, Pavel and Gesbert, David},
journal={IEEE Wireless Communications Letters}, title={Positioning and Association Rules for Transparent Flying Relay Stations},
year={2021},
volume={10},
number={6},
pages={1276-1280},
abstract={Transparent flying relay stations (FlyRSs), represented by transparent relays mounted on unmanned aerial vehicles (UAVs), have the potential to improve cellular network's capacity and coverage at little extra complexity and energy cost, especially when compared with non-transparent relays. As the transparent relays do not transmit reference signals, they do not lend themselves easily to channel estimation. This makes solving the problems of user association and positioning of transparent FlyRSs much harder. We propose a solution enabling an efficient association of users to the FlyRSs and determining suitable positions of the FlyRSs. Surprisingly, this can be done knowing neither the qualities of the channels linking the FlyRSs and the users nor the users' location information. Our approach involves the users being grouped into clusters based on the channels to nearby static base stations via agglomerative hierarchical clustering. Then, 3D positions of one FlyRS per cluster are determined by deep neural networks. The proposal improves the users' sum capacity with respect to existing solutions that rely on the knowledge of users' positions.},
keywords={Relays;Channel estimation;Gain;Buildings;Neural networks;Urban areas;Unmanned aerial vehicles;Transparent relays;unmanned aerial vehicles;agglomerative hierarchical clustering;deep neural networks},
doi={10.1109/LWC.2021.3063909},
ISSN={2162-2345},
month={June},}
@INBOOK{9227207,
author={},
booktitle={Security within CONASENSE Paragon}, title={6 UAV Communication Networks: Problems and Possible Solutions},
year={2019},
volume={},
number={},
pages={85-94},
abstract={Security within CONASENSE Paragon describes in particular the cyber security issues in the field of Communication, Navigation, Sensing and Services within the broad platform of CTIF Global Capsule (CGC). This covers future technologies and its enablers, smart cities, crowd computing, reliable and secure communication interface, satellite unnamed air vehicles, wireless sensor networks, data analytics and deep learning, remotely piloted aircraft system and public safety, network neutrality, business ecosystem innovation and so on.},
keywords={},
doi={},
ISSN={},
publisher={River Publishers},
isbn={9788770220910},
url={https://ieeexplore-ieee-org.ez294.periodicos.capes.gov.br/document/9227207},}
@INPROCEEDINGS{9213915,
author={Astudillo, Armando and Al-Kaff, Abdulla and Madridano, Ángel and García, Fernando and Martín, David and de la Escalera, Arturo},
booktitle={2020 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Mono-LSDE: Lightweight Semantic-CNN for Depth Estimation from Monocular Aerial Images},
year={2020},
volume={},
number={},
pages={807-814},
abstract={In the last decade, with the advances in autonomous technologies, Unmanned Aerial Vehicles (UAVs) have been encountered a significant focus on several applications. With the complexity of the tasks performed by the UAVs, this addresses the necessity to obtain information about the surrounding environment. Estimating depth maps from monocular images is considered a key role when working small or micro UAVs, this is due to the Size, Weight, and Power (SWaP) constraints on these vehicles. Therefore, this paper proposed a lightweight Semantic Neural Network based on Encoder-Decoder architecture; to obtain a depth map from a monocular camera.The proposed method has been tested in several scenarios of complex environments, and the obtained results show its robustness and efficiency against different weather and light conditions, illustrating the functionality of the proposed method in real-time applications.},
keywords={Cameras;Forestry;Urban areas;Estimation;Neural networks;Feature extraction;Semantics},
doi={10.1109/ICUAS48674.2020.9213915},
ISSN={2575-7296},
month={Sep.},}
@ARTICLE{7784185,
author={An, Meiyan and Wang, Zhaokui and Zhang, Yulin},
journal={Journal of Systems Engineering and Electronics}, title={Self-organizing strategy design and validation for integrated air-ground detection swarm},
year={2016},
volume={27},
number={5},
pages={1018-1027},
abstract={A self-organized integrated air-ground detection swarm is tentatively applied to achieve reentry vehicle landing detection, such as searching and rescuing a manned spaceship. The detection swarm consists of multiple unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). The UAVs can access a detected object quickly for high mobility, while the UGVs can comprehensively investigate the object due to the variety of carried equipment. In addition, the integrated air-ground detection swarm is capable of detecting from the ground and the air simultaneously. To accomplish the coordination of the UGVs and UAVs, they are all regarded as individuals of the artificial swarm. Those individuals make control decisions independently of others based on the self-organizing strategy. The overall requirements for the detection swarm are analyzed, and the theoretical model of the self-organizing strategy based on a combined individual and environmental virtual function is established. The numerical investigation proves that the self-organizing strategy is suitable and scalable to control the detection swarm. To further inspect the engineering reliability, an experiment set is established in laboratory, and the experimental demonstration shows that the self-organizing strategy drives the detection swarm forming a close range and multiangular surveillance configuration of a landing spot.},
keywords={Mobile communication;Vehicles;Surveillance;Cameras;Global Positioning System;Optical devices;Analytical models;artificial swarm;virtual potential field;self-organizing;integrated air-ground detection swarm},
doi={10.21629/JSEE.2016.05.10},
ISSN={1004-4132},
month={Oct},}
@INPROCEEDINGS{9207539,
author={Nguyen, Tung and Liu, Jing and Nguyen, Hung and Kasmarik, Kathryn and Anavatti, Sreenatha and Garratt, Matthew and Abbass, Hussein},
booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, title={Perceptron-Learning for Scalable and Transparent Dynamic Formation in Swarm-on-Swarm Shepherding},
year={2020},
volume={},
number={},
pages={1-8},
abstract={Swarm guidance, such as the case of guiding a group of sheep away from a field, is a challenging task. As the swarm size increases, it becomes necessary that multiple control points, or sheepdogs, are needed to guide the swarm. In this paper, a swarm of unmanned aerial vehicles (UAVs) acts as a moving safety network (aka a formation) that not only guides the sheep swarm, but also prevents them from dispersing or reversing to the other side of the field. We investigate two types of formations. The first type acts as a baseline, maintains fixed distances from the sheep swarm, and relies on fixed predefined angular structure relative to the sheep's global centre of mass (GCM). The second type is dynamic, where the force vector to control the UAV and the individual distance of each UAV from the sheep's GCM are controlled by a Perceptron, with the weights optimized by a particle swarm optimization algorithm. We evolve five Perceptrons to specialize in relative positions in the formation, which fixes the space cost for the optimization algorithm, while allowing the size of the swarm of UAVs to scale up. We demonstrate that the use of Perceptron-networks for dynamic control scheme reduces the total distance travelled by the UAVs, is transparent when interpreted with Hinton diagrams, and transferable to a larger number of UAVs.},
keywords={Heuristic algorithms;Force;Particle swarm optimization;Optimization;Vehicle dynamics;Task analysis;Unmanned aerial vehicles;Multi-Agent Systems;Formation Control;Shepherding;Particle Swarm Optimization},
doi={10.1109/IJCNN48605.2020.9207539},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{8062431,
author={Stebler, Shane and MacKunis, William and Ramos-Pedroza, Natalie and Reyhanoglu, Mahmut},
booktitle={2017 IEEE Conference on Control Technology and Applications (CCTA)}, title={A dynamic neural network-based sliding mode observer method for a class of uncertain dynamic systems},
year={2017},
volume={},
number={},
pages={1-6},
abstract={A dynamic neural network (DNN)-based observer design is presented, which amalgamates an adaptive neural network-based technique with a finite-time sliding mode estimation method. The proposed observer design is motivated by practical quadrotor unmanned aerial vehicle tracking control applications, where direct sensor measurements of translational and rotational rates are not available for feedback. While sliding mode estimation strategies are well established as an effective means to compensate for bounded disturbances and dynamic model uncertainty, the proposed observer design employs a feedforward adaptive DNN-based estimation term in addition to a robust, high-gain feedback sliding mode element. The use of the DNN-based term in the estimator design is motivated by the desire to improve transient performance and reduce steady state error. In addition, the proposed sliding mode estimator design is proven to compensate for input-multiplicative parametric model uncertainty. To the best of the authors' knowledge, this is the first DNN-based sliding mode estimator result to rigorously prove asymptotic state estimation in the presence of parametric actuator uncertainty. A Lyapuov-based stability analysis is utilized to prove that the proposed DNN-based observer achieves asymptotic estimation of the quadrotor altitude and attitude rates in the presence of model uncertainty and bounded disturbances (e.g., sensor noise). Numerical simulation results are also provided to demonstrate the improved performance that is achieved by incorporating the adaptive DNN in the observer.},
keywords={Observers;Uncertainty;Artificial neural networks;Vehicle dynamics;Trajectory tracking;Aerodynamics},
doi={10.1109/CCTA.2017.8062431},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8170401,
author={Koops, Hendrik Vincent and Garg, Kashish and Kim, Munsung and Li, Jonathan and Volk, Anja and Franchetti, Franz},
booktitle={2017 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)}, title={Multirotor UAV state prediction through multi-microphone side-channel fusion},
year={2017},
volume={},
number={},
pages={15-21},
abstract={Improving trust in the state of Cyber-Physical Systems becomes increasingly important as more Cyber-Physical Systems tasks become autonomous. Research into the sound of Cyber-Physical Systems has shown that audio side-channel information from a single microphone can be used to accurately model traditional primary state sensor measurements such as speed and gear position. Furthermore, data integration research has shown that information from multiple heterogeneous sources can be integrated to create improved and more reliable data. In this paper, we present a multi-microphone machine learning data fusion approach to accurately predict ascending/hovering/descending states of a multi-rotor UAV in flight. We show that data fusion of multiple audio classifiers predicts these states with accuracies over 94%. Furthermore, we significantly improve the state predictions of single microphones, and outperform several other integration methods. These results add to a growing body of work showing that microphone side-channel approaches can be used in Cyber-Physical Systems to accurately model and improve the assurance of primary sensors measurements.},
keywords={Microphones;Data integration;Rotors;Spectrogram;State estimation;Meters},
doi={10.1109/MFI.2017.8170401},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9130475,
author={Domozi, Zsolt and Stojcsics, Daniel and Benhamida, Abdallah and Kozlovszky, Miklos and Molnar, Andras},
booktitle={2020 IEEE 15th International Conference of System of Systems Engineering (SoSE)}, title={Real time object detection for aerial search and rescue missions for missing persons},
year={2020},
volume={},
number={},
pages={000519-000524},
abstract={This paper introduces a solution to stand-alone system based, real-time object-detection, can efficiently facilitate the search for missing persons with an unmanned aerial vehicle. The challenge is the real-time implementation of the systems and training the given deep neural network for the desired task. The paper describes the methods and procedures currently in use, as well as the possible tools. Subsequently, the autonomous aircraft system, which carries a real-time detection system, is introduced. In the section about real-time detection, we will introduce the TensorFlow lite-based application, building on SSD topology, in detail, which was implemented on mobile phones. We will also introduce the dataset used for training, testing and the results achieved. In summary, the recall achieved is 65.4% and precision is 96.4%, besides the fact that the android-based application, using the phone’s camera, performs image analysis at a rate of 11 to 17 FPS in real-time, while continuously providing},
keywords={Training;Network topology;Object detection;Search problems;Cameras;Real-time systems;Topology;search and rescue;system of systems;deep learning;unmanned aerial vehicles;real time object detection;tensorflow lite},
doi={10.1109/SoSE50414.2020.9130475},
ISSN={},
month={June},}
@ARTICLE{8404075,
author={Yang, Zhuoqian and Dan, Tingting and Yang, Yang},
journal={IEEE Access}, title={Multi-Temporal Remote Sensing Image Registration Using Deep Convolutional Features},
year={2018},
volume={6},
number={},
pages={38544-38555},
abstract={Registration of multi-temporal remote sensing images has been widely applied in military and civilian fields, such as ground target identification, urban development assessment, and geographic change assessment. Ground surface change challenges feature point detection in amount and quality, which is a common dilemma faced by feature-based registration algorithms. Under severe appearance variation, detected feature points may contain a large proportion of outliers, whereas inliers may be inadequate and unevenly distributed. This paper presents a convolutional neural network (CNN) feature-based multitemporal remote sensing image registration method with two key contributions: (i) we use a CNN to generate robust multi-scale feature descriptors and (ii) we design a gradually increasing selection of inliers to improve the robustness of feature point registration. Extensive experiments on feature matching and image registration are performed over a multi-temporal satellite image data set and a multi-temporal unmanned aerial vehicle image dataset. Our method outperforms four state-of-the-art methods in most scenarios.},
keywords={Feature extraction;Image registration;Remote sensing;Robustness;Convolutional neural networks;Optimization;Indexes;Remote sensing;feature matching;image registration;convolutional feature},
doi={10.1109/ACCESS.2018.2853100},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9213845,
author={Zhu, Jing and Zhang, Peng and Jiang, Bin},
booktitle={2020 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Online ADP based Oxygen Excess Ratio Control of the PEM Fuel Cell System Applying to UAVs},
year={2020},
volume={},
number={},
pages={1376-1383},
abstract={The excess ratio control of PEM fuel cells systems is investigated in this paper with the use of double loop cascade control structure. In the outer loop, an improved super-twisting control algorithm is proposed which is robust against dynamics and disturbances in UAVs. As for the inner loop, the optimal tracking controller based upon adaptive dynamic programming (ADP) is exploited to adaptively approximate the optimal control policy, where the weights of neural networks are updated real-time. Simulation results are demonstrated with comparison between the traditional cascaded super twisting control scheme and the ADP based scheme.},
keywords={Fuel cells;Cathodes;Mathematical model;Angular velocity;Heuristic algorithms;Robustness;Voltage control},
doi={10.1109/ICUAS48674.2020.9213845},
ISSN={2575-7296},
month={Sep.},}
@ARTICLE{8945396,
author={Li, Xiaoxia and Li, Wei and Yang, Qiang and Yan, Wenjun and Zomaya, Albert Y.},
journal={IEEE Journal of Photovoltaics}, title={An Unmanned Inspection System for Multiple Defects Detection in Photovoltaic Plants},
year={2020},
volume={10},
number={2},
pages={568-576},
abstract={Condition monitoring and fault diagnosis of photovoltaic modules are essential to ensure the efficient and reliable operation of large-scale photovoltaic plants. This article presents an algorithmic solution for the rapid and sensitive detection of photovoltaic modules with multiple visible defects by an image analyzing apparatus mounted onto an unmanned aerial vehicle. The proposed solution is composed of three stages to efficiently and accurately analyze various forms of module defects. First, the Kirsch operator is employed to identify the anomalous regions, which can significantly reduce the computational complexity, and error rate. Afterward, a deep convolutional neural network is adopted to extract defect features. Finally, a multiple classification support vector machine is developed to facilitate the defects detection decision-making. The proposed solution is extensively evaluated by the comprehensive dataset collected from real-world solar photovoltaic plants. The experimental results clearly demonstrate the effectiveness of our solution for photovoltaic modules diagnosis with multiple visible defects.},
keywords={Inspection;Feature extraction;Photovoltaic systems;Glass;Maintenance engineering;Condition monitoring;convolutional neural network (CNN);deep learning;Kirsch operator;photovoltaic (PV) plant;support vector machine (SVM)},
doi={10.1109/JPHOTOV.2019.2955183},
ISSN={2156-3403},
month={March},}
@INPROCEEDINGS{8362113,
author={Gonzalez, Angelo and Zuniga, Marcos D. and Nikulin, Christopher and Carvajal, Gonzalo and Cardenas, Daniel G. and Pedraza, Manuel A. and Fernandez, Camilo A. and Munoz, Roberto I. and Castro, Nicolas A. and Rosales, Bryan F. and Quinteros, Jose M. and Rauh, Felix J. and Akhloufi, Moulay A.},
booktitle={7th Latin American Conference on Networked and Electronic Media (LACNEM 2017)}, title={Accurate fire detection through fully convolutional network},
year={2017},
volume={},
number={},
pages={1-6},
abstract={The devastating effects of wildland fires is an unsolved worldwide problem, resulting in human losses and the destruction of natural and economical resources. Assisting firefighters in controlling this kind of natural disasters is an important task. Nowadays, technology advances can help to fulfil this complex task. We propose a new convolutional neural network architecture able to detect fires in images, with high accuracy and high performance which enable the operation of the system in real-time. Preliminary results show that the proposed approach, called SFEwAN-SD, outperforms state-of-the-art approaches both in accuracy and processing time. This performance will be useful in the development of our UAV fire monitoring system that can detect and track fires in real-time.},
keywords={fire detection;wildland fires;convolutional neural networks;UAV},
doi={10.1049/ic.2017.0026},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8289450,
author={Raja, Muhammad Adil and Rahman, Shams Ur},
booktitle={2017 International Multi-topic Conference (INMIC)}, title={A tutorial on simulating unmanned aerial vehicles},
year={2017},
volume={},
number={},
pages={1-6},
abstract={This paper presents our reflections about our recent, intense involvement with the simulation of unmanned aerial vehicles (UAVs). Our idea was to integrate a flight simulator with a machine learning (ML) algorithm. As in any research project, we came across many challenging issues. We would like to highlight those issues and their workarounds. Our hope is that this will make it easier for the wider research community to address the challenges involved in UAV simulation.},
keywords={Aircraft;Atmospheric modeling;Matlab;Open source software;Aerodynamics;Force;Evolutionary Computation;Genetic Algorithms;Machine Learning},
doi={10.1109/INMIC.2017.8289450},
ISSN={},
month={Nov},}
@ARTICLE{9321707,
author={Albanese, Antonio and Sciancalepore, Vincenzo and Costa-Perez, Xavier},
journal={IEEE Transactions on Mobile Computing}, title={SARDO: An Automated Search-and-Rescue Drone-based Solution for Victims Localization},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Natural disasters affect millions of people every year. Finding missing persons in the shortest possible time is of crucial importance to reduce the death toll. This task is especially challenging when victims are sparsely distributed in large and/or difficult-to-reach areas and cellular networks are down. In this paper we present SARDO, a drone-based search and rescue solution that leverages the high penetration rate of mobile phones in the society to localize missing people. SARDO is an autonomous, all-in-one drone-based mobile network solution that does not require infrastructure support or mobile phones modifications. It builds on novel concepts such as pseudo-trilateration combined with machine-learning techniques to efficiently locate mobile phones in a given area. Our results, with a prototype implementation in a field-trial, show that SARDO rapidly determines the location of mobile phones (~3 min/UE) in a given area with an accuracy of few tens of meters and at a low battery consumption cost (~5%). State-of-the-art localization solutions for disaster scenarios rely either on mobile infrastructure support or exploit onboard cameras for human/computer vision, IR, thermal-based localization. To the best of our knowledge, SARDO is the first drone-based cellular search-and-rescue solution able to accurately localize missing victims through mobile phones.},
keywords={Location awareness;Global navigation satellite system;Mobile handsets;Base stations;Trajectory;Time measurement;Task analysis;UAV-based cellular coverage;Search and Rescue Operations;Single-UAV localization;Pseudo-Trilateration;Convolutional Neural Network (CNN);Long Short-Term Memory (LSTM)},
doi={10.1109/TMC.2021.3051273},
ISSN={1558-0660},
month={},}
@INPROCEEDINGS{8798265,
author={Kóta, Fülöp and Zsedrovits, Tamás and Nagy, Zoltán},
booktitle={2019 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Sense-and-avoid system development on an FPGA},
year={2019},
volume={},
number={},
pages={575-579},
abstract={In this paper, the first steps of development towards a collision avoidance system for UAV are introduced. The system is based on camera sensors controlled by an FPGA SoC, running an image processing algorithm, controlling a quadcopter to avoid mid-air collisions with other aircraft. The algorithm was already tested in a real mid-air close encounter scenario between two UAVs, but in that scenario, the implementation platform was a GPU-based SoC which had serious limitations concerning processing frame rate and power consumption. Our aim is to realize the same algorithm with higher framerate and lower power consumption. The paper introduces fundamental considerations for the selection of tools used during this process.},
keywords={Field programmable gate arrays;Cameras;Tools;Unmanned aerial vehicles;Hardware;Neural networks;Python},
doi={10.1109/ICUAS.2019.8798265},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{8639306,
author={Sarwar, Farah and Griffin, Anthony and Periasamy, Priyadharsini and Portas, Kurt and Law, Jim},
booktitle={2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)}, title={Detecting and Counting Sheep with a Convolutional Neural Network},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Counting livestock is generally done only during major events, such as drenching, shearing or loading, and thus farmers get stock numbers sporadically throughout the year. More accurate and timely stock information would enable farmers to manage their herds better. Additionally, prompt response to any stock in distress is extremely valuable, both in terms of animal welfare and the avoidance of financial loss. In this regard, the evolution of deep learning algorithms and Unmanned Aerial Vehicles (UAVs) is forging a new research area for remote monitoring and counting of different animal species under various climatic conditions. In this paper, we focus on detecting and counting sheep in a paddock from UAV video. Sheep are counted using a model based on Region-based Convolutional Neural Networks and the results are then compared with other techniques to evaluate their performance.},
keywords={Animals;Training;Training data;Unmanned aerial vehicles;Task analysis;Testing;Agriculture},
doi={10.1109/AVSS.2018.8639306},
ISSN={},
month={Nov},}
@INPROCEEDINGS{6244311,
author={Fu Li and Wang Qi and Xu Jin and Zhou Yuandong and Zhu Kun},
booktitle={2012 24th Chinese Control and Decision Conference (CCDC)}, title={Target assignment and sorting for multi-target attack in Multi-aircraft coordinated based on RBF},
year={2012},
volume={},
number={},
pages={1935-1938},
abstract={In this paper, we make the UAV air combat as the background. Based on air combat situation and target's air combat ability, the threat evaluation model of UAV air combat is established, then it uses RBF neural network to identify complex nonlinear relation between the types of threats to get the overall threat situation. In the course of air combat, we get the threat situation index of air combat, and then get the target threat matrix through RBF neural network. Finally, it uses the matrix method to get the result of target assignment and sorting. The experimental results show that RBF neural network can successfully approximate the weights of all the types of threats.},
keywords={Aircraft;Indexes;Neural networks;Sorting;Educational institutions;Atmospheric modeling;Fires;Threat Evaluation Model;RBF Neural Network;Matrix Method;Target Assignment and Sorting},
doi={10.1109/CCDC.2012.6244311},
ISSN={1948-9447},
month={May},}
@INPROCEEDINGS{8899261,
author={Zheng, Zhuo and Zhong, Yanfei},
booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium}, title={S3NET: Towards Real-Time Hyperspectral Imagery Classification},
year={2019},
volume={},
number={},
pages={3293-3296},
abstract={Fast hyperspectral image classification methods are required to real time processing on UAV and airborne platform. But current state of the art methods are under patch based framework that is slow due to duplicate computation, while fully convolutional neural network (FCN) is difficult to run inference in one shot due to patch based training strategy. In this paper, we firstly identify overparameterization and inconsistent class ratio per mini-batch as the central causes impeding training of FCN based methods so we propose a novel framework based on a new lightweight network and a stratified sample based training strategy to overcome above problems. To refine redundant spectrum information for fast computation, the spectral attention module is proposed as a soft band selection. The proposed training strategy enables the stability of training by keeping class ratio consistent in mini-batches. On the WHU-HongHu UAV dataset, our method achieves great performance by obtaining a OA of 98.94 and running at 144 fps. Additionally, our method can obtain a flexible trade-off between speed and accuracy.},
keywords={Training;Hyperspectral imaging;Convolution;Real-time systems;Standards;Convolutional neural networks;Fully convolutional neural network;stratified sample;real-time;hyperspectral image classification},
doi={10.1109/IGARSS.2019.8899261},
ISSN={2153-7003},
month={July},}
@ARTICLE{9681624,
author={Mozaffari, Mohammad and Lin, Xingqin and Hayes, Stephen},
journal={IEEE Communications Magazine}, title={Toward 6G with Connected Sky: UAVs and Beyond},
year={2021},
volume={59},
number={12},
pages={74-80},
abstract={The large-scale and ever-growing use of unmanned aerial vehicles (UAVs) in a wide range of applications is foreseen to be a major part of beyond 5G and 6G wireless networks in the next decade. The effective support of such massive deployment of UAVs requires offering reliable, secure, and cost-effective wireless connectivity. Cellular networks play essential roles in serving UAVs acting as flying user equipments. While the cellular networks provide promising connectivity solutions for UAVs, enabling robust UAV operations faces several challenges. In this article, an overview of key barriers and design considerations of widespread commercial use of flying UAVs are presented along with their potential solutions. In addition, we discuss how cellular networks can support UAVs by relying on their advanced features, network intelligence, key enabling technologies for beyond 5G and 6G, and exploiting new tools from machine learning. Finally, we shed light on offering wireless services to high altitudes and the integration of non-terrestrial networks with terrestrial networks toward limitless connectivity in 6G.},
keywords={6G mobile communication;Cellular networks;5G mobile communication;Wireless networks;Autonomous aerial vehicles;Safety;Communication system security},
doi={10.1109/MCOM.005.2100142},
ISSN={1558-1896},
month={December},}
@INPROCEEDINGS{8904014,
author={Sriram, P.R. and Ramani, Sandeep Kumar and Shrivatsav, Ram V and M.Mankiandan, Muthu and Ayyappaa, Nithin},
booktitle={2019 Third World Conference on Smart Trends in Systems Security and Sustainablity (WorldS4)}, title={Autonomous Drone for Defence Machinery Maintenance and Surveillance},
year={2019},
volume={},
number={},
pages={288-292},
abstract={This proposed research work focuses on the implementation of an autonomous unmanned aerial vehicle (UAV) which is controlled using a pix hawk flight controller. The Quad Copter is capable of navigating autonomously without any real-time input from the user and also programmed to follow a specified path autonomously. The algorithm enables a control technique by which quad copter is empowered to fly autonomously, trajectory tracking, graceful motion and accurate altitude hold performance. Surveillance and Machinery maintenance application are the primary applications designed for the Defense purposes in the Line Of Control and War-zones. This work is aimed to design a quad copter that will follow a command to fly through specified way points. The deep learning algorithm detects human motions and from data acquired camera and ultrasonic sensors to the cloud. On deviations from the standard protocol which is detected using a Sjcam 5000x elite Camera. Also, here a backup auxiliary mini drone is programmed to eject along with the data stored on the primary drone's memory on an unforeseen calamity or an attack that would damage the primary drone's ability to fly.},
keywords={Drones;Machinery;Cameras;Surveillance;Payloads;Protocols;Software;Autonomous Drone;Deep Learning;Wireless Communication;Auxiliary Drone;image Processing;Line Of Control;Sense Hat;UAV},
doi={10.1109/WorldS4.2019.8904014},
ISSN={},
month={July},}
@INPROCEEDINGS{8794057,
author={Mérida-Floriano, M. and Caballero, F. and Acedo, D. and García-Morales, D. and Casares, F. and Merino, L.},
booktitle={2019 International Conference on Robotics and Automation (ICRA)}, title={Bioinspired Direct Visual Estimation of Attitude Rates with Very Low Resolution Images using Deep Networks},
year={2019},
volume={},
number={},
pages={5672-5678},
abstract={In this work we present a bioinspired visual system sensor to estimate angular rates in unmanned aerial vehicles (UAV) using Neural Networks. We have conceived a hardware setup to emulate Drosophila's ocellar system, three simple eyes related to stabilization. This device is composed of three low resolution cameras with a similar spatial configuration as the ocelli. There have been previous approaches based on this ocellar system, most of them considering assumptions such as known light source direction or a punctual light source. In contrast, here we present a learning approach using Artificial Neural Networks in order to recover the system's angular rates indoors and outdoors without previous knowledge. A classical computer vision based method is also derived to be used as a benchmark for the learning approach. The method is validated with a large dataset of images (more than half a million samples) including synthetic and real data. The source code of the algorithms and the datasets used in this paper have been released in an open repository.},
keywords={Cameras;Robot sensing systems;Visualization;Estimation;Neural networks;Computer vision;Image resolution},
doi={10.1109/ICRA.2019.8794057},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{9079122,
author={Zhao, Yubin and Zhang, Xiao and Fioranelli, Francesco},
booktitle={2019 International Radar Conference (RADAR)}, title={Initial results of Radar-based classification of commercial drone carrying small payloads},
year={2019},
volume={},
number={},
pages={1-4},
abstract={This student paper shows preliminary results on the possibility of using radar systems to identify small payloads carried by a commercial drone. This can be of great interest for traffic monitoring and situational awareness in near-future scenarios when drones are expected to be used for parcel delivery and many other applications. In this work, we consider a distributed and rather small payload, approximately 92g, carried by a commercial drone flying back and forth. Different combinations of features extracted from the micro-Doppler signatures and dwell time have been analyzed, showing promising results with median accuracy around 80% and maximum accuracy approaching 90% for the optimal case.},
keywords={radar classification;micro-Doppler;supervised machine learning;UAVs},
doi={10.1109/RADAR41533.2019.171305},
ISSN={2640-7736},
month={Sep.},}
@INPROCEEDINGS{7487719,
author={Sarkar, Suproteem K. and Das, Jnaneshwar and Ehsani, Reza and Kumar, Vijay},
booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)}, title={Towards autonomous phytopathology: Outcomes and challenges of citrus greening disease detection through close-range remote sensing},
year={2016},
volume={},
number={},
pages={5143-5148},
abstract={Unmanned aerial vehicles (UAVs) have the potential to significantly impact early detection and monitoring of plant diseases. In this paper, we present preliminary work in developing a UAV-mounted sensor suite for detection of citrus greening disease, a major threat to Florida citrus production. We propose a depth-invariant sensing methodology for measuring reflectance of polarized amber light, a metric which has been found to measure starch accumulation in greening-infected leaves. We describe the implications of adding depth information to this method, including the use of machine learning models to discriminate between healthy and infected leaves with validation accuracies up to 93%. Additionally, we discuss stipulations and challenges of use of the system with UAV platforms. This sensing system has the potential to allow for rapid scanning of groves to determine the spread of the disease, especially in areas where infection is still in early stages, including citrus farms in California. Although presented in the context of citrus greening disease, the methods can be applied to a variety of plant pathology studies, enabling timely monitoring of plant health-impacting scientists, growers, and policymakers.},
keywords={Robot sensing systems;Cameras;Support vector machines;Diseases;Green products;Light emitting diodes;Standards},
doi={10.1109/ICRA.2016.7487719},
ISSN={},
month={May},}
@INPROCEEDINGS{8941573,
author={Xu, Yiming and Gu, Haifeng and Dai, Quixia and Lu, Guan and Gu, Juping and Hua, Liang},
booktitle={2019 11th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC)}, title={Motion Tracking Detection and Tracking Technology Based on Aerial Video},
year={2019},
volume={2},
number={},
pages={122-125},
abstract={Aiming at the problems of complex outdoor background lighting conditions, unsatisfactory moving target features, and high degree of background fusion of wind turbines with large target background, the proposed wind turbine detection and tracking method based on deep learning convolutional neural network is proposed. This paper uses migration learning technology to use a pre-trained SSD model trained with COCO data sets and makes a dedicated localized wind turbine dataset . Through data enhancement, the neural network model can effectively improve the accuracy of wind turbine identification and the average accuracy remains above 96%. The fast recognition speed enables detection and tracking of the fan target in aerial video quickly and accurately.},
keywords={UAV inspection;target detection;location tracking;convolutional neural network;migration learning},
doi={10.1109/IHMSC.2019.10124},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9638796,
author={Liu, Yang and Zhao, Tongzhou and Shen, Zhiyu},
booktitle={2021 4th International Conference on Robotics, Control and Automation Engineering (RCAE)}, title={Small Target Detection for UAV Aerial Images Based on Improved YOLOv3},
year={2021},
volume={},
number={},
pages={12-16},
abstract={Aiming at the high rate of missed detection and false detection rate of small targets in UAV aerial photography in target detection, this paper proposes a small target detection method based on improved YOLOv3.Based on the YOLOv3 model, the 8-fold downsampled feature map output from the network is stitched with the 4-fold downsampled feature map to create a new $104 \times104$ scale detection layer. A new feature fusion network, BiFPN, is introduced to enhance feature extraction. The proposed algorithm is tested in simulation experiments on VisDrone2019 dataset, and the experimental results show that the model improves 7% over the base model with almost no impact on speed, and the detection accuracy of small targets is significantly improved.},
keywords={Photography;Automation;Object detection;Feature extraction;Autonomous aerial vehicles;Robustness;Robots;deep learning;multi-object detectiong;YOLOv3 model;feature fusion},
doi={10.1109/RCAE53607.2021.9638796},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9625393,
author={Sharma, Susanta and Venkata Susmitha, Allumallu Veera and Van, Lan-Da and Tseng, Yu-Chee},
booktitle={2021 IEEE 94th Vehicular Technology Conference (VTC2021-Fall)}, title={An Edge-Controlled Outdoor Autonomous UAV for Colorwise Safety Helmet Detection and Counting of Workers in Construction Sites},
year={2021},
volume={},
number={},
pages={1-5},
abstract={In this paper, an edge-computed and controlled outdoor autonomous UA V system is proposed to monitor the safety helmet wearing of workers in construction sites. Detection and counting of the workers with safety helmets of specified colors and those without safety helmets is the main focus of this work. Five standard safety helmet colors including blue, orange, red, white, and yellow are considered. The novelties of the work are 1) the design of a modularized software architecture running on an Android smartphone as an edge device for outdoor autonomous UA V navigation, 2) the implementation of realtime colorwise detection and counting of workers with and without safety helmets from UAV's first-person view (FPV), 3) the implementation of a simple upper-side cropping and hue, saturation, value (HSV) filtering method for color decision. The resulting average safety helmet detection accuracy for 10 different cases is 81.02%.},
keywords={Head;Filtering;Software architecture;Navigation;Image edge detection;Color;Software systems;Autonomous flying;computer vision;deep learning;edge computing;UA V (Unmanned Arial Vehicle)},
doi={10.1109/VTC2021-Fall52928.2021.9625393},
ISSN={2577-2465},
month={Sep.},}
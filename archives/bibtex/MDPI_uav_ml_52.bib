
@Article{app11209680,
AUTHOR = {Zhou, Xuan and Ke, Ruimin and Yang, Hao and Liu, Chenxi},
TITLE = {When Intelligent Transportation Systems Sensing Meets Edge Computing: Vision and Challenges},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {9680},
URL = {https://www.mdpi.com/2076-3417/11/20/9680},
ISSN = {2076-3417},
ABSTRACT = {The widespread use of mobile devices and sensors has motivated data-driven applications that can leverage the power of big data to benefit many aspects of our daily life, such as health, transportation, economy, and environment. Under the context of smart city, intelligent transportation systems (ITS), as a main building block of modern cities, and edge computing (EC), as an emerging computing service that targets addressing the limitations of cloud computing, have attracted increasing attention in the research community in recent years. It is well believed that the application of EC in ITS will have considerable benefits to transportation systems regarding efficiency, safety, and sustainability. Despite the growing trend in ITS and EC research, a big gap in the existing literature is identified: the intersection between these two promising directions has been far from well explored. In this paper, we focus on a critical part of ITS, i.e., sensing, and conducting a review on the recent advances in ITS sensing and EC applications in this field. The key challenges in ITS sensing and future directions with the integration of edge computing are discussed.},
DOI = {10.3390/app11209680}
}



@Article{rs13204155,
AUTHOR = {Ahmad, Uzair and Alvino, Arturo and Marino, Stefano},
TITLE = {A Review of Crop Water Stress Assessment Using Remote Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4155},
URL = {https://www.mdpi.com/2072-4292/13/20/4155},
ISSN = {2072-4292},
ABSTRACT = {Currently, the world is facing high competition and market risks in improving yield, crop illness, and crop water stress. This could potentially be addressed by technological advancements in the form of precision systems, improvements in production, and through ensuring the sustainability of development. In this context, remote-sensing systems are fully equipped to address the complex and technical assessment of crop production, security, and crop water stress in an easy and efficient way. They provide simple and timely solutions for a diverse set of ecological zones. This critical review highlights novel methods for evaluating crop water stress and its correlation with certain measurable parameters, investigated using remote-sensing systems. Through an examination of previous literature, technologies, and data, we review the application of remote-sensing systems in the analysis of crop water stress. Initially, the study presents the relationship of relative water content (RWC) with equivalent water thickness (EWT) and soil moisture crop water stress. Evapotranspiration and sun-induced chlorophyll fluorescence are then analyzed in relation to crop water stress using remote sensing. Finally, the study presents various remote-sensing technologies used to detect crop water stress, including optical sensing systems, thermometric sensing systems, land-surface temperature-sensing systems, multispectral (spaceborne and airborne) sensing systems, hyperspectral sensing systems, and the LiDAR sensing system. The study also presents the future prospects of remote-sensing systems in analyzing crop water stress and how they could be further improved.},
DOI = {10.3390/rs13204155}
}



@Article{app11209691,
AUTHOR = {Muhadi, Nur Atirah and Abdullah, Ahmad Fikri and Bejo, Siti Khairunniza and Mahadi, Muhammad Razif and Mijic, Ana},
TITLE = {Deep Learning Semantic Segmentation for Water Level Estimation Using Surveillance Camera},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {9691},
URL = {https://www.mdpi.com/2076-3417/11/20/9691},
ISSN = {2076-3417},
ABSTRACT = {The interest in visual-based surveillance systems, especially in natural disaster applications, such as flood detection and monitoring, has increased due to the blooming of surveillance technology. In this work, semantic segmentation based on convolutional neural networks (CNN) was proposed to identify water regions from the surveillance images. This work presented two well-established deep learning algorithms, DeepLabv3+ and SegNet networks, and evaluated their performances using several evaluation metrics. Overall, both networks attained high accuracy when compared to the measurement data but the DeepLabv3+ network performed better than the SegNet network, achieving over 90% for overall accuracy and IoU metrics, and around 80% for boundary F1 score (BF score), respectively. When predicting new images using both trained networks, the results show that both networks successfully distinguished water regions from the background but the outputs from DeepLabv3+ were more accurate than the results from the SegNet network. Therefore, the DeepLabv3+ network was used for practical application using a set of images captured at five consecutive days in the study area. The segmentation result and water level markers extracted from light detection and ranging (LiDAR) data were overlaid to estimate river water levels and observe the water fluctuation. River water levels were predicted based on the elevation from the predefined markers. The proposed water level framework was evaluated according to Spearman’s rank-order correlation coefficient. The correlation coefficient was 0.91, which indicates a strong relationship between the estimated water level and observed water level. Based on these findings, it can be concluded that the proposed approach has high potential as an alternative monitoring system that offers water region information and water level estimation for flood management and related activities.},
DOI = {10.3390/app11209691}
}



@Article{e23101358,
AUTHOR = {Liu, Yan and Wang, Jingwen and Qiu, Tiantian and Qi, Wenting},
TITLE = {An Adaptive Deblurring Vehicle Detection Method for High-Speed Moving Drones: Resistance to Shake},
JOURNAL = {Entropy},
VOLUME = {23},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {1358},
URL = {https://www.mdpi.com/1099-4300/23/10/1358},
PubMedID = {34682082},
ISSN = {1099-4300},
ABSTRACT = {Vehicle detection is an essential part of an intelligent traffic system, which is an important research field in drone application. Because unmanned aerial vehicles (UAVs) are rarely configured with stable camera platforms, aerial images are easily blurred. There is a challenge for detectors to accurately locate vehicles in blurred images in the target detection process. To improve the detection performance of blurred images, an end-to-end adaptive vehicle detection algorithm (DCNet) for drones is proposed in this article. First, the clarity evaluation module is used to determine adaptively whether the input image is a blurred image using improved information entropy. An improved GAN called Drone-GAN is proposed to enhance the vehicle features of blurred images. Extensive experiments were performed, the results of which show that the proposed method can detect both blurred and clear images well in poor environments (complex illumination and occlusion). The detector proposed achieves larger gains compared with SOTA detectors. The proposed method can enhance the vehicle feature details in blurred images effectively and improve the detection accuracy of blurred aerial images, which shows good performance with regard to resistance to shake.},
DOI = {10.3390/e23101358}
}



@Article{polym13203587,
AUTHOR = {Fotouhi, Sakineh and Khayatzadeh, Saber and Pui, Wei Xia and Damghani, Mahdi and Bodaghi, Mahdi and Fotouhi, Mohamad},
TITLE = {Detection of Barely Visible Impact Damage in Polymeric Laminated Composites Using a Biomimetic Tactile Whisker},
JOURNAL = {Polymers},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {3587},
URL = {https://www.mdpi.com/2073-4360/13/20/3587},
PubMedID = {34685345},
ISSN = {2073-4360},
ABSTRACT = {This is a novel investigation on the possibility of detecting barely visible impact damage (BVID) in composite materials by whisking across the surface via tactile whisker sensors that resemble rats’ whiskers. A series of drop tower low-velocity impact tests were performed on quasi-isotropic composite plates. The plates were made from unidirectional T800 carbon/MTM49-3 epoxy prepregs with the stacking sequence of [45/0/90/−45]4S. Investigating the specimens’ surface by the naked eye does not reveal any significant damage, rather than a small dent on the surface, with no tangible difference in the different impact energy levels. Ultrasonic C-scan observations showed the existence of BVID in all the impact energy levels, with an increasing trend in the damage size by increasing the impact energy level. The collected data from whisker sensors were analyzed using the support vector machine classifier, based on their vibrational properties, to identify the impacted region and classify the impact severity. It was observed that after training for 13 whisker contacts, the BVID severity can be classified with an accuracy of 100%. This is offering a new BVID detection technique, with a high potential for automation and high reliability that can be used as an alternative or combined with available inspection systems.},
DOI = {10.3390/polym13203587}
}



@Article{jimaging7100217,
AUTHOR = {Nguyen, Tran Xuan Bach and Rosser, Kent and Chahl, Javaan},
TITLE = {A Review of Modern Thermal Imaging Sensor Technology and Applications for Autonomous Aerial Navigation},
JOURNAL = {Journal of Imaging},
VOLUME = {7},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {217},
URL = {https://www.mdpi.com/2313-433X/7/10/217},
PubMedID = {34677303},
ISSN = {2313-433X},
ABSTRACT = {Limited navigation capabilities of many current robots and UAVs restricts their applications in GPS denied areas. Large aircraft with complex navigation systems rely on a variety of sensors including radio frequency aids and high performance inertial systems rendering them somewhat resistant to GPS denial. The rapid development of computer vision has seen cameras incorporated into small drones. Vision-based systems, consisting of one or more cameras, could arguably satisfy both size and weight constraints faced by UAVs. A new generation of thermal sensors is available that are lighter, smaller and widely available. Thermal sensors are a solution to enable navigation in difficult environments, including in low-light, dust or smoke. The purpose of this paper is to present a comprehensive literature review of thermal sensors integrated into navigation systems. Furthermore, the physics and characteristics of thermal sensors will also be presented to provide insight into challenges when integrating thermal sensors in place of conventional visual spectrum sensors.},
DOI = {10.3390/jimaging7100217}
}



@Article{app11209744,
AUTHOR = {Li, Jing and Song, Yafei},
TITLE = {Design of Supply Chain System Based on Blockchain Technology},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {9744},
URL = {https://www.mdpi.com/2076-3417/11/20/9744},
ISSN = {2076-3417},
ABSTRACT = {As the interaction between companies becomes more and more complex, the problems of asymmetric information, weak traceability, and low collaboration efficiency in the traditional centralized supply chain are becoming increasingly prominent. To solve these problems, this paper designs a supply chain system based on blockchain. With the help of trade chain and information chain platforms, an overall framework of the supply chain system is constructed. By formulating platform interaction rules, the system information exchange format is standardized to ensure the stability and efficiency of system interaction. Smart contracts are used to manage supply chain system transactions and information interactions to achieve efficient and convenient information sharing, ensuring the security and reliability of supply chain information. The comprehensive performance of the system is evaluated through experiments. Experimental results indicate that while the system realizes the basic functions of the supply chain, it can promote the sharing of information between participants and improve its efficiency.},
DOI = {10.3390/app11209744}
}



@Article{rs13204183,
AUTHOR = {Huang, Zhaoyang and Wang, Feng and You, Hongjian and Hu, Yuxin},
TITLE = {STC-Det: A Slender Target Detector Combining Shadow and Target Information in Optical Satellite Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4183},
URL = {https://www.mdpi.com/2072-4292/13/20/4183},
ISSN = {2072-4292},
ABSTRACT = {Object detection has made great progress. However, due to the unique imaging method of optical satellite remote sensing, the detection of slender targets is still insufficient. Specifically, the perspective of optical satellites is small, and the characteristics of slender targets are severely lost during imaging, resulting in insufficient detection task information; at the same time, the appearance of slender targets in the image is greatly affected by the satellite perspective, which is likely to cause insufficient generalization capabilities of conventional detection models. In response to these two points, we have made some improvements. First, in this paper, we introduce the shadow as auxiliary information to complement the trunk features of the target lost in imaging. Second, to reduce the impact of satellite perspective on imaging, in this paper, we use the characteristic that shadow information is not affected by satellite perspective to design STC-Det. STC-Det treats the shadow and the target as two different types of targets and uses the shadow information to assist the detection, reducing the impact of the satellite perspective on detection. Among them, in order to improve the performance of STC-Det, we propose an automatic matching method (AMM) of shadow and target and a feature fusion method (FFM). Finally, this paper proposes a new method to calculate the heatmaps of detectors, which verifies the effectiveness of the proposed network in a visual way. Experiments show that when the satellite perspective is variable, the precision of STC-Det is increased by 1.7%, and when the satellite perspective is small, the precision of STC-Det is increased by 5.2%.},
DOI = {10.3390/rs13204183}
}



@Article{rs13214198,
AUTHOR = {Bennett, Rohan Mark and Koeva, Mila and Asiama, Kwabena},
TITLE = {Review of Remote Sensing for Land Administration: Origins, Debates, and Selected Cases},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4198},
URL = {https://www.mdpi.com/2072-4292/13/21/4198},
ISSN = {2072-4292},
ABSTRACT = {Conventionally, land administration—incorporating cadastres and land registration—uses ground-based survey methods. This approach can be traced over millennia. The application of photogrammetry and remote sensing is understood to be far more contemporary, only commencing deeper into the 20th century. This paper seeks to counter this view, contending that these methods are far from recent additions to land administration: successful application dates back much earlier, often complementing ground-based methods. Using now more accessible historical works, made available through archive digitisation, this paper presents an enriched and more complete synthesis of the developments of photogrammetric methods and remote sensing applied to the domain of land administration. Developments from early phototopography and aerial surveys, through to analytical photogrammetric methods, the emergence of satellite remote sensing, digital cameras, and latterly lidar surveys, UAVs, and feature extraction are covered. The synthesis illustrates how debates over the benefits of the technique are hardly new. Neither are well-meaning, although oft-flawed, comparative analyses on criteria relating to time, cost, coverage, and quality. Apart from providing this more holistic view and a timely reminder of previous work, this paper brings contemporary practical value in further demonstrating to land administration practitioners that remote sensing for data capture, and subsequent map production, are an entirely legitimate, if not essential, part of the domain. Contemporary arguments that the tools and approaches do not bring adequate accuracy for land administration purposes are easily countered by the weight of evidence. Indeed, these arguments may be considered to undermine the pragmatism inherent to the surveying discipline, traditionally an essential characteristic of the profession. That said, it is left to land administration practitioners to determine the relevance of these methods for any specific country context.},
DOI = {10.3390/rs13214198}
}



@Article{rs13214196,
AUTHOR = {Koay, Hong Vin and Chuah, Joon Huang and Chow, Chee-Onn and Chang, Yang-Lang and Yong, Keh Kok},
TITLE = {YOLO-RTUAV: Towards Real-Time Vehicle Detection through Aerial Images with Low-Cost Edge Devices},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4196},
URL = {https://www.mdpi.com/2072-4292/13/21/4196},
ISSN = {2072-4292},
ABSTRACT = {Object detection in aerial images has been an active research area thanks to the vast availability of unmanned aerial vehicles (UAVs). Along with the increase of computational power, deep learning algorithms are commonly used for object detection tasks. However, aerial images have large variations, and the object sizes are usually small, rendering lower detection accuracy. Besides, real-time inferencing on low-cost edge devices remains an open-ended question. In this work, we explored the usage of state-of-the-art deep learning object detection on low-cost edge hardware. We propose YOLO-RTUAV, an improved version of YOLOv4-Tiny, as the solution. We benchmarked our proposed models with various state-of-the-art models on the VAID and COWC datasets. Our proposed model can achieve higher mean average precision (mAP) and frames per second (FPS) than other state-of-the-art tiny YOLO models, especially on a low-cost edge device such as the Jetson Nano 2 GB. It was observed that the Jetson Nano 2 GB can achieve up to 12.8 FPS with a model size of only 5.5 MB.},
DOI = {10.3390/rs13214196}
}



@Article{app11219840,
AUTHOR = {Zhao, Wenchao and Han, Shuai and Chen, Yapeng and Gao, Yusheng and Liu, Manjie},
TITLE = {Development of Quick Digital Field Recording and Mapping Method of Geological Objects for Hydraulic Engineering},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {9840},
URL = {https://www.mdpi.com/2076-3417/11/21/9840},
ISSN = {2076-3417},
ABSTRACT = {During the fieldwork of hydraulic engineering, practical engineers normally document geological information manually. Although there are some GIS-based digital tools for geology, they are not perfectly applicable to hydraulic engineering. As a result, the current work mode is ineffective, unmanageable, error-prone, and not conducive to subsequent analysis. To address this problem, we developed a digital tool which enables geological recording and quick modeling based on 3D real scenes in the field of hydropower projects. There are three modules in the surface tool: object recording, image interpretation, and field analysis. The object recording module is to mark geological points (e.g., drills and shafts), lines (e.g., faults, stratigraphic boundaries), and surfaces (e.g., slope and stocking yard) on a 3D scene and then store them in the database. The image interpretation is to interpret the 2D information in images to 3D models loaded in 3D software for further studies, such as GOCAD. The field analysis includes surface fitting, stability analysis of blocks, occurrences calculating, rock recognition, and 69/sketching. The tool is helpful for recording data, drawing geological boundaries, and building a preliminary model in the geological survey.},
DOI = {10.3390/app11219840}
}



@Article{a14110302,
AUTHOR = {Atli, İbrahim and Ozturk, Metin and Valastro, Gianluca C. and Asghar, Muhammad Zeeshan},
TITLE = {Multi-Objective UAV Positioning Mechanism for Sustainable Wireless Connectivity in Environments with Forbidden Flying Zones},
JOURNAL = {Algorithms},
VOLUME = {14},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {302},
URL = {https://www.mdpi.com/1999-4893/14/11/302},
ISSN = {1999-4893},
ABSTRACT = {A communication system based on unmanned aerial vehicles (UAVs) is a viable alternative for meeting the coverage and capacity needs of future wireless networks. However, because of the limitations of UAV-enabled communications in terms of coverage, energy consumption, and flying laws, the number of studies focused on the sustainability element of UAV-assisted networking in the literature was limited thus far. We present a solution to this problem in this study; specifically, we design a Q-learning-based UAV placement strategy for long-term wireless connectivity while taking into account major constraints such as altitude regulations, nonflight zones, and transmit power. The goal is to determine the best location for the UAV base station (BS) while reducing energy consumption and increasing the number of users covered. Furthermore, a weighting method is devised, allowing energy usage and the number of users served to be prioritized based on network/battery circumstances. The suggested Q-learning-based solution is contrasted to the standard k-means clustering method, in which the UAV BS is positioned at the centroid location with the shortest cumulative distance between it and the users. The results demonstrate that the proposed solution outperforms the baseline k-means clustering-based method in terms of the number of users covered while achieving the desired minimization of the energy consumption.},
DOI = {10.3390/a14110302}
}



@Article{rs13214235,
AUTHOR = {Jia, Jianxin and Sun, Haibin and Jiang, Changhui and Karila, Kirsi and Karjalainen, Mika and Ahokas, Eero and Khoramshahi, Ehsan and Hu, Peilun and Chen, Chen and Xue, Tianru and Wang, Tinghuai and Chen, Yuwei and Hyyppä, Juha},
TITLE = {Review on Active and Passive Remote Sensing Techniques for Road Extraction},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4235},
URL = {https://www.mdpi.com/2072-4292/13/21/4235},
ISSN = {2072-4292},
ABSTRACT = {Digital maps of road networks are a vital part of digital cities and intelligent transportation. In this paper, we provide a comprehensive review on road extraction based on various remote sensing data sources, including high-resolution images, hyperspectral images, synthetic aperture radar images, and light detection and ranging. This review is divided into three parts. Part 1 provides an overview of the existing data acquisition techniques for road extraction, including data acquisition methods, typical sensors, application status, and prospects. Part 2 underlines the main road extraction methods based on four data sources. In this section, road extraction methods based on different data sources are described and analysed in detail. Part 3 presents the combined application of multisource data for road extraction. Evidently, different data acquisition techniques have unique advantages, and the combination of multiple sources can improve the accuracy of road extraction. The main aim of this review is to provide a comprehensive reference for research on existing road extraction technologies.},
DOI = {10.3390/rs13214235}
}



@Article{rs13214278,
AUTHOR = {Zhang, Ying and Chi, Zhaohui and Hui, Fengming and Li, Teng and Liu, Xuying and Zhang, Baogang and Cheng, Xiao and Chen, Zhuoqi},
TITLE = {Accuracy Evaluation on Geolocation of the Chinese First Polar Microsatellite (Ice Pathfinder) Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4278},
URL = {https://www.mdpi.com/2072-4292/13/21/4278},
ISSN = {2072-4292},
ABSTRACT = {Ice Pathfinder (Code: BNU-1), launched on 12 September 2019, is the first Chinese polar observation microsatellite. Its main payload is a wide-view camera with a ground resolution of 74 m at the subsatellite point and a scanning width of 744 km. BNU-1 takes into account the balance between spatial resolution and revisit frequency, providing observations with finer spatial resolution than Terra/Aqua MODIS data and more frequent revisits than Landsat-8 OLI and Sentinel-2 MSI. It is a valuable supplement for polar observations. Geolocation is an essential step in satellite image processing. This study aims to geolocate BNU-1 images; this includes two steps. For the first step, a geometric calibration model is applied to transform the image coordinates to geographic coordinates. The images calibrated by the geometric model are the Level1A (L1A) product. Due to the inaccuracy of satellite attitude and orbit parameters, the geometric calibration model also exhibits errors, resulting in geolocation errors in the BNU-1 L1A product. Then, a geometric correction method is applied as the second step to find the control points (CPs) extracted from the BNU-1 L1A product and the corresponding MODIS images. These CPs are used to estimate and correct geolocation errors. The BNU-1 L1A product corrected by the geometric correction method is processed to the Level1B (L1B) product. Although the geometric correction method based on CPs has been widely used to correct the geolocation errors of visible remote sensing images, it is difficult to extract enough CPs from polar images due to the high reflectance of snow and ice. In this study, the geometric correction employs an image division and an image enhancement method to extract more CPs from the BNU-1 L1A products. The results indicate that the number of CPs extracted by the division and image enhancements increases by about 30% to 182%. Twenty-eight images of Antarctica and fifteen images of Arctic regions were evaluated to assess the performance of the geometric correction. The average geolocation error was reduced from 10 km to ~300 m. In general, this study presents the geolocation method, which could serve as a reference for the geolocation of other visible remote sensing images for polar observations.},
DOI = {10.3390/rs13214278}
}



@Article{rs13214282,
AUTHOR = {Yu, Jin-Woo and Yoon, Young-Woong and Baek, Won-Kyung and Jung, Hyung-Sup},
TITLE = {Forest Vertical Structure Mapping Using Two-Seasonal Optic Images and LiDAR DSM Acquired from UAV Platform through Random Forest, XGBoost, and Support Vector Machine Approaches},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4282},
URL = {https://www.mdpi.com/2072-4292/13/21/4282},
ISSN = {2072-4292},
ABSTRACT = {Research on the forest structure classification is essential, as it plays an important role in assessing the vitality and diversity of vegetation. However, classifying forest structure involves in situ surveying, which requires considerable time and money, and cannot be conducted directly in some instances; also, the update cycle of the classification data is very late. To overcome these drawbacks, feasibility studies on mapping the forest vertical structure from aerial images using machine learning techniques were conducted. In this study, we investigated (1) the performance improvement of the forest structure classification, using a high-resolution LiDAR-derived digital surface model (DSM) acquired from an unmanned aerial vehicle (UAV) platform and (2) the performance comparison of results obtained from the single-seasonal and two-seasonal data, using random forest (RF), extreme gradient boosting (XGBoost), and support vector machine (SVM). For the performance comparison, the UAV optic and LiDAR data were divided into three cases: (1) only used autumn data, (2) only used winter data, and (3) used both autumn and winter data. From the results, the best model was XGBoost, and the F1 scores achieved using this method were approximately 0.92 in the autumn and winter cases. A remarkable improvement was achieved when both two-seasonal images were used. The F1 score improved by 35.3% from 0.68 to 0.92. This implies that (1) the seasonal variation in the forest vertical structure can be more important than the spatial resolution, and (2) the classification performance achieved from the two-seasonal UAV optic images and LiDAR-derived DSMs can reach 0.9 with the application of an optimal machine learning approach.},
DOI = {10.3390/rs13214282}
}



@Article{en14217024,
AUTHOR = {Li, Xiaokun and Lu, Junwei and Stegen, Sascha},
TITLE = {Magnetic Coupler Optimization for Inductive Power Transfer System of Unmanned Aerial Vehicles},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7024},
URL = {https://www.mdpi.com/1996-1073/14/21/7024},
ISSN = {1996-1073},
ABSTRACT = {Unmanned aerial vehicles (UAVs) have been widely used in military and civilian applications. However, the insufficient cruising range restricts the development of UAVs due to the limitation of their battery. Inductive power transfer (IPT) is an effective way to charge the battery and solve this problem. Magnetic coupler is a key component of the IPT system, which greatly affects the power transfer and efficiency of the IPT. This paper proposes a new magnetic coupler with vertical spiral coils and ferrite PQI cores for the IPT system of UAVs, which can enhance the magnetic coupling and improve the performance of the IPT system. Finite element simulations are used to investigate the magnetic field distribution and coupling capability of the proposed magnetic coupler. In addition, an experimental platform is built to prove the validity of the IPT system using the proposed magnetic coupler. The results show that the coupling coefficient can reach 0.98, and the system transfer efficiency is 89.27% with an output power of 93 W. The IPT system also has a perfect misalignment tolerance and can achieve a stable output power.},
DOI = {10.3390/en14217024}
}



@Article{rs13214312,
AUTHOR = {Zhao, Genping and Zhang, Weiguang and Peng, Yeping and Wu, Heng and Wang, Zhuowei and Cheng, Lianglun},
TITLE = {PEMCNet: An Efficient Multi-Scale Point Feature Fusion Network for 3D LiDAR Point Cloud Classification},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4312},
URL = {https://www.mdpi.com/2072-4292/13/21/4312},
ISSN = {2072-4292},
ABSTRACT = {Point cloud classification plays a significant role in Light Detection and Ranging (LiDAR) applications. However, most available multi-scale feature learning networks for large-scale 3D LiDAR point cloud classification tasks are time-consuming. In this paper, an efficient deep neural architecture denoted as Point Expanded Multi-scale Convolutional Network (PEMCNet) is developed to accurately classify the 3D LiDAR point cloud. Different from traditional networks for point cloud processing, PEMCNet includes successive Point Expanded Grouping (PEG) units and Absolute and Relative Spatial Embedding (ARSE) units for representative point feature learning. The PEG unit enables us to progressively increase the receptive field for each observed point and aggregate the feature of a point cloud at different scales but without increasing computation. The ARSE unit following the PEG unit furthermore realizes representative encoding of points relationship, which effectively preserves the geometric details between points. We evaluate our method on both public datasets (the Urban Semantic 3D (US3D) dataset and Semantic3D benchmark dataset) and our new collected Unmanned Aerial Vehicle (UAV) based LiDAR point cloud data of the campus of Guangdong University of Technology. In comparison with four available state-of-the-art methods, our methods ranked first place regarding both efficiency and accuracy. It was observed on the public datasets that with a 2% increase in classification accuracy, over 26% improvement of efficiency was achieved at the same time compared to the second efficient method. Its potential value is also tested on the newly collected point cloud data with over 91% of classification accuracy and 154 ms of processing time.},
DOI = {10.3390/rs13214312}
}



@Article{jmse9111189,
AUTHOR = {Hu, Kai and Chen, Xu and Xia, Qingfeng and Jin, Junlan and Weng, Liguo},
TITLE = {A Control Algorithm for Sea&ndash;Air Cooperative Observation Tasks Based on a Data-Driven Algorithm},
JOURNAL = {Journal of Marine Science and Engineering},
VOLUME = {9},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {1189},
URL = {https://www.mdpi.com/2077-1312/9/11/1189},
ISSN = {2077-1312},
ABSTRACT = {There is tremendous demand for marine environmental observation, which requires the development of a multi-agent cooperative observation algorithm to guide Unmanned Surface Vehicles (USVs) and Unmanned Aerial Vehicles (UAVs) to observe isotherm data of the mesoscale vortex. The task include two steps: firstly, USVs search out the isotherm, navigate independently along the isotherm, and collect marine data; secondly, a UAV takes off, and in its one round trip, the UAV and USVs jointly perform the task of the UAV reading the observation data from USVs. In this paper, aiming at the first problem of the USV following the isotherm in an unknown environment, a data-driven Deep Deterministic Policy Gradient (DDPG) control algorithm is designed that allows USVs to navigate independently along isotherms in unknown environments. In addition, a hybrid cooperative control algorithm based on a multi-agent DDPG is adopted to solve the second problem, which enables USVs and a UAV to complete data reading tasks with the shortest flight distance of the UAV. The experimental simulation results show that the trained system can complete this tas, with good stability and accuracy.},
DOI = {10.3390/jmse9111189}
}



@Article{make3040043,
AUTHOR = {Xiang, Xuanchen and Foo, Simon and Zang, Huanyu},
TITLE = {Recent Advances in Deep Reinforcement Learning Applications for Solving Partially Observable Markov Decision Processes (POMDP) Problems Part 2—Applications in Transportation, Industries, Communications and Networking and More Topics},
JOURNAL = {Machine Learning and Knowledge Extraction},
VOLUME = {3},
YEAR = {2021},
NUMBER = {4},
PAGES = {863--878},
URL = {https://www.mdpi.com/2504-4990/3/4/43},
ISSN = {2504-4990},
ABSTRACT = {The two-part series of papers provides a survey on recent advances in Deep Reinforcement Learning (DRL) for solving partially observable Markov decision processes (POMDP) problems. Reinforcement Learning (RL) is an approach to simulate the human’s natural learning process, whose key is to let the agent learn by interacting with the stochastic environment. The fact that the agent has limited access to the information of the environment enables AI to be applied efficiently in most fields that require self-learning. It’s essential to have an organized investigation—we can make good comparisons and choose the best structures or algorithms when applying DRL in various applications. The first part of the overview introduces Markov Decision Processes (MDP) problems and Reinforcement Learning and applications of DRL for solving POMDP problems in games, robotics, and natural language processing. In part two, we continue to introduce applications in transportation, industries, communications and networking, etc. and discuss the limitations of DRL.},
DOI = {10.3390/make3040043}
}



@Article{drones5040126,
AUTHOR = {Rominger, Kody R. and Meyer, Susan E.},
TITLE = {Drones, Deep Learning, and Endangered Plants: A Method for Population-Level Census Using Image Analysis},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {126},
URL = {https://www.mdpi.com/2504-446X/5/4/126},
ISSN = {2504-446X},
ABSTRACT = {A census of endangered plant populations is critical to determining their size, spatial distribution, and geographical extent. Traditional, on-the-ground methods for collecting census data are labor-intensive, time-consuming, and expensive. Use of drone imagery coupled with application of rapidly advancing deep learning technology could greatly reduce the effort and cost of collecting and analyzing population-level data across relatively large areas. We used a customization of the YOLOv5 object detection model to identify and count individual dwarf bear poppy (Arctomecon humilis) plants in drone imagery obtained at 40 m altitude. We compared human-based and model-based detection at 40 m on n = 11 test plots for two areas that differed in image quality. The model out-performed human visual poppy detection for precision and recall, and was 1100× faster at inference/evaluation on the test plots. Model inference precision was 0.83, and recall was 0.74, while human evaluation resulted in precision of 0.67, and recall of 0.71. Both model and human performance were better in the area with higher-quality imagery, suggesting that image quality is a primary factor limiting model performance. Evaluation of drone-based census imagery from the 255 ha Webb Hill population with our customized YOLOv5 model was completed in &lt;3 h and provided a reasonable estimate of population size (7414 poppies) with minimal investment of on-the-ground resources.},
DOI = {10.3390/drones5040126}
}



@Article{rs13214333,
AUTHOR = {Schulze-Brüninghoff, Damian and Wachendorf, Michael and Astor, Thomas},
TITLE = {Potentials and Limitations of WorldView-3 Data for the Detection of Invasive Lupinus polyphyllus Lindl. in Semi-Natural Grasslands},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4333},
URL = {https://www.mdpi.com/2072-4292/13/21/4333},
ISSN = {2072-4292},
ABSTRACT = {Semi-natural grasslands contribute highly to biodiversity and other ecosystem services, but they are at risk by the spread of invasive plant species, which alter their habitat structure. Large area grassland monitoring can be a powerful tool to manage invaded ecosystems. Therefore, WorldView-3 multispectral sensor data was utilized to train multiple machine learning algorithms in an automatic machine learning workflow called ‘H2O AutoML’ to detect L. polyphyllus in a nature protection grassland ecosystem. Different degree of L. polyphyllus cover was collected on 3 × 3 m2 reference plots, and multispectral bands, indices, and texture features were used in a feature selection process to identify the most promising classification model and machine learning algorithm based on mean per class error, log loss, and AUC metrics. The best performance was achieved with a binary classification of lupin-free vs. fully invaded 3 × 3 m2 plot classification with a set of 7 features out of 763. The findings reveal that L. polyphyllus detection from WorldView-3 sensor data is limited to large dominant spots and not recommendable for lower plant coverage, especially single plant detection. Further research is needed to clarify if different phenological stages of L. polyphyllus as well as time series increase classification performance.},
DOI = {10.3390/rs13214333}
}



@Article{rs13214347,
AUTHOR = {Khan, Rabia Munsaf and Salehi, Bahram and Mahdianpari, Masoud and Mohammadimanesh, Fariba and Mountrakis, Giorgos and Quackenbush, Lindi J.},
TITLE = {A Meta-Analysis on Harmful Algal Bloom (HAB) Detection and Monitoring: A Remote Sensing Perspective},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4347},
URL = {https://www.mdpi.com/2072-4292/13/21/4347},
ISSN = {2072-4292},
ABSTRACT = {Algae serves as a food source for a wide range of aquatic species; however, a high concentration of inorganic nutrients under favorable conditions can result in the development of harmful algal blooms (HABs). Many studies have addressed HAB detection and monitoring; however, no global scale meta-analysis has specifically explored remote sensing-based HAB monitoring. Therefore, this manuscript elucidates and visualizes spatiotemporal trends in HAB detection and monitoring using remote sensing methods and discusses future insights through a meta-analysis of 420 journal articles. The results indicate an increase in the quantity of published articles which have facilitated the analysis of sensors, software, and HAB proxy estimation methods. The comparison across multiple studies highlighted the need for a standardized reporting method for HAB proxy estimation. Research gaps include: (1) atmospheric correction methods, particularly for turbid waters, (2) the use of analytical-based models, (3) the application of machine learning algorithms, (4) the generation of harmonized virtual constellation and data fusion for increased spatial and temporal resolutions, and (5) the use of cloud-computing platforms for large scale HAB detection and monitoring. The planned hyperspectral satellites will aid in filling these gaps to some extent. Overall, this review provides a snapshot of spatiotemporal trends in HAB monitoring to assist in decision making for future studies.},
DOI = {10.3390/rs13214347}
}



@Article{app112110139,
AUTHOR = {Aguilar, Fernando J. and Nemmaoui, Abderrahim and Aguilar, Manuel A. and Peñalver, Alberto},
TITLE = {Building Tree Allometry Relationships Based on TLS Point Clouds and Machine Learning Regression},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {10139},
URL = {https://www.mdpi.com/2076-3417/11/21/10139},
ISSN = {2076-3417},
ABSTRACT = {Most of the allometric models used to estimate tree aboveground biomass rely on tree diameter at breast height (DBH). However, it is difficult to measure DBH from airborne remote sensors, and is common to draw upon traditional least squares linear regression models to relate DBH with dendrometric variables measured from airborne sensors, such as tree height (H) and crown diameter (CD). This study explores the usefulness of ensemble-type supervised machine learning regression algorithms, such as random forest regression (RFR), categorical boosting (CatBoost), gradient boosting (GBoost), or AdaBoost regression (AdaBoost), as an alternative to linear regression (LR) for modelling the allometric relationships DBH = Φ(H) and DBH = Ψ(H, CD). The original dataset was made up of 2272 teak trees (Tectona grandis Linn. F.) belonging to three different plantations located in Ecuador. All teak trees were digitally reconstructed from terrestrial laser scanning point clouds. The results showed that allometric models involving both H and CD to estimate DBH performed better than those based solely on H. Furthermore, boosting machine learning regression algorithms (CatBoost and GBoost) outperformed RFR (bagging) and LR (traditional linear regression) models, both in terms of goodness-of-fit (R2) and stability (variations in training and testing samples).},
DOI = {10.3390/app112110139}
}



@Article{drones5040127,
AUTHOR = {Raza, Wamiq and Osman, Anas and Ferrini, Francesco and Natale, Francesco De},
TITLE = {Energy-Efficient Inference on the Edge Exploiting TinyML Capabilities for UAVs},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {127},
URL = {https://www.mdpi.com/2504-446X/5/4/127},
ISSN = {2504-446X},
ABSTRACT = {In recent years, the proliferation of unmanned aerial vehicles (UAVs) has increased dramatically. UAVs can accomplish complex or dangerous tasks in a reliable and cost-effective way but are still limited by power consumption problems, which pose serious constraints on the flight duration and completion of energy-demanding tasks. The possibility of providing UAVs with advanced decision-making capabilities in an energy-effective way would be extremely beneficial. In this paper, we propose a practical solution to this problem that exploits deep learning on the edge. The developed system integrates an OpenMV microcontroller into a DJI Tello Micro Aerial Vehicle (MAV). The microcontroller hosts a set of machine learning-enabled inference tools that cooperate to control the navigation of the drone and complete a given mission objective. The goal of this approach is to leverage the new opportunistic features of TinyML through OpenMV including offline inference, low latency, energy efficiency, and data security. The approach is successfully validated on a practical application consisting of the onboard detection of people wearing protection masks in a crowded environment.},
DOI = {10.3390/drones5040127}
}



@Article{drones5040128,
AUTHOR = {Gopi, Sudheesh Puthenveettil and Magarini, Maurizio and Alsamhi, Saeed Hamood and Shvetsov, Alexey V.},
TITLE = {Machine Learning-Assisted Adaptive Modulation for Optimized Drone-User Communication in B5G},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {128},
URL = {https://www.mdpi.com/2504-446X/5/4/128},
ISSN = {2504-446X},
ABSTRACT = {The fundamental issue for Beyond fifth Generation (B5G) is providing a pervasive connection to heterogeneous and various devices in smart environments. Therefore, Drones play a vital role in the B5G, allowing for wireless broadcast and high-speed communications. In addition, the drone offers several advantages compared to fixed terrestrial communications, including flexible deployment, robust Line of Sight (LoS) connections, and more design degrees of freedom due to controlled mobility. Drones can provide reliable and high data rate connectivity to users irrespective of their location. However, atmospheric disturbances impact the signal quality between drones and users and degrade the system performance. Considering practical implementation, the location of drones makes the drone–user communication susceptible to several environmental disturbances. In this paper, we evaluate the performance of drone-user connectivity during atmospheric disturbances. Further, a Machine Learning (ML)-assisted algorithm is proposed to adapt to a modulation technique that offers optimal performance during atmospheric disturbances. The results show that, with the algorithm, the system switches to a lower order modulation scheme during higher rain rate and provides reliable communication with optimized data rate and error performance.},
DOI = {10.3390/drones5040128}
}



@Article{su132112005,
AUTHOR = {Csákvári, Edina and Halassy, Melinda and Enyedi, Attila and Gyulai, Ferenc and Berke, József},
TITLE = {Is Einkorn Wheat (Triticum monococcum L.) a Better Choice than Winter Wheat (Triticum aestivum L.)? Wheat Quality Estimation for Sustainable Agriculture Using Vision-Based Digital Image Analysis},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {12005},
URL = {https://www.mdpi.com/2071-1050/13/21/12005},
ISSN = {2071-1050},
ABSTRACT = {Einkorn wheat (Triticum monococcum L. ssp. monococcum) plays an increasingly important role in agriculture, promoted by organic farming. Although the number of comparative studies about modern and ancient types of wheats is increasing, there are still some knowledge gaps about the nutritional and health benefit differences between ancient and modern bread wheats. The aim of the present study was to compare ancient, traditional and modern wheat cultivars—including a field study and a laboratory stress experiment using vision-based digital image analysis—and to assess the feasibility of imaging techniques. Our study shows that modern winter wheat had better yield and grain quality compared to einkorn wheats, but the latter were not far behind; thus the cultivation of various species could provide a diverse and sustainable agriculture which contributes to higher agrobiodiversity. The results also demonstrate that digital image analysis could be a viable alternate method for the real-time estimation of aboveground biomass and for predicting yield and grain quality parameters. Digital area outperformed other digital variables in biomass prediction in relation to drought stress, but height and Feret’s diameter better correlated with yield and grain quality parameters. Based on these results we suggest that the combination of various vision-based methods could improve the performance estimation of modern and ancient types of wheat in a non-destructive and real-time manner.},
DOI = {10.3390/su132112005}
}



@Article{rs13214370,
AUTHOR = {Lan, Yubin and Huang, Kanghua and Yang, Chang and Lei, Luocheng and Ye, Jiahang and Zhang, Jianling and Zeng, Wen and Zhang, Yali and Deng, Jizhong},
TITLE = {Real-Time Identification of Rice Weeds by UAV Low-Altitude Remote Sensing Based on Improved Semantic Segmentation Model},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4370},
URL = {https://www.mdpi.com/2072-4292/13/21/4370},
ISSN = {2072-4292},
ABSTRACT = {Real-time analysis of UAV low-altitude remote sensing images at airborne terminals facilitates the timely monitoring of weeds in the farmland. Aiming at the real-time identification of rice weeds by UAV low-altitude remote sensing, two improved identification models, MobileNetV2-UNet and FFB-BiSeNetV2, were proposed based on the semantic segmentation models U-Net and BiSeNetV2, respectively. The MobileNetV2-UNet model focuses on reducing the amount of calculation of the original model parameters, and the FFB-BiSeNetV2 model focuses on improving the segmentation accuracy of the original model. In this study, we first tested and compared the segmentation accuracy and operating efficiency of the models before and after the improvement on the computer platform, and then transplanted the improved models to the embedded hardware platform Jetson AGX Xavier, and used TensorRT to optimize the model structure to improve the inference speed. Finally, the real-time segmentation effect of the two improved models on rice weeds was further verified through the collected low-altitude remote sensing video data. The results show that on the computer platform, the MobileNetV2-UNet model reduced the amount of network parameters, model size, and floating point calculations by 89.12%, 86.16%, and 92.6%, and the inference speed also increased by 2.77 times, when compared with the U-Net model. The FFB-BiSeNetV2 model improved the segmentation accuracy compared with the BiSeNetV2 model and achieved the highest pixel accuracy and mean Intersection over Union ratio of 93.09% and 80.28%. On the embedded hardware platform, the optimized MobileNetV2-UNet model and FFB-BiSeNetV2 model inferred 45.05 FPS and 40.16 FPS for a single image under the weight accuracy of FP16, respectively, both meeting the performance requirements of real-time identification. The two methods proposed in this study realize the real-time identification of rice weeds under low-altitude remote sensing by UAV, which provide a reference for the subsequent integrated operation of plant protection drones in real-time rice weed identification and precision spraying.},
DOI = {10.3390/rs13214370}
}



@Article{rs13214377,
AUTHOR = {Sun, Long and Chen, Jie and Feng, Dazheng and Xing, Mengdao},
TITLE = {Parallel Ensemble Deep Learning for Real-Time Remote Sensing Video Multi-Target Detection},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4377},
URL = {https://www.mdpi.com/2072-4292/13/21/4377},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle (UAV) is one of the main means of information warfare, such as in battlefield cruises, reconnaissance, and military strikes. Rapid detection and accurate recognition of key targets in UAV images are the basis of subsequent military tasks. The UAV image has characteristics of high resolution and small target size, and in practical application, the detection speed is often required to be fast. Existing algorithms are not able to achieve an effective trade-off between detection accuracy and speed. Therefore, this paper proposes a parallel ensemble deep learning framework for unmanned aerial vehicle video multi-target detection, which is a global and local joint detection strategy. It combines a deep learning target detection algorithm with template matching to make full use of image information. It also integrates multi-process and multi-threading mechanisms to speed up processing. Experiments show that the system has high detection accuracy for targets with focal lengths varying from one to ten times. At the same time, the real-time and stable display of detection results is realized by aiming at the moving UAV video image.},
DOI = {10.3390/rs13214377}
}



@Article{rs13214387,
AUTHOR = {Liu, Jia and Xiang, Jianjian and Jin, Yongjun and Liu, Renhua and Yan, Jining and Wang, Lizhe},
TITLE = {Boost Precision Agriculture with Unmanned Aerial Vehicle Remote Sensing and Edge Intelligence: A Survey},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4387},
URL = {https://www.mdpi.com/2072-4292/13/21/4387},
ISSN = {2072-4292},
ABSTRACT = {In recent years unmanned aerial vehicles (UAVs) have emerged as a popular and cost-effective technology to capture high spatial and temporal resolution remote sensing (RS) images for a wide range of precision agriculture applications, which can help reduce costs and environmental impacts by providing detailed agricultural information to optimize field practices. Furthermore, deep learning (DL) has been successfully applied in agricultural applications such as weed detection, crop pest and disease detection, etc. as an intelligent tool. However, most DL-based methods place high computation, memory and network demands on resources. Cloud computing can increase processing efficiency with high scalability and low cost, but results in high latency and great pressure on the network bandwidth. The emerging of edge intelligence, although still in the early stages, provides a promising solution for artificial intelligence (AI) applications on intelligent edge devices at the edge of the network close to data sources. These devices are with built-in processors enabling onboard analytics or AI (e.g., UAVs and Internet of Things gateways). Therefore, in this paper, a comprehensive survey on the latest developments of precision agriculture with UAV RS and edge intelligence is conducted for the first time. The major insights observed are as follows: (a) in terms of UAV systems, small or light, fixed-wing or industrial rotor-wing UAVs are widely used in precision agriculture; (b) sensors on UAVs can provide multi-source datasets, and there are only a few public UAV dataset for intelligent precision agriculture, mainly from RGB sensors and a few from multispectral and hyperspectral sensors; (c) DL-based UAV RS methods can be categorized into classification, object detection and segmentation tasks, and convolutional neural network and recurrent neural network are the mostly common used network architectures; (d) cloud computing is a common solution to UAV RS data processing, while edge computing brings the computing close to data sources; (e) edge intelligence is the convergence of artificial intelligence and edge computing, in which model compression especially parameter pruning and quantization is the most important and widely used technique at present, and typical edge resources include central processing units, graphics processing units and field programmable gate arrays.},
DOI = {10.3390/rs13214387}
}



@Article{f12111508,
AUTHOR = {Stolle, Lorena and Corte, Ana Paula Dalla and Sanquetta, Carlos Roberto and Behling, Alexandre and Hentz, Ângela Maria Klein and Eisfeld, Rozane de Loyola},
TITLE = {Predicting Stand Volume by Number of Trees Automatically Detected in UAV Images: An Alternative Method for Forest Inventory},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {1508},
URL = {https://www.mdpi.com/1999-4907/12/11/1508},
ISSN = {1999-4907},
ABSTRACT = {In this study, we estimate the forest stock volume by multiplying the number of trees detected remotely by the estimated mean individual volume of the population (individual approach). A comparison was made with the conventional inventory method (area approach), which included 100 simulations of a simple random sampling process and a Bootstrap resampling. The study area included three stands: stand 1, 16-year-old pine; stand 2, 7-year-old pine; and stand 3, 5-year-old eucalyptus. A census was carried out in each stand for the variables diameter and total height. Individual volume was estimated by a ratio estimator, and the sum of all volumes was considered as the total parametric volume. The area approach presented parametric values within the confidence interval for 91%, 94%, and 98% of the simulations for the three stands, respectively. The mean relative errors for the area approach were −3.5% for stand 1, 0.3% for stand 2, and −0.9% for stand 3. The errors in stands 1 and 3 were associated with the spatial distribution of the volume. The individual approach proved to be efficient for all stands, and their respective parametric values were within the confidence interval. The relative errors were 1% for stand 1, −0.7% for stand 2, and 1.8% for stand 3. For stand 1 and 3, this approach yielded better results than the mean values obtained by the area approach simulations (Bootstrap resampling). Future research should evaluate other remote sources of data and other forest conditions.},
DOI = {10.3390/f12111508}
}




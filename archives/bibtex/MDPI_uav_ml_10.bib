
@Article{s19081898,
AUTHOR = {Chen, Jun and Xu, Quan and Luo, Linbo and Wang, Yongtao and Wang, Shuchun},
TITLE = {A Robust Method for Automatic Panoramic UAV Image Mosaic},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {1898},
URL = {https://www.mdpi.com/1424-8220/19/8/1898},
ISSN = {1424-8220},
ABSTRACT = {This paper introduces a robust method for panoramic unmanned aerial vehicle (UAV) image mosaic. In the traditional automatic panoramic image stitching method (Autostitch), it assumes that the camera rotates about its optical centre and the group of transformations the source images may undergo is a special group of homographies. It is rare to get such ideal data in reality. In particular, remote sensing images obtained by UAV do not satisfy such an ideal situation, where the images may not be on a plane yet and even may suffer from nonrigid changes, leading to poor mosaic results. To overcome the above mentioned challenges, in this paper a nonrigid matching algorithm is introduced to the mosaic system to generate accurate feature matching on remote sensing images. We also propose a new strategy for bundle adjustment to make the mosaic system suitable for the UAV image panoramic mosaic effect. Experimental results show that our method outperforms the traditional method and some of the latest methods in terms of visual effect.},
DOI = {10.3390/s19081898}
}



@Article{info10040149,
AUTHOR = {Mylonas, Phivos and Voutos, Yorghos and Sofou, Anastasia},
TITLE = {A Collaborative Pilot Platform for Data Annotation and Enrichment in Viticulture},
JOURNAL = {Information},
VOLUME = {10},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {149},
URL = {https://www.mdpi.com/2078-2489/10/4/149},
ISSN = {2078-2489},
ABSTRACT = {It took some time indeed, but the research evolution and transformations that occurred in the smart agriculture field over the recent years tend to constitute the latter as the main topic of interest in the so-called Internet of Things (IoT) domain. Undoubtedly, our era is characterized by the mass production of huge amounts of data, information and content deriving from many different sources, mostly IoT devices and sensors, but also from environmentalists, agronomists, winemakers, or plain farmers and interested stakeholders themselves. Being an emerging field, only a small part of this rich content has been aggregated so far in digital platforms that serve as cross-domain hubs. The latter offer typically limited usability and accessibility of the actual content itself due to problems dealing with insufficient data and metadata availability, as well as their quality. Over our recent involvement within a precision viticulture environment and in an effort to make the notion of smart agriculture in the winery domain more accessible to and reusable from the general public, we introduce herein the model of an aggregation platform that provides enhanced services and enables human-computer collaboration for agricultural data annotations and enrichment. In principle, the proposed architecture goes beyond existing digital content aggregation platforms by advancing digital data through the combination of artificial intelligence automation and creative user engagement, thus facilitating its accessibility, visibility, and re-use. In particular, by using image and free text analysis methodologies for automatic metadata enrichment, in accordance to the human expertise for enrichment, it offers a cornerstone for future researchers focusing on improving the quality of digital agricultural information analysis and its presentation, thus establishing new ways for its efficient exploitation in a larger scale with benefits both for the agricultural and the consumer domains.},
DOI = {10.3390/info10040149}
}



@Article{rs11080967,
AUTHOR = {Wang, Sijia and Chen, Yunhao and Wang, Mingguo and Zhao, Yifei and Li, Jing},
TITLE = {SPA-Based Methods for the Quantitative Estimation of the Soil Salt Content in Saline-Alkali Land from Field Spectroscopy Data: A Case Study from the Yellow River Irrigation Regions},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {967},
URL = {https://www.mdpi.com/2072-4292/11/8/967},
ISSN = {2072-4292},
ABSTRACT = {The problem of soil salinization has always been a global problem involving resource, environmental, and ecological issues, and is closely related to the sustainable development of the social economy. Remote sensing provides an effective technical means for soil salinity identification and quantification research. This study focused on the estimation of the soil salt content in saline-alkali soils and applied the Successive Projections Algorithm (SPA) method to the estimation model; twelve spectral forms were applied in the estimation model of the spectra and soil salt content. Regression modeling was performed using the Partial Least Squares Regression (PLSR) method. Proximal-field spectral measurements data and soil samples were collected in the Yellow River Irrigation regions of Shizuishan City. A total of 60 samples were collected. The results showed that application of the SPA method improved the modeled determination coefficient (R2) and the ratio of performance to deviation (RPD), and reduced the modeled root mean square error (RMSE) and the percentage root mean square error (RMSE%); the maximum value of R2 increased by 0.22, the maximum value of RPD increased by 0.97, the maximum value of the RMSE decreased by 0.098 and the maximum value of the RMSE% decreased by 8.52%. The SPA&ndash;PLSR model, based on the first derivative of reflectivity (FD), the FD&ndash;SPA&ndash;PLSR model, showed the best results, with an R2 value of 0.89, an RPD value of 2.72, an RMSE value of 0.177, and RMSE% value of 11.81%. The results of this study demonstrated the applicability of the SPA method in the estimation of soil salinity, by using field spectroscopy data. The study provided a reference for a subsequent study of the hyperspectral estimation of soil salinity, and the proximal sensing data from a low distance, in this study, could provide detailed data for use in future remote sensing studies.},
DOI = {10.3390/rs11080967}
}



@Article{rs11080970,
AUTHOR = {Sławik, Łukasz and Niedzielko, Jan and Kania, Adam and Piórkowski, Hubert and Kopeć, Dominik},
TITLE = {Multiple Flights or Single Flight Instrument Fusion of Hyperspectral and ALS Data? A Comparison of their Performance for Vegetation Mapping},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {970},
URL = {https://www.mdpi.com/2072-4292/11/8/970},
ISSN = {2072-4292},
ABSTRACT = {Fusion of remote sensing data often improves vegetation mapping, compared to using data from only a single source. The effectiveness of this fusion is subject to many factors, including the type of data, collection method, and purpose of the analysis. In this study, we compare the usefulness of hyperspectral (HS) and Airborne Laser System (ALS) data fusion acquired in separate flights, Multiple Flights Data Fusion (MFDF), and during a single flight through Instrument Fusion (IF) for the classification of non-forest vegetation. An area of 6.75 km2 was selected, where hyperspectral and ALS data was collected during two flights in 2015 and one flight in 2017. This data was used to classify three non-forest Natura 2000 habitats i.e., Xeric sand calcareous grasslands (code 6120), alluvial meadows of river valleys of the Cnidion dubii (code 6440), species-rich Nardus grasslands (code 6230) using a Random Forest classifier. Our findings show that it is not possible to determine which sensor, HS, or ALS used independently leads to a higher classification accuracy for investigated Natura 2000 habitats. Concurrently, increased stability and consistency of classification results was confirmed, regardless of the type of fusion used; IF, MFDF and varied information relevance of single sensor data. The research shows that the manner of data collection, using MFDF or IF, does not determine the level of relevance of ALS or HS data. The analysis of fusion effectiveness, gauged as the accuracy of the classification result and time consumed for data collection, has shown a superiority of IF over MFDF. IF delivered classification results that are more accurate compared to MFDF. IF is always cheaper than MFDF and the difference in effectiveness of both methods becomes more pronounced when the area of aerial data collection becomes larger.},
DOI = {10.3390/rs11080970}
}



@Article{s19081933,
AUTHOR = {Pham, Tien Dat and Xia, Junshi and Ha, Nam Thang and Bui, Dieu Tien and Le, Nga Nhu and Tekeuchi, Wataru},
TITLE = {A Review of Remote Sensing Approaches for Monitoring Blue Carbon Ecosystems: Mangroves, Seagrassesand Salt Marshes during 2010–2018},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {1933},
URL = {https://www.mdpi.com/1424-8220/19/8/1933},
ISSN = {1424-8220},
ABSTRACT = {Blue carbon (BC) ecosystems are an important coastal resource, as they provide a range of goods and services to the environment. They play a vital role in the global carbon cycle by reducing greenhouse gas emissions and mitigating the impacts of climate change. However, there has been a large reduction in the global BC ecosystems due to their conversion to agriculture and aquaculture, overexploitation, and removal for human settlements. Effectively monitoring BC ecosystems at large scales remains a challenge owing to practical difficulties in monitoring and the time-consuming field measurement approaches used. As a result, sensible policies and actions for the sustainability and conservation of BC ecosystems can be hard to implement. In this context, remote sensing provides a useful tool for mapping and monitoring BC ecosystems faster and at larger scales. Numerous studies have been carried out on various sensors based on optical imagery, synthetic aperture radar (SAR), light detection and ranging (LiDAR), aerial photographs (APs), and multispectral data. Remote sensing-based approaches have been proven effective for mapping and monitoring BC ecosystems by a large number of studies. However, to the best of our knowledge, this is the first comprehensive review on the applications of remote sensing techniques for mapping and monitoring BC ecosystems. The main goal of this review is to provide an overview and summary of the key studies undertaken from 2010 onwards on remote sensing applications for mapping and monitoring BC ecosystems. Our review showed that optical imagery, such as multispectral and hyper-spectral data, is the most common for mapping BC ecosystems, while the Landsat time-series are the most widely-used data for monitoring their changes on larger scales. We investigate the limitations of current studies and suggest several key aspects for future applications of remote sensing combined with state-of-the-art machine learning techniques for mapping coastal vegetation and monitoring their extents and changes.},
DOI = {10.3390/s19081933}
}



@Article{agronomy9050216,
AUTHOR = {Cambra Baseca, Carlos and Sendra, Sandra and Lloret, Jaime and Tomas, Jesus},
TITLE = {A Smart Decision System for Digital Farming},
JOURNAL = {Agronomy},
VOLUME = {9},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {216},
URL = {https://www.mdpi.com/2073-4395/9/5/216},
ISSN = {2073-4395},
ABSTRACT = {New technologies have the potential to transform agriculture and to reduce environmental impact through a green revolution. Internet of Things (IoT)-based application development platforms have the potential to run farm management tools capable of monitoring real-time events when integrated into interactive innovation models for fertirrigation. Their capabilities must extend to flexible reconfiguration of programmed actions. IoT platforms require complex smart decision-making systems based on data-analysis and data mining of big data sets. In this paper, the advantages are demonstrated of a powerful tool that applies real-time decisions from data such as variable rate irrigation, and selected parameters from field and weather conditions. The field parameters, the index vegetation (estimated using aerial images), and the irrigation events, such as flow level, pressure level, and wind speed, are periodically sampled. Data is processed in a decision-making system based on learning prediction rules in conjunction with the Drools rule engine. The multimedia platform can be remotely controlled, and offers a smart farming open data network with shared restriction levels for information exchange oriented to farmers, the fertilizer provider, and agricultural technicians that should provide the farmer with added value in the form of better decision making or more efficient exploitation operations and management.},
DOI = {10.3390/agronomy9050216}
}



@Article{s19091994,
AUTHOR = {Sun, Guibin and Zhou, Rui and Di, Bin and Dong, Zhuoning and Wang, Yingxun},
TITLE = {A Novel Cooperative Path Planning for Multi-robot Persistent Coverage with Obstacles and Coverage Period Constraints},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1994},
URL = {https://www.mdpi.com/1424-8220/19/9/1994},
ISSN = {1424-8220},
ABSTRACT = {In this paper, a multi-robot persistent coverage of the region of interest is considered, where persistent coverage and cooperative coverage are addressed simultaneously. Previous works have mainly concentrated on the paths that allow for repeated coverage, but ignored the coverage period requirements of each sub-region. In contrast, this paper presents a combinatorial approach for path planning, which aims to cover mission domains with different task periods while guaranteeing both obstacle avoidance and minimizing the number of robots used. The algorithm first deploys the sensors in the region to satisfy coverage requirements with minimum cost. Then it solves the travelling salesman problem to obtain the frame of the closed path. Finally, the approach partitions the closed path into the fewest segments under the coverage period constraints, and it generates the closed route for each robot on the basis of portioned segments of the closed path. Therefore, each robot can circumnavigate one closed route to cover the different task areas completely and persistently. The numerical simulations show that the proposed approach is feasible to implement the cooperative coverage in consideration of obstacles and coverage period constraints, and the number of robots used is also minimized.},
DOI = {10.3390/s19091994}
}



@Article{rs11091017,
AUTHOR = {Zhang, Yang and Xiong, Zhangyue and Zang, Yu and Wang, Cheng and Li, Jonathan and Li, Xiang},
TITLE = {Topology-Aware Road Network Extraction via Multi-Supervised Generative Adversarial Networks},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1017},
URL = {https://www.mdpi.com/2072-4292/11/9/1017},
ISSN = {2072-4292},
ABSTRACT = {Road network extraction from remote sensing images has played an important role in various areas. However, due to complex imaging conditions and terrain factors, such as occlusion and shades, it is very challenging to extract road networks with complete topology structures. In this paper, we propose a learning-based road network extraction framework via a Multi-supervised Generative Adversarial Network (MsGAN), which is jointly trained by the spectral and topology features of the road network. Such a design makes the network capable of learning how to &ldquo;guess&rdquo; the aberrant road cases, which is caused by occlusion and shadow, based on the relationship between the road region and centerline; thus, it is able to provide a road network with integrated topology. Additionally, we also present a sample quality measurement to efficiently generate a large number of training samples with a little human interaction. Through the experiments on images from various satellites and the comprehensive comparisons to state-of-the-art approaches on the public datasets, it is demonstrated that the proposed method is able to provide high-quality results, especially for the completeness of the road network.},
DOI = {10.3390/rs11091017}
}



@Article{rs11091018,
AUTHOR = {Li, Zhen and Zan, Qijie and Yang, Qiong and Zhu, Dehuang and Chen, Youjun and Yu, Shixiao},
TITLE = {Remote Estimation of Mangrove Aboveground Carbon Stock at the Species Level Using a Low-Cost Unmanned Aerial Vehicle System},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1018},
URL = {https://www.mdpi.com/2072-4292/11/9/1018},
ISSN = {2072-4292},
ABSTRACT = {There is ongoing interest in developing remote sensing technology to map and monitor the spatial distribution and carbon stock of mangrove forests. Previous research has demonstrated that the relationship between remote sensing derived parameters and aboveground carbon (AGC) stock varies for different species types. However, the coarse spatial resolution of satellite images has restricted the estimated AGC accuracy, especially at the individual species level. Recently, the availability of unmanned aerial vehicles (UAVs) has provided an operationally efficient approach to map the distribution of species and accurately estimate AGC stock at a fine scale in mangrove areas. In this study, we estimated mangrove AGC in the core area of northern Shenzhen Bay, South China, using four kinds of variables, including species type, canopy height metrics, vegetation indices, and texture features, derived from a low-cost UAV system. Three machine-learning algorithm models, including Random Forest (RF), Support Vector Regression (SVR), and Artificial Neural Network (ANN), were compared in this study, where a 10-fold cross-validation was used to evaluate each model&rsquo;s effectiveness. The results showed that a model that used all four type of variables, which were based on the RF algorithm, provided better AGC estimates (R2 = 0.81, relative RMSE (rRMSE) = 0.20, relative MAE (rMAE) = 0.14). The average predicted AGC from this model was 93.0 &plusmn; 24.3 Mg C ha&minus;1, and the total estimated AGC was 7903.2 Mg for the mangrove forests. The species-based model had better performance than the considered canopy-height-based model for AGC estimation, and mangrove species was the most important variable among all the considered input variables; the mean height (Hmean) the second most important variable. Additionally, the RF algorithms showed better performance in terms of mangrove AGC estimation than the SVR and ANN algorithms. Overall, a low-cost UAV system with a digital camera has the potential to enable satisfactory predictions of AGC in areas of homogenous mangrove forests.},
DOI = {10.3390/rs11091018}
}



@Article{rs11091023,
AUTHOR = {Cinat, Paolo and Di Gennaro, Salvatore Filippo and Berton, Andrea and Matese, Alessandro},
TITLE = {Comparison of Unsupervised Algorithms for Vineyard Canopy Segmentation from UAV Multispectral Images},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1023},
URL = {https://www.mdpi.com/2072-4292/11/9/1023},
ISSN = {2072-4292},
ABSTRACT = {Technical resources are currently supporting and enhancing the ability of precision agriculture techniques in crop management. The accuracy of prescription maps is a key aspect to ensure a fast and targeted intervention. In this context, remote sensing acquisition by unmanned aerial vehicles (UAV) is one of the most advanced platforms to collect imagery of the field. Besides the imagery acquisition, canopy segmentation among soil, plants and shadows is another practical and technical aspect that must be fast and precise to ensure a targeted intervention. In this paper, algorithms to be applied to UAV imagery are proposed according to the sensor used that could either be visible spectral or multispectral. These algorithms, called HSV-based (Hue, Saturation, Value), DEM (Digital Elevation Model) and K-means, are unsupervised, i.e., they perform canopy segmentation without human support. They were tested and compared in three different scenarios obtained from two vineyards over two years, 2017 and 2018 for RGB (Red-Green-Blue) and NRG (Near Infrared-Red-Green) imagery. Particular attention is given to the unsupervised ability of these algorithms to identify vines in these different acquisition conditions. This ability is quantified by the introduction of over- and under- estimation indexes, which are the algorithm&rsquo;s ability to over-estimate or under-estimate vine canopies. For RGB imagery, the HSV-based algorithms consistently over-estimate vines, and never under-estimate them. The k-means and DEM method have a similar trend of under-estimation. While for NRG imagery, the HSV is the more stable algorithm and the DEM model slightly over-estimates the vines. HSV-based algorithms and the DEM algorithm have comparable computation time. The k-means algorithm increases computational demand as the quality of the DEM decreases. The algorithms developed can isolate canopy vegetation data, which is useful information about the current vineyard state, and can be used as a tool to be efficiently applied in the crop management procedure within precision viticulture applications.},
DOI = {10.3390/rs11091023}
}



@Article{s19092031,
AUTHOR = {Quirós Vargas, Juan José and Zhang, Chongyuan and Smitchger, Jamin A. and McGee, Rebecca J. and Sankaran, Sindhuja},
TITLE = {Phenotyping of Plant Biomass and Performance Traits Using Remote Sensing Techniques in Pea (Pisum sativum, L.)},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {2031},
URL = {https://www.mdpi.com/1424-8220/19/9/2031},
ISSN = {1424-8220},
ABSTRACT = {Field pea cultivars are constantly improved through breeding programs to enhance biotic and abiotic stress tolerance and increase seed yield potential. In pea breeding, the Above Ground Biomass (AGBM) is assessed due to its influence on seed yield, canopy closure, and weed suppression. It is also the primary yield component for peas used as a cover crop and/or grazing. Measuring AGBM is destructive and labor-intensive process. Sensor-based phenotyping of such traits can greatly enhance crop breeding efficiency. In this research, high resolution RGB and multispectral images acquired with unmanned aerial systems were used to assess phenotypes in spring and winter pea breeding plots. The Green Red Vegetation Index (GRVI), Normalized Difference Vegetation Index (NDVI), Normalized Difference Red Edge Index (NDRE), plot volume, canopy height, and canopy coverage were extracted from RGB and multispectral information at five imaging times (between 365 to 1948 accumulated degree days/ADD after 1 May) in four winter field pea experiments and at three imaging times (between 1231 to 1648 ADD) in one spring field pea experiment. The image features were compared to ground-truth data including AGBM, lodging, leaf type, days to 50% flowering, days to physiological maturity, number of the first reproductive node, and seed yield. In two of the winter pea experiments, a strong correlation between image features and seed yield was observed at 1268 ADD (flowering). An increase in correlation between image features with the phenological traits such as days to 50% flowering and days to physiological maturity was observed at about 1725 ADD in these winter pea experiments. In the spring pea experiment, the plot volume estimated from images was highly correlated with ground truth canopy height (r = 0.83) at 1231 ADD. In two other winter pea experiments and the spring pea experiment, the GRVI and NDVI features were significantly correlated with AGBM at flowering. When selected image features were used to develop a least absolute shrinkage and selection operator model for AGBM estimation, the correlation coefficient between the actual and predicted AGBM was 0.60 and 0.84 in the winter and spring pea experiments, respectively. A SPOT-6 satellite image (1.5 m resolution) was also evaluated for its applicability to assess biomass and seed yield. The image features extracted from satellite imagery showed significant correlation with seed yield in two winter field pea experiments, however, the trend was not consistent. In summary, the study supports the potential of using unmanned aerial system-based imaging techniques to estimate biomass and crop performance in pea breeding programs.},
DOI = {10.3390/s19092031}
}



@Article{rs11091025,
AUTHOR = {Li, Weijia and He, Conghui and Fu, Haohuan and Zheng, Juepeng and Dong, Runmin and Xia, Maocai and Yu, Le and Luk, Wayne},
TITLE = {A Real-Time Tree Crown Detection Approach for Large-Scale Remote Sensing Images on FPGAs},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1025},
URL = {https://www.mdpi.com/2072-4292/11/9/1025},
ISSN = {2072-4292},
ABSTRACT = {The on-board real-time tree crown detection from high-resolution remote sensing images is beneficial for avoiding the delay between data acquisition and processing, reducing the quantity of data transmission from the satellite to the ground, monitoring the growing condition of individual trees, and discovering the damage of trees as early as possible, etc. Existing high performance platform based tree crown detection studies either focus on processing images in a small size or suffer from high power consumption or slow processing speed. In this paper, we propose the first FPGA-based real-time tree crown detection approach for large-scale satellite images. A pipelined-friendly and resource-economic tree crown detection algorithm (PF-TCD) is designed through reconstructing and modifying the workflow of the original algorithm into three computational kernels on FPGAs. Compared with the well-optimized software implementation of the original algorithm on an Intel 12-core CPU, our proposed PF-TCD obtains the speedup of 18.75 times for a satellite image with a size of 12,188 &times; 12,576 pixels without reducing the detection accuracy. The image processing time for the large-scale remote sensing image is only 0.33 s, which satisfies the requirements of the on-board real-time data processing on satellites.},
DOI = {10.3390/rs11091025}
}



@Article{rs11091026,
AUTHOR = {Luo, Yiran and Li, Jian and Yu, Chunyang and Xu, Bing and Li, You and Hsu, Li-Ta and El-Sheimy, Naser},
TITLE = {Research on Time-Correlated Errors Using Allan Variance in a Kalman Filter Applicable to Vector-Tracking-Based GNSS Software-Defined Receiver for Autonomous Ground Vehicle Navigation},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1026},
URL = {https://www.mdpi.com/2072-4292/11/9/1026},
ISSN = {2072-4292},
ABSTRACT = {The global navigation satellite system (GNSS) has been applied to many areas, e.g., the autonomous ground vehicle, unmanned aerial vehicle (UAV), precision agriculture, smart city, and the GNSS-reflectometry (GNSS-R), being of considerable significance over the past few decades. Unfortunately, the GNSS signal performance has the high risk of being reduced by the environmental interference. The vector tracking (VT) technique is promising to enhance the robustness in high dynamics as well as improve the sensitivity against the weak environment of the GNSS receiver. However, the time-correlated error coupled in the receiver clock estimations in terms of the VT loop can decrease the accuracy of the navigation solution. There are few works present dealing with this issue. In this work, the Allan variance is accordingly exploited to specify a model which is expected to account for this type of error based on the 1st-order Gauss-Markov (GM) process. Then, it is used for proposing an enhanced Kalman filter (KF) by which this error can be suppressed. Furthermore, the proposed system model makes use of the innovation sequence so that the process covariance matrix can be adaptively adjusted and updated. The field tests demonstrate the performance of the proposed adaptive vector-tracking time-correlated error suppressed Kalman filter (A-VTTCES-KF). When compared with the results produced by the ordinary adaptive KF algorithm in terms of the VT loop, the real-time kinematic (RTK) positioning and code-based differential global positioning system (DGPS) positioning accuracies have been improved by 14.17% and 9.73%, respectively. On the other hand, the RTK positioning performance has been increased by maximum 21.40% when compared with the results obtained from the commercial low-cost U-Blox receiver.},
DOI = {10.3390/rs11091026}
}



@Article{beverages5020033,
AUTHOR = {Gonzalez Viejo, Claudia and Torrico, Damir D. and Dunshea, Frank R. and Fuentes, Sigfredo},
TITLE = {Development of Artificial Neural Network Models to Assess Beer Acceptability Based on Sensory Properties Using a Robotic Pourer: A Comparative Model Approach to Achieve an Artificial Intelligence System},
JOURNAL = {Beverages},
VOLUME = {5},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {33},
URL = {https://www.mdpi.com/2306-5710/5/2/33},
ISSN = {2306-5710},
ABSTRACT = {Artificial neural networks (ANN) have become popular for optimization and prediction of parameters in foods, beverages, agriculture and medicine. For brewing, they have been explored to develop rapid methods to assess product quality and acceptability. Different beers (N = 17) were analyzed in triplicates using a robotic pourer, RoboBEER (University of Melbourne, Melbourne, Australia), to assess 15 color and foam-related parameters using computer-vision. Those samples were tested using sensory analysis for acceptability of carbonation mouthfeel, bitterness, flavor and overall liking with 30 consumers using a 9-point hedonic scale. ANN models were developed using 17 different training algorithms with 15 color and foam-related parameters as inputs and liking of four descriptors obtained from consumers as targets. Each algorithm was tested using five, seven and ten neurons and compared to select the best model based on correlation coefficients, slope and performance (mean squared error (MSE). Bayesian Regularization algorithm with seven neurons presented the best correlation (R = 0.98) and highest performance (MSE = 0.03) with no overfitting. These models may be used as a cost-effective method for fast-screening of beers during processing to assess acceptability more efficiently. The use of RoboBEER, computer-vision algorithms and ANN will allow the implementation of an artificial intelligence system for the brewing industry to assess its effectiveness.},
DOI = {10.3390/beverages5020033}
}



@Article{rs11091040,
AUTHOR = {He, Haiqing and Zhou, Junchao and Chen, Min and Chen, Ting and Li, Dajun and Cheng, Penggen},
TITLE = {Building Extraction from UAV Images Jointly Using 6D-SLIC and Multiscale Siamese Convolutional Networks},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1040},
URL = {https://www.mdpi.com/2072-4292/11/9/1040},
ISSN = {2072-4292},
ABSTRACT = {Automatic building extraction using a single data type, either 2D remotely-sensed images or light detection and ranging 3D point clouds, remains insufficient to accurately delineate building outlines for automatic mapping, despite active research in this area and the significant progress which has been achieved in the past decade. This paper presents an effective approach to extracting buildings from Unmanned Aerial Vehicle (UAV) images through the incorporation of superpixel segmentation and semantic recognition. A framework for building extraction is constructed by jointly using an improved Simple Linear Iterative Clustering (SLIC) algorithm and Multiscale Siamese Convolutional Networks (MSCNs). The SLIC algorithm, improved by additionally imposing a digital surface model for superpixel segmentation, namely 6D-SLIC, is suited for building boundary detection under building and image backgrounds with similar radiometric signatures. The proposed MSCNs, including a feature learning network and a binary decision network, are used to automatically learn a multiscale hierarchical feature representation and detect building objects under various complex backgrounds. In addition, a gamma-transform green leaf index is proposed to truncate vegetation superpixels for further processing to improve the robustness and efficiency of building detection, the Douglas&ndash;Peucker algorithm and iterative optimization are used to eliminate jagged details generated from small structures as a result of superpixel segmentation. In the experiments, the UAV datasets, including many buildings in urban and rural areas with irregular shapes and different heights and that are obscured by trees, are collected to evaluate the proposed method. The experimental results based on the qualitative and quantitative measures confirm the effectiveness and high accuracy of the proposed framework relative to the digitized results. The proposed framework performs better than state-of-the-art building extraction methods, given its higher values of recall, precision, and intersection over Union (IoU).},
DOI = {10.3390/rs11091040}
}



@Article{rs11091042,
AUTHOR = {Hakdaoui, Sofia and Emran, Anas and Pradhan, Biswajeet and Lee, Chang-Wook and Nguemhe Fils, Salomon Cesar},
TITLE = {A Collaborative Change Detection Approach on Multi-Sensor Spatial Imagery for Desert Wetland Monitoring after a Flash Flood in Southern Morocco},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1042},
URL = {https://www.mdpi.com/2072-4292/11/9/1042},
ISSN = {2072-4292},
ABSTRACT = {This study aims to present a technique that combines multi-sensor spatial data to monitor wetland areas after a flash-flood event in a Saharan arid region. To extract the most efficient information, seven satellite images (radar and optical) taken before and after the event were used. To achieve the objectives, this study used Sentinel-1 data to discriminate water body and soil roughness, and optical data to monitor the soil moisture after the event. The proposed method combines two approaches: one based on spectral processing, and the other based on categorical processing. The first step was to extract four spectral indices and utilize change vector analysis on multispectral diachronic images from three MSI Sentinel-2 images and two Landsat-8 OLI images acquired before and after the event. The second step was performed using pattern classification techniques, namely, linear classifiers based on support vector machines (SVM) with Gaussian kernels. The results of these two approaches were fused to generate a collaborative wetland change map. The application of co-registration and supervised classification based on textural and intensity information from Radar Sentinel-1 images taken before and after the event completes this work. The results obtained demonstrate the importance of the complementarity of multi-sensor images and a multi-approach methodology to better monitor changes to a wetland area after a flash-flood disaster.},
DOI = {10.3390/rs11091042}
}



@Article{sym11050617,
AUTHOR = {Li, Zhiwei and Lu, Yu and Shi, Yun and Wang, Zengguang and Qiao, Wenxin and Liu, Yicen},
TITLE = {A Dyna-Q-Based Solution for UAV Networks Against Smart Jamming Attacks},
JOURNAL = {Symmetry},
VOLUME = {11},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {617},
URL = {https://www.mdpi.com/2073-8994/11/5/617},
ISSN = {2073-8994},
ABSTRACT = {Unmanned aerial vehicle (UAV) networks have a wide range of applications, such as in the Internet of Things (IoT), 5G communications, and so forth. However, the communications between UAVs and UAVs to ground control stations mainly use radio channels, and therefore these communications are vulnerable to cyberattacks. With the advent of software-defined radio (SDR), smart attacks that can flexibly select attack strategies according to the defender&rsquo;s state information are gradually attracting the attention of researchers and potential attackers of UAV networks. The smart attack can even induce the defender to take a specific defense strategy, causing even greater damage. Inspired by symmetrical thinking, a solution using a software-defined network (SDN) to combat software-defined radio was proposed. We propose a network architecture which uses dual controllers, including a UAV flight controller and SDN controller, to achieve collaborative decision-making. Built on the top of the SDN, the state information of the whole network converges quickly and is fitted to an environment model used to develop an improved Dyna-Q-based reinforcement learning algorithm. The improved algorithm integrates the power allocation and track planning of UAVs into a unified action space. The simulation data showed that the proposed communication solution can effectively avoid smart jamming attacks and has faster learning efficiency and higher convergence performance than the compared algorithms.},
DOI = {10.3390/sym11050617}
}



@Article{agronomy9050226,
AUTHOR = {Marino, Stefano and Alvino, Arturo},
TITLE = {Detection of Spatial and Temporal Variability of Wheat Cultivars by High-Resolution Vegetation Indices},
JOURNAL = {Agronomy},
VOLUME = {9},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {226},
URL = {https://www.mdpi.com/2073-4395/9/5/226},
ISSN = {2073-4395},
ABSTRACT = {An on-farm research study was carried out on two small-plots cultivated with two cultivars of durum wheat (Odisseo and Ariosto). The paper presents a theoretical approach for investigating frequency vegetation indices (VIs) in different areas of the experimental plot for early detection of agronomic spatial variability. Four flights were carried out with an unmanned aerial vehicle (UAV) to calculate high-resolution normalized difference vegetation index (NDVI) and optimized soil-adjusted vegetation index (OSAVI) images. Ground agronomic data (biomass, leaf area index (LAI), spikes, plant height, and yield) have been linked to the vegetation indices (VIs) at different growth stages. Regression coefficients of all samplings data were highly significant for both the cultivars and VIs at anthesis and tillering stage. At harvest, the whole plot (W) data were analyzed and compared with two sub-areas characterized by high agronomic performance (H) yield 20% higher than the whole plot, and low performances (L), about 20% lower of yield related to the whole plot). The whole plot and two sub-areas were analyzed backward in time comparing the VIs frequency curves. At anthesis, more than 75% of the surface of H sub-areas showed a VIs value higher than the L sub-plot. The differences were evident also at the tillering and seedling stages, when the 75% (third percentile) of VIs H data was over the 50% (second percentile) of the W curve and over the 25% (first percentile) of L sub-plot. The use of high-resolution images for analyzing the frequency value of VIs in different areas can be a useful approach for the detection of agronomic constraints for precision agriculture purposes.},
DOI = {10.3390/agronomy9050226}
}



@Article{rs11091081,
AUTHOR = {Chen, Shih-Yu and Lin, Chinsu and Chuang, Shang-Ju and Kao, Zhe-Yuan},
TITLE = {Weighted Background Suppression Target Detection Using Sparse Image Enhancement Technique for Newly Grown Tree Leaves},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1081},
URL = {https://www.mdpi.com/2072-4292/11/9/1081},
ISSN = {2072-4292},
ABSTRACT = {The process from leaf sprouting to senescence is a phenological response, which is caused by the effect of temperature and moisture on the physiological response during the life cycle of trees. Therefore, detecting newly grown leaves could be useful for studying tree growth or even climate change. This study applied several target detection techniques to observe the growth of leaves in unmanned aerial vehicle (UAV) multispectral images. The weighted background suppression (WBS) method was proposed in this paper to reduce the interference of the target of interest through a weighted correlation/covariance matrix. This novel technique could strengthen targets and suppress the background. This study also developed the sparse enhancement (SE) method for newly grown leaves (NGL), as sparsity has features similar to newly grown leaves. The experimental results suggested that using SE-WBS based algorithms could improve the detection performance of NGL for most detectors. For the global target detection methods, the SE-WBS version of adaptive coherence estimator (SE-WBS-ACE) refines the area under the receiver operating characteristic curve (AUC) from 0.9417 to 0.9658 and kappa from 0.3389 to 0.4484. The SE-WBS version of target constrained interference minimized filter (SE-WBS-TCIMF) increased AUC from 0.9573 to 0.9708 and kappa from 0.3472 to 0.4417; the SE-WBS version of constrained energy minimization (SE-WBS-CEM) boosted AUC from 0.9606 to 0.9713 and kappa from 0.3604 to 0.4483. For local target detection methods, the SE-WBS version of adaptive sliding window CEM (ASW SE-WBS-CEM) enhanced AUC from 0.9704 to 0.9796 and kappa from 0.4526 to 0.5121, which outperforms other methods.},
DOI = {10.3390/rs11091081}
}



@Article{soilsystems3020033,
AUTHOR = {Krenz, Juliane and Greenwood, Philip and Kuhn, Nikolaus J.},
TITLE = {Soil Degradation Mapping in Drylands Using Unmanned Aerial Vehicle (UAV) Data},
JOURNAL = {Soil Systems},
VOLUME = {3},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {33},
URL = {https://www.mdpi.com/2571-8789/3/2/33},
ISSN = {2571-8789},
ABSTRACT = {Arid and semi-arid landscapes often show a patchwork of bare and vegetated spaces. Their heterogeneous patterns can be of natural origin, but may also indicate soil degradation. This study investigates the use of unmanned aerial vehicle (UAV) imagery to identify the degradation status of soils, based on the hypothesis that vegetation cover can be used as a proxy for estimating the soils&rsquo; health status. To assess the quality of the UAV-derived products, we compare a conventional field-derived map (FM) with two modelled maps based on (i) vegetation cover (RGB map), and (ii) vegetation cover, topographic information, and a flow accumulation analysis (RGB+DEM map). All methods were able to identify areas of soil degradation but differed in the extent of classified soil degradation, with the RGB map classifying the least amount as degraded. The RGB+DEM map classified 12% more as degraded than the FM, due to the wider perspective of the UAV compared to conventional field mapping. Overall, conventional UAVs provide a valuable tool for soil mapping in heterogeneous landscapes where manual field sampling is very time consuming. Additionally, the UAVs&rsquo; planform view from a bird&rsquo;s-eye perspective can overcome the limited view from the surveyors&rsquo; (ground-based) vantage point.},
DOI = {10.3390/soilsystems3020033}
}



@Article{rs11091085,
AUTHOR = {Ma, Xiaodan and Zhu, Kexin and Guan, Haiou and Feng, Jiarui and Yu, Song and Liu, Gang},
TITLE = {High-Throughput Phenotyping Analysis of Potted Soybean Plants Using Colorized Depth Images Based on A Proximal Platform},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1085},
URL = {https://www.mdpi.com/2072-4292/11/9/1085},
ISSN = {2072-4292},
ABSTRACT = {Canopy color and structure can strongly reflect plant functions. Color characteristics and plant height as well as canopy breadth are important aspects of the canopy phenotype of soybean plants. High-throughput phenotyping systems with imaging capabilities providing color and depth information can rapidly acquire data of soybean plants, making it possible to quantify and monitor soybean canopy development. The goal of this study was to develop a 3D imaging approach to quantitatively analyze soybean canopy development under natural light conditions. Thus, a Kinect sensor-based high-throughput phenotyping (HTP) platform was developed for soybean plant phenotyping. To calculate color traits accurately, the distortion phenomenon of color images was first registered in accordance with the principle of three primary colors and color constancy. Then, the registered color images were applied to depth images for the reconstruction of the colorized three-dimensional canopy structure. Furthermore, the 3D point cloud of soybean canopies was extracted from the background according to adjusted threshold, and each area of individual potted soybean plants in the depth images was segmented for the calculation of phenotypic traits. Finally, color indices, plant height and canopy breadth were assessed based on 3D point cloud of soybean canopies. The results showed that the maximum error of registration for the R, G, and B bands in the dataset was 1.26%, 1.09%, and 0.75%, respectively. Correlation analysis between the sensors and manual measurements yielded R2 values of 0.99, 0.89, and 0.89 for plant height, canopy breadth in the west-east (W&ndash;E) direction, and canopy breadth in the north-south (N&ndash;S) direction, and R2 values of 0.82, 0.79, and 0.80 for color indices h, s, and i, respectively. Given these results, the proposed approaches provide new opportunities for the identification of the quantitative traits that control canopy structure in genetic/genomic studies or for soybean yield prediction in breeding programs.},
DOI = {10.3390/rs11091085}
}



@Article{ijms20092273,
AUTHOR = {Casari, Raphael A. C. N. and Paiva, Dayane S. and Silva, Vivianny N. B. and Ferreira, Thalita M. M. and Souza, Junior, Manoel T. and Oliveira, Nelson G. and Kobayashi, Adilson K. and Molinari, Hugo B. C. and Santos, Thiago T. and Gomide, Reinaldo L. and Magalhães, Paulo C. and Sousa, Carlos A. F.},
TITLE = {Using Thermography to Confirm Genotypic Variation for Drought Response in Maize},
JOURNAL = {International Journal of Molecular Sciences},
VOLUME = {20},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {2273},
URL = {https://www.mdpi.com/1422-0067/20/9/2273},
PubMedID = {31071964},
ISSN = {1422-0067},
ABSTRACT = {The feasibility of thermography as a technique for plant screening aiming at drought-tolerance has been proven by its relationship with gas exchange, biomass, and yield. In this study, unlike most of the previous, thermography was applied for phenotyping contrasting maize genotypes whose classification for drought tolerance had already been established in the field. Our objective was to determine whether thermography-based classification would discriminate the maize genotypes in a similar way as the field selection in which just grain yield was taken into account as a criterion. We evaluated gas exchange, daily water consumption, leaf relative water content, aboveground biomass, and grain yield. Indeed, the screening of maize genotypes based on canopy temperature showed similar results to traditional methods. Nevertheless, canopy temperature only partially reflected gas exchange rates and daily water consumption in plants under drought. Part of the explanation may lie in the changes that drought had caused in plant leaves and canopy structure, altering absorption and dissipation of energy, photosynthesis, transpiration, and partitioning rates. Accordingly, although there was a negative relationship between grain yield and plant canopy temperature, it does not necessarily mean that plants whose canopies were maintained cooler under drought achieved the highest yield.},
DOI = {10.3390/ijms20092273}
}



@Article{s19092130,
AUTHOR = {Zemmour, Elie and Kurtser, Polina and Edan, Yael},
TITLE = {Automatic Parameter Tuning for Adaptive Thresholding in Fruit Detection},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {2130},
URL = {https://www.mdpi.com/1424-8220/19/9/2130},
ISSN = {1424-8220},
ABSTRACT = {This paper presents an automatic parameter tuning procedure specially developed for a dynamic adaptive thresholding algorithm for fruit detection. One of the major algorithm strengths is its high detection performances using a small set of training images. The algorithm enables robust detection in highly-variable lighting conditions. The image is dynamically split into variably-sized regions, where each region has approximately homogeneous lighting conditions. Nine thresholds were selected to accommodate three different illumination levels for three different dimensions in four color spaces: RGB, HSI, LAB, and NDI. Each color space uses a different method to represent a pixel in an image: RGB (Red, Green, Blue), HSI (Hue, Saturation, Intensity), LAB (Lightness, Green to Red and Blue to Yellow) and NDI (Normalized Difference Index, which represents the normal difference between the RGB color dimensions). The thresholds were selected by quantifying the required relation between the true positive rate and false positive rate. A tuning process was developed to determine the best fit values of the algorithm parameters to enable easy adaption to different kinds of fruits (shapes, colors) and environments (illumination conditions). Extensive analyses were conducted on three different databases acquired in natural growing conditions: red apples (nine images with 113 apples), green grape clusters (129 images with 1078 grape clusters), and yellow peppers (30 images with 73 peppers). These databases are provided as part of this paper for future developments. The algorithm was evaluated using cross-validation with 70% images for training and 30% images for testing. The algorithm successfully detected apples and peppers in variable lighting conditions resulting with an F-score of 93.17% and 99.31% respectively. Results show the importance of the tuning process for the generalization of the algorithm to different kinds of fruits and environments. In addition, this research revealed the importance of evaluating different color spaces since for each kind of fruit, a different color space might be superior over the others. The LAB color space is most robust to noise. The algorithm is robust to changes in the threshold learned by the training process and to noise effects in images.},
DOI = {10.3390/s19092130}
}



@Article{app9091908,
AUTHOR = {Zhang, Yan and Wen, Jinxiao and Yang, Guanshu and He, Zunwen and Wang, Jing},
TITLE = {Path Loss Prediction Based on Machine Learning: Principle, Method, and Data Expansion},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1908},
URL = {https://www.mdpi.com/2076-3417/9/9/1908},
ISSN = {2076-3417},
ABSTRACT = {Path loss prediction is of great significance for the performance optimization of wireless networks. With the development and deployment of the fifth-generation (5G) mobile communication systems, new path loss prediction methods with high accuracy and low complexity should be proposed. In this paper, the principle and procedure of machine-learning-based path loss prediction are presented. Measured data are used to evaluate the performance of different models such as artificial neural network, support vector regression, and random forest. It is shown that these machine-learning-based models outperform the log-distance model. In view of the fact that the volume of measured data sometimes cannot meet the requirements of machine learning algorithms, we propose two mechanisms to expand the training dataset. On one hand, old measured data can be reused in new scenarios or at different frequencies. On the other hand, the classical model can also be utilized to generate a number of training samples based on the prior information obtained from measured results. Measured data are employed to verify the feasibility of these data expansion mechanisms. Finally, some issues for future research are discussed.},
DOI = {10.3390/app9091908}
}



@Article{s19092147,
AUTHOR = {Zhang, Chuang and Zhao, Xiubin and Pang, Chunlei and Zhang, Liang and Feng, Bo},
TITLE = {The Influence of Satellite Configuration and Fault Duration Time on the Performance of Fault Detection in GNSS/INS Integration},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {2147},
URL = {https://www.mdpi.com/1424-8220/19/9/2147},
ISSN = {1424-8220},
ABSTRACT = {For the integration of global navigation satellite system (GNSS) and inertial navigation system (INS), real-time and accurate fault detection is essential to enhance the reliability and precision of the system. Among the existing methods, the residual chi-square detection is still widely used due to its good real-time performance and sensibility of fault detection. However, further investigation on the performance of fault detection for different observational conditions and fault models is still required. In this paper, the principle of chi-square detection based on the predicted residual and least-squares residual is analyzed and the equivalence between them is deduced. Then, choosing the chi-square detection based on the predicted residual as the research object, the influence of satellite configuration and fault duration time on the performance of fault detection is analyzed in theory. The influence of satellite configuration is analyzed from the number and geometry of visible satellites. Several numerical simulations are conducted to verify the theoretical analysis. The results show that, for a single-epoch fault, the location of faulty measurement and the geometry have little effect on the performance of fault detection, while the number of visible satellites has greater influence on the fault detection performance than the geometry. For a continuous fault, the fault detection performance will decrease with the increase of fault duration time when the value of the fault is near the minimal detectable bias (MDB), and faults occurring on different satellite&rsquo;s measurement will result in different detection results.},
DOI = {10.3390/s19092147}
}



@Article{app9091909,
AUTHOR = {Van Pham, Hai and Asadi, Farzin and Abut, Nurettin and Kandilli, Ismet},
TITLE = {Hybrid Spiral STC-Hedge Algebras Model in Knowledge Reasonings for Robot Coverage Path Planning and Its Applications},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1909},
URL = {https://www.mdpi.com/2076-3417/9/9/1909},
ISSN = {2076-3417},
ABSTRACT = {Robotics is a highly developed field in industry, and there is a large research effort in terms of humanoid robotics, including the development of multi-functional empathetic robots as human companions. An important function of a robot is to find an optimal coverage path planning, with obstacle avoidance in dynamic environments for cleaning and monitoring robotics. This paper proposes a novel approach to enable robotic path planning. The proposed approach combines robot reasoning with knowledge reasoning techniques, hedge algebra, and the Spiral Spanning Tree Coverage (STC) algorithm, for a cleaning and monitoring robot with optimal decisions. This approach is used to apply knowledge inference and hedge algebra with the Spiral STC algorithm to enable autonomous robot control in the optimal coverage path planning, with minimum obstacle avoidance. The results of experiments show that the proposed approach in the optimal robot path planning avoids tangible and intangible obstacles for the monitoring and cleaning robot. Experimental results are compared with current methods under the same conditions. The proposed model using knowledge reasoning techniques in the optimal coverage path performs better than the conventional algorithms in terms of high robot coverage and low repetition rates. Experiments are done with real robots for cleaning in dynamic environments.},
DOI = {10.3390/app9091909}
}



@Article{app9091943,
AUTHOR = {Wei, Lifei and Yuan, Ziran and Zhong, Yanfei and Yang, Lanfang and Hu, Xin and Zhang, Yangxi},
TITLE = {An Improved Gradient Boosting Regression Tree Estimation Model for Soil Heavy Metal (Arsenic) Pollution Monitoring Using Hyperspectral Remote Sensing},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1943},
URL = {https://www.mdpi.com/2076-3417/9/9/1943},
ISSN = {2076-3417},
ABSTRACT = {Hyperspectral remote sensing can be used to effectively identify contaminated elements in soil. However, in the field of monitoring soil heavy metal pollution, hyperspectral remote sensing has the characteristics of high dimensionality and high redundancy, which seriously affect the accuracy and stability of hyperspectral inversion models. To resolve the problem, a gradient boosting regression tree (GBRT) hyperspectral inversion algorithm for heavy metal (Arsenic (As)) content in soils based on Spearman&rsquo;s rank correlation analysis (SCA) coupled with competitive adaptive reweighted sampling (CARS) is proposed in this paper. Firstly, the CARS algorithm is used to roughly select the original spectral data. Second derivative (SD), Gaussian filtering (GF), and min-max normalization (MMN) pretreatments are then used to improve the correlation between the spectra and As in the characteristic band enhancement stage. Finally, the low-correlation bands are removed using the SCA method, and a subset with absolute correlation values greater than 0.6 is retained as the optimal band subset after each pretreatment. For the modeling, the five most representative characteristic bands were selected in the Honghu area of China, and the nine most representative characteristic bands were selected in the Daye area of China. In order to verify the generalization ability of the proposed algorithm, 92 soil samples from the Honghu and Daye areas were selected as the research objects. With the use of support vector machine regression (SVMR), linear regression (LR), and random forest (RF) regression methods as comparative methods, all the models obtained a good prediction accuracy. However, among the different combinations, CARS-SCA-GBRT obtained the highest precision, which indicates that the proposed algorithm can select fewer characteristic bands to achieve a better inversion effect, and can thus provide accurate data support for the treatment and recovery of heavy metal pollution in soils.},
DOI = {10.3390/app9091943}
}



@Article{app9091952,
AUTHOR = {Petrellis, Nikos},
TITLE = {Plant Disease Diagnosis for Smart Phone Applications with Extensible Set of Diseases},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1952},
URL = {https://www.mdpi.com/2076-3417/9/9/1952},
ISSN = {2076-3417},
ABSTRACT = {A plant disease diagnosis method that can be implemented with the resources of a mobile phone application, that does not have to be connected to a remote server, is presented and evaluated on citrus diseases. It can be used both by amateur gardeners and by professional agriculturists for early detection of diseases. The features used are extracted from photographs of plant parts like leaves or fruits and include the color, the relative area and the number of the lesion spots. These classification features, along with additional information like weather metadata, form disease signatures that can be easily defined by the end user (e.g., an agronomist). These signatures are based on the statistical processing of a small number of representative training photographs. The extracted features of a test photograph are compared against the disease signatures in order to select the most likely disease. An important advantage of the proposed approach is that the diagnosis does not depend on the orientation, the scale or the resolution of the photograph. The experiments have been conducted under several light exposure conditions. The accuracy was experimentally measured between 70% and 99%. An acceptable accuracy higher than 90% can be achieved in most of the cases since the lesion spots can recognized interactively with high precision.},
DOI = {10.3390/app9091952}
}



@Article{s19102222,
AUTHOR = {Li, Yingshun and Wang, Aina and Yi, Xiaojian},
TITLE = {Fire Control System Operation Status Assessment Based on Information Fusion: Case Study},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {2222},
URL = {https://www.mdpi.com/1424-8220/19/10/2222},
ISSN = {1424-8220},
ABSTRACT = {In traditional fault diagnosis strategies, massive and disordered data cannot be utilized effectively. Furthermore, just a single parameter is used for fault diagnosis of a weapons fire control system, which might lead to uncertainty in the results. This paper proposes an information fusion method in which rough set theory (RST) is combined with an improved Dempster&ndash;Shafer (DS) evidence theory to identify various system operation states. First, the feature information of different faults is extracted from the original data, then this information is used as the evidence of the state for a diagnosis object. By introducing RST, the extracted fault information is reduced in terms of the number of attributes, and the basic probability value of the reduced fault information is obtained. Based on an analysis of conflicts in the existing DS evidence theory, an improved conflict evidence synthesis method is proposed, which combines the improved synthesis rule and the conflict evidence weight allocation methods. Then, an intelligent evaluation model for the fire control system operation state is established, which is based on the improved evidence theory and RST. The case of a power supply module in a fire control computer is analyzed. In this case, the state grade of the power supply module is evaluated by the proposed method, and the conclusion verifies the effectiveness of the proposed method in evaluating the operation state of a fire control system.},
DOI = {10.3390/s19102222}
}



@Article{s19102230,
AUTHOR = {Wang, Su and Kobayashi, Yukinori and Ravankar, Ankit A. and Ravankar, Abhijeet and Emaru, Takanori},
TITLE = {A Novel Approach for Lidar-Based Robot Localization in a Scale-Drifted Map Constructed Using Monocular SLAM},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {2230},
URL = {https://www.mdpi.com/1424-8220/19/10/2230},
ISSN = {1424-8220},
ABSTRACT = {Scale ambiguity and drift are inherent drawbacks of a pure-visual monocular simultaneous localization and mapping (SLAM) system. This problem could be a crucial challenge for other robots with range sensors to perform localization in a map previously built by a monocular camera. In this paper, a metrically inconsistent priori map is made by the monocular SLAM that is subsequently used to perform localization on another robot only using a laser range finder (LRF). To tackle the problem of the metric inconsistency, this paper proposes a 2D-LRF-based localization algorithm which allows the robot to locate itself and resolve the scale of the local map simultaneously. To align the data from 2D LRF to the map, 2D structures are extracted from the 3D point cloud map obtained by the visual SLAM process. Next, a modified Monte Carlo localization (MCL) approach is proposed to estimate the robot&rsquo;s state which is composed of both the robot&rsquo;s pose and map&rsquo;s relative scale. Finally, the effectiveness of the proposed system is demonstrated in the experiments on a public benchmark dataset as well as in a real-world scenario. The experimental results indicate that the proposed method is able to globally localize the robot in real-time. Additionally, even in a badly drifted map, the successful localization can also be achieved.},
DOI = {10.3390/s19102230}
}



@Article{rs11101153,
AUTHOR = {Bejiga, Mesay Belete and Melgani, Farid and Beraldini, Pietro},
TITLE = {Domain Adversarial Neural Networks for Large-Scale Land Cover Classification},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {1153},
URL = {https://www.mdpi.com/2072-4292/11/10/1153},
ISSN = {2072-4292},
ABSTRACT = {Learning classification models require sufficiently labeled training samples, however, collecting labeled samples for every new problem is time-consuming and costly. An alternative approach is to transfer knowledge from one problem to another, which is called transfer learning. Domain adaptation (DA) is a type of transfer learning that aims to find a new latent space where the domain discrepancy between the source and the target domain is negligible. In this work, we propose an unsupervised DA technique called domain adversarial neural networks (DANNs), composed of a feature extractor, a class predictor, and domain classifier blocks, for large-scale land cover classification. Contrary to the traditional methods that perform representation and classifier learning in separate stages, DANNs combine them into a single stage, thereby learning a new representation of the input data that is both domain-invariant and discriminative. Once trained, the classifier of a DANN can be used to predict both source and target domain labels. Additionally, we also modify the domain classifier of a DANN to evaluate its suitability for multi-target domain adaptation problems. Experimental results obtained for both single and multiple target DA problems show that the proposed method provides a performance gain of up to 40%.},
DOI = {10.3390/rs11101153}
}



@Article{rs11101157,
AUTHOR = {Fuentes-Pacheco, Jorge and Torres-Olivares, Juan and Roman-Rangel, Edgar and Cervantes, Salvador and Juarez-Lopez, Porfirio and Hermosillo-Valadez, Jorge and Rendón-Mancha, Juan Manuel},
TITLE = {Fig Plant Segmentation from Aerial Images Using a Deep Convolutional Encoder-Decoder Network},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {1157},
URL = {https://www.mdpi.com/2072-4292/11/10/1157},
ISSN = {2072-4292},
ABSTRACT = {Crop segmentation is an important task in Precision Agriculture, where the use of aerial robots with an on-board camera has contributed to the development of new solution alternatives. We address the problem of fig plant segmentation in top-view RGB (Red-Green-Blue) images of a crop grown under open-field difficult circumstances of complex lighting conditions and non-ideal crop maintenance practices defined by local farmers. We present a Convolutional Neural Network (CNN) with an encoder-decoder architecture that classifies each pixel as crop or non-crop using only raw colour images as input. Our approach achieves a mean accuracy of 93.85% despite the complexity of the background and a highly variable visual appearance of the leaves. We make available our CNN code to the research community, as well as the aerial image data set and a hand-made ground truth segmentation with pixel precision to facilitate the comparison among different algorithms.},
DOI = {10.3390/rs11101157}
}



@Article{app9102009,
AUTHOR = {Han, Jiaming and Yang, Zhong and Zhang, Qiuyan and Chen, Cong and Li, Hongchen and Lai, Shangxiang and Hu, Guoxiong and Xu, Changliang and Xu, Hao and Wang, Di and Chen, Rui},
TITLE = {A Method of Insulator Faults Detection in Aerial Images for High-Voltage Transmission Lines Inspection},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {2009},
URL = {https://www.mdpi.com/2076-3417/9/10/2009},
ISSN = {2076-3417},
ABSTRACT = {Insulator faults detection is an important task for high-voltage transmission line inspection. However, current methods often suffer from the lack of accuracy and robustness. Moreover, these methods can only detect one fault in the insulator string, but cannot detect a multi-fault. In this paper, a novel method is proposed for insulator one fault and multi-fault detection in UAV-based aerial images, the backgrounds of which usually contain much complex interference. The shapes of the insulators also vary obviously due to the changes in filming angle and distance. To reduce the impact of complex interference on insulator faults detection, we make full use of the deep neural network to distinguish between insulators and background interference. First of all, plenty of insulator aerial images with manually labelled ground-truth are collected to construct a standard insulator detection dataset &lsquo;InST_detection&rsquo;. Secondly, a new convolutional network is proposed to obtain accurate insulator string positions in the aerial image. Finally, a novel fault detection method is proposed that can detect both insulator one fault and multi-fault in aerial images. Experimental results on a large number of aerial images show that our proposed method is more effective and efficient than the state-of-the-art insulator fault detection methods.},
DOI = {10.3390/app9102009}
}



@Article{s19102271,
AUTHOR = {Bi, Fukun and Hou, Jinyuan and Chen, Liang and Yang, Zhihua and Wang, Yanping},
TITLE = {Ship Detection for Optical Remote Sensing Images Based on Visual Attention Enhanced Network},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {2271},
URL = {https://www.mdpi.com/1424-8220/19/10/2271},
ISSN = {1424-8220},
ABSTRACT = {Ship detection plays a significant role in military and civil fields. Although some state-of-the-art detection methods, based on convolutional neural networks (CNN) have certain advantages, they still cannot solve the challenge well, including the large size of images, complex scene structure, a large amount of false alarm interference, and inshore ships. This paper proposes a ship detection method from optical remote sensing images, based on visual attention enhanced network. To effectively reduce false alarm in non-ship area and improve the detection efficiency from remote sensing images, we developed a light-weight local candidate scene network(     L 2     CSN) to extract the local candidate scenes with ships. Then, for the selected local candidate scenes, we propose a ship detection method, based on the visual attention DSOD(VA-DSOD). Here, to enhance the detection performance and positioning accuracy of inshore ships, we both extract semantic features, based on DSOD and embed a visual attention enhanced network in DSOD to extract the visual features. We test the detection method on a large number of typical remote sensing datasets, which consist of Google Earth images and GaoFen-2 images. We regard the state-of-the-art method [sliding window DSOD (SW+DSOD)] as a baseline, which achieves the average precision (AP) of 82.33%. The AP of the proposed method increases by 7.53%. The detection and location performance of our proposed method outperforms the baseline in complex remote sensing scenes.},
DOI = {10.3390/s19102271}
}



@Article{sym11050678,
AUTHOR = {Wang, Bodi and Liu, Guixiong and Wu, Junfang},
TITLE = {Blind Deblurring of Saturated Images Based on Optimization and Deep Learning for Dynamic Visual Inspection on the Assembly Line},
JOURNAL = {Symmetry},
VOLUME = {11},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {678},
URL = {https://www.mdpi.com/2073-8994/11/5/678},
ISSN = {2073-8994},
ABSTRACT = {Image deblurring can improve visual quality and mitigates motion blur for dynamic visual inspection. We propose a method to deblur saturated images for dynamic visual inspection by applying blur kernel estimation and deconvolution modeling. The blur kernel is estimated in a transform domain, whereas the deconvolution model is decoupled into deblurring and denoising stages via variable splitting. Deblurring predicts the mask specifying saturated pixels, which are then discarded, and denoising is learned via the fast and flexible denoising network (FFDNet) convolutional neural network (CNN) at a wide range of noise levels. Hence, the proposed deconvolution model provides the benefits of both model optimization and deep learning. Experiments demonstrate that the proposed method suitably restores visual quality and outperforms existing approaches with good score improvements.},
DOI = {10.3390/sym11050678}
}



@Article{rs11101174,
AUTHOR = {Sheykhmousa, Mohammadreza and Kerle, Norman and Kuffer, Monika and Ghaffarian, Saman},
TITLE = {Post-Disaster Recovery Assessment with Machine Learning-Derived Land Cover and Land Use Information},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {1174},
URL = {https://www.mdpi.com/2072-4292/11/10/1174},
ISSN = {2072-4292},
ABSTRACT = {Post-disaster recovery (PDR) is a complex, long-lasting, resource intensive, and poorly understood process. PDR goes beyond physical reconstruction (physical recovery) and includes relevant processes such as economic and social (functional recovery) processes. Knowing the size and location of the places that positively or negatively recovered is important to effectively support policymakers to help readjust planning and resource allocation to rebuild better. Disasters and the subsequent recovery are mainly expressed through unique land cover and land use changes (LCLUCs). Although LCLUCs have been widely studied in remote sensing, their value for recovery assessment has not yet been explored, which is the focus of this paper. An RS-based methodology was created for PDR assessment based on multi-temporal, very high-resolution satellite images. Different trajectories of change were analyzed and evaluated, i.e., transition patterns (TPs) that signal positive or negative recovery. Experimental analysis was carried out on three WorldView-2 images acquired over Tacloban city, Philippines, which was heavily affected by Typhoon Haiyan in 2013. Support vector machine, a robust machine learning algorithm, was employed with texture features extracted from the grey level co-occurrence matrix and local binary patterns. Although classification results for the images before and four years after the typhoon show high accuracy, substantial uncertainties mark the results for the immediate post-event image. All land cover (LC) and land use (LU) classified maps were stacked, and only changes related to TPs were extracted. The final products are LC and LU recovery maps that quantify the PDR process at the pixel level. It was found that physical and functional recovery can be mainly explained through the LCLUC information. In addition, LC and LU-based recovery maps support a general and a detailed recovery understanding, respectively. It is therefore suggested to use the LC and LU-based recovery maps to monitor and support the short and the long-term recovery, respectively.},
DOI = {10.3390/rs11101174}
}



@Article{rs11101180,
AUTHOR = {Buters, Todd M. and Bateman, Philip W. and Robinson, Todd and Belton, David and Dixon, Kingsley W. and Cross, Adam T.},
TITLE = {Methodological Ambiguity and Inconsistency Constrain Unmanned Aerial Vehicles as A Silver Bullet for Monitoring Ecological Restoration},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {1180},
URL = {https://www.mdpi.com/2072-4292/11/10/1180},
ISSN = {2072-4292},
ABSTRACT = {The last decade has seen an exponential increase in the application of unmanned aerial vehicles (UAVs) to ecological monitoring research, though with little standardisation or comparability in methodological approaches and research aims. We reviewed the international peer-reviewed literature in order to explore the potential limitations on the feasibility of UAV-use in the monitoring of ecological restoration, and examined how they might be mitigated to maximise the quality, reliability and comparability of UAV-generated data. We found little evidence of translational research applying UAV-based approaches to ecological restoration, with less than 7% of 2133 published UAV monitoring studies centred around ecological restoration. Of the 48 studies, &gt; 65% had been published in the three years preceding this study. Where studies utilised UAVs for rehabilitation or restoration applications, there was a strong propensity for single-sensor monitoring using commercially available RPAs fitted with the modest-resolution RGB sensors available. There was a strong positive correlation between the use of complex and expensive sensors (e.g., LiDAR, thermal cameras, hyperspectral sensors) and the complexity of chosen image classification techniques (e.g., machine learning), suggesting that cost remains a primary constraint to the wide application of multiple or complex sensors in UAV-based research. We propose that if UAV-acquired data are to represent the future of ecological monitoring, research requires a) consistency in the proven application of different platforms and sensors to the monitoring of target landforms, organisms and ecosystems, underpinned by clearly articulated monitoring goals and outcomes; b) optimization of data analysis techniques and the manner in which data are reported, undertaken in cross-disciplinary partnership with fields such as bioinformatics and machine learning; and c) the development of sound, reasonable and multi-laterally homogenous regulatory and policy framework supporting the application of UAVs to the large-scale and potentially trans-disciplinary ecological applications of the future.},
DOI = {10.3390/rs11101180}
}



@Article{ijgi8050240,
AUTHOR = {Kim, Nari and Ha, Kyung-Ja and Park, No-Wook and Cho, Jaeil and Hong, Sungwook and Lee, Yang-Won},
TITLE = {A Comparison Between Major Artificial Intelligence Models for Crop Yield Prediction: Case Study of the Midwestern United States, 2006–2015},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {8},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {240},
URL = {https://www.mdpi.com/2220-9964/8/5/240},
ISSN = {2220-9964},
ABSTRACT = {This paper compares different artificial intelligence (AI) models in order to develop the best crop yield prediction model for the Midwestern United States (US). Through experiments to examine the effects of phenology using three different periods, we selected the July&ndash;August (JA) database as the best months to predict corn and soybean yields. Six different AI models for crop yield prediction are tested in this research. Then, a comprehensive and objective comparison is conducted between the AI models. Particularly for the deep neural network (DNN) model, we performed an optimization process to ensure the best configurations for the layer structure, cost function, optimizer, activation function, and drop-out ratio. In terms of mean absolute error (MAE), our DNN model with the JA database was approximately 21&ndash;33% and 17&ndash;22% more accurate for corn and soybean yields, respectively, than the other five AI models. This indicates that corn and soybean yields for a given year can be forecasted in advance, at the beginning of September, approximately a month or more ahead of harvesting time. A combination of the optimized DNN model and spatial statistical methods should be investigated in future work, to mitigate partly clustered errors in some regions.},
DOI = {10.3390/ijgi8050240}
}



@Article{e21050515,
AUTHOR = {Joung, Jingon and Choi, Jihoon and Jung, Bang Chul and Yu, Sungwook},
TITLE = {Artificial Noise Injection and Its Power Loading Methods for Secure Space-Time Line Coded Systems},
JOURNAL = {Entropy},
VOLUME = {21},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {515},
URL = {https://www.mdpi.com/1099-4300/21/5/515},
ISSN = {1099-4300},
ABSTRACT = {In this paper, we consider a     2 &times; 2     space-time line coded (STLC) system having two-transmit and two-receive antennas. To improve the secrecy rate of the STLC system, in which an illegitimate receiver eavesdrops the information delivered from the STLC transmitter to the STLC receiver, we propose an artificial noise (AN) injection method. By exploiting the STLC structure, a novel AN for the STLC is designed and its optimal power loading factor is derived. Numerical results verify that the proposed secure STLC systems with the designed AN injection and the power control method can significantly improve the secrecy rate compared to the conventional STLC systems. It is observed that the proposed method is more effective if there is a significant gap between the main-channel and the eavesdropper-channel gains.},
DOI = {10.3390/e21050515}
}



@Article{agronomy9050258,
AUTHOR = {Chawade, Aakash and van Ham, Joost and Blomquist, Hanna and Bagge, Oscar and Alexandersson, Erik and Ortiz, Rodomiro},
TITLE = {High-Throughput Field-Phenotyping Tools for Plant Breeding and Precision Agriculture},
JOURNAL = {Agronomy},
VOLUME = {9},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {258},
URL = {https://www.mdpi.com/2073-4395/9/5/258},
ISSN = {2073-4395},
ABSTRACT = {High-throughput field phenotyping has garnered major attention in recent years leading to the development of several new protocols for recording various plant traits of interest. Phenotyping of plants for breeding and for precision agriculture have different requirements due to different sizes of the plots and fields, differing purposes and the urgency of the action required after phenotyping. While in plant breeding phenotyping is done on several thousand small plots mainly to evaluate them for various traits, in plant cultivation, phenotyping is done in large fields to detect the occurrence of plant stresses and weeds at an early stage. The aim of this review is to highlight how various high-throughput phenotyping methods are used for plant breeding and farming and the key differences in the applications of such methods. Thus, various techniques for plant phenotyping are presented together with applications of these techniques for breeding and cultivation. Several examples from the literature using these techniques are summarized and the key technical aspects are highlighted.},
DOI = {10.3390/agronomy9050258}
}



@Article{rs11101238,
AUTHOR = {De Luca, Giandomenico and N. Silva, João M. and Cerasoli, Sofia and Araújo, João and Campos, José and Di Fazio, Salvatore and Modica, Giuseppe},
TITLE = {Object-Based Land Cover Classification of Cork Oak Woodlands using UAV Imagery and Orfeo ToolBox},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {1238},
URL = {https://www.mdpi.com/2072-4292/11/10/1238},
ISSN = {2072-4292},
ABSTRACT = {This paper investigates the reliability of free and open-source algorithms used in the geographical object-based image classification (GEOBIA) of very high resolution (VHR) imagery surveyed by unmanned aerial vehicles (UAVs). UAV surveys were carried out in a cork oak woodland located in central Portugal at two different periods of the year (spring and summer). Segmentation and classification algorithms were implemented in the Orfeo ToolBox (OTB) configured in the QGIS environment for the GEOBIA process. Image segmentation was carried out using the Large-Scale Mean-Shift (LSMS) algorithm, while classification was performed by the means of two supervised classifiers, random forest (RF) and support vector machines (SVM), both of which are based on a machine learning approach. The original, informative content of the surveyed imagery, consisting of three radiometric bands (red, green, and NIR), was combined to obtain the normalized difference vegetation index (NDVI) and the digital surface model (DSM). The adopted methodology resulted in a classification with higher accuracy that is suitable for a structurally complex Mediterranean forest ecosystem such as cork oak woodlands, which are characterized by the presence of shrubs and herbs in the understory as well as tree shadows. To improve segmentation, which significantly affects the subsequent classification phase, several tests were performed using different values of the range radius and minimum region size parameters. Moreover, the consistent selection of training polygons proved to be critical to improving the results of both the RF and SVM classifiers. For both spring and summer imagery, the validation of the obtained results shows a very high accuracy level for both the SVM and RF classifiers, with kappa coefficient values ranging from 0.928 to 0.973 for RF and from 0.847 to 0.935 for SVM. Furthermore, the land cover class with the highest accuracy for both classifiers and for both flights was cork oak, which occupies the largest part of the study area. This study shows the reliability of fixed-wing UAV imagery for forest monitoring. The study also evidences the importance of planning UAV flights at solar noon to significantly reduce the shadows of trees in the obtained imagery, which is critical for classifying open forest ecosystems such as cork oak woodlands.},
DOI = {10.3390/rs11101238}
}



@Article{electronics8050576,
AUTHOR = {You, Shixun and Diao, Ming and Gao, Lipeng},
TITLE = {Completing Explorer Games with a Deep Reinforcement Learning Framework Based on Behavior Angle Navigation},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {576},
URL = {https://www.mdpi.com/2079-9292/8/5/576},
ISSN = {2079-9292},
ABSTRACT = {In cognitive electronic warfare, when a typical combat vehicle, such as an unmanned combat air vehicle (UCAV), uses radar sensors to explore an unknown space, the target-searching fails due to an inefficient servoing/tracking system. Thus, to solve this problem, we developed an autonomous reasoning search method that can generate efficient decision-making actions and guide the UCAV as early as possible to the target area. For high-dimensional continuous action space, the UCAV&rsquo;s maneuvering strategies are subject to certain physical constraints. We first record the path histories of the UCAV as a sample set of supervised experiments and then construct a grid cell network using long short-term memory (LSTM) to generate a new displacement prediction to replace the target location estimation. Finally, we enable a variety of continuous-control-based deep reinforcement learning algorithms to output optimal/sub-optimal decision-making actions. All these tasks are performed in a three-dimensional target-searching simulator, i.e., the Explorer game. Please note that we use the behavior angle (BHA) for the first time as the main factor of the reward-shaping of the deep reinforcement learning framework and successfully make the trained UCAV achieve a 99.96% target destruction rate, i.e., the game win rate, in a 0.1 s operating cycle.},
DOI = {10.3390/electronics8050576}
}



@Article{s19102396,
AUTHOR = {Lin, Shijie and Wang, Jinwang and Peng, Rui and Yang, Wen},
TITLE = {Development of an Autonomous Unmanned Aerial Manipulator Based on a Real-Time Oriented-Object Detection Method},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {2396},
URL = {https://www.mdpi.com/1424-8220/19/10/2396},
ISSN = {1424-8220},
ABSTRACT = {Autonomous Unmanned Aerial Manipulators (UAMs) have shown promising potential in mobile 3-dimensional grasping applications, but they still suffer from some difficulties impeding their board applications, such as target detection and indoor positioning. For the autonomous grasping mission, the UAMs need ability to recognize the objects and grasp them. Considering the efficiency and precision, we present a novel oriented-object detection method called Rotation-SqueezeDet. This method can run on embedded-platforms in near real-time. Besides, this method can give the oriented bounding box of an object in images to enable a rotation-aware grasping. Based on this method, a UAM platform was designed and built. We have given the formulation, positioning, control, and planning of the whole UAM system. All the mechanical designs are fully provided as open-source hardware for reuse by the community. Finally, the effectiveness of the proposed scheme was validated in multiple experimental trials, highlighting its applicability of autonomous aerial rotational grasping in Global Positioning System (GPS) denied environments. We believe this system can be deployed to many potential workplaces which need UAM to accomplish difficult manipulation tasks.},
DOI = {10.3390/s19102396}
}



@Article{f10050458,
AUTHOR = {Keefe, Robert F. and Wempe, Ann M. and Becker, Ryer M. and Zimbelman, Eloise G. and Nagler, Emily S. and Gilbert, Sophie L. and Caudill, Christopher C.},
TITLE = {Positioning Methods and the Use of Location and Activity Data in Forests},
JOURNAL = {Forests},
VOLUME = {10},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {458},
URL = {https://www.mdpi.com/1999-4907/10/5/458},
ISSN = {1999-4907},
ABSTRACT = {In this paper, we provide an overview of positioning systems for moving resources in forest and fire management and review the related literature. Emphasis is placed on the accuracy and range of different localization and location-sharing methods, particularly in forested environments and in the absence of conventional cellular or internet connectivity. We then conduct a second review of literature and concepts related to several emerging, broad themes in data science, including the terms location-based services (LBS), geofences, wearable technology, activity recognition, mesh networking, the Internet of Things (IoT), and big data. Our objective in this second review is to inform how these broader concepts, with implications for networking and analytics, may help to advance natural resource management and science in the future. Based on methods, themes, and concepts that arose in our systematic reviews, we then augmented the paper with additional literature from wildlife and fisheries management, as well as concepts from video object detection, relative positioning, and inventory-tracking that are also used as forms of localization. Based on our reviews of positioning technologies and emerging data science themes, we present a hierarchical model for collecting and sharing data in forest and fire management, and more broadly in the field of natural resources. The model reflects tradeoffs in range and bandwidth when recording, processing, and communicating large quantities of data in time and space to support resource management, science, and public safety in remote areas. In the hierarchical approach, wearable devices and other sensors typically transmit data at short distances using Bluetooth, Bluetooth Low Energy (BLE), or ANT wireless, and smartphones and tablets serve as intermediate data collection and processing hubs for information that can be subsequently transmitted using radio networking systems or satellite communication. Data with greater spatial and temporal complexity is typically processed incrementally at lower tiers, then fused and summarized at higher levels of incident command or resource management. Lastly, we outline several priority areas for future research to advance big data analytics in natural resources.},
DOI = {10.3390/f10050458}
}



@Article{w11051112,
AUTHOR = {Zhao, Rong-Heng and Zhang, Zi-Han and He, Wu-Quan and Lou, Zong-Ke and Ma, Xiao-Yi},
TITLE = {Synthetical Optimization of a Gravity-Driven Irrigation Pipeline Network System with Pressure-Regulating Facilities},
JOURNAL = {Water},
VOLUME = {11},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {1112},
URL = {https://www.mdpi.com/2073-4441/11/5/1112},
ISSN = {2073-4441},
ABSTRACT = {Due to the influence of topographic drops, a large elevation difference often occurs in the middle and lower sections of the main pipe of a gravity-driven irrigation pipe network (GDIPN) system. This elevation difference must be reduced appropriately through pressure reduction facilities (pressure-regulating ponds (PRPs) or pressure-reducing valves (PRVs)). The number and locations of PRPs are crucial factors in regulating and balancing the pressure head of the main pipe of a GDIPN system as well as in reducing the project cost. However, there are few studies on the optimization of this kind of pipe network system. In this paper, first, we generalize such type of GDIPN system, and a simplified mathematical model for such system optimization was established. A genetic algorithm based on a fixed proportion and direct comparison (GA-FPDC) was introduced to solve the model. Two existing projects were tested by the proposed method. The results show that the presented method not only improved the design efficiency and rationality but also greatly decreased the project cost. The presented method is effective and efficient to address optimization design of such GDIPN system problems.},
DOI = {10.3390/w11051112}
}



@Article{rs11111261,
AUTHOR = {Niu, Yaxiao and Zhang, Liyuan and Zhang, Huihui and Han, Wenting and Peng, Xingshuo},
TITLE = {Estimating Above-Ground Biomass of Maize Using Features Derived from UAV-Based RGB Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1261},
URL = {https://www.mdpi.com/2072-4292/11/11/1261},
ISSN = {2072-4292},
ABSTRACT = {The rapid, accurate, and economical estimation of crop above-ground biomass at the farm scale is crucial for precision agricultural management. The unmanned aerial vehicle (UAV) remote-sensing system has a great application potential with the ability to obtain remote-sensing imagery with high temporal-spatial resolution. To verify the application potential of consumer-grade UAV RGB imagery in estimating maize above-ground biomass, vegetation indices and plant height derived from UAV RGB imagery were adopted. To obtain a more accurate observation, plant height was directly derived from UAV RGB point clouds. To search the optimal estimation method, the estimation performances of the models based on vegetation indices alone, based on plant height alone, and based on both vegetation indices and plant height were compared. The results showed that plant height directly derived from UAV RGB point clouds had a high correlation with ground-truth data with an R2 value of 0.90 and an RMSE value of 0.12 m. The above-ground biomass exponential regression models based on plant height alone had higher correlations for both fresh and dry above-ground biomass with R2 values of 0.77 and 0.76, respectively, compared to the linear regression model (both R2 values were 0.59). The vegetation indices derived from UAV RGB imagery had great potential to estimate maize above-ground biomass with R2 values ranging from 0.63 to 0.73. When estimating the above-ground biomass of maize by using multivariable linear regression based on vegetation indices, a higher correlation was obtained with an R2 value of 0.82. There was no significant improvement of the estimation performance when plant height derived from UAV RGB imagery was added into the multivariable linear regression model based on vegetation indices. When estimating crop above-ground biomass based on UAV RGB remote-sensing system alone, looking for optimized vegetation indices and establishing estimation models with high performance based on advanced algorithms (e.g., machine learning technology) may be a better way.},
DOI = {10.3390/rs11111261}
}



@Article{s19112448,
AUTHOR = {Xiong, Xin and Zhang, Jingjin and Guo, Doudou and Chang, Liying and Huang, Danfeng},
TITLE = {Non-Invasive Sensing of Nitrogen in Plant Using Digital Images and Machine Learning for Brassica Campestris ssp. Chinensis L.},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2448},
URL = {https://www.mdpi.com/1424-8220/19/11/2448},
ISSN = {1424-8220},
ABSTRACT = {Monitoring plant nitrogen (N) in a timely way and accurately is critical for precision fertilization. The imaging technology based on visible light is relatively inexpensive and ubiquitous, and open-source analysis tools have proliferated. In this study, texture- and geometry-related phenotyping combined with color properties were investigated for their potential use in evaluating N in pakchoi (Brassica campestris ssp. chinensis L.). Potted pakchoi treated with four levels of N were cultivated in a greenhouse. Their top-view images were acquired using a camera at six growth stages. The corresponding plant N concentration was determined destructively. The quantitative relationships between the nitrogen nutrition index (NNI) and the image-based phenotyping features were established using the following algorithms: random forest (RF), support vector regression (SVR), and neural network (NN). The results showed the full model based on the color, texture, and geometry-related features outperforms the model based on only the color-related feature in predicting the NNI. The RF full model exhibited the most robust performance in both the seedling and harvest stages, reaching prediction accuracies of 0.823 and 0.943, respectively. The high prediction accuracy of the model allows for a low-cost, non-destructive monitoring of N in the field of precision crop management.},
DOI = {10.3390/s19112448}
}



@Article{s19112467,
AUTHOR = {Mwenegoha, Hery and Moore, Terry and Pinchin, James and Jabbal, Mark},
TITLE = {Model-Based Autonomous Navigation with Moment of Inertia Estimation for Unmanned Aerial Vehicles},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2467},
URL = {https://www.mdpi.com/1424-8220/19/11/2467},
ISSN = {1424-8220},
ABSTRACT = {The dominant navigation system for low-cost, mass-market Unmanned Aerial Vehicles (UAVs) is based on an Inertial Navigation System (INS) coupled with a Global Navigation Satellite System (GNSS). However, problems tend to arise during periods of GNSS outage where the navigation solution degrades rapidly. Therefore, this paper details a model-based integration approach for fixed wing UAVs, using the Vehicle Dynamics Model (VDM) as the main process model aided by low-cost Micro-Electro-Mechanical Systems (MEMS) inertial sensors and GNSS measurements with moment of inertia calibration using an Unscented Kalman Filter (UKF). Results show that the position error does not exceed 14.5 m in all directions after 140 s of GNSS outage. Roll and pitch errors are bounded to 0.06 degrees and the error in yaw grows slowly to 0.65 degrees after 140 s of GNSS outage. The filter is able to estimate model parameters and even the moment of inertia terms even with significant coupling between them. Pitch and yaw moment coefficient terms present significant cross coupling while roll moment terms seem to be decorrelated from all of the other terms, whilst more dynamic manoeuvres could help to improve the overall observability of the parameters.},
DOI = {10.3390/s19112467}
}



@Article{w11061129,
AUTHOR = {Arabameri, Alireza and Cerda, Artemi and Tiefenbacher, John P.},
TITLE = {Spatial Pattern Analysis and Prediction of Gully Erosion Using Novel Hybrid Model of Entropy-Weight of Evidence},
JOURNAL = {Water},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {1129},
URL = {https://www.mdpi.com/2073-4441/11/6/1129},
ISSN = {2073-4441},
ABSTRACT = {Gully erosion is an environmental problem in arid and semi-arid areas. Gullies threaten the soil and water resources and cause off- and on-site problems. In this research, a new hybrid model combines the index-of-entropy (IoE) model with the weight-of-evidence (WoE) model. Remote sensing and GIS techniques are used to map gully-erosion susceptibility in the watershed of the Bastam district of Semnan Province in northern Iran. The performance of the hybrid model is assessed by comparing the results with from models that use only IoE or WoE. Three hundred and three gullies were mapped in the study area and were randomly classified into two groups for training (70% or 212 gullies) and validation (30% or 91 gullies). Eighteen topographical, hydrological, geological, and environmental conditioning factors were considered in the modeling process. Prediction-rate curves (PRCs) and success-rate curves (SRCs) were used for validation. Results from the IoE model indicate that drainage density, slope, and rainfall factors are the most important factors promoting gullying in the study area. Validation results indicate that the ensemble model performed better than either the IoE or WoE models. The hybrid model predicted that 38.02 percent of the study area has either high or very high susceptible to gullying. Given the high accuracy of the novel hybrid model, this scientific methodology may be very useful for land use management decisions and for land use planning in gully-prone regions. Our research contributes to achieve Land Degradation Neutrality as will help to design remediation programs to control non-sustainable soil erosion rates.},
DOI = {10.3390/w11061129}
}



@Article{rs11111286,
AUTHOR = {Chen, Xiang and Wang, Tao and Liu, Shulin and Peng, Fei and Tsunekawa, Atsushi and Kang, Wenping and Guo, Zichen and Feng, Kun},
TITLE = {A New Application of Random Forest Algorithm to Estimate Coverage of Moss-Dominated Biological Soil Crusts in Semi-Arid Mu Us Sandy Land, China},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1286},
URL = {https://www.mdpi.com/2072-4292/11/11/1286},
ISSN = {2072-4292},
ABSTRACT = {Biological soil crusts (BSCs) play an essential role in desert ecosystems. Knowledge of the distribution and disappearance of BSCs is vital for the management of ecosystems and for desertification researches. However, the major remote sensing approaches used to extract BSCs are multispectral indices, which lack accuracy, and hyperspectral indices, which have lower data availability and require a higher computational effort. This study employs random forest (RF) models to optimize the extraction of BSCs using band combinations similar to the two multispectral BSC indices (Crust Index-CI; Biological Soil Crust Index-BSCI), but covering all possible band combinations. Simulated multispectral datasets resampled from in-situ hyperspectral data were used to extract BSC information. Multispectral datasets (Landsat-8 and Sentinel-2 datasets) were then used to detect BSC coverage in Mu Us Sandy Land, located in northern China, where BSCs dominated by moss are widely distributed. The results show that (i) the spectral curves of moss-dominated BSCs are different from those of other typical land surfaces, (ii) the BSC coverage can be predicted using the simulated multispectral data (mean square error (MSE) &lt; 0.01), (iii) Sentinel-2 satellite datasets with CI-based band combinations provided a reliable RF model for detecting moss-dominated BSCs (10-fold validation, R2 = 0.947; ground validation, R2 = 0.906). In conclusion, application of the RF algorithm to the Sentinel-2 dataset can precisely and effectively map BSCs dominated by moss. This new application can be used as a theoretical basis for detecting BSCs in other arid and semi-arid lands within desert ecosystems.},
DOI = {10.3390/rs11111286}
}



@Article{f10060471,
AUTHOR = {Lopes Queiroz, Gustavo and McDermid, Gregory J. and Castilla, Guillermo and Linke, Julia and Rahman, Mir Mustafizur},
TITLE = {Mapping Coarse Woody Debris with Random Forest Classification of Centimetric Aerial Imagery},
JOURNAL = {Forests},
VOLUME = {10},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {471},
URL = {https://www.mdpi.com/1999-4907/10/6/471},
ISSN = {1999-4907},
ABSTRACT = {Coarse woody debris (CWD; large parts of dead trees) is a vital element of forest ecosystems, playing an important role in nutrient cycling, carbon storage, fire fuel, microhabitats, and overall forest structure. However, there is a lack of effective tools for identifying and mapping both standing (snags) and downed (logs) CWD in complex natural settings. We applied a random forest machine learning classifier to detect CWD in centimetric aerial imagery acquired over a 270-hectare study area in the boreal forest of Alberta, Canada. We used a geographic object-based image analysis (GEOBIA) approach in the classification with spectral, spatial, and LiDAR (light detection and ranging)-derived height predictor variables. We found CWD to be detected with great accuracy (93.4 &plusmn; 4.2% completeness and 94.5 &plusmn; 3.2% correctness) when training samples were located within the application area, and with very good accuracy (84.2 &plusmn; 5.2% completeness and 92.2 &plusmn; 3.2% correctness) when training samples were located outside the application area. The addition of LiDAR-derived variables did not increase the accuracy of CWD detection overall (&lt;2%), but aided significantly (p &lt; 0.001) in the distinction between logs and snags. Foresters and researchers interested in CWD can take advantage of these novel methods to produce accurate maps of logs and snags, which will contribute to the understanding and management of forest ecosystems.},
DOI = {10.3390/f10060471}
}



@Article{cancers11060756,
AUTHOR = {Halicek, Martin and Fabelo, Himar and Ortega, Samuel and Callico, Gustavo M. and Fei, Baowei},
TITLE = {In-Vivo and Ex-Vivo Tissue Analysis through Hyperspectral Imaging Techniques: Revealing the Invisible Features of Cancer},
JOURNAL = {Cancers},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {756},
URL = {https://www.mdpi.com/2072-6694/11/6/756},
ISSN = {2072-6694},
ABSTRACT = {In contrast to conventional optical imaging modalities, hyperspectral imaging (HSI) is able to capture much more information from a certain scene, both within and beyond the visual spectral range (from 400 to 700 nm). This imaging modality is based on the principle that each material provides different responses to light reflection, absorption, and scattering across the electromagnetic spectrum. Due to these properties, it is possible to differentiate and identify the different materials/substances presented in a certain scene by their spectral signature. Over the last two decades, HSI has demonstrated potential to become a powerful tool to study and identify several diseases in the medical field, being a non-contact, non-ionizing, and a label-free imaging modality. In this review, the use of HSI as an imaging tool for the analysis and detection of cancer is presented. The basic concepts related to this technology are detailed. The most relevant, state-of-the-art studies that can be found in the literature using HSI for cancer analysis are presented and summarized, both in-vivo and ex-vivo. Lastly, we discuss the current limitations of this technology in the field of cancer detection, together with some insights into possible future steps in the improvement of this technology.},
DOI = {10.3390/cancers11060756}
}



@Article{rs11111298,
AUTHOR = {Laamrani, Ahmed and Berg, Aaron A. and Voroney, Paul and Feilhauer, Hannes and Blackburn, Line and March, Michael and Dao, Phuong D. and He, Yuhong and Martin, Ralph C.},
TITLE = {Ensemble Identification of Spectral Bands Related to Soil Organic Carbon Levels over an Agricultural Field in Southern Ontario, Canada},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1298},
URL = {https://www.mdpi.com/2072-4292/11/11/1298},
ISSN = {2072-4292},
ABSTRACT = {The recent use of hyperspectral remote sensing imagery has introduced new opportunities for soil organic carbon (SOC) assessment and monitoring. These data enable monitoring of a wide variety of soil properties but pose important methodological challenges. Highly correlated hyperspectral spectral bands can affect the prediction and accuracy as well as the interpretability of the retrieval model. Therefore, the spectral dimension needs to be reduced through a selection of specific spectral bands or regions that are most helpful to describing SOC. This study evaluates the efficiency of visible near-infrared (VNIR) and shortwave near-infrared (SWIR) hyperspectral data to identify the most informative hyperspectral bands responding to SOC content in agricultural soils. Soil samples (111) were collected over an agricultural field in southern Ontario, Canada and analyzed against two hyperspectral datasets: An airborne Nano-Hyperspec imaging sensor with 270 bands (400&ndash;1000 nm) and a laboratory hyperspectral dataset (ASD FieldSpec 3) along the 1000&ndash;2500 nm range (NIR-SWIR). In parallel, a multimethod modeling approach consisting of random forest, support vector machine, and partial least squares regression models was used to conduct band selections and to assess the validity of the selected bands. The multimethod model resulted in a selection of optimal band or regions over the VNIR and SWIR sensitive to SOC and potentially for mapping. The bands that achieved the highest respective importance values were 711&ndash;715, 727, 986&ndash;998, and 433&ndash;435 nm regions (VNIR); and 2365&ndash;2373, 2481&ndash;2500, and 2198&ndash;2206 nm (NIR-SWIR). Some of these bands are in agreement with the absorption features of SOC reported in the literature, whereas others have not been reported before. Ultimately, the selection of optimal band and regions is of importance for quantification of agricultural SOC and would provide a new framework for creating optimized SOC-specific sensors.},
DOI = {10.3390/rs11111298}
}



@Article{f10060478,
AUTHOR = {Zhou, Xisheng and Li, Long and Chen, Longqian and Liu, Yunqiang and Cui, Yifan and Zhang, Yu and Zhang, Ting},
TITLE = {Discriminating Urban Forest Types from Sentinel-2A Image Data through Linear Spectral Mixture Analysis: A Case Study of Xuzhou, East China},
JOURNAL = {Forests},
VOLUME = {10},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {478},
URL = {https://www.mdpi.com/1999-4907/10/6/478},
ISSN = {1999-4907},
ABSTRACT = {Urban forests are an important component of the urban ecosystem. Urban forest types are a key piece of information required for monitoring the condition of an urban ecosystem. In this study, we propose an urban forest type discrimination method based on linear spectral mixture analysis (LSMA) and a support vector machine (SVM) in the case study of Xuzhou, east China. From 10-m Sentinel-2A imagery data, three different vegetation endmembers, namely broadleaved forest, coniferous forest, and low vegetation, and their abundances were extracted through LSMA. Using a combination of image spectra, topography, texture, and vegetation abundances, four SVM classification models were performed and compared to investigate the impact of these features on classification accuracy. With a particular interest in the role that vegetation abundances play in classification, we also compared SVM and other classifiers, i.e., random forest (RF), artificial neural network (ANN), and quick unbiased efficient statistical tree (QUEST). Results indicate that (1) the LSMA method can derive accurate vegetation abundances from Sentinel-2A image data, and the root-mean-square error (RMSE) was 0.019; (2) the classification accuracies of the four SVM models were improved after adding topographic features, textural features, and vegetation abundances one after the other; (3) the SVM produced higher classification accuracies than the other three classifiers when identical classification features were used; and (4) vegetation endmember abundances improved classification accuracy regardless of which classifier was used. It is concluded that Sentinel-2A image data has a strong capability to discriminate urban forest types in spectrally heterogeneous urban areas, and that vegetation abundances derived from LSMA can enhance such discrimination.},
DOI = {10.3390/f10060478}
}



@Article{rs11111308,
AUTHOR = {Wang, Dongliang and Shao, Quanqin and Yue, Huanyin},
TITLE = {Surveying Wild Animals from Satellites, Manned Aircraft and Unmanned Aerial Systems (UASs): A Review},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1308},
URL = {https://www.mdpi.com/2072-4292/11/11/1308},
ISSN = {2072-4292},
ABSTRACT = {This article reviews studies regarding wild animal surveys based on multiple platforms, including satellites, manned aircraft, and unmanned aircraft systems (UASs), and focuses on the data used, animal detection methods, and their accuracies. We also discuss the advantages and limitations of each type of remote sensing data and highlight some new research opportunities and challenges. Submeter very-high-resolution (VHR) spaceborne imagery has potential in modeling the population dynamics of large (&gt;0.6 m) wild animals at large spatial and temporal scales, but has difficulty discerning small (&lt;0.6 m) animals at the species level, although high-resolution commercial satellites, such as WorldView-3 and -4, have been able to collect images with a ground resolution of up to 0.31 m in panchromatic mode. This situation will not change unless the satellite image resolution is greatly improved in the future. Manned aerial surveys have long been employed to capture the centimeter-scale images required for animal censuses over large areas. However, such aerial surveys are costly to implement in small areas and can cause significant disturbances to wild animals because of their noise. In contrast, UAS surveys are seen as a safe, convenient and less expensive alternative to ground-based and conventional manned aerial surveys, but most UASs can cover only small areas. The proposed use of UAS imagery in combination with VHR satellite imagery would produce critical population data for large wild animal species and colonies over large areas. The development of software systems for automatically producing image mosaics and recognizing wild animals will further improve survey efficiency.},
DOI = {10.3390/rs11111308}
}



@Article{s19112527,
AUTHOR = {Sakhakarmi, Sayan and Park, JeeWoong},
TITLE = {Investigation of Tactile Sensory System Configuration for Construction Hazard Perception},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2527},
URL = {https://www.mdpi.com/1424-8220/19/11/2527},
ISSN = {1424-8220},
ABSTRACT = {The application of tactile-based wearable devices to assist in navigation for people with low sight/low memory has demonstrated the feasibility of using such devices as a means of communication. Accordingly, a previous study in construction research investigated various parameters of tactile signals to develop a communicable system for potential application in construction hazard communication. However, the nature of construction limits the application of such devices to the body of construction workers, and it is important to understand sensor design parameters for improved communication, which has not been given significant attention yet. Therefore, this study aims to determine key design factors such as the number of motors, spacing between sensors and the layout of a tactile sensory system to be used for communicating construction hazards to workers. For this purpose, this study focused on identifying the number of motors based on extensive literature and the problem of construction safety as to hazard communication, determining the arrangement that allowed for effective delivery and perception of information with minimum effort. The researchers conducted two experimental studies: First, to determine the minimum spacing between vibration motors that allows for the identification of each individual motor with high accuracy; and second, to determine the layout of motors that is suitable for effective communication of multiple types of information. More importantly, the tactile-sensor configuration identified from this study allows the workers to learn the signal patterns easily in order to identify multiple types of information related to hazards. Using such a communication system on construction sites will assist in transmitting hazard-related information to workers, and thus, protect the lives of workers. Such wearable technologies enable the detection of individual-level hazards and prevent worker fatalities and severe injuries.},
DOI = {10.3390/s19112527}
}



@Article{rs11111338,
AUTHOR = {Sothe, Camile and Dalponte, Michele and Almeida, Cláudia Maria de and Schimalski, Marcos Benedito and Lima, Carla Luciane and Liesenberg, Veraldo and Miyoshi, Gabriela Takahashi and Tommaselli, Antonio Maria Garcia},
TITLE = {Tree Species Classification in a Highly Diverse Subtropical Forest Integrating UAV-Based Photogrammetric Point Cloud and Hyperspectral Data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1338},
URL = {https://www.mdpi.com/2072-4292/11/11/1338},
ISSN = {2072-4292},
ABSTRACT = {The use of remote sensing data for tree species classification in tropical forests is still a challenging task, due to their high floristic and spectral diversity. In this sense, novel sensors on board of unmanned aerial vehicle (UAV) platforms are a rapidly evolving technology that provides new possibilities for tropical tree species mapping. Besides the acquisition of high spatial and spectral resolution images, UAV-hyperspectral cameras operating in frame format enable to produce 3D hyperspectral point clouds. This study investigated the use of UAV-acquired hyperspectral images and UAV-photogrammetric point cloud (PPC) for classification of 12 major tree species in a subtropical forest fragment in Southern Brazil. Different datasets containing hyperspectral visible/near-infrared (VNIR) bands, PPC features, canopy height model (CHM), and other features extracted from hyperspectral data (i.e., texture, vegetation indices-VIs, and minimum noise fraction-MNF) were tested using a support vector machine (SVM) classifier. The results showed that the use of VNIR hyperspectral bands alone reached an overall accuracy (OA) of 57% (Kappa index of 0.53). Adding PPC features to the VNIR hyperspectral bands increased the OA by 11%. The best result was achieved combining VNIR bands, PPC features, CHM, and VIs (OA of 72.4% and Kappa index of 0.70). When only the CHM was added to VNIR bands, the OA increased by 4.2%. Among the hyperspectral features, besides all the VNIR bands and the two VIs (NDVI and PSSR), the first four MNF features and the textural mean of 565 and 679 nm spectral bands were pointed out as more important to discriminate the tree species according to Jeffries&ndash;Matusita (JM) distance. The SVM method proved to be a good classifier for the tree species recognition task, even in the presence of a high number of classes and a small dataset.},
DOI = {10.3390/rs11111338}
}



@Article{rs11111353,
AUTHOR = {Hao, Pengyu and Chen, Zhongxin and Tang, Huajun and Li, Dandan and Li, He},
TITLE = {New Workflow of Plastic-Mulched Farmland Mapping using Multi-Temporal Sentinel-2 data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1353},
URL = {https://www.mdpi.com/2072-4292/11/11/1353},
ISSN = {2072-4292},
ABSTRACT = {Using plastic film mulch on cropland improves crop yield in water-deficient areas, but the use of plastic film on cropland leads to soil pollution. The accurate mapping of plastic-mulched land (PML) is valuable for monitoring the environmental problems caused by the use of plastic film. The drawback of PML mapping is that the detectable period of PML changes among the fields, which causes uncertainty when supervised classification methods are used to identify PML. In this study, a new workflow which merging PML of multiple temporal phases (MTPML) is proposed. For each temporal phase, the &ldquo;possible PML&rdquo; is firstly generated, these &ldquo;temporal possible PML&rdquo; layers are then combined to generate the &ldquo;possible PML&rdquo; layer. Finally, the maximum normalized difference vegetation index (NDVI) of the growing season is used to remove the non-cropland pixels from the &ldquo;possible PML layer,&rdquo; and then generate PML images. When generating &ldquo;temporal possible PML layers,&rdquo; three new PML indices (PMLI with near-infrared bands known as PMLI_NIR, PMLI with shortwave infrared bands known as PMLI_SWIR, and Normalized Difference PMLI known as PMLI_ND) are proposed to separate PML from bare land at plastic film cover stage; and the &ldquo;temporal possible PML layer&rdquo; are identified by the threshold based method. To estimate the performance of the three PML indices, two other approaches, PMLI threshold and Random Forest (RF) are used to generate &ldquo;temporal possible PML layer.&rdquo; Finally, PML images generated from the five MTPML approaches are compared with the image time series supervised classification (SUPML) result. Two study regions, Hengshui (HS) and Guyuan (GY), are used in this study. PML identification models are generated using training samples in HS and the models are used for PML mapping in both study regions. The results showed that MTPML workflow outperformed SUPML with 3%&ndash;5% higher classification accuracy. The three proposed PML indices had higher separability and importance score for bare land and PML discrimination. Among the five approaches used to generate the &ldquo;temporal possible PML layer,&rdquo; PMLI_SWIR is the recommended approach because the PMLI_SWIR threshold approach is easy to implement and the accuracy is only slightly lower than the RF approach. It is notable that no training sample was used in GY and the accuracy of the MTPML approach was higher than 85%, which indicated that the rules proposed in this study are suitable for other study regions.},
DOI = {10.3390/rs11111353}
}



@Article{e21060568,
AUTHOR = {Shekaramiz, Mohammad and Moon, Todd K. and Gunther, Jacob H.},
TITLE = {Exploration vs. Data Refinement via Multiple Mobile Sensors},
JOURNAL = {Entropy},
VOLUME = {21},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {568},
URL = {https://www.mdpi.com/1099-4300/21/6/568},
ISSN = {1099-4300},
ABSTRACT = {We examine the deployment of multiple mobile sensors to explore an unknown region to map regions containing concentration of a physical quantity such as heat, electron density, and so on. The exploration trades off between two desiderata: to continue taking data in a region known to contain the quantity of interest with the intent of refining the measurements vs. taking data in unobserved areas to attempt to discover new regions where the quantity may exist. Making reasonable and practical decisions to simultaneously fulfill both goals of exploration and data refinement seem to be hard and contradictory. For this purpose, we propose a general framework that makes value-laden decisions for the trajectory of mobile sensors. The framework employs a Gaussian process regression model to predict the distribution of the physical quantity of interest at unseen locations. Then, the decision-making on the trajectories of sensors is performed using an epistemic utility controller. An example is provided to illustrate the merit and applicability of the proposed framework.},
DOI = {10.3390/e21060568}
}



@Article{s19112596,
AUTHOR = {Jung, Dae-Hyun and Kim, Hak-Jin and Kim, Hyoung Seok and Choi, Jaeyoung and Kim, Jeong Do and Park, Soo Hyun},
TITLE = {Fusion of Spectroscopy and Cobalt Electrochemistry Data for Estimating Phosphate Concentration in Hydroponic Solution},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2596},
URL = {https://www.mdpi.com/1424-8220/19/11/2596},
ISSN = {1424-8220},
ABSTRACT = {Phosphate is a key element affecting plant growth. Therefore, the accurate determination of phosphate concentration in hydroponic nutrient solutions is essential for providing a balanced set of nutrients to plants within a suitable range. This study aimed to develop a data fusion approach for determining phosphate concentrations in a paprika nutrient solution. As a conventional multivariate analysis approach using spectral data, partial least squares regression (PLSR) and principal components regression (PCR) models were developed using 56 samples for calibration and 24 samples for evaluation. The R2 values of estimation models using PCR and PLSR ranged from 0.44 to 0.64. Furthermore, an estimation model using raw electromotive force (EMF) data from cobalt electrodes gave R2 values of 0.58–0.71. To improve the model performance, a data fusion method was developed to estimate phosphate concentration using near infrared (NIR) spectral and cobalt electrochemical data. Raw EMF data from cobalt electrodes and principle component values from the spectral data were combined. Results of calibration and evaluation tests using an artificial neural network estimation model showed that R2 = 0.90 and 0.89 and root mean square error (RMSE) = 96.70 and 119.50 mg/L, respectively. These values are sufficiently high for application to measuring phosphate concentration in hydroponic solutions.},
DOI = {10.3390/s19112596}
}



@Article{rs11111371,
AUTHOR = {Wang, Yanyu and Zhang, Ke and Tang, Chunlan and Cao, Qiang and Tian, Yongchao and Zhu, Yan and Cao, Weixing and Liu, Xiaojun},
TITLE = {Estimation of Rice Growth Parameters Based on Linear Mixed-Effect Model Using Multispectral Images from Fixed-Wing Unmanned Aerial Vehicles},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1371},
URL = {https://www.mdpi.com/2072-4292/11/11/1371},
ISSN = {2072-4292},
ABSTRACT = {The accurate estimation of aboveground biomass (AGB) and leaf area index (LAI) is critical to characterize crop growth status and predict grain yield. Unmanned aerial vehicle (UAV) -based remote sensing has attracted significant interest due to its high flexibility and easiness of operation. The mixed effect model introduced in this study can capture secondary factors that cannot be captured by standard empirical relationships. The objective of this study was to explore the potential benefit of using a linear mixed-effect (LME) model and multispectral images from a fixed-wing UAV to estimate both AGB and LAI of rice. Field experiments were conducted over two consecutive years (2017&ndash;2018), that involved different N rates, planting patterns and rice cultivars. Images were collected by a compact multispectral camera mounted on a fixed-wing UAV during key rice growth stages. LME, simple regression (SR), artificial neural networks (ANN) and random forests (RF) models were developed relating growth parameters (AGB and LAI) to spectral information. Cultivar (C), growth stage (S) and planting pattern (P) were selected as candidates of random effects for the LME models due to their significant effects on rice growth. Compared to other regression models (SR, ANN and RF), the LME model improved the AGB estimation accuracy for all stage groups to varying degrees: the R2 increased by 0.14&ndash;0.35 and the RMSE decreased by 0.88&ndash;1.80 t ha&minus;1 for the whole season, the R2 increased by 0.07&ndash;0.15 and the RMSE decreased by 0.31&ndash;0.61 t ha&minus;1 for pre-heading stages and the R2 increased by 0.21&ndash;0.53 and the RMSE decreased by 0.72&ndash;1.52 t ha&minus;1 for post-heading stages. Further analysis suggested that the LME model also successfully predicted within the groups when the number of groups was suitable. More importantly, depending on the availability of C, S, P or combinations thereof, mixed effects could lead to an outperformance of baseline retrieval methods (SR, ANN or RF) due to the inclusion of secondary effects. Satisfactory results were also obtained for the LAI estimation while the superiority of the LME model was not as significant as that for AGB estimation. This study demonstrates that the LME model could accurately estimate rice AGB and LAI and fixed-wing UAVs are promising for the monitoring of the crop growth status over large-scale farmland.},
DOI = {10.3390/rs11111371}
}



@Article{rs11111373,
AUTHOR = {Abdulridha, Jaafar and Batuman, Ozgur and Ampatzidis, Yiannis},
TITLE = {UAV-Based Remote Sensing Technique to Detect Citrus Canker Disease Utilizing Hyperspectral Imaging and Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1373},
URL = {https://www.mdpi.com/2072-4292/11/11/1373},
ISSN = {2072-4292},
ABSTRACT = {A remote sensing technique was developed to detect citrus canker in laboratory conditions and was verified in the grove by utilizing an unmanned aerial vehicle (UAV). In the laboratory, a hyperspectral (400&ndash;1000 nm) imaging system was utilized for the detection of citrus canker in several disease development stages (i.e., asymptomatic, early, and late symptoms) on Sugar Belle leaves and immature (green) fruit by using two classification methods: (i) radial basis function (RBF) and (ii) K nearest neighbor (KNN). The same imaging system mounted on an UAV was used to detect citrus canker on tree canopies in the orchard. The overall classification accuracy of the RBF was higher (94%, 96%, and 100%) than the KNN method (94%, 95%, and 96%) for detecting canker in leaves. Among the 31 studied vegetation indices, the water index (WI) and the Modified Chlorophyll Absorption in Reflectance Index (ARI and TCARI 1) more accurately detected canker in laboratory and in orchard conditions, respectively. Immature fruit was not a reliable tissue for early detection of canker. However, the proposed technique successfully distinguished the late stage canker-infected fruit with 92% classification accuracy. The UAV-based technique achieved 100% classification accuracy for identifying healthy and canker-infected trees.},
DOI = {10.3390/rs11111373}
}



@Article{plants8060161,
AUTHOR = {Beckie, Hugh J. and Ashworth, Michael B. and Flower, Ken C.},
TITLE = {Herbicide Resistance Management: Recent Developments and Trends},
JOURNAL = {Plants},
VOLUME = {8},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {161},
URL = {https://www.mdpi.com/2223-7747/8/6/161},
PubMedID = {31181770},
ISSN = {2223-7747},
ABSTRACT = {This review covers recent developments and trends in herbicide-resistant (HR) weed management in agronomic field crops. In countries where input-intensive agriculture is practiced, these developments and trends over the past decade include renewed efforts by the agrichemical industry in herbicide discovery, cultivation of crops with combined (stacked) HR traits, increasing reliance on preemergence vs. postemergence herbicides, breeding for weed-competitive crop cultivars, expansion of harvest weed seed control practices, and advances in site-specific or precision weed management. The unifying framework or strategy underlying these developments and trends is mitigation of viable weed seeds into the soil seed bank and maintaining low weed seed banks to minimize population proliferation, evolution of resistance to additional herbicidal sites of action, and spread. A key question going forward is: how much weed control is enough to consistently achieve the goal of low weed seed banks? The vision for future HR weed management programs must be sustained crop production and profitability with reduced herbicide (particularly glyphosate) dependency.},
DOI = {10.3390/plants8060161}
}



@Article{app9112357,
AUTHOR = {Dematteis, Niccolò and Giordan, Daniele and Allasia, Paolo},
TITLE = {Image Classification for Automated Image Cross-Correlation Applications in the Geosciences},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2357},
URL = {https://www.mdpi.com/2076-3417/9/11/2357},
ISSN = {2076-3417},
ABSTRACT = {In Earth Science, image cross-correlation (ICC) can be used to identify the evolution of active processes. However, this technology can be ineffective, because it is sometimes difficult to visualize certain phenomena, and surface roughness can cause shadows. In such instances, manual image selection is required to select images that are suitably illuminated, and in which visibility is adequate. This impedes the development of an autonomous system applied to ICC in monitoring applications. In this paper, the uncertainty introduced by the presence of shadows is quantitatively analysed, and a method suitable for ICC applications is proposed: The method automatically selects images, and is based on a supervised classification of images using the support vector machine. According to visual and illumination conditions, the images are divided into three classes: (i) No visibility, (ii) direct illumination and (iii) diffuse illumination. Images belonging to the diffuse illumination class are used in cross-correlation processing. Finally, an operative procedure is presented for applying the automated ICC processing chain in geoscience monitoring applications.},
DOI = {10.3390/app9112357}
}



@Article{rs11111380,
AUTHOR = {Abeysinghe, Tharindu and Simic Milas, Anita and Arend, Kristin and Hohman, Breann and Reil, Patrick and Gregory, Andrew and Vázquez-Ortega, Angélica},
TITLE = {Mapping Invasive Phragmites australis in the Old Woman Creek Estuary Using UAV Remote Sensing and Machine Learning Classifiers},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1380},
URL = {https://www.mdpi.com/2072-4292/11/11/1380},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicles (UAV) are increasingly used for spatiotemporal monitoring of invasive plants in coastal wetlands. Early identification of invasive species is necessary in planning, restoring, and managing wetlands. This study assessed the effectiveness of UAV technology to identify invasive Phragmites australis in the Old Woman Creek (OWC) estuary using machine learning (ML) algorithms: Neural network (NN), support vector machine (SVM), and k-nearest neighbor (kNN). The ML algorithms were compared with the parametric maximum likelihood classifier (MLC) using pixel- and object-based methods. Pixel-based NN was identified as the best classifier with an overall accuracy of 94.80% and the lowest error of omission of 1.59%, the outcome desirable for effective eradication of Phragmites. The results were reached combining Sequoia multispectral imagery (green, red, red edge, and near-infrared bands) combined with the canopy height model (CHM) acquired in the mid-growing season and normalized difference vegetation index (NDVI) acquired later in the season. The sensitivity analysis, using various vegetation indices, image texture, CHM, and principal components (PC), demonstrated the impact of various feature layers on the classifiers. The study emphasizes the necessity of a suitable sampling and cross-validation methods, as well as the importance of optimum classification parameters.},
DOI = {10.3390/rs11111380}
}



@Article{s19112640,
AUTHOR = {Xin, Junfeng and Zhong, Jiabao and Yang, Fengru and Cui, Ying and Sheng, Jinlu},
TITLE = {An Improved Genetic Algorithm for Path-Planning of Unmanned Surface Vehicle},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2640},
URL = {https://www.mdpi.com/1424-8220/19/11/2640},
ISSN = {1424-8220},
ABSTRACT = {The genetic algorithm (GA) is an effective method to solve the path-planning problem and help realize the autonomous navigation for and control of unmanned surface vehicles. In order to overcome the inherent shortcomings of conventional GA such as population premature and slow convergence speed, this paper proposes the strategy of increasing the number of offsprings by using the multi-domain inversion. Meanwhile, a second fitness evaluation was conducted to eliminate undesirable offsprings and reserve the most advantageous individuals. The improvement could help enhance the capability of local search effectively and increase the probability of generating excellent individuals. Monte-Carlo simulations for five examples from the library for the travelling salesman problem were first conducted to assess the effectiveness of algorithms. Furthermore, the improved algorithms were applied to the navigation, guidance, and control system of an unmanned surface vehicle in a real maritime environment. Comparative study reveals that the algorithm with multi-domain inversion is superior with a desirable balance between the path length and time-cost, and has a shorter optimal path, a faster convergence speed, and better robustness than the others.},
DOI = {10.3390/s19112640}
}



@Article{app9112389,
AUTHOR = {Zhou, Chengquan and Ye, Hongbao and Xu, Zhifu and Hu, Jun and Shi, Xiaoyan and Hua, Shan and Yue, Jibo and Yang, Guijun},
TITLE = {Estimating Maize-Leaf Coverage in Field Conditions by Applying a Machine Learning Algorithm to UAV Remote Sensing Images},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2389},
URL = {https://www.mdpi.com/2076-3417/9/11/2389},
ISSN = {2076-3417},
ABSTRACT = {Leaf coverage is an indicator of plant growth rate and predicted yield, and thus it is crucial to plant-breeding research. Robust image segmentation of leaf coverage from remote-sensing images acquired by unmanned aerial vehicles (UAVs) in varying environments can be directly used for large-scale coverage estimation, and is a key component of high-throughput field phenotyping. We thus propose an image-segmentation method based on machine learning to extract relatively accurate coverage information from the orthophoto generated after preprocessing. The image analysis pipeline, including dataset augmenting, removing background, classifier training and noise reduction, generates a set of binary masks to obtain leaf coverage from the image. We compare the proposed method with three conventional methods (Hue-Saturation-Value, edge-detection-based algorithm, random forest) and a frontier deep-learning method called DeepLabv3+. The proposed method improves indicators such as Qseg, Sr, Es and mIOU by 15% to 30%. The experimental results show that this approach is less limited by radiation conditions, and that the protocol can easily be implemented for extensive sampling at low cost. As a result, with the proposed method, we recommend using red-green-blue (RGB)-based technology in addition to conventional equipment for acquiring the leaf coverage of agricultural crops.},
DOI = {10.3390/app9112389}
}



@Article{agronomy9060309,
AUTHOR = {Kyere, Isaac and Astor, Thomas and Graß, Rüdiger and Wachendorf, Michael},
TITLE = {Multi-Temporal Agricultural Land-Cover Mapping Using Single-Year and Multi-Year Models Based on Landsat Imagery and IACS Data},
JOURNAL = {Agronomy},
VOLUME = {9},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {309},
URL = {https://www.mdpi.com/2073-4395/9/6/309},
ISSN = {2073-4395},
ABSTRACT = {The spatial distribution and location of crops are necessary information for agricultural planning. The free availability of optical satellites such as Landsat offers an opportunity to obtain this key information. Crop type mapping using satellite data is challenged by its reliance on ground truth data. The Integrated Administration and Control System (IACS) data, submitted by farmers in Europe for subsidy payments, provide a solution to the issue of periodic field data collection. The present study tested the performance of the IACS data in the development of a generalized predictive crop type model, which is independent of the calibration year. Using the IACS polygons as objects, the mean spectral information based on four different vegetation indices and six Landsat bands were extracted for each crop type and used as predictors in a random forest model. Two modelling methods called single-year (SY) and multiple-year (MY) calibration were tested to find out their performance in the prediction of grassland, maize, summer, and winter crops. The independent validation of SY and MY resulted in a mean overall accuracy of 71.5% and 77.3%, respectively. The field-based approach of calibration used in this study dealt with the &lsquo;salt and pepper&rsquo; effects of the pixel-based approach.},
DOI = {10.3390/agronomy9060309}
}



@Article{app9122410,
AUTHOR = {Patel, Maharshi and Jernigan, Shaphan and Richardson, Rob and Ferguson, Scott and Buckner, Gregory},
TITLE = {Autonomous Robotics for Identification and Management of Invasive Aquatic Plant Species},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {2410},
URL = {https://www.mdpi.com/2076-3417/9/12/2410},
ISSN = {2076-3417},
ABSTRACT = {Invasive aquatic plant species can expand rapidly throughout water bodies and cause severely adverse economic and ecological impacts. While mechanical, chemical, and biological methods exist for the identification and treatment of these invasive species, they are manually intensive, inefficient, costly, and can cause collateral ecological damage. To address current deficiencies in aquatic weed management, this paper details the development of a small fleet of fully autonomous boats capable of subsurface hydroacoustic imaging (to scan aquatic vegetation), machine learning (for automated weed identification), and herbicide deployment (for vegetation control). These capabilities aim to minimize manual labor and provide more efficient, safe (reduced chemical exposure to personnel), and timely weed management. Geotagged hydroacoustic imagery of three aquatic plant varieties (Hydrilla, Cabomba, and Coontail) was collected and used to create a software pipeline for subsurface aquatic weed classification and distribution mapping. Employing deep learning, the novel software achieved a classification accuracy of 99.06% after training.},
DOI = {10.3390/app9122410}
}



@Article{su11123278,
AUTHOR = {Voutos, Yorghos and Mylonas, Phivos and Katheniotis, John and Sofou, Anastasia},
TITLE = {A Survey on Intelligent Agricultural Information Handling Methodologies},
JOURNAL = {Sustainability},
VOLUME = {11},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {3278},
URL = {https://www.mdpi.com/2071-1050/11/12/3278},
ISSN = {2071-1050},
ABSTRACT = {The term intelligent agriculture, or smart farming, typically involves the incorporation of computer science and information technologies into the traditional notion of farming. The latter utilizes plain machinery and equipment used for many decades and the only significant improvement made over the years has been the introduction of automation in the process. Still, at the beginning of the new century, there are ways and room for further vast improvements. More specifically, the low cost of rather advanced sensors and small-scale devices, now even connected to the Internet of Things (IoT), allowed them to be introduced in the process and used within agricultural production systems. New and emerging technologies and methodologies, like the utilization of cheap network storage, are expected to advance this development. In this sense, the main goals of this paper may be summarized as follows: (a) To identify, group, and acknowledge the current state-of-the-art research knowledge about intelligent agriculture approaches, (b) to categorize them according to meaningful data sources categories, and (c) to describe current efficient data processing and utilization aspects from the perspective of the main trends in the field.},
DOI = {10.3390/su11123278}
}



@Article{machines7020042,
AUTHOR = {Rivera, Zandra B. and De Simone, Marco C. and Guida, Domenico},
TITLE = {Unmanned Ground Vehicle Modelling in Gazebo/ROS-Based Environments},
JOURNAL = {Machines},
VOLUME = {7},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {42},
URL = {https://www.mdpi.com/2075-1702/7/2/42},
ISSN = {2075-1702},
ABSTRACT = {The fusion of different technologies is the base of the fourth industrial revolution. Companies are encouraged to integrate new tools in their production processes in order to improve working conditions and increase productivity and production quality. The integration between information, communication technologies and industrial automation can create highly flexible production models for products and services that can be customized through real-time interactions between consumer, production and machinery throughout the production process. The future of production, therefore, depends on increasingly intelligent machinery through the use of digital systems. The key elements for future integrated devices are intelligent systems and machines, based on human&ndash;machine interaction and information sharing. To do so, the implementation of shared languages that allow different systems to dialogue in a simple way is necessary. In this perspective, the use of advanced prototyping tools like Open-Source programming systems, the development of more detailed multibody models through the use of CAD software and the use of self-learning techniques will allow for developing a new class of machines capable of revolutionizing our companies. The purpose of this paper is to present a waypoint navigation activity of a custom Wheeled Mobile Robot (WMR) in an available simulated 3D indoor environment by using the Gazebo simulator. Gazebo was developed in 2002 at the University of Southern California. The idea was to create a high-fidelity simulator that gave the possibility to simulate robots in outdoor environments under various conditions. In particular, we wanted to test the high-performance physics Open Dynamics Engine (ODE) and the sensors feature present in Gazebo for prototype development activities. This choice was made for the possibility of emulating not only the system under analysis, but also the world in which the robot will operate. Furthermore, the integration tools available with Solidworks and Matlab-Simulink, well known commercial platforms of modelling and robotics control respectively, are also explored.},
DOI = {10.3390/machines7020042}
}



@Article{s19122703,
AUTHOR = {Okeson, Trent J. and Barrett, Benjamin J. and Arce, Samuel and Vernon, Cory A. and Franke, Kevin W. and Hedengren, John D.},
TITLE = {Achieving Tiered Model Quality in 3D Structure from Motion Models Using a Multi-Scale View-Planning Algorithm for Automated Targeted Inspection},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {2703},
URL = {https://www.mdpi.com/1424-8220/19/12/2703},
ISSN = {1424-8220},
ABSTRACT = {This study presents a novel multi-scale view-planning algorithm for automated targeted inspection using unmanned aircraft systems (UAS). In industrial inspection, it is important to collect the most relevant data to keep processing demands, both human and computational, to a minimum. This study investigates the viability of automated targeted multi-scale image acquisition for Structure from Motion (SfM)-based infrastructure modeling. A traditional view-planning approach for SfM is extended to a multi-scale approach, planning for targeted regions of high, medium, and low priority. The unmanned aerial vehicle (UAV) can traverse the entire aerial space and facilitates collection of an optimized set of views, both close to and far away from areas of interest. The test case for field validation is the Tibble Fork Dam in Utah. Using the targeted multi-scale flight planning, a UAV automatically flies a tiered inspection using less than 25% of the number of photos needed to model the entire dam at high-priority level. This results in approximately 75% reduced flight time and model processing load, while still maintaining high model accuracy where needed. Models display stepped improvement in visual clarity and SfM reconstruction integrity by priority level, with the higher priority regions more accurately modeling smaller and finer features. A resolution map of the final tiered model is included. While this study focuses on multi-scale view planning for optical sensors, the methods potentially extend to other remote sensors, such as aerial LiDAR.},
DOI = {10.3390/s19122703}
}



@Article{s19122722,
AUTHOR = {Higa, Kyota and Iwamoto, Kota},
TITLE = {Robust Shelf Monitoring Using Supervised Learning for Improving On-Shelf Availability in Retail Stores},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {2722},
URL = {https://www.mdpi.com/1424-8220/19/12/2722},
ISSN = {1424-8220},
ABSTRACT = {This paper proposes a method to robustly monitor shelves in retail stores using supervised learning for improving on-shelf availability. To ensure high on-shelf availability, which is a key factor for improving profits in retail stores, we focus on understanding changes in products regarding increases/decreases in product amounts on the shelves. Our method first detects changed regions of products in an image by using background subtraction followed by moving object removal. It then classifies the detected change regions into several classes representing the actual changes on the shelves, such as &ldquo;product taken (decrease)&rdquo; and &ldquo;product replenished/returned (increase)&rdquo;, by supervised learning using convolutional neural networks. It finally updates the shelf condition representing the presence/absence of products using classification results and computes the product amount visible in the image as on-shelf availability using the updated shelf condition. Three experiments were conducted using two videos captured from a surveillance camera on the ceiling in a real store. Results of the first and second experiments show the effectiveness of the product change classification in our method. Results of the third experiment show that our method achieves a success rate of 89.6% for on-shelf availability when an error margin is within one product. With high accuracy, store clerks can maintain high on-shelf availability, enabling retail stores to increase profits.},
DOI = {10.3390/s19122722}
}



@Article{rs11121443,
AUTHOR = {Yao, Huang and Qin, Rongjun and Chen, Xiaoyu},
TITLE = {Unmanned Aerial Vehicle for Remote Sensing Applications—A Review},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {1443},
URL = {https://www.mdpi.com/2072-4292/11/12/1443},
ISSN = {2072-4292},
ABSTRACT = {The unmanned aerial vehicle (UAV) sensors and platforms nowadays are being used in almost every application (e.g., agriculture, forestry, and mining) that needs observed information from the top or oblique views. While they intend to be a general remote sensing (RS) tool, the relevant RS data processing and analysis methods are still largely ad-hoc to applications. Although the obvious advantages of UAV data are their high spatial resolution and flexibility in acquisition and sensor integration, there is in general a lack of systematic analysis on how these characteristics alter solutions for typical RS tasks such as land-cover classification, change detection, and thematic mapping. For instance, the ultra-high-resolution data (less than 10 cm of Ground Sampling Distance (GSD)) bring more unwanted classes of objects (e.g., pedestrian and cars) in land-cover classification; the often available 3D data generated from photogrammetric images call for more advanced techniques for geometric and spectral analysis. In this paper, we perform a critical review on RS tasks that involve UAV data and their derived products as their main sources including raw perspective images, digital surface models, and orthophotos. In particular, we focus on solutions that address the &ldquo;new&rdquo; aspects of the UAV data including (1) ultra-high resolution; (2) availability of coherent geometric and spectral data; and (3) capability of simultaneously using multi-sensor data for fusion. Based on these solutions, we provide a brief summary of existing examples of UAV-based RS in agricultural, environmental, urban, and hazards assessment applications, etc., and by discussing their practical potentials, we share our views in their future research directions and draw conclusive remarks.},
DOI = {10.3390/rs11121443}
}



@Article{s19122734,
AUTHOR = {Zou, Xiaojun and Lian, Baowang and Wu, Peng},
TITLE = {Fault Identification Ability of a Robust Deeply Integrated GNSS/INS System Assisted by Convolutional Neural Networks},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {2734},
URL = {https://www.mdpi.com/1424-8220/19/12/2734},
ISSN = {1424-8220},
ABSTRACT = {The problem of fault propagation which exists in the deeply integrated GNSS (Global Navigation Satellite System)/INS (Inertial Navigation System) system makes it difficult to identify faults. Once a fault occurs, system performance will be degraded due to the inability to identify and isolate the fault accurately. After analyzing the causes of fault propagation and the difficulty of fault identification, maintaining correct navigation solution is found to be the key to prevent fault propagation from occurring. In order to solve the problem, a novel robust algorithm based on convolutional neural network (CNN) is proposed. The optimal expansion factor of the robust algorithm is obtained adaptively by utilizing CNN, thus the adverse effect of fault on navigation solution can be reduced as much as possible. At last, the fault identification ability is verified by two types of experiments: artificial fault injection and outdoor occlusion. Experiment results show that the proposed robust algorithm which can successfully suppress the fault propagation is an effective solution. The accuracy of fault identification is increased by more than 20% compared with that before improvement, and the robustness of deep GNSS/INS integration is also improved.},
DOI = {10.3390/s19122734}
}



@Article{rs11121455,
AUTHOR = {Wei, Lifei and Huang, Can and Zhong, Yanfei and Wang, Zhou and Hu, Xin and Lin, Liqun},
TITLE = {Inland Waters Suspended Solids Concentration Retrieval Based on PSO-LSSVM for UAV-Borne Hyperspectral Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {1455},
URL = {https://www.mdpi.com/2072-4292/11/12/1455},
ISSN = {2072-4292},
ABSTRACT = {Suspended solids concentration (SSC) is an important indicator of the degree of water pollution. However, when using an empirical or semi-empirical model adapted to some of the inland waters to estimate SSC on unmanned aerial vehicle (UAV)-borne hyperspectral images, the accuracy is often not sufficient. Thus, in this study, we attempted to use the particle swarm optimization (PSO) algorithm to find the optimal parameters of the least-squares support vector machine (LSSVM) model for the quantitative inversion of SSC. A reservoir and a polluted riverway were selected as the study areas. The spectral data of the 36-point and 29-point 400&ndash;900 nm wavelength range on the UAV-borne images were extracted. Compared with the semi-empirical model, the random forest (RF) algorithm and the competitive adaptive reweighted sampling (CARS) algorithm combined with partial least squares (PLS), the accuracy of the PSO-LSSVM algorithm in predicting the SSC was significantly improved. The training samples had a coefficient of determination (     R 2     ) of 0.98, a root mean square error (RMSE) of 0.68 mg/L, and a mean absolute percentage error (MAPE) of 12.66% at the reservoir. For the polluted riverway, PSO-LSSVM also performed well. Finally, the established SSC inversion model was applied to UAV-borne hyperspectral remote sensing (HRS) images. The results confirmed that the distribution of the predicted SSC was consistent with the observed results in the field, which proves that PSO-LSSVM is a feasible approach for the SSC inversion of UAV-borne HRS images.},
DOI = {10.3390/rs11121455}
}



@Article{s19122775,
AUTHOR = {Munaye, Yirga Yayeh and Lin, Hsin-Piao and Adege, Abebe Belay and Tarekegn, Getaneh Berie},
TITLE = {UAV Positioning for Throughput Maximization Using Deep Learning Approaches},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {2775},
URL = {https://www.mdpi.com/1424-8220/19/12/2775},
ISSN = {1424-8220},
ABSTRACT = {The use of unmanned aerial vehicles (UAVs) as a communication platform has great practical importance for future wireless networks, especially for on-demand deployment for temporary and emergency conditions. The user throughput estimation in a wireless system depends on the data traffic load and the available capacity to support that load. In UAV-assisted communication, the position of the UAV is one major factor that affects the capacity available to the data flows being served. This study applies multi-layer perceptron (MLP) and long short term memory (LSTM) approaches to determine the position of a UAV that maximizes the overall system performance and user throughput. To analyze and evaluate the system performance, we apply the hybrid of MLP-LSTM for classification regression tasks and K-means algorithms for automatic clustering of classes. The implementation of our work is done through TensorFlow packages. The performance of our proposed system is compared with other approaches to give accurate and novel results for both classification and regression tasks of the user throughput maximization and UAV positioning. According to the results, 98% of the user throughput maximization accuracy is correctly classified. Moreover, the UAV positioning provides accuracy levels of 94.73%, 98.33%, and 99.53% for original datasets (scenario 1), reduced features on the estimated values of user throughput at each grid point (scenario 2), and reduced feature datasets collected on different days and grid points achieved maximum throughput (scenario 3), respectively.},
DOI = {10.3390/s19122775}
}



@Article{rs11121468,
AUTHOR = {Vanbrabant, Yasmin and Tits, Laurent and Delalieux, Stephanie and Pauly, Klaas and Verjans, Wim and Somers, Ben},
TITLE = {Multitemporal Chlorophyll Mapping in Pome Fruit Orchards from Remotely Piloted Aircraft Systems},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {1468},
URL = {https://www.mdpi.com/2072-4292/11/12/1468},
ISSN = {2072-4292},
ABSTRACT = {Early and precise spatio-temporal monitoring of tree vitality is key for steering management decisions in pome fruit orchards. Spaceborne remote sensing instruments face a tradeoff between spatial and spectral resolution, while manned aircraft sensor-platform systems are very expensive. In order to address the shortcomings of these platforms, this study investigates the potential of Remotely Piloted Aircraft Systems (RPAS) to facilitate rapid, low cost, and flexible chlorophyll monitoring. Due to the complexity of orchard scenery a robust chlorophyll retrieval model on RPAS level has not yet been developed. In this study, specific focus therefore lies on evaluating the sensitivity of retrieval models to confounding factors. For this study, multispectral and hyperspectral imagery was collected over pome fruit orchards. Sensitivities of both univariate and multivariate retrieval models were demonstrated under different species, phenology, shade, and illumination scenes. Results illustrate that multivariate models have a significantly higher accuracy than univariate models as the former provide accuracies for the canopy chlorophyll content retrieval of R2 = 0.80 and Relative Root Mean Square Error (RRMSE) = 12% for the hyperspectral sensor. Random forest regression on multispectral imagery (R2 &gt; 0.9 for May, June, July, and August, and R2 = 0.5 for October) and hyperspectral imagery (0.6 &lt; R2 &lt; 0.9) led to satisfactory high and consistent accuracies for all months.},
DOI = {10.3390/rs11121468}
}



@Article{s19122829,
AUTHOR = {Yu, Li and Tian, Yugang and Wu, Wei},
TITLE = {A Dark Target Detection Method Based on the Adjacency Effect: A Case Study on Crack Detection},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {2829},
URL = {https://www.mdpi.com/1424-8220/19/12/2829},
ISSN = {1424-8220},
ABSTRACT = {Dark target detection is important for engineering applications but the existing methods do not consider the imaging environment of dark targets, such as the adjacency effect. The adjacency effect will affect the quantitative applications of remote sensing, especially for high contrast images and images with ever-increasing resolution. Further, most studies have focused on how to eliminate the adjacency effect and there is almost no research about the application of the adjacency effect. However, the adjacency effect leads to some unique characteristics for the dark target surrounded by a bright background. This paper utilizes these characteristics to assist in the detection of the dark object, and the low-high threshold detection strategy and the adaptive threshold selection method under the assumption of Gaussian distribution are designed. Meanwhile, preliminary case experiments are carried out on the crack detection of concrete slope protection. Finally, the experiment results show that it is feasible to utilize the adjacency effect for dark target detection.},
DOI = {10.3390/s19122829}
}



@Article{rs11121505,
AUTHOR = {Zhang, Heng and Eziz, Anwar and Xiao, Jian and Tao, Shengli and Wang, Shaopeng and Tang, Zhiyao and Zhu, Jiangling and Fang, Jingyun},
TITLE = {High-Resolution Vegetation Mapping Using eXtreme Gradient Boosting Based on Extensive Features},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {1505},
URL = {https://www.mdpi.com/2072-4292/11/12/1505},
ISSN = {2072-4292},
ABSTRACT = {Accurate mapping of vegetation is a premise for conserving, managing, and sustainably using vegetation resources, especially in conditions of intensive human activities and accelerating global changes. However, it is still challenging to produce high-resolution multiclass vegetation map in high accuracy, due to the incapacity of traditional mapping techniques in distinguishing mosaic vegetation classes with subtle differences and the paucity of fieldwork data. This study created a workflow by adopting a promising classifier, extreme gradient boosting (XGBoost), to produce accurate vegetation maps of two strikingly different cases (the Dzungarian Basin in China and New Zealand) based on extensive features and abundant vegetation data. For the Dzungarian Basin, a vegetation map with seven vegetation types, 17 subtypes, and 43 associations was produced with an overall accuracy of 0.907, 0.801, and 0.748, respectively. For New Zealand, a map of 10 habitats and a map of 41 vegetation classes were produced with 0.946, and 0.703 overall accuracy, respectively. The workflow incorporating simplified field survey procedures outperformed conventional field survey and remote sensing based methods in terms of accuracy and efficiency. In addition, it opens a possibility of building large-scale, high-resolution, and timely vegetation monitoring platforms for most terrestrial ecosystems worldwide with the aid of Google Earth Engine and citizen science programs.},
DOI = {10.3390/rs11121505}
}



@Article{rs11121507,
AUTHOR = {Cardenal, Javier and Fernández, Tomás and Pérez-García, José Luis and Gómez-López, José Miguel},
TITLE = {Measurement of Road Surface Deformation Using Images Captured from UAVs},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {1507},
URL = {https://www.mdpi.com/2072-4292/11/12/1507},
ISSN = {2072-4292},
ABSTRACT = {This paper presents a methodology for measuring road surface deformation due to terrain instability processes. The methodology is based on ultra-high resolution images acquired from unmanned aerial vehicles (UAVs). Flights are georeferenced by means of Structure from Motion (SfM) techniques. Dense point clouds, obtained using the multiple-view stereo (MVS) approach, are used to generate digital surface models (DSM) and high resolution orthophotographs (0.02 m GSD). The methodology has been applied to an unstable area located in La Guardia (Jaen, Southern Spain), where an active landslide was identified. This landslide affected some roads and accesses to a highway at the landslide foot. The detailed road deformation was monitored between 2012 and 2015 by means of eleven UAV flights of ultrahigh resolution covering an area of about 260 m × 90 m. The accuracy of the analysis has been established in 0.02 ± 0.01 m in XY and 0.04 ± 0.02 m in Z. Large deformations in the order of two meters were registered in the total period analyzed that resulted in maximum average rates of 0.62 m/month in the unstable area. Some boundary conditions were considered because of the low required flying height (&lt;50 m above ground level) in order to achieve a suitable image GSD, the fast landslide dynamic, continuous maintenance works on the affected roads and dramatic seasonal vegetation changes throughout the monitoring period. Finally, we have analyzed the relation of displacements to rainfalls in the area, finding a significant correlation between the two variables, as well as two different reactivation episodes.},
DOI = {10.3390/rs11121507}
}



@Article{app9132583,
AUTHOR = {Sheu, Bor-Horng and Chiu, Chih-Cheng and Lu, Wei-Ting and Huang, Chu-I and Chen, Wen-Ping},
TITLE = {Development of UAV Tracing and Coordinate Detection Method Using a Dual-Axis Rotary Platform for an Anti-UAV System},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {2583},
URL = {https://www.mdpi.com/2076-3417/9/13/2583},
ISSN = {2076-3417},
ABSTRACT = {The rapid development of unmanned aerial vehicles (UAVs) has led to many security problems. In order to prevent UAVs from invading restricted areas or famous buildings, an anti-UAV defense system (AUDS) has been developed and become a research topic of interest. Topics under research in relation to this include electromagnetic interference guns for UAVs, high-energy laser guns, US military net warheads, and AUDSs with net guns. However, these AUDSs use either manual aiming or expensive radar to trace drones. This research proposes a dual-axis mechanism with UAVs automatic tracing. The tracing platform uses visual image processing technology to trace and lock the dynamic displacement of a drone. When a target UAV is locked, the system uses a nine-axis attitude meter and laser rangers to measure its flight altitude and calculates its longitude and latitude coordinates through sphere coordinates to provide drone monitoring for further defense or attack missions. Tracing tests of UAV flights in the air were carried out using a DJI MAVIC UAV at a height of 30 m to 100 m. It was set up for drone image capture and visual identification for tracing under various weather conditions by a thermal imaging camera and a full-color camera, respectively. When there was no cloud during the daytime, the images acquired by the thermal imaging camera and full-color camera provide a high-quality image identification result. However, under dark weather, black clouds will emit radiant energy and seriously affect the capture of images by a thermal imaging camera. When there is no cloud at night, the thermal imaging camera performs well in drone image capture. When the drone is traced and locked, the system can effectively obtain the flight altitude and longitude and latitude coordinate values.},
DOI = {10.3390/app9132583}
}



@Article{rs11131534,
AUTHOR = {Park, John Y. and Muller-Landau, Helene C. and Lichstein, Jeremy W. and Rifai, Sami W. and Dandois, Jonathan P. and Bohlman, Stephanie A.},
TITLE = {Quantifying Leaf Phenology of Individual Trees and Species in a Tropical Forest Using Unmanned Aerial Vehicle (UAV) Images},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {1534},
URL = {https://www.mdpi.com/2072-4292/11/13/1534},
ISSN = {2072-4292},
ABSTRACT = {Tropical forests exhibit complex but poorly understood patterns of leaf phenology. Understanding species- and individual-level phenological patterns in tropical forests requires datasets covering large numbers of trees, which can be provided by Unmanned Aerial Vehicles (UAVs). In this paper, we test a workflow combining high-resolution RGB images (7 cm/pixel) acquired from UAVs with a machine learning algorithm to monitor tree and species leaf phenology in a tropical forest in Panama. We acquired images for 34 flight dates over a 12-month period. Crown boundaries were digitized in images and linked with forest inventory data to identify species. We evaluated predictions of leaf cover from different models that included up to 14 image features extracted for each crown on each date. The models were trained and tested with visual estimates of leaf cover from 2422 images from 85 crowns belonging to eight species spanning a range of phenological patterns. The best-performing model included both standard color metrics, as well as texture metrics that quantify within-crown variation, with r2 of 0.84 and mean absolute error (MAE) of 7.8% in 10-fold cross-validation. In contrast, the model based only on the widely-used Green Chromatic Coordinate (GCC) index performed relatively poorly (r2 = 0.52, MAE = 13.6%). These results highlight the utility of texture features for image analysis of tropical forest canopies, where illumination changes may diminish the utility of color indices, such as GCC. The algorithm successfully predicted both individual-tree and species patterns, with mean r2 of 0.82 and 0.89 and mean MAE of 8.1% and 6.0% for individual- and species-level analyses, respectively. Our study is the first to develop and test methods for landscape-scale UAV monitoring of individual trees and species in diverse tropical forests. Our analyses revealed undescribed patterns of high intraspecific variation and complex leaf cover changes for some species.},
DOI = {10.3390/rs11131534}
}



@Article{drones3030053,
AUTHOR = {Buters, Todd and Belton, David and Cross, Adam},
TITLE = {Seed and Seedling Detection Using Unmanned Aerial Vehicles and Automated Image Classification in the Monitoring of Ecological Recovery},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {53},
URL = {https://www.mdpi.com/2504-446X/3/3/53},
ISSN = {2504-446X},
ABSTRACT = {Monitoring is a crucial component of ecological recovery projects, yet it can be challenging to achieve at scale and during the formative stages of plant establishment. The monitoring of seeds and seedlings, which represent extremely vulnerable stages in the plant life cycle, is particularly challenging due to their diminutive size and lack of distinctive morphological characteristics. Counting and classifying seedlings to species level can be time-consuming and extremely difficult, and there is a need for technological approaches offering restoration practitioners with fine-resolution, rapid and scalable plant-based monitoring solutions. Unmanned aerial vehicles (UAVs) offer a novel approach to seed and seedling monitoring, as the combination of high-resolution sensors and low flight altitudes allow for the detection and monitoring of small objects, even in challenging terrain and in remote areas. This study utilized low-altitude UAV imagery and an automated object-based image analysis software to detect and count target seeds and seedlings from a matrix of non-target grasses across a variety of substrates reflective of local restoration substrates. Automated classification of target seeds and target seedlings was achieved at accuracies exceeding 90% and 80%, respectively, although the classification accuracy decreased with increasing flight altitude (i.e., decreasing image resolution) and increasing background surface complexity (increasing percentage cover of non-target grasses and substrate surface texture). Results represent the first empirical evidence that small objects such as seeds and seedlings can be classified from complex ecological backgrounds using automated processes from UAV-imagery with high levels of accuracy. We suggest that this novel application of UAV use in ecological monitoring offers restoration practitioners an excellent tool for rapid, reliable and non-destructive early restoration trajectory assessment.},
DOI = {10.3390/drones3030053}
}



@Article{rs11131540,
AUTHOR = {Wang, Yanjun and Chen, Qi and Zhu, Qing and Liu, Lin and Li, Chaokui and Zheng, Dunyong},
TITLE = {A Survey of Mobile Laser Scanning Applications and Key Techniques over Urban Areas},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {1540},
URL = {https://www.mdpi.com/2072-4292/11/13/1540},
ISSN = {2072-4292},
ABSTRACT = {Urban planning and management need accurate three-dimensional (3D) data such as light detection and ranging (LiDAR) point clouds. The mobile laser scanning (MLS) data, with up to millimeter-level accuracy and point density of a few thousand points/m2, have gained increasing attention in urban applications. Substantial research has been conducted in the past decade. This paper conducted a comprehensive survey of urban applications and key techniques based on MLS point clouds. We first introduce the key characteristics of MLS systems and the corresponding point clouds, and present the challenges and opportunities of using the data. Next, we summarize the current applications of using MLS over urban areas, including transportation infrastructure mapping, building information modeling, utility surveying and mapping, vegetation inventory, and autonomous vehicle driving. Then, we review common key issues for processing and analyzing MLS point clouds, including classification methods, object recognition, data registration, data fusion, and 3D city modeling. Finally, we discuss the future prospects for MLS technology and urban applications.},
DOI = {10.3390/rs11131540}
}



@Article{rs11131550,
AUTHOR = {Koch, Tobias and Körner, Marco and Fraundorfer, Friedrich},
TITLE = {Automatic and Semantically-Aware 3D UAV Flight Planning for Image-Based 3D Reconstruction},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {1550},
URL = {https://www.mdpi.com/2072-4292/11/13/1550},
ISSN = {2072-4292},
ABSTRACT = {Small-scaled unmanned aerial vehicles (UAVs) emerge as ideal image acquisition platforms due to their high maneuverability even in complex and tightly built environments. The acquired images can be utilized to generate high-quality 3D models using current multi-view stereo approaches. However, the quality of the resulting 3D model highly depends on the preceding flight plan which still requires human expert knowledge, especially in complex urban and hazardous environments. In terms of safe flight plans, practical considerations often define prohibited and restricted airspaces to be accessed with the vehicle. We propose a 3D UAV path planning framework designed for detailed and complete small-scaled 3D reconstructions considering the semantic properties of the environment allowing for user-specified restrictions on the airspace. The generated trajectories account for the desired model resolution and the demands on a successful photogrammetric reconstruction. We exploit semantics from an initial flight to extract the target object and to define restricted and prohibited airspaces which have to be avoided during the path planning process to ensure a safe and short UAV path, while still aiming to maximize the object reconstruction quality. The path planning problem is formulated as an orienteering problem and solved via discrete optimization exploiting submodularity and photogrammetrical relevant heuristics. An evaluation of our method on a customized synthetic scene and on outdoor experiments suggests the real-world capability of our methodology by providing feasible, short and safe flight plans for the generation of detailed 3D reconstruction models.},
DOI = {10.3390/rs11131550}
}



@Article{app9132656,
AUTHOR = {Zhang, Hanxue and Shen, Chong and Chen, Xuemei and Cao, Huiliang and Zhao, Donghua and Huang, Haoqian and Guo, Xiaoting},
TITLE = {An Enhanced Fusion Strategy for Reliable Attitude Measurement Utilizing Vision and Inertial Sensors},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {2656},
URL = {https://www.mdpi.com/2076-3417/9/13/2656},
ISSN = {2076-3417},
ABSTRACT = {In this paper, we present a radial basis function (RBF) and cubature Kalman filter (CKF) based enhanced fusion strategy for vision and inertial integrated attitude measurement for sampling frequency discrepancy and divergence. First, the multi-frequency problem of the integrated system and the reason for attitude divergence are analyzed. Second, the filter equation and attitude differential equation are constructed to calculate attitudes separately in time series when visual and inertial data are available or when there are only inertial data. Third, attitude errors between inertial and vision are sent to the input layer of RBF for training. After this, through the activation function of the hidden layer, the errors are transferred to the output layer for weighting the sums, and the training model is established. To overcome the problem of divergence inherent in a multi-frequency system, the well-trained RBF, which can output the attitude errors, is utilized to compensate the attitudes calculated by pure inertial data. Finally, semi-physical simulation experiments under different scenarios are performed to validate the effectiveness and superiority of the proposed scheme in accurate attitude measurements and enhanced anti-divergence capability.},
DOI = {10.3390/app9132656}
}



@Article{act8030053,
AUTHOR = {Kidd, Robert},
TITLE = {Artificial Immune Systems: An Overview for Faulting Actuators},
JOURNAL = {Actuators},
VOLUME = {8},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {53},
URL = {https://www.mdpi.com/2076-0825/8/3/53},
ISSN = {2076-0825},
ABSTRACT = {This paper reviews Artificial Immune Systems (AIS) that can be implemented to compensate for actuators that are in a faulted state or operating abnormally. Eventually, all actuators will fail or wear out, and these actuator faults must be managed if a system is to operate safely. The AIS are adaptive algorithms which are inherently well-suited to these situations by treating these faults as infections that must be combated. However, the computational intensity of these algorithms has caused them to have limited success in real-time situations. With the advent of distributed and cloud-based computing these algorithms have begun to be feasible for diagnosing faulted actuators and then generating compensating controllers in near-real-time. To encourage the application of AIS to these situations, this work presents research for the fundamental operating principles of AIS, their applications, and a brief case-study on their applicability to fault compensation by considering an overactuated rover with four independent drive wheels and independent front and rear steering.},
DOI = {10.3390/act8030053}
}



@Article{rs11131554,
AUTHOR = {Zhang, Xin and Han, Liangxiu and Dong, Yingying and Shi, Yue and Huang, Wenjiang and Han, Lianghao and González-Moreno, Pablo and Ma, Huiqin and Ye, Huichun and Sobeih, Tam},
TITLE = {A Deep Learning-Based Approach for Automated Yellow Rust Disease Detection from High-Resolution Hyperspectral UAV Images},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {1554},
URL = {https://www.mdpi.com/2072-4292/11/13/1554},
ISSN = {2072-4292},
ABSTRACT = {Yellow rust in winter wheat is a widespread and serious fungal disease, resulting in significant yield losses globally. Effective monitoring and accurate detection of yellow rust are crucial to ensure stable and reliable wheat production and food security. The existing standard methods often rely on manual inspection of disease symptoms in a small crop area by agronomists or trained surveyors. This is costly, time consuming and prone to error due to the subjectivity of surveyors. Recent advances in unmanned aerial vehicles (UAVs) mounted with hyperspectral image sensors have the potential to address these issues with low cost and high efficiency. This work proposed a new deep convolutional neural network (DCNN) based approach for automated crop disease detection using very high spatial resolution hyperspectral images captured with UAVs. The proposed model introduced multiple Inception-Resnet layers for feature extraction and was optimized to establish the most suitable depth and width of the network. Benefiting from the ability of convolution layers to handle three-dimensional data, the model used both spatial and spectral information for yellow rust detection. The model was calibrated with hyperspectral imagery collected by UAVs in five different dates across a whole crop cycle over a well-controlled field experiment with healthy and rust infected wheat plots. Its performance was compared across sampling dates and with random forest, a representative of traditional classification methods in which only spectral information was used. It was found that the method has high performance across all the growing cycle, particularly at late stages of the disease spread. The overall accuracy of the proposed model (0.85) was higher than that of the random forest classifier (0.77). These results showed that combining both spectral and spatial information is a suitable approach to improving the accuracy of crop disease detection with high resolution UAV hyperspectral images.},
DOI = {10.3390/rs11131554}
}



@Article{drones3030054,
AUTHOR = {Nuijten, Rik J. G. and Kooistra, Lammert and De Deyn, Gerlinde B.},
TITLE = {Using Unmanned Aerial Systems (UAS) and Object-Based Image Analysis (OBIA) for Measuring Plant-Soil Feedback Effects on Crop Productivity},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {54},
URL = {https://www.mdpi.com/2504-446X/3/3/54},
ISSN = {2504-446X},
ABSTRACT = {Unmanned aerial system (UAS) acquired high-resolution optical imagery and object-based image analysis (OBIA) techniques have the potential to provide spatial crop productivity information. In general, plant-soil feedback (PSF) field studies are time-consuming and laborious which constrain the scale at which these studies can be performed. Development of non-destructive methodologies is needed to enable research under actual field conditions and at realistic spatial and temporal scales. In this study, the influence of six winter cover crop (WCC) treatments (monocultures Raphanus sativus, Lolium perenne, Trifolium repens, Vicia sativa and two species mixtures) on the productivity of succeeding endive (Cichorium endivia) summer crop was investigated by estimating crop volume. A three-dimensional surface and terrain model were photogrammetrically reconstructed from UAS imagery, acquired on 1 July 2015 in Wageningen, the Netherlands. Multi-resolution image segmentation (MIRS) and template matching algorithms were used in an integrated workflow to detect individual crops (accuracy = 99.8%) and delineate C. endivia crop covered area (accuracy = 85.4%). Mean crop area (R = 0.61) and crop volume (R = 0.71) estimates had strong positive correlations with in situ measured dry biomass. Productivity differences resulting from the WCC treatments were greater for estimated crop volume in comparison to in situ biomass, the legacy of Raphanus was most beneficial for estimated crop volume. The perennial ryegrass L. perenne treatment resulted in a significantly lower production of C. endivia. The developed workflow has potential for PSF studies as well as precision farming due to its flexibility and scalability. Our findings provide insight into the potential of UAS for determining crop productivity on a large scale.},
DOI = {10.3390/drones3030054}
}



@Article{sym11070842,
AUTHOR = {Ryu, June-Woo and Pham, Quoc-Viet and Luan, Huynh N. T. and Hwang, Won-Joo and Kim, Jong-Deok and Lee, Jung-Tae},
TITLE = {Multi-Access Edge Computing Empowered Heterogeneous Networks: A Novel Architecture and Potential Works},
JOURNAL = {Symmetry},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {842},
URL = {https://www.mdpi.com/2073-8994/11/7/842},
ISSN = {2073-8994},
ABSTRACT = {One of the most promising approaches to address the mismatch between computation- intensive applications and computation-limited end devices is multi-access edge computing (MEC). To overcome the rapid increase in traffic volume and offload the traffic from macrocells, a massive number of small cells have been deployed, so-called heterogeneous networks (HetNets). Strongly motivated by the close integration of MEC and HetNets, in this paper, we propose an envisioned architecture of MEC-empowered HetNets, where both wireless and wired backhaul solutions are supported, flying base stations (BSs) can be equipped with MEC servers, and mobile users (MUs) need both communication and computation resources for their computationally heavy tasks. Subsequently, we provide the research progress summary of task offloading and resource allocation in the proposed MEC-empowered unmanned aerial vehicle (UAV)-assisted heterogeneous networks. We complete this article by spotlighting key challenges and open future directives for researches.},
DOI = {10.3390/sym11070842}
}



@Article{su11133637,
AUTHOR = {Lee, SangSik and Jeong, YiNa and Son, SuRak and Lee, ByungKwan},
TITLE = {A Self-Predictable Crop Yield Platform (SCYP) Based On Crop Diseases Using Deep Learning},
JOURNAL = {Sustainability},
VOLUME = {11},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {3637},
URL = {https://www.mdpi.com/2071-1050/11/13/3637},
ISSN = {2071-1050},
ABSTRACT = {This paper proposes a self-predictable crop yield platform (SCYP) based on crop diseases using deep learning that collects weather information (temperature, humidity, sunshine, precipitation, etc.) and farm status information (harvest date, disease information, crop status, ground temperature, etc.), diagnoses crop diseases by using convolutional neural network (CNN), and predicts crop yield based on factors such as climate change, crop diseases, and others by using artificial neural network (ANN). The SCYP consists of an image preprocessing module (IPM) to determine crop diseases through the Google Vision API and image resizing, a crop disease diagnosis module (CDDM) based on CNN to diagnose the types and extent of crop diseases through photographs, and a crop yield prediction module (CYPM) based on ANN by using information of crop diseases, remaining time until harvest (based on the date), current temperature, humidity and precipitation (amount of snowfall) in the area, sunshine amount, ground temperature, atmospheric pressure, moisture evaporation in the ground, etc. Four experiments were conducted to verify the efficiency of the SCYP. In the CDMM, the accuracy and operation time of each model were measured using three neural network models: CNN, region-CNN(R-CNN), and you only look once (YOLO). In the CYPM, rectified linear unit (ReLU), Sigmoid, and Step activation functions were compared to measure ANN accuracy. The accuracy of CNN was about 3.5% higher than that of R-CNN and about 5.4% higher than that of YOLO. The operation time of CNN was about 37 s less than that of R-CNN and about 72 s less than that of YOLO. The CDDM had slightly less operation time, but in this paper, we prefer accuracy over operation time to diagnose crop diseases efficiently and accurately. When the activation function of the ANN used in the CYPM was ReLU, the accuracy of the ANN was 2% higher than that of Sigmoid and 7% higher than that of Step. The CYPM prediction was about 34% more accurate when using multiple diseases than when not using them. Therefore, the SCYP can predict farm yields more accurately than traditional methods.},
DOI = {10.3390/su11133637}
}



@Article{agronomy9070354,
AUTHOR = {Zhang, Xiuhua and Derival, Magda and Albrecht, Ute and Ampatzidis, Yiannis},
TITLE = {Evaluation of a Ground Penetrating Radar to Map the Root Architecture of HLB-Infected Citrus Trees},
JOURNAL = {Agronomy},
VOLUME = {9},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {354},
URL = {https://www.mdpi.com/2073-4395/9/7/354},
ISSN = {2073-4395},
ABSTRACT = {This paper investigates the influences of several limiting factors on the performance of ground penetrating radar (GPR) in accurately detecting huanglongbing (HLB)-infected citrus roots and determining their main structural characteristics. First, single-factor experiments were conducted to evaluate GPR performance. The factors that were evaluated were (i) root diameter; (ii) root moisture level; (iii) root depth; (iv) root spacing; (v) survey angle; and, (vi) soil moisture level. Second, two multi-factor field experiments were conducted to evaluate the performance of the GPR in complex orchard environments. The GPR generated a hyperbola in the radar profile upon root detection; the diameter of the root was successfully determined according to the width of the hyperbola when the roots were larger than 6 mm in diameter. The GPR also distinguished live from dead roots, a capability that is indispensable for studying the effects of soil-borne and other diseases on the citrus tree root system. The GPR can distinguish the roots only if their horizontal distance is greater than 10 cm and their vertical distance is greater than 5 cm if two or more roots are in proximity. GPR technology can be applied to determine the efficacy of advanced crop production strategies, especially under the pressures of disease and environmental stresses.},
DOI = {10.3390/agronomy9070354}
}



@Article{rs11131581,
AUTHOR = {Uddin, Kabir and Matin, Mir A. and Meyer, Franz J.},
TITLE = {Operational Flood Mapping Using Multi-Temporal Sentinel-1 SAR Images: A Case Study from Bangladesh},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {1581},
URL = {https://www.mdpi.com/2072-4292/11/13/1581},
ISSN = {2072-4292},
ABSTRACT = {Bangladesh is one of the most flood-affected countries in the world. In the last few decades, flood frequency, intensity, duration, and devastation have increased in Bangladesh. Identifying flood-damaged areas is highly essential for an effective flood response. This study aimed at developing an operational methodology for rapid flood inundation and potential flood damaged area mapping to support a quick and effective event response. Sentinel-1 images from March, April, June, and August 2017 were used to generate inundation extents of the corresponding months. The 2017 pre-flood land cover maps were prepared using Landsat-8 images to identify major land cover on the ground before flooding. The overall accuracy of flood inundation mapping was 96.44% and the accuracy of the land cover map was 87.51%. The total flood inundated area corresponded to 2.01%, 4.53%, and 7.01% for the months April, June, and August 2017, respectively. Based on the Landsat-8 derived land cover information, the study determined that cropland damaged by floods was 1.51% in April, 3.46% in June, 5.30% in August, located mostly in the Sylhet and Rangpur divisions. Finally, flood inundation maps were distributed to the broader user community to aid in hazard response. The data and methodology of the study can be replicated for every year to map flooding in Bangladesh.},
DOI = {10.3390/rs11131581}
}



@Article{rs11131584,
AUTHOR = {Chen, Yang and Lee, Won Suk and Gan, Hao and Peres, Natalia and Fraisse, Clyde and Zhang, Yanchao and He, Yong},
TITLE = {Strawberry Yield Prediction Based on a Deep Neural Network Using High-Resolution Aerial Orthoimages},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {1584},
URL = {https://www.mdpi.com/2072-4292/11/13/1584},
ISSN = {2072-4292},
ABSTRACT = {Strawberry growers in Florida suffer from a lack of efficient and accurate yield forecasts for strawberries, which would allow them to allocate optimal labor and equipment, as well as other resources for harvesting, transportation, and marketing. Accurate estimation of the number of strawberry flowers and their distribution in a strawberry field is, therefore, imperative for predicting the coming strawberry yield. Usually, the number of flowers and their distribution are estimated manually, which is time-consuming, labor-intensive, and subjective. In this paper, we develop an automatic strawberry flower detection system for yield prediction with minimal labor and time costs. The system used a small unmanned aerial vehicle (UAV) (DJI Technology Co., Ltd., Shenzhen, China) equipped with an RGB (red, green, blue) camera to capture near-ground images of two varieties (Sensation and Radiance) at two different heights (2 m and 3 m) and built orthoimages of a 402 m2 strawberry field. The orthoimages were automatically processed using the Pix4D software and split into sequential pieces for deep learning detection. A faster region-based convolutional neural network (R-CNN), a state-of-the-art deep neural network model, was chosen for the detection and counting of the number of flowers, mature strawberries, and immature strawberries. The mean average precision (mAP) was 0.83 for all detected objects at 2 m heights and 0.72 for all detected objects at 3 m heights. We adopted this model to count strawberry flowers in November and December from 2 m aerial images and compared the results with a manual count. The average deep learning counting accuracy was 84.1% with average occlusion of 13.5%. Using this system could provide accurate counts of strawberry flowers, which can be used to forecast future yields and build distribution maps to help farmers observe the growth cycle of strawberry fields.},
DOI = {10.3390/rs11131584}
}



@Article{rs11131594,
AUTHOR = {Qiu, Heqian and Li, Hongliang and Wu, Qingbo and Meng, Fanman and Ngan, King Ngi and Shi, Hengcan},
TITLE = {A2RMNet: Adaptively Aspect Ratio Multi-Scale Network for Object Detection in Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {1594},
URL = {https://www.mdpi.com/2072-4292/11/13/1594},
ISSN = {2072-4292},
ABSTRACT = {Object detection is a significant and challenging problem in the study area of remote sensing and image analysis. However, most existing methods are easy to miss or incorrectly locate objects due to the various sizes and aspect ratios of objects. In this paper, we propose a novel end-to-end Adaptively Aspect Ratio Multi-Scale Network (A     2    RMNet) to solve this problem. On the one hand, we design a multi-scale feature gate fusion network to adaptively integrate the multi-scale features of objects. This network is composed of gate fusion modules, refine blocks and region proposal networks. On the other hand, an aspect ratio attention network is leveraged to preserve the aspect ratios of objects, which alleviates the excessive shape distortions of objects caused by aspect ratio changes during training. Experiments show that the proposed A     2    RMNet significantly outperforms the previous state of the arts on the DOTA dataset, NWPU VHR-10 dataset, RSOD dataset and UCAS-AOD dataset by     5.73 %    ,     7.06 %    ,     3.27 %     and     2.24 %    , respectively.},
DOI = {10.3390/rs11131594}
}



@Article{s19132976,
AUTHOR = {Li, Yunwang and Dai, Sumei and Shi, Yong and Zhao, Lala and Ding, Minghua},
TITLE = {Navigation Simulation of a Mecanum Wheel Mobile Robot Based on an Improved A* Algorithm in Unity3D},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {2976},
URL = {https://www.mdpi.com/1424-8220/19/13/2976},
ISSN = {1424-8220},
ABSTRACT = {Computer simulation is an effective means for the research of robot navigation algorithms. In order to implement real-time, three-dimensional, and visual navigation algorithm simulation, a method of algorithm simulation based on secondary development of Unity3D is proposed. With this method, a virtual robot prototype can be created quickly with the imported 3D robot model, virtual joints, and virtual sensors, and then the navigation simulation can be carried out using the virtual prototype with the algorithm script in the virtual environment. Firstly, the scripts of the virtual revolute joint, virtual LiDAR sensors, and terrain environment are written. Secondly, the A* algorithm is improved for navigation in unknown 3D space. Thirdly, taking the Mecanum wheel mobile robot as an example, the 3D robot model is imported into Unity3D, and the virtual joint, sensor, and navigation algorithm scripts are added to the model. Then, the navigation is simulated in static and dynamic environments using a virtual prototype. Finally, the navigation tests of the physical robot are carried out in the physical environment, and the test trajectory is compared with the simulation trajectory. The simulation and test results validate the algorithm simulation method based on the redevelopment of Unity3d, showing that it is feasible, efficient, and flexible.},
DOI = {10.3390/s19132976}
}



@Article{s19132992,
AUTHOR = {Won, Jongbin and Park, Jong-Woong and Park, Kyoohong and Yoon, Hyungchul and Moon, Do-Soo},
TITLE = {Non-Target Structural Displacement Measurement Using Reference Frame-Based Deepflow},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {2992},
URL = {https://www.mdpi.com/1424-8220/19/13/2992},
ISSN = {1424-8220},
ABSTRACT = {Displacement is crucial for structural health monitoring, although it is very challenging to measure under field conditions. Most existing displacement measurement methods are costly, labor-intensive, and insufficiently accurate for measuring small dynamic displacements. Computer vision (CV)-based methods incorporate optical devices with advanced image processing algorithms to accurately, cost-effectively, and remotely measure structural displacement with easy installation. However, non-target-based CV methods are still limited by insufficient feature points, incorrect feature point detection, occlusion, and drift induced by tracking error accumulation. This paper presents a reference frame-based Deepflow algorithm integrated with masking and signal filtering for non-target-based displacement measurements. The proposed method allows the user to select points of interest for images with a low gradient for displacement tracking and directly calculate displacement without drift accumulated by measurement error. The proposed method is experimentally validated on a cantilevered beam under ambient and occluded test conditions. The accuracy of the proposed method is compared with that of a reference laser displacement sensor for validation. The significant advantage of the proposed method is its flexibility in extracting structural displacement in any region on structures that do not have distinct natural features.},
DOI = {10.3390/s19132992}
}



@Article{s19132993,
AUTHOR = {Wang, Chaoqun and Wang, Jiankun and Li, Chenming and Ho, Danny and Cheng, Jiyu and Yan, Tingfang and Meng, Lili and Meng, Max Q.-H.},
TITLE = {Safe and Robust Mobile Robot Navigation in Uneven Indoor Environments},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {2993},
URL = {https://www.mdpi.com/1424-8220/19/13/2993},
ISSN = {1424-8220},
ABSTRACT = {Complex environments pose great challenges for autonomous mobile robot navigation. In this study, we address the problem of autonomous navigation in 3D environments with staircases and slopes. An integrated system for safe mobile robot navigation in 3D complex environments is presented and both the perception and navigation capabilities are incorporated into the modular and reusable framework. Firstly, to distinguish the slope from the staircase in the environment, the robot builds a 3D OctoMap of the environment with a novel Simultaneously Localization and Mapping (SLAM) framework using the information of wheel odometry, a 2D laser scanner, and an RGB-D camera. Then, we introduce the traversable map, which is generated by the multi-layer 2D maps extracted from the 3D OctoMap. This traversable map serves as the input for autonomous navigation when the robot faces slopes and staircases. Moreover, to enable robust robot navigation in 3D environments, a novel camera re-localization method based on regression forest towards stable 3D localization is incorporated into this framework. In addition, we utilize a variable step size Rapidly-exploring Random Tree (RRT) method which can adjust the exploring step size automatically without tuning this parameter manually according to the environment, so that the navigation efficiency is improved. The experiments are conducted in different kinds of environments and the output results demonstrate that the proposed system enables the robot to navigate efficiently and robustly in complex 3D environments.},
DOI = {10.3390/s19132993}
}



@Article{rs11131617,
AUTHOR = {Wang, Jicheng and Shen, Li and Qiao, Wenfan and Dai, Yanshuai and Li, Zhilin},
TITLE = {Deep Feature Fusion with Integration of Residual Connection and Attention Model for Classification of VHR Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {1617},
URL = {https://www.mdpi.com/2072-4292/11/13/1617},
ISSN = {2072-4292},
ABSTRACT = {The classification of very-high-resolution (VHR) remote sensing images is essential in many applications. However, high intraclass and low interclass variations in these kinds of images pose serious challenges. Fully convolutional network (FCN) models, which benefit from a powerful feature learning ability, have shown impressive performance and great potential. Nevertheless, only classification results with coarse resolution can be obtained from the original FCN method. Deep feature fusion is often employed to improve the resolution of outputs. Existing strategies for such fusion are not capable of properly utilizing the low-level features and considering the importance of features at different scales. This paper proposes a novel, end-to-end, fully convolutional network to integrate a multiconnection ResNet model and a class-specific attention model into a unified framework to overcome these problems. The former fuses multilevel deep features without introducing any redundant information from low-level features. The latter can learn the contributions from different features of each geo-object at each scale. Extensive experiments on two open datasets indicate that the proposed method can achieve class-specific scale-adaptive classification results and it outperforms other state-of-the-art methods. The results were submitted to the International Society for Photogrammetry and Remote Sensing (ISPRS) online contest for comparison with more than 50 other methods. The results indicate that the proposed method (ID: SWJ_2) ranks #1 in terms of overall accuracy, even though no additional digital surface model (DSM) data that were offered by ISPRS were used and no postprocessing was applied.},
DOI = {10.3390/rs11131617}
}



@Article{rs11131623,
AUTHOR = {Dong, Yu and Yan, Huimin and Wang, Na and Huang, Mei and Hu, Yunfeng},
TITLE = {Automatic Identification of Shrub-Encroached Grassland in the Mongolian Plateau Based on UAS Remote Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {1623},
URL = {https://www.mdpi.com/2072-4292/11/13/1623},
ISSN = {2072-4292},
ABSTRACT = {Recently, the increasing shrub-encroached grassland in the Mongolian Plateau partly indicates grassland quality decline and degradation. Accurate shrub identification and regional difference analysis in shrub-encroached grassland are significant for ecological degradation research. Object-oriented filter (OOF) and digital surface model (DSM)-digital terrain model (DTM) analyses were combined to establish a high-accuracy automatic shrub identification algorithm (CODA), which made full use of remote sensing products by unmanned aircraft systems (UASs). The results show that: (1) The overall accuracy of CODA in the Grain for Green test area is 89.96%, which is higher than that of OOF (84.52%) and DSM-DTM (78.44%), mainly due to the effective elimination of interference factors (such as shrub-like highland, well-grown grassland in terrain-depression area, etc.) by CODA. (2) The accuracy (87.5%) of CODA in the typical steppe test area is lower than that (92.5%) in the desert steppe test area, which may be related to the higher community structure complexity of typical steppe. Besides, the shrub density is smaller, and the regional difference is more massive in the typical steppe test area. (3) The ground sampling distance for best CODA accuracy in the Grain for Green test area is about 15 cm, while it is below 3 cm in the typical and desert steppe test area.},
DOI = {10.3390/rs11131623}
}



@Article{s19133014,
AUTHOR = {Jalil, Bushra and Leone, Giuseppe Riccardo and Martinelli, Massimo and Moroni, Davide and Pascali, Maria Antonietta and Berton, Andrea},
TITLE = {Fault Detection in Power Equipment via an Unmanned Aerial System Using Multi Modal Data},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {3014},
URL = {https://www.mdpi.com/1424-8220/19/13/3014},
ISSN = {1424-8220},
ABSTRACT = {The power transmission lines are the link between power plants and the points of consumption, through substations. Most importantly, the assessment of damaged aerial power lines and rusted conductors is of extreme importance for public safety; hence, power lines and associated components must be periodically inspected to ensure a continuous supply and to identify any fault and defect. To achieve these objectives, recently, Unmanned Aerial Vehicles (UAVs) have been widely used; in fact, they provide a safe way to bring sensors close to the power transmission lines and their associated components without halting the equipment during the inspection, and reducing operational cost and risk. In this work, a drone, equipped with multi-modal sensors, captures images in the visible and infrared domain and transmits them to the ground station. We used state-of-the-art computer vision methods to highlight expected faults (i.e., hot spots) or damaged components of the electrical infrastructure (i.e., damaged insulators). Infrared imaging, which is invariant to large scale and illumination changes in the real operating environment, supported the identification of faults in power transmission lines; while a neural network is adapted and trained to detect and classify insulators from an optical video stream. We demonstrate our approach on data captured by a drone in Parma, Italy.},
DOI = {10.3390/s19133014}
}



@Article{robotics8030053,
AUTHOR = {Roldán, Juan Jesús and Díaz-Maroto, Víctor and Real, Javier and Palafox, Pablo R. and Valente, João and Garzón, Mario and Barrientos, Antonio},
TITLE = {Press Start to Play: Classifying Multi-Robot Operators and Predicting Their Strategies through a Videogame},
JOURNAL = {Robotics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {53},
URL = {https://www.mdpi.com/2218-6581/8/3/53},
ISSN = {2218-6581},
ABSTRACT = {One of the active challenges in multi-robot missions is related to managing operator workload and situational awareness. Currently, the operators are trained to use interfaces, but in the near future this can be turned inside out: the interfaces will adapt to operators so as to facilitate their tasks. To this end, the interfaces should manage models of operators and adapt the information to their states and preferences. This work proposes a videogame-based approach to classify operator behavior and predict their actions in order to improve teleoperated multi-robot missions. First, groups of operators are generated according to their strategies by means of clustering algorithms. Second, the operators&rsquo; strategies are predicted, taking into account their models. Multiple information sources and modeling methods are used to determine the approach that maximizes the mission goal. The results demonstrate that predictions based on previous data from single operators increase the probability of success in teleoperated multi-robot missions by 19%, whereas predictions based on operator clusters increase this probability of success by 28%.},
DOI = {10.3390/robotics8030053}
}



@Article{s19143054,
AUTHOR = {Fuentes, Sigfredo and Chacon, Gabriela and Torrico, Damir D. and Zarate, Andrea and Gonzalez Viejo, Claudia},
TITLE = {Spatial Variability of Aroma Profiles of Cocoa Trees Obtained through Computer Vision and Machine Learning Modelling: A Cover Photography and High Spatial Remote Sensing Application},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {3054},
URL = {https://www.mdpi.com/1424-8220/19/14/3054},
ISSN = {1424-8220},
ABSTRACT = {Cocoa is an important commodity crop, not only to produce chocolate, one of the most complex products from the sensory perspective, but one that commonly grows in developing countries close to the tropics. This paper presents novel techniques applied using cover photography and a novel computer application (VitiCanopy) to assess the canopy architecture of cocoa trees in a commercial plantation in Queensland, Australia. From the cocoa trees monitored, pod samples were collected, fermented, dried, and ground to obtain the aroma profile per tree using gas chromatography. The canopy architecture data were used as inputs in an artificial neural network (ANN) algorithm, with the aroma profile, considering six main aromas, as targets. The ANN model rendered high accuracy (correlation coefficient (R) = 0.82; mean squared error (MSE) = 0.09) with no overfitting. The model was then applied to an aerial image of the whole cocoa field studied to produce canopy vigor, and aroma profile maps up to the tree-by-tree scale. The tool developed could significantly aid the canopy management practices in cocoa trees, which have a direct effect on cocoa quality.},
DOI = {10.3390/s19143054}
}



@Article{rs11141657,
AUTHOR = {Holman, Fenner H. and Riche, Andrew B. and Castle, March and Wooster, Martin J. and Hawkesford, Malcolm J.},
TITLE = {Radiometric Calibration of ‘Commercial off the Shelf’ Cameras for UAV-Based High-Resolution Temporal Crop Phenotyping of Reflectance and NDVI},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {1657},
URL = {https://www.mdpi.com/2072-4292/11/14/1657},
ISSN = {2072-4292},
ABSTRACT = {Vegetation indices, such as the Normalised Difference Vegetation Index (NDVI), are common metrics used for measuring traits of interest in crop phenotyping. However, traditional measurements of these indices are often influenced by multiple confounding factors such as canopy cover and reflectance of underlying soil, visible in canopy gaps. Digital cameras mounted to Unmanned Aerial Vehicles offer the spatial resolution to investigate these confounding factors, however incomplete methods for radiometric calibration into reflectance units limits how the data can be applied to phenotyping. In this study, we assess the applicability of very high spatial resolution (1 cm) UAV-based imagery taken with commercial off the shelf (COTS) digital cameras for both deriving calibrated reflectance imagery, and isolating vegetation canopy reflectance from that of the underlying soil. We present new methods for successfully normalising COTS camera imagery for exposure and solar irradiance effects, generating multispectral (RGB-NIR) orthomosaics of our target field-based wheat crop trial. Validation against measurements from a ground spectrometer showed good results for reflectance (R2 &ge; 0.6) and NDVI (R2 &ge; 0.88). Application of imagery collected through the growing season and masked using the Excess Green Red index was used to assess the impact of canopy cover on NDVI measurements. Results showed the impact of canopy cover artificially reducing plot NDVI values in the early season, where canopy development is low.},
DOI = {10.3390/rs11141657}
}



@Article{rs11141662,
AUTHOR = {Nyandwi, Emmanuel and Koeva, Mila and Kohli, Divyani and Bennett, Rohan},
TITLE = {Comparing Human Versus Machine-Driven Cadastral Boundary Feature Extraction},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {1662},
URL = {https://www.mdpi.com/2072-4292/11/14/1662},
ISSN = {2072-4292},
ABSTRACT = {The objective to fast-track the mapping and registration of large numbers of unrecorded land rights globally has led to the experimental application of Artificial Intelligence in the domain of land administration, and specifically the application of automated visual cognition techniques for cadastral mapping tasks. In this research, we applied and compared the ability of rule-based systems within Object-Based Image Analysis (OBIA), as opposed to human analysis, to extract visible cadastral boundaries from very high-resolution World View-2 images, in both rural and urban settings. From our experiments, machine-based techniques were able to automatically delineate a good proportion of rural parcels with explicit polygons where the correctness of the automatically extracted boundaries was 47.4% against 74.24% for humans and the completeness of 45% for the machine compared to 70.4% for humans. On the contrary, in the urban area, automatic results were counterintuitive: even though urban plots and buildings are clearly marked with visible features such as fences, roads and tacitly perceptible to eyes, automation resulted in geometrically and topologically poorly structured data. Thus, these could neither be geometrically compared with human digitisation, nor actual cadastral data from the field. The results of this study provide an updated snapshot with regards to the performance of contemporary machine-driven feature extraction techniques compared to conventional manual digitising. In our methodology, using an iterative approach of segmentation and classification, we demonstrated how to overcome the weaknesses of having undesirable segments due to intra-parcel and inter-parcel variability, when using segmentation approaches for cadastral feature delineation. We also demonstrated how we can easily implement a geometric comparison framework within the Esri&rsquo;s ArcGIS software environment and firmly believe the developed methodology can be reproduced.},
DOI = {10.3390/rs11141662}
}



@Article{jsan8030039,
AUTHOR = {Fakhrulddin, Saif Saad and Gharghan, Sadik Kamel},
TITLE = {An Autonomous Wireless Health Monitoring System Based on Heartbeat and Accelerometer Sensors},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {8},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {39},
URL = {https://www.mdpi.com/2224-2708/8/3/39},
ISSN = {2224-2708},
ABSTRACT = {Falls are a main cause of injury for patients with certain diseases. Patients who wear health monitoring systems can go about daily activities without limitations, thereby enhancing their quality of life. In this paper, patient falls and heart rate were accurately detected and measured using two proposed algorithms. The first algorithm, abnormal heart rate detection (AHRD), improves patient heart rate measurement accuracy and distinguishes between normal and abnormal heart rate functions. The second algorithm, TB-AIC, combines an acceleration threshold and monitoring of patient activity/inactivity functions to accurately detect patient falls. The two algorithms were practically implemented in a proposed autonomous wireless health monitoring system (AWHMS). The AWHMS was implemented based on a GSM module, GPS, microcontroller, heartbeat and accelerometer sensors, and a smartphone. The measurement accuracy of the recorded heart rate was evaluated based on the mean absolute error, Bland&ndash;Altman plots, and correlation coefficients. Fourteen types of patient activities were considered (seven types of falling and seven types of daily activities) to determine the fall detection accuracy. The results indicate that the proposed AWHMS succeeded in monitoring the patient&rsquo;s vital signs, with heart rate measurement and fall detection accuracies of 98.75% and 99.11%, respectively. In addition, the sensitivity and specificity of the fall detection algorithm (both 99.12%) were explored.},
DOI = {10.3390/jsan8030039}
}



@Article{app9142808,
AUTHOR = {Peng, Yahui and Liu, Xiaochen and Shen, Chong and Huang, Haoqian and Zhao, Donghua and Cao, Huiliang and Guo, Xiaoting},
TITLE = {An Improved Optical Flow Algorithm Based on Mask-R-CNN and K-Means for Velocity Calculation},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {2808},
URL = {https://www.mdpi.com/2076-3417/9/14/2808},
ISSN = {2076-3417},
ABSTRACT = {Aiming at enhancing the accuracy and reliability of velocity calculation in vision navigation, an improved method is proposed in this paper. The method integrates Mask-R-CNN (Mask Region-based Convolutional Neural Network) and K-Means with the pyramid Lucas Kanade algorithm in order to reduce the harmful effect of moving objects on velocity calculation. Firstly, Mask-R-CNN is used to recognize the objects which have motions relative to the ground and covers them with masks to enhance the similarity between pixels and to reduce the impacts of the noisy moving pixels. Then, the pyramid Lucas Kanade algorithm is used to calculate the optical flow value. Finally, the value is clustered by the K-Means algorithm to abandon the outliers, and vehicle velocity is calculated by the processed optical flow. The prominent advantages of the proposed algorithm are (i) decreasing the bad impacts to velocity calculation, due to the objects which have relative motions; (ii) obtaining the correct optical flow sets and velocity calculation outputs with less fluctuation; and (iii) the applicability enhancement of the optical flow algorithm in complex navigation environment. The proposed algorithm is tested by actual experiments. Results with superior precision and reliability show the feasibility and effectiveness of the proposed method for vehicle velocity calculation in vision navigation system.},
DOI = {10.3390/app9142808}
}



@Article{s19143106,
AUTHOR = {Zhou, Chengquan and Ye, Hongbao and Hu, Jun and Shi, Xiaoyan and Hua, Shan and Yue, Jibo and Xu, Zhifu and Yang, Guijun},
TITLE = {Automated Counting of Rice Panicle by Applying Deep Learning Model to Images from Unmanned Aerial Vehicle Platform},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {3106},
URL = {https://www.mdpi.com/1424-8220/19/14/3106},
ISSN = {1424-8220},
ABSTRACT = {The number of panicles per unit area is a common indicator of rice yield and is of great significance to yield estimation, breeding, and phenotype analysis. Traditional counting methods have various drawbacks, such as long delay times and high subjectivity, and they are easily perturbed by noise. To improve the accuracy of rice detection and counting in the field, we developed and implemented a panicle detection and counting system that is based on improved region-based fully convolutional networks, and we use the system to automate rice-phenotype measurements. The field experiments were conducted in target areas to train and test the system and used a rotor light unmanned aerial vehicle equipped with a high-definition RGB camera to collect images. The trained model achieved a precision of 0.868 on a held-out test set, which demonstrates the feasibility of this approach. The algorithm can deal with the irregular edge of the rice panicle, the significantly different appearance between the different varieties and growing periods, the interference due to color overlapping between panicle and leaves, and the variations in illumination intensity and shading effects in the field. The result is more accurate and efficient recognition of rice-panicles, which facilitates rice breeding. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a global scale.},
DOI = {10.3390/s19143106}
}



@Article{s19143115,
AUTHOR = {Wei, Yang and Wang, Hao and Tsang, Kim Fung and Liu, Yucheng and Wu, Chung Kit and Zhu, Hongxu and Chow, Yuk-Tak and Hung, Faan Hei},
TITLE = {Proximity Environmental Feature Based Tree Health Assessment Scheme Using Internet of Things and Machine Learning Algorithm},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {3115},
URL = {https://www.mdpi.com/1424-8220/19/14/3115},
ISSN = {1424-8220},
ABSTRACT = {Improperly grown trees may cause huge hazards to the environment and to humans, through e.g., climate change, soil erosion, etc. A proximity environmental feature-based tree health assessment (PTA) scheme is proposed to prevent these hazards by providing guidance for early warning methods of potential poor tree health. In PTA development, tree health is defined and evaluated based on proximity environmental features (PEFs). The PEF takes into consideration the seven surrounding ambient features that strongly impact tree health. The PEFs were measured by the deployed smart sensors surrounding trees. A database composed of tree health and relative PEFs was established for further analysis. An adaptive data identifying (ADI) algorithm is applied to exclude the influence of interference factors in the database. Finally, the radial basis function (RBF) neural network (NN), a machine leaning algorithm, has been identified as the appropriate tool with which to correlate tree health and PEFs to establish the PTA algorithm. One of the salient features of PTA is that the algorithm can evaluate, and thus monitor, tree health remotely and automatically from smart sensor data by taking advantage of the well-established internet of things (IoT) network and machine learning algorithm.},
DOI = {10.3390/s19143115}
}



@Article{rs11141678,
AUTHOR = {Fu, Yongyong and Ye, Ziran and Deng, Jinsong and Zheng, Xinyu and Huang, Yibo and Yang, Wu and Wang, Yaohua and Wang, Ke},
TITLE = {Finer Resolution Mapping of Marine Aquaculture Areas Using WorldView-2 Imagery and a Hierarchical Cascade Convolutional Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {1678},
URL = {https://www.mdpi.com/2072-4292/11/14/1678},
ISSN = {2072-4292},
ABSTRACT = {Marine aquaculture plays an important role in seafood supplement, economic development, and coastal ecosystem service provision. The precise delineation of marine aquaculture areas from high spatial resolution (HSR) imagery is vital for the sustainable development and management of coastal marine resources. However, various sizes and detailed structures of marine objects make it difficult for accurate mapping from HSR images by using conventional methods. Therefore, this study attempts to extract marine aquaculture areas by using an automatic labeling method based on the convolutional neural network (CNN), i.e., an end-to-end hierarchical cascade network (HCNet). Specifically, for marine objects of various sizes, we propose to improve the classification performance by utilizing multi-scale contextual information. Technically, based on the output of a CNN encoder, we employ atrous convolutions to capture multi-scale contextual information and aggregate them in a hierarchical cascade way. Meanwhile, for marine objects with detailed structures, we propose to refine the detailed information gradually by using a series of long-span connections with fine resolution features from the shallow layers. In addition, to decrease the semantic gaps between features in different levels, we propose to refine the feature space (i.e., channel and spatial dimensions) using an attention-based module. Experimental results show that our proposed HCNet can effectively identify and distinguish different kinds of marine aquaculture, with 98% of overall accuracy. It also achieves better classification performance compared with object-based support vector machine and state-of-the-art CNN-based methods, such as FCN-32s, U-Net, and DeeplabV2. Our developed method lays a solid foundation for the intelligent monitoring and management of coastal marine resources.},
DOI = {10.3390/rs11141678}
}



@Article{en12142706,
AUTHOR = {Ejaz, Waleed and Azam, Muhammad Awais and Saadat, Salman and Iqbal, Farkhund and Hanan, Abdul},
TITLE = {Unmanned Aerial Vehicles enabled IoT Platform for Disaster Management},
JOURNAL = {Energies},
VOLUME = {12},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {2706},
URL = {https://www.mdpi.com/1996-1073/12/14/2706},
ISSN = {1996-1073},
ABSTRACT = {Efficient and reliable systems are required to detect and monitor disasters such as wildfires as well as to notify the people in the disaster-affected areas. Internet of Things (IoT) is the key paradigm that can address the multitude problems related to disaster management. In addition, an unmanned aerial vehicles (UAVs)-enabled IoT platform connected via cellular network can further enhance the robustness of the disaster management system. The UAV-enabled IoT platform is based on three main research areas: (i) ground IoT network; (ii) communication technologies for ground and aerial connectivity; and (iii) data analytics. In this paper, we provide a holistic view of a UAVs-enabled IoT platform which can provide ubiquitous connectivity to both aerial and ground users in challenging environments such as wildfire management. We then highlight key challenges for the design of an efficient and reliable IoT platform. We detail a case study targeting the design of an efficient ground IoT network that can detect and monitor fire and send notifications to people using named data networking (NDN) architecture. The use of NDN architecture in a sensor network for IoT integrates pull-based communication to enable reliable and efficient message dissemination in the network and to notify the users as soon as possible in case of disastrous situations. The results of the case study show the enormous impact on the performance of IoT platform for wildfire management. Lastly, we draw the conclusion and outline future research directions in this field.},
DOI = {10.3390/en12142706}
}



@Article{drones3030058,
AUTHOR = {Akhloufi, Moulay A. and Arola, Sebastien and Bonnet, Alexandre},
TITLE = {Drones Chasing Drones: Reinforcement Learning and Deep Search Area Proposal},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {58},
URL = {https://www.mdpi.com/2504-446X/3/3/58},
ISSN = {2504-446X},
ABSTRACT = {Unmanned aerial vehicles (UAVs) are very popular and increasingly used in different applications. Today, the use of multiple UAVs and UAV swarms are attracting more interest from the research community, leading to the exploration of topics such as UAV cooperation, multi-drone autonomous navigation, etc. In this work, we propose two approaches for UAV pursuit-evasion. The first approach uses deep reinforcement learning to predict the actions to apply to the follower UAV to keep track of the target UAV. The second approach uses a deep object detector and a search area proposal (SAP) to predict the position of the target UAV in the next frame for tracking purposes. The two approaches are promising and lead to a higher tracking accuracy with an intersection over union (IoU) above the selected threshold. We also show that the deep SAP-based approach improves the detection of distant objects that cover small areas in the image. The efficiency of the proposed algorithms is demonstrated in outdoor tracking scenarios using real UAVs.},
DOI = {10.3390/drones3030058}
}



@Article{rs11141692,
AUTHOR = {Farooq, Adnan and Jia, Xiuping and Hu, Jiankun and Zhou, Jun},
TITLE = {Multi-Resolution Weed Classification via Convolutional Neural Network and Superpixel Based Local Binary Pattern Using Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {1692},
URL = {https://www.mdpi.com/2072-4292/11/14/1692},
ISSN = {2072-4292},
ABSTRACT = {Automatic weed detection and classification faces the challenges of large intraclass variation and high spectral similarity to other vegetation. With the availability of new high-resolution remote sensing data from various platforms and sensors, it is possible to capture both spectral and spatial characteristics of weed species at multiple scales. Effective multi-resolution feature learning is then desirable to extract distinctive intensity, texture and shape features of each category of weed to enhance the weed separability. We propose a feature extraction method using a Convolutional Neural Network (CNN) and superpixel based Local Binary Pattern (LBP). Both middle and high level spatial features are learned using the CNN. Local texture features from superpixel-based LBP are extracted, and are also used as input to Support Vector Machines (SVM) for weed classification. Experimental results on the hyperspectral and remote sensing datasets verify the effectiveness of the proposed method, and show that it outperforms several feature extraction approaches.},
DOI = {10.3390/rs11141692}
}



@Article{rs11141708,
AUTHOR = {Cao, Shuang and Yu, Yongtao and Guan, Haiyan and Peng, Daifeng and Yan, Wanqian},
TITLE = {Affine-Function Transformation-Based Object Matching for Vehicle Detection from Unmanned Aerial Vehicle Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {1708},
URL = {https://www.mdpi.com/2072-4292/11/14/1708},
ISSN = {2072-4292},
ABSTRACT = {Vehicle detection from remote sensing images plays a significant role in transportation related applications. However, the scale variations, orientation variations, illumination variations, and partial occlusions of vehicles, as well as the image qualities, bring great challenges for accurate vehicle detection. In this paper, we present an affine-function transformation-based object matching framework for vehicle detection from unmanned aerial vehicle (UAV) images. First, meaningful and non-redundant patches are generated through a superpixel segmentation strategy. Then, the affine-function transformation-based object matching framework is applied to a vehicle template and each of the patches for vehicle existence estimation. Finally, vehicles are detected and located after matching cost thresholding, vehicle location estimation, and multiple response elimination. Quantitative evaluations on two UAV image datasets show that the proposed method achieves an average completeness, correctness, quality, and F1-measure of 0.909, 0.969, 0.883, and 0.938, respectively. Comparative studies also demonstrate that the proposed method achieves compatible performance with the Faster R-CNN and outperforms the other eight existing methods in accurately detecting vehicles of various conditions.},
DOI = {10.3390/rs11141708}
}



@Article{rs11141713,
AUTHOR = {Jozdani, Shahab Eddin and Johnson, Brian Alan and Chen, Dongmei},
TITLE = {Comparing Deep Neural Networks, Ensemble Classifiers, and Support Vector Machine Algorithms for Object-Based Urban Land Use/Land Cover Classification},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {1713},
URL = {https://www.mdpi.com/2072-4292/11/14/1713},
ISSN = {2072-4292},
ABSTRACT = {With the advent of high-spatial resolution (HSR) satellite imagery, urban land use/land cover (LULC) mapping has become one of the most popular applications in remote sensing. Due to the importance of context information (e.g., size/shape/texture) for classifying urban LULC features, Geographic Object-Based Image Analysis (GEOBIA) techniques are commonly employed for mapping urban areas. Regardless of adopting a pixel- or object-based framework, the selection of a suitable classifier is of critical importance for urban mapping. The popularity of deep learning (DL) (or deep neural networks (DNNs)) for image classification has recently skyrocketed, but it is still arguable if, or to what extent, DL methods can outperform other state-of-the art ensemble and/or Support Vector Machines (SVM) algorithms in the context of urban LULC classification using GEOBIA. In this study, we carried out an experimental comparison among different architectures of DNNs (i.e., regular deep multilayer perceptron (MLP), regular autoencoder (RAE), sparse, autoencoder (SAE), variational autoencoder (AE), convolutional neural networks (CNN)), common ensemble algorithms (Random Forests (RF), Bagging Trees (BT), Gradient Boosting Trees (GB), and Extreme Gradient Boosting (XGB)), and SVM to investigate their potential for urban mapping using a GEOBIA approach. We tested the classifiers on two RS images (with spatial resolutions of 30 cm and 50 cm). Based on our experiments, we drew three main conclusions: First, we found that the MLP model was the most accurate classifier. Second, unsupervised pretraining with the use of autoencoders led to no improvement in the classification result. In addition, the small difference in the classification accuracies of MLP from those of other models like SVM, GB, and XGB classifiers demonstrated that other state-of-the-art machine learning classifiers are still versatile enough to handle mapping of complex landscapes. Finally, the experiments showed that the integration of CNN and GEOBIA could not lead to more accurate results than the other classifiers applied.},
DOI = {10.3390/rs11141713}
}



@Article{app9142908,
AUTHOR = {Zhou, Qiang and Li, Xin},
TITLE = {Deep Homography Estimation and Its Application to Wall Maps of Wall-Climbing Robots},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {2908},
URL = {https://www.mdpi.com/2076-3417/9/14/2908},
ISSN = {2076-3417},
ABSTRACT = {When locating wall-climbing robots with vision-based methods, locating and controlling the wall-climbing robot in the pixel coordinate of the wall map is an effective alternative that eliminates the need to calibrate the internal and external parameters of the camera. The estimation accuracy of the homography matrix between the camera image and the wall map directly impacts the pixel positioning accuracy of the wall-climbing robot in the wall map. In this study, we focused on the homography estimation between the camera image and wall map. We proposed HomographyFpnNet and obtained a smaller homography estimation error for a center-aligned image pair compared with the state of the art. The proposed hierarchical HomographyFpnNet for a non-center-aligned image pair significantly outperforms the method based on artificially designed features + Random Sample Consensus. The experiments conducted with a trained three-stage hierarchical HomographyFpnNet model on wall images of climbing robots also achieved small mean corner pixel error and proved its potential for estimating the homography between the wall map and camera images. The three-stage hierarchical HomographyFpnNet model has an average processing time of 10.8 ms on a GPU. The real-time processing speed satisfies the requirements of wall-climbing robots.},
DOI = {10.3390/app9142908}
}



@Article{s19143205,
AUTHOR = {Escobar Villanueva, Jairo R. and Iglesias Martínez, Luis and Pérez Montiel, Jhonny I.},
TITLE = {DEM Generation from Fixed-Wing UAV Imaging and LiDAR-Derived Ground Control Points for Flood Estimations},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {3205},
URL = {https://www.mdpi.com/1424-8220/19/14/3205},
ISSN = {1424-8220},
ABSTRACT = {Geospatial products, such as digital elevation models (DEMs), are important topographic tools for tackling local flood studies. This study investigates the contribution of LiDAR elevation data in DEM generation based on fixed-wing unmanned aerial vehicle (UAV) imaging for flood applications. More specifically, it assesses the accuracy of UAV-derived DEMs using the proposed LiDAR-derived control point (LCP) method in a Structure-from-Motion photogrammetry processing. Also, the flood estimates (volume and area) of the UAV terrain products are compared with a LiDAR-based reference. The applied LCP-georeferencing method achieves an accuracy comparable with other studies. In addition, it has the advantage of using semi-automatic terrain data classification and is readily applicable in flood studies. Lastly, it proves the complementarity between LiDAR and UAV photogrammetry at the local level.},
DOI = {10.3390/s19143205}
}



@Article{robotics8030059,
AUTHOR = {Iannace, Gino and Ciaburro, Giuseppe and Trematerra, Amelia},
TITLE = {Fault Diagnosis for UAV Blades Using Artificial Neural Network},
JOURNAL = {Robotics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {59},
URL = {https://www.mdpi.com/2218-6581/8/3/59},
ISSN = {2218-6581},
ABSTRACT = {In recent years, unmanned aerial vehicles (UAVs) have been used in several fields including, for example, archaeology, cargo transport, conservation, healthcare, filmmaking, hobbies and recreational use. UAVs are aircraft characterized by the absence of a human pilot on board. The extensive use of these devices has highlighted maintenance problems with regard to the propellers, which represent the source of propulsion of the aircraft. A defect in the propellers of a drone can cause the aircraft to fall to the ground and its consequent destruction, and it also constitutes a safety problem for objects and people that are in the range of action of the aircraft. In this study, the measurements of the noise emitted by a UAV were used to build a classification model to detect unbalanced blades in a UAV propeller. To simulate the fault condition, two strips of paper tape were applied to the upper surface of a blade. The paper tape created a substantial modification of the aerodynamics of the blade, and this modification characterized the noise produced by the blade in its rotation. Then, a model based on artificial neural network algorithms was built to detect unbalanced blades in a UAV propeller. This model showed high accuracy (0.9763), indicating a high number of correct detections and suggests the adoption of this tool to verify the operating conditions of a UAV. The test must be performed indoors; from the measurements of the noise produced by the UAV it is possible to identify an imbalance in the propeller blade.},
DOI = {10.3390/robotics8030059}
}



@Article{rs11141725,
AUTHOR = {Xia, Xue and Persello, Claudio and Koeva, Mila},
TITLE = {Deep Fully Convolutional Networks for Cadastral Boundary Detection from UAV Images},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {1725},
URL = {https://www.mdpi.com/2072-4292/11/14/1725},
ISSN = {2072-4292},
ABSTRACT = {There is a growing demand for cheap and fast cadastral mapping methods to face the challenge of 70% global unregistered land rights. As traditional on-site field surveying is time-consuming and labor intensive, imagery-based cadastral mapping has in recent years been advocated by fit-for-purpose (FFP) land administration. However, owing to the semantic gap between the high-level cadastral boundary concept and low-level visual cues in the imagery, improving the accuracy of automatic boundary delineation remains a major challenge. In this research, we use imageries acquired by Unmanned Aerial Vehicles (UAV) to explore the potential of deep Fully Convolutional Networks (FCNs) for cadastral boundary detection in urban and semi-urban areas. We test the performance of FCNs against other state-of-the-art techniques, including Multi-Resolution Segmentation (MRS) and Globalized Probability of Boundary (gPb) in two case study sites in Rwanda. Experimental results show that FCNs outperformed MRS and gPb in both study areas and achieved an average accuracy of 0.79 in precision, 0.37 in recall and 0.50 in F-score. In conclusion, FCNs are able to effectively extract cadastral boundaries, especially when a large proportion of cadastral boundaries are visible. This automated method could minimize manual digitization and reduce field work, thus facilitating the current cadastral mapping and updating practices.},
DOI = {10.3390/rs11141725}
}



@Article{s19143212,
AUTHOR = {Zhou, Sanzhang and Kang, Feng and Li, Wenbin and Kan, Jiangming and Zheng, Yongjun and He, Guojian},
TITLE = {Extracting Diameter at Breast Height with a Handheld Mobile LiDAR System in an Outdoor Environment},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {3212},
URL = {https://www.mdpi.com/1424-8220/19/14/3212},
ISSN = {1424-8220},
ABSTRACT = {Mobile laser scanning (MLS) is widely used in the mapping of forest environments. It has become important for extracting the parameters of forest trees using the generated environmental map. In this study, a three-dimensional point cloud map of a forest area was generated by using the Velodyne VLP-16 LiDAR system, so as to extract the diameter at breast height (DBH) of individual trees. The Velodyne VLP-16 LiDAR system and inertial measurement units (IMU) were used to construct a mobile measurement platform for generating 3D point cloud maps for forest areas. The 3D point cloud map in the forest area was processed offline, and the ground point cloud was removed by the random sample consensus (RANSAC) algorithm. The trees in the experimental area were segmented by the European clustering algorithm, and the DBH component of the tree point cloud was extracted and projected onto a 2D plane, fitting the DBH of the trees using the RANSAC algorithm in the plane. A three-dimensional point cloud map of 71 trees was generated in the experimental area, and estimated the DBH. The mean and variance of the absolute error were 0.43 cm and 0.50, respectively. The relative error of the whole was 2.27%, the corresponding variance was 15.09, and the root mean square error (RMSE) was 0.70 cm. The experimental results were good and met the requirements of forestry mapping, and the application value and significance were presented.},
DOI = {10.3390/s19143212}
}



@Article{app9142917,
AUTHOR = {Chen, Yan and Zhang, Chengming and Wang, Shouyi and Li, Jianping and Li, Feng and Yang, Xiaoxia and Wang, Yuanyuan and Yin, Leikun},
TITLE = {Extracting Crop Spatial Distribution from Gaofen 2 Imagery Using a Convolutional Neural Network},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {2917},
URL = {https://www.mdpi.com/2076-3417/9/14/2917},
ISSN = {2076-3417},
ABSTRACT = {Using satellite remote sensing has become a mainstream approach for extracting crop spatial distribution. Making edges finer is a challenge, while simultaneously extracting crop spatial distribution information from high-resolution remote sensing images using a convolutional neural network (CNN). Based on the characteristics of the crop area in the Gaofen 2 (GF-2) images, this paper proposes an improved CNN to extract fine crop areas. The CNN comprises a feature extractor and a classifier. The feature extractor employs a spectral feature extraction unit to generate spectral features, and five coding-decoding-pair units to generate five level features. A linear model is used to fuse features of different levels, and the fusion results are up-sampled to obtain a feature map consistent with the structure of the input image. This feature map is used by the classifier to perform pixel-by-pixel classification. In this study, the SegNet and RefineNet models and 21 GF-2 images of Feicheng County, Shandong Province, China, were chosen for comparison experiment. Our approach had an accuracy of 93.26%, which is higher than those of the existing SegNet (78.12%) and RefineNet (86.54%) models. This demonstrates the superiority of the proposed method in extracting crop spatial distribution information from GF-2 remote sensing images.},
DOI = {10.3390/app9142917}
}



@Article{s19143221,
AUTHOR = {Ladosz, Pawel and Kim, Jongyun and Oh, Hyondong and Chen, Wen-Hua},
TITLE = {Experimental Validation of Gaussian Process-Based Air-to-Ground Communication Quality Prediction in Urban Environments},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {3221},
URL = {https://www.mdpi.com/1424-8220/19/14/3221},
ISSN = {1424-8220},
ABSTRACT = {This paper presents a detailed experimental assessment of Gaussian Process (GP) regression for air-to-ground communication channel prediction for relay missions in urban environment. Considering restrictions from outdoor urban flight experiments, a way to simulate complex urban environments at an indoor room scale is introduced. Since water significantly absorbs wireless communication signal, water containers are utilized to replace buildings in a real-world city. To evaluate the performance of the GP-based channel prediction approach, several indoor experiments in an artificial urban environment were conducted. The performance of the GP-based and empirical model-based prediction methods for a relay mission was evaluated by measuring and comparing the communication signal strength at the optimal relay position obtained from each method. The GP-based prediction approach shows an advantage over the model-based one as it provides a reasonable performance without a need for a priori information of the environment (e.g., 3D map of the city and communication model parameters) in dynamic urban environments.},
DOI = {10.3390/s19143221}
}



@Article{geosciences9070323,
AUTHOR = {Jakovljevic, Gordana and Govedarica, Miro and Alvarez-Taboada, Flor and Pajic, Vladimir},
TITLE = {Accuracy Assessment of Deep Learning Based Classification of LiDAR and UAV Points Clouds for DTM Creation and Flood Risk Mapping},
JOURNAL = {Geosciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {323},
URL = {https://www.mdpi.com/2076-3263/9/7/323},
ISSN = {2076-3263},
ABSTRACT = {Digital elevation model (DEM) has been frequently used for the reduction and management of flood risk. Various classification methods have been developed to extract DEM from point clouds. However, the accuracy and computational efficiency need to be improved. The objectives of this study were as follows: (1) to determine the suitability of a new method to produce DEM from unmanned aerial vehicle (UAV) and light detection and ranging (LiDAR) data, using a raw point cloud classification and ground point filtering based on deep learning and neural networks (NN); (2) to test the convenience of rebalancing datasets for point cloud classification; (3) to evaluate the effect of the land cover class on the algorithm performance and the elevation accuracy; and (4) to assess the usability of the LiDAR and UAV structure from motion (SfM) DEM in flood risk mapping. In this paper, a new method of raw point cloud classification and ground point filtering based on deep learning using NN is proposed and tested on LiDAR and UAV data. The NN was trained on approximately 6 million points from which local and global geometric features and intensity data were extracted. Pixel-by-pixel accuracy assessment and visual inspection confirmed that filtering point clouds based on deep learning using NN is an appropriate technique for ground classification and producing DEM, as for the test and validation areas, both ground and non-ground classes achieved high recall (&gt;0.70) and high precision values (&gt;0.85), which showed that the two classes were well handled by the model. The type of method used for balancing the original dataset did not have a significant influence in the algorithm accuracy, and it was suggested not to use any of them unless the distribution of the generated and real data set will remain the same. Furthermore, the comparisons between true data and LiDAR and a UAV structure from motion (UAV SfM) point clouds were analyzed, as well as the derived DEM. The root mean square error (RMSE) and the mean average error (MAE) of the DEM were 0.25 m and 0.05 m, respectively, for LiDAR data, and 0.59 m and &ndash;0.28 m, respectively, for UAV data. For all land cover classes, the UAV DEM overestimated the elevation, whereas the LIDAR DEM underestimated it. The accuracy was not significantly different in the LiDAR DEM for the different vegetation classes, while for the UAV DEM, the RMSE increased with the height of the vegetation class. The comparison of the inundation areas derived from true LiDAR and UAV data for different water levels showed that in all cases, the largest differences were obtained for the lowest water level tested, while they performed best for very high water levels. Overall, the approach presented in this work produced DEM from LiDAR and UAV data with the required accuracy for flood mapping according to European Flood Directive standards. Although LiDAR is the recommended technology for point cloud acquisition, a suitable alternative is also UAV SfM in hilly areas.},
DOI = {10.3390/geosciences9070323}
}



@Article{w11081527,
AUTHOR = {Priori, Simone and Barbetti, Roberto and Meini, Luca and Morelli, Annalisa and Zampolli, Andrea and D’Avino, Lorenzo},
TITLE = {Towards Economic Land Evaluation at the Farm Scale Based on Soil Physical-Hydrological Features and Ecosystem Services},
JOURNAL = {Water},
VOLUME = {11},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {1527},
URL = {https://www.mdpi.com/2073-4441/11/8/1527},
ISSN = {2073-4441},
ABSTRACT = {The economic evaluation of a land parcel is mainly based on the local economy, as well as on the topography, distance to the main streets, distance to the river, and presence of irrigation. Spatial variability of soil features and functionalities are often left behind during economic land evaluation, probably due to a scarce awareness of soil function’s economic value. The paper shows an approach for economic land evaluation of irrigated croplands in the Po River plain (Northern Italy), based on spatial variability of soil functions, namely biomass production and carbon sequestration, as well as taking into account the river flood risk. The soil spatial variability was mapped using proximal sensing technology and few calibration points (one every 5 hectares). Biomass production of the main crops of the area, namely maize, soybean, and sorghum, was monitored and mapped for three years (2016, 2017, and 2018) using precision agriculture technologies. The results showed that the available water capacity (AWC) reached the highest correlation with biomass production, additionally, soil texture and cation exchange capacity were significantly correlated. Economic evaluation of the land parcels was computed considering the mean land market value of the area, the site-specific deviations due to the spatial variability of the biomass production by capitalization rate, and carbon sequestration soil functions, applying a natural capital approach by the mean annual value of the carbon market. This site-specific methodology could be applied to many other arable lands.},
DOI = {10.3390/w11081527}
}



@Article{app9152961,
AUTHOR = {Cao, Mingwei and Jia, Wei and Lv, Zhihan and Zheng, Liping and Liu, Xiaoping},
TITLE = {Superpixel-Based Feature Tracking for Structure from Motion},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {2961},
URL = {https://www.mdpi.com/2076-3417/9/15/2961},
ISSN = {2076-3417},
ABSTRACT = {Feature tracking in image collections significantly affects the efficiency and accuracy of Structure from Motion (SFM). Insufficient correspondences may result in disconnected structures and incomplete components, while the redundant correspondences containing incorrect ones may yield to folded and superimposed structures. In this paper, we present a Superpixel-based feature tracking method for structure from motion. In the proposed method, we first propose to use a joint approach to detect local keypoints and compute descriptors. Second, the superpixel-based approach is used to generate labels for the input image. Third, we combine the Speed Up Robust Feature and binary test in the generated label regions to produce a set of combined descriptors for the detected keypoints. Fourth, the locality-sensitive hash (LSH)-based k nearest neighboring matching (KNN) is utilized to produce feature correspondences, and then the ratio test approach is used to remove outliers from the previous matching collection. Finally, we conduct comprehensive experiments on several challenging benchmarking datasets including highly ambiguous and duplicated scenes. Experimental results show that the proposed method gets better performances with respect to the state of the art methods.},
DOI = {10.3390/app9152961}
}



@Article{su11154016,
AUTHOR = {Li, Dawei and Zhang, Yujia and Li, Cheng},
TITLE = {Mining Public Opinion on Transportation Systems Based on Social Media Data},
JOURNAL = {Sustainability},
VOLUME = {11},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {4016},
URL = {https://www.mdpi.com/2071-1050/11/15/4016},
ISSN = {2071-1050},
ABSTRACT = {Public participation plays an important role of traffic planning and management, but it is a great challenge to collect and analyze public opinions for traffic problems on a large scale under traditional methods. Traffic management departments should appropriately adopt public opinions in order to formulate scientific and reasonable regulations and policies. At present, while increasing degree of public participation, data collection and processing should be accelerated to make up for the shortcomings of traditional planning. This paper focuses on text analysis using large data with temporal and spatial attributes of social network platform. Web crawler technology is used to obtain traffic-related text in mainstream social platforms. After basic treatment, the emotional tendency of the text is analyzed. Then, based on the probabilistic topic modeling (latent Dirichlet allocation model), the main opinions of the public are extracted, and the spatial and temporal characteristics of the data are summarized. Taking Nanjing Metro as an example, the existing problems are summarized from the public opinions and improvement measures are put forward, which proves the feasibility of providing technical support for public participation in public transport with social media big data.},
DOI = {10.3390/su11154016}
}



@Article{rs11151763,
AUTHOR = {Li, Songyang and Yuan, Fei and Ata-UI-Karim, Syed Tahir and Zheng, Hengbiao and Cheng, Tao and Liu, Xiaojun and Tian, Yongchao and Zhu, Yan and Cao, Weixing and Cao, Qiang},
TITLE = {Combining Color Indices and Textures of UAV-Based Digital Imagery for Rice LAI Estimation},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {1763},
URL = {https://www.mdpi.com/2072-4292/11/15/1763},
ISSN = {2072-4292},
ABSTRACT = {Leaf area index (LAI) is a fundamental indicator of plant growth status in agronomic and environmental studies. Due to rapid advances in unmanned aerial vehicle (UAV) and sensor technologies, UAV-based remote sensing is emerging as a promising solution for monitoring crop LAI with great flexibility and applicability. This study aimed to determine the feasibility of combining color and texture information derived from UAV-based digital images for estimating LAI of rice (Oryza sativa L.). Rice field trials were conducted at two sites using different nitrogen application rates, varieties, and transplanting methods during 2016 to 2017. Digital images were collected using a consumer-grade UAV after sampling at key growth stages of tillering, stem elongation, panicle initiation and booting. Vegetation color indices (CIs) and grey level co-occurrence matrix-based textures were extracted from mosaicked UAV ortho-images for each plot. As a solution of using indices composed by two different textures, normalized difference texture indices (NDTIs) were calculated by two randomly selected textures. The relationships between rice LAIs and each calculated index were then compared using simple linear regression. Multivariate regression models with different input sets were further used to test the potential of combining CIs with various textures for rice LAI estimation. The results revealed that the visible atmospherically resistant index (VARI) based on three visible bands and the NDTI based on the mean textures derived from the red and green bands were the best for LAI retrieval in the CI and NDTI groups, respectively. Independent accuracy assessment showed that random forest (RF) exhibited the best predictive performance when combining CI and texture inputs (R2 = 0.84, RMSE = 0.87, MAE = 0.69). This study introduces a promising solution of combining color indices and textures from UAV-based digital imagery for rice LAI estimation. Future studies are needed on finding the best operation mode, suitable ground resolution, and optimal predictive methods for practical applications.},
DOI = {10.3390/rs11151763}
}



@Article{rs11151771,
AUTHOR = {Dayananda, Supriya and Astor, Thomas and Wijesingha, Jayan and Chickadibburahalli Thimappa, Subbarayappa and Dimba Chowdappa, Hanumanthappa and Mudalagiriyappa and Nidamanuri, Rama Rao and Nautiyal, Sunil and Wachendorf, Michael},
TITLE = {Multi-Temporal Monsoon Crop Biomass Estimation Using Hyperspectral Imaging},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {1771},
URL = {https://www.mdpi.com/2072-4292/11/15/1771},
ISSN = {2072-4292},
ABSTRACT = {Hyperspectral remote sensing is considered to be an effective tool in crop monitoring and estimation of biomass. Many of the previous approaches are from single year or single date measurements, even though the complete crop growth with multiple years would be required for an appropriate estimation of biomass. The aim of this study was to estimate the fresh matter biomass (FMB) by terrestrial hyperspectral imaging of the three crops (lablab, maize and finger millet) under different levels of nitrogen fertiliser and water supply. Further, the importance of the different spectral regions for the estimation of FMB was assessed. The study was conducted in two experimental layouts (rainfed (R) and irrigated (I)) at the University of Agricultural Sciences, Bengaluru, India. Spectral images and the FMB were collected over three years (2016&ndash;2018) during the growing season of the crops. Random forest regression method was applied to build FMB models. R&sup2; validation (R&sup2;val) and relative root mean square error prediction (rRMSEP) was used to evaluate the FMB models. The Generalised model (combination of R and I data) performed better for lablab (R&sup2;val = 0.53, rRMSEP = 13.9%), maize (R&sup2;val = 0.53, rRMSEP = 18.7%) and finger millet (R&sup2;val = 0.46, rRMSEP = 18%) than the separate FMB models for R and I. In the best derived model, the most important variables contributing to the estimation of biomass were in the wavelength ranges of 546&ndash;910 nm (lablab), 750&ndash;794 nm (maize) and 686&ndash;814 nm (finger millet). The deviation of predicted and measured FMB did not differ much among the different levels of N and water supply. However, there was a trend of overestimation at the initial stage and underestimation at the later stages of crop growth.},
DOI = {10.3390/rs11151771}
}



@Article{rs11151774,
AUTHOR = {Yi, Yaning and Zhang, Zhijie and Zhang, Wanchang and Zhang, Chuanrong and Li, Weidong and Zhao, Tian},
TITLE = {Semantic Segmentation of Urban Buildings from VHR Remote Sensing Imagery Using a Deep Convolutional Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {1774},
URL = {https://www.mdpi.com/2072-4292/11/15/1774},
ISSN = {2072-4292},
ABSTRACT = {Urban building segmentation is a prevalent research domain for very high resolution (VHR) remote sensing; however, various appearances and complicated background of VHR remote sensing imagery make accurate semantic segmentation of urban buildings a challenge in relevant applications. Following the basic architecture of U-Net, an end-to-end deep convolutional neural network (denoted as DeepResUnet) was proposed, which can effectively perform urban building segmentation at pixel scale from VHR imagery and generate accurate segmentation results. The method contains two sub-networks: One is a cascade down-sampling network for extracting feature maps of buildings from the VHR image, and the other is an up-sampling network for reconstructing those extracted feature maps back to the same size of the input VHR image. The deep residual learning approach was adopted to facilitate training in order to alleviate the degradation problem that often occurred in the model training process. The proposed DeepResUnet was tested with aerial images with a spatial resolution of 0.075 m and was compared in performance under the exact same conditions with six other state-of-the-art networks&mdash;FCN-8s, SegNet, DeconvNet, U-Net, ResUNet and DeepUNet. Results of extensive experiments indicated that the proposed DeepResUnet outperformed the other six existing networks in semantic segmentation of urban buildings in terms of visual and quantitative evaluation, especially in labeling irregular-shape and small-size buildings with higher accuracy and entirety. Compared with the U-Net, the F1 score, Kappa coefficient and overall accuracy of DeepResUnet were improved by 3.52%, 4.67% and 1.72%, respectively. Moreover, the proposed DeepResUnet required much fewer parameters than the U-Net, highlighting its significant improvement among U-Net applications. Nevertheless, the inference time of DeepResUnet is slightly longer than that of the U-Net, which is subject to further improvement.},
DOI = {10.3390/rs11151774}
}



@Article{s19153316,
AUTHOR = {Salhaoui, Marouane and Guerrero-González, Antonio and Arioua, Mounir and Ortiz, Francisco J. and El Oualkadi, Ahmed and Torregrosa, Carlos Luis},
TITLE = {Smart Industrial IoT Monitoring and Control System Based on UAV and Cloud Computing Applied to a Concrete Plant},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {3316},
URL = {https://www.mdpi.com/1424-8220/19/15/3316},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles (UAVs) are now considered one of the best remote sensing techniques for gathering data over large areas. They are now being used in the industry sector as sensing tools for proactively solving or preventing many issues, besides quantifying production and helping to make decisions. UAVs are a highly consistent technological platform for efficient and cost-effective data collection and event monitoring. The industrial Internet of things (IIoT) sends data from systems that monitor and control the physical world to data processing systems that cloud computing has shown to be important tools for meeting processing requirements. In fog computing, the IoT gateway links different objects to the internet. It can operate as a joint interface for different networks and support different communication protocols. A great deal of effort has been put into developing UAVs and multi-UAV systems. This paper introduces a smart IIoT monitoring and control system based on an unmanned aerial vehicle that uses cloud computing services and exploits fog computing as the bridge between IIoT layers. Its novelty lies in the fact that the UAV is automatically integrated into an industrial control system through an IoT gateway platform, while UAV photos are systematically and instantly computed and analyzed in the cloud. Visual supervision of the plant by drones and cloud services is integrated in real-time into the control loop of the industrial control system. As a proof of concept, the platform was used in a case study in an industrial concrete plant. The results obtained clearly illustrate the feasibility of the proposed platform in providing a reliable and efficient system for UAV remote control to improve product quality and reduce waste. For this, we studied the communication latency between the different IIoT layers in different IoT gateways.},
DOI = {10.3390/s19153316}
}



@Article{robotics8030062,
AUTHOR = {Thomas, Ajith and Hedley, John},
TITLE = {FumeBot: A Deep Convolutional Neural Network Controlled Robot},
JOURNAL = {Robotics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {62},
URL = {https://www.mdpi.com/2218-6581/8/3/62},
ISSN = {2218-6581},
ABSTRACT = {This paper describes the development of a convolutional neural network for the control of a home monitoring robot (FumeBot). The robot is fitted with a Raspberry Pi for on board control and a Raspberry Pi camera is used as the data feed for the neural network. A wireless connection between the robot and a graphical user interface running on a laptop allows for the diagnostics and development of the neural network. The neural network, running on the laptop, was trained using a supervised training method. The robot was put through a series of obstacle courses to test its robustness, with the tests demonstrating that the controller has learned to navigate the obstacles to a reasonable level. The main problem identified in this work was that the neural controller did not have memory of past actions it took and a past state of the world resulting in obstacle collisions. Options to rectify this issue are suggested.},
DOI = {10.3390/robotics8030062}
}



@Article{s19153335,
AUTHOR = {Fuentes, Sigfredo and Tongson, Eden Jane and De Bei, Roberta and Gonzalez Viejo, Claudia and Ristic, Renata and Tyerman, Stephen and Wilkinson, Kerry},
TITLE = {Non-Invasive Tools to Detect Smoke Contamination in Grapevine Canopies, Berries and Wine: A Remote Sensing and Machine Learning Modeling Approach},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {3335},
URL = {https://www.mdpi.com/1424-8220/19/15/3335},
ISSN = {1424-8220},
ABSTRACT = {Bushfires are becoming more frequent and intensive due to changing climate. Those that occur close to vineyards can cause smoke contamination of grapevines and grapes, which can affect wines, producing smoke-taint. At present, there are no available practical in-field tools available for detection of smoke contamination or taint in berries. This research proposes a non-invasive/in-field detection system for smoke contamination in grapevine canopies based on predictable changes in stomatal conductance patterns based on infrared thermal image analysis and machine learning modeling based on pattern recognition. A second model was also proposed to quantify levels of smoke-taint related compounds as targets in berries and wines using near-infrared spectroscopy (NIR) as inputs for machine learning fitting modeling. Results showed that the pattern recognition model to detect smoke contamination from canopies had 96% accuracy. The second model to predict smoke taint compounds in berries and wine fit the NIR data with a correlation coefficient (R) of 0.97 and with no indication of overfitting. These methods can offer grape growers quick, affordable, accurate, non-destructive in-field screening tools to assist in vineyard management practices to minimize smoke taint in wines with in-field applications using smartphones and unmanned aerial systems (UAS).},
DOI = {10.3390/s19153335}
}



@Article{rs11151780,
AUTHOR = {Böhler, Jonas E. and Schaepman, Michael E. and Kneubühler, Mathias},
TITLE = {Optimal Timing Assessment for Crop Separation Using Multispectral Unmanned Aerial Vehicle (UAV) Data and Textural Features},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {1780},
URL = {https://www.mdpi.com/2072-4292/11/15/1780},
ISSN = {2072-4292},
ABSTRACT = {The separation of crop types is essential for many agricultural applications, particularly when within-season information is required. Generally, remote sensing may provide timely information with varying accuracy over the growing season, but in small structured agricultural areas, a very high spatial resolution may be needed that exceeds current satellite capabilities. This paper presents an experiment using spectral and textural features of NIR-red-green-blue (NIR-RGB) bands data sets acquired with an unmanned aerial vehicle (UAV). The study area is located in the Swiss Plateau, which has highly fragmented and small structured agricultural fields. The observations took place between May 5 and September 29, 2015 over 11 days. The analyses are based on a random forest (RF) approach, predicting crop separation metrics of all analyzed crops. Three temporal windows of observations based on accumulated growing degree days (AGDD) were identified: an early temporal window (515&ndash;1232 AGDD, 5 May&ndash;17 June 2015) with an average accuracy (AA) of 70&ndash;75%; a mid-season window (1362&ndash;2016 AGDD, 25 June&ndash;22 July 2015) with an AA of around 80%; and a late window (2626&ndash;3238 AGDD, 21 August&ndash;29 September 2015) with an AA of &lt;65%. Therefore, crop separation is most promising in the mid-season window, and an additional NIR band increases the accuracy significantly. However, discrimination of winter crops is most effective in the early window, adding further observational requirements to the first window.},
DOI = {10.3390/rs11151780}
}



@Article{app9153099,
AUTHOR = {Hashmi, Muhammad Zeeshan Ul Hasnain and Riaz, Qaiser and Hussain, Mehdi and Shahzad, Muhammad},
TITLE = {What Lies Beneath One’s Feet? Terrain Classification Using Inertial Data of Human Walk},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {3099},
URL = {https://www.mdpi.com/2076-3417/9/15/3099},
ISSN = {2076-3417},
ABSTRACT = {The objective of this study was to investigate if the inertial data collected from normal human walk can be used to reveal the underlying terrain types. For this purpose, we recorded the gait patterns of normal human walk on six different terrain types with variation in hardness and friction using body mounted inertial sensors. We collected accelerations and angular velocities of 40 healthy subjects with two smartphones embedded inertial measurement units (MPU-6500) attached at two different body locations (chest and lower back). The recorded data were segmented with stride based segmentation approach and 194 tempo-spectral features were computed for each stride. We trained two machine learning classifiers, namely random forest and support vector machine, and cross validated the results with 10-fold cross-validation strategy. The classification tasks were performed on indoor&ndash;outdoor terrains, hard&ndash;soft terrains, and a combination of binary, ternary, quaternary, quinary and senary terrains. From the experimental results, the classification accuracies of 97% and 92% were achieved for indoor&ndash;outdoor and hard&ndash;soft terrains, respectively. The classification results for binary, ternary, quaternary, quinary and senary class classification were 96%, 94%, 92%, 90%, and 89%, respectively. These results demonstrate that the stride data collected with the low-level signals of a single IMU can be used to train classifiers and predict terrain types with high accuracy. Moreover, the problem at hand can be solved invariant of sensor type and sensor location.},
DOI = {10.3390/app9153099}
}



@Article{rs11151797,
AUTHOR = {Wyngaard, Jane and Barbieri, Lindsay and Thomer, Andrea and Adams, Josip and Sullivan, Don and Crosby, Christopher and Parr, Cynthia and Klump, Jens and Raj Shrestha, Sudhir and Bell, Tom},
TITLE = {Emergent Challenges for Science sUAS Data Management: Fairness through Community Engagement and Best Practices Development},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {1797},
URL = {https://www.mdpi.com/2072-4292/11/15/1797},
ISSN = {2072-4292},
ABSTRACT = {The use of small Unmanned Aircraft Systems (sUAS) as platforms for data capture has rapidly increased in recent years. However, while there has been significant investment in improving the aircraft, sensors, operations, and legislation infrastructure for such, little attention has been paid to supporting the management of the complex data capture pipeline sUAS involve. This paper reports on a four-year, community-based investigation into the tools, data practices, and challenges that currently exist for particularly researchers using sUAS as data capture platforms. The key results of this effort are: (1) sUAS captured data&mdash;as a set that is rapidly growing to include data in a wide range of Physical and Environmental Sciences, Engineering Disciplines, and many civil and commercial use cases&mdash;is characterized as both sharing many traits with traditional remote sensing data and also as exhibiting&mdash;as common across the spectrum of disciplines and use cases&mdash;novel characteristics that require novel data support infrastructure; and (2), given this characterization of sUAS data and its potential value in the identified wide variety of use case, we outline eight challenges that need to be addressed in order for the full value of sUAS captured data to be realized. We conclude that there would be significant value gained and costs saved across both commercial and academic sectors if the global sUAS user and data management communities were to address these challenges in the immediate to near future, so as to extract the maximal value of sUAS captured data for the lowest long-term effort and monetary cost.},
DOI = {10.3390/rs11151797}
}



@Article{electronics8080856,
AUTHOR = {Konecny, Jaromir and Kromer, Pavel and Prauzek, Michal and Musilek, Petr},
TITLE = {Scan Matching by Cross-Correlation and Differential Evolution},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {856},
URL = {https://www.mdpi.com/2079-9292/8/8/856},
ISSN = {2079-9292},
ABSTRACT = {Scan matching is an important task, solved in the context of many high-level problems including pose estimation, indoor localization, simultaneous localization and mapping and others. Methods that are accurate and adaptive and at the same time computationally efficient are required to enable location-based services in autonomous mobile devices. Such devices usually have a wide range of high-resolution sensors but only a limited processing power and constrained energy supply. This work introduces a novel high-level scan matching strategy that uses a combination of two advanced algorithms recently used in this field: cross-correlation and differential evolution. The cross-correlation between two laser range scans is used as an efficient measure of scan alignment and the differential evolution algorithm is used to search for the parameters of a transformation that aligns the scans. The proposed method was experimentally validated and showed good ability to match laser range scans taken shortly after each other and an excellent ability to match laser range scans taken with longer time intervals between them.},
DOI = {10.3390/electronics8080856}
}



@Article{rs11151812,
AUTHOR = {Dash, Jonathan P. and Watt, Michael S. and Paul, Thomas S. H. and Morgenroth, Justin and Pearse, Grant D.},
TITLE = {Early Detection of Invasive Exotic Trees Using UAV and Manned Aircraft Multispectral and LiDAR Data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {1812},
URL = {https://www.mdpi.com/2072-4292/11/15/1812},
ISSN = {2072-4292},
ABSTRACT = {Exotic conifers can provide significant ecosystem services, but in some environments, they have become invasive and threaten indigenous ecosystems. In New Zealand, this phenomenon is of considerable concern as the area occupied by invasive exotic trees is large and increasing rapidly. Remote sensing methods offer a potential means of identifying and monitoring land infested by these trees, enabling managers to efficiently allocate resources for their control. In this study, we sought to develop methods for remote detection of exotic invasive trees, namely Pinus sylvestris and P. ponderosa. Critically, the study aimed to detect these species prior to the onset of maturity and coning as this is important for preventing further spread. In the study environment in New Zealand&rsquo;s South Island, these species reach maturity and begin bearing cones at a young age. As such, detection of these smaller individuals requires specialist methods and very high-resolution remote sensing data. We examined the efficacy of classifiers developed using two machine learning algorithms with multispectral and laser scanning data collected from two platforms&mdash;manned aircraft and unmanned aerial vehicles (UAV). The study focused on a localized conifer invasion originating from a multi-species pine shelter belt in a grassland environment. This environment provided a useful means of defining the detection thresholds of the methods and technologies employed. An extensive field dataset including over 17,000 trees (height range = 1 cm to 476 cm) was used as an independent validation dataset for the detection methods developed. We found that data from both platforms and using both logistic regression and random forests for classification provided highly accurate (kappa     &lt; 0.996    ) detection of invasive conifers. Our analysis showed that the data from both UAV and manned aircraft was useful for detecting trees down to 1 m in height and therefore shorter than 99.3% of the coning individuals in the study dataset. We also explored the relative contribution of both multispectral and airborne laser scanning (ALS) data in the detection of invasive trees through fitting classification models with different combinations of predictors and found that the most useful models included data from both sensors. However, the combination of ALS and multispectral data did not significantly improve classification accuracy. We believe that this was due to the simplistic vegetation and terrain structure in the study site that resulted in uncomplicated separability of invasive conifers from other vegetation. This study provides valuable new knowledge of the efficacy of detecting invasive conifers prior to the onset of coning using high-resolution data from UAV and manned aircraft. This will be an important tool in managing the spread of these important invasive plants.},
DOI = {10.3390/rs11151812}
}



@Article{app9153150,
AUTHOR = {Choi, In Hyuk and Son, Ju Am and Koo, Ja Bin and Yoon, Young Geun and Oh, Tae Keun},
TITLE = {Damage Assessment of Porcelain Insulators through Principal Component Analysis Associated with Frequency Response Signals},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {3150},
URL = {https://www.mdpi.com/2076-3417/9/15/3150},
ISSN = {2076-3417},
ABSTRACT = {More than 55% of porcelain insulators installed throughout Korea have exceeded their service life. Hence, utilities are extremely interested in determining the robustness of insulators in their systems. In this study, the identification of the peak ranges in the main natural modes by frequency response analysis, the principal component analysis (PCA) method by feature extraction in the time and frequency domains for the damage detection of porcelain insulators are investigated; among these, the PCA method, which utilizes frequency response data, is proposed for defect classification. The 67 porcelain insulators are secured as specimens from 154 kV transmission towers installed in various parts of Korea; their main materials are cristobalite and alumina. In these specimens, it is observed that the three types of damage, such as porcelain damage, cap damage, and internal damage, are those that are typically found in actual sites. Accordingly, the use of two eigenvectors (moments of real value and moments of imaginary value) considerably aids in the analysis of principal components. With the frequency response data, the material and damage types are found to be distinguishable. The classification accuracy is increased by including the third largest eigenvector (area of real value) in three-dimensional analysis. By employing frequency response data, the PCA method provides useful information for assessing the integrity of porcelain insulators; it may be used as basis for future machine learning applications.},
DOI = {10.3390/app9153150}
}



@Article{rs11151816,
AUTHOR = {Iizuka, Kotaro and Kato, Tsuyoshi and Silsigia, Sisva and Soufiningrum, Alifia Yuni and Kozan, Osamu},
TITLE = {Estimating and Examining the Sensitivity of Different Vegetation Indices to Fractions of Vegetation Cover at Different Scaling Grids for Early Stage Acacia Plantation Forests Using a Fixed-Wing UAS},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {1816},
URL = {https://www.mdpi.com/2072-4292/11/15/1816},
ISSN = {2072-4292},
ABSTRACT = {Understanding the information on land conditions and especially green vegetation cover is important for monitoring ecosystem dynamics. The fraction of vegetation cover (FVC) is a key variable that can be used to observe vegetation cover trends. Conventionally, satellite data are utilized to compute these variables, although computations in regions such as the tropics can limit the amount of available observation information due to frequent cloud coverage. Unmanned aerial systems (UASs) have become increasingly prominent in recent research and can remotely sense using the same methods as satellites but at a lower altitude. UASs are not limited by clouds and have a much higher resolution. This study utilizes a UAS to determine the emerging trends for FVC estimates at an industrial plantation site in Indonesia, which utilizes fast-growing Acacia trees that can rapidly change the land conditions. First, the UAS was utilized to collect high-resolution RGB imagery and multispectral images for the study area. The data were used to develop general land use/land cover (LULC) information for the site. Multispectral data were converted to various vegetation indices, and within the determined resolution grid (5, 10, 30 and 60 m), the fraction of each LULC type was analyzed for its correlation between the different vegetation indices (Vis). Finally, a simple empirical model was developed to estimate the FVC from the UAS data. The results show the correlation between the FVC (acacias) and different Vis ranging from R2 = 0.66&ndash;0.74, 0.76&ndash;0.8, 0.84&ndash;0.89 and 0.93&ndash;0.94 for 5, 10, 30 and 60 m grid resolutions, respectively. This study indicates that UAS-based FVC estimations can be used for observing fast-growing acacia trees at a fine scale resolution, which may assist current restoration programs in Indonesia.},
DOI = {10.3390/rs11151816}
}



@Article{computers8030058,
AUTHOR = {Ferrag, Mohamed Amine and Maglaras, Leandros},
TITLE = {DeliveryCoin: An IDS and Blockchain-Based Delivery Framework for Drone-Delivered Services},
JOURNAL = {Computers},
VOLUME = {8},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {58},
URL = {https://www.mdpi.com/2073-431X/8/3/58},
ISSN = {2073-431X},
ABSTRACT = {In this paper, we propose an intrusion detection system (IDS) and Blockchain-based delivery framework, called DeliveryCoin, for drone-delivered services. The DeliveryCoin framework consists of four phases, including system initialization phase, creating the block, updating the blockchain, and intrusion detection phase. To achieve privacy-preservation, the DeliveryCoin framework employs hash functions and short signatures without random oracles and the Strong Diffie&ndash;Hellman (SDH) assumption in bilinear groups. To achieve consensus inside the blockchain-based delivery platform, we introduce a UAV-aided forwarding mechanism, named pBFTF. We also propose an IDS system in each macro eNB (5G) for detecting self-driving network attacks as well as false transactions between self-driving nodes. Furthermore, extensive simulations are conducted, and results confirm the efficiency of our proposed DeliveryCoin framework in terms of latency of blockchain consensus and accuracy.},
DOI = {10.3390/computers8030058}
}



@Article{rs11151835,
AUTHOR = {Askari, Mohammad Sadegh and McCarthy, Timothy and Magee, Aidan and Murphy, Darren J.},
TITLE = {Evaluation of Grass Quality under Different Soil Management Scenarios Using Remote Sensing Techniques},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {1835},
URL = {https://www.mdpi.com/2072-4292/11/15/1835},
ISSN = {2072-4292},
ABSTRACT = {Hyperspectral and multispectral imagery have been demonstrated to have a considerable potential for near real-time monitoring and mapping of grass quality indicators. The objective of this study was to evaluate the efficiency of remote sensing techniques for quantification of aboveground grass biomass (BM) and crude protein (CP) in a temperate European climate such as Ireland. The experiment was conducted on 64 plots and 53 paddocks with varying quantities of nitrogen applied. Hyperspectral imagery (HSI) and multispectral imagery (MSI) were analyzed to develop the prediction models. The MSI data used in this study were captured using an unmanned aircraft vehicle (UAV) and the satellite Sentinel-2, while the HSI data were obtained using a handheld hyperspectral camera. The prediction models were developed using partial least squares regression (PLSR) and stepwise multi-linear regression (MLR). Eventually, the spatial distribution of grass biomass over plots and paddocks was mapped to assess the within-field variability of grass quality metrics. An excellent accuracy was achieved for the prediction of BM and CP using HSI (RPD &gt; 2.5 and R2 &gt; 0.8), and a good accuracy was obtained via MSI-UAV (2 &lt; RPD &lt; 2.5 and R2 &gt; 0.7) for the grass quality indicators. The accuracy of the models calculated using MSI-Sentinel-2 was reasonable for BM prediction and insufficient for CP estimation. The red-edge range of the wavelengths showed the maximum impact on the predictability of grass BM, and the NIR range had the greatest influence on the estimation of grass CP. Both the PLSR and MLR techniques were found to be sufficiently robust for spectral modelling of aboveground BM and CP. The PLSR yielded a slightly better model than MLR. This study suggested that remote sensing techniques can be used as a rapid and reliable approach for near real-time quantitative assessment of fresh grass quality under a temperate European climate.},
DOI = {10.3390/rs11151835}
}



@Article{rs11151837,
AUTHOR = {Brinkhoff, James and Dunn, Brian W. and Robson, Andrew J. and Dunn, Tina S. and Dehaan, Remy L.},
TITLE = {Modeling Mid-Season Rice Nitrogen Uptake Using Multispectral Satellite Data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {15},
ARTICLE-NUMBER = {1837},
URL = {https://www.mdpi.com/2072-4292/11/15/1837},
ISSN = {2072-4292},
ABSTRACT = {Mid-season nitrogen (N) application in rice crops can maximize yield and profitability. This requires accurate and efficient methods of determining rice N uptake in order to prescribe optimal N amounts for topdressing. This study aims to determine the accuracy of using remotely sensed multispectral data from satellites to predict N uptake of rice at the panicle initiation (PI) growth stage, with a view to providing optimum variable-rate N topdressing prescriptions without needing physical sampling. Field experiments over 4 years, 4&ndash;6 N rates, 4 varieties and 2 sites were conducted, with at least 3 replicates of each plot. One WorldView satellite image for each year was acquired, close to the date of PI. Numerous single- and multi-variable models were investigated. Among single-variable models, the square of the NDRE vegetation index was shown to be a good predictor of N uptake (R     2     = 0.75, RMSE = 22.8 kg/ha for data pooled from all years and experiments). For multi-variable models, Lasso regularization was used to ensure an interpretable and compact model was chosen and to avoid over fitting. Combinations of remotely sensed reflectances and spectral indexes as well as variety, climate and management data as input variables for model training achieved R     2    &lt; 0.9 and RMSE &lt; 15 kg/ha for the pooled data set. The ability of remotely sensed data to predict N uptake in new seasons where no physical sample data has yet been obtained was tested. A methodology to extract models that generalize well to new seasons was developed, avoiding model overfitting. Lasso regularization selected four or less input variables, and yielded R     2     of better than 0.67 and RMSE better than 27.4 kg/ha over four test seasons that weren&rsquo;t used to train the models.},
DOI = {10.3390/rs11151837}
}



@Article{make1030052,
AUTHOR = {Zahidi, Usman A. and Chatterjee, Ayan and Yuen, Peter W. T.},
TITLE = {A Radiative Transfer Model-Based Multi-Layered Regression Learning to Estimate Shadow Map in Hyperspectral Images},
JOURNAL = {Machine Learning and Knowledge Extraction},
VOLUME = {1},
YEAR = {2019},
NUMBER = {3},
PAGES = {904--927},
URL = {https://www.mdpi.com/2504-4990/1/3/52},
ISSN = {2504-4990},
ABSTRACT = {The application of Empirical Line Method (ELM) for hyperspectral Atmospheric Compensation (AC) premises the underlying linear relationship between a material&rsquo;s reflectance and appearance. ELM solves the Radiative Transfer (RT) equation under specialized constraint by means of in-scene white and black calibration panels. The reflectance of material is invariant to illumination. Exploiting this property, we articulated a mathematical formulation based on the RT model to create cost functions relating variably illuminated regions within a scene. In this paper, we propose multi-layered regression learning-based recovery of radiance components, i.e., total ground-reflected radiance and path radiance from reflectance and radiance images of the scene. These decomposed components represent terms in the RT equation and enable us to relate variable illumination. Therefore, we assume that Hyperspectral Image (HSI) radiance of the scene is provided and AC can be processed on it, preferably with QUick Atmospheric Correction (QUAC) algorithm. QUAC is preferred because it does not account for surface models. The output from the proposed algorithm is an intermediate map of the scene on which our mathematically derived binary and multi-label threshold is applied to classify shadowed and non-shadowed regions. Results from a satellite and airborne NADIR imagery are shown in this paper. Ground truth (GT) is generated by ray-tracing on a LIDAR-based surface model in the form of contour data, of the scene. Comparison of our results with GT implies that our algorithm&rsquo;s binary classification shadow maps outperform other existing shadow detection algorithms in true positive, which is the detection of shadows when it is in ground truth. It also has the lowest false negative i.e., detecting non-shadowed region as shadowed, compared to existing algorithms.},
DOI = {10.3390/make1030052}
}



@Article{s19163451,
AUTHOR = {Lay, Usman Salihu and Pradhan, Biswajeet and Yusoff, Zainuddin Bin Md and Abdallah, Ahmad Fikri Bin and Aryal, Jagannath and Park, Hyuck-Jin},
TITLE = {Data Mining and Statistical Approaches in Debris-Flow Susceptibility Modelling Using Airborne LiDAR Data},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {16},
ARTICLE-NUMBER = {3451},
URL = {https://www.mdpi.com/1424-8220/19/16/3451},
ISSN = {1424-8220},
ABSTRACT = {Cameron Highland is a popular tourist hub in the mountainous area of Peninsular Malaysia. Most communities in this area suffer frequent incidence of debris flow, especially during monsoon seasons. Despite the loss of lives and properties recorded annually from debris flow, most studies in the region concentrate on landslides and flood susceptibilities. In this study, debris-flow susceptibility prediction was carried out using two data mining techniques; Multivariate Adaptive Regression Splines (MARS) and Support Vector Regression (SVR) models. The existing inventory of debris-flow events (640 points) were selected for training 70% (448) and validation 30% (192). Twelve conditioning factors namely; elevation, plan-curvature, slope angle, total curvature, slope aspect, Stream Transport Index (STI), profile curvature, roughness index, Stream Catchment Area (SCA), Stream Power Index (SPI), Topographic Wetness Index (TWI) and Topographic Position Index (TPI) were selected from Light Detection and Ranging (LiDAR)-derived Digital Elevation Model (DEM) data. Multi-collinearity was checked using Information Factor, Cramer&rsquo;s V, and Gini Index to identify the relative importance of conditioning factors. The susceptibility models were produced and categorized into five classes; not-susceptible, low, moderate, high and very-high classes. Models performances were evaluated using success and prediction rates where the area under the curve (AUC) showed a higher performance of MARS (93% and 83%) over SVR (76% and 72%). The result of this study will be important in contingency hazards and risks management plans to reduce the loss of lives and properties in the area.},
DOI = {10.3390/s19163451}
}



@Article{s19163465,
AUTHOR = {Pongsakornsathien, Nichakorn and Lim, Yixiang and Gardi, Alessandro and Hilton, Samuel and Planke, Lars and Sabatini, Roberto and Kistan, Trevor and Ezer, Neta},
TITLE = {Sensor Networks for Aerospace Human-Machine Systems},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {16},
ARTICLE-NUMBER = {3465},
URL = {https://www.mdpi.com/1424-8220/19/16/3465},
ISSN = {1424-8220},
ABSTRACT = {Intelligent automation and trusted autonomy are being introduced in aerospace cyber-physical systems to support diverse tasks including data processing, decision-making, information sharing and mission execution. Due to the increasing level of integration/collaboration between humans and automation in these tasks, the operational performance of closed-loop human-machine systems can be enhanced when the machine monitors the operator’s cognitive states and adapts to them in order to maximise the effectiveness of the Human-Machine Interfaces and Interactions (HMI2). Technological developments have led to neurophysiological observations becoming a reliable methodology to evaluate the human operator’s states using a variety of wearable and remote sensors. The adoption of sensor networks can be seen as an evolution of this approach, as there are notable advantages if these sensors collect and exchange data in real-time, while their operation is controlled remotely and synchronised. This paper discusses recent advances in sensor networks for aerospace cyber-physical systems, focusing on Cognitive HMI2 (CHMI2) implementations. The key neurophysiological measurements used in this context and their relationship with the operator’s cognitive states are discussed. Suitable data analysis techniques based on machine learning and statistical inference are also presented, as these techniques allow processing both neurophysiological and operational data to obtain accurate cognitive state estimations. Lastly, to support the development of sensor networks for CHMI2 applications, the paper addresses the performance characterisation of various state-of-the-art sensors and the propagation of measurement uncertainties through a machine learning-based inference engine. Results show that a proper sensor selection and integration can support the implementation of effective human-machine systems for various challenging aerospace applications, including Air Traffic Management (ATM), commercial airliner Single-Pilot Operations (SIPO), one-to-many Unmanned Aircraft Systems (UAS), and space operations management.},
DOI = {10.3390/s19163465}
}



@Article{ECRS-3-06184,
AUTHOR = {KAPLAN, Gordana and AVDAN, Ugur},
TITLE = {Evaluating Sentinel-2 Red-Edge Bands for Wetland Classification},
JOURNAL = {Proceedings},
VOLUME = {18},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {12},
URL = {https://www.mdpi.com/2504-3900/18/1/12},
ISSN = {2504-3900},
ABSTRACT = {Due to the high spatial heterogeneity and temporal variability, wetlands are one of the most difficult ecosystems to observe using remote sensing data. With the additional Sentinel-2 vegetation red-edge bands, an improvement of the vegetated classes classification is expected. In order to investigate the influence of the Sentinel-2 red-edge bands, in this paper we evaluate two classification scenarios over wetland classes. The first scenario excludes the red-edge bands, while in the second scenario all red-edge bands are included in the classification dataset where two different wetland classes&mdash;intensive vegetated wetland classes such as swamps and partially decayed vegetated wetland areas such as bogs&mdash;are classified using a support vector machine (SVM) learning classifier. The classes are defined using high-resolution images from an Unmanned Aerial Vehicle (UAV) obtained on the same date with the passing of the Sentinel-2 satellite over the study area. As expected, the results show a significant improvement of the intensive vegetated wetlands, with more than 30% in both user and producer accuracy, while no significant changes are noted in the partially decayed vegetated wetlands. For future studies, we recommend evaluating the influence of the Sentinel radar data over wetland areas.},
DOI = {10.3390/ECRS-3-06184}
}



@Article{rs11161859,
AUTHOR = {Dyson, Jack and Mancini, Adriano and Frontoni, Emanuele and Zingaretti, Primo},
TITLE = {Deep Learning for Soil and Crop Segmentation from Remotely Sensed Data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {16},
ARTICLE-NUMBER = {1859},
URL = {https://www.mdpi.com/2072-4292/11/16/1859},
ISSN = {2072-4292},
ABSTRACT = {One of the most challenging problems in precision agriculture is to correctly identify and separate crops from the soil. Current precision farming algorithms based on artificially intelligent networks use multi-spectral or hyper-spectral data to derive radiometric indices that guide the operational management of agricultural complexes. Deep learning applications using these big data require sensitive filtering of raw data to effectively drive their hidden layer neural network architectures. Threshold techniques based on the normalized difference vegetation index (NDVI) or other similar metrics are generally used to simplify the development and training of deep learning neural networks. They have the advantage of being natural transformations of hyper-spectral or multi-spectral images that filter the data stream into a neural network, while reducing training requirements and increasing system classification performance. In this paper, to calculate a detailed crop/soil segmentation based on high resolution Digital Surface Model (DSM) data, we propose the redefinition of the radiometric index using a directional mathematical filter. To further refine the analysis, we feed this new radiometric index image of about 3500 &times; 4500 pixels into a relatively small Convolution Neural Network (CNN) designed for general image pattern recognition at 28 &times; 28 pixels to evaluate and resolve the vegetation correctly. We show that the result of applying a DSM filter to the NDVI radiometric index before feeding it into a Convolutional Neural Network can potentially improve crop separation hit rate by 65%.},
DOI = {10.3390/rs11161859}
}



@Article{geosciences9080350,
AUTHOR = {Polykretis, Christos and Kalogeropoulos, Kleomenis and Andreopoulos, Panagiotis and Faka, Antigoni and Tsatsaris, Andreas and Chalkias, Christos},
TITLE = {Comparison of Statistical Analysis Models for Susceptibility Assessment of Earthquake-Triggered Landslides: A Case Study from 2015 Earthquake in Lefkada Island},
JOURNAL = {Geosciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {350},
URL = {https://www.mdpi.com/2076-3263/9/8/350},
ISSN = {2076-3263},
ABSTRACT = {The main purpose of this study is to comparatively assess the susceptibility of earthquake-triggered landslides in the island of Lefkada (Ionian Islands, Greece) using two different statistical analysis models, a bivariate model represented by frequency ratio (FR), and a multivariate model represented by logistic regression (LR). For the implementation of the models, the relationship between geo-environmental factors contributing to landslides and documented events related to the 17th November 2015 earthquake was investigated by geographic information systems (GIS)-based analysis. A landslide inventory with events attributed to the specific earthquake was prepared using satellite imagery interpretation and field surveys. Eight factors: Elevation, slope angle, slope aspect, distance to main road network, distance to faults, land cover, geology, and peak ground acceleration (PGA), were considered and used as thematic data layers. The prediction capability of the models and the accuracy of the resulting susceptibility maps were tested by a standard validation method, the receiver operator characteristic (ROC) analysis. Based on the validation results, the output map with the highest reliability could potentially constitute an ideal basis for use within regional spatial planning as well as for the organization of emergency actions by local authorities.},
DOI = {10.3390/geosciences9080350}
}



@Article{rs11161877,
AUTHOR = {Strimbu, Bogdan M. and Qi, Chu and Sessions, John},
TITLE = {Accurate Geo-Referencing of Trees with No or Inaccurate Terrestrial Location Devices},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {16},
ARTICLE-NUMBER = {1877},
URL = {https://www.mdpi.com/2072-4292/11/16/1877},
ISSN = {2072-4292},
ABSTRACT = {Accurate and precise location of trees from data acquired under-the-canopy is challenging and time-consuming. However, current forestry practices would benefit tremendously from the knowledge of tree coordinates, particularly when the information used to position them is acquired with inexpensive sensors. Therefore, the objective of our study is to geo-reference trees using point clouds created from the images acquired below canopy. We developed a procedure that uses the coordinates of the trees seen from above canopy to position the same trees seen below canopy. To geo-reference the trees from above canopy we captured images with an unmanned aerial vehicle. We reconstructed the trunk with photogrammetric point clouds built with a structure&ndash;from&ndash;motion procedure from images recorded in a circular pattern at multiple locations throughout the stand. We matched the trees segmented from below canopy with the trees extracted from above canopy using a non-rigid point-matching algorithm. To ensure accuracy, we reduced the number of matching trees by dividing the trees segmented from above using a grid with 50 m cells. Our procedure was implemented on a 7.1 ha Douglas-fir stand from Oregon USA. The proposed procedure is relatively fast, as approximately 600 trees were mapped in approximately 1 min. The procedure is sensitive to the point density, directly impacting tree location, as differences larger than 2 m between the coordinates of the tree top and the bottom part of the stem could lead to matching errors larger than 1 m. Furthermore, the larger the number of trees to be matched the higher the accuracy is, which could allow for misalignment errors larger than 2 m between the locations of the trees segmented from above and below.},
DOI = {10.3390/rs11161877}
}



@Article{s19163517,
AUTHOR = {Ji, Zheng and Liao, Yifan and Zheng, Li and Wu, Liang and Yu, Manzhu and Feng, Yanjie},
TITLE = {An Assembled Detector Based on Geometrical Constraint for Power Component Recognition},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {16},
ARTICLE-NUMBER = {3517},
URL = {https://www.mdpi.com/1424-8220/19/16/3517},
ISSN = {1424-8220},
ABSTRACT = {The intelligent inspection of power lines and other difficult-to-access structures and facilities has been greatly enhanced by the use of Unmanned Aerial Vehicles (UAVs), which allow inspection in a safe, efficient, and high-quality fashion. This paper analyzes the characteristics of a scene containing power equipment and the operation mode of UAVs. A low-cost virtual scene is created, and a training sample for the power-line components is generated quickly. Taking a vibration-damper as the main object, an assembled detector based on geometrical constraint (ADGC) is proposed and is used to analyze the virtual dataset. The geometric positional relationship is used as the constraint, and the Faster Region with Convolutional Neural Network (R-CNN), Deformable Part Model (DPM), and Haar cascade classifiers are combined, which allows the features of different classifiers, such as contour, shape, and texture to be fully used. By combining the characteristics of virtual data and real data using UAV images, the power components are detected by the ADGC. The result produced by the detector with relatively good performance can help expand the training set and achieve a better detection model. Moreover, this method can be smoothly transferred to other power-line facilities and other power-line scenarios.},
DOI = {10.3390/s19163517}
}



@Article{photonics6030091,
AUTHOR = {Zhan, Shuyue and Zhou, Weiwen and Ma, Xu and Huang, Hui},
TITLE = {Hyperspectral Imaging Bioinspired by Chromatic Blur Vision in Color Blind Animals},
JOURNAL = {Photonics},
VOLUME = {6},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {91},
URL = {https://www.mdpi.com/2304-6732/6/3/91},
ISSN = {2304-6732},
ABSTRACT = {Hyperspectral imaging remote sensing is mutually restricted in terms of spatial and spectral resolutions, signal-to-noise ratio and exposure time. To deal with this trade-off properly, it is beneficial for imaging systems to have high light flux. In this paper, we put forward a novel hyperspectral imaging method with high light flux bioinspired by chromatic blur vision in color blind animals. We designed a camera lens with high degree of longitudinal chromatic aberration, a monochrome image sensor captured the chromatic blur images at different focal lengths. Finally, by using the known point spread functions of the chromatic blur imaging system, we process these chromatically blurred images by deconvolution based on singular value decomposition inverse filtering, and the spectral images of a target were restored. We constructed three different targets for validating image restoration based on a typical octopus eyeball imaging system. The results show that the proposed imaging method can effectively extract spectral images from the chromatically blurred images. This study can facilitate development of a novel bionic hyperspectral imaging, which may benefit from the high light flux of a large aperture and provide higher detection sensitivity.},
DOI = {10.3390/photonics6030091}
}



@Article{agriculture9080179,
AUTHOR = {Gage, Karla L. and Schwartz-Lazaro, Lauren M.},
TITLE = {Shifting the Paradigm: An Ecological Systems Approach to Weed Management},
JOURNAL = {Agriculture},
VOLUME = {9},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {179},
URL = {https://www.mdpi.com/2077-0472/9/8/179},
ISSN = {2077-0472},
ABSTRACT = {Weeds have been historically, and are still today, the primary and most economically important pest in agriculture. Several selection pressures associated with weed management, such as an overreliance on herbicides, have promoted the rapid evolution of herbicide-resistant weeds. Integrated Weed Management (IWM) is promoted as an ecological systems approach, through the combination of biological, chemical, cultural, ecological, and mechanical control methods. The concept of a systems approach is defined as managing weeds by combining practice and knowledge with the goals of increasing yield and minimizing economic loss, minimizing risks to human health and the environment, and reducing energy requirements and off-target impacts. The reliance on herbicides in modern cropping systems has shifted the management focus from requiring intimate knowledge of biology, ecology, and ecological systems to herbicide chemistry, mixes, and rotations, application technology, and herbicide-tolerant crop traits. Here, an ecological systems approach is considered, examining new trends and technologies in relation to IWM and weed ecology. Prevention of spread, seedbank management, crop rotations, tillage, cover crops, competitive cultivars, biological weed control, and future solutions in concept-only are presented, and knowledge gaps are identified where research advancements may be possible. An ecological systems approach will provide improved stewardship of new herbicide technologies and reduce herbicide resistance evolution through diversification of selection pressures. Agroecological interactions should be studied in light of new, developing weed control technologies. The science of weed management needs to refocus on the foundations of weed biology and ecology to enable an ecological systems approach and promote agricultural sustainability.},
DOI = {10.3390/agriculture9080179}
}



@Article{s19163542,
AUTHOR = {Lygouras, Eleftherios and Santavas, Nicholas and Taitzoglou, Anastasios and Tarchanidis, Konstantinos and Mitropoulos, Athanasios and Gasteratos, Antonios},
TITLE = {Unsupervised Human Detection with an Embedded Vision System on a Fully Autonomous UAV for Search and Rescue Operations},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {16},
ARTICLE-NUMBER = {3542},
URL = {https://www.mdpi.com/1424-8220/19/16/3542},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles (UAVs) play a primary role in a plethora of technical and scientific fields owing to their wide range of applications. In particular, the provision of emergency services during the occurrence of a crisis event is a vital application domain where such aerial robots can contribute, sending out valuable assistance to both distressed humans and rescue teams. Bearing in mind that time constraints constitute a crucial parameter in search and rescue (SAR) missions, the punctual and precise detection of humans in peril is of paramount importance. The paper in hand deals with real-time human detection onboard a fully autonomous rescue UAV. Using deep learning techniques, the implemented embedded system was capable of detecting open water swimmers. This allowed the UAV to provide assistance accurately in a fully unsupervised manner, thus enhancing first responder operational capabilities. The novelty of the proposed system is the combination of global navigation satellite system (GNSS) techniques and computer vision algorithms for both precise human detection and rescue apparatus release. Details about hardware configuration as well as the system&rsquo;s performance evaluation are fully discussed.},
DOI = {10.3390/s19163542}
}



@Article{rs11161900,
AUTHOR = {Wang, Luyao and Fan, Hong and Wang, Yankun},
TITLE = {Fine-Resolution Population Mapping from International Space Station Nighttime Photography and Multisource Social Sensing Data Based on Similarity Matching},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {16},
ARTICLE-NUMBER = {1900},
URL = {https://www.mdpi.com/2072-4292/11/16/1900},
ISSN = {2072-4292},
ABSTRACT = {Previous studies have attempted to disaggregate census data into fine resolution with multisource remote sensing data considering the importance of fine-resolution population distribution in urban planning, environmental protection, resource allocation, and social economy. However, the lack of direct human activity information invariably restricts the accuracy of population mapping and reduces the credibility of the mapping process even when external facility distribution information is adopted. To address these problems, the present study proposed a novel population mapping method by combining International Space Station (ISS) photography nighttime light data, point of interest (POI) data, and location-based social media data. A similarity matching model, consisting of semantic and distance matching models, was established to integrate POI and social media data. Effective information was extracted from the integrated data through principal component analysis and then used along with road density information to train the random forest (RF) model. A comparison with WordPop data proved that our method can generate fine-resolution population distribution with higher accuracy (     R 2  = 0.91    ) than those of previous studies (     R 2  = 0.55    ). To illustrate the advantages of our method, we highlighted the limitations of previous methods that ignore social media data in handling residential regions with similar light intensity. We also discussed the performance of our method in adopting social media data, considering their characteristics, with different volumes and acquisition times. Results showed that social media data acquired between 19:00 and 8:00 with a volume of approximately 300,000 will help our method realize high accuracy with low computation burden. This study showed the great potential of combining social sensing data for disaggregating fine-resolution population.},
DOI = {10.3390/rs11161900}
}



@Article{rs11161909,
AUTHOR = {Jawak, Shridhar D. and Luis, Alvarinho J. and Fretwell, Peter T. and Convey, Peter and Durairajan, Udhayaraj A.},
TITLE = {Semiautomated Detection and Mapping of Vegetation Distribution in the Antarctic Environment Using Spatial-Spectral Characteristics of WorldView-2 Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {16},
ARTICLE-NUMBER = {1909},
URL = {https://www.mdpi.com/2072-4292/11/16/1909},
ISSN = {2072-4292},
ABSTRACT = {Effective monitoring of changes in the geographic distribution of cryospheric vegetation requires high-resolution and accurate baseline maps. The rationale of the present study is to compare multiple feature extraction approaches to remotely mapping vegetation in Antarctica, assessing which give the greatest accuracy and reproducibility relative to those currently available. This study provides precise, high-resolution, and refined baseline information on vegetation distribution as is required to enable future spatiotemporal change analyses of the vegetation in Antarctica. We designed and implemented a semiautomated customized normalized difference vegetation index (NDVI) approach for extracting cryospheric vegetation by incorporating very high resolution (VHR) 8-band WorldView-2 (WV-2) satellite data. The viability of state-of-the-art target detection, spectral processing/matching, and pixel-wise supervised classification feature extraction techniques are compared with the customized NDVI approach devised in this study. An extensive quantitative and comparative assessment was made by evaluating four semiautomatic feature extraction approaches consisting of 16 feature extraction standalone methods (four customized NDVI plus 12 existing methods) for mapping vegetation on Fisher Island and Stornes Peninsula in the Larsemann Hills, situated on continental east Antarctica. The results indicated that the customized NDVI approach achieved superior performance (average bias error ranged from ~6.44 &plusmn; 1.34% to ~11.55 &plusmn; 1.34%) and highest statistical stability in terms of performance when compared with existing feature extraction approaches. Overall, the accuracy analysis of the vegetation mapping relative to manually digitized reference data (supplemented by validation with ground truthing) indicated that the 16 semi-automatic mapping methods representing four general feature extraction approaches extracted vegetated area from Fisher Island and Stornes Peninsula totalling between 2.38 and 3.72 km2 (2.85 &plusmn; 0.10 km2 on average) with bias values ranging from 3.49 to 31.39% (average 12.81 &plusmn; 1.88%) and average root mean square error (RMSE) of 0.41 km2 (14.73 &plusmn; 1.88%). Further, the robustness of the analyses and results were endorsed by a cross-validation experiment conducted to map vegetation from the Schirmacher Oasis, East Antarctica. Based on the robust comparative analysis of these 16 methods, vegetation maps of the Larsemann Hills and Schirmacher Oasis were derived by ensemble merging of the five top-performing methods (Mixture Tuned Matched Filtering, Matched Filtering, Matched Filtering/Spectral Angle Mapper Ratio, NDVI-2, and NDVI-4). This study is the first of its kind to detect and map sparse and isolated vegetated patches (with smallest area of 0.25 m2) in East Antarctica using VHR data and to use ensemble merging of feature extraction methods, and provides access to an important indicator for environmental change.},
DOI = {10.3390/rs11161909}
}



@Article{electronics8080904,
AUTHOR = {Li, Qingyu and Dai, Keren and Wang, Xiaofeng and Zhang, Yu and Zhang, He and Jiang, Defu},
TITLE = {Low-Complexity Failed Element Diagnosis for Radar-Communication mmWave Antenna Array with Low SNR},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {904},
URL = {https://www.mdpi.com/2079-9292/8/8/904},
ISSN = {2079-9292},
ABSTRACT = {The millimeter-wave (mmWave) antenna array plays an important role in the excellent performance of wireless sensors networks (WSN) or unmanned aerial vehicle (UAV) clusters. However, the array elements are easily damaged in its harsh working environment but hard to be repaired or exchanged timely, resulting in a serious decline in the beamforming performance. Thus, accurate self-diagnosis of the failed elements is of great importance. In previous studies, there are still significant difficulties for large-scale arrays under extremely low SNR. In this paper, a diagnosis algorithm with low complexity and high reliability for the failed elements is proposed, which is based on a joint decision of communication signal and sensing echoes. Compared with the previous studies, the complexity of the algorithm is reduced by the construction of low-dimensional feature vectors for classification, the decoupling of the degree of arrival (DOA) estimation and the failed pattern diagnosis, with the help of the sub-array division. Simulation results show that, under an ultra-low SNR of &minus;12.5 dB for communication signals and &minus;16 dB for sensing echoes, an accurate self-diagnosis with a block error rate lower than 8% can be realized. The study in this paper will effectively promote the long-term and reliable operation of the mmWave antenna array in WSN, UAV clusters and other similar fields.},
DOI = {10.3390/electronics8080904}
}



@Article{rs11161916,
AUTHOR = {Corradino, Claudia and Ganci, Gaetana and Cappello, Annalisa and Bilotta, Giuseppe and Hérault, Alexis and Del Negro, Ciro},
TITLE = {Mapping Recent Lava Flows at Mount Etna Using Multispectral Sentinel-2 Images and Machine Learning Techniques},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {16},
ARTICLE-NUMBER = {1916},
URL = {https://www.mdpi.com/2072-4292/11/16/1916},
ISSN = {2072-4292},
ABSTRACT = {Accurate mapping of recent lava flows can provide significant insight into the development of flow fields that may aid in predicting future flow behavior. The task is challenging, due to both intrinsic properties of the phenomenon (e.g., lava flow resurfacing processes) and technical issues (e.g., the difficulty to survey a spatially extended lava flow with either aerial or ground instruments while avoiding hazardous locations). The huge amount of moderate to high resolution multispectral satellite data currently provides new opportunities for monitoring of extreme thermal events, such as eruptive phenomena. While retrieving boundaries of an active lava flow is relatively straightforward, problems arise when discriminating a recently cooled lava flow from older lava flow fields. Here, we present a new supervised classifier based on machine learning techniques to discriminate recent lava imaged in the MultiSpectral Imager (MSI) onboard Sentinel-2 satellite. Automated classification evaluates each pixel in a scene and then groups the pixels with similar values (e.g., digital number, reflectance, radiance) into a specified number of classes. Bands at the spatial resolution of 10 m (bands 2, 3, 4, 8) are used as input to the classifier. The training phase is performed on a small number of pixels manually labeled as covered by fresh lava, while the testing characterizes the entire lava flow field. Compared with ground-based measurements and actual lava flows of Mount Etna emplaced in 2017 and 2018, our automatic procedure provides excellent results in terms of accuracy, precision, and sensitivity.},
DOI = {10.3390/rs11161916}
}



@Article{rs11161922,
AUTHOR = {Guo, Shichen and Jin, Qizhao and Wang, Hongzhen and Wang, Xuezhi and Wang, Yangang and Xiang, Shiming},
TITLE = {Learnable Gated Convolutional Neural Network for Semantic Segmentation in Remote-Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {16},
ARTICLE-NUMBER = {1922},
URL = {https://www.mdpi.com/2072-4292/11/16/1922},
ISSN = {2072-4292},
ABSTRACT = {Semantic segmentation in high-resolution remote-sensing (RS) images is a fundamental task for RS-based urban understanding and planning. However, various types of artificial objects in urban areas make this task quite challenging. Recently, the use of Deep Convolutional Neural Networks (DCNNs) with multiscale information fusion has demonstrated great potential in enhancing performance. Technically, however, existing fusions are usually implemented by summing or concatenating feature maps in a straightforward way. Seldom do works consider the spatial importance for global-to-local context-information aggregation. This paper proposes a Learnable-Gated CNN (L-GCNN) to address this issue. Methodologically, the Taylor expression of the information-entropy function is first parameterized to design the gate function, which is employed to generate pixelwise weights for coarse-to-fine refinement in the L-GCNN. Accordingly, a Parameterized Gate Module (PGM) was designed to achieve this goal. Then, the single PGM and its densely connected extension were embedded into different levels of the encoder in the L-GCNN to help identify the discriminative feature maps at different scales. With the above designs, the L-GCNN is finally organized as a self-cascaded end-to-end architecture that is able to sequentially aggregate context information for fine segmentation. The proposed model was evaluated on two public challenging benchmarks, the ISPRS 2Dsemantic segmentation challenge Potsdam dataset and the Massachusetts building dataset. The experiment results demonstrate that the proposed method exhibited significant improvement compared with several related segmentation networks, including the FCN, SegNet, RefineNet, PSPNet, DeepLab and GSN.For example, on the Potsdam dataset, our method achieved a 93.65%     F 1     score and 88.06%     I o U     score for the segmentation of tiny cars in high-resolution RS images. As a conclusion, the proposed model showed potential for object segmentation from the RS images of buildings, impervious surfaces, low vegetation, trees and cars in urban settings, which largely varies in size and have confusing appearances.},
DOI = {10.3390/rs11161922}
}



@Article{s19163595,
AUTHOR = {Santos, Anderson Aparecido dos and Marcato Junior, José and Araújo, Márcio Santos and Di Martini, David Robledo and Tetila, Everton Castelão and Siqueira, Henrique Lopes and Aoki, Camila and Eltner, Anette and Matsubara, Edson Takashi and Pistori, Hemerson and Feitosa, Raul Queiroz and Liesenberg, Veraldo and Gonçalves, Wesley Nunes},
TITLE = {Assessment of CNN-Based Methods for Individual Tree Detection on Images Captured by RGB Cameras Attached to UAVs},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {16},
ARTICLE-NUMBER = {3595},
URL = {https://www.mdpi.com/1424-8220/19/16/3595},
ISSN = {1424-8220},
ABSTRACT = {Detection and classification of tree species from remote sensing data were performed using mainly multispectral and hyperspectral images and Light Detection And Ranging (LiDAR) data. Despite the comparatively lower cost and higher spatial resolution, few studies focused on images captured by Red-Green-Blue (RGB) sensors. Besides, the recent years have witnessed an impressive progress of deep learning methods for object detection. Motivated by this scenario, we proposed and evaluated the usage of Convolutional Neural Network (CNN)-based methods combined with Unmanned Aerial Vehicle (UAV) high spatial resolution RGB imagery for the detection of law protected tree species. Three state-of-the-art object detection methods were evaluated: Faster Region-based Convolutional Neural Network (Faster R-CNN), YOLOv3 and RetinaNet. A dataset was built to assess the selected methods, comprising 392 RBG images captured from August 2018 to February 2019, over a forested urban area in midwest Brazil. The target object is an important tree species threatened by extinction known as Dipteryx alata Vogel (Fabaceae). The experimental analysis delivered average precision around 92% with an associated processing times below 30 miliseconds.},
DOI = {10.3390/s19163595}
}



@Article{math7080755,
AUTHOR = {Ran, Xiangjin and Xue, Linfu and Zhang, Yanyan and Liu, Zeyu and Sang, Xuejia and He, Jinxin},
TITLE = {Rock Classification from Field Image Patches Analyzed Using a Deep Convolutional Neural Network},
JOURNAL = {Mathematics},
VOLUME = {7},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {755},
URL = {https://www.mdpi.com/2227-7390/7/8/755},
ISSN = {2227-7390},
ABSTRACT = {The automatic identification of rock type in the field would aid geological surveying, education, and automatic mapping. Deep learning is receiving significant research attention for pattern recognition and machine learning. Its application here has effectively identified rock types from images captured in the field. This paper proposes an accurate approach for identifying rock types in the field based on image analysis using deep convolutional neural networks. The proposed approach can identify six common rock types with an overall classification accuracy of 97.96%, thus outperforming other established deep-learning models and a linear model. The results show that the proposed approach based on deep learning represents an improvement in intelligent rock-type identification and solves several difficulties facing the automated identification of rock types in the field.},
DOI = {10.3390/math7080755}
}



@Article{f10080701,
AUTHOR = {Roberts, John and Koeser, Andrew and Abd-Elrahman, Amr and Wilkinson, Benjamin and Hansen, Gail and Landry, Shawn and Perez, Ali},
TITLE = {Mobile Terrestrial Photogrammetry for Street Tree Mapping and Measurements},
JOURNAL = {Forests},
VOLUME = {10},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {701},
URL = {https://www.mdpi.com/1999-4907/10/8/701},
ISSN = {1999-4907},
ABSTRACT = {Urban forests are often heavily populated by street trees along right-of-ways (ROW), and monitoring efforts can enhance municipal tree management. Terrestrial photogrammetric techniques have been used to measure tree biometry, but have typically used images from various angles around individual trees or forest plots to capture the entire stem while also utilizing local coordinate systems (i.e., non-georeferenced data). We proposed the mobile collection of georeferenced imagery along 100 m sections of urban roadway to create photogrammetric point cloud datasets suitable for measuring stem diameters and attaining positional x and y coordinates of street trees. In a comparison between stationary and mobile photogrammetry, diameter measurements of urban street trees (N = 88) showed a slightly lower error (RMSE = 8.02%) relative to non-mobile stem measurements (RMSE = 10.37%). Tree Y-coordinates throughout urban sites for mobile photogrammetric data showed a lower standard deviation of 1.70 m relative to 2.38 m for a handheld GPS, which was similar for X-coordinates where photogrammetry and handheld GPS coordinates showed standard deviations of 1.59 m and the handheld GPS 2.36 m, respectively&mdash;suggesting higher precision for the mobile photogrammetric models. The mobile photogrammetric system used in this study to create georeferenced models for measuring stem diameters and mapping tree positions can also be potentially expanded for more wide-scale applications related to tree inventory and monitoring of roadside infrastructure.},
DOI = {10.3390/f10080701}
}



@Article{rs11161952,
AUTHOR = {Du, Jinyang and Watts, Jennifer D. and Jiang, Lingmei and Lu, Hui and Cheng, Xiao and Duguay, Claude and Farina, Mary and Qiu, Yubao and Kim, Youngwook and Kimball, John S. and Tarolli, Paolo},
TITLE = {Remote Sensing of Environmental Changes in Cold Regions: Methods, Achievements and Challenges},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {16},
ARTICLE-NUMBER = {1952},
URL = {https://www.mdpi.com/2072-4292/11/16/1952},
ISSN = {2072-4292},
ABSTRACT = {Cold regions, including high-latitude and high-altitude landscapes, are experiencing profound environmental changes driven by global warming. With the advance of earth observation technology, remote sensing has become increasingly important for detecting, monitoring, and understanding environmental changes over vast and remote regions. This paper provides an overview of recent achievements, challenges, and opportunities for land remote sensing of cold regions by (a) summarizing the physical principles and methods in remote sensing of selected key variables related to ice, snow, permafrost, water bodies, and vegetation; (b) highlighting recent environmental nonstationarity occurring in the Arctic, Tibetan Plateau, and Antarctica as detected from satellite observations; (c) discussing the limits of available remote sensing data and approaches for regional monitoring; and (d) exploring new opportunities from next-generation satellite missions and emerging methods for accurate, timely, and multi-scale mapping of cold regions.},
DOI = {10.3390/rs11161952}
}



@Article{electronics8090915,
AUTHOR = {Maldonado-Bascón, Saturnino and Iglesias-Iglesias, Cristian and Martín-Martín, Pilar and Lafuente-Arroyo, Sergio},
TITLE = {Fallen People Detection Capabilities Using Assistive Robot},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {915},
URL = {https://www.mdpi.com/2079-9292/8/9/915},
ISSN = {2079-9292},
ABSTRACT = {One of the main problems in the elderly population and for people with functional disabilities is falling when they are not supervised. Therefore, there is a need for monitoring systems with fall detection functionality. Mobile robots are a good solution for keeping the person in sight when compared to static-view sensors. Mobile-patrol robots can be used for a group of people and systems are less intrusive than ones based on mobile robots. In this paper, we propose a novel vision-based solution for fall detection based on a mobile-patrol robot that can correct its position in case of doubt. The overall approach can be formulated as an end-to-end solution based on two stages: person detection and fall classification. Deep learning-based computer vision is used for person detection and fall classification is done by using a learning-based Support Vector Machine (SVM) classifier. This approach mainly fulfills the following design requirements&mdash;simple to apply, adaptable, high performance, independent of person size, clothes, or the environment, low cost and real-time computing. Important to highlight is the ability to distinguish between a simple resting position and a real fall scene. One of the main contributions of this paper is the input feature vector to the SVM-based classifier. We evaluated the robustness of the approach using a realistic public dataset proposed in this paper called the Fallen Person Dataset (FPDS), with 2062 images and 1072 falls. The results obtained from different experiments indicate that the system has a high success rate in fall classification (precision of 100% and recall of 99.74%). Training the algorithm using our Fallen Person Dataset (FPDS) and testing it with other datasets showed that the algorithm is independent of the camera setup.},
DOI = {10.3390/electronics8090915}
}



@Article{su11174557,
AUTHOR = {Liu, Chunting and Jia, Guozhu},
TITLE = {Industrial Big Data and Computational Sustainability: Multi-Method Comparison Driven by High-Dimensional Data for Improving Reliability and Sustainability of Complex Systems},
JOURNAL = {Sustainability},
VOLUME = {11},
YEAR = {2019},
NUMBER = {17},
ARTICLE-NUMBER = {4557},
URL = {https://www.mdpi.com/2071-1050/11/17/4557},
ISSN = {2071-1050},
ABSTRACT = {Sustainable development is of great significance. The emerging research on data-driven computational sustainability has become an effective way to solve this problem. This paper presents a fault diagnosis and prediction framework for complex systems based on multi-dimensional data and multi-method comparison, aimed at improving the reliability and sustainability of the system by selecting methods with relatively superior performance. This study took the avionics system in the industrial field as an example. Based on the literature research on typical fault modes and fault diagnosis requirements of avionics systems, three popular high-dimensional data-driven fault diagnosis methods&mdash;support vector machine, convolutional neural network, and long- and short-term memory neural network&mdash;were comprehensively analyzed and compared. Finally, the actual bearing failure data were used for programming in order to verify and compare various methods and the process of selecting the superior method driven by high-dimensional data was fully demonstrated. We attempt to provide a sustainable development idea that continuously explores multi-method integration and comparison, aimed at improving the calculation efficiency and accuracy of reliability assessments, optimizing system performance, and ultimately achieving the goal of long-term improvement of system reliability and sustainability.},
DOI = {10.3390/su11174557}
}



@Article{rs11171976,
AUTHOR = {Hamdi, Zayd Mahmoud and Brandmeier, Melanie and Straub, Christoph},
TITLE = {Forest Damage Assessment Using Deep Learning on High Resolution Remote Sensing Data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {17},
ARTICLE-NUMBER = {1976},
URL = {https://www.mdpi.com/2072-4292/11/17/1976},
ISSN = {2072-4292},
ABSTRACT = {Storms can cause significant damage to forest areas, affecting biodiversity and infrastructure and leading to economic loss. Thus, rapid detection and mapping of windthrows are crucially important for forest management. Recent advances in computer vision have led to highly-accurate image classification algorithms such as Convolutional Neural Network (CNN) architectures. In this study, we tested and implemented an algorithm based on CNNs in an ArcGIS environment for automatic detection and mapping of damaged areas. The algorithm was trained and tested on a forest area in Bavaria, Germany. . It is a based on a modified U-Net architecture that was optimized for the pixelwise classification of multispectral aerial remote sensing data. The neural network was trained on labeled damaged areas from after-storm aerial orthophotos of a ca.     109 k  m 2      forest area with RGB and NIR bands and 0.2-m spatial resolution. Around     10 7     pixels of labeled data were used in the process. Once the network is trained, predictions on further datasets can be computed within seconds, depending on the size of the input raster and the computational power used. The overall accuracy on our test dataset was     92 %    . During visual validation, labeling errors were found in the reference data that somewhat biased the results because the algorithm in some instance performed better than the human labeling procedure, while missing areas affected by shadows. Our results are very good in terms of precision, and the methods introduced in this paper have several additional advantages compared to traditional methods: CNNs automatically detect high- and low-level features in the data, leading to high classification accuracies, while only one after-storm image is needed in comparison to two images for approaches based on change detection. Furthermore, flight parameters do not affect the results in the same way as for approaches that require DSMs and DTMs as the classification is only based on the image data themselves, and errors occurring in the computation of DSMs and DTMs do not affect the results with respect to the z component. The integration into the ArcGIS Platform allows a streamlined workflow for forest management, as the results can be accessed by mobile devices in the field to allow for high-accuracy ground-truthing and additional mapping that can be synchronized back into the database. Our results and the provided automatic workflow highlight the potential of deep learning on high-resolution imagery and GIS for fast and efficient post-disaster damage assessment as a first step of disaster management.},
DOI = {10.3390/rs11171976}
}



@Article{en12173234,
AUTHOR = {Joung, Jingon and Lee, Han Lim and Zhao, Jian and Kang, Xin},
TITLE = {Power Control Method for Energy Efficient Buffer-Aided Relay Systems},
JOURNAL = {Energies},
VOLUME = {12},
YEAR = {2019},
NUMBER = {17},
ARTICLE-NUMBER = {3234},
URL = {https://www.mdpi.com/1996-1073/12/17/3234},
ISSN = {1996-1073},
ABSTRACT = {In this paper, a power control method is proposed for a buffer-aided relay node (RN) to enhance the energy efficiency of the RN system. By virtue of a buffer, the RN can reserve the data at the buffer when the the channel gain between an RN and a destination node (DN) is weaker than that between SN and RN. The RN then opportunistically forward the reserved data in the buffer according to channel condition between the RN and the DN. By exploiting the buffer, RN reduces transmit power when it reduces the transmit data rate and reserve the data in the buffer. Therefore, without any total throughput reduction, the power consumption of RN can be reduced, resulting in the energy efficiency (EE) improvement of the RN system. Furthermore, for the power control, we devise a simple power control method based on a two-dimensional surface fitting model of an optimal transmit power of RN. The proposed RN power control method is readily and locally implementable at the RN, and it can significantly improve EE of the RN compared to the fixed power control method and the spectral efficiency based method as verified by the rigorous numerical results.},
DOI = {10.3390/en12173234}
}



@Article{electronics8090919,
AUTHOR = {Wu, Ruidong and Liu, Bing and Fu, Jiafeng and Xu, Mingzhu and Fu, Ping and Li, Junbao},
TITLE = {Research and Implementation of ε-SVR Training Method Based on FPGA},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {919},
URL = {https://www.mdpi.com/2079-9292/8/9/919},
ISSN = {2079-9292},
ABSTRACT = {Online training of Support Vector Regression (SVR) in the field of machine learning is a computationally complex algorithm. Due to the need for multiple iterative processing in training, SVR training is usually implemented on computer, and the existing training methods cannot be directly implemented on Field-Programmable Gate Array (FPGA), which restricts the application range. This paper reconstructs the training framework and implementation without precision loss to reduce the total latency required for matrix update, reducing time consumption by 90%. A general &epsilon;-SVR training system with low latency is implemented on Zynq platform. Taking the regression of samples in two-dimensional as an example, the maximum acceleration ratio is 27.014&times; compared with microcontroller platform and the energy consumption is 12.449% of microcontroller. From the experiments for the University of California, Riverside (UCR) time series data set. The regression results obtain excellent regression effects. The minimum coefficient of determination is 0.996, and running time is less than 30 ms, which can meet the requirements of different applications for real-time regression.},
DOI = {10.3390/electronics8090919}
}



@Article{rs11171979,
AUTHOR = {Lu, Bing and He, Yuhong},
TITLE = {Evaluating Empirical Regression, Machine Learning, and Radiative Transfer Modelling for Estimating Vegetation Chlorophyll Content Using Bi-Seasonal Hyperspectral Images},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {17},
ARTICLE-NUMBER = {1979},
URL = {https://www.mdpi.com/2072-4292/11/17/1979},
ISSN = {2072-4292},
ABSTRACT = {Different types of methods have been developed to retrieve vegetation attributes from remote sensing data, including conventional empirical regressions (i.e., linear regression (LR)), advanced empirical regressions (e.g., multivariable linear regression (MLR), partial least square regression (PLSR)), machine learning (e.g., random forest regression (RFR), decision tree regression (DTR)), and radiative transfer modelling (RTM, e.g., PROSAIL). Given that each algorithm has its own strengths and weaknesses, it is essential to compare them and evaluate their effectiveness. Previous studies have mainly used single-date multispectral imagery or ground-based hyperspectral reflectance data for evaluating the models, while multi-seasonal hyperspectral images have been rarely used. Extensive spectral and spatial information in hyperspectral images, as well as temporal variations of landscapes, potentially influence the model performance. In this research, LR, PLSR, RFR, and PROSAIL, representing different types of methods, were evaluated for estimating vegetation chlorophyll content from bi-seasonal hyperspectral images (i.e., a middle- and a late-growing season image, respectively). Results show that the PLSR and RFR generally performed better than LR and PROSAIL. RFR achieved the highest accuracy for both images. This research provides insights on the effectiveness of different models for estimating vegetation chlorophyll content using hyperspectral images, aiming to support future vegetation monitoring research.},
DOI = {10.3390/rs11171979}
}



@Article{rs11171982,
AUTHOR = {Feng, Xiaoxue and Li, Peijun},
TITLE = {A Tree Species Mapping Method from UAV Images over Urban Area Using Similarity in Tree-Crown Object Histograms},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {17},
ARTICLE-NUMBER = {1982},
URL = {https://www.mdpi.com/2072-4292/11/17/1982},
ISSN = {2072-4292},
ABSTRACT = {Timely and accurate information about spatial distribution of tree species in urban areas provides crucial data for sustainable urban development, management and planning. Very high spatial resolution data collected by sensors onboard Unmanned Aerial Vehicles (UAV) systems provide rich data sources for mapping tree species. This paper proposes a method of tree species mapping from UAV images over urban areas using similarity in tree-crown object histograms and a simple thresholding method. Tree-crown objects are first extracted and used as processing units in subsequent steps. Tree-crown object histograms of multiple features, i.e., spectral and height related features, are generated to quantify within-object variability. A specific tree species is extracted by comparing similarity in histogram between a target tree-crown object and reference objects. The proposed method is evaluated in mapping four different tree species using UAV multispectral ortho-images and derived Digital Surface Model (DSM) data collected in Shanghai urban area, by comparing with an existing method. The results demonstrate that the proposed method outperforms the comparative method for all four tree species, with improvements of 0.61&ndash;5.81% in overall accuracy. The proposed method provides a simple and effective way of mapping tree species over urban area.},
DOI = {10.3390/rs11171982}
}



@Article{jmse7090287,
AUTHOR = {Lee, EunSu and Mokashi, Amit J. and Moon, Sang Young and Kim, GeunSub},
TITLE = {The Maturity of Automatic Identification Systems (AIS) and Its Implications for Innovation},
JOURNAL = {Journal of Marine Science and Engineering},
VOLUME = {7},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {287},
URL = {https://www.mdpi.com/2077-1312/7/9/287},
ISSN = {2077-1312},
ABSTRACT = {The member states of International Maritime Organization (IMO) have been leading in and enforcing the use of automatic identification systems (AIS) in the analysis of ship-to-ship collisions, vessel monitoring, and maritime traffic management offshore. This study will help non-federal stakeholders understand the AIS data and contribute to future research by assessing difficulties and improving access to data and applications. This study introduces the basics of AIS materials, shared channels, and currently developed applications, and discusses areas where they can be incorporated in the future. The literature revealed that using AIS data will be beneficial to the public as well as to business and public agencies.},
DOI = {10.3390/jmse7090287}
}



@Article{drones3030066,
AUTHOR = {Khoufi, Ines and Laouiti, Anis and Adjih, Cedric},
TITLE = {A Survey of Recent Extended Variants of the Traveling Salesman and Vehicle Routing Problems for Unmanned Aerial Vehicles},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {66},
URL = {https://www.mdpi.com/2504-446X/3/3/66},
ISSN = {2504-446X},
ABSTRACT = {The use of Unmanned Aerial Vehicles (UAVs) is rapidly growing in popularity. Initially introduced for military purposes, over the past few years, UAVs and related technologies have successfully transitioned to a whole new range of civilian applications such as delivery, logistics, surveillance, entertainment, and so forth. They have opened new possibilities such as allowing operation in otherwise difficult or hazardous areas, for instance. For all applications, one foremost concern is the selection of the paths and trajectories of UAVs, and at the same time, UAVs control comes with many challenges, as they have limited energy, limited load capacity and are vulnerable to difficult weather conditions. Generally, efficiently operating a drone can be mathematically formalized as a path optimization problem under some constraints. This shares some commonalities with similar problems that have been extensively studied in the context of urban vehicles and it is only natural that the recent literature has extended the latter to fit aerial vehicle constraints. The knowledge of such problems, their formulation, the resolution methods proposed—through the variants induced specifically by UAVs features—are of interest for practitioners for any UAV application. Hence, in this study, we propose a review of existing literature devoted to such UAV path optimization problems, focusing specifically on the sub-class of problems that consider the mobility on a macroscopic scale. These are related to the two existing general classic ones—the Traveling Salesman Problem and the Vehicle Routing Problem. We analyze the recent literature that adapted the problems to the UAV context, provide an extensive classification and taxonomy of their problems and their formulation and also give a synthetic overview of the resolution techniques, performance metrics and obtained numerical results.},
DOI = {10.3390/drones3030066}
}



@Article{agronomy9090481,
AUTHOR = {Maharjan, Sajana and Qamer, Faisal Mueen and Matin, Mir and Joshi, Govinda and Bhuchar, Sanjeev},
TITLE = {Integrating Modelling and Expert Knowledge for Evaluating Current and Future Scenario of Large Cardamom Crop in Eastern Nepal},
JOURNAL = {Agronomy},
VOLUME = {9},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {481},
URL = {https://www.mdpi.com/2073-4395/9/9/481},
ISSN = {2073-4395},
ABSTRACT = {Large Cardamom (Amomum subulatum Roxb.) is one of the most valuable cash crop of the Himalayan mountain region including Nepal, India, and Bhutan. Nepal is the world&rsquo;s largest producer of the crop while the Taplejung district contributes a 30%&ndash;40% share in Nepal&rsquo;s total production. Large cardamom is an herbaceous perennial crop usually grown under the shade of the Uttis tree in very specialized bioclimatic conditions. In recent years, a decline in cardamom production has been observed which is being attributed to climate-related indicators. To understand the current dynamics of this under-canopy herbaceous crop distribution and its future potential under climate change, a combination of modelling, remote sensing, and expert knowledge is applied for the assessment. The results suggest that currently, Uttis tree cover is 10,735 ha in the district, while 50% (5198 ha) of this cover has a large cardamom crop underneath. When existing cultivation is compared with modelled suitable areas, it is observed that the cultivatable area has not yet reached its full potential. In a future climate scenario, the current habitat will be negatively affected, where mid elevations will remain stable while lower and higher elevation will become infeasible for the crop. Future changes are closely related to temperature and precipitation which are steadily changing in Nepal over time.},
DOI = {10.3390/agronomy9090481}
}



@Article{rs11172008,
AUTHOR = {Yang, Qinchen and Liu, Man and Zhang, Zhitao and Yang, Shuqin and Ning, Jifeng and Han, Wenting},
TITLE = {Mapping Plastic Mulched Farmland for High Resolution Images of Unmanned Aerial Vehicle Using Deep Semantic Segmentation},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {17},
ARTICLE-NUMBER = {2008},
URL = {https://www.mdpi.com/2072-4292/11/17/2008},
ISSN = {2072-4292},
ABSTRACT = {With increasing consumption, plastic mulch benefits agriculture by promoting crop quality and yield, but the environmental and soil pollution is becoming increasingly serious. Therefore, research on the monitoring of plastic mulched farmland (PMF) has received increasing attention. Plastic mulched farmland in unmanned aerial vehicle (UAV) remote images due to the high resolution, shows a prominent spatial pattern, which brings difficulties to the task of monitoring PMF. In this paper, through a comparison between two deep semantic segmentation methods, SegNet and fully convolutional networks (FCN), and a traditional classification method, Support Vector Machine (SVM), we propose an end-to-end deep-learning method aimed at accurately recognizing PMF for UAV remote sensing images from Hetao Irrigation District, Inner Mongolia, China. After experiments with single-band, three-band and six-band image data, we found that deep semantic segmentation models built via single-band data which only use the texture pattern of PMF can identify it well; for example, SegNet reaching the highest accuracy of 88.68% in a 900 nm band. Furthermore, with three visual bands and six-band data (3 visible bands and 3 near-infrared bands), deep semantic segmentation models combining the texture and spectral features further improve the accuracy of PMF identification, whereas six-band data obtains an optimal performance for FCN and SegNet. In addition, deep semantic segmentation methods, FCN and SegNet, due to their strong feature extraction capability and direct pixel classification, clearly outperform the traditional SVM method in precision and speed. Among three classification methods, SegNet model built on three-band and six-band data obtains the optimal average accuracy of 89.62% and 90.6%, respectively. Therefore, the proposed deep semantic segmentation model, when tested against the traditional classification method, provides a promising path for mapping PMF in UAV remote sensing images.},
DOI = {10.3390/rs11172008}
}



@Article{geosciences9090373,
AUTHOR = {Groh, Till and Blöthe, Jan Henrik},
TITLE = {Rock Glacier Kinematics in the Kaunertal, Ötztal Alps, Austria},
JOURNAL = {Geosciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {373},
URL = {https://www.mdpi.com/2076-3263/9/9/373},
ISSN = {2076-3263},
ABSTRACT = {The quantification of rock glacier kinematics on a regional basis has gained increasing importance in recent years. Here, we applied an image tracking approach on high-resolution aerial imagery to infer surface kinematics of 129 mapped rock glaciers in the Kaunertal, Austrian Alps. We find significant surface movement for 30 features with mean velocities falling between 0.11 and 0.29 m yr&minus;1 and a maximum of 1.7 m yr&minus;1. Local analysis and comparison to earlier studies reveals significant increases in rock glacier velocities in the study area. From the rock glacier inventory and high-resolution digital topography, we computed a series of morphometric parameters to analyze potential controls on rock glacier creep and to predict rock glacier activity using random forests and logistic regression models. The results point towards a stronger dependence of velocities on parameters describing general inclination, potentially acting as proxies for internal rock glacier properties, while activity states seem to be regulated mainly by rock glacier dimensions and topoclimate. Using a parameter subset, we successfully separated active from inactive rock glaciers with accuracies of up to 77.5%, indicating a promising approach to predict rock glacier activity solely relying on parameters that can be derived from regionally available data sets.},
DOI = {10.3390/geosciences9090373}
}



@Article{rs11172045,
AUTHOR = {Geraeds, Marlein and van Emmerik, Tim and de Vries, Robin and bin Ab Razak, Mohd Shahrizal},
TITLE = {Riverine Plastic Litter Monitoring Using Unmanned Aerial Vehicles (UAVs)},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {17},
ARTICLE-NUMBER = {2045},
URL = {https://www.mdpi.com/2072-4292/11/17/2045},
ISSN = {2072-4292},
ABSTRACT = {Plastic debris has become an abundant pollutant in marine, coastal and riverine environments, posing a large threat to aquatic life. Effective measures to mitigate and prevent marine plastic pollution require a thorough understanding of its origin and eventual fate. Several models have estimated that land-based sources are the main source of marine plastic pollution, although field data to substantiate these estimates remain limited. Current methodologies to measure riverine plastic transport require the availability of infrastructure and accessible riverbanks, but, to obtain measurements on a higher spatial and temporal scale, new monitoring methods are required. This paper presents a new methodology for quantifying riverine plastic debris using Unmanned Aerial Vehicles (UAVs), including a first application on Klang River, Malaysia. Additional plastic measurements were done in parallel with the UAV-based approach to make comparisons between the two methods. The spatiotemporal distribution of the plastics obtained with both methods show similar patterns and variations. With this, we show that UAV-based monitoring methods are a promising alternative for currently available approaches for monitoring riverine plastic transport, especially in remote and inaccessible areas.},
DOI = {10.3390/rs11172045}
}



@Article{rs11172046,
AUTHOR = {Ghorbanzadeh, Omid and Meena, Sansar Raj and Blaschke, Thomas and Aryal, Jagannath},
TITLE = {UAV-Based Slope Failure Detection Using Deep-Learning Convolutional Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {17},
ARTICLE-NUMBER = {2046},
URL = {https://www.mdpi.com/2072-4292/11/17/2046},
ISSN = {2072-4292},
ABSTRACT = {Slope failures occur when parts of a slope collapse abruptly under the influence of gravity, often triggered by a rainfall event or earthquake. The resulting slope failures often cause problems in mountainous or hilly regions, and the detection of slope failure is therefore an important topic for research. Most of the methods currently used for mapping and modelling slope failures rely on classification algorithms or feature extraction, but the spatial complexity of slope failures, the uncertainties inherent in expert knowledge, and problems in transferability, all combine to inhibit slope failure detection. In an attempt to overcome some of these problems we have analyzed the potential of deep learning convolutional neural networks (CNNs) for slope failure detection, in an area along a road section in the northern Himalayas, India. We used optical data from unmanned aerial vehicles (UAVs) over two separate study areas. Different CNN designs were used to produce eight different slope failure distribution maps, which were then compared with manually extracted slope failure polygons using different accuracy assessment metrics such as the precision, F-score, and mean intersection-over-union (mIOU). A slope failure inventory data set was produced for each of the study areas using a frequency-area distribution (FAD). The CNN approach that was found to perform best (precision accuracy assessment of almost 90% precision, F-score 85%, mIOU 74%) was one that used a window size of 64 &times; 64 pixels for the sample patches, and included slope data as an additional input layer. The additional information from the slope data helped to discriminate between slope failure areas and roads, which had similar spectral characteristics in the optical imagery. We concluded that the effectiveness of CNNs for slope failure detection was strongly dependent on their design (i.e., the window size selected for the sample patch, the data used, and the training strategies), but that CNNs are currently only designed by trial and error. While CNNs can be powerful tools, such trial and error strategies make it difficult to explain why a particular pooling or layer numbering works better than any other.},
DOI = {10.3390/rs11172046}
}



@Article{a12090183,
AUTHOR = {Li, Kexin and Wang, Jun and Qi, Dawei},
TITLE = {An Intelligent Warning Method for Diagnosing Underwater Structural Damage},
JOURNAL = {Algorithms},
VOLUME = {12},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {183},
URL = {https://www.mdpi.com/1999-4893/12/9/183},
ISSN = {1999-4893},
ABSTRACT = {A number of intelligent warning techniques have been implemented for detecting underwater infrastructure diagnosis to partially replace human-conducted on-site inspections. However, the extensively varying real-world situation (e.g., the adverse environmental conditions, the limited sample space, and the complex defect types) can lead to challenges to the wide adoption of intelligent warning techniques. To overcome these challenges, this paper proposed an intelligent algorithm combing gray level co-occurrence matrix (GLCM) with self-organization map (SOM) for accurate diagnosis of the underwater structural damage. In order to optimize the generative criterion for GLCM construction, a triangle algorithm was proposed based on orthogonal experiments. The constructed GLCM were utilized to evaluate the texture features of the regions of interest (ROI) of micro-injury images of underwater structures and extracted damage image texture characteristic parameters. The digital feature screening (DFS) method was used to obtain the most relevant features as the input for the SOM network. According to the unique topology information of the SOM network, the classification result, recognition efficiency, parameters, such as the network layer number, hidden layer node, and learning step, were optimized. The robustness and adaptability of the proposed approach were tested on underwater structure images through the DFS method. The results showed that the proposed method revealed quite better performances and can diagnose structure damage in underwater realistic situations.},
DOI = {10.3390/a12090183}
}



@Article{rs11172050,
AUTHOR = {Revill, Andrew and Florence, Anna and MacArthur, Alasdair and Hoad, Stephen P. and Rees, Robert M. and Williams, Mathew},
TITLE = {The Value of Sentinel-2 Spectral Bands for the Assessment of Winter Wheat Growth and Development},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {17},
ARTICLE-NUMBER = {2050},
URL = {https://www.mdpi.com/2072-4292/11/17/2050},
ISSN = {2072-4292},
ABSTRACT = {Leaf Area Index (LAI) and chlorophyll content are strongly related to plant development and productivity. Spatial and temporal estimates of these variables are essential for efficient and precise crop management. The availability of open-access data from the European Space Agency’s (ESA) Sentinel-2 satellite—delivering global coverage with an average 5-day revisit frequency at a spatial resolution of up to 10 metres—could provide estimates of these variables at unprecedented (i.e., sub-field) resolution. Using synthetic data, past research has demonstrated the potential of Sentinel-2 for estimating crop variables. Nonetheless, research involving a robust analysis of the Sentinel-2 bands for supporting agricultural applications is limited. We evaluated the potential of Sentinel-2 data for retrieving winter wheat LAI, leaf chlorophyll content (LCC) and canopy chlorophyll content (CCC). In coordination with destructive and non-destructive ground measurements, we acquired multispectral data from an Unmanned Aerial Vehicle (UAV)-mounted sensor measuring key Sentinel-2 spectral bands (443 to 865 nm). We applied Gaussian processes regression (GPR) machine learning to determine the most informative Sentinel-2 bands for retrieving each of the variables. We further evaluated the GPR model performance when propagating observation uncertainty. When applying the best-performing GPR models without propagating uncertainty, the retrievals had a high agreement with ground measurements—the mean R2 and normalised root-mean-square error (NRMSE) were 0.89 and 8.8%, respectively. When propagating uncertainty, the mean R2 and NRMSE were 0.82 and 11.9%, respectively. When accounting for measurement uncertainty in the estimation of LAI and CCC, the number of most informative Sentinel-2 bands was reduced from four to only two—the red-edge (705 nm) and near-infrared (865 nm) bands. This research demonstrates the value of the Sentinel-2 spectral characteristics for retrieving critical variables that can support more sustainable crop management practices.},
DOI = {10.3390/rs11172050}
}



@Article{s19173796,
AUTHOR = {Shafi, Uferah and Mumtaz, Rafia and García-Nieto, José and Hassan, Syed Ali and Zaidi, Syed Ali Raza and Iqbal, Naveed},
TITLE = {Precision Agriculture Techniques and Practices: From Considerations to Applications},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {17},
ARTICLE-NUMBER = {3796},
URL = {https://www.mdpi.com/1424-8220/19/17/3796},
ISSN = {1424-8220},
ABSTRACT = {Internet of Things (IoT)-based automation of agricultural events can change the agriculture sector from being static and manual to dynamic and smart, leading to enhanced production with reduced human efforts. Precision Agriculture (PA) along with Wireless Sensor Network (WSN) are the main drivers of automation in the agriculture domain. PA uses specific sensors and software to ensure that the crops receive exactly what they need to optimize productivity and sustainability. PA includes retrieving real data about the conditions of soil, crops and weather from the sensors deployed in the fields. High-resolution images of crops are obtained from satellite or air-borne platforms (manned or unmanned), which are further processed to extract information used to provide future decisions. In this paper, a review of near and remote sensor networks in the agriculture domain is presented along with several considerations and challenges. This survey includes wireless communication technologies, sensors, and wireless nodes used to assess the environmental behaviour, the platforms used to obtain spectral images of crops, the common vegetation indices used to analyse spectral images and applications of WSN in agriculture. As a proof of concept, we present a case study showing how WSN-based PA system can be implemented. We propose an IoT-based smart solution for crop health monitoring, which is comprised of two modules. The first module is a wireless sensor network-based system to monitor real-time crop health status. The second module uses a low altitude remote sensing platform to obtain multi-spectral imagery, which is further processed to classify healthy and unhealthy crops. We also highlight the results obtained using a case study and list the challenges and future directions based on our work.},
DOI = {10.3390/s19173796}
}



@Article{rs11172066,
AUTHOR = {Tilly, Nora and Bareth, Georg},
TITLE = {Estimating Nitrogen from Structural Crop Traits at Field Scale—A Novel Approach Versus Spectral Vegetation Indices},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {17},
ARTICLE-NUMBER = {2066},
URL = {https://www.mdpi.com/2072-4292/11/17/2066},
ISSN = {2072-4292},
ABSTRACT = {A sufficient nitrogen (N) supply is mandatory for healthy crop growth, but negative consequences of N losses into the environment are known. Hence, deeply understanding and monitoring crop growth for an optimized N management is advisable. In this context, remote sensing facilitates the capturing of crop traits. While several studies on estimating biomass from spectral and structural data can be found, N is so far only estimated from spectral features. It is well known that N is negatively related to dry biomass, which, in turn, can be estimated from crop height. Based on this indirect link, the present study aims at estimating N concentration at field scale in a two-step model: first, using crop height to estimate biomass, and second, using the modeled biomass to estimate N concentration. For comparison, N concentration was estimated from spectral data. The data was captured on a spring barley field experiment in two growing seasons. Crop surface height was measured with a terrestrial laser scanner, seven vegetation indices were calculated from field spectrometer measurements, and dry biomass and N concentration were destructively sampled. In the validation, better results were obtained with the models based on structural data (R2 &lt; 0.85) than on spectral data (R2 &lt; 0.70). A brief look at the N concentration of different plant organs showed stronger dependencies on structural data (R2: 0.40&ndash;0.81) than on spectral data (R2: 0.18&ndash;0.68). Overall, this first study shows the potential of crop-specific across‑season two-step models based on structural data for estimating crop N concentration at field scale. The validity of the models for in-season estimations requires further research.},
DOI = {10.3390/rs11172066}
}



@Article{rs11182075,
AUTHOR = {Zhou, Jing and Yungbluth, Dennis and Vong, Chin Nee and Scaboo, Andrew and Zhou, Jianfeng},
TITLE = {Estimation of the Maturity Date of Soybean Breeding Lines Using UAV-Based Multispectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {18},
ARTICLE-NUMBER = {2075},
URL = {https://www.mdpi.com/2072-4292/11/18/2075},
ISSN = {2072-4292},
ABSTRACT = {Physiological maturity date is a critical parameter for the selection of breeding lines in soybean breeding programs. The conventional method to estimate the maturity dates of breeding lines uses visual ratings based on pod senescence by experts, which is subjective by human estimation, labor-intensive and time-consuming. Unmanned aerial vehicle (UAV)-based phenotyping systems provide a high-throughput and powerful tool of capturing crop traits using remote sensing, image processing and machine learning technologies. The goal of this study was to investigate the potential of predicting maturity dates of soybean breeding lines using UAV-based multispectral imagery. Maturity dates of 326 soybean breeding lines were taken using visual ratings from the beginning maturity stage (R7) to full maturity stage (R8), and the aerial multispectral images were taken during this period on 27 August, 14 September and 27 September, 2018. One hundred and thirty features were extracted from the five-band multispectral images. The maturity dates of the soybean lines were predicted and evaluated using partial least square regression (PLSR) models with 10-fold cross-validation. Twenty image features with importance to the estimation were selected and their changing rates between each two of the data collection days were calculated. The best prediction (R2 = 0.81, RMSE = 1.4 days) was made by the PLSR model using image features taken on 14 September and their changing rates between 14 September and 27 September with five components, leading to the conclusion that the UAV-based multispectral imagery is promising and practical in estimating maturity dates of soybean breeding lines.},
DOI = {10.3390/rs11182075}
}



@Article{rs11182082,
AUTHOR = {Marshall, Michael and Crommelinck, Sophie and Kohli, Divyani and Perger, Christoph and Yang, Michael Ying and Ghosh, Aniruddha and Fritz, Steffen and Bie, Kees de and Nelson, Andy},
TITLE = {Crowd-Driven and Automated Mapping of Field Boundaries in Highly Fragmented Agricultural Landscapes of Ethiopia with Very High Spatial Resolution Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {18},
ARTICLE-NUMBER = {2082},
URL = {https://www.mdpi.com/2072-4292/11/18/2082},
ISSN = {2072-4292},
ABSTRACT = {Mapping the extent and location of field boundaries is critical to food security analysis but remains problematic in the Global South where such information is needed the most. The difficulty is due primarily to fragmentation in the landscape, small farm sizes, and irregular farm boundaries. Very high-resolution satellite imagery affords an opportunity to delineate such fields, but the challenge remains of determining such boundaries in a systematic and accurate way. In this paper, we compare a new crowd-driven manual digitization tool (Crop Land Extent) with two semi-automated methods (contour detection and multi-resolution segmentation) to determine farm boundaries from WorldView imagery in highly fragmented agricultural landscapes of Ethiopia. More than 7000 one square-kilometer image tiles were used for the analysis. The three methods were assessed using quantitative completeness and spatial correctness. Contour detection tended to under-segment when compared to manual digitization, resulting in better performance for larger (approaching 1 ha) sized fields. Multi-resolution segmentation on the other hand, tended to over-segment, resulting in better performance for small fields. Neither semi-automated method in their current realizations however are suitable for field boundary mapping in highly fragmented landscapes. Crowd-driven manual digitization is promising, but requires more oversight, quality control, and training than the current workflow could allow.},
DOI = {10.3390/rs11182082}
}



@Article{sym11091139,
AUTHOR = {Hu, Bo and Li, Jiaxi and Yang, Jie and Bai, Haitao and Li, Shuang and Sun, Youchang and Yang, Xiaoyu},
TITLE = {Reinforcement Learning Approach to Design Practical Adaptive Control for a Small-Scale Intelligent Vehicle},
JOURNAL = {Symmetry},
VOLUME = {11},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1139},
URL = {https://www.mdpi.com/2073-8994/11/9/1139},
ISSN = {2073-8994},
ABSTRACT = {Reinforcement learning (RL) based techniques have been employed for the tracking and adaptive cruise control of a small-scale vehicle with the aim to transfer the obtained knowledge to a full-scale intelligent vehicle in the near future. Unlike most other control techniques, the purpose of this study is to seek a practical method that enables the vehicle, in the real environment and in real time, to learn the control behavior on its own while adapting to the changing circumstances. In this context, it is necessary to design an algorithm that symmetrically considers both time efficiency and accuracy. Meanwhile, in order to realize adaptive cruise control specifically, a set of symmetrical control actions consisting of steering angle and vehicle speed needs to be optimized simultaneously. In this paper, firstly, the experimental setup of the small-scale intelligent vehicle is introduced. Subsequently, three model-free RL algorithm are conducted to develop and finally form the strategy to keep the vehicle within its lanes at constant and top velocity. Furthermore, a model-based RL strategy is compared that incorporates learning from real experience and planning from simulated experience. Finally, a Q-learning based adaptive cruise control strategy is intermixed to the existing tracking control architecture to allow the vehicle slow-down in the curve and accelerate on straightaways. The experimental results show that the Q-learning and Sarsa (&lambda;) algorithms can achieve a better tracking behavior than the conventional Sarsa, and Q-learning outperform Sarsa (&lambda;) in terms of computational complexity. The Dyna-Q method performs similarly with the Sarsa (&lambda;) algorithms, but with a significant reduction of computational time. Compared with a fine-tuned proportion integration differentiation (PID) controller, the good-balanced Q-learning is seen to perform better and it can also be easily applied to control problems with over one control actions.},
DOI = {10.3390/sym11091139}
}



@Article{s19183880,
AUTHOR = {Díez-González, Javier and Álvarez, Rubén and González-Bárcena, David and Sánchez-González, Lidia and Castejón-Limas, Manuel and Perez, Hilde},
TITLE = {Genetic Algorithm Approach to the 3D Node Localization in TDOA Systems},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {18},
ARTICLE-NUMBER = {3880},
URL = {https://www.mdpi.com/1424-8220/19/18/3880},
ISSN = {1424-8220},
ABSTRACT = {Positioning asynchronous architectures based on time measurements are reaching growing importance in Local Positioning Systems (LPS). These architectures have special relevance in precision applications and indoor/outdoor navigation of automatic vehicles such as Automatic Ground Vehicles (AGVs) and Unmanned Aerial Vehicles (UAVs). The positioning error of these systems is conditioned by the algorithms used in the position calculation, the quality of the time measurements, and the sensor deployment of the signal receivers. Once the algorithms have been defined and the method to compute the time measurements has been selected, the only design criteria of the LPS is the distribution of the sensors in the three-dimensional space. This problem has proved to be NP-hard, and therefore a heuristic solution to the problem is recommended. In this paper, a genetic algorithm with the flexibility to be adapted to different scenarios and ground modelings is proposed. This algorithm is used to determine the best node localization in order to reduce the Cram&eacute;r-Rao Lower Bound (CRLB) with a heteroscedastic noise consideration in each sensor of an Asynchronous Time Difference of Arrival (A-TDOA) architecture. The methodology proposed allows for the optimization of the 3D sensor deployment of a passive A-TDOA architecture, including ground modeling flexibility and heteroscedastic noise consideration with sequential iterations, and reducing the spatial discretization to achieve better results. Results show that optimization with 15% of elitism and a Tournament 3 selection strategy offers the best maximization for the algorithm.},
DOI = {10.3390/s19183880}
}



@Article{s19183917,
AUTHOR = {Fan, Shurui and Li, Zirui and Xia, Kewen and Hao, Dongxia},
TITLE = {Quantitative and Qualitative Analysis of Multicomponent Gas Using Sensor Array},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {18},
ARTICLE-NUMBER = {3917},
URL = {https://www.mdpi.com/1424-8220/19/18/3917},
ISSN = {1424-8220},
ABSTRACT = {The gas sensor array has long been a major tool for measuring gas due to its high sensitivity, quick response, and low power consumption. This goal, however, faces a difficult challenge because of the cross-sensitivity of the gas sensor. This paper presents a novel gas mixture analysis method for gas sensor array applications. The features extracted from the raw data utilizing principal component analysis (PCA) were used to complete random forest (RF) modeling, which enabled qualitative identification. Support vector regression (SVR), optimized by the particle swarm optimization (PSO) algorithm, was used to select hyperparameters C and &gamma; to establish the optimal regression model for the purpose of quantitative analysis. Utilizing the dataset, we evaluated the effectiveness of our approach. Compared with logistic regression (LR) and support vector machine (SVM), the average recognition rate of PCA combined with RF was the highest (97%). The fitting effect of SVR optimized by PSO for gas concentration was better than that of SVR and solved the problem of hyperparameters selection.},
DOI = {10.3390/s19183917}
}



@Article{rs11182114,
AUTHOR = {Li, Qiaosi and Wong, Frankie Kwan Kit and Fung, Tung},
TITLE = {Classification of Mangrove Species Using Combined WordView-3 and LiDAR Data in Mai Po Nature Reserve, Hong Kong},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {18},
ARTICLE-NUMBER = {2114},
URL = {https://www.mdpi.com/2072-4292/11/18/2114},
ISSN = {2072-4292},
ABSTRACT = {Mangroves have significant social, economic, environmental, and ecological values but they are under threat due to human activities. An accurate map of mangrove species distribution is required to effectively conserve mangrove ecosystem. This study evaluates the synergy of WorldView-3 (WV-3) spectral bands and high return density LiDAR-derived elevation metrics for classifying seven species in mangrove habitat in Mai Po Nature Reserve in Hong Kong, China. A recursive feature elimination algorithm was carried out to identify important spectral bands and LiDAR (Airborne Light Detection and Ranging) metrics whilst appropriate spatial resolution for pixel-based classification was investigated for discriminating different mangrove species. Two classifiers, support vector machine (SVM) and random forest (RF) were compared. The results indicated that the combination of 2 m resolution WV-3 and LiDAR data yielded the best overall accuracy of 0.88 by SVM classifier comparing with WV-3 (0.72) and LiDAR (0.79). Important features were identified as green (510&ndash;581 nm), red edge (705&ndash;745 nm), red (630&ndash;690 nm), yellow (585&ndash;625 nm), NIR (770&ndash;895 nm) bands of WV-3, and LiDAR metrics relevant to canopy height (e.g., canopy height model), canopy shape (e.g., canopy relief ratio), and the variation of height (e.g., variation and standard deviation of height). LiDAR features contributed more information than spectral features. The significance of this study is that a mangrove species distribution map with satisfactory accuracy can be acquired by the proposed classification scheme. Meanwhile, with LiDAR data, vertical stratification of mangrove forests in Mai Po was firstly mapped, which is significant to bio-parameter estimation and ecosystem service evaluation in future studies.},
DOI = {10.3390/rs11182114}
}



@Article{rs11182118,
AUTHOR = {Hillman, Samuel and Wallace, Luke and Reinke, Karin and Hally, Bryan and Jones, Simon and Saldias, Daisy S.},
TITLE = {A Method for Validating the Structural Completeness of Understory Vegetation Models Captured with 3D Remote Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {18},
ARTICLE-NUMBER = {2118},
URL = {https://www.mdpi.com/2072-4292/11/18/2118},
ISSN = {2072-4292},
ABSTRACT = {Characteristics describing below canopy vegetation are important for a range of forest ecosystem applications including wildlife habitat, fuel hazard and fire behaviour modelling, understanding forest recovery after disturbance and competition dynamics. Such applications all rely on accurate measures of vegetation structure. Inherent in this is the assumption or ability to demonstrate measurement accuracy. 3D point clouds are being increasingly used to describe vegetated environments, however limited research has been conducted to validate the information content of terrestrial point clouds of understory vegetation. This paper describes the design and use of a field frame to co-register point intercept measurements with point cloud data to act as a validation source. Validation results show high correlation of point matching in forests with understory vegetation elements with large mass and/or surface area, typically consisting of broad leaves, twigs and bark 0.02 m diameter or greater in size (SfM, MCC 0.51&ndash;0.66; TLS, MCC 0.37&ndash;0.47). In contrast, complex environments with understory vegetation elements with low mass and low surface area showed lower correlations between validation measurements and point clouds (SfM, MCC 0.40 and 0.42; TLS, MCC 0.25 and 0.16). The results of this study demonstrate that the validation frame provides a suitable method for comparing the relative performance of different point cloud generation processes.},
DOI = {10.3390/rs11182118}
}



@Article{s19183935,
AUTHOR = {Liu, Xiaolei and Liu, Liansheng and Wang, Lulu and Guo, Qing and Peng, Xiyuan},
TITLE = {Performance Sensing Data Prediction for an Aircraft Auxiliary Power Unit Using the Optimized Extreme Learning Machine},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {18},
ARTICLE-NUMBER = {3935},
URL = {https://www.mdpi.com/1424-8220/19/18/3935},
ISSN = {1424-8220},
ABSTRACT = {The aircraft auxiliary power unit (APU) is responsible for environmental control in the cabin and the main engines starting the aircraft. The prediction of its performance sensing data is significant for condition-based maintenance. As a complex system, its performance sensing data have a typically nonlinear feature. In order to monitor this process, a model with strong nonlinear fitting ability needs to be formulated. A neural network has advantages of solving a nonlinear problem. Compared with the traditional back propagation neural network algorithm, an extreme learning machine (ELM) has features of a faster learning speed and better generalization performance. To enhance the training of the neural network with a back propagation algorithm, an ELM is employed to predict the performance sensing data of the APU in this study. However, the randomly generated weights and thresholds of the ELM often may result in unstable prediction results. To address this problem, a restricted Boltzmann machine (RBM) is utilized to optimize the ELM. In this way, a stable performance parameter prediction model of the APU can be obtained and better performance parameter prediction results can be achieved. The proposed method is evaluated by the real APU sensing data of China Southern Airlines Company Limited Shenyang Maintenance Base. Experimental results show that the optimized ELM with an RBM is more stable and can obtain more accurate prediction results.},
DOI = {10.3390/s19183935}
}



@Article{s19183965,
AUTHOR = {Abdi, Omid},
TITLE = {Climate-Triggered Insect Defoliators and Forest Fires Using Multitemporal Landsat and TerraClimate Data in NE Iran: An Application of GEOBIA TreeNet and Panel Data Analysis},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {18},
ARTICLE-NUMBER = {3965},
URL = {https://www.mdpi.com/1424-8220/19/18/3965},
ISSN = {1424-8220},
ABSTRACT = {Despite increasing the number of studies for mapping remote sensing insect-induced forest infestations, applying novel approaches for mapping and identifying its triggers are still developing. This study was accomplished to test the performance of Geographic Object-Based Image Analysis (GEOBIA) TreeNet for discerning insect-infested forests induced by defoliators from healthy forests using Landsat 8 OLI and ancillary data in the broadleaved mixed Hyrcanian forests. Moreover, it has studied mutual associations between the intensity of forest defoliation and the severity of forest fires under TerraClimate-derived climate hazards by analyzing panel data models within the TreeNet-derived insect-infested forest objects. The TreeNet optimal performance was obtained after building 333 trees with a sensitivity of 93.7% for detecting insect-infested objects with the contribution of the top 22 influential variables from 95 input object features. Accordingly, top image-derived features were the mean of the second principal component (PC2), the mean of the red channel derived from the gray-level co-occurrence matrix (GLCM), and the mean values of the normalized difference water index (NDWI) and the global environment monitoring index (GEMI). However, tree species type has been considered as the second rank for discriminating forest-infested objects from non-forest-infested objects. The panel data models using random effects indicated that the intensity of maximum temperatures of the current and previous years, the drought and soil-moisture deficiency of the current year, and the severity of forest fires of the previous year could significantly trigger the insect outbreaks. However, maximum temperatures were the only significant triggers of forest fires. This research proposes testing the combination of object features of Landsat 8 OLI with other data for monitoring near-real-time defoliation and pathogens in forests.},
DOI = {10.3390/s19183965}
}



@Article{rs11182155,
AUTHOR = {Wang, Jie and Simeonova, Sandra and Shahbazi, Mozhdeh},
TITLE = {Orientation- and Scale-Invariant Multi-Vehicle Detection and Tracking from Unmanned Aerial Videos},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {18},
ARTICLE-NUMBER = {2155},
URL = {https://www.mdpi.com/2072-4292/11/18/2155},
ISSN = {2072-4292},
ABSTRACT = {Along with the advancement of light-weight sensing and processing technologies, unmanned aerial vehicles (UAVs) have recently become popular platforms for intelligent traffic monitoring and control. UAV-mounted cameras can capture traffic-flow videos from various perspectives providing a comprehensive insight into road conditions. To analyze the traffic flow from remotely captured videos, a reliable and accurate vehicle detection-and-tracking approach is required. In this paper, we propose a deep-learning framework for vehicle detection and tracking from UAV videos for monitoring traffic flow in complex road structures. This approach is designed to be invariant to significant orientation and scale variations in the videos. The detection procedure is performed by fine-tuning a state-of-the-art object detector, You Only Look Once (YOLOv3), using several custom-labeled traffic datasets. Vehicle tracking is conducted following a tracking-by-detection paradigm, where deep appearance features are used for vehicle re-identification, and Kalman filtering is used for motion estimation. The proposed methodology is tested on a variety of real videos collected by UAVs under various conditions, e.g., in late afternoons with long vehicle shadows, in dawn with vehicles lights being on, over roundabouts and interchange roads where vehicle directions change considerably, and from various viewpoints where vehicles&rsquo; appearance undergo substantial perspective distortions. The proposed tracking-by-detection approach performs efficiently at 11 frames per second on color videos of 2720p resolution. Experiments demonstrated that high detection accuracy could be achieved with an average F1-score of 92.1%. Besides, the tracking technique performs accurately, with an average multiple-object tracking accuracy (MOTA) of 81.3%. The proposed approach also addressed the shortcomings of the state-of-the-art in multi-object tracking regarding frequent identity switching, resulting in a total of only one identity switch over every 305 tracked vehicles.},
DOI = {10.3390/rs11182155}
}



@Article{rs11182156,
AUTHOR = {Wang, Dezhi and Wan, Bo and Qiu, Penghua and Zuo, Zejun and Wang, Run and Wu, Xincai},
TITLE = {Mapping Height and Aboveground Biomass of Mangrove Forests on Hainan Island Using UAV-LiDAR Sampling},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {18},
ARTICLE-NUMBER = {2156},
URL = {https://www.mdpi.com/2072-4292/11/18/2156},
ISSN = {2072-4292},
ABSTRACT = {Hainan Island is the second-largest island in China and has the most species-diverse mangrove forests in the country. To date, the height and aboveground ground biomass (AGB) of the mangrove forests on Hainan Island are unknown, partly as a result of the challenges faced during extensive field sampling in mangrove habitats (intertidal mudflats inundated by periodic seawater). Therefore, this study used a low-cost UAV-LiDAR (light detection and ranging sensor mounted on an unmanned aerial vehicle) system as a sampling tool and Sentinel-2 imagery as auxiliary data to estimate and map the mangrove height and AGB on Hainan Island. Hainan Island has 3697.02 hectares of mangrove forests with an average patch area of approximately 1 ha. The results show that the mangroves on whole Hainan Island have an average height of 6.99 m, a total AGB of 474,199.31 Mg and an AGB density of 128.27 Mg ha&minus;1. The AGB hot spots are located in Qinglan Harbor and the south of Dongzhai Harbor. The proposed height model LiDAR-S2 performed well with an R2 of 0.67 and an RMSE (root mean square error) of 1.90 m; the proposed AGB model G~LiDAR~S2 performed better (an R2 of 0.62 and an RMSE of 50.36 Mg ha&minus;1) than the traditional AGB model G~S2 that directly related ground plots and Sentinel-2 data. The results also indicate that the LiDAR metrics describing the canopy&rsquo;s thickness and its top and bottom characteristics are the most important variables for mangrove AGB estimation. For the Sentinel-2 indices, the red-edge and shortwave infrared features, especially the red-edge 1 and shortwave infrared Band 11 features, play the most important roles in estimating mangrove AGB and height. In conclusion, this paper presents the first mangrove height and AGB maps of Hainan Island and demonstrates the feasibility of using UAV-LiDAR as a sampling tool for mangrove forests.},
DOI = {10.3390/rs11182156}
}



@Article{en12183569,
AUTHOR = {Mpfumali, Phathutshedzo and Sigauke, Caston and Bere, Alphonce and Mulaudzi, Sophie},
TITLE = {Day Ahead Hourly Global Horizontal Irradiance Forecasting—Application to South African Data},
JOURNAL = {Energies},
VOLUME = {12},
YEAR = {2019},
NUMBER = {18},
ARTICLE-NUMBER = {3569},
URL = {https://www.mdpi.com/1996-1073/12/18/3569},
ISSN = {1996-1073},
ABSTRACT = {Due to its variability, solar power generation poses challenges to grid energy management. In order to ensure an economic operation of a national grid, including its stability, it is important to have accurate forecasts of solar power. The current paper discusses probabilistic forecasting of twenty-four hours ahead of global horizontal irradiance (GHI) using data from the Tellerie radiometric station in South Africa for the period August 2009 to April 2010. Variables are selected using a least absolute shrinkage and selection operator (Lasso) via hierarchical interactions and the parameters of the developed models are estimated using the Barrodale and Roberts&rsquo;s algorithm. Two forecast combination methods are used in this study. The first is a convex forecast combination algorithm where the average loss suffered by the models is based on the pinball loss function. A second forecast combination method, which is quantile regression averaging (QRA), is also used. The best set of forecasts is selected based on the prediction interval coverage probability (PICP), prediction interval normalised average width (PINAW) and prediction interval normalised average deviation (PINAD). The results demonstrate that QRA gives more robust prediction intervals than the other models. A comparative analysis is done with two machine learning methods&mdash;stochastic gradient boosting and support vector regression&mdash;which are used as benchmark models. Empirical results show that the QRA model yields the most accurate forecasts compared to the machine learning methods based on the probabilistic error measures. Results on combining prediction interval limits show that the PMis the best prediction limits combination method as it gives a hit rate of 0.955 which is very close to the target of 0.95. This modelling approach is expected to help in optimising the integration of solar power in the national grid.},
DOI = {10.3390/en12183569}
}



@Article{f10090815,
AUTHOR = {Zou, Xiaodan and Liang, Anjie and Wu, Bizhi and Su, Jun and Zheng, Renhua and Li, Jian},
TITLE = {UAV-Based High-Throughput Approach for Fast Growing Cunninghamia lanceolata (Lamb.) Cultivar Screening by Machine Learning},
JOURNAL = {Forests},
VOLUME = {10},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {815},
URL = {https://www.mdpi.com/1999-4907/10/9/815},
ISSN = {1999-4907},
ABSTRACT = {Obtaining accurate measurements of tree height and diameter at breast height (DBH) in forests to evaluate the growth rate of cultivars is still a significant challenge, even when using light detection and ranging (LiDAR) and three-dimensional (3-D) modeling. As an alternative, we provide a novel high-throughput strategy for predicting the biomass of forests in the field by vegetation indices. This study proposes an integrated pipeline methodology to measure the biomass of different tree cultivars in plantation forests with high crown density, which combines unmanned aerial vehicles (UAVs), hyperspectral image sensors, and data processing algorithms using machine learning. Using a planation of Cunninghamia lanceolate, which is commonly known as Chinese fir, in Fujian, China, images were collected while using a hyperspectral camera. Vegetation indices and modeling were processed in Python using decision trees, random forests, support vector machine, and eXtreme Gradient Boosting (XGBoost) third-party libraries. The tree height and DBH of 2880 samples were manually measured and clustered into three groups&mdash;&ldquo;Fast&rdquo;, &ldquo;median&rdquo;, and &ldquo;normal&rdquo; growth groups&mdash;and 19 vegetation indices from 12,000 pixels were abstracted as the input of features for the modeling. After modeling and cross-validation, the classifier that was generated by random forests had the best prediction accuracy when compared to other algorithms (75%). This framework can be applied to other tree species to make management and business decisions.},
DOI = {10.3390/f10090815}
}



@Article{e21090912,
AUTHOR = {Mei, Wenjuan and Liu, Zhen and Su, Yuanzhang and Du, Li and Huang, Jianguo},
TITLE = {Evolved-Cooperative Correntropy-Based Extreme Learning Machine for Robust Prediction},
JOURNAL = {Entropy},
VOLUME = {21},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {912},
URL = {https://www.mdpi.com/1099-4300/21/9/912},
ISSN = {1099-4300},
ABSTRACT = {In recent years, the correntropy instead of the mean squared error has been widely taken as a powerful tool for enhancing the robustness against noise and outliers by forming the local similarity measurements. However, most correntropy-based models either have too simple descriptions of the correntropy or require too many parameters to adjust in advance, which is likely to cause poor performance since the correntropy fails to reflect the probability distributions of the signals. Therefore, in this paper, a novel correntropy-based extreme learning machine (ELM) called ECC-ELM has been proposed to provide a more robust training strategy based on the newly developed multi-kernel correntropy with the parameters that are generated using cooperative evolution. To achieve an accurate description of the correntropy, the method adopts a cooperative evolution which optimizes the bandwidths by switching delayed particle swarm optimization (SDPSO) and generates the corresponding influence coefficients that minimizes the minimum integrated error (MIE) to adaptively provide the best solution. The simulated experiments and real-world applications show that cooperative evolution can achieve the optimal solution which provides an accurate description on the probability distribution of the current error in the model. Therefore, the multi-kernel correntropy that is built with the optimal solution results in more robustness against the noise and outliers when training the model, which increases the accuracy of the predictions compared with other methods.},
DOI = {10.3390/e21090912}
}



@Article{s19194083,
AUTHOR = {Zhang, Xinxiang and Zeinali, Yasha and Story, Brett A. and Rajan, Dinesh},
TITLE = {Measurement of Three-Dimensional Structural Displacement Using a Hybrid Inertial Vision-Based System},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {19},
ARTICLE-NUMBER = {4083},
URL = {https://www.mdpi.com/1424-8220/19/19/4083},
ISSN = {1424-8220},
ABSTRACT = {Accurate three-dimensional displacement measurements of bridges and other structures have received significant attention in recent years. The main challenges of such measurements include the cost and the need for a scalable array of instrumentation. This paper presents a novel Hybrid Inertial Vision-Based Displacement Measurement (HIVBDM) system that can measure three-dimensional structural displacements by using a monocular charge-coupled device (CCD) camera, a stationary calibration target, and an attached tilt sensor. The HIVBDM system does not require the camera to be stationary during the measurements, while the camera movements, i.e., rotations and translations, during the measurement process are compensated by using a stationary calibration target in the field of view (FOV) of the camera. An attached tilt sensor is further used to refine the camera movement compensation, and better infers the global three-dimensional structural displacements. This HIVBDM system is evaluated on both short-term and long-term synthetic static structural displacements, which are conducted in an indoor simulated experimental environment. In the experiments, at a 9.75 m operating distance between the monitoring camera and the structure that is being monitored, the proposed HIVBDM system achieves an average of 1.440 mm Root Mean Square Error (RMSE) on the in-plane structural translations and an average of 2.904 mm RMSE on the out-of-plane structural translations.},
DOI = {10.3390/s19194083}
}



@Article{rs11192212,
AUTHOR = {Salameh, Edward and Frappart, Frédéric and Almar, Rafael and Baptista, Paulo and Heygster, Georg and Lubac, Bertrand and Raucoules, Daniel and Almeida, Luis Pedro and Bergsma, Erwin W. J. and Capo, Sylvain and De Michele, Marcello and Idier, Deborah and Li, Zhen and Marieu, Vincent and Poupardin, Adrien and Silva, Paulo A. and Turki, Imen and Laignel, Benoit},
TITLE = {Monitoring Beach Topography and Nearshore Bathymetry Using Spaceborne Remote Sensing: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {19},
ARTICLE-NUMBER = {2212},
URL = {https://www.mdpi.com/2072-4292/11/19/2212},
ISSN = {2072-4292},
ABSTRACT = {With high anthropogenic pressure and the effects of climate change (e.g., sea level rise) on coastal regions, there is a greater need for accurate and up-to-date information about the topography of these systems. Reliable topography and bathymetry information are fundamental parameters for modelling the morpho-hydrodynamics of coastal areas, for flood forecasting, and for coastal management. Traditional methods such as ground, ship-borne, and airborne surveys suffer from limited spatial coverage and temporal sampling due to logistical constraints and high costs which limit their ability to provide the needed information. The recent advancements of spaceborne remote sensing techniques, along with their ability to acquire data over large spatial areas and to provide high frequency temporal monitoring, has made them very attractive for topography and bathymetry mapping. In this review, we present an overview of the current state of spaceborne-based remote sensing techniques used to estimate the topography and bathymetry of beaches, intertidal, and nearshore areas. We also provide some insights about the potential of these techniques when using data provided by new and future satellite missions.},
DOI = {10.3390/rs11192212}
}



@Article{rs11192211,
AUTHOR = {Petliak, Helen and Cerovski-Darriau, Corina and Zaliva, Vadim and Stock, Jonathan},
TITLE = {Where’s the Rock: Using Convolutional Neural Networks to Improve Land Cover Classification},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {19},
ARTICLE-NUMBER = {2211},
URL = {https://www.mdpi.com/2072-4292/11/19/2211},
ISSN = {2072-4292},
ABSTRACT = {While machine learning techniques have been increasingly applied to land cover classification problems, these techniques have not focused on separating exposed bare rock from soil covered areas. Therefore, we built a convolutional neural network (CNN) to differentiate exposed bare rock (rock) from soil cover (other). We made a training dataset by mapping exposed rock at eight test sites across the Sierra Nevada Mountains (California, USA) using USDA’s 0.6 m National Aerial Inventory Program (NAIP) orthoimagery. These areas were then used to train and test the CNN. The resulting machine learning approach classifies bare rock in NAIP orthoimagery with a 0.95     F 1     score. Comparatively, the classical OBIA approach gives only a 0.84     F 1     score. This is an improvement over existing land cover maps, which underestimate rock by almost 90%. The resulting CNN approach is likely scalable but dependent on high-quality imagery and high-performance algorithms using representative training sets informed by expert mapping. As image quality and quantity continue to increase globally, machine learning models that incorporate high-quality training data informed by geologic, topographic, or other topical maps may be applied to more effectively identify exposed rock in large image collections.},
DOI = {10.3390/rs11192211}
}



@Article{robotics8040082,
AUTHOR = {Abouheaf, Mohammed and Gueaieb, Wail and Spinello, Davide},
TITLE = {Online Multi-Objective Model-Independent Adaptive Tracking Mechanism for Dynamical Systems},
JOURNAL = {Robotics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {82},
URL = {https://www.mdpi.com/2218-6581/8/4/82},
ISSN = {2218-6581},
ABSTRACT = {The optimal tracking problem is addressed in the robotics literature by using a variety of robust and adaptive control approaches. However, these schemes are associated with implementation limitations such as applicability in uncertain dynamical environments with complete or partial model-based control structures, complexity and integrity in discrete-time environments, and scalability in complex coupled dynamical systems. An online adaptive learning mechanism is developed to tackle the above limitations and provide a generalized solution platform for a class of tracking control problems. This scheme minimizes the tracking errors and optimizes the overall dynamical behavior using simultaneous linear feedback control strategies. Reinforcement learning approaches based on value iteration processes are adopted to solve the underlying Bellman optimality equations. The resulting control strategies are updated in real time in an interactive manner without requiring any information about the dynamics of the underlying systems. Means of adaptive critics are employed to approximate the optimal solving value functions and the associated control strategies in real time. The proposed adaptive tracking mechanism is illustrated in simulation to control a flexible wing aircraft under uncertain aerodynamic learning environment.},
DOI = {10.3390/robotics8040082}
}



@Article{electronics8101079,
AUTHOR = {Phuc, Le Tran Huu and Jeon, HyeJun and Truong, Nguyen Tam Nguyen and Hak, Jung Jae},
TITLE = {Applying the Haar-cascade Algorithm for Detecting Safety Equipment in Safety Management Systems for Multiple Working Environments},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {1079},
URL = {https://www.mdpi.com/2079-9292/8/10/1079},
ISSN = {2079-9292},
ABSTRACT = {There are many ways to maintain the safety of workers on a working site, such as using a human supervisor, computer supervisor, and smoke&ndash;flame detecting system. In order to create a safety warning system for the working site, the machine-learning algorithm&mdash;Haar-cascade classifier&mdash;was used to build four different classes for safety equipment recognition. Then a proposed algorithm was applied to calculate a score to determine the dangerousness of the current working environment based on the safety equipment and working environment. With this data, the system decides whether it is necessary to give a warning signal. For checking the efficiency of this project, three different situations were installed with this system. Generally, with the promising outcome, this application can be used in maintaining, supervising, and controlling the safety of a worker.},
DOI = {10.3390/electronics8101079}
}




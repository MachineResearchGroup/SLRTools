@article{GOH2022107847,
title = {Management of safe distancing on construction sites during COVID-19: A smart real-time monitoring system},
journal = {Computers & Industrial Engineering},
volume = {163},
pages = {107847},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2021.107847},
url = {https://www.sciencedirect.com/science/article/pii/S0360835221007518},
author = {Yang Miang Goh and Jing Tian and Eugene Yan Tao Chian},
keywords = {COVID-19, Construction safety, Computer vision, Video surveillance, Safe distancing},
abstract = {The outbreak of Coronavirus Disease 2019 (COVID-19) poses a great threat to the world. One mandatory and efficient measure to prevent the spread of COVID-19 on construction sites is to ensure safe distancing during workers’ daily activities. However, manual monitoring of safe distancing during construction activities can be toilsome and inconsistent. This study proposes a computer vision-based smart monitoring system to automatically detect worker breaching safe distancing rules. Our proposed system consists of three main modules: (1) worker detection module using CenterNet; (2) proximity determination module using Homography; and (3) warning alert and data collection module. To evaluate the system, it was implemented in a construction site as a case study. This study has two key contributions: (1) it is demonstrated that monitoring of safe distancing can be automated using our approach; and (2) CenterNet, an anchorless detection model, outperforms current state-of-the-art approaches in the real-time detection of workers.}
}
@article{CHEN2020518,
title = {A multichannel human-swarm robot interaction system in augmented reality},
journal = {Virtual Reality & Intelligent Hardware},
volume = {2},
number = {6},
pages = {518-533},
year = {2020},
issn = {2096-5796},
doi = {https://doi.org/10.1016/j.vrih.2020.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S2096579620300905},
author = {Mingxuan Chen and Ping Zhang and Zebo Wu and Xiaodan Chen},
keywords = {Human-swarm interaction, Augmented reality, Multichannel integration},
abstract = {Background
A large number of robots have put forward the new requirements for humanrobot interaction. One of the problems in human-swarm robot interaction is how to naturally achieve an efficient and accurate interaction between humans and swarm robot systems. To address this, this paper proposes a new type of human-swarm natural interaction system.
Methods
Through the cooperation between three-dimensional (3D) gesture interaction channel and natural language instruction channel, a natural and efficient interaction between a human and swarm robots is achieved.
Results
First, A 3D lasso technology realizes a batch-picking interaction of swarm robots through oriented bounding boxes. Second, control instruction labels for swarm-oriented robots are defined. The instruction label is integrated with the 3D gesture and natural language through instruction label filling. Finally, the understanding of natural language instructions is realized through a text classifier based on the maximum entropy model. A head-mounted augmented reality display device is used as a visual feedback channel.
Conclusions
The experiments on selecting robots verify the feasibility and availability of the system.}
}
@article{ZHAO2018266,
title = {Applying deep bidirectional LSTM and mixture density network for basketball trajectory prediction},
journal = {Optik},
volume = {158},
pages = {266-272},
year = {2018},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2017.12.038},
url = {https://www.sciencedirect.com/science/article/pii/S0030402617316662},
author = {Yu Zhao and Rennong Yang and Guillaume Chevalier and Rajiv C. Shah and Rob Romijnders},
keywords = {Bidiretional LSTM, Mixture density network, Basketball trajectory, SportVu, Classification and prediction},
abstract = {Data analytics helps basketball teams to create tactics. However, manual data collection and analytics are costly and ineffective. Therefore, we applied a deep bidirectional long short-term memory (BLSTM) and mixture density network (MDN) approach. This model is not only capable of predicting a basketball trajectory based on real data, but it also can generate new trajectory samples. It is an excellent application to help coaches and players decide when and where to shoot. Its structure is particularly suitable for dealing with time series problems. BLSTM receives forward and backward information at the same time, while stacking multiple BLSTMs further increases the learning ability of the model. Combined with BLSTMs, MDN is used to generate a multi-modal distribution of outputs. Thus, the proposed model can, in principle, represent arbitrary conditional probability distributions of output variables. We tested our model with two experiments on three-pointer datasets from NBA SportVu data. In the hit-or-miss classification experiment, the proposed model outperformed other models in terms of the convergence speed and accuracy. In the trajectory generation experiment, eight model-generated trajectories at a given time closely matched real trajectories.}
}
@article{LIN2022101508,
title = {Remaining useful life prediction in prognostics using multi-scale sequence and Long Short-Term Memory network⋆},
journal = {Journal of Computational Science},
volume = {57},
pages = {101508},
year = {2022},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2021.101508},
url = {https://www.sciencedirect.com/science/article/pii/S187775032100171X},
author = {Ruiguan Lin and Yaowei Yu and Huawei Wang and Changchang Che and Xiaomei Ni},
keywords = {RUL prediction, PHM, LSTM, Multi-scale sequence, Time window},
abstract = {The development of sensors and artificial intelligence technology provides practical tools for aircraft Prognosis and Health Management (PHM). The remaining useful life (RUL) prediction is the critical process of PHM. A novel data-driven framework is proposed to estimate the RUL of complex systems in this paper. The framework evaluates the system's RUL based on multi-scale sequences and Long Short-Term Memory (LSTM) networks. First, the sliding time window method is used to prepare training samples, and the degradation features are directly mapped to RUL predictions. In addition, the model parameters are adjusted through the input multi-scale sequence to obtain the best prediction performance. This method integrates the application of time window, multi-scale sequence, and LSTM structure to improve prediction accuracy. The proposed method is validated using the NASA C-MAPSS data set, and the results demonstrate the superiority of the proposed framework.}
}
@article{GUPTA2021100342,
title = {Future Smart Connected Communities to Fight COVID-19 Outbreak},
journal = {Internet of Things},
volume = {13},
pages = {100342},
year = {2021},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2020.100342},
url = {https://www.sciencedirect.com/science/article/pii/S2542660520301736},
author = {Deepti Gupta and Smriti Bhatt and Maanak Gupta and Ali Saman Tosun},
keywords = {COVID-19, Coronavirus, Internet of things, Cloud computing, Edge computing, Artificial intelligence (AI), Machine learning, Smart communities, Multi-layered architecture, Security, Privacy},
abstract = {Internet of Things (IoT) has grown rapidly in the last decade and continues to develop in terms of dimension and complexity, offering a wide range of devices to support a diverse set of applications. With ubiquitous Internet, connected sensors and actuators, networking and communication technology along with artificial intelligence (AI), smart cyber-physical systems (CPS) provide services rendering assistance and convenience to humans in their daily lives. However, the recent outbreak of COVID-19 (also known as coronavirus) pandemic has exposed and highlighted the limitations of contemporary technological deployments especially to contain the widespread of this disease. IoT and smart connected technologies together with data-driven applications can play a crucial role not only in the prevention, mitigation, or continuous remote monitoring of patients, but also enable prompt enforcement of guidelines, rules, and administrative orders to contain such future outbreaks. In this paper, we envision an IoT and data-supported connected ecosystem designed for intelligent monitoring, pro-active prevention and control, and mitigation of COVID-19 and similar epidemics. We propose a gamut of synergistic applications and technology systems for various smart infrastructures including E-Health, smart home, supply chain management, transportation, and city, which will work in convergence to develop ‘pandemic-proof’ future smart communities. We also present a generalized cloud-enabled IoT implementation framework along with scientific solutions, which can be adapted and extended to deploy smart connected ecosystem scenarios using widely used Amazon Web Services (AWS) cloud infrastructures. In addition, we also implement an E-Health RPM use case scenario to demonstrate the need and practicality for smart connected communities. Finally, we highlight challenges and research directions that need thoughtful consideration and across the board cooperation among stakeholders to build resilient communities against future pandemics.}
}
@article{FLOREZLOZANO202032,
title = {Cooperative and distributed decision-making in a multi-agent perception system for improvised land mines detection},
journal = {Information Fusion},
volume = {64},
pages = {32-49},
year = {2020},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2020.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S1566253520303067},
author = {Johana Florez-Lozano and Fabio Caraffini and Carlos Parra and Mario Gongora},
keywords = {Land mine detection, Improvised explosive device, Neuroevolution, Genetic fuzzy systems, Feature extraction, Sensor fusion},
abstract = {This work presents a novel intelligent system designed using a multi-agent hardware platform to detect improvised explosive devices concealed in the ground. Each agent is equipped with a different sensor, (i.e. a ground-penetrating radar, a thermal sensor and three cameras each covering a different spectrum) and processes dedicated AI decision-making capabilities. The proposed system has a unique hardware structure, with a distributed design and effective selection of sensors, and a novel multi-phase and cooperative decision-making framework. Agents operate independently via a customised logic adjusting their sensor positions - to achieve optimal acquisition; performing a preliminary “local decision-making” - to classify buried objects; sharing information with the other agents. Once sufficient information is shared by the agents, a collaborative behaviour emerges in the so-called “cooperative decision-making” process, which performs the final detection. In this paper, 120 variations of the proposed system, obtained by combining both classic aggregation operators as well as advanced neural and fuzzy systems, are presented, tested and evaluated. Results show a good detection accuracy and robustness to environmental and data sets changes, in particular when the cooperative decision-making is implemented with the neuroevolution paradigm.}
}
@article{MOURA2020266,
title = {On the design and analysis of structured-ANN for online PID-tuning to bulk resumption process in ore mining system},
journal = {Neurocomputing},
volume = {402},
pages = {266-282},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.03.074},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220304616},
author = {José Pinheiro Moura and João Viana Fonseca Neto and Ernesto Franklin Marçal Ferreira and Evandro Martins Araujo Filho},
keywords = {Bulk resumption process, Computational aspects, Bio-inspired adaptive method, Neurocomputing, Structured artificial neural networks},
abstract = {The tuning of proportional–integral–derivative (PID) controllers has been extensively used in the industry, this adjustment is performed by means of conventional methods, such as the Ziegler–Nichols and trial-and-error that often fails to address inherent complexity of industrial processes. To overcome these problems of PID tuning, a neurocomputing adaptive novel methodology is presented in this paper. The proposed methodology is based on a structured artificial neural network (S-ANN) and a propagation matrix of PID actions that was developed to support the tuning. The problem formulation and S-ANN-based solution are tightly connected, i.e., the nodes and layers of S-ANN topology are ruled by the order of the propagation matrix. For given operational conditions of the plant and disturbance in its parameters, the performance of the trained network is evaluated for tasks within the scope of learning on a bulk resumption process in ore mining system, focusing the control system output accuracy and convergence of the S-ANN algorithm.}
}
@article{FANG201853,
title = {Falls from heights: A computer vision-based approach for safety harness detection},
journal = {Automation in Construction},
volume = {91},
pages = {53-61},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.02.018},
url = {https://www.sciencedirect.com/science/article/pii/S0926580517308403},
author = {Weili Fang and Lieyun Ding and Hanbin Luo and Peter E.D. Love},
keywords = {Convolution neural network, Falls from height, Harness, Unsafe behavior},
abstract = {Falls from heights (FFH) are major contributors of injuries and deaths in construction. Yet, despite workers being made aware of the dangers associated with not wearing a safety harness, many forget or purposefully do not wear them when working at heights. To address this problem, this paper develops an automated computer vision-based method that uses two convolutional neural network (CNN) models to determine if workers are wearing their harness when performing tasks while working at heights. The algorithms developed are: (1) a Faster-R-CNN to detect the presence of a worker; and (2) a deep CNN model to identify the harness. A database of photographs of people working at heights was created from activities undertaken on several construction projects in Wuhan, China. The database was then used to test and train the developed networks. The precision and recall rates for the Faster R-CNN were 99% and 95%, and the CNN models 80% and 98%, respectively. The results demonstrate that the developed method can accurately detect workers not wearing their harness. Thus, the computer vision-based approach developed can be used by construction and safety managers as a mechanism to proactively identify unsafe behavior and therefore take immediate action to mitigate the likelihood of a FFH occurring.}
}
@article{FABRA2019413,
title = {Automatic system supporting multicopter swarms with manual guidance},
journal = {Computers & Electrical Engineering},
volume = {74},
pages = {413-428},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.01.026},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618323577},
author = {Francisco Fabra and Willian Zamora and Joan Masanet and Carlos T. Calafate and Juan-Carlos Cano and Pietro Manzoni},
keywords = {UAV, Swarm, Multicopter, Flight coordination, ArduSim},
abstract = {Currently, there are some scenarios, such as search and rescue operations,where the deployment of manually guided swarms of UAVs can be necessary. In such cases, the pilot’s commands are unknown a priori (unpredictable), meaning that the UAVs must respond in near real time to the movements of the leader UAV in order to maintain swarm consistency. In this paper we develop a protocol for the coordination of UAVs in a swarm where the swarm leader is controlled by a real pilot, and the other UAVs must follow it in real time to maintain swarm cohesion. We validate our solution using a realistic simulation software that we developed (ArduSim), testing flights with multiple numbers of UAVs and different swarm configurations. Simulation results show the validity of the proposed swarm coordination protocol, detailing the responsiveness limits of our solution, and finding the minimum distances between UAVs to avoid collisions.}
}
@article{CHAKRAVARTHY20152648,
title = {Adapting Stream Processing Framework for Video Analysis},
journal = {Procedia Computer Science},
volume = {51},
pages = {2648-2657},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.372},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915011801},
author = {S. Chakravarthy and A. Aved and S. Shirvani and M. Annappa and E. Blasch},
keywords = {Stream processing, Image pre-processing, Video stream processing},
abstract = {Stream processing (SP) became relevant mainly due to inexpensive and hence ubiquitous deployment of sensors in many domains (e.g., environmental monitoring, battle field monitoring). Other continuous data generators (surveillance, traffic data) have also prompted processing and analysis of these streams for applications such as traffic congestion/accidents and personalized marketing. Image processing has been researched for several decades. Recently there is emphasis on video stream analysis for situation monitoring due to the ubiquitous deployment of video cameras and unmanned aerial vehicles for security and other applications. This paper elaborates on the research and development issues that need to be addressed for extending the traditional stream processing framework for video analysis, especially for situation awareness. This entails extensions to: data model, operators and language for expressing complex situations, QoS (Quality of service) specifications and algorithms needed for their satisfaction. Specifically, this paper demonstrates inadequacy of current data representation (e.g., relation and arrable) and querying capabilities to infer long-term research and development issues.}
}
@article{PENG2019365,
title = {Precision irrigation perspectives on the sustainable water-saving of field crop production in China: Water demand prediction and irrigation scheme optimization},
journal = {Journal of Cleaner Production},
volume = {230},
pages = {365-377},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.04.347},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619314441},
author = {Yaoqi Peng and Yingxin Xiao and Zetian Fu and Yuhong Dong and Yongjun Zheng and Haijun Yan and Xinxing Li},
keywords = {Field crop, Water demand prediction, Irrigation scheme optimization, Precision irrigation},
abstract = {There is a global shortage of fresh water to meet the clean production of field crops. Water-saving irrigation can increase the production of field crops, but under certain conditions it can be overly water-saving and unsustainable, particularly in complex terrains in China where there is already a shortage of water resources. In light of the insufficient water resources and partial inequality in China, several investigators in China and abroad have researched irrigation nozzles and pumps, but there is little information on the impact of the environment on crop irrigation. The purpose of this study was to provide a fast and effective crop water demand prediction model to estimate the water requirement during the growth period of crops, to achieve the purpose of applying water according to the demand of the crops, and to optimize the irrigation network to determine the optimal network structure in order to reduce irrigation energy consumption in the process. Specifically, this study analyzed the environmental factors, namely, the soil moisture, soil electrical conductivity, air temperature, and light intensity, affecting the physiological water demand of field crops. Relevant sensors were used in the field, and environmental information was collected. This study used the collected environmental data to build a water demand prediction model based on the back propagation (BP) neural network. It also carried out optimized layout and hydrodynamic analyses of the drip irrigation network and identified the best pipe network arrangement. On the basis of the BP neural network, the remarkable R amount of 0.98963 was obtained for the water demand prediction model. The mean square error (MSE) value was 0.00857724. We also found that the drip irrigation pipe network in the H-shaped arrangement was more suitable for field crop irrigation than the comb-shaped and fish bone-shaped arrangements. This study employed the common field crops in China as the research object, used the wireless sensing technology to obtain the field environment information quickly, and constructed a water demand prediction model with high prediction accuracy. Finally, this study realized the precise control of field crop irrigation, reduced the waste of agricultural water, and achieved sustainable field crop production.}
}
@article{ZHANG2019278,
title = {Formation control of autonomous surface vehicle and experimental validation},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {24},
pages = {278-282},
year = {2019},
note = {5th IFAC Symposium on Telematics Applications TA 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.421},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319323298},
author = {Shaoze Zhang and Shaolong Yang and Xianbo Xiang},
keywords = {Autonomous surface vehicle, Formation control, Fuzzy PID, Experimental verification},
abstract = {In this paper, formation controller based on leader-follower strategy is designed for autonomous surface vehicles (ASV), and field experiment with four vehicles in geometric formation is presented. First, the set up of communication network for multiple vehicles is introduced. Second, the design and implementation of the motion controller from single vehicle to multi-ASV formation controller is presented, in which the leader-follower strategy is adopted to maintain positional relationship between the leader vehicle and the followers. The distance and course control variables are decoupled based on the proposed fuzzy PID controller for ASVs. Finally, the experimental verification of single ASV control and Multi-ASV formation control is given.}
}
@article{LYU201955,
title = {A survey on image and video stitching},
journal = {Virtual Reality & Intelligent Hardware},
volume = {1},
number = {1},
pages = {55-83},
year = {2019},
issn = {2096-5796},
doi = {https://doi.org/10.3724/SP.J.2096-5796.2018.0008},
url = {https://www.sciencedirect.com/science/article/pii/S2096579619300063},
author = {Wei LYU and Zhong ZHOU and Lang CHEN and Yi ZHOU},
keywords = {Image stitching, Video stitching, Panoramic stitching, Registration, Alignment, Mesh optimization, Deep learning, 3D stitching},
abstract = {Image/video stitching is a technology for solving the field of view (FOV) limitation of images/ videos. It stitches multiple overlapping images/videos to generate a wide-FOV image/video, and has been used in various fields such as sports broadcasting, video surveillance, street view, and entertainment. This survey reviews image/video stitching algorithms, with a particular focus on those developed in recent years. Image stitching first calculates the corresponding relationships between multiple overlapping images, deforms and aligns the matched images, and then blends the aligned images to generate a wide-FOV image. A seamless method is always adopted to eliminate such potential flaws as ghosting and blurring caused by parallax or objects moving across the overlapping regions. Video stitching is the further extension of image stitching. It usually stitches selected frames of original videos to generate a stitching template by performing image stitching algorithms, and the subsequent frames can then be stitched according to the template. Video stitching is more complicated with moving objects or violent camera movement, because these factors introduce jitter, shakiness, ghosting, and blurring. Foreground detection technique is usually combined into stitching to eliminate ghosting and blurring, while video stabilization algorithms are adopted to solve the jitter and shakiness. This paper further discusses panoramic stitching as a special-extension of image / video stitching. Panoramic stitching is currently the most widely used application in stitching. This survey reviews the latest image/video stitching methods, and introduces the fundamental principles/advantages/weaknesses of image/video stitching algorithms. Image/video stitching faces long-term challenges such as wide baseline, large parallax, and low-texture problem in the overlapping region. New technologies may present new opportunities to address these issues, such as deep learning-based semantic correspondence, and 3D image stitching. Finally, this survey discusses the challenges of image/video stitching and proposes potential solutions.}
}
@article{TORRES2019161,
title = {Integration of LiDAR and multispectral images for rapid exposure and earthquake vulnerability estimation. Application in Lorca, Spain},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {81},
pages = {161-175},
year = {2019},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2019.05.015},
url = {https://www.sciencedirect.com/science/article/pii/S0303243418308250},
author = {Yolanda Torres and José Juan Arranz and Jorge M. Gaspar-Escribano and Azadeh Haghi and Sandra Martínez-Cuevas and Belén Benito and Juan Carlos Ojeda},
keywords = {LiDAR, Orthophoto, Machine learning, Exposure, Earthquake vulnerability},
abstract = {We present a procedure for assessing the urban exposure and seismic vulnerability that integrates LiDAR data with aerial images from the Spanish National Plan of Aerial Orthophotography (PNOA). It comprises three phases: first, we segment the satellite image to divide the study area into different urban patterns. Second, we extract building footprints and attributes that represent the type of building of each urban pattern. Finally, we assign the seismic vulnerability to each building using different machine-learning techniques: Decision trees, SVM, logistic regression and Bayesian networks. We apply the procedure to 826 buildings in the city of Lorca (SE Spain), where we count on a vulnerability database that we use as ground truth for the validation of results. The outcomes show that the machine learning techniques have similar performance, yielding vulnerability classification results with an accuracy of 77%–80% (F1-Score). The procedure is scalable and can be replicated in different areas. This is particularly relevant in Spain, where more than seven hundred towns have to develop seismic risk studies in the years to come, according to the General Direction of Civil Protection and Emergencies. It is especially interesting as a complement to conventional data gathering approaches for disaster risk applications in cities where field surveys need to be restricted to certain areas, dates or budget.}
}
@article{RAUT20214830,
title = {Optimization techniques for damage detection of composite structure: A review},
journal = {Materials Today: Proceedings},
volume = {45},
pages = {4830-4834},
year = {2021},
note = {Second International Conference on Aspects of Materials Science and Engineering (ICAMSE 2021)},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.01.295},
url = {https://www.sciencedirect.com/science/article/pii/S2214785321003849},
author = {Nikhil P. Raut and A.B. Kolekar and S.L. Gombi},
keywords = {Structural integrity, Composite structure, SHM methodologies, Optimization methods, Low velocity impact (LVI), Damage detection},
abstract = {Majority of the aerospace components are made up of composite materials. The composite materials are prone to damage especially low velocity impacts which lead to loss of serviceability and safety. Composites mainly damaged due to impact. Composite structures are more vulnerable to impact damage and therefore its detection is the main objective of SHM methodology. SHM is the best way for the identification and classification of damage due to low velocity impact (LVI). The structural integrity of composite can be assessed by two major components which are a set of accelerometers and computational techniques. By using these methods damage can be detected but it requires more time. The time required for assessing the extent of damage can be optimized by improving the accuracy and efficiency of the computational techniques. The computational techniques help in the classification, prediction, and time optimization required for damage detection. The popular computational techniques used for optimization are the neural network, genetic algorithm, principal component analysis, swarm particle optimization respectively. The paper discusses the various methods for optimization required for damage detection in the composite structure.}
}
@article{ZHAN201988,
title = {Video deblurring via motion compensation and adaptive information fusion},
journal = {Neurocomputing},
volume = {341},
pages = {88-98},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S092523121930311X},
author = {Zongqian Zhan and Xue Yang and Yihui Li and Chao Pang},
keywords = {Video deblurring, Motion blur, Optical flow, Motion compensation},
abstract = {Non-uniform motion blur caused by camera shake or object motion is a common artifact in videos captured by hand-held devices. Recent advances in video deblurring have shown that convolutional neural networks (CNNs) are able to aggregate information from multiple unaligned consecutive frames to generate sharper images. However, without explicit image alignment, most of the existing CNN-based methods often introduce temporal artifacts, especially when the input frames are severely blurred. To this end, we propose a novel video deblurring method to handle spatially varying blur in dynamic scenes. In particular, we introduce a motion estimation and motion compensation module which estimates the optical flow from the blurry images and then warps the previously deblurred frame to restore the current frame. Thus, the previous processing results benefit the restoration of the subsequent frames. This recurrent scheme is able to utilize contextual information efficiently and can facilitate the temporal coherence of the results. Furthermore, to suppress the negative effect of alignment error, we propose an adaptive information fusion module that can filter the temporal information adaptively. The experimental results obtained in this study confirm that the proposed method is both effective and efficient.}
}
@article{SUN2022108502,
title = {Two-stage aware attentional Siamese network for visual tracking},
journal = {Pattern Recognition},
volume = {124},
pages = {108502},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.108502},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321006786},
author = {Xinglong Sun and Guangliang Han and Lihong Guo and Hang Yang and Xiaotian Wu and Qingqing Li},
keywords = {Visual tracking, Siamese network, Feature learning, Attention network},
abstract = {Siamese networks have achieved great success in visual tracking with the advantages of speed and accuracy. However, how to track an object precisely and robustly still remains challenging. One reason is that multiple types of features are required to achieve good precision and robustness, which are unattainable by a single training phase. Moreover, Siamese networks usually struggle with online adaption problem. In this paper, we present a novel two-stage aware attentional Siamese network for tracking (Ta-ASiam). Concretely, we first propose a position-aware and an appearance-aware training strategy to optimize different layers of Siamese network. By introducing diverse training patterns, two types of required features can be captured simultaneously. Then, following the rule of feature distribution, an effective feature selection module is constructed by combining both channel and spatial attention networks to adapt to rapid appearance changes of the object. Extensive experiments on various latest benchmarks have well demonstrated the effectiveness of our method, which significantly outperforms state-of-the-art trackers.}
}
@article{WANG201873,
title = {Hyperspectral sensing of heavy metals in soil and vegetation: Feasibility and challenges},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {136},
pages = {73-84},
year = {2018},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2017.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0924271617303702},
author = {Fenghe Wang and Jay Gao and Yong Zha},
keywords = {Heavy metal contamination, Hyperspectral sensing, Analytical modelling, Partial least squares regression, Fuzzy neural network, Vegetation indexing},
abstract = {Remote sensing of heavy metal contamination of soils has been widely studied. These studies concentrate heavily on the hyperspectral reflectance of typical metals in soils and in plants measured either in situ or in the laboratory. The most used wavebands lie within the visible-near infrared portion of the spectrum, especially the red edge. In comparison, mid- and far-infrared wavelengths are used far less frequently. Hyperspectral data are optimized to suppress noises and enhance the signal of the targeted metals through spectral derivatives and vegetation indexing. It is found that only subtle disparity exists in spectral responses for some metals at a sufficiently high content level. Not all metals have their own unique spectral response. Their detection has to rely on their co-variation with the spectrally responsive metals or organic matter in the soils. The closeness of the correlation dictates the accuracy of prediction. Without any theoretical grounding, this correlation is site-specific. Various analytical methods, including stepwise multi-linear regression, partial least squares regression, and neural networks have been used to model metal content level from the identified spectrally sensitive bands and/or their transformed indices. Both the model and the explanatory variables vary with the metal under detection and the area from which in situ samples are collected. Despite the amply demonstrated feasibility of estimating several metals by a large number of authors, only a few have succeeded in mapping the spatial distribution of metals from HyMAP, HJ-1A and Hyperion images to a satisfactory accuracy using complex algorithms and after taking environmental variables into account. The large number of reported failures testifies the difficulty in the detection of heavy metals in soils and plants, especially when their concentration level is low. The reasons or factors responsible for the success or failure have not been systematically analyzed, including the minimal spectral resolution required.}
}
@article{LIU2021102481,
title = {A novel Landsat-based automated mapping of marsh wetland in the headwaters of the Brahmaputra, Ganges and Indus Rivers, southwestern Tibetan Plateau},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {103},
pages = {102481},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102481},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421001884},
author = {Qionghuan Liu and Yili Zhang and Linshan Liu and Zhaofeng Wang and Yong Nie and Mohan Rai},
keywords = {Wetland mapping, Random forest, Feature optimization, Google Earth Engine, Tibetan Plateau},
abstract = {Wetlands not only affect the local hydrology and ecosystems, but also regulate the conditions of human-environment. However, the availability of accurate wetland data remains a key challenge in wetland research. This study attempts to address this problem through a novel mapping framework that is based on the Google Earth Engine (GEE), feature optimization, and the random forest (RF) model (GFORF). This framework was built to map high-accuracy wetland data on the headwaters of the Brahmaputra, Ganges, and Indus rivers (HBGIR) in the western Tibetan Plateau (TP). Four time periods were examined: 1990, 2000, 2010, and 2017. Our results showed that the overall accuracy for the acquired wetland data was 82.73%, 83.16%, 82.47%, and 88.14% in 1990, 2000, 2010, and 2017, respectively. Furthermore, the feature optimization results showed that the spectral indices feature was the main contributor to the accuracy of wetland mapping, with the highest value being 26.9%. The seasonal factors, surface reflectance, auxiliary data, and texture contributed 21.8%, 21.6%, 21.5%, and 8.1%, respectively. Combining the seasonal features and auxiliary data of distances to rivers significantly improved the mapping accuracy of the wetlands by approximately 14%, 24%, 11%, and 10% in 1990, 2000, 2010, and 2017, respectively. In addition, our analysis showed that the wetland areas in the HBGIR amounted to 5177.39 km2, accounting for 5.82% of the total area. Over the 30-year observation period, the overall consolidation of the wetlands was characterized by a slight expansionary phase, with an average increase of 0.16% per year from 1990 to 2017. As a result of the improvement in the accuracy of wetland mapping in alpine areas, the change dynamics of wetlands was revealed, which provides justification for implementing ongoing wetland ecological services and protection measures.}
}
@article{FOTOHI2020106675,
title = {Securing of Unmanned Aerial Systems (UAS) against security threats using human immune system},
journal = {Reliability Engineering & System Safety},
volume = {193},
pages = {106675},
year = {2020},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2019.106675},
url = {https://www.sciencedirect.com/science/article/pii/S0951832018314212},
author = {Reza Fotohi},
keywords = {Unmanned Aerial Systems, Security threats, IDS, HIS, Routing security, SUAS-HIS},
abstract = {UASs form a large part of the fighting ability of the advanced military forces. In particular, these systems that carry confidential information are subject to security attacks. Accordingly, an Intrusion Detection System (IDS) has been proposed in the proposed design to protect against the security problems using the human immune system (HIS). The IDSs are used to detect and respond to attempts to compromise the target system. Since the UASs operate in the real world, the testing and validation of these systems with a variety of sensors is confronted with problems. This design is inspired by HIS. In the mapping, insecure signals are equivalent to an antigen that are detected by antibody- based training patterns and removed from the operation cycle. Among the main uses of the proposed design are the quick detection of intrusive signals and quarantining their activity. Moreover, SUAS-HIS method is evaluated here via extensive simulations carried out in NS-3 environment. The simulation results indicate that the UAS network performance metrics are improved in terms of false positive rate, false negative rate, detection rate, and packet delivery rate.}
}
@article{SWIRAD2021107799,
title = {Automating coastal cliff erosion measurements from large-area LiDAR datasets in California, USA},
journal = {Geomorphology},
volume = {389},
pages = {107799},
year = {2021},
issn = {0169-555X},
doi = {https://doi.org/10.1016/j.geomorph.2021.107799},
url = {https://www.sciencedirect.com/science/article/pii/S0169555X21002075},
author = {Zuzanna M. Swirad and Adam P. Young},
keywords = {Coastal cliffs, Landslides, Topographic change detection, Machine learning},
abstract = {Quantifying coastal cliff erosion is critical for improved predictions of coastal change and coastal management. However, few studies have been conducted at a scale (>100 km) and resolution (~1 m) sufficient to constrain regional change. Here, we quantified cliff erosion for 866 km of the California coastline using airborne LiDAR data collected in 2009–2011 and 2016. A semi-automated method was used to map cliff faces. Negative (volume loss) and positive (volume gain) change objects were created by grouping adjacent cells using vertical and areal change thresholds and surface optical signatures. We assessed the performance of five machine learning algorithms to separate erosion and deposition from other changes within the cliff face, notably vegetation loss and growth, and found that discriminant analysis performed best. After applying the classification method to the entire cliff change dataset, the results were visually inspected for quality control, producing a final dataset comprised of 45,699 erosion and 1728 deposition objects. The net volume loss from 2009–2011 to 2016 was 1.24 × 107 m3, equivalent to an erosion rate of 2.47 m3 yr−1 per meter of coastline, and an average cliff retreat rate of 0.06 m yr−1. Eroded volumes ranged from 6.43 m3 to 7.52 × 105 m3 and fit a power-law frequency distribution (β = 0.80; r2 = 0.99). Over this study period, 7% of eroded material remained on the cliff face. Cliff retreat rates varied spatially with the highest rates in Humboldt County (0.18 m yr−1) and the lowest in Orange County (0.003 m yr−1).}
}
@article{REZAEI2018224,
title = {Adaptive consensus for high-order unknown nonlinear multi-agent systems with unknown control directions and switching topologies},
journal = {Information Sciences},
volume = {459},
pages = {224-237},
year = {2018},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2018.04.089},
url = {https://www.sciencedirect.com/science/article/pii/S002002551830344X},
author = {Mohammad Hadi Rezaei and Meisam Kabiri and Mohammad Bagher Menhaj},
keywords = {Consensus, High-order nonlinear multi-agent systems, Unknown control directions, Input saturation, Switching topologies, Unknown dynamics},
abstract = {In this paper, we provide a comprehensive assessment of the consensus of high-order nonlinear multi-agent systems with input saturation and time-varying disturbance under switching topologies. The control directions and model parameters of agents are supposed to be unknown. Our approach is based on transforming the problem of consensus for a network that consists of high-order nonlinear agents to that of perturbed first-order multi-agent systems. The unknown part of dynamics is cancelled using radial basis neural networks. Nussbaum gains and auxiliary systems are respectively employed to overcome the unknown input direction and the saturation. Adaptive sliding mode control is used to compensate for the time-varying disturbance and the imperfect approximation of the developed neural network as well. Through Lyapunov analysis, it is shown that the overall closed-loop system maintains asymptotic stability. Finally, our approach is applied to a group of multiple single-link flexible joint manipulators to highlight better its merit.}
}
@article{FARZANMANESH2021100612,
title = {Technological opportunities for measuring and monitoring blue carbon initiatives in mangrove ecosystems},
journal = {Remote Sensing Applications: Society and Environment},
volume = {24},
pages = {100612},
year = {2021},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2021.100612},
url = {https://www.sciencedirect.com/science/article/pii/S2352938521001488},
author = {Raheleh Farzanmanesh and Kourosh Khoshelham and Sebastian Thomas},
keywords = {Climate change, Remote sensing, Image classification, REDD+, Carbon measurement},
abstract = {Mangrove forests play a crucial role in the carbon cycle and mitigate climate change by reducing carbon dioxide emissions. However, mangrove ecosystems have declined dramatically in most regions due to natural and human factors, resulting in the release of substantial amounts of carbon dioxide. ‘Blue carbon’ conservation and restoration initiatives seek to reduce greenhouse gas emissions and support adaptation in mangrove areas. Various methods are employed to estimate, map, and monitor the extent and dynamics of mangrove biomass and carbon stocks, and these play a critical role in sustainable management and the climate policy and market instruments which can provide financial support for ecosystem conservation and restoration. This paper presents a comprehensive review of different mapping and monitoring methods applied from 2010 to 2020 for carbon stocks in mangrove forests, and highlights the limitations of previous studies. Destructive sampling, use of allometric equations, and remote sensing technologies are described and assessed. Passive and active sensors at various spatial resolutions (1 m–30 m), and supervised and unsupervised classification methods, are discussed. A novel aspect of this paper is the assessment of monitoring methods and the uncertainty of carbon stock estimation in mangrove forests. The study discusses the advantages and drawbacks of existing methods for mangrove carbon stock measurement and provides recommendations for effective application of blue carbon studies in global markets.}
}
@article{SINGH2021,
title = {Forest 4.0: Digitalization of forest using the Internet of Things (IoT)},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821000483},
author = {Rajesh Singh and Anita Gehlot and Shaik {Vaseem Akram} and Amit {Kumar Thakur} and Dharam Buddhi and Prabin {Kumar Das}},
keywords = {Digital network, Forest, IoT, Minor forest produce, Real-time sensing, Tribal livelihood, And wildlife},
abstract = {“Digitalization of forest”, as this phrase itself suggests the sustainable implementation of cutting-edge technologies into forests for improving the current trends that are being used for forest environment monitoring, data acquisition, and analysis in the field of research and development. Technologies that can be used effectively for achieving these objectives include the Internet of Things, Wireless Sensor Networks, Internet of Trees, Deep Learning, etc. In this study, we will be exploring and assimilating the limitless possibilities for technological interventions in forests to drastically improve their ecosystem. Intelligent systems for sensing, monitoring, and methods for analysis to be used in applications such as forest fire incidents, illegal logging of trees, poaching, etc. have been discussed briefly. In addition to that, generalized architectures have been proposed which can be used directly in the future for advancements in research and development related to data collection and processing applications like flora analysis, forest fire predictions, etc. without the need for any changes in forest deployment systems. Various methods for enhancement of tribal livelihood, high yield marketing of minor forest produces, and wildlife monitoring is also discussed relating to the areas concentric on the forest environment. Effective connectivity, sustained deployment of real-time sensing systems, and energy harvesting are some of the vital recommendations included and addressed in this study for aiding the proper implementation of digital networks in the forest ecosystem.}
}
@article{LIU2014217,
title = {2-D defect profile reconstruction from ultrasonic guided wave signals based on QGA-kernelized ELM},
journal = {Neurocomputing},
volume = {128},
pages = {217-223},
year = {2014},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2012.11.053},
url = {https://www.sciencedirect.com/science/article/pii/S0925231213007285},
author = {Bing Liu and Liwei Tang and Jianbin Wang and Aihua Li and Yali Hao},
keywords = {Ultrasonic guided wave, Profile reconstruction, Extreme learning machine, Kernelized extreme learning machine, Least squares support vector machine, Quantum genetic algorithm},
abstract = {The reconstruction of defect profiles based on ultrasonic guided waves means the acquisition of defect profiles and parameters from ultrasonic guided wave inspection signals, and it is the key for the inversion of ultrasonic guided waves. A method for the reconstruction of 2-D profiles based on kernelized extreme learning machine (ELM) is presented, and quantum genetic algorithm (QGA) is adopted to optimize the cost parameter C and kernel parameter γ of kernelized ELM. The input data sets of kernelized ELM are defect echo signals, and the output data sets are 2-D profile parameters. The mapping from defect echo signals to 2-D profiles is established. The sample database is achieved by practical experiments and numerical simulations. Then, 2-D profile reconstruction of artificial defects in ultrasonic guided wave testing is implemented with QGA-kernelized ELM. To compare the generalization performance and reconstruction results, another reconstruction model based on LS-SVM is designed simultaneously with the same kernel. Finally, experimental results indicate that proposed method possesses faster speed, lower computational complexity and better generalization performance, and it is a feasible and effective approach to reconstruct 2-D defect profiles.}
}
@article{DESA2017738,
title = {Distributed and resilient localization algorithm for Swarm Robotic Systems},
journal = {Applied Soft Computing},
volume = {57},
pages = {738-750},
year = {2017},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2016.07.049},
url = {https://www.sciencedirect.com/science/article/pii/S1568494616303842},
author = {Alan Oliveira {de Sá} and Nadia Nedjah and Luiza de Macedo Mourelle},
keywords = {Localization, Swarm robotics, Swarm intelligence, BSA},
abstract = {Many applications of Swarm Robotic Systems (SRSs) require each robot to be able to discover its own position. To provide such capability, some localization methods have been proposed, in which the positions of the robots are estimated based on a set of reference nodes in the swarm. In this paper, a distributed and resilient localization algorithm is proposed based on the BSA–MMA algorithm, which uses the Backtracking Search Algorithm (BSA) and the Min–Max Area (MMA) confidence factor. It is designed in a novel four-stage approach, where a new method, called Multi-hop Collaborative Min–Max Localization (MCMM), is included to improve the resilience in case of failures during the recognition of the reference nodes. The results, obtained with real Kilobot robots, show 28–36% of performance improvement obtained by the MCMM. Also, it is shown that the final result of the localization process is better when the MCMM is executed than if it is not executed. The experiments outcomes demonstrate that the novel four-stage approach and the use of the MCMM algorithm represents a progress in the design of distributed localization algorithms for SRS, especially with regard to its resilience.}
}
@article{CHEN2019292,
title = {Distributed Norm Optimal Iterative Learning Control for Point-to-Point Consensus Tracking},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {29},
pages = {292-297},
year = {2019},
note = {13th IFAC Workshop on Adaptive and Learning Control Systems ALCOS 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.665},
url = {https://www.sciencedirect.com/science/article/pii/S240589631932614X},
author = {Bin Chen and Bing Chu},
keywords = {Iterative learning control, networked dynamical systems, point to point tasks, the alternating direction method of multipliers},
abstract = {High performance consensus tracking of networked dynamical systems working repetitively is an important class of coordination problems and it has found many applications in different areas. Recently, iterative learning control (ILC), which does not require a highly accurate model to achieve the high performance requirement, has been developed for the consensus tracking problem. Most of existing ILC algorithms consider about the tracking of a reference defined over the whole trial length, while the Point-to-Point (P2P) task where the emphasis is placed on the tracking of intermediate time instant points, has not been explored. To bridge this gap, we develop a norm optimal ILC (NOILC) algorithm for P2P consensus tracking problem that guarantees not only the monotonic convergence of consensus tracking error norm to zero, but also the convergence of input to the minimum input energy solution, which is desired in practice. Moreover, using the idea of the alternating direction method of multipliers, we develop a distributed implementation method for the proposed algorithm, allowing the resulting algorithm to be applied to large scale networked dynamical systems. Rigorous analysis of the algorithm’s properties is provided and numerical simulations are given to verify its effectiveness.}
}
@article{STOVALL2019111271,
title = {Quantifying wetland microtopography with terrestrial laser scanning},
journal = {Remote Sensing of Environment},
volume = {232},
pages = {111271},
year = {2019},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2019.111271},
url = {https://www.sciencedirect.com/science/article/pii/S0034425719302901},
author = {Atticus E.L. Stovall and Jacob S. Diamond and Robert A. Slesak and Daniel L. McLaughlin and Hank Shugart},
keywords = {3D, Hummock, Hollow, Hydrology, Terrestrial LiDAR, Algorithm, Automatic, Sensitivity, Model resolution, Classification, Machine learning},
abstract = {Wetlands hold the highest density of belowground carbon stocks on earth, provide myriad biogeochemical and habitat functions, and are at increasing risk of degradation due to climate and land use change. Microtopographic variation is a common and functionally important feature of wetlands but is challenging to quantify, constraining estimates of the processes and functions (e.g., habitat diversity, carbon storage) that it regulates. We introduce a novel method of quantifying fine-scale microtopographic structure with Terrestrial Laser Scanning using 10 black ash (Fraxinus nigra) wetlands in northern Minnesota, USA as test cases. Our method reconstructs surface models with fine detail on the order of 1 cm. Our independent validation verifies the surface models capture hummock (local high points) and hollow (local low points) features with high precision (RMSE = 3.67 cm) and low bias (1.26 cm). A sensitivity analysis of surface model resolution showed a doubling of model error between 1 cm and 50 cm resolutions, suggesting high-resolution reconstructions most precisely capture surface variation. We also compared five classification methods at resolutions ranging from 1 cm to 1 m and determined that maximum likelihood classification at 25 cm resolution most accurately (78.7%) identifies hummock and hollow features, but a simple thresholding of surface model elevation and slope was ideal for hummock feature delineation, retaining over 91% of hummock areas. Finally, we test and validate a novel microtopographic delineation method (TopoSeg) that accurately (Bias = 0.2–11.9%, RMSE = 19.6–24.1%) estimates the height, area, volume, and perimeter of individual hummock features. For the first time, we introduce an accurate and automated approach for quantifying fine-scale microtopography through high resolution surface models, feature classification, and feature delineation, enabling geospatial statistics that can explain spatial heterogeneity of habitat structure, soil processes, and carbon storage in wetland systems.}
}
@article{CHEN2021101387,
title = {Mapping the scientific research on natural landscape change with rephotography},
journal = {Ecological Informatics},
volume = {64},
pages = {101387},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101387},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121001783},
author = {Junru Chen and Lanmin Liu and Miles Dyck and Jialong Lv and Hailong He},
keywords = {Landscape change, Rephotography, Scientometrics, Bibliometric analysis, VOSviewer, HistCite Pro},
abstract = {Rephotography is the most common method used to observe landscape changes over time. The objective of this study was to analyze the trajectory of rephotography research with scientometrics. The Web of Science Core Collection database was used and a total of 315 publications on landscape change with rephotography from 1992 to 2020 were retrieved. The results identified that the number of articles published in this field was on the rise. Most of these articles describe changes in the natural landscape, such as changes in vegetation cover, the rate of plant growth, and the speed at which glaciers are retreating. The analysis results show that Dr. Michael Timm Hoffman published the most articles on rephotography, while Dr. Nyssen Jan collaborated the most with other researchers. The co-authorship analysis revealed that University of Cape Town (South Africa), Ghent University (Belgium), and US Geology Survey (USA) were the top three organizations. The USA, Canada and the UK showed active research cooperation with other countries. Geomorphology, Journal of Arid Environments, and Earth Surface Processes and Landforms were the most utilized journals. The co-occurrence and citation analysis also identified hot research areas in this field and the highly cited publications. Future development on new technology or user-friendly mobile applications is required for more widely applications of rephotography.}
}
@article{GUO2020111731,
title = {A real time data driven algal bloom risk forecast system for mariculture management},
journal = {Marine Pollution Bulletin},
volume = {161},
pages = {111731},
year = {2020},
issn = {0025-326X},
doi = {https://doi.org/10.1016/j.marpolbul.2020.111731},
url = {https://www.sciencedirect.com/science/article/pii/S0025326X20308493},
author = {Jiuhao Guo and Yahong Dong and Joseph H.W. Lee},
keywords = {Eutrophication, Harmful algal blooms, Fisheries management, Red tide, Stratification, Real-time forecast, Water quality prediction, Dissolved oxygen, Chlorophyll, Artificial neural network, Data assimilation, Risk management},
abstract = {In eutrophic coastal waters, harmful algal blooms (HAB) often occur and present challenges to environmental and fisheries management. Despite decades of research on HAB early warning systems, the field validation of algal bloom forecast models have received scant attention. We propose a daily algal bloom risk forecast system based on: (i) a vertical stability theory verified against 191 past algal bloom events; and (ii) a data-driven artificial neural network (ANN) model that assimilates high frequency data to predict sea surface temperature (SST), vertical temperature and salinity differential with an accuracy of 0.35oC, 0.51oC, and 0.58 psu respectively. The model does not rely on past chlorophyll measurements and has been validated against extensive field data. Operational forecasts are illustrated for representative algal bloom events at a marine fish farm in Tolo Harbour, Hong Kong. The robust model can assist with traditional onsite monitoring as well as artificial-intelligence (AI) based methods.}
}
@article{VANDEVIJVER2020105106,
title = {In-field detection of Alternaria solani in potato crops using hyperspectral imaging},
journal = {Computers and Electronics in Agriculture},
volume = {168},
pages = {105106},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.105106},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919304582},
author = {Ruben {Van De Vijver} and Koen Mertens and Kurt Heungens and Ben Somers and David Nuyttens and Irene Borra-Serrano and Peter Lootens and Isabel Roldán-Ruiz and Jürgen Vangeyte and Wouter Saeys},
keywords = {Precision crop farming, Crop protection, Proximal sensing, PLS-DA, SVM},
abstract = {Automatic detection of early blight caused by Alternaria solani could promote a drastic reduction in the consumption of plant protection agents and the related production losses. A proximal sensing platform was constructed and calibrated for acquiring high resolution hyperspectral images in the field, and used to accurately map Alternaria lesions. High resolution canopy reflectance images were obtained for 32 potato plants that had been infected with A. solani and 32 healthy reference plants. Spectral classifiers like partial least squares discriminant analysis (PLS-DA) and support vector machines (SVM) based on PCA scores were tested to discriminate affected and non-affected pixels. Both spectral classifiers performed well at pixel level with accuracies above 0.92. The NIR region (750 nm) was identified as the most discriminative part of the spectrum for detecting the lesions. As the disease pressure is typically expressed as the number of lesions per area, the accuracy was also evaluated at this level. This indicated a considerable number of false detections at the edges of the leaves and the leaf axils. Therefore, a decision tree was designed based on expert knowledge about the shape of Alternaria lesions, and used to post-process the classified images. This reduced the number of false detections, increasing the precision from 0.17 to 0.22 at the expense of a reduction in recall from 0.88 to 0.84. This leaves considerable room for improvement in the classification accuracy at the object level. We learned that (1) few, broad wavelengths are sufficient and (2) spatial context is essential for the detection of lesions caused by Alternaria infection. The application of more powerful object classification techniques such as convolutional neural networks to enhance the model performance by efficiently encapsulating the spatial context in the classifier might further improve the detection performance. This could pave the way to UAV or tractor based Alternaria mapping.}
}
@article{OLIVARES20151240,
title = {Modeling Internal Logistics by Using Drones on the Stage of Assembly of Products},
journal = {Procedia Computer Science},
volume = {55},
pages = {1240-1249},
year = {2015},
note = {3rd International Conference on Information Technology and Quantitative Management, ITQM 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.07.132},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915016075},
author = {Víctor Olivares and Felisa Cordova and Juan M. Sepúlveda and Ivan Derpich},
keywords = {Genetic Algorithm, Quadcopter, Traveling Salesman Problem, Energy Saving of Battery},
abstract = {The subject addressed in this paper is the issue of using an UAV type Quadcopter in the internal logistics within a manufacturing plant, particularly at the stage of assembly and /or customization of products. The vertical takeoff and landing, as well as horizontal flight, both with the characteristic of low speed and high precision, are major requirements for this work. The quadrotor architecture has been chosen for analysis because of its low dimensions, good maneuverability, simple mechanics and available payload capacity. As a major drawback, the high energy consumption when operating is a constraint to be modeled and optimized. In the first step, an internal logistics modeling is performed in order to determine the location of depots, clusters and sub-clusters; workstations are defined and routes are generated using a genetic algorithm for each quadcopter of a particular fleet. In a second step, the weight to be transported by each quadcopter is determined, depending on the assigned route and workstations that should go through the sequence either to remove materials (picking) or to deliver materials (delivery). In a third step, it is determined the electric power amount to be drained off the battery of every quadcopter for a given route depending on the weight carried, distance covered, number of workstations visited and the quadcopter aerodynamic efficiency.}
}
@article{MIRANDA201921,
title = {Sensing, smart and sustainable technologies for Agri-Food 4.0},
journal = {Computers in Industry},
volume = {108},
pages = {21-36},
year = {2019},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2019.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0166361518305517},
author = {Jhonattan Miranda and Pedro Ponce and Arturo Molina and Paul Wright},
keywords = {Agri-Food 4.0, Industry 4.0, Agri-food production, Connectivity, Digitalisation, Sensing, Smart and sustainable systems},
abstract = {Currently, the agri-food sector takes advantage of modern machinery, tools and emerging information and communication technologies (ICTs) that consider the Internet of Things (IoT) capabilities. These implementations have given way to a new era of agri-food production called ‘Agri-Food 4.0’, where automation, connectivity, digitalisation, the use of renewable energies and the efficient use of resources are predominant in this sector. In this article, the ‘sensing, smart and sustainable (S3)’ concept is applied to develop new technologies that can respond to current challenges of agri-food industries. Therefore, this work focuses on describing how S3 technologies for the agri-food sector can be developed using a systematic process for new product development (NPD). The main objective of this work is to fill the gap vis-à-vis the current lack of design roadmaps that permit the development of this new generation of products in the context of agri-food 4.0. Finally, this work presents case studies of S3 technologies applied to the agri-food sector: an intelligent greenhouse, a sun tracker trajectory, an hexapod robot for field monitoring and an agricultural drone.}
}
@article{LIU2021109193,
title = {Review of electromagnetic waves-based distance measurement technologies for remote monitoring of civil engineering structures},
journal = {Measurement},
volume = {176},
pages = {109193},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.109193},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121002116},
author = {Yiming Liu and Yi Bao},
keywords = {Computer vision, Condition assessment, Electromagnetic wave, Global navigation satellite system, Laser-based measurement, Microwave radar, Remote sensing},
abstract = {Measuring distance is essential for health monitoring and condition assessment of civil engineering structures. This paper reviews recent advances in remote sensing technologies for measuring distance based on electromagnetic waves. Specifically, four families of technologies are reviewed, which are the Global Navigation Satellite Systems, microwave radars, laser-based methods, and vision-based methods. The reviewed content covers the measurement principles, signal processing methods, state-of-the-art applications, and key performance metrics. The investigated performance includes the measurement accuracy, sampling frequency, operating distance, robustness to the environment, and compatibility with autonomous platforms. Existing inconsistent viewpoints concerning the performance are discussed. Based on the features of different technologies, a decision tree is presented to facilitate selection of appropriate methods for intended applications. This research is expected to promote development and applications of remote sensing technologies for facilitating condition assessment of engineering structures.}
}
@article{ALMUHTARAM2021108442,
title = {State of knowledge on early warning tools for cyanobacteria detection},
journal = {Ecological Indicators},
volume = {133},
pages = {108442},
year = {2021},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2021.108442},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X21011079},
author = {Husein Almuhtaram and Faith A. Kibuye and Suraj Ajjampur and Caitlin M. Glover and Ron Hofmann and Virginie Gaget and Christine Owen and Eric C. Wert and Arash Zamyadi},
keywords = {Monitoring, Remote sensing, Drones, Automated cell imaging, Artificial intelligence, Phycocyanin},
abstract = {The potential for cyanobacterial blooms to impact recreational and drinking water source quality is a growing concern. Numerous monitoring tools have been developed that can alert stakeholders to the onset of cyanobacterial blooms to initiate mitigation efforts for waters used for recreation or drinking water supply. Early warning monitoring systems need to consider multiple aspects of a cyanobacterial bloom: whether a bloom is occurring in the source water, whether it might be transported to drinking water intakes, whether toxin or taste and odor compound producers are present and what proportion of the cells in a bloom they comprise, and whether cells are entering a utility at concentrations above threshold levels. No single monitoring tool can provide all this information, so multi-barrier approaches are needed. Reviews of monitoring tools and their variations are available, but they are generally limited to one type of tool. Instead, a review and comparison of all the available tools is needed to inform stakeholders of them and their relative advantages and limitations. Therefore, this review covers conventional tools including microscopic enumeration, pigment extraction, qPCR, probes, and remote sensing as well as emerging techniques including next-generation sequencing, photonic systems, biosensors, drones, and applications of machine learning and discusses them primarily from a practical and operational standpoint. Moreover, a three-tier framework is proposed for designing comprehensive early warning systems that groups monitoring tools by their analytical targets: biological activity or algal biomass, cyanobacteria or cyanobacteria-related genes, and cyanobacterial metabolites. First tier tools are generally simple and inexpensive to use, including turbidity, optical density, visual inspection, drones, chlorophyll a, and adenosine triphosphate. Changes in water quality conditions detected using a first tier tool triggers the use of a second tier tools for identification and quantification of cyanobacteria by microscopy, phycocyanin, biosensors, hyperspectral remote sensing, or next-generation sequencing. If potentially harmful concentrations of cyanobacteria are confirmed, third tier tools are deployed for quantifying concentrations of cyanotoxins and taste and odor compounds or the genes that encode for them using enzyme-linked immunosorbent assays, mass spectrometry, qPCR, or other analytical methods. This framework is designed to minimize the time and cost associated with cyanobacteria monitoring without compromising the ability of stakeholders to detect the onset of a bloom.}
}
@article{XUAN202194,
title = {Rotation adaptive correlation filter for moving object tracking in satellite videos},
journal = {Neurocomputing},
volume = {438},
pages = {94-106},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.01.058},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221000862},
author = {Shiyu Xuan and Shengyang Li and Zifei Zhao and Zhuang Zhou and Wanfeng Zhang and Hong Tan and Guisong Xia and Yanfeng Gu},
keywords = {Correlation filter, Moving object tracking, Rotation adaptive, Video satellite},
abstract = {As a new method of Earth observation, video satellite can provide high-temporal resolution remote sensing images for object tracking. Object tracking in satellite videos is promising yet challenging in computer vision. Although many algorithms for satellite video object tracking have been proposed, none of them solve the problem of tracking rotating object. Due to the nadir view, the rotation of an object is very common in the satellite videos. This problem urgently needs to be addressed. In this paper, a rotation-adaptive correlation filter (RACF) tracking algorithm is proposed to address the problem caused by the rotation of object. The proposed algorithm provides the following improvements: (a) A method of estimating the object rotation angle to keep the feature map stable during the object rotation is proposed. This method can overcome the drawback of histogram of oriented gradient (HOG) based trackers, which cannot deal with the rotation of objects in satellite videos; and (b) making the algorithm capable of estimating the change in the bounding box size caused by object’s rotation. The experimental results demonstrate that our algorithm can track object with a 99.84% precision score and 92.96% success score in six videos from the Jilin-1 satellite constellation.}
}
@article{ANITHA2021143,
title = {DEQLFER — A Deep Extreme Q-Learning Firefly Energy Efficient and high performance routing protocol for underwater communication},
journal = {Computer Communications},
volume = {174},
pages = {143-153},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.04.030},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421001742},
author = {D. Anitha and R.A. Karthika},
keywords = {Underwater sensor networks, Deep extreme learning machines, Adaptive firefly algorithms, Q-learning, Reward function, DQLER},
abstract = {With an advent of Underwater sensor networks, underwater communication has reached its new dimension of research. These networks are characterized by the elongated end to end delay, high energy utility and most importantly dynamic network topologies. By incorporating these characteristics, numerous automated routing algorithms has been proposed to achieve the energy efficient and low latency data transmission. But still, short-comings still exists due to the above mentioned characteristics and the most comprehensive routing algorithms are badly desired. In this article, a novel routing scheme based on Q-learning framework and Deep Extreme Learning Machines aided with Adaptive Firefly Routing algorithm to address the above mentioned research constraints including energy efficiency and network unsteadiness in underwater communication , that practices the hybrid combination of reward function and adaptive fireflies to determine the optimal routing mechanism. In this algorithm, traditional q-learning mechanism has been replaced by the powerful q-deep extreme learning mechanism which uses the adaptive reward function for the varying underwater environment and to boost the packet-delivery ratio (PDR) and throughputs. Also the paper uses the powerful firefly aided routing mechanism to achieve the energy efficient data transmission and to avoid the void dilemma problems. The extensive experimentations has been conducted on the proposed algorithm and compared with other state of art schemes such as Q deep q-Learning energy aware routing protocol (DQLER), DELR Protocols and VBF protocols in which the proposed algorithm has outperformed than the compared existing algorithms in terms of complexity, energy consumption , packet delivery ratio and end to end delay.}
}
@article{ALHASSAN2020105862,
title = {Power transmission line inspection robots: A review, trends and challenges for future research},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {118},
pages = {105862},
year = {2020},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2020.105862},
url = {https://www.sciencedirect.com/science/article/pii/S0142061519324524},
author = {Ahmad Bala Alhassan and Xiaodong Zhang and Haiming Shen and Haibo Xu},
keywords = {Climbing robots, Power transmission line inspection, Review, UAVs, Service robots},
abstract = {Routine inspection of a power transmission line (PTL) system for early fault detection and maintenance is crucial for efficient transmission of electric power to consumers. Unlike the conventional manual inspection methods that are labor intensive, dangerous and expensive, an efficient inspection using robots has been a key research interest for many research institutes around the world. This paper presents a comprehensive review and trends of power transmission line inspection robots (PTLIRs) focusing on the latest research achievements within the years 2008 to 2019. The structure, operation, and limitations of the inspection robots, namely, climbing, flying, and hybrid (climbing-flying) robots are extensively discussed. Although climbing robots provides the most reliable inspection data due to their proximity to the line, landing the robot on the line as well as obstacle avoidance has been challenging. Thus, hybridizing the climbing and the flying robots have proved to be an excellent approach to the robotic PTL inspection. Furthermore, power supply, automatic obstacle detection, and control system which are the main challenges of PTL inspection are presented. Finally, it is has been concluded that challenges such as limited on-board battery capacity, unreliable line fault detection, electromagnetic shielding, de-icing mechanism and advanced control techniques for external wind disturbance would be a promising future research direction for researchers in the field of robotic PTL inspection.}
}
@article{MOORTHY2021996,
title = {Multi-expert visual tracking using hierarchical convolutional feature fusion via contextual information},
journal = {Information Sciences},
volume = {546},
pages = {996-1013},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.09.060},
url = {https://www.sciencedirect.com/science/article/pii/S0020025520309701},
author = {Sathishkumar Moorthy and Young Hoon Joo},
keywords = {Feature fusion, Ensembled trackers, Contextual information, Online learning},
abstract = {In the literature, numerous techniques have proposed to enhance the performance of tracking the visual objects and each method has its own merits and demerits. For instance, the existing tracking methods may lack in performance due to external disturbances that include background clutter, occlusion, and scale variations. In this article, we propose a multi-expert tracking framework that exploits feature fusion and contextual information of the target to improve the tracking accuracy and robustness. Specifically, we constitute an expert group by ensembling the features extracted from deep convolutional neural networks with different properties. Besides, each expert belonging to the constituted group helps to track target in all frames and the best expert with maximum robustness score is selected in each frame. Then, the contextual information of the target is introduced into the correlation filter to improve performance under complex interference. In addition, to further improve efficiency, more experts can be generated by fusing different type of features which leads to more robustness. Moreover, an adaptive model update strategy is introduced into the correlation filter to discriminate the unreliable samples effectively. Finally, extensive experimental results on OTB2013, OTB2015, TempleColor128 and UAVDT datasets demonstrate that the proposed method performs favourably against state-of-the-art methods.}
}
@article{LI2020107419,
title = {Visual tracking by dynamic matching-classification network switching},
journal = {Pattern Recognition},
volume = {107},
pages = {107419},
year = {2020},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107419},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320302223},
author = {Peixia Li and Boyu Chen and Dong Wang and Huchuan Lu},
keywords = {Visual Tracking, Deep Learning, Ensemble learning},
abstract = {Existing deep trackers can be roughly divided into either matching-based or classification-based methods. The formers are fast but not very robust; while the latter ones introduce more discriminative information but often very slow. In this work, we present a novel real-time robust tracking method to take full use of the benefits from both kinds of networks. First, we propose a matching-classification network switching (MCS) framework to integrate the matching, classification, verification networks and conduct dynamic switching among them. Second, to speed up online update, we devlop a meta learning method as a critical component in our classification network. The meta classifier is trained offline to obtain general discriminative ability and updated online to the current frame just through one iteration. Extensive experiments are conducted on two popular benchmark datasets. Both qualitative and quantitative evaluations show that our tracker performs favorably against other state-of-the-art trackers with real-time performance.}
}
@article{HOSSAIN2020105953,
title = {A reliable data-driven model for Ablative Pulsed Plasma Thruster},
journal = {Aerospace Science and Technology},
volume = {105},
pages = {105953},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.105953},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820306350},
author = {Noman Hossain and Ningfei Wang and Guorui Sun and Hang Li and Zhiwen Wu},
keywords = {Ablative Pulsed Plasma Thruster, Data-driven model, Machine learning, Electric propulsion, Space propulsion},
abstract = {Ablative Pulsed Plasma Thrusters (APPTs) are high specific impulse electric space propulsion system, but a reliable model equivalent of the experimental model is still unavailable. In this paper, a reliable model is developed based on APPT experimental data by using Machine Learning (ML) ecosystem. The goals of this study are to justify the accuracy and reliability of the newly built APPT model with the existing experimental and simulation model. For four sets of operating conditions, 600 experimental and simulation test operations are done. The experimental voltages and currents are measured with a high-voltage probe and a Rogowski coil, respectively. The simulation voltages and currents are gathered by running the respective simulation program. Comparison results show that the newly built APPT model has better accuracy and reliability than the simulated APPT model as compared to real APPT used in the experiment. This data-driven approach provides a novel way of designing a reliable alternative model of physical APPTs.}
}
@article{SHAHRIAR20141236,
title = {A Dynamic Data-driven Decision Support for Aquaculture Farm Closure},
journal = {Procedia Computer Science},
volume = {29},
pages = {1236-1245},
year = {2014},
note = {2014 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.05.111},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914002889},
author = {Md. Sumon Shahriar and John McCulluch},
keywords = {Aquaculture decision support, Machine learning, Dynamic data-driven decision support},
abstract = {We present a dynamic data-driven decision support for aquaculture farm closure. In decision support, we use machine learning techniques in predicting closures of a shellfish farm. As environmental time series are used in closure, we propose two approaches using time series and machine learning for closure prediction. In one approach, we consider time series prediction and then using expert rules to predict closure. In other approach, we use time series classification for closure prediction. Both approaches exploit a dynamic data-driven technique where prediction models are updated with the update of new data to predict closure decisions. Experimental results at a case study shellfish farm validate the applicability of the proposed method in aquaculture decision support.}
}
@article{BABAEI2019361,
title = {Adaptive super-twisting sliding mode control of 6-DOF nonlinear and uncertain air vehicle},
journal = {Aerospace Science and Technology},
volume = {84},
pages = {361-374},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2018.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S1270963818312446},
author = {Ali-Reza Babaei and Maryam Malekzadeh and Davood Madhkhan},
keywords = {6DOF nonlinear model, Decoupled flight dynamics, Adaptive sliding mode control, Adaptive super-twisting algorithm, Uncertainties, Separation mechanism},
abstract = {In this paper, to control the six degree-of-freedom non-linear unmanned aerial vehicle, two strategies are implemented using adaptive super-twisting sliding mode control approach. The first one is a single-channel controller that is designed on the basis of decoupled equations of motion. The other one is a three-channel controller that is designed based on the coupling equations of motion along with an adaptive super-twisting observer. The stability of the closed loop system of the controller-observer is proven. The comparison between the single-channel controller and the three-channel could lead us to select between a little lower efficiency and less complexity versus efficiency and more complexity. To examine the performance and robustness of these two control loops, their performances are analyzed in the presence of combined uncertainties, including aerodynamics, mass, inertial moment, sensor, and actuator disturbances and parametric uncertainties in the stage separation phase. The explosive bolt separation mechanism is assumed to perform the stage separation, and its forces, moments and disturbances are modeled as needed. Finally, the responses are compared with the classic PID controller.}
}
@article{HUANG2021107757,
title = {Contrast-weighted dictionary learning based saliency detection for VHR optical remote sensing images},
journal = {Pattern Recognition},
volume = {113},
pages = {107757},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107757},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320305604},
author = {Zhou Huang and Huai-Xin Chen and Tao Zhou and Yun-Zhi Yang and Chang-Yin Wang and Bi-Yuan Liu},
keywords = {Contrast-weighted dictionary, Dictionary learning, Gradient optimization, Remote sensing, Saliency detection},
abstract = {Object detection in very high resolution (VHR) optical remote sensing (RS) images is one of the most fundamental but challenging tasks in the field of RS image analysis. To reduce the computational complexity of redundant information and improve the efficiency of image processing, visual saliency models have been widely applied in this field. In this paper, a novel saliency detection model based on Contrast-weighted Dictionary Learning (CDL) is proposed for VHR optical RS images. Specifically, the proposed CDL learns salient and non-salient atoms from positive and negative samples to construct a discriminant dictionary, in which a contrast-weighted term is proposed to encourage the contrast-weighted patterns to be present in the learned salient dictionary while discouraging them from being present in the non-salient dictionary. Then, we measure the saliency by combining the coefficients of the sparse representation (SR) and reconstruction errors. Furthermore, by using the proposed joint saliency measure, a variety of saliency maps are generated based on the discriminant dictionary. Finally, a fusion method based on global gradient optimization is proposed to integrate multiple saliency maps. Experimental results on four datasets demonstrate that the proposed model outperforms other state-of-the-art methods.}
}
@article{TZELEPI2021115132,
title = {Online Subclass Knowledge Distillation},
journal = {Expert Systems with Applications},
volume = {181},
pages = {115132},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115132},
url = {https://www.sciencedirect.com/science/article/pii/S095741742100573X},
author = {Maria Tzelepi and Nikolaos Passalis and Anastasios Tefas},
keywords = {Knowledge distillation, Online distillation, Subclass knowledge distillation, Self distillation, Deep neural networks},
abstract = {Knowledge Distillation has been established as a highly promising approach for training compact and faster models by transferring knowledge from more heavyweight and powerful models, so as to satisfy the computation and storage requirements of deploying state-of-the-art deep neural models on embedded systems. However, conventional knowledge distillation requires multiple stages of training rendering it a computationally and memory demanding procedure. In this paper, a novel single-stage self knowledge distillation method is proposed, namely Online Subclass Knowledge Distillation (OSKD), that aims at revealing the similarities inside classes, improving the performance of any deep neural model in an online manner. Hence, as opposed to existing online distillation methods, we are able to acquire further knowledge from the model itself, without building multiple identical models or using multiple models to teach each other, rendering the OSKD approach more effective. The experimental evaluation on five datasets indicates that the proposed method enhances the classification performance, while comparison results against existing online distillation methods validate the superiority of the proposed method.}
}
@article{HE202260,
title = {Learning object-uncertainty policy for visual tracking},
journal = {Information Sciences},
volume = {582},
pages = {60-72},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521009233},
author = {Xuedong He and Calvin Yu-Chian Chen},
keywords = {Visual tracking, Deep learning, Discriminative correlation filter, Template matching, Object uncertainty policy},
abstract = {In research, we found that the purpose of most trackers is to obtain an accurate and robust score map, neglecting how to further examine the confidence of the results. Inspired by the Siamese trackers, which merely use the template from the first frame to locate the target, we propose a novel object-uncertainty policy. Firstly, we propose a dynamic design of the target template set for the tracked target, considering the initial target template and the reliable target template of the subsequent frames concurrently. Secondly, we adopt the multi-layer fusion to represent the target while analyzing the fusion of various feature layers. Moreover, we use a more effective cosine similarity function to calculate the similarity instead of the correlation operation. Finally, we propose a novel voting mechanism in accordance with the similarity between the target tracked in subsequent frames and the target template set. More importantly, this method can be embedded into DCF-like methods to improve tracking performance, which is embedded into the recent DiMP and PrDiMP trackers separately for comparison. Extensive experiments demonstrate that the discriminative ability of the model can be enhanced effectively by using our proposed method, capable of preventing the model from learning the background information. The code and raw tracking results are available at https://github.com/hexdjx/OUPT.}
}
@article{LV2021102407,
title = {Modeling of winter wheat fAPAR by integrating Unmanned Aircraft Vehicle-based optical, structural and thermal measurement},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {102},
pages = {102407},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102407},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421001148},
author = {Zhengang Lv and Ran Meng and Jianguo Man and Linglin Zeng and Meiyv Wang and Binyuan Xu and Renjie Gao and Rui Sun and Feng Zhao},
keywords = {Winter wheat, fAPAR, Saturation problem, Multi-source remote sensing fusion, Machine learning, Smart agriculture, UAV},
abstract = {The fraction of absorbed photosynthetically active radiation (fAPAR) is a critical biophysical parameter for crop growth monitoring and yield estimation. Remote sensing provides an efficient way for measuring fAPAR over large areas, compared with the time-consuming and labor-intensive field measurements. However, the optical remote sensing signals usually saturate over dense vegetation (e.g., Leaf Area Index (LAI) > 5 or fAPAR > 0.7), limiting the performance of optical remote sensing in modeling fAPAR. Multi-source remote sensing data fusion has proven to be a feasible method to overcome the saturation problem of optical remote sensing in vegetation monitoring, but little is known about the performance of optical, structural and thermal features fusion for modeling winter wheat fAPAR. Also, the modeling powers of optical, structural, and thermal features for fAPAR estimation have seldom been compared. To fill in these knowledge gaps, the very high spatial resolution RGB-optical and thermal imagery collected by Unmanned Aircraft Vehicle (UAV) were used to quantify the powers of RGB-derived vegetation indices (VIs), Structural Indices (SIs, crop height/canopy cover), and Canopy Temperature (CT) and their combinations in modeling winter wheat fAPAR in this study. The modeling powers of different remote sensing features were compared with the commonly used hyperspectral vegetation indices (HVIs) from field spectrometer measurements. Results showed that (1) multi-source data fusion that integrates optical, structural, and thermal features provided the best model in winter wheat fAPAR mapping (R2 = 0.907 and RMSE = 0.041) ; (2) the RGB imagery-derived optical (i.e., RGB VIs) and structural features (i.e., RGB SIs) were important preditors for winter wheat fAPAR modeling, and their combination can steadily improve the modeling accuracy (~2% improvement in R2 compared to optical-only model); (3) the thermal feature alone performed the worst among all experiments, but it still can complement other types of remote sensing features (i.e., RGB VIs&SIs) and further improve the modeling accuracy within the framework of data fusion (~3% improvement in R2 compared to optical-only model). In general, this study indicates that the framework of multi-source remote sensing data fusion can provide more accurate, efficient measurements of winter wheat fAPAR for crop management in precision agriculture, which can help improve resource utilization efficiency (e.g., determine where and when to apply nitrogen fertilizer) and ensure food security in the face of climate change.}
}
@article{VEETTIL2020106560,
title = {Opportunities for seagrass research derived from remote sensing: A review of current methods},
journal = {Ecological Indicators},
volume = {117},
pages = {106560},
year = {2020},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2020.106560},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X20304970},
author = {Bijeesh Kozhikkodan Veettil and Raymond D. Ward and Mariana Do Amaral Camara Lima and Milica Stankovic and Pham Ngoc Hoai and Ngo Xuan Quang},
keywords = {Submerged marine vegetation, Coastal ecosystems, Marine environment, Coastal management},
abstract = {Seagrass communities provide critical ecosystem and provisioning services for both human populations and a wide range of associated species globally. However, it has been reported that seagrass area is decreasing at a rapid rate in many parts of the world, mostly due to anthropogenic activities including global change (pollution and climate change). The aim of this review article is to highlight the range of current tools for studying seagrasses as well as identify the benefits and limitations of a range of remote sensing and traditional methodologies. This paper provides a discussion of the ecological importance of seagrass meadows, and recent trends and developments in seagrass research methods are discussed including the use of satellite images and aerial photographs for seagrass monitoring and various image processing steps that are frequently utilised for seagrass mapping. The extensive use of various optical, Radar and LiDAR data for seagrass research in recent years has also been described in detail. The review concludes that the recent explosion of new methods and tools available from a wide range of platforms combined with the recent recognition of the importance of seagrasses provides the research community with an excellent opportunity to undertake a range of timely research. This research should include mapping the extent and distribution of seagrasses, identifying the drivers of change and factors that confer resilience, as well as quantification of the ecosystem services provided. Whilst remotely sensed data provides an important new tool it should be used in conjunction with traditional methods for validation and with a knowledge of the limitations of results and careful interpretation.}
}
@article{KAHRAMAN2021236,
title = {A comprehensive review of hyperspectral data fusion with lidar and sar data},
journal = {Annual Reviews in Control},
volume = {51},
pages = {236-253},
year = {2021},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2021.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S1367578821000110},
author = {Sevcan Kahraman and Raphael Bacher},
keywords = {hyperspectral (HS) image, Light Detection And Ranging (LiDAR), Synthetic Aperture Radar (SAR), multi-modal data fusion, review},
abstract = {With the development of remote sensing techniques, the fusion of multimodal data, particularly hyperspectral-Light Detection And Ranging (HS-LiDAR) and hyperspectral-SAR, has become an important research field in numerous application areas. Multispectral, HS, LiDAR, and Synthetic Aperture Radar (SAR) images contain detailed information about the monitored surface that are complementary to each other. Thus, data fusion methods have become a promising solution to obtain high spatial resolution remote-sensing images. The main point of this review paper is to classify hyperspectral-LiDAR and hyperspectral-SAR data fusion with approaches. Moreover, recent achievements in the fusion of hyperspectral-LiDAR and hyperspectral-SAR data are highlighted in terms of faced challenges and applications. Most frequently used data fusion datasets that include IEEE GRSS Data Fusion Contests are also described.}
}
@article{PATRICK2021777,
title = {Collision Avoidance Using Spherical Harmonics⁎⁎This research has been supported in part by NSF award ECCS-1924790.},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {20},
pages = {777-782},
year = {2021},
note = {Modeling, Estimation and Control Conference MECC 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.11.266},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321023107},
author = {Steven D. Patrick and Efstathios Bakolas},
keywords = {Collision avoidance, path planning, spherical harmonics},
abstract = {In this paper, we propose a novel optimization-based trajectory planner that utilizes spherical harmonics to estimate the collision-free solution space around an agent. The space is estimated using a constrained over-determined least-squares estimator to determine the parameters that define a spherical harmonic approximation at a given time step. Since spherical harmonics produce star-convex shapes, the planner can consider all paths that are in line-of-sight for the agent within a given radius. This contrasts with other state-of-the-art planners that generate trajectories by estimating obstacle boundaries with rough approximations and using heuristic rules to prune a solution space into one that can be easily explored. Those methods cause the trajectory planner to be overly conservative in environments where an agent must get close to obstacles to accomplish a goal. Our method is shown to perform on-par with other path planners and surpass these planners in certain environments. It generates feasible trajectories while still running in real-time and guaranteeing safety when a valid solution exists.}
}
@article{CONTIU2016269,
title = {Improving remote sensing crop classification by argumentation-based conflict resolution in ensemble learning},
journal = {Expert Systems with Applications},
volume = {64},
pages = {269-286},
year = {2016},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2016.07.037},
url = {https://www.sciencedirect.com/science/article/pii/S0957417416303840},
author = {Ştefan Conţiu and Adrian Groza},
keywords = {Crop classification, Ensemble learning, Defeasible argumentation, Agricultural expert knowledge, Rule extraction},
abstract = {The acquisition of data through remote sensing has become of great importance in precision agriculture, as it covers large geographical areas faster and cheaper than ground inspections. The challenge is to develop technical solutions that can benefit from both huge amounts of raw data extracted from satellite images, but also from the robust amount of knowledge refined during centuries of agricultural practice. Aiming to accurately classify crops from satellite images, we developed a hybrid intelligent system that can exploit both agricultural expert knowledge and machine learning algorithms. As the crop raw data is characterized by heterogeneity, we drive our attention to ensemble learners, while expert knowledge is encapsulated within a rule-based system. Vote-based methods for solving conflicts between ensemble’s base learners have difficulties in classifying exceptional cases correctly and also to give the rationale behind their decision. The conceptual research question is on conflict resolution in ensemble learning. To deal with debatable cases in ensemble learning and to increase transparency in such debatable decisions, our hypothesis is that argumentation could be more effective than voting-based methods. The main contribution is that voting system in ensemble learning is substituted by an argumentation-base conflict resolutor. Prospective decisions of base classifiers are presented to an argumentative system based on defeasible logic that performs dialectical reasoning on pros and cons against a classification decision. The system computes a recommendation considering both the rules extracted from base learners and the available expert knowledge. The investigated case study deals with crop classification into four classes: corn, soybean, cotton, and rice. The test site used for the experiment is an area of 20 square kilometers in the New Madrid County, southeast of the Missouri State, USA. The results show that our approach increases classification accuracy compared to the voting-based method for conflict resolution in an ensemble learner comprising of three base classifiers: a decision tree, a neural network, and a support vector machine algorithm. We also argue that combining ensemble learning and argumentation fits the decision patterns of human agents, who first collect various opinions and then perform dialectical reasoning on these opinions. We think that the people who can benefit from the conceptual instrumentation presented in this work are decision makers in domains characterized by high data availability, robust expert knowledge, and a need for justifying the rationale behind decisions.}
}
@article{CHAIREZ2014118,
title = {Multiple DNN identifier for uncertain nonlinear systems based on Takagi–Sugeno inference},
journal = {Fuzzy Sets and Systems},
volume = {237},
pages = {118-135},
year = {2014},
note = {Theme : Data Analysis and Fuzzy Models},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2013.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0165011413001905},
author = {I. Chairez},
keywords = {Differential neural networks, Takagi–Sugeno inference, Non-parametric identifier, Neural–fuzzy systems, Chen circuit, Rabinovich–Fabrikant system},
abstract = {In nature, most systems show nonlinear complex behaviors. Among other characteristics, plants present a high degree of oscillation over time. Adaptive algorithms used to approximate such difficult behaviors show some important deficiencies. Many adaptive non-parametric methods cannot reconstruct the trajectories of such complex dynamics. Differential neural networks (DNNs) are no exception. When just one DNN is applied to achieve an approximation, the identification error may significantly differ from zero. A natural trick to overcome this difficulty is to increase the number of neurons or to increase the number of layers. Another possible suggestion is to define a set of neural networks working together (usually in parallel). The members of such a set each work on well-defined trajectories contained in specific subspaces in which the uncertain system may evolve. Nevertheless, a decision system is required to define the contribution of each DNN in the final identification scheme. One of the most successful methodologies for constructing this selector is based on a Takagi–Sugeno (TS) inference system. This paper discusses how to combine the identification properties offered by a continuous neural network and the characteristic decision capabilities of fuzzy methods. The selection of which neural network is activated depends on the decision achieved by a TS fuzzy system. The convergence of this algorithm is proved using a quadratic Lyapunov function. A complete description of the learning laws used for the set of DNN identifiers is also obtained. The Chen circuit and the Rabinovich–Fabrikant system are used to demonstrate the superior performance achieved by this mixed DNN and fuzzy system, usually called a neuro-fuzzy system.}
}
@article{MANAVALAN2020105802,
title = {Automatic identification of diseases in grains crops through computational approaches: A review},
journal = {Computers and Electronics in Agriculture},
volume = {178},
pages = {105802},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105802},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920316379},
author = {R. Manavalan},
keywords = {Grains, Plant disease, Image processing, Segmentation, Classification},
abstract = {Agricultural productivity significantly contributes to every country's economy. The grain plants such as wheat, rice, corn (maize), barley, oats, rye, millet, and sorghum are commonly grown across the world. The pest and various diseases in the grain plants severely affect major production and cause heavy losses in the global economy. Monitoring of health and early diagnosing of diseases in grains plants is a critical task for sustainable agriculture. The information on early diagnosis of several diseases can facilitate the control of diseases through proper selection of pest control techniques to improve the grains productivity. The manual identification of the disorders in grains plants can lead to inaccurate measurements of pesticides. While several papers on grain diseases identification through intelligent techniques have been published in recent years, there has been no clear attempt to study these papers systematically to describe various phases of diagnosis system such as image preprocessing, segmentation, feature extraction, features selection, and classification methods. In this context, a total of 109 peer-reviewed articles reporting to identify the diseases at the early stage to increase the production of the five most-produced grains in the world such as maize, rice, wheat, soybean, and barley are reviewed, ranging in publication date from 2001 to 2020. The article also presents a detailed taxonomy of grain plant leaf diseases. The study found that there are still many issues that’s need to be addressed in each phase of the automated disease detection system. The pros and cons of reviewed computational method is explored and future directions are highlighted. The survey outcomes reveal that the existing automated detection and classification methods for grain plants diseases is still infancy. Hence novel fully automated tools are necessary for the process of detection and classification diseases in grain plants.}
}
@article{WU202123,
title = {Disturbance-observer-based adaptive NN control for a class of MIMO discrete-time nonlinear strict-feedback systems with dead zone},
journal = {Neurocomputing},
volume = {446},
pages = {23-31},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.02.077},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221003349},
author = {Bei Wu and Mou Chen and Shuyi Shao and Luo Zhang},
keywords = {Discrete-time nonlinear system, Tracking control, Adaptive neural network control, Disturbance observer},
abstract = {In this paper, based on a disturbance observer (DO), an adaptive neural network (ANN) tracking control scheme is proposed for the multi-input and multi-output (MIMO) strict-feedback discrete-time system (SFDTS). The unknown nonlinear functions, dead-zone input and external disturbance are all considered in the studied SFDTS. Before starting to design the controller, the MIMO SFDTS is transformed into a maximum N-step ahead predictor to solve the noncausal problem. Then, the backstepping method is successfully used to design the control scheme for the new system. The unknown nonlinear functions are approximated by radial basis function neural networks. The external disturbance is estimated based on the DO, and the ANN controller is designed on the basis of the outputs of the DO. By applying the Lyapunov stability theory, all the signals in the whole closed-loop system are ensured bounded. Finally, a numerical simulation is provided to verify the validity of the proposed control scheme.}
}
@article{OYEKAN2016679,
title = {Tracking and Sensor Coverage of Spatio-temporal Quantities Using a Swarm of Artificial Foraging Agents},
journal = {Journal of Bionic Engineering},
volume = {13},
number = {4},
pages = {679-689},
year = {2016},
issn = {1672-6529},
doi = {https://doi.org/10.1016/S1672-6529(16)60339-6},
url = {https://www.sciencedirect.com/science/article/pii/S1672652916603396},
author = {John Oluwagbemiga Oyekan and Dongbing Gu and Huosheng Hu},
keywords = {bioinspired algorithm, artificial foraging swarm, spatio-temporal mapping, bacterium},
abstract = {Using a network of mobile sensors to track and map a dynamic spatio-temporal process in the environment is one of the current challenges in multi-agent systems. In this work, a distributed probabilistic multi-agent algorithm inspired by the bacterium foraging behavior is presented. The novelty of the algorithm lies in being capable of tracking and mapping a spatio-temporal quantity without the need of machine learning, estimation algorithms or future planning. This is unlike most current techniques that rely heavily on machine learning to estimate the distribution as well as the profile of spatio-temporal quantities. The experimental studies carried out in this work show that the algorithm works well by following the concentration gradient of a dynamic plume created under diffusive conditions. Furthermore, the algorithm is inherently capable of finding the source of a diffusive spatio-temporal quantity as well as performing environmental exploration. It is computationally tractable for simple agents, shown to adapt to its environment and can deal successfully with noise in sensor readings as well as in robot dynamics.}
}
@article{ZHAO2022116634,
title = {Robust power line extraction from aerial image using object-based Gaussian-Markov random field with gravity property parameters},
journal = {Signal Processing: Image Communication},
pages = {116634},
year = {2022},
issn = {0923-5965},
doi = {https://doi.org/10.1016/j.image.2022.116634},
url = {https://www.sciencedirect.com/science/article/pii/S0923596522000017},
author = {Le Zhao and Hongtai Yao and Meng Tian and Xianpei Wang},
keywords = {Aerial image, Power line extraction, Object-based Markov random field, Gaussian-Markov model, Gravity property model},
abstract = {The extraction of power line from aerial image with complex background is an extremely difficult task. In order to solve the drawbacks of low accuracy and insufficient stability of extraction algorithms, a novel object-based Gaussian-Markov random field with gravity property parameters (OGMRF-GPP) method is proposed. First of all, the OGMRF-GPP method extends the Gaussian-Markov model to a contactless and irregular neighborhood system. Secondly, the OGMRF-GPP method constructs a gravity property model by introducing multi-dimensional spatial correlations between line segments. The gravity property model can not only realize the high-precision adaptive estimation of the parameters of the linear regression equation, but also simplify the parameter estimation process. Finally, the power line segments extracted by OGMRF-GPP method can be fitted effectively. Experimental results show that the proposed method can extract power lines in a variety of scenes with higher accuracy compared with several other methods.}
}
@article{LIU2020105621,
title = {Hyperspectral imaging and 3D technologies for plant phenotyping: From satellite to close-range sensing},
journal = {Computers and Electronics in Agriculture},
volume = {175},
pages = {105621},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105621},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919318848},
author = {Huajian Liu and Brooke Bruning and Trevor Garnett and Bettina Berger},
keywords = {Plant phenotyping, Hyperspectral imaging, 3D sensing, Remote sensing, Sensor fusion},
abstract = {High-throughput phenotyping technologies in controlled environments or field conditions have proven to be extremely useful in unravelling key quantitative traits of plants for breeding. Among many plant phenotyping methods, hyperspectral imaging (HSI) and three-dimensional (3D) sensing are the fastest growing and promising approaches for measuring multiple plant parameters. There are many types of HSI and 3D sensors available with each being designed for a specific purpose. Also, the same sensor could be set up and calibrated in different ways to measure different plant parameters on various platforms. This review aims to guide the use of HSI and 3D sensing technologies for plant phenotyping. It first introduces the preliminary knowledge of HSI and 3D sensing for plant phenotyping. In addition, it provides the detail of plant phenotyping using different HSI and 3D sensors on various platforms with different scales. Lastly, the problems and challenges of close-range HSI and 3D modelling of plants are discussed and potential solutions are suggested.}
}
@article{DORA2015255,
title = {A sequential learning algorithm for a spiking neural classifier},
journal = {Applied Soft Computing},
volume = {36},
pages = {255-268},
year = {2015},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2015.06.062},
url = {https://www.sciencedirect.com/science/article/pii/S156849461500455X},
author = {S. Dora and S. Suresh and N. Sundararajan},
keywords = {Spiking neural network, Sequential learning, Pattern classification, 2-Dimensional coding},
abstract = {This paper presents a biologically inspired, sequential learning spiking neural classifier (SLSNC) for pattern classification problems. It consists of a two layered neural network and a separate decision block which estimates the predicted class label. Inspired by observations in the neuroscience literature, the input layer employs a new neuron model which converts real valued stimuli into spikes with varying amplitudes and firing times. The intermediate layer neurons are modeled as integrate-and-fire spiking neurons. The decision block identifies that intermediate neuron which fires first and returns the class label associated with that neuron as the predicted class label. The sequential learning algorithm for the spiking neural network automatically determines the network structure from the training samples and adapts its synaptic weights by long term potentiation and long term depression. Performance of SLSNC has been evaluated using a number of benchmark classification problems and the results have been compared with other well-known spiking neural network classifiers in the literature as well as with the standard support vector machine (SVM) with a Gaussian kernel and the fast learning Extreme Learning Machine (ELM) classifiers. The results clearly indicate that the described spiking neural network produces similar or better generalization performance with a smaller network.}
}
@article{KHANNA2020101,
title = {Local Mutual Exclusion algorithm using fuzzy logic for Flying Ad hoc Networks},
journal = {Computer Communications},
volume = {156},
pages = {101-111},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.03.036},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419307856},
author = {Ashish Khanna and Joel J.P.C. Rodrigues and Naman Gupta and Abhishek Swaroop and Deepak Gupta},
keywords = {Resource allocation problem, Local Mutual Exclusion, Leader election, Dynamic topology},
abstract = {The Local Mutual Exclusion (LME) problem is a variant of classical Mutual Exclusion (ME) problem and can be considered as an extension of dining philosopher problem. In LME, no two neighboring nodes can enter the critical section (CS) simultaneously, whereas two non-neighboring nodes can be in their CS simultaneously. The resource allocation problem in Flying Ad hoc Networks (FANETs), is relatively an unexplored area despite having several potential applications. The present paper proposes LME problem for FANETs and provides a leader-based algorithm named as Request Collector Local Mutual Exclusion (RCLME) for the same. To the best of our information, LME problem is introduced first time in Flying Ad hoc Networks. The striking feature of the proposed algorithm is the introduction of a fuzzy logic-based leader election that considers the node speed, node direction, link quality, and the distance from the resource. The correctness proof of the RCLME algorithm has been presented. The simulation results show that RCLME algorithm significantly outperforms other related algorithms available in the literature; specially, when the number of nodes is large. The use of fuzzy logic and request collector improves the efficiency, fault tolerating capacity and ability to handle volatility.}
}
@article{KUMAR2018585,
title = {On the technologies empowering drones for intelligent monitoring of solar photovoltaic power plants},
journal = {Procedia Computer Science},
volume = {133},
pages = {585-593},
year = {2018},
note = {International Conference on Robotics and Smart Manufacturing (RoSMa2018)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.07.087},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918310366},
author = {Nallapaneni Manoj Kumar and K. Sudhakar and M. Samykano and V. Jayaseelan},
keywords = {Drones, solar power plants, monitoring of solar plants, drones in the solar industry, intelligent drones, autonomous drones},
abstract = {Monitoring of solar photovoltaic power plants is an essential task that could enable efficient operation and maintenance. Active control and regular maintenance will enhance the photovoltaic plant's output performance and helps in reasonable or better returns on the investments made. The process of monitoring is done by conducting manual inspections, but due to technological advancements, the manual checks were replaced by intelligent systems, centralized control, and monitoring systems, surveillance cameras, robotics, drones, etc. Drones are becoming more suitable for the solar industry due to a wide range of surveillance capability, long range inspection, efficient data logging capability, easy to control and access from the central level, etc. In this paper, the role of drones in solar photovoltaic power plants, and scope for enabling intelligence and automation in drones for the active monitoring and data logging is discussed. Various types drones and their configurations along with the dynamics are also considered. A study on the technologies behind the drone intelligence and automation were identified and discussed. From this study, it was found that Recognition Technologies (RT), Artificial Intelligence (AI), and Machine Learning (ML) could empower the drones and make the monitoring of large-scale solar power plants easier. This study could help the developers and researcher who are working on intelligent drones for specialist care of massive solar parks, unaccessible remote solar plants, etc.}
}
@article{XIE2019106542,
title = {Ship predictive collision avoidance method based on an improved beetle antennae search algorithm},
journal = {Ocean Engineering},
volume = {192},
pages = {106542},
year = {2019},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2019.106542},
url = {https://www.sciencedirect.com/science/article/pii/S0029801819306766},
author = {Shuo Xie and Xiumin Chu and Mao Zheng and Chenguang Liu},
keywords = {Collision avoidance, Ship dynamic model, COLREGs, Predictive control, Beetle antennae search},
abstract = {To enhance the real-time performance and reliability of existing ship collision avoidance methods by collision risk prediction, a predictive collision avoidance method based on an improved beetle antennae search (BAS) algorithm for underactuated surface vessels is proposed. Firstly, a simplified 3-DOF hydrodynamic model based on Abkowitz model is proposed, which provides a model basis for real-time prediction of ship states and collision risks. Referring to the idea of model predictive control (MPC), a predictive optimization strategy for real-time collision avoidance is established by minimizing the safety cost and the economic cost, i.e., collision risk and control changes at the same time. Specifically, the proposed simplified 3-DOF model is used as the state predictive model and the International Regulations for Preventing Collisions at Sea (COLREGs) is considered as the control constraints. To solve the optimization problem, an improved BAS algorithm is proposed to enhance the optimization performance of the original BAS algorithm under the known constraints, which is applied to solve the predictive collision avoidance problem. Simulation experiments under several typical encounter scenarios are carried out based on KVLCC2 ship model, and the effectiveness of the improved BAS based predictive collision avoidance method is verified.}
}
@article{HUANG201931,
title = {Empirical curvelet based fully convolutional network for supervised texture image segmentation},
journal = {Neurocomputing},
volume = {349},
pages = {31-43},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219305454},
author = {Yuan Huang and Fugen Zhou and Jérôme Gilles},
keywords = {Texture segmentation/classification, Empirical wavelet transform, Fully convolutional network, Supervised learning},
abstract = {In this paper, we propose a new approach to perform supervised texture classification/segmentation. The proposed idea is to feed a Fully Convolutional Network with specific texture descriptors. These texture features are extracted from images by using an empirical curvelet transform. We propose a method to build a unique empirical curvelet filter bank adapted to a given dictionary of textures. We then show that the output of these filters can be used to build efficient texture descriptors utilized to finally feed deep learning networks. Our approach is finally evaluated on several datasets and compare the results to various state-of-the-art algorithms and show that the proposed method dramatically outperform all existing ones.}
}
@article{AHMED2021,
title = {Development of smart quadcopter for autonomous overhead power transmission line inspections},
journal = {Materials Today: Proceedings},
year = {2021},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.05.271},
url = {https://www.sciencedirect.com/science/article/pii/S2214785321038645},
author = {MD. Faiyaz Ahmed and J.C. Mohanta and Mohd. Nayab Zafar},
keywords = {Autonomous, Quadcopter, GPS, Thermal camera, Overhead power transmission lines},
abstract = {To meet the electricity demand, the power grid needs to be extended and improved due to increasing global energy requirement, population growth, access to better living standards, and increasing industrial output. To ensure an efficient & uninterrupted power supply proper maintenance and operations of overhead power transmission lines are required. This manuscript outlines the development and fabrication of an autonomous quadcopter for the application of overhead power line inspection. It can hover in denied environments with advanced components and sensors like Global Positioning System (GPS), Hex HereFlow, and motion capture cameras to localize itself or attain self-stability/altitude lock. The process of fabricating the quadcopter includes the usage of low-cost frame and electronic components with the best quality. Following preset criteria, an S500 frame was modified as a quadcopter with a smart controller like Pixhawk 2.1 orange cube with Here2 Global Navigation Satellite System (GNSS), an NVIDIA Nano TK1 developer board and FLIR Vue Pro thermal camera for localization and processing the data from onboard sensors and cameras.}
}
@article{ZHOU2021110751,
title = {A piezoelectric sensing neuron and resonance synchronization between auditory neurons under stimulus},
journal = {Chaos, Solitons & Fractals},
volume = {145},
pages = {110751},
year = {2021},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2021.110751},
url = {https://www.sciencedirect.com/science/article/pii/S0960077921001041},
author = {Ping Zhou and Zhao Yao and Jun Ma and Zhigang Zhu},
keywords = {Neuron, Piezoelectric ceramic, Synchronization, Noise},
abstract = {A piezoelectric ceramic can convert external mechanical force and vibration into electric signals by producing distinct output voltage when certain deformation is induced. As a result, a piezoelectric ceramic in nonlinear circuit can be used as sensitive sensor for detecting external sound signals. In this paper, a piezoelectric ceramic is incorporated into a simple FithzHugh–Nagumo neural circuit for capturing and encoding external sound signals. The improved neural circuit and functional neuron models are obtained, and a variety of firing modes are reproduced in the neural activities by changing the external sound signals. For animals, two ears can receive and encode the external sound signals synchronously in effective way, and thus the synchronization between two auditory neurons. To explore the capacity of discernment and cooperation of two ears in the auditory system when external voice is applied, two piezoelectric sensing neurons (PSNs) are driven by the same external voice for detecting possible synchronization approach without any synapse coupling. It is found that two identical PSNs driven by the same periodical stimuli (external forces) can reach synchronous bursting, spiking, and periodical firings, respectively. In case of chaotic firing, the synchronization stability is dependent on the external forcing applied on the two PSNs. Furthermore, external additive noise is applied for considering stochastic forcing on the PSN, it is confirmed that two identical PSNs can reach kinds of synchronous firings, while some intermediate noise intensities seldom enhance the synchronization stability between two identical PSNs. The Hamilton energy in isolated PSN driven by external forcing is estimated, and this kind of non-coupling synchronization is explained as a kind of resonance synchronization. These results can be helpful to design functional auxiliary devices for those patients with hearing impairment.}
}
@article{YANG2020187,
title = {Crop Phenomics and High-Throughput Phenotyping: Past Decades, Current Challenges, and Future Perspectives},
journal = {Molecular Plant},
volume = {13},
number = {2},
pages = {187-214},
year = {2020},
issn = {1674-2052},
doi = {https://doi.org/10.1016/j.molp.2020.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1674205220300083},
author = {Wanneng Yang and Hui Feng and Xuehai Zhang and Jian Zhang and John H. Doonan and William David Batchelor and Lizhong Xiong and Jianbing Yan},
keywords = {crop phenomics, high-throughput, field phenotyping, root system architecture, yield and quality, genetic studies},
abstract = {Since whole-genome sequencing of many crops has been achieved, crop functional genomics studies have stepped into the big-data and high-throughput era. However, acquisition of large-scale phenotypic data has become one of the major bottlenecks hindering crop breeding and functional genomics studies. Nevertheless, recent technological advances provide us potential solutions to relieve this bottleneck and to explore advanced methods for large-scale phenotyping data acquisition and processing in the coming years. In this article, we review the major progress on high-throughput phenotyping in controlled environments and field conditions as well as its use for post-harvest yield and quality assessment in the past decades. We then discuss the latest multi-omics research combining high-throughput phenotyping with genetic studies. Finally, we propose some conceptual challenges and provide our perspectives on how to bridge the phenotype–genotype gap. It is no doubt that accurate high-throughput phenotyping will accelerate plant genetic improvements and promote the next green revolution in crop breeding.}
}
@article{BONNEAU2019598,
title = {The use of terrestrial laser scanning for the characterization of a cliff-talus system in the Thompson River Valley, British Columbia, Canada},
journal = {Geomorphology},
volume = {327},
pages = {598-609},
year = {2019},
issn = {0169-555X},
doi = {https://doi.org/10.1016/j.geomorph.2018.11.022},
url = {https://www.sciencedirect.com/science/article/pii/S0169555X18304719},
author = {David A. Bonneau and D. Jean Hutchinson},
keywords = {Talus, Terrestrial laser scanning, Granular flows, Grain size mapping, CANUPO, Machine learning},
abstract = {A postglacial river terrace along the Thompson River in Interior British Columbia, Canada has been monitored using terrestrial laser scanning (TLS) and high-resolution photography for almost a 3-year study to observe the deformation and failure processes, which result in changes in the slope morphology. Change detection using Multiscale Model to Model Cloud Comparison (M3C2) and a multi-scale dimensionality analysis (CANUPO) were performed on the 3-dimensional point cloud data to track the deposition patterns occurring in this active cliff talus system. Changes documented in the analysis of TLS data were verified using the high-resolution photography. Over 1.5 m of valley parallel retreat was captured in a section of the cliff face related to instability of a cobble and boulder horizon beneath a thick fluvial gravel unit. Because of the high-resolution remote sensing data, it was possible to observe a longitudinal sorting of grain sizes (i.e. fall sorting) in this cliff-talus system, whereby the size of individual particles controls the position on the slope. The overall mapped distribution of particle sizes on the slope remained constant for the almost 3-year study period. Flows of granular debris were observed in TLS change detection and the CANUPO analysis was able to display the longitudinal and lateral sorting of grain sizes that occurs during flow. This case history demonstrates that high resolution remote sensing data of large slopes permits us to link the geomorphic processes occurring in the cliff face with mass movement and deposition occurring on the talus slope below.}
}
@article{SUN2014153,
title = {Application of BW-ELM model on traffic sign recognition},
journal = {Neurocomputing},
volume = {128},
pages = {153-159},
year = {2014},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2012.11.057},
url = {https://www.sciencedirect.com/science/article/pii/S0925231213009934},
author = {Zhan-Li Sun and Han Wang and Wai-Shing Lau and Gerald Seet and Danwei Wang},
keywords = {Traffic sign recognition, Extreme learning machine, Histograms of oriented gradient},
abstract = {Traffic sign recognition is an important and active research topic of intelligent transport system. With a constant increasing of the training database size, not only the recognition accuracy, but also the computation complexity should be considered in designing a feasible recognition approach. In this paper, an effective and efficient algorithm based on a relatively new artificial neural network, extreme learning machine (ELM), is proposed for traffic sign recognition. In the proposed algorithm, the locally normalized histograms of the oriented gradient (HOG) descriptors, which are extracted from the traffic sign images, are used as the features and the inputs of the ELM classification model. Moreover, the ratio of feature's between-category to within-category sums of squares (BW) is designed as a feature selection criterion to improve the recognition accuracy and to decrease the computation burden. Application on a well known database, German traffic sign recognition benchmark (GTSRB) dataset, demonstrates the feasibility and efficiency of the proposed BW-ELM model.}
}
@article{BARTA2022119984,
title = {Comparison of field survey and remote sensing techniques for detection of bark beetle-infested trees},
journal = {Forest Ecology and Management},
volume = {506},
pages = {119984},
year = {2022},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2021.119984},
url = {https://www.sciencedirect.com/science/article/pii/S037811272101077X},
author = {Vojtěch Bárta and Jan Hanuš and Lumír Dobrovolný and Lucie Homolová},
keywords = {Bark beetle,  (L.), Hyperspectral remote sensing, Ecological modelling, Norway spruce},
abstract = {Detection in the early phase of bark beetle infestation is a vital task for proactive management strategies, as practiced in most Central European forests, to minimize economic losses due to bark beetle infestation and to mitigate their further spreading. For this work, remote sensing methods are coming to be in great demand as an objective approach to enable monitoring bark beetle infestation even at individual tree level. This case study monitored bark beetle (Ips typographus) activity at local level in Norway spruce forest in the Czech Republic. The main aim of this study was to compare the remote sensing methods against classical field survey conducted by forest workers in detecting newly infested trees. To compare these two methods, an extensive field and aerial campaign was conducted in the southern part of the Czech Republic during 2020. Bark beetle infestation was monitored by traditional methods (i.e. field survey) on a weekly basis from mid-March to mid-September. During the same period, aerial scans were performed once per month (seven in total) using a CASI-1500 hyperspectral sensor (visible and near-infrared, 400–1000 nm) with spatial resolution of 0.5 m. This work mapped transition from healthy up to red attack of 75 Norway spruce trees that were infested during the same week. The same number of healthy trees were added to the data set for hyperspectral data analysis. Both groups were analysed by vegetation indices, with emphasis on effect caused in the canopy by bark beetles. The success rate for bark beetle detection is always associated with acquisition time. In order to define the optimal time for data acquisition, we employed a phenology model for I. typographus (RITY 2.0) to take into consideration bark beetle development. The results of the experiment showed that classic field survey detected infested trees earlier than did analysis using remote sensing data from the visible and near-infrared region. The difference was 23 days for the most successful indices (i.e. REIP, PRI, and ANCB650–720) in our test. Nevertheless, both methods detected the infested trees within 6 weeks after infestation, which is the recommended period for taking measures to prevent bark beetles from spreading further, and thus hyperspectral imagery can be used as a valid information source for bark beetle detection.}
}
@article{LU2019133,
title = {Learning transform-aware attentive network for object tracking},
journal = {Neurocomputing},
volume = {349},
pages = {133-144},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.02.021},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219302358},
author = {Xiankai Lu and Bingbing Ni and Chao Ma and Xiaokang Yang},
keywords = {Transform-aware, Visual attention, Spatial Transformer Networks, Object tracking},
abstract = {Existing trackers often decompose the task of visual tracking into multiple independent components, such as target appearance sampling, classifier learning, and target state inferring. In this paper, we present a transform-aware attentive tracking framework, which uses a deep attentive network to directly predict the target states via spatial transform parameters. During off-line training, the proposed network learns generic motion patterns of target objects from auxiliary large-scale videos. These leaned motion patterns are then applied to track target objects on test sequences. Built on the Spatial Transform Network (STN), the proposed attentive network is fully differentiable and can be trained in an end-to-end manner. Notably, we only fine-tune the pre-trained network in the initial frame. The proposed tracker requires neither online model update nor appearance sampling during the tracking process. Extensive experiments on OTB-2013, OTB-2015, VOT-2014 and UAV-123 datasets demonstrate the competitive performance of our method against state-of-the-art attentive tracking methods.}
}
@article{GONCALVES2019218,
title = {SegOptim—A new R package for optimizing object-based image analyses of high-spatial resolution remotely-sensed data},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {76},
pages = {218-230},
year = {2019},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2018.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S0303243418303556},
author = {João Gonçalves and Isabel Pôças and Bruno Marcos and C.A. Mücher and João P. Honrado},
keywords = {Geographic object-based image analysis, GEOBIA, Image segmentation, Supervised classification, Genetic algorithms, Optimization, High-spatial resolution, Open-source software, R package},
abstract = {Geographic Object-based Image Analysis (GEOBIA) is increasingly used to process high-spatial resolution imagery, with applications ranging from single species detection to habitat and land cover mapping. Image segmentation plays a key role in GEOBIA workflows, allowing to partition images into homogenous and mutually exclusive regions. Nonetheless, segmentation techniques require a robust parameterization to achieve the best results. Frequently, inappropriate parameterization leads to sub-optimal results and difficulties in comparing distinct methods. Here, we present an approach based on Genetic Algorithms (GA) to optimize image segmentation parameters by using the performance scores from object-based classification, thus allowing to assess the adequacy of a segmented image in relation to the classification problem. This approach was implemented in a new R package called SegOptim, in which several segmentation algorithms are interfaced, mostly from open-source software (GRASS GIS, Orfeo Toolbox, RSGISLib, SAGA GIS, TerraLib), but also from proprietary software (ESRI ArcGIS). SegOptim also provides access to several machine-learning classification algorithms currently available in R, including Gradient Boosted Modelling, Support Vector Machines, and Random Forest. We tested our approach using very-high to high spatial resolution images collected from an Unmanned Aerial Vehicle (0.03 – 0.10 m), WorldView-2 (2 m), RapidEye (5 m) and Sentinel-2 (10 – 20 m) in six different test sites located in northern Portugal with varying environmental conditions and for different purposes, including invasive species detection and land cover mapping. The results highlight the added value of our novel comparison of image segmentation and classification algorithms. Overall classification performances (assessed through cross-validation with the Kappa index) ranged from 0.85 to 1.00. Pilot-tests show that our GA-based approach is capable of providing sound results for optimizing the parameters of different segmentation algorithms, with benefits for classification accuracy and for comparison across techniques. We also verified that no particular combination of an image segmentation and a classification algorithm is suited for all the tasks/objectives. Consequently, it is crucial to compare and optimize available methods to understand which one is more suited for a certain objective. Our approach allows a closer integration between the segmentation and classification stages, which is of high importance for GEOBIA workflows. The results from our tests confirm that this integration has benefits for comparing and optimizing both processes. We discuss some limitations of the SegOptim approach (and potential solutions) as well as a future roadmap to expand its current functionalities.}
}
@article{ZHAO2021107837,
title = {An intelligent fuzzy-based routing scheme for software-defined vehicular networks},
journal = {Computer Networks},
volume = {187},
pages = {107837},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.107837},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621000219},
author = {Liang Zhao and Zhenguo Bi and Mingwei Lin and Ammar Hawbani and Junling Shi and Yunchong Guan},
keywords = {Vehicular Ad-hoc Networks (Vanets), Software-defined Vehicular Network (SDVN), Hierarchical routing, Fuzzy logic, Reinforcement learning},
abstract = {Due to the lack of fully considering dynamic traffic information, in Vehicular Ad-hoc Networks (VANETs), existing routing schemes are easily stuck in local optimum, path redundancy, and congestion problems. By combining Software Defined Network (SDN) with VANET, the emerging Software Defined Vehicular Network (SDVN) can provide a global perspective of the traffic network to bridge the gap. In this paper, we introduce an intelligent fuzzy-based routing scheme for urban SDVN. First, a large urban area is divided into multiple sub-areas, in which each area is centered on an intersection. Second, the central controller maintains a routing table that records the priorities of packets be forwarded from an area to another, and all values in the routing table are initialized using Fuzzy Logic. Finally, we propose a hierarchical greedy routing with link stability (GLS) to calculate the routing path with the highest link stability according to the routing table. Meanwhile, considering the dynamic nature of vehicles in an area, Reinforcement Learning is employed to update the routing table during the routing process. Simulation results show that the proposed routing scheme achieved a significant improvement in performance over its counterparts.}
}
@article{BUTTSWILMSMEYER202063,
title = {The technological advancements that enabled the age of big data in the environmental sciences: A history and future directions},
journal = {Current Opinion in Environmental Science & Health},
volume = {18},
pages = {63-69},
year = {2020},
note = {Environmental Chemistry: Innovative Approaches and Instrumentation in Environmental Chemistry},
issn = {2468-5844},
doi = {https://doi.org/10.1016/j.coesh.2020.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S2468584420300489},
author = {Carrie J. Butts-Wilmsmeyer and Samuel Rapp and Bryn Guthrie},
keywords = {Big data, Remote sensing, Environmental monitoring, Data curation and integration},
abstract = {Advancements in environmental sensors and laboratory instrumentation are inherently linked with Big Data in environmental chemistry. Technological advancements in instrumentation have greatly increased the throughput and precision of measuring chemical, biological, and physical variability and have also resulted in the generation of vast quantities of digital data that can be used to monitor the fate of chemicals in the environment. However, many challenges to accessing and analyzing these data are proving persistent. This review provides a brief overview of the technological advancements that enabled the age of Big Data in the environmental chemistry, the current status of data integration in the environmental sciences, and areas of opportunity for more efficient data integration and comprehensive environmental study, particularly accessibility and use by a multidisciplinary audience.}
}
@article{LI2021104,
title = {Towards intelligent design optimization: Progress and challenge of design optimization theories and technologies for plastic forming},
journal = {Chinese Journal of Aeronautics},
volume = {34},
number = {2},
pages = {104-123},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120304325},
author = {Heng LI and Jingchao YANG and Guangyao CHEN and Xin LIU and Zhao ZHANG and Guangjun LI and Wenhui LIU},
keywords = {Advanced manufacturing, Design optimization, Deterministic optimization (DOP), Intelligent design optimization (IDO), Plastic forming, Uncertain optimization (UOP)},
abstract = {Plastic forming is one of enabling and fundamental technologies in advanced manufacturing chains. Design optimization is a critical way to improve the performance of the forming system, exploit the advantages of high productivity, high product quality, low production cost and short time to market and develop precise, accurate, green, and intelligent (smart) plastic forming technology. However, plastic forming is quite complicated, relating to multi-physics field coupling, multi-factor influence, multi-defect constraint, and triple nonlinear, etc., and the design optimization for plastic forming involves multi-objective, multi-parameter, multi-constraint, nonlinear, high-dimensionality, non-continuity, time-varying, and uncertainty, etc. Therefore, how to achieve accurate and efficient design optimization of products, equipment, tools/dies, and processing as well as materials characterization has always been the research frontier and focus in the field of engineering and manufacturing. In recent years, with the rapid development of computing science, data science and internet of things (IoT), the theories and technologies of design optimization have attracted more and more attention, and developed rapidly in forming process. Accordingly, this paper first introduced the framework of design optimization for plastic forming. Then, focusing on the key problems of design optimization, such as numerical model and optimization algorithm, this paper summarized the research progress on the development and application of the theories and technologies about design optimization in forming process, including deterministic and uncertain optimization. Moreover, the applicability of various modeling methods and optimization algorithms was elaborated in solving the design optimization problems of plastic forming. Finally, considering the development trends of forming technology, this paper discusses some challenges of design optimization that may need to be solved and faced in forming process.}
}
@article{LIANG2022103308,
title = {Multi-access Edge Computing fundamentals, services, enablers and challenges: A complete survey},
journal = {Journal of Network and Computer Applications},
volume = {199},
pages = {103308},
year = {2022},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103308},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521002976},
author = {Bin Liang and Mark A. Gregory and Shuo Li},
keywords = {Multi-access Edge Computing, Software Defined Networking, Network Function Virtualization, Information-Centric Networking, Service Function Chaining, Network Slicing, Cloud-Radio Access Network, Fog-computing based Radio Access Network},
abstract = {Traffic over mobile cellular networks has significantly increased over the past decade, and with the introduction of 5G there is a growing focus on throughput capacity, reliability, and low latency to meet the demands of new and innovative applications. Multi-access Edge Computing (MEC) is being developed to achieve a series of challenges posed by the introduction of new applications and services that require ultra-low latency and high bandwidth. This article is a comprehensive survey of recent advances in MEC and provides a description of the MEC concept, framework, and capabilities. We also summarize a set of MEC technology enablers including Software Defined Networking, Network Function Virtualization, Information-Centric Networking, Service Function Chaining, Cloud-Radio Access Networks, Fog-computing based Radio Access Networks and Network Slicing. The MEC use cases and the open research challenges are presented.}
}
@article{MEI20151185,
title = {Robust adaptive control scheme for optical tracking telescopes with unknown disturbances},
journal = {Optik},
volume = {126},
number = {11},
pages = {1185-1190},
year = {2015},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2015.02.088},
url = {https://www.sciencedirect.com/science/article/pii/S0030402615001382},
author = {Rong Mei and Mou Chen and William W. Guo},
keywords = {Optical tracking telescope, Neural network, Nonlinear disturbance observer, Robust adaptive control, Tracking control},
abstract = {In this paper, a robust adaptive control scheme is proposed for optical tracking telescopes with parametric uncertainty, unknown external disturbance and input saturation. To improve tracking performance of this robust adaptive control scheme, a nonlinear disturbance observer (NDO) is employed to tackle the integrated effect amalgamated from unknown parameters, unknown external disturbance and input saturation. At the same time, the radial basis function neural network (RBFNN) is introduced to approximate the input of an unknown function. Utilizing the estimated outputs of NDO and RBFNN, the robust adaptive control scheme is developed for optical tracking telescopes. Stability of the closed-loop system is rigourously proved via Lyapunov analysis and the convergent tracking error is guaranteed for optical tracking telescopes. Numerical simulation results are presented to illustrate the effectiveness of the proposed robust adaptive control scheme based on RBFNN and NDO for the uncertain dynamic of optical tracking telescopes.}
}
@article{ZHAO2022108529,
title = {Classification of Zambian grasslands using random forest feature importance selection during the optimal phenological period},
journal = {Ecological Indicators},
volume = {135},
pages = {108529},
year = {2022},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2021.108529},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X21011948},
author = {Yifan Zhao and Weiwei Zhu and Panpan Wei and Peng Fang and Xiwang Zhang and Nana Yan and Wenjun Liu and Hao Zhao and Qirui Wu},
keywords = {Grassland classification, Optimal feature selection, PROBA-V, GEE},
abstract = {It is important to conduct grassland resource surveys for the scientific management of grassland resources. Currently, remote sensing technology is widely used to classify land cover. The fine classification datasets of grasslands with high spatial and temporal resolutions are very necessary for scientific research. In order to use remote sensing data conveniently, this study selected the Google Earth Engine platform to select 100-m resolution PROBA-V remote sensing images from 2018 of Zambia, in central Africa. The differences in the normalized vegetation index time-series curves of the different types of grasslands were combined, and June to October was identified as the best phenological classification period. Using the random forest feature importance selection algorithm, the original feature indices and identification of the different grass types were optimized. The results indicate that using the optimal feature combination selected by the random forest feature importance selection algorithm to refine the classification of grasslands improves computational efficiency with an overall accuracy of 83%, which is 3% higher than that of the original feature combination. Among the optimal feature combinations, elevation contributes the most to the improvement classification accuracy. The most significant improvement in the producer’s accuracy was found for grassland (30% increase) and savanna (22% increase). Adjustment of the appropriate phenological periods according to the seasonal characteristics of different regions, the methodology established in this study can be easily applied to other areas for the fine classification of grasslands and the subsequent calculation of grassland biomass and carbon storage.}
}
@article{CHEN202214,
title = {Towards real-time object detection in GigaPixel-level video},
journal = {Neurocomputing},
volume = {477},
pages = {14-24},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.12.049},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221018877},
author = {Kai Chen and Zerun Wang and Xueyang Wang and Dahan Gong and Longlong Yu and Yuchen Guo and Guiguang Ding},
keywords = {Object detection, GigaPixel, Deep learning, Real-time},
abstract = {Object detection aims to locate and recognize objects in images or videos, which contributes to many downstream intelligent applications. Recently, emerging gigapixel videography has attracted considerable attention from computer vision, microscopy, telescopy and many other communities. Its large field of view and high spatial resolution provide sufficient global and local information simultaneously. Although state-of-the-art detection methods have achieved success in common images, they can not be transferred to gigapixel images with both effectiveness and efficiency. To solve this problem, we make the first attempt towards accurate and real-time object detection in giga-pixel video. In this paper we propose a novel framework, termed as GigaDet, which adopts an efficient global-to-local strategy, following the principle of human vision system. Based on the spatial sparsity of objects, a patch generation network (PGN) is introduced to globally locate possible regions containing objects and determine the proper resize ratio of each patch. Then the collected multi-scale patches are fed into a decorated detector (DecDet) in parallel to perform accurate and fast detection in a local way. We carry out extensive experiments on PANDA dataset and GigaDet yields 76.2% AP and 5 FPS on a single 2080ti GPU, which is comparably accurate but 50x faster than Faster RCNN. We believe this research can inspire new applications based on gigapixel video for a large range of fields.}
}
@article{ZHONG2019102919,
title = {Mapping computer vision research in construction: Developments, knowledge gaps and implications for research},
journal = {Automation in Construction},
volume = {107},
pages = {102919},
year = {2019},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2019.102919},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519303875},
author = {Botao Zhong and Haitao Wu and Lieyun Ding and Peter E.D. Love and Heng Li and Hanbin Luo and Li Jiao},
keywords = {Computer vision, Construction, Science mapping, Review},
abstract = {Computer vision is transforming processes associated with the engineering and management of construction projects. It can enable the acquisition, processing, analysis of digital images, and the extraction of high-dimensional data from the real world to produce information to improve managerial decision-making. To acquire an understanding of the developments and applications of computer vision research within the field of construction, we performed a detailed bibliometric and scientometric analysis of the normative literature from 2000 to 2018. We identified the primary areas where computer vision has been applied, including defect inspection, safety monitoring, and performance analysis. By performing a mapping exercise, a detailed analysis of the computer vision literature enables the identification of gaps in knowledge, which provides a platform to support future research in this fertile area for construction.}
}
@article{SHI2019282,
title = {Adaptive leader-following formation control with collision avoidance for a class of second-order nonlinear multi-agent systems},
journal = {Neurocomputing},
volume = {350},
pages = {282-290},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.03.045},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219303856},
author = {Quan Shi and Tieshan Li and Jingqi Li and C.L. Philip Chen and Yang Xiao and Qihe Shan},
keywords = {Formation control, Collision avoidance, Second-order nonlinear multi-agent systems, Artificial potential field method, Neural-network},
abstract = {Combined with artificial potential field (APF) method, an adaptive leader-following formation control with collision avoidance strategy is developed for a class of second-order nonlinear multi-agent systems. Since nonlinear dynamic systems contain the inherent complexities and uncertainties, most formation control with collision avoidance objectives are focused on linear multi-agent systems. In order to solve the problems of unknown nonlinear dynamics, neural network (NN) is employed in the proposed formation protocol design. In any formation control, the higher probability of collision among agents is taken place in the initial stage. The proposed method effectively solves the problems by integrating APF method into leader-following formation strategy. Based on the Lyapunov stability theory and graph theory, the second-order nonlinear multi-agent systems can achieve an ideal formation pattern with the collision avoidance performance. The numerical simulations are carried out to further verify the performance of the proposed algorithm.}
}
@article{YANG201819,
title = {Self-learning robust optimal control for continuous-time nonlinear systems with mismatched disturbances},
journal = {Neural Networks},
volume = {99},
pages = {19-30},
year = {2018},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2017.11.022},
url = {https://www.sciencedirect.com/science/article/pii/S0893608017302861},
author = {Xiong Yang and Haibo He},
keywords = {Adaptive dynamic programming, Neural network, Reinforcement learning, Robust optimal control, Mismatched disturbance},
abstract = {This paper presents a novel adaptive dynamic programming(ADP)-based self-learning robust optimal control scheme for input-affine continuous-time nonlinear systems with mismatched disturbances. First, the stabilizing feedback controller for original nonlinear systems is designed by modifying the optimal control law of the auxiliary system. It is also demonstrated that this feedback controller can optimize a specified value function. Then, within the framework of ADP, a single critic network is constructed to solve the Hamilton–Jacobi–Bellman equation associated with the auxiliary system optimal control law. To update the critic network weights, an indicator function and a concurrent learning technique are employed. By using the proposed update law for the critic network, the restrictive conditions including the initial admissible control and the persistence of excitation condition are relaxed. Moreover, the stability of the closed-loop auxiliary system is guaranteed in the sense that all the signals are uniformly ultimately bounded. Finally, the applicability of the developed control strategy is illustrated through simulations for an unstable nonlinear plant and a power system.}
}
@article{RAZA20224573,
title = {Two-time-scale robust output feedback control for aircraft longitudinal dynamics via sliding mode control and high-gain observer},
journal = {Alexandria Engineering Journal},
volume = {61},
number = {6},
pages = {4573-4583},
year = {2022},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2021.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S1110016821006864},
author = {Abid Raza and Fahad Mumtaz Malik and Naveed Mazhar and Rameez Khan},
keywords = {Longitudinal aircraft, High-gain observer, Output feedback control, Singularly perturbed system, Two-time-scale system},
abstract = {This paper presents output feedback control for longitudinal dynamics of fixed-wing aircraft using singular perturbation techniques. The longitudinal dynamic model is separated into two timescales. A composite feedback control law based on sliding mode control (SMC) is designed for slow and fast subsystems to track the aerodynamic velocity and flight path angle references. Additionally, two separate high-gain observers (HGO) are designed for the slow and fast subsystems to estimate system states. The proposed technique not only simplifies the design but also is computationally efficient. Simulations are performed in MATLAB/Simulink environment with results demonstrating that the proposed output feedback control method robustly achieves trajectory tracking.}
}
@article{ACHILLOPOULOU2020141001,
title = {Monitoring of transport infrastructure exposed to multiple hazards: a roadmap for building resilience},
journal = {Science of The Total Environment},
volume = {746},
pages = {141001},
year = {2020},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2020.141001},
url = {https://www.sciencedirect.com/science/article/pii/S0048969720345307},
author = {Dimitra V. Achillopoulou and Stergios A. Mitoulis and Sotirios A. Argyroudis and Ying Wang},
abstract = {Monitoring-enhanced resilience in transport management is emerging together with the new technologies and digital data, however have not been fully explored yet. Digital technologies have the potential to provide rapid resilience assessments in a quantifiable and engineered manner for transport infrastructure, which is exposed to multiple natural and human-induced hazards and diverse loads throughout their life-cycle. Physical damage and disruption of networks and interdependent systems may cause tremendous socioeconomic impact, affecting world economies and societies. Nowadays, transport infrastructure stakeholders have shifted the requirements in risk and resilience assessment. The expectation is that risk is estimated efficiently, almost in real-time with high accuracy, aiming at maximising the functionality and minimising losses. Nevertheless, no integrated framework exists for quantifying resilience to diverse hazards, based on structural and functionality monitoring (SHFM) data, and this is the main capability gap that this paper envisages filling. Monitoring systems have been used widely in transport infrastructure and have been studied extensively in the literature. Data can facilitate prognosis of the asset condition and the functionality of the network, informing computer-based asset and traffic models, which can assist in defining actionable performance indicators, for diagnosis and for defining risk and loss expediently and accurately. Evidence exists that SHFM is an enabler of resilience. However, strategies are absent in support of monitoring-based resilience assessment in transport infrastructure management. In response to the above challenge, this paper puts forward for the first time in the international literature, a roadmap for monitoring-based quantification of resilience for transport infrastructure, based on a comprehensive review of the current state-of-the-art. It is a holistic asset management roadmap, which identifies the interactions among the design, monitoring, risk assessment and quantification of resilience to multiple hazards. Monitoring is embraced as a vital component, providing expedient feedback for recovery measures, accelerating decision-making for adaptation of changing ecosystems and built environments, utilising emerging technologies, to continuously deliver safer and resilient transport infrastructure.}
}
@article{HUANG2021200,
title = {Multi-level cross-modal interaction network for RGB-D salient object detection},
journal = {Neurocomputing},
volume = {452},
pages = {200-211},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.04.053},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221005956},
author = {Zhou Huang and Huai-Xin Chen and Tao Zhou and Yun-Zhi Yang and Bi-Yuan Liu},
keywords = {Salient object detection, RGB-D, Cross-modal feature learning, Multi-level interactive integration},
abstract = {Depth cues with affluent spatial information have been proven beneficial in boosting salient object detection (SOD), while the depth quality directly affects the subsequent SOD performance. However, it is inevitable to obtain some low-quality depth cues due to thelimitations of its acquisition devices, which can inhibit the SOD performance. Besides, existing methods tend to combine RGB images and depth cues in a direct fusion or a simple fusion module, making them not effectively exploit the complex correlations between the two sources. Moreover, few methods design an appropriate module to fully fuse multi-level features, resulting in cross-level feature interaction insufficient. To address these issues, we propose a novel Multi-level Cross-modal Interaction Network (MCI-Net) for RGB-D based SOD. Our MCI-Net includes two key components: 1) a cross-modal feature learning network, which is used to learn the high-level features for the RGB images and depth cues, effectively enabling the correlations between the two sources to be exploited; and 2) a multi-level interactive integration network, which integrates multi-level cross-modal features to boost the SOD performance. Extensive experiments on six benchmark datasets demonstrate the superiority of our MCI-Net over 14 state-of-the-art methods, and validate the effectiveness of different components in our MCI-Net. More important, our MCI-Net significantly improves the SOD performance as well as has a higher FPS.}
}
@article{TAMATSUKURI201946,
title = {Guaranteed satisficing and finite regret: Analysis of a cognitive satisficing value function},
journal = {Biosystems},
volume = {180},
pages = {46-53},
year = {2019},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2019.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0303264718304453},
author = {Akihiro Tamatsukuri and Tatsuji Takahashi},
keywords = {Satisficing, Decision-making, Multi-armed bandit problems, Reinforcement learning},
abstract = {As reinforcement learning algorithms are being applied to increasingly complicated and realistic tasks, it is becoming increasingly difficult to solve such problems within a practical time frame. Hence, we focus on a satisficing strategy that looks for an action whose value is above the aspiration level (analogous to the break-even point), rather than the optimal action. In this paper, we introduce a simple mathematical model called risk-sensitive satisficing (RS) that implements a satisficing strategy by integrating risk-averse and risk-prone attitudes under the greedy policy. We apply the proposed model to the K-armed bandit problems, which constitute the most basic class of reinforcement learning tasks, and prove two propositions. The first is that RS is guaranteed to find an action whose value is above the aspiration level. The second is that the regret (expected loss) of RS is upper bounded by a finite value, given that the aspiration level is set to an “optimal level” so that satisficing implies optimizing. We confirm the results through numerical simulations and compare the performance of RS with that of other representative algorithms for the K-armed bandit problems.}
}
@article{JORDANOU2019214,
title = {Online learning control with Echo State Networks of an oil production platform},
journal = {Engineering Applications of Artificial Intelligence},
volume = {85},
pages = {214-228},
year = {2019},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2019.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S0952197619301502},
author = {Jean P. Jordanou and Eric Aislan Antonelo and Eduardo Camponogara},
keywords = {Echo State Networks, Online learning, Oil production wells, Control of unknown systems, Inverse model learning, Recurrent neural networks},
abstract = {The design of a control algorithm is difficult when models are unavailable, the physics are varying in time, or structural uncertainties are involved. One such case is an oil production platform in which reservoir conditions and the composition of the multiphase flow are not precisely known. Today, with streams of data generated from sensors, black-box adaptive control emerged as an alternative to control such systems. In this work, we employed an online adaptive controller based on Echo State Networks (ESNs) in diverse scenarios of controlling an oil production platform. The ESN learns an inverse model of the plant from which a control law is derived to attain set-point tracking of a simulated model. The analysis considers high steady-state gains, potentially unstable conditions, and a multi-variate control structure. All in all, this work contributes to the literature by demonstrating that online-learning control can be effective in highly complex dynamic systems (oil production platforms) devoid of suitable models, and with multiple inputs and outputs.}
}
@article{HWANG2021,
title = {Collision avoidance control for formation flying of multiple spacecraft using artificial potential field},
journal = {Advances in Space Research},
year = {2021},
issn = {0273-1177},
doi = {https://doi.org/10.1016/j.asr.2021.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S0273117721009091},
author = {Jiyoon Hwang and Jinah Lee and Chandeok Park},
keywords = {Artificial Potential Field (APF), Autonomous Control, Collision Avoidance, Spacecraft Formation Flying},
abstract = {This study presents trajectory design/control for spacecraft formation flying with obstacle avoidance. Based on the artificial potential field (APF), a formation potential is first defined to derive a formation control law for virtual structure, which enables multiple spacecraft to maintain polygonal or tetrahedral formation. As an efficient method to circumvent local minima which often occur in the APF-based approach, a newly proposed rotational potential is derived in a local coordinate frame to add in the APF framework. The synthesized formation and rotational potential function is used to develop a gradient-based control law to design/control the formation flying trajectory while avoiding collision with obstacles. Proven to be asymptotically stable in the sense of Lyapunov, the proposed continuous feedback control law is demonstrated via formation keeping/reconfiguration examples. The proposed approach successfully maintains the trajectory in the desired formation without colliding with obstacles and without falling into local minimum. These results are comparatively analysed with those of other APF-based approaches. The overall analysis shows that the proposed rotational potential, which has been newly derived in this research, enables a group of spacecraft in formation to efficiently avoid collision with obstacles without convergence to a local minimum.}
}
@article{SOYATA2019101566,
title = {Smart city in crisis: Technology and policy concerns},
journal = {Sustainable Cities and Society},
volume = {50},
pages = {101566},
year = {2019},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2019.101566},
url = {https://www.sciencedirect.com/science/article/pii/S2210670718320183},
author = {Tolga Soyata and Hadi Habibzadeh and Chinwe Ekenna and Brian Nussbaum and Jose Lozano},
keywords = {Emergency communications, Mesh networks, Internet of things, Unused capacity, Smart cities, Smart city policy, Disaster response, Emergency management, Disaster mode technology},
abstract = {Any effective smart city application proposal must consider both the technological and policy challenges to be optimally beneficial to the city; and not only in functioning of the narrow area of application during normal operations (lighting, parking, etc.), but also the utility of these systems and data in disasters and emergencies. In this paper, we propose a conceptual redundant mesh network of smart devices (termed “smart boxes”), which are capable of harvesting their own energy from off-grid sources and operating in two modes: in normal mode, smart boxes act as data collection devices and enable smart city data to be shared through traditional IT services. Alternatively, during a catastrophic event in the city, smart boxes switch to emergency mode and provide a communication channel to first responders via the redundant overlay network they establish, without requiring any power from the grid. We provide a detailed research map to realize such a conceptual network, both from technology (i.e., communication, hardware) and policy aspects (i.e., institutional and personal policy adoption), including extensive suggestions for assessment of both technical and policy success, and incorporation of non-traditional smart city customers for smart city application data and services like first responders and emergency managers.}
}
@article{BACCO2022100443,
title = {Air-to-ground real-time multimedia delivery: A multipath testbed},
journal = {Vehicular Communications},
volume = {33},
pages = {100443},
year = {2022},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2021.100443},
url = {https://www.sciencedirect.com/science/article/pii/S2214209621001121},
author = {Manlio Bacco and Pietro Cassarà and Alberto Gotta},
keywords = {Multipath, Video streaming, Real-time, QoS, QoE, Testbed},
abstract = {In this work, we focus our attention on real-time multimedia flows from Unmanned Aerial Vehicless (UAV) to the ground, presenting and analysing the data collected in field trials during a real testbed. The objective is assessing whether a video feed of reasonable quality can be provided to the pilot of an UAV to enable Beyond Visual Line of Sight (BVLoS) operations, by exploiting the multiple cellular operators available in the area. Three cellular networks have been jointly used in a multihoming/multipath setup, leveraging the variable coverage offered in both urban and suburban environments. Taking into account both Quality of Service (QoS) and Quality of Experience (QoE) metrics, the target parameters measured in this testbed are: latency, packet error rate, and video quality, which accounts for frames integrity, continuity, and fluidity. Data collected on the field allow to evaluate both QoS and QoE in the presence of a multipath architecture, showing how the latter, in the presence of network diversity, offer the possibility to improve the QoE at the receiver. We also design a framework to characterize the error model and to map it into a QoE model, therefore providing an analytical characterisation of a multipath channel.}
}
@article{NOUSI2020103933,
title = {Dense convolutional feature histograms for robust visual object tracking},
journal = {Image and Vision Computing},
volume = {99},
pages = {103933},
year = {2020},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2020.103933},
url = {https://www.sciencedirect.com/science/article/pii/S0262885620300652},
author = {Paraskevi Nousi and Anastasios Tefas and Ioannis Pitas},
keywords = {Object Tracking, Deep Learning, Bag-of-Features, Convolutional Feature Histograms},
abstract = {Despite recent breakthroughs in the field, Visual Object Tracking remains an open and challenging task in Computer Vision. Modern applications require trackers to not only be accurate but also very fast, even on embedded systems. In this work, we use features from Convolutional Neural Networks to build histograms, which are more adept at handling appearance variations, in an end-to-end trainable architecture. To deal with the internal covariate shift that occurs when extracting histograms from convolutional features as well as to incorporate informations from the multiple levels of the neural hierarchy, we propose and use a novel densely connected architecture where histograms from multiple layers are concatenated to produce the final representation. Experimental results validate our hypotheses on the benefits of using histograms as opposed to standard convolutional features, as the proposed histogram-based tracker surpasses recently proposed sophisticated trackers on multiple benchmarks. Long-term tracking results also reaffirm the usefulness of the proposed tracker in more challenging scenarios, where appearance variations are more severe and traditional trackers fail.}
}
@article{SUN2020393,
title = {Content-aware rate control scheme for HEVC based on static and dynamic saliency detection},
journal = {Neurocomputing},
volume = {411},
pages = {393-405},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220309668},
author = {Xuebin Sun and XiaoFei Yang and Sukai Wang and Ming Liu},
keywords = {HEVC, Content-aware, Static saliency, Dynamic saliency, Rate control},
abstract = {High efficiency video coding (HEVC) greatly outperforms previous standards H.264/AVC in terms of coding bit rate and video quality. However, it does not take into account the human visual system (HVS), that people pay more attention to specific areas and moving objects. In this paper, we present a content-aware rate control scheme for HEVC based on static and dynamic saliency detection. The proposed strategy mainly consists of three techniques, static saliency detection, dynamic saliency detection, and adaptive bit rate allocation. Firstly, we train a deep convolution network (DCN) model to extract the static saliency map by highlighting semantically salient regions. Compared to traditional texture-based or color-based region of interest (ROI) extraction techniques, our models are more in line with the HVS. Secondly, we develop a moving object segmentation technique to automatically extract the dynamic salient regions for each frame. Furthermore, according to the fusion saliency map, a coding tree unit (CTU) level bit control technique is exploited to realize flexible and adaptive bit rate allocation. As a result, the quality of salient regions is improved by allocating more bits, while allocating fewer bits to the non-salient regions. We verified the proposed method on both the JCT-VC recommended data set and eye-tracking data set. Experiment results show that the PSNR of salient regions can improve by an average of 1.85 dB without adding bit rate burden, which significantly improves the visual experience.}
}
@article{SHEN2022102167,
title = {Omics-based interdisciplinarity is accelerating plant breeding},
journal = {Current Opinion in Plant Biology},
volume = {66},
pages = {102167},
year = {2022},
issn = {1369-5266},
doi = {https://doi.org/10.1016/j.pbi.2021.102167},
url = {https://www.sciencedirect.com/science/article/pii/S1369526621001692},
author = {Yanting Shen and Guoan Zhou and Chengzhi Liang and Zhixi Tian},
keywords = {Omics, Interdisciplinarity, Plant Breeding},
abstract = {Plant breeding is one of the oldest and most important activities accompanying human civilization. During the past thousand years, plant breeding has achieved three significant innovations, each of which derives from introgression of new theories or technologies. These innovations have significantly increased the food supply and allowed for population development. However, with population increases and resource shortages, the world is continuously facing the challenge of food security, which calls for next innovation in plant breeding. Recent technological advances in multiple disciplines have boosted the development of omics, which is accelerating plant breeding. Here, we review the recent advances in omics and discuss our understanding of how interdisciplinary researches will prompt new innovations in plant breeding.}
}
@article{GALLO2022107237,
title = {Reduction of GNSS-Denied inertial navigation errors for fixed wing autonomous unmanned air vehicles},
journal = {Aerospace Science and Technology},
volume = {120},
pages = {107237},
year = {2022},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107237},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821007471},
author = {Eduardo Gallo and Antonio Barrientos},
keywords = {-Denied, -Denied, Inertial navigation, Autonomous navigation, , },
abstract = {This article proposes an inertial navigation algorithm intended to lower the negative consequences of the absence of GNSS (Global Navigation Satellite System) signals on the navigation of autonomous fixed wing low SWaP (Size, Weight, and Power) UAVs (Unmanned Air Vehicles). In addition to accelerometers and gyroscopes, the filter takes advantage of sensors usually present onboard these platforms, such as magnetometers, Pitot tube, and air vanes, and aims to reduce the attitude error and position drift (both horizontal and vertical) with the dual objective of improving the aircraft GNSS-Denied inertial navigation capabilities as well as facilitating the fusion of the inertial filter with visual odometry algorithms. Stochastic high fidelity Monte Carlo simulations of two representative scenarios involving the loss of GNSS signals are employed to evaluate the results, compare the proposed filter with more traditional implementations, and analyze the sensitivity of the results to the quality of the onboard sensors. The author releases the Image 1 implementation of both the navigation filter and the high fidelity simulation as open-source software [1].}
}
@article{BOURAS2021100360,
title = {Energy efficient mechanism for LoRa networks},
journal = {Internet of Things},
volume = {13},
pages = {100360},
year = {2021},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2021.100360},
url = {https://www.sciencedirect.com/science/article/pii/S2542660521000044},
author = {Christos Bouras and Apostolos Gkamas and Spyridon Aniceto Katsampiris Salgado},
keywords = {Energy efficiency, FLoRa, LoRa, Search and rescue, WeSAR},
abstract = {Internet of Things (IoT) is the ability of communication between objects and refers to a wide range of applications, such as the Search and Rescue (SAR) operations. SAR applications need long distance connectivity, thus can be benefited by Low Power Wide Area Networks (LPWAN). One LPWAN technology is called LoRa (Long Range). In this context, the WeSAR project has been created that provides a system for locating and rescuing people, especially those who belong to population groups with a very high probability of getting lost. The energy consumption of the wearable devices is important factor in the SAR operations, as the battery should last more than 50 hours. Therefore, the proposed system is based on LoRa technology, the user localization is based on LoRa using trilateration and Time Difference of Arrival (TDoA) instead of Geolocation Positioning System (GPS), as GPS increases the energy consumption, and we created an energy-efficient mechanism to tackle the problem of energy consumption. In this paper, an energy efficient mechanism for LoRa networks is presented, that is based on the user's state and the battery level of the wearable device. Realistic simulations have been conducted to evaluate the system for both one wearable device, and multiple wearable devices, using different mobility models. The results from the simulations have shown a decrease in the energy consumption in various node mobility models that were tested, without compromising the delivery ratio of the network, something important as the LoRa packets are used for the localization of the lost person.}
}
@article{JIMENEZ2020105474,
title = {A survey on intelligent agents and multi-agents for irrigation scheduling},
journal = {Computers and Electronics in Agriculture},
volume = {176},
pages = {105474},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105474},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919326316},
author = {Andres-F Jimenez and Pedro-F Cardenas and Antonio Canales and Fabian Jimenez and Alfonso Portacio},
keywords = {Artificial intelligence, Intelligent agent, Irrigation scheduling, Precision irrigation, Multi-agent},
abstract = {Irrigation is very important for ensuring food security and reducing crop production vulnerability caused by the lack of rain. Sustainable irrigation is the rational practice of all the activities related to water application on the crops. In irrigation, the rationality of intelligent agents can be used to reach soil water content near the field capacity to increase yields and reduce waste of water. Rationality in artificial intelligence is the capability of the intelligent agents to decide their actions. This paper discusses how incorporating intelligent agents on irrigation systems allows significant advances in respect of current irrigation approaches. This paper review not only focuses on intelligent reactive systems as usual, but rather discloses developments in systems that incorporate other behaviors such as proactivity, planning, learning, social abilities, organization, coordination and negotiation. From the literature review, it is found that the use of soil, plant and environmental sensors, as well as reasoning, learning and communication capabilities, provides innovative technological support to improve sustainability in irrigated agriculture. The review also shows that intelligent agents can adequately consider the timing and the amount of water to apply according to the spatio-temporal variations of the soil–plant–atmosphere system. It is concluded that significant improvements in water savings and crop yield can be achieved incorporating artificial intelligence into precision irrigation. Further research is needed on irrigation scheduling based on multi-agent systems at different scales of agricultural production systems.}
}
@article{SHARMA2017604,
title = {A Novel Cognitive Cycle for Fault Diagnosis in Infrastructural Systems},
journal = {Procedia Computer Science},
volume = {112},
pages = {604-613},
year = {2017},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 21st International Conference, KES-20176-8 September 2017, Marseille, France},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.08.062},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917314060},
author = {Hrishikesh Sharma and Hiranmay Ghosh and P. Balamuralidhar},
keywords = {Cognitive Systems, Reactive Planning, Fault Diagnosis, Qualitative Reasoning, Qualitative Belief Networks},
abstract = {Remote sensing techniques are being increasingly used for periodic structural health monitoring of vast infrastructures such as power transmission systems. The current efforts concentrate on analysis of visual and other signals captured from the sensing devices, to diagnose the faults. Such data collection and analysis is expensive in terms of both computational overheads as well as towards robotic maneuvering of the data collection platform, such as a UAV. In this paper, we model the data gathering platform as an intelligent situated agent, and propose to autonomously control its data gathering and analysis activities through a cognitive cycle, to optimize the cost of efforts in identifying the faults that may exist. In this context, we explore use of less expensive qualitative reasoning with the background knowledge expressed as a Qualitative Bayesian Network (QBN). We introduce a reactive, economical planning algorithm around QBN that controls the sequence of data collection and analysis, much like how human inspectors do. We substantiate our claims with the results of simulation of the corresponding cognitive cycle.}
}
@article{PETROVSKAIA2021115362,
title = {Optimal soil sampling design based on the maxvol algorithm},
journal = {Geoderma},
volume = {402},
pages = {115362},
year = {2021},
issn = {0016-7061},
doi = {https://doi.org/10.1016/j.geoderma.2021.115362},
url = {https://www.sciencedirect.com/science/article/pii/S0016706121004420},
author = {Anna Petrovskaia and Gleb Ryzhakov and Ivan Oseledets},
keywords = {Pedometrics, Sampling design, Optimal design, Digital soil mapping},
abstract = {Spatial soil sampling is an integral part of a soil survey aimed at describing spatial variability in soil properties. We propose considering the soil sampling procedure as a task of optimal design. In practical terms, optimal experiments can reduce experimentation costs, as they allow the researcher to obtain one optimal set of points. We present a sampling design, based on the fundamental idea of selecting sample locations with the most significant dissimilarities. The proposed sampling design is founded upon an optimal design method called the maxvol algorithm. The sampling design is tested in three real cases differing in field data availability and compared to the popular sampling schemes — simple random sampling, conditional Latin Hypercube, Kennard-Stone and stratified random sampling based on complex geographical strata. It is shown that the maxvol-base algorithm has a high potential for practical usage. Our method outperforms popular sampling methods in soil taxa prediction based on topographical features of the site. The proposed algorithm can be especially beneficial for practical application because it can produce high-quality sampling scheme with very few points.}
}
@article{AREVALORAMIREZ202179,
title = {Single bands leaf reflectance prediction based on fuel moisture content for forestry applications},
journal = {Biosystems Engineering},
volume = {202},
pages = {79-95},
year = {2021},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2020.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1537511020303330},
author = {Tito André Arevalo-Ramirez and Andrés Hernán Fuentes Castillo and Pedro Sebastián Reszka Cabello and Fernando A. {Auat Cheein}},
keywords = {Leaf water index, Machine learning, Remote sensing, Wildfire, Wildland fuels},
abstract = {Vegetation indices can be used to perform quantitative and qualitative assessment of vegetation cover. These indices exploit the reflectance features of leaves to predict their biophysical properties. In general, there are different vegetation indices capable of describing the same biophysical parameter. For instance, vegetation water content can be inferred from at least sixteen vegetation indices, where each one uses the reflectance of leaves in different spectral bands. Therefore, if the leaf moisture content, a vegetation index and the reflectance at the wavelengths to compute the vegetation index are known, then the reflectance in other spectral bands can be computed with a bounded error. The current work proposes a method to predict, by a machine learning regressor, the leaf reflectance (spectral signature) at specific spectral bands using the information of leaf moisture content and a single vegetation index of two tree species (Pinus radiata, and Eucalyptus globulus), which constitute 97.5% of the Valparaíso forests in Chile. Results suggest that the most suitable vegetation index to predict the spectral signature is the Leaf Water Index, which using a Kernel Ridge Regressor achieved the best prediction results, with a RMSE lower than 0.022, and a average R2 greater than 0.95 for Pinus radiata and 0.81 for Eucalyptus globulus, respectively.}
}
@article{FAWAKHERJI2021103861,
title = {Multi-Spectral Image Synthesis for Crop/Weed Segmentation in Precision Farming},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103861},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103861},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001469},
author = {Mulham Fawakherji and Ciro Potena and Alberto Pretto and Domenico D. Bloisi and Daniele Nardi},
keywords = {Agricultural robotics, Crop/weed detection, cGANs, Semantic segmentation},
abstract = {An effective perception system is a fundamental component for farming robots, as it enables them to properly perceive the surrounding environment and to carry out targeted operations. The most recent methods make use of state-of-the-art machine learning techniques to learn a valid model for the target task. However, those techniques need a large amount of labeled data for training. A recent approach to deal with this issue is data augmentation through Generative Adversarial Networks (GANs), where entire synthetic scenes are added to the training data, thus enlarging and diversifying their informative content. In this work, we propose an alternative solution with respect to the common data augmentation methods, applying it to the fundamental problem of crop/weed segmentation in precision farming. Starting from real images, we create semi-artificial samples by replacing the most relevant object classes (i.e., crop and weeds) with their synthesized counterparts. To do that, we employ a conditional GAN (cGAN), where the generative model is trained by conditioning the shape of the generated object. Moreover, in addition to RGB data, we take into account also near-infrared (NIR) information, generating four channel multi-spectral synthetic images. Quantitative experiments, carried out on three publicly available datasets, show that (i) our model is capable of generating realistic multi-spectral images of plants and (ii) the usage of such synthetic images in the training process improves the segmentation performance of state-of-the-art semantic segmentation convolutional networks.}
}
@article{BALAMURUGAN2022103564,
title = {DOA tracking for seamless connectivity in beamformed IoT-based drones},
journal = {Computer Standards & Interfaces},
volume = {79},
pages = {103564},
year = {2022},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2021.103564},
url = {https://www.sciencedirect.com/science/article/pii/S0920548921000593},
author = {N.M. Balamurugan and Senthilkumar Mohan and M. Adimoolam and A John and Thippa {reddy G} and Weizheng Wang},
keywords = {Adaptive antenna arrays, DOA tracking, Seamless communication, IoT, Drone},
abstract = {In recent times, there has been a surge of interest around the usage of adaptive antenna arrays of Internet of Things (IoT) based Drones in the communication systems. Adaptive antenna arrays have the ability to form customized radiation patterns based on the changes in the environment by employing methods for estimating Direction of Arrival (DOA) and adaptive beamforming. Nevertheless, upon deploying adaptive antenna arrays in complex IoT platforms, the radiation patterns that result from the use of such adaptive algorithms may be adjusted to the preceding location of the node and not attuned to the current location. These issues that arise due to mobility can be resolved by continuously tracking the DOA of the intended target. As DOA is time varying in an IoT Drone environment, existing algorithms for estimating the DOA like MUltiple SIgnal Classification (MUSIC) and Estimation of Signal Parameter via Rotational Invariance Techniques (ESPRIT) cannot be used to track the signal subspace recursively, as they are based on batch eigenvalue decomposition which is highly time consuming with a time complexity of O(n3). Furthermore, DOA estimation algorithms do not result in robust subspace estimates when the Signal to Noise Ratio (SNR) is low.The main novelty of the proposed work is a low computational complexity subspace tracking algorithm for tracking DOA in order to provide seamless connectivity. Simulation results show that the proposed DOA tracking takes lesser time for tracking the current location of the drone target as opposed to conventional DOA estimation methods. Furthermore,it is observed that the tracking process remains unaffected by SNR.}
}
@article{DESOUZABRITO2021115403,
title = {Combining max-pooling and wavelet pooling strategies for semantic image segmentation},
journal = {Expert Systems with Applications},
volume = {183},
pages = {115403},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115403},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421008253},
author = {André {de Souza Brito} and Marcelo Bernardes Vieira and Mauren Louise Sguario Coelho {de Andrade} and Raul Queiroz Feitosa and Gilson Antonio Giraldi},
keywords = {Convolutional neural networks, Semantic segmentation, Max pooling, Wavelet pooling, IRRG images},
abstract = {This paper presents a novel multi-pooling architecture generated by combining the advantages of wavelet and max-pooling operations in convolutional neural networks (CNNs), focusing on semantic segmentation tasks. CNNs often use pooling to reduce the number of parameters, improve invariance to certain distortions, and enlarge the receptive field. However, pooling can cause information loss and thus is detrimental to further operations such as feature extraction and analysis. This problem is particularly critical for semantic segmentation, where each pixel of an image is assigned to a specific class to divide the image into disjoint regions of interest. To address this problem, pooling strategies based on wavelets-operations have been proposed with the promise to achieve a better trade-off between receptive field size and computational efficiency. Previous works have confirmed the superiority of wavelet pooling over the traditional one in semantic segmentation tasks. However, we have observed in our computational experiments that the expressive gains reported from the use of wavelet pooling in other segmentation tasks were not observed in the scope of aerial imagery due to imprecision in the segmentation of image details. The combination of wavelet pooling and max-pooling, a solution not yet reported in the literature, can address that issue. Such gap observed in the pooling area motivated the two proposals that are the main contributions of this paper: (a) A new multi-pooling strategy combining wavelet and traditional pooling in a new network structure suitable for aerial image segmentation tasks; (b) Two-stream architectures using the traditional max-pooling and wavelet pooling as streams. These proposals were implemented using the Segnet, a known architecture for semantic segmentation. The computational experiments, based on the IRRG images from the Potsdam and Vaihingen data sets, demonstrated that the proposed architectures surpassed the original Segnet architecture’s performance with results comparable to state-of-the-art approaches.}
}
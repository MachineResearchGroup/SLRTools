@inproceedings{10.1145/3487923.3487924,
author = {Ukaegbu, Uchechi F. and Tartibu, Lagouge K. and Okwu, Modestus O. and Olayode, Isaac O.},
title = {Integrating Unmanned Aerial Vehicle and Deep Learning Algorithm for Pipeline Monitoring and Inspection in the Oil and Gas Sector},
year = {2021},
isbn = {9781450385756},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3487923.3487924},
doi = {10.1145/3487923.3487924},
abstract = {Organizations invest heavily during the installation of pipeline facilities which spans across extensive geographical linkage. Also, the issue of pipeline protection and safety must be taken into consideration to have a free flow of oil and gas at inbound and outbound locations. This has necessitated the need for routine inspection and monitoring of pipelines for structural integrity, continued safe operations, and also to monitor intruders/potential trespassers at such locations. This research is focused on the elucidation of a modular unmanned aerial vehicle (UAV) integrated with deep learning algorithms for monitoring and security response to obtain very useful information around the oil and gas facility. The deep learning model employed in this study had training, validation and testing accuracies of 88.3%, 87.5%, and 83.3% respectively. Also, training and validation losses of 0.3583 and 0.3649 were obtained. The suggested integrated UAV has a low maintenance requirement, high endurance, and is cost-effective. It has a superior advantage over the manned aerial vehicles (MAV) currently in use since safety is greatly improved, the cost is reduced, adequate information is obtained and communication is enhanced.},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Its Applications},
articleno = {1},
numpages = {6},
keywords = {Deep learning algorithm, Pipeline, Inspection, Unmanned aerial vehicle, Monitoring},
location = {Virtual Event, Mauritius},
series = {icARTi '21}
}

@inproceedings{10.1145/3501409.3501697,
author = {Zhou, Huan and Zhang, Xiaoyan and Sun, Chu},
title = {Intelligent Maneuver Decision Method of Unmanned Aerial Vehicle},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3501409.3501697},
doi = {10.1145/3501409.3501697},
abstract = {As the key link of airspace task execution, UAV maneuver decision-making is the core intelligence embodiment of UAV, which can best represent the intelligence of UAV "brain". This paper summarizes the intelligent maneuver decision-making methods of UAV. Firstly, the problem and application background of UAV intelligent maneuver decision-making are introduced. Then, the research status of maneuver decision-making methods at home and abroad is analyzed. Intelligent maneuver decision-making is divided into two aspects: maneuver decision-making based on game theory and artificial intelligence. Game theory focuses on differential game, matrix game and influence diagram, Artificial intelligence focuses on expert system, intelligent optimization theory and neural network. Finally, a new air combat intelligent maneuver decision-making method based on bird foraging search algorithm is designed and verified by simulation experiments. The summary of UAV intelligent maneuver decision-making methods will contribute to the innovative research in this field, so as to promote the rapid development of maneuver decision-making technology.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1634–1639},
numpages = {6},
keywords = {Maneuver decision, UAV, Artificial Intelligence, Reinforcement learning, Game theory},
location = {Xiamen, China},
series = {EITCE 2021}
}

@article{10.1145/3301273,
author = {Koch, William and Mancuso, Renato and West, Richard and Bestavros, Azer},
title = {Reinforcement Learning for UAV Attitude Control},
year = {2019},
issue_date = {April 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
issn = {2378-962X},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3301273},
doi = {10.1145/3301273},
abstract = {Autopilot systems are typically composed of an “inner loop” providing stability and control, whereas an “outer loop” is responsible for mission-level objectives, such as way-point navigation. Autopilot systems for unmanned aerial vehicles are predominately implemented using Proportional-Integral-Derivative&nbsp;(PID) control systems, which have demonstrated exceptional performance in stable environments. However, more sophisticated control is required to operate in unpredictable and harsh environments. Intelligent flight control systems is an active area of research addressing limitations of PID control most recently through the use of reinforcement learning&nbsp;(RL), which has had success in other applications, such as robotics. Yet previous work has focused primarily on using RL at the mission-level controller. In this work, we investigate the performance and accuracy of the inner control loop providing attitude control when using intelligent flight control systems trained with state-of-the-art RL algorithms—Deep Deterministic Policy Gradient, Trust Region Policy Optimization, and Proximal Policy Optimization. To investigate these unknowns, we first developed an open source high-fidelity simulation environment to train a flight controller attitude control of a quadrotor through RL. We then used our environment to compare their performance to that of a PID controller to identify if using RL is appropriate in high-precision, time-critical flight control.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = {feb},
articleno = {22},
numpages = {21},
keywords = {adaptive control, Attitude control, PID, quadcopter, intelligent control, autopilot, reinforcement learning, UAV, machine learning}
}

@inproceedings{10.1145/3297156.3297269,
author = {Zhang, Jiaohao and Zhang, Qiang and Shi, Chunlei},
title = {An Unmanned Aerial Vehicle Detection Algorithm Based on Semantic Segmentation and Visual Attention Mechanism},
year = {2018},
isbn = {9781450366069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3297156.3297269},
doi = {10.1145/3297156.3297269},
abstract = {Combined with semantic segmentation and visual attention mechanism, a new method for UAV detection in complex background is presented. The semantic segmentation of target image, which is implemented by Mask R-CNN, is used to exclude invalid regions. Then the processes of small target detection based on visual attention mechanism is built. This method is used to detecting the position of UAV in the sky. The effectiveness of algorithm proposed in this paper is proved by a large number of experiments.},
booktitle = {Proceedings of the 2018 2nd International Conference on Computer Science and Artificial Intelligence},
pages = {309–313},
numpages = {5},
keywords = {UAV detection, Mask R-CNN, semantic segmentation, visual attention mechanism},
location = {Shenzhen, China},
series = {CSAI '18}
}

@inproceedings{10.1145/3164541.3164624,
author = {Saadat, Md. Nazmus and Husen, Mohd Nizam},
title = {An Application Framework for Forest Fire and Haze Detection with Data Acquisition Using Unmanned Aerial Vehicle},
year = {2018},
isbn = {9781450363853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3164541.3164624},
doi = {10.1145/3164541.3164624},
abstract = {An application framework is presented in this paper to mitigate the problems that cause the forest area to be harmed. Along with this, a sensor based data collection module is presented that will be enhancing monitoring facility in places in the forest or plants where usually human does not go regularly. The are many use cases of the proposed solutions, for example, it targets to detect the haze or forest fire in early stage so that it can't wide spread and cause severe damage to the forest itself and surrounded locality, object detection and intruder identification, raw imagery collection for finding the appropriate trees to be harvested in Timber industry. These functionalities reside on a remote server. This ongoing research considers supervised machine learning and big data implementation along with the custom system with unmanned aerial vehicles to be the career of designed system. We have proposed an application framework particularly to be cheap and easy to handle by non-technical persons and that it does not require large software system knowledge like Pix4D or DroneDeploy. This system will be useful for not only regular operations but also for research and development as well specially in the forestry and palm oil plantation surveillance, and sustainable timber industry that specially needs carefully collected imageries and data from objects inside the dense forests.},
booktitle = {Proceedings of the 12th International Conference on Ubiquitous Information Management and Communication},
articleno = {46},
numpages = {7},
keywords = {Image processing, Timber harvesting, Android, Drone, Data Acquisition, Mobile Application framework},
location = {Langkawi, Malaysia},
series = {IMCOM '18}
}

@inproceedings{10.1145/3448891.3448919,
author = {Lee, Isabella and Babu, Vignesh and Caesar, Matthew and Nicol, David},
title = {Deep Reinforcement Learning for UAV-Assisted Emergency Response},
year = {2020},
isbn = {9781450388405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3448891.3448919},
doi = {10.1145/3448891.3448919},
abstract = { In the aftermath of a disaster, the ability to reliably communicate and coordinate emergency response could make a meaningful difference in the number of lives saved or lost. However, post-disaster areas tend to have limited functioning communication network infrastructure while emergency response teams are carrying increasingly more devices, such as sensors and video transmitting equipment, which can be low-powered with limited transmission ranges. In such scenarios, unmanned aerial vehicles (UAVs) can be used as relays to connect these devices with each other. Since first responders are likely to be constantly mobile, the problem of where these UAVs are placed and how they move in response to the changing environment could have a large effect on the number of connections this UAV relay network is able to maintain. In this work, we propose DroneDR, a reinforcement learning framework for UAV positioning that uses information about connectivity requirements and user node positions to decide how to move each UAV in the network while maintaining connectivity between UAVs. The proposed approach is shown to outperform other greedy heuristics across a broad range of scenarios and demonstrates the potential in using reinforcement learning techniques to aid communication during disaster relief operations.},
booktitle = {MobiQuitous 2020 - 17th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
pages = {327–336},
numpages = {10},
keywords = {reinforcement learning, UAV network, disaster relief, IoT network},
location = {Darmstadt, Germany},
series = {MobiQuitous '20}
}

@inproceedings{10.1145/3372938.3372945,
author = {AlAfandy, Khalid A. and Omara, Hicham and Lazaar, Mohamed and Al Achhab, Mohammed},
title = {Artificial Neural Networks Optimization and Convolution Neural Networks to Classifying Images in Remote Sensing: A Review},
year = {2019},
isbn = {9781450372404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3372938.3372945},
doi = {10.1145/3372938.3372945},
abstract = {One of important functions of remote sensing data is producing the land-use/land-cover maps. Image classification is one of important applications for remote sensing imaginary. Machine learning (ML) techniques are the most widely used for this purpose in recent years. With the advent of computer vision thus, the need to deal with a large amount of data and avoiding any data redundancy, the deep learning techniques were appeared. Deep learning (DL) is a branch of machine learning that imitates the human brain structure and depends on the artificial neural networks (ANNs). Optimization of the neural networks is necessary for reduce the loss functions and avoiding any redundancy data in the training set, thus raise the accuracy. Genetic algorithms (GA) are the most widely used in the neural networks optimization, which considered as fully connected neural networks. Convolution neural networks (CNNs) are a branch of the artificial neural networks that are saving the computing cost and processing time. Thus, this paper presents a review of the deep learning algorithms specially the artificial neural networks, the genetic algorithm and the convolution neural networks. This paper also introduces a comparative study between the genetic algorithm and the convolution neural networks method. This comparison based on the overall accuracy (OA) and the kappa coefficient. This comparison shows that there are many conditions can affect the classifier accuracy. The results demonstrate that the CNNs algorithms are more accurate than the GA and in the other hand, the CNNs algorithms have lower computing cost.},
booktitle = {Proceedings of the 4th International Conference on Big Data and Internet of Things},
articleno = {7},
numpages = {8},
keywords = {Machine Learning, Deep Learning, CNNs, Remote Sensing, GA, optimization, Image Classification, ANNs},
location = {Rabat, Morocco},
series = {BDIoT'19}
}

@inproceedings{10.1145/3401895.3401931,
author = {de Sousa Paula, Patricia and Sarmento, Wellington W. Ferreira and Paillard, Gabriel A. Louis and de Castro, Miguel Franklin},
title = {Using Swarm Intelligence in Unmanned Aerial Vehicles for Unknown Location Fixed Target Search},
year = {2020},
isbn = {9781450377119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3401895.3401931},
doi = {10.1145/3401895.3401931},
abstract = {The context of this research is the use of bioinspired algorithms applied to unmanned aerial vehicles (UAV) to search for a fixed target of unknown location. A target can be a lost human being or a broken vehicle, for example. Swarm algorithms used with UAVs can be adapted to perform better than a simple scanning algorithm such as Parallel Path Finder. The Particle Swarm Optimization and Bat Algorithm algorithms are compared using constraints such as UAV battery life and the size of the search area. Thus, the best solution to this problem is shown, among the adapted ones, considering the applied restrictions.},
booktitle = {Proceedings of the 10th Euro-American Conference on Telematics and Information Systems},
articleno = {20},
numpages = {8},
keywords = {mobile, UAV, swarm intelligence, bioinspired algorithms},
location = {Aveiro, Portugal},
series = {EATIS '20}
}

@inproceedings{10.1145/3369985.3370039,
author = {Zhang, Ganghong and Huo, Chao and Yuan, Jianan},
title = {Deep Learning Chips: Challenges and Opportunities for Ubiquitous Power Internet of Things},
year = {2019},
isbn = {9781450372589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3369985.3370039},
doi = {10.1145/3369985.3370039},
abstract = {Tasks of Ubiquitous Power Internet of Things run through the power generation, transmission, transformation, distribution, electricity use and other links, requiring advanced communication, artificial intelligence, big data and other technologies. Deep learning chips provide computational power for algorithm execution and data processing, which are indispensable foundations and basic components for intelligent terminals. Therefore, this paper summarizes the challenges and opportunities faced by deep learning chips in the construction of ubiquitous power Internet of Things. Firstly, the four parts of ubiquitous power Internet of Things including terminal layer, network layer, platform layer and application layer are described. Secondly, the key technologies of deep learning technology and deep neural network accelerator involved in deep learning chips are summarized. Finally, the research work of deep learning chips for ubiquitous power Internet of Things is surveyed. The main functions and existing problems are discussed, and the future research work is proposed.},
booktitle = {Proceedings of the 5th International Conference on Communication and Information Processing},
pages = {305–312},
numpages = {8},
keywords = {intelligent terminal, ubiquitous power internet of things, deep learning chips, deep neural network},
location = {Chongqing, China},
series = {ICCIP '19}
}

@inproceedings{10.5555/3398761.3399125,
author = {Padakandla, Sindhu},
title = {Reinforcement Learning Algorithms for Autonomous Adaptive Agents},
year = {2020},
isbn = {9781450375184},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Intelligent agents are being designed to automate many tasks - for e.g., traffic signal control, vehicle driving, inventory control and are also being used in improving lives of people - like in healthcare, agriculture, wildlife protection etc. The widespread deployment of intelligent agents requires that we minimize the bottlenecks which affect their performance and utility. Motivated by this challenge, my thesis proposes new algorithms and methods which helps the agent in efficiently operating in the real-world and also during interaction with humans. My work has shown significant improvements in the performance of deployed agents, when operating in real world.},
booktitle = {Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {2201–2203},
numpages = {3},
keywords = {reinforcement learning, non-stationary environments, deep reinforcement learning, data efficiency, continual learning},
location = {Auckland, New Zealand},
series = {AAMAS '20}
}

@inproceedings{10.5555/2936924.2937002,
author = {Ceren, Roi and Doshi, Prashant and Banerjee, Bikramjit},
title = {Reinforcement Learning in Partially Observable Multiagent Settings: Monte Carlo Exploring Policies with PAC Bounds},
year = {2016},
isbn = {9781450342391},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Perkins' Monte Carlo exploring starts for partially observable Markov decision processes (MCES-P) integrates Monte Carlo exploring starts into a local search of policy space to offer a template for reinforcement learning that operates under partial observability of the state. In this paper, we generalize the reinforcement learning under partial observability to the self-interested multiagent setting. We present a new template, MCES-IP, which extends MCES-P by maintaining predictions of the other agent's actions based on dynamic beliefs over models. MCES-IP is instantiated to be approximately locally optimal with some probability by deriving a theoretical bound on the sample size that in part depends on the allowed error from the sampling; we refer to this algorithm as MCESIP+PAC. Our experiments demonstrate that MCESIP+PAC learns policies whose values are comparable or better than those from MCESP+PAC in multiagent domains while utilizing much less samples for each transformation.},
booktitle = {Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems},
pages = {530–538},
numpages = {9},
keywords = {multiple agents, reinforcement learning, probably approximately correct, partial observability},
location = {Singapore, Singapore},
series = {AAMAS '16}
}

@inproceedings{10.1145/3414045.3415948,
author = {Chen, Yun and Lin, Xingqin and Khan, Talha and Mozaffari, Mohammad},
title = {A Deep Learning Approach to Efficient Drone Mobility Support},
year = {2020},
isbn = {9781450381055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3414045.3415948},
doi = {10.1145/3414045.3415948},
abstract = {The growing deployment of drones in a myriad of applications relies on seamless and reliable wireless connectivity for safe control and operation of drones. Cellular technology is a key enabler for providing essential wireless services to drones flying in the sky. Existing cellular networks targeting terrestrial usage can support the initial deployment of low-altitude drone users, but there are challenges such as mobility support. In this paper, we propose a novel handover framework for providing efficient mobility support and reliable wireless connectivity to drones served by a terrestrial cellular network. Using tools from deep reinforcement learning, we develop a deep Q-learning algorithm to dynamically optimize handover decisions to ensure robust connectivity for drone users. Simulation results show that the proposed framework significantly reduces the number of handovers at the expense of a small loss in signal strength relative to the baseline case where a drone always connect to a base station that provides the strongest received signal strength.},
booktitle = {Proceedings of the 2nd ACM MobiCom Workshop on Drone Assisted Wireless Communications for 5G and Beyond},
pages = {67–72},
numpages = {6},
keywords = {mobility management, 5G, non-terrestrial networks, deep learning, handover, UAV, reinforcement learning, drone},
location = {London, United Kingdom},
series = {DroneCom '20}
}

@inproceedings{10.1145/3265007.3265014,
author = {Malinao, Ronjie Mar L. and Hernandez, Alexander A.},
title = {Classifying Breadfruit Tree Using Artificial Neural Networks},
year = {2018},
isbn = {9781450365741},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3265007.3265014},
doi = {10.1145/3265007.3265014},
abstract = {This is a research-in-progress of designing an intelligent morphological analysis for Artocarpus Altilis or commonly called "breadfruit." This research applied image processing, artificial intelligence (AI) and system design. Using Unmanned Aerial Vehicle (UAV), images are captured, processed and fed to the artificial intelligence for classification. The initial result yields a 75% accuracy using the initial dataset. This study proves that using UAV combined with AI could substantially contribute to the agricultural industry in efficiently classifying breadfruit. This paper recommends further enhancement of the system.},
booktitle = {Proceedings of the 6th ACM/ACIS International Conference on Applied Computing and Information Technology},
pages = {27–31},
numpages = {5},
keywords = {Artificial Neural Networks, Image Processing, Artocarpus, Breadfruit},
location = {Kunming, China},
series = {ACIT 2018}
}

@inproceedings{10.1145/3349801.3349805,
author = {Piciarelli, Claudio and Foresti, Gian Luca},
title = {Drone Patrolling with Reinforcement Learning},
year = {2019},
isbn = {9781450371896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3349801.3349805},
doi = {10.1145/3349801.3349805},
abstract = {When a camera-equipped drone is assigned a patrolling task, it typically follows a pre-defined path that evenly covers the whole environment. In this paper instead we consider the problem of finding an ideal path under the assumption that not all the areas have the same coverage requirements. We thus propose a reinforcement learning approach that, given a relevance map representing coverage requirements, autonomously chooses the best drone actions to optimize the coverage.},
booktitle = {Proceedings of the 13th International Conference on Distributed Smart Cameras},
articleno = {4},
numpages = {6},
location = {Trento, Italy},
series = {ICDSC 2019}
}

@inproceedings{10.1145/3339311.3339357,
author = {Mittal, Usha and Srivastava, Sonal and Chawla, Priyanka},
title = {Review of Different Techniques for Object Detection Using Deep Learning},
year = {2019},
isbn = {9781450366526},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3339311.3339357},
doi = {10.1145/3339311.3339357},
abstract = {Human brain takes less than a minute to identify the location of object inside the image as well as recognize it as soon as it sees to it; but machine needs time and large amount of data to do the same task. Deep neural network based on convolution neural network gives high accuracy and great results in object detection and classification. To train deep neural networks, large amount of data such as (images and videos) and time is required. As computational cost of computer vision is very high, transfer-learning technique, where a model trained on one task is reused on another related task, gives better results. Authors have proposed various deep learning based algorithms for object detection and classification like Region based Convolutional neural network, Fast Region based Convolutional neural network, Faster Region based Convolutional neural network, Mask Region based Convolutional neural network and You Only Look Once. In this paper, a comparative study of different algorithms is given.},
booktitle = {Proceedings of the Third International Conference on Advanced Informatics for Computing Research},
articleno = {46},
numpages = {8},
keywords = {convolutional neural network, classification, YOLO, object detection, deep learning, R-CNN},
location = {Shimla, India},
series = {ICAICR '19}
}

@inproceedings{10.1145/3396864.3399701,
author = {Venturini, Federico and Mason, Federico and Pase, Francesco and Chiariotti, Federico and Testolin, Alberto and Zanella, Andrea and Zorzi, Michele},
title = {Distributed Reinforcement Learning for Flexible UAV Swarm Control with Transfer Learning Capabilities},
year = {2020},
isbn = {9781450380102},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3396864.3399701},
doi = {10.1145/3396864.3399701},
abstract = {Over the past few years, the use of swarms of Unmanned Aerial Vehicles (UAVs) in monitoring and remote area surveillance applications has become economically efficient thanks to the price reduction and the increased capabilities of drones. The drones in the swarm need to cooperatively explore an unknown area, in order to identify and monitor interesting targets, while minimizing their movements. In this work, we propose a distributed Reinforcement Learning (RL) approach that scales to larger swarms without modifications. The proposed framework can easily deal with non-uniform distributions of targets, drawing from past experience to improve its performance. In particular, our experiments show that when agents are trained for a specific scenario, they can adapt to a new one with a minimal amount of additional training. We show that our RL approach achieves favorable performance compared to a computationally intensive look-ahead heuristic.},
booktitle = {Proceedings of the 6th ACM Workshop on Micro Aerial Vehicle Networks, Systems, and Applications},
articleno = {10},
numpages = {6},
keywords = {surveilling, multi-agent RL, distributed deep RL, UAV networks},
location = {Toronto, Ontario, Canada},
series = {DroNet '20}
}

@inproceedings{10.1145/3374587.3374599,
author = {Sun, Jian and Zhang, Yingzhou},
title = {A Reinforcement Learning-Based Decentralized Method of Avoiding Multi-UAV Collision in 3-D Airspace},
year = {2019},
isbn = {9781450376273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3374587.3374599},
doi = {10.1145/3374587.3374599},
abstract = {Recently, large-scale multi-UAV collaboration system have been proposed for mobile sensor network applications and the collision avoidance becomes the core of the scalable control for any multi-UAV system. We present a decentralized collision avoidance mechanism of cooperative unmanned aerial vehicles (UAVs) in three-dimensional airspace, which directly maps the observed environment information to a UAV's steer commands. We solve the problem on continuous state space and action space and design a multi-module reward function to decrease the collision rate of UAV-UAV and UAV-obstacle, deviation from the planned trajectory and the cost of turning angular velocity. Our method is based on the Distributed Proximal Policy Optimization (DPPO) algorithm with asynchronous training framework, which is a policy gradient of Reinforcement Learning algorithm to learn an optimal policy. Subsequently, we propose a multi-scenario multi-stage training process to our experiment as for a good convergence solution. After testing our method in non-stationary stochastic environments and conducting a contrast experiment, the result shows that our method is able to find collision-free policy for a large-scale multi-UAV swarm.},
booktitle = {Proceedings of the 2019 3rd International Conference on Computer Science and Artificial Intelligence},
pages = {77–82},
numpages = {6},
keywords = {reinforcement learning, DPPO, Decentralized collision avoidance, multi-module},
location = {Normal, IL, USA},
series = {CSAI2019}
}

@inproceedings{10.5555/2936924.2937076,
author = {Bogert, Kenneth and Lin, Jonathan Feng-Shun and Doshi, Prashant and Kulic, Dana},
title = {Expectation-Maximization for Inverse Reinforcement Learning with Hidden Data},
year = {2016},
isbn = {9781450342391},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {We consider the problem of performing inverse reinforcement learning when the trajectory of the agent being observed is partially occluded from view. Motivated by robotic scenarios in which limited sensor data is available to a learner, we treat the missing information as hidden variables and present an algorithm based on expectation-maximization to solve the non-linear, non-convex problem. Previous work in this area simply removed the occluded portions from consideration when computing feature expectations; in contrast our technique takes expectations over the missing values, enabling learning even in the presence of dynamic occlusion. We evaluate our new algorithm in a simulated reconnaissance scenario in which the visible portion of the state space varies. Finally, we show our approach enables apprenticeship learning by observing a human performing a sorting task in spite of key information missing from observations.},
booktitle = {Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems},
pages = {1034–1042},
numpages = {9},
keywords = {machine learning, latent variables, inverse reinforcement learning, fruit sorting},
location = {Singapore, Singapore},
series = {AAMAS '16}
}

@inproceedings{10.1145/3487075.3487094,
author = {Huang, Conghui and Wang, Chaozhe and Tong, Qi},
title = {Infrared Air Combat Simulation Model for Deep Reinforcement Learning},
year = {2021},
isbn = {9781450389853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3487075.3487094},
doi = {10.1145/3487075.3487094},
abstract = {Aiming at the problem of lacking credible and realistic infrared air combat simulation platform for applying the deep reinforcement learning method, this paper explored the design requirements for the construction of simulation system, built the overall architecture of infrared air combat simulation system, described the structure, principle and working process of the fighter jet, infrared air-to-air missile, point source decoy and environment model. The implementation method of the simulation system was given, and the credibility of the system was verified through attack and defense simulation examples and error analysis of missile anti-jamming probability, which indicated that the simulation system can be used for the training and testing of agents based on deep reinforcement learning in infrared air combat scenarios.},
booktitle = {The 5th International Conference on Computer Science and Application Engineering},
articleno = {19},
numpages = {7},
keywords = {Deep reinforcement learning, Air combat simulation, Agent},
location = {Sanya, China},
series = {CSAE 2021}
}

@inproceedings{10.5555/2772879.2773251,
author = {Efthymiadis, Kyriakos and Kudenko, Daniel},
title = {Knowledge Revision for Reinforcement Learning with Abstract MDPs},
year = {2015},
isbn = {9781450334136},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Reward shaping is a method often used in RL so as to provide domain knowledge to agents and thus improve learning. An unrealistic assumption however is that the provided knowledge is always correct. This assumption can lead to poor performance in terms of total reward and convergence speed in case it is not met. Previous research demonstrated the use of plan-based reward shaping with knowledge revision in a single agent scenario where agents showed that they can quickly identify and revise erroneous knowledge and thus benefit from more accurate plans. This method however has no mechanism to deal with non-deterministic scenarios and is thus limited to deterministic domains. In this paper we present a method to provide heuristic knowledge via abstract MDPs, coupled with a revision algorithm to manage the cases where the provided domain knowledge is wrong. We show empirically that our method can efficiently revise erroneous knowledge even in the cases where the environment is non-deterministic and also removes the need for some of the assumptions present in plan-based reward shaping with knowledge revision.},
booktitle = {Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
pages = {763–770},
numpages = {8},
keywords = {reward shaping, reinforcement learning, knowledge revision},
location = {Istanbul, Turkey},
series = {AAMAS '15}
}

@inproceedings{10.1145/3059336.3059337,
author = {Jiang, Xiaowei and Zhou, Qiang and Ye, Ying},
title = {Method of Task Assignment for UAV Based on Particle Swarm Optimization in Logistics},
year = {2017},
isbn = {9781450347983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3059336.3059337},
doi = {10.1145/3059336.3059337},
abstract = {In recent years, there are many research achievements in the fields of logistics and Unmanned Aerial Vehicle (UAV). But the research achievement of the combination of the two fields is few. Researching on the combination of the UAV filed and the logistics filed has theoretical significance. Effective logistics system and task assignment strategy play an important role in reducing the operation cost of logistics enterprise as well as improving transport efficiency. In this paper, according to the Vehicle Routing Problems with Time Windows (VRPTW), we establish the model of task assignment for UAV in logistics. This model takes multi-constraints (such as weight coefficients, time-windows constraints, the constraints of the UAV and so on ) into account. And then the task assignment problem with multiple constraints is solved by improved Particle Swarm Optimization (PSO) algorithm which is suitable for solving complex combinatorial optimization problems. Meanwhile, we make some modification for the PSO to suit for the acquirement of mutually exclusive. The basic principle and simulation steps of the improved PSO algorithm is described in detail. And a simulation example is given. Furthermore, we compare PSO with Genetic Algorithm. The simulation results show that this algorithm is efficient to solve the problem of task assignment for UAV.},
booktitle = {Proceedings of the 2017 International Conference on Intelligent Systems, Metaheuristics &amp; Swarm Intelligence},
pages = {113–117},
numpages = {5},
keywords = {VRPTW, Unmanned Aerial Vehicle (UAV), PSO, swarm intelligence, logistics, task assignment},
location = {Hong Kong, Hong Kong},
series = {ISMSI '17}
}

@inproceedings{10.1145/3309772.3309797,
author = {Gorobetz, Mikhail and Ribickis, Leonids and Levchenkov, Anatoly and Beinarovica, Anna},
title = {Machine Learning Algorithm of Immune Neuro-Fuzzy Anti-Collision Embedded System for Autonomous Unmanned Aerial Vehicles Team},
year = {2019},
isbn = {9781450360852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3309772.3309797},
doi = {10.1145/3309772.3309797},
abstract = {This study is dedicated to solve a collision prevention task for autonomous unmanned aerial vehicles' (UAVs) team by Immune Neuro-Fuzzy Network (INFN) application. It is a part of the project aimed at the development of intelligent safety and optimal control systems of autonomous electric vehicles and transport in general.The goal of the current research is to develop the machine learning algorithm for autonomous UAV, that will give possibility for UAVs to train themselves without a teacher to avoid the collisions in the most effective way by changing the UAVs trajectory of the flight and without human intervention, i.e. the system should be self-organized. For this purpose, authors have improved previously developed immune neuro-fuzzy logic method to minimize collision probability. The experiments prove the workability and advantages of the developed algorithm.},
booktitle = {Proceedings of the 2nd International Conference on Applications of Intelligent Systems},
articleno = {25},
numpages = {8},
keywords = {autonomous vehicle, immune network, unmanned aerial vehicle, fuzzy logic, neural network, vehicle's team, anti-collision system, machine learning},
location = {Las Palmas de Gran Canaria, Spain},
series = {APPIS '19}
}

@article{10.1145/3317573,
author = {Ding, Junhua and Li, Xinchuan and Kang, Xiaojun and Gudivada, Venkat N.},
title = {A Case Study of the Augmentation and Evaluation of Training Data for Deep Learning},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
issn = {1936-1955},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3317573},
doi = {10.1145/3317573},
abstract = {Deep learning has been widely used for extracting values from big data. As many other machine learning algorithms, deep learning requires significant training data. Experiments have shown both the volume and the quality of training data can significantly impact the effectiveness of the value extraction. In some cases, the volume of training data is not sufficiently large for effectively training a deep learning model. In other cases, the quality of training data is not high enough to achieve the optimal performance. Many approaches have been proposed for augmenting training data to mitigate the deficiency. However, whether the augmented data are “fit for purpose” of deep learning is still a question. A framework for comprehensively evaluating the effectiveness of the augmented data for deep learning is still not available. In this article, we first discuss a data augmentation approach for deep learning. The approach includes two components: the first one is to remove noisy data in a dataset using a machine learning based classification to improve its quality, and the second one is to increase the volume of the dataset for effectively training a deep learning model. To evaluate the quality of the augmented data in fidelity, variety, and veracity, a data quality evaluation framework is proposed. We demonstrated the effectiveness of the data augmentation approach and the data quality evaluation framework through studying an automated classification of biology cell images using deep learning. The experimental results clearly demonstrated the impact of the volume and quality of training data to the performance of deep learning and the importance of the data quality evaluation. The data augmentation approach and the data quality evaluation framework can be straightforwardly adapted for deep learning study in other domains.},
journal = {J. Data and Information Quality},
month = {aug},
articleno = {20},
numpages = {22},
keywords = {diffraction image, machine learning, convolutional neural network, deep learning, support vector machine, Data quality}
}

@inproceedings{10.1145/3447587.3447598,
author = {Yi, JianWei and Guan, Banglei and Li, Pengcheng},
title = {Intelligent Highway Speed Monitoring UAV System Based on Deep Learning},
year = {2021},
isbn = {9781450389105},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3447587.3447598},
doi = {10.1145/3447587.3447598},
abstract = {At present, with economic development, traffic accidents occur frequently, and more than one-third of traffic accidents are caused by speeding. Current highway speed measurement devices have disadvantages such as high cost, inability to move, and low speed measurement accuracy. For these reasons, we propose an intelligent monitoring drone system for highway speed measurement based on deep learning. The system uses drones for monitoring, so the system is low-cost and flexible. First, the system's camera captures and recognizes vehicle movement and license plate information. Second, we propose algorithms based on the corners of the lane line speed measurement and the speed measurement based on the homography matrix to calculate the vehicle speed, and at the same time detect and recognize the license plate. Third, we propose to use ensemble learning methods to improve the accuracy of vehicle speed measurement, and finally obtain vehicle speed and speeding license plates. Experimental results prove that the proposed highway speed measurement UAV system can accurately identify and measure vehicle speed and record speeding license plates.},
booktitle = {2021 The 4th International Conference on Image and Graphics Processing},
pages = {73–79},
numpages = {7},
keywords = {Vehicle Speed Measurement, Deep Learning, License Plate Recognition},
location = {Sanya, China},
series = {ICIGP 2021}
}

@article{10.1145/3434398,
author = {Boukerche, Azzedine and Hou, Zhijun},
title = {Object Detection Using Deep Learning Methods in Traffic Scenarios},
year = {2021},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3434398},
doi = {10.1145/3434398},
abstract = {The recent boom of autonomous driving nowadays has made object detection in traffic scenes a hot topic of research. Designed to classify and locate instances in the image, this is a basic but challenging task in the computer vision field. With its powerful feature extraction abilities, which are vital for object detection, deep learning has expanded its application areas to this field during the past several years and thus achieved breakthroughs. However, even with such powerful approaches, traffic scenarios have their own specific challenges, such as real-time detection, changeable weather, and complex lighting conditions. This survey is dedicated to summarizing research and papers on applying deep learning to the transportation environment in recent years. More than 100 research papers are covered, and different aspects such as key generic object detection frameworks, categorized object detection applications in traffic scenario, evaluation metrics, and classified datasets are included. Some open research fields are also provided. We believe that it is the first survey focusing on deep learning-based object detection in traffic scenario.},
journal = {ACM Comput. Surv.},
month = {mar},
articleno = {30},
numpages = {35},
keywords = {convolutional neural networks, autonomous driving system, vehicle detection, deep learning, Object detection}
}

@inproceedings{10.1145/3293663.3297155,
author = {Al Shibli, Murad and Marques, Pascual and Spiridon, Elena},
title = {Artificial Intelligent Drone-Based Encrypted Machine Learning of Image Extraction Using Pretrained Convolutional Neural Network (CNN)},
year = {2018},
isbn = {9781450366410},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3293663.3297155},
doi = {10.1145/3293663.3297155},
abstract = {Recently Pretrained Convolutional Neural Networks (CNNs) have proven its effectiveness in image extraction and classification. This powerful feature of CNNs in image processing is facilitated by machine learning to train and classify big data. Image capturing and security transformation are considered as a central necessity of remote sensing imagery of unmanned aerial vehicles (UAVs) and drones. This paper presents a novel artificial intelligent drone-based encrypted machine learning of image classification using a pertained CNN and image encryption-decryption by utilizing singular value decomposition (SVD) and XOR-Secret-Key block cipher cryptology. Initially, pretrained convolutional neural networks (CNN) are extensively used to extract and classify image features making advantage of machine learning training tools features. Training of partial set of image data can be performed to test, classify and label the untrained image data. Pretrained CNN can classify images into object categories. Afterward, the CNN the classified image output is transformed into a digital matrix using SVD and identifies its associated eigenvalues. These eigenvalues are then converted into a binary code. The image data encryption is implemented according to suggested keys. The first part applies the exclusive OR (XOR) operation of the eigenvalues with a selected cipher key. Meanwhile, the second part implements the XOR operation of the output of part one with a randomly generated key using Poisson distribution. The last step in the encryption will be obtained by generating a non-real SVD decomposition matrix; according to which a non-readable image will be resulted. The original image-matrix can be constructed by reversing the process using the security key-cipher block (Poisson Distribution Key and Stand-alone Cipher Code). Finally, SVD image processing results are demonstrated to verify the effectiveness and security of the applied approach that can be implemented for different images.},
booktitle = {Proceedings of the 2018 International Conference on Artificial Intelligence and Virtual Reality},
pages = {72–82},
numpages = {11},
keywords = {Drone, Image extraction, Poisson Distribution, Cryptology, XOR, Pretrained convolutional neural networks, Machine learning, Artificial intelligent, SVD, CNN, UAV},
location = {Nagoya, Japan},
series = {AIVR 2018}
}

@inproceedings{10.5555/3237383.3238121,
author = {Nguyen, Hung The and Garratt, Matthew and Bui, Lam Thu and Abbass, Hussein},
title = {Apprenticeship Bootstrapping: Inverse Reinforcement Learning in a Multi-Skill UAV-UGV Coordination Task},
year = {2018},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Apprenticeship learning enables learning from human demonstrations performed on tasks. However, acquiring demonstrations in complex tasks where a human expert is not available can be a challenge. In this paper, we propose a new learning algorithm, called Apprenticeship bootstrapping via Inverse Reinforcement Learning using Deep Q-learning (ABS via IRL-DQN), to learn a complex task through using demonstrations performed on primitive sub-tasks. The algorithm is evaluated on an aerial and ground coordination scenario, where an Unmanned Aerial Vehicle (UAV) is required to maintain three Unmanned Ground Vehicles (UGVs) within a field of view of the UAV 's camera (FoV). The results show that performance of our proposed algorithm is comparable to that of a human, and competitive to the original IRL using expert demonstrations performed on the composite task.},
booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {2204–2206},
numpages = {3},
keywords = {apprenticeship learning, uavs, inverse reinforcement learning, ugvs, deep q-learning, ground-air interaction},
location = {Stockholm, Sweden},
series = {AAMAS '18}
}

@article{10.1145/3304104,
author = {Pilly, Praveen K. and Stepp, Nigel D. and Liapis, Yannis and Payton, David W. and Srinivasa, Narayan},
title = {Hypercolumn Sparsification for Low-Power Convolutional Neural Networks},
year = {2019},
issue_date = {April 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {1550-4832},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3304104},
doi = {10.1145/3304104},
abstract = {We provide here a novel method, called hypercolumn sparsification, to achieve high recognition performance for convolutional neural networks (CNNs) despite low-precision weights and activities during both training and test phases. This method is applicable to any CNN architecture that operates on signal patterns (e.g., audio, image, video) to extract information such as class membership. It operates on the stack of feature maps in each of the cascading feature matching and pooling layers through the processing hierarchy of the CNN by an explicit competitive process (k-WTA, winner take all) that generates a sparse feature vector at each spatial location. This principle is inspired by local brain circuits, where neurons tuned to respond to different patterns in the incoming signals from an upstream region inhibit each other using interneurons, such that only the ones that are maximally activated survive the quenching threshold. We show this process of sparsification is critical for probabilistic learning of low-precision weights and bias terms, thereby making pattern recognition amenable for energy-efficient hardware implementations. Further, we show that hypercolumn sparsification could lead to more data-efficient learning as well as having an emergent property of significantly pruning down the number of connections in the network. A theoretical account and empirical analysis are provided to understand these effects better.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = {mar},
articleno = {20},
numpages = {16},
keywords = {low precision, embedded systems, low energy, Convolutional neural networks, sparse, quantization, object recognition, machine learning}
}

@inproceedings{10.5555/3507788.3507815,
author = {Liu, Xiaotian and Armstrong, Victoria and Nabil, Sara and Muise, Christian},
title = {Exploring Multi-View Perspectives on Deep Reinforcement Learning Agents for Embodied Object Navigation in Virtual Home Environments},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {Recent years have brought the exploration of embodied reinforcement learning agents in a variety of domains. One of the advantages of artificial agents is that they can obtain visual inputs simultaneously using multiple input devices. This work explores multi-view reinforcement learning for object navigation tasks in 3D rendered virtual home environments using AI2-THOR. We trained CNN based Deep Q-learning embodied agents with egocentric, allocentric, and combined egocentric-allocentric perspectives to locate an object in an unknown environment. We compared the results of the three RL agents, and evaluated them by both reward improvement rate, and reward obtained. We demonstrate that the egocentric perspective allows for faster reward accumulation in the earlier episodes, whereas the allocentric agents obtained better long-term rewards. Interesting results arise from the combined allocentric and egocentric perspective, where we found that the agent had the best overall results by harnessing the benefits of each perspective. The results show that while single perspective embodied agents each have their own advantages, combining both inputs yields the best overall reward. Our findings provide a foundation and benchmark for building embodied RL agents with multi-view perspectives.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {190–195},
numpages = {6},
keywords = {deep reinforcement learning, computer vision, embodied agent, multi-view reinforcement learning, object navigation},
location = {Toronto, Canada},
series = {CASCON '21}
}

@inproceedings{10.1145/3501409.3501578,
author = {Zhou, Tongtong and Zheng, Lu and Peng, Yueping and Jiang, Rongqi},
title = {Research on Crowd Counting and Density Estimation Algorithms Based on Deep Learning},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3501409.3501578},
doi = {10.1145/3501409.3501578},
abstract = {Thanks to the rapid development of computer vision technology, methods based on deep learning have gradually replaced counting methods based on traditional machine learning, and substantial progress has been made in counting accuracy and real-time detection. Firstly, the research background and application fields of target counting are introduced. Secondly, according to the classification of model tasks, the deep learning hotspot models are classified into three categories, and the crowd density estimation algorithms based on multi-scale strategies, multi-stage models and attention mechanisms, and multi-feature fusion are introduced from different perspectives. An introduction to the three algorithm models. Finally, it summarizes the shortcomings of the current target counting model, and looks forward to the future research directions.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {939–945},
numpages = {7},
keywords = {crowd density, attention mechanism, multi-scale strategy, multi-feature fusion, model introduction, deep learning},
location = {Xiamen, China},
series = {EITCE 2021}
}

@inproceedings{10.1145/3363384.3363392,
author = {Benerradi, Johann and A. Maior, Horia and Marinescu, Adrian and Clos, Jeremie and L. Wilson, Max},
title = {Exploring Machine Learning Approaches for Classifying Mental Workload Using FNIRS Data from HCI Tasks},
year = {2019},
isbn = {9781450372039},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3363384.3363392},
doi = {10.1145/3363384.3363392},
abstract = {Functional Near-Infrared Spectroscopy (fNIRS) has shown promise for being potentially more suitable (than e.g. EEG) for brain-based Human Computer Interaction (HCI). While some machine learning approaches have been used in prior HCI work, this paper explores different approaches and configurations for classifying Mental Workload (MWL) from a continuous HCI task, to identify and understand potential limitations and data processing decisions. In particular, we investigate three overall approaches: a logistic regression method, a supervised shallow method (SVM), and a supervised deep learning method (CNN). We examine personalised and generalised models, as well as consider different features and ways of labelling the data. Our initial explorations show that generalised models can perform as well as personalised ones and that deep learning can be a suitable approach for medium size datasets. To provide additional practical advice for future brain-computer interaction systems, we conclude by discussing the limitations and data-preparation needs of different machine learning approaches. We also make recommendations for avenues of future work that are most promising for the machine learning of fNIRS data. },
booktitle = {Proceedings of the Halfway to the Future Symposium 2019},
articleno = {8},
numpages = {11},
keywords = {Deep Learning, fNIRS, Machine Learning, Mental Workload},
location = {Nottingham, United Kingdom},
series = {HTTF 2019}
}

@inproceedings{10.1145/3220228.3220242,
author = {Hru\v{s}ka, Jon\'{a}\v{s} and Ad\~{a}o, Telmo and P\'{a}dua, Lu\'{\i}s and Marques, Pedro and Cunha, Ant\'{o}nio and Peres, Emanuel and Sousa, Ant\'{o}nio and Morais, Raul and Sousa, Joaquim J.},
title = {Machine Learning Classification Methods in Hyperspectral Data Processing for Agricultural Applications},
year = {2018},
isbn = {9781450364454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3220228.3220242},
doi = {10.1145/3220228.3220242},
abstract = {In agricultural applications hyperspectral imaging is used in cases where differences in spectral reflectance of the examined objects are small. However, the large amount of data generated by hyperspectral sensors requires advance processing methods. Machine learning approaches may play an important role in this task. They are known for decades, but they need high volume of data to compute accurate results. Until recently, the availability of hyperspectral data was a big drawback. It was first used in satellites, later in manned aircrafts and data availability from those platforms was limited because of logistics complexity and high price. Nowadays, hyperspectral sensors are available for unmanned aerial vehicles, which enabled to reach a high volume of data, thus overcoming these issues. This way, the aim of this paper is to present the status of the usage of machine learning approaches in the hyperspectral data processing, with a focus on agriculture applications. Nevertheless, there are not many studies available applying machine learning approach to hyperspectral data for agricultural applications. This apparent limitation was in fact the inspiration for making this survey. Preliminary results using UAV-based data are presented, showing the suitability of machine learning techniques in remote sensed data.},
booktitle = {Proceedings of the International Conference on Geoinformatics and Data Analysis},
pages = {137–141},
numpages = {5},
keywords = {remote sensing, agriculture, deep learning, hyperspectral data, machine learning},
location = {Prague, Czech Republic},
series = {ICGDA '18}
}

@inproceedings{10.5555/2343576.2343636,
author = {Teacy, W. T. L. and Chalkiadakis, G. and Farinelli, A. and Rogers, A. and Jennings, N. R. and McClean, S. and Parr, G.},
title = {Decentralized Bayesian Reinforcement Learning for Online Agent Collaboration},
year = {2012},
isbn = {0981738117},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Solving complex but structured problems in a decentralized manner via multiagent collaboration has received much attention in recent years. This is natural, as on one hand, multiagent systems usually possess a structure that determines the allowable interactions among the agents; and on the other hand, the single most pressing need in a cooperative multiagent system is to coordinate the local policies of autonomous agents with restricted capabilities to serve a system-wide goal. The presence of uncertainty makes this even more challenging, as the agents face the additional need to learn the unknown environment parameters while forming (and following) local policies in an online fashion. In this paper, we provide the first Bayesian reinforcement learning (BRL) approach for distributed coordination and learning in a cooperative multiagent system by devising two solutions to this type of problem. More specifically, we show how the Value of Perfect Information (VPI) can be used to perform efficient decentralised exploration in both model-based and model-free BRL, and in the latter case, provide a closed form solution for VPI, correcting a decade old result by Dearden, Friedman and Russell. To evaluate these solutions, we present experimental results comparing their relative merits, and demonstrate empirically that both solutions outperform an existing multiagent learning method, representative of the state-of-the-art.},
booktitle = {Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems - Volume 1},
pages = {417–424},
numpages = {8},
keywords = {uncertainty, Bayesian techniques, multiagent learning},
location = {Valencia, Spain},
series = {AAMAS '12}
}

@inproceedings{10.1145/3501409.3501673,
author = {Wu, Fan and Zong, Yantao and Zhao, Rui and Yu, Tianyi and Tang, Xiaqing and He, Ximing},
title = {Visual Odometery for UAV Navigation Based on Deep Learning},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3501409.3501673},
doi = {10.1145/3501409.3501673},
abstract = {Taking UAV as the application background, this paper studies the visual odometery for deep learning in UAV navigation. Firstly, the dataset FLYING is made through UAV aerial photography. Secondly, pretraining and testing the established G-LSTM VO and attention VO models through the KITTI dataset. Thirdly, by means of transfer learning, training and testing the pre trained model based on FLYING dataset. Finally, the model is tested. The performance of the model in UAV mission is analyzed from the aspects of trajectory, pose estimation accuracy and algorithm time-consuming. The experimental results show that the monocular visual odometery method based on depth neural network is effective in the field of UAV navigation.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1493–1501},
numpages = {9},
keywords = {Attention mechanism, Convolutional neural network, Recurrent neural network, Visual odometery},
location = {Xiamen, China},
series = {EITCE 2021}
}

@inproceedings{10.1145/3487923.3487926,
author = {Ukaegbu, Uchechi F. and Tartibu, Lagouge K. and Okwu, Modestus O. and Olayode, Isaac O.},
title = {Deep Learning Application in Diverse Fields with Plant Weed Detection as a Case Study},
year = {2021},
isbn = {9781450385756},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3487923.3487926},
doi = {10.1145/3487923.3487926},
abstract = {Machine learning applications have gained popularity over the years as more advanced algorithms like the deep learning (DL) algorithm are being employed in signal identification, classification and detection of cracks or faults in structures. The DL algorithm has broader applications compared to other machine learning systems and it is a creative algorithm capable of processing data, creating pattern, interpreting information due to its high level of accuracy in pattern recognition under stochastic conditions. This research gives an exposition of DL in diverse areas of operations with a focus on plant weed detection which is inspired by the need to treat a specific class of weed with a particular herbicide. A Convolutional Neural Network (CNN) model was trained through transfer learning on a pre-trained ResNet50 model and the performance was evaluated using a random forest (RF) classifier, the trained model was deployed on a raspberry pi for prediction of the test data. Training accuracies of 99% and 93% were obtained for the CNN and RF classifier respectively. Some recommendations have been proffered to improve inference time such as the use of better embedded systems such as the Nvidia Jetson TX2, synchronizing DL hardware accelerators with appropriate optimization techniques. A prospect of this work would be to incorporate an embedded system, deployed with DL algorithms, on an unmanned aerial vehicle or ground vehicle. Overall, it is revealed from this study that DL is highly efficient in every sector and can improve the accuracy on automatic detection of systems in especially in this era of Industry 4.0.},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Its Applications},
articleno = {3},
numpages = {9},
keywords = {Deep learning algorithm, Convolutional neural network, Random forest, Agriculture, fourth industrial revolution},
location = {Virtual Event, Mauritius},
series = {icARTi '21}
}

@inproceedings{10.1145/3454127.3457632,
author = {Benbarrad, Tajeddine and Salhaoui, Marouane and Arioua, Mounir},
title = {On the Performance of Deep Learning in the Full Edge and the Full Cloud Architectures},
year = {2021},
isbn = {9781450388719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3454127.3457632},
doi = {10.1145/3454127.3457632},
abstract = {Deep learning today surpasses various machine learning approaches in performance and is widely used for variety of different tasks. Deep learning has increased accuracy compared to other approaches for tasks like language translation and image recognition. However, training a deep learning model on a large dataset is a challenging and expensive task that can be time consuming and require large computational resources. Therefore, Different architectures have been proposed for the implementation of deep learning models in machine vision systems to deal with this problem. Currently, the application of deep learning in the cloud is the most common and typical method. Nevertheless, the challenge of having to move the data from where it is generated to a cloud data center so that it can be used to prepare and develop machine learning models represents a major limitation of this approach. As a result, it is becoming increasingly important to consider moving aspects of deep learning to the edge, instead of the cloud, especially with the rapid increase in data volumes and the growing need to act in real time. From this perspective, a comparative study between the full edge and the full cloud architectures based on the performance of the deep learning models implemented in both architectures is elaborated. The results of this study lead us to specify the strengths of both the cloud and the edge for deploying deep learning models, and to choose the optimal architecture to deal with the rapid increase in data volumes and the growing need for real-time action.},
booktitle = {Proceedings of the 4th International Conference on Networking, Information Systems &amp; Security},
articleno = {57},
numpages = {7},
keywords = {Deep learning, Full cloud, Full edge, Machine vision},
location = {KENITRA, AA, Morocco},
series = {NISS2021}
}

@article{10.1145/2735392.2735396,
author = {Faust, Aleksandra},
title = {Reinforcement Learning and Planning for Preference Balancing Tasks},
year = {2015},
issue_date = {March 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {3},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2735392.2735396},
doi = {10.1145/2735392.2735396},
abstract = {Many robotic motion tasks, such as UAV control, have non-linear and high-dimensional dynamics. Difficult for both human demonstration and explicit solutions, these tasks can be described with opposing preferences. This thesis develops PEARL, a real-time solution for such tasks on acceleration-controlled systems with unknown dynamics, and finds PEARL's safety conditions.},
journal = {AI Matters},
month = {mar},
pages = {8–12},
numpages = {5}
}

@inproceedings{10.1145/3297280.3297408,
author = {Ahmad, Qadeer and Rafiq, Atif and Raja, Muhammad Adil and Javed, Noman},
title = {Evolving MIMO Multi-Layered Artificial Neural Networks Using Grammatical Evolution},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3297280.3297408},
doi = {10.1145/3297280.3297408},
abstract = {In this paper, we propose a scheme for evolving multiple-input-multiple-output (MIMO) artificial neural networks (ANNs) using grammatical evolution (GE). GE is a well-known technique for program evolution. While it has also been used for the evolution of ANN structures in the past, little work is reported on the evolution of MIMO ANNs.MIMO ANNs are important for problems that have multiple outputs. Examples are controllers for autonomous systems such as unmanned aerial vehicles (UAVs) and driver-less cars that take in multiple inputs and are expected to produce multiple outputs simultaneously such as speed, steering etc. Certain regression problems are also MIMO in nature. Our results are promising.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1278–1285},
numpages = {8},
keywords = {grammatical evolution, neural networks},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3443467.3443855,
author = {Zhang, Xiaoyan and Wang, Xiaodong},
title = {An Effective Bridge Cracks Classification Method Based on Machine Learning},
year = {2020},
isbn = {9781450387811},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3443467.3443855},
doi = {10.1145/3443467.3443855},
abstract = {Crack is the most common threat to the safety of bridges. Historical data show that the safety accidents caused by cracks account for more than 90% of the total bridge disasters. After a long period of engineering practice and rigorous theoretical analysis, it was found that 0.3 mm is the maximum allowable for bridge cracks. If the width exceeds the limit, the integrity of the bridge will be destroyed, and even a collapse accident will occur. Therefore, it is important to identify cracks in bridge structure effectively and provide information for structural disaster reduction projects in time. With the development of machine learning, bridge crack detection and classification based on deep learning has been paid more attention. This paper designs a bridge crack classification algorithm based on convolution neural network and support vector machine. Firstly, the captured image data are divided into training set and test set. Secondly, they are preprocessing and extracted features by convolution neural network. Lastly, they are classified by SVM. The proposed algorithm can solve the problems of insufficient samples and low classification accuracy, and realizes the effective and accurate classification.},
booktitle = {Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering},
pages = {790–794},
numpages = {5},
keywords = {Bridge crack, Machine learning, Convolution neural network, Support vector machine},
location = {Xiamen, China},
series = {EITCE 2020}
}

@inproceedings{10.1145/3458305.3478446,
author = {Richter, David J. and Calix, Ricardo A.},
title = {QPlane: An Open-Source Reinforcement Learning Toolkit for Autonomous Fixed Wing Aircraft Simulation},
year = {2021},
isbn = {9781450384346},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3458305.3478446},
doi = {10.1145/3458305.3478446},
abstract = {Reinforcement Learning (RL) is a fast-growing field of research that is mostly applied in the realm of video games due to the compatibility of RL and game tasks. AI Gym has established itself as the gold standard toolkit for Reinforcement Learning research. Unfortunately, toolkits like AI Gym are very optimized for benchmark purposes and may not always be suitable for real world type problems. Additionally, fixed wing flight simulation has specific requirements and may need other solutions. In this paper, we propose QPlane as an alternative toolkit for RL training of fixed wing aircraft. QPlane was developed in an effort to create a RL toolkit for fixed wing aircraft simulation that is easily modifiable for different scenarios. QPlane is replicable and flexible for ease of implementation to high performance computing, and is modular for quick environment and algorithm replacement. In this paper we present and discuss details of QPlane, as well as proof of concept results.},
booktitle = {Proceedings of the 12th ACM Multimedia Systems Conference},
pages = {261–266},
numpages = {6},
keywords = {aviation, deep learning, reinforcement learning, artificial intelligence},
location = {Istanbul, Turkey},
series = {MMSys '21}
}

@inproceedings{10.1145/3447587.3447590,
author = {Symeonidis, Charalampos and Kakaletsis, Efstratios and Mademlis, Ioannis and Nikolaidis, Nikos and Tefas, Anastasios and Pitas, Ioannis},
title = {Vision-Based UAV Safe Landing Exploiting Lightweight Deep Neural Networks},
year = {2021},
isbn = {9781450389105},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3447587.3447590},
doi = {10.1145/3447587.3447590},
abstract = {Recent advances in artificial intelligence, control and sensing technologies have facilitated the development of autonomous Unmanned Aerial Vehicles (UAVs, or drones) able to self-navigate in various settings. Although these technologies have already entered a mature stage, ensuring flight safety in crowded areas or performing an emergency landing in case of malfunctions, while adhering to relevant legislation, is generally treated as an afterthought when designing autonomous UAV platforms for unstructured environments. This paper proposes a UAV safe landing navigation pipeline that relies on lightweight computer vision modules, able to be executed on the limited computational resources on-board a typical UAV. Pre-trained Deep Neural Networks (DNNs) are mainly employed as the underlying building blocks, since deep learning has made a major impact on robotic perception by drastically improving the performance of relevant tasks, such as object detection or tracking, semantic image segmentation, etc. Evaluation of the proposed pipeline on a simulated environment indicates highly favorable results.},
booktitle = {2021 The 4th International Conference on Image and Graphics Processing},
pages = {13–19},
numpages = {7},
keywords = {path planning, autonomous drones, semantic image segmentation, object detection, robot navigation, UAV safe landing},
location = {Sanya, China},
series = {ICIGP 2021}
}

@inproceedings{10.1145/3274895.3274901,
author = {Xie, Yiqun and Bhojwani, Rahul and Shekhar, Shashi and Knight, Joseph},
title = {An Unsupervised Augmentation Framework for Deep Learning Based Geospatial Object Detection: A Summary of Results},
year = {2018},
isbn = {9781450358897},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3274895.3274901},
doi = {10.1145/3274895.3274901},
abstract = {Given remote sensing datasets in a spatial domain, we aim to detect geospatial objects with minimum bounding rectangles (i.e., angle-aware) leveraging deep learning frameworks. Geospatial objects (e.g., buildings, vehicles, farms) provide meaningful information for a variety of societal applications, including urban planning, census, sustainable development, security surveillance, agricultural management, etc. The detection of these objects are challenging because their directions are often heavily mixed and not parallel to the orthogonal directions of an image frame due to topography, planning, etc. In addition, there is very limited training data with angle information for most types of objects. In related work, state-of-the-art deep learning frameworks detect objects using orthogonal bounding rectangles (i.e., sides are parallel to the sides of an input image), so they cannot identify the directions of objects and generate loose rectangular bounds on objects. We propose an Unsupervised Augmentation (UA) framework to detect geospatial objects with general minimum bounding rectangles (i.e., with angles). The UA framework contains two schemes, namely a ROtation-Vector (ROV) based scheme and a context-based scheme. The schemes completely avoid the need for: (1) additional ground-truth data with annotated angles; (2) restructuring of existing network architectures; and (3) re-training. Experimental results show that the UA framework can well approximate the angles of objects and generate much tighter bounding boxes on objects.},
booktitle = {Proceedings of the 26th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems},
pages = {349–358},
numpages = {10},
keywords = {rectangles, rotations, geospatial objects, deep learning, remote sensing},
location = {Seattle, Washington},
series = {SIGSPATIAL '18}
}

@inproceedings{10.1145/3467707.3467714,
author = {Wu, Qiang and Wu, Xuegang and Zheng, Xin and Yue, Bin},
title = {Research on UAV Detection of Threat Target around Oil Pipeline Based on Deep Learning},
year = {2021},
isbn = {9781450389501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3467707.3467714},
doi = {10.1145/3467707.3467714},
abstract = {With the development of UAV, UAV has been applied to various projects with its advantages of low construction cost,low safety risk coefficient and convenient operation.In terms of UAV platform, currently composite wing and multi-rotor UAV are typically adopted, which can realize basic flight route. In terms of image detection, neural network is mainly used to classify and recognize the target in the image. In this paper, the YOLOV4 algorithm is improved to make it more suitable for UAV detection of ground targets.In the ground detection of UAV, most of them are small targets, so clustering method is used to redesign anchor for small targets. Because the features of small targets have more details in the shallow feature layer, the shallow feature is superimposed into the feature extraction layer, and the shallow feature and the deep feature are fused.In the data processing, data enhancement, color dithering, flipping, cutting of the data set for expansion. Through the test of the modified network, the following results are obtained: the overall mAP is improved by 9.3%, the detection mAP for small targets such as people is improved by 23.75%, and the detection mAP for working vehicles is improved by 15.4%. The detection efficiency of small targets is improved, and the speed can meet the real-time requirements, and it can be deployed in the UAV for UAV detection.},
booktitle = {2021 7th International Conference on Computing and Artificial Intelligence},
pages = {48–56},
numpages = {9},
keywords = {TargetDetection, Pipeline Inspection, YOLO UAV},
location = {Tianjin, China},
series = {ICCAI 2021}
}

@article{10.1145/3453155,
author = {Luo, Yuan and Xiao, Ya and Cheng, Long and Peng, Guojun and Yao, Danfeng (Daphne)},
title = {Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities},
year = {2021},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3453155},
doi = {10.1145/3453155},
abstract = {Anomaly detection is crucial to ensure the security of cyber-physical systems (CPS). However, due to the increasing complexity of CPSs and more sophisticated attacks, conventional anomaly detection methods, which face the growing volume of data and need domain-specific knowledge, cannot be directly applied to address these challenges. To this end, deep learning-based anomaly detection (DLAD) methods have been proposed. In this article, we review state-of-the-art DLAD methods in CPSs. We propose a taxonomy in terms of the type of anomalies, strategies, implementation, and evaluation metrics to understand the essential properties of current methods. Further, we utilize this taxonomy to identify and highlight new characteristics and designs in each CPS domain. Also, we discuss the limitations and open problems of these methods. Moreover, to give users insights into choosing proper DLAD methods in practice, we experimentally explore the characteristics of typical neural models, the workflow of DLAD methods, and the running performance of DL models. Finally, we discuss the deficiencies of DL approaches, our findings, and possible directions to improve DLAD methods and motivate future research.},
journal = {ACM Comput. Surv.},
month = {may},
articleno = {106},
numpages = {36},
keywords = {anomaly detection, cyber-physical systems, Deep learning}
}

@article{10.1145/3466618,
author = {Mysore, Siddharth and Mabsout, Bassel and Saenko, Kate and Mancuso, Renato},
title = {How to Train Your Quadrotor: A Framework for Consistently Smooth and Responsive Flight Control via Reinforcement Learning},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {2378-962X},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3466618},
doi = {10.1145/3466618},
abstract = {We focus on the problem of reliably training Reinforcement Learning (RL) models (agents) for stable low-level control in embedded systems and test our methods on a high-performance, custom-built quadrotor platform. A common but often under-studied problem in developing RL agents for continuous control is that the control policies developed are not always smooth. This lack of smoothness can be a major problem when learning controllers as it can result in control instability and hardware failure.Issues of noisy control are further accentuated when training RL agents in simulation due to simulators ultimately being imperfect representations of reality—what is known as the reality gap. To combat issues of instability in RL agents, we propose a systematic framework, REinforcement-based transferable Agents through Learning (RE+AL), for designing simulated training environments that preserve the quality of trained agents when transferred to real platforms. RE+AL is an evolution of the Neuroflight infrastructure detailed in technical reports prepared by members of our research group. Neuroflight is a state-of-the-art framework for training RL agents for low-level attitude control. RE+AL improves and completes Neuroflight by solving a number of important limitations that hindered the deployment of Neuroflight to real hardware. We benchmark RE+AL on the NF1 racing quadrotor developed as part of Neuroflight. We demonstrate that RE+AL significantly mitigates the previously observed issues of smoothness in RL agents. Additionally, RE+AL is shown to consistently train agents that are flight capable and with minimal degradation in controller quality upon transfer. RE+AL agents also learn to perform better than a tuned PID controller, with better tracking errors, smoother control, and reduced power consumption. To the best of our knowledge, RE+AL agents are the first RL-based controllers trained in simulation to outperform a well-tuned PID controller on a real-world controls problem that is solvable with classical control.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = {sep},
articleno = {36},
numpages = {24},
keywords = {continuous control, Neural networks, quadrotor}
}

@inproceedings{10.1145/3501409.3501507,
author = {Liu, Zhengcheng and Qi, Yongmei and Dai, Xiao},
title = {Radar Plot Classification Based on Machine Learning},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3501409.3501507},
doi = {10.1145/3501409.3501507},
abstract = {Clutter is the inherent environment of radar signal detection and processing. On the one hand, too many clutter points will start a false track, on the other hand, clutter plots will be incorrectly associated with the track, resulting in track errors. Therefore, how to further distinguish target plots and clutter plots after target detection is an important and difficult problem in radar data processing. Aiming at the clutter data mixed in the plot data output by signal processing, this paper extracts the multi-dimensional feature parameters of radar plot on the radar measured data set, classifies the radar real target and false target by using the traditional support vector machine, fully connected neural network and convolution neural network respectively, and compares the effects of three different classification methods.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {537–541},
numpages = {5},
keywords = {Support vector machine, Plot classification, Convolutional neural network, Fully connected neural network},
location = {Xiamen, China},
series = {EITCE 2021}
}

@inproceedings{10.1145/3366194.3366251,
author = {Yang, Songyue and Meng, Zhijun and Chen, Xuzhi and Xie, Ronglei},
title = {Real-Time Obstacle Avoidance with Deep Reinforcement Learning Three-Dimensional Autonomous Obstacle Avoidance for UAV},
year = {2019},
isbn = {9781450372985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3366194.3366251},
doi = {10.1145/3366194.3366251},
abstract = {At present, drones are rapidly developing in the aviation industry and are applied to all aspects of life. However, letting drones autonomously avoid obstacles is still the focus of research by aviation scholars at this stage. However, the current automation is mostly based on human experience to determine the obstacle avoidance strategy of UAV. And the method only rely on the machine to avoid obstacle is very few. In this paper, the UAV collect visual and distance sensor information to make autonomous obstacle avoidance decision through the deep reinforcement learning algorithm, and the algorithm is tested in the v-rep simulation environment.},
booktitle = {Proceedings of the 2019 International Conference on Robotics, Intelligent Control and Artificial Intelligence},
pages = {324–329},
numpages = {6},
keywords = {v-rep, aircraft, obstacle avoidance, DQN},
location = {Shanghai, China},
series = {RICAI 2019}
}

@inproceedings{10.1145/3461353.3461373,
author = {Gong, Peng and Shi, Dianxi and Xue, Chao and Chen, Xucan},
title = {A Domain Data Pattern Randomization Based Deep Reinforcement Learning Method for Sim-to-Real Transfer},
year = {2021},
isbn = {9781450388634},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3461353.3461373},
doi = {10.1145/3461353.3461373},
abstract = { Transferring reinforcement learning policies trained in a physical simulator to the real world is a highly challenging problem, because the gap between the simulation and reality, usually causes the transferred model to perform poorly in the real world. Many algorithms including domain randomization, have been proposed to try to bridge the gap between simulation and reality. However, most of them are to change the value of the corresponding data by superimposing gaussian noise on robot dynamics parameters or environmental data. Such policies often fail to solve the problem of long-term/intermittent missing data patterns caused by sensor failures in the actual operation of the robot. Faced with this problem, we proposed a memory-enhanced domain data pattern randomization method. This method achieves data enhancement by randomizing the distribution pattern of data connection, at the same time, the memory mechanism based on recurrent neural network is introduced into the decision model, to alleviate the jitter of environmental distribution caused by data pattern changes, so as to improve the decision-making ability of the robot in some observable scenes triggered by the change of data pattern.},
booktitle = {2021 the 5th International Conference on Innovation in Artificial Intelligence},
pages = {1–7},
numpages = {7},
keywords = {Deep Reinforcement Learning, Domain Randomization, Recurrent Neural Network, Sim to Real, Data Pattern},
location = {Xia men, China},
series = {ICIAI 2021}
}

@article{10.1007/s00165-021-00553-4,
author = {Tran, Hoang-Dung and Pal, Neelanjana and Lopez, Diego Manzanas and Musau, Patrick and Yang, Xiaodong and Nguyen, Luan Viet and Xiang, Weiming and Bak, Stanley and Johnson, Taylor T.},
title = {Verification of Piecewise Deep Neural Networks: A Star Set Approach with Zonotope Pre-Filter},
year = {2021},
issue_date = {Aug 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {4–5},
issn = {0934-5043},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1007/s00165-021-00553-4},
doi = {10.1007/s00165-021-00553-4},
abstract = {Verification has emerged as a means to provide formal guarantees on
learning-based systems incorporating neural network before using
them in safety-critical applications. This paper proposes a new
verification approach for deep neural networks (DNNs) with piecewise
linear activation functions using reachability analysis. The core of
our approach is a collection of reachability algorithms using star
sets (or shortly, stars), an effective symbolic representation of
high-dimensional polytopes. The star-based reachability algorithms
compute the output reachable sets of a network with a given input
set before using them for verification. For a neural network with
piecewise linear activation functions, our approach can construct
both exact and over-approximate reachable sets of the neural
network. To enhance the scalability of our approach, a star set is
equipped with an outer-zonotope (a zonotope over-approximation of
the star set) to quickly estimate the lower and upper bounds of an
input set at a specific neuron to determine if splitting occurs at
that neuron. This zonotope pre-filtering step reduces significantly
the number of linear programming optimization problems that
must be solved in the analysis, and leads to a reduction in
computation time, which enhances the scalability of the star set
approach. Our reachability algorithms are implemented in a software
prototype called the neural network verification tool, and can
be applied to problems analyzing the robustness of machine learning
methods, such as safety and robustness verification of DNNs. Our
experiments show that our approach can achieve runtimes twenty to
1400 times faster than Reluplex, a satisfiability modulo
theory-based approach. Our star set approach is also less
conservative than other recent zonotope and abstract domain
approaches.
},
journal = {Form. Asp. Comput.},
month = {aug},
pages = {519–545},
numpages = {27},
keywords = {Robustness, Neural networks, Safety, Formal verification, Neural network verification}
}

@inproceedings{10.1145/3378184.3378185,
author = {Greco, Antonio and Pironti, Christopher and Saggese, Alessia and Vento, Mario and Vigilante, Vincenzo},
title = {A Deep Learning Based Approach for Detecting Panels in Photovoltaic Plants},
year = {2020},
isbn = {9781450376303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3378184.3378185},
doi = {10.1145/3378184.3378185},
abstract = {Photovoltaic (PV) panels are a clean and widespread way to produce renewable energy from sunlight; at the same time, such plants require maintenance, since solar panels can be affected by many types of damaging factors and have a limited yet variable lifespan. With the impressive growth of such PV installations, it is in the public eye the need of a cheap and effective way to continuously monitor the state of the plants and a standard technique designed to promptly replace broken modules, in order to prevent drops in the energy production. Since the faults mainly appear as Hot Spots on the surface of the PV panels, aerial thermal imaging can be used to diagnose such problems and also locate them in huge plants. To this aim, dedicated automatic Computer Vision methods are able to automatically find hot spots from thermal images, where they appear as white stains. In these methods a fundamental step is the segmentation of the PV panels, which allows to automatically detect each module.In this paper, we address the problem of PV Panel Detection using a Convolutional Neural Network framework called YOLO. We demonstrate that it is able to effectively and efficiently segment panels from an image. The method is quantitatively evaluated and compared to existing PV panel detection approaches on the biggest publicly available benchmark dataset; the experimental results confirm its robustness.},
booktitle = {Proceedings of the 3rd International Conference on Applications of Intelligent Systems},
articleno = {1},
numpages = {7},
keywords = {deep learning, object detection, UAV, photovoltaic},
location = {Las Palmas de Gran Canaria, Spain},
series = {APPIS 2020}
}


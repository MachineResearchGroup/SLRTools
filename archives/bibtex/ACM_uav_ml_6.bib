@inproceedings{10.1145/3467707.3467756,
author = {Jia, Weisheng and Cui, Jinling and Zheng, Xin and Wu, Qiang},
title = {Design and Implementation of Real-Time Semantic Segmentation Network Based on FPGA},
year = {2021},
isbn = {9781450389501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3467707.3467756},
doi = {10.1145/3467707.3467756},
abstract = {With the rapid development of deep learning, the neural network of semantic segmentation has been developed towards the miniaturization of the network structure and the lightweight development of the network model. At the same time, FPGA-based neural network hardware accelerators have been proposed. The situation that the network module is too complex and computationally intensive to implement and apply on edge platforms is gradually being solved. However, the implementation of real-time processing network on the edge platform is still of great significance in many areas, such as robots, UAVs, driverless, etc. In this paper, a lightweight semantically segmented neural network Efficient neural network (E-Net) is designed and implemented on the image acquisition board with Zynq 7035 FPGA as processing unit, which achieves the frame rate of 32.9 FPS and meets the requirements of real-time processing.},
booktitle = {2021 7th International Conference on Computing and Artificial Intelligence},
pages = {321–325},
numpages = {5},
keywords = {Field Programmable Gate Array (FPGA), Efficient neural network (E-Net), Edge Computing, Zynq},
location = {Tianjin, China},
series = {ICCAI 2021}
}

@inproceedings{10.5555/3398761.3399117,
author = {Bondi, Elizabeth},
title = {Vision for Decisions: Utilizing Uncertain Real-Time Information and Signaling for Conservation},
year = {2020},
isbn = {9781450375184},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Recent advances in fields such as computer vision and natural language processing have created new opportunities for developing agents that can automatically interpret their environment. Concurrently, advances in artificial intelligence have made the coordination of many such agents possible. However, there is little work considering both the low-level reasoning that allows agents to interpret their environment, such as deep learning techniques, and the high-level reasoning that coordinates such agents. By considering both together, we can better handle real-world scenarios. We will describe a real-world deployment of conservation drones to illustrate this point.},
booktitle = {Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {2179–2181},
numpages = {3},
keywords = {computational sustainability, uncertainty, sensors, conservation, unmanned aerial vehicles, security games},
location = {Auckland, New Zealand},
series = {AAMAS '20}
}

@inproceedings{10.1145/3340555.3353732,
author = {Fahim, Md Abdullah Al and Khan, Mohammad Maifi Hasan and Jensen, Theodore and Albayram, Yusuf and Coman, Emil and Buck, Ross},
title = {Effect of Feedback on Users’ Immediate Emotions: Analysis of Facial Expressions during a Simulated Target Detection Task},
year = {2019},
isbn = {9781450368605},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3340555.3353732},
doi = {10.1145/3340555.3353732},
abstract = {Safety-critical systems (e.g., UAV systems) often incorporate warning modules that alert users regarding imminent hazards (e.g., system failures). However, these warning systems are often not perfect, and trigger false alarms, which can lead to negative emotions and affect subsequent system usage. Although various feedback mechanisms have been studied in the past to counter the possible negative effects of system errors, the effect of such feedback mechanisms and system errors on users’ immediate emotions and task performance is not clear. To investigate the influence of affective feedback on participants’ immediate emotions, we designed a 2 (warning reliability: high/low) \texttimes{} 2 (feedback: present/absent) between-group study where participants interacted with a simulated UAV system to identify and neutralize enemy vehicles under time constraint. Task performance along with participants’ facial expressions were analyzed. Results indicated that giving feedback decreased fear emotions during the task whereas warning increased frustration for high reliability groups compared to low reliability groups. Finally, feedback was found not to affect task performance. },
booktitle = {2019 International Conference on Multimodal Interaction},
pages = {49–58},
numpages = {10},
keywords = {Emotion, Facial Expression, Safety-critical Systems, Affective Computing, Warning},
location = {Suzhou, China},
series = {ICMI '19}
}

@inproceedings{10.1145/3307363.3307398,
author = {Miyamoto, Ryusuke and Migita, Yuta and Izumo, Shunya and Kobayashi, Shingo and Oki, Takuro and Yomo, Hiroyuki and Hara, Shinsuke},
title = {Implementation of a CG-Based Simulator to Evaluate Dynamic Relocation of UAVs in Image-Assisted Routing},
year = {2019},
isbn = {9781450366199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3307363.3307398},
doi = {10.1145/3307363.3307398},
abstract = {The authors are trying to construct a real-time vital sensing system during exercise based on image-assisted routing. In order to estimate locations of target exercisers based on image processing required for multi-hop networking, robust personal identification is indispensable because visual target tracking executed after detection sometimes fails in practical scenes. To solve this problem, dynamic relocation of UAVs to obtain visual cues to identify who is a target is adopted to our system. In this paper, a CG-based simulator that has functions necessary for evaluation of dynamic relocation algorithm of UAVs. Experimental results using a basic scenario show that the implemented simulator works well.},
booktitle = {Proceedings of the 11th International Conference on Computer Modeling and Simulation},
pages = {254–258},
numpages = {5},
keywords = {visual object localization, A CG-based simulator, image-assisted routing},
location = {North Rockhampton, QLD, Australia},
series = {ICCMS 2019}
}

@inproceedings{10.1145/3360322.3360835,
author = {Li, Xiaoxia and Li, Wei and Yang, Qiang and Yan, Wenjun and Zomaya, Albert Y.},
title = {Building an Online Defect Detection System for Large-Scale Photovoltaic Plants},
year = {2019},
isbn = {9781450370059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3360322.3360835},
doi = {10.1145/3360322.3360835},
abstract = {The power efficiency of photovoltaic modules is highly correlated with their health status. Under dynamically changing environments, photovoltaic defects could spontaneously form and develop into fatal faults during the daily operation of photovoltaic plants. To facilitate defect detection with less human intervention, a nondestructive and contactless visual inspection system with the help of unmanned aerial vehicles and edge computing is proposed in this work. Limited by the resources of edge devices and the availability of images of photovoltaic defects for training, we developed an online solution combined with deep learning, data argumentation and transfer learning to properly address the issues of running resource hungry applications on edge devices and lack of training samples faced by the deep learning approaches used in the field. With the reduction of the network depth of the deep convolutional neural network model and the transfer of features from the learned defects, the resource consumption of our proposed approach is significantly reduced, and thus can be used on a wide range of edge devices to complete defect detection in a timely manner with high accuracy. To study the performance of our design, a testbed was built from open source hardware and software, and field trials were carried out in three photovoltaic plants. The experimental results clearly demonstrate the practicality and effectiveness of our design for detecting visible defects on photovoltaic modules.},
booktitle = {Proceedings of the 6th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {253–262},
numpages = {10},
keywords = {defects detection, cyber-physical systems, transfer learning, edge computing, classification},
location = {New York, NY, USA},
series = {BuildSys '19}
}

@inproceedings{10.1145/3478586.3478608,
author = {Katiyar, Shubhi and Dutta, Ashish},
title = {PSO Based Path Planning and Dynamic Obstacle Avoidance in CG Space of a 10 DOF Rover},
year = {2021},
isbn = {9781450389716},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3478586.3478608},
doi = {10.1145/3478586.3478608},
abstract = { Dynamic path planning is a core research content for intelligent robots. This NP-hard problem is complex enough for an algorithm to plan a realistic path for a velocity-bound point robot in a dynamic environment. This paper presents a new CG-Space based real-time dynamic path planning method for finding the obstacle-free path for 10 DOF rocker-bogie type wheeled mobile robot (Rover) traversing over a 3D uneven terrain with dynamic and static obstacles. CG-Space is the locus of the center of gravity location of Rover while moving on a 3D terrain. A swarm intelligence-based Particle Swarm Optimization (PSO) method has been modified to plan an optimum collision-free path over CG-Space of Rover with dynamic obstacles. Dynamic replanning using a modified penalty in the PSO objective function can handle the randomly moving obstacles of varying sizes and shapes in real-time. Simulations demonstrate that the Rover can obtain the target location in 3D uneven dynamic environments with fixed and randomly moving obstacles. This 3D dynamic replanning study will benefit the cooperative sensing in multiple Rover systems and target tracking in cluttered environments.},
booktitle = {Advances in Robotics - 5th International Conference of The Robotics Society},
articleno = {5},
numpages = {6},
keywords = {Dynamic path planning, Random obstacles, Rover, PSO, CG-Space},
location = {Kanpur, India},
series = {AIR2021}
}

@inproceedings{10.1145/3284432.3284471,
author = {Charles, Jack-Antoine and Chanel, Caroline P. C. and Chauffaut, Corentin and Chauvin, Pascal and Drougard, Nicolas},
title = {Human-Agent Interaction Model Learning Based on Crowdsourcing},
year = {2018},
isbn = {9781450359535},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3284432.3284471},
doi = {10.1145/3284432.3284471},
abstract = {Missions involving humans interacting with automated systems become increasingly common. Due to the non-deterministic behavior of the human and possibly high risk of failing due to human factors, such an integrated system should react smartly by adapting its behavior when necessary. A promise avenue to design an efficient interaction-driven system is the mixed-initiative paradigm. In this context, this paper proposes a method to learn the model of a mixed-initiative human-robot mission. The first step to set up a reliable model is to acquire enough data. For this aim a crowdsourcing campaign was conducted and learning algorithms were trained on the collected data in order to model the human-robot mission and to optimize a supervision policy with a Markov Decision Process (MDP). This model takes into account the actions of the human operator during the interaction as well as the state of the robot and the mission. Once such a model has been learned, the supervision strategy can be optimized according to a criterion representing the goal of the mission. In this paper, the supervision strategy concerns the robot's operating mode. Simulations based on the MDP model show that planning under uncertainty solvers can be used to adapt robot's mode according to the state of the human-robot system. The optimization of the robot's operation mode seems to be able to improve the team's performance. The dataset that comes from crowdsourcing is therefore a material that can be useful for research in human-machine interaction, that is why it has been made available on our web site.},
booktitle = {Proceedings of the 6th International Conference on Human-Agent Interaction},
pages = {20–28},
numpages = {9},
keywords = {mixed-initiative mission, markov chain learning, markov decision process, human-robot interaction, crowdsourcing, classification},
location = {Southampton, United Kingdom},
series = {HAI '18}
}

@inproceedings{10.5555/2936924.2936946,
author = {Qian, Yundi and Zhang, Chao and Krishnamachari, Bhaskar and Tambe, Milind},
title = {Restless Poachers: Handling Exploration-Exploitation Tradeoffs in Security Domains},
year = {2016},
isbn = {9781450342391},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {The success of Stackelberg Security Games (SSGs) in counter-terrorism domains has inspired researchers' interest in applying game-theoretic models to other security domains with frequent interactions between defenders and attackers, e.g., wildlife protection. Previous research optimizes defenders' strategies by modeling this problem as a repeated Stackelberg game, capturing the special property in this domain --- frequent interactions between defenders and attackers. However, this research fails to handle exploration-exploitation tradeoff in this domain caused by the fact that defenders only have knowledge of attack activities at targets they protect. This paper addresses this shortcoming and provides the following contributions: (i) We formulate the problem as a restless multi-armed bandit (RMAB) model to address this challenge. (ii) To use Whittle index policy to plan for patrol strategies in the RMAB, we provide two sufficient conditions for indexability and an algorithm to numerically evaluate indexability. (iii) Given indexability, we propose a binary search based algorithm to find Whittle index policy efficiently.},
booktitle = {Proceedings of the 2016 International Conference on Autonomous Agents &amp; Multiagent Systems},
pages = {123–131},
numpages = {9},
keywords = {whittle index policy, pomdp, restless multi-armed bandit, exploration-exploitation tradeoff},
location = {Singapore, Singapore},
series = {AAMAS '16}
}

@inproceedings{10.1145/3360774.3360787,
author = {Lu, Jianchao and Zheng, Xi and Sheng, Quan Z. and Hussain, Zawar and Wang, Jiaxing and Zhou, Wanlei},
title = {MFE-HAR: Multiscale Feature Engineering for Human Activity Recognition Using Wearable Sensors},
year = {2019},
isbn = {9781450372831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3360774.3360787},
doi = {10.1145/3360774.3360787},
abstract = {Human activity recognition plays a key role in the application areas such as fitness tracking, healthcare and aged care support. However, inaccurate recognition results may cause an adverse effect on users or even an unpredictable accident. In order to improve the accuracy of human activity recognition, multi-device and deep learning based approaches have been proposed. However, they are not practical on a daily basis due to the limitations that devices are difficult to wear, and deep learning requires large training dataset and incurs expensive computational costs. To address this problem, we propose a novel approach, multiscale feature engineering for human activity recognition (MFE-HAR), which exploits the properties of arm movement from global and local scales using the accelerometer and gyroscope sensors on a single wearable device. Our method takes advantage of having important features at multiple scales over previous single-scale methods. We evaluated the performance of the proposed method on two public datasets and achieved the mean classification accuracy of 93% and 98% respectively. Our proposed system performs better than the state of the art multi-device based approaches, and is more practical for real-world applications.},
booktitle = {Proceedings of the 16th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
pages = {180–189},
numpages = {10},
keywords = {pervasive technologies for healthcare, mobile and wearable computing systems and services, activity recognition},
location = {Houston, Texas, USA},
series = {MobiQuitous '19}
}

@inproceedings{10.1145/3345770.3356740,
author = {Bouachir, Ouns and Aloqaily, Moayad and Garcia, Fabien and Larrieu, Nicolas and Gayraud, Thierry},
title = {Testbed of QoS Ad-Hoc Network Designed for Cooperative Multi-Drone Tasks},
year = {2019},
isbn = {9781450369053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3345770.3356740},
doi = {10.1145/3345770.3356740},
abstract = {Thanks to technological advances in information and communications, Unmanned Aerial Vehicles (UAVs) (aka drones) technology has become one of the most important service delivery inventions these days. Equipped with sensors and cameras, these technologies can perform much on-demand critical application ranging from military and environmental to rescue operations. These UAVs devices, sometimes tiny, that can replace human and manned aircraft in several tasks, have been utilized to perform various types of services and applications more efciently. However, the deployment side of such emerging technology is still facing many issues and challenges. Using multi-drones or swarm of drones, together to accomplish one operation is one of these recent challenges. Such a system requires a high level of delicacy and cooperation to achieve the required autonomy and reduce human interaction as possible. Communication is one of the biggest challenges in these systems, since the devices should keep exchanging various types of messages with different Quality of Service (QoS) requirements. In this paper, a collaborative autonomous system of swarm drones based on deep learning has been proposed and a testbed of cooperative UAVs' mission to validate the performance of the dedicated QoS communication system using Paparazzi drones The proposed system is aware of the drones' requirements in term of QoS and able to meet with their dynamic demands.},
booktitle = {Proceedings of the 17th ACM International Symposium on Mobility Management and Wireless Access},
pages = {89–95},
numpages = {7},
keywords = {cooperation, qos ad-hoc, testbed, uavs, drones},
location = {Miami Beach, FL, USA},
series = {MobiWac '19}
}

@inproceedings{10.1145/1830483.1830594,
author = {Knoester, David B. and Goldsby, Heather J. and McKinley, Philip K.},
title = {Neuroevolution of Mobile Ad Hoc Networks},
year = {2010},
isbn = {9781450300728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/1830483.1830594},
doi = {10.1145/1830483.1830594},
abstract = {This paper describes a study of the evolution of distributed behavior, specifically the control of agents in a mobile ad hoc network, using neuroevolution. In neuroevolution, a population of artificial neural networks (ANNs) are subject to mutation and natural selection. For this study, we compare three different neuroevolutionary systems: a direct encoding, an indirect encoding, and an indirect encoding that supports heterogeneity. Multiple variations of each of these systems were tested on a problem where agents were able to coordinate their collective behavior. Specifically, movement of agents in a simulated physics environment affected which agents were able to communicate with each other. The results of experiments indicate that this is a challenging problem domain for neuroevolution, and although direct and indirect encodings tended to perform similarly in our tests, the strategies employed by indirect encodings tended to favor stable, cohesive groups, while the direct encoding versions appeared more stochastic in nature.},
booktitle = {Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation},
pages = {603–610},
numpages = {8},
keywords = {developmental, distributed systems, neural network, generative, mobile ad-hoc networks, neuroevolution},
location = {Portland, Oregon, USA},
series = {GECCO '10}
}

@inproceedings{10.1145/3384544.3384599,
author = {Aoki, Risako and Oki, Takuro and Miyamoto, Ryusuke},
title = {Accuracy Improvement of Human Tracking in Aerial Images Using Error Correction Based on Color Information},
year = {2020},
isbn = {9781450376655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3384544.3384599},
doi = {10.1145/3384544.3384599},
abstract = {The authors are trying to construct a real-time vital sensing system during exercise where humans wearing sensor nodes move quickly and their density becomes sometimes higher. In this case, existing multi-hop networking using RSSI or GPS to gather vital signs exercisers may not work appropriately. To solve this problem, the authors are proposing image-assisted routing (shortly IAR) that estimates the locations of sensor nodes by image processing. This paper proposes a tracking scheme with error correction based on color information, which is indispensable for IAR. Experimental results using actual images taken from a UAV showed that the proposed scheme achieved accurate tracking using only simple operations without sophisticated state estimation and computationally exhaustive deep learning: MT reached 100% by the proposed scheme.},
booktitle = {Proceedings of the 2020 9th International Conference on Software and Computer Applications},
pages = {124–128},
numpages = {5},
keywords = {color Information, Simple Computation, Visual Object Tracking, Error Correction},
location = {Langkawi, Malaysia},
series = {ICSCA 2020}
}

@inproceedings{10.1145/3450522.3451328,
author = {Rakotonarivo, Balita Heriniaina and Drougard, Nicolas and Conversy, St\'{e}phane and Garcia, J\'{e}r\'{e}mie},
title = {Revue Syst\'{e}Matique de La Litt\'{e}Rature Sur Le Soutien \`{a} La S\'{e}Curit\'{e} Des Op\'{e}Rations de Drones: Systematic Literature Review of Safety Support for Drones Operations},
year = {2021},
isbn = {9781450383622},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3450522.3451328},
doi = {10.1145/3450522.3451328},
abstract = {In this paper, we focus on Unmanned Aircraft Systems (UAS) operations safety support. This is a key issue for operators, who must comply with the european regulation. First, we introduce the important elements of a civil UAS, including the European regulation. Then we describe a systematic literature review on this topic. This results in the identification of the main approaches: Detect &amp; Avoid, Human-Computer Interactions and Human Factors (HCI/HF), aircraft integrity, safety assessment, path planning, geofencing, cybersecurity and UAS traffic management. We further analyze the contributions related to HCI by identifying user tasks, interaction design recommendations for improving the safety of UAS operations and research perspectives. Finally, we discuss aspects that are poorly covered in the reviewed articles.},
booktitle = {32e Conf\'{e}rence Francophone Sur l'Interaction Homme-Machine},
articleno = {13},
numpages = {16},
keywords = {UAS, Human-machine interaction, UTM, authorization, mission, U-space, risk assessment},
location = {Virtual Event, France},
series = {IHM '21}
}

@inproceedings{10.1145/3386723.3387867,
author = {Ikuesan, Richard Adeyemi and Ganiyu, Shefiu Olusegun and Majigi, Muhammad Umar and Opaluwa, Yusuf Drisu and Venter, H. S.},
title = {Practical Approach to Urban Crime Prevention in Developing Nations},
year = {2020},
isbn = {9781450376341},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3386723.3387867},
doi = {10.1145/3386723.3387867},
abstract = {The growing surge in urban-crime rate represents a global complex endemic that is beyond the immediate capability of the policing apparatus of nations. This trend is particularly prevalent in urban cities in developing nations, where crime-rate exhibits dynamic tendencies in contrast to the static policing apparatus being deployed. Thus, the policing apparatus in urban cities in developing nations often play catchups with crime; a phenomenon that further elicits crime complexity. As a way to ameliorate this societal menace, this study evaluates probable practical approaches that can be integrated into the modern policing modality in developing nations. The approach considers the development of a dynamic surveillance management system that considers the contextual peculiarity of developing nations. Through the use of a self-administered measurement instrument from Police respondents in developing nations, the implementation feasibility and the probable effectiveness of the proposition will be further evaluated. From the preliminary result from sampled Police officers, this practical approach could present a complementary paradigm that can leverage modern technology towards an effective urban-policing mechanism. Furthermore, this approach presents modalities for the maximization of the human capacity of the Policing service, as well as the management of policing response-rate in developing nations.},
booktitle = {Proceedings of the 3rd International Conference on Networking, Information Systems &amp; Security},
articleno = {48},
numpages = {8},
keywords = {dynamic surveillance methods, dynamic and static policing, Urban crime, crime prevention},
location = {Marrakech, Morocco},
series = {NISS2020}
}

@inproceedings{10.1145/2345316.2345351,
author = {Chang, Peter C. and Liao, Duoduo},
title = {Image-Based Structural Damage Assessment with Sensor Fusion},
year = {2012},
isbn = {9781450311137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2345316.2345351},
doi = {10.1145/2345316.2345351},
abstract = {This paper presents a new approach to improve the accuracy and time needed to assess the structural damage based on imaging and sensor fusion technologies. The major structural properties (i.e., global properties, temperature, and deformation) are employed, which can be obtained through different kinds of sensors. Enhancements of visual images including thermal imaging and historical data are important methods to determinate both visible and invisible structural stability. Crack detection is given to further enhance the assessment. The latest GPGPU (General-Purpose Graphics Processing Unit) technology to help improve computation performance is introduced in briefly. An expert system is created to assist final sensor fusion and analysis for structural stability determination.},
booktitle = {Proceedings of the 3rd International Conference on Computing for Geospatial Research and Applications},
articleno = {30},
numpages = {6},
keywords = {GPGPU, computer vision, crack detection, expert system, finite element modeling, structural assessment, sensor fusion, thermal imaging},
location = {Washington, D.C., USA},
series = {COM.Geo '12}
}

@inproceedings{10.1145/3242969.3264971,
author = {Mahi, S M Al},
title = {Multi-Modal Multi Sensor Interaction between Human AndHeterogeneous Multi-Robot System},
year = {2018},
isbn = {9781450356923},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3242969.3264971},
doi = {10.1145/3242969.3264971},
abstract = {I introduce a novel multi-modal multi-sensor interaction method between humans and heterogeneous multi-robot systems. I have also developed a novel algorithm to control heterogeneous multi-robot systems. The proposed algorithm allows the human operator to provide intentional cues and information to a multi-robot system using a multimodal multi-sensor touchscreen interface. My proposed method can effectively convey complex human intention to multiple robots as well as represent robots' intentions over the spatiotemporal domain. The proposed method is scalable and robust to dynamic change in the deployment configuration. I describe the implementation of the control algorithm used to control multiple quad-rotor unmanned aerial vehicles in simulated and real environments. I will also present my initial work on human interaction with the robots running my algorithm using mobile phone touch screens and other potential multimodal interactions.},
booktitle = {Proceedings of the 20th ACM International Conference on Multimodal Interaction},
pages = {524–528},
numpages = {5},
keywords = {uav, multimodal interaction, uas, heterogeneous robot team, autonomy, human-robot interaction},
location = {Boulder, CO, USA},
series = {ICMI '18}
}

@inproceedings{10.1145/3207677.3278006,
author = {Li, Meng and Sun, Qinpeng and Song, Qing and Wang, Zhaoliang and Li, Yuan},
title = {Path Planning of Mobile Robot Based on RRT in Rugged Terrain},
year = {2018},
isbn = {9781450365123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3207677.3278006},
doi = {10.1145/3207677.3278006},
abstract = {The1 basic RRT algorithm is difficult to realize the path planning of 3D environment. Aiming at the 3D path planning problem of mobile robot in complex environment. An improved RRT algorithm is proposed. Firstly, the 3D environment model is established for the path planning of mobile robot under complex rugged terrain, and the task requirements are analyzed. Then, based on the basic RRT algorithm, a new node acceptance criterion is proposed for the particularity of 3D environment. This acceptance criterion of new node take into account the variation of terrain height, the smooth of path, and the kinematics constraints such as turning radius and pitch angle of the mobile robot. Furthermore, the dynamic pg value design is carried out, and the process of improving the algorithm is given. At last, simulation results show the effectiveness of the proposed method. The generated path passes at low altitudes, avoiding peaks and rough terrain.},
booktitle = {Proceedings of the 2nd International Conference on Computer Science and Application Engineering},
articleno = {10},
numpages = {5},
keywords = {heuristic algorithm, Rapidly-exploring Random Tree, Mobile Robot, Path planning},
location = {Hohhot, China},
series = {CSAE '18}
}

@inproceedings{10.1145/3352593.3352601,
author = {Jada, Chakravarthi and Pusuluri, Vinod and Baswani, Pavan and Urlana, Ashok and Devineni, Mahima Kumari and Motepalli, Padma Priya and Bodakurthi, Ganesh and Motupalli, Sumanth},
title = {Simultaneous Localization of Signal Sources Inspired by Butterfly Paradigm},
year = {2019},
isbn = {9781450366502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3352593.3352601},
doi = {10.1145/3352593.3352601},
abstract = {Nature is the source of the huge number of species with many unknown and hidden things. In those, Butterfly is one of the specialized creatures with its prominent behavior. Recently, a metaphor named as Butterfly Mating Optimization (BMO) was developed to solve the multimodal optimization problems. To imitate this algorithm a mobile robot (Bflybot) was designed to meet the features of the Bfly in the BMO algorithm. This paper presents an investigation of the simultaneous localization of multiple signal sources. Subsequently, various strategies are annotated while Bflybots are converged towards multiple signal sources. The experimental result shows that the BMO algorithm is applicable to detect multiple signal sources with significant variations in their movements i.e., static and dynamic.},
booktitle = {Proceedings of the Advances in Robotics 2019},
articleno = {7},
numpages = {6},
keywords = {Bflybot, Optimization, Localization, BMO, Signal Source, Butterfly},
location = {Chennai, India},
series = {AIR 2019}
}

@article{10.1109/TCBB.2016.2622692,
author = {Ushakov, Anton V. and Klimentova, Xenia and Vasilyev, Igor},
title = {Bi-Level and Bi-Objective p-Median Type Problems for Integrative Clustering: Application to Analysis of Cancer Gene-Expression and Drug-Response Data},
year = {2018},
issue_date = {January 2018},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {15},
number = {1},
issn = {1545-5963},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/TCBB.2016.2622692},
doi = {10.1109/TCBB.2016.2622692},
abstract = {Recent advances in high-throughput technologies have given rise to collecting large amounts of multidimensional heterogeneous data that provide diverse information on the same biological samples. Integrative analysis of such multisource datasets may reveal new biological insights into complex biological mechanisms and therefore remains an important research field in systems biology. Most of the modern integrative clustering approaches rely on independent analysis of each dataset and consensus clustering, probabilistic or statistical modeling, while flexible distance-based integrative clustering techniques are sparsely covered. We propose two distance-based integrative clustering frameworks based on bi-level and bi-objective extensions of the p-median problem. A hybrid branch-and-cut method is developed to find global optimal solutions to the bi-level p-median model. As to the bi-objective problem, an $varepsilon$-constraint algorithm is proposed to generate an approximation to the Pareto optimal set. Every solution found by any of the frameworks corresponds to an integrative clustering. We present an application of our approaches to integrative analysis of NCI-60 human tumor cell lines characterized by gene expression and drug activity profiles. We demonstrate that the proposed mathematical optimization-based approaches outperform some state-of-the-art and traditional distance-based integrative and non-integrative clustering techniques.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {jan},
pages = {46–59},
numpages = {14}
}

@inproceedings{10.1145/2670473.2670498,
author = {Qin, Xue and Xiao, Shuangjiu},
title = {Transparent-Supported Radiance Regression Function},
year = {2014},
isbn = {9781450332545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2670473.2670498},
doi = {10.1145/2670473.2670498},
abstract = {A modified RRF[Ren et al. 2013] rendering method called TsRRF is presented in this paper, which support global illumination in realtime for scenes with moving transparent objects. The key idea of this method is to augment the map between object and scene. There are two kinds of method to augment this map. First, we choose different attributes which can represent the true color of an object and the relationship with the whole scene in space, and at the same time in order to get these attributes, we use GPGPU to get real time information. Second we use deep learning to get the most important information from the sample data which can decrease the overfitting. In order to get more details and make full use of the sample data, we not only partition the scene by position, but also partition by object, and we will use different TsRRF to render different light effect like reflection or refraction. The network forward propagate process will also be put into the GPU and use the parallel feature to calculate quickly. As a result, the modified method works well when dealing with the transparent objects and have a real time effect.},
booktitle = {Proceedings of the 13th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry},
pages = {197–200},
numpages = {4},
keywords = {transparent, radiance regression function, global illumination},
location = {Shenzhen, China},
series = {VRCAI '14}
}

@article{10.1145/3279949,
author = {Lu, Sixing and Lysecky, Roman},
title = {Data-Driven Anomaly Detection with Timing Features for Embedded Systems},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
issn = {1084-4309},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3279949},
doi = {10.1145/3279949},
abstract = {Malware is a serious threat to network-connected embedded systems, as evidenced by the continued and rapid growth of such devices, commonly referred to as the Internet of Things. Their ubiquitous use in critical applications require robust protection to ensure user safety and privacy. That protection must be applied to all system aspects, extending beyond protecting the network and external interfaces. Anomaly detection is one of the last lines of defence against malware, in which data-driven approaches that require the least domain knowledge are popular. However, embedded systems, particularly edge devices, face several challenges in applying data-driven anomaly detection, including unpredictability of malware, limited tolerance to long data collection windows, and limited computing/energy resources. In this article, we utilize subcomponent timing information of software execution, including intrinsic software execution, instruction cache misses, and data cache misses as features, to detect anomalies based on ranges, multi-dimensional Euclidean distance, and classification at runtime. Detection methods based on lumped timing range are also evaluated and compared. We design several hardware detectors implementing these data-driven detection methods, which non-intrusively measuring lumped/subcomponent timing of all system/function calls of the embedded application. We evaluate the area, power, and detection latency of the presented detector designs. Experimental results demonstrate that the subcomponent timing model provides sufficient features to achieve high detection accuracy with low false-positive rates using a one-class support vector machine, considering sophisticated mimicry malware.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {apr},
articleno = {33},
numpages = {27},
keywords = {timing-based detection, One-class SVM, anomaly detection, embedded system security, software security}
}

@article{10.1109/TNET.2019.2946481,
author = {Talak, Rajat and Karaman, Sertac and Modiano, Eytan},
title = {Optimizing Information Freshness in Wireless Networks Under General Interference Constraints},
year = {2020},
issue_date = {Feb. 2020},
publisher = {IEEE Press},
volume = {28},
number = {1},
issn = {1063-6692},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/TNET.2019.2946481},
doi = {10.1109/TNET.2019.2946481},
abstract = {Age of information (AoI) is a recently proposed metric for measuring information freshness. AoI measures the time that elapsed since the last received update was generated. We consider the problem of minimizing average and peak AoI in a wireless networks, consisting of a set of source-destination links, under general interference constraints. When fresh information is always available for transmission, we show that a stationary scheduling policy is peak age optimal. We also prove that this policy achieves average age that is within a factor of two of the optimal average age. In the case where fresh information is not always available, and packet/information generation rate has to be controlled along with scheduling links for transmission, we prove an important <italic>separation principle</italic>: the optimal scheduling policy can be designed assuming fresh information, and independently, the packet generation rate control can be done by ignoring interference. Peak and average AoI for discrete time G/Ber/1 queue is analyzed for the first time, which may be of independent interest.},
journal = {IEEE/ACM Trans. Netw.},
month = {feb},
pages = {15–28},
numpages = {14}
}

@inproceedings{10.1145/3442555.3442566,
author = {Huang, Shanshan and Huang, Jianhui and Kong, Yongqiang},
title = {Attention Guided YOLOv3 for Wearing Safety Helmet Detection},
year = {2020},
isbn = {9781450388092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3442555.3442566},
doi = {10.1145/3442555.3442566},
abstract = {Wearing safety helmet is of great importance to ensure the personal safety in power substations. The task of safety helmet detection still requires manual effort which is time-consuming and laborious. To address this problem, this paper introduces a computer vision method for automatic safety helmet detection based on YOLOv3 algorithm. We propose an attention mechanism which contains spatial-wise and channel-wise attention modules, to separately enhance the low-level and high-level features of deep convolutional encoder. Equipping YOLOv3 with our attention mechanism, the detector can improve its ability of detecting small objects, which is suitable for real-world safety helmet detection. Experiments on a publicly available helmet wearing detection dataset show that the proposed method is able to achieve good performance while running at a high speed.},
booktitle = {2020 the 6th International Conference on Communication and Information Processing},
pages = {65–69},
numpages = {5},
keywords = {Safety helmet detection, YOLOv3, attention mechanism},
location = {Tokyo, Japan},
series = {ICCIP 2020}
}

@inproceedings{10.1145/3467707.3467708,
author = {Zhenbo, Bi and Shiyou, Zhang and Hongjun, Pan and Yuanhong, Wu and Hua, Yang},
title = {A Survey of Preprocessing Methods for Marine Ship Target Detection Based on Video Surveillance},
year = {2021},
isbn = {9781450389501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3467707.3467708},
doi = {10.1145/3467707.3467708},
abstract = {Ship target detection based on video surveillance has an important application in maritime security. In order to reduce the interference caused by the complex marine environment, it is usually necessary to preprocess the captured images. Based on the current research results of ship video detection at sea, this paper summarizes the commonly used ship target detection preprocessing methods under visible light detection conditions, including: image format conversion, video image anti jitter, defogging processing, image filtering, binary processing and morphological filtering. On this basis, the development of pretreatment technology and the research and development strategy of ship target detection system are discussed.},
booktitle = {2021 7th International Conference on Computing and Artificial Intelligence},
pages = {1–7},
numpages = {7},
keywords = {maritime security, preprocessing technology, Ship target detection, computer vision},
location = {Tianjin, China},
series = {ICCAI 2021}
}

@inproceedings{10.1145/3339311.3339314,
author = {Panda, Madhusmita and Das, Bikramaditya and Pati, Bibhuti Bhusan},
title = {Grey Wolf Optimization for Global Path Planning of Autonomous Underwater Vehicle},
year = {2019},
isbn = {9781450366526},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3339311.3339314},
doi = {10.1145/3339311.3339314},
abstract = {Path planning problem (PPP) deals with finding an optimized path between a source and a goal point. Global path planning (GPP) for Autonomous underwater vehicle (AUV), provides an optimized predefined path to reach the desired destination of the AUV. AUVs are largely useful in missions involving marine geoscience, scientific research, military warfare, along with commercial sectors of oil and gas industries. A time optimized path that can avoid collision helps in reducing time and energy expenses of such real time missions. Grey Wolf Optimization (GWO) is a nature inspired metaheuristic algorithm based on hunting behavior of the grey wolves. GWO provides better exploration of the solution space and good at avoiding local minima. This research presents an overview of GWO with its mathematical modelling. The research mainly contributes in applying GWO for path planning of an AUV to generate a global path in a two-dimensional underwater environment with static obstacles. Simulation results are obtained using MATLAB. The resultant path is optimized in time, distance travel and requires less processing time as compared to results obtained by applying Ant colony Optimization (ACO) for the same problem.},
booktitle = {Proceedings of the Third International Conference on Advanced Informatics for Computing Research},
articleno = {3},
numpages = {6},
keywords = {evolutionary algorithm (EA), hunting, ant colony optimization (ACO), global, leadership, autonomous underwater vehicle (AUV), grey wolf optimization (GWO), path planning problem (PPP)},
location = {Shimla, India},
series = {ICAICR '19}
}

@article{10.1145/2337542.2337560,
author = {Zhang, Xiaoqin Shelley and Shrestha, Bhavesh and Yoon, Sungwook and Kambhampati, Subbarao and DiBona, Phillip and Guo, Jinhong K. and McFarlane, Daniel and Hofmann, Martin O. and Whitebread, Kenneth and Appling, Darren Scott and Whitaker, Elizabeth T. and Trewhitt, Ethan B. and Ding, Li and Michaelis, James R. and McGuinness, Deborah L. and Hendler, James A. and Doppa, Janardhan Rao and Parker, Charles and Dietterich, Thomas G. and Tadepalli, Prasad and Wong, Weng-Keen and Green, Derek and Rebguns, Anton and Spears, Diana and Kuter, Ugur and Levine, Geoff and DeJong, Gerald and MacTavish, Reid L. and Onta\~{n}\'{o}n, Santiago and Radhakrishnan, Jainarayan and Ram, Ashwin and Mostafa, Hala and Zafar, Huzaifa and Zhang, Chongjie and Corkill, Daniel and Lesser, Victor and Song, Zhexuan},
title = {An Ensemble Architecture for Learning Complex Problem-Solving Techniques from Demonstration},
year = {2012},
issue_date = {September 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
issn = {2157-6904},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2337542.2337560},
doi = {10.1145/2337542.2337560},
abstract = {We present a novel ensemble architecture for learning problem-solving techniques from a very small number of expert solutions and demonstrate its effectiveness in a complex real-world domain. The key feature of our “Generalized Integrated Learning Architecture” (GILA) is a set of heterogeneous independent learning and reasoning (ILR) components, coordinated by a central meta-reasoning executive (MRE). The ILRs are weakly coupled in the sense that all coordination during learning and performance happens through the MRE. Each ILR learns independently from a small number of expert demonstrations of a complex task. During performance, each ILR proposes partial solutions to subproblems posed by the MRE, which are then selected from and pieced together by the MRE to produce a complete solution. The heterogeneity of the learner-reasoners allows both learning and problem solving to be more effective because their abilities and biases are complementary and synergistic. We describe the application of this novel learning and problem solving architecture to the domain of airspace management, where multiple requests for the use of airspaces need to be deconflicted, reconciled, and managed automatically. Formal evaluations show that our system performs as well as or better than humans after learning from the same training data. Furthermore, GILA outperforms any individual ILR run in isolation, thus demonstrating the power of the ensemble architecture for learning and problem solving.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = {sep},
articleno = {75},
numpages = {38},
keywords = {Ensemble architecture, learning from demonstration, complex problem-solving}
}

@inproceedings{10.1145/3468737.3494098,
author = {Lyons, Eric and Saplakoglu, Hakan and Zink, Michael and Thareja, Komal and Mandal, Anirban and Qu, Chengyi and Wang, Songjie and Calyam, Prasad and Papadimitriou, George and Tanaka, Ryan and Deelman, Ewa},
title = {FlyNet: A Platform to Support Scientific Workflows from the Edge to the Core for UAV Applications},
year = {2021},
isbn = {9781450385640},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3468737.3494098},
doi = {10.1145/3468737.3494098},
abstract = {Many Internet of Things (IoT) applications require compute resources that cannot be provided by the devices themselves. At the same time, processing of the data generated by IoT devices often has to be performed in real- or near real-time. Examples of such scenarios are autonomous vehicles in the form of cars and drones where the processing of observational data (e.g., video feeds) needs to be performed expeditiously to allow for safe operation. To support the computational needs and timeliness requirements of such applications it is essential to include suitable edge resources to execute these applications. In this paper, we present our FlyNet architecture which has the goal to provide a new platform to support workflows that include applications executing at the network edge, at the computing core, and leverage deeply programmable networks. We discuss the challenges associated with provisioning such networking and compute infrastructure on demand, tailored to IoT application workflows. We describe a strategy to leverage the end-to-end integrated infrastructure that covers all points in the spectrum of response latency for application processing. We present our prototype implementation of the architecture and evaluate its performance for the case of drone video analytics workflows with varying computational requirements.},
booktitle = {Proceedings of the 14th IEEE/ACM International Conference on Utility and Cloud Computing},
articleno = {12},
numpages = {10},
location = {Leicester, United Kingdom},
series = {UCC '21}
}

@inproceedings{10.1145/3469213.3470681,
author = {Wei, Shuyi and Yang, Lailong and Zhang, Xiuxia},
title = {Design of the Face Recognition System for Criminals in Taxi Based on Cloud Platform},
year = {2021},
isbn = {9781450390200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3469213.3470681},
doi = {10.1145/3469213.3470681},
abstract = {Taxi safety incidents cause serious threats to the personal and property safety of drivers and passengers. An effective solution was installed video surveillance in taxis. For privacy issues and the cost of using equipment, only a few taxis were equipped with surveillance cameras. However, the uploaded video didn't be transmitted to the management platform for inspection, and it doesn't have the function of criminal identification. To solve the problem mentioned above, the cloud platform combined with face recognition technology, transmit the required video to the cloud server database through wireless transmission technology. The web client would check uploaded videos online and passengers pass through criminal face recognition system before boarding the taxi. This design could monitor, review and verify the entire process of incidents online, would effectively reduce the occurrence of taxi safety incidents.},
booktitle = {2021 2nd International Conference on Artificial Intelligence and Information Systems},
articleno = {248},
numpages = {4},
keywords = {criminal face recognition, video surveillance, Taxi safety, cloud platform},
location = {Chongqing, China},
series = {ICAIIS 2021}
}

@inproceedings{10.5555/3237383.3237877,
author = {Amir, Ofra and Doshi-Velez, Finale and Sarne, David},
title = {Agent Strategy Summarization},
year = {2018},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Intelligent agents and AI-based systems are becoming increasingly prevalent. They support people in different ways, such as providing users with advice, working with them to achieve goals or acting on users' behalf. One key capability missing in such systems is the ability to present their users with an effective summary of their strategy and expected behaviors under different conditions and scenarios. This capability, which we see as complimentary to those currently under development in the context of "interpretable machine learning'' and "explainable AI'', is critical in various settings. In particular, it is likely to play a key role whenever a user needs to understand the strategy of an agent she is working along with, when having to choose between different available agents to act on her behalf, or when requested to determine the level of autonomy to be granted to the agent or approve its strategy. In this paper, we pose the challenge of developing capabilities for strategy summarization, which is not addressed by current theories and methods in the field. We propose a conceptual framework for strategy summarization, which we envision as a collaborative process that involves both agents and people. Last, we suggest possible testbeds that could be used to evaluate progress in research on strategy summarization.},
booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {1203–1207},
numpages = {5},
keywords = {explainable ai, strategy summarization},
location = {Stockholm, Sweden},
series = {AAMAS '18}
}

@inproceedings{10.1145/3207677.3278007,
author = {Qi, Yincheng and Du, Liqun and Zhao, Zhenbing and Cui, Yaping and Si, Wenhao},
title = {Insulator Detection Based on SSD with the Default Box Adaptively Selection},
year = {2018},
isbn = {9781450365123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3207677.3278007},
doi = {10.1145/3207677.3278007},
abstract = {Detecting1 power line insulator automatically has important practical significance for the stable and reliable operation of the entire power system. In this paper, Single Shot Multibox Detector is applied to target detection of power line insulator images. Due to the particularity of the insulator shape, the aspect ratios of the default box do not match the insulator. According to the statistical result of the dataset, an adaptively select method of the default box aspect ratios is proposed. Experimental results show that the use of improved Single Shot Multibox Detector algorithm to identify and locate the insulator can reach to 87.5% and the detection time is 84ms per image only.},
booktitle = {Proceedings of the 2nd International Conference on Computer Science and Application Engineering},
articleno = {110},
numpages = {4},
keywords = {default box, insulator detection, Single Shot Multibox Detector (SSD), Power line image},
location = {Hohhot, China},
series = {CSAE '18}
}

@inproceedings{10.1145/2808492.2808498,
author = {Wang, Dong and Wang, Bin and Zhao, Sicheng and Sun, Xiaoshuai and Yao, Hongxun and Liu, Hong},
title = {Dual-Mode Video Stabilization Based on Adaptive Motion Clustering},
year = {2015},
isbn = {9781450335287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2808492.2808498},
doi = {10.1145/2808492.2808498},
abstract = {Many target tracking videos suffer from significant shake due to the undesirable camera motion or target vibration. These degraded video records have a negative impact on viewing experience as well as the follow-up analysis and application. Most existing digital video stabilization methods aim at removing camera shake using the techniques of global motion estimation and compensation between adjacent frames, while paying little attention to motion pattern and the relationship between the foreground and background contents. In this paper, we present a novel approach to stabilize the videos containing large dynamic object, which can realize the normal stabilization task and describe the target motion path at the meantime. We combine K-means and Gaussian mixture model to distinguish the motion modes of background and foreground without applying any prior knowledge about the moving object. The proposed approach gives a flexible choice in stabilizing background motion as traditional algorithms or foreground motion for salient target surveillance.},
booktitle = {Proceedings of the 7th International Conference on Internet Multimedia Computing and Service},
articleno = {6},
numpages = {4},
keywords = {video stabilization, dual motion modes, foreground stabilization},
location = {Zhangjiajie, Hunan, China},
series = {ICIMCS '15}
}

@article{10.1109/TCBB.2015.2443789,
author = {Zhang, Bo and Duan, Haibin},
title = {Three-Dimensional Path Planning for Uninhabited Combat Aerial Vehicle Based on Predator-Prey Pigeon-Inspired Optimization in Dynamic Environment},
year = {2017},
issue_date = {January 2017},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {14},
number = {1},
issn = {1545-5963},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/TCBB.2015.2443789},
doi = {10.1109/TCBB.2015.2443789},
abstract = {Three-dimension path planning of uninhabited combat aerial vehicle UCAV is a complicated optimal problem, which mainly focused on optimizing the flight route considering the different types of constrains under complex combating environment. A novel predator-prey pigeon-inspired optimization PPPIO is proposed to solve the UCAV three-dimension path planning problem in dynamic environment. Pigeon-inspired optimization PIO is a new bio-inspired optimization algorithm. In this algorithm, map and compass operator model and landmark operator model are used to search the best result of a function. The prey-predator concept is adopted to improve global best properties and enhance the convergence speed. The characteristics of the optimal path are presented in the form of a cost function. The comparative simulation results show that our proposed PPPIO algorithm is more efficient than the basic PIO, particle swarm optimization PSO, and different evolution DE in solving UCAV three-dimensional path planning problems.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {jan},
pages = {97–107},
numpages = {11}
}

@inproceedings{10.1145/3289602.3293904,
author = {Ding, Caiwen and Wang, Shuo and Liu, Ning and Xu, Kaidi and Wang, Yanzhi and Liang, Yun},
title = {REQ-YOLO: A Resource-Aware, Efficient Quantization Framework for Object Detection on FPGAs},
year = {2019},
isbn = {9781450361378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3289602.3293904},
doi = {10.1145/3289602.3293904},
abstract = {Deep neural networks (DNNs), as the basis of object detection, will play a key role in the development of future autonomous systems with full autonomy. The autonomous systems have special requirements of real-time, energy-e cient implementations of DNNs on a power-budgeted system. Two research thrusts are dedicated to per- formance and energy e ciency enhancement of the inference phase of DNNs. The first one is model compression techniques while the second is e cient hardware implementations. Recent researches on extremely-low-bit CNNs such as binary neural network (BNN) and XNOR-Net replace the traditional oating point operations with bi- nary bit operations, signi cantly reducing memory bandwidth and storage requirement, whereas suffering non-negligible accuracy loss and waste of digital signal processing (DSP) blocks on FPGAs. To overcome these limitations, this paper proposes REQ-YOLO, a resource aware, systematic weight quantization framework for object detection, considering both algorithm and hardware resource aspects in object detection. We adopt the block-circulant matrix method and propose a heterogeneous weight quantization using Alternative Direction Method of Multipliers (ADMM), an e ective optimization technique for general, non-convex optimization problems. To achieve real-time, highly efficient implementations on FPGA, we present the detailed hardware implementation of block circulant matrices on CONV layers and de- velop an e cient processing element (PE) structure supporting the heterogeneous weight quantization, CONV data ow and pipelining techniques, design optimization, and a template-based automatic synthesis framework to optimally exploit hardware resource. Experimental results show that our proposed REQ-YOLO framework can signi cantly compress the YOLO model while introducing very small accuracy degradation. The related codes are here: https://github.com/Anonymous788/heterogeneous_ADMM_YOLO.},
booktitle = {Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
pages = {33–42},
numpages = {10},
keywords = {fpga, admm, yolo, compression, object detection},
location = {Seaside, CA, USA},
series = {FPGA '19}
}

@inproceedings{10.1145/3086439.3086447,
author = {Andryeyev, Oleksandr and Mitschele-Thiel, Andreas},
title = {Increasing the Cellular Network Capacity Using Self-Organized Aerial Base Stations},
year = {2017},
isbn = {9781450349604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3086439.3086447},
doi = {10.1145/3086439.3086447},
abstract = {Nowadays, the cellular network planning becomes a complex task due to unpredictable changes in mobile user behavior and high capacity requirements. Therefore, it is needed to deploy a high number of base stations in order to provide a requested quality of service. The advancement in technologies gives us an opportunity to use aerial base stations, which can change their positions in order to provide capacity only in space and time where and when it is needed. In this work, we present a novel self-organized approach based on gradient search and potential fields for aerial base station deployment in order to increase the cellular network capacity. In contrast to the current aerial base station deployment approaches, our solution satisfies all requirements of modern urban scenario -- it uses only local information, adapts to different environments, provides high degree of autonomy and scalability and operates in real time.We provide a simulation-based evaluation of the proposed approach and a comparison to traditional base station placement in terms of the average aggregated system capacity. Results indicate that capacity can be improved by up to 52% in case of dense user clusters. Therefore network deployment costs can be minimized and spectrum efficiency maximized.},
booktitle = {Proceedings of the 3rd Workshop on Micro Aerial Vehicle Networks, Systems, and Applications},
pages = {37–42},
numpages = {6},
keywords = {cellular system capacity, base station placement, LTE, aerial base station, self-organization, MAV},
location = {Niagara Falls, New York, USA},
series = {DroNet '17}
}

@article{10.1145/3450626.3459676,
author = {Zhang, Jiazhao and Zhu, Chenyang and Zheng, Lintao and Xu, Kai},
title = {ROSEFusion: Random Optimization for Online Dense Reconstruction under Fast Camera Motion},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {4},
issn = {0730-0301},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3450626.3459676},
doi = {10.1145/3450626.3459676},
abstract = {Online reconstruction based on RGB-D sequences has thus far been restrained to relatively slow camera motions (&lt;1m/s). Under very fast camera motion (e.g., 3m/s), the reconstruction can easily crumble even for the state-of-the-art methods. Fast motion brings two challenges to depth fusion: 1) the high nonlinearity of camera pose optimization due to large inter-frame rotations and 2) the lack of reliably trackable features due to motion blur. We propose to tackle the difficulties of fast-motion camera tracking in the absence of inertial measurements using random optimization, in particular, the Particle Filter Optimization (PFO). To surmount the computation-intensive particle sampling and update in standard PFO, we propose to accelerate the randomized search via updating a particle swarm template (PST). PST is a set of particles pre-sampled uniformly within the unit sphere in the 6D space of camera pose. Through moving and rescaling the pre-sampled PST guided by swarm intelligence, our method is able to drive tens of thousands of particles to locate and cover a good local optimum extremely fast and robustly. The particles, representing candidate poses, are evaluated with a fitness function defined based on depth-model conformance. Therefore, our method, being depth-only and correspondence-free, mitigates the motion blur impediment as (ToF-based) depths are often resilient to motion blur. Thanks to the efficient template-based particle set evolution and the effective fitness function, our method attains good quality pose tracking under fast camera motion (up to 4m/s) in a realtime framerate without including loop closure or global pose optimization. Through extensive evaluations on public datasets of RGB-D sequences, especially on a newly proposed benchmark of fast camera motion, we demonstrate the significant advantage of our method over the state of the arts.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {56},
numpages = {17},
keywords = {RGB-D reconstruction, random optimization, fast-motion camera tracking, online dense reconstruction}
}

@inproceedings{10.1145/3071178.3071248,
author = {Howard, Gerard David},
title = {On Self-Adaptive Rate Restarts for Evolutionary Robotics with Real Rotorcraft},
year = {2017},
isbn = {9781450349208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3071178.3071248},
doi = {10.1145/3071178.3071248},
abstract = {Self-adaptive parameters are increasingly used in the field of Evolutionary Robotics, as they allow key evolutionary rates to vary autonomously in a context-sensitive manner throughout the optimisation process. A significant limitation to self-adaptive mutation is that rates can be set unfavourably which hinders convergence. Rate restarts are typically employed to remedy this, but thus far have only been applied in Evolutionary Robotics for mutation-only algorithms. This paper focuses on the level at which evolutionary rate restarts are applied in population-based algorithms with &gt;1 evolutionary operator. After testing on a real hexacopter hovering task, we conclude that individual-level restarting results in higher fitness solutions without fitness stagnation, and population restarts provide a more stable rate evolution. Without restarts, experiments can become stuck in suboptimal controller/rate combinations which can be difficult to escape from.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {123–130},
numpages = {8},
keywords = {differential evolution, self-adaptation, evolvable hardware, evolutionary robotics},
location = {Berlin, Germany},
series = {GECCO '17}
}

@inproceedings{10.1145/3444950.3444959,
author = {Eisoldt, Marc and Hinderink, Steffen and Tassemeier, Marco and Flottmann, Marcel and Vana, Juri and Wiemann, Thomas and Gaal, Julian and Rothmann, Marc and Porrmann, Mario},
title = {ReconfROS: Running ROS on Reconfigurable SoCs},
year = {2021},
isbn = {9781450389525},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3444950.3444959},
doi = {10.1145/3444950.3444959},
abstract = { In this paper, we present an approach to integrate reconfigurable SoCs into the well known Robot Operating System (ROS). Our method allows to implement hardware-accelerated algorithms on FPGA and integrate them directly into the ROS ecosystem. This allows to combine the established and well tested ROS infrastructure together with low-power hardware acceleration. As a proof-of-concept for this novel integration, we ported an existing path-following algorithm onto an FPGA and tested it on an unmanned ground vehicle (UGV).},
booktitle = {Proceedings of the 2021 Drone Systems Engineering and Rapid Simulation and Performance Evaluation: Methods and Tools Proceedings},
pages = {16–21},
numpages = {6},
keywords = {FPGA, ROS, UGV, Path Detection, UAV, SoC},
location = {Budapest, Hungary},
series = {DroneSE and RAPIDO '21}
}

@inproceedings{10.1145/3501409.3501663,
author = {Hu, Yendo and Wu, Yiliang and Bai, Xue and Chen, Minghong and Guanglei, Zhuo and Shi, Zhipeng},
title = {A Low-Latency Control Path Design for Cloud Based Micro-Drones},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3501409.3501663},
doi = {10.1145/3501409.3501663},
abstract = {Dynamic real-time control through a remote network is becoming a reality, given the drive of the latest generation of wireless networks. As cloud computing takes on an even stronger role in the industry, the desire to offload time critical processes into the network becomes a possibility. With the combination of cloud edge processing centers, and the UUL standardization for sub-millisecond delay over 5G networks, applications requiring dynamic time critical closed loop control is now an option. With the support of cloud edge processors, advanced complex analysis and processing algorithms, such deep learning engines or video-based approaches, miniature drones can achieve higher levels of capability without the weight or cost requirements. In this paper, we present wireless closed loop control system. The proposed framework is composed of a controller, drone flight receiver and motor control. The delay time from the issuance of the control command to the start of the execution of the control command is only about 4 ms. The proposed solution has been implemented and verified on the research UAV data link system.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1430–1435},
numpages = {6},
keywords = {Micro-drone control, low-latency path},
location = {Xiamen, China},
series = {EITCE 2021}
}

@inproceedings{10.1145/3444685.3446316,
author = {Tang, Yao and Zhao, Lin and Yao, Zhaoliang and Gong, Chen and Yang, Jian},
title = {Graph-Based Motion Prediction for Abnormal Action Detection},
year = {2021},
isbn = {9781450383080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3444685.3446316},
doi = {10.1145/3444685.3446316},
abstract = {Abnormal action detection is the most noteworthy part of anomaly detection, which tries to identify unusual human behaviors in videos. Previous methods typically utilize future frame prediction to detect frames deviating from the normal scenario. While this strategy enjoys success in the accuracy of anomaly detection, critical information such as the cause and location of the abnormality is unable to be acquired. This paper proposes human motion prediction for abnormal action detection. We employ sequence of human poses to represent human motion, and detect irregular behavior by comparing the predicted pose with the actual pose detected in the frame. Hence the proposed method is able to explain why the action is regarded as irregularity and locate where the anomaly happens. Moreover, pose sequence is robust to noise, complex background and small targets in videos. Since posture information is non-Euclidean data, graph convolutional network is adopted for future pose prediction, which not only leads to greater expressive power but also stronger generalization capability.Experiments are conducted both on the widely used anomaly detection dataset ShanghaiTech and our newly proposed dataset NJUST-Anomaly, which mainly contains irregular behaviors happened in the campus. Our dataset expands the existing datasets by giving more abnormal actions attracting public attention in social security, which happen in more complex scenes and dynamic backgrounds. Experimental results on both datasets demonstrate the superiority of our method over the-state-of-the-art methods. The source code and NJUST-Anomaly dataset will be made public at https://github.com/datangzhengqing/MP-GCN.},
booktitle = {Proceedings of the 2nd ACM International Conference on Multimedia in Asia},
articleno = {63},
numpages = {7},
keywords = {graph convolutional network, abnormal action detection, motion prediction},
location = {Virtual Event, Singapore},
series = {MMAsia '20}
}

@inproceedings{10.1145/2735960.2735970,
author = {Ahmed, Nisar and Campbell, Mark and Casbeer, David and Cao, Yongcan and Kingston, Derek},
title = {Fully Bayesian Learning and Spatial Reasoning with Flexible Human Sensor Networks},
year = {2015},
isbn = {9781450334556},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2735960.2735970},
doi = {10.1145/2735960.2735970},
abstract = {This work considers the challenging problem of simultaneous modeling and fusion of 'soft data' generated by a network of 'human sensors' for spatial state estimation tasks, such as lost target search or large area surveillance. Human sensors can opportunistically provide useful information to constrain difficult state estimation problems, but are imperfect information sources whose reliability cannot be easily determined in advance. Formal observation likelihood models are derived for flexible sketch-based observations, but are found to lead to analytically intractable statistical dependencies between unknown sensor parameters and spatial states of interest that cannot adequately characterized by simple point estimates. Hierarchical Bayesian models and centralized inference strategies based on Gibbs sampling are proposed to address these issues, especially in cases of sparse, noisy, ambiguous and conflicting soft data. This leads to an automatic online calibration procedure for human sensor networks, as well as conservative spatial state posteriors that naturally account for model uncertainties. Experimental outdoor target search results with real spatial human sensor data (obtained via networked mobile graphical sketch interfaces) demonstrate the proposed methodology.},
booktitle = {Proceedings of the ACM/IEEE Sixth International Conference on Cyber-Physical Systems},
pages = {80–89},
numpages = {10},
keywords = {human-in-the-loop, autonomous sensor networks, statistical signal processing},
location = {Seattle, Washington},
series = {ICCPS '15}
}

@inbook{10.1145/3384419.3430776,
author = {Lu, Chris Xiaoxuan and Saputra, Muhamad Risqi U. and Zhao, Peijun and Almalioglu, Yasin and de Gusmao, Pedro P. B. and Chen, Changhao and Sun, Ke and Trigoni, Niki and Markham, Andrew},
title = {MilliEgo: Single-Chip MmWave Radar Aided Egomotion Estimation via Deep Sensor Fusion},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3384419.3430776},
abstract = {Robust and accurate trajectory estimation of mobile agents such as people and robots is a key requirement for providing spatial awareness for emerging capabilities such as augmented reality or autonomous interaction. Although currently dominated by optical techniques e.g., visual-inertial odometry these suffer from challenges with scene illumination or featureless surfaces. As an alternative, we propose milliEgo, a novel deep-learning approach to robust egomotion estimation which exploits the capabilities of low-cost mm Wave radar. Although mmWave radar has a fundamental advantage over monocular cameras of being metric i.e., providing absolute scale or depth, current single chip solutions have limited and sparse imaging resolution, making existing point-cloud registration techniques brittle. We propose a new architecture that is optimized for solving this challenging pose transformation problem. Secondly, to robustly fuse mmWave pose estimates with additional sensors, e.g. inertial or visual sensors we introduce a mixed attention approach to deep fusion. Through extensive experiments, we demonstrate our proposed system is able to achieve 1.3% 3D error drift and generalizes well to unseen environments. We also show that the neural architecture can be made highly efficient and suitable for real-time embedded applications.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {109–122},
numpages = {14}
}

@article{10.1145/3385008,
author = {Perelman, Brandon S. and Evans III, Arthur W. and Schaefer, Kristin E.},
title = {Where Do You Think You're Going? Characterizing Spatial Mental Models from Planned Routes},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {4},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3385008},
doi = {10.1145/3385008},
abstract = {Route planning is a critical behavior for human-intelligent agent (H-IA) team mobility. The scientific community has made major advances in improving route planner optimality and speed. However, human factors, such as the ability to predict and understand teammates’ actions and goals, are necessary for trust development in H-IA teams. Trust is especially critical when agents’ behaviors do not match human team members’ expectations, or the human cannot understand the agent's underlying reasoning process. To address this issue, the artificial intelligence community has pushed toward creating human-like agent behaviors using machine learning. The problem with this approach is that we do not yet have a clear understanding of what constitutes human-like behavior across the breadth of tasks that H-IA teams undertake. This article describes an investigation and comparison of human and agent route planning behaviors, the interplay between humans and agents in collaborative planning, and the role of trust in this collaborative process. Finally, we propose a data-driven methodology for characterizing and visualizing differences among routes planned by humans and agents. This methodology provides a means to advance compatible mental model metrics and theory by informing targeted transparency manipulations, thereby improving the speed and quality of routes produced by H-IA teams.},
journal = {J. Hum.-Robot Interact.},
month = {may},
articleno = {23},
numpages = {55},
keywords = {spatial planning, spatial navigation, spatial cognition, navigation systems, route planning, mental models, human-robot interaction, autonomous systems, Human-autonomy teaming, GPS systems}
}

@article{10.1145/2930957.2930962,
author = {Altmeyer, Sebastian and Navet, Nicolas},
title = {Towards a Declarative Modeling and Execution Framework for Real-Time Systems},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2930957.2930962},
doi = {10.1145/2930957.2930962},
abstract = {Our work is a contribution towards addressing what Thomas Henziger called the grand challenge in embedded software design [5]: "offering high-level programming models that exposes the execution properties of a system in a way that permits the programmer to express desired reaction and execution requirements, permits the compiler and run-time systems to ensure that these requirements are satisfied". In the programming model we describe here, the developer states the permissible timing behavior of the system, a system synthesis step involving both analysis and optimization generates a scheduling solution which at run-time is enforced by the execution environment. With respect to the synchronous programming models, our approach implements a weaker version of time-determinism, still providing a form of timing-predictability sufficient in many applications while remaining closer to mainstay software development practices. This approach is currently being implemented and experimented in the CPAL language development tools and associated runtime environment.},
journal = {SIGBED Rev.},
month = {apr},
pages = {30–33},
numpages = {4}
}

@inproceedings{10.1145/3402597.3402601,
author = {Hong, Liang and Yangfan, Zhou and Lihua, Li and Xiaofeng, He and Junxi, Chen and Lingna, Chen},
title = {Monocular SLAM Based on Semi-Direct Method},
year = {2020},
isbn = {9781450387644},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3402597.3402601},
doi = {10.1145/3402597.3402601},
abstract = {We propose a monocular SLAM based on semi-direct method, which combines the advantages of direct method and indirect (feature-based) method. On the basis of extracting the salient feature points of the image, the pose of the camera is estimated by the direct method. The key-frame descriptors are represented by image description model based on learning. The key-frame descriptors are combined with the effective retrieval strategy to get rough closed-loop detection, and the descriptors are combined with direct matching to verify closed-loop candidate. Compared with popular open source algorithms, our method is tested on the publicly available datasets. Compared with state-of-the-art direct-based method and indirect-based method slam, our experimental results improve the overall performance of the system.},
booktitle = {Proceedings of the 2020 3rd International Conference on Robot Systems and Applications},
pages = {21–24},
numpages = {4},
keywords = {Monocular SLAM, Semi-direct method, Loop closure},
location = {Chengdu, China},
series = {ICRSA 2020}
}

@inproceedings{10.5555/3463952.3464114,
author = {Yang, Bo and Ma, Chaofan and Xia, Xiaofang},
title = {Drone Formation Control via Belief-Correlated Imitation Learning},
year = {2021},
isbn = {9781450383073},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {The proliferation of unmanned aerial vehicles (UAVs) has flourished various intelligent services, in which the effective coordination plays a significant role in enhancing swarm execution efficiency. However, due to the unreliable communication in the air as well as the heterogeneity in operation mode, it is challenging to achieve highly coordinated actions, particularly in the fully distributed environment with incomplete observations. In this paper, we leverage the generative adversarial imitation learning (GAIL) technique to coordinate the drones' actions by directly imitating the peer's demonstrations. In order to characterize the true environment state under local incomplete observations, we transform historical observation-action trajectories into belief representations, which are trained in conjunction with the imitation policies. We also gain regularized belief representations by correlating the prediction of future states, the trace of historical contexts, and the action-assisted guidance information, which contribute to more accurate imitation policies. We evaluate the proposed algorithm on the drones' formation control scenario. Evaluation results show the superiorities on imitation accuracy, teamwork execution time and energy cost.},
booktitle = {Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {1407–1415},
numpages = {9},
keywords = {unmanned aerial vehicles, generative adversarial imitation learning, formation control},
location = {Virtual Event, United Kingdom},
series = {AAMAS '21}
}

@inbook{10.1145/3447548.3467308,
author = {Zeng, Qingkai and Lin, Jinfeng and Yu, Wenhao and Cleland-Huang, Jane and Jiang, Meng},
title = {Enhancing Taxonomy Completion with Concept Generation via Fusing Relational Representations},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3447548.3467308},
abstract = {Automatic construction of a taxonomy supports many applications in e-commerce, web search, and question answering. Existing taxonomy expansion or completion methods assume that new concepts have been accurately extracted and their embedding vectors learned from the text corpus. However, one critical and fundamental challenge in fixing the incompleteness of taxonomies is the incompleteness of the extracted concepts, especially for those whose names have multiple words and consequently low frequency in the corpus. To resolve the limitations of extraction-based methods, we propose GenTaxo to enhance taxonomy completion by identifying positions in existing taxonomies that need new concepts and then generating appropriate concept names. Instead of relying on the corpus for concept embeddings, GenTaxo learns the contextual embeddings from their surrounding graph-based and language-based relational information, and leverages the corpus for pre-training a concept name generator. Experimental results demonstrate that GenTaxo improves the completeness of taxonomies over existing methods.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {2104–2113},
numpages = {10}
}

@inproceedings{10.5555/2772879.2772947,
author = {Ramchurn, Sarvapali D. and Huynh, Trung Dong and Ikuno, Yuki and Flann, Jack and Wu, Feng and Moreau, Luc and Jennings, Nicholas R. and Fischer, Joel E. and Jiang, Wenchao and Rodden, Tom and Simpson, Edwin and Reece, Steven and Roberts, Stephen J.},
title = {HAC-ER: A Disaster Response System Based on Human-Agent Collectives},
year = {2015},
isbn = {9781450334136},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {This paper proposes a novel disaster management system called HAC-ER that addresses some of the challenges faced by emergency responders by enabling humans and agents, using state-of-the-art algorithms, to collaboratively plan and carry out tasks in teams referred to as human-agent collectives. In particular, HAC-ER utilises crowdsourcing combined with machine learning to extract situational awareness information from large streams of reports posted by members of the public and trusted organisations. We then show how this information can inform human-agent teams in coordinating multi-UAV deployments as well as task planning for responders on the ground. Finally, HAC-ER incorporates a tool for tracking and analysing the provenance of information shared across the entire system. In summary, this paper describes a prototype system, validated by real-world emergency responders, that combines several state-of-the-art techniques for integrating humans and agents, and illustrates, for the first time, how such an approach can enable more effective disaster response operations.},
booktitle = {Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
pages = {533–541},
numpages = {9},
keywords = {innovative applications, human and agents, disaster response},
location = {Istanbul, Turkey},
series = {AAMAS '15}
}

@inproceedings{10.1145/2996913.2996984,
author = {Jeong, Myeong-Hun and Cai, Yaping and Sullivan, Clair J. and Wang, Shaowen},
title = {Data Depth Based Clustering Analysis},
year = {2016},
isbn = {9781450345897},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2996913.2996984},
doi = {10.1145/2996913.2996984},
abstract = {This paper proposes a new algorithm for identifying patterns within data, based on data depth. Such a clustering analysis has an enormous potential to discover previously unknown insights from existing data sets. Many clustering algorithms already exist for this purpose. However, most algorithms are not affine invariant. Therefore, they must operate with different parameters after the data sets are rotated, scaled, or translated. Further, most clustering algorithms, based on Euclidean distance, can be sensitive to noises because they have no global perspective. Parameter selection also significantly affects the clustering results of each algorithm. Unlike many existing clustering algorithms, the proposed algorithm, called data depth based clustering analysis (DBCA), is able to detect coherent clusters after the data sets are affine transformed without changing a parameter. It is also robust to noises because using data depth can measure centrality and outlyingness of the underlying data. Further, it can generate relatively stable clusters by varying the parameter. The experimental comparison with the leading state-of-the-art alternatives demonstrates that the proposed algorithm outperforms DBSCAN and HDBSCAN in terms of affine invariance, and exceeds or matches the ro-bustness to noises of DBSCAN or HDBSCAN. The robust-ness to parameter selection is also demonstrated through the case study of clustering twitter data.},
booktitle = {Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems},
articleno = {29},
numpages = {10},
keywords = {affine invariant clustering, data depth, density-based clustering analysis, cluster analysis},
location = {Burlingame, California},
series = {SIGSPACIAL '16}
}

@inbook{10.1145/3458380.3458399,
author = {Liu, Shan and Huang, Lilian and Shi, Xu and Sun, Yi},
title = {Siamese Networks with Distance-IoU Loss for Real-Time Visual Tracking},
year = {2021},
isbn = {9781450389365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3458380.3458399},
abstract = {The combination of siamese networks and region proposal networks (RPN) has drawn attention of a great many scholars in the field of visual object tracking with its balanced speed and accuracy. SiamRPN is composed of siamese subnetwork and RPN subnetwork. It abandons the traditional multi-scale testing and online tracking, which greatly meets real-time requirements. Aiming at the limited tracking accuracy of the SiamRPN, we propose the siamese networks with Distance-IoU Loss for real-time visual tracking. The first is to crop and fuse the multi-layer feature maps extracted by the feature extraction network to make full use of the multi-layer features. The weights of weighted fusion are obtained by network learning rather than the manual setting. For the loss function of the bounding box regression, we choose the Distance-IoU loss to replace the Smooth loss adopted by SiamRPN, which greatly improves the performance of tracking algorithm. We compare our algorithm with other state-of-the-art tracking algorithms on the VOT2016, VOT2018, and UAV123 datasets. The experimental results show that our algorithm shows better tracking accuracy and robustness in various scenarios and works at 154 frames per second, which verifies the effectiveness of the algorithm.},
booktitle = {2021 5th International Conference on Digital Signal Processing},
pages = {109–115},
numpages = {7}
}

@article{10.1145/3374857.3374862,
author = {Kelley, Dean},
title = {Technical Report Column},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0163-5700},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3374857.3374862},
doi = {10.1145/3374857.3374862},
abstract = {Welcome to the Technical Reports Column. If your institution publishes technical reports that you'd like to have included here, please contact me at the email address above.},
journal = {SIGACT News},
month = {dec},
pages = {14–25},
numpages = {12}
}


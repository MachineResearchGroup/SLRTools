
@Article{rs12091357,
AUTHOR = {Maimaitijiang, Maitiniyazi and Sagan, Vasit and Sidike, Paheding and Daloye, Ahmad M. and Erkbol, Hasanjan and Fritschi, Felix B.},
TITLE = {Crop Monitoring Using Satellite/UAV Data Fusion and Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1357},
URL = {https://www.mdpi.com/2072-4292/12/9/1357},
ISSN = {2072-4292},
ABSTRACT = {Non-destructive crop monitoring over large areas with high efficiency is of great significance in precision agriculture and plant phenotyping, as well as decision making with regards to grain policy and food security. The goal of this research was to assess the potential of combining canopy spectral information with canopy structure features for crop monitoring using satellite/unmanned aerial vehicle (UAV) data fusion and machine learning. Worldview-2/3 satellite data were tasked synchronized with high-resolution RGB image collection using an inexpensive unmanned aerial vehicle (UAV) at a heterogeneous soybean (Glycine max (L.) Merr.) field. Canopy spectral information (i.e., vegetation indices) was extracted from Worldview-2/3 data, and canopy structure information (i.e., canopy height and canopy cover) was derived from UAV RGB imagery. Canopy spectral and structure information and their combination were used to predict soybean leaf area index (LAI), aboveground biomass (AGB), and leaf nitrogen concentration (N) using partial least squares regression (PLSR), random forest regression (RFR), support vector regression (SVR), and extreme learning regression (ELR) with a newly proposed activation function. The results revealed that: (1) UAV imagery-derived high-resolution and detailed canopy structure features, canopy height, and canopy coverage were significant indicators for crop growth monitoring, (2) integration of satellite imagery-based rich canopy spectral information with UAV-derived canopy structural features using machine learning improved soybean AGB, LAI, and leaf N estimation on using satellite or UAV data alone, (3) adding canopy structure information to spectral features reduced background soil effect and asymptotic saturation issue to some extent and led to better model performance, (4) the ELR model with the newly proposed activated function slightly outperformed PLSR, RFR, and SVR in the prediction of AGB and LAI, while RFR provided the best result for N estimation. This study introduced opportunities and limitations of satellite/UAV data fusion using machine learning in the context of crop monitoring.},
DOI = {10.3390/rs12091357}
}



@Article{ai1020010,
AUTHOR = {Tang, Ziyang and Liu, Xiang and Chen, Hanlin and Hupy, Joseph and Yang, Baijian},
TITLE = {Deep Learning Based Wildfire Event Object Detection from 4K Aerial Images Acquired by UAS},
JOURNAL = {AI},
VOLUME = {1},
YEAR = {2020},
NUMBER = {2},
PAGES = {166--179},
URL = {https://www.mdpi.com/2673-2688/1/2/10},
ISSN = {2673-2688},
ABSTRACT = {Unmanned Aerial Systems, hereafter referred to as UAS, are of great use in hazard events such as wildfire due to their ability to provide high-resolution video imagery over areas deemed too dangerous for manned aircraft and ground crews. This aerial perspective allows for identification of ground-based hazards such as spot fires and fire lines, and to communicate this information with fire fighting crews. Current technology relies on visual interpretation of UAS imagery, with little to no computer-assisted automatic detection. With the help of big labeled data and the significant increase of computing power, deep learning has seen great successes on object detection with fixed patterns, such as people and vehicles. However, little has been done for objects, such as spot fires, with amorphous and irregular shapes. Additional challenges arise when data are collected via UAS as high-resolution aerial images or videos; an ample solution must provide reasonable accuracy with low delays. In this paper, we examined 4K (    3840 × 2160    ) videos collected by UAS from a controlled burn and created a set of labeled video sets to be shared for public use. We introduce a coarse-to-fine framework to auto-detect wildfires that are sparse, small, and irregularly-shaped. The coarse detector adaptively selects the sub-regions that are likely to contain the objects of interest while the fine detector passes only the details of the sub-regions, rather than the entire 4K region, for further scrutiny. The proposed two-phase learning therefore greatly reduced time overhead and is capable of maintaining high accuracy. Compared against the real-time one-stage object backbone of YoloV3, the proposed methods improved the mean average precision(mAP) from     0 . 29     to     0 . 67    , with an average inference speed of 7.44 frames per second. Limitations and future work are discussed with regard to the design and the experiment results.},
DOI = {10.3390/ai1020010}
}



@Article{rs12091383,
AUTHOR = {Tian, Yanlin and Jia, Mingming and Wang, Zongming and Mao, Dehua and Du, Baojia and Wang, Chao},
TITLE = {Monitoring Invasion Process of Spartina alterniflora by Seasonal Sentinel-2 Imagery and an Object-Based Random Forest Classification},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1383},
URL = {https://www.mdpi.com/2072-4292/12/9/1383},
ISSN = {2072-4292},
ABSTRACT = {In the late 1990s, the exotic plant Spartina alterniflora (S. alterniflora), was introduced to the Zhangjiang Estuary of China for tidal zone reclamation and protection. However, it invaded rapidly and has caused serious ecological problems. Accurate information on the seasonal invasion of S. alterniflora is vital to understand invasion pattern and mechanism, especially at a high temporal resolution. This study aimed to explore the S. alterniflora invasion process at a seasonal scale from 2016 to 2018. However, due to the uncertainties caused by periodic inundation of local tides, accurately monitoring the spatial extent of S. alterniflora is challenging. Thus, to achieve the goal and address the challenge, we firstly built a high-quality seasonal Sentinel-2 image collection by developing a new submerged S. alterniflora index (SAI) to reduce the errors caused by high tide fluctuations. Then, an object-based random forest (RF) classification method was applied to the image collection. Finally, seasonal extents of S. alterniflora were captured. Results showed that (1) the red edge bands (bands 5, 6, and 7) of Sentinel-2 imagery played critical roles in delineating submerged S. alterniflora; (2) during March 2016 to November 2018, the extent of S. alterniflora increased from 151.7 to 270.3 ha, with an annual invasion rate of 39.5 ha; (3) S. alterniflora invaded with a rate of 31.5 ha/season during growing season and 12.1 ha/season during dormant season. To our knowledge, this is the first study monitoring S. alterniflora invasion process at a seasonal scale during continuous years, discovering that S. alterniflora also expands during dormant seasons. This discovery is of great significance for understanding the invasion pattern and mechanism of S. alterniflora and will facilitate coastal biodiversity conservation efforts.},
DOI = {10.3390/rs12091383}
}



@Article{su12093581,
AUTHOR = {Postorino, Maria Nadia and Sarné, Giuseppe M. L.},
TITLE = {Reinventing Mobility Paradigms: Flying Car Scenarios and Challenges for Urban Mobility},
JOURNAL = {Sustainability},
VOLUME = {12},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {3581},
URL = {https://www.mdpi.com/2071-1050/12/9/3581},
ISSN = {2071-1050},
ABSTRACT = {Flying vehicles are receiving more and more attention and are becoming an opportunity to start a new urban mobility paradigm. The most interesting feature of flying cars is the expected opportunity they could offer to reduce congestion, traffic jams and the loss of time to move between origin/destination pairs in urban contexts. In this perspective, urban air mobility might meet the concept of &ldquo;sustainable mobility&rdquo;, intended as the ideal model of a transport system that minimizes the environmental impacts by maximizing efficiency and travel speed. For transport engineering planning issues, further knowledge is required in this field to understand the effects that a possible urban air mobility system, including the ground traffic component, could have in terms of sustainable mobility in the above meaning. This paper contributes to this topic by providing an analysis of different urban flying car scenarios by using an agent-based approach with different traffic conditions. The preliminary results obtained on some test networks and focusing on travel cost effects suggest that the expected advantages the flying car will depend on trip origin/destination points, average distances travelled in the urban contexts and the location of transition nodes, which are introduced as interchange nodes between aerial and ground mode.},
DOI = {10.3390/su12093581}
}



@Article{s20092530,
AUTHOR = {Mazzia, Vittorio and Comba, Lorenzo and Khaliq, Aleem and Chiaberge, Marcello and Gay, Paolo},
TITLE = {UAV and Machine Learning Based Refinement of a Satellite-Driven Vegetation Index for Precision Agriculture},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {2530},
URL = {https://www.mdpi.com/1424-8220/20/9/2530},
ISSN = {1424-8220},
ABSTRACT = {Precision agriculture is considered to be a fundamental approach in pursuing a low-input, high-efficiency, and sustainable kind of agriculture when performing site-specific management practices. To achieve this objective, a reliable and updated description of the local status of crops is required. Remote sensing, and in particular satellite-based imagery, proved to be a valuable tool in crop mapping, monitoring, and diseases assessment. However, freely available satellite imagery with low or moderate resolutions showed some limits in specific agricultural applications, e.g., where crops are grown by rows. Indeed, in this framework, the satellite&rsquo;s output could be biased by intra-row covering, giving inaccurate information about crop status. This paper presents a novel satellite imagery refinement framework, based on a deep learning technique which exploits information properly derived from high resolution images acquired by unmanned aerial vehicle (UAV) airborne multispectral sensors. To train the convolutional neural network, only a single UAV-driven dataset is required, making the proposed approach simple and cost-effective. A vineyard in Serralunga d&rsquo;Alba (Northern Italy) was chosen as a case study for validation purposes. Refined satellite-driven normalized difference vegetation index (NDVI) maps, acquired in four different periods during the vine growing season, were shown to better describe crop status with respect to raw datasets by correlation analysis and ANOVA. In addition, using a K-means based classifier, 3-class vineyard vigor maps were profitably derived from the NDVI maps, which are a valuable tool for growers.},
DOI = {10.3390/s20092530}
}



@Article{w12051281,
AUTHOR = {Chen, Je-Chian and Wang, Yu-Min},
TITLE = {Comparing Activation Functions in Modeling Shoreline Variation Using Multilayer Perceptron Neural Network},
JOURNAL = {Water},
VOLUME = {12},
YEAR = {2020},
NUMBER = {5},
ARTICLE-NUMBER = {1281},
URL = {https://www.mdpi.com/2073-4441/12/5/1281},
ISSN = {2073-4441},
ABSTRACT = {The study has modeled shoreline changes by using a multilayer perceptron (MLP) neural network with the data collected from five beaches in southern Taiwan. The data included aerial survey maps of the Forestry Bureau for years 1982, 2002, and 2006, which served as predictors, while the unmanned aerial vehicle (UAV) surveyed data of 2019 served as the respondent. The MLP was configured using five different activation functions with the aim of evaluating their significance. These functions were Identity, Tahn, Logistic, Exponential, and Sine Functions. The results have shown that the performance of an MLP model may be affected by the choice of an activation function. Logistic and the Tahn activation functions outperformed the other models, with Logistic performing best in three beaches and Tahn having the rest. These findings suggest that the application of machine learning to shoreline changes should be accompanied by an extensive evaluation of the different activation functions.},
DOI = {10.3390/w12051281}
}



@Article{rs12091438,
AUTHOR = {Silva, Vanessa Sousa da and Silva, Carlos Alberto and Mohan, Midhun and Cardil, Adrián and Rex, Franciel Eduardo and Loureiro, Gabrielle Hambrecht and Almeida, Danilo Roberti Alves de and Broadbent, Eben North and Gorgens, Eric Bastos and Dalla Corte, Ana Paula and Silva, Emanuel Araújo and Valbuena, Rubén and Klauberg, Carine},
TITLE = {Combined Impact of Sample Size and Modeling Approaches for Predicting Stem Volume in Eucalyptus spp. Forest Plantations Using Field and LiDAR Data},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1438},
URL = {https://www.mdpi.com/2072-4292/12/9/1438},
ISSN = {2072-4292},
ABSTRACT = {Light Detection and Ranging (LiDAR) remote sensing has been established as one of the most promising tools for large-scale forest monitoring and mapping. Continuous advances in computational techniques, such as machine learning algorithms, have been increasingly improving our capability to model forest attributes accurately and at high spatial and temporal resolution. While there have been previous studies exploring the use of LiDAR and machine learning algorithms for forest inventory modeling, as yet, no studies have demonstrated the combined impact of sample size and different modeling techniques for predicting and mapping stem total volume in industrial Eucalyptus spp. tree plantations. This study aimed to compare the combined effects of parametric and nonparametric modeling methods for estimating volume in Eucalyptus spp. tree plantation using airborne LiDAR data while varying the reference data (sample size). The modeling techniques were compared in terms of root mean square error (RMSE), bias, and R2 with 500 simulations. The best performance was verified for the ordinary least-squares (OLS) method, which was able to provide comparable results to the traditional forest inventory approaches using only 40% (n = 63; ~0.04 plots/ha) of the total field plots, followed by the random forest (RF) algorithm with identical sample size values. This study provides solutions for increasing the industry efficiency in monitoring and managing forest plantation stem volume for the paper and pulp supply chain.},
DOI = {10.3390/rs12091438}
}



@Article{rs12091444,
AUTHOR = {Abdollahi, Abolfazl and Pradhan, Biswajeet and Shukla, Nagesh and Chakraborty, Subrata and Alamri, Abdullah},
TITLE = {Deep Learning Approaches Applied to Remote Sensing Datasets for Road Extraction: A State-Of-The-Art Review},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1444},
URL = {https://www.mdpi.com/2072-4292/12/9/1444},
ISSN = {2072-4292},
ABSTRACT = {One of the most challenging research subjects in remote sensing is feature extraction, such as road features, from remote sensing images. Such an extraction influences multiple scenes, including map updating, traffic management, emergency tasks, road monitoring, and others. Therefore, a systematic review of deep learning techniques applied to common remote sensing benchmarks for road extraction is conducted in this study. The research is conducted based on four main types of deep learning methods, namely, the GANs model, deconvolutional networks, FCNs, and patch-based CNNs models. We also compare these various deep learning models applied to remote sensing datasets to show which method performs well in extracting road parts from high-resolution remote sensing images. Moreover, we describe future research directions and research gaps. Results indicate that the largest reported performance record is related to the deconvolutional nets applied to remote sensing images, and the F1 score metric of the generative adversarial network model, DenseNet method, and FCN-32 applied to UAV and Google Earth images are high: 96.08%, 95.72%, and 94.59%, respectively.},
DOI = {10.3390/rs12091444}
}



@Article{rs12091447,
AUTHOR = {Adamo, Maria and Tomaselli, Valeria and Tarantino, Cristina and Vicario, Saverio and Veronico, Giuseppe and Lucas, Richard and Blonda, Palma},
TITLE = {Knowledge-Based Classification of Grassland Ecosystem Based on Multi-Temporal WorldView-2 Data and FAO-LCCS Taxonomy},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1447},
URL = {https://www.mdpi.com/2072-4292/12/9/1447},
ISSN = {2072-4292},
ABSTRACT = {Grassland ecosystems can provide a variety of services for humans, such as carbon storage, food production, crop pollination and pest regulation. However, grasslands are today one of the most endangered ecosystems due to land use change, agricultural intensification, land abandonment as well as climate change. The present study explores the performance of a knowledge-driven GEOgraphic-Object&mdash;based Image Analysis (GEOBIA) learning scheme to classify Very High Resolution (VHR) images for natural grassland ecosystem mapping. The classification was applied to a Natura 2000 protected area in Southern Italy. The Food and Agricultural Organization Land Cover Classification System (FAO-LCCS) hierarchical scheme was instantiated in the learning phase of the algorithm. Four multi-temporal WorldView-2 (WV-2) images were classified by combining plant phenology and agricultural practices rules with prior-image spectral knowledge. Drawing on this knowledge, spectral bands and entropy features from one single date (Post Peak of Biomass) were firstly used for multiple-scale image segmentation into Small Objects (SO) and Large Objects (LO). Thereafter, SO were labelled by considering spectral and context-sensitive features from the whole multi-seasonal data set available together with ancillary data. Lastly, the labelled SO were overlaid to LO segments and, in turn, the latter were labelled by adopting FAO-LCCS criteria about the SOs presence dominance in each LO. Ground reference samples were used only for validating the SO and LO output maps. The knowledge driven GEOBIA classifier for SO classification obtained an OA value of 97.35% with an error of 0.04. For LO classification the value was 75.09% with an error of 0.70. At SO scale, grasslands ecosystem was classified with 92.6%, 99.9% and 96.1% of User&rsquo;s, Producer&rsquo;s Accuracy and F1-score, respectively. The findings reported indicate that the knowledge-driven approach not only can be applied for (semi)natural grasslands ecosystem mapping in vast and not accessible areas but can also reduce the costs of ground truth data acquisition. The approach used may provide different level of details (small and large objects in the scene) but also indicates how to design and validate local conservation policies.},
DOI = {10.3390/rs12091447}
}



@Article{drones4020018,
AUTHOR = {Gorkin, Robert and Adams, Kye and Berryman, Matthew J and Aubin, Sam and Li, Wanqing and Davis, Andrew R and Barthelemy, Johan},
TITLE = {Sharkeye: Real-Time Autonomous Personal Shark Alerting via Aerial Surveillance},
JOURNAL = {Drones},
VOLUME = {4},
YEAR = {2020},
NUMBER = {2},
ARTICLE-NUMBER = {18},
URL = {https://www.mdpi.com/2504-446X/4/2/18},
ISSN = {2504-446X},
ABSTRACT = {While aerial shark spotting has been a standard practice for beach safety for decades, new technologies offer enhanced opportunities, ranging from drones/unmanned aerial vehicles (UAVs) that provide new viewing capabilities, to new apps that provide beachgoers with up-to-date risk analysis before entering the water. This report describes the Sharkeye platform, a first-of-its-kind project to demonstrate personal shark alerting for beachgoers in the water and on land, leveraging innovative UAV image collection, cloud-hosted machine learning detection algorithms, and reporting via smart wearables. To execute, our team developed a novel detection algorithm trained via machine learning based on aerial footage of real sharks and rays collected at local beaches, hosted and deployed the algorithm in the cloud, and integrated push alerts to beachgoers in the water via a shark app to run on smartwatches. The project was successfully trialed in the field in Kiama, Australia, with over 350 detection events recorded, followed by the alerting of multiple smartwatches simultaneously both on land and in the water, and with analysis capable of detecting shark analogues, rays, and surfers in average beach conditions, and all based on ~1 h of training data in total. Additional demonstrations showed potential of the system to enable lifeguard-swimmer communication, and the ability to create a network on demand to enable the platform. Our system was developed to provide swimmers and surfers with immediate information via smart apps, empowering lifeguards/lifesavers and beachgoers to prevent unwanted encounters with wildlife before it happens.},
DOI = {10.3390/drones4020018}
}



@Article{rs12091461,
AUTHOR = {Sancho Martínez, Jorge and Fernández, Yadira Bajón and Leinster, Paul and Casado, Mónica Rivas},
TITLE = {Combining Unmanned Aircraft Systems and Image Processing for Wastewater Treatment Plant Asset Inspection},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1461},
URL = {https://www.mdpi.com/2072-4292/12/9/1461},
ISSN = {2072-4292},
ABSTRACT = {Wastewater treatment plants are essential for preserving the water quality of freshwater and marine ecosystems. It is estimated that, in the UK, as much as 11 billion liters of wastewater are treated on a daily basis. Effective and efficient treatment of wastewater requires treatment plants to be maintained in good condition. Recent studies have highlighted the potential of unmanned aircraft systems (UASs) and image processing to be used in autonomous and automated monitoring systems. However, the combined use of UASs and image processing for wastewater treatment plant inspections has not yet been tested. This paper presents a novel image processing-UAS framework for the identification of failures in trickling filters and activated sludge facilities. The results show that the proposed framework has an accuracy of 95% in the detection of failures in activated sludge assets, with the accuracy ranging between 55% and 81% for trickling filters. These results are promising and they highlight the potential use of the technology for the inspection of wastewater treatment plants.},
DOI = {10.3390/rs12091461}
}



@Article{rs12091470,
AUTHOR = {Ding, Yanling and Zhang, Hongyan and Wang, Zhongqiang and Xie, Qiaoyun and Wang, Yeqiao and Liu, Lin and Hall, Christopher C.},
TITLE = {A Comparison of Estimating Crop Residue Cover from Sentinel-2 Data Using Empirical Regressions and Machine Learning Methods},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1470},
URL = {https://www.mdpi.com/2072-4292/12/9/1470},
ISSN = {2072-4292},
ABSTRACT = {Quantifying crop residue cover (CRC) on field surfaces is important for monitoring the tillage intensity and promoting sustainable management. Remote-sensing-based techniques have proven practical for determining CRC, however, the methods used are primarily limited to empirical regression based on crop residue indices (CRIs). This study provides a systematic evaluation of empirical regressions and machine learning (ML) algorithms based on their ability to estimate CRC using Sentinel-2 Multispectral Instrument (MSI) data. Unmanned aerial vehicle orthomosaics were used to extracted ground CRC for training Sentinel-2 data-based CRC models. For empirical regression, nine MSI bands, 10 published CRIs, three proposed CRIs, and four mean textural features were evaluated using univariate linear regression. The best performance was obtained by a three-band index calculated using (B2 &minus; B4)/(B2 &minus; B12), with an R2cv of 0.63 and RMSEcv of 6.509%, using a 10-fold cross-validation. The methodologies of partial least squares regression (PLSR), artificial neural network (ANN), Gaussian process regression (GPR), support vector regression (SVR), and random forest (RF) were compared with four groups of predictors, including nine MSI bands, 13 CRIs, a combination of MSI bands and mean textural features, and a combination of CRIs and textural features. In general, ML approaches achieved high accuracy. A PLSR model with 13 CRIs and textural features resulted in an accuracy of R2cv = 0.66 and RMSEcv = 6.427%. An RF model with predictors of MSI bands and textural features estimated CRC with an R2cv = 0.61 and RMSEcv = 6.415%. The estimation was improved by an SVR model with the same input predictors (R2cv = 0.67, RMSEcv = 6.343%), followed by a GPR model based on CRIs and textural features. The performance of GPR models was further improved by optimal input variables. A GPR model with six input variables, three MSI bands and three textural features, performed the best, with R2cv = 0.69 and RMSEcv = 6.149%. This study provides a reference for estimating CRC from Sentinel-2 imagery using ML approaches. The GPR approach is recommended. A combination of spectral information and textural features leads to an improvement in the retrieval of CRC.},
DOI = {10.3390/rs12091470}
}



@Article{sym12050791,
AUTHOR = {Zhao, Peng and Wang, Jianzhong and Kong, Lingren},
TITLE = {Construction and Optimization of Biconnected and Wide-Coverage Topology Based on Node Mobility},
JOURNAL = {Symmetry},
VOLUME = {12},
YEAR = {2020},
NUMBER = {5},
ARTICLE-NUMBER = {791},
URL = {https://www.mdpi.com/2073-8994/12/5/791},
ISSN = {2073-8994},
ABSTRACT = {Constructing a communications topology with fault tolerance and effective coverage plays an important role in wireless sensor networks. This paper is aimed at constructing and maintaining a biconnected topology, while minimizing the movement distance of the nodes and maximizing the coverage of the field of interest. First, it presents a new model with the motion constraint. If the nodes move at distance within the limit value calculated by the model, the topology is always connected, whether the neighbors of nodes are dynamic or static. Secondly, it improves the coverage strategy based on the nearest neighbor rule (NNR) and finds a rule of nodes&rsquo; spreading so that the nodes are distributed evenly and the spacing of the adjacent nodes is controllable. In addition, the nodes move only when necessary according to the added judgment conditions. Consequently, the movement distance is reduced. The simulation results prove the feasibility and effectiveness of the Localized Topology Optimized Method (LTOM) proposed by this paper. The connected indicators of the system&rsquo;s topology during implementing LTOM are consistent, and the transformation of topology by LTOM is symmetric. Compared with the other distributed algorithm, NNR, LTOM reduces the movement distance of nodes, improves the connected probability, and maximizes the coverage of the topological structures under the biconnected conditions.},
DOI = {10.3390/sym12050791}
}



@Article{geosciences10050172,
AUTHOR = {Randazzo, Giovanni and Barreca, Giovanni and Cascio, Maria and Crupi, Antonio and Fontana, Marco and Gregorio, Francesco and Lanza, Stefania and Muzirafuti, Anselme},
TITLE = {Analysis of Very High Spatial Resolution Images for Automatic Shoreline Extraction and Satellite-Derived Bathymetry Mapping},
JOURNAL = {Geosciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {5},
ARTICLE-NUMBER = {172},
URL = {https://www.mdpi.com/2076-3263/10/5/172},
ISSN = {2076-3263},
ABSTRACT = {The amount of Earth observation images available to the public has been the main source of information, helping governments and decision-makers tackling the current world&rsquo;s most pressing global challenge. However, a number of highly skilled and qualified personnel are still needed to fill the gap and help turn these data into intelligence. In addition, the accuracy of this intelligence relies on the quality of these images in times of temporal, spatial, and spectral resolution. For the purpose of contributing to the global effort aiming at monitoring natural and anthropic processes affecting coastal areas, we proposed a framework for image processing to extract the shoreline and the shallow water depth on GeoEye-1 satellite image and orthomosaic image acquired by an unmanned aerial vehicle (UAV) on the coast of San Vito Lo Capo, with image preprocessing steps involving orthorectification, atmospheric correction, pan sharpening, and binary imaging for water and non-water pixels analysis. Binary imaging analysis step was followed by automatic instantaneous shoreline extraction on a digital image and satellite-derived bathymetry (SDB) mapping on GeoEye-1 water pixels. The extraction of instantaneous shoreline was conducted automatically in ENVI software using a raster to vector (R2V) algorithm, whereas the SDB was computed in ArcGIS software using a log-band ratio method applied on the satellite image and available field data for calibration and vertical referencing. The results obtained from these very high spatial resolution images demonstrated the ability of remote sensing techniques in providing information where techniques using traditional methods present some limitations, especially due to their inability to map hard-to-reach areas and very dynamic near shoreline waters. We noticed that for the period of 5 years, the shoreline of San Vito Lo Capo sand beach migrated about 15 m inland, indicating the high dynamism of this coastal area. The bathymetric information obtained on the GeoEye-1 satellite image provided water depth until 10 m deep with R2 = 0.753. In this paper, we presented cost-effective and practical methods for automatic shoreline extraction and bathymetric mapping of shallow water, which can be adopted for the management and the monitoring of coastal areas.},
DOI = {10.3390/geosciences10050172}
}



@Article{s20092708,
AUTHOR = {Rodoshi, Rehenuma Tasnim and Kim, Taewoon and Choi, Wooyeol},
TITLE = {Resource Management in Cloud Radio Access Network: Conventional and New Approaches},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {2708},
URL = {https://www.mdpi.com/1424-8220/20/9/2708},
ISSN = {1424-8220},
ABSTRACT = {Cloud radio access network (C-RAN) is a promising mobile wireless sensor network architecture to address the challenges of ever-increasing mobile data traffic and network costs. C-RAN is a practical solution to the strict energy-constrained wireless sensor nodes, often found in Internet of Things (IoT) applications. Although this architecture can provide energy efficiency and reduce cost, it is a challenging task in C-RAN to utilize the resources efficiently, considering the dynamic real-time environment. Several research works have proposed different methodologies for effective resource management in C-RAN. This study performs a comprehensive survey on the state-of-the-art resource management techniques that have been proposed recently for this architecture. The resource management techniques are categorized into computational resource management (CRM) and radio resource management (RRM) techniques. Then both of the techniques are further classified and analyzed based on the strategies used in the studies. Remote radio head (RRH) clustering schemes used in CRM techniques are discussed extensively. In this research work, the investigated performance metrics and their validation techniques are critically analyzed. Moreover, other important challenges and open research issues for efficient resource management in C-RAN are highlighted to provide future research direction.},
DOI = {10.3390/s20092708}
}



@Article{s20092721,
AUTHOR = {Khaki, Saeed and Pham, Hieu and Han, Ye and Kuhl, Andy and Kent, Wade and Wang, Lizhi},
TITLE = {Convolutional Neural Networks for Image-Based Corn Kernel Detection and Counting},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {2721},
URL = {https://www.mdpi.com/1424-8220/20/9/2721},
ISSN = {1424-8220},
ABSTRACT = {Precise in-season corn grain yield estimates enable farmers to make real-time accurate harvest and grain marketing decisions minimizing possible losses of profitability. A well developed corn ear can have up to 800 kernels, but manually counting the kernels on an ear of corn is labor-intensive, time consuming and prone to human error. From an algorithmic perspective, the detection of the kernels from a single corn ear image is challenging due to the large number of kernels at different angles and very small distance among the kernels. In this paper, we propose a kernel detection and counting method based on a sliding window approach. The proposed method detects and counts all corn kernels in a single corn ear image taken in uncontrolled lighting conditions. The sliding window approach uses a convolutional neural network (CNN) for kernel detection. Then, a non-maximum suppression (NMS) is applied to remove overlapping detections. Finally, windows that are classified as kernel are passed to another CNN regression model for finding the     ( x , y )     coordinates of the center of kernel image patches. Our experiments indicate that the proposed method can successfully detect the corn kernels with a low detection error and is also able to detect kernels on a batch of corn ears positioned at different angles.},
DOI = {10.3390/s20092721}
}



@Article{w12051369,
AUTHOR = {Jiang, Ling and Hu, Yang and Xia, Xilin and Liang, Qiuhua and Soltoggio, Andrea and Kabir, Syed Rezwan},
TITLE = {A Multi-Scale Mapping Approach Based on a Deep Learning CNN Model for Reconstructing High-Resolution Urban DEMs},
JOURNAL = {Water},
VOLUME = {12},
YEAR = {2020},
NUMBER = {5},
ARTICLE-NUMBER = {1369},
URL = {https://www.mdpi.com/2073-4441/12/5/1369},
ISSN = {2073-4441},
ABSTRACT = {The scarcity of high-resolution urban digital elevation model (DEM) datasets, particularly in certain developing countries, has posed a challenge for many water-related applications such as flood risk management. A solution to address this is to develop effective approaches to reconstruct high-resolution DEMs from their low-resolution equivalents that are more widely available. However, the current high-resolution DEM reconstruction approaches mainly focus on natural topography. Few attempts have been made for urban topography, which is typically an integration of complex artificial and natural features. This study proposed a novel multi-scale mapping approach based on convolutional neural network (CNN) to deal with the complex features of urban topography and to reconstruct high-resolution urban DEMs. The proposed multi-scale CNN model was firstly trained using urban DEMs that contained topographic features at different resolutions, and then used to reconstruct the urban DEM at a specified (high) resolution from a low-resolution equivalent. A two-level accuracy assessment approach was also designed to evaluate the performance of the proposed urban DEM reconstruction method, in terms of numerical accuracy and morphological accuracy. The proposed DEM reconstruction approach was applied to a 121 km2 urbanized area in London, United Kingdom. Compared with other commonly used methods, the current CNN-based approach produced superior results, providing a cost-effective innovative method to acquire high-resolution DEMs in other data-scarce regions.},
DOI = {10.3390/w12051369}
}



@Article{app10103371,
AUTHOR = {Fu, Jun and Yuan, Haikuo and Zhao, Rongqiang and Chen, Zhi and Ren, Luquan},
TITLE = {Peeling Damage Recognition Method for Corn Ear Harvest Using RGB Image},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {3371},
URL = {https://www.mdpi.com/2076-3417/10/10/3371},
ISSN = {2076-3417},
ABSTRACT = {Corn ear damage caused by peeling significantly influence the output and quality of corn harvest. Ear damage recognition is the basis to adjust working parameters and to reduce damage. Image processing is attracting increasing attentions in the field of agriculture. Conventional image processing methods are difficult to be used for recognizing corn ear damage caused by peeling in field harvesting. To address the this problem, in this paper, we propose a peeling damage recognition method based on RGB image. For our method, we develop a dictionary-learning-based method to recognize corn kernels and a thresholding method to recognize ear damage regions. To obtain better performance, we also develop the corroding algorithm and the expanding algorithm for the post-processing of recognized results. The experimental results demonstrate the practicality and accuracy of the proposed method. This study could provide the theoretical basis to develop online peeling damage detection system for corn ear harvesters.},
DOI = {10.3390/app10103371}
}



@Article{s20102778,
AUTHOR = {Azimi, Mohsen and Eslamlou, Armin Dadras and Pekcan, Gokhan},
TITLE = {Data-Driven Structural Health Monitoring and Damage Detection through Deep Learning: State-of-the-Art Review},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {2778},
URL = {https://www.mdpi.com/1424-8220/20/10/2778},
ISSN = {1424-8220},
ABSTRACT = {Data-driven methods in structural health monitoring (SHM) is gaining popularity due to recent technological advancements in sensors, as well as high-speed internet and cloud-based computation. Since the introduction of deep learning (DL) in civil engineering, particularly in SHM, this emerging and promising tool has attracted significant attention among researchers. The main goal of this paper is to review the latest publications in SHM using emerging DL-based methods and provide readers with an overall understanding of various SHM applications. After a brief introduction, an overview of various DL methods (e.g., deep neural networks, transfer learning, etc.) is presented. The procedure and application of vibration-based, vision-based monitoring, along with some of the recent technologies used for SHM, such as sensors, unmanned aerial vehicles (UAVs), etc. are discussed. The review concludes with prospects and potential limitations of DL-based methods in SHM applications.},
DOI = {10.3390/s20102778}
}



@Article{s20102780,
AUTHOR = {Chun, Pang-jo and Yamane, Tatsuro and Izumi, Shota and Kuramoto, Naoya},
TITLE = {Development of a Machine Learning-Based Damage Identification Method Using Multi-Point Simultaneous Acceleration Measurement Results},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {2780},
URL = {https://www.mdpi.com/1424-8220/20/10/2780},
ISSN = {1424-8220},
ABSTRACT = {It is necessary to assess damage properly for the safe use of a structure and for the development of an appropriate maintenance strategy. Although many efforts have been made to measure the vibration of a structure to determine the degree of damage, the accuracy of evaluation is not high enough, so it is difficult to say that a damage evaluation based on vibrations in a structure has not been put to practical use. In this study, we propose a method to evaluate damage by measuring the acceleration of a structure at multiple points and interpreting the results with a Random Forest, which is a kind of supervised machine learning. The proposed method uses the maximum response acceleration, standard deviation, logarithmic decay rate, and natural frequency to improve the accuracy of damage assessment. We propose a three-step Random Forest method to evaluate various damage types based on the results of these many measurements. Then, the accuracy of the proposed method is verified based on the results of a cross-validation and a vibration test of an actual damaged specimen.},
DOI = {10.3390/s20102780}
}



@Article{agriculture10050170,
AUTHOR = {Hong, Suk-Ju and Kim, Sang-Yeon and Kim, Eungchan and Lee, Chang-Hyup and Lee, Jung-Sup and Lee, Dong-Soo and Bang, Jiwoong and Kim, Ghiseok},
TITLE = {Moth Detection from Pheromone Trap Images Using Deep Learning Object Detectors},
JOURNAL = {Agriculture},
VOLUME = {10},
YEAR = {2020},
NUMBER = {5},
ARTICLE-NUMBER = {170},
URL = {https://www.mdpi.com/2077-0472/10/5/170},
ISSN = {2077-0472},
ABSTRACT = {Diverse pheromones and pheromone-based traps, as well as images acquired from insects captured by pheromone-based traps, have been studied and developed to monitor the presence and abundance of pests and to protect plants. The purpose of this study is to construct models that detect three species of pest moths in pheromone trap images using deep learning object detection methods and compare their speed and accuracy. Moth images in pheromone traps were collected for training and evaluation of deep learning detectors. Collected images were then subjected to a labeling process that defines the ground truths of target objects for their box locations and classes. Because there were a few negative objects in the dataset, non-target insects were labeled as unknown class and images of non-target insects were added to the dataset. Moreover, data augmentation methods were applied to the training process, and parameters of detectors that were pre-trained with the COCO dataset were used as initial parameter values. Seven detectors&mdash;Faster R-CNN ResNet 101, Faster R-CNN ResNet 50, Faster R-CNN Inception v.2, R-FCN ResNet 101, Retinanet ResNet 50, Retinanet Mobile v.2, and SSD Inception v.2 were trained and evaluated. Faster R-CNN ResNet 101 detector exhibited the highest accuracy (mAP as 90.25), and seven different detector types showed different accuracy and speed. Furthermore, when unexpected insects were included in the collected images, a four-class detector with an unknown class (non-target insect) showed lower detection error than a three-class detector.},
DOI = {10.3390/agriculture10050170}
}



@Article{rs12101574,
AUTHOR = {Pan, Zhuokun and Xu, Jiashu and Guo, Yubin and Hu, Yueming and Wang, Guangxing},
TITLE = {Deep Learning Segmentation and Classification for Urban Village Using a Worldview Satellite Image Based on U-Net},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {1574},
URL = {https://www.mdpi.com/2072-4292/12/10/1574},
ISSN = {2072-4292},
ABSTRACT = {Unplanned urban settlements exist worldwide. The geospatial information of these areas is critical for urban management and reconstruction planning but usually unavailable. Automatically characterizing individual buildings in the unplanned urban village using remote sensing imagery is very challenging due to complex landscapes and high-density settlements. The newly emerging deep learning method provides the potential to characterize individual buildings in a complex urban village. This study proposed an urban village mapping paradigm based on U-net deep learning architecture. The study area is located in Guangzhou City, China. The Worldview satellite image with eight pan-sharpened bands at a 0.5-m spatial resolution and building boundary vector file were used as research purposes. There are ten sites of the urban villages included in this scene of the Worldview image. The deep neural network model was trained and tested based on the selected six and four sites of the urban village, respectively. Models for building segmentation and classification were both trained and tested. The results indicated that the U-net model reached overall accuracy over 86% for building segmentation and over 83% for the classification. The F1-score ranged from 0.9 to 0.98 for the segmentation, and from 0.63 to 0.88 for the classification. The Interaction over Union reached over 90% for the segmentation and 86% for the classification. The superiority of the deep learning method has been demonstrated through comparison with Random Forest and object-based image analysis. This study fully showed the feasibility, efficiency, and potential of the deep learning in delineating individual buildings in the high-density urban village. More importantly, this study implied that through deep learning methods, mapping unplanned urban settlements could further characterize individual buildings with considerable accuracy.},
DOI = {10.3390/rs12101574}
}



@Article{agronomy10050718,
AUTHOR = {Cholula, Uriel and da Silva, Jorge A. and Marconi, Thiago and Thomasson, J. Alex and Solorzano, Jorge and Enciso, Juan},
TITLE = {Forecasting Yield and Lignocellulosic Composition of Energy Cane Using Unmanned Aerial Systems},
JOURNAL = {Agronomy},
VOLUME = {10},
YEAR = {2020},
NUMBER = {5},
ARTICLE-NUMBER = {718},
URL = {https://www.mdpi.com/2073-4395/10/5/718},
ISSN = {2073-4395},
ABSTRACT = {Crop monitoring and appropriate agricultural management practices of elite germplasm will enhance bioenergy&rsquo;s efficiency. Unmanned aerial systems (UAS) may be a useful tool for this purpose. The objective of this study was to assess the use of UAS with true color and multispectral imagery to predict the yield and total cellulosic content (TCC) of newly created energy cane germplasm. A trial was established in the growing season of 2016 at the Texas A&amp;M AgriLife Research Center in Weslaco, Texas, where 15 energy cane elite lines and three checks were grown on experimental plots, arranged in a complete block design and replicated four times. Four flights were executed at different growth stages in 2018, at the first ratoon crop, using two multi-rotor UAS: the DJI Phantom 4 Pro equipped with RGB camera and the DJI Matrice 100, equipped with multispectral sensor (SlantRange 3p). Canopy cover, canopy height, NDVI (Normalized Difference Vegetation Index), and ExG (Excess Green Index) were extracted from the images and used to perform a stepwise regression to obtain the yield and TCC models. The results showed a good agreement between the predicted and the measured yields (R2 = 0.88); however, a low coefficient of determination was found between the predicted and the observed TCC (R2 = 0.30). This study demonstrated the potential application of UAS to estimate energy cane yield with high accuracy, enabling plant breeders to phenotype larger populations and make selections with higher confidence.},
DOI = {10.3390/agronomy10050718}
}



@Article{rs12101597,
AUTHOR = {Thompson, Laura J. and Puntel, Laila A.},
TITLE = {Transforming Unmanned Aerial Vehicle (UAV) and Multispectral Sensor into a Practical Decision Support System for Precision Nitrogen Management in Corn},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {1597},
URL = {https://www.mdpi.com/2072-4292/12/10/1597},
ISSN = {2072-4292},
ABSTRACT = {Determining the optimal nitrogen (N) rate in corn remains a critical issue, mainly due to unaccounted spatial (e.g., soil properties) and temporal (e.g., weather) variability. Unmanned aerial vehicles (UAVs) equipped with multispectral sensors may provide opportunities to improve N management by the timely informing of spatially variable, in-season N applications. Here, we developed a practical decision support system (DSS) to translate spatial field characteristics and normalized difference red edge (NDRE) values into an in-season N application recommendation. On-farm strip-trials were established at three sites over two years to compare farmer&rsquo;s traditional N management to a split-application N management guided by our UAV sensor-based DSS. The proposed systems increased nitrogen use efficiency 18.3 &plusmn; 6.1 kg grain kg N&minus;1 by reducing N rates by 31 &plusmn; 6.3 kg N ha&minus;1 with no yield differences compared to the farmers&rsquo; traditional management. We identify five avenues for further improvement of the proposed DSS: definition of the initial base N rate, estimation of inputs for sensor algorithms, management zone delineation, high-resolution image normalization approach, and the threshold for triggering N application. Two virtual reference (VR) methods were compared with the high N (HN) reference strip method for normalizing high-resolution sensor data. The VR methods resulted in significantly lower sufficiency index values than those generated by the HN reference, resulting in N fertilization recommendations that were 31.4 &plusmn; 10.3 kg ha&minus;1 higher than the HN reference N fertilization recommendation. The use of small HN reference blocks in contrasting management zones may be more appropriate to translate field-scale, high-resolution imagery into in-season N recommendations. In view of a growing interest in using UAVs in commercial fields and the need to improve crop NUE, further work is needed to refine approaches for translating imagery into in-season N recommendations.},
DOI = {10.3390/rs12101597}
}



@Article{agriengineering2020019,
AUTHOR = {Deng, Xiaoling and Tong, Zejing and Lan, Yubin and Huang, Zixiao},
TITLE = {Detection and Location of Dead Trees with Pine Wilt Disease Based on Deep Learning and UAV Remote Sensing},
JOURNAL = {AgriEngineering},
VOLUME = {2},
YEAR = {2020},
NUMBER = {2},
PAGES = {294--307},
URL = {https://www.mdpi.com/2624-7402/2/2/19},
ISSN = {2624-7402},
ABSTRACT = {Pine wilt disease causes huge economic losses to pine wood forestry because of its destructiveness and rapid spread. This paper proposes a detection and location method of pine wood nematode disease at a large scale adopting UAV (Unmanned Aerial Vehicle) remote sensing and artificial intelligence technology. The UAV remote sensing images were enhanced by computer vision tools. A Faster-RCNN (Faster Region Convolutional Neural Networks) deep learning framework based on a RPN (Region Proposal Network) network and the ResNet residual neural network were used to train the pine wilt diseased dead tree detection model. The loss function and the anchors in the RPN of the convolutional neural network were optimized. Finally, the location of pine wood nematode dead tree was conducted, which generated the geographic information on the detection results. The results show that ResNet101 performed better than VGG16 (Visual Geometry Group 16) convolutional neural network. The detection accuracy was improved and reached to about 90% after a series of optimizations to the network, meaning that the optimization methods proposed in this paper are feasible to pine wood nematode dead tree detection.},
DOI = {10.3390/agriengineering2020019}
}



@Article{rs12101649,
AUTHOR = {Iizuka, Kotaro and Hayakawa, Yuichi S. and Ogura, Takuro and Nakata, Yasutaka and Kosugi, Yoshiko and Yonehara, Taichiro},
TITLE = {Integration of Multi-Sensor Data to Estimate Plot-Level Stem Volume Using Machine Learning Algorithms–Case Study of Evergreen Conifer Planted Forests in Japan},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {1649},
URL = {https://www.mdpi.com/2072-4292/12/10/1649},
ISSN = {2072-4292},
ABSTRACT = {The development of new methods for estimating precise forest structure parameters is essential for the quantitative evaluation of forest resources. Conventional use of satellite image data, increasing use of terrestrial laser scanning (TLS), and emerging trends in the use of unmanned aerial systems (UASs) highlight the importance of modern technologies in the realm of forest observation. Each technology has different advantages, and this work seeks to incorporate multiple satellite, TLS- and UAS-based remote sensing data sets to improve the ability to estimate forest structure parameters. In this paper, two regression analysis approaches are considered for the estimation: random forest regression (RFR) and support vector regression (SVR). To collect the dependent variable, in situ measurements of individual tree parameters (tree height and diameter at breast height (DBH)) were taken in a Japanese cypress forest using the nondestructive TLS method, which scans the forest to obtain dense and accurate point clouds under the tree canopy. Based on the TLS data, the stem volume was then computed and treated as ground truth information. Topographic and UAS information was then used to calculate various remotely sensed explanatory variables, such as canopy size, canopy cover, and tree height. Canopy cover and canopy shapes were computed via the orthoimages derived from the UAS and watershed segmentation method, respectively. Tree height was computed by combining the digital surface model (DSM) from the UAS and the digital terrain model (DTM) from the TLS data. Topographic variables were computed from the DTM. The backscattering intensity in the satellite imagery was obtained based on L-band (Advanced Land Observing Satellite-2 (ALOS-2) Phased Array type L-band Synthetic Aperture Radar-2 (PALSAR-2)) and C-band (Sentinel-1) synthetic aperture radar (SAR). All satellite (10&ndash;25 m resolution), TLS (3.4 mm resolution) and UAS (2.3&ndash;4.6 cm resolution) data were then combined, and RFR and SVR were trained; the resulting predictive powers were then compared. The RFR method yielded fitting R2 up to 0.665 and RMSE up to 66.87 m3/ha (rRMSE = 11.95%) depending on the input variables (best result with canopy height, canopy size, canopy cover, and Sentinel-1 data), and the SVR method showed fitting R2 up to 0.519 and RMSE up to 80.12 m3/ha (rRMSE = 12.67%). The RFR outperformed the SVR method, which could delineate the relationship between the variables for better model accuracy. This work has demonstrated that incorporating various remote sensing data to satellite data, especially adding finer resolution data, can provide good estimates of forest parameters at a plot level (10 by 10 m), potentially allowing advancements in precision forestry.},
DOI = {10.3390/rs12101649}
}



@Article{buildings10050096,
AUTHOR = {Ciaburro, Giuseppe and Iannace, Gino and Trematerra, Amelia},
TITLE = {Research for the Presence of Unmanned Aerial Vehicle inside Closed Environments with Acoustic Measurements},
JOURNAL = {Buildings},
VOLUME = {10},
YEAR = {2020},
NUMBER = {5},
ARTICLE-NUMBER = {96},
URL = {https://www.mdpi.com/2075-5309/10/5/96},
ISSN = {2075-5309},
ABSTRACT = {Small UAVs (unmanned aerial vehicle) can be used in many sectors such as the acquisition of images or the transport of objects. Small UAVs have also been used for terrorist activities or to disturb the flight of airplanes. Due to the small size and the presence of only rotating parts, drones escape traditional controls and therefore represent a danger. This paper reports a methodology for identifying the presence of small UAVs inside a closed environment by measuring the noise emitted during the flight. Acoustic measurements of the noise emitted by a drone inside a large environment (12.0 &times; 30.0 &times; 12.0 m) were performed. The noise was measured with a sound level meter placed at different distances (5, 10, and 15 m), to characterize the noise in the absence of anthropic noise. In this configuration, a typical tonal component of drone noise is highlighted at the frequency of one-third of an octave at 5000 Hz due to the rotation of the blades. This component is also present 15 m away from the source point. Subsequent measurements were performed by introducing into the environment, through a loudspeaker, the anthropogenic noise produced by the buzz of people and background music. It is possible to distinguish the typical tonal component of UAV noise at the frequency of 5000 Hz even when the level of recording of anthropogenic noise emitted by the loudspeaker is at the maximum power tested. It is therefore possible to search for the presence of small UAVs inside a specific closed environment with only acoustic measurements, paying attention to the typical frequency of noise emission equal to 5000 Hz.},
DOI = {10.3390/buildings10050096}
}



@Article{rs12111808,
AUTHOR = {Mielcarek, Miłosz and Kamińska, Agnieszka and Stereńczak, Krzysztof},
TITLE = {Digital Aerial Photogrammetry (DAP) and Airborne Laser Scanning (ALS) as Sources of Information about Tree Height: Comparisons of the Accuracy of Remote Sensing Methods for Tree Height Estimation},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {1808},
URL = {https://www.mdpi.com/2072-4292/12/11/1808},
ISSN = {2072-4292},
ABSTRACT = {The rapid developments in the field of digital aerial photogrammetry (DAP) in recent years have increased interest in the application of DAP data for extracting three-dimensional (3D) models of forest canopies. This technology, however, still requires further investigation to confirm its reliability in estimating forest attributes in complex forest conditions. The main purpose of this study was to evaluate the accuracy of tree height estimation based on a crown height model (CHM) generated from the difference between a DAP-derived digital surface model (DSM) and an airborne laser scanning (ALS)-derived digital terrain model (DTM). The tree heights determined based on the DAP-CHM were compared with ground-based measurements and heights obtained using ALS data only (ALS-CHM). Moreover, tree- and stand-related factors were examined to evaluate the potential influence on the obtained discrepancies between ALS- and DAP-derived heights. The obtained results indicate that the differences between the means of field-measured heights and DAP-derived heights were statistically significant. The root mean square error (RMSE) calculated in the comparison of field heights and DAP-derived heights was 1.68 m (7.34%). The results obtained for the CHM generated using only ALS data produced slightly lower errors, with RMSE = 1.25 m (5.46%) on average. Both ALS and DAP displayed the tendency to underestimate tree heights compared to those measured in the field; however, DAP produced a higher bias (1.26 m) than ALS (0.88 m). Nevertheless, DAP heights were highly correlated with the heights measured in the field (R2 = 0.95) and ALS-derived heights (R2 = 0.97). Tree species and height difference (the difference between the reference tree height and mean tree height in a sample plot) had the greatest influence on the differences between ALS- and DAP-derived heights. Our study confirms that a CHM computed based on the difference between a DAP-derived DSM and an ALS-derived DTM can be successfully used to measure the height of trees in the upper canopy layer.},
DOI = {10.3390/rs12111808}
}



@Article{rs12111838,
AUTHOR = {Zhang, Zhao and Flores, Paulo and Igathinathane, C. and L. Naik, Dayakar and Kiran, Ravi and Ransom, Joel K.},
TITLE = {Wheat Lodging Detection from UAS Imagery Using Machine Learning Algorithms},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {1838},
URL = {https://www.mdpi.com/2072-4292/12/11/1838},
ISSN = {2072-4292},
ABSTRACT = {The current mainstream approach of using manual measurements and visual inspections for crop lodging detection is inefficient, time-consuming, and subjective. An innovative method for wheat lodging detection that can overcome or alleviate these shortcomings would be welcomed. This study proposed a systematic approach for wheat lodging detection in research plots (372 experimental plots), which consisted of using unmanned aerial systems (UAS) for aerial imagery acquisition, manual field evaluation, and machine learning algorithms to detect the occurrence or not of lodging. UAS imagery was collected on three different dates (23 and 30 July 2019, and 8 August 2019) after lodging occurred. Traditional machine learning and deep learning were evaluated and compared in this study in terms of classification accuracy and standard deviation. For traditional machine learning, five types of features (i.e. gray level co-occurrence matrix, local binary pattern, Gabor, intensity, and Hu-moment) were extracted and fed into three traditional machine learning algorithms (i.e., random forest (RF), neural network, and support vector machine) for detecting lodged plots. For the datasets on each imagery collection date, the accuracies of the three algorithms were not significantly different from each other. For any of the three algorithms, accuracies on the first and last date datasets had the lowest and highest values, respectively. Incorporating standard deviation as a measurement of performance robustness, RF was determined as the most satisfactory. Regarding deep learning, three different convolutional neural networks (simple convolutional neural network, VGG-16, and GoogLeNet) were tested. For any of the single date datasets, GoogLeNet consistently had superior performance over the other two methods. Further comparisons between RF and GoogLeNet demonstrated that the detection accuracies of the two methods were not significantly different from each other (p &gt; 0.05); hence, the choice of any of the two would not affect the final detection accuracies. However, considering the fact that the average accuracy of GoogLeNet (93%) was larger than RF (91%), it was recommended to use GoogLeNet for wheat lodging detection. This research demonstrated that UAS RGB imagery, coupled with the GoogLeNet machine learning algorithm, can be a novel, reliable, objective, simple, low-cost, and effective (accuracy &gt; 90%) tool for wheat lodging detection.},
DOI = {10.3390/rs12111838}
}



@Article{app10113953,
AUTHOR = {de la Fuente Castillo, Víctor and Díaz-Álvarez, Alberto and Manso-Callejo, Miguel-Ángel and Serradilla García, Francisco},
TITLE = {Grammar Guided Genetic Programming for Network Architecture Search and Road Detection on Aerial Orthophotography},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {3953},
URL = {https://www.mdpi.com/2076-3417/10/11/3953},
ISSN = {2076-3417},
ABSTRACT = {Photogrammetry involves aerial photography of the Earth&rsquo;s surface and subsequently processing the images to provide a more accurate depiction of the area (Orthophotography). It is used by the Spanish Instituto Geogr&aacute;fico Nacional to update road cartography but requires a significant amount of manual labor due to the need to perform visual inspection of all tiled images. Deep learning techniques (artificial neural networks with more than one hidden layer) can perform road detection but it is still unclear how to find the optimal network architecture. Our main goal is the automatic design of deep neural network architectures with grammar-guided genetic programming. In this kind of evolutive algorithm, all the population individuals (here candidate network architectures) are constrained to rules specified by a grammar that defines valid and useful structural patterns to guide the search process. Grammar used includes well-known complex structures (e.g., Inception-like modules) combined with a custom designed mutation operator (dynamically links the mutation probability to structural diversity). Pilot results show that the system is able to design models for road detection that obtain test accuracies similar to that reached by state-of-the-art models when evaluated over a dataset from the Spanish National Aerial Orthophotography Plan.},
DOI = {10.3390/app10113953}
}




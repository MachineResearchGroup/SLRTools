@article{WU2021120106,
title = {A novel fast-charging stations locational planning model for electric bus transit system},
journal = {Energy},
volume = {224},
pages = {120106},
year = {2021},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2021.120106},
url = {https://www.sciencedirect.com/science/article/pii/S0360544221003558},
author = {Xiaomei Wu and Qijin Feng and Chenchen Bai and Chun Sing Lai and Youwei Jia and Loi Lei Lai},
keywords = {Fast-charging station, Location planning, Affinity propagation, Binary particle swarm optimization},
abstract = {With more electric buses, the optimal location of charging station plays an important role for bus electrification. This paper proposes a location planning model of electric bus fast-charging stations for the electric bus transit system, that takes the bus operation network and the distribution network into account. The model 1) simulates the operation network of electric buses thoroughly to obtain the charging demand of electric buses and 2) takes into account of the absorption capacity of distribution network and other constraints in the siting and capacity determination stage. The objective of the model is to minimize the sum of the construction cost, operation and maintenance costs, travel cost to charging stations, and the cost of power loss for charging stations at established bus terminus. The Affinity Propagation method is adopted to cluster the bus terminuses in order to obtain a preliminary number of charging stations. Subsequently, the Binary Particle Swarm Optimization algorithm is used to optimize the site selection and capacity. Finally, the model is applied to simulate and analyze the bus operation network of a coastal city in South China. The case study shows that the model can effectively optimize the layout of bus charging stations for the city.}
}
@article{KJAERGAARD2020106848,
title = {Current practices and infrastructure for open data based research on occupant-centric design and operation of buildings},
journal = {Building and Environment},
volume = {177},
pages = {106848},
year = {2020},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2020.106848},
url = {https://www.sciencedirect.com/science/article/pii/S0360132320302079},
author = {Mikkel B. Kjærgaard and Omid Ardakanian and Salvatore Carlucci and Bing Dong and Steven K. Firth and Nan Gao and Gesche Margarethe Huebner and Ardeshir Mahdavi and Mohammad Saiedur Rahaman and Flora D. Salim and Fisayo Caleb Sangogboye and Jens Hjort Schwee and Dawid Wolosiuk and Yimin Zhu},
keywords = {Open data, Data publishing, Data use, Occupant behavior, FAIR Data, Ontology, Anonymi, z, ation, Metadata schema},
abstract = {Many new tools for improving the design and operation of buildings try to realize the potential of big data. In particular, data is an important element for occupant-centric design and operation as occupants’ presence and actions are affected by a high degree of uncertainty and, hence, are hard to model in general. For such research, data handling is an important challenge, and following an open science paradigm based on open data can increase efficiency and transparency of scientific work. This article reviews current practices and infrastructure for open data-driven research on occupant-centric design and operation of buildings. In particular, it covers related work on open data in general and for the built environment in particular, presents survey results for existing scientific practices, reviews technical solutions for handling data and metadata, discusses ethics and privacy protection and analyses principles for the sharing of open data. In summary, this study establishes the status quo and presents an outlook on future work for methods and infrastructures to support the open data community within the built environment.}
}
@article{TRILLES2020100309,
title = {Development of an open sensorized platform in a smart agriculture context: A vineyard support system for monitoring mildew disease},
journal = {Sustainable Computing: Informatics and Systems},
volume = {28},
pages = {100309},
year = {2020},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2019.01.011},
url = {https://www.sciencedirect.com/science/article/pii/S2210537918302270},
author = {Sergio Trilles and Joaquín Torres-Sospedra and Óscar Belmonte and F. Javier Zarazaga-Soria and Alberto González-Pérez and Joaquín Huerta},
keywords = {Wireless Sensor Networks, Internet of Things, Edge computing, Open sensorized platform, Precision agriculture, Vineyard, Downy mildew, Goidanich},
abstract = {In recent years, some official reports, to produce best products regarding quality, quantity and economic conditions, recommend that the farming sector should benefit with new tools and techniques coming from Information and Communications Technology (ICT) realm. In this way, during last decade the deployment of sensing devices has increased considerably in the field of agriculture. This fact has led to a new concept called smart agriculture, and it contemplates activities such as field monitoring, which offer support to make decisions or perform actions, such as irrigation or fertilization. Apart from sensing devices, which use the Internet protocol to transfer data (Internet of Things), there are the so-called crop models, which are able to provide added value over the data provided by the sensors, with the aim of providing recommendations to farmers in decision-making and thus, increase the quality and quantity of their production. In this scenario, the current work uses a low-cost sensorized platform, capable of monitoring meteorological phenomena following the Internet of Things paradigm, with the goal to apply an alert disease model on the cultivation of the vine. The edge computing paradigm is used to achieve this objective; also our work follows some advances from GIScience to increase interoperability. An example of this platform has been deployed in a vineyard parcel located in the municipality of Vilafamés (Castelló, Spain).}
}
@article{GOLESTAN201668,
title = {Situation awareness within the context of connected cars: A comprehensive review and recent trends},
journal = {Information Fusion},
volume = {29},
pages = {68-83},
year = {2016},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2015.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1566253515000743},
author = {Keyvan Golestan and Ridha Soua and Fakhri Karray and Mohamed S. Kamel},
keywords = {Situation awareness, High-level information fusion, Internet of Cars, Advanced driving assisted systems},
abstract = {Driving safety is among the most important factors in the design of next generation vehicles as an integral component of Intelligent Transportation Systems. Crash avoidance and reduction of potential subsequent fatalities require timely delivery of sensitive and pertinent safety information for the drivers. Hence, the driver can become aware of the current driving situation, and can consequently, take appropriate decisions to avoid potentially imminent hazards. In this paper, we propose a comprehensive survey on situation awareness within the context of connected vehicles and Internet of Cars (also called here as connected cars). We provide context for the Internet of Cars and highlight its major features. Furthermore, situation awareness in the Internet of Cars is explored through presenting an in-depth discussion on its different components. Various aspects of high and low level information fusions are described within this context. Besides, major methods/models in situation awareness are linked to the main aspects of each component, and an overall comparison between them is reported. Moreover, on-the-road safety frameworks incorporating situation awareness are highlighted. Finally, the challenging issues and the emerging trends that shall be faced by the research community are addressed.}
}
@article{RAY2018291,
title = {A survey on Internet of Things architectures},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {30},
number = {3},
pages = {291-319},
year = {2018},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2016.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S1319157816300799},
author = {P.P. Ray},
keywords = {Internet of Things (IoT), Architecture, Cyber physical system},
abstract = {Internet of Things is a platform where every day devices become smarter, every day processing becomes intelligent, and every day communication becomes informative. While the Internet of Things is still seeking its own shape, its effects have already stared in making incredible strides as a universal solution media for the connected scenario. Architecture specific study does always pave the conformation of related field. The lack of overall architectural knowledge is presently resisting the researchers to get through the scope of Internet of Things centric approaches. This literature surveys Internet of Things oriented architectures that are capable enough to improve the understanding of related tool, technology, and methodology to facilitate developer’s requirements. Directly or indirectly, the presented architectures propose to solve real-life problems by building and deployment of powerful Internet of Things notions. Further, research challenges have been investigated to incorporate the lacuna inside the current trends of architectures to motivate the academics and industries get involved into seeking the possible way outs to apt the exact power of Internet of Things. A main contribution of this survey paper is that it summarizes the current state-of-the-art of Internet of Things architectures in various domains systematically.}
}
@article{BILYATDINOVA201765,
title = {Revisiting Master’s Program Design in Computational Science:: Case of ITMO University},
journal = {Procedia Computer Science},
volume = {119},
pages = {65-72},
year = {2017},
note = {6th International Young Scientist Conference on Computational Science, YSC 2017, 01-03 November 2017, Kotka, Finland},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.161},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917323712},
author = {Anna Bilyatdinova and Alexandra Klimova},
keywords = {Computational Science, Higher Education, Interdisciplinary Program, Learning Environment},
abstract = {Science and technology domains are facing a diversity of challenges enforcing ICT professionals to transfer and aggregate knowledge from different subject areas. This article discusses the creation of the educational environment in supercomputer simulations in the framework of three double-degree Master’s programs in Applied Mathematics and Informatics (Computational Science). These programs (BigData and Extreme Computing, Urban Supercomputing, and Computational Biomedicine) where developed by ITMO University, Russia, in partnership with University of Amsterdam (UvA), the Netherlands. Having critically reviewed the place of ICT master’s programs in Russia and abroad, we base our training methodology on the diversification of global academic and professional activity of master students by immersing them in research projects. Mastering professional, cultural, and engineering competencies during the learning process in multidisciplinary learning environment, we know we will enable our graduates to use effectively computing systems of different architecture and apply a variety of programming techniques, as well as promote the formation of creativity, emotional intelligence and after graduation to be apt to professional mobility.}
}
@article{GOY20153391,
title = {Estimating Demand Response Potential in Building Clusters},
journal = {Energy Procedia},
volume = {78},
pages = {3391-3396},
year = {2015},
note = {6th International Building Physics Conference, IBPC 2015},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2015.11.756},
url = {https://www.sciencedirect.com/science/article/pii/S1876610215024881},
author = {Solène Goy and Donal Finn},
keywords = {Demand Response, Building Energy Modelling, Predictive control ;},
abstract = {The large-scale implementation of demand-response measures has the potential to play a significant role in overcoming the various issues related to electricity supply/demand imbalances. This paper assesses various building energy modelling techniques and compares them using a schematic representation; the integration of the building models into a demand response scheme is then addressed and guidelines are given for different contexts. From the review carried out, the paper highlights the need to develop demand-response estimation tools at a large-scale taking into account the buildings characteristics. An outlook is given on a proposed method for large-scale demand response estimation.}
}
@article{ASGHARI201861,
title = {Service composition approaches in IoT: A systematic review},
journal = {Journal of Network and Computer Applications},
volume = {120},
pages = {61-77},
year = {2018},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2018.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S1084804518302376},
author = {Parvaneh Asghari and Amir Masoud Rahmani and Hamid Haj Seyyed Javadi},
keywords = {Service composition, Internet of things, Systematic literature review, Smart objects, QoS},
abstract = {The Internet of Things (IoT) signifies to an overall system of interconnected physical Things utilizing existing correspondence conventions. One critical inquiry remains in what manner can make and communicate the management of provided services for smart devices by an assortment of protest things that substituted and joined capably. Service composition process permits the interaction between user requirements and smart objects of IoT environment. Leveraging on the service discovery procedure can be influenced on finding the desired services. Consequently, choosing suitable services is the main challenge that covers functionality and required quality to combine several services as the integrated composite service in the IoT. The service composition process has been broadly considered with regards to web suppliers and business processes in the IoT. Currently, the IoT environment identifies the dynamic relationship topics on physical processes that are combined as the enhanced web services heterogeneously. This paper focuses on several service composition approaches that are applied in the IoT environment based on the Systematic Literature Review (SLR) method. The aim of this study is to analytically and statistically categorize and analyze the current research techniques on the service composition in the IoT (published between 2012 and 2017). A technical taxonomy is presented for the service composition approaches according to content of the existing studies that are selected with SLR method in this review with respect to functional and non-functional aspects in service composition approaches. The functional aspect emphasizes on verifying the behavior of service composition approach and the non-functional aspect considers the Quality of Service (QoS) in IoT environment. The approaches are compared with each other according to some technical aspects such as system correctness factors in functional properties approaches, and (QoS) factors, presented algorithms, and existing platforms in non-functional approaches. The advantages and disadvantages of each selected approach discussed as well as providing some hints for solving their weaknesses. A brief contribution to this literature is as follows: (1) Presenting a SLR method for the service composition approaches in IoT, (2) Addressing a discussion of the main challenges, (3) Providing the future research directions and open perspectives.}
}
@article{OZMEN2021107090,
title = {A hardware and environment-agnostic smart home architecture with containerized on-the-fly service offloading},
journal = {Computers & Electrical Engineering},
volume = {92},
pages = {107090},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107090},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621000999},
author = {Huseyin Anil Ozmen and Sinan Isik and Cem Ersoy},
keywords = {Internet of Things, Fog computing, Smart homes, Home automation architecture, Docker, Service orchestration, Real-time service deployment},
abstract = {The Fog-based Home Automation Platform (FOGHA) is a novel Fog-based smart home platform that utilizes real-time containerized service deployment and task-offloading over its computing nodes. Fog is the middle computing layer that is physically near to the Things layer (connected appliances) and is composed of multiple Fog nodes that are orchestrated in a distributed manner. The architecture supports intra-Fog and inter-layer task offloading mechanisms via the real-time deployment of containerized services. The delay-sensitive services are mostly performed among Fog nodes, whereas the resource-demanding tasks are offloaded to the Cloud nodes. FOGHA utilizes software services as Docker containers, which is a novel approach for resource-scarce Fog nodes compared to existing automation platforms. Our experiments proved that resource-demanding tasks such as face recognition could also be collectively performed within the Fog layer, revealing that Fog layer nodes can provide the Cloud layer’s computational power and service variety.}
}
@article{GARCIA2021792,
title = {Data-flow driven optimal tasks distribution for global heterogeneous systems},
journal = {Future Generation Computer Systems},
volume = {125},
pages = {792-805},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21002806},
author = {Jordi Garcia and Francesc Aguiló and Adrià Asensio and Ester Simó and Marisa Zaragozá and Xavi Masip-Bruin},
keywords = {Edge computing, Distributed computing, Heterogeneous systems, Task distribution, Task offloading, Resources allocation},
abstract = {As a result of advances in technology and highly demanding users expectations, more and more applications require intensive computing resources and, most importantly, high consumption of data distributed throughout the environment. For this reason, there has been an increasing number of research efforts to cooperatively use geographically distributed resources, working in parallel and sharing resources and data. In fact, an application can be structured into a set of tasks organized through interdependent relationships, some of which can be effectively executed in parallel, notably speeding up the execution time. In this work a model is proposed aimed at offloading tasks execution in heterogeneous environments, considering different nodes computing capacity connected through distinct network bandwidths, and located at different distances. In the envisioned model, the focus is on the overhead produced when accessing remote data sources as well as the data transfer cost generated between tasks at run-time. The novelty of this approach is that the mechanism proposed for tasks allocation is data-flow aware, considering the geographical location of both, computing nodes and data sources, ending up in an optimal solution to a highly complex problem. Two optimization strategies are proposed, the Optimal Matching Model and the Staged Optimization Model, as two different approaches to obtain a solution to the task scheduling problem. In the optimal model approach a global solution for all application’s tasks is considered, finding an optimal solution. Differently, the staged model approach is designed to obtain a local optimal solution by stages. In both cases, a mixed integer linear programming model has been designed intended to minimizing the application execution time. In the studies carried out to evaluate this proposal, the staged model provides the optimal solution in 76% of the simulated scenarios, while it also dramatically reduces the solving time with respect to optimal. Both models have pros and cons and, in fact, can be used together to complement each other. The optimal model finds the global optimal solution at high running time cost, which makes this model unpractical on some scenarios. The staged model instead, is faster enough to be used on those scenarios; however, the given solution might not be optimal in some cases.}
}
@article{SEPULVEDA2022103532,
title = {Daylight and overheating prediction formulas for building design in a cold climate},
journal = {Journal of Building Engineering},
volume = {45},
pages = {103532},
year = {2022},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2021.103532},
url = {https://www.sciencedirect.com/science/article/pii/S2352710221013905},
author = {Abel Sepúlveda and Francesco {De Luca} and Jarek Kurnitski},
keywords = {Daylight, Overheating, EN 17037, Thermal comfort, Visual comfort, Degree-hour},
abstract = {Indoor comfort in buildings has a critical impact on occupants’ health and cognitive performance. The fulfillment of daylight provision and overheating risk requirements can be challenging. This paper proposes a coupled method based on prediction formulas that can be used to assess daylight provision and overheating risk in buildings. In addition, this method can be used for the design of interior floor plan and window sizing in order to rooms fulfill simultaneously both performances. The considered daylight provision requirements are based on the minimum Daylight Factor (minDF) defined by the European standard EN 17037, and the overheating risk requirements are based on the degree-hour (DH) metric adopted by the Estonian regulation. The minimum window-to-wall ratio (minWWR) to fulfill minDF-based requirements and maximum g-value to fulfill at the same time DH-based requirements for any room design can be calculated or represented graphically. The prediction accuracy in terms of relative RMSE is up to 0.20 for minDF and DH values. By using this approach, designers can minimize the number of design iterations during early stages, as well as the required computational time required by daylight and energy simulations. Furthermore, the proposed coupled method based on minDF and DH prediction formulas has big potential to help architects and designers to achieve the combined fulfillment between daylight provision and overheating protection during early stages of the design process within the Estonian context. Finally, the authors recommend the proposed coupled method to regulation makers for future building standards and regulations.}
}
@article{ALABARCE2022100651,
title = {Optical network design and analysis tools: A test of time},
journal = {Optical Switching and Networking},
volume = {44},
pages = {100651},
year = {2022},
issn = {1573-4277},
doi = {https://doi.org/10.1016/j.osn.2021.100651},
url = {https://www.sciencedirect.com/science/article/pii/S1573427721000485},
author = {Miquel Garrich Alabarce and Pablo Pavón Mariño},
keywords = {Multi-layer networks, Network function virtualization, Network planning, Optical communications, Software defined networking},
abstract = {Telecom operators' infrastructure is sustained by optical communication networks that provide the means for exchanging large amounts of information, which is essential for many modern society needs. Optical networks are characterized by rapid breakthroughs in a variety of technologies. Relevantly, the last decade encompassed remarkable advances in optical networks’ subfields of signal processing, electronics, photonics, communications, protocols, and control-plane architectures. Hence, these advancements unlocked unprecedented transmission capacities, reconfigurability and programmability, entailing an evolution in the way which networks were designed, planned, and analyzed. In this paper, we review the historical status of optical planning and design tools by focusing on the major enabling technologies and relevant landmarks of the last decade(s). We begin by pinpointing the major breakthroughs in the optical data plane, estimation models capturing the transmission medium behavior and the control plane. We then distil the implications that these advancements entail in the landscape of optical network design and analysis tools, which commonly sit “on top” of the control plane or as a fully separated entity. Then, we speculate with our view for the future, in which automatic validation of optical network operations and dimensioning jointly with learning/artificial intelligence mechanisms will permit zero-touch optical networking: i.e. updating, provisioning, and upgrading network capacities, by means of automation with minimal human intervention. We conclude with a proposal of an architecture that encompasses data and control planes in a comprehensive manner for paving the way towards zero-touch optical networking.}
}
@article{JABLONSKI2017211,
title = {Integrated living environment: Measurements in modern energy efficient smart building with implemented the functionality of telemedicine},
journal = {Measurement},
volume = {101},
pages = {211-235},
year = {2017},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2015.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0263224115005928},
author = {Ireneusz Jabłoński},
keywords = {Measurement, Complex systems, Scaling effect, Data fusion, Smart building, Telemedicine},
abstract = {The paper depicts the metrology as a vivid fundamental science with implications for possible applications in various engineering fields. This depiction uses the energy efficient smart building with embedded the functionality of telemedicine as the example of integrated living environment. State of the art for such issue and object has been reviewed here. Results provided for exemplary CTE’s office building show the effectiveness of performance of multisensory measurement network in the task of heating system optimization. These results highlight also the meaning of fusion algorithms in management of complex systems. Although the building infrastructure described in the paper aggregates a bench of open questions, it moves also the perception to more generalized objects, which can be explained in the context of complex systems, networking science, scaling rules, etc. Proposed attempt has opened the challenges for researchers and engineers in numerous domains. This domains and problems have been denoted and shortly characterized in the paper.}
}
@article{NGUYEN2018256,
title = {Re-engineering traditional urban water management practices with smart metering and informatics},
journal = {Environmental Modelling & Software},
volume = {101},
pages = {256-267},
year = {2018},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2017.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S1364815217305893},
author = {Khoi A. Nguyen and Rodney A. Stewart and Hong Zhang and Oz Sahin and Nilmini Siriwardene},
keywords = {Smart metering, Pattern recognition, Water demand management, Artificial intelligence, Network modelling},
abstract = {Current practice for the design of an urban water system usually relies on various models that are often founded on a number of assumptions on how bulk water consumption is attributed to customer connections and outdated demand information that does not reflect present consumption trends; meaning infrastructure is often unnecessarily overdesigned. The recent advent of high resolution smart water meters and advanced data analytics allow for a new era of using the continuous ‘big data’ generated by these meter fleets to create an intelligent system for urban water management to overcome this problem. The aim of this research is to provide infrastructure planners with a detailed understanding of how granular data generated by an intelligent water management system (Autoflow©) can be utilised to obtain significant efficiencies throughout different stages of an urban water cycle, from supply, distribution, customer engagement, and even wastewater treatment.}
}
@article{YI2021100891,
title = {Energy trading IoT system based on blockchain},
journal = {Swarm and Evolutionary Computation},
volume = {64},
pages = {100891},
year = {2021},
issn = {2210-6502},
doi = {https://doi.org/10.1016/j.swevo.2021.100891},
url = {https://www.sciencedirect.com/science/article/pii/S2210650221000523},
author = {Haibo Yi and Weipeng Lin and Xin Huang and Xuejun Cai and Ruinan Chi and Zhe Nie},
keywords = {Energy trading, Blockchain, Privacy protection, Internet of things (IoTs)},
abstract = {Energy trading technology based on Internet of Things (IoTs) is one of the research hotspots. However, in the process of energy trading, it is easy to leak the user’s personal privacy. In order to solve the problem of privacy leakage in the energy trading IoT system, we explore a secure energy trading method based on blockchain technology and homomorphic encryption technology. Firstly, we propose a homomorphic encryption method for blockchain system. Secondly, we propose a privacy protection method based on blockchain architecture. Finally, we propose an energy trading IoT system based on blockchain. By integrating homomorphic encryption, blockchain and other technologies, we have implemented a secure energy trading system. Compared with other similar systems, our energy trading IoT system based on blockchain can provide more secure user services. In addition, our system can better protect the privacy of users.}
}
@article{CHANDU20201066,
title = {Understanding And Extrapolation Of Disruption For Engineering Education-Principles And Problems},
journal = {Procedia Computer Science},
volume = {172},
pages = {1066-1076},
year = {2020},
note = {9th World Engineering Education Forum (WEEF 2019) Proceedings : Disruptive Engineering Education for Sustainable Development},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.05.156},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920314861},
author = {Ravi Sankar Chandu and Sai Ganesh {Swapnil Chandu}},
keywords = {Disruption, EESD, Industry 4.0},
abstract = {Engineering Education faced few disruptions like Outcome Based Education, Engineering Education for Sustainable Development and the present Industry 4.0 in the recent times. These disruptions failed to change Curricula, Teaching-Learning processes, Assessment appreciably in the large number of engineering institutions in several countries across the world. Same old processes despite switching over to Outcome Based Education or EESD or Industry 4.0 are being continued. Disruption is most sought after in engineering education as it offers lot of advantages like leadership, profit and professional standing. Many Institutions offering engineering programs try to implement disruptions but fail because of lack of understanding about disruption and the associated processes, required finances, Human Resources and more importantly the innovation capabilities. Disruption is a process where a product outsmarts others through Innovation either in Technology or in Product or in processes. Disruption is building a new eco-system to meet the customer’s purpose of buying a product, service or a program. Of late people are trying to implement innovations in Engineering Education with no knowledge of Disruption, its properties and processes. In this paper, we try to take an example of Kingsmen Coffee, a company trying to disrupt in the Indian market, analyse what it is offering and how they are trying to disrupt the existing players and what lessons does it offer to Engineering Educators in Disruption. Kingsmen Coffee is a coffee dispensing machine with new technology and the way it is creating win-win situations for all the stake holders involved, is a matter of interest and study for Engineering Educators. Through this study of Disruption, essential pre-requisites for disruption to happen are noted and they are used to extrapolate for realizing disruption in engineering education. Some suggestions regarding implementation of Disruption are given.}
}
@article{ISKHAKOV2021493,
title = {Algorithm for building a cyberphysical system operator profile for adaptive authentication},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {13},
pages = {493-498},
year = {2021},
note = {20th IFAC Conference on Technology, Culture, and International Stability TECIS 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.10.497},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321019340},
author = {Andrey Y. Iskhakov and Anastasia O. Iskhakova and Roman V. Meshcheryakov},
keywords = {adaptive authentication, cybersecurity, cyberphysical systems, device fingerprint, verification},
abstract = {Modern control systems designed to automate the control of process equipment in industrial plants require the provision of serious security mechanisms and functions. The COVID-19 pandemic in 2020 has highlighted the urgent need to implement remote access for operators of such enterprises, including access to some interfaces of industrial systems. Current information security challenges require modernization of the defense-in-depth of such facilities, including protection against compromising credentials by developing new solutions in the field of authentication of system subjects. This paper proposes a method for forming a profile of access subject authentication allowing differentiated development of adaptive algorithms to verify the legitimacy of operations. This eliminates the disadvantages of existing traditional authentication methods based on the use of explicit verification methods associated with the fact that in order to establish the authenticity of the user are used identifying characteristics that can be compromised by attackers. The paper presents the results of comparing the information content of different attributes when forming a subject access profile. The experiments confirmed the successful application of the proposed approach for different groups of access subjects and cyberphysical systems.}
}
@article{VALERO202196,
title = {AIoTES: Setting the principles for semantic interoperable and modern IoT-enabled reference architecture for Active and Healthy Ageing ecosystems},
journal = {Computer Communications},
volume = {177},
pages = {96-111},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421002346},
author = {Clara I. Valero and Alejandro M. Medrano Gil and Regel Gonzalez-Usach and Matilde Julian and Giuseppe Fico and Maria Teresa Arredondo and Thanos G. Stavropoulos and Dimitrios Strantsalis and Antonis Voulgaridis and Felipe Roca and Antonio J. Jara and Martín Serrano and Achille Zappa and Yasar Khan and Sergio Guillen and Pilar Sala and Andreu Belsa and Konstantinos Votis and Carlos E. Palau},
keywords = {Internet of Things, Platforms and services, Reference architecture, Active and Healthy Ageing, Semantic interoperability, Marketplace, Ecosystem},
abstract = {The average life expectancy of the world’s population is increasing and the healthcare systems sooner than later will be compromised by its reduced capacity and its highly economic cost; in addition, the age distribution of the population is leading towards the older spectrum. This trend will lead to immeasurable and unexpected economic problems and social changes. In order to face up this challenge and complex economic and social problem, it is necessary to rely on the appropriate digital tools and technological infrastructures for ensuring that the elderly are properly cared in their everyday living environments and they can live independently for longer. This article presents ACTIVAGE IoT Ecosystem Suite (AIoTES), a concrete reference architecture and its implementation process that addresses these issues and that was designed within the first European Large Scale Pilot, ACTIVAGE, a H2020 funded project by the European Commission with the objective of creating sustainable ecosystems for Active and Healthy Ageing (AHA) based on Internet of Things and big data technologies. AIoTES offers platform level semantic interoperability, with security and privacy, as well as Big Data and Ecosystem tools. AIoTES enables and promotes the creation, exchange and adoption of cross-platform services and applications for AHA. The number of existing AHA services and solutions are quite large, especially when state-of-the-art technology is introduced, however a concrete architecture such as AIoTES gains more importance and relevance by providing a vision for establishing a complete ecosystem, that looks for supporting a larger variety of AHA services, rather than claiming to be a unique solution for all the AHA domain problems. AIoTES has been successfully validated by testing all of its components, individually, integrated, and in real-world environments with 4345 direct users. Each validation is contextualized in 11 Deployment Sites (DS) with 13 Validation Scenarios covering the heterogeneity of the AHA-IoT needs. These results also show a clear path for improvement, as well as the importance for standardization efforts in the ever-evolving AHA-IoT domain.}
}
@article{KAW2019262,
title = {A reversible and secure patient information hiding system for IoT driven e-health},
journal = {International Journal of Information Management},
volume = {45},
pages = {262-275},
year = {2019},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2018.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0268401218302615},
author = {Javaid A. Kaw and Nazir A. Loan and Shabir A. Parah and K. Muhammad and Javaid A. Sheikh and G.M. Bhat},
keywords = {Steganography, Multimedia data management, Internet of things, Data hiding, e-healthcare, Reversibility, Payload, Cloud-assisted multimedia, Security},
abstract = {Internet of things (IoT) coupled with mobile cloud computing has made a paradigm shift in the service sector. IoT-assisted mobile cloud based e-healthcare services are making giant strides and are likely to change the conventional ways of healthcare service delivery. Though numerous approaches for preventing unauthorized access to information exchanged between a mobile phone and cloud platform do exist, but there is no security mechanism to prevent unauthorized access by the cloud administrators. With an aim to ensure security of client data such as Electronic Patient Records (EPR), we propose a novel high-capacity and reversible data hiding approach for securely embedding EPR within the medical images using Optimal Pixel Repetition (OPR). OPR converts every pixel of the input image to a 2 × 2 block to facilitate reversibility by ensuring all the pixels in a 2 × 2 block to have different values. Since a 2 × 2 block is comprised of 4-pixel elements, which could be arranged in sixteen possible ways; we generate a lookup table corresponding to sixteen possible positions of pixels. EPR hiding in each block is achieved by permuting the pixels of a block according to the four-bit word of secret data, resulting in a histogram invariant stego image. The histogram invariance improves the robustness of the proposed scheme to statistical attacks. A stego image is said to hide embedded data securely, when it provides better imperceptivity for an appreciably high payload. Thus, while using information embedding approach for securing client data on a mobile-cloud platform, high imperceptivity is a desirable feature. Experimental results show that average PSNR obtained is 42 dB for payload 1.25 bpp by our scheme, showing its effectiveness for preventing unauthorized access to client’s sensitive data.}
}
@article{MERSHAD2021100392,
title = {Proof of accumulated trust: A new consensus protocol for the security of the IoV},
journal = {Vehicular Communications},
volume = {32},
pages = {100392},
year = {2021},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2021.100392},
url = {https://www.sciencedirect.com/science/article/pii/S2214209621000619},
author = {Khaleel Mershad and Omar Cheikhrouhou and Leila Ismail},
keywords = {Internet of vehicles, Blockchain, Consensus protocol, Security and privacy, Trust management, Distributed systems},
abstract = {The Internet of Vehicles (IoV) is a distributed network that enables vehicles to connect to each other and to various infrastructure and smart devices, in order to exchange data and provide important services. The highly dynamic environment of the IoV offers a lot of opportunities but at the same time makes the network susceptible to a large number of security attacks. In this paper, we propose a framework that comprises a private blockchain model to secure the transactions that are generated by vehicles. Our model makes use of our proposed Proof of Accumulated Trust (PoAT) mechanism that selects specific RSUs to become blockchain miners based on their accumulated trust. In addition, the proposed system introduces a smart redundancy method in which each vehicle and RSU sends a transaction to multiple destinations, in order to avoid the situation when one or more IoV nodes are compromised. We conduct extensive experiments in which we compare our system to two recent blockchain-based security frameworks for the IoV. The simulation results illustrate the superiority of our system in terms of attack detection rate, blockchain generation time, and network overhead traffic.}
}
@article{PONCE2021112,
title = {DDF Library: Enabling functional programming in a task-based model},
journal = {Journal of Parallel and Distributed Computing},
volume = {151},
pages = {112-124},
year = {2021},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2021.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0743731521000307},
author = {Lucas M. Ponce and Daniele Lezzi and Rosa M. Badia and Dorgival Guedes},
keywords = {COMPSs, Big Data, Performance evaluation, Data-flow programming},
abstract = {In recent years, the areas of High-Performance Computing (HPC) and massive data processing (also know as Big Data) have been in a convergence course, since they tend to be deployed on similar hardware. HPC systems have historically performed well in regular, matrix-based computations; on the other hand, Big Data problems have often excelled in fine-grained, data parallel workloads. While HPC programming is mostly task-based, like COMPSs, popular Big Data environments, like Spark, adopt the functional programming paradigm. A careful analysis shows that there are pros and cons to both approaches, and integrating them may yield interesting results. With that reasoning in mind, we have developed DDF, an API and library for COMPSs that allows developers to use Big Data techniques while using that HPC environment. DDF has a functional-based interface, similar to many Data Science tools, that allows us to use dynamic evaluation to adapt the task execution in run time. It brings some of the qualities of Big Data programming, making it easier for application domain experts to write Data Analysis jobs. In this article we discuss the API and evaluate the impact of the techniques used in its implementation that allow a more efficient COMPSs execution. In addition, we present a performance comparison with Spark in several application patterns. The results show that each technique significantly impacts the performance, allowing COMPSs to outperform Spark in many use cases.}
}
@article{CHANDRASHEKERAN2020110,
title = {From responsibilization to responsiveness through metrics: Smart meter deployment in Australia},
journal = {Geoforum},
volume = {116},
pages = {110-118},
year = {2020},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2020.07.014},
url = {https://www.sciencedirect.com/science/article/pii/S0016718520302074},
author = {Sangeetha Chandrashekeran},
keywords = {Electricity, Smart meters, Responsibilization, Responsiveness, Governmentality, Accountability, Infrastructure, Metrics, Data, Universal service provision},
abstract = {Smart meters are a central element in strategies to create data-rich environments that enhance the rationalization and technical optimization of electricity production and consumption. Bold claims are made by industry and government that smart measurement devices will enable a new class of responsibilizing subjects who can be nudged and incentivized to orchestrate efficient low carbon energy governance. The carbon governmentality literature reveals the microphysics of power involved in responsibilization-as-governance. However, it insufficiently explains how the individualization of responsibility is shaped by and coexists with other sectoral and policy priorities, and political-economic imperatives. I show how the obdurate political-economic relations of the Australian electricity sector shape what can be measured, who can do the measuring, and who can access the metrics from smart meters. Utopian promises to govern for all by metrics are constrained by industry accumulation strategies, weak regulation and the embedded inequalities of infrastructural projects. I then show how responsibilization is being eclipsed by responsiveness as the new regime of accountability. Responsiveness bypasses active individual consumer decision-making, in favour of technologically-mediated automated processes. I show how responsiveness regimes are being driven by new whole-of-economy accumulation opportunities and enabled through the creation of a weakly-regulated sectoral market for electricity consumption data. Metering is a crucial but insufficient condition for the larger assemblage of responsiveness that involves data mobility through third party access, new forms of market competition, and value creation in demand response.}
}
@article{WONG201837,
title = {Progress in Hong Kong’s Tropical Cyclone Forecasting and Warning Services in Recent Decades},
journal = {Tropical Cyclone Research and Review},
volume = {7},
number = {1},
pages = {37-50},
year = {2018},
issn = {2225-6032},
doi = {https://doi.org/10.6057/2018TCRR01.05},
url = {https://www.sciencedirect.com/science/article/pii/S2225603219300281},
author = {Wai-Kin Wong and Chun-Wing Choy},
keywords = {Hong Kong Observatory, tropical cyclones, forecasting and warning services},
abstract = {ABSTRACT
With modern infrastructures and effective warning systems, casualties, damages and losses due to tropical cyclones (TCs) have been significantly reduced over the years in Hong Kong. Nevertheless, densely populated coastal cities like Hong Kong will need to continuously enhance its resilience to high winds, heavy rain and storm surges brought by TCs, especially with the growing concern of the challenges induced by climate change and sea level rise. By embracing the advance of remote sensing, communication and numerical modelling technology, the Hong Kong Observatory (HKO) continues to improve its TC monitoring and forecasting techniques as well as forecasting and warning services to meet the needs of the society. This paper concisely reviews the major development and achievement of TC-related operation and services of HKO in recent decades, in aspects such as Numerical Weather Prediction (NWP) models, nowcasting techniques, warning communication and public education. Future thrusts on TC forecasting and warning services of HKO will also be discussed.}
}
@article{ZHANG2021106848,
title = {Trading-oriented battery energy storage planning for distribution market},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {129},
pages = {106848},
year = {2021},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2021.106848},
url = {https://www.sciencedirect.com/science/article/pii/S0142061521000880},
author = {Chenxi Zhang and Jing Qiu and Yi Yang and Junhua Zhao},
keywords = {Power system planning, Double-side auction, Energy storage system, Electricity market, Distribution market},
abstract = {In this paper, we present a trading-oriented battery energy storage system (BESS) planning model for a distribution market. The proposed planning model is formulated as a mutual-iteration and multi-objective two-stage optimization problem. The first stage is designed to optimize the internal resources allocation including PV system, wind turbine, gas turbine and BESS. Then a double-side auction model named as averaging pricing market (APM) mechanism is presented in the second stage, which aims at solving the issue of energy trading benefit loss caused by the relatively high difference between time-of-use (ToU) electricity price and feed-in-tariff. The contribution of this paper lies in combining the planning of BESS with the optimization of the distribution electricity market. Numerical results on a modified IEEE 24-bus system are presented to demonstrate the superiority of the two-stage optimization model and the sensitivity of the model is also investigated based on regret analysis.}
}
@article{CELAYAECHARRI2020108038,
title = {Validation of 3D simulation tool for radio channel modeling at 60 GHz: A meeting point for empirical and simulation-based models},
journal = {Measurement},
volume = {163},
pages = {108038},
year = {2020},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2020.108038},
url = {https://www.sciencedirect.com/science/article/pii/S0263224120305765},
author = {Mikel Celaya-Echarri and Leyre Azpilicueta and Peio Lopez-Iturri and Francisco Falcone and Manuel {Garcia Sanchez} and Ana {Vazquez Alejos}},
keywords = {5G, 3D Ray Launching (3D-RL), Empirical channel modeling},
abstract = {The radio channel modelling of the millimeter wave bands for the fifth generation of wireless mobile communications, appears as a challenge for both empirical and simulation approaches. In this paper we discuss the use of experimental datasets for validation of a simulation tool based on deterministic 3D ray-launching technique. The goal it twofold: validating the simulation tool and achieving more consistent results considering the restrictions and performance limits of hardware elements. A microcell canyon street scenario has been chosen for interleaving ray launching prediction and empirical analysis. Simulation results such as received power or angular distribution of path loss, as well as channel dispersion parameters such as root-mean-square delay spread have been presented. In addition, the line-of-sight to non-line-of-sight transition has been modeled as a result of the empirical-simulation interaction. Comparison of simulation and measurement results for the proposed microcellular urban scenario exhibit good agreement, validating the proposed methodology.}
}
@article{AUBOIN2021844,
title = {Trade and innovation policies: Coexistence and spillovers},
journal = {Journal of Policy Modeling},
volume = {43},
number = {4},
pages = {844-872},
year = {2021},
note = {The World Economy After Covid-19},
issn = {0161-8938},
doi = {https://doi.org/10.1016/j.jpolmod.2021.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0161893821000375},
author = {Marc Auboin and Robert Koopman and Ankai Xu},
abstract = {The debate over trade’s role in growth and inequality in recent years seems to center on the question of whether the gains from trade are worth the disruption from necessary adjustments. In particular static gains from trade for advanced economies are generally estimated to be small, while empirical evidence around growing employment and inequality challenges suggest trade’s role may be larger than previously thought, though still only one of many contributing factors. The focus on static gains though likely understates substantially the dynamic gains, as trade’s role in spurring faster economic growth, in both developed and developing countries through competitive and innovative forces. The dynamic, competition and innovation angle suggests a need for industrial policies to be revisited and examine how spillovers play out in the global economy. At the same time significant technological disruption is occurring through digital technology, big data, and machine learning/AI techniques that often require advanced capabilities and have significant competition implications. In recent COVID-19 pandemic policy responses governments have dramatically increased spending and liquidity to support stressed firms and households and encouraged many countries to consider strategic efforts to build certain domestic capabilities with the aim of reducing dependence on trade for emergency related goods and services. This paper provides insights on the specific role of innovation policies, and they differ from and are similar to traditional industrial policies, and what that might mean for future trade rules.}
}
@article{MARINTORDERA2017117,
title = {Do we all really know what a fog node is? Current trends towards an open definition},
journal = {Computer Communications},
volume = {109},
pages = {117-130},
year = {2017},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2017.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0140366416307113},
author = {Eva Marín-Tordera and Xavi Masip-Bruin and Jordi García-Almiñana and Admela Jukan and Guang-Jie Ren and Jiafeng Zhu},
keywords = {Fog computing, Fog node, IoT, Edge devices, Edge computing},
abstract = {Fog computing has emerged as a promising technology that can bring cloud applications closer to the physical IoT devices at the network edge. While it is widely known what cloud computing is, how data centers can build the cloud infrastructure and how applications can make use of this infrastructure, there is no common picture on what fog computing and particularly a fog node, as its main building block, really is. One of the first attempts to define a fog node was made by Cisco, qualifying a fog computing system as a “mini-cloud” located at the edge of the network and implemented through a variety of edge devices, interconnected by a variety, mostly wireless, communication technologies. Thus, a fog node would be the infrastructure implementing the said mini-cloud. Other proposals have their own definition of what a fog node is, usually in relation to a specific edge device, a specific use case or an application. In this paper, we first survey the state of the art in technologies for fog computing nodes, paying special attention to the contributions that analyze the role edge devices play in the fog node definition. We summarize and compare the concepts, lessons learned from their implementation, and end up showing how a conceptual framework is emerging towards a unifying fog node definition. We focus on core functionalities of a fog node as well as in the accompanying opportunities and challenges towards their practical realization in the near future.}
}
@article{ALZAHRANI2020102706,
title = {UAV assistance paradigm: State-of-the-art in applications and challenges},
journal = {Journal of Network and Computer Applications},
volume = {166},
pages = {102706},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102706},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520301806},
author = {Bander Alzahrani and Omar Sami Oubbati and Ahmed Barnawi and Mohammed Atiquzzaman and Daniyal Alghazzawi},
keywords = {UAV, IoT, Cellular communications, Routing, Data gathering, Fog computing},
abstract = {Unmanned Aerial Vehicles (UAVs) are an emerging technology with the potential to be used in industries and various sectors of human life to provide a wide range of applications and services. During the last decade, there has been a growing focus of research in the UAV's assistance paradigm as a fundamental concept resulting in the constant improvement between different kinds of ground networks and the hovering UAVs in the sky. Recently, the wide availability of embedded wireless interfaces in the communicating entities has allowed the deployment of such a paradigm simpler and easiest. Moreover, due to UAVs' controlled mobility and adjustable altitudes, they can be considered as the most appropriate candidate to enhance the performance and overcome the restrictions of ground networks. This comprehensive survey both studies and summarizes the existing UAV-assisted research, such as routing, data gathering, cellular communications, Internet of Things (IoT) networks, and disaster management that supports existing enabling technologies. Descriptions, classifications, and comparative studies related to different UAV-assisted proposals are presented throughout the paper. By pointing out numerous future challenges, it is expected to simulate research in this emerging and hot research area. To the best of our knowledge, there are many survey papers on the topic from a technology perspective. Nevertheless, this survey can be considered as the first attempt at a comprehensive analysis of different types of existing UAV-assisted networks and describes the state-of-the-art in UAV-assisted research.}
}
@article{REGE2021196,
title = {Generation of realistic cloud access times for mobile application testing using transfer learning},
journal = {Computer Communications},
volume = {172},
pages = {196-215},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421001067},
author = {Manoj R. Rege and Vlado Handziski and Adam Wolisz},
keywords = {Mobile, Cloud, Network, Access time, Transfer learning, Long Short Term Memory, Neural net, Testing},
abstract = {The network Quality of Service (QoS) metrics such as the access time, the bandwidth, and the packet loss play an important role in determining the Quality of Experience (QoE) of mobile applications. Various factors like the Radio Resource Control (RRC) states, the Mobile Network Operator (MNO) specific retransmission configurations, handovers triggered by the user mobility, the network load, etc. can cause high variability in these QoS metrics on 4G/LTE, and WiFi networks, which can be detrimental to the application QoE. Therefore, exposing the mobile application to realistic network QoS metrics is critical for a tester attempting to predict its QoE. A viable approach is testing using synthetic traces. The main challenge in the generation of realistic synthetic traces is the diversity of environments and the lack of wide scope of real traces to calibrate the generators. In this paper, we describe a measurement-driven methodology based on transfer learning with Long Short Term Memory (LSTM) neural nets to solve this problem. The methodology requires a relatively short sample of the targeted environment to adapt the presented basic model to new environments, thus simplifying synthetic traces generation. We present this feature for realistic WiFi and LTE cloud access time models adapted for diverse target environments with a trace size of just 6000 samples measured over a few tens of minutes. We demonstrate that synthetic traces generated from these models are capable of accurately reproducing application QoE metric distributions including their outlier values.}
}
@article{JILANI2019117,
title = {An implementation of IoT-based microwave sensing system for the evaluation of tissues moisture},
journal = {Microelectronics Journal},
volume = {88},
pages = {117-127},
year = {2019},
issn = {0026-2692},
doi = {https://doi.org/10.1016/j.mejo.2018.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0026269217306651},
author = {Muhammad Taha Jilani and Muhammad Zaka Ur Rehman and Abid Muhmmad Khan and Omer Chughtai and Muhammad Azeem Abbas and Muhammad Talha Khan},
keywords = {Internet of Things, Microwave sensor, Tissue moisture content, Dielectric spectroscopy, Meat quality monitoring, Water holding capacity, Bluetooth low energy},
abstract = {Internet-of-Things (IoT) is no longer just a buzzword. “Things” that are immensely connecting to the Internet, are now creating “Smart” systems. However, heterogeneous devices and the dominance of propriety protocols are still the major challenges for practical application of such systems. This research work presents a practical application of a real-time microwave sensing system for the evaluation of tissues moisture. The work addresses two major challenges; first, the use of a highly sensitive microwave sensor to determine tissue moisture; second, to share the measurement with the remote users through an IoT-based system over the Bluetooth low-energy radio using open standards and protocols. The prototype shows significant changes in its resonance frequency, return loss and bandwidth (5.5%–26%) for the measured moisture content, which is also validated. This implementation demonstrates the feasibility of real-time monitoring of food quality. It also enables data-analytics that may help the industries to improve product quality, supply-chain and predicts demand in a more effective manner.}
}
@article{SAFI201818,
title = {SVPS: Cloud-based smart vehicle parking system over ubiquitous VANETs},
journal = {Computer Networks},
volume = {138},
pages = {18-30},
year = {2018},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.03.034},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618301531},
author = {Qamas Gul Khan Safi and Senlin Luo and Limin Pan and Wangtong Liu and Rasheed Hussain and Safdar H. Bouk},
keywords = {Smart parking system, Parking facility, Cloud computing, Traffic congestion, VANET},
abstract = {Due to immense urbanization and growing number of vehicles, parking space is scarce and expensive in metropolitan cities. Drivers spend more time in searching and wandering for vacant parking facilities which causes traffic congestion, additional fuel consumption, and pollution. To provide more robust parking solutions, we propose a novel cloud-based smart vehicle parking system (SVPS) over ubiquitous VANETs. The proposed SVPS architecture offers a unique algorithm that provides an appropriate vacant parking space information along with booking and recommendation options to facilitate vehicles in an effective, real-time and precise manner. For the best utilization of existing parking facilities, numerous factors such as drive time, distance to the recommended parking facility, parking fee, walking distance from the parking facility to destination and traffic congestion, are deliberated in the proposed SVPS algorithm. Moreover, Parking Side Units (PSUs) are installed along every parking facility for coordinated management between cloud infrastructure and Road Side Units (RSUs). Extensive simulations results reveal that the proposed cloud-based SVPS reduces the fuel consumption and hazard emissions by enabling the best utilization of existing parking resources. Furthermore, the proposed approach addresses the traffic congestion caused by both vehicles searching for parking spaces and congestion caused by traffic routing.}
}
@article{ALI201819,
title = {An intelligent healthcare system for detection and classification to discriminate vocal fold disorders},
journal = {Future Generation Computer Systems},
volume = {85},
pages = {19-28},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.02.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17324421},
author = {Zulfiqar Ali and M. Shamim Hossain and Ghulam Muhammad and Arun Kumar Sangaiah},
keywords = {Healthcare, Vocal fold disorders, Binary classification, Critical bands, Auditory perception},
abstract = {The growing population of senior citizens around the world will appear as a big challenge in the future and they will engage a significant portion of the healthcare facilities. Therefore, it is necessary to develop intelligent healthcare systems so that they can be deployed in smart homes and cities for remote diagnosis. To overcome the problem, an intelligent healthcare system is proposed in this study. The proposed intelligent system is based on the human auditory mechanism and capable of detection and classification of various types of the vocal fold disorders. In the proposed system, critical bandwidth phenomena by using the bandpass filters spaced over Bark scale is implemented to simulate the human auditory mechanism. Therefore, the system acts like an expert clinician who can evaluate the voice of a patient by auditory perception. The experimental results show that the proposed system can detect the pathology with an accuracy of 99.72%. Moreover, the classification accuracy for vocal fold polyp, keratosis, vocal fold paralysis, vocal fold nodules, and adductor spasmodic dysphonia is 97.54%, 99.08%, 96.75%, 98.65%, 95.83%, and 95.83%, respectively. In addition, an experiment for paralysis versus all other disorders is also conducted, and an accuracy of 99.13% is achieved. The results show that the proposed system is accurate and reliable in vocal fold disorder assessment and can be deployed successfully for remote diagnosis. Moreover, the performance of the proposed system is better as compared to existing disorder assessment systems.}
}
@article{LADJ2021168,
title = {A knowledge-based Digital Shadow for machining industry in a Digital Twin perspective},
journal = {Journal of Manufacturing Systems},
volume = {58},
pages = {168-179},
year = {2021},
note = {Digital Twin towards Smart Manufacturing and Industry 4.0},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S027861252030128X},
author = {Asma Ladj and Zhiqiang Wang and Oussama Meski and Farouk Belkadi and Mathieu Ritou and Catherine {Da Cunha}},
keywords = {Digital shadow, Digital twin, Data and knowledge management, Machining},
abstract = {This paper addresses the problems of data management and analytics for decision-aid by proposing a new vision of Digital Shadow (DS) which would be considered as the core component of a future Digital Twin. Knowledge generated by experts and artificial intelligence, is transformed into formal business rules and integrated into the DS to enable the characterization of the real behavior of the physical system throughout its operation stage. This behavior model is continuously enriched by direct or derived learning, in order to improve the digital twin. The proposed DS relies on data analytics (based on unsupervised learning) and on a knowledge inference engine. It enables the incidents to be detected and it is also able to decipher its operational context. An example of this application in the aeronautic machining industry is provided to stress both the feasibility of the proposition and its potential impact on shop floor performance.}
}
@article{MADAAN2018125,
title = {Data integration in IoT ecosystem: Information linkage as a privacy threat},
journal = {Computer Law & Security Review},
volume = {34},
number = {1},
pages = {125-133},
year = {2018},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2017.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0267364917301358},
author = {Nishtha Madaan and Mohd Abdul Ahad and Sunil M. Sastry},
keywords = {Internet of things, Data integration, Information linkage, Privacy, Heterogeneous IoT ecosystem},
abstract = {Internet of things (IoT) is changing the way data is collected and processed. The scale and variety of devices, communication networks, and protocols involved in data collection present critical challenges for data processing and analyses. Newer and more sophisticated methods for data integration and aggregation are required to enhance the value of real-time and historical IoT data. Moreover, the pervasive nature of IoT data presents a number of privacy threats because of intermediate data processing steps, including data acquisition, data aggregation, fusion and integration. User profiling and record linkage are well studied topics in online social networks (OSNs); however, these have become more critical in IoT applications where different systems share and integrate data and information. The proposed study aims to discuss the privacy threat of information linkage, technical and legal approaches to address it in a heterogeneous IoT ecosystem. The paper illustrates and explains information linkage during the process of data integration in a smart neighbourhood scenario. Through this work, the authors aim to enable a technical and legal framework to ensure stakeholders awareness and protection of subjects about privacy breaches due to information linkage.}
}
@article{KONSTANTOPOULOS2020103741,
title = {Pore and phase identification through nanoindentation mapping and micro-computed tomography in nanoenhanced cement},
journal = {Cement and Concrete Composites},
volume = {114},
pages = {103741},
year = {2020},
issn = {0958-9465},
doi = {https://doi.org/10.1016/j.cemconcomp.2020.103741},
url = {https://www.sciencedirect.com/science/article/pii/S095894652030247X},
author = {George Konstantopoulos and Elias Koumoulos and Anna Karatza and Costas Charitidis},
keywords = {Nanoindentation, Carbon nanotubes, Nanomechanics, Micro-computed tomography, Image analysis, Calcium-silicate-hydrate (C-S-H)},
abstract = {In this work, a methodology is presented in order to assess the microstructure of Portland Cement through advanced characterisation. Nanoindentation is used to determine reduced elastic modulus and hardness, which are involved in the design of construction materials. Elemental mapping and X-ray scanning microtomography were also used to establish structure-property relations through porosity distribution and morphology as well as phase identification by nanoindentation and image analysis. The variation of carbon nanotubes (CNTs) concentration between 0.02 and 1.0 wt% demonstrated alterations in phase composition, and thus the effect of CNTs reinforcement in hydration progress was clarified. Characterisation by all techniques identified 0.5 wt% concentration as promising due to the formation of higher density hydrated phases, even though total porosity was not minimized. This fact was explained by nanoindentation as enhanced Calcium-Silicate-Hydrates connectivity in the porous network was detected. The voids of cement were filled with low stiffness hydrated gel phases as a result of enhanced hydration in the presence of CNTs.}
}
@article{WANG2021111637,
title = {The impact of COVID-19 pandemic on sustainable development goals – A survey},
journal = {Environmental Research},
volume = {202},
pages = {111637},
year = {2021},
issn = {0013-9351},
doi = {https://doi.org/10.1016/j.envres.2021.111637},
url = {https://www.sciencedirect.com/science/article/pii/S0013935121009312},
author = {Qiang Wang and Rui Huang},
keywords = {COVID-19, Sustainability, SDGs, Bibliometrics, Visualization},
abstract = {COVID-19 pandemic is the biggest challenge facing humanity after the 1918 Flu pandemic. The pandemic also poses a massive challenge to the achievement of Sustainable Development Goals (SDGs). Meeting this challenge requires a comprehensive investigation of the impact of the pandemic on sustainability. In this work, publications related to the impact of COVID-19 on sustainability in the Web of Science database were explored systematically by using bibliometrics techniques and meta-analysis approach. The results show the research scope is extensive, covering many subjects, whereas the research depth is not enough. Research in developed countries is dominant, although the pandemic poses more significant challenges to the sustainable development of developing countries than of developed countries. Developed countries are committed to studying education sustainability, while developing countries have shown greater attention to economic sustainability during the epidemic. The cluster analysis also shows that the COVID-19 pandemic has brought negative effects on 17 SDGs goals, whereas the pandemic may also bring opportunities to another 14 SDGs goals. At the end of the article, we put forward relevant suggestions for achieving sustainable development goals in the post-epidemic era.}
}
@article{HYUN2021145335,
title = {Modeling decision-maker preferences for long-term climate adaptation planning using a pathways approach},
journal = {Science of The Total Environment},
volume = {772},
pages = {145335},
year = {2021},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2021.145335},
url = {https://www.sciencedirect.com/science/article/pii/S0048969721004022},
author = {Jung Hee Hyun and Ji Yeon Kim and Chae Yeon Park and Dong Kun Lee},
keywords = {Climate change, Adaptation pathways, Decision-making under uncertainty, Adaptation planning, Maladaptation, Heat mortality},
abstract = {Decision-makers are faced with the task to translate the science of future climate change impacts to set policy goals and plans based on their capacities and contexts. However, there is a lack in support tools that translate the preferences and constraints of stakeholders to assess the viability of goals and strategies for adaptation planning. In this study, we introduce a decision-support model that simulates adaptation pathways using a multi-objective optimization algorithm. The model has been applied to find optimal adaptation pathways for reducing heat related morbidity in Seoul, South Korea under Representative Concentration Pathway (RCP) 8.5. We analyzed the effects of six hard and soft adaptation strategies from 2020 to 2100. Decision-maker preference scenarios based on three budget levels, two goal setting approaches and two investment delay plans were evaluated. The results show that after 2065, current adaptation strategies cannot reduce the impacts of heat mortality even with high budgets. A low budget limits adaptation for both ambitious and conservative goal settings while a higher budget did lead to greater adaptation but was not necessary for the conservative goal setting suggesting that efficient pairing of budget level based on the adaptation goal can be beneficial. Further, the longer the delay in investment toward adaptation results in irrecoverable reduction in adaptation. These results imply that different planning approaches are necessary for the desired adaptation effect and level of cost efficiency. This study is significant in that the methodology can be expanded to include other sectors and applied to various locations of different scales to help stakeholders develop more effective long-term adaptation plans based on their needs and constraints.}
}
@article{SHU2017635,
title = {Design for reduced resource consumption during the use phase of products},
journal = {CIRP Annals},
volume = {66},
number = {2},
pages = {635-658},
year = {2017},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2017.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0007850617301518},
author = {L.H. Shu and Joost Duflou and Christoph Herrmann and Tomohiko Sakao and Yoshiki Shimomura and Yannick {De Bock} and Jayesh Srivastava},
keywords = {Sustainable development, Human aspect, Pro-environmental behavior},
abstract = {Much work on sustainable design has focused on product manufacture/assembly and end of life. Gains in products’ technical efficiency address the use phase, but how these products are used clearly affects resource consumption. This paper describes two main approaches to reduce resource consumption during product life. Firstly, interventions aim to change user behavior, through information and feedback, as well as physical product affordances abstracted from lead users to guide or steer users toward the desired behavior. Secondly, automatic adjustment of product systems performance levels based on personal user profiles and anticipated usage is implemented using artificial intelligence techniques.}
}
@article{ABBASI202171,
title = {Intelligent workload allocation in IoT–Fog–cloud architecture towards mobile edge computing},
journal = {Computer Communications},
volume = {169},
pages = {71-80},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.01.022},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421000438},
author = {M. Abbasi and E. Mohammadi-Pasand and M.R. Khosravi},
keywords = {Internet of Things (IoT), Mobile edge computing (MEC), Multi-objective genetic algorithm, Workload allocation},
abstract = {Because of the tremendous growth in the number of smart vehicular devices and 5G mobile technologies, the Internet of Things (IoT) has experienced rapid expansion. This has led to a considerable increase in the volume of sensory data produced from, but not limited to, monitoring devices, traffic congestion in cities, safety, and pollution control. Cloud computing can deal with the corresponding workload by providing virtually unlimited computational resources. But, given the importance of the quality of service and security in delay-sensitive requests, other solutions like fog computing have also been introduced to speed up processing and management of sensory data in real scenarios like smart grid and IoT. Processing workloads at the network edge reduces the delay in mobile edge computing, but it highly increases the consuming power. Therefore, there is an urgent need for the improvement of the energy model of fog devices at the network edge. This paper is an attempt to modify this model using the green energy concept and reduce both delay and power consumption in multi-sensorial frameworks in secure IoT systems. In the proposed method, a Genetic Algorithm (GA) is used for handling a large number of requests and the corresponding quality and security limitations. Simulation results show that the proposed method can simultaneously reduce the delay and the power consumption of edge devices compared to a baseline strategy.}
}
@article{RAWAT20161,
title = {Cognitive radio for M2M and Internet of Things: A survey},
journal = {Computer Communications},
volume = {94},
pages = {1-29},
year = {2016},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2016.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S0140366416302699},
author = {Priyanka Rawat and Kamal Deep Singh and Jean Marie Bonnin},
keywords = {Cognitive radio, Spectrum management, Internet of Things, Smart grid, M2M},
abstract = {Internet of things (IoT) paradigm poses new challenges to the communication technology as numerous heterogeneous objects will need to be connected. To address these issues new radio technologies and network architectures need to be designed to cater to several future devices having connectivity demands. For radio communications, the frequency spectrum allocation will have to be adapted for efficient spectrum utilization considering new bandwidth and application requirements. Novel research directions based on the use of opportunistic radio resource utilization such as those based on cognitive radio (CR) technology will have to be pursued for efficiency as well as reliability. Cognitive Radio is a promising enabler communication technology for IoT. Its opportunistic communication paradigm is suited to communicating objects having event driven nature, that generate bursty traffic. Cognitive Radio can help overcome the problems of collision and excessive contention in the wireless access network that will arise due to the deployment of several objects connected to infrastructure through radio links. However, there are several issues that need to be addressed before cognitive radio technology can be used for Internet of things. This paper surveys novel approaches and discusses research challenges related to the use of cognitive radio technology for Internet of things. In addition, the paper presents a general background on cognitive radio and Internet of Things with some potential applications. Our survey is different from existing surveys in that we focus on recent advances and ongoing research directions in cognitive radio in the context of Machine to Machine and Internet of Things. We review CR solutions that address generic problems of IoT including emerging challenges of autonomicity, scalability, energy efficiency, heterogeneity in terms of user equipment capabilities, complexity and environments, etc. The solutions are supported by our taxonomy of different CR approaches that are classified into two categories, flexible and efficient networking, and tackling heterogeneity. This paper intends to help new researchers entering the domain of CR and IoT by providing a comprehensive survey on recent advances.}
}
@article{ALOMAISI2021100353,
title = {A survey of data dissemination schemes in vehicular named data networking},
journal = {Vehicular Communications},
volume = {30},
pages = {100353},
year = {2021},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2021.100353},
url = {https://www.sciencedirect.com/science/article/pii/S221420962100022X},
author = {Hussein Al-Omaisi and Elankovan A. Sundararajan and Raed Alsaqour and Nor Fadzilah Abdullah and Maha Abdelhaq},
keywords = {Vehicular networking, Named data networking, Vehicular named data network, Data dissemination scheme, Forwarding strategy, VNDN},
abstract = {Vehicular Ad hoc NETworks (VANETs) have become a leading technology receiving great attention from various research communities as a pivotal infrastructure for data dissemination in intelligent transportation systems. Data dissemination in VANET is a challenging task due to high dynamics in topology, mobility, and links connection. Internet model (i.e., TCP/IP) is inefficient for VANET data dissemination due to the host/address-centric, and connection-oriented communication mechanism that is fundamentally designed for stable wired networks. Recently, Named Data Networking (NDN) paradigm has been used as a promising perfect-enabler underlying vehicular communication model, i.e., Vehicular Named Data Networking (V-NDN) model. In NDN, the nodes communication involves named-based data-centric operations decoupled from the data provider address/location. Several V-NDN data dissemination schemes have been proposed. In this article, we provide a comprehensive survey representing a thorough-critical presentation of recently proposed V-NDN data dissemination solutions and introduce a new fine-grained taxonomy for these solutions. Then, a qualitative comparison of the reviewed solutions based on several parameters is provided. We also suggest a unified performance evaluation metrics in this domain. Finally, we present the open problems in V-NDN data dissemination and highlight the directions of future-oriented solutions. This comprehensive and self-contained survey can contribute to the exploration and understanding of this research domain. Consequently, the future solutions in the aspects of unresolved problems and inefficient resolutions may be directed towards new solving methods.}
}
@article{WANG2021114402,
title = {Wind speed forecasting based on multi-objective grey wolf optimisation algorithm, weighted information criterion, and wind energy conversion system: A case study in Eastern China},
journal = {Energy Conversion and Management},
volume = {243},
pages = {114402},
year = {2021},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2021.114402},
url = {https://www.sciencedirect.com/science/article/pii/S0196890421005781},
author = {Chen Wang and Shenghui Zhang and Ling Xiao and Tonglin Fu},
keywords = {Combined forecasting model, Model selection, Multi-objective algorithm, Wind energy conversion},
abstract = {Accurate wind speed forecasting and effective wind energy conversion can reduce the operating cost of wind farms. However, many previous studies have been restricted to analyses of wind speed forecasting and wind energy conversion, which may result in poor decisions and inaccurate power scheduling for wind farms. This study develops a wind energy decision system based on forecasting and simulation, which includes two modules: wind speed forecasting and wind energy conversion. In the wind speed forecasting module, an effective secondary denoising strategy based on singular spectrum analysis and ensemble empirical mode decomposition was used to eliminate chaotic noise and extract important features from the original data. Then, a model selection called weighted information criterion was applied to select optimal sub-models for the combined model. To improve the forecasting performance of the combined model, a modified multi-objective grey wolf optimisation algorithm was adopted to optimise the parameters of the sub-models and the weight of the combined model. In the wind energy conversion module, a wind energy conversion curve was established by simulating historical electrical energy data and wind speed data, which can effectively analyse the power generation at each site. The numerical results show that compared with the mean absolute percentage error values of the single models, that of the combined model is reduced by up to 35.57%. Moreover, the standard deviation of the absolute percentage error is decreased by up to 49.88% for wind speed forecasting, and the R2 of the wind energy conversion curve is more than 0.9. Therefore, the proposed combined method can serve as an effective tool for wind farm management and decision-making.}
}
@article{SINGH2020119963,
title = {Bibliometric overview of the Technological Forecasting and Social Change journal: Analysis from 1970 to 2018},
journal = {Technological Forecasting and Social Change},
volume = {154},
pages = {119963},
year = {2020},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2020.119963},
url = {https://www.sciencedirect.com/science/article/pii/S0040162519305220},
author = {Shiwangi Singh and Sanjay Dhir and V. Mukunda Das and Anuj Sharma},
keywords = {, Journal analysis, Bibliometrics, Keyword co-occurrences, Co-citation analysis, Factor analysis},
abstract = {The purpose of this paper is to analyze the evolution of Technological Forecasting and Social Change journal for a period between 1970 and 2018 for 4248 articles. The growing scope and diversity of the field creates fragmentation and the belief that reviews could contribute to synthesis and integration. This analysis includes key factors impacting growth of a journal such as publication evolution and citation structure, most cited articles, leading authors, institutions and countries, related journals and ranking, key research streams in the journal, and co-citation analysis. Factors of the Technological Forecasting and Social Change journal determine the relationship between various sub-fields. The analysis also provides key insights about the evolution of the field over time.}
}
@article{WILSON2022101652,
title = {Public engagement and AI: A values analysis of national strategies},
journal = {Government Information Quarterly},
volume = {39},
number = {1},
pages = {101652},
year = {2022},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2021.101652},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X21000885},
author = {Christopher Wilson},
keywords = {Public engagement, Public values, Public value management, Artificial intelligence, Technology frames, Technology policy, Participation, Open government},
abstract = {Calls for public engagement and participation in AI governance align strongly with a public value management approach to public administration. Simultaneously, the prominence of commercial vendors and consultants in AI discourse emphasizes market value and efficiency in a way often associated with the private sector and New Public Management. To understand how this might influence the consolidation of AI governance regimes and decision-making by public administrators, 16 national strategies for AI are subjected to content analysis. References to the public's role and public engagement mechanisms are mapped across national strategies, as is the articulation of values related to professionalism, efficiency, service, engagement, and the private sector. Though engagement rhetoric is common, references to specific engagement mechanisms and activities are rare. Analysis of value relationships highlights congruence of engagement values with professionalism and private sector values, and raises concerns about neoliberal technology frames that normalize AI, obscuring policy complexity and trade-offs.}
}
@article{DEY2021128254,
title = {Blockchain for sustainable e-agriculture: Literature review, architecture for data management, and implications},
journal = {Journal of Cleaner Production},
volume = {316},
pages = {128254},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.128254},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621024707},
author = {Kushankur Dey and Umedsingh Shekhawat},
keywords = {Blockchain, Internet-of-Things, Smart function, e-agriculture, RAFT Consensus, FAIR data Principles, Distributed ledger technology},
abstract = {The architecture design by integrating the blockchain and IoT has gained salience in information systems and information technology research. However, there has not been significant work on the comprehensive and sequential applications of blockchain integrated IoT in e-agriculture for data validation, data storage, data security and data privacy. We aim to bridge this gap in the literature and discuss how the integration of blockchain and IoT can improve backward and forward linkages in agricultural value chains, benefit value chain actors, and augment the performance of IoT network. The study considers use cases of agriculture inputs and commodities/products to demonstrate the application of IoT devices in data collection and blockchain technology for data validation, data storage, data security, and data transmission. RAFT consensus algorithm for permission blockchain and FAIR principles are utilized to make e-agriculture information systems decentralized, efficient, fault tolerant, and interoperable. The technology coupling in e-agriculture can create externalities such as shared benefits, improved coordination between value chain actors, and real-time decision-making for optimal resource allocation and their sustainable utilization in e-agriculture.}
}
@article{WANG2019160,
title = {An integrated GIS platform architecture for spatiotemporal big data},
journal = {Future Generation Computer Systems},
volume = {94},
pages = {160-172},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.10.034},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17319283},
author = {Shaohua Wang and Yang Zhong and Erqi Wang},
keywords = {Spatiotemporal big data, Distributed computing framework, Cloud-terminal integration GIS, SuperMap GIS},
abstract = {With the increase in smart devices, spatiotemporal data has grown exponentially. To deal with challenges caused by an increase data requires a scalable and efficient architecture that can store, query, analyze, and visualize spatiotemporal big data. This paper describes a Cloud-terminal integrated GIS platform architecture designed to meet the requirements of processing and analyzing spatiotemporal big data. Cloud-terminal Integration GIS is developed according to the architecture. Extensive experiments deployed on the internal organization cluster using real-time datasets showed that the SuperMap GIS spatiotemporal big data engine achieved excellent performance.}
}
@article{NEDJAH2019622,
title = {Efficient fingerprint matching on smart cards for high security and privacy in smart systems},
journal = {Information Sciences},
volume = {479},
pages = {622-639},
year = {2019},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.12.038},
url = {https://www.sciencedirect.com/science/article/pii/S0020025517311611},
author = {Nadia Nedjah and Rafael S. Wyant and Luiza M. Mourelle and Brij B. Gupta},
keywords = {Biometrics, Fingerprint, Minutiae, Smart-card},
abstract = {Smart control access to any service is at the very basis of any smart project. Biometrics have been used as a solution for service access control an any smart system, for many years now. However, the simple use of biometrics cannot be considered as final and perfect solution. Most problems are related to the data transmission method between the medias, for which the users require access and the servers, wherein the biometric data, captured upon registration, are stored. In this paper, we use smart cards as an effective yet efficient solution to this critical data storage problem. Furthermore, fingerprints have been used as a human identifier for some time now. This biometric is considered one of the most reliable to distinguish a person from another as its unique yet perfectly stable over time. In this work, we propose an efficient implementation of fingerprint verification on smart cards. For this implementation, the matching is done on-card. Thus, the biometric characteristics are always kept in the owner’s card, guaranteeing the maximum security and privacy. The proposed implementation is based on the Skin Elasticity Tolerant Algorithm (SETA), which uses minutiae to implement fingerprints matching. It consists of finding the best alignment between the compared fingerprints before proceeding with the comparison step to maximize the score that quantifies the quality of the matching. Although efficient, SETA is not suitable for card implementation because it requires a lot of dynamic storage memory to store the counters of all possible rotations and translations. In order to make the implementation on smart cards viable mitigating the problem of the volume of storage required to store the translations and rotations, we subdivide the search space into small subspaces. Thus, only the translations and rotations that fall within to the handled subspace at each instant are considered. The implementation on smart cards is evaluated for known fingerprint datasets. Several settings are tested, establishing that the implementation is suitable for real-time applications.}
}
@article{CASTIGLIONE20181134,
title = {CHIS: A big data infrastructure to manage digital cultural items},
journal = {Future Generation Computer Systems},
volume = {86},
pages = {1134-1145},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17305605},
author = {Aniello Castiglione and Francesco Colace and Vincenzo Moscato and Francesco Palmieri},
keywords = {Big data, Cultural heritage, Resource management, Big data analytics, SOA, NoSQL},
abstract = {In this paper, we describe CHIS (Cultural Heritage Information System), a big data infrastructure that can be used to query, browse, analyze and process digital contents related to cultural heritage from a set of heterogeneous and distributed repositories. CHIS is characterized by the following technical features: capability to gather information from distributed and heterogeneous data sources (e.g., Sensor Networks, Social Media Networks, Digital Libraries and Archives, Multimedia Collections, Web Data Services, etc.); advanced data management techniques and technologies; ability to provide useful and personalized data to users based on their preferences and context; advanced information retrieval facilities, data analytics and other utilities/services, according to the SOA paradigm. By means of a set of ad-hoc APIs, and value-added data processing and analytics services, our system can support several applications: mobile multimedia guides for cultural environments, web portals to promote the cultural heritage of a given organization, multimedia recommender and storytelling systems and so on. We discuss the main ideas that characterize the system, showing its use for several applications.}
}
@article{RAJAMAND2022101922,
title = {Feedback-based control structure for frequency/voltage regulation using the state of electrical vehicle charge station and point estimation method},
journal = {Sustainable Energy Technologies and Assessments},
volume = {51},
pages = {101922},
year = {2022},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2021.101922},
url = {https://www.sciencedirect.com/science/article/pii/S221313882100936X},
author = {Sahbasadat Rajamand},
keywords = {Electrical vehicle charge station, State of charge, Frequency control, Voltage control, EV-feedback control structure},
abstract = {Electrical-vehicle-based microgrid (MG) has received much attention in new power systems. Cost reduction, voltage profile improvement and greenhouse gas reduction are some benefits available in these system. However, some challenges as electrical vehicle (EV) energy management, electrical vehicle charging station (EVCS) localization, supporting all load demands and voltage/frequency regulation are focused in new research issues. In other side, uncertainties of EVs, EVCS, PV/WT and loads must be analyzed in the MG to improve the performance in voltage and frequency regulation. Using the state of charge (SOC) in EVCS and feedback it to the control structure can enhance the performance of the MG in voltage and frequency regulation and stability. The effect of EVCS feedback on the control circuit is analyzed in this paper with combining of accurate estimated values of uncertain DGs and loads using point estimation method. Simulation results show significant improvement in frequency/voltage regulation in addition to the voltage profile and supported load using SOC of EV and EVCS in the control structure.}
}
@article{WU2020124854,
title = {A logarithmic descent direction algorithm for the quadratic knapsack problem},
journal = {Applied Mathematics and Computation},
volume = {369},
pages = {124854},
year = {2020},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2019.124854},
url = {https://www.sciencedirect.com/science/article/pii/S009630031930846X},
author = {Zhengtian Wu and Baoping Jiang and Hamid Reza Karimi},
keywords = {Quadratic knapsack problem, NP-hard optimization problem, Damped newton method, Karush–Kuhn–Tucker condition},
abstract = {The quadratic knapsack problem is an NP-hard optimization problem with many diverse applications in industrial and management engineering. However, computational complexities still remain in the quadratic knapsack problem. In this study, a logarithmic descent direction algorithm is proposed to approximate a solution to the quadratic knapsack problem. The proposed algorithm is based on the Karush–Kuhn–Tucker necessary optimality condition and the damped Newton method. The convergence of the algorithm is proven, and the numerical results indicate its effectiveness.}
}
@article{SHARIFI2021107102,
title = {Urban sustainability assessment: An overview and bibliometric analysis},
journal = {Ecological Indicators},
volume = {121},
pages = {107102},
year = {2021},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2020.107102},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X20310414},
author = {Ayyoob Sharifi},
keywords = {Sustainable development, Urban sustainability, Sustainability assessment, Cities, Indicators, Bibliometrics},
abstract = {Following the recognition of the significance of urban areas for achieving sustainable development in the late 1980′s, first studies on ‘urban sustainability assessment’ were published in early 1990s. Since then, the field has grown rapidly, with over 300 papers published annually in recent years. The main objective of this study is to present a bibliometric analysis of about thirty years of research on urban sustainability assessment. The literature database includes 3877 articles published in the Web of Science. VOSviewer and SciMAT are two science mapping software tools that were utilized for this purpose. VOSviewer is utilized to detect major focus areas and to identify influential authors, publications, and journals using various network analysis techniques such as term co-occurrence, co-citation, and bibliographic coupling. Also, SciMAT is used to understand how the intellectual base of the field has evolved over time and what are the major themes that have contributed to this evolution. For this purpose, the study interval was divided into four sub-periods (i.e., 1991–2000; 2001–2009; 2010–2015; and 2016–2020). Results show that this field has initially been mainly focused on few themes but has later become more diversified to acknowledge the multi-dimensional characteristics of urban sustainability. Despite this, environmental aspects are still dominant and major socio-economic issues such as equity, justice, and public engagement are not well represented. Sustainable development indicators, energy, green infrastructure, water, land use, and urban design are major thematic areas, with the first three playing more important roles in structuring the development of the field. This study can be used as a point of reference for those interested in gaining more knowledge about urban sustainability assessment and its evolution.}
}
@article{PLAMONDON2018633,
title = {Personal digital bodyguards for e-security, e-learning and e-health: A prospective survey},
journal = {Pattern Recognition},
volume = {81},
pages = {633-659},
year = {2018},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2018.04.012},
url = {https://www.sciencedirect.com/science/article/pii/S0031320318301456},
author = {Réjean Plamondon and Giuseppe Pirlo and Éric Anquetil and Céline Rémi and Hans-Leo Teulings and Masaki Nakagawa},
keywords = {Signature verification, Handwriting learning and recognition, Neuromuscular disorder, Lognormality principle, Mobile devices, E-security, E-recognition, E-interaction, E-health, E-learning, E-testing tools, Personal digital body guard},
abstract = {The widespread availability of hand-held devices like tablets, phablets and smart phones, along with their new handwriting digitizing and their increased computing powers, enable these to process the graphomotor dimension and the lognormal trends of human handwriting. By exploiting such capacity, it becomes possible to extend these mobile devices into Personal Digital Bodyguards (PDBs). PDBs will be able to supplement people's sensitive data protection with signature verification, equipment use security with writer authentication and handwritten CAPTCHAs processing (e-security), and to enhance human-machine interaction performances through words spotting and handwriting recognition (e-recognition). For young children, these tools will turn into interactive toys helping them to learn and master their fine motor control and become better writers. For advanced students they will enable sophisticated systems for (e-learning) and (e-testing). Moreover, PDBs will also be able to provide the user with fine motor control monitoring, which can detect stress, aging and health problems (e-health). This paper presents a prospective survey of various projects dealing with these five e-fields of investigation, focussing on state of the art results and providing directions in research and development, under the theoretical umbrella of the Kinematic Theory of human movements and its Lognormality Principle. From a practical point of view, the concept of lognormality provides a fundamental common thread, an integrative psychophysical standpoint to track the graphomotor problems of signature verification, writer identification, handwriting generation, recognition and learning.}
}
@article{REPETTO2021251,
title = {An architecture to manage security operations for digital service chains},
journal = {Future Generation Computer Systems},
volume = {115},
pages = {251-266},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.08.044},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20303290},
author = {Matteo Repetto and Alessandro Carrega and Riccardo Rapuzzi},
keywords = {Cyber-security paradigms, Security architectures, Digital services, Service mesh},
abstract = {Evolving business models are progressively pushing for increasing digitalization of existing and novel processes. The ICT industry is already addressing this need by massive introduction of virtualization paradigms and tight integration with the physical environment, which allow the creation of multi-domain and complex business service chains. Emerging technologies undoubtedly bring more agility in service deployment and operation but also break traditional security models, which have not been conceived for dynamic and multi-tenancy environments. In this paper, we briefly elaborate on existing gaps and research challenges towards advanced assurance and protection of trustworthy and reliable business chains spanning multiple administrative domains and heterogeneous infrastructures. We consolidate our analysis in a reference architecture, which includes all functional elements to effectively tackle the dynamic and agile nature of emerging ICT paradigms.}
}
@article{ZHONG2017616,
title = {Intelligent Manufacturing in the Context of Industry 4.0: A Review},
journal = {Engineering},
volume = {3},
number = {5},
pages = {616-630},
year = {2017},
issn = {2095-8099},
doi = {https://doi.org/10.1016/J.ENG.2017.05.015},
url = {https://www.sciencedirect.com/science/article/pii/S2095809917307130},
author = {Ray Y. Zhong and Xun Xu and Eberhard Klotz and Stephen T. Newman},
keywords = {Intelligent manufacturing, Industry 4.0, Internet of Things, Manufacturing systems, Cloud manufacturing, Cyber-physical system},
abstract = {Our next generation of industry—Industry 4.0—holds the promise of increased flexibility in manufacturing, along with mass customization, better quality, and improved productivity. It thus enables companies to cope with the challenges of producing increasingly individualized products with a short lead-time to market and higher quality. Intelligent manufacturing plays an important role in Industry 4.0. Typical resources are converted into intelligent objects so that they are able to sense, act, and behave within a smart environment. In order to fully understand intelligent manufacturing in the context of Industry 4.0, this paper provides a comprehensive review of associated topics such as intelligent manufacturing, Internet of Things (IoT)-enabled manufacturing, and cloud manufacturing. Similarities and differences in these topics are highlighted based on our analysis. We also review key technologies such as the IoT, cyber-physical systems (CPSs), cloud computing, big data analytics (BDA), and information and communications technology (ICT) that are used to enable intelligent manufacturing. Next, we describe worldwide movements in intelligent manufacturing, including governmental strategic plans from different countries and strategic plans from major international companies in the European Union, United States, Japan, and China. Finally, we present current challenges and future research directions. The concepts discussed in this paper will spark new ideas in the effort to realize the much-anticipated Fourth Industrial Revolution.}
}
@article{VALOCKY201992,
title = {Experimental Autonomous Car Model with safety sensor in Wireless Network},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {27},
pages = {92-97},
year = {2019},
note = {16th IFAC Conference on Programmable Devices and Embedded Systems PDES 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.739},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319326886},
author = {Frederik Valocky and Milos Orgon and Ina Fujdiak},
keywords = {Autonomous vehicles, Ultrasonic sensor, VANET, IoT, IoV},
abstract = {Autonomous vehicles are vehicles equipped with autonomous control systems that allow certain aspects of the control functions important for safe traffic to be controlled by the vehicle itself. At the same time, these cars are able to move from point A to point B separately in a defined environment and decide independently and adapt to unknown situations and a changing environment. These actions are autonomous cars capable of performing with minimal or no interference from the driver. This article is aimed at verifying the communication capabilities with data from safety sensors mounted on autonomous car between a control unit and car.}
}
@article{CHONG2022122801,
title = {Post COVID-19 ENERGY sustainability and carbon emissions neutrality},
journal = {Energy},
volume = {241},
pages = {122801},
year = {2022},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2021.122801},
url = {https://www.sciencedirect.com/science/article/pii/S0360544221030504},
author = {Cheng Tung Chong and Yee Van Fan and Chew Tin Lee and Jiří Jaromír Klemeš},
keywords = {Smart energy, Energy efficiency, Emission neutrality, Novel material, Energy sustainability},
abstract = {This review covers the recent advancements in selected emerging energy sectors, emphasising carbon emission neutrality and energy sustainability in the post-COVID-19 era. It benefited from the latest development reported in the Virtual Special Issue of ENERGY dedicated to the 6th International Conference on Low Carbon Asia and Beyond (ICLCA′20) and the 4th Sustainable Process Integration Laboratory Scientific Conference (SPIL′20). As nations bind together to tackle global climate change, one of the urgent needs is the energy sector's transition from fossil-fuel reliant to a more sustainable carbon-free solution. Recent progress shows that advancement in energy efficiency modelling of components and energy systems has greatly facilitated the development of more complex and efficient energy systems. The scope of energy system modelling can be based on temporal, spatial and technical resolutions. The emergence of novel materials such as MXene, metal-organic framework and flexible phase change materials have shown promising energy conversion efficiency. The integration of the internet of things (IoT) with an energy storage system and renewable energy supplies has led to the development of a smart energy system that effectively connects the power producer and end-users, thereby allowing more efficient management of energy flow and consumption. The future smart energy system has been redefined to include all energy sectors via a cross-sectoral integration approach, paving the way for the greater utilization of renewable energy. This review highlights that energy system efficiency and sustainability can be improved via innovations in smart energy systems, novel energy materials and low carbon technologies. Their impacts on the environment, resource availability and social well-being need to be holistically considered and supported by diverse solutions, in alignment with the sustainable development goal of Affordable and Clean Energy (SDG 7) and other related SDGs (1, 8, 9, 11,13,15 and 17), as put forth by the United Nations.}
}
@article{WANG2019176,
title = {An adaptive latent factor model via particle swarm optimization},
journal = {Neurocomputing},
volume = {369},
pages = {176-184},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.08.052},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219311907},
author = {Qingxian Wang and Sili Chen and Xin Luo},
keywords = {Latent factor analysis, Particle swarm optimization, High-dimensional and sparse matrix, Stochastic gradient descent, Self-adaptive model},
abstract = {Latent factor (LF) models are greatly efficient in extracting valuable knowledge from High-Dimensional and Sparse (HiDS) matrices which are usually seen in many industrial applications. Stochastic gradient descent (SGD) is an effective algorithm to build an LF model, yet its convergence rate depends vastly on the learning rate which should be tuned with care. Therefore, automatic selection of an optimal learning rate for an SGD-based LF model is a meaningful issue. To address it, this study incorporates the principle of particle swarm optimization (PSO) into an SGD-based LF model for searching an optimal learning rate automatically. With it, we further propose an adaptive Latent Factor (ALF) model. Empirical studies on four HiDS matrices from real industrial applications indicate that an ALF model obvious outperforms an LF model according to convergence rate, and maintain competitive prediction accuracy for missing data.}
}
@article{TANG20191,
title = {The strategic role of logistics in the industry 4.0 era},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {129},
pages = {1-11},
year = {2019},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2019.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S1366554519306349},
author = {Christopher S. Tang and Lucas P. Veelenturf},
keywords = {Industry 4.0, Additive manufacturing, Blockchain, Drones, Artificial intelligence, Logistics, Transportation},
abstract = {By leveraging new technologies (Additive Manufacturing, Advanced Robotics, Artificial Intelligence, Autonomous Vehicles, Blockchain, Drones, Internet of Things, etc.), many companies are developing cyber-physical systems that can change the competition landscape. In the midst of this exciting development, we examine the strategic role of logistics and transportation services for creating economic, environmental and social values. Also, we discuss some new research directions.}
}
@article{SHEIKHPOUR2021105085,
title = {High-throughput configurable SIMON architecture for flexible security},
journal = {Microelectronics Journal},
volume = {113},
pages = {105085},
year = {2021},
issn = {0026-2692},
doi = {https://doi.org/10.1016/j.mejo.2021.105085},
url = {https://www.sciencedirect.com/science/article/pii/S0026269221000963},
author = {Saeideh Sheikhpour and Mohammad Hassani Sadi and Ali Mahani},
keywords = {SIMON block cipher, High-throughput cryptography, Internet-of-Things (IoTs), Compact implementation, Fault attack, Power attack},
abstract = {As the Internet of Things applications become mission-critical and their data more valuable, it becomes more and more essential to paramount their security. The security can be improved by using emerging light-weight ciphers. SIMON is a relatively recent family of light-weight ciphers which is proposed by the National Security Agency optimized for hardware platforms. In this paper, we propose an optimized hardware architecture for SIMON for high-throughput resource-constrained applications with multiple levels of security. Moreover, a configurable architecture with different operating modes is introduced for utilizing in applications requiring higher resistance to fault and power attacks. This architecture also supports an ultra-high-throughput mode for different key sizes. Implementation results of the proposed architectures on both ASIC and FPGA are reported. The comparison results show that our proposals outperform similar architectures in terms of some design metrics, e.g. throughput, which make it suitable for IoT applications. Finally, we implement practically our architecture on the Digilent-ZYBO board and report the experimental results.}
}
@article{AHREND2021100406,
title = {Sensors as the Basis for Digitalization: New Approaches in Instrumentation, IoT-concepts, and 5G},
journal = {Internet of Things},
volume = {15},
pages = {100406},
year = {2021},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2021.100406},
url = {https://www.sciencedirect.com/science/article/pii/S2542660521000500},
author = {Ulf Ahrend and Markus Aleksy and Matthias Berning and Jörg Gebhardt and Francisco Mendoza and Dirk Schulz},
keywords = {Sensors, Sensing concepts, Model-based, Non-invasive, Digitalization, Industrie 4.0, Monitoring and optimization, Temperature sensors, Infrared thermography, Connectivity, Pervasive sensing, Communication, Sensor use cases, OPC-UA, APL, 5G},
abstract = {The role of sensors and sensing concepts is reviewed and reflected in the context of digitalization, particularly of large automation systems. Process industries have been chosen as an example and starting point. Large-scale market driving forces are elaborated and a scenario for the proliferation of innovative sensors in process industries is proposed. Detailed requirements for future sensor systems are derived, both functional and non-functional, e.g. regarding communication capabilities and power supply. Examples of recent instrumentation developments are given, as well as several use cases for innovative sensing solutions. New communication options for integrating the sensors in automation systems are reviewed. Finally, specific 5G-related opportunities for new sensor applications are discussed.}
}
@article{GAO2017220,
title = {A novel target detection method for SAR images based on shadow proposal and saliency analysis},
journal = {Neurocomputing},
volume = {267},
pages = {220-231},
year = {2017},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217310597},
author = {Fei Gao and Jialing You and Jun Wang and Jinping Sun and Erfu Yang and Huiyu Zhou},
keywords = {Synthetic aperture radar (SAR) target detection, Shadow, Saliency detection, Local spatial autocorrelation, Visual features, One-Class SVM (OC-SVM)},
abstract = {Conventional synthetic aperture radar (SAR) based target detection methods generally use high intensity pixels in the pre-screening stage while ignoring shadow information. Furthermore, they cannot accurately extract the target area and also have poor performance in cluttered environments. To solve this problem, a novel SAR target detection method which combines shadow proposal and saliency analysis is presented in this paper. The detection process is divided into shadow proposal, saliency detection and One-Class Support Vector Machine (OC-SVM) screening stages. In the shadow proposal stage, localizing targets is performed first with the detected shadow regions to generate proposal chips that may contain potential targets. Then saliency detection is conducted to extract salient regions of the proposal chips using local spatial autocorrelation and significance tests. Afterwards, in the last stage, the OC-SVM is employed to identify the real targets from the salient regions. Experimental results show that the proposed saliency detection method possesses higher detection accuracy than several state of the art methods on SAR images. Furthermore, the proposed SAR target detection method is demonstrated to be robust under different imaging environments.}
}
@article{YIN2020100143,
title = {A novel temporal and spatial panorama stream processing engine on IoT applications},
journal = {Journal of Industrial Information Integration},
volume = {18},
pages = {100143},
year = {2020},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2020.100143},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X20300182},
author = {Yifan Yin and Boyi Xu and Hongming Cai and Han Yu},
keywords = {Internet of things, Temporal and spatial panorama modeling, Stream processing, Clustering analysis},
abstract = {Nowadays, more and more streaming data are generated with the development of Internet of Things. Although, streaming data show great application values in practical scenarios, raw streams from terminal sensors are quite massive, heterogeneous and complex, and those features make it difficult for applications to deal with them. In order to simplify streaming data processing for applications, a novel temporal and spatial panorama stream processing engine is proposed. This stream processing engine forms an effective link between bottom sensors and upper stream-based applications, and provides configurable, flexible, available and usable stream services for various upper applications. With support of Internet plus and domain data, raw streaming data are formatted thorough data fusion and are represented in temporal, spatial, logic and storage views. Fusion data are encapsulated with multiple strategies and methods of clustering models on every dimension. According to configurable strategies, encapsulated data are extracted, partitioned and distributed as the form of dynamical variable gratitude data blocks into stream channels. Our engine is applied to a practical application scenario. Case study of dynamic power distribution application based on people crowd streaming data proves the customized service capabilities of our engine. And the outstanding performance of the engine is shown further by experiments evaluation in this case.}
}
@article{SHI2022107860,
title = {Enhancing distribution system resilience against extreme weather events: Concept review, algorithm summary, and future vision},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {138},
pages = {107860},
year = {2022},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2021.107860},
url = {https://www.sciencedirect.com/science/article/pii/S0142061521010759},
author = {Qingxin Shi and Wenxia Liu and Bo Zeng and Hongxun Hui and Fangxing Li},
keywords = {Resilient distribution system, Extreme weather event, Restoration, Line hardening, Optimal dispatch, Network reconfiguration},
abstract = {Distribution system infrastructures are vulnerable to extreme weather events, such as hurricane, ice coating, flood, and wildfires. Resilience is a measure of the system's ability to prevent the damage during extreme events and to recover the system function after such events. With the economic development, it becomes increasingly important for power utilities to maintain critical loads always in service and to reduce the unserved energy of all loads. If many distribution system equipments are damaged, the utility companies dispatch static or mobile distributed energy resources, reconfigure the network topology in order to restore the islanded sections of the distribution system. In recent years, a large number of studies have been done on operation and planning strategies to enhance the distribution system resilience. This review paper introduces the background of resilient distribution system. Then, it makes a comprehensive summary of the resources for resilience enhancement, the mathematical model of operation and planning algorithms. In particular, the objective function, mathematical formulation, decision variables, and solution algorithm of each study are compared. Finally, the roadmap of resilient distribution system is extracted and the future research direction on this topic is proposed.}
}
@article{NAVIOMARCO2018460,
title = {Progress in information technology and tourism management: 30 years on and 20 years after the internet - Revisiting Buhalis & Law's landmark study about eTourism},
journal = {Tourism Management},
volume = {69},
pages = {460-470},
year = {2018},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2018.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0261517718301134},
author = {Julio Navío-Marco and Luis Manuel Ruiz-Gómez and Claudia Sevilla-Sevilla},
keywords = {e-Tourism, Buhalis, Law, Internet, Digital tourism, ICTs},
abstract = {“Progress in information technology and tourism management: 20 years on and 10 years after the Internet—The state of eTourism research” is reviewed in terms of its significance to academic literature linking Information and Communication Technologies (ICTs) and tourism. Ten years after its publication in 2008, we revisit this paper with a view to observing the main changes in eTourism over these years, analysing the strategic lines that are driving its evolution, and verifying the fulfilment of the tendencies anticipated by Buhalis and Law. Their diagnosis has been very accurate and, given the rapidity of the technological changes, it is appropriate to highlight the changes that this sector has experienced since then.}
}
@article{CHENG2020334,
title = {Blind image deblurring via hybrid deep priors modeling},
journal = {Neurocomputing},
volume = {387},
pages = {334-345},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220300230},
author = {Shichao Cheng and Risheng Liu and Yi He and Xin Fan and Zhongxuan Luo},
keywords = {Image processing, Blind image deblurring, Kernel estimation, Hybrid deep priors, Residual network},
abstract = {Blind image deblurring is a challenging low-level vision problem which aims to restore a sharp image only from the blurry observation. Few known information makes this problem fundamentally ill-posed. Most recent works focus on designing various priors on both latent image and blur kernel based on the maximum a posteriori (MAP) model to restrict the solution space. However, their performance is highly related to these hand-crafted explicit priors. In fact, the pre-designed explicit priors may have less flexibility to fit different image structures in real-world scenarios. To overcome these difficulties, we propose a novel framework, named Hybrid Deep Priors Model (HDPM), to simulate the propagation of sharp latent image used in kernel estimation and final deconvolution. Specifically, we introduce the learnable implicit deep prior and hand-crafted explicit prior as regularizations into the MAP inference process to extract the detailed texture and sharp structures of latent image, respectively. In HDPM, we can successfully take the advantages of explicit cues based on task information and implicit deep priors from training data to facilitate the propagation of sharp latent image which is beneficial for the kernel estimation. Extensive experiments demonstrate that the proposed method performs favorably against the state-of-the-art deblurring methods on benchmarks, challenging scenarios and non-uniform images.}
}
@article{WANG2020119852,
title = {Safety informatics as a new, promising and sustainable area of safety science in the information age},
journal = {Journal of Cleaner Production},
volume = {252},
pages = {119852},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.119852},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619347225},
author = {Bing Wang and Chao Wu},
keywords = {Safety science, Information science, Safety information, Safety informatics, Safety 4.0},
abstract = {Safety is a central dimension in contemporary debates on human health, loss prevention, environmental protection, sustainability, and cleaner production. In the information age, especially in the era of big data, safety information is an essential strategy for safety, and safety informatics has become a major research interest and a popular issue in the field of safety science. In recent years, safety informatics—a new area of safety science—has received increasing attention, developing greatly with successful research on the subject. The three key purposes of this paper are: (i) to analyze the historical development of safety informatics, (ii) to review the research progress of safety informatics, and (iii) to review limitations and propose future directions in the field of safety informatics. First, the development process of safety informatics is divided into four typical stages: (i) the embryonic stage (1940–1980), (ii) the initial stage (1980–1990), (iii) the formation stage (1990–2010), and (iv) the deepening stage (2010–present). Then, a review of safety informatics research is provided from seven aspects, including: (i) the discipline construction of safety informatics, (ii) theoretical safety information model, (iii) accident causation model from a safety information perspective, (iv) safety management based on safety information, (v) safety big data, (vi) safety intelligence, and (vii) safety information technology. Finally, limitations and future research directions in the safety informatics area are briefly discussed.}
}
@article{ASADI2021102426,
title = {Effect of internet of things on manufacturing performance: A hybrid multi-criteria decision-making and neuro-fuzzy approach},
journal = {Technovation},
pages = {102426},
year = {2021},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2021.102426},
url = {https://www.sciencedirect.com/science/article/pii/S0166497221002078},
author = {Shahla Asadi and Mehrbakhsh Nilashi and Mohammad Iranmanesh and Sunghyup Sean Hyun and Azadeh Rezvani},
keywords = {Adaptive neuro-fuzzy inference system, ANFIS, Decision-making trial and evaluation laboratory, DEMATEL, Internet of things, IoT, Manufacturing, Multi-criteria decision-making, Performance},
abstract = {We have entered a new technological paradigm with the emergence of Internet-embedded software and hardware, so-called the Internet of Things (IoT). Although IoT offers pan-industry business opportunities, most industries are only just beginning to employ it. We thus determine and prioritize the most important factors that influence IoT adoption, and reveal how IoT adoption affects the performance of manufacturing companies. We use a hybrid method that integrates the adaptive neuro-fuzzy inference system with the decision-making trial and evaluation laboratory, a novelty of the study. The literature on this subject informs our selection of the critical adoption factors, namely, technological, environmental, and organizational. The data are acquired from industrial managers involved in the decision-making process of information technology procurement in manufacturing companies in Malaysia. Our results can support IoT adoption guidelines geared to yield maximum efficiency in manufacturing industries, service providers, and governments.}
}
@article{YAN2020107370,
title = {Low-resolution facial expression recognition: A filter learning perspective},
journal = {Signal Processing},
volume = {169},
pages = {107370},
year = {2020},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2019.107370},
url = {https://www.sciencedirect.com/science/article/pii/S0165168419304232},
author = {Yan Yan and Zizhao Zhang and Si Chen and Hanzi Wang},
keywords = {Filter design, Subspace learning, Image representation, Low-resolution, Facial expression recognition},
abstract = {Automatic facial expression recognition has attracted increasing attention for a variety of applications. However, the problem of low-resolution generally causes the performance degradation of facial expression recognition methods under real-life environments. In this paper, we propose to perform low-resolution facial expression recognition from the filter learning perspective. More specifically, a novel image filter based subspace learning (IFSL) method is developed to derive an effective facial image representation. The proposed IFSL method mainly includes three steps: Firstly, we embed the image filter learning into the optimization process of linear discriminant analysis (LDA). By optimizing the cost function of LDA, a set of discriminative image filters (DIFs) corresponding to different facial expressions is learned. Secondly, the images filtered by the learned DIFs are added together to generate the combined images. Finally, a regression learning technique is leveraged for subspace learning, where an expression-aware transformation matrix is obtained using the combined images. Based on the transformation matrix, IFSL effectively removes irrelevant information while preserving useful information in the facial images. Experimental results on several facial expression datasets, including CK+, MMI, JAFFE, SFEW and RAF-DB, show the superior performance of the proposed IFSL method for low-resolution facial expression recognition, compared with several state-of-the-art methods.}
}
@article{JU2016882,
title = {Prototyping Business Models for IoT Service},
journal = {Procedia Computer Science},
volume = {91},
pages = {882-890},
year = {2016},
note = {Promoting Business Analytics and Quantitative Management of Technology: 4th International Conference on Information Technology and Quantitative Management (ITQM 2016)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.106},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916312911},
author = {Jaehyeon Ju and Mi-Seon Kim and Jae-Hyeon Ahn},
keywords = {Internet of Things, Business Model, IoT},
abstract = {The Internet of Things (IoT) generates new business opportunities by connecting physical objects with a multitude of sensors. IoT research mainly focused on technology and business models are relatively unexplored, although developing IoT business models is important for successful IoT service. The existing literature on IoT business models are industry or context-dependent. The aim of this research is to develop a generic business model framework for IoT business through literature analysis and interviews. To test the proposed business model framework, we undertake case studies of current IoT companies. The findings suggest that capability for data analytics is an essential element for IoT service. Also, open ecosystems help companies provide new integrated service and offer greater value for consumers. This research acts as a starting point for designing or developing business models for IoT services.}
}
@article{KOLONIARIS2019110431,
title = {Survey-based investigation, feature extraction and classification of Greek municipalities maturity for open source adoption and migration prospects},
journal = {Journal of Systems and Software},
volume = {158},
pages = {110431},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110431},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219302055},
author = {Stavros Koloniaris and George Kousiouris and Dimosthenis Anagnostopoulos and Mara Nikolaidou and Konstantinos Tserpes},
keywords = {FOSS, Migration, Classification, Survey, Risk analysis, Maturity models},
abstract = {While FOSS solutions have attracted a significant amount of attention, alongside with necessary and growing IT related expenditure for the digitalization of public administration, authorities face the question of whether migration to such solutions is feasible and/or worthwhile. The purpose of the presented work is to analyze existing domain research and extract key features, grouped in three major areas (namely Readiness, Ease of Use and Gain from migration), that should be investigated prior to a migration attempt. Following and building upon an extensive survey on Greek municipalities, the latter are categorized via the k-means non-supervised machine learning method to 3 levels of maturity regarding candidate participation in relevant projects. A combined scoring approach, based on similar features of the target FOSS solution as well as the aforementioned municipality categorization, is presented in order to detect a priori good candidate combinations (municipality and software) for minimizing a migration project risk. The method is validated through the aforementioned survey on municipalities with confirmed FOSS usage, indicating that selection in the proposed organized manner can aid in harvesting FOSS benefits. Furthermore, it is compared against a popular maturity model method (BPMMM) in order to comment on the applicability and classification process.}
}
@article{ZHANG2019209,
title = {Ontology-driven hierarchical sparse coding for large-scale image classification},
journal = {Neurocomputing},
volume = {360},
pages = {209-219},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.05.059},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219307659},
author = {Yan Zhang and Yanyun Qu and Cuihua Li and Yunqi Lei and Jianping Fan},
keywords = {Large-scale image classification, Deep features, Joint dictionary learning, Split Bregman Iteration, Hierarchical image classification},
abstract = {An ontology-driven hierarchical sparse representation is developed in this paper, which aims to support hierarchical learning for large scale image classification. Firstly, a two-layer ontology (semantic ontology and visual ontology) is built to organize large number of image classes hierarchically, where WordNet is used to construct semantic ontology and deep features extracted by Inception V3 are used to construct visual ontology (visual tree). Secondly, a novel algorithm based on Split Bregman Iteration is developed to learn hierarchical sparse representation, i.e., learning a shared dictionary and a set of class-specified dictionaries depending on the two-layer ontology. For multi-class image classification, a tree classifier is trained according to the two-layer ontology by using the hierarchical sparse representation. Thirdly, for a given test image, multiple paths are simultaneously evaluated to achieve optimal prediction of its class label. Our proposed approach has been evaluated over three benchmark datasets: ILSVRC2010, SUN397, and Caltech256, and the experimental results have demonstrated that our approach is better than the original joint dictionary learning method and can achieve better accuracy compared with other approaches which use handcrafted features.}
}
@article{SHI2021102564,
title = {EKGTF: A knowledge-enhanced model for optimizing social network-based meteorological briefings},
journal = {Information Processing & Management},
volume = {58},
number = {4},
pages = {102564},
year = {2021},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2021.102564},
url = {https://www.sciencedirect.com/science/article/pii/S0306457321000637},
author = {Kaize Shi and Yusen Wang and Hao Lu and Yifan Zhu and Zhendong Niu},
keywords = {Event knowledge guided text formalization model, Fine-tuned BERT model, Meteorological event knowledge, Meteorological briefing formalization service framework, Meteorological decision support platform},
abstract = {With the frequent occurrence of extreme natural phenomena, news about meteorological disasters has increased. As a timely and effective social sensor, social networks have gradually become an important data source for the perception of extreme meteorological events. Meteorological briefing refers to screening valuable knowledge from massive data to provide decision-makers with efficient situational awareness support. However, social network-based briefing content has challenges, including colloquialisms and informal text styles. How to optimize these data in a formal text style is of great significance to improve decision-making efficiency. This paper proposes a meteorological briefing formalization module composed of three models: the text form judgment model, the formalization words detection model, and the event knowledge guided text formalization (EKGTF) model. These models are concatenated to optimize the meteorological briefing, specifically formalizing the briefing content’s language style based on Sina Weibo data. As a knowledge-enhanced model, the EKGTF model focuses on describing the core meteorological event knowledge while formalizing the content. Compared to baseline models, the EKGTF model achieves the best results on the BLEU score. Based on the meteorological briefing formalization module, a meteorological briefing formalization service framework is constructed, which is to be applied to the China Meteorological Administration (CMA) Public Meteorological Service Center.}
}
@article{ZAHOOR2021921,
title = {Resource management in pervasive Internet of Things: A survey},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {33},
number = {8},
pages = {921-935},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2018.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S1319157818305858},
author = {Saniya Zahoor and Roohie Naaz Mir},
keywords = {Internet of Things, Data aggregation, Resource management, Fog computing, Body Area Networks},
abstract = {Internet of Things (IoT) embodies a vision of merging heterogeneous objects to establish seamless interaction among physical and virtual entities. IoT has given the Internet a shift from connecting networks to interconnecting the physical world. The IoT devices are capable of sensing, processing, communicating and storing the data acquired from the physical world. Most of the applications of IoT are pervasive in nature, the pervasive IoT environment poses many challenges due to constrained resources in these miniature and unattended IoT devices. This paper presents a survey of physical and virtual resource management in IoT systems. The main focus of the paper is on resource management in pervasive IoT environment with limited resources. This paper also presents a use case of IoT based Body Area Network and proposes a model for resource management in personal and community healthcare.}
}
@article{ZHANG2020107394,
title = {Video anomaly detection and localization using motion-field shape description and homogeneity testing},
journal = {Pattern Recognition},
volume = {105},
pages = {107394},
year = {2020},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107394},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320301977},
author = {Xinfeng Zhang and Su Yang and Jiulong Zhang and Weishan Zhang},
keywords = {Abnormal activity, Anomaly detection, Anomaly localization, Shape description, -NN similarity-based outlier detection},
abstract = {Detection and localization of abnormal behaviors in surveillance videos of crowded scenes is challenging, where high-density people and various objects performing highly unpredictable motions lead to severe occlusions, making object segmentation and tracking extremely difficult. We associate the optical flows between multiple frames to capture short-term trajectories and introduce the histogram-based shape descriptor to describe such short-term trajectories, which reflects faithfully the motion trend and details in local patches. Furthermore, we propose a method to detect anomalies over time and space by judging whether the similarities between the testing sample and the retrieved K-NN samples follow the pattern distribution of homogeneous intra-class similarities, which is unsupervised one-class learning requiring no clustering nor prior assumption. Such a scheme can adapt to the whole scene, since the probability is used to judge and the calculation of probability is not affected by motion distortions arising from perspective distortion, which gains advantage over the existing solutions. We conduct experiments on real-world surveillance videos, and the results demonstrate that the proposed method can reliably detect and locate the abnormal events in video sequences, outperforming the state-of-the-art approaches.}
}
@article{HUSSNAIN2020101451,
title = {A framework to bridge digital planning tools' utilization gap in peri-urban spatial planning; lessons from Pakistan},
journal = {Computers, Environment and Urban Systems},
volume = {80},
pages = {101451},
year = {2020},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2019.101451},
url = {https://www.sciencedirect.com/science/article/pii/S0198971519301759},
author = {Muhammad Qadeer ul Hussnain and Abdul Waheed and Ghulam Abbas Anjum and Malik Asghar Naeem and Ejaz Hussain and Khydija Wakil and Christopher James Pettit},
keywords = {Peri-urban plan, Spatial planning, GIS, Planning support systems},
abstract = {As cities grow, the continued development pressure and land-use change of peri-urban areas pose a key challenge for urban planners to address. In the planning of peri-urban areas, the complexity of intertwining physical, environmental, transportation, social and institutional planning dimensions, rapidness of change, demand for precision, and subjectivity of the situations; application of digital planning tools (GIS, PSS and similar) offers a result-oriented and at times the only way out for realistic planning. Like many other countries, peri-urban growth in Pakistan is being managed by the preparation of Peri-Urban Structure Plans (PUSPs). Since, 2009, such plans have been prepared for 36 urban centres of various scale which offer a considerable size to explore the usage pattern of digital planning tools in real-world practice and learn the lessons. Despite wider development and adoption of geographic information systems (GIS) based planning support system (PSS) in spatial planning all over the world, the utilization of digital planning tools in Pakistan to support planning practise has been very limited. This research adopts a case study-based methodology to review the legal requirements of peri-urban plan-making and highlight tasks where digital planning tools can add value. It investigates why there is a paucity of up taking digital planning tools in the spatial plan preparation and documents key stumbling factors. To understand the user's perspective, a survey of (n = 108) urban planners has been undertaken using an online questionnaire. The survey assesses their understanding of the terms and their perception behind the current utilization level of digital planning tools for plan preparation. The analysis reveals a very low familiarity of urban planners with digital planning tools, particularly planning support systems, in Pakistan which is aligned with the findings from technologically advanced countries. The causes behind low utilization have been documented and grouped under three dimensions, adopted from previous research including ‘user acceptance’, ‘instrument quality’ and ‘diffusion’. Finally, the paper concludes by proposing a framework for bridging the utilization gap to improve spatial planning practice.}
}
@article{BHARDWAJ201913,
title = {Cyber security attacks on robotic platforms},
journal = {Network Security},
volume = {2019},
number = {10},
pages = {13-19},
year = {2019},
issn = {1353-4858},
doi = {https://doi.org/10.1016/S1353-4858(19)30122-9},
url = {https://www.sciencedirect.com/science/article/pii/S1353485819301229},
author = {Akashdeep Bhardwaj and Vinay Avasthi and Sam Goundar},
abstract = {Robotic technology has been rapidly transforming world economies in terms of business productivity and profitability. The market is shifting towards optimisation and automation – not just for the warehousing and manufacturing sectors, but even non-industrial areas such as defence, farming, hospitals, offices and even schools. The availability of open source platforms, falling hardware and electronics prices, prompt prototyping and convergence of technologies are some of the major reasons for this new revolution. However, cyber security and physical threats are high-priority areas when critical applications and missions are involved. Robotic technology has been rapidly transforming world economies in terms of business productivity and profitability. However, security threats are not always top of mind. Open source platforms, falling hardware and electronics prices and fast prototyping are some of the reasons for this new revolution. Cyber security and physical threats are high-priority areas when critical applications and missions are involved. Dr Akashdeep Bhardwaj, Dr Vinay Avasthi and Dr Sam Goundar analyse the threats to robotic systems and map the CIA model to boost security resilience.}
}
@article{MARINAKIS201898,
title = {Cyborged ecosystems: Scenario planning and Participatory Technology Assessment of a potentially Rosennean-complex technology},
journal = {Ecological Complexity},
volume = {35},
pages = {98-105},
year = {2018},
note = {Rosennean Complexity},
issn = {1476-945X},
doi = {https://doi.org/10.1016/j.ecocom.2017.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1476945X17300879},
author = {Yorgos Marinakis and Rainer Harms and Bruce T. Milne and Steven T. Walsh},
keywords = {Cyborged ecosystem, Participatory Technology Assessment, Rosennean complexity, Scenario planning},
abstract = {Public involvement in technology policy making is particularly relevant because technological development is now reaching into virtually all planetary systems. The advent of Genetically Modified Organisms (GMO) for human food is particularly controversial, and it also raises questions about related technological-based potential products such as cyborged organisms in general. The research question in the present study is, what are the results of a Participatory Technology Assessment of cyborged ecosystems? The method utilized is Participatory Technology Assessment, implemented through scenario planning. The result of the study was three core themes: superfluous technology, dangerous tampering, and potential public health consequences. Resonances were observed between answers by laypersons and experts, indicating that they recognized the same issues but expressed themselves using different vocabularies and with different levels or types of understanding. Criteria are needed to ensure the public is able to engage in policy decisions that involve Rosennean-complex technologies.}
}
@article{BABUTA2021108961,
title = {Power and energy measurement devices: A review, comparison, discussion, and the future of research},
journal = {Measurement},
volume = {172},
pages = {108961},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2020.108961},
url = {https://www.sciencedirect.com/science/article/pii/S0263224120314354},
author = {Aniket Babuta and Bhavna Gupta and Abhimanyu Kumar and Souvik Ganguli},
keywords = {Wattmeter, Energy meter, Smart meter, Energy theft, Internet of Energy (IoE)},
abstract = {This paper presents a detailed survey on power and energy measurement devices capturing the overall progress over the decades in the associated field of instrumentation. The working principle of several devices along with their applications and advantages/disadvantages are provided in this review work. The implementation of wattmeter in a single-phase system along with three-phase system is also given. An appropriate apparatus is extremely important for proper evaluation of power transfer and energy consumption within a network. The development of energy measurement instruments from simple machines to complex computational structures with data transmission and processing ability is also discussed. A thorough description of smart meters and the internet of energy (IoE) follows thereafter. Finally, the future of the power sector in view of the present technology and the current situation of energy theft is also provided. This paper not only presents information but also indicates future direction for inquisitive researchers.}
}
@article{ROCHA2020101972,
title = {Functionality-based mobile application recommendation system with security and privacy awareness},
journal = {Computers & Security},
volume = {97},
pages = {101972},
year = {2020},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2020.101972},
url = {https://www.sciencedirect.com/science/article/pii/S0167404820302455},
author = {Thiago Rocha and Eduardo Souto and Khalil El-Khatib},
keywords = {Security, Privacy, Recommendation, Malware, Android},
abstract = {Nowadays, there are a variety of mobile device applications to execute tasks, such as paying bills and ordering food. However, some apps (malicious) claim that they perform a certain task just to lure users to damage their devices and/or execute malicious activities such as leaking sensitive information. Because of that, users need a way to choose an app that is safe and meets their needs. Recommendation systems are currently being used to choose apps, but most approaches do not evaluate security and privacy, and when they do, only permissions are considered. In this context, this work presents a novel system to evaluate and suggest apps. The main contributions are the addition of a security layer, the evaluation of the metrics inside a functionality context and a mapping between permissions and API calls raising user confidence and understanding.}
}
@article{ZHUO202018,
title = {An online and generalized non-negativity constrained model for large-scale sparse tensor estimation on multi-GPU},
journal = {Neurocomputing},
volume = {399},
pages = {18-36},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.02.068},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220302587},
author = {Linlin Zhuo and Kenli Li and Hao Li and Jiwu Peng and Keqin Li},
keywords = {Canonical polyadic decomposition, Generalized model, GPU and multi-GPU, High-dimension and sparse data, Single-thread-based model, Sparse non-negative tensor factorization, Online learning, Stream-like data merging},
abstract = {Non-negative Tensor Factorization (NTF) models are effective and efficient in extracting useful knowledge from various types of probabilistic distribution with multi-way information. Current NTF models are mostly designed for problems in computer vision which involve the whole Matricized Tensor Times Khatri−Rao Product (MTTKRP). Meanwhile, a Sparse NTF (SNTF) proposed to solve the problem of sparse Tensor Factorization (TF) can result in large-scale intermediate data. A Single-thread-based SNTF (SSNTF) model is proposed to solve the problem of non-linear computing and memory overhead caused by large-scale intermediate data. However, the SSNTF is not a generalized model. Furthermore, the above methods cannot describe the stream-like data from industrial applications in mainstream processors, e.g, Graphics Processing Unit (GPU) and multi-GPU in an online way. To address these two issues, a Generalized SSNTF (GSSNTF) is proposed, which extends the works of SSNTF to the Euclidean distance, KullbackLeibler (KL)-divergence, and ItakuraSaito (IS)-divergence. The GSSNTF only involves the feature elements instead of the entire factor matrices during its update process, which can avoid the formation of large-scale intermediate matrices with convergence and accuracy promises. Furthermore, GSSNTF can merge the new data into the state-of-the-art built tree dataset for sparse tensor, and then online learning has the promise of the correct data format. At last, a model of Compute Unified Device Architecture (CUDA) parallelizing GSSNTF (CUGSSNTF) is proposed on GPU and Multi-GPU (MCUGSSNTF). Thus, CUGSSNTF has linear computing complexity and space requirement, and linear communication overhead on multi-GPU. CUGSSNTF and MCUGSSNTF are implemented on 8 P100 GPUs in this work, and the experimental results from real-world industrial data sets indicate the linear scalability and 40X speedup performances of CUGSSNTF than the state-of-the-art parallelized approachs.}
}
@article{ZAVALA2020607,
title = {HAFLoop: An architecture for supporting Highly Adaptive Feedback Loops in self-adaptive systems},
journal = {Future Generation Computer Systems},
volume = {105},
pages = {607-630},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.12.026},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19318448},
author = {Edith Zavala and Xavier Franch and Jordi Marco and Christian Berger},
keywords = {Self-adaptive system, Smart vehicle, IoT system, Adaptive monitoring, Adaptive feedback loop, Self-improvement},
abstract = {Most of the current self-adaptive systems (SASs) rely on static feedback loops such as the IBM’s MAPE-K loop for managing their adaptation process. Static loops do not allow SASs to react to runtime events such as changing adaptation requirements or MAPE-K elements’ faults. In order to address this issue, some solutions have emerged for manually or automatically perform changes on SASs’ feedback loops. However, from the software engineering perspective, most of the proposals cannot be reused or extended by other SASs. In this paper, we present HAFLoop (Highly Adaptive Feedback control Loop), a generic architectural proposal that aims at easing and fastening the design and implementation of adaptive feedback loops in modern SASs. Our solution enables both structural and parameter adaptation of the loop elements. Moreover, it provides a highly modular design that allows SASs’ owners to support a variety of feedback loop settings from centralized to fully decentralized. In this work, HAFLoop has been implemented as a framework for Java-based systems and evaluated in two emerging software application domains: self-driving vehicles and IoT networks. Results demonstrate that our proposal easies and accelerates the development of adaptive feedback loops as well as how it could help to address some of the most relevant challenges of self-driving vehicles and IoT applications. Concretely, HAFLoop has demonstrated to improve SASs’ feedback loops’ runtime availability and operation.}
}
@article{SHEIBANI2022101525,
title = {A lightweight distributed detection algorithm for DDAO attack on RPL routing protocol in Internet of Things},
journal = {Pervasive and Mobile Computing},
volume = {80},
pages = {101525},
year = {2022},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2021.101525},
url = {https://www.sciencedirect.com/science/article/pii/S1574119221001450},
author = {Mohsen Sheibani and Behrang Barekatain and Erfan Arvan},
keywords = {DDAO attack, Internet of Things (ioT), Intrusion Detection System (IDS), RPL},
abstract = {A significant increase in the number of connected devices in the Internet of Things poses a key challenge to efficiently handling the attacks in routing protocols such as Routing Protocol for Low Power and Lossy Networks (RPL). The attacks on RPL are partly studied in the literature, and the proposed solutions typically overlook the appropriate trade-off among the detection rate and communication and computational overhead. This study aimed at introducing a new attack called Dropped Destination Advertisement Object (DDAO) and a new Intrusion Detection System (IDS) to counter this attack in RPL protocol. DDAO attack adversely affects the network by preventing the creation of the downward routes through not forwarding Destination Advertisement Object (DAO) messages and sending fake Destination Advertisement Object Acknowledgment (DAO-ACK) messages to the DAO source. A distributed lightweight IDS is proposed in this study to detect and counter DDAO attacks by monitoring the behavior of parents against forwarded DAO messages. According to the evaluations conducted on the Cooja simulator under different real-world conditions, the proposed IDS can detect DDAO attacks with high accuracy, precision, and True Positive Rate (TPR) and low False Positive Rate (i.e., close to zero). Additionally, compared to RPL, the proposed IDS improves Packet Delivery Rate (PDR) by 158 percent when countering attacks.}
}
@article{YU20213678,
title = {Stochastic control and time scheduling for irregular robots},
journal = {Journal of the Franklin Institute},
volume = {358},
number = {7},
pages = {3678-3700},
year = {2021},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2021.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0016003221001691},
author = {Hongjun Yu and Yutong Liu and Lihua Liang},
abstract = {Vehicles of different sizes are difficult to navigate in close vicinity. In this paper, we propose multi-vehicle coordination strategy by stochastic control and time scheduling to guarantee no collisions. We use contours and relative motions of vehicles to calculate collision time and use it in multi-vehicle scheduling and reduce computation burden. The proposed strategy enables the vehicles to add calculation delay when vehicles are moving towards the destinations. To avoid complicated control rule design for motion-restricted irregular vehicles, we propose stochastic control to provide satisfactory performance. By changing the frequency of control update, a modification is proposed to take congestion into account. Simulation examples are given to demonstrate the effectiveness of the proposed approach.}
}
@article{MOHAMADNOOR2019283,
title = {Current research on Internet of Things (IoT) security: A survey},
journal = {Computer Networks},
volume = {148},
pages = {283-294},
year = {2019},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.11.025},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618307035},
author = {Mardiana binti {Mohamad Noor} and Wan Haslina Hassan},
keywords = {IoT security, Challenges, Current research, Simulation},
abstract = {The results of IoT failures can be severe, therefore, the study and research in security issues in the IoT is of extreme significance. The main objective of IoT security is to preserve privacy, confidentiality, ensure the security of the users, infrastructures, data, and devices of the IoT, and guarantee the availability of the services offered by an IoT ecosystem. Thus, research in IoT security has recently been gaining much momentum with the help of the available simulation tools, modellers, and computational and analysis platforms. This paper presents an analysis of recent research in IoT security from 2016 to 2018, its trends and open issues. The main contribution of this paper is to provide an overview of the current state of IoT security research, the relevant tools,IoT modellers and simulators.}
}
@article{CHEN2021107952,
title = {An adaptive trust model based on recommendation filtering algorithm for the Internet of Things systems},
journal = {Computer Networks},
volume = {190},
pages = {107952},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.107952},
url = {https://www.sciencedirect.com/science/article/pii/S138912862100089X},
author = {Guozhu Chen and Fanping Zeng and Jian Zhang and Tingting Lu and Jingfei Shen and Wenjuan Shu},
keywords = {Internet of Things, Trust model},
abstract = {The Internet of Things (IoT) is growing rapidly and brings great convenience to humans. But it also causes some security issues which may have negative impacts on humans. Trust management is an effective method to solve these problems by establishing trust relationships among interconnected IoT objects. In this paper, we propose an adaptive trust model based on recommendation filtering algorithm for the IoT systems. The utilization of sliding window and time decay function when calculating direct trust can greatly accelerate the convergence rate of trust evaluation. We design a recommendation filtering algorithm to effectively filter out bad recommendations and minimize the impact of malicious objects. An adaptive weight is developed to better combine direct trust and recommendation trust into synthesis trust so as to adapt to the dynamically hostile environment. In the simulation experiments, we compare our adaptive trust model with three related models: TBSM, NRB and NTM. The experimental results indicate that our trust model converges fast and the mean absolute error is always less than 0.05 when the proportion of malicious nodes is from 10% to 70%. The comparative experiments further verify the effectiveness of our trust model in terms of accuracy, convergence rate and resistance to trust related attacks.}
}
@article{SHARMA2020536,
title = {Musical Instrument Sound Signal Separation from Mixture using DWT and Fast ICA Based Algorithm in Noisy Environment},
journal = {Materials Today: Proceedings},
volume = {29},
pages = {536-547},
year = {2020},
note = {National Conference on Smart Materials: Energy and Environment for Smart Cities, NSES-2018, 28th February 2018, Gwalior, India},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2020.07.310},
url = {https://www.sciencedirect.com/science/article/pii/S2214785320354031},
author = {Raghavendra Sharma},
keywords = {additive white Gaussian noise, fast ICA, DWT, blind signal separation, wavelet coefficients},
abstract = {The structured arrangement of sounds in musical pieces, results in the unique creation of complex acoustic mixtures. The analysis of these mixtures, with the objective of estimating the individual sounds which constitute them, is known as musical instrument sound signal separation, and has applications in audio coding, audio restoration, music production, music information retrieval and music education. In this paper, the problem of sound signal separation from the mixture in the presence of additive white Gaussian noise (AWGN) is investigated. Because of the additive noise independent component analysis (ICA) algorithm does not give a consistent estimation of separated signals. The different sound signals are first down sampled and then mixed with the help of mixing matrix found iteratively. The mixed signal is added with variable percentage of AWGN. Resulting noisy mixed signal is further denoised with block denoising algorithm, and then decomposed into wavelet coefficients with DWT. Fast ICA algorithm is further applied on these wavelet coefficients for identification of individual sound signal, and then IDWT is used to reconstruct the separated sound signals. The hearing perception of the separated sound signals is close to the original signals}
}
@article{COLOM2017385,
title = {Collaborative building of behavioural models based on internet of things},
journal = {Computers & Electrical Engineering},
volume = {58},
pages = {385-396},
year = {2017},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2016.08.019},
url = {https://www.sciencedirect.com/science/article/pii/S0045790616302191},
author = {José Francisco Colom and Higinio Mora and David Gil and María Teresa Signes-Pont},
keywords = {Social internet of things, Big data, Embedded systems, Healthcare, Distributed system framework},
abstract = {This paper proposes a new framework that takes advantage of the computing capabilities provided by the Internet of Thing (IoT) paradigm in order to support collaborative applications. It looks at the requirements needed to run a wide range of computing tasks on a set of devices in the user environment with limited computing resources. This approach contributes to building the social dimension of the IoT by enabling the addition of computing resources accessible to the user without harming the other activities for which the IoT devices are intended. The framework mainly includes a model of the computing load, a scheduling mechanism and a handover procedure for transferring tasks between available devices. The experiments show the feasibility of the approach and compare different implementation alternatives.}
}
@article{KETU2021103179,
title = {Internet of Healthcare Things: A contemporary survey},
journal = {Journal of Network and Computer Applications},
volume = {192},
pages = {103179},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103179},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521001892},
author = {Shwet Ketu and Pramod Kumar Mishra},
keywords = {Internet of healthcare things (IoHT), Internet of things (IoT), Healthcare system, Sensors, Issues and challenges, Security, Services and applications, Smart healthcare, Wireless sensor network (WSN), Industry trends and status},
abstract = {Internet of Things (IoT) is one of the emerging technologies, which is expanding its wings day by day. Smart objects in the IoT system are the ultimate building blocks used in the development process of IoT-based smart pervasive frameworks. Healthcare is one of the essential and well-known application domains of IoT technology. IoT is giving a new shape to the modern healthcare system, which is defined as the Internet of Healthcare Things (IoHT) with proficient technological, social, and economical prospects. In this paper, we have reviewed various advances in the Internet of Healthcare Things (IoHT) technologies such as topologies, platforms/architectures, taxonomies, services and applications, industry trends, and the status of IoHT-based solutions. This paper also investigates various issues related to IoHT privacy and security structures from the perspective of smart healthcare, including security challenges, security requirements, and taxonomy of attacks. Further, this paper explores future research's direction by addressing issues and challenges of the Internet of Healthcare Things (IoHT) based solutions. It also addresses various IoT-based health policies and regulations worldwide for determining the social and economic impact of sustainable growth.}
}
@article{WANG201942,
title = {Data fusion in cyber-physical-social systems: State-of-the-art and perspectives},
journal = {Information Fusion},
volume = {51},
pages = {42-57},
year = {2019},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2018.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S1566253518301507},
author = {Puming Wang and Laurence T. Yang and Jintao Li and Jinjun Chen and Shangqing Hu},
keywords = {CPSS, Data fusion, Data fusion framework design, Tensor},
abstract = {Cyber-Physical-Social systems (CPSSs) are the extension of Cyber-Physical systems (CPS), which seamlessly integrate cyber space, physical space and social space. CPSSs promote the information resource from single space to tri-space, so as to lead a revolution in data science (DS). This paper aims to provide a comprehensive review of data fusion in CPSSs for readers. We firstly analyze data collection and representation in CPSS and propose to use tensors to represent CPSS data, then a general definition of CPSS data fusion is proposed to clarify the concept of information fusion in CPSS. After that, some representative data fusion methods related to CPSS are reviewed. Furthermore, we propose a series of tensor based data fusion methods for CPSS data. Also, we review the design of data fusion frameworks and propose a comprehensive data fusion framework for CPSS. Some challenges and future works are discussed as well.}
}
@article{NEIJ2021128348,
title = {Municipal climate mitigation policy and policy learning - A review},
journal = {Journal of Cleaner Production},
volume = {317},
pages = {128348},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.128348},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621025622},
author = {Lena Neij and Eva Heiskanen},
keywords = {Review, Climate mitigation, Urban policy, Urban governance, Policy learning},
abstract = {Cities are expected to contribute to climate mitigation by providing effective climate policy actions in a multilevel governance context. Yet, it is unclear what we actually know about the strengths and weaknesses of urban climate policy measures and how municipal policy learning could be enhanced. In this article we present a comprehensive review on cities’ experience in climate mitigation policy and policy learning, focusing on research published in journal articles. We provide observations from the literature on municipal experience in policy practice and on how local governments manage learning in urban mitigation policy. The review provides valuable examples and reflections on individual policy initiatives, both in terms of policy framing and policy instruments, but finds sporadic evidence on systematically successful policy learning and capacity building processes in the scientific literature. The number of scientific articles on empirical assessments of local policy learning are few, and the research found, published in numerous journals, potentially addressing different research communities, provides limited knowledge on policy learning in terms of lessons learned, lessons drawing and capacity building. Moreover, the literature builds mostly on case studies within particular institutional contexts, which makes the transferability of findings problematic. While evidence on policy learning is still limited, there are indications that under the right conditions, cities can “learn to learn”.}
}
@article{ZHANG2020103117,
title = {Neutrosophic fusion of rough set theory: An overview},
journal = {Computers in Industry},
volume = {115},
pages = {103117},
year = {2020},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2019.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0166361519300090},
author = {Chao Zhang and Deyu Li and Xiangping Kang and Dong Song and Arun Kumar Sangaiah and Said Broumi},
keywords = {Neutrosophic fusion, Rough set theory, Rough neutrosophic sets, Neutrosophic rough sets, Bibliometric overview},
abstract = {Neutrosophic sets (NSs) and logic are one of the influential mathematical tools to manage various uncertainties. Among diverse models for analyzing neutrosophic information, rough set theory (RST) provides an effective way in the field of neutrosophic information analysis, and a multitude of scholars have focused on neutrosophic fusion of RST in recent years. At present, there are not comprehensive literature reviews and statistics of these generalized rough set theories and applications. This review study first explores a summarization of current neutrosophic fusion of RST from five basic aspects, i.e., rough neutrosophic sets (RNSs) and neutrosophic rough sets (NRSs), soft rough neutrosophic sets (SRNSs) and neutrosophic soft rough sets (NSRSs), mathematical foundations of RNSs and NRSs, RNSs and NRSs-based decision making, RNSs and NRSs-based other applications. Then, on the basis of the overview from five fundamental perspectives, a systematic bibliometric overview of current works with respect to neutrosophic fusion of RST is further conducted. Finally, in light of the results of this review, different challenging issues related to the main topics are listed, which are beneficial to future studies of NSs and logic.}
}
@article{MOCNEJ2018168,
title = {Decentralised IoT Architecture for Efficient Resources Utilisation},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {6},
pages = {168-173},
year = {2018},
note = {15th IFAC Conference on Programmable Devices and Embedded Systems PDeS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.07.148},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318308942},
author = {Jozef Mocnej and Winston K.G. Seah and Adrian Pekar and Iveta Zolotova},
keywords = {Internet of Things, decentralised architecture, resource utilisation, efficiency, optimisation},
abstract = {The exponentially growing number of devices connected to the Internet, the diversity of the Internet of Things (IoT), and the variety of IoT protocol stacks yield to concerns about IoT sustainability. A promising solution is in IoT integration platforms which can address challenges such as interoperability, scalability and adaptability surrounding IoT. Current implementations of IoT platforms are based on centralised architectures, yet a decentralised IoT architecture with logic moved to the (network) edge can offer several benefits to IoT platforms and devices. This paper identifies the feature set that a decentralised IoT platform should have. Based on the determined features, a general decentralised IoT architecture is proposed for efficient resource utilisation.}
}
@article{TREVISAN2020107289,
title = {ERRANT: Realistic emulation of radio access networks},
journal = {Computer Networks},
volume = {176},
pages = {107289},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107289},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620301420},
author = {Martino Trevisan and Ali {Safari Khatouni} and Danilo Giordano},
keywords = {Mobile networks, Network emulation, Data-driven, Realistic},
abstract = {Mobile devices drastically changed how people use the Internet. We use smartphones to access a heterogeneous catalog of web services such as news, social networks, audio/video streaming. Differently from wired connections, mobile networks do not offer the same kind of performance stability yet. Thus, service providers have to handle different network scenarios, e.g., 3G or 4G, while promising good end-users’ quality of experience (QoE). To ensure that QoE is adequate, it is necessary to thoroughly test applications with a wide range of possible network conditions. For this, network emulation is of vital importance as it allows a tester to run experiments with a wide range of network conditions. However, when it comes to mobile networks, the variety of technical characteristics, coupled with the opaque network configurations, makes realistic emulation a challenging task. Most of the freely available emulation tools rely on a simple emulation, offering limited variability performances for each network condition. In this paper, we propose ERRANT, EmulatoR of Radio Access NeTworks, an open-source tool that emulates mobile networks with a high level of realism, following a data-driven approach. We use a large-scale dataset composed of 100 k speed test measurements collected from 4 network operators in 2 countries. We create 32 different network profiles based on different countries, operators, radio access technologies, and signal qualities. For each profile, we obtain both typical behavior and variability for latency, download and upload bandwidth. We use the profiles to create models by means of the Kernel Density Estimation. Then, ERRANT employs the tc-netem Linux tool and the models for emulation. In this way, ERRANT offers realistic network emulation, in which both typical behavior and network variability are accurately recreated. We validate ERRANT models with an independent dataset of HTTP downloads performed on the same mobile networks as of the profiles. Results show the effectiveness of ERRANT in the emulation of real mobile networks in terms of average behavior and obtained variability. We also show the limitations of a simple emulation, and of other freeware approaches versus ERRANT. Finally, we show two practical use cases to demonstrate the benefits of a dynamic emulation in understanding the performance of web browsing and video streaming. To run new measurement campaigns and create new models, we provide guidelines along with the required open-source code.}
}
@article{LI20201106,
title = {Heterogeneity-aware elastic provisioning in cloud-assisted edge computing systems},
journal = {Future Generation Computer Systems},
volume = {112},
pages = {1106-1121},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.06.022},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20300339},
author = {Chunlin Li and Jingpan Bai and Yuan Ge and Youlong Luo},
keywords = {Heterogeneity-aware, Elastic provisioning, Cloud-assisted edge computing systems},
abstract = {Edge computing is the provision of cloud services and IT environment services to application developers and service providers on the edge of the network. Edge computing faces some challenges, such as dealing with randomly varying workloads, which is an important issue. Thus, a cloud-assisted edge computing system (CAECS) is studied. A replica placement strategy is proposed to satisfy the diversity of user demands and reduce the response time. A data migration strategy is proposed to guarantee data reliability if there exist the released instances. A heterogeneity-aware elastic provisioning strategy is proposed to rent the cloud instances. Finally, the performance of the proposed algorithms is evaluated via extensive experiments. The results imply that the total tenanted cost of the heterogeneity-aware elastic provisioning algorithm can averagely achieve up to 19.23% and 9.50% reduction over that of ARP algorithm and MADRP algorithm, respectively.}
}
@article{JIANG2018132,
title = {Urban pluvial flooding and stormwater management: A contemporary review of China’s challenges and “sponge cities” strategy},
journal = {Environmental Science & Policy},
volume = {80},
pages = {132-143},
year = {2018},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2017.11.016},
url = {https://www.sciencedirect.com/science/article/pii/S1462901117306123},
author = {Yong Jiang and Chris Zevenbergen and Yongchi Ma},
keywords = {Urban pluvial flooding, China, Stormwater management, Urban planning, Governance, Low impact development},
abstract = {In recent years, urban pluvial flooding caused by extreme rainfall has increasingly occurred across China. This paper reviews the challenges faced by China in addressing urban pluvial flooding and managing urban stormwater, with a particular focus on a policy initiative termed sponge cities. The paper first synthetically presents pluvial flood disasters in urbanized areas, and analyses their causes and formation mechanisms. It then introduces China’s sponge cities initiative and discusses policy implementation in relation to contemporary understanding of sustainable urban stormwater management and international experience with innovative practices. The initiative, while theoretically well grounded and appropriate by its design principles, is shown subject to diverse implementation challenges, ranging from technological complexity to limited or lack of governance capacity as reflected in management ideology, knowledge and capacity of learning, participatory and integrated governance, investment financing, implementation pathway, planning and organization, and project evaluation. The paper offers some strategies for addressing those challenges, which include: 1) continuous experiment-based deep learning through pilot and institutionalization of knowledge and information management with city-to-city peering learning mechanisms, 2) establishment of institutional mechanisms dedicated to participatory, coordinated and integrated governance of the policy initiative, 3) increased government role in creating favorable conditions for investments, and 4) appropriate planning and an adaptive approach to policy implementation. The paper concludes that the sponge cities initiative can be an effective approach only if China commits to appropriate technical, governance, financial, and organizational measures to effectively address the challenges for policy implementation.}
}
@article{POPKOVA2022101831,
title = {A theory of digital technology advancement to address the grand challenges of sustainable development},
journal = {Technology in Society},
volume = {68},
pages = {101831},
year = {2022},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101831},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21003067},
author = {Elena G. Popkova and Paola {De Bernardi} and Yuliya G. Tyurina and Bruno S. Sergi},
keywords = {Developed countries, Developing countries, Digital technologies, Economic development policy, Grand challenges, Sustainable growth},
abstract = {Scholarly research has not yet discussed the totality of the 17 sustainable development goals (SDGs) as part of a broader picture of sustainable development. This paper provides a unique analysis of the linkages between institutions, SDGs and digital technologies to establish their exact interdependencies. Factor analysis of the grand challenges of sustainable development has shown only SDG3 and SDG17 might progress through institutions’ development in developed countries, while only SDG16 in developing countries. In developed countries, the institutions of human development, globalisation and innovations influence SDG3, and SDG17, which depend on digitised knowledge and the application of digital technologies. Human development and economic freedom, which rely on digital infrastructure and technologies, impacted SDG16 in developing countries. The digital knowledge index and the digital technologies index in developed countries enhance management efficiency, having a maximum impact on SDG3 and SDG17. The findings of this paper contribute to social and economic policy implications on digital technology development for addressing grand challenges.}
}
@article{HAMILTON202085,
title = {The questions we ask: Opportunities and challenges for using big data analytics to strategically manage human capital resources},
journal = {Business Horizons},
volume = {63},
number = {1},
pages = {85-95},
year = {2020},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2019.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0007681319301466},
author = {R.H. Hamilton and William A. Sodeman},
keywords = {Big data analytics, Workforce analytics, Stakeholder management, Strategic human capital, Knowledge stars, Human resource management},
abstract = {Big data analytics have transformed research in many fields, including the business areas of marketing, accounting and finance, and supply chain management. Yet, the discussion surrounding big data analytics in human resource management has primarily focused on job candidate screenings. In this article, we consider how significant strategic human capital questions can be addressed with big data analytics, enabling HR to enhance overall firm performance. We also examine how new data sources that help assess workforce performance in real time can assist in the identification and development of the knowledge stars that contribute to firm performance disproportionately as well as help reinforce firm capabilities. But in order for big data analytics to be successful in the HR field, regulatory and ethical challenges must also be addressed; these include privacy concerns and, in Europe, the General Data Protection Regulation (GDPR). We conclude by discussing how big data analytics can facilitate strategic change within HR and the organization as a whole.}
}
@article{BU2018675,
title = {An efficient fuzzy c-means approach based on canonical polyadic decomposition for clustering big data in IoT},
journal = {Future Generation Computer Systems},
volume = {88},
pages = {675-682},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.04.045},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18306472},
author = {Fanyu Bu},
keywords = {Big data, Internet of Things, Smart data, Fuzzy c-means algorithm, Canonical polyadic decomposition},
abstract = {Mining smart data from the collected big data in Internet of Things which attempts to better human life by integrating physical devices into the information space. As one of the most important clustering techniques for drilling smart data, the fuzzy c-means algorithm (FCM) assigns each object to multiple groups by calculating a membership matrix. However, each big data object has a large number of attributes, posing an remarkable challenge on FCM for IoT big data real-time clustering. In this paper, we propose an efficient fuzzy c-means approach based on the tensor canonical polyadic decomposition for clustering big data in Internet of Things. In the presented scheme, the traditional fuzzy c-means algorithm is converted to the high-order tensor fuzzy c-means algorithm (HOFCM) via a bijection function. Furthermore, the tensor canonical polyadic decomposition is utilized to reduce the attributes of every objects for enhancing the clustering efficiency. Finally, the extensive experiments are conducted to compare the developed scheme with the traditional fuzzy c-means algorithm on two large IoT datasets including sWSN and eGSAD regarding clustering accuracy and clustering efficiency. The results argue that the developed scheme achieves a significantly higher clustering efficiency with a slight clustering accuracy drop compared with the traditional algorithm, indicating the potential of the developed scheme for drilling smart data from IoT big data.}
}
@article{CHEN201847,
title = {Graph regularized local self-representation for missing value imputation with applications to on-road traffic sensor data},
journal = {Neurocomputing},
volume = {303},
pages = {47-59},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.04.029},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218304570},
author = {Xiaobo Chen and Yingfeng Cai and Qiaolin Ye and Lei Chen and Zuoyong Li},
keywords = {Graph regularization, Local constraint, Matrix completion, Missing values, Traffic sensor data},
abstract = {Recovering missing values (MVs) from incomplete data is an important problem for many real-world applications. Previous research efforts toward solving MVs problem primarily exploit the global and/or local structure of data. In this work, we propose a novel MVs imputation method by combing sample self-representation strategy and underlying local linear structure of data in a uniformed framework. Specifically, the proposed method consists of the following steps. First, an existing method is applied to obtain the first-round estimation of MVs. Then, a graph, characterizing local proximity structure of data, is constructed based on imputed data. Next, a novel model coined as graph regularized local self-representation (GRLSR) is proposed by integrating two crucial elements: local self-representation and graph regularization. The former assumes each sample can be well represented (reconstructed) by linearly combining the neighboring samples while the latter further requires the neighboring samples should not deviate too much from each other after reconstruction. By doing so, MVs can be more accurately restored due to the joint imputation as well as local linear reconstruction. We also develop an effective alternating optimization algorithm to solve GRLSR model, thereby achieving final imputation. The convergence and computational complexity analysis of our method are also presented. To evaluate our method, extensive experiments are conducted on both traffic flow dataset and UCI benchmark datasets. The results demonstrate the effectiveness of our proposed method compared with a set of widely-used competing methods.}
}
@article{SAWALHA2021,
title = {Towards an efficient big data management schema for IoT},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821002640},
author = {Samer Sawalha and Ghazi Al-Naymat},
keywords = {Internet of Things, IoT challenges, Sensors, Big data, Database schema},
abstract = {Internet of things (IoT) is an essential technology in our life; the importance of IoT is yearly increasing because of the excellent usage value. IoT management can help stakeholders in analyzing and making the right decisions based on previous historical sensed data. However, some challenges emerge while using the IoT that will be more complicated in the future. Data management is one of the significant challenges that is facing IoT technology. The growth of the number of sensors will increase the generated data (Big Data). In a few years, the problem of analyzing, processing, and storing such data will become a highly complex process. Due to the mentioned challenges, in this paper, we propose a new schema to efficiently store the structured IoT data to improve the performance of analyzing and retrieving the data. The main idea about the proposed schema is performed in the data preprocessing step by grouping the data into different levels without losing any single value (lossless compression). We evaluate our proposed schema using eight other datasets in terms of storage size and processing time; our results show that the proposed schema outperforms the traditional storing method for all datasets.}
}
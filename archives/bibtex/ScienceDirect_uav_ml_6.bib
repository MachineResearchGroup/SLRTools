@article{SINGH2018883,
title = {Deep Learning for Plant Stress Phenotyping: Trends and Future Perspectives},
journal = {Trends in Plant Science},
volume = {23},
number = {10},
pages = {883-898},
year = {2018},
issn = {1360-1385},
doi = {https://doi.org/10.1016/j.tplants.2018.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S1360138518301572},
author = {Asheesh Kumar Singh and Baskar Ganapathysubramanian and Soumik Sarkar and Arti Singh},
keywords = {high throughput, phenomics, machine learning, diseases, transfer learning, imaging, smartphone app, automation},
abstract = {Deep learning (DL), a subset of machine learning approaches, has emerged as a versatile tool to assimilate large amounts of heterogeneous data and provide reliable predictions of complex and uncertain phenomena. These tools are increasingly being used by the plant science community to make sense of the large datasets now regularly collected via high-throughput phenotyping and genotyping. We review recent work where DL principles have been utilized for digital image–based plant stress phenotyping. We provide a comparative assessment of DL tools against other existing techniques, with respect to decision accuracy, data size requirement, and applicability in various scenarios. Finally, we outline several avenues of research leveraging current and future DL tools in plant science.}
}
@article{HUANG2021114896,
title = {A deep reinforcement learning-based method applied for solving multi-agent defense and attack problems},
journal = {Expert Systems with Applications},
volume = {176},
pages = {114896},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114896},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421003377},
author = {Liwei Huang and Mingsheng Fu and Hong Qu and Siying Wang and Shangqian Hu},
keywords = {Multi-agent cooperation, Defense and attack, Deep reinforcement learning, Multi-agent reinforcement learning},
abstract = {Learning to cooperate among agents has always been an important research topic in artificial intelligence. Multi-agent defense and attack, one of the important issues in multi-agent cooperation, requires multiple agents in the environment to learn effective strategies to achieve their goals. Deep reinforcement learning (DRL) algorithms have natural advantages dealing with continuous control problems especially under situations with dynamic interactions, and have provided new solutions for those long-studied multi-agent cooperation problems. In this paper, we start from deep deterministic policy gradient (DDPG) algorithm and then introduce multi-agent DDPG (MADDPG) to solve the multi-agent defense and attack problem under different situations. We reconstruct the considered environment, redefine the continuous state space, continuous action space, reward functions accordingly, and then apply deep reinforcement learning algorithms to obtain effective decision strategies. Several experiments considering different confrontation scenarios are conducted to validate the feasibility and effectiveness of the DRL-based methods. Experimental results show that through learning the agents can make better decisions, and learning with MADDPG achieves superior performance than learning with other DRL-based models, which also explains the importance and necessity of mastering other agents’ information.}
}
@article{WANG2020100014,
title = {Fundamentals, materials, and machine learning of polymer electrolyte membrane fuel cell technology},
journal = {Energy and AI},
volume = {1},
pages = {100014},
year = {2020},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2020.100014},
url = {https://www.sciencedirect.com/science/article/pii/S2666546820300148},
author = {Yun Wang and Bongjin Seo and Bowen Wang and Nada Zamel and Kui Jiao and Xavier Cordobes Adroher},
keywords = {Pem, Fuel cell, Fundamental, Material, Machine learning, Artificial intelligence, Physics-informed},
abstract = {Polymer electrolyte membrane (PEM) fuel cells are electrochemical devices that directly convert the chemical energy stored in fuel into electrical energy with a practical conversion efficiency as high as 65%. In the past years, significant progress has been made in PEM fuel cell commercialization. By 2019, there were over 19,000 fuel cell electric vehicles (FCEV) and 340 hydrogen refueling stations (HRF) in the U.S. (~8,000 and 44, respectively), Japan (~3,600 and 112, respectively), South Korea (~5,000 and 34, respectively), Europe (~2,500 and 140, respectively), and China (~110 and 12, respectively). Japan, South Korea, and China plan to build approximately 3,000 HRF stations by 2030. In 2019, Hyundai Nexo and Toyota Mirai accounted for approximately 63% and 32% of the total sales, with a driving range of 380 and 312 miles and a mile per gallon (MPGe) of 65 and 67, respectively. Fundamentals of PEM fuel cells play a crucial role in the technological advancement to improve fuel cell performance/durability and reduce cost. Several key aspects for fuel cell design, operational control, and material development, such as durability, electrocatalyst materials, water and thermal management, dynamic operation, and cold start, are briefly explained in this work. Machine learning and artificial intelligence (AI) have received increasing attention in material/energy development. This review also discusses their applications and potential in the development of fundamental knowledge and correlations, material selection and improvement, cell design and optimization, system control, power management, and monitoring of operation health for PEM fuel cells, along with main physics in PEM fuel cells for physics-informed machine learning. The objective of this review is three fold: (1) to present the most recent status of PEM fuel cell applications in the portable, stationary, and transportation sectors; (2) to describe the important fundamentals for the further advancement of fuel cell technology in terms of design and control optimization, cost reduction, and durability improvement; and (3) to explain machine learning, physics-informed deep learning, and AI methods and describe their significant potentials in PEM fuel cell research and development (R&D).}
}
@article{LI2021110512,
title = {Application of Artificial Neural Networks to photovoltaic fault detection and diagnosis: A review},
journal = {Renewable and Sustainable Energy Reviews},
volume = {138},
pages = {110512},
year = {2021},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2020.110512},
url = {https://www.sciencedirect.com/science/article/pii/S136403212030798X},
author = {B. Li and C. Delpha and D. Diallo and A. Migan-Dubois},
keywords = {Photovoltaic, Artificial neural network, Fault detection, Fault classification, Machine learning, Deep learning},
abstract = {The rapid development of photovoltaic (PV) technology and the growing number and size of PV power plants require increasingly efficient and intelligent health monitoring strategies to ensure reliable operation and high energy availability. Among the various techniques, Artificial Neural Network (ANN) has exhibited the functional capacity to perform the identification and classification of PV faults. In the present review, a systematic study on the application of ANN and hybridized ANN models for PV fault detection and diagnosis (FDD) is conducted. For each application, the targeted PV faults, the detectable faults, the type and amount of data used, the model configuration and the FDD performance are extracted, and analyzed. The main trends, challenges and prospects for the application of ANN for PV FDD are extracted and presented.}
}
@article{LI2020103807,
title = {Path planning of multiple UAVs with online changing tasks by an ORPFOA algorithm},
journal = {Engineering Applications of Artificial Intelligence},
volume = {94},
pages = {103807},
year = {2020},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2020.103807},
url = {https://www.sciencedirect.com/science/article/pii/S0952197620301895},
author = {Kun Li and Fawei Ge and Ying Han and Yi’an Wang and Wensu Xu},
keywords = {Oilfield inspection, UAVs, Path planning, Task assignment, Swarm intelligence algorithm, Fruit fly optimization algorithm},
abstract = {The unmanned aerial vehicle (UAV) is a new type oilfield inspection tool which is characterized by high flexibility, low cost and high efficiency. In the UAV based oilfield inspection technology, the path planning is an indispensable element which finds an optimal flight path for UAV to finish the inspection jobs successfully. In comparison with the other researches, our study focuses on two challenging issues: path planning of multiple UAVs by traversing a certain amount of task points in the three-dimensional environment within the required completion time, and optimizing solving for the best flight path with online changing tasks. In the research, a novel task assignment method including the initial task assignment and the task assignment with changing tasks is proposed to determine the initial task sequences of each UAV and rapidly replan task sequences after tasks change. An improved fruit fly optimization algorithm (named ORPFOA) is proposed to solve the path planning problem in both initial task sequences and new task sequences after tasks change, in which the optimal reference point and a distance cost matrix are used to reach both faster solving and higher optimizing precision for the optimal flight path. In ORPFOA, two cost functions are defined to evaluate the optimizing results in the initial phase and the new phase after task changes, respectively. A simulation model of the three-dimensional oilfield environment is established to verify the effectiveness of the proposed method in comparison with other six algorithms.}
}
@article{GUO2021519,
title = {STMTO: A smart and trust multi-UAV task offloading system},
journal = {Information Sciences},
volume = {573},
pages = {519-540},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521004667},
author = {Jialin Guo and Guosheng Huang and Qiang Li and Neal N. Xiong and Shaobo Zhang and Tian Wang},
keywords = {Multi Unmanned Aerial Vehicles, Task offloading, Trust, Double auction model, Energy effective, Security},
abstract = {As one of promising distributed multi-robot system, Unmanned Aerial Vehicles (UAVs) can collaborate to offload complex tasks in edge networks. A Smart and Trust Multi-UAV Task Offloading (STMTO) system is established to offload tasks from Internet of Thing (IoT) devices to edge severs through UAVs with a trust style. In STMTO system, first, a group of UAVs is dispatched to relay tasks from devices to edge servers with rich computing resource. A collaborative task collection scheme is proposed to minimize energy consumption and the task processing delay by dividing working area for each UAV and designing the flight trajectory. Secondly, a many-to-many task double auction model is established for devices and edge servers to maximize the offloading utility, where devices act as buyers, edge servers as sellers, and UAVs as auctioneers. Last, to resist attack of malicious edge servers and ensure the task security, a novel trust evaluation method based on the comparison of true utility and expected utility is integrated in auction mechanism. The theoretical analysis and implementation results show that the proposed STMTO system not only achieve the best utility for devices and edge servers simultaneously, but also identify the malicious edge servers and protect task from attacks.}
}
@article{HE2021107832,
title = {Mapping topo-bathymetry of transparent tufa lakes using UAV-based photogrammetry and RGB imagery},
journal = {Geomorphology},
volume = {389},
pages = {107832},
year = {2021},
issn = {0169-555X},
doi = {https://doi.org/10.1016/j.geomorph.2021.107832},
url = {https://www.sciencedirect.com/science/article/pii/S0169555X21002403},
author = {Jinchen He and Jiayuan Lin and Mingguo Ma and Xiaohan Liao},
keywords = {Tufa lake, Bathymetry, Unmanned aerial vehicle (UAV), Refraction correction, Band difference model},
abstract = {Seasonal or interannual precipitation differences lead to changes in the water level of a tufa lake, while the underwater topography affects its local depth. Therefore, topo-bathymetry is important to study and protect the aquatic environment of tufa lakes. However, traditional field-based topo-bathymetric surveying methods (e.g., sounding rod or sonar) inevitably disturb the fragile lake ecosystem. In recent years, the emerging remote sensing technology of unmanned aerial vehicles (UAV) has provided a cost-effective solution for measuring topo-bathymetry without disturbance. In this paper, taking Spark Lake in Jiuzhaigou, China, as an example, we captured red-green-blue (RGB) images using a fixed-wing UAV and produced a digital elevation model (DEM) prior to the Jiuzhaigou Earthquake using Structure-from-Motion (SfM) photogrammetry. The underwater topography of Spark Lake was obtained by refraction correction and water color inversion based on the DEM and orthophoto, respectively. For refraction correction, a water depth correction model based on Snell's Law was used. For water color inversion, general band ratio models were replaced by a band difference model (blue band - green band). The qualities of the resulting DEMs produced by the two methods were evaluated against the topography of the drained Spark Lake after the earthquake, and the corresponding DEMs of difference (DoD) were also analyzed. The coefficient of determination (R2) and root mean square error (RMSE) are 0.88 and 1.32 m for refraction correction, and 0.86 and 1.37 m for water color inversion, respectively. The results demonstrated the feasibility and effectiveness of applying UAV-acquired RGB imagery and the two optical remote sensing methods to topo-bathymetric mapping of transparent tufa lakes.}
}
@article{SUDHAKAR2021334,
title = {MCFT-CNN: Malware classification with fine-tune convolution neural networks using traditional and transfer learning in Internet of Things},
journal = {Future Generation Computer Systems},
volume = {125},
pages = {334-351},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.06.029},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21002247},
author = { Sudhakar and Sushil Kumar},
keywords = {Cybersecurity, Malware, Image-based malware classification, Deep learning, Fine-tuning, Convolutional neural networks, Transfer learning, Traditional learning},
abstract = {With ever-increasing, internet-connected devices provide an opportunity to fulfil the attacker’s malicious intention. They use malicious programs to compromise the devices and use them to infect others also. The security researchers are straggling to develop a technique that detects all the malware accurately because of the use of invincible techniques in the development of malware such as strong encryption, obfuscation, polymorphic and metamorphic engine. In this context, this paper proposes a novel malware classification with fine-tune convolution neural networks (MCFT-CNN) model. The MCFT-CNN model detects the unknown malware sample without feature engineering and prior knowledge of binary code analysis or reverse engineering, even the advanced evading techniques used to develop the malware. The model uses deep transfer learning to classify the malware images to their respective malware families. The proposed model enhances the ResNet50 model by altering the last layer with a fully connected dense layer. The output of fully connected dense layer and knowledge of ImageNet model are supplied to softmax layer for malware classification. The model is trained with MalImg malware datasets. The proposed model reported 99.18% accuracy and 5.14ms prediction time. The model also shows consistent performance with a relatively larger dataset (Microsoft malware challenge dataset, approximately 500GB) with 98.63% accuracy and 5.15ms prediction time. The proposed model shows consistent efficacy with two benchmark datasets that clarify the model’s generalisability to perform on the diverse datasets.}
}
@article{MONTERO2021108486,
title = {Proactive radio- and QoS-aware UAV as BS deployment to improve cellular operations},
journal = {Computer Networks},
volume = {200},
pages = {108486},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108486},
url = {https://www.sciencedirect.com/science/article/pii/S138912862100431X},
author = {Emanuel Montero and Carlos Rocha and Helder Oliveira and Eduardo Cerqueira and Paulo Mendes and Aldri Santos and Denis Rosário},
keywords = {UAV-BS, Mobility prediction, And QoS support},
abstract = {Unmanned Aerial Vehicle as Base Stations (UAV-BS) is a promising technology for mitigating Terrestrial Base Stations (TBS) failures or becoming an ideal temporary solution to offloading. UAV-BS can be deployed to complement existing cellular systems by providing additional capacity to hotspot areas, as well as to provide network coverage in emergency and public safety situations, for instance, during a parade or flash-crowd events. A key issue for the success of UAV-BS is to design and model how to define the position and behavior of UAV-BSs to improve the coverage area for mobile users while enhancing the Quality of Service (QoS). This article proposes ProactivE Radio-QoS-aware UAV-BS deployment mechanism to improve Cellular nEtwork oPeraTion (PERCEPT) to define the positioning of the UAV-BS’s in specific zones according to the conditions of the LTE networks and QoS. PERCEPT divides the optimal positioning problem into three parts, prediction of users mobility, radio- and QoS-aware user clustering, and positioning of the UAV-BS’s. Simulation results show the gains of PERCEPT by improving in 33%, 30%, and 50% the throughput, packet delivery ratio, and delay, respectively, compared to state-of-the-art algorithms in UAV-assisted cellular scenarios.}
}
@article{OU2021300,
title = {Autonomous quadrotor obstacle avoidance based on dueling double deep recurrent Q-learning with monocular vision},
journal = {Neurocomputing},
volume = {441},
pages = {300-310},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.02.017},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221002629},
author = {Jiajun Ou and Xiao Guo and Ming Zhu and Wenjie Lou},
keywords = {Unmanned aerial vehicle, Obstacle avoidance, Deep reinforcement learning, Depth estimation},
abstract = {This paper proposes a novel learning-based framework to realize quadrotor autonomous obstacle avoidance with monocular vision. The framework adopts a two-stage architecture, consisting of a sensing module and a decision module. The sensing module trained in an unsupervised manner can extract depth information from the on-board camera image. Moreover, the decision module uses dueling double deep recurrent Q-learning to eliminate the adverse effects of the on-board monocular camera’s limited observation capacity while choosing practical obstacle avoidance action. The framework has two advantages: (1) it enables the quadrotor to realize autonomous obstacle avoidance without any prior environment information or labeled datasets for training, and (2) its model can be easily updated while facing new application scenarios. The experiments in several different simulation scenes show that the trained framework outperforms a high passing rate in crowded environments and a good generalization ability for transformed scenarios.}
}
@article{LIU2021107491,
title = {Sliding mode control of multi-agent system with application to UAV air combat},
journal = {Computers & Electrical Engineering},
volume = {96},
pages = {107491},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107491},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621004432},
author = {Chang Liu and Shaoshan Sun and Chenggang Tao and Yingxin Shou and Bin Xu},
keywords = {Air combat, Sliding mode control, Game theory, Estimate of distribution algorithm},
abstract = {This paper investigates the air combat mission between the multiple Unmanned Aerial Vehicle (UAV) and hostile multi-UAV. The multi-UAV air combat threat assessment model is firstly established to evaluate the situation of each drone in the combat scenario and then, the target allocation problem is formulated based on matrix game theory. To solve the target allocation problem, the modified Estimate of Distribution Algorithm (EDA) is proposed to search the best strategy. After the target allocation, the social behavioral based sliding mode control is finally constructed to realize the UAV swarm motion. The simulation experiment of multi-UAV air combat proves the validity of the algorithm.}
}
@article{KIM2021115075,
title = {Nine-Axis IMU-based Extended inertial odometry neural network},
journal = {Expert Systems with Applications},
volume = {178},
pages = {115075},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115075},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421005169},
author = {Won-Yeol Kim and Hong-Il Seo and Dong-Hoan Seo},
keywords = {Extended inertial odometry neural network, Inertial measurement unit, Drift, Pose-TuningNet},
abstract = {With the development of mobile devices, such as smartphones, research on fast and accurate trajectory tracking is being actively conducted. This research requires a continuous integration of the acceleration and angular velocity data obtained from the low-cost microelectromechanical system-based inertial measurement unit (IMU) installed in a device to track the user’s trajectory. During this process, drift occurs over time due to the bias and intrinsic error of the IMU sensor. Hence, the 6-Axis IMU-based inertial odometry neural network (IONet) using deep learning, which is designed as a framework for velocity estimation, is used to reduce drift by dividing the acceleration data into independent windows. However, drift still occurs in estimating a pose containing both a position and an orientation because the integration of pose changes is also required. In this study, we proposed the Extended IONet that combines a 9-Axis IONet and Pose-TuningNet to improve the accuracy of trajectory tracking by compensating for the drift problem of the 6-Axis IONet. The proposed 9-Axis IONet uses the gravitational acceleration and geomagnetic data of the IMU in addition to the input structure of the existing 6-Axis IONet; thus, the estimation accuracy of pose changes improves by reducing the data dependence on the original input of the 6-Axis IONet. The proposed Pose-TuningNet is an auxiliary network that is capable of estimating pose changes more precisely using the higher-dimensional inclination-angle information obtained from the IMU to focus on the noise model of the IMU. Experiments were conducted using the Oxford Inertial Odometry Dataset, which is public dataset for deep learning based inertial navigation research to verify the performance of the proposed neural network. Compared with the existing 6-Axis IONet, the Extended IONet achieved superior performance in five out of seven cases, and its overall 39.8% RMSE improvement demonstrated its excellent performance. Additionally, the results showed that Pose-TuningNet improved the position estimation performance by correcting the drift problem in the 9-Axis IONet.}
}
@article{ZHANG20201049,
title = {Finite-Sample Analysis For Decentralized Cooperative Multi-Agent Reinforcement Learning From Batch Data},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {1049-1056},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.1290},
url = {https://www.sciencedirect.com/science/article/pii/S240589632031692X},
author = {Kaiqing Zhang and Zhuoran Yang and Han Liu and Tong Zhang and Tamer Başar},
keywords = {Reinforcement Learning, Finite-Sample Analysis, Networked Systems, Multi-Agent Systems, Decentralized Optimization},
abstract = {In contrast to its great empirical success, theoretical understanding of multi-agent reinforcement learning (MARL) remains largely underdeveloped. As an initial attempt, we provide a finite-sample analysis for decentralized cooperative MARL with networked agents. In particular, we consider a team of cooperative agents connected by a time-varying communication network, with no central controller coordinating them. The goal for each agent is to maximize the long-term return associated with the team-average reward, by communicating only with its neighbors over the network. A batch MARL algorithm is developed for this setting, which can be implemented in a decentralized fashion. We then quantify the estimation errors of the action-value functions obtained from our algorithm, establishing their dependence on the function class, the number of samples in each iteration, and the number of iterations. This work appears to be the first finite-sample analysis for decentralized cooperative MARL from batch data.}
}
@article{LU2022102,
title = {An automatic isotropic/anisotropic hybrid grid generation technique for viscous flow simulations based on an artificial neural network},
journal = {Chinese Journal of Aeronautics},
volume = {35},
number = {4},
pages = {102-117},
year = {2022},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121003113},
author = {Peng LU and Nianhua WANG and Xinghua CHANG and Laiping ZHANG and Yadong WU},
keywords = {Advancing front method, Advancing layer method, Anisotropic quadrilateral grid generation, Artificial neural network, Isotropic triangular grid generation, Machine learning},
abstract = {Based on the author's previous research, a novel hybrid grid generation technique is developed by introducing an Artificial Neural Network (ANN) approach for realistic viscous flow simulations. An initial hybrid grid over a typical geometry with anisotropic quadrilaterals in the boundary layer and isotropic triangles in the off-body region is generated by the classical mesh generation method to train two ANNs on how to predict the advancing direction of the new point and to control the grid size. After inputting the initial discretized fronts, the ANN-based Advancing Layer Method (ALM) is adopted to generate the anisotropic quadrilaterals in boundary layers. When the high aspect ratio of the anisotropic grid reaches a specified value, the ANN-based Advancing Front Method (AFM) is adopted to generate isotropic triangles in the off-body computational domain. The initial isotropic triangles are smoothed to further improve the grid quality. Three typical cases are tested and compared with experimental data to validate the effectiveness of grids generated by the ANN-based hybrid grid generation method. The experimental results show that the two ANNs can predict the advancing direction and the grid size very well, and improve the adaptability of the isotropic/anisotropic hybrid grid generation for viscous flow simulations.}
}
@article{THOMAS2021102741,
title = {Battery monitoring system using machine learning},
journal = {Journal of Energy Storage},
volume = {40},
pages = {102741},
year = {2021},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2021.102741},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X21004734},
author = {John K. Thomas and Hancy Rohan Crasta and K. Kausthubha and Chavan Gowda and Ashwath Rao},
keywords = {Battery, BMS, Lithium-ion, Rechargeable, LSTM, Health},
abstract = {Battery life prediction helps in smooth and uniform functioning of the battery-operated systems. Although, the capacity of the battery can be monitored by some devices, they cannot estimate how long the battery can work before a failure occurs. The technique that we have proposed here, estimates the life span of a battery using Long Short Term-Memory (LSTM), an artificial Recurrent Neural Network (RNN) architecture in Machine Learning (ML). The battery life is measured by considering each cell voltage, load voltage, temperature of the battery and charge-discharge cycle. The voltage and temperature of the battery cells are measured by a thermistor and microcontroller. The voltage values fetched by the micro controller are sent to a web server and these values are displayed on a web based mobile phone application. Balance charging of the battery cells and over charge protection is provided by constantly monitoring the battery status. This paper includes explanation on different circuit parts, algorithm used in training the model, Graphical User Interface (GUI) and the test results.}
}
@article{MONNA2020118,
title = {Machine learning for rapid mapping of archaeological structures made of dry stones – Example of burial monuments from the Khirgisuur culture, Mongolia –},
journal = {Journal of Cultural Heritage},
volume = {43},
pages = {118-128},
year = {2020},
issn = {1296-2074},
doi = {https://doi.org/10.1016/j.culher.2020.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S1296207419305333},
author = {Fabrice Monna and Jérôme Magail and Tanguy Rolland and Nicolas Navarro and Josef Wilczek and Jamiyan-Ombo Gantulga and Yury Esin and Ludovic Granjon and Anne-Caroline Allard and Carmela Chateau-Smith},
keywords = {Pixel classification, Grey level co-occurrence matrix, RGB colour space, Texture, Topographic position index, Photogrammetry, Burial complex planigraphy, Mongolia, Bronze age, Iron age},
abstract = {The present study proposes a workflow to extract from orthomosaics the enormous amount of dry stones used by past societies to construct funeral complexes in the Mongolian steppes. Several different machine learning algorithms for binary pixel classification (i.e. stone vs non-stone) were evaluated. Input features were extracted from high-resolution orthomosaics and digital elevation models (both derived from aerial imaging). Comparative analysis used two colour spaces (RGB and HSV), texture features (contrast, homogeneity and entropy raster maps), and the topographic position index, combined with nine supervised learning algorithms (nearest centroid, naive Bayes, k-nearest neighbours, logistic regression, linear and quadratic discriminant analyses, support vector machine, random forest, and artificial neural network). When features are processed together, excellent output maps, very close to or outperforming current standards in archaeology, are observed for almost all classifiers. The size of the training set can be drastically reduced (to ca. 300 samples) by majority voting, while maintaining performance at the highest level (about 99.5% for all performance scores). Note, however, that if the training set is inadequate or not fully representative, the classification results are poor. That said, the methods applied and tested here are extremely rapid. Extensive mapping, which would have been difficult with traditional, manual, or semi-automatic delineation of stones using a vector graphics editor, now becomes possible. This workflow generally surpasses pedestrian surveys using differential GPS or a total station.}
}
@article{LIANG2021,
title = {Data-driven fault diagnosis of FW-UAVs with consideration of multiple operation conditions},
journal = {ISA Transactions},
year = {2021},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2021.07.043},
url = {https://www.sciencedirect.com/science/article/pii/S0019057821004109},
author = {Shaojun Liang and Shirong Zhang and Yuping Huang and Xing Zheng and Jian Cheng and Sisi Wu},
keywords = {Fixed-wing UAV, Multiple operation conditions, SNN, DBSCAN, DKPCA},
abstract = {Fixed-wing Unmanned Aerial Vehicles (FW-UAVs) are intelligent aircrafts. It is of significance to carry out fault diagnosis of FW-UAVs to improve reliability and safety. An entire mission of FW-UAVs contains couple of phases; correspondingly, this paper treats FW-UAVs as multiple operation condition processes. An innovative framework is then proposed for fault diagnosis of FW-UAVs, where the process dynamics, multiple operation conditions, variable data density, and process disturbance are considered. Firstly, augmented matrixes are constructed with the data samples to involve the dynamic characteristic of FW-UAVs. Secondly, a modified DBSCAN algorithm employing Shared Nearest Neighbor based Distance (SNND-DBSCAN) and a K Nearest Neighbor algorithm employing SNND (SNND-KNN) are proposed respectively. They cooperate with each other to realize offline operation condition classification and online recognition. Thirdly, Multiple condition oriented Dynamic KPCA (M-DKPCA) algorithms incorporated with Weighted sliding window denoising (WM-DKPCA) is proposed for fault diagnosis. Finally, the proposed algorithms are tested with real flight data sets in terms of linear and nonlinear faults; and the comparisons between KPCA, DKPCA, M-DKPCA and WM-DKPCA are presented. The results confirm that the multiple condition oriented M-DKPCA and WM-DKPA algorithms are more suitable for fault diagnosis of FW-UAVs; and WSW denoising can indeed improve the fault diagnosis performance.}
}
@article{WANG2022106629,
title = {GIS-based volunteer cotton habitat prediction and plant-level detection with UAV remote sensing},
journal = {Computers and Electronics in Agriculture},
volume = {193},
pages = {106629},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106629},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006463},
author = {Tianyi Wang and Xiaohan Mei and J. {Alex Thomasson} and Chenghai Yang and Xiongzhe Han and Pappu Kumar Yadav and Yeyin Shi},
keywords = {Volunteer cotton, Feral cotton, GIS, Network analysis, Plant-level, Classification, Precision agriculture, Cotton boll weevil},
abstract = {Volunteer cotton plants germinate and grow at unwanted locations like transport routes and can serve as hosts for a harmful cotton pests called cotton boll weevils. The main objective of this study was to develop a geographic information system (GIS) framework to efficiently locate volunteer cotton plants in the cotton production regions in southern Texas, thus reducing time and economic cost for their removal. A GIS network analysis tool was applied to estimate the most likely routes for cotton transportation, and a GIS model was created to identify and visualize potential areas of volunteer cotton growth. The GIS model indicated that, of the 31 counties in southern Texas that may have habitat for volunteer cotton, Hidalgo, Cameron, Nueces, and San Patricio are the counties at the greatest risk. Moreover, a method based on unmanned aerial vehicle (UAV) remote sensing was proposed to detect the precise locations of volunteer cotton plants in potential areas for their subsequent removal. In this study, a UAV was used to scan limited samples of potential volunteer cotton growth areas identified with the GIS model. The results indicated that UAV remote sensing coupled with the proposed image analysis methods could accurately identify the precise locations of volunteer cotton and could potentially assist in the elimination of volunteer cotton along transport routes.}
}
@article{ZHANG2020,
title = {Real-Time Detection of Cracks on Concrete Bridge Decks Using Deep Learning in the Frequency Domain},
journal = {Engineering},
year = {2020},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2020.07.026},
url = {https://www.sciencedirect.com/science/article/pii/S2095809920303301},
author = {Qianyun Zhang and Kaveh Barri and Saeed K. Babanajad and Amir H. Alavi},
keywords = {Crack detection, Concrete bridge deck, Deep learning, Real-time},
abstract = {This paper presents a vision-based crack detection approach for concrete bridge decks using an integrated one-dimensional convolutional neural network (1D-CNN) and long short-term memory (LSTM) method in the image frequency domain. The so-called 1D-CNN-LSTM algorithm is trained using thousands of images of cracked and non-cracked concrete bridge decks. In order to improve the training efficiency, images are first transformed into the frequency domain during a preprocessing phase. The algorithm is then calibrated using the flattened frequency data. LSTM is used to improve the performance of the developed network for long sequence data. The accuracy of the developed model is 99.05%, 98.9%, and 99.25%, respectively, for training, validation, and testing data. An implementation framework is further developed for future application of the trained model for large-scale images. The proposed 1D-CNN-LSTM method exhibits superior performance in comparison with existing deep learning methods in terms of accuracy and computation time. The fast implementation of the 1D-CNN-LSTM algorithm makes it a promising tool for real-time crack detection.}
}
@article{YU2020181,
title = {Distributed adaptive fault-tolerant close formation flight control of multiple trailing fixed-wing UAVs},
journal = {ISA Transactions},
volume = {106},
pages = {181-199},
year = {2020},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2020.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0019057820302780},
author = {Ziquan Yu and Youmin Zhang and Bin Jiang and Xiang Yu and Jun Fu and Ying Jin and Tianyou Chai},
keywords = {Unmanned aerial vehicle (UAV), Distributed control, Close formation control, Fault-tolerant control (FTC), Actuator fault, Wake vortices},
abstract = {This paper considers the reliable control problem for multiple trailing fixed-wing unmanned aerial vehicles (UAVs) against actuator faults and wake vortices. A distributed adaptive fault-tolerant control (FTC) scheme is proposed by using a distributed sliding-mode estimator, dynamic surface control architecture, neural networks, and disturbance observers. The proposed control scheme can make all trailing fixed-wing UAVs converge to the leading UAV with pre-defined time-varying relative positions even when all trailing UAVs encounter the wake vortices generated by the leading UAV and a portion of trailing UAVs is subjected to the actuator faults. It is shown that under the proposed distributed FTC scheme, the tracking errors of all trailing UAVs with respect to their desired positions are bounded. Comparative simulation results are provided to illustrate the effectiveness of the proposed control scheme.}
}
@article{JINTASUTTISAK2022106560,
title = {Deep neural network based date palm tree detection in drone imagery},
journal = {Computers and Electronics in Agriculture},
volume = {192},
pages = {106560},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106560},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921005779},
author = {Thani Jintasuttisak and Eran Edirisinghe and Ali Elbattay},
keywords = {Convolutional Neural Networks, Date palm tree, Object detection, Drone imagery, YOLO-V5},
abstract = {Date palm trees are an important economic crop in the Arabian Peninsula, Middle East, and North Africa. Counting the numbers and determining the locations of date palm trees are important for predicting the date production and plantation management. In this paper, we exploit the effective use of the state-of-the-art CNN, YOLO-V5, in detecting date palm trees in images captured by a camera onboard of a drone flying 122 m above farmlands in the Northern Emirates of the United Arab Emirates (UAE). In the dataset preparation process, we randomly selected 125 captured images and divided them into three datasets: training (60%), validation (20%), and testing (20%). The images of date palm trees in the training and validation datasets were manually annotated and those in the training dataset were used to train the four sub-versions of YOLO-V5 CNNs. The validation dataset was used during the training process to assess how well the network was performing during training. Finally, the images in the test dataset were used to evaluate the performance of the trained models. The results of using YOLO-V5 for date palm tree detection in drone imagery are compared with those obtainable with other popular CNN architectures, YOLO-V3, YOLO-V4, and SSD300, both quantitatively and qualitatively. The results show that for the amount of training data used, YOLO-V5m (medium depth) model records the highest accuracy, resulting in a mean average precision of 92.34%. Further it provides the ability to detect and localize date palm trees of different sizes, in crowded, overlapped environments and areas where the date palm tree distribution is sparse. Therefore, it is concluded that the method can be a useful component of an automated plantation management system and help forecast the quantities of date production and condition monitoring of the date palm trees.}
}
@article{ZHOU2021108384,
title = {Novel methodology for identifying the weight of moving vehicles on bridges using structural response pattern extraction and deep learning algorithms},
journal = {Measurement},
volume = {168},
pages = {108384},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2020.108384},
url = {https://www.sciencedirect.com/science/article/pii/S0263224120309209},
author = {Yun Zhou and Yilin Pei and Sai Zhou and Yu Zhao and Jianxin Hu and Weijian Yi},
keywords = {Bridge health monitoring, Vehicle weight identification, Structural dynamic response, Feature patterns extraction, Time-frequency analysis, Deep learning algorithm},
abstract = {Acquiring the weights of moving vehicles on bridges is crucial for structural performance assessment, as well as for bridge operating and maintenance strategies. Due to the high cost and complex maintenance structure of the bridge weigh-in-motion (BWIM) system, it is necessary to develop an economic and intelligent technology to replace it. This paper proposes a novel methodology for acquiring the weights of vehicles in motion on a bridge, based on the extraction of structural dynamic response patterns and deep learning algorithms that allow the input of a vehicle to be directly distinguished from the bridge’s output response. The response patterns induced by vehicles crossing a bridge are captured by accelerometers, and the raw signals transformed into two-dimensional spectrogram images via time–frequency analysis to extract corresponding visual patterns. Object classification is then conducted using a deep convolutional neural network (DCNN) to automatically learn the features, while the application of optimal analysis enhances performance of the trained network. Experiments in both a laboratory and in the field were conducted to evaluate the effectiveness of the proposed method with results demonstrating that vehicle loads could be directly distinguished from a bridge’s structural responses, even in a noisy environment.}
}
@article{YU2021107406,
title = {Nussbaum-based finite-time fractional-order backstepping fault-tolerant flight control of fixed-wing UAV against input saturation with hardware-in-the-loop validation},
journal = {Mechanical Systems and Signal Processing},
volume = {153},
pages = {107406},
year = {2021},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2020.107406},
url = {https://www.sciencedirect.com/science/article/pii/S0888327020307925},
author = {Ziquan Yu and Youmin Zhang and Bin Jiang and Chun-Yi Su and Jun Fu and Ying Jin and Tianyou Chai},
keywords = {Fixed-wing UAV, Fault-tolerant control, Fractional-order calculus, Finite-time, Input saturation, Hardware-in-the-loop},
abstract = {This paper investigates a new finite-time fault-tolerant control (FTC) using a fractional-order backstepping iterative design strategy for a fixed-wing unmanned aerial vehicle (UAV) in the presence of actuator faults and input saturation. To compensate for the lumped disturbance induced by the actuator faults, a neural network disturbance observer (NNDO) with finite-time observation capability is first developed as the fault diagnostic unit. Then, based on the diagnosed fault information, fractional-order (FO) calculus is artfully utilized to enhance the FTC performance within the backstepping design architecture. The salient feature of the developed control scheme is that the finite-time NNDO and FO calculus are simultaneously used to significantly increase the FTC performance against unexpected actuator faults. Moreover, to address the input saturation problem, the faulty UAV dynamics is augmented by a new auxiliary system. Furthermore, a Nussbaum function is incorporated into the FTC scheme to further avoid the calculation of the inverse gain matrix involved within the auxiliary system. It is shown by Lyapunov analysis that the tracking errors are convergent in finite time. Finally, comparative simulations are conducted to show the effectiveness of the developed FTC scheme. Some hardware-in-the-loop (HIL) experimental results are illustrated to further demonstrate the feasibility of the proposed finite-time fractional-order fault-tolerant control (FTFOFTC) method.}
}
@article{BORGESOLIVEIRA2021104700,
title = {A review of deep learning algorithms for computer vision systems in livestock},
journal = {Livestock Science},
volume = {253},
pages = {104700},
year = {2021},
issn = {1871-1413},
doi = {https://doi.org/10.1016/j.livsci.2021.104700},
url = {https://www.sciencedirect.com/science/article/pii/S1871141321003085},
author = {Dario Augusto {Borges Oliveira} and Luiz Gustavo {Ribeiro Pereira} and Tiago Bresolin and Rafael Ehrich {Pontes Ferreira} and Joao Ricardo {Reboucas Dorea}},
keywords = {Artificial intelligence, Cattle, Machine learning, Precision farming, Swine},
abstract = {In livestock operations, systematically monitoring animal body weight, biometric body measurements, animal behavior, feed bunk, and other difficult-to-measure phenotypes is manually unfeasible due to labor, costs, and animal stress. Applications of computer vision are growing in importance in livestock systems due to their ability to generate real-time, non-invasive, and accurate animal-level information. However, the development of a computer vision system requires sophisticated statistical and computational approaches for efficient data management and appropriate data mining, as it involves massive datasets. This article aims to provide an overview of how deep learning has been implemented in computer vision systems used in livestock, and how such implementation can be an effective tool to predict animal phenotypes and to accelerate the development of predictive modeling for precise management decisions. First, we reviewed the most recent milestones achieved with computer vision systems and the respective deep learning algorithms implemented in Animal Science studies. Then, we reviewed the published research studies in Animal Science which used deep learning algorithms as the primary analytical strategy for image classification, object detection, object segmentation, and feature extraction. The great number of reviewed articles published in the last few years demonstrates the high interest and rapid development of deep learning algorithms in computer vision systems across livestock species. Deep learning algorithms for computer vision systems, such as Mask R-CNN, Faster R-CNN, YOLO (v3 and v4), DeepLab v3, U-Net and others have been used in Animal Science research studies. Additionally, network architectures such as ResNet, Inception, Xception, and VGG16 have been implemented in several studies across livestock species. The great performance of these deep learning algorithms suggests an improved predictive ability in livestock applications and a faster inference. However, only a few articles fully described the deep learning algorithms and their implementation. Thus, information regarding hyperparameter tuning, pre-trained weights, deep learning backbone, and hierarchical data structure were missing. We summarized peer-reviewed articles by computer vision tasks (image classification, object detection, and object segmentation), deep learning algorithms, animal species, and phenotypes including animal identification and behavior, feed intake, animal body weight, and many others. Understanding the principles of computer vision and the algorithms used for each application is crucial to develop efficient systems in livestock operations. Such development will potentially have a major impact on the livestock industry by predicting real-time and accurate phenotypes, which could be used in the future to improve farm management decisions, breeding programs through high-throughput phenotyping, and optimized data-driven interventions.}
}
@article{LORK2020115426,
title = {An uncertainty-aware deep reinforcement learning framework for residential air conditioning energy management},
journal = {Applied Energy},
volume = {276},
pages = {115426},
year = {2020},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2020.115426},
url = {https://www.sciencedirect.com/science/article/pii/S0306261920309387},
author = {Clement Lork and Wen-Tai Li and Yan Qin and Yuren Zhou and Chau Yuen and Wayes Tushar and Tapan K. Saha},
keywords = {Bayesian neural networks, Air conditioning, Energy saving},
abstract = {Most existing methods for controlling the energy consumption of air conditioning (AC), focus on either scheduling the switching (on/off) of compressors or optimizing the overall energy consumption of AC system of an entire building. Unlike commercial buildings, residential apartments typically house separate ACs in individual rooms occupied by people with different thermal comfort preferences. Fortunately, the advancement of Internet-of-Things (IoT) technology has enabled the exploitation of sensory data to intelligently control the set-point temperature of ACs in individual rooms based on environmental conditions and occupant’s preferences, improving the energy efficiency of residential buildings. Indeed, control decisions based on sensory data may suffer from uncertainties due to error in data measurement and contribute to model uncertainty. This work proposes a data-driven uncertainty-aware approach to control split-type inverter ACs of residential buildings. First, information from similar AC and residential units are aggregated to reduce data imbalances, and Bayesian-Convolutional-Neural-Networks (BCNNs) are utilized to model the performance and uncertainty of the ACs from the aggregated data. Second, a Q-learning based reinforcement learning algorithm for set-point decision making is designed for setpoint optimization with transitions sampled from the BCNN models. Third, a case study is simulated based on such a framework to show that the control actions taken by the uncertainty-aware agent perform better in terms of discomfort management and energy savings compared to the uncertainty unaware agent. Further, the agent could also be adjusted to capture the trade-off between energy savings and comfort levels for varying degrees of energy and discomfort savings.}
}
@article{ZHAO2021103832,
title = {Structural health monitoring and inspection of dams based on UAV photogrammetry with image 3D reconstruction},
journal = {Automation in Construction},
volume = {130},
pages = {103832},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103832},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521002831},
author = {Sizeng Zhao and Fei Kang and Junjie Li and Chuanbo Ma},
keywords = {Dams, Structural health monitoring, Damage detection, Unmanned aerial vehicle, Structure from motion, 3D image reconstruction},
abstract = {This study presents a three-dimensional (3D) reconstruction model based on unmanned aerial vehicle (UAV) images for dam emergency monitoring and inspection. The structure from motion method is adopted to generate a high-precision 3D dam model with scene geometry by matching the features in multiple overlapping images. Then, the generated model is used to calculate the 3D point coordinates and camera pose through the bundle adjustment system. Effect of ground control points on the model accuracy is analyzed by different position sets for adaptation to various situations. The proposed emergency monitoring model is verified on two rock-fill dams, inspection model is utilized on a concrete dam, and damage detection method is achieved on a small-scale dam model with loadable panels. Results show that the proposed 3D dam reconstruction model based on UAV images can obtain satisfactory accuracy and result in a significant improvement in the dam monitoring and inspection efficiency.}
}
@article{GUAN2021103788,
title = {Automated pixel-level pavement distress detection based on stereo vision and deep learning},
journal = {Automation in Construction},
volume = {129},
pages = {103788},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103788},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521002399},
author = {Jinchao Guan and Xu Yang and Ling Ding and Xiaoyun Cheng and Vincent C.S. Lee and Can Jin},
keywords = {Pavement distress detection, Stereo vision, Deep learning, U-net, Depthwise separable convolution, Crack and pothole segmentation},
abstract = {Automated pavement distress detection based on 2D images is facing various challenges. To efficiently complete the crack and pothole segmentation in a practical environment, an automated pixel-level pavement distress detection framework integrating stereo vision and deep learning is developed in this study. Based on the multi-view stereo imaging system, multi-feature pavement image datasets containing color images, depth images and color-depth overlapped images are established, providing a new perspective for deep learning. To alleviate computational burden, a modified U-net deep learning architecture introducing depthwise separable convolution is proposed for crack and pothole segmentation. These methods are tested in asphalt roads with different circumstances. The results show that the 3D pavement image achieves millimeter-level accuracy. The enhanced 3D crack segmentation model outperforms other models in terms of segmentation accuracy and inference speed. After obtaining the high-resolution pothole segmentation map, the automated pothole volume measurement is realized with high accuracy.}
}
@article{GUO2021102493,
title = {Estimating mangrove leaf area index based on red-edge vegetation indices: A comparison among UAV, WorldView-2 and Sentinel-2 imagery},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {103},
pages = {102493},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102493},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421002002},
author = {Xianxian Guo and Mao Wang and Mingming Jia and Wenqing Wang},
keywords = {Mangrove, Leaf area index, Red-edge band, Vegetation index, Unmanned Aerial Vehicle, WorldView-2, Sentinel-2},
abstract = {Accurate estimation of mangrove leaf area index (LAI) is fundamental for effective mangrove ecosystem management and protection. Remote sensing technology has showed its powerful potential in accurately retrieving mangrove LAI. The generic estimation model combining vegetation indices (VIs) with physically-based law, simplified as LAI-VIs model, has successfully estimated crop LAI. However, the capacity of estimating mangrove LAI using this model, so far, is unclear. Moreover, some studies have proved that estimation accuracy of terrestrial forests and crops LAI can be ameliorated with VIs based on red-edge band (VIs_RE) because of less affecting by canopy structure. However, little literature explores the ability of VIs_RE, especially, from different multispectral sensors, for estimating mangrove LAI. Therefore, our main purpose is to evaluate the robustness and sensitivity of the LAI-VIs_RE model from Sentinel-2, WorldView-2 (WV-2) and Unmanned Aerial Vehicle (UAV) multispectral imagery for estimating mangrove LAI. The estimation models with input variables of NDVI, NDVI_RE1 (band combination from red-edge and visible band), NDVI_RE2 (band combination from red-edge and near-infrared reflectance) from three types of multispectral imagery are used to calculate mangrove LAI of 99 plots. The results showed that the WV-2 imagery acquires the best estimation accuracy (R2 = 0.72, RMSE = 0.414), followed by Sentinel-2 imagery (R2 = 0.68, RMSE = 0.440), and UAV multispectral imagery (R2 = 0.48, RMSE = 0.570). The analyses display the good results of the LAI-NDVI model and LAI-NDVI_RE1 model from WV-2 and Sentinel-2 imagery with the range of R2 from 0.57 to 0.72, and the discrepant consequences of LAI-NDVI_RE2 model from UAV imagery with R2 of 0.15, WV-2 imagery with R2 of 0.67 and Sentienl-2 imagery with R2 of 0.65, 0.18 and 0.12. This study proves that the generic estimation model and NDVI_RE1 derived from WV-2 and Sentinel-2 multispectral imagery could be deemed as a basic method and input variables of mapping mangrove LAI.}
}
@article{KAMARI2022104091,
title = {AI-based risk assessment for construction site disaster preparedness through deep learning-based digital twinning},
journal = {Automation in Construction},
volume = {134},
pages = {104091},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.104091},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521005422},
author = {Mirsalar Kamari and Youngjib Ham},
keywords = {Visual sensing and analytics, Construction site disaster preparedness, Scene understanding, Artificial intelligence},
abstract = {Hurricanes are among the most devastating natural disasters in the United States, causing billions of dollars of property damage and insured losses. During extreme wind events, unsecured objects in jobsites can easily become airborne debris, which results in substantial loss to construction projects and neighboring communities. Towards a systematic disaster preparedness in construction jobsites, this paper presents a novel vision-based digital twinning and threat assessment framework. We encode the context of disaster risk into deep-learning architectures to identify and analyze the characteristics and impacts of potential wind-borne debris in construction site digital twin models. Case studies on nine piles of construction materials are presented to demonstrate and discuss the fidelity of the proposed computational modules. The proposed methods are expected to help provide heads up for practitioners to quickly recognize, localize, and assess potential wind-borne derbies in construction jobsites, and thereby implementing hurricane preparedness in an effective and timely manner.}
}
@article{BRAUN2019102879,
title = {Combining inverse photogrammetry and BIM for automated labeling of construction site images for machine learning},
journal = {Automation in Construction},
volume = {106},
pages = {102879},
year = {2019},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2019.102879},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519300329},
author = {Alex Braun and André Borrmann},
keywords = {Machine learning, Labeling, Construction progress monitoring, BIM, Photogrammetry, Semantic and temporal knowledge},
abstract = {Image-based object detection provides a valuable basis for site information retrieval and construction progress monitoring. Machine learning approaches, such as neural networks, are able to provide reliable detection rates. However, labeling of training data is a tedious and time-consuming process, as it must be performed manually for a substantial number of images. The paper presents a novel method for automatically labeling construction images based on the combination of 4D Building Information Models and an inverse photogrammetry approach. For the reconstruction of point clouds, which are often used for progress monitoring, a large number of pictures are taken from the site. By aligning the Building Information Model and the resulting point cloud, it is possible to project any building element of the BIM model into the acquired pictures. This allows for automated labeling as the semantic information of the element type is provided by the BIM model and can be associated with the respective regions. The labeled data can subsequently be used to train an image-based neural network. Since the exact regions for all elements are defined, labels can be generated for basic tasks like classification as well as more complex tasks like semantic segmentation. To prove the feasibility of the developed methods, the labeling procedure is applied to several real-world construction sites, providing over 30,000 automatically labeled elements. The correctness of the assigned labels has been validated by pixel based area comparison against manual labels.}
}
@article{STOCKER2022105930,
title = {Scaling up UAVs for land administration: Towards the plateau of productivity},
journal = {Land Use Policy},
volume = {114},
pages = {105930},
year = {2022},
issn = {0264-8377},
doi = {https://doi.org/10.1016/j.landusepol.2021.105930},
url = {https://www.sciencedirect.com/science/article/pii/S0264837721006530},
author = {Claudia Stöcker and Rohan Bennett and Mila Koeva and Francesco Nex and Jaap Zevenbergen},
keywords = {UAV technology, Cadastral mapping, Diffusion of innovation, Technology adoption, Fit-for-purpose land administration},
abstract = {Unmanned aerial vehicles (UAVs) are considered an innovative tool for land administration. However, despite the prospects and market opportunities in the domain, there is a gap between experimentation and widespread technology diffusion. In this work, the Framework for Effective Land Administration (FELA) and the Hype Cycle concept are integrated to understand the dynamics of the innovation process of UAVs for the land administration sector. Empirical data stems from literature and interviews of UAV and land administration experts worldwide. The majority of experts estimate UAV technology to be in a phase in which the innovation needs to overcome initial unmet expectations to foster market development and increased adoption. The assessment indicates the changing importance of different FELA pathways during this process. Enabling laws and policies and supporting governance, accountability and institutions are crucial to create such a UAV-friendly national ecosystem early on and allay exaggerated expectations. Once this ecosystem has been made, market demand is expected to surge driven by partnerships, adapted standards, tech advocacy and awareness-raising campaigns, highlighting the superiority of high-resolution data amongst other benefits of UAV technology. These insights can be used as a baseline to direct national strategic decisions towards the increased adoption of UAVs in land administration.}
}
@article{DUO2021102592,
title = {Joint robust 3D trajectory and communication design for dual-UAV enabled secure communications in probabilistic LoS channel},
journal = {Ad Hoc Networks},
volume = {121},
pages = {102592},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102592},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521001293},
author = {Bin Duo and Yilian Li and Hao Hu and Junsong Luo and Yanmei Hu and Zibin Wang},
keywords = {UAV communication, Physical-layer security, Secrecy rate maximization, Robust 3D trajectory design, Joint optimization, Probabilistic LoS channel},
abstract = {This paper considers a dual-unmanned aerial vehicle (UAV) enabled secure communication system under the probabilistic line-of-sight (LoS) channel model. Specifically, one UAV transmits confidential information to multiple ground nodes while the other UAV cooperatively sends jamming signals to confuse a potential ground eavesdropper. We maximize the minimum worst-case average (expected) secrecy rate of the considered system, by jointly optimizing the communication scheduling, robust three-dimensional (3D) trajectories, transmit/jamming powers of both the UAVs for a given flight duration. However, the formulated problem is difficult to obtain a globally optimal solution due to the imperfect location information of the eavesdropper and its non-convex constraints. As such, we first derive an approximated (expected) secrecy rate with high accuracy, based on which we solve it by applying the block coordinate descent and successive convex approximation techniques to obtain its suboptimal solution. Simulation results show that the superiority of the proposed algorithm in urban environments, compared to other benchmarks.}
}
@article{LI2021100057,
title = {Understanding rooftop PV panel semantic segmentation of satellite and aerial images for better using machine learning},
journal = {Advances in Applied Energy},
volume = {4},
pages = {100057},
year = {2021},
issn = {2666-7924},
doi = {https://doi.org/10.1016/j.adapen.2021.100057},
url = {https://www.sciencedirect.com/science/article/pii/S2666792421000494},
author = {Peiran Li and Haoran Zhang and Zhiling Guo and Suxing Lyu and Jinyu Chen and Wenjing Li and Xuan Song and Ryosuke Shibasaki and Jinyue Yan},
keywords = {PV, Computer vision, Deep learning, Satellite and aerial image, Semantic segmentation},
abstract = {The photovoltaic (PV) industry boom and increased PV applications call for better planning based on accurate and updated data on the installed capacity. Compared with the manual statistical approach, which is often time-consuming and labor-intensive, using satellite/aerial images to estimate the existing PV installed capacity offers a new method with cost-effective and data-consistent features. Previous studies investigated the feasibility of segmenting PV panels from images involving machine learning technologies. However, due to the particular characteristics of PV panel semantic-segmentation, the machine learning tools need to be designed and applied with careful considerations of the issue formulation, data quality, and model explainability. This paper investigated the characteristics of PV panel semantic-segmentation from the perspective of computer vision. The results reveal that the PV panel image data has several specific characteristics: highly class-imbalance and non-concentrated distribution; homogeneous texture and heterogenous color features; and the notable resolution threshold for effective semantic-segmentation. Moreover, this paper provided recommendations for data obtaining and model design, aiming at each observed character from the viewpoints of recent solutions in computer vision, which can be helpful for future improvement of the PV panel semantic-segmentation.}
}
@article{FU2020107324,
title = {Surrounding-aware correlation filter for UAV tracking with selective spatial regularization},
journal = {Signal Processing},
volume = {167},
pages = {107324},
year = {2020},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2019.107324},
url = {https://www.sciencedirect.com/science/article/pii/S0165168419303779},
author = {Changhong Fu and Weijiang Xiong and Fuling Lin and Yufeng Yue},
keywords = {Unmanned aerial vehicle (UAV), Visual object tracking, Discriminative correlation filter, Surrounding information, Selective spatial regularization},
abstract = {The great advance of visual object tracking has provided unmanned aerial vehicle (UAV) with intriguing capability for various practical applications. With promising performance and efficiency, discriminative correlation filter-based trackers have drawn great attention and undergone remarkable progress. However, background interference and boundary effect remain two thorny problems. In this paper, a surrounding-aware tracker with selective spatial regularization (SASR) is presented. SASR tracker extracts surrounding samples according to the size and shape of the object in order to utilize context and maintain the integrality of the object. Additionally, a selective spatial regularizer is introduced to address boundary effect. Central coefficients in the filter are evenly regularized to preserve valid information from the object. While the others are penalized according to their spatial location. Under the framework of SASR tracker, surrounding information and selective spatial regularization prove to be complementary to each other, which actually did not draw much attention before. They managed to improve not only the robustness against various distractions in the surrounding but also the flexibility to catch up with frequent appearance change of the object. Qualitative evaluation and quantitative experiments on challenging UAV tracking sequences have shown that SASR tracker has performed favorably against 23 state-of-the-art trackers.}
}
@article{LI201955,
title = {Optimal Tracking Control Based on Integral Reinforcement Learning for An Underactuated Drone},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {8},
pages = {55-60},
year = {2019},
note = {10th IFAC Symposium on Intelligent Autonomous Vehicles IAV 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.08.048},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319303684},
author = {Shaobao Li and Petar Durdevic and Zhenyu Yang},
keywords = {Reinforcement learning, optimal control, neural network, inner-outer loop control},
abstract = {A drone is desirable to perform various flying missions with different loads while always guaranteeing optimal flying performance. In this paper, an integral reinforcement learning algorithm is developed for a drone such that it can learn optimal control policy online. The drone is described by an underactuated nonlinear model and the inner-outer loop control strategy is applied for the navigation control. In the outer loop an optimal controller is designed to minimize a cost function with input saturation, and a policy iteration based integral reinforcement learning (IRL) algorithm is proposed. Critic-actor neural networks (NNs) are further applied for online implementation of the IRL algorithm. In the inner loop a quaternion based feedback attitude controller is designed to guarantee system stability. A simulation study is finally provided to demonstrate the effectiveness of the proposed IRL algorithm.}
}
@article{ZHANG20208163,
title = {Path-following Control of Fish-like Robots: A Deep Reinforcement Learning Approach ⁎⁎This work was supported in part by grants from the National Natural Science Foundation of China (NSFC, No. 61973007, 61633002, U1909206.},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {8163-8168},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.2306},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320329724},
author = {Tianhao Zhang and Runyu Tian and Chen Wang and Guangming Xie},
keywords = {Reinforcement learning control, autonomous underwater vehicles, biomimetic underwater robots, path following, deep learning},
abstract = {In this paper, we propose a deep reinforcement learning (DRL) approach for path-following control of a fish-like robot. The desired path may be a randomly generated Bézier curve. First, to implement the locomotion control of the fish-like robot, we design a modified Central Pattern Generated (CPG) model, using which the fish achieves varied swimming behaviors just by adjusting a single control input. To reduce the reality gap between simulation and the physical system, using the experimental data of the real fish-like robot, we build a surrogate simulation environment, which also well balances the accuracy and the speed of training. Second, for the path-following control, we select the advantage actor-critic (A2C) approach and train the control policy in the surrogate simulation environment with a straight line as the desired path. Then the trained control policy is directly deployed on a physical fish-like robot to follow a randomly generated Bézier curve. The experimental results show that our proposed approach has good practical applicability in view of its efficiency and feasibility in controlling the physical fishlike robot. This work shows a novel and promising way to control biomimetic underwater robots in the real world.}
}
@article{NASH2021108650,
title = {Tracking the fine scale movements of fish using autonomous maritime robotics: A systematic state of the art review},
journal = {Ocean Engineering},
volume = {229},
pages = {108650},
year = {2021},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2021.108650},
url = {https://www.sciencedirect.com/science/article/pii/S0029801821000858},
author = {John Zachary Nash and Jenny Bond and Michael Case and Ian McCarthy and Ryan Mowat and Iestyn Pierce and William Teahan},
keywords = {Maritime robotics, AUV, ASV, Underwater robotics, Acoustic telemetry, Fish tracking},
abstract = {This paper provides a systematic state of the art review on tracking the fine scale movements of fish with the use of autonomous maritime robotics. Knowledge of migration patterns and the localization of specific species of fish at a given time is vital to many aspects of conservation. This paper reviews these technologies and provides insight into what systems are being used and why. The review results show that a larger amount of complex systems that use a deep learning techniques are used over more simplistic approaches to the design. Most results found in the study involve Autonomous Underwater Vehicles, which generally require the most complex array of sensors. The results also provide insight into future research such as methods involving swarm intelligence, which has seen an increase in use in recent years. This synthesis of current and future research will be helpful to research teams working to create an autonomous vehicle with intentions to track, navigate or survey.}
}
@article{KHANAL2021104880,
title = {Assessing the impact of agricultural field traffic on corn grain yield using remote sensing and machine learning},
journal = {Soil and Tillage Research},
volume = {208},
pages = {104880},
year = {2021},
issn = {0167-1987},
doi = {https://doi.org/10.1016/j.still.2020.104880},
url = {https://www.sciencedirect.com/science/article/pii/S0167198720306620},
author = {Sami Khanal and Andrew Klopfenstein and Kushal KC and Venkatesh Ramarao and John Fulton and Nathan Douridas and Scott A. Shearer},
keywords = {Soil compaction, Pinch rows, Corn yield, Remote sensing, Machine learning},
abstract = {With the increase in the physical size of agricultural field machinery, producers can experience negative effects of machinery-induced soil compaction on soil health and crop productivity. Traditionally, the impact of compaction from machinery traffic on crop yield has been examined either by hand harvesting of crops or by using yield maps generated using yield monitors mounted on combines at the time of harvest. While a hand harvesting approach is time consuming, laborious and subjective, yield maps generated from yield monitors are too coarse in resolution to truly assess the yield differences between individual crop rows. Remote sensing technology offers a cost- and time-effective approach to generate high-resolution yield maps that can be used to assess crop yields of individual rows or areas within a row and, thus, the impacts of field traffic on crop yield. The objectives of this study were to: (1) develop a framework to predict crop grain yield at both the centimeter scale and individual row level by integrating remote sensing and field collected data, and (2) use the predicted yield map to assess the impact of field traffic during planting on corn grain yield. Field experiments were conducted in three corn fields, each in 2016, 2017, and 2018, at the Molly Caren Agricultural Center, London, Ohio, to evaluate yield impact of field traffic at planting. Data collected included corn grain yield based on yield monitors and hand-harvesting, and aerial (i.e., visible and multispectral) imagery collected during the corn growing season. Corn grain yield was predicted using six machine learning algorithms (i.e., linear regression, random forest regression, support vector machine, stochastic gradient boosting model, neural network, and cubist). The results from the high-resolution yield maps were consistent with hand-harvest and yield-monitor data. Models using a cubist algorithm predicted corn grain yield with R2 of 0.76, 0.61 and 0.88 for fields F11, F8A and F7, respectively. Based on high-resolution corn grain yield maps, yield differences between rows that were most impacted by tires (i.e., pinch rows) and least impacted (i.e., non-pinch rows) at the time of planting were less than 0.1 t ha−1 and not significant. Corn grain yield varied based on the soil landscape in the field, with 39–75 % of the field showing higher corn grain yield in non-pinch rows than pinch rows. The developed framework could also be applied to assess the effect of other field management practices on crop yield with higher accuracy and resolution.}
}
@article{LI202111,
title = {Optimal trajectory and downlink power control for multi-type UAV aerial base stations},
journal = {Chinese Journal of Aeronautics},
volume = {34},
number = {9},
pages = {11-23},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.12.019},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120305720},
author = {Lixin LI and Yan SUN and Qianqian CHENG and Dawei WANG and Wensheng LIN and Wei CHEN},
keywords = {Mean-Field-Type Game (MFTG), Power control, Q-learning, Trajectory, Unmanned Aerial Vehicle (UAV)},
abstract = {Unmanned Aerial Vehicles (UAVs) enabled Aerial Base Stations (UABSs) have been studied widely in future communications. However, there are a series of challenges such as interference management, trajectory design and resource allocation in the scenarios of multi-UAV networks. Besides, different performances among UABSs increase complexity and bring many challenges. In this paper, the joint downlink transmission power control and trajectory design problem in multi-type UABSs communication network is investigated. In order to satisfy the signal to interference plus noise power ratio of users, each UABS needs to adjust its position and transmission power. Based on the interactions among multiple communication links, a non-cooperative Mean-Field-Type Game (MFTG) is proposed to model the joint optimization problem. Then, a Nash equilibrium solution is solved by two steps: first, the users in the given area are clustered to get the initial deployment of the UABSs; second, the Mean-Field Q (MFQ)-learning algorithm is proposed to solve the discrete MFTG problem. Finally, the effectiveness of the approach is verified through the simulations, which simplifies the solution process and effectively reduces the energy consumption of each UABS.}
}
@article{MENG2021231,
title = {A data-driven intelligent planning model for UAVs routing networks in mobile Internet of Things},
journal = {Computer Communications},
volume = {179},
pages = {231-241},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S014036642100308X},
author = {Dian Meng and Yang Xiao and Zhiwei Guo and Alireza Jolfaei and Lanxia Qin and Xinting Lu and Qiao Xiang},
keywords = {Internet of Things, UAVs routing networks, Intelligent data analysis, Optimal planning},
abstract = {Owing to constant progress of wireless communications, the Unmanned Aerial Vehicles (UAVs) routing networks (UAVs-RN) under mobile Internet of Things (MIoT) have been prevalent tools to deal with natural emergencies. But the achievement of effective responses and proper utility, still remains a challenging task. It is required to analyze multi-source data of UAVs-RN, so that optimal planning schemes under MIoT can be found. To bridge such gap, this work mainly takes three aspects of factors into consideration: rapid response, finite budget and uncertain signal fading. Accordingly, a data-driven intelligent planning model for UAVs-RN under MIoT, is put forward in this paper. Data about wildfire happened in local areas of Australia is selected to build experimental scenarios. And two kinds of UAVs, Surveillance and Situational Awareness drones and Radio Repeater drones, are considered in this study. Firstly, the source data is visualized and the internal trend is analyzed to verify true validity. Then, a multi-objective planning model is accordingly established to aggregate multi-source data. At last, a case study is deeply investigated on real-world data to assess the proposed approach and suggest feasible planning schemes.}
}
@article{WANG2021112631,
title = {Satellite remote sensing of pelagic Sargassum macroalgae: The power of high resolution and deep learning},
journal = {Remote Sensing of Environment},
volume = {264},
pages = {112631},
year = {2021},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112631},
url = {https://www.sciencedirect.com/science/article/pii/S0034425721003515},
author = {Mengqiu Wang and Chuanmin Hu},
keywords = {Landsat-8, Sentinel-2, MSI, OLI, Worldview-2, Dove, MODIS, FAI, , Clouds, Feature extraction, Deep convolution neural network, Deep learning, U-net, VGGUnet},
abstract = {In recent years, massive blooms of pelagic Sargassum have occurred in the Atlantic Ocean, Caribbean Sea, and Gulf of Mexico, and satellite imagery have been used operationally to monitor and track the blooms. However, limited by the coarse resolution and other confounding factors, there is often a data gap in nearshore waters, and the uncertainties in the estimated Sargassum abundance in offshore waters are also unclear. Higher-resolution satellite data may overcome these limitations, yet such a potential is hindered by the lack of reliable methods to accurately detect and quantify Sargassum in an automatic fashion. Here, we address this challenge by combining large quantities of high-resolution satellite data with deep learning. Specifically, data from the Multispectral Instrument (MSI, 10–20 m), Operational Land Imager (OLI, 30 m), WorldView-II (WV-2, 2 m), and PlanetScope/Dove (3 m) are used with a deep convolution neural network (DCNN) to extract Sargassum features and quantify Sargassum biomass density or areal coverage. By utilizing the U-net architecture and the pre-trained weights from the VGG16 model, the DCNN (i.e., the VGGUnet model) can extract Sargassum features while discarding other confusing features (waves, currents, phytoplankton blooms, clouds, cloud shadows, or striping noise). For Sargassum biomass estimated from OLI and MSI images, results indicate an accuracy of ~92% and 90%, respectively, when evaluated using images from the same sensor. When Sargassum areal coverage is estimated from WV-2 and Dove images, there is an accuracy of ~98% and 82%, respectively. When different sensors are cross-compared, OLI reveals ~30% more Sargassum biomass than MODIS from 14 OLI images collected in the Caribbean Sea (path/row: 001/050) for their commonly viewed observable areas, and ~ 180% more Sargassum biomass than MSI (N = 15, path/row: 001/050); such differences appear systematic (R2 = 0.98 and 0.73, respectively). Compared to the quasi-simultaneous MSI, OLI, and MODIS images, Dove shows higher Sargassum coverage. Higher-resolution sensors tend to observe more Sargassum because they can detect smaller-scale features that are missed by the coarser-resolution sensors, although the difference varies with time and location. The morphological characteristics of Sargassum features from these high-resolution data are also reported to facilitate management actions. The findings here not only fill the knowledge gaps and coverage gaps from previous studies, but more importantly pave the road toward operational monitoring and tracking Sargassum features in nearshore waters.}
}
@article{WILKE2021106380,
title = {Assessment of plant density for barley and wheat using UAV multispectral imagery for high-throughput field phenotyping},
journal = {Computers and Electronics in Agriculture},
volume = {189},
pages = {106380},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106380},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921003975},
author = {Norman Wilke and Bastian Siegmann and Johannes A. Postma and Onno Muller and Vera Krieger and Ralf Pude and Uwe Rascher},
keywords = {Plant density, Germination rate, Barley, Wheat, High-throughput phenotyping, UAV},
abstract = {Cereal plant density is a relevant agronomic trait in agriculture and high-throughput phenotyping of plant density is important for the decision-making process in precision farming and breeding. It influences the water as well as the fertilization requirements, the intraspecific competition, and the occurrence of weeds or pathogens. Recent studies have determined plant density using machine-learning approaches and feature extraction. This requires spatially very highly resolved images (0.02 cm) because the accuracy distinctly decreased when images had lower resolution. In this study, we present an approach that uses the linear relationship between plant density manually counted in the field and fractional cover derived from a RGB and a multispectral camera equipped on an unmanned aerial vehicle (UAV). We assumed that at an early seedling stage fractional cover is closely related to the number of plants. Spring barley and spring wheat experiments, each with three genotypes and four different sowing densities, were examined. The practicability and repeatability of the methodology were evaluated with an independent experiment consisting of 42 winter wheat genotypes. This experiment mainly differed for genotypes, sowing density and season. The empirical regression models that make us of multispectral images having a GSD of 0.69 cm were able to determine plant density with a high prediction accuracy for barley and wheat (R2 > 0.91, mean absolute error (MAE) < 28 plants). In addition, prediction accuracy only slightly declines for multispectral image data having 1.4 cm GSD or RGB image data having 0.6 cm GSD (MAE < 35 plants m−2). BBCH stage 13 was identified as the ideal growth stage in which the plants were large enough to accurately determine fractional cover even from the lower resolution image data. Moreover, a developed empirical regression model was transferred to an independent experimental field verifying its robustness across different conditions. The prediction accuracy of UAV estimated plant density showed an R2 value of 0.83 and an MAE of less than 21 plants m−2. Furthermore, manual measurements of 11 randomly selected plots proved sufficient for a user-based training of the regression model (R2 = 0.83, MAE < 23 plants m−2) adapted to the independent experimental field. The method and the use of UAV image data enable high-throughput phenotyping of cereal plant density with uncertainties of less than 10 %.The practicability, repeatability and robustness of the developed approach were demonstrated in this study.}
}
@article{MAYER2021100005,
title = {Deep learning approach for Sentinel-1 surface water mapping leveraging Google Earth Engine},
journal = {ISPRS Open Journal of Photogrammetry and Remote Sensing},
volume = {2},
pages = {100005},
year = {2021},
issn = {2667-3932},
doi = {https://doi.org/10.1016/j.ophoto.2021.100005},
url = {https://www.sciencedirect.com/science/article/pii/S2667393221000053},
author = {Timothy Mayer and Ate Poortinga and Biplov Bhandari and Andrea P. Nicolau and Kel Markert and Nyein Soe Thwal and Amanda Markert and Arjen Haag and John Kilbride and Farrukh Chishtie and Amit Wadhwa and Nicholas Clinton and David Saah},
keywords = {Image segmentation, Synthetic aperture radar, Surface water mapping, Deep learning, U-net, Google earth engine},
abstract = {Satellite remote sensing plays an important role in mapping the location and extent of surface water. A variety of approaches are available for mapping surface water, but deep learning approaches are not commonplace as they are ‘data hungry’ and require large amounts of computational resources. However, with the availability of various satellite sensors and rapid development in cloud computing, the remote sensing scientific community is adapting modern deep learning approaches. The new integration of cloud-based Google AI platform and Google Earth Engine enables users to deploy calculations at scale. In this paper, we investigate two methods of automatic data labeling: 1. the Joint Research Centre (JRC) surface water maps; 2. an Edge-Otsu dynamic threshold approach. We deployed a U-Net convolutional neural network to map surface water from Sentinel-1 Synthetic Aperture Radar (SAR) data and tested the model performance using different hyperparameter tuning combinations to identify the optimal learning rate and loss function. The performance was then evaluated using an independent validation data set. We tested 12 models overall and found that the models utilizing the JRC data labels showed a better model performance, with F1-scores ranging from 0.972 to 0.986 for the training test and validation efforts. Additionally, an independently sampled high-resolution data set was used to further evaluate model performance. From this independent validation effort we observed models leveraging JRC data labels produced F1-Scores ranging from 0.9130.922. A pairwise comparison of models, through varying input data, learning rates, and loss functions constituents, revealed the JRC Adjusted Binary Cross Entropy Dice model to be statistically different than the 66 other model combinations and displayed the highest relative evaluations metrics including accuracy, precision score, Cohen Kappa coefficient, and F1-score. These results are in the same range as many of the conventional methods. We observed that the integration of Google AI Platform into Google Earth Engine can be a powerful tool to deploy deep-learning algorithms at scale and that automatic data labeling can be an effective strategy in the development of deep-learning models, however independent data validation remains an important step in model evaluation.}
}
@article{SHIN2021106042,
title = {A deep learning approach for RGB image-based powdery mildew disease detection on strawberry leaves},
journal = {Computers and Electronics in Agriculture},
volume = {183},
pages = {106042},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106042},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921000600},
author = {Jaemyung Shin and Young K. Chang and Brandon Heung and Tri Nguyen-Quang and Gordon W. Price and Ahmad Al-Mallahi},
keywords = {Disease detection, Powdery mildew, Deep learning, Convolutional neural network, Artificial intelligence},
abstract = {In this study, Deep Learning (DL) was used to detect powdery mildew (PM), persistent fungal disease in strawberries to reduce the amount of unnecessary fungicide use, and the need for field scouts. This study optimised and evaluated several well-established learners, including AlexNet, SqueezeNet, GoogLeNet, ResNet-50, SqueezeNet-MOD1, and SqueezeNet-MOD2. Data augmentation was carried out from among 1450 healthy and infected leaf images to prevent overfitting and to consider the various shapes and direction of the leaves in the field. A total of eight clockwise rotations (0°; the original data, 45°, 90°, 135°, 180°, 225°, 270°, and 315°) was performed to generate 11,600 data points. Overall, the six DL algorithms that were used in this study showed on average of >92% in classification accuracy (CA). ResNet-50 gave the highest CA of 98.11% in classifying the healthy and infected leaves; however, considering the computation time, AlexNet had the fastest processing time, at 40.73 s, to process 2320 images with a CA of 95.59%.When considering the memory requirements for hardware deployment, SqueezeNet-MOD2 would be recommended for PM detection on strawberry leaves with a CA of 92.61%.}
}
@article{RODRIGUEZ2021106061,
title = {Assessment of potato late blight from UAV-based multispectral imagery},
journal = {Computers and Electronics in Agriculture},
volume = {184},
pages = {106061},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106061},
url = {https://www.sciencedirect.com/science/article/pii/S016816992100079X},
author = {Jorge Rodríguez and Iván Lizarazo and Flavio Prieto and Victor Angulo-Morales},
keywords = {Late blight, UAV, Machine learning, Potato, Agriculture},
abstract = {This paper evaluates a method for assessment and detection of potato late blight using UAV-based multispectral imagery. Traditional methods of detection and mapping of late blight are time consuming, require large human effort and, in many cases, are subjective. The approach evaluated integrates morphological operations and evaluates the performance of five Machine Learning (ML) algorithms: Random forest, Gradient Boosting Classifier, Support Vector Classifier, Linear Support Vector Classifier and K-Nearest Neighbours Classifier to detect zones of late blight occurrence. The main components of the proposed approach are: (i) radiometric and geometric correction of raw images; (ii) soil and weed removal by application of a thresholding technique; (iii) a supervised classification procedure using ML algorithms; and (iv) use of trained models to classify a new data set. The performance of the method is evaluated on two dates in an experimental potato field. Results showed that the Linear Support Vector Classifier and Random Forest algorithms had the best performance in terms of both accuracy metrics and run time. The study showed that the proposed method allows the detection of late blight with little human intervention.}
}
@article{ALFEO201934,
title = {Enhancing biologically inspired swarm behavior: Metaheuristics to foster the optimization of UAVs coordination in target search},
journal = {Computers & Operations Research},
volume = {110},
pages = {34-47},
year = {2019},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2019.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S0305054819301340},
author = {Antonio L. Alfeo and Mario G.C.A. Cimino and Gigliola Vaglini},
keywords = {UAVs, Swarm intelligence, Stigmergy, Flocking, Differential evolution, Distributed targets search},
abstract = {Recent miniaturization in Unmanned Aerial Vehicles (UAVs) technology encourages the use of many small UAVs for search missions in unknown environments, provided that the autonomous and adaptive coordination logic can be effective. In this research field, biologically inspired metaheuristics have been proposed to mimics swarms, flocks, and other coordination schemas. The design and management of such systems is a research challenge when considering (i) combination and optimization of multiple metaheuristics and (ii) enhancements of biologically inspired metaheuristic through technological advances. In this paper the swarm coordination of UAVs employed in target search is based on flocking and stigmergy, to provide robust formation control and dynamic environmental information sharing, respectively. The design of both metaheuristics takes into account UAVs equipment, and the coordination logic is adapted to the mission by means of a differential evolutionary algorithm. This algorithm optimizes the aggregated structural parameters of all metaheuristics to allow the most efficient coordination with respect to the mission environment. Some possible enhancements of stigmergy are studied by simulating target search tasks on synthetic and real-world scenarios.}
}
@article{ZHAO2022108515,
title = {Analysis of UAV lidar information loss and its influence on the estimation accuracy of structural and functional traits in a meadow steppe},
journal = {Ecological Indicators},
volume = {135},
pages = {108515},
year = {2022},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2021.108515},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X21011808},
author = {Xiaoxia Zhao and Yanjun Su and Tianyu Hu and Mengqi Cao and Xiaoqiang Liu and Qiuli Yang and Hongcan Guan and Lingli Liu and Qinghua Guo},
keywords = {UAV lidar, Information loss, TLS, Structural trait, Functional trait},
abstract = {Accurate quantification of grassland structural and functional traits is the foundation for grassland management and restoration. Light detection and ranging (lidar), especially the unmanned aerial vehicle (UAV) lidar, has been recognized as an accurate and effective technique for local to regional-scale vegetation structural and functional traits estimation. However, in grassland ecosystems, it is more likely to be influenced by UAV lidar information loss caused by dense vegetation canopies. In this study, we investigated how UAV lidar information loss may occur and how it may influence the estimation accuracy of grassland structural and functional traits by comparing it with terrestrial laser scanning (TLS) and field measurements in a meadow steppe of northern China. Five structural traits (i.e., mean vegetation height, maximum vegetation height, standard deviation of vegetation height, canopy cover, and canopy volume) and one functional trait (i.e., aboveground biomass) were estimated from the UAV lidar data and TLS data for evaluation. The results showed that TLS-derived structural and functional traits had a much higher accuracy than UAV lidar-derived traits. By comparing with TLS data, we found that UAV lidar data had a much more prevailing information loss at canopy tops than at canopy bottoms. The average height loss of UAV lidar at canopy tops reached over 0.30 m, and the average relative height loss reached over 49%, comparing to a value of 0.03 m and 6% at canopy bottoms. Maximum vegetation height, standard deviation, and the distance from the UAV lidar system to the ground were the three most influential factors on UAV lidar information loss at canopy tops, indicating the commonly seen sharp canopy tops of grasslands were prone to be missed by the UAV lidar system. UAV lidar information loss at canopy tops had a much stronger influence on the estimation accuracy of grassland structural and functional traits than that at canopy bottoms. With the decrease of information loss at canopy tops, UAV lidar can be used to extract grassland structural and functional traits with a comparable accuracy to TLS. Among the five grassland traits, aboveground biomass was the least influenced by UAV lidar information loss. This study is a very first evaluation on the UAV lidar information loss in grassland ecosystems and its influence on grassland structural and functional trait estimation, which can provide guidance for UAV lidar data collection and processing in future grassland applications.}
}
@article{ALIPOUR2020110157,
title = {Increasing the robustness of material-specific deep learning models for crack detection across different materials},
journal = {Engineering Structures},
volume = {206},
pages = {110157},
year = {2020},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2019.110157},
url = {https://www.sciencedirect.com/science/article/pii/S0141029619304389},
author = {Mohamad Alipour and Devin K. Harris},
keywords = {Computer vision, Deep learning, Transportation infrastructure, Inspection, Convolutional neural networks, Crack detection},
abstract = {Infrastructure defect detection solutions based on computer vision have recently emerged as powerful tools with applications in both traditional inspection practices, as well as robotic inspections. These applications involve the collection of images from a wide range of infrastructure systems with heterogeneous characteristics such as conditions, materials, surface appearances and textures. Consequently, defect detection models need to be sufficiently robust to accommodate this type of heterogeneity. Existing image-based crack detection literature almost entirely focuses on models tailored to crack detection in either concrete or asphalt surfaces with prior knowledge of the material involved and studies on crack detection in more than one material are needed for truly automated inspection systems. This paper focuses on the adaptability of deep learning-based crack detection models across common construction materials. To investigate this problem, a residual convolutional neural network architecture was trained and tested on two separate concrete and asphalt crack image data sets and compared with existing baselines. These tests demonstrated that the change of material significantly reduces crack detection accuracy of a tailored model. In response, three domain adaptation techniques, namely joint training, sequential training, and ensemble learning are proposed and implemented to develop robust crack detection models that work on both datasets regardless of the material environment. Results demonstrate that the proposed techniques are able to successfully produce accuracies comparable to those of the material-specific models, without prior knowledge of the material.}
}
@article{WEIDNER2021106344,
title = {The influence of training data variability on a supervised machine learning classifier for Structure from Motion (SfM) point clouds of rock slopes},
journal = {Engineering Geology},
volume = {294},
pages = {106344},
year = {2021},
issn = {0013-7952},
doi = {https://doi.org/10.1016/j.enggeo.2021.106344},
url = {https://www.sciencedirect.com/science/article/pii/S0013795221003550},
author = {Luke Weidner and Gabriel Walton},
abstract = {Supervised Machine Learning (ML) can be used to automatically interpret remote sensing data in engineering geology, with applications for rockfall and landslide characterization. However, supervised algorithms typically require very large training databases from which to learn predictive relationships, and there is little guidance on how to construct such a database in an earth science context with high temporal and spatial heterogeneity. This study builds a supervised classifier to perform basic rock slope characterization on Structure from Motion (SfM) point clouds collected under a variety of conditions. Eight datasets were collected in Colorado and Utah, USA, with multiple different sensor platforms (terrestrial and aerial), rock types, seasons, and lighting conditions, and each dataset was manually labeled to identify regions of vegetation, rock, soil, talus, and snow. A total of 2560 Random Forest models were built with different combinations of training datasets and combinations of geometric and color features. Most models were able to identify vegetation and rock with high accuracy (median F scores of 86% and 68% respectively), but performance for soil, talus, and snow was overall much poorer, and the median overall accuracy of generalized classifiers was 60%. Many characteristics of the training data were found to have significant effects on generalization accuracy, indicating that training datasets must be curated to be applicable to specific data collection parameters, seasons, lighting conditions, and geological settings. We conclude that high accuracy generalized results can be obtained, but the ML model must be carefully constructed, and its limitations acknowledged.}
}
@article{KUMAR2021107440,
title = {Security and privacy-aware Artificial Intrusion Detection System using Federated Machine Learning},
journal = {Computers & Electrical Engineering},
volume = {96},
pages = {107440},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107440},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621004006},
author = {K.P. Sanal Kumar and S Anu H Nair and Deepsubhra {Guha Roy} and B. Rajalingam and R. Santhosh Kumar},
keywords = {Beyond 5G, Edge intelligence, Paillier Homomorphic Encryption, Differential privacy, Artificial Immune System, Intrusion Detection System},
abstract = {Beyond 5G networks integrating 5G technology offer efficient services globally with sustainable higher capacity and much lower latency across various applications. Moving into the beyond 5G networks, edge intelligence solutions with data-driven machine learning algorithms and cybersecurity paradigms have become crucial among various real-time applications, including smart transportation, smart health, etc. Since the data gets transferred continuously from the edge devices to the dedicated computing in any edge computing environment, it experiences a higher risk of vulnerability and complexity measures. In this view, this paper firstly defines a federated machine learning mechanism for privacy-enhanced edge intelligence model Beyond 5G networks with Paillier Homomorphic Encryption and differential privacy. Secondly, an Artificial Immune Intrusion Detection System has been designed to monitor and classify the nodes resulting in an anomaly in the edge network so that the network can experience smooth and secure data transmission as per the requirement. The experiments and comparison results show that the proposed system is more optimal and secure than the existing edge security models.}
}
@article{LI2022101814,
title = {Distributed deep reinforcement learning-based coordination performance optimization method for proton exchange membrane fuel cell system},
journal = {Sustainable Energy Technologies and Assessments},
volume = {50},
pages = {101814},
year = {2022},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2021.101814},
url = {https://www.sciencedirect.com/science/article/pii/S2213138821008286},
author = {Jiawen Li and Bo Yang and Tao Yu},
keywords = {Metaverse, Metaverse-based multi-agent double delay deep deterministic policy gradient algorithm, Proton exchange membrane fuel cell (PEMFC), Power coordination management method, Distributed deep reinforcement learning},
abstract = {A proton exchange membrane fuel cell (PEMFC) is a multi-input multi-output nonlinear complicated system, the output power and operating efficiency of which are affected by various operating variables. To achieve coordinated control of multiple operating variables and thus improve the stability, performance, and efficiency of the PEMFC power system, a data-driven power coordination management method is proposed. Furthermore, a metaverse-based multiagent double delay deep deterministic policy gradient (MET-MADDPG) algorithm is also presented. The design of this algorithm is structured on the concept of the metaverse in that it employs different metaverses during pre-learning and combines imitation learning and curriculum learning to enable agents in different combinations to be fully trained in different environments to improve coordination strategy robustness. In this algorithm, the hydrogen controller, air controller, water pump controller and radiator controller are regarded as four agents; the objective of the training is to enable agents with their different goals to coordinate. The effectiveness of the proposed algorithm is demonstrated in a series of experiments in which it is compared with existing algorithms.}
}
@article{HAN2022103190,
title = {A classification method for EEG motor imagery signals based on parallel convolutional neural network},
journal = {Biomedical Signal Processing and Control},
volume = {71},
pages = {103190},
year = {2022},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.103190},
url = {https://www.sciencedirect.com/science/article/pii/S1746809421007874},
author = {Yuexing Han and Bing Wang and Jie Luo and Long Li and Xiaolong Li},
keywords = {Brain computer interface (BCI), Motor imagery (MI), Regularized common spatial pattern (RCSP), Short time fourier transform (STFT), Deep learning, Parallel convolutional neural network (PCNN)},
abstract = {Deep learning has been used popularly and successfully in state of art researches to classify different types of images. However, so far, the applications of deep learning methods for the electroencephalography (EEG) motor imagery classification is very limited. In this study, a pre-processing algorithm is proposed for the EEG signals representation. Then, a parallel convolutional neural network (PCNN) architecture is proposed to classify motor imagery signals. For the raw EEG signals representation, a new form of the images is created to combine spatial filtering and frequency bands extracting together. By feeding the represented images into the PCNN, it stacks three unique sub-models together aiming to optimize the performance of classification. The average accuracy of the proposed method achieves 83.0 ± 3.4% on BCI Competition IV dataset 2b, which outperforms the compared methods at least 5.2%. The average Kappa value of the proposed method achieves 0.659 ± 0.067 on dataset 2b, providing at least 20.5% improvement with respect to the compared algorithms. The results show that the proposed method performs better in EEG motor imagery signals classification.}
}
@article{GUO2021108566,
title = {Mechanical fault time series prediction by using EFMSAE-LSTM neural network},
journal = {Measurement},
volume = {173},
pages = {108566},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2020.108566},
url = {https://www.sciencedirect.com/science/article/pii/S0263224120310897},
author = {Jianwen Guo and Zhenpeng Lao and Ming Hou and Chuan Li and Shaohui Zhang},
keywords = {Mechanical equipment, Error fusion of multiple SAEs, Long short-term memory, Multi-threshold, Prediction},
abstract = {The working state of mechanical parts plays an important role in the safe and reliable operation of equipment. Therefore, in order to enhance the dependability and security of mechanical equipment, it is very important to accurately predict the changing trend of mechanical components in advance. This paper proposes a method combining error fusion of multiple sparse auto-encoders with long short-term memory for predicting mechanical fault time series. First, error fusion of multiple sparse auto-encoders layer can extract multi-feature time series and fuse them into a square prediction error trend curve representing each channel and a threshold control line of bearing system health judgment. Then, long short-term memory layer predicts the irregular trend in the square prediction error trend curve, and sets a number of threshold control lines according to different machine fault variation trends for more accurate prediction. The experimental results prove the availability and superiority of this method in the prediction of mechanical fault time series.}
}
@article{CHENG20218811,
title = {Robust finite-time cooperative formation control of UGV-UAV with model uncertainties and actuator faults},
journal = {Journal of the Franklin Institute},
volume = {358},
number = {17},
pages = {8811-8837},
year = {2021},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2021.08.038},
url = {https://www.sciencedirect.com/science/article/pii/S0016003221005238},
author = {Wanglei Cheng and Bin Jiang and Ke Zhang and Steven X. Ding},
abstract = {This paper investigates the finite-time cooperative formation control problem for a heterogeneous system consisting of an unmanned ground vehicle (UGV) - the leader and an unmanned aerial vehicle (UAV) - the follower. The UAV system under consideration is subject to modeling uncertainties, external disturbance as well as actuator faults simultaneously, which is associated with aerodynamic and gyroscopic effects, payload mass, and other external forces. First, a backstepping controller is developed to stabilize the leader system to track the desired trajectory. Second, a robust nonsingular fast terminal sliding mode surface is designed for UAV and finite-time position control is achieved using terminal sliding mode technique, which ensures the formation error converges to zero in finite time in the presence of actuator faults and other uncertainties. Furthermore, by combining the radial basis function neural networks (NNs) with adaptive virtual parameter technology, a novel NN-based adaptive nonsingular fast terminal sliding formation controller (NN-ANFTSMFC) is developed. By means of the proposed adaptive control strategy, both uncertainties and actuator faults can be compensated without the prior knowledges of the uncertainty bounds and fault information. By using the proposed control schemes, larger actuator faults can be tolerated while eliminating control chattering. In order to realize fast coordinated formation, the expected position trajectory of UAV is composed of the leader position information and the desired relative distance with UGV, based on local distributed theory, in the three-dimensional space. The tracking and formation controllers are proved to be stable by the Lyapunov theory and the simulation results demonstrate the effectiveness of proposed algorithms.}
}
@article{EJAZ2020150,
title = {Energy-efficient task scheduling and physiological assessment in disaster management using UAV-assisted networks},
journal = {Computer Communications},
volume = {155},
pages = {150-157},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.03.019},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419318638},
author = {Waleed Ejaz and Arslan Ahmed and Aliza Mushtaq and Mohamed Ibnkahla},
keywords = {Disaster management, Energy efficiency, Internet of Things, Unmanned aerial vehicles, Early warning score, Vital signs, Physiologic monitoring},
abstract = {Internet of Things (IoT) and unmanned aerial vehicles (UAVs) together can significantly enhance the performance of disaster management systems. UAVs can collect massive heterogeneous data from disaster-affected areas using fifth-generation (5G)/beyond 5G networks and this data can be analyzed to get the information required by the first responders such as marking the boundary of the affected area, identifying the infrastructure damaged and the roads blocked, and the health situation of people living in that area. This paper presents an overview of different platforms (UAVs-based, IoT-based, and IoT, coupled with UAVs) for disaster management. We propose an energy-efficient task scheduling scheme for data collection by UAVs from the ground IoT network. The focus is to optimize the path taken by the UAVs to minimize energy consumption. We also analyze the vital signs data collected by UAVs for people in disaster-affected areas and apply the decision tree classification algorithm to determine their health risk status. The risk status will enable the first responders to decide the areas which need the most immediate help Simulation results compare the effectiveness of our proposed scheduling scheme with the traditional approach used for data collection. Also, we present the results of our predicted risk status compared with the risk status calculated through the National Early Warning Score 2 (NEWS2) method.}
}
@article{JIA2021115845,
title = {VIRS based detection in combination with machine learning for mapping soil pollution},
journal = {Environmental Pollution},
volume = {268},
pages = {115845},
year = {2021},
issn = {0269-7491},
doi = {https://doi.org/10.1016/j.envpol.2020.115845},
url = {https://www.sciencedirect.com/science/article/pii/S0269749120365349},
author = {Xiyue Jia and David O’Connor and Zhou Shi and Deyi Hou},
keywords = {Reflectance spectroscopy, Machine learning, Soil mapping, Heavy metals, Soil pollution},
abstract = {Widespread soil contamination threatens living standards and weakens global efforts towards the Sustainable Development Goals (SDGs). Detailed soil mapping is needed to guide effective countermeasures and sustainable remediation operations. Here, we review visible and infrared reflectance spectroscopy (VIRS) based detection methods in combination with machine learning. To date, proximal, airborne and spaceborne carrier devices have been employed for soil contamination detection, allowing large areas to be covered at low cost and with minimal secondary environmental impact. In this way, soil contaminants can be monitored remotely, either directly or through correlation with soil components (e.g. Fe-oxides, soil organic matter, clay minerals). Observed vegetation reflectance spectra has also been proven an effective indicator for mapping soil pollution. Calibration models based on machine learning are used to interpret spectral data and predict soil contamination levels. The algorithms used for this include partial least squares regression, neural networks, and random forest. The processes underlying each of these approaches are outlined in this review. Finally, current challenges and future research directions are explored and discussed.}
}
@article{NASCIMENTO2020103996,
title = {A tutorial on solving ordinary differential equations using Python and hybrid physics-informed neural network},
journal = {Engineering Applications of Artificial Intelligence},
volume = {96},
pages = {103996},
year = {2020},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2020.103996},
url = {https://www.sciencedirect.com/science/article/pii/S095219762030292X},
author = {Renato G. Nascimento and Kajetan Fricke and Felipe A.C. Viana},
keywords = {Physics-informed neural network, Scientific machine learning, Uncertainty quantification, Hybrid model python implementation},
abstract = {We present a tutorial on how to directly implement integration of ordinary differential equations through recurrent neural networks using Python. In order to simplify the implementation, we leveraged modern machine learning frameworks such as TensorFlow and Keras. Besides, offering implementation of basic models (such as multilayer perceptrons and recurrent neural networks) and optimization methods, these frameworks offer powerful automatic differentiation. With all that, the main advantage of our approach is that one can implement hybrid models combining physics-informed and data-driven kernels, where data-driven kernels are used to reduce the gap between predictions and observations. Alternatively, we can also perform model parameter identification. In order to illustrate our approach, we used two case studies. The first one consisted of performing fatigue crack growth integration through Euler’s forward method using a hybrid model combining a data-driven stress intensity range model with a physics-based crack length increment model. The second case study consisted of performing model parameter identification of a dynamic two-degree-of-freedom system through Runge–Kutta integration. The examples presented here as well as source codes are all open-source under the GitHub repository https://github.com/PML-UCF/pinn_code_tutorial.}
}
@article{BROGAN2021100094,
title = {Deep learning computer vision for robotic disassembly and servicing applications},
journal = {Array},
volume = {12},
pages = {100094},
year = {2021},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2021.100094},
url = {https://www.sciencedirect.com/science/article/pii/S2590005621000394},
author = {Daniel P. Brogan and Nicholas M. DiFilippo and Musa K. Jouaneh},
keywords = {Screw detection, YOLO, Robotic disassembly, Robotic servicing, Deep learning},
abstract = {Fastener detection is a necessary step for computer vision (CV) based robotic disassembly and servicing applications. Deep learning (DL) provides a robust approach for creating CV models capable of generalizing to diverse visual environments. Such DL CV systems rely on tuning input resolution and mini-batch size parameters to fit the needs of the detection application. This paper provides a method for determining the optimal compromise between input resolution and mini-batch size to determine the highest performance for cross-recessed screw (CRS) detection while utilizing maximum graphics processing unit resources. The Tiny-You Only Look Once v2 (Tiny-YOLO v2) DL object detection system was chosen to evaluate this method. Tiny-YOLO v2 was employed to solve the specialized task of detecting CRS which are highly common in electronic devices. The method used in this paper for CRS detection is meant to lay the ground-work for multi-class fastener detection, as the method is not dependent on the type or number of object classes. An original dataset of 900 images of 12.3 MPx resolution was manually collected and annotated for training. Three additional distinct datasets of 90 images each were manually collected and annotated for testing. It was found an input resolution of 1664 x 1664 pixels paired with a mini-batch size of 16 yielded the highest average precision (AP) among the seven models tested for all three testing datasets. This model scored an AP of 92.60% on the first testing dataset, 99.20% on the second testing dataset, and 98.39% on the third testing dataset.}
}
@article{ZHANG2021107985,
title = {Estimating the maize biomass by crop height and narrowband vegetation indices derived from UAV-based hyperspectral images},
journal = {Ecological Indicators},
volume = {129},
pages = {107985},
year = {2021},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2021.107985},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X21006506},
author = {Yue Zhang and Chenzhen Xia and Xingyu Zhang and Xianhe Cheng and Guozhong Feng and Yin Wang and Qiang Gao},
keywords = {UAV-remote sensing, Aboveground biomass, Stepwise regression, Random forest regression, XGBoost regression, Precision agriculture},
abstract = {Monitoring the aboveground biomass (AGB) of maize is essential for improving site-specific nutrient management and predicting yield to ensure food safety. A low-altitude unmanned aerial vehicle (UAV) was employed to acquire hyperspectral imagery of the maize canopy at three growth stages (V6, R1, R3) to estimate the maize AGB. Five maize nitrogen (N) rate experiments were conducted in Lishu County, Jilin Province, Northeastern China, to create different biomass conditions. Combined with crop height data obtained from the field measurements, 30 narrowband vegetation indices (VIs) were extracted using surface reflectance data from the hyperspectral imagery. Stepwise regression, random forest (RF) regression and XGBoost regression models were used to predict the fresh and dry AGB of the 2019 growth season. The study revealed that (1) crop height explained the most variability (60–70%) in the maize dry and fresh AGB estimation of the V6 growth stage, while different VIs exhibited various importance for AGB estimation at other maize growth stages; (2) XGBoost regression models demonstrated high prediction accuracy in both fresh and dry AGB estimation, compared with stepwise regression and RF models. (3) XGBoost models also presented high prediction accuracy at each single-growth stage and the whole-growth stage, with the highest accuracy for the dry AGB at V6 growth stage (R2 = 0.81, RMSE = 0.27 t/ha). This study demonstrated the capability of UAV-based hyperspectral imagery for estimating maize AGB at the field scale, which can be used to assist precision agriculture.}
}
@article{YU2020105939,
title = {Decentralized fractional-order backstepping fault-tolerant control of multi-UAVs against actuator faults and wind effects},
journal = {Aerospace Science and Technology},
volume = {104},
pages = {105939},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.105939},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820306210},
author = {Ziquan Yu and Youmin Zhang and Bin Jiang and Chun-Yi Su and Jun Fu and Ying Jin and Tianyou Chai},
keywords = {Unmanned aerial vehicles, Fault-tolerant control, Fractional-order control, Actuator faults, Wind effects},
abstract = {Concurrent occurrences of actuator faults and wind effects can significantly threaten the flight safety of multiple unmanned aerial vehicles (multi-UAVs). To address this difficult control problem against actuator faults and wind effects, a composite decentralized fractional-order (FO) backstepping adaptive neural fault-tolerant control (FTC) method is presented for the attitude synchronization tracking of multi-UAVs, which is integrated with neural networks (NNs), disturbance observers (DOs), FO calculus, and high-order sliding-mode differentiators (HOSMDs). The distinctive feature of this work is addressing the attitude synchronization tracking control problem with actuator faults and wind effects in a decentralized framework and proposing a composite approximation method for multi-UAVs. It is shown that by using Lyapunov methods the synchronization tracking control is achieved even when multi-UAVs simultaneously encounter wind effects and actuator faults. Comparative simulation results illustrate the theoretical feasibility.}
}
@article{TAN2020100235,
title = {Addressing spectrum efficiency through hybrid-duplex UAV communications: Challenges and opportunities},
journal = {Vehicular Communications},
volume = {24},
pages = {100235},
year = {2020},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2020.100235},
url = {https://www.sciencedirect.com/science/article/pii/S2214209620300061},
author = {Zheng Hui Ernest Tan and A.S. Madhukumar and Rajendra Prasad Sirigina and Anoop Kumar Krishna},
keywords = {Unmanned Aerial Vehicle (UAV), Spectrum efficiency, Full-duplex, Hybrid-duplex, Non-Orthogonal Multiple Access (NOMA), Channel modeling},
abstract = {Unmanned aerial vehicles (UAVs) are set to play a prominent role in next-generation communications networks. However, the shortage of available spectrum to support UAV communications is a crucial challenge towards realizing multi-UAV networks. To this end, a hybrid-duplex (HBD) UAV communication system, i.e., HBD-UCS, is a potential solution towards improving spectrum efficiency in UAV communications. In an HBD-UCS, UAVs with half-duplex (HD) transceivers simultaneously communicate on the same spectrum with full-duplex (FD) ground stations (GSs). However, HBD-UCSs are also limited by self-interference (SI) at the FD-enabled GSs and inter-UAV interference at the downlink UAVs. As such, accurate modeling of HBD-UCSs that realistically accounts for SI and inter-UAV interference is necessary before any realization of practical HBD-UCSs is possible. In this regard, this survey paper first discusses the state-of-the-art and open research problems in UAV channel modeling. Next, the literature on the various types of SI mitigation, and the modeling of FD transceiver impairments are discussed. An example signal model for the FD-enabled GS that considers the various FD transceiver impairments is also proposed, before critical technical and regulatory challenges are presented. At the HD UAVs, interference management strategies that can be potentially adopted are discussed, together with the associated state-of-the-art. Furthermore, realistic performance metrics, and open research problems, for the interference management strategies are also discussed. For multi-UAV scenarios in HBD-UCSs, potential non-orthogonal multiple access (NOMA) techniques for multi-UAV deployment are discussed, with an example power-domain NOMA signal model proposed for a NOMA-aided multi-UAV HBD-UCS. Relevant open research problems in power-domain NOMA are then presented for successive interference cancellation (SIC) detection, user-pairing, and DL-based techniques for a power-domain NOMA-aided multi-UAV HBD-UCS.}
}
@article{CHAI2022107287,
title = {Multi-strategy fusion differential evolution algorithm for UAV path planning in complex environment},
journal = {Aerospace Science and Technology},
volume = {121},
pages = {107287},
year = {2022},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107287},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821007975},
author = {Xuzhao Chai and Zhishuai Zheng and Junming Xiao and Li Yan and Boyang Qu and Pengwei Wen and Haoyu Wang and You Zhou and Hang Sun},
keywords = {UAV path planning, Differential evolution, Self-adaptive, Interactive mutation strategy, Complex environment},
abstract = {The path planning of Unmanned Aerial Vehicle (UAV) is a real-world optimization problem, and even develops into a hard optimization problem with many objectives and constraints when UAVs work in a complex environment. In a complex environment, the resulting constraints can lead to decrease the quantity of the feasible solutions, so that can bring difficulties to plan routes for UAVs. Therefore, it is necessary to design a high-quality planner for a UAV in a complex environment. In this work, we have proposed a Multi-Strategy Fusion Differential Evolution algorithm (MSFDE). The proposed algorithm integrates the multi-population strategy, the novel self-adaptive strategy and the ensemble of the interactive mutation strategy in order to balance the exploitation and exploration capabilities. The multi-population strategy is used to divide the whole population into the three indicator subpopulations and a reward subpopulation for maintaining the diversity of the whole population; the novel self-adaptive strategy is introduced to control the parameters F and CR based on the teaching-learning-based optimization method; the ensemble of the interactive mutation strategy is to exchange the information among the three indicator subpopulations on each generation for boosting the population diversity. The constraints in the UAV path planning are transformed into the objective functions by the linear weighted sum method. Scenario 1, 2, 3, and 4 are designed with different complex level, and other eight algorithms are introduced to be compared with MSFDE. The simulation results confirm that MSFDE has an outstanding performance for the UAV three-dimensional path planning in the complex environment.}
}
@article{ULLAH2022286,
title = {Artificial Intelligence of Things-assisted two-stream neural network for anomaly detection in surveillance Big Video Data},
journal = {Future Generation Computer Systems},
volume = {129},
pages = {286-297},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.10.033},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21004295},
author = {Waseem Ullah and Amin Ullah and Tanveer Hussain and Khan Muhammad and Ali Asghar Heidari and Javier {Del Ser} and Sung Wook Baik and Victor Hugo C. {De Albuquerque}},
keywords = {Anomaly detection, Two-stream network, Anomaly recognition, Surveillance videos},
abstract = {In the last few years, visual sensors are deployed almost everywhere, generating a massive amount of surveillance video data in smart cities that can be inspected intelligently to recognize anomalous events. In this work, we present an efficient and robust framework to recognize anomalies from surveillance Big Video Data (BVD) using Artificial Intelligence of Things (AIoT). Smart surveillance is an important application of AIoT and we propose a two-stream neural network in this direction. The first stream comprises instant anomaly detection that is functional over resource-constrained IoT devices, whereas second phase is a two-stream deep neural network allowing for detailed anomaly analysis, suited to be deployed as a cloud computing service. Firstly, a self-pruned fine-tuned lightweight convolutional neural network (CNN) classifies the ongoing events as normal or anomalous in an AIoT environment. Upon anomaly detection, the edge device alerts the concerned departments and transmits the anomalous frames to cloud analysis center for their detailed evaluation in the second phase. The cloud analysis center resorts to the proposed two-stream network, modeled from the integration of spatiotemporal and optical flow features through the sequential frames. Fused features flow through a bi-directional long short-term memory (BD-LSTM) layer, which classifies them into their respective anomaly classes, e.g., assault and abuse. We perform extensive experiments over benchmarks built on top of the UCF-Crime and RWF-2000 datasets to test the effectiveness of our framework. We report a 9.88% and 4.01% increase in accuracy when compared to state-of-the-art methods evaluated over the aforementioned datasets.}
}
@article{BANG2020103116,
title = {Context-based information generation for managing UAV-acquired data using image captioning},
journal = {Automation in Construction},
volume = {112},
pages = {103116},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103116},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519308519},
author = {Seongdeok Bang and Hyoungkwan Kim},
keywords = {Image captioning, Text generation, On-site management, UAV},
abstract = {Unmanned aerial vehicles (UAVs) can efficiently collect image data representing various situations at construction sites, however, it requires a lot of time and cost to analyze it manually to retrieve useful information for on-site management. The paper proposes a methodology to generate time-spatial and visual context-based information from UAV-acquired data. This methodology generates textual information on the position, status, movement, color, and quantity of construction resources from site images using image captioning. Then, construction site images, text generated from them, and UAV flight data containing the latitude, longitude, date, and time of day, are systemized into a database. For evaluating the proposed methodology, data obtained by UAV at actual construction sites was used. Our methodology could predict textual information with a mean average precision of 43.52%, which is superior to those of existing methods.}
}
@article{CHUN2021109216,
title = {Deep reinforcement learning-based collision avoidance for an autonomous ship},
journal = {Ocean Engineering},
volume = {234},
pages = {109216},
year = {2021},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2021.109216},
url = {https://www.sciencedirect.com/science/article/pii/S0029801821006466},
author = {Do-Hyun Chun and Myung-Il Roh and Hye-Won Lee and Jisang Ha and Donghun Yu},
keywords = {Collision avoidance, Autonomous ship, Collision risk, COLREGs, Deep reinforcement learning},
abstract = {Social interest in autonomous navigation systems for autonomous ships is also increasing. For a robust autonomous navigation system, the location, speed, and direction of the ship and other ships must be identified in real time, and collision avoidance should be performed at an appropriate time by considering the collision risk. In this study, we proposed a collision avoidance method that quantitatively assesses the collision risk and then generates an avoidance path. First, to assess the collision risk, a collision risk assessment method based on the ship domain and the closest point of approach (CPA) was proposed. The ship domain is created with an asymmetric shape considering manoeuvring performance and the COLREGs. The CPA is used to assess quantitative collision risk value. Subsequently, a path generation algorithm based on deep reinforcement learning (DRL) was proposed to determine the avoidance time and to generate an avoidance path complying the COLREGs for the most dangerous ship in terms of collision risk. The information of own ship and target ship such as location, speed, heading, collision risk is used as the input state, and the rudder angle of own ship is set as the output action of the DRL. The cost function related to the path following and the collision avoidance is defined as the reward of the DRL-based collision avoidance method. Additionally, the DRL modes are defined to navigate the flexible avoidance path by changing the ratio between the path following and the collision avoidance. To verify the proposed method, we compared the collision avoidance method with the A* algorithm, which is a traditional path planning algorithm, and analyzed the results for various scenarios. The proposed method reliably avoided collisions through flexible paths for complex and unexpected changes in situations compared to the A* algorithm.}
}
@article{SONG2021112466,
title = {A comparative study of deep learning-based network model and conventional method to assess beach debris standing-stock},
journal = {Marine Pollution Bulletin},
volume = {168},
pages = {112466},
year = {2021},
issn = {0025-326X},
doi = {https://doi.org/10.1016/j.marpolbul.2021.112466},
url = {https://www.sciencedirect.com/science/article/pii/S0025326X21005002},
author = {Kyounghwan Song and Jung-Yeul Jung and Seung Hyun Lee and Sanghyun Park},
keywords = {Beach debris, Deep learning, Detection and quantification, Fieldwork, Image processing, Marine debris},
abstract = {The conventional survey of marine debris standing-stock has various drawbacks such as high cost and inaccuracy because the total amount of debris in the whole beach is inferred using the results of the manual investigation in selected narrow areas. To overcome the disadvantages, an automatic detection method using a deep learning-based network model was developed to detect and quantify the beach debris. The network model developed in this study classified items with a precision of 0.87 (87%) mAP and showed <5% error compared to actual survey. This study is the first fieldwork in Korea that shows the difference between automatic and conventional methods to predict the beach debris standing-stock. The results provide essential information for the development of effective beach debris management systems and policies.}
}
@article{PRATES2019343,
title = {Insulator visual non-conformity detection in overhead power distribution lines using deep learning},
journal = {Computers & Electrical Engineering},
volume = {78},
pages = {343-355},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S004579061930967X},
author = {Ricardo M. Prates and Ricardo Cruz and André P. Marotta and Rodrigo P. Ramos and Eduardo F. {Simas Filho} and Jaime S. Cardoso},
keywords = {Overhead Distribution Power Lines (ODPLs), Insulators, Automated inspection, Data augmentation, Convolutional Neural Networks (CNNs), Multi-task learning (MTL)},
abstract = {Overhead Power Distribution Lines (OPDLs) correspond to a large percentage of the medium-voltage electrical systems. In these networks, visual inspection activities are usually performed without resorting to automated systems, requiring a significant investment of time and human resources. We present a methodology to identify the defect and type of insulators using Convolutional Neural Networks (CNNs). More than 2500 photographs were collected both from inside a studio and from a realistic OPDL. A classification model is proposed to automatically recognize the insulators conformity. This model is able to learn from indoors photographs by augmenting these images with realistic details such as top ties and real-world backgrounds. Furthermore, Multi-Task Learning (MTL) was used to improve performance of defect detection by also predicting the insulator class. The proposed methodology is able to achieve an accuracy of 92% for material classification and 85% for defect detection, with F1-score of 0.75, surpassing available solutions.}
}
@article{DIAZGOMEZ2022108106,
title = {Mapping subaerial sand-gravel-cobble fluvial sediment facies using airborne lidar and machine learning},
journal = {Geomorphology},
pages = {108106},
year = {2022},
issn = {0169-555X},
doi = {https://doi.org/10.1016/j.geomorph.2021.108106},
url = {https://www.sciencedirect.com/science/article/pii/S0169555X21005146},
author = {Romina Diaz-Gomez and Gregory B. Pasternack and Hervé Guillon and Colin F. Byrne and Sebastian Schwindt and Kenneth G. Larrieu and Samuel Sandoval Solis},
keywords = {Grain size, Lidar, Substrate, Gravelometry, Machine learning, Remote sensing, Fluvial geomorphology},
abstract = {Substrate facies monitoring is critical for the understanding of fluvial geomorphologic and ecohydraulic patterns and processes. However, direct substrate measurement is time-consuming and subjected to data sparsity because of small sample, size, and limited data collections within an area of interest, which make it difficult to capture facies patterns. Most new experimental studies focus on mapping substrate based on median grain size of a specific grain size class using automatic or semiautomatic photosieving techniques. This study aimed to develop and apply a method to accurately predict size-mixture facies patterns on exposed riverbeds with minimal ground truth plots (100) using airborne lidar and machine learning. The selected testbed river was a 37.5-km stretch of the regulated lower Yuba River in California, USA, mapped at sub-meter resolution in 2017. First, we designed a grid-by-point grain size sampling method and binned grain sizes into representative mixtures, such as fine or large gravel, to assign subaerial facies labels. Second, we classified facies based on a multivariate cluster analysis. Third, we generated 15 lidar-derived topographic and spectral predictors. Six distinct size-mixture facies were identified from field data and a seventh, pure sand facies, from UAV data. A random forest predictive model with an 84% 10-fold cross-validation accuracy was applied to produce a facies map at the 1.54 m pixel scale. The detrended elevation was identified as the most important variable for predicting facies spatial patterning, followed by baseflow, wetted area proximity, and green lidar intensity. We conclude that machine learning combined with intensity lidar data is highly effective for distinguishing mixed classes of substrates. Ultimately, the new substrate mixture-binning approach also provides novel insights into the arrangement of river sediment facies patterns.}
}
@article{SANTI2022112878,
title = {Detecting fire disturbances in forests by using GNSS reflectometry and machine learning: A case study in Angola},
journal = {Remote Sensing of Environment},
volume = {270},
pages = {112878},
year = {2022},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112878},
url = {https://www.sciencedirect.com/science/article/pii/S0034425721005988},
author = {E. Santi and M.P. Clarizia and D. Comite and L. Dente and L. Guerriero and N. Pierdicca},
keywords = {GNSS reflectometry (GNSS-R), CyGNSS, Fire disturbances, Forests, Machine learning},
abstract = {This paper aims at exploiting the potential of Global Navigation Satellite System Reflectometry (GNSS-R) for the detection of forest disturbances due to fires. The study focuses on the forested part of Angola that was largely affected by fires during summer 2019. The data collected in the area by the NASA Cyclone GNSS (CyGNSS) constellation have been downloaded and processed. As reference data for developing and testing the retrieval algorithms, the ESA Climate Change Initiative (CCI) decadal burned areas maps have been considered. After evaluating the sensitivity of the GNSS-R observables, namely Signal to Noise Ratio and Equivalent Reflectivity, to the forest disturbances, some retrieval algorithms based on different machine learning techniques have been implemented, tested, and compared with a simple approach based on the temporal gradient of the GNSS-R observables. In details, classifiers based on Support Vector Machines (SVM) and Random Forests (RF) have been implemented for discriminating burned/not burned pixels of the images and regressors based on Artificial Neural Networks (ANN), RF and Support Vector Regressors (SVR) have been implemented for estimating the fraction of burned areas within a pixel. All these algorithms allowed a satisfactory identification of the burned areas with respect to the reference data, enabling the generation of maps every ten days. These results represent the first observations of forest disturbances due to fires using spaceborne GNSS-Reflectometry.}
}
@article{WANG20202877,
title = {Multi-UAV coordination control by chaotic grey wolf optimization based distributed MPC with event-triggered strategy},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {11},
pages = {2877-2897},
year = {2020},
note = {SI: Emerging Technologies of Unmanned Aerial Vehicles},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.04.028},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120302387},
author = {Yingxun WANG and Tian ZHANG and Zhihao CAI and Jiang ZHAO and Kun WU},
keywords = {Chaotic Grey Wolf Optimization (CGWO), Coordination control, Distributed Model Predictive Control (MPC), Event-triggered strategy, Multi-UAV},
abstract = {The paper proposes a new swarm intelligence-based distributed Model Predictive Control (MPC) approach for coordination control of multiple Unmanned Aerial Vehicles (UAVs). First, a distributed MPC framework is designed and each member only shares the information with neighbors. The Chaotic Grey Wolf Optimization (CGWO) method is developed on the basis of chaotic initialization and chaotic search to solve the local Finite Horizon Optimal Control Problem (FHOCP). Then, the distributed cost function is designed and integrated into each FHOCP to achieve multi-UAV formation control and trajectory tracking with no-fly zone constraint. Further, an event-triggered strategy is proposed to reduce the computational burden for the distributed MPC approach, which considers the predicted state errors and the convergence of cost function. Simulation results show that the CGWO-based distributed MPC approach is more computationally efficient to achieve multi-UAV coordination control than traditional method.}
}
@article{JOSHI2021101197,
title = {VirLeafNet: Automatic analysis and viral disease diagnosis using deep-learning in Vigna mungo plant},
journal = {Ecological Informatics},
volume = {61},
pages = {101197},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2020.101197},
url = {https://www.sciencedirect.com/science/article/pii/S1574954120301473},
author = {Rakesh Chandra Joshi and Manoj Kaushik and Malay Kishore Dutta and Ashish Srivastava and Nandlal Choudhary},
keywords = {Agriculture, Artificial intelligence, Deep learning, Image processing, Plant disease, },
abstract = {Various viral diseases affect the growth of the plants that causes a huge loss to farmers. If the viral infection could be noticed at earlier stages, then recovery procedures and respective action can be taken on time. Thus, there is a need for developing automatic viral infection detection methods for monitoring of crops analysing symptoms at different parts of plants. This paper proposes an automatic deep-learning-based viral infection detection method for a leguminous plant, Vigna mungo which is grown largely in the Indian subcontinent. Due to viral infection, some properties of the leaf image changes but the pattern is very random throughout the leaf structure. Hence, it is quite challenging to make an automatic disease detection method and perform the detection tasks in real-time. The collected image dataset of Vigna mungo leaves belonging to different categories are segmented and augmented to introduce more variety in the leaf image dataset. The convolutional neural network VirLeafNet is trained with different leaf images consisting of healthy, mild-infected and severely infected leaves for multiple epochs. The proposed methodology can be integrated with drones for wider crop area analysis. The proposed method is completely automatic, non-destructive and quickly classifies the leaf images of different categories in real-time. All the proposed models achieved high validation accuracy and yielded testing accuracy for VirLeafNet-1, VirLeafNet-2, and VirLeafNet-3 as 91.234%, 96.429%, and 97.403% respectively on different leaves images after extensive testing of the algorithm.}
}
@article{SONY2021111347,
title = {A systematic review of convolutional neural network-based structural condition assessment techniques},
journal = {Engineering Structures},
volume = {226},
pages = {111347},
year = {2021},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2020.111347},
url = {https://www.sciencedirect.com/science/article/pii/S0141029620339481},
author = {Sandeep Sony and Kyle Dunphy and Ayan Sadhu and Miriam Capretz},
keywords = {Structural health monitoring, Artificial intelligence, Deep learning, CNN, Damage detection, Anomaly detection, Structural condition assessment},
abstract = {With recent advances in non-contact sensing technology such as cameras, unmanned aerial and ground vehicles, the structural health monitoring (SHM) community has witnessed a prominent growth in deep learning-based condition assessment techniques of structural systems. These deep learning methods rely primarily on convolutional neural networks (CNNs). The CNN networks are trained using a large number of datasets for various types of damage and anomaly detection and post-disaster reconnaissance. The trained networks are then utilized to analyze newer data to detect the type and severity of the damage, enhancing the capabilities of non-contact sensors in developing autonomous SHM systems. In recent years, a broad range of CNN architectures has been developed by researchers to accommodate the extent of lighting and weather conditions, the quality of images, the amount of background and foreground noise, and multiclass damage in the structures. This paper presents a detailed literature review of existing CNN-based techniques in the context of infrastructure monitoring and maintenance. The review is categorized into multiple classes depending on the specific application and development of CNNs applied to data obtained from a wide range of structures. The challenges and limitations of the existing literature are discussed in detail at the end, followed by a brief conclusion on potential future research directions of CNN in structural condition assessment.}
}
@article{GUI2022104626,
title = {New mist-edge-fog-cloud system architecture for thermal error prediction and control enabled by deep-learning},
journal = {Engineering Applications of Artificial Intelligence},
volume = {109},
pages = {104626},
year = {2022},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104626},
url = {https://www.sciencedirect.com/science/article/pii/S0952197621004371},
author = {Hongquan Gui and Jialan Liu and Chi Ma and Mengyuan Li and Shilong Wang},
keywords = {CSGWO-Bi-LSTM neural network, Internet of Things, Mist computing, Deep learning, Thermally-induced error},
abstract = {The geometric precision of machined gears is reduced by thermal errors. So the prediction and control of thermal errors are essential. But the prediction and control are a process involving the processing of a large-volume thermal data, and then the processing efficiency is low, which severely hinders the geometric precision improvement. To solve this problem, a new mist-edge-fog-cloud system (MEFCS) architecture is proposed for the error prediction and control. A finite element model is established to prove the applicability of bidirectional long short-term memory (Bi-LSTM) network. A cosine and sine gray wolf optimization (CSGWO) algorithm is proposed to optimize the batch size. Then the CSGWO-Bi-LSTM network error model is proposed. The predictive accuracy is 90.80%, 94.57%, 95.77%, 96.79%, 97.51%, 98.45%, and 98.92% for the multiple linear regression model, recurrent neural network, LSTM network, Bi-LSTM network, CSGWO1-Bi-LSTM network, CSGWO2-Bi-LSTM network, and CSGWO3-Bi-LSTM network, respectively. The volume of the transferred data is reduced by 11/16 with the data-based model, and the volume of the transferred thermal data is reduced to 1/10 with the designed system. A precision threshold is set, and the predictive accuracy is improved by 8.31% by the system with the precision threshold compared with the system without the precision threshold. With the proposed MEFCS, the accuracy level of the tooth profile deviation fHα is increased from ISO level 5 to ISO level 3. The total execution time of the mist-cloud structure, mist-edge-cloud structure, mist-fog-cloud structure, and mist-edge-fog-cloud structure is 206 s, 200 s, 186 s, and 167 s, respectively.}
}
@article{SHI202160,
title = {Wind-induced response of rice under the action of the downwash flow field of a multi-rotor UAV},
journal = {Biosystems Engineering},
volume = {203},
pages = {60-69},
year = {2021},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2020.12.012},
url = {https://www.sciencedirect.com/science/article/pii/S1537511020303445},
author = {Qiang Shi and Da Liu and Hanping Mao and Baoguo Shen and Meiqing Li},
keywords = {Rice plant, Wind-induced response, Unmanned aerial vehicle (UAV), Downwash flow field, Crop morphology},
abstract = {Unmanned aerial vehicles (UAVs) are becoming increasingly used in agriculture. Many agricultural operations, the involving UAVs are carried out at low flying altitudes, which generates a powerful downwash flow field that changes the shape of plants. To explore the influences of the downwash flow field on the shape of plants, this paper focused on rice plants at heading stage and tested the effect of different UAV flight parameters. The single-factor tests in hover showed that the wind speed at the rice canopy reduced and turbulence intensity of the downwash flow field increased as the UAV flight altitude increased from 2 to 8 m. Moreover, it showed that the degree of rice plant deformation was closely related to the maximum velocity of the downwash flow field. The multifactor field tests showed that the area of rice deformation was shaped like a horseshoe; and the flight altitude (1.5–5 m), flight speed (1–5 m s−1) and payload (0–20 kg) had obvious effects on rice plant deformation with the greatest effect due to payload, followed by flight speed, and flight altitude. When the maximum wind speed was less than 3 m s−1, the downwash flow field did not cause obvious changes to rice plant morphology.}
}
@article{CHEN2020102744,
title = {Conflict analytics through the vehicle safety space in mixed traffic flows using UAV image sequences},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {119},
pages = {102744},
year = {2020},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2020.102744},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X20306586},
author = {Albert Y. Chen and Yen-Lin Chiu and Meng-Hsiu Hsieh and Po-Wei Lin and Ohay Angah},
keywords = {Traffic conflict, Computer vision, Safety space, Object based tracking, Mixed traffic flow, Unmanned aerial vehicle (UAV)},
abstract = {The mixed traffic flow has complex dynamics by nature. The kinematic differences between automobiles and motorcycles result to distinct driving behaviors. Traditional automobile-based traffic flow theory is not always suitable for mixed traffic streams. The purpose of this study is to observe from actual data a clearance boundary, called Safety Space, drivers maintain from other vehicles, and use it as a spatial filter to determine conflicts in mixed traffic flows. Image data are collected from an Unmanned Aerial Vehicle (UAV), and microscopic characteristics such as vehicle type, position, velocity, and trajectory are extracted through computer vision techniques. The Histogram of Oriented Gradients (HOG) feature and the Support Vector Machine (SVM) classifier are utilized for the vehicle detection, while the Kalman Filter is employed for the derivation of vehicle trajectories. The Safety Space is then determined based on those trajectories. Validation data are collected at intersections in Taipei, Taiwan; Bangkok, Thailand; and Mumbai, India. The vehicle detection and tracking are satisfactory, and the Safety Space surrogate reveals risk zones caused by spatial proximity between vehicles.}
}
@article{MIGLANI2019100184,
title = {Deep learning models for traffic flow prediction in autonomous vehicles: A review, solutions, and challenges},
journal = {Vehicular Communications},
volume = {20},
pages = {100184},
year = {2019},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2019.100184},
url = {https://www.sciencedirect.com/science/article/pii/S2214209619302311},
author = {Arzoo Miglani and Neeraj Kumar},
keywords = {Cognitive Internet of Things, Traffic flow prediction, Machine learning, Deep learning, Autonomous vehicles},
abstract = {In the last few years, there has been an exponential increase in the usage of the autonomous vehicles across the globe. It is due to an exponential increase in the popularity and usage of the artificial intelligence techniques in various applications. Traffic flow predication is important for autonomous vehicles using which they decide their itinerary and take adaptive decisions (for example, turn let or right, move straight, lane change, stop, or accelerate) with respect to their surrounding objects. From the existing literature, it has been observed that research on autonomous vehicles has shifted from the traditional statistical models to adaptive machine learning techniques. However, existing machine learning models may not be directly applicable in this environment due to non-linear complex relationship between spatial and temporal data collected from the surroundings during the aforementioned adaptive decisions taken by the vehicles. So, with focus on these issues, in this article, we explore various deep learning models for traffic flow prediction in autonomous vehicles and compared these models with respect to their applicability in modern smart transportation systems. Various parameters are chosen to have a relative comparison among different deep learning models. Moreover, challenges and future research directions are also discussed in the article.}
}
@article{OUATTARA202015777,
title = {Drone based Mapping and Identification of Young Spruce Stand for Semiautonomous Cleaning⁎⁎Strategic Research Council at the Academy of Finland is acknowledged for financial support of project “Competence-Based Growth Through Integrated Disruptive Technologies of 3D Digitalization, Robotics, Geospatial Information and Image Processing/Computing - Point Cloud Ecosystem” (project decision numbers 293389 and 314312).Issouf Ouattara is a PhD Student with the Autonomous Systems research group, Department of Electrical Engineering and Automation, School of Electrical Engineering, Aalto University, PO Box 15500, FIN-00076 Aalto, FinlandHeikki Hyyti is a researcher with the department of Remote Sensing and Photogrammetry at the Finnish Geospatial Research Institute (FGI), National Land Survey of FinlandArto Visala is a Professor with the Autonomous Systems research group, Department of Electrical Engineering and Automation, School of Electrical Engineering, Aalto University, PO Box 15500, FIN-00076 Aalto, Finland},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {15777-15783},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.205},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320304705},
author = {Issouf Ouattara and Heikki Hyyti and Arto Visala},
keywords = {unmanned aerial vehicle, mapping, individual tree identification, convolutional neural network, autonomous vehicle, forestry},
abstract = {We propose a novel method to locate spruces in a young stand with a low cost unmanned aerial vehicle. The method has three stages: 1) the forest area is mapped and a digital surface model and terrain models are generated, 2) the locations of trees are found from a canopy height model using local maximum and watershed algorithms, and 3) these locations are used in a convolution neural network architecture to detect young spruces. Our result for detecting young spruce trees among other vegetation using only color images from a single RGB camera were promising. The proposed method is able to achieve a detection accuracy of more than 91%. As low cost unmanned aerial vehicles with color cameras are versatile today, the proposed work is enabling low cost forest inventory for automating forest management.}
}
@article{HENTATI2020103451,
title = {Comprehensive survey of UAVs communication networks},
journal = {Computer Standards & Interfaces},
volume = {72},
pages = {103451},
year = {2020},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2020.103451},
url = {https://www.sciencedirect.com/science/article/pii/S0920548919303411},
author = {Aicha Idriss Hentati and Lamia Chaari Fourati},
keywords = {UAV networks, Drones, Networking models, Multi-UAVs systems, Non-Orthogonal Multiple Access (NOMA)},
abstract = {Recently, technologies related to Unmanned Aerial Vehicle (UAV) are growing rapidly particularly sensors, networking, and processing technologies. Accordingly, governments and industry have heavily invested in the studies of UAVs and improvingtheir performances for reliable and secure deployments. The design methods and the investigation of UAVs systems have progressed from mono-UAV uses to multi-UAVs and cooperative UAVs systems that need a high level of coordination and collaboration to perform tasks which require new networking models, approaches, and mechanisms for highly mobile nodes involving many complex parameters and constraints. In this context, this paper provides more details and offers a thorough investigation concerning UAV communication protocols, networking systems, architectures, and applications. In addition, we discuss UAV solutions as well as highlighting important technical challenges and open research issues requiring further studies and R&D work.}
}
@article{BANERJEE2022108623,
title = {EDTP: Energy and Delay Optimized Trajectory Planning for UAV-IoT Environment},
journal = {Computer Networks},
volume = {202},
pages = {108623},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108623},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621005156},
author = {Anuradha Banerjee and Abu Sufian and Krishna Keshob Paul and Sachin Kumar Gupta},
keywords = {ARMA Model in UAV, Clustering Model, Delay Optimization, Energy-Efficiency, Internet of Things, Multi-Unmanned Aerial Vehicle, Trajectory Estimation},
abstract = {In modern days, UAV (Unmanned Aerial Vehicle) are being extensively used in various fields like military, healtcare, security, government sectors, supervision, home delivery agents, etc. They significantly enhance the potential of IoT devices by processing their data. However, issues like efficient trajectory planning, security and privacy protection, task scheduling, a delegation of tasks from one UAV to another in multi-UAV systems, etc., require rigorous research and analysis. In this paper, we consider a multi-UAV multi-IoT network, which is divided into certain hexagonal cells. Each cell consists of some IoT devices and a UAV to process the data those IoT devices collect from the environment. IoT devices in each cell are grouped into clusters so that UAVs hover only above cluster heads and midpoints of cell boundaries to collect and delegate tasks whenever required. Provision of both single and multi-hop task delegation exists in our system. The schedule is formed based on the UAV’s next intended arrival time as computed by cluster heads in the cell using the Auto-Regressive Moving Average (ARMA) model. Timestamps of visiting midpoints of cell boundaries are fitted between predicted next arrival times of visiting cluster heads. Energy consumption and time of transition from one hovering point to another can be optimized. However, the most energy-efficient solution may not necessarily be the most delay efficient. A multi-objective optimization technique is applied to identify the Pareto-optimal front and select the best possible solution. Simulation results show that compared to other trajectory planning algorithms viz. Dijkstra’s and HEA, our proposed technique saves much more energy (approx 78% over the other two) and time (42% over the other two).}
}
@article{CHO20212229,
title = {Reproduction strategy of radiation data with compensation of data loss using a deep learning technique},
journal = {Nuclear Engineering and Technology},
volume = {53},
number = {7},
pages = {2229-2236},
year = {2021},
issn = {1738-5733},
doi = {https://doi.org/10.1016/j.net.2021.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S1738573321000334},
author = {Woosung Cho and Hyeonmin Kim and Duckhyun Kim and SongHyun Kim and Inyong Kwon},
keywords = {Deep learning, U-net algorithm, Radiation map, Sensor network system, Reproduction},
abstract = {In nuclear-related facilities, such as nuclear power plants, research reactors, accelerators, and nuclear waste storage sites, radiation detection, and mapping are required to prevent radiation overexposure. Sensor network systems consisting of radiation sensor interfaces and wxireless communication units have become promising tools that can be used for data collection of radiation detection that can in turn be used to draw a radiation map. During data collection, malfunctions in some of the sensors can occasionally occur due to radiation effects, physical damage, network defects, sensor loss, or other reasons. This paper proposes a reproduction strategy for radiation maps using a U-net model to compensate for the loss of radiation detection data. To perform machine learning and verification, 1,561 simulations and 417 measured data of a sensor network were performed. The reproduction results show an accuracy of over 90%. The proposed strategy can offer an effective method that can be used to resolve the data loss problem for conventional sensor network systems and will specifically contribute to making initial responses with preserved data and without the high cost of radiation leak accidents at nuclear facilities.}
}
@article{BALCI2021107646,
title = {Massive connectivity with machine learning for the Internet of Things},
journal = {Computer Networks},
volume = {184},
pages = {107646},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107646},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620312652},
author = {Abdullah Balcı and Radosveta Sokullu},
keywords = {Internet of Things, Random access, Grant-free access, Grand-based access, Aloha, NOMA, Machine learning},
abstract = {Driven by the need to ensure the connectivity of an unprecedentedly huge number of IoT devices with no human intervention the issues of massive connectivity have recently become one of the main research areas in IoT studies. Conventional wireless communication technologies are designed for Human-to-Human (H2H) communication which leads to major problems in primary access, channel utilization and spectrum efficiency when massive numbers of devices require connectivity. Current random access procedures are based on a four-step handshaking with control messages which contradicts the requirements of IoT applications in terms of small data payloads and low complexity. Targeted channel utilization and spectrum efficiency cannot be achieved using traditional orthogonal approaches. Thus the goal of our work is to review the most recent developments and critically evaluate the existing work related to the evolution of network access methods in the new communication era. The paper covers three major aspects: first the primary random access procedures, proposed for IoT communications are discussed. The second aspect focuses on the approaches for integration of existing random multiple access schemes with non-orthogonal multiple access methods (NOMA). This integration of random access procedures with NOMA opens a new research trend in the field of massive connectivity. Operating on space domains additional to the physical domain such as code and power domains, NOMA integration targets increased channel utilization and spectrum efficiency to complement the flexibility of random access. On the other hand, the design of efficient algorithms for massive connectivity in IoT is also challenged by the highly application and environmentally dependent traffic model. A new angle of tackling this problem has emerged thanks to the extensive developments in machine learning and the possibilities of their incorporation in communication networks. Thus, the final aspect this review paper addresses are the newly emerging research directions of incorporating machine learning (ML) methods for providing efficient IoT connectivity. Breakthrough ML techniques allow wireless networking devices to perform transmissions by learning and building knowledge about the communication and networking environment. A critical evaluation of the large body of work accumulated in this area in the most recent years and outlining of some major open research issues concludes the paper.}
}
@article{CUI2022116075,
title = {Remaining capacity prediction of lithium-ion battery based on the feature transformation process neural network},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116075},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116075},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014135},
author = {Zhiquan Cui and Xuhong Gao and Jiawei Mao and Chunhui Wang},
keywords = {Feature transformation process neural networks, Lithium-ion battery, Remaining capacity, Time series prediction, Levenberg-Marquardt algorithm},
abstract = {In order to improve the prediction accuracy of discrete time series data, a lithium-ion battery remaining capacity prediction model based on feature transformation process neural network is proposed. According to the time series characteristics of lithium-ion battery performance degradation data, the remaining capacity prediction of lithium-ion battery is converted into a functional approximation method. The integral operation of continuous function is used to realize the time accumulation effect of network input data. In order to simplify the integral operation of continuous function, a discrete Walsh transform is performed on the input data, and the integral operation of continuous function is transformed into the inner product operation of the discrete Walsh transform pair. This method simplifies the integral operation of the continuous function and eliminates the loss of precision caused by the continuity of discrete time series data. A Levenberg-Marquardt network weight learning algorithm based on the discrete Walsh transform is developed. The model and algorithm are applied to predict the remaining capacity of lithium-ion batteries. The experimental results show that the model can reduce the average absolute error, average relative error and root mean square error of lithium-ion battery remaining capacity prediction to 0.0231AH, 1.73% and 0.0299 respectively.}
}
@article{PAL2021103892,
title = {Deep-learning-based visual data analytics for smart construction management},
journal = {Automation in Construction},
volume = {131},
pages = {103892},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103892},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521003435},
author = {Aritra Pal and Shang-Hsien Hsieh},
keywords = {Deep learning, visual data analytics, construction management, generalized workflow, 3D visual data},
abstract = {Visual data captured at construction sites is a rich source of information for the day-to-day operation of construction projects. The development of deep-learning-based methods has demonstrated their capabilities in analyzing complex visual data and inferring valuable insights. Recent applications of these methods in construction have also shown promising performance in making the construction management process smarter. To understand the current research trends and to highlight future research directions, this study reviews state-of-the-art deep-learning applications on visual data analytics in the context of construction project management. This in-depth review identifies six major fields and fifty-two subfields of construction management where deep-learning-based visual data analytics have been applied. It also proposes a generalized workflow for applying deep-learning-based visual data analytics methods for solving construction management problems. In addition, the study highlights three future research directions where deep-learning-based visual data analytics can be applied on relatively less explored 3D visual data.}
}
@article{LIU2021107562,
title = {Graph relation network for person counting in construction site using UAV},
journal = {Applied Soft Computing},
volume = {110},
pages = {107562},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107562},
url = {https://www.sciencedirect.com/science/article/pii/S156849462100483X},
author = {Zun Liu and Xiaonan Hu and Jianqiang Li and Jie Chen and Wenlian Huang and Xiaoyu Zhao and Victor C.M. Leung},
keywords = {Soft computing, Person re-identification, Person counting, Graph similarity, Internet of Things, UAV},
abstract = {Due to its portability and maneuverability, Unmanned Aerial Vehicles (UAVs) are increasingly used in industrial fields. Our work aims to develop a framework of person counting executed by an UAV, which can count the total number of persons accurately. To solve the problem of multiple counts for the same person, this work proposes a novel Graph Similarity-based Person Counting Network (GSPCN) which consists of three modules: person detection network, person re-identification module, and person counting module. To begin with, we detect the bounding boxes and the corresponding images for each object in image sequence. Secondly, we calculate the visual similarity between persons. And then, each person is taken as the root node to construct a graph, then we calculate the similarity between different graphs as the graph similarity. After that, we comprehensively consider the visual similarity and graph similarity to determine whether the person is repeated. Finally, by removing all duplicate persons, we can get the total number of persons. The proposed framework is tested in a real-world scenario and it empirically outperforms the existing state-of-the-art methods.}
}
@article{ALI2022103989,
title = {Structural crack detection using deep convolutional neural networks},
journal = {Automation in Construction},
volume = {133},
pages = {103989},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103989},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521004404},
author = {Raza Ali and Joon Huang Chuah and Mohamad Sofian Abu Talip and Norrima Mokhtar and Muhammad Ali Shoaib},
keywords = {Deep convolutional neural networks, Structure cracks, Crack detection, Crack classification, Crack segmentation, Feature extraction},
abstract = {Convolutional Neural Networks (CNN) have immense potential to solve a broad range of computer vision problems. It has achieved encouraging results in numerous applications of engineering, medical, and other research fields due to the advancement in hardware, data collection procedures, and efficient algorithms. These innovations have changed the way how specific problems are solved as compared to conventional methods. This article presents a review of CNN implementation on civil structure crack detection. The review highlights the significant research that has been performed to detect structure cracks through classification and segmentation of crack images with CNN in the perspective of image pre-processing techniques, processing hardware, software tools, datasets, network architectures, learning procedures, loss functions, and network performance. The key contribution of this review article is the study and analysis of the most recent developments on crack detection using CNN. Additionally, this work also presents a discussion on crack detection through a manual process, image processing techniques, and machine learning methods along with their limitations. Finally, this article aims for assisting the readers to understand the motivation and methodology of the various CNN-based crack detection methods and to invoke them for exploring the solutions of challenges outlined in future research.}
}
@article{GODAVARTHI2021,
title = {Classification of covid related articles using machine learning},
journal = {Materials Today: Proceedings},
year = {2021},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.01.480},
url = {https://www.sciencedirect.com/science/article/pii/S221478532100571X},
author = {Deepthi Godavarthi and Mary Sowjanya A},
keywords = {COVID-19, Text classification, KNN, MLP, XGBoost, Explainability},
abstract = {Covid 19 pandemic has placed the entire world in a precarious condition. Earlier it was a serious issue in china whereas now it is being witnessed by citizens all over the world. Scientists are working hard to find treatment and vaccines for the coronavirus, also termed as covid. With the growing literature, it has become a major challenge for the medical community to find answers to questions related to covid-19. We have proposed a machine learning-based system that uses text classification applications of NLP to extract information from the scientific literature. Classification of large textual data makes the searching process easier thus useful for scientists. The main aim of our system is to classify the abstracts related to covid with their respective journals so that a researcher can refer to articles of his interest from the required journals instead of searching all the articles. In this paper, we describe our methodology needed to build such a system. Our system experiments on the COVID-19 open research dataset and the performance is evaluated using classifiers like KNN, MLP, etc. An explainer was also built using XGBoost to show the model predictions.}
}
@article{KONERT2021292,
title = {Military autonomous drones (UAVs) - from fantasy to reality. Legal and Ethical implications.},
journal = {Transportation Research Procedia},
volume = {59},
pages = {292-299},
year = {2021},
note = {10th International Conference on Air Transport – INAIR 2021, TOWARDS AVIATION REVIVAL},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2021.11.121},
url = {https://www.sciencedirect.com/science/article/pii/S2352146521008838},
author = {Anna Konert and Tomasz Balcerzak},
keywords = {drone, drone operators, liability of a State, human rights, military drones, right to life},
abstract = {Unmanned aerial vehicles, (UAVs), called drones, have recently greatly increased their role from simple surveillance and reconnaissance to increasingly controversial targeted killings. Autonomous drones raise important judicial and ethical issues about responsibility for unintentional harm which will be discussed in this paper. Autonomy refers to respect for human autonomy (in contrast with the autonomy of a drone) and includes the free choice of individuals and groups. In the context of drones used, the ethical principle of autonomy is translated into the human values, responsibility and trust. Some features of these unmanned combat aircraft (UAVs), such as flying at high altitudes, the ability to collect effective information and their impact on civilians, influence decisions on the legality of these weapons, and the distance between the operator of the aircraft and military targets also affects the principles of international law and humanitarian law. The paper will analyze the legal and ethical issues on using drones as a weapon.}
}
@article{LIMA20211058,
title = {Helping to detect legal swimming pools with Deep Learning and Data Visualization},
journal = {Procedia Computer Science},
volume = {181},
pages = {1058-1065},
year = {2021},
note = {CENTERIS 2020 - International Conference on ENTERprise Information Systems / ProjMAN 2020 - International Conference on Project MANagement / HCist 2020 - International Conference on Health and Social Care Information Systems and Technologies 2020, CENTERIS/ProjMAN/HCist 2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.01.301},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921003501},
author = {Bruno Lima and Luís Ferreira and João Martinho Moura},
keywords = {Artificial Intelligence, Orthophotomaps, Detection, GIS, Data Visualization, Pattern Recognition},
abstract = {The municipalities have, as a primary responsibility, the administrative management of their territory. The use of geographic information systems (GIS) and orthophoto maps can help to handle this task. One of the great difficulties they face is related to the continuous and quick changes that the territory suffers, and whose inspection is challenging to support. An example of this is the maintenance of the swimming pool registration system, in order to validate or license them. Indeed, it requires a substantial manual intervention, yet. This paper describes a system prototype for helping on detecting swimming pools on aerial images. It explores and integrates artificial intelligence (AI), systems integration, GIS, and data visualization. The AI improves the detection of objects, and middleware supports the integration of the detection results with other municipality systems for georeferencing and private property data licensing data crossing. To the innovative interoperability services, visualization libraries were explored, and an advanced visualization and analysis system was constructed. A dataset of aerial images of swimming pools and correspondent classification metadata was created. The model was trained with several convolutional neural networks in order to obtain and compare the precision results. The more accurate model is described.}
}
@article{LIN2022108710,
title = {A Novel Lyapunov based Dynamic Resource Allocation for UAVs-assisted Edge Computing},
journal = {Computer Networks},
volume = {205},
pages = {108710},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108710},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621005685},
author = {Jie Lin and Lin Huang and Hanlin Zhang and Xinyu Yang and Peng Zhao},
keywords = {UAVs-assisted edge computing, Dynamic resource allocation, Lyapunov optimization, System cost and utility},
abstract = {Mobile edge computing (MEC), as a key component in the development of IoT and 5G technologies, can provide extra computation resources in edge servers for mobile devices to complete their computation tasks with low latency and high reliability. Considerable efforts on computation offloading and resource allocation have been developed to reduce the energy consumption and computation latency in edge computing. Nonetheless, the system utility of heterogeneous edge computing system (e.g., UAVs-assisted edge computing), in which multiple unmanned aerial vehicles (UAVs) are involved in an edge computing system to serve as edge servers still needs to be further investigated. To this end, in this paper, we propose a novel Lyapunov based Dynamic Resource Allocation (LDRA) for UAVs-assisted Mobile Edge Computing, which can effectively choose suitable edge servers for mobile devices to offload and complete their computation tasks with low system cost and great system utility of UAVs-assisted edge computing system, as well as acceptable computation latency and great reliability for computation tasks of mobile devices. Particularly, a random queue model for edge servers is conducted in our LDRA scheme to support the dynamic of offloaded computation tasks of mobile devices. Additionally, a system cost model of UAVs-assisted edge computing is developed considering the combination of multiple constraints, such as both the mobility of UAVs and mobile devices, energy consumption, communication cost, etc. With the objective of minimizing the system cost and maximizing the system utility in providing edge resources to complete the offloaded computation tasks of mobile devices, by introducing Lyapunov optimization, a dynamic resource allocation scheme is proposed to effectively determine edge servers to offload tasks of mobile devices with considering both the real-time execution state of offloaded tasks in edge servers and states of the communication link. Through analysis and performance evaluations, our results show that our proposed LDRA scheme can achieve a great balance between system cost and system stability. Additionally, our results also demonstrate that our LDRA scheme also can achieve better system utility in comparison with existing schemes.}
}
@article{CAO2021102414,
title = {Combining UAV-based hyperspectral and LiDAR data for mangrove species classification using the rotation forest algorithm},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {102},
pages = {102414},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102414},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421001215},
author = {Jingjing Cao and Kai Liu and Li Zhuo and Lin Liu and Yuanhui Zhu and Liheng Peng},
keywords = {Mangrove species classification, Hyperspectral imaging, Unmanned aerial vehicle (UAV), Light detection and ranging (LiDAR), Rotation forest (RoF)},
abstract = {Accurate and timely monitoring of mangrove species information is crucial for precise management and practical conservation. Conventional hyperspectral techniques employed in mangrove monitoring are often limited to achieve the fine classification of mangrove species, due to the low spatial resolution of space-borne images and the high cost of airborne images. Moreover, using the spectral information alone is not adequate for fine-scale classification of mangrove species in complex ecosystems, because the spectral discriminability of mangrove species is generally restricted by complex canopy structures. To address these limitations, this study proposes a novel mangrove species classification method that integratively uses unmanned aerial vehicle (UAV)-based Nano-hyperspec hyperspectral imagery, light detection and ranging (LiDAR) data, and the rotation forest (RoF) ensemble learning algorithm. The proposed method was tested in China’s largest artificially planted mangroves, Qi'ao Island. First, we extracted spectral features from UAV-based hyperspectral data and structural information from LiDAR data; then we utilized the RoF algorithm to classify mangrove species based on the spectral and structural features and compared with two other popular ensemble learning algorithms, namely random forest (RF) and logistic model tree (LMT). Results showed that the combined hyperspectral and LiDAR data produced satisfactory results for all three classifiers with overall accuracy (OA) higher than 95%, and the proposed method achieved the highest OA of 97.22% and Kappa coefficient of 0.9686. Our study proved that incorporating the canopy height information can improve the classification accuracy, with the OA and Kappa coefficient being 2.43% and 0.0274 higher than using the original spectral bands alone, respectively. It is also found that the RoF algorithm is more accurate and stable in classifying mangrove species than those of RF and LMT. These findings indicated that the proposed approach could achieve fine-scale mangrove monitoring and further facilitate mangrove forest restoration and management.}
}
@article{SCOWEN2021149263,
title = {The current and future uses of machine learning in ecosystem service research},
journal = {Science of The Total Environment},
volume = {799},
pages = {149263},
year = {2021},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2021.149263},
url = {https://www.sciencedirect.com/science/article/pii/S0048969721043369},
author = {Matthew Scowen and Ioannis N. Athanasiadis and James M. Bullock and Felix Eigenbrod and Simon Willcock},
keywords = {Machine learning, Ecosystem services, Big data, Methodology, Validation, Data-driven modelling},
abstract = {Machine learning (ML) expands traditional data analysis and presents a range of opportunities in ecosystem service (ES) research, offering rapid processing of ‘big data’ and enabling significant advances in data description and predictive modelling. Descriptive ML techniques group data with little or no prior domain specific assumptions; they can generate hypotheses and automatically sort data prior to other analyses. Predictive ML techniques allow for the predictive modelling of highly non-linear systems where casual mechanisms are poorly understood, as is often the case for ES. We conducted a review to explore how ML is used in ES research and to identify and quantify trends in the different ML approaches that are used. We reviewed 308 peer-reviewed publications and identified that ES studies implemented machine learning techniques in data description (64%; n = 308) and predictive modelling (44%), with some papers containing both categories. Classification and Regression Trees were the most popular techniques (60%), but unsupervised learning techniques were also used for descriptive tasks such as clustering to group or split data without prior assumptions (19%). Whilst there are examples of ES publications that apply ML with rigour, many studies do not have robust or repeatable methods. Some studies fail to report model settings (43%) or software used (28%), and many studies do not report carrying out any form of model hyperparameter tuning (67%) or test model generalisability (59%). Whilst studies use ML to analyse very large and complex datasets, ES research is generally not taking full advantage of the capacity of ML to model big data (1138 medium number of data points; 13 median quantity of variables). There is great further opportunity to utilise ML in ES research, to make better use of big data and to develop detailed modelling of spatial-temporal dynamics that meet stakeholder demands.}
}
@article{DUONG2022101532,
title = {UAV caching in 6G networks: A Survey on models, techniques, and applications},
journal = {Physical Communication},
volume = {51},
pages = {101532},
year = {2022},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101532},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721002482},
author = {Trung Q. Duong and Kyeong Jin Kim and Zeeshan Kaleem and Minh-Phung Bui and Nguyen-Son Vo},
keywords = {6G networks, UAV communications with caching, UAV networks, UAV caching optimisation framework},
abstract = {The rapid development road map of 6G networks has posed a new set of challenges to both industrial and academic sectors. On the one hand, it needs more disruptive technologies and solutions for addressing the threefold issues including enhanced mobile broadband, massive machine-type communications, and ultra-reliable and low-latency communications. On the other hand, the ever-massive number of mobile users and Internet of Things devices conveys the huge volume of traffic throughout the 6G networks. In this context, caching is one of the most feasible technologies and solutions that does not require any system architecture changes nor costly investments, while significantly improve the system performance, i.e., quality of service and resource efficiency. Ground caching models deployed at macro base stations, small-cell base stations, and mobile devices have been successfully studied and currently extended to the air done by unmanned aerial vehicles (UAVs) to deal with the challenges of 6G networks. This paper provides a comprehensive survey of UAV caching models, techniques, and applications in 6G networks. In particular, we first investigate the entire picture of caching models moving from the ground to the air as well as the related surveys on UAV communications. Then, we introduce a typical UAV caching system and describe how it works in connection with all types of the transceivers, end users, and applications and services (A&Ss). After that, we present the recent advancements and analyses of the UAV caching models and common system performance metrics. Furthermore, the UAV caching with assisted techniques, UAV caching-enabled mechanisms, and UAV caching A&Ss are discussed to demonstrate the role of UAV caching system in 6G networks. Finally, we highlight the ongoing challenges and potential research directions toward UAV caching in 6G networks.}
}
@article{JAGANNATH2019101913,
title = {Machine learning for wireless communications in the Internet of Things: A comprehensive survey},
journal = {Ad Hoc Networks},
volume = {93},
pages = {101913},
year = {2019},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2019.101913},
url = {https://www.sciencedirect.com/science/article/pii/S1570870519300812},
author = {Jithin Jagannath and Nicholas Polosky and Anu Jagannath and Francesco Restuccia and Tommaso Melodia},
keywords = {Machine learning, Deep learning, Reinforcement learning, Internet of Things, Wireless ad hoc network, Spectrum sensing, Medium access control, Routing protocol},
abstract = {The Internet of Things (IoT) is expected to require more effective and efficient wireless communications than ever before. For this reason, techniques such as spectrum sharing, dynamic spectrum access, extraction of signal intelligence and optimized routing will soon become essential components of the IoT wireless communication paradigm. In this vision, IoT devices must be able to not only learn to autonomously extract spectrum knowledge on-the-fly from the network but also leverage such knowledge to dynamically change appropriate wireless parameters (e.g., frequency band, symbol modulation, coding rate, route selection, etc.) to reach the network’s optimal operating point. Given that the majority of the IoT will be composed of tiny, mobile, and energy-constrained devices, traditional techniques based on a priori network optimization may not be suitable, since (i) an accurate model of the environment may not be readily available in practical scenarios; (ii) the computational requirements of traditional optimization techniques may prove unbearable for IoT devices. To address the above challenges, much research has been devoted to exploring the use of machine learning to address problems in the IoT wireless communications domain. The reason behind machine learning’s popularity is that it provides a general framework to solve very complex problems where a model of the phenomenon being learned is too complex to derive or too dynamic to be summarized in mathematical terms. This work provides a comprehensive survey of the state of the art in the application of machine learning techniques to address key problems in IoT wireless communications with an emphasis on its ad hoc networking aspect. First, we present extensive background notions of machine learning techniques. Then, by adopting a bottom-up approach, we examine existing work on machine learning for the IoT at the physical, data-link and network layer of the protocol stack. Thereafter, we discuss directions taken by the community towards hardware implementation to ensure the feasibility of these techniques. Additionally, before concluding, we also provide a brief discussion of the application of machine learning in IoT beyond wireless communication. Finally, each of these discussions is accompanied by a detailed analysis of the related open problems and challenges.}
}
@article{SHI2021100014,
title = {Video-based trajectory extraction with deep learning for High-Granularity Highway Simulation (HIGH-SIM)},
journal = {Communications in Transportation Research},
volume = {1},
pages = {100014},
year = {2021},
issn = {2772-4247},
doi = {https://doi.org/10.1016/j.commtr.2021.100014},
url = {https://www.sciencedirect.com/science/article/pii/S2772424721000147},
author = {Xiaowei Shi and Dongfang Zhao and Handong Yao and Xiaopeng Li and David K. Hale and Amir Ghiasi},
keywords = {Video analytics, Image processing, Vehicle trajectory extraction, Deep learning, Microsimulation},
abstract = {High-granularity vehicle trajectory data can help researchers develop traffic simulation models, understand traffic flow characteristics, and thus propose insightful strategies for road traffic management. This paper proposes a novel vehicle trajectory extraction method that can extract high-granularity vehicle trajectories from aerial videos. The proposed method includes video calibration, vehicle detection and tracking, lane marking identification, and vehicle motion characteristics calculation. In particular, the authors propose a Monte-Carlo-based lane marking identification approach to identify each vehicle's lane. This is a challenging problem for vehicle trajectory extraction, especially when the aerial videos are taken from a high altitude. The authors applied the proposed method to extract vehicle trajectories from several high-resolution aerial videos recorded from helicopters. The extracted dataset is named by the High-Granularity Highway Simulation (HIGH-SIM) vehicle trajectory dataset. To demonstrate the effectiveness of the proposed method and understand the quality of the HIGH-SIM dataset, we compared the HIGH-SIM dataset with a well-known dataset, the NGSIM US-101 dataset, regarding the accuracy and consistency aspects. The comparison results showed that the HIGH-SIM dataset has more reasonable speed and acceleration distributions than the NGSIM US-101 dataset. Also, the internal and platoon consistencies of the HIGH-SIM dataset give lower errors compared to the NGSIM US-101 dataset. To benefit future research, the authors have published the HIGH-SIM dataset online for public use.}
}
@article{JATAIN2021,
title = {A contemplative perspective on federated machine learning: Taxonomy, threats & vulnerability assessment and challenges},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.05.016},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821001312},
author = {Divya Jatain and Vikram Singh and Naveen Dahiya},
keywords = {Federated Learning, Security Concerns, Language Modelling, Fog Computing, Healthcare Informatics, Vulnerability Assessment},
abstract = {Today, the rapid growth of the internet and advancements in mobile technology and increased internet connectivity have brought us to a data-driven economy where an enormous amount of data is being used to train machine learning models to make strategic decisions. However, in the aftermath of a data breach by Facebook in 2018, there are some serious concerns over user data privacy and security being used to train the Machine Learning models. In this context, a new approach, Federated Machine Learning is now one of the most talked-about and recent approaches. Current research primarily focuses on Federated Learning's advantages over the traditional methods and/or its classification. However, being in a nascent stage of development as a method, certain challenges need to be addressed. This paper intends to address the totality of federated learning with a complete vulnerability assessment. During the study of the literature, it is found that security being promised as one of the key advantages of federated learning can still not be guaranteed because of some issues inherently present, and this can lead to poisoning, inference attacks and insertion of backdoors, etc. This paper intends to provide a complete picture by giving an in-depth and comprehensive analysis of Federated Learning and its taxonomy. It also provides a detailed vulnerability assessment and highlights the challenges faced in the current setting and future research directions to make federated learning a more functional, robust and secure method to train machine learning models.}
}
@article{YING2021101239,
title = {Evaluation of water quality based on UAV images and the IMP-MPP algorithm},
journal = {Ecological Informatics},
volume = {61},
pages = {101239},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101239},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000303},
author = {Hanting Ying and Kai Xia and Xinxi Huang and Hailin Feng and Yinhui Yang and Xiaochen Du and Leijun Huang},
keywords = {Unmanned aerial vehicle, Multispectral, Suspended solids concentration, Turbidity, IMP-MPP algorithm},
abstract = {In recent years, UAV remote sensing has been used to estimate water quality parameters, such as suspended solids (SS), turbidity (TUB), and chlorophyll-a (chl-a) levels, due to its low cost, convenience, and high resolution. The matching pixel-by-pixel (MPP) algorithm is one of the methods to find the optimal regression equation for retrieving water quality parameters from UAV images. However, MPP has a high computational burden and commonly experiences overfitting problems. Therefore, we propose an improved MPP algorithm (called IMP-MPP) to solve the above problems by sampling pixels based on clustering results and selecting models with more filtering conditions. In this study, Qingshan Lake, Hangzhou City, Zhejiang Province, China, is taken as the study area to evaluate the suspended solids and turbidity indicators. A total of 45 in situ samples and the UAV images around the sampling points are analyzed and processed by the proposed IMP-MPP algorithm, along with the average value method and MPP for comparison purpose. The experimental results show that the determination coefficient, average relative error and comprehensive error of the best inversion model derived by the IMP-MPP algorithm for SS are 0.8255, 15.08%, and 0.1981, respectively. The determination coefficient, average relative error and comprehensive error of the best inversion model for TUB are 0.8311, 16.49% and 0.2033, respectively. The results suggest that the IMP-MPP algorithm is promising in finding more accurate inversion models for SS and TUB. Finally, based on the optimal models, suspended solids and turbidity distribution maps are generated for further research.}
}
@article{ZHANG2021116,
title = {MIDPhyNet: Memorized infusion of decomposed physics in neural networks to model dynamic systems},
journal = {Neurocomputing},
volume = {428},
pages = {116-129},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.11.042},
url = {https://www.sciencedirect.com/science/article/pii/S092523122031835X},
author = {Zhibo Zhang and Rahul Rai and Souma Chowdhury and David Doermann},
keywords = {Hybrid model, Physics infused machine learning, Physics guided machine learning, TCN, Empirical mode decomposition},
abstract = {Integrating simplified or partial physics models with data-driven machine learning models is an emerging concept targeted at facilitating generalizability and extrapolability of complex system behavior predictions. In this paper, we introduce a novel machine learning based fusion model MIDPhyNet that decomposes, memorizes, and integrates first principle physics-based information with data-driven models. In MIDPhyNet the output of partial physics is decomposed into Intrinsic Mode Functions (IMFs), which are then infused to a Memorization Unit to generate embedded vectors. A Prediction Unit synthesizes all of the data to generate prediction results. We test the performance of MIDPhyNet on modeling the behavior of dynamic systems such as an inverted pendulum under wind drag. The results clearly demonstrate the performance benefits of our hybrid architecture over both purely data-driven models and state-of-art hybrid models in terms of generalizability and extrapolability. The MIDPhyNet architecture’s superiority is most significant when the models are trained over sparse data sets and in general, MIDPhyNet provides a generic way to explore how physical information can be infused with data-driven models.}
}
@article{MARTINS2021127241,
title = {Deep learning-based tree species mapping in a highly diverse tropical urban setting},
journal = {Urban Forestry & Urban Greening},
volume = {64},
pages = {127241},
year = {2021},
issn = {1618-8667},
doi = {https://doi.org/10.1016/j.ufug.2021.127241},
url = {https://www.sciencedirect.com/science/article/pii/S1618866721002661},
author = {Gabriela Barbosa Martins and Laura Elena Cué {La Rosa} and Patrick Nigri Happ and Luiz Carlos Teixeira Coelho Filho and Celso Junius F. Santos and Raul Queiroz Feitosa and Matheus Pinheiro Ferreira},
keywords = {Tree species discrimination, Deep learning, Convolutional neural networks, Remote sensing},
abstract = {Spatially explicit information on urban tree species distribution is crucial for green infrastructure management in cities. This information is usually acquired with ground-based surveys, which are time-consuming and usually cover limited spatial extents. The combination of machine learning algorithms and remote sensing images has been hailed as a promising way to map tree species over broad areas. Recently, convolutional neural networks (CNNs), a type of deep learning method, have achieved outstanding results for tree species discrimination in various remote sensing data types. However, there is a lack of studies using CNN-based methods to produce tree species composition maps, particularly for tropical urban settings. Here, we propose a multi-task CNN to map tree species in a highly diverse neighborhood in Rio de Janeiro, Brazil. Our network architecture takes an aerial photograph (RGB bands and pixel size = 0.15 m) and delivers two outputs: a semantically segmented image and a distance map transform. In the former, all pixel positions are labeled, while in the latter, each pixel position contains the Euclidean distance to the crown boundary. We developed a post-processing approach that combines the two outputs, and we classified nine and five tree species with an average F1-score of 79.3 ± 8.6% and 87.6 ± 4.4%, respectively. Moreover, our post-processing approach produced a realistic tree species composition map by labeling only pixels of the target species with high class membership probabilities. Our results show the potential of CNNs and aerial photographs to map tree species in highly diverse tropical urban settings, providing valuable insights for urban forest management and green spaces planning.}
}
@article{KIM2019168,
title = {Remote proximity monitoring between mobile construction resources using camera-mounted UAVs},
journal = {Automation in Construction},
volume = {99},
pages = {168-182},
year = {2019},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0926580518304102},
author = {Daeho Kim and Meiyin Liu and SangHyun Lee and Vineet R. Kamat},
keywords = {Struck-by accident, Proximity monitoring, Unmanned aerial vehicle, Deep neural network, Computer vision},
abstract = {Struck-by accidents have resulted in a significant number of fatal and nonfatal injuries in the construction industry. As a proactive safety measure against struck-by hazards, the authors present an Unmanned Aerial Vehicle (UAV)-assisted visual monitoring method that can automatically measure proximities among construction entities. To attain this end, this research conducts two research thrusts: (i) object localization using a deep neural network, YOLO-V3; and (ii) development of an image rectification method that allows for the measurement of actual distance from a 2D image collected from a UAV. Tests on real-site aerial videos show the promising accuracy of the proposed method; the mean absolute distance errors for estimated proximity were less than 0.9 m and the mean absolute percentage errors were around 4%. The proposed method enables the advanced detection of struck-by hazards around workers, which in turn can make timely intervention possible. This proactive intervention can ultimately promote a safer working environment for construction workers.}
}
@article{VILLACRES202276,
title = {Construction of 3D maps of vegetation indices retrieved from UAV multispectral imagery in forested areas},
journal = {Biosystems Engineering},
volume = {213},
pages = {76-88},
year = {2022},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2021.11.025},
url = {https://www.sciencedirect.com/science/article/pii/S153751102100297X},
author = {Juan Villacrés and Fernando A. {Auat Cheein}},
keywords = {Fuel moisture content, Multispectral images, Vegetation indices estimation, Canopy segmentation},
abstract = {The construction of fuel moisture content (FMC) maps, as well as temperature, terrain topography, and wind speed maps, are essential for the development of fire susceptibility models in forested areas. Moisture distribution in tree canopies requires exploration and a three-dimensional representation. This paper presents the construction of FMC maps expressed as vegetation indices (VIs) in a point cloud. Multispectral images were captured by a camera mounted on an unmanned aerial vehicle to create the point cloud. VIs were estimated in the points that belonged to the forest canopy. To classify the canopy points, we a combination of filtering of ground points and thresholding of VIs was evaluated. On such canopy points, random forest (RF), kernel ridge regression (KRR), and Gaussian process retrieval (GPR) regressors were investigated to estimate twelve VIs related to FMC. The input set of the models consisted of the points representing five wavelengths provided by the multispectral camera. The ground truth of VIs was obtained using a spectrometer. The study area was a 1 ha forest of Pinus radiata in the Maule Region, Chile. The results demonstrated that combining ground filtering and VIs thresholding for canopy points segmentation achieved a precision of 93.27%, recall of 95.65%, F1 score of 90.12%, and accuracy of 87.82%. Furthermore, the recovery of the VIs using GPR achieved a root mean square error of 0.175 and a coefficient of determination of 0.18. According to the correlation coefficient, GPR was able to recover eleven of the twelve VIs, KRR recovered three, and RF failed to recover any.}
}

@Article{app11041835,
AUTHOR = {Liao, Kuo-Chien and Lu, Jau-Huai},
TITLE = {Using UAV to Detect Solar Module Fault Conditions of a Solar Power Farm with IR and Visual Image Analysis},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1835},
URL = {https://www.mdpi.com/2076-3417/11/4/1835},
ISSN = {2076-3417},
ABSTRACT = {In recent years, solar energy has been regarded as one of the most important sustainable energy sources. Under the rapid and large-scale construction of solar farms, the maintenance and inspection of the health conditions of solar modules in a large solar farm become an important issue. This article proposes a method for detecting solar cell faults with unmanned aerial vehicle (UAV) equipped with a thermal imager and a visible light camera, and providing a fast and reliable detection method. The detection process includes a new concept of real-time monitoring of the detected area and analysis of the health of solar panels. An image process is proposed that may quickly and accurately detect the abnormality of a solar module. The whole process includes grayscale conversion, filtering, 3-D temperature representation, probability density function, and cumulative density function analysis. Ten cases in real fields have been studied with this process, including large scale solar farms and small size solar modules installed on buildings. Results show that the cumulative density function is a convenient way to determine the health status of the solar panel and may provide maintenance personnel a basis for determining whether replacement of solar cells is necessary for improving the overall power generation efficiency and simplify the maintenance process. It is worth noting that image recognition can increase the clarity of IR images and the cumulative chart can judge the defect rate of the cell. These two methods were combined to provide an instant, fast and accurate defect judgment.},
DOI = {10.3390/app11041835}
}



@Article{mi12020214,
AUTHOR = {Han, Shipeng and Meng, Zhen and Zhang, Xingcheng and Yan, Yuepeng},
TITLE = {Hybrid Deep Recurrent Neural Networks for Noise Reduction of MEMS-IMU with Static and Dynamic Conditions},
JOURNAL = {Micromachines},
VOLUME = {12},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {214},
URL = {https://www.mdpi.com/2072-666X/12/2/214},
PubMedID = {33672478},
ISSN = {2072-666X},
ABSTRACT = {Micro-electro-mechanical system inertial measurement unit (MEMS-IMU), a core component in many navigation systems, directly determines the accuracy of inertial navigation system; however, MEMS-IMU system is often affected by various factors such as environmental noise, electronic noise, mechanical noise and manufacturing error. These can seriously affect the application of MEMS-IMU used in different fields. Focus has been on MEMS gyro since it is an essential and, yet, complex sensor in MEMS-IMU which is very sensitive to noises and errors from the random sources. In this study, recurrent neural networks are hybridized in four different ways for noise reduction and accuracy improvement in MEMS gyro. These are two-layer homogenous recurrent networks built on long short term memory (LSTM-LSTM) and gated recurrent unit (GRU-GRU), respectively; and another two-layer but heterogeneous deep networks built on long short term memory-gated recurrent unit (LSTM-GRU) and a gated recurrent unit-long short term memory (GRU-LSTM). Practical implementation with static and dynamic experiments was carried out for a custom MEMS-IMU to validate the proposed networks, and the results show that GRU-LSTM seems to be overfitting large amount data testing for three-dimensional axis gyro in the static test. However, for X-axis and Y-axis gyro, LSTM-GRU had the best noise reduction effect with over 90% improvement in the three axes. For Z-axis gyroscope, LSTM-GRU performed better than LSTM-LSTM and GRU-GRU in quantization noise and angular random walk, while LSTM-LSTM shows better improvement than both GRU-GRU and LSTM-GRU networks in terms of zero bias stability. In the dynamic experiments, the Hilbert spectrum carried out revealed that time-frequency energy of the LSTM-LSTM, GRU-GRU, and GRU-LSTM denoising are higher compared to LSTM-GRU in terms of the whole frequency domain. Similarly, Allan variance analysis also shows that LSTM-GRU has a better denoising effect than the other networks in the dynamic experiments. Overall, the experimental results demonstrate the effectiveness of deep learning algorithms in MEMS gyro noise reduction, among which LSTM-GRU network shows the best noise reduction effect and great potential for application in the MEMS gyroscope area.},
DOI = {10.3390/mi12020214}
}



@Article{app11041861,
AUTHOR = {Rong, Zihao and Wang, Shaofan and Kong, Dehui and Yin, Baocai},
TITLE = {A Cascaded Ensemble of Sparse-and-Dense Dictionaries for Vehicle Detection},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1861},
URL = {https://www.mdpi.com/2076-3417/11/4/1861},
ISSN = {2076-3417},
ABSTRACT = {Vehicle detection as a special case of object detection has practical meaning but faces challenges, such as the difficulty of detecting vehicles of various orientations, the serious influence from occlusion, the clutter of background, etc. In addition, existing effective approaches, like deep-learning-based ones, demand a large amount of training time and data, which causes trouble for their application. In this work, we propose a dictionary-learning-based vehicle detection approach which explicitly addresses these problems. Specifically, an ensemble of sparse-and-dense dictionaries (ESDD) are learned through supervised low-rank decomposition; each pair of sparse-and-dense dictionaries (SDD) in the ensemble is trained to represent either a subcategory of vehicle (corresponding to certain orientation range or occlusion level) or a subcategory of background (corresponding to a cluster of background patterns) and only gives good reconstructions to samples of the corresponding subcategory, making the ESDD capable of classifying vehicles from background even though they exhibit various appearances. We further organize ESDD into a two-level cascade (CESDD) to perform coarse-to-fine two-stage classification for better performance and computation reduction. The CESDD is then coupled with a downstream AdaBoost process to generate robust classifications. The proposed CESDD model is used as a window classifier in a sliding-window scan process over image pyramids to produce multi-scale detections, and an adapted mean-shift-like non-maximum suppression process is adopted to remove duplicate detections. Our CESDD vehicle detection approach is evaluated on KITTI dataset and compared with other strong counterparts; the experimental results exhibit the effectiveness of CESDD-based classification and detection, and the training of CESDD only demands small amount of time and data.},
DOI = {10.3390/app11041861}
}



@Article{s21041492,
AUTHOR = {Li, Guoming and Huang, Yanbo and Chen, Zhiqian and Chesser, Gary D. and Purswell, Joseph L. and Linhoss, John and Zhao, Yang},
TITLE = {Practices and Applications of Convolutional Neural Network-Based Computer Vision Systems in Animal Farming: A Review},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1492},
URL = {https://www.mdpi.com/1424-8220/21/4/1492},
PubMedID = {33670030},
ISSN = {1424-8220},
ABSTRACT = {Convolutional neural network (CNN)-based computer vision systems have been increasingly applied in animal farming to improve animal management, but current knowledge, practices, limitations, and solutions of the applications remain to be expanded and explored. The objective of this study is to systematically review applications of CNN-based computer vision systems on animal farming in terms of the five deep learning computer vision tasks: image classification, object detection, semantic/instance segmentation, pose estimation, and tracking. Cattle, sheep/goats, pigs, and poultry were the major farm animal species of concern. In this research, preparations for system development, including camera settings, inclusion of variations for data recordings, choices of graphics processing units, image preprocessing, and data labeling were summarized. CNN architectures were reviewed based on the computer vision tasks in animal farming. Strategies of algorithm development included distribution of development data, data augmentation, hyperparameter tuning, and selection of evaluation metrics. Judgment of model performance and performance based on architectures were discussed. Besides practices in optimizing CNN-based computer vision systems, system applications were also organized based on year, country, animal species, and purposes. Finally, recommendations on future research were provided to develop and improve CNN-based computer vision systems for improved welfare, environment, engineering, genetics, and management of farm animals.},
DOI = {10.3390/s21041492}
}



@Article{app11041900,
AUTHOR = {Aljohani, Sarah L. and Alenazi, Mohammed J. F.},
TITLE = {MPResiSDN: Multipath Resilient Routing Scheme for SDN-Enabled Smart Cities Networks},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1900},
URL = {https://www.mdpi.com/2076-3417/11/4/1900},
ISSN = {2076-3417},
ABSTRACT = {The number of smart cities is increasing rapidly around the world with the continuous increase of governments’ interest in exploiting Information and Communication Technologies (ICT) to solve issues arising from rapid urbanization. Most smart city services rely fundamentally on ubiquitous sensing, enabled by Wireless Sensor Network (WSN) technologies. However, WSNs in smart cities are naturally vulnerable to unavoidable external challenges like storms, fires, and other natural disasters. Such challenges pose a great threat to smart city infrastructure, including WSNs, as they might affect network connectivity or result in complete blockages of network services. However, some particular smart city services are critical, to the point where they must remain available in all situations, especially during disasters; to monitor the disaster and obtain sensory information needed for controlling it, limiting its danger, or for decision-making during rescue operations. Thus, it is crucial to design a smart-city network to maintain connectivity against such challenges. In this paper, we introduce MPResiSDN, a MultiPath Resilient routing system based on Software Defined Networking (SDN). The system introduced exploits SDN’s capabilities and aided-multipath routing to reactively provide connectivity in smart city networks in the presence of challenges. We evaluated our proposed system under simulations of different natural disasters. The results demonstrate that the system improved data delivery under the challenges by as much as 100% compared to the Spanning Tree Protocol when a suitable value for k diverse paths was selected.},
DOI = {10.3390/app11041900}
}



@Article{rs13040808,
AUTHOR = {Neupane, Bipul and Horanont, Teerayut and Aryal, Jagannath},
TITLE = {Deep Learning-Based Semantic Segmentation of Urban Features in Satellite Images: A Review and Meta-Analysis},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {808},
URL = {https://www.mdpi.com/2072-4292/13/4/808},
ISSN = {2072-4292},
ABSTRACT = {Availability of very high-resolution remote sensing images and advancement of deep learning methods have shifted the paradigm of image classification from pixel-based and object-based methods to deep learning-based semantic segmentation. This shift demands a structured analysis and revision of the current status on the research domain of deep learning-based semantic segmentation. The focus of this paper is on urban remote sensing images. We review and perform a meta-analysis to juxtapose recent papers in terms of research problems, data source, data preparation methods including pre-processing and augmentation techniques, training details on architectures, backbones, frameworks, optimizers, loss functions and other hyper-parameters and performance comparison. Our detailed review and meta-analysis show that deep learning not only outperforms traditional methods in terms of accuracy, but also addresses several challenges previously faced. Further, we provide future directions of research in this domain.},
DOI = {10.3390/rs13040808}
}



@Article{app11041950,
AUTHOR = {Qi, Haixia and Liang, Yu and Ding, Quanchen and Zou, Jun},
TITLE = {Automatic Identification of Peanut-Leaf Diseases Based on Stack Ensemble},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1950},
URL = {https://www.mdpi.com/2076-3417/11/4/1950},
ISSN = {2076-3417},
ABSTRACT = {Peanut is an important food crop, and diseases of its leaves can directly reduce its yield and quality. In order to solve the problem of automatic identification of peanut-leaf diseases, this paper uses a traditional machine-learning method to ensemble the output of a deep learning model to identify diseases of peanut leaves. The identification of peanut-leaf diseases included healthy leaves, rust disease on a single leaf, leaf-spot disease on a single leaf, scorch disease on a single leaf, and both rust disease and scorch disease on a single leaf. Three types of data-augmentation methods were used: image flipping, rotation, and scaling. In this experiment, the deep-learning model had a higher accuracy than the traditional machine-learning methods. Moreover, the deep-learning model achieved better performance when using data augmentation and a stacking ensemble. After ensemble by logistic regression, the accuracy of residual network with 50 layers (ResNet50) was as high as 97.59%, and the F1 score of dense convolutional network with 121 layers (DenseNet121) was as high as 90.50. The deep-learning model used in this experiment had the greatest improvement in F1 score after the logistic regression ensemble. Deep-learning networks with deeper network layers like ResNet50 and DenseNet121 performed better in this experiment. This study can provide a reference for the identification of peanut-leaf diseases.},
DOI = {10.3390/app11041950}
}



@Article{rs13040814,
AUTHOR = {Megahed, Yasmine and Shaker, Ahmed and Yan, Wai Yeung},
TITLE = {Fusion of Airborne LiDAR Point Clouds and Aerial Images for Heterogeneous Land-Use Urban Mapping},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {814},
URL = {https://www.mdpi.com/2072-4292/13/4/814},
ISSN = {2072-4292},
ABSTRACT = {The World Health Organization has reported that the number of worldwide urban residents is expected to reach 70% of the total world population by 2050. In the face of challenges brought about by the demographic transition, there is an urgent need to improve the accuracy of urban land-use mappings to more efficiently inform about urban planning processes. Decision-makers rely on accurate urban mappings to properly assess current plans and to develop new ones. This study investigates the effects of including conventional spectral signatures acquired by different sensors on the classification of airborne LiDAR (Light Detection and Ranging) point clouds using multiple feature spaces. The proposed method applied three machine learning algorithms—ML (Maximum Likelihood), SVM (Support Vector Machines), and MLP (Multilayer Perceptron Neural Network)—to classify LiDAR point clouds of a residential urban area after being geo-registered to aerial photos. The overall classification accuracy passed 97%, with height as the only geometric feature in the classifying space. Misclassifications occurred among different classes due to independent acquisition of aerial and LiDAR data as well as shadow and orthorectification problems from aerial images. Nevertheless, the outcomes are promising as they surpassed those achieved with large geometric feature spaces and are encouraging since the approach is computationally reasonable and integrates radiometric properties from affordable sensors.},
DOI = {10.3390/rs13040814}
}



@Article{rs13050842,
AUTHOR = {Hegyi, Alexandru and Diaconescu, Dragoș and Urdea, Petru and Sarris, Apostolos and Pisz, Michał and Onaca, Alexandru},
TITLE = {Using Geophysics to Characterize a Prehistoric Burial Mound in Romania},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {842},
URL = {https://www.mdpi.com/2072-4292/13/5/842},
ISSN = {2072-4292},
ABSTRACT = {A geophysical investigation was carried across the M3 burial mound from Silvașu de Jos —Dealu Țapului, a tumuli necropolis in western Romania, where the presence of the Yamnaya people was certified archaeologically. For characterizing the inner structure of the mound, two conventional geophysical methods have been used: a geomagnetic survey and electrical resistivity tomography (ERT). The results allowed the mapping of the central features of the mound and the establishment of the relative stratigraphy of the mantle, which indicated at least two chronological phases. Archaeological excavations performed in the central part of the mound accurately validated the non-invasive geophysical survey and offered a valuable chronological record of the long-forgotten archaeological monument. Geophysical approaches proved to be an invaluable instrument for the exploration of the monument and suggest a fast constructive tool for the investigation of the entire necropolis which currently has a number of distinct mounds.},
DOI = {10.3390/rs13050842}
}



@Article{su13052461,
AUTHOR = {Imran and Iqbal, Naeem and Ahmad, Shabir and Kim, Do Hyeun},
TITLE = {Towards Mountain Fire Safety Using Fire Spread Predictive Analytics and Mountain Fire Containment in IoT Environment},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {2461},
URL = {https://www.mdpi.com/2071-1050/13/5/2461},
ISSN = {2071-1050},
ABSTRACT = {Mountains are popular tourist destinations due to their climate, fresh atmosphere, breathtaking sceneries, and varied topography. However, they are at times exposed to accidents, such as fire caused due to natural hazards and human activities. Such unforeseen fire accidents have a social, economic, and environmental impact on mountain towns worldwide. Protecting mountains from such fire accidents is also very challenging in terms of the high cost of fire containment resources, tracking fire spread, and evacuating the people at risk. This paper aims to fill this gap and proposes a three-fold methodology for fire safety in the mountains. The first part of the methodology is an optimization model for effective fire containment resource utilization. The second part of the methodology is a novel ensemble model based on machine learning, the heuristic approach, and principal component regression for predictive analytics of fire spread data. The final part of the methodology consists of an Internet of Things-based task orchestration approach to notify fire safety information to safety authorities. The proposed three-fold fire safety approach provides in-time information to safety authorities for making on-time decisions to minimize the damage caused by mountain fire with minimum containment cost. The performance of optimization models is evaluated in terms of execution time and cost. The particle swarm optimization-based model performs better in terms of cost, whereas the bat algorithm performs better in terms of execution time. The prediction models’ performance is evaluated in terms of root mean square error, mean absolute error, and mean absolute percentage error. The proposed ensemble-based prediction model accuracy for fire spread and burned area prediction is higher than that of the state-of-the-art algorithms. It is evident from the results that the proposed fire safety mechanism is a step towards efficient mountain fire safety management.},
DOI = {10.3390/su13052461}
}



@Article{s21051604,
AUTHOR = {Pant, Shashank and Nooralishahi, Parham and Avdelidis, Nicolas P. and Ibarra-Castanedo, Clemente and Genest, Marc and Deane, Shakeb and Valdes, Julio J. and Zolotas, Argyrios and Maldague, Xavier P. V.},
TITLE = {Evaluation and Selection of Video Stabilization Techniques for UAV-Based Active Infrared Thermography Application},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {1604},
URL = {https://www.mdpi.com/1424-8220/21/5/1604},
PubMedID = {33668881},
ISSN = {1424-8220},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) that can fly around an aircraft carrying several sensors, e.g., thermal and optical cameras, to inspect the parts of interest without removing them can have significant impact in reducing inspection time and cost. One of the main challenges in the UAV based active InfraRed Thermography (IRT) inspection is the UAV’s unexpected motions. Since active thermography is mainly concerned with the analysis of thermal sequences, unexpected motions can disturb the thermal profiling and cause data misinterpretation especially for providing an automated process pipeline of such inspections. Additionally, in the scenarios where post-analysis is intended to be applied by an inspector, the UAV’s unexpected motions can increase the risk of human error, data misinterpretation, and incorrect characterization of possible defects. Therefore, post-processing is required to minimize/eliminate such undesired motions using digital video stabilization techniques. There are number of video stabilization algorithms that are readily available; however, selecting the best suited one is also challenging. Therefore, this paper evaluates video stabilization algorithms to minimize/mitigate undesired UAV motion and proposes a simple method to find the best suited stabilization algorithm as a fundamental first step towards a fully operational UAV-IRT inspection system.},
DOI = {10.3390/s21051604}
}



@Article{s21051617,
AUTHOR = {Safonova, Anastasiia and Guirado, Emilio and Maglinets, Yuriy and Alcaraz-Segura, Domingo and Tabik, Siham},
TITLE = {Olive Tree Biovolume from UAV Multi-Resolution Image Segmentation with Mask R-CNN},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {1617},
URL = {https://www.mdpi.com/1424-8220/21/5/1617},
PubMedID = {33668984},
ISSN = {1424-8220},
ABSTRACT = {Olive tree growing is an important economic activity in many countries, mostly in the Mediterranean Basin, Argentina, Chile, Australia, and California. Although recent intensification techniques organize olive groves in hedgerows, most olive groves are rainfed and the trees are scattered (as in Spain and Italy, which account for 50% of the world’s olive oil production). Accurate measurement of trees biovolume is a first step to monitor their performance in olive production and health. In this work, we use one of the most accurate deep learning instance segmentation methods (Mask R-CNN) and unmanned aerial vehicles (UAV) images for olive tree crown and shadow segmentation (OTCS) to further estimate the biovolume of individual trees. We evaluated our approach on images with different spectral bands (red, green, blue, and near infrared) and vegetation indices (normalized difference vegetation index—NDVI—and green normalized difference vegetation index—GNDVI). The performance of red-green-blue (RGB) images were assessed at two spatial resolutions 3 cm/pixel and 13 cm/pixel, while NDVI and GNDV images were only at 13 cm/pixel. All trained Mask R-CNN-based models showed high performance in the tree crown segmentation, particularly when using the fusion of all dataset in GNDVI and NDVI (F1-measure from 95% to 98%). The comparison in a subset of trees of our estimated biovolume with ground truth measurements showed an average accuracy of 82%. Our results support the use of NDVI and GNDVI spectral indices for the accurate estimation of the biovolume of scattered trees, such as olive trees, in UAV images.},
DOI = {10.3390/s21051617}
}



@Article{rs13050858,
AUTHOR = {Koh, Joshua C.O. and Spangenberg, German and Kant, Surya},
TITLE = {Automated Machine Learning for High-Throughput Image-Based Plant Phenotyping},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {858},
URL = {https://www.mdpi.com/2072-4292/13/5/858},
ISSN = {2072-4292},
ABSTRACT = {Automated machine learning (AutoML) has been heralded as the next wave in artificial intelligence with its promise to deliver high-performance end-to-end machine learning pipelines with minimal effort from the user. However, despite AutoML showing great promise for computer vision tasks, to the best of our knowledge, no study has used AutoML for image-based plant phenotyping. To address this gap in knowledge, we examined the application of AutoML for image-based plant phenotyping using wheat lodging assessment with unmanned aerial vehicle (UAV) imagery as an example. The performance of an open-source AutoML framework, AutoKeras, in image classification and regression tasks was compared to transfer learning using modern convolutional neural network (CNN) architectures. For image classification, which classified plot images as lodged or non-lodged, transfer learning with Xception and DenseNet-201 achieved the best classification accuracy of 93.2%, whereas AutoKeras had a 92.4% accuracy. For image regression, which predicted lodging scores from plot images, transfer learning with DenseNet-201 had the best performance (R2 = 0.8303, root mean-squared error (RMSE) = 9.55, mean absolute error (MAE) = 7.03, mean absolute percentage error (MAPE) = 12.54%), followed closely by AutoKeras (R2 = 0.8273, RMSE = 10.65, MAE = 8.24, MAPE = 13.87%). In both tasks, AutoKeras models had up to 40-fold faster inference times compared to the pretrained CNNs. AutoML has significant potential to enhance plant phenotyping capabilities applicable in crop breeding and precision agriculture.},
DOI = {10.3390/rs13050858}
}



@Article{s21051631,
AUTHOR = {Martini, Bruno Guilherme and Helfer, Gilson Augusto and Barbosa, Jorge Luis Victória and Espinosa Modolo, Regina Célia and da Silva, Marcio Rosa and de Figueiredo, Rodrigo Marques and Mendes, André Sales and Silva, Luís Augusto and Leithardt, Valderi Reis Quietinho},
TITLE = {IndoorPlant: A Model for Intelligent Services in Indoor Agriculture Based on Context Histories},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {1631},
URL = {https://www.mdpi.com/1424-8220/21/5/1631},
PubMedID = {33652603},
ISSN = {1424-8220},
ABSTRACT = {The application of ubiquitous computing has increased in recent years, especially due to the development of technologies such as mobile computing, more accurate sensors, and specific protocols for the Internet of Things (IoT). One of the trends in this area of research is the use of context awareness. In agriculture, the context involves the environment, for example, the conditions found inside a greenhouse. Recently, a series of studies have proposed the use of sensors to monitor production and/or the use of cameras to obtain information about cultivation, providing data, reminders, and alerts to farmers. This article proposes a computational model for indoor agriculture called IndoorPlant. The model uses the analysis of context histories to provide intelligent generic services, such as predicting productivity, indicating problems that cultivation may suffer, and giving suggestions for improvements in greenhouse parameters. IndoorPlant was tested in three scenarios of the daily life of farmers with hydroponic production data that were obtained during seven months of cultivation of radicchio, lettuce, and arugula. Finally, the article presents the results obtained through intelligent services that use context histories. The scenarios used services to recommend improvements in cultivation, profiles and, finally, prediction of the cultivation time of radicchio, lettuce, and arugula using the partial least squares (PLS) regression technique. The prediction results were relevant since the following values were obtained: 0.96 (R2, coefficient of determination), 1.06 (RMSEC, square root of the mean square error of calibration), and 1.94 (RMSECV, square root of the mean square error of cross validation) for radicchio; 0.95 (R2), 1.37 (RMSEC), and 3.31 (RMSECV) for lettuce; 0.93 (R2), 1.10 (RMSEC), and 1.89 (RMSECV) for arugula. Eight farmers with different functions on the farm filled out a survey based on the technology acceptance model (TAM). The results showed 92% acceptance regarding utility and 98% acceptance for ease of use.},
DOI = {10.3390/s21051631}
}



@Article{rs13050907,
AUTHOR = {Lendzioch, Theodora and Langhammer, Jakub and Vlček, Lukáš and Minařík, Robert},
TITLE = {Mapping the Groundwater Level and Soil Moisture of a Montane Peat Bog Using UAV Monitoring and Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {907},
URL = {https://www.mdpi.com/2072-4292/13/5/907},
ISSN = {2072-4292},
ABSTRACT = {One of the best preconditions for the sufficient monitoring of peat bog ecosystems is the collection, processing, and analysis of unique spatial data to understand peat bog dynamics. Over two seasons, we sampled groundwater level (GWL) and soil moisture (SM) ground truth data at two diverse locations at the Rokytka Peat bog within the Sumava Mountains, Czechia. These data served as reference data and were modeled with a suite of potential variables derived from digital surface models (DSMs) and RGB, multispectral, and thermal orthoimages reflecting topomorphometry, vegetation, and surface temperature information generated from drone mapping. We used 34 predictors to feed the random forest (RF) algorithm. The predictor selection, hyperparameter tuning, and performance assessment were performed with the target-oriented leave-location-out (LLO) spatial cross-validation (CV) strategy combined with forward feature selection (FFS) to avoid overfitting and to predict on unknown locations. The spatial CV performance statistics showed low (R2 = 0.12) to high (R2 = 0.78) model predictions. The predictor importance was used for model interpretation, where temperature had strong impact on GWL and SM, and we found significant contributions of other predictors, such as Normalized Difference Vegetation Index (NDVI), Normalized Difference Index (NDI), Enhanced Red-Green-Blue Vegetation Index (ERGBVE), Shape Index (SHP), Green Leaf Index (GLI), Brightness Index (BI), Coloration Index (CI), Redness Index (RI), Primary Colours Hue Index (HI), Overall Hue Index (HUE), SAGA Wetness Index (TWI), Plan Curvature (PlnCurv), Topographic Position Index (TPI), and Vector Ruggedness Measure (VRM). Additionally, we estimated the area of applicability (AOA) by presenting maps where the prediction model yielded high-quality results and where predictions were highly uncertain because machine learning (ML) models make predictions far beyond sampling locations without sampling data with no knowledge about these environments. The AOA method is well suited and unique for planning and decision-making about the best sampling strategy, most notably with limited data.},
DOI = {10.3390/rs13050907}
}



@Article{geosciences11030108,
AUTHOR = {Elíasson, Jόnas and Sæmundsson, Þorsteinn},
TITLE = {Physics and Modeling of Various Hazardous Landslides},
JOURNAL = {Geosciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {108},
URL = {https://www.mdpi.com/2076-3263/11/3/108},
ISSN = {2076-3263},
ABSTRACT = {In 2014, the Varnes classification system for landslides was updated. Complex landslides can still be a problem to classify as the classification does not include the flow type in the hydrodynamical sense. Three examples of Icelandic landslides are presented and later used as case studies in order to demonstrate the methods suggested to analyze the flow. The methods are based on the different physical properties of the flow types of the slides. Three different flow types are presented, named type (i), (ii), and (iii). Types (i) and (ii) do not include turbulent flows and their flow paths are sometimes independent of the velocity. Type (iii) include high velocity flows; they are treated with the translator wave theory, where a new type of a slope factor is used. It allows the slide to stop when the slope has flattened out to the value that corresponds to the stable slope property of the flowing material. The type studies are for a fast slide of this type, also a large slip circle slide that turns into a fast-flowing slide farther down the path and finally a large slide running so fast that it can run for a kilometer on flat land where it stops with a steep front.},
DOI = {10.3390/geosciences11030108}
}



@Article{s21051682,
AUTHOR = {Tai, Kuan-Chen and Tang, Chih-Wei},
TITLE = {Siamese Networks-Based People Tracking Using Template Update for 360-Degree Videos Using EAC Format},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {1682},
URL = {https://www.mdpi.com/1424-8220/21/5/1682},
PubMedID = {33804396},
ISSN = {1424-8220},
ABSTRACT = {Rich information is provided by 360-degree videos. However, non-uniform geometric deformation caused by sphere-to-plane projection significantly decreases tracking accuracy of existing trackers, and the huge amount of data makes it difficult to achieve real-time tracking. Thus, this paper proposes a Siamese networks-based people tracker using template update for 360-degree equi-angular cubemap (EAC) format videos. Face stitching overcomes the problem of content discontinuity of the EAC format and avoids raising new geometric deformation in stitched images. Fully convolutional Siamese networks enable tracking at high speed. Mostly important, to be robust against combination of non-uniform geometric deformation of the EAC format and partial occlusions caused by zero padding in stitched images, this paper proposes a novel Bayes classifier-based timing detector of template update by referring to the linear discriminant feature and statistics of a score map generated by Siamese networks. Experimental results show that the proposed scheme significantly improves tracking accuracy of the fully convolutional Siamese networks SiamFC on the EAC format with operation beyond the frame acquisition rate. Moreover, the proposed score map-based timing detector of template update outperforms state-of-the-art score map-based timing detectors.},
DOI = {10.3390/s21051682}
}



@Article{s21051688,
AUTHOR = {Ali, Luqman and Alnajjar, Fady and Jassmi, Hamad Al and Gocho, Munkhjargal and Khan, Wasif and Serhani, M. Adel},
TITLE = {Performance Evaluation of Deep CNN-Based Crack Detection and Localization Techniques for Concrete Structures},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {1688},
URL = {https://www.mdpi.com/1424-8220/21/5/1688},
PubMedID = {33804490},
ISSN = {1424-8220},
ABSTRACT = {This paper proposes a customized convolutional neural network for crack detection in concrete structures. The proposed method is compared to four existing deep learning methods based on training data size, data heterogeneity, network complexity, and the number of epochs. The performance of the proposed convolutional neural network (CNN) model is evaluated and compared to pretrained networks, i.e., the VGG-16, VGG-19, ResNet-50, and Inception V3 models, on eight datasets of different sizes, created from two public datasets. For each model, the evaluation considered computational time, crack localization results, and classification measures, e.g., accuracy, precision, recall, and F1-score. Experimental results demonstrated that training data size and heterogeneity among data samples significantly affect model performance. All models demonstrated promising performance on a limited number of diverse training data; however, increasing the training data size and reducing diversity reduced generalization performance, and led to overfitting. The proposed customized CNN and VGG-16 models outperformed the other methods in terms of classification, localization, and computational time on a small amount of data, and the results indicate that these two models demonstrate superior crack detection and localization for concrete structures.},
DOI = {10.3390/s21051688}
}



@Article{ijgi10030127,
AUTHOR = {Liu, Dan and Li, Dajun and Wang, Meizhen and Wang, Zhiming},
TITLE = {3D Change Detection Using Adaptive Thresholds Based on Local Point Cloud Density},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {127},
URL = {https://www.mdpi.com/2220-9964/10/3/127},
ISSN = {2220-9964},
ABSTRACT = {In recent years, because of highly developed LiDAR (Light Detection and Ranging) technologies, there has been increasing demand for 3D change detection in urban monitoring, urban model updating, and disaster assessment. In order to improve the effectiveness of 3D change detection based on point clouds, an approach for 3D change detection using point-based comparison is presented in this paper. To avoid density variation in point clouds, adaptive thresholds are calculated through the k-neighboring average distance and the local point cloud density. A series of experiments for quantitative evaluation is performed. In the experiments, the influencing factors including threshold, registration error, and neighboring number of 3D change detection are discussed and analyzed. The results of the experiments demonstrate that the approach using adaptive thresholds based on local point cloud density are effective and suitable.},
DOI = {10.3390/ijgi10030127}
}



@Article{app11052185,
AUTHOR = {Nakama, Justin and Parada, Ricky and Matos-Carvalho, João P. and Azevedo, Fábio and Pedro, Dário and Campos, Luís},
TITLE = {Autonomous Environment Generator for UAV-Based Simulation},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {2185},
URL = {https://www.mdpi.com/2076-3417/11/5/2185},
ISSN = {2076-3417},
ABSTRACT = {The increased demand for Unmanned Aerial Vehicles (UAV) has also led to higher demand for realistic and efficient UAV testing environments. The current use of simulated environments has been shown to be a relatively inexpensive, safe, and repeatable way to evaluate UAVs before real-world use. However, the use of generic environments and manually-created custom scenarios leaves more to be desired. In this paper, we propose a new testbed that utilizes machine learning algorithms to procedurally generate, scale, and place 3D models to create a realistic environment. These environments are additionally based on satellite images, thus providing users with a more robust example of real-world UAV deployment. Although certain graphical improvements could be made, this paper serves as a proof of concept for an novel autonomous and relatively-large scale environment generator. Such a testbed could allow for preliminary operational planning and testing worldwide, without the need for on-site evaluation or data collection in the future.},
DOI = {10.3390/app11052185}
}



@Article{f12030292,
AUTHOR = {Lin, Wenshu and Fan, Weiwei and Liu, Haoran and Xu, Yongsheng and Wu, Jinzhuo},
TITLE = {Classification of Handheld Laser Scanning Tree Point Cloud Based on Different KNN Algorithms and Random Forest Algorithm},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {292},
URL = {https://www.mdpi.com/1999-4907/12/3/292},
ISSN = {1999-4907},
ABSTRACT = {Handheld mobile laser scanning (HMLS) can quickly acquire point cloud data, and has the potential to conduct forest inventory at the plot scale. Considering the problems associated with HMLS data such as large discreteness and difficulty in classification, different classification models were compared in order to realize efficient separation of stem, branch and leaf points from HMLS data. First, the HMLS point cloud was normalized and ground points were removed, then the neighboring points were identified according to three KNN algorithms and eight geometric features were constructed. On this basis, the random forest classifier was used to calculate feature importance and perform dataset training. Finally, the classification accuracy of different KNN algorithms-based models was evaluated. Results showed that the training sample classification accuracy based on the adaptive radius KNN algorithm was the highest (0.9659) among the three KNN algorithms, but its feature calculation time was also longer; The validation accuracy of two test sets was 0.9596 and 0.9201, respectively, which is acceptable, and the misclassification mainly occurred in the branch junction of the canopy. Therefore, the optimal classification model can effectively achieve the classification of stem, branch and leaf points from HMLS point cloud under the premise of comprehensive training.},
DOI = {10.3390/f12030292}
}



@Article{rs13050937,
AUTHOR = {Najafi, Payam and Feizizadeh, Bakhtiar and Navid, Hossein},
TITLE = {A Comparative Approach of Fuzzy Object Based Image Analysis and Machine Learning Techniques Which Are Applied to Crop Residue Cover Mapping by Using Sentinel-2 Satellite and UAV Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {937},
URL = {https://www.mdpi.com/2072-4292/13/5/937},
ISSN = {2072-4292},
ABSTRACT = {Conservation tillage methods through leaving the crop residue cover (CRC) on the soil surface protect it from water and wind erosions. Hence, the percentage of the CRC on the soil surface is very critical for the evaluation of tillage intensity. The objective of this study was to develop a new methodology based on the semiautomated fuzzy object based image analysis (fuzzy OBIA) and compare its efficiency with two machine learning algorithms which include: support vector machine (SVM) and artificial neural network (ANN) for the evaluation of the previous CRC and tillage intensity. We also considered the spectral images from two remotely sensed platforms of the unmanned aerial vehicle (UAV) and Sentinel-2 satellite, respectively. The results indicated that fuzzy OBIA for multispectral Sentinel-2 image based on Gaussian membership function with overall accuracy and Cohen’s kappa of 0.920 and 0.874, respectively, surpassed machine learning algorithms and represented the useful results for the classification of tillage intensity. The results also indicated that overall accuracy and Cohen’s kappa for the classification of RGB images from the UAV using fuzzy OBIA method were 0.860 and 0.779, respectively. The semiautomated fuzzy OBIA clearly outperformed machine learning approaches in estimating the CRC and the classification of the tillage methods and also it has the potential to substitute or complement field techniques.},
DOI = {10.3390/rs13050937}
}



@Article{rs13050939,
AUTHOR = {Xue, Yongan and Zhao, Jinling and Zhang, Mingmei},
TITLE = {A Watershed-Segmentation-Based Improved Algorithm for Extracting Cultivated Land Boundaries},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {939},
URL = {https://www.mdpi.com/2072-4292/13/5/939},
ISSN = {2072-4292},
ABSTRACT = {To accurately extract cultivated land boundaries based on high-resolution remote sensing imagery, an improved watershed segmentation algorithm was proposed herein based on a combination of pre- and post-improvement procedures. Image contrast enhancement was used as the pre-improvement, while the color distance of the Commission Internationale de l´Eclairage (CIE) color space, including the Lab and Luv, was used as the regional similarity measure for region merging as the post-improvement. Furthermore, the area relative error criterion (δA), the pixel quantity error criterion (δP), and the consistency criterion (Khat) were used for evaluating the image segmentation accuracy. The region merging in Red–Green–Blue (RGB) color space was selected to compare the proposed algorithm by extracting cultivated land boundaries. The validation experiments were performed using a subset of Chinese Gaofen-2 (GF-2) remote sensing image with a coverage area of 0.12 km2. The results showed the following: (1) The contrast-enhanced image exhibited an obvious gain in terms of improving the image segmentation effect and time efficiency using the improved algorithm. The time efficiency increased by 10.31%, 60.00%, and 40.28%, respectively, in the RGB, Lab, and Luv color spaces. (2) The optimal segmentation and merging scale parameters in the RGB, Lab, and Luv color spaces were C for minimum areas of 2000, 1900, and 2000, and D for a color difference of 1000, 40, and 40. (3) The algorithm improved the time efficiency of cultivated land boundary extraction in the Lab and Luv color spaces by 35.16% and 29.58%, respectively, compared to the RGB color space. The extraction accuracy was compared to the RGB color space using the δA, δP, and Khat, that were improved by 76.92%, 62.01%, and 16.83%, respectively, in the Lab color space, while they were 55.79%, 49.67%, and 13.42% in the Luv color space. (4) Through the visual comparison, time efficiency, and segmentation accuracy, the comprehensive extraction effect using the proposed algorithm was obviously better than that of RGB color-based space algorithm. The established accuracy evaluation indicators were also proven to be consistent with the visual evaluation. (5) The proposed method has a satisfying transferability by a wider test area with a coverage area of 1 km2. In addition, the proposed method, based on the image contrast enhancement, was to perform the region merging in the CIE color space according to the simulated immersion watershed segmentation results. It is a useful attempt for the watershed segmentation algorithm to extract cultivated land boundaries, which provides a reference for enhancing the watershed algorithm.},
DOI = {10.3390/rs13050939}
}



@Article{s21051766,
AUTHOR = {Müezzinoğlu, Taha and Karaköse, Mehmet},
TITLE = {An Intelligent Human–Unmanned Aerial Vehicle Interaction Approach in Real Time Based on Machine Learning Using Wearable Gloves},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {1766},
URL = {https://www.mdpi.com/1424-8220/21/5/1766},
PubMedID = {33806388},
ISSN = {1424-8220},
ABSTRACT = {The interactions between humans and unmanned aerial vehicles (UAVs), whose applications are increasing in the civilian field rather than for military purposes, are a popular future research area. Human–UAV interactions are a challenging problem because UAVs move in a three-dimensional space. In this paper, we present an intelligent human–UAV interaction approach in real time based on machine learning using wearable gloves. The proposed approach offers scientific contributions such as a multi-mode command structure, machine-learning-based recognition, task scheduling algorithms, real-time usage, robust and effective use, and high accuracy rates. For this purpose, two wearable smart gloves working in real time were designed. The signal data obtained from the gloves were processed with machine-learning-based methods and classified multi-mode commands were included in the human–UAV interaction process via the interface according to the task scheduling algorithm to facilitate sequential and fast operation. The performance of the proposed approach was verified on a data set created using 25 different hand gestures from 20 different people. In a test using the proposed approach on 49,000 datapoints, process time performance of a few milliseconds was achieved with approximately 98 percent accuracy.},
DOI = {10.3390/s21051766}
}



@Article{app11052299,
AUTHOR = {Skoczylas, Artur and Stefaniak, Paweł and Anufriiev, Sergii and Jachnik, Bartosz},
TITLE = {Belt Conveyors Rollers Diagnostics Based on Acoustic Signal Collected Using Autonomous Legged Inspection Robot},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {2299},
URL = {https://www.mdpi.com/2076-3417/11/5/2299},
ISSN = {2076-3417},
ABSTRACT = {Growing demand for raw materials forces mining companies to reach deeper deposits. Difficult environmental conditions, especially high temperature and the presence of toxic/explosives gases, as well as high seismic activity in deeply located areas, pose serious threats to humans. In such conditions, running an exploration strategy of machinery parks becomes a difficult challenge, especially from the point of view of technical facilities inspections performed by mining staff. Therefore, there is a growing need for new, reliable, and autonomous inspection solutions for mining infrastructure, which will limit the role of people in these areas. In this article, a method for detection of conveyor rollers failure based on an acoustic signal is described. The data were collected using an ANYmal autonomous legged robot inspecting conveyors operating at the Polish Ore Enrichment Plant of KGHM Polska Miedź S.A., a global producer of copper and silver. As a part of an experiment, about 100 m of operating belt conveyor were inspected. The sound-based fault detection in the plant conditions is not a trivial task, given a considerable level of sonic disturbance produced by a plurality of sources. Additionally, some disturbances partially coincide with the studied phenomenon. Therefore, a suitable filtering method was proposed. Developed diagnostic algorithms, as well as ANYmal robot inspection functionalities and resistance to underground conditions, are developed as a part of the “THING–subTerranean Haptic INvestiGator” project.},
DOI = {10.3390/app11052299}
}



@Article{f12030297,
AUTHOR = {Gray, Ross E. J. and Ewers, Robert M.},
TITLE = {Monitoring Forest Phenology in a Changing World},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {297},
URL = {https://www.mdpi.com/1999-4907/12/3/297},
ISSN = {1999-4907},
ABSTRACT = {Plant phenology is strongly interlinked with ecosystem processes and biodiversity. Like many other aspects of ecosystem functioning, it is affected by habitat and climate change, with both global change drivers altering the timings and frequency of phenological events. As such, there has been an increased focus in recent years to monitor phenology in different biomes. A range of approaches for monitoring phenology have been developed to increase our understanding on its role in ecosystems, ranging from the use of satellites and drones to collection traps, each with their own merits and limitations. Here, we outline the trade-offs between methods (spatial resolution, temporal resolution, cost, data processing), and discuss how their use can be optimised in different environments and for different goals. We also emphasise emerging technologies that will be the focus of monitoring in the years to follow and the challenges of monitoring phenology that still need to be addressed. We conclude that there is a need to integrate studies that incorporate multiple monitoring methods, allowing the strengths of one to compensate for the weaknesses of another, with a view to developing robust methods for upscaling phenological observations from point locations to biome and global scales and reconciling data from varied sources and environments. Such developments are needed if we are to accurately quantify the impacts of a changing world on plant phenology.},
DOI = {10.3390/f12030297}
}



@Article{s21051809,
AUTHOR = {Malhotra, Parushi and Singh, Yashwant and Anand, Pooja and Bangotra, Deep Kumar and Singh, Pradeep Kumar and Hong, Wei-Chiang},
TITLE = {Internet of Things: Evolution, Concerns and Security Challenges},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {1809},
URL = {https://www.mdpi.com/1424-8220/21/5/1809},
PubMedID = {33807724},
ISSN = {1424-8220},
ABSTRACT = {The escalated growth of the Internet of Things (IoT) has started to reform and reshape our lives. The deployment of a large number of objects adhered to the internet has unlocked the vision of the smart world around us, thereby paving a road towards automation and humongous data generation and collection. This automation and continuous explosion of personal and professional information to the digital world provides a potent ground to the adversaries to perform numerous cyber-attacks, thus making security in IoT a sizeable concern. Hence, timely detection and prevention of such threats are pre-requisites to prevent serious consequences. The survey conducted provides a brief insight into the technology with prime attention towards the various attacks and anomalies and their detection based on the intelligent intrusion detection system (IDS). The comprehensive look-over presented in this paper provides an in-depth analysis and assessment of diverse machine learning and deep learning-based network intrusion detection system (NIDS). Additionally, a case study of healthcare in IoT is presented. The study depicts the architecture, security, and privacy issues and application of learning paradigms in this sector. The research assessment is finally concluded by listing the results derived from the literature. Additionally, the paper discusses numerous research challenges to allow further rectifications in the approaches to deal with unusual complications.},
DOI = {10.3390/s21051809}
}



@Article{rs13051009,
AUTHOR = {Niu, Yaxiao and Zhang, Huihui and Han, Wenting and Zhang, Liyuan and Chen, Haipeng},
TITLE = {A Fixed-Threshold Method for Estimating Fractional Vegetation Cover of Maize under Different Levels of Water Stress},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {1009},
URL = {https://www.mdpi.com/2072-4292/13/5/1009},
ISSN = {2072-4292},
ABSTRACT = {Accurate estimation of fractional vegetation cover (FVC) from digital images taken by commercially available cameras is of great significance in order to monitor the vegetation growth status, especially when plants are under water stress. Two classic threshold-based methods, namely, the intersection method (T1 method) and the equal misclassification probability method (T2 method), have been widely applied to Red-Green-Blue (RGB) images. However, the high coverage and severe water stress of crops in the field make it difficult to extract FVC stably and accurately. To solve this problem, this paper proposes a fixed-threshold method based on the statistical analysis of thresholds obtained from the two classic threshold approaches. Firstly, a Gaussian mixture model (GMM), including the distributions of green vegetation and backgrounds, was fitted on four color features: excessive green index, H channel of the Hue-Saturation-Value (HSV) color space, a* channel of the CIE L*a*b* color space, and the brightness-enhanced a* channel (denoted as a*_I). Secondly, thresholds were calculated by applying the T1 and T2 methods to the GMM of each color feature. Thirdly, based on the statistical analysis of the thresholds with better performance between T1 and T2, the fixed-threshold method was proposed. Finally, the fixed-threshold method was applied to the optimal color feature a*_I to estimate FVC, and was compared with the two classic approaches. Results showed that, for some images with high reference FVC, FVC was seriously underestimated by 0.128 and 0.141 when using the T1 and T2 methods, respectively, but this problem was eliminated by the proposed fixed-threshold method. Compared with the T1 and T2 methods, for images taken in plots under severe water stress, the mean absolute error of FVC obtained by the fixed-threshold method was decreased by 0.043 and 0.193, respectively. Overall, the FVC estimation using the proposed fixed-threshold method has the advantages of robustness, accuracy, and high efficiency, with a coefficient of determination (R2) of 0.99 and root mean squared error (RMSE) of 0.02.},
DOI = {10.3390/rs13051009}
}



@Article{drones5010019,
AUTHOR = {Kedia, Arnold Chi and Kapos, Brandi and Liao, Songmei and Draper, Jacob and Eddinger, Justin and Updike, Christopher and Frazier, Amy E.},
TITLE = {An Integrated Spectral–Structural Workflow for Invasive Vegetation Mapping in an Arid Region Using Drones},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {19},
URL = {https://www.mdpi.com/2504-446X/5/1/19},
ISSN = {2504-446X},
ABSTRACT = {Mapping invasive vegetation species in arid regions is a critical task for managing water resources and understanding threats to ecosystem services. Traditional remote sensing platforms, such as Landsat and MODIS, are ill-suited for distinguishing native and non-native vegetation species in arid regions due to their large pixels compared to plant sizes. Unmanned aircraft systems, or UAS, offer the potential to capture the high spatial resolution imagery needed to differentiate species. However, in order to extract the most benefits from these platforms, there is a need to develop more efficient and effective workflows. This paper presents an integrated spectral–structural workflow for classifying invasive vegetation species in the Lower Salt River region of Arizona, which has been the site of fires and flooding, leading to a proliferation of invasive vegetation species. Visible (RGB) and multispectral images were captured and processed following a typical structure from motion workflow, and the derived datasets were used as inputs in two machine learning classifications—one incorporating only spectral information and one utilizing both spectral data and structural layers (e.g., digital terrain model (DTM) and canopy height model (CHM)). Results show that including structural layers in the classification improved overall accuracy from 80% to 93% compared to the spectral-only model. The most important features for classification were the CHM and DTM, with the blue band and two spectral indices (normalized difference water index (NDWI) and normalized difference salinity index (NDSI)) contributing important spectral information to both models.},
DOI = {10.3390/drones5010019}
}



@Article{rs13051036,
AUTHOR = {Belmonte, Adam and Sankey, Temuulen and Biederman, Joel and Bradford, John and Goetz, Scott and Kolb, Thomas},
TITLE = {UAV-Based Estimate of Snow Cover Dynamics: Optimizing Semi-Arid Forest Structure for Snow Persistence},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {1036},
URL = {https://www.mdpi.com/2072-4292/13/5/1036},
ISSN = {2072-4292},
ABSTRACT = {Seasonal snow cover in the dry forests of the American West provides essential water resources to both human and natural systems. The structure of trees and their arrangement across the landscape are important drivers of snow cover distribution across these forests, varying widely in both space and time. We used unmanned aerial vehicle (UAV) multispectral imagery and Structure-from-Motion (SfM) models to quantify rapidly melting snow cover dynamics and examine the effects of forest structure shading on persistent snow cover in a recently thinned ponderosa pine forest. Using repeat UAV multispectral imagery (n = 11 dates) across the 76 ha forest, we first developed a rapid and effective method for identifying persistent snow cover with 90.2% overall accuracy. The SfM model correctly identified 98% (n = 1280) of the trees, when compared with terrestrial laser scanner validation data. Using the SfM-derived forest structure variables, we then found that canopy shading associated with the vertical and horizontal metrics was a significant driver of persistent snow cover patches (R2 = 0.70). The results indicate that UAV image-derived forest structure metrics can be used to accurately predict snow patch size and persistence. Our results provide insight into the importance of forest structure, specifically canopy shading, in the amount and distribution of persistent seasonal snow cover in a typical dry forest environment. An operational understanding of forest structure effects on snow cover will help drive forest management that can target snow cover dynamics in addition to forest health.},
DOI = {10.3390/rs13051036}
}



@Article{rs13061046,
AUTHOR = {Kaplan, Gregoriy and Fine, Lior and Lukyanov, Victor and Manivasagam, V. S. and Malachy, Nitzan and Tanny, Josef and Rozenstein, Offer},
TITLE = {Estimating Processing Tomato Water Consumption, Leaf Area Index, and Height Using Sentinel-2 and VENµS Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1046},
URL = {https://www.mdpi.com/2072-4292/13/6/1046},
ISSN = {2072-4292},
ABSTRACT = {Crop monitoring throughout the growing season is key for optimized agricultural production. Satellite remote sensing is a useful tool for estimating crop variables, yet continuous high spatial resolution earth observations are often interrupted by clouds. This paper demonstrates overcoming this limitation by combining observations from two public-domain spaceborne optical sensors. Ground measurements were conducted in the Hula Valley, Israel, over four growing seasons to monitor the development of processing tomato. These measurements included continuous water consumption measurements using an eddy-covariance tower from which the crop coefficient (Kc) was calculated and measurements of Leaf Area Index (LAI) and crop height. Satellite imagery acquired by Sentinel-2 and VENµS was used to derive vegetation indices and model Kc, LAI, and crop height. The conjoint use of Sentinel-2 and VENµS imagery facilitated accurate estimation of Kc (R2 = 0.82, RMSE = 0.09), LAI (R2 = 0.79, RMSE = 1.2), and crop height (R2 = 0.81, RMSE = 7 cm). Additionally, our empirical models for LAI estimation were found to perform better than the SNAP biophysical processor (R2 = 0.53, RMSE = 2.3). Accordingly, Sentinel-2 and VENµS imagery was demonstrated to be a viable tool for agricultural monitoring.},
DOI = {10.3390/rs13061046}
}



@Article{app11062458,
AUTHOR = {Roberts, Ronald and Inzerillo, Laura and Di Mino, Gaetano},
TITLE = {Exploiting Data Analytics and Deep Learning Systems to Support Pavement Maintenance Decisions},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2458},
URL = {https://www.mdpi.com/2076-3417/11/6/2458},
ISSN = {2076-3417},
ABSTRACT = {Road networks are critical infrastructures within any region and it is imperative to maintain their conditions for safe and effective movement of goods and services. Road Management, therefore, plays a key role to ensure consistent efficient operation. However, significant resources are required to perform necessary maintenance activities to achieve and maintain high levels of service. Pavement maintenance can typically be very expensive and decisions are needed concerning planning and prioritizing interventions. Data are key towards enabling adequate maintenance planning but in many instances, there is limited available information especially in small or under-resourced urban road authorities. This study develops a roadmap to help these authorities by using flexible data analysis and deep learning computational systems to highlight important factors within road networks, which are used to construct models that can help predict future intervention timelines. A case study in Palermo, Italy was successfully developed to demonstrate how the techniques could be applied to perform appropriate feature selection and prediction models based on limited data sources. The workflow provides a pathway towards more effective pavement maintenance management practices using techniques that can be readily adapted based on different environments. This takes another step towards automating these practices within the pavement management system.},
DOI = {10.3390/app11062458}
}



@Article{w13060756,
AUTHOR = {Kang, Dong-Ho and Nam, Dong-Ho and Jeung, Se-Jin and Kim, Byung-Sik},
TITLE = {Impact Assessment of Flood Damage in Urban Areas Using RCP 8.5 Climate Change Scenarios and Building Inventory},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {756},
URL = {https://www.mdpi.com/2073-4441/13/6/756},
ISSN = {2073-4441},
ABSTRACT = {Korea has frequent flood damage due to localized torrential rain and typhoons as a result of climate change, which causes many casualties and property damage. In particular, much damage occurs due to urban inundation caused by stream flooding as a result of climate change. Thus, this study aims to analyze the effect of climate change on flood damage targeting the Wonjucheon basin, which is an urban stream flowing the city. For future rainfall data, RCP (Representative Concentration Pathways) 8.5 climate change scenario data was used, statistical detailed using SDQDM (Spatial Disaggregation with Quantile Delta Mapping) techniques, and daily data was downscaled using Copula model. In general, the flood damage rate is calculated by using the area ratio according to the land use in the administrative district, but in this study, the flood damage rate is calculated using the flood damage rate proposed in the multi-dimensional flood damage analysis using Building Inventory. Using the created future rainfall data and current data, the runoff in the Wonjucheon basin, Wonju-si, South Korea, by rainfall frequency was calculated through the Spatial Runoff Assessment Tool (S-RAT) model, which was a distributed rainfall-runoff model. The runoff was calculated using 100-year and 200-year frequency rainfalls for a four-hour duration and the flood damage area was calculated by applying the calculated runoff to the Flo-2D model, was developed by Federal Emergency Management Agency (FEMA) in United State of America, which was a flood inundation model. As a result of calculating the amount of discharge, it was analyzed that the average amount of discharge increased by 16% over the 100-year, 200-year frequency. The calculated result of the flood damage area was analyzed and the analysis results showed that the future flood damage area increased by around 30% at the 100-year frequency and around 15% at the 200-year frequency. The estimated flood damage by rainfall frequency was calculated using the flood damage area by frequency and multi-dimensional analysis, and the analysis result exhibited that the damage increased by around 23% at the 100-year frequency and around 45% at the 200-year frequency.},
DOI = {10.3390/w13060756}
}



@Article{s21061947,
AUTHOR = {Nemer, Ibrahim and Sheltami, Tarek and Ahmad, Irfan and Yasar, Ansar Ul-Haque and Abdeen, Mohammad A. R.},
TITLE = {RF-Based UAV Detection and Identification Using Hierarchical Learning Approach},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1947},
URL = {https://www.mdpi.com/1424-8220/21/6/1947},
PubMedID = {33802189},
ISSN = {1424-8220},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) are widely available in the current market to be used either for recreation as a hobby or to serve specific industrial requirements, such as agriculture and construction. However, illegitimate and criminal usage of UAVs is also on the rise which introduces their effective identification and detection as a research challenge. This paper proposes a novel machine learning-based for efficient identification and detection of UAVs. Specifically, an improved UAV identification and detection approach is presented using an ensemble learning based on the hierarchical concept, along with pre-processing and feature extraction stages for the Radio Frequency (RF) data. Filtering is applied on the RF signals in the detection approach to improve the output. This approach consists of four classifiers and they are working in a hierarchical way. The sample will pass the first classifier to check the availability of the UAV, and then it will specify the type of the detected UAV using the second classifier. The last two classifiers will handle the sample that is related to Bebop and AR to specify their mode. Evaluation of the proposed approach with publicly available dataset demonstrates better efficiency compared to existing detection systems in the literature. It has the ability to investigate whether a UAV is flying within the area or not, and it can directly identify the type of UAV and then the flight mode of the detected UAV with accuracy around 99%.},
DOI = {10.3390/s21061947}
}



@Article{s21061960,
AUTHOR = {Fotouhi, Azade and Ding, Ming and Hassan, Mahbub},
TITLE = {Deep Q-Learning for Two-Hop Communications of Drone Base Stations},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1960},
URL = {https://www.mdpi.com/1424-8220/21/6/1960},
PubMedID = {33799546},
ISSN = {1424-8220},
ABSTRACT = {In this paper, we address the application of the flying Drone Base Stations (DBS) in order to improve the network performance. Given the high degrees of freedom of a DBS, it can change its position and adapt its trajectory according to the users movements and the target environment. A two-hop communication model, between an end-user and a macrocell through a DBS, is studied in this work. We propose Q-learning and Deep Q-learning based solutions to optimize the drone’s trajectory. Simulation results show that, by employing our proposed models, the drone can autonomously fly and adapts its mobility according to the users’ movements. Additionally, the Deep Q-learning model outperforms the Q-learning model and can be applied in more complex environments.},
DOI = {10.3390/s21061960}
}



@Article{f12030327,
AUTHOR = {Dainelli, Riccardo and Toscano, Piero and Di Gennaro, Salvatore Filippo and Matese, Alessandro},
TITLE = {Recent Advances in Unmanned Aerial Vehicle Forest Remote Sensing—A Systematic Review. Part I: A General Framework},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {327},
URL = {https://www.mdpi.com/1999-4907/12/3/327},
ISSN = {1999-4907},
ABSTRACT = {Natural, semi-natural, and planted forests are a key asset worldwide, providing a broad range of positive externalities. For sustainable forest planning and management, remote sensing (RS) platforms are rapidly going mainstream. In a framework where scientific production is growing exponentially, a systematic analysis of unmanned aerial vehicle (UAV)-based forestry research papers is of paramount importance to understand trends, overlaps and gaps. The present review is organized into two parts (Part I and Part II). Part II inspects specific technical issues regarding the application of UAV-RS in forestry, together with the pros and cons of different UAV solutions and activities where additional effort is needed, such as the technology transfer. Part I systematically analyzes and discusses general aspects of applying UAV in natural, semi-natural and artificial forestry ecosystems in the recent peer-reviewed literature (2018–mid-2020). The specific goals are threefold: (i) create a carefully selected bibliographic dataset that other researchers can draw on for their scientific works; (ii) analyze general and recent trends in RS forest monitoring (iii) reveal gaps in the general research framework where an additional activity is needed. Through double-step filtering of research items found in the Web of Science search engine, the study gathers and analyzes a comprehensive dataset (226 articles). Papers have been categorized into six main topics, and the relevant information has been subsequently extracted. The strong points emerging from this study concern the wide range of topics in the forestry sector and in particular the retrieval of tree inventory parameters often through Digital Aerial Photogrammetry (DAP), RGB sensors, and machine learning techniques. Nevertheless, challenges still exist regarding the promotion of UAV-RS in specific parts of the world, mostly in the tropical and equatorial forests. Much additional research is required for the full exploitation of hyperspectral sensors and for planning long-term monitoring.},
DOI = {10.3390/f12030327}
}



@Article{agronomy11030532,
AUTHOR = {Hashim, Izrahayu Che and Shariff, Abdul Rashid Mohamed and Bejo, Siti Khairunniza and Muharam, Farrah Melissa and Ahmad, Khairulmazmi},
TITLE = {Machine-Learning Approach Using SAR Data for the Classification of Oil Palm Trees That Are Non-Infected and Infected with the Basal Stem Rot Disease},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {532},
URL = {https://www.mdpi.com/2073-4395/11/3/532},
ISSN = {2073-4395},
ABSTRACT = {Basal stem rot disease (BSR) in oil palm plants is caused by the Ganoderma boninense (G. boninense) fungus. BSR is a major disease that affects oil palm plantations in Malaysia and Indonesia. As of now, the only available sustaining measure is to prolong the life of oil palm trees since there has been no effective treatment for the BSR disease. This project used an ALOS PALSAR-2 image with dual polarization, Horizontal transmit and Horizontal receive (HH) and Horizontal transmit and Vertical receive (HV). The aims of this study were to (1) identify the potential backscatter variables; and (2) examine the performance of machine learning (ML) classifiers (Multilayer Perceptron (MLP) and Random Forest (RF) to classify oil palm trees that are non-infected and infected by G. boninense. The sample size consisted of 55 uninfected trees and 37 infected trees. We used the imbalance data approach (Synthetic Minority Over-Sampling Technique (SMOTE) in these classifications due to the differing sample sizes. The result showed backscatter variable HV had a higher correct classification for the G. boninense non-infected and infected oil palm trees for both classifiers; the MLP classifier model had a robust success rate, which correctly classified 100% for non-infected and 91.30% for infected G. boninense, and RF had a robust success rate, which correctly classified 94.11% for non-infected and 91.30% for infected G. boninense. In terms of model performance using the most significant variables, HV, the MLP model had a balanced accuracy (BCR) of 95.65% compared to 92.70% for the RF model. Comparison between the MLP model and RF model for the receiver operating characteristics (ROC) curve region, (AUC) gave a value of 0.92 and 0.95, respectively, for the MLP and RF models. Therefore, it can be concluded by using only the HV polarization, that both the MLP and RF can be used to predict BSR disease with a relatively high accuracy.},
DOI = {10.3390/agronomy11030532}
}



@Article{s21061994,
AUTHOR = {Ma, Qian and Han, Wenting and Huang, Shenjin and Dong, Shide and Li, Guang and Chen, Haipeng},
TITLE = {Distinguishing Planting Structures of Different Complexity from UAV Multispectral Images},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1994},
URL = {https://www.mdpi.com/1424-8220/21/6/1994},
PubMedID = {33808967},
ISSN = {1424-8220},
ABSTRACT = {This study explores the classification potential of a multispectral classification model for farmland with planting structures of different complexity. Unmanned aerial vehicle (UAV) remote sensing technology is used to obtain multispectral images of three study areas with low-, medium-, and high-complexity planting structures, containing three, five, and eight types of crops, respectively. The feature subsets of three study areas are selected by recursive feature elimination (RFE). Object-oriented random forest (OB-RF) and object-oriented support vector machine (OB-SVM) classification models are established for the three study areas. After training the models with the feature subsets, the classification results are evaluated using a confusion matrix. The OB-RF and OB-SVM models’ classification accuracies are 97.09% and 99.13%, respectively, for the low-complexity planting structure. The equivalent values are 92.61% and 99.08% for the medium-complexity planting structure and 88.99% and 97.21% for the high-complexity planting structure. For farmland with fragmentary plots and a high-complexity planting structure, as the planting structure complexity changed from low to high, both models’ overall accuracy levels decreased. The overall accuracy of the OB-RF model decreased by 8.1%, and that of the OB-SVM model only decreased by 1.92%. OB-SVM achieves an overall classification accuracy of 97.21%, and a single-crop extraction accuracy of at least 85.65%. Therefore, UAV multispectral remote sensing can be used for classification applications in highly complex planting structures.},
DOI = {10.3390/s21061994}
}



@Article{chemosensors9030055,
AUTHOR = {Elsayed, Salah and El-Hendawy, Salah and Khadr, Mosaad and Elsherbiny, Osama and Al-Suhaibani, Nasser and Dewir, Yaser Hassan and Tahir, Muhammad Usman and Mubushar, Muhammad and Darwish, Waleed},
TITLE = {Integration of Spectral Reflectance Indices and Adaptive Neuro-Fuzzy Inference System for Assessing the Growth Performance and Yield of Potato under Different Drip Irrigation Regimes},
JOURNAL = {Chemosensors},
VOLUME = {9},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {55},
URL = {https://www.mdpi.com/2227-9040/9/3/55},
ISSN = {2227-9040},
ABSTRACT = {Simultaneous and timely assessment of growth and water status-related plant traits is critical for precision irrigation management in arid regions. Here, we used proximal hyperspectral sensing tools to estimate biomass fresh weight (BFW), biomass dry weight (BDW), canopy water content (CWC), and total tuber yield (TTY) of two potato varieties irrigated with 100%, 75%, and 50% of the estimated crop evapotranspiration (ETc). Plant traits were assessed remotely using published and newly constructed vegetation and water spectral reflectance indices (SRIs). We integrated genetic algorithm (GA) and adaptive neuro-fuzzy inference system (ANFIS) models to predict the measured traits based on all SRIs. The different plant traits and SRIs varied significantly (p &lt; 0.05) between the three irrigation regimes for the two varieties. The values of plant traits and majority SRIs showed a continuous decrease from the 100% ETc to the 50% ETc. Water-SRIs performed better than vegetation-SRIs for estimating the four plant traits. Almost all indices of the two SRI types had a weak relationship with the four plant traits (R2 = 0.00–0.37) under each irrigation regime. However, the majority of vegetation-SRIs and all water-SRIs showed strong relationships with BFW, CWC, and TTY (R2 ≥ 0.65) and moderate relationships with BDW (R2 ≥ 0.40) when the data of all irrigation regimes and varieties were analyzed together for each growing season or the data of all irrigation regimes, varieties, and seasons were combined together. The ANFIS-GA model predicted plant traits with satisfactory accuracy in both calibration (R2 = 1.0) and testing (R2 = 0.72–0.97) modes. The results indicate that SRI-based ANFIS models can improve plant trait estimation. This analysis also confirmed the benefits of applying GA to ANFIS to estimate plant responses to different growth conditions.},
DOI = {10.3390/chemosensors9030055}
}



@Article{rs13061084,
AUTHOR = {Beselly, Sebrian Mirdeklis and van der Wegen, Mick and Grueters, Uwe and Reyns, Johan and Dijkstra, Jasper and Roelvink, Dano},
TITLE = {Eleven Years of Mangrove–Mudflat Dynamics on the Mud Volcano-Induced Prograding Delta in East Java, Indonesia: Integrating UAV and Satellite Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1084},
URL = {https://www.mdpi.com/2072-4292/13/6/1084},
ISSN = {2072-4292},
ABSTRACT = {This article presents a novel approach to explore mangrove dynamics on a prograding delta by integrating unmanned aerial vehicle (UAV) and satellite imagery. The Porong Delta in Indonesia has a unique geographical setting with rapid delta development and expansion of the mangrove belt. This is due to an unprecedented mud load from the LUSI mud volcanic eruption. The mangrove dynamics analysis combines UAV-based Structure from Motion (SfM) photogrammetry and 11 years (2009–2019) satellite imagery cloud computing analysis by Google Earth Engine (GEE). Our analysis shows unique, high-spatiotemporal-resolution mangrove extent maps. The SfM photogrammetry analysis leads to a 3D representation of the mangrove canopy and an estimate of mangrove biophysical properties with accurate height and individual position of the mangroves stand. GEE derived vegetation indices resulted in high (three-monthly) resolution mangrove coverage dynamics over 11 years (2009–2019), yielding a value of more than 98% for the overall, producer and consumer accuracy. Combining the satellite-derived age maps and the UAV-derived spatial tree structure allowed us to monitor the mangrove dynamics on a rapidly prograding delta along with its structural attributes. This analysis is of essential value to ecologists, coastal managers, and policymakers.},
DOI = {10.3390/rs13061084}
}



@Article{rs13061094,
AUTHOR = {Peng, Xingshuo and Han, Wenting and Ao, Jianyi and Wang, Yi},
TITLE = {Assimilation of LAI Derived from UAV Multispectral Data into the SAFY Model to Estimate Maize Yield},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1094},
URL = {https://www.mdpi.com/2072-4292/13/6/1094},
ISSN = {2072-4292},
ABSTRACT = {In this study, we develop a method to estimate corn yield based on remote sensing data and ground monitoring data under different water treatments. Spatially explicit information on crop yields is essential for farmers and agricultural agencies to make well-informed decisions. One approach to estimate crop yield with remote sensing is data assimilation, which integrates sequential observations of canopy development from remote sensing into model simulations of crop growth processes. We found that leaf area index (LAI) inversion based on unmanned aerial vehicle (UAV) vegetation index has a high accuracy, with R2 and root mean square error (RMSE) values of 0.877 and 0.609, respectively. Maize yield estimation based on UAV remote sensing data and simple algorithm for yield (SAFY) crop model data assimilation has different yield estimation accuracy under different water treatments. This method can be used to estimate corn yield, where R2 is 0.855 and RMSE is 692.8kg/ha. Generally, the higher the water stress, the lower the estimation accuracy. Furthermore, we perform the yield estimate mapping at 2 m spatial resolution, which has a higher spatial resolution and accuracy than satellite remote sensing. The great potential of incorporating UAV observations with crop data to monitor crop yield, and improve agricultural management is therefore indicated.},
DOI = {10.3390/rs13061094}
}



@Article{infrastructures6030043,
AUTHOR = {Gkoumas, Konstantinos and Gkoktsi, Kyriaki and Bono, Flavio and Galassi, Maria Cristina and Tirelli, Daniel},
TITLE = {The Way Forward for Indirect Structural Health Monitoring (iSHM) Using Connected and Automated Vehicles in Europe},
JOURNAL = {Infrastructures},
VOLUME = {6},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {43},
URL = {https://www.mdpi.com/2412-3811/6/3/43},
ISSN = {2412-3811},
ABSTRACT = {Europe’s aging transportation infrastructure requires optimized maintenance programs. However, data and monitoring systems may not be readily available to support strategic decisions or they may require costly installations in terms of time and labor requirements. In recent years, the possibility of monitoring bridges by indirectly sensing relevant parameters from traveling vehicles has emerged—an approach that would allow for the elimination of the costly installation of sensors and monitoring campaigns. The advantages of cooperative, connected, and automated mobility (CCAM), which is expected to become a reality in Europe towards the end of this decade, should therefore be considered for the future development of iSHM strategies. A critical review of methods and strategies for CCAM, including Intelligent Transportation Systems, is a prerequisite for moving towards the goal of identifying the synergies between CCAM and civil infrastructures, in line with future developments in vehicle automation. This study presents the policy framework of CCAM in Europe and discusses the policy enablers and bottlenecks of using CCAM in the drive-by monitoring of transport infrastructure. It also highlights the current direction of research within the iSHM paradigm towards the identification of technologies and methods that could benefit from the use of connected and automated vehicles (CAVs).},
DOI = {10.3390/infrastructures6030043}
}



@Article{s21062062,
AUTHOR = {Dias, Pollyanna G. Faria and Silva, Mateus C. and Rocha Filho, Geraldo P. and Vargas, Patrícia A. and Cota, Luciano P. and Pessin, Gustavo},
TITLE = {Swarm Robotics: A Perspective on the Latest Reviewed Concepts and Applications},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2062},
URL = {https://www.mdpi.com/1424-8220/21/6/2062},
PubMedID = {33804187},
ISSN = {1424-8220},
ABSTRACT = {Known as an artificial intelligence subarea, Swarm Robotics is a developing study field investigating bio-inspired collaborative control approaches and integrates a huge collection of agents, reasonably plain robots, in a distributed and decentralized manner. It offers an inspiring essential platform for new researchers to be engaged and share new knowledge to examine their concepts in analytical and heuristic strategies. This paper introduces an overview of current activities in Swarm Robotics and examines the present literature in this area to establish to approach between a realistic swarm robotic system and real-world enforcements. First, we review several Swarm Intelligence concepts to define Swarm Robotics systems, reporting their essential qualities and features and contrast them to generic multi-robotic systems. Second, we report a review of the principal projects that allow realistic study of Swarm Robotics. We demonstrate knowledge regarding current hardware platforms and multi-robot simulators. Finally, the forthcoming promissory applications and the troubles to surpass with a view to achieving them have been described and analyzed.},
DOI = {10.3390/s21062062}
}



@Article{asi4010023,
AUTHOR = {Naseem, Usman and Khushi, Matloob and Khan, Shah Khalid and Shaukat, Kamran and Moni, Mohammad Ali},
TITLE = {A Comparative Analysis of Active Learning for Biomedical Text Mining},
JOURNAL = {Applied System Innovation},
VOLUME = {4},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {23},
URL = {https://www.mdpi.com/2571-5577/4/1/23},
ISSN = {2571-5577},
ABSTRACT = {An enormous amount of clinical free-text information, such as pathology reports, progress reports, clinical notes and discharge summaries have been collected at hospitals and medical care clinics. These data provide an opportunity of developing many useful machine learning applications if the data could be transferred into a learn-able structure with appropriate labels for supervised learning. The annotation of this data has to be performed by qualified clinical experts, hence, limiting the use of this data due to the high cost of annotation. An underutilised technique of machine learning that can label new data called active learning (AL) is a promising candidate to address the high cost of the label the data. AL has been successfully applied to labelling speech recognition and text classification, however, there is a lack of literature investigating its use for clinical purposes. We performed a comparative investigation of various AL techniques using ML and deep learning (DL)-based strategies on three unique biomedical datasets. We investigated random sampling (RS), least confidence (LC), informative diversity and density (IDD), margin and maximum representativeness-diversity (MRD) AL query strategies. Our experiments show that AL has the potential to significantly reducing the cost of manual labelling. Furthermore, pre-labelling performed using AL expediates the labelling process by reducing the time required for labelling.},
DOI = {10.3390/asi4010023}
}



@Article{ani11030829,
AUTHOR = {Herlin, Anders and Brunberg, Emma and Hultgren, Jan and Högberg, Niclas and Rydberg, Anna and Skarin, Anna},
TITLE = {Animal Welfare Implications of Digital Tools for Monitoring and Management of Cattle and Sheep on Pasture},
JOURNAL = {Animals},
VOLUME = {11},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {829},
URL = {https://www.mdpi.com/2076-2615/11/3/829},
PubMedID = {33804235},
ISSN = {2076-2615},
ABSTRACT = {The opportunities for natural animal behaviours in pastures imply animal welfare benefits. Nevertheless, monitoring the animals can be challenging. The use of sensors, cameras, positioning equipment and unmanned aerial vehicles in large pastures has the potential to improve animal welfare surveillance. Directly or indirectly, sensors measure environmental factors together with the behaviour and physiological state of the animal, and deviations can trigger alarms for, e.g., disease, heat stress and imminent calving. Electronic positioning includes Radio Frequency Identification (RFID) for the recording of animals at fixed points. Positioning units (GPS) mounted on collars can determine animal movements over large areas, determine their habitat and, somewhat, health and welfare. In combination with other sensors, such units can give information that helps to evaluate the welfare of free-ranging animals. Drones equipped with cameras can also locate and count the animals, as well as herd them. Digitally defined virtual fences can keep animals within a predefined area without the use of physical barriers, relying on acoustic signals and weak electric shocks. Due to individual variations in learning ability, some individuals may be exposed to numerous electric shocks, which might compromise their welfare. More research and development are required, especially regarding the use of drones and virtual fences.},
DOI = {10.3390/ani11030829}
}



@Article{electronics10060697,
AUTHOR = {Ijemaru, Gerald K. and Ang, Kenneth L.-M. and Seng, Jasmine K. P.},
TITLE = {Mobile Collectors for Opportunistic Internet of Things in Smart City Environment with Wireless Power Transfer},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {697},
URL = {https://www.mdpi.com/2079-9292/10/6/697},
ISSN = {2079-9292},
ABSTRACT = {In the context of Internet of Things (IoT) for Smart City (SC) applications, Mobile Data Collectors (MDCs) can be opportunistically exploited as wireless energy transmitters to recharge the energy-constrained IoT sensor-nodes placed within their charging vicinity or coverage area. The use of MDCs has been well studied and presents several advantages compared to the traditional methods that employ static sinks. However, data collection and transmission from the hundreds of thousands of sensors sparsely distributed across virtually every smart city has raised some new challenges. One of these concerns lies in how these sensors are being powered as majority of the IoT sensors are extremely energy-constrained owing to their smallness and mode of deployments. It is also evident that sensor-nodes closer to the sinks dissipate their energy faster than their counterparts. Moreover, battery recharging or replacement is impractical and incurs very large operational costs. Recent breakthrough in wireless power transfer (WPT) technologies allows the transfer of energy to the energy-hungry IoT sensor-nodes wirelessly. WPT finds applications in medical implants, electric vehicles, wireless sensor networks (WSNs), unmanned aerial vehicles (UAVs), mobile phones, and so on. The present study highlights the use of mobile collectors (data mules) as wireless power transmitters for opportunistic IoT-SC operations. Specifically, mobile vehicles used for data collection are further exploited as wireless power transmitters (wireless battery chargers) to wirelessly recharge the energy-constrained IoT nodes placed within their coverage vicinity. This paper first gives a comprehensive survey of the different aspects of wireless energy transmission technologies—architecture, energy sources, IoT energy harvesting modes, WPT techniques and applications that can be exploited for SC scenarios. A comparative analysis of the WPT technologies is also highlighted to determine the most energy-efficient technique for IoT scenarios. We then propose a WPT scheme that exploits vehicular networks for opportunistic IoT-SC operations. Experiments are conducted using simulations to evaluate the performance of the proposed model and to investigate WPT efficiency of a power-hungry opportunistic IoT network for different trade-off factors.},
DOI = {10.3390/electronics10060697}
}



@Article{aerospace8030079,
AUTHOR = {Swinney, Carolyn J. and Woods, John C.},
TITLE = {Unmanned Aerial Vehicle Operating Mode Classification Using Deep Residual Learning Feature Extraction},
JOURNAL = {Aerospace},
VOLUME = {8},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {79},
URL = {https://www.mdpi.com/2226-4310/8/3/79},
ISSN = {2226-4310},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) undoubtedly pose many security challenges. We need only look to the December 2018 Gatwick Airport incident for an example of the disruption UAVs can cause. In total, 1000 flights were grounded for 36 h over the Christmas period which was estimated to cost over 50 million pounds. In this paper, we introduce a novel approach which considers UAV detection as an imagery classification problem. We consider signal representations Power Spectral Density (PSD); Spectrogram, Histogram and raw IQ constellation as graphical images presented to a deep Convolution Neural Network (CNN) ResNet50 for feature extraction. Pre-trained on ImageNet, transfer learning is utilised to mitigate the requirement for a large signal dataset. We evaluate performance through machine learning classifier Logistic Regression. Three popular UAVs are classified in different modes; switched on; hovering; flying; flying with video; and no UAV present, creating a total of 10 classes. Our results, validated with 5-fold cross validation and an independent dataset, show PSD representation to produce over 91% accuracy for 10 classifications. Our paper treats UAV detection as an imagery classification problem by presenting signal representations as images to a ResNet50, utilising the benefits of transfer learning and outperforming previous work in the field.},
DOI = {10.3390/aerospace8030079}
}



@Article{rs13061128,
AUTHOR = {Tahmasbian, Iman and Morgan, Natalie K. and Hosseini Bai, Shahla and Dunlop, Mark W. and Moss, Amy F.},
TITLE = {Comparison of Hyperspectral Imaging and Near-Infrared Spectroscopy to Determine Nitrogen and Carbon Concentrations in Wheat},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1128},
URL = {https://www.mdpi.com/2072-4292/13/6/1128},
ISSN = {2072-4292},
ABSTRACT = {Hyperspectral imaging (HSI) is an emerging rapid and non-destructive technology that has promising application within feed mills and processing plants in poultry and other intensive animal industries. HSI may be advantageous over near infrared spectroscopy (NIRS) as it scans entire samples, which enables compositional gradients and sample heterogenicity to be visualised and analysed. This study was a preliminary investigation to compare the performance of HSI with that of NIRS for quality measurements of ground samples of Australian wheat and to identify the most important spectral regions for predicting carbon (C) and nitrogen (N) concentrations. In total, 69 samples were scanned using an NIRS (400–2500 nm), and two HSI cameras operated in 400–1000 nm (VNIR) and 1000–2500 nm (SWIR) spectral regions. Partial least square regression (PLSR) models were used to correlate C and N concentrations of 63 calibration samples with their spectral reflectance, with 6 additional samples used for testing the models. The accuracy of the HSI predictions (full spectra) were similar or slightly higher than those of NIRS (NIRS Rc2 for C = 0.90 and N = 0.96 vs. HSI Rc2 for C (VNIR) = 0.97 and N (SWIR) = 0.97). The most important spectral region for C prediction identified using HSI reflectance was 400–550 nm with R2 of 0.93 and RMSE of 0.17% in the calibration set and R2 of 0.86, RMSE of 0.21% and ratio of performance to deviation (RPD) of 2.03 in the test set. The most important spectral regions for predicting N concentrations in the feed samples included 1451–1600 nm, 1901–2050 nm and 2051–2200 nm, providing prediction with R2 ranging from 0.91 to 0.93, RMSE ranging from 0.06% to 0.07% in the calibration sets, R2 from 0.96 to 0.99, RMSE of 0.06% and RPD from 3.47 to 3.92 in the test sets. The prediction accuracy of HSI and NIRS were comparable possibly due to the larger statistical population (larger number of pixels) that HSI provided, despite the fact that HSI had smaller spectral range compared with that of NIRS. In addition, HSI enabled visualising the variability of C and N in the samples. Therefore, HSI is advantageous compared to NIRS as it is a multifunctional tool that poses many potential applications in data collection and quality assurance within feed mills and poultry processing plants. The ability to more accurately measure and visualise the properties of feed ingredients has potential economic benefits and therefore additional investigation and development of HSI in this application is warranted.},
DOI = {10.3390/rs13061128}
}



@Article{agriengineering3010008,
AUTHOR = {Hardy, Tom and Kooistra, Lammert and Domingues Franceschini, Marston and Richter, Sebastiaan and Vonk, Erwin and van den Eertwegh, Gé and van Deijl, Dion},
TITLE = {Sen2Grass: A Cloud-Based Solution to Generate Field-Specific Grassland Information Derived from Sentinel-2 Imagery},
JOURNAL = {AgriEngineering},
VOLUME = {3},
YEAR = {2021},
NUMBER = {1},
PAGES = {118--137},
URL = {https://www.mdpi.com/2624-7402/3/1/8},
ISSN = {2624-7402},
ABSTRACT = {Grasslands are important for their ecological values and for agricultural activities such as livestock production worldwide. Efficient grassland management is vital to these values and activities, and remote sensing technologies are increasingly being used to characterize the spatiotemporal variation of grasslands to support those management practices. For this study, Sentinel-2 satellite imagery was used as an input to develop an open-source and automated monitoring system (Sen2Grass) to gain field-specific grassland information on the national and regional level for any given time range as of January 2016. This system was implemented in a cloud-computing platform (StellaSpark Nexus) designed to process large geospatial data streams from a variety of sources and was tested for a number of parcels from the Haus Riswick experimental farm in Germany. Despite outliers due to fluctuating weather conditions, vegetation index time series suggested four distinct growing cycles per growing season. Established relationships between vegetation indices and grassland yield showed poor to moderate positive trends, implying that vegetation indices could be a potential predictor for grassland biomass and chlorophyll content. However, the inclusion of larger and additional datasets such as Sentinel-1 imagery could be beneficial to developing more robust prediction models and for automatic detection of mowing events for grasslands.},
DOI = {10.3390/agriengineering3010008}
}



@Article{educsci11030126,
AUTHOR = {Danaher, Michael and Wu, Jiaping and Hewson, Michael},
TITLE = {Sustainability: A Regional Australian Experience of Educating Secondary Geography Teachers},
JOURNAL = {Education Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {126},
URL = {https://www.mdpi.com/2227-7102/11/3/126},
ISSN = {2227-7102},
ABSTRACT = {The United Nations Sustainable Development Goal (SDG) number four seeks an equitable and widespread education that enables an outcome of sustainable development by 2030. Intersecting the studies of society and earth processes, a geographical education is well placed to make cohesive sense of all the individual knowledge silos that contribute to achieving sustainability. Geography education is compulsory for the first three years of the secondary education curriculum in Australia; however, research has shown that many geography teachers are underprepared and report limitations in their teaching of sustainability. This article engages with this research problem to provide a critical reflection, using experiential knowledge as an analytical lens, on how tertiary level geography training at one Australian regional university can equip undergraduate teacher education students with the values, knowledge, and skills needed to develop their future students’ understanding and appreciation of the principles of sustainability. The authors unpacked a geography minor for a Bachelor of Secondary Education degree at Central Queensland University and, deploying content analysis, explain how three units in that minor can develop these students’ values, knowledge, and skills through fostering initiatives and activities. The analysis was framed by elements of pedagogy that offer learners a context for developing active, global citizenship and participation to understand the interdependencies of ecological, societal, and economic systems including a multisided view of sustainability and sustainable development. The study concluded that the three geography units engage student teachers in sustainable thinking in a variety of ways, which can have a wider application in the geography curricula in other teacher education courses. More importantly, however, the study found that there is a critical need for collaboration between university teachers of sustainability content and university teachers of school-based pedagogy in order to maximise the efficacy of sustainability education in schools.},
DOI = {10.3390/educsci11030126}
}



@Article{rs13061134,
AUTHOR = {El-Alem, Anas and Chokmani, Karem and Venkatesan, Aarthi and Rachid, Lhissou and Agili, Hachem and Dedieu, Jean-Pierre},
TITLE = {How Accurate Is an Unmanned Aerial Vehicle Data-Based Model Applied on Satellite Imagery for Chlorophyll-a Estimation in Freshwater Bodies?},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1134},
URL = {https://www.mdpi.com/2072-4292/13/6/1134},
ISSN = {2072-4292},
ABSTRACT = {Optical sensors are increasingly sought to estimate the amount of chlorophyll a (chl_a) in freshwater bodies. Most, whether empirical or semi-empirical, are data-oriented. Two main limitations are often encountered in the development of such models. The availability of data needed for model calibration, validation, and testing and the locality of the model developed—the majority need a re-parameterization from lake to lake. An Unmanned aerial vehicle (UAV) data-based model for chl_a estimation is developed in this work and tested on Sentinel-2 imagery without any re-parametrization. The Ensemble-based system (EBS) algorithm was used to train the model. The leave-one-out cross validation technique was applied to evaluate the EBS, at a local scale, where results were satisfactory (R2 = Nash = 0.94 and RMSE = 5.6 µg chl_a L−1). A blind database (collected over 89 lakes) was used to challenge the EBS’ Sentine-2-derived chl_a estimates at a regional scale. Results were relatively less good, yet satisfactory (R2 = 0.85, RMSE= 2.4 µg chl_a L−1, and Nash = 0.79). However, the EBS has shown some failure to correctly retrieve chl_a concentration in highly turbid waterbodies. This particularity nonetheless does not affect EBS performance, since turbid waters can easily be pre-recognized and masked before the chl_a modeling.},
DOI = {10.3390/rs13061134}
}



@Article{s21062105,
AUTHOR = {Cooper, Hannah M. and Wasklewicz, Thad and Zhu, Zhen and Lewis, William and LeCompte, Karley and Heffentrager, Madison and Smaby, Rachel and Brady, Julian and Howard, Robert},
TITLE = {Evaluating the Ability of Multi-Sensor Techniques to Capture Topographic Complexity},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2105},
URL = {https://www.mdpi.com/1424-8220/21/6/2105},
PubMedID = {33802744},
ISSN = {1424-8220},
ABSTRACT = {This study provides an evaluation of multiple sensors by examining their precision and ability to capture topographic complexity. Five different small unmanned aerial systems (sUAS) were evaluated, each with a different camera, Global Navigation Satellite System (GNSS), and Inertial Measurement Unit (IMU). A lidar was also used on the largest sUAS and as a mobile scanning system. The quality of each of the seven platforms were compared to actual surface measurements gathered with real-time kinematic (RTK)-GNSS and terrestrial laser scanning. Rigorous field and photogrammetric assessment workflows were designed around a combination of structure-from-motion to align images, Monte Carlo simulations to calculate spatially variable error, object-based image analysis to create objects, and MC32-PM algorithm to calculate vertical differences between two dense point clouds. The precision of the sensors ranged 0.115 m (minimum of 0.11 m for MaRS with Sony A7iii camera and maximum of 0.225 m for Mavic2 Pro). In a heterogenous test location with varying slope and high terrain roughness, only three of the seven mobile platforms performed well (MaRS, Inspire 2, and Phantom 4 Pro). All mobile sensors performed better for the homogenous test location, but the sUAS lidar and mobile lidar contained the most noise. The findings presented herein provide insights into cost–benefit of purchasing various sUAS and sensors and their ability to capture high-definition topography.},
DOI = {10.3390/s21062105}
}



@Article{molecules26061672,
AUTHOR = {Mirabelli-Montan, Ysadora A. and Marangon, Matteo and Graça, Antonio and Mayr Marangon, Christine M. and Wilkinson, Kerry L.},
TITLE = {Techniques for Mitigating the Effects of Smoke Taint While Maintaining Quality in Wine Production: A Review},
JOURNAL = {Molecules},
VOLUME = {26},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1672},
URL = {https://www.mdpi.com/1420-3049/26/6/1672},
PubMedID = {33802808},
ISSN = {1420-3049},
ABSTRACT = {Smoke taint has become a prominent issue for the global wine industry as climate change continues to impact the length and extremity of fire seasons around the world. Although the issue has prompted a surge in research on the subject in recent years, no singular solution has yet been identified that is capable of maintaining the quality of wine made from smoke-affected grapes. In this review, we summarize the main research on smoke taint, the key discoveries, as well as the prevailing uncertainties. We also examine methods for mitigating smoke taint in the vineyard, in the winery, and post production. We assess the effectiveness of remediation methods (proposed and actual) based on available research. Our findings are in agreement with previous studies, suggesting that the most viable remedies for smoke taint are still the commercially available activated carbon fining and reverse osmosis treatments, but that the quality of the final treated wines is fundamentally dependent on the initial severity of the taint. In this review, suggestions for future studies are introduced for improving our understanding of methods that have thus far only been preliminarily investigated. We select regions that have already been subjected to severe wildfires, and therefore subjected to smoke taint (particularly Australia and California) as a case study to inform other wine-producing countries that will likely be impacted in the future and suggest specific data collection and policy implementation actions that should be taken, even in countries that have not yet been impacted by smoke taint. Ultimately, we streamline the available information on the topic of smoke taint, apply it to a global perspective that considers the various stakeholders involved, and provide a launching point for further research on the topic.},
DOI = {10.3390/molecules26061672}
}



@Article{s21062129,
AUTHOR = {Buja, Ilaria and Sabella, Erika and Monteduro, Anna Grazia and Chiriacò, Maria Serena and De Bellis, Luigi and Luvisi, Andrea and Maruccio, Giuseppe},
TITLE = {Advances in Plant Disease Detection and Monitoring: From Traditional Assays to In-Field Diagnostics},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2129},
URL = {https://www.mdpi.com/1424-8220/21/6/2129},
PubMedID = {33803614},
ISSN = {1424-8220},
ABSTRACT = {Human activities significantly contribute to worldwide spread of phytopathological adversities. Pathogen-related food losses are today responsible for a reduction in quantity and quality of yield and decrease value and financial returns. As a result, “early detection” in combination with “fast, accurate, and cheap” diagnostics have also become the new mantra in plant pathology, especially for emerging diseases or challenging pathogens that spread thanks to asymptomatic individuals with subtle initial symptoms but are then difficult to face. Furthermore, in a globalized market sensitive to epidemics, innovative tools suitable for field-use represent the new frontier with respect to diagnostic laboratories, ensuring that the instruments and techniques used are suitable for the operational contexts. In this framework, portable systems and interconnection with Internet of Things (IoT) play a pivotal role. Here we review innovative diagnostic methods based on nanotechnologies and new perspectives concerning information and communication technology (ICT) in agriculture, resulting in an improvement in agricultural and rural development and in the ability to revolutionize the concept of “preventive actions”, making the difference in fighting against phytopathogens, all over the world.},
DOI = {10.3390/s21062129}
}



@Article{agronomy11030575,
AUTHOR = {Sabzi, Sajad and Pourdarbani, Razieh and Rohban, Mohammad Hossein and García-Mateos, Ginés and Paliwal, Jitendra and Molina-Martínez, José Miguel},
TITLE = {Early Detection of Excess Nitrogen Consumption in Cucumber Plants Using Hyperspectral Imaging Based on Hybrid Neural Networks and the Imperialist Competitive Algorithm},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {575},
URL = {https://www.mdpi.com/2073-4395/11/3/575},
ISSN = {2073-4395},
ABSTRACT = {To achieve healthy and optimal yields of agricultural products, the principles of nutrition must be observed and appropriate fertilizers must be applied. Nutritional deficiencies or overabundance reduce the quality and yield of the products. Thus, their early detection prevents physiological disorders and associated diseases. Most research efforts have focused on spectroscopy, which extracts only spectral data from a single point of the product. The present study aims to detect early excess nitrogen in cucumber plants by using a new hyperspectral imaging technique based on a hybrid of artificial neural networks and the imperialist competitive algorithm (ANN-ICA), which can provide spectral and spatial information on the leaves at the same time. First, cucumber seeds were planted in 18 pots. The same inputs were applied to all the pots until the plants grew; after that, 30% excess nitrogen was applied to nine pots with irrigation water, while it remained constant in the other nine pots. Each day, six leaves were collected from each pot, and their images were captured using a hyperspectral camera (in the range of 400–1100 nm). The wavelengths of 715, 783 and 821 nm were determined as the most effective for early detection of excess nitrogen using a hybrid of artificial neural networks and the artificial bee colony algorithm (ANN-ABC). The parameter of days of treatment was classified using ANN-ICA. The performance of the classifier was evaluated using different criteria, namely recall, accuracy, specificity, precision and the F-measure. The results indicate that the differences between different days were statistically significant. This means that the hyperspectral imaging technique was able to detect plants with excess nitrogen in the near-infrared range (NIR), with a correct classification rate of 96.11%.},
DOI = {10.3390/agronomy11030575}
}



@Article{s21062141,
AUTHOR = {Nafea, Ohoud and Abdul, Wadood and Muhammad, Ghulam and Alsulaiman, Mansour},
TITLE = {Sensor-Based Human Activity Recognition with Spatio-Temporal Deep Learning},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2141},
URL = {https://www.mdpi.com/1424-8220/21/6/2141},
PubMedID = {33803891},
ISSN = {1424-8220},
ABSTRACT = {Human activity recognition (HAR) remains a challenging yet crucial problem to address in computer vision. HAR is primarily intended to be used with other technologies, such as the Internet of Things, to assist in healthcare and eldercare. With the development of deep learning, automatic high-level feature extraction has become a possibility and has been used to optimize HAR performance. Furthermore, deep-learning techniques have been applied in various fields for sensor-based HAR. This study introduces a new methodology using convolution neural networks (CNN) with varying kernel dimensions along with bi-directional long short-term memory (BiLSTM) to capture features at various resolutions. The novelty of this research lies in the effective selection of the optimal video representation and in the effective extraction of spatial and temporal features from sensor data using traditional CNN and BiLSTM. Wireless sensor data mining (WISDM) and UCI datasets are used for this proposed methodology in which data are collected through diverse methods, including accelerometers, sensors, and gyroscopes. The results indicate that the proposed scheme is efficient in improving HAR. It was thus found that unlike other available methods, the proposed method improved accuracy, attaining a higher score in the WISDM dataset compared to the UCI dataset (98.53% vs. 97.05%).},
DOI = {10.3390/s21062141}
}



@Article{s21062143,
AUTHOR = {Paiva, Sara and Ahad, Mohd Abdul and Tripathi, Gautami and Feroz, Noushaba and Casalino, Gabriella},
TITLE = {Enabling Technologies for Urban Smart Mobility: Recent Trends, Opportunities and Challenges},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2143},
URL = {https://www.mdpi.com/1424-8220/21/6/2143},
PubMedID = {33803903},
ISSN = {1424-8220},
ABSTRACT = {The increasing population across the globe makes it essential to link smart and sustainable city planning with the logistics of transporting people and goods, which will significantly contribute to how societies will face mobility in the coming years. The concept of smart mobility emerged with the popularity of smart cities and is aligned with the sustainable development goals defined by the United Nations. A reduction in traffic congestion and new route optimizations with reduced ecological footprint are some of the essential factors of smart mobility; however, other aspects must also be taken into account, such as the promotion of active mobility and inclusive mobility, encouraging the use of other types of environmentally friendly fuels and engagement with citizens. The Internet of Things (IoT), Artificial Intelligence (AI), Blockchain and Big Data technology will serve as the main entry points and fundamental pillars to promote the rise of new innovative solutions that will change the current paradigm for cities and their citizens. Mobility-as-a-service, traffic flow optimization, the optimization of logistics and autonomous vehicles are some of the services and applications that will encompass several changes in the coming years with the transition of existing cities into smart cities. This paper provides an extensive review of the current trends and solutions presented in the scope of smart mobility and enabling technologies that support it. An overview of how smart mobility fits into smart cities is provided by characterizing its main attributes and the key benefits of using smart mobility in a smart city ecosystem. Further, this paper highlights other various opportunities and challenges related to smart mobility. Lastly, the major services and applications that are expected to arise in the coming years within smart mobility are explored with the prospective future trends and scope.},
DOI = {10.3390/s21062143}
}



@Article{s21062153,
AUTHOR = {Hou, Yuewu and Liu, Zhaoying and Zhang, Ting and Li, Yujian},
TITLE = {C-UNet: Complement UNet for Remote Sensing Road Extraction},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2153},
URL = {https://www.mdpi.com/1424-8220/21/6/2153},
PubMedID = {33808588},
ISSN = {1424-8220},
ABSTRACT = {Roads are important mode of transportation, which are very convenient for people’s daily work and life. However, it is challenging to accuratly extract road information from a high-resolution remote sensing image. This paper presents a road extraction method for remote sensing images with a complement UNet (C-UNet). C-UNet contains four modules. Firstly, the standard UNet is used to roughly extract road information from remote sensing images, getting the first segmentation result; secondly, a fixed threshold is utilized to erase partial extracted information; thirdly, a multi-scale dense dilated convolution UNet (MD-UNet) is introduced to discover the complement road areas in the erased masks, obtaining the second segmentation result; and, finally, we fuse the extraction results of the first and the third modules, getting the final segmentation results. Experimental results on the Massachusetts Road dataset indicate that our C-UNet gets the higher results than the state-of-the-art methods, demonstrating its effectiveness.},
DOI = {10.3390/s21062153}
}



@Article{rs13061172,
AUTHOR = {Chen, De-Yue and Peng, Ling and Li, Wei-Chao and Wang, Yin-Da},
TITLE = {Building Extraction and Number Statistics in WUI Areas Based on UNet Structure and Ensemble Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1172},
URL = {https://www.mdpi.com/2072-4292/13/6/1172},
ISSN = {2072-4292},
ABSTRACT = {Following the advancement and progression of urbanization, management problems of the wildland&ndash;urban interface (WUI) have become increasingly serious. WUI regional governance issues involve many factors including climate, humanities, etc., and have attracted attention and research from all walks of life. Building research plays a vital part in the WUI area. Building location is closely related with the planning and management of the WUI area, and the number of buildings is related to the rescue arrangement. There are two major methods to obtain this building information: one is to obtain them from relevant agencies, which is slow and lacks timeliness, while the other approach is to extract them from high-resolution remote sensing images, which is relatively inexpensive and offers improved timeliness. Inspired by the recent successful application of deep learning, in this paper, we propose a method for extracting building information from high-resolution remote sensing images based on deep learning, which is combined with ensemble learning to extract the building location. Further, we use the idea of image anomaly detection to estimate the number of buildings. After verification on two datasets, we obtain superior semantic segmentation results and achieve better building contour extraction and number estimation.},
DOI = {10.3390/rs13061172}
}



@Article{rs13061184,
AUTHOR = {Geng, Xiaomeng and Shi, Lei and Yang, Jie and Li, Pingxiang and Zhao, Lingli and Sun, Weidong and Zhao, Jinqi},
TITLE = {Ship Detection and Feature Visualization Analysis Based on Lightweight CNN in VH and VV Polarization Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1184},
URL = {https://www.mdpi.com/2072-4292/13/6/1184},
ISSN = {2072-4292},
ABSTRACT = {Synthetic aperture radar (SAR) is a significant application in maritime monitoring, which can provide SAR data throughout the day and in all weather conditions. With the development of artificial intelligence and big data technologies, the data-driven convolutional neural network (CNN) has become widely used in ship detection. However, the accuracy, feature visualization, and analysis of ship detection need to be improved further, when the CNN method is used. In this letter, we propose a two-stage ship detection for land-contained sea area without a traditional sea-land segmentation process. First, to decrease the possibly existing false alarms from the island, an island filter is used as the first step, and then threshold segmentation is used to quickly perform candidate detection. Second, a two-layer lightweight CNN model-based classifier is built to separate false alarms from the ship object. Finally, we discuss the CNN interpretation and visualize in detail when the ship is predicted in vertical–horizontal (VH) and vertical–vertical (VV) polarization. Experiments demonstrate that the proposed method can reach an accuracy of 99.4% and an F1 score of 0.99 based on the Sentinel-1 images for a ship with a size of less than 32 × 32.},
DOI = {10.3390/rs13061184}
}



@Article{land10030321,
AUTHOR = {Akumu, Clement E. and Amadi, Eze O. and Dennis, Samuel},
TITLE = {Application of Drone and WorldView-4 Satellite Data in Mapping and Monitoring Grazing Land Cover and Pasture Quality: Pre- and Post-Flooding},
JOURNAL = {Land},
VOLUME = {10},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {321},
URL = {https://www.mdpi.com/2073-445X/10/3/321},
ISSN = {2073-445X},
ABSTRACT = {Frequent flooding worldwide, especially in grazing environments, requires mapping and monitoring grazing land cover and pasture quality to support land management. Although drones, satellite, and machine learning technologies can be used to map land cover and pasture quality, there have been limited applications in grazing land environments, especially monitoring land cover change and pasture quality pre- and post-flood events. The use of high spatial resolution drone and satellite data such as WorldView-4 can provide effective mapping and monitoring in grazing land environments. The aim of this study was to utilize high spatial resolution drone and WorldView-4 satellite data to map and monitor grazing land cover change and pasture quality pre-and post-flooding. The grazing land cover was mapped pre-flooding using WorldView-4 satellite data and post-flooding using real-time drone data. The machine learning Random Forest classification algorithm was used to delineate land cover types and the normalized difference vegetation index (NDVI) was used to monitor pasture quality. This study found a seven percent (7%) increase in pasture cover and a one hundred percent (100%) increase in pasture quality post-flooding. The drone and WorldView-4 satellite data were useful to detect grazing land cover change at a finer scale.},
DOI = {10.3390/land10030321}
}



@Article{rs13061187,
AUTHOR = {Rufo, Rubén and Soriano, Jose Miguel and Villegas, Dolors and Royo, Conxita and Bellvert, Joaquim},
TITLE = {Using Unmanned Aerial Vehicle and Ground-Based RGB Indices to Assess Agronomic Performance of Wheat Landraces and Cultivars in a Mediterranean-Type Environment},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1187},
URL = {https://www.mdpi.com/2072-4292/13/6/1187},
ISSN = {2072-4292},
ABSTRACT = {The adaptability and stability of new bread wheat cultivars that can be successfully grown in rainfed conditions are of paramount importance. Plant improvement can be boosted using effective high-throughput phenotyping tools in dry areas of the Mediterranean basin, where drought and heat stress are expected to increase yield instability. Remote sensing has been of growing interest in breeding programs since it is a cost-effective technology useful for assessing the canopy structure as well as the physiological traits of large genotype collections. The purpose of this study was to evaluate the use of a 4-band multispectral camera on-board an unmanned aerial vehicle (UAV) and ground-based RGB imagery to predict agronomic traits as well as quantify the best estimation of leaf area index (LAI) in rainfed conditions. A collection of 365 bread wheat genotypes, including 181 Mediterranean landraces and 184 modern cultivars, was evaluated during two consecutive growing seasons. Several vegetation indices (VI) derived from multispectral UAV and ground-based RGB images were calculated at different image acquisition dates of the crop cycle. The modified triangular vegetation index (MTVI2) proved to have a good accuracy to estimate LAI (R2 = 0.61). Although the stepwise multiple regression analysis showed that grain yield and number of grains per square meter (NGm2) were the agronomic traits most suitable to be predicted, the R2 were low due to field trials were conducted under rainfed conditions. Moreover, the prediction of agronomic traits was slightly better with ground-based RGB VI rather than with UAV multispectral VIs. NDVI and GNDVI, from multispectral images, were present in most of the prediction equations. Repeated measurements confirmed that the ability of VIs to predict yield depends on the range of phenotypic data. The current study highlights the potential use of VI and RGB images as an efficient tool for high-throughput phenotyping under rainfed Mediterranean conditions.},
DOI = {10.3390/rs13061187}
}



@Article{rs13061198,
AUTHOR = {Liu, Bi-Yuan and Chen, Huai-Xin and Huang, Zhou and Liu, Xing and Yang, Yun-Zhi},
TITLE = {ZoomInNet: A Novel Small Object Detector in Drone Images with Cross-Scale Knowledge Distillation},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1198},
URL = {https://www.mdpi.com/2072-4292/13/6/1198},
ISSN = {2072-4292},
ABSTRACT = {Drone-based object detection has been widely applied in ground object surveillance, urban patrol, and some other fields. However, the dramatic scale changes and complex backgrounds of drone images usually result in weak feature representation of small objects, which makes it challenging to achieve high-precision object detection. Aiming to improve small objects detection, this paper proposes a novel cross-scale knowledge distillation (CSKD) method, which enhances the features of small objects in a manner similar to image enlargement, so it is termed as ZoomInNet. First, based on an efficient feature pyramid network structure, the teacher and student network are trained with images in different scales to introduce the cross-scale feature. Then, the proposed layer adaption (LA) and feature level alignment (FA) mechanisms are applied to align the feature size of the two models. After that, the adaptive key distillation point (AKDP) algorithm is used to get the crucial positions in feature maps that need knowledge distillation. Finally, the position-aware L2 loss is used to measure the difference between feature maps from cross-scale models, realizing the cross-scale information compression in a single model. Experiments on the challenging Visdrone2018 dataset show that the proposed method draws on the advantages of the image pyramid methods, while avoids the large calculation of them and significantly improves the detection accuracy of small objects. Simultaneously, the comparison with mainstream methods proves that our method has the best performance in small object detection.},
DOI = {10.3390/rs13061198}
}



@Article{s21062208,
AUTHOR = {Park, Kyung Ho and Park, Eunji and Kim, Huy Kang},
TITLE = {Unsupervised Fault Detection on Unmanned Aerial Vehicles: Encoding and Thresholding Approach},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2208},
URL = {https://www.mdpi.com/1424-8220/21/6/2208},
PubMedID = {33809830},
ISSN = {1424-8220},
ABSTRACT = {Unmanned Aerial Vehicles are expected to create enormous benefits to society, but there are safety concerns in recognizing faults at the vehicle’s control component. Prior studies proposed various fault detection approaches leveraging heuristics-based rules and supervised learning-based models, but there were several drawbacks. The rule-based approaches required an engineer to update the rules on every type of fault, and the supervised learning-based approaches necessitated the acquisition of a finely-labeled training dataset. Moreover, both prior approaches commonly include a limit that the detection model can identify the trained type of faults only, but fail to recognize the unseen type of faults. In pursuit of resolving the aforementioned drawbacks, we proposed a fault detection model utilizing a stacked autoencoder that lies under unsupervised learning. The autoencoder was trained with data from safe UAV states, and its reconstruction loss was examined to distinguish the safe states and faulty states. The key contributions of our study are, as follows. First, we presented a series of analyses to extract essential features from raw UAV flight logs. Second, we designed a fault detection model consisting of the stacked autoencoder and the classifier. Lastly, we validated our approach’s fault detection performance with two datasets consisting of different types of UAV faults.},
DOI = {10.3390/s21062208}
}



@Article{electronics10060747,
AUTHOR = {Passafiume, Marco and Rojhani, Neda and Collodi, Giovanni and Cidronali, Alessandro},
TITLE = {Modeling Small UAV Micro-Doppler Signature Using Millimeter-Wave FMCW Radar},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {747},
URL = {https://www.mdpi.com/2079-9292/10/6/747},
ISSN = {2079-9292},
ABSTRACT = {With the increase in small unmanned aerial vehicle (UAV) applications in several technology areas, detection and small UAVs classification have become of interest. To cope with small radar cross-sections (RCSs), slow-flying speeds, and low flying altitudes, the micro-Doppler signature provides some of the most distinctive information to identify and classify targets in many radar systems. In this paper, we introduce an effective model for the micro-Doppler effect that is suitable for frequency-modulated continuous-wave (FMCW) radar applications, and exploit it to investigate UAV signatures. The latter depends on the number of UAV motors, which are considered vibrational sources, and their rotation speed. To demonstrate the reliability of the proposed model, it is used to build simulated FMCW radar images, which are compared with experimental data acquired by a 77 GHz FMCW multiple-input multiple-output (MIMO) cost-effective automotive radar platform. The experimental results confirm the model’s ability to estimate the class of the UAV, namely its number of motors, in different operative scenarios. In addition, the experimental results show that the motors rotation speed does not imprint a significant signature on the classification of the UAV; thus, the estimation of the number of motors represents the only viable parameter for small UAV classification using the micro-Doppler effect.},
DOI = {10.3390/electronics10060747}
}



@Article{f12030378,
AUTHOR = {Magstadt, Shayne and Gwenzi, David and Madurapperuma, Buddhika},
TITLE = {Can a Remote Sensing Approach with Hyperspectral Data Provide Early Detection and Mapping of Spatial Patterns of Black Bear Bark Stripping in Coast Redwoods?},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {378},
URL = {https://www.mdpi.com/1999-4907/12/3/378},
ISSN = {1999-4907},
ABSTRACT = {The prevalence of black bear (Ursus americanus) bark stripping in commercial redwood (Sequoia sempervirens (D. Don) Endl.) timber stands has been increasing in recent years. This stripping is a threat to commercial timber production because of the deleterious effects on redwood tree fitness. This study sought to unveil a remote sensing method to detect these damaged trees early and map their spatial patterns. By developing a timely monitoring method, forest timber companies can manipulate their timber harvesting routines to adapt to the consequences of the problem. We explored the utility of high spatial resolution UAV-collected hyperspectral imagery as a means for early detection of individual trees stripped by black bears. A hyperspectral sensor was used to capture ultra-high spatial and spectral information pertaining to redwood trees with no damage, those that have been recently attacked by bears, and those with old bear damage. This spectral information was assessed using the Jeffries-Matusita (JM) distance to determine regions along the electromagnetic spectrum that are useful for discerning these three-health classes. While we were able to distinguish healthy trees from trees with old damage, we were unable to distinguish healthy trees from recently damaged trees due to the inherent characteristics of redwood tree growth and the subtle spectral changes within individual tree crowns for the time period assessed. The results, however, showed that with further assessment, a time window may be identified that informs damage before trees completely lose value.},
DOI = {10.3390/f12030378}
}



@Article{rs13061204,
AUTHOR = {Delavarpour, Nadia and Koparan, Cengiz and Nowatzki, John and Bajwa, Sreekala and Sun, Xin},
TITLE = {A Technical Study on UAV Characteristics for Precision Agriculture Applications and Associated Practical Challenges},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1204},
URL = {https://www.mdpi.com/2072-4292/13/6/1204},
ISSN = {2072-4292},
ABSTRACT = {The incorporation of advanced technologies into Unmanned Aerial Vehicles (UAVs) platforms have enabled many practical applications in Precision Agriculture (PA) over the past decade. These PA tools offer capabilities that increase agricultural productivity and inputs’ efficiency and minimize operational costs simultaneously. However, these platforms also have some constraints that limit the application of UAVs in agricultural operations. The constraints include limitations in providing imagery of adequate spatial and temporal resolutions, dependency on weather conditions, and geometric and radiometric correction requirements. In this paper, a practical guide on technical characterizations of common types of UAVs used in PA is presented. This paper helps select the most suitable UAVs and on-board sensors for different agricultural operations by considering all the possible constraints. Over a hundred research studies were reviewed on UAVs applications in PA and practical challenges in monitoring and mapping field crops. We concluded by providing suggestions and future directions to overcome challenges in optimizing operational proficiency.},
DOI = {10.3390/rs13061204}
}



@Article{app11062813,
AUTHOR = {Colucci, Elisabetta and Xing, Xufeng and Kokla, Margarita and Mostafavi, Mir Abolfazl and Noardo, Francesca and Spanò, Antonia},
TITLE = {Ontology-Based Semantic Conceptualisation of Historical Built Heritage to Generate Parametric Structured Models from Point Clouds},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2813},
URL = {https://www.mdpi.com/2076-3417/11/6/2813},
ISSN = {2076-3417},
ABSTRACT = {Nowadays, cultural and historical built heritage can be more effectively preserved, valorised and documented using advanced geospatial technologies. In such a context, there is a major issue concerning the automation of the process and the extraction of useful information from a huge amount of spatial information acquired by means of advanced survey techniques (i.e., highly detailed LiDAR point clouds). In particular, in the case of historical built heritage (HBH) there are very few effective efforts. Therefore, in this paper, the focus is on establishing the connections between semantic and geometrical information in order to generate a parametric, structured model from point clouds using ontology as an effective approach for the formal conceptualisation of application domains. Hence, in this paper, an ontological schema is proposed to structure HBH representations, starting with international standards, vocabularies, and ontologies (CityGML-Geography Markup Language, International Committee for Documentation conceptual reference model (CIDOC-CRM), Industry Foundation Classes (IFC), Getty Art and Architecture Thesaurus (AAT), as well as reasoning about morphology of historical centres by analysis of real case studies) to represent the built and architecture domain. The validation of such schema is carried out by means of its use to guide the segmentation of a LiDAR point cloud from a castle, which is later used to generate parametric geometries to be used in a historical building information model (HBIM).},
DOI = {10.3390/app11062813}
}



@Article{rs13061205,
AUTHOR = {Zhao, Caidan and Luo, Gege and Wang, Yilin and Chen, Caiyun and Wu, Zhiqiang},
TITLE = {UAV Recognition Based on Micro-Doppler Dynamic Attribute-Guided Augmentation Algorithm},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1205},
URL = {https://www.mdpi.com/2072-4292/13/6/1205},
ISSN = {2072-4292},
ABSTRACT = {A micro-Doppler signature (m-DS) based on the rotation of drone blades is an effective way to detect and identify small drones. Deep-learning-based recognition algorithms can achieve higher recognition performance, but they needs a large amount of sample data to train models. In addition to the hovering state, the signal samples of small unmanned aerial vehicles (UAVs) should also include flight dynamics, such as vertical, pitch, forward and backward, roll, lateral, and yaw. However, it is difficult to collect all dynamic UAV signal samples under actual flight conditions, and these dynamic flight characteristics will lead to the deviation of the original features, thus affecting the performance of the recognizer. In this paper, we propose a small UAV m-DS recognition algorithm based on dynamic feature enhancement. We extract the combined principal component analysis and discrete wavelet transform (PCA-DWT) time–frequency characteristics and texture features of the UAV’s micro-Doppler signal and use a dynamic attribute-guided augmentation (DAGA) algorithm to expand the feature domain for model training to achieve an adaptive, accurate, and efficient multiclass recognition model in complex environments. After the training model is stable, the average recognition accuracy rate can reach 98% during dynamic flight.},
DOI = {10.3390/rs13061205}
}



@Article{s21062233,
AUTHOR = {Li, Ke and Zhang, Kun and Zhang, Zhenchong and Liu, Zekun and Hua, Shuai and He, Jianliang},
TITLE = {A UAV Maneuver Decision-Making Algorithm for Autonomous Airdrop Based on Deep Reinforcement Learning},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2233},
URL = {https://www.mdpi.com/1424-8220/21/6/2233},
PubMedID = {33806886},
ISSN = {1424-8220},
ABSTRACT = {How to operate an unmanned aerial vehicle (UAV) safely and efficiently in an interactive environment is challenging. A large amount of research has been devoted to improve the intelligence of a UAV while performing a mission, where finding an optimal maneuver decision-making policy of the UAV has become one of the key issues when we attempt to enable the UAV autonomy. In this paper, we propose a maneuver decision-making algorithm based on deep reinforcement learning, which generates efficient maneuvers for a UAV agent to execute the airdrop mission autonomously in an interactive environment. Particularly, the training set of the learning algorithm by the Prioritized Experience Replay is constructed, that can accelerate the convergence speed of decision network training in the algorithm. It is shown that a desirable and effective maneuver decision-making policy can be found by extensive experimental results.},
DOI = {10.3390/s21062233}
}



@Article{e23030380,
AUTHOR = {Cavenaghi, Emanuele and Sottocornola, Gabriele and Stella, Fabio and Zanker, Markus},
TITLE = {Non Stationary Multi-Armed Bandit: Empirical Evaluation of a New Concept Drift-Aware Algorithm},
JOURNAL = {Entropy},
VOLUME = {23},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {380},
URL = {https://www.mdpi.com/1099-4300/23/3/380},
PubMedID = {33807028},
ISSN = {1099-4300},
ABSTRACT = {The Multi-Armed Bandit (MAB) problem has been extensively studied in order to address real-world challenges related to sequential decision making. In this setting, an agent selects the best action to be performed at time-step t, based on the past rewards received by the environment. This formulation implicitly assumes that the expected payoff for each action is kept stationary by the environment through time. Nevertheless, in many real-world applications this assumption does not hold and the agent has to face a non-stationary environment, that is, with a changing reward distribution. Thus, we present a new MAB algorithm, named f-Discounted-Sliding-Window Thompson Sampling (f-dsw TS), for non-stationary environments, that is, when the data streaming is affected by concept drift. The f-dsw TS algorithm is based on Thompson Sampling (TS) and exploits a discount factor on the reward history and an arm-related sliding window to contrast concept drift in non-stationary environments. We investigate how to combine these two sources of information, namely the discount factor and the sliding window, by means of an aggregation function f(.). In particular, we proposed a pessimistic (f=min), an optimistic (f=max), as well as an averaged (f=mean) version of the f-dsw TS algorithm. A rich set of numerical experiments is performed to evaluate the f-dsw TS algorithm compared to both stationary and non-stationary state-of-the-art TS baselines. We exploited synthetic environments (both randomly-generated and controlled) to test the MAB algorithms under different types of drift, that is, sudden/abrupt, incremental, gradual and increasing/decreasing drift. Furthermore, we adapt four real-world active learning tasks to our framework—a prediction task on crimes in the city of Baltimore, a classification task on insects species, a recommendation task on local web-news, and a time-series analysis on microbial organisms in the tropical air ecosystem. The f-dsw TS approach emerges as the best performing MAB algorithm. At least one of the versions of f-dsw TS performs better than the baselines in synthetic environments, proving the robustness of f-dsw TS under different concept drift types. Moreover, the pessimistic version (f=min) results as the most effective in all real-world tasks.},
DOI = {10.3390/e23030380}
}



@Article{rs13061224,
AUTHOR = {Azpiroz, Izar and Oses, Noelia and Quartulli, Marco and Olaizola, Igor G. and Guidotti, Diego and Marchi, Susanna},
TITLE = {Comparison of Climate Reanalysis and Remote-Sensing Data for Predicting Olive Phenology through Machine-Learning Methods},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1224},
URL = {https://www.mdpi.com/2072-4292/13/6/1224},
ISSN = {2072-4292},
ABSTRACT = {Machine-learning algorithms used for modelling olive-tree phenology generally and largely rely on temperature data. In this study, we developed a prediction model on the basis of climate data and geophysical information. Remote measurements of weather conditions, terrain slope, and surface spectral reflectance were considered for this purpose. The accuracy of the temperature data worsened when replacing weather-station measurements with remote-sensing records, though the addition of more complete environmental data resulted in an efficient prediction model of olive-tree phenology. Filtering and embedded feature-selection techniques were employed to analyze the impact of variables on olive-tree phenology prediction, facilitating the inclusion of measurable information in decision support frameworks for the sustainable management of olive-tree systems.},
DOI = {10.3390/rs13061224}
}



@Article{computers10040039,
AUTHOR = {Bijur, Gururaj and Mundugar, Ramakrishna and Mantoor, Vinayak and A Kotegar, Karunakar},
TITLE = {Estimation of Adaptation Parameters for Dynamic Video Adaptation in Wireless Network Using Experimental Method},
JOURNAL = {Computers},
VOLUME = {10},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {39},
URL = {https://www.mdpi.com/2073-431X/10/4/39},
ISSN = {2073-431X},
ABSTRACT = {A wireless network gives flexibility to the user in terms of mobility that attracts the user to use wireless communication more. The video communication in the wireless network experiences Quality of Services (QoS) and Quality of Experience (QoE) issues due to network dynamics. The parameters, such as node mobility, routing protocols, and distance between the nodes, play a major role in the quality of video communication. Scalable Video Coding (SVC) is an extension to H.264 Advanced Video Coding (AVC), allows partial removal of layers, and generates a valid adapted bit-stream. This adaptation feature enables the streaming of video data over a wireless network to meet the availability of the resources. The video adaptation is a dynamic process and requires prior knowledge to decide the adaptation parameter for extraction of the video levels. This research work aims at building the adaptation parameters that are required by the adaptation engines, such as Media Aware Network Elements (MANE), to perform adaptation on-the-fly. The prior knowledge improves the performances of the adaptation engines and gives the improved quality of the video communication. The unique feature of this work is that, here, we used an experimental evaluation method to identify the video levels that are suitable for a given network condition. In this paper, we estimated the adaptation parameters for streaming scalable video over the wireless network using the experimental method. The adaptation parameters are derived using node mobility, link bandwidth, and motion level of video sequences as deciding parameters. The experimentation is carried on the OMNeT++ tool, and Joint Scalable Video Module (JSVM) is used to encode and decode the scalable video data.},
DOI = {10.3390/computers10040039}
}



@Article{rs13071231,
AUTHOR = {Agrillo, Emiliano and Filipponi, Federico and Pezzarossa, Alice and Casella, Laura and Smiraglia, Daniela and Orasi, Arianna and Attorre, Fabio and Taramelli, Andrea},
TITLE = {Earth Observation and Biodiversity Big Data for Forest Habitat Types Classification and Mapping},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1231},
URL = {https://www.mdpi.com/2072-4292/13/7/1231},
ISSN = {2072-4292},
ABSTRACT = {In the light of the “Biological Diversity” concept, habitats are cardinal pieces for biodiversity quantitative estimation at a local and global scale. In Europe EUNIS (European Nature Information System) is a system tool for habitat identification and assessment. Earth Observation (EO) data, which are acquired by satellite sensors, offer new opportunities for environmental sciences and they are revolutionizing the methodologies applied. These are providing unprecedented insights for habitat monitoring and for evaluating the Sustainable Development Goals (SDGs) indicators. This paper shows the results of a novel approach for a spatially explicit habitat mapping in Italy at a national scale, using a supervised machine learning model (SMLM), through the combination of vegetation plot database (as response variable), and both spectral and environmental predictors. The procedure integrates forest habitat data in Italy from the European Vegetation Archive (EVA), with Sentinel-2 imagery processing (vegetation indices time series, spectral indices, and single bands spectral signals) and environmental data variables (i.e., climatic and topographic), to parameterize a Random Forests (RF) classifier. The obtained results classify 24 forest habitats according to the EUNIS III level: 12 broadleaved deciduous (T1), 4 broadleaved evergreen (T2) and eight needleleaved forest habitats (T3), and achieved an overall accuracy of 87% at the EUNIS II level classes (T1, T2, T3), and an overall accuracy of 76.14% at the EUNIS III level. The highest overall accuracy value was obtained for the broadleaved evergreen forest equal to 91%, followed by 76% and 68% for needleleaved and broadleaved deciduous habitat forests, respectively. The results of the proposed methodology open the way to increase the EUNIS habitat categories to be mapped together with their geographical extent, and to test different semi-supervised machine learning algorithms and ensemble modelling methods.},
DOI = {10.3390/rs13071231}
}



@Article{rs13071238,
AUTHOR = {Kaivosoja, Jere and Hautsalo, Juho and Heikkinen, Jaakko and Hiltunen, Lea and Ruuttunen, Pentti and Näsi, Roope and Niemeläinen, Oiva and Lemsalu, Madis and Honkavaara, Eija and Salonen, Jukka},
TITLE = {Reference Measurements in Developing UAV Systems for Detecting Pests, Weeds, and Diseases},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1238},
URL = {https://www.mdpi.com/2072-4292/13/7/1238},
ISSN = {2072-4292},
ABSTRACT = {The development of UAV (unmanned aerial vehicle) imaging technologies for precision farming applications is rapid, and new studies are published frequently. In cases where measurements are based on aerial imaging, there is the need to have ground truth or reference data in order to develop reliable applications. However, in several precision farming use cases such as pests, weeds, and diseases detection, the reference data can be subjective or relatively difficult to capture. Furthermore, the collection of reference data is usually laborious and time consuming. It also appears that it is difficult to develop generalisable solutions for these areas. This review studies previous research related to pests, weeds, and diseases detection and mapping using UAV imaging in the precision farming context, underpinning the applied reference measurement techniques. The majority of the reviewed studies utilised subjective visual observations of UAV images, and only a few applied in situ measurements. The conclusion of the review is that there is a lack of quantitative and repeatable reference data measurement solutions in the areas of mapping pests, weeds, and diseases. In addition, the results that the studies present should be reflected in the applied references. An option in the future approach could be the use of synthetic data as reference.},
DOI = {10.3390/rs13071238}
}



@Article{rs13071239,
AUTHOR = {Oddi, Ludovica and Cremonese, Edoardo and Ascari, Lorenzo and Filippa, Gianluca and Galvagno, Marta and Serafino, Davide and Cella, Umberto Morra di},
TITLE = {Using UAV Imagery to Detect and Map Woody Species Encroachment in a Subalpine Grassland: Advantages and Limits},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1239},
URL = {https://www.mdpi.com/2072-4292/13/7/1239},
ISSN = {2072-4292},
ABSTRACT = {Woody species encroachment on grassland ecosystems is occurring worldwide with both negative and positive consequences for biodiversity conservation and ecosystem services. Remote sensing and image analysis represent useful tools for the monitoring of this process. In this paper, we aimed at evaluating quantitatively the potential of using high-resolution UAV imagery to monitor the encroachment process during its early development and at comparing the performance of manual and semi-automatic classification methods. The RGB images of an abandoned subalpine grassland on the Western Italian Alps were acquired by drone and then classified through manual photo-interpretation, with both pixel- and object-based semi-automatic models, using machine-learning algorithms. The classification techniques were applied at different resolution levels and tested for their accuracy against reference data including measurements of tree dimensions collected in the field. Results showed that the most accurate method was the photo-interpretation (≈99%), followed by the pixel-based approach (≈86%) that was faster than the manual technique and more accurate than the object-based one (≈78%). The dimensional threshold for juvenile tree detection was lower for the photo-interpretation but comparable to the pixel-based one. Therefore, for the encroachment mapping at its early stages, the pixel-based approach proved to be a promising and pragmatic choice.},
DOI = {10.3390/rs13071239}
}



@Article{robotics10020052,
AUTHOR = {Oliveira, Luiz F. P. and Moreira, António P. and Silva, Manuel F.},
TITLE = {Advances in Agriculture Robotics: A State-of-the-Art Review and Challenges Ahead},
JOURNAL = {Robotics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {52},
URL = {https://www.mdpi.com/2218-6581/10/2/52},
ISSN = {2218-6581},
ABSTRACT = {The constant advances in agricultural robotics aim to overcome the challenges imposed by population growth, accelerated urbanization, high competitiveness of high-quality products, environmental preservation and a lack of qualified labor. In this sense, this review paper surveys the main existing applications of agricultural robotic systems for the execution of land preparation before planting, sowing, planting, plant treatment, harvesting, yield estimation and phenotyping. In general, all robots were evaluated according to the following criteria: its locomotion system, what is the final application, if it has sensors, robotic arm and/or computer vision algorithm, what is its development stage and which country and continent they belong. After evaluating all similar characteristics, to expose the research trends, common pitfalls and the characteristics that hinder commercial development, and discover which countries are investing into Research and Development (R&amp;D) in these technologies for the future, four major areas that need future research work for enhancing the state of the art in smart agriculture were highlighted: locomotion systems, sensors, computer vision algorithms and communication technologies. The results of this research suggest that the investment in agricultural robotic systems allows to achieve short—harvest monitoring—and long-term objectives—yield estimation.},
DOI = {10.3390/robotics10020052}
}



@Article{robotics10020053,
AUTHOR = {Oliveira, Luiz F. P. and Moreira, António P. and Silva, Manuel F.},
TITLE = {Advances in Forest Robotics: A State-of-the-Art Survey},
JOURNAL = {Robotics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {53},
URL = {https://www.mdpi.com/2218-6581/10/2/53},
ISSN = {2218-6581},
ABSTRACT = {The development of robotic systems to operate in forest environments is of great relevance for the public and private sectors. In this sense, this article reviews several scientific papers, research projects and commercial products related to robotic applications for environmental preservation, monitoring, wildfire firefighting, inventory operations, planting, pruning and harvesting. After conducting critical analysis, the main characteristics observed were: (a) the locomotion system is directly affected by the type of environmental monitoring to be performed; (b) different reasons for pruning result in different locomotion and cutting systems; (c) each type of forest, in each season and each type of soil can directly interfere with the navigation technique used; and (d) the integration of the concept of swarm of robots with robots of different types of locomotion systems (land, air or sea) can compensate for the time of executing tasks in unstructured environments. Two major areas are proposed for future research works: Internet of Things (IoT)-based smart forest and navigation systems. It is expected that, with the various characteristics exposed in this paper, the current robotic forest systems will be improved, so that forest exploitation becomes more efficient and sustainable.},
DOI = {10.3390/robotics10020053}
}



@Article{electronics10070771,
AUTHOR = {Liu, Chuanyang and Wu, Yiquan and Liu, Jingjing and Sun, Zuo},
TITLE = {Improved YOLOv3 Network for Insulator Detection in Aerial Images with Diverse Background Interference},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {771},
URL = {https://www.mdpi.com/2079-9292/10/7/771},
ISSN = {2079-9292},
ABSTRACT = {Automatic inspection of insulators from high-voltage transmission lines is of paramount importance to the safety and reliable operation of the power grid. Due to different size insulators and the complex background of aerial images, it is a difficult task to recognize insulators in aerial views. Most of the traditional image processing methods and machine learning methods cannot achieve sufficient performance for insulator detection when diverse background interference is present. In this study, a deep learning method—based on You Only Look Once (YOLO)—will be proposed, capable of detecting insulators from aerial images with complex backgrounds. Firstly, aerial images with common aerial scenes were collected by Unmanned Aerial Vehicle (UAV), and a novel insulator dataset was constructed. Secondly, to enhance feature reuse and propagation, on the basis of YOLOv3 and Dense-Blocks, the YOLOv3-dense network was utilized for insulator detection. To improve detection accuracy for different sized insulators, a structure of multiscale feature fusion was adapted to the YOLOv3-dense network. To obtain abundant semantic information of upper and lower layers, multilevel feature mapping modules were employed across the YOLOv3-dense network. Finally, the YOLOv3-dense network and compared networks were trained and tested on the testing set. The average precision of YOLOv3-dense, YOLOv3, and YOLOv2 were 94.47%, 90.31%, and 83.43%, respectively. Experimental results and analysis validate the claim that the proposed YOLOv3-dense network achieves good performance in the detection of different size insulators amid diverse background interference.},
DOI = {10.3390/electronics10070771}
}



@Article{rs13071245,
AUTHOR = {Lin, Jinhuang and Jin, Xiaobin and Ren, Jie and Liu, Jingping and Liang, Xinyuan and Zhou, Yinkang},
TITLE = {Rapid Mapping of Large-Scale Greenhouse Based on Integrated Learning Algorithm and Google Earth Engine},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1245},
URL = {https://www.mdpi.com/2072-4292/13/7/1245},
ISSN = {2072-4292},
ABSTRACT = {A greenhouse is an important land-use type, which can effectively improve agricultural production conditions and increase crop yields. It is of great significance to obtain the spatial distribution data of greenhouses quickly and accurately for regional agricultural production and food security. Based on the Google Earth Engine cloud platform and Landsat 8 images, this study selected a total of 18 indicators from three aspects of spectral features, texture features and terrain features to construct greenhouse identification features. From a variety of classification algorithms for remote-sensing recognition of greenhouses, this study selected three classifiers with higher accuracy (classification and regression trees (CART), random forest model (randomForest) and maximum entropy model (gmoMaxEnt)) to construct an integrated classification algorithm, and then extracted the spatial distribution data of greenhouses in Jiangsu Province. The results show that: (1) Google Earth Engine with its own massive data and cloud computing capabilities, combined with integrated classification algorithms, can achieve rapid remote-sensing mapping of large-scale greenhouses under complex terrain, and the classification accuracy is higher than that of a single classification algorithm. (2) The combination of different spectral, texture and terrain features has a greater impact on the extraction of regional greenhouses, the combination of all three aspects of features has the highest accuracy. Spectral features are the key factors for greenhouse remote-sensing mapping, but terrain and texture features can also enhance classification accuracy. (3) The greenhouse in Jiangsu Province has significant spatial differentiation and spatial agglomeration characteristics. The most widely distributed greenhouses are mainly concentrated in the agriculturally developed areas such as Dongtai City, Hai’an County, Rudong County and Pizhou City.},
DOI = {10.3390/rs13071245}
}



@Article{geomatics1020010,
AUTHOR = {Khedr, Maan and El-Sheimy, Naser},
TITLE = {S-PDR: SBAUPT-Based Pedestrian Dead Reckoning Algorithm for Free-Moving Handheld Devices},
JOURNAL = {Geomatics},
VOLUME = {1},
YEAR = {2021},
NUMBER = {2},
PAGES = {148--176},
URL = {https://www.mdpi.com/2673-7418/1/2/10},
ISSN = {2673-7418},
ABSTRACT = {Mobile location-based services (MLBS) are attracting attention for their potential public and personal use for a variety of applications such as location-based advertisement, smart shopping, smart cities, health applications, emergency response, and even gaming. Many of these applications rely on Inertial Navigation Systems (INS) due to the degraded GNSS services indoors. INS-based MLBS using smartphones is hindered by the quality of the MEMS sensors provided in smartphones which suffer from high noise and errors resulting in high drift in the navigation solution rapidly. Pedestrian dead reckoning (PDR) is an INS-based navigation technique that exploits human motion to reduce navigation solution errors, but the errors cannot be eliminated without aid from other techniques. The purpose of this study is to enhance and extend the short-term reliability of PDR systems for smartphones as a standalone system through an enhanced step detection algorithm, a periodic attitude correction technique, and a novel PCA-based motion direction estimation technique. Testing shows that the developed system (S-PDR) provides a reliable short-term navigation solution with a final positioning error that is up to 6 m after 3 min runtime. These results were compared to a PDR solution using an Xsens IMU which is known to be a high grade MEMS IMU and was found to be worse than S-PDR. The findings show that S-PDR can be used to aid GNSS in challenging environments and can be a viable option for short-term indoor navigation until aiding is provided by alternative means. Furthermore, the extended reliable solution of S-PDR can help reduce the operational complexity of aiding navigation systems such as RF-based indoor navigation and magnetic map matching as it reduces the frequency by which these aiding techniques are required and applied.},
DOI = {10.3390/geomatics1020010}
}



@Article{rs13071248,
AUTHOR = {Xu, Hao and Yao, Wei and Cheng, Li and Li, Bo},
TITLE = {Multiple Spectral Resolution 3D Convolutional Neural Network for Hyperspectral Image Classification},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1248},
URL = {https://www.mdpi.com/2072-4292/13/7/1248},
ISSN = {2072-4292},
ABSTRACT = {In recent years, benefiting from the rapid development of deep learning technology in the field of computer vision, the study of hyperspectral image (HSI) classification has also made great progress. However, compared with ordinary RGB images, HSIs are more like 3D cubes; therefore, it is necessary and beneficial to explore classification methods suitable for the very special data structure of HSIs. In this paper, we propose Multiple Spectral Resolution 3D Convolutional Neural Network (MSR-3DCNN) for HSI classification tasks. In MSR-3DCNN, we expand the idea of multi-scale feature fusion and dilated convolution from the spatial dimension to the spectral dimension, and combine 3D convolution and residual connection; therefore, it can better adapt to the 3D cubic form of hyperspectral data and make efficient use of spectral information in different bands. Experimental results on four benchmark datasets show the effectiveness of the proposed approach and its superiority as compared with some state-of-the-art (SOTA) HSI classification methods.},
DOI = {10.3390/rs13071248}
}



@Article{agronomy11040621,
AUTHOR = {López-Andreu, Francisco Javier and Erena, Manuel and Dominguez-Gómez, Jose Antonio and López-Morales, Juan Antonio},
TITLE = {Sentinel-2 Images and Machine Learning as Tool for Monitoring of the Common Agricultural Policy: Calasparra Rice as a Case Study},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {621},
URL = {https://www.mdpi.com/2073-4395/11/4/621},
ISSN = {2073-4395},
ABSTRACT = {The European Commission introduces the Control by Monitoring through new technologies to manage Common Agricultural Policy funds through the Regulation 2018/746. The advances in remote sensing have been considered one of these new technologies, mainly since the European Space Agency designed the Copernicus Programme. The Sentinel-1 (radar range) and Sentinel-2 (optical range) satellites have been designed for monitoring agricultural problems based on the characteristics they provide. The data provided by the Sentinel 2 missions, together with the emergence of different scientific disciplines in artificial intelligence —especially machine learning— offer the perfect basis for identifying and classifying any crop and its phenological state. Our research is based on developing and evaluating a pixel-based supervised classification scheme to produce accurate rice crop mapping in a smallholder agricultural zone in Calasparra, Murcia, Spain. Several models are considered to obtain the most suitable model for each element of the time series used; pixel-based classification is performed and finished with a statistical treatment. The highly accurate results obtained, especially across the most significant vegetative development dates, indicate the benefits of using Sentinel-2 data combined with Machine Learning techniques to identify rice crops. It should be noted that it was possible to locate rice crop areas with an overall accuracy of 94% and standard deviation of 1%, which could be increased to 96% (±1%) if we focus on the months of the crop’s highest development state. Thanks to the proposed methodology, the on-site inspections carried out, 5% of the files, have been replaced by remote sensing evaluations of 100% of the analyzed season files. Besides, by adjusting the model input data, it is possible to detect unproductive or abandoned plots.},
DOI = {10.3390/agronomy11040621}
}



@Article{rs13071261,
AUTHOR = {Roncella, Riccardo and Bruno, Nazarena and Diotri, Fabrizio and Thoeni, Klaus and Giacomini, Anna},
TITLE = {Photogrammetric Digital Surface Model Reconstruction in Extreme Low-Light Environments},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1261},
URL = {https://www.mdpi.com/2072-4292/13/7/1261},
ISSN = {2072-4292},
ABSTRACT = {Digital surface models (DSM) have become one of the main sources of geometrical information for a broad range of applications. Image-based systems typically rely on passive sensors which can represent a strong limitation in several survey activities (e.g., night-time monitoring, underground survey and night surveillance). However, recent progresses in sensor technology allow very high sensitivity which drastically improves low-light image quality by applying innovative noise reduction techniques. This work focuses on the performances of night-time photogrammetric systems devoted to the monitoring of rock slopes. The study investigates the application of different camera settings and their reliability to produce accurate DSM. A total of 672 stereo-pairs acquired with high-sensitivity cameras (Nikon D800 and D810) at three different testing sites were considered. The dataset includes different camera configurations (ISO speed, shutter speed, aperture and image under-/over-exposure). The use of image quality assessment (IQA) methods to evaluate the quality of the images prior to the 3D reconstruction is investigated. The results show that modern high-sensitivity cameras allow the reconstruction of accurate DSM in an extreme low-light environment and, exploiting the correct camera setup, achieving comparable results to daylight acquisitions. This makes imaging sensors extremely versatile for monitoring applications at generally low costs.},
DOI = {10.3390/rs13071261}
}



@Article{s21072328,
AUTHOR = {Shahbazi, Nooshin and Ashworth, Michael B. and Callow, J. Nikolaus and Mian, Ajmal and Beckie, Hugh J. and Speidel, Stuart and Nicholls, Elliot and Flower, Ken C.},
TITLE = {Assessing the Capability and Potential of LiDAR for Weed Detection},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {2328},
URL = {https://www.mdpi.com/1424-8220/21/7/2328},
PubMedID = {33810604},
ISSN = {1424-8220},
ABSTRACT = {Conventional methods of uniformly spraying fields to combat weeds, requires large herbicide inputs at significant cost with impacts on the environment. More focused weed control methods such as site-specific weed management (SSWM) have become popular but require methods to identify weed locations. Advances in technology allows the potential for automated methods such as drone, but also ground-based sensors for detecting and mapping weeds. In this study, the capability of Light Detection and Ranging (LiDAR) sensors were assessed to detect and locate weeds. For this purpose, two trials were performed using artificial targets (representing weeds) at different heights and diameter to understand the detection limits of a LiDAR. The results showed the detectability of the target at different scanning distances from the LiDAR was directly influenced by the size of the target and its orientation toward the LiDAR. A third trial was performed in a wheat plot where the LiDAR was used to scan different weed species at various heights above the crop canopy, to verify the capacity of the stationary LiDAR to detect weeds in a field situation. The results showed that 100% of weeds in the wheat plot were detected by the LiDAR, based on their height differences with the crop canopy.},
DOI = {10.3390/s21072328}
}



@Article{rs13071277,
AUTHOR = {Khosravi, Vahid and Ardejani, Faramarz Doulati and Gholizadeh, Asa and Saberioon, Mohammadmehdi},
TITLE = {Satellite Imagery for Monitoring and Mapping Soil Chromium Pollution in a Mine Waste Dump},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1277},
URL = {https://www.mdpi.com/2072-4292/13/7/1277},
ISSN = {2072-4292},
ABSTRACT = {Weathering and oxidation of sulphide minerals in mine wastes release toxic elements in surrounding environments. As an alternative to traditional sampling and chemical analysis methods, the capability of proximal and remote sensing techniques was investigated in this study to predict Chromium (Cr) concentration in 120 soil samples collected from a dumpsite in Sarcheshmeh copper mine, Iran. The samples’ mineralogy and Cr concentration were determined and were then subjected to laboratory reflectance spectroscopy in the range of Visible–Near Infrared–Shortwave Infrared (VNIR–SWIR: 350–2500 nm). The raw spectra were pre-processed using Savitzky-Golay First-Derivative (SG-FD) and Savitzky-Golay Second-Derivative (SG-SD) algorithms. The important wavelengths were determined using Partial Least Squares Regression (PLSR) coefficients and Genetic Algorithm (GA). Artificial Neural Networks (ANN), Stepwise Multiple Linear Regression (SMLR) and PLSR data mining methods were applied to the selected spectral variables to assess Cr concentration. The developed models were then applied to the selected bands of Aster, Hyperion, Sentinel-2A, and Landsat 8-OLI satellite images of the area. Afterwards, rasters obtained from the best prediction model were segmented using a binary fitness function. According to the outputs of the laboratory reflectance spectroscopy, the highest prediction accuracy was obtained using ANN applied to the SD pre-processed spectra with R2 = 0.91, RMSE = 8.73 mg/kg and RPD = 2.76. SD-ANN also showed an acceptable performance on mapping the spatial distribution of Cr using the ordinary kriging technique. Using satellite images, SD-SMLR provided the best prediction models with R2 values of 0.61 and 0.53 for Hyperion and Sentinel-2A, respectively. This led to the higher visual similarity of the segmented Hyperion and Sentinel-2A images with the Cr distribution map. This study’s findings indicated that applying the best prediction models obtained by spectroscopy to the selected wavebands of Hyperion and Sentinel-2A satellite imagery could be considered a promising technique for rapid, cost-effective and eco-friendly assessment of Cr concentration in highly heterogeneous mining areas.},
DOI = {10.3390/rs13071277}
}



@Article{electronics10070798,
AUTHOR = {Sánchez, José David Vega and Urquiza-Aguiar, Luis and Paredes Paredes, Martha Cecilia},
TITLE = {Fading Channel Models for mm-Wave Communications},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {798},
URL = {https://www.mdpi.com/2079-9292/10/7/798},
ISSN = {2079-9292},
ABSTRACT = {A realistic performance assessment of any wireless communication system requires the use of a fading channel model that reflects its main characteristics. The traditional Rayleigh and Nakagami-m models have been (and still are) the basis of most theoretical research on wireless technologies today, even for emerging technologies, such as millimeter-wave communications (mm-Wave). In this article, we show that the fluctuating multiple-ray (FMR) and κ-μ shadowed models had a better fit (i.e., lowest mean square error statistical test) to field measurements in outdoor environments at 28 GHz than the conventional channel models. Therefore, these generalized models are feasible alternatives that can be used as a benchmark when evaluating communication performance in mm-Wave scenarios.},
DOI = {10.3390/electronics10070798}
}



@Article{rs13071279,
AUTHOR = {Li, Tong and Cui, Lizhen and Xu, Zhihong and Hu, Ronghai and Joshi, Pawan K. and Song, Xiufang and Tang, Li and Xia, Anquan and Wang, Yanfen and Guo, Da and Zhu, Jiapei and Hao, Yanbin and Song, Lan and Cui, Xiaoyong},
TITLE = {Quantitative Analysis of the Research Trends and Areas in Grassland Remote Sensing: A Scientometrics Analysis of Web of Science from 1980 to 2020},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1279},
URL = {https://www.mdpi.com/2072-4292/13/7/1279},
ISSN = {2072-4292},
ABSTRACT = {Grassland remote sensing (GRS) is an important research topic that applies remote sensing technology to grassland ecosystems, reflects the number of grassland resources and grassland health promptly, and provides inversion information used in sustainable development management. A scientometrics analysis based on Science Citation Index-Expanded (SCI-E) was performed to understand the research trends and areas of focus in GRS research studies. A total of 2692 papers related to GRS research studies and 82,208 references published from 1980 to 2020 were selected as the research objects. A comprehensive overview of the field based on the annual documents, research areas, institutions, influential journals, core authors, and temporal trends in keywords were presented in this study. The results showed that the annual number of documents increased exponentially, and more than 100 papers were published each year since 2010. Remote sensing, environmental sciences, and ecology were the most popular Web of Science research areas. The journal Remote Sensing was one of the most popular for researchers to publish documents and shows high development and publishing potential in GRS research studies. The institution with the greatest research documents and most citations was the Chinese Academy of Sciences. Guo X.L., Hill M.J., and Zhang L. were the most productive authors across the 40-year study period in terms of the number of articles published. Seven clusters of research areas were identified that generated contributions to this topic by keyword co-occurrence analysis. We also detected 17 main future directions of GRS research studies by document co-citation analysis. Emerging or underutilized methodologies and technologies, such as unmanned aerial systems (UASs), cloud computing, and deep learning, will continue to further enhance GRS research in the process of achieving sustainable development goals. These results can help related researchers better understand the past and future of GRS research studies.},
DOI = {10.3390/rs13071279}
}



@Article{modelling2020011,
AUTHOR = {Grekhov, Andrii and Kondratiuk, Vasyl and Ilnytska, Svitlana},
TITLE = {Data Traffic Modeling in RPAS/UAV Networks with Different Architectures},
JOURNAL = {Modelling},
VOLUME = {2},
YEAR = {2021},
NUMBER = {2},
PAGES = {210--223},
URL = {https://www.mdpi.com/2673-3951/2/2/11},
ISSN = {2673-3951},
ABSTRACT = {Deploying of Fifth Generation and Beyond Fifth Generation (5G/B5G) wireless networks will require wider coverage, flexible connectivity, low latency, support for a large number of user devices, and more bandwidth. This article explores the paradigm that Remotely Piloted Air Systems (RPASs) or Unmanned Aerial Vehicles (UAVs) are integrated as a communication platform with cellular networks using radio access. It is important to know the possibilities and ways of such integration for effective interaction with RPASs. This paper studies the issues of ensuring the required Quality of Service (QoS) during heavy traffic and the choice of necessary data transmission modes for this. Models of RPAS communication channels with different architectures were created. The relationships between models’ performance and traffic parameters were obtained using the NetCracker Professional 4.1 software. The dependencies of the Average Utilization (AU) on the Transaction Size (TS) were analyzed. The effects of different bandwidths and the Bit Error Rate (BER) were studied. The traffic characteristics in all models were compared.},
DOI = {10.3390/modelling2020011}
}



@Article{s21072363,
AUTHOR = {Campos, Javier and García-Ruíz, Francisco and Gil, Emilio},
TITLE = {Assessment of Vineyard Canopy Characteristics from Vigour Maps Obtained Using UAV and Satellite Imagery},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {2363},
URL = {https://www.mdpi.com/1424-8220/21/7/2363},
PubMedID = {33805351},
ISSN = {1424-8220},
ABSTRACT = {Canopy characterisation is a key factor for the success and efficiency of the pesticide application process in vineyards. Canopy measurements to determine the optimal volume rate are currently conducted manually, which is time-consuming and limits the adoption of precise methods for volume rate selection. Therefore, automated methods for canopy characterisation must be established using a rapid and reliable technology capable of providing precise information about crop structure. This research providedregression models for obtaining canopy characteristics of vineyards from unmanned aerial vehicle (UAV) and satellite images collected in three significant growth stages. Between 2018 and 2019, a total of 1400 vines were characterised manually and remotely using a UAV and a satellite-based technology. The information collected from the sampled vines was analysed by two different procedures. First, a linear relationship between the manual and remote sensing data was investigated considering every single vine as a data point. Second, the vines were clustered based on three vigour levels in the parcel, and regression models were fitted to the average values of the ground-based and remote sensing-estimated canopy parameters. Remote sensing could detect the changes in canopy characteristics associated with vegetation growth. The combination of normalised differential vegetation index (NDVI) and projected area extracted from the UAV images is correlated with the tree row volume (TRV) when raw point data were used. This relationship was improved and extended to canopy height, width, leaf wall area, and TRV when the data were clustered. Similarly, satellite-based NDVI yielded moderate coefficients of determination for canopy width with raw point data, and for canopy width, height, and TRV when the vines were clustered according to the vigour. The proposed approach should facilitate the estimation of canopy characteristics in each area of a field using a cost-effective, simple, and reliable technology, allowing variable rate application in vineyards.},
DOI = {10.3390/s21072363}
}



@Article{rs13071301,
AUTHOR = {Lee, Cheonjae and de Vries, Walter Timo},
TITLE = {Testing and Validating the Suitability of Geospatially Informed Proxies on Land Tenure in North Korea for Korean (Re-)Unification},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1301},
URL = {https://www.mdpi.com/2072-4292/13/7/1301},
ISSN = {2072-4292},
ABSTRACT = {The role of remote sensing data in detecting, estimating, and monitoring socioeconomic status (SES) such as quality of life dimensions and sustainable development prospects has received increased attention. Geospatial data has emerged as powerful source of information for enabling both socio-technical assessment and socio-legal analysis in land administration domain. In the context of Korean (re-)unification, there is a notable paucity of evidence how to identify unknowns in North Korea. The main challenge is the lack of complete and adequate information when it comes to clarifying unknown land tenure relations and land governance arrangements. Deriving informative land tenure relations from geospatial data in line with socio-economic land attributes is currently the most innovative approach. In-close and in-depth investigations of validating the suitability of a set of geospatially informed proxies combining multiple values were taken into consideration, as were the forms of knowledge co-production. Thus, the primary aim is to provide empirical evidence of whether proposed proxies are scientifically valid, policy-relevant, and socially robust. We revealed differences in the distributions of agreements relating to land ownership and land transfer rights identification among scientists, bureaucrats, and stakeholders. Moreover, we were able to measure intrinsic, contextual, representational, and accessibility attributes of information quality regarding the associations between earth observation (EO) data and land tenure relations in North Korea from a number of different viewpoints. This paper offers valuable insights into new techniques for validating suitability of EO data proxies in the land administration domain off the reliance on conventional practices formed and customized to the specific artefacts and guidelines of the remote sensing community.},
DOI = {10.3390/rs13071301}
}



@Article{s21072385,
AUTHOR = {Jasinski, Tomasz and Brooker, Graham and Antipov, Irina},
TITLE = {W-Band Multi-Aspect High Resolution Range Profile Radar Target Classification Using Support Vector Machines},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {2385},
URL = {https://www.mdpi.com/1424-8220/21/7/2385},
PubMedID = {33808183},
ISSN = {1424-8220},
ABSTRACT = {Millimeter-wave (W-band) radar measurements were taken for two maritime targets instrumented with attitude and heading reference systems (AHRSs) in a littoral environment with the aim of developing a multiaspect classifier. The focus was on resource-limited implementations such as short-range, tactical, unmanned aircraft systems (UASs) and dealing with limited and imbalanced datasets. Radar imaging and preprocessing consisted of recording high-resolution range profiles (HRRPs) and performing range alignment using peak detection and fast Fourier transforms (FFTs). HRRPs were used because of their simplicity, reliability, and speed. The features used were fixed-length, frequency domain range profiles. Two linear support vector machine (SVM)-based classifiers were developed which both yielded excellent results in their general forms and were simple to implement. The first approach utilized the positive predictive value (PPV) and negative predictive value (NPV) statistics of the SVM directly to generate target probabilities and consequently determine the optimal aspect transitions for classification. The second approach used the Kolmogorov–Smirnov test for dimensionality reduction, followed by concatenating feature vectors across several aspects. The latter approach is particularly well-suited to resource-constrained scenarios, potentially allowing for retraining and updating in the field.},
DOI = {10.3390/s21072385}
}



@Article{rs13071311,
AUTHOR = {Xu, Danqing and Wu, Yiquan},
TITLE = {FE-YOLO: A Feature Enhancement Network for Remote Sensing Target Detection},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1311},
URL = {https://www.mdpi.com/2072-4292/13/7/1311},
ISSN = {2072-4292},
ABSTRACT = {In the past few decades, target detection from remote sensing images gained from aircraft or satellites has become one of the hottest topics. However, the existing algorithms are still limited by the detection of small remote sensing targets. Benefiting from the great development of computing power, deep learning has also made great breakthroughs. Due to a large number of small targets and complexity of background, the task of remote sensing target detection is still a challenge. In this work, we establish a series of feature enhancement modules for the network based on YOLO (You Only Look Once) -V3 to improve the performance of feature extraction. Therefore, we term our proposed network as FE-YOLO. In addition, to realize fast detection, the original Darknet-53 was simplified. Experimental results on remote sensing datasets show that our proposed FE-YOLO performs better than other state-of-the-art target detection models.},
DOI = {10.3390/rs13071311}
}



@Article{rs13071327,
AUTHOR = {Tian, Ling and Cao, Yu and He, Bokun and Zhang, Yifan and He, Chu and Li, Deshi},
TITLE = {Image Enhancement Driven by Object Characteristics and Dense Feature Reuse Network for Ship Target Detection in Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1327},
URL = {https://www.mdpi.com/2072-4292/13/7/1327},
ISSN = {2072-4292},
ABSTRACT = {As the application scenarios of remote sensing imagery (RSI) become richer, the task of ship detection from an overhead perspective is of great significance. Compared with traditional methods, the use of deep learning ideas has more prospects. However, the Convolutional Neural Network (CNN) has poor resistance to sample differences in detection tasks, and the huge differences in the image environment, background, and quality of RSIs affect the performance for target detection tasks; on the other hand, upsampling or pooling operations result in the loss of detailed information in the features, and the CNN with outstanding results are often accompanied by a high computation and a large amount of memory storage. Considering the characteristics of ship targets in RSIs, this study proposes a detection framework combining an image enhancement module with a dense feature reuse module: (1) drawing on the ideas of the generative adversarial network (GAN), we designed an image enhancement module driven by object characteristics, which improves the quality of the ship target in the images while augmenting the training set; (2) the intensive feature extraction module was designed to integrate low-level location information and high-level semantic information of different resolutions while minimizing the computation, which can improve the efficiency of feature reuse in the network; (3) we introduced the receptive field expansion module to obtain a wider range of deep semantic information and enhance the ability to extract features of targets were at different sizes. Experiments were carried out on two types of ship datasets, optical RSI and Synthetic Aperture Radar (SAR) images. The proposed framework was implemented on classic detection networks such as You Only Look Once (YOLO) and Mask-RCNN. The experimental results verify the effectiveness of the proposed method.},
DOI = {10.3390/rs13071327}
}



@Article{s21072407,
AUTHOR = {You, Hojun and Kim, Dongsu},
TITLE = {Development of an Image Registration Technique for Fluvial Hyperspectral Imagery Using an Optical Flow Algorithm},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {2407},
URL = {https://www.mdpi.com/1424-8220/21/7/2407},
PubMedID = {33807293},
ISSN = {1424-8220},
ABSTRACT = {Fluvial remote sensing has been used to monitor diverse riverine properties through processes such as river bathymetry and visual detection of suspended sediment, algal blooms, and bed materials more efficiently than laborious and expensive in-situ measurements. Red–green–blue (RGB) optical sensors have been widely used in traditional fluvial remote sensing. However, owing to their three confined bands, they rely on visual inspection for qualitative assessments and are limited to performing quantitative and accurate monitoring. Recent advances in hyperspectral imaging in the fluvial domain have enabled hyperspectral images to be geared with more than 150 spectral bands. Thus, various riverine properties can be quantitatively characterized using sensors in low-altitude unmanned aerial vehicles (UAVs) with a high spatial resolution. Many efforts are ongoing to take full advantage of hyperspectral band information in fluvial research. Although geo-referenced hyperspectral images can be acquired for satellites and manned airplanes, few attempts have been made using UAVs. This is mainly because the synthesis of line-scanned images on top of image registration using UAVs is more difficult owing to the highly sensitive and heavy image driven by dense spatial resolution. Therefore, in this study, we propose a practical technique for achieving high spatial accuracy in UAV-based fluvial hyperspectral imaging through efficient image registration using an optical flow algorithm. Template matching algorithms are the most common image registration technique in RGB-based remote sensing; however, they require many calculations and can be error-prone depending on the user, as decisions regarding various parameters are required. Furthermore, the spatial accuracy of this technique needs to be verified, as it has not been widely applied to hyperspectral imagery. The proposed technique resulted in an average reduction of spatial errors by 91.9%, compared to the case where the image registration technique was not applied, and by 78.7% compared to template matching.},
DOI = {10.3390/s21072407}
}



@Article{s21072416,
AUTHOR = {Wang, Fei and Liu, Zhendong and Zhu, Hongchun and Wu, Pengda and Li, Chengming},
TITLE = {An Improved Method for Stable Feature Points Selection in Structure-from-Motion Considering Image Semantic and Structural Characteristics},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {2416},
URL = {https://www.mdpi.com/1424-8220/21/7/2416},
PubMedID = {33915845},
ISSN = {1424-8220},
ABSTRACT = {Feature matching plays a crucial role in the process of 3D reconstruction based on the structure from motion (SfM) technique. For a large collection of oblique images, feature matching is one of the most time-consuming steps, and the matching result directly affects the accuracy of subsequent tasks. Therefore, how to extract the reasonable feature points robustly and efficiently to improve the matching speed and quality has received extensive attention from scholars worldwide. Most studies perform quantitative feature point selection based on image Difference-of-Gaussian (DoG) pyramids in practice. However, the stability and spatial distribution of feature points are not considered enough, resulting in selected feature points that may not adequately reflect the scene structures and cannot guarantee the matching rate and the aerial triangulation accuracy. To address these issues, an improved method for stable feature point selection in SfM considering image semantic and structural characteristics is proposed. First, the visible-band difference vegetation index is used to identify the vegetation areas from oblique images, and the line feature in the image is extracted by the optimized line segment detector algorithm. Second, the feature point two-tuple classification model is established, in which the vegetation area recognition result is used as the semantic constraint, the line feature extraction result is used as the structural constraint, and the feature points are divided into three types. Finally, a progressive selection algorithm for feature points is proposed, in which feature points in the DoG pyramid are selected by classes and levels until the number of feature points is satisfied. Oblique images of a 40-km2 area in Dongying city, China, were used for validation. The experimental results show that compared to the state-of-the-art method, the method proposed in this paper not only effectively reduces the number of feature points but also better reflects the scene structure. At the same time, the average reprojection error of the aerial triangulation decrease by 20%, the feature point matching rate increase by 3%, the selected feature points are more stable and reasonable.},
DOI = {10.3390/s21072416}
}



@Article{agronomy11040667,
AUTHOR = {Araújo, Sara Oleiro and Peres, Ricardo Silva and Barata, José and Lidon, Fernando and Ramalho, José Cochicho},
TITLE = {Characterising the Agriculture 4.0 Landscape—Emerging Trends, Challenges and Opportunities},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {667},
URL = {https://www.mdpi.com/2073-4395/11/4/667},
ISSN = {2073-4395},
ABSTRACT = {Investment in technological research is imperative to stimulate the development of sustainable solutions for the agricultural sector. Advances in Internet of Things, sensors and sensor networks, robotics, artificial intelligence, big data, cloud computing, etc. foster the transition towards the Agriculture 4.0 era. This fourth revolution is currently seen as a possible solution for improving agricultural growth, ensuring the future needs of the global population in a fair, resilient and sustainable way. In this context, this article aims at characterising the current Agriculture 4.0 landscape. Emerging trends were compiled using a semi-automated process by analysing relevant scientific publications published in the past ten years. Subsequently, a literature review focusing these trends was conducted, with a particular emphasis on their applications in real environments. From the results of the study, some challenges are discussed, as well as opportunities for future research. Finally, a high-level cloud-based IoT architecture is presented, serving as foundation for designing future smart agricultural systems. It is expected that this work will positively impact the research around Agriculture 4.0 systems, providing a clear characterisation of the concept along with guidelines to assist the actors in a successful transition towards the digitalisation of the sector.},
DOI = {10.3390/agronomy11040667}
}



@Article{rs13071341,
AUTHOR = {Appeltans, Simon and Pieters, Jan G. and Mouazen, Abdul M.},
TITLE = {Detection of Leek Rust Disease under Field Conditions Using Hyperspectral Proximal Sensing and Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1341},
URL = {https://www.mdpi.com/2072-4292/13/7/1341},
ISSN = {2072-4292},
ABSTRACT = {Rust disease is an important problem for leek cultivation worldwide. It reduces market value and in extreme cases destroys the entire harvest. Farmers have to resort to periodical full-field fungicide applications to prevent the spread of disease, once every 1 to 5 weeks, depending on the cultivar and weather conditions. This implies an economic cost for the farmer and an environmental cost for society. Hyperspectral sensors have been extensively used to address this issue in research, but their application in the field has been limited to a relatively low number of crops, excluding leek, due to the high investment costs and complex data gathering and analysis associated with these sensors. To fill this gap, a methodology was developed for detecting leek rust disease using hyperspectral proximal sensing data combined with supervised machine learning. First, a hyperspectral library was constructed containing 43,416 spectra with a waveband range of 400–1000 nm, measured under field conditions. Then, an extensive evaluation of 11 common classifiers was performed using the scikit-learn machine learning library in Python, combined with a variety of wavelength selection techniques and preprocessing strategies. The best performing model was a (linear) logistic regression model that was able to correctly classify rust disease with an accuracy of 98.14%, using reflectance values at 556 and 661 nm, combined with the value of the first derivative at 511 nm. This model was used to classify unlabelled hyperspectral images, confirming that the model was able to accurately classify leek rust disease symptoms. It can be concluded that the results in this work are an important step towards the mapping of leek rust disease, and that future research is needed to overcome certain challenges before variable rate fungicide applications can be adopted against leek rust disease.},
DOI = {10.3390/rs13071341}
}



@Article{rs13071344,
AUTHOR = {Li, Changlong and Li, Zengyuan and Gao, Zhihai and Sun, Bin},
TITLE = {Estimation of Evapotranspiration in Sparse Vegetation Areas by Applying an Optimized Two-Source Model},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1344},
URL = {https://www.mdpi.com/2072-4292/13/7/1344},
ISSN = {2072-4292},
ABSTRACT = {Evapotranspiration (ET) is an important part of the water, carbon, and energy cycles in ecosystems, especially in the drylands. However, due to the particularity of sparse vegetation, the estimation accuracy of ET has been relatively low in the drylands. Therefore, based on the dry climate and sparse vegetation distribution characteristics of the drylands, this study optimized the core algorithms (canopy boundary resistance, aerodynamic resistance, and sparse vegetation coverage) and explored an ET estimation method in the Shuttleworth–Wallace two-layer model (SW model). Then, the Beijing–Tianjin sandstorm source region (BTSSR) was used as the study area to evaluate the applicability of the improved model in the drylands. Results show that: (1) The R2 value of the improved model results was increased by 1.4 and the RMSE was reduced by 1.9 mm, especially in extreme value regions of ET (maximum or minimum). (2) Regardless of the spatial distribution and seasonal changes of the ET (63–790 mm), the improved ET estimation model could accurately capture the differences. Furtherly, the different vegetation regions could stand for the different climate regions to a certain extent. The accuracy of the optimized model was higher in the semi-arid region (R2 = 0.92 and 0.93), while the improved model had the best improvement effect in the arid region, with R2 increasing by 0.12. (3) Precipitation was the decisive factor affecting vegetation transpiration and ET, with R2 value for both exceeding 0.9. The effect of vegetation coverage (VC) was less. This method is expected to provide a more accurate and adaptable model for the estimation of ET in the drylands.},
DOI = {10.3390/rs13071344}
}



@Article{rs13071343,
AUTHOR = {Li, Bonan and Good, Stephen P. and URycki, Dawn R.},
TITLE = {The Value of L-Band Soil Moisture and Vegetation Optical Depth Estimates in the Prediction of Vegetation Phenology},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1343},
URL = {https://www.mdpi.com/2072-4292/13/7/1343},
ISSN = {2072-4292},
ABSTRACT = {Vegetation phenology is a key ecosystem characteristic that is sensitive to environmental conditions. Here, we examined the utility of soil moisture (SM) and vegetation optical depth (VOD) observations from NASA’s L-band Soil Moisture Active Passive (SMAP) mission for the prediction of leaf area index (LAI), a common metric of canopy phenology. We leveraged mutual information theory to determine whether SM and VOD contain information about the temporal dynamics of LAI that is not contained in traditional LAI predictors (i.e., precipitation, temperature, and radiation) and known LAI climatology. We found that adding SMAP SM and VOD to multivariate non-linear empirical models to predict daily LAI anomalies improved model fit and reduced error by 5.2% compared with models including only traditional LAI predictors and LAI climatology (average R2 = 0.22 vs. 0.15 and unbiased root mean square error [ubRMSE] = 0.130 vs. 0.137 for cross-validated models with and without SM and VOD, respectively). SMAP SM and VOD made the more improvement in model fit in grasslands (R2 = 0.24 vs. 0.16 and ubRMSE = 0.118 vs. 0.126 [5.7% reduction] for models with and without SM and VOD, respectively); model predictions were least improved in shrublands. Analysis of feature importance indicates that LAI climatology and temperature were overall the two most informative variables for LAI anomaly prediction. SM was more important in drier regions, whereas VOD was consistently the second least important factor. Variations in total LAI were mostly explained by local daily LAI climatology. On average, the R2s and ubRMSE of total LAI predictions by the traditional drivers and its climatology are 0.81 and 0.137, respectively. Adding SMAP SM and VOD to these existing predictors improved the R2s to 0.83 (0.02 improvement in R2s) and reduced the ubRMSE to 0.13 (5.2% reduction). Though these improvements were modest on average, in locations where LAI climatology is not reflective of LAI dynamics and anomalies are larger, we find SM and VOD to be considerably more useful for LAI prediction. Overall, we find that L-band SM and VOD observations can be useful for prediction of LAI, though the informational contribution varies with land cover and environmental conditions.},
DOI = {10.3390/rs13071343}
}



@Article{rs13071353,
AUTHOR = {Neuwirthová, Eva and Kuusk, Andres and Lhotáková, Zuzana and Kuusk, Joel and Albrechtová, Jana and Hallik, Lea},
TITLE = {Leaf Age Matters in Remote Sensing: Taking Ground Truth for Spectroscopic Studies in Hemiboreal Deciduous Trees with Continuous Leaf Formation},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1353},
URL = {https://www.mdpi.com/2072-4292/13/7/1353},
ISSN = {2072-4292},
ABSTRACT = {We examined the seasonal changes in biophysical, anatomical, and optical traits of young leaves, formed throughout the vegetative season due to sylleptic growth, and mature leaves formed by proleptic growth in spring. Leaf developmental categories contribute to the top-of-canopy reflectance and should be considered when taking ground truth for remote sensing studies (RS). Deciduous tree species, Betula pendula, Populus tremula, and Alnus incana, were sampled from May to October 2018 in an Estonian hemiboreal forest. Chlorophyll and carotenoid content were detected biochemically; leaf anatomical traits (leaf, palisade, and spongy mesophyll thickness) were measured on leaf cross-sections; leaf reflectance was measured by a spectroradiometer with an integrating sphere (350–2500 nm). Biophysical and anatomical leaf traits were related to 64 vegetation indices (VIs). Linear models based on VIs for all tested leaf traits were more robust if both juvenile and mature leaves were included. This study provides information on which VIs are interchangeable or independent. Pigment and leaf thickness sensitive indices formed PC1; water and structural trait related VIs formed an independent group associated with PC3. Type of growth and leaf age could affect the validation of biophysical and anatomical leaf trait retrieval from the optical signal. It is, therefore, necessary to sample both leaf developmental categories—young and mature—in RS, especially if sampling is only once within the vegetation season.},
DOI = {10.3390/rs13071353}
}



@Article{rs13071359,
AUTHOR = {Vélez-Nicolás, Mercedes and García-López, Santiago and Barbero, Luis and Ruiz-Ortiz, Verónica and Sánchez-Bellón, Ángel},
TITLE = {Applications of Unmanned Aerial Systems (UASs) in Hydrology: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1359},
URL = {https://www.mdpi.com/2072-4292/13/7/1359},
ISSN = {2072-4292},
ABSTRACT = {In less than two decades, UASs (unmanned aerial systems) have revolutionized the field of hydrology, bridging the gap between traditional satellite observations and ground-based measurements and allowing the limitations of manned aircraft to be overcome. With unparalleled spatial and temporal resolutions and product-tailoring possibilities, UAS are contributing to the acquisition of large volumes of data on water bodies, submerged parameters and their interactions in different hydrological contexts and in inaccessible or hazardous locations. This paper provides a comprehensive review of 122 works on the applications of UASs in surface water and groundwater research with a purpose-oriented approach. Concretely, the review addresses: (i) the current applications of UAS in surface and groundwater studies, (ii) the type of platforms and sensors mainly used in these tasks, (iii) types of products generated from UAS-borne data, (iv) the associated advantages and limitations, and (v) knowledge gaps and future prospects of UASs application in hydrology. The first aim of this review is to serve as a reference or introductory document for all researchers and water managers who are interested in embracing this novel technology. The second aim is to unify in a single document all the possibilities, potential approaches and results obtained by different authors through the implementation of UASs.},
DOI = {10.3390/rs13071359}
}



@Article{s21072445,
AUTHOR = {Lluvia, Iker and Lazkano, Elena and Ansuategi, Ander},
TITLE = {Active Mapping and Robot Exploration: A Survey},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {2445},
URL = {https://www.mdpi.com/1424-8220/21/7/2445},
PubMedID = {33918107},
ISSN = {1424-8220},
ABSTRACT = {Simultaneous localization and mapping responds to the problem of building a map of the environment without any prior information and based on the data obtained from one or more sensors. In most situations, the robot is driven by a human operator, but some systems are capable of navigating autonomously while mapping, which is called native simultaneous localization and mapping. This strategy focuses on actively calculating the trajectories to explore the environment while building a map with a minimum error. In this paper, a comprehensive review of the research work developed in this field is provided, targeting the most relevant contributions in indoor mobile robotics.},
DOI = {10.3390/s21072445}
}



@Article{s21072447,
AUTHOR = {Park, Jonghyuk and Park, Jonghun and Shin, Dongmin and Choi, Yerim},
TITLE = {A BCI Based Alerting System for Attention Recovery of UAV Operators},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {2447},
URL = {https://www.mdpi.com/1424-8220/21/7/2447},
PubMedID = {33918116},
ISSN = {1424-8220},
ABSTRACT = {As unmanned aerial vehicles have become popular, the number of accidents caused by an operator’s inattention have increased. To prevent such accidents, the operator should maintain an attention status. However, limited research has been conducted on the brain-computer interface (BCI)-based system with an alerting module for the operator’s attention recovery of unmanned aerial vehicles. Therefore, we introduce a detection and alerting system that prevents an unmanned aerial vehicle operator from falling into inattention status by using the operator’s electroencephalogram signal. The proposed system consists of the following three components: a signal processing module, which collects and preprocesses an electroencephalogram signal of an operator, an inattention detection module, which determines whether an inattention status occurred based on the preprocessed signal, and, lastly, an alert providing module that presents stimulus to an operator when inattention is detected. As a result of evaluating the performance with a real-world dataset, it was shown that the proposed system successfully contributed to the recovery of operator attention in the evaluating dataset, although statistical significance could not be established due to the small number of subjects.},
DOI = {10.3390/s21072447}
}



@Article{s21072458,
AUTHOR = {Verde, Paula and Díez-González, Javier and Ferrero-Guillén, Rubén and Martínez-Gutiérrez, Alberto and Perez, Hilde},
TITLE = {Memetic Chains for Improving the Local Wireless Sensor Networks Localization in Urban Scenarios},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {2458},
URL = {https://www.mdpi.com/1424-8220/21/7/2458},
PubMedID = {33918199},
ISSN = {1424-8220},
ABSTRACT = {Local Positioning Systems (LPS) have become an active field of research in the last few years. Their application in harsh environments for high-demanded accuracy applications is allowing the development of technological activities such as autonomous navigation, indoor localization, or low-level flights in restricted environments. LPS consists of ad-hoc deployments of sensors which meets the design requirements of each activity. Among LPS, those based on temporal measurements are attracting higher interest due to their trade-off among accuracy, robustness, availability, and costs. The Time Difference of Arrival (TDOA) is extended in the literature for LPS applications and consequently we perform, in this paper, an analysis of the optimal sensor deployment of this architecture for achieving practical results. This is known as the Node Location Problem (NLP) and has been categorized as NP-Hard. Therefore, heuristic solutions such as Genetic Algorithms (GA) or Memetic Algorithms (MA) have been applied in the literature for the NLP. In this paper, we introduce an adaptation of the so-called MA-Solis Wets-Chains (MA-SW-Chains) for its application in the large-scale discrete discontinuous optimization of the NLP in urban scenarios. Our proposed algorithm MA-Variable Neighborhood Descent-Chains (MA-VND-Chains) outperforms the GA and the MA of previous proposals for the NLP, improving the accuracy achieved by 17% and by 10% respectively for the TDOA architecture in the urban scenario introduced.},
DOI = {10.3390/s21072458}
}



@Article{app11073186,
AUTHOR = {Sahal, Radhya and Alsamhi, Saeed H. and Breslin, John G. and Brown, Kenneth N. and Ali, Muhammad Intizar},
TITLE = {Digital Twins Collaboration for Automatic Erratic Operational Data Detection in Industry 4.0},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {3186},
URL = {https://www.mdpi.com/2076-3417/11/7/3186},
ISSN = {2076-3417},
ABSTRACT = {Digital twin (DT) plays a pivotal role in the vision of Industry 4.0. The idea is that the real product and its virtual counterpart are twins that travel a parallel journey from design and development to production and service life. The intelligence that comes from DTs’ operational data supports the interactions between the DTs to pave the way for the cyber-physical integration of smart manufacturing. This paper presents a conceptual framework for digital twins collaboration to provide an auto-detection of erratic operational data by utilizing operational data intelligence in the manufacturing systems. The proposed framework provide an interaction mechanism to understand the DT status, interact with other DTs, learn from each other DTs, and share common semantic knowledge. In addition, it can detect the anomalies and understand the overall picture and conditions of the operational environments. Furthermore, the proposed framework is described in the workflow model, which breaks down into four phases: information extraction, change detection, synchronization, and notification. A use case of Energy 4.0 fault diagnosis for wind turbines is described to present the use of the proposed framework and DTs collaboration to identify and diagnose the potential failure, e.g., malfunctioning nodes within the energy industry.},
DOI = {10.3390/app11073186}
}



@Article{rs13071371,
AUTHOR = {Wang, Junshu and Yang, Yue and Chen, Yuan and Han, Yuxing},
TITLE = {LighterGAN: An Illumination Enhancement Method for Urban UAV Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1371},
URL = {https://www.mdpi.com/2072-4292/13/7/1371},
ISSN = {2072-4292},
ABSTRACT = {In unmanned aerial vehicle based urban observation and monitoring, the performance of computer vision algorithms is inevitably limited by the low illumination and light pollution caused degradation, therefore, the application image enhancement is a considerable prerequisite for the performance of subsequent image processing algorithms. Therefore, we proposed a deep learning and generative adversarial network based model for UAV low illumination image enhancement, named LighterGAN. The design of LighterGAN refers to the CycleGAN model with two improvements—attention mechanism and semantic consistency loss—having been proposed to the original structure. Additionally, an unpaired dataset that was captured by urban UAV aerial photography has been used to train this unsupervised learning model. Furthermore, in order to explore the advantages of the improvements, both the performance in the illumination enhancement task and the generalization ability improvement of LighterGAN were proven in the comparative experiments combining subjective and objective evaluations. In the experiments with five cutting edge image enhancement algorithms, in the test set, LighterGAN achieved the best results in both visual perception and PIQE (perception based image quality evaluator, a MATLAB build-in function, the lower the score, the higher the image quality) score of enhanced images, scores were 4.91 and 11.75 respectively, better than EnlightenGAN the state-of-the-art. In the enhancement of low illumination sub-dataset Y (containing 2000 images), LighterGAN also achieved the lowest PIQE score of 12.37, 2.85 points lower than second place. Moreover, compared with the CycleGAN, the improvement of generalization ability was also demonstrated. In the test set generated images, LighterGAN was 6.66 percent higher than CycleGAN in subjective authenticity assessment and 3.84 lower in PIQE score, meanwhile, in the whole dataset generated images, the PIQE score of LighterGAN is 11.67, 4.86 lower than CycleGAN.},
DOI = {10.3390/rs13071371}
}



@Article{rs13071373,
AUTHOR = {Raya-Sereno, María D. and Ortiz-Monasterio, J. Ivan and Alonso-Ayuso, María and Rodrigues, Francelino A. and Rodríguez, Arlet A. and González-Perez, Lorena and Quemada, Miguel},
TITLE = {High-Resolution Airborne Hyperspectral Imagery for Assessing Yield, Biomass, Grain N Concentration, and N Output in Spring Wheat},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1373},
URL = {https://www.mdpi.com/2072-4292/13/7/1373},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing allows fast assessment of crop monitoring over large areas; however, questions regarding uncertainty in crop parameter prediction and application to nitrogen (N) fertilization remain open. The objective of this study was to optimize of remote sensing spectral information for its application to grain yield (GY), biomass, grain N concentration (GNC), and N output assessment, and decision making on spring wheat fertilization. Spring wheat (Triticum turgidum L.) field experiments testing two tillage treatments, two irrigation levels and six N treatments were conducted in Northwest Mexico over four consecutive years. Hyperspectral images were acquired through 27 airborne flight campaigns. At harvest, GY, biomass, GNC and N output were determined. Spectral exploratory analysis was used to identify the best wavelength combinations, the most suitable vegetation indices (VIs) and the best growth stages to assess the agronomic variables. The relationship between the spectral information and the agronomic measurements was evaluated by the coefficient of determination (R2) and the root mean square error (RMSE). The ability of the indices to guide fertilizer recommendation was assessed through an error analysis based on the N sufficiency index. GY was better assessed from the end of flowering to the early milk stage by VIs based on the combination of bands from near infrared radiation/visible and from near infrared radiation/red-edge regions (R2 &gt; 0.6; RMSE &lt; 700 kg ha−1). N output was efficiently assessed by a combination of bands from near infrared radiation/red-edge at booting (R2 &gt; 0.7; RMSE &lt; 9 kg N ha−1). The GNC was better estimated by VIs combining bands in near infrared radiation/red-edge at early milk, but with great variability among the years studied. Some VIs were promising for guiding fertilizer recommendation for increasing GNC, but there was not a single index providing reliable recommendations every year. This study highlights the potential of remote sensing imagery to assess GY and N output in spring wheat, but the identification of GNC responsive sites needs to be improved.},
DOI = {10.3390/rs13071373}
}



@Article{buildings11040150,
AUTHOR = {Han, Dongyeob and Lee, Suk Bae and Song, Mihwa and Cho, Jun Sang},
TITLE = {Change Detection in Unmanned Aerial Vehicle Images for Progress Monitoring of Road Construction},
JOURNAL = {Buildings},
VOLUME = {11},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {150},
URL = {https://www.mdpi.com/2075-5309/11/4/150},
ISSN = {2075-5309},
ABSTRACT = {Currently, unmanned aerial vehicles are increasingly being used in various construction projects such as housing developments, road construction, and bridge maintenance. If a drone is used at a road construction site, elevation information and orthoimages can be generated to acquire the construction status quantitatively. However, the detection of detailed changes in the site owing to construction depends on visual video interpretation. This study develops a method for automatic detection of the construction area using multitemporal images and a deep learning method. First, a deep learning model was trained using images of the changing area as reference. Second, we obtained an effective application method by applying various parameters to the deep learning process. The application of the time-series images of a construction site to the selected deep learning model enabled more effective identification of the changed areas than the existing pixel-based change detection. The proposed method is expected to be very helpful in construction management by aiding in the development of smart construction technology.},
DOI = {10.3390/buildings11040150}
}



@Article{oceans2020018,
AUTHOR = {Collin, Antoine and Andel, Mark and Lecchini, David and Claudet, Joachim},
TITLE = {Mapping Sub-Metre 3D Land-Sea Coral Reefscapes Using Superspectral WorldView-3 Satellite Stereoimagery},
JOURNAL = {Oceans},
VOLUME = {2},
YEAR = {2021},
NUMBER = {2},
PAGES = {315--329},
URL = {https://www.mdpi.com/2673-1924/2/2/18},
ISSN = {2673-1924},
ABSTRACT = {Shallow coral reefs ensure a wide portfolio of ecosystem services, from fish provisioning to tourism, that support more than 500 million people worldwide. The protection and sustainable management of these pivotal ecosystems require fine-scale but large-extent mapping of their 3D composition. The sub-metre spaceborne imagery can neatly produce such an expected product using multispectral stereo-imagery. We built the first 3D land-sea coral reefscape mapping using the 0.3 m superspectral WorldView-3 stereo-imagery. An array of 13 land use/land cover and sea use/sea cover habitats were classified using sea-, ground- and air-truth data. The satellite-derived topography and bathymetry reached vertical accuracies of 1.11 and 0.89 m, respectively. The value added of the eight mid-infrared (MIR) channels specific to the WorldView-3 was quantified using the classification overall accuracy (OA). With no topobathymetry, the best combination included the eight-band optical (visible + near-infrared) and the MIR8, which boosted the basic blue-green-red OA by 9.58%. The classes that most benefited from this MIR information were the land use “roof” and land cover “soil” classes. The addition of the satellite-derived topobathymetry to the optical+MIR1 produced the best full combination, increasing the basic OA by 9.73%, and reinforcing the “roof” and “soil” distinction.},
DOI = {10.3390/oceans2020018}
}



@Article{rs13071391,
AUTHOR = {Fernandez-Beltran, Ruben and Baidar, Tina and Kang, Jian and Pla, Filiberto},
TITLE = {Rice-Yield Prediction with Multi-Temporal Sentinel-2 Data and 3D CNN: A Case Study in Nepal},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1391},
URL = {https://www.mdpi.com/2072-4292/13/7/1391},
ISSN = {2072-4292},
ABSTRACT = {Crop yield estimation is a major issue of crop monitoring which remains particularly challenging in developing countries due to the problem of timely and adequate data availability. Whereas traditional agricultural systems mainly rely on scarce ground-survey data, freely available multi-temporal and multi-spectral remote sensing images are excellent tools to support these vulnerable systems by accurately monitoring and estimating crop yields before harvest. In this context, we introduce the use of Sentinel-2 (S2) imagery, with a medium spatial, spectral and temporal resolutions, to estimate rice crop yields in Nepal as a case study. Firstly, we build a new large-scale rice crop database (RicePAL) composed by multi-temporal S2 and climate/soil data from the Terai districts of Nepal. Secondly, we propose a novel 3D Convolutional Neural Network (CNN) adapted to these intrinsic data constraints for the accurate rice crop yield estimation. Thirdly, we study the effect of considering different temporal, climate and soil data configurations in terms of the performance achieved by the proposed approach and several state-of-the-art regression and CNN-based yield estimation methods. The extensive experiments conducted in this work demonstrate the suitability of the proposed CNN-based framework for rice crop yield estimation in the developing country of Nepal using S2 data.},
DOI = {10.3390/rs13071391}
}



@Article{s21072534,
AUTHOR = {Doukhi, Oualid and Lee, Deok-Jin},
TITLE = {Deep Reinforcement Learning for End-to-End Local Motion Planning of Autonomous Aerial Robots in Unknown Outdoor Environments: Real-Time Flight Experiments},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {2534},
URL = {https://www.mdpi.com/1424-8220/21/7/2534},
PubMedID = {33916624},
ISSN = {1424-8220},
ABSTRACT = {Autonomous navigation and collision avoidance missions represent a significant challenge for robotics systems as they generally operate in dynamic environments that require a high level of autonomy and flexible decision-making capabilities. This challenge becomes more applicable in micro aerial vehicles (MAVs) due to their limited size and computational power. This paper presents a novel approach for enabling a micro aerial vehicle system equipped with a laser range finder to autonomously navigate among obstacles and achieve a user-specified goal location in a GPS-denied environment, without the need for mapping or path planning. The proposed system uses an actor–critic-based reinforcement learning technique to train the aerial robot in a Gazebo simulator to perform a point-goal navigation task by directly mapping the noisy MAV’s state and laser scan measurements to continuous motion control. The obtained policy can perform collision-free flight in the real world while being trained entirely on a 3D simulator. Intensive simulations and real-time experiments were conducted and compared with a nonlinear model predictive control technique to show the generalization capabilities to new unseen environments, and robustness against localization noise. The obtained results demonstrate our system’s effectiveness in flying safely and reaching the desired points by planning smooth forward linear velocity and heading rates.},
DOI = {10.3390/s21072534}
}



@Article{jmse9040385,
AUTHOR = {Kari, Raheleh and Steinert, Martin},
TITLE = {Human Factor Issues in Remote Ship Operations: Lesson Learned by Studying Different Domains},
JOURNAL = {Journal of Marine Science and Engineering},
VOLUME = {9},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {385},
URL = {https://www.mdpi.com/2077-1312/9/4/385},
ISSN = {2077-1312},
ABSTRACT = {The idea of remote controlling ships for operational and commercial uses has developed beyond concepts. Controlling and monitoring vessels from a distant location requires updating the concept and requirements of shore control centers (SCCs), where human operators control the fleet via cameras, GPS, and many other types of sensors. While remote ship operation promises to reduce operational and maintenance costs, while increasing loading capacity and safety, it also brings significant uncertainty related to both the human-machine and human-human interactions which will affect operations. Achieving safe, reliable, and efficient remote ship operations requires consideration of both technological, cultural, social and human factor aspects of the system. Indeed, operators will act as captain and crew remotely, from the SCC, introducing new types of hardware and software interactions. This paper provides an overview of human factor issues that may affect human-machine and human-human interactions in the course of remote ship operations. In doing so, the literature related to remote operations in the domains of shipping, aerial vehicles, cranes, train transportation, automobiles, and mining is reviewed. Findings revealed that human factor issues are likely to fall into 13 distinct groups based on the type of human interactions that take place in SCCs.},
DOI = {10.3390/jmse9040385}
}



@Article{cli9040058,
AUTHOR = {Ghaffarian, Saman and Emtehani, Sobhan},
TITLE = {Monitoring Urban Deprived Areas with Remote Sensing and Machine Learning in Case of Disaster Recovery},
JOURNAL = {Climate},
VOLUME = {9},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {58},
URL = {https://www.mdpi.com/2225-1154/9/4/58},
ISSN = {2225-1154},
ABSTRACT = {Rapid urbanization and increasing population in cities with a large portion of them settled in deprived neighborhoods, mostly defined as slum areas, have escalated inequality and vulnerability to natural disasters. As a result, monitoring such areas is essential to provide information and support decision-makers and urban planners, especially in case of disaster recovery. Here, we developed an approach to monitor the urban deprived areas over a four-year period after super Typhoon Haiyan, which struck Tacloban city, in the Philippines, in 2013, using high-resolution satellite images and machine learning methods. A Support Vector Machine classification method supported by a local binary patterns feature extraction model was initially performed to detect slum areas in the pre-disaster, just after/event, and post-disaster images. Afterward, a dense conditional random fields model was employed to produce the final slum areas maps. The developed method detected slum areas with accuracies over 83%. We produced the damage and recovery maps based on change analysis over the detected slum areas. The results revealed that most of the slum areas were reconstructed 4 years after Typhoon Haiyan, and thus, the city returned to the pre-existing vulnerability level.},
DOI = {10.3390/cli9040058}
}



@Article{agriengineering3020011,
AUTHOR = {Quino, Jannette and Maja, Joe Mari and Robbins, James and Fernandez, R. Thomas and Owen, James S. and Chappell, Matthew},
TITLE = {RFID and Drones: The Next Generation of Plant Inventory},
JOURNAL = {AgriEngineering},
VOLUME = {3},
YEAR = {2021},
NUMBER = {2},
PAGES = {168--181},
URL = {https://www.mdpi.com/2624-7402/3/2/11},
ISSN = {2624-7402},
ABSTRACT = {Collection of plant inventory (i.e., count, grade, plant size, yield) data is time-consuming, costly, and can be inaccurate. In response to increasing labor costs and shortages, there is an increased need for the adoption of more automated technologies by the nursery industry. Growers, small and large, are beginning to adopt technologies (e.g., plant spacing robots) that automate or augment certain operations, but greater strides must be taken to integrate next-generation technologies into these challenging unstructured agricultural environments. The main objective of this work is to demonstrate merging specific ground and aerial-based technologies (Radio Frequency Identification (RFID), and small Unmanned Aircraft System (sUAS)) into a holistic systems approach to address the specific need of moving toward automated on-demand plant inventory. This preliminary work focuses on evaluating different RFID tags with respect to their distance and orientation to the RFID reader. Fourteen different RFID tags, five distances (1.5 m, 3.0 m, 4.5 m, 6.0 m, and 7.6 m), and four tag orientations (the front of the tag (UP), back of the tag (DN), tag at sideways left (SL), and tag at sideways right (SR)) were assessed. Results showed that the tag upward orientation resulted in the highest scanning total for both the laboratory and field experiments. Two orientations (UP and SR) had significant effect on the scan total of tags. The distance between the reader and the tags at 1.5 m and 6.0 m did not significantly affect the scanning efficiency of the RFID system in horizontally fixed (p-value &gt; 0.05) position regardless of tags. Different tag designs also produced different scan totals. Overall, since most of the tags were scanned at least once (except for Tag 6F), it is a very promising technology for use in nursery inventory data acquisition. This work will create a unique inventory system for agriculture where locations of plants or animals will not present a barrier as the system can easily be mounted on a drone. Although these experiments are focused on inventory in plant nurseries, results for this work has potential for inventory management in other agricultural sectors.},
DOI = {10.3390/agriengineering3020011}
}



@Article{electronics10070868,
AUTHOR = {Martínez, Anselmo and Belmonte, Lidia M. and García, Arturo S. and Fernández-Caballero, Antonio and Morales, Rafael},
TITLE = {Facial Emotion Recognition from an Unmanned Flying Social Robot for Home Care of Dependent People},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {868},
URL = {https://www.mdpi.com/2079-9292/10/7/868},
ISSN = {2079-9292},
ABSTRACT = {This work is part of an ongoing research project to develop an unmanned flying social robot to monitor dependants at home in order to detect the person’s state and bring the necessary assistance. In this sense, this paper focuses on the description of a virtual reality (VR) simulation platform for the monitoring process of an avatar in a virtual home by a rotatory-wing autonomous unmanned aerial vehicle (UAV). This platform is based on a distributed architecture composed of three modules communicated through the message queue telemetry transport (MQTT) protocol: the UAV Simulator implemented in MATLAB/Simulink, the VR Visualiser developed in Unity, and the new emotion recognition (ER) system developed in Python. Using a face detection algorithm and a convolutional neural network (CNN), the ER System is able to detect the person’s face in the image captured by the UAV’s on-board camera and classify the emotion among seven possible ones (surprise; fear; happiness; sadness; disgust; anger; or neutral expression). The experimental results demonstrate the correct integration of this new computer vision module within the VR platform, as well as the good performance of the designed CNN, with around 85% in the F1-score, a mean of the precision and recall of the model. The developed emotion detection system can be used in the future implementation of the assistance UAV that monitors dependent people in a real environment, since the methodology used is valid for images of real people.},
DOI = {10.3390/electronics10070868}
}



@Article{ijgi10040229,
AUTHOR = {Dolapsaki, Maria Melina and Georgopoulos, Andreas},
TITLE = {Edge Detection in 3D Point Clouds Using Digital Images},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {229},
URL = {https://www.mdpi.com/2220-9964/10/4/229},
ISSN = {2220-9964},
ABSTRACT = {This paper presents an effective and semi-automated method for detecting 3D edges in 3D point clouds with the help of high-resolution digital images. The effort aims to contribute towards addressing the unsolved problem of automated production of vector drawings from 3D point clouds of cultural heritage objects. Edges are the simplest primitives to detect in an unorganized point cloud and an algorithm was developed to perform this task. The provided edges are defined and measured on 2D digital images of known orientation, and the algorithm determines the plane defined by the edge on the image and its perspective center. This is accomplished by applying suitable transformations to the image coordinates of the edge points based on the Analytical Geometry relationships and properties of planes in 3D space. This plane inevitably contains the 3D points of the edge in the point cloud. The algorithm then detects and isolates those points which define the edge in the world system. Finally, the goal is to reliably locate the points that describe the desired edge in their true position in the geodetic space, using several constraints. The algorithm is firstly investigated theoretically for its efficiency using simulation data and then assessed under real conditions and under different image orientations and lengths of the edge on the image. The results are presented and evaluated.},
DOI = {10.3390/ijgi10040229}
}



@Article{electronics10070872,
AUTHOR = {Sun, Yixin and Luo, Yusen and Chai, Xiaoyu and Zhang, Pengpeng and Zhang, Qian and Xu, Lizhang and Wei, Lele},
TITLE = {Double-Threshold Segmentation of Panicle and Clustering Adaptive Density Estimation for Mature Rice Plants Based on 3D Point Cloud},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {872},
URL = {https://www.mdpi.com/2079-9292/10/7/872},
ISSN = {2079-9292},
ABSTRACT = {Crop density estimation ahead of the combine harvester provides a valuable reference for operators to keep the feeding amount stable in agriculture production, and, as a consequence, guaranteeing the working stability and improving the operation efficiency. For the current method depending on LiDAR, it is difficult to extract individual plants for mature rice plants with luxuriant branches and leaves, as well as bent and intersected panicles. Therefore, this paper proposes a clustering adaptive density estimation method based on the constructed LiDAR measurement system and double-threshold segmentation. The Otsu algorithm is adopted to construct a double-threshold according to elevation and inflection intensity in different parts of the rice plant, after reducing noise through the statistical outlier removal (SOR) algorithm. For adaptively parameter adjustment of supervoxel clustering and mean-shift clustering during density estimation, the calculation relationship between influencing factors (including seed-point size and kernel-bandwidth size) and number of points are, respectively, deduced by analysis. The experiment result of density estimation proved the two clustering methods effective, with a Root Mean Square Error (RMSE) of 9.968 and 5.877, and a Mean Absolute Percent Error (MAPE) of 5.67% and 3.37%, and the average accuracy was more than 90% and 95%, respectively. This estimation method is of positive significance for crop density measurement and could lay the foundation for intelligent harvest.},
DOI = {10.3390/electronics10070872}
}



@Article{rs13081411,
AUTHOR = {Zhang, Yanchao and Yang, Wen and Sun, Ying and Chang, Christine and Yu, Jiya and Zhang, Wenbo},
TITLE = {Fusion of Multispectral Aerial Imagery and Vegetation Indices for Machine Learning-Based Ground Classification},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1411},
URL = {https://www.mdpi.com/2072-4292/13/8/1411},
ISSN = {2072-4292},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) are emerging and promising platforms for carrying different types of cameras for remote sensing. The application of multispectral vegetation indices for ground cover classification has been widely adopted and has proved its reliability. However, the fusion of spectral bands and vegetation indices for machine learning-based land surface investigation has hardly been studied. In this paper, we studied the fusion of spectral bands information from UAV multispectral images and derived vegetation indices for almond plantation classification using several machine learning methods. We acquired multispectral images over an almond plantation using a UAV. First, a multispectral orthoimage was generated from the acquired multispectral images using SfM (Structure from Motion) photogrammetry methods. Eleven types of vegetation indexes were proposed based on the multispectral orthoimage. Then, 593 data points that contained multispectral bands and vegetation indexes were randomly collected and prepared for this study. After comparing six machine learning algorithms (Support Vector Machine, K-Nearest Neighbor, Linear Discrimination Analysis, Decision Tree, Random Forest, and Gradient Boosting), we selected three (SVM, KNN, and LDA) to study the fusion of multi-spectral bands information and derived vegetation index for classification. With the vegetation indexes increased, the model classification accuracy of all three selected machine learning methods gradually increased, then dropped. Our results revealed that that: (1) spectral information from multispectral images can be used for machine learning-based ground classification, and among all methods, SVM had the best performance; (2) combination of multispectral bands and vegetation indexes can improve the classification accuracy comparing to only spectral bands among all three selected methods; (3) among all VIs, NDEGE, NDVIG, and NDVGE had consistent performance in improving classification accuracies, and others may reduce the accuracy. Machine learning methods (SVM, KNN, and LDA) can be used for classifying almond plantation using multispectral orthoimages, and fusion of multispectral bands with vegetation indexes can improve machine learning-based classification accuracy if the vegetation indexes are properly selected.},
DOI = {10.3390/rs13081411}
}



@Article{rs13081416,
AUTHOR = {Bao, Min and Chala Urgessa, Guyo and Xing, Mengdao and Han, Liang and Chen, Rui},
TITLE = {Toward More Robust and Real-Time Unmanned Aerial Vehicle Detection and Tracking via Cross-Scale Feature Aggregation Based on the Center Keypoint},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1416},
URL = {https://www.mdpi.com/2072-4292/13/8/1416},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicles (UAVs) play an essential role in various applications, such as transportation and intelligent environmental sensing. However, due to camera motion and complex environments, it can be difficult to recognize the UAV from its surroundings thus, traditional methods often miss detection of UAVs and generate false alarms. To address these issues, we propose a novel method for detecting and tracking UAVs. First, a cross-scale feature aggregation CenterNet (CFACN) is constructed to recognize the UAVs. CFACN is a free anchor-based center point estimation method that can effectively decrease the false alarm rate, the misdetection of small targets, and computational complexity. Secondly, the region of interest-scale-crop-resize (RSCR) method is utilized to merge CFACN and region-of-interest (ROI) CFACN (ROI-CFACN) further, in order to improve the accuracy at a lower computational cost. Finally, the Kalman filter is adopted to track the UAV. The effectiveness of our method is validated using a collected UAV dataset. The experimental results demonstrate that our methods can achieve higher accuracy with lower computational cost, being superior to BiFPN, CenterNet, YoLo, and their variants on the same dataset.},
DOI = {10.3390/rs13081416}
}



@Article{rs13081420,
AUTHOR = {Tang, Mingliang and Esmaeili, Kamran},
TITLE = {Heap Leach Pad Surface Moisture Monitoring Using Drone-Based Aerial Images and Convolutional Neural Networks: A Case Study at the El Gallo Mine, Mexico},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1420},
URL = {https://www.mdpi.com/2072-4292/13/8/1420},
ISSN = {2072-4292},
ABSTRACT = {An efficient metal recovery in heap leach operations relies on uniform distribution of leaching reagent solution over the heap leach pad surface. However, the current practices for heap leach pad (HLP) surface moisture monitoring often rely on manual inspection, which is labor-intensive, time-consuming, discontinuous, and intermittent. In order to complement the manual monitoring process and reduce the frequency of exposing technical manpower to the hazardous leaching reagent (e.g., dilute cyanide solution in gold leaching), this manuscript describes a case study of implementing an HLP surface moisture monitoring method based on drone-based aerial images and convolutional neural networks (CNNs). Field data collection was conducted on a gold HLP at the El Gallo mine, Mexico. A commercially available hexa-copter drone was equipped with one visible-light (RGB) camera and one thermal infrared sensor to acquire RGB and thermal images from the HLP surface. The collected data had high spatial and temporal resolutions. The high-quality aerial images were used to generate surface moisture maps of the HLP based on two CNN approaches. The generated maps provide direct visualization of the different moisture zones across the HLP surface, and such information can be used to detect potential operational issues related to distribution of reagent solution and to facilitate timely decision making in heap leach operations.},
DOI = {10.3390/rs13081420}
}



@Article{su13084115,
AUTHOR = {Budiman, Jaka and Bahrawi, Jarbou and Hidayatulloh, Asep and Almazroui, Mansour and Elhag, Mohamed},
TITLE = {Volumetric Quantification of Flash Flood Using Microwave Data on a Watershed Scale in Arid Environments, Saudi Arabia},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {4115},
URL = {https://www.mdpi.com/2071-1050/13/8/4115},
ISSN = {2071-1050},
ABSTRACT = {Actual flood mapping and quantification in an area provide valuable information for the stakeholder to prevent future losses. This study presents the actual flash flood quantification in Al-Lith Watershed, Saudi Arabia. The study is divided into two steps: first is actual flood mapping using remote sensing data, and the second is the flood volume calculation. Two Sentinel-1 images are processed to map the actual flood, i.e., image from 25 May 2018 (dry condition), and 24 November 2018 (peak flood condition). SNAP software is used for the flood mapping step. During SNAP processing, selecting the backscatter data representing the actual flood in an arid region is challenging. The dB range value from 7.23–14.22 is believed to represent the flood. In GIS software, the flood map result is converted into polygon to define the flood boundary. The flood boundary that is overlaid with Digital Elevation Map (DEM) is filled with the same elevation value. The Focal Statistics neighborhood method with three iterations is used to generate the flood surface elevation inside the flood boundary. The raster contains depth information is derived by subtraction of the flood surface elevation with DEM. Several steps are carried out to minimize the overcalculation outside the flood boundary. The flood volume can be derived by the multiplication of flood depth points with each cell size area. The flash flood volume in Al-Lith Watershed on 24 November 2018 is 155,507,439 m3. Validity checks are performed by comparing it with other studies, and the result shows that the number is reliable.},
DOI = {10.3390/su13084115}
}



@Article{rs13081424,
AUTHOR = {Terres de Lima, Lucas and Fernández-Fernández, Sandra and Gonçalves, João Francisco and Magalhães Filho, Luiz and Bernardes, Cristina},
TITLE = {Development of Tools for Coastal Management in Google Earth Engine: Uncertainty Bathtub Model and Bruun Rule},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1424},
URL = {https://www.mdpi.com/2072-4292/13/8/1424},
ISSN = {2072-4292},
ABSTRACT = {Sea-level rise is a problem increasingly affecting coastal areas worldwide. The existence of free and open-source models to estimate the sea-level impact can contribute to improve coastal management. This study aims to develop and validate two different models to predict the sea-level rise impact supported by Google Earth Engine (GEE)—a cloud-based platform for planetary-scale environmental data analysis. The first model is a Bathtub Model based on the uncertainty of projections of the sea-level rise impact module of TerrSet—Geospatial Monitoring and Modeling System software. The validation process performed in the Rio Grande do Sul coastal plain (S Brazil) resulted in correlations from 0.75 to 1.00. The second model uses the Bruun rule formula implemented in GEE and can determine the coastline retreat of a profile by creatting a simple vector line from topo-bathymetric data. The model shows a very high correlation (0.97) with a classical Bruun rule study performed in the Aveiro coast (NW Portugal). Therefore, the achieved results disclose that the GEE platform is suitable to perform these analysis. The models developed have been openly shared, enabling the continuous improvement of the code by the scientific community.},
DOI = {10.3390/rs13081424}
}



@Article{rs13081425,
AUTHOR = {Chan, Catherine and Nelson, Peter R. and Hayes, Daniel J. and Zhang, Yong-Jiang and Hall, Bruce},
TITLE = {Predicting Water Stress in Wild Blueberry Fields Using Airborne Visible and Near Infrared Imaging Spectroscopy},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1425},
URL = {https://www.mdpi.com/2072-4292/13/8/1425},
ISSN = {2072-4292},
ABSTRACT = {Water management and irrigation practices are persistent challenges for many agricultural systems, exacerbated by changing seasonal and weather patterns. The wild blueberry industry is at heightened susceptibility due to its unique growing conditions and uncultivated nature. Stress detection in agricultural fields can prompt management responses to mitigate detrimental conditions, including drought and disease. We assessed airborne spectral data accompanied by ground sampled water potential over three developmental stages of wild blueberries collected throughout the 2019 summer on two adjacent fields, one irrigated and one non-irrigated. Ground sampled leaves were collected in tandem to the hyperspectral image collection with an unoccupied aerial vehicle (UAV) and then measured for leaf water potential. Using methods in machine learning and statistical analysis, we developed models to determine irrigation status and water potential. Seven models were assessed in this study, with four used to process six hyperspectral cube images for analysis. These images were classified as irrigated or non-irrigated and estimated for water potential levels, resulting in an R2 of 0.62 and verified with a validation dataset. Further investigation relating imaging spectroscopy and water potential will be beneficial in understanding the dynamics between the two for future studies.},
DOI = {10.3390/rs13081425}
}



@Article{rs13081427,
AUTHOR = {Kanniah, Kasturi Devi and Kang, Chuen Siang and Sharma, Sahadev and Amir, A. Aldrie},
TITLE = {Remote Sensing to Study Mangrove Fragmentation and Its Impacts on Leaf Area Index and Gross Primary Productivity in the South of Peninsular Malaysia},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1427},
URL = {https://www.mdpi.com/2072-4292/13/8/1427},
ISSN = {2072-4292},
ABSTRACT = {Mangrove is classified as an important ecosystem along the shorelines of tropical and subtropical landmasses, which are being degraded at an alarming rate despite numerous international treaties having been agreed. Iskandar Malaysia (IM) is a fast-growing economic region in southern Peninsular Malaysia, where three Ramsar Sites are located. Since the beginning of the 21st century (2000–2019), a total loss of 2907.29 ha of mangrove area has been estimated based on medium-high resolution remote sensing data. This corresponds to an annual loss rate of 1.12%, which is higher than the world mangrove depletion rate. The causes of mangrove loss were identified as land conversion to urban, plantations, and aquaculture activities, where large mangrove areas were shattered into many smaller patches. Fragmentation analysis over the mangrove area shows a reduction in the mean patch size (from 105 ha to 27 ha) and an increase in the number of mangrove patches (130 to 402), edge, and shape complexity, where smaller and isolated mangrove patches were found to be related to the rapid development of IM region. The Moderate Resolution Imaging Spectro-radiometer (MODIS) Leaf Area Index (LAI) and Gross Primary Productivity (GPP) products were used to inspect the impact of fragmentation on the mangrove ecosystem process. The mean LAI and GPP of mangrove areas that had not undergone any land cover changes over the years showed an increase from 3.03 to 3.55 (LAI) and 5.81 g C m−2 to 6.73 g C m−2 (GPP), highlighting the ability of the mangrove forest to assimilate CO2 when it is not disturbed. Similarly, GPP also increased over the gained areas (from 1.88 g C m−2 to 2.78 g C m−2). Meanwhile, areas that lost mangroves, but replaced them with oil palm, had decreased mean LAI from 2.99 to 2.62. In fragmented mangrove patches an increase in GPP was recorded, and this could be due to the smaller patches (&lt;9 ha) and their edge effects where abundance of solar radiation along the edges of the patches may increase productivity. The impact on GPP due to fragmentation is found to rely on the type of land transformation and patch characteristics (size, edge, and shape complexity). The preservation of mangrove forests in a rapidly developing region such as IM is vital to ensure ecosystem, ecology, environment, and biodiversity conservation, in addition to providing economical revenue and supporting human activities.},
DOI = {10.3390/rs13081427}
}



@Article{rs13081428,
AUTHOR = {Marang, Ian J. and Filippi, Patrick and Weaver, Tim B. and Evans, Bradley J. and Whelan, Brett M. and Bishop, Thomas F. A. and Murad, Mohammed O. F. and Al-Shammari, Dhahi and Roth, Guy},
TITLE = {Machine Learning Optimised Hyperspectral Remote Sensing Retrieves Cotton Nitrogen Status},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1428},
URL = {https://www.mdpi.com/2072-4292/13/8/1428},
ISSN = {2072-4292},
ABSTRACT = {Hyperspectral imaging spectrometers mounted on unmanned aerial vehicle (UAV) can capture high spatial and spectral resolution to provide cotton crop nitrogen status for precision agriculture. The aim of this research was to explore machine learning use with hyperspectral datacubes over agricultural fields. Hyperspectral imagery was collected over a mature cotton crop, which had high spatial (~5.2 cm) and spectral (5 nm) resolution over the spectral range 475–925 nm that allowed discrimination of individual crop rows and field features as well as a continuous spectral range for calculating derivative spectra. The nominal reflectance and its derivatives clearly highlighted the different treatment blocks and were strongly related to N concentration in leaf and petiole samples, both in traditional vegetation indices (e.g., Vogelman 1, R2 = 0.8) and novel combinations of spectra (R2 = 0.85). The key hyperspectral bands identified were at the red-edge inflection point (695–715 nm). Satellite multispectral was compared against the UAV hyperspectral remote sensing’s performance by testing the ability of Sentinel MSI to predict N concentration using the bands in VIS-NIR spectral region. The Sentinel 2A Green band (B3; mid-point 559.8 nm) explained the same amount of variation in N as the hyperspectral data and more than the Sentinel Red Edge Point 1 (B5; mid-point 704.9 nm) with the lower 10 m resolution Green band reporting an R2 = 0.85, compared with the R2 = 0.78 of downscaled Sentinel Red Edge Point 1 at 5 m. The remaining Sentinel bands explained much lower variation (maximum was NIR at R2 = 0.48). Investigation of the red edge peak region in the first derivative showed strong promise with RIDAmid (R2 = 0.81) being the best index. The machine learning approach narrowed the range of bands required to investigate plant condition over this trial site, greatly improved processing time and reduced processing complexity. While Sentinel performed well in this comparison and would be useful in a broadacre crop production context, the impact of pixel boundaries relative to a region of interest and coarse spatial and temporal resolution impacts its utility in a research capacity.},
DOI = {10.3390/rs13081428}
}



@Article{en14082060,
AUTHOR = {Niemyjski, Olgierd and Zwierzchowski, Ryszard},
TITLE = {Impact of Water Temperature Changes on Water Loss Monitoring in Large District Heating Systems},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2060},
URL = {https://www.mdpi.com/1996-1073/14/8/2060},
ISSN = {1996-1073},
ABSTRACT = {This paper explores how water temperature changes in a district heating system (DHS) impact the monitoring of water losses. Water volume in DHS is constantly monitored, recorded, and replenished. The leakage and failure status of the DHS is often monitored through measuring the make-up water flow rate. In this paper, we present the methodology and a simplified model of the dynamics of the heating system operation, which was used to determine the profile of changes in the average temperature and density of water in the system. The mathematical model of the district heating network (DHN) was verified by comparing the results of simulation calculations, i.e., calculated values of the temperature of water returning to the heat source, with the measured values. Fluctuations in water temperature cause changes in the density and volume of water in the DHN, which affect the amount of water supplementing the system. This is particularly noticeable in a DHN with a large water volume. The study reports an analysis of measurement results of operating parameters of a major DHS in Poland (city of Szczecin). Hourly measurements were made of supply and return water temperature, water flow rate, and pressure throughout the whole of 2019. The water volume of the analyzed DHN is almost 42,000 m3 and the changes in water volume per hour are as high as 5 m3/h, representing 20–30% of the value of the make-up water flow rate. The analysis showed that systems for monitoring the tightness of the DHS and detecting failures, on the basis of measurements of the make-up water flow rate, should take into account the dynamics of water volume changes in the DHN.},
DOI = {10.3390/en14082060}
}



@Article{ijgi10040251,
AUTHOR = {Ludwig, Christina and Hecht, Robert and Lautenbach, Sven and Schorcht, Martin and Zipf, Alexander},
TITLE = {Mapping Public Urban Green Spaces Based on OpenStreetMap and Sentinel-2 Imagery Using Belief Functions},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {251},
URL = {https://www.mdpi.com/2220-9964/10/4/251},
ISSN = {2220-9964},
ABSTRACT = {Public urban green spaces are important for the urban quality of life. Still, comprehensive open data sets on urban green spaces are not available for most cities. As open and globally available data sets, the potential of Sentinel-2 satellite imagery and OpenStreetMap (OSM) data for urban green space mapping is high but limited due to their respective uncertainties. Sentinel-2 imagery cannot distinguish public from private green spaces and its spatial resolution of 10 m fails to capture fine-grained urban structures, while in OSM green spaces are not mapped consistently and with the same level of completeness everywhere. To address these limitations, we propose to fuse these data sets under explicit consideration of their uncertainties. The Sentinel-2 derived Normalized Difference Vegetation Index was fused with OSM data using the Dempster–Shafer theory to enhance the detection of small vegetated areas. The distinction between public and private green spaces was achieved using a Bayesian hierarchical model and OSM data. The analysis was performed based on land use parcels derived from OSM data and tested for the city of Dresden, Germany. The overall accuracy of the final map of public urban green spaces was 95% and was mainly influenced by the uncertainty of the public accessibility model.},
DOI = {10.3390/ijgi10040251}
}



@Article{agriculture11040337,
AUTHOR = {Pane, Catello and Manganiello, Gelsomina and Nicastro, Nicola and Cardi, Teodoro and Carotenuto, Francesco},
TITLE = {Powdery Mildew Caused by Erysiphe cruciferarum on Wild Rocket (Diplotaxis tenuifolia): Hyperspectral Imaging and Machine Learning Modeling for Non-Destructive Disease Detection},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {337},
URL = {https://www.mdpi.com/2077-0472/11/4/337},
ISSN = {2077-0472},
ABSTRACT = {Wild rocket is a widely cultivated salad crop. Typical signs and symptoms of powdery mildew were observed on leaves of Diplotaxis tenuifolia, likely favored by climatic conditions occurring in a greenhouse. Based on morphological features and molecular analysis, the disease agent was identified as the fungal pathogen Erysiphe cruciferarum. To the best of our knowledge, this is the first report of E. cruciferarum on D. tenuifolia. Moreover, the present study provides a non-destructive high performing digital approach to efficiently detect the disease. Hyperspectral image analysis allowed to characterize the spectral response of wild rocket affected by powdery mildew and the adopted machine-learning approach (a trained Random Forest model with the four most contributory wavelengths falling in the range 403–446 nm) proved to be able to accurately discriminate between healthy and diseased wild rocket leaves. Shifts in the irradiance absorption by chlorophyll a of diseased leaves in the spectrum blue range seems to be at the base of the hyperspectral imaging detection of wild rocket powdery mildew.},
DOI = {10.3390/agriculture11040337}
}



@Article{rs13081464,
AUTHOR = {Liang, Zhu and Wang, Changming and Duan, Zhijie and Liu, Hailiang and Liu, Xiaoyang and Ullah Jan Khan, Kaleem},
TITLE = {A Hybrid Model Consisting of Supervised and Unsupervised Learning for Landslide Susceptibility Mapping},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1464},
URL = {https://www.mdpi.com/2072-4292/13/8/1464},
ISSN = {2072-4292},
ABSTRACT = {Landslides cause huge damage to social economy and human beings every year. Landslide susceptibility mapping (LSM) occupies an important position in land use and risk management. This study is to investigate a hybrid model which makes full use of the advantage of supervised learning model (SLM) and unsupervised learning model (ULM). Firstly, ten continuous variables were used to develop a ULM which consisted of factor analysis (FA) and k-means cluster for a preliminary landslide susceptibility map. Secondly, 351 landslides with “1” label were collected and the same number of non-landslide samples with “0” label were selected from the very low susceptibility area in the preliminary map, constituting a new priori condition for a SLM, and thirteen factors were used for the modeling of gradient boosting decision tree (GBDT) which represented for SLM. Finally, the performance of different models was verified using related indexes. The results showed that the performance of the pretreated GBDT model was improved with sensitivity, specificity, accuracy and the area under the curve (AUC) values of 88.60%, 92.59%, 90.60% and 0.976, respectively. It can be concluded that a pretreated model with strong robustness can be constructed by increasing the purity of samples.},
DOI = {10.3390/rs13081464}
}



@Article{electronics10080905,
AUTHOR = {Rodríguez-García, Miguel Ángel and García-Sánchez, Francisco and Valencia-García, Rafael},
TITLE = {Knowledge-Based System for Crop Pests and Diseases Recognition},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {905},
URL = {https://www.mdpi.com/2079-9292/10/8/905},
ISSN = {2079-9292},
ABSTRACT = {With the rapid increase in the world’s population, there is an ever-growing need for a sustainable food supply. Agriculture is one of the pillars for worldwide food provisioning, with fruits and vegetables being essential for a healthy diet. However, in the last few years the worldwide dispersion of virulent plant pests and diseases has caused significant decreases in the yield and quality of crops, in particular fruit, cereal and vegetables. Climate change and the intensification of global trade flows further accentuate the issue. Integrated Pest Management (IPM) is an approach to pest control that aims at maintaining pest insects at tolerable levels, keeping pest populations below an economic injury level. Under these circumstances, the early identification of pests and diseases becomes crucial. In this work, we present the first step towards a fully fledged, semantically enhanced decision support system for IPM. The ultimate goal is to build a complete agricultural knowledge base by gathering data from multiple, heterogeneous sources and to develop a system to assist farmers in decision making concerning the control of pests and diseases. The pest classifier framework has been evaluated in a simulated environment, obtaining an aggregated accuracy of 98.8%.},
DOI = {10.3390/electronics10080905}
}



@Article{s21082679,
AUTHOR = {Ye, Zhoujing and Yan, Guannan and Wei, Ya and Zhou, Bin and Li, Ning and Shen, Shihui and Wang, Linbing},
TITLE = {Real-Time and Efficient Traffic Information Acquisition via Pavement Vibration IoT Monitoring System},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2679},
URL = {https://www.mdpi.com/1424-8220/21/8/2679},
PubMedID = {33920249},
ISSN = {1424-8220},
ABSTRACT = {Traditional road-embedded monitoring systems for traffic monitoring have the disadvantages of a short life, high energy consumption and data redundancy, resulting in insufficient durability and high cost. In order to improve the durability and efficiency of the road-embedded monitoring system, a pavement vibration monitoring system is developed based on the Internet of things (IoT). The system includes multi-acceleration sensing nodes, a gateway, and a cloud platform. The key design principles and technologies of each part of the system are proposed, which provides valuable experience for the application of IoT monitoring technology in road infrastructures. Characterized by low power consumption, distributed computing, and high extensibility properties, the pavement vibration IoT monitoring system can realize the monitoring, transmission, and analysis of pavement vibration signal, and acquires the real-time traffic information. This road-embedded system improves the intellectual capacity of road infrastructure and is conducive to the construction of a new generation of smart roads.},
DOI = {10.3390/s21082679}
}



@Article{s21082681,
AUTHOR = {Besher, Kedir Mamo and Nieto-Hipolito, Juan Ivan and Buenrostro-Mariscal, Raymundo and Ali, Mohammed Zamshed},
TITLE = {Spectrum Based Power Management for Congested IoT Networks},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2681},
URL = {https://www.mdpi.com/1424-8220/21/8/2681},
PubMedID = {33920253},
ISSN = {1424-8220},
ABSTRACT = {With constantly increasing demand in connected society Internet of Things (IoT) network is frequently becoming congested. IoT sensor devices lose more power while transmitting data through congested IoT networks. Currently, in most scenarios, the distributed IoT devices in use have no effective spectrum based power management, and have no guarantee of a long term battery life while transmitting data through congested IoT networks. This puts user information at risk, which could lead to loss of important information in communication. In this paper, we studied the extra power consumed due to retransmission of IoT data packet and bad communication channel management in a congested IoT network. We propose a spectrum based power management solution that scans channel conditions when needed and utilizes the lowest congested channel for IoT packet routing. It also effectively measured power consumed in idle, connected, paging and synchronization status of a standard IoT device in a congested IoT network. In our proposed solution, a Freescale Freedom Development Board (FREDEVPLA) is used for managing channel related parameters. While supervising the congestion level and coordinating channel allocation at the FREDEVPLA level, our system configures MAC and Physical layer of IoT devices such that it provides the outstanding power utilization based on the operating network in connected mode compared to the basic IoT standard. A model has been set up and tested using freescale launchpads. Test data show that battery life of IoT devices using proposed spectrum based power management increases by at least 30% more than non-spectrum based power management methods embedded within IoT devices itself. Finally, we compared our results with the basic IoT standard, IEEE802.15.4. Furthermore, the proposed system saves lot of memory for IoT devices, improves overall IoT network performance, and above all, decrease the risk of losing data packets in communication. The detail analysis in this paper also opens up multiple avenues for further research in future use of channel scanning by FREDEVPLA board.},
DOI = {10.3390/s21082681}
}



@Article{rs13081471,
AUTHOR = {Marin, Diego Bedin and Ferraz, Gabriel Araújo e Silva and Guimarães, Paulo Henrique Sales and Schwerz, Felipe and Santana, Lucas Santos and Barbosa, Brenon Dienevam Souza and Barata, Rafael Alexandre Pena and Faria, Rafael de Oliveira and Dias, Jessica Ellen Lima and Conti, Leonardo and Rossi, Giuseppe},
TITLE = {Remotely Piloted Aircraft and Random Forest in the Evaluation of the Spatial Variability of Foliar Nitrogen in Coffee Crop},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1471},
URL = {https://www.mdpi.com/2072-4292/13/8/1471},
ISSN = {2072-4292},
ABSTRACT = {The development of approaches to determine the spatial variability of nitrogen (N) into coffee leaves is essential to increase productivity and reduce production costs and environmental impacts associated with excessive N applications. Thus, this study aimed to assess the potential of the Random Forest (RF) machine learning method applied to vegetation indices (VI) obtained from Remotely Piloted Aircraft (RPA) images to measure the N content in coffee plants. A total of 10 VI were obtained from multispectral images by a camera attached to a rotary-wing RPA. The RGB orthomosaic was used to determine sampling points at the crop area, which were ranked by N levels in the plants as deficient, critical, or sufficient. The chemical analysis of N content in the coffee leaves, as well as the VI values in sample points, were used as input parameters for the image training and its classification by the RF. The suggested model has shown global accuracy and a kappa coefficient of up to 0.91 and 0.86, respectively. The best results were achieved using the Green Normalized Difference Vegetation (GNDVI) and Green Optimized Soil Adjusted Vegetation Index (GOSAVI). In addition, the model enabled the evaluation of the spatial distribution of N in the coffee trees, as well as quantification of N deficiency in the crop for the whole area. The GNDVI and GOSAVI allowed the verification that 22% of the entire crop area had plants with N deficiency symptoms, which would result in a reduction of 78% in the amount of N applied by the producer.},
DOI = {10.3390/rs13081471}
}



@Article{electronics10080910,
AUTHOR = {Ateya, Abdelhamied A. and Algarni, Abeer D. and Hamdi, Monia and Koucheryavy, Andrey and Soliman, Naglaa. F.},
TITLE = {Enabling Heterogeneous IoT Networks over 5G Networks with Ultra-Dense Deployment—Using MEC/SDN},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {910},
URL = {https://www.mdpi.com/2079-9292/10/8/910},
ISSN = {2079-9292},
ABSTRACT = {The Internet of things (IoT) is the third evolution of the traditional Internet that enables interaction and communication among machines. Many IoT platforms and networks have been developed, and recently, market sectors have started to develop specific IoT applications and services. Integrating heterogeneous IoT networks with the existing ones, mainly with the cellular networks, is a great demand. IoT represents one of the main use cases of the fifth-generation (5G) cellular system as announced by the 3rd Generation Partnership Project (3GPP) and the International Telecommunication Union (ITU). Integrating IoT networks with 5G networks face many challenges related to dense deployment and a massive number of expected connected devices. Thus, IoT network availability and scalability are the main requirements that should be achieved. To this end, this work provides a framework for integrating heterogeneous IoT networks with the 5G networks. The proposed system considers dense deployment and system scalability and availability requirements as announced by ITU and 3GPP. Our proposed structure deploys three main communication paradigms; mobile edge computing (MEC), device-to-device communications (D2D), and software-defined networking (SDN). Our proposed system is evaluated over a reliable environment for various deployment scenarios, and the results validate the proposed structure. The proposed IoT/5G reduces the percentage of blocked tasks by an average of 30% than other traditional IoT networks. This increases the overall system availability and scalability since IoT networks can have more devices and tasks than existing IoT networks. Furthermore, our proposed structure reduces the overall consumed energy by an average of 20% than existing IoT networks, which is an effective metric for IoT networks.},
DOI = {10.3390/electronics10080910}
}



@Article{app11083435,
AUTHOR = {Kim, Jeonghwan and Lee, Soomin and Seo, Jongwon and Lee, Dong-Eun and Choi, Hee Seon},
TITLE = {The Integration of Earthwork Design Review and Planning Using UAV-Based Point Cloud and BIM},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {3435},
URL = {https://www.mdpi.com/2076-3417/11/8/3435},
ISSN = {2076-3417},
ABSTRACT = {Earthwork is seemingly guesswork, but it requires a high level of accuracy and precise planning. Differences between earthwork design and finishing levels cause project delays and cost overrun due to the time-consuming nature of earthwork re-work. Therefore, error-free earthwork planning and design review is a key to the success of earthwork projects. This study utilized an integrated approach of an unmanned aerial vehicle (UAV)-based point cloud and BIM (Building Information Modeling) to verify the design and to operate the earthwork planning. The integrated approach was proposed and applied to a 420 square meters housing construction project to review an original earthwork design and create an earthwork plan for excavator work. As a result, errors in earthwork design that caused by inaccurate initial DEM was revealed, thus the earthwork design was revised with a UAV-based point cloud map. Additionally, the integrated approach was able to generate an explicit task sequence for an excavator.},
DOI = {10.3390/app11083435}
}



@Article{app11083454,
AUTHOR = {Gaspar, Pedro D. and Fernandez, Carlos M. and Soares, Vasco N. G. J. and Caldeira, João M. L. P. and Silva, Hélio},
TITLE = {Development of Technological Capabilities through the Internet of Things (IoT): Survey of Opportunities and Barriers for IoT Implementation in Portugal’s Agro-Industry},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {3454},
URL = {https://www.mdpi.com/2076-3417/11/8/3454},
ISSN = {2076-3417},
ABSTRACT = {The agro-industrial sector consumes a significant amount of natural resources for farming and meat production. By 2050, population growth is expected, generating more demand and, consequently, more consumption of scarce resources. This challenging scenario is a concern of the European Commission, revealed in the Green Deal commitment and by the United Nations’ 12th goal of sustainable development. Thus, organizations must increase productivity and be more sustainable as soon as possible. Internet of Things (IoT) is introduced as a solution to facilitate agro-food companies to be more eco-efficient, mainly facing difficulties on farms, such as food loss and waste, best efficiency in management of resources, and production. The deployment of this technology depends on the stage of maturity and potential of implementation. To assess and characterize companies, with respect of IoT implementation, a survey was applied in 21 micro, small and medium agro-food companies, belonging to milk, honey, olive oil, jams, fruticulture, bakery and pastry, meat, coffee, and wine sectors, in the central region of Portugal. As results, this paper reveals the stage of maturity, level of sophistication, potential, opportunities, solutions, and barriers for implementation of IoT. Additionally, suggestions and recommendations to improve practices are discussed.},
DOI = {10.3390/app11083454}
}



@Article{rs13081479,
AUTHOR = {Schovanec, Heather and Walton, Gabriel and Kromer, Ryan and Malsam, Adam},
TITLE = {Development of Improved Semi-Automated Processing Algorithms for the Creation of Rockfall Databases},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1479},
URL = {https://www.mdpi.com/2072-4292/13/8/1479},
ISSN = {2072-4292},
ABSTRACT = {While terrestrial laser scanning and photogrammetry provide high quality point cloud data that can be used for rock slope monitoring, their increased use has overwhelmed current data analysis methodologies. Accordingly, point cloud processing workflows have previously been developed to automate many processes, including point cloud alignment, generation of change maps and clustering. However, for more specialized rock slope analyses (e.g., generating a rockfall database), the creation of more specialized processing routines and algorithms is necessary. More specialized algorithms include the reconstruction of rockfall volumes from clusters and points and automatic classification of those volumes are both processing steps required to automate the generation of a rockfall database. We propose a workflow that can automate all steps of the point cloud processing workflow. In this study, we detail adaptions to commonly used algorithms for rockfall monitoring use cases, such as Multiscale Model to Model Cloud Comparison (M3C2). This workflow details the entire processing pipeline for rockfall database generation using terrestrial laser scanning.},
DOI = {10.3390/rs13081479}
}



@Article{rs13081489,
AUTHOR = {Fricke, Katharina and Baschek, Björn and Jenal, Alexander and Kneer, Caspar and Weber, Immanuel and Bongartz, Jens and Wyrwa, Jens and Schöl, Andreas},
TITLE = {Observing Water Surface Temperature from Two Different Airborne Platforms over Temporarily Flooded Wadden Areas at the Elbe Estuary—Methods for Corrections and Analysis},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1489},
URL = {https://www.mdpi.com/2072-4292/13/8/1489},
ISSN = {2072-4292},
ABSTRACT = {Over the Hahnöfer Nebenelbe, a part of the Elbe estuary near Hamburg, Germany, a combined aerial survey with an unmanned aerial system (UAV) and a gyrocopter was conducted to acquire information about the water surface temperatures. The water temperature in the estuary is important for biological processes and living conditions of riverine organisms. This study aimed to develop a workflow that allows for comparing and analysing surface temperatures acquired by two different remote sensing systems. The thermal infrared (TIR) datasets were compared with in situ measurements gathered during the data acquisition, where both TIR datasets showed a varying bias. Potential error sources regarding the absolute and relative accuracy were investigated and modelled based on the available measurements, including emissivity, atmosphere, skin effect at the water surface, camera flat field correction and calibration. The largest effects on the observed TIR water temperature had the camera calibration and the modelled atmospheric effects. After the correction steps, both datasets could be combined to create a multitemporal representation of the temperature pattern and profiles over the survey area’s wadden flats.},
DOI = {10.3390/rs13081489}
}



@Article{s21082748,
AUTHOR = {Leon-Medina, Jersson X. and Anaya, Maribel and Parés, Núria and Tibaduiza, Diego A. and Pozo, Francesc},
TITLE = {Structural Damage Classification in a Jacket-Type Wind-Turbine Foundation Using Principal Component Analysis and Extreme Gradient Boosting},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2748},
URL = {https://www.mdpi.com/1424-8220/21/8/2748},
PubMedID = {33924654},
ISSN = {1424-8220},
ABSTRACT = {Damage classification is an important topic in the development of structural health monitoring systems. When applied to wind-turbine foundations, it provides information about the state of the structure, helps in maintenance, and prevents catastrophic failures. A data-driven pattern-recognition methodology for structural damage classification was developed in this study. The proposed methodology involves several stages: (1) data acquisition, (2) data arrangement, (3) data normalization through the mean-centered unitary group-scaling method, (4) linear feature extraction, (5) classification using the extreme gradient boosting machine learning classifier, and (6) validation applying a 5-fold cross-validation technique. The linear feature extraction capabilities of principal component analysis are employed; the original data of 58,008 features is reduced to only 21 features. The methodology is validated with an experimental test performed in a small-scale wind-turbine foundation structure that simulates the perturbation effects caused by wind and marine waves by applying an unknown white noise signal excitation to the structure. A vibration-response methodology is selected for collecting accelerometer data from both the healthy structure and the structure subjected to four different damage scenarios. The datasets are satisfactorily classified, with performance measures over 99.9% after using the proposed damage classification methodology.},
DOI = {10.3390/s21082748}
}



@Article{rs13081502,
AUTHOR = {Fan, Yongzhao and Zou, Rong and Fan, Xiaoyun and Dong, Rendong and Xie, Mengyou},
TITLE = {A Hierarchical Clustering Method to Repair Gaps in Point Clouds of Powerline Corridor for Powerline Extraction},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1502},
URL = {https://www.mdpi.com/2072-4292/13/8/1502},
ISSN = {2072-4292},
ABSTRACT = {Powerline detection is becoming a significant issue for powerline monitoring and maintenance, which further ensures transmission security. As an efficient method, laser scanning has attracted considerable attention in powerline detection for its high precision and robustness during the night period. However, due to occlusion and varying point density, gaps will appear in scans and greatly influence powerline detection by over–clustering, insufficient extraction, or misclassification in existing methods. Moreover, this situation will be worse in terrestrial laser scanning (TLS), because TLS suffers more from gaps due to its unique ground–based scanning mode compared to other laser scanning systems. Thereby, this paper explores a robust method to repair gaps for extracting powerlines from TLS data. Firstly, a hierarchical clustering method is used to extract the powerlines. During the clustering, gaps are repaired based on neighborhood relations of powerline candidates, and repaired gaps can create continuous neighborhood relations that ensure the execution of the clustering method in return. Test results show that the hierarchical clustering method is robust in powerline extraction with repaired gaps. Secondly, reconstruction is performed for further detection. Pylon–powerline connections are found by the slope change method, and powerlines with multi–span are successfully fitted using these connections. Experiment shows that it is feasible to find connections for multi–span reconstruction.},
DOI = {10.3390/rs13081502}
}



@Article{drones5020025,
AUTHOR = {Crawford, Brandon and Swanson, Erika and Schultz-Fellenz, Emily and Collins, Adam and Dann, Julian and Lathrop, Emma and Milazzo, Damien},
TITLE = {A New Method for High Resolution Surface Change Detection: Data Collection and Validation of Measurements from UAS at the Nevada National Security Site, Nevada, USA},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {25},
URL = {https://www.mdpi.com/2504-446X/5/2/25},
ISSN = {2504-446X},
ABSTRACT = {The use of uncrewed aerial systems (UAS) increases the opportunities for detecting surface changes in remote areas and in challenging terrain. Detecting surface topographic changes offers an important constraint for understanding earthquake damage, groundwater depletion, effects of mining, and other events. For these purposes, changes on the order of 5–10 cm are readily detected, but sometimes it is necessary to detect smaller changes. An example is the surface changes that result from underground explosions, which can be as small as 3 cm. Previous studies that described change detection methodologies were generally not aimed at detecting sub-5-cm changes. Additionally, studies focused on high-fidelity accuracy were either computationally modeled or did not fully provide the necessary examples to highlight the usability of these workflows. Detecting changes at this threshold may be critical in certain applications, such as global security research and monitoring for high-consequence natural hazards, including landslides. Here we provide a detailed description of the methodology we used to detect 2–3 cm changes in an important applied research setting—surface changes related to underground explosions. This methodology improves the accuracy of change detection data collection and analysis through the optimization of pre-field planning, surveying, flight operations, and post-processing the collected data, all of which are critical to obtaining the highest output data resolution possible. We applied this methodology to a field study location, collecting 1.4 Tb of images over the course of 30 flights, and location data for 239 ground control points (GCPs). We independently verified changes with orthoimagery, and found that structure-from-motion, software-reported root mean square errors (RMSEs) for both control and check points underestimated the actual error. We found that 3 cm changes are detectable with this methodology, thereby improving our knowledge of a rock’s response to underground explosions.},
DOI = {10.3390/drones5020025}
}



@Article{rs13081508,
AUTHOR = {Kang, Yeseong and Nam, Jinwoo and Kim, Younggwang and Lee, Seongtae and Seong, Deokgyeong and Jang, Sihyeong and Ryu, Chanseok},
TITLE = {Assessment of Regression Models for Predicting Rice Yield and Protein Content Using Unmanned Aerial Vehicle-Based Multispectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1508},
URL = {https://www.mdpi.com/2072-4292/13/8/1508},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle-based multispectral imagery including five spectral bands (blue, green, red, red-edge, and near-infrared) for a rice field in the ripening stage was used to develop regression models for predicting the rice yield and protein content and to select the most suitable regression analysis method for the year-invariant model: partial least squares regression, ridge regression, and artificial neural network (ANN). The regression models developed with six vegetation indices (green normalization difference vegetation index (GNDVI), normalization difference red-edge index (NDRE), chlorophyll index red edge (CIrededge), difference NIR/Green green difference vegetation index (GDVI), green-red NDVI (GRNDVI), and medium resolution imaging spectrometer terrestrial chlorophyll index (MTCI)), calculated from the spectral bands, were applied to single years (2018, 2019, and 2020) and multiple years (2018 + 2019, 2018 + 2020, 2019 + 2020, and all years). The regression models were cross-validated through mutual prediction against the vegetation indices in nonoverlapping years, and the prediction errors were evaluated via root mean squared error of prediction (RMSEP). The ANN model was reproducible, with low and sustained prediction errors of 24.2 kg/1000 m2 ≤ RMSEP ≤ 59.1 kg/1000 m2 in rice yield and 0.14% ≤ RMSEP ≤ 0.28% in rice-protein content in all single-year and multiple-year analyses. When the importance of each vegetation index of the regression models was evaluated, only the ANN model showed the same ranking in the vegetation index of the first (MTCI in both rice yield and protein content) and second importance (CIrededge in rice yield and GRNDVI in rice-protein content). Overall, this means that the ANN model has the highest potential for developing a year-invariant model with stable RMSEP and consistent variable ranking.},
DOI = {10.3390/rs13081508}
}



@Article{rs13081509,
AUTHOR = {Hu, Xikun and Ban, Yifang and Nascetti, Andrea},
TITLE = {Uni-Temporal Multispectral Imagery for Burned Area Mapping with Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1509},
URL = {https://www.mdpi.com/2072-4292/13/8/1509},
ISSN = {2072-4292},
ABSTRACT = {Accurate burned area information is needed to assess the impacts of wildfires on people, communities, and natural ecosystems. Various burned area detection methods have been developed using satellite remote sensing measurements with wide coverage and frequent revisits. Our study aims to expound on the capability of deep learning (DL) models for automatically mapping burned areas from uni-temporal multispectral imagery. Specifically, several semantic segmentation network architectures, i.e., U-Net, HRNet, Fast-SCNN, and DeepLabv3+, and machine learning (ML) algorithms were applied to Sentinel-2 imagery and Landsat-8 imagery in three wildfire sites in two different local climate zones. The validation results show that the DL algorithms outperform the ML methods in two of the three cases with the compact burned scars, while ML methods seem to be more suitable for mapping dispersed burn in boreal forests. Using Sentinel-2 images, U-Net and HRNet exhibit comparatively identical performance with higher kappa (around 0.9) in one heterogeneous Mediterranean fire site in Greece; Fast-SCNN performs better than others with kappa over 0.79 in one compact boreal forest fire with various burn severity in Sweden. Furthermore, directly transferring the trained models to corresponding Landsat-8 data, HRNet dominates in the three test sites among DL models and can preserve the high accuracy. The results demonstrated that DL models can make full use of contextual information and capture spatial details in multiple scales from fire-sensitive spectral bands to map burned areas. Using only a post-fire image, the DL methods not only provide automatic, accurate, and bias-free large-scale mapping option with cross-sensor applicability, but also have potential to be used for onboard processing in the next Earth observation satellites.},
DOI = {10.3390/rs13081509}
}



@Article{s21082765,
AUTHOR = {Taghvaee, Hamidreza and Jain, Akshay and Timoneda, Xavier and Liaskos, Christos and Abadal, Sergi and Alarcón, Eduard and Cabellos-Aparicio, Albert},
TITLE = {Radiation Pattern Prediction for Metasurfaces: A Neural Network-Based Approach},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2765},
URL = {https://www.mdpi.com/1424-8220/21/8/2765},
PubMedID = {33919861},
ISSN = {1424-8220},
ABSTRACT = {As the current standardization for the 5G networks nears completion, work towards understanding the potential technologies for the 6G wireless networks is already underway. One of these potential technologies for the 6G networks is reconfigurable intelligent surfaces. They offer unprecedented degrees of freedom towards engineering the wireless channel, i.e., the ability to modify the characteristics of the channel whenever and however required. Nevertheless, such properties demand that the response of the associated metasurface is well understood under all possible operational conditions. While an understanding of the radiation pattern characteristics can be obtained through either analytical models or full-wave simulations, they suffer from inaccuracy and extremely high computational complexity, respectively. Hence, in this paper, we propose a neural network-based approach that enables a fast and accurate characterization of the metasurface response. We analyze multiple scenarios and demonstrate the capabilities and utility of the proposed methodology. Concretely, we show that this method can learn and predict the parameters governing the reflected wave radiation pattern with an accuracy of a full-wave simulation (98.8–99.8%) and the time and computational complexity of an analytical model. The aforementioned result and methodology will be of specific importance for the design, fault tolerance, and maintenance of the thousands of reconfigurable intelligent surfaces that will be deployed in the 6G network environment.},
DOI = {10.3390/s21082765}
}



@Article{rs13081523,
AUTHOR = {Shao, Yang and Cooner, Austin J. and Walsh, Stephen J.},
TITLE = {Assessing Deep Convolutional Neural Networks and Assisted Machine Perception for Urban Mapping},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1523},
URL = {https://www.mdpi.com/2072-4292/13/8/1523},
ISSN = {2072-4292},
ABSTRACT = {High-spatial-resolution satellite imagery has been widely applied for detailed urban mapping. Recently, deep convolutional neural networks (DCNNs) have shown promise in certain remote sensing applications, but they are still relatively new techniques for general urban mapping. This study examines the use of two DCNNs (U-Net and VGG16) to provide an automatic schema to support high-resolution mapping of buildings, road/open built-up, and vegetation cover. Using WorldView-2 imagery as input, we first applied an established OBIA method to characterize major urban land cover classes. An OBIA-derived urban map was then divided into a training and testing region to evaluate the DCNNs’ performance. For U-Net mapping, we were particularly interested in how sample size or the number of image tiles affect mapping accuracy. U-Net generated cross-validation accuracies ranging from 40.5 to 95.2% for training sample sizes from 32 to 4096 image tiles (each tile was 256 by 256 pixels). A per-pixel accuracy assessment led to 87.8 percent overall accuracy for the testing region, suggesting U-Net’s good generalization capabilities. For the VGG16 mapping, we proposed an object-based framing paradigm that retains spatial information and assists machine perception through Gaussian blurring. Gaussian blurring was used as a pre-processing step to enhance the contrast between objects of interest and background (contextual) information. Combined with the pre-trained VGG16 and transfer learning, this analytical approach generated a 77.3 percent overall accuracy for per-object assessment. The mapping accuracy could be further improved given more robust segmentation algorithms and better quantity/quality of training samples. Our study shows significant promise for DCNN implementation for urban mapping and our approach can transfer to a number of other remote sensing applications.},
DOI = {10.3390/rs13081523}
}



@Article{app11083547,
AUTHOR = {Hou, Xiaoyu and Zhang, Kunlin and Xu, Jihui and Huang, Wei and Yu, Xinmiao and Xu, Huaiyu},
TITLE = {Object Detection in Drone Imagery via Sample Balance Strategies and Local Feature Enhancement},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {3547},
URL = {https://www.mdpi.com/2076-3417/11/8/3547},
ISSN = {2076-3417},
ABSTRACT = {With the advent of drones, new potential applications have emerged for the unconstrained analysis of images and videos from aerial view cameras. Despite the tremendous success of the generic object detection methods developed using ground-based photos, a considerable performance drop is observed when these same methods are directly applied to images captured by Unmanned Aerial Vehicles (UAVs). Usually, most of the work goes into improving the performance of the detector in aspects such as design loss, training sample selection, feature enhancement, and so forth. This paper proposes a detection framework based on an anchor-free detector with several modules, including a sample balance strategies module and super-resolved generated feature module, to improve performance. We proposed the sample balance strategies module to optimize the imbalance among training samples, especially the imbalance between positive and negative, and easy and hard samples. Due to the high frequencies and noisy representation of the small objects in images captured by drones, the detection task is extraordinarily challenging. However, when compared with other algorithms of this kind, our method achieves better results. We also propose a super-resolved generated GAN (Generative Adversarial Network) module with center-ness weights to effectively enhance the local feature map. Finally, we demonstrate our method’s effectiveness with the proposed modules by carrying out a state-of-the-art performance on Visdrone2020 benchmarks.},
DOI = {10.3390/app11083547}
}



@Article{rs13081529,
AUTHOR = {Jiang, Yufeng and Zhang, Li and Yan, Min and Qi, Jianguo and Fu, Tianmeng and Fan, Shunxiang and Chen, Bowei},
TITLE = {High-Resolution Mangrove Forests Classification with Machine Learning Using Worldview and UAV Hyperspectral Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1529},
URL = {https://www.mdpi.com/2072-4292/13/8/1529},
ISSN = {2072-4292},
ABSTRACT = {Mangrove forests, as important ecological and economic resources, have suffered a loss in the area due to natural and human activities. Monitoring the distribution of and obtaining accurate information on mangrove species is necessary for ameliorating the damage and protecting and restoring mangrove forests. In this study, we compared the performance of UAV Rikola hyperspectral images, WorldView-2 (WV-2) satellite-based multispectral images, and a fusion of data from both in the classification of mangrove species. We first used recursive feature elimination‒random forest (RFE-RF) to select the vegetation’s spectral and texture feature variables, and then implemented random forest (RF) and support vector machine (SVM) algorithms as classifiers. The results showed that the accuracy of the combined data was higher than that of UAV and WV-2 data; the vegetation index features of UAV hyperspectral data and texture index of WV-2 data played dominant roles; the overall accuracy of the RF algorithm was 95.89% with a Kappa coefficient of 0.95, which is more accurate and efficient than SVM. The use of combined data and RF methods for the classification of mangrove species could be useful in biomass estimation and breeding cultivation.},
DOI = {10.3390/rs13081529}
}



@Article{rs13081528,
AUTHOR = {Song, Yongze and Wu, Peng},
TITLE = {Earth Observation for Sustainable Infrastructure: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1528},
URL = {https://www.mdpi.com/2072-4292/13/8/1528},
ISSN = {2072-4292},
ABSTRACT = {Infrastructure is a fundamental sector for sustainable development and Earth observation has great potentials for sustainable infrastructure development (SID). However, implementations of the timely, large–scale and multi–source Earth observation are still limited in satisfying the huge global requirements of SID. This study presents a systematical literature review to identify trends of Earth observation for sustainable infrastructure (EOSI), investigate the relationship between EOSI and Sustainable Development Goals (SDGs), and explore challenges and future directions of EOSI. Results reveal the close associations of infrastructure, urban development, ecosystems, climate, Earth observation and GIS in EOSI, and indicate their relationships. In addition, from the perspective of EOSI–SDGs relationship, the huge potentials of EOSI are demonstrated from the 70% of the infrastructure influenced targets that can be directly or indirectly derived from Earth observation data, but have not been included in current SDG indicators. Finally, typical EOSI cases are presented to indicate challenges and future research directions. This review emphasizes the contributions and potentials of Earth observation to SID and EOSI is a powerful pathway to deliver on SDGs.},
DOI = {10.3390/rs13081528}
}



@Article{rs13081535,
AUTHOR = {Jiang, Fugen and Zhao, Feng and Ma, Kaisen and Li, Dongsheng and Sun, Hua},
TITLE = {Mapping the Forest Canopy Height in Northern China by Synergizing ICESat-2 with Sentinel-2 Using a Stacking Algorithm},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1535},
URL = {https://www.mdpi.com/2072-4292/13/8/1535},
ISSN = {2072-4292},
ABSTRACT = {The forest canopy height (FCH) plays a critical role in forest quality evaluation and resource management. The accurate and rapid estimation and mapping of the regional forest canopy height is crucial for understanding vegetation growth processes and the internal structure of the ecosystem. A stacking algorithm consisting of multiple linear regression (MLR), support vector machine (SVM), k-nearest neighbor (kNN), and random forest (RF) was used in this paper and demonstrated optimal performance in predicting the forest canopy height by synergizing Sentinel-2 images acquired from the cloud-based computation platform Google Earth Engine (GEE) with data from ICESat-2 (Ice, Cloud, and Land Elevation Satellite-2). This research was conducted to achieve continuous mapping of the canopy height of plantations in Saihanba Mechanical Forest Plantation, which is located in Chengde City, northern Hebei province, China. The results show that stacking achieved the best prediction accuracy for the forest canopy height, with an R2 of 0.77 and a root mean square error (RMSE) of 1.96 m. Compared with MLR, SVM, kNN, and RF, the RMSE obtained by stacking was reduced by 25.2%, 24.9%, 22.8%, and 18.7%, respectively. Since Sentinel-2 images and ICESat-2 data are publicly available, this opens the door for the accurate mapping of the continuous distribution of the forest canopy height globally in the future.},
DOI = {10.3390/rs13081535}
}



@Article{rs13081534,
AUTHOR = {Zhang, Fan and Hu, Zhenqi and Yang, Kun and Fu, Yaokun and Feng, Zewei and Bai, Mingbo},
TITLE = {The Surface Crack Extraction Method Based on Machine Learning of Image and Quantitative Feature Information Acquisition Method},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1534},
URL = {https://www.mdpi.com/2072-4292/13/8/1534},
ISSN = {2072-4292},
ABSTRACT = {In order to effectively control the damage caused by surface cracks to a geological environment, we need to find a convenient, efficient, and accurate method to obtain crack information. The existing crack extraction methods based on unmanned air vehicle (UAV) images inevitably have some erroneous pixels because of the complexity of background information. At the same time, there are few researches on crack feature information. In view of this, this article proposes a surface crack extraction method based on machine learning of UAV images, the data preprocessing steps, and the content and calculation methods for crack feature information: length, width, direction, location, fractal dimension, number, crack rate, and dispersion rate. The results show that the method in this article can effectively avoid the interference by vegetation and soil crust. By introducing the concept of dispersion rate, the method combining crack rate and dispersion rate can describe the distribution characteristics of regional cracks more clearly. Compared to field survey data, the calculation result of the crack feature information in this article is close to the true value, which proves that this is a reliable method for obtaining quantitative crack feature information.},
DOI = {10.3390/rs13081534}
}



@Article{s21082803,
AUTHOR = {Jaffari, Rabeea and Hashmani, Manzoor Ahmed and Reyes-Aldasoro, Constantino Carlos},
TITLE = {A Novel Focal Phi Loss for Power Line Segmentation with Auxiliary Classifier U-Net},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2803},
URL = {https://www.mdpi.com/1424-8220/21/8/2803},
PubMedID = {33923472},
ISSN = {1424-8220},
ABSTRACT = {The segmentation of power lines (PLs) from aerial images is a crucial task for the safe navigation of unmanned aerial vehicles (UAVs) operating at low altitudes. Despite the advances in deep learning-based approaches for PL segmentation, these models are still vulnerable to the class imbalance present in the data. The PLs occupy only a minimal portion (1–5%) of the aerial images as compared to the background region (95–99%). Generally, this class imbalance problem is addressed via the use of PL-specific detectors in conjunction with the popular class balanced cross entropy (BBCE) loss function. However, these PL-specific detectors do not work outside their application areas and a BBCE loss requires hyperparameter tuning for class-wise weights, which is not trivial. Moreover, the BBCE loss results in low dice scores and precision values and thus, fails to achieve an optimal trade-off between dice scores, model accuracy, and precision–recall values. In this work, we propose a generalized focal loss function based on the Matthews correlation coefficient (MCC) or the Phi coefficient to address the class imbalance problem in PL segmentation while utilizing a generic deep segmentation architecture. We evaluate our loss function by improving the vanilla U-Net model with an additional convolutional auxiliary classifier head (ACU-Net) for better learning and faster model convergence. The evaluation of two PL datasets, namely the Mendeley Power Line Dataset and the Power Line Dataset of Urban Scenes (PLDU), where PLs occupy around 1% and 2% of the aerial images area, respectively, reveal that our proposed loss function outperforms the popular BBCE loss by 16% in PL dice scores on both the datasets, 19% in precision and false detection rate (FDR) values for the Mendeley PL dataset and 15% in precision and FDR values for the PLDU with a minor degradation in the accuracy and recall values. Moreover, our proposed ACU-Net outperforms the baseline vanilla U-Net for the characteristic evaluation parameters in the range of 1–10% for both the PL datasets. Thus, our proposed loss function with ACU-Net achieves an optimal trade-off for the characteristic evaluation parameters without any bells and whistles. Our code is available at Github.},
DOI = {10.3390/s21082803}
}



@Article{drones5020027,
AUTHOR = {Khoufi, Ines and Laouiti, Anis and Adjih, Cedric and Hadded, Mohamed},
TITLE = {UAVs Trajectory Optimization for Data Pick Up and Delivery with Time Window},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {27},
URL = {https://www.mdpi.com/2504-446X/5/2/27},
ISSN = {2504-446X},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs), also known as drones, are a class of aircraft without the presence of pilots on board. UAVs have the ability to reduce the time and cost of deliveries and to respond to emergency situations. Currently, UAVs are extensively used for data delivery and/or collection to/from dangerous or inaccessible sites. However, trajectory planning is one of the major UAV issues that needs to be solved. To address this question, we focus in this paper on determining the optimized routes to be followed by the drones for data pickup and delivery with a time window with an intermittent connectivity network, while also having the possibility to recharge the drones’ batteries on the way to their destinations. To do so, we formulated the problem as a multi-objective optimization problem, and we showed how to use the Non-dominated Sorting Genetic Algorithm II (NSGA-II) to solve this problem. Several experiments were conducted to validate the proposed algorithm by considering different scenarios.},
DOI = {10.3390/drones5020027}
}



@Article{app11083586,
AUTHOR = {Xu, Gaofei and Guo, Wei and Zhao, Yang and Zhou, Yue and Zhang, Yinlong and Liu, Xinyu and Xu, Gaopeng and Li, Guangwei},
TITLE = {Online Learning Based Underwater Robotic Thruster Fault Detection},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {3586},
URL = {https://www.mdpi.com/2076-3417/11/8/3586},
ISSN = {2076-3417},
ABSTRACT = {This paper presents a novel online learning-based fault detection designed for underwater robotic thruster health monitoring. In the fault detection algorithm, we build a mathematical model between the control variable and the propeller speed by fitting collected online work status data to the model. To improve the accuracy of online modeling, a multi-center PSO algorithm with memory ability is utilized to optimize the modeling parameters. Additionally, a model online update mechanism is designed to accommodate the model to the change of thruster work status and sea environment. During the operation, propeller speed of the underwater robot is predicted through the online learning-based model, and the model residuals are used for thruster health monitoring. To avoid false alarm, an adaptive fault detection strategy is established based on model online update mechanism. The proposed method has been extensively evaluated using different underwater robotics, through a sea trial data simulation, a pool test fault detection experiment and a sea trial fault detection experiment. Compared with fixed model-based method, speed prediction MAE of the online learning model is at least 37.9% lower than that of the fixed model. The online learning-based method show no misdiagnosis in experiments, while the fixed model-based method is misdiagnosed. Experimental results show that the proposed method is competitive in terms of accuracy, adaptability, and robustness.},
DOI = {10.3390/app11083586}
}



@Article{s21082824,
AUTHOR = {Coluccia, Angelo and Fascista, Alessio and Schumann, Arne and Sommer, Lars and Dimou, Anastasios and Zarpalas, Dimitrios and Méndez, Miguel and de la Iglesia, David and González, Iago and Mercier, Jean-Philippe and Gagné, Guillaume and Mitra, Arka and Rajashekar, Shobha},
TITLE = {Drone vs. Bird Detection: Deep Learning Algorithms and Results from a Grand Challenge},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2824},
URL = {https://www.mdpi.com/1424-8220/21/8/2824},
PubMedID = {33923829},
ISSN = {1424-8220},
ABSTRACT = {Adopting effective techniques to automatically detect and identify small drones is a very compelling need for a number of different stakeholders in both the public and private sectors. This work presents three different original approaches that competed in a grand challenge on the “Drone vs. Bird” detection problem. The goal is to detect one or more drones appearing at some time point in video sequences where birds and other distractor objects may be also present, together with motion in background or foreground. Algorithms should raise an alarm and provide a position estimate only when a drone is present, while not issuing alarms on birds, nor being confused by the rest of the scene. In particular, three original approaches based on different deep learning strategies are proposed and compared on a real-world dataset provided by a consortium of universities and research centers, under the 2020 edition of the Drone vs. Bird Detection Challenge. Results show that there is a range in difficulty among different test sequences, depending on the size and the shape visibility of the drone in the sequence, while sequences recorded by a moving camera and very distant drones are the most challenging ones. The performance comparison reveals that the different approaches perform somewhat complementary, in terms of correct detection rate, false alarm rate, and average precision.},
DOI = {10.3390/s21082824}
}



@Article{drones5020028,
AUTHOR = {Li, Joan Y. Q. and Duce, Stephanie and Joyce, Karen E. and Xiang, Wei},
TITLE = {SeeCucumbers: Using Deep Learning and Drone Imagery to Detect Sea Cucumbers on Coral Reef Flats},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {28},
URL = {https://www.mdpi.com/2504-446X/5/2/28},
ISSN = {2504-446X},
ABSTRACT = {Sea cucumbers (Holothuroidea or holothurians) are a valuable fishery and are also crucial nutrient recyclers, bioturbation agents, and hosts for many biotic associates. Their ecological impacts could be substantial given their high abundance in some reef locations and thus monitoring their populations and spatial distribution is of research interest. Traditional in situ surveys are laborious and only cover small areas but drones offer an opportunity to scale observations more broadly, especially if the holothurians can be automatically detected in drone imagery using deep learning algorithms. We adapted the object detection algorithm YOLOv3 to detect holothurians from drone imagery at Hideaway Bay, Queensland, Australia. We successfully detected 11,462 of 12,956 individuals over 2.7ha with an average density of 0.5 individual/m2. We tested a range of hyperparameters to determine the optimal detector performance and achieved 0.855 mAP, 0.82 precision, 0.83 recall, and 0.82 F1 score. We found as few as ten labelled drone images was sufficient to train an acceptable detection model (0.799 mAP). Our results illustrate the potential of using small, affordable drones with direct implementation of open-source object detection models to survey holothurians and other shallow water sessile species.},
DOI = {10.3390/drones5020028}
}



@Article{rs13081557,
AUTHOR = {Balsi, Marco and Moroni, Monica and Chiarabini, Valter and Tanda, Giovanni},
TITLE = {High-Resolution Aerial Detection of Marine Plastic Litter by Hyperspectral Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1557},
URL = {https://www.mdpi.com/2072-4292/13/8/1557},
ISSN = {2072-4292},
ABSTRACT = {An automatic custom-made procedure is developed to identify macroplastic debris loads in coastal and marine environment, through hyperspectral imaging from unmanned aerial vehicles (UAVs). Results obtained during a remote-sensing field campaign carried out in the seashore of Sassari (Sardinia, Italy) are presented. A push-broom-sensor-based spectral device, carried onboard a DJI Matrice 600 drone, was employed for the acquisition of spectral data in the range 900−1700 nm. The hyperspectral platform was realized by assembling commercial devices, whereas algorithms for mosaicking, post-flight georeferencing, and orthorectification of the acquired images were developed in-house. Generation of the hyperspectral cube was based on mosaicking visible-spectrum images acquired synchronously with the hyperspectral lines, by performing correlation-based registration and applying the same translations, rotations, and scale changes to the hyperspectral data. Plastics detection was based on statistically relevant feature selection and Linear Discriminant Analysis, trained on a manually labeled sample. The results obtained from the inspection of either the beach site or the sea water facing the beach clearly show the successful separate identification of polyethylene (PE) and polyethylene terephthalate (PET) objects through the post-processing data treatment based on the developed classifier algorithm. As a further implementation of the procedure described, direct real-time processing, by an embedded computer carried onboard the drone, permitted the immediate plastics identification (and visual inspection in synchronized images) during the UAV survey, as documented by short video sequences provided in this research paper.},
DOI = {10.3390/rs13081557}
}



@Article{s21082834,
AUTHOR = {Kazaz, Billur and Poddar, Subhadipto and Arabi, Saeed and Perez, Michael A. and Sharma, Anuj and Whitman, J. Blake},
TITLE = {Deep Learning-Based Object Detection for Unmanned Aerial Systems (UASs)-Based Inspections of Construction Stormwater Practices},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2834},
URL = {https://www.mdpi.com/1424-8220/21/8/2834},
PubMedID = {33920610},
ISSN = {1424-8220},
ABSTRACT = {Construction activities typically create large amounts of ground disturbance, which can lead to increased rates of soil erosion. Construction stormwater practices are used on active jobsites to protect downstream waterbodies from offsite sediment transport. Federal and state regulations require routine pollution prevention inspections to ensure that temporary stormwater practices are in place and performing as intended. This study addresses the existing challenges and limitations in the construction stormwater inspections and presents a unique approach for performing unmanned aerial system (UAS)-based inspections. Deep learning-based object detection principles were applied to identify and locate practices installed on active construction sites. The system integrates a post-processing stage by clustering results. The developed framework consists of data preparation with aerial inspections, model training, validation of the model, and testing for accuracy. The developed model was created from 800 aerial images and was used to detect four different types of construction stormwater practices at 100% accuracy on the Mean Average Precision (MAP) with minimal false positive detections. Results indicate that object detection could be implemented on UAS-acquired imagery as a novel approach to construction stormwater inspections and provide accurate results for site plan comparisons by rapidly detecting the quantity and location of field-installed stormwater practices.},
DOI = {10.3390/s21082834}
}



@Article{s21082839,
AUTHOR = {Poudel, Sabitri and Moh, Sangman},
TITLE = {Hybrid Path Planning for Efficient Data Collection in UAV-Aided WSNs for Emergency Applications},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2839},
URL = {https://www.mdpi.com/1424-8220/21/8/2839},
PubMedID = {33920627},
ISSN = {1424-8220},
ABSTRACT = {In unmanned aerial vehicle (UAV)-aided wireless sensor networks (UWSNs), a UAV is employed as a mobile sink to gather data from sensor nodes. Incorporating UAV helps prolong the network lifetime and avoid the energy-hole problem faced by sensor networks. In emergency applications, timely data collection from sensor nodes and transferal of the data to the base station (BS) is a prime requisite. The timely and safe path of UAV is one of the fundamental premises for effective UWSN operations. It is essential and challenging to identify a suitable path in an environment comprising various obstacles and to ensure that the path can efficiently reach the target point. This paper proposes a hybrid path planning (HPP) algorithm for efficient data collection by assuring the shortest collision-free path for UAV in emergency environments. In the proposed HPP scheme, the probabilistic roadmap (PRM) algorithm is used to design the shortest trajectory map and the optimized artificial bee colony (ABC) algorithm to improve different path constraints in a three-dimensional environment. Our simulation results show that the proposed HPP outperforms the PRM and conventional ABC schemes significantly in terms of flight time, energy consumption, convergence time, and flight path.},
DOI = {10.3390/s21082839}
}



@Article{rs13081562,
AUTHOR = {Ge, Xiangyu and Ding, Jianli and Jin, Xiuliang and Wang, Jingzhe and Chen, Xiangyue and Li, Xiaohang and Liu, Jie and Xie, Boqiang},
TITLE = {Estimating Agricultural Soil Moisture Content through UAV-Based Hyperspectral Images in the Arid Region},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1562},
URL = {https://www.mdpi.com/2072-4292/13/8/1562},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle (UAV)-based hyperspectral remote sensing is an important monitoring technology for the soil moisture content (SMC) of agroecological systems in arid regions. This technology develops precision farming and agricultural informatization. However, hyperspectral data are generally used in data mining. In this study, UAV-based hyperspectral imaging data with a resolution o 4 cm and totaling 70 soil samples (0–10 cm) were collected from farmland (2.5 × 104 m2) near Fukang City, Xinjiang Uygur Autonomous Region, China. Four estimation strategies were tested: the original image (strategy I), first- and second-order derivative methods (strategy II), the fractional-order derivative (FOD) technique (strategy III), and the optimal fractional order combined with the optimal multiband indices (strategy IV). These strategies were based on the eXtreme Gradient Boost (XGBoost) algorithm, with the aim of building the best estimation model for agricultural SMC in arid regions. The results demonstrated that FOD technology could effectively mine information (with an absolute maximum correlation coefficient of 0.768). By comparison, strategy IV yielded the best estimates out of the methods tested (R2val = 0.921, RMSEP = 1.943, and RPD = 2.736) for the SMC. The model derived from the order of 0.4 within strategy IV worked relatively well among the different derivative methods (strategy I, II, and III). In conclusion, the combination of FOD technology and the optimal multiband indices generated a highly accurate model within the XGBoost algorithm for SMC estimation. This research provided a promising data mining approach for UAV-based hyperspectral imaging data.},
DOI = {10.3390/rs13081562}
}



@Article{s21082835,
AUTHOR = {Hashima, Sherief and Hatano, Kohei and Kasban, Hany and Mahmoud Mohamed, Ehab},
TITLE = {Wi-Fi Assisted Contextual Multi-Armed Bandit for Neighbor Discovery and Selection in Millimeter Wave Device to Device Communications},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2835},
URL = {https://www.mdpi.com/1424-8220/21/8/2835},
PubMedID = {33920717},
ISSN = {1424-8220},
ABSTRACT = {The unique features of millimeter waves (mmWaves) motivate its leveraging to future, beyond-fifth-generation/sixth-generation (B5G/6G)-based device-to-device (D2D) communications. However, the neighborhood discovery and selection (NDS) problem still needs intelligent solutions due to the trade-off of investigating adjacent devices for the optimum device choice against the crucial beamform training (BT) overhead. In this paper, by making use of multiband (μW/mmWave) standard devices, the mmWave NDS problem is addressed using machine-learning-based contextual multi-armed bandit (CMAB) algorithms. This is done by leveraging the context information of Wi-Fi signal characteristics, i.e., received signal strength (RSS), mean, and variance, to further improve the NDS method. In this setup, the transmitting device acts as the player, the arms are the candidate mmWave D2D links between that device and its neighbors, while the reward is the average throughput. We examine the NDS’s primary trade-off and the impacts of the contextual information on the total performance. Furthermore, modified energy-aware linear upper confidence bound (EA-LinUCB) and contextual Thomson sampling (EA-CTS) algorithms are proposed to handle the problem through reflecting the nearby devices’ withstanding battery levels, which simulate real scenarios. Simulation results ensure the superior efficiency of the proposed algorithms over the single band (mmWave) energy-aware noncontextual MAB algorithms (EA-UCB and EA-TS) and traditional schemes regarding energy efficiency and average throughput with a reasonable convergence rate.},
DOI = {10.3390/s21082835}
}



@Article{app11083648,
AUTHOR = {Jimenez, Jose M. and Parra, Lorena and García, Laura and Lloret, Jaime and Mauri, Pedro V. and Lorenz, Pascal},
TITLE = {New Protocol and Architecture for a Wastewater Treatment System Intended for Irrigation},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {3648},
URL = {https://www.mdpi.com/2076-3417/11/8/3648},
ISSN = {2076-3417},
ABSTRACT = {Water quality may be affected by aspects such as pollution from industries, agricultural fertilizers and pesticides, and waste produced by humans. This contamination can affect the produce of the fields irrigated by untreated water. Therefore, it is necessary to add a treatment process in irrigation systems. In this paper, an architecture, communication protocol, and a data analysis algorithm for a wastewater treatment system intended for irrigation are presented. Our system includes a smart group-based wireless sensor network that is able to detect high salinity levels and pollution stains, such as oil spills. When contamination is detected, the water is led into auxiliary canals that perform the biosorption process to treat the water and dump it back into the main canal. Simulations were performed to assess the amount of data stored on the secure digital (SD) card, the consumed bandwidth, and the energy consumption of our proposal. The results show the system has a low bandwidth consumption with a maximum of 2.58 kbps for the setting of two daily data transmissions of the node in the last auxiliary canal. Furthermore, it can sustain the energy consumption in adverse conditions, where the node with the highest energy consumption reaches the lowest energy value of 12,320 mW/h.},
DOI = {10.3390/app11083648}
}



@Article{su13084511,
AUTHOR = {Haque, Amlan and Islam, Nahina and Samrat, Nahidul Hoque and Dey, Shuvashis and Ray, Biplob},
TITLE = {Smart Farming through Responsible Leadership in Bangladesh: Possibilities, Opportunities, and Beyond},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {4511},
URL = {https://www.mdpi.com/2071-1050/13/8/4511},
ISSN = {2071-1050},
ABSTRACT = {Smart farming has the potential to overcome the challenge of 2050 to feed 10 billion people. Both artificial intelligence (AI) and the internet of things (IoT) have become critical prerequisites to smart farming due to their high interoperability, sensors, and cutting-edge technologies. Extending the role of responsible leadership, this paper proposes an AI and IoT based smart farming system in Bangladesh. With a comprehensive literature review, this paper counsels the need to go beyond the simple application of traditional farming and irrigation practices and recommends implementing smart farming enabling responsible leadership to uphold sustainable agriculture. It contributes to the current literature of smart farming in several ways. First, this paper helps to understand the prospect and challenges of both AI and IoT and the requirement of smart farming in a nonwestern context. Second, it clarifies the interventions of responsible leadership into Bangladesh’s agriculture sector and justifies the demand for sustainable smart farming. Third, this paper is a step forward to explore future empirical studies for the effective and efficient use of AI and IoT to adopt smart farming. Finally, this paper will help policymakers to take responsible initiatives to plan and apply smart farming in a developing economy like Bangladesh.},
DOI = {10.3390/su13084511}
}



@Article{s21082861,
AUTHOR = {Bukowiecki, Josephine and Rose, Till and Kage, Henning},
TITLE = {Sentinel-2 Data for Precision Agriculture?—A UAV-Based Assessment},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2861},
URL = {https://www.mdpi.com/1424-8220/21/8/2861},
PubMedID = {33921631},
ISSN = {1424-8220},
ABSTRACT = {An approach of exploiting and assessing the potential of Sentinel-2 data in the context of precision agriculture by using data from an unmanned aerial vehicle (UAV) is presented based on a four-year dataset. An established model for the estimation of the green area index (GAI) of winter wheat from a UAV-based multispectral camera was used to calibrate the Sentinel-2 data. Large independent datasets were used for evaluation purposes. Furthermore, the potential of the satellite-based GAI-predictions for crop monitoring and yield prediction was tested. Therefore, the total absorbed photosynthetic radiation between spring and harvest was calculated with satellite and UAV data and correlated with the final grain yield. Yield maps at the same resolution were generated by combining yield data on a plot level with a UAV-based crop coverage map. The best tested model for satellite-based GAI-prediction was obtained by combining the near-, infrared- and Red Edge-waveband in a simple ratio (R2 = 0.82, mean absolute error = 0.52 m2/m2). Yet, the Sentinel-2 data seem to depict average GAI-developments through the seasons, rather than to map site-specific variations at single acquisition dates. The results show that the lower information content of the satellite-based crop monitoring might be mainly traced back to its coarser Red Edge-band. Additionally, date-specific effects within the Sentinel-2 data were detected. Due to cloud coverage, the temporal resolution was found to be unsatisfactory as well. These results emphasize the need for further research on the applicability of the Sentinel-2 data and a cautious use in the context of precision agriculture.},
DOI = {10.3390/s21082861}
}



@Article{s21082862,
AUTHOR = {Yanes Luis, Samuel and Gutiérrez-Reina, Daniel and Toral Marín, Sergio},
TITLE = {A Dimensional Comparison between Evolutionary Algorithm and Deep Reinforcement Learning Methodologies for Autonomous Surface Vehicles with Water Quality Sensors},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2862},
URL = {https://www.mdpi.com/1424-8220/21/8/2862},
PubMedID = {33921649},
ISSN = {1424-8220},
ABSTRACT = {The monitoring of water resources using Autonomous Surface Vehicles with water-quality sensors has been a recent approach due to the advances in unmanned transportation technology. The Ypacaraí Lake, the biggest water resource in Paraguay, suffers from a major contamination problem because of cyanobacteria blooms. In order to supervise the blooms using these on-board sensor modules, a Non-Homogeneous Patrolling Problem (a NP-hard problem) must be solved in a feasible amount of time. A dimensionality study is addressed to compare the most common methodologies, Evolutionary Algorithm and Deep Reinforcement Learning, in different map scales and fleet sizes with changes in the environmental conditions. The results determined that Deep Q-Learning overcomes the evolutionary method in terms of sample-efficiency by 50–70% in higher resolutions. Furthermore, it reacts better than the Evolutionary Algorithm in high space-state actions. In contrast, the evolutionary approach shows a better efficiency in lower resolutions and needs fewer parameters to synthesize robust solutions. This study reveals that Deep Q-learning approaches exceed in efficiency for the Non-Homogeneous Patrolling Problem but with many hyper-parameters involved in the stability and convergence.},
DOI = {10.3390/s21082862}
}



@Article{s21082864,
AUTHOR = {Zhang, Yuanping and Huang, Xiumei and Yang, Ming},
TITLE = {A Hybrid Visual Tracking Algorithm Based on SOM Network and Correlation Filter},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2864},
URL = {https://www.mdpi.com/1424-8220/21/8/2864},
PubMedID = {33921720},
ISSN = {1424-8220},
ABSTRACT = {To meet the challenge of video target tracking, based on a self-organization mapping network (SOM) and correlation filter, a long-term visual tracking algorithm is proposed. Objects in different videos or images often have completely different appearance, therefore, the self-organization mapping neural network with the characteristics of signal processing mechanism of human brain neurons is used to perform adaptive and unsupervised features learning. A reliable method of robust target tracking is proposed, based on multiple adaptive correlation filters with a memory function of target appearance at the same time. Filters in our method have different updating strategies and can carry out long-term tracking cooperatively. The first is the displacement filter, a kernelized correlation filter that combines contextual characteristics to precisely locate and track targets. Secondly, the scale filters are used to predict the changing scale of a target. Finally, the memory filter is used to maintain the appearance of the target in long-term memory and judge whether the target has failed to track. If the tracking fails, the incremental learning detector is used to recover the target tracking in the way of sliding window. Several experiments show that our method can effectively solve the tracking problems such as severe occlusion, target loss and scale change, and is superior to the state-of-the-art methods in the aspects of efficiency, accuracy and robustness.},
DOI = {10.3390/s21082864}
}



@Article{joitmc7020115,
AUTHOR = {Didenko, Nikolay and Skripnuk, Djamilia and Kikkas, Kseniia and Kalinina, Olga and Kosinski, Eryk},
TITLE = {The Impact of Digital Transformation on the Micrologistic System, and the Open Innovation in Logistics},
JOURNAL = {Journal of Open Innovation: Technology, Market, and Complexity},
VOLUME = {7},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {115},
URL = {https://www.mdpi.com/2199-8531/7/2/115},
ISSN = {2199-8531},
ABSTRACT = {This paper investigates the effects of digital production and information technologies on the development of logistic systems of different kinds: megalogistic, macrologistic, and micrologistic. The notions of a logistic system and types of logistic systems imply that logistics is considered in its broad sense as a modern methodology for managing all types of flows that appear in the process of socioeconomic activities of society and business: material, information, energy, financial and labor flows. The methodology discussed in this paper gives the answer to the question of what impact digital production and information technologies have on the development of various types of logistic systems. The methodology includes building a mathematical model in which the endogenous variables of the model reflect the resulting variables of the logistic system, while the exogenous variables reflect digital production and information technologies. The mathematical model is a system of interdependent dynamic econometric equations. Each equation is an autoregressive distributed lags model. In the model, the current values of an endogenous variable depend on their previous values, as well as on the current and previous values of other endogenous and exogenous variables. The novelty of the research is in the developed methodology for a comprehensive assessment of the impact made by digitalization on a totality of the interrelated and interdependent resulting indicators of the logistic system. A comprehensive assessment of the impact made by digitalization on a totality of interrelated and interdependent indicators of the logistic system is understood as a change in the indicators of the logistic system due to the effect of digitalization. The proposed methodology for a comprehensive assessment was empirically tested for Salesforce company.},
DOI = {10.3390/joitmc7020115}
}



@Article{rs13081578,
AUTHOR = {Xiao, Ting and Huang, Wei and Deng, Yunkai and Tian, Weiming and Sha, Yonglian},
TITLE = {Long-Term and Emergency Monitoring of Zhongbao Landslide Using Space-Borne and Ground-Based InSAR},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1578},
URL = {https://www.mdpi.com/2072-4292/13/8/1578},
ISSN = {2072-4292},
ABSTRACT = {This work presents the ideal combination of space-borne and ground-based (GB) Interferometric Synthetic Aperture Radar (InSAR) applications. In the absence of early investigation reporting and specialized monitoring, the Zhongbao landslide unexpectedly occurred on 25 July 2020, forming a barrier lake that caused an emergency. As an emergency measure, the GB-InSAR system was installed 1.8 km opposite the landslide to assess real-time cumulative deformation with a monitoring frequency of 3 min. A zone of strong deformation was detected, with 178 mm deformation accumulated within 15 h, and then a successful emergency warning was issued to evacuate on-site personnel. Post-event InSAR analysis of 19 images acquired by the ESA Sentinel-1 from December 2019 to August 2020 revealed that the landslide started in March 2020. However, the deformation time series obtained from satellite InSAR did not show any signs that the landslide had occurred. The results suggest that satellite InSAR is effective for mapping unstable areas but is not qualified for rapid landslide monitoring and timely warning. The GB-InSAR system performs well in monitoring and providing early warning, even with dense vegetation on the landslide. The results show the shortcomings of satellite InSAR and GB-InSAR and a clearer understanding of the necessity of combining multiple monitoring methods.},
DOI = {10.3390/rs13081578}
}



@Article{s21082868,
AUTHOR = {Cheng, Gong and Wei, Huangfu},
TITLE = {Virtual Angle Boundary-Aware Particle Swarm Optimization to Maximize the Coverage of Directional Sensor Networks},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2868},
URL = {https://www.mdpi.com/1424-8220/21/8/2868},
PubMedID = {33921843},
ISSN = {1424-8220},
ABSTRACT = {With the transition of the mobile communication networks, the network goal of the Internet of everything further promotes the development of the Internet of Things (IoT) and Wireless Sensor Networks (WSNs). Since the directional sensor has the performance advantage of long-term regional monitoring, how to realize coverage optimization of Directional Sensor Networks (DSNs) becomes more important. The coverage optimization of DSNs is usually solved for one of the variables such as sensor azimuth, sensing radius, and time schedule. To reduce the computational complexity, we propose an optimization coverage scheme with a boundary constraint of eliminating redundancy for DSNs. Combined with Particle Swarm Optimization (PSO) algorithm, a Virtual Angle Boundary-aware Particle Swarm Optimization (VAB-PSO) is designed to reduce the computational burden of optimization problems effectively. The VAB-PSO algorithm generates the boundary constraint position between the sensors according to the relationship among the angles of different sensors, thus obtaining the boundary of particle search and restricting the search space of the algorithm. Meanwhile, different particles search in complementary space to improve the overall efficiency. Experimental results show that the proposed algorithm with a boundary constraint can effectively improve the coverage and convergence speed of the algorithm.},
DOI = {10.3390/s21082868}
}



@Article{rs13081588,
AUTHOR = {Guillaume, Annie S. and Leempoel, Kevin and Rochat, Estelle and Rogivue, Aude and Kasser, Michel and Gugerli, Felix and Parisod, Christian and Joost, Stéphane},
TITLE = {Multiscale Very High Resolution Topographic Models in Alpine Ecology: Pros and Cons of Airborne LiDAR and Drone-Based Stereo-Photogrammetry Technologies},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1588},
URL = {https://www.mdpi.com/2072-4292/13/8/1588},
ISSN = {2072-4292},
ABSTRACT = {The vulnerability of alpine environments to climate change presses an urgent need to accurately model and understand these ecosystems. Popularity in the use of digital elevation models (DEMs) to derive proxy environmental variables has increased over the past decade, particularly as DEMs are relatively cheaply acquired at very high resolutions (VHR; &lt;1 m spatial resolution). Here, we implement a multiscale framework and compare DEM-derived variables produced by Light Detection and Ranging (LiDAR) and stereo-photogrammetry (PHOTO) methods, with the aim of assessing their relevance and utility in species distribution modelling (SDM). Using a case study on the arctic-alpine plant, Arabis alpina, in two valleys in the western Swiss Alps, we show that both LiDAR and PHOTO technologies can be relevant for producing DEM-derived variables for use in SDMs. We demonstrate that PHOTO DEMs, up to a spatial resolution of at least 1 m, rivalled the accuracy of LiDAR DEMs, largely owing to the customizability of PHOTO DEMs to the study sites compared to commercially available LiDAR DEMs. We obtained DEMs at spatial resolutions of 6.25 cm–8 m for PHOTO and 50 cm–32 m for LiDAR, where we determined that the optimal spatial resolutions of DEM-derived variables in SDM were between 1 and 32 m, depending on the variable and site characteristics. We found that the reduced extent of PHOTO DEMs altered the calculations of all derived variables, which had particular consequences on their relevance at the site with heterogenous terrain. However, for the homogenous site, SDMs based on PHOTO-derived variables generally had higher predictive powers than those derived from LiDAR at matching resolutions. From our results, we recommend carefully considering the required DEM extent to produce relevant derived variables. We also advocate implementing a multiscale framework to appropriately assess the ecological relevance of derived variables, where we caution against the use of VHR-DEMs finer than 50 cm in such studies.},
DOI = {10.3390/rs13081588}
}



@Article{rs13081595,
AUTHOR = {Li, Chunhua and Zhou, Lizhi and Xu, Wenbin},
TITLE = {Estimating Aboveground Biomass Using Sentinel-2 MSI Data and Ensemble Algorithms for Grassland in the Shengjin Lake Wetland, China},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1595},
URL = {https://www.mdpi.com/2072-4292/13/8/1595},
ISSN = {2072-4292},
ABSTRACT = {Wetland vegetation aboveground biomass (AGB) directly indicates wetland ecosystem health and is critical for water purification, carbon cycle, and biodiversity conservation. Accurate AGB estimation is essential for the monitoring and supervision of ecosystems, especially in seasonal floodplain wetlands. This paper explored the capability of spectral and texture features from the Sentinel-2 Multispectral Instrument (MSI) for modeling grassland AGB using random forest (RF) and extreme gradient boosting (XGBoost) algorithms in Shengjin Lake wetland (a Ramsar site). We use five-fold cross-validation to verify the model effectiveness. The results indicated that the RF and XGBoost models had a robust and efficient performance (with root mean square error (RMSE) of 126.571 g·m−2 and R2 of 0.844 for RF, RMSE of 112.425 g·m−2 and R2 of 0.869 for XGBoost), and the XGBoost models, by contrast, performed better. Both traditional and red-edge vegetation indices (VIs) obtained satisfactory results of AGB estimation (RMSE = 127.936 g·m−2, RMSE = 125.879 g·m−2 in XGBoost models, respectively), with the red-edge VIs contributed more to the AGB models. Moreover, we selected eight gray-level co-occurrence matrix (GLCM) textures calculated by four processing window sizes using the mean value of four offsets, and further analyzed the results of three analysis sets. Textures derived from traditional and red-edge bands using a 7 × 7 window size performed better in biomass estimation. This finding suggested that textures derived from the traditional bands were as important as the red-edge bands. The introduction of textures moderately improved the accuracy of modeling AGB, whereas the use of textures alo ne was not satisfactory. This research demonstrated that using the Sentinel-2 MSI and the two ensemble algorithms is an effective method for long-term dynamic monitoring and assessment of grass AGB in seasonal floodplain wetlands, which can support sustainable management and carbon accounting of wetland ecosystems.},
DOI = {10.3390/rs13081595}
}



@Article{rs13081596,
AUTHOR = {Zhong, Bo and Yang, Aixia and Jue, Kunsheng and Wu, Junjun},
TITLE = {Long Time Series High-Quality and High-Consistency Land Cover Mapping Based on Machine Learning Method at Heihe River Basin},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1596},
URL = {https://www.mdpi.com/2072-4292/13/8/1596},
ISSN = {2072-4292},
ABSTRACT = {Long time series of land cover changes (LCCs) are critical in the analysis of long-term climate, environmental, and ecological changes. Although several moderate to fine resolution global land cover datasets have been publicly released and they show strong consistency at the global scale, they have large deviations at the regional scale; furthermore, high-quality land cover datasets from before 2000 are not available and the classification consistency among different datasets is not very good. Thus, long time series of land cover datasets with high quality and consistency are in great demand but they are still unavailable, even at the regional scale. The Landsat series of satellite imagery composed of eight successive satellites can be traced back to 1972 and it is, therefore, possible to produce a long time series land cover dataset. In addition, the newly available satellite data have the capability to construct time series satellite images and a time series analysis method such as LCMM can be employed for making high-quality land cover datasets. Therefore, by taking the advantages of the two categories of satellite data, we proposed a new time series land cover mapping method based on machine learning and it, thereafter, is applied to Heihe River Basin (HRB) for verification purposes. Firstly, the high-quality land cover datasets at HRB from 2011–2015, which were retrieved using the LCMM method, are used for quickly and accurately making training samples. Secondly, a strategy for transferring the training samples after 2011 to earlier years is established. Thirdly, the random forest model is employed to train the selected yearly samples and a land cover map for every year is subsequently made. Finally, comprehensive analysis and validation are carried out for evaluation. In this study, a long time series land cover dataset including 1986, 1990, 1995, 2000, 2005, 2010, 2011, 2012, 2013, 2014, and 2015 is finally made and an average precision of about 90% is achieved. It is the longest time series land cover map with 30 m resolution at HRB and the dataset has good time continuity and stability.},
DOI = {10.3390/rs13081596}
}



@Article{rs13081599,
AUTHOR = {Seitsonen, Oula and Ikäheimo, Janne},
TITLE = {Detecting Archaeological Features with Airborne Laser Scanning in the Alpine Tundra of Sápmi, Northern Finland},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1599},
URL = {https://www.mdpi.com/2072-4292/13/8/1599},
ISSN = {2072-4292},
ABSTRACT = {Open access airborne laser scanning (ALS) data have been available in Finland for over a decade and have been actively applied by the Finnish archaeologists in that time. The low resolution of this laser scanning 2008–2019 dataset (0.5 points/m2), however, has hindered its usability for archaeological prospection. In the summer of 2020, the situation changed markedly, when the Finnish National Land Survey started a new countrywide ALS survey with a higher resolution of 5 points/m2. In this paper we present the first results of applying this newly available ALS material for archaeological studies. Finnish LIDARK consortium has initiated the development of semi-automated approaches for visualizing, detecting, and analyzing archaeological features with this new dataset. Our first case studies are situated in the Alpine tundra environment of Sápmi in northern Finland, and the assessed archaeological features range from prehistoric sites to indigenous Sámi reindeer herding features and Second Word War-era German military structures. Already the initial analyses of the new ALS-5p data show their huge potential for locating, mapping, and assessing archaeological material. These results also suggest an imminent burst in the number of known archaeological sites, especially in the poorly accessible and little studied northern wilderness areas, when more data become available.},
DOI = {10.3390/rs13081599}
}



@Article{app11093737,
AUTHOR = {Hrúz, Michal and Bugaj, Martin and Novák, Andrej and Kandera, Branislav and Badánik, Benedikt},
TITLE = {The Use of UAV with Infrared Camera and RFID for Airframe Condition Monitoring},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {3737},
URL = {https://www.mdpi.com/2076-3417/11/9/3737},
ISSN = {2076-3417},
ABSTRACT = {The new progressive smart technologies announced in the fourth industrial revolution in aviation—Aviation 4.0—represent new possibilities and big challenges in aircraft maintenance processes. The main benefit of these technologies is the possibility to monitor, transfer, store, and analyze huge datasets. Based on analysis outputs, there is a possibility to improve current preventive maintenance processes and implement predictive maintenance processes. These solutions lower the downtime, save manpower, and extend the components’ lifetime; thus, the maximum effectivity and safety is achieved. The article deals with the possible implementation of an unmanned aerial vehicle (UAV) with an infrared camera and Radio Frequency Identification (RFID) as two of the smart hangar technologies for airframe condition monitoring. The presented implementations of smart technologies follow up the specific results of a case study focused on trainer aircraft failure monitoring and its impact on maintenance strategy changes. The case study failure indexes show the critical parts of aircraft that are subjected to damage the most. The aim of the article was to justify the need for thorough monitoring of critical parts of the aircraft and then analyze and propose a more effective and the most suitable form of technical condition monitoring of aircraft critical parts. The article describes the whole process of visual inspection performed by an unmanned aerial vehicle (UAV) with an IR camera and its related processes; in addition, it covers the possible usage of RFID tags as a labeling tool supporting the visual inspection. The implementations criteria apply to the repair and overhaul small aircraft maintenance organization, and later, it can also increase operational efficiency. The final suggestions describe the possible usage of proposed solutions, their main benefits, and also the limitations of their implementations in maintenance of trainer aircraft.},
DOI = {10.3390/app11093737}
}



@Article{rs13091619,
AUTHOR = {Yan, Bin and Fan, Pan and Lei, Xiaoyan and Liu, Zhijie and Yang, Fuzeng},
TITLE = {A Real-Time Apple Targets Detection Method for Picking Robot Based on Improved YOLOv5},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1619},
URL = {https://www.mdpi.com/2072-4292/13/9/1619},
ISSN = {2072-4292},
ABSTRACT = {The apple target recognition algorithm is one of the core technologies of the apple picking robot. However, most of the existing apple detection algorithms cannot distinguish between the apples that are occluded by tree branches and occluded by other apples. The apples, grasping end-effector and mechanical picking arm of the robot are very likely to be damaged if the algorithm is directly applied to the picking robot. Based on this practical problem, in order to automatically recognize the graspable and ungraspable apples in an apple tree image, a light-weight apple targets detection method was proposed for picking robot using improved YOLOv5s. Firstly, BottleneckCSP module was improved designed to BottleneckCSP-2 module which was used to replace the BottleneckCSP module in backbone architecture of original YOLOv5s network. Secondly, SE module, which belonged to the visual attention mechanism network, was inserted to the proposed improved backbone network. Thirdly, the bonding fusion mode of feature maps, which were inputs to the target detection layer of medium size in the original YOLOv5s network, were improved. Finally, the initial anchor box size of the original network was improved. The experimental results indicated that the graspable apples, which were unoccluded or only occluded by tree leaves, and the ungraspable apples, which were occluded by tree branches or occluded by other fruits, could be identified effectively using the proposed improved network model in this study. Specifically, the recognition recall, precision, mAP and F1 were 91.48%, 83.83%, 86.75% and 87.49%, respectively. The average recognition time was 0.015 s per image. Contrasted with original YOLOv5s, YOLOv3, YOLOv4 and EfficientDet-D0 model, the mAP of the proposed improved YOLOv5s model increased by 5.05%, 14.95%, 4.74% and 6.75% respectively, the size of the model compressed by 9.29%, 94.6%, 94.8% and 15.3% respectively. The average recognition speeds per image of the proposed improved YOLOv5s model were 2.53, 1.13 and 3.53 times of EfficientDet-D0, YOLOv4 and YOLOv3 and model, respectively. The proposed method can provide technical support for the real-time accurate detection of multiple fruit targets for the apple picking robot.},
DOI = {10.3390/rs13091619}
}



@Article{rs13091629,
AUTHOR = {Kwak, Geun-Ho and Park, Chan-won and Lee, Kyung-do and Na, Sang-il and Ahn, Ho-yong and Park, No-Wook},
TITLE = {Potential of Hybrid CNN-RF Model for Early Crop Mapping with Limited Input Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1629},
URL = {https://www.mdpi.com/2072-4292/13/9/1629},
ISSN = {2072-4292},
ABSTRACT = {When sufficient time-series images and training data are unavailable for crop classification, features extracted from convolutional neural network (CNN)-based representative learning may not provide useful information to discriminate crops with similar spectral characteristics, leading to poor classification accuracy. In particular, limited input data are the main obstacles to obtain reliable classification results for early crop mapping. This study investigates the potential of a hybrid classification approach, i.e., CNN-random forest (CNN-RF), in the context of early crop mapping, that combines the automatic feature extraction capability of CNN with the superior discrimination capability of an RF classifier. Two experiments on incremental crop classification with unmanned aerial vehicle images were conducted to compare the performance of CNN-RF with that of CNN and RF with respect to the length of the time-series and training data sizes. When sufficient time-series images and training data were used for the classification, the accuracy of CNN-RF was slightly higher or comparable with that of CNN. In contrast, when fewer images and the smallest training data were used at the early crop growth stage, CNN-RF was substantially beneficial and the overall accuracy increased by maximum 6.7%p and 4.6%p in the two study areas, respectively, compared to CNN. This is attributed to its ability to discriminate crops from features with insufficient information using a more sophisticated classifier. The experimental results demonstrate that CNN-RF is an effective classifier for early crop mapping when only limited input images and training samples are available.},
DOI = {10.3390/rs13091629}
}



@Article{rs13091630,
AUTHOR = {Zhu, Yaohui and Yang, Guijun and Yang, Hao and Zhao, Fa and Han, Shaoyu and Chen, Riqiang and Zhang, Chengjian and Yang, Xiaodong and Liu, Miao and Cheng, Jinpeng and Zhao, Chunjiang},
TITLE = {Estimation of Apple Flowering Frost Loss for Fruit Yield Based on Gridded Meteorological and Remote Sensing Data in Luochuan, Shaanxi Province, China},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1630},
URL = {https://www.mdpi.com/2072-4292/13/9/1630},
ISSN = {2072-4292},
ABSTRACT = {With the increase in the frequency of extreme weather events in recent years, apple growing areas in the Loess Plateau frequently encounter frost during flowering. Accurately assessing the frost loss in orchards during the flowering period is of great significance for optimizing disaster prevention measures, market apple price regulation, agricultural insurance, and government subsidy programs. The previous research on orchard frost disasters is mainly focused on early risk warning. Therefore, to effectively quantify orchard frost loss, this paper proposes a frost loss assessment model constructed using meteorological and remote sensing information and applies this model to the regional-scale assessment of orchard fruit loss after frost. As an example, this article examines a frost event that occurred during the apple flowering period in Luochuan County, Northwestern China, on 17 April 2020. A multivariable linear regression (MLR) model was constructed based on the orchard planting years, the number of flowering days, and the chill accumulation before frost, as well as the minimum temperature and daily temperature difference on the day of frost. Then, the model simulation accuracy was verified using the leave-one-out cross-validation (LOOCV) method, and the coefficient of determination (R2), the root mean square error (RMSE), and the normalized root mean square error (NRMSE) were 0.69, 18.76%, and 18.76%, respectively. Additionally, the extended Fourier amplitude sensitivity test (EFAST) method was used for the sensitivity analysis of the model parameters. The results show that the simulated apple orchard fruit number reduction ratio is highly sensitive to the minimum temperature on the day of frost, and the chill accumulation and planting years before the frost, with sensitivity values of ≥0.74, ≥0.25, and ≥0.15, respectively. This research can not only assist governments in optimizing traditional orchard frost prevention measures and market price regulation but can also provide a reference for agricultural insurance companies to formulate plans for compensation after frost.},
DOI = {10.3390/rs13091630}
}



@Article{rs13091620,
AUTHOR = {Ge, Haixiao and Xiang, Haitao and Ma, Fei and Li, Zhenwang and Qiu, Zhengchao and Tan, Zhengzheng and Du, Changwen},
TITLE = {Estimating Plant Nitrogen Concentration of Rice through Fusing Vegetation Indices and Color Moments Derived from UAV-RGB Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1620},
URL = {https://www.mdpi.com/2072-4292/13/9/1620},
ISSN = {2072-4292},
ABSTRACT = {Estimating plant nitrogen concentration (PNC) has been conducted using vegetation indices (VIs) from UAV-based imagery, but color features have been rarely considered as additional variables. In this study, the VIs and color moments (color feature) were calculated from UAV-based RGB images, then partial least square regression (PLSR) and random forest regression (RF) models were established to estimate PNC through fusing VIs and color moments. The results demonstrated that the fusion of VIs and color moments as inputs yielded higher accuracies of PNC estimation compared to VIs or color moments as input; the RF models based on the combination of VIs and color moments (R2 ranging from 0.69 to 0.91 and NRMSE ranging from 0.07 to 0.13) showed similar performances to the PLSR models (R2 ranging from 0.68 to 0.87 and NRMSE ranging from 0.10 to 0.29); Among the top five important variables in the RF models, there was at least one variable which belonged to the color moments in different datasets, indicating the significant contribution of color moments in improving PNC estimation accuracy. This revealed the great potential of combination of RGB-VIs and color moments for the estimation of rice PNC.},
DOI = {10.3390/rs13091620}
}



@Article{jsan10020028,
AUTHOR = {Pourroostaei Ardakani, Saeid},
TITLE = {MINDS: Mobile Agent Itinerary Planning Using Named Data Networking in Wireless Sensor Networks},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {10},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {28},
URL = {https://www.mdpi.com/2224-2708/10/2/28},
ISSN = {2224-2708},
ABSTRACT = {Mobile agents have the potential to offer benefits, as they are able to either independently or cooperatively move throughout networks and collect/aggregate sensory data samples. They are programmed to autonomously move and visit sensory data stations through optimal paths, which are established according to the application requirements. However, mobile agent routing protocols still suffer heavy computation/communication overheads, lack of route planning accuracy and long-delay mobile agent migrations. For this, mobile agent route planning protocols aim to find the best-fitted paths for completing missions (e.g., data collection) with minimised delay, maximised performance and minimised transmitted traffic. This article proposes a mobile agent route planning protocol for sensory data collection called MINDS. The key goal of this MINDS is to reduce network traffic, maximise data robustness and minimise delay at the same time. This protocol utilises the Hamming distance technique to partition a sensor network into a number of data-centric clusters. In turn, a named data networking approach is used to form the cluster-heads as a data-centric, tree-based communication infrastructure. The mobile agents utilise a modified version of the Depth-First Search algorithm to move through the tree infrastructure according to a hop-count-aware fashion. As the simulation results show, MINDS reduces path length, reduces network traffic and increases data robustness as compared with two conventional benchmarks (ZMA and TBID) in dense and large wireless sensor networks.},
DOI = {10.3390/jsan10020028}
}



@Article{f12050517,
AUTHOR = {Kelley, Jason and Trofymow, John A. (Tony) and Metsaranta, Juha M. and Filipescu, Cosmin N. and Bone, Christopher},
TITLE = {Use of Multi-Temporal LiDAR to Quantify Fertilization Effects on Stand Volume and Biomass in Late-Rotation Coastal Douglas-Fir Forests},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {517},
URL = {https://www.mdpi.com/1999-4907/12/5/517},
ISSN = {1999-4907},
ABSTRACT = {Forest fertilization is common in coastal British Columbia as a means to increase wood production and potentially enhance carbon sequestration. Generally, the effects of fertilization are determined by measuring sample plots pre- and post-treatment, resulting in fertilization effects being determined for a limited portion of the treatment area. Applications of remote sensing-based enhanced forest inventories have allowed for estimations to expand to the wider forested area. However, these applications have not focused on monitoring the effects of silvicultural treatments. The objective of this research was to examine if a multi-temporal application of the LiDAR area-based method can be used to detect the fertilization effects on volume, biomass, and height in a second-growth Douglas-fir (Pseudotsuga menziesii) stand. The study area on Vancouver Island was fertilized in January 2007, and sample plots were established in 2011. LiDAR acquisitions were made in 2004, prior to fertilization, and in 2008, 2011, and 2016, covering both treated and untreated areas. A total of 29 paired LiDAR blocks, comprised of four 20 m resolution raster cells, were selected on either side of the fertilization boundary for analysis of the effects across several different stand types differing in the percentage of Douglas-fir, site index, and age. Random forest (RF) plot-level models were developed to estimate total stem volume and total stem biomass for each year of LiDAR acquisition using an area-based approach. Plot level results showed an increase in stem volume by 13% fertilized over control from 2005 to 2011, which was similar to a 14% increase in above-ground carbon stocks estimated using a tree-ring stand reconstruction approach. Plot-level RF models showed R2 values of 0.86 (volume) and 0.92 (biomass) with relative cross-validated root mean square errors of 12.5% (volume) and 11.9% (biomass). For both the sample plots and LiDAR blocks, statistical results indicated no significant differences in volume or biomass between treatments. However, significant differences in height increments were detected between treatments in LiDAR blocks. The results from this research highlight the promising potential for the use of enhanced forest inventory methods to rapidly expand the assessment of treatment effects beyond sample plots to the stand, block, or landscape level.},
DOI = {10.3390/f12050517}
}



@Article{rs13091634,
AUTHOR = {Wegmueller, Sarah A. and Townsend, Philip A.},
TITLE = {Astrape: A System for Mapping Severe Abiotic Forest Disturbances Using High Spatial Resolution Satellite Imagery and Unsupervised Classification},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1634},
URL = {https://www.mdpi.com/2072-4292/13/9/1634},
ISSN = {2072-4292},
ABSTRACT = {Severe forest disturbance events are becoming more common due to climate change and many forest managers rely heavily upon airborne surveys to map damage. However, when the damage is extensive, airborne assets are in high demand and it can take managers several weeks to account for the damage, delaying important management actions. While some satellite-based systems exist to help with this process, their spatial resolution or latency can be too large for the needs of managers, as evidenced by the continued use of airborne imaging. Here, we present a new, operational-focused system capable of leveraging high spatial and temporal resolution Sentinel-2 and Planet Dove imagery to support the mapping process. This system, which we have named Astrape (“ah-STRAH-pee”), uses recently developed techniques in image segmentation and machine learning to produce maps of damage in different forest types and regions without requiring ground data, greatly reducing the need for potentially dangerous airborne surveys and ground sampling needed to accurately quantify severe damage. Although some limited field work is required to verify results, similar to current operational systems, Astrape-produced maps achieved 78–86% accuracy with respect to damage severity when evaluated against reference data. We present the Astrape framework and demonstrate its flexibility and potential with four case studies depicting four different disturbance types—fire, hurricane, derecho and tornado—in three disparate regions of the United States. Astrape is capable of leveraging various sources of satellite imagery and offers an efficient, flexible and economical option for mapping severe damage in forests.},
DOI = {10.3390/rs13091634}
}



@Article{electronics10090999,
AUTHOR = {Azar, Ahmad Taher and Koubaa, Anis and Ali Mohamed, Nada and Ibrahim, Habiba A. and Ibrahim, Zahra Fathy and Kazim, Muhammad and Ammar, Adel and Benjdira, Bilel and Khamis, Alaa M. and Hameed, Ibrahim A. and Casalino, Gabriella},
TITLE = {Drone Deep Reinforcement Learning: A Review},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {999},
URL = {https://www.mdpi.com/2079-9292/10/9/999},
ISSN = {2079-9292},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) are increasingly being used in many challenging and diversified applications. These applications belong to the civilian and the military fields. To name a few; infrastructure inspection, traffic patrolling, remote sensing, mapping, surveillance, rescuing humans and animals, environment monitoring, and Intelligence, Surveillance, Target Acquisition, and Reconnaissance (ISTAR) operations. However, the use of UAVs in these applications needs a substantial level of autonomy. In other words, UAVs should have the ability to accomplish planned missions in unexpected situations without requiring human intervention. To ensure this level of autonomy, many artificial intelligence algorithms were designed. These algorithms targeted the guidance, navigation, and control (GNC) of UAVs. In this paper, we described the state of the art of one subset of these algorithms: the deep reinforcement learning (DRL) techniques. We made a detailed description of them, and we deduced the current limitations in this area. We noted that most of these DRL methods were designed to ensure stable and smooth UAV navigation by training computer-simulated environments. We realized that further research efforts are needed to address the challenges that restrain their deployment in real-life scenarios.},
DOI = {10.3390/electronics10090999}
}



@Article{inventions6020029,
AUTHOR = {Kashyap, Bhuwan and Kumar, Ratnesh},
TITLE = {Sensing Methodologies in Agriculture for Monitoring Biotic Stress in Plants Due to Pathogens and Pests},
JOURNAL = {Inventions},
VOLUME = {6},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {29},
URL = {https://www.mdpi.com/2411-5134/6/2/29},
ISSN = {2411-5134},
ABSTRACT = {Reducing agricultural losses is an effective way to sustainably increase agricultural output efficiency to meet our present and future needs for food, fiber, fodder, and fuel. Our ever-improving understanding of the ways in which plants respond to stress, biotic and abiotic, has led to the development of innovative sensing technologies for detecting crop stresses/stressors and deploying efficient measures. This article aims to present the current state of the methodologies applied in the field of agriculture towards the detection of biotic stress in crops. Key sensing methodologies for plant pathogen (or phytopathogen), as well as herbivorous insects/pests are presented, where the working principles are described, and key recent works discussed. The detection methods overviewed for phytopathogen-related stress identification include nucleic acid-based methods, immunological methods, imaging-based techniques, spectroscopic methods, phytohormone biosensing methods, monitoring methods for plant volatiles, and active remote sensing technologies. Whereas the pest-related sensing techniques include machine-vision-based methods, pest acoustic-emission sensors, and volatile organic compound-based stress monitoring methods. Additionally, Comparisons have been made between different sensing techniques as well as recently reported works, where the strengths and limitations are identified. Finally, the prospective future directions for monitoring biotic stress in crops are discussed.},
DOI = {10.3390/inventions6020029}
}



@Article{su13094735,
AUTHOR = {Mudau, Naledzani and Mhangara, Paidamwoyo},
TITLE = {Investigation of Informal Settlement Indicators in a Densely Populated Area Using Very High Spatial Resolution Satellite Imagery},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {4735},
URL = {https://www.mdpi.com/2071-1050/13/9/4735},
ISSN = {2071-1050},
ABSTRACT = {Automation of informal settlements detection using satellite imagery remains a challenging task in urban remote sensing. This is due to the fact that informal settlements vary in shape, size and spatial arrangement from one region to the other in some cases within a city. This paper investigated the methodology to detect informal settlements in a densely populated township by assessing informal settlement indicators observed from very high spatial resolution satellite imagery. We assessed twelve informal settlement indicators to determine the most effective indicators to distinguish between informal and informal classes. These indicators included the spectral indices first and second-order statistical measurements. In addition to the commonly used informal settlement indicators, we assessed the effectiveness of built-up area and iron cover. The GLCM textural measures performed poorly in separating informal and formal settlements compared to first-order statistics measurement and spectral indices. The built-up area index, coastal blue index and the first-order statistics mean measurements produced higher separability distance of informal and formal settlements. The iron index performed better in separating the two settlement types than the commonly used GLCM measure and NDVI. The proposed ruleset that uses the three features with the highest separability distance achieved producer and user accuracies of informal settlements of 95% and 82%, respectively. The results of this study will contribute towards developing methodologies to automatically detect informal settlements.},
DOI = {10.3390/su13094735}
}



@Article{math9090940,
AUTHOR = {Haghnazar Koochaksaraei, Roozbeh and Gadelha Guimarães, Frederico and Hamidzadeh, Babak and Hashemkhani Zolfani, Sarfaraz},
TITLE = {Visualization Method for Decision-Making: A Case Study in Bibliometric Analysis},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {940},
URL = {https://www.mdpi.com/2227-7390/9/9/940},
ISSN = {2227-7390},
ABSTRACT = {Data and information visualization have drawn an increasingly wide range of interest from several academic fields and industries. Concurrently, exploring a huge set of data to support feasible decisions needs an organized method of Multi-Criteria Decision Making (MCDM). The dramatic increasing of data producing during the past decade makes visualization necessary as a presentation layer on the top of MCDM process. This study aims to propose an integrated strategy to rank the alternatives in the dataset, by combining data, MCDM methods, and visualization layers. In fact, the well designed combination of Information Visualization and MCDM provides a more user-friendly approach than the traditional methods. We investigate a case study in bibliometric analyses, which have become an important dimension and tool for evaluating the impact and performance of researchers, departments, and universities. Hence, finding the best and most reliable papers, authors, and publishers considering diverse criteria is one of the important challenges in science world. Therefore, this text is presenting a new strategy on the bibliometric dataset as a case study and it demonstrates that this strategy can be more meaningful for the end users than the current tools. Finally, the presented simulations illustrate the performance and utilization of this combination. In other words, the researchers of this study could design and implement a tool that overcomes the biggest challenges of data analyzing and ranking via a combination of MCDM and visualization methodologies that can provide a tremendous amount of insight and information from a massive dataset in an efficient way.},
DOI = {10.3390/math9090940}
}



@Article{ijgi10050273,
AUTHOR = {Palander, Teijo and Kärhä, Kalle},
TITLE = {Utilization of Image, LiDAR and Gamma-Ray Information to Improve Environmental Sustainability of Cut-to-Length Wood Harvesting Operations in Peatlands: A Management Systems Perspective},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {273},
URL = {https://www.mdpi.com/2220-9964/10/5/273},
ISSN = {2220-9964},
ABSTRACT = {Forest industry corporations use quality management systems in their wood procurement operations. Spatial quality data are used to improve the quality of wood harvesting and to achieve environmental sustainability. Some studies have proposed new management systems based on LiDAR. The main aim of this study was to investigate how efficiently planning systems can select areas for wood harvesting a priori with respect to avoiding harvesting damage caused by forest machinery. A literature review revealed the possibility of using GISs, and case studies showed the criteria required to predict the required quality levels. Terrestrial LiDAR can be utilized in authorities’ quality control systems, but it is inefficient for preplanning without terrestrial gamma-ray data collection. Airborne LiDAR and gamma-ray information about forest soils can only be used for planning larger regions at the forest level because the information includes too much uncertainty to allow it to be used for planning in small-sized areas before wood harvesting operations involving wood procurement. In addition, airborne LiDAR is not accurate enough, even at the forest level, for the planning of wood procurement systems because wood harvesting remains challenging without field measurements. Therefore, there is a need for the use of manual ground-penetrating radar for determining the peat layer thickness and the depth to the groundwater table.},
DOI = {10.3390/ijgi10050273}
}



@Article{w13091171,
AUTHOR = {Wen, Chao and Zhan, Qingming and Zhan, De and Zhao, Huang and Yang, Chen},
TITLE = {Spatiotemporal Evolution of Lakes under Rapid Urbanization: A Case Study in Wuhan, China},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1171},
URL = {https://www.mdpi.com/2073-4441/13/9/1171},
ISSN = {2073-4441},
ABSTRACT = {The impact of urbanization on lakes in the urban context has aroused continuous attention from the public. However, the long-term evolution of lakes in a certain megacity and the heterogeneity of the spatial relationship between related influencing factors and lake changes are rarely discussed. The evolution of 58 lakes in Wuhan, China from 1990 to 2019 was analyzed from three aspects of lake area, lake landscape, and lakefront ecology, respectively. The Multi-Scale Geographic Weighted Regression model (MGWR) was then used to analyze the impact of related influencing factors on lake area change. The investigation found that the total area of 58 lakes decreased by 15.3%. A worsening trend was found regarding lake landscape with the five landscape indexes of lakes dropping; in contrast, lakefront ecology saw a gradual recovery with variations in the remote sensing ecological index (RSEI) in the lakefront area. The MGWR regression results showed that, on the whole, the increase in Gross Domestic Product (GDP), RSEI in the lakefront area, precipitation, and humidity contributed to lake restoration. The growth of population and the proportion of impervious surface (IS) in the lakefront area had different effects on different lakes. Specifically, the increase in GDP and population in all downtown districts and two suburb districts promoted lake restoration (e.g., Wu Lake), while the increase in population in Jiangxia led to lake loss. The growth of RSEI in lakefront area promoted the restoration of most lakes. A higher proportion of IS in lakefront area normally resulted in more lake loss. However, in some cases, the growth of IS was caused by lake conservation, which contributed to lake restoration (e.g., Tangxun Lake). The study reveals the spatiotemporal evolution of multiple lakes in Wuhan and provides a useful reference for the government to formulate differentiated protection policies.},
DOI = {10.3390/w13091171}
}



@Article{rs13091661,
AUTHOR = {Gargees, Rasha S. and Scott, Grant J.},
TITLE = {Large-Scale, Multiple Level-of-Detail Change Detection from Remote Sensing Imagery Using Deep Visual Feature Clustering},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1661},
URL = {https://www.mdpi.com/2072-4292/13/9/1661},
ISSN = {2072-4292},
ABSTRACT = {In the era of big data, where massive amounts of remotely sensed imagery can be obtained from various satellites accompanied by the rapid change in the surface of the Earth, new techniques for large-scale change detection are necessary to facilitate timely and effective human understanding of natural and human-made phenomena. In this research, we propose a chip-based change detection method that is enabled by using deep neural networks to extract visual features. These features are transformed into deep orthogonal visual features that are then clustered based on land cover characteristics. The resulting chip cluster memberships allow arbitrary level-of-detail change analysis that can also support irregular geospatial extent based agglomerations. The proposed methods naturally support cross-resolution temporal scenes without requiring normalization of the pixel resolution across scenes and without requiring pixel-level coregistration processes. This is achieved with configurable spatial locality comparisons between years, where the aperture of a unit of measure can be a single chip, a small neighborhood of chips, or a large irregular geospatial region. The performance of our proposed method has been validated using various quantitative and statistical metrics in addition to presenting the visual geo-maps and the percentage of the change. The results show that our proposed method efficiently detected the change from a large scale area.},
DOI = {10.3390/rs13091661}
}



@Article{electronics10091021,
AUTHOR = {Chan, Teck Kai and Chin, Cheng Siong},
TITLE = {Review of Autonomous Intelligent Vehicles for Urban Driving and Parking},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1021},
URL = {https://www.mdpi.com/2079-9292/10/9/1021},
ISSN = {2079-9292},
ABSTRACT = {With the concept of Internet-of-Things, autonomous vehicles can provide higher driving efficiency, traffic safety, and freedom for the driver to perform other tasks. This paper first covers enabling technology involving a vehicle moving out of parking, traveling on the road, and parking at the destination. The development of autonomous vehicles relies on the data collected for deployment in actual road conditions. Research gaps and recommendations for autonomous intelligent vehicles are included. For example, a sudden obstacle while the autonomous vehicle executes the parking trajectory on the road is discussed. Several aspects of social problems, such as the liability of an accident affecting the autonomous vehicle, are described. A smart device to detect abnormal driving behaviors to prevent possible accidents is briefly discussed.},
DOI = {10.3390/electronics10091021}
}



@Article{rs13091669,
AUTHOR = {Chen, Zhiang and Wagner, Melissa and Das, Jnaneshwar and Doe, Robert K. and Cerveny, Randall S.},
TITLE = {Data-Driven Approaches for Tornado Damage Estimation with Unpiloted Aerial Systems},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1669},
URL = {https://www.mdpi.com/2072-4292/13/9/1669},
ISSN = {2072-4292},
ABSTRACT = {Tornado damage estimation is important for providing insights into tornado studies and assisting rapid disaster response. However, it is challenging to precisely estimate tornado damage because of the large volumes of perishable data. This study presents data-driven approaches to tornado damage estimation using imagery collected from Unpiloted Aerial Systems (UASs) following the 26 June 2018 Eureka Kansas tornado. High-resolution orthomosaics were generated from Structure from Motion (SfM). We applied deep neural networks (DNNs) on the orthomosaics to estimate tornado damage and assessed their performance in four scenarios: (1) object detection with binary categories, (2) object detection with multiple categories, (3) image classification with binary categories, and (4) image classification with multiple categories. Additionally, two types of tornado damage heatmaps were generated. By directly stitching the resulting image tiles from the DNN inference, we produced the first type of tornado damage heatmaps where damage estimates are accurately georeferenced. We also presented a Gaussian process (GP) regression model to build the second type of tornado damage heatmap (a spatially continuous tornado damage heatmap) by merging the first type of object detection and image classification heatmaps. The GP regression results were assessed with ground-truth annotations and National Weather Service (NWS) ground surveys. This detailed information can help NWS Weather Forecast Offices and emergency managers with their damage assessments and better inform disaster response and recovery.},
DOI = {10.3390/rs13091669}
}



@Article{s21093012,
AUTHOR = {Wang, Wenbo and Aguilar Sanchez, Ignacio and Caparra, Gianluca and McKeown, Andy and Whitworth, Tim and Lohan, Elena Simona},
TITLE = {A Survey of Spoofer Detection Techniques via Radio Frequency Fingerprinting with Focus on the GNSS Pre-Correlation Sampled Data},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {3012},
URL = {https://www.mdpi.com/1424-8220/21/9/3012},
PubMedID = {33923015},
ISSN = {1424-8220},
ABSTRACT = {Radio frequency fingerprinting (RFF) methods are becoming more and more popular in the context of identifying genuine transmitters and distinguishing them from malicious or non-authorized transmitters, such as spoofers and jammers. RFF approaches have been studied to a moderate-to-great extent in the context of non-GNSS transmitters, such as WiFi, IoT, or cellular transmitters, but they have not yet been addressed much in the context of GNSS transmitters. In addition, the few RFF-related works in GNSS context are based on post-correlation or navigation data and no author has yet addressed the RFF problem in GNSS with pre-correlation data. Moreover, RFF methods in any of the three domains (pre-correlation, post-correlation, or navigation) are still hard to be found in the context of GNSS. The goal of this paper was two-fold: first, to provide a comprehensive survey of the RFF methods applicable in the GNSS context; and secondly, to propose a novel RFF methodology for spoofing detection, with a focus on GNSS pre-correlation data, but also applicable in a wider context. In order to support our proposed methodology, we qualitatively investigated the capability of different methods to be used in the context of pre-correlation sampled GNSS data, and we present a simulation-based example, under ideal noise conditions, of how the feature down selection can be done. We are also pointing out which of the transmitter features are likely to play the biggest roles in the RFF in GNSS, and which features are likely to fail in helping RFF-based spoofing detection.},
DOI = {10.3390/s21093012}
}



@Article{agriculture11050387,
AUTHOR = {Islam, Nahina and Rashid, Md Mamunur and Wibowo, Santoso and Xu, Cheng-Yuan and Morshed, Ahsan and Wasimi, Saleh A. and Moore, Steven and Rahman, Sk Mostafizur},
TITLE = {Early Weed Detection Using Image Processing and Machine Learning Techniques in an Australian Chilli Farm},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {387},
URL = {https://www.mdpi.com/2077-0472/11/5/387},
ISSN = {2077-0472},
ABSTRACT = {This paper explores the potential of machine learning algorithms for weed and crop classification from UAV images. The identification of weeds in crops is a challenging task that has been addressed through orthomosaicing of images, feature extraction and labelling of images to train machine learning algorithms. In this paper, the performances of several machine learning algorithms, random forest (RF), support vector machine (SVM) and k-nearest neighbours (KNN), are analysed to detect weeds using UAV images collected from a chilli crop field located in Australia. The evaluation metrics used in the comparison of performance were accuracy, precision, recall, false positive rate and kappa coefficient. MATLAB is used for simulating the machine learning algorithms; and the achieved weed detection accuracies are 96% using RF, 94% using SVM and 63% using KNN. Based on this study, RF and SVM algorithms are efficient and practical to use, and can be implemented easily for detecting weed from UAV images.},
DOI = {10.3390/agriculture11050387}
}



@Article{w13091191,
AUTHOR = {Lee, Jaeyeong and Kim, Byunghyun},
TITLE = {Scenario-Based Real-Time Flood Prediction with Logistic Regression},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1191},
URL = {https://www.mdpi.com/2073-4441/13/9/1191},
ISSN = {2073-4441},
ABSTRACT = {This study proposed a real-time flood extent prediction method to shorten the time it takes from the flood occurrence to an alert issuance. This method uses logistic regression to generate a flood probability discriminant for each grid constituting the study area, and then predicts the flood extent with the amount of runoff caused by rainfall. In order to generate the flood probability discriminant for each grid, a two-dimensional (2D) flood inundation model was verified by applying the Typhoon Chaba, which caused great damage to the study area in 2016. Then, 100 probability rainfall scenarios were created by combining the return period, duration, and time distribution using past observation rainfall data, and rainfall-runoff–inundation relation databases were built for each scenario by applying hydrodynamic and hydrological models. A flood probability discriminant based on logistic regression was generated for each grid by using whether the grid was flooded (1 or 0) for the runoff amount in the database. When the runoff amount is input to the generated discriminant, the flood probability on the target grid is calculated by the coefficients, so that the flood extent is quickly predicted. The proposed method predicted the flood extent in a few seconds in both cases and showed high accuracy with 83.6~98.4% and 74.4~99.1%, respectively, in the application of scenario rainfall and actual rainfall.},
DOI = {10.3390/w13091191}
}



@Article{rs13091670,
AUTHOR = {Avola, Danilo and Cinque, Luigi and Diko, Anxhelo and Fagioli, Alessio and Foresti, Gian Luca and Mecca, Alessio and Pannone, Daniele and Piciarelli, Claudio},
TITLE = {MS-Faster R-CNN: Multi-Stream Backbone for Improved Faster R-CNN Object Detection and Aerial Tracking from UAV Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1670},
URL = {https://www.mdpi.com/2072-4292/13/9/1670},
ISSN = {2072-4292},
ABSTRACT = {Tracking objects across multiple video frames is a challenging task due to several difficult issues such as occlusions, background clutter, lighting as well as object and camera view-point variations, which directly affect the object detection. These aspects are even more emphasized when analyzing unmanned aerial vehicles (UAV) based images, where the vehicle movement can also impact the image quality. A common strategy employed to address these issues is to analyze the input images at different scales to obtain as much information as possible to correctly detect and track the objects across video sequences. Following this rationale, in this paper, we introduce a simple yet effective novel multi-stream (MS) architecture, where different kernel sizes are applied to each stream to simulate a multi-scale image analysis. The proposed architecture is then used as backbone for the well-known Faster-R-CNN pipeline, defining a MS-Faster R-CNN object detector that consistently detects objects in video sequences. Subsequently, this detector is jointly used with the Simple Online and Real-time Tracking with a Deep Association Metric (Deep SORT) algorithm to achieve real-time tracking capabilities on UAV images. To assess the presented architecture, extensive experiments were performed on the UMCD, UAVDT, UAV20L, and UAV123 datasets. The presented pipeline achieved state-of-the-art performance, confirming that the proposed multi-stream method can correctly emulate the robust multi-scale image analysis paradigm.},
DOI = {10.3390/rs13091670}
}



@Article{rs13091672,
AUTHOR = {Pan, Erting and Ma, Yong and Fan, Fan and Mei, Xiaoguang and Huang, Jun},
TITLE = {Hyperspectral Image Classification across Different Datasets: A Generalization to Unseen Categories},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1672},
URL = {https://www.mdpi.com/2072-4292/13/9/1672},
ISSN = {2072-4292},
ABSTRACT = {With the rapid developments of hyperspectral imaging, the cost of collecting hyperspectral data has been lower, while the demand for reliable and detailed hyperspectral annotations has been much more substantial. However, limited by the difficulties of labelling annotations, most existing hyperspectral image (HSI) classification methods are trained and evaluated on a single hyperspectral data cube. It brings two significant challenges. On the one hand, many algorithms have reached a nearly perfect classification accuracy, but their trained models are hard to generalize to other datasets. On the other hand, since different hyperspectral datasets are usually not collected in the same scene, different datasets will contain different classes. To address these issues, in this paper, we propose a new paradigm for HSI classification, which is training and evaluating separately across different hyperspectral datasets. It is of great help to labelling hyperspectral data. However, it has rarely been studied in the hyperspectral community. In this work, we utilize a three-phase scheme, including feature embedding, feature mapping, and label reasoning. More specifically, we select a pair of datasets acquired by the same hyperspectral sensor, and the classifier learns from one dataset and then evaluated it on the other. Inspired by the latest advances in zero-shot learning, we introduce label semantic representation to establish associations between seen categories in the training set and unseen categories in the testing set. Extensive experiments on two pairs of datasets with different comparative methods have shown the effectiveness and potential of zero-shot learning in HSI classification.},
DOI = {10.3390/rs13091672}
}



@Article{drones5020031,
AUTHOR = {Song, Bonggeun and Park, Kyunghun},
TITLE = {Comparison of Outdoor Compost Pile Detection Using Unmanned Aerial Vehicle Images and Various Machine Learning Techniques},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {31},
URL = {https://www.mdpi.com/2504-446X/5/2/31},
ISSN = {2504-446X},
ABSTRACT = {Since outdoor compost piles (OCPs) contain large amounts of nitrogen and phosphorus, they act as a major pollutant that deteriorates water quality, such as eutrophication and green algae, when the OCPs enter the river during rainfall. In South Korea, OCPs are frequently used, but there is a limitation that a lot of manpower and budget are consumed to investigate the current situation, so it is necessary to efficiently investigate the OCPs. This study compared the accuracy of various machine learning techniques for the efficient detection and management of outdoor compost piles (OCPs), a non-point pollution source in agricultural areas in South Korea, using unmanned aerial vehicle (UAV) images. RGB, multispectral, and thermal infrared UAV images were taken in August and October 2019. Additionally, vegetation indices (NDVI, NDRE, ENDVI, and GNDVI) and surface temperature were also considered. Four machine learning techniques, including support vector machine (SVM), decision tree (DT), random forest (RF), and k-NN, were implemented, and the machine learning technique with the highest accuracy was identified by adjusting several variables. The accuracy of all machine learning techniques was very high, reaching values of up to 0.96. Particularly, the accuracy of the RF method with the number of estimators set to 10 was highest, reaching 0.989 in August and 0.987 in October. The proposed method allows for the prediction of OCP location and area over large regions, thereby foregoing the need for OCP field measurements. Therefore, our findings provide highly useful data for the improvement of OCP management strategies and water quality.},
DOI = {10.3390/drones5020031}
}



@Article{rs13091679,
AUTHOR = {Elsayed, Salah and El-Hendawy, Salah and Khadr, Mosaad and Elsherbiny, Osama and Al-Suhaibani, Nasser and Alotaibi, Majed and Tahir, Muhammad Usman and Darwish, Waleed},
TITLE = {Combining Thermal and RGB Imaging Indices with Multivariate and Data-Driven Modeling to Estimate the Growth, Water Status, and Yield of Potato under Different Drip Irrigation Regimes},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1679},
URL = {https://www.mdpi.com/2072-4292/13/9/1679},
ISSN = {2072-4292},
ABSTRACT = {Advances in proximal hyperspectral sensing tools, chemometric techniques, and data-driven modeling have enhanced precision irrigation management by facilitating the monitoring of several plant traits. This study investigated the performance of remote sensing indices derived from thermal and red-green-blue (RGB) images combined with stepwise multiple linear regression (SMLR) and an integrated adaptive neuro-fuzzy inference system with a genetic algorithm (ANFIS-GA) for monitoring the biomass fresh weight (BFW), biomass dry weight (BDW), biomass water content (BWC), and total tuber yield (TTY) of two potato varieties under 100%, 75%, and 50% of the estimated crop evapotranspiration (ETc). Results showed that the plant traits and indices varied significantly between the three irrigation regimes. Furthermore, all of the indices exhibited strong relationships with BFW, CWC, and TTY (R2 = 0.80–0.92) and moderate to weak relationships with BDW (R2 = 0.25–0.65) when considered for each variety across the irrigation regimes, for each season across the varieties and irrigation regimes, and across all data combined, but none of the indices successfully assessed any of the plant traits when considered for each irrigation regime across the two varieties. The SMLR and ANFIS-GA models gave the best predictions for the four plant traits in the calibration and testing stages, with the exception of the SMLR testing model for BDW. Thus, the use of thermal and RGB imaging indices with ANFIS-GA models could be a practical tool for managing the growth and production of potato crops under deficit irrigation regimes.},
DOI = {10.3390/rs13091679}
}



@Article{su13094883,
AUTHOR = {Khan, Nawab and Ray, Ram L. and Sargani, Ghulam Raza and Ihtisham, Muhammad and Khayyam, Muhammad and Ismail, Sohaib},
TITLE = {Current Progress and Future Prospects of Agriculture Technology: Gateway to Sustainable Agriculture},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {4883},
URL = {https://www.mdpi.com/2071-1050/13/9/4883},
ISSN = {2071-1050},
ABSTRACT = {The agricultural industry is getting more data-centric and requires precise, more advanced data and technologies than before, despite being familiar with agricultural processes. The agriculture industry is being advanced by various information and advanced communication technologies, such as the Internet of Things (IoT). The rapid emergence of these advanced technologies has restructured almost all other industries, as well as advanced agriculture, which has shifted the industry from a statistical approach to a quantitative one. This radical change has shaken existing farming techniques and produced the latest prospects in a series of challenges. This comprehensive review article enlightens the potential of the IoT in the advancement of agriculture and the challenges faced when combining these advanced technologies with conventional agricultural systems. A brief analysis of these advanced technologies with sensors is presented in advanced agricultural applications. Numerous sensors that can be implemented for specific agricultural practices require best management practices (e.g., land preparation, irrigation systems, insect, and disease management). This review includes the integration of all suitable techniques, from sowing to harvesting, packaging, transportation, and advanced technologies available for farmers throughout the cropping system. Besides, this review article highlights the utilization of other tools such as unmanned aerial vehicles (UAVs) for crop monitoring and other beneficiary measures, such as optimizing crop yields. In addition, advanced programs based on the IoT are also discussed. Finally, based on our comprehensive review, we identified advanced prospects regarding the IoT, which are essential tools for sustainable agriculture.},
DOI = {10.3390/su13094883}
}



@Article{rs13091682,
AUTHOR = {Sodango, Terefe Hanchiso and Sha, Jinming and Li, Xiaomei and Noszczyk, Tomasz and Shang, Jiali and Aneseyee, Abreham Berta and Bao, Zhongcong},
TITLE = {Modeling the Spatial Dynamics of Soil Organic Carbon Using Remotely-Sensed Predictors in Fuzhou City, China},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1682},
URL = {https://www.mdpi.com/2072-4292/13/9/1682},
ISSN = {2072-4292},
ABSTRACT = {Assessing the spatial dynamics of soil organic carbon (SOC) is essential for carbon monitoring. Since variability of SOC is mainly attributed to biophysical land surface variables, integrating a compressive set of such indices may support the pursuit of an optimum set of predictor variables. Therefore, this study was aimed at predicting the spatial distribution of SOC in relation to remotely sensed variables and other covariates. Hence, the land surface variables were combined from remote sensing, topographic, and soil spectral sources. Moreover, the most influential variables for prediction were selected using the random forest (RF) and classification and regression tree (CART). The results indicated that the RF model has good prediction performance with corresponding R2 and root-mean-square error (RMSE) values of 0.96 and 0.91 mg·g−1, respectively. The distribution of SOC content showed variability across landforms (CV = 78.67%), land use (CV = 93%), and lithology (CV = 64.67%). Forestland had the highest SOC (13.60 mg·g−1) followed by agriculture (10.43 mg·g−1), urban (9.74 mg·g−1), and water body (4.55 mg·g−1) land uses. Furthermore, soils developed in bauxite and laterite lithology had the highest SOC content (14.69 mg·g−1). The SOC content was remarkably lower in soils developed in sandstones; however, the values obtained in soils from the rest of the lithologies could not be significantly differentiated. The mean SOC concentration was 11.70 mg·g−1, where the majority of soils in the study area were classified as highly humus and extremely humus. The soils with the highest SOC content (extremely humus) were distributed in the mountainous regions of the study area. The biophysical land surface indices, brightness removed vegetation indices, topographic indices, and soil spectral bands were the most influential predictors of SOC in the study area. The spatial variability of SOC may be influenced by landform, land use, and lithology of the study area. Remotely sensed predictors including land moisture, land surface temperature, and built-up indices added valuable information for the prediction of SOC. Hence, the land surface indices may provide new insights into SOC modeling in complex landscapes of warm subtropical urban regions.},
DOI = {10.3390/rs13091682}
}



@Article{en14092484,
AUTHOR = {Rinaldi, Giovanni and Thies, Philipp R. and Johanning, Lars},
TITLE = {Current Status and Future Trends in the Operation and Maintenance of Offshore Wind Turbines: A Review},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {2484},
URL = {https://www.mdpi.com/1996-1073/14/9/2484},
ISSN = {1996-1073},
ABSTRACT = {Operation and maintenance constitute a substantial share of the lifecycle expenditures of an offshore renewable energy farm. A noteworthy number of methods and techniques have been developed to provide decision-making support in strategic planning and asset management. Condition monitoring instrumentation is commonly used, especially in offshore wind farms, due to the benefits it provides in terms of fault identification and performance evaluation and improvement. Incorporating technology advancements, a shift towards automation and digitalisation is taking place in the offshore maintenance sector. This paper reviews the existing literature and novel approaches in the operation and maintenance planning and the condition monitoring of offshore renewable energy farms, with an emphasis on the offshore wind sector, discussing their benefits and limitations. The state-of-the-art in industrial condition-based maintenance is reviewed, together with deterioration models and fault diagnosis and prognosis techniques. Future scenarios in robotics, artificial intelligence and data processing are investigated. The application challenges of these strategies and Industry 4.0 concepts in the offshore renewables sector are scrutinised, together with the potential implications of early-stage project integration. The identified technologies are ranked against a series of indicators, providing a reference for a range of industry stakeholders.},
DOI = {10.3390/en14092484}
}




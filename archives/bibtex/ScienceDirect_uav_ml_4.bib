@article{ZHAO202281,
title = {Distributed coordinated control scheme of UAV swarm based on heterogeneous roles},
journal = {Chinese Journal of Aeronautics},
volume = {35},
number = {1},
pages = {81-97},
year = {2022},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.01.014},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121000534},
author = {Jiang ZHAO and Jiaming SUN and Zhihao CAI and Yingxun WANG and Kun WU},
keywords = {Coordination strategy, Distributed control, Heterogeneous roles, Swarm intelligence, Unmanned Aerial Vehicles (UAV)},
abstract = {This paper proposes a new distributed coordinated control scheme based on heterogeneous roles for Unmanned Aerial Vehicle (UAV) swarm to achieve formation control. First, the framework of the distributed coordinated control scheme is designed on the basis of Distributed Model Predictive Control (DMPC). Then, the effect of heterogeneous roles including leader, coordinator and follower is discussed, and the role-based cost functions are developed to improve the performance of coordinated control for UAV swarm. Furthermore, a group of coordination strategies are proposed for UAVs with different roles to achieve swarm conflict resolution. Numerical simulations demonstrate that the presented distributed coordinated control scheme is effective to formulate and maintain the desired formation for the UAV swarm.}
}
@article{COUTURIER2021103666,
title = {A review on absolute visual localization for UAV},
journal = {Robotics and Autonomous Systems},
volume = {135},
pages = {103666},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103666},
url = {https://www.sciencedirect.com/science/article/pii/S0921889020305066},
author = {Andy Couturier and Moulay A. Akhloufi},
keywords = {Absolute visual localization, UAV, Navigation, Satellite imagery, Computer vision, Deep learning},
abstract = {Research on unmanned aerial vehicles is growing as they are becoming less expensive and more available than before. The applications span a large number of areas and include border security, search and rescue, wildlife surveying, firefighting, precision agriculture, structure inspection, surveying and mapping, aerial photography, and recreative applications. These applications can require autonomous behavior which is only possible with a precise and robust self-localization. Until recently, the favored approach to localization was based on inertial sensors and global navigation satellite systems. However, global navigation satellite systems have multiple shortcomings related to long-distance radio communications (e.g. non-line-of-sight reception, multipath, spoofing). This motivated the development of new approaches to supplement or supplant satellite navigation. Absolute visual localization is one of the two main approaches to vision-based localization. The goal is to locate the current view of the UAV in a reference satellite map or georeferenced imagery from previous flights. Various approaches were proposed in this area and this paper review most of the literature in this field since 2015. The problematic at hand is analyzed and defined. Existing approaches are reviewed in 4 categories: template matching, feature points matching, deep learning and visual odometry.}
}
@article{MA2021107204,
title = {Adaptive model-free fault-tolerant control based on integral reinforcement learning for a highly flexible aircraft with actuator faults},
journal = {Aerospace Science and Technology},
volume = {119},
pages = {107204},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107204},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821007148},
author = {Jianjun Ma and Chi Peng},
keywords = {Model-free, Fault-tolerant control, Integral reinforcement learning, Highly flexible aircraft, Observer-like reference model},
abstract = {This article presents an adaptive model-free fault-tolerant control scheme based on integral reinforcement learning (IRL) technique for tracking control of a highly flexible aircraft (HFA) with actuator faults. To begin, the integral of the tracking error is introduced as a new state to construct an augmented system for the control design. Following that, the off-policy IRL method is applied to obtain the optimal feedback control law online in order to solve the tracking problem without system knowledge. Furthermore, in order to effectively handle system uncertainties, external disturbances, and actuator faults, an adaptive model-free fault-tolerant controller with an observer-like reference model is developed. The designed controller can guarantee that the closed-loop system is uniformly bounded and the tracking error asymptotically approaches zero by choosing design parameters appropriately. Finally, numerical simulations demonstrate the desirable fault accommodation capability of the proposed fault-tolerant strategy.}
}
@article{NGUYEN2018107,
title = {Automatic autonomous vision-based power line inspection: A review of current status and the potential role of deep learning},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {99},
pages = {107-120},
year = {2018},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2017.12.016},
url = {https://www.sciencedirect.com/science/article/pii/S0142061517324444},
author = {Van Nhan Nguyen and Robert Jenssen and Davide Roverso},
keywords = {Power line inspection, Vision-based inspection, Deep learning, UAVs},
abstract = {To maintain the reliability, availability, and sustainability of electricity supply, electricity companies regularly perform visual inspections on their transmission and distribution networks. These inspections have been typically carried out using foot patrol and/or helicopter-assisted methods to plan for necessary repair or replacement works before any major damage, which may cause power outage. This solution is quite slow, expensive, and potentially dangerous. In recent years, numerous researches have been conducted to automate the visual inspections by using automated helicopters, flying robots, and/or climbing robots. However, due to the high accuracy requirements of the task and its unique challenges, automatic vision-based inspection has not been widely adopted. In this paper, with the aim of providing a good starting point for researchers who are interested in developing a fully automatic autonomous vision-based power line inspection system, we conduct an extensive literature review. First, we examine existing power line inspection methods with special attention paid to highlight their advantages and disadvantages. Next, we summarize well-suited tasks and review potential data sources for automatic vision-based inspection. Then, we survey existing automatic vision-based power line inspection systems. Based on that, we propose a new automatic autonomous vision-based power line inspection concept that uses Unmanned Aerial Vehicle (UAV) inspection as the main inspection method, optical images as the primary data source, and deep learning as the backbone of data analysis and inspection. Then, we present an overview of possibilities and challenges of deep vision (deep learning for computer vision) approaches for both UAV navigation and UAV inspection and discuss possible solutions to the challenges. Finally, we conclude the paper with an outlook for the future of this field and propose potential next steps for implementing the concept.}
}
@article{XU2021109794,
title = {Deep reinforcement learning based multi-AUVs cooperative decision-making for attack–defense confrontation missions},
journal = {Ocean Engineering},
volume = {239},
pages = {109794},
year = {2021},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2021.109794},
url = {https://www.sciencedirect.com/science/article/pii/S0029801821011562},
author = {Jian Xu and Fei Huang and Di Wu and Yunfei Cui and Zheping Yan and Kai Zhang},
keywords = {Multi-AUVs, Deep reinforcement learning, Cooperative decision-making, Attack–defense confrontation},
abstract = {This paper mainly focuses on using deep reinforcement learning (RL) to deal with the cooperative decision-making problem of multiple Autonomous Underwater Vehicles (multi-AUVs) under limited perception and limited communication in attack–defense confrontation missions. Firstly, a novel Coding-Convolutional Network (CCN) is proposed, which can encode the raw sensor information of AUVs and extract representative features from limited perception. Secondly, utilizing the approximator of the state value function and policy function composed of CCN and fully connected network, we put forward a centralized decision-making architecture for multi-AUVs system based on actor–critic framework and give the corresponding algorithm combined with asynchronous training. Moreover, with respect to multi-AUVs attack–defense confrontation tasks, we develop a simulation platform to train and evaluate the proposed algorithms under different parameters. It can be directly observed from the visualization of the simulation that the algorithm enables multi-AUVs to complete the attack–defense confrontation missions excellently and generate some interesting collaborative behaviors. The average winning probability data of the simulation results also indicate that the designed method is feasible for multi-AUVs to achieve cooperative decision-making in attack–defense confrontation missions.}
}
@article{ELNABTY2021101564,
title = {A survey on UAV placement optimization for UAV-assisted communication in 5G and beyond networks},
journal = {Physical Communication},
pages = {101564},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101564},
url = {https://www.sciencedirect.com/science/article/pii/S187449072100269X},
author = {Israa A. Elnabty and Yasmine Fahmy and Mai Kafafy},
keywords = {Unmanned aerial vehicle (UAV), Placement optimization, Wireless communication},
abstract = {With the increase in capacity demands and the requirement of ubiquitous coverage in the fifth generation (5G) and beyond wireless communications networks, unmanned aerial vehicles (UAVs) have acquired a great attention owing to their outstanding characteristics over traditional base stations and relays. UAVs can be deployed faster and with much lower expenditure than ground base stations. In addition, UAVs can enhance the network performance thanks to their strong line-of-sight link conditions with their associated users and their dynamic nature that adapts to varying network conditions. Optimization of the UAV 3D locations in a UAV-assisted wireless communication network was considered in a large body of research as it is a critical design issue that greatly affects communication performance. Although the topic of UAV placement optimization was considered in few surveys, these surveys reviewed only a small part of the growing literature. In addition, the surveys were brief and did not discuss many important design issues such as the objectives of the optimization problem, the adopted solution techniques, the air-to-ground channel models, the transmission media for access and backhaul links, the limited energy nature of the UAV on-board batteries, co-channel interference and spectrum sharing, the interference management, etc. Motivated by the importance of the topic of UAV placement optimization as well as the need for a detailed review of its recent literature, we survey more than 90 of the recent research papers and provide in-depth discussion to fill the gaps found in the previous survey papers. The considered research papers are summarized and categorized to highlight the differences in the deployment scenario and system model, the optimization objectives and parameters, the proposed solution techniques, and the decision-making strategies and many other points. We also point to some of the existing challenges and potential research directions that have been considered in the surveyed literature and that requires to be considered}
}
@article{REN2022102660,
title = {An improved mask-RCNN algorithm for UAV TIR video stream target detection},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {106},
pages = {102660},
year = {2022},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102660},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421003676},
author = {Xiang Ren and Min Sun and Xianfeng Zhang and Lei Liu and Hang Zhou and Xiaoping Ren},
keywords = {UAV, Thermal infrared, Mask-RCNN, Target detection},
abstract = {In emergency rescue operations, unmanned aerial vehicles (UAVs) equipped with thermal infrared (TIR) sensors are essential to obtain ground information during nighttime operations. However, existing target detection algorithms mainly consider the detection accuracy but not the processing speed and storage space requirements. Furthermore, current neural network target detection algorithms primarily focus on conventional RGB images and are not optimized for UAV-based TIR video stream data. This paper proposes an improved Mask-RCNN algorithm for target detection in UAV TIR video streams to address current research deficiencies. First, MobileNetV3, which is used to process RGB images, is applied to process TIR data for outdoor emergency rescue operations, significantly increasing the time efficiency of the algorithm. Second, prior knowledge such as the projection model of the airborne camera and the target temperature characteristics in the UAV TIR video stream is utilized to filter the detecting results instead of pre-detection temperature masks. Compared with the original Mask-RCNN algorithm, the improved algorithm increases the processing speed, reduces the storage space requirements, and provides detection performances equal or slightly superior to that before the improvement.}
}
@article{LAC2022106606,
title = {Crop stem detection and tracking for precision hoeing using deep learning},
journal = {Computers and Electronics in Agriculture},
volume = {192},
pages = {106606},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106606},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006232},
author = {Louis Lac and Jean-Pierre {Da Costa} and Marc Donias and Barna Keresztes and Alain Bardet},
keywords = {Precision agriculture, Deep learning, Neural network, Object detection, Tracking algorithm},
abstract = {Developing alternatives to the chemical weeding process usually carried out in vegetable crop farming is necessary in order to reach a more sustainable agriculture. However, a precise mechanical weeding requires specific sensors and advanced computer vision algorithms to process crop and weed discrimination in real-time. In this paper we propose an algorithm able to detect, locate, and track the stem position of crops in images which is suitable for precision actions in vegetable fields such as mechanical hoeing within crop rows. The algorithm is twofold: (i) a deep neural network for object detection is first used to detect crop stems in individual RGB images and then (ii) an aggregation algorithm further refines the detections taking advantage of the temporal redundancy in consecutive frames. We evaluated the pipeline on images of maize and bean crops at an early stage of development, acquired in field conditions with a camera embedded in an experimental mechanical weeding system. We reported F1-scores of respectively 94.74% and 93.82% with a location accuracy around 0.7 cm when compared with human annotation. Moreover, this pipeline can operate in real-time on an embedded computer consuming as little power as 30 W.}
}
@article{GUPTA2022108439,
title = {Cybersecurity of multi-cloud healthcare systems: A hierarchical deep learning approach},
journal = {Applied Soft Computing},
pages = {108439},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2022.108439},
url = {https://www.sciencedirect.com/science/article/pii/S1568494622000175},
author = {Lav Gupta and Tara Salman and Ali Ghubaish and Devrim Unal and Abdulla Khalid Al-Ali and Raj Jain},
keywords = {Cloud networks, Edge clouds, Network function virtualization, Critical healthcare, Deep neural networks, Stacked autoencoders, Hierarchical neural networks, Multi-cloud systems},
abstract = {With the increase in sophistication and connectedness of the healthcare networks, their attack surfaces and vulnerabilities increase significantly. Malicious agents threaten patients’ health and life by stealing or altering data as it flows among the multiple domains of healthcare networks. The problem is likely to exacerbate with the increasing use of IoT devices, edge, and core clouds in the next generation healthcare networks. Presented in this paper is MUSE, a system of deep hierarchical stacked neural networks for timely and accurate detection of malicious activity that leads to alteration of meta-information or payload of the dataflow between the IoT gateway, edge and core clouds. Smaller models at the edge clouds take substantially less time to train as compared to the large models in the core cloud. To improve the speed of training and accuracy of detection of large core cloud models, the MUSE system uses a novel method of merging and aggregating layers of trained edge cloud models to construct a partly pre-trained core cloud model. As a result, the model in the core cloud takes substantially smaller number of epochs (6 to 8) and, consequently, less time, compared to edge clouds, training of which take 35 to 40 epochs to converge. With the help of extensive evaluations, it is shown that with the MUSE system, large, merged models can be trained in significantly less time than the unmerged models that are created independently in the core cloud. Through several runs it is seen that the merged models give on an average 26.2% reduction in training times. From the experimental evaluation we demonstrate that along with fast training speeds the merged MUSE model gives high training and test accuracies, ranging from 95% to 100%, in detection of unknown attacks on dataflows. The merged model thus generalizes very well on the test data. This is a marked improvement when compared with the accuracy given by un-merged model as well as accuracy reported by other researchers with newer datasets.}
}
@article{FU2022126405,
title = {Combining UAV multispectral imagery and ecological factors to estimate leaf nitrogen and grain protein content of wheat},
journal = {European Journal of Agronomy},
volume = {132},
pages = {126405},
year = {2022},
issn = {1161-0301},
doi = {https://doi.org/10.1016/j.eja.2021.126405},
url = {https://www.sciencedirect.com/science/article/pii/S1161030121001763},
author = {Zhaopeng Fu and Shanshan Yu and Jiayi Zhang and Hui Xi and Yang Gao and Ruhua Lu and Hengbiao Zheng and Yan Zhu and Weixing Cao and Xiaojun Liu},
keywords = {Wheat, UAV multispectral imagery, Leaf nitrogen content, Grain protein content, Texture, Ecological factors, Artificial Neural Network},
abstract = {Nitrogen is an essential element of wheat growth and grain quality. Leaf nitrogen content (LNC), a critical monitoring indicator of crop nitrogen status, plays a reference role for later estimations of grain protein content (GPC). Developments in unmanned aerial vehicle (UAV) platforms and multispectral sensors have provided new approaches for LNC monitoring and GPC estimation, with great convenience for assessing the nutritional status of plants and grains without traditional destructive sampling. The objective of this study was to evaluate the feasibility of wheat LNC monitoring and GPC estimation based on UAV multispectral imagery. Wheat experiments were carried out in Xinghua, Kunshan and Suining of Jiangsu Province during 2018−2019 and in Rugao of Jiangsu Province during 2020−2021 with different varieties and nitrogen application rates. Remote sensing images were obtained by a multi-rotor UAV carrying a multispectral camera. The destructive sampling method was used to collect LNC, GPC and other field data. Wheat LNC monitoring and GPC estimation models were established after selection of the optimal indicators. Different modelling methods were used for the comparative analysis, including unitary linear regression, multiple linear regression and artificial neural network (ANN) methods. Three techniques were adopted to improve the GPC prediction accuracy: (1) multiple factors were substituted for single factor for the prediction; (2) texture information was added through further imagery mining; and (3) ecological factors were considered to improve the prediction mechanism. The results showed that the use of UAV-based Airphen multispectral imagery had a good effect on wheat LNC monitoring and GPC estimation. The vegetation indices constructed by red-edge and near-infrared bands had good performances in LNC monitoring and GPC estimation. The addition of texture information and ecological factors further improved the modelling accuracy. In this study, the optimal wheat GPC estimation model was established by NDVI (675, 730) at the jointing stage, NDVIT (730mea., 850) at the booting stage, NDVIT (730mea., 850) at the flowering stage and NDVI (730, 850) at the early filling stage. The modelling R2, validation R2 and relative root mean square error (RRMSE) reached 0.662, 0.7445 and 0.0635, respectively. The results provide a reference for crop LNC monitoring and GPC estimation based on UAV multispectral imagery.}
}
@article{CHENG201953,
title = {Finite Time Fault Tolerant Control Design for UAV Attitude Control Systems with Actuator Fault and Actuator Saturation⁎⁎This work is jointly supported by the National Natural Science Foundation of China under Grant No.61573186 and No.61773214.},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {24},
pages = {53-58},
year = {2019},
note = {5th IFAC Symposium on Telematics Applications TA 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.380},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319322803},
author = {Peng Cheng and Chenxiao Cai and Yun Zou},
keywords = {Unmanned aerial vehicle, attitude control systems, fault tolerant control},
abstract = {This paper presents a novel fault tolerant control (FTC) strategy for an unmanned aerial vehicle (UAV) subject to multiple constraints of actuator fault, actuator saturation and external disturbance. First, a radial basis function neural network (RBFNN)-based fault estimation observer is developed to obtain the accurate value of actuator fault. Second, an attitude stabilization FTC approach is established with combining the non-singular fast terminal sliding mode (NFTSM) technology, which could tolerate the estimated loss of effectiveness fault. Third, it is discussed asymptotically stability and stabilization of UAV attitude systems in finite time by Lyapunov method and the improved FTC scheme. Finally, the simulation is carried out to verify the fault tolerant capability of the designed algorithm.}
}
@article{NGUYEN2022156,
title = {DeepPlace: Deep reinforcement learning for adaptive flow rule placement in Software-Defined IoT Networks},
journal = {Computer Communications},
volume = {181},
pages = {156-163},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421003789},
author = {Tri Gia Nguyen and Trung V. Phan and Dinh Thai Hoang and Hai Hoang Nguyen and Duc Tran Le},
keywords = {Flow rule placement, Quality-of-Service, Software-Defined Networking, Internet of Things, Deep reinforcement learning},
abstract = {In this paper, we propose a novel and adaptive flow rule placement system based on deep reinforcement learning, namely DeepPlace, in Software-Defined Internet of Things (SDIoT) networks. DeepPlace can provide a fine-grained traffic analysis capability while assuring QoS of traffic flows and proactively avoiding the flow-table overflow issue in the data plane. Specifically, we first investigate the traffic forwarding process in an SDIoT network, i.e., routing and flow rule placement tasks. We design a cost function for the routing to set up traffic flow paths in the data plane. Next, we propose an adaptive flow rule placement approach to maximize the number of match-fields in a flow rule at SDN switches. To deal with the dynamics of IoT traffic flows, we model the system operation by using the Markov decision process (MDP) with a continuous action space and formulate its optimization problem. Subsequently, we develop a deep deterministic policy gradient-based algorithm to help the system obtain the optimal policy. The evaluation results demonstrate that DeepPlace can efficiently maintain a significant number of match-fields in a flow rule, i.e., approximately 86% of the maximum level, while minimizing the QoS violation ratio of traffic flows, i.e., 6.7%, in a highly dynamic traffic scenario, which outperforms three other existing solutions, i.e., FlowMan, FlowStat, and DeepMatch.}
}
@article{SU2021107286,
title = {Real-time hierarchical risk assessment for UAVs based on recurrent fusion autoencoder and dynamic FCE: A hybrid framework},
journal = {Applied Soft Computing},
volume = {106},
pages = {107286},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107286},
url = {https://www.sciencedirect.com/science/article/pii/S156849462100209X},
author = {Xuanyuan Su and Laifa Tao and Hongmei Liu and Lizhi Wang and Mingliang Suo},
keywords = {Hybrid framework, Hierarchical risk assessment, Recurrent fusion autoencoder, Dynamic fuzzy comprehensive evaluation, Unmanned aerial vehicles},
abstract = {Effective risk assessment is critical for unmanned aerial vehicles (UAVs) to ensure their safety and reliability. Up to now, the researchers have proposed quite a few methods for the above target. However, these methods are mainly based on path planning and collision theory, the risk caused by the abnormal status of UAVs themselves is generally ignored, which limits the further improvement on their performance. In practice, due to factors such as complicated compositions, variable condition monitoring (CM) data, and scarce failure records, etc., it is always a great challenge to implement the complete information fusion and accurate risk assessment for UAVs based on their real-time status. In this regard, a novel hybrid framework is proposed in this paper, which integrates the qualitative knowledge and the quantitative CM data, to evaluate the real-time hierarchical risk of UAVs. Specifically, the complicated UAV is firstly abstracted as a multi-level evaluating index system considering its qualitative logic compositions. Then, for each low-level index, given its multivariate CM data of several time instants, recurrent fusion autoencoder (RFA), a novel unsupervised neural network architecture, is proposed to extract their robust and complete feature embeddings automatically, where not only the information of variate dimension but also the information of time dimension can be fully fused. Furthermore, the risk of each low-level index is quantified by the adaptive Gaussian mixture model in a probabilistic way, which is truly data-driven with the help of the Bayesian hyperparameter optimization. Finally, the dynamic fuzzy comprehensive evaluation is utilized to evaluate the hierarchical risk of UAVs level by level, it should be noticed that our method can dynamically adjust the weights of each index employing the variable weight coefficients, which can capture the preliminary risk of UAVs more timely compared with the traditional methods. The proposed framework is validated on two typical datasets: the turbofan engine datasets (simulation) and the UAV flight datasets (real). The experimental results demonstrate the effectiveness and superiority of the hybrid framework on robust information fusion and accurate hierarchical risk assessment.}
}
@article{ZIELINSKI2021107602,
title = {3D robotic navigation using a vision-based deep reinforcement learning model},
journal = {Applied Soft Computing},
volume = {110},
pages = {107602},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107602},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621005238},
author = {P. Zieliński and U. Markowska-Kaczmar},
keywords = {Deep reinforcement learning, A2C, PPO, Vision-based navigation, YOLO, CNN},
abstract = {In this paper, we address a problem of vision-based 3D robotic navigation using deep reinforcement learning for an Autonomous Underwater Vehicle (AUV). Our research offers conclusions from the experimental study based on one of the RoboSub 2018 competition tasks. However, it can be generalized to any navigation task consisting of movement from a starting point to the front of the next station. The presented reinforcement learning-based model predicts the robot’s steering settings using the data acquired from the robot’s sensors. Its Vision Module may be based on a built-in convolutional network or a pre-trained TinyYOLO network so that a comparison of various levels of features’ complexity is possible. To enable evaluation of the proposed solution, we prepared a test environment imitating the real conditions. It provides the ability to steer the agent simulating the AUV and calculate values of rewards, used for training the model by evaluating its decisions. We study the solution in terms of the reward function form, the model’s hyperparameters and the exploited camera images processing method, and provide an analysis of the correctness and speed of the model’s functioning. As a result, we obtain a valid model able to steer the robot from the starting point to the destination based on visual cues and inputs from other sensors.}
}
@article{ZHANG20221,
title = {Resource allocation in UAV assisted air ground intelligent inspection system},
journal = {Cognitive Robotics},
volume = {2},
pages = {1-12},
year = {2022},
issn = {2667-2413},
doi = {https://doi.org/10.1016/j.cogr.2021.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S2667241321000215},
author = {Zhuoya Zhang and Fei Xu and Zengshi Qin and Yue Xie},
keywords = {Power inspection, Resource allocation, Genetic algorithm, Unmanned aerial vehicle, Mobile edge computing},
abstract = {With the progress of power grid technology and intelligent technology, intelligent inspection robot (IR) came into being and are expected to become the main force of substation inspection in the future. Among them, mobile edge computing provides a promising architecture to meet the explosive growth of communication and computing needs of inspection robot. Inspection robot can transmit the collected High Definition (HD) video to adjacent edge servers for data processing and state research and judgment. However, the communication constraints of long-distance transmission, high reliability and low delay pose challenges to task offloading optimization. Therefore, this paper introduced Unmanned Aerial Vehicle (UAV) and established UAV assisted mobile edge computing system. UAV assisted and mobile edge computing are combined to form edge computing nodes. In this way, it provided communication and computing services to the IR for fast data processing. Specifically, in order to optimize the system energy consumption, a resource allocation strategy based on genetic algorithm is proposed. By optimizing the offloading decision and computing resource allocation of the IRs, the computing task of the IRs are offloaded to an energy-efficient UAV. The experimental results show that the resource allocation strategy based on genetic algorithm can effectively reduce the energy consumption and cost of UAVs and IRs, and effectively realize the reasonable allocation of resources. The results verify the effectiveness and reliability of the algorithm in the real scene.}
}
@article{LOPEZJIMENEZ2019131,
title = {Columnar cactus recognition in aerial images using a deep learning approach},
journal = {Ecological Informatics},
volume = {52},
pages = {131-138},
year = {2019},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2019.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S1574954119300895},
author = {Efren López-Jiménez and Juan Irving Vasquez-Gomez and Miguel Angel Sanchez-Acevedo and Juan Carlos Herrera-Lozada and Abril Valeria Uriarte-Arcia},
keywords = {Deep learning, Cactus, Arid land, Environmental conservation, Drones},
abstract = {Tehuacán-Cuicatlán Valley is a semi-arid zone in the south of Mexico. It was inscribed in the World Heritage List by the UNESCO in 2018. This unique area has wide biodiversity including several endemic plants. Unfortunately, human activity is constantly affecting the area. A way to preserve a protected area is to carry out autonomous surveillance of the area. A first step to reach this autonomy is to automatically detect and recognize elements in the area. In this work, we present a deep learning based approach for columnar cactus recognition, specifically, the Neobuxbaumia tetetzo species, endemic of the Valley. An image dataset was generated for this study by our research team, containing more than 10,000 image examples. The proposed approach uses this dataset to train a modified LeNet-5 Convolutional Neural Network. Experimental results have shown a high recognition accuracy, 0.95 for the validation set, validating the use of the approach for columnar cactus recognition.}
}
@article{LE2021108477,
title = {Reinforcement learning-based optimal complete water-blasting for autonomous ship hull corrosion cleaning system},
journal = {Ocean Engineering},
volume = {220},
pages = {108477},
year = {2021},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2020.108477},
url = {https://www.sciencedirect.com/science/article/pii/S0029801820313846},
author = {Anh Vu Le and Phone Thiha Kyaw and Prabakaran Veerajagadheswar and M.A. Viraj J. Muthugala and Mohan Rajesh Elara and Madhu Kumar and Nguyen Huu {Khanh Nhan}},
keywords = {Ship maintenance industry, Corrosion cleaning, Benchmarking blasting quality, Reinforcement learning, Path planning},
abstract = {Routine cleaning of the corroded ship hulls in dry dock maintenance guarantees the smooth operation of the shipping industry. Deploying the autonomous system to remove the corrosion by water-blasting is a feasible approach to ease the burden in manual operation and to reduce water, time, and energy consumption. In this paper, the water-blasting framework is proposed for a novel robot platform named Hornbill with the adhesion mechanism by permanent magnetic, self-localization by sensor fusion to navigate smoothly on a vertical surface. Hence, we propose a complete waypoint path planning (CWPP) to re-blast the self-synthesizing deep convolutional neural network (DCNN) based corrosion heatmap by initial-blasting. The optimal CWPP problem, including the shortest travel distance and shortest travel time to save water, power while ensuring visiting all predefined waypoints by benchmarking output, is modeled as the classic Travel Salesman Problem (TSP). Further, the Pareto-optimal trajectory for given TSP has been driven by the reinforcement learning (RL) technique with a proposed reward function based on the robot's operation during blasting. From the experimental results at the shipyard site, the proposed RL-based CWPP generates the Pareto-optimal trajectory that enables the water-blasting robot to spend about 10% of energy and 9% of water less than the second-best evolutionary-based optimization method in various workspaces.}
}
@article{RAYAN2019361,
title = {Machine Learning Approaches in Smart Health},
journal = {Procedia Computer Science},
volume = {154},
pages = {361-368},
year = {2019},
note = {Proceedings of the 9th International Conference of Information and Communication Technology [ICICT-2019] Nanning, Guangxi, China January 11-13, 2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.06.052},
url = {https://www.sciencedirect.com/science/article/pii/S187705091930821X},
author = {Zeina Rayan and Marco Alfonse and Abdel-Badeeh M. Salem},
keywords = {Smart Health, Electronic Health, Medical Informatics, Machine Learning},
abstract = {The increase of age average led to an increase in the demand of providing and improving the service of healthcare. The advancing of the information and communication technology (ICT) led to the development of smart cities which have a lot of components. One of those components is Smart Health (s-Health), which is used in improving healthcare by providing many services such as patient monitoring, early diagnosis of diseases and so on. Nowadays there are many machine learning techniques that can facilitates s-Health services. This paper reviews recent published papers in the area of smart health starting from the years 2011 to 2017, and a structured analysis for different machine learning (ML) approaches that are applied in s-Health. The results show that the ML approach is used in many s-Health applications such as Glaucoma diagnosis, Alzheimer’s disease, bacterial sepsis diagnoses, the Intensive Care Unit (ICU) readmissions, and cataract detection. The Artificial Neural Network (ANN), Support Vector Machine (SVM) algorithm and deep learning models especially the Convolutional Neural Network (CNN) are the most commonly used machine learning approaches where they proved to get high evaluation performance in most cases.}
}
@article{GU2022123,
title = {Hybrid interpretable predictive machine learning model for air pollution prediction},
journal = {Neurocomputing},
volume = {468},
pages = {123-136},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.09.051},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221014296},
author = {Yuanlin Gu and Baihua Li and Qinggang Meng},
keywords = {Air pollution prediction, Interpretable machine learning, Neural network, NARMAX model},
abstract = {Air pollution prediction is a burning issue, as pollutants can harm human health. Traditional machine learning models usually aim to improve the overall prediction accuracy but neglect the accuracy for peak values. Moreover, these models are not interpretable. They fail to explain the interactions between various determining factors and their impacts on air pollution. In this paper, we propose a new Hybrid Interpretable Predictive Machine Learning model for the Particulate Matter 2.5 prediction, which carries two novelties. First, a hybrid model structure is constructed with deep neural network and Nonlinear Auto Regressive Moving Average with Exogenous Input model. Second, automatic feature generation and feature selection procedures are integrated into this hybrid model. The experimental results demonstrate the superiority of our model over other models in prediction accuracy for peak values and model interpretability. The proposed model reveals how PM2.5 prediction is estimated by historical PM2.5, weather, and season. The accuracies (measured by correlation coefficients) of 1, 3 and 6-hour-ahead prediction are 0.9870, 0.9332 and 0.8587, respectively. More importantly, the proposed approach presents a new interpretable machine learning framework for time series data, enabling to explain complex dependence of multimode inputs, and to build reliable predictive models.}
}
@article{PEREIRA2022106645,
title = {Nitrogen variability assessment of pasture fields under an integrated crop-livestock system using UAV, PlanetScope, and Sentinel-2 data},
journal = {Computers and Electronics in Agriculture},
volume = {193},
pages = {106645},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106645},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006621},
author = {F.R.da S. Pereira and J.P. {de Lima} and R.G. Freitas and A.A. {Dos Reis} and L.R.do Amaral and G.K.D.A. Figueiredo and R.A.C. Lamparelli and P.S.G. Magalhães},
keywords = {Remote sensing, Machine learning, Ruzi grass, Precision agriculture},
abstract = {In agricultural production, nitrogen (N) deficiency reduces yield, while overapplication may have an unwanted impact on the natural environment and farm finances. Frequent field N monitoring is impractical due to the time and cost required for traditional laboratory analysis. However, remotely sensed data are an alternative to evaluate and monitor crop nutrition status throughout the growing season. This study evaluates the spatial distribution of N in pasture fields cultivated under an integrated crop-livestock system (ICLS) using unmanned aerial vehicle (UAV) and satellites data. We assessed the performance of UAV, PlanetScope, and Sentinel-2A platforms to predict the N parameters: plant N content (PNC), aboveground biomass (AGB), and nutritional nitrogen index (NNI). Moreover, we also simulated a UAV device with a visible light sensor (i.e., red–green-blue (RGB)) as a costly alternative to near-infrared (NIR) sensors to monitor N status. Finally, we assessed whether combining the information from these platforms would improve the N predictions in our study area. The UAV, PlanetScope, and Sentinel-2A data were able to estimate N parameters in the studied pasture fields using the random forest regression algorithm. The UAV multispectral data resulted in the best prediction accuracies (R2: 0.84-PNC, 0.70-AGB, and 0.84-NNI). The combination of UAV_RGB with either PlanetScope (R2: 0.79-PNC, 0.67-AGB, 0.77-NNI) or Sentinel-2A (R2: 0.76-PNC, 0.57-AGB, 0.69-NNI) improved the performance of the three platforms individually (UAV_RGB, PlanetScope or Sentinel-2A). The association between high spatial and spectral resolutions contributes to the highest prediction accuracy in estimating N variability in pasture fields using remote sensing data. Our results suggest that remote sensing techniques are a reliable approach for N monitoring in commercial pasture fields under ICLS.}
}
@article{ZHANG2021283,
title = {Multi-scale adversarial network for vehicle detection in UAV imagery},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {180},
pages = {283-295},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621002021},
author = {Ruiqian Zhang and Shawn Newsam and Zhenfeng Shao and Xiao Huang and Jiaming Wang and Deren Li},
keywords = {Vehicle detection, UAV imagery, Multi-scale structure, Adversarial network, Domain adaptation},
abstract = {Vehicle detection in Unmanned Aerial Vehicle (UAV) imagery plays a crucial role in a variety of applications. However, UAVs are usually small, very maneuverable, and can take images from a variety of viewpoints and heights, leading to large differences in vehicle appearance and size. To address the vehicle detection challenge with such diversity in UAV images, we seek to align features between different viewpoints, illumination, weather, and background using remote sensing imagery as an anchor. Following this domain adaptation concept, we propose a multi-scale adversarial network, consisting of a deep convolutional feature extractor, a multi-scale discriminator, and a vehicle detection network. Specifically, the feature extractor is a Siamese network with one path for the UAV imagery and another for the satellite imagery. The shared weights in this sub-network allow us to exploit the large collections of labeled remote sensing imagery for improved vehicle detection in UAV imagery. Experimental results suggest that our proposed algorithm improves the vehicle detection accuracy in the UAVDT dataset and VisDrone dataset. The proposed model achieves great performance in images taken from different perspectives, at different altitudes, and under different imaging situations.}
}
@article{AHMED2021102632,
title = {Deep learning-driven opportunistic spectrum access (OSA) framework for cognitive 5G and beyond 5G (B5G) networks},
journal = {Ad Hoc Networks},
volume = {123},
pages = {102632},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102632},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521001529},
author = {Ramsha Ahmed and Yueyun Chen and Bilal Hassan},
keywords = {Deep learning, Cognitive radio (CR), Spectrum sensing, Opportunistic spectrum access (OSA), 5G/B5G wireless networks},
abstract = {The evolving 5G and beyond 5G (B5G) wireless technologies are envisioned to provide ubiquitous connectivity and great heterogeneity in communication infrastructure by connecting diverse devices and providing multifarious services. Recently, the Internet of Things (IoT) and unmanned aerial vehicles (UAVs) are realized as an essential component of the upcoming 5G/B5G networks, enabling enhanced communication capacity, high reliability, low latency, and massive connectivity. However, one limiting factor in the expansion of 5G/B5G technology is the finite radio spectrum, which necessitates managing the anticipated spectrum crunch for future wireless networks. One potential solution is to develop intelligent cognitive methods to dynamically optimize the use of spectrum in 5G/B5G networks to solve the imminent problem of spectrum congestion and improve radio efficiency. This paper addresses the opportunistic spectrum access (OSA) problem in the 5G/B5G cognitive radio (CR) network of IoTs and UAVs through the novel deep learning-based detector, dubbed as Deep-CRNet. The proposed detector employs residual connections with cascaded multi-kernel convolutions to identify the primary user (PU) spectrum usage by extracting the inherent multi-scale signal and noise features in the sensed transmission patterns. Thereby, Deep-CRNet intelligently learns and locates the spectrum holes so that secondary users (SUs) and PUs can dynamically share network spectrum resources. The efficacy of Deep-CRNet is validated through simulation results, where it achieved 99.74% accuracy with 99.65% precision and 99.83% recall in accurately classifying the PU status. In addition, the average correct detection probability of Deep-CRNet in the low signal-to-noise ratio (−20 dB to −15 dB) range is 38.21% higher than the second best-performing detector.}
}
@article{GIACOMIN201526,
title = {A probabilistic approach for designing nonlinear optimal robust tracking controllers for unmanned aerial vehicles},
journal = {Applied Soft Computing},
volume = {34},
pages = {26-38},
year = {2015},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2015.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S1568494615002483},
author = {Paulo André S. Giacomin and Elder Moreira Hemerly and Witold Pedrycz},
keywords = {Bio-inspired optimization, Automatic control, Simulation, Unmanned aerial vehicles},
abstract = {In this study, we propose a probabilistic approach for designing nonlinear optimal robust tracking controllers for unmanned aerial vehicles. The controller design is formulated in terms of a multi-objective optimization problem that is solved by using a bio-inspired optimization algorithm, offering high likelihood of finding an optimal or near-optimal global solution. The process of tuning the controller minimizes differences between system outputs and optimal specifications given in terms of rising time, overshoot and steady-state error, and the controller succeed in fitting the performance requirements even considering parametric uncertainties and the nonlinearities of the aircraft. The stability of the controller is proved for the nominal case and its robustness is carefully verified by means of Monte Carlo simulations.}
}
@article{GE2022106621,
title = {Facial expression recognition based on deep learning},
journal = {Computer Methods and Programs in Biomedicine},
pages = {106621},
year = {2022},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2022.106621},
url = {https://www.sciencedirect.com/science/article/pii/S0169260722000062},
author = {Huilin Ge and Zhiyu Zhu and Yuewei Dai and Biao Wang and Xuedong Wu},
keywords = {3D face depth information, Deep learning, Facial expression recognition, Target detection, Convolutional neural network},
abstract = {Background and objective
Facial expression recognition technology will play an increasingly important role in our daily life. Autonomous driving, virtual reality and all kinds of robots integrated into our life depend on the development of facial expression recognition technology. Many tasks in the field of computer vision are based on deep learning technology and convolutional neural network. The paper proposes an occluded expression recognition model based on the generated countermeasure network. The model is divided into two modules, namely, occluded face image restoration and face recognition.
Methods
Firstly, this paper summarizes the research status of deep facial expression recognition methods in recent ten years and the development of related facial expression database. Then, the current facial expression recognition methods based on deep learning are divided into two categories: Static facial expression recognition and dynamic facial expression recognition. The two methodswill be introduced and summarized respectively. Aiming at the advanced deep expression recognition algorithms in the field, the performance of these algorithms on common expression databases is compared, and the strengths and weaknesses of these algorithms are analyzed in detail.
Discussion and Results
As the task of facial expression recognition is gradually transferred from the controlled laboratory environment to the challenging real-world environment, with the rapid development of deep learning technology, deep neural network can learn discriminative features, and is gradually applied to automatic facial expression recognition task. The current deep facial expression recognition system is committed to solve the following two problems: 1) Overfitting due to lack of sufficient training data; 2) In the real world environment, other variables that have nothing to do with expression bring interference problems.
Conclusion
From the perspective of algorithm, combining other expression models, such as facial action unit model and pleasure arousal dimension model, as well as other multimodal models, such as audio mode, 3D face depth information and human physiological information, can make expression recognition more practical.}
}
@article{ZHANG2022107315,
title = {On UAV source seeking with complex dynamic characteristics and multiple constraints: A cooperative standoff monitoring mode},
journal = {Aerospace Science and Technology},
volume = {121},
pages = {107315},
year = {2022},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107315},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821008257},
author = {Menghua Zhang and Honglun Wang and Jianfa Wu},
keywords = {Source seeking, Unmanned aerial vehicle, Dynamic level set tracking, Interfered fluid dynamical system},
abstract = {Aiming at the source-seeking problem with complex dynamic characteristics and multiple constraints in a three-dimensional (3-D) environment, a cooperative standoff monitoring mode that uses unmanned aerial vehicles (UAVs) is proposed in this paper. First, the dynamic pollutant field is modeled by a 3-D advection-diffusion partial differential equation (PDE), and quantifiable indexes are proposed for source seeking around multiple constraints, which consist of UAV kinematics, no-fly zones and cumulative exposure to the high concentration of pollutants. Second, to eliminate the essential gradient information in source seeking of the dependence on known advection and diffusion coefficients in the PDE, UAVs cooperatively estimate the spatial gradient of the pollutant field by the least squares method. Third, a cooperative standoff monitoring mode for source seeking is proposed based on dynamic level set tracking and an interfered fluid dynamical system (IFDS), and receding horizon control (RHC) is introduced to improve the source-seeking effect. Finally, source localization is achieved by the UAVs with the multiple constraints being satisfied, and the effectiveness of the proposed method is validated by the simulation results.}
}
@article{RAJ2021103107,
title = {A survey on the role of Internet of Things for adopting and promoting Agriculture 4.0},
journal = {Journal of Network and Computer Applications},
volume = {187},
pages = {103107},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103107},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521001284},
author = {Meghna Raj and Shashank Gupta and Vinay Chamola and Anubhav Elhence and Tanya Garg and Mohammed Atiquzzaman and Dusit Niyato},
abstract = {There is a rapid increase in the adoption of emerging technologies like the Internet of Things (IoT), Unmanned Aerial Vehicles (UAV), Internet of Underground Things (IoUT), Data analytics in the agriculture domain to meet the increased food demand to cater to the increasing population. Agriculture 4.0 is set to revolutionize agriculture productivity by using Precision Agriculture (PA), IoT, UAVs, IoUT, and other technologies to increase agriculture produce for growing demographics while addressing various farm-related issues. This survey provides a comprehensive overview of how multiple technologies such as IoT, UAVs, IoUT, Big Data Analytics, Deep Learning Techniques, and Machine Learning methods can be used to manage various farm-related operations. For each of these technologies, a detailed review is done on how the technology is being used in Agriculture 4.0. These discussions include an overview of relevant technologies, their use cases, existing case studies, and research works that demonstrate the use of these technologies in Agriculture 4.0. This paper also highlights the various future research gaps in the adoption of these technologies in Agriculture 4.0.}
}
@article{TAN2021107261,
title = {YOLOv4_Drone: UAV image target detection based on an improved YOLOv4 algorithm},
journal = {Computers & Electrical Engineering},
volume = {93},
pages = {107261},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107261},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621002445},
author = {Li Tan and Xinyue Lv and Xiaofeng Lian and Ge Wang},
keywords = {UAV, Target detection, YOLOv4, Attention mechanism},
abstract = {Advanced communications and networks have greatly improved the user experience, and unmanned aerial vehicle (UAV) are an important technology that supports people's daily life and military activities. Since target detection in UAV images is complicated by a complex background, small targets, and target occlusion, the detection accuracy of the You Only Look Once(YOLO) v4 algorithm is relatively low. Therefore, hollow convolution is used to resample the feature image to improve the feature extraction and target detection performance. In addition, the ultra-lightweight subspace attention mechanism (ULSAM) is used to derive different attention feature maps for each subspace of the feature map for multi-scale feature representation. Finally, soft non-maximum suppression (Soft-NMS) is introduced to minimize the occurrence of missed targets due to occlusion. The experimental results prove that the proposed UAV image target detection model (YOLOv4_Drone) has 5% improved to the YOLOv4 algorithm, demonstrating the effectiveness of the method.}
}
@article{CHEN2022102650,
title = {DeepUrbanDownscale: A physics informed deep learning framework for high-resolution urban surface temperature estimation via 3D point clouds},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {106},
pages = {102650},
year = {2022},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102650},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421003573},
author = {Linwei Chen and Bowen Fang and Lei Zhao and Yu Zang and Weiquan Liu and Yiping Chen and Cheng Wang and Jonathan Li},
keywords = {Deep urban downscale, Physics informed neural network, 3D point cloud},
abstract = {Accurate high-resolution downscaling of surface climate variables (such as surface temperature) over urban areas has long been a critical yet unresolved research problem in the field of urban climate and environmental sciences. In this paper, we propose a novel physics informed neural network (PINN) based framework: DeepUrbanDownscale (DUD) for high-resolution urban surface temperature estimation. Anchored in process-based modeling and satellite remote sensing, the DUD network leverages the high-precision 3D point clouds to achieve accurate urban land surface temperature (LST) estimation at an ultra-high spatial resolution. This network, ingesting the high-precision land surface geometry information derived from 3D point clouds and guided by the atmospheric physics related to surface temperature, constructs a physics informed data-driven framework to fit high-resolution temperature distribution, which is otherwise difficult to be obtained by physical (numerical) simulations or traditional machine learning. Specifically, the proposed DUD network contains two branches: The Global Feature Perception (GPFP) branch and Local Urban Surface Perception (LUSP) branch. The former considers the broader-scale urban physical parameters, constraining the estimation results in accordance with the relevant physical laws. The latter, by employing a proposed local spatial coefficient index (LSCI), which is based on 3D point clouds, the estimation performance is further improved at a very high resolution. Results from designed experiments demonstrate that the proposed DUD network predicts the urban LST on a 30-by-30 m grid with the estimated error less than 0.2 Kelvin compared to the satellite measurement, which is well below the errors of other traditional methods.}
}
@article{WANG2020106150,
title = {Tracking a dynamic invading target by UAV in oilfield inspection via an improved bat algorithm},
journal = {Applied Soft Computing},
volume = {90},
pages = {106150},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106150},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620300909},
author = {Yi’an Wang and Kun Li and Ying Han and Fawei Ge and Wensu Xu and Liang Liu},
keywords = {Oilfield inspection, UAV, Dynamic target tracking, Trajectory prediction and optimization, Swarm intelligence},
abstract = {A novel dynamic invading target tracking method for the oilfield inspection by unmanned aerial vehicle (UAV) is presented in this paper. In this study the quad-rotor UAV is used to track an invading target, because the traditional manual inspection method and fixed-points video monitoring method has some drawbacks such as low efficiency, high cost, blind spot, and so on. A trajectory prediction method for the ground dynamic invading target is firstly proposed to predict the moving trajectory of the invading target. Then, the swarm intelligence based optimization algorithm is used to optimize the tracking trajectory of UAV, which in order to keep the distance between the UAV and the target closing to the desired distance during tracking process. In order to overcome some drawbacks such as easily being fallen into the local optimal solution and poor stability of the optimization, an improved bat algorithm (named FOBA) is proposed to improve the local searching ability of the bat algorithm (BA), which uses a food searching mechanism in the fruit fly optimization algorithm (FOA). Case studies are conducted with the desired distance is 50m between the UAV and the target, and experimental results show that the FOBA algorithm can effectively keep the tracking distance between the UAV and the target being about 55m, which is better than some other methods.}
}
@article{XU2021103699,
title = {Prediction of tunnel boring machine operating parameters using various machine learning algorithms},
journal = {Tunnelling and Underground Space Technology},
volume = {109},
pages = {103699},
year = {2021},
issn = {0886-7798},
doi = {https://doi.org/10.1016/j.tust.2020.103699},
url = {https://www.sciencedirect.com/science/article/pii/S0886779820306532},
author = {Chen Xu and Xiaoli Liu and Enzhi Wang and Sijing Wang},
keywords = {TBM, Operating parameters, Machine learning algorithms, CNN, LSTM},
abstract = {The operating parameters of a tunnel boring machine (TBM) reflect its geological conditions and working status and are accordingly critical data for ensuring safe and efficient tunnel construction. The accurate prediction of the advance rate, rotation speed, thrust, and torque indicators based on the operating parameters can guide the control and application of a TBM. In this study, we analyzed the relationships between the TBM operating parameters and daily collected TBM data. We used the smoothing method and outlier detection to process this data, and determined the stable values of four different TBM indicators in the ascending phase of a complete TBM operational segment. Then, we evaluated the application of five different statistical and ensemble machine learning methods (Bayesian ridge regression (BR), nearest neighbors regression, random forests, gradient tree boosting (GTB), and support vector machine) and two different deep neural networks (a convolutional neural network (CNN) and long short-term memory network (LSTM)) to establish prediction models. The GTB method provided the best prediction accuracy and the BR method provided the least calculation time of the five different statistical and ensemble machine learning methods evaluated. The LSTM method provided a higher prediction accuracy than the CNN model. The ensemble machine learning methods were found to be the most accurate for the relatively limited data sets used in this study, suggesting that sufficient data must be present before the advantages of deep neural networks can be truly realized. The successful application of statistical, ensemble, and deep neural network machine learning methods to predict TBM indicators in this study suggests the promise of machine learning in this application.}
}
@article{BRUNETTI201817,
title = {Computer vision and deep learning techniques for pedestrian detection and tracking: A survey},
journal = {Neurocomputing},
volume = {300},
pages = {17-33},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.01.092},
url = {https://www.sciencedirect.com/science/article/pii/S092523121830290X},
author = {Antonio Brunetti and Domenico Buongiorno and Gianpaolo Francesco Trotta and Vitoantonio Bevilacqua},
keywords = {Pedestrian detection, Human tracking, Deep learning, Convolutional neural network, Machine learning, Artificial neural network, Features extraction},
abstract = {Pedestrian detection and tracking have become an important field in the computer vision research area. This growing interest, started in the last decades, might be explained by the multitude of potential applications that could use the results of this research field, e.g. robotics, entertainment, surveillance, care for the elderly and disabled, and content-based indexing. In this survey paper, vision-based pedestrian detection systems are analysed based on their field of application, acquisition technology, computer vision techniques and classification strategies. Three main application fields have been individuated and discussed: video surveillance, human-machine interaction and analysis. Due to the large variety of acquisition technologies, this paper discusses both the differences between 2D and 3D vision systems, and indoor and outdoor systems. The authors reserved a dedicated section for the analysis of the Deep Learning methodologies, including the Convolutional Neural Networks in pedestrian detection and tracking, considering their recent exploding adoption for such a kind systems. Finally, focusing on the classification point of view, different Machine Learning techniques have been analysed, basing the discussion on the classification performances on different benchmark datasets. The reported results highlight the importance of testing pedestrian detection systems on different datasets to evaluate the robustness of the computed groups of features used as input to classifiers.}
}
@article{SALEHI2021108415,
title = {Improving UAV base station energy efficiency for industrial IoT URLLC services by irregular repetition slotted-ALOHA},
journal = {Computer Networks},
volume = {199},
pages = {108415},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108415},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621003856},
author = {Shavbo Salehi and Behdis Eslamnour},
keywords = {Unmanned aerial vehicle base station, Ultra-reliable and low latency communications, Irregular repetition slotted-ALOHA, Mahalanobis distance, Energy efficiency, Trajectory design, Q-learning, Clustering},
abstract = {In the past few years, the continual improvement of 5G technology has supported powerful IoT (Internet of Things) and IIoT (Industrial IoT) devices which have been used to provide a wide range of services. One of the service types that has been noticed recently is URLLC (Ultra-Reliable Low-Latency Communication) service that requires highly reliable communication and low latency bounds. In this paper, intending to meet the latency and reliability requirements of IIoT users located outdoor in a hard-to-reach area, we propose to use a UAV-BS (Unmanned Aerial Vehicle Base Station) for air-to-ground (A2G) communications. Despite the very fact that UAV-BSs have been used widely, yet they have some shortcomings in flight time. So we proposed an energy-efficient trajectory design method to reduce the UAV-BS’s energy consumption for both the communication and mobility functions while fulfilling the application’s reliability and latency requirements. We proposed a UMC-IRSA (UAV-BS Multi-Channel Irregular Repetition Slotted-ALOHA) method to adapt the New Radio (NR) distinct frame structure for IIoT users. The IIoT nodes are clustered by the UMC-IRSA method (based on Mahalanobis distance) to decrease the UAV-BS energy consumption. The simulation results show that the UMC-IRSA clustering method combined with the Q-Learning algorithm for clusters serving decreases the UAV-BS energy consumption for flying in fixed altitude. The reduction in energy consumption provided by using the combination of UMC-IRSA and Q-Learning, in comparison to the combination of UMC-IRSA and Random Serving, combination of CRP (Chinese Restaurant Process) and Q-Learning, and CRP and Random Serving is 19%, 24%, and 31% respectively.}
}
@article{RODRIGUEZABREO2022103910,
title = {Backstepping control for a UAV-manipulator tuned by Cuckoo Search algorithm},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103910},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103910},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001950},
author = {Omar Rodríguez-Abreo and Francisco-Javier Ornelas-Rodríguez and Alfonso Ramírez-Pedraza and Juan B. Hurtado-Ramos and José-Joel González-Barbosa},
keywords = {Cuckoo Search algorithm, Backstepping control, Unmanned aerial vehicle, Manipulator, Optimal control},
abstract = {Manipulators coupled with an Unmanned Aerial Vehicle (UAV) have made it possible to perform aerial handling, transport, and picking maneuvers. One of the techniques used to control these systems is a backstepping controller that has shown high performance compared to a PID in the face of uncertainties and parametric disturbances. This paper presents the study of a backstepping controller for a mobile manipulator (MM–UAV) system tuned with the Cuckoo Search algorithm (CS) for trajectory tracking. Unlike other research, this study focuses on optimization using this metaheuristic algorithm that has never been applied in an MM–UAV. The system is divided in a novel way to implement the CS, considering the dependence of each rotation axis with the correspondence translation axis. Additionally, the tuning focuses on two critical points of the dynamic response, the overshoot and settling time. The results at the simulation and experimental level show that for all cases, a settling time of fewer than 0.8 s and overshoot is minor than 2%. This allows a balanced response of the system, which directly impacts energy consumption. The results are compared with a PID controller to verify the proposed work efficiency, showing a reduction of up to 8% of overshoots without exceeding in any experiment the maximum settling time of 0.8 s imposed to the system.}
}
@article{HASAN2021106067,
title = {A survey of deep learning techniques for weed detection from images},
journal = {Computers and Electronics in Agriculture},
volume = {184},
pages = {106067},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106067},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921000855},
author = {A S M Mahmudul Hasan and Ferdous Sohel and Dean Diepeveen and Hamid Laga and Michael G.K. Jones},
keywords = {Deep learning, Weed detection, Weed classification, Machine learning, Digital agriculture},
abstract = {The rapid advances in Deep Learning (DL) techniques have enabled rapid detection, localisation, and recognition of objects from images or videos. DL techniques are now being used in many applications related to agriculture and farming. Automatic detection and classification of weeds can play an important role in weed management and so contribute to higher yields. Weed detection in crops from imagery is inherently a challenging problem because both weeds and crops have similar colours (‘green-on-green’), and their shapes and texture can be very similar at the growth phase. Also, a crop in one setting can be considered a weed in another. In addition to their detection, the recognition of specific weed species is essential so that targeted controlling mechanisms (e.g. appropriate herbicides and correct doses) can be applied. In this paper, we review existing deep learning-based weed detection and classification techniques. We cover the detailed literature on four main procedures, i.e., data acquisition, dataset preparation, DL techniques employed for detection, location and classification of weeds in crops, and evaluation metrics approaches. We found that most studies applied supervised learning techniques, they achieved high classification accuracy by fine-tuning pre-trained models on any plant dataset, and past experiments have already achieved high accuracy when a large amount of labelled data is available.}
}
@article{ALSAD201986,
title = {RF-based drone detection and identification using deep learning approaches: An initiative towards a large open source drone database},
journal = {Future Generation Computer Systems},
volume = {100},
pages = {86-97},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18330760},
author = {Mohammad F. Al-Sa’d and Abdulla Al-Ali and Amr Mohamed and Tamer Khattab and Aiman Erbad},
keywords = {UAV detection, Drone identification, Deep learning, Neural networks, Machine learning},
abstract = {The omnipresence of unmanned aerial vehicles, or drones, among civilians can lead to technical, security, and public safety issues that need to be addressed, regulated and prevented. Security agencies are in continuous search for technologies and intelligent systems that are capable of detecting drones. Unfortunately, breakthroughs in relevant technologies are hindered by the lack of open source databases for drone’s Radio Frequency (RF) signals, which are remotely sensed and stored to enable developing the most effective way for detecting and identifying these drones. This paper presents a stepping stone initiative towards the goal of building a database for the RF signals of various drones under different flight modes. We systematically collect, analyze, and record raw RF signals of different drones under different flight modes such as: off, on and connected, hovering, flying, and video recording. In addition, we design intelligent algorithms to detect and identify intruding drones using the developed RF database. Three deep neural networks (DNN) are used to detect the presence of a drone, the presence of a drone and its type, and lastly, the presence of a drone, its type, and flight mode. Performance of each DNN is validated through a 10-fold cross-validation process and evaluated using various metrics. Classification results show a general decline in performance when increasing the number of classes. Averaged accuracy has decreased from 99.7% for the first DNN (2-classes), to 84.5% for the second DNN (4-classes), and lastly, to 46.8% for the third DNN (10-classes). Nevertheless, results of the designed methods confirm the feasibility of the developed drone RF database to be used for detection and identification. The developed drone RF database along with our implementations are made publicly available for students and researchers alike.}
}
@article{LI20201747,
title = {Multi-block SSD based on small object detection for UAV railway scene surveillance},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {6},
pages = {1747-1755},
year = {2020},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.02.024},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120301126},
author = {Yundong LI and Han DONG and Hongguang LI and Xueyan ZHANG and Baochang ZHANG and Zhifeng XIAO},
keywords = {Deep learning, Multi-block Single Shot MultiBox Detector (SSD), Objection detection, Railway scene, Unmanned aerial vehicle remote sensing},
abstract = {A method of multi-block Single Shot MultiBox Detector (SSD) based on small object detection is proposed to the railway scene of unmanned aerial vehicle surveillance. To address the limitation of small object detection, a multi-block SSD mechanism, which consists of three steps, is designed. First, the original input images are segmented into several overlapped patches. Second, each patch is separately fed into an SSD to detect the objects. Third, the patches are merged together through two stages. In the first stage, the truncated object of the sub-layer detection result is spliced. In the second stage, a sub-layer suppression and filtering algorithm applying the concept of non-maximum suppression is utilized to remove the overlapped boxes of sub-layers. The boxes that are not detected in the main-layer are retained. In addition, no sufficient labeled training samples of railway circumstance are available, thereby hindering the deployment of SSD. A two-stage training strategy leveraging to transfer learning is adopted to solve this issue. The deep learning model is preliminarily trained using labeled data of numerous auxiliaries, and then it is refined using only a few samples of railway scene. A railway spot in China, which is easily damaged by landslides, is investigated as a case study. Experimental results show that the proposed multi-block SSD method produces an overall accuracy of 96.6% and obtains an improvement of up to 9.2% compared with the traditional SSD.}
}
@article{LOVER2021146,
title = {Explainable AI methods on a deep reinforcement learning agent for automatic docking⁎⁎This work was supported by the Research Council of Norway through the EXAIGON project, project number 304843.},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {16},
pages = {146-152},
year = {2021},
note = {13th IFAC Conference on Control Applications in Marine Systems, Robotics, and Vehicles CAMS 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.10.086},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321014889},
author = {Jakob Løver and Vilde B. Gjærum and Anastasios M. Lekkas},
keywords = {Marine control systems, Explainable Artificial Intelligence, Deep Reinforcement Learning, Autonomous ships, Docking},
abstract = {Artifical neural networks (ANNs) have made their way into marine robotics in the last years, where they are used in control and perception systems, to name a few examples. At the same time, the black-box nature of ANNs is responsible for key challenges related to interpretability and trustworthiness, which need to be addressed if ANNs are to be deployed safely in real-life operations. In this paper, we implement three XAI methods to provide explanations to the decisions made by a deep reinforcement learning agent: Kernel SHAP, LIME and Linear Model Trees (LMTs). The agent was trained via Proximal Policy Optimization (PPO) to perform automatic docking on a fully-actuated vessel. We discuss the properties and suitability of the three methods, and juxtapose them with important attributes of the docking agent to provide context to the explanations.}
}
@article{HUYNH2019102844,
title = {Quasi-autonomous bolt-loosening detection method using vision-based deep learning and image processing},
journal = {Automation in Construction},
volume = {105},
pages = {102844},
year = {2019},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2019.102844},
url = {https://www.sciencedirect.com/science/article/pii/S092658051930250X},
author = {Thanh-Canh Huynh and Jae-Hyung Park and Hyung-Jo Jung and Jeong-Tae Kim},
keywords = {Bolted connection, Bolt-loosening, Deep learning, CNN, Hough transform, Canny line detector, Bolt detection, Bolt rotation estimation},
abstract = {In this study, a quasi-autonomous vision-based method is newly proposed for detecting loosened bolts in critical connections. The main idea of the approach is to estimate the rotational angles of bolts from the connection images by integrating deep learning technology with image processing techniques. Firstly, a regional convolutional neural network (RCNN)-based deep learning algorithm is developed to automatically detect and crop plausible bolts in the connection image. Also, the Hough line transform (HLT)-based image processing algorithm is designed to automatically estimate the bolt angles from the cropped bolt images. Secondly, the proposed vision-based approach is validated for bolt-loosening detection in a lab-scale girder connection using images captured by a smartphone camera. The accuracy of the RCNN-based bolt detector and the HLT-based bolt angle estimator are examined under different levels of perspective distortion and shooting distance. Finally, the practicality of the proposed vision-based method is verified on a real-scale girder bridge connection containing numerous bolts. The images of the connection are captured by an unmanned aerial vehicle and transferred to a computer where a quasi-autonomous bolt-loosening detection process is performed via the proposed algorithm. The experimental results demonstrate potentials of the proposed approach for quasi real-time bolt-loosening monitoring of large bolted connections. The results show that the perspective angle should not go beyond 40 degrees to ensure the accuracy of the detection results.}
}
@article{FU202011920,
title = {Deep Learning in Mining and Mineral Processing Operations: A Review},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {11920-11925},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.712},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320310296},
author = {Y. Fu and C. Aldrich},
keywords = {artificial intelligence, machine learning, mining, mineral processing},
abstract = {In this paper, the application of deep learning in the mining and processing of ores is reviewed. Deep learning is strongly impacting the development of sensor systems, particularly computer vision systems used in mining and mineral processing automation, where it is filling a gap not currently achievable by traditional approaches. To a lesser extent, deep learning is also being considered in the automation of decision support systems. There is significant scope for the application of deep learning to improve operations, but access to industrial data and big data infrastructure in operational environments are critical bottlenecks to the development and deployment of the technology.}
}
@article{ASLAM2021110992,
title = {A survey on deep learning methods for power load and renewable energy forecasting in smart microgrids},
journal = {Renewable and Sustainable Energy Reviews},
volume = {144},
pages = {110992},
year = {2021},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2021.110992},
url = {https://www.sciencedirect.com/science/article/pii/S1364032121002847},
author = {Sheraz Aslam and Herodotos Herodotou and Syed Muhammad Mohsin and Nadeem Javaid and Nouman Ashraf and Shahzad Aslam},
keywords = {Energy forecasting, Renewable energy, Deep learning, Artificial neural networks, Machine learning},
abstract = {Microgrids have recently emerged as a building block for smart grids combining distributed renewable energy sources (RESs), energy storage devices, and load management methodologies. The intermittent nature of RESs brings several challenges to the smart microgrids, such as reliability, power quality, and balance between supply and demand. Thus, forecasting power generation from RESs, such as wind turbines and solar panels, is becoming essential for the efficient and perpetual operations of the power grid and it also helps in attaining optimal utilization of RESs. Energy demand forecasting is also an integral part of smart microgrids that helps in planning the power generation and energy trading with commercial grid. Machine learning (ML) and deep learning (DL) based models are promising solutions for predicting consumers’ demands and energy generations from RESs. In this context, this manuscript provides a comprehensive survey of the existing DL-based approaches, which are developed for power forecasting of wind turbines and solar panels as well as electric power load forecasting. It also discusses the datasets used to train and test the different DL-based prediction models, enabling future researchers to identify appropriate datasets to use in their work. Even though there are a few related surveys regarding energy management in smart grid applications, they are focused on a specific production application such as either solar or wind. Moreover, none of the surveys review the forecasting schemes for production and load side simultaneously. Finally, previous surveys do not consider the datasets used for forecasting despite their significance in DL-based forecasting approaches. Hence, our survey work is intrinsically different due to its data-centered view, along with presenting DL-based applications for load and energy generation forecasting in both residential and commercial sectors. The comparison of different DL approaches discussed in this manuscript reveals that the efficiency of such forecasting methods is highly dependent on the amount of the historical data and thus a large number of data storage devices and high processing power devices are required to deal with big data. Finally, this study raises several open research problems and opportunities in the area of renewable energy forecasting for smart microgrids.}
}
@article{TANG2022527,
title = {Deep learning-based linear defects detection system for large-scale photovoltaic plants based on an edge-cloud computing infrastructure},
journal = {Solar Energy},
volume = {231},
pages = {527-535},
year = {2022},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2021.11.016},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X21009695},
author = {Wuqin Tang and Qiang Yang and Xiaochen Hu and Wenjun Yan},
keywords = {Edge computing, Defects diagnosis, Deep learning, Suspected defected area segmentation},
abstract = {Linear defects detection of photovoltaic (PV) modules plays a key role in the health assessment in PV plants. However, the conventional defects diagnosis is mainly carried out manually and hence is inefficient or even infeasible in practice. With the recent advances in computing and communication technologies, different forms of edge computing facilities are designed with less human intervention and a non-destructive inspection in the industry. However, the assessment of PV plants using electroluminescence images faces some fundamental challenges. This paper proposed an automatic linear defects detection system for large-scale PV plants based on an edge-cloud computing framework. A novel deep learning-based PV defects detection algorithmic solution is developed considering the trade-off between detection performance and computational complexity through allocating the computing tasks across the edge devices, edge server and cloud server. The proposed solution is evaluated through experiments using real-world data and the numerical results demonstrate its effectiveness and accuracy of PV defect detection as well as the reduction of communication overhead by decreasing the size of EL images.}
}
@article{LUNGU2020105912,
title = {Auto-landing of UAVs with variable centre of mass using the backstepping and dynamic inversion control},
journal = {Aerospace Science and Technology},
volume = {103},
pages = {105912},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.105912},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820305940},
author = {Mihai Lungu},
keywords = {UAV, Backstepping, Dynamic inversion, Auto-landing},
abstract = {The paper proposes the design methodology of a new auto-landing system for unmanned aerial vehicles (UAVs) with variable centre of mass subject to wind shears, wind gusts, and atmospheric turbulences. Starting from the UAV nonlinear dynamics, a new control architecture is developed. It combines the backstepping and dynamic inversion approaches for the control of UAV attitude angles, lateral deviation from runway, flight altitude, and forward speed during the three landing stages (final approach, glide slope, flare). The estimation of the wind shears, wind gusts, and atmospheric turbulences is achieved via a neural network based disturbance observer, included in the new auto-landing architecture. By its software implementation and validation, the robustness to wind type disturbances and the stability of the new auto-landing system are proved. There are cancelled the altitude error, the lateral deviation from runway, while the UAV trajectory is the desired one with continuous and smooth transition from one stage of landing to another.}
}
@article{DENG2021101328,
title = {Joint UAV trajectory and power allocation optimization for NOMA in cognitive radio network},
journal = {Physical Communication},
volume = {46},
pages = {101328},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101328},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721000653},
author = {Dan Deng and Mingfu Zhu},
keywords = {Cognitive radio network, NOMA, Power allocation, UAV},
abstract = {The joint unmanned aerial vehicle(UAV) trajectory and power allocation optimization for Non-orthogonal multiplex access (NOMA) protocol in cognitive radio network is investigated in this paper. In the considered system, the UAV node transmits data streams to multiple secondary users by using NOMA protocol under the interference constraint to the primary user. In order to maximize the sum rate of all secondary users, the UAV trajectory as well as the total transmission power and the power allocation scheme for NOMA should be carefully designed. Firstly, the optimization problem is modeled and formulated with interference and flying velocity constraints. Considering the non-convexity of the joint optimization, the alternate optimization algorithm is proposed. During the iteration procedure, the power allocation scheme is firstly solved by successive convex optimization tools with given UAV trajectory and total transmission power. Afterwards, with the help of optimal power allocation scheme, the UAV trajectory as well as the total transmission power is iterative optimized by using of Taylor series approximation. Simulation results are provided to verify the convergence and the effectiveness of the proposed algorithm as well as the effects of system parameters.}
}
@article{GUO2021102435,
title = {Integrating spectral and textural information for identifying the tasseling date of summer maize using UAV based RGB images},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {102},
pages = {102435},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102435},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421001422},
author = {Yahui Guo and Yongshuo H. Fu and Shouzhi Chen and Christopher {Robin Bryant} and Xinxi Li and J. Senthilnath and Hongyong Sun and Shuxin Wang and Zhaofei Wu and Kirsten {de Beurs}},
keywords = {UAV, Spectral information, Textural information, Phenology extraction},
abstract = {The extraction of phenological events in forest and agriculture commonly relies on Vegetation Indices (VI) composed by visible and near infrared bands from satellite images. However, the textural information playing an important role in image fusion, image classification and change detection is commonly ignored. In this study, high-throughput images collected from an Unmanned Aerial Vehicle (UAV) platform during the growth stages of summer maize were used to identify the Tasseling Date (TD) based on both spectral and textural information. The spectral and textural information were extracted using various VI and the Gray Level Co-occurrence Matrix (GLCM), respectively. The results showed that the Normalized Green Blue Difference Index (NGBDI), and the Green Blue Difference Index (GBDI) of VI and the Contrast Information (Contrast) of GLCM performed better than other variables. A new index was generated by integrating spectral and textural information using the Improved Adaptive Feature Weighting Method (IAFWM), and then the TDs were identified for each plot. The Root Mean Square Error (RMSE) of new index was 5.77 days and it was the lowest among all variables. The potential ability of more advanced machine learning and deep learning in integrating the spectral and textural information should be investigated.}
}
@article{ABBASI2021104234,
title = {Deep Reinforcement Learning for QoS provisioning at the MAC layer: A Survey},
journal = {Engineering Applications of Artificial Intelligence},
volume = {102},
pages = {104234},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104234},
url = {https://www.sciencedirect.com/science/article/pii/S0952197621000816},
author = {Mahmoud Abbasi and Amin Shahraki and Md. {Jalil Piran} and Amir Taherkordi},
keywords = {Quality of Service, Medium Access Control, Rate control, Resource sharing and scheduling, Deep Reinforcement Learning, Survey},
abstract = {Quality of Service (QoS) provisioning is based on various network management techniques including resource management and medium access control (MAC). Various techniques have been introduced to automate networking decisions, particularly at the MAC layer. Deep reinforcement learning (DRL), as a solution to sequential decision making problems, is a combination of the power of deep learning (DL), to represent and comprehend the world, with reinforcement learning (RL), to understand the environment and act rationally. In this paper, we present a survey on the applications of DRL in QoS provisioning at the MAC layer. First, we present the basic concepts of QoS and DRL. Second, we classify the main challenges in the context of QoS provisioning at the MAC layer, including medium access and data rate control, and resource sharing and scheduling. Third, we review various DRL algorithms employed to support QoS at the MAC layer, by analyzing, comparing, and identifying their pros and cons. Furthermore, we outline a number of important open research problems and suggest some avenues for future research.}
}
@article{CHAUDHURI2020113234,
title = {Exploring the role of deep neural networks for post-disaster decision support},
journal = {Decision Support Systems},
volume = {130},
pages = {113234},
year = {2020},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2019.113234},
url = {https://www.sciencedirect.com/science/article/pii/S0167923619302635},
author = {Neha Chaudhuri and Indranil Bose},
keywords = {Convolutional neural networks, Decision support, Deep learning, Disaster management, Image analytics},
abstract = {Disaster management operations are information intensive activities due to high uncertainty and complex information needs. Emergency response planners need to effectively plan response activities with limited resources and assign rescue teams to specific disaster sites with high probability of survivors swiftly. Decision making becomes tougher since the limited information available is heterogenous, untimely and often fragmented. We address the problem of lack of insightful information of the disaster sites by utilizing image data obtained from smart infrastructures. We collect geo-tagged images from earthquake-hit regions and apply deep learning method for classification of these images to identify survivors in debris. We find that deep learning method is able to classify the images with significantly higher accuracy than the conventionally used machine learning methods for image classification and utilizes significantly lesser time and computational resources. The novel application of image analytics and the resultant findings from our models have valuable implications for effective disaster response operations, especially in smart urban settlements.}
}
@article{WANG2022108746,
title = {On the beamforming design of millimeter wave UAV networks: Power vs. capacity trade-offs},
journal = {Computer Networks},
pages = {108746},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108746},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621005922},
author = {Yang Wang and Marco Giordani and Xiangming Wen and Michele Zorzi},
keywords = {5G, 6G, Millimeter wave (mmWave), Analog/hybrid beamforming, Unmanned aerial vehicles (UAVs), Stochastic geometry, Energy consumption},
abstract = {The millimeter wave (mmWave) technology enables unmanned aerial vehicles (UAVs) to offer broadband high-speed wireless connectivity in 5G/6G networks. However, the limited footprint of a single UAV implementing analog beamforming (ABF) requires multiple aerial stations to operate in swarms to provide ubiquitous network coverage, thereby posing serious constraints in terms of battery power consumption. A possible remedy is to investigate the concept of hybrid beamforming (HBF) transceivers, which use a combination of analog beamformers to achieve higher flexibility in the beamforming design. This approach permits multiple ground users to be served simultaneously by the same UAV, despite involving higher energy consumption than its ABF counterpart. This paper presents a tractable stochastic analysis to characterize the ergodic capacity and power consumption of UAV mmWave networks, focusing on the trade-off between ABF and HBF architectures. A multi-beam coverage model is derived as a function of several UAV-specific parameters, including the number of UAVs, the deployment altitude, the antenna configuration, and the beamforming design. Our results show that, while ABF achieves better ergodic capacity at high altitudes, an HBF configuration with multiple beams, despite the use of more individually power-hungry RF blocks, always consumes less total power with limited capacity degradation.}
}
@article{MASROOR2021185,
title = {Efficient deployment of UAVs for disaster management: A multi-criterion optimization approach},
journal = {Computer Communications},
volume = {177},
pages = {185-194},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421002607},
author = {Rooha Masroor and Muhammad Naeem and Waleed Ejaz},
keywords = {UAVs, Deployment, Multi-criterion optimization},
abstract = {Recently different information and communication technologies are investigated to manage disasters. Acknowledging disaster resilience, many efforts are commenced to monitor, forecast, and assess the situation in time. Response time and situational awareness is the key to save lives in disaster situations. These issues motivate the utilization of unmanned aerial vehicles (UAVs) in emergency conditions where a lack of communication and support services are core objectives to control. This paper has addressed UAV-assisted wireless networks’ situational awareness deployment in disaster management as a mobile helping unit. In this regard, we have to efficiently place UAVs in emergency situations where infrastructure is devastated and diffused with features of minimum distance, cost, and number of UAVs. To this end, we optimize a multi-objective problem of UAV placement, users-UAV connectivity, distance, and cost. The formulated problem is a integer linear optimization problem (ILP). To solve it, we first propose a high complexity branch and bound (B&B) algorithm to find an optimal solution. Then, we develop a low complexity heuristic to conquer the objectives efficiently. Finally, simulation results show that our proposed approach can maximize the number of users with a minimum number of UAVs efficiently.}
}
@article{BARRETO2021106493,
title = {Automatic UAV-based counting of seedlings in sugar-beet field and extension to maize and strawberry},
journal = {Computers and Electronics in Agriculture},
volume = {191},
pages = {106493},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106493},
url = {https://www.sciencedirect.com/science/article/pii/S016816992100510X},
author = {Abel Barreto and Philipp Lottes and Facundo Ramón {Ispizua Yamati} and Stephen Baumgarten and Nina Anastasia Wolf and Cyrill Stachniss and Anne-Katrin Mahlein and Stefan Paulus},
keywords = {Deep learning, FCN, UAV, Sugar beet, Plant segmentation, Time-series, Intra-row distance, Growth stage},
abstract = {Counting crop seedlings is a time-demanding activity involved in diverse agricultural practices like plant cultivating, experimental trials, plant breeding procedures, and weed control. Unmanned Aerial Vehicles (UAVs) carrying RGB cameras are novel tools for automatic field mapping, and the analysis of UAV images by deep learning methods can provide relevant agronomic information. UAV-based camera systems and a deep learning image analysis pipeline are implemented for a fully automated plant counting in sugar beet, maize, and strawberry fields in the present study. Five locations were monitored at different growth stages, and the crop number per plot was automatically predicted by using a fully convolutional network (FCN) pipeline. Our FCN-based approach is a single model for jointly determining both the exact stem location of crop and weed plants and a pixel-wise plant classification considering crop, weed, and soil. To determinate the approach performance, predicted crop counting was compared to visually assessed ground truth data. Results show that UAV-based counting of sugar-beet plants delivers forecast errors lower than 4.6%, and the main factors for performance are related to the intra-row distance and the growth stage. The pipeline’s extension to other crops is possible; the errors of the predictions are lower than 4% under practical field conditions for maize and strawberry fields. This work highlight the feasibility of automatic crop counting, which can reduce manual effort to the farmers.}
}
@article{FLAH2020103781,
title = {Classification and quantification of cracks in concrete structures using deep learning image-based techniques},
journal = {Cement and Concrete Composites},
volume = {114},
pages = {103781},
year = {2020},
issn = {0958-9465},
doi = {https://doi.org/10.1016/j.cemconcomp.2020.103781},
url = {https://www.sciencedirect.com/science/article/pii/S0958946520302870},
author = {Majdi Flah and Ahmed R. Suleiman and Moncef L. Nehdi},
keywords = {, , , , , },
abstract = {Visual inspection has been the most widely used technique for monitoring concrete structures in service. Inspectors visually evaluate defects based on experience, skill, and engineering judgment. However, this process is subjective, laborious, time-consuming, and hampered by demanding access to numerous parts of complex structures. Accordingly, the present study proposes a nearly automated inspection model based on image processing and deep learning for detecting defects in typically inaccessible areas of concrete structures. Results indicate that using the Keras classifier combined with Otsu image processing can achieve superior classification accuracy of 97.63%, 96.5%, and 96.17% for training, validation, and testing data, respectively, along with low quantification error of 1.5%, 5% and 2% for the crack length, width, and angle of orientation, respectively. The type of structural damage and its severity are identified based on the allowed range of concrete crack width for different structures, including buildings and bridges based on different international standards and codes. The proposed method can deploy unmanned aerial vehicle image acquisition to offer a nearly automated inspection platform for the colossal backlog of aging concrete structures.}
}
@article{ABADE2021106125,
title = {Plant diseases recognition on images using convolutional neural networks: A systematic review},
journal = {Computers and Electronics in Agriculture},
volume = {185},
pages = {106125},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106125},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921001435},
author = {André Abade and Paulo Afonso Ferreira and Flavio {de Barros Vidal}},
keywords = {Plant diseases, Convolutional neural networks, Crop disease recognition, Plant pathogen, SLR},
abstract = {Plant diseases are considered one of the main factors influencing food production and minimize losses in production, and it is essential that crop diseases have fast detection and recognition. The recent expansion of deep learning methods has found its application in plant disease detection, offering a robust tool with highly accurate results. In this context, this work presents a systematic review of the literature that aims to identify the state of the art of the use of convolutional neural networks(CNN) in the process of identification and classification of plant diseases, delimiting trends, and indicating gaps. In this sense, we review 121 papers selected in the last ten years with different approaches to treat aspects related to disease detection, characteristics of the dataset, the crops and pathogens investigated. From the results of the systematic review, it is possible to understand the innovative trends regarding the use of CNN’s in the identification of plant diseases and to identify the gaps that need the attention of the research community.}
}
@article{GUPTA2021101355,
title = {Blockchain and 5G integrated softwarized UAV network management: Architecture, solutions, and challenges},
journal = {Physical Communication},
volume = {47},
pages = {101355},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101355},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721000926},
author = {Rajesh Gupta and Sudeep Tanwar and Neeraj Kumar},
keywords = {Blockchain, Security, 5G, Unmanned aerial vehicle, SDN, NFV, Softwarization},
abstract = {Network management for unmanned aerial vehicles (UAVs) is challenging, keeping in view the high mobility of the vehicles. Hence, for smooth execution of various operations such as rescue, surveillance, and crowdsensing in a UAV environment, softwarization of UAV networks becomes essential, which separates control functions from hardware, i.e., data from the control plane. Using softwarization, various complex operations in the UAV environment can be executed with an increase in UAVs. However, with an increase in the complexity of UAV network management, secure communication among UAVs becomes a tedious task as most of the communication among UAVs takes place using an open network, i.e., the Internet. Software-defined networking (SDN) and network function virtualization (NFV) are the key softwarization enabling techniques in fifth-generation (5G) networks, which are used to manage secure network services with reduced capital and operating expenditures. However, different softwarization layers may suffer from controller hijacking, user authentication, access control, and resource consumption attack. Many solutions reported in the literature for this problem are centralized controlled that suffers from single-point of failure and also prone to various security attacks. Motivated from this, in this paper, a systematic and comprehensive survey is presented, which is based on blockchain (BC)-envisioned secure and trusted softwarized UAV network management. We also propose a BC-based softwarized UAV architecture to make the communication network secure and easily manageable. It can offer flexible and dynamic decision capabilities for network management services even in open 5G-enabled UAV networks. Finally, we analyzed the research challenges posed and future challenges in this area.}
}
@article{JEON2021101430,
title = {Semantic segmentation of seagrass habitat from drone imagery based on deep learning: A comparative study},
journal = {Ecological Informatics},
volume = {66},
pages = {101430},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101430},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121002211},
author = {Eui-ik Jeon and Sunghak Kim and Soyoung Park and Juwon Kwak and Imho Choi},
keywords = {Seagrass, Drone, UAV, Semantic segmentation, Deep learning, Image normalization},
abstract = {In this study, the utilization of drone images and deep learning to monitor the seagrass habitat, which is important in the marine ecosystem, is evaluated. Two experiments were conducted to compare the effect of image normalization and the performance of deep learning models in semantic segmentation with drone optical images acquired for the alpine habitats in coastal waters. Z-score and Min-Max normalization techniques were used to examine the effect of image normalization, and U-Net, SegNet, PSPNet, and DeepLab v3+ were used to compare the performance of the deep learning models. As a result, Min-Max normalization demonstrated outstanding performance for optical images, and Z-score normalization for black and white images. Regardless of the normalization of the image, the performance of the models was ranked in the order of U-Net, PSPNet, SegNet, and DeepLab v3+. Although the latest model, DeepLab v3+, was expected to have excellent performance, in fact, U-Net, having a relatively simple structure and a small number of parameters, showed the best performance. As the accuracy of semantic results seems to depend on the deep learning models and normalization methods, an experiment to determine an appropriate normalization method and deep learning model should be preceded for the semantic segmentation of high-resolution optical images in coastal waters.}
}
@article{KOLLE2021100001,
title = {The Hessigheim 3D (H3D) benchmark on semantic segmentation of high-resolution 3D point clouds and textured meshes from UAV LiDAR and Multi-View-Stereo},
journal = {ISPRS Open Journal of Photogrammetry and Remote Sensing},
volume = {1},
pages = {100001},
year = {2021},
issn = {2667-3932},
doi = {https://doi.org/10.1016/j.ophoto.2021.100001},
url = {https://www.sciencedirect.com/science/article/pii/S2667393221000016},
author = {Michael Kölle and Dominik Laupheimer and Stefan Schmohl and Norbert Haala and Franz Rottensteiner and Jan Dirk Wegner and Hugo Ledoux},
keywords = {Semantic segmentation, UAV Laser scanning, Multi-View-Stereo, 3D point cloud, 3D textured mesh, Multi-modality, Multi-temporality},
abstract = {Automated semantic segmentation and object detection are of great importance in geospatial data analysis. However, supervised machine learning systems such as convolutional neural networks require large corpora of annotated training data. Especially in the geospatial domain, such datasets are quite scarce. Within this paper, we aim to alleviate this issue by introducing a new annotated 3D dataset that is unique in three ways: i) The dataset consists of both an Unmanned Aerial Vehicle (UAV) laser scanning point cloud and a 3D textured mesh. ii) The point cloud features a mean point density of about 800 ​pts/m2 and the oblique imagery used for 3D mesh texturing realizes a ground sampling distance of about 2–3 ​cm. This enables the identification of fine-grained structures and represents the state of the art in UAV-based mapping. iii) Both data modalities will be published for a total of three epochs allowing applications such as change detection. The dataset depicts the village of Hessigheim (Germany), henceforth referred to as H3D - either represented as 3D point cloud H3D(PC) or 3D mesh H3D(Mesh). It is designed to promote research in the field of 3D data analysis on one hand and to evaluate and rank existing and emerging approaches for semantic segmentation of both data modalities on the other hand. Ultimately, we hope that H3D will become a widely used benchmark dataset in company with the well-established ISPRS Vaihingen 3D Semantic Labeling Challenge benchmark (V3D). The dataset can be downloaded from https://ifpwww.ifp.uni-stuttgart.de/benchmark/hessigheim/default.aspx.}
}
@article{DEOLIVEIRA2021119496,
title = {Eucalyptus growth recognition using machine learning methods and spectral variables},
journal = {Forest Ecology and Management},
volume = {497},
pages = {119496},
year = {2021},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2021.119496},
url = {https://www.sciencedirect.com/science/article/pii/S0378112721005867},
author = {Bruno Rodrigues {de Oliveira} and Arlindo Ananias Pereira {da Silva} and Larissa Pereira Ribeiro Teodoro and Gileno Brito {de Azevedo} and Glauce Taís de Oliveira Sousa Azevedo and Fábio Henrique Rojo Baio and Renato Lustosa Sobrinho and Carlos Antonio {da Silva Junior} and Paulo Eduardo Teodoro},
keywords = {Random forest, Classification, Vegetation index},
abstract = {Growth and production models can help to simulate the growth of tree dimensions to predict forest productivity at different levels. In this context, the following questions arise: (i) is it possible to recognize the growth pattern of eucalyptus species based on spectral features using machine learning (ML) for data modeling? (ii) what spectral features provides better accuracy? and (iii) what ML algorithms are most accurate for performing this modeling? To answer these questions, the present study evaluated the use of ML techniques using breast height and total plant height to classify the growth of five species of eucalyptus and Corymbria citriodora in an unsupervised learning, and the obtained classes for induce ML algorithms to recognize the species with relation to their growth using vegetation indices (VIs) and spectral bands (SBs). It were evaluated five eucalyptus species (E. camaldulensis, E. uroplylla, E. saligna, E. grandis e E. urograndis) and C. citriodora in experimental design of randomized blocks with four replicates, with 20 plants inside each experimental plot. The diameter at breast height and total plant height at stand level were obtained by measuring five trees in each experimental unit in seven measurements. During this same period, a flight was carried out using a remotely piloted aircraft for the acquisition of spectral variables (SBs and VIs). For recognition of eucalyptus species in relation to their growth two machine learning approaches were employed: supervised and unsupervised. The average accuracy obtained from 10-fold cross-validation, employing Random Forest algorithm and 24 features, was 0.76. This result shows that the proposed approach is appropriate to recognize different eucalyptus species based on their growth.}
}
@article{GAO2021106723,
title = {Automatic late blight lesion recognition and severity quantification based on field imagery of diverse potato genotypes by deep learning},
journal = {Knowledge-Based Systems},
volume = {214},
pages = {106723},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2020.106723},
url = {https://www.sciencedirect.com/science/article/pii/S0950705120308522},
author = {Junfeng Gao and Jesper Cairo Westergaard and Ea Høegh Riis Sundmark and Merethe Bagge and Erland Liljeroth and Erik Alexandersson},
keywords = {Plant disease, Resistance breeding, Convolutional neural networks, Semantic segmentation, Multi-scale prediction, Mask fusion, Image-based crop phenotyping},
abstract = {The plant pathogen Phytophthora infestans causes the severe disease late blight in potato, which can result in huge yield loss for potato production. Automatic and accurate disease lesion segmentation enables fast evaluation of disease severity and assessment of disease progress. In tasks requiring computer vision, deep learning has recently gained tremendous success for image classification, object detection and semantic segmentation. To test whether we could extract late blight lesions from unstructured field environments based on high-resolution visual field images and deep learning algorithms, we collected ∼500 field RGB images in a set of diverse potato genotypes with different disease severity (0%–70%), resulting in 2100 cropped images. 1600 of these cropped images were used as the dataset for training deep neural networks and 250 cropped images were randomly selected as the validation dataset. Finally, the developed model was tested on the remaining 250 cropped images. The results show that the values for intersection over union (IoU) of the classes background (leaf and soil) and disease lesion in the test dataset were 0.996 and 0.386, respectively. Furthermore, we established a linear relationship (R2=0.655) between manual visual scores of late blight and the number of lesions detected by deep learning at the canopy level. We also showed that imbalance weights of lesion and background classes improved segmentation performance, and that fused masks based on the majority voting of the multiple masks enhanced the correlation with the visual disease scores. This study demonstrates the feasibility of using deep learning algorithms for disease lesion segmentation and severity evaluation based on proximal imagery, which could aid breeding for crop resistance in field environments, and also benefit precision farming.}
}
@article{REN202256,
title = {A privacy-protected intelligent crowdsourcing application of IoT based on the reinforcement learning},
journal = {Future Generation Computer Systems},
volume = {127},
pages = {56-69},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21003411},
author = {Yingying Ren and Wei Liu and Anfeng Liu and Tian Wang and Ang Li},
keywords = {Crowdsourcing, Reinforcement learning, Q-learning, Trust evaluation, Privacy-protection},
abstract = {The crowdsourcing scheme emerges as a promising solution for data-based application in the Internet of Things (IoT) network by dividing the large-scale complex sensing tasks into simple micro sensing tasks. AI technologies have been widely applied in crowdsourcing applications for IoT security. However, there are still several issues to be stressed. There exist malicious participants aiming at gaining unjust payment. A trust evaluation mechanism can effectively filter the attackers. Nevertheless, the existing trust evaluation mechanisms cannot preclude co-cheating and overlook the conflicts with the privacy exposure of participants. A novel Privacy-protected Intelligent Crowdsourcing scheme based on Reinforcement Learning (PICRL) is proposed. PICRL optimizes the utility of the system considering the data amount, data quality, and costs at the same time. The main innovations of the PICRL are as follows. First, the quality is guaranteed by an effective trust evaluation mechanism. The proposed trust evaluation consists of three parts: privacy trust, crowd trust, and hybrid active trust. Second, the trust evaluation can effectively prevent co-cheating and provide personal privacy exposure choice for the participants. Third, PICRL maximizes the utility based on evaluated trust utilizing the reinforcement method Q-learning without knowing the specific sensing model, which aims at maximizing the cumulated reward by the selection of state–action pair. The effectiveness of the proposed PICRL is verified by the extensive simulation experiments.}
}
@article{WU2021107743,
title = {Deep learning for privacy preservation in autonomous moving platforms enhanced 5G heterogeneous networks},
journal = {Computer Networks},
volume = {185},
pages = {107743},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107743},
url = {https://www.sciencedirect.com/science/article/pii/S138912862031327X},
author = {Yulei Wu and Yuxiang Ma and Hong-Ning Dai and Hao Wang},
keywords = {Deep learning, 5G, Heterogeneous networks, Privacy preservation, Network slicing},
abstract = {5G heterogeneous networks have become a promising platform to connect a growing number of Internet-of-Things (IoT) devices and accommodate a wide variety of vertical services. IoT has not been limited to traditional sensing systems since the introduction of 5G, but also includes a range of autonomous moving platforms, e.g., autonomous flying vehicles, autonomous underwater vehicles, autonomous surface vehicles as well as autonomous land vehicles. These platforms can be used as an effective means to connect air, space, ground, and sea mobile networks for providing a wider diversity of Internet services. Deep learning has been widely used to extract useful information from network big data for enhancing network quality-of-service and user quality-of-experience. Privacy preservation for user and network data is a burning concern in 5G heterogeneous networks due to various attacks in this environment. In this paper, we conduct an in-depth investigation on how deep learning can cope with privacy preservation issues in 5G heterogeneous networks, in terms of heterogeneous radio access networks (RANs), beyond-RAN networks, and end-to-end network slices, followed by a set of key research challenges and open issues that aim to guide future research.}
}
@article{LE2021101545,
title = {Remote anomaly detection and classification of solar photovoltaic modules based on deep neural network},
journal = {Sustainable Energy Technologies and Assessments},
volume = {48},
pages = {101545},
year = {2021},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2021.101545},
url = {https://www.sciencedirect.com/science/article/pii/S2213138821005579},
author = {Minhhuy Le and Van Su Luong and Dang Khoa Nguyen and Van-Duong Dao and Ngoc Hung Vu and Hong Ha Thi Vu},
keywords = {Solar photovoltaic modules, Green energy, Safety assessment, Deep learning},
abstract = {Solar photovoltaic systems are being widely used in green energy harvesting recently. At the same rate of growth, the modules that come to the end of life are growing fast. The solar modules contain heavy metals such as lead, tin, and cadmium, which could pollute the environment. Inspection and maintenance of solar modules are important to increase the lifetime, reduce energy loss, and environmental protection. In this research, we proposed an efficient way for inspection and classification of anomaly solar modules using infrared radiation (IR) cameras and deep neural networks. The IR cameras could capture the temperature distribution on the solar modules remotely, and the deep neural networks could accurately prediction of the anomaly modules and classification of the anomaly types. We proposed a deep neural network based on a residual network structure and ensemble technique to accurately predict and classify anomaly solar modules based on the IR images. An IR images dataset on real solar farms with 20,000 images and 12 anomaly solar modules was used to verify the proposed approach. The experiment results show that the proposed model could predict an anomaly module on an average of 94% and correctly classify 12 anomaly types on an average of 86%.}
}
@article{WEST2020113515,
title = {Improved reinforcement learning with curriculum},
journal = {Expert Systems with Applications},
volume = {158},
pages = {113515},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113515},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420303390},
author = {Joseph West and Frederic Maire and Cameron Browne and Simon Denman},
keywords = {Curriculum learning, Reinforcement learning, Monte Carlo tree search, General game playing},
abstract = {Humans tend to learn complex abstract concepts faster if examples are presented in a structured manner. For instance, when learning how to play a board game, usually one of the first concepts learned is how the game ends, i.e. the actions that lead to a terminal state (win, lose or draw). The advantage of learning end-games first is that once the actions leading to a terminal state are understood, it becomes possible to incrementally learn the consequences of actions that are further away from a terminal state – we call this an end-game-first curriculum. The state-of-the-art machine learning player for general board games, AlphaZero by Google DeepMind, does not employ a structured training curriculum. Whilst Deepmind’s approach is effective, their method for generating experiences by self-play is resource intensive, costing literally millions of dollars in computational resources. We have developed a new method called the end-game-first training curriculum, which, when applied to the self-play/experience-generation loop, reduces the required computational resources to achieve the same level of learning. Our approach improves performance by not generating experiences which are expected to be of low training value. The end-game-first curriculum enables significant savings in processing resources and is potentially applicable to other problems that can be framed in terms of a game.}
}
@article{HE202219,
title = {A multi-strategy pigeon-inspired optimization approach to active disturbance rejection control parameters tuning for vertical take-off and landing fixed-wing UAV},
journal = {Chinese Journal of Aeronautics},
volume = {35},
number = {1},
pages = {19-30},
year = {2022},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121001898},
author = {Hangxuan HE and Haibin DUAN},
keywords = {Active Disturbance Rejection Control (ADRC), Pigeon-inspired optimization algorithm, Transition mode, Unmanned Aerial Vehicle (UAV), Vertical take-off and landing},
abstract = {In this paper, Active Disturbance Rejection Control (ADRC) is utilized in the pitch control of a vertical take-off and landing fixed-wing Unmanned Aerial Vehicle (UAV) to address the problem of height fluctuation during the transition from hover to level flight. Considering the difficulty of parameter tuning of ADRC as well as the requirement of accuracy and rapidity of the controller, a Multi-Strategy Pigeon-Inspired Optimization (MSPIO) algorithm is employed. Particle Swarm Optimization (PSO), Genetic Algorithm (GA), the basic Pigeon-Inspired Optimization (PIO), and an improved PIO algorithm CMPIO are compared. In addition, the optimized ADRC control system is compared with the pure Proportional-Integral-Derivative (PID) control system and the non-optimized ADRC control system. The effectiveness of the designed control strategy for forward transition is verified and the faster convergence speed and better exploitation ability of the proposed MSPIO algorithm are confirmed by simulation results.}
}
@article{PALLATHADKA2021,
title = {Application of machine learning techniques in rice leaf disease detection},
journal = {Materials Today: Proceedings},
year = {2021},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.11.398},
url = {https://www.sciencedirect.com/science/article/pii/S2214785321074228},
author = {Harikumar Pallathadka and Pavankumar Ravipati and Guna {Sekhar Sajja} and Khongdet Phasinam and Thanwamas Kassanuk and Domenic T. Sanchez and P. Prabhu},
keywords = {Machine learning, Precision agriculture, Classification, Detection, Leaf disease, Preprocessing, Feature extraction},
abstract = {The automated leaf disease diagnosis system is a precision agriculture system that predicts sickness by analyzing images of infected leaf disease with Computer Vision, Image Processing, and Machine Learning algorithms. Thanks to automated disease detection technology, which speeds up the diagnosis procedure, the farmer can make an informed decision about a plant sickness. Previously, the farmer had to submit the infected leaf to a pathology lab, where the pathologist confirmed the disease, a time-consuming procedure. As a result of the delayed reaction, crop productivity declines. As a result, it is important to automate the disease detection system in order to increase crop yield. This article presents a machine learning based framework for classification and detection of leaf disease. SVM, Naïve Bayes and CNN are used in framework. Preprocessing is done using histogram equalization. For feature extraction, PCA algorithm is used.}
}
@article{TANG2021,
title = {Energy-efficient data collection for UAV-assisted IoT: Joint trajectory and resource optimization},
journal = {Chinese Journal of Aeronautics},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121003551},
author = {Xiao TANG and Wei WANG and Hongliang HE and Ruonan ZHANG},
keywords = {Block coordinate descent, Data collection, Dinkelbach method, Energy efficiency, Internet of Things (IoT), Unmanned aerial vehicle},
abstract = {Internet of Things (IoT) can be conveniently deployed while empowering various applications, where the IoT nodes can form clusters to finish certain missions collectively. As energy-efficient operations are critical to prolong the lifetime of the energy-constrained IoT devices, the Unmanned Aerial Vehicle (UAV) can be dispatched to geographically approach the IoT clusters towards energy-efficient IoT transmissions. This paper intends to maximize the system energy efficiency by considering both the IoT transmission energy and UAV propulsion energy, where the UAV trajectory and IoT communication resources are jointly optimized. By applying large-system analysis and Dinkelbach method, the original fractional optimization is approximated and reformulated in the form of subtraction, and further a block coordinate descent framework is employed to update the UAV trajectory and IoT communication resources iteratively. Extensive simulation results are provided to corroborate the effectiveness of the proposed method.}
}
@article{PI2020101009,
title = {Convolutional neural networks for object detection in aerial imagery for disaster response and recovery},
journal = {Advanced Engineering Informatics},
volume = {43},
pages = {101009},
year = {2020},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2019.101009},
url = {https://www.sciencedirect.com/science/article/pii/S1474034619305828},
author = {Yalong Pi and Nipun D. Nath and Amir H. Behzadan},
keywords = {Disaster management, Convolutional neural network (CNN), Aerial reconnaissance, Deep learning, Unmanned aerial vehicle (UAV)},
abstract = {Accurate and timely access to data describing disaster impact and extent of damage is key to successful disaster management (a process that includes prevention, mitigation, preparedness, response, and recovery). Airborne data acquisition using helicopter and unmanned aerial vehicle (UAV) helps obtain a bird’s-eye view of disaster-affected areas. However, a major challenge to this approach is robustly processing a large amount of data to identify and map objects of interest on the ground in real-time. The current process is resource-intensive (must be carried out manually) and requires offline computing (through post-processing of aerial videos). This research introduces and evaluates a series of convolutional neural network (CNN) models for ground object detection from aerial views of disaster’s aftermath. These models are capable of recognizing critical ground assets including building roofs (both damaged and undamaged), vehicles, vegetation, debris, and flooded areas. The CNN models are trained on an in-house aerial video dataset (named Volan2018) that is created using web mining techniques. Volan2018 contains eight annotated aerial videos (65,580 frames) collected by drone or helicopter from eight different locations in various hurricanes that struck the United States in 2017–2018. Eight CNN models based on You-Only-Look-Once (YOLO) algorithm are trained by transfer learning, i.e., pre-trained on the COCO/VOC dataset and re-trained on Volan2018 dataset, and achieve 80.69% mAP for high altitude (helicopter footage) and 74.48% for low altitude (drone footage), respectively. This paper also presents a thorough investigation of the effect of camera altitude, data balance, and pre-trained weights on model performance, and finds that models trained and tested on videos taken from similar altitude outperform those trained and tested on videos taken from different altitudes. Moreover, the CNN model pre-trained on the VOC dataset and re-trained on balanced drone video yields the best result in significantly shorter training time.}
}
@article{YUAN2022107259,
title = {A continuous modeling method via improved pigeon-inspired optimization for wake vortices in UAVs close formation flight},
journal = {Aerospace Science and Technology},
volume = {120},
pages = {107259},
year = {2022},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107259},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821007690},
author = {Guangsong Yuan and Jie Xia and Haibin Duan},
keywords = {Unmanned aerial vehicle (UAV), Pigeon-inspired optimization (PIO), Continuous horseshoe vortex method, Interaction coefficient, Wake vortex effect},
abstract = {This paper explores the modeling of wake vortices to estimate the wake vortex effect in unmanned aerial vehicles (UAVs) close formation flight. A continuous horseshoe vortex method is proposed based on the consideration of a compromise between estimation accuracy and computational efficiency. Using the proposed modeling method, the wake vortex model can easily adapt to UAVs with different wing shapes by adjusting model parameters. Furthermore, the interaction coefficient of filaments of the wake vortex is introduced to improve the estimation accuracy. However, the analytical value is solved difficultly by theoretical derivation. Therefore, the improved pigeon-inspired optimization is developed to search for the optimal value. On the other hand, the wake vortex effect is formulated by the statistical average strategy. The formulated wake vortex effect can be readily utilized to conduct a realistic dynamic model of the vortex-suffering UAV. Simulation results show that the estimation accuracy of the proposed modeling method increases by approximately 30% and 34%, compared with the single and multiple horseshoe vortex methods respectively. Furthermore, the computational efficiency is sufficient enough for the real-time estimation in UAVs close formation flight.}
}
@article{ALLRED2021107071,
title = {Time of day impact on mapping agricultural subsurface drainage systems with UAV thermal infrared imagery},
journal = {Agricultural Water Management},
volume = {256},
pages = {107071},
year = {2021},
issn = {0378-3774},
doi = {https://doi.org/10.1016/j.agwat.2021.107071},
url = {https://www.sciencedirect.com/science/article/pii/S037837742100336X},
author = {Barry Allred and Luis Martinez and Melake K. Fessehazion and Greg Rouse and Triven Koganti and Robert Freeland and Neal Eash and DeBonne Wishart and Robert Featheringill},
keywords = {Agricultural subsurface drainage systems, Unmanned Aerial Vehicles (UAVs), Thermal Infrared (TIR) imagery, drainage pipe mapping},
abstract = {Due to economic and environmental considerations, there exists a need for effective, efficient, and nondestructive methods for locating buried agricultural drainage pipes. Previous research indicates that thermal infrared (TIR) imagery obtained with an unmanned aerial vehicle (UAV) has potential for mapping agricultural subsurface drainage systems, thereby warranting further investigation to determine the best time of day to conduct these UAV TIR surveys. Accordingly, a set of sunrise to sunset UAV TIR surveys were carried out at four different farm field sites in Ohio, U.S.A. Late morning through late afternoon UAV TIR surveys were generally found to work well for determining drainage system patterns. During late morning through late afternoon, the apparent radiant temperature of the soil surface over the drain lines was higher than between the drain lines (i.e., emitted TIR radiation from the soil surface over a drain line was greater than between the drain lines). Conversely, near sunrise or sunset, the UAV surveys often showed the apparent radiant temperature of the soil surface over the drain lines to be lower than between the drain lines (i.e., less emitted TIR radiation over the drain lines than between drain lines). Some excellent UAV TIR drainage mapping results were obtained near sunrise/sunset due to TIR drain line responses that were more easily distinguished from those of farm field operations. However, difficulties were occasionally encountered processing this sunrise/sunset TIR imagery, likely due to the impact on image quality from high relative humidity during these times of the day. Consequently, strictly on a consistency of success basis alone, late morning through late afternoon are the best times for locating drainage pipes with UAV TIR surveys; however, in certain cases, UAV TIR surveys at sunrise/sunset can provide exceptional drainage pattern recognition. These results provide valuable guidance for those considering UAV TIR drainage mapping surveys.}
}
@article{WU2021242,
title = {UAV path planning for backscatter communication with phase cancellation},
journal = {Computer Communications},
volume = {179},
pages = {242-250},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421003078},
author = {Chunyue Wu and Ruifeng Liang and Feng Xu and Feng Ke},
keywords = {Backscatter communication, Unmanned aerial vehicle (UAV), Phase cancellation, Path planning},
abstract = {Backscatter communication has emerged as a promising technology to realize internet of things (IoT), which can fascinate the data transmission without energy supply and constitute a maintenance-free wireless network. When combining it with unmanned aerial vehicle (UAV), it can gather sensed data in extreme scenarios such as surveying in unreachable areas. When modulated by amplitude shift keying (ASK), the received signal at an UAV is the superposition of backscatter signal of tags and the signal of the RF source. As the UAV moves, the phase difference between the two signals changes. A phase cancellation effect will happen when the UAV enters a blind communication zone, which will deteriorate the performance of communication. In this paper, a two-step moving strategy for the UAV is proposed to eliminate the phase cancellation effect and find the optimal communication spot, so as to improve the reliability and stability of date transmission. The sampling-based UAV path planning algorithm and a median filter is used to adjust the moving direction and filter out environmental noise. By simulation, we can see that it is feasible for the UAV to find global optimal spot and the probability of finding the optimal spot can reach 96%.}
}
@article{WANG2021103968,
title = {Automatic detection of unreinforced masonry buildings from street view images using deep learning-based image segmentation},
journal = {Automation in Construction},
volume = {132},
pages = {103968},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103968},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521004192},
author = {Chaofeng Wang and Sarah Elizabeth Antos and Luis Miguel Triveno},
keywords = {Unreinforced masonry building, Instance segmentation, Deep learning, URM, Masonry building, Street view image},
abstract = {Mitigation of seismic risk is a challenge for 70+ countries in the world. Screening the building stock for potential structural defects is one way to locate structures that are vulnerable to strong ground motion. Often in developing countries, masonry buildings are not reinforced or confined to withstand earthquake loads. It has been observed that such buildings cannot withstand the lateral loads imposed by an earthquake. An estimated 77 percent of the fatalities in the earthquakes during the last 100 years were caused mainly by the collapse of masonry buildings. Given the probability of severe damage or collapse in the event of an earthquake, identification and retrofit of such masonry buildings are critical. Screening of masonry buildings by conventional methods is usually a time-consuming and labor-intensive process. This research presents an automated workflow for segmenting the presence of such buildings through the use of street-view images. The method uses deep learning techniques. An inventory composed of a set of street view images was collected from the streets of Oaxaca State, Mexico using a 360° camera mounted on a car. These images were then annotated by trained engineers. Using the annotated dataset, an instance segmentation model was trained to detect and classify masonry buildings from the street view images. Using the model, we performed city scale detections of masonry buildings. We found the spatial distribution pattern of masonry buildings is correlated with the urbanization paths of the cities. The model could be used to produce large-scale automated detection of buildings at a fraction of the cost and in the fraction of the time of the alternatives. With affordable, accurate and massive screenings, governments can target these buildings for retrofit efforts and companies can assess the business opportunity of prevention (or “Building Better Before”).}
}
@article{GARCIAGARIN2021116490,
title = {Automatic detection and quantification of floating marine macro-litter in aerial images: Introducing a novel deep learning approach connected to a web application in R},
journal = {Environmental Pollution},
volume = {273},
pages = {116490},
year = {2021},
issn = {0269-7491},
doi = {https://doi.org/10.1016/j.envpol.2021.116490},
url = {https://www.sciencedirect.com/science/article/pii/S0269749121000683},
author = {Odei Garcia-Garin and Toni Monleón-Getino and Pere López-Brosa and Asunción Borrell and Alex Aguilar and Ricardo Borja-Robalino and Luis Cardona and Morgana Vighi},
keywords = {Remote sensing, Machine learning, Unmanned aerial vehicles, Convolutional neural network, Marine litter},
abstract = {The threats posed by floating marine macro-litter (FMML) of anthropogenic origin to the marine fauna, and marine ecosystems in general, are universally recognized. Dedicated monitoring programmes and mitigation measures are in place to address this issue worldwide, with the increasing support of new technologies and the automation of analytical processes. In the current study, we developed algorithms capable of detecting and quantifying FMML in aerial images, and a web-oriented application that allows users to identify FMML within images of the sea surface. The proposed algorithm is based on a deep learning approach that uses convolutional neural networks (CNNs) capable of learning from unstructured or unlabelled data. The CNN-based deep learning model was trained and tested using 3723 aerial images (50% containing FMML, 50% without FMML) taken by drones and aircraft over the waters of the NW Mediterranean Sea. The accuracies of image classification (performed using all the images for training and testing the model) and cross-validation (performed using 90% of images for training and 10% for testing) were 0.85 and 0.81, respectively. The Shiny package of R was then used to develop a user-friendly application to identify and quantify FMML within the aerial images. The implementation of this, and similar algorithms, allows streamlining substantially the detection and quantification of FMML, providing support to the monitoring and assessment of this environmental threat. However, the automated monitoring of FMML in the open sea still represents a technological challenge, and further research is needed to improve the accuracy of current algorithms.}
}
@article{KATTENBORN202124,
title = {Review on Convolutional Neural Networks (CNN) in vegetation remote sensing},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {173},
pages = {24-49},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.12.010},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620303488},
author = {Teja Kattenborn and Jens Leitloff and Felix Schiefer and Stefan Hinz},
keywords = {Convolutional Neural Networks (CNN), Deep learning, Vegetation, Plants, Remote sensing, Earth observation},
abstract = {Identifying and characterizing vascular plants in time and space is required in various disciplines, e.g. in forestry, conservation and agriculture. Remote sensing emerged as a key technology revealing both spatial and temporal vegetation patterns. Harnessing the ever growing streams of remote sensing data for the increasing demands on vegetation assessments and monitoring requires efficient, accurate and flexible methods for data analysis. In this respect, the use of deep learning methods is trend-setting, enabling high predictive accuracy, while learning the relevant data features independently in an end-to-end fashion. Very recently, a series of studies have demonstrated that the deep learning method of Convolutional Neural Networks (CNN) is very effective to represent spatial patterns enabling to extract a wide array of vegetation properties from remote sensing imagery. This review introduces the principles of CNN and distils why they are particularly suitable for vegetation remote sensing. The main part synthesizes current trends and developments, including considerations about spectral resolution, spatial grain, different sensors types, modes of reference data generation, sources of existing reference data, as well as CNN approaches and architectures. The literature review showed that CNN can be applied to various problems, including the detection of individual plants or the pixel-wise segmentation of vegetation classes, while numerous studies have evinced that CNN outperform shallow machine learning methods. Several studies suggest that the ability of CNN to exploit spatial patterns particularly facilitates the value of very high spatial resolution data. The modularity in the common deep learning frameworks allows a high flexibility for the adaptation of architectures, whereby especially multi-modal or multi-temporal applications can benefit. An increasing availability of techniques for visualizing features learned by CNNs will not only contribute to interpret but to learn from such models and improve our understanding of remotely sensed signals of vegetation. Although CNN has not been around for long, it seems obvious that they will usher in a new era of vegetation remote sensing.}
}
@article{KOPACZ2021104316,
title = {Deep replacement: Reinforcement learning based constellation management and autonomous replacement},
journal = {Engineering Applications of Artificial Intelligence},
volume = {104},
pages = {104316},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104316},
url = {https://www.sciencedirect.com/science/article/pii/S0952197621001640},
author = {Joseph Kopacz and Jason Roney and Roman Herschitz},
abstract = {The Deep Reinforcement Learning (DRL) algorithm, Proximal Policy Optimization (PPO2), is deployed on a custom spacecraft (S/C) build and loss model to determine if an Artificial Intelligence (AI) can learn to monitor satellite constellation health and determine an optimal replacement strategy. A custom environment is created to simulate how S/C are built, launched, generate revenue, and finally decay. The reinforcement learning agent successfully learned an optimal policy for two models: a Simplified Model where the financial cost of actions is ignored; and an Advanced Model where the financial cost of actions is a major element. In both models the AI monitors the constellations and takes multiple strategic and tactical actions to replace satellites to maintain constellation performance. The Simplified Model showed that the PPO2 algorithm was able to converge on an optimal solution after ∼200,000 simulations. The Advanced Model was much more difficult for the AI to learn, and thus, the performance drops during the early episodes, but eventually converges to an optimal policy at ∼25,000,000 simulations. With the Advanced Model, the AI is taking actions that are successfully providing strategies for constellation management and satellite replacements which include these actions’ financial implications. Thus, the methods in this paper provide initial research developments towards a real-world tool and an AI application that can aid various Aerospace businesses in managing Low Earth Orbit (LEO) constellations. This type of AI application may become imperative for deploying and maintaining small satellite mega-constellations.}
}
@article{XU2021125691,
title = {Recognition of lane-changing behaviour with machine learning methods at freeway off-ramps},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {567},
pages = {125691},
year = {2021},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2020.125691},
url = {https://www.sciencedirect.com/science/article/pii/S0378437120309894},
author = {Ting Xu and Zhishun Zhang and Xingqi Wu and Long Qi and Yi Han},
keywords = {Lane-changing recognition, Convolutional neural network, Lane-changing behaviour, Freeway off-ramps},
abstract = {Crashes are occurred frequently at freeway off-ramps due to improper lane-changing (LC) behaviours. The LC behaviour is the main cause of freeway off-ramp crashes. It is important to warn the LC to reduce potential crashes. The uncertainty of LC behaviour increases the difficulties of predicting in advance. The off-ramps at Xi’an Raocheng freeway were chosen for investigation. The datasets were collected by the UAV. There was a total of 637 LC images extracted from the 200 minutes’ video stream. All LC behaviours were divided into twelve categories according to the changing direction and the influence of other vehicles in the target-lane or ego-lane. The machine learning technology is efficient in the image recognition. Thus, the vision technology was applied to devised a lane-changing recognition (LCR) model with the two-level convolutional neural network. A novel convolutional neural network based on the AlexNet was also proposed to compare with the LCR model. All samples were divided into a training dataset and a testing dataset for two models. The performance of two machines networks was compared. The training average accuracy was above 94.6% with the LCR model. The LCR model outperformed the model based on the AlexNet which was only 73.97% on average.}
}
@article{DUAN201412,
title = {Inversion of the PROSAIL model to estimate leaf area index of maize, potato, and sunflower fields from unmanned aerial vehicle hyperspectral data},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {26},
pages = {12-20},
year = {2014},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2013.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0303243413000561},
author = {Si-Bo Duan and Zhao-Liang Li and Hua Wu and Bo-Hui Tang and Lingling Ma and Enyu Zhao and Chuanrong Li},
keywords = {Leaf area index, PROSAIL, Hyperspectral, Look-up table, Dual-angle observations},
abstract = {Leaf area index (LAI) is a key variable for modeling energy and mass exchange between the land surface and the atmosphere. Inversion of physically based radiative transfer models is the most established technique for estimating LAI from remotely sensed data. This study aims to evaluate the suitability of the PROSAIL model for LAI estimation of three typical row crops (maize, potato, and sunflower) from unmanned aerial vehicle (UAV) hyperspectral data. LAI was estimated using a look-up table (LUT) based on the inversion of the PROSAIL model. The estimated LAI was evaluated against in situ LAI measurements. The results indicated that the LUT-based inversion of the PROSAIL model was suitable for LAI estimation of these three crops, with a root mean square error (RMSE) of approximately 0.62m2m−2, and a relative RMSE (RRMSE) of approximately 15.5%. Dual-angle observations were also used to estimate LAI and proved to be more accurate than single-angle observations, with an RMSE of approximately 0.55m2m−2 and an RRMSE of approximately 13.6%. The results demonstrate that additional directional information improves the performance of LAI estimation.}
}
@article{SHAFIEE2021106036,
title = {Sequential forward selection and support vector regression in comparison to LASSO regression for spring wheat yield prediction based on UAV imagery},
journal = {Computers and Electronics in Agriculture},
volume = {183},
pages = {106036},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106036},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921000545},
author = {Sahameh Shafiee and Lars Martin Lied and Ingunn Burud and Jon Arne Dieseth and Muath Alsheikh and Morten Lillemo},
keywords = {Machine learning, Support Vector Regression (SVR), SFS (Sequential Forward Selection), LASSO, Yield, Wheat phenotyping},
abstract = {Traditional plant breeding based on selection for grain yield is time-consuming and costly; therefore, new innovative methods are in high demand to reduce costs and accelerate genetic gains. Remote sensing-based platforms such as unmanned aerial vehicles (UAV) show promise to predict different traits including grain yield. Attention is currently being devoted to machine learning methods in order to extract the most meaningful information from the massive amounts of data generated by UAV images. These methods have shown a promising capability to come up with nonlinearity and explore patterns beyond the human ability. This study investigates the application of two different machine learning based regressor methods to predict wheat grain yield using extracted vegetation indices from UAV images. The goal of the study was to investigate the strength of Support Vector Regression (SVR) in combination with Sequential Forward Selection (SFS) for grain yield prediction and compare the results with LASSO regressor with an internal feature selector. Models were tested on grain yield data from 600 plots of spring wheat planted in South-Eastern Norway in 2018. Five spectral bands along with three different vegetation indices; the Normalized Difference Vegetation Index (NDVI), Enhanced Vegetation Index (EVI), and MERIS Terrestrial Chlorophyll Index (MTCI) were extracted from multispectral images at three dates between heading and maturity of the plants. These features for each field trial plot at each date were used as input data for the SVR model. The best model hyperparameters were estimated using grid search. Based on feature selection results from both methods, NDVI showed the highest prediction ability for grain yield at all dates and its explanatory power increased toward maturity, while adding MTCI and EVI at earlier stages of grain filling improved model performance. Combined models based on all indices and dates explained up to 90% of the variation in grain yield on the test set. Inclusion of individual bands added collinearity to the models and did not improve the predictions. Although both regression methods showed a good capability for grain yield prediction, LASSO regressor proved to be more affordable and economical in terms of time.}
}
@article{DAS2021104159,
title = {Application of deep convolutional neural networks for automated and rapid identification and computation of crack statistics of thin cracks in strain hardening cementitious composites (SHCCs)},
journal = {Cement and Concrete Composites},
volume = {122},
pages = {104159},
year = {2021},
issn = {0958-9465},
doi = {https://doi.org/10.1016/j.cemconcomp.2021.104159},
url = {https://www.sciencedirect.com/science/article/pii/S0958946521002274},
author = {Avik Kumar Das and Christopher.K.Y. Leung and Kai Tai Wan},
keywords = {SHCC, Automated crack characterization, Deep learning, Convolutional neural network, Smart structures},
abstract = {Characterization of surface cracks is one of the key steps towards condititional assessment and understanding the durability of strain hardening cementitious composites (SHCCs). Under laboratory conditions, surface crack statistics can be obtained from images of specimen surfaces through manual inspection. This is subjective, time consuming and laborious. In order to automate this process a framework encompassing a deep learning model for rapid identification and computation of crack parameters of thin SHCC cracks in presented in this work. A tailored deep convolutiontional neural network (TDCNN) was trained to detect thin cracks and then crack parameters were computed using image processing technique. The proposed technique does not require optimal lighting conditions, proper surface treatment, and prior (manual) selection of the correct region for proper inference.. The results from the controlled study suggest that the inference ability of TDCNN is reasonably good, resilient against epistemic uncertainty and tunable for completely independent but adverse observations. From the crack pattern computed using TDCCN, crack parameters-average crack width (ACW) and crack density (CD) can be calculated to facilitate conditional and durability assessment in a practical environment.}
}
@article{HAO2021101470,
title = {URLLC resource slicing and scheduling for trustworthy 6G vehicular services: A federated reinforcement learning approach},
journal = {Physical Communication},
volume = {49},
pages = {101470},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101470},
url = {https://www.sciencedirect.com/science/article/pii/S187449072100207X},
author = {Min Hao and Dongdong Ye and Siming Wang and Beihai Tan and Rong Yu},
keywords = {6G, Vehicular edge computing, Resource slicing, Federated learning, Zero trust architecture},
abstract = {In the upcoming 6G era, vehicles will massively connect to the wireless network through edge access points such as roadside units (RSUs). The increasing number of connected vehicles and vehicular services will take 6G vehicular network to a new challenging security boundary, i.e., the so-called zero trust network. The traditional resource slicing and scheduling solution has to evolve to deal with the zero trust security problems. In this paper, we consider the trustworthy 6G vehicular services and focus on the typical scenario of vehicular task offloading with resource slicing and scheduling. In order to prevent vehicles from malicious attacks by untrusted edge access points, we exploit a subjective logic model to score the reputation of edge nodes. The vehicles will select the edge nodes with high reputation for task offloading. After that, we develop an federated asynchronous reinforcement learning algorithm to optimize the offloading problem. The simulation results show that our approach can efficiently schedule the slice resources and effectively protect the information security of vehicles.}
}
@article{DONG2021106850,
title = {Self-learned suppression of roll oscillations based on model-free reinforcement learning},
journal = {Aerospace Science and Technology},
volume = {116},
pages = {106850},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.106850},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821003606},
author = {Yizhang Dong and Zhiwei Shi and Kun Chen and Zhangyi Yao},
keywords = {Reinforcement learning, Real-world, Uncommanded roll oscillation, Closed-loop blowing},
abstract = {The high-angle-of-attack uncommanded roll oscillations are dangerous and cause significant challenges in flight control. This paper focuses on investigating the feasibility and performance of an artificial-intelligence method - “model-free reinforcement learning” (MFRL) on this issue, in both simulation and experiment. In simulation, two algorithms TD3 and SAC were used to learn the policies to suppress the roll oscillations of a widely used mathematical model. The agents only utilized current states as observation vector, and achieved perfect results. In the experiments, these two algorithms were used to learn the policies to suppress the roll oscillations of a flying-wing model which utilized spanwise blowing as its roll effectors. It is worth noting that unlike in simulation, the experiments investigated the influence of the observation vectors' memory size on training results. The results show that for both algorithms, the agents cannot learn good-enough policies when their observation spaces were constructed only by the current sensor data. This phenomenon, which is a big difference between experiments and simulations of MFRL, is due to the non-Markovian characteristic of the real-world dynamics caused by inevitable latencies. However, constructing the observation space using current and past sensor data help both the TD3 and SAC agents to learn great policies to suppress the oscillations using spanwise blowing in real world. Surprisingly, the trained agents showed some counterintuitive “smart” behaviors in tests.}
}
@article{SIT2021104919,
title = {Deep learning for classifying and characterizing atmospheric ducting within the maritime setting},
journal = {Computers & Geosciences},
volume = {157},
pages = {104919},
year = {2021},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2021.104919},
url = {https://www.sciencedirect.com/science/article/pii/S0098300421002090},
author = {Hilarie Sit and Christopher J. Earls},
keywords = {Atmospheric ducting, Marine atmosphere, Deep learning, Ensemble model},
abstract = {Real-time characterization of refractivity within the marine atmospheric boundary layer can provide valuable information that can potentially be used to mitigate the effects of atmospheric ducting on radar performance. Many duct characterization models are successful at predicting parameters from a specific refractivity profile associated with a given type of duct; however, the ability to classify, and then subsequently characterize, various duct types is an important step towards a more comprehensive prediction model. We introduce a two-step approach using deep learning to differentiate sparsely sampled propagation factor measurements collected under evaporation ducting conditions with those collected under surface-based ducting conditions in order to subsequently estimate the appropriate refractivity parameters based on that differentiation. We show that this approach is not only accurate, but also efficient; thus providing a suitable method for real-time applications.}
}
@article{IUGA2018199,
title = {Fall monitoring and detection for at-risk persons using a UAV},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {10},
pages = {199-204},
year = {2018},
note = {3rd IFAC Conference on Embedded Systems, Computational Intelligence and Telematics in Control CESCIT 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.06.262},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318305834},
author = {Cristi Iuga and Paul Drăgan and Lucian Bușoniu},
keywords = {unmanned aerial vehicles, deep learning, fall detection},
abstract = {We describe a demonstrator application that uses a UAV to monitor and detect falls of an at-risk person. The position and state (upright or fallen) of the person are determined with deep-learning-based computer vision, where existing network weights are used for position detection, while for fall detection the last layer is fine-tuned in additional training. A simple visual servoing control strategy keeps the person in view of the drone, and maintains the drone at a set distance from the person. In experiments, falls were reliably detected, and the algorithm was able to successfully track the person indoors.}
}
@article{HE20202831,
title = {Mission-driven autonomous perception and fusion based on UAV swarm},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {11},
pages = {2831-2834},
year = {2020},
note = {SI: Emerging Technologies of Unmanned Aerial Vehicles},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.02.027},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120302272},
author = {You HE},
keywords = {Autonomous perception, Consensus, Distributed information fusion, Situation awareness, State estimation, Swarm, Unmanned aerial vehicle},
abstract = {Distributed autonomous situational awareness is one of the most important foundation for Unmanned Aerial Vehicle (UAV) swarm to implement various missions. Considering the application environment being usually characterized by strong confrontation, high dynamics, and deep uncertainty, the distributed situational awareness system based on UAV swarm needs to be driven by the mission requirements, while each node in the network can autonomously avoid collisions and perform detection mission through limited resource sharing as well as complementarity of respective advantages. By efficiently solving the problems of self-avoidance, autonomous flocking and splitting, joint estimation and control, etc., perception data from multi-platform multi-source should be extracted and fused reasonably, to generate refined, tailored target information and provide reliable support for decision-making.}
}
@article{SIHANG2020107503,
title = {Precise detection of Chinese characters in historical documents with deep reinforcement learning},
journal = {Pattern Recognition},
volume = {107},
pages = {107503},
year = {2020},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107503},
url = {https://www.sciencedirect.com/science/article/pii/S003132032030306X},
author = {Wu Sihang and Wang Jiapeng and Ma Weihong and Jin Lianwen},
keywords = {Deep reinforcement learning, Historical documents, Character detection, Reward function},
abstract = {The decision-making ability of deep reinforcement learning has been proved successfully in a variety of fields. Here, we use this method for precise character detection by making tight bounding boxes around the Chinese characters in historical documents. An agent is trained to learn the control policy of fine-tuning a bounding box step-by-step through a Markov Decision Process. We introduce a novel fully convolutional network with position-sensitive Region-of-Interest (RoI) pooling (FCPN). The network receives character patches as input without fixed size, and it can fuse position information into the features of actions. Besides, we propose a dense reward function (DRF) that provides excellent rewards according to different actions and environment states, improving the decision-making ability of the agent. Our approach is designed as a universal method that can be applied to the output of all character-level or word-level text detectors to obtain more precise detection results. Application to the Tripitaka Koreana in Han (TKH) and Multiple Tripitaka in Han (MTH) datasets confirm the very promising performance of this method. In particular, our approach yields a significant improvement under a large Intersection over Union (IoU) of 0.8. The robustness and generality are also proved by experiments on the scene text datasets ICDAR2013 and ICDAR2015.}
}
@article{KHAN2020571,
title = {Open Source Machine Learning Frameworks for Industrial Internet of Things},
journal = {Procedia Computer Science},
volume = {170},
pages = {571-577},
year = {2020},
note = {The 11th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 3rd International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.127},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920305652},
author = {Asharul Islam Khan and Ali Al-Badi},
keywords = {industrial internet of things, artificial intelligence, machine learning, deep learning, industrial 4. revolution, open source, frameworks, sensors, Tensorflow},
abstract = {Information and communication technology has revolutionized the industrial operations and productions. The industries irrespective of size, whether small or large, have felt the need of artificial intelligence and machine learning techniques to process the terabytes of data generated through sensors, actuators, industrial management systems, and web applications. These data have the characteristics of volume (terabyte) and variety (image, audio, video, graphics) and thus customized models and techniques are required for analysis and management. The advancement in computer hardware, processing power, storage capacity, and cloud computing have led to experimentation and implementation of machine learning models in industrial domain for resource optimization, operation management, and quality control. However, the industrial Data Analysts face the dilemma of selecting the affordable and easy to use machine learning frameworks that suite their need and expectations. The study investigates the open source machine learning frameworks, aligned with the industrial domain (processing data generated from Industrial Internet of Things), in terms of usage, programming languages, implementations, and future prospects.}
}
@article{MUNAWAR2021103916,
title = {A review on flood management technologies related to image processing and machine learning},
journal = {Automation in Construction},
volume = {132},
pages = {103916},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103916},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521003678},
author = {Hafiz Suliman Munawar and Ahmed W.A. Hammad and S. Travis Waller},
keywords = {Flood management, Image processing, Machine learning, Disaster management},
abstract = {Flood management, which involves flood prediction, detection, mapping, evacuation, and relief activities, can be improved via the adoption of state-of-the-art tools and technology. Focusing on ways to mitigate floods and provide a quick response after floods is critical to ensuring fatalities are minimized, along with reducing environmental and economic damages. In the literature, techniques from different domains including remote sensing, machine learning, image processing and data analysis have been explored to manage different tasks related to flood management. This study proposes a new framework that categorizes the recent research that has been conducted on flood management systems. The framework addresses the following significant research questions: (1) What are the major techniques deployed in flood management? (2) What are the phases of flood management which existing studies tend to focus on? (3) What are the systems that are proposed to tackle problems related to flood management? (4) What are the research gaps identified in the literature when it comes to deploying technology for flood management? A classification framework for flood management has been proposed to group the various technologies reviewed. Lack of hybrid models, which combine image processing and machine learning, for flood management was observed. In addition, the application of machine learning-based methods in the post-disaster scenario was found to be limited. Thus, future efforts need to focus on combining disaster management knowledge, image processing techniques and machine learning tools to ensure effective and holistic disaster management across all phases.}
}
@article{VRBA2022103970,
title = {Autonomous capture of agile flying objects using UAVs: The MBZIRC 2020 challenge},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103970},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103970},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002396},
author = {Matouš Vrba and Yurii Stasinchuk and Tomáš Báča and Vojtěch Spurný and Matěj Petrlík and Daniel Heřt and David Žaitlík and Martin Saska},
keywords = {Unmanned aerial systems, Machine perception, Mobile robotics, Aerial safety},
abstract = {In this paper, a novel approach for autonomously catching fast flying objects is presented, as inspired by the Mohamed Bin Zayed International Robotics Challenge (MBZIRC) 2020. In this competition, an autonomous Unmanned Aerial Vehicle (UAV) was used to intercept a ball carried by a fast flying drone. The presented solution utilizes a 3D LiDAR sensor for quick and robust target detection. The trajectory of the target is estimated and predicted to select a suitable interception position. The interceptor UAV is navigated into the interception position to safely approach the target. The interception position is frequently being adjusted based on the updated estimation and prediction of the target’s motion to ensure that the ball is caught in the dedicated onboard net. After a successful interception is detected, the UAV lands in a designated landing area. The proposed concept was intensively tested and refined in demanding outdoor conditions with strong winds and varying perception conditions to achieve the robustness required by both the demanding application and the competition. In the MBZIRC 2020 competition, our solution scored second place in Challenge 1 and first place in a combined Grand Challenge. This manuscript will provide a detailed description of the applied methods and an evaluation of our approach with data collected from real-world experiments. In addition, we present achievements of our R&D towards the transition from the MBZIRC competition to an autonomous drone interceptor, which was the main motivation of this challenge.}
}
@article{MAZHAR2013210,
title = {On using neural networks in UAV structural design for CFD data fitting and classification},
journal = {Aerospace Science and Technology},
volume = {30},
number = {1},
pages = {210-225},
year = {2013},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2013.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S1270963813001454},
author = {Farrukh Mazhar and Abdul Munem Khan and Imran Ali Chaudhry and Mansoor Ahsan},
keywords = {Artificial neural networks (ANN), Aircraft structural design, Unmanned aerial vehicle (UAV), Finite element analysis (FEM/FEA), Computational fluid dynamics (CFD), One way fluid–solid interaction (FSI)},
abstract = {In this paper, we present a novel technique based upon artificial neural network (ANN), for applying aerodynamic pressure loads on the unmanned aerial vehicle (UAV) for the purpose of carrying out finite element (FE) analysis during its structural design process. The objective of the work aims at carrying out one way fluid–solid interaction (FSI) for UAV structural design, in which aerodynamics loads obtained from Computational Fluid Dynamics (CFD) analysis are applied on the vehicle structure for steady-state static FE analysis. CFD analysis of the UAV was performed using FLUENT® software. While, the FE analysis of the UAV was performed in ANSYS® software. As CFD and FE software employ different meshing schemes, thus pressure points coordinates obtained from CFD are not concurrent with the FE mesh. A methodology was, therefore, devised using artificial neural networks to generate pressure functions. In this method, aerodynamic pressure data was first sorted in terms of coordinates for different regions; a feed forward back propagation neural network model was then trained for each data set to generate approximate pressure functions in terms of coordinates. These pressure equations are subsequently used for applying pressure loads on the aircraft for strength and stiffness computation and internal layout design of the UAV structure. The work exhibits successful employment of ANN to match actual pressure profile on the aircraft. In comparison with conventional 3D regression techniques, this technique yielded very satisfactory and reliable results. It has been shown that this technique provided superior performance in comparison with 2D curve fitting employing higher order polynomials.}
}
@article{CEVALLOS2019757,
title = {Convolutional Neural Network in the Recognition of Spatial Images of Sugarcane Crops in the Troncal Region of the Coast of Ecuador},
journal = {Procedia Computer Science},
volume = {150},
pages = {757-763},
year = {2019},
note = {Proceedings of the 13th International Symposium “Intelligent Systems 2018” (INTELS’18), 22-24 October, 2018, St. Petersburg, Russia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919303436},
author = {J.P. Cobeña Cevallos and J.M. Atiencia Villagomez and I.S. Andryshchenko},
keywords = {Convolutional Neural Network, Machine Learning, classification, image analysis, precision agriculture},
abstract = {This article deals with the agriculture, as part of the primary sector of the economy, includes the transformation of the natural environment through a set of actions and human intervention that allows satisfying the production mainly of food and derived raw materials. Therefore, with the high demand for products required for agricultural activity, it is necessary to implement new technologies to guarantee the quality and performance of production techniques and reduce environmental impact. In this context, precision agriculture has emerged to improve, evaluate, estimate and understand, based on the information obtained, the needs of crops. Taking into account the evolution of the methodology for processing of satellite images and the obtaining of indirect data, a classification of the characteristics of crop yield can be made. Definitely, different techniques have been applied to the processing of satellite images, but recently a current approach, both in effectiveness and speed in obtaining excellent results is the use of deep learning of the convolution of neural networks. The deep convolution of neural networks is used both in the recognition as well as in the classification of the satellite images of the sugarcane plantation in the Troncal region of the Coast of Ecuador. The experiment showed affirmative results of approximately 95% probability of recognition of crop status.}
}
@article{WU2021,
title = {Periodic event-triggered formation control for multi-UAV systems with collision avoidance},
journal = {Chinese Journal of Aeronautics},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121003733},
author = {Tong WU and Jie WANG and Bailing TIAN},
keywords = {Collision avoidance, Distributed formation control, Event-triggered strategy, Leader-follower method, Multiple Unmanned Aerial Vehicles (UAVs)},
abstract = {In this paper, periodic event-triggered formation control problems with collision avoidance are studied for leader–follower multiple Unmanned Aerial Vehicles (UAVs). Firstly, based on the Artificial Potential Field (APF) method, a novel sliding manifold is proposed for controller design, which can solve the problem of collision avoidance. Then, the event-triggered strategy is applied to the distributed formation control of multi-UAV systems, where the evaluation of the event condition is continuous. In addition, the exclusion of Zeno behavior can be guaranteed by the inter-event time between two successive trigger events have a positive lower bound. Next, a periodic event-triggered mechanism is developed for formation control based on the continuous event-triggered mechanism. The periodic trigger mechanism does not need additional hardware circuits and sophisticated sensors, which can reduce the control cost. The stability of the control system is proved by the Lyapunov function method. Finally, some numerical simulations are presented to illustrate the effectiveness of the proposed control protocol.}
}
@article{QADIR2021114,
title = {Addressing disasters in smart cities through UAVs path planning and 5G communications: A systematic review},
journal = {Computer Communications},
volume = {168},
pages = {114-135},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421000116},
author = {Zakria Qadir and Fahim Ullah and Hafiz Suliman Munawar and Fadi Al-Turjman},
keywords = {Unmanned aerial vehicles (UAVs), UAV path planning, UAV communication networks (UAVCN), Disaster management, Smart cities},
abstract = {UAVs are increasingly incorporated in a wide range of domains such as disaster management and rescue missions. UAV path planning deals with finding the most optimal or shortest path for UAVs such that minimum energy and resources are utilized. This paper examines the path planning algorithms for UAVs through a literature survey conducted on 139 systematically retrieved articles published in the last decade that are narrowed down to 36 highly relevant articles. As retrieved from the shortlisted articles, the path planning algorithms include RRT, Artificial Potential, Voronoi, D-Star, A-Star, Dijkstra, MILP, Neural Network, Ant Colony Optimization, and Particle Swarm Optimization that are classified into four main types: Model-based, Conventional, Learning-based, and Cell-based. Most of the disaster-related articles are focused on the post-disaster phase only and use conventional and learning-based algorithms with applications to localize victims and optimize paths. Regarding the UAV communication network (UAVCN), the key challenges are communication issues, resource allocation, UAV deployment, defining UAV trajectory, and content security. UAV path planning’s key barriers are path optimization, path completeness, optimality, efficiency, and achieving robustness. Accordingly, a holistic IoT-powered UAV-based smart city management system has been recommended in the current study where all the smart city key components are integrated to address disasters like floods, earthquakes, and bush fire. The proposed holistic system can help prepare for disasters and mitigate them as soon as these arise and help enhance the smart city governance.}
}
@article{JI2021108874,
title = {Model-free fault diagnosis for autonomous underwater vehicles using sequence Convolutional Neural Network},
journal = {Ocean Engineering},
volume = {232},
pages = {108874},
year = {2021},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2021.108874},
url = {https://www.sciencedirect.com/science/article/pii/S0029801821003097},
author = {Daxiong Ji and Xin Yao and Shuo Li and Yuangui Tang and Yu Tian},
keywords = {Fault diagnosis, Autonomous Underwater Vehicles (AUVs), Convolutional Neural Network (CNN), Model-free, Global feature},
abstract = {The AUV must be capable of fault diagnosis if it is to perform tasks in complex environments without human assistance. However, the current fault diagnosis methods for AUV lack of manual experience and accuracy, leading to the lack of fault handling capacity. Different from the traditional model-based fault diagnosis, we propose a new model-free fault diagnosis method characterized by a deep learning-based algorithm, which is a new Sequence Convolutional Neural Network (SeqCNN) that learns the patterns between state data and fault type. More specifically, the proposed SeqCNN aims to extract global feature and local feature from state data and classify the extracted information into different fault types, and can convert two-stage diagnosis mode into a single-stage one. Compared to the traditional model-based diagnosis, it can significantly reduce the time-consuming burden, simplify the diagnosis procedure and improve the efficiency. The effectiveness of SeqCNN was validated by a practical experiment on a small quadrotor AUV ‘Haizhe’. The results indicate that the proposed SeqCNN can solve the problem of fault detection and fault isolation in single-stage diagnosis mode and that its accuracy is far superior to that of other deep learning diagnosis algorithms.}
}
@article{HIBA20197,
title = {The applicability of on-line contextual calibration to a neural network based monocular collision avoidance system on a UAV⁎⁎Research is supported by 2018-1.2.1-NKP-00008: Exploring the Mathematical Foundations of Artificial Intelligence and by MTA Premium Postdoctoral Grant 2018. This paper was also supported by the Janos Bolyai Research Scholarship of the Hungarian Academy of Sciences and the Higher Education Institutional Excellence Program.},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {11},
pages = {7-12},
year = {2019},
note = {5th IFAC Conference on Intelligent Control and Automation Sciences ICONS 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.09.110},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319307396},
author = {Antal Hiba and Rita Aleksziev and Koppány Pázmán and Péter Bauer and András Benczúr and Ákos Zarándy and Bálint Daróczy},
keywords = {Learning, adaptation, evaluation, Aerospace, Robotics, autonomous systems},
abstract = {Contextual calibration for object detection is a technique where a pretrained network collects attractive false positives during a calibration phase and use this calibration data for further training. This paper investigates the applicability of this method to a vision based onboard sense and avoid system, which requires intruder aircraft detection in camera images. Various landscape and sky backgrounds were generated by Unreal4 3D engine for calibration tests. Contextual calibration is a promising candidate for handling extreme situations which are not covered well in the training data.}
}
@article{PI2020104222,
title = {Low-level autonomous control and tracking of quadrotor using reinforcement learning},
journal = {Control Engineering Practice},
volume = {95},
pages = {104222},
year = {2020},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2019.104222},
url = {https://www.sciencedirect.com/science/article/pii/S0967066119301923},
author = {Chen-Huan Pi and Kai-Chun Hu and Stone Cheng and I-Chen Wu},
keywords = {Reinforcement learning, Policy gradient, Quadrotor},
abstract = {This paper proposes a low-level quadrotor control algorithm using neural networks with model-free reinforcement learning, then explores the algorithm’s capabilities on quadrotor hover and tracking tasks. We provide a new point of view by examining the well-known policy gradient algorithm from reinforcement learning, then relaxing its requirements to improve training efficiency. Without requiring expert demonstrations, the improved algorithm is then applied to train a quadrotor controller with its output directly mapped to four actuators in a simulator, which is a technique used to control any linear or nonlinear system under unknown dynamic parameters and disturbances. We show two experimental tasks both in simulation and real-world quadrotors to verify our method and demonstrate performance: 1) hovering at a fixed position, and 2) tracking along a specific trajectory. The video of our experiments can be found at https://youtu.be/oEVcdiFPnMo.}
}
@article{CUI2016220,
title = {Reinforcement learning-based asymptotic cooperative tracking of a class multi-agent dynamic systems using neural networks},
journal = {Neurocomputing},
volume = {171},
pages = {220-229},
year = {2016},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.06.066},
url = {https://www.sciencedirect.com/science/article/pii/S0925231215009418},
author = {Lili Cui and Xiaowei Wang and Yong Zhang},
keywords = {Reinforcement learning, Neural networks, Multi-agent dynamic systems, Cooperative tracking, RISE technique},
abstract = {In this paper, a novel reinforcement learning-based cooperative tracking control scheme is proposed for a class of multi-agent dynamic systems with disturbances and un-modeled dynamics on undirected graphs by using neural networks (NNs). For each agent, two NNs are employed, i.e., an actor NN which approximates the unknown nonlinearity and generates the control input, and a critic NN which evaluates the performance of the actor and updates the weights of actor NN. Further, a RISE technique is utilized in the design of the actor NN and the critic NN to compensate for the external disturbances and the NN approximation errors. Based on the Lyapunov theory, it is proved that the proposed control scheme can guarantee the tracking error of each agent to converge to zero asymptotically. Additionally, the proposed control scheme is distributed in the sense that the controller for each agent only uses the local neighbor information. Finally, two simulation examples are given to verify the effectiveness of the proposed control scheme.}
}
@article{BAKIRCIOGLU2022103977,
title = {Experimental comparison of the effect of the number of redundant rotors on the fault tolerance performance for the proposed multilayer UAV},
journal = {Robotics and Autonomous Systems},
volume = {149},
pages = {103977},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103977},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002438},
author = {Veli Bakırcıoğlu and Nihat Çabuk and Şahin Yıldırım},
keywords = {Actuator redundancy, Fault-tolerance, Flight safety, Multi-layer UAV, Universal UAV},
abstract = {In this paper, experimental investigation of the flight performance of the proposed universal Unmanned Aerial Vehicle (UAV) in case of rotor failures is presented. In the experimental flight tests, proposed universal UAV that can be converted to many different configurations due to its non-standard multi-layer structure was used in two different configurations as a standard octorotor and a multi-layer dodecarotor. Multiple outdoor experiments are conducted to show flight safety and reliability of the proposed UAV in terms of rotor failure tolerance. In order to evaluate flight safety and reliability of the proposed UAV, take-off, hovering and landing flight performance analyzes were performed in cases where one or two motors/propellers were completely lost. As performance criteria, errors in the UAV’s roll, pitch and yaw angles, altitude error and vibration in three axes were determined. The flight test results are presented both numerically and graphically. According to the results, multi-layer dodecarotor type has shown a more stable flight performance in terms of angular position errors. In addition, in both types of UAVs, in the case of failure of two rotors rotating in the opposite direction, it has been observed that the error in yaw angle is less than a rotor failure, as expected. Likewise, in the case of failure of two rotors rotating in the same direction, performance loss was observed in the control of yaw angle.}
}
@article{ZHANG2021103796,
title = {Research on environmental landscape design based on virtual reality technology and deep learning},
journal = {Microprocessors and Microsystems},
volume = {81},
pages = {103796},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2020.103796},
url = {https://www.sciencedirect.com/science/article/pii/S0141933120309418},
author = {Tao Zhang},
keywords = {Environmental landscape, Virtual reality technology, Deep neural network (DNN), Field programmable gate array (FPGA)},
abstract = {Virtual Reality (VR) provides immersive visualization and intuitive interaction. The VR is used to enable any biomedical profession to develop a deep learning (DL) model for image classification. The Deep Neural Network (DNN) models can be used as a powerful tool for data analysis, but they are also challenging to understand and develop. To make deep learning more convenient and fast operation, it have established a landscape of DNN development environment based on virtual reality. In this environment, users can move concrete objects only to build neural networks with their own hands. It automatically transforms these configurations into a trainable model and reports on the real-time test dataset. In addition to realizing the insights users are developing into DNN models, it has also visually enriched the virtual environmental landscape objects with the parts of the model. In this way bridge the gap between professionals in different disciplines, providing a new perspective on the model analysis and data interaction. This system further demonstrates that learning and visualization technologies developed in Shenzhen can benefit from integrating virtual reality.}
}
@article{ALAM2020302,
title = {Survey on Deep Neural Networks in Speech and Vision Systems},
journal = {Neurocomputing},
volume = {417},
pages = {302-321},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.07.053},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220311619},
author = {M. Alam and M.D. Samad and L. Vidyaratne and A. Glandon and K.M. Iftekharuddin},
keywords = {Vision processing, Speech recognition, Natural language processing, Computational intelligence, Deep learning, Computer vision, Hardware constraints, Embedded systems, Convolutional neural networks, Deep autoencoders, Generative neural networks},
abstract = {This survey presents a review of state-of-the-art deep neural network architectures, algorithms, and systems in speech and vision applications. Recent advances in deep artificial neural network algorithms and architectures have spurred rapid innovation and development of intelligent speech and vision systems. With availability of vast amounts of sensor data and cloud computing for processing and training of deep neural networks, and with increased sophistication in mobile and embedded technology, the next-generation intelligent systems are poised to revolutionize personal and commercial computing. This survey begins by providing background and evolution of some of the most successful deep learning models for intelligent speech and vision systems to date. An overview of large-scale industrial research and development efforts is provided to emphasize future trends and prospects of intelligent speech and vision systems. Robust and efficient intelligent systems demand low-latency and high fidelity in resource-constrained hardware platforms such as mobile devices, robots, and automobiles. Therefore, this survey also provides a summary of key challenges and recent successes in running deep neural networks on hardware-restricted platforms, i.e. within limited memory, battery life, and processing capabilities. Finally, emerging applications of speech and vision across disciplines such as affective computing, intelligent transportation, and precision medicine are discussed. To our knowledge, this paper provides one of the most comprehensive surveys on the latest developments in intelligent speech and vision applications from the perspectives of both software and hardware systems. Many of these emerging technologies using deep neural networks show tremendous promise to revolutionize research and development for future speech and vision systems.}
}
@article{HE2021107485,
title = {Neuro-adaptive singularity-free finite-time attitude tracking control of quadrotor UAVs},
journal = {Computers & Electrical Engineering},
volume = {96},
pages = {107485},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107485},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621004407},
author = {Xiongxiong He and Meiling Tao and Shuzong Xie and Qiang Chen},
keywords = {Adaptive control, Finite-time control, Neural network, Quadrotors, Singularity-free sliding mode surface},
abstract = {In this paper, a neuro-adaptive finite-time control law is proposed for the quadrotor unmanned aerial vehicles. Instead of employing any piecewise continuous functions, a singularity-free terminal sliding mode surface and an auxiliary function are presented to overcome the singularity issues resulted from the differentiation of the sliding variable and the error-related inverse matrix in the controller design, respectively. A simple neural network is employed to estimate the unknown dynamics, such that no prior knowledge on system model uncertainties is required for designing attitude controllers. With the presented control law, the finite-time convergence of the attitude and angular velocity errors can be guaranteed by rigorously theoretical analysis, and numerical simulations are performed to demonstrate the satisfactory performance of the proposed method.}
}
@article{CHEN2021102523,
title = {A deep region-based pyramid neural network for automatic detection and multi-classification of various surface defects of aluminum alloys},
journal = {Journal of Building Engineering},
volume = {43},
pages = {102523},
year = {2021},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2021.102523},
url = {https://www.sciencedirect.com/science/article/pii/S2352710221003806},
author = {Keyu Chen and Zhaoyang Zeng and Jianfei Yang},
keywords = {Aluminum alloys, Defect detection, Faster R–CNN, Feature pyramid network (FPN), Deformable-ConvNets (DCN), Contextual ROI pooling},
abstract = {Aluminum alloys have a wide range of applications in building and civil infrastructure. During the process of production, transportation and storage, various defects inevitably occur on the material, including blisters, scratches, base exposure, dirty points, etc. The efficiency and accuracy of defect detection and classification can be greatly improved by replacing the conventional manual approaches with modern deep learning techniques. This paper proposes to use computer vision and deep learning techniques to achieve automatic detection of various defects of aluminum alloys. Faster region-based convolutional neural network (Faster R–CNN) is selected as the fundamental framework due to its advantages in efficiency and accuracy. According to the characteristics of defects in aluminum alloys, the framework is optimized by (1) feature pyramid networks (FPN) for integration of low-level structural information with high-level semantic information, as well as increasing the feature mapping resolution of small targets; (2) deformable-ConvNets for feature extraction at the most appropriate places; and (3) contextual ROI pooling for fine adjustment of region proposal taking the entire image as a reference. To make full use of the limited samples, the training process is also optimized by (1) utilizing samples without defects; and (2) sample duplication by horizontal and vertical rotation. The proposed approach is validated on a dataset with 10000 images and is shown to have outstanding performance compared to other existing deep learning approaches in defect detection and classification.}
}
@article{BARBEDO2019482,
title = {Detection of nutrition deficiencies in plants using proximal images and machine learning: A review},
journal = {Computers and Electronics in Agriculture},
volume = {162},
pages = {482-492},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.04.035},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918318957},
author = {Jayme Garcia Arnal Barbedo},
keywords = {Image processing, Computer vision, Plant nutrition, Machine learning},
abstract = {During the last decade, the combination of digital images and machine learning techniques for tackling agricultural problems has been one of the most explored elements of digital farming. In the specific case of proximal images, most efforts have been directed to the detection and classification of plant diseases and crop-damaging pests. Important progress has also been made on the use of close-range images to determine vegetal nutrient status, but because such studies are fewer and more scattered, it is difficult to draw a complete picture on the state of art of this type of research. In this context, a thorough literature search was carried out in order to identify as many relevant investigations on the subject as possible. Every kind of imaging sensor was considered (visible range, multispectral, hyperspectral, chlorophyll fluorescence, etc.), provided that images were captured at close range, thus excluding research using Unmanned Aerial Vehicles (UAVs), airplanes and satellites. A careful analysis of the techniques for detection and classification was carried out and used as basis for an in-depth discussion on the main challenges yet to be overcome. Some directions for future research are also suggested, having as target to increase the practical adoption of this kind of technology.}
}
@article{FERCHICHI2022101552,
title = {Forecasting vegetation indices from spatio-temporal remotely sensed data using deep learning-based approaches: A systematic literature review},
journal = {Ecological Informatics},
pages = {101552},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101552},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122000012},
author = {Aya Ferchichi and Ali Ben Abbes and Vincent Barra and Imed Riadh Farah},
keywords = {Deep learning, Vegetation, Remote sensing, Spatio-temporal forecasting},
abstract = {Over the last few years, Deep learning (DL) approaches have been shown to outperform state-of-the-art machine learning (ML) techniques in many applications such as vegetation forecasting, sales forecast, weather conditions, crop yield prediction, landslides detection and even COVID-19 spread predictions. Several DL algorithms have been employed to facilitate vegetation forecasting research using Remotely Sensed (RS) data. Vegetation is an extremely important component of our global ecosystem and a necessary indicator of land cover dynamics and productivity. Vegetation phenology is influenced by lifecycle patterns, seasonality and weather conditions, leading to changes in their spectral reflectance. Various relevant information, such as vegetation indices (VIs), can be extracted from RS data for vegetation forecasting. Therefore, the Normalized Difference Vegetation Index (NDVI) is known as one of the most widely recognized indices for vegetation related studies. This paper reviews the related works on DL-based spatio-temporal vegetation forecasting using RS data over the period between 2015 and 2021. In this review, we present several DL-based studies and discuss DL algorithms and various sources of data that have been used in these studies. The purpose of this work is to highlight the open challenges such as spatio-temporal prediction issues, spatial and temporal non-stationarity, fusion data, hybrid approaches, deep transfer learning and large parameter requirements. We also attempt to figure out the future directions and limits of DL for vegetation forecasting.}
}
@article{ZHAO2020324,
title = {Ubiquitous Distributed Deep Reinforcement Learning at the Edge: Analyzing Byzantine Agents in Discrete Action Spaces},
journal = {Procedia Computer Science},
volume = {177},
pages = {324-329},
year = {2020},
note = {The 11th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2020) / The 10th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH 2020) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.10.043},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920323115},
author = {Wenshuai Zhao and Jorge Peña Queralta and Li Qingqing and Tomi Westerlund},
keywords = {Reinforcement Learning, Edge Computing, Multi-Agent Systems, Collaborative Learning, RL, Deep RL, Adversarial RL},
abstract = {The integration of edge computing in next-generation mobile networks is bringing low-latency and high-bandwidth ubiquitous connectivity to a myriad of cyber-physical systems. This will further boost the increasing intelligence that is being embedded at the edge in various types of autonomous systems, where collaborative machine learning has the potential to play a significant role. This paper discusses some of the challenges in multi-agent distributed deep reinforcement learning that can occur in the presence of byzantine or malfunctioning agents. As the simulation-to-reality gap gets bridged, the probability of malfunctions or errors must be taken into account. We show how wrong discrete actions can significantly affect the collaborative learning effort. In particular, we analyze the effect of having a fraction of agents that might perform the wrong action with a given probability. We study the ability of the system to converge towards a common working policy through the collaborative learning process based on the number of experiences from each of the agents to be aggregated for each policy update, together with the fraction of wrong actions from agents experiencing malfunctions. Our experiments are carried out in a simulation environment using the Atari testbed for the discrete action spaces, and advantage actor-critic (A2C) for the distributed multi-agent training.}
}
@inproceedings{10.1109/ICSE-Companion.2019.00051,
author = {Sun, Youcheng and Huang, Xiaowei and Kroening, Daniel and Sharp, James and Hill, Matthew and Ashmore, Rob},
title = {DeepConcolic: Testing and Debugging Deep Neural Networks},
year = {2019},
publisher = {IEEE Press},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/ICSE-Companion.2019.00051},
doi = {10.1109/ICSE-Companion.2019.00051},
abstract = {Deep neural networks (DNNs) have been deployed in a wide range of applications. We introduce a DNN testing and debugging tool, called DeepConcolic, which is able to detect errors with sufficient rigour so as to be applicable to the testing of DNNs in safety-related applications. DeepConcolic is the first tool that implements a concolic testing technique for DNNs, and the first testing tool that provides users with the functionality of investigating particular parts of a DNN. The tool has been made publicly available and a demo video can be found at https://youtu.be/rliynbhoNLM.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings},
pages = {111–114},
numpages = {4},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/3468691.3468702,
author = {Xie, Wen and Bai, Xiangyu},
title = {Research on Data Collection Mechanism of Wireless Sensor Network Based on UAV},
year = {2021},
isbn = {9781450389693},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3468691.3468702},
doi = {10.1145/3468691.3468702},
abstract = {In recent years, Wireless Sensor networks (WSNs) have developed rapidly and have been widely used in various fields such as commerce, agriculture, military affairs and the environment. However, with the development of technology and the increasing demand of application scenarios, the limitations of WSNs are becoming more and more obvious. On the other hand, through continuous improvement, Unmanned Aerial Vehicle (UAV) technology has become more and more powerful, which can provide reliable, cost-effective services for people. The connectivity and energy efficiency of WSN can be significantly improved by taking advantage of UAV's high altitude hovering capability, communication capability and flexible mobility. Many researchers believe that UAV assisted communication in WSN is a promising solution. In this paper, we first discuss the limitations of WSN in certain scenarios and the advantages of UAV-assisted WSN. Secondly, the development and research status of UAV-assisted wireless sensor network communication are introduced. In this process, this paper introduces the research status of three data collection methods: data storage and forwarding UAV, mobile relay UAV and aerial base station UAV, and discusses the research progress in the field of wireless communication of UAV. Finally, this paper compares and analyzes the above three types of UAV-assisted sensor network data collection methods, and prospects the future research of UAV-assisted WSN.},
booktitle = {2021 2nd International Conference on Computing, Networks and Internet of Things},
articleno = {11},
numpages = {8},
keywords = {Wireless sensor networks, aerial wireless relay, Mobile base station, UAV, Data collection},
location = {Beijing, China},
series = {CNIOT '21}
}

@inproceedings{10.1145/3094243.3094254,
author = {Wang, Miaoyiquan and Tong, Weiguo and Liu, Shibo},
title = {Fault Detection for Power Line Based on Convolution Neural Network},
year = {2017},
isbn = {9781450352321},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3094243.3094254},
doi = {10.1145/3094243.3094254},
abstract = {In order to solve the problem of power line fault detection, we proposed to introduce convolutional neural network (CNN) into the field of power line fault detection. In this paper, we describe a novel detection method which combines the sliding window approach and the output map information. Our algorithm can be divide into three steps. The first step uses CNN combined with sliding window approach to make predictions of all part of input image and achieves the output map. In the second step, the output map is preprocessed to make it more conducive to localization. Finally, object detection is accomplished according to the information of the preprocessed output map. Experimental results show that our algorithm can effectively solve the problem of power line fault detection in complex background.},
booktitle = {Proceedings of the 2017 International Conference on Deep Learning Technologies},
pages = {95–101},
numpages = {7},
keywords = {Convolutional neural network, Output map, Sliding window, Digital image processing, Deep learning, Power line fault detection},
location = {Chengdu, China},
series = {ICDLT '17}
}

@inproceedings{10.1145/3193025.3193051,
author = {Kim, Seongyong and Park, Seula and Yu, Kiyun},
title = {Proposal for a Method of Extracting Road Layers from Remote Sensing Images Using Conditional GANs},
year = {2018},
isbn = {9781450364027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3193025.3193051},
doi = {10.1145/3193025.3193051},
abstract = {With the recent advances in unmanned aerial vehicle (UAV) technology, remote sensing images have become relatively easy to obtain and their accuracy has increased enough to be able to handle land information. Therefore, there is a growing demand to utilize remote sensing images for extracting semantic objects Conventional methods are mainly focused on pixel-based classification and recently people commonly use convolutional neural networks, which post processing is required to linearize roads that are cut off and accurately shape the contours of buildings. We propose the use of a generative model to carry out this post processing in the networks. Using conditional Generative Adversarial Network (GANs), we translate remote sensing images into map-based images from which roads are easily extracted, while retaining the underlying structure. Next, we extract road layers from the generated images. Through this approach, it is possible to achieve the same effect as if complicating post processing were done in the networks during the object extraction process.},
booktitle = {Proceedings of the 2nd International Conference on Digital Signal Processing},
pages = {84–87},
numpages = {4},
keywords = {Generative adversarial networks, Deep learning, Satellite images, Remote sensing, Extracting roads},
location = {Tokyo, Japan},
series = {ICDSP 2018}
}

@inproceedings{10.1145/3383812.3383838,
author = {Pacot, Mark Phil B. and Marcos, Nelson},
title = {Cloud Removal from Aerial Images Using Generative Adversarial Network with Simple Image Enhancement},
year = {2020},
isbn = {9781450377201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3383812.3383838},
doi = {10.1145/3383812.3383838},
abstract = {The atmospheric condition of the presence of clouds is one of the biggest problems in most aerial imaging systems. It degrades the visual quality of images leading to the loss of information for ground scenes. Hence, an effective cloud removal algorithm is a significant factor for this kind of problem and other related applications. The proposed cloud removal technique using the generative adversarial network with simple image enhancement (SIE-GAN) is a useful tool in removing cloud formations, most notably in images acquired using Unmanned Aerial Vehicle System (UAVs). This technique showed flexibility in performing the given task with satisfactory results, which is a gauge based on No-Reference Image Quality Metric, specifically the Perception-based Image Quality Evaluator (PIQE). Also, the proposed algorithm outperformed some of existing cloud removal algorithms by producing a better quality output when tested on the too-cloudy satellite images. Overall, the authors introduced a new frontier in generating cloud-free aerial images and added a valuable contribution to the array of cloud removal algorithms.},
booktitle = {Proceedings of the 2020 3rd International Conference on Image and Graphics Processing},
pages = {77–81},
numpages = {5},
keywords = {no-reference image quality metric, simple image enhancement, unmanned aerial vehicle system, cloud removal, generative adversarial network},
location = {Singapore, Singapore},
series = {ICIGP 2020}
}

@inproceedings{10.1145/3411043.3412502,
author = {Gao, Ning and Jin, Shi and Li, Xiao},
title = {3D Deployment of UAV Swarm for Massive MIMO Communications},
year = {2020},
isbn = {9781450380812},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3411043.3412502},
doi = {10.1145/3411043.3412502},
abstract = {In this paper, we consider the uplink transmission between a multi-antenna ground station and an unmanned aerial vehicle (UAV) swarm. The UAVs are assumed as intelligent agents which can adaptively adjust their three dimensional (3D) deployment to maximize the channel capacity of the multiple input multiple output (MIMO) system. Specifically, for the limitations of each UAV in accessing the global information, we consider a decentralized control strategy and divide the optimization problem into several optimization sub-problems, and then formulated into a UAVs channel capacity game. We analyze such game according to the designed reward function and the potential function. Then, we discuss the existence of the pure Nash equilibrium in the game. To achieve the best Nash equilibrium of the MIMO system, we develop a decentralized learning algorithm, namely decentralized UAVs channel capacity learning. The details of the algorithm is provided and the convergence of the algorithm is analyzed. In the meanwhile, we give some insightful remarks. The simulations show that the developed learning algorithm can achieve a high channel capacity than the benchmark methods.},
booktitle = {Proceedings of the ACM MobiArch 2020 The 15th Workshop on Mobility in the Evolving Internet Architecture},
pages = {24–29},
numpages = {6},
keywords = {3D deployment, massive MIMO communications, decentralized, UAV swarm},
location = {London, United Kingdom},
series = {MobiArch'20}
}

@inproceedings{10.1145/3290420.3290426,
author = {Qi, Shengxiang and Zhang, Wei and Xu, Guojing},
title = {Detecting Consumer Drones from Static Infrared Images by Fast-Saliency and HOG Descriptor},
year = {2018},
isbn = {9781450365345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3290420.3290426},
doi = {10.1145/3290420.3290426},
abstract = {Consumer drones detection plays an important role in applications including counter-terrorism, intelligent security and airway management. In this paper, we present an effective way for detecting consumer drones from static infrared images by saliency mapping and machine learning. Crucially, we propose a fast-saliency model with a simple 5 \texttimes{} 5 kernel convolution to obtain the saliency map of the input image, in which targets are enhanced while the background is suppressed. Candidate regions that may contain drones are extracted from the saliency map by adaptive thresholding and connected domain filtering, followed by feature expression with HOG descriptor for each region. Finally, the realities of these candidates are discriminated by support vector machine being trained from 200 drone samples and 400 background samples. Experiments on four real sequences over 600 infrared images demonstrate that our proposed algorithm has good performance in both the detection accuracy and the computation efficiency.},
booktitle = {Proceedings of the 4th International Conference on Communication and Information Processing},
pages = {62–66},
numpages = {5},
keywords = {unmanned aerial vehicle, consumer drone, infrared image, target detection},
location = {Qingdao, China},
series = {ICCIP '18}
}

@inproceedings{10.1145/3430199.3430212,
author = {Wang, Ziyuan and Zhang, Geng and Hu, Bingliang and Feng, Xiangpeng},
title = {Real Time Detection and Identification of UAV Abnormal Trajectory},
year = {2020},
isbn = {9781450375511},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3430199.3430212},
doi = {10.1145/3430199.3430212},
abstract = {Abnormal behavior detection based on video sequence is a hot field. At the same time, monitoring and tracking the UAV (Unmanned Aerial Vehicle) and identifying its abnormal behavior are great significance for the UAV defense. This paper focuses on the detection and recognition of the UAV abnormal trajectory based on real-time video sequence. By tracking and analyzing the characteristics of the UAV, the detection and recognition of abnormal trajectory are divided into two stages. First, by analyzing the UAV's abnormal trajectory satisfying the change conditions is extracted by the quantitative analysis of the UAV's directional angle change features. Second, the normalized polar path fourier spectrum feature of abnormal trajectory is established, and the feature is combined with window search length to accelerate the classification and identification of the UAV trajectory types. Through the contrast experiment, it shows that the method in this paper has good real-time performance and accuracy for trajectory recognition with scale and translation changes.},
booktitle = {Proceedings of the 2020 3rd International Conference on Artificial Intelligence and Pattern Recognition},
pages = {51–56},
numpages = {6},
keywords = {Trajectory recognition, Anomaly detection, UAV defense},
location = {Xiamen, China},
series = {AIPR 2020}
}

@inproceedings{10.1145/3457682.3457742,
author = {Liu, Xia and Li, Yazhuo and Xie, Zhengyuan},
title = {Path Planning of UAV Based on Error Correction},
year = {2021},
isbn = {9781450389310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3457682.3457742},
doi = {10.1145/3457682.3457742},
abstract = {Abstract: Due to the limitation of system structure, UAV can not accurately locate itself. Once the positioning error accumulates to a certain extent, it may lead to mission failure. Therefore, the aircraft needs to go through several calibration points to correct vertical and horizontal error. In this paper, an improved ant colony optimization algorithm is used to realize path planning of the aircraft based on error correction. Firstly, mathematical model of path planning is established based on constraints of location error. Secondly, ant colony optimization is used to realize multi-objectives including maximizing success rate reaching the destination, minimizing the number of correction nodes and minimizing length of the path. To find feasible solutions for different problems, constraints are strengthened or relaxed and search strategies of the next node are set. Finally, the algorithm with adaptive parameters is verified by an example, the optimal path with 100% arrival rate, shorter length, and less correction nodes shows its effectiveness.},
booktitle = {2021 13th International Conference on Machine Learning and Computing},
pages = {392–396},
numpages = {5},
keywords = {Ant colony optimization, Path planning, Error correction, UAV},
location = {Shenzhen, China},
series = {ICMLC 2021}
}

@inproceedings{10.1145/3460268.3460276,
author = {Hou, Zhigang and Yan, Jin and Yang, Bowen and Ding, Zhiming},
title = {A Novel UAV Aerial Vehicle Detection Method Based on Attention Mechanism and Multi-Scale Feature Cross Fusion},
year = {2021},
isbn = {9781450389273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3460268.3460276},
doi = {10.1145/3460268.3460276},
abstract = {With the rapid development of artificial intelligence science, more and more researchers try to use deep learning to train neural networks and have achieved great success in object detection. Vehicle detection based on UAV image is a special field of object detection. Due to the low resolution of the vehicle object, complex background, and less image information, it is challenging to extract robust visual and spatial features from the depth network and accurately locate the object in complex scenes. In this paper, combining the characteristics of vehicles in aerial images, we design a novel feature pyramid network called channel-spatial attention fused feature pyramid network (CSF-FPN) with Faster R-CNN as the basic framework. In CSF-FPN, a hybrid attention mechanism and feature cross-fusion module are introduced, so that feature maps can be generated with enhanced spatial and channel interdependence to extract richer semantic information. After our CSF-FPN is integrated into the Faster R-CNN network, the detection performance of small objects is greatly improved. The experimental results based on the VEDIA Dataset showed that the proposed framework could effectively detect the vehicle in large scene azimuth. Compared with the existing advanced methods, mAP and F1-score are improved.},
booktitle = {2021 2nd International Conference on Artificial Intelligence in Electronics Engineering},
pages = {51–59},
numpages = {9},
keywords = {deep learning, UAV image, vehicle detection, feature pyramid, attention mechanism},
location = {Phuket, Thailand},
series = {AIEE 2021}
}

@inproceedings{10.5555/2499592.2499599,
author = {Madey, Alexander G. and Madey, Gregory R.},
title = {Design and Evaluation of UAV Swarm Command and Control Strategies},
year = {2013},
isbn = {9781627480291},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {We present an approach to developing unmanned aerial vehicle (UAV) swarming behaviors and command and control (C2) strategies to govern them. In recent years, the military has become increasingly interested in the development and applications of UAVs. Recent attention has shifted toward designing UAVs which are not only unmanned, but also autonomous or self-controlled. One possible method is to utilize a large number of small, autonomous UAVs which form a cohesive group or "swarm" to accomplish complex missions as a whole. Swarms offer numerous benefits over single UAVs which include higher coverage, redundancy in numbers and reduced long-range bandwidth requirements. A major challenge to engineering a swarm is not only designing the swarming behavior, but finding an effective way to control the behavior so that the swarm can be directed to complete the desired mission. In this paper, we used the agent-based modeling toolkit NetLogo to create two different mission types. We then created UAV swarming behaviors and ways in which those behaviors can be altered to accomplish each mission. Despite the fact that these models are still preliminary, and lacking in full realism, this work has demonstrated the potential usefulness of agent-based modeling in the engineering of UAV swarms.},
booktitle = {Proceedings of the Agent-Directed Simulation Symposium},
articleno = {7},
numpages = {8},
keywords = {command and control, swarming, UAVs, NetLogo, emergent behavior},
location = {San Diego, California},
series = {ADSS 13}
}

@inproceedings{10.1145/3338533.3366561,
author = {Yu, Hongyang and Li, Guorong and Zhang, Weigang and Yao, Hongxun and Huang, Qingming},
title = {Self-Balance Motion and Appearance Model for Multi-Object Tracking in UAV},
year = {2019},
isbn = {9781450368414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3338533.3366561},
doi = {10.1145/3338533.3366561},
abstract = {Under the tracking-by-detection framework, multi-object tracking methods try to connect object detections with target trajectories by reasonable policy. Most methods represent objects by the appearance and motion. The inference of the association is mostly judged by a fusion of appearance similarity and motion consistency. However, the fusion ratio between appearance and motion are often determined by subjective setting. In this paper, we propose a novel self-balance method fusing appearance similarity and motion consistency. Extensive experimental results on public benchmarks demonstrate the effectiveness of the proposed method with comparisons to several state-of-the-art trackers.},
booktitle = {Proceedings of the ACM Multimedia Asia},
articleno = {12},
numpages = {6},
keywords = {Neural networks, Multi-object tracking, UAV},
location = {Beijing, China},
series = {MMAsia '19}
}

@inproceedings{10.1145/3281548.3281556,
author = {Xu, Yingxiao and Pan, Long and Du, Chun and Li, Jun and Jing, Ning and Wu, Jiangjiang},
title = {Vision-Based UAVs Aerial Image Localization: A Survey},
year = {2018},
isbn = {9781450360364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3281548.3281556},
doi = {10.1145/3281548.3281556},
abstract = {Unmanned aerial vehicles (UAVs) have been increasingly used in earth observation, public safety, military and civilian applications due to its portability, high mobility and flexibility. In some GPS-denied environments, accurate drone position cannot be obtained due to occlusion, multi-path interference and other factors. While understanding and localization the content of the images is vital for earth observation, map revision, multi-source image fusion, disaster relief, smart city and other applications. The progress of computer vision and convolutional neural networks(CNNs) in image processing provide a promising solution to locate UAVs aerial image and mapping to the large-scale reference image. Firstly, key localization techniques based on image retrieval-----image description, image matching and position mapping are summarized considering the characteristics of UAVs aerial images. And then, image localization based on extracting deep semantic features and image localization based on classification method by subdividing areas are recommended. Throughout this paper, we will have an insight into the prospect of the UAVs image localization and the challenges to be faced.},
booktitle = {Proceedings of the 2nd ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {9–18},
numpages = {10},
keywords = {Semantic, Image Description, Vision-based Image Localization, UAVs Aerial Image, Deep Learning},
location = {Seattle, WA, USA},
series = {GeoAI'18}
}

@inproceedings{10.1145/3297156.3297175,
author = {Chen, Jie and Cheng, Sheng and Xu, Meng},
title = {An Overview and Practical Application of Biological Intelligence Algorithm Used in Intelligence Control},
year = {2018},
isbn = {9781450366069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3297156.3297175},
doi = {10.1145/3297156.3297175},
abstract = {Because of the disadvantages of the classical control methods, such as its fixed parameters, so the control effect of the classical control methods is greatly limited, and the Biological Intelligence Algorithm has provided a new way to break the bottleneck of classical control methods because of its adaptive and learning mechanism. With the improvement of the theory of reinforcement learning and deep learning, these theories have greatly improved the performance of the Biological Intelligence Algorithm. This paper summarizes seven kinds of intelligent algorithms which is used in intelligence control commonly, and emphatically analyzes the application examples of the combination of classical automatic control method and intelligent algorithms, especially reinforcement learning. The development status and future development trend of intelligent control based on reinforcement learning, deep learning and Brain-inspired Intelligence Technology in recent years are discussed for the first time in this paper. The purpose of this paper is to emphasize a new idea of combining intelligent algorithm with classical control method, and provide new ideas and practical examples for the research of intelligent control.},
booktitle = {Proceedings of the 2018 2nd International Conference on Computer Science and Artificial Intelligence},
pages = {200–206},
numpages = {7},
keywords = {Brain-inspired Intelligence, Intelligent control, Biological intelligence, Reinforcement learning, Automatic control},
location = {Shenzhen, China},
series = {CSAI '18}
}

@inproceedings{10.1145/3468891.3468916,
author = {Mo, Xiaoyu and Peters, Doney and Lei, Chengwei},
title = {Low Cost Autonomous UAV Swarm Application in Wildfire Surveillance and Suppression},
year = {2021},
isbn = {9781450389402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3468891.3468916},
doi = {10.1145/3468891.3468916},
booktitle = {2021 6th International Conference on Machine Learning Technologies},
pages = {164–169},
numpages = {6},
keywords = {UAV, wildfire, Particle Swarm Optimization},
location = {Jeju Island, Republic of Korea},
series = {ICMLT 2021}
}

@inproceedings{10.1145/3373509.3373517,
author = {Jiang, Xiangwei and Zhao, Boxin and Zhang, Boyang and Chen, Xiaolong and Wang, Xiongwei},
title = {Research on Multi-UAVs Formation Flight Control Based on Fuzzy PID},
year = {2019},
isbn = {9781450376570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3373509.3373517},
doi = {10.1145/3373509.3373517},
abstract = {Small Unmanned Aerial Vehicle (UAV for short) has advantages of low cost, light and flexible. But single UAV also has disadvantages of lack of sight distance, sole access to information, limited airborne computing resources, etc. In order to overcome those weaknesses, UAV is undergoing a change for formation cluster. Moreover, UAV formation control is a key technology to ensure effective cooperative formation flight of UAV. [1] Therefore the paper studied the fuzzy PID controller for formation control of mini quad-rotor UAV through MATLAB simulation and contrast with the typical PID controller.},
booktitle = {Proceedings of the 2019 8th International Conference on Computing and Pattern Recognition},
pages = {476–481},
numpages = {6},
keywords = {fuzzy PID, control, UAVs formation flight},
location = {Beijing, China},
series = {ICCPR '19}
}

@inproceedings{10.1145/3462648.3462658,
author = {Xing, Ruibo and Zhang, Wei and Shu, Leizheng and Zhang, Bihui},
title = {An Autonomous Moving Target Tracking System for Rotor UAV},
year = {2021},
isbn = {9781450389471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3462648.3462658},
doi = {10.1145/3462648.3462658},
abstract = {This paper presents a set of overall system design for tracking moving target with rotor Unmanned Aerial Vehicle (UAV). The tracking scene of the system is the autonomous tracking of the vehicle target in the environment with obstacles. Aiming at the autonomous ability of moving target tracking, this paper adopted the Single Shot MultiBox Detector (SSD) target detection method to detect the moving target of interest, which was used as a template for SiamRPN++ frame by frame tracking. After the target tracking has been completed in each frame, the center coordinates of the target selection box, which are converted to the UAV coordinates system through coordinates conversion, are used as the target points of path planning. Combined with the real-time visual inertial simultaneous localization and mapping (SLAM) system, VINS-MONO, to estimate the drone's pose and perceive the surrounding environment. Fast-planner can effectively plan the feasible path of moving target tracking under the obstacle environment and control the UAV tracking target. The design work of this autonomous moving target tracking system for rotor UAV was presented, and the key functional modules were closed-looply tested and verified within the gazebo software. The method used in this paper can detect the vehicle again in the case of target occlusion loss. A system of tracking moving vehicle in obstructed environment, which provides a set of basic research scheme for subsequent UAV tracking research, has been built.},
booktitle = {2021 International Conference on Robotics and Control Engineering},
pages = {48–53},
numpages = {6},
location = {Tokyo, Japan},
series = {RobCE 2021}
}

@inproceedings{10.1145/3274694.3274724,
author = {Etigowni, Sriharsha and Hossain-McKenzie, Shamina and Kazerooni, Maryam and Davis, Katherine and Zonouz, Saman},
title = {Crystal (Ball): I Look at Physics and Predict Control Flow! Just-Ahead-Of-Time Controller Recovery},
year = {2018},
isbn = {9781450365697},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3274694.3274724},
doi = {10.1145/3274694.3274724},
abstract = {Recent major attacks against unmanned aerial vehicles (UAV) and their controller software necessitate domain-specific cyber-physical security protection. Existing offline formal methods for (untrusted) controller code verification usually face state-explosion. On the other hand, runtime monitors for cyber-physical UAVs often lead to too-late notifications about unsafe states that makes timely safe operation recovery impossible.We present Crystal, a just-ahead-of-time control flow predictor and proactive recovery for UAVs. Crystal monitors the execution state of the flight controller and predicts the future control flows ahead of time-based on the UAV's physical dynamics. Crystal deploys the operator's countermeasures proactively in case of an upcoming unsafe state. Crystal's just-ahead-of-time model checking explores the future control flows in parallel ahead of the UAV's actual operation by some time margin. The introduced time margin enables Crystal to accommodate operator's feedback latency by the time the actual execution reaches to the identified unsafe state. Crystal periodically queries the controller's execution state. It emulates the UAV physical dynamical model and predicts future sensor measurements (controller inputs) and upcoming feasible controller's execution paths. This drives Crystal's model-checking exploration away from unreachable future states. Crystal's selective model checking saves computational time to stay ahead of execution by concentrating on relevant upcoming control flows only. This eliminates the state-explosion problem in traditional offline formal methods. We evaluated a multi-threaded prototype of Crystal between the control station server and the UAV. Crystal was able to predict upcoming hazardous states caused by the third-party controller program and proactively restored the safe states successfully with minimal overhead.},
booktitle = {Proceedings of the 34th Annual Computer Security Applications Conference},
pages = {553–565},
numpages = {13},
keywords = {Unmanned Aerial Vehicle, Just-Ahead-of-Time verification},
location = {San Juan, PR, USA},
series = {ACSAC '18}
}

@inbook{10.1145/3387168.3387179,
author = {Han, Seongkyun and Kwon, Juwon and Kwon, Soonchul},
title = {Real-Time Small Object Detection Model in the Bird-View UAV Imagery},
year = {2019},
isbn = {9781450376259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3387168.3387179},
abstract = {Object detection is one of the most important parts of UAV applications. UAV imagery has object distortion and small-sized objects peculiarities. In this paper, we propose a D-RFB module which can enhance the expressive power of the feature map, and D-RFBNet300 attached D-RFB module so that detect small objects in the UAV imagery more accurately. And we propose the UAV-cars dataset including peculiarities of UAV imagery. Our D-RFBNet300 trained on MS COCO achieved 21% mAP with 45 FPS speed, which is the highest score among the other SSD type object detectors. In addition, our D-RFBNet300 trained on UAV-cars dataset achieved 99.24% AP at 10m altitude and highest AP at every test set altitude from 15m to 30m with 57FPS speed.},
booktitle = {Proceedings of the 3rd International Conference on Vision, Image and Signal Processing},
articleno = {47},
numpages = {7}
}

@inproceedings{10.1145/3390557.3394300,
author = {Zhu, Sirui and Peng, Yuexing and Alexandropoulos, Geoge C.},
title = {RCS-Based Flight Target Recognition Using Deep Networks with Convolutional and Bidirectional GRU Layer},
year = {2020},
isbn = {9781450376587},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3390557.3394300},
doi = {10.1145/3390557.3394300},
abstract = {Flight target recognition (FTR) has always been a hot research topic in the field of pattern recognition and machine vision. It is of great significance for civil aviation safety, hazard early warning, and many other fields. Radar Cross Section (RCS) can fully reflect the electromagnetic scattering profile, motion and polarization characteristics of the flight target, and then has been widely used for FTR. Most FTR methods are based on object-specific feature parameters distilling from RCS by statistical techniques, which demand high-quality and long-term signal samples to compute higher-order cumulants. These statistical feature-based methods degrade severely in the case of low-quality data in the form of low signal-to-inference-and-noise ratio and insufficient samples, which may be the normal case in practice. In this paper, a deep learning-based FTR model is proposed, which consists of spatial convolutional layers and bidirectional gated recurrent unit (Bi-GRU) layers to exploit the inner temporal patterns of the RCS sequence. Experiment results verify that the proposed model outperforms existing methods including statistical approaches, machine learning model and deep neural network model.},
booktitle = {Proceedings of the 2020 the 4th International Conference on Innovation in Artificial Intelligence},
pages = {137–141},
numpages = {5},
keywords = {Radar Cross Section, GRU, Flight Target Recognition, Deep Learning, CNN},
location = {Xiamen, China},
series = {ICIAI 2020}
}

@inproceedings{10.1145/3377283.3377284,
author = {Kapania, Shivani and Saini, Dharmender and Goyal, Sachin and Thakur, Narina and Jain, Rachna and Nagrath, Preeti},
title = {Multi Object Tracking with UAVs Using Deep SORT and YOLOv3 RetinaNet Detection Framework},
year = {2020},
isbn = {9781450376662},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3377283.3377284},
doi = {10.1145/3377283.3377284},
abstract = {Over the years, object tracking and detection has emerged as one of the most important aspects of UAV applications such as surveillance, reconnaissance, etc. In our paper, we present a tracking-by-detection approach for real-time Multiple Object Tracking (MOT) of footage from a drone-mounted camera. Tracking-by-detection is the leading paradigm considering its computational effectiveness and improved detection algorithms. Our algorithm builds on the baseline Deep SORT algorithm implemented for MOT benchmarks. However, to circumvent the challenges posed by videos captured from a significant height we use a combination of YOLOv3 and RetinaNet for generating detections in each frame. The results of our experiment on the VisDrone 2018 dataset exhibit competitive performance in comparison to the existing trackers.},
booktitle = {Proceedings of the 1st ACM Workshop on Autonomous and Intelligent Mobile Systems},
articleno = {1},
numpages = {6},
keywords = {object detection, neural networks, Unmanned aerial vehicles, object tracking},
location = {Bangalore, India},
series = {AIMS '20}
}

@inproceedings{10.1145/3425577.3425593,
author = {Wattanacheep, Bhattarabhorn and Chitsobhuk, Orachat},
title = {Camera Pose Estimation Using CNN},
year = {2020},
isbn = {9781450388023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3425577.3425593},
doi = {10.1145/3425577.3425593},
abstract = {Estimating camera pose is a significant process, which assures the success of the 3D modeling performance. This research presents a camera pose estimation using convolutional neural network (CNN) to transfer learning from pre-trained deep learning VGG19 model in order to extract features from a single image using several datasets captured in indoor and outdoor environments with diverse perspectives and photographic styles. Due to the large dimensions of the extracted features, Latent Semantic Analysis (LSA) are introduced prior to the CNN input. Then, the CNN is trained to predict the camera views and translations. The prediction performance is measured in terms of average mean square errors and compared to the reference techniques. As a result, the regression estimation of the proposed CNN model outperforms the others with average 0.24 degrees rotation error and 0.26 m. translation errors.},
booktitle = {2020 the 3rd International Conference on Control and Computer Vision},
pages = {84–88},
numpages = {5},
keywords = {3D Reconstruction, Image Processing, Robotics, Deep Learning},
location = {Macau, China},
series = {ICCCV'20}
}

@inbook{10.1145/3394171.3413661,
author = {Li, Xinke and Li, Chongshou and Tong, Zekun and Lim, Andrew and Yuan, Junsong and Wu, Yuwei and Tang, Jing and Huang, Raymond},
title = {Campus3D: A Photogrammetry Point Cloud Benchmark for Hierarchical Understanding of Outdoor Scene},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3394171.3413661},
abstract = {Learning on 3D scene-based point cloud has received extensive attention as its promising application in many fields, and well-annotated and multisource datasets can catalyze the development of those data-driven approaches. To facilitate the research of this area, we present a richly-annotated 3D point cloud dataset for multiple outdoor scene understanding tasks and also an effective learning framework for its hierarchical segmentation task. The dataset was generated via the photogrammetric processing on unmanned aerial vehicle (UAV) images of the National University of Singapore (NUS) campus, and has been point-wisely annotated with both hierarchical and instance-based labels. Based on it, we formulate a hierarchical learning problem for 3D point cloud segmentation and propose a measurement evaluating consistency across various hierarchies. To solve this problem, a two-stage method including multi-task (MT) learning and hierarchical ensemble (HE) with consistency consideration is proposed. Experimental results demonstrate the superiority of the proposed method and potential advantages of our hierarchical annotations. In addition, we benchmark results of semantic and instance segmentation, which is accessible online at https://3d.dataset.site with the dataset and all source codes.},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {238–246},
numpages = {9}
}

@inproceedings{10.1145/3436369.3437445,
author = {Wang, Xiaohan and Liu, Yuehu},
title = {Pedestrian Motion Prediction with Improved ADNet Model},
year = {2020},
isbn = {9781450387835},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3436369.3437445},
doi = {10.1145/3436369.3437445},
abstract = {Motion prediction obtains pedestrian moving direction, which is fundamental control parameters for robot tail following. In this paper, a tracker named ADNet-PMP is proposed for pedestrian motion prediction. The ADNet model is improved with interlace sampling and optimized with model- update mechanism. The network is pre-trained with deep reinforcement learning and supervised learning to track the pedestrian by moving the bounding box sequentially. The movements of bounding box are transformed to actual motion behaviors with a prediction strategy. According to the results on OTB-100 datasets, ADNet-PMP achieves 1.6 times speed enhancement while keeps competitive accuracy against original ADNet. Experiment on pedestrian motion videos validates the effectiveness of motion prediction.},
booktitle = {Proceedings of the 2020 9th International Conference on Computing and Pattern Recognition},
pages = {238–243},
numpages = {6},
keywords = {Pedestrian motion prediction, visual object tracking, deep reinforcement learning},
location = {Xiamen, China},
series = {ICCPR 2020}
}

@inproceedings{10.1145/3444950.3444951,
author = {Corradi, Federico and Adriaans, Guido and Stuijk, Sander},
title = {Gyro: A Digital Spiking Neural Network Architecture for Multi-Sensory Data Analytics},
year = {2021},
isbn = {9781450389525},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3444950.3444951},
doi = {10.1145/3444950.3444951},
abstract = { Unmanned Aerial Vehicles (UAVs) that interact with the physical world in real-time make use of a multitude of sensors and often execute deep neural network workloads for perceiving the state of the environment. To increase UAV’s operations, it is required to execute these workloads in the most power-efficient manner. Spiking Neural Networks (SNNs) have been proposed as an alternative solution for the execution of deep neural networks in an energy-efficient way. We introduce Gyro, a digital event-driven architecture capable of executing spiking neural networks. The architecture is tailored towards sensory fusion applications and it is optimized for Field-Programmable Gate Arrays (FPGAs). In hardware, we demonstrate the performance of a sensory fusion task using a public dataset of bi-temporal optical-radar data for pixel-wise crop classification. We achieve an accuracy of 99,7%, a peak throughput of 31,82 Giga Synaptic Operations per Second (GSOPS) while consuming 50 pico Joule / Synaptic Operation (pJ/SO). },
booktitle = {Proceedings of the 2021 Drone Systems Engineering and Rapid Simulation and Performance Evaluation: Methods and Tools Proceedings},
pages = {9–15},
numpages = {7},
keywords = {fpga, embedded hardware, remote sensing, spiking neural networks, optical-radar sensory fusion},
location = {Budapest, Hungary},
series = {DroneSE and RAPIDO '21}
}

@inproceedings{10.1145/3441369.3441382,
author = {Chen, Xiaomin and Wu, Xiaoming and Wang, Shuai},
title = {Research on Classification of UAV Optical Image Tree Species Based on Res2Net},
year = {2020},
isbn = {9781450389044},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3441369.3441382},
doi = {10.1145/3441369.3441382},
abstract = {The internal features of remote sensing images of plant communities are complex and the boundaries between classes are blurred. The traditional image processing methods based on pixel spectral information cannot make full use of the image feature information, making the extraction effect poor. Therefore, this paper proposes a deep convolutional neural network. Convolutional neural network (CNN) high-resolution remote sensing image plant community automatic classification method. Segment drone images to obtain regular images, and then use the CNN-based Res2Net model to abstract and learn the features of the image to automatically obtain deeper abstractions and more representative image deep features, realize the extraction of the distribution area of the plant community, and output the automatic classification result of the plant community in the form of the original image and the result image superimposed on each other. The number of samples with different gradients are used as training samples, and the method proposed in this paper is used to analyze the influence of the number of training samples with different gradients on the results of automatic classification. Experimental results show that the number of training samples has a significant impact on classification accuracy, the modeling accuracy of the ResNet50 model and the Res2Net model are increased from 82% and 83% to 90% and 92%, compared with the traditional supervised classification method, the deep convolutional network significantly improves the classification accuracy. The classification results show that when the number of training samples is not less than 200, the CNN-based Res2Net model shows the best classification results.},
booktitle = {2020 3rd International Conference on Digital Medicine and Image Processing},
pages = {74–80},
numpages = {7},
keywords = {Automatic classification, CNN deep convolutional network, Res2Net model},
location = {Kyoto, Japan},
series = {DMIP '20}
}

@inproceedings{10.1145/3213526.3213533,
author = {Hrabia, Christopher-Eyk and Hessler, Axel and Xu, Yuan and Brehmer, Jan and Albayrak, Sahin},
title = {EffFeu Project: Efficient Operation of Unmanned Aerial Vehicles for Industrial Fire Fighters},
year = {2018},
isbn = {9781450358392},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3213526.3213533},
doi = {10.1145/3213526.3213533},
abstract = {The number of unmanned aerial system (UAS) applications for supporting rescue forces is growing in recent years. The analysis of sensed information and control of the UAV creates an enormous psychological and emotional load for the involved humans especially in critical and hectic situations. To enable a mission-guided application of drones and reduce the load of manual control and analysis, the research project EffFeu (Efficient Operation of Unmanned Aerial Vehicle for Industrial Fire Fighters) aims for a holistic integration of UAS in the daily work of industrial fire fighters in particular. This work presents the current stage of the project including the overall system architecture and first results of the project research topics: high-level task control of UAV, localisation and navigation in the transition of indoor and outdoor environments, and objects and situation recognition.},
booktitle = {Proceedings of the 4th ACM Workshop on Micro Aerial Vehicle Networks, Systems, and Applications},
pages = {33–38},
numpages = {6},
keywords = {GNSS-denied localisation, decision-making, decisional autonomy, deep learning, object recognition, planning},
location = {Munich, Germany},
series = {DroNet'18}
}

@article{10.1145/3409262,
author = {Morbidoni, Christian and Pierdicca, Roberto and Paolanti, Marina and Quattrini, Ramona and Mammoli, Raissa},
title = {Learning from Synthetic Point Cloud Data for Historical Buildings Semantic Segmentation},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {1556-4673},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3409262},
doi = {10.1145/3409262},
abstract = {Historical heritage is demanding robust pipelines for obtaining Heritage Building Information Modeling models that are fully interoperable and rich in their informative content. The definition of efficient Scan-to-BIM workflows represent a very important step toward a more efficient management of the historical real estate, as creating structured three-dimensional (3D) models from point clouds is complex and time-consuming. In this scenario, semantic segmentation of 3D Point Clouds is gaining more and more attention, since it might help to automatically recognize historical architectural elements. The way paved by recent Deep Learning approaches proved to provide reliable and affordable degrees of automation in other contexts, as road scenes understanding. However, semantic segmentation is particularly challenging in historical and classical architecture, due to the shapes complexity and the limited repeatability of elements across different buildings, which makes it difficult to define common patterns within the same class of elements. Furthermore, as Deep Learning models requires a considerably large amount of annotated data to be trained and tuned to properly handle unseen scenes, the lack of (big) publicly available annotated point clouds in the historical building domain is a huge problem, which in fact blocks the research in this direction. However, creating a critical mass of annotated point clouds by manual annotation is very time-consuming and impractical. To tackle this issue, in this work we explore the idea of leveraging synthetic point cloud data to train Deep Learning models to perform semantic segmentation of point clouds obtained via Terrestrial Laser Scanning. The aim is to provide a first assessment of the use of synthetic data to drive Deep Learning--based semantic segmentation in the context of historical buildings. To achieve this purpose, we present an improved version of the Dynamic Graph CNN (DGCNN) named RadDGCNN. The main improvement consists on exploiting the radius distance. In our experiments, we evaluate the trained models on synthetic dataset (publicly available) about two different historical buildings: the Ducal Palace in Urbino, Italy, and Palazzo Ferretti in Ancona, Italy. RadDGCNN yields good results, demonstrating improved segmentation performances on the TLS real datasets.},
journal = {J. Comput. Cult. Herit.},
month = {dec},
articleno = {34},
numpages = {16},
keywords = {scan-to-BIM, radius distance, historical building, point cloud semantic segmentation, dynamic graph convolutional neural network, Deep learning, cultural heritage, synthetic point cloud}
}

@inproceedings{10.1145/3356471.3365235,
author = {Peng, Bo and Liu, Xinyi and Meng, Zonglin and Huang, Qunying},
title = {Urban Flood Mapping with Residual Patch Similarity Learning},
year = {2019},
isbn = {9781450369572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3356471.3365235},
doi = {10.1145/3356471.3365235},
abstract = {Urban flood mapping is essential for disaster rescue and relief missions, reconstruction efforts, and financial loss evaluation. Much progress has been made to map the extent of flooding with multi-source remote sensing imagery and pattern recognition algorithms. However, urban flood mapping at high spatial resolution remains a major challenge due to three main reasons: (1) the very high resolution (VHR) optical remote sensing imagery often has heterogeneous background involving various ground objects (e.g., vehicles, buildings, roads, and trees), making traditional classification algorithms fail to capture the underlying spatial correlation between neighboring pixels within the flood hazard area; (2) traditional flood mapping methods with handcrafted features as input cannot fully leverage massive available data, which requires robust and scalable algorithms; and (3) due to inconsistent weather conditions at different time of data acquisition, pixels of the same objects in VHR optical imagery could have very different pixel values, leading to the poor generalization capability of classical flood mapping methods. To address this challenge, this paper proposed a residual patch similarity convolutional neural network (ResPSNet) to map urban flood hazard zones using bi-temporal high resolution (3m) pre- and post-flooding multispectral surface reflectance satellite imagery. Besides, remote sensing specific data augmentation was also developed to remove the impact of varying illuminations due to different data acquisition conditions, which in turn further improves the performance of the proposed model. Experiments using the high resolution imagery before and after the 2017 Hurricane Harvey flood in Houston, Texas, showed that the developed ResPSNet model, along with associated remote sensing specific data augmentation method, can robustly produce flood maps over urban areas with high precision (0.9002), recall (0.9302), F1 score (0.9128), and overall accuracy (0.9497). The research sheds light on multitemporal image fusion for high precision image change detection, which in turn can be used for monitoring natural hazards.},
booktitle = {Proceedings of the 3rd ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {40–47},
numpages = {8},
keywords = {deep learning, residual learning, flood extent estimation, patch similarity, Flood mapping},
location = {Chicago, IL, USA},
series = {GeoAI 2019}
}

@inproceedings{10.1145/3468691.3468693,
author = {An, Zhenpeng and Zhang, Chunhua and Zhang, Di and Xing, Ao and Jiang, Shuai},
title = {Research on Information Transmission System of Fire Fighting UAV},
year = {2021},
isbn = {9781450389693},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3468691.3468693},
doi = {10.1145/3468691.3468693},
abstract = {Fire and rescue task need to master a variety of UAV information. Therefore, the transmission and aggregation of information for firefighting UAV is an urgent need. This paper develops a fire UAV integrated information management system, unify the transmission and interaction protocol between the UAV and the system, converge video and audio, status information, geographical location and other information of UAV equipment, realize the integrated information management of fire fighting UAV, provide multi-dimensional information and training analysis of UAV. The UAV audio information aggregation and remote transmission device module is developed to support two-way information interaction with the control end or airborne equipment.},
booktitle = {2021 2nd International Conference on Computing, Networks and Internet of Things},
articleno = {2},
numpages = {5},
keywords = {Information transmission, UAV},
location = {Beijing, China},
series = {CNIOT '21}
}

@inproceedings{10.1145/3416012.3424622,
author = {Ruby, Rukhsana and Wu, Kaishun and Pham, Quoc-Viet and ElHalawany, Basem M.},
title = {Aiding a Disaster Spot via an UAV-Based Mobile AF Relay: Joint Trajectory and Power Optimization},
year = {2020},
isbn = {9781450381192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3416012.3424622},
doi = {10.1145/3416012.3424622},
abstract = {Followed by the destruction of existing infrastructure or the emergence of the necessity for a new infrastructure, disaster events (e.g., earthquakes and pandemic) may require inspection of certain area and passing information to a dedicated help unit. Unmanned Aerial Vehicle (UAV)-aided mobile relaying technology is one of the effective means of provisioning service in such situations. In this paper, as the part of the rescuing operation in a certain disaster spot, we consider a mobile relaying technique, where an UAV acts as a relay node to ferry data between two disconnected floating or fixed nodes. For the sake of simplicity and low cost, amplify-and-forward relaying capability is adopted for the UAV. We consider the maximization of end-to-end throughput of such a system by optimizing the source/UAV power allocation as well as the trajectory of the UAV while considering practical mobility constraints (on the speed and initial/final locations of the UAV) as well as signal causality constraints. The formulated optimization problem is non-convex, and hence intractable to solve. Therefore, similar to the existing solution approach, we solve the problem via an iteration-based solution strategy, however we solve the source/UAV power allocation and the UAV trajectory design problems per iteration in a different manner. For the source/UAV power allocation problem, we provide heuristic solutions while considering both the availability and absence of a buffer at the UAV node. On the other hand, for the given power assignment, we adopt the geometric programming (GP)-based approach upon the transformation of variables and constraints. Furthermore, under the free initial and final UAV locations, jointly optimal power allocation and UAV trajectory are derived. Through extensive simulation, we verify the effectiveness of the proposed scheme while comparing with one existing work.},
booktitle = {Proceedings of the 18th ACM Symposium on Mobility Management and Wireless Access},
pages = {105–113},
numpages = {9},
keywords = {amplify-and-forward (AF) mobile relay, power optimization, unmanned aerial vehicles (UAVs), trajectory design},
location = {Alicante, Spain},
series = {MobiWac '20}
}

@inproceedings{10.1145/3456415.3456424,
author = {Zhang, Bingbing and Qian, Xiaojun and Yang, Rui and Xu, Zhen},
title = {Water Surface Target Detection Based on Improved YOLOv3 in UAV Images},
year = {2021},
isbn = {9781450389174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3456415.3456424},
doi = {10.1145/3456415.3456424},
abstract = {In order to better manage and protect rivers and lakes, the most important requirement is to find the objects on the surface of rivers and lakes in time. Generally, image segmentation and target detection are used to detect water surface targets. The former is sensitive to the selection of target features, with poor generalization ability and slow detection speed. The latter has not yet been applied to surface target detection in UAV images. In view of this situation, this paper proposes a target detection model based on YOLOv3, which is used to detect surface targets in UAV images. In order to verify the performance of the model, the images collected in this paper include five types of surface targets. These images are then enhanced by rotation transform, brightness transform and mirror transform, and the enhanced images are used to generate data sets. In the YOLOv3 model, we use the inception module for multi-scale depth features to process the deep features of the network. The module can activate the multi-scale sensing field of the deep features, so as to fully utilize the deep features and improve the detection accuracy of small and medium targets in the UAV image. In addition, we optimize the loss function to train the network better. The experimental results show that the mAP of the proposed Yolov3-inception is 81%, the detection speed is 23 frames per second, and the overall performance is better than YOLOv3, Faster RCNN and SSD. Therefore, this method is suitable for surface target detection in UAV images.},
booktitle = {2021 9th International Conference on Communications and Broadband Networking},
pages = {47–53},
numpages = {7},
keywords = {UAV images, YOLOv3, deep learning, image enhancement, target detection},
location = {Shanghai, China},
series = {ICCBN 2021}
}

@inproceedings{10.1145/3473465.3473484,
author = {Xie, Wentao},
title = {Research on UAV Anti-Multi-Type Interferences Strategy Based on Improved Q-Learning},
year = {2021},
isbn = {9781450389884},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3473465.3473484},
doi = {10.1145/3473465.3473484},
abstract = {UAVs have been widely used in military and civilian applications, and they play a huge role in many aspects. However, due to the open nature of the UAV communication link, it is susceptible to malicious or unintentional interference. Besides, the interference that UAVs are facing has developed from a single type of interference to multi-type interference. The traditional anti-interference method is designed to deal with single-dimensional interference and cannot meet the requirements of anti-Multi-type interference. The purpose of the paper is to improve the communication capabilities of UAVs by programming frequency-power (Change the transmission frequency and transmission power of the UAV)in Multi-type interference environment. Compared with the existing work, the UAVs in the system can exploit degree-of-freedom in frequency, power to optimize the communication quality in the receiving area and reduce energy costs. The paper propose a Anti-multi-type interference strategy based on improved and eligibility traces Q-learning algorithm, which is based on multi-parameters, and the simulation results show the effectiveness of the algorithm.},
booktitle = {2021 3rd International Conference on Information Technology and Computer Communications},
pages = {109–114},
numpages = {6},
location = {Guangzhou, China},
series = {ITCC 2021}
}

@inproceedings{10.1145/3386415.3386972,
author = {Wang, Xuejun and Zhou, Zhiguo and Li, Yun},
title = {Multi Target Detection of UAV Video Based on Deep Convolution Neural Network},
year = {2019},
isbn = {9781450372930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3386415.3386972},
doi = {10.1145/3386415.3386972},
abstract = {Aiming at the existing multi-target detection algorithm in UAV shooting dynamic scene effect is not good, Color similarity problem, Athletes block each other. In this paper, a region compensation method based on fixed background is to propos detect multiple players in soccer video captured by UAV. Through Effective marking of targets in aerial images and the framework construction of deep convolution network. The difference processing of two adjacent frames, the changing and unchanging regions in the image are distinguished, and different regions are given different update rates and added to the background frame, in order to achieve faster background reconstruction. Experimental results in different video sequences, the detection accuracy of the algorithm is more than 90% on average. The algorithm processing has real-time, accuracy and stability of target detection.},
booktitle = {Proceedings of the 2nd International Conference on Information Technologies and Electrical Engineering},
articleno = {25},
numpages = {5},
keywords = {deep convolution neural network algorithm, multi-target detection, UAV video},
location = {Zhuzhou, Hunan, China},
series = {ICITEE-2019}
}

@inproceedings{10.1145/3414045.3415935,
author = {Lim, Wei Yang Bryan and Xiong, Zehui and Kang, Jiawen and Niyato, Dusit and Zhang, Yang and Leung, Cyril and Miao, Chunyan},
title = {An Incentive Scheme for Federated Learning in the Sky},
year = {2020},
isbn = {9781450381055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3414045.3415935},
doi = {10.1145/3414045.3415935},
abstract = {The enhanced capabilities of Unmanned Aerial Vehicles have promoted the rapid growth of the Drones-as-a-Service (DaaS) market. To enable privacy-preserving collaborative machine learning among independent DaaS providers, we propose a Federated Learning (FL) based approach. There exists a tradeoff between Service Latency (SL), i.e., the time taken for the training request to be completed, and Age of Information (AoI), i.e., the time elapsed between data aggregation to completion of the FL based training. Given that different training tasks may have varying AoI requirements, we propose a contract-theoretic task-aware incentive scheme that can be calibrated based on the weighted preferences of the model owner. Performance evaluation validates the incentive compatibility and flexibility of our contract design amid information asymmetry.},
booktitle = {Proceedings of the 2nd ACM MobiCom Workshop on Drone Assisted Wireless Communications for 5G and Beyond},
pages = {55–60},
numpages = {6},
keywords = {incentive mechanism, federated learning, unmanned aerial vehicle, mobile crowdsensing},
location = {London, United Kingdom},
series = {DroneCom '20}
}

@inproceedings{10.1145/3404555.3404648,
author = {Wu, Qiang and Zhao, JiaXiang and Zheng, Xin},
title = {Self-Matching Moving Target Detection Algorithm Based On Gaussian Mixture Model And CSIFT},
year = {2020},
isbn = {9781450377089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3404555.3404648},
doi = {10.1145/3404555.3404648},
abstract = {With the development of unmanned aerial vehicle (UAV) technology, more and more unmanned aerial vehicles have entered various fields, including the aspect of moving target detection. Due to the characteristics of the drone, the captured video does not have a fixed background, which makes the traditional moving target detection algorithm unusable. Herein, this paper proposes a self-matching detection algorithm based on Gaussian mixture model and CSIFT. This algorithm is applied to unmanned On board, under the background of moving targets, the target can be identified when there is relative movement between the target and the background.},
booktitle = {Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence},
pages = {418–423},
numpages = {6},
keywords = {Gaussian mixture model, CSIFT features, moving target detection, UAV},
location = {Tianjin, China},
series = {ICCAI '20}
}

@inproceedings{10.1145/3313151.3313163,
author = {Li, Yilan and Eslamiat, Hossein and Wang, Ningshan and Zhao, Ziyi and Sanyal, Amit K. and Qiu, Qinru},
title = {Autonomous Waypoints Planning and Trajectory Generation for Multi-Rotor UAVs},
year = {2019},
isbn = {9781450366991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3313151.3313163},
doi = {10.1145/3313151.3313163},
abstract = {Autonomous trajectory generation in a complex environment is a challenging task for multi-rotor unmanned aerial vehicles (UAVs), which have high maneuverability in three-dimensional motion. Safe and effective operations for these UAVs demand obstacle avoidance strategies and advanced trajectory planning and control schemes for stability and energy efficiency. To solve those problems in one framework analytically is extremely challenging when the UAV needs to fly large distance in a complex environment. To address this challenge, a two-level optimization strategy is adopted. At the higher-level, a sequence of waypoints is selected that lead the UAV from its current position to the destination. At the lower-level, an optimal trajectory is generated between each pair of adjacent waypoints analytically. While the goal of trajectory generation is to maintain the stability of the UAV, the goal of the waypoints planning is to select waypoints with the lowest control thrust consumption throughout the entire trip while avoiding collisions with obstacles. The entire framework is implemented using deep reinforcement learning, which learns the highly complicated and non-linear interaction between those two levels, and the impact from the environment. A progressive learning strategy is investigated that not only reduces convergence time but also improves result quality. We further investigate and provide results regarding the tuning of gains in the optimal trajectory scheme using genetic algorithm. The experimental results demonstrate that our proposed approach is able to generate a list of obstacle-free waypoints with minimum control energy and develop an optimal trajectory with optimized platform velocity, acceleration, jerk and control thrust.},
booktitle = {Proceedings of the Workshop on Design Automation for CPS and IoT},
pages = {31–40},
numpages = {10},
keywords = {waypoints planning, multi-rotor UAV, optimal trajectory generation, deep reinforcement learning},
location = {Montreal, Quebec, Canada},
series = {DESTION '19}
}

@inproceedings{10.5555/2499592.2499600,
author = {McCune, R. Ryan and Madey, Gregory R.},
title = {Agent-Based Simulation of Cooperative Hunting with UAVs},
year = {2013},
isbn = {9781627480291},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {Swarm intelligent systems are simple but robust, capable of solving complex problems that no single agent could attempt. While technological advancements have driven development of multi-agent systems across disciplines, emergent behavior inherent to swarms is a desirable yet difficult property to exploit. Solutions utilizing swarm behavior have been proposed for the Cooperative Cleaning Problem, which is applicable to UAVs cooperatively searching for evasive targets. This work proposes a new agent behavior capable of partitioning a search area, and when combined with previous swarm solutions, forms an optimization problem of how to best assign swarms to a complex topology. Agent-based simulations are developed to test swarm solutions.},
booktitle = {Proceedings of the Agent-Directed Simulation Symposium},
articleno = {8},
numpages = {6},
keywords = {swarm intelligence, agent-based simulation, cooperative control, mission planning, UAV swarm},
location = {San Diego, California},
series = {ADSS 13}
}

@inproceedings{10.1145/3438872.3439077,
author = {Bu, Yichuan and Gan, Haifeng and Gan, Yu},
title = {Current Status and Perspectives of the Artificial Intelligence-Based Identification of Citrus Huanglongbing},
year = {2020},
isbn = {9781450388306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3438872.3439077},
doi = {10.1145/3438872.3439077},
abstract = {Over the past decade, several studies have been published exploring AI-based identification of Huanglongbing. However, there is a shortage of studies that integrate the existing knowledge related to AI technical identification. The main objective of this paper is to review the published papers in a time series to summarize the accuracy of HLB recognition-related AI algorithms in practical use. It also compares the different algorithms used in different studies using the identification accuracy as a benchmark, and finds that more sophisticated AI algorithms such as deep learning have higher accuracy rates. In addition, the article also makes suggestions for the future development direction of this field.},
booktitle = {Proceedings of the 2020 2nd International Conference on Robotics, Intelligent Control and Artificial Intelligence},
pages = {175–180},
numpages = {6},
keywords = {Artificial intelligence, Supervised Learning, HLB, Deep Learning, Huanglongbing},
location = {Shanghai, China},
series = {RICAI 2020}
}

@inproceedings{10.1145/3055635.3056659,
author = {Riansyah, Moch I. and Nugraha, Yayan P. and Ridlwan, Hasvienda M. and Trilaksono, Bambang R.},
title = {3D Mapping Hexacopter Simulation Using Gazebo and Robot Operating Sytem(ROS)},
year = {2017},
isbn = {9781450348171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3055635.3056659},
doi = {10.1145/3055635.3056659},
abstract = {This paper present a simulation of Unmanned Aerial Vehicle which is type of hexacopter for building 3D maps of exploration environment. This simulation using Gazebo Simulator environment with Software In the Loop (SITL) ardupilot that is integrated with Robot Operating System as a open source flexible framework for writing robot software. To proceed 3D maps construction, we have installed Intel Realsense R200 RGB-D camera on hexacopter for getting RGB image data and Depth data that will be computed by open source octomap ROS package to result 3D Maps. Octomap using octree data structure to form 3D Map of voxel with odometry of hexacopter.},
booktitle = {Proceedings of the 9th International Conference on Machine Learning and Computing},
pages = {507–510},
numpages = {4},
keywords = {Odometry, Octomap, R200, ROS, Simulation, 3D Map, Gazebo},
location = {Singapore, Singapore},
series = {ICMLC 2017}
}

@inproceedings{10.1145/3407023.3407068,
author = {Du, Xiaoyu and Hargreaves, Chris and Sheppard, John and Anda, Felix and Sayakkara, Asanka and Le-Khac, Nhien-An and Scanlon, Mark},
title = {SoK: Exploring the State of the Art and the Future Potential of Artificial Intelligence in Digital Forensic Investigation},
year = {2020},
isbn = {9781450388337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3407023.3407068},
doi = {10.1145/3407023.3407068},
abstract = {Multi-year digital forensic backlogs have become commonplace in law enforcement agencies throughout the globe. Digital forensic investigators are overloaded with the volume of cases requiring their expertise compounded by the volume of data to be processed. Artificial intelligence is often seen as the solution to many big data problems. This paper summarises existing artificial intelligence based tools and approaches in digital forensics. Automated evidence processing leveraging artificial intelligence based techniques shows great promise in expediting the digital forensic analysis process while increasing case processing capacities. For each application of artificial intelligence highlighted, a number of current challenges and future potential impact is discussed.},
booktitle = {Proceedings of the 15th International Conference on Availability, Reliability and Security},
articleno = {46},
numpages = {10},
keywords = {machine learning, digital forensics, deep learning},
location = {Virtual Event, Ireland},
series = {ARES '20}
}

@inproceedings{10.1145/3400286.3418258,
author = {Khatri, Romancha and Won, Kwanghee},
title = {Kernel-Controlled DQN Based CNN Pruning for Model Compression and Acceleration},
year = {2020},
isbn = {9781450380256},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3400286.3418258},
doi = {10.1145/3400286.3418258},
abstract = {Apart from the accuracy, the size of Convolutional Neural Networks (CNN) model is another principal factor for facilitating the deployment of models on memory, power and budget constrained devices. Conventional compression techniques require human expert to setup parameters to explore the design space and iterative based pruning requires heavy training which is sub-optimal and time consuming. Given a CNN model, we propose deep reinforcement learning [8] DQN based automated compression which effectively turned off kernels on each layer by observing its significance. Observing accuracy, compression ratio and convergence rate, proposed DQN model can automatically re- activate the healthiest kernels back to train it again to regain accuracy which greatly ameliorate the model compression quality. Based on experiments on MNIST [3] dataset, our method can compress convolution layers for VGG-like [10] model up to 60% with 0.5% increase in test accuracy within less than a half the number of initial amount of training (speed-up up to 2.5\texttimes{}), state- of-the-art results of dropping 80% of kernels (compressed 86% parameters) with increase in accuracy by 0.14%. Further dropping 84% of kernels (compressed 94% parameters) with the loss of 0.4% accuracy. The first proposed Auto-AEC (Accuracy-Ensured Compression) model can compress the network by preserving original accuracy or increase in accuracy of the model, whereas, the second proposed Auto-CECA (Compression-Ensured Considering the Accuracy) model can compress to the maximum by preserving original accuracy or minimal drop of accuracy. We further analyze effectiveness of kernels on different layers based on how our model explores and exploits in various stages of training.},
booktitle = {Proceedings of the International Conference on Research in Adaptive and Convergent Systems},
pages = {36–41},
numpages = {6},
keywords = {Kernels fitness, Model Compression and Acceleration, Convolutional Neural Network, Deep Reinforcement Learning, Deep Q Network},
location = {Gwangju, Republic of Korea},
series = {RACS '20}
}

@inproceedings{10.5555/3306127.3331907,
author = {Yang, Bo and Liu, Min},
title = {Attack-Resilient Connectivity Game for UAV Networks Using Generative Adversarial Learning},
year = {2019},
isbn = {9781450363099},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {The continuous link connectivity is critical for the efficient collaboration of multiple unmanned aerial vehicles (UAVs). However, the UAV communication environments are not only harsh, but are also confronted with the threats of smart attackers, which pose great barriers in maintaining the links unblocked. In this paper, we leverage the paradigm of the Generative Adversarial Network (GAN) to formulate an attack-resilient connectivity game between a pair of neighboring UAVs and an attacker. In the three-agent adversary game, the attacker acts as the generator, which attempts to generate highly approximate information as the UAVs so as to maximize its jamming capability; while the pairwise UAVs act as the discriminators, which attempt to enhance the capability of refusing the fake information (i.e., the opponent's attack). As the state-of-the-art GAN learning algorithms suffer from the instability dilemma (i.e., either with the unsuccessful convergence or with the low generation/discrimination performance), we incorporate the conditional GAN with the least square objective loss function as well as the mean square error such that the attacker can improve the detection capability from UAVs' historical activity patterns and the UAVs can accordingly adjust the connectivity strategy. We validate the effectiveness of the proposed algorithm through extensive evaluations. Results demonstrate that the proposed algorithm can improve the convergence efficiency, reduce the connection latency, and enhance the attack-resilience capability significantly.},
booktitle = {Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {1743–1751},
numpages = {9},
keywords = {unmanned aerial vehicles, smart attacks, connectivity establishment, adversarial learning},
location = {Montreal QC, Canada},
series = {AAMAS '19}
}

@inbook{10.1145/3471287.3471304,
author = {Banerjee, Chaity and Lilian, Chad and Reasor, Daniel and Pasiliao, Eduardo and Mukherjee, Tathagata},
title = {An Application of Generative Adversarial Networks for Robust Inference in Computational Fluid Dynamics},
year = {2021},
isbn = {9781450389549},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3471287.3471304},
abstract = {In this paper we propose a robust learning pipeline for inference in computational fluid dynamics (CFD) systems in the presence of faulty sensor data. The standard methods for handling faulty sensor data involve outlier detection techniques which assume that the faulty data is generated from the tail regions of the underlying data distribution and hence can be eliminated by modeling the high probability regions of the distribution. However this assumption is not always true and subtle faults in sensors can lead to recording of faulty data which can be thought of as being generated from a subtly perturbed version of the underlying distribution. Methods based on outlier detection techniques will fail to work under these settings and hence novel approaches are required for eliminating faulty data in such systems. In this work we explore the use of a Generative Adversarial Network (GAN) for this purpose. We train the generator network of the GAN to generate “fake” sensor data that mimics the distribution of the real data, albeit, a slightly perturbed one. We use this to train a discriminator network which learns to distinguish between the “real” and “fake” data generated from the generator. This discriminator is then used to filter out faulty sensor data generated from a perturbed version of the distribution generating the real data. We also build a simple regressor that uses the trained discriminator to perform robust regression on the CFD data after eliminating faulty sensor data. We tested the robust regression pipeline with CFD data for predicting fluid flow characteristics (specifically the angle of attack (AoA)) over a 2D foil. Our discriminator trained in a GAN framework could eliminate faulty sensor data, generated using the trained generator, with ∼ 100 % efficiency. The filtered data is then used for inference of the fluid flow parameters using the regressor. },
booktitle = {2021 the 5th International Conference on Information System and Data Mining},
pages = {74–83},
numpages = {10}
}

@inproceedings{10.5555/3237383.3237896,
author = {Ramirez, Miquel and Papasimeon, Michael and Lipovetzky, Nir and Benke, Lyndon and Miller, Tim and Pearce, Adrian R. and Scala, Enrico and Zamani, Mohammad},
title = {Integrated Hybrid Planning and Programmed Control for Real Time UAV Maneuvering},
year = {2018},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {The automatic generation of realistic behaviour such as tactical intercepts for Unmanned Aerial Vehicles (UAV) in air combat is a challenging problem. State-of-the-art solutions propose hand--crafted algorithms and heuristics whose performance depends heavily on the initial conditions and aerodynamic properties of the UAVs involved. This paper shows how to employ domain--independent planners, embedded into professional multi--agent simulations, to implement two--level Model Predictive Control (MPC) hybrid control systems for simulated UAVs. We compare the performance of controllers using planners with others based on behaviour trees that implement real world tactics. Our results indicate that hybrid planners derive novel and effective tactics from first principles inherent to the dynamical constraints UAVs are subject to.},
booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {1318–1326},
numpages = {9},
keywords = {hybrid systems, agent programming, uav, planning},
location = {Stockholm, Sweden},
series = {AAMAS '18}
}

@inproceedings{10.1145/3404397.3404425,
author = {He, Bo and Wang, Jingyu and Qi, Qi and Sun, Haifeng and Zhuang, Zirui and Liu, Cong and Liao, Jianxin},
title = {DeepHop on Edge: Hop-by-Hop Routing ByDistributed Learning with Semantic Attention},
year = {2020},
isbn = {9781450388160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3404397.3404425},
doi = {10.1145/3404397.3404425},
abstract = {Multi-access Edge Computing (MEC) and ubiquitous smart devices help serve end-users efficiently and optimally through providing emerging edge-deployed services. Meanwhile, heavy and time-varying traffic loads are produced in the edge network, so that an efficient traffic forwarding mechanism is required. In this paper, we propose a parallel and distributed learning approach, DeepHop, to adapt to the volatile environments and realize hop-by-hop routing. The Multi-Agent Deep Reinforcement Learning (MADRL) is used to alleviate the edge network congestion and maximize the utilization of network resources. DeepHop determines the routing among edge network nodes for heterogeneous types of traffic according to the current workload and capability. By joining with an attention mechanism, DeepHop obtains the semantics from the elements of the network state to help the agents learn the importance of each element on routing. Experiment results show that DeepHop achieves the increase of successfully transmitted packets by 15% compared with the state-of-the-art algorithms. Besides, DeepHop with an attention mechanism reduces convergence time by nearly half compared with the common-used structures of neural networks.},
booktitle = {49th International Conference on Parallel Processing - ICPP},
articleno = {58},
numpages = {11},
keywords = {multi-agent reinforcement learning, distributed routing, wireless edge networks, self-attention},
location = {Edmonton, AB, Canada},
series = {ICPP '20}
}

@inproceedings{10.1145/3318299.3318376,
author = {Guan, Yirong and Gao, Mingsheng and Bai, Yufan},
title = {Double-Ant Colony Based UAV Path Planning Algorithm},
year = {2019},
isbn = {9781450366007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3318299.3318376},
doi = {10.1145/3318299.3318376},
abstract = {Path planning plays an important role in the applications of Unmanned Aerial Vehicles (UAVs). It allows the UAV to autonomously compute an optimal path from the initial point to the end by checking some specific control points or fulfill some mission specific constraints (e.g., obstacle avoidance, fuel consumption, etc.). While ant colony optimization (ACO) algorithm has attracted a great deal of attention due to the fact that ants can work cooperatively to find an optimal path. However, ACO converges slowly in finding an optimal path, particularly for the case when the problem domain is large. To solve this problem, a double-ant colony based algorithm is proposed in this paper. More specifically, in the early stage we exploit genetic algorithm to generate pheromones, thus accelerating the convergence of the algorithm. Numerical results validate the effectiveness of the proposed algorithm.},
booktitle = {Proceedings of the 2019 11th International Conference on Machine Learning and Computing},
pages = {258–262},
numpages = {5},
keywords = {UAV path planning, initial pheromone, double-ant colony optimization},
location = {Zhuhai, China},
series = {ICMLC '19}
}

@inproceedings{10.1145/3441110.3441151,
author = {Blachut, Krzysztof and Danilowicz, Michal and Szolc, Hubert and Wasala, Mateusz and Kryjak, Tomasz and Pankiewicz, Nikodem and Komorkiewicz, Mateusz},
title = {Automotive Perception System Evaluation with Reference Data Obtained by A&nbsp;UAV},
year = {2021},
isbn = {9781450389013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3441110.3441151},
doi = {10.1145/3441110.3441151},
abstract = { Testing and evaluation of an automotive perception system is a&nbsp;complicated task which requires special equipment and infrastructure. To compute key performance indicators and compare the results with the real-world situation, some additional sensors and manual data labelling are often required. In this article, we propose a&nbsp;different approach, which is based on a&nbsp;UAV equipped with a&nbsp;4K camera flying above the test track. Thanks to the synchronisation of the sensors between the tested vehicle and the UAV, it is possible to precisely determine the positions of the objects around the car and correlate them with the perception system readings. The performed experiments indicate that this approach could be an interesting alternative to the existing evaluation solutions. },
booktitle = {Workshop on Design and Architectures for Signal and Image Processing (14th Edition)},
pages = {10–18},
numpages = {9},
keywords = {LiDAR, perception systems, automotive, testing, UAV, ADAS, drone, evaluation, automatic labelling},
location = {Budapest, Hungary},
series = {DASIP '21}
}

@article{10.1145/3380782,
author = {Zhang, Ruiwen and Holvoet, Tom and Song, Bifeng and Pei, Yang},
title = {UAVs vs. Pirates: An Anticipatory Swarm Monitoring Method Using an Adaptive Pheromone Map},
year = {2020},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {1556-4665},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3380782},
doi = {10.1145/3380782},
abstract = {For the rising hazard of pirate attacks, unmanned aerial vehicle (UAV) swarm monitoring is a promising countermeasure. Previous monitoring methods have deficiencies in either adaptivity to dynamic events or simple but effective path coordination mechanisms, and they are inapplicable to the large-area, low-target-density, and long-duration persistent counter-piracy monitoring. This article proposes a self-organized UAV swarm counter-piracy monitoring method. Based on the pheromone map, this method is characterized by (1) a reservation mechanism for anticipatory path coordination and (2) a ship-adaptive mechanism for adapting to merchant ship distributions. A heuristic depth-first branch and bound search algorithm is designed for solving individual path planning. Simulation experiments are conducted to study the optimal number of plan steps and adaptivity scaling factor for different numbers of UAVs. Results show that merely decreasing revisit intervals cannot effectively reduce pirate attacks. Without the ship-adaptive mechanism, the proposed method reduces up to 87.2%, 43.2%, and 5.5% of revisit intervals compared to the L\`{e}vy Walk method, the sweep method, and the baseline self-organized method, respectively, but cannot reduce pirate attacks; while with the ship-adaptive mechanism, the proposed method can reduce pirate attacks by up to 6.7% compared to the best of the baseline methods.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = {aug},
articleno = {13},
numpages = {31},
keywords = {piracy, pheromone map, adaptive, UAV swarm, reservation mechanism}
}

@inproceedings{10.5555/3408352.3408598,
author = {Yakopcic, Chris and Rahman, Nayim and Atahary, Tanvir and Taha, Tarek M. and Douglass, Scott},
title = {Solving Constraint Satisfaction Problems Using the Loihi Spiking Neuromorphic Processor},
year = {2020},
isbn = {9783981926347},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {In many cases, low power autonomous systems need to make decisions extremely efficiently. However, as a potential solution space becomes more complex, finding a solution quickly becomes nearly impossible using traditional computing methods. Thus, in this work we present a constraint satisfaction algorithm based on the principles of spiking neural networks. To demonstrate the validity of this algorithm, we have shown successful execution of the Boolean satisfiability problem (SAT) on the Intel Loihi spiking neuromorphic research processor. Power consumption in this spiking processor is due primarily to the propagation of spikes, which are the key drivers of data movement and processing. Thus, this system is inherently efficient for many types of problems. However, algorithms must be redesigned in a spiking neural network format to achieve the greatest efficiency gains. To the best of our knowledge, the work in this paper exhibits the first implementation of constraint satisfaction on a low power embedded neuromorphic processor. With this result, we aim to show that embedded spiking neuromorphic hardware is capable of executing general problem solving algorithms with great areal and computational efficiency.},
booktitle = {Proceedings of the 23rd Conference on Design, Automation and Test in Europe},
pages = {1079–1084},
numpages = {6},
keywords = {SAT, spiking neural networks, intel loihi, constraint satisfaction, neuromorphic hardware},
location = {Grenoble, France},
series = {DATE '20}
}


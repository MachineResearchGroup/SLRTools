@article{LIU2017377,
title = {Analysis of the Relation between Artificial Intelligence and the Internet from the Perspective of Brain Science},
journal = {Procedia Computer Science},
volume = {122},
pages = {377-383},
year = {2017},
note = {5th International Conference on Information Technology and Quantitative Management, ITQM 2017},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.383},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917326261},
author = {Feng Liu and Yong Shi and Peijia Li},
keywords = {Internet’s virtual brain, Big SNS, AI model of the Internet-like brain},
abstract = {Artificial intelligence (AI) like deep learning, cloud AI computation has been advancing at a rapid pace since 2014. There is no doubt that the prosperity of AI is inseparable with the development of the Internet. However, there has been little attention to the link between AI and the internet. This paper explores them with brain insights mainly from four views:1) How is the general relation between artificial intelligence and Internet of Things, cloud computing, big data and Industrial Internet from the perspective of brain science. 2) Construction of a new AI system model with the Internet and brain science.}
}
@article{CHOWDURY2019161,
title = {IoT Based Real-time River Water Quality Monitoring System},
journal = {Procedia Computer Science},
volume = {155},
pages = {161-168},
year = {2019},
note = {The 16th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2019),The 14th International Conference on Future Networks and Communications (FNC-2019),The 9th International Conference on Sustainable Energy Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.08.025},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919309391},
author = {Mohammad Salah Uddin Chowdury and Talha Bin Emran and Subhasish Ghosh and Abhijit Pathak and Mohd. Manjur Alam and Nurul Absar and Karl Andersson and Mohammad Shahadat Hossain},
keywords = {Water quality monitoring, sensors, Big Data Analytics System, Internet of things, Real-time},
abstract = {Current water quality monitoring system is a manual system with a monotonous process and is very time-consuming. This paper proposes a sensor-based water quality monitoring system. The main components of Wireless Sensor Network (WSN) include a microcontroller for processing the system, communication system for inter and intra node communication and several sensors. Real-time data access can be done by using remote monitoring and Internet of Things (IoT) technology. Data collected at the apart site can be displayed in a visual format on a server PC with the help of Spark streaming analysis through Spark MLlib, Deep learning neural network models, Belief Rule Based (BRB) system and is also compared with standard values. If the acquired value is above the threshold value automated warning SMS alert will be sent to the agent. The uniqueness of our proposed paper is to obtain the water monitoring system with high frequency, high mobility, and low powered. Therefore, our proposed system will immensely help Bangladeshi populations to become conscious against contaminated water as well as to stop polluting the water.}
}
@article{WANG2019139,
title = {NormalNet: A voxel-based CNN for 3D object classification and retrieval},
journal = {Neurocomputing},
volume = {323},
pages = {139-147},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.09.075},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218311561},
author = {Cheng Wang and Ming Cheng and Ferdous Sohel and Mohammed Bennamoun and Jonathan Li},
keywords = {3D object classification, 3D object retrieval, Convolutional neural network, Network fusion},
abstract = {A common approach to tackle 3D object recognition tasks is to project 3D data to multiple 2D images. Projection only captures the outline of the object, and discards the internal information that may be crucial for the recognition. In this paper, we stay in 3D and concentrate on tapping the potential of 3D representations. We present NormalNet, a voxel-based convolutional neural network (CNN) designed for 3D object recognition. The network uses normal vectors of the object surfaces as input, which demonstrate stronger discrimination capability than binary voxels. We propose a reflection–convolution–concatenation (RCC) module to realize the conv layers, which extracts distinguishable features for 3D vision tasks while reducing the number of parameters significantly. We further improve the performance of NormalNet by combining two networks, which take normal vectors and voxels as input respectively. We carry out a series of experiments that validate the design of the network and achieve competitive performance in 3D object classification and retrieval tasks.}
}
@article{GUPTA2021100342,
title = {Future Smart Connected Communities to Fight COVID-19 Outbreak},
journal = {Internet of Things},
volume = {13},
pages = {100342},
year = {2021},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2020.100342},
url = {https://www.sciencedirect.com/science/article/pii/S2542660520301736},
author = {Deepti Gupta and Smriti Bhatt and Maanak Gupta and Ali Saman Tosun},
keywords = {COVID-19, Coronavirus, Internet of things, Cloud computing, Edge computing, Artificial intelligence (AI), Machine learning, Smart communities, Multi-layered architecture, Security, Privacy},
abstract = {Internet of Things (IoT) has grown rapidly in the last decade and continues to develop in terms of dimension and complexity, offering a wide range of devices to support a diverse set of applications. With ubiquitous Internet, connected sensors and actuators, networking and communication technology along with artificial intelligence (AI), smart cyber-physical systems (CPS) provide services rendering assistance and convenience to humans in their daily lives. However, the recent outbreak of COVID-19 (also known as coronavirus) pandemic has exposed and highlighted the limitations of contemporary technological deployments especially to contain the widespread of this disease. IoT and smart connected technologies together with data-driven applications can play a crucial role not only in the prevention, mitigation, or continuous remote monitoring of patients, but also enable prompt enforcement of guidelines, rules, and administrative orders to contain such future outbreaks. In this paper, we envision an IoT and data-supported connected ecosystem designed for intelligent monitoring, pro-active prevention and control, and mitigation of COVID-19 and similar epidemics. We propose a gamut of synergistic applications and technology systems for various smart infrastructures including E-Health, smart home, supply chain management, transportation, and city, which will work in convergence to develop ‘pandemic-proof’ future smart communities. We also present a generalized cloud-enabled IoT implementation framework along with scientific solutions, which can be adapted and extended to deploy smart connected ecosystem scenarios using widely used Amazon Web Services (AWS) cloud infrastructures. In addition, we also implement an E-Health RPM use case scenario to demonstrate the need and practicality for smart connected communities. Finally, we highlight challenges and research directions that need thoughtful consideration and across the board cooperation among stakeholders to build resilient communities against future pandemics.}
}
@article{OJAGH2021107572,
title = {Enhanced air quality prediction by edge-based spatiotemporal data preprocessing},
journal = {Computers & Electrical Engineering},
volume = {96},
pages = {107572},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107572},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621005097},
author = {Soroush Ojagh and Francesco Cauteruccio and Giorgio Terracina and Steve H.L. Liang},
keywords = {Air quality IoT sensors, Data preprocessing, Long short term memory, Dynamic time warping, PM2.5 prediction},
abstract = {Particulate matter with a diameter less than 2.5 micrometers (PM2.5) can be considered as the most dangerous air pollutant that affects human health. In addition, technological advances, such as those involving the Internet of Things (IoT) for monitoring air quality, have made it possible to monitor air quality for a lower cost. However, missing values and noisy data make nonlinear data provided by air quality IoT sensors less reliable and more complicated than data provided by air quality monitoring stations. In this study, we propose a mixed edge-based and cloud-based framework with the final goal of PM2.5 value prediction. In order to validate the proposed approach, we evaluate the quality of predictions using both original and preprocessed data on a real-world dataset from air quality sensors distributed in Calgary, Canada. Obtained results show an average improvement of 40.18% of the prediction accuracy on Mean Absolute Percentage Error by using the proposed preprocessing technique.}
}
@article{ALFASEEH2020102593,
title = {Greenhouse gas emission prediction on road network using deep sequence learning},
journal = {Transportation Research Part D: Transport and Environment},
volume = {88},
pages = {102593},
year = {2020},
issn = {1361-9209},
doi = {https://doi.org/10.1016/j.trd.2020.102593},
url = {https://www.sciencedirect.com/science/article/pii/S1361920920307793},
author = {Lama Alfaseeh and Ran Tu and Bilal Farooq and Marianne Hatzopoulou},
keywords = {Greenhouse Gas (GHG) emissions, Carbon dioxide equivalent (CO), Machine learning, Clustering, Long-short term memory network (LSTM), Autoregressive integrated moving average (ARIMA), Link level GHG prediction},
abstract = {Mitigating the substantial undesirable impact of transportation systems on the environment is paramount. Thus, predicting Greenhouse Gas (GHG) emissions is one of the profound topics, especially with the emergence of intelligent transportation systems (ITS). We developed a deep learning framework to predict link-level GHG emission rate (ER) (in CO2eq gram/second) based on the most representative predictors, such as speed, density, and GHG ER of previous time steps. In particular, various specifications of the long short-term memory (LSTM) networks with explanatory variables were examined, and were compared with clustering and the autoregressive integrated moving average (ARIMA) model with explanatory variables. The downtown Toronto road network was used as the study area, and highly detailed data were synthesized using a calibrated traffic microsimulation and MOVES. It was found that LSTM specification with speed, density, GHG ER, and in-links speed from three previous minutes performed the best while adopting two hidden layers, and when the hyper-parameters were systematically tuned. Adopting a 30-second updating interval slightly improved the correlation between true (simulated) and predicted GHG ERs (from predictive models), but contributed negatively to the prediction accuracy as reflected in the increased root mean square error (RMSE) value. Efficiently predicting GHG emissions at a higher frequency with lower data requirements will pave the way for various applications, e.g. anticipatory eco-routing in large-scale road networks to alleviate the adverse impact on global warming.}
}
@article{KUMAR2021107819,
title = {SP2F: A secured privacy-preserving framework for smart agricultural Unmanned Aerial Vehicles},
journal = {Computer Networks},
volume = {187},
pages = {107819},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.107819},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621000086},
author = {Randhir Kumar and Prabhat Kumar and Rakesh Tripathi and Govind P. Gupta and Thippa Reddy Gadekallu and Gautam Srivastava},
keywords = {Blockchain technology, Artificial intelligence, Deep learning, Intrusion detection system, Privacy-preservation, Smart agriculture, Unmanned Aerial Vehicles (UAVs)},
abstract = {The current advancement in Unmanned Aerial Vehicles (UAVs) and the proliferation of the Internet of Things (IoT) devices is revolutionizing conventional farming operations into precision agriculture. The agricultural UAVs combined with IoT use an open channel i.e., the Internet to assist cultivators with data collection, processing, monitoring, and making correct decisions on the farm. However, the use of the Internet opens up a wide range of challenges such as security (e.g., performing cyber-attacks), risk of data privacy (e.g., data poisoning and inference attacks), etc. The usage of current conventional centralized security measures has limitations in terms of a single point of failure, verifiability, traceability, and scalability. Motivated from the aforementioned challenges, we propose a Secured Privacy-Preserving Framework (SP2F) for smart agricultural UAVs. The proposed SP2F framework has two main engines, a two-level privacy engine, and a deep learning-based anomaly detection engine. In the two-level privacy engine, a blockchain, and smart contract-based enhanced Proof of Work (ePoW) is designed for data authentication, and to mitigate data poisoning attacks. A Sparse AutoEncoder (SAE) is applied for transforming data into a new encoded format for preventing inference attacks. In the anomaly detection engine, a Stacked Long-Short-Term Memory (SLSTM) is used to train and evaluate the results of the proposed two-level privacy engine using two publicly accessible IoT-based datasets, namely ToN-IoT and IoT Botnet. Finally, based on thorough analysis, and comparison, we identify that the SP2F framework outperforms several state-of-the-art techniques in both non-blockchain and blockchain frameworks.}
}
@article{REN2019150,
title = {Multi-modal Correlated Network for emotion recognition in speech},
journal = {Visual Informatics},
volume = {3},
number = {3},
pages = {150-155},
year = {2019},
issn = {2468-502X},
doi = {https://doi.org/10.1016/j.visinf.2019.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X19300488},
author = {Minjie Ren and Weizhi Nie and Anan Liu and Yuting Su},
keywords = {Multi-modal, Emotion recognition, Neural networks},
abstract = {With the growing demand of automatic emotion recognition system, emotion recognition is becoming more and more crucial for human–computer interaction (HCI) research. Recently, there is a continuous improvement in the performance of automatic emotion recognition due to the development of both hardware and deep learning methods. However, because of the abstract concept and multiple expressions of emotion, automatic emotion recognition is still a challenging task. In this paper, we propose a novel Multi-modal Correlated Network for emotion recognition aiming at exploiting the information from both audio and visual channels to achieve more robust and accurate detection. In the proposed method, the audio signals and visual signals are first preprocessed for the feature extraction. After preprocessing, we obtain the Mel-spectrograms, which can be treated as images, and the representative frames from visual segments. Then the Mel-spectrograms are fed to the convolutional neural network (CNN) to get the audio features and the representative frames are fed to the CNN and LSTM to get features. Specially, we employ the triplet loss to increase the differentiation of inter-class. Meanwhile, we propose a novel correlated loss to reduce the differentiation of intra-class. Finally, we apply the feature fusion method to fuse the audio and visual feature for emotion recognition classification. The experimental result on AEFW dataset demonstrates the correlation information of multiple modals is crucial for automatic emotion recognition and the proposed method can achieve the state-of-the-art performance on the classification task.}
}
@article{RUIZ2020101315,
title = {A case study on understanding energy consumption through prediction and visualization (VIMOEN)},
journal = {Journal of Building Engineering},
volume = {30},
pages = {101315},
year = {2020},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2020.101315},
url = {https://www.sciencedirect.com/science/article/pii/S2352710219317978},
author = {L.G.B. Ruiz and M.C. Pegalajar and M. Molina-Solana and Yi-Ke Guo},
keywords = {Energy efficiency, Energy forecasting, Visualization, Mapbox, Energy monitoring},
abstract = {Energy efficiency has emerged as an overarching concern due to the high pollution and cost associated with operating heating, ventilation and air-conditioning systems in buildings, which are an essential part of our day to day life. Besides, energy monitoring becomes one of the most important research topics nowadays as it enables us the possibility of understanding the consumption of the facilities. This, along with energy forecasting, represents a very decisive task for energy efficiency. The goal of this study is divided into two parts. First to provide a methodology to predict energy usage every hour. To do so, several Machine Learning technologies were analysed: Trees, Support Vector Machines and Neural Networks. Besides, as the University of Granada lacks a tool to properly monitoring those data, a second aim is to propose an intelligent system to visualize and to use those models in order to predict energy consumption in real-time. To this end, we designed VIMOEN (VIsual MOnitoring of ENergy), a web-based application to provide not only visual information about the energy consumption of a set of geographically-distributed buildings but also expected expenditures in the near future. The system has been designed to be easy-to-use and intuitive for non-expert users. Our system was validated on data coming from buildings of the UGR and the experiments show that the Elman Neural Networks proved to be the most accurate and stable model and since the 5th hour the results maintain accuracy.}
}
@article{AKBAR2021107950,
title = {NOMA and 5G emerging technologies: A survey on issues and solution techniques},
journal = {Computer Networks},
volume = {190},
pages = {107950},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.107950},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621000888},
author = {Aamina Akbar and Sobia Jangsher and Farrukh A. Bhatti},
keywords = {NOMA, 5G, Optimization, Game theory, Graph theory, Machine learning, Matching theory, Analytical techniques},
abstract = {Power Domain Non-Orthogonal Multiple Access (PD-NOMA) is a potential technology for the next generation of cellular networks. Compared to classical orthogonal multiple access (OMA) techniques, PD-NOMA leverages the distinct channel gains of users for multiplexing different signals in a single resource block (time, frequency, code) in power domain. This results in higher spectral efficiency, improved user fairness, better cell-edge throughput, increased reliability and connectivity and low-latency. The flexible combination of PD-NOMA with existing and emerging technologies such as heterogeneous networks (HetNets), multiple-input multiple-output (MIMO), massive MIMO, cooperative communication, cognitive radios (CRs), millimeter wave communication, simultaneous wireless information and power transfer (SWIPT), visible light communication (VLC), mobile edge computing (MEC), intelligent reflecting surfaces (IRS), unmanned aerial vehicles (UAVs), underwater communication etc., is expected to cause further enhancements in performance. Existing survey papers on NOMA mainly focus on its concept, comparison, issues and analysis without any categorization of different techniques to solve the issues related to it. This survey paper highlights the main issues and constraints of resource allocation, signaling, practical implementation and security aspects of NOMA and its integration with 5G and upcoming wireless technologies. Various solutions have been proposed in the literature that involve optimization, analytical, game theory, matching theory, graph theory and machine learning (ML) techniques. We present an in-depth analysis and comparison of these solutions with key insights emphasizing the feasibility and applicability for a qualitative analysis. We finally identify promising future research directions and challenges in the context of PD-NOMA’s application to the existing 5G and next generation wireless networks.}
}
@article{CINTRANO2020113684,
title = {Using metaheuristics for the location of bicycle stations},
journal = {Expert Systems with Applications},
volume = {161},
pages = {113684},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113684},
url = {https://www.sciencedirect.com/science/article/pii/S095741742030508X},
author = {C. Cintrano and F. Chicano and E. Alba},
keywords = {Bike station location, -Median problem, Metaheuristics},
abstract = {In this work, we solve the problem of finding the best locations to place stations for depositing/collecting shared bicycles. To do this, we model the problem as the p-median problem, that is a major existing localization problem in optimization. The p-median problem seeks to place a set of facilities (bicycle stations) in a way that minimizes the distance between a set of clients (citizens) and their closest facility (bike station). We have used a genetic algorithm, iterated local search, particle swarm optimization, simulated annealing, and variable neighbourhood search, to find the best locations for the bicycle stations and study their comparative advantages. We use irace to parameterize each algorithm automatically, to contribute with a methodology to fine-tune algorithms automatically. We have also studied different real data (distance and weights) from diverse open data sources from a real city, Malaga (Spain), hopefully leading to a final smart city application. We have compared our results with the implemented solution in Malaga. Finally, we have analyzed how we can use our proposal to improve the existing system in the city by adding more stations.}
}
@article{ABDELWAHAB2018352,
title = {Energy Efficiency: Improving the renewable energy penetration in a smart and green community},
journal = {Procedia Computer Science},
volume = {134},
pages = {352-357},
year = {2018},
note = {The 15th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2018) / The 13th International Conference on Future Networks and Communications (FNC-2018) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.07.199},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918311645},
author = {Haddaoui Abdelwahab and Laila Moussaid and Fouad Moutaouakkil and Hicham Medromi},
keywords = {Energy Efficiency, Energy Storage Systems, Renewable Energy, Building Energy Management System, Green, Smart cities},
abstract = {In this paper, we will focus on the energy efficiency by proposing a new concept to manage and improve the integration of the energy produced with renewable resources in a smart home community. By realizing this the total energy cost for that neighborhood will be reduced significantly and will also improve the quality of life. We even want to have a positive storage capacity in order to collect excess energy and redirect it to other neighborhoods belonging to the same area which are in need of energy. This will enhance the integration efficiency of energy produced locally, which will allow us to have a better quality of life, less gas emission, reducing greenhouse effect and resulting in a wiser management of the resources available in our cities.}
}
@article{TOLBA2022101043,
title = {Modular Interactive Computation Scheme for the Internet of Things assisted Robotic Services},
journal = {Swarm and Evolutionary Computation},
pages = {101043},
year = {2022},
issn = {2210-6502},
doi = {https://doi.org/10.1016/j.swevo.2022.101043},
url = {https://www.sciencedirect.com/science/article/pii/S2210650222000153},
author = {Amr Tolba and Zafer Al-Makhadmeh},
keywords = {Decision-Making, IoT, Edge Computing, Robot-Assisted Services, Swarm Intelligence},
abstract = {Internet of Things (IoT) assisted robotic applications are becoming prominent in smart cities for granting autonomous services for end-users. The IoT-enabled edge-computing paradigm provides ubiquitous computing and resource access for the robots for robust services. The interactive sessions and partial computations of the robots result in unnecessary exploitation of real-time resources. This paper introduces a swarm intelligence-based modular interactive computation scheme (MICS) for IoT-assisted robots to address the incompleteness in resource utilization and reduce computational complexity. In this scheme, particle swarm optimization (PSO) is incorporated with intelligent decision-making. The role of swarm intelligence is to improve interactive computations using different agents that provide offloading support. The flexible sharing of swarm agents provides shared resource utilization and comprehensive calculations for robot-based assistance. The proposed scheme performs computing and interaction decisions based on the robot inputs and its parallel processing feature. The proposed scheme's performance is verified using the metrics interaction span, decision complexity, offloading ratio, computing time, and outages. The proposed scheme achieves a 12.74% high interaction span, 6.68% less decision complexity, 11.69% less offloading ratio, and 19.41% less computing time under different intervals. Based on the resource availability analysis, MICS achieves 62.1% compared to IoT-IF 25.6%, SF-EM 32.9%, and 25.61%. Further MICS offloading ratio achieves up to 8.5% following IoT-IF 11.9%, SF-EM 10.1%, and SDF 9.1%.}
}
@article{ASGHARI2019241,
title = {Internet of Things applications: A systematic review},
journal = {Computer Networks},
volume = {148},
pages = {241-261},
year = {2019},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618305127},
author = {Parvaneh Asghari and Amir Masoud Rahmani and Hamid Haj Seyyed Javadi},
keywords = {Application-based services, Internet of things, Systematic literature review, Smart objects, Quality of service},
abstract = {Internet of Things (IoT) is considered as an ecosystem that contains smart objects equipped with sensors, networking and processing technologies integrating and working together to provide an environment in which smart services are taken to the end users. The IoT is leading numerous benefits into the human life through the environment wherein smart services are provided to utilize every activity anywhere and anytime. All these facilities and services are conveyed through the diverse applications which are performed in the IoT environment. The most important utilities that are achieved by the IoT applications are monitoring and consequently immediate decision making for efficient management. In this paper, we intend to survey in divers IoT application domains to comprehend the different approaches in IoT applications which have been recently presented based on the Systematic Literature Review (SLR) method. The aim of this paper is to categorize analytically and statistically, and analyze the current research techniques on IoT applications approaches published from 2011 to 2018. A technical taxonomy is presented for the IoT applications approaches according to the content of current studies that are selected with SLR process in this study including health care, environmental monitoring, smart city, commercial, industrial and general aspects in IoT applications. IoT applications are compared with each other according to some technical features such as Quality of Service (QoS), proposed case study and evaluation environments. The achievements and disadvantages of each study is discussed as well as presenting some hints for addressing their weaknesses and highlighting the future research challenges and open issues in IoT applications.}
}
@article{AMER2020102181,
title = {Non-cooperative game based congestion control for data rate optimization in vehicular ad hoc networks},
journal = {Ad Hoc Networks},
volume = {107},
pages = {102181},
year = {2020},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2020.102181},
url = {https://www.sciencedirect.com/science/article/pii/S1570870519302859},
author = {Hayder Amer and Hayder Al-Kashoash and Mohammed J Khami and Martin Mayfield and Lyudmila Mihaylova},
keywords = {Vehicular ad hoc networks, Congestion control, Non-cooperative game approach, Data rate adaptation, IoV applications},
abstract = {The growth of connected vehicles in smart cities increases the number of information being communicated on the Internet of Vehicle networks. This causes wireless channel congestion problems, which degrades the network performance and reliability due to the low throughput, high average delay and the high packets loss. Therefore, this paper proposes a non-cooperative game approach to control congestion in the vehicular ad-hoc network channel where the nodes behave as selfish players requesting high data transmission rates. Moreover, the satisfaction of the Nash equilibrium condition for the optimum data transmission rate for each vehicle, is proven. A utility function is introduced based on data transmission rates, the priority of vehicles and contention delay in order to obtain the optimal rates. The performance of the proposed approach has been evaluated and validated in comparison with three others approaches over two testing scenarios for highway and urban traffic. The results show that the network performance and efficiency have been improved by an overall average of 35%, 30% and 37.17% in terms of packets loss, channel busy time and number of collision messages, respectively, as compared with the state-of-the-art-strategies for the highway testing scenario. Similar performance is achieved for the urban testing scenario.}
}
@article{LONGO2020899,
title = {Apollon: Towards a citizen science methodology for urban environmental monitoring},
journal = {Future Generation Computer Systems},
volume = {112},
pages = {899-912},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.06.041},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20303940},
author = {Antonella Longo and Marco Zappatore and Mario A. Bochicchio},
keywords = {Mobile crowd sensing, Citizen science, Smart cities, Internet of people},
abstract = {The collaborative power of ICT systems is a key enabler of social and technological advances providing multiple opportunities for public involvement in participatory activities, thanks to novel paradigms like citizen science and mobile crowd sensing. These paradigms, if applied according to specific methodologies, promise to increase the pervasive observation of urban environmental pollution either directly by human observers, or by means of crowd-sourcing data measurement tasks using sensors in smart phones or other mobile devices. We propose a platform, named Apollon, to enable scientists and others to take part in citizen science projects based on the exploitation of mobile devices. The platform has been implemented and validated in an educational context, in which students participate in urban environmental monitoring activities. In the paper, we describe the platform and the approach developed to produce successful experiments.}
}
@article{MARTIN202215,
title = {Kafka-ML: Connecting the data stream with ML/AI frameworks},
journal = {Future Generation Computer Systems},
volume = {126},
pages = {15-33},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.07.037},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21002995},
author = {Cristian Martín and Peter Langendoerfer and Pouya Soltani Zarrin and Manuel Díaz and Bartolomé Rubio},
keywords = {Kafka-ML, Apache Kafka, Machine Learning, Artificial Intelligence, Data streams, Docker, Kubernetes, Distributed systems},
abstract = {Machine Learning (ML) and Artificial Intelligence (AI) depend on data sources to train, improve, and make predictions through their algorithms. With the digital revolution and current paradigms like the Internet of Things, this information is turning from static data to continuous data streams. However, most of the ML/AI frameworks used nowadays are not fully prepared for this revolution. In this paper, we propose Kafka-ML, a novel and open-source framework that enables the management of ML/AI pipelines through data streams. Kafka-ML provides an accessible and user-friendly Web user interface where users can easily define ML models, to then train, evaluate, and deploy them for inferences. Kafka-ML itself and the components it deploys are fully managed through containerization technologies, which ensure their portability, easy distribution, and other features such as fault-tolerance and high availability. Finally, a novel approach has been introduced to manage and reuse data streams, which may eliminate the need for data storage or file systems.}
}
@article{ZAMIRALOV2020213,
title = {Detection of housing and utility problems in districts through social media texts},
journal = {Procedia Computer Science},
volume = {178},
pages = {213-223},
year = {2020},
note = {9th International Young Scientists Conference in Computational Science, YSC2020, 05-12 September 2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.11.023},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920323978},
author = {Alexandr Zamiralov and Maria Khodorchenko and Denis Nasonov},
keywords = {Topic Modelling, One-class Classification, Urban Problems, Social Media Mining},
abstract = {Social media stores a significant amount of information which can be used for extraction of specific knowledge. A variety of topics that arise there concerns a lot of everyday life aspects, including urban-related problems. In this work, we demonstrate the way of using the texts from social media on the topic of housing and utility problems, such as litter on the streets, graffiti on a public building or noisy neighbours. Our aim is to develop an approach based on machine learning to automatically filter such citizen messages and classify them into several categories. To achieve this, we solve the classification problem with an almost unlimited number of negative categories using the One-Class approach and combine data from several resources to construct proper text embedding by combining results from the guided topic model and deep neural pretrained BERT method. Comparison with statistics taken from the official site indicates that the distributions of posts on each problem category are similar for districts of Saint-Petersburg}
}
@article{PERKOVIC2020121181,
title = {Smart Parking Sensors: State of the Art and Performance Evaluation},
journal = {Journal of Cleaner Production},
volume = {262},
pages = {121181},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2020.121181},
url = {https://www.sciencedirect.com/science/article/pii/S0959652620312282},
author = {T. Perković and P. Šolić and H. Zargariasl and D. Čoko and Joel J.P.C. Rodrigues},
keywords = {Sensor performance, Smart parking, LPWA, IoT power consumption},
abstract = {Smart parking systems present one of the essential infrastructure concepts that enable Internet of Things (IoT) in Smart cities. Finding a free parking lot plays a role in reducing traffic congestion, gas emissions, and increasing the quality of life of people living and working in it. Therein, the fundamental part of every smart parking system is the detection of vehicle presence, which is usually employed by devices comprised of power-hungry sensors. This paper gives an extension to state-of-the-art by a systematic in-depth overview of technologies used for the smart parking detection realization consuming mW of power. Deeper insights on the real-scenario performances and power consumption of most popular sensor devices and Low Power Wide Area (LPWA) radio technologies available today (LoRa, Sigfox and NB-IoT) are provided. The results show that based on the architectures of IoT system, lowest consumption is for LoRa devices. Further, analysis of power consumption of commercial LPWA-based Smart parking sensor device is provided along with battery estimation lifetime, which is especially important for the deployment of future smart parking solutions. Battery lifetime heavily depends on the number of parking lots exchanges and based on the less frequent changes, the estimated battery lifetime is approximately 7 years. Inspired by the limitations of power-hungry and relatively expensive smart parking sensor devices, two strategies for the optimization are proposed: first one is based on the premise where a drop in received signal strength of the LPWA device can serve as the presence of the vehicle in the parking lot, while the second one proposes a big picture on a novel architecture for harvesting the surrounding energy and using the same for circuitry wake-up therefore saving the energy.}
}
@article{IMRAN2022111762,
title = {IoT Task Management Mechanism Based on Predictive Optimization for Efficient Energy Consumption in Smart Residential Buildings},
journal = {Energy and Buildings},
volume = {257},
pages = {111762},
year = {2022},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2021.111762},
url = {https://www.sciencedirect.com/science/article/pii/S037877882101046X},
author = { Imran and Naeem Iqbal and Do Hyeun Kim},
keywords = {Energy saving, Prediction, Optimization, Task management, Energy consumption, Predictive optimization},
abstract = {Energy-saving is a global challenge and one of the hot research topics of this decade. The need for sustainable technologies and solutions for energy-saving dramatically increased in residential buildings due to population growth, quality of indoor environment, and climate change. Recently, IoT based applications have been developed in smart homes, smart cities, smart hospitals, and other smart environments. The goals of sustainable technologies in residential buildings incorporate maximization of thermal comfort and minimizing energy consumption. The challenges and problems of residential buildings can be solved using consumer behavior models and integrating their inference into residential problem solutions. This paper proposes an IoT task management mechanism based on predictive optimization for energy consumption minimization in smart residential buildings. The proposed task management mechanism has a predictive optimization module based on prediction and an optimization module for solving energy consumption minimization problems. The energy data is obtained from different appliances to evaluate the proposed predictive optimization approach. The proposed approach results are compared with prediction and optimization modules. The performance is evaluated in terms of regression performance metrics. The case study results show that the predictive optimization mechanism based on task management performs better than standalone prediction and optimization-based energy consumption mechanisms in residential buildings.}
}
@article{KHAN2020101035,
title = {An ultra-reliable and low latency communications assisted modulation based non-orthogonal multiple access scheme},
journal = {Physical Communication},
volume = {43},
pages = {101035},
year = {2020},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2020.101035},
url = {https://www.sciencedirect.com/science/article/pii/S1874490719305373},
author = {Rabia Khan and Dushantha Nalin K. Jayakody},
keywords = {Data rate, ITS, Interference, Lagrange, Latency, M-NOMA, Optimization, SER, URLLC},
abstract = {The technological demand drastically requires Internet of Things (IoT) execution. Certainly, it will bring a paradigm transformation from a local city to a smart city. Besides several other applications, Intelligent transportation system (ITS) will bring a dominant smart society shift. ITS will benefit growing traffic system safety, reliability, demand and security. 5G Ultra-Reliable and Low Latency Communications (URLLC) amalgamation is certain with ITS due to big data and traffic requirements. In this paper we demontrate our Modulation based Non Orthogonal Multiple Access (M-NOMA) technique support for Ultra-Reliable and Low Latencey Communication (URLLC) user case of 5G. Then we present it as a user case for ITS. M-NOMA guarantees reliability and low latency of the system due to its minimum symbol error rate (SER), reduced interference, better data rate and hence the Quality of service (QoS). In this paper, we derive SER for M-NOMA with Additive White Gaussian Noise (AWGN) and fading channel. We also optimized the derived SER, data rate with Lagrange optimization. The proposed system supports the low latency and high reliability requirements. Simulation result confirmed the added benefits offered by our M-NOMA scheme over the traditional schemes.}
}
@article{DINARDO2014525,
title = {Ant Algorithm for Smart Water Network Partitioning},
journal = {Procedia Engineering},
volume = {70},
pages = {525-534},
year = {2014},
note = {12th International Conference on Computing and Control for the Water Industry, CCWI2013},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2014.02.058},
url = {https://www.sciencedirect.com/science/article/pii/S1877705814000605},
author = {A. {Di Nardo} and M. {Di Natale} and R. Greco and G.F. Santonastaso},
keywords = {water network partitioning, graph theory, district meter area, network sectorization, ant algorithm, multi agents},
abstract = {Applying ICT devices to WDS makes it possible to introduce also the new concept of Smart WAter Network (SWAN), as a key Smart City subsystem, improving the traditional management of WDS. The possibility of inserting remote-controlled valves and flow meters in a WDS allows to divide a water network into k smaller subsystems, in order to improve the management and protection of WDS. This study proposes a novel technique for water network partitioning based on an ant algorithm that allows to obtain a network partitioning compatible with the hydraulic performance. The technique is applied to a real water network.}
}
@article{RAWASHDEH2020924,
title = {A knowledge-driven approach for activity recognition in smart homes based on activity profiling},
journal = {Future Generation Computer Systems},
volume = {107},
pages = {924-941},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.10.031},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17311342},
author = {Majdi Rawashdeh and Mohammed GH. {Al Zamil} and Samer Samarah and M. Shamim Hossain and Ghulam Muhammad},
keywords = {Smart cities, Smart homes, Internet of Things, Activity recognition, Data mining},
abstract = {The Internet of Things (IoT) is a technology for seamlessly connecting a large number of small-end devices and enabling the development of many smart applications to control different aspects of our life; shifting us, ever-closer to living in a smart city. IoT makes it possible to convert our homes to smart environments in which sensors are responsible for handling inhabitants’ behaviours and monitor their daily activities. Activity Recognition (AR) is a new service within smart homes. It has been introduced as a solution to improve the quality of life of people such as elderly and children. AR is concerned with the assignment of an activity label to a sequence of sensors’ events that are generated from the smart infrastructure. To help in effectively recognizing home activities, classification algorithms are applied on segmented sequences that are extracted automatically. Segments are subject to error due to the existence of irrelevant data and difficulties in how segmentation is applied. This negatively affects the accuracy on the classification task. In addition, the data generated from the network is streamed in nature, and big data techniques need to be utilized. In this paper, we propose a model to improve Activity Recognition in smart homes. The proposed technique is based on defining a profile for each activity from training datasets. The profile will be used to induce extra features and will help in distinguishing residents’ activities (fingerprinting). To validate our model, real datasets have been used for the experiments, and results show a significant enhancement in accuracy, compared with traditional techniques.}
}
@article{LUO2019100926,
title = {Development of an IoT-based big data platform for day-ahead prediction of building heating and cooling demands},
journal = {Advanced Engineering Informatics},
volume = {41},
pages = {100926},
year = {2019},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2019.100926},
url = {https://www.sciencedirect.com/science/article/pii/S1474034619301855},
author = {X.J. Luo and Lukumon O. Oyedele and Anuoluwapo O. Ajayi and Chukwuka G. Monyei and Olugbenga O. Akinade and Lukman A. Akanbi},
keywords = {Day-ahead prediction, Clustering, Artificial neural network, Building heating and cooling demand, Internet of Things, Big data},
abstract = {The emerging technologies of the Internet of Things (IoT) and big data can be utilised to derive knowledge and support applications for energy-efficient buildings. Effective prediction of heating and cooling demands is fundamental in building energy management. In this study, a 4-layer IoT-based big data platform is developed for day-ahead prediction of building energy demands, while the core part is the hybrid machine learning-based predictive model. The proposed energy demand predictive model is based on the hybrids of k-means clustering and artificial neural network (ANN). Due to different temperatures of walls, windows, grounds, roofs and indoor air, various IoT sensors are installed at different locations of the building. To determine the input variables to the hybrid machine learning-based predictive model, correlation analysis is adopted. Through clustering analysis, the characteristic patterns of daily weather profile are identified. Thus, the annual profile is classified into several featuring groups. Each group of weather profile, along with IoT sensor readings, building operating schedules as well as heating and cooling demands, is used to train the sub-ANN predictive models. Due to the involvement of IoT sensors, the overall prediction accuracy can be improved. It is found that the mean absolute percentage error of energy demands prediction is 3% and 8% in training and testing cases, respectively.}
}
@article{LE2021,
title = {BrainyEdge: An AI-enabled framework for IoT edge computing},
journal = {ICT Express},
year = {2021},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2021.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S2405959521001727},
author = {Kim-Hung Le and Khanh-Hoi Le-Minh and Huy-Tan Thai},
keywords = {AI-enabled framework, Edge computing, Artificial Intelligence, Smart IoT},
abstract = {Along with the proliferation of the Internet of Things (IoT) and the surge in the use of artificial intelligence (AI), Edge Computing has proved considerable success in reducing latency, network traffic consumption, and security risks. The convergence of AI and Edge Computing, emerging a brand-new paradigm called edge intelligence, has been expected to unleash the full potential of intelligent IoT services. Unfortunately, integrating AI and Edge Computing into IoT is highly challenging due to the concerns over IoT device performance, energy efficiency, and privacy. In this paper, we present brainyEdge, an AI-enabled framework for edge devices able to jointly satisfy the Quality of Experience (QoE) criteria of IoT applications. We enhanced the intelligence of AI models operating at edges by designing a learning procedure consisting of transfer learning and incremental learning to dynamically retrain the models with personalized and incremental data locally stored. These data are classified into private data permanently stored in edges and public data shared in the cloud. This increases the edge-cloud collaboration level while preserving data privacy. To minimize the network cost of deploying the models to edge devices, we developed a lightweight deployment paradigm supporting cloud-compression and edge-decompression based on a user-desired compression ratio. Our prototype-based evaluation results indicate the superiority of brainyEdge over a typical edge-cloud paradigm.}
}
@article{THAKKAR202195,
title = {Fusion in stock market prediction: A decade survey on the necessity, recent developments, and potential future directions},
journal = {Information Fusion},
volume = {65},
pages = {95-107},
year = {2021},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2020.08.019},
url = {https://www.sciencedirect.com/science/article/pii/S1566253520303481},
author = {Ankit Thakkar and Kinjal Chaudhari},
keywords = {Stock market prediction, Information fusion, Feature fusion, Model fusion, Machine learning, Deep learning},
abstract = {Investment in a financial market is aimed at getting higher benefits; this complex market is influenced by a large number of events wherein the prediction of future market dynamics is challenging. The investors’ etiquettes towards stock market may demand the need of studying various associated factors and extract the useful information for reliable forecasting. Fusion can be considered as an approach to integrate data or characteristics, in general, and enhance the prediction based on the combinational approach that can aid each other. We conduct a systematic approach to present a survey for the years 2011–2020 by considering articles that have used fusion techniques for various stock market applications and broadly categorize them into information fusion, feature fusion, and model fusion. The major applications of stock market include stock price and trend prediction, risk analysis and return forecasting, index prediction, as well as portfolio management. We also provide an infographic overview of fusion in stock market prediction and extend our survey for other finely addressed financial prediction problems. Based on our surveyed articles, we provide potential future directions and concluding remarks on the significance of applying fusion in stock market.}
}
@article{JIN2020112412,
title = {Artificial intelligence biosensors: Challenges and prospects},
journal = {Biosensors and Bioelectronics},
volume = {165},
pages = {112412},
year = {2020},
issn = {0956-5663},
doi = {https://doi.org/10.1016/j.bios.2020.112412},
url = {https://www.sciencedirect.com/science/article/pii/S0956566320304061},
author = {Xiaofeng Jin and Conghui Liu and Tailin Xu and Lei Su and Xueji Zhang},
keywords = {Wearable biosensor, Artificial intelligence, Biomarker, Wireless communication, Machine learning, Healthcare},
abstract = {Artificial intelligence (AI) and wearable sensors are two essential fields to realize the goal of tailoring the best precision medicine treatment for individual patients. Integration of these two fields enables better acquisition of patient data and improved design of wearable sensors for monitoring the wearers' health, fitness and their surroundings. Currently, as the Internet of Things (IoT), big data and big health move from concept to implementation, AI-biosensors with appropriate technical characteristics are facing new opportunities and challenges. In this paper, the most advanced progress made in the key phases for future wearable and implantable technology from biosensing, wearable biosensing to AI-biosensing is summarized. Without a doubt, material innovation, biorecognition element, signal acquisition and transportation, data processing and intelligence decision system are the most important parts, which are the main focus of the discussion. The challenges and opportunities of AI-biosensors moving forward toward future medicine devices are also discussed.}
}
@article{ZENG2022102780,
title = {Visibility graph entropy based radiometric feature for physical layer identification},
journal = {Ad Hoc Networks},
volume = {127},
pages = {102780},
year = {2022},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2022.102780},
url = {https://www.sciencedirect.com/science/article/pii/S1570870522000014},
author = {Shuiguang Zeng and Yin Chen and Xufei Li and Jinxiao Zhu and Yulong Shen and Norio Shiratori},
keywords = {Physical layer identification, Visibility graph, Machine learning, Wireless security, Radiometric features, Wireless device identification},
abstract = {Emerging physical layer identification methods have demonstrated the capability to complement and enhance the device authentication of Internet of Things networks by exploiting the uncontrollable, unclonable, and unforgeable radiometric features resulted from randomly generated hardware imperfection in wireless devices. Multiple feature-based identification has proven an efficient and feasible approach to improving identification performance. At the same time, the lack of radiometric features effective for device identification is a major problem. Most of the existing features are derived from the view of the time, frequency, or phase domain. In this study, we explore the graph domain of wireless frame’s preambles and propose a new radiometric feature called normalized horizontal visibility graph Shannon entropy (HVGE). At first, we introduce a preprocessing consisting of sample truncation and downsampling to enable the adjustment between the computational time of visibility graph (VG) conversion and the identification performance. Secondly, we propose the calculation method of the new HVGE feature from the VG representation. Finally, an experimental study using 50 off-the-shelf wireless devices was conducted to investigate the impact of the preprocessing parameters and the effect of noise and feature combinations on the identification performance gain.}
}
@article{AGUILAR2021111530,
title = {A systematic literature review on the use of artificial intelligence in energy self-management in smart buildings},
journal = {Renewable and Sustainable Energy Reviews},
volume = {151},
pages = {111530},
year = {2021},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2021.111530},
url = {https://www.sciencedirect.com/science/article/pii/S136403212100808X},
author = {J. Aguilar and A. Garces-Jimenez and M.D. R-Moreno and Rodrigo García},
keywords = {Energy management system, Autonomous management architecture, Smart building, Artificial intelligence, Systematic literature review, Smart grid},
abstract = {Buildings are one of the main consumers of energy in cities, which is why a lot of research has been generated around this problem. Especially, the buildings energy management systems must improve in the next years. Artificial intelligence techniques are playing and will play a fundamental role in these improvements. This work presents a systematic review of the literature on researches that have been done in recent years to improve energy management systems for smart building using artificial intelligence techniques. An originality of the work is that they are grouped according to the concept of “Autonomous Cycles of Data Analysis Tasks”, which defines that an autonomous management system requires specialized tasks, such as monitoring, analysis, and decision-making tasks for reaching objectives in the environment, like improve the energy efficiency. This organization of the work allows us to establish not only the positioning of the researches, but also, the visualization of the current challenges and opportunities in each domain. We have identified that many types of researches are in the domain of decision-making (a large majority on optimization and control tasks), and defined potential projects related to the development of autonomous cycles of data analysis tasks, feature engineering, or multi-agent systems, among others.}
}
@article{MARINO2020121926,
title = {Unsupervised learning for deploying smart charging public infrastructure for electric vehicles in sprawling cities},
journal = {Journal of Cleaner Production},
volume = {266},
pages = {121926},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2020.121926},
url = {https://www.sciencedirect.com/science/article/pii/S0959652620319739},
author = {Carlos Antonio Marino and Mohammad Marufuzzaman},
keywords = {Electric vehicle, Charging stations, Stochastic optimization, Clustering, Sprawling, Smart cities},
abstract = {This paper presents a novel methodology to study the deployment of public smart charging stations (CS) of electric vehicles (EV) in a sprawling Latin American city. A relevant difference between developed and emerging economies is the reduced access to home charging in emerging economies, which is the case in Latin American cities. Thus, developing public charging stations represents a crucial factor in the mass adoption of EVs by road commuters. We develop herein a methodology for optimizing the deployment of smart charging stations under the sprawling phenomenon perspective. Our method comprises two steps. In step one, we applied principal component analysis (PCA) to facilitate the analysis of a sprawling city, and then we define candidates for potential locations from ‘demand clusters’ within an urbanized area, by K-means clustering analysis. In the second step, a stochastic programming model was employed to optimize the integration of infrastructural facilities with distributed energy resources (DERs) and EV charging stations using a collaborative strategy to minimize its energy consumption cost under demand uncertainty. We demonstrate the capabilities of this approach through a case study in the city of Lima. Experimental results reveal managerial insights for different stakeholders (i.e., government, industry, academia, and civil society) to promote policies, investment, and incentives.}
}
@article{YAMAN2021104388,
title = {Automated book location and classification method using RFID tags for smart libraries},
journal = {Microprocessors and Microsystems},
volume = {87},
pages = {104388},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2021.104388},
url = {https://www.sciencedirect.com/science/article/pii/S0141933121005354},
author = {Orhan Yaman and Turker Tuncer and Fatih Ertam},
keywords = {Smart libraries, RFID based book location classification, MSPCA, ImRMR, Bagged Tree},
abstract = {Purpose
There are hundreds of thousands of books in libraries, causing problems in searching and counting books. To overcome these problems, this research presents a received signal strength indicator (RSSI) dataset and a new automated book location classification model using the RSSI dataset.
Materials and method
In this study, a RSSI signals dataset was collected using a mobile vehicle from 3279 books. These books are randomly placed on six benches, 24 cabinets, and 144 racks. The primary objective of this work is to detect book position automatically using a simple learning model. Thus, a new automated book position detection model is presented and this model is tested on the RSSI dataset collected. (i) Multiscale principal component analysis (MSPCA) is considered a pre-processing method. (ii) Iterative minimum redundancy maximum relevance (ImRMR) algorithm was used to select the most informative features automatically. (iii) The most informative features selected are classified using the Decision Trees (DT) and Ensemble Bagged Trees (BT) algorithms. Three cases are defined according to bench, cabinet, and rack.
Results
The recommended model yielded 97.34% 98.26% and 93.1% overall accuracies using the bench, cabinet, and rack cases consecutively deploying the BT classifier with 10-fold cross-validation.
Conclusions
The presented book position classification model reached above 90% for all cases and these results calculated and finding clearly demonstrates that this model is ready to use in a big library for book position detection.}
}
@article{XUE2019100965,
title = {BIM reconstruction from 3D point clouds: A semantic registration approach based on multimodal optimization and architectural design knowledge},
journal = {Advanced Engineering Informatics},
volume = {42},
pages = {100965},
year = {2019},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2019.100965},
url = {https://www.sciencedirect.com/science/article/pii/S1474034619305385},
author = {Fan Xue and Weisheng Lu and Ke Chen and Christopher J. Webster},
keywords = {Building information model, Architectural repetition, Multimodal optimization, Semantic enrichment, 3D point cloud},
abstract = {Reconstructing semantically rich building information model (BIM) from 2D images or 3D point clouds represents a research realm that is gaining increasing popularity in architecture, engineering, and construction. Researchers have found that architectural design knowledge, such as symmetry, planarity, parallelism, and orthogonality, can be utilized to improve the effectiveness of such BIM reconstruction. Following this line of enquiry, this paper aims to develop a novel semantic registration approach for complicated scenes with repetitive, irregular-shaped objects. The approach first formulates the architectural repetition as the multimodality in mathematics. Thus, the reconstruction of repetitive objects becomes a multimodal optimization (MMO) problem of registering BIM components which have accurate geometries and rich semantics. Then, the topological information about repetition and symmetry in the reconstructed BIM is recognized and regularized for BIM semantic enrichment. A university lecture hall case, consisting of 1.9 million noisy points of 293 chairs, was selected for an experiment to validate the proposed approach. Experimental results showed that a BIM was satisfactorily created (achieving about 90% precision and recall) automatically in 926.6 s; and an even more satisfactory BIM achieved 99.3% precision and 98.0% recall with detected semantic and topological information under the minimal effort of human intervention in 228.4 s. The multimodality model of repetitive objects, the repetition detection and regularization for BIM, and satisfactory reconstruction results in the presented approach can contribute to methodologies and practices in multiple disciplines related to BIM and smart city.}
}
@article{JIN202017047,
title = {Motion Planning at Intersections with Event-driven Recurrent Q-Learning},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {17047-17052},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.1533},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320321285},
author = {Xinze Jin and Qing-Shan Jia and Dongchun Ren and Yu Bai},
keywords = {motion planning, reinforcement learning, event-driven, recurrency},
abstract = {Autonomous driving at intersection has great potential on control for smart cities to relieve the energy consumption and transportation congestion. However, it remains challenging to find promising behavior sequence in multi-agent environment with uncertain participation of obstacles. This work develops Event-driven Recurrent Q-Learning (ERQL) to focus on the motion planning task towards intersection scenarios to conclude a sample path with safety and efficiency. We elaborate the definition of events to capture the environment structure and introduce recurrency to process sequence model. Besides, we incorporate collision-avoidance into the event-driven framework and design a mechanism to extract recurrent feature from replay buffer in Q-learning framework. Simulation results show that the developed off-line learning procedure can adapt to on-line decision making towards uncertain agent behaviors.}
}
@article{NEILSON201935,
title = {Systematic Review of the Literature on Big Data in the Transportation Domain: Concepts and Applications},
journal = {Big Data Research},
volume = {17},
pages = {35-44},
year = {2019},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2019.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S2214579617303866},
author = {Alex Neilson and  Indratmo and Ben Daniel and Stevanus Tjandra},
keywords = {Big Data, Smart city, Intelligent transportation system, Connected vehicle, Road traffic safety, Vision Zero},
abstract = {Research in Big Data and analytics offers tremendous opportunities to utilize evidence in making decisions in many application domains. To what extent can the paradigms of Big Data and analytics be used in the domain of transport? This article reports on an outcome of a systematic review of published articles in the last five years that discuss Big Data concepts and applications in the transportation domain. The goal is to explore and understand the current research, opportunities, and challenges relating to the utilization of Big Data and analytics in transportation. The review shows the potential of Big Data and analytics to garner insights and improve transportation systems through the analysis of various forms of data obtained from traffic monitoring systems, connected vehicles, crowdsourcing, and social media. We discuss some platforms and software architecture for the transport domain, along with a wide array of storage, processing, and analytical techniques, and describe challenges associated with the implementation of Big Data and analytics. This review contributes broadly to the various ways in which cities can utilize Big Data in transportation to guide the creation of sustainable and safer traffic systems. Since research in Big Data and transportation is, by and large, at infancy, this article does not prescribe recommendations to the various challenges identified, which also constitutes the limitation of the article.}
}
@article{KONIG2021101688,
title = {The legitimacy gap of algorithmic decision-making in the public sector: Why it arises and how to address it},
journal = {Technology in Society},
volume = {67},
pages = {101688},
year = {2021},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101688},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21001639},
author = {Pascal D. König and Georg Wenzelburger},
keywords = {Algorithmic decision-making, Public services, Smart city, Legitimacy, Stakeholder participation, Accountability},
abstract = {Algorithmic decision-making (ADM) systems are increasingly adopted by the state to support various administrative functions and improve the effectiveness and efficiency of public services, such as in unemployment services or policing. While these systems create challenges of opaqueness, unfairness, and value trade-offs, the present paper argues that a more fundamental challenge lies in the way these systems alter the epistemic bases of decision-making. It contributes to the literature by highlighting why procedural standards of legitimacy in operative decision-making no longer suffice for certain applications and by discussing how the resulting legitimacy gap can be addressed through stakeholder involvement. By adapting research on participatory technology assessments to the particularities of ADM system design, it is possible to identify the core challenges of such a stakeholder process and the necessary steps to deal with them.}
}
@article{BAUCAS2020102013,
title = {Using cloud and fog computing for large scale IoT-based urban sound classification},
journal = {Simulation Modelling Practice and Theory},
volume = {101},
pages = {102013},
year = {2020},
note = {Modeling and Simulation of Fog Computing},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2019.102013},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X19301431},
author = {Marc Jayson Baucas and Petros Spachos},
keywords = {Fog computing, Edge computing, Cloud computing, Large scale internet of things, Urban sound classification.},
abstract = {The Internet of Things (IoT) has become the forefront of bridging different technologies together. It brings rise to online computational services that make mundane tasks convenient. However, the volume of devices connecting to the network started to increase. In turn, services that thrived on centralized storage are being strained and overloaded. As applications and software advances, processing and computational power become a concern to technology companies. With data risks and large numbers of connected devices, cloud computing has become outdated. Devices are forced to commit unnecessary expenses to stay relevant in the market due to the increase in software complexity. This need for change resulted in the introduction of edge computing. Edge computing distributes the computational strain between the server and the devices. This contribution allows the cloud to accommodate more users and devices are no longer in need to make significant changes to their design every so often. Many real-time applications have evolved to require high amounts of processing power to execute. For example, sound classification comes with massive computational needs due to its affiliation with neural networks and deep learning. This paper aims to create a feasible and deployable real-time sound classification system. There were three configurations tested in this paper. The results of our experiments show that cloud computing and edge computing alone cannot cater to a technological market that is exponentially growing in size and complexity. However, the same results show promise in finding optimal configurations in terms of a combination of end device power consumption, application runtime and server latency to systems instead of focusing on a single model. Overall, it is better to take into consideration the strengths and weaknesses of each computing architecture. In finding a reasonable configuration balance, lower power consumption in end devices and lesser computational strain on cloud servers is a must.}
}
@article{ZUIDERWIJK2021101577,
title = {Implications of the use of artificial intelligence in public governance: A systematic literature review and a research agenda},
journal = {Government Information Quarterly},
volume = {38},
number = {3},
pages = {101577},
year = {2021},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2021.101577},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X21000137},
author = {Anneke Zuiderwijk and Yu-Che Chen and Fadi Salem},
keywords = {Public governance, Artificial intelligence, Artificial intelligence for government, Public sector, Digital government, Systematic literature review, Research agenda},
abstract = {To lay the foundation for the special issue that this research article introduces, we present 1) a systematic review of existing literature on the implications of the use of Artificial Intelligence (AI) in public governance and 2) develop a research agenda. First, an assessment based on 26 articles on this topic reveals much exploratory, conceptual, qualitative, and practice-driven research in studies reflecting the increasing complexities of using AI in government – and the resulting implications, opportunities, and risks thereof for public governance. Second, based on both the literature review and the analysis of articles included in this special issue, we propose a research agenda comprising eight process-related recommendations and seven content-related recommendations. Process-wise, future research on the implications of the use of AI for public governance should move towards more public sector-focused, empirical, multidisciplinary, and explanatory research while focusing more on specific forms of AI rather than AI in general. Content-wise, our research agenda calls for the development of solid, multidisciplinary, theoretical foundations for the use of AI for public governance, as well as investigations of effective implementation, engagement, and communication plans for government strategies on AI use in the public sector. Finally, the research agenda calls for research into managing the risks of AI use in the public sector, governance modes possible for AI use in the public sector, performance and impact measurement of AI use in government, and impact evaluation of scaling-up AI usage in the public sector.}
}
@article{BALASUBRAMANIYAN202118,
title = {Applications of Internet of Things for smart farming – A survey},
journal = {Materials Today: Proceedings},
volume = {47},
pages = {18-24},
year = {2021},
note = {NCRABE},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.03.480},
url = {https://www.sciencedirect.com/science/article/pii/S2214785321025359},
author = {M. Balasubramaniyan and C. Navaneethan},
keywords = {Internet of Things, Crop, Sensor, Water, Soil, Agriculture, Seed, Wireless sensor network.},
abstract = {In today’s world agriculture is very important in farmer and people’s life, because without food production people cannot able to live. Farmer’s day-by-day make food production in the world. This food production process has many difficulties in farmer’s normal life in current world. The farmer’s facing the difficulties in manually are monitoring the water, monitoring the human works, monitoring the animals, monitoring the dangerous animals, cost, and etc. These difficulties will be overcome through IoT technologies. This technology used to monitor the water through sensor, monitoring the normal animals and dangerous animals through sensor because farmer’s avoid risk and disease, and finally save and improve the farmer’s production time, production cost, and health. The researchers are searching technological key to improve the agriculture existing services by setting technology of IoT. In this paper, based on the survey paper, to help the farmers for increase the crop production between high and low quality through various algorithms. This algorithm used to find the best quality, and used to implement the manage climate change, soil erosion, and availability of water efficiently in various sensors. Finally, discuss about the trends and platform of the agriculture with various applications and finding the research gap.}
}
@article{AHMAD2021125834,
title = {Artificial intelligence in sustainable energy industry: Status Quo, challenges and opportunities},
journal = {Journal of Cleaner Production},
volume = {289},
pages = {125834},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.125834},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621000548},
author = {Tanveer Ahmad and Dongdong Zhang and Chao Huang and Hongcai Zhang and Ningyi Dai and Yonghua Song and Huanxin Chen},
keywords = {Artificial intelligence, Renewable energy, Energy demand, Decision making, Big data, Energy digitization},
abstract = {The energy industry is at a crossroads. Digital technological developments have the potential to change our energy supply, trade, and consumption dramatically. The new digitalization model is powered by the artificial intelligence (AI) technology. The integration of energy supply, demand, and renewable sources into the power grid will be controlled autonomously by smart software that optimizes decision-making and operations. AI will play an integral role in achieving this goal. This study focuses on the use of AI techniques in the energy sector. This study aims to present a realistic baseline that allows researchers and readers to compare their AI efforts, ambitions, new state-of-the-art applications, challenges, and global roles in policymaking. We covered three major aspects, including: i) the use of AI in solar and hydrogen power generation; (ii) the use of AI in supply and demand management control; and (iii) recent advances in AI technology. This study explored how AI techniques outperform traditional models in controllability, big data handling, cyberattack prevention, smart grid, IoT, robotics, energy efficiency optimization, predictive maintenance control, and computational efficiency. Big data, the development of a machine learning model, and AI will play an important role in the future energy market. Our study’s findings show that AI is becoming a key enabler of a complex, new and data-related energy industry, providing a key magic tool to increase operational performance and efficiency in an increasingly cut-throat environment. As a result, the energy industry, utilities, power system operators, and independent power producers may need to focus more on AI technologies if they want meaningful results to remain competitive. New competitors, new business strategies, and a more active approach to customers would require informed and flexible regulatory engagement with the associated complexities of customer safety, privacy, and information security. Given the pace of development in information technology, AI and data analysis, regulatory approvals for new services and products in the new Era of digital energy markets can be enforced as quickly and efficiently as possible.}
}
@article{MARTI2021,
title = {Charging stations and mobility data generators for agent-based simulations},
journal = {Neurocomputing},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.06.098},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221016532},
author = {Pasqual Martí and Jaume Jordán and Javier Palanca and Vicente Julian},
keywords = {Multi-agent system, Simulation, Transportation, Electric vehicle, Smart city, Urban fleets},
abstract = {Current traffic congestion and the resulting carbon emissions are two of the main problems threatening the sustainability of modern cities. The challenges facing today’s cities focus primarily on the optimization of traffic flow and the transition to electric vehicles. The latter aspect implies the need for an adequate deployment of the infrastructure of charging stations. The inherent complexity in today’s cities and the difficulty in implementing new policies whose benefits are difficult to measure and predict has led in recent years to consider the enormous potential of simulation tools and in particular of the agent-based simulation (ABS). ABS allows the specification of complex models that reflect the complexity and dynamism of urban mobility. Current technology in ABS has evolved and matured sufficiently to provide very sophisticated tools but lacking facilities for a flexible and realistic generation of input data in the execution of the experiments. In line with this, this paper introduces two configurable generators that automatize the creation of experiments in agent-based simulations. The generators have been developed with the SimFleet simulation tool enhancing the simulation of realistic movements and location of vehicles, passengers and other users of the urban traffic system within a city. The generators proved to be useful for comparing different distributions of locations as well as different agent movement behaviors based on real city data.}
}
@article{KARAGIANNIS2021101316,
title = {Distributed algorithms based on proximity for self-organizing fog computing systems},
journal = {Pervasive and Mobile Computing},
volume = {71},
pages = {101316},
year = {2021},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2020.101316},
url = {https://www.sciencedirect.com/science/article/pii/S1574119220301437},
author = {Vasileios Karagiannis and Stefan Schulte},
keywords = {Fog computing, Edge computing, Hierarchical structures, Flat structures, Self-organization, Internet of Things, IoT},
abstract = {Various performance benefits such as low latency and high bandwidth have turned fog computing into a well-accepted extension of the cloud computing paradigm. Many fog computing systems have been proposed so far, consisting of distributed compute nodes which are often organized hierarchically in layers. To achieve low latency, these systems commonly rely on the assumption that the nodes of adjacent layers reside close to each other. However, this assumption may not hold in fog computing systems that span over large geographical areas, due to the wide distribution of the nodes. To avoid relying on this assumption, in this paper we design distributed algorithms whereby the compute nodes measure the network proximity to each other, and self-organize into a hierarchical or a flat structure accordingly. Moreover, we implement these algorithms on geographically distributed compute nodes, and we experiment with image processing and smart city use cases. Our results show that compared to alternative methods, the proposed algorithms decrease the communication latency of latency-sensitive processes by 27%–43%, and increase the available network bandwidth by 36%–86%. Furthermore, we analyze the scalability of our algorithms, and we show that a flat structure (i.e., without layers) scales better than the commonly used layered hierarchy due to generating less overhead when the size of the system grows.}
}
@article{DEEBAK2022293,
title = {A robust and distributed architecture for 5G-enabled networks in the smart blockchain era},
journal = {Computer Communications},
volume = {181},
pages = {293-308},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.10.015},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421003935},
author = {B.D. Deebak and Fadi AL-Turjman},
keywords = {Decentralization, Blockchain, Privacy preservation, Smart contracts, Key exposure},
abstract = {Internet-of-Things (IoT) integrates ubiquitous computing to extend the Internet connectivity to the various application environments such as e-Health, smart cities, cyber–physical systems, etc. It connects the real-time objects to experience high-speed data transfer in 5G network deployment. It may periodically collect and process the data to control the access mechanism that utilizes a dedicated network protocol to fetches the information from different network domains. However, most of the access mechanisms cannot be applicable to the industrial application as it is based on a centralized architecture. This architecture has a complexity of computation overhead to deteriorate the performance of device-to-device (D2D) communication. In the industrial sectors, security and privacy preservation are majorly concerned to perform expensive operations and to prevent malicious cloud servers. Moreover, the real-time objects should be coordinated to optimize communication efficiencies. Thus, this paper presents a robust blockchain-based lightweight distributed architecture (RB-LDA) for 5G-enabled networks. The proposed RB-LDA authenticates the device access that advertises genuine data possession to restrict the key exposure. Moreover, the qualitative analysis proves the identity management continuously monitors the activities of IoT devices to perform a better auditing process. Above all, the experimental analysis shows that the proposed RB-LDA can achieve better data privacy to preserve sensitive information against the trusted third parties.}
}
@article{BAO2021103624,
title = {FPGA processor and visual keyword matching to optimize feature recognition of tourism resources},
journal = {Microprocessors and Microsystems},
volume = {80},
pages = {103624},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2020.103624},
url = {https://www.sciencedirect.com/science/article/pii/S0141933120307717},
author = {Chunyu Bao},
keywords = {Hardware-software co-simulation, FPGA, Feature extraction, Machine learning, Real-time classification, K-nearest neighbors},
abstract = {Confirm information from the web page is a critical issue to support tourism activities. These steps are based on how the analysis and synthesis of a web page article grammatical structure. Semantic structure is a single sentence or a fragment of the marked text. This is a characteristic of developing useful tourist information from a web page to identify the way. Identification, development, and utilization of tourism resources have proved inseparable from the earth sciences. In this case, the literature does not explain Earth's tourism resources' characteristics from a scientific point of almost complete. Still, it is only mentioned in the discussion of the operation of tourism resources and tourism. Machine learning algorithms are used in the proposed architecture, which resembles a field-programmable gate array to achieve. FPGA implementation of a fixed point, comparing classification performance.}
}
@article{SHARIFI2020142391,
title = {The COVID-19 pandemic: Impacts on cities and major lessons for urban planning, design, and management},
journal = {Science of The Total Environment},
volume = {749},
pages = {142391},
year = {2020},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2020.142391},
url = {https://www.sciencedirect.com/science/article/pii/S0048969720359209},
author = {Ayyoob Sharifi and Amir Reza Khavarian-Garmsir},
keywords = {COVID-19, Smart cities, Environmental factors, Air quality, Urban planning, Pandemics},
abstract = {Since the early days of the COVID-19 crisis the scientific community has constantly been striving to shed light on various issues such as the mechanisms driving the spread of the virus, its environmental and socio-economic impacts, and necessary recovery and adaptation plans and policies. Given the high concentration of population and economic activities in cities, they are often hotspots of COVID-19 infections. Accordingly, many researchers are struggling to explore the dynamics of the pandemic in urban areas to understand impacts of COVID-19 on cities. In this study we seek to provide an overview of COVID-19 research related to cities by reviewing literature published during the first eight months after the first confirmed cases were reported in Wuhan, China. The main aims are to understand impacts of the pandemic on cities and to highlight major lessons that can be learned for post-COVID urban planning and design. Results show that, in terms of thematic focus, early research on the impacts of COVID-19 on cities is mainly related to four major themes, namely, (1) environmental quality, (2) socio-economic impacts, (3) management and governance, and (4) transportation and urban design. While this indicates a diverse research agenda, the first theme that covers issues related to air quality, meteorological parameters, and water quality is dominant, and the others are still relatively underexplored. Improvements in air and water quality in cities during lockdown periods highlight the significant environmental impacts of anthropogenic activities and provide a wake-up call to adopt environmentally friendly development pathways. The paper also provides other recommendations related to the socio-economic factors, urban management and governance, and transportation and urban design that can be used for post-COVID urban planning and design. Overall, existing knowledge shows that the COVID-19 crisis entails an excellent opportunity for planners and policy makers to take transformative actions towards creating cities that are more just, resilient, and sustainable.}
}
@article{SUN202094,
title = {A dual-domain deep lattice network for rapid MRI reconstruction},
journal = {Neurocomputing},
volume = {397},
pages = {94-107},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.01.063},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220301156},
author = {Liyan Sun and Yawen Wu and Binglin Shu and Xinghao Ding and Congbo Cai and Yue Huang and John Paisley},
keywords = {Compressed sensing, Magnetic resonance imaging, Dual domain, Deep neural network},
abstract = {Compressed sensing is utilized with the aims of reconstructing an MRI using a fraction of measurements to accelerate magnetic resonance imaging called compressed sensing magnetic resonance imaging (CS-MRI). Conventional optimization-based CS-MRI methods use random under-sampling patterns and model the MRI data in the image domain as the classic CS-MRI paradigm. Instead, we design a uniform under-sampling strategy and explore the potential of modeling the MRI data directly in the measured Fourier domain. We propose a dual-domain deep lattice network (DD-DLN) for CS-MRI with variable density uniform under-sampling. We train the networks to learn the mapping between both image and frequency domains. We observe the dual networks have complementary advantages, which motivates their combination via a lattice structure. Experiments show that the proposed DD-DLN model provides promising performance in CS-MRI under the designed variable density uniform under-sampling.}
}
@article{FAN2021102612,
title = {High-integrity based cooperative file transmission at urban intersections using pure V2V communication},
journal = {Ad Hoc Networks},
volume = {122},
pages = {102612},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102612},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521001396},
author = {Xiying Fan and Yuekun Lu and Baolin Liu and Di Liu and Shaojie Wen and Bin Fu},
keywords = {VANETs, V2V, File integrity, Cooperative file transmission},
abstract = {Vehicular Ad Hoc Networks (VANETs) provide safety management and entertainment services in smart city scenarios. However, due to the highly time-varying network topology caused by vehicles’ movement and non-line-of-sight (NLOS) areas in complex urban environment, the connection time between vehicles might be very short, leading to limited transmission capacity between vehicles. As a result, large file transmission such as online video sharing might be unavailable. To alleviate this issue, we study high-integrity based file transmission using pure vehicle-to-vehicle (V2V) communication at urban intersections. First, we develop the analytical models to evaluate file transmission at intersections, including vehicle mobility model, connection time prediction model, and V2V communication model. Then, we derive the relationship between transmission capacity and vehicles’ mobility. Based upon this analysis, we propose a cooperative file transmission strategy for the transmitting vehicle, which helps transmit the target file to the receiving vehicle. The proposed strategy includes three phases: transmission capacity evaluation, cluster establishment, and cooperative file transmission. By taking advantage of the cluster characteristics, the strategy can achieve file transmission with high integrity. Through extensive simulations, we demonstrate the accuracy of the proposed system model which matches our analysis well, and show the effectiveness of the proposed strategy by comparing with other file transmission strategies in aspects of transmission success rate and data transmission volume.}
}
@article{ALBADARNEH2018388,
title = {Cooperative mobile edge computing system for VANET-based software-defined content delivery},
journal = {Computers & Electrical Engineering},
volume = {71},
pages = {388-397},
year = {2018},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2018.07.021},
url = {https://www.sciencedirect.com/science/article/pii/S0045790617337187},
author = {Jafar Al-Badarneh and Yaser Jararweh and Mahmoud Al-Ayyoub and Ramon Fontes and Mohammad Al-Smadi and Christian Rothenberg},
keywords = {Vehicular Ad-hoc networks, Content delivery service, Mobile edge computing, Software defined systems, Internet of things, Intelligent transportation systems},
abstract = {Next-generation smart cities and Internet of Things (IoT) are getting more mature in terms of services and infrastructure requirements. Multiple smart vehicle applications are being conceived these days, including road traffic, road safety and infotainment, all of which are suffering from the WAN-latency problem. In this paper, we propose a Vehicular Adhoc Network (VANET)-based Software-Defined Edge Computing infrastructure supporting content delivery services among connected vehicles. The proposed approach leverages network base stations to embed mobile edge computing (MEC) services closer to the vehicles. Our approach can enable the delivery of more competitive services with reduced-latency by utilizing cooperative MEC search strategy for vehicle to infrastructure (V2I) communications as well as utilizing vehicle-level caching for vehicle to vehicle (V2V) communications between peers. The framework prototype has been implemented as a clean extension of the Mininet-WiFi emulator. Preliminary results serve as validation of the proposed framework and point out the potential benefits of the approach in mitigating WAN-latency in VANET.}
}
@article{GILL2019100118,
title = {Transformative effects of IoT, Blockchain and Artificial Intelligence on cloud computing: Evolution, vision, trends and open challenges},
journal = {Internet of Things},
volume = {8},
pages = {100118},
year = {2019},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2019.100118},
url = {https://www.sciencedirect.com/science/article/pii/S2542660519302331},
author = {Sukhpal Singh Gill and Shreshth Tuli and Minxian Xu and Inderpreet Singh and Karan Vijay Singh and Dominic Lindsay and Shikhar Tuli and Daria Smirnova and Manmeet Singh and Udit Jain and Haris Pervaiz and Bhanu Sehgal and Sukhwinder Singh Kaila and Sanjay Misra and Mohammad Sadegh Aslanpour and Harshit Mehta and Vlado Stankovski and Peter Garraghan},
keywords = {Cloud computing, Quality of Service, Cloud applications, Cloud paradigms and technologies, IoT, Blockchain, Artificial Intelligence},
abstract = {Cloud computing plays a critical role in modern society and enables a range of applications from infrastructure to social media. Such system must cope with varying load and evolving usage reflecting societies’ interaction and dependency on automated computing systems whilst satisfying Quality of Service (QoS) guarantees. Enabling these systems are a cohort of conceptual technologies, synthesized to meet demand of evolving computing applications. In order to understand current and future challenges of such system, there is a need to identify key technologies enabling future applications. In this study, we aim to explore how three emerging paradigms (Blockchain, IoT and Artificial Intelligence) will influence future cloud computing systems. Further, we identify several technologies driving these paradigms and invite international experts to discuss the current status and future directions of cloud computing. Finally, we proposed a conceptual model for cloud futurology to explore the influence of emerging paradigms and technologies on evolution of cloud computing.}
}
@article{CHATFIELD2019346,
title = {A framework for Internet of Things-enabled smart government: A case of IoT cybersecurity policies and use cases in U.S. federal government},
journal = {Government Information Quarterly},
volume = {36},
number = {2},
pages = {346-357},
year = {2019},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2018.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X17304847},
author = {Akemi Takeoka Chatfield and Christopher G. Reddick},
keywords = {Smart government, Internet of Things, IoT, Dynamic capabilities in sensing and responding, IoT cybersecurity policy, IoT technology policy, U.S. federal government, IoT use},
abstract = {Internet of Things (IoT) is ubiquitous in society. IoT-enabled dynamic capabilities in real-time sensing and responding can spur digital transformation in unlocking the potential of digital government into data-driven smart government capable of delivering policies and services of public interest and public value. However, the literature indicates challenges in IoT cybersecurity and systemic use across the government. There is the urgent need for IoT research on policy and use. This paper developed a framework for IoT-enabled smart government performance. We applied this framework to conduct case study analyses of digital technology policy, IoT cybersecurity policy, and IoT use in major application domains at the U.S. federal government level. The results show that some agencies were strategic and forward-thinking in funding and partnering with sub-national governments in promoting the IoT use. However, there remains a critical need for national IoT policies to promote systemic IoT use across the application domains.}
}
@article{MARTINLOPO2020107101,
title = {A literature review of IoT energy platforms aimed at end users},
journal = {Computer Networks},
volume = {171},
pages = {107101},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107101},
url = {https://www.sciencedirect.com/science/article/pii/S138912861931271X},
author = {Miguel M. Martín-Lopo and Jaime Boal and Álvaro Sánchez-Miralles},
keywords = {Internet of Things, Energy platforms, Energy middlewares, Communication protocols, Energy services, Physical layer, Server layer, Application layer, Security},
abstract = {The rising interest in connecting everything to the Internet has not gone unnoticed in the energy sector. New actors that aim to remotely monitor and control home devices such as heating, ventilation and air conditioning (HVAC), light bulbs, or distributed energy resources (e.g., batteries, PV panels…) have come into play. However, transitioning from isolated often not interoperable home automation systems to open, yet secure, solutions that integrate external sources of information and cloud computing to make a more efficient use of energy, is not trivial. It requires designing and implementing hierarchical architectures and standard solutions to facilitate interoperability, one of the challenges of cross-domain smart-city applications as no standard solution has been established yet. Even though most solutions share a set of building blocks that have fostered the appearance of Internet of Things (IoT) middlewares to accelerate development, most existing energy platforms are still tailor-made for specific applications. This paper targets three audiences. First, for those interested in using or selecting an energy platform, the study carries out a comparative analysis of some of the most popular alternatives. Second, for those that are considering building new energy platforms, this paper analyzes the necessary hierarchical blocks, and the main design options and strategies. Finally, for those interested in comparing platforms, a new set of IoT levels that evaluate the adoption of IoT technologies is proposed.}
}
@article{KORONIOTIS2019779,
title = {Towards the development of realistic botnet dataset in the Internet of Things for network forensic analytics: Bot-IoT dataset},
journal = {Future Generation Computer Systems},
volume = {100},
pages = {779-796},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.05.041},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18327687},
author = {Nickolaos Koroniotis and Nour Moustafa and Elena Sitnikova and Benjamin Turnbull},
keywords = {Bot-IoT dataset, Network flow, Network forensics, Forensics analytics},
abstract = {The proliferation of IoT systems, has seen them targeted by malicious third parties. To address this challenge, realistic protection and investigation countermeasures, such as network intrusion detection and network forensic systems, need to be effectively developed. For this purpose, a well-structured and representative dataset is paramount for training and validating the credibility of the systems. Although there are several network datasets, in most cases, not much information is given about the Botnet scenarios that were used. This paper proposes a new dataset, so-called Bot-IoT, which incorporates legitimate and simulated IoT network traffic, along with various types of attacks. We also present a realistic testbed environment for addressing the existing dataset drawbacks of capturing complete network information, accurate labeling, as well as recent and complex attack diversity. Finally, we evaluate the reliability of the BoT-IoT dataset using different statistical and machine learning methods for forensics purposes compared with the benchmark datasets. This work provides the baseline for allowing botnet identification across IoT-specific networks. The Bot-IoT dataset can be accessed at Bot-iot (2018) [1].}
}
@article{YIN202142,
title = {Multi-stage attention spatial-temporal graph networks for traffic prediction},
journal = {Neurocomputing},
volume = {428},
pages = {42-53},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.11.038},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220318312},
author = {Xueyan Yin and Genze Wu and Jinze Wei and Yanming Shen and Heng Qi and Baocai Yin},
keywords = {Attention mechanism, Graph neural networks, Traffic prediction},
abstract = {Accurate traffic prediction plays an important role in Intelligent Transportation System. This problem is very challenging due to the heterogeneity and dynamic spatio-temporal dependence of large-scale traffic data. Existing models often suffer two limitations: (1) They usually only consider one type of data in the input, or simply treat other collected time series data as features, ignoring the non-linear interactions among different series. In fact, heterogeneous data at a specific location has direct impacts on the predicted series. (2) The method based on graph convolutional network uses a fixed Laplacian matrix to model spatial correlation, without considering its dynamics. The aggregations also occur only in the neighborhood, making it difficult to capture long-range dependencies. In this paper, we propose a Multi-Stage Attention Spatial-Temporal Graph Networks (MASTGN). First, an internal attention mechanism is designed to capture the interactions among multiple time series collected by the same sensor. Second, to model the complex spatial correlations, we apply a dynamic neighborhood-based attention mechanism. Unlike the general attention-based methods that ignore the structure information of the road network, we use the adjacency relations as a prior to divide the nodes of a road network into different neighborhood sets. In this way, attention can capture spatial correlations both within the same order neighborhood, and among different neighborhoods dynamically. Furthermore, a temporal attention mechanism is used to extract the dynamic temporal dependencies. Experiments are conducted on two real traffic datasets, and the results verify the effectiveness of the proposed model.}
}
@article{ATANGANANJOCK2020105988,
title = {Evaluation of soil liquefaction using AI technology incorporating a coupled ENN / t-SNE model},
journal = {Soil Dynamics and Earthquake Engineering},
volume = {130},
pages = {105988},
year = {2020},
issn = {0267-7261},
doi = {https://doi.org/10.1016/j.soildyn.2019.105988},
url = {https://www.sciencedirect.com/science/article/pii/S0267726119302738},
author = {Pierre Guy {Atangana Njock} and Shui-Long Shen and Annan Zhou and Hai-Min Lyu},
keywords = {Differential evolution, Optimisation, t-SNE, Neural network, Liquefaction},
abstract = {This paper presents a new evolutionary neural network (ENN) algorithm coupled with the dimensionality reduction technique ‘t-distributed stochastic neighbour embedding’ (t-SNE). The ENN model features the crossbreeding of a differential evolution method and a stochastic gradient optimisation algorithm. The t-SNE is used to visualise the training and testing datasets and the ENN model performance. The proposed ENN model is applied to a relatively large soil liquefaction database. The good convergence and generalisation ability of the proposed model and the negligible misclassification results demonstrate that the proposed ENN model can provide accurate, efficient, and flexible results. The prominent and practical abilities of t-SNE to recover the structure of the initial conditions and to demonstrate the ENN model performance are discussed. This coupled approach simplifies the analysis and/or prediction of hazards for which large quantities of data are required.}
}
@article{GRYCAN2020121995,
title = {Legislative support for improving sustainable and smart electricity consumption in polish residential sector},
journal = {Journal of Cleaner Production},
volume = {266},
pages = {121995},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2020.121995},
url = {https://www.sciencedirect.com/science/article/pii/S0959652620320424},
author = {Wiktoria Grycan},
keywords = {Sustainable, Energy efficiency, Households, Renewable energy sources, Smart metering},
abstract = {Reducing energy consumption is a way to make the energy sector less invasive for the natural environment. Energy policy is essential to motivate consumers to decrease electricity consumption and should take into account the specificity of each sector (industry, households, transport). The energy policy of the member states of the European Union should consider the factors of increased demand for electricity and support solutions such as smart metering and prosumer energy. This paper provides an overview of the pro-efficiency policy of households in Poland, affecting the residential sector, and assesses the regulations implemented so far. The evaluation of the policy uses an econometric approach (congruent modelling). The impact of energy policy was determined by giving weights to individual regulations taking into account their variability in time. The created models showed a significant impact of the introduced regulations on the reduction of energy consumption and confirmed their changeable influence over time. Their time-limited impact on reducing energy consumption forces taking further actions motivating consumers to electricity saving. The review of Polish energy regulations revealed a lack of sufficient provision in the field of developing smart technology limited use of energy policy tools such as informative billing and information campaigns.}
}
@article{LI2020232,
title = {Pairwise registration of TLS point clouds by deep multi-scale local features},
journal = {Neurocomputing},
volume = {386},
pages = {232-243},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.12.074},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219317837},
author = {Wei Li and Cheng Wang and Chenglu Wen and Zheng Zhang and Congren Lin and Jonathan Li},
keywords = {MSSNet, Point cloud registration, Terrestrial laser scanning (TLS), Data augmentation, Geometric constraints},
abstract = {Because of the mechanism of TLS system, noise, outliers, various occlusions, varying cloud densities, etc. inevitably exist in the collection of TLS point clouds. To achieve automatic TLS point cloud registration, many methods, based on the hand-crafted features of keypoints, have been proposed. Despite significant progress, the current methods still face great challenges in accomplishing TLS point cloud registration. In this paper, we propose a multi-scale neural network to learn local shape descriptors for establishing correspondences between pairwise TLS point clouds. To train our model, data augmentation, developed on pairwise semi-synthetic 3D local patches, is to extend our network to be robust to rotation transformation. Then, based on varying local neighborhoods, multi-scale subnetworks are constructed and fused to learn robust local features. Experimental results demonstrate that our proposed method successfully registers two TLS point clouds and outperforms state-of-the-art methods. Besides, our learned descriptors are invariant to translation and tolerant to changes in rotation.}
}
@article{GURDURBROO2021102645,
title = {Built environment of Britain in 2040: Scenarios and strategies},
journal = {Sustainable Cities and Society},
volume = {65},
pages = {102645},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102645},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720308611},
author = {Didem {Gürdür Broo} and Kirsten Lamb and Richmond Juvenile Ehwi and Erika Pärn and Antiopi Koronaki and Chara Makri and Thayla Zomer},
keywords = {Built environment, 2040, Future studies, Scenario planning, Smart cities, Resilience},
abstract = {We are living through a convergence of crises. In 2020, when the ongoing Covid-19 global pandemic spread across the world, it brought economic instability in its wake. Sectors of the built environment (BE), among others, were hit hard by a public health crisis followed swiftly by an unprecedented economic downturn. In 2018, the Intergovernmental Panel on Climate Change (IPCC) report highlighted the need for rapid and drastic action on climate change by 2030 to prevent the disastrous effects of a world warmed by more than 1.5 °C above pre-industrial levels, raising the urgency of achieving the United Nations (UN) Sustainable Development Goals (SDGs) adopted by Member States in 2015. Even rapid decarbonisation, the report warned, would likely not be sufficient to address the intertwined problems of poverty, mass migration, politics and ecological collapse that the SDGs seek to address. Digital technology offers an opportunity to better understand and model solutions to these complex crises, but it is unclear how digital technology should be harnessed in the face of an uncertain future. Written at the beginning of this critical decade leading up to 2030, this paper looks ahead 20 years in the future to better understand the resources, technology, economy, governance, infrastructure, mobility and social factors that may shape the development of Britain’s digital BE. By exploring four scenarios around the variables of i) the UK’s compliance with the interconnected targets of the SDGs and ii) the size of the workforce relative to the dependent population (dependency), this paper concludes with the identification of key strategies that can lead to the sustainable development of the BE sectors, outlining a number of actions that should be combined with the path for recovery from Covid-19 and are based on digital technology and a green information economy that ensures a future better for everyone in a digital built Britain.}
}
@article{LIU2019394,
title = {Multi Features and Multi-time steps LSTM Based Methodology for Bike Sharing Availability Prediction},
journal = {Procedia Computer Science},
volume = {155},
pages = {394-401},
year = {2019},
note = {The 16th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2019),The 14th International Conference on Future Networks and Communications (FNC-2019),The 9th International Conference on Sustainable Energy Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.08.055},
url = {https://www.sciencedirect.com/science/article/pii/S187705091930969X},
author = {Xu Liu and Abdelouahed Gherbi and Wubin Li and Mohamed Cheriet},
keywords = {Bike-sharing, LSTM, RNN, DNN, Neural Network, Prediction},
abstract = {Most cities in the world promote bike-sharing services to encourage people to decrease carbon exhausting and to enhance their health. However, it is a big challenge for a bike-sharing service supplying corporation to re-balance bikes efficiently among different bike-sharing dockers without a forecasting ability. For solving this problem, we contribute two new approaches based on standard Long short-term memory (LSTM), which can not only take advantages of multi features inputs and multi-time steps outputs to improve the accuracy of predicting available bikes in one-time step, but also can forecast the number of bikes in multi-time steps. These approaches will help the bike-sharing agencies to make a better decision to distribute their bikes to each docker efficiently. The experimental results confirmed that our multi-feature and multi-time steps models outperform the standard LSTM model.}
}
@article{TIAN2021158,
title = {Facial age estimation with bilateral relationships exploitation},
journal = {Neurocomputing},
volume = {444},
pages = {158-169},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.07.149},
url = {https://www.sciencedirect.com/science/article/pii/S092523122100120X},
author = {Qing Tian and Meng Cao and Heyang Sun and Lianyong Qi and Junxiang Mao and Yue Cao and Jun Tang},
keywords = {Age estimation, Cumulative attribute, Joint relationship-exploiting learning, Correlation learning strategy},
abstract = {In the environment of smart cities, human facial age estimation has become an important research topic due to its wide applications. Although a variety of methods are proposed to depict facial biologic attributes, the underlying relationships between facial appearance and its biological aging process have not been fully explored. Although relationship learning methods have been constructed in terms of modeling either the facial representations or the facial attributes, none of them model the relationships simultaneously. In this paper, we propose a unified model to explore these relationships simultaneously, coined as JREAE. In JREAE, two covariance matrices are symmetrically constructed to capture the underlying correlations from both aspects of input facial features and output age labels. In this way, the potential relationships of both feature and label are not only modeled definitely, but also explored adaptively from the training data, which is significantly different from those methods that define the relationships manually. Then, we extend the JREAE model with deep convolutional architecture (deep-JREAE) for more powerful discrimination. In addition, we present optimization algorithms to solve the proposed models with theoretical convergence and complexity proof. Finally, through extensive experiments, we not only validate the effectiveness and superior of the proposed methods in performance, but also visualize and analyze the resulting relationships.}
}
@article{WANG2020298,
title = {Learning multiple instance deep quality representation for robust object tracking},
journal = {Future Generation Computer Systems},
volume = {113},
pages = {298-303},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.07.024},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20310712},
author = {Guan Wang and Jing Liu and Wei Lo and Chun-Ming Yang},
keywords = {Visual object tracking, Quality model, Bidirectional LSTM, Weakly-supervised, Spatial temporal modeling},
abstract = {Robustly tracking various objects within a video stream with complex objects and backgrounds is a useful technique in next generation computer vision systems. However, in practice, it is difficult to design a successful video-based object tracking system due to the varied light conditions, possible occlusions, and fast-moving objects. In this work, a novel weakly-supervised and quality-guided visual object tracking model is proposed, wherein the key is a bidirectional long short-term memory recurrent neural network (BLSTM-RNN) that captures the feature sequence and predicts the quality score of each candidate window. More specifically, given a rich set of training videos annotated with the target objects, a weakly-supervised learning algorithm is first used to project all the candidate window features onto the semantic space. Next, we propose a two-stage algorithm to select the key frames from the video sequences, where both the shallow and deep filtering operations are conducted. Subsequently, the so-called BLSTM-RNN is proposed to characterize the feature sequence temporally, based on which the maximally possible object window can be calculated and finally output. In our experiment, a large video dataset containing 2045 NBA regular seasons and playoff basketball games was compiled. Based on this, a comparative study is conducted between the proposed algorithm and state-of-the-art video tracking methods. Extensive visualization results and comparative tracking precisions show the competitiveness of the proposed method.}
}
@article{SAMPAIO2021107246,
title = {Autonomic energy management with Fog Computing},
journal = {Computers & Electrical Engineering},
volume = {93},
pages = {107246},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107246},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621002330},
author = {Hugo Vaz Sampaio and Carlos Becker Westphall and Fernando Koch and Ricardo {do Nascimento Boing} and René Nolio {Santa Cruz}},
keywords = {Internet of Things, Fog Computing, Energy Management System, Autonomic System, Smart Environments, Smart homes},
abstract = {We introduce an Autonomic System to perform management of energy consumption in Internet of Things (IoT) devices and Fog Computing, including an advanced orchestration mechanisms to manage dynamic duty cycles for extra energy savings. The solution works by adjusting Home (H) and Away (A) cycles based on contextual information, like environmental conditions, user behavior, behavior variation, regulations on energy and network resources utilization, among others. Performance analysis through a proof-of-concept implementation presents average energy savings of up to 61.51% when augmenting with a scheduling system and variable long sleep cycles (LS), and potential for 75.9% savings in specific conditions. We also concluded that there is no linear relation between increasing LS time and additional savings. The significance of this research is to promote autonomic management as a solution to develop more energy efficient buildings and smarter cities, towards sustainable goals.}
}
@article{WANG2021101321,
title = {Automatic representation and detection of fault bearings in in-wheel motors under variable load conditions},
journal = {Advanced Engineering Informatics},
volume = {49},
pages = {101321},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101321},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621000744},
author = {Xian-Bo Wang and Luqing Luo and Lulu Tang and Zhi-Xin Yang},
keywords = {Fault diagnosis, Synchronous resampling, Convolutional neural network, In-wheel motor, Time–frequency representation},
abstract = {The wear fault of the inner and outer race of bearing in an in-wheel motor is vital as the performance of bearing effects the transmission efficiency. Unlike the commonly used vibration analysis-based monitoring methods, the accelerometer cannot be installed inside the in-wheel motor since it would damage the structural reliability. The electricity-related signals sourcing from the motor controller may be a feasible way. In this paper, a load demodulation and normalization method under the condition of no vibration sensor is proposed to solve the problem of fault detection and diagnosis of the in-wheel motor transmission component under the condition of variable load. First, the stator current is selected to reflect the load changes according to the mathematical model of in-wheel motor in the three-phase stationary coordinates. Second, the order tracking is applied to synchronize the sampled signals on time domain with synchronous resampling, which converts the equally spaced signals into the angularly spaced signals. The merits are improving the definition of time–frequency representations (TFRs) of wear fault and avoiding the difficulty to determine the resolution of TFRs caused by load fluctuations. The short-time Fourier transform (STFT) is introduced to convert the angularly spaced signals into the TFRs. Finally, an adapted convolutional neural network (CNN) with random weight initialization and dropout strategy is employed to classify the wear of inner race and outer race. The proposed framework is verified on the in-wheel motor simulation platform. The experimental results show that the proposed method has a higher fault detection precision than the other methods. The core contribution reveals that this paper does not use the vibration-free sensor. Instead, the electrical signals of the controller are used to realize the fault detection and diagnosis of the inner and outer wear of the in-wheel motor bearing under the variable load conditions. Compared with the commonly used fault diagnosis method based on vibration signal analysis, the proposed method is more suitable for the condition monitoring system of the in-wheel motor transmission mechanism.}
}
@article{ZHANG2020658,
title = {Power cognition: Enabling intelligent energy harvesting and resource allocation for solar-powered UAVs},
journal = {Future Generation Computer Systems},
volume = {110},
pages = {658-664},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.05.068},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19308349},
author = {Jing Zhang and Minhao Lou and Lin Xiang and Long Hu},
keywords = {Solar-powered unmanned aerial vehicle, Power cognition, Resource allocation, Reinforcement learning},
abstract = {Solar-powered unmanned aerial vehicles (SUAVs) are a promising solution to increase the flight time of unmanned aerial vehicles (UAVs) in the sky, reducing human interventions for battery charging. Exploiting networked SUAVs for providing long-duration wireless communication cannot only improve the signal transmission reliability but realize energy autonomy. To reap these benefits, in this article, we propose an efficient energy and radio resource management framework based on intelligent power cognition at the SUAVs. Thereby, power-cognitive SUAVs can learn the environment including the spatial distributions of solar energy density, the channel state evolution, and the traffic patterns of wireless communication applications in adaption to the environment changes. These SUAVs intelligently adjust the energy harvesting, information transmission, and flight trajectory to improve the utilization of solar energy for two primary goals: staying aloft over a long time period and achieving high communication performance. We adopt reinforcement learning to compute the optimal decisions for maximization of the total system throughput within the lifetime of the SUAV. Simulation results show that the proposed power cognition scheme can simultaneously improve the communication throughput and the harvested energy for SUAVs.}
}
@article{YANG2019228,
title = {Mini-batch algorithms with online step size},
journal = {Knowledge-Based Systems},
volume = {165},
pages = {228-240},
year = {2019},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2018.11.031},
url = {https://www.sciencedirect.com/science/article/pii/S0950705118305835},
author = {Zhuang Yang and Cheng Wang and Zhemin Zhang and Jonathan Li},
keywords = {Stochastic optimization, Convex optimization, Mini-batch of samples, Online step size},
abstract = {Mini-batch algorithms have been proposed as a way to speed-up stochastic optimization methods and good results for mini-batch algorithms have been reported previously. A major issue with mini-batch algorithms is how to timely and readily acquire step size while running the algorithm. Usually, mini-batch algorithms employ a diminishing step size, or a best-tuned step size by mentor, which, in practice, are time consuming. To solve this problem, we propose using a hypergradient to compute an online step size (OSS) for mini-batch algorithms. Specifically, we incorporate online step size into advanced mini-batch algorithms, mini-batch nonconvex stochastic variance reduced gradient (MSVRG), thereby generating a new method, MSVRG-OSS. When computing step size in MSVRG-OSS, mini-batch samples are used. In addition, MSVRG-OSS, which needs little additional computation, requires only one extra copy of the original gradient to be stored in memory. We prove that MSVRG-OSS converges linearly in expectation and analyze its complexity. We present numerical results on problems arising with machine learning that indicate the proposed method shows great promise. We also show that, with slightly large batch samples, MSVRG-OSS is insensitive to the initial parameters, which are the key factor for controlling the performance of the algorithm.}
}
@article{ASIF2019132,
title = {License plate detection for multi-national vehicles: An illumination invariant approach in multi-lane environment},
journal = {Computers & Electrical Engineering},
volume = {78},
pages = {132-147},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618330507},
author = {Muhammad Rizwan Asif and Chun Qi and Tiexiang Wang and Muhammad Sadiq Fareed and Syed Ali Raza},
keywords = {Intelligent traffic system, License plate detection, Multi-national vehicles, Corona effect, Vehicle identification, Vehicle rear lights},
abstract = {Only a few methods in literature are effective for multi-national license plate detection in a multi-lane scenario. These methods are prone to illumination variance, complex background and weak-edged license plates. In this paper, we propose a novel illumination invariant method to handle multi-national vehicle license plates of different colors and styles. Red corona is initially used to detect the tail-lights of vehicles to establish region-of-interest as the license plates are in a vicinity of its tail-lights. The vertical edges within each region-of-interest are obtained using a unique approach that preserve license plate edges for improved performance. Heuristic energy map is then used to distinguish the license plate area. To validate the detected regions, high-level features extracted from AlexNet Convolutional Neural Network are used. Extensive experiments on the license plates of six countries show that the proposed approach not only ensures real-time performance, but also outperforms the conventional and deep-learning methods.}
}
@article{COSTA2021100206,
title = {A Survey on Data-driven Performance Tuning for Big Data Analytics Platforms},
journal = {Big Data Research},
volume = {25},
pages = {100206},
year = {2021},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2021.100206},
url = {https://www.sciencedirect.com/science/article/pii/S221457962100023X},
author = {Rogério Luís de C. Costa and José Moreira and Paulo Pintor and Veronica {dos Santos} and Sérgio Lifschitz},
keywords = {Big data systems, Big data platforms, Performance tuning, Database systems},
abstract = {Many research works deal with big data platforms looking forward to data science and analytics. These are complex and usually distributed environments, composed of several systems and tools. As expected, there is a need for a closer look at performance issues. In this work, we review performance tuning strategies in the big data environment. We focus on data-driven tuning techniques, discussing the use of database inspired approaches. Concerning big data and NoSQL stores, performance tuning issues are quite different from the so-called conventional systems. Many existing solutions are mostly ad-hoc activities that do not fit for multiple situations. But there are some categories of data-driven solutions that can be taken as guidelines and incorporated into general-purpose auto-tuning modules for big data systems. We examine typical performance tuning actions, discussing available solutions to support some of the tuning process's primary activities. We also discuss recent implementations of data-driven performance tuning solutions for big data platforms. We propose an initial classification based on the domain state-of-the-art and present selected tuning actions for large-scale data processing systems. Finally, we organized existing works towards self-tuning big data systems based on this classification and presented general and system-specific tuning recommendations. We found that most of the literature pieces evaluate the use of tuning actions at the physical design perspective, and there is a lack of self-tuning machine-learning-based solutions for big data systems.}
}
@article{QUERALTA2019343,
title = {Comparative Study of LPWAN Technologies on Unlicensed Bands for M2M Communication in the IoT: beyond LoRa and LoRaWAN},
journal = {Procedia Computer Science},
volume = {155},
pages = {343-350},
year = {2019},
note = {The 16th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2019),The 14th International Conference on Future Networks and Communications (FNC-2019),The 9th International Conference on Sustainable Energy Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.08.049},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919309639},
author = {J. Penã Queralta and T.N. Gia and Z. Zou and H. Tenhunen and T. Westerlund},
keywords = {IoT, IIoT, M2M Communication, LoRa, SigFox, LoRaWAN, LPWAN, Symphony Link, Ingenu, RPMA, Smart City, Industry 4.0},
abstract = {Low power wide area networks (LPWAN) are widely used in IoT applications as they offer low power consumption and long-range communication. LoRaWAN and SigFox have taken the top positions in the unlicensed ISM bands, while LTE-M and NB-IoT have emerged within cellular networks. We focus on unlicensed bands operation because of their availability for both private and public use with one’s own infrastructure. New technologies have since been developed to overcome limitations of LoRaWAN and SigFox, based on LoRa or other modulation techniques, and are finding their way mainly into the industrial IoT. These include Symphony Link or Ingenu RPMA. To the best of our knowledge, previous works have not been focused on comparing LPWAN technologies in-depth including alternatives to the link and network layers over LoRa other than LoRaWAN. This paper provides a detailed comparative study of these technologies and potential application scenarios. We defend that LoRaWAN is the most suitable for small-scale or public deployments, while Symphony Link provides a robust solution for industrial environments. SigFox is one the most widely deployed networks; and RPMA has the advantage of using the 2.4GHz band, equally regulated in most countries.}
}
@article{SNAPHAAN2021101691,
title = {Utilizing geo-referenced imagery for systematic social observation of neighborhood disorder},
journal = {Computers, Environment and Urban Systems},
volume = {90},
pages = {101691},
year = {2021},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2021.101691},
url = {https://www.sciencedirect.com/science/article/pii/S0198971521000983},
author = {Thom Snaphaan and Wim Hardyns},
keywords = {Artificial intelligence, Big data, Convolutional neural networks, Geo-referenced imagery, Neighborhood disorder, Systematic social observation},
abstract = {Research methods in social science take advantage from broader trends such as digitalization and increasing computational power, however, this is an evolving explorative search. The main purpose of this article is to describe the methodological innovations in the collection and processing of geo-referenced imagery for the observation of neighborhood disorder. In this narrative review, attention is paid to advances in both the data sources and the data processing methods used. Neighborhood disorder is traditionally measured by means of survey methods and (systematic) (social) observations, but these methods have specific shortcomings, such as respectively the subjective measurement that does not deliver a valid measure of actual prevalence of disorderly phenomena and the intensive use of resources in terms of time and money. This has repercussions for (the interpretation of) the results based on these data. Today, scholars have innovative data sources and cutting-edge data processing methods at their disposal that can meet (some of) these shortcomings, but which have not yet been fully explored. In this article, the evolutions in the use of geo-referenced imagery for the observation of neighborhood disorder from the last 25 years are described with a focus on the empirical opportunities, and the methodological challenges and prospects. We conclude by outlining the road ahead: promising avenues for future research to exploit the full potential of ‘big primary data’.}
}
@article{YIN2021103874,
title = {Automated semantic segmentation of industrial point clouds using ResPointNet++},
journal = {Automation in Construction},
volume = {130},
pages = {103874},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103874},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521003253},
author = {Chao Yin and Boyu Wang and Vincent J.L. Gan and Mingzhu Wang and Jack C.P. Cheng},
keywords = {As-built BIM, Deep learning, Industrial object recognition, Local aggregation operator, PointNet++, Point clouds, Residual learning, Semantic segmentation, Laser scanning},
abstract = {Currently, as-built building information modeling (BIM) models from point clouds show great potential in managing building information. The automatic creation of as-built BIM models from point clouds is important yet challenging due to the inefficiency of semantic segmentation. To overcome this challenge, this paper proposes a novel deep learning-based approach, ResPointNet++, by integrating deep residual learning with conventional PointNet++ network. To unleash the power of deep learning methods, this study firstly builds an expert-labeled high-quality industrial LiDAR dataset containing 80 million data points collected from four different industrial scenes covering nearly 4000 m2. Our dataset consists of five typical semantic categories of plumbing and structural components (i.e., pipes, pumps, tanks, I-shape and rectangular beams). Second, we introduce two effective neural modules including local aggregation operator and residual bottleneck modules to learn complex local structures from neighborhood regions and build up deeper point cloud networks with residual settings. Based on these two neural modules, we construct our proposed network, ResPointNet++, with a U-Net style encoder-decoder structure. To validate the proposed method, comprehensive experiments are conducted to compare the robustness and efficiency of our ResPointNet++ with two representative baseline methods (PointNet and PointNet++) on our benchmark dataset. The experimental results demonstrate that ResPointNet++ outperforms two baselines with a remarkable overall segmentation accuracy of 94% and mIoU of 87%, which is 23% and 42% higher than that of conventional PointNet++, respectively. Finally, ablation studies are performed to evaluate the influence of design choices of the local aggregation operator module including input feature type and aggregation function type. This study contributes to automated 3D scene interpretation of industrial point clouds as well as the as-built BIM creation for industrial components such as pipes and beams.}
}
@article{KAMATCHI2019724,
title = {Improvement of Crop Production Using Recommender System by Weather Forecasts},
journal = {Procedia Computer Science},
volume = {165},
pages = {724-732},
year = {2019},
note = {2nd International Conference on Recent Trends in Advanced Computing ICRTAC -DISRUP - TIV INNOVATION , 2019 November 11-12, 2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.01.023},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920300314},
author = {S. Bangaru Kamatchi and R. Parvathi},
keywords = {Artificial Neural Networks, Weather Prediction, Case-Based Reasoning, Collaborative Filtering},
abstract = {Establishing linkages between Meteorological and climatic data, and farming decision-making is a challenging task. The following paper addresses the challenges associated with this. A large amount of weather and climate information is presently available for farmers. A portion of the information is operational or already under development, and in particular, forecasting through climatic data and formation may not be suitable for farmers when it comes to the decision-making process. The best way to gain an advantage from natural factors is to consider them during decision-making and understand them in the best way possible. Meteorological information pertaining to agriculture, and climatic data, in particular, is an important aspect of planning in the context of agricultural production. Therefore, climatic conditions must be an integral part of the decision-making process. These factors can be determined by recording hourly, daily, and weekly temperature data, rainfall, solar radiation, wind speed, evaporation, relative humidity, and evapotranspiration. Artificial Neural Networks possess the capability of not just analysing the data but also learning from the data. This paper presents a predictive analysis to analyse the best crop which can be produced for specific weather conditions and also suggests a hybrid recommender system that adopts CBR - Case-Based Reasoning for enhancing the success ratio of the system. This proposed novel hybrid system is a combination of the collaborative filtering technique and case-based reasoning.The novelty of the model lies in the of district-wise agriculture data analysis for predicting future climatic conditions and recommending crops based on that climatic conditions and also considering the agriculture pattern of the district using a hybrid recommender system.}
}
@article{QAMAR2020196,
title = {An Approach towards Position-Independent Human Activity Recognition Model based on Wearable Accelerometer Sensor},
journal = {Procedia Computer Science},
volume = {177},
pages = {196-203},
year = {2020},
note = {The 11th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2020) / The 10th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH 2020) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.10.028},
url = {https://www.sciencedirect.com/science/article/pii/S187705092032295X},
author = {Naima Qamar and Nasir Siddiqui and Muhammad Ehatisham-ul-Haq and Muhammad {Awais Azam} and Usman Naeem},
keywords = {accelerometer, activity recognition, machine learning, position-independent, transformation, wearable sensor},
abstract = {The continuous progress in wearable sensing technologies has motivated the researchers to develop novel models for human activity and behavior monitoring. As wearable sensors possess more liberty in their placement at multiple positions on the user’s body to track human motion patterns, hence, they have been extensively utilized in activity recognition systems. However, wearable inertial sensors are prone to their position and orientation sensitivity, thus leading to poor recognition performance in real-time scenarios. Therefore, in this study, we address the problem of position-independent human activity recognition using the wearable sensor. In this aspect, we propose a set of linear and non-linear transformations for 3D-sensor data to minimize the position and orientation sensitivity of the inertial sensor. We also present a feature extraction framework to efficiently recognize human activities independent of any sensor position. Finally, we validate our proposed scheme using the PAMAP dataset, which achieves the best average performance of 94.7% and 91.7% for position-dependent and position-independent activity recognition.}
}
@article{GUO2020109866,
title = {Optimal modification of heating, ventilation, and air conditioning system performances in residential buildings using the integration of metaheuristic optimization and neural computing},
journal = {Energy and Buildings},
volume = {214},
pages = {109866},
year = {2020},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2020.109866},
url = {https://www.sciencedirect.com/science/article/pii/S037877881933453X},
author = {Zhanjun Guo and Hossein Moayedi and Loke Kok Foong and Mehdi Bahiraei},
keywords = {Hvac system, Heating load, Cooling load, Neural computing, Metaheuristic optimization},
abstract = {This study pursues optima modification of heating, ventilating, and air conditioning (HVAC) systems embedded in residential buildings through predicting heating load (HL) and cooling load (CL). This purpose is carried out by employing four wise metaheuristic algorithms, namely wind-driven optimization (WDO), whale optimization algorithm (WOA), spotted hyena optimization (SHO), and salp swarm algorithm (SSA) synthesized with a multi-layer perceptron (MLP) neural work in order to overcome the computational shortcomings of this model. The used dataset consists of overall height, glazing area, orientation, relative compactness, wall area, glazing area distribution, roof area, and surface area as independent factors, and the HL and CL as target factors. The results indicated a high capability of all four metaheuristic ensembles for understanding the non-linear relationship between the mentioned factors. Meanwhile, a comparison between the used models revealed that SSA-MLP (ErrorHL = 1.9178 and ErrorCL = 2.1830) is the most accurate model, followed by WDO-MLP (ErrorHL = 1.9863 and ErrorCL = 2.2424), WOA-MLP (ErrorHL = 2.1921 and ErrorCL = 2.5390), and SHO-MLP (ErrorHL = 3.1092 and ErrorCL = 4.5930). Regarding the satisfying accuracy of the SSA-based ensemble, it can be a reliable tool for estimating the HL and CL for future smart city planning.}
}
@article{IDOJE2021107104,
title = {Survey for smart farming technologies: Challenges and issues},
journal = {Computers & Electrical Engineering},
volume = {92},
pages = {107104},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107104},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621001117},
author = {Godwin Idoje and Tasos Dagiuklas and Muddesar Iqbal},
keywords = {Artificial intelligent, Internet of things, Cloud, Unmanned area vehicle, Smart farming, Sensors},
abstract = {Internet of Things (IoT) has been a major influence in Agriculture since its application to the sector. This paper provides an extensive review of the use of smart technologies in agriculture and elaborates the state-of-the-art technologies for smart agriculture including, Internet of Things, cloud computing, machine learning, and artificial intelligence. The application of smart farming to crop and animal production and post-harvesting is discussed. The impact of climate change on agriculture is also considered. This paper contributes to knowledge by iterating the challenges of smart technology to agriculture while highlighting the issues identified from existing framework of smart agriculture. The authors identify many gaps in existing research affecting the application of IoT in smart farming, and suggest further research to improve the current food production globally, to provide better food management and sustainability measures across the globe.}
}
@article{ILIASHENKO2021900,
title = {Big Data in Transport Modelling and Planning},
journal = {Transportation Research Procedia},
volume = {54},
pages = {900-908},
year = {2021},
note = {International Scientific Siberian Transport Forum - TransSiberia 2020},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2021.02.145},
url = {https://www.sciencedirect.com/science/article/pii/S2352146521003240},
author = {Oksana Iliashenko and Victoria Iliashenko and Ekaterina Lukyanchenko},
keywords = {Transport Modelling, Planning, Big Data, Internet of Things, Machine Learning},
abstract = {This article is built on the exploration of the possibilities of using Big Data, Machine Learning and the Internet of Things technologies for the needs of transport planning and modeling. The authors analyze the problems arising in the transport infrastructure because of the growing urbanization of cities and propose a solution to the problems based on the use of processing large amounts of data. As a result of the study, a comparative table was created showing the possible application of Big Data technologies in integration with other modern technologies and what problems of transport planning they will solve.}
}
@article{PESANTEZ2020104633,
title = {Smart meters data for modeling and forecasting water demand at the user-level},
journal = {Environmental Modelling & Software},
volume = {125},
pages = {104633},
year = {2020},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2020.104633},
url = {https://www.sciencedirect.com/science/article/pii/S1364815219303457},
author = {Jorge E. Pesantez and Emily Zechman Berglund and Nikhil Kaza},
keywords = {Smart water meters, AMI, Forecasting model, Hourly water demand, User-level data, Water demand management, Machine learning, Urban water systems},
abstract = {Smart meters installed at the user-level provide a new data source for managing water infrastructure. This research explores the use of machine learning methods, including Random Forests (RFs), Artificial Neural Networks (ANNs), and Support Vector Regression (SVR) to forecast hourly water demand at 90 accounts using smart-metered data. Demands are predicted using lagged demand, seasonality, weather, and household characteristics. Time-series clustering is applied to delineate data based on the time of day and day of the week, which improves model performance. Two modeling approaches are compared. Individual models are developed separately for each meter, and a Group model is trained using a data set of multiple meters. Individual models predict demands at meters in the original data set with lower error than Group models, while the Group model predicts demands at new meters with lower error than Individual models. Results demonstrate that RF and ANN perform better than SVR across all scenarios.}
}
@article{MIHAITA2019398,
title = {Evaluating air quality by combining stationary, smart mobile pollution monitoring and data-driven modelling},
journal = {Journal of Cleaner Production},
volume = {221},
pages = {398-418},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.02.179},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619305785},
author = {Adriana Simona Mihăiţă and Laurent Dupont and Olivier Chery and Mauricio Camargo and Chen Cai},
keywords = {Air pollution, Eco-neighbourhood, Mobile sensing, Decision trees, Neural networks},
abstract = {Air pollution impact assessment is a major objective for various community councils in large cities, which have lately redirected their attention towards using more low-cost sensing units supported by citizen involvement. However, there is a lack of research studies investigating real-time mobile air-quality measurement through smart sensing units and even more of any data-driven modelling techniques that could be deployed to predict air quality accurately from the generated data-sets. This paper addresses these challenges by: a) proposing a comparative and detailed investigation of various air quality monitoring devices (both fixed and mobile), tested through field measurements and citizen sensing in an eco-neighbourhood from Lorraine, France, and by b) proposing a machine learning approach to evaluate the accuracy and potential of such mobile generated data for air quality prediction. The air quality evaluation consists of three experimenting protocols: a) first, we installed fixed passive tubes for monitoring the nitrogen dioxide concentrations placed in strategic locations highly affected by traffic circulation in an eco-neighbourhood, b) second, we monitored the nitrogen dioxide registered by citizens using smart and mobile pollution units carried at breathing level; results revealed that mobile-captured concentrations were 3–5 times higher than the ones registered by passive-static monitoring tubes and c) third, we compared different mobile pollution stations working simultaneously, which revealed noticeable differences in terms of result variability and sensitivity. Finally, we applied a machine learning modelling by using decision trees and neural networks on the mobile-generated data and show that humidity and noise are the most important factors influencing the prediction of nitrogen dioxide concentrations of mobile stations.}
}
@article{SHAO2021107047,
title = {An agile and intelligent dynamic economic emission dispatcher based on multi-objective proximal policy optimization},
journal = {Applied Soft Computing},
volume = {102},
pages = {107047},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.107047},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620309856},
author = {Zhuang Shao and Fengqi Si and Huaijiang Wu and Xiaozhong Tong},
keywords = {DEED, Multi-objective policy optimization, Reinforcement learning, Artificial neural network},
abstract = {The recent development in power systems claims the improvement of the efficiency to solve dynamic economic emission dispatch (DEED) problem. However, the popular pure optimization framework based on evolutionary algorithms only starts the compute-intensive optimization process after receiving the power demand, which causes significant delays To address this limitation, this research defines a novel dynamic economic emission dispatcher (DEEDer) problem and the dispatcher learning framework. It is different from previous research and the most current algorithms in the advantage of transferring the on-line compute-intensive optimization task to off-line. To solve the dispatcher, we model the dispatching process as a conditional deterministic Markov Decision Process (MDP) and propose the multi-objective proximal policy optimization (MOPPO). The Benchmark Test Set with 10,000 different dispatching tasks for 5-unit and 10-unit system is released to evaluate the generalization of the dispatcher. The experiment results indicate that the neural network dispatcher trained with MOPPO is hundreds to thousands of times faster than the state-of-the-art pure optimization algorithms. Meanwhile, the dispatcher not only has comparable performance as the state-of-the-art multi-objective optimization algorithms in standard dispatching task but also shows generalization on generating Pareto optimal solutions given any possible dispatching task. Following the DEEDer framework, the proposed method makes it possible to dispatch power in a more agile way as the timely response to the changing of power demand while still controlling economic and emission.}
}
@article{TANG2020101927,
title = {Incorporating weather conditions and travel history in estimating the alighting bus stops from smart card data},
journal = {Sustainable Cities and Society},
volume = {53},
pages = {101927},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2019.101927},
url = {https://www.sciencedirect.com/science/article/pii/S2210670719321274},
author = {Tianli Tang and Ronghui Liu and Charisma Choudhury},
keywords = {Smart card data, Machine learning, Gradient boosting decision tree, Alighting bus stop},
abstract = {Origin-destination flow of passengers in bus networks is a crucial input to the public transport planning and operational decisions. Smart card systems in many cities, however, record only the bus boarding information (namely an open system), which makes it challenging to use smart card data for origin-destination estimations and subsequent analyses. This study addresses this research gap by proposing a machine learning approach and applying the gradient boosting decision tree (GBDT) algorithm to estimate the alighting stops of bus trips from open smart card data. It advances the state-of-the-art by including, for the first time, weather variables and travel history of individuals in the GBDT algorithm alongside the network characteristics. The method is applied to six-month smart card data from the City of Changsha, China, with more than 17 million trip-records from 700 thousand card users. The model prediction results show that, compared to classic machine learning methods, GBDT not only yields higher prediction accuracy but more importantly is also able to rank the influencing factors on bus ridership. The results demonstrate that incorporation of weather variables and travel history further improves the prediction capability of the models. The proposed GBDT-based framework is flexible and scalable: it can be readily trained with smart card data from other cities to be used for predicting bus origin-destination flow. The results can contribute to improved transport sustainability of a city by enabling smart bus planning and operational decisions.}
}
@article{DUTTA2021100461,
title = {TinyML Meets IoT: A Comprehensive Survey},
journal = {Internet of Things},
volume = {16},
pages = {100461},
year = {2021},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2021.100461},
url = {https://www.sciencedirect.com/science/article/pii/S2542660521001025},
author = {Dr. Lachit Dutta and Swapna Bharali},
keywords = {Internet of Things (IoT), tiny machine learning (TinyML), hardware-software co-design},
abstract = {The rapid growth in miniaturization of low-power embedded devices and advancement in the optimization of machine learning (ML) algorithms have opened up a new prospect of the Internet of Things (IoT), tiny machine learning (TinyML), which calls for implementing the ML algorithm within the IoT device. TinyML framework in IoT is aimed to provide low latency, effective bandwidth utilization, strengthen data safety, enhance privacy, and reduce cost. Its ability to empower the IoT device to reliably function without consistent access to the cloud services while delivering accurate ML services makes it a promising option for IoT applications seeking cost-effective solutions. Especially in settings where inadequate connectivity is common, TinyML aims to provide on-premise analytics which will add substantial benefit to IoT services. In this article, we introduce the definition of TinyML and provide background information on diverse related technologies stating their strengths and weaknesses. We then show how TinyML-as-a-service is implemented through efficient hardware-software co-design. This article also introduces the role of 5G in TinyML-IoT scenario. Furthermore, it touches on the recent progress in TinyML research in both academia and industry along with future challenges and opportunities. We believe that this review will serve as an information cornerstone for the IoT research community and pave the way for further research in this direction.}
}
@article{SIDDIQUA2019365,
title = {iCAFE: Intelligent Congestion Avoidance and Fast Emergency services},
journal = {Future Generation Computer Systems},
volume = {99},
pages = {365-375},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.04.023},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19302377},
author = {Ayesha Siddiqua and Munam Ali Shah and Hasan Ali Khattak and Ikram {Ud Din} and Mohsen Guizani},
keywords = {Emergency management, Road side unit (RSU), Intelligent transportation system (ITS), Smart health, Emergency services},
abstract = {Content Centric Network (CCN) has been envisioned as a paradigm shift from client server architecture. In smart cities, transportation plays an important role where integrated services facilitate citizens through the ease of use, safety, and convenience. In this work, we propose an integrated CCN for intelligent Congestion Avoidance and Fast Emergency (iCAFE) services delivery at road side accidents. One of the significant contributions is a novel content-centric VANET-based protocol called iCAFE, an efficient traffic control algorithm and five unique packet headers for effective communications. In case of accident, emergency packets are broadcast to RSU wherein the forwarding information based (FIB) and pending interest table (PIT) are updated accordingly. The RSU broadcasts interest packets to hospital and sends a rescue message to the ambulance. The RSU also informs nearest RSUs and vehicles to evacuate the affected lane. After the rescue process is completed, the data packet is unicast from the hospital to the RSU and the PIT and FIB are updated. iCAFE achieves a high packet delivery ratio (PDR) with minimum rescue delay (R-Delay), high throughput, minimum network load, smaller collision probability, and minimum packet drop fraction. The iCAFE results are compared with the traffic accidents reduction strategy (TARS).}
}
@article{SU2022108372,
title = {DLA-Net: Learning dual local attention features for semantic segmentation of large-scale building facade point clouds},
journal = {Pattern Recognition},
volume = {123},
pages = {108372},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.108372},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321005525},
author = {Yanfei Su and Weiquan Liu and Zhimin Yuan and Ming Cheng and Zhihong Zhang and Xuelun Shen and Cheng Wang},
keywords = {Semantic segmentation, Building facade, Self-attention, Attentive pooling, DLA-Net},
abstract = {The semantic segmentation of building facades is critical for various construction applications, such as urban building reconstruction and damage assessments. As there is a lack of 3D point cloud datasets related to fine-grained building facades, in this work we construct the first large-scale point cloud benchmark dataset for building facade semantic segmentation. In terms of the characteristics of building facade dataset, the existing methods of semantic segmentation cannot fully mine the local neighborhood information of point clouds; therefore, we propose an attention module that learns Dual Local Attention features, called DLA in this paper. The proposed DLA module consists of two blocks, a self-attention block and an attentive pooling block, which both embed an enhanced position encoding block. The DLA module can be easily embedded into various network architectures for point cloud segmentation, naturally resulting in a new 3D semantic segmentation network with an encoder-decoder architecture; we called this network the DLA-Net. Extensive experimental results on our constructed building facade dataset demonstrate that the proposed DLA-Net achieves better performance than the state-of-the-art methods for semantic segmentation.}
}
@article{DIAZ201699,
title = {State-of-the-art, challenges, and open issues in the integration of Internet of things and cloud computing},
journal = {Journal of Network and Computer Applications},
volume = {67},
pages = {99-117},
year = {2016},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2016.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S108480451600028X},
author = {Manuel Díaz and Cristian Martín and Bartolomé Rubio},
keywords = {Internet of things, Cloud computing, Infrastructure as a service, Cloud platforms, Iot middleware, Big data},
abstract = {The Internet of Things (IoT) is a paradigm based on the Internet that comprises many interconnected technologies like RFID (Radio Frequency IDentification) and WSAN (Wireless Sensor and Actor Networks) in order to exchange information. The current needs for better control, monitoring and management in many areas, and the ongoing research in this field, have originated the appearance and creation of multiple systems like smart-home, smart-city and smart-grid. However, the limitations of associated devices in the IoT in terms of storage, network and computing, and the requirements of complex analysis, scalability, and data access, require a technology like Cloud Computing to supplement this field. Moreover, the IoT can generate large amounts of varied data and quickly when there are millions of things feeding data to Cloud Computing. The latter is a clear example of Big Data, that Cloud Computing needs to take into account. This paper presents a survey of integration components: Cloud platforms, Cloud infrastructures and IoT Middleware. In addition, some integration proposals and data analytics techniques are surveyed as well as different challenges and open research issues are pointed out.}
}
@article{YANG2021100,
title = {Research on equipment health prediction technology based on edge computing and VAE-TCN},
journal = {Procedia Computer Science},
volume = {183},
pages = {100-106},
year = {2021},
note = {Proceedings of the 10th International Conference of Information and Communication Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.02.036},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921005019},
author = {Yanfang Yang and Bo Yu and Wei Wang},
keywords = {edge computing, equipment health prediction, Variational Auto-Encoder, Time Convolution Network},
abstract = {The Internet of Things technology is developing rapidly, and the data generated has also exploded. Traditional cloud computing technology can no longer meet the demand for efficient processing of massive data. Edge computing technology can move the amount of calculation down to the edge of the network, which can greatly improve computing efficiency. Applying edge computing to the field of equipment health prediction, the combination of strong responsiveness and computing capabilities of edge computing and high-precision prediction technology makes production operation and maintenance more reliable and efficient. At the same time, a neural network prediction model combining Variational Auto-Encoder (VAE) and Time Convolutional Network (TCN) is proposed to improve the accuracy of equipment health prediction. This model uses VAE for dimensionality reduction, extracts the hidden information in the original data, reconstructs high-quality sample data, and then uses TCN to mine the internal connection between the features and the target in the long sequence information. Compared with five benchmark prediction models on the C-MAPSS dataset, experiments show that the proposed model has higher prediction accuracy.}
}
@article{ELHADDADEH2019310,
title = {Examining citizens' perceived value of internet of things technologies in facilitating public sector services engagement},
journal = {Government Information Quarterly},
volume = {36},
number = {2},
pages = {310-320},
year = {2019},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2018.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X1730446X},
author = {Ramzi El-Haddadeh and Vishanth Weerakkody and Mohamad Osmani and Dhaval Thakker and Kawaljeet Kaur Kapoor},
keywords = {Internet of things, Public Sector, Perceived Value, Continuous Use},
abstract = {With the advancement of disruptive new technologies, there has been a considerable focus on personalisation as an important component in nurturing users' engagement. In the context of smart cities, Internet of Things (IoT) offer a unique opportunity to help empower citizens and improve societies' engagement with their governments at both micro and macro levels. This study aims to examine the role of perceived value of IoT in improving citizens' engagement with public services. A survey of 313 citizens in the UK, engaging in various public services, enabled through IoT, found that the perceived value of IoT is strongly influenced by empowerment, perceived usefulness and privacy related issues resulting in significantly affecting their continuous use intentions. The study offers valuable insights into the importance of perceived value of IoT-enabled services, while at the same time, providing an intersectional perspective of UK citizens towards the use of disruptive new technologies in the public sector.}
}
@article{ZHOU2021103369,
title = {The main trends for multi-tier supply chain in Industry 4.0 based on Natural Language Processing},
journal = {Computers in Industry},
volume = {125},
pages = {103369},
year = {2021},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2020.103369},
url = {https://www.sciencedirect.com/science/article/pii/S0166361520306035},
author = {Rongyan Zhou and Anjali Awasthi and Julie {Stal-Le Cardinal}},
keywords = {Multi-tier supply chain (MSC), Industry 4.0, Literature review, Text mining, Unsupervised learning},
abstract = {Multi-tier supply chains in Industry 4.0 are critical emerging issues today. This article briefly examines the Industry 4.0 policies in different countries. In order to decide on a better model and the number of topics in the model, a comparative test of the coherence value for two machine learning classification methods based on Latent Dirichlet Allocation was conducted. Subsequently, the article combines the traditional literature review method with a survey article referring to Industry 4.0 and multi-tier supply chain, indexed by science citation index expanded (SCI-EXPANDED) and social sciences citation index (SSCI) during 2009-2018. The research direction, research type, and research approaches of each paper were extracted, and the topics of all the articles were classified by machine learning, which provides feasible routes and valuable research directions for researchers in this field. Afterward, the research status and future research directions were identified. The combination of natural language processing in machine learning to classify research topics and traditional literature review to investigate article details greatly improved the objectivity and scientificity of the study and laid a solid foundation for further research.}
}
@article{MOCNEJ2021102001,
title = {Quality-enabled decentralized IoT architecture with efficient resources utilization},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {67},
pages = {102001},
year = {2021},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2020.102001},
url = {https://www.sciencedirect.com/science/article/pii/S073658452030212X},
author = {Jozef Mocnej and Adrian Pekar and Winston K.G. Seah and Peter Papcun and Erik Kajati and Dominika Cupkova and Jiri Koziorek and Iveta Zolotova},
keywords = {Decentralized IoT architecture, Edge computing, Energy efficiency, Internet of Things, Industrial Internet of Things, Quality-enabled platform},
abstract = {The Internet of Things (IoT) is a paradigm aimed at connecting everyday objects to the internet. IoT applications include smart cities, healthcare, agriculture, as well as the industry and manufacturing. The ability to monitor and control the physical world using information technology creates many opportunities. However, it also comes with some costs. The exponential growth of connected devices, the heterogeneity of IoT use cases, and the diversity of the network technologies yield a concern regarding IoT sustainability. With this work, we aim to contribute to this concern. In doing so, we introduce a novel representation model that is destined for (i) monitoring the IoT environment at runtime, (ii) expressing the overall quality of the system, and (iii) helping to utilize the available resources efficiently. We also define a feature set that describes the best the expectations of decentralized IoT platforms. Furthermore, we describe a quality-enabled decentralized IoT architecture too that incorporates the specified feature set as well as our representation model. Such solutions are necessary to improve and maintain IoT of the future and all its application domains, including the Industrial Internet of Things (IIoT). With the presented research, we aim to encourage the efficient utilization of resources and simplify the production of next-generation IoT solutions.}
}
@article{ALBIERO2022106608,
title = {Swarm robots in mechanized agricultural operations: A review about challenges for research},
journal = {Computers and Electronics in Agriculture},
volume = {193},
pages = {106608},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106608},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006256},
author = {Daniel Albiero and Angel {Pontin Garcia} and Claudio {Kiyoshi Umezu} and Rodrigo {Leme de Paulo}},
keywords = {Agriculture, Operational cost, Electric tractor, Artificial intelligence, Plowing, Forestry, Multi-robot},
abstract = {Agricultural mechanization is an area of knowledge that has evolved a lot over the past century, its main actors being agricultural tractors that, in 100 years, have increased their powers by 3,300%. This evolution has resulted in an exponential increase in the field capacity of such machines. However, it has also generated negative results such as excessive consumption of fossil fuel, excessive weight on the soil, very high operating costs, and millionaire acquisition value. The objective of this paper aims at exploring the upcoming challenges of employing swarm robot tractors that together have the same field capacity as a large tractor with an internal combustion engine. A systematic literature review technique is used to survey 32 representative papers that report research about swarm robots in agriculture. These papers are analyzed in an organized manner concerning the operationalization of swarm robots to fulfill agricultural mechanization missions. A comprehensive evaluation is conducted from the aspects of technology readiness level (TRL), configurability, adaptability, dependability, motion ability, perception ability and decision autonomy. Based on the evaluation result, upcoming challenges are detected and summarized, suggesting the development of a roadmap for future research. Another systematic review was done for these challenges by assessing the distance between what is being studied and the needs for a commercial operation of a robotic tractor swarm.}
}
@article{LE2022102752,
title = {Artificial intelligence-aided privacy preserving trustworthy computation and communication in 5G-based IoT networks},
journal = {Ad Hoc Networks},
volume = {126},
pages = {102752},
year = {2022},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102752},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521002341},
author = {Tan Le and Sachin Shetty},
keywords = {Vehicular networks, Trustworthy computation, Privacy preservation, AI, 5G network},
abstract = {5G offers unprecedented bandwidth coupled with extremely low latency and an extraordinarily high density of connections as well as the increased efficiency and reliability. These are slated to support 5G-based IoT services such as basic safety, fuel-economy, entertainment, surveillance, etc., which are observed in many applications, like vehicular networks and smart healthcare systems. However, cyber-attacks to the 5G network architecture pose severe risks to communication and computational services. Thus, we need to develop mechanisms to enhance the current untrustworthy 5G networks as well as to preserve 5G privacy capabilities, which then makes 5G workable for the modern operations and activities of IoT networks. In this paper, we firstly present the recent trust management and privacy preservation mechanisms, which are usually used for the communications of IoT networks. Then, we develop the artificial intelligence (AI)-aided framework to address the joint privacy preserving trustworthy communication and computation in 5G-enabled IoT networks, which is neglected in the existing research works. Finally, we highlight the potential future directions and their corresponding trust and privacy challenges in 5G-enabled IoT networks.}
}
@article{YANG2017120,
title = {Utilizing Cloud Computing to address big geospatial data challenges},
journal = {Computers, Environment and Urban Systems},
volume = {61},
pages = {120-128},
year = {2017},
note = {Geospatial Cloud Computing and Big Data},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2016.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S0198971516303106},
author = {Chaowei Yang and Manzhu Yu and Fei Hu and Yongyao Jiang and Yun Li},
keywords = {Big Data, Cloud Computing, Spatiotemporal data, Geospatial science, Smart cities},
abstract = {Big Data has emerged with new opportunities for research, development, innovation and business. It is characterized by the so-called four Vs: volume, velocity, veracity and variety and may bring significant value through the processing of Big Data. The transformation of Big Data's 4 Vs into the 5th (value) is a grand challenge for processing capacity. Cloud Computing has emerged as a new paradigm to provide computing as a utility service for addressing different processing needs with a) on demand services, b) pooled resources, c) elasticity, d) broad band access and e) measured services. The utility of delivering computing capability fosters a potential solution for the transformation of Big Data's 4 Vs into the 5th (value). This paper investigates how Cloud Computing can be utilized to address Big Data challenges to enable such transformation. We introduce and review four geospatial scientific examples, including climate studies, geospatial knowledge mining, land cover simulation, and dust storm modelling. The method is presented in a tabular framework as a guidance to leverage Cloud Computing for Big Data solutions. It is demostrated throught the four examples that the framework method supports the life cycle of Big Data processing, including management, access, mining analytics, simulation and forecasting. This tabular framework can also be referred as a guidance to develop potential solutions for other big geospatial data challenges and initiatives, such as smart cities.}
}
@article{LIM2021100013,
title = {State of data platforms for connected vehicles and infrastructures},
journal = {Communications in Transportation Research},
volume = {1},
pages = {100013},
year = {2021},
issn = {2772-4247},
doi = {https://doi.org/10.1016/j.commtr.2021.100013},
url = {https://www.sciencedirect.com/science/article/pii/S2772424721000135},
author = {Kai Li Lim and Jake Whitehead and Dongyao Jia and Zuduo Zheng},
keywords = {Connected mobility, Vehicular networks, Data platforms, Electric vehicles},
abstract = {The continuing expansion of connected and electro-mobility products and services has led to their ability to rapidly generate very large amounts of data, leading to a demand for effective data management solutions. This is further catalysed through the need for society to make informed policies and decisions that can properly support their emerging growth. While data systems and platforms exist, they are often proprietary, being only compatible to the products that they are designed for. Given the products and services generate energy and spatial-temporal data that can often correlate, a lack of interoperability between these systems would impede decision making, as data from each system must be considered independently. By studying currently available data platforms and frameworks, this paper weighs the problems that these products address, and identifies necessary gaps for a more cohesive platform to exist. This is performed through a top-down approach, whereby broader vehicle-to-everything approaches are first studied, before moving to the components that could comprise a data platform to integrate and ingest these various data feeds. Finally, potential design considerations for a data platform is presented, along with examples of application benefits that would enable users to make more informed and holistic decisions about current mobility options.}
}
@article{DUGGAL2021101791,
title = {Infrastructure, mobility and safety 4.0: Modernization in road transportation},
journal = {Technology in Society},
volume = {67},
pages = {101791},
year = {2021},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101791},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21002669},
author = {Angel Swastik Duggal and Rajesh Singh and Anita Gehlot and Lovi Raj Gupta and Sheik Vaseem Akram and Chander Prakash and Sunpreet Singh and Raman Kumar},
keywords = {Artificial intelligence (AI), Big data, Electric vehicles (EV), Digitalization, Sustainability, Machine learning (ML), Mobility},
abstract = {This study explores the modernization of road-based technologies for the enhancement of mobility while also implementing safer transportation. Mobility plays a critical role in everyday life on a micro and a macro scale combined. Modernization in mobility would enable establishment of a sustainable, digitalized and informed society. The inclusion of AI/ML to enhance road environment, curbing driver distraction, adopting electric vehicles, and integrating low power computing units in vehicular networks are among the potential recommendations for strengthening the evolving digital road architecture. The current ecosystem surrounding road safety and mobility can be boosted even further upon integrating products of modern technology into the classical elements of transportation. Modern technologies are classified and perceptually investigated by realizing the current challenges and proposing seamless potential extensions to the existing infrastructure from each domain. Techno-administrative concepts like the regulation of individual risk profiles for achieving a safer road environment are addressed.}
}
@article{SHINDE2021313,
title = {LidarCSNet: A Deep Convolutional Compressive Sensing Reconstruction Framework for 3D Airborne Lidar Point Cloud},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {180},
pages = {313-334},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.08.019},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621002252},
author = {Rajat C. Shinde and Surya S. Durbha and Abhishek V. Potnis},
keywords = {Compressive sensing, Deep learning for point cloud classification, 3D airborne lidar point cloud, Deep network-based optimization, Lidar for forests, Urban environment, Convolutional sparse coding, Ensemble deep learning},
abstract = {Lidar scanning is a widely used surveying and mapping technique ranging across remote-sensing applications involving topological, and topographical information. Typically, lidar point clouds, unlike images, lack inherent consistent structure and store redundant information thus requiring huge processing time. The Compressive Sensing (CS) framework leverages this property to generate sparse representations and accurately reconstructs the signals from very few linear, non-adaptive measurements. The reconstruction is based on valid assumptions on the following parameters- (1) sampling function governed by sampling ratio for generating samples, and (2) measurement function for sparsely representing the data in a low-dimensional subspace. In our work, we address the following motivating scientific questions- Is it possible to reconstruct dense point cloud data from a few sparse measurements? And, what could be the optimal limit for CS sampling ratio with respect to overall classification metrics? Our work proposes a novel Convolutional Neural Network based deep Compressive Sensing Network (named LidarCSNet) for generating sparse representations using publicly available 3D lidar point clouds of the Philippines. We have performed extensive evaluations for analysing the reconstruction for different sampling ratios {4%, 10%, 25%, 50% and 75%} and we observed that our proposed LidarCSNet reconstructed the 3D lidar point cloud with a maximum PSNR of 54.47 dB for a sampling ratio of 75%. We investigate the efficacy of our novel LidarCSNet framework with 3D airborne lidar point clouds for two domains - forests and urban environment on the basis of Peak Signal to Noise Ratio, Haussdorf distance, Pearson Correlation Coefficient and Kolmogorov-Smirnov Test Statistic as evaluation metrics for 3D reconstruction. The results relevant to forests such as Canopy Height Model and 2D vertical profile are compared with the ground truth to investigate the robustness of the LidarCSNet framework. In the urban environment, we extend our work to propose two novel 3D lidar point cloud classification frameworks, LidarNet and LidarNet++, achieving maximum classification accuracy of 90.6% as compared to other prominent lidar classification frameworks. The improved classification accuracy is attributed to ensemble-based learning on the proposed novel 3D feature stack and justifies the robustness of using our proposed LidarCSNet for near-perfect reconstruction followed by classification. We document our classification results for the original dataset along with the point clouds reconstructed by using LidarCSNet for five different measurement ratios - based on overall accuracy and mean Intersection over Union as evaluation metrics for 3D classification. It is envisaged that our proposed deep network based convolutional sparse coding approach for rapid lidar point cloud processing finds huge potential across vast applications, either as a plug-and-play (reconstruction) framework or as an end-to-end (reconstruction followed by classification) system for scalability.}
}
@article{ABDULQADDER2020107364,
title = {Multi-layered intrusion detection and prevention in the SDN/NFV enabled cloud of 5G networks using AI-based defense mechanisms},
journal = {Computer Networks},
volume = {179},
pages = {107364},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107364},
url = {https://www.sciencedirect.com/science/article/pii/S1389128619310205},
author = {Ihsan H Abdulqadder and Shijie Zhou and Deqing Zou and Israa T. Aziz and Syed Muhammad Abrar Akber},
keywords = {SDN/NFV Cloud of 5G, Multilayered architecture, Intrusion detection and prevention, And artificial intelligence},
abstract = {Software defined networking (SDN), network function virtualization (NFV), and cloud computing are receiving significant attention in 5G networks. However, this attention creates a new challenge for security provisioning in these integrated technologies. Research in the field of SDN, NFV, cloud computing, and 5G has recently focused on the intrusion detection and prevention system (IDPS). Existing IDPS solutions are inadequate, which could cause large resource wastage and several security threats. To alleviate security issues, timely detection of an attacker is important. Thus, in this paper, we propose a novel approach that is referred to as multilayered intrusion detection and prevention (ML-IDP) in an SDN/NFV-enabled cloud of 5G networks. The proposed approach defends against security attacks using artificial intelligence (AI). In this paper, we employed five layers: data acquisition layer, switches layer, domain controllers (DC) layer, smart controller (SC) layer, and virtualization layer (NFV infrastructure). User authentication is held in the first layer using the Four-Q-Curve algorithm. To address the flow table overloading attack in the switches layer, the game theory approach, which is executed in the IDP agent, is proposed. The involvement of the IDP agent is to completely avoid a flow table overloading attack by a deep reinforcement learning algorithm, and thus, it updates the current state of all switches. In the DC layer, packets are processed and classified into two classes (normal and suspicious) by a Shannon Entropy function. Normal packets are forwarded to the cloud via the SC. Suspicious packets are sent to the VNF using a growing multiple self-organization map (GM-SOM). The proposed ML-IDP system is evaluated using NS3.26 for different security attacks, including IP Spoofing, flow table overloading, DDoS, Control Plane Saturation, and host location hijacking. From the experiment results, we proved that the ML-IDP with AI-based defense mechanisms effectively detects and prevents attacks.}
}
@article{CARVALHO2019178,
title = {Edge Computing Applied to Industrial Machines},
journal = {Procedia Manufacturing},
volume = {38},
pages = {178-185},
year = {2019},
note = {29th International Conference on Flexible Automation and Intelligent Manufacturing ( FAIM 2019), June 24-28, 2019, Limerick, Ireland, Beyond Industry 4.0: Industrial Advances, Engineering Education and Intelligent Manufacturing},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2020.01.024},
url = {https://www.sciencedirect.com/science/article/pii/S2351978920300251},
author = {Anderson Carvalho and Niall {O’ Mahony} and Lenka Krpalkova and Sean Campbell and Joseph Walsh and Pat Doody},
keywords = {edge computing, industrial machines, artificial intelligence},
abstract = {This paper will review specific aspects of the edge computing architecture and its correlation to industrial applications as part of a literal revision, performed to provide evidences supporting the use of edge solutions in challenging conditions which arise in Industry 4.0, including smart factories and smart agriculture. Further it presents findings about accuracy improvements comparing conventional machine learning techniques for many important tasks, such as image classification and speech recognition, how edge applications are adopting Artificial Intelligence (AI) to assist users in tasks like augmented reality, face recognition, and intelligent personal assistants. Studies like this leads the present review to acknowledge that AI has great potential when combined with edge devices and might maximize the potential of “not-smart” existing applications. This paper aims to present some important findings on this area, compare main architectural aspects and provide a broad view of how edge solutions might be built. Having discussed how the edge computing works and having provided an overview about how it may be applied to industrial plants, the final section of this paper addresses ways to foment the use of artificial intelligence on edge solutions, forming a new source of “smart capabilities” to existing environments.}
}
@article{TORRES2021102214,
title = {An open source framework based on Kafka-ML for Distributed DNN inference over the Cloud-to-Things continuum},
journal = {Journal of Systems Architecture},
volume = {118},
pages = {102214},
year = {2021},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2021.102214},
url = {https://www.sciencedirect.com/science/article/pii/S138376212100151X},
author = {Daniel R. Torres and Cristian Martín and Bartolomé Rubio and Manuel Díaz},
keywords = {Distributed deep neural networks, Cloud computing, Fog/edge computing, Distributed processing, Low-latency fault-tolerant framework},
abstract = {The current dependency of Artificial Intelligence (AI) systems on Cloud computing implies higher transmission latency and bandwidth consumption. Moreover, it challenges the real-time monitoring of physical objects, e.g., the Internet of Things (IoT). Edge systems bring computing closer to end devices and support time-sensitive applications. However, Edge systems struggle with state-of-the-art Deep Neural Networks (DNN) due to computational resource limitations. This paper proposes a technology framework that combines the Edge-Cloud architecture concept with BranchyNet advantages to support fault-tolerant and low-latency AI predictions. The implementation and evaluation of this framework allow assessing the benefits of running Distributed DNN (DDNN) in the Cloud-to-Things continuum. Compared to a Cloud-only deployment, the results obtained show an improvement of 45.34% in the response time. Furthermore, this proposal presents an extension for Kafka-ML that reduces rigidness over the Cloud-to-Things continuum managing and deploying DDNN.}
}
@article{MAHBUB2020102761,
title = {Progressive researches on IoT security: An exhaustive analysis from the perspective of protocols, vulnerabilities, and preemptive architectonics},
journal = {Journal of Network and Computer Applications},
volume = {168},
pages = {102761},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102761},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520302356},
author = {Mobasshir Mahbub},
keywords = {IoT, Vulnerability, Security, Cryptography, Fog computing, Edge computing, Machine learning},
abstract = {The IoT is the upcoming one of the major networking technologies. Using the IoT, different items or devices can be allowed to continuously generate, obtain, and exchange information. Different IoT applications nowadays are centered on computerizing various errands and are attempting to engage the inanimate physical items to act without direct supervision of a human. The current and forthcoming IoT services are exceptionally encouraging to build the degree of solace, proficiency, and automation for the clients. To obtain the option to actualize such a world in a continuously developing manner requires high security, protection, verification, and recuperation from assaults. Right now, incorporating the requisite changes in IoT systems engineering to achieve end-to-end, stable IoT infrastructure is paramount. In this research, a comprehensive analysis is incorporated into the security-relevant problems and threat wellsprings in IoT resources or applications. Specific that and current advancements based on maintaining a high degree of confidence in IoT apps are addressed while looking at the security issues. Four distinct developments are investigated, including cryptography, fog computing, edge computing, and ML (Machine Learning), to extend the degree of IoT security.}
}
@article{SUH2022108302,
title = {Discriminative feature generation for classification of imbalanced data},
journal = {Pattern Recognition},
volume = {122},
pages = {108302},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.108302},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321004829},
author = {Sungho Suh and Paul Lukowicz and Yong Oh Lee},
keywords = {Imbalanced classification, Generative adversarial networks, Discriminative feature generation, Transfer learning, Feature map regularization},
abstract = {The data imbalance problem is a frequent bottleneck in the classification performance of neural networks. In this paper, we propose a novel supervised discriminative feature generation (DFG) method for a minority class dataset. DFG is based on the modified structure of a generative adversarial network consisting of four independent networks: generator, discriminator, feature extractor, and classifier. To augment the selected discriminative features of the minority class data by adopting an attention mechanism, the generator for the class-imbalanced target task is trained, and the feature extractor and classifier are regularized using the pre-trained features from a large source data. The experimental results show that the DFG generator enhances the augmentation of the label-preserved and diverse features, and the classification results are significantly improved on the target task. The feature generation model can contribute greatly to the development of data augmentation methods through discriminative feature generation and supervised attention methods.}
}
@article{CRIADO2021103501,
title = {Heuristics-based mediation for building smart architectures at run-time},
journal = {Computer Standards & Interfaces},
volume = {75},
pages = {103501},
year = {2021},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2020.103501},
url = {https://www.sciencedirect.com/science/article/pii/S0920548920303883},
author = {Javier Criado and Luis Iribarne and Nicolás Padilla},
keywords = {Dynamic software architectures, Heuristics, Trading, A* search, Model-based engineering},
abstract = {Smart architectures are increasingly being used in current software development. Smart user interfaces, smart homes, or smart buildings are becoming common examples in the new era of smart cities. Software architectures usually related to these domains need to be adapted and reconfigured at run-time, for example, to provide new services, react to user interaction, or due to changes decided from the business logic of the application. Component-based techniques are a suitable way to carry out this kind of adaptation, as dynamic reconfiguration operations can be applied to the architecture. In this paper, we address run-time generation of component-based applications, taking the abstract definitions of their architecture as a reference, in addition to a set of available components. The process calculates the best configuration of components from the abstract definition by applying a trading approach based on an adapted A* algorithm. This algorithm uses heuristics based on syntactic and semantic information obtained from the component definitions. A case study related to mashup user interfaces formed by coarse-grained components is also explained. In short, the results show the usefulness of heuristics and suitable execution times for building the best configurations.}
}
@article{RASLAN2022101592,
title = {Deep-BiGRU based channel estimation scheme for MIMO–FBMC systems},
journal = {Physical Communication},
volume = {51},
pages = {101592},
year = {2022},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101592},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721002871},
author = {Walid A. Raslan and Mohamed A. Mohamed and Heba M. Abdel-Atty},
keywords = {Channel estimation, Deep learning (DL), Filter bank multicarrier (FBMC), Gated-recurrent unit (GRU), Interference approximation method (IAM), Multiple-input multiple-output (MIMO)},
abstract = {Deep Learning (DL)–based wireless communication systems have the potential to improve the conventional functions and current architecture of communication systems. In this paper, we propose a novel DL-based channel estimation scheme for multiple-input multiple-output filter bank multicarrier with offset quadrature amplitude modulation (MIMO-FBMC/OQAM) systems called deep bidirectional gated-recurrent unit (BiGRU) scheme. This scheme can easily be applied to a single-input single-output (SISO) system. The proposed scheme is divided into two stages: offline and online. The network is first trained in the offline stage. The prediction of channel information and estimation of the channel matrix using the trained network is then performed in the online stage. The simulation results in terms of the normalized mean square error (NMSE) and bit error rate (BER) demonstrate that, under different time-varying channel models, the proposed DL scheme significantly improves the channel estimation performance of FBMC for single and multiple antennas compared to conventional interference approximation method (IAM) channel estimation methods.}
}
@article{SUBRAMANIAN2021103132,
title = {A deep genetic algorithm for human activity recognition leveraging fog computing frameworks},
journal = {Journal of Visual Communication and Image Representation},
volume = {77},
pages = {103132},
year = {2021},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2021.103132},
url = {https://www.sciencedirect.com/science/article/pii/S1047320321000857},
author = {R. Raja Subramanian and V. Vasudevan},
keywords = {Deep genetic algorithm, Human activity recognition, Fog computing, Ambulatory healthcare},
abstract = {With modern e-healthcare developments, ambulatory healthcare has become a prominent requirement for physical or mental ailed, elderly, childhood people. One of the major challenges in such applications is timing and precision. A potential solution to this problem is the fog-assisted cloud computing architecture. The activity recognition task is performed with the hybrid advantages of deep learning and genetic algorithms. The video frames captured from vision cameras are subjected to the genetic change detection algorithm, which detects changes in activities of subsequent frames. Consequently, the deep learning algorithm recognizes the activity of the changed frame. This hybrid algorithm is run on top of fog-assisted cloud framework, fogbus and the performance measures including latency, execution time, arbitration time and jitter are observed. Empirical evaluations of the proposed model against three activity data sets shows that the proposed deep genetic algorithm exhibits higher accuracy in inferring human activities as compared to the state-of-the-art algorithms.}
}
@article{JIN2020102665,
title = {Urban ride-hailing demand prediction with multiple spatio-temporal information fusion network},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {117},
pages = {102665},
year = {2020},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2020.102665},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X20305805},
author = {Guangyin Jin and Yan Cui and Liang Zeng and Hanbo Tang and Yanghe Feng and Jincai Huang},
keywords = {Ride-hailing prediction, Information fusion, Graph convolutional neural networks, Sequence to sequence learning, Spatio-temporal analysis},
abstract = {Urban ride-hailing demand prediction is a long-term but challenging task for online car-hailing system decision, taxi scheduling and intelligent transportation construction. Accurate urban ride-hailing demand prediction can improve vehicle utilization and scheduling, reduce waiting time and traffic congestion. Existing traffic flow prediction approaches mainly utilize region-based situation awareness image or station-based graph representation to capture traffic spatial dynamic while we observe that combination of situation awareness image and graph representation are also critical for accurate forecasting. In this paper, we propose the Multiple Spatio-Temporal Information Fusion Networks (MSTIF-Net), a novel deep learning approach to better fuse multiple situation awareness information and graphs representation. MSTIF-Net model integrates structures of Graph Convolutional Neural Networks (GCN), Variational Auto-Encoders (VAE) and Sequence to Sequence Learning (Seq2seq) model to obtain the joint latent representation of urban ride-hailing situation that contain both Euclidean spatial features and non-Euclidean structural features, and capture the spatio-temporal dynamics. We evaluate the proposed model on two real-world large scale urban traffic datasets and the experimental studies demonstrate MSTIF-Net has achieved superior performance of urban ride-Hailing demand prediction compared with some traditional state-of-art baseline models.}
}

@Article{app10134574,
AUTHOR = {Ghaffarian, Saman and Rezaie Farhadabad, Ali and Kerle, Norman},
TITLE = {Post-Disaster Recovery Monitoring with Google Earth Engine},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {13},
ARTICLE-NUMBER = {4574},
URL = {https://www.mdpi.com/2076-3417/10/13/4574},
ISSN = {2076-3417},
ABSTRACT = {Post-disaster recovery is a complex process in terms of measuring its progress after a disaster and understanding its components and influencing factors. During this process, disaster planners and governments need reliable information to make decisions towards building the affected region back to normal (pre-disaster), or even improved, conditions. Hence, it is essential to use methods to understand the dynamics/variables of the post-disaster recovery process, and rapid and cost-effective data and tools to monitor the process. Google Earth Engine (GEE) provides free access to vast amounts of remote sensing (RS) data and a powerful computing environment in a cloud platform, making it an attractive tool to analyze earth surface data. In this study we assessed the suitability of GEE to analyze and track recovery. To do so, we employed GEE to assess the recovery process over a three-year period after Typhoon Haiyan, which struck Leyte island, in the Philippines, in 2013. We developed an approach to (i) generate cloud and shadow-free image composites from Landsat 7 and 8 satellite imagery and produce land cover classification data using the Random Forest method, and (ii) generate damage and recovery maps based on post-classification change analysis. The method produced land cover maps with accuracies &gt;88%. We used the model to produce damage and three time-step recovery maps for 62 municipalities on Leyte island. The results showed that most of the municipalities had recovered after three years in terms of returning to the pre-disaster situation based on the selected land cover change analysis. However, more analysis (e.g., functional assessment) based on detailed data (e.g., land use maps) is needed to evaluate the more complex and subtle socio-economic aspects of the recovery. The study showed that GEE has good potential for monitoring the recovery process for extensive regions. However, the most important limitation is the lack of very-high-resolution RS data that are critical to assess the process in detail, in particular in complex urban environments.},
DOI = {10.3390/app10134574}
}



@Article{rs12132136,
AUTHOR = {Veeranampalayam Sivakumar, Arun Narenthiran and Li, Jiating and Scott, Stephen and Psota, Eric and J. Jhala, Amit and Luck, Joe D. and Shi, Yeyin},
TITLE = {Comparison of Object Detection and Patch-Based Classification Deep Learning Models on Mid- to Late-Season Weed Detection in UAV Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {13},
ARTICLE-NUMBER = {2136},
URL = {https://www.mdpi.com/2072-4292/12/13/2136},
ISSN = {2072-4292},
ABSTRACT = {Mid- to late-season weeds that escape from the routine early-season weed management threaten agricultural production by creating a large number of seeds for several future growing seasons. Rapid and accurate detection of weed patches in field is the first step of site-specific weed management. In this study, object detection-based convolutional neural network models were trained and evaluated over low-altitude unmanned aerial vehicle (UAV) imagery for mid- to late-season weed detection in soybean fields. The performance of two object detection models, Faster RCNN and the Single Shot Detector (SSD), were evaluated and compared in terms of weed detection performance using mean Intersection over Union (IoU) and inference speed. It was found that the Faster RCNN model with 200 box proposals had similar good weed detection performance to the SSD model in terms of precision, recall, f1 score, and IoU, as well as a similar inference time. The precision, recall, f1 score and IoU were 0.65, 0.68, 0.66 and 0.85 for Faster RCNN with 200 proposals, and 0.66, 0.68, 0.67 and 0.84 for SSD, respectively. However, the optimal confidence threshold of the SSD model was found to be much lower than that of the Faster RCNN model, which indicated that SSD might have lower generalization performance than Faster RCNN for mid- to late-season weed detection in soybean fields using UAV imagery. The performance of the object detection model was also compared with patch-based CNN model. The Faster RCNN model yielded a better weed detection performance than the patch-based CNN with and without overlap. The inference time of Faster RCNN was similar to patch-based CNN without overlap, but significantly less than patch-based CNN with overlap. Hence, Faster RCNN was found to be the best model in terms of weed detection performance and inference time among the different models compared in this study. This work is important in understanding the potential and identifying the algorithms for an on-farm, near real-time weed detection and management.},
DOI = {10.3390/rs12132136}
}



@Article{app10134668,
AUTHOR = {Cao, Dalu and Bai, Guangchen},
TITLE = {A Study on Aeroengine Conceptual Design Considering Multi-Mission Performance Reliability},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {13},
ARTICLE-NUMBER = {4668},
URL = {https://www.mdpi.com/2076-3417/10/13/4668},
ISSN = {2076-3417},
ABSTRACT = {Owing to the realization of multi-mission adaptability requires more complex mechanical structure, the candidates of future aviation propulsion are confronted with more overall reliability problems than that of the conventional gas turbine engine. This situation is challenging to a traditional aeroengine deterministic design method. To overcome this challenge, the Reliability-based Multi-Design Point Methodology is proposed for aeroengine conceptual design. The presented methodology adopted an unconventional approach of engaging the reliability prediction by artificial neural network (ANN) surrogate models rather than the time-consuming Monte Carlo (MC) simulation. Based on the Adaptive Particle swarm optimization, the utilization of the pre-training technique optimizes the initial network parameters to acquire better-conditioned initial network, which is sited closer to designated optimum so that contributes to the convergence property. Moreover, a new hybrid algorithm is presented to integrate the pre-training technique into neural network training procedure in order to enhance the ANN performance. The proposed methodology is applied to the cycle design of a turbofan engine with uncertainty component performance. The testing results certify that the prediction accuracy of pre-trained ANN is improved with negligible computational cost, which only spent nearly one-millionth as much time as the MC-based probabilistic analysis (0.1267 s vs. 95,262 s, for 20 testing samples). The MC simulation results substantiate that optimal cycle parameters precisely improve the engine overall performance to simultaneously reach expected reliability (&ge;98.9%) in multiple operating conditions without unnecessary performance redundancy, which verifies the efficiency of the presented methodology. The presented efforts provide a novel approach for aeroengine cycle design, and enrich reliability design theory as well.},
DOI = {10.3390/app10134668}
}



@Article{rs12132169,
AUTHOR = {Arce, Samuel and Vernon, Cory A. and Hammond, Joshua and Newell, Valerie and Janson, Joseph and Franke, Kevin W. and Hedengren, John D.},
TITLE = {Automated 3D Reconstruction Using Optimized View-Planning Algorithms for Iterative Development of Structure-from-Motion Models},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {13},
ARTICLE-NUMBER = {2169},
URL = {https://www.mdpi.com/2072-4292/12/13/2169},
ISSN = {2072-4292},
ABSTRACT = {Unsupervised machine learning algorithms (clustering, genetic, and principal component analysis) automate Unmanned Aerial Vehicle (UAV) missions as well as the creation and refinement of iterative 3D photogrammetric models with a next best view (NBV) approach. The novel approach uses Structure-from-Motion (SfM) to achieve convergence to a specified orthomosaic resolution by identifying edges in the point cloud and planning cameras that &ldquo;view&rdquo; the holes identified by edges without requiring an initial model. This iterative UAV photogrammetric method successfully runs in various Microsoft AirSim environments. Simulated ground sampling distance (GSD) of models reaches as low as     3.4     cm per pixel, and generally, successive iterations improve resolution. Besides analogous application in simulated environments, a field study of a retired municipal water tank illustrates the practical application and advantages of automated UAV iterative inspection of infrastructure using     63 %     fewer photographs than a comparable manual flight with analogous density point clouds obtaining a GSD of less than 3 cm per pixel. Each iteration qualitatively increases resolution according to a logarithmic regression, reduces holes in models, and adds details to model edges.},
DOI = {10.3390/rs12132169}
}



@Article{agriculture10070277,
AUTHOR = {García-Martínez, Héctor and Flores-Magdaleno, Héctor and Ascencio-Hernández, Roberto and Khalil-Gardezi, Abdul and Tijerina-Chávez, Leonardo and Mancilla-Villa, Oscar R. and Vázquez-Peña, Mario A.},
TITLE = {Corn Grain Yield Estimation from Vegetation Indices, Canopy Cover, Plant Density, and a Neural Network Using Multispectral and RGB Images Acquired with Unmanned Aerial Vehicles},
JOURNAL = {Agriculture},
VOLUME = {10},
YEAR = {2020},
NUMBER = {7},
ARTICLE-NUMBER = {277},
URL = {https://www.mdpi.com/2077-0472/10/7/277},
ISSN = {2077-0472},
ABSTRACT = {Corn yields vary spatially and temporally in the plots as a result of weather, altitude, variety, plant density, available water, nutrients, and planting date; these are the main factors that influence crop yield. In this study, different multispectral and red-green-blue (RGB) vegetation indices were analyzed, as well as the digitally estimated canopy cover and plant density, in order to estimate corn grain yield using a neural network model. The relative importance of the predictor variables was also analyzed. An experiment was established with five levels of nitrogen fertilization (140, 200, 260, 320, and 380 kg/ha) and four replicates, in a completely randomized block design, resulting in 20 experimental polygons. Crop information was captured using two sensors (Parrot Sequoia_4.9, and DJI FC6310_8.8) mounted on an unmanned aerial vehicle (UAV) for two flight dates at 47 and 79 days after sowing (DAS). The correlation coefficient between the plant density, obtained through the digital count of corn plants, and the corn grain yield was 0.94; this variable was the one with the highest relative importance in the yield estimation according to Garson&rsquo;s algorithm. The canopy cover, digitally estimated, showed a correlation coefficient of 0.77 with respect to the corn grain yield, while the relative importance of this variable in the yield estimation was 0.080 and 0.093 for 47 and 79 DAS, respectively. The wide dynamic range vegetation index (WDRVI), plant density, and canopy cover showed the highest correlation coefficient and the smallest errors (R = 0.99, mean absolute error (MAE) = 0.028 t ha&minus;1, root mean square error (RMSE) = 0.125 t ha&minus;1) in the corn grain yield estimation at 47 DAS, with the WDRVI index and the density being the variables with the highest relative importance for this crop development date. For the 79 DAS flight, the combination of the normalized difference vegetation index (NDVI), normalized difference red edge (NDRE), WDRVI, excess green (EXG), triangular greenness index (TGI), and visible atmospherically resistant index (VARI), as well as plant density and canopy cover, generated the highest correlation coefficient and the smallest errors (R = 0.97, MAE = 0.249 t ha&minus;1, RMSE = 0.425 t ha&minus;1) in the corn grain yield estimation, where the density and the NDVI were the variables with the highest relative importance, with values of 0.295 and 0.184, respectively. However, the WDRVI, plant density, and canopy cover estimated the corn grain yield with acceptable precision (R = 0.96, MAE = 0.209 t ha&minus;1, RMSE = 0.449 t ha&minus;1). The generated neural network models provided a high correlation coefficient between the estimated and the observed corn grain yield, and also showed acceptable errors in the yield estimation. The spectral information registered through remote sensors mounted on unmanned aerial vehicles and its processing in vegetation indices, canopy cover, and plant density allowed the characterization and estimation of corn grain yield. Such information is very useful for decision-making and agricultural activities planning.},
DOI = {10.3390/agriculture10070277}
}



@Article{electronics9071121,
AUTHOR = {Kong, Weiren and Zhou, Deyun and Yang, Zhen and Zhao, Yiyang and Zhang, Kai},
TITLE = {UAV Autonomous Aerial Combat Maneuver Strategy Generation with Observation Error Based on State-Adversarial Deep Deterministic Policy Gradient and Inverse Reinforcement Learning},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {7},
ARTICLE-NUMBER = {1121},
URL = {https://www.mdpi.com/2079-9292/9/7/1121},
ISSN = {2079-9292},
ABSTRACT = {With the development of unmanned aerial vehicle (UAV) and artificial intelligence (AI) technology, Intelligent UAV will be widely used in future autonomous aerial combat. Previous researches on autonomous aerial combat within visual range (WVR) have limitations due to simplifying assumptions, limited robustness, and ignoring sensor errors. In this paper, in order to consider the error of the aircraft sensors, we model the aerial combat WVR as a state-adversarial Markov decision process (SA-MDP), which introduce the small adversarial perturbations on state observations and these perturbations do not alter the environment directly, but can mislead the agent into making suboptimal decisions. Meanwhile, we propose a novel autonomous aerial combat maneuver strategy generation algorithm with high-performance and high-robustness based on state-adversarial deep deterministic policy gradient algorithm (SA-DDPG), which add a robustness regularizers related to an upper bound on performance loss at the actor-network. At the same time, a reward shaping method based on maximum entropy (MaxEnt) inverse reinforcement learning algorithm (IRL) is proposed to improve the aerial combat strategy generation algorithm&rsquo;s efficiency. Finally, the efficiency of the aerial combat strategy generation algorithm and the performance and robustness of the resulting aerial combat strategy is verified by simulation experiments. Our main contributions are three-fold. First, to introduce the observation errors of UAV, we are modeling air combat as SA-MDP. Second, to make the strategy network of air combat maneuver more robust in the presence of observation errors, we introduce regularizers into the policy gradient. Third, to solve the problem that air combat&rsquo;s reward function is too sparse, we use MaxEnt IRL to design a shaping reward to accelerate the convergence of SA-DDPG.},
DOI = {10.3390/electronics9071121}
}



@Article{drones4030034,
AUTHOR = {Shahmoradi, Javad and Talebi, Elaheh and Roghanchi, Pedram and Hassanalian, Mostafa},
TITLE = {A Comprehensive Review of Applications of Drone Technology in the Mining Industry},
JOURNAL = {Drones},
VOLUME = {4},
YEAR = {2020},
NUMBER = {3},
ARTICLE-NUMBER = {34},
URL = {https://www.mdpi.com/2504-446X/4/3/34},
ISSN = {2504-446X},
ABSTRACT = {This paper aims to provide a comprehensive review of the current state of drone technology and its applications in the mining industry. The mining industry has shown increased interest in the use of drones for routine operations. These applications include 3D mapping of the mine environment, ore control, rock discontinuities mapping, postblast rock fragmentation measurements, and tailing stability monitoring, to name a few. The article offers a review of drone types, specifications, and applications of commercially available drones for mining applications. Finally, the research needs for the design and implementation of drones for underground mining applications are discussed.},
DOI = {10.3390/drones4030034}
}



@Article{ani10071207,
AUTHOR = {Akçay, Hüseyin Gökhan and Kabasakal, Bekir and Aksu, Duygugül and Demir, Nusret and Öz, Melih and Erdoğan, Ali},
TITLE = {Automated Bird Counting with Deep Learning for Regional Bird Distribution Mapping},
JOURNAL = {Animals},
VOLUME = {10},
YEAR = {2020},
NUMBER = {7},
ARTICLE-NUMBER = {1207},
URL = {https://www.mdpi.com/2076-2615/10/7/1207},
PubMedID = {32708550},
ISSN = {2076-2615},
ABSTRACT = {A challenging problem in the field of avian ecology is deriving information on bird population movement trends. This necessitates the regular counting of birds which is usually not an easily-achievable task. A promising attempt towards solving the bird counting problem in a more consistent and fast way is to predict the number of birds in different regions from their photos. For this purpose, we exploit the ability of computers to learn from past data through deep learning which has been a leading sub-field of AI for image understanding. Our data source is a collection of on-ground photos taken during our long run of birding activity. We employ several state-of-the-art generic object-detection algorithms to learn to detect birds, each being a member of one of the 38 identified species, in natural scenes. The experiments revealed that computer-aided counting outperformed the manual counting with respect to both accuracy and time. As a real-world application of image-based bird counting, we prepared the spatial bird order distribution and species diversity maps of Turkey by utilizing the geographic information system (GIS) technology. Our results suggested that deep learning can assist humans in bird monitoring activities and increase citizen scientists&rsquo; participation in large-scale bird surveys.},
DOI = {10.3390/ani10071207}
}



@Article{f11070763,
AUTHOR = {Klemmt, Hans-Joachim and Seitz, Rudolf and Straub, Christoph},
TITLE = {Application of Haralick’s Texture Features for Rapid Detection of Windthrow Hotspots in Orthophotos},
JOURNAL = {Forests},
VOLUME = {11},
YEAR = {2020},
NUMBER = {7},
ARTICLE-NUMBER = {763},
URL = {https://www.mdpi.com/1999-4907/11/7/763},
ISSN = {1999-4907},
ABSTRACT = {Windthrow and storm damage are crucial issues in practical forestry. We propose a method for rapid detection of windthrow hotspots in airborne digital orthophotos. Therefore, we apply Haralick&rsquo;s texture features on 50 &times; 50 m cells of the orthophotos and classify the cells with a random forest algorithm. We apply the classification results from a training data set on a validation set. The overall classification accuracy of the proposed method varies between 76% for fine distinction of the cells and 96% for a distinction level that tried to detect only severe damaged cells. The proposed method enables the rapid detection of windthrow hotspots in forests immediately after their occurrence in single-date data. It is not adequate for the determination of areas with only single fallen trees. Future research will investigate the possibilities and limitations when applying the method on other data sources (e.g., optical satellite data).},
DOI = {10.3390/f11070763}
}



@Article{s20143954,
AUTHOR = {Ahmed, Habib and La, Hung Manh and Gucunski, Nenad},
TITLE = {Review of Non-Destructive Civil Infrastructure Evaluation for Bridges: State-of-the-Art Robotic Platforms, Sensors and Algorithms},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {14},
ARTICLE-NUMBER = {3954},
URL = {https://www.mdpi.com/1424-8220/20/14/3954},
ISSN = {1424-8220},
ABSTRACT = {The non-destructive evaluation (NDE) of civil infrastructure has been an active area of research in recent decades. The traditional inspection of civil infrastructure mostly relies on visual inspection using human inspectors. To facilitate this process, different sensors for data collection and techniques for data analyses have been used to effectively carry out this task in an automated fashion. This review-based study will examine some of the recent developments in the field of autonomous robotic platforms for NDE and the structural health monitoring (SHM) of bridges. Some of the salient features of this review-based study will be discussed in the light of the existing surveys and reviews that have been published in the recent past, which will enable the clarification regarding the novelty of the present review-based study. The review methodology will be discussed in sufficient depth, which will provide insights regarding some of the primary aspects of the review methodology followed by this review-based study. In order to provide an in-depth examination of the state-of-the-art, the current research will examine the three major research streams. The first stream relates to technological robotic platforms developed for NDE of bridges. The second stream of literature examines myriad sensors used for the development of robotic platforms for the NDE of bridges. The third stream of literature highlights different algorithms for the surface- and sub-surface-level analysis of bridges that have been developed by studies in the past. A number of challenges towards the development of robotic platforms have also been discussed.},
DOI = {10.3390/s20143954}
}



@Article{rs12142308,
AUTHOR = {Muhadi, Nur Atirah and Abdullah, Ahmad Fikri and Bejo, Siti Khairunniza and Mahadi, Muhammad Razif and Mijic, Ana},
TITLE = {The Use of LiDAR-Derived DEM in Flood Applications: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {14},
ARTICLE-NUMBER = {2308},
URL = {https://www.mdpi.com/2072-4292/12/14/2308},
ISSN = {2072-4292},
ABSTRACT = {Flood occurrence is increasing due to escalated urbanization and extreme climate change; hence, various studies on this issue and methods of flood monitoring and mapping are also increasing to reduce the severe impacts of flood disasters. The advancement of current technologies such as light detection and ranging (LiDAR) systems facilitated and improved flood applications. In a LiDAR system, a laser emits light that travels to the ground and reflects off objects like buildings and trees. The reflected light energy returns to the sensor, whereby the time interval is recorded. Since the conventional methods cannot produce high-resolution digital elevation model (DEM) data, which results in low accuracy of flood simulation results, LiDAR data are extensively used as an alternative. This review aims to study the potential and the applications of LiDAR-derived DEM in flood studies. It also provides insight into the operating principles of different LiDAR systems, system components, and advantages and disadvantages of each system. This paper discusses several topics relevant to flood studies from a LiDAR-derived DEM perspective. Furthermore, the challenges and future perspectives regarding DEM LiDAR data for flood mapping and assessment are also reviewed. This study demonstrates that LiDAR-derived data are useful in flood risk management, especially in the future assessment of flood-related problems.},
DOI = {10.3390/rs12142308}
}



@Article{rs12142313,
AUTHOR = {El Mahrad, Badr and Newton, Alice and Icely, John D. and Kacimi, Ilias and Abalansa, Samuel and Snoussi, Maria},
TITLE = {Contribution of Remote Sensing Technologies to a Holistic Coastal and Marine Environmental Management Framework: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {14},
ARTICLE-NUMBER = {2313},
URL = {https://www.mdpi.com/2072-4292/12/14/2313},
ISSN = {2072-4292},
ABSTRACT = {Coastal and marine management require the evaluation of multiple environmental threats and issues. However, there are gaps in the necessary data and poor access or dissemination of existing data in many countries around the world. This research identifies how remote sensing can contribute to filling these gaps so that environmental agencies, such as the United Nations Environmental Programme, European Environmental Agency, and International Union for Conservation of Nature, can better implement environmental directives in a cost-effective manner. Remote sensing (RS) techniques generally allow for uniform data collection, with common acquisition and reporting methods, across large areas. Furthermore, these datasets are sometimes open-source, mainly when governments finance satellite missions. Some of these data can be used in holistic, coastal and marine environmental management frameworks, such as the DAPSI(W)R(M) framework (Drivers–Activities–Pressures–State changes–Impacts (on Welfare)–Responses (as Measures), an updated version of Drivers–Pressures–State–Impact–Responses. The framework is a useful and holistic problem-structuring framework that can be used to assess the causes, consequences, and responses to change in the marine environment. Six broad classifications of remote data collection technologies are reviewed for their potential contribution to integrated marine management, including Satellite-based Remote Sensing, Aerial Remote Sensing, Unmanned Aerial Vehicles, Unmanned Surface Vehicles, Unmanned Underwater Vehicles, and Static Sensors. A significant outcome of this study is practical inputs into each component of the DAPSI(W)R(M) framework. The RS applications are not expected to be all-inclusive; rather, they provide insight into the current use of the framework as a foundation for developing further holistic resource technologies for management strategies in the future. A significant outcome of this research will deliver practical insights for integrated coastal and marine management and demonstrate the usefulness of RS to support the implementation of environmental goals, descriptors, targets, and policies, such as the Water Framework Directive, Marine Strategy Framework Directive, Ocean Health Index, and United Nations Sustainable Development Goals. Additionally, the opportunities and challenges of these technologies are discussed.},
DOI = {10.3390/rs12142313}
}



@Article{s20144042,
AUTHOR = {Vidal, Vinicius F. and Honório, Leonardo M. and Dias, Felipe M. and Pinto, Milena F. and Carvalho, Alexandre L. and Marcato, Andre L. M.},
TITLE = {Sensors Fusion and Multidimensional Point Cloud Analysis for Electrical Power System Inspection},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {14},
ARTICLE-NUMBER = {4042},
URL = {https://www.mdpi.com/1424-8220/20/14/4042},
ISSN = {1424-8220},
ABSTRACT = {Thermal inspection is a powerful tool that enables the diagnosis of several components at its early stages. One critical aspect that influences thermal inspection outputs is the infrared reflection from external sources. This situation may change the readings, demanding that an expert correctly define the camera position, which is a time consuming and expensive operation. To mitigate this problem, this work proposes an autonomous system capable of identifying infrared reflections by filtering and fusing data obtained from both stereo and thermal cameras. The process starts by acquiring readings from multiples Observation Points (OPs) where, at each OP, the system processes the 3D point cloud and thermal image by fusing them together. The result is a dense point cloud where each point has its spatial position and temperature. Considering that each point&rsquo;s information is acquired from multiple poses, it is possible to generate a temperature profile of each spatial point and filter undesirable readings caused by interference and other phenomena. To deploy and test this approach, a Directional Robotic System (DRS) is mounted over a traditional human-operated service vehicle. In that way, the DRS autonomously tracks and inspects any desirable equipment as the service vehicle passes them by. To demonstrate the results, this work presents the algorithm workflow, a proof of concept, and a real application result, showing improved performance in real-life conditions.},
DOI = {10.3390/s20144042}
}



@Article{s20154082,
AUTHOR = {Qiu, Zhengjun and Zhao, Nan and Zhou, Lei and Wang, Mengcen and Yang, Liangliang and Fang, Hui and He, Yong and Liu, Yufei},
TITLE = {Vision-Based Moving Obstacle Detection and Tracking in Paddy Field Using Improved Yolov3 and Deep SORT},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {15},
ARTICLE-NUMBER = {4082},
URL = {https://www.mdpi.com/1424-8220/20/15/4082},
ISSN = {1424-8220},
ABSTRACT = {Using intelligent agricultural machines in paddy fields has received great attention. An obstacle avoidance system is required with the development of agricultural machines. In order to make the machines more intelligent, detecting and tracking obstacles, especially the moving obstacles in paddy fields, is the basis of obstacle avoidance. To achieve this goal, a red, green and blue (RGB) camera and a computer were used to build a machine vision system, mounted on a transplanter. A method that combined the improved You Only Look Once version 3 (Yolov3) and deep Simple Online and Realtime Tracking (deep SORT) was used to detect and track typical moving obstacles, and figure out the center point positions of the obstacles in paddy fields. The improved Yolov3 has 23 residual blocks and upsamples only once, and has new loss calculation functions. Results showed that the improved Yolov3 obtained mean intersection over union (mIoU) score of 0.779 and was 27.3% faster in processing speed than standard Yolov3 on a self-created test dataset of moving obstacles (human and water buffalo) in paddy fields. An acceptable performance for detecting and tracking could be obtained in a real paddy field test with an average processing speed of 5&ndash;7 frames per second (FPS), which satisfies actual work demands. In future research, the proposed system could support the intelligent agriculture machines more flexible in autonomous navigation.},
DOI = {10.3390/s20154082}
}



@Article{app10155075,
AUTHOR = {Fang, Peng and Zhang, Xiwang and Wei, Panpan and Wang, Yuanzheng and Zhang, Huiyi and Liu, Feng and Zhao, Jun},
TITLE = {The Classification Performance and Mechanism of Machine Learning Algorithms in Winter Wheat Mapping Using Sentinel-2 10 m Resolution Imagery},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {15},
ARTICLE-NUMBER = {5075},
URL = {https://www.mdpi.com/2076-3417/10/15/5075},
ISSN = {2076-3417},
ABSTRACT = {Machine learning algorithms are crucial for crop identification and mapping. However, many works only focus on the identification results of these algorithms, but pay less attention to their classification performance and mechanism. In this paper, based on Google Earth Engine (GEE), Sentinel-2 10 m resolution images during a specific phenological period of winter wheat were obtained. Then, support vector machine (SVM), random forest (RF), and classification and regression tree (CART) machine learning algorithms were employed to identify and map winter wheat in a large-scale area. The hyperparameters of the three machine learning algorithms were tuned by grid search and the 5-fold cross-validation method. The classification performance of the three machine learning algorithms were compared, the results of which demonstrate that SVM achieves best performance in identifying winter wheat, and its overall accuracy (OA), user&rsquo;s accuracy (UA), producer&rsquo;s accuracy (PA), and kappa coefficient (Kappa) are 0.94, 0.95, 0.95, and 0.92, respectively. Moreover, 50 various combinations of training and validation sets were used to analyze the generalization ability of the algorithms, and the results show that the average OA of SVM, RF, and CART are 0.93, 0.92, and 0.88, respectively, thus indicating that SVM and RF are more robust than CART. To further explore the sensitivity of SVM, RF, and CART to variations of the algorithm parameters&mdash;namely, (C and gamma), (tree and split), and (maxD and minSP)&mdash;we employed the grid search method to iterate these parameters, respectively, and to analyze the effect of these parameters on the accuracy scores and classification residuals. It was found that with the change of (C and gamma) in (0.01~1000), SVM&rsquo;s maximum variation of accuracy score is up to 0.63, and the maximum variation of residuals is 76,215 km2. We concluded that SVM is sensitive to the parameters (C and gamma) and presents a positive correlation. When the parameters (tree and split) change between (100~600) and (1~6), respectively, the RF&rsquo;s maximum variation of accuracy score is 0.08, and the maximum variation of residuals is 1157 km2, indicating that RF is low in sensitivity toward the parameters (tree and split). When the parameters (maxD and minSP) are between (10~60), the maximum accuracy change value is 0.06, and the maximum variation of residuals is 6943 km2. Therefore, compared to RF, CART is sensitive to the parameters (maxD and minSP) and has poor robustness. In general, under the conditions of the hyperparameters, SVM and RF exhibit optimal classification performance, while CART has relatively inferior performance. Meanwhile, SVM, RF, and CART have different sensitivities toward the algorithm parameters; that is, SVM and CART are more sensitive to the algorithm parameters, while RF has low sensitivity toward changes in the algorithm parameters. The different parameters cause great changes in the accuracy scores and residuals, so it is necessary to determine the algorithm hyperparameters. Generally, default parameters can be used to achieve crop classification, but we recommend the enumeration method, similar to grid search, as a practical way to improve the classification performance of the algorithm if the best classification effect is expected.},
DOI = {10.3390/app10155075}
}



@Article{rs12152379,
AUTHOR = {Pulido, Dagoberto and Salas, Joaquín and Rös, Matthias and Puettmann, Klaus and Karaman, Sertac},
TITLE = {Assessment of Tree Detection Methods in Multispectral Aerial Images},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {15},
ARTICLE-NUMBER = {2379},
URL = {https://www.mdpi.com/2072-4292/12/15/2379},
ISSN = {2072-4292},
ABSTRACT = {Detecting individual trees and quantifying their biomass is crucial for carbon accounting procedures at the stand, landscape, and national levels. A significant challenge for many organizations is the amount of effort necessary to document carbon storage levels, especially in terms of human labor. To advance towards the goal of efficiently assessing the carbon content of forest, we evaluate methods to detect trees from high-resolution images taken from unoccupied aerial systems (UAS). In the process, we introduce the Digital Elevated Vegetation Model (DEVM), a representation that combines multispectral images, digital surface models, and digital terrain models. We show that the DEVM facilitates the development of refined synthetic data to detect individual trees using deep learning-based approaches. We carried out experiments in two tree fields located in different countries. Simultaneously, we perform comparisons among an array of classical and deep learning-based methods highlighting the precision and reliability of the DEVM.},
DOI = {10.3390/rs12152379}
}



@Article{f11080808,
AUTHOR = {Prosekov, Alexander and Kuznetsov, Alexander and Rada, Artem and Ivanova, Svetlana},
TITLE = {Methods for Monitoring Large Terrestrial Animals in the Wild},
JOURNAL = {Forests},
VOLUME = {11},
YEAR = {2020},
NUMBER = {8},
ARTICLE-NUMBER = {808},
URL = {https://www.mdpi.com/1999-4907/11/8/808},
ISSN = {1999-4907},
ABSTRACT = {Reliable information about wildlife is absolutely important for making informed management decisions. The issues with the effectiveness of the control and monitoring of both large and small wild animals are relevant to assess and protect the world&rsquo;s biodiversity. Monitoring becomes part of the methods in wildlife ecology for observation, assessment, and forecasting of the human environment. World practice reveals the potential of the joint application of both proven traditional and modern technologies using specialized equipment to organize environmental control and management processes. Monitoring large terrestrial animals require an individual approach due to their low density and larger habitat. Elk/moose are such animals. This work aims to evaluate the methods for monitoring large wild animals, suitable for controlling the number of elk/moose in the framework of nature conservation activities. Using different models allows determining the population size without affecting the animals and without significant financial costs. Although, the accuracy of each model is determined by its postulates implementation and initial conditions that need statistical data. Depending on the geographical, climatic, and economic conditions in each territory, it is possible to use different tools and equipment (e.g., cameras, GPS sensors, and unmanned aerial vehicles), a flexible variation of which will allow reaching the golden mean between the desires and capabilities of researchers.},
DOI = {10.3390/f11080808}
}



@Article{rs12152397,
AUTHOR = {Schlosser, Aletta Dóra and Szabó, Gergely and Bertalan, László and Varga, Zsolt and Enyedi, Péter and Szabó, Szilárd},
TITLE = {Building Extraction Using Orthophotos and Dense Point Cloud Derived from Visual Band Aerial Imagery Based on Machine Learning and Segmentation},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {15},
ARTICLE-NUMBER = {2397},
URL = {https://www.mdpi.com/2072-4292/12/15/2397},
ISSN = {2072-4292},
ABSTRACT = {Urban sprawl related increase of built-in areas requires reliable monitoring methods and remote sensing can be an efficient technique. Aerial surveys, with high spatial resolution, provide detailed data for building monitoring, but archive images usually have only visible bands. We aimed to reveal the efficiency of visible orthophotographs and photogrammetric dense point clouds in building detection with segmentation-based machine learning (with five algorithms) using visible bands, texture information, and spectral and morphometric indices in different variable sets. Usually random forest (RF) had the best (99.8%) and partial least squares the worst overall accuracy (~60%). We found that &gt;95% accuracy can be gained even in class level. Recursive feature elimination (RFE) was an efficient variable selection tool, its result with six variables was like when we applied all the available 31 variables. Morphometric indices had 82% producer&rsquo;s and 85% user&rsquo;s Accuracy (PA and UA, respectively) and combining them with spectral and texture indices, it had the largest contribution in the improvement. However, morphometric indices are not always available but by adding texture and spectral indices to red-green-blue (RGB) bands the PA improved with 12% and the UA with 6%. Building extraction from visual aerial surveys can be accurate, and archive images can be involved in the time series of a monitoring.},
DOI = {10.3390/rs12152397}
}



@Article{su12156080,
AUTHOR = {Zwęgliński, Tomasz},
TITLE = {The Use of Drones in Disaster Aerial Needs Reconnaissance and Damage Assessment – Three-Dimensional Modeling and Orthophoto Map Study},
JOURNAL = {Sustainability},
VOLUME = {12},
YEAR = {2020},
NUMBER = {15},
ARTICLE-NUMBER = {6080},
URL = {https://www.mdpi.com/2071-1050/12/15/6080},
ISSN = {2071-1050},
ABSTRACT = {The aim of this research is to provide disaster managers with the results of testing three-dimensional modeling and orthophoto mapping, so as to add value to aerial assessments of flood-related needs and damages. The relevant testing of solutions concerning the real needs of disaster managers is an essential part of the pre-disaster phase. As such, providing evidence-based results of the solutions&rsquo; performance is critical with regard to purchasing them and their successful implementation for disaster management purposes. Since disaster response is mostly realized in complex and dynamic, rather than repetitive, environments, it requires pertinent testing methods. A quasi-experimental approach, applied in a form of a full-scale trial meets disaster manager&rsquo;s requirements as well as addressing limitations resulting from the disaster environment&rsquo;s characteristics. Three-dimensional modeling and orthophoto mapping have already proven their potential in many professional fields; however, they have not yet been broadly tested for disaster response purposes. Therefore, the objective here is to verify the technologies regarding their applicability in aerial reconnaissance in sudden-onset disasters. The hypothesis assumes that they will improve the efficiency (e.g., time) and effectiveness (e.g., accuracy of revealed data) of this process. The research verifies that the technologies have a potential to facilitate disaster managers with more precise damage assessment; however, their effectivity was less than expected in terms of needs reconnaissance. Secondly, the overall assessment process is heavily burdened by data processing time, however, the technologies allow a reduction of analytical work.},
DOI = {10.3390/su12156080}
}



@Article{rs12152426,
AUTHOR = {Pleșoianu, Alin-Ionuț and Stupariu, Mihai-Sorin and Șandric, Ionuț and Pătru-Stupariu, Ileana and Drăguț, Lucian},
TITLE = {Individual Tree-Crown Detection and Species Classification in Very High-Resolution Remote Sensing Imagery Using a Deep Learning Ensemble Model},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {15},
ARTICLE-NUMBER = {2426},
URL = {https://www.mdpi.com/2072-4292/12/15/2426},
ISSN = {2072-4292},
ABSTRACT = {Traditional methods for individual tree-crown (ITC) detection (image classification, segmentation, template matching, etc.) applied to very high-resolution remote sensing imagery have been shown to struggle in disparate landscape types or image resolutions due to scale problems and information complexity. Deep learning promised to overcome these shortcomings due to its superior performance and versatility, proven with reported detection rates of ~90%. However, such models still find their limits in transferability across study areas, because of different tree conditions (e.g., isolated trees vs. compact forests) and/or resolutions of the input data. This study introduces a highly replicable deep learning ensemble design for ITC detection and species classification based on the established single shot detector (SSD) model. The ensemble model design is based on varying the input data for the SSD models, coupled with a voting strategy for the output predictions. Very high-resolution unmanned aerial vehicles (UAV), aerial remote sensing imagery and elevation data are used in different combinations to test the performance of the ensemble models in three study sites with highly contrasting spatial patterns. The results show that ensemble models perform better than any single SSD model, regardless of the local tree conditions or image resolution. The detection performance and the accuracy rates improved by 3&ndash;18% with only as few as two participant single models, regardless of the study site. However, when more than two models were included, the performance of the ensemble models only improved slightly and even dropped.},
DOI = {10.3390/rs12152426}
}



@Article{rs12152427,
AUTHOR = {Cai, Yiming and Ding, Yalin and Zhang, Hongwen and Xiu, Jihong and Liu, Zhiming},
TITLE = {Geo-Location Algorithm for Building Targets in Oblique Remote Sensing Images Based on Deep Learning and Height Estimation},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {15},
ARTICLE-NUMBER = {2427},
URL = {https://www.mdpi.com/2072-4292/12/15/2427},
ISSN = {2072-4292},
ABSTRACT = {To improve the accuracy of the geographic positioning of a single aerial remote sensing image, the height information of a building in the image must be considered. Oblique remote sensing images are essentially two-dimensional images and produce a large positioning error if a traditional positioning algorithm is used to locate the building directly. To address this problem, this study uses a convolutional neural network to automatically detect the location of buildings in remote sensing images. Moreover, it optimizes an automatic building recognition algorithm for oblique aerial remote sensing images based on You Only Look Once V4 (YOLO V4). This study also proposes a positioning algorithm for the building target, which uses the imaging angle to estimate the height of a building, and combines the spatial coordinate transformation matrix to calculate high-accuracy geo-location of target buildings. Simulation analysis shows that the traditional positioning algorithm inevitably leads to large errors in the positioning of building targets. When the target height is 50 m and the imaging angle is 70&deg;, the positioning error is 114.89 m. Flight tests show that the algorithm established in this study can improve the positioning accuracy of building targets by approximately 20%&ndash;50% depending on the difference in target height.},
DOI = {10.3390/rs12152427}
}



@Article{en13153910,
AUTHOR = {Li, Hongchen and Yang, Zhong and Han, Jiaming and Lai, Shangxiang and Zhang, Qiuyan and Zhang, Chi and Fang, Qianhui and Hu, Guoxiong},
TITLE = {TL-Net: A Novel Network for Transmission Line Scenes Classification},
JOURNAL = {Energies},
VOLUME = {13},
YEAR = {2020},
NUMBER = {15},
ARTICLE-NUMBER = {3910},
URL = {https://www.mdpi.com/1996-1073/13/15/3910},
ISSN = {1996-1073},
ABSTRACT = {With the development of unmanned aerial vehicle (UAV) control technology, one of the recent trends in this research domain is to utilize UAVs to perform non-contact transmission line inspection. The RGB camera mounted on UAVs collects large numbers of images during the transmission line inspection, but most of them contain no critical components of transmission lines. Hence, it is a momentous task to adopt image classification algorithms to distinguish key images from all aerial images. In this work, we propose a novel classification method to remove redundant data and retain informative images. A novel transmission line scene dataset, namely TLS_dataset, is built to evaluate the classification performance of networks. Then, we propose a novel convolutional neural network (CNN), namely TL-Net, to classify transmission line scenes. In comparison to other typical deep learning networks, TL-Nets gain better classification accuracy and less memory consumption. The experimental results show that TL-Net101 gains 99.68% test accuracy on the TLS_dataset.},
DOI = {10.3390/en13153910}
}



@Article{en13153916,
AUTHOR = {Nielsen, Mikkel Schou and Nikolov, Ivan and Kruse, Emil Krog and Garnæs, Jørgen and Madsen, Claus Brøndgaard},
TITLE = {High-Resolution Structure-from-Motion for Quantitative Measurement of Leading-Edge Roughness},
JOURNAL = {Energies},
VOLUME = {13},
YEAR = {2020},
NUMBER = {15},
ARTICLE-NUMBER = {3916},
URL = {https://www.mdpi.com/1996-1073/13/15/3916},
ISSN = {1996-1073},
ABSTRACT = {Over time, erosion of the leading edge of wind turbine blades increases the leading-edge roughness (LER). This may reduce the aerodynamic performance of the blade and hence the annual energy production of the wind turbine. As early detection is key for cost-effective maintenance, inspection methods are needed to quantify the LER of the blade. The aim of this proof-of-principle study is to determine whether high-resolution Structure-from-Motion (SfM) has the sufficient resolution and accuracy for quantitative inspection of LER. SfM provides 3D reconstruction of an object geometry using overlapping images of the object acquired with an RGB camera. Using information of the camera positions and orientations, absolute scale of the reconstruction can be achieved. Combined with a UAV platform, SfM has the potential for remote blade inspections with a reduced downtime. The tip of a decommissioned blade with an artificially enhanced erosion was used for the measurements. For validation, replica molding was used to transfer areas-of-interest to the lab for reference measurements using confocal microscopy. The SfM reconstruction resulted in a spatial resolution of 1 mm as well as a sub-mm accuracy in both the RMS surface roughness and the size of topographic features. In conclusion, high-resolution SfM demonstrated a successful quantitative reconstruction of LER.},
DOI = {10.3390/en13153916}
}



@Article{smartcities3030039,
AUTHOR = {Su, Wen-Hao},
TITLE = {Advanced Machine Learning in Point Spectroscopy, RGB- and Hyperspectral-Imaging for Automatic Discriminations of Crops and Weeds: A Review},
JOURNAL = {Smart Cities},
VOLUME = {3},
YEAR = {2020},
NUMBER = {3},
PAGES = {767--792},
URL = {https://www.mdpi.com/2624-6511/3/3/39},
ISSN = {2624-6511},
ABSTRACT = {Crop productivity is readily reduced by competition from weeds. It is particularly important to control weeds early to prevent yield losses. Limited herbicide choices and increasing costs of weed management are threatening the profitability of crops. Smart agriculture can use intelligent technology to accurately measure the distribution of weeds in the field and perform weed control tasks in selected areas, which cannot only improve the effectiveness of pesticides, but also increase the economic benefits of agricultural products. The most important thing for an automatic system to remove weeds within crop rows is to utilize reliable sensing technology to achieve accurate differentiation of weeds and crops at specific locations in the field. In recent years, there have been many significant achievements involving the differentiation of crops and weeds. These studies are related to the development of rapid and non-destructive sensors, as well as the analysis methods for the data obtained. This paper presents a review of the use of three sensing methods including spectroscopy, color imaging, and hyperspectral imaging in the discrimination of crops and weeds. Several algorithms of machine learning have been employed for data analysis such as convolutional neural network (CNN), artificial neural network (ANN), and support vector machine (SVM). Successful applications include the weed detection in grain crops (such as maize, wheat, and soybean), vegetable crops (such as tomato, lettuce, and radish), and fiber crops (such as cotton) with unsupervised or supervised learning. This review gives a brief introduction into proposed sensing and machine learning methods, then provides an overview of instructive examples of these techniques for weed/crop discrimination. The discussion describes the recent progress made in the development of automated technology for accurate plant identification as well as the challenges and future prospects. It is believed that this review is of great significance to those who study automatic plant care in crops using intelligent technology.},
DOI = {10.3390/smartcities3030039}
}



@Article{app10165436,
AUTHOR = {Kim, Dong-Hyun and Go, Yong-Guk and Choi, Soo-Mi},
TITLE = {An Aerial Mixed-Reality Environment for First-Person-View Drone Flying},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {5436},
URL = {https://www.mdpi.com/2076-3417/10/16/5436},
ISSN = {2076-3417},
ABSTRACT = {A drone be able to fly without colliding to preserve the surroundings and its own safety. In addition, it must also incorporate numerous features of interest for drone users. In this paper, an aerial mixed-reality environment for first-person-view drone flying is proposed to provide an immersive experience and a safe environment for drone users by creating additional virtual obstacles when flying a drone in an open area. The proposed system is effective in perceiving the depth of obstacles, and enables bidirectional interaction between real and virtual worlds using a drone equipped with a stereo camera based on human binocular vision. In addition, it synchronizes the parameters of the real and virtual cameras to effectively and naturally create virtual objects in a real space. Based on user studies that included both general and expert users, we confirm that the proposed system successfully creates a mixed-reality environment using a flying drone by quickly recognizing real objects and stably combining them with virtual objects.},
DOI = {10.3390/app10165436}
}



@Article{app10165461,
AUTHOR = {Blaya-Ros, Pedro José and Blanco, Víctor and Domingo, Rafael and Soto-Valles, Fulgencio and Torres-Sánchez, Roque},
TITLE = {Feasibility of Low-Cost Thermal Imaging for Monitoring Water Stress in Young and Mature Sweet Cherry Trees},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {5461},
URL = {https://www.mdpi.com/2076-3417/10/16/5461},
ISSN = {2076-3417},
ABSTRACT = {Infrared thermography has been introduced as an affordable tool for plant water status monitoring, especially in regions where water availability is the main limiting factor in agricultural production. This paper outlines the potential applications of low-cost thermal imaging devices to evaluate the water status of young and mature sweet cherry trees (Prunus avium L.) submitted to water stress. Two treatments per plot were assayed: (i) a control treatment irrigated to ensure non-limiting soil water conditions; and (ii) a water-stress treatment. The seasonal evolution of the temperature of the canopy (Tc) and the difference between Tc and air temperature (&Delta;T) were compared and three thermal indices were calculated: crop water stress index (CWSI), degrees above control treatment (DAC) and degrees above non-water-stressed baseline (DANS). Midday stem water potential (&Psi;stem) was used as the reference indicator of water stress and linear relationships of Tc, &Delta;T, CWSI, DAC and DANS with &Psi;stem were discussed in order to assess their sensitivity to quantify water stress. CWSI and DANS exhibited strong relationships with &Psi;stem and two regression lines to young and mature trees were found. The promising results obtained highlight that using low-cost infrared thermal devices can be used to determine the plant water status in sweet cherry trees.},
DOI = {10.3390/app10165461}
}



@Article{plants9081008,
AUTHOR = {Billet, Kévin and Malinowska, Magdalena Anna and Munsch, Thibaut and Unlubayir, Marianne and Adler, Sophie and Delanoue, Guillaume and Lanoue, Arnaud},
TITLE = {Semi-Targeted Metabolomics to Validate Biomarkers of Grape Downy Mildew Infection Under Field Conditions},
JOURNAL = {Plants},
VOLUME = {9},
YEAR = {2020},
NUMBER = {8},
ARTICLE-NUMBER = {1008},
URL = {https://www.mdpi.com/2223-7747/9/8/1008},
PubMedID = {32784974},
ISSN = {2223-7747},
ABSTRACT = {Grape downy mildew is a devastating disease worldwide and new molecular phenotyping tools are required to detect metabolic changes associated to plant disease symptoms. In this purpose, we used UPLC-DAD-MS-based semi-targeted metabolomics to screen downy mildew symptomatic leaves that expressed oil spots (6 dpi, days post-infection) and necrotic lesions (15 dpi) under natural infections in the field. Leaf extract analyses enabled the identification of 47 metabolites belonging to the primary metabolism including 6 amino acids and 1 organic acid, as well as an important diversity of specialized metabolites including 9 flavonols, 11 flavan-3-ols, 3 phenolic acids, and stilbenoids with various degree of polymerization (DP) including 4 stilbenoids DP1, 8 stilbenoids DP2, and 4 stilbenoids DP3. Principal component analysis (PCA) was applied as unsupervised multivariate statistical analysis method to reveal metabolic variables that were affected by the infection status. Univariate and multivariate statistics revealed 33 and 27 metabolites as relevant infection biomarkers at 6 and 15 dpi, respectively. Correlation-based networks highlighted a general decrease of flavonoid-related metabolites, whereas stilbenoid DP1 and DP2 concentrations increased upon downy mildew infection. Stilbenoids DP3 were identified only in necrotic lesions representing late biomarkers of downy mildew infection.},
DOI = {10.3390/plants9081008}
}



@Article{rs12162576,
AUTHOR = {de Bem, Pablo Pozzobon and de Carvalho Júnior, Osmar Abílio and de Carvalho, Osmar Luiz Ferreira and Gomes, Roberto Arnaldo Trancoso and Fontes Guimarães, Renato},
TITLE = {Performance Analysis of Deep Convolutional Autoencoders with Different Patch Sizes for Change Detection from Burnt Areas},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {2576},
URL = {https://www.mdpi.com/2072-4292/12/16/2576},
ISSN = {2072-4292},
ABSTRACT = {Fire is one of the primary sources of damages to natural environments globally. Estimates show that approximately 4 million km2 of land burns yearly. Studies have shown that such estimates often underestimate the real extent of burnt land, which highlights the need to find better, state-of-the-art methods to detect and classify these areas. This study aimed to analyze the use of deep convolutional Autoencoders in the classification of burnt areas, considering different sample patch sizes. A simple Autoencoder and the U-Net and ResUnet architectures were evaluated. We collected Landsat 8 OLI+ data from three scenes in four consecutive dates to detect the changes specifically in the form of burnt land. The data were sampled according to four different sampling strategies to evaluate possible performance changes related to sampling window sizes. The training stage used two scenes, while the validation stage used the remaining scene. The ground truth change mask was created using the Normalized Burn Ratio (NBR) spectral index through a thresholding approach. The classifications were evaluated according to the F1 index, Kappa index, and mean Intersection over Union (mIoU) value. Results have shown that the U-Net and ResUnet architectures offered the best classifications with average F1, Kappa, and mIoU values of approximately 0.96, representing excellent classification results. We have also verified that a sampling window size of 256 by 256 pixels offered the best results.},
DOI = {10.3390/rs12162576}
}



@Article{agriculture10080348,
AUTHOR = {Wei, Marcelo Chan Fu and Molin, José Paulo},
TITLE = {Soybean Yield Estimation and Its Components: A Linear Regression Approach},
JOURNAL = {Agriculture},
VOLUME = {10},
YEAR = {2020},
NUMBER = {8},
ARTICLE-NUMBER = {348},
URL = {https://www.mdpi.com/2077-0472/10/8/348},
ISSN = {2077-0472},
ABSTRACT = {Soybean yield estimation is either based on yield monitors or agro-meteorological and satellite imagery data, but they present several limiting factors regarding on-farm decision level. Aware that machine learning approaches have been largely applied to estimate soybean yield and the availability of data regarding soybean yield and its components (number of grains (NG) and thousand grains weight (TGW)), there is an opportunity to study their relationships. The objective was to explore the relationships between soybean yield and its components, generate equations to estimate yield and evaluate its prediction accuracy. The training dataset was composed of soybean yield and its components&rsquo; data from 2010 to 2019. Linear regression models based on NG, TGW and yield were fitted on the training dataset and applied to a validation dataset composed of 58 on-field collected samples. It was found that globally TGW and NG presented weak (r = 0.50) and strong (r = 0.92) linear relationships with yield, respectively. In addition to that, applying the fitted models to the validation dataset, model based on NG presented the highest accuracy, coefficient of determination (R2) of 0.70, mean absolute error (MAE) of 639.99 kg ha&minus;1 and root mean squared error (RMSE) of 726.67 kg ha&minus;1.},
DOI = {10.3390/agriculture10080348}
}



@Article{rs12162578,
AUTHOR = {Li, Daoliang and Zhang, Pan and Chen, Tao and Qin, Wei},
TITLE = {Recent Development and Challenges in Spectroscopy and Machine Vision Technologies for Crop Nitrogen Diagnosis: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {2578},
URL = {https://www.mdpi.com/2072-4292/12/16/2578},
ISSN = {2072-4292},
ABSTRACT = {Recent development of non-destructive optical techniques, such as spectroscopy and machine vision technologies, have laid a good foundation for real-time monitoring and precise management of crop N status. However, their advantages and disadvantages have not been systematically summarized and evaluated. Here, we reviewed the state-of-the-art of non-destructive optical methods for monitoring the N status of crops, and summarized their advantages and disadvantages. We mainly focused on the contribution of spectral and machine vision technology to the accurate diagnosis of crop N status from three aspects: system selection, data processing, and estimation methods. Finally, we discussed the opportunities and challenges of the application of these technologies, followed by recommendations for future work to address the challenges.},
DOI = {10.3390/rs12162578}
}



@Article{ijgi9080485,
AUTHOR = {Ding, Kaimeng and Liu, Yueming and Xu, Qin and Lu, Fuqiang},
TITLE = {A Subject-Sensitive Perceptual Hash Based on MUM-Net for the Integrity Authentication of High Resolution Remote Sensing Images},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {9},
YEAR = {2020},
NUMBER = {8},
ARTICLE-NUMBER = {485},
URL = {https://www.mdpi.com/2220-9964/9/8/485},
ISSN = {2220-9964},
ABSTRACT = {Data security technology is of great significance to the application of high resolution remote sensing image (HRRS) images. As an important data security technology, perceptual hash overcomes the shortcomings of cryptographic hashing that is not robust and can achieve integrity authentication of HRRS images based on perceptual content. However, the existing perceptual hash does not take into account whether the user focuses on certain types of information of the HRRS image. In this paper, we introduce the concept of subject-sensitive perceptual hash, which can be seen as a special case of conventional perceptual hash, for the integrity authentication of HRRS image. To achieve subject-sensitive perceptual hash, we propose a new deep convolutional neural network architecture, named MUM-Net, for extracting robust features of HRRS images. MUM-Net is the core of perceptual hash algorithm, and it uses focal loss as the loss function to overcome the imbalance between the positive and negative samples in the training samples. The robust features extracted by MUM-Net are further compressed and encoded to obtain the perceptual hash sequence of HRRS image. Experiments show that our algorithm has higher tamper sensitivity to subject-related malicious tampering, and the robustness is improved by about 10% compared to the existing U-net-based algorithm; compared to other deep learning-based algorithms, this algorithm achieves a better balance between robustness and tampering sensitivity, and has better overall performance.},
DOI = {10.3390/ijgi9080485}
}



@Article{rs12162599,
AUTHOR = {Gonçalves, Gil and Andriolo, Umberto and Gonçalves, Luísa and Sobral, Paula and Bessa, Filipa},
TITLE = {Quantifying Marine Macro Litter Abundance on a Sandy Beach Using Unmanned Aerial Systems and Object-Oriented Machine Learning Methods},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {2599},
URL = {https://www.mdpi.com/2072-4292/12/16/2599},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial systems (UASs) have recently been proven to be valuable remote sensing tools for detecting marine macro litter (MML), with the potential of supporting pollution monitoring programs on coasts. Very low altitude images, acquired with a low-cost RGB camera onboard a UAS on a sandy beach, were used to characterize the abundance of stranded macro litter. We developed an object-oriented classification strategy for automatically identifying the marine macro litter items on a UAS-based orthomosaic. A comparison is presented among three automated object-oriented machine learning (OOML) techniques, namely random forest (RF), support vector machine (SVM), and k-nearest neighbor (KNN). Overall, the detection was satisfactory for the three techniques, with mean F-scores of 65% for KNN, 68% for SVM, and 72% for RF. A comparison with manual detection showed that the RF technique was the most accurate OOML macro litter detector, as it returned the best overall detection quality (F-score) with the lowest number of false positives. Because the number of tuning parameters varied among the three automated machine learning techniques and considering that the three generated abundance maps correlated similarly with the abundance map produced manually, the simplest KNN classifier was preferred to the more complex RF. This work contributes to advances in remote sensing marine litter surveys on coasts, optimizing the automated detection on UAS-derived orthomosaics. MML abundance maps, produced by UAS surveys, assist coastal managers and authorities through environmental pollution monitoring programs. In addition, they contribute to search and evaluation of the mitigation measures and improve clean-up operations on coastal environments.},
DOI = {10.3390/rs12162599}
}



@Article{s20164546,
AUTHOR = {Zhao, Weiwei and Chu, Hairong and Miao, Xikui and Guo, Lihong and Shen, Honghai and Zhu, Chenhao and Zhang, Feng and Liang, Dongxin},
TITLE = {Research on the Multiagent Joint Proximal Policy Optimization Algorithm Controlling Cooperative Fixed-Wing UAV Obstacle Avoidance},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {4546},
URL = {https://www.mdpi.com/1424-8220/20/16/4546},
ISSN = {1424-8220},
ABSTRACT = {Multiple unmanned aerial vehicle (UAV) collaboration has great potential. To increase the intelligence and environmental adaptability of multi-UAV control, we study the application of deep reinforcement learning algorithms in the field of multi-UAV cooperative control. Aiming at the problem of a non-stationary environment caused by the change of learning agent strategy in reinforcement learning in a multi-agent environment, the paper presents an improved multiagent reinforcement learning algorithm&mdash;the multiagent joint proximal policy optimization (MAJPPO) algorithm with the centralized learning and decentralized execution. This algorithm uses the moving window averaging method to make each agent obtain a centralized state value function, so that the agents can achieve better collaboration. The improved algorithm enhances the collaboration and increases the sum of reward values obtained by the multiagent system. To evaluate the performance of the algorithm, we use the MAJPPO algorithm to complete the task of multi-UAV formation and the crossing of multiple-obstacle environments. To simplify the control complexity of the UAV, we use the six-degree of freedom and 12-state equations of the dynamics model of the UAV with an attitude control loop. The experimental results show that the MAJPPO algorithm has better performance and better environmental adaptability.},
DOI = {10.3390/s20164546}
}



@Article{rs12162640,
AUTHOR = {Vlachopoulos, Odysseas and Leblon, Brigitte and Wang, Jinfei and Haddadi, Ataollah and LaRocque, Armand and Patterson, Greg},
TITLE = {Delineation of Crop Field Areas and Boundaries from UAS Imagery Using PBIA and GEOBIA with Random Forest Classification},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {2640},
URL = {https://www.mdpi.com/2072-4292/12/16/2640},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aircraft systems (UAS) have been proven cost- and time-effective remote-sensing platforms for precision agriculture applications. This study presents a method for automatic delineation of field areas and boundaries that uses UAS multispectral orthomosaics acquired over 7 vegetated fields having a variety of crops in Prince Edward Island (PEI). This information is needed by crop insurance agencies and growers for an accurate determination of crop insurance premiums. The field areas and boundaries were delineated by applying both a pixel-based and an object-based supervised random forest (RF) classifier applied to reflectance and vegetation index images, followed by a vectorization pipeline. Both methodologies performed exceptionally well, resulting in a mean area goodness of fit (AGoF) for the field areas greater than 98% and a mean boundary mean positional error (BMPE) lower than 0.8 m for the seven surveyed fields.},
DOI = {10.3390/rs12162640}
}



@Article{rs12162646,
AUTHOR = {Zhang, Shiyu and Zhuo, Li and Zhang, Hui and Li, Jiafeng},
TITLE = {Object Tracking in Unmanned Aerial Vehicle Videos via Multifeature Discrimination and Instance-Aware Attention Network},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {2646},
URL = {https://www.mdpi.com/2072-4292/12/16/2646},
ISSN = {2072-4292},
ABSTRACT = {Visual object tracking in unmanned aerial vehicle (UAV) videos plays an important role in a variety of fields, such as traffic data collection, traffic monitoring, as well as film and television shooting. However, it is still challenging to track the target robustly in UAV vision task due to several factors such as appearance variation, background clutter, and severe occlusion. In this paper, we propose a novel two-stage UAV tracking framework, which includes a target detection stage based on multifeature discrimination and a bounding-box estimation stage based on the instance-aware attention network. In the target detection stage, we explore a feature representation scheme for a small target that integrates handcrafted features, low-level deep features, and high-level deep features. Then, the correlation filter is used to roughly predict target location. In the bounding-box estimation stage, an instance-aware intersection over union (IoU)-Net is integrated together with an instance-aware attention network to estimate the target size based on the bounding-box proposals generated in the target detection stage. Extensive experimental results on the UAV123 and UAVDT datasets show that our tracker, running at over 25 frames per second (FPS), has superior performance as compared with state-of-the-art UAV visual tracking approaches.},
DOI = {10.3390/rs12162646}
}



@Article{drones4030046,
AUTHOR = {Adamopoulos, Efstathios and Rinaudo, Fulvio},
TITLE = {UAS-Based Archaeological Remote Sensing: Review, Meta-Analysis and State-of-the-Art},
JOURNAL = {Drones},
VOLUME = {4},
YEAR = {2020},
NUMBER = {3},
ARTICLE-NUMBER = {46},
URL = {https://www.mdpi.com/2504-446X/4/3/46},
ISSN = {2504-446X},
ABSTRACT = {Over the last decade, we have witnessed momentous technological developments in unmanned aircraft systems (UAS) and in lightweight sensors operating at various wavelengths, at and beyond the visible spectrum, which can be integrated with unmanned aerial platforms. These innovations have made feasible close-range and high-resolution remote sensing for numerous archaeological applications, including documentation, prospection, and monitoring bridging the gap between satellite, high-altitude airborne, and terrestrial sensing of historical sites and landscapes. In this article, we track the progress made so far, by systematically reviewing the literature relevant to the combined use of UAS platforms with visible, infrared, multi-spectral, hyper-spectral, laser, and radar sensors to reveal archaeological features otherwise invisible to archaeologists with applied non-destructive techniques. We review, specific applications and their global distribution, as well as commonly used platforms, sensors, and data-processing workflows. Furthermore, we identify the contemporary state-of-the-art and discuss the challenges that have already been overcome, and those that have not, to propose suggestions for future research.},
DOI = {10.3390/drones4030046}
}



@Article{s20174709,
AUTHOR = {Wang, Bin and Gu, Yinjuan},
TITLE = {An Improved FBPN-Based Detection Network for Vehicles in Aerial Images},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {4709},
URL = {https://www.mdpi.com/1424-8220/20/17/4709},
ISSN = {1424-8220},
ABSTRACT = {With the development of artificial intelligence and big data analytics, an increasing number of researchers have tried to use deep-learning technology to train neural networks and achieved great success in the field of vehicle detection. However, as a special domain of object detection, vehicle detection in aerial images still has made limited progress because of low resolution, complex backgrounds and rotating objects. In this paper, an improved feature-balanced pyramid network (FBPN) has been proposed to enhance the network&rsquo;s ability to detect small objects. By combining FBPN with modified faster region convolutional neural network (faster-RCNN), a vehicle detection framework for aerial images is proposed. The focal loss function is adopted in the proposed framework to reduce the imbalance between easy and hard samples. The experimental results based on the VEDIA, USCAS-AOD, and DOTA datasets show that the proposed framework outperforms other state-of-the-art vehicle detection algorithms for aerial images.},
DOI = {10.3390/s20174709}
}



@Article{rs12172729,
AUTHOR = {Yang, Jianxiu and Xie, Xuemei and Shi, Guangming and Yang, Wenzhe},
TITLE = {A Feature-Enhanced Anchor-Free Network for UAV Vehicle Detection},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {2729},
URL = {https://www.mdpi.com/2072-4292/12/17/2729},
ISSN = {2072-4292},
ABSTRACT = {Vehicle detection based on unmanned aerial vehicle (UAV) images is a challenging task. One reason is that the objects are small size, low-resolution, and large scale variations, resulting in weak feature representation. Another reason is the imbalance between positive and negative examples. In this paper, we propose a novel architecture for UAV vehicle detection to solve above problems. In detail, we use anchor-free mechanism to eliminate predefined anchors, which can reduce complicated computation and relieve the imbalance between positive and negative samples. Meanwhile, to enhance the features for vehicles, we design a multi-scale semantic enhancement block (MSEB) and an effective 49-layer backbone which is based on the DetNet59. The proposed network offers appropriate receptive fields that match the small-sized vehicles, and involves precise localization information provided by the contexts with high resolution. The MSEB strengthens discriminative feature representation at various scales, without reducing the spatial resolution of prediction layers. Experiments show that the proposed method achieves the state-of-the-art performance. Particularly, the main part of vehicles, much smaller ones, the accuracy is about 2% higher than other existing methods.},
DOI = {10.3390/rs12172729}
}



@Article{rs12172732,
AUTHOR = {Abdulridha, Jaafar and Ampatzidis, Yiannis and Qureshi, Jawwad and Roberts, Pamela},
TITLE = {Laboratory and UAV-Based Identification and Classification of Tomato Yellow Leaf Curl, Bacterial Spot, and Target Spot Diseases in Tomato Utilizing Hyperspectral Imaging and Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {2732},
URL = {https://www.mdpi.com/2072-4292/12/17/2732},
ISSN = {2072-4292},
ABSTRACT = {Tomato crops are susceptible to multiple diseases, several of which may be present during the same season. Therefore, rapid disease identification could enhance crop management consequently increasing the yield. In this study, nondestructive methods were developed to detect diseases that affect tomato crops, such as bacterial spot (BS), target spot (TS), and tomato yellow leaf curl (TYLC) for two varieties of tomato (susceptible and tolerant to TYLC only) by using hyperspectral sensing in two conditions: a) laboratory (benchtop scanning), and b) in field using an unmanned aerial vehicle (UAV-based). The stepwise discriminant analysis (STDA) and the radial basis function were applied to classify the infected plants and distinguish them from noninfected or healthy (H) plants. Multiple vegetation indices (VIs) and the M statistic method were utilized to distinguish and classify the diseased plants. In general, the classification results between healthy and diseased plants were highly accurate for all diseases; for instance, when comparing H vs. BS, TS, and TYLC in the asymptomatic stage and laboratory conditions, the classification rates were 94%, 95%, and 100%, respectively. Similarly, in the symptomatic stage, the classification rates between healthy and infected plants were 98% for BS, and 99&ndash;100% for TS and TYLC diseases. The classification results in the field conditions also showed high values of 98%, 96%, and 100%, for BS, TS, and TYLC, respectively. The VIs that could best identify these diseases were the renormalized difference vegetation index (RDVI), and the modified triangular vegetation index 1 (MTVI 1) in both laboratory and field. The results were promising and suggest the possibility to identify these diseases using remote sensing.},
DOI = {10.3390/rs12172732}
}



@Article{rs12172733,
AUTHOR = {Devadoss, Jashvina and Falco, Nicola and Dafflon, Baptiste and Wu, Yuxin and Franklin, Maya and Hermes, Anna and Hinckley, Eve-Lyn S. and Wainwright, Haruko},
TITLE = {Remote Sensing-Informed Zonation for Understanding Snow, Plant and Soil Moisture Dynamics within a Mountain Ecosystem},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {2733},
URL = {https://www.mdpi.com/2072-4292/12/17/2733},
ISSN = {2072-4292},
ABSTRACT = {In the headwater catchments of the Rocky Mountains, plant productivity and its dynamics are largely dependent upon water availability, which is influenced by changing snowmelt dynamics associated with climate change. Understanding and quantifying the interactions between snow, plants and soil moisture is challenging, since these interactions are highly heterogeneous in mountainous terrain, particularly as they are influenced by microtopography within a hillslope. Recent advances in satellite remote sensing have created an opportunity for monitoring snow and plant dynamics at high spatiotemporal resolutions that can capture microtopographic effects. In this study, we investigate the relationships among topography, snowmelt, soil moisture and plant dynamics in the East River watershed, Crested Butte, Colorado, based on a time series of 3-meter resolution PlanetScope normalized difference vegetation index (NDVI) images. To make use of a large volume of high-resolution time-lapse images (17 images total), we use unsupervised machine learning methods to reduce the dimensionality of the time lapse images by identifying spatial zones that have characteristic NDVI time series. We hypothesize that each zone represents a set of similar snowmelt and plant dynamics that differ from other identified zones and that these zones are associated with key topographic features, plant species and soil moisture. We compare different distance measures (Ward and complete linkage) to understand the effects of their influence on the zonation map. Results show that the identified zones are associated with particular microtopographic features; highly productive zones are associated with low slopes and high topographic wetness index, in contrast with zones of low productivity, which are associated with high slopes and low topographic wetness index. The zones also correspond to particular plant species distributions; higher forb coverage is associated with zones characterized by higher peak productivity combined with rapid senescence in low moisture conditions, while higher sagebrush coverage is associated with low productivity and similar senescence patterns between high and low moisture conditions. In addition, soil moisture probe and sensor data confirm that each zone has a unique soil moisture distribution. This cluster-based analysis can tractably analyze high-resolution time-lapse images to examine plant-soil-snow interactions, guide sampling and sensor placements and identify areas likely vulnerable to ecological change in the future.},
DOI = {10.3390/rs12172733}
}



@Article{app10176053,
AUTHOR = {Yu, Hang and Gong, Jiulu and Chen, Derong},
TITLE = {Object Detection Using Multi-Scale Balanced Sampling},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {6053},
URL = {https://www.mdpi.com/2076-3417/10/17/6053},
ISSN = {2076-3417},
ABSTRACT = {Detecting small objects and objects with large scale variants are always challenging for deep learning based object detection approaches. Many efforts have been made to solve these problems such as adopting more effective network structures, image features, loss functions, etc. However, for both small objects detection and detecting objects with various scale in single image, the first thing should be solve is the matching mechanism between anchor boxes and ground-truths. In this paper, an approach based on multi-scale balanced sampling(MB-RPN) is proposed for the difficult matching of small objects and detecting multi-scale objects. According to the scale of the anchor boxes, different positive and negative sample IOU discriminate thresholds are adopted to improve the probability of matching the small object area with the anchor boxes so that more small object samples are included in the training process. Moreover, the balanced sampling method is proposed for the collected samples, the samples are further divided and uniform sampling to ensure the diversity of samples in training process. Several datasets are adopted to evaluate the MB-RPN, the experimental results show that compare with the similar approach, MB-RPN improves detection performances effectively.},
DOI = {10.3390/app10176053}
}



@Article{rs12172833,
AUTHOR = {Arabameri, Alireza and Asadi Nalivan, Omid and Chandra Pal, Subodh and Chakrabortty, Rabin and Saha, Asish and Lee, Saro and Pradhan, Biswajeet and Tien Bui, Dieu},
TITLE = {Novel Machine Learning Approaches for Modelling the Gully Erosion Susceptibility},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {2833},
URL = {https://www.mdpi.com/2072-4292/12/17/2833},
ISSN = {2072-4292},
ABSTRACT = {The extreme form of land degradation caused by the formation of gullies is a major challenge for the sustainability of land resources. This problem is more vulnerable in the arid and semi-arid environment and associated damage to agriculture and allied economic activities. Appropriate modeling of such erosion is therefore needed with optimum accuracy for estimating vulnerable regions and taking appropriate initiatives. The Golestan Dam has faced an acute problem of gully erosion over the last decade and has adversely affected society. Here, the artificial neural network (ANN), general linear model (GLM), maximum entropy (MaxEnt), and support vector machine (SVM) machine learning algorithm with 90/10, 80/20, 70/30, 60/40, and 50/50 random partitioning of training and validation samples was selected purposively for estimating the gully erosion susceptibility. The main objective of this work was to predict the susceptible zone with the maximum possible accuracy. For this purpose, random partitioning approaches were implemented. For this purpose, 20 gully erosion conditioning factors were considered for predicting the susceptible areas by considering the multi-collinearity test. The variance inflation factor (VIF) and tolerance (TOL) limit were considered for multi-collinearity assessment for reducing the error of the models and increase the efficiency of the outcome. The ANN with 50/50 random partitioning of the sample is the most optimal model in this analysis. The area under curve (AUC) values of receiver operating characteristics (ROC) in ANN (50/50) for the training and validation data are 0.918 and 0.868, respectively. The importance of the causative factors was estimated with the help of the Jackknife test, which reveals that the most important factor is the topography position index (TPI). Apart from this, the prioritization of all predicted models was estimated taking into account the training and validation data set, which should help future researchers to select models from this perspective. This type of outcome should help planners and local stakeholders to implement appropriate land and water conservation measures.},
DOI = {10.3390/rs12172833}
}



@Article{ijgi9090527,
AUTHOR = {Liu, Jiantao and Feng, Quanlong and Wang, Ying and Batsaikhan, Bayartungalag and Gong, Jianhua and Li, Yi and Liu, Chunting and Ma, Yin},
TITLE = {Urban Green Plastic Cover Mapping Based on VHR Remote Sensing Images and a Deep Semi-Supervised Learning Framework},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {9},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {527},
URL = {https://www.mdpi.com/2220-9964/9/9/527},
ISSN = {2220-9964},
ABSTRACT = {With the rapid process of both urban sprawl and urban renewal, large numbers of old buildings have been demolished in China, leading to wide spread construction sites, which could cause severe dust contamination. To alleviate the accompanied dust pollution, green plastic mulch has been widely used by local governments of China. Therefore, timely and accurate mapping of urban green plastic covered regions is of great significance to both urban environmental management and the understanding of urban growth status. However, the complex spatial patterns of the urban landscape make it challenging to accurately identify these areas of green plastic cover. To tackle this issue, we propose a deep semi-supervised learning framework for green plastic cover mapping using very high resolution (VHR) remote sensing imagery. Specifically, a multi-scale deformable convolution neural network (CNN) was exploited to learn representative and discriminative features under complex urban landscapes. Afterwards, a semi-supervised learning strategy was proposed to integrate the limited labeled data and massive unlabeled data for model co-training. Experimental results indicate that the proposed method could accurately identify green plastic-covered regions in Jinan with an overall accuracy (OA) of 91.63%. An ablation study indicated that, compared with supervised learning, the semi-supervised learning strategy in this study could increase the OA by 6.38%. Moreover, the multi-scale deformable CNN outperforms several classic CNN models in the computer vision field. The proposed method is the first attempt to map urban green plastic-covered regions based on deep learning, which could serve as a baseline and useful reference for future research.},
DOI = {10.3390/ijgi9090527}
}



@Article{s20174976,
AUTHOR = {Meng , Kaitao and Li , Deshi and He , Xiaofan and Liu , Mingliu and Song , Weitao},
TITLE = {Real-Time Compact Environment Representation for UAV Navigation},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {4976},
URL = {https://www.mdpi.com/1424-8220/20/17/4976},
ISSN = {1424-8220},
ABSTRACT = {Recently, unmanned aerial vehicles (UAVs) have attracted much attention due to their on-demand deployment, high mobility, and low cost. For UAVs navigating in an unknown environment, efficient environment representation is needed due to the storage limitation of the UAVs. Nonetheless, building an accurate and compact environment representation model is highly non-trivial because of the unknown shape of the obstacles and the time-consuming operations such as finding and eliminating the environmental details. To overcome these challenges, a novel vertical strip extraction algorithm is proposed to analyze the probability density function characteristics of the normalized disparity value and segment the obstacles through an adaptive size sliding window. In addition, a plane adjustment algorithm is proposed to represent the obstacle surfaces as polygonal prism profiles while minimizing the redundant obstacle information. By combining these two proposed algorithms, the depth sensor data can be converted into the multi-layer polygonal prism models in real time. Besides, a drone platform equipped with a depth sensor is developed to build the compact environment representation models in the real world. Experimental results demonstrate that the proposed scheme achieves better performance in terms of precision and storage as compared to the baseline.},
DOI = {10.3390/s20174976}
}



@Article{rs12182866,
AUTHOR = {Ren, Yongfeng and Yu, Yongtao and Guan, Haiyan},
TITLE = {DA-CapsUNet: A Dual-Attention Capsule U-Net for Road Extraction from Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {2866},
URL = {https://www.mdpi.com/2072-4292/12/18/2866},
ISSN = {2072-4292},
ABSTRACT = {The up-to-date and information-accurate road database plays a significant role in many applications. Recently, with the improvement in image resolutions and quality, remote sensing images have provided an important data source for road extraction tasks. However, due to the topology variations, spectral diversities, and complex scenarios, it is still challenging to realize fully automated and highly accurate road extractions from remote sensing images. This paper proposes a novel dual-attention capsule U-Net (DA-CapsUNet) for road region extraction by combining the advantageous properties of capsule representations and the powerful features of attention mechanisms. By constructing a capsule U-Net architecture, the DA-CapsUNet can extract and fuse multiscale capsule features to recover a high-resolution and semantically strong feature representation. By designing the multiscale context-augmentation and two types of feature attention modules, the DA-CapsUNet can exploit multiscale contextual properties at a high-resolution perspective and generate an informative and class-specific feature encoding. Quantitative evaluations on a large dataset showed that the DA-CapsUNet provides a competitive road extraction performance with a precision of 0.9523, a recall of 0.9486, and an F-score of 0.9504, respectively. Comparative studies with eight recently developed deep learning methods also confirmed the applicability and superiority or compatibility of the DA-CapsUNet in road extraction tasks.},
DOI = {10.3390/rs12182866}
}




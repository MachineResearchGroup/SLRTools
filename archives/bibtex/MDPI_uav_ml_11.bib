
@Article{s18124272,
AUTHOR = {Sang, Jun and Wu, Zhongyuan and Guo, Pei and Hu, Haibo and Xiang, Hong and Zhang, Qian and Cai, Bin},
TITLE = {An Improved YOLOv2 for Vehicle Detection},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {4272},
URL = {https://www.mdpi.com/1424-8220/18/12/4272},
ISSN = {1424-8220},
ABSTRACT = {Vehicle detection is one of the important applications of object detection in intelligent transportation systems. It aims to extract specific vehicle-type information from pictures or videos containing vehicles. To solve the problems of existing vehicle detection, such as the lack of vehicle-type recognition, low detection accuracy, and slow speed, a new vehicle detection model YOLOv2_Vehicle based on YOLOv2 is proposed in this paper. The k-means++ clustering algorithm was used to cluster the vehicle bounding boxes on the training dataset, and six anchor boxes with different sizes were selected. Considering that the different scales of the vehicles may influence the vehicle detection model, normalization was applied to improve the loss calculation method for length and width of bounding boxes. To improve the feature extraction ability of the network, the multi-layer feature fusion strategy was adopted, and the repeated convolution layers in high layers were removed. The experimental results on the Beijing Institute of Technology (BIT)-Vehicle validation dataset demonstrated that the mean Average Precision (mAP) could reach 94.78%. The proposed model also showed excellent generalization ability on the CompCars test dataset, where the &ldquo;vehicle face&rdquo; is quite different from the training dataset. With the comparison experiments, it was proven that the proposed method is effective for vehicle detection. In addition, with network visualization, the proposed model showed excellent feature extraction ability.},
DOI = {10.3390/s18124272}
}



@Article{s18124275,
AUTHOR = {Zhu, Dongjie and Du, Haiwen and Sun, Yundong and Cao, Ning},
TITLE = {Research on Path Planning Model Based on Short-Term Traffic Flow Prediction in Intelligent Transportation System},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {4275},
URL = {https://www.mdpi.com/1424-8220/18/12/4275},
ISSN = {1424-8220},
ABSTRACT = {Vehicle driving path planning is an important information service in intelligent transportation systems. As an important basis for path planning optimization, the travel time prediction method has attracted much attention. However, traffic flow has features of high nonlinearity, time-varying, and uncertainty, which makes it hard for prediction method with single feature to meet the accuracy demand of intelligent transportation system in big data environment. In this paper, the historical vehicle Global Positioning System (GPS) information data is used to establish the traffic prediction model. Firstly, the Clustering in QUEst (CLIQUE)-based clustering algorithm V-CLIQUE is proposed to analyze the historical vehicle GPS data. Secondly, an artificial neural network (ANN)-based prediction model is proposed. Finally, the ANN-based weighted shortest path algorithm, A-Dijkstra, is proposed. We used mean absolute percentage error (MAPE) to evaluate the predictive model and compare it with the predicted results of Average and support regression vector (SRV). Experiments show that the improved ANN path planning model we proposed can accurately predict real-time traffic status at the given location. It has less relative error and saves time for users&rsquo; travel while saving social resources.},
DOI = {10.3390/s18124275}
}



@Article{f9120759,
AUTHOR = {Wan Mohd Jaafar, Wan Shafrina and Woodhouse, Iain Hector and Silva, Carlos Alberto and Omar, Hamdan and Abdul Maulud, Khairul Nizam and Hudak, Andrew Thomas and Klauberg, Carine and Cardil, Adrián and Mohan, Midhun},
TITLE = {Improving Individual Tree Crown Delineation and Attributes Estimation of Tropical Forests Using Airborne LiDAR Data},
JOURNAL = {Forests},
VOLUME = {9},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {759},
URL = {https://www.mdpi.com/1999-4907/9/12/759},
ISSN = {1999-4907},
ABSTRACT = {Individual tree crown (ITC) segmentation is an approach to isolate individual tree from the background vegetation and delineate precisely the crown boundaries for forest management and inventory purposes. ITC detection and delineation have been commonly generated from canopy height model (CHM) derived from light detection and ranging (LiDAR) data. Existing ITC segmentation methods, however, are limited in their efficiency for characterizing closed canopies, especially in tropical forests, due to the overlapping structure and irregular shape of tree crowns. Furthermore, the potential of 3-dimensional (3D) LiDAR data is not fully realized by existing CHM-based methods. Thus, the aim of this study was to develop an efficient framework for ITC segmentation in tropical forests using LiDAR-derived CHM and 3D point cloud data in order to accurately estimate tree attributes such as the tree height, mean crown width and aboveground biomass (AGB). The proposed framework entails five major steps: (1) automatically identifying dominant tree crowns by implementing semi-variogram statistics and morphological analysis; (2) generating initial tree segments using a watershed algorithm based on mathematical morphology; (3) identifying &ldquo;problematic&rdquo; segments based on predetermined set of rules; (4) tuning the problematic segments using a modified distance-based algorithm (DBA); and (5) segmenting and counting the number of individual trees based on the 3D LiDAR point clouds within each of the identified segment. This approach was developed in a way such that the 3D LiDAR points were only examined on problematic segments identified for further evaluations. 209 reference trees with diameter at breast height (DBH) &ge; 10 cm were selected in the field in two study areas in order to validate ITC detection and delineation results of the proposed framework. We computed tree crown metrics (e.g., maximum crown height and mean crown width) to estimate aboveground biomass (AGB) at tree level using previously published allometric equations. Accuracy assessment was performed to calculate percentage of correctly detected trees, omission and commission errors. Our method correctly identified individual tree crowns with detection accuracy exceeding 80 percent at both forest sites. Also, our results showed high agreement (R2 &gt; 0.64) in terms of AGB estimates using 3D LiDAR metrics and variables measured in the field, for both sites. The findings from our study demonstrate the efficacy of the proposed framework in delineating tree crowns, even in high canopy density areas such as tropical rainforests, where, usually the traditional algorithms are limited in their performances. Moreover, the high tree delineation accuracy in the two study areas emphasizes the potential robustness and transferability of our approach to other densely forested areas across the globe.},
DOI = {10.3390/f9120759}
}



@Article{atmos9120481,
AUTHOR = {Zheng, Naishan and Luo, Manman and Zou, Xiuguo and Qiu, Xinfa and Lu, Jingxia and Han, Jiaqi and Wang, Siyu and Wei, Yuning and Zhang, Shikai and Yao, Heyang},
TITLE = {A Novel Method for the Recognition of Air Visibility Level Based on the Optimal Binary Tree Support Vector Machine},
JOURNAL = {Atmosphere},
VOLUME = {9},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {481},
URL = {https://www.mdpi.com/2073-4433/9/12/481},
ISSN = {2073-4433},
ABSTRACT = {As the traditional methods for the recognition of air visibility level have the disadvantages of high cost, complicated operation, and the need to set markers, this paper proposes a novel method for the recognition of air visibility level based on an optimal binary tree support vector machine (SVM) using image processing techniques. Firstly, morphological processing is performed on the image. Then, whether the region of interest (ROI) is extracted is determined by the extracted feature values, that is, the contrast features and edge features are extracted in the ROI. After that, the transmittance features of red, green and blue channels (RGB) are extracted throughout the whole image. These feature values are used to construct the visibility level recognition model based on optimal binary tree SVM. The experiments are carried out to verify the proposed method. The experimental results show that the recognition accuracies of the proposed method for four levels of visibility, i.e., good air quality, mild pollution, moderate pollution, and heavy pollution, are 92.00%, 92%, 88.00%, and 100.00%, respectively, with an average recognition accuracy of 93.00%. The proposed method is compared with one-to-one SVM and one-to-many SVM in terms of training time and recognition accuracy. The experimental results show that the proposed method can distinguish four levels of visibility at a relatively satisfactory level, and it performs better than the other two methods in terms of training time and recognition accuracy. This proposed method provides an effective solution for the recognition of air visibility level.},
DOI = {10.3390/atmos9120481}
}



@Article{electronics7120405,
AUTHOR = {Fernández-Caramés, Tiago M. and Fraga-Lamas, Paula},
TITLE = {Towards The Internet of Smart Clothing: A Review on IoT Wearables and Garments for Creating Intelligent Connected E-Textiles},
JOURNAL = {Electronics},
VOLUME = {7},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {405},
URL = {https://www.mdpi.com/2079-9292/7/12/405},
ISSN = {2079-9292},
ABSTRACT = {Technology has become ubiquitous, it is all around us and is becoming part of us. Togetherwith the rise of the Internet of Things (IoT) paradigm and enabling technologies (e.g., Augmented Reality (AR), Cyber-Physical Systems, Artificial Intelligence (AI), blockchain or edge computing), smart wearables and IoT-based garments can potentially have a lot of influence by harmonizing functionality and the delight created by fashion. Thus, smart clothes look for a balance among fashion, engineering, interaction, user experience, cybersecurity, design and science to reinvent technologies that can anticipate needs and desires. Nowadays, the rapid convergence of textile and electronics is enabling the seamless and massive integration of sensors into textiles and the development of conductive yarn. The potential of smart fabrics, which can communicate with smartphones to process biometric information such as heart rate, temperature, breathing, stress, movement, acceleration, or even hormone levels, promises a new era for retail. This article reviews the main requirements for developing smart IoT-enabled garments and shows smart clothing potential impact on business models in the medium-term. Specifically, a global IoT architecture is proposed, the main types and components of smart IoT wearables and garments are presented, their main requirements are analyzed and some of the most recent smart clothing applications are studied. In this way, this article reviews the past and present of smart garments in order to provide guidelines for the future developers of a network where garments will be connected like other IoT objects: the Internet of Smart Clothing.},
DOI = {10.3390/electronics7120405}
}



@Article{s18124333,
AUTHOR = {Vinayaraj, Poliyapram and Imamoglu, Nevrez and Nakamura, Ryosuke and Oda, Atsushi},
TITLE = {Investigation on Perceptron Learning for Water Region Estimation Using Large-Scale Multispectral Images},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {4333},
URL = {https://www.mdpi.com/1424-8220/18/12/4333},
ISSN = {1424-8220},
ABSTRACT = {Land cover classification and investigation of temporal changes are considered to be common applications of remote sensing. Water/non-water region estimation is one of the most fundamental classification tasks, analyzing the occurrence of water on the Earth&rsquo;s surface. However, common remote sensing practices such as thresholding, spectral analysis, and statistical approaches are not sufficient to produce a globally adaptable water classification. The aim of this study is to develop a formula with automatically derived tuning parameters using perceptron neural networks for water/non-water region estimation, which we call the Perceptron-Derived Water Formula (PDWF), using Landsat-8 images. Water/non-water region estimates derived from PDWF were compared with three different approaches&mdash;Modified Normalized Difference Water Index (MNDWI), Automatic Water Extraction Index (AWEI), and Deep Convolutional Neural Network&mdash;using various case studies. Our proposed method outperforms all three approaches, showing a significant improvement in water/non-water region estimation. PDWF performance is consistently better even in cases of challenging conditions such as low reflectance due to hill shadows, building-shadows, and dark soils. Moreover, our study implemented a sunglint correction to adapt water/non-water region estimation over sunglint-affected pixels.},
DOI = {10.3390/s18124333}
}



@Article{electronics7120411,
AUTHOR = {Torti, Emanuele and Fontanella, Alessandro and Plaza, Antonio and Plaza, Javier and Leporati, Francesco},
TITLE = {Hyperspectral Image Classification Using Parallel Autoencoding Diabolo Networks on Multi-Core and Many-Core Architectures},
JOURNAL = {Electronics},
VOLUME = {7},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {411},
URL = {https://www.mdpi.com/2079-9292/7/12/411},
ISSN = {2079-9292},
ABSTRACT = {One of the most important tasks in hyperspectral imaging is the classification of the pixels in the scene in order to produce thematic maps. This problem can be typically solved through machine learning techniques. In particular, deep learning algorithms have emerged in recent years as a suitable methodology to classify hyperspectral data. Moreover, the high dimensionality of hyperspectral data, together with the increasing availability of unlabeled samples, makes deep learning an appealing approach to process and interpret those data. However, the limited number of labeled samples often complicates the exploitation of supervised techniques. Indeed, in order to guarantee a suitable precision, a large number of labeled samples is normally required. This hurdle can be overcome by resorting to unsupervised classification algorithms. In particular, autoencoders can be used to analyze a hyperspectral image using only unlabeled data. However, the high data dimensionality leads to prohibitive training times. In this regard, it is important to realize that the operations involved in autoencoders training are intrinsically parallel. Therefore, in this paper we present an approach that exploits multi-core and many-core devices in order to achieve efficient autoencoders training in hyperspectral imaging applications. Specifically, in this paper, we present new OpenMP and CUDA frameworks for autoencoder training. The obtained results show that the CUDA framework provides a speed-up of about two orders of magnitudes as compared to an optimized serial processing chain.},
DOI = {10.3390/electronics7120411}
}



@Article{rs10121991,
AUTHOR = {Garcia-Pedrero, Angel and Gonzalo-Martín, Consuelo and Lillo-Saavedra, Mario and Rodríguez-Esparragón, Dionisio},
TITLE = {The Outlining of Agricultural Plots Based on Spatiotemporal Consensus Segmentation},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {1991},
URL = {https://www.mdpi.com/2072-4292/10/12/1991},
ISSN = {2072-4292},
ABSTRACT = {The outlining of agricultural land is an important task for obtaining primary information used to create agricultural policies, estimate subsidies and agricultural insurance, and update agricultural geographical databases, among others. Most of the automatic and semi-automatic methods used for outlining agricultural plots using remotely sensed imagery are based on image segmentation. However, these approaches are usually sensitive to intra-plot variability and depend on the selection of the correct parameters, resulting in a poor performance due to the variability in the shape, size, and texture of the agricultural landscapes. In this work, a new methodology based on consensus image segmentation for outlining agricultural plots is presented. The proposed methodology combines segmentation at different scales&mdash;carried out using a superpixel (SP) method&mdash;and different dates from the same growing season to obtain a single segmentation of the agricultural plots. A visual and numerical comparison of the results provided by the proposed methodology with field-based data (ground truth) shows that the use of segmentation consensus is promising for outlining agricultural plots in a semi-supervised manner.},
DOI = {10.3390/rs10121991}
}



@Article{rs10121992,
AUTHOR = {Xie, Zixi and Song, Weiguo and Ba, Rui and Li, Xiaolian and Xia, Long},
TITLE = {A Spatiotemporal Contextual Model for Forest Fire Detection Using Himawari-8 Satellite Data},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {1992},
URL = {https://www.mdpi.com/2072-4292/10/12/1992},
ISSN = {2072-4292},
ABSTRACT = {Two of the main remote sensing data resources for forest fire detection have significant drawbacks: geostationary Earth Observation (EO) satellites have high temporal resolution but low spatial resolution, whereas Polar-orbiting systems have high spatial resolution but low temporal resolution. Therefore, the existing forest fire detection algorithms that are based on a single one of these two systems have only exploited temporal or spatial information independently. There are no approaches yet that have effectively merged spatial and temporal characteristics to detect forest fires. This paper fills this gap by presenting a spatiotemporal contextual model (STCM) that fully exploits geostationary data&rsquo;s spatial and temporal dimensions based on the data from Himawari-8 Satellite. We used an improved robust fitting algorithm to model each pixel&rsquo;s diurnal temperature cycles (DTC) in the middle and long infrared bands. For each pixel, a Kalman filter was used to blend the DTC to estimate the true background brightness temperature. Subsequently, we utilized the Otsu method to identify the fire after using an MVC (maximum value month composite of NDVI) threshold to test which areas have enough fuel to support such events. Finally, we used a continuous timeslot test to correct the fire detection results. The proposed algorithm was applied to four fire cases in East Asia and Australia in 2016. A comparison of detection results between MODIS Terra and Aqua active fire products (MOD14 and MYD14) demonstrated that the proposed algorithm from this paper effectively analyzed the spatiotemporal information contained in multi-temporal remotely sensed data. In addition, this new forest fire detection method can lead to higher detection accuracy than the traditional contextual and temporal algorithms. By developing algorithms that are based on AHI measurements to meet the requirement to detect forest fires promptly and accurately, this paper assists both emergency responders and the general public to mitigate the damage of forest fires.},
DOI = {10.3390/rs10121992}
}



@Article{s18124356,
AUTHOR = {Chen, Chien-Ying and Hasan, Monowar and Mohan, Sibin},
TITLE = {Securing Real-Time Internet-of-Things},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {4356},
URL = {https://www.mdpi.com/1424-8220/18/12/4356},
ISSN = {1424-8220},
ABSTRACT = {Modern embedded and cyber-physical systems are ubiquitous. Many critical cyber-physical systems have real-time requirements (e.g., avionics, automobiles, power grids, manufacturing systems, industrial control systems, etc.). Recent developments and new functionality require real-time embedded devices to be connected to the Internet. This gives rise to the real-time Internet-of-things (RT-IoT) that promises a better user experience through stronger connectivity and efficient use of next-generation embedded devices. However, RT-IoT are also increasingly becoming targets for cyber-attacks, which is exacerbated by this increased connectivity. This paper gives an introduction to RT-IoT systems, an outlook of current approaches and possible research challenges towards secure RT-IoT frameworks.},
DOI = {10.3390/s18124356}
}



@Article{s18124359,
AUTHOR = {Piltan, Farzin and Kim, Jong-Myon},
TITLE = {Bearing Fault Diagnosis Using an Extended Variable Structure Feedback Linearization Observer},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {4359},
URL = {https://www.mdpi.com/1424-8220/18/12/4359},
ISSN = {1424-8220},
ABSTRACT = {The rolling element bearing is a significant component in rotating machinery. Suitable bearing fault detection and diagnosis (FDD) is vital to maintaining machine operations in a safe and healthy state. To address this issue, an extended observer-based FDD method is proposed, which uses a variable structure feedback linearization observer (FLO). The traditional feedback linearization observer is stable; however, this technique suffers from a lack of robustness. The proposed variable structure technique was used to improve the robustness of the fault estimation while reducing the uncertainties in the feedback linearization observer. The effectiveness of the proposed FLO procedure for the identification of outer, inner, and ball faults was tested using the Case Western University vibration dataset. The proposed model outperformed the variable structure observer (VSO), traditional feedback linearization observer (TFLO), and proportional-integral observer (PIO) by achieving average performance improvements of 5.5%, 8.5%, and 18.5%, respectively.},
DOI = {10.3390/s18124359}
}



@Article{rs10121998,
AUTHOR = {Lou, Yidong and Zhang, Tian and Tang, Jian and Song, Weiwei and Zhang, Yi and Chen, Liang},
TITLE = {A Fast Algorithm for Rail Extraction Using Mobile Laser Scanning Data},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {1998},
URL = {https://www.mdpi.com/2072-4292/10/12/1998},
ISSN = {2072-4292},
ABSTRACT = {Railroads companies conduct regular inspections of their tracks to maintain and update the geographic data for railway management. Traditional railroad inspection methods, such as onsite inspections and semi-automated analysis of imagery and video data, are time consuming and ineffective. This study presents an automated effective method to detect tracks on the basis of their physical shape, geometrical properties, and reflection intensity feature. This study aims to investigate the feasibility of fast extraction of railroad using onboard Velodyne puck data collected by mobile laser scanning (MLS) system. Results show that the proposed method can be executed rapidly on an i5 computer with at least 10 Hz. The MLS system used in this study comprises a Velodyne puck/onboard GNSS receiver/inertial measurement unit. The range accuracy of Velodyne puck equipment is 2 cm, which fulfills the need of precise mapping. Notably, positioning STD is lower than 4 cm in most areas. Experiments are also undertaken to evaluate the timing of the proposed method. Experimental results indicate that the proposed method can extract 3D tracks in real-time and correctly recognize pairs of tracks. Accuracy, precision, and sensitivity of total test area are 99.68%, 97.55%, and 66.55%, respectively. Results suggest that in a multi-track area, close collaboration between MLS platforms mounted on several trains is required.},
DOI = {10.3390/rs10121998}
}



@Article{rs10122010,
AUTHOR = {Tauro, Flavia and Tosi, Fabio and Mattoccia, Stefano and Toth, Elena and Piscopia, Rodolfo and Grimaldi, Salvatore},
TITLE = {Optical Tracking Velocimetry (OTV): Leveraging Optical Flow and Trajectory-Based Filtering for Surface Streamflow Observations},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {2010},
URL = {https://www.mdpi.com/2072-4292/10/12/2010},
ISSN = {2072-4292},
ABSTRACT = {Nonintrusive image-based methods have the potential to advance hydrological streamflow observations by providing spatially distributed data at high temporal resolution. Due to their simplicity, correlation-based approaches have until recent been preferred to alternative image-based approaches, such as optical flow, for camera-based surface flow velocity estimate. In this work, we introduce a novel optical flow scheme, optical tracking velocimetry (OTV), that entails automated feature detection, tracking through the differential sparse Lucas-Kanade algorithm, and then a posteriori filtering to retain only realistic trajectories that pertain to the transit of actual objects in the field of view. The method requires minimal input on the flow direction and camera orientation. Tested on two image data sets collected in diverse natural conditions, the approach proved suitable for rapid and accurate surface flow velocity estimations. Five different feature detectors were compared and the features from accelerated segment test (FAST) resulted in the best balance between the number of features identified and successfully tracked as well as computational efficiency. OTV was relatively insensitive to reduced image resolution but was impacted by acquisition frequencies lower than 7&ndash;8 Hz. Compared to traditional correlation-based techniques, OTV was less affected by noise and surface seeding. In addition, the scheme is foreseen to be applicable to real-time gauge-cam implementations.},
DOI = {10.3390/rs10122010}
}



@Article{s18124390,
AUTHOR = {Xiang, Tingli and Wang, Hongjun},
TITLE = {Research on Distributed 5G Signal Coverage Detection Algorithm Based on PSO-BP-Kriging},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {4390},
URL = {https://www.mdpi.com/1424-8220/18/12/4390},
ISSN = {1424-8220},
ABSTRACT = {In order to overcome the limitations of traditional road test methods in 5G mobile communication network signal coverage detection, a signal coverage detection algorithm based on distributed sensor network for 5G mobile communication network is proposed. First, the received signal strength of the communication base station is collected and pre-processed by randomly deploying distributed sensor nodes. Then, the neural network objective function is modified by using the variogram function, and the initial weight coefficient of the neural network is optimized by using the improved particle swarm optimization algorithm. Next, the trained network model is used to interpolate the perceptual blind zone. Finally, the sensor node sampling data and the interpolation estimation result are combined to generate an effective coverage of the 5G mobile communication network signal. Simulation results indicate that the proposed algorithm can detect the real situation of 5G mobile communication network signal coverage better than other algorithms, and has certain feasibility and application prospects.},
DOI = {10.3390/s18124390}
}



@Article{rs10122015,
AUTHOR = {Zhang, Yao and Qin, Qiming and Ren, Huazhong and Sun, Yuanheng and Li, Minzan and Zhang, Tianyuan and Ren, Shilong},
TITLE = {Optimal Hyperspectral Characteristics Determination for Winter Wheat Yield Prediction},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {2015},
URL = {https://www.mdpi.com/2072-4292/10/12/2015},
ISSN = {2072-4292},
ABSTRACT = {Crop growth in different periods influences the final yield. This study started from the agronomic mechanism of yield formation and aimed to extract useful spectral characteristics in different phenological phases, which could directly describe the final yield and dynamic contributions of different phases to the yield formation. Hyperspectral information of the winter wheat canopy was acquired during three important phases (jointing stage, heading stage, and grain-filling stage). An enhanced 2D correlation spectral analysis method modified by mutual information was proposed to identify the sensitive wavebands. The selected wavebands performed well with good mechanism interpretation and close correlation with important crop growth parameters and main physiological activities related to yield formation. The quantitative contribution proportions of plant growth in three phases to the final yield were estimated by determining the coefficients of partial least square models based on full spectral information. They were then used as single-phase weight factors to merge the selected wavebands. The support vector machine model based on the weighted spectral dataset performed well in yield prediction with satisfactory accuracy and robustness. This result would provide rapid and accurate guidance for agricultural production and would be valuable for the processing of hyperspectral remote sensing data.},
DOI = {10.3390/rs10122015}
}



@Article{rs10122020,
AUTHOR = {Lu, Chunyan and Liu, Jinfu and Jia, Mingming and Liu, Mingyue and Man, Weidong and Fu, Weiwei and Zhong, Lianxiu and Lin, Xiaoqing and Su, Ying and Gao, Yibin},
TITLE = {Dynamic Analysis of Mangrove Forests Based on an Optimal Segmentation Scale Model and Multi-Seasonal Images in Quanzhou Bay, China},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {2020},
URL = {https://www.mdpi.com/2072-4292/10/12/2020},
ISSN = {2072-4292},
ABSTRACT = {Mangrove forests are important coastal ecosystems and are crucial for the equilibrium of the global carbon cycle. Monitoring and mapping of mangrove forests are essential for framing knowledge-based conservation policies and funding decisions by governments and managers. The purpose of this study was to monitor mangrove forest dynamics in the Quanzhou Bay Estuary Wetland Nature Reserve. To achieve this goal, we compared and analyzed the spectral discrimination among mangrove forests, mudflats and Spartina using multi-seasonal Landsat images from 1990, 1997, 2005, 2010, and 2017. We identified the spatio-temporal distribution of mangrove forests by combining an optimal segmentation scale model based on object-oriented classification, decision tree and visual interpretation. In addition, mangrove forest dynamics were determined by combining the annual land change area, centroid migration and overlay analysis. The results showed that there were advantages in the approaches used in this study for monitoring mangrove forests. From 1990 to 2017, the extent of mangrove forests increased by 2.48 km2, which was mostly converted from mudflats and Spartina. Environmental threats including climate change and sea-level rise, aquaculture development and Spartina invasion, pose potential and direct threats to the existence and expansion of mangrove forests. However, the implementation of reforestation projects and Spartina control plays a substantial role in the expansion of mangrove forests. It has been demonstrated that conservation activities can be beneficial for the restoration and succession of mangrove forests. This study provides an example of how the application of an optimal segmentation scale model and multi-seasonal images to mangrove forest monitoring can facilitate government policies that ensure the effective protection of mangrove forests.},
DOI = {10.3390/rs10122020}
}



@Article{rs10122026,
AUTHOR = {Zheng, Hengbiao and Li, Wei and Jiang, Jiale and Liu, Yong and Cheng, Tao and Tian, Yongchao and Zhu, Yan and Cao, Weixing and Zhang, Yu and Yao, Xia},
TITLE = {A Comparative Assessment of Different Modeling Algorithms for Estimating Leaf Nitrogen Content in Winter Wheat Using Multispectral Images from an Unmanned Aerial Vehicle},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {2026},
URL = {https://www.mdpi.com/2072-4292/10/12/2026},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle (UAV)-based remote sensing (RS) possesses the significant advantage of being able to efficiently collect images for precision agricultural applications. Although numerous methods have been proposed to monitor crop nitrogen (N) status in recent decades, just how to utilize an appropriate modeling algorithm to estimate crop leaf N content (LNC) remains poorly understood, especially based on UAV multispectral imagery. A comparative assessment of different modeling algorithms (i.e., simple and non-parametric modeling algorithms alongside the physical model retrieval method) for winter wheat LNC estimation is presented in this study. Experiments were conducted over two consecutive years and involved different winter wheat varieties, N rates, and planting densities. A five-band multispectral camera (i.e., 490 nm, 550 nm, 671 nm, 700 nm, and 800 nm) was mounted on a UAV to acquire canopy images across five critical growth stages. The results of this study showed that the best-performing vegetation index (VI) was the modified renormalized difference VI (RDVI), which had a determination coefficient (R2) of 0.73 and a root mean square error (RMSE) of 0.38. This method was also characterized by a high processing speed (0.03 s) for model calibration and validation. Among the 13 non-parametric modeling algorithms evaluated here, the random forest (RF) approach performed best, characterized by R2 and RMSE values of 0.79 and 0.33, respectively. This method also had the advantage of full optical spectrum utilization and enabled flexible, non-linear fitting with a fast processing speed (2.3 s). Compared to the other two methods assessed here, the use of a look up table (LUT)-based radiative transfer model (RTM) remained challenging with regard to LNC estimation because of low prediction accuracy (i.e., an R2 value of 0.62 and an RMSE value of 0.46) and slow processing speed. The RF approach is a fast and accurate technique for N estimation based on UAV multispectral imagery.},
DOI = {10.3390/rs10122026}
}



@Article{systems6040044,
AUTHOR = {Madni, Azad M. and Madni, Carla C.},
TITLE = {Architectural Framework for Exploring Adaptive Human-Machine Teaming Options in Simulated Dynamic Environments},
JOURNAL = {Systems},
VOLUME = {6},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {44},
URL = {https://www.mdpi.com/2079-8954/6/4/44},
ISSN = {2079-8954},
ABSTRACT = {With the growing complexity of environments in which systems are expected to operate, adaptive human-machine teaming (HMT) has emerged as a key area of research. While human teams have been extensively studied in the psychological and training literature, and agent teams have been investigated in the artificial intelligence research community, the commitment to research in HMT is relatively new and fueled by several technological advances such as electrophysiological sensors, cognitive modeling, machine learning, and adaptive/adaptable human-machine systems. This paper presents an architectural framework for investigating HMT options in various simulated operational contexts including responding to systemic failures and external disruptions. The paper specifically discusses new and novel roles for machines made possible by new technology and offers key insights into adaptive human-machine teams. Landed aircraft perimeter security is used as an illustrative example of an adaptive cyber-physical-human system (CPHS). This example is used to illuminate the use of the HMT framework in identifying the different human and machine roles involved in this scenario. The framework is domain-independent and can be applied to both defense and civilian adaptive HMT. The paper concludes with recommendations for advancing the state-of-the-art in HMT.},
DOI = {10.3390/systems6040044}
}



@Article{en11123496,
AUTHOR = {Liu, Ziquan and Wang, Huifang},
TITLE = {Automatic Detection of Transformer Components in Inspection Images Based on Improved Faster R-CNN},
JOURNAL = {Energies},
VOLUME = {11},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {3496},
URL = {https://www.mdpi.com/1996-1073/11/12/3496},
ISSN = {1996-1073},
ABSTRACT = {To detect the categories and positions of various transformer components in inspection images automatically, this paper proposes a transformer component detection model with high detection accuracy, based on the structure of Faster R-CNN. In consideration of the significant difference in component sizes, double feature maps are used to adapt to the size change, by adjusting two weights dynamically according to the object size. Moreover, different from the detection of ordinary objects, there is abundant useful information contained in the relative positions between components. Thus, the relative position features are defined and introduced to the refinement of the detection results. Then, the training process and detection process are proposed specifically for the improved model. Finally, an experiment is given to compare the accuracy and efficiency of the improved model and the original Faster R-CNN, along with other object detection models. Results show that the improved model has an obvious advantage in accuracy, and the efficiency is significantly higher than that of manual detection, which suggests that the model is suitable for practical engineering applications.},
DOI = {10.3390/en11123496}
}



@Article{rs10122047,
AUTHOR = {Cao, Jingjing and Liu, Kai and Liu, Lin and Zhu, Yuanhui and Li, Jun and He, Zhi},
TITLE = {Identifying Mangrove Species Using Field Close-Range Snapshot Hyperspectral Imaging and Machine-Learning Techniques},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {2047},
URL = {https://www.mdpi.com/2072-4292/10/12/2047},
ISSN = {2072-4292},
ABSTRACT = {Investigating mangrove species composition is a basic and important topic in wetland management and conservation. This study aims to explore the potential of close-range hyperspectral imaging with a snapshot hyperspectral sensor for identifying mangrove species under field conditions. Specifically, we assessed the data pre-processing and transformation, waveband selection and machine-learning techniques to develop an optimal classification scheme for eight mangrove species in Qi&rsquo;ao Island of Zhuhai, Guangdong, China. After data pre-processing and transformation, five spectral datasets, which included the reflectance spectra R and its first-order derivative d(R), the logarithm of the reflectance spectra log(R) and its first-order derivative d[log(R)], and hyperspectral vegetation indices (VIs), were used as the input data for each classifier. Consequently, three waveband selection methods, including the stepwise discriminant analysis (SDA), correlation-based feature selection (CFS), and successive projections algorithm (SPA) were used to reduce dimensionality and select the effective wavebands for identifying mangrove species. Furthermore, we evaluated the performance of mangrove species classification using four classifiers, including linear discriminant analysis (LDA), k-nearest neighbor (KNN), random forest (RF), and support vector machine (SVM). Application of the four considered classifiers on the reflectance spectra of all wavebands yielded overall classification accuracies of the eight mangrove species higher than 80%, with SVM having the highest accuracy of 93.54% (Kappa = 0.9256). Using the selected wavebands derived from SPA, the accuracy of SVM reached 93.13% (Kappa = 0.9208). The addition of hyperspectral VIs and d[log(R)] spectral datasets further improves the accuracies to 93.54% (Kappa = 0.9253) and 96.46% (Kappa = 0.9591), respectively. These results suggest that it is highly effective to apply field close-range snapshot hyperspectral images and machine-learning classifiers to classify mangrove species.},
DOI = {10.3390/rs10122047}
}



@Article{s18124464,
AUTHOR = {Cao, Feng and Liu, Fei and Guo, Han and Kong, Wenwen and Zhang, Chu and He, Yong},
TITLE = {Fast Detection of Sclerotinia Sclerotiorum on Oilseed Rape Leaves Using Low-Altitude Remote Sensing Technology},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {4464},
URL = {https://www.mdpi.com/1424-8220/18/12/4464},
ISSN = {1424-8220},
ABSTRACT = {Sclerotinia sclerotiorum, one of the major diseases infecting oilseed rape leaves, has seriously affected crop yield and quality. In this study, an indoor unmanned aerial vehicle (UAV) low-altitude remote sensing simulation platform was built for disease detection. Thermal, multispectral and RGB images were acquired before and after being artificially inoculated with Sclerotinia sclerotiorum on oilseed rape leaves. New image registration and fusion methods based on scale-invariant feature transform (SIFT) were presented to construct a fused database using multi-model images. The changes of temperature distribution in different sections of infected areas were analyzed by processing thermal images, the maximum temperature difference (MTD) on a single leaf reached 1.7 degrees Celsius 24 h after infection. Four machine learning models were established using thermal images and fused images respectively, including support vector machine (SVM), random forest (RF), K-nearest neighbor (KNN) and na&iuml;ve Bayes (NB). The results demonstrated that the classification accuracy was improved by 11.3% after image fusion, and the SVM model obtained a classification accuracy of 90.0% on the task of classifying disease severity. The overall results indicated the UAV low-altitude remote sensing simulation platform equipped with multi-sensors could be used to early detect Sclerotinia sclerotiorum on oilseed rape leaves.},
DOI = {10.3390/s18124464}
}



@Article{s18124474,
AUTHOR = {Djedouboum, Asside Christian and Abba Ari, Ado Adamou and Gueroui, Abdelhak Mourad and Mohamadou, Alidou and Aliouat, Zibouda},
TITLE = {Big Data Collection in Large-Scale Wireless Sensor Networks},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {4474},
URL = {https://www.mdpi.com/1424-8220/18/12/4474},
ISSN = {1424-8220},
ABSTRACT = {Data collection is one of the main operations performed in Wireless Sensor Networks (WSNs). Even if several interesting approaches on data collection have been proposed during the last decade, it remains a research focus in full swing with a number of important challenges. Indeed, the continuous reduction in sensor size and cost, the variety of sensors available on the market, and the tremendous advances in wireless communication technology have potentially broadened the impact of WSNs. The range of application of WSNs now extends from health to the military field through home automation, environmental monitoring and tracking, as well as other areas of human activity. Moreover, the expansion of the Internet of Things (IoT) has resulted in an important amount of heterogeneous data that are produced at an exponential rate. Furthermore, these data are of interest to both industry and in research. This fact makes their collection and analysis imperative for many purposes. In view of the characteristics of these data, we believe that very large-scale and heterogeneous WSNs can be very useful for collecting and processing these Big Data. However, the scaling up of WSNs presents several challenges that are of interest in both network architecture to be proposed, and the design of data-routing protocols. This paper reviews the background and state of the art of Big Data collection in Large-Scale WSNs (LS-WSNs), compares and discusses on challenges of Big Data collection in LS-WSNs, and proposes possible directions for the future.},
DOI = {10.3390/s18124474}
}



@Article{app8122664,
AUTHOR = {Zhao, Caidan and Chen, Caiyun and He, Zeping and Wu, Zhiqiang},
TITLE = {Application of Auxiliary Classifier Wasserstein Generative Adversarial Networks in Wireless Signal Classification of Illegal Unmanned Aerial Vehicles},
JOURNAL = {Applied Sciences},
VOLUME = {8},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {2664},
URL = {https://www.mdpi.com/2076-3417/8/12/2664},
ISSN = {2076-3417},
ABSTRACT = {Recently, many studies have reported on image synthesis based on Generative Adversarial Networks (GAN). However, the use of GAN does not provide much attention on the signal classification problem. In the context of using wireless signals to classify illegal Unmanned Aerial Vehicles (UAVs), this paper explores the feasibility of using GAN to improve the training datasets and obtain a better classification model, thereby improving the accuracy of classification. First, we use the generative model of GAN to generate a large datasets, which does not need manual annotation. At the same time, the discriminative model of GAN is improved to classify the types of signals based on the loss function of the discriminative model. Finally, this model can be used to the outdoor environment and obtain a real-time illegal UAVs signal classification system. Our experiments confirmed that the improvements on the Auxiliary Classifier Generative Adversarial Networks (AC-GANs) by limited datasets achieve excellent results. The recognition rate can reach more than 95% in the indoor environment, and this method is also applicable in the outdoor environment. Moreover, based on the theory of Wasserstein GANs (WGAN) and AC-GANs, a more robust Auxiliary Classifier Wasserstein GANs (AC-WGANs) model is obtained, which is suitable for multi-class UAVs. Through the combination of AC-WGANs and Universal Software Radio Peripheral (USRP) B210 software defined radio (SDR) platform, a real-time UAVs signal classification system is also implemented.},
DOI = {10.3390/app8122664}
}



@Article{app8122670,
AUTHOR = {Guo, Hao and Wei, Guo and An, Jubai},
TITLE = {Dark Spot Detection in SAR Images of Oil Spill Using Segnet},
JOURNAL = {Applied Sciences},
VOLUME = {8},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {2670},
URL = {https://www.mdpi.com/2076-3417/8/12/2670},
ISSN = {2076-3417},
ABSTRACT = {Damping Bragg scattering from the ocean surface is the basic underlying principle of synthetic aperture radar (SAR) oil slick detection, and they produce dark spots on SAR images. Dark spot detection is the first step in oil spill detection, which affects the accuracy of oil spill detection. However, some natural phenomena (such as waves, ocean currents, and low wind belts, as well as human factors) may change the backscatter intensity on the surface of the sea, resulting in uneven intensity, high noise, and blurred boundaries of oil slicks or lookalikes. In this paper, Segnet is used as a semantic segmentation model to detect dark spots in oil spill areas. The proposed method is applied to a data set of 4200 from five original SAR images of an oil spill. The effectiveness of the method is demonstrated through the comparison with fully convolutional networks (FCN), an initiator of semantic segmentation models, and some other segmentation methods. It is here observed that the proposed method can not only accurately identify the dark spots in SAR images, but also show a higher robustness under high noise and fuzzy boundary conditions.},
DOI = {10.3390/app8122670}
}



@Article{rs10122067,
AUTHOR = {Huang, Lingcao and Liu, Lin and Jiang, Liming and Zhang, Tingjun},
TITLE = {Automatic Mapping of Thermokarst Landforms from Remote Sensing Images Using Deep Learning: A Case Study in the Northeastern Tibetan Plateau},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {2067},
URL = {https://www.mdpi.com/2072-4292/10/12/2067},
ISSN = {2072-4292},
ABSTRACT = {Thawing of ice-rich permafrost causes thermokarst landforms on the ground surface. Obtaining the distribution of thermokarst landforms is a prerequisite for understanding permafrost degradation and carbon exchange at local and regional scales. However, because of their diverse types and characteristics, it is challenging to map thermokarst landforms from remote sensing images. We conducted a case study towards automatically mapping a type of thermokarst landforms (i.e., thermo-erosion gullies) in a local area in the northeastern Tibetan Plateau from high-resolution images by the use of deep learning. In particular, we applied the DeepLab algorithm (based on Convolutional Neural Networks) to a 0.15-m-resolution Digital Orthophoto Map (created using aerial photographs taken by an Unmanned Aerial Vehicle). Here, we document the detailed processing flow with key steps including preparing training data, fine-tuning, inference, and post-processing. Validating against the field measurements and manual digitizing results, we obtained an F1 score of 0.74 (precision is 0.59 and recall is 1.0), showing that the proposed method can effectively map small and irregular thermokarst landforms. It is potentially viable to apply the designed method to mapping diverse thermokarst landforms in a larger area where high-resolution images and training data are available.},
DOI = {10.3390/rs10122067}
}



@Article{rs11010001,
AUTHOR = {Rançon, Florian and Bombrun, Lionel and Keresztes, Barna and Germain, Christian},
TITLE = {Comparison of SIFT Encoded and Deep Learning Features for the Classification and Detection of Esca Disease in Bordeaux Vineyards},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {1},
URL = {https://www.mdpi.com/2072-4292/11/1/1},
ISSN = {2072-4292},
ABSTRACT = {Grapevine wood fungal diseases such as esca are among the biggest threats in vineyards nowadays. The lack of very efficient preventive (best results using commercial products report 20% efficiency) and curative means induces huge economic losses. The study presented in this paper is centered around the in-field detection of foliar esca symptoms during summer, exhibiting a typical &ldquo;striped&rdquo; pattern. Indeed, in-field disease detection has shown great potential for commercial applications and has been successfully used for other agricultural needs such as yield estimation. Differentiation with foliar symptoms caused by other diseases or abiotic stresses was also considered. Two vineyards from the Bordeaux region (France, Aquitaine) were chosen as the basis for the experiment. Pictures of diseased and healthy vine plants were acquired during summer 2017 and labeled at the leaf scale, resulting in a patch database of around 6000 images (224 &times; 224 pixels) divided into red cultivar and white cultivar samples. Then, we tackled the classification part of the problem comparing state-of-the-art SIFT encoding and pre-trained deep learning feature extractors for the classification of database patches. In the best case, 91% overall accuracy was obtained using deep features extracted from MobileNet network trained on ImageNet database, demonstrating the efficiency of simple transfer learning approaches without the need to design an ad-hoc specific feature extractor. The third part aimed at disease detection (using bounding boxes) within full plant images. For this purpose, we integrated the deep learning base network within a &ldquo;one-step&rdquo; detection network (RetinaNet), allowing us to perform detection queries in real time (approximately six frames per second on GPU). Recall/Precision (RP) and Average Precision (AP) metrics then allowed us to evaluate the performance of the network on a 91-image (plants) validation database. Overall, 90% precision for a 40% recall was obtained while best esca AP was about 70%. Good correlation between annotated and detected symptomatic surface per plant was also obtained, meaning slightly symptomatic plants can be efficiently separated from severely attacked plants.},
DOI = {10.3390/rs11010001}
}



@Article{f10010001,
AUTHOR = {Wang, Kepu and Wang, Tiejun and Liu, Xuehua},
TITLE = {A Review: Individual Tree Species Classification Using Integrated Airborne LiDAR and Optical Imagery with a Focus on the Urban Environment},
JOURNAL = {Forests},
VOLUME = {10},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {1},
URL = {https://www.mdpi.com/1999-4907/10/1/1},
ISSN = {1999-4907},
ABSTRACT = {With the significant progress of urbanization, cities and towns are suffering from air pollution, heat island effects, and other environmental problems. Urban vegetation, especially trees, plays a significant role in solving these ecological problems. To maximize services provided by vegetation, urban tree species should be properly selected and optimally arranged. Therefore, accurate classification of tree species in urban environments has become a major issue. In this paper, we reviewed the potential of light detection and ranging (LiDAR) data to improve the accuracy of urban tree species classification. In detail, we reviewed the studies using LiDAR data in urban tree species mapping, especially studies where LiDAR data was fused with optical imagery, through classification accuracy comparison, general workflow extraction, and discussion and summarizing of the specific contribution of LiDAR. It is concluded that combining LiDAR data in urban tree species identification could achieve better classification accuracy than using either dataset individually, and that such improvements are mainly due to finer segmentation, shadowing effect reduction, and refinement of classification rules based on LiDAR. Furthermore, some suggestions are given to improve the classification accuracy on a finer and larger species level, while also aiming to maintain classification costs.},
DOI = {10.3390/f10010001}
}



@Article{rs11010007,
AUTHOR = {Chen, Yuyun and Li, Longwei and Lu, Dengsheng and Li, Dengqiu},
TITLE = {Exploring Bamboo Forest Aboveground Biomass Estimation Using Sentinel-2 Data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {7},
URL = {https://www.mdpi.com/2072-4292/11/1/7},
ISSN = {2072-4292},
ABSTRACT = {Bamboo forests, due to rapid growth and short harvest rotation, play an important role in carbon cycling and local economic development. Accurate estimation of bamboo forest aboveground biomass (AGB) has garnered increasing attention during the past two decades. However, remote sensing-based AGB estimation for bamboo forests is challenging due to poor understanding of the mechanisms between bamboo forest growth characteristics and remote sensing data. The objective of this research is to examine the remote sensing characteristics of on-year and off-year bamboo forests at different dates and their AGB estimation performance. This research used multiple Sentinel-2 data to explore AGB estimation of bamboo forests in Zhejiang Province, China, by taking into account the unique characteristics of on-year and off-year bamboo forest growth features. Combining field survey data and Sentinel-2 spectral responses (spectral bands and vegetation indices) and textural images, random forest was used to identify key variables for AGB estimation. The results show that (1) the on-year and off-year bamboo forests have considerably different spectral signatures, especially in the wavelengths between red edge 2 and near-infrared wavelength (NIR2) (740&ndash;865 nm), making it possible to separate on-year and off-year bamboo forests; (2) on-year bamboo forests have similar spectral signatures although AGB increases from as small as 40 Mgha&minus;1 to as high as 90 Mgha&minus;1, implying that optical sensor data cannot effectively model on-year bamboo AGB; (3) off-year bamboo AGB has significant relationships with red and shortwave infrared (SWIR) spectral bands in the April image and with red edge 2 in the July image, but the AGB saturation problem yields poor estimation accuracy; (4) stratification considerably improved off-year bamboo AGB estimation but not on-year, non-stratification using the April image is recommended; and (5) Sentinel-2 data cannot solve the bamboo AGB data saturation problem when AGB is greater than 70 Mgha&minus;1, similar to other optical sensor data such as Landsat. More research should be conducted in the future to integrate multiple sources&mdash;remotely sensed data (e.g., lidar, optical sensor data) and ancillary data (e.g., soil, topography)&mdash;into AGB modeling to improve the estimation. The use of very high spatial resolution images that can effectively extract tree density information may improve bamboo AGB estimation and yield new insights.},
DOI = {10.3390/rs11010007}
}



@Article{s19010017,
AUTHOR = {Kosak, Oliver and Wanninger, Constantin and Hoffmann, Alwin and Ponsar, Hella and Reif, Wolfgang},
TITLE = {Multipotent Systems: Combining Planning, Self-Organization, and Reconfiguration in Modular Robot Ensembles},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {17},
URL = {https://www.mdpi.com/1424-8220/19/1/17},
ISSN = {1424-8220},
ABSTRACT = {Mobile multirobot systems play an increasing role in many disciplines. Their capabilities can be used, e.g., to transport workpieces in industrial applications or to support operational forces in search and rescue scenarios, among many others. Depending on the respective application, the hardware design and accompanying software of mobile robots are of various forms, especially for integrating different sensors and actuators. Concerning this design, robots of one system compared to each other can be classified to exclusively be either homogeneous or heterogeneous, both resulting in different system properties. While homogeneously configured systems are known to be robust against failures through redundancy but are highly specialized for specific use cases, heterogeneously designed systems can be used for a broad range of applications but suffer from their specialization, i.e., they can only hardly compensate for the failure of one specialist. Up to now, there has been no known approach aiming to unify the benefits of both these types of system. In this paper, we present our approach to filling this gap by introducing a reference architecture for mobile robots that defines the interplay of all necessary technologies for achieving this goal. We introduce the class of robot systems implementing this architecture as multipotent systems that bring together the benefits of both system classes, enabling homogeneously designed robots to become heterogeneous specialists at runtime. When many of these robots work together, we call the structure of this cooperation an ensemble. To achieve multipotent ensembles, we also integrate reconfigurable and self-descriptive hardware (i.e., sensors and actuators) in this architecture, which can be freely combined to change the capabilities of robots at runtime. Because typically a high degree of autonomy in such systems is a prerequisite for their practical usage, we also present the integration of necessary mechanisms and algorithms for achieving the systems&rsquo; multipotency. We already achieved the first results with robots implementing our approach of multipotent systems in real-world experiments as well as in a simulation environment, which we present in this paper.},
DOI = {10.3390/s19010017}
}



@Article{rs11010011,
AUTHOR = {Li, Weijia and Dong, Runmin and Fu, Haohuan and Yu, Le},
TITLE = {Large-Scale Oil Palm Tree Detection from High-Resolution Satellite Images Using Two-Stage Convolutional Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {11},
URL = {https://www.mdpi.com/2072-4292/11/1/11},
ISSN = {2072-4292},
ABSTRACT = {Being an important economic crop that contributes 35% of the total consumption of vegetable oil, remote sensing-based quantitative detection of oil palm trees has long been a key research direction for both agriculture and environmental purposes. While existing methods already demonstrate satisfactory effectiveness for small regions, performing the detection for a large region with satisfactory accuracy is still challenging. In this study, we proposed a two-stage convolutional neural network (TS-CNN)-based oil palm detection method using high-resolution satellite images (i.e. Quickbird) in a large-scale study area of Malaysia. The TS-CNN consists of one CNN for land cover classification and one CNN for object classification. The two CNNs were trained and optimized independently based on 20,000 samples collected through human interpretation. For the large-scale oil palm detection for an area of 55 km2, we proposed an effective workflow that consists of an overlapping partitioning method for large-scale image division, a multi-scale sliding window method for oil palm coordinate prediction, and a minimum distance filter method for post-processing. Our proposed approach achieves a much higher average F1-score of 94.99% in our study area compared with existing oil palm detection methods (87.95%, 81.80%, 80.61%, and 78.35% for single-stage CNN, Support Vector Machine (SVM), Random Forest (RF), and Artificial Neural Network (ANN), respectively), and much fewer confusions with other vegetation and buildings in the whole image detection results.},
DOI = {10.3390/rs11010011}
}



@Article{rs11010020,
AUTHOR = {Wang, Yuhao and Liang, Binxiu and Ding, Meng and Li, Jiangyun},
TITLE = {Dense Semantic Labeling with Atrous Spatial Pyramid Pooling and Decoder for High-Resolution Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {20},
URL = {https://www.mdpi.com/2072-4292/11/1/20},
ISSN = {2072-4292},
ABSTRACT = {Dense semantic labeling is significant in high-resolution remote sensing imagery research and it has been widely used in land-use analysis and environment protection. With the recent success of fully convolutional networks (FCN), various types of network architectures have largely improved performance. Among them, atrous spatial pyramid pooling (ASPP) and encoder-decoder are two successful ones. The former structure is able to extract multi-scale contextual information and multiple effective field-of-view, while the latter structure can recover the spatial information to obtain sharper object boundaries. In this study, we propose a more efficient fully convolutional network by combining the advantages from both structures. Our model utilizes the deep residual network (ResNet) followed by ASPP as the encoder and combines two scales of high-level features with corresponding low-level features as the decoder at the upsampling stage. We further develop a multi-scale loss function to enhance the learning procedure. In the postprocessing, a novel superpixel-based dense conditional random field is employed to refine the predictions. We evaluate the proposed method on the Potsdam and Vaihingen datasets and the experimental results demonstrate that our method performs better than other machine learning or deep learning methods. Compared with the state-of-the-art DeepLab_v3+ our model gains 0.4% and 0.6% improvements in overall accuracy on these two datasets respectively.},
DOI = {10.3390/rs11010020}
}



@Article{s19010060,
AUTHOR = {Guzmán, Cesar H. and Carrera, José L. and Durán, Héctor A. and Berumen, Javier and Ortiz, Arturo A. and Guirette, Omar A. and Arroyo, Angélica and Brizuela, Jorge A. and Gómez, Fabio and Blanco, Andrés and Azcaray, Héctor R. and Hernández, Marlen},
TITLE = {Implementation of Virtual Sensors for Monitoring Temperature in Greenhouses Using CFD and Control},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {60},
URL = {https://www.mdpi.com/1424-8220/19/1/60},
ISSN = {1424-8220},
ABSTRACT = {Virtual sensing is crucial in order to provide feasible and economical alternatives when physical measuring instruments are not available. Developing model-based virtual sensors to calculate real-time information at each targeted location is a complex endeavor in terms of sensing technology. This paper proposes a new approach for model-based virtual sensor development using computational fluid dynamics (CFD) and control. Its main objective is to develop a three-dimensional (3D) real-time simulator using virtual sensors to monitor the temperature in a greenhouse. To conduct this study, a small-scale greenhouse was designed, modeled, and fabricated. The controller was based on the convection heat transfer equation under specific assumptions and conditions. To determine the temperature distribution in the greenhouse, a CFD analysis was conducted. Only one well-calibrated and controlled physical sensor (temperature reference) was enough for the CFD analysis. After processing the result that was obtained from the real sensor output, each virtual sensor had learned the associative transfer function that estimated the output from given input data, resulting in a 3D real-time simulator. This study has demonstrated, for the first time, that CFD analysis and a control strategy can be combined to obtain system models for monitoring the temperature in greenhouses. These findings suggest that, generally, virtual sensing can be applied in large greenhouses for monitoring the temperature using a 3D real-time simulator.},
DOI = {10.3390/s19010060}
}



@Article{w11010038,
AUTHOR = {Ramírez-Cuesta, Juan Miguel and Mirás-Avalos, José Manuel and Rubio-Asensio, José Salvador and Intrigliolo, Diego S.},
TITLE = {A Novel ArcGIS Toolbox for Estimating Crop Water Demands by Integrating the Dual Crop Coefficient Approach with Multi-Satellite Imagery},
JOURNAL = {Water},
VOLUME = {11},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {38},
URL = {https://www.mdpi.com/2073-4441/11/1/38},
ISSN = {2073-4441},
ABSTRACT = {Advances in information and communication technologies facilitate the application of complex models for optimizing agricultural water management. This paper presents an easy-to-use tool for determining crop water demands using the dual crop coefficient approach and remote sensing imagery. The model was developed using Python as a programming language and integrated into an ArcGIS (geographic information system) toolbox. Inputs consist of images from satellites Landsat 7 and 8, and Sentinel 2A, along with data for defining crop, weather, soil type, and irrigation system. The tool produces a spatial distribution map of the crop evapotranspiration estimates, assuming no water stress, which allows quantifying the water demand and its variability within an agricultural field with a spatial resolution of either 10 m (for Sentinel) or 30 m (for Landsat). The model was validated by comparing the estimated basal crop coefficients (Kcb) of lettuce and peach during an irrigation season with those tabulated as a reference for these crops. Good agreements between Kcb derived from both methods were obtained with a root mean squared error ranging from 0.01 to 0.02 for both crops, although certain underestimations were observed resulting from the uneven crop development in the field (percent bias of &minus;4.74% and &minus;1.80% for lettuce and peach, respectively). The developed tool can be incorporated into commercial decision support systems for irrigation scheduling and other applications that account for the water balance in agro-ecosystems. This tool is freely available upon request to the corresponding author.},
DOI = {10.3390/w11010038}
}



@Article{data4010004,
AUTHOR = {Moskalenko, Viacheslav and Moskalenko, Alona and Korobov, Artem and Semashko, Viktor},
TITLE = {The Model and Training Algorithm of Compact Drone Autonomous Visual Navigation System},
JOURNAL = {Data},
VOLUME = {4},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {4},
URL = {https://www.mdpi.com/2306-5729/4/1/4},
ISSN = {2306-5729},
ABSTRACT = {Trainable visual navigation systems based on deep learning demonstrate potential for robustness of onboard camera parameters and challenging environment. However, a deep model requires substantial computational resources and large labelled training sets for successful training. Implementation of the autonomous navigation and training-based fast adaptation to the new environment for a compact drone is a complicated task. The article describes an original model and training algorithms adapted to the limited volume of labelled training set and constrained computational resource. This model consists of a convolutional neural network for visual feature extraction, extreme-learning machine for estimating the position displacement and boosted information-extreme classifier for obstacle prediction. To perform unsupervised training of the convolution filters with a growing sparse-coding neural gas algorithm, supervised learning algorithms to construct the decision rules with simulated annealing search algorithm used for finetuning are proposed. The use of complex criterion for parameter optimization of the feature extractor model is considered. The resulting approach performs better trajectory reconstruction than the well-known ORB-SLAM. In particular, for sequence 7 from the KITTI dataset, the translation error is reduced by nearly 65.6% under the frame rate 10 frame per second. Besides, testing on the independent TUM sequence shot outdoors produces a translation error not exceeding 6% and a rotation error not exceeding 3.68 degrees per 100 m. Testing was carried out on the Raspberry Pi 3+ single-board computer.},
DOI = {10.3390/data4010004}
}



@Article{rs11010044,
AUTHOR = {Fu, Hualian and Shen, Yuan and Liu, Jun and He, Guangjun and Chen, Jinsong and Liu, Ping and Qian, Jing and Li, Jun},
TITLE = {Cloud Detection for FY Meteorology Satellite Based on Ensemble Thresholds and Random Forests Approach},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {44},
URL = {https://www.mdpi.com/2072-4292/11/1/44},
ISSN = {2072-4292},
ABSTRACT = {Cloud detection is the first step for the practical processing of meteorology satellite images, and also determines the accuracy of subsequent applications. For Chinese FY serial satellite, the National Meteorological Satellite Center (NSMC) officially provides the cloud detection products. In practical applications, there still are some misdetection regions. Therefore, this paper proposes a cloud detection method trying to improve NSMC&rsquo;s products based on ensemble threshold and random forest. The binarization is firstly performed using ten threshold methods of the first infrared band and visible channel of the image, and the binarized images are obtained by the voting strategy. Secondly, the binarized images of the two channels are combined to form an ensemble threshold image. Then the middle part of the ensemble threshold image and the upper and lower margins of NSMC&rsquo;s cloud detection result are used as the sample collection source data for the random forest. Training samples rely only on source image data at one moment, and then the trained random forest model is applied to images of other times to obtain the final cloud detection results. This method performs well on FY-2G images and can effectively detect incorrect areas of the cloud detection products of the NSMC. The accuracy of the algorithm is evaluated by manually labeled ground truth using different methods and objective evaluation indices including Probability of Detection (POD), False Alarm Rate (FAR), Critical Success Index (CSI) and the average and standard deviation of all indices. The accuracy results show that the proposed method performs better than the other methods with less incorrect detection regions. Though the proposed approach is simple enough, it is a useful attempt to improve the cloud detection result, and there is plenty of room for further improvement.},
DOI = {10.3390/rs11010044}
}



@Article{jimaging5010006,
AUTHOR = {Bachmann, Charles M. and Eon, Rehman S. and Lapszynski, Christopher S. and Badura, Gregory P. and Vodacek, Anthony and Hoffman, Matthew J. and McKeown, Donald and Kremens, Robert L. and Richardson, Michael and Bauch, Timothy and Foote, Mark},
TITLE = {A Low-Rate Video Approach to Hyperspectral Imaging of Dynamic Scenes},
JOURNAL = {Journal of Imaging},
VOLUME = {5},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {6},
URL = {https://www.mdpi.com/2313-433X/5/1/6},
ISSN = {2313-433X},
ABSTRACT = {The increased sensitivity of modern hyperspectral line-scanning systems has led to the development of imaging systems that can acquire each line of hyperspectral pixels at very high data rates (in the 200&ndash;400 Hz range). These data acquisition rates present an opportunity to acquire full hyperspectral scenes at rapid rates, enabling the use of traditional push-broom imaging systems as low-rate video hyperspectral imaging systems. This paper provides an overview of the design of an integrated system that produces low-rate video hyperspectral image sequences by merging a hyperspectral line scanner, operating in the visible and near infra-red, with a high-speed pan-tilt system and an integrated IMU-GPS that provides system pointing. The integrated unit is operated from atop a telescopic mast, which also allows imaging of the same surface area or objects from multiple view zenith directions, useful for bi-directional reflectance data acquisition and analysis. The telescopic mast platform also enables stereo hyperspectral image acquisition, and therefore, the ability to construct a digital elevation model of the surface. Imaging near the shoreline in a coastal setting, we provide an example of hyperspectral imagery time series acquired during a field experiment in July 2017 with our integrated system, which produced hyperspectral image sequences with 371 spectral bands, spatial dimensions of 1600 &times; 212, and 16 bits per pixel, every 0.67 s. A second example times series acquired during a rooftop experiment conducted on the Rochester Institute of Technology campus in August 2017 illustrates a second application, moving vehicle imaging, with 371 spectral bands, 16 bit dynamic range, and 1600 &times; 300 spatial dimensions every second.},
DOI = {10.3390/jimaging5010006}
}



@Article{f10010024,
AUTHOR = {Fraser, Benjamin T. and Congalton, Russell G.},
TITLE = {Evaluating the Effectiveness of Unmanned Aerial Systems (UAS) for Collecting Thematic Map Accuracy Assessment Reference Data in New England Forests},
JOURNAL = {Forests},
VOLUME = {10},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {24},
URL = {https://www.mdpi.com/1999-4907/10/1/24},
ISSN = {1999-4907},
ABSTRACT = {Thematic mapping provides today&rsquo;s analysts with an essential geospatial science tool for conveying spatial information. The advancement of remote sensing and computer science technologies has provided classification methods for mapping at both pixel-based and object-based analysis, for increasingly complex environments. These thematic maps then serve as vital resources for a variety of research and management needs. However, to properly use the resulting thematic map as a decision-making support tool, an assessment of map accuracy must be performed. The methods for assessing thematic accuracy have coalesced into a site-specific multivariate analysis of error, measuring uncertainty in relation to an established reality known as reference data. Ensuring statistical validity, access and time constraints, and immense costs limit the collection of reference data in many projects. Therefore, this research proposes evaluating the feasibility of adopting the low-cost, flexible, high-resolution sensor-capable Unmanned Aerial Systems (UAS, UAV, or Drone) platform for collecting reference data to use in thematic map accuracy assessments for complex environments. This pilot study analyzed 377.57 ha of New England forests, over six University of New Hampshire woodland properties, to compare the similarity between UAS-derived orthomosaic samples and ground-based continuous forest inventory (CFI) plot classifications of deciduous, mixed, and coniferous forest cover types. Using an eBee Plus fixed-wing UAS, 9173 images were acquired and used to create six comprehensive orthomosaics. Agreement between our UAS orthomosaics and ground-based sampling forest compositions reached 71.43% for pixel-based classification and 85.71% for object-based classification reference data methods. Despite several documented sources of uncertainty or error, this research demonstrated that UAS are capable of highly efficient and effective thematic map accuracy assessment reference data collection. As UAS hardware, software, and implementation policies continue to evolve, the potential to meet the challenges of accurate and timely reference data collection will only increase.},
DOI = {10.3390/f10010024}
}



@Article{rs11010077,
AUTHOR = {Navarro, José Antonio and Algeet, Nur and Fernández-Landa, Alfredo and Esteban, Jessica and Rodríguez-Noriega, Pablo and Guillén-Climent, María Luz},
TITLE = {Integration of UAV, Sentinel-1, and Sentinel-2 Data for Mangrove Plantation Aboveground Biomass Monitoring in Senegal},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {77},
URL = {https://www.mdpi.com/2072-4292/11/1/77},
ISSN = {2072-4292},
ABSTRACT = {Due to the increasing importance of mangroves in climate change mitigation projects, more accurate and cost-effective aboveground biomass (AGB) monitoring methods are required. However, field measurements of AGB may be a challenge because of their remote location and the difficulty to walk in these areas. This study is based on the Livelihoods Fund Oceanium project that monitors 10,000 ha of mangrove plantations. In a first step, the possibility of replacing traditional field measurements of sample plots in a young mangrove plantation by a semiautomatic processing of UAV-based photogrammetric point clouds was assessed. In a second step, Sentinel-1 radar and Sentinel-2 optical imagery were used as auxiliary information to estimate AGB and its variance for the entire study area under a model-assisted framework. AGB was measured using UAV imagery in a total of 95 sample plots. UAV plot data was used in combination with non-parametric support vector regression (SVR) models for the estimation of the study area AGB using model-assisted estimators. Purely UAV-based AGB estimates and their associated standard error (SE) were compared with model-assisted estimates using (1) Sentinel-1, (2) Sentinel-2, and (3) a combination of Sentinel-1 and Sentinel-2 data as auxiliary information. The validation of the UAV-based individual tree height and crown diameter measurements showed a root mean square error (RMSE) of 0.21 m and 0.32 m, respectively. Relative efficiency of the three model-assisted scenarios ranged between 1.61 and 2.15. Although all SVR models improved the efficiency of the monitoring over UAV-based estimates, the best results were achieved when a combination of Sentinel-1 and Sentinel-2 data was used. Results indicated that the methodology used in this research can provide accurate and cost-effective estimates of AGB in young mangrove plantations.},
DOI = {10.3390/rs11010077}
}



@Article{drones3010005,
AUTHOR = {Melville, Bethany and Lucieer, Arko and Aryal, Jagannath},
TITLE = {Classification of Lowland Native Grassland Communities Using Hyperspectral Unmanned Aircraft System (UAS) Imagery in the Tasmanian Midlands},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {5},
URL = {https://www.mdpi.com/2504-446X/3/1/5},
ISSN = {2504-446X},
ABSTRACT = {This paper presents the results of a study undertaken to classify lowland native grassland communities in the Tasmanian Midlands region. Data was collected using the 20 band hyperspectral snapshot PhotonFocus sensor mounted on an unmanned aerial vehicle. The spectral range of the sensor is 600 to 875 nm. Four vegetation classes were identified for analysis including Themeda triandra grassland, Wilsonia rotundifolia, Danthonia/Poa grassland, and Acacia dealbata. In addition to the hyperspectral UAS dataset, a Digital Surface Model (DSM) was derived using a structure-from-motion (SfM). Classification was undertaken using an object-based Random Forest (RF) classification model. Variable importance measures from the training model indicated that the DSM was the most significant variable. Key spectral variables included bands two (620.9 nm), four (651.1 nm), and 11 (763.2 nm) from the hyperspectral UAS imagery. Classification validation was performed using both the reference segments and the two transects. For the reference object validation, mean accuracies were between 70% and 72%. Classification accuracies based on the validation transects achieved a maximum overall classification accuracy of 93.},
DOI = {10.3390/drones3010005}
}



@Article{s19010176,
AUTHOR = {Zhou, Xiaomao and Gao, Yanbin and Guan, Lianwu},
TITLE = {Towards Goal-Directed Navigation Through Combining Learning Based Global and Local Planners},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {176},
URL = {https://www.mdpi.com/1424-8220/19/1/176},
ISSN = {1424-8220},
ABSTRACT = {Robot navigation is a fundamental problem in robotics and various approaches have been developed to cope with this problem. Despite the great success of previous approaches, learning-based methods are receiving growing interest in the research community. They have shown great efficiency in solving navigation tasks and offer considerable promise to build intelligent navigation systems. This paper presents a goal-directed robot navigation system that integrates global planning based on goal-directed end-to-end learning and local planning based on reinforcement learning (RL). The proposed system aims to navigate the robot to desired goal positions while also being adaptive to changes in the environment. The global planner is trained to imitate an expert&rsquo;s navigation between different positions by goal-directed end-to-end learning, where both the goal representations and local observations are incorporated to generate actions. However, it is trained in a supervised fashion and is weak in dealing with changes in the environment. To solve this problem, a local planner based on deep reinforcement learning (DRL) is designed. The local planner is first implemented in a simulator and then transferred to the real world. It works complementarily to deal with situations that have not been met during training the global planner and is able to generalize over different situations. The experimental results on a robot platform demonstrate the effectiveness of the proposed navigation system.},
DOI = {10.3390/s19010176}
}



@Article{e21010036,
AUTHOR = {Vecer, Jan},
TITLE = {Dynamic Scoring: Probabilistic Model Selection Based on Utility Maximization},
JOURNAL = {Entropy},
VOLUME = {21},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {36},
URL = {https://www.mdpi.com/1099-4300/21/1/36},
ISSN = {1099-4300},
ABSTRACT = {We propose a novel approach of model selection for probability estimates that may be applied in time evolving setting. Specifically, we show that any discrepancy between different probability estimates opens a possibility to compare them by trading on a hypothetical betting market that trades probabilities. We describe the mechanism of such a market, where agents maximize some utility function which determines the optimal trading volume for given odds. This procedure produces supply and demand functions, that determine the size of the bet as a function of a trading probability. These functions are closed form for the choice of logarithmic and exponential utility functions. Having two probability estimates and the corresponding supply and demand functions, the trade matching these estimates happens at the intersection of the supply and demand functions. We show that an agent using correct probabilities will realize a profit in expectation when trading against any other set of probabilities. The expected profit realized by the correct view of the market probabilities can be used as a measure of information in terms of statistical divergence.},
DOI = {10.3390/e21010036}
}



@Article{drones3010009,
AUTHOR = {Hernandez-Santin, Lorna and Rudge, Mitchel L. and Bartolo, Renee E. and Erskine, Peter D.},
TITLE = {Identifying Species and Monitoring Understorey from UAS-Derived Data: A Literature Review and Future Directions},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {9},
URL = {https://www.mdpi.com/2504-446X/3/1/9},
ISSN = {2504-446X},
ABSTRACT = {Understorey vegetation plays an important role in many ecosystems, yet identifying and monitoring understorey vegetation through remote sensing has proved a challenge for researchers and land managers because understorey plants tend to be small, spatially and spectrally similar, and are often blocked by the overstorey. The emergence of Unmanned Aerial Systems (UAS) is revolutionising how vegetation is measured, and may allow us to measure understorey species where traditional remote sensing previously could not. The goal of this paper was to review current literature and assess the current capability of UAS to identify and monitor understorey vegetation. From the literature, we focused on the technical attributes that limit the ability to monitor understorey vegetation&mdash;specifically (1) spatial resolution, (2) spectral sensitivity, (3) spatial extent, and (4) temporal frequency at which a sensor acquires data. We found that UAS have provided improved levels of spatial resolution, with authors reporting successful classifications of understorey vegetation at resolutions of between 3 mm and 200 mm. Species discrimination can be achieved by targeting flights to correspond with phenological events to allow the detection of species-specific differences. We provide recommendations as to how UAS attributes can be tailored to help identify and monitor understorey species.},
DOI = {10.3390/drones3010009}
}



@Article{rs11020108,
AUTHOR = {Xu, Lu and Ming, Dongping and Zhou, Wen and Bao, Hanqing and Chen, Yangyang and Ling, Xiao},
TITLE = {Farmland Extraction from High Spatial Resolution Remote Sensing Images Based on Stratified Scale Pre-Estimation},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {108},
URL = {https://www.mdpi.com/2072-4292/11/2/108},
ISSN = {2072-4292},
ABSTRACT = {Extracting farmland from high spatial resolution remote sensing images is a basic task for agricultural information management. According to Tobler&rsquo;s first law of geography, closer objects have a stronger relation. Meanwhile, due to the scale effect, there are differences on both spatial and attribute scales among different kinds of objects. Thus, it is not appropriate to segment images with unique or fixed parameters for different kinds of objects. In view of this, this paper presents a stratified object-based farmland extraction method, which includes two key processes: one is image region division on a rough scale and the other is scale parameter pre-estimation within local regions. Firstly, the image in RGB color space is converted into HSV color space, and then the texture features of the hue layer are calculated using the grey level co-occurrence matrix method. Thus, the whole image can be divided into different regions based on the texture features, such as the mean and homogeneity. Secondly, within local regions, the optimal spatial scale segmentation parameter was pre-estimated by average local variance and its first-order and second-order rate of change. The optimal attribute scale segmentation parameter can be estimated based on the histogram of local variance. Through stratified regionalization and local segmentation parameters estimation, fine farmland segmentation can be achieved. GF-2 and Quickbird images were used in this paper, and mean-shift and multi-resolution segmentation algorithms were applied as examples to verify the validity of the proposed method. The experimental results have shown that the stratified processing method can release under-segmentation and over-segmentation phenomena to a certain extent, which ultimately benefits the accurate farmland information extraction.},
DOI = {10.3390/rs11020108}
}



@Article{drones3010010,
AUTHOR = {Jiménez López, Jesús and Mulero-Pázmány, Margarita},
TITLE = {Drones for Conservation in Protected Areas: Present and Future},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {10},
URL = {https://www.mdpi.com/2504-446X/3/1/10},
ISSN = {2504-446X},
ABSTRACT = {Park managers call for cost-effective and innovative solutions to handle a wide variety of environmental problems that threaten biodiversity in protected areas. Recently, drones have been called upon to revolutionize conservation and hold great potential to evolve and raise better-informed decisions to assist management. Despite great expectations, the benefits that drones could bring to foster effectiveness remain fundamentally unexplored. To address this gap, we performed a literature review about the use of drones in conservation. We selected a total of 256 studies, of which 99 were carried out in protected areas. We classified the studies in five distinct areas of applications: “wildlife monitoring and management”; “ecosystem monitoring”; “law enforcement”; “ecotourism”; and “environmental management and disaster response”. We also identified specific gaps and challenges that would allow for the expansion of critical research or monitoring. Our results support the evidence that drones hold merits to serve conservation actions and reinforce effective management, but multidisciplinary research must resolve the operational and analytical shortcomings that undermine the prospects for drones integration in protected areas.},
DOI = {10.3390/drones3010010}
}



@Article{rs11020111,
AUTHOR = {Shiu, Yi-Shiang and Chuang, Yung-Chung},
TITLE = {Yield Estimation of Paddy Rice Based on Satellite Imagery: Comparison of Global and Local Regression Models},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {111},
URL = {https://www.mdpi.com/2072-4292/11/2/111},
ISSN = {2072-4292},
ABSTRACT = {Precisely estimating the yield of paddy rice is crucial for national food security and development evaluation. Rice yield estimation based on satellite imagery is usually performed with global regression models; however, estimation errors may occur because the spatial variation is not considered. Therefore, this study proposed an approach estimating paddy rice yield based on global and local regression models. In our study area, the overall per-field data might not available because it took lots of time and manpower as well as resources. Therefore, we gathered and accumulated 26 to 63 ground survey sample fields, accounting for about 0.05% of the total cultivated areas, as the training samples for our regression models. To demonstrate whether the spatial autocorrelation or spatial heterogeneity exists and dominates the estimation, global models including the ordinary least squares (OLS), support vector regression (SVR), and the local model geographically weighted regression (GWR) were used to build the yield estimation models. We obtained the representative independent variables, including 4 original bands, 11 vegetation indices, and 32 texture indices, from SPOT-7 multispectral satellite imagery. To determine the optimal variable combination, feature selection based on the Pearson correlation was used for all of the regression models. The case study in Central Taiwan rendered that the error rate was between 0.06% and 13.22%. Through feature selection, the GWR model&rsquo;s performance was more relatively stable than the OLS model and nonlinear SVR model for yield estimation. Where the GWR model considers the spatial autocorrelation and spatial heterogeneity of the relationships between the yield and the independent variables, the OLS and nonlinear SVR models lack this feature; this led to the rice yield estimation of GWR in this study be more stable than those of the other two models.},
DOI = {10.3390/rs11020111}
}



@Article{s19020274,
AUTHOR = {Yang, Shengying and Qin, Huibin and Liang, Xiaolin and Gulliver, Thomas Aaron},
TITLE = {An Improved Unauthorized Unmanned Aerial Vehicle Detection Algorithm Using Radiofrequency-Based Statistical Fingerprint Analysis},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {274},
URL = {https://www.mdpi.com/1424-8220/19/2/274},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles (UAVs) are now readily available worldwide and users can easily fly them remotely using smart controllers. This has created the problem of keeping unauthorized UAVs away from private or sensitive areas where they can be a personal or public threat. This paper proposes an improved radio frequency (RF)-based method to detect UAVs. The clutter (interference) is eliminated using a background filtering method. Then singular value decomposition (SVD) and average filtering are used to reduce the noise and improve the signal to noise ratio (SNR). Spectrum accumulation (SA) and statistical fingerprint analysis (SFA) are employed to provide two frequency estimates. These estimates are used to determine if a UAV is present in the detection environment. The data size is reduced using a region of interest (ROI), and this improves the system efficiency and improves azimuth estimation accuracy. Detection results are obtained using real UAV RF signals obtained experimentally which show that the proposed method is more effective than other well-known detection algorithms. The recognition rate with this method is close to 100% within a distance of 2.4 km and greater than 90% within a distance of 3 km. Further, multiple UAVs can be detected accurately using the proposed method.},
DOI = {10.3390/s19020274}
}



@Article{s19020275,
AUTHOR = {Chen, Xi and Kopsaftopoulos, Fotis and Wu, Qi and Ren, He and Chang, Fu-Kuo},
TITLE = {A Self-Adaptive 1D Convolutional Neural Network for Flight-State Identification},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {275},
URL = {https://www.mdpi.com/1424-8220/19/2/275},
ISSN = {1424-8220},
ABSTRACT = {The vibration of a wing structure in the air reflects coupled aerodynamic&ndash;mechanical responses under varying flight states that are defined by the angle of attack and airspeed. It is of great challenge to identify the flight state from the complex vibration signals. In this paper, a novel one-dimension convolutional neural network (CNN) is developed, which is able to automatically extract useful features from the structural vibration of a recently fabricated self-sensing wing through wind-tunnel experiments. The obtained signals are firstly decomposed into various subsignals with different frequency bands via dual-tree complex-wavelet packet transformation. Then, the reconstructed subsignals are selected to form the best combination for multichannel inputs of the CNN. A swarm-based evolutionary algorithm called grey-wolf optimizer is utilized to optimize a set of key parameters of the CNN, which saves considerable human efforts. Two case studies demonstrate the high identification accuracy and robustness of the proposed method over standard deep-learning methods in flight-state identification, thus providing new perspectives in self-awareness toward the next generation of intelligent air vehicles.},
DOI = {10.3390/s19020275}
}



@Article{rs11020135,
AUTHOR = {Shi, Xiaoran and Zhou, Feng and Yang, Shuang and Zhang, Zijing and Su, Tao},
TITLE = {Automatic Target Recognition for Synthetic Aperture Radar Images Based on Super-Resolution Generative Adversarial Network and Deep Convolutional Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {135},
URL = {https://www.mdpi.com/2072-4292/11/2/135},
ISSN = {2072-4292},
ABSTRACT = {Aiming at the problem of the difficulty of high-resolution synthetic aperture radar (SAR) image acquisition and poor feature characterization ability of low-resolution SAR image, this paper proposes a method of an automatic target recognition method for SAR images based on a super-resolution generative adversarial network (SRGAN) and deep convolutional neural network (DCNN). First, the threshold segmentation is utilized to eliminate the SAR image background clutter and speckle noise and accurately extract target area of interest. Second, the low-resolution SAR image is enhanced through SRGAN to improve the visual resolution and the feature characterization ability of target in the SAR image. Third, the automatic classification and recognition for SAR image is realized by using DCNN with good generalization performance. Finally, the open data set, moving and stationary target acquisition and recognition, is utilized and good recognition results are obtained under standard operating condition and extended operating conditions, which verify the effectiveness, robustness, and good generalization performance of the proposed method.},
DOI = {10.3390/rs11020135}
}



@Article{app9020261,
AUTHOR = {Maldonado-Ramírez, Angel Alejandro and Torres-Méndez, Luz Abril},
TITLE = {A Collaborative Human-Robot Framework for Visual Topological Mapping of Coral Reefs},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {261},
URL = {https://www.mdpi.com/2076-3417/9/2/261},
ISSN = {2076-3417},
ABSTRACT = {One of the most important tasks when creating a map of visual information obtained from different agents is finding common locations between the sets of images that enable them to be fused into a single representation. Typical approaches focus on images obtained from the same agent. However, in this paper, we focus on recognizing the same places in images captured by different agents to create a topological map of coral reefs. The main components of the proposed method are the voting scheme to find a sparse similarity matrix between different frames and an effective method to match sequences of images exploiting the sparsity of the resulting similarity matrix. We have applied our method to sequences of images obtained from coral reef explorations performed by different agents. The presented method shows a good performance compared to other well-established methods such as FABMAP. This demonstrates its ability to find common locations from visual information gathered from different sources, which eases the collaboration between humans and robots to map the environment.},
DOI = {10.3390/app9020261}
}



@Article{rs11020145,
AUTHOR = {Zhuo, Xiangyu and Fraundorfer, Friedrich and Kurz, Franz and Reinartz, Peter},
TITLE = {Automatic Annotation of Airborne Images by Label Propagation Based on a Bayesian-CRF Model},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {145},
URL = {https://www.mdpi.com/2072-4292/11/2/145},
ISSN = {2072-4292},
ABSTRACT = {The tremendous advances in deep neural networks have demonstrated the superiority of deep learning techniques for applications such as object recognition or image classification. Nevertheless, deep learning-based methods usually require a large amount of training data, which mainly comes from manual annotation and is quite labor-intensive. In order to reduce the amount of manual work required for generating enough training data, we hereby propose to leverage existing labeled data to generate image annotations automatically. Specifically, the pixel labels are firstly transferred from one image modality to another image modality via geometric transformation to create initial image annotations, and then additional information (e.g., height measurements) is incorporated for Bayesian inference to update the labeling beliefs. Finally, the updated label assignments are optimized with a fully connected conditional random field (CRF), yielding refined labeling for all pixels in the image. The proposed approach is tested on two different scenarios, i.e., (1) label propagation from annotated aerial imagery to unmanned aerial vehicle (UAV) imagery and (2) label propagation from map database to aerial imagery. In each scenario, the refined image labels are used as pseudo-ground truth data for training a convolutional neural network (CNN). Results demonstrate that our model is able to produce accurate label assignments even around complex object boundaries; besides, the generated image labels can be effectively leveraged for training CNNs and achieve comparable classification accuracy as manual image annotations, more specifically, the per-class classification accuracy of the networks trained by the manual image annotations and the generated image labels have a difference within     &plusmn; 5 %    .},
DOI = {10.3390/rs11020145}
}



@Article{s19020301,
AUTHOR = {Song, Wenzhan and Li, Fangyu and Valero, Maria and Zhao, Liang},
TITLE = {Toward Creating a Subsurface Camera},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {301},
URL = {https://www.mdpi.com/1424-8220/19/2/301},
ISSN = {1424-8220},
ABSTRACT = {In this article, the framework and architecture of a Subsurface Camera (SAMERA) are envisioned and described for the first time. A SAMERA is a geophysical sensor network that senses and processes geophysical sensor signals and computes a 3D subsurface image in situ in real time. The basic mechanism is geophysical waves propagating/reflected/refracted through subsurface enter a network of geophysical sensors, where a 2D or 3D image is computed and recorded; control software may be connected to this network to allow view of the 2D/3D image and adjustment of settings such as resolution, filter, regularization, and other algorithm parameters. System prototypes based on seismic imaging have been designed. SAMERA technology is envisioned as a game changer to transform many subsurface survey and monitoring applications, including oil/gas exploration and production, subsurface infrastructures and homeland security, wastewater and CO2 sequestration, and earthquake and volcano hazard monitoring. System prototypes for seismic imaging have been built. Creating SAMERA requires interdisciplinary collaboration and the transformation of sensor networks, signal processing, distributed computing, and geophysical imaging.},
DOI = {10.3390/s19020301}
}



@Article{s19020312,
AUTHOR = {Giernacki, Wojciech and Horla, Dariusz and Báča, Tomáš and Saska, Martin},
TITLE = {Real-Time Model-Free Minimum-Seeking Autotuning Method for Unmanned Aerial Vehicle Controllers Based on Fibonacci-Search Algorithm},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {312},
URL = {https://www.mdpi.com/1424-8220/19/2/312},
ISSN = {1424-8220},
ABSTRACT = {The paper presents a novel autotuning approach for finding locally-best parameters of controllers on board of unmanned aerial vehicles (UAVs). The controller tuning is performed fully autonomously during flight on the basis of predefined ranges of controller parameters. Required controller properties may be simply interpreted by a cost function, which is involved in the optimization process. For example, the sum of absolute values of the tracking error samples or performance indices, including weighed functions of control signal samples, can be penalized to achieve very precise position control, if required. The proposed method relies on an optimization procedure using Fibonacci-search technique fitted into bootstrap sequences, enabling one to obtain a global minimizer for a unimodal cost function. The approach is characterized by low computational complexity and does not require any UAV dynamics model (just periodical measurements from basic onboard sensors) to obtain proper tuning of a controller. In addition to the theoretical background of the method, an experimental verification in real-world outdoor conditions is provided. The experiments have demonstrated a high robustness of the method to in-environment disturbances, such as wind, and its easy deployability.},
DOI = {10.3390/s19020312}
}



@Article{s19020313,
AUTHOR = {Gao, Pengbo and Zhang, Yan and Zhang, Linhuan and Noguchi, Ryozo and Ahamed, Tofael},
TITLE = {Development of a Recognition System for Spraying Areas from Unmanned Aerial Vehicles Using a Machine Learning Approach},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {313},
URL = {https://www.mdpi.com/1424-8220/19/2/313},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicle (UAV)-based spraying systems have recently become important for the precision application of pesticides, using machine learning approaches. Therefore, the objective of this research was to develop a machine learning system that has the advantages of high computational speed and good accuracy for recognizing spray and non-spray areas for UAV-based sprayers. A machine learning system was developed by using the mutual subspace method (MSM) for images collected from a UAV. Two target lands: agricultural croplands and orchard areas, were considered in building two classifiers for distinguishing spray and non-spray areas. The field experiments were conducted in target areas to train and test the system by using a commercial UAV (DJI Phantom 3 Pro) with an onboard 4K camera. The images were collected from low (5 m) and high (15 m) altitudes for croplands and orchards, respectively. The recognition system was divided into offline and online systems. In the offline recognition system, 74.4% accuracy was obtained for the classifiers in recognizing spray and non-spray areas for croplands. In the case of orchards, the average classifier recognition accuracy of spray and non-spray areas was 77%. On the other hand, the online recognition system performance had an average accuracy of 65.1% for croplands, and 75.1% for orchards. The computational time for the online recognition system was minimal, with an average of 0.0031 s for classifier recognition. The developed machine learning system had an average recognition accuracy of 70%, which can be implemented in an autonomous UAV spray system for recognizing spray and non-spray areas for real-time applications.},
DOI = {10.3390/s19020313}
}



@Article{ijgi8010028,
AUTHOR = {Feng, Quanlong and Zhu, Dehai and Yang, Jianyu and Li, Baoguo},
TITLE = {Multisource Hyperspectral and LiDAR Data Fusion for Urban Land-Use Mapping based on a Modified Two-Branch Convolutional Neural Network},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {8},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {28},
URL = {https://www.mdpi.com/2220-9964/8/1/28},
ISSN = {2220-9964},
ABSTRACT = {Accurate urban land-use mapping is a challenging task in the remote-sensing field. With the availability of diverse remote sensors, synthetic use and integration of multisource data provides an opportunity for improving urban land-use classification accuracy. Neural networks for Deep Learning have achieved very promising results in computer-vision tasks, such as image classification and object detection. However, the problem of designing an effective deep-learning model for the fusion of multisource remote-sensing data still remains. To tackle this issue, this paper proposes a modified two-branch convolutional neural network for the adaptive fusion of hyperspectral imagery (HSI) and Light Detection and Ranging (LiDAR) data. Specifically, the proposed model consists of a HSI branch and a LiDAR branch, sharing the same network structure to reduce the time cost of network design. A residual block is utilized in each branch to extract hierarchical, parallel, and multiscale features. An adaptive-feature fusion module is proposed to integrate HSI and LiDAR features in a more reasonable and natural way (based on &ldquo;Squeeze-and-Excitation Networks&rdquo;). Experiments indicate that the proposed two-branch network shows good performance, with an overall accuracy of almost 92%. Compared with single-source data, the introduction of multisource data improves accuracy by at least 8%. The adaptive fusion model can also increase classification accuracy by more than 3% when compared with the feature-stacking method (simple concatenation). The results demonstrate that the proposed network can effectively extract and fuse features for a better urban land-use mapping accuracy.},
DOI = {10.3390/ijgi8010028}
}



@Article{ijgi8010039,
AUTHOR = {Li, Zhiqiang and Cheng, Chengqi and Kwan, Mei-Po and Tong, Xiaochong and Tian, Shaohong},
TITLE = {Identifying Asphalt Pavement Distress Using UAV LiDAR Point Cloud Data and Random Forest Classification},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {8},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {39},
URL = {https://www.mdpi.com/2220-9964/8/1/39},
ISSN = {2220-9964},
ABSTRACT = {Asphalt pavement ages and incurs various distresses due to natural and human factors. Thus, it is crucial to rapidly and accurately extract different types of pavement distress to effectively monitor road health status. In this study, we explored the feasibility of pavement distress identification using low-altitude unmanned aerial vehicle light detection and ranging (UAV LiDAR) and random forest classification (RFC) for a section of an asphalt road that is located in the suburb of Shihezi City in Xinjiang Province of China. After a spectral and spatial feature analysis of pavement distress, a total of 48 multidimensional and multiscale features were extracted based on the strength of the point cloud elevations and reflection intensities. Subsequently, we extracted the pavement distresses from the multifeature dataset by utilizing the RFC method. The overall accuracy of the distress identification was 92.3%, and the kappa coefficient was 0.902. When compared with the maximum likelihood classification (MLC) and support vector machine (SVM), the RFC had a higher accuracy, which confirms its robustness and applicability to multisample and high-dimensional data classification. Furthermore, the method achieved an overall accuracy of 95.86% with a validation dataset. This result indicates the validity and stability of our method, which highway maintenance agencies can use to evaluate road health conditions and implement maintenance.},
DOI = {10.3390/ijgi8010039}
}



@Article{s19020387,
AUTHOR = {Du, Ming and Ding, Yan and Meng, Xiuyun and Wei, Hua-Liang and Zhao, Yifan},
TITLE = {Distractor-Aware Deep Regression for Visual Tracking},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {387},
URL = {https://www.mdpi.com/1424-8220/19/2/387},
ISSN = {1424-8220},
ABSTRACT = {In recent years, regression trackers have drawn increasing attention in the visual-object tracking community due to their favorable performance and easy implementation. The tracker algorithms directly learn mapping from dense samples around the target object to Gaussian-like soft labels. However, in many real applications, when applied to test data, the extreme imbalanced distribution of training samples usually hinders the robustness and accuracy of regression trackers. In this paper, we propose a novel effective distractor-aware loss function to balance this issue by highlighting the significant domain and by severely penalizing the pure background. In addition, we introduce a full differentiable hierarchy-normalized concatenation connection to exploit abstractions across multiple convolutional layers. Extensive experiments were conducted on five challenging benchmark-tracking datasets, that is, OTB-13, OTB-15, TC-128, UAV-123, and VOT17. The experimental results are promising and show that the proposed tracker performs much better than nearly all the compared state-of-the-art approaches.},
DOI = {10.3390/s19020387}
}



@Article{f10010072,
AUTHOR = {Uribe-Toril, Juan and Ruiz-Real, José Luis and Haba-Osca, Julia and de Pablo Valenciano, Jaime},
TITLE = {Forests’ First Decade: A Bibliometric Analysis Overview},
JOURNAL = {Forests},
VOLUME = {10},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {72},
URL = {https://www.mdpi.com/1999-4907/10/1/72},
ISSN = {1999-4907},
ABSTRACT = {Forests is a Swiss open access journal in the field of forestry and forest ecology founded in 2010. Currently, the journal celebrates its 10th anniversary. Therefore, the purpose of this research for the special issue A Decade of Forests Open Access Publishing is to present a whole bibliometric overview of the journal and highlight the state of the art of forestry as an interdisciplinary knowledge area. A bibliometric analysis of 2094 articles, reviews, editorials and corrections was conducted using two different scientific information platforms which publish indexes in online databases: Web of Science (WoS) and Scopus. The most influential countries and their relationship with funding institutions, the most leading and outstanding authors and the most significant articles published in Forests have been analyzed. A complete keyword concurrence network with a graphical visualization and a cluster analysis are adopted for identifying the main trends and opening issues to address in the coming decade, such as genetic diversity, forest productivity, resistance or resilience. This article has identified climate change, remote sensing, biomass and forest management as the main trends in forestry research during the last ten years.},
DOI = {10.3390/f10010072}
}



@Article{ijgi8010049,
AUTHOR = {Liu, Wei and Cheng, Dayu and Yin, Pengcheng and Yang, Mengyuan and Li, Erzhu and Xie, Meng and Zhang, Lianpeng},
TITLE = {Small Manhole Cover Detection in Remote Sensing Imagery with Deep Convolutional Neural Networks},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {8},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {49},
URL = {https://www.mdpi.com/2220-9964/8/1/49},
ISSN = {2220-9964},
ABSTRACT = {With the development of remote sensing technology and the advent of high-resolution images, obtaining data has become increasingly convenient. However, the acquisition of small manhole cover information still has shortcomings including low efficiency of manual surveying and high leakage rate. Recently, deep learning models, especially deep convolutional neural networks (DCNNs), have proven to be effective at object detection. However, several challenges limit the applications of DCNN in manhole cover object detection using remote sensing imagery: (1) Manhole cover objects often appear at different scales in remotely sensed images and DCNNs&rsquo; fixed receptive field cannot match the scale variability of such objects; (2) Manhole cover objects in large-scale remotely-sensed images are relatively small in size and densely packed, while DCNNs have poor localization performance when applied to such objects. To address these problems, we propose an effective method for detecting manhole cover objects in remotely-sensed images. First, we redesign the feature extractor by adopting the visual geometry group (VGG), which can increase the variety of receptive field size. Then, detection is performed using two sub-networks: a multi-scale output network (MON) for manhole cover object-like edge generation from several intermediate layers whose receptive fields match different object scales and a multi-level convolution matching network (M-CMN) for object detection based on fused feature maps, which combines several feature maps that enable small and densely packed manhole cover objects to produce a stronger response. The results show that our method is more accurate than existing methods at detecting manhole covers in remotely-sensed images.},
DOI = {10.3390/ijgi8010049}
}



@Article{sym11010118,
AUTHOR = {Lynskey, Jared and Thar, Kyi and Oo, Thant Zin and Hong, Choong Seon},
TITLE = {Facility Location Problem Approach for Distributed Drones},
JOURNAL = {Symmetry},
VOLUME = {11},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {118},
URL = {https://www.mdpi.com/2073-8994/11/1/118},
ISSN = {2073-8994},
ABSTRACT = {Currently, industry and academia are undergoing an evolution in developing the next generation of drone applications. Including the development of autonomous drones that can carry out tasks without the assistance of a human operator. In spite of this, there are still problems left unanswered related to the placement of drone take-off, landing and charging areas. Future policies by governments and aviation agencies are inevitably going to restrict the operational area where drones can take-off and land. Hence, there is a need to develop a system to manage landing and take-off areas for drones. Additionally, we proposed this approach due to the lack of justification for the initial location of drones in current research. Therefore, to provide a foundation for future research, we give a justified reason that allows predetermined location of drones with the use of drone ports. Furthermore, we propose an algorithm to optimally place these drone ports to minimize the average distance drones must travel based on a set of potential drone port locations and tasks generated in a given area. Our approach is derived from the Facility Location problem which produces an efficient near optimal solution to place drone ports that reduces the overall drone energy consumption. Secondly, we apply various traveling salesman algorithms to determine the shortest route the drone must travel to visit all the tasks.},
DOI = {10.3390/sym11010118}
}



@Article{s19020413,
AUTHOR = {Itakura, Kenta and Kamakura, Itchoku and Hosoi, Fumiki},
TITLE = {Three-Dimensional Monitoring of Plant Structural Parameters and Chlorophyll Distribution},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {413},
URL = {https://www.mdpi.com/1424-8220/19/2/413},
ISSN = {1424-8220},
ABSTRACT = {Image analysis is widely used for accurate and efficient plant monitoring. Plants have complex three-dimensional (3D) structures; hence, 3D image acquisition and analysis is useful for determining the status of plants. Here, 3D images of plants were reconstructed using a photogrammetric approach, called &ldquo;structure from motion&rdquo;. Chlorophyll content is an important parameter that determines the status of plants. Chlorophyll content was estimated from 3D images of plants with color information. To observe changes in the chlorophyll content and plant structure, a potted plant was kept for five days under a water stress condition and its 3D images were taken once a day. As a result, the normalized Red value and the chlorophyll content were correlated; a high R2 value (0.81) was obtained. The absolute error of the chlorophyll content estimation in cross-validation studies was 4.0 &times; 10&minus;2 &mu;g/mm2. At the same time, the structural parameters (i.e., the leaf inclination angle and the azimuthal angle) were calculated by simultaneously monitoring the changes in the plant&rsquo;s status in terms of its chlorophyll content and structural parameters. By combining these parameters related to plant information in plant image analysis, early detection of plant stressors, such as water stress, becomes possible.},
DOI = {10.3390/s19020413}
}



@Article{rs11030224,
AUTHOR = {Franceschini, Marston Héracles Domingues and Bartholomeus, Harm and van Apeldoorn, Dirk Frederik and Suomalainen, Juha and Kooistra, Lammert},
TITLE = {Feasibility of Unmanned Aerial Vehicle Optical Imagery for Early Detection and Severity Assessment of Late Blight in Potato},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {224},
URL = {https://www.mdpi.com/2072-4292/11/3/224},
ISSN = {2072-4292},
ABSTRACT = {Assessment of disease incidence and severity at farm scale or in agronomic trials is frequently performed based on visual crop inspection, which is a labor intensive task prone to errors associated with its subjectivity. Therefore, alternative methods to relate disease incidence and severity with changes in crop traits are of great interest. Optical imagery in the visible and near-infrared (Vis-NIR) can potentially be used to detect changes in crop traits caused by pathogen development. Also, cameras on-board of Unmanned Aerial Vehicles (UAVs) have flexible data collection capabilities allowing adjustments considering the trade-off between data throughput and its resolution. However, studies focusing on the use of UAV imagery to describe changes in crop traits related to disease infection are still lacking. More specifically, evaluation of late blight (Phytophthora infestans) incidence in potato concerning early discrimination of different disease severity levels has not been extensively reported. In this article, the description of spectral changes related to the development of potato late blight under low disease severity levels is performed using sub-decimeter UAV optical imagery. The main objective was to evaluate the sensitivity of the data acquired regarding early changes in crop traits related to disease incidence. For that, UAV images were acquired on four dates during the growing season (from 37 to 78 days after planting), before and after late blight was detected in the field. The spectral variability observed in each date was summarized using Simplex Volume Maximization (SiVM), and its relationship with experimental treatments (different crop systems) and disease severity levels (evaluated by visual assessment) was determined based on pixel-wise log-likelihood ratio (LLR) calculation. Using this analytical framework it was possible to identify considerable spectral changes related to late blight incidence in different treatments and also to disease severity level as low as between 2.5 and 5.0% of affected leaf area. Comparison of disease incidence and spectral information acquired using UAV (with 4&ndash;5 cm of spatial resolution) and ground-based imagery (with 0.1&ndash;0.2 cm of spatial resolution) indicate that UAV data allowed identification of patterns comparable to those described by ground-based images, despite some differences concerning the distribution of affected areas detected within the sampling units and an attenuation in the signal measured. Finally, although aggregated information at sampling unit level provided discriminative potential for higher levels of disease development, focusing on spectral information related to disease occurrence increased the discriminative potential of the data acquired.},
DOI = {10.3390/rs11030224}
}



@Article{rs11030230,
AUTHOR = {Pham, Tien Dat and Yokoya, Naoto and Bui, Dieu Tien and Yoshino, Kunihiko and Friess, Daniel A.},
TITLE = {Remote Sensing Approaches for Monitoring Mangrove Species, Structure, and Biomass: Opportunities and Challenges},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {230},
URL = {https://www.mdpi.com/2072-4292/11/3/230},
ISSN = {2072-4292},
ABSTRACT = {The mangrove ecosystem plays a vital role in the global carbon cycle, by reducing greenhouse gas emissions and mitigating the impacts of climate change. However, mangroves have been lost worldwide, resulting in substantial carbon stock losses. Additionally, some aspects of the mangrove ecosystem remain poorly characterized compared to other forest ecosystems due to practical difficulties in measuring and monitoring mangrove biomass and their carbon stocks. Without a quantitative method for effectively monitoring biophysical parameters and carbon stocks in mangroves, robust policies and actions for sustainably conserving mangroves in the context of climate change mitigation and adaptation are more difficult. In this context, remote sensing provides an important tool for monitoring mangroves and identifying attributes such as species, biomass, and carbon stocks. A wide range of studies is based on optical imagery (aerial photography, multispectral, and hyperspectral) and synthetic aperture radar (SAR) data. Remote sensing approaches have been proven effective for mapping mangrove species, estimating their biomass, and assessing changes in their extent. This review provides an overview of the techniques that are currently being used to map various attributes of mangroves, summarizes the studies that have been undertaken since 2010 on a variety of remote sensing applications for monitoring mangroves, and addresses the limitations of these studies. We see several key future directions for the potential use of remote sensing techniques combined with machine learning techniques for mapping mangrove areas and species, and evaluating their biomass and carbon stocks.},
DOI = {10.3390/rs11030230}
}



@Article{rs11030233,
AUTHOR = {Puliti, Stefano and Solberg, Svein and Granhus, Aksel},
TITLE = {Use of UAV Photogrammetric Data for Estimation of Biophysical Properties in Forest Stands Under Regeneration},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {233},
URL = {https://www.mdpi.com/2072-4292/11/3/233},
ISSN = {2072-4292},
ABSTRACT = {The objective of this study was to assess the use of unmanned aerial vehicle (UAV) data for modelling tree density and canopy height in young boreal forests stands. The use of UAV data for such tasks can be beneficial thanks to the high resolution and reduction of the time spent in the field. This study included 29 forest stands, within which 580 clustered plots were measured in the field. An area-based approach was adopted to which random forest models were fitted using the plot data and the corresponding UAV data and then applied and validated at plot and stand level. The results were compared to those of models based on airborne laser scanning (ALS) data and those from a traditional field-assessment. The models based on UAV data showed the smallest stand-level     R M S E     values for mean height (0.56 m) and tree density (1175 trees ha&minus;1). The     R M S E     of the tree density using UAV data was 50% smaller than what was obtained using ALS data (2355 trees ha&minus;1). Overall, this study highlighted that the use of UAVs for the inventory of forest stands under regeneration can be beneficial both because of the high accuracy of the derived data analytics and the time saving compared to traditional field assessments.},
DOI = {10.3390/rs11030233}
}



@Article{s19030467,
AUTHOR = {Macoir, Nicola and Bauwens, Jan and Jooris, Bart and Van Herbruggen, Ben and Rossey, Jen and Hoebeke, Jeroen and De Poorter , Eli},
TITLE = {UWB Localization with Battery-Powered Wireless Backbone for Drone-Based Inventory Management},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {467},
URL = {https://www.mdpi.com/1424-8220/19/3/467},
ISSN = {1424-8220},
ABSTRACT = {Current inventory-taking methods (counting stocks and checking correct placements) in large vertical warehouses are mostly manual, resulting in (i) large personnel costs, (ii) human errors and (iii) incidents due to working at large heights. To remedy this, the use of autonomous indoor drones has been proposed. However, these drones require accurate localization solutions that are easy to (temporarily) install at low costs in large warehouses. To this end, we designed a Ultra-Wideband (UWB) solution that uses infrastructure anchor nodes that do not require any wired backbone and can be battery powered. The resulting system has a theoretical update rate of up to 2892 Hz (assuming no hardware dependent delays). Moreover, the anchor nodes have an average current consumption of only 27 mA (compared to 130 mA of traditional UWB infrastructure nodes). Finally, the system has been experimentally validated and is available as open-source software.},
DOI = {10.3390/s19030467}
}



@Article{e21020106,
AUTHOR = {He, Qingfeng and Xu, Zhihao and Li, Shaojun and Li, Renwei and Zhang, Shuai and Wang, Nianqin and Pham, Binh Thai and Chen, Wei},
TITLE = {Novel Entropy and Rotation Forest-Based Credal Decision Tree Classifier for Landslide Susceptibility Modeling},
JOURNAL = {Entropy},
VOLUME = {21},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {106},
URL = {https://www.mdpi.com/1099-4300/21/2/106},
ISSN = {1099-4300},
ABSTRACT = {Landslides are a major geological hazard worldwide. Landslide susceptibility assessments are useful to mitigate human casualties, loss of property, and damage to natural resources, ecosystems, and infrastructures. This study aims to evaluate landslide susceptibility using a novel hybrid intelligence approach with the rotation forest-based credal decision tree (RF-CDT) classifier. First, 152 landslide locations and 15 landslide conditioning factors were collected from the study area. Then, these conditioning factors were assigned values using an entropy method and subsequently optimized using correlation attribute evaluation (CAE). Finally, the performance of the proposed hybrid model was validated using the receiver operating characteristic (ROC) curve and compared with two well-known ensemble models, bagging (bag-CDT) and MultiBoostAB (MB-CDT). Results show that the proposed RF-CDT model had better performance than the single CDT model and hybrid bag-CDT and MB-CDT models. The findings in the present study overall confirm that a combination of the meta model with a decision tree classifier could enhance the prediction power of the single landslide model. The resulting susceptibility maps could be effective for enforcement of land management regulations to reduce landslide hazards in the study area and other similar areas in the world.},
DOI = {10.3390/e21020106}
}



@Article{s19030484,
AUTHOR = {Tuyishimire, Emmanuel and Bagula, Antoine and Ismail, Adiel},
TITLE = {Clustered Data Muling in the Internet of Things in Motion},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {484},
URL = {https://www.mdpi.com/1424-8220/19/3/484},
ISSN = {1424-8220},
ABSTRACT = {This paper considers a case where an Unmanned Aerial Vehicle (UAV) is used to monitor an area of interest. The UAV is assisted by a Sensor Network (SN), which is deployed in the area such as a smart city or smart village. The area being monitored has a reasonable size and hence may contain many sensors for efficient and accurate data collection. In this case, it would be expensive for one UAV to visit all the sensors; hence the need to partition the ground network into an optimum number of clusters with the objective of having the UAV visit only cluster heads (fewer sensors). In such a setting, the sensor readings (sensor data) would be sent to cluster heads where they are collected by the UAV upon its arrival. This paper proposes a clustering scheme that optimizes not only the sensor network energy usage, but also the energy used by the UAV to cover the area of interest. The computation of the number of optimal clusters in a dense and uniformly-distributed sensor network is proposed to complement the k-means clustering algorithm when used as a network engineering technique in hybrid UAV/terrestrial networks. Furthermore, for general networks, an efficient clustering model that caters for both orphan nodes and multi-layer optimization is proposed and analyzed through simulations using the city of Cape Town in South Africa as a smart city hybrid network engineering use-case.},
DOI = {10.3390/s19030484}
}



@Article{electronics8020129,
AUTHOR = {Memon, Mudasar Latif and Saxena, Navrati and Roy, Abhishek and Shin, Dong Ryeol},
TITLE = {Backscatter Communications: Inception of the Battery-Free Era—A Comprehensive Survey},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {129},
URL = {https://www.mdpi.com/2079-9292/8/2/129},
ISSN = {2079-9292},
ABSTRACT = {The ever increasing proliferation of wireless objects and consistent connectivity demands are creating significant challenges for battery-constrained wireless devices. The vision of massive IoT, involving billions of smart objects to be connected to the cellular network, needs to address the problem of uninterrupted power consumption while taking advantage of emerging high-frequency 5G communications. The problem of limited battery power motivates us to utilize radio frequency (RF) signals as the energy source for battery-free communications in next-generation wireless networks. Backscatter communication (BackCom) makes it possible to harvest energy from incident RF signals and reflect back parts of the same signals while modulating the data. Ambient BackCom (Amb-BackCom) is a type of BackCom that can harvest energy from nearby WiFi, TV, and cellular RF signals to modulate information. The objective of this article is to review BackCom as a solution to the limited battery life problem and enable future battery-free communications for combating the energy issues for devices in emerging wireless networks. We first highlight the energy constraint in existing wireless communications. We then investigate BackCom as a practical solution to the limited battery life problem. Subsequently, in order to take the advantages of omnipresent radio waves, we elaborate BackCom tag architecture and various types of BackCom. To understand encoding and data extraction, we demonstrate signal processing aspects that cover channel coding, interference, decoding, and signal detection schemes. Moreover, we also describe BackCom communication modes, modulation schemes, and multiple access techniques to accommodate maximum users with high throughput. Similarly, to mitigate the increased network energy, adequate data and power transfer schemes for BackCom are elaborated, in addition to reliability, security, and range extension. Finally, we highlight BackCom applications with existing research challenges and future directions for next-generation 5G wireless networks.},
DOI = {10.3390/electronics8020129}
}



@Article{rs11030249,
AUTHOR = {Rasti, Pejman and Ahmad, Ali and Samiei, Salma and Belin, Etienne and Rousseau, David},
TITLE = {Supervised Image Classification by Scattering Transform with Application to Weed Detection in Culture Crops of High Density},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {249},
URL = {https://www.mdpi.com/2072-4292/11/3/249},
ISSN = {2072-4292},
ABSTRACT = {In this article, we assess the interest of the recently introduced multiscale scattering transform for texture classification applied for the first time in plant science. Scattering transform is shown to outperform monoscale approaches (gray-level co-occurrence matrix, local binary patterns) but also multiscale approaches (wavelet decomposition) which do not include combinatory steps. The regime in which scatter transform also outperforms a standard CNN architecture in terms of data-set size is evaluated (    10 4     instances). An approach on how to optimally design the scatter transform based on energy contrast is provided. This is illustrated on the hard and open problem of weed detection in culture crops of high density from the top view in intensity images. An annotated synthetic data-set available under the form of a data challenge and a simulator are proposed for reproducible science. Scatter transform only trained on synthetic data shows an accuracy of     85 %     when tested on real data.},
DOI = {10.3390/rs11030249}
}



@Article{agronomy9020054,
AUTHOR = {Grüner, Esther and Astor, Thomas and Wachendorf, Michael},
TITLE = {Biomass Prediction of Heterogeneous Temperate Grasslands Using an SfM Approach Based on UAV Imaging},
JOURNAL = {Agronomy},
VOLUME = {9},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {54},
URL = {https://www.mdpi.com/2073-4395/9/2/54},
ISSN = {2073-4395},
ABSTRACT = {An early and precise yield estimation in intensive managed grassland is mandatory for economic management decisions. RGB (red, green, blue) cameras attached on an unmanned aerial vehicle (UAV) represent a promising non-destructive technology for the assessment of crop traits especially in large and remote areas. Photogrammetric structure from motion (SfM) processing of the UAV-based images into point clouds can be used to generate 3D spatial information about the canopy height (CH). The aim of this study was the development of prediction models for dry matter yield (DMY) in temperate grassland based on CH data generated by UAV RGB imaging over a whole growing season including four cuts. The multi-temporal study compared the remote sensing technique with two conventional methods, i.e., destructive biomass sampling and ruler height measurements in two legume-grass mixtures with red clover (Trifolium pratense L.) and lucerne (Medicago sativa L.) in combination with Italian ryegrass (Lolium multiflorum Lam.). To cover the full range of legume contribution occurring in a practical grassland, pure stands of legumes and grasses contained in each mixture were also investigated. The results showed, that yield prediction by SfM-based UAV RGB imaging provided similar accuracies across all treatments (R2 = 0.59&ndash;0.81) as the ruler height measurements (R2 = 0.58&ndash;0.78). Furthermore, results of yield prediction by UAV RGB imaging demonstrated an improved robustness when an increased CH variability occurred due to extreme weather conditions. It became apparent that morphological characteristics of clover-based canopies (R2 = 0.75) allow a better remotely sensed prediction of total annual yield than for lucerne-grass mixtures (R2 = 0.64), and that these crop-specific models cannot be easily transferred to other grassland types.},
DOI = {10.3390/agronomy9020054}
}



@Article{rs11030254,
AUTHOR = {Xu, Yi and Wang, Junjie and Xia, Anquan and Zhang, Kangyong and Dong, Xuanyan and Wu, Kaipeng and Wu, Guofeng},
TITLE = {Continuous Wavelet Analysis of Leaf Reflectance Improves Classification Accuracy of Mangrove Species},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {254},
URL = {https://www.mdpi.com/2072-4292/11/3/254},
ISSN = {2072-4292},
ABSTRACT = {Due to continuous degradation of mangrove forests, the accurate monitoring of spatial distribution and species composition of mangroves is essential for restoration, conservation and management of coastal ecosystems. With leaf hyperspectral reflectance, this study aimed to explore the potential of continuous wavelet analysis (CWA) combined with different sample subset partition (stratified random sampling (STRAT), Kennard-Stone sampling algorithm (KS), and sample subset partition based on joint X-Y distances (SPXY)) and feature extraction methods (principal component analysis (PCA), successive projections algorithm (SPA), and vegetation index (VI)) in mangrove species classification. A total of 301 mangrove leaf samples with four species (Avicennia marina, Bruguiera gymnorrhiza, Kandelia obovate and Aegiceras corniculatum) were collected across six different regions. The smoothed reflectance (Smth) and first derivative reflectance (Der) spectra were subjected to CWA using different wavelet scales, and a total of 270 random forest classification models were established and compared. Among the 120 models with CWA of Smth, 88.3% of models increased the overall accuracy (OA) values with an improvement of 0.2&ndash;28.6% compared to the model with the Smth spectra; among the 120 models with CWA of Der, 25.8% of models increased the OA values with an improvement of 0.1&ndash;11.4% compared to the model with the Der spectra. The model with CWA of Der at the scale of 23 coupling with STRAT and SPA achieved the best classification result (OA = 98.0%), while the best model with Smth and Der alone had OA values of 86.3% and 93.0%, respectively. Moreover, the models using STRAT outperformed those using KS and SPXY, and the models using PCA and SPA had better performances than those using VIs. We have concluded that CWA with suitable scales holds great potential in improving the classification accuracy of mangrove species, and that STRAT combined with the PCA or SPA method is also recommended to improve classification performance. These results may lay the foundation for further studies with UAV-acquired or satellite hyperspectral data, and the encouraging performance of CWA for mangrove species classification can also be extended to other plant species.},
DOI = {10.3390/rs11030254}
}



@Article{s19030528,
AUTHOR = {Kalatzis, Nikos and Routis, George and Marinellis, Yiorgos and Avgeris, Marios and Roussaki, Ioanna and Papavassiliou, Symeon and Anagnostou, Miltiades},
TITLE = {Semantic Interoperability for IoT Platforms in Support of Decision Making: An Experiment on Early Wildfire Detection},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {528},
URL = {https://www.mdpi.com/1424-8220/19/3/528},
ISSN = {1424-8220},
ABSTRACT = {One of the main obstacles towards the promotion of IoT adoption and innovation is data interoperability. Facilitating cross-domain interoperability is expected to be the core element for the realisation of the next generation of the IoT computing paradigm that is already taking shape under the name of Internet of Everything (IoE). In this article, an analysis of the current status on IoT semantic interoperability is presented that leads to the identification of a set of generic requirements that act as fundamental design principles for the specification of interoperability enabling solutions. In addition, an extension of NGSIv2 data model and API (de-facto) standards is proposed aiming to bridge the gap among IoT and social media and hence to integrate user communities with cyber-physical systems. These specifications have been utilised for the implementation of the IoT2Edge interoperability enabling mechanism which is evaluated within the context of a catastrophic wildfire incident that took place in Greece on July 2018. Weather data, social media activity, video recordings from the fire, sensor measurements and satellite data, linked to the location and the time of this fire incident have been collected, modeled in a uniform manner and fed to an early fire detection decision support system. The findings of the experiment certify that achieving minimum data interoperability with light-weight, plug-n-play mechanisms can be realised with significant benefits for our society.},
DOI = {10.3390/s19030528}
}



@Article{s19030542,
AUTHOR = {Syifa, Mutiara and Kadavi, Prima Riza and Lee, Chang-Wook},
TITLE = {An Artificial Intelligence Application for Post-Earthquake Damage Mapping in Palu, Central Sulawesi, Indonesia},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {542},
URL = {https://www.mdpi.com/1424-8220/19/3/542},
ISSN = {1424-8220},
ABSTRACT = {A Mw 7.4 earthquake hit Donggala County, Central Sulawesi Province, Indonesia, on 28 September 2018, triggering a tsunami and liquefaction in Palu City and Donggala. Around 2101 fatalities ensued and 68,451 houses were damaged by the earthquake. In light of this devastating event, a post-earthquake map is required to establish the first step in the evacuation and mitigation plan. In this study, remote sensing imagery from the Landsat-8 and Sentinel-2 satellites was used. Pre- and post-earthquake satellite images were classified using artificial neural network (ANN) and support vector machine (SVM) classifiers and processed using a decorrelation method to generate the post-earthquake damage map. The affected areas were compared to the field data, the percentage conformity between the ANN and SVM results was analyzed, and four post-earthquake damage maps were generated. Based on the conformity analysis, the Landsat-8 imagery (85.83%) was superior to that of Sentinel-2 (63.88%). The resulting post-earthquake damage map can be used to assess the distribution of seismic damage following the Palu earthquake and may be used to mitigate damage in the event of future earthquakes.},
DOI = {10.3390/s19030542}
}



@Article{rs11030261,
AUTHOR = {Domingo, Darío and Alonso, Rafael and Lamelas, María Teresa and Montealegre, Antonio Luis and Rodríguez, Francisco and de la Riva, Juan},
TITLE = {Temporal Transferability of Pine Forest Attributes Modeling Using Low-Density Airborne Laser Scanning Data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {261},
URL = {https://www.mdpi.com/2072-4292/11/3/261},
ISSN = {2072-4292},
ABSTRACT = {This study assesses model temporal transferability using airborne laser scanning (ALS) data acquired over two different dates. Seven forest attributes (i.e. stand density, basal area, squared mean diameter, dominant diameter, tree dominant height, timber volume, and total tree biomass) were estimated using an area-based approach in Mediterranean Aleppo pine forests. Low-density ALS data were acquired in 2011 and 2016 while 147 forest inventory plots were measured in 2013, 2014, and 2016. Single-tree growth models were used to generate concomitant field data for 2011 and 2016. A comparison of five selection techniques and five regression methods were performed to regress field observations against ALS metrics. The selection of the best regression models fitted for each stand attribute, and separately for both 2011 and 2016, was performed following an indirect approach. Model performance and temporal transferability were analyzed by extrapolating the best fitted models from 2011 to 2016 and inversely from 2016 to 2011 using the direct approach. Non-parametric support vector machine with radial kernel was the best regression method with average relative % root mean square error differences of 2.13% for 2011 models and 1.58% for 2016 ones.},
DOI = {10.3390/rs11030261}
}



@Article{rs11030272,
AUTHOR = {Mo, Nan and Yan, Li and Zhu, Ruixi and Xie, Hong},
TITLE = {Class-Specific Anchor Based and Context-Guided Multi-Class Object Detection in High Resolution Remote Sensing Imagery with a Convolutional Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {272},
URL = {https://www.mdpi.com/2072-4292/11/3/272},
ISSN = {2072-4292},
ABSTRACT = {In this paper, the problem of multi-scale geospatial object detection in High Resolution Remote Sensing Images (HRRSI) is tackled. The different flight heights, shooting angles and sizes of geographic objects in the HRRSI lead to large scale variance in geographic objects. The inappropriate anchor size to propose the objects and the indiscriminative ability of features for describing the objects are the main causes of missing detection and false detection in multi-scale geographic object detection. To address these challenges, we propose a class-specific anchor based and context-guided multi-class object detection method with a convolutional neural network (CNN), which can be divided into two parts: a class-specific anchor based region proposal network (RPN) and a discriminative feature with a context information classification network. A class-specific anchor block providing better initial values for RPN is proposed to generate the anchor of the most suitable scale for each category in order to increase the recall ratio. Meanwhile, we proposed to incorporate the context information into the original convolutional feature to improve the discriminative ability of the features and increase classification accuracy. Considering the quality of samples for classification, the soft filter is proposed to select effective boxes to improve the diversity of the samples for the classifier and avoid missing or false detection to some extent. We also introduced the focal loss in order to improve the classifier in classifying the hard samples. The proposed method is tested on a benchmark dataset of ten classes to prove the superiority. The proposed method outperforms some state-of-the-art methods with a mean average precision (mAP) of 90.4% and better detects the multi-scale objects, especially when objects show a minor shape change.},
DOI = {10.3390/rs11030272}
}



@Article{rs11030273,
AUTHOR = {Nichol, Caroline J. and Drolet, Guillaume and Porcar-Castell, Albert and Wade, Tom and Sabater, Neus and Middleton, Elizabeth M. and MacLellan, Chris and Levula, Janne and Mammarella, Ivan and Vesala, Timo and Atherton, Jon},
TITLE = {Diurnal and Seasonal Solar Induced Chlorophyll Fluorescence and Photosynthesis in a Boreal Scots Pine Canopy},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {273},
URL = {https://www.mdpi.com/2072-4292/11/3/273},
ISSN = {2072-4292},
ABSTRACT = {Solar induced chlorophyll fluorescence has been shown to be increasingly an useful proxy for the estimation of gross primary productivity (GPP), at a range of spatial scales. Here, we explore the seasonality in a continuous time series of canopy solar induced fluorescence (hereafter SiF) and its relation to canopy gross primary production (GPP), canopy light use efficiency (LUE), and direct estimates of leaf level photochemical efficiency in an evergreen canopy. SiF was calculated using infilling in two bands from the incoming and reflected radiance using a pair of Ocean Optics USB2000+ spectrometers operated in a dual field of view mode, sampling at a 30 min time step using custom written automated software, from early spring through until autumn in 2011. The optical system was mounted on a tower of 18 m height adjacent to an eddy covariance system, to observe a boreal forest ecosystem dominated by Scots pine. (Pinus sylvestris) A Walz MONITORING-PAM, multi fluorimeter system, was simultaneously mounted within the canopy adjacent to the footprint sampled by the optical system. Following correction of the SiF data for O2 and structural effects, SiF, SiF yield, LUE, the photochemicsl reflectance index (PRI), and the normalized difference vegetation index (NDVI) exhibited a seasonal pattern that followed GPP sampled by the eddy covariance system. Due to the complexities of solar azimuth and zenith angle (SZA) over the season on the SiF signal, correlations between SiF, SiF yield, GPP, and LUE were assessed on SZA &lt;50&deg; and under strictly clear sky conditions. Correlations found, even under these screened scenarios, resulted around ~r2 = 0.3. The diurnal responses of SiF, SiF yield, PAM estimates of effective quantum yield (&Delta;F/Fm&prime;), and meteorological parameters demonstrated some agreement over the diurnal cycle. The challenges inherent in SiF retrievals in boreal evergreen ecosystems are discussed.},
DOI = {10.3390/rs11030273}
}



@Article{ijgi8020068,
AUTHOR = {Zhu, Qing and Zhang, Junxiao and Ding, Yulin and Liu, Mingwei and Li, Yun and Feng, Bin and Miao, Shuangxi and Yang, Weijun and He, Huagui and Zhu, Jun},
TITLE = {Semantics-Constrained Advantageous Information Selection of Multimodal Spatiotemporal Data for Landslide Disaster Assessment},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {8},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {68},
URL = {https://www.mdpi.com/2220-9964/8/2/68},
ISSN = {2220-9964},
ABSTRACT = {Although abundant spatiotemporal data are collected before and after landslides, the volume, variety, intercorrelation, and heterogeneity of multimodal data complicates disaster assessments, so it is challenging to select information from multimodal spatiotemporal data that is advantageous for credible and comprehensive disaster assessment. In disaster scenarios, multimodal data exhibit intrinsic relationships, and their interactions can greatly influence selection results. Previous data retrieval methods have mainly focused on candidate ranking while ignoring the generation and evaluation of candidate subsets. In this paper, a semantic-constrained data selection approach is proposed. First, multitype relationships are defined and reasoned through the heterogeneous information network. Then, relevance, redundancy, and complementarity are redefined to evaluate data sets in terms of semantic proximity and similarity. Finally, the approach is tested using Mao County (China) landslide data. The proposed method can automatically and effectively generate suitable datasets for certain tasks rather than simply ranking by similarity, and the selection results are compared with manual results to verify their effectiveness.},
DOI = {10.3390/ijgi8020068}
}



@Article{rs11030278,
AUTHOR = {Kumbula, Samuel Takudzwa and Mafongoya, Paramu and Peerbhay, Kabir Yunus and Lottering, Romano Trent and Ismail, Riyad},
TITLE = {Using Sentinel-2 Multispectral Images to Map the Occurrence of the Cossid Moth (Coryphodema tristis) in Eucalyptus Nitens Plantations of Mpumalanga, South Africa},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {278},
URL = {https://www.mdpi.com/2072-4292/11/3/278},
ISSN = {2072-4292},
ABSTRACT = {Coryphodema tristis is a wood-boring insect, indigenous to South Africa, that has recently been identified as an emerging pest feeding on Eucalyptus nitens, resulting in extensive damage and economic loss. Eucalyptus plantations contributes over 9% to the total exported manufactured goods of South Africa which contributes significantly to the gross domestic product. Currently, the distribution extent of the Coryphodema tristis is unknown and estimated to infest Eucalyptus nitens compartments from less than 1% to nearly 80%, which is certainly a concern for the forestry sector related to the quantity and quality of yield produced. Therefore, the study sought to model the probability of occurrence of Coryphodema tristis on Eucalyptus nitens plantations in Mpumalanga, South Africa, using data from the Sentinel-2 multispectral instrument (MSI). Traditional field surveys were carried out through mass trapping in all compartments (n = 878) of Eucalyptus nitens plantations. Only 371 Eucalyptus nitens compartments were positively identified as infested and were used to generate the Coryphodema tristis presence data. Presence data and spectral features from the area were analysed using the Maxent algorithm. Model performance was evaluated using the receiver operating characteristics (ROC) curve showing the area under the curve (AUC) and True Skill Statistic (TSS) while the performance of predictors was analysed with the jack-knife. Validation of results were conducted using the test data. Using only the occurrence data and Sentinel-2 bands and derived vegetation indices, the Maxent model provided successful results, exhibiting an area under the curve (AUC) of 0.890. The Photosynthetic vigour ratio, Band 5 (Red edge 1), Band 4 (Red), Green NDVI hyper, Band 3 (Green) and Band 12 (SWIR 2) were identified as the most influential predictor variables. Results of this study suggest that remotely sensed derived vegetation indices from cost-effective platforms could play a crucial role in supporting forest pest management strategies and infestation control.},
DOI = {10.3390/rs11030278}
}



@Article{rs11030280,
AUTHOR = {Fu, Yongyong and Liu, Kunkun and Shen, Zhangquan and Deng, Jinsong and Gan, Muye and Liu, Xinguo and Lu, Dongming and Wang, Ke},
TITLE = {Mapping Impervious Surfaces in Town–Rural Transition Belts Using China’s GF-2 Imagery and Object-Based Deep CNNs},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {280},
URL = {https://www.mdpi.com/2072-4292/11/3/280},
ISSN = {2072-4292},
ABSTRACT = {Impervious surfaces play an important role in urban planning and sustainable environmental management. High-spatial-resolution (HSR) images containing pure pixels have significant potential for the detailed delineation of land surfaces. However, due to high intraclass variability and low interclass distance, the mapping and monitoring of impervious surfaces in complex town&ndash;rural areas using HSR images remains a challenge. The fully convolutional network (FCN) model, a variant of convolution neural networks (CNNs), recently achieved state-of-the-art performance in HSR image classification applications. However, due to the inherent nature of FCN processing, it is challenging for an FCN to precisely capture the detailed information of classification targets. To solve this problem, we propose an object-based deep CNN framework that integrates object-based image analysis (OBIA) with deep CNNs to accurately extract and estimate impervious surfaces. Specifically, we also adopted two widely used transfer learning technologies to expedite the training of deep CNNs. Finally, we compare our approach with conventional OBIA classification and state-of-the-art FCN-based methods, such as FCN-8s and the U-Net methods. Both of these FCN-based methods are well designed for pixel-wise classification applications and have achieved great success. Our results show that the proposed approach effectively identified impervious surfaces, with 93.9% overall accuracy. Compared with the existing methods, i.e., OBIA, FCN-8s and U-Net methods, it shows that our method achieves obviously improvement in accuracy. Our findings also suggest that the classification performance of our proposed method is related to training strategy, indicating that significantly higher accuracy can be achieved through transfer learning by fine-tuning rather than feature extraction. Our approach for the automatic extraction and mapping of impervious surfaces also lays a solid foundation for intelligent monitoring and the management of land use and land cover.},
DOI = {10.3390/rs11030280}
}



@Article{agronomy9020065,
AUTHOR = {Gebremedhin, Alem and Badenhorst, Pieter E. and Wang, Junping and Spangenberg, German C. and Smith, Kevin F.},
TITLE = {Prospects for Measurement of Dry Matter Yield in Forage Breeding Programs Using Sensor Technologies},
JOURNAL = {Agronomy},
VOLUME = {9},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {65},
URL = {https://www.mdpi.com/2073-4395/9/2/65},
ISSN = {2073-4395},
ABSTRACT = {Increasing the yield of perennial forage crops remains a crucial factor underpinning the profitability of grazing industries, and therefore is a priority for breeding programs. Breeding for high dry matter yield (DMY) in forage crops is likely to be enhanced with the development of genomic selection (GS) strategies. However, realising the full potential of GS will require an increase in the amount of phenotypic data and the rate at which it is collected. Therefore, phenotyping remains a critical bottleneck in the implementation of GS in forage species. Assessments of DMY in forage crop breeding include visual scores, sample clipping and mowing of plots, which are often costly and time-consuming. New ground- and aerial-based platforms equipped with advanced sensors offer opportunities for fast, nondestructive and low-cost, high-throughput phenotyping (HTP) of plant growth, development and yield in a field environment. The workflow of image acquisition, processing and analysis are reviewed. The &ldquo;big data&rdquo; challenges, proposed storage and management techniques, development of advanced statistical tools and methods for incorporating the HTP into forage breeding systems are also reviewed. Initial results where these techniques have been applied to forages have been promising but further research and development is required to adapt them to forage breeding situations, particularly with respect to the management of large data sets and the integration of information from spaced plants to sward plots. However, realizing the potential of sensor technologies combined with GS leads to greater rates of genetic gain in forages.},
DOI = {10.3390/agronomy9020065}
}



@Article{rs11030296,
AUTHOR = {Rossi, Mattia and Niedrist, Georg and Asam, Sarah and Tonon, Giustino and Tomelleri, Enrico and Zebisch, Marc},
TITLE = {A Comparison of the Signal from Diverse Optical Sensors for Monitoring Alpine Grassland Dynamics},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {296},
URL = {https://www.mdpi.com/2072-4292/11/3/296},
ISSN = {2072-4292},
ABSTRACT = {Grasslands cover up to 40% of the mountain areas globally and 23% of the European Alps and affect numerous key ecological processes. An increasing number of optical sensors offer a great opportunity to monitor and address dynamic changes in the growth and status of grassland vegetation due to climatic and anthropogenic influences. Vegetation indices (VI) calculated from optical sensor data are a powerful tool in analyzing vegetation dynamics. However, different sensors have their own characteristics, advantages, and challenges in monitoring vegetation over space and time that require special attention when compared to or combined with each other. We used the Normalized Difference Vegetation Index (NDVI) derived from handheld spectrometers, station-based Spectral Reflectance Sensors (SRS), and Phenocams as well as the spaceborne Sentinel-2 Multispectral Instrument (MSI) for assessing growth and dynamic changes in four alpine meadows. We analyzed the similarity of the NDVI on diverse spatial scales and to what extent grassland dynamics of alpine meadows can be detected. We found that NDVI across all sensors traces the growing phases of the vegetation although we experienced a notable variability in NDVI signals among sensors and differences among the sites and plots. We noticed differences in signal saturation, sensor specific offsets, and in the detectability of short-term events. These NDVI inconsistencies depended on sensor-specific spatial and spectral resolutions and acquisition geometries, as well as on grassland management activities and vegetation growth during the year. We demonstrated that the combination of multiple-sensors enhanced the possibility for detecting short-term dynamic changes throughout the year for each of the stations. The presented findings are relevant for building and evaluating a combined sensor approach for consistent vegetation monitoring.},
DOI = {10.3390/rs11030296}
}



@Article{s19030639,
AUTHOR = {Avgeris, Marios and Spatharakis, Dimitrios and Dechouniotis, Dimitrios and Kalatzis, Nikos and Roussaki, Ioanna and Papavassiliou, Symeon},
TITLE = {Where There Is Fire There Is SMOKE: A Scalable Edge Computing Framework for Early Fire Detection},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {639},
URL = {https://www.mdpi.com/1424-8220/19/3/639},
ISSN = {1424-8220},
ABSTRACT = {A Cyber-Physical Social System (CPSS) tightly integrates computer systems with the physical world and human activities. In this article, a three-level CPSS for early fire detection is presented to assist public authorities to promptly identify and act on emergency situations. At the bottom level, the system&rsquo;s architecture involves IoT nodes enabled with sensing and forest monitoring capabilities. Additionally, in this level, the crowd sensing paradigm is exploited to aggregate environmental information collected by end user devices present in the area of interest. Since the IoT nodes suffer from limited computational energy resources, an Edge Computing Infrastructure, at the middle level, facilitates the offloaded data processing regarding possible fire incidents. At the top level, a decision-making service deployed on Cloud nodes integrates data from various sources, including users&rsquo; information on social media, and evaluates the situation criticality. In our work, a dynamic resource scaling mechanism for the Edge Computing Infrastructure is designed to address the demanding Quality of Service (QoS) requirements of this IoT-enabled time and mission critical application. The experimental results indicate that the vertical and horizontal scaling on the Edge Computing layer is beneficial for both the performance and the energy consumption of the IoT nodes.},
DOI = {10.3390/s19030639}
}



@Article{electronics8020181,
AUTHOR = {Jiang, Changhui and Chen, Yuwei and Chen, Shuai and Bo, Yuming and Li, Wei and Tian, Wenxin and Guo, Jun},
TITLE = {A Mixed Deep Recurrent Neural Network for MEMS Gyroscope Noise Suppressing},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {181},
URL = {https://www.mdpi.com/2079-9292/8/2/181},
ISSN = {2079-9292},
ABSTRACT = {Currently, positioning, navigation, and timing information is becoming more and more vital for both civil and military applications. Integration of the global navigation satellite system and /inertial navigation system is the most popular solution for various carriers or vehicle positioning. As is well-known, the global navigation satellite system positioning accuracy will degrade in signal challenging environments. Under this condition, the integration system will fade to a standalone inertial navigation system outputting navigation solutions. However, without outer aiding, positioning errors of the inertial navigation system diverge quickly due to the noise contained in the raw data of the inertial measurement unit. In particular, the micromechanics system inertial measurement unit experiences more complex errors due to the manufacturing technology. To improve the navigation accuracy of inertial navigation systems, one effective approach is to model the raw signal noise and suppress it. Commonly, an inertial measurement unit is composed of three gyroscopes and three accelerometers, among them, the gyroscopes play an important role in the accuracy of the inertial navigation system&rsquo;s navigation solutions. Motivated by this problem, in this paper, an advanced deep recurrent neural network was employed and evaluated in noise modeling of a micromechanics system gyroscope. Specifically, a deep long short term memory recurrent neural network and a deep gated recurrent unit&ndash;recurrent neural network were combined together to construct a two-layer recurrent neural network for noise modeling. In this method, the gyroscope data were treated as a time series, and a real dataset from a micromechanics system inertial measurement unit was employed in the experiments. The results showed that, compared to the two-layer long short term memory, the three-axis attitude errors of the mixed long short term memory&ndash;gated recurrent unit decreased by 7.8%, 20.0%, and 5.1%. When compared with the two-layer gated recurrent unit, the proposed method showed 15.9%, 14.3%, and 10.5% improvement. These results supported a positive conclusion on the performance of designed method, specifically, the mixed deep recurrent neural networks outperformed than the two-layer gated recurrent unit and the two-layer long short term memory recurrent neural networks.},
DOI = {10.3390/electronics8020181}
}



@Article{rs11030312,
AUTHOR = {Freudenberg, Maximilian and Nölke, Nils and Agostini, Alejandro and Urban, Kira and Wörgötter, Florentin and Kleinn, Christoph},
TITLE = {Large Scale Palm Tree Detection in High Resolution Satellite Images Using U-Net},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {312},
URL = {https://www.mdpi.com/2072-4292/11/3/312},
ISSN = {2072-4292},
ABSTRACT = {Oil and coconut palm trees are important crops in many tropical countries, which are either planted as plantations or scattered in the landscape. Monitoring in terms of counting provides useful information for various stakeholders. Most of the existing monitoring methods are based on spectral profiles or simple neural networks and either fall short in terms of accuracy or speed. We use a neural network of the U-Net type in order to detect oil and coconut palms on very high resolution satellite images. The method is applied to two different study areas: (1) large monoculture oil palm plantations in Jambi, Indonesia, and (2) coconut palms in the Bengaluru Metropolitan Region in India. The results show that the proposed method reaches a performance comparable to state of the art approaches, while being about one order of magnitude faster. We reach a maximum throughput of 235 ha/s with a spatial image resolution of 40 cm. The proposed method proves to be reliable even under difficult conditions, such as shadows or urban areas, and can easily be transferred from one region to another. The method detected palms with accuracies between 89% and 92%.},
DOI = {10.3390/rs11030312}
}



@Article{rs11030316,
AUTHOR = {Salamí, Esther and Gallardo, Antonia and Skorobogatov, Georgy and Barrado, Cristina},
TITLE = {On-the-Fly Olive Tree Counting Using a UAS and Cloud Services},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {316},
URL = {https://www.mdpi.com/2072-4292/11/3/316},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial systems (UAS) are becoming a common tool for aerial sensing applications. Nevertheless, sensed data need further processing before becoming useful information. This processing requires large computing power and time before delivery. In this paper, we present a parallel architecture that includes an unmanned aerial vehicle (UAV), a small embedded computer on board, a communication link to the Internet, and a cloud service with the aim to provide useful real-time information directly to the end-users. The potential of parallelism as a solution in remote sensing has not been addressed for a distributed architecture that includes the UAV processors. The architecture is demonstrated for a specific problem: the counting of olive trees in a crop field where the trees are regularly spaced from each other. During the flight, the embedded computer is able to process individual images on board the UAV and provide the total count. The tree counting algorithm obtains an     F 1     score of     99.09 %     for a sequence of ten images with 332 olive trees. The detected trees are geolocated and can be visualized on the Internet seconds after the take-off of the flight, with no further processing required. This is a use case to demonstrate near real-time results obtained from UAS usage. Other more complex UAS applications, such as tree inventories, search and rescue, fire detection, or stock breeding, can potentially benefit from this architecture and obtain faster outcomes, accessible while the UAV is still on flight.},
DOI = {10.3390/rs11030316}
}



@Article{s19030652,
AUTHOR = {Al-Kaff, Abdulla and Gómez-Silva, María José and Moreno, Francisco Miguel and de la Escalera, Arturo and Armingol, José María},
TITLE = {An Appearance-Based Tracking Algorithm for Aerial Search and Rescue Purposes},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {652},
URL = {https://www.mdpi.com/1424-8220/19/3/652},
ISSN = {1424-8220},
ABSTRACT = {The automation of the Wilderness Search and Rescue (WiSAR) task aims for high levels of understanding of various scenery. In addition, working in unfriendly and complex environments may cause a time delay in the operation and consequently put human lives at stake. In order to address this problem, Unmanned Aerial Vehicles (UAVs), which provide potential support to the conventional methods, are used. These vehicles are provided with reliable human detection and tracking algorithms; in order to be able to find and track the bodies of the victims in complex environments, and a robust control system to maintain safe distances from the detected bodies. In this paper, a human detection based on the color and depth data captured from onboard sensors is proposed. Moreover, the proposal of computing data association from the skeleton pose and a visual appearance measurement allows the tracking of multiple people with invariance to the scale, translation and rotation of the point of view with respect to the target objects. The system has been validated with real and simulation experiments, and the obtained results show the ability to track multiple individuals even after long-term disappearances. Furthermore, the simulations present the robustness of the implemented reactive control system as a promising tool for assisting the pilot to perform approaching maneuvers in a safe and smooth manner.},
DOI = {10.3390/s19030652}
}



@Article{rs11030330,
AUTHOR = {Sagan, Vasit and Maimaitijiang, Maitiniyazi and Sidike, Paheding and Eblimit, Kevin and Peterson, Kyle T. and Hartling, Sean and Esposito, Flavio and Khanal, Kapil and Newcomb, Maria and Pauli, Duke and Ward, Rick and Fritschi, Felix and Shakoor, Nadia and Mockler, Todd},
TITLE = {UAV-Based High Resolution Thermal Imaging for Vegetation Monitoring, and Plant Phenotyping Using ICI 8640 P, FLIR Vue Pro R 640, and thermoMap Cameras},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {330},
URL = {https://www.mdpi.com/2072-4292/11/3/330},
ISSN = {2072-4292},
ABSTRACT = {The growing popularity of Unmanned Aerial Vehicles (UAVs) in recent years, along with decreased cost and greater accessibility of both UAVs and thermal imaging sensors, has led to the widespread use of this technology, especially for precision agriculture and plant phenotyping. There are several thermal camera systems in the market that are available at a low cost. However, their efficacy and accuracy in various applications has not been tested. In this study, three commercially available UAV thermal cameras, including ICI 8640 P-series (Infrared Cameras Inc., USA), FLIR Vue Pro R 640 (FLIR Systems, USA), and thermoMap (senseFly, Switzerland) have been tested and evaluated for their potential for forest monitoring, vegetation stress detection, and plant phenotyping. Mounted on multi-rotor or fixed wing systems, these cameras were simultaneously flown over different experimental sites located in St. Louis, Missouri (forest environment), Columbia, Missouri (plant stress detection and phenotyping), and Maricopa, Arizona (high throughput phenotyping). Thermal imagery was calibrated using procedures that utilize a blackbody, handheld thermal spot imager, ground thermal targets, emissivity and atmospheric correction. A suite of statistical analyses, including analysis of variance (ANOVA), correlation analysis between camera temperature and plant biophysical and biochemical traits, and heritability were utilized in order to examine the sensitivity and utility of the cameras against selected plant phenotypic traits and in the detection of plant water stress. In addition, in reference to quantitative assessment of image quality from different thermal cameras, a non-reference image quality evaluator, which primarily measures image focus that is based on the spatial relationship of pixels in different scales, was developed. Our results show that (1) UAV-based thermal imaging is a viable tool in precision agriculture and (2) the three examined cameras are comparable in terms of their efficacy for plant phenotyping. Overall, accuracy, when compared against field measured ground temperature and estimating power of plant biophysical and biochemical traits, the ICI 8640 P-series performed better than the other two cameras, followed by FLIR Vue Pro R 640 and thermoMap cameras. Our results demonstrated that all three UAV thermal cameras provide useful temperature data for precision agriculture and plant phenotying, with ICI 8640 P-series presenting the best results among the three systems. Cost wise, FLIR Vue Pro R 640 is more affordable than the other two cameras, providing a less expensive option for a wide range of applications.},
DOI = {10.3390/rs11030330}
}



@Article{s19030685,
AUTHOR = {Fan, Han and Hernandez Bennetts, Victor and Schaffernicht, Erik and Lilienthal, Achim J.},
TITLE = {Towards Gas Discrimination and Mapping in Emergency Response Scenarios Using a Mobile Robot with an Electronic Nose},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {685},
URL = {https://www.mdpi.com/1424-8220/19/3/685},
ISSN = {1424-8220},
ABSTRACT = {Emergency personnel, such as firefighters, bomb technicians, and urban search and rescue specialists, can be exposed to a variety of extreme hazards during the response to natural and human-made disasters. In many of these scenarios, a risk factor is the presence of hazardous airborne chemicals. The recent and rapid advances in robotics and sensor technologies allow emergency responders to deal with such hazards from relatively safe distances. Mobile robots with gas-sensing capabilities allow to convey useful information such as the possible source positions of different chemicals in the emergency area. However, common gas sampling procedures for laboratory use are not applicable due to the complexity of the environment and the need for fast deployment and analysis. In addition, conventional gas identification approaches, based on supervised learning, cannot handle situations when the number and identities of the present chemicals are unknown. For the purpose of emergency response, all the information concluded from the gas detection events during the robot exploration should be delivered in real time. To address these challenges, we developed an online gas-sensing system using an electronic nose. Our system can automatically perform unsupervised learning and update the discrimination model as the robot is exploring a given environment. The online gas discrimination results are further integrated with geometrical information to derive a multi-compound gas spatial distribution map. The proposed system is deployed on a robot built to operate in harsh environments for supporting fire brigades, and is validated in several different real-world experiments of discriminating and mapping multiple chemical compounds in an indoor open environment. Our results show that the proposed system achieves high accuracy in gas discrimination in an online, unsupervised, and computationally efficient manner. The subsequently created gas distribution maps accurately indicate the presence of different chemicals in the environment, which is of practical significance for emergency response.},
DOI = {10.3390/s19030685}
}



@Article{rs11030338,
AUTHOR = {Jayathunga, Sadeepa and Owari, Toshiaki and Tsuyuki, Satoshi},
TITLE = {Digital Aerial Photogrammetry for Uneven-Aged Forest Management: Assessing the Potential to Reconstruct Canopy Structure and Estimate Living Biomass},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {338},
URL = {https://www.mdpi.com/2072-4292/11/3/338},
ISSN = {2072-4292},
ABSTRACT = {Scientifically robust yet economical and efficient methods are required to gather information about larger areas of uneven-aged forest resources, particularly at the landscape level, to reduce deforestation and forest degradation and to support the sustainable management of forest resources. In this study, we examined the potential of digital aerial photogrammetry (DAP) for assessing uneven-aged forest resources. Specifically, we tested the performance of biomass estimation by varying the conditions of several factors, e.g., image downscaling, vegetation metric extraction (point cloud- and canopy height model (CHM)-derived), modeling method ((simple linear regression (SLR), multiple linear regression (MLR), and random forest (RF)), and season (leaf-on and leaf-off). We built dense point clouds and CHMs using high-resolution aerial imagery collected in leaf-on and leaf-off conditions of an uneven-aged mixed conifer&ndash;broadleaf forest. DAP-derived vegetation metrics were then used to predict the dominant height and living biomass (total, conifer, and broadleaf) at the plot level. Our results demonstrated that image downscaling had a negative impact on the accuracy of the dominant height and biomass estimation in leaf-on conditions. In comparison to CHM-derived vegetation metrics, point cloud-derived metrics performed better in dominant height and biomass (total and conifer) estimations. Although the SLR (%RMSE = 21.1) and MLR (%RMSE = 18.1) modeling methods produced acceptable results for total biomass estimations, RF modeling significantly improved the plot-level total biomass estimation accuracy (%RMSE of 12.0 for leaf-on data). Overall, leaf-on DAP performed better in total biomass estimation compared to leaf-off DAP (%RMSE of 15.0 using RF modeling). Nevertheless, conifer biomass estimation accuracy improved when leaf-off data were used (from a %RMSE of 32.1 leaf-on to 23.8 leaf-off using RF modeling). Leaf-off DAP had a negative impact on the broadleaf biomass estimation (%RMSE &gt; 35% for SLR, MLR, and RF modeling). Our results demonstrated that the performance of forest biomass estimation for uneven-aged forests varied with statistical representations as well as data sources. Thus, it would be appropriate to explore different statistical approaches (e.g., parametric and nonparametric) and data sources (e.g., different image resolutions, vegetation metrics, and leaf-on and leaf-off data) to inform the interpretation of remotely sensed data for biomass estimation for uneven-aged forest resources.},
DOI = {10.3390/rs11030338}
}



@Article{rs11030339,
AUTHOR = {Chen, Chaoyue and Gong, Weiguo and Chen, Yongliang and Li, Weihong},
TITLE = {Object Detection in Remote Sensing Images Based on a Scene-Contextual Feature Pyramid Network},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {339},
URL = {https://www.mdpi.com/2072-4292/11/3/339},
ISSN = {2072-4292},
ABSTRACT = {Object detection has attracted increasing attention in the field of remote sensing image analysis. Complex backgrounds, vertical views, and variations in target kind and size in remote sensing images make object detection a challenging task. In this work, considering that the types of objects are often closely related to the scene in which they are located, we propose a convolutional neural network (CNN) by combining scene-contextual information for object detection. Specifically, we put forward the scene-contextual feature pyramid network (SCFPN), which aims to strengthen the relationship between the target and the scene and solve problems resulting from variations in target size. Additionally, to improve the capability of feature extraction, the network is constructed by repeating a building aggregated residual block. This block increases the receptive field, which can extract richer information for targets and achieve excellent performance with respect to small object detection. Moreover, to improve the proposed model performance, we use group normalization, which divides the channels into groups and computes the mean and variance for normalization within each group, to solve the limitation of the batch normalization. The proposed method is validated on a public and challenging dataset. The experimental results demonstrate that our proposed method outperforms other state-of-the-art object detection models.},
DOI = {10.3390/rs11030339}
}



@Article{f10020145,
AUTHOR = {Cao, Lin and Liu, Hao and Fu, Xiaoyao and Zhang, Zhengnan and Shen, Xin and Ruan, Honghua},
TITLE = {Comparison of UAV LiDAR and Digital Aerial Photogrammetry Point Clouds for Estimating Forest Structural Attributes in Subtropical Planted Forests},
JOURNAL = {Forests},
VOLUME = {10},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {145},
URL = {https://www.mdpi.com/1999-4907/10/2/145},
ISSN = {1999-4907},
ABSTRACT = {Estimating forest structural attributes of planted forests plays a key role in managing forest resources, monitoring carbon stocks, and mitigating climate change. High-resolution and low-cost remote-sensing data are increasingly available to measure three-dimensional (3D) canopy structure and model forest structural attributes. In this study, we compared two suites of point cloud metrics and the accuracies of predictive models of forest structural attributes using unmanned aerial vehicle (UAV) light detection and ranging (LiDAR) and digital aerial photogrammetry (DAP) data, in a subtropical coastal planted forest of East China. A comparison between UAV-LiDAR and UAV-DAP metrics was performed across plots among different tree species, heights, and stem densities. The results showed that a higher similarity between the UAV-LiDAR and UAV-DAP metrics appeared in the dawn redwood plots with greater height and lower stem density. The comparison between the UAV-LiDAR and DAP metrics showed that the metrics of the upper percentiles (r for dawn redwood = 0.95&ndash;0.96, poplar = 0.94&ndash;0.95) showed a stronger correlation than the lower percentiles (r = 0.92&ndash;0.93, 0.90&ndash;0.92), whereas the metrics of upper canopy return density (r = 0.21&ndash;0.24, 0.14&ndash;0.15) showed a weaker correlation than those of lower canopy return density (r = 0.32&ndash;0.68, 0.31&ndash;0.52). The Weibull &alpha; parameter indicated a higher correlation (r = 0.70&ndash;0.72) than that of the Weibull &beta; parameter (r = 0.07&ndash;0.60) for both dawn redwood and poplar plots. The accuracies of UAV-LiDAR (adjusted (Adj)R2 = 0.58&ndash;0.91, relative root-mean-square error (rRMSE) = 9.03%&ndash;24.29%) predicted forest structural attributes were higher than UAV-DAP (Adj-R2 = 0.52&ndash;0.83, rRMSE = 12.20%&ndash;25.84%). In addition, by comparing the forest structural attributes between UAV-LiDAR and UAV-DAP predictive models, the greatest difference was found for volume (&Delta;Adj-R2 = 0.09, &Delta;rRMSE = 4.20%), whereas the lowest difference was for basal area (&Delta;Adj-R2 = 0.03, &Delta;rRMSE = 0.86%). This study proved that the UAV-DAP data are useful and comparable to LiDAR for forest inventory and sustainable forest management in planted forests, by providing accurate estimations of forest structural attributes.},
DOI = {10.3390/f10020145}
}



@Article{drones3010016,
AUTHOR = {Khan, Muhammad Asghar and Qureshi, Ijaz Mansoor and Khanzada, Fahimullah},
TITLE = {A Hybrid Communication Scheme for Efficient and Low-Cost Deployment of Future Flying Ad-Hoc Network (FANET)},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {16},
URL = {https://www.mdpi.com/2504-446X/3/1/16},
ISSN = {2504-446X},
ABSTRACT = {In recent years, FANET-related research and development has doubled, due to the increased demands of unmanned aerial vehicles (UAVs) in both military and civilian operations. Equipped with more capabilities and unique characteristics, FANET is able to play a vital role in mission-critical applications. However, these distinctive features enforce a series of guidelines to be considered for its efficient deployment. Particularly, the use of FANET for on-time data communication services presents demanding challenges in terms of energy efficiency and quality of service (QoS). Proper use of communication architecture and wireless technology will assist to solve these challenges. Therefore, in this paper, we review different communication architectures, including the existing wireless technologies, in order to provide seamless wireless connectivity. Based on the discussions, we conclude that a multi-layer UAV ad-hoc network is the most suitable architecture for networking a group of heterogeneous UAVs, while Bluetooth 5 (802.15.1) is the most favored option because of its low-cost, low power consumption, and longer transmission range for FANET. However, 802.15.1 has the limitation of a lower data rate as compared to Wi-Fi (802.11). Therefore, we propose a hybrid wireless communication scheme so as to utilize the features of the high data transmission rate of 802.11 and the low-power consumption of 802.15.1. The proposed scheme significantly reduces communication cost and improves the network performance in terms of throughput and delay. Further, simulation results using the Optimized Network Engineering Tool (OPNET) further support the effectiveness of our proposed scheme.},
DOI = {10.3390/drones3010016}
}



@Article{robotics8010010,
AUTHOR = {Scalera, Lorenzo and Seriani, Stefano and Gasparetto, Alessandro and Gallina, Paolo},
TITLE = {Non-Photorealistic Rendering Techniques for Artistic Robotic Painting},
JOURNAL = {Robotics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {10},
URL = {https://www.mdpi.com/2218-6581/8/1/10},
ISSN = {2218-6581},
ABSTRACT = {In this paper, we present non-photorealistic rendering techniques that are applied together with a painting robot to realize artworks with original styles. Our robotic painting system is called Busker Robot and it has been considered of interest in recent art fairs and international exhibitions. It consists of a six degree-of-freedom collaborative robot and a series of image processing and path planning algorithms. In particular, here, two different rendering techniques are presented and a description of the experimental set-up is carried out. Finally, the experimental results are discussed by analyzing the elements that can account for the aesthetic appreciation of the artworks.},
DOI = {10.3390/robotics8010010}
}



@Article{rs11040374,
AUTHOR = {Jones, John W.},
TITLE = {Improved Automated Detection of Subpixel-Scale Inundation—Revised Dynamic Surface Water Extent (DSWE) Partial Surface Water Tests},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {374},
URL = {https://www.mdpi.com/2072-4292/11/4/374},
ISSN = {2072-4292},
ABSTRACT = {In order to produce useful hydrologic and aquatic habitat data from the Landsat system, the U.S. Geological Survey has developed the &ldquo;Dynamic Surface Water Extent&rdquo; (DSWE) Landsat Science Product. DSWE will provide long-term, high-temporal resolution data on variations in inundation extent. The model used to generate DSWE is composed of five decision-rule based tests that do not require scene-based training. To allow its general application, required inputs are limited to the Landsat at-surface reflectance product and a digital elevation model. Unlike other Landsat-based water products, DSWE includes pixels that are only partially covered by water to increase inundation dynamics information content. Previously published DSWE model development included one wetland-focused test developed through visual inspection of field-collected Everglades spectra. A comparison of that test&rsquo;s output against Everglades Depth Estimation Network (EDEN) in situ data confirmed the expectation that omission errors were a prime source of inaccuracy in vegetated environments. Further evaluation exposed a tendency toward commission error in coniferous forests. Improvements to the subpixel level &ldquo;partial surface water&rdquo; (PSW) component of DSWE was the focus of this research. Spectral mixture models were created from a variety of laboratory and image-derived endmembers. Based on the mixture modeling, a more &ldquo;aggressive&rdquo; PSW rule improved accuracy in herbaceous wetlands and reduced errors of commission elsewhere, while a second &ldquo;conservative&rdquo; test provides an alternative when commission errors must be minimized. Replication of the EDEN-based experiments using the revised PSW tests yielded a statistically significant increase in mean overall agreement (4%, p = 0.01, n = 50) and a statistically significant decrease (11%, p = 0.009, n = 50) in mean errors of omission. Because the developed spectral mixture models included image-derived vegetation endmembers and laboratory spectra for soil groups found across the US, simulations suggest where the revised DSWE PSW tests perform as they do in the Everglades and where they may prove problematic. Visual comparison of DSWE outputs with an unusual variety of coincidently collected images for locations spread throughout the US support conclusions drawn from Everglades quantitative analyses and highlight DSWE PSW component strengths and weaknesses.},
DOI = {10.3390/rs11040374}
}



@Article{agronomy9020084,
AUTHOR = {Sabzi, Sajad and Abbaspour-Gilandeh, Yousef and García-Mateos, Ginés and Ruiz-Canales, Antonio and Molina-Martínez, José Miguel and Arribas, Juan Ignacio},
TITLE = {An Automatic Non-Destructive Method for the Classification of the Ripeness Stage of Red Delicious Apples in Orchards Using Aerial Video},
JOURNAL = {Agronomy},
VOLUME = {9},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {84},
URL = {https://www.mdpi.com/2073-4395/9/2/84},
ISSN = {2073-4395},
ABSTRACT = {The estimation of the ripening state in orchards helps improve post-harvest processes. Picking fruits based on their stage of maturity can reduce the cost of storage and increase market outcomes. Moreover, aerial images and the estimated ripeness can be used as indicators for detecting water stress and determining the water applied during irrigation. Additionally, they can also be related to the crop coefficient (Kc) of seasonal water needs. The purpose of this research is to develop a new computer vision algorithm to detect the existing fruits in aerial images of an apple cultivar (of Red Delicious variety) and estimate their ripeness stage among four possible classes: unripe, half-ripe, ripe, and overripe. The proposed method is based on a combination of the most effective color features and a classifier based on artificial neural networks optimized with genetic algorithms. The obtained results indicate an average classification accuracy of 97.88%, over a dataset of 8390 images and 27,687 apples, and values of the area under the ROC (receiver operating characteristic) curve near or above 0.99 for all classes. We believe this is a remarkable performance that allows a proper non-intrusive estimation of ripening that will help to improve harvesting strategies.},
DOI = {10.3390/agronomy9020084}
}



@Article{aerospace6020019,
AUTHOR = {Tabassum, Asma and Sabatini, Roberto and Gardi, Alessandro},
TITLE = {Probabilistic Safety Assessment for UAS Separation Assurance and Collision Avoidance Systems},
JOURNAL = {Aerospace},
VOLUME = {6},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {19},
URL = {https://www.mdpi.com/2226-4310/6/2/19},
ISSN = {2226-4310},
ABSTRACT = {The airworthiness certification of aerospace cyber-physical systems traditionally relies on the probabilistic safety assessment as a standard engineering methodology to quantify the potential risks associated with faults in system components. This paper presents and discusses the probabilistic safety assessment of detect and avoid (DAA) systems relying on multiple cooperative and non-cooperative tracking technologies to identify the risk of collision of unmanned aircraft systems (UAS) with other flight vehicles. In particular, fault tree analysis (FTA) is utilized to measure the overall system unavailability for each basic component failure. Considering the inter-dependencies of navigation and surveillance systems, the common cause failure (CCF)-beta model is applied to calculate the system risk associated with common failures. Additionally, an importance analysis is conducted to quantify the safety measures and identify the most significant component failures. Results indicate that the failure in traffic detection by cooperative surveillance systems contribute more to the overall DAA system functionality and that the probability of failure for ownship locatability in cooperative surveillance is greater than its traffic detection function. Although all the sensors individually yield 99.9% operational availability, the implementation of adequate multi-sensor DAA system relying on both cooperative and non-cooperative technologies is shown to be necessary to achieve the desired levels of safety in all possible encounters. These results strongly support the adoption of a unified analytical framework for cooperative/non-cooperative UAS DAA and elicits an evolution of the current certification framework to properly account for artificial intelligence and machine-learning based systems.},
DOI = {10.3390/aerospace6020019}
}



@Article{app9040643,
AUTHOR = {Kwak, Geun-Ho and Park, No-Wook},
TITLE = {Impact of Texture Information on Crop Classification with Machine Learning and UAV Images},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {643},
URL = {https://www.mdpi.com/2076-3417/9/4/643},
ISSN = {2076-3417},
ABSTRACT = {Unmanned aerial vehicle (UAV) images that can provide thematic information at much higher spatial and temporal resolutions than satellite images have great potential in crop classification. Due to the ultra-high spatial resolution of UAV images, spatial contextual information such as texture is often used for crop classification. From a data availability viewpoint, it is not always possible to acquire time-series UAV images due to limited accessibility to the study area. Thus, it is necessary to improve classification performance for situations when a single or minimum number of UAV images are available for crop classification. In this study, we investigate the potential of gray-level co-occurrence matrix (GLCM)-based texture information for crop classification with time-series UAV images and machine learning classifiers including random forest and support vector machine. In particular, the impact of combining texture and spectral information on the classification performance is evaluated for cases that use only one UAV image or multi-temporal images as input. A case study of crop classification in Anbandegi of Korea was conducted for the above comparisons. The best classification accuracy was achieved when multi-temporal UAV images which can fully account for the growth cycles of crops were combined with GLCM-based texture features. However, the impact of the utilization of texture information was not significant. In contrast, when one August UAV image was used for crop classification, the utilization of texture information significantly affected the classification performance. Classification using texture features extracted from GLCM with larger kernel size significantly improved classification accuracy, an improvement of 7.72%p in overall accuracy for the support vector machine classifier, compared with classification based solely on spectral information. These results indicate the usefulness of texture information for classification of ultra-high-spatial-resolution UAV images, particularly when acquisition of time-series UAV images is difficult and only one UAV image is used for crop classification.},
DOI = {10.3390/app9040643}
}



@Article{app9040648,
AUTHOR = {Giernacki, Wojciech},
TITLE = {Iterative Learning Method for In-Flight Auto-Tuning of UAV Controllers Based on Basic Sensory Information},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {648},
URL = {https://www.mdpi.com/2076-3417/9/4/648},
ISSN = {2076-3417},
ABSTRACT = {With an increasing number of multirotor unmanned aerial vehicles (UAVs), solutions supporting the improvement in their precision of operation and safety of autonomous flights are gaining importance. They are particularly crucial in transportation tasks, where control systems are required to provide a stable and controllable flight in various environmental conditions, especially after changing the total mass of the UAV (by adding extra load). In the paper, the problem of using only available basic sensory information for fast, locally best, iterative real-time auto-tuning of parameters of fixed-gain altitude controllers is considered. The machine learning method proposed for this purpose is based on a modified zero-order optimization algorithm (golden-search algorithm) and bootstrapping technique. It has been validated in numerous simulations and real-world experiments in terms of its effectiveness in such aspects as: the impact of environmental disturbances (wind gusts); flight with change in mass; and change of sensory information sources in the auto-tuning procedure. The main advantage of the proposed method is that for the trajectory primitives repeatedly followed by an UAV (for programmed controller gains), the method effectively minimizes the selected performance index (cost function). Such a performance index might, e.g., express indirect requirements about tracking quality and energy expenditure. In the paper, a comprehensive description of the method, as well as a wide discussion of the results obtained from experiments conducted in the AeroLab for a low-cost UAV (Bebop 2), are included. The results have confirmed high efficiency of the method at the expected, low computational complexity.},
DOI = {10.3390/app9040648}
}



@Article{rs11040400,
AUTHOR = {Ancin-Murguzur, Francisco Javier and Taff, Gregory and Davids, Corine and Tømmervik, Hans and Mølmann, Jørgen and Jørgensen, Marit},
TITLE = {Yield Estimates by a Two-Step Approach Using Hyperspectral Methods in Grasslands at High Latitudes},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {400},
URL = {https://www.mdpi.com/2072-4292/11/4/400},
ISSN = {2072-4292},
ABSTRACT = {Ruminant fodder production in agricultural lands in latitudes above the Arctic Circle is constrained by short and hectic growing seasons with a 24-hour photoperiod and low growth temperatures. The use of remote sensing to measure crop production at high latitudes is hindered by intrinsic challenges, such as a low sun elevation angle and a coastal climate with high humidity, which influences the spectral signatures of the sampled vegetation. We used a portable spectrometer (ASD FieldSpec 3) to assess spectra of grass crops and found that when applying multivariate models to the hyperspectral datasets, results show significant predictability of yields (R2 &gt; 0.55, root mean squared error (RMSE) &lt; 180), even when captured under sub-optimal conditions. These results are consistent both in the full spectral range of the spectrometer (350&ndash;2500 nm) and in the 350&ndash;900 nm spectral range, which is a region more robust against air moisture. Sentinel-2A simulations resulted in moderately robust models that could be used in qualitative assessments of field productivity. In addition, simulation of the upcoming hyperspectral EnMap satellite bands showed its potential applicability to measure yields in northern latitudes both in the full spectral range of the satellite (420&ndash;2450 nm) with similar performance as the Sentinel-2A satellite and in the 420&ndash;900 nm range with a comparable reliability to the portable spectrometer. The combination of EnMap and Sentinel-2A to detect fields with low productivity and portable spectrometers to identify the fields or specific regions of fields with the lowest production can help optimize the management of fodder production in high latitudes.},
DOI = {10.3390/rs11040400}
}



@Article{rs11040410,
AUTHOR = {Ampatzidis, Yiannis and Partel, Victor},
TITLE = {UAV-Based High Throughput Phenotyping in Citrus Utilizing Multispectral Imaging and Artificial Intelligence},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {410},
URL = {https://www.mdpi.com/2072-4292/11/4/410},
ISSN = {2072-4292},
ABSTRACT = {Traditional plant breeding evaluation methods are time-consuming, labor-intensive, and costly. Accurate and rapid phenotypic trait data acquisition and analysis can improve genomic selection and accelerate cultivar development. In this work, a technique for data acquisition and image processing was developed utilizing small unmanned aerial vehicles (UAVs), multispectral imaging, and deep learning convolutional neural networks to evaluate phenotypic characteristics on citrus crops. This low-cost and automated high-throughput phenotyping technique utilizes artificial intelligence (AI) and machine learning (ML) to: (i) detect, count, and geolocate trees and tree gaps; (ii) categorize trees based on their canopy size; (iii) develop individual tree health indices; and (iv) evaluate citrus varieties and rootstocks. The proposed remote sensing technique was able to detect and count citrus trees in a grove of 4,931 trees, with precision and recall of 99.9% and 99.7%, respectively, estimate their canopy size with overall accuracy of 85.5%, and detect, count, and geolocate tree gaps with a precision and recall of 100% and 94.6%, respectively. This UAV-based technique provides a consistent, more direct, cost-effective, and rapid method to evaluate phenotypic characteristics of citrus varieties and rootstocks.},
DOI = {10.3390/rs11040410}
}



@Article{rs11040414,
AUTHOR = {Chen, Lin and Wang, Yeqiao and Ren, Chunying and Zhang, Bai and Wang, Zongming},
TITLE = {Optimal Combination of Predictors and Algorithms for Forest Above-Ground Biomass Mapping from Sentinel and SRTM Data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {414},
URL = {https://www.mdpi.com/2072-4292/11/4/414},
ISSN = {2072-4292},
ABSTRACT = {Accurate forest above-ground biomass (AGB) mapping is crucial for sustaining forest management and carbon cycle tracking. The Shuttle Radar Topographic Mission (SRTM) and Sentinel satellite series offer opportunities for forest AGB monitoring. In this study, predictors filtered from 121 variables from Sentinel-1 synthetic aperture radar (SAR), Sentinal-2 multispectral instrument (MSI) and SRTM digital elevation model (DEM) data were composed into four groups and evaluated for their effectiveness in prediction of AGB. Five evaluated algorithms include linear regression such as stepwise regression (SWR) and geographically weighted regression (GWR); machine learning (ML) such as artificial neural network (ANN), support vector machine for regression (SVR), and random forest (RF). The results showed that the RF model used predictors from both the Sentinel series and SRTM DEM performed the best, based on the independent validation set. The RF model achieved accuracy with the mean error, mean absolute error, root mean square error, and correlation coefficient in 1.39, 25.48, 61.11 Mg&middot;ha&minus;1 and 0.9769, respectively. Texture characteristics, reflectance, vegetation indices, elevation, stream power index, topographic wetness index and surface roughness were recommended predictors for AGB prediction. Predictor variables were more important than algorithms for improving the accuracy of AGB estimates. The study demonstrated encouraging results in the optimal combination of predictors and algorithms for forest AGB mapping, using openly accessible and fine-resolution data based on RF algorithms.},
DOI = {10.3390/rs11040414}
}



@Article{mi10020137,
AUTHOR = {Liu, Zhonglun and Chen, Mingce and Xin, Zhaowei and Dai, Wanwan and Han, Xinjie and Zhang, Xinyu and Wang, Haiwei and Xie, Changsheng},
TITLE = {Research on a Dual-Mode Infrared Liquid-Crystal Device for Simultaneous Electrically Adjusted Filtering and Zooming},
JOURNAL = {Micromachines},
VOLUME = {10},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {137},
URL = {https://www.mdpi.com/2072-666X/10/2/137},
PubMedID = {30791375},
ISSN = {2072-666X},
ABSTRACT = {A new dual-mode liquid-crystal (LC) micro-device constructed by incorporating a Fabry&ndash;Perot (FP) cavity and an arrayed LC micro-lens for performing simultaneous electrically adjusted filtering and zooming in infrared wavelength range is presented in this paper. The main micro-structure is a micro-cavity consisting of two parallel zinc selenide (ZnSe) substrates that are pre-coated with ~20-nm aluminum (Al) layers which served as their high-reflection films and electrodes. In particular, the top electrode of the device is patterned by 44 &times; 38 circular micro-holes of 120 &mu;m diameter, which also means a 44 &times; 38 micro-lens array. The micro-cavity with a typical depth of ~12 &mu;m is fully filled by LC materials. The experimental results show that the spectral component with needed frequency or wavelength can be selected effectively from incident micro-beams, and both the transmission spectrum and the point spread function can be adjusted simultaneously by simply varying the root-mean-square value of the signal voltage applied, so as to demonstrate a closely correlated feature of filtering and zooming. In addition, the maximum transmittance is already up to ~20% according the peak-to-valley value of the spectral transmittance curves, which exhibits nearly twice the increment compared with that of the ordinary LC-FP filtering without micro-lenses.},
DOI = {10.3390/mi10020137}
}



@Article{f10020180,
AUTHOR = {Erickson, Adam and Strigul, Nikolay},
TITLE = {A Forest Model Intercomparison Framework and Application at Two Temperate Forests Along the East Coast of the United States},
JOURNAL = {Forests},
VOLUME = {10},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {180},
URL = {https://www.mdpi.com/1999-4907/10/2/180},
ISSN = {1999-4907},
ABSTRACT = {State-of-the-art forest models are often complex, analytically intractable, and computationally expensive, due to the explicit representation of detailed biogeochemical and ecological processes. Different models often produce distinct results while predictions from the same model vary with parameter values. In this project, we developed a rigorous quantitative approach for conducting model intercomparisons and assessing model performance. We have applied our original methodology to compare two forest biogeochemistry models, the Perfect Plasticity Approximation with Simple Biogeochemistry (PPA-SiBGC) and Landscape Disturbance and Succession with Net Ecosystem Carbon and Nitrogen (LANDIS-II NECN). We simulated past-decade conditions at flux tower sites located within Harvard Forest, MA, USA (HF-EMS) and Jones Ecological Research Center, GA, USA (JERC-RD). We mined field data available from both sites to perform model parameterization, validation, and intercomparison. We assessed model performance using the following time-series metrics: Net ecosystem exchange, aboveground net primary production, aboveground biomass, C, and N, belowground biomass, C, and N, soil respiration, and species total biomass and relative abundance. We also assessed static observations of soil organic C and N, and concluded with an assessment of general model usability, performance, and transferability. Despite substantial differences in design, both models achieved good accuracy across the range of pool metrics. While LANDIS-II NECN showed better fidelity to interannual NEE fluxes, PPA-SiBGC indicated better overall performance for both sites across the 11 temporal and two static metrics tested (HF-EMS       R 2  &macr;  = 0.73 , + 0.07    ,       R M S E  &macr;  = 4.68 , &minus; 9.96    ; JERC-RD       R 2  &macr;  = 0.73 , + 0.01    ,       R M S E  &macr;  = 2.18 , &minus; 1.64    ). To facilitate further testing of forest models at the two sites, we provide pre-processed datasets and original software written in the R language of statistical computing. In addition to model intercomparisons, our approach may be employed to test modifications to forest models and their sensitivity to different parameterizations.},
DOI = {10.3390/f10020180}
}



@Article{en12040676,
AUTHOR = {Shihavuddin, ASM and Chen, Xiao and Fedorov, Vladimir and Nymark Christensen, Anders and Andre Brogaard Riis, Nicolai and Branner, Kim and Bjorholm Dahl, Anders and Reinhold Paulsen, Rasmus},
TITLE = {Wind Turbine Surface Damage Detection by Deep Learning Aided Drone Inspection Analysis},
JOURNAL = {Energies},
VOLUME = {12},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {676},
URL = {https://www.mdpi.com/1996-1073/12/4/676},
ISSN = {1996-1073},
ABSTRACT = {Timely detection of surface damages on wind turbine blades is imperative for minimizing downtime and avoiding possible catastrophic structural failures. With recent advances in drone technology, a large number of high-resolution images of wind turbines are routinely acquired and subsequently analyzed by experts to identify imminent damages. Automated analysis of these inspection images with the help of machine learning algorithms can reduce the inspection cost. In this work, we develop a deep learning-based automated damage suggestion system for subsequent analysis of drone inspection images. Experimental results demonstrate that the proposed approach can achieve almost human-level precision in terms of suggested damage location and types on wind turbine blades. We further demonstrate that for relatively small training sets, advanced data augmentation during deep learning training can better generalize the trained model, providing a significant gain in precision.},
DOI = {10.3390/en12040676}
}



@Article{rs11040436,
AUTHOR = {Khaliq, Aleem and Comba, Lorenzo and Biglia, Alessandro and Ricauda Aimonino, Davide and Chiaberge, Marcello and Gay, Paolo},
TITLE = {Comparison of Satellite and UAV-Based Multispectral Imagery for Vineyard Variability Assessment},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {436},
URL = {https://www.mdpi.com/2072-4292/11/4/436},
ISSN = {2072-4292},
ABSTRACT = {In agriculture, remotely sensed data play a crucial role in providing valuable information on crop and soil status to perform effective management. Several spectral indices have proven to be valuable tools in describing crop spatial and temporal variability. In this paper, a detailed analysis and comparison of vineyard multispectral imagery, provided by decametric resolution satellite and low altitude Unmanned Aerial Vehicle (UAV) platforms, is presented. The effectiveness of Sentinel-2 imagery and of high-resolution UAV aerial images was evaluated by considering the well-known relation between the Normalised Difference Vegetation Index (NDVI) and crop vigour. After being pre-processed, the data from UAV was compared with the satellite imagery by computing three different NDVI indices to properly analyse the unbundled spectral contribution of the different elements in the vineyard environment considering: (i) the whole cropland surface; (ii) only the vine canopies; and (iii) only the inter-row terrain. The results show that the raw s resolution satellite imagery could not be directly used to reliably describe vineyard variability. Indeed, the contribution of inter-row surfaces to the remotely sensed dataset may affect the NDVI computation, leading to biased crop descriptors. On the contrary, vigour maps computed from the UAV imagery, considering only the pixels representing crop canopies, resulted to be more related to the in-field assessment compared to the satellite imagery. The proposed method may be extended to other crop typologies grown in rows or without intensive layout, where crop canopies do not extend to the whole surface or where the presence of weeds is significant.},
DOI = {10.3390/rs11040436}
}



@Article{s19040926,
AUTHOR = {Sanchez-Gonzalez, Pedro-Luis and Díaz-Gutiérrez, David and Leo, Teresa J. and Núñez-Rivas, Luis R.},
TITLE = {Toward Digitalization of Maritime Transport?},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {926},
URL = {https://www.mdpi.com/1424-8220/19/4/926},
ISSN = {1424-8220},
ABSTRACT = {Although maritime transport is the backbone of world commerce, its digitalization lags significantly behind when we consider some basic facts. This work verifies the state-of-the-art as it currently applies to eight digital domains: Autonomous vehicles and robotics; artificial intelligence; big data; virtual reality, augmented and mixed reality; internet of things; the cloud and edge computing; digital security; and 3D printing and additive engineering. It also provides insight into each of the three sectors into which this industry has been divided: Ship design and shipbuilding; shipping; and ports. The work, based on a systematic literature review, demonstrates that there are domains on which almost no formal study has been done thus far and concludes that there are major areas that require attention in terms of research. It also illustrates the increasing interest on the subject, arising from the necessity of raising the maritime transport industry to the same level of digitalization as other industries.},
DOI = {10.3390/s19040926}
}



@Article{rs11040452,
AUTHOR = {Zhang, Jingxiao and Jia, Li and Menenti, Massimo and Hu, Guangcheng},
TITLE = {Glacier Facies Mapping Using a Machine-Learning Algorithm: The Parlung Zangbo Basin Case Study},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {452},
URL = {https://www.mdpi.com/2072-4292/11/4/452},
ISSN = {2072-4292},
ABSTRACT = {Glaciers in the Tibetan Plateau are an important indicator of climate change. Automatic glacier facies mapping utilizing remote sensing data is challenging due to the spectral similarity of supraglacial debris and the adjacent bedrock. Most of the available glacier datasets do not provide the boundary of clean ice and debris-covered glacier facies, while debris-covered glacier facies play a key role in mass balance research. The aim of this study was to develop an automatic algorithm to distinguish ice cover types based on multi-temporal satellite data, and the algorithm was implemented in a subregion of the Parlung Zangbo basin in the southeastern Tibetan Plateau. The classification method was built upon an automated machine learning approach: Random Forest in combination with the analysis of topographic and textural features based on Landsat-8 imagery and multiple digital elevation model (DEM) data. Very high spatial resolution Gao Fen-1 (GF-1) Panchromatic and Multi-Spectral (PMS) imagery was used to select training samples and validate the classification results. In this study, all of the land cover types were classified with overall good performance using the proposed method. The results indicated that fully debris-covered glaciers accounted for approximately 20.7% of the total glacier area in this region and were mainly distributed at elevations between 4600 m and 4800 m above sea level (a.s.l.). Additionally, an analysis of the results clearly revealed that the proportion of small size glaciers (&lt;1 km2) were 88.3% distributed at lower elevations compared to larger size glaciers (&ge;1 km2). In addition, the majority of glaciers (both in terms of glacier number and area) were characterized by a mean slope ranging between 20&deg; and 30&deg;, and 42.1% of glaciers had a northeast and north orientation in the Parlung Zangbo basin.},
DOI = {10.3390/rs11040452}
}



@Article{s19040933,
AUTHOR = {Wang, Linhui and Yue, Xuejun and Liu, Yongxin and Wang, Jian and Wang, Huihui},
TITLE = {An Intelligent Vision Based Sensing Approach for Spraying Droplets Deposition Detection},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {933},
URL = {https://www.mdpi.com/1424-8220/19/4/933},
ISSN = {1424-8220},
ABSTRACT = {The rapid development of vision sensor based on artificial intelligence (AI) is reforming industries and making our world smarter. Among these trends, it is of great significance to adapt AI technologies into the intelligent agricultural management. In smart agricultural aviation spraying, the droplets&rsquo; distribution and deposition are important indexes for estimating effectiveness in plant protection process. However, conventional approaches are problematic, they lack adaptivity to environmental changes, and consumes non-reusable test materials. One example is that the machine vision algorithms they employ can&rsquo;t guarantee that the division of adhesive droplets thereby disabling the accurate measurement of critical parameters. To alleviate these problems, we put forward an intelligent visual droplet detection node which can adapt to the environment illumination change. Then, we propose a modified marker controllable watershed segmentation algorithm to segment those adhesive droplets, and calculate their characteristic parameters on the basis of the segmentation results, including number, coverage, coverage density, etc. Finally, we use the intelligent node to detect droplets, and then expound the situation that the droplet region is effectively segmented and marked. The intelligent node has better adaptability and robustness even under the condition of illumination changing. The large-scale distributed detection result indicates that our approach has good consistency with the non-recyclable water-sensitive paper approach. Our approach provides an intelligent and environmental friendly way of tests for spraying techniques, especially for plant protection with Unmanned Aerial Vehicles.},
DOI = {10.3390/s19040933}
}



@Article{drones3010022,
AUTHOR = {Madokoro, Hirokazu and Sato, Kazuhito and Shimoi, Nobuhiro},
TITLE = {Vision-Based Indoor Scene Recognition from Time-Series Aerial Images Obtained Using a MAV Mounted Monocular Camera},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {22},
URL = {https://www.mdpi.com/2504-446X/3/1/22},
ISSN = {2504-446X},
ABSTRACT = {This paper presents a vision-based indoor scene recognition method from aerial time-series images obtained using a micro air vehicle (MAV). The proposed method comprises two procedures: a codebook feature description procedure, and a recognition procedure using category maps. For the former procedure, codebooks are created automatically as visual words using self-organizing maps (SOMs) after extracting part-based local features using a part-based descriptor from time-series scene images. For the latter procedure, category maps are created using counter propagation networks (CPNs) with the extraction of category boundaries using a unified distance matrix (U-Matrix). Using category maps, topologies of image features are mapped into a low-dimensional space based on competitive and neighborhood learning. We obtained aerial time-series image datasets of five sets for two flight routes: a round flight route and a zigzag flight route. The experimentally obtained results with leave-one-out cross-validation (LOOCV) revealed respective mean recognition accuracies for the round flight datasets (RFDs) and zigzag flight datasets (ZFDs) of 71.7% and 65.5% for 10 zones. The category maps addressed the complexity of scenes because of segmented categories. Although extraction results of category boundaries using U-Matrix were partially discontinuous, we obtained comprehensive category boundaries that segment scenes into several categories.},
DOI = {10.3390/drones3010022}
}



@Article{rs11050473,
AUTHOR = {Michez, Adrien and Lejeune, Philippe and Bauwens, Sébastien and Herinaina, Andriamandroso Andriamasinoro Lalaina and Blaise, Yannick and Castro Muñoz, Eloy and Lebeau, Frédéric and Bindelle, Jérôme},
TITLE = {Mapping and Monitoring of Biomass and Grazing in Pasture with an Unmanned Aerial System},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {473},
URL = {https://www.mdpi.com/2072-4292/11/5/473},
ISSN = {2072-4292},
ABSTRACT = {The tools available to farmers to manage grazed pastures and adjust forage demand to grass growth are generally rather static. Unmanned aerial systems (UASs) are interesting versatile tools that can provide relevant 3D information, such as sward height (3D structure), or even describe the physical condition of pastures through the use of spectral information. This study aimed to evaluate the potential of UAS to characterize a pasture’s sward height and above-ground biomass at a very fine spatial scale. The pasture height provided by UAS products showed good agreement (R2 = 0.62) with a reference terrestrial light detection and ranging (LiDAR) dataset. We tested the ability of UAS imagery to model pasture biomass based on three different combinations: UAS sward height, UAS sward multispectral reflectance/vegetation indices, and a combination of both UAS data types. The mixed approach combining the UAS sward height and spectral data performed the best (adj. R2 = 0.49). This approach reached a quality comparable to that of more conventional non-destructive on-field pasture biomass monitoring tools. As all of the UAS variables used in the model fitting process were extracted from spatial information (raster data), a high spatial resolution map of pasture biomass was derived based on the best fitted model. A sward height differences map was also derived from UAS-based sward height maps before and after grazing. Our results demonstrate the potential of UAS imagery as a tool for precision grazing study applications. The UAS approach to height and biomass monitoring was revealed to be a potential alternative to the widely used but time-consuming field approaches. While reaching a similar level of accuracy to the conventional field sampling approach, the UAS approach provides wall-to-wall pasture characterization through very high spatial resolution maps, opening up a new area of research for precision grazing.},
DOI = {10.3390/rs11050473}
}



@Article{rs11050484,
AUTHOR = {Feng, Jie and Wang, Lin and Yu, Haipeng and Jiao, Licheng and Zhang, Xiangrong},
TITLE = {Divide-and-Conquer Dual-Architecture Convolutional Neural Network for Classification of Hyperspectral Images},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {484},
URL = {https://www.mdpi.com/2072-4292/11/5/484},
ISSN = {2072-4292},
ABSTRACT = {Convolutional neural network (CNN) is well-known for its powerful capability on image classification. In hyperspectral images (HSIs), fixed-size spatial window is generally used as the input of CNN for pixel-wise classification. However, single fixed-size spatial architecture hinders the excellent performance of CNN due to the neglect of various land-cover distributions in HSIs. Moreover, insufficient samples in HSIs may cause the overfitting problem. To address these problems, a novel divide-and-conquer dual-architecture CNN (DDCNN) method is proposed for HSI classification. In DDCNN, a novel regional division strategy based on local and non-local decisions is devised to distinguish homogeneous and heterogeneous regions. Then, for homogeneous regions, a multi-scale CNN architecture with larger spatial window inputs is constructed to learn joint spectral-spatial features. For heterogeneous regions, a fine-grained CNN architecture with smaller spatial window inputs is constructed to learn hierarchical spectral features. Moreover, to alleviate the problem of insufficient training samples, unlabeled samples with high confidences are pre-labeled under adaptively spatial constraint. Experimental results on HSIs demonstrate that the proposed method provides encouraging classification performance, especially region uniformity and edge preservation with limited training samples.},
DOI = {10.3390/rs11050484}
}



@Article{rs11050487,
AUTHOR = {Pu, Can and Song, Runzi and Tylecek, Radim and Li, Nanbo and Fisher, Robert B.},
TITLE = {SDF-MAN: Semi-Supervised Disparity Fusion with Multi-Scale Adversarial Networks},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {487},
URL = {https://www.mdpi.com/2072-4292/11/5/487},
ISSN = {2072-4292},
ABSTRACT = {Refining raw disparity maps from different algorithms to exploit their complementary advantages is still challenging. Uncertainty estimation and complex disparity relationships among pixels limit the accuracy and robustness of existing methods and there is no standard method for fusion of different kinds of depth data. In this paper, we introduce a new method to fuse disparity maps from different sources, while incorporating supplementary information (intensity, gradient, etc.) into a refiner network to better refine raw disparity inputs. A discriminator network classifies disparities at different receptive fields and scales. Assuming a Markov Random Field for the refined disparity map produces better estimates of the true disparity distribution. Both fully supervised and semi-supervised versions of the algorithm are proposed. The approach includes a more robust loss function to inpaint invalid disparity values and requires much less labeled data to train in the semi-supervised learning mode. The algorithm can be generalized to fuse depths from different kinds of depth sources. Experiments explored different fusion opportunities: stereo-monocular fusion, stereo-ToF fusion and stereo-stereo fusion. The experiments show the superiority of the proposed algorithm compared with the most recent algorithms on public synthetic datasets (Scene Flow, SYNTH3, our synthetic garden dataset) and real datasets (Kitti2015 dataset and Trimbot2020 Garden dataset).},
DOI = {10.3390/rs11050487}
}



@Article{rs11050490,
AUTHOR = {Shen, Wenjuan and Li, Mingshi and Huang, Chengquan and Tao, Xin and Li, Shu and Wei, Anshi},
TITLE = {Mapping Annual Forest Change Due to Afforestation in Guangdong Province of China Using Active and Passive Remote Sensing Data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {490},
URL = {https://www.mdpi.com/2072-4292/11/5/490},
ISSN = {2072-4292},
ABSTRACT = {Accurate acquisition of spatial distribution of afforestation in a large area is of great significance to contributing to the sustainable utilization of forest resources and the evaluation of the carbon accounting. Annual forest maps (1986&ndash;2016) of Guangdong, China were generated using time series Landsat images and PALSAR data. Initially, four PALSAR-based classifiers were used to classify land cover types. Then, the optimal mapping algorithm was determined. Next, an accurate identification of forest and non-forest was carried out by combining Landsat-based phenological variables and PALSAR-based land cover classifications. Finally, the spatio-temporal distribution of forest cover change due to afforestation was created and its forest biomass dynamics changes were detected. The results indicated that the overall accuracy of forest classification of the improved model based on the PALSAR-based stochastic gradient boosting (SGB) classification and the maximum value of normalized difference vegetation index (NDVI; SGB-NDVI) were approximately 75&ndash;85% in 2005, 2010, and 2016. Compared with the Japan Aerospace Exploration Agency (JAXA) PALSAR-forest/non-forest, the SGB-NDVI-based forest product showed great improvement, while the SGB-NDVI product was the same or slightly inferior to the Global Land Cover (GLC) and vegetation tracker change (VCT)-based land cover types, respectively. Although this combination of multiple sources contained some errors, the SGB-NDVI model effectively identified the distribution of forest cover changes by afforestation events. By integrating aboveground biomass dynamics (AGB) change with forest cover, the trend in afforestation area closely corresponded with the trend in forest AGB. This technique can provide an essential data baseline for carbon assessment in the planted forests of southern China.},
DOI = {10.3390/rs11050490}
}



@Article{s19051016,
AUTHOR = {Viseras, Alberto and Shutin, Dmitriy and Merino, Luis},
TITLE = {Robotic Active Information Gathering for Spatial Field Reconstruction with Rapidly-Exploring Random Trees and Online Learning of Gaussian Processes},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {1016},
URL = {https://www.mdpi.com/1424-8220/19/5/1016},
ISSN = {1424-8220},
ABSTRACT = {Information gathering (IG) algorithms aim to intelligently select a mobile sensor actions required to efficiently obtain an accurate reconstruction of a physical process, such as an occupancy map, or a magnetic field. Many recent works have proposed algorithms for IG that employ Gaussian processes (GPs) as underlying model of the process. However, most algorithms discretize the state space, which makes them computationally intractable for robotic systems with complex dynamics. Moreover, they are not suited for online information gathering tasks as they assume prior knowledge about GP parameters. This paper presents a novel approach that tackles the two aforementioned issues. Specifically, our approach includes two intertwined steps: (i) a Rapidly-Exploring Random Tree (RRT) search that allows a robot to identify unvisited locations, and to learn the GP parameters, and (ii) an RRT*-based informative path planning that guides the robot towards those locations by maximizing the information gathered while minimizing path cost. The combination of the two steps allows an online realization of the algorithm, while eliminating the need for discretization. We demonstrate that our proposed algorithm outperforms state-of-the-art both in simulations, and in a lab experiment in which a ground-based robot explores the magnetic field intensity within an indoor environment populated with obstacles.},
DOI = {10.3390/s19051016}
}



@Article{rs11050496,
AUTHOR = {Gao, Shupeng and Liu, Xiaolong and Bo, Yanchen and Shi, Zhengtao and Zhou, Hongmin},
TITLE = {Rubber Identification Based on Blended High Spatio-Temporal Resolution Optical Remote Sensing Data: A Case Study in Xishuangbanna},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {496},
URL = {https://www.mdpi.com/2072-4292/11/5/496},
ISSN = {2072-4292},
ABSTRACT = {As an important economic resource, rubber has rapidly grown in Xishuangbanna of Yunnan Province, China, since the 1990s. Tropical rainforests have been replaced by extensive rubber plantations, which has resulted in ecological problems such as the loss of biodiversity and local water shortages. It is vitally important to accurately map the rubber plantations in this region. Although several rubber mapping methods have been proposed, few studies have investigated methods based on optical remote sensing time series data with high spatio-temporal resolution due to the cloudy and foggy weather conditions in this area. This study presented a rubber plantation identification method that used spatio-temporal optical remote sensing data fusion technology to obtain vegetation index data at high spatio-temporal resolution within the optical remote sensing window in Xishuangbanna. The analysis of the proposed method shows that (1) fused optical remote sensing data with high spatio-temporal resolution could map the rubber distribution with high accuracy (overall accuracy of up to 89.51% and kappa of 0.86). (2) Fused indices have high R2 (R2 greater than 0.8, where R is the correlation coefficient) with the indices that were derived from the Landsat observed data, which indicates that fusion results are dependable. However, the fusion accuracy is affected by terrain factors including elevation, slope, and slope aspects. These factors have obvious negative effects on the fusion accuracy of high spatio-temporal resolution optical remote sensing data: the highest fusion accuracy occurred in areas with elevations between 1201 and 1400 m.a.s.l., and the lowest accuracy occurred in areas with elevations less than 600 m.a.s.l. For the 5 fused time series indices (normalized difference vegetation index (NDVI), enhanced vegetation index (EVI), normalized difference moisture index (NDMI), normalized burn ratio (NBR), and tasseled cap angle (TCA)), the fusion accuracy decreased with increasing slope, and increasing slope had the least impact on the EVI, but the greatest negative impact on the NDVI; the slope aspect had a limited influence on the fusion accuracies of the 5 time series indices, but fusion accuracy was lowest on the northwest slope. (3) EVI had the highest accuracy of rubber plantation classification among the 5 time series indices, and the overall classification accuracies of the time series EVI for the four different years (2000, 2005, 2010, and 2015) reached 87.20% (kappa 0.82), 86.91% (kappa 0.81), 88.85% (kappa 0.84), and 89.51% (kappa 0.86), respectively. The results indicate that the method is a promising approach for rubber plantation mapping and the detection of changes in rubber plantations in this tropical area.},
DOI = {10.3390/rs11050496}
}



@Article{s19051067,
AUTHOR = {Zhao, Dan-feng and Tian, Hai and Xue, Rui},
TITLE = {Adaptive Rate-Compatible Non-Binary LDPC Coding Scheme for the B5G Mobile System},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {1067},
URL = {https://www.mdpi.com/1424-8220/19/5/1067},
ISSN = {1424-8220},
ABSTRACT = {This paper studies an adaptive coding scheme for B5G (beyond 5th generation) mobile system-enhanced transmission technology. Different from the existing works, the authors develop a class of rate-compatible, non-binary, low-density parity check (RC-NB-LDPC) codes, which expresses the strong connection between the algebra-based and graph-theoretic-based constructions. The constructed codes can not only express rate-compatible (RC) features, but also possess a quasi-cyclic (QC) structure that facilitates the encoding implementation. Further, in order to achieve the code rate-adaptive allocation scheme, the authors propose using the K-means++ clustering algorithm to cluster different channel environments, considering various factors that affect channel characteristics. Finally, in order to present the advantages of the adaptive coding scheme, the authors construct a coding scheme for image transmission. The numerical results demonstrate that the developed code can obtain better waterfall performance in a larger code rate range, which is more suitable for data transmission; the adaptive coding transmission scheme can obtain higher reconstructed image quality compared to the fixed code rate-coding scheme. Moreover, when considering unequal error protection (UEP), the proposed scheme can further improve the reconstructed image quality.},
DOI = {10.3390/s19051067}
}



@Article{rs11050512,
AUTHOR = {Ma, Fei and Gao, Fei and Sun, Jinping and Zhou, Huiyu and Hussain, Amir},
TITLE = {Weakly Supervised Segmentation of SAR Imagery Using Superpixel and Hierarchically Adversarial CRF},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {512},
URL = {https://www.mdpi.com/2072-4292/11/5/512},
ISSN = {2072-4292},
ABSTRACT = {Synthetic aperture radar (SAR) image segmentation aims at generating homogeneous regions from a pixel-based image and is the basis of image interpretation. However, most of the existing segmentation methods usually neglect the appearance and spatial consistency during feature extraction and also require a large number of training data. In addition, pixel-based processing cannot meet the real time requirement. We hereby present a weakly supervised algorithm to perform the task of segmentation for high-resolution SAR images. For effective segmentation, the input image is first over-segmented into a set of primitive superpixels. This algorithm combines hierarchical conditional generative adversarial nets (CGAN) and conditional random fields (CRF). The CGAN-based networks can leverage abundant unlabeled data learning parameters, reducing their reliance on the labeled samples. In order to preserve neighborhood consistency in the feature extraction stage, the hierarchical CGAN is composed of two sub-networks, which are employed to extract the information of the central superpixels and the corresponding background superpixels, respectively. Afterwards, CRF is utilized to perform label optimization using the concatenated features. Quantified experiments on an airborne SAR image dataset prove that the proposed method can effectively learn feature representations and achieve competitive accuracy to the state-of-the-art segmentation approaches. More specifically, our algorithm has a higher Cohen&rsquo;s kappa coefficient and overall accuracy. Its computation time is less than the current mainstream pixel-level semantic segmentation networks.},
DOI = {10.3390/rs11050512}
}



@Article{rs11050513,
AUTHOR = {Xu, Hanqiu and Hu, Xiujuan and Guan, Huade and Zhang, Bobo and Wang, Meiya and Chen, Shanmu and Chen, Minghua},
TITLE = {A Remote Sensing Based Method to Detect Soil Erosion in Forests},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {513},
URL = {https://www.mdpi.com/2072-4292/11/5/513},
ISSN = {2072-4292},
ABSTRACT = {Rainwater-induced soil erosion occurring in the forest is a special phenomenon of soil erosion in many red soil areas. Detection of such soil erosion is essential for developing land management to reduce soil loss in areas including southern China and other red soil regions of the world. Remotely sensed canopy cover is often used to determine the potential of soil erosion over a large spatial scale, which, however, becomes less useful in forest areas. This study proposes a new remote sensing method to detect soil erosion under forest canopy and presents a case study in a forest area in southern China. Five factors that are closely related to soil erosion in forest were used as discriminators to develop the model. These factors include fractional vegetation coverage, nitrogen reflectance index, yellow leaf index, bare soil index and slope. They quantitatively represent vegetation density, vegetation health status, soil exposure intensity and terrain steepness that are considered relevant to forest soil erosion. These five factors can all be derived from remote sensing imagery based on related thematic indices or algorithms. The five factors were integrated to create the soil erosion under forest model (SEUFM) through Principal Components Analysis (PCA) or a multiplication method. The case study in the forest area in Changting County of southern China with a Landsat 8 image shows that the first principal component-based SEUFM achieves an overall accuracy close to 90%, while the multiplication-based model reaches 81%. The detected locations of soil erosion in forest provide the target areas to be managed from further soil loss. The proposed method provides a tool to understand more about soil erosion in forested areas where soil erosion is usually not considered an issue. Therefore, the method is useful for soil conservation in forest.},
DOI = {10.3390/rs11050513}
}



@Article{s19051086,
AUTHOR = {Peng, Shubiao and Ma, Hongchao and Zhang, Liang},
TITLE = {Automatic Registration of Optical Images with Airborne LiDAR Point Cloud in Urban Scenes Based on Line-Point Similarity Invariant and Extended Collinearity Equations},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {1086},
URL = {https://www.mdpi.com/1424-8220/19/5/1086},
ISSN = {1424-8220},
ABSTRACT = {This paper proposes a novel method to achieve the automatic registration of optical images and Light Detection and Ranging (LiDAR) points in urban areas. The whole procedure, which adopts a coarse-to-precise registration strategy, can be summarized as follows: Coarse registration is performed through a conventional point-feature-based method. The points needed can be extracted from both datasets through a matured point extractor, such as the Forster operator, followed by the extraction of straight lines. Considering that lines are mainly from building roof edges in urban scenes, and being aware of their inaccuracy when extracted from an irregularly spaced point cloud, an &ldquo;infinitesimal feature analysis method&rdquo; fully utilizing LiDAR scanning characteristics is proposed to refine edge lines. Points which are matched between the image and LiDAR data are then applied as guidance to search for matched lines via the line-point similarity invariant. Finally, a transformation function based on extended collinearity equations is applied to achieve precise registration. The experimental results show that the proposed method outperforms the conventional ones in terms of the registration accuracy and automation level.},
DOI = {10.3390/s19051086}
}



@Article{s19051112,
AUTHOR = {Wen, Sheng and Zhang, Quanyong and Yin, Xuanchun and Lan, Yubin and Zhang, Jiantao and Ge, Yufeng},
TITLE = {Design of Plant Protection UAV Variable Spray System Based on Neural Networks},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {1112},
URL = {https://www.mdpi.com/1424-8220/19/5/1112},
ISSN = {1424-8220},
ABSTRACT = {Recently, unmanned aerial vehicles (UAVs) have rapidly emerged as a new technology in the fields of plant protection and pest control in China. Based on existing variable spray research, a plant protection UAV variable spray system integrating neural network based decision making is designed. Using the existing data on plant protection UAV operations, combined with artificial neural network (ANN) technology, an error back propagation (BP) neural network model between the factors affecting droplet deposition is trained. The factors affecting droplet deposition include ambient temperature, ambient humidity, wind speed, flight speed, flight altitude, propeller pitch, nozzles pitch and prescription value. Subsequently, the BP neural network model is combined with variable rate spray control for plant protection UAVs, and real-time information is collected by multi-sensor. The deposition rate is determined by the neural network model, and the flow rate of the spray system is regulated according to the predicted deposition amount. The amount of droplet deposition can meet the prescription requirement. The results show that the training variance of the ANN is 0.003, and thus, the model is stable and reliable. The outdoor tests show that the error between the predicted droplet deposition and actual droplet deposition is less than 20%. The ratio of droplet deposition to prescription value in each unit is approximately equal, and a variable spray operation under different conditions is realized.},
DOI = {10.3390/s19051112}
}



@Article{s19051119,
AUTHOR = {Hernandez Bennetts, Victor and Kamarudin, Kamarulzaman and Wiedemann, Thomas and Kucner, Tomasz Piotr and Somisetty, Sai Lokesh and Lilienthal, Achim J.},
TITLE = {Multi-Domain Airflow Modeling and Ventilation Characterization Using Mobile Robots, Stationary Sensors and Machine Learning},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {1119},
URL = {https://www.mdpi.com/1424-8220/19/5/1119},
ISSN = {1424-8220},
ABSTRACT = {Ventilation systems are critically important components of many public buildings and workspaces. Proper ventilation is often crucial for preventing accidents, such as explosions in mines and avoiding health issues, for example, through long-term exposure to harmful respirable matter. Validation and maintenance of ventilation systems is thus of key interest for plant operators and authorities. However, methods for ventilation characterization, which allow us to monitor whether the ventilation system in place works as desired, hardly exist. This article addresses the critical challenge of ventilation characterization&mdash;measuring and modelling air flow at micro-scales&mdash;that is, creating a high-resolution model of wind speed and direction from airflow measurements. Models of the near-surface micro-scale flow fields are not only useful for ventilation characterization, but they also provide critical information for planning energy-efficient paths for aerial robots and many applications in mobile robot olfaction. In this article we propose a heterogeneous measurement system composed of static, continuously sampling sensing nodes, complemented by localized measurements, collected during occasional sensing missions with a mobile robot. We introduce a novel, data-driven, multi-domain airflow modelling algorithm that estimates (1) fields of posterior distributions over wind direction and speed (&ldquo;ventilation maps&rdquo;, spatial domain); (2) sets of ventilation calendars that capture the evolution of important airflow characteristics at measurement positions (temporal domain); and (3) a frequency domain analysis that can reveal periodic changes of airflow in the environment. The ventilation map and the ventilation calendars make use of an improved estimation pipeline that incorporates a wind sensor model and a transition model to better filter out sporadic, noisy airflow changes. These sudden changes may originate from turbulence or irregular activity in the surveyed environment and can, therefore, disturb modelling of the relevant airflow patterns. We tested the proposed multi-domain airflow modelling approach with simulated data and with experiments in a semi-controlled environment and present results that verify the accuracy of our approach and its sensitivity to different turbulence levels and other disturbances. Finally, we deployed the proposed system in two different real-world industrial environments (foundry halls) with different ventilation regimes for three weeks during full operation. Since airflow ground truth cannot be obtained, we present a qualitative discussion of the generated airflow models with plant operators, who concluded that the computed models accurately depicted the expected airflow patterns and are useful to understand how pollutants spread in the work environment. This analysis may then provide the basis for decisions about corrective actions to avoid long-term exposure of workers to harmful respirable matter.},
DOI = {10.3390/s19051119}
}



@Article{fi11030065,
AUTHOR = {Li, Yang and Shi, Leyi and Feng, Haijie},
TITLE = {A Game-Theoretic Analysis for Distributed Honeypots},
JOURNAL = {Future Internet},
VOLUME = {11},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {65},
URL = {https://www.mdpi.com/1999-5903/11/3/65},
ISSN = {1999-5903},
ABSTRACT = {A honeypot is a decoy tool for luring an attacker and interacting with it, further consuming its resources. Due to its fake property, a honeypot can be recognized by the adversary and loses its value. Honeypots equipped with dynamic characteristics are capable of deceiving intruders. However, most of their dynamic properties are reflected in the system configuration, rather than the location. Dynamic honeypots are faced with the risk of being identified and avoided. In this paper, we focus on the dynamic locations of honeypots and propose a distributed honeypot scheme. By periodically changing the services, the attacker cannot distinguish the real services from honeypots, and the illegal attack flow can be recognized. We adopt game theory to illustrate the effectiveness of our system. Gambit simulations are conducted to validate our proposed scheme. The game-theoretic reasoning shows that our system comprises an innovative system defense. Further simulation results prove that the proposed scheme improves the server’s payoff and that the attacker tends to abandon launching attacks. Therefore, the proposed distributed honeypot scheme is effective for network security.},
DOI = {10.3390/fi11030065}
}



@Article{rs11050544,
AUTHOR = {Fu, Kun and Dai, Wei and Zhang, Yue and Wang, Zhirui and Yan, Menglong and Sun, Xian},
TITLE = {MultiCAM: Multiple Class Activation Mapping for Aircraft Recognition in Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {544},
URL = {https://www.mdpi.com/2072-4292/11/5/544},
ISSN = {2072-4292},
ABSTRACT = {Aircraft recognition in remote sensing images has long been a meaningful topic. Most related methods treat entire images as a whole and do not concentrate on the features of parts. In fact, a variety of aircraft types have small interclass variance, and the main evidence for classifying subcategories is related to some discriminative object parts. In this paper, we introduce the idea of fine-grained visual classification (FGVC) and attempt to make full use of the features from discriminative object parts. First, multiple class activation mapping (MultiCAM) is proposed to extract the discriminative parts of aircrafts of different categories. Second, we present a mask filter (MF) strategy to enhance the discriminative object parts and filter the interference of the background from original images. Third, a selective connected feature fusion method is proposed to fuse the features extracted from both networks, focusing on the original images and the results of MF, respectively. Compared with the single prediction category in class activation mapping (CAM), MultiCAM makes full use of the predictions of all categories to overcome the wrong discriminative parts produced by a wrong single prediction category. Additionally, the designed MF preserves the object scale information and helps the network to concentrate on the object itself rather than the interfering background. Experiments on a challenging dataset prove that our method can achieve state-of-the-art performance.},
DOI = {10.3390/rs11050544}
}



@Article{rs11050545,
AUTHOR = {Stavrakoudis, Dimitris and Katsantonis, Dimitrios and Kadoglidou, Kalliopi and Kalaitzidis, Argyris and Gitas, Ioannis Z.},
TITLE = {Estimating Rice Agronomic Traits Using Drone-Collected Multispectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {545},
URL = {https://www.mdpi.com/2072-4292/11/5/545},
ISSN = {2072-4292},
ABSTRACT = {The knowledge of rice nitrogen (N) requirements and uptake capacity are fundamental for the development of improved N management. This paper presents empirical models for predicting agronomic traits that are relevant to yield and N requirements of rice (Oryza sativa L.) through remotely sensed data. Multiple linear regression models were constructed at key growth stages (at tillering and at booting), using as input reflectance values and vegetation indices obtained from a compact multispectral sensor (green, red, red-edge, and near-infrared channels) onboard an unmanned aerial vehicle (UAV). The models were constructed using field data and images from two consecutive years in a number of experimental rice plots in Greece (Thessaloniki Regional Unit), by applying four different N treatments (C0: 0 N kg∙ha&minus;1, C1: 80 N kg∙ha&minus;1, C2: 160 N kg∙ha&minus;1, and C4: 320 N kg∙ha&minus;1). Models for estimating the current crop status (e.g., N uptake at the time of image acquisition) and predicting the future one (e.g., N uptake of grains at maturity) were developed and evaluated. At the tillering stage, high accuracies (R2 &ge; 0.8) were achieved for N uptake and biomass. At the booting stage, similarly high accuracies were achieved for yield, N concentration, N uptake, biomass, and plant height, using inputs from either two or three images. The results of the present study can be useful for providing N recommendations for the two top-dressing fertilizations in rice cultivation, through a cost-efficient workflow.},
DOI = {10.3390/rs11050545}
}



@Article{f10030235,
AUTHOR = {Carl, Christin and Lehmann, Jan R. K. and Landgraf, Dirk and Pretzsch, Hans},
TITLE = {Robinia pseudoacacia L. in Short Rotation Coppice: Seed and Stump Shoot Reproduction as well as UAS-based Spreading Analysis},
JOURNAL = {Forests},
VOLUME = {10},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {235},
URL = {https://www.mdpi.com/1999-4907/10/3/235},
ISSN = {1999-4907},
ABSTRACT = {Varying reproduction strategies are an important trait that tree species need in order both to survive and to spread. Black locust is able to reproduce via seeds, stump shoots, and root suckers. However, little research has been conducted on the reproduction and spreading of black locust in short rotation coppices. This research study focused on seed germination, stump shoot resprout, and spreading by root suckering of black locust in ten short rotation coppices in Germany. Seed experiments and sample plots were analyzed for the study. Spreading was detected and measured with unmanned aerial system (UAS)-based images and classification technology&mdash;object-based image analysis (OBIA). Additionally, the classification of single UAS images was tested by applying a convolutional neural network (CNN), a deep learning model. The analyses showed that seed germination increases with increasing warm-cold variety and scarification. Moreover, it was found that the number of shoots per stump decreases as shoot age increases. Furthermore, spreading increases with greater light availability and decreasing tillage. The OBIA and CNN image analysis technologies achieved 97% and 99.5% accuracy for black locust classification in UAS images. All in all, the three reproduction strategies of black locust in short rotation coppices differ with regards to initialization, intensity, and growth performance, but all play a role in the survival and spreading of black locust.},
DOI = {10.3390/f10030235}
}



@Article{agronomy9030126,
AUTHOR = {Pratap, Aditya and Gupta, Sanjeev and Nair, Ramakrishnan Madhavan and Gupta, S. K. and Schafleitner, Roland and Basu, P. S. and Singh, Chandra Mohan and Prajapati, Umashanker and Gupta, Ajeet Kumar and Nayyar, Harsh and Mishra, Awdhesh Kumar and Baek, Kwang-Hyun},
TITLE = {Using Plant Phenomics to Exploit the Gains of Genomics},
JOURNAL = {Agronomy},
VOLUME = {9},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {126},
URL = {https://www.mdpi.com/2073-4395/9/3/126},
ISSN = {2073-4395},
ABSTRACT = {Agricultural scientists face the dual challenge of breeding input-responsive, widely adoptable and climate-resilient varieties of crop plants and developing such varieties at a faster pace. Integrating the gains of genomics with modern-day phenomics will lead to increased breeding efficiency which in turn offers great promise to develop such varieties rapidly. Plant phenotyping techniques have impressively evolved during the last two decades. The low-cost, automated and semi-automated methods for data acquisition, storage and analysis are now available which allow precise quantitative analysis of plant structure and function; and genetic dissection of complex traits. Appropriate plant types can now be quickly developed that respond favorably to low input and resource-limited environments and address the challenges of subsistence agriculture. The present review focuses on the need of systematic, rapid, minimal invasive and low-cost plant phenotyping. It also discusses its evolution to modern day high throughput phenotyping (HTP), traits amenable to HTP, integration of HTP with genomics and the scope of utilizing these tools for crop improvement.},
DOI = {10.3390/agronomy9030126}
}



@Article{drones3010025,
AUTHOR = {Heim, René H.J. and Wright, Ian J. and Scarth, Peter and Carnegie, Angus J. and Taylor, Dominique and Oldeland, Jens},
TITLE = {Multispectral, Aerial Disease Detection for Myrtle Rust (Austropuccinia psidii) on a Lemon Myrtle Plantation},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {25},
URL = {https://www.mdpi.com/2504-446X/3/1/25},
ISSN = {2504-446X},
ABSTRACT = {Disease management in agriculture often assumes that pathogens are spread homogeneously across crops. In practice, pathogens can manifest in patches. Currently, disease detection is predominantly carried out by human assessors, which can be slow and expensive. A remote sensing approach holds promise. Current satellite sensors are not suitable to spatially resolve individual plants or lack temporal resolution to monitor pathogenesis. Here, we used multispectral imaging and unmanned aerial systems (UAS) to explore whether myrtle rust (Austropuccinia psidii) could be detected on a lemon myrtle (Backhousia citriodora) plantation. Multispectral aerial imagery was collected from fungicide treated and untreated tree canopies, the fungicide being used to control myrtle rust. Spectral vegetation indices and single spectral bands were used to train a random forest classifier. Treated and untreated trees could be classified with high accuracy (95%). Important predictors for the classifier were the near-infrared (NIR) and red edge (RE) spectral band. Taking some limitations into account, that are discussedherein, our work suggests potential for mapping myrtle rust-related symptoms from aerial multispectral images. Similar studies could focus on pinpointing disease hotspots to adjust management strategies and to feed epidemiological models.},
DOI = {10.3390/drones3010025}
}



@Article{rs11060603,
AUTHOR = {Fang, Lei and Crocker, Ellen V. and Yang, Jian and Yan, Yan and Yang, Yuanzheng and Liu, Zhihua},
TITLE = {Competition and Burn Severity Determine Post-Fire Sapling Recovery in a Nationally Protected Boreal Forest of China: An Analysis from Very High-Resolution Satellite Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {603},
URL = {https://www.mdpi.com/2072-4292/11/6/603},
ISSN = {2072-4292},
ABSTRACT = {Anticipating how boreal forest landscapes will change in response to changing fire regime requires disentangling the effects of various spatial controls on the recovery process of tree saplings. Spatially explicit monitoring of post-fire vegetation recovery through moderate resolution Landsat imagery is a popular technique but is filled with ambiguous information due to mixed pixel effects. On the other hand, very-high resolution (VHR) satellite imagery accurately measures crown size of tree saplings but has gained little attention and its utility for estimating leaf area index (LAI, m2/m2) and tree sapling abundance (TSA, seedlings/ha) in post-fire landscape remains untested. We compared the explanatory power of 30 m Landsat satellite imagery with 0.5-m WorldView-2 VHR imagery for LAI and TSA based on field sampling data, and subsequently mapped the distribution of LAI and TSA based on the most predictive relationships. A random forest (RF) model was applied to assess the relative importance and causal mechanisms of spatial controls on tree sapling recovery. The results showed that pixel percentage of canopy trees (PPCT) derived from VHR imagery outperform all Landsat-derived spectral indices for explaining variance of LAI (R2VHR = 0.676 vs. R2Landsat = 0.427) and TSA (R2VHR = 0.508 vs. R2Landsat = 0.499). The RF model explained an average of 55.5% (SD = 3.0%, MSE = 0.382, N = 50) of the variation of estimated LAI. Understory vegetation coverage (competition) and post-fire surviving mature trees (seed sources) were the most important spatial controls for LAI recovery, followed by burn severity (legacy effect), topographic factors (environmental filter) and nearest distance to unburned area (edge effect). These analyses allow us to conclude that in our study area, mitigating wildfire severity and size may increase forest resilience to wildfire damage. Given the easily-damaged seed banks and relatively short seed dispersal distance of coniferous trees, reasonable human help to natural recovery of coniferous forests is necessary for severe burns with a large patch size, particularly in certain areas. Our research shows the VHR WorldView-2 imagery better resolves key characteristics of forest landscapes like LAI and TSA than Landsat imagery, providing a valuable tool for land managers and researchers alike.},
DOI = {10.3390/rs11060603}
}



@Article{rs11060610,
AUTHOR = {Li, Tuan and Zhang, Hongping and Gao, Zhouzheng and Niu, Xiaoji and El-sheimy, Naser},
TITLE = {Tight Fusion of a Monocular Camera, MEMS-IMU, and Single-Frequency Multi-GNSS RTK for Precise Navigation in GNSS-Challenged Environments},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {610},
URL = {https://www.mdpi.com/2072-4292/11/6/610},
ISSN = {2072-4292},
ABSTRACT = {Precise position, velocity, and attitude is essential for self-driving cars and unmanned aerial vehicles (UAVs). The integration of global navigation satellite system (GNSS) real-time kinematics (RTK) and inertial measurement units (IMUs) is able to provide high-accuracy navigation solutions in open-sky conditions, but the accuracy will be degraded severely in GNSS-challenged environments, especially integrated with the low-cost microelectromechanical system (MEMS) IMUs. In order to navigate in GNSS-denied environments, the visual&ndash;inertial system has been widely adopted due to its complementary characteristics, but it suffers from error accumulation. In this contribution, we tightly integrate the raw measurements from the single-frequency multi-GNSS RTK, MEMS-IMU, and monocular camera through the extended Kalman filter (EKF) to enhance the navigation performance in terms of accuracy, continuity, and availability. The visual measurement model from the well-known multistate constraint Kalman filter (MSCKF) is combined with the double-differenced GNSS measurement model to update the integration filter. A field vehicular experiment was carried out in GNSS-challenged environments to evaluate the performance of the proposed algorithm. Results indicate that both multi-GNSS and vision contribute significantly to the centimeter-level positioning availability in GNSS-challenged environments. Meanwhile, the velocity and attitude accuracy can be greatly improved by using the tightly-coupled multi-GNSS RTK/INS/Vision integration, especially for the yaw angle.},
DOI = {10.3390/rs11060610}
}



@Article{data4010040,
AUTHOR = {Asadi, Khashayar and Chen, Pengyu and Han, Kevin and Wu, Tianfu and Lobaton, Edgar},
TITLE = {LNSNet: Lightweight Navigable Space Segmentation for Autonomous Robots on Construction Sites},
JOURNAL = {Data},
VOLUME = {4},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {40},
URL = {https://www.mdpi.com/2306-5729/4/1/40},
ISSN = {2306-5729},
ABSTRACT = {An autonomous robot that can monitor a construction site should be able to be can contextually detect its surrounding environment by recognizing objects and making decisions based on its observation. Pixel-wise semantic segmentation in real-time is vital to building an autonomous and mobile robot. However, the learning models&rsquo; size and high memory usage associated with real-time segmentation are the main challenges for mobile robotics systems that have limited computing resources. To overcome these challenges, this paper presents an efficient semantic segmentation method named LNSNet (lightweight navigable space segmentation network) that can run on embedded platforms to determine navigable space in real-time. The core of model architecture is a new block based on separable convolution which compresses the parameters of present residual block meanwhile maintaining the accuracy and performance. LNSNet is faster, has fewer parameters and less model size, while provides similar accuracy compared to existing models. A new pixel-level annotated dataset for real-time and mobile navigable space segmentation in construction environments has been constructed for the proposed method. The results demonstrate the effectiveness and efficiency that are necessary for the future development of the autonomous robotics systems.},
DOI = {10.3390/data4010040}
}



@Article{s19061275,
AUTHOR = {Ahn, Sanghyun and Choi, Jonghwa},
TITLE = {Internet of Vehicles and Cost-Effective Traffic Signal Control},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {1275},
URL = {https://www.mdpi.com/1424-8220/19/6/1275},
ISSN = {1424-8220},
ABSTRACT = {The Internet of Vehicles (IoV) is attracting many researchers with the emergence of autonomous or smart vehicles. Vehicles on the road are becoming smart objects equipped with lots of sensors and powerful computing and communication capabilities. In the IoV environment, the efficiency of road transportation can be enhanced with the help of cost-effective traffic signal control. Traffic signal controllers control traffic lights based on the number of vehicles waiting for the green light (in short, vehicle queue length). So far, the utilization of video cameras or sensors has been extensively studied as the intelligent means of the vehicle queue length estimation. However, it has the deficiencies like high computing overhead, high installation and maintenance cost, high susceptibility to the surrounding environment, etc. Therefore, in this paper, we propose the vehicular communication-based approach for intelligent traffic signal control in a cost-effective way with low computing overhead and high resilience to environmental obstacles. In the vehicular communication-based approach, traffic signals are efficiently controlled at no extra cost by using the pre-equipped vehicular communication capabilities of IoV. Vehicular communications allow vehicles to send messages to traffic signal controllers (i.e., vehicle-to-infrastructure (V2I) communications) so that they can estimate vehicle queue length based on the collected messages. In our previous work, we have proposed a mechanism that can accomplish the efficiency of vehicular communications without losing the accuracy of traffic signal control. This mechanism gives transmission preference to the vehicles farther away from the traffic signal controller, so that the other vehicles closer to the stop line give up transmissions. In this paper, we propose a new mechanism enhancing the previous mechanism by selecting the vehicles performing V2I communications based on the concept of road sectorization. In the mechanism, only the vehicles within specific areas, called sectors, perform V2I communications to reduce the message transmission overhead. For the performance comparison of our mechanisms, we carry out simulations by using the Veins vehicular network simulation framework and measure the message transmission overhead and the accuracy of the estimated vehicle queue length. Simulation results verify that our vehicular communication-based approach significantly reduces the message transmission overhead without losing the accuracy of the vehicle queue length estimation.},
DOI = {10.3390/s19061275}
}



@Article{rs11060619,
AUTHOR = {Zhang, Chengming and Han, Yingjuan and Li, Feng and Gao, Shuai and Song, Dejuan and Zhao, Hui and Fan, Keqi and Zhang, Ya’nan},
TITLE = {A New CNN-Bayesian Model for Extracting Improved Winter Wheat Spatial Distribution from GF-2 imagery},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {619},
URL = {https://www.mdpi.com/2072-4292/11/6/619},
ISSN = {2072-4292},
ABSTRACT = {When the spatial distribution of winter wheat is extracted from high-resolution remote sensing imagery using convolutional neural networks (CNN), field edge results are usually rough, resulting in lowered overall accuracy. This study proposed a new per-pixel classification model using CNN and Bayesian models (CNN-Bayesian model) for improved extraction accuracy. In this model, a feature extractor generates a feature vector for each pixel, an encoder transforms the feature vector of each pixel into a category-code vector, and a two-level classifier uses the difference between elements of category-probability vectors as the confidence value to perform per-pixel classifications. The first level is used to determine the category of a pixel with high confidence, and the second level is an improved Bayesian model used to determine the category of low-confidence pixels. The CNN-Bayesian model was trained and tested on Gaofen 2 satellite images. Compared to existing models, our approach produced an improvement in overall accuracy, the overall accuracy of SegNet, DeepLab, VGG-Ex, and CNN-Bayesian was 0.791, 0.852, 0.892, and 0.946, respectively. Thus, this approach can produce superior results when winter wheat spatial distribution is extracted from satellite imagery.},
DOI = {10.3390/rs11060619}
}



@Article{s19061284,
AUTHOR = {Hartling, Sean and Sagan, Vasit and Sidike, Paheding and Maimaitijiang, Maitiniyazi and Carron, Joshua},
TITLE = {Urban Tree Species Classification Using a WorldView-2/3 and LiDAR Data Fusion Approach and Deep Learning},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {1284},
URL = {https://www.mdpi.com/1424-8220/19/6/1284},
ISSN = {1424-8220},
ABSTRACT = {Urban areas feature complex and heterogeneous land covers which create challenging issues for tree species classification. The increased availability of high spatial resolution multispectral satellite imagery and LiDAR datasets combined with the recent evolution of deep learning within remote sensing for object detection and scene classification, provide promising opportunities to map individual tree species with greater accuracy and resolution. However, there are knowledge gaps that are related to the contribution of Worldview-3 SWIR bands, very high resolution PAN band and LiDAR data in detailed tree species mapping. Additionally, contemporary deep learning methods are hampered by lack of training samples and difficulties of preparing training data. The objective of this study was to examine the potential of a novel deep learning method, Dense Convolutional Network (DenseNet), to identify dominant individual tree species in a complex urban environment within a fused image of WorldView-2 VNIR, Worldview-3 SWIR and LiDAR datasets. DenseNet results were compared against two popular machine classifiers in remote sensing image analysis, Random Forest (RF) and Support Vector Machine (SVM). Our results demonstrated that: (1) utilizing a data fusion approach beginning with VNIR and adding SWIR, LiDAR, and panchromatic (PAN) bands increased the overall accuracy of the DenseNet classifier from 75.9% to 76.8%, 81.1% and 82.6%, respectively. (2) DenseNet significantly outperformed RF and SVM for the classification of eight dominant tree species with an overall accuracy of 82.6%, compared to 51.8% and 52% for SVM and RF classifiers, respectively. (3) DenseNet maintained superior performance over RF and SVM classifiers under restricted training sample quantities which is a major limiting factor for deep learning techniques. Overall, the study reveals that DenseNet is more effective for urban tree species classification as it outperforms the popular RF and SVM techniques when working with highly complex image scenes regardless of training sample size.},
DOI = {10.3390/s19061284}
}



@Article{s19061317,
AUTHOR = {Xiu, Supu and Wen, Yuanqiao and Yuan, Haiwen and Xiao, Changshi and Zhan, Wenqiang and Zou, Xiong and Zhou, Chunhui and Shah, Sayed Chhattan},
TITLE = {A Multi-Feature and Multi-Level Matching Algorithm Using Aerial Image and AIS for Vessel Identification},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {1317},
URL = {https://www.mdpi.com/1424-8220/19/6/1317},
ISSN = {1424-8220},
ABSTRACT = {In order to monitor and manage vessels in channels effectively, identification and tracking are very necessary. This work developed a maritime unmanned aerial vehicle (Mar-UAV) system equipped with a high-resolution camera and an Automatic Identification System (AIS). A multi-feature and multi-level matching algorithm using the spatiotemporal characteristics of aerial images and AIS information was proposed to detect and identify field vessels. Specifically, multi-feature information, including position, scale, heading, speed, etc., are used to match between real-time image and AIS message. Additionally, the matching algorithm is divided into two levels, point matching and trajectory matching, for the accurate identification of surface vessels. Through such a matching algorithm, the Mar-UAV system is able to automatically identify the vessel&rsquo;s vision, which improves the autonomy of the UAV in maritime tasks. The multi-feature and multi-level matching algorithm has been employed for the developed Mar-UAV system, and some field experiments have been implemented in the Yangzi River. The results indicated that the proposed matching algorithm and the Mar-UAV system are very significant for achieving autonomous maritime supervision.},
DOI = {10.3390/s19061317}
}



@Article{rs11060643,
AUTHOR = {Safonova, Anastasiia and Tabik, Siham and Alcaraz-Segura, Domingo and Rubtsov, Alexey and Maglinets, Yuriy and Herrera, Francisco},
TITLE = {Detection of Fir Trees (Abies sibirica) Damaged by the Bark Beetle in Unmanned Aerial Vehicle Images with Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {643},
URL = {https://www.mdpi.com/2072-4292/11/6/643},
ISSN = {2072-4292},
ABSTRACT = {Invasion of the Polygraphus proximus Blandford bark beetle causes catastrophic damage to forests with firs (Abies sibirica Ledeb) in Russia, especially in Central Siberia. Determining tree damage stage based on the shape, texture and colour of tree crown in unmanned aerial vehicle (UAV) images could help to assess forest health in a faster and cheaper way. However, this task is challenging since (i) fir trees at different damage stages coexist and overlap in the canopy, (ii) the distribution of fir trees in nature is irregular and hence distinguishing between different crowns is hard, even for the human eye. Motivated by the latest advances in computer vision and machine learning, this work proposes a two-stage solution: In a first stage, we built a detection strategy that finds the regions of the input UAV image that are more likely to contain a crown, in the second stage, we developed a new convolutional neural network (CNN) architecture that predicts the fir tree damage stage in each candidate region. Our experiments show that the proposed approach shows satisfactory results on UAV Red, Green, Blue (RGB) images of forest areas in the state nature reserve “Stolby” (Krasnoyarsk, Russia).},
DOI = {10.3390/rs11060643}
}



@Article{rs11060647,
AUTHOR = {Zang, Yufu and Yang, Bisheng and Li, Jianping and Guan, Haiyan},
TITLE = {An Accurate TLS and UAV Image Point Clouds Registration Method for Deformation Detection of Chaotic Hillside Areas},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {647},
URL = {https://www.mdpi.com/2072-4292/11/6/647},
ISSN = {2072-4292},
ABSTRACT = {Deformation detection determines the quantified change of a scene&rsquo;s geometric state, which is of great importance for the mitigation of hazards and property loss from earth observation. Terrestrial laser scanning (TLS) provides an efficient and flexible solution to rapidly capture high precision three-dimensional (3D) point clouds of hillside areas. Most existing methods apply multi-temporal TLS surveys to detect deformations depending on a variety of ground control points (GCPs). However, on the one hand, the deployment of various GCPs is time-consuming and labor-intensive, particularly for difficult terrain areas. On the other hand, in most cases, TLS stations do not form a closed loop, such that cumulative errors cannot be corrected effectively by the existing methods. To overcome these drawbacks, this paper proposes a deformation detection method with limited GCPs based on a novel registration algorithm that accurately registers TLS stations to the UAV (Unmanned Aerial Vehicle) dense image points. First, the proposed method extracts patch primitives from smoothed hillside points, and adjacent TLS scans are pairwise registered by comparing the geometric and topological information of or between patches. Second, a new multi-station adjustment algorithm is proposed, which makes full use of locally closed loops to reach the global optimal registration. Finally, digital elevation models (DEMs, a DEM is a numerical representation of the terrain surface, formed by height points to represent the topography), slope and aspect maps, and vertical sections are generated from multi-temporal TLS surveys to detect and analyze the deformations. Comprehensive experiments demonstrate that the proposed deformation detection method obtains good performance for the hillside areas with limited (few) GCPs.},
DOI = {10.3390/rs11060647}
}



@Article{app9061128,
AUTHOR = {Li, Yundong and Hu, Wei and Dong, Han and Zhang, Xueyan},
TITLE = {Building Damage Detection from Post-Event Aerial Imagery Using Single Shot Multibox Detector},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {1128},
URL = {https://www.mdpi.com/2076-3417/9/6/1128},
ISSN = {2076-3417},
ABSTRACT = {Using aerial cameras, satellite remote sensing or unmanned aerial vehicles (UAV) equipped with cameras can facilitate search and rescue tasks after disasters. The traditional manual interpretation of huge aerial images is inefficient and could be replaced by machine learning-based methods combined with image processing techniques. Given the development of machine learning, researchers find that convolutional neural networks can effectively extract features from images. Some target detection methods based on deep learning, such as the single-shot multibox detector (SSD) algorithm, can achieve better results than traditional methods. However, the impressive performance of machine learning-based methods results from the numerous labeled samples. Given the complexity of post-disaster scenarios, obtaining many samples in the aftermath of disasters is difficult. To address this issue, a damaged building assessment method using SSD with pretraining and data augmentation is proposed in the current study and highlights the following aspects. (1) Objects can be detected and classified into undamaged buildings, damaged buildings, and ruins. (2) A convolution auto-encoder (CAE) that consists of VGG16 is constructed and trained using unlabeled post-disaster images. As a transfer learning strategy, the weights of the SSD model are initialized using the weights of the CAE counterpart. (3) Data augmentation strategies, such as image mirroring, rotation, Gaussian blur, and Gaussian noise processing, are utilized to augment the training data set. As a case study, aerial images of Hurricane Sandy in 2012 were maximized to validate the proposed method&rsquo;s effectiveness. Experiments show that the pretraining strategy can improve of 10% in terms of overall accuracy compared with the SSD trained from scratch. These experiments also demonstrate that using data augmentation strategies can improve mAP and mF1 by 72% and 20%, respectively. Finally, the experiment is further verified by another dataset of Hurricane Irma, and it is concluded that the paper method is feasible.},
DOI = {10.3390/app9061128}
}



@Article{s19061345,
AUTHOR = {Leung, Carson K. and Braun, Peter and Cuzzocrea, Alfredo},
TITLE = {AI-Based Sensor Information Fusion for Supporting Deep Supervised Learning},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {1345},
URL = {https://www.mdpi.com/1424-8220/19/6/1345},
ISSN = {1424-8220},
ABSTRACT = {In recent years, artificial intelligence (AI) and its subarea of deep learning have drawn the attention of many researchers. At the same time, advances in technologies enable the generation or collection of large amounts of valuable data (e.g., sensor data) from various sources in different applications, such as those for the Internet of Things (IoT), which in turn aims towards the development of smart cities. With the availability of sensor data from various sources, sensor information fusion is in demand for effective integration of big data. In this article, we present an AI-based sensor-information fusion system for supporting deep supervised learning of transportation data generated and collected from various types of sensors, including remote sensed imagery for the geographic information system (GIS), accelerometers, as well as sensors for the global navigation satellite system (GNSS) and global positioning system (GPS). The discovered knowledge and information returned from our system provides analysts with a clearer understanding of trajectories or mobility of citizens, which in turn helps to develop better transportation models to achieve the ultimate goal of smarter cities. Evaluation results show the effectiveness and practicality of our AI-based sensor information fusion system for supporting deep supervised learning of big transportation data.},
DOI = {10.3390/s19061345}
}



@Article{f10030273,
AUTHOR = {Surový, Peter and Kuželka, Karel},
TITLE = {Acquisition of Forest Attributes for Decision Support at the Forest Enterprise Level Using Remote-Sensing Techniques—A Review},
JOURNAL = {Forests},
VOLUME = {10},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {273},
URL = {https://www.mdpi.com/1999-4907/10/3/273},
ISSN = {1999-4907},
ABSTRACT = {In recent decades, remote sensing techniques and the associated hardware and software have made substantial improvements. With satellite images that can obtain sub-meter spatial resolution, and new hardware, particularly unmanned aerial vehicles and systems, there are many emerging opportunities for improved data acquisition, including variable temporal and spectral resolutions. Combined with the evolution of techniques for aerial remote sensing, such as full wave laser scanners, hyperspectral scanners, and aerial radar sensors, the potential to incorporate this new data in forest management is enormous. Here we provide an overview of the current state-of-the-art remote sensing techniques for large forest areas thousands or tens of thousands of hectares. We examined modern remote sensing techniques used to obtain forest data that are directly applicable to decision making issues, and we provided a general overview of the types of data that can be obtained using remote sensing. The most easily accessible forest variable described in many works is stand or tree height, followed by other inventory variables like basal area, tree number, diameters, and volume, which are crucial in decision making process, especially for thinning and harvest planning, and timber transport optimization. Information about zonation and species composition are often described as more difficult to assess; however, this information usually is not required on annual basis. Counts of studies on forest health show an increasing trend in the last years, mostly in context of availability of new sensors as well as increased forest vulnerability caused by climate change; by virtue to modern sensors interesting methods were developed for detection of stressed or damaged trees. Unexpectedly few works focus on regeneration and seedlings evaluation; though regenerated stands should be regularly monitored in order to maintain forest cover sustainability.},
DOI = {10.3390/f10030273}
}



@Article{rs11060670,
AUTHOR = {Banks, Sarah and White, Lori and Behnamian, Amir and Chen, Zhaohua and Montpetit, Benoit and Brisco, Brian and Pasher, Jon and Duffe, Jason},
TITLE = {Wetland Classification with Multi-Angle/Temporal SAR Using Random Forests},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {670},
URL = {https://www.mdpi.com/2072-4292/11/6/670},
ISSN = {2072-4292},
ABSTRACT = {To better understand and mitigate threats to the long-term health and functioning of wetlands, there is need to establish comprehensive inventorying and monitoring programs. Here, remote sensing data and machine learning techniques that could support or substitute traditional field-based data collection are evaluated. For the Bay of Quinte on Lake Ontario, Canada, different combinations of multi-angle/temporal quad pol RADARSAT-2, simulated compact pol RADARSAT Constellation Mission (RCM), and high and low spatial resolution Digital Elevation and Surface Models (DEM and DSM, respectively) were used to classify six land cover classes with Random Forests: shallow water, marsh, swamp, water, forest, and agriculture/non-forested. Results demonstrate that high accuracies can be achieved with multi-temporal SAR data alone (e.g., user&rsquo;s and producer&rsquo;s accuracies &ge;90% for a model based on a spring image and a summer image), or via fusion of SAR and DEM and DSM data for single dates/incidence angles (e.g., user&rsquo;s and producer&rsquo;s accuracies &ge;90% for a model based on a spring image, DEM, and DSM data). For all models based on single SAR images, simulated compact pol data generally achieved lower accuracies than quad pol RADARSAT-2 data. However, it was possible to compensate for observed differences through either multi-temporal/angle data fusion or the inclusion of DEM and DSM data (i.e., as a result, there was not a statistically significant difference between multiple models). With a higher repeat-pass cycle than RADARSAT-2, RCM is expected to be a reliable source of C-band SAR data that will contribute positively to ongoing efforts to inventory wetlands and monitor change in areas containing the same land cover classes evaluated here.},
DOI = {10.3390/rs11060670}
}



@Article{s19061379,
AUTHOR = {Hummel, Karin Anna and Pollak, Manuela and Krahofer, Johannes},
TITLE = {A Distributed Architecture for Human-Drone Teaming: Timing Challenges and Interaction Opportunities},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {1379},
URL = {https://www.mdpi.com/1424-8220/19/6/1379},
ISSN = {1424-8220},
ABSTRACT = {Drones are expected to operate autonomously, yet they will also interact with humans to solve tasks together. To support civilian human-drone teams, we propose a distributed architecture where sophisticated operations such as image recognition, coordination with humans, and flight-control decisions are made, not on-board the drone, but remotely. The benefits of such an architecture are the increased computational power available for image recognition and the possibility to integrate interfaces for humans. On the downside, communication is necessary, resulting in the delayed reception of commands. In this article, we discuss the design considerations of the distributed approach, a sample implementation on a smartphone, and an application to the concrete use case of bookshelf inventory. Further, we report experimentally-derived first insights into messaging and command response delays with a custom drone connected through Wi-Fi.},
DOI = {10.3390/s19061379}
}



@Article{ijgi8030150,
AUTHOR = {Lim, Joongbin and Kim, Kyoung-Min and Jin, Ri},
TITLE = {Tree Species Classification Using Hyperion and Sentinel-2 Data with Machine Learning in South Korea and China},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {8},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {150},
URL = {https://www.mdpi.com/2220-9964/8/3/150},
ISSN = {2220-9964},
ABSTRACT = {Remote sensing (RS) has been used to monitor inaccessible regions. It is considered a useful technique for deriving important environmental information from inaccessible regions, especially North Korea. In this study, we aim to develop a tree species classification model based on RS and machine learning techniques, which can be utilized for classification in North Korea. Two study sites were chosen, the Korea National Arboretum (KNA) in South Korea and Mt. Baekdu (MTB; a.k.a., Mt. Changbai in Chinese) in China, located in the border area between North Korea and China, and tree species classifications were examined in both regions. As a preliminary step in developing a classification algorithm that can be applied in North Korea, common coniferous species at both study sites, Korean pine (Pinus koraiensis) and Japanese larch (Larix kaempferi), were chosen as targets for investigation. Hyperion data have been used for tree species classification due to the abundant spectral information acquired from across more than 200 spectral bands (i.e., hyperspectral satellite data). However, it is impossible to acquire recent Hyperion data because the satellite ceased operation in 2017. Recently, Sentinel-2 satellite multispectral imagery has been used in tree species classification. Thus, it is necessary to compare these two kinds of satellite data to determine the possibility of reliably classifying species. Therefore, Hyperion and Sentinel-2 data were employed, along with machine learning techniques, such as random forests (RFs) and support vector machines (SVMs), to classify tree species. Three questions were answered, showing that: (1) RF and SVM are well established in the hyperspectral imagery for tree species classification, (2) Sentinel-2 data can be used to classify tree species with RF and SVM algorithms instead of Hyperion data, and (3) training data that were built in the KNA cannot be used for the tree classification of MTB. Random forests and SVMs showed overall accuracies of 0.60 and 0.51 and kappa values of 0.20 and 0.00, respectively. Moreover, combined training data from the KNA and MTB showed high classification accuracies in both regions; RF and SVM values exhibited accuracies of 0.99 and 0.97 and kappa values of 0.98 and 0.95, respectively.},
DOI = {10.3390/ijgi8030150}
}



@Article{rs11060676,
AUTHOR = {Angelopoulou, Theodora and Tziolas, Nikolaos and Balafoutis, Athanasios and Zalidis, George and Bochtis, Dionysis},
TITLE = {Remote Sensing Techniques for Soil Organic Carbon Estimation: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {676},
URL = {https://www.mdpi.com/2072-4292/11/6/676},
ISSN = {2072-4292},
ABSTRACT = {Towards the need for sustainable development, remote sensing (RS) techniques in the Visible-Near Infrared&ndash;Shortwave Infrared (VNIR&ndash;SWIR, 400&ndash;2500 nm) region could assist in a more direct, cost-effective and rapid manner to estimate important indicators for soil monitoring purposes. Soil reflectance spectroscopy has been applied in various domains apart from laboratory conditions, e.g., sensors mounted on satellites, aircrafts and Unmanned Aerial Systems. The aim of this review is to illustrate the research made for soil organic carbon estimation, with the use of RS techniques, reporting the methodology and results of each study. It also aims to provide a comprehensive introduction in soil spectroscopy for those who are less conversant with the subject. In total, 28 journal articles were selected and further analysed. It was observed that prediction accuracy reduces from Unmanned Aerial Systems (UASs) to satellite platforms, though advances in machine learning techniques could further assist in the generation of better calibration models. There are some challenges concerning atmospheric, radiometric and geometric corrections, vegetation cover, soil moisture and roughness that still need to be addressed. The advantages and disadvantages of each approach are highlighted and future considerations are also discussed at the end.},
DOI = {10.3390/rs11060676}
}



@Article{f10030279,
AUTHOR = {Mauya, Ernest William and Koskinen, Joni and Tegel, Katri and Hämäläinen, Jarno and Kauranne, Tuomo and Käyhkö, Niina},
TITLE = {Modelling and Predicting the Growing Stock Volume in Small-Scale Plantation Forests of Tanzania Using Multi-Sensor Image Synergy},
JOURNAL = {Forests},
VOLUME = {10},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {279},
URL = {https://www.mdpi.com/1999-4907/10/3/279},
ISSN = {1999-4907},
ABSTRACT = {Remotely sensed assisted forest inventory has emerged in the past decade as a robust and cost efficient method for generating accurate information on forest biophysical parameters. The launching and public access of ALOS PALSAR-2, Sentinel-1 (SAR), and Sentinel-2 together with the associated open-source software, has further increased the opportunity for application of remotely sensed data in forest inventories. In this study, we evaluated the ability of ALOS PALSAR-2, Sentinel-1 (SAR) and Sentinel-2 and their combinations to predict growing stock volume in small-scale forest plantations of Tanzania. The effects of two variable extraction approaches (i.e., centroid and weighted mean), seasonality (i.e., rainy and dry), and tree species on the prediction accuracy of growing stock volume when using each of the three remotely sensed data were also investigated. Statistical models relating growing stock volume and remotely sensed predictor variables at the plot-level were fitted using multiple linear regression. The models were evaluated using the k-fold cross validation and judged based on the relative root mean square error values (RMSEr). The results showed that: Sentinel-2 (RMSEr = 42.03% and pseudo &minus; R2 = 0.63) and the combination of Sentinel-1 and Sentinel-2 (RMSEr = 46.98% and pseudo &minus; R2 = 0.52), had better performance in predicting growing stock volume, as compared to Sentinel-1 (RMSEr = 59.48% and pseudo &minus; R2 = 0.18) alone. Models fitted with variables extracted from the weighted mean approach, turned out to have relatively lower RMSEr % values, as compared to centroid approaches. Sentinel-2 rainy season based models had slightly smaller RMSEr values, as compared to dry season based models. Dense time series (i.e., annual) data resulted to the models with relatively lower RMSEr values, as compared to seasonal based models when using variables extracted from the weighted mean approach. For the centroid approach there was no notable difference between the models fitted using dense time series versus rain season based predictor variables. Stratifications based on tree species resulted into lower RMSEr values for Pinus patula tree species, as compared to other tree species. Finally, our study concluded that combination of Sentinel-1&amp;2 as well as the use Sentinel-2 alone can be considered for remote-sensing assisted forest inventory in the small-scale plantation forests of Tanzania. Further studies on the effect of field plot size, stratification and statistical methods on the prediction accuracy are recommended.},
DOI = {10.3390/f10030279}
}



@Article{rs11060690,
AUTHOR = {Liu, Shengjie and Qi, Zhixin and Li, Xia and Yeh, Anthony Gar-On},
TITLE = {Integration of Convolutional Neural Networks and Object-Based Post-Classification Refinement for Land Use and Land Cover Mapping with Optical and SAR Data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {690},
URL = {https://www.mdpi.com/2072-4292/11/6/690},
ISSN = {2072-4292},
ABSTRACT = {Object-based image analysis (OBIA) has been widely used for land use and land cover (LULC) mapping using optical and synthetic aperture radar (SAR) images because it can utilize spatial information, reduce the effect of salt and pepper, and delineate LULC boundaries. With recent advances in machine learning, convolutional neural networks (CNNs) have become state-of-the-art algorithms. However, CNNs cannot be easily integrated with OBIA because the processing unit of CNNs is a rectangular image, whereas that of OBIA is an irregular image object. To obtain object-based thematic maps, this study developed a new method that integrates object-based post-classification refinement (OBPR) and CNNs for LULC mapping using Sentinel optical and SAR data. After producing the classification map by CNN, each image object was labeled with the most frequent land cover category of its pixels. The proposed method was tested on the optical-SAR Sentinel Guangzhou dataset with 10 m spatial resolution, the optical-SAR Zhuhai-Macau local climate zones (LCZ) dataset with 100 m spatial resolution, and a hyperspectral benchmark the University of Pavia with 1.3 m spatial resolution. It outperformed OBIA support vector machine (SVM) and random forest (RF). SVM and RF could benefit more from the combined use of optical and SAR data compared with CNN, whereas spatial information learned by CNN was very effective for classification. With the ability to extract spatial features and maintain object boundaries, the proposed method considerably improved the classification accuracy of urban ground targets. It achieved overall accuracy (OA) of 95.33% for the Sentinel Guangzhou dataset, OA of 77.64% for the Zhuhai-Macau LCZ dataset, and OA of 95.70% for the University of Pavia dataset with only 10 labeled samples per class.},
DOI = {10.3390/rs11060690}
}



@Article{rs11060691,
AUTHOR = {Wu, Jintao and Yang, Guijun and Yang, Xiaodong and Xu, Bo and Han, Liang and Zhu, Yaohui},
TITLE = {Automatic Counting of in situ Rice Seedlings from UAV Images Based on a Deep Fully Convolutional Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {691},
URL = {https://www.mdpi.com/2072-4292/11/6/691},
ISSN = {2072-4292},
ABSTRACT = {The number of rice seedlings in the field is one of the main agronomic components for determining rice yield. This counting task, however, is still mainly performed using human vision rather than computer vision and is thus cumbersome and time-consuming. A fast and accurate alternative method of acquiring such data may contribute to monitoring the efficiency of crop management practices, to earlier estimations of rice yield, and as a phenotyping trait in breeding programs. In this paper, we propose an efficient method that uses computer vision to accurately count rice seedlings in a digital image. First, an unmanned aerial vehicle (UAV) equipped with red-green-blue (RGB) cameras was used to acquire field images at the seedling stage. Next, we use a regression network (Basic Network) inspired by a deep fully convolutional neural network to regress the density map and estimate the number of rice seedlings for a given UAV image. Finally, an improved version of the Basic Network, the Combined Network, is also proposed to further improve counting accuracy. To explore the efficacy of the proposed method, a novel rice seedling counting (RSC) dataset was built, which consisted of 40 images (where the number of seedlings varied between 3732 and 16,173) and corresponding manually-dotted annotations. The results demonstrated high average accuracy (higher than 93%) between counts according to the proposed method and manual (UAV image-based) rice seedling counts, and very good performance, with a high coefficient of determination (R2) (around 0.94). In conclusion, the results indicate that the proposed method is an efficient alternative for large-scale counting of rice seedlings, and offers a new opportunity for yield estimation. The RSC dataset and source code are available online.},
DOI = {10.3390/rs11060691}
}



@Article{land8030052,
AUTHOR = {Robinson, Eugene S. and Yang, Xi and Lee, Jung-Eun},
TITLE = {Ecosystem Productivity and Water Stress in Tropical East Africa: A Case Study of the 2010–2011 Drought},
JOURNAL = {Land},
VOLUME = {8},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {52},
URL = {https://www.mdpi.com/2073-445X/8/3/52},
ISSN = {2073-445X},
ABSTRACT = {Characterizing the spatiotemporal patterns of ecosystem responses to drought is important in understanding the impact of water stress on tropical ecosystems and projecting future land cover transitions in the East African tropics. Through the analysis of satellite measurements of solar-induced chlorophyll fluorescence (SIF) and the normalized difference vegetation index (NDVI), soil moisture, rainfall, and reanalysis data, here we characterize the 2010&ndash;2011 drought in tropical East Africa. The 2010&ndash;2011 drought included the consecutive failure of rainy seasons in October&ndash;November&ndash;December 2010 and March&ndash;April&ndash;May 2011 and extended further east and south compared with previous regional droughts. During 2010&ndash;2011, SIF, a proxy of ecosystem productivity, showed a concomitant decline (~32% lower gross primary productivity, or GPP, based on an empirical SIF&ndash;GPP relationship, as compared to the long-term average) with water stress, expressed by lower precipitation and soil moisture. Both SIF and NDVI showed a negative response to drought, and SIF captured the response to soil moisture with a lag of 16 days, even if it had lower spatial resolution and much smaller energy compared with NDVI, suggesting that SIF can also serve as an early indicator of drought in the future. This work demonstrates the unique characteristics of the 2010&ndash;2011 East African drought and the ability of SIF and NDVI to track the levels of water stress during the drought.},
DOI = {10.3390/land8030052}
}



@Article{en12061139,
AUTHOR = {Nguyen, Ngoc Phi and Hong, Sung Kyung},
TITLE = {Fault Diagnosis and Fault-Tolerant Control Scheme for Quadcopter UAVs with a Total Loss of Actuator},
JOURNAL = {Energies},
VOLUME = {12},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {1139},
URL = {https://www.mdpi.com/1996-1073/12/6/1139},
ISSN = {1996-1073},
ABSTRACT = {Fault-tolerant control has drawn attention in recent years owning to its reliability and safe flight during missions. In this article, an active fault-tolerant control method is proposed to control a quadcopter in the presence of actuator faults and disturbances. Firstly, the dynamics of the quadcopter are presented. Secondly, a robust adaptive sliding mode Thau observer is presented to estimate the time-varying magnitudes of actuator faults. Thirdly, a fault-tolerant control scheme based on sliding mode control and reconfiguration technique is designed to maintain the quadcopter at the desired position despite the presence of faults. Unlike previous studies, the proposed method aims to integrate the fault diagnosis and a fault-tolerant control scheme into a single unit with total loss of actuator. Simulation results illustrate the efficiency of the suggested algorithm.},
DOI = {10.3390/en12061139}
}



@Article{rs11060714,
AUTHOR = {Salgadoe, Arachchige Surantha Ashan and Robson, Andrew James and Lamb, David William and Schneider, Derek},
TITLE = {A Non-Reference Temperature Histogram Method for Determining Tc from Ground-Based Thermal Imagery of Orchard Tree Canopies},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {714},
URL = {https://www.mdpi.com/2072-4292/11/6/714},
ISSN = {2072-4292},
ABSTRACT = {Obtaining average canopy temperature (Tc) by thresholding canopy pixels from on-ground thermal imagery has historically been undertaken using &lsquo;wet&rsquo; and &lsquo;dry&rsquo; reference surfaces in the field (reference temperature thresholding). However, this method is extremely time inefficient and can suffer inaccuracies if the surfaces are non-standardised or unable to stabilise with the environment. The research presented in this paper evaluates non-reference techniques to obtain average canopy temperature (Tc) from thermal imagery of avocado trees, both for the shaded side and sunlit side, without the need of reference temperature values. A sample of 510 thermal images (from 130 avocado trees) were acquired with a FLIR B250 handheld thermal imaging camera. Two methods based on temperature histograms were evaluated for removing non-canopy-related pixel information from the analysis, enabling Tc to be determined. These approaches included: 1) Histogram gradient thresholding based on temperature intensity changes (HG); and 2) histogram thresholding at one or more standard deviation (SD) above and below the mean. The HG method was found to be more accurate (R2 &gt; 0.95) than the SD method in defining canopy pixels and calculating Tc from each thermal image (shaded and sunlit) when compared to the standard reference temperature thresholding method. The results from this study present an alternative non-reference method for determining Tc from ground-based thermal imagery without the need of calibration surfaces. As such, it offers a more efficient and computationally autonomous method that will ultimately support the greater adoption of non-invasive thermal technologies within a precision agricultural system.},
DOI = {10.3390/rs11060714}
}



@Article{rs11060719,
AUTHOR = {Rominger, Kody and Meyer, Susan E.},
TITLE = {Application of UAV-Based Methodology for Census of an Endangered Plant Species in a Fragile Habitat},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {719},
URL = {https://www.mdpi.com/2072-4292/11/6/719},
ISSN = {2072-4292},
ABSTRACT = {Accurate census is essential for endangered plant management, yet lack of resources may make complete on-the-ground census difficult to achieve. Accessibility, especially for species in fragile habitats, is an added constraint. We examined the feasibility of using UAV (unmanned aerial vehicle, drone)-based imagery for census of an endangered plant species, Arctomecon humilis (dwarf bear-poppy), an herbaceous perennial gypsophile endemic of the Mojave Desert, USA. Using UAV technology, we captured imagery at both 50-m altitude (census) and 15-m altitude (validation) at two populations, White Dome (325 ha) and Red Bluffs (166 ha). The imagery was processed into orthomosaics that averaged 2.32 cm ground sampling distance (GSD) for 50-m imagery and 0.73 cm GSD for 15-m imagery. Putative poppy plants were marked in the 50-m imagery according to predefined criteria. We then used the 15-m imagery from each area to verify the identification accuracy of marked plants. Visual evaluation of the 50-m imagery resulted in errors of both commission and omission, mainly caused by failure to accurately identify or detect small poppies (&lt;10 cm diameter). Higher-resolution 30-m altitude imagery (1.19 cm GSD) greatly reduced errors of commission. Habitat classification demonstrated that poppy density variation was closely tied to soil surface color. This study showed that drone imagery can potentially be used to census rare plant species with distinctive morphology in open habitats and understand their spatial distribution.},
DOI = {10.3390/rs11060719}
}



@Article{s19061469,
AUTHOR = {Santamaria, Amilcare Francesco and Raimondo, Pierfrancesco and Tropea, Mauro and De Rango, Floriano and Aiello, Carmine},
TITLE = {An IoT Surveillance System Based on a Decentralised Architecture},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {1469},
URL = {https://www.mdpi.com/1424-8220/19/6/1469},
ISSN = {1424-8220},
ABSTRACT = {In the last few years, we witnessed numerous episodes of terrorist attacks and menaces in public crowded places. The necessity of better surveillance in these places pushed the development of new automated solutions to spot and notify possible menaces as fast as possible. In this work, we propose a novel approach to create a decentralized architecture to manage patrolling drones and cameras exploiting lightweight protocols used in the internet of things (IoT) domain. Through the adoption of the mist computing paradigm it is possible to give to all the object of the smart ecosystem a cognitive intelligence to speed up the recognition and analysis tasks. Distributing the intelligence among all the objects of the surveillance ecosystem allows a faster recognition and reaction to possible warning situations. The recognition of unusual objects in certain areas, e.g., airports, train stations and bus stations, has been made using computer vision algorithms. The adoption of the IoT protocols in a hierarchical architecture provides high scalability allowing an easy and painless join of other smart objects. Also a study on the soft real-time feasibility has been conducted and is herein presented.},
DOI = {10.3390/s19061469}
}



@Article{s19061479,
AUTHOR = {Jin, Ren and Jiang, Jiaqi and Qi, Yuhua and Lin, Defu and Song, Tao},
TITLE = {Drone Detection and Pose Estimation Using Relational Graph Networks},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {1479},
URL = {https://www.mdpi.com/1424-8220/19/6/1479},
ISSN = {1424-8220},
ABSTRACT = {With the upsurge in use of Unmanned Aerial Vehicles (UAVs), drone detection and pose estimation by using optical sensors becomes an important research subject in cooperative flight and low-altitude security. The existing technology only obtains the position of the target UAV based on object detection methods. To achieve better adaptability and enhanced cooperative performance, the attitude information of the target drone becomes a key message to understand its state and intention, e.g., the acceleration of quadrotors. At present, most of the object 6D pose estimation algorithms depend on accurate pose annotation or a 3D target model, which costs a lot of human resource and is difficult to apply to non-cooperative targets. To overcome these problems, a quadrotor 6D pose estimation algorithm was proposed in this paper. It was based on keypoints detection (only need keypoints annotation), relational graph network and perspective-n-point (PnP) algorithm, which achieves state-of-the-art performance both in simulation and real scenario. In addition, the inference ability of our relational graph network to the keypoints of four motors was also evaluated. The accuracy and speed were improved significantly compared with the state-of-the-art keypoints detection algorithm.},
DOI = {10.3390/s19061479}
}



@Article{rs11060733,
AUTHOR = {Windrim, Lloyd and Bryson, Mitch and McLean, Michael and Randle, Jeremy and Stone, Christine},
TITLE = {Automated Mapping of Woody Debris over Harvested Forest Plantations Using UAVs, High-Resolution Imagery, and Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {733},
URL = {https://www.mdpi.com/2072-4292/11/6/733},
ISSN = {2072-4292},
ABSTRACT = {Surveying of woody debris left over from harvesting operations on managed forests is an important step in monitoring site quality, managing the extraction of residues and reconciling differences in pre-harvest inventories and actual timber yields. Traditional methods for post-harvest survey involving manual assessment of debris on the ground over small sample plots are labor-intensive, time-consuming, and do not scale well to heterogeneous landscapes. In this paper, we propose and evaluate new automated methods for the collection and interpretation of high-resolution, Unmanned Aerial Vehicle (UAV)-borne imagery over post-harvested forests for estimating quantities of fine and coarse woody debris. Using high-resolution, geo-registered color mosaics generated from UAV-borne images, we develop manual and automated processing methods for detecting, segmenting and counting both fine and coarse woody debris, including tree stumps, exploiting state-of-the-art machine learning and image processing techniques. Results are presented using imagery over a post-harvested compartment in a Pinus radiata plantation and demonstrate the capacity for both manual image annotations and automated image processing to accurately detect and quantify coarse woody debris and stumps left over after harvest, providing a cost-effective and scalable survey method for forest managers.},
DOI = {10.3390/rs11060733}
}



@Article{ijgi8040160,
AUTHOR = {Liu, Bingxin and Li, Ying and Li, Guannan and Liu, Anling},
TITLE = {A Spectral Feature Based Convolutional Neural Network for Classification of Sea Surface Oil Spill},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {8},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {160},
URL = {https://www.mdpi.com/2220-9964/8/4/160},
ISSN = {2220-9964},
ABSTRACT = {Spectral characteristics play an important role in the classification of oil film, but the presence of too many bands can lead to information redundancy and reduced classification accuracy. In this study, a classification model that combines spectral indices-based band selection (SIs) and one-dimensional convolutional neural networks was proposed to realize automatic oil films classification using hyperspectral remote sensing images. Additionally, for comparison, the minimum Redundancy Maximum Relevance (mRMR) was tested for reducing the number of bands. The support vector machine (SVM), random forest (RF), and Hu&rsquo;s convolutional neural networks (CNN) were trained and tested. The results show that the accuracy of classifications through the one dimensional convolutional neural network (1D CNN) models surpassed the accuracy of other machine learning algorithms such as SVM and RF. The model of SIs+1D CNN could produce a relatively higher accuracy oil film distribution map within less time than other models.},
DOI = {10.3390/ijgi8040160}
}



@Article{rs11070736,
AUTHOR = {Hu, Jie and Peng, Jie and Zhou, Yin and Xu, Dongyun and Zhao, Ruiying and Jiang, Qingsong and Fu, Tingting and Wang, Fei and Shi, Zhou},
TITLE = {Quantitative Estimation of Soil Salinity Using UAV-Borne Hyperspectral and Satellite Multispectral Images},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {736},
URL = {https://www.mdpi.com/2072-4292/11/7/736},
ISSN = {2072-4292},
ABSTRACT = {Soil salinization is a global issue resulting in soil degradation, arable land loss and ecological environmental deterioration. Over the decades, multispectral and hyperspectral remote sensing have enabled efficient and cost-effective monitoring of salt-affected soils. However, the potential of hyperspectral sensors installed on an unmanned aerial vehicle (UAV) to estimate and map soil salinity has not been thoroughly explored. This study quantitatively characterized and estimated field-scale soil salinity using an electromagnetic induction (EMI) equipment and a hyperspectral camera installed on a UAV platform. In addition, 30 soil samples (0~20 cm) were collected in each field for the lab measurements of electrical conductivity. First, the apparent electrical conductivity (ECa) values measured by EMI were calibrated using the lab measured electrical conductivity derived from soil samples based on empirical line method. Second, the soil salinity was quantitatively estimated using the random forest (RF) regression method based on the reflectance factors of UAV hyperspectral images and satellite multispectral data. The performance of models was assessed by Lin&rsquo;s concordance coefficient (CC), ratio of performance to deviation (RPD), and root mean square error (RMSE). Finally, the soil salinity of three study fields with different land cover were mapped. The results showed that bare land (field A) exhibited the most severe salinity, followed by dense vegetation area (field C) and sparse vegetation area (field B). The predictive models using UAV data outperformed those derived from GF-2 data with lower RMSE, higher CC and RPD values, and the most accurate UAV-derived model was developed using 62 hyperspectral bands of the image of the field A with the RMSE, CC, and RPD values of 1.40 dS m&minus;1, 0.94, and 2.98, respectively. Our results indicated that UAV-borne hyperspectral imager is a useful tool for field-scale soil salinity monitoring and mapping. With the help of the EMI technique, quantitative estimation of surface soil salinity is critical to decision-making in arid land management and saline soil reclamation.},
DOI = {10.3390/rs11070736}
}



@Article{rs11070740,
AUTHOR = {Maimaitiyiming, Matthew and Sagan, Vasit and Sidike, Paheding and Kwasniewski, Misha T.},
TITLE = {Dual Activation Function-Based Extreme Learning Machine (ELM) for Estimating Grapevine Berry Yield and Quality},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {740},
URL = {https://www.mdpi.com/2072-4292/11/7/740},
ISSN = {2072-4292},
ABSTRACT = {Reliable assessment of grapevine productivity is a destructive and time-consuming process. In addition, the mixed effects of grapevine water status and scion-rootstock interactions on grapevine productivity are not always linear. Despite the potential opportunity of applying remote sensing and machine learning techniques to predict plant traits, there are still limitations to previously studied techniques for vine productivity due to the complexity of the system not being adequately modeled. During the 2014 and 2015 growing seasons, hyperspectral reflectance spectra were collected using a handheld spectroradiometer in a vineyard designed to investigate the effects of irrigation level (0%, 50%, and 100%) and rootstocks (1103 Paulsen, 3309 Couderc, SO4 and Chambourcin) on vine productivity. To assess vine productivity, it is necessary to measure factors related to fruit ripeness and not just yield, as an over cropped vine may produce high-yield but poor-quality fruit. Therefore, yield, Total Soluble Solids (TSS), Titratable Acidity (TA) and the ratio TSS/TA (maturation index, IMAD) were measured. A total of 20 vegetation indices were calculated from hyperspectral data and used as input for predictive model calibration. Prediction performance of linear/nonlinear multiple regression methods and Weighted Regularized Extreme Learning Machine (WRELM) were compared with our newly developed WRELM-TanhRe. The developed method is based on two activation functions: hyperbolic tangent (Tanh) and rectified linear unit (ReLU). The results revealed that WRELM and WRELM-TanhRe outperformed the widely used multiple regression methods when model performance was tested with an independent validation dataset. WRELM-TanhRe produced the highest prediction accuracy for all the berry yield and quality parameters (R2 of 0.522&ndash;0.682 and RMSE of 2&ndash;15%), except for TA, which was predicted best with WRELM (R2 of 0.545 and RMSE of 6%). The results demonstrate the value of combining hyperspectral remote sensing and machine learning methods for improving of berry yield and quality prediction.},
DOI = {10.3390/rs11070740}
}



@Article{s19071486,
AUTHOR = {Gebrehiwot, Asmamaw and Hashemi-Beni, Leila and Thompson, Gary and Kordjamshidi, Parisa and Langan, Thomas E.},
TITLE = {Deep Convolutional Neural Network for Flood Extent Mapping Using Unmanned Aerial Vehicles Data},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1486},
URL = {https://www.mdpi.com/1424-8220/19/7/1486},
ISSN = {1424-8220},
ABSTRACT = {Flooding is one of the leading threats of natural disasters to human life and property, especially in densely populated urban areas. Rapid and precise extraction of the flooded areas is key to supporting emergency-response planning and providing damage assessment in both spatial and temporal measurements. Unmanned Aerial Vehicles (UAV) technology has recently been recognized as an efficient photogrammetry data acquisition platform to quickly deliver high-resolution imagery because of its cost-effectiveness, ability to fly at lower altitudes, and ability to enter a hazardous area. Different image classification methods including SVM (Support Vector Machine) have been used for flood extent mapping. In recent years, there has been a significant improvement in remote sensing image classification using Convolutional Neural Networks (CNNs). CNNs have demonstrated excellent performance on various tasks including image classification, feature extraction, and segmentation. CNNs can learn features automatically from large datasets through the organization of multi-layers of neurons and have the ability to implement nonlinear decision functions. This study investigates the potential of CNN approaches to extract flooded areas from UAV imagery. A VGG-based fully convolutional network (FCN-16s) was used in this research. The model was fine-tuned and a k-fold cross-validation was applied to estimate the performance of the model on the new UAV imagery dataset. This approach allowed FCN-16s to be trained on the datasets that contained only one hundred training samples, and resulted in a highly accurate classification. Confusion matrix was calculated to estimate the accuracy of the proposed method. The image segmentation results obtained from FCN-16s were compared from the results obtained from FCN-8s, FCN-32s and SVMs. Experimental results showed that the FCNs could extract flooded areas precisely from UAV images compared to the traditional classifiers such as SVMs. The classification accuracy achieved by FCN-16s, FCN-8s, FCN-32s, and SVM for the water class was 97.52%, 97.8%, 94.20% and 89%, respectively.},
DOI = {10.3390/s19071486}
}



@Article{ijerph16071109,
AUTHOR = {Chu, Hone-Jay and Chen, Yi-Chin and Ali, Muhammad Zeeshan and Höfle, Bernhard},
TITLE = {Multi-Parameter Relief Map from High-Resolution DEMs: A Case Study of Mudstone Badland},
JOURNAL = {International Journal of Environmental Research and Public Health},
VOLUME = {16},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1109},
URL = {https://www.mdpi.com/1660-4601/16/7/1109},
PubMedID = {30925700},
ISSN = {1660-4601},
ABSTRACT = {Topographic parameters of high-resolution digital elevation models (DEMs) with meter to sub-meter spatial resolution, such as slope, curvature, openness, and wetness index, show the spatial properties and surface characterizations of terrains. The multi-parameter relief map, including two-parameter (2P) or three-parameter (3P) information, can visualize the topographic slope and terrain concavities and convexities in the hue, saturation, and value (HSV) color system. Various combinations of the topographic parameters can be used in the relief map, for instance, using wetness index for upstream representation. In particular, 3P relief maps are integrated from three critical topographic parameters including wetness or aspect, slope, and openness data. This study offers an effective way to explore the combination of topographic parameters in visualizing terrain features using multi-parameter relief maps in badlands and in showing the effects of smoothing and parameter selection. The multi-parameter relief images of high-resolution DEMs clearly show micro-topographic features, e.g., popcorn-like morphology and rill.},
DOI = {10.3390/ijerph16071109}
}



@Article{en12071204,
AUTHOR = {Zhao, Zhenbing and Zhen, Zhen and Zhang, Lei and Qi, Yincheng and Kong, Yinghui and Zhang, Ke},
TITLE = {Insulator Detection Method in Inspection Image Based on Improved Faster R-CNN},
JOURNAL = {Energies},
VOLUME = {12},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1204},
URL = {https://www.mdpi.com/1996-1073/12/7/1204},
ISSN = {1996-1073},
ABSTRACT = {The detection of insulators in power transmission and transformation inspection images is the basis for insulator state detection and fault diagnosis in thereafter. Aiming at the detection of insulators with different aspect ratios and scales and ones with mutual occlusion, a method of insulator inspection image based on the improved faster region-convolutional neural network (R-CNN) is put forward in this paper. By constructing a power transmission and transformation insulation equipment detection dataset and fine-tuning the faster R-CNN model, the anchor generation method and non-maximum suppression (NMS) in the region proposal network (RPN) of the faster R-CNN model were improved, thus realizing a better detection of insulators. The experimental results show that the average precision (AP) value of the faster R-CNN model was increased to 0.818 with the improved anchor generation method under the VGG-16 Net. In addition, the detection effect of different aspect ratios and different scales of insulators in the inspection images was improved significantly, and the occlusion of insulators could be effectively distinguished and detected using the improved NMS.},
DOI = {10.3390/en12071204}
}



@Article{rs11070755,
AUTHOR = {Zhang, Xiaodong and Zhu, Kun and Chen, Guanzhou and Tan, Xiaoliang and Zhang, Lifei and Dai, Fan and Liao, Puyun and Gong, Yuanfu},
TITLE = {Geospatial Object Detection on High Resolution Remote Sensing Imagery Based on Double Multi-Scale Feature Pyramid Network},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {755},
URL = {https://www.mdpi.com/2072-4292/11/7/755},
ISSN = {2072-4292},
ABSTRACT = {Object detection on very-high-resolution (VHR) remote sensing imagery has attracted a lot of attention in the field of image automatic interpretation. Region-based convolutional neural networks (CNNs) have been vastly promoted in this domain, which first generate candidate regions and then accurately classify and locate the objects existing in these regions. However, the overlarge images, the complex image backgrounds and the uneven size and quantity distribution of training samples make the detection tasks more challenging, especially for small and dense objects. To solve these problems, an effective region-based VHR remote sensing imagery object detection framework named Double Multi-scale Feature Pyramid Network (DM-FPN) was proposed in this paper, which utilizes inherent multi-scale pyramidal features and combines the strong-semantic, low-resolution features and the weak-semantic, high-resolution features simultaneously. DM-FPN consists of a multi-scale region proposal network and a multi-scale object detection network, these two modules share convolutional layers and can be trained end-to-end. We proposed several multi-scale training strategies to increase the diversity of training data and overcome the size restrictions of the input images. We also proposed multi-scale inference and adaptive categorical non-maximum suppression (ACNMS) strategies to promote detection performance, especially for small and dense objects. Extensive experiments and comprehensive evaluations on large-scale DOTA dataset demonstrate the effectiveness of the proposed framework, which achieves mean average precision (mAP) value of 0.7927 on validation dataset and the best mAP value of 0.793 on testing dataset.},
DOI = {10.3390/rs11070755}
}



@Article{rs11070760,
AUTHOR = {Mondini, Alessandro C. and Santangelo, Michele and Rocchetti, Margherita and Rossetto, Enrica and Manconi, Andrea and Monserrat, Oriol},
TITLE = {Sentinel-1 SAR Amplitude Imagery for Rapid Landslide Detection},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {760},
URL = {https://www.mdpi.com/2072-4292/11/7/760},
ISSN = {2072-4292},
ABSTRACT = {Despite landslides impact the society worldwide every day, landslide information is inhomogeneous and lacking. When landslides occur in remote areas or where the availability of optical images is rare due to cloud persistence, they might remain unknown, or unnoticed for long time, preventing studies and hampering civil protection operations. The unprecedented availability of SAR C-band images provided by the Sentinel-1 constellation offers the opportunity to propose new solutions to detect landslides events. In this work, we perform a systematic assessment of Sentinel-1 SAR C-band images acquired before and after known events. We present the results of a pilot study on 32 worldwide cases of rapid landslides entailing different types, sizes, slope expositions, as well as pre-existing land cover, triggering factors and climatic regimes. Results show that in about eighty-four percent of the cases, changes caused by landslides on SAR amplitudes are unambiguous, whereas only in about thirteen percent of the cases there is no evidence. On the other hand, the signal does not allow for a systematic use to produce inventories because only in 8 cases, a delineation of the landslide borders (i.e., mapping) can be manually attempted. In a few cases, cascade multi-hazard (e.g., floods caused by landslides) and evidences of extreme triggering factors (e.g., strong earthquakes or very rapid snow melting) were detected. The method promises to increase the availability of information on landslides at different spatial and temporal scales with benefits for event magnitude assessment during weather-related emergencies, model tuning, and landslide forecast model validation, in particular when accurate mapping is not required.},
DOI = {10.3390/rs11070760}
}



@Article{en12071223,
AUTHOR = {Gao, Jianlei and Chai, Senchun and Zhang, Baihai and Xia, Yuanqing},
TITLE = {Research on Network Intrusion Detection Based on Incremental Extreme Learning Machine and Adaptive Principal Component Analysis},
JOURNAL = {Energies},
VOLUME = {12},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1223},
URL = {https://www.mdpi.com/1996-1073/12/7/1223},
ISSN = {1996-1073},
ABSTRACT = {Recently, network attacks launched by malicious attackers have seriously affected modern life and enterprise production, and these network attack samples have the characteristic of type imbalance, which undoubtedly increases the difficulty of intrusion detection. In response to this problem, it would naturally be very meaningful to design an intrusion detection system (IDS) to effectively and quickly identify and detect malicious behaviors. In our work, we have proposed a method for an IDS-combined incremental extreme learning machine (I-ELM) with an adaptive principal component (A-PCA). In this method, the relevant features of network traffic are adaptively selected, where the best detection accuracy can then be obtained by I-ELM. We have used the NSL-KDD standard dataset and UNSW-NB15 standard dataset to evaluate the performance of our proposed method. Through analysis of the experimental results, we can see that our proposed method has better computation capacity, stronger generalization ability, and higher accuracy.},
DOI = {10.3390/en12071223}
}



@Article{drones3020031,
AUTHOR = {Wang, Liyang and Misra, Gaurav and Bai, Xiaoli},
TITLE = {A K Nearest Neighborhood-Based Wind Estimation for Rotary-Wing VTOL UAVs},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {31},
URL = {https://www.mdpi.com/2504-446X/3/2/31},
ISSN = {2504-446X},
ABSTRACT = {Wind speed estimation for rotary-wing vertical take-off and landing (VTOL) UAVs is challenging due to the low accuracy of airspeed sensors, which can be severely affected by the rotor&rsquo;s down-wash effect. Unlike traditional aerodynamic modeling solutions, in this paper, we present a K Nearest Neighborhood learning-based method which does not require the details of the aerodynamic information. The proposed method includes two stages: an off-line training stage and an on-line wind estimation stage. Only flight data is used for the on-line estimation stage, without direct airspeed measurements. We use Parrot AR.Drone as the testing quadrotor, and a commercial fan is used to generate wind disturbance. Experimental results demonstrate the accuracy and robustness of the developed wind estimation algorithms under hovering conditions.},
DOI = {10.3390/drones3020031}
}



@Article{s19071561,
AUTHOR = {Aalerud, Atle and Dybedal, Joacim and Hovland, Geir},
TITLE = {Automatic Calibration of an Industrial RGB-D Camera Network Using Retroreflective Fiducial Markers},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1561},
URL = {https://www.mdpi.com/1424-8220/19/7/1561},
ISSN = {1424-8220},
ABSTRACT = {This paper describes a non-invasive, automatic, and robust method for calibrating a scalable RGB-D sensor network based on retroreflective ArUco markers and the iterative closest point (ICP) scheme. We demonstrate the system by calibrating a sensor network comprised of six sensor nodes positioned in a relatively large industrial robot cell with an approximate size of     10 &nbsp; m &times; 10 &nbsp; m &times; 4        m   . Here, the automatic calibration achieved an average Euclidean error of 3    c      m    at distances up to     9.45        m   . To achieve robustness, we apply several innovative techniques: Firstly, we mitigate the ambiguity problem that occurs when detecting a marker at long range or low resolution by comparing the camera projection with depth data. Secondly, we use retroreflective fiducial markers in the RGB-D calibration for improved accuracy and detectability. Finally, the repeating ICP refinement uses an exact region of interest such that we employ the precise depth measurements of the retroreflective surfaces only. The complete calibration software and a recorded dataset are publically available and open source.},
DOI = {10.3390/s19071561}
}



@Article{s19071562,
AUTHOR = {Yang, Jiachen and Liu, Lin and Zhang, Linfeng and Li, Gen and Sun, Zhonghao and Song, Houbing},
TITLE = {Prediction of Marine Pycnocline Based on Kernel Support Vector Machine and Convex Optimization Technology},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1562},
URL = {https://www.mdpi.com/1424-8220/19/7/1562},
ISSN = {1424-8220},
ABSTRACT = {With the explosive growth of ocean data, it is of great significance to use ocean observation data to analyze ocean pycnocline data in military field. However, due to natural factors, most of the time the ocean hydrological data is not complete. In this case, predicting the ocean hydrological data by partial data has become a hot spot in marine science. In this paper, based on the traditional statistical analysis literature, we propose a machine-learning ocean hydrological data processing process under big data. At the same time, based on the traditional pycnocline gradient determination method, the open Argo data set is analyzed, and the local characteristics of pycnocline are verified from several aspects combined with the current research about pycnocline. Most importantly, in this paper, the combination of kernel function and support vector machine(SVM) is extended to nonlinear learning by using the idea of machine learning and convex optimization technology. Based on this, the known pycnocline training set is trained, and an accurate model is obtained to predict the pycnocline in unknown domains. In the specific steps, this paper combines the classification problem with the regression problem, and determines the proportion of training set and test formula set by polynomial regression. Subsequently, the feature scaling of the input data accelerated the gradient convergence, and a grid search algorithm with variable step size was proposed to determine the super parameter c and gamma of the SVM model. The prediction results not only used the confusion matrix to analyze the accuracy of GridSearch-SVM with variable step size, but also compared the traditional SVM and the similar algorithm. At the end of the experiment, two features which have the greatest influence on the Marine density thermocline are found out by the feature ranking algorithm based on learning.},
DOI = {10.3390/s19071562}
}



@Article{rs11070780,
AUTHOR = {Wei, Lifei and Yu, Ming and Zhong, Yanfei and Zhao, Ji and Liang, Yajing and Hu, Xin},
TITLE = {Spatial–Spectral Fusion Based on Conditional Random Fields for the Fine Classification of Crops in UAV-Borne Hyperspectral Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {780},
URL = {https://www.mdpi.com/2072-4292/11/7/780},
ISSN = {2072-4292},
ABSTRACT = {The fine classification of crops is critical for food security and agricultural management. There are many different species of crops, some of which have similar spectral curves. As a result, the precise classification of crops is a difficult task. Although the classification methods that incorporate spatial information can reduce the noise and improve the classification accuracy, to a certain extent, the problem is far from solved. Therefore, in this paper, the method of spatial&ndash;spectral fusion based on conditional random fields (SSF-CRF) for the fine classification of crops in UAV-borne hyperspectral remote sensing imagery is presented. The proposed method designs suitable potential functions in a pairwise conditional random field model, fusing the spectral and spatial features to reduce the spectral variation within the homogenous regions and accurately identify the crops. The experiments on hyperspectral datasets of the cities of Hanchuan and Honghu in China showed that, compared with the traditional methods, the proposed classification method can effectively improve the classification accuracy, protect the edges and shapes of the features, and relieve excessive smoothing, while retaining detailed information. This method has important significance for the fine classification of crops in hyperspectral remote sensing imagery.},
DOI = {10.3390/rs11070780}
}



@Article{s19071579,
AUTHOR = {Ostovar, Ahmad and Talbot, Bruce and Puliti, Stefano and Astrup, Rasmus and Ringdahl, Ola},
TITLE = {Detection and Classification of Root and Butt-Rot (RBR) in Stumps of Norway Spruce Using RGB Images and Machine Learning},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1579},
URL = {https://www.mdpi.com/1424-8220/19/7/1579},
ISSN = {1424-8220},
ABSTRACT = {Root and butt-rot (RBR) has a significant impact on both the material and economic outcome of timber harvesting, and therewith on the individual forest owner and collectively on the forest and wood processing industries. An accurate recording of the presence of RBR during timber harvesting would enable a mapping of the location and extent of the problem, providing a basis for evaluating spread in a climate anticipated to enhance pathogenic growth in the future. Therefore, a system to automatically identify and detect the presence of RBR would constitute an important contribution to addressing the problem without increasing workload complexity for the machine operator. In this study, we developed and evaluated an approach based on RGB images to automatically detect tree stumps and classify them as to the absence or presence of rot. Furthermore, since knowledge of the extent of RBR is valuable in categorizing logs, we also classify stumps into three classes of infestation; rot = 0%, 0% &lt; rot &lt; 50% and rot &ge; 50%. In this work we used deep-learning approaches and conventional machine-learning algorithms for detection and classification tasks. The results showed that tree stumps were detected with precision rate of 95% and recall of 80%. Using only the correct output (TP) of the stump detector, stumps without and with RBR were correctly classified with accuracy of 83.5% and 77.5%, respectively. Classifying rot into three classes resulted in 79.4%, 72.4%, and 74.1% accuracy for stumps with rot = 0%, 0% &lt; rot &lt; 50%, and rot &ge; 50%, respectively. With some modifications, the developed algorithm could be used either during the harvesting operation to detect RBR regions on the tree stumps or as an RBR detector for post-harvest assessment of tree stumps and logs.},
DOI = {10.3390/s19071579}
}



@Article{rs11070788,
AUTHOR = {Luo, Kaisheng},
TITLE = {Spatial Pattern of Forest Carbon Storage in the Vertical and Horizontal Directions Based on HJ-CCD Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {788},
URL = {https://www.mdpi.com/2072-4292/11/7/788},
ISSN = {2072-4292},
ABSTRACT = {To provide a comprehensive understanding of the spatial distribution of forest carbon reserves, this study explores carbon storage and its spatial pattern in the horizontal and vertical directions on a provincial scale using HJ-CCD remote sensing imagery. Results show that carbon storage in the forests of Hubei Province was 784.46 Tg. In the horizontal direction, Enshi Prefecture contributed the most, with a contribution rate of 22.01%, followed by Yichang (18.74%), Shiyan (15.21%), and Xiangfan (10.61%). Coniferous forests contributed the most to the total carbon reserves of the forests, with a contribution rate of 71.34%, followed by broadleaf forests (25.36%), and mixed forests (3.30%). In the vertical direction, the environmental difference in the vertical direction of the forest ecosystem led to the obvious stratification of carbon storage in the vertical direction, that is: soil layer &gt; tree canopy layer &gt; shrub layer &gt; litter layer. The soil layer had the largest carbon storage, contributing 76.63%, followed by the tree canopy layer (19.05%), shrub layer (2.39%), and litter layer (1.93%). The different contributing layers of coniferous, broadleaf, and mixed forests to carbon storage followed the same order: soil layer &gt; tree canopy layer &gt; shrub layer &gt; litter layer.},
DOI = {10.3390/rs11070788}
}



@Article{rs11070789,
AUTHOR = {Laybros, Anthony and Schläpfer, Daniel and Féret, Jean-Baptiste and Descroix, Laurent and Bedeau, Caroline and Lefevre, Marie-Jose and Vincent, Grégoire},
TITLE = {Across Date Species Detection Using Airborne Imaging Spectroscopy},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {789},
URL = {https://www.mdpi.com/2072-4292/11/7/789},
ISSN = {2072-4292},
ABSTRACT = {Imaging spectroscopy is a promising tool for airborne tree species recognition in hyper-diverse tropical canopies. However, its widespread application is limited by the signal sensitivity to acquisition parameters, which may require new training data in every new area of application. This study explores how various pre-processing steps may improve species discrimination and species recognition under different operational settings. In the first experiment, a classifier was trained and applied on imaging spectroscopy data acquired on a single date, while in a second experiment, the classifier was trained on data from one date and applied to species identification on data from a different date. A radiative transfer model based on atmospheric compensation was applied with special focus on the automatic retrieval of aerosol amounts. The impact of spatial or spectral filtering and normalisation was explored as an alternative to atmospheric correction. A pixel-wise classification was performed with a linear discriminant analysis trained on individual tree crowns identified at the species level. Tree species were then identified at the crown scale based on a majority vote rule. Atmospheric corrections did not outperform simple statistical processing (i.e., filtering and normalisation) when training and testing sets were taken from the same flight date. However, atmospheric corrections became necessary for reliable species recognition when different dates were considered. Shadow masking improved species classification results in all cases. Single date classification rate was 83.9% for 1297 crowns of 20 tropical species. The loss of mean accuracy observed when using training data from one date to identify species at another date in the same area was limited to 10% when atmospheric correction was applied.},
DOI = {10.3390/rs11070789}
}



@Article{s19071595,
AUTHOR = {Ji, Shan-Qian and Huang, Ming-Bao and Huang, Han-Pang},
TITLE = {Robot Intelligent Grasp of Unknown Objects Based on Multi-Sensor Information},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1595},
URL = {https://www.mdpi.com/1424-8220/19/7/1595},
ISSN = {1424-8220},
ABSTRACT = {Robots frequently need to work in human environments and handle many different types of objects. There are two problems that make this challenging for robots: human environments are typically cluttered, and the multi-finger robot hand needs to grasp and to lift objects without knowing their mass and damping properties. Therefore, this study combined vision and robot hand real-time grasp control action to achieve reliable and accurate object grasping in a cluttered scene. An efficient online algorithm for collision-free grasping pose generation according to a bounding box is proposed, and the grasp pose will be further checked for grasp quality. Finally, by fusing all available sensor data appropriately, an intelligent real-time grasp system was achieved that is reliable enough to handle various objects with unknown weights, friction, and stiffness. The robots used in this paper are the NTU 21-DOF five-finger robot hand and the NTU 6-DOF robot arm, which are both constructed by our Lab.},
DOI = {10.3390/s19071595}
}



@Article{ijgi8040169,
AUTHOR = {Zahran, Shady and Moussa, Adel and El-Sheimy, Naser},
TITLE = {Enhanced Drone Navigation in GNSS Denied Environment Using VDM and Hall Effect Sensor},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {8},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {169},
URL = {https://www.mdpi.com/2220-9964/8/4/169},
ISSN = {2220-9964},
ABSTRACT = {The last decade has witnessed a wide spread of small drones in many civil and military applications. With the massive advancement in the manufacture of small and lightweight Inertial Navigation System (INS), navigation in challenging environments became feasible. Navigation of these small drones mainly depends on the integration of Global Navigation Satellite Systems (GNSS) and INS. However, the navigation performance of these small drones deteriorates quickly when the GNSS signals are lost, due to accumulated errors of the low-cost INS that is typically used in these drones. During GNSS signal outages, another aiding sensor is required to bound the drift exhibited by the INS. Before adding any additional sensor on-board the drones, there are some limitations that must be taken into considerations. These limitations include limited availability of power, space, weight, and size. This paper presents a novel unconventional method, to enhance the navigation of autonomous drones in GNSS denied environment, through a new utilization of hall effect sensor to act as flying odometer &ldquo;Air-Odo&rdquo; and vehicle dynamic model (VDM) for heading estimation. The proposed approach enhances the navigational solution by estimating the unmanned aerial vehicle (UAV) velocity, and heading and fusing these measurements in the Extended Kalman Filter (EKF) of the integrated system.},
DOI = {10.3390/ijgi8040169}
}



@Article{drones3020033,
AUTHOR = {Xavier, Thomaz W. F. and Souto, Roberto N. V. and Statella, Thiago and Galbieri, Rafael and Santos, Emerson S. and S. Suli, George and Zeilhofer, Peter},
TITLE = {Identification of Ramularia Leaf Blight Cotton Disease Infection Levels by Multispectral, Multiscale UAV Imagery},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {33},
URL = {https://www.mdpi.com/2504-446X/3/2/33},
ISSN = {2504-446X},
ABSTRACT = {The reduction of the production cost and negative environmental impacts by pesticide application to control cotton diseases depends on the infection patterns spatialized in the farm scale. Here, we evaluate the potential of three-band multispectral imagery from a multi-rotor unmanned airborne vehicle (UAV) platform for the detection of ramularia leaf blight from different flight heights in an experimental field. Increasing infection levels indicate the progressive degradation of the spectral vegetation signal, however, they were not sufficient to differentiate disease severity levels. At resolutions of ~5 cm (100 m) and ~15 cm (300 m) up to a ground spatial resolution of ~25 cm (500 m flight height), two-scaled infection levels can be detected for the best performing algorithm of four classifiers tested, with an overall accuracy of ~79% and a kappa index of ~0.51. Despite limited classification performance, the results show the potential interest of low-cost multispectral systems to monitor ramularia blight in cotton.},
DOI = {10.3390/drones3020033}
}



@Article{rs11070795,
AUTHOR = {Durante, Pilar and Martín-Alcón, Santiago and Gil-Tena, Assu and Algeet, Nur and Tomé, José Luis and Recuero, Laura and Palacios-Orueta, Alicia and Oyonarte, Cecilio},
TITLE = {Improving Aboveground Forest Biomass Maps: From High-Resolution to National Scale},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {795},
URL = {https://www.mdpi.com/2072-4292/11/7/795},
ISSN = {2072-4292},
ABSTRACT = {Forest aboveground biomass (AGB) estimation over large extents and high temporal resolution is crucial in managing Mediterranean forest ecosystems, which have been predicted to be very sensitive to climate change effects. Although many modeling procedures have been tested to assess forest AGB, most of them cover small areas and attain high accuracy in evaluations that are difficult to update and extrapolate without large uncertainties. In this study, focusing on the Region of Murcia in Spain (11,313 km2), we integrated forest AGB estimations, obtained from high-precision airborne laser scanning (ALS) data calibrated with plot-level ground-based measures and bio-geophysical spectral variables (eight different indices derived from MODIS computed at different temporal resolutions), as well as topographic factors as predictors. We used a quantile regression forest (QRF) to spatially predict biomass and the associated uncertainty. The fitted model produced a satisfactory performance (R2 0.71 and RMSE 9.99 t&middot;ha&minus;1) with the normalized difference vegetation index (NDVI) as the main vegetation index, in combination with topographic variables as environmental drivers. An independent validation carried out over the final predicted biomass map showed a satisfactory statistically-robust model (R2 0.70 and RMSE 10.25 t&middot;ha&minus;1), confirming its applicability at coarser resolutions.},
DOI = {10.3390/rs11070795}
}



@Article{rs11070800,
AUTHOR = {Shen, Xin and Cao, Lin and Yang, Bisheng and Xu, Zhong and Wang, Guibin},
TITLE = {Estimation of Forest Structural Attributes Using Spectral Indices and Point Clouds from UAS-Based Multispectral and RGB Imageries},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {800},
URL = {https://www.mdpi.com/2072-4292/11/7/800},
ISSN = {2072-4292},
ABSTRACT = {Forest structural attributes are key indicators for parameterization of forest growth models, which play key roles in understanding the biophysical processes and function of the forest ecosystem. In this study, UAS-based multispectral and RGB imageries were used to estimate forest structural attributes in planted subtropical forests. The point clouds were generated from multispectral and RGB imageries using the digital aerial photogrammetry (DAP) approach. Different suits of spectral and structural metrics (i.e., wide-band spectral indices and point cloud metrics) derived from multispectral and RGB imageries were compared and assessed. The selected spectral and structural metrics were used to fit partial least squares (PLS) regression models individually and in combination to estimate forest structural attributes (i.e., Lorey&rsquo;s mean height (HL) and volume(V)), and the capabilities of multispectral- and RGB-derived spectral and structural metrics in predicting forest structural attributes in various stem density forests were assessed and compared. The results indicated that the derived DAP point clouds had perfect visual effects and that most of the structural metrics extracted from the multispectral DAP point cloud were highly correlated with the metrics derived from the RGB DAP point cloud (R2 &gt; 0.75). Although the models including only spectral indices had the capability to predict forest structural attributes with relatively high accuracies (R2 = 0.56&ndash;0.69, relative Root-Mean-Square-Error (RMSE) = 10.88&ndash;21.92%), the models with spectral and structural metrics had higher accuracies (R2 = 0.82&ndash;0.93, relative RMSE = 4.60&ndash;14.17%). Moreover, the models fitted using multispectral- and RGB-derived metrics had similar accuracies (∆R2 = 0&ndash;0.02, ∆ relative RMSE = 0.18&ndash;0.44%). In addition, the combo models fitted with stratified sample plots had relatively higher accuracies than those fitted with all of the sample plots (∆R2 = 0&ndash;0.07, ∆ relative RMSE = 0.49&ndash;3.08%), and the accuracies increased with increasing stem density.},
DOI = {10.3390/rs11070800}
}



@Article{make1020033,
AUTHOR = {Azabi, Yousef and Savvaris, Al and Kipouros, Timoleon},
TITLE = {Artificial Intelligence to Enhance Aerodynamic Shape Optimisation of the Aegis UAV},
JOURNAL = {Machine Learning and Knowledge Extraction},
VOLUME = {1},
YEAR = {2019},
NUMBER = {2},
PAGES = {552--574},
URL = {https://www.mdpi.com/2504-4990/1/2/33},
ISSN = {2504-4990},
ABSTRACT = {This article presents an optimisation framework that uses stochastic multi-objective optimisation, combined with an Artificial Neural Network (ANN), and describes its application to the aerodynamic design of aircraft shapes. The framework uses the Multi-Objective Particle Swarm Optimisation (MOPSO) algorithm and the obtained results confirm that the proposed technique provides highly optimal solutions in less computational time than other approaches to the same design problem. The main idea was to focus computational effort on worthwhile design solutions rather than exploring and evaluating all possible solutions in the design space. It is shown that the number of valid solutions obtained using ANN-MOPSO compared to MOPSO for 3000 evaluations grew from 529 to 1006 (90% improvement) with a penalty of only 8.3% (11 min) in computational time. It is demonstrated that including an ANN, the ANN-MOPSO with 3000 evaluations produced a larger number of valid solutions than the MOPSO with 5500 evaluations, and in 33% less computational time (64 min). This is taken as confirmation of the potential power of ANNs when applied to this type of design problem.},
DOI = {10.3390/make1020033}
}



@Article{s19071651,
AUTHOR = {Hong, Suk-Ju and Han, Yunhyeok and Kim, Sang-Yeon and Lee, Ah-Yeong and Kim, Ghiseok},
TITLE = {Application of Deep-Learning Methods to Bird Detection Using Unmanned Aerial Vehicle Imagery},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1651},
URL = {https://www.mdpi.com/1424-8220/19/7/1651},
ISSN = {1424-8220},
ABSTRACT = {Wild birds are monitored with the important objectives of identifying their habitats and estimating the size of their populations. Especially in the case of migratory bird, they are significantly recorded during specific periods of time to forecast any possible spread of animal disease such as avian influenza. This study led to the construction of deep-learning-based object-detection models with the aid of aerial photographs collected by an unmanned aerial vehicle (UAV). The dataset containing the aerial photographs includes diverse images of birds in various bird habitats and in the vicinity of lakes and on farmland. In addition, aerial images of bird decoys are captured to achieve various bird patterns and more accurate bird information. Bird detection models such as Faster Region-based Convolutional Neural Network (R-CNN), Region-based Fully Convolutional Network (R-FCN), Single Shot MultiBox Detector (SSD), Retinanet, and You Only Look Once (YOLO) were created and the performance of all models was estimated by comparing their computing speed and average precision. The test results show Faster R-CNN to be the most accurate and YOLO to be the fastest among the models. The combined results demonstrate that the use of deep-learning-based detection methods in combination with UAV aerial imagery is fairly suitable for bird detection in various environments.},
DOI = {10.3390/s19071651}
}



@Article{rs11070831,
AUTHOR = {Poortinga, Ate and Tenneson, Karis and Shapiro, Aurélie and Nquyen, Quyen and San Aung, Khun and Chishtie, Farrukh and Saah, David},
TITLE = {Mapping Plantations in Myanmar by Fusing Landsat-8, Sentinel-2 and Sentinel-1 Data along with Systematic Error Quantification},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {831},
URL = {https://www.mdpi.com/2072-4292/11/7/831},
ISSN = {2072-4292},
ABSTRACT = {Forests in Southeast Asia are experiencing some of the highest rates of deforestation and degradation in the world, with natural forest species being replaced by cropland and plantation monoculture. In this work, we have developed an innovative method to accurately map rubber and palm oil plantations using fusion of Landsat-8, Sentinel 1 and 2. We applied cloud and shadow masking, bidirectional reflectance distribution function (BRDF), atmospheric and topographic corrections to the optical imagery and a speckle filter and harmonics for Synthetic Aperture Radar (SAR) data. In this workflow, we created yearly composites for all sensors and combined the data into a single composite. A series of covariates were calculated from optical bands and sampled using reference data of the land cover classes including surface water, forest, urban and built-up, cropland, rubber, palm oil and mangrove. This training dataset was used to create biophysical probability layers (primitives) for each class. These primitives were then used to create land cover and probability maps in a decision tree logic and Monte-Carlo simulations. Validation showed good overall accuracy (84%) for the years 2017 and 2018. Filtering for validation points with high error estimates improved the accuracy up to 91%. We demonstrated and concluded that error quantification is an essential step in land cover classification and land cover change detection. Our overall analysis supports and presents a path for improving present assessments for sustainable supply chain analyses and associated recommendations.},
DOI = {10.3390/rs11070831}
}



@Article{app9071459,
AUTHOR = {Mao, Huihui and Meng, Jihua and Ji, Fujiang and Zhang, Qiankun and Fang, Huiting},
TITLE = {Comparison of Machine Learning Regression Algorithms for Cotton Leaf Area Index Retrieval Using Sentinel-2 Spectral Bands},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1459},
URL = {https://www.mdpi.com/2076-3417/9/7/1459},
ISSN = {2076-3417},
ABSTRACT = {Leaf area index (LAI) is a crucial crop biophysical parameter that has been widely used in a variety of fields. Five state-of-the-art machine learning regression algorithms (MLRAs), namely, artificial neural network (ANN), support vector regression (SVR), Gaussian process regression (GPR), random forest (RF) and gradient boosting regression tree (GBRT), have been used in the retrieval of cotton LAI with Sentinel-2 spectral bands. The performances of the five machine learning models are compared for better applications of MLRAs in remote sensing, since challenging problems remain in the selection of MLRAs for crop LAI retrieval, as well as the decision as to the optimal number for the training sample size and spectral bands to different MLRAs. A comprehensive evaluation was employed with respect to model accuracy, computational efficiency, sensitivity to training sample size and sensitivity to spectral bands. We conducted the comparison of five MLRAs in an agricultural area of Northwest China over three cotton seasons with the corresponding field campaigns for modeling and validation. Results show that the GBRT model outperforms the other models with respect to model accuracy in average (       R 2   &macr;      = 0.854,       R M S E  &macr;      = 0.674 and       M A E  &macr;      = 0.456). SVR achieves the best performance in computational efficiency, which means it is fast to train, and to validate that it has great potentials to deliver near-real-time operational products for crop management. As for sensitivity to training sample size, GBRT behaves as the most robust model, and provides the best model accuracy on the average among the variations of training sample size, compared with other models (       R 2   &macr;      = 0.884,       R M S E  &macr;      = 0.615 and       M A E  &macr;      = 0.452). Spectral bands sensitivity analysis with dCor (distance correlation), combined with the backward elimination approach, indicates that SVR, GPR and RF provide relatively robust performance to the spectral bands, while ANN outperforms the other models in terms of model accuracy on the average among the reduction of spectral bands (       R 2   &macr;      = 0.881,       R M S E  &macr;      = 0.625 and       M A E  &macr;      = 0.480). A comprehensive evaluation indicates that GBRT is an appealing alternative for cotton LAI retrieval, except for its computational efficiency. Despite the different performance of the ML models, all models exhibited considerable potential for cotton LAI retrieval, which could offer accurate crop parameters information timely and accurately for crop fields management and agricultural production decisions.},
DOI = {10.3390/app9071459}
}



@Article{app9071461,
AUTHOR = {Wada, Daichi and Tamayama, Masato},
TITLE = {Wing Load and Angle of Attack Identification by Integrating Optical Fiber Sensing and Neural Network Approach in Wind Tunnel Test},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1461},
URL = {https://www.mdpi.com/2076-3417/9/7/1461},
ISSN = {2076-3417},
ABSTRACT = {The load and angle of attack (AoA) for wing structures are critical parameters to be monitored for efficient operation of an aircraft. This study presents wing load and AoA identification techniques by integrating an optical fiber sensing technique and a neural network approach. We developed a 3.6-m semi-spanned wing model with eight flaps and bonded two optical fibers with 30 fiber Bragg gratings (FBGs) each along the main and aft spars. Using this model in a wind tunnel test, we demonstrate load and AoA identification through a neural network approach. We input the FBG data and the eight flap angles to a neural network and output estimated load distributions on the eight wing segments. Thereafter, we identify the AoA by using the estimated load distributions and the flap angles through another neural network. This multi-neural-network process requires only the FBG and flap angle data to be measured. We successfully identified the load distributions with an error range of &minus;1.5&ndash;1.4 N and a standard deviation of 0.57 N. The AoA was also successfully identified with error ranges of &minus;1.03&ndash;0.46&deg; and a standard deviation of 0.38&deg;.},
DOI = {10.3390/app9071461}
}



@Article{rs11070838,
AUTHOR = {Li, You and Zahran, Shady and Zhuang, Yuan and Gao, Zhouzheng and Luo, Yiran and He, Zhe and Pei, Ling and Chen, Ruizhi and El-Sheimy, Naser},
TITLE = {IMU/Magnetometer/Barometer/Mass-Flow Sensor Integrated Indoor Quadrotor UAV Localization with Robust Velocity Updates},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {838},
URL = {https://www.mdpi.com/2072-4292/11/7/838},
ISSN = {2072-4292},
ABSTRACT = {Velocity updates have been proven to be important for constraining motion-sensor-based dead-reckoning (DR) solutions in indoor unmanned aerial vehicle (UAV) applications. The forward velocity from a mass flow sensor and the lateral and vertical non-holonomic constraints (NHC) can be utilized for three-dimensional (3D) velocity updates. However, it is observed that (a) the quadrotor UAV may have a vertical velocity trend when it is controlled to move horizontally; (b) the quadrotor may have a pitch angle when moving horizontally; and (c) the mass flow sensor may suffer from sensor errors, especially the scale factor error. Such phenomenons degrade the performance of velocity updates. Thus, this paper presents a multi-sensor integrated localization system that has more effective sensor interactions. Specifically, (a) the barometer data are utilized to detect height changes and thus determine the weight of vertical velocity update; (b) the pitch angle from the inertial measurement unit (IMU) and magnetometer data fusion is used to set the weight of forward velocity update; and (c) an extra mass flow sensor calibration module is introduced. Indoor flight tests have indicated the effectiveness of the proposed sensor interaction strategies in enhancing indoor quadrotor DR solutions, which can also be used for detecting outliers in external localization technologies such as ultrasonics.},
DOI = {10.3390/rs11070838}
}



@Article{rs11070855,
AUTHOR = {Marques, Pedro and Pádua, Luís and Adão, Telmo and Hruška, Jonáš and Peres, Emanuel and Sousa, António and Sousa, Joaquim J.},
TITLE = {UAV-Based Automatic Detection and Monitoring of Chestnut Trees},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {855},
URL = {https://www.mdpi.com/2072-4292/11/7/855},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicles have become a popular remote sensing platform for agricultural applications, with an emphasis on crop monitoring. Although there are several methods to detect vegetation through aerial imagery, these remain dependent of manual extraction of vegetation parameters. This article presents an automatic method that allows for individual tree detection and multi-temporal analysis, which is crucial in the detection of missing and new trees and monitoring their health conditions over time. The proposed method is based on the computation of vegetation indices (VIs), while using visible (RGB) and near-infrared (NIR) domain combination bands combined with the canopy height model. An overall segmentation accuracy above 95% was reached, even when RGB-based VIs were used. The proposed method is divided in three major steps: (1) segmentation and first clustering; (2) cluster isolation; and (3) feature extraction. This approach was applied to several chestnut plantations and some parameters&mdash;such as the number of trees present in a plantation (accuracy above 97%), the canopy coverage (93% to 99% accuracy), the tree height (RMSE of 0.33 m and R2 = 0.86), and the crown diameter (RMSE of 0.44 m and R2 = 0.96)&mdash;were automatically extracted. Therefore, by enabling the substitution of time-consuming and costly field campaigns, the proposed method represents a good contribution in managing chestnut plantations in a quicker and more sustainable way.},
DOI = {10.3390/rs11070855}
}



@Article{rs11070863,
AUTHOR = {Fradette, Marie-Soleil and Leboeuf, Antoine and Riopel, Martin and Bégin, Jean},
TITLE = {Method to Reduce the Bias on Digital Terrain Model and Canopy Height Model from LiDAR Data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {863},
URL = {https://www.mdpi.com/2072-4292/11/7/863},
ISSN = {2072-4292},
ABSTRACT = {Underestimation of LiDAR heights is widely known but has never been evaluated for several sensors and for diverse types of ecological conditions. This underestimation is mainly linked to the probability of the pulse to reach the ground and the top of vegetation. Main causes of this underestimation are pulse density, pattern of scan (sensors), scan angles, specific contract parameters (flying altitude, pulse repetition frequency) and characteristics of the territory (slopes, stand density and species composition). This study, carried out at a resolution of 1 &times; 1 m, first assessed the possibility of making an adjustment model to correct the bias of the digital terrain model (DTM), and then proposed a global adjustment model to correct the bias on the canopy height model (CHM). For this study, the bias of both DTM and CHM were calculated by subtracting two LiDAR datasets: high-density pixels with 21 pulses/m&sup2; (first return) and more (DTM or CHM reference value pixels) and low-density pixels (DTM or CHM value to correct). After preliminary analyses, it was concluded that the DTM did not need specific adjustment. In contrast, the CHM needed adjustments. Among the variables studied, three were selected for the final CHM adjustment model: the maximum height of the pixel (H2Corr); the density of first returns by m2 (D_first); and the standard deviation of nine maximum heights of the neighborhood cells (H_STD9). The modeling occurred in three steps. The first two steps enabled the determination of significant variables and the shape of the equation to be defined (linear mixed model and non-linear model). The third step made it possible to propose an empirical equation using a non-linear mixed model that can be applied to a 1 &times; 1 m CHM. The CHM underestimation correction could be used for a preliminary step to several uses of the CHM such as volume calculation, forest growth models or multi-temporal analysis.},
DOI = {10.3390/rs11070863}
}



@Article{en12071385,
AUTHOR = {Liu, Yao and Shi, Jianmai and Liu, Zhong and Huang, Jincai and Zhou, Tianren},
TITLE = {Two-Layer Routing for High-Voltage Powerline Inspection by Cooperated Ground Vehicle and Drone},
JOURNAL = {Energies},
VOLUME = {12},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1385},
URL = {https://www.mdpi.com/1996-1073/12/7/1385},
ISSN = {1996-1073},
ABSTRACT = {A novel high-voltage powerline inspection system was investigated, which consists of the cooperated ground vehicle and drone. The ground vehicle acts as a mobile platform that can launch and recycle the drone, while the drone can fly over the powerline for inspection within limited endurance. This inspection system enables the drone to inspect powerline networks in a very large area. Both vehicle&rsquo; route in the road network and drone&rsquo;s routes along the powerline network have to be optimized for improving the inspection efficiency, which generates a new Two-Layer Point-Arc Routing Problem (2L-PA-RP). Two constructive heuristics were designed based on &ldquo;Cluster First, Route Second&rdquo; and &ldquo;Route First, Split Second&rdquo;. Then, local search strategies were developed to further improve the quality of the solution. To test the performance of the proposed algorithms, different-scale practical cases were designed based on the road network and powerline network of Ji&rsquo;an, China. Sensitivity analysis on the parameters related to the drone&rsquo;s inspection speed and battery capacity was conducted. Computational results indicate that technical improvement on the inspection sensor is more important for the cooperated ground vehicle and drone system.},
DOI = {10.3390/en12071385}
}



@Article{s19071728,
AUTHOR = {Yang, Bo and Zhang, Sheng and Tian, Yan and Li, Bijun},
TITLE = {Front-Vehicle Detection in Video Images Based on Temporal and Spatial Characteristics},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1728},
URL = {https://www.mdpi.com/1424-8220/19/7/1728},
ISSN = {1424-8220},
ABSTRACT = {Assisted driving and unmanned driving have been areas of focus for both industry and academia. Front-vehicle detection technology, a key component of both types of driving, has also attracted great interest from researchers. In this paper, to achieve front-vehicle detection in unmanned or assisted driving, a vision-based, efficient, and fast front-vehicle detection method based on the spatial and temporal characteristics of the front vehicle is proposed. First, a method to extract the motion vector of the front vehicle is put forward based on Oriented FAST and Rotated BRIEF (ORB) and the spatial position constraint. Then, by analyzing the differences between the motion vectors of the vehicle and those of the background, feature points of the vehicle are extracted. Finally, a feature-point clustering method based on a combination of temporal and spatial characteristics are applied to realize front-vehicle detection. The effectiveness of the proposed algorithm is verified using a large number of videos.},
DOI = {10.3390/s19071728}
}



@Article{rs11070886,
AUTHOR = {Adriano, Bruno and Xia, Junshi and Baier, Gerald and Yokoya, Naoto and Koshimura, Shunichi},
TITLE = {Multi-Source Data Fusion Based on Ensemble Learning for Rapid Building Damage Mapping during the 2018 Sulawesi Earthquake and Tsunami in Palu, Indonesia},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {886},
URL = {https://www.mdpi.com/2072-4292/11/7/886},
ISSN = {2072-4292},
ABSTRACT = {This work presents a detailed analysis of building damage recognition, employing multi-source data fusion and ensemble learning algorithms for rapid damage mapping tasks. A damage classification framework is introduced and tested to categorize the building damage following the recent 2018 Sulawesi earthquake and tsunami. Three robust ensemble learning classifiers were investigated for recognizing building damage from Synthetic Aperture Radar (SAR) and optical remote sensing datasets and their derived features. The contribution of each feature dataset was also explored, considering different combinations of sensors as well as their temporal information. SAR scenes acquired by the ALOS-2 PALSAR-2 and Sentinel-1 sensors were used. The optical Sentinel-2 and PlanetScope sensors were also included in this study. A non-local filter in the preprocessing phase was used to enhance the SAR features. Our results demonstrated that the canonical correlation forests classifier performs better in comparison to the other classifiers. In the data fusion analysis, Digital Elevation Model (DEM)- and SAR-derived features contributed the most in the overall damage classification. Our proposed mapping framework successfully classifies four levels of building damage (with overall accuracy &gt;90%, average accuracy &gt;67%). The proposed framework learned the damage patterns from a limited available human-interpreted building damage annotation and expands this information to map a larger affected area. This process including pre- and post-processing phases were completed in about 3 h after acquiring all raw datasets.},
DOI = {10.3390/rs11070886}
}



@Article{rs11070888,
AUTHOR = {Du, Zhenrong and Yang, Jianyu and Ou, Cong and Zhang, Tingting},
TITLE = {Smallholder Crop Area Mapped with a Semantic Segmentation Deep Learning Method},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {888},
URL = {https://www.mdpi.com/2072-4292/11/7/888},
ISSN = {2072-4292},
ABSTRACT = {The growing population in China has led to an increasing importance of crop area (CA) protection. A powerful tool for acquiring accurate and up-to-date CA maps is automatic mapping using information extracted from high spatial resolution remote sensing (RS) images. RS image information extraction includes feature classification, which is a long-standing research issue in the RS community. Emerging deep learning techniques, such as the deep semantic segmentation network technique, are effective methods to automatically discover relevant contextual features and get better image classification results. In this study, we exploited deep semantic segmentation networks to classify and extract CA from high-resolution RS images. WorldView-2 (WV-2) images with only Red-Green-Blue (RGB) bands were used to confirm the effectiveness of the proposed semantic classification framework for information extraction and the CA mapping task. Specifically, we used the deep learning framework TensorFlow to construct a platform for sampling, training, testing, and classifying to extract and map CA on the basis of DeepLabv3+. By leveraging per-pixel and random sample point accuracy evaluation methods, we conclude that the proposed approach can efficiently obtain acceptable accuracy (Overall Accuracy = 95%, Kappa = 0.90) of CA classification in the study area, and the approach performs better than other deep semantic segmentation networks (U-Net/PspNet/SegNet/DeepLabv2) and traditional machine learning methods, such as Maximum Likelihood (ML), Support Vector Machine (SVM), and RF (Random Forest). Furthermore, the proposed approach is highly scalable for the variety of crop types in a crop area. Overall, the proposed approach can train a precise and effective model that is capable of adequately describing the small, irregular fields of smallholder agriculture and handling the great level of details in RGB high spatial resolution images.},
DOI = {10.3390/rs11070888}
}



@Article{rs11070890,
AUTHOR = {Jiang, Qi and Fang, Shenghui and Peng, Yi and Gong, Yan and Zhu, Renshan and Wu, Xianting and Ma, Yi and Duan, Bo and Liu, Jian},
TITLE = {UAV-Based Biomass Estimation for Rice-Combining Spectral, TIN-Based Structural and Meteorological Features},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {890},
URL = {https://www.mdpi.com/2072-4292/11/7/890},
ISSN = {2072-4292},
ABSTRACT = {Accurate estimation of above ground biomass (AGB) is very important for crop growth monitoring. The objective of this study was to estimate rice biomass by utilizing structural and meteorological features with widely used spectral features. Structural features were derived from the triangulated irregular network (TIN), which was directly built from structure from motion (SfM) point clouds. Growing degree days (GDD) was used as the meteorological feature. Three models were used to estimate rice AGB, including the simple linear regression (SLR) model, simple exponential regression (SER) model, and machine learning model (random forest). Compared to models that do not use structural and meteorological features (NDRE, R2 = 0.64, RMSE = 286.79 g/m2, MAE = 236.49 g/m2), models that include such features obtained better estimation accuracy (NDRE*Hcv/GDD, R2 = 0.86, RMSE = 178.37 g/m2, MAE = 127.34 g/m2). This study suggests that the estimation accuracy of rice biomass can benefit from the utilization of structural and meteorological features.},
DOI = {10.3390/rs11070890}
}



@Article{rs11080895,
AUTHOR = {Tsai, Ya-Lun S. and Dietz, Andreas and Oppelt, Natascha and Kuenzer, Claudia},
TITLE = {Wet and Dry Snow Detection Using Sentinel-1 SAR Data for Mountainous Areas with a Machine Learning Technique},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {895},
URL = {https://www.mdpi.com/2072-4292/11/8/895},
ISSN = {2072-4292},
ABSTRACT = {Traditional studies on mapping wet snow cover extent (SCE) often feature limitations, especially in vegetated and mountainous areas. The aim of this study is to propose a new total and wet SCE mapping strategy based on freely accessible spaceborne synthetic aperture radar (SAR) data. The approach is transferable on a global scale as well as for different land cover types (including densely vegetated forest and agricultural regions), and is based on the use of backscattering coefficient, interferometric SAR coherence, and polarimetric parameters. Furthermore, four topographical factors were included in the simple tuning of random forest-based land cover type-dependent classification strategy. Results showed the classification accuracy was above 0.75, with an F-measure higher than 0.70, in all five selected regions of interest located around globally distributed mountain ranges. Whilst excluding forest-type land cover classes, the accuracy and F-measure increases to 0.80 and 0.75. In cross-location model set, the accuracy can also be maintained at 0.80 with non-forest accuracy up to 0.85. It has been found that the elevation and polarimetric parameters are the most critical factors, and that the quality of land cover information would also affect the subsequent mapping reliability. In conclusion, through comprehensive validation using optical satellite and in-situ data, our land cover-dependent total SCE mapping approach has been confirmed to be robustly applicable, and the holistic SCE map for different months were eventually derived.},
DOI = {10.3390/rs11080895}
}



@Article{agriengineering1020013,
AUTHOR = {Das V., Jithin and Sharma, Shubham and Kaushik, Abhishek},
TITLE = {Views of Irish Farmers on Smart Farming Technologies: An Observational Study},
JOURNAL = {AgriEngineering},
VOLUME = {1},
YEAR = {2019},
NUMBER = {2},
PAGES = {164--187},
URL = {https://www.mdpi.com/2624-7402/1/2/13},
ISSN = {2624-7402},
ABSTRACT = {The primary objective of this research is to find the disparity for slow adoption of Smart Farming Technologies (SFT) in Ireland. The usage of Cloud Computing technology among Irish farmers would help to find out the adoption behaviour barrier and way to enhance from the present system. The research will also help us to indicate the reasons for farmers in adopting and not adopting any technology. The research followed a mixed method where both surveys and interviews were used to collect the data from Irish farmers. A total sample of 32 farmers were selected through snowball sampling with the help of social websites. This study explored the major factors in adopting new technology among Irish farmers. It also helped to find the perception of farmers and ways to improve from the present system. The result shows that Cloud Computing adoption among the young farmers is greater while it is lower among the old farmers in Ireland.},
DOI = {10.3390/agriengineering1020013}
}



@Article{s19081800,
AUTHOR = {Brini, Oussama and Deslandes, Dominic and Nabki, Frederic},
TITLE = {A System-Level Methodology for the Design of Reliable Low-Power Wireless Sensor Networks},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {1800},
URL = {https://www.mdpi.com/1424-8220/19/8/1800},
ISSN = {1424-8220},
ABSTRACT = {Innovative Internet of Things (IoT) applications with strict performance and energy consumption requirements and where the agile collection of data is paramount are arising. Wireless sensor networks (WSNs) represent a promising solution as they can be easily deployed to sense, process, and forward data. The large number of Sensor Nodes (SNs) composing a WSN are expected to be autonomous, with a node&rsquo;s lifetime dictated by the battery&rsquo;s size. As the form factor of the SN is critical in various use cases, minimizing energy consumption while ensuring availability becomes a priority. Moreover, energy harvesting techniques are increasingly considered as a viable solution for building an entirely green SN and prolonging its lifetime. In the process of building a SN and in the absence of a clear and well-rounded methodology, the designer can easily make unfounded and suboptimal decisions about the right hardware components, their configuration, and reliable data communication techniques, such as automatic repeat request (ARQ) and forward error correction (FEC). In this paper, a methodology to design, configure, and deploy a reliable ultra-low power WSNs is proposed. A comprehensive energy model and a realistic path-loss (PL) model of the sensor node are also established. Through estimations and field measurements it is proven that, following the proposed methodology, the designer can thoroughly explore the design space and the make most favorable decisions when choosing commercial off-the-shelf (COTS) components, configuring the node, and deploying a reliable and energy-efficient WSN.},
DOI = {10.3390/s19081800}
}



@Article{rs11080920,
AUTHOR = {Shah, Syed Haleem and Angel, Yoseline and Houborg, Rasmus and Ali, Shawkat and McCabe, Matthew F.},
TITLE = {A Random Forest Machine Learning Approach for the Retrieval of Leaf Chlorophyll Content in Wheat},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {920},
URL = {https://www.mdpi.com/2072-4292/11/8/920},
ISSN = {2072-4292},
ABSTRACT = {Developing rapid and non-destructive methods for chlorophyll estimation over large spatial areas is a topic of much interest, as it would provide an indirect measure of plant photosynthetic response, be useful in monitoring soil nitrogen content, and offer the capacity to assess vegetation structural and functional dynamics. Traditional methods of direct tissue analysis or the use of handheld meters, are not able to capture chlorophyll variability at anything beyond point scales, so are not particularly useful for informing decisions on plant health and status at the field scale. Examining the spectral response of plants via remote sensing has shown much promise as a means to capture variations in vegetation properties, while offering a non-destructive and scalable approach to monitoring. However, determining the optimum combination of spectra or spectral indices to inform plant response remains an active area of investigation. Here, we explore the use of a machine learning approach to enhance the estimation of leaf chlorophyll (Chlt), defined as the sum of chlorophyll a and b, from spectral reflectance data. Using an ASD FieldSpec 4 Hi-Res spectroradiometer, 2700 individual leaf hyperspectral reflectance measurements were acquired from wheat plants grown across a gradient of soil salinity and nutrient levels in a greenhouse experiment. The extractable Chlt was determined from laboratory analysis of 270 collocated samples, each composed of three leaf discs. A random forest regression algorithm was trained against these data, with input predictors based upon (1) reflectance values from 2102 bands across the 400&ndash;2500 nm spectral range; and (2) 45 established vegetation indices. As a benchmark, a standard univariate regression analysis was performed to model the relationship between measured Chlt and the selected vegetation indices. Results show that the root mean square error (RMSE) was significantly reduced when using the machine learning approach compared to standard linear regression. When exploiting the entire spectral range of individual bands as input variables, the random forest estimated Chlt with an RMSE of 5.49 &micro;g&middot;cm&minus;2 and an R2 of 0.89. Model accuracy was improved when using vegetation indices as input variables, producing an RMSE ranging from 3.62 to 3.91 &micro;g&middot;cm&minus;2, depending on the particular combination of indices selected. In further analysis, input predictors were ranked according to their importance level, and a step-wise reduction in the number of input features (from 45 down to 7) was performed. Implementing this resulted in no significant effect on the RMSE, and showed that much the same prediction accuracy could be obtained by a smaller subset of indices. Importantly, the random forest regression approach identified many important variables that were not good predictors according to their linear regression statistics. Overall, the research illustrates the promise in using established vegetation indices as input variables in a machine learning approach for the enhanced estimation of Chlt from hyperspectral data.},
DOI = {10.3390/rs11080920}
}



@Article{s19081818,
AUTHOR = {Liu, Yuan and Sui, Xiubao and Kuang, Xiaodong and Liu, Chengwei and Gu, Guohua and Chen, Qian},
TITLE = {Object Tracking Based on Vector Convolutional Network and Discriminant Correlation Filters},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {1818},
URL = {https://www.mdpi.com/1424-8220/19/8/1818},
ISSN = {1424-8220},
ABSTRACT = {Due to the fast speed and high efficiency, discriminant correlation filter (DCF) has drawn great attention in online object tracking recently. However, with the improvement of performance, the costs are the increase in parameters and the decline of speed. In this paper, we propose a novel visual tracking algorithm, namely VDCFNet, and combine DCF with a vector convolutional network (VCNN). We replace one traditional convolutional filter with two novel vector convolutional filters in the convolutional stage of our network. This enables our model with few memories (only 59 KB) trained offline to learn the generic image features. In the online tracking stage, we propose a coarse-to-fine search strategy to solve drift problems under fast motion. Besides, we update model selectively to speed up and increase robustness. The experiments on OTB benchmarks demonstrate that our proposed VDCFNet can achieve a competitive performance while running over real-time speed.},
DOI = {10.3390/s19081818}
}



@Article{rs11080925,
AUTHOR = {Zhu, Jiasong and Chen, Siyuan and Tu, Wei and Sun, Ke},
TITLE = {Tracking and Simulating Pedestrian Movements at Intersections Using Unmanned Aerial Vehicles},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {925},
URL = {https://www.mdpi.com/2072-4292/11/8/925},
ISSN = {2072-4292},
ABSTRACT = {For a city to be livable and walkable is the ultimate goal of future cities. However, conflicts among pedestrians, vehicles, and cyclists at traffic intersections are becoming severe in high-density urban transportation areas, especially in China. Correspondingly, the transit time at intersections is becoming prolonged, and pedestrian safety is becoming endangered. Simulating pedestrian movements at complex traffic intersections is necessary to optimize the traffic organization. We propose an unmanned aerial vehicle (UAV)-based method for tracking and simulating pedestrian movements at intersections. Specifically, high-resolution videos acquired by a UAV are used to recognize and position moving targets, including pedestrians, cyclists, and vehicles, using the convolutional neural network. An improved social force-based motion model is proposed, considering the conflicts among pedestrians, cyclists, and vehicles. In addition, maximum likelihood estimation is performed to calibrate an improved social force model. UAV videos of intersections in Shenzhen are analyzed to demonstrate the performance of the presented approach. The results demonstrate that the proposed social force-based motion model can effectively simulate the movement of pedestrians and cyclists at road intersections. The presented approach provides an alternative method to track and simulate pedestrian movements, thus benefitting the organization of pedestrian flow and traffic signals controlling the intersections.},
DOI = {10.3390/rs11080925}
}



@Article{s19081824,
AUTHOR = {Tzitzilonis, Vasileios and Malandrakis, Konstantinos and Zanotti Fragonara, Luca and Gonzalez Domingo, Jose Angel and Avdelidis, Nicolas P. and Tsourdos, Antonios and Forster, Kevin},
TITLE = {Inspection of Aircraft Wing Panels Using Unmanned Aerial Vehicles},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {1824},
URL = {https://www.mdpi.com/1424-8220/19/8/1824},
ISSN = {1424-8220},
ABSTRACT = {In large civil aircraft manufacturing, a time-consuming post-production process is the non-destructive inspection of wing panels. This work aims to address this challenge and improve the defects&rsquo; detection by performing automated aerial inspection using a small off-the-shelf multirotor. The UAV is equipped with a wide field-of-view camera and an ultraviolet torch for implementing non-invasive imaging inspection. In particular, the UAV is programmed to perform the complete mission and stream video, in real-time, to the ground control station where the defects&rsquo; detection algorithm is executed. The proposed platform was mathematically modelled in MATLAB/SIMULINK in order to assess the behaviour of the system using a path following method during the aircraft wing inspection. In addition, two defect detection algorithms were implemented and tested on a dataset containing images obtained during inspection at Airbus facilities. The results show that for the current dataset the proposed methods can identify all the images containing defects.},
DOI = {10.3390/s19081824}
}



@Article{rs11080928,
AUTHOR = {Swinfield, Tom and Lindsell, Jeremy A. and Williams, Jonathan V. and Harrison, Rhett D. and Agustiono and Habibi and Gemita, Elva and Schönlieb, Carola B. and Coomes, David A.},
TITLE = {Accurate Measurement of Tropical Forest Canopy Heights and Aboveground Carbon Using Structure From Motion},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {928},
URL = {https://www.mdpi.com/2072-4292/11/8/928},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicles are increasingly used to monitor forests. Three-dimensional models of tropical rainforest canopies can be constructed from overlapping photos using Structure from Motion (SfM), but it is often impossible to map the ground elevation directly from such data because canopy gaps are rare in rainforests. Without knowledge of the terrain elevation, it is, thus, difficult to accurately measure the canopy height or forest properties, including the recovery stage and aboveground carbon density. Working in an Indonesian ecosystem restoration landscape, we assessed how well SfM derived the estimates of the canopy height and aboveground carbon density compared with those from an airborne laser scanning (also known as LiDAR) benchmark. SfM systematically underestimated the canopy height with a mean bias of approximately 5 m. The linear models suggested that the bias increased quadratically with the top-of-canopy height for short, even-aged, stands but linearly for tall, structurally complex canopies (&gt;10 m). The predictions based on the simple linear model were closely correlated to the field-measured heights when the approach was applied to an independent survey in a different location (    R 2     = 67% and RMSE = 1.85 m), but a negative bias of 0.89 m remained, suggesting the need to refine the model parameters with additional training data. Models that included the metrics of canopy complexity were less biased but with a reduced     R 2    . The inclusion of ground control points (GCPs) was found to be important in accurately registering SfM measurements in space, which is essential if the survey requirement is to produce small-scale restoration interventions or to track changes through time. However, at the scale of several hectares, the top-of-canopy height and above-ground carbon density estimates from SfM and LiDAR were very similar even without GCPs. The ability to produce accurate top-of-canopy height and carbon stock measurements from SfM is game changing for forest managers and restoration practitioners, providing the means to make rapid, low-cost surveys over hundreds of hectares without the need for LiDAR.},
DOI = {10.3390/rs11080928}
}



@Article{s19081832,
AUTHOR = {Ma, Liqun and Xia, Haoming and Meng, Qingmin},
TITLE = {Spatiotemporal Variability of Asymmetric Daytime and Night-Time Warming and Its Effects on Vegetation in the Yellow River Basin from 1982 to 2015},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {1832},
URL = {https://www.mdpi.com/1424-8220/19/8/1832},
ISSN = {1424-8220},
ABSTRACT = {Temperatures from 1982 to 2015 have exhibited an asymmetric warming pattern between day and night throughout the Yellow River Basin. The response to this asymmetric warming can be linked to vegetation growth as quantified by the NDVI (Normalized Difference Vegetation Index). In this study, the time series trends of the maximum temperature (Tmax) and the minimum temperature (Tmin) and their spatial patterns in the growing season (April&ndash;October) of the Yellow River Basin from 1982 to 2015 were analyzed. We evaluated how vegetation NDVI had responded to daytime and night-time warming, based on NDVI and meteorological parameters (precipitation and temperature) over the period 1982&ndash;2015. We found: (1) a persistent increase in the growing season Tmax and Tmin in 1982&ndash;2015 as confirmed by using the Mann&ndash;Kendall (M&ndash;K) non-parametric test method (p &lt; 0.01), where the rate of increase of Tmin was 1.25 times that of Tmax, and thus the diurnal warming was asymmetric during 1982&ndash;2015; (2) the partial correlation between Tmax and NDVI was significantly positive only for cultivated plants, shrubs, and desert, which means daytime warming may increase arid and semi-arid vegetation&rsquo;s growth and coverage, and cultivated plants&rsquo; growth and yield. The partial correlation between Tmin and NDVI of all vegetation types except broadleaf forest is very significant (p &lt; 0.01) and, therefore, it has more impacts vegetation across the whole basin. This study demonstrates a methodogy for studying regional responses of vegetation to climate extremes under global climate change.},
DOI = {10.3390/s19081832}
}



@Article{drones3020038,
AUTHOR = {Raber, George T. and Schill, Steven R.},
TITLE = {Reef Rover: A Low-Cost Small Autonomous Unmanned Surface Vehicle (USV) for Mapping and Monitoring Coral Reefs},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {38},
URL = {https://www.mdpi.com/2504-446X/3/2/38},
ISSN = {2504-446X},
ABSTRACT = {In the effort to design a more repeatable and consistent platform to collect data for Structure from Motion (SfM) monitoring of coral reefs and other benthic habitats, we explore the use of recent advances in open source Global Positioning System (GPS)-guided drone technology to design and test a low-cost and transportable small unmanned surface vehicle (sUSV). The vehicle operates using Ardupilot open source software and can be used by local scientists and marine managers to map and monitor marine environments in shallow areas (&lt;20 m) with commensurate visibility. The imaging system uses two Sony a6300 mirrorless cameras to collect stereo photos that can be later processed using photogrammetry software to create underwater high-resolution orthophoto mosaics and digital surface models. The propulsion system consists of two small brushless motors powered by lithium batteries that follow pre-programmed survey transects and are operated by a GPS-guided autopilot control board. Results from our project suggest the sUSV provides a repeatable, viable, and low-cost (&lt;$3000 USD) solution for acquiring images of benthic environments on a frequent basis from directly below the water surface. These images can be used to create SfM models that provide very detailed images and measurements that can be used to monitor changes in biodiversity, reef erosion/accretion, and assessing health conditions.},
DOI = {10.3390/drones3020038}
}



@Article{s19081875,
AUTHOR = {Galán-Jiménez, Jaime and Berrocal, Javier and Garcia-Alonso, Jose and Azabal, Manuel Jesús},
TITLE = {A Novel Routing Scheme for Creating Opportunistic Context-Virtual Networks in IoT Scenarios},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {1875},
URL = {https://www.mdpi.com/1424-8220/19/8/1875},
ISSN = {1424-8220},
ABSTRACT = {The massive amount of traffic required by the emerging Internet of Things (IoT) paradigm can be supported by the imminent arrival of 5G next-generation networks. However, the limited capacity of resources in IoT nodes, e.g., battery lifetime or buffer space, opens a challenge to be taken into account when proposing new routing solutions on IoT scenarios with intermittent connectivity. In this paper, we propose the concept of Opportunistic Context-Virtual Networks (OCVNs). The novelty of this approach is to create virtual groups of nodes that share interests in common for routing purposes. Therefore, only the nodes that are interested in the content of the messages that are flowing throughout the network are used as relaying nodes, providing their own resources for the sake of the communication. By leveraging the use of store-carry-and-forward mechanisms, a novel routing algorithm is proposed and evaluated over two realistic scenarios. Experimental results reveal that our solution outperforms other well-known opportunistic routing algorithms in terms of delivery probability and overhead ratio, while resource usage of relaying nodes is significantly reduced.},
DOI = {10.3390/s19081875}
}



@Article{rs11080950,
AUTHOR = {Piermattei, Livia and Karel, Wilfried and Wang, Di and Wieser, Martin and Mokroš, Martin and Surový, Peter and Koreň, Milan and Tomaštík, Julián and Pfeifer, Norbert and Hollaus, Markus},
TITLE = {Terrestrial Structure from Motion Photogrammetry for Deriving Forest Inventory Data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {950},
URL = {https://www.mdpi.com/2072-4292/11/8/950},
ISSN = {2072-4292},
ABSTRACT = {The measurements of tree attributes required for forest monitoring and management planning, e.g., National Forest Inventories, are derived by rather time-consuming field measurements on sample plots, using calipers and measurement tapes. Therefore, forest managers and researchers are looking for alternative methods. Currently, terrestrial laser scanning (TLS) is the remote sensing method that provides the most accurate point clouds at the plot-level to derive these attributes from. However, the demand for even more efficient and effective solutions triggers further developments to lower the acquisition time, costs, and the expertise needed to acquire and process 3D point clouds, while maintaining the quality of extracted tree parameters. In this context, photogrammetry is considered a potential solution. Despite a variety of studies, much uncertainty still exists about the quality of photogrammetry-based methods for deriving plot-level forest attributes in natural forests. Therefore, the overall goal of this study is to evaluate the competitiveness of terrestrial photogrammetry based on structure from motion (SfM) and dense image matching for deriving tree positions, diameters at breast height (DBHs), and stem curves of forest plots by means of a consumer grade camera. We define an image capture method and we assess the accuracy of the photogrammetric results on four forest plots located in Austria and Slovakia, two in each country, selected to cover a wide range of conditions such as terrain slope, undergrowth vegetation, and tree density, age, and species. For each forest plot, the reference data of the forest parameters were obtained by conducting field surveys and TLS measurements almost simultaneously with the photogrammetric acquisitions. The TLS data were also used to estimate the accuracy of the photogrammetric ground height, which is a necessary product to derive DBHs and tree heights. For each plot, we automatically derived tree counts, tree positions, DBHs, and part of the stem curve from both TLS and SfM using a software developed at TU Wien (Forest Analysis and Inventory Tool, FAIT), and the results were compared. The images were oriented with errors of a few millimetres only, according to checkpoint residuals. The automatic tree detection rate for the SfM reconstruction ranges between 65% and 98%, where the missing trees have average DBHs of less than 12 cm. For each plot, the mean error of SfM and TLS DBH estimates is &minus;1.13 cm and &minus;0.77 cm with respect to the caliper measurements. The resulting stem curves show that the mean differences between SfM and TLS stem diameters is at maximum &minus;2.45 cm up to 3 m above ground, which increases to almost +4 cm for higher elevations. This study shows that with the adopted image capture method, terrestrial SfM photogrammetry, is an accurate solution to support forest inventory for estimating the number of trees and their location, the DBHs and stem curve up to 3 m above ground.},
DOI = {10.3390/rs11080950}
}



@Article{drones3020040,
AUTHOR = {Barbedo, Jayme Garcia Arnal},
TITLE = {A Review on the Use of Unmanned Aerial Vehicles and Imaging Sensors for Monitoring and Assessing Plant Stresses},
JOURNAL = {Drones},
VOLUME = {3},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {40},
URL = {https://www.mdpi.com/2504-446X/3/2/40},
ISSN = {2504-446X},
ABSTRACT = {Unmanned aerial vehicles (UAVs) are becoming a valuable tool to collect data in a variety of contexts. Their use in agriculture is particularly suitable, as those areas are often vast, making ground scouting difficult, and sparsely populated, which means that injury and privacy risks are not as important as in urban settings. Indeed, the use of UAVs for monitoring and assessing crops, orchards, and forests has been growing steadily during the last decade, especially for the management of stresses such as water, diseases, nutrition deficiencies, and pests. This article presents a critical overview of the main advancements on the subject, focusing on the strategies that have been used to extract the information contained in the images captured during the flights. Based on the information found in more than 100 published articles and on our own research, a discussion is provided regarding the challenges that have already been overcome and the main research gaps that still remain, together with some suggestions for future research.},
DOI = {10.3390/drones3020040}
}



@Article{rs11080953,
AUTHOR = {Paz-Kagan, Tarin and Silver, Micha and Panov, Natalya and Karnieli, Arnon},
TITLE = {Multispectral Approach for Identifying Invasive Plant Species Based on Flowering Phenology Characteristics},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {953},
URL = {https://www.mdpi.com/2072-4292/11/8/953},
ISSN = {2072-4292},
ABSTRACT = {Invasive plant species (IPS) are the second biggest threat to biodiversity after habitat loss. Since the spatial extent of IPS is essential for managing the invaded ecosystem, the current study aims at identifying and mapping the aggressive IPS of Acacia salicina and Acacia saligna, to understand better the key factors influencing their distribution in the coastal plain of Israel. This goal was achieved by integrating airborne-derived hyperspectral imaging and multispectral earth observation for creating species distribution maps. Hyperspectral data, in conjunction with high spatial resolution species distribution maps, were used to train the multispectral images at the species level. We incorporated a series of statistical models to classify the IPS location and to recognize their distribution and density. We took advantage of the phenological flowering stages of Acacia trees, as obtained by the multispectral images, for the support vector machine classification procedure. The classification yielded an overall Kappa coefficient accuracy of 0.89. We studied the effect of various environmental and human factors on IPS density by using a random forest machine learning model, to understand the mechanisms underlying successful invasions, and to assess where IPS have a higher likelihood of occurring. This algorithm revealed that the high density of Acacia most closely related to elevation, temperature pattern, and distances from rivers, settlements, and roads. Our results demonstrate how the integration of remote-sensing data with different data sources can assist in determining IPS proliferation and provide detailed geographic information for conservation and management efforts to prevent their future spread.},
DOI = {10.3390/rs11080953}
}




@article{HAONAN2021114504,
title = {Fuzzy rule-based neural appointed-time control for uncertain nonlinear systems with aperiodic samplings},
journal = {Expert Systems with Applications},
volume = {170},
pages = {114504},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.114504},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420311489},
author = {Si Haonan and Shao Xingling and Zhang Wendong},
keywords = {Fuzzy wavelet neural network, Improved prescribed performance control, State observer, Event-triggered control, Unknown control coefficients},
abstract = {In this paper, a fuzzy rule-based neural appointed-time control scheme for uncertain nonlinear systems with aperiodic samplings is proposed. To guarantee tracking properties with preassigned convergence time and remove the high dependency on accurate initial states of system, we construct an improved prescribed performance control (IPPC) scheme on the basis of a hyperbolic cosecant performance function with a finite-time behavior. In light of the unavailability of partial states and uncertainties, by combining a fuzzy wavelet neural network (FWNN) with a state observer, a FWNN-based state observer is developed, which can simultaneously approximate unavailable system states and unknown lumped disturbances with a remarkable accuracy. In addition, aimed at eliminating the problem of parameter updating explosion caused by overlarge learning dimensions, a minimum-learning-parameter (MLP) technique is embedded in the FWNN-based state observer, where the norm of weight matrix is employed for online adaptive updating. Furthermore, an event-triggered control scheme with relative thresholds is synthesized within the framework of dynamic surface control (DSC), which can allow for aperiodic samplings to save communication and actuating resources. Meanwhile, a Nussbaum type function is introduced to solve the issue of unknown control coefficients. The significant features of our work are twofold: (1) Appointed-time tracking performances with much fewer sampling times are assured. (2) An enhanced robustness against uncertainties is achieved with a lower computational complexity and the requirement of full-state measurements is relaxed. Finally, two simulation examples are performed to validate the effectiveness and advantages of the proposed control scheme.}
}
@article{ZHANG2020166,
title = {Object fusion tracking based on visible and infrared images: A comprehensive review},
journal = {Information Fusion},
volume = {63},
pages = {166-187},
year = {2020},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2020.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1566253520302657},
author = {Xingchen Zhang and Ping Ye and Henry Leung and Ke Gong and Gang Xiao},
keywords = {Fusion tracking, Deep learning, Object tracking, RGBT, Correlation filter},
abstract = {Visual object tracking has attracted widespread interests recently. Due to the complementary features provided by visible and infrared images, fusion tracking based on visible and infrared images can boost the tracking performance under adverse challenging conditions. RGB-infrared fusion tracking has become an active research topic and various algorithms have been proposed in recent years. In this paper, we present a review on RGB-infrared fusion tracking. We summarize all major RGB-infrared trackers in the literature and categorize them into several major groups for better understanding. We also discuss the development of RGB-infrared datasets, and analyze the main results on public datasets. We observe that deep learning-based methodsachieve the state-of-the-art performances. Besides, the graph-based and correlation filter-based methods give a bit worse but still competitive performances. In conclusion, we give some suggestions on future research directions of fusion tracking based on our observations. This review can serve as a reference for researchers in RGB-infrared fusion tracking, image fusion, and related fields.}
}
@article{SHARMA2021101415,
title = {Resource allocation trends for ultra dense networks in 5G and beyond networks: A classification and comprehensive survey},
journal = {Physical Communication},
volume = {48},
pages = {101415},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101415},
url = {https://www.sciencedirect.com/science/article/pii/S187449072100152X},
author = {Nidhi Sharma and Krishan Kumar},
keywords = {Resource allocation, LTE-U, Cognitive radio, HetNets, Ultra dense networks},
abstract = {With an exaggerating upsurge in mobile data traffic, the wireless networks are confronted with a subtle task of enhancing their network capacity. The shortage of spectrum resources creates a jamming situation in the enhancement of network capacity. To overcome this challenge, cellular networks have been persuaded to seek more fruitful radio spectra. That is why the wireless industry has been experiencing a new evolution through ultra-densification. Ultra dense networks (UDNs) involving LTE-U, cognitive radio networks, heterogeneous networks, cloud-radio access networks, device to device networks and millimeter wave networks appear to be the leading technologies for many more years to come for achieving the distinct capabilities that 5G and beyond networks are expected to provide. Therefore, these technologies will be a crucial enabler for next-generation mobile communications for enhancing capacity. As the resources are scarce which have to be shared by ubiquitous users, therefore it becomes more impelling to follow resource allocation approaches. Hence, the resource allocation in cellular networks inherently makes endeavors for the maximization of resource utilization such as spectrum efficiency, power efficiency etc. In this direction, the article provides a detailed survey of resource allocation approaches for UDNs in 5G and beyond networks. Specifically, in the first phase, this article presents the resource allocation process in different scenarios of UDNs. In the second phase, a taxonomy to classify the resource allocation problem based on approaches, methods, and optimization criteria has been reviewed. The last phase alleviates the main difficulties of the resource allocation process in the wireless network; some prevailing and feasible techniques are presented in detail too. Finally, the emerging technologies, challenges and active research initiatives are outlined which require the attention of the researchers.}
}
@article{CAPI2012156,
title = {Multiple Robots Formation–A Multiobjctive Evolution Approach},
journal = {Procedia Engineering},
volume = {41},
pages = {156-162},
year = {2012},
note = {International Symposium on Robotics and Intelligent Sensors 2012 (IRIS 2012)},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2012.07.156},
url = {https://www.sciencedirect.com/science/article/pii/S1877705812025428},
author = {Genci Capi and Zulkifli Mohamed},
keywords = {Robot formation, Neural networks, evolution},
abstract = {In this paper, we present a new method for multiple robots formation, which means certain geometrical constrains on the relative positions and orientations of the robots throughout their travel. In our method, we apply multiobjective evolutionary computation to generate the neural networks that control the robots to get to the target position relative to the leader robot. The advantage of the proposed algorithm is that in a single run of multiobjective evolution are generated multiple neural controllers. We can select neural networks that control each robot to get to the target position relative to the leader robot. In addition, the robots can switch between neural controllers, therefore creating different geometrical formations. The simulation and experimental results show that the multiobjective-based evolutionary method can be applied effectively for generating neural networks which enable the robots to perform formation tasks.}
}
@article{CONG2019106967,
title = {Novel event analysis for human-machine collaborative underwater exploration},
journal = {Pattern Recognition},
volume = {96},
pages = {106967},
year = {2019},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2019.106967},
url = {https://www.sciencedirect.com/science/article/pii/S0031320319302705},
author = {Yang Cong and Baojie Fan and Dongdong Hou and Huijie Fan and Kaizhou Liu and Jiebo Luo},
keywords = {Underwater, Underwater robot, Visual summarization, Visual saliency, Visual tracking, Robot vision, Video analysis, Novel event, Deep sea},
abstract = {One of the main task for deep sea submersible is for human-machine collaborative scientific exploration, e.g., human ourselves drive the submersible and monitor cameras around the submersible to observe new species fish or strange topography in a tedious way. In this paper, by defining novel marine animals or any extreme events as novel events, we design a new deep sea novel visual event analysis framework to improve the efficiency of human-machine collaboration and improve the accuracy simultaneously. Specifically, our visual framework concerns diverse functions than most state-of-the-arts, including novel event detection, tracking and summarization. Due to the power and computation resource limitation of the submersible, we design an efficient deep learning based visual saliency method for novel event detection and propose an online object tracking strategy as well. All the experiments are depending on Chinese Jiaolong, the manned deep sea submersible, which mounts several PanCtiltCzoom (PTZ) camera and static cameras. We build a new novel deep sea event dataset and the results justify that our human-machine collaborative visual observation framework can automatically detect, track and summarize the novel deep sea event.}
}
@article{PEI2021207,
title = {GIScience and remote sensing in natural resource and environmental research: Status quo and future perspectives},
journal = {Geography and Sustainability},
volume = {2},
number = {3},
pages = {207-215},
year = {2021},
issn = {2666-6839},
doi = {https://doi.org/10.1016/j.geosus.2021.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S2666683921000389},
author = {Tao Pei and Jun Xu and Yu Liu and Xin Huang and Liqiang Zhang and Weihua Dong and Chengzhi Qin and Ci Song and Jianya Gong and Chenghu Zhou},
keywords = {Natural resource, Environmental science, GIScience, Remote sensing, Information technology},
abstract = {Geographic information science (GIScience) and remote sensing have long provided essential data and methodological support for natural resource challenges and environmental problems research. With increasing advances in information technology, natural resource and environmental science research faces the dual challenges of data and computational intensiveness. Therefore, the role of remote sensing and GIScience in the fields of natural resources and environmental science in this new information era is a key concern of researchers. This study clarifies the definition and frameworks of these two disciplines and discusses their role in natural resource and environmental research. GIScience is the discipline that studies the abstract and formal expressions of the basic concepts and laws of geography, and its research framework mainly consists of geo-modeling, geo-analysis, and geo-computation. Remote sensing is a comprehensive technology that deals with the mechanisms of human effects on the natural ecological environment system by observing the earth surface system. Its main areas include sensors and platforms, information processing and interpretation, and natural resource and environmental applications. GIScience and remote sensing provide data and methodological support for resource and environmental science research. They play essential roles in promoting the development of resource and environmental science and other related technologies. This paper provides forecasts of ten future directions for GIScience and eight future directions for remote sensing, which aim to solve issues related to natural resources and the environment.}
}
@article{LIU2022107913,
title = {HCDC-SRCF tracker: Learning an adaptively multi-feature fuse tracker in spatial regularized correlation filters framework},
journal = {Knowledge-Based Systems},
volume = {238},
pages = {107913},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107913},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121010674},
author = {Bing Liu and Xiaojun Chang and Di Yuan and Yong Yang},
keywords = {Multi-layer convolutional features, Hand-crafted features, Visual object tracking, Convolutional neural network},
abstract = {Integrating multi-feature based on multi-layer features from the convolutional network or based on multiple hand-crafted features has been proved to be an effective way for improving tracking performance. In this work, we investigate how to integrate multi-layer convolutional features with hand-crafted features. Specifically, an adaptive multi-feature fusion strategy is proposed based on convolutional features from ResNet-101 and hand-crafted features from HOG as well as Grayscale in spatial regularized correlation filter framework. We fully consider the complementary advantages of multi-layer convolutional features and hand-crafted features to construct a robust and reliable appearance representation of the target. Comprehensive experimental results on benchmark datasets demonstrate that our tracker has achieved significant performance improvements in various challenging environments. Compared to the trackers based only on multi-layer convolutional features or complete hand-crafted fusion features, the most important is that our proposed tracker obtains more competitive tracking performance. Our tracker is publicly available. You can find open-sourced code of our tracker at https://github.com/binger1225/HCDC-SRCF.}
}
@article{ISLAM2021102225,
title = {A Survey on Task Offloading in Multi-access Edge Computing},
journal = {Journal of Systems Architecture},
volume = {118},
pages = {102225},
year = {2021},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2021.102225},
url = {https://www.sciencedirect.com/science/article/pii/S1383762121001570},
author = {Akhirul Islam and Arindam Debnath and Manojit Ghose and Suchetana Chakraborty},
keywords = {Multi-access edge computing, Task offloading, Mobile edge computing, Survey},
abstract = {With the advent of new technologies in both hardware and software, we are in the need of a new type of application that requires huge computation power and minimal delay. Applications such as face recognition, augmented reality, virtual reality, automated vehicles, industrial IoT, etc. belong to this category. Cloud computing technology is one of the candidates to satisfy the computation requirement of resource-intensive applications running in UEs (User Equipment) as it has ample computational capacity, but the latency requirement for these applications cannot be satisfied by the cloud due to the propagation delay between UEs and the cloud. To solve the latency issues for the delay-sensitive applications a new network paradigm has emerged recently known as Multi-Access Edge Computing (MEC) (also known as mobile edge computing) in which computation can be done at the network edge of UE devices. To execute the resource-intensive tasks of UEs in the MEC servers hosted in the network edge, a UE device has to offload some of the tasks to MEC servers. Few survey papers talk about task offloading in MEC, but most of them do not have in-depth analysis and classification exclusive to MEC task offloading. In this paper, we are providing a comprehensive survey on the task offloading scheme for MEC proposed by many researchers. We will also discuss issues, challenges, and future research direction in the area of task offloading to MEC servers.}
}
@article{ZHANG201635,
title = {An effective LS-SVM-based approach for surface roughness prediction in machined surfaces},
journal = {Neurocomputing},
volume = {198},
pages = {35-39},
year = {2016},
note = {Advances in Neural Networks, Intelligent Control and Information Processing},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.08.124},
url = {https://www.sciencedirect.com/science/article/pii/S0925231216003295},
author = {Nian Zhang and Devdas Shetty},
keywords = {Surface roughness prediction, Least squares support vector machine (LS-SVM), Neural networks, Levenberg–Marquardt algorithm, ANOVA, Machined surfaces},
abstract = {An effective least squares support vector machine (LS-SVM)-based approach was developed to predict the surface roughness in machined surface. The real AISI4340 steel and AISID2 steel data set was used to conduct the experiments. The analysis of variance (ANOVA) was used to validate the assumption of normal distribution, as well as the independent distribution of the errors. For the neural networks model, with 70%, 15%, and 15% of data as training, validation, and testing data, respectively, the best validation error is 0.0097343. The training error is 9.08888e–4 and the testing error is 1.09510e–1 accordingly. NN methods also discovered the correlation between the predicted surface roughness (Ra) and the actual surface roughness in the form of predicted Ra≅0.41*Actual Ra+0.2. The LS-SVM performance was also compared to the analysis of variance (ANOVA) method, and neural networks model trained by Levenberg–Marquardt algorithm. The experimental results showed that the proposed LS-SVM algorithm produced a determination coefficient of =0.9439, which is higher than the ANOVA and NN results of 0.1917 and 0.7266.}
}
@article{PANTAZI2017224,
title = {Evaluation of hierarchical self-organising maps for weed mapping using UAS multispectral imagery},
journal = {Computers and Electronics in Agriculture},
volume = {139},
pages = {224-230},
year = {2017},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2017.05.026},
url = {https://www.sciencedirect.com/science/article/pii/S0168169916308973},
author = {X.E. Pantazi and A.A. Tamouridou and T.K. Alexandridis and A.L. Lagopodi and J. Kashefi and D. Moshou},
keywords = {Precision farming, Site-specific weed management, Unmanned aircraft system, Neural networks, eBee},
abstract = {Remote sensing has been used for species discrimination and for operational weed mapping. In the study presented here, the detection and mapping of Silybum marianum using a hierarchical self-organising map is reported. A multispectral camera (green-red-NIR) mounted on a fixed wing Unmanned Aircraft System (UAS) was used for the acquisition of high-resolution images of a pixel size of 0.1m, resampled to 0.5m. The Supervised Kohonen Network (SKN), Counter-propagation Artificial Neural Network (CP-ANN) and XY-Fusion network (XY-F) were used to identify the S. marianum among other vegetation in a field, with Avena sterilis L. being predominant. As input features to the classifiers, the three spectral bands of Red, Green, Near Infrared (NIR) and the texture layer were used. The S. marianum identification rates using SKN achieved an accuracy level of 98.64%, the CP-ANN achieved 98.87%, while XY-F was 98.64%. The results prove the feasibility of operational S. marianum mapping using hierarchical self-organising maps on multispectral UAS imagery.}
}
@article{FU2020105321,
title = {Progress of hyperspectral data processing and modelling for cereal crop nitrogen monitoring},
journal = {Computers and Electronics in Agriculture},
volume = {172},
pages = {105321},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105321},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919318253},
author = {Yuanyuan Fu and Guijun Yang and Zhenhai Li and Heli Li and Zhenhong Li and Xingang Xu and Xiaoyu Song and Yunhe Zhang and Dandan Duan and Chunjiang Zhao and Liping Chen},
keywords = {Hyperspectral remote sensing, Cereal crop N status indicators, N-related hyperspectral feature analysis technique, Machine learning based regression, Radiative transfer model},
abstract = {Nitrogen (N) is the most limiting nutrient for cereal crop production, which often results in over-application of N fertilization to maximize crop yield. Negative environmental impacts and long-term reductions in productivity has encouraged site-specific N fertilization approaches, but these require timely and accurate crop N monitoring. The advent of hyperspectral remote sensing potentially provides a fast and economic way to accomplish this. A framework for hyperspectral remote sensing of cereal crop N is introduced, based on a comprehensive literature survey, to help inform monitoring best practices. Existing and potential crop N status indicators are summarized, with some recommendations provided. Hyperspectral analysis techniques for extracting N-related features are also examined and categorized into spatial domain and frequency domain based methods. In-depth analyses are conducted regarding: (1) the inconsistency in selected wavebands by different band selection methods and (2) determination of optimal wavelet, scale and wavelength in continuous wavelet transformations. Characteristics and deployment of machine learning based regression methods are also presented for crop N monitoring. Further, existing strategies to alleviate the ill-posed problem in physical and hybrid methods are outlined with some examples. Finally, the strengths and weaknesses of crop N retrieval methods are summarized to improve the understanding of how these methods affect prediction quality. Existing limitations and future areas of research emphasize on the fusion of crop N-related features from different domain spaces and the improved combination of empirical and physical methods.}
}
@article{CHANG2020119447,
title = {Smart cities in the 21st century},
journal = {Technological Forecasting and Social Change},
volume = {153},
pages = {119447},
year = {2020},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2018.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0040162518313465},
author = {Victor Chang and Sugam Sharma and Chung-Sheng Li}
}
@article{KAPLAN2021107468,
title = {Goal driven network pruning for object recognition},
journal = {Pattern Recognition},
volume = {110},
pages = {107468},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107468},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320302715},
author = {Cagri Kaplan and Abdullah Bulbul},
keywords = {Deep learning, Computer vision, Network pruning, Network compressing, Top-down attention, Perceptual visioning},
abstract = {Pruning studies up to date focused on uncovering a smaller network by removing redundant units, and fine-tuning to compensate accuracy drop as a result. In this study, unlike the others, we propose an approach to uncover a smaller network that is competent only in a specific task, similar to top-down attention mechanism in human visual system. This approach doesn’t require fine-tuning and is proposed as a fast and effective alternative of training from scratch when the network focuses on a specific task in the dataset. Pruning starts from the output and proceeds towards the input by computing neuron importance scores in each layer and propagating them to the preceding layer. In the meantime, neurons determined as worthless are pruned. We applied our approach on three benchmark datasets: MNIST, CIFAR-10 and ImageNet. The results demonstrate that the proposed pruning method typically reduces computational units and storage without harming accuracy significantly.}
}
@article{VANTASSEL2022102150,
title = {Re-imagining crop domestication in the era of high throughput phenomics},
journal = {Current Opinion in Plant Biology},
volume = {65},
pages = {102150},
year = {2022},
issn = {1369-5266},
doi = {https://doi.org/10.1016/j.pbi.2021.102150},
url = {https://www.sciencedirect.com/science/article/pii/S1369526621001515},
author = {David L. {Van Tassel} and Lee R. DeHaan and Luis Diaz-Garcia and Jenna Hershberger and Matthew J. Rubin and Brandon Schlautman and Kathryn Turner and Allison J. Miller},
keywords = {Phenomic selection, Genomic selection, Crop domestication, Phenomics},
abstract = {De novo domestication is an exciting option for increasing species diversity and ecosystem service functionality of agricultural landscapes. Genomic selection (GS), the application of genomic markers to predict phenotypic traits in a breeding population, offers the possibility of rapid genetic improvement, making GS especially attractive for modifying traits of long-lived species. However, for some wild species just entering the domestication pipeline, especially those with large and complex genomes, a lack of funding and/or prior genome characterization, GS is often out of reach. High throughput phenomics has the potential to augment traditional pedigree selection, reduce costs and amplify impacts of genomic selection, and even create new predictive selection approaches independent of sequencing or pedigrees.}
}
@article{JIANG2021268,
title = {High speed long-term visual object tracking algorithm for real robot systems},
journal = {Neurocomputing},
volume = {434},
pages = {268-284},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.12.113},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220320257},
author = {Muxi Jiang and Rui Li and Qisheng Liu and Yingjing Shi and Esteban Tlelo-Cuautle},
keywords = {Long-term UAV tracking, Correlation filter, Drift correction, Target relocate},
abstract = {Although many visual tracking algorithms have made many achievements in video sequences, they have not been confirmed to work well on the real robot systems with the unpredictable changes and limited computing capabilities. In order to face the complex practical conditions, including huge scale variation, occlusion and long-term task, this paper develops a CF-based long-term tracking algorithm. The main strategies are as follows. A novel confidence score is proposed to judge tracking reliability, and the tracking drift is corrected to keep the target’s long-term appearance. Furthermore, once the target is lost, it can be relocated by the multi-scale search. Our tracker performs favorably against other CF-based trackers with strong engineering applicability. Finally, experiments on the datasets and an UAV are carried out to verify the effectiveness for real robot systems.}
}
@article{ZHANG2018156,
title = {An overview on probability undirected graphs and their applications in image processing},
journal = {Neurocomputing},
volume = {321},
pages = {156-168},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.07.078},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218310580},
author = {Jian Zhang and Shifei Ding and Nan Zhang},
keywords = {Restricted Boltzmann machine, Conditional random field, Classification, Deep neural nets},
abstract = {This review aims to report recent developments about deep learning algorithms based on Restricted Boltzmann Machines (RBMs) and Conditional Random Fields (CRFs). Firstly, we give an overview of the general RBMs and CRFs, which are powerful methods for representing dependency of input data, and they can be treated as the basic blocks of deep neural nets as well. Secondly, this review introduces RBM variants and the deep learning models. Apart from the Deep Belief Networks (DBNs) and the Deep Boltzmann Machines (DBMs), the RBMs can be combined with the Convolutional Neural Nets (CNNs), which perform well in image recognition and image reconstruction. Thirdly, this review discusses CRFs and their applications in image annotation and scene recognition. Lastly, this review describes the developments and existing problems in neural nets and lists some experiments.}
}
@article{ALAMU2021102353,
title = {An overview of massive MIMO localization techniques in wireless cellular networks: Recent advances and outlook},
journal = {Ad Hoc Networks},
volume = {111},
pages = {102353},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2020.102353},
url = {https://www.sciencedirect.com/science/article/pii/S1570870520307009},
author = {Olumide Alamu and Babatunde Iyaomolere and Abdulfatai Abdulrahman},
keywords = {Massive MIMO, mmWave, Base station, User equipment, Localization},
abstract = {The massive multiple-input-multiple-output (mMIMO) antenna systems are well known for their capability to achieve high spectral efficiency in wireless communication systems thanks to millimeter waves (mmWaves) which allow a large number of antennas to be deployed at the base stations (BSs). Aside from communication-based services, mMIMO BSs are presently being exploited for location estimation of user equipment due to their high angular resolution, low-cost implementation, and excellent performance in the indoor and clutter urban environments where line-of-sight may not be available. Although various mMIMO localization solutions have been proposed, there are still pressing issues yet to be resolved. To this end, this article first provides an overview of recent and relevant state-of-the-art survey papers on localization. Further to this, we provide various foundational background concepts based on the existing localization techniques applicable to mMIMO localization systems. Furthermore, we discuss various methods under each technique and we also identify some critical factors to be considered in a practical radio environment. Based on these techniques, we provide a comprehensive review of recent works on mMIMO localization. Finally, we suggest key research directions to be addressed in the future and also we discuss key enabling technologies that will enhance the performance of localization systems in 6G communication networks.}
}
@article{ABDULRIDHA2018203,
title = {Evaluating the performance of spectral features and multivariate analysis tools to detect laurel wilt disease and nutritional deficiency in avocado},
journal = {Computers and Electronics in Agriculture},
volume = {155},
pages = {203-211},
year = {2018},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2018.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918310536},
author = {Jaafar Abdulridha and Yiannis Ampatzidis and Reza Ehsani and Ana I. {de Castro}},
keywords = {Vegetation indices, Disease detection, Spectral reflectance analysis, Multi-layer perceptron, Decision tree, Neural networks},
abstract = {Laurel wilt (Lw) disease is an exotic and lethal disease that can kill laurel family trees very fast. It is vectored by the redbay ambrosia beetle that prefers to live and lay eggs inside avocado trees (among other plants). Lw disease continues to expand in Florida posing a major threat to the avocado industry. Early and accurate disease detection is very critical in this case to remove infected trees and distinguish Lw disease from other diseases or disorders with similar symptoms. Herein, we present a nondestructive remote sensing method to detect Lw-infected avocado trees (in early and late stage) and discriminate them from healthy and other factors that cause similar symptoms, such as iron and nitrogen deficiencies, by using a portable spectral data collection system (visible – near infrared; 400–970 nm). Two data sets were collected in 10 nm and 40 nm spectral resolution, and 23 vegetation indices (VIs) were calculated to detect Lw-affected trees by using two classification methods: decision tree (DT) and multilayer perceptron (MLP) neural networks. Additionally, the optimal wavelengths and VIs to discriminate healthy, Lw-infected and avocado trees with iron and nitrogen deficiencies were identified. The results showed that it was possible to detect Lw-infected trees at early stage and distinguish them from other biotic and abiotic factors with high accuracy (around 100%) using the MLP method. Poorer results were achieved with DTs. The optimum 10 nm wide bands and VIs selected for the Lw-detection were found in the red, red-edge and NIR bands.}
}
@article{WONDERS201615,
title = {Training with synthesised data for disaggregated event classification at the water meter},
journal = {Expert Systems with Applications},
volume = {43},
pages = {15-22},
year = {2016},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2015.08.033},
url = {https://www.sciencedirect.com/science/article/pii/S0957417415005898},
author = {M. Wonders and Z. Ghassemlooy and M. {Alamgir Hossain}},
keywords = {Training data synthesis, Machine learning, Load disaggregation, Assisted living},
abstract = {Activity recognition in monitored environments where the occupants are elderly or disabled is currently a popular research topic, with current systems implementing ubiquitous sensing or video surveillance techniques. Using disaggregated data from smart meters could be a viable alternative to what is often perceived as intrusive recognition technology. Disaggregation methods have proven to perform exceptionally well when trained with large quantities of data, but gathering and labelling this data is, in itself, an intrusive process that requires significant effort and could compromise the practicality of such promising systems. Here we show that by synthesising labelled training data, using a domain specific algorithm, an innovative water meter disaggregation system that uses Artificial Neural Networks (ANN), Support Vector Machine (SVM) and K-Nearest Neighbour (KNN) classifiers can be trained in minutes rather than hours. We show that by artificially synthesising labelled data accuracies of 83%, 79% and 85% with the SVM, ANN and KNN classifiers, respectively can be achieved. Though these values are marginally lower than 89%, 83% and 89% achieved with no synthesis, the measure of accuracy masks the underlying imbalance of representative classes in the data set.}
}
@article{ZHANG2019101687,
title = {A CA-NCS algorithm in curve trajectory for smart global village},
journal = {Sustainable Cities and Society},
volume = {51},
pages = {101687},
year = {2019},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2019.101687},
url = {https://www.sciencedirect.com/science/article/pii/S2210670719313538},
author = {Yan Zhang and Tan Qu},
keywords = {Embedded device, Curve trajectory, Motion compensation, Nonlinear chirp, Scaling algorithm, Method of series reversion},
abstract = {The development of embedded system makes it convenient to process SAR data in curve trajectory which caused by maneuvers with acceleration. To eliminate the effect of acceleration on imaging, a constant acceleration nonlinear chirp scaling (CA-NCS) algorithm in curve trajectory based on motion compensation is proposed. Through dividing the acceleration into forward-looking and cross-track acceleration, which could be divided into the acceleration vertical to the imaging plane and the other one in imaging plane further, we use vectorial methods to compensate the phase errors caused by acceleration. Moreover, for range migration we compensate it through NCS approach based on the accurate 2-D spectrum acquired by the method of series reversion (MSR). The system integrated with this algorithm can process SAR data in curve trajectory and reduce computation burden. In addition, the integration of the research in this paper and the machine learning will further identify the motion curve of the aircraft with cross-track acceleration quickly, and real-time SAR imaging can be realized which helps to achieve fast target localization in smart global village.}
}
@article{HASSAN2020124919,
title = {Operational framework for recent advances in backtracking search optimisation algorithm: A systematic review and performance evaluation},
journal = {Applied Mathematics and Computation},
volume = {370},
pages = {124919},
year = {2020},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2019.124919},
url = {https://www.sciencedirect.com/science/article/pii/S0096300319309117},
author = {Bryar A. Hassan and Tarik A. Rashid},
keywords = {Swarm intelligence, Evolutionary optimisation algorithms, Backtracking search optimisation algorithm, Optimisation problems, BSA applications, Performance evaluation},
abstract = {Backtracking search optimisation algorithm (BSA) is a commonly used meta-heuristic optimisation algorithm and was proposed by Civicioglu in 2013. When it was first used, it exhibited its strong potential for solving numerical optimisation problems. Additionally, the experiments conducted in previous studies demonstrated the successful performance of BSA and its non-sensitivity toward the several types of optimisation problems. This success of BSA motivated researchers to work on expanding it, e.g., developing its improved versions or employing it for different applications and problem domains. However, there is a lack of literature review on BSA; therefore, reviewing the aforementioned modifications and applications systematically will aid further development of the algorithm. This paper provides a systematic review and meta-analysis that emphasise on reviewing the related studies and recent developments on BSA. Hence, the objectives of this work are two-fold: (i) First, two frameworks for depicting the main extensions and the uses of BSA are proposed. The first framework is a general framework to depict the main extensions of BSA, whereas the second is an operational framework to present the expansion procedures of BSA to guide the researchers who are working on improving it. (ii) Second, the experiments conducted in this study fairly compare the analytical performance of BSA with four other competitive algorithms: differential evolution (DE), particle swarm optimisation (PSO), artificial bee colony (ABC), and firefly (FF) on 16 different hardness scores of the benchmark functions with different initial control parameters such as problem dimensions and search space. The experimental results indicate that BSA is statistically superior than the aforementioned algorithms in solving different cohorts of numerical optimisation problems such as problems with different levels of hardness score, problem dimensions, and search spaces. This study can act as a systematic and meta-analysis guide for the scholars who are working on improving BSA.}
}
@article{MULLEROVA2021108156,
title = {Characterizing vegetation complexity with unmanned aerial systems (UAS) – A framework and synthesis},
journal = {Ecological Indicators},
volume = {131},
pages = {108156},
year = {2021},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2021.108156},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X21008219},
author = {Jana Müllerová and Xurxo Gago and Martynas Bučas and Jaume Company and Joan Estrany and Josep Fortesa and Salvatore Manfreda and Adrien Michez and Martin Mokroš and Gernot Paulus and Edvinas Tiškus and Maria A. Tsiafouli and Rafi Kent},
keywords = {Biodiversity, Drones, Heterogeneity, Methodology, Phenology, Plant composition, Plant stress, Remote sensing, RPAS, Structural diversity, UAS, UAV},
abstract = {Ecosystem complexity is among the important drivers of biodiversity and ecosystem functioning, and unmanned aerial systems (UASs) are becoming an important tool for characterizing vegetation patterns and processes. The variety of UASs applications is immense, and so are the procedures to process UASs data described in the literature. Optimizing the workflow is still a matter of discussion. Here, we present a comprehensive synthesis aiming to identify common rules that shape workflows applied in UAS-based studies facing complexity in ecosystems. Analysing the studies, we found similarities irrespective of the ecosystem, according to the character of the property addressed, such as species composition (biodiversity), ecosystem structure (stand volume/complexity), plant status (phenology and stress levels), and dynamics (disturbances and regeneration). We propose a general framework allowing to design UAS-based vegetation surveys according to its purpose and the component of ecosystem complexity addressed. We support the framework by detailed schemes as well as examples of best practices of UAS studies covering each of the vegetation properties (i.e. composition, structure, status and dynamics) and related applications. For an efficient UAS survey, the following points are crucial: knowledge of the phenomenon, choice of platform, sensor, resolution (temporal, spatial and spectral), model and classification algorithm according to the phenomenon, as well as careful interpretation of the results. The simpler the procedure, the more robust, repeatable, applicable and cost effective it is. Therefore, the proper design can minimize the efforts while maximizing the quality of the results.}
}
@article{MUALLA2022103573,
title = {The quest of parsimonious XAI: A human-agent architecture for explanation formulation},
journal = {Artificial Intelligence},
volume = {302},
pages = {103573},
year = {2022},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2021.103573},
url = {https://www.sciencedirect.com/science/article/pii/S0004370221001247},
author = {Yazan Mualla and Igor Tchappi and Timotheus Kampik and Amro Najjar and Davide Calvaresi and Abdeljalil Abbas-Turki and Stéphane Galland and Christophe Nicolle},
keywords = {Explainable artificial intelligence, Human-computer interaction, Multi-agent systems, Empirical user studies, Statistical testing},
abstract = {With the widespread use of Artificial Intelligence (AI), understanding the behavior of intelligent agents and robots is crucial to guarantee successful human-agent collaboration since it is not straightforward for humans to understand an agent's state of mind. Recent empirical studies have confirmed that explaining a system's behavior to human users fosters the latter's acceptance of the system. However, providing overwhelming or unnecessary information may also confuse the users and cause failure. For these reasons, parsimony has been outlined as one of the key features allowing successful human-agent interaction with parsimonious explanation defined as the simplest explanation (i.e. least complex) that describes the situation adequately (i.e. descriptive adequacy). While parsimony is receiving growing attention in the literature, most of the works are carried out on the conceptual front. This paper proposes a mechanism for parsimonious eXplainable AI (XAI). In particular, it introduces the process of explanation formulation and proposes HAExA, a human-agent explainability architecture allowing to make it operational for remote robots. To provide parsimonious explanations, HAExA relies on both contrastive explanations and explanation filtering. To evaluate the proposed architecture, several research hypotheses are investigated in an empirical user study that relies on well-established XAI metrics to estimate how trustworthy and satisfactory the explanations provided by HAExA are. The results are analyzed using parametric and non-parametric statistical testing.}
}
@article{MAININI2017296,
title = {Data to decisions: Real-time structural assessment from sparse measurements affected by uncertainty},
journal = {Computers & Structures},
volume = {182},
pages = {296-312},
year = {2017},
issn = {0045-7949},
doi = {https://doi.org/10.1016/j.compstruc.2016.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0045794916308197},
author = {Laura Mainini and Karen E. Willcox},
keywords = {Data-driven reduced-order modeling, Data-driven structural assessment, Data-to-decisions, Sparse and uncertain measurements, Real-time capability assessment, Self-aware vehicle},
abstract = {This paper proposes a data-to-decisions framework—a methodology and a computational strategy—to assist real-time decisions associated with structural monitoring and informed by incomplete, noisy measurements. The data-to-decision structural assessment problem is described in terms of sensor data measurements (such as strain components) and system capabilities (such as failure indices). A MultiStep Reduced-Order Modeling (MultiStep-ROM) strategy tackles the time-critical problem of estimating capabilities from measured data. The methodology relies on an offline-online decomposition of tasks, and combines reduced-order modeling, surrogate modeling, and clustering techniques. The performance of the approach is studied for the case of uncertain measurements arising from spatially distributed sensors over a wing panel. Both sensor noise and sensor spatial sparsity affect the quality of the information available online. The discussion is supported by three investigations that explore the efficiency of the online procedure for multiple combinations of quantity and quality of sensed data. The method is demonstrated for an unmanned aerial vehicle composite wing panel undergoing local degradation of its structural properties.}
}
@article{LEE2019109,
title = {Design and development of a DDDAMS-based border surveillance system via UVs and hybrid simulations},
journal = {Expert Systems with Applications},
volume = {128},
pages = {109-123},
year = {2019},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.03.034},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419301964},
author = {Seunghan Lee and Saurabh Jain and Yifei Yuan and Yinwei Zhang and Haomiao Yang and Jian Liu and Young-Jun Son},
keywords = {Surveillance, Physics-based simulation, Unmanned vehicles, Real-time detection, Human-behavior analysis, Autonomous control},
abstract = {Despite the increasing use of sensor technologies in border surveillance applications, there is a lack of systematic methodology and its implementation with the effective control system. The challenge arises due to information heterogeneity and uncertainty caused by the usage of different sensors. This paper extends the authors’ previous dynamic-data-driven adaptive multi-level simulation (DDDAMS) framework to overcome this challenge using unmanned vehicles (UVs), sensors, and multi-level simulation. Specifically, the detection and classification algorithms are employed to process real-time data generated by fixed (e.g. geophone) and mobile (e.g. UV camera) sensors for the adequate monitoring. Also, physics-based simulation (PBS) is utilized to provide uncertainties for robust planning and control of UVs. The environmental effects as well as target's proactive behavior against the surveillance system are incorporated into the framework using utility-based decision-making model. Finally, we provide a detailed description regarding field demonstration, where autonomous control of UVs and real-time communications among all system components are attained through PBS.}
}
@article{EQUERE2021102825,
title = {Integration of topological aspect of city terrains to predict the spatial distribution of urban heat island using GIS and ANN},
journal = {Sustainable Cities and Society},
volume = {69},
pages = {102825},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.102825},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721001153},
author = {Victor Equere and Parham A. Mirzaei and Saffa Riffat and Yilin Wang},
keywords = {Urban heat island, GIS, Artificial neural networks, Terrain topography, Land surface temperature},
abstract = {Urban heat island (UHI) has multiple negative impacts on cities from heat related morbidities to excessive energy demands by buildings. Hence, better understanding of the contributing factors on its formation ensues ene efficient mitigation of these adverse effects. Previous studies demonstrate a significant correlation between the vertical elevation of urban morphology and UHI, however, topological parameters are barely considered. This study aims to improve the surface UHI prediction by integrating the impact of land surface elevation using a novel parameter of terrain factor (TF), which is integrated with other morphological parameters to develop an artificial neural network (ANN) model to predict the spatial distribution of UHI indicated by land surface temperature (LST). Morphological parameters were derived from two case studies representing areas with high terrain variation and relative flat terrain in Illinois, USA. The developed model was utilized to predict the LST for parts of the city, not initially included in the training process. Integration of TF significantly improves the LST predictions for high terrain variation areas, as the average root mean square error decreased from 1.26 to 0.90⁰C and R2 increased from 0.74 to 0.81. In conclusion, TF has significant impact on the surface UHI in areas with a significant surface relief variation.}
}
@article{M2020106527,
title = {Prediction of the price of Ethereum blockchain cryptocurrency in an industrial finance system},
journal = {Computers & Electrical Engineering},
volume = {81},
pages = {106527},
year = {2020},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.106527},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618331343},
author = {Poongodi M. and Ashutosh Sharma and Vijayakumar V. and Vaibhav Bhardwaj and Abhinav Parkash Sharma and Razi Iqbal and Rajiv Kumar},
keywords = {Linear regression, SVM, Cryptocurrency, Ether, Industrial finance system},
abstract = {Cryptocurrency has gained considerable popularity in the past decade. The untraceable and uncontrolled nature of cryptocurrency attracts millions of people around the world. Research in cryptocurrency is dedicated to finding the ether and predicting its price according to the cryptocurrency's past price inflations. In this study, price prediction is performed with two machine learning methods, namely linear regression (LR) and support vector machine (SVM), by using a time series consisting of daily ether cryptocurrency closing prices. Different window lengths are used in ether cryptocurrency price prediction by using filters with different weight coefficients. In the training phase, a cross-validation method is used to construct a high-performance model independent of the data set. The proposed model is implemented using two machine learning techniques. When using the proposed model, the SVM method has a higher accuracy (96.06%) than the LR method (85.46%). Furthermore, the accuracy score of the proposed model can be increased up to 99% by adding features to the SVM method.}
}
@article{SINHA2022169,
title = {Recent advancements and challenges of Internet of Things in smart agriculture: A survey},
journal = {Future Generation Computer Systems},
volume = {126},
pages = {169-184},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21003113},
author = {Bam Bahadur Sinha and R. Dhanalakshmi},
keywords = {IoT, Automated irrigation, Data analytics, IoT challenges, IoT smart farming},
abstract = {The Internet of Things (IoT) is an evolving paradigm that seeks to connect different smart physical components for multi-domain modernization. To automatically manage and track agricultural lands with minimal human intervention, numerous IoT-based frameworks have been introduced. This paper presents a rigorous discussion on the major components, new technologies, security issues, challenges and future trends involved in the agriculture domain. An in-depth report on recent advancements has been covered in this paper. The goal of this survey is to help potential researchers detect relevant IoT problems and, based on the application requirements, adopt suitable technologies. Furthermore, the significance of IoT and Data Analytics for smart agriculture has been highlighted.}
}
@article{WANG2021641,
title = {Research on parallelization of Apriori algorithm in association rule mining},
journal = {Procedia Computer Science},
volume = {183},
pages = {641-647},
year = {2021},
note = {Proceedings of the 10th International Conference of Information and Communication Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.02.109},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921005858},
author = {Huan-Bin Wang and Yang-Jun Gao},
keywords = {Association rules, Apriori algorithm, MapReduce, Parallelization},
abstract = {Aiming at the performance bottleneck of traditional Apriori algorithm when the data set is slightly large, this paper adopts the idea of parallelization and improves the Apriori algorithm based on MapReduce model. Firstly, the local frequent itemsets on each sub node in the cluster are calculated, then all the local frequent itemsets are merged into the global candidate itemsets, and finally, the frequent itemsets that meet the conditions are filtered according to the minimum support threshold. The advantage of the improved algorithm is that it only needs to scan the transaction database twice and calculate the frequent item set in parallel, which improves the efficiency of the algorithm.}
}
@article{SAMY2011658,
title = {Survey and application of sensor fault detection and isolation schemes},
journal = {Control Engineering Practice},
volume = {19},
number = {7},
pages = {658-674},
year = {2011},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2011.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S0967066111000414},
author = {Ihab Samy and Ian Postlethwaite and Da-Wei Gu},
keywords = {Multiple sensor fault detection, Fault isolation, Fault accommodation, Neural networks, UAV},
abstract = {Model-based sensor fault detection, isolation and accommodation (SFDIA) is a direction of development in particular with UAVs where sensor redundancy may not be an option due to weight, cost and space implications. SFDIA via neural networks (NNs) have been proposed over the years due to their nonlinear structures and online learning capabilities. The majority of papers tend to consider single sensor faults. While useful, this assumption can limit application to real systems where sensor faults can occur simultaneously or consecutively. In this paper we consider the latter scenario, where it is assumed that a 1s time gap is present between consecutive faults. Furthermore few applications have considered fixed-wing UAVs where full autonomy is most needed. In this paper an EMRAN RBF NN is chosen for modelling purposes due to its ability to adapt well to nonlinear environments while maintaining high computational speeds. A nonlinear UAV model is used for demonstration, where decoupled longitudinal motion is considered. System and measurement noise is also included in the UAV model as wind gust disturbances on the angle of attack and sensor noise, respectively. The UAV is assumed to operate at an initial trimmed condition of speed, 32m/s and altitude, 1000m. After 30 separate SFDIA tests implemented on a 1.6GHz Pentium processor, the NN-SFDIA scheme detected all but 2 faults and the NN processing time was 97% lower than the flight data sampling time.}
}
@article{JIA2021109235,
title = {A novel fault diagnosis method for aircraft actuator based on ensemble model},
journal = {Measurement},
volume = {176},
pages = {109235},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.109235},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121002475},
author = {Zhen Jia and Zhenbao Liu and Yongyi Cai},
keywords = {Actuator, Fault diagnosis, Imbalanced data, Ensemble model, Auto-encoder, Extreme learning machine},
abstract = {The actuator of aircraft is the direct executor of flight control signal. When it fails, the aircraft will lose control and even crash. However, due to the low frequency of fault occurrence and the lack of real fault data, the amount of health data and fault data is seriously imbalanced. The research on fault diagnosis of aircraft actuator under imbalanced data has practical engineering significance. Inspired by the ensemble model for solving the problem of imbalanced data classification, this paper proposes an innovative ensemble model called ensemble deep auto-encoder based extreme learning machine (DELM-AE). DELM-AE is a deep network constructed by multi-layer extreme learning machine based auto-encoder, which has the advantages of strong feature mining ability, high accuracy and fast speed. Firstly, the fault simulation model of flight control actuator is established, and then residual analysis and feature extraction are carried out on the data. Finally, compared with other common shallow model (extreme learning machine, support vector machine, back propagation neural network), ensemble model (random forest) and deep networks, the advantages of the proposed method in accuracy, processing speed, robustness and ability to deal with imbalanced data are proved.}
}
@article{CAI2011803,
title = {Design and implementation of a robust and nonlinear flight control system for an unmanned helicopter},
journal = {Mechatronics},
volume = {21},
number = {5},
pages = {803-820},
year = {2011},
note = {Special Issue on Development of Autonomous Unmanned Aerial Vehicles},
issn = {0957-4158},
doi = {https://doi.org/10.1016/j.mechatronics.2011.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0957415811000262},
author = {Guowei Cai and Ben M. Chen and Xiangxu Dong and Tong H. Lee},
keywords = {Unmanned aerial vehicles, Unmanned systems, Nonlinear flight dynamics, Flight control, Robust control},
abstract = {In this work, we focus on the design and implementation of a robust flight control system for an unmanned helicopter. A comprehensive nonlinear model for an unmanned helicopter system, which is built by our research team at the National University of Singapore, is first presented. A three-layer control architecture is then adopted to construct an automatic flight control system for the aircraft, which includes (1) an inner-loop controller designed using the H∞ control technique to internally stabilize the aircraft and at the same time yield good robustness properties with respect to external disturbances, (2) a nonlinear outer-loop controller to effectively control the helicopter position and yaw angle in the overall flight envelope, and lastly, (3) a flight-scheduling layer for coordinating flight missions. Design specifications for military rotorcraft set for the US army aviation are utilized throughout the whole process to guarantee a top level performance. The result of actual flight tests shows our design is very successful. The unmanned helicopter system is capable of achieving the desired performance in accordance with the military standard under examination.}
}
@article{WANG20188,
title = {Fractional order sliding mode control via disturbance observer for a class of fractional order systems with mismatched disturbance,},
journal = {Mechatronics},
volume = {53},
pages = {8-19},
year = {2018},
issn = {0957-4158},
doi = {https://doi.org/10.1016/j.mechatronics.2018.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0957415818300758},
author = {Jing Wang and Changfeng Shao and Yang-Quan Chen},
keywords = {Fractional order calculus, Fractional order sliding mode control, Fractional order disturbance observer, Mismatched uncertain},
abstract = {This article proposes a novel fractional order sliding mode control for a class of fractional order and integer order systems with mismatched disturbances. First, a new fractional order disturbance observer is designed to estimate the fractional order differential of the mismatched disturbance directly. Second, the fractional order sliding surface and controller are proposed based on the designed disturbance observer. Our method can deal with mismatched disturbance and has better control performance with faster response speed, lower overshoot, and less chattering effect. The simulations on Quad–Rotor UAV and Maglev suspension systems demonstrate the effectiveness of the proposed method.}
}
@article{TEIZER2015225,
title = {Status quo and open challenges in vision-based sensing and tracking of temporary resources on infrastructure construction sites},
journal = {Advanced Engineering Informatics},
volume = {29},
number = {2},
pages = {225-238},
year = {2015},
note = {Infrastructure Computer Vision},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2015.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S1474034615000336},
author = {Jochen Teizer},
keywords = {Building information modeling, Computer vision and machine learning, Resource location tracking and progress monitoring, Safety and health, Sensors: photo and video cameras, unmanned aerial vehicles, Surveying: laser scanning, photo- and videogrammetry},
abstract = {Modern construction projects require sufficient planning and management of resources to become successful. Core issues are tasks that deal with maintaining the schedule, such as procuring materials, guaranteeing the supply chain, controlling the work status, and monitoring safety and quality. Timely feedback of project status aids project management by providing accurate percentages of task completions and appropriately allocating resources (workforce, equipment, material) to coordinate the next work packages. However, current methods for measuring project status or progress, especially on large infrastructure projects, are mostly based on manual assessments. Recent academic research and commercial development has focused on semi- or fully-automated approaches to collect and process images of evolving worksites. Preliminary results are promising and show capturing, analyzing, and documenting construction progress and linking to information models is possible. This article presents first an overview to vision-based sensing technology available for temporary resource tracking at infrastructure construction sites. Second, it provides the status quo of research applications by highlighting exemplary case. Third, a discussion follows on existing advantages and current limitations of vision based sensing and tracking. Open challenges that need to be addressed in future research efforts conclude this paper.}
}
@article{JHA2021107592,
title = {Layer based security in Narrow Band Internet of Things (NB-IoT)},
journal = {Computer Networks},
volume = {185},
pages = {107592},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107592},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620312299},
author = {Rakesh Kumar Jha and  Puja and Haneet Kour and Manoj Kumar and Shubha Jain},
keywords = {IoT, Bug, Security, MEMS, Secrecy rate (SR), Secrecy outage probability (SOP)},
abstract = {In the recent years, the growth of technology and the resulting transformation is happening at a rapid pace. In this junction, IoT has provided a great platform and bridge between these technologies. A lot of research regarding the application of IoT Systems has been done in the recent years but one area that lacks research is security issues in Narrow Band Internet of Things (NB-IoT).It is noticed that security and Privacy in NB-IoT system is a challenging task for researchers and academia. Application of NB-IoT in Defense security opened a new way for the researchers but at the same time security threat can lead to drastic loss. Nowadays, MEMS-NB-IoT device (Bug)/ BOT are being used for carrying out any malicious security attack. This can be a serious area of concern in the case of defense security. These MEMS device are very dangerous and it can spoof data from any type of network. The size of this device is very small, it can travel to any location for monitoring the enemy movement, and it is very difficult to identify these types of bugs. These BOT device very sensitive at Perception and Network Layered. In this paper, we have provided detail analysis of IoT/NB-IoT Layered architecture. A novel proposal depicting security attack in a Smart home system with IoT and NB-IoT enabled devices is presented. The Secrecy Rate (SR), the Secrecy Outage Probability (SOP) is being calculated, and performance analysis of IoT system in the presence of Bugs for a smart home system is carried out. Simulations have been performed and the performance analysis done is based on Security non-outage probability vs security rate with real time analysis.}
}
@article{YANG2021124,
title = {Real-time Semantic Segmentation with Context Aggregation Network},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {178},
pages = {124-134},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621001647},
author = {Michael Ying Yang and Saumya Kumaar and Ye Lyu and Francesco Nex},
keywords = {Semantic segmentation, Real-time, Convolutional neural network, Context aggregation network},
abstract = {With the increasing demand of autonomous systems, pixelwise semantic segmentation for visual scene understanding needs to be not only accurate but also efficient for potential real-time applications. In this paper, we propose Context Aggregation Network, a dual branch convolutional neural network, with significantly lower computational costs as compared to the state-of-the-art, while maintaining a competitive prediction accuracy. Building upon the existing dual branch architectures for high-speed semantic segmentation, we design a high resolution branch for effective spatial detailing and a context branch with light-weight versions of global aggregation and local distribution blocks, potent to capture both long-range and local contextual dependencies required for accurate semantic segmentation, with low computational overheads. We evaluate our method on two semantic segmentation datasets, namely Cityscapes dataset and UAVid dataset. For Cityscapes test set, our model achieves state-of-the-art results with mIOU of 75.9%, at 76 FPS on an NVIDIA RTX 2080Ti and 8 FPS on a Jetson Xavier NX. With regards to UAVid dataset, our proposed network achieves mIOU score of 63.5% with high execution speed (15 FPS).}
}
@article{CAO2021113833,
title = {Detecting the shuttlecock for a badminton robot: A YOLO based approach},
journal = {Expert Systems with Applications},
volume = {164},
pages = {113833},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113833},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420306436},
author = {Zhiguang Cao and Tingbo Liao and Wen Song and Zhenghua Chen and Chongshou Li},
keywords = {Deep learning, Object detection, YOLO, Badminton robot},
abstract = {The ability to identify objects of interest from digital visual signals is critical for many applications of intelligent systems. For such object detection task, accuracy and computational efficiency are two important aspects, especially for applications with real-time requirement. In this paper, we study shuttlecock detection problem of a badminton robot, which is very challenging since the shuttlecock often moves fast in complex contexts, and must be detected precisely in real time so that the robot can plan and execute its following movements. To this end, we propose two novel variants of Tiny YOLOv2, a well-known deep learning based detector. We first modify the loss function to adaptively improve the detection speed for small objects such as shuttlecock. We then modify the architecture of Tiny YOLOv2 to retain more semantic information of small objects, so as to further improve the performance. Experimental results show that the proposed networks can achieve high detection accuracy with the fastest speed, compared with state-of-the-art deep detectors such as Faster R-CNN, SSD, Tiny YOLOv2, and YOLOv3. Our methods could be potentially applied to other tasks of detecting high-speed small objects.}
}
@article{KAHRAMAN2020103643,
title = {Fuzzy controlled humanoid robots: A literature review},
journal = {Robotics and Autonomous Systems},
volume = {134},
pages = {103643},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103643},
url = {https://www.sciencedirect.com/science/article/pii/S0921889020304838},
author = {Cengiz Kahraman and Muhammet Deveci and Eda Boltürk and Seda Türk},
keywords = {Humanoid robots, Robots, Fuzzy control, Fuzzy sets, Classification},
abstract = {Humanoid robots generated by inspiring by human appearances and abilities have became essential in human society to improve the quality of their life. All over the world, there have been many researchers who have focused on humanoid robots to develop the capabilities of humanoid robots. Generally, humanoid robot systems include mechanisms of decision making and information processing. Because of the uncertainty behind decision making and information processes, fuzzy sets are used most commonly. This study investigates a comprehensive literature review about humanoid robots that presents the recent technological developments and the theories associated with fuzzy set models. The basic principles and concepts of fuzzy sets for humanoid robots are presented.}
}
@article{SINGH202156,
title = {Fog computing: A taxonomy, systematic review, current trends and research challenges},
journal = {Journal of Parallel and Distributed Computing},
volume = {157},
pages = {56-85},
year = {2021},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2021.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S0743731521001349},
author = {Jagdeep Singh and Parminder Singh and Sukhpal Singh Gill},
keywords = {Fog computing, Frameworks, Edge computing, Applications, Internet of things (IoT)},
abstract = {There has been rapid development in the number of Internet of Things (IoT) connected nodes and devices in our daily life in recent times. With this increase in the number of devices, fog computing has become a well-established paradigm to optimize various key Quality of Service (QoS) requirements such as latency, bandwidth limitation, response time, scalability, privacy and security. In this paper, we present a systematic literature review of fog computing. This review article aims to classify recently published studies and investigate the current status in the area of fog computing. In this work, we have discussed the important characteristics of fog computing frameworks and identified various issues related to its architectural design, QoS metrics, implementation details, applications and communication modes. We have proposed taxonomy for fog computing frameworks based on the existing literature and compared the different research work based on taxonomy. Finally, various open research challenges and promising future directions are highlighted for further research in the area of fog computing.}
}
@article{SHAW2013265,
title = {Event-related cerebral hemodynamics reveal target-specific resource allocation for both “go” and “no-go” response-based vigilance tasks},
journal = {Brain and Cognition},
volume = {82},
number = {3},
pages = {265-273},
year = {2013},
issn = {0278-2626},
doi = {https://doi.org/10.1016/j.bandc.2013.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0278262613000651},
author = {Tyler H. Shaw and Matthew E. Funke and Michael Dillard and Gregory J. Funke and Joel S. Warm and Raja Parasuraman},
keywords = {Vigilance, Sustained attention, Event-related, Cerebral blood flow velocity, Attentional resource theory},
abstract = {Transcranial Doppler sonography was used to measure cerebral blood flow velocity (CBFV) in the right and left cerebral hemispheres during the performance of a 50-min visual vigilance session. Observers monitored a simulated flight of unmanned aerial vehicles for cases in which one of the vehicles was flying in an inappropriate direction relative to its cohorts. Two types of vigilance tasks were employed: a traditional task in which observers made button press (“go”) responses to critical signals, and a modification of the traditional task called the Sustained Attention to Response Task (SART) in which “go” responses acknowledged nonsignal events and response withholding (“no-go”) signified signal detection. Signal detections and global CBFV scores declined over time. In addition, fine-grained event-related analyses revealed that the detection of signals was accompanied by an elevation of CBFV that was not present with missed signals. As was the case with the global scores, the magnitude of the transient CBFV increments associated with signal detection also declined over time, and these findings were independent of task type. The results support the view of CBFV as an index of the cognitive evaluation of stimulus significance, and a resource model of vigilance in which the need for continuous attention produces a depletion of information-processing assets that are not replenished as the task progresses. Further, temporal declines in the magnitude of event-related CBFV in response to critical signals only is evidence that the decrement function in vigilance is due to attentional processing and not specific task elements such as the required response format.}
}
@article{BONNINPASCUAL2019106420,
title = {On the use of robots and vision technologies for the inspection of vessels: A survey on recent advances},
journal = {Ocean Engineering},
volume = {190},
pages = {106420},
year = {2019},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2019.106420},
url = {https://www.sciencedirect.com/science/article/pii/S0029801819305682},
author = {Francisco Bonnin-Pascual and Alberto Ortiz},
keywords = {Vessel inspection, Current approaches, Survey, Robotic platforms, Defect detectors},
abstract = {Vessels are widely used for transporting goods around the world. All cargo vessels are affected by two main defective situations, namely cracks and corrosion. To prevent major damage/accidents, intensive inspection schemes must be carried out periodically, identifying the affected plates for a subsequent repair/replacement. These inspections are performed at a great cost due to the arrangements that allow human inspectors to reach any point of the vessel structure while guaranteeing their physical integrity and respecting all the stipulated safety measures. Technological advances can provide alternatives to facilitate the vessel inspection and reduce the associated cost. This paper surveys approaches which can contribute to the reengineering process of vessel visual inspection focusing on two main aspects: robotic platforms which can be used for the visual inspection of vessels, and computer vision algorithms for the detection of cracks and/or corrosion in images. The different approaches found in the literature are reviewed and classified regarding their key features, what allows identifying the main trends which are being applied so far and those which could mean an improvement in the current visual inspection.}
}
@article{LI2019312,
title = {Robust tracking control strategy for a quadrotor using RPD-SMC and RISE},
journal = {Neurocomputing},
volume = {331},
pages = {312-322},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.11.070},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218314164},
author = {Zhi Li and Xin Ma and Yibin Li},
keywords = {PD-SMC, Quadrotor, RBFNNs, RISE, Tracking control},
abstract = {This paper proposes a robust hierarchical controller using adaptive radical basis function neural networks (RBFNNs) based proportional derivative-sliding mode control (RPD-SMC) method and robust integral of the signum of error (RISE) approach for an under-actuated quadrotor in the presence of disturbances and parametric uncertainties. The quadrotor system is decoupled into two parts: the outer loop for position control and the inner loop for attitude control. The RPD-SMC is designed for the outer loop to ensure robust position tracking. The PRD-SMC combines the advantages of simplicity of PD control, the strong robustness of SMC and the approximation ability of arbitrary functions of RBFNNs. The RISE method is applied in the inner loop to guarantee fast convergence of the attitude angles to their desired values with continuous control signals. The capabilities of online approximating and null steady-state tracking are proved using Lyapunov stability theory. The effectiveness of the proposed control strategy is validated by comparing with the performances achieved by PD, PID, PD-SMC and RBFNNs based controllers via numerical simulations.}
}
@article{ABASI2020106002,
title = {Link-based multi-verse optimizer for text documents clustering},
journal = {Applied Soft Computing},
volume = {87},
pages = {106002},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2019.106002},
url = {https://www.sciencedirect.com/science/article/pii/S1568494619307847},
author = {Ammar Kamal Abasi and Ahamad Tajudin Khader and Mohammed Azmi Al-Betar and Syibrah Naim and Sharif Naser Makhadmeh and Zaid Abdi Alkareem Alyasseri},
keywords = {Multi-verse optimizer, Optimization, Test clustering, Data clustering, Neighborhood selection strategy},
abstract = {Text document clustering (TDC) represents a key task in text mining and unsupervised machine learning, which partitions a specific documents’ collection into varied K-groups according to certain similarity/dissimilarity criterion. There exists a considerable amount of knowledge in the text clustering field and many attempts were carried out to resolve the TDC problem and improve the learning performance. The multi-verse optimizer algorithm (MVO) is a stochastic population-based algorithm, which was recently introduced and successfully utilized to tackle many optimization problems that are complex. The original MVO performance is limited to the utilization of only the best solution in the exploitation phase (local search capability), which makes it suffer from entrapment in local optima and low convergence rate. This paper aims to propose a novel method of modifying the MVO algorithm called link-based Multi-verse optimizer algorithm (LBMVO) to enhance the exploitation phase in the original MVO. The enhancement involves adding a neighbor operator to the MVO algorithm to enhance the search capability via a novel probability factor, namely neighborhood selection strategy (NSS). The proposed LBMVO’s effectiveness was tested on six standard datasets, which are used in the text clustering domain in addition to five standard datasets, which are utilized in the data clustering domain. The experiments revealed that the modified MVO with NSS has boosted the results in terms of error rate, accuracy, recall, precision, F-measure, purity, entropy criteria, and high convergence rate. Generally, LBMVO has outperformed or at least showed that it is profoundly competitive compared with the original MVO algorithm and with widely known clustering techniques like Spectral, Agglomerative, Density-based spatial clustering of applications with noise (DBSCAN), K-means, K-means++ clustering techniques and the optimization algorithms like harmony search (HS), genetic algorithm (GA), particle swarm optimization (PSO), krill herd algorithm (KHA), covariance matrix adaptation evolution strategy (CMAES), coyote optimization algorithm (COA), as well as original MVO.}
}
@article{CASTELLINI2021104382,
title = {Partially Observable Monte Carlo Planning with state variable constraints for mobile robot navigation},
journal = {Engineering Applications of Artificial Intelligence},
volume = {104},
pages = {104382},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104382},
url = {https://www.sciencedirect.com/science/article/pii/S095219762100230X},
author = {Alberto Castellini and Enrico Marchesini and Alessandro Farinelli},
keywords = {Planning under uncertainty, POMDP, POMCP, Mobile robot planning, Industry 4.0, Explainable planning},
abstract = {Autonomous mobile robots employed in industrial applications often operate in complex and uncertain environments. In this paper we propose an approach based on an extension of Partially Observable Monte Carlo Planning (POMCP) for robot velocity regulation in industrial-like environments characterized by uncertain motion difficulties. The velocity selected by POMCP is used by a standard engine controller which deals with path planning. This two-layer approach allows POMCP to exploit prior knowledge on the relationships between task similarities to improve performance in terms of time spent to traverse a path with obstacles. We also propose three measures to support human-understanding of the strategy used by POMCP to improve the performance. The overall architecture is tested on a Turtlebot3 in two environments, a rectangular path and a realistic production line in a research lab. Tests performed on a C++ simulator confirm the capability of the proposed approach to profitably use prior knowledge, achieving a performance improvement from 0.7% to 3.1% depending on the complexity of the path. Experiments on a Unity simulator show that the proposed two-layer approach outperforms also single-layer approaches based only on the engine controller (i.e., without the POMCP layer). In this case the performance improvement is up to 37% comparing to a state-of-the-art deep reinforcement learning engine controller, and up to 51% comparing to the standard ROS engine controller. Finally, experiments in a real-world testing arena confirm the possibility to run the approach on real robots.}
}
@article{NEBYLOV2010112,
title = {Smart Control Systems for Next-Generation Autonomous Wing-In-Ground Effect Vehicles},
journal = {IFAC Proceedings Volumes},
volume = {43},
number = {15},
pages = {112-117},
year = {2010},
note = {18th IFAC Symposium on Automatic Control in Aerospace},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20100906-5-JP-2022.00020},
url = {https://www.sciencedirect.com/science/article/pii/S1474667015318255},
author = {Alexander Nebylov and Sukrit Sharan and Farid Arifuddin},
keywords = {Autonomous & Intelligent Vehicles, Automatic Control, Integrated Navigation systems and Data Fusion},
abstract = {Abstract
In the paper a scientific and technological analysis has been presented for the viability, advantages and highly successful prospects for the realization of an Autonomous and Intelligent Wing-In-Ground Effect Vehicle mainly for Coastal Patrolling and Search & Rescue Operations. The necessary Autopilots and Automatic Control Systems have been proposed and described especially considering such vehicles for their various modes of motion. Also has been described the special Phase-Radioaltimeter created in IIAAT for such purposes and missions. Some alternate sources of power and energy for such systems for round the clock sea surveillance have also been suggested for such highly promising and highly advanced next generation intellectual amphibious vehicles.}
}
@article{FOROUTAN2017156,
title = {Semi-automatic mapping of linear-trending bedforms using ‘Self-Organizing Maps’ algorithm},
journal = {Geomorphology},
volume = {293},
pages = {156-166},
year = {2017},
issn = {0169-555X},
doi = {https://doi.org/10.1016/j.geomorph.2017.05.016},
url = {https://www.sciencedirect.com/science/article/pii/S0169555X16306535},
author = {M. Foroutan and J.R. Zimbelman},
keywords = {Semi-automatic mapping, Linear-trending bedforms, Self-organizing maps, Image processing, Transverse Aeolian Ridges},
abstract = {Increased application of high resolution spatial data such as high resolution satellite or Unmanned Aerial Vehicle (UAV) images from Earth, as well as High Resolution Imaging Science Experiment (HiRISE) images from Mars, makes it necessary to increase automation techniques capable of extracting detailed geomorphologic elements from such large data sets. Model validation by repeated images in environmental management studies such as climate-related changes as well as increasing access to high-resolution satellite images underline the demand for detailed automatic image-processing techniques in remote sensing. This study presents a methodology based on an unsupervised Artificial Neural Network (ANN) algorithm, known as Self Organizing Maps (SOM), to achieve the semi-automatic extraction of linear features with small footprints on satellite images. SOM is based on competitive learning and is efficient for handling huge data sets. We applied the SOM algorithm to high resolution satellite images of Earth and Mars (Quickbird, Worldview and HiRISE) in order to facilitate and speed up image analysis along with the improvement of the accuracy of results. About 98% overall accuracy and 0.001 quantization error in the recognition of small linear-trending bedforms demonstrate a promising framework.}
}
@article{ARAUS2018237,
title = {Breeding to adapt agriculture to climate change: affordable phenotyping solutions},
journal = {Current Opinion in Plant Biology},
volume = {45},
pages = {237-247},
year = {2018},
note = {AGRI 2017},
issn = {1369-5266},
doi = {https://doi.org/10.1016/j.pbi.2018.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S1369526618300098},
author = {José L Araus and Shawn C Kefauver},
abstract = {Breeding is one of the central pillars of adaptation of crops to climate change. However, phenotyping is a key bottleneck that is limiting breeding efficiency. The awareness of phenotyping as a breeding limitation is not only sustained by the lack of adequate approaches, but also by the perception that phenotyping is an expensive activity. Phenotyping is not just dependent on the choice of appropriate traits and tools (e.g. sensors) but relies on how these tools are deployed on their carrying platforms, the speed and volume of data extraction and analysis (throughput), the handling of spatial variability and characterization of environmental conditions, and finally how all the information is integrated and processed. Affordable high throughput phenotyping aims to achieve reasonably priced solutions for all the components comprising the phenotyping pipeline. This mini-review will cover current and imminent solutions for all these components, from the increasing use of conventional digital RGB cameras, within the category of sensors, to open-access cloud-structured data processing and the use of smartphones. Emphasis will be placed on field phenotyping, which is really the main application for day-to-day phenotyping.}
}
@article{PANERU2021103940,
title = {Computer vision applications in construction: Current state, opportunities & challenges},
journal = {Automation in Construction},
volume = {132},
pages = {103940},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103940},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521003915},
author = {Suman Paneru and Idris Jeelani},
keywords = {Computer vision, Technology in construction, Visual data analytics, Monitoring},
abstract = {Thousands of images and videos are collected from construction projects during construction. These contain valuable data that, if harnessed efficiently, can help automate or at least reduce human effort in diverse construction management activities such as progress monitoring, safety management, quality control and productivity tracking. Extracting meaningful information from images requires the development of technology and algorithms that enable computers to understand digital images or videos, replicating the functionality of human visual systems. This is the goal of computer vision. This review aims at providing an updated and categorized overview of computer vision applications in construction by examining the recent developments in the field and identifying the opportunities and challenges that future research needs to address to fully leverage the potential benefits of Computer Vision. We restrict the focus to four areas that can benefit the most from computer vision - Safety Management, Progress Monitoring, Productivity Tracking and Quality Control.}
}
@article{PINNOW2021106185,
title = {A review of naturalistic driving study surrogates and surrogate indicator viability within the context of different road geometries},
journal = {Accident Analysis & Prevention},
volume = {157},
pages = {106185},
year = {2021},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2021.106185},
url = {https://www.sciencedirect.com/science/article/pii/S0001457521002165},
author = {Jack Pinnow and Mahmoud Masoud and Mohammed Elhenawy and Sebastien Glaser},
keywords = {NDS, Surrogate indicator, Road geometry, SCE},
abstract = {Advancements in data collection and processing methods have produced large databases containing high quality vehicular data. Despite this, conventional vehicle-vehicle collisions remain difficult to identify due to their rarity. Therefore, there is a need to identify potential collisions given the introduction of these new data collection methods. Surrogate indicators are a popular methods utilised to identify such events, however, the type of surrogate that can be used depends heavily on the type of data collection method. Though most surrogate indicators are used at different road geometries, there is evidence to suggest that some surrogate indicators may perform better than others at a given geometry. This review provides two key contributions to the body of literature. Firstly, a review of kinematic surrogates is put forward, along with a discussion on the whether these surrogates can be contextualised at different road geometries. Secondly, an extensive analysis and discussion of observer-based and video processed surrogate indicators, the collision types they aim to identify and the geometries they have been used at previously were analysed and advantages and disadvantages of the surrogates have been presented for future use. To do this, intersections, highways and roundabouts were selected and divided into geometry subtypes (i.e. three-legged and four-legged intersection) and segments (i.e. approaches to intersections and internal to the intersection) based on the likelihood of crash types and pre-crash manoeuvres occurring in that segment. Due to the lack of research around the use of kinematic triggers at road geometries, it is difficult to advocate for the use of any given trigger over another at a given geometry. Furthermore, it was found that kinematic triggers cannot accurately identify conflicts from naturalistic driving data and require the use of advanced statistical techniques such as machine learning to increase accuracy. A brief analysis of threshold identification techniques was also performed. Several future works have been put forward including the introduction of surrogates which capture conflict severity and the role of surrogate indicators in connected and automated vehicle environments.}
}
@article{DU2021104476,
title = {The object-oriented dynamic task assignment for unmanned surface vessels},
journal = {Engineering Applications of Artificial Intelligence},
volume = {106},
pages = {104476},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104476},
url = {https://www.sciencedirect.com/science/article/pii/S0952197621003249},
author = {Bin Du and Yu Lu and Xiaotong Cheng and Weidong Zhang and Xuesong Zou},
keywords = {Unmanned surface vessels, IPNG guidance, Task allocation, Consensus based auction algorithm, Interception game},
abstract = {This paper investigates the task assignment and guidance issues of unmanned surface vessels (USVs) interception. When the USVs formation is invaded by some moving objects during its escort, it is necessary for the unmanned systems to assign defenders to prevent attackers approaching the vulnerable target in antagonistic scenarios. This action requires efficient guidance and task assignment strategies. With this in mind, this paper presents the Integral Proportional Navigation Guidance (IPNG) with Tabu Dynamic Consensus-Based Auction Algorithm (TDCBAA) in marine interception scenario. First, IPNG is introduced in the interception game considering the USV kinematic model, which can effectively reduce the individual interception time. Second, a new bidding function is designed for moving objects interception with the consideration of the attackers’ types, positions and interception time. Finally, a TDCBAA is designed to solve the task assignment subproblem, resulting in a shorter overall interception time and a higher interception success rate. Simulations demonstrate that the proposed algorithm can optimize the allocation of defenders in real-time and intercept the attackers more quickly compared with other classical algorithms, which is more suitable in situations where attackers are approaching from all directions.}
}
@article{KUCHARCZYK2021112577,
title = {Remote sensing of natural hazard-related disasters with small drones: Global trends, biases, and research opportunities},
journal = {Remote Sensing of Environment},
volume = {264},
pages = {112577},
year = {2021},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112577},
url = {https://www.sciencedirect.com/science/article/pii/S0034425721002972},
author = {Maja Kucharczyk and Chris H. Hugenholtz},
keywords = {Drone, UAV, UAS, RPAS, Disaster, Hazard, Emergency, Risk, PRISMA},
abstract = {Small (< 25 kg) aerial drones have expanded the remote sensing toolkit for disaster management activities. Here, we provide a critical review of drone-based remote sensing of natural hazard-related disasters to highlight research trends, biases, and expose new opportunities. We performed a systematic literature search using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses methodology, resulting in 635 relevant articles from which we derived statistics relating to geography, drone hardware, disaster management application, and drone remote sensing data type and analysis method. Key findings include a bias towards: (i) mass movement hazards (38%); (ii) small (< 1 km2) (76%) and rural (79%) study areas in high-income countries and territories (64%); (iii) image-based observations of features from the natural environment (77%); and (iv) support of mitigation-related vulnerability assessment and risk modeling (54%) and environmental recovery (23%). We recommend that future studies focus on: (i) earthquakes, floods, and cyclones and other windstorms due to higher loss of life and economic impacts; (ii) larger and urban study areas in low, lower-middle, and upper-middle income countries and territories to support vulnerable populations; (iii) under-demonstrated (and especially response-related) disaster management activities, which generally require observations of built features from urban environments; and (iv) data standards for integrating drone-based remote sensing with international disaster management methodologies.}
}
@article{HE2021110967,
title = {A non-intrusive approach for fault detection and diagnosis of water distribution systems based on image sensors, audio sensors and an inspection robot},
journal = {Energy and Buildings},
volume = {243},
pages = {110967},
year = {2021},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2021.110967},
url = {https://www.sciencedirect.com/science/article/pii/S0378778821002516},
author = {Ruikai He and Peng Xu and Zhibo Chen and Wei Luo and Zhineng Su and Jiong Mao},
keywords = {Fault diagnosis, Audio signal processing, Image processing, Inspection robot},
abstract = {Fault diagnosis is important to maintain the normal operation of air-conditioning systems, reduce the energy consumption in buildings, and increase the service life of air-conditioning system equipment. We present a novel approach for fault detection and diagnosis system that relies on image and audio sensors and relevant algorithms. This paper proposes a fault diagnosis algorithm based on a robot that can automatically capture audio and image signals from microphone arrays and cameras during inspection in a chiller room. It includes audio- and image-based fault diagnosis algorithms. The validity of the algorithm combined with sensors is verified using data from actual equipment in a chiller room. The audio-based algorithm, which can monitor the abnormal sound of pumps to detect faults, utilizes Fourier transform, a finite impulse response digital filter, and an autoregressive integrated moving average model. We analyze the frequency domain of the pump signal and set the appropriate threshold to monitor abnormal signals based on the fitted model. Meanwhile, the image-based algorithms are divided into three sections to achieve three functions: 1) an AlexNet convolutional neural network is modified to classify the images of the chiller room equipment obtained by the visible light camera; 2) image morphology methods and trigonometric functions are used to read the dials’ indicators acquired by the visible light camera; and 3) optical character recognition is used to obtain the highest temperature value in the infrared image of the pump captured by the infrared camera, which helps maintenance staff verify the operation of the pump and detect faults as soon as possible. These diagnostic algorithms are non-intrusive, low cost, and easy to deploy. Combined with real-time data collection from the sensors on the robot, the algorithms can effectively improve the intelligence of the equipment room and allocate human resources more reasonably.}
}
@article{LASSALLE2021147758,
title = {Monitoring natural and anthropogenic plant stressors by hyperspectral remote sensing: Recommendations and guidelines based on a meta-review},
journal = {Science of The Total Environment},
volume = {788},
pages = {147758},
year = {2021},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2021.147758},
url = {https://www.sciencedirect.com/science/article/pii/S0048969721028291},
author = {Guillaume Lassalle},
keywords = {Field spectroscopy, Imaging spectroscopy, Hyperspectral remote sensing, Precision farming, Environmental monitoring, Plant stress},
abstract = {This review outlines the advances achieved in monitoring natural and anthropogenic plant stressors by hyperspectral remote sensing over the last 50 years. A broad diversity of methods based on field and imaging spectroscopy were developed in that field for precision farming and environmental monitoring purposes. From the 466 articles reviewed, we identified the main factors to consider to achieve accurate monitoring of plant stress, namely: The plant species and the stressor to monitor, the goal (detection or quantification), and scale (field or broad-scale) of monitoring, and the need for controlled experiments. Based on these factors, we then provide recommendations and guidelines for the development of reliable methods to monitor 11 major biotic and abiotic plant stressors. For each stressor, the effects on plant health and reflectance are described and the most suited spectral regions, scale, spatial resolution, and processing approaches to achieve accurate monitoring are presented. As a perspective, we discuss two major components that should be implemented in future methods to improve stress monitoring: The discrimination of plant stressors with similar effects on plants and the transferability of the methods across scales.}
}
@article{VILLAHENRIKSEN202060,
title = {Internet of Things in arable farming: Implementation, applications, challenges and potential},
journal = {Biosystems Engineering},
volume = {191},
pages = {60-84},
year = {2020},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2019.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S1537511020300039},
author = {Andrés Villa-Henriksen and Gareth T.C. Edwards and Liisa A. Pesonen and Ole Green and Claus Aage Grøn Sørensen},
keywords = {Smart farming, Internet of things, Wireless sensor network, Farm management information system, Big data, Machine learning},
abstract = {The Internet of Things is allowing agriculture, here specifically arable farming, to become data-driven, leading to more timely and cost-effective production and management of farms, and at the same time reducing their environmental impact. This review is addressing an analytical survey of the current and potential application of Internet of Things in arable farming, where spatial data, highly varying environments, task diversity and mobile devices pose unique challenges to be overcome compared to other agricultural systems. The review contributes an overview of the state of the art of technologies deployed. It provides an outline of the current and potential applications, and discusses the challenges and possible solutions and implementations. Lastly, it presents some future directions for the Internet of Things in arable farming. Current issues such as smart phones, intelligent management of Wireless Sensor Networks, middleware platforms, integrated Farm Management Information Systems across the supply chain, or autonomous vehicles and robotics stand out because of their potential to lead arable farming to smart arable farming. During the implementation, different challenges are encountered, and here interoperability is a key major hurdle throughout all the layers in the architecture of an Internet of Things system, which can be addressed by shared standards and protocols. Challenges such as affordability, device power consumption, network latency, Big Data analysis, data privacy and security, among others, have been identified by the articles reviewed and are discussed in detail. Different solutions to all identified challenges are presented addressing technologies such as machine learning, middleware platforms, or intelligent data management.}
}
@article{YU2022393,
title = {Bionic tracking-containment control based on smooth transition in communication},
journal = {Information Sciences},
volume = {587},
pages = {393-407},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.12.060},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521012810},
author = {Dengxiu Yu and Jia Long and C.L. {Philip Chen} and Zhen Wang},
keywords = {Bionic tracking-containment control, Command filter, Input saturation, Smooth transition, Adaptive backstepping},
abstract = {In this paper, we propose the bionic tracking-containment control based on smooth transition in communication, which is inspired by wolf hunting. To realize the hunting target process, we concentrate on the transition from tracking control to containment control of the swarm system by using backstepping method. The smooth transition of switching communication topology is introduced to realize bionic switching. We design a smooth switching function, which can avoid the negative influence of instant switch. Due to the input saturation and smooth switching function, it is challenging to design the tracking-containment controller with nonlinear dynamics and external disturbances. To overcome these difficulties, we design the tracking-containment control based on the adaptive backstepping method, which includes n command filters and one adaptive neural network to improve the control performance. The swarm system is proved stable under the Lyapunov stability criterion. Finally, simulation is carried out to verify the feasibility of the proposed method.}
}
@article{DRAKE2020405,
title = {Recent advances in selection hyper-heuristics},
journal = {European Journal of Operational Research},
volume = {285},
number = {2},
pages = {405-428},
year = {2020},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2019.07.073},
url = {https://www.sciencedirect.com/science/article/pii/S0377221719306526},
author = {John H. Drake and Ahmed Kheiri and Ender Özcan and Edmund K. Burke},
keywords = {Decision support systems, Artificial intelligence, Machine learning, Metaheuristics, Heuristics},
abstract = {Hyper-heuristics have emerged as a way to raise the level of generality of search techniques for computational search problems. This is in contrast to many approaches, which represent customised methods for a single problem domain or a narrow class of problem instances. The term hyper-heuristic was defined in the early 2000s as a heuristic to choose heuristics, but the idea of designing high-level heuristic methodologies can be traced back to the early 1960s. The current state-of-the-art in hyper-heuristic research comprises a set of methods that are broadly concerned with intelligently selecting or generating a suitable heuristic for a given situation. Hyper-heuristics can be considered as search methods that operate on lower-level heuristics or heuristic components, and can be categorised into two main classes: heuristic selection and heuristic generation. Here we will focus on the first of these two categories, selection hyper-heuristics. This paper gives a brief history of this emerging area, reviews contemporary selection hyper-heuristic literature, and discusses recent selection hyper-heuristic frameworks. In addition, the existing classification of selection hyper-heuristics is extended, in order to reflect the nature of the challenges faced in contemporary research. Unlike the survey on hyper-heuristics published in 2013, this paper focuses only on selection hyper-heuristics and presents critical discussion, current research trends and directions for future research.}
}
@article{GENG2018895,
title = {Combining CNN and MRF for road detection},
journal = {Computers & Electrical Engineering},
volume = {70},
pages = {895-903},
year = {2018},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2017.11.026},
url = {https://www.sciencedirect.com/science/article/pii/S0045790617321663},
author = {Lei Geng and Jiangdong Sun and Zhitao Xiao and Fang Zhang and Jun Wu},
keywords = {Driver assistance system, Road detection, Super-pixel, CNN, MRF},
abstract = {Road detection aims at detecting the road surface ahead of the vehicle and plays a crucial role in driver assistance systems. To improve the accuracy and robustness of road detection approaches in complex environments, a new road detection method based on a convolutional neural network (CNN) and Markov random field (MRF) is proposed. The original road image is segmented into super-pixels of uniform size using the simple linear iterative clustering (SLIC) algorithm. On this basis, we train the convolutional neural network, which can automatically learn the features that are most beneficial to the classification. The trained convolutional neural network (CNN) is then applied to classify road and non-road regions. Finally, based on the relationship between the super-pixel neighborhood, we utilize Markov random field (MRF) to optimize the classification results of the convolutional neural network (CNN). The approach provides the better performance.}
}
@article{GILL2019100118,
title = {Transformative effects of IoT, Blockchain and Artificial Intelligence on cloud computing: Evolution, vision, trends and open challenges},
journal = {Internet of Things},
volume = {8},
pages = {100118},
year = {2019},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2019.100118},
url = {https://www.sciencedirect.com/science/article/pii/S2542660519302331},
author = {Sukhpal Singh Gill and Shreshth Tuli and Minxian Xu and Inderpreet Singh and Karan Vijay Singh and Dominic Lindsay and Shikhar Tuli and Daria Smirnova and Manmeet Singh and Udit Jain and Haris Pervaiz and Bhanu Sehgal and Sukhwinder Singh Kaila and Sanjay Misra and Mohammad Sadegh Aslanpour and Harshit Mehta and Vlado Stankovski and Peter Garraghan},
keywords = {Cloud computing, Quality of Service, Cloud applications, Cloud paradigms and technologies, IoT, Blockchain, Artificial Intelligence},
abstract = {Cloud computing plays a critical role in modern society and enables a range of applications from infrastructure to social media. Such system must cope with varying load and evolving usage reflecting societies’ interaction and dependency on automated computing systems whilst satisfying Quality of Service (QoS) guarantees. Enabling these systems are a cohort of conceptual technologies, synthesized to meet demand of evolving computing applications. In order to understand current and future challenges of such system, there is a need to identify key technologies enabling future applications. In this study, we aim to explore how three emerging paradigms (Blockchain, IoT and Artificial Intelligence) will influence future cloud computing systems. Further, we identify several technologies driving these paradigms and invite international experts to discuss the current status and future directions of cloud computing. Finally, we proposed a conceptual model for cloud futurology to explore the influence of emerging paradigms and technologies on evolution of cloud computing.}
}
@article{WANG202066,
title = {Cognitive multi-agent empowering mobile edge computing for resource caching and collaboration},
journal = {Future Generation Computer Systems},
volume = {102},
pages = {66-74},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19318783},
author = {Rui Wang and Miao Li and Limei Peng and Ying Hu and Mohammad Mehedi Hassan and Abdulhameed Alelaiwi},
keywords = {Cognitive agent, Mobile edge computing, Caching strategy, Resource collaboration},
abstract = {The service of mobile network develops rapidly nowadays, which generates various computing and resource-intensive applications, such as Internet of vehicles and virtual reality. Mobile edge computing (MEC) is close to data source and users, so terminals can execute tasks at the edge of network. In this way, the heavy load on core network can be relieved and tasks can be executed effectively. However, the demands of users vary from each other and users move all the time. It is difficult for the existing way of service supply to meet demands of all users. Cognitive Agent (CA) is put forward in this paper to help users cache and execute tasks on MEC in advance. In detail, CA is used to build personalized model combined with users’ behavior data. At the same time, it uses Long short-term memory neural network to forecast the moving trajectory of terminal equipment and the service types to be requested, uses the prediction result to generate caching strategy, cache business and shorten the delay of task execution. Besides, to further reduce the stress on MEC, we propose the collaboration of computing, communicating and caching resource with neighboring users’ equipment. To verify the effectiveness of CA, we build a model that assesses the performance of the system. Finally, we design a simulation experiment to execute resource request and resource collaboration. The result of the experiments show that CA can improve the efficiency of communication network, relieve the stress on network and improve the quality of services to users.}
}
@article{TALATI2021107783,
title = {An AI-driven object segmentation and speed control scheme for autonomous moving platforms},
journal = {Computer Networks},
volume = {186},
pages = {107783},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107783},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620313566},
author = {Shreya Talati and Darshan Vekaria and Aparna Kumari and Sudeep Tanwar},
keywords = {AMP, CNN, Image segmentation, Speed Range Analyser, K-Means, 5G},
abstract = {In recent times, Autonomous Moving Platforms (AMP) have been a vital component for various industrial sectors across the globe as they include a diverse set of aerial, marine, and land-based vehicles. The emergence and the rise of AMP necessitate a precise object-level understanding of the environment, which directly impacts the functioning like decision making, speed control, and direction of the autonomous driving vehicles. Obstacle detection and object classification are the key issues in the AMP. The autonomous vehicle is designed to move in the city roads and it should be bolstered with high-quality object detection/segmentation mechanisms since inaccurate movements and speed limits can prove to be fatal. Motivated from the aforementioned discussion, in this paper, we present ϑinspect (velocity-inspect), an AI-based 5G enabled object segmentation and speed limit identification scheme for self-driving cars on the city roads. In ϑinspect, the Convolutional Neural Network (CNN) based semantic image segmentation is carried out to segment the objects as interpreted from the Cityscapes dataset. Then, object clustering is done using the K-Means approach based on the number of unique objects. The semantic segmentation is done over 12 classes and the model outshines concerning state-of-the-art approaches for various parameters like latency, high accuracy of 82.2%, and others. Further, K-Means clustering based Speed Range Analyser (SRA) is proposed to determine the acceptable and safe speed range for the vehicle, which is computed based on the object density of every object in the environment. The results show that the proposed scheme outperforms compared to traditional schemes in terms of latency and accuracy.}
}
@article{AGNISARMAN201952,
title = {A survey of automation-enabled human-in-the-loop systems for infrastructure visual inspection},
journal = {Automation in Construction},
volume = {97},
pages = {52-76},
year = {2019},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.10.019},
url = {https://www.sciencedirect.com/science/article/pii/S0926580518303248},
author = {Sruthy Agnisarman and Snowil Lopes and Kapil {Chalil Madathil} and Kalyan Piratla and Anand Gramopadhye},
keywords = {Systematic review, Infrastructure inspection, Automation, Human-in-the-loop systems},
abstract = {Routine inspection and maintenance are critical for the proper functioning of civil infrastructures such as bridges, pavements and underground structures. Civil infrastructures are being inspected less frequently because of the high cost and long duration of current inspection procedures. Furthermore, conventional inspection procedures often interrupt the routine functioning of the infrastructure, are inspector-dependent and expose the inspectors to complex and unsafe working environments. Visual inspection technologies play a crucial role in the inspection and maintenance of civil infrastructures. Automation-assisted technologies such as drones and underwater vehicles equipped with multiple imaging and sensing systems have been developed to address some of these issues with the conventional visual inspection processes. This paper reviews peer-reviewed research publications investigating automated visual inspection technologies following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Specifically, 53 publications satisfying a set of inclusion criteria were reviewed, its results highlighting the application domain, the level of autonomy of the automated systems, the sensor technologies used for the inspection process and navigation, the navigation and control technologies and the algorithms used. The review of the articles revealed that the data collected by automation is used to augment the qualitative assessment. Several types of algorithms such as target detection and image enhancing have been developed to reduce the inspector bias in these automated technologies. Path planning algorithms reduce the workload on the inspector by automating the navigation and control tasks. Remotely operated systems reduce the risk to the inspectors by minimizing their exposure to the inspection environment. However, only a limited number of studies investigated the human factors aspects of the automation-assisted inspection process. It is important to understand the cognitive, physical, and temporal demands these technologies place on inspectors to improve the design of systems assisting in the inspection process. Moreover, factors such as automation bias, trust in the system and communication between the automation and the operator need to be investigated. Furthermore, it is important to incorporate appropriate decision aids that support adequate situation awareness in the interface design. Based on these findings this review proposes directions for future research. This review concludes by highlighting the need for human-centered research to develop better solutions for infrastructure inspection problems.}
}
@article{KANG2019366,
title = {Long short-term memory-based Malware classification method for information security},
journal = {Computers & Electrical Engineering},
volume = {77},
pages = {366-375},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618328167},
author = {Jungho Kang and Sejun Jang and Shuyu Li and Young-Sik Jeong and Yunsick Sung},
keywords = {Malware classification, Security, Deep learning, Static analysis},
abstract = {Signature-based malware detection approaches are inadequate for detecting the increasingly intelligent and large number of malware programs emerging today. Therefore, alternative approaches are required. The effects of malware can be estimated by analyzing the opcodes in its executable files. It can then be classified into families using a long short-term memory (LSTM) network. Vectorizing opcodes and application programming interface (API) function names using one-hot encoding results in high-dimensional vectors because each case is represented using one dimension. Therefore, this paper proposes a word2vec-based LSTM method to analyze opcodes and API function names using fewer dimensions. The results of opcode and API function name classification using the proposed method and one-hot encoding were compared using the Microsoft Malware Classification Challenge dataset. The proposed method showed approximately 0.5% higher performance than the one-hot encoding-based approach.}
}
@article{YOUSFI2022,
title = {Smart big data framework for insight discovery},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821003542},
author = {Siham Yousfi and Dalila Chiadmi and Maryem Rhanoui},
keywords = {Big data value chain, Data integration, Heterogeneous data sources, Spacio-temporal traffic monitoring, Traffic management systems},
abstract = {Big Data deal with new challenges such as data variety, data veracity (correct, incorrect, misleading, etc.) and data completeness (provide a single part of the overall information.). In fact, the knowledge discovered from a single source that can offer incorrect or incomplete data, may have a negative impact on the quality of decisions based on it. Therefore, integrating data coming from multiple sources allows verifying the veracity and ensuring the completeness of the results and thus improving the quality of analysis and enhancing business decisions. In this paper, we present a smart framework that falls within the Big Data value chain process and aims to improve the quality of analytical results by focusing two main concerns regarding Big Data Integration; data completeness and data veracity. The framework integrates Big Data in order to build a complete global and correct insight from heterogeneous sources. The paper presents two implementations of the framework in the context of urban and highway traffic management systems.}
}
@article{FENG2020101694,
title = {Efficient drone hijacking detection using two-step GA-XGBoost},
journal = {Journal of Systems Architecture},
volume = {103},
pages = {101694},
year = {2020},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2019.101694},
url = {https://www.sciencedirect.com/science/article/pii/S1383762119305016},
author = {Zhiwei Feng and Nan Guan and Mingsong Lv and Wenchen Liu and Qingxu Deng and Xue Liu and Wang Yi},
keywords = {Cyber-physical system, UAV, Security, GPS spoofing, Machine learning},
abstract = {With the fast growth of civilian drones, their security problems meet significant challenges. A commercial drone may be hijacked by Global Positioning System (GPS)-spoofing attacks for illegal activities, such as terrorist attacks. Ideally, comparing positions respectively estimated by GPS and Inertial Navigation System (INS) can detect such attacks, while the results may always get fault because of the accumulated errors over time in INS. Therefore, in this paper, we propose a two-step GA-XGBoost method to detect GPS-spoofing attacks that just uses GPS and Inertial Measurement Unit (IMU) data. However, tunning the proper values of XGBoost parameters directly on the drone to achieve high prediction results consumes lots of resources which would influence the real-time performance of the drone. The proposed method separates the training phase into offboard step and onboard step. In offboard step, model is first trained by flight logs, and the training parameter values are automatically tuned by Genetic Algorithm (GA). Once the offboard model is trained, it could be uploaded to drones. To adapt our method to drones with different types of sensors and improve the correctness of prediction results, in onboard step, the model is further trained when a drone starts a mission. After onboard training finishes, the proposed method switches to the prediction mode. Besides, our method does not require any extra onboard hardware. The experiments with a real quadrotor drone also show the detection correctness is 96.3% and 100% in hijacked and non-hijacked cases at each sampling time respectively. Moreover, our method can achieve 100% detection correctness just within 1 s just after the attacks start.}
}
@article{PRADEEPKUMAR2020106216,
title = {Advances in detection algorithms for radiation monitoring},
journal = {Journal of Environmental Radioactivity},
volume = {217},
pages = {106216},
year = {2020},
issn = {0265-931X},
doi = {https://doi.org/10.1016/j.jenvrad.2020.106216},
url = {https://www.sciencedirect.com/science/article/pii/S0265931X20300588},
author = {K.A. {Pradeep Kumar} and G.A. {Shanmugha Sundaram} and R. Thiruvengadathan},
keywords = {Gamma radiation detection, Radiation monitoring, Mapping fallout, Localization, Plume tracking, Isotope-identification, Spectroscopy processing, de-noising, Compton continuum},
abstract = {This paper presents a review of up-to-date advancements in detection algorithms employed in radiation monitoring for generating radiation maps of ground contamination and tracking radioactive release into the atmosphere. Detection algorithms for true count processing, spectroscopy processing, and plume tracking are discussed in chronological order of development. Process steps of detection include height correction, solid-angle correction, background radioactivity correction, Compton continuum elimination, de-noising of gamma-radiation spectra, and recording of plume passage events.}
}
@article{FERNANDES2016217,
title = {ODROID XU4 based implementation of decision level fusion approach for matching computer generated sketches},
journal = {Journal of Computational Science},
volume = {16},
pages = {217-224},
year = {2016},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2016.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S1877750316301211},
author = {Steven Lawrence Fernandes and G. Josemin Bala},
keywords = {Single board computer, Supervised auto-encoder, Deep architecture, Parallel convolutional neural network},
abstract = {Implementing computer vision applications on energy efficient and powerful single board computer devices is a hot topic of research. ODROID-XU4 is one such latest single board computing device which is extremely energy efficient and powerful, having a small form factor when compared to any other ARM based embedded devices. It supports open source operations systems and runs a variety of Linux flavors including Ubuntu and various Android versions including Lollipop. Moreover, it supports USB 3.0, eMMC 5.0 and Gigabit Ethernet interfaces thus, making the device feasible to transfer data at a very high speed. The key contribution of this paper is we have developed a novel technique to match computer generated sketches with face photos and implemented it on ODROID XU4 single board computer which makes it feasible to be used in real-time. Human face is detected on the face photos using Viola Jones method. On the detected faces and computer generated sketches, feature extraction is performed using supervised auto-encoder to build deep architecture and matching is performed between computer generated sketches and face photos using Parallel Convolutional Neural Network (PCNN). Finally decision level fusion is performed to find the optimal matching result. In this study, the authors have performed pilot testing of their technique and results of their analysis are presented to the readers.}
}
@article{DRECCER201973,
title = {Yielding to the image: How phenotyping reproductive growth can assist crop improvement and production},
journal = {Plant Science},
volume = {282},
pages = {73-82},
year = {2019},
note = {The 4th International Plant Phenotyping Symposium},
issn = {0168-9452},
doi = {https://doi.org/10.1016/j.plantsci.2018.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0168945217311585},
author = {M. Fernanda Dreccer and Gemma Molero and Carolina Rivera-Amado and Carus John-Bejai and Zoe Wilson},
keywords = {High-throughput phenotyping, Reproductive structures, Phenology, Pollen, Floret fertility, Yield components},
abstract = {Reproductive organs are the main reason we grow and harvest most plant species as crops, yet they receive less attention from phenotyping due to their complexity and inaccessibility for analysis. This review highlights recent progress towards the quantitative high-throughput phenotyping of reproductive development, focusing on three impactful areas that are pivotal for plant breeding and crop production. First, we look at phenotyping phenology, summarizing the indirect and direct approaches that are available. This is essential for analysis of genotype by environment, and to enable effective management interpretation and agronomy and physiological interventions. Second, we look at pollen development and production, in addition to anther characteristics, these are critical points of vulnerability for yield loss when stress occurs before and during flowering, and are of particular interest for hybrid technology development. Third, we elaborate on phenotyping yield components, indirectly or directly during the season, with a numerical or growth related approach and post-harvest processing. Finally, we summarise the opportunities and challenges ahead for phenotyping reproductive growth and their feasibility and impact, with emphasis on plant breeding applications and targeted yield increases.}
}
@article{FANG201613,
title = {Motion Based Animal Detection in Aerial Videos},
journal = {Procedia Computer Science},
volume = {92},
pages = {13-17},
year = {2016},
note = {2nd International Conference on Intelligent Computing, Communication & Convergence, ICCC 2016, 24-25 January 2016, Bhubaneswar, Odisha, India},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.316},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916315629},
author = {Yunfei Fang and Shengzhi Du and Rishaad Abdoola and Karim Djouani and Coneth Richards},
keywords = {optical flow, image segmentation, computer vision, object detection, animal tracking, dynamic background, moving camera, UAV, drone, wildlife survey},
abstract = {Computer vision techniques are applied to perform automatic wildlife surveying and animal monitoring. Animal detection in aerial videos is challenging because of the complexity of wild environments. In this paper, a method for moving animal detection is proposed by taking advantage of global patterns of pixel motion. In the video dataset, where animals make obvious movement against the background, motion vectors of each pixel are estimated by applying optical flow methods. A coarse segmentation then removes most parts of the background by applying a pixel velocity threshold. Based on the segmented regions, another threshold was employed to filter out negative candidates that could belong to the background. The pros and cons of this method are discussed.}
}
@article{RANI20222994,
title = {Role of IoT-Cloud Ecosystem in Smart Cities : Review and Challenges},
journal = {Materials Today: Proceedings},
volume = {49},
pages = {2994-2998},
year = {2022},
note = {National Conference on Functional Materials: Emerging Technologies and Applications in Materials Science},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2020.10.054},
url = {https://www.sciencedirect.com/science/article/pii/S2214785320376215},
author = {Ridhima Rani and Vijaita Kashyap and Meenu Khurana},
keywords = {Smart city, IoT, Cloud computing, Fog computing},
abstract = {Smart Cities is one of the most important Internet of Things (IoT) applications. Billions of smart devices on IoT produce volumes of data directed to cloud for storage and processing. Sending complete data to cloud is least preferred from resource utilization perspective comprising of bandwidth and storage. Therefore, cloud computing paradigm limitations conquered by fog computing, acting as a bridge between IoT and cloud. Further, the limited computational capacity of end-devices in IoT infrastructure and inherited pros and cons of cloud and fog computing necessitates for all three paradigms to work together to full fill the needs of sustainable infrastructure for smart city. Keeping in view the need of integrating fog computing paradigm (due to its limited storage and computational capabilities), with IoT and cloud infrastructure, this article reviews the literature on role of IoT & cloud ecosystem in smart cities along with parameters of evaluation and future research directions in smart cities.}
}
@article{MOGHADDAM202170,
title = {On the guidance, navigation and control of in-orbit space robotic missions: A survey and prospective vision},
journal = {Acta Astronautica},
volume = {184},
pages = {70-100},
year = {2021},
issn = {0094-5765},
doi = {https://doi.org/10.1016/j.actaastro.2021.03.029},
url = {https://www.sciencedirect.com/science/article/pii/S0094576521001429},
author = {Borna Monazzah Moghaddam and Robin Chhabra},
keywords = {Guidance, navigation and control, Space robotic, On-orbit servicing, Artificial intelligence, Geometric mechanics},
abstract = {In the first part, this article presents an overview of Guidance, Navigation and Control (GNC) methodologies developed for space manipulators to perform in-orbit robotic missions, including but not limited to, on-orbit servicing, satellite/station assembly, probing extra-terrestrial objects and space debris mitigation. Some space mission concepts are briefly mentioned, for which space robotics is discussed to be among the most practical and universal solutions. Common phases of an in-orbit robotic mission are identified as: close-range rendezvous, attitude synchronization, target identification, manipulator deployment, capture, and if needed, post-capture maneuvers. Prominent GNC methodologies that are either proposed for or applicable to each phase are extensively reviewed. In the current article, the emphasis is placed on the study of GNC methodologies utilized in attitude synchronization, manipulator deployment, and capture phases, specially the ones reported for use in the two free-floating and free-flying operating regimes of space manipulators. Kinematics and dynamics of space manipulator systems are formulated to help unifying the presentation of the main ideas behind different GNC methodologies. Using a unified notation, comparison tables and discussions provided in this paper, researchers can compare various GNC approaches and contribute to the next-generation GNC systems for space robots. In addition, this survey aids technology users to learn about in-orbit robotic missions and choose appropriate GNC technologies for specific applications. In the second part of this paper, two families of emerging control schemes based upon reinforcement learning and geometric mechanics are introduced as promising research directions in the GNC of space robotic systems. The benefits of implementing these techniques to the GNC of in-orbit robotic missions are discussed. An exclusive study of environmental disturbances affecting space manipulators and their threat to long-term autonomy concludes this article.}
}
@article{ELAYAPERUMAL2021467,
title = {Robust visual object tracking using context-based spatial variation via multi-feature fusion},
journal = {Information Sciences},
volume = {577},
pages = {467-482},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.06.084},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521006757},
author = {Dinesh Elayaperumal and Young Hoon Joo},
keywords = {Correlation filter, Context, Spatial variation, Feature fusion, ADMM, Object tracking},
abstract = {With the emergence of camera technology, visual tracking has witnessed great attention in the field of computer vision. For instance, numerous discriminative correlation filter (DCF) methods are broadly used in tracking, nevertheless, most of them fail to efficiently find the target in challenging situations which leads to tracking failure throughout the sequences. In order to handle these issues, we propose contextual information based spatial variation with a multi-feature fusion method (CSVMF) for robust object tracking. This work incorporates the contextual information of the target to determine the location of the target accurately, which utilizes the relationship between the target and its surroundings to increase the efficiency of the tracker. In addition, we integrate the spatial variation information which measures the second-order difference of the filter to avoid the over-fitting problem caused by the changes in filter coefficient. Furthermore, we adopt multi-feature fusion strategy to enhance the target appearance by using different metrics. The tracking results from different features are fused by employing peak-to-sidelobe ratio (PSR) which measures the peak strength of the response. Finally, we conduct extensive experiments on TC128, DTB70, UAV123@10fps, and UAV123 datasets to demonstrate that the proposed method achieves a favorable performance over the existing ones.}
}
@article{JIN2021202,
title = {Lidar sheds new light on plant phenomics for plant breeding and management: Recent advances and future prospects},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {171},
pages = {202-223},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620303130},
author = {Shichao Jin and Xiliang Sun and Fangfang Wu and Yanjun Su and Yumei Li and Shiling Song and Kexin Xu and Qin Ma and Frédéric Baret and Dong Jiang and Yanfeng Ding and Qinghua Guo},
keywords = {Lidar, Traits, Phenomics, Breeding, Management, Multi-omics},
abstract = {Plant phenomics is a new avenue for linking plant genomics and environmental studies, thereby improving plant breeding and management. Remote sensing techniques have improved high-throughput plant phenotyping. However, the accuracy, efficiency, and applicability of three-dimensional (3D) phenotyping are still challenging, especially in field environments. Light detection and ranging (lidar) provides a powerful new tool for 3D phenotyping with the rapid development of facilities and algorithms. Numerous efforts have been devoted to studying static and dynamic changes of structural and functional phenotypes using lidar in agriculture. These progresses also improve 3D plant modeling across different spatial–temporal scales and disciplines, providing easier and less expensive association with genes and analysis of environmental practices and affords new insights into breeding and management. Beyond agriculture phenotyping, lidar shows great potential in forestry, horticultural, and grass phenotyping. Although lidar has resulted in remarkable improvements in plant phenotyping and modeling, the synthetization of lidar-based phenotyping for breeding and management has not been fully explored. We identify three main challenges in lidar-based phenotyping development: 1) developing low cost, high spatial–temporal, and hyperspectral lidar facilities, 2) moving into multi-dimensional phenotyping with an endeavor to generate new algorithms and models, and 3) embracing open source and big data.}
}
@article{BEHERA2021163,
title = {Futuristic person re-identification over internet of biometrics things (IoBT): Technical potential versus practical reality},
journal = {Pattern Recognition Letters},
volume = {151},
pages = {163-171},
year = {2021},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2021.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0167865521002841},
author = {Nayan Kumar Subhashis Behera and Tanmay Kumar Behera and Michele Nappi and Sambit Bakshi and Pankaj Kumar Sa},
keywords = {Visual surveillance, Person re-identification, Internet of things (IoT), Internet of biometric things (IoBT)},
abstract = {This article presents an overview of how person re-identification can be achieved over the Internet of Biometric Things (IoBT) architecture by enabling technologies and protocols for multimodal biometric authentication leveraging futuristic cues. The Internet of Things (IoT), as a new era of technology, extends the power of the internet to a whole range of devices, thus reshaping our daily lives in the best possible way. IoT-enabled intelligent surveillance devices are the most indispensable part of public safety and security in smart cities. These IoT devices generate a vast amount of surveillance traffic that is practically impossible for humans to continuously monitor and/or analyze. Person re-identification (PRId), which aims to track and recognize a person in a multi-camera scene is an important feature of visual surveillance systems in IoT infrastructures and can utilize the aforementioned traffic. This is where the concept of IoBT, which is a cloud-centric biometric authentication architecture composed of these IoT-enabled devices for the PRId system,  comes into play. This article conceptualizes an overview of interpreting various futuristic cues on the IoT platform for achieving PRId. We highlight some opportunities and key challenges of implementing this futuristic PRId system on IoBT. The article is a proof of concept of the technical potential of such implementation in the near future.}
}
@article{APOSTOL2020134074,
title = {Species discrimination and individual tree detection for predicting main dendrometric characteristics in mixed temperate forests by use of airborne laser scanning and ultra-high-resolution imagery},
journal = {Science of The Total Environment},
volume = {698},
pages = {134074},
year = {2020},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2019.134074},
url = {https://www.sciencedirect.com/science/article/pii/S0048969719340513},
author = {Bogdan Apostol and Marius Petrila and Adrian Lorenţ and Albert Ciceu and Vladimir Gancz and Ovidiu Badea},
keywords = {ALS, UAV, OBIA, Forest inventory, Monte Carlo simulation},
abstract = {This study aims to investigate the combined use of two types of remote sensing data — ALS derived and digital aerial photogrammetry data (based on imagery collected by airborne UAV sensors) — along with intensive field measurements for extracting and predicting tree and stand parameters in even-aged mixed forests. The study is located in South West Romania and analyzes data collected from mixed-species plots. The main tree species within each plot are Norway spruce (Picea abies L. Karst.) and Beech (Fagus sylvatica L.). The ALS data were used to extract the digital terrain model (DTM), digital surface model (DSM) and normalized canopy height model (CHM). Object-Based Image Analysis (OBIA) classification was performed to automatically detect and separate the main tree species. A local filtering algorithm with a canopy-height based variable window size was applied to identify the position, height and crown diameter of the main tree species within each plot. The filter was separately applied for each of the plots and for the areas covered with Norway spruce and beech trees, respectively (i.e. as resulted from OBIA classification). The dbh was predicted based on ALS data by statistical Monte Carlo simulations and a linear regression model that relates field dbh for each tree species with their corresponding ALS-derived tree height and crown diameter. The overall RMSE for each of the tree species within all the plots was 5.8 cm for the Norway spruce trees, respectively 5.9 cm for the beech trees. The results indicate a higher individual tree detection rate and subsequently a more precise estimation of dendrometric parameters for Norway spruce compared to beech trees located in spruce-beech even-aged mixed stands. Further investigations are required, particularly in the case of choosing the best method for individual tree detection of beech trees located in temperate even-aged mixed stands.}
}
@article{SIVACHITRA2015198,
title = {A Fully Complex-valued Fast Learning Classifier (FC-FLC) for real-valued classification problems},
journal = {Neurocomputing},
volume = {149},
pages = {198-206},
year = {2015},
note = {Advances in neural networks Advances in Extreme Learning Machines},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2014.04.075},
url = {https://www.sciencedirect.com/science/article/pii/S0925231214011527},
author = {M. Sivachitra and R. Savitha and S. Suresh and S. Vijayachitra},
keywords = {Complex-valued neural network, Classification, Gudermannian function, Circular transformation, Extreme learning machine},
abstract = {This paper presents a Fully Complex-valued Fast Learning Classifier (FC-FLC) to solve real-valued classification problems. FC-FLC is a single hidden layer network with a nonlinear input and hidden layer, and a linear output layer. The neurons at the input layer of the FC-FLC employ the circular transformation to convert the real-valued input features to the Complex domain. At the hidden layer, the complex-valued input features are projected onto a hyper-dimensional complex plane (Cm→CK) using the K hidden neurons employing Gudermannian (Gd) activation function. To investigate the suitability of the Gd as an activation function for a fully complex-valued network, we formulate the activation function in two forms. The output layer is linear. The input weights of the FC-FLC are chosen randomly and the output weights are estimated analytically. The best input weights corresponding to the best generalization performance of the FC-FLC are obtained by a k-fold cross validation. The performance of the proposed classifier is evaluated in comparison to other complex-valued and a few best performing real-valued classifiers on a set of benchmark classification problems from the UCI machine learning repository and a practical human emotion recognition problem. Statistical analysis is carried out to validate the performance of the classifier. Performance results show that FC-FLC has better classification ability than the other classifiers in the literature.}
}
@article{PHAM2019176,
title = {LPV and Nonlinear-based control of an Autonomous Quadcopter under variations of mass and moment of inertia⁎⁎We would like to express our greatest gratitude toward the late Professor Yasmina BESTAOUI-SEBBANE, Professeure des Universités à l’UFR Sciences et Technologies de l’Université d’Evry-Val-d’Essonne, without whom this project could not have gotten this far.},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {28},
pages = {176-183},
year = {2019},
note = {3rd IFAC Workshop on Linear Parameter Varying Systems LPVS 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.371},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319322712},
author = {The Hung Pham and Dalil Ichalal and Said Mammar},
keywords = {UAV, Quadcopter, Linear Parameter Varying, Backstepping, Proportional Integral Derivative, Linear Matrix Inequality, Robust Control, -Optimal control},
abstract = {This paper presents a hybrid robust control strategy to solve the trajectory tracking function of a quadcopter with time-varying mass. In the context of this paper, two ways of changing the mass of a quadcopter are considered. The first one involves a gradual continuous reduction of the mass throughout the flying time, and the second involves an abrupt change at some point during the flight. Besides the change of the mass, the moments of inertia with respect to the three axes are also changing. These moments of inertia are recalculated in realtime according to the mass changes. The quadcopter model is separated into two subsystems: rotational and translational. The rotational subsystem contains several time-varying parameters, such as the mass, the moments of inertia, and the speed of the rotor. It can be considered as a quasi-Linear Parameter Varying (LPV) system. An LPV H∞ controller has been designed to stabilize the orientation actuator’s dynamic. To ensure that the quadcopter follows the pre-defined trajectory, a combination of Integral Backstepping and Proportional Derivative (PD) controllers are used for the translational subsystem. The efficiency and robustness of the proposed cascaded controller with disturbances, noises, and model parameters uncertainties have been tested in MATLAB.}
}
@article{ZHAI2020102252,
title = {Damage assessment using Google Street View: Evidence from Hurricane Michael in Mexico Beach, Florida},
journal = {Applied Geography},
volume = {123},
pages = {102252},
year = {2020},
issn = {0143-6228},
doi = {https://doi.org/10.1016/j.apgeog.2020.102252},
url = {https://www.sciencedirect.com/science/article/pii/S0143622819303479},
author = {Wei Zhai and Zhong-Ren Peng},
keywords = {Damage assessment, Google street view, Deep learning, Remote sensing},
abstract = {Assessing damage on the ground is a challenging task for humanitarian organizations and disaster managers due to the limited availability of data and methods for processing. As the most commonly adopted data source, remote sensing imagery can only reflect the damage situation on top of a building and fails to present the damage level from the perspective of the human eye. Recently, an increasing number of Google Street View (GSV) images provide the chance to understand the human's perception of damage on the ground. However, to automatically and quantitatively apply GSV images in damage assessment, two research questions need to be answered: (1) Can deep learning be successfully applied to automate the process of evaluating postdisaster damage using GSV images? (2) Does damage assessment using GSV images provide a different insight, compared with existing approaches, such as remote sensing imagery? Based on our experiments using GSV images and remote sensing imagery in Mexico Beach, FL after Hurricane Michael, we present two conclusions: (1) By applying a deep learning model, the GSV-based damage assessment can be satisfactorily and automatically conducted, with an accuracy of approximately 70% for a single GSV image. (2) GSV images provide a different insight into damage assessment since remote sensing imagery cannot record the damage to exterior walls, windows, doors and facades. When the overall damage level is relatively low, GSV images show better performance in damage assessment. Conversely, when the overall damage level is relatively high, remote sensing imagery shows better performance based our experiments.}
}
@article{XIA2020146,
title = {Review-material degradation assessed by digital image processing: Fundamentals, progresses, and challenges},
journal = {Journal of Materials Science & Technology},
volume = {53},
pages = {146-162},
year = {2020},
issn = {1005-0302},
doi = {https://doi.org/10.1016/j.jmst.2020.04.033},
url = {https://www.sciencedirect.com/science/article/pii/S1005030220303868},
author = {Da-Hai Xia and Shizhe Song and Lei Tao and Zhenbo Qin and Zhong Wu and Zhiming Gao and Jihui Wang and Wenbin Hu and Yashar Behnamian and Jing-Li Luo},
keywords = {Image processing, Material degradation, Corrosion, Pitting, Fuzzy K-S entropy},
abstract = {Material degradation is accompanied by the changes in surface structure, morphology, and composition. These changes can be recorded by a variety of image acquisition devices that export digital images in grayscale or true color to a detector. Information regarding corrosion type and extent can be extracted with image processing methods. This paper provides a comprehensive review of material degradation assessed by digital image processing. Digital image processing systems used to assess material degradation are briefly reviewed, and the algorithms developed to process metallic materials degradation images are described. Physical and electrochemical methods that can be used to support digital image processing results are summarized, and future work that will augment the present methods of evaluating material degradation are discussed.}
}
@article{ZHANG2017127,
title = {Tracking control optimization scheme of continuous-time nonlinear system via online single network adaptive critic design method},
journal = {Neurocomputing},
volume = {251},
pages = {127-135},
year = {2017},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217306781},
author = {Kun Zhang and Huaguang Zhang and Geyang Xiao and Hanguang Su},
keywords = {Optimal tracking control, Continuous nonlinear system, Adaptive critic design (ACD), Neural network},
abstract = {In this paper, the optimal tracking control problem (OTCP) for a class of continuous-time nonlinear systems with infinite horizon cost is discussed. An online adaptive critic design method is proposed to learn the solution of OTCP by constructing an augmented system associated with a discounted performance function, which is composed of the tracking errors and reference trajectory dynamics. Only one neural network (NN) is used as critic module for approximating the performance function in the solution procedure, and thus the architecture is simpler than the typical action-critic structure, which needs more computational load from neural networks. Therefore, by the means of the approximate policy iteration, the tracking errors get converged to a region near zero and the parameters of critic module get converged to the optimal ones based on our proposed method. Both the convergence of the NN weights and the stability of the tracking error dynamics are guaranteed by the Lyapunov theory. Two simulation examples are proposed to verify the effectiveness of the proposed method.}
}
@article{GARCIAAUNON2018107,
title = {Control optimization of an aerial robotic swarm in a search task and its adaptation to different scenarios},
journal = {Journal of Computational Science},
volume = {29},
pages = {107-118},
year = {2018},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2018.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1877750318308482},
author = {Pablo Garcia-Aunon and Antonio {Barrientos Cruz}},
keywords = {Swarm robotics, Optimization, Modeling, Search},
abstract = {In many cases, the control system for robotic swarms are complex behavioral networks (frequently probabilistic finite state machines) with several parameters to be tuned. Their selection has a high impact on the performance of the swarm carrying out a given task. In the past, those parameters have been optimized using automatic methods, whereas in other cases the network is simplified and tuned making use of expert knowledge. The problem becomes trickier when the performance depends not only on these control parameters, but also on other variables that cannot be selected by the designer (such as the size of the scenario, or the number of available agents). Moreover, there usually exist factors that inject noise in the measured outcome, such as the initial conditions, making the task more difficult to be analyzed. This work proposes and compares principled methods that address these two issues: the optimal configuration of controls with a high dimensional configuration space, that at the same time must be optimized for a broad range of scenarios. As a testbed task, search on a rectangular area is studied. We show that our proposal successfully addresses this complex problem. Moreover, our approach may be also implemented to configure subtasks inside a global mission, or on single behaviors that must be configured on-line depending on external state values.}
}
@article{SUN2021106437,
title = {Distributed consensus algorithm for multiple parafoils in mass airdrop mission based on disturbance rejection},
journal = {Aerospace Science and Technology},
volume = {109},
pages = {106437},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.106437},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820311196},
author = {Hao Sun and Fuyong Wang and Qinglin Sun and Zengqiang Chen and Jin Tao},
keywords = {Parafoil delivery system, Airdrop experiment, Active disturbance rejection control, Homing theory, Multi-agent system},
abstract = {The mass airdrop is essential for transporting massive supplies and military, especially for the regions where the ground transportation is underdeveloped. It is realized by multiple parafoils which exist strong nonlinearity. In this paper, in order to achieve the mass airdrop, we explore a distributed control algorithm for the multiple parafoils by active disturbance rejection control. The highlight is to realize the consensus of multiple parafoils under the complicated dynamic characteristics and hybrid disturbance. Firstly, an eight-degree of freedom model is designed, which is applied to accurately simulate the states of the parafoil. Based on the dynamical model, the distributed consensus algorithm is presented. An active disturbance rejection controller is designed to achieve the precise trajectory tracking for this nonlinear multi-agent system. The stability of the proposed control method is also proved. At last, comparing with the traditional centralized algorithm and PID controller, the detailed simulation results show that the distributed method has huge improvement on the control accuracy and convergence time. The consensus of the multiple parafoils is successfully realized in 132 s under the hybrid disturbance which is 50 s faster than PID controller. The average error of the proposed method is also 60% smaller than the traditional controller. In this condition, the feasibility and validity of the proposed method in the mass airdrop has been proved.}
}
@article{THARAYIL2020103904,
title = {Sensor Defense In-Software (SDI): Practical software based detection of spoofing attacks on position sensors},
journal = {Engineering Applications of Artificial Intelligence},
volume = {95},
pages = {103904},
year = {2020},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2020.103904},
url = {https://www.sciencedirect.com/science/article/pii/S0952197620302402},
author = {Kevin Sam Tharayil and Benyamin Farshteindiker and Shaked Eyal and Nir Hasidim and Roy Hershkovitz and Shani Houri and Ilia Yoffe and Michal Oren and Yossi Oren},
keywords = {Sensor spoofing, Sensor fusion, Machine learning},
abstract = {Position sensors, such as the gyroscope, the magnetometer and the accelerometer, are found in a staggering variety of devices, from smartphones and UAVs to autonomous robots. Several works have shown how adversaries can mount spoofing attacks to remotely corrupt or even completely control the outputs of these sensors. With more and more critical applications relying on sensor readings to make important decisions, defending sensors from these attacks is of prime importance. In this work we present practical software based defenses against attacks on two common types of position sensors, specifically the gyroscope and the magnetometer. We first characterize the sensitivity of these sensors to acoustic and magnetic adversaries. Next, we present two software-only defenses: a machine learning-based single sensor defense, and a sensor fusion defense which makes use of the mathematical relationship between the two sensors. We performed a detailed theoretical analysis of our defenses, and implemented them on a variety of smartphones, as well as on a resource-constrained IoT sensor node. Our defenses do not require any hardware or OS-level modifications, making it possible to use them with existing hardware. Moreover, they provide a high detection accuracy, a short detection time and a reasonable power consumption.}
}
@article{QI201975,
title = {Robust visual tracking via scale-and-state-awareness},
journal = {Neurocomputing},
volume = {329},
pages = {75-85},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.10.035},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218312232},
author = {Yuankai Qi and Lei Qin and Shengping Zhang and Qingming Huang and Hongxun Yao},
keywords = {Visual tracking, Convolutional neural network, Bounding box refinement, Occlusion awareness},
abstract = {Convolutional neural networks (CNNs) have been applied to visual tracking with demonstrated success in recent years. However, the performance of CNN-based trackers can be further improved, because the predicted upright bounding box cannot tightly enclose the target due to factors such as deformations and rotations. Besides, many existing CNN-based trackers neglect to distinguish the occluded state of the target from non-occluded states, which causes the samples collected during occlusions wrongly update the tracker to focus on other objects. To address these problems, we propose to adaptively utilize the level set segmentation and bounding box regression techniques to obtain a tight enclosing box, and design a CNN to recognize whether the target is occluded. Extensive experimental results on a large benchmark dataset demonstrate the effectiveness of the proposed method compared to several state-of-the-art tracking algorithms.}
}
@article{YANG2021365,
title = {RGBT tracking via cross-modality message passing},
journal = {Neurocomputing},
volume = {462},
pages = {365-375},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221011966},
author = {Rui Yang and Xiao Wang and Chenglong Li and Jinmin Hu and Jin Tang},
keywords = {RGB-T tracking, Feature fusion, Channel communication},
abstract = {Many RGBT trackers utilize adaptive weighting mechanism to treat dual modalities differently and obtain more robust feature representations for tracking. Although these trackers work well under certain conditions, however, they ignore the information interactions in feature learning, which might limit tracking performance. In this paper, we propose a novel cross-modality message passing model to interactively learn robust deep representations of dual modalities for RGBT tracking. Specifically, we extract features of dual modalities by backbone network and take each channel of these features as a node of a graph. Therefore, all channels of dual modalities can explicitly communicate with each other by the graph learning, and the outputted features are thus more diverse and discriminative. Moreover, we introduce the gate mechanism to control the propagation of information flow to achieve more intelligent fusion. The features generated from the interactive cross-modality message passing model will be passed selectively through the gate layer and concatenated with original features as the final representation. We extend the ATOM tracker into its dual-modality version and combine it with our proposed module for final tracking. Extensive experiments on two RGBT benchmark datasets validate the effectiveness and efficiency of our proposed algorithm.}
}
@article{HART2021132882,
title = {Echo State Networks trained by Tikhonov least squares are L2(μ) approximators of ergodic dynamical systems},
journal = {Physica D: Nonlinear Phenomena},
volume = {421},
pages = {132882},
year = {2021},
issn = {0167-2789},
doi = {https://doi.org/10.1016/j.physd.2021.132882},
url = {https://www.sciencedirect.com/science/article/pii/S0167278921000403},
author = {Allen G. Hart and James L. Hook and Jonathan H.P. Dawes},
keywords = {Reservoir computing, Liquid state machine, Time series analysis, Lorenz equations, Delay embedding, Recurrent neural networks},
abstract = {Echo State Networks (ESNs) are a class of single-layer recurrent neural networks with randomly generated internal weights, and a single layer of tuneable outer weights, which are usually trained by regularised linear least squares regression. Remarkably, ESNs still enjoy the universal approximation property despite the training procedure being entirely linear. In this paper, we prove that an ESN trained on a sequence of observations from an ergodic dynamical system (with invariant measure μ) using Tikhonov least squares regression against a set of targets, will approximate the target function in the L2(μ) norm. In the special case that the targets are future observations, the ESN is learning the next step map, which allows time series forecasting. We demonstrate the theory numerically by training an ESN using Tikhonov least squares on a sequence of scalar observations of the Lorenz system.}
}
@article{MUNAWAR2022151351,
title = {Disruptive technologies as a solution for disaster risk management: A review},
journal = {Science of The Total Environment},
volume = {806},
pages = {151351},
year = {2022},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2021.151351},
url = {https://www.sciencedirect.com/science/article/pii/S0048969721064299},
author = {Hafiz Suliman Munawar and Mohammad Mojtahedi and Ahmed W.A. Hammad and Abbas Kouzani and M.A. Parvez Mahmud},
keywords = {Disaster management, Smart cities, Wireless communication, Cloud computing, Internet of Things, Big data},
abstract = {Integrating disruptive technologies within smart cities improves the infrastructure needed to potentially deal with disasters. This paper provides a perspective review of disruptive technologies such as the Internet of Things (IoT), image processing, artificial intelligence (AI), big data and smartphone applications which are in use and have been proposed for future improvements in disaster management of urban regions. The key focus of this paper is exploring ways in which smart cities could be established to harness the potential of disruptive technologies and improve post-disaster management. The key questions explored are a) what are the gaps or barriers to the utilization of disruptive technologies in the area of disaster management and b) How can the existing methods of disaster management be improved through the application of disruptive technologies. To respond to these questions, a novel framework based on integrated approaches based on big data analytics and AI is proposed for developing disaster management solutions using disruptive technologies.}
}
@article{ZAKI201741,
title = {Learning a deeply supervised multi-modal RGB-D embedding for semantic scene and object category recognition},
journal = {Robotics and Autonomous Systems},
volume = {92},
pages = {41-52},
year = {2017},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2017.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0921889016304225},
author = {Hasan F.M. Zaki and Faisal Shafait and Ajmal Mian},
keywords = {RGB-D image, Visual place recognition, Object categorization, Multi-modal deep learning},
abstract = {Recognizing semantic category of objects and scenes captured using vision-based sensors is a challenging yet essential capability for mobile robots and UAVs to perform high-level tasks such as long-term autonomous navigation. However, extracting discriminative features from multi-modal inputs, such as RGB-D images, in a unified manner is non-trivial given the heterogeneous nature of the modalities. We propose a deep network which seeks to construct a joint and shared multi-modal representation through bilinearly combining the convolutional neural network (CNN) streams of the RGB and depth channels. This technique motivates bilateral transfer learning between the modalities by taking the outer product of each feature extractor output. Furthermore, we devise a technique for multi-scale feature abstraction using deeply supervised branches which are connected to all convolutional layers of the multi-stream CNN. We show that end-to-end learning of the network is feasible even with a limited amount of training data and the trained network generalizes across different datasets and applications. Experimental evaluations on benchmark RGB-D object and scene categorization datasets show that the proposed technique consistently outperforms state-of-the-art algorithms.}
}
@article{HU2021103398,
title = {A method for measuring ice thickness of wind turbine blades based on edge detection},
journal = {Cold Regions Science and Technology},
volume = {192},
pages = {103398},
year = {2021},
issn = {0165-232X},
doi = {https://doi.org/10.1016/j.coldregions.2021.103398},
url = {https://www.sciencedirect.com/science/article/pii/S0165232X21001798},
author = {Qin Hu and Xing Xu and Dongbing Leng and Lichun Shu and Xingliang Jiang and Muhammad Virk and Pancheng Yin},
keywords = {Wind turbine blades, Ice thickness, Defogging, Multi-scale wavelet edge detection},
abstract = {In recent years, with the successive development of mountain wind power resources in the high humidity regions, the problem of ice covering on wind turbine blades has become increasingly prominent. Wind turbine blade icing will affect blade aerodynamic performance and reduce power generation. In this paper, a method for measuring the ice thickness of wind turbine blades based on edge detection was proposed. As the icing images of blades have characteristics like low contrast, unclearness and blurred edges, the images were preprocessed by methods like defogging, gray-scale transformation, histogram correction, Gaussian filtering, and Laplace edge enhancement. Aiming at the characteristics of wind turbine icing images with many noises and many small edges, a multiscale wavelet edge detection algorithm was used to detect the blade icing images. Based on the pixel coordinates of the ice edge and the edge of the blade, through the pre-calibration, a method for calculating the ice thickness of the leading edge of the blade based on the pixel coordinate difference /real length ratio was proposed. Multiple measurement tests were performed in the natural icing environment. The average ice thickness measurement error value of short distance (0.5 m)/long distance (35 m) is 0.31 mm/8.9 mm, and the average ice thickness measurement error rate is 2.62% /6.0%.}
}
@article{SUN2020105942,
title = {A gradient boosting decision tree based GPS signal reception classification algorithm},
journal = {Applied Soft Computing},
volume = {86},
pages = {105942},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2019.105942},
url = {https://www.sciencedirect.com/science/article/pii/S1568494619307239},
author = {Rui Sun and Guanyu Wang and Wenyu Zhang and Li-Ta Hsu and Washington Y. Ochieng},
keywords = {GPS, GBDT, Urban canyon, Multipath, NLOS},
abstract = {In urban areas, GPS signals are often reflected or blocked by buildings, which causes multipath effects and non-line-of-sight (NLOS) reception respectively consequently degrading GPS positioning performance. While improved receiver design can reduce the effect of multipath to some extent, it cannot deal with NLOS. Modelling methods based on measurements have shown promise to reduce the effect of NLOS signal reception. However, this depends on their ability to accurately and reliably classify line-of-sight (LOS), multipath and NLOS signals. The traditional method is based on one feature using signal strength as measured by the carrier to noise ratio, C/N0. However, this feature is ineffective in capturing the characteristics of multipath and NLOS in all environments. In this paper, to improve the accuracy of signal reception classification, we are using the three features of C/N0, pseudorange residuals and satellite elevation angle with a gradient boosting decision tree (GBDT) based classification algorithm. Experiments are carried out to compare the proposed algorithm with classifiers based on decision tree, distance weighted k-nearest neighbour (KNN) and the adaptive network-based fuzzy inference system (ANFIS). Test results from static receivers in urban environments, show that the GBDT based algorithm achieves a classification accuracy of 100%, 82% and 86% for LOS, multipath and NLOS signals, respectively. This is superior to the other three algorithms with the corresponding results of 100%, 82% and 84% for the Distance-Weighted KNN, 99%, 70% and 65% for the ANFIS and 98%, 35% and 95% for the traditional decision tree. With the NLOS detection and exclusion, the proposed GBDT with multi-feature based method can provide a positioning accuracy improvement of 34.1% compared to the traditional C/N0 based method.}
}
@article{LIU202180,
title = {Multi-object tracking with hard-soft attention network and group-based cost minimization},
journal = {Neurocomputing},
volume = {447},
pages = {80-91},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.02.084},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221003416},
author = {Yating Liu and Xuesong Li and Tianxiang Bai and Kunfeng Wang and Fei-Yue Wang},
keywords = {Multi-object tracking, Attention mechanism, Unary and binary costs, Appearance-motion affinity},
abstract = {Multi-object tracking (MOT) has received constant attention from researchers with the development of deep learning and person re-identification (ReID). However, the occlusion caused tracking failure is still far from solved. In this paper, we propose a Hard-Soft Attention Network (HSAN) to improve the ReID performance and get robust appearance features of different targets. The pose information and attention mechanism are combined to distinguish between challenging targets. Besides, the unary and binary costs are constructed to ensure consistency and long-term tracking, which consider not only the appearance-motion affinity of single tracks, but also the interactions between neighboring tracks. For that we cluster the tracks into different groups and choose reliable tracks as anchors to establish the two types of costs. Our HSAN appearance model is evaluated on the Market-1501, DUKE and CUHK03 ReID datasets and the MOT tracking method is conducted on MOTChallenge 15, 16 and 17. The experimental results demonstrate that our method can improve tracking accuracy and reduce fragments.}
}
@article{COSTA2020105334,
title = {A new visible band index (vNDVI) for estimating NDVI values on RGB images utilizing genetic algorithms},
journal = {Computers and Electronics in Agriculture},
volume = {172},
pages = {105334},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105334},
url = {https://www.sciencedirect.com/science/article/pii/S016816991932383X},
author = {Lucas Costa and Leon Nunes and Yiannis Ampatzidis},
keywords = {Genetic algorithm, Big data, NDVI, Vegetation index, RGB, Multispectral, Hyperspectral},
abstract = {Several vegetation indices have been developed, with the normalized difference vegetation index (NDVI) been the most studied and commonly used. To generate an NDVI map, a relatively high-cost multispectral sensor is required; but currently, most UAVs are equipped with low-cost RGB cameras. For that reason, other indices that utilize RGB data have been developed to generate maps similar to NDVI and minimize the data acquisition cost, such as the triangular greenness index (TGI) and the visible atmospheric resistant index (VARI). However, several studies found that these indices cannot be recommended as reliable general-purpose crop health indicators. This study utilizes a genetic algorithm to develop a new visible index (visible NDVI; vNDVI) that estimates NDVI values of vegetation from uncalibrated RGB cameras mounted on UAVs (or other remote sensing platforms). Three experiments were conducted to create and validate the proposed index. First, the NDVI values generated from a multispectral camera were compared with the NDVI values generated by a hyperspectral camera. In the second experiment, the vNDVI formula was created using a genetic algorithm. The third experiment validates the proposed vNDVI, generated from two uncalibrated RGB cameras, in three different crops (citrus, grapes, and sugarcane). The proposed vNDVI proved to be highly accurate on estimating NDVI values by just using RGB cameras, with an overall mean percentage error of 6.89% and a mean average error of 0.052 in all three crops, providing a low-cost alternative for remote sensing and plant phenotyping.}
}
@article{ANDRIEVSKY2013270,
title = {Rainbow Runner glider as a testbed for robust and adaptive control methods*},
journal = {IFAC Proceedings Volumes},
volume = {46},
number = {30},
pages = {270-275},
year = {2013},
note = {2nd IFAC Workshop on Research, Education and Development of Unmanned Aerial Systems},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20131120-3-FR-4045.00029},
url = {https://www.sciencedirect.com/science/article/pii/S1474667015403052},
author = {Boris Andrievsky and Alexander L. Fradkov and Kirill Kravchuk},
keywords = {aerospace, adaptive control design, robust control, testbed, small UAV},
abstract = {In the paper the dynamics of the UAV glider Rainbow Runner are described and the research plan of using the glider as a testbed for robust and adaptive control methods is outlined.}
}
@article{TAN2021159,
title = {A Survey Of zero shot detection: Methods and applications},
journal = {Cognitive Robotics},
volume = {1},
pages = {159-167},
year = {2021},
issn = {2667-2413},
doi = {https://doi.org/10.1016/j.cogr.2021.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S2667241321000124},
author = {Chufeng Tan and Xing Xu and Fumin Shen},
keywords = {Deep learning, Zero shot learning, Zero shot detection},
abstract = {Zero shot learning (ZSL) is aim to identify objects whose label is unavailable during training. This learning paradigm makes classifier has the ability to distinguish unseen class. The traditional ZSL method only focuses on the image recognition problems that the objects only appear in the central part of images. But real-world applications are far from ideal, which images can contain various objects. Zero shot detection (ZSD) is proposed to simultaneously localizing and recognizing unseen objects belongs to novel categories. We propose a detailed survey about zero shot detection in this paper. First, we summarize the background of zero shot detection and give the definition of zero shot detection. Second, based on the combination of traditional detection framework and zero shot learning methods, we categorize existing zero shot detection methods into two different classes, and the representative methods under each category are introduced. Third, we discuss some possible application scenario of zero shot detection and we propose some future research directions of zero-shot detection.}
}
@article{LU2021232,
title = {A mixture varying-gain dynamic learning network for solving nonlinear and nonconvex constrained optimization problems},
journal = {Neurocomputing},
volume = {456},
pages = {232-242},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.05.037},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221007906},
author = {Rongxiu Lu and Guanhua Qiu and Zhijun Zhang and Xianzhi Deng and Hui Yang and Zhenmin Zhu and Jianyong Zhu},
keywords = {Recurrent neural networks, Nonlinear and nonconvex optimization, Inequality constraints},
abstract = {Nonlinear and nonconvex optimization problem (NNOP) is a challenging problem in control theory and applications. In this paper, a novel mixture varying-gain dynamic learning network (MVG-DLN) is proposed to solve NNOP with inequality constraints. To do so, first, this NNOP is transformed into some equations through Karush–Kuhn–Tucker (KKT) conditions and projection theorem, and the neuro-dynamics function can be obtained. Second, the time varying convergence parameter is utilized to obtain a faster convergence speed. Third, an integral term is used to strengthen the robustness. Theoretical analysis proves that the proposed MVG-DLN has global convergence and good robustness. Three numerical simulation comparisons between FT-FP-CDNN and MVG-DLN substantiate the faster convergence performance and greater robustness of the MVG-DLN in solving the nonlinear and nonconvex optimization problems.}
}
@article{BATTULWAR2021920,
title = {A state-of-the-art review of automated extraction of rock mass discontinuity characteristics using three-dimensional surface models},
journal = {Journal of Rock Mechanics and Geotechnical Engineering},
volume = {13},
number = {4},
pages = {920-936},
year = {2021},
issn = {1674-7755},
doi = {https://doi.org/10.1016/j.jrmge.2021.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1674775521000287},
author = {Rushikesh Battulwar and Masoud Zare-Naghadehi and Ebrahim Emami and Javad Sattarvand},
keywords = {Rock mass, Discontinuity characterization, Automatic extraction, Three-dimensional (3D) point cloud},
abstract = {In the last two decades, significant research has been conducted in the field of automated extraction of rock mass discontinuity characteristics from three-dimensional (3D) models. This provides several methodologies for acquiring discontinuity measurements from 3D models, such as point clouds generated using laser scanning or photogrammetry. However, even with numerous automated and semi-automated methods presented in the literature, there is not one single method that can automatically characterize discontinuities accurately in a minimum of time. In this paper, we critically review all the existing methods proposed in the literature for the extraction of discontinuity characteristics such as joint sets and orientations, persistence, joint spacing, roughness and block size using point clouds, digital elevation maps, or meshes. As a result of this review, we identify the strengths and drawbacks of each method used for extracting those characteristics. We found that the approaches based on voxels and region growing are superior in extracting joint planes from 3D point clouds. Normal tensor voting with trace growth algorithm is a robust method for measuring joint trace length from 3D meshes. Spacing is estimated by calculating the perpendicular distance between joint planes. Several independent roughness indices are presented to quantify roughness from 3D surface models, but there is a need to incorporate these indices into automated methodologies. There is a lack of efficient algorithms for direct computation of block size from 3D rock mass surface models.}
}
@article{WEI2021198,
title = {Large-scale rice mapping under different years based on time-series Sentinel-1 images using deep semantic segmentation model},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {174},
pages = {198-214},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.02.011},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621000502},
author = {Pengliang Wei and Dengfeng Chai and Tao Lin and Chao Tang and Meiqi Du and Jingfeng Huang},
keywords = {Sentinel-1 images, Multi-temporal, Rice mapping, Large-scale, Deep semantic segmentation},
abstract = {Identifying spatial distribution of crop planting in large-scale is one of the most significant applications of remote sensing imagery. As an active remote sensing system, synthetic aperture radar (SAR) provides high-resolution polarimetric information of land covers. Nowadays, it is possible to carry out continuous multi-temporal analysis of crops in large-scales since an increased number of spaceborne SAR systems has been launched. This paper formulates rice mapping as a semantic segmentation problem and proposes to use deep learning techniques to exploit the phenological similarity of rice production to identify the rice distribution in large-scales. The study area (i.e., about 58504 km2) located in Arkansas River Basin is selected to develop an adapted U-Net for large-scale rice mapping. The Sentinel-1 data in previous years (i.e., data collected in 2017 and 2018) are used to train and fine-tune the network, and current season data (i.e., data collected in 2019) is selected to test the robustness of the network. Experimental results show that the proposed method achieves the state-of-the-art performance as it benefits from the spatial characteristics and phenological similarity of rice. The experiments of rice extraction in different planting pattern regions and extracted features visual projection are conducted to explain the features mined by the adapted U-Net. Furthermore, the advantages of temporal generalization in large-scale are validated by the comparison between space migration and time migration, which indicates that the difference of rice in different years is smaller than that of rice in different spaces. Finally, the issues for operational implementation are discussed.}
}
@article{AN201799,
title = {Three dimensional memristor-based neuromorphic computing system and its application to cloud robotics},
journal = {Computers & Electrical Engineering},
volume = {63},
pages = {99-113},
year = {2017},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2017.06.023},
url = {https://www.sciencedirect.com/science/article/pii/S0045790617318475},
author = {Hongyu An and Jialing Li and Ying Li and Xin Fu and Yang Yi},
keywords = {Cloud robotics, Neuromorphic computing, Cognitive computing, Vertical RRAM structure, Memristor, Monolithic 3D-IC},
abstract = {Neuromorphic computing based on three-dimensional inetgraed circuits (3D-NCs) offers a novel hardware implementation of neuromorphic computing, and provides high device density, massively parallel signal processing capability, low power consumption, and direct analog signal processing capability. In this paper, by replacing conventional CPUs based on Von Neumann architecture with 3D-NCs, a novel neuromorphic computing based cloud robotics (NC-robotics) system is proposed, which is constructed by 1) cloud server center using 3D-NCs as computing units, 2) neuromorphic robotics based on neural network control technology. Besides the benefits of normal Cloud Robotics platform, this NC- Robotics system has more advantages on massive parallel-computing, analog signals processing, and lower power consumption. In order to implement this NC––Robotics system, a novel 3D-NCs architecture combining vertical RRAM structure is investigated and its concise equivalent circuit model is created, evaluated, and analyzed through SPICE simulations.}
}
@article{ZHANG2021677,
title = {Collaborative algorithms that combine AI with IoT towards monitoring and control system},
journal = {Future Generation Computer Systems},
volume = {125},
pages = {677-686},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21002697},
author = {Tao Zhang and Yan Zhao and Wenjing Jia and Mu-Yen Chen},
keywords = {Collaborative Algorithm, Artificial Intelligence of Things (AIoT), Crowd counting, Monitoring and control system},
abstract = {Recently, a new IoT structure known as the Artificial Intelligence of Things (AIoT) comes into play. Crowd counting is a promising field in data analysis of AIoT, however, due to poor transparency and high data security risks, developing a novel network architecture that can precisely elevate the counting of heavy crowd is extremely difficult. In addition, the fusion of IoT and AI also poses several challenges. The focus of this work is on the effective design of IoT framework and deep learning algorithm towards security of smart city. The system can be used to estimate the crowd traffic in public places, and can prevent the occurrence of congestion, stampede and other accidents, such as stations, airports, large-scale exhibitions, tourist attractions and other places. The constructed system contains video collection, upload and display as well as data analysis and early warning operation at the embedded device end, and automatically tracks densely crowd areas by controlling the video monitoring device. Moreover, the cloud platform can be controlled through the network. Our proposed algorithms are composed of two main aspects, i.e., division and focus. Firstly, we propose a novel density-adaptive Gaussian kernel to elevate the quality of density maps. Then, we propose a module based on conditional random fields for feature fusion. Finally, we propose a block segmentation module to predict our segmentation results and extract the context-aware information in segmentation stage. Experiments on our captured data, the Shanghai Tech, UCF_CC_50 and UCF_QNRF datasets demonstrate that our solution has obtained better performance and lower count errors over the state of the art.}
}
@article{RAHIM2020142,
title = {An efficient caching policy for content retrieval in autonomous connected vehicles},
journal = {Transportation Research Part A: Policy and Practice},
volume = {140},
pages = {142-152},
year = {2020},
issn = {0965-8564},
doi = {https://doi.org/10.1016/j.tra.2020.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0965856420306893},
author = {Muddasir Rahim and Muhammad Awais Javed and Ahmad Naseem Alvi and Muhammad Imran},
keywords = {Connected vehicles, Caching, Content retrieval},
abstract = {Connected vehicles will enable the smart and autonomous transportation systems in the future. Cellular Vehicle-to-Everything (C-V2X) communication will provide wireless connectivity to enable large number of connected vehicle applications. Vehicles will receive traffic and infotainment contents from the city traffic command center using C-V2X communications. In this context, infrastructure Road Side Units (RSUs) will cache urgent and popular data in their memory storage, hence providing vehicles to retrieve information from a closer vicinity at a RSU. In this paper, we present a content caching policy for the connected vehicles operator to improve the efficiency of the content retrieval in terms of download rate and delay. We propose the utility functions for the RSUs and vehicles to cache a particular content at a given RSU. Moreover, Gale-Shapley stable matching algorithm is used to efficiently allocate RSU cache to the contents. We also provide rules to update the cache slots. The proposed caching scheme is compared with random caching policy and market matching based caching policies. Results show that the proposed content caching policy improves the efficiency of the content retrieval with 60% more data transmission with reduced downloading time and better link utilization as compared to other two scheme.}
}
@article{SAMANTA2020315,
title = {Learning elastic memory online for fast time series forecasting},
journal = {Neurocomputing},
volume = {390},
pages = {315-326},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.07.105},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219314511},
author = {Subhrajit Samanta and Mahardhika Pratama and Suresh Sundaram and Narasimalu Srikanth},
keywords = {Time series forecasting, Temporality determination, Past dependency in time series forecasting, Temporal neural network, Online learning, Drift detection, Elastic memory, Adaptive temporal network},
abstract = {It is well known that any kind of time series algorithm requires past information to model the inherent temporal relationship between past and future. This temporal dependency (i.e. number of past samples required for a good prediction) is generally addressed by feeding a number of past instances to the model in an empirical manner. Conventional approaches mostly rely on offline model, making them impractical to be adopted in the online or streaming context. Hence, a novel method of online temporality analysis is proposed in this paper. The estimated temporality is then employed to form an Adaptive Temporal Neural Network (ATNN) with an elastic memory capable of automatically selecting number of past samples to be used. Temporality change or drift can be a common occurrence in data streams. Hence a drift detection mechanism is also proposed. Once such drift is detected, a drift handling mechanism kicks in which utilizes the rate of drift, making our solution truly autonomous. The entire mechanism is termed as LEMON: Learning Elastic Memory Online. LEMON although not a time series model in itself, can work with any predictive models to improve their performance. Synthetic datasets are used here as proof of correct temporality estimation and drift detection whereas real world datasets are employed to demonstrate how LEMON improves the predictive performance and speed of an existing model with the knowledge of temporality and drift.}
}
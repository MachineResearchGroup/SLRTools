@article{ISLAM201911,
title = {Real-time frequency regulation using aggregated electric vehicles in smart grid},
journal = {Computers & Industrial Engineering},
volume = {134},
pages = {11-26},
year = {2019},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2019.05.025},
url = {https://www.sciencedirect.com/science/article/pii/S036083521930292X},
author = {Md. Monirul Islam and Xiao Zhong and Zeyi Sun and Haoyi Xiong and Wenqing Hu},
keywords = {Electric vehicle, Frequency regulation, Real-time, Smart grid},
abstract = {The electric vehicle (EV) market has witnessed a continuous and steady increase in the past few years. The benefits of lower energy costs and less greenhouse gas (GHG) emission have been widely recognized by customers. In addition to these benefits for the transportation sector, EVs are also considered a critical supplementary resource for building a sustainable energy system in a smart grid environment. The applications of EVs in a smart grid have attracted wide attention in recent years. One appealing application is to use aggregated EVs as either energy sources or sinks to provide a service of frequency regulation for the request signals from the grid. A real-time decision-making model is proposed in this paper for the EV aggregator to dynamically control the energy flow between the grid and each individual EV in the aggregated group as an effective response to the signals of frequency regulation issued by the grid using Markov Decision Process. The aggregator’s benefit is maximized through the identification of a set of optimal charging/discharging decisions for the aggregated EVs. A semi-online solution strategy is also proposed to find the near-optimal decisions on a real-time basis. A numerical case study is used to illustrate the effectiveness of the proposed model.}
}
@article{LI202013,
title = {“Green” effects of hybrid actors through carbon trading: Cases in Beijing},
journal = {Global Transitions Proceedings},
volume = {1},
number = {1},
pages = {13-22},
year = {2020},
issn = {2666-285X},
doi = {https://doi.org/10.1016/j.gltp.2020.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666285X20300017},
author = {Li Li},
keywords = {Voluntary climate governance, Public-private partnership (PPP), Carbon trading, hybrid actors, Beijing},
abstract = {The global climate change is resetting the regime complex and mindsets of countries and cities. To provide global public goods of climate governance, multilevel, multidisciplinary, public and private actors interact through “trial-and-error” experiments. Local institutions and mechanisms are likely to be innovated during such interactions. Carbon trading mechanism has been a key unlocking China's low-carbon practices, placing “caps” to pilot cities like Beijing. The first Clean Development Mechanism (CDM) project of China started at Anding Landfill Plant in Daxing District, which was the miniature for provincial CDM Centers in China. Since 2011, Beijing was chosen as a pilot city to carry out cap-and-trade mechanism to mitigate carbon emission. In 2013, China Beijing Environment Exchange (CBEEX) was established, enabling more diverse carbon trading projects to be carried out. After the Paris Agreement was reached in 2015, more stringent emission cap was imposed. On the basis of CDM experiences, the 2008 Beijing Olympic Games provided various industries to fulfill their “Green” corporate social responsibilities. Challenged by the international questioning about the wind power projects and carbon footprint tagging criteria, domestic voluntary carbon market standard, “Panda Standard” was given birth to; and the independent intellectual property right of electricity-saving refrigerant was invented. Public and private actors became an integral part of China's Innovation-driven and Sustainable Development Strategies. Public-private partnerships (PPPs) derive into hybrid networks with local voluntariness. This paper focuses on the stages reflecting the development of “voluntary hybridity”, by analyzing several cases in representative industries in Beijing.}
}
@article{GUAN201699,
title = {Energy planning of university campus building complex: Energy usage and coincidental analysis of individual buildings with a case study},
journal = {Energy and Buildings},
volume = {124},
pages = {99-111},
year = {2016},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2016.04.051},
url = {https://www.sciencedirect.com/science/article/pii/S0378778816303164},
author = {Jun Guan and Natasa Nord and Shuqin Chen},
keywords = {University campus, Building complex, Energy use, Coincidence factor, Energy plan, Case study},
abstract = {As the demonstration of eco-communities, energy planning becomes more and more important for university campus. However, insufficient energy use data accumulation has been a significant barrier against fully understanding of energy use characteristics, and demand load features of campus buildings, which usually provide the basic support for energy planning from the demand side. A methodology to reveal the features of demand load and energy use of campus building was developed for this purpose. As a case study, both the long-term and real-time data of the electricity, heating, and water usage of a Norwegian university campus were analyzed by the descriptive statistics. On this base, coincidence characteristics of energy and water usage of the entire campus were analyzed, and individual coincidental rates to the campus were also quantified accordingly. The coincidence factors were calculated to be at high levels, which implied that the campus buildings’ usage of energy was quite similar to that of water. Finally, the individual coincidental contribution to total campus energy use was analyzed by the cluster analysis, to identify those buildings with the large potential of operation optimization. The results from this study could be used for the energy planning of cities and other urban energy systems.}
}
@article{DIFRANCO201572,
title = {Current situation and needs in man-made and natech risks management using Earth Observation techniques},
journal = {Remote Sensing Applications: Society and Environment},
volume = {1},
pages = {72-84},
year = {2015},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2015.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S2352938515000075},
author = {Sabina {Di Franco} and Rosamaria Salvatori},
keywords = {Natech, Man-made hazards, Industrial accident, Risk management, Preparedness, Emergency, Recovery, Small satellite, UAV},
abstract = {The Earth Observation (EO) techniques are becoming increasingly important in risk management activities not only for natural hazards and natural disaster monitoring but also to ride out industrial and natech accidents. The latest developments in the aerospace industry such as sensors miniaturization and high spatial and temporal resolution missions, devoted to monitoring areas of specific interest, have made the use of EO techniques more efficiently and are vready to be used in near real time conditions. This paper summarize the current state of knowledge on how EO data can be useful in managing all the phases of the Industrial/natech disaster, and from the environmental conditions before the accident strikes to the post accident relief, from the scenario setting and planning stage to the damage assessment.}
}
@article{PATEL2021103092,
title = {Impact assessment of distributed generations with electric vehicles planning: A review},
journal = {Journal of Energy Storage},
volume = {43},
pages = {103092},
year = {2021},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2021.103092},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X21007970},
author = {Dilip Kumar Patel and Deependra Singh and Bindeshwar Singh},
keywords = {Distributed Generations, Distribution Systems, Electric Vehicles, Optimization Techniques, Sizing, Types, Location, Load Models},
abstract = {Distributed Generations (DGs) with Electric Vehicles (EVs) now play a key role in the planning of power distribution systems. The integration of DGs with EVs planning in the power distribution system is becoming increasingly significant in recent years. This paper presents a review of different optimization techniques for DGs, EVs, and DGs with EVs planning in distribution systems with different load models. The optimization techniques are broadly classified into five categories such as conventional, optimization, artificial intelligence, hybrid, and recent optimization techniques for planning. The different system performances are considered for planning with different goal function viewpoints such as minimization of real and reactive power losses of the system. This review paper also provides an overview of the state-of-the-art models and methods applicable to the DGs with EVs planning, analyzing, and classifying existing and future research trends in this field. Authors strongly believe that this review article would be very useful for researchers, industrial persons, academicians, and scientific persons for finding out the relevant references in the same field.}
}
@article{RUBIO2013551,
title = {Adaptive non-parametric identification of dense areas using cell phone records for urban analysis},
journal = {Engineering Applications of Artificial Intelligence},
volume = {26},
number = {1},
pages = {551-563},
year = {2013},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2012.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0952197612001017},
author = {Alberto Rubio and Angel Sanchez and Enrique Frias-Martinez},
keywords = {Urban analysis, Urban dynamics, CDR, Dense areas, Clustering},
abstract = {Pervasive large-scale infrastructures (like GPS, WLAN networks or cell-phone networks) generate large datasets containing human behavior information. One of the applications that can benefit from this data is the study of urban environments. In this context, one of the main problems is the detection of dense areas, i.e., areas with a high density of individuals within a specific geographical region and time period. Nevertheless, the techniques used so far face an important limitation: the definition of dense area is not adaptive and as a result the areas identified are related to a threshold applied over the density of individuals, which usually implies that dense areas are mainly identified in downtowns. In this paper, we propose a novel technique, called AdaptiveDAD, to detect dense areas that adaptively define the concept of density using the infrastructure provided by a cell phone network. We evaluate and validate our approach with a real dataset containing the Call Detail Records (CDR) of fifteen million individuals.}
}
@article{RAUXDEFOSSEZ2018209,
title = {Grid Services Provided By The Interactions Of Energy Sectors In Multi-Energy Systems: Three International Case Studies},
journal = {Energy Procedia},
volume = {155},
pages = {209-227},
year = {2018},
note = {12th International Renewable Energy Storage Conference, IRES 2018, 13-15 March 2018, Düsseldorf, Germany},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2018.11.055},
url = {https://www.sciencedirect.com/science/article/pii/S1876610218310099},
author = {Pauline Raux-Defossez and Nadja Wegerer and Diane Pétillon and Agnes Bialecki and Aimee Gotway Bailey and Régine Belhomme},
keywords = {Multi-energy systems, grid services, electricity, heat, gas, interactions},
abstract = {Solutions towards the development of a low carbon energy system have until recently largely focussed on the electricity sector. However, interactions between energy vectors (e.g. heat, electricity and gas) may contribute to increase the penetration of renewable energies, lower CO2 emissions, and improve energy efficiency by offering, amongst others, additional grid flexibility resources. Multi-energy systems that use synergies between energy vectors are thus gaining in relevance and attention. They rely on the existence of technologies interfacing the energy systems (e.g. CHP plants) and on the regulatory framework, the market design and more generally the organization of the energy system as a whole. Flexibility generated by the synergies may especially provide services by contributing to ensure the offer-demand balance at any time, as well as grid security and stability. Based on a comparison of case studies in UK, Germany and US/California, the paper analyses services provided to the electricity grid by multi-energy systems and examines how involved parties share roles and responsibilities. The analysis is conducted in the light of the regulatory framework in the above-mentioned countries that strongly influences the development of potential services. Identified services are associated to the corresponding market and service layers (e.g. energy, balancing or even capacity) in which they are providing flexibility. The paper relies on a methodology previously developed to analyse and characterize existing and potential future market designs for the electricity system taking into account the specificities met in different countries. The aim of this methodology is to build an integrated and coherent vision of the different roles, functions and interactions within the system. The methodology has been further developed and applied to multi-energy systems. The analysis contributes to a whole-system perspective of flexibility services for electricity systems and underlying market structures.}
}
@article{BONNAH2020363,
title = {DecChain: A decentralized security approach in Edge Computing based on Blockchain},
journal = {Future Generation Computer Systems},
volume = {113},
pages = {363-379},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19323933},
author = {Ernest Bonnah and Ju Shiguang},
keywords = {Blockchain, Edge computing, Security, Scalability, Authentication, Decentralized},
abstract = {Security in edge computing paradigms has become a major concern in recent times due to the integral role it plays in the framework of edge computing. Privacy-preserving and data security challenges are among the many concerns impeding the goal of making data storage available and processing at the edge of the network quite difficult to implement. Authenticated users must be the only ones with access to their respective stored data which are protected against any form of intruder manipulation. Most authentication schemes proposed and implemented in edge computing and other paradigms use a trusted entity to initialize the authentication process between edge servers and prospective users. Servers and users are expected to register with the trusted party first before they are able to subsequently authenticate one another. The presence of the trusted party presents scalability issues as well as the threat of having a single point of failure which may threaten the availability of the entire network. In this paper, we present a fully decentralized approach to solving this problem by eliminating the public trusted entity within the network framework termed DecChain. In DecChain we employ some notable principles of permissioned blockchain technology in the rollout and authentication of elements within the network. Authenticated users within our proposed framework would not have to sign in to every service provider to be authenticated to access a service or resource. Security experiments and the deployment of our scheme are carried out to evaluate the performance of DecChain. The results show our scheme is secured and achieves the intended purpose efficiently.}
}
@article{HASAN2021104,
title = {Search and rescue operation in flooded areas: A survey on emerging sensor networking-enabled IoT-oriented technologies and applications},
journal = {Cognitive Systems Research},
volume = {67},
pages = {104-123},
year = {2021},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2020.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S1389041720301145},
author = {Md. Munirul Hasan and Md. Arafatur Rahman and Arya Sedigh and Ana U. Khasanah and A. {Taufiq Asyhari} and Hai Tao and Suraya Abu Bakar},
keywords = {Communication protocols, Disaster mitigation, Flood, Cognitive ICT for disasters, Internet of things, IoT, SAR, Search and rescue, Sensor networks, WSN},
abstract = {The climate and weather dynamics in the past few years has driven a massive increase in the number and intensity of flood disasters, which severely claim casualties in human, goods and properties. Aimed to reduce these casualties, emerging software-defined internet protocol-based communication technologies in the form of Internet of Things (IoT) have attracted strong interests from disaster mitigation stakeholders to rapidly locate victims and acquire their relevant information, which in turn can boost up the efficiency and effectiveness of Search and Rescue (SAR) missions. In order to capture state-of-the-art development and technological challenges, this paper presents an extensive review on the flood SAR systems, highlighting some of the key emerging IoT technologies that prove or are potentially useful in improving the SAR operation by the rescuers. Furthermore, a comprehensive study on different existing communication technologies for SAR is provided, covering the system architecture, communication network compositions and applications. Based on the critical analysis of existing works, this paper puts forward a proposal on an IoT-aided integrated flood management framework to support SAR in the flood-catchment areas, leveraging upon three-domain (ground, water and air) collaborative wireless networks.}
}
@article{BECKER20182173,
title = {ANP-based analysis of ICT usage in Central European enterprises},
journal = {Procedia Computer Science},
volume = {126},
pages = {2173-2183},
year = {2018},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 22nd International Conference, KES-2018, Belgrade, Serbia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.07.231},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918312067},
author = {Jarosław Becker and Aneta Becker and Piotr Sulikowski and Tomasz Zdziebko},
keywords = {Information, Communication Technologies (ICT), Multiple-Criteria Decision-Making (MCDM), Analytic Network Process (ANP), Cluster Analysis (k-means method)},
abstract = {The purpose of this paper is to perform a multi-criteria evaluation of selected European Union member states in Central Europe with regard to the use of information and communication technologies (ICT) in enterprises in 2017. The analytic network process (ANP) methodology and k-means clustering were used. Basing on data obtained from Eurostat, ICT attributes were selected and the network of criteria was built. The preferences for main criteria were extracted from empirical data for each analyzed country (each decision variant). The obtained priority values reflected strengths of the analyzed regions. The preferences for sub-criteria were determined basing on that the criteria describing the newest fields of ICT development (e-commerce and e-business in general) are considered most important. With regard to that, the multi-criteria analysis showed that Slovenia and Austria were leaders in Central Europe in 2017, and the worst-performing country was Poland, preceded by Hungary. The results of the study can be used to generalize about the level of ICT development of each country.}
}
@article{NGUYEN2020133,
title = {A smartphone perspective on computation offloading—A survey},
journal = {Computer Communications},
volume = {159},
pages = {133-154},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419319401},
author = {Quang-Huy Nguyen and Falko Dressler},
keywords = {Computation offloading, Mobile edge computing, Smartphones, Energy consumption},
abstract = {Computation offloading has emerged as one of the promising approaches to address the issues of restricted resources, leading to poor user experiences on smartphones in terms of battery life and performance when executing CPU intensive tasks. Meanwhile, an entire research domain has been initiated around this topic and several concepts have been studied touching both the smartphone and the cloud side. In this paper, we develop a categorization of fundamental aspects regarding computation offloading in heterogeneous cloud computing from the perspective of smartphone applications. We refer to heterogeneity in terms of the multitude of smartphone applications, the various uplink channels, and the variety of cloud solutions. We also survey state-of-the-art solutions for the identified categories. Finally, we conclude with a summary of the most important research challenges in making computation offloading reality.}
}
@article{MOTLAGH201911,
title = {Clustering of residential electricity customers using load time series},
journal = {Applied Energy},
volume = {237},
pages = {11-24},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2018.12.063},
url = {https://www.sciencedirect.com/science/article/pii/S0306261918318816},
author = {Omid Motlagh and Adam Berry and Lachlan O'Neil},
keywords = {Electricity consumption, Time series clustering, Unequal time series, Load profile},
abstract = {Clustering of electricity customers supports effective market segmentation and management. The literature suggests the clustering of residential customers by their load characteristics. The key challenge is the application of appropriate processes to reduce the extreme dimensionality of load time series to facilitate unique clusters. Time feature extraction is a potential remedy, however, it is limited by the type of noisy, patchy, and unequal time-series common in residential datasets. In this paper we propose a strategy to alleviate these limitations by converting any types of load time series into map models that can be readily clustered. This also results in higher cluster distinction and robustness against noise compared to a baseline feature-based approach. A large dataset of residential electricity customers is used to confirm the outcomes as measured by a number of analytical and industrial metrics. The experiment with 12 clusters results in around 61% distinction, improved coincidence factor by around 6.75% relative to a random grouping, and robustness of around 59% against the applied noise.}
}
@article{TCHERNYKH201860,
title = {AC-RRNS: Anti-collusion secured data sharing scheme for cloud storage},
journal = {International Journal of Approximate Reasoning},
volume = {102},
pages = {60-73},
year = {2018},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2018.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X18300562},
author = {Andrei Tchernykh and Mikhail Babenko and Nikolay Chervyakov and Vanessa Miranda-López and Viktor Kuchukov and Jorge M. Cortés-Mendoza and Maxim Deryabin and Nikolay Kucherov and Gleb Radchenko and Arutyun Avetisyan},
keywords = {Uncertainty, Collusion, Multi-cloud, Cloud Computing, Secret Sharing Schemes, Residue Number System},
abstract = {Cloud security issues are important factors for data storage and processing. Apart from the existing security and reliability problems of traditional distributed computing, there are new security and reliability problems. They include attacks on a virtual machine, attacks on the synchronization keys, and so on. According to the assessment of international experts in the field of cloud security, there are risks of cloud collusion under uncertain conditions. To mitigate this type of uncertainty and reduce harms it can cause, we propose AC-RRNS algorithm based on modified threshold Asmuth–Bloom and Mignotte secret sharing schemes. We prove that the algorithm satisfies the formal definition of computational security. If the adversary coalition knows the secret shares, but does not know the secret key, the probability to obtain the secret is less than 1/(2l⋅(k−1)(2l−k−1)). The probability is less than 1/2(l−1) with unknown secret shares and known secret key, and 1/2l⋅k with unknown secret key. Its complexity is equal to brute-force method. We demonstrate that the proposed scheme ensures security under several types of attacks. We propose approaches for selection of parameters for AC-RRNS secret sharing scheme to optimize the system behavior and data redundancy of encryption.}
}
@article{LEMIC2021100365,
title = {Localization in power-constrained Terahertz-operating software-defined metamaterials},
journal = {Nano Communication Networks},
volume = {30},
pages = {100365},
year = {2021},
issn = {1878-7789},
doi = {https://doi.org/10.1016/j.nancom.2021.100365},
url = {https://www.sciencedirect.com/science/article/pii/S1878778921000260},
author = {Filip Lemic and Sergi Abadal and Chong Han and Johann M. Marquez-Barja and Eduard Alarcón and Jeroen Famaey},
keywords = {Software-defined metamaterials/metasurfaces, Localization, Two-way ToF trilateration, Terahertz nanonetworks, Energy harvesting},
abstract = {Software-Defined Metamaterials (SDMs) show a strong potential for advancing the engineered control of electromagnetic waves. As such, they are envisioned to enable a variety of exciting applications, among others in the domains of smart textiles, high-resolution structural monitoring, and sensing in challenging environments. Many of the applications envisage deformations of the SDM structures, such as their bending, stretching or rolling, which implies that the locations of metamaterial elements will be changing relative to one another. In this paper, we argue that if the metamaterial elements would be accurately localizable, this location information could potentially be utilized for enabling novel SDM applications, as well as for optimizing the control of the elements themselves. To enable their localization, we assume that these elements are controlled wirelessly through a Terahertz (THz)-operating nanonetwork. We consider the elements to be power-constrained, with their sole powering option being to harvest energy from different environmental sources. By means of simulation, we demonstrate sub-millimeter accuracy of the two-way Time of Flight (ToF)-based localization, as well as high availability of the service (i.e., consistently more than 80% of the time), which is a result of the low energy consumed in the localization process. Finally, we qualitatively characterize the latency of the proposed localization service, as well as outline several challenges and future research directions.}
}
@article{G2020862,
title = {An optimal delay aware task assignment scheme for wireless SDN networked edge cloudlets},
journal = {Future Generation Computer Systems},
volume = {102},
pages = {862-875},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19301232},
author = {S.S. Chalapathi G. and Vinay Chamola and Chen-Khong Tham and Gurunarayanan S. and Nirwan Ansari},
keywords = {Edge computing, Load balancing, Quality of service, Task assignment, Wireless SDN},
abstract = {Over the past decade, there has been an increasing demand for mobile devices to perform computationally intensive tasks. However, the computational capability of these devices is limited due to memory, power and portability constraints. One of the feasible and attractive ways to enhance the performance of the resource-limited mobile devices is to offload their computationally intensive tasks on to the cloud servers when internet connectivity is available. However, when cloud servers are involved in processing, the latency and cost of computation increases. To mitigate these problems, devices with high computational resources, called cloudlets, can be deployed in the locations close to the mobile users/devices. The mobile devices can then offload their computationally intensive tasks on to them. Due to easier access and nearness of the cloudlets, the cost and latency in processing the tasks decreases. In this work, we focus on task assignment problem in a multi-cloudlet network connected via a wireless SDN network, which services the task offload requests from mobile devices in a given locality. The aim of the proposed solution is to minimize latency and thus enhance the quality of service for mobile devices. We prove the optimality of the proposed solution mathematically and employ an admission control policy to maintain this optimality even in heavily loaded networks. We also perform numerical simulations for two scenarios of small and large networks and evaluate the performance for varying traffic and network parameters. The results demonstrate that the proposed task assignment method offers reduced latency compared to state-of-the-art task assignment approaches and hence improves the quality of service offered to mobile devices.}
}
@article{PAGARE2021166168,
title = {Design and analysis of hybrid optical distribution network for worst-case scenario of E2-class symmetric coexistence 80 Gbps TWDM NG-PON2 architecture for FTTX access networks},
journal = {Optik},
volume = {228},
pages = {166168},
year = {2021},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2020.166168},
url = {https://www.sciencedirect.com/science/article/pii/S0030402620319744},
author = {Rajendraprasad A. Pagare and Santosh Kumar and Abhilasha Mishra},
keywords = {Access networks, GPON, FTTX, PON, NG-PON2, WDM-PON},
abstract = {In this paper, we investigated the cost-effective design and validation of E2-class coexistence 80 Gbps symmetric 8 × 8 Time and Wavelength Division Multiplexing (TWDM) NG-PON2 optical access network considering worst-case scenario for the deployment of Fiber-to-the-X (FTTX) access network using hybrid optical distribution network (ODN). Full-service access network (FASN) unanimously agreed and ITU-T G.989.2 described recommendations for TWDM PON NG-PON2 technology to cater to the need of ever-increasing demand for higher bandwidth and data speed beyond 10 Gbps per user through access networks. Wavelength select (WS) and wavelength-routed (WR) ODN for downstream (D/S) and upstream (U/S) channels symmetric coexistence functionality supporting 80 Gbps accommodating GPON and XGS-PON legacy channels i.e.4-TWDM and 4 point-to-point (PtP) WDM channels operating at 1.25/2.5/10 Gbps respectively in D/S and U/S direction with error free higher splitter configuration of 2304 at 20 km, 640 at 40 km, 576 at 60 km. Precise calculations are done to ensure 11 dBm and 9 dBm ODN launch power (PTODN) to implement worst-case scenario for symmetric E2-class TWDM NG-PON2 network. Calculated inter-channel cross-talk (Cc) is -33.57 dB/-34.74 dB and corresponding cross-talk power penalty (Pc) is 0 dB for D/s and U/S channels respectively. Simulation results demonstrated and verified with the recommendations made in ITU-T G.989.2 confirmed that the proposed network configuration supports extended to reach upto 60 km in D/S and 80 km in U/S direction delivering incremental receiver sensitivity (Rxs) as -34.40/-34.40/42.21 dBm and -34.11/-37.25/-33.37 dBm, ODN path loss 29.40 dB.}
}
@article{JIE2018159,
title = {Online task scheduling for edge computing based on repeated Stackelberg game},
journal = {Journal of Parallel and Distributed Computing},
volume = {122},
pages = {159-172},
year = {2018},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2018.07.019},
url = {https://www.sciencedirect.com/science/article/pii/S0743731518305409},
author = {Yingmo Jie and Xinyu Tang and Kim-Kwang Raymond Choo and Shenghao Su and Mingchu Li and Cheng Guo},
keywords = {Allocation scheduling, Repeated Stackelberg game, Equilibrium, Edge computing resourcing},
abstract = {A key function of an edge service provider (ESP) is to dynamically allocate resources to tasks existing at the edges upon request. This is, however, a challenging task due to a number of several factors: real-time decision-making without any prior knowledge of future arrivals, tasks’ satisfactions provided by requests, and utilization of resources. To address these challenges, we propose an online scheduling that maps various tasks to the given relevant resources based on a repeated Stackelberg game. First, we model this problem as a long-term vs. short-term repeated Stackelberg game. In particular, for each round of the game, acting as a short-term leader, a user with a request first decides the unit prices for processing tasks within the relevant budget to maximize current total satisfaction of tasks. Then, based on the prices offered by different users in different rounds, to maximize the long-term profits earned from users, the ESP acts as the follower whose strategy is matching resources with tasks, and splitting those tasks among different edge centers owning various types of resources (edge mobile devices). The Stackelberg equilibrium between the ESP and the users is obtained using our proposed algorithms. Finally, we evaluate the effectiveness of our proposal, in terms of task distributions.}
}
@article{LI2020107371,
title = {Revisiting spectral clustering for near-convex decomposition of 2D shape},
journal = {Pattern Recognition},
volume = {105},
pages = {107371},
year = {2020},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107371},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320301746},
author = {Zhiyang Li and Jia Hu and Milos Stojmenovic and Zhaobin Liu and Weijiang Liu},
keywords = {Convex decomposition, Visibility, Shape signature, Spectral graph cut},
abstract = {We present a novel 2D shape decomposition algorithm via a recursive partitioning process. Starting with the contour points of a shape, we repeatedly separate the points into two parts by spectral clustering, until the stopping condition is met. Motivated by the fact that the points in a convex part are mutually visible, we regard the visibility matrix of points as the affinity matrix of spectral clustering to obtain a near-convex decomposition. Additionally, we present an efficient stopping rule to avoid over-segmentation on the shape branches. The stopping criterion is based on a novel shape signature called visible protrusion strength which can be used to measure the segmentability of a sub-shape. Finally, we demonstrate the efficiency of our algorithm on a variety of publicly available shapes, and provide qualitative and quantitative comparisons with state-of-art approaches.}
}
@article{YANG2020103276,
title = {Public and private blockchain in construction business process and information integration},
journal = {Automation in Construction},
volume = {118},
pages = {103276},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103276},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520301886},
author = {Rebecca Yang and Ron Wakefield and Sainan Lyu and Sajani Jayasuriya and Fengling Han and Xun Yi and Xuechao Yang and Gayashan Amarasinghe and Shiping Chen},
keywords = {Blockchain, Construction industry, Business process management, Smart contract, Ethereum, Hyperledger fabric},
abstract = {Blockchain as an emergent decentralized digital technology has been widely explored in many sectors to remedy the deficiencies of centralized solutions It has been recognized that blockchain technology has great potential to facilitate business activities spanning the whole life cycle of a building project in the construction industry, such as better communication or understanding, documents sharing, stage transition and quality endorsement. A comprehensive review of the literature regarding the application of blockchain in the construction domain found that there are few studies and applications of blockchain in construction practices, and most of the current research involves qualitative studies only. In this paper, we aim to explore the feasibility of applying both public blockchain and private blockchain technologies in the construction industry using two industry cases. Two business process cases (i.e., Case 1 and Case 2) were selected and used to drive the blockchain-based software system architecture design. The proposed architectures were demonstrated using Hyperledger Fabric (a private, permissioned and open source blockchain platform) and Ethereum (a public blockchain platform) respectively, to reflect the different requirements of the two use cases. This pilot study also illustrates the process, benefits, and challenges of adopting private and public blockchain technologies in construction domain. This research provides insights to researchers and practitioners regarding the adoption of blockchain technology, especially in construction industry.}
}
@article{ASLAM2020874,
title = {Dye-sensitized solar cells (DSSCs) as a potential photovoltaic technology for the self-powered internet of things (IoTs) applications},
journal = {Solar Energy},
volume = {207},
pages = {874-892},
year = {2020},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2020.07.029},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X20307611},
author = {Asad Aslam and Umer Mehmood and Muhammad Hamza Arshad and Abdulrehman Ishfaq and Junaid Zaheer and Anwar {Ul Haq Khan} and Muhammad Sufyan},
keywords = {Internet of Things, Sensors, Indoor, Photovoltaic, DSSC},
abstract = {Indoor solar cells have a prospective to influence the ecology of the Internet of Things (IoTs), containing communication devices, actuators, remote, and distributed sensors. Smart IoT sensors have the potential of performing control functions and mass monitoring, which leads to modernize the industrial and domestic automation systems. These sensor devices necessitate exceptionally less electrical power in several applications, and it will be remarkable if they could be driven by an indoor power gathering system. The technology of Dye-Sensitized Solar Cell has engraved a significant space in the field of photovoltaics due to its various distinctive merits like relatively cheap methods of fabrication, roll-to-roll compatibility, using readily available materials and easy processing ability on the flexible substrates. Multi-colored, semi-transparent dye solar cells/panels also exhibit exceptional performance in indoor/artificial light, consequently streamlining the stage for the indoor light-harvesting and self-power the applications of IoTs. The objective of this review is to emphasize applications of DSSCs for IoTs, factors affecting the performance, and challenges in their commercialization. This paper consists of four parts. The first part will explain the importance of solar energy and the merits of photovoltaic technology over other technologies. The second part will describe the evolution of DSSC from the laboratory to commercialization. The potential of DSSCs for IoT applications will be discussed in the third part. Finally, challenges and future outlook will be discussed in the last part of this literature.}
}
@article{RONDON2022102728,
title = {Survey on Enterprise Internet-of-Things systems (E-IoT): A security perspective},
journal = {Ad Hoc Networks},
volume = {125},
pages = {102728},
year = {2022},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102728},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521002171},
author = {Luis Puche Rondon and Leonardo Babun and Ahmet Aris and Kemal Akkaya and A. Selcuk Uluagac},
keywords = {Enterprise IoT systems, E-IoT, Smart home, Smart offices, Protocols, Security, BACnet},
abstract = {As technology becomes more widely available, millions of users worldwide have installed some form of smart device in their homes or workplaces. These devices are often off-the-shelf commodity systems, such as Google Home or Samsung SmartThings, that are installed by end-users looking to automate a small deployment. In contrast to these “plug-and-play” systems, purpose-built Enterprise Internet-of-Things (E-IoT) systems such as Crestron, Control4, RTI, Savant offer a smart solution for more sophisticated applications (e.g., complete lighting control, A/V management, security). In contrast to commodity systems, E-IoT systems are usually closed source, costly, require certified installers, and are overall more robust for their use cases. Due to this, E-IoT systems are often found in expensive smart homes, government and academic conference rooms, yachts, and smart private offices. However, while there has been plenty of research on the topic of commodity systems, no current study exists that provides a complete picture of E-IoT systems, their components, and relevant threats. As such, lack of knowledge of E-IoT system threats, coupled with the cost of E-IoT systems has led many to assume that E-IoT systems are secure. To address this research gap, raise awareness on E-IoT security, and motivate further research, this work emphasizes E-IoT system components, E-IoT vulnerabilities, solutions, and their security implications. In order to systematically analyze the security of E-IoT systems, we divide E-IoT systems into four layers: E-IoT Devices Layer, Communications Layer, Monitoring and Applications Layer, and Business Layer. We survey attacks and defense mechanisms, considering the E-IoT components at each layer and the associated threats. In addition, we present key observations in state-of-the-art E-IoT security and provide a list of open research problems that need further research.}
}
@article{LOPEZBENITEZ2017146,
title = {Prototype for multidisciplinary research in the context of the Internet of Things},
journal = {Journal of Network and Computer Applications},
volume = {78},
pages = {146-161},
year = {2017},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2016.11.023},
url = {https://www.sciencedirect.com/science/article/pii/S1084804516302922},
author = {Miguel López-Benítez and Timothy D. Drysdale and Simon Hadfield and Mohamed Ismaeel Maricar},
keywords = {Internet of Things, Hardware design, Communications, Data processing, Prototyping, Experimentation},
abstract = {The Internet of Things (IoT) poses important challenges requiring multidisciplinary solutions that take into account the potential mutual effects and interactions among the different dimensions of future IoT systems. A suitable platform is required for an accurate and realistic evaluation of such solutions. This paper presents a prototype developed in the context of the EPSRC/eFutures-funded project “Internet of Surprise: Self-Organising Data”. The prototype has been designed to effectively enable the joint evaluation and optimisation of multidisciplinary aspects of IoT systems, including aspects related with hardware design, communications and data processing. This paper provides a comprehensive description, discussing design and implementation details that may be helpful to other researchers and engineers in the development of similar tools. Examples illustrating the potentials and capabilities are presented as well. The developed prototype is a versatile tool that can be used for proof-of-concept, validation and cross-layer optimisation of multidisciplinary solutions for future IoT deployments.}
}
@article{YADAV2021110077,
title = {A multi-constraint combined method for road extraction from airborne laser scanning data},
journal = {Measurement},
volume = {186},
pages = {110077},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.110077},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121009994},
author = {Manohar Yadav},
keywords = {Airborne laser scanning (ALS), Road extraction, Intensity-based filtering, Region growing, Window sliding},
abstract = {Airborne laser scanning (ALS) is a state-of-the-art technique for fast and accurate acquisition of road network information. In this paper, an ALS data-based road extraction method, with four well-designed steps namely pre-processing, intensity-based filtering, quadrant-based region growing, and road candidate regions extraction is proposed. The contributions of this paper are mainly concentrated in last three steps, where radiometric, geometric and statistical constraints are combined to differentiate road and non-road points. The proposed method is straightforward to implement, where complex cases, such as removal of attached areas to the road, extraction of road surfaces surround the irregular data gaps left by vehicles and trees are effectively dealt. The method performance was evaluated using two datasets having complex cases and road network was extracted at average completeness, correctness and quality of 84.3%, 93% and 79.2%, respectively. The method achieves significant improvement in comparison with several state-of-the-art methods.}
}
@article{LIU2021120827,
title = {A bibliometric analysis of 30 years of platform research: Developing the research agenda for platforms, the associated technologies and social impacts},
journal = {Technological Forecasting and Social Change},
volume = {169},
pages = {120827},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.120827},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521002596},
author = {He Liu and Xuerong Li and Shouyang Wang},
keywords = {Platform research, Bibliometric analysis, Co-citation analysis, Research agenda},
abstract = {Platform markets have enormous economic significance in society and global economy, and platform research attracts scholars from different communities. In this paper, we conduct a bibliometric analysis of 3490 platform papers which appear in top business, economics, and management journals from 1990 to 2019. Influential journals, institutions, landmark papers, citation bursts are identified from the analysis. In addition to scholars from economics, strategy, and technology management communities, scholars from marketing, information systems, and operations management also participate in platform research. Moreover, the results indicate that the research focus of platform evolves from supply-side product development, product design and open innovation, goes through demand-side two-sided markets, and centers on sharing economy in recent years. The viewpoint of platform research experiences a conversion from a research object to a research context. We further develop a future research agenda for platforms, the associated technologies and social impacts. Our bibliometric analysis contributes to the literature by offering an objective and systematic overview of platform research.}
}
@article{REN201794,
title = {D-Log: A WiFi Log-based differential scheme for enhanced indoor localization with single RSSI source and infrequent sampling rate},
journal = {Pervasive and Mobile Computing},
volume = {37},
pages = {94-114},
year = {2017},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2016.09.018},
url = {https://www.sciencedirect.com/science/article/pii/S1574119216302450},
author = {Yongli Ren and Flora Dilys Salim and Martin Tomko and Yuntian Brian Bai and Jeffrey Chan and Kyle Kai Qin and Mark Sanderson},
keywords = {RSSI, WiFi log, Localization},
abstract = {Currently, large amounts of Wi-Fi access logs are collected in diverse indoor environments, but cannot be widely used for fine-grained spatio-temporal analysis due to coarse positioning. We present a Log-based Differential (D-Log) scheme for post-hoc localization based on differentiated location estimates obtained from large-scale Access Point (AP) logs of WiFi connectivity traces, which can be used for data analysis and knowledge discovery of visitor behaviours. Specifically, the location estimates are calculated by utilizing a combination of Received Signal Strength Indicator (RSSI) records from two neighbouring APs. D-Log exploits real-world industry WiFi logs where RSSI data sampled at low rates from single AP sources are recorded in each connectivity trace. The approach is independent of device and network infrastructure type. D-Log is evaluated using WiFi logs collected from controlled environment as well as real-world uncontrolled public indoor spaces, which includes discrete single-AP RSSI traces of around 100,000 mobile devices over a one-year period. The experiment results indicate that, despite of the challenges with the infrequent sampling rate and the limitations of the data that only records RSSI from single AP sources in each instance, D-Log performs comparatively well to the state-of-the-art RSSI-based localization methods and presents a viable alternative for many application areas where high-accuracy positioning infrastructure may not be cost effective or where positioning applications are considered on legacy information infrastructure.}
}
@article{CHEN20163,
title = {Information from imagery: ISPRS scientific vision and research agenda},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {115},
pages = {3-21},
year = {2016},
note = {Theme issue 'State-of-the-art in photogrammetry, remote sensing and spatial information science'},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2015.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S092427161500218X},
author = {Jun Chen and Ian Dowman and Songnian Li and Zhilin Li and Marguerite Madden and Jon Mills and Nicolas Paparoditis and Franz Rottensteiner and Monika Sester and Charles Toth and John Trinder and Christian Heipke},
keywords = {Research agenda, Photogrammetry, Remote sensing, Spatial information science, ISPRS},
abstract = {With the increased availability of very high-resolution satellite imagery, terrain based imaging and participatory sensing, inexpensive platforms, and advanced information and communication technologies, the application of imagery is now ubiquitous, playing an important role in many aspects of life and work today. As a leading organisation in this field, the International Society for Photogrammetry and Remote Sensing (ISPRS) has been devoted to effectively and efficiently obtaining and utilising information from imagery since its foundation in the year 1910. This paper examines the significant challenges currently facing ISPRS and its communities, such as providing high-quality information, enabling advanced geospatial computing, and supporting collaborative problem solving. The state-of-the-art in ISPRS related research and development is reviewed and the trends and topics for future work are identified. By providing an overarching scientific vision and research agenda, we hope to call on and mobilise all ISPRS scientists, practitioners and other stakeholders to continue improving our understanding and capacity on information from imagery and to deliver advanced geospatial knowledge that enables humankind to better deal with the challenges ahead, posed for example by global change, ubiquitous sensing, and a demand for real-time information generation.}
}
@article{HOSSAIN2018422,
title = {An Internet of Things-based health prescription assistant and its security system design},
journal = {Future Generation Computer Systems},
volume = {82},
pages = {422-439},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17314085},
author = {Mahmud Hossain and S.M. Riazul Islam and Farman Ali and Kyung-Sup Kwak and Ragib Hasan},
keywords = {Internet of things, Healthcare, Health assistant, Telemedicine, Security system},
abstract = {Today, telemedicine has a great reputation because of its capacity to provide quality healthcare services to remote locations. To achieve its purposes, telemedicine utilizes a number of wireless technologies as well as the Internet of Things (IoT). The IoT is redefining the capacity of telemedicine in terms of improved and seamless healthcare services. In this regard, this paper contributes to the set of features of telemedicine by proposing a model for an IoT-based health prescription assistant (HPA), which helps each patient to follow the doctors recommendations properly. This paper also designs a security system that ensures user authentication and protected access to resources and services. The security system authenticates a user based on the OpenID standard. An access control mechanism is implemented to prevent unauthorized access to medical devices. Once the authentication is successful, the user is issued an authorization ticket, which this paper calls a security access token (SAT). The SAT contains a set of privileges that grants the user access to medical IoT devices and their services and/or resources. The SAT is cryptographically protected to guard against forgery. A medical IoT device verifies the SAT prior to serving a request, and thus, ensures protected access. A prototype of the proposed system has been implemented to experimentally analyze and compare the resource efficiency of different SAT verification approaches in terms of a number of performance metrics, including computation and communication overhead.}
}
@article{COLAKOVIC201817,
title = {Internet of Things (IoT): A review of enabling technologies, challenges, and open research issues},
journal = {Computer Networks},
volume = {144},
pages = {17-39},
year = {2018},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618305243},
author = {Alem Čolaković and Mesud Hadžialić},
keywords = {IoT (Internet of Things), IoT vision, IoT features, IoT enabling technologies, Open issues and challenges, Future research direction},
abstract = {IoT (Internet of Things) is a new paradigm which provides a set of new services for the next wave of technological innovations. IoT applications are nearly limitless while enabling seamless integration of the cyber-world with the physical world. However, despite the enormous efforts of standardization bodies, alliances, industries, researchers and others, there are still numerous problems to deal with in order to reach the full potential of IoT. These issues should be considered from various aspects such as enabling technologies, applications, business models, social and environmental impacts. In focus of this paper are open issues and challenges considered from the technological perspective. Just for clarification, we put in light different visions that stand behind this paradigm in order to facilitate a better understanding of the IoT's features. Furthermore, this exhaustive survey provides insights into the state-of-the-art of IoT enabling and emerging technologies. The most relevant among them are addressed with some details. The main scope is to deliver a comprehensive overview of open issues and challenges to be tackled by future research. We provide some insights into specific emerging ideas in order to facilitate future research. Also, this paper brings order in the existing literature by classifying contributions according to different research topics.}
}
@article{FRIASMARTINEZ2014237,
title = {Spectral clustering for sensing urban land use using Twitter activity},
journal = {Engineering Applications of Artificial Intelligence},
volume = {35},
pages = {237-245},
year = {2014},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2014.06.019},
url = {https://www.sciencedirect.com/science/article/pii/S0952197614001419},
author = {Vanessa Frias-Martinez and Enrique Frias-Martinez},
keywords = {Urban computing, Crowd behavior, Land use detection, Spectral clustering},
abstract = {Individuals generate vast amounts of geolocated content through the use of mobile social media applications. In this context, Twitter has become an important sensor of the interactions between individuals and their environment. Building on this idea, this paper proposes the use of geolocated tweets as a complementary source of information for urban planning applications, focusing on the characterization of land use. The proposed technique uses unsupervised learning and automatically determines land uses in urban areas by clustering geographical regions with similar tweeting activity patterns. Three case studies are presented and validated for Manhattan (NYC), London (UK) and Madrid (Spain) using Twitter activity and land use information provided by the city planning departments. Results indicate that geolocated tweets can be used as a powerful data source for urban planning applications.}
}
@article{ROBIN201876,
title = {Global urban policy and the geopolitics of urban data},
journal = {Political Geography},
volume = {66},
pages = {76-87},
year = {2018},
issn = {0962-6298},
doi = {https://doi.org/10.1016/j.polgeo.2018.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S0962629817302184},
author = {Enora Robin and Michele Acuto},
keywords = {Urban knowledge, Urban policy, Habitat III, Geopolitics, Network analysis},
abstract = {Cities have gained prominence in global sustainability discourses. The United Nations ‘2030 Agenda’ highlights in at least four key agreements the need to engage local stakeholders as key partners for the implementation of global policy objectives. As a result, the rise of a ‘cities agenda’ has led not only to an increased role for cities in global politics but also to a reshaping of the knowledge-base underpinning international agreements and their implementation. This paper argues that the contemporary willingness to move beyond the “territorial trap” of modern geopolitics, by emphasizing cities’ agency in global affairs and by calling for the production of globally comparable urban data, induces a process of reframing and rescaling existing understandings of the global. In that sense, the question of urban knowledge production – especially that of urban data creation – is an essentially geopolitical one. However, insights from critical geopolitics have been rarely used in current debates on global urban policy and urban data politics. This work, we posit, can inform current academic and policy discussions, as it invites us to explore three interrelated questions: how is the urban being written into contemporary global politics? What type of ‘urban’ issues are made salient/invisible in that process? Which geopolitical actors are currently dominating the production of urban knowledge globally? This paper offers to start addressing those themes, through the study of 28 global urban databases, digging into the technical as well as human components of those. In doing so, we offer a preliminary assessment of techno-political apparatus that underpins the construction of a global ‘urban gaze’ which in turn shapes - as much as it is maintained by - global urban policy frameworks and hegemonic forms of knowledge production.}
}
@article{GAO2019227,
title = {BIM-enabled facilities operation and maintenance: A review},
journal = {Advanced Engineering Informatics},
volume = {39},
pages = {227-247},
year = {2019},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2019.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S1474034618303987},
author = {Xinghua Gao and Pardis Pishdad-Bozorgi},
keywords = {Building Information Modeling (BIM), Facilities Management (FM), Operation & maintenance (O&M), Emergency management, Energy management},
abstract = {Building Information modeling (BIM) has the potential to advance and transform facilities Operation and Maintenance (O&M) by providing a platform for facility managers to retrieve, analyze, and process building information in a digitalized 3D environment. Currently, because of rapid developments in BIM, researchers and industry professionals need a state-of-the-art overview of BIM implementation and research in facility O&M. This paper presents a review of recent publications on the topic. It aims to evaluate and summarize the current BIM-O&M research and application developments from a facility manager's point of view, analyze research trends, and identify research gaps and promising future research directions. The scope of this research includes the academic articles, industry reports and guidelines pertaining to using BIM to improve selected facility O&M activities, including maintenance and repair, emergency management, energy management, change/relocation management, and security. The content analysis results show that research on BIM for O&M is still in its early stage and most of the current research has focused on energy management. We have identified that the interoperability in the BIM-O&M context is still a challenge and adopting the National Institute of Standards and Technology (NIST) Cyber-Physical Systems (CPS) Framework is a potential starting point to address this issue. More studies involving surveys are needed to understand the underlying O&M principles for BIM implementation – data requirements, areas of inefficiencies, the process changes. In addition, more studies on the return on investment of the innovative systems are required to justify the value of BIM-O&M applications and an improved Life Cycle Cost Analysis method is critical for such justifications.}
}
@article{VANDENBROEK2018330,
title = {Governance of big data collaborations: How to balance regulatory compliance and disruptive innovation},
journal = {Technological Forecasting and Social Change},
volume = {129},
pages = {330-338},
year = {2018},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2017.09.040},
url = {https://www.sciencedirect.com/science/article/pii/S0040162517314695},
author = {Tijs {van den Broek} and Anne Fleur {van Veenstra}},
keywords = {Disruptive innovation, Data protection regulation, Big data, Governance, Inter-organizational collaboration},
abstract = {Big data is an important driver of disruptive innovation that may increase organizations' competitive advantage. To create innovative data combinations and decrease investments, big data is often shared among organizations, crossing organizational boundaries. However, these big data collaborations need to balance disruptive innovation and compliance to a strict data protection regime in the EU. This paper investigates how inter-organizational big data collaborations arrange and govern their activities in the context of this dilemma. We conceptualize big data as inter-organizational systems and build on IS and Organization Theory literature to develop four archetypical governance arrangements: Market, Hierarchy, Bazaar and Network. Subsequently, these arrangements are investigated in four big data collaboration use cases. The contributions of this study to literature are threefold. First, we conceptualize the organization behind big data collaborations as IOS governance. Second, we show that the choice for an inter-organizational governance arrangement highly depends on the institutional pressure from regulation and the type of data that is shared. In this way, we contribute to the limited body of research on the antecedents of IOS governance. Last, we highlight with four use cases how the principles of big data, specifically data maximization, clash with the principles of EU data protection regulation. Practically, our study provides guidelines for IT and innovation managers how to arrange and govern the sharing of data among multiple organizations.}
}
@article{MARTIN20191,
title = {Mapping heterogeneous research infrastructure metadata into a unified catalogue for use in a generic virtual research environment},
journal = {Future Generation Computer Systems},
volume = {101},
pages = {1-13},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.05.076},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19302699},
author = {Paul Martin and Laurent Remy and Maria Theodoridou and Keith Jeffery and Zhiming Zhao},
keywords = {Virtual research environment, Science gateway, Research infrastructure, Metadata catalogue, Metadata mapping},
abstract = {Virtual Research Environments (VREs), also known as science gateways or virtual laboratories, assist researchers in data science by integrating tools for data discovery, data retrieval, workflow management and researcher collaboration, often coupled with a specific computing infrastructure. Recently, the push for better open data science has led to the creation of a variety of dedicated research infrastructures (RIs) that gather data and provide services to different research communities, all of which can be used independently of any specific VRE. There is therefore a need for generic VREs that can be coupled with the resources of many different RIs simultaneously, easily customised to the needs of specific communities. The resource metadata produced by these RIs rarely all adhere to any one standard or vocabulary however, making it difficult to search and discover resources independently of their providers without some translation into a common framework. Cross-RI search can be expedited by using mapping services that harvest RI-published metadata to build unified resource catalogues, but the development and operation of such services pose a number of challenges. In this paper, we discuss some of these challenges and look specifically at the VRE4EIC Metadata Portal, which uses X3ML mappings to build a single catalogue for describing data products and other resources provided by multiple RIs. The Metadata Portal was built in accordance to the e-VRE Reference Architecture, a microservice-based architecture for generic modular VREs, and uses the CERIF standard to structure its catalogued metadata. We consider the extent to which it addresses the challenges of cross-RI search, particularly in the environmental and earth science domain, and how it can be further augmented, for example to take advantage of linked vocabularies to provide more intelligent semantic search across multiple domains of discourse.}
}
@article{LAURO2015494,
title = {Model Predictive Control for Building Active Demand Response Systems},
journal = {Energy Procedia},
volume = {83},
pages = {494-503},
year = {2015},
note = {Sustainability in Energy and Buildings: Proceedings of the 7th International Conference SEB-15},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2015.12.169},
url = {https://www.sciencedirect.com/science/article/pii/S1876610215028349},
author = {Fiorella Lauro and Fabio Moretti and Alfonso Capozzoli and Stefano Panzieri},
keywords = {Demand side management, Active demand response, Economic model predictive control, Energy market, Smart grid.},
abstract = {The Active Demand Response (ADR), integrated with the distributed energy generation and storage systems, is the most common strategy for the optimization of energy consumption and indoor comfort in buildings, considering the energy availability and the balancing of the energy production from renewable sources. In the paper an overview of basic requirements and applications of ADR management is presented. Specifically, the model predictive control (MPC) adopted in several applications as optimal control strategy in the ADR buildings context is analysed. Finally the research experience of the authors in this context is described.}
}
@article{KELOBONYE2020102706,
title = {Measuring the accessibility and spatial equity of urban services under competition using the cumulative opportunities measure},
journal = {Journal of Transport Geography},
volume = {85},
pages = {102706},
year = {2020},
issn = {0966-6923},
doi = {https://doi.org/10.1016/j.jtrangeo.2020.102706},
url = {https://www.sciencedirect.com/science/article/pii/S0966692319307811},
author = {Keone Kelobonye and Heng Zhou and Gary McCarney and Jianhong (Cecilia) Xia},
keywords = {Accessibility, Cumulative opportunities, Competition, Education accessibility, Job accessibility, Spatial equity},
abstract = {As accessibility becomes an increasingly relevant concept in the analysis of sustainable transport and urban development, the accuracy of accessibility measures becomes increasingly vital. While more complex measures are gradually gaining popularity with increasing data and computational resources, policy makers and planners are still prone to opt for less complex methods that are easy to use and interpret. The cumulative opportunities measure is the most widely applied accessibility measure in planning practice, but it is also among the least accurate due to its lack of consideration of the impact of competition for those opportunities. This study seeks to highlight the impact of addressing competition for different urban services in the cumulative opportunities measure. A competition component is added to the measure, which is applied to a case study of three types of urban services in the Perth metropolitan area; jobs, primary/secondary education and shopping. The results show that considering competition changes the spatial patterns of accessibility and its equity. Since this approach reveals demand-supply imbalances, it can more accurately determine spatial inequalities in accessibility, and hence increases the utility of the cumulative opportunities measure. We also find that the three services had varying levels and spatial patterns of accessibility and spatial equity, thus relying on any single one of them for assessing spatial structural performance can be misleading.}
}
@article{ECTORS2020338,
title = {Optimizing copious activity type classes based on classification accuracy and entropy retention},
journal = {Future Generation Computer Systems},
volume = {110},
pages = {338-349},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.04.080},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18301675},
author = {Wim Ectors and Sofie Reumers and Won Do Lee and Bruno Kochan and Davy Janssens and Tom Bellemans and Geert Wets},
keywords = {Activity type classification, (Big) Transport data annotation, Optimal set of activity types, Local search algorithm, Classification accuracy, Entropy indices},
abstract = {Despite the advantages, big transport data are characterized by a considerable disadvantage as well. Personal and activity-travel information are often lacking, making it necessary to deduce this information with data mining techniques. However, some studies predict many unique activity type classes (ATCs), while others merge multiple activity types into larger ATCs. This action enhances the activity inference estimation, but destroys important activity information. Previous studies do not provide a strong justification for this practice. An objectively optimized set of ATCs, balancing model prediction accuracy and preserving activity information from the original data, becomes essential. Previous research developed a classification methodology in which the optimal set of ATCs was identified by analyzing all possible ATC combinations. However, this approach is practically impossible in a finite amount of time for e.g. the US National Household Travel Survey (NHTS) 2009 data set, which comprises 36 ATCs (home activity excluded), since there would be 3.82⋅1030 unique combinations (an exponential increase). The aim of this paper is to optimize which original ATCs should be grouped into a new class, and this for data sets for which it is impossible or impractical to simply calculate all ATC combinations. The proposed method defines an optimization parameter U (based on classification accuracy and information retention) which is maximized in an iterative local search algorithm. The optimal set of ATCs for the NHTS 2009 data set was determined. A comparison finds that this optimum is considerably better than many expert opinion activity type classification systems. Convergence was confirmed and large performance gains were found.}
}
@article{ATTIE2022121485,
title = {The acceptance and usage of smart connected objects according to adoption stages: an enhanced technology acceptance model integrating the diffusion of innovation, uses and gratification and privacy calculus theories},
journal = {Technological Forecasting and Social Change},
volume = {176},
pages = {121485},
year = {2022},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2022.121485},
url = {https://www.sciencedirect.com/science/article/pii/S0040162522000178},
author = {Elodie Attié and Lars Meyer-Waarden},
keywords = {IoT, smart connected objects, technology acceptance, well-being, privacy concerns, diffusion of innovation, adoption stage, innovativeness},
abstract = {ABSTRACT
In today's digitalized world, technologies such as the Internet of Things (IoT) and smart connected objects (SCOs) are moving to the forefront and have given rise to fundamental changes in consumers’ daily lives. During the context of COVID-19, the IoT and SCOs enabled people to better deal with the pandemic situation (e.g., control their health or use fitness indicators) (Gupta et al., 2021). The purpose of this study is to explain the acceptance and usage of SCOs and therefore extend the technology acceptance model (TAM; Davis, 1989) with other theories (i.e., uses and gratification, diffusion of innovation, privacy calculus), and thus new antecedents adapted to the SCO context. More specifically, in addition to the TAM's main variables (i.e., perceived usefulness, ease of use, intention to use, real use), we investigate the roles of concepts rarely investigated in innovation and new technology research, such as well-being, social image, privacy concerns, and innovativeness. We also study the differences in the adoption of SCOs between different user adoption stages, such as the early adopters, early majority, and late majority (Rogers, 1983). The data come from 702 respondents surveyed in a longitudinal study over three years of their acceptance and real usage. Structural equation modeling shows that the TAM variables remain relevant in the SCO context. The results show that utilitarian benefits are the main reasons leading to SCO technology acceptance, and well-being and social image lead to higher usage in the long term. However, privacy concerns are the main obstacles to the adoption of SCOs.}
}
@article{GHARBAOUI2016279,
title = {Cloud and network orchestration in SDN data centers: Design principles and performance evaluation},
journal = {Computer Networks},
volume = {108},
pages = {279-295},
year = {2016},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2016.08.029},
url = {https://www.sciencedirect.com/science/article/pii/S1389128616302821},
author = {M. Gharbaoui and B. Martini and D. Adami and S. Giordano and P. Castoldi},
keywords = {Cloud, SDN, Orchestration, OpenFlow, Data Center network},
abstract = {The oversubscription of Data Center network links and the high volatility of Virtual Machine (VM) deployments call for a flexible and agile control of Data Center networks, coordinated with computing resource control (i.e., cloud resource management). The Software-Defined Network (SDN) paradigm opens up new opportunities to design convergent resource management systems able to address the provisioning of cloud services while meeting dynamically changing traffic demands of running VMs. This paper presents the architectural design of an SDN-based orchestration system which is able to coordinate the provision of composite cloud and network services while assuring computational requirements as well as a better than best effort VM data delivery. The proposed orchestration system is able to perform VM allocations also based on estimations of switch/link and server loads as result of the synergistic interwork of the following functions: (i) resource selection and composition functions, (ii) coordinated resource configuration and management functions, (iii) monitoring and registration functions of resource status. A set of resource selection and composition strategies and estimation schemes have been also specified. The orchestration process has been thoroughly evaluated through a comprehensive set of simulations that clearly show an increasing acceptance rate of service requests, an improved utilization of network capabilities while effectively preventing significant degradations of the user experience despite the oversubscription of data center network links.}
}
@article{TELIKANI2020318,
title = {A survey of evolutionary computation for association rule mining},
journal = {Information Sciences},
volume = {524},
pages = {318-352},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.02.073},
url = {https://www.sciencedirect.com/science/article/pii/S002002552030164X},
author = {Akbar Telikani and Amir H. Gandomi and Asadollah Shahbahrami},
keywords = {Data mining, Association rule mining, Evolutionary computation, Swarm intelligent},
abstract = {Association Rule Mining (ARM) is a significant task for discovering frequent patterns in data mining. It has achieved great success in a plethora of applications such as market basket, computer networks, recommendation systems, and healthcare. In the past few years, evolutionary computation-based ARM has emerged as one of the most popular research areas for addressing the high computation time of traditional ARM. Although numerous papers have been published, there is no comprehensive analysis of existing evolutionary ARM methodologies. In this paper, we review emerging research of evolutionary computation for ARM. We discuss the applications on evolutionary computations for different types of ARM approaches including numerical rules, fuzzy rules, high-utility itemsets, class association rules, and rare association rules. Evolutionary ARM algorithms were classified into four main groups in terms of the evolutionary approach, including evolution-based, swarm intelligence-based, physics-inspired, and hybrid approaches. Furthermore, we discuss the remaining challenges of evolutionary ARM and discuss its applications and future topics.}
}
@article{JI2016268,
title = {Joint Depth and Semantic Inference from a Single Image via Elastic Conditional Random Field},
journal = {Pattern Recognition},
volume = {59},
pages = {268-281},
year = {2016},
note = {Compositional Models and Structured Learning for Visual Recognition},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2016.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0031320316001114},
author = {Rongrong Ji and Liujuan Cao and Yan Wang},
keywords = {Depth estimation, Semantic labeling, Conditional random field, Structured Support Vector Machine, Content analysis, Scene understanding},
abstract = {The estimations of depth and regional semantics from a single image have traditionally been considered as two separated problems. In this paper, we argue that these two tasks provide complementary information, which therefore can be performed jointly to reinforce individual tasks in terms of both accuracy and speed. In particular, we propose an Elastic Conditional Random Field (E-CRF) deployed upon superpixel segmentations, which models the interdependency between depth and semantics to refine each other in an iterative manner. Differing from the traditional CRFs, E-CRF makes edges elastically hidden/emergent during inference to conduct fast Loopy Belief Propagation, while explicitly modeling the depth-label interdependency to achieve high inference accuracy. Moreover, the Structured Support Vector Machine (SSVM) is further introduced to drastically speed up the inference. We have conducted extensive evaluations on both Make3D and NYU benchmark datasets, which demonstrated that our E-CRF method significantly outperforms state-of-the-art techniques in terms of precision, while significantly accelerating the inference speed (2–3 orders of magnitude).}
}
@article{TONNE2021106236,
title = {Defining pathways to healthy sustainable urban development},
journal = {Environment International},
volume = {146},
pages = {106236},
year = {2021},
issn = {0160-4120},
doi = {https://doi.org/10.1016/j.envint.2020.106236},
url = {https://www.sciencedirect.com/science/article/pii/S0160412020321917},
author = {Cathryn Tonne and Linda Adair and Deepti Adlakha and Isabelle Anguelovski and Kristine Belesova and Maximilian Berger and Christa Brelsford and Payam Dadvand and Asya Dimitrova and Billie Giles-Corti and Andreas Heinz and Nassim Mehran and Mark Nieuwenhuijsen and François Pelletier and Otavio Ranzani and Marianne Rodenstein and Diego Rybski and Sahar Samavati and David Satterthwaite and Jonas Schöndorf and Dirk Schreckenberg and Jörg Stollmann and Hannes Taubenböck and Geetam Tiwari and Bert {van Wee} and Mazda Adli},
keywords = {Urbanization, Urban extent, Urbanicity, Cities, Health, Mental health},
abstract = {Goals and pathways to achieve sustainable urban development have multiple interlinkages with human health and wellbeing. However, these interlinkages have not been examined in depth in recent discussions on urban sustainability and global urban science. This paper fills that gap by elaborating in detail the multiple links between urban sustainability and human health and by mapping research gaps at the interface of health and urban sustainability sciences. As researchers from a broad range of disciplines, we aimed to: 1) define the process of urbanization, highlighting distinctions from related concepts to support improved conceptual rigour in health research; 2) review the evidence linking health with urbanization, urbanicity, and cities and identify cross-cutting issues; and 3) highlight new research approaches needed to study complex urban systems and their links with health. This novel, comprehensive knowledge synthesis addresses issue of interest across multiple disciplines. Our review of concepts of urban development should be of particular value to researchers and practitioners in the health sciences, while our review of the links between urban environments and health should be of particular interest to those outside of public health. We identify specific actions to promote health through sustainable urban development that leaves no one behind, including: integrated planning; evidence-informed policy-making; and monitoring the implementation of policies. We also highlight the critical role of effective governance and equity-driven planning in progress towards sustainable, healthy, and just urban development.}
}
@article{HOYER202057,
title = {Transforming the Customer Experience Through New Technologies},
journal = {Journal of Interactive Marketing},
volume = {51},
pages = {57-71},
year = {2020},
note = {Special issue on Big Data, Technology-Driven CRM & Artificial Intelligence},
issn = {1094-9968},
doi = {https://doi.org/10.1016/j.intmar.2020.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1094996820300827},
author = {Wayne D. Hoyer and Mirja Kroschke and Bernd Schmitt and Karsten Kraume and Venkatesh Shankar},
keywords = {Customer experience, Experiential marketing, Customer value, Internet of Things (IoT), Augmented and Virtual Reality (AR/VR), AI and robots},
abstract = {New technologies such as Internet of Things (IoT), Augmented Reality (AR), Virtual Reality (VR), Mixed Reality (MR), virtual assistants, chatbots, and robots, which are typically powered by Artificial Intelligence (AI), are dramatically transforming the customer experience. In this paper, we offer a fresh typology of new technologies powered by AI and propose a new framework for understanding the role of new technologies on the customer/shopper journey. Specifically, we discuss the impact and implications of these technologies on each broad stage of the shopping journey (pre-transaction, transaction, and post-transaction) and advance a new conceptualization for managing these new AI technologies along customer experience dimensions to create experiential value. We discuss future research ideas emanating from our framework and outline interdisciplinary research avenues.}
}
@article{CHENG201810,
title = {Industrial IoT in 5G environment towards smart manufacturing},
journal = {Journal of Industrial Information Integration},
volume = {10},
pages = {10-19},
year = {2018},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2018.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X18300049},
author = {Jiangfeng Cheng and Weihai Chen and Fei Tao and Chun-Liang Lin},
keywords = {5G, Industrial Internet-of-Things (IIoT), Cyber-physical Manufacturing System (CPMS), Smart manufacturing, Architecture},
abstract = {Smart manufacturing based on cyber-physical manufacturing systems (CPMS) has become the development trend and been widely recognized all over the world. Throughout the development trend of CPMS, one of the key issues is industrial Internet-of-Things (IIoT) with the characteristics of automation, smart connected, real-time monitoring, and collaborative control. Along with the permeation and applications of advanced technologies in manufacturing, massive amounts of data have been generated in the manufacturing process. However, the current 3th generation mobile network (3G), 4G and other communication technologies cannot meet the demands of CPMS for high data rate, high reliability, high coverage, low latency, etc., which hinders the development and implementation of CPMS. As a future advanced wireless transmission technology, 5G has a significant potential to promote IIoT and CPMS. Based on the architecture and characteristics of 5G wireless communication technology, this paper proposes the architecture of 5G-based IIoT, and describes the implementation methods of different advanced manufacturing scenarios and manufacturing technologies under the circumstances of three typical application modes of 5G, respectively, i.e., enhance mobile broadband (eMBB), massive machine type communication (mMTC), ultra-reliable and low latency communication (URLLC). Besides, the characteristics, key technologies and challenges of the 5G based IIoT are also analyzed.}
}
@article{IQBAL2020107476,
title = {DM-GKM: A key management scheme for dynamic group based applications},
journal = {Computer Networks},
volume = {182},
pages = {107476},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107476},
url = {https://www.sciencedirect.com/science/article/pii/S138912862031152X},
author = {Salman Iqbal and Miss Laiha {Mat Kiah} and Aqeel {ur Rehman} and Zahid Abbas and Babak Daghighi},
keywords = {Secure group communication, Key management, Host mobility, Wireless mobile networks},
abstract = {In recent years, group-based applications (GBAs) have gained popularity due to their interesting and promising functionalities such as video on demand, teleconferencing, and pay per view. The advancements in wireless networks and the emergence of mobile devices such as smartphones and tablets have also increased the demands for GBAs. However, the implementation of group key management protocols for GBAs leads to significant computational, storage and communication overheads as well as potential system bottlenecks due to the high mobility of group members. The goal of this research is to address these issues and design a lightweight key management framework that requires fewer computations of keys for dynamic mobile users. A new group key management framework is proposed in this research, which is called the “DynaMic Group Key Management” (DM-GKM) framework. This framework exploits the advantages of the asymmetric key cryptosystem in order to guarantee security and it alleviates the rekeying overhead and distributing the independent Group Key (GK) for each cluster. Simulation and performance analysis demonstrates that the DM-GKM framework fulfils the requirements of a lightweight key management framework for large, dynamic groups of users. An analytical model is also developed to determine the performance and security features of the proposed framework.}
}
@article{CAO2016198,
title = {Building energy-consumption status worldwide and the state-of-the-art technologies for zero-energy buildings during the past decade},
journal = {Energy and Buildings},
volume = {128},
pages = {198-213},
year = {2016},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2016.06.089},
url = {https://www.sciencedirect.com/science/article/pii/S0378778816305783},
author = {Xiaodong Cao and Xilei Dai and Junjie Liu},
keywords = {Building energy, Zero-energy building (ZEB), Energy savings, Renewable energy, Climate change},
abstract = {Energy consumption has dramatically increased in buildings over the past decade due to population growth, more time spent indoors, increased demand for building functions and indoor environmental quality, and global climate change. Building energy use currently accounts for over 40% of total primary energy consumption in the U.S. and E.U. Nevertheless, significant energy savings can be achieved in buildings if they are properly designed, constructed and operated. For this reason, building energy efficiency can provide key solutions to energy shortages, carbon emissions and their serious threat to our living environment. This paper offers a brief overview of building energy-consumption situations, relevant energy-saving approaches, and the influence of global climate change. Building energy-consumption situations based on data derived from international energy reports are initially compared between the U.S., China and the E.U. Both similarities and differences are found in aspects of building energy end-uses and final energy fuel-types among these top three building energy consumers. We then introduce the current concept of the zero-energy building (ZEB). State-of-the-art approaches for ZEB technologies are summarized in three categories: passive energy-saving technologies, energy-efficient building service systems and renewable energy production technologies. The feasibility of these technologies is reviewed. In addition, we briefly discuss the influence of global climate change on the evolution of building energy use in the future. We find that climate change significantly impacts building energy performance, particularly in space heating and cooling. Improvements on building envelope and ventilation can play an important role in reducing space heating and cooling consumption levels. We also provide some suggestions for further developing ZEBs.}
}
@article{PRATESI2020101786,
title = {PRIMULE: Privacy risk mitigation for user profiles},
journal = {Data & Knowledge Engineering},
volume = {125},
pages = {101786},
year = {2020},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2019.101786},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X18305342},
author = {Francesca Pratesi and Lorenzo Gabrielli and Paolo Cintia and Anna Monreale and Fosca Giannotti},
keywords = {Mobile phone data, Call detail record, Privacy, Anonymization},
abstract = {The availability of mobile phone data has encouraged the development of different data-driven tools, supporting social science studies and providing new data sources to the standard official statistics. However, this particular kind of data are subject to privacy concerns because they can enable the inference of personal and private information. In this paper, we address the privacy issues related to the sharing of user profiles, derived from mobile phone data, by proposing PRIMULE, a privacy risk mitigation strategy. Such a method relies on PRUDEnce (Pratesi et al., 2018), a privacy risk assessment framework that provides a methodology for systematically identifying risky-users in a set of data. An extensive experimentation on real-world data shows the effectiveness of PRIMULE strategy in terms of both quality of mobile user profiles and utility of these profiles for analytical services such as the Sociometer (Furletti et al., 2013), a data mining tool for city users classification.}
}
@article{GONZALEZCOMPEAN2019430,
title = {A policy-based containerized filter for secure information sharing in organizational environments},
journal = {Future Generation Computer Systems},
volume = {95},
pages = {430-444},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18311774},
author = {J.L. Gonzalez-Compean and Oscar Telles and Ivan Lopez-Arevalo and Miguel Morales-Sandoval and Victor J. Sosa-Sosa and Jesus Carretero},
keywords = {Cloud security, Risk assessment, Mining, Multi-level security, Virtual containers},
abstract = {In organizational environments, sensitive information is unintentionally exposed and sent to the cloud without encryption by insiders that even were previously informed about cloud risks. To mitigate the effects of this information privacy paradox, we propose the design, development and implementation of SecFilter, a security filter that enables organizations to implement security policies for information sharing. SecFilter automatically performs the following tasks: (a) intercepts files before sending them to the cloud; (b) searches for sensitive criteria in the context and content of the intercepted files by using mining techniques; (c) calculates the risk level for each identified criterion; (d) assigns a security level to each file based on the detected risk in its content and context; and (e) encrypts each file by using a multi-level security engine, based on digital envelopes from symmetric encryption, attribute-based encryption and digital signatures to guarantee the security services of confidentiality, integrity and authentication on each file at the same time that access control mechanisms are enforced before sending the secured file versions to cloud storage. A prototype of SecFilter was implemented for a real-world file sharing application that has been deployed on a private cloud. Fine-tuning of SecFilter components is described and a case study has been conducted based on document sharing of a well-known repository (MedLine corpus). The experimental evaluation revealed the feasibility and efficiency of applying a security filter to share information in organizational environments.}
}
@article{GOMES2020100359,
title = {Dust effect impact on PV in an aggregation with wind and thermal powers},
journal = {Sustainable Energy, Grids and Networks},
volume = {22},
pages = {100359},
year = {2020},
issn = {2352-4677},
doi = {https://doi.org/10.1016/j.segan.2020.100359},
url = {https://www.sciencedirect.com/science/article/pii/S2352467720302903},
author = {I.L.R. Gomes and R. Melicio and V.M.F. Mendes},
keywords = {Variable renewable resources, Thermal units, Unit commitment, Day-ahead market, Stochastic programming, Energy storage, Dust effect},
abstract = {This paper is about the dust effect impact on photovoltaic systems on the profit of an electricity market agent acting as an aggregator of photovoltaic power, wind power, thermal power, and an energy storage system. Energy storage ensures arbitrage and smoothing of the variability of photovoltaic power and wind power. The market agent intends to derive bids for submission in a day-ahead market, having consideration of the dust effect impact on the photovoltaic power. A formulation is proposed for a support decision system by a profit-based unit commitment problem solved by a stochastic programming approach, considering the operating characteristics of the virtual power plant. The photovoltaic power, wind power, and market price uncertainties are input data derived from scenarios of historical data. Case studies addressed show the advantages of the stochastic programming approach and insights concerned with the integration of uncertainties within the modeling for the schedule of the energy storage system and the dust effect impact on profit.}
}
@article{THOMPSON2021101628,
title = {Platform, or technology project? A spectrum of six strategic ‘plays’ from UK government IT initiatives and their implications for policy},
journal = {Government Information Quarterly},
volume = {38},
number = {4},
pages = {101628},
year = {2021},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2021.101628},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X21000642},
author = {Mark Thompson and Will Venters},
keywords = {Platform innovation, Platform strategy, Government policy, Digital innovation, UK},
abstract = {There is a markedly broad range of definitions and illustrative examples of the role played by governments themselves within the literature on government platforms. In response we conduct an inductive and deductive qualitative review of the literature to clarify this landscape and so to develop a typology of six definitions of government platforms, organised within three genres along a spectrum from fully centralised, through to fully decentralised. For each platform definition we offer illustrative ‘mini-cases’ drawn from the UK government experience as well as further insights and implications for each genre, drawn from the broader information systems literature on platforms. A range of benefits, risks, governance challenges, policy recommendations, and suggestions for further research are then identified and discussed.}
}
@article{NANDY202157,
title = {An enhanced lightweight and secured authentication protocol for vehicular ad-hoc network},
journal = {Computer Communications},
volume = {177},
pages = {57-76},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421002371},
author = {Tarak Nandy and Mohd Yamani Idna Idris and Rafidah Md Noor and Ashok Kumar Das and Xiong Li and Norjihan Abdul Ghani and Sananda Bhattacharyya},
keywords = {Authentication, Vehicle ad-hoc network (VANET), Fuzzy extractor, Security and privacy, Biometrics, BAN logic, AVISPA},
abstract = {A substantial number of authentication protocols are designed to safeguard vehicular ad-hoc network (VANET) communication from potential attacks; however, they experienced an inability to provide a balance between lightweight and security. Existing security and privacy-preserving based authentication protocols in vehicular networks mostly rely on the trusted authority and signatures to validate the communication on road. Accomplishing the quick validation and correspondence is difficult in such methodologies and further, they endure execution obliges from coming about overhead. To overcome these issues, we have developed an enhanced lightweight and secure authentication protocol (ELSAP) for V2V Communication in VANETs. Moreover, the scheme withheld with self-authentication prior to communication that enhances the network feasibilities, which in return needs less message transfer during authentication as well as communication, indicates lightweight features. Furthermore, two or more vehicles can securely perform mutual authentication, proven by Burrow–Abadi–Needham (BAN) logic. Additionally, the competency of the proposed protocol against the current updated threats is shown via security analysis and comparisons tools such as Automated Validation of Internet Security Protocols and Applications (AVISPA). The result of the performance analysis shows that the communication cost and computational cost outperformed the earlier authentication schemes alongside the security features of the proposed protocol.}
}
@article{GARG2021120407,
title = {Measuring the perceived benefits of implementing blockchain technology in the banking sector},
journal = {Technological Forecasting and Social Change},
volume = {163},
pages = {120407},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2020.120407},
url = {https://www.sciencedirect.com/science/article/pii/S0040162520312336},
author = {Poonam Garg and Bhumika Gupta and Ajay Kumar Chauhan and Uthayasankar Sivarajah and Shivam Gupta and Sachin Modgil},
keywords = {Blockchain, Banking sector, Perceived benefits, Instrument development, AMOS},
abstract = {This study aims to measure the perceived business benefits of blockchain technology implementation in the banking sector and establish factors to measure these benefits. Concerns regarding security, values, and standards are essential to banking operations. Data was collected from 291 respondents who are either blockchain consultants, blockchain marketing experts, or CEOs/business heads of banks that are in the process of advising, consulting, or implementing blockchain technology. Confirmatory factor analysis (CFA) was carried out to assess the reliability and validity of the proposed instrument. The results support the proposed instrument and its five constructs. The scale emerging from this study indicates a good degree of reliability, validity and unidimensionality in each of its constructs. Technologies like blockchain are in their initial stages, and recent advances in blockchain technology may impact our findings. The developed instrument could help give decision makers a foundational view to measure the benefits of implementing blockchain technology before they choose to integrate it in their existing system. The scientific and societal significance of the study based on its practical and theoretical applications is presented at the end.}
}
@article{HORNG2019349,
title = {The cooperative on-street parking space searching mechanism in city environments},
journal = {Computers & Electrical Engineering},
volume = {74},
pages = {349-361},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618312886},
author = {Gwo-Jiun Horng},
keywords = {SOI, CA, On-street parking space, VANETs, The small-world mechanism},
abstract = {In this paper, we aim to design an innovative parking space searching space occupancy indicator (SOI) system. Searching for a parking space is a common global problem that needs urgent solutions. The proposed mechanism uses taxis, public vehicles (PVs), and on-street parked vehicles to sense parking spaces and transmits sensed information to nearby road side unit (RSU) hotspots. The transmitted data include the availability of parking spaces and their location and direction. We use a cellular automata (CA) model and small world mechanism to achieve on-street parking space searching and recommendation. The current study evaluates the performance of the approach by conducting computer simulations. Simulation results reveal the strengths of the proposed optimized and parking space searching SOI system in terms of reduces search time, and increases success rate of tracking in VANETs.}
}
@article{ZUCCARO2020101783,
title = {Future research and innovation priorities in the field of natural hazards, disaster risk reduction, disaster risk management and climate change adaptation: a shared vision from the ESPREssO project},
journal = {International Journal of Disaster Risk Reduction},
volume = {51},
pages = {101783},
year = {2020},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2020.101783},
url = {https://www.sciencedirect.com/science/article/pii/S2212420920312851},
author = {G. Zuccaro and M.F. Leone and C. Martucci},
keywords = {Sendai framework, DRR and CCA integration, Resilience, Research and Innovation},
abstract = {The H2020 ESPREssO project (Enhancing Synergies for Disaster Prevention in the European Union), aimed at identifying the existing gaps and key priorities for Research and Innovation (R&I) in the domains of Natural Hazards (NH), Disaster Risk Reduction (DRR), Disaster Risk Management (DRM) and Climate Change Adaptation (CCA). Key research priorities have been framed within the Sendai Framework for Disaster Risk Reduction 2015–2030 (SFDRR) and the related EU Action Plan, exploring the opportunities emerging from the linkages with the Sendai priorities and the key overarching issues from the literature review and networking activities carried out by ESPREssO project. The many ongoing initiatives at European and Global levels on NH, DRR, DRM and CCA and have been taken into account, with the aim of providing a harmonised framework able to capture the complexity of these fields, in terms of research and innovation and deliver a synthesized view of the emerging priorities. The paper identifies five broad areas of R&I in the field of DRR and CCA where EU investment is needed, highlighting for each of them relevant key topics of investigation. These areas (Improved Risk and Impact Assessment; Better Data for Resilient Future; Risk Governance and Partnership; Overcoming the Implementation Gap in DRR and CCA; Human Behaviour and Disaster Risk) have been suggested by the ESPREssO “Vision Paper” [1] as an answer to the relevant gaps and needs as expressed by the network of stakeholders and international experts engaged during the project. The Vision Paper is available at http://www.espressoproject.eu/images/deliverables/ESPREssO_D5.5.pdf.}
}
@article{TZOUNIS201731,
title = {Internet of Things in agriculture, recent advances and future challenges},
journal = {Biosystems Engineering},
volume = {164},
pages = {31-48},
year = {2017},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2017.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S1537511017302544},
author = {Antonis Tzounis and Nikolaos Katsoulas and Thomas Bartzanas and Constantinos Kittas},
keywords = {Internet of things, RFID, Cloud, Wireless sensor networks, Food supply chain},
abstract = {The increasing demand for food, both in terms of quantity and quality, has raised the need for intensification and industrialisation of the agricultural sector. The “Internet of Things” (IoT) is a highly promising family of technologies which is capable of offering many solutions towards the modernisation of agriculture. Scientific groups and research institutions, as well as the industry, are in a race trying to deliver more and more IoT products to the agricultural business stakeholders, and, eventually, lay the foundations to have a clear role when IoT becomes a mainstream technology. At the same time Cloud Computing, which is already very popular, and Fog Computing provide sufficient resources and solutions to sustain, store and analyse the huge amounts of data generated by IoT devices. The management and analysis of IoT data (“Big Data”) can be used to automate processes, predict situations and improve many activities, even in real-time. Moreover, the concept of interoperability among heterogeneous devices inspired the creation of the appropriate tools, with which new applications and services can be created and give an added value to the data flows produced at the edge of the network. The agricultural sector was highly affected by Wireless Sensor Network (WSN) technologies and is expected to be equally benefited by the IoT. In this article, a survey of recent IoT technologies, their current penetration in the agricultural sector, their potential value for future farmers and the challenges that IoT faces towards its propagation is presented.}
}
@article{GUERRERO2019131,
title = {Evaluation and efficiency comparison of evolutionary algorithms for service placement optimization in fog architectures},
journal = {Future Generation Computer Systems},
volume = {97},
pages = {131-144},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.02.056},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18325147},
author = {Carlos Guerrero and Isaac Lera and Carlos Juiz},
keywords = {Fog computing, Resource management, Evolutionary algorithms, Service placement},
abstract = {This study compares three evolutionary algorithms for the problem of fog service placement: weighted sum genetic algorithm (WSGA), non-dominated sorting genetic algorithm II (NSGA-II), and multiobjective evolutionary algorithm based on decomposition (MOEA/D). A model for the problem domain (fog architecture and fog applications) and for the optimization (objective functions and solutions) is presented. Our main concerns are related to optimize the network latency, the service spread and the use of the resources. The algorithms are evaluated with a random Barabasi–Albert network topology with 100 devices and with two experiment sizes of 100 and 200 application services. The results showed that NSGA-II obtained the highest optimizations of the objectives and the highest diversity of the solution space. On the contrary, MOEA/D was better to reduce the execution times. The WSGA algorithm did not show any benefit with regard to the other two algorithms.}
}
@article{AHN201649,
title = {Becoming a network beyond boundaries: Brain-Machine Interfaces (BMIs) as the actor-networks after the internet of things},
journal = {Technology in Society},
volume = {47},
pages = {49-59},
year = {2016},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2016.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X16300926},
author = {Sungyong Ahn},
keywords = {Brain-Machine Interface, Actor-network, Neuroprosthetics, Internet of things, Nicolelis},
abstract = {For the last few decades, actor-network theory has been usually criticized for its focus on Machiavellian human actors controlling the overall networking between other actors or blamed for its dissipation of human agencies within the global status of a network. However, at the moment of its development, the freshness of actor-network theory was more relevant to its focus on the meaning of what the hyphen signifies; not so much just a simple connection between two independent variables, but an ontological event itself, from which certain entities juxtaposed together become involved by exchanging stable influences each other thus settled down as the actors participating in a network being associated as the summing up of these settled influences. The aim of this paper is to refresh this bygone freshness of ANT from the recent development of the Internet of Things (IoT); which vividly exemplifies how a network and its actors are generated from a manifold technologically augmented entities—such as smart appliances in a house, migratory animals with RFID tags, and ensembles of neurons signaling beyond one's brain through a bundle of microwires—each of which is physiologically or algorithmically adaptable to the environmental signals from other entities thus able to be settled down together into “new sensor/processor/actuator affiliations.” Brain-Machine Interface (BMI), developed by Nicolelis Lab at Duke University as a prototype of the future neuroprosthetics, shows a specific example of these networks of things; in which mutual adaptations of the technologically augmented entities—namely neurons and robot limbs—associate artificial sensory-motor circuits, programming its human/animal users' possible motor behaviors as well as their motor intentions.}
}
@article{MONTORI2020225,
title = {Performance evaluation of hybrid crowdsensing systems with stateful CrowdSenSim 2.0 simulator},
journal = {Computer Communications},
volume = {161},
pages = {225-237},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.07.021},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420309361},
author = {Federico Montori and Luca Bedogni and Claudio Fiandrino and Andrea Capponi and Luciano Bononi},
keywords = {Mobile crowdsensing, Simulation, Modeling, Distributed algorithms},
abstract = {Mobile crowdsensing (MCS) has become a popular paradigm for data collection in urban environments. In MCS systems, a crowd supplies sensing information for monitoring phenomena through mobile devices. Depending on the degree of involvement of users, MCS systems can be participatory, opportunistic or hybrid, which combines strengths of above approaches. Typically, a large number of participants is required to make a sensing campaign successful which makes impractical to build and deploy large testbeds to assess the performance of MCS phases like data collection, user recruitment, and evaluating the quality of information. Simulations offer a valid alternative. In this paper, we focus on hybrid MCS and extend CrowdSenSim 2.0 in order to support such systems. Specifically, we propose an algorithm for efficient re-route users that would offer opportunistic contribution towards the location of sensitive MCS tasks that require participatory-type of sensing contribution. We implement such design in CrowdSenSim 2.0, which by itself extends the original CrowdSenSim by featuring a stateful approach to support algorithms where the chronological order of events matters, extensions of the architectural modules, including an additional system to model urban environments, code refactoring, and parallel execution of algorithms.}
}
@article{GHARBAOUI201640,
title = {An incentive-compatible and trust-aware multi-provider path computation element (PCE)},
journal = {Computer Networks},
volume = {108},
pages = {40-54},
year = {2016},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2016.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S1389128616302407},
author = {Molka Gharbaoui and Barbara Martini and Carol.J. Fung and Francesco Paolucci and Alessio Giorgetti and Piero Castoldi},
keywords = {Trust, Multi-domain, Multi-provider, Traffic engineering, PCE, Confidentiality, Security},
abstract = {In multi-domain backbone networks, the Path Computation Element (PCE) architecture provides effective traffic engineering while limiting the exposure of intra-domain information. However, returned path computations may still reveal confidential intra-domain information, if artfully correlated by a malicious PCE. In such cases, the cooperation among PCEs should consider not only the capability of providing feasible paths but also the likelihood of security breaches (e.g., confidentiality risk exposure). In fact, a PCE might have the interest to block a request if it is arriving from a malicious or a competitor provider. In this scenario, the PCEs cooperation could benefit from a trust management model that accounts for the quality of the past interactions in terms of security violations while avoiding abuse of path computation services. This work introduces the concepts of Trust Ranking and Quality of Interaction in PCE-based multi-domain backbone networks and elaborates a Bayes trust model to regulate the cooperation among PCEs. Specifically, the proposed trust management model aims at creating a common interest for the PCEs in contributing to effective traffic engineering while avoiding misuse of path computation services. Accordingly, we further propose a trust-aware PCE architecture and an incentive-compatible decision model that stimulate the behaviors of PCEs towards an effective cooperation. Simulation results show that the proposed trust model provides effective incentive-compatible service differentiation to collaborating domains and is effective in detecting malicious PCE behaviors thereby tuning the amount of information returned in the path computation replies.}
}
@article{ZHU2019101646,
title = {Measuring the efficiency and driving factors of urban land use based on the DEA method and the PLS-SEM model—A case study of 35 large and medium-sized cities in China},
journal = {Sustainable Cities and Society},
volume = {50},
pages = {101646},
year = {2019},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2019.101646},
url = {https://www.sciencedirect.com/science/article/pii/S2210670719304226},
author = {Xinhua Zhu and Peifeng Zhang and Yigang Wei and Yan Li and Hongrui Zhao},
keywords = {Urban land use, Efficiency evaluation, Driving factors, DEA, PLS-SEM, China},
abstract = {Using 35 large and medium-sized cities data during 2007–2015, this study aims to measure the efficiency of urban land use in different typical cities and estimate the effects of key driving factors. The novel integration of Super efficiency SBM model of data envelopment analysis (DEA) and Partial Least Squares Structural Equation Modeling (PLS-SEM) is introduced in land use study. This study finds that: 1) The urban land use efficiency (ULUE) shows strong characteristics of spatial heterogeneity, with sharply different efficiencies in different regions. 2) During 2007–2015, although the ULUE of the 35 cities was in fluctuating increase, the rate of increase was significantly low, with an average rise of 0.17%. 3) The driving factors of ULUE have been identified. The three Grade I indexes, including economic, infrastructure, and market, have a considerable positive influence on ULUE, with influencing coefficients being 0.329, 0.112, and 0.204 respectively; The Land System index has a significant negative influence, and its influencing coefficient is -0.177. Base on the findings, policy suggestions are proposed to improve the efficiency of China’s urban land use and promote sustainable urban development.}
}
@article{ZHANG202185,
title = {Multi-source information fusion based on rough set theory: A review},
journal = {Information Fusion},
volume = {68},
pages = {85-117},
year = {2021},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2020.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S1566253520304085},
author = {Pengfei Zhang and Tianrui Li and Guoqiang Wang and Chuan Luo and Hongmei Chen and Junbo Zhang and Dexian Wang and Zeng Yu},
keywords = {Multi-source information fusion, Rough set theory, Homogeneous and heterogeneous MSIF, Multi-view rough sets, Parallel computing, Incremental learning, Cluster ensembles},
abstract = {Multi-Source Information Fusion (MSIF) is a comprehensive and interdisciplinary subject, and is referred to as, multi-sensor information fusion which was originated in the 1970s. Nowadays, the types and updates of data are becoming more multifarious and frequent, which bring new challenges for information fusion to deal with the multi-source data. Consequently, the construction of MSIF models suitable for different scenarios and the application of different fusion technologies are the core problems that need to be solved urgently. Rough set theory (RST) provides a computing paradigm for uncertain data modeling and reasoning, especially for classification issues with noisy, inaccurate or incomplete data. Furthermore, due to the rapid development of MSIF in recent years, the methodologies of learning under RST are becoming increasingly mature and systematic, unveiling a framework which has not been mentioned in the literature. In order to better clarify the approaches and application of MSIF in RST research community, this paper reviews the existing models and technologies from the perspectives of MSIF model (i.e., homogeneous and heterogeneous MSIF model), multi-view rough sets information fusion model (i.e., multi-granulation, multi-scale and multi-view decisions information fusion models), parallel computing information fusion model, incremental learning fusion technology and cluster ensembles fusion technology. Finally, RST based MSIF related research directions and challenges are also covered and discussed. By providing state-of-the-art understanding in specialized literature, this survey will directly help researchers understand the research developments of MSIF under RST.}
}
@article{ETESAMI2020109148,
title = {Smart routing of electric vehicles for load balancing in smart grids},
journal = {Automatica},
volume = {120},
pages = {109148},
year = {2020},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2020.109148},
url = {https://www.sciencedirect.com/science/article/pii/S0005109820303460},
author = {S. Rasoul Etesami and Walid Saad and Narayan B. Mandayam and H. Vincent Poor},
keywords = {Smart grids, Electric vehicles, Load balancing, Selfish routing, Distributed control, Price of anarchy, Prospect theory},
abstract = {Electric vehicles (EVs) are expected to be a major component of the smart grid. The rapid proliferation of EVs will introduce an unprecedented load on the existing electric grid due to the charging/discharging behavior of the EVs, thus motivating the need for novel approaches for routing EVs across the grid. In this paper, a novel distributed control framework based on noncooperative game theory for routing of EVs within the smart grid is proposed. The goal of this framework is to control and balance the electricity load in a distributed manner across the grid while taking into account the traffic congestion and the waiting time at charging stations. The EV routing problem is formulated as a repeated game, and it is shown that the selfish behavior of EVs will result in a pure-strategy Nash equilibrium with the price of anarchy upper bounded by the ratio of the variance of the ground load to the total number of EVs in the grid. In particular, it is shown that any achieved Nash equilibrium substantially improves the load balance across the grid. Moreover, the results are extended to capture the stochastic nature of induced ground load as well as the subjective behavior of the EV owners using the behavioral framework of prospect theory. Simulation results provide new insights on efficient energy pricing at charging stations and under realistic grid conditions.}
}
@article{EVER202081,
title = {Performance evaluation of hybrid disaster recovery framework with D2D communications},
journal = {Computer Communications},
volume = {152},
pages = {81-92},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.01.021},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419316433},
author = {Enver Ever and Eser Gemikonakli and Huan X. Nguyen and Fadi Al-Turjman and Adnan Yazici},
keywords = {Public safety networks, D2D communications, Relay nodes, Tandem queues, Analytical Modeling},
abstract = {Public Safety Networks (PSNs) provide assistance before- and post-disaster events. With the help of technological advances, PSNs are able to cope with both natural and man-made disasters, protecting people, environment and property. Effective communications, better situational awareness, lower response times and greater emergency efficiency are essential to an effective response to emergencies and disasters. Long Term Evolution (LTE) has been chosen to be the key technology for public safety networks. In this study, a performance model is presented for the PSN frameworks which use cooperative devices with LTE device to device (D2D) communications features. Mobile stations that are out of cellular network coverage range use D2D communications, where mobile stations which are in a healthy area can act as relay nodes to provide information about the location of potential victims to a central system. Since relay nodes have the potential to become bottlenecks for relatively high scale disasters, the interaction between the relay node and the base station is critically considered in this study. The analytical model and solution are suitable for assessing the quality of service for PSNs with similar infrastructures. Results obtained from the analytical model are presented comparatively with those from discrete event simulations for validation. The maximum discrepancy between the results obtained from the analytical model and the simulation results is less than 1.4%, which is within the confidence interval of the simulation.}
}
@article{AMIN2021102729,
title = {Software-Defined Network enabled Vehicle to Vehicle secured data transmission protocol in VANETs},
journal = {Journal of Information Security and Applications},
volume = {58},
pages = {102729},
year = {2021},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2020.102729},
url = {https://www.sciencedirect.com/science/article/pii/S2214212620308681},
author = {Ruhul Amin and Isha Pali and Venkatasamy Sureshkumar},
keywords = {SDN, RSU compromisation attack, Scyther simulation},
abstract = {Software-Defined Network (SDN) improves the performance of the network model by managing the whole system through a programmed software. Nowadays, the concept of SDN can be applied in several application areas such as Wireless Sensor Network (WSN), Internet of Things (IoT) communications, cloud–fog computing, Vehicular Ad-hoc Networks (VANETs), etc. To improve the overall network performance, we have integrated SDN technology in the VANET system for Vehicle to Vehicle(V2V) communication. Security is a major concern in the SDN enabled VANET system. The main objective of this paper is to design an authentication protocol which will establish a common session key for secure communication. Further, this paper provides a solution to protect against the RSU compromisation attack which is always a challenging task. The simulation using the Scyther tool confirms that all the private information is being protected during the protocol run. Moreover, informal security analysis shows that the protocol has no security weaknesses. Besides, the proposed protocol achieves better performance in the aspect of security features and also in terms of computation and communication overheads.}
}
@article{MOSTERMAN2014259,
title = {Automating humanitarian missions with a heterogeneous fleet of vehicles},
journal = {Annual Reviews in Control},
volume = {38},
number = {2},
pages = {259-270},
year = {2014},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2014.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S136757881400042X},
author = {Pieter J. Mosterman and David {Escobar Sanabria} and Enes Bilgin and Kun Zhang and Justyna Zander},
abstract = {The use of technology for disaster response and relief in the aftermath of natural disasters is growing. To explore the opportunity afforded by emerging technologies, this work developed an experimental automated emergency response system. Given a set of requests from the field and infrastructure information, a high-level optimization method generates a mission plan for a fleet of autonomous vehicles, including ground vehicles, fixed-wing aircraft, and delivery rotorcraft. The mission plan assigns vehicles to a list of functions and locations to be visited. Internet technology integrates the various system elements and provides a unifying environment for the physical and the modeled world in cyberspace. Guidance and control enable the vehicles to autonomously execute their plans. The movements of the fleet vehicles including their dynamic behavior are illustrated in a virtual reality interface. Preliminary experiments with a small fleet of simulated vehicles show the feasibility of such an approach.}
}
@article{HUANG2020102179,
title = {Electric vehicle charging station locations: Elastic demand, station congestion, and network equilibrium},
journal = {Transportation Research Part D: Transport and Environment},
volume = {78},
pages = {102179},
year = {2020},
issn = {1361-9209},
doi = {https://doi.org/10.1016/j.trd.2019.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S1361920919306406},
author = {Yantao Huang and Kara M. Kockelman},
keywords = {Electric vehicle charging stations, Battery electric vehicles, Genetic algorithm, Elastic demand, Network equilibrium},
abstract = {Battery-only electric vehicles (BEVs) generally offer better air quality through lowered emissions, along with energy savings and security. The issue of long-duration battery charging makes charging-station placement and design key for BEV adoption rates. This work uses genetic algorithms to identify profit-maximizing station placement and design details, with applications that reflect the costs of installing, operating, and maintaining service equipment, including land acquisition. Fast electric vehicle charging stations (EVCSs) are placed across a congested city's network subject to stochastic demand for charging under a user-equilibrium traffic assignment. BEV users’ station choices consider endogenously determined travel times and on-site charging queues. The model allows for congested-travel and congested-station feedback into travelers’ route choices under elastic demand and BEV owners’ station choices, as well as charging price elasticity for BEV charging users. Boston-network results suggest that EVCSs should locate mostly along major highways, which may be a common finding for other metro settings. If 10% of current EV owners seek to charge en route, a user fee of $6 for a 30-min charging session is not enough for station profitability under a 5-year time horizon in this region. However, $10 per BEV charging delivers a 5-year profit of $0.82 million, and 11 cords across 3 stations are enough to accommodate a near-term charging demand in this Boston-area application. Shorter charging sessions, higher fees, and/or allowing for more cords per site also increase profits generally, everything else constant. Power-grid and station upgrades should keep pace with demand, to maximize profits over time, and avoid on-site congestion.}
}
@article{LUTHRA2022321,
title = {An analysis of operational behavioural factors and circular economy practices in SMEs: An emerging economy perspective},
journal = {Journal of Business Research},
volume = {141},
pages = {321-336},
year = {2022},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2021.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0148296321009280},
author = {Sunil Luthra and Anil Kumar and Manu Sharma and Jose {Arturo Garza-Reyes} and Vikas Kumar},
keywords = {Circular Economy (CE), Operational Behavioural factors, SMEs, Exploratory Factor Analysis, Quantitative analysis},
abstract = {Circular Economy (CE) principles are relatively unexplored, especially in emerging economies. None of the studies so far have also explored operational behavioural factors and CE practices in the context of Small and Medium-sized Enterprises (SMEs). To address this gap, the present study explores operational behavioural factors that contribute to the adoption of CE practices in SMEs of emerging economies for the sustainable development of their societies. The study was conducted in three different phases. This involved an extensive literature review, a brainstorming session with experts, an empirical investigation based on 162 responses from SMEs, the development of a factors structure model employing Exploratory Factor Analysis (EFA) and building a Network Relationship Map (NRM). The study contributes to the theory of planned and operational behaviour by considering the influence of personal determinants in assessing the adoption of CE among SMEs to examine the behavioural factors that influence CE adoption in these organisations.}
}
@article{ASHRAF2019104,
title = {Energy management in harvesting enabled sensing nodes: Prediction and control},
journal = {Journal of Network and Computer Applications},
volume = {132},
pages = {104-117},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.01.015},
url = {https://www.sciencedirect.com/science/article/pii/S1084804519300232},
author = {Nouman Ashraf and Muhammad Faizan and Waqar Asif and Hassaan Khaliq Qureshi and Adnan Iqbal and Marios Lestas},
keywords = {Energy harvesting, Energy prediction, Internet of things, Wireless sensor networks, Markov chains, Energy management, Non-linear control},
abstract = {Energy efficient transmission rate regulation of wireless sensing nodes, is a critical issue when operating in an energy harvesting (EH) enabled environment. In this work, we view the energy management problem as a queue control problem where the objective is to regulate transmission such that the energy level converges to a reference value. We employ a validated non-linear queuing model to derive two non-linear robust throughput controllers. A notable feature of the proposed scheme is its capability of predicting harvest-able energy. The predictions are generated using the proposed Accurate Solar Irradiance prediction Model (ASIM) whose effectiveness in generating accurate both long and short term predictions is demonstrated using real world data. The stability of the proposed controllers is established analytically and the effectiveness of the proposed strategies is demonstrated using simulations conducted on the Network Simulator (NS-3). The proposed policy is successful in guiding the energy level to the reference value, and outperforms the Throughput Optimal (TO) policy in terms of the throughput achieved.}
}
@article{NIELSEN2013260,
title = {New and renewed developments in automotive control},
journal = {IFAC Proceedings Volumes},
volume = {46},
number = {21},
pages = {260-269},
year = {2013},
note = {7th IFAC Symposium on Advances in Automotive Control},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20130904-4-JP-2042.00169},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016383811},
author = {Lars Nielsen},
keywords = {Automotive models, vehicle experiments, co-simulators, drive cycles, maneuvers},
abstract = {There are currently new and renewed automotive trends that are made possible by new sensors, models, and methodologies. There is renewed interest in interpretation of in-cylinder phenomena, and for engines the approach of mean value modeling is maturing so that established modeling blocks can be combined in many new configurations like e.g. multiple turbo systems. For the vehicle as a whole there has been a dramatic development in experimental possibilities, since there now exist cost effective vehicle dynamometers and sensors for vehicle dynamics behavior. This has increased activities in realistic driving cycles and in optimal maneuvers. A final aspect is the integration with transportation and smart houses, which leads to overall city planning.}
}
@article{DAS2020108,
title = {A comprehensive review of wind–solar hybrid energy policies in India: Barriers and Recommendations},
journal = {Renewable Energy Focus},
volume = {35},
pages = {108-121},
year = {2020},
issn = {1755-0084},
doi = {https://doi.org/10.1016/j.ref.2020.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S1755008420300508},
author = {Alok Das and Hardik K. Jani and Garlapati Nagababu and Surendra Singh Kachhwaha},
abstract = {Wind and solar energy are currently the most prominent and reliable sources of renewable energy. Wind and solar power deployment largely depend on government policies and have a specific policy and regulatory provisions. The declaration of hybrid wind–solar policy has changed the dynamics of individual wind and solar power projects by introducing the scope for developing hybrid power projects to harness wind and solar energy simultaneously. The techno-economic structure and the existing scenarios of the fractional contribution of wind and solar sectors are going to play an important role in the development of hybrid power projects. This paper aims to present a comprehensive review of the impact of the existing individual wind and solar energy policies along with the recently declared hybrid policy in India and how this hybrid policy will affect the techno-economic structure of the existing and new power projects. Further, various kind of barriers faced by project developers while establishing renewable energy-based power projects and recommendations which can be practically implemented have been elaborated to facilitate and achieve the faster deployment of wind and solar power generation.}
}
@article{JENILA2021410,
title = {Green indoor optical wireless communication systems: Pathway towards pervasive deployment},
journal = {Digital Communications and Networks},
volume = {7},
number = {3},
pages = {410-444},
year = {2021},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2020.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S2352864820302650},
author = {C. Jenila and R.K. Jeyachitra},
keywords = {Data rate, Energy efficiency, Green communication, Infrared communication, Optical wireless communication, Visible light communication},
abstract = {The Optical Wireless Communication (OWC) offers the high capacity of optical fiber communication with the flexibility of wireless communication. Since it works in the optical region of the ElectroMagnetic (EM) spectrum, it guarantees safety and security which are critical in radio and microwave frequency communication. The principal objective of this paper is to analyze the indoor OWC systems on these guaranteed features, and safety and security are jointly denoted by the term green. The high obstacle impermeability of optical signals and their directivity strengthen the security of indoor OWC data transmission. The confidentiality and authenticity of optical wireless data can also be preserved with the Quantum Key Distribution (QKD). This paper provides a technological overview and a review of literature about the OWC system that helps to identify the challenges in the path of a ubiquitous deployment of green wireless communication systems. Significant advancements in the sources and detectors are discussed together with the coding, modulation and multiplexing techniques for making highly robust OWC links. The ubiquitous deployment of green OWC necessitates the development of optical transmitters and receivers, performance enhancement techniques, incorporation of uplink and energy harvesting abilities, and safety and security enhancement techniques. Hence, a special emphasis is placed on these aspects and their challenges towards the green implementation. Furthermore, the paper explores some significant indoor applications based on the OWC that have great impacts on the Next Generation Networks (NGN) and the Internet of Things (IoT).}
}
@article{CHIFOR2018740,
title = {A security authorization scheme for smart home Internet of Things devices},
journal = {Future Generation Computer Systems},
volume = {86},
pages = {740-749},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.05.048},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17311020},
author = {Bogdan-Cosmin Chifor and Ion Bica and Victor-Valeriu Patriciu and Florin Pop},
keywords = {IoT, Security, Identity, Embedded, Cloud computing, Smart home},
abstract = {The Internet of Things (IoT) is becoming an important factor in many areas of our society. IoT brings intelligence to critical aspects like transportation, industry, payments, health and many others. The interaction between embedded devices and Cloud based web services is a common scenario of IoT deployment. From the security point of view, both users and smart devices must establish a secure communication channel and have a form of digital identity. Most of the times, the usage of IoT devices requires an already existing infrastructure which cannot be controlled by the device owner, for instance in a smart home. This scenario requires a security stack suitable for heterogeneous devices which can be integrated in already existing operating systems or IoT frameworks. This paper proposes a lightweight authorization stack for smart-home IoT applications, where a Cloud-connected device relays input commands to a user’s smart-phone for authorization. This architecture is user-device centric and addresses security issues in the context of an untrusted Cloud platform.}
}
@article{ALFEO201819,
title = {Design and simulation of the emergent behavior of small drones swarming for distributed target localization},
journal = {Journal of Computational Science},
volume = {29},
pages = {19-33},
year = {2018},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2018.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S1877750318302898},
author = {Antonio L. Alfeo and Mario G.C.A. Cimino and Nicoletta {De Francesco} and Massimiliano Lega and Gigliola Vaglini},
keywords = {Swarm intelligence, Drone, Stigmergy, Flocking, Differential evolution, Target search},
abstract = {A swarm of autonomous drones with self-coordination and environment adaptation can offer a robust, scalable and flexible manner to localize objects in an unexplored, dangerous or unstructured environment. We design a novel coordination algorithm combining three biologically inspired processes: stigmergy, flocking and evolution. Stigmergy, a form of coordination exhibited by social insects, is exploited to attract drones in areas with potential targets. Flocking enables efficient cooperation between flock mates upon target detection, while keeping an effective scan. The two mechanisms can interoperate if their structural parameters are correctly tuned for a given scenario. Differential evolution adapts the swarm coordination according to environmental conditions. The performance of the proposed algorithm is examined with synthetic and real-world scenarios.}
}
@article{FERRARI2022106816,
title = {Drivers, barriers and impacts of digitalisation in rural areas from the viewpoint of experts},
journal = {Information and Software Technology},
volume = {145},
pages = {106816},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106816},
url = {https://www.sciencedirect.com/science/article/pii/S0950584921002469},
author = {Alessio Ferrari and Manlio Bacco and Kirsten Gaber and Andreas Jedlitschka and Steffen Hess and Jouni Kaipainen and Panagiota Koltsida and Eleni Toli and Gianluca Brunori},
keywords = {Software engineering, Requirements engineering, Sustainability requirements, Interviews, Digitalisation, Empirical study},
abstract = {Context:
The domain of rural areas, including rural communities, agriculture, and forestry, is going through a process of deep digital transformation. Digitalisation can have positive impacts on sustainability in terms of greater environmental control, and community prosperity. At the same time, it can also have disruptive effects, with the marginalisation of actors that cannot cope with the change. When developing a novel system for rural areas, requirements engineers should carefully consider the specific socio-economic characteristics of the domain, so that potential positive effects can be maximised, while mitigating negative impacts.
Objective:
The goal of this paper is to support requirements engineers with a reference catalogue of drivers, barriers and potential impacts associated to the introduction of novel ICT solutions in rural areas.
Method:
To this end, we interview 30 cross-disciplinary experts in digitalisation of rural areas, and we analyse the transcripts to identify common themes.
Results:
According to the experts, main drivers are economic, with the possibility of reducing costs, and regulatory, as institutions push for more precise tracing and monitoring of production; barriers are the limited connectivity, but also distrust towards technology and other socio-cultural aspects; positive impacts are socio-economic (e.g., reduction of manual labour, greater productivity), while negative ones include potential dependency from technology, with loss of hands-on expertise, and marginalisation of certain actors (e.g., small farms, subjects with limited education).
Conclusion:
This paper contributes to the literature with a domain-specific catalogue that characterises digitalisation in rural areas. The catalogue can be used as a reference baseline for requirements elicitation endeavours in rural areas, to support domain analysis prior to the development of novel solutions, as well as fit-gap analysis for the adaptation of existing technologies.}
}
@article{FENG2020119070,
title = {Integrated intelligent green scheduling of sustainable flexible workshop with edge computing considering uncertain machine state},
journal = {Journal of Cleaner Production},
volume = {246},
pages = {119070},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.119070},
url = {https://www.sciencedirect.com/science/article/pii/S095965261933940X},
author = {Yixiong Feng and Zhaoxi Hong and Zhiwu Li and Hao Zheng and Jianrong Tan},
keywords = {Intelligent green scheduling, Sustainable flexible workshop, Edge computing, Wireless sensor network, Uncertain machine state},
abstract = {Green scheduling plays an important role in green manufacturing. However, the uncertain interference events, especially sudden changes of machine state, and the improvement of processing quality are ignored in green scheduling. They result in the current green scheduling is one-sided for green manufacturing. Therefore, this paper proposes an integrated method for intelligent green scheduling of the sustainable flexible workshop with edge computing considering uncertain machine state. Firstly, a multi-objective model for green scheduling is built and solved with the makespan, processing cost, processing quality and energy consumption as its optimisation objectives. Then, a hardware system for intelligent monitoring and diagnosis of machine state is established based on wireless sensor network (WSN), edge computing and artificial intelligence (AI). Finally, the diagnosis results of machine state provide feedback to the original green scheduling scheme and the corresponding real-time adjustment called green rescheduling is conducted to response to uncertain dynamic machine state. A case study of intelligent green scheduling where several machines fall into fault operation suddenly is employed to illustrate the practicality and effectiveness of the proposed method, and it is compared with other multi-objective optimisation algorithms for green scheduling. The results indicate that the proposed method is superior to the rivals on this issue.}
}
@article{HILLEN201529,
title = {Geo-reCAPTCHA: Crowdsourcing large amounts of geographic information from earth observation data},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {40},
pages = {29-38},
year = {2015},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2015.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0303243415000665},
author = {Florian Hillen and Bernhard Höfle},
keywords = {User-generated geographic information, Volunteered geographic information, Crowdsourcing, reCAPTCHA, Geo-reCAPTCHA},
abstract = {The reCAPTCHA concept provides a large amount of valuable information for various applications. First, it provides security, e.g., for a form on a website, by means of a test that only a human could solve. Second, the effort of the user for this test is used to generate additional information, e.g., digitization of books or identification of house numbers. In this work, we present a concept for adapting the reCAPTCHA idea to create user-generated geographic information from earth observation data, and the requirements during the conception and implementation are depicted in detail. Furthermore, the essential parts of a Geo-reCAPTCHA system are described, and afterwards transferred, to a prototype implementation. An empirical user study is conducted to investigate the Geo-reCAPTCHA approach, assessing time and quality of the resulting geographic information. Our results show that a Geo-reCAPTCHA can be solved by the users of our study on building digitization in a short amount of time (19.2s on average) with an overall average accuracy of the digitizations of 82.2%. In conclusion, Geo-reCAPTCHA has the potential to be a reasonable alternative to the typical reCAPTCHA, and to become a new data-rich channel of crowdsourced geographic information.}
}
@article{ASLAM2020101759,
title = {FoNAC - An automated Fog Node Audit and Certification scheme},
journal = {Computers & Security},
volume = {93},
pages = {101759},
year = {2020},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2020.101759},
url = {https://www.sciencedirect.com/science/article/pii/S0167404820300432},
author = {Mudassar Aslam and Bushra Mohsin and Abdul Nasir and Shahid Raza},
keywords = {Fog, Edge, Cloud computing, Continuous auditing, TPM 2.0, Remote attestation, Certification, Security, SLA},
abstract = {Meeting the security and privacy needs for IoT data becomes equally important in the newly introduced intermediary Fog Computing layer, as it was in its former technological layer - Cloud; but the accomplishment of such security is critical and challenging. While security assurance of the fog layer devices is imperative due to their exposure to the public Internet, it becomes even more complex, than the cloud layer, as it involves a large number of heterogeneous devices deployed hierarchically. Manual audit and certification schemes are unsuitable for large number of fog nodes thereby inhibiting the involved stakeholders to use manual security assurance schemes altogether. However, scalable and feasible security assurance can be provided by introducing automated and continuous monitoring and auditing of fog nodes to ensure a trusted, updated and vulnerability free fog layer. This paper presents such an solution in the form of an automated Fog Node Audit and Certification scheme (FoNAC) which guarantees a secure fog layer through the proposed fog layer assurance mechanism. FoNAC leverages Trusted Platform Module (TPM 2.0) capabilities to evaluate/audit the platform integrity of the operating fog nodes and grants certificate to the individual node after a successful security audit. FoNAC security is also validated through its formal security analysis performed using AVISPA under Dolev-Yao intruder model. The security analysis of FoNAC shows its resistance against cyber-attacks like impersonation, replay attack, forgery, Denial of Service(DoS) and MITM attack.}
}
@article{MAGDALINOS2017184,
title = {A context extraction and profiling engine for 5G network resource mapping},
journal = {Computer Communications},
volume = {109},
pages = {184-201},
year = {2017},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2017.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0140366417306722},
author = {Panagis Magdalinos and Sokratis Barmpounakis and Panagiotis Spapis and Alexandros Kaloxylos and Georgios Kyprianidis and Apostolis Kousaridas and Nancy Alonistioti and Chan Zhou},
keywords = {5G network, User profiling, Data mining, Network optimization},
abstract = {Future 5G network ecosystems comprise a plethora of 3GPP and non 3GGP Radio Access Technologies - RATs. Deployment scenarios envision a multi-layer use of macro, micro and femto-cells where multi-mode end devices, supporting different applications, are served by different technologies. The association of end devices to the most appropriate RAT/layer will therefore become a tantalizing process necessitating the introduction of mechanisms that decide and execute an optimal mapping. The latter is of paramount importance since sub-optimal configuration of network components will affect overall network performance. Towards this end, we introduce the Context Extraction and Profiling Engine (CEPE), a knowledge discovery (KDD) framework catering for the extraction and exploitation of user behavioral patterns from network and service information. An eNB exploits the knowledge scheme derived by CEPE in order to improve the placement of end devices to RATs/layers. In the context of this paper, we provide a thorough analysis of existing standards, research papers and patents, discuss the main innovation of our proposal and highlight the differences with existing schemes. Building on use cases involving mobility management mechanisms that typically affect device to technology mapping (i.e. cell (re)selection, handover) we provide an extensive set of experiments that demonstrate the validity and viability of our idea. Overall evaluation showcases that CEPE achieves high quality results thus emerging as a viable approach for network optimization in future 5G environments.}
}
@article{LIN2021109714,
title = {Synthesis of covert actuator and sensor attackers},
journal = {Automatica},
volume = {130},
pages = {109714},
year = {2021},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2021.109714},
url = {https://www.sciencedirect.com/science/article/pii/S000510982100234X},
author = {Liyong Lin and Rong Su},
keywords = {Cyber physical systems, Supervisory control, Discrete event systems, Actuator attack, Sensor attack, Covert attack},
abstract = {In this work, we shall investigate the problem of covert attacker synthesis in the framework of supervisory control of discrete-event systems. Intuitively, the covertness property says that the attacker cannot reach a situation where its existence has been detected by the supervisor while no damage can be caused. We consider covert attackers that can exercise both actuator attacks (including enablement attacks and disablement attacks) and sensor attacks (restricted to sensor replacement attacks), where the (partial-observation) attackers may or may not eavesdrop the control commands issued by the supervisor. We shall develop an exponential time reduction from the covert attacker synthesis problem to the well studied Ramadge–Wonham supervisor synthesis problem, which generalizes our previous work on a reduction based approach for covert actuator attacker synthesis, for both the damage-reachable goal and the damage-nonblocking goal. We also provide discussions on conditions under which the exponential blowup in state sizes, due to the reduction construction, can be avoided.}
}
@article{PRIYANKA2020100127,
title = {Integrating IoT with LQR-PID controller for online surveillance and control of flow and pressure in fluid transportation system},
journal = {Journal of Industrial Information Integration},
volume = {17},
pages = {100127},
year = {2020},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2020.100127},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X20300030},
author = {E.B. Priyanka and C. Maheswari and S. Thangavel and M. Ponni Bala},
keywords = {Integrated IoT architecture, Fluid transportation system, Automation and control system, IoT module},
abstract = {In the modern upgradation era, monitoring and control system is essential to ensure the smooth operation of the long-distance pipeline in the fluid transportation system. Now-a-days, to design an accurate online monitoring and control system represents a critical task that requires proactive planning in fluid transportation system. In the fluid pipeline system, the huge amount of fluid loss caused by leakages, cracks and blockages due to extreme pressure changes in the pipelines during transportation. The present research work focuses on developing Integrated IoT based intelligent architecture to perform online monitoring and control of pressure and flow rate in the fluid transportation system. The proposed Integrtaed IoT based architecture holds SCADA with LQR-PID controller as local control unit or local intelliegnce. During crack and leak occurrences in the fluid pipeline, SCADA with PID controller cannot afford desired control action due to drastic change in the pressure and the flow rate. Hence the entire architecture is monitored and accessed through high-level online server IoT interface to identify leaks and cracks in the pipeline at the initial stage before it leads to any catastropic situations. In order to attain better data communication between cloud server and pipeline hardware setup, smart IoT module is designed and fabricated. Once the crack or leaks is identified in the IoT front end, immediately emergency shut off is activated by the cloud server through smart IoT module by stopping the pump. The developed Integrated IoT architecture is experimentally validated in real-time lab-scale fluid transportation pipeline system. Further in this present work, the performance of Linear Quadratic Regulator-PID controller to regulate pressure and flow rate of the fluid being tansported is analyzed by comparing with convnetional controllers like Internal-Mode controller and Zigler–Nichols controller.}
}
@article{KASAMATSU201727,
title = {Effective opportunistic dissemination of spatio-temporal contents in mobile environments},
journal = {Pervasive and Mobile Computing},
volume = {42},
pages = {27-44},
year = {2017},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2017.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1574119216301055},
author = {Daisuke Kasamatsu and Peizhao Hu and Mohan Kumar},
keywords = {Opportunistic environments, Content dissemination, Analytical framework, Spatio-temporal reachability graphs},
abstract = {Dissemination of spatio-temporally valid content from content providers to consumers is critical in certain application contexts as data items could lose their validity across time and space. Content sharing in challenged opportunistic environments remains a research challenge as existing solutions fail to exploit dissemination patterns across spatio-temporal limits. In this paper, we propose spatio-temporal reachability graphs to depict reachability of time- and space-sensitive content in opportunistic mobile environments. Furthermore, we develop an analytical framework to estimate content distribution in such environments and validate its feasibility over long-term datasets. We perform extensive trace-driven simulation studies to determine content dissemination properties of environments with known mobility patterns. The analytical framework estimates dissemination ratio, optimizes parameter setting, and tests transmission capacities of opportunistic environments. Proposed scheme is useful to content providers as well as receivers.}
}
@article{JIBREEL2020101023,
title = {Performance analysis of sparse code multiple access with variant MIMO techniques},
journal = {Physical Communication},
volume = {39},
pages = {101023},
year = {2020},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2020.101023},
url = {https://www.sciencedirect.com/science/article/pii/S187449071930610X},
author = {Nareeman Jibreel and Salma Elkawafi and Abdelhamid Younis and Raed Mesleh},
keywords = {Sparse code multiple access (SCMA), Multiple-input multiple-output (MIMO), Generalized spatial modulation (GSM), Spatial modulation (SM), Spatial multiplexing (SMX), Space shift keying (SSK)},
abstract = {Performance analysis, in terms of the (ABER), mutual information and theoretical capacity, for sparse code multiple access (SCMA) with variant multiple-input multiple-output (MIMO) techniques is presented and thoroughly discussed in this article. In particular, novel combination between space modulation techniques (SMTs) and SCMA is proposed and analyzed. As well, the performance of spatial multiplexing (SMX)-SCMA MIMO system is presented and used as a benchmark for the sake of comparison. Additionally, several designs for the mother constellation (MC) matrices are studied and their impact on the performance of the considered MIMO system is investigated. It is reported that different MC designs can lead to different performance and the performance of both MIMO systems can be optimized based on the considered codebook design. The closed-form analytical upper bound of the ABER over Rayleigh, Rician and Nakagami-m fading channels is derived and corroborated through Monte Carlo simulation results. Also, the theoretical capacity and the mutual information for SCMA–SMTS and SCMA–SMX MIMO systems are derived and studied over the considered fading channels. Monte-Carlo simulation results reveal that the derived capacity is the true upper bound for the simulated mutual information results and the conditions under which the capacity can be achieved are discussed. The performances of the considered SCMA–MIMO systems are compared to (OFDMA)–MIMO systems and significant gains are reported.}
}
@article{REZAZADEH2019217,
title = {A sub-modular receding horizon approach to persistent monitoring for a group of mobile agents over an urban area},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {20},
pages = {217-222},
year = {2019},
note = {8th IFAC Workshop on Distributed Estimation and Control in Networked Systems NECSYS 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.161},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319320129},
author = {Navid Rezazadeh and Solmaz S. Kia},
keywords = {Multi-agent systems, Persistent monitoring, Submodular optimization},
abstract = {We consider the problem of persistent monitoring of a finite number of interconnected geographical nodes for event detection via a group of heterogeneous mobile agents. We assume that the probability of the events occurring at the geographical points of interest follow known Poisson processes. We tie a utility function to the probability of detecting an event in each point of interest and use it to incentivize the agents to visit the geographical nodes with higher probability of event occurrence. We show that the design of an optimal monitoring policy that specifies the sequence of the geographical nodes and time of visit of those nodes for each mobile agent so that the utility of event detection over a mission horizon is maximized is an NP-hard problem. To reduce the time complexity of constructing the feasible set of the optimal approach and also to induce robustness to changes in event occurrence and other operational factors, we consider a receding horizon approach. We note that, with the number of agents growing, the cost of finding the optimal path grows exponentially even with shortened horizon. To overcome this issue, we introduce a sub-modular optimization approach that has a polynomial time complexity and also comes with a known sub-optimality lower bound. We demonstrate our results through simulations.}
}
@article{SMAHI2020101195,
title = {A blockchainized privacy-preserving support vector machine classification on mobile crowd sensed data},
journal = {Pervasive and Mobile Computing},
volume = {66},
pages = {101195},
year = {2020},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2020.101195},
url = {https://www.sciencedirect.com/science/article/pii/S1574119220300651},
author = {Abla Smahi and Qi Xia and Hu Xia and Nantogma Sulemana and Ahmed Ameen Fateh and Jianbin Gao and Xiaojiang Du and Mohsen Guizani},
keywords = {Mobile crowd sensing, Blockchain, Smart contract, State channels, SVM, Secure multiparty computation, Secure dot product},
abstract = {The voluminous amount of data generated by individuals’ mobile sensors and wearable devices is considered of a great value for the benefits of patients and clinical research. Recent advances incorporating data mining and cloud computing have leveraged the great potential of these data. However, the introduction of such technologies in the process of mobile crowd sensed data mining and analytics could potentially lead to security and privacy concerns. Individuals and organizations are not able to share and collectively run computations on their private data captured by different sensors to infer any processes of common interest. Although solutions such as Secure Multiparty Computation (SMC) were laid decades ago, they are still perceived for theoretical interest only, so far. In this paper, we aim at bridging the gap between privacy-preserving data mining and its practice. To do so, we introduce a blockchain-based privacy-preserving SVM classification (BPPSVC) between mutually distrustful data owners. In BPPSVC, blockchain technology along with smart contracts underlay more realistic assumptions about the adversarial model. Our main focus is on investigating the immutability, security and the bookkeeping properties of the blockchain in preserving the privacy of an SVM classifier over horizontally distributed IoT data. To this end, we first propose the system architecture, adversary model and design goals of BPPSVC, then we describe the design details. Our security analysis indicates that the proposed system is secure and it provides fairness and protection against Denial of Service (DoS) attacks. We finally show the efficiency and feasibility of BPPSVC through rigorous experimental results.}
}
@article{BERA202191,
title = {Private blockchain-based access control mechanism for unauthorized UAV detection and mitigation in Internet of Drones environment},
journal = {Computer Communications},
volume = {166},
pages = {91-109},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420320119},
author = {Basudeb Bera and Ashok Kumar Das and Anil Kumar Sutrala},
keywords = {Internet of drones (IoD), UAV detection and mitigation, Access control, Blockchain, Security, AVISPA},
abstract = {Drones, which are also known as Unmanned Aerial Vehicles (UAVs), are very useful in delivering the packages, and real-time object detection and tracking with minimal human interference. However, there may be several security threats in such an environment, for instance, a malicious user can spy unauthorized drones, transfer malicious packages, or even damage the network reliability that can have direct impact on drones control. This may lead to a potential threat for people, governments, and business sectors. To deal with these issues, in this paper, we propose a novel access control scheme for unauthorized UAV detection and mitigation in an Internet of Drones (IoD) environment, called ACSUD-IoD. With the help of the blockchain-based solution incorporated in ACSUD-IoD, the transactional data having both the normal secure data from a drone (UAV) to the Ground Station Server (GSS) and the abnormal (suspected) data for detection of unauthorized UAVs by the GSS are stored in private blockchain, that are authentic and genuine. As a result, the Big data analytics can be performed on the authenticated transactional data stored in the blockchain. Through the detailed security analysis including formal security under the broadly-accepted Real-Or-Random (ROR) model, formal security verification using the widely-applied Automated Validation of Internet Security Protocols and Applications (AVISPA) tool and non-mathematical security analysis show the robustness of the proposed scheme against a number of potential attacks needed in an IoD environment. The testbed experiments for various cryptographic primitives using the broadly-accepted Multiprecision Integer and Rational Arithmetic Cryptographic Library (MIRACL) have been performed under both server and Raspberry PI 3 configurations. Furthermore, a detailed comparative analysis among the proposed scheme and other existing competing schemes shows the efficacy and more robustness as compared to the existing schemes. Finally, the blockchain-based practical demonstration shows the effectiveness of the proposed scheme.}
}
@article{WANG2019172,
title = {Capability of Sentinel-2 MSI data for monitoring and mapping of soil salinity in dry and wet seasons in the Ebinur Lake region, Xinjiang, China},
journal = {Geoderma},
volume = {353},
pages = {172-187},
year = {2019},
issn = {0016-7061},
doi = {https://doi.org/10.1016/j.geoderma.2019.06.040},
url = {https://www.sciencedirect.com/science/article/pii/S0016706119304100},
author = {Jingzhe Wang and Jianli Ding and Danlin Yu and Xuankai Ma and Zipeng Zhang and Xiangyu Ge and Dexiong Teng and Xiaohang Li and Jing Liang and Ivan Lizaga and Xiangyue Chen and Lin Yuan and Yahui Guo},
keywords = {Sentinel-2, Soil salinity, Red-edge, Spectral indices, Remote sensing},
abstract = {Soil salinization is one of the most important causes for land degradation and desertification and is an important threat to land management, farming activities, water quality, and sustainable development in arid and semi-arid areas. Soil salinization is often characterized with significant spatiotemporal dynamics. The salt-affected soil is predominant in the Ebinur Lake region in the Northwestern China. However, detailed local soil salinity information is ambiguous at the best due to limited monitoring techniques. Nowadays, the availability of Multi-Spectral Instrument (MSI) onboard Sentinel-2, offers unprecedented perspectives for the monitoring and mapping of soil salinity. The use of MSI data is an innovative attempt for salinity detection in arid land. We hypothesize that field observations and MSI data and MSI data-derived spectral indices using the partial least square regression (PLSR) approach will yield fairly accurate regional salinity map. Based on electrical conductivity of 1:5 soil:water extract (EC) of 72 ground-truth measurements (out of 116 sample sites) and various spectral parameters, such as satellite band reflectance, published satellite salinity indices, red-edge indices, newly constructed two-band indices, and three-band indices from MSI data, we built a few inversion models in an attempt to produce the regional salinity maps. Different algorithms including Pearson correlation coefficient method (PCC), variable importance in projection (VIP), Gray relational analysis (GRA), and random forest (RF) were applied for variable selection. The results suggest that both the newly proposed normalized difference index (NDI) [(B12 − B7) / (B12 + B7)] and three-band index (TBI4) [(B12 − B3) / (B3 − B11)] show a better correlation with validation data and could be applied to estimate the soil salinity in the Ebinur Lake region. The established models were validated using the remaining 44 independent ground-based measurements. The RF-PLSR model performed the best across the five models with R2V, RMSEV, and RPD of 0.92, 7.58 dS m−1, and 2.36, respectively. The result from this model was then used to map the soil salinity over the study area. Our analyses suggest that soil salinization changes quite significantly in different seasons. Specifically, soil salinity in the dry season was higher than in the wet season, mostly in the lake area and nearby shores. We contend that the results from the study will be useful for soil salinization monitoring and land reclamation in arid or semi-arid regions outside the current study area.}
}
@article{SALMENTO2017145,
title = {An enhanced receiver for an impulsive UWB-based PLC system for low-bit rate applications},
journal = {Digital Signal Processing},
volume = {70},
pages = {145-154},
year = {2017},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2017.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S1051200417301872},
author = {Marlon Lucas Gomes Salmento and Eduardo {Pestana de Aguiar} and Ândrei Camponogara and Moisés Vidal Ribeiro},
keywords = {Power line communication, Impulsive ultra wideband modulation, Reduced rank adaptive filter, Computational complexity, Convergence speed},
abstract = {This paper focuses on the convergence speed improvement and the computational complexity reduction during the training phase of a receiver based on reduced rank adaptive filter, which is applied to a power line communication system based on impulsive ultra wideband modulation. In this regard, the use of variable step-size, set-membership, and soft threshold into the training phase of a reduced rank adaptive filter is introduced. In order to evaluate the effectiveness of our proposal, performance analyses with measured in-home and outdoor power line channels distorted by additive noise, which are modeled as white Gaussian and impulsive Gaussian, are carried out. Based on the numerical results, we show that the convergence speed can be considerably improved with the proposed enhancement for training this adaptive filter. Regardless the types of adopted additive noises and power line channels, we show that the improved convergence speed results in low bit error rate if the number of training symbol is reduced, which is a severe constraint associated with the coherence time of power line channels. Moreover, we show that the use of epochs during the training phase is convenient to deal with short coherence time. Performance comparisons with other receivers show that the proposal is more effective to deal with the hardness of power line channels. Moreover, computational complexity comparison shows that the proposed improvement demands less computational complexity than its predecessors. Finally, we show that proposal yields a receiver that outperforms the receivers based on matched filter or a combination of matched filter with the median filter, when similar computational complexity applies.}
}
@article{TRIANTAFYLLOU2021107735,
title = {Leveraging fairness in LoRaWAN: A novel scheduling scheme for collision avoidance},
journal = {Computer Networks},
volume = {186},
pages = {107735},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107735},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620313232},
author = {Anna Triantafyllou and Panagiotis Sarigiannidis and Thomas Lagkas and Ioannis D. Moscholios and Antonios Sarigiannidis},
keywords = {Low-Power Wide Area Networks, LoRaWAN, LoRa, Internet of Things, Medium Access Control, Collision avoidance, Fairness, Scalability},
abstract = {The employment of Low-Power Wide Area Networks (LPWANs) has proven quite beneficial to the advancement of the Internet of Things (IoT) paradigm. The utilization of low power but long range communication links of the LoRaWAN technology promises low energy consumption, while ensuring sufficient throughput. However, due to LoRa’s original scheduling process there is a high chance of packet collisions, compromising the technology’s reliability. In this paper, we propose a new Medium Access Control (MAC) protocol, entitled the FCA-LoRa leveraging fairness and improving collision avoidance in LoRa wide-area networks. The novel scheduling process that is introduced is based on the broadcasting of beacon frames by the network’s gateway in order to synchronize communication with end devices. Our results demonstrate the benefits of FCA-LoRa over an enhanced version of the legacy LoRaWAN employing the ALOHA protocol and an advanced adaptive rate mechanism, in terms of throughput and collision avoidance. Indicatively, in a single gateway scenario with 600 nodes, FCA-LoRa can increase throughput by nearly 50%while in a multiple gateway scenario, throughput reaches an increase of 49% for 500 nodes.}
}
@article{COLLOTTA20155403,
title = {A novel approach for dynamic traffic lights management based on Wireless Sensor Networks and multiple fuzzy logic controllers},
journal = {Expert Systems with Applications},
volume = {42},
number = {13},
pages = {5403-5415},
year = {2015},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2015.02.011},
url = {https://www.sciencedirect.com/science/article/pii/S0957417415001104},
author = {Mario Collotta and Lucia {Lo Bello} and Giovanni Pau},
keywords = {Road-traffic management, Dynamic management of traffic lights, Fuzzy logic controllers},
abstract = {This paper proposes a novel approach to dynamically manage the traffic lights cycles and phases in an isolated intersection. The target of the work is a system that, comparing with previous solutions, offers improved performance, is flexible and can be implemented on off-the-shelf components. The challenge here is to find an effective design that achieves the target while avoiding complex and computationally expensive solutions, which would not be appropriate for the problem at hand and would impair the practical applicability of the approach in real scenarios. The proposed solution is a traffic lights dynamic control system that combines an IEEE 802.15.4 Wireless Sensor Network (WSN) for real-time traffic monitoring with multiple fuzzy logic controllers, one for each phase, that work in parallel. Each fuzzy controller addresses vehicles turning movements and dynamically manages both the phase and the green time of traffic lights. The proposed system combines the advantages of the WSN, such as easy deployment and maintenance, flexibility, low cost, noninvasiveness, and scalability, with the benefits of using four parallel fuzzy controllers, i.e., better performance, fault-tolerance, and support for phase-specific management. Simulation results show that the proposed system outperforms other solutions in the literature, significantly reducing the vehicles waiting times. A proof-of-concept implementation on an off-the-shelf device proves that the proposed controller does not require powerful hardware and can be easily implemented on a low-cost device, thus paving the way for extensive usage in practice.}
}
@article{GONG2020148,
title = {High-performance spatiotemporal trajectory matching across heterogeneous data sources},
journal = {Future Generation Computer Systems},
volume = {105},
pages = {148-161},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.11.027},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19319880},
author = {Xuri Gong and Zhou Huang and Yaoli Wang and Lun Wu and Yu Liu},
keywords = {Distributed computing, Spatiotemporal big data, Trajectory similarity, Trajectory matching},
abstract = {In the era of big data, the movement of the same object or person can be recorded by different devices with different measurement accuracies and sampling rates. Matching and conflating these heterogeneous trajectories help to enhance trajectory semantics, describe user portraits, and discover specified groups from human mobility. In this paper, we proposed a high-performance approach for matching spatiotemporal trajectories across heterogeneous massive datasets. Two indicators, i.e., Time Weighted Similarity (TWS) and Space Weighted Similarity (SWS), are proposed to measure the similarity of spatiotemporal trajectories. The core idea is that trajectories are more similar if they stay close in a longer time and distance. A distributed computing framework based on Spark is built for efficient trajectory matching among massive datasets. In the framework, the trajectory segments are partitioned into 3-dimensional space–time cells for parallel processing, and a novel method of segment reference point is designed to avoid duplicated computation. We conducted extensive matching experiments on real-world and synthetic trajectory datasets. The experimental results illustrate that the proposed approach outperforms other similarity metrics in accuracy, and the Spark-based framework greatly improves the efficiency in spatiotemporal trajectory matching.}
}
@article{LIU2019881,
title = {Failure mode and effect analysis using multi-criteria decision making methods: A systematic literature review},
journal = {Computers & Industrial Engineering},
volume = {135},
pages = {881-897},
year = {2019},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2019.06.055},
url = {https://www.sciencedirect.com/science/article/pii/S0360835219303857},
author = {Hu-Chen Liu and Xu-Qi Chen and Chun-Yan Duan and Ying-Ming Wang},
keywords = {Reliability management, Failure mode and effect analysis (FMEA), Multi-criteria decision making (MCDM), Risk analysis, Literature review},
abstract = {Failure mode and effect analysis (FMEA) is a proactive reliability management technique extensively utilized in a variety of fields. To enhance the effectiveness of FMEA, a great many multi-criteria decision making (MCDM) methods have been applied for properly evaluating the risk of failure modes over the past two decades. However, there is a lack of study concerning systematic literature review and classification of the researches on this topic. This article aims to provide a comprehensive review of the FMEA studies using MCDM approaches for evaluation and prioritization of failure modes. To do so, a total of 169 journal papers extracted from the online database over the period of 1998–2018 were selected and reviewed. These publications were classified into 10 categories according to the used MCDM methods, and analyzed in regard to the risk factors, risk factor weighting methods, and risk assessment methods in FMEA. Furthermore, a bibliometric analysis was performed based on the frequency of MCDM methods, number of citations, year of publication, appeared journals, country of origin and application areas. This research supports academics and practitioners in effectively adopting MCDM methods to overcome the deficiencies of the traditional FMEA and provides an insight into its state-of-the-art.}
}
@article{BELLOUSMAN2018143,
title = {Toward trust based protocols in a pervasive and mobile computing environment: A survey},
journal = {Ad Hoc Networks},
volume = {81},
pages = {143-159},
year = {2018},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2018.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S1570870518304906},
author = {Aminu {Bello Usman} and Jairo Gutierrez},
keywords = {Trust-based routing protocol, Pervasive and mobile computing, Secure routing protocols, Device-to-device communication, Wireless mobile networks},
abstract = {In the blooming era of Pervasive and Mobile Computing, trust has been accepted as a vital factor for provisioning secure, reliable and seamless communications between pervasive computing elements. However, advancing research in the area of trust-based protocol for distributed Pervasive and Mobile Computing might be challenging due to the ambiguity of the concept of trust as well as the variety of divergent trust models, protocols and algorithms in different contexts. In this research, we augment the trust concept and definition from various field of studies and proposed models in the literature and provide general conceptual phases and methods of trust management toward-trust-based protocols, in the context of Pervasive and Mobile Computing. The paper addresses a broad range of techniques, methods, models, applications and desired futures of trust-based protocols. A number of the currently used trust-based protocols are critically reviewed, and this further leads our discussion to the security attacks and mitigation strategies used with trust-based protocols for pervasive and mobile computing. Finally, the paper discusses open research issues.}
}
@article{WISNIEWSKI201920,
title = {Decomposition of distributed edge systems based on the Petri nets and linear algebra technique},
journal = {Journal of Systems Architecture},
volume = {96},
pages = {20-31},
year = {2019},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2019.01.015},
url = {https://www.sciencedirect.com/science/article/pii/S1383762118303357},
author = {R. Wiśniewski and A. Karatkevich and Ł. Stefanowicz and M. Wojnakowski},
keywords = {Petri net, Decomposition, Edge computing, Distributed system},
abstract = {Edge computing, the architecture of cloud computing systems in which operations and computation tasks are shifted from the centralized cloud-based system to the devices being close to end users, has been gaining increasing popularity in recent years. Prototyping of such systems involves several tasks, including decomposition (splitting) of the system into distributed components. This paper proposes a novel decomposition algorithm oriented to the distributed edge systems specified by Petri nets. Formal proof of the correctness of the proposed algorithm is presented, together with corresponding theoretical results. The idea is illustrated by a real-life example of the distributed edge system. The experimental verification and comparison with the traditional decomposition technique gives proof of the efficiency of the proposed technique.}
}
@article{GARROPPO2018240,
title = {Anomaly detection mechanisms to find social events using cellular traffic data},
journal = {Computer Communications},
volume = {116},
pages = {240-252},
year = {2018},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2017.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0140366416306570},
author = {Rosario G. Garroppo and Saverio Niccolini},
keywords = {Discrete stationary wavelets transform, Anomaly detection, Cellular traffic, Social events, Spatial analysis, Time analysis},
abstract = {The design of new tools to detect on-the-fly traffic anomaly without scalability problems is a key point to exploit the cellular system for monitoring social activities. To this goal, the paper proposes two methods based on the wavelet analysis of the cumulative cellular traffic. The utilisation of the wavelets permits to easily filter “normal” traffic anomalies such as the periodic trends present in the cellular traffic. The two presented approaches, denoted as Spatial Analysis (SA) and Time Analysis (TA), differ on how they consider the spatial information of the traffic data. We examine the performance of the considered algorithms using cellular traffic data acquired from one the most important Italian Mobile Network Operator in the city of Milan throughout December 2013. The results highlight the weak points of TA and some important features of SA. Both approaches overcome the performance of one reference algorithm present in literature. The strategy used in the SA emerges as the most suitable for exploiting the spatial correlation when we aim at the detection of the traffic anomaly focused on the localisation of social events.}
}
@article{ELLOUZE201246,
title = {CITOM: An incremental construction of multilingual topic maps},
journal = {Data & Knowledge Engineering},
volume = {74},
pages = {46-62},
year = {2012},
note = {Applications of Natural Language to Information Systems},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2012.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X12000201},
author = {Nebrasse Ellouze and Nadira Lammari and Elisabeth Métais},
keywords = {Topic Map (TM), Incremental construction, Multilingual documents, Information retrieval, Thesaurus},
abstract = {This paper proposes the CITOM approach for an incremental construction of multilingual Topic Maps. Our main goal is to facilitate user's navigation across documents available in different languages. Our approach takes into account three types of information sources: (a) a set of multilingual documents, (b) a domain thesaurus and (c) all the possible questioning sources such as FAQ and user's or expert's requests about documents. In this paper we present the different steps of the proposed approach to construct the Topic Map and the pruning process of the generated Topic Map. We validate our approach with a real corpus from the sustainable construction domain.}
}
@article{ZHAO201983,
title = {Blockchain technology in agri-food value chain management: A synthesis of applications, challenges and future research directions},
journal = {Computers in Industry},
volume = {109},
pages = {83-99},
year = {2019},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2019.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0166361518305670},
author = {Guoqing Zhao and Shaofeng Liu and Carmen Lopez and Haiyan Lu and Sebastian Elgueta and Huilan Chen and Biljana Mileva Boshkoska},
keywords = {Blockchain technology, Systematic literature network analysis, Industry 4.0, Internet of things (IoT), Agri-food value chain digitisation},
abstract = {Agri-food value chain is an area of significant importance because of providing sustainable, affordable, safety and sufficient food, feed, fibre and fuel to consumers, it is critical to ensure these value chains running smoothly and successfully by applying advanced internet technologies. Blockchain technology is a new digital technological approach underpinned by the Industry 4.0 to ensuring data integrity and preventing tampering and single point failure through offering fault-tolerance, immutability, trust, transparency and full traceability of the stored transaction records to all agri-food value chain partners. This paper used systematic literature network analysis to review the state-of-the-art blockchain technology including its recent advances, main applications in agri-food value chain and challenges from a holistic perspective. The findings suggest that blockchain technology together with advanced information and communication technology and internet of things have been adopted for the improvement of agri-food value chain management in four main aspects: traceability, information security, manufacturing and sustainable water management. Six challenges have been identified including storage capacity and scalability, privacy leakage, high cost and regulation problem, throughput and latency issue, and lack of skills. Based on the critical analysis of literature, research gaps and future research directions are proposed in this paper regarding the applications and challenges of blockchain technology in agri-food value chain management. This study makes contributions to the extant literature in the field of agri-food value chain management by discovering the potential of blockchain technology and its implications for agri-food value chain performance improvements such as food safety, food quality and food traceability.}
}
@article{DASILVA2020101865,
title = {Multidimensional flood risk management under climate changes: Bibliometric analysis, trends and strategic guidelines for decision-making in urban dynamics},
journal = {International Journal of Disaster Risk Reduction},
volume = {50},
pages = {101865},
year = {2020},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2020.101865},
url = {https://www.sciencedirect.com/science/article/pii/S2212420920313674},
author = {Lucas Borges Leal {da Silva} and Marcelo Hazin Alencar and Adiel Teixeira {de Almeida}},
keywords = {Systematic literature review, Climate change, Flood risk management, Decision-making, Urban area},
abstract = {The inevitability of more frequent and more extensive floods, phenomena that display one aspect of the inherent variability of Nature, has been increasingly accepted by managers and policymakers. Climate changes due to global warming add considerable complexity to dealing with flooding, since increases in average temperature alter the patterns and intensity of precipitation. Thus, adverse events arising from natural hazards have tended to become even more frequent and their impacts more severe. Consequently, urban centers face a huge challenge and statistics already show the urgent need for all levels of government to review the adequacy of their plans for anticipating and combating extreme events. Therefore, this paper undertakes a systematic review of the literature, using well-founded and established search strategies, in order to determine the state-of-the-art as presented in 52 peer-reviewed articles strategically selected from two main sources of scientific data. Cross-matching important research metrics from these papers has enabled two axes of discussion to be detailed in this article: a bibliometric analysis and a content analysis. Among many findings, those that stand out are the lack of a formal methodology for climate modeling and the use and sharing of GIS tools, these being key-factors for developing new ways of visualizing risk. Finally, some guidelines for decision-making are put forward in order to share insights and to provide DMs, scholars, experts, stakeholders, and other professionals with an overall background of managerial aspects when engaging on applying flood risk management in urban areas.}
}
@article{SHEKHAR2020101710,
title = {URMILA: Dynamically trading-off fog and edge resources for performance and mobility-aware IoT services},
journal = {Journal of Systems Architecture},
volume = {107},
pages = {101710},
year = {2020},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2020.101710},
url = {https://www.sciencedirect.com/science/article/pii/S1383762120300047},
author = {Shashank Shekhar and Ajay Chhokra and Hongyang Sun and Aniruddha Gokhale and Abhishek Dubey and Xenofon Koutsoukos and Gabor Karsai},
keywords = {Fog computing, Edge computing, Cloud computing, User mobility, Latency-sensitive, IoT, Resource management, Performance interference, Latency, Offloading},
abstract = {The fog/edge computing paradigm is increasingly being adopted to support a range of latency-sensitive IoT services due to its ability to assure the latency requirements of these services while supporting the elastic properties of cloud computing. IoT services that cater to user mobility, however, face a number of challenges in this context. First, since user mobility can incur wireless connectivity issues, executing these services entirely on edge resources, such as smartphones, will result in a rapid drain in the battery charge. In contrast, executing these services entirely on fog resources, such as cloudlets or micro data centers, will incur higher communication costs and increased latencies in the face of fluctuating wireless connectivity and signal strength. Second, a high degree of multi-tenancy on fog resources involving different IoT services can lead to performance interference issues due to resource contention. In order to address these challenges, this paper describes URMILA, which makes dynamic resource management decisions to achieve effective trade-offs between using the fog and edge resources yet ensuring that the latency requirements of the IoT services are met. We evaluate URMILA’s capabilities in the context of a real-world use case on an emulated but realistic IoT testbed.}
}
@article{WANG2021110018,
title = {Optimal control of interconnected systems with time-correlated noises: Application to vehicle platoon},
journal = {Automatica},
pages = {110018},
year = {2021},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2021.110018},
url = {https://www.sciencedirect.com/science/article/pii/S0005109821005458},
author = {Yan Wang and Rong Su and Bohui Wang},
keywords = {Interconnected systems, LQG control, Optimal control, Time-correlated noises, Vehicle platoon},
abstract = {This paper studies the optimal state-feedback LQG control (OSLC) of interconnected systems (ISs) with time-correlated process noises. In an IS, the information is transmitted among subsystems via the network, and the transmission time is proportional to the distance of the corresponding subsystem pairs. This means that the information received by a subsystem includes the non-real-time information, and that the information from different subsystems may be of different time indexes. This makes the optimal controller design challenging. The OSLC of ISs with time-uncorrelated process noises is studied by an independence decomposition method in the existing literature. However, the existing independence decomposition method strongly relies on the condition that the process noises are time-uncorrelated, and fails for the time-correlated process noises case. In this paper, the globally optimal LQG controller of ISs with time-correlated process noises is successfully designed. In particular, a new cost function decomposition is obtained based on the Bellman equation. Both the system state and the control input are decomposed into two independent parts by the orthogonal decomposition technique. The proposed decomposition method leads to the successful design of the globally optimal controller. The proposed theoretical results are applied to a vehicle platoon system. The simulation shows that the platoon maintains a desired state and achieves a good performance under the proposed controller.}
}
@article{DEFARIAS2019109,
title = {A multi-sensor data fusion technique using data correlations among multiple applications},
journal = {Future Generation Computer Systems},
volume = {92},
pages = {109-118},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.09.034},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18307283},
author = {Claudio M. {de Farias} and Luci Pirmez and Giancarlo Fortino and Antonio Guerrieri},
keywords = {Wireless sensor networks, Data correlation, Hidden correlations, Overlapping intervals, Multisensor data fusion},
abstract = {While wireless sensor networks (WSNs) have been traditionally tasked with single applications, in recent years we have witnessed the emergence of WSNs that allow the sensing and communication infrastructure to be shared among multiple applications thus optimizing the use of resources. As the number of applications in a WSN increases, a growing amount of sensor-generated data will be produced, from which useful information can be extracted. A major requirement in these networks is to save energy in order to extend their operational lifetime. However, wireless sensors and actuators commonly rely on batteries as their energy sources, whose replacement is undesirable or unfeasible. Among the methods employed to extend network lifetime, Multisensor data fusion (MDF) is one of the most widely used. Traditional MDFs are not able to identify different contexts, since they are designed using an application-specific design for the network. As the number of applications increases, the application data ranges overlap and it becomes more complex to identify the origin of each data sample to deliver data to the correct application, with the consequence of reducing data accuracy. In order to overcome these limitations, we propose a MDF technique that divides the monitored interval into a set of intervals (non-overlapped intervals and overlapped intervals) and attributes each interval to an abstract sensor. Then we use MDFs to identify (hidden) correlations in abstract sensors and to exploit such knowledge to monitor the behavior of sensors during their working life. Our proposal is validated through simulations and tests on real nodes.}
}
@article{ZOU2021106831,
title = {Towards the optimality of service instance selection in mobile edge computing},
journal = {Knowledge-Based Systems},
volume = {217},
pages = {106831},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.106831},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121000940},
author = {Guobing Zou and Zhen Qin and Shuiguang Deng and Kuan-Ching Li and Yanglan Gan and Bofeng Zhang},
keywords = {Mobile edge computing, Edge service, Service instance selection, Genetic algorithm, Response time},
abstract = {Mobile edge computing (MEC) has been proposed to significantly reduce the response time of service invocations for end users. In MEC environment, a service provider can create multiple instances from a service and deploy them to different hired edge servers, where the deployed instances can be selected and invoked to decrease the network latency by nearby users. However, service instance selection in MEC is a challenging research problem from threefold aspects. First, the limitations of an edge server in terms of computation capacity and coverage range result in serving for only a certain number of users at the same time. Second, due to variable geographical locations from user mobility paths in MEC, the mobility of edge users is highly related to data transmission rate and affects the delay of service invocations. Furthermore, when many users in an edge server covered region request the same service instance at the same time, they interfere with each other and may reduce the experience of service invocations if there is no effective strategy to distribute these requests to appropriate instances deployed on different edge servers. To improve the user experience on service invocations with a lower response time, we take the above three factors into account and model the service instance selection problem (SISP) in MEC as an optimization problem, and propose a novel genetic algorithm-based approach with a response time-aware mutation operation with normalization for service instance selection called GASISMEC to find approximately optimal solution. Extensive experiments are conducted on two widely-used real-world datasets. The results demonstrate that our approach significantly outperforms the six baseline competing approaches.}
}
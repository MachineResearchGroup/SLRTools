@article{WANG2021103327,
title = {The dynamic bike repositioning problem with battery electric vehicles and multiple charging technologies},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {131},
pages = {103327},
year = {2021},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2021.103327},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X21003326},
author = {Yue Wang and W.Y. Szeto},
keywords = {Dynamic bike-repositioning problem, Rolling horizon method, Demand forecasting, Battery electric vehicles, Artificial bee colony algorithm},
abstract = {The bike-repositioning problem (BRP) primarily involves determining the routes and loading instructions for a fleet of vehicles that transport bikes between stations in a bike sharing system (BSS), to mitigate the mismatch between the demand for and supply of public bikes. However, the use of fossil-fueled vehicles for this repositioning task generates pollutants and greenhouse gases, which harm the environment. The use of battery electric vehicles (BEVs) instead of fossil-fueled vehicles for repositioning bikes can mitigate this negative environmental impact. On the other hand, user demand for bikes is dynamic during the daytime. Therefore, this study addresses the dynamic BRP with battery electric vehicles. Multiple charging technologies are available at charging stations to allow repositioning vehicles to recharge en-route at different speeds and costs. The objective is to solve the problem by minimizing the weighted sum of the penalty costs of unmet user demand and the charging costs of repositioning vehicles. A rolling horizon framework is adopted to incorporate the revealed inventory levels at bike stations, the BEV load of bikes, and the battery energy levels of BEVs at regular intervals. An artificial bee colony algorithm with an embedded dynamic programming method for computing the loading instructions is proposed to generate solutions. Computational experiments are conducted on a real-world BSS, and three aspects of the problem properties are analyzed: the horizon settings, the various penalties for failed rentals and returns, and the charging-related settings. The results provide practical insights into the use of BEVs for daily bike-repositioning tasks in BSSs.}
}
@article{WANG2020413,
title = {Migration strategy of cloud collaborative computing for delay-sensitive industrial IoT applications in the context of intelligent manufacturing},
journal = {Computer Communications},
volume = {150},
pages = {413-420},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419313775},
author = {Ke Wang},
keywords = {Intelligent manufacturing, Industrial Internet of Things, Cloud cooperation, Computing migration},
abstract = {In the context of intelligent manufacturing, machinery and equipment in the industrial manufacturing process form the “industrial Internet of Things.” In this process of interlocking production, the requirements for sensor data delay typically reach the millisecond level. Once the data is delayed, the equipment will be shut down, which will make the production difficult or dangerous. In the context of intelligent manufacturing, local computers have been unable to complete calculations and decisions quickly and on time for the huge computing demands. Therefore, the cloud computing migration mode needs to be introduced, but cloud computing migration will cause additional delays. Based on the above problems, this paper designs a cloud cooperative migration strategy based on the information exchange structure of the industrial Internet of Things and the delay mechanism caused by the migration. The feasibility of selecting the optimal migration strategy based on task partitioning is verified by simulation.}
}
@article{COPPOLINO2019100055,
title = {A comprehensive survey of hardware-assisted security: From the edge to the cloud},
journal = {Internet of Things},
volume = {6},
pages = {100055},
year = {2019},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2019.100055},
url = {https://www.sciencedirect.com/science/article/pii/S2542660519300101},
author = {Luigi Coppolino and Salvatore D’Antonio and Giovanni Mazzeo and Luigi Romano},
keywords = {Hardware-assisted security, IoT security, Cloud security, Edge computing, Trusted computing},
abstract = {Sensitive data processing occurs more and more on machines or devices out of users control. In the Internet of Things world, for example, the security of data could be posed at risk regardless the adopted deployment is oriented on Cloud or Edge Computing. In these systems different categories of attacks—such as physical bus sniffing, cold boot, cache side-channel, buffer overflow, code-reuse, or Iago—can be realized. Software-based countermeasures have been proposed. However, the severity and complexity of these attacks require a level of security that only the hardware support can ensure. In the last years, major companies released a number of architectural extensions aiming at provide hardware-assisted security to software. In this paper, we realize a comprehensive survey of HW-assisted technological solutions produced by vendors like Intel, AMD, and ARM for both embedded edge-devices and hosting machines such as cloud servers. The different approaches are classified based on the type of attacks prevented and the enforced techniques. An analysis on their mechanisms, issues, and market adoption is provided to support investigations of researchers approaching to this field of systems security.}
}
@article{GADELRAB2021109611,
title = {Towards a new generation of digital calibration certificate: Analysis and survey},
journal = {Measurement},
volume = {181},
pages = {109611},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.109611},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121005844},
author = {Mohammed S. Gadelrab and Reham A. Abouhogail},
keywords = {Measurement, Instrumentation, Digital calibration certificate, Traceability, Digital transformation, Metrology 4.0, Industry 4.0},
abstract = {Calibration Certificates (CC) are essential for maintaining the accuracy of measurement instruments, which in turn are necessary to maintain the quality of products and services. Such certificates are mainly used in legal metrology for quality audits, accreditation and examination processes; and also in the operational metrology to adjust measurement results according to device uncertainty. Paper-based CC (PCC) or a digital copy of the paper format has been successfully used for this purpose for many decades. However, the PCC starts to fail short with the emergence of new technologies and applications that require automated creation, processing and updates of the calibration certificates. The last years have witnessed an intense effort on digital transformation in metrology and especially developing Digital Calibration Certificates (DCC). Until recently, we noticed the lack of agreement on the nature and the usage of such important new metrology artifacts as well as some repetition in the work by different researchers. To help reaching a minimum consensus on the subject, we present in this paper, a thorough analysis of the calibration certificate and the calibration process. Besides that, we aim by this work to provide an overview of the carried research on that point to help peer researchers to view the big picture and to avoid wasting their efforts in repeating same work on same ideas. Consequently, they can recognize the peer researchers and organizations working on the same topics, find available resources, identify research gaps and identify the best potential directions of their efforts as well. Finally, our paper aims also to establish a bridge between the metrological concepts and information technology concepts such that more computer science researchers can be involved in solving the problem.}
}
@article{SRINIVASARAO202134,
title = {Performance evaluation of congestion aware transmission opportunity scheduling scheme for 802.11 wireless LANs},
journal = {International Journal of Intelligent Networks},
volume = {2},
pages = {34-41},
year = {2021},
issn = {2666-6030},
doi = {https://doi.org/10.1016/j.ijin.2021.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666603021000075},
author = {D. {Srinivasa Rao} and V. {Berlin Hency}},
keywords = {802.11, WLAN, Internet, TXOP, CA-TXOP, Congestion, Scheduling},
abstract = {In the last two decades, Wireless Local Area Networks (WLANs) based on 802.11 have become crucial in offering Internet services with high data transmission rates. Under crowded scenarios like airports, shopping centers, and stadiums, WLANs can be easily congested due to their random access nature and limited operational capability. This may result in a reduced user multimedia experience. With a proper Transmission Opportunity (TXOP) allocation and scheduling scheme, the user service quality could be improved under such scenarios. In this paper, a Congestion-Aware Transmission Opportunity (CA-TXOP) scheme is proposed, allocating transmission resources by considering network level congestion and information like buffer status, channel quality, and data rates. The CA-TXOP scheme prioritizes congested and noncongested user stations and improves the overall network performance. Simulation results show that the CA-TXOP scheme attained 45%, 35%, and 20% enhancement compared with Fixed, Bi-level, and FRA-TXOP scheduling schemes. Such scheme applies to future congested scenarios like smart buildings and organizations that require satisfying video quality to all the user stations.}
}
@article{KARABEYAKSAKALLI2021111014,
title = {Deployment and communication patterns in microservice architectures: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {180},
pages = {111014},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111014},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221001114},
author = {Işıl {Karabey Aksakalli} and Turgay Çelik and Ahmet Burak Can and Bedir Teki̇nerdoğan},
keywords = {Microservice architectures, Microservice deployment, Communication patterns of microservices, Deployment challenges, Communication concerns, Research directions},
abstract = {Context:
Microservice is an architectural style that separates large systems into small functional units to provide better modularity. A key challenge of microservice architecture design frequently discussed in the literature is the identification and decomposition of the service modules. Besides this, two other key challenges can be identified, including the deployment of the modules on the corresponding execution platform, and adopted communication patterns.
Objective:
This study aims to identify and describe the reported deployment approaches, and the communication platforms for microservices in the current literature. Furthermore, we aim to describe the identified obstacles of these approaches as well as the corresponding research directions.
Method:
A systematic literature review (SLR) is conducted using a multiphase study selection process in which we reviewed a total of 239 papers. Among these, we selected 38 of them as primary studies related to the described research questions.
Results:
Based on our study, we could identify three types of deployment approaches and seven different communication patterns. Moreover, we have identified eight challenges related to the deployment and six challenges related to the communication concerns.
Conclusion:
Our study shows that in addition to the identification of modules, the deployment and communication approaches are equally crucial for a successful application of the microservice architecture style. Various deployment approaches and communication patterns appear to be useful for different contexts. The identified research directions in the literature study show that still more research is needed to cope with the current challenges.}
}
@article{RAMEEMZAHRA2021,
title = {Detecting Covid-19 chaos driven phishing/malicious URL attacks by a fuzzy logic and data mining based intelligence system},
journal = {Egyptian Informatics Journal},
year = {2021},
issn = {1110-8665},
doi = {https://doi.org/10.1016/j.eij.2021.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1110866521000815},
author = {Syed {Rameem Zahra} and Mohammad {Ahsan Chishti} and Asif {Iqbal Baba} and Fan Wu},
keywords = {Covid-19, Phishing, Business Email Compromise (BEC), Ransomware, Fuzzy-Logic, Data mining, Cybercriminals, Security},
abstract = {With confusion and uncertainty ruling the world, 2020 created near-perfect conditions for cybercriminals. As businesses virtually eliminated in-person experiences, the COVID-19 pandemic changed the way we live and caused a mass migration to digital platforms. However, this shift also made people more vulnerable to cyber-crime. Victims are being targeted by attackers for their credentials or financial rewards, or both. This is because the Internet itself is inherently difficult to secure, and the attackers can code in a way that exploits its flaws. Once the attackers gain root access to the devices, they have complete control and can do whatever they want. Consequently, taking advantage of highly unprecedented circumstances created by the Covid-19 event, cybercriminals launched massive phishing, malware, identity theft, and ransomware attacks. Therefore, if we wish to save people from these frauds in times when millions have already been tipped into poverty and the rest are trying hard to sustain, it is imperative to curb these attacks and attackers. This paper analyses the impact of Covid-19 on various cyber-security related aspects and sketches out the timeline of Covid-19 themed cyber-attacks launched globally to identify the modus operandi of the attackers and the impact of attacks. It also offers a thoroughly researched set of mitigation strategies which can be employed to prevent the attacks in the first place. Moreover, this manuscript proposes a fuzzy logic and data mining-based intelligence system for detecting Covid-19 themed malicious URL/phishing attacks. The performance of the system has been evaluated against various malicious/phishing URLs, and it was observed that the proposed system is a viable solution to this problem.}
}
@article{YU2021104125,
title = {A digital twin-based decision analysis framework for operation and maintenance of tunnels},
journal = {Tunnelling and Underground Space Technology},
volume = {116},
pages = {104125},
year = {2021},
issn = {0886-7798},
doi = {https://doi.org/10.1016/j.tust.2021.104125},
url = {https://www.sciencedirect.com/science/article/pii/S0886779821003163},
author = {Gang Yu and Yi Wang and Zeyu Mao and Min Hu and Vijayan Sugumaran and Y. Ken Wang},
keywords = {Digital twins, COBie, Semantic Web, Operation and maintenance},
abstract = {Digital twins are at the core of urban infrastructure maintenance, operation and evaluation. In modern cities, digital twins can be established to integrate the life cycle spatio-temporal data of tunnels, as well as analyze the potential causes and effects of abnormalities in civil structures or electromechanical equipment. This will provide reasonable and feasible countermeasures to guide and optimize the operation and maintenance (O&M) management. This paper proposes a digital twin-based decision analysis framework for the O&M of tunnels. The framework defines an extended COBie standard-based organization method for the tunnel twin data, and uses Semantic Web technologies to achieve fusion at the data, object and knowledge levels. In addition, a rule-based reasoning engine has been developed by establishing a large rule base. The framework has been utilized for the fault cause analysis of fans in Wenyi Road Tunnel in Hangzhou, China to demonstrate its decision analysis process and validity. The application results show that the framework can provide efficient and automatic decision analysis support for the O&M of tunnels.}
}
@article{DIMURO202027,
title = {The state-of-art of the generalizations of the Choquet integral: From aggregation and pre-aggregation to ordered directionally monotone functions},
journal = {Information Fusion},
volume = {57},
pages = {27-43},
year = {2020},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2019.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1566253519304385},
author = {Graçaliz Pereira Dimuro and Javier Fernández and Benjamín Bedregal and Radko Mesiar and José Antonio Sanz and Giancarlo Lucca and Humberto Bustince},
keywords = {Aggregation functions, Pre-aggregation functions, Pseudo pre-aggregation function pair, Ordered directionally monotonicity, Choquet integral, -integral, -integral, -integral, -Integral, -Integral},
abstract = {In 2013, Barrenechea et al. used the Choquet integral as an aggregation function in the fuzzy reasoning method (FRM) of fuzzy rule-based classification systems. After that, starting from 2016, new aggregation-like functions generalizing the Choquet integral have appeared in the literature, in particular in the works by Lucca et al. Those generalizations of the Choquet integral, namely CT-integrals (by t-norm T), CF-integrals (by a fusion function F satisfying some specific properties), CC-integrals (by a copula C), CF1F2-integrals (by a pair of fusion functions (F1, F2) under some specific constraints) and their generalization gCF1F2-integrals, achieved excellent results in classification problems. The works by Lucca et al. showed that the aggregation task in a FRM may be performed by either aggregation, pre-aggregation or just ordered directional monotonic functions satisfying some boundary conditions, that is, it is not necessary to have an aggregation function to obtain competitive results in classification. The aim of this paper is to present and discuss such generalizations of the Choquet integral, offering a general panorama of the state of the art, showing the relations and intersections among such five classes of generalizations. First, we present them from a theoretical point of view. Then, we also summarize some applications found in the literature.}
}
@article{ZHOU2020402,
title = {The 5G communication technology-oriented intelligent building system planning and design},
journal = {Computer Communications},
volume = {160},
pages = {402-410},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.06.022},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420306459},
author = {Yan Zhou and Liyuan Li},
keywords = {5G, Communication technology, Intelligent building systems, Planning and design},
abstract = {Due to the irreplaceable advantages of 5G communication technology, there is no need to carry out complex bridge and wiring works in the construction of the network structure of smart buildings It is convenient and flexible to install, easy to expand and transform. This paper uses the special advantages of 5G-communication technology to apply 5G communication technology to intelligent buildings. This article first designs different subsystems based on different functions. Then, the local area networks composed of various subsystems distributed in the building are connected together through a 5G network. Finally, the basic centralized topology is adopted, and the building automatic control system installed in the public facilities in the middle of the plant is used as the network centre to communicate with each sub local area network through the bridge of 5G. In this paper, through the centralized monitoring and unified management of the distributed subsystems, and using the same monitoring interface to manage the different subsystems on a platform, the ultimate cost-effective system integration solution is finally achieved with the least investment optimal performance.}
}
@article{YANG201929785,
title = {HIES: Cases for hydrogen energy and I-Energy},
journal = {International Journal of Hydrogen Energy},
volume = {44},
number = {56},
pages = {29785-29804},
year = {2019},
note = {The 2nd International Symposium on Hydrogen Energy and Energy Technologies (HEET-2018)},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2019.03.056},
url = {https://www.sciencedirect.com/science/article/pii/S0360319919309826},
author = {Lu Yang and Pengli Xie and Ronghui Zhang and Yanjie Cheng and Bowen Cai and Rongben Wang},
keywords = {Renewable energy sources, Smart grid, I-Energy, Hydrogen energy, Household intelligent electricity system},
abstract = {With the increasing demand for electricity, more and more fossil fuels are used to generate electricity which leads to energy shortage and environmental pollution. Therefore, using Renewable Energy Sources (RESs) and developing sustainable smart grid have become a common global priority: Since RESs, like solar and wind energy, are inherently unstable, hydrogen energy, as a completely clean new energy, has received widespread attention: I-Energy, which combines information and energy, is a new research direction in smart grid. Furthermore, the household electricity usage accounts for 41% of the total power consumption. Therefore, Household Intelligent Electricity System (HIES), combining hydrogen energy and i-Energy, becomes smart solutions. In this paper, we review the scientific literature for hydrogen energy and i-Energy on HIES, including recognition of electricity appliances, establishment of power consumption model, human activity analysis, smart interactive terminal, home energy management system, distributed power supply and district coordinated power utilization. Finally, we summarize the challenges and give the solutions concerning HIES, and this work can give a useful reference to new energy used model and environment protection.}
}
@article{CASADOVARA2019227,
title = {Non-linear adaptive closed-loop control system for improved efficiency in IoT-blockchain management},
journal = {Information Fusion},
volume = {49},
pages = {227-239},
year = {2019},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2018.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S1566253518306079},
author = {Roberto Casado-Vara and Pablo Chamoso and Fernando {De la Prieta} and Javier Prieto and Juan M. Corchado},
keywords = {Adaptive closed-loop, Control system, Algorithm design and analysis, Queuing theory, IoT, Non-linear control},
abstract = {IoT network generates a large amount of data. This means that the monitoring and control of these networks and the transfer of packets from the IoT network to the server can cause communications to collapse. On the other hand, due to the large volume of data stored in the databases the monitoring of the IoT network needs very powerful servers to have a high degree of efficiency. This paper presents a novel adaptive closed-loop control system and speed up searches model to improve the monitor and control efficiency in IoT networks, specially those which are based in blockchain. The non linear control model under consideration includes a new way to evaluate the optimal number of blocks that should be at the queue of the miners’ network in order to make the process efficient through the use of queuing theory. Also, a new system to speed up searches is presented by using hashmaps, which makes the monitoring process faster, reliable and efficient. The efficiency of the presented approach is illustrated by a numerical case study.}
}
@article{KHAN2019219,
title = {Edge computing: A survey},
journal = {Future Generation Computer Systems},
volume = {97},
pages = {219-235},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.02.050},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18319903},
author = {Wazir Zada Khan and Ejaz Ahmed and Saqib Hakak and Ibrar Yaqoob and Arif Ahmed},
keywords = {Mobile edge computing, Edge computing, Cloudlets, Fog computing, Micro clouds, Cloud computing},
abstract = {In recent years, the Edge computing paradigm has gained considerable popularity in academic and industrial circles. It serves as a key enabler for many future technologies like 5G, Internet of Things (IoT), augmented reality and vehicle-to-vehicle communications by connecting cloud computing facilities and services to the end users. The Edge computing paradigm provides low latency, mobility, and location awareness support to delay-sensitive applications. Significant research has been carried out in the area of Edge computing, which is reviewed in terms of latest developments such as Mobile Edge Computing, Cloudlet, and Fog computing, resulting in providing researchers with more insight into the existing solutions and future applications. This article is meant to serve as a comprehensive survey of recent advancements in Edge computing highlighting the core applications. It also discusses the importance of Edge computing in real life scenarios where response time constitutes the fundamental requirement for many applications. The article concludes with identifying the requirements and discuss open research challenges in Edge computing.}
}
@article{COHEN2020100133,
title = {A constructive role for social science in the development of automated vehicles},
journal = {Transportation Research Interdisciplinary Perspectives},
volume = {6},
pages = {100133},
year = {2020},
issn = {2590-1982},
doi = {https://doi.org/10.1016/j.trip.2020.100133},
url = {https://www.sciencedirect.com/science/article/pii/S2590198220300440},
author = {Tom Cohen and Jack Stilgoe and Sally Stares and Nihan Akyelken and Clemence Cavoli and Jennie Day and Janet Dickinson and Vaike Fors and Debbie Hopkins and Glenn Lyons and Noortje Marres and Jonathan Newman and Louise Reardon and Neil Sipe and Chris Tennant and Zia Wadud and Edward Wigley},
keywords = {Automated vehicles, Autonomous vehicles, Self-driving, Driverless, Social science, Research agenda},
abstract = {Automated vehicles (AVs) have the potential to cause profound shifts across a wide range of areas of human life, including economic structures, land use, lifestyles and personal well-being. Most current social science on AVs is narrowly framed. Research on public attitudes has focused on whether people are likely to accept and use AVs. We contend that failing to anticipate a wider range of profound social implications may have serious negative consequences, and that social scientists from a range of disciplinary perspectives can provide invaluable insights. Our conclusions are the product of a workshop in London held in 2018 to discuss the place of social science research in relation to the development of AVs. This paper summarises a core selection of our concerns, interests, theoretical and substantive points of reference and aspirations for a constructive role in this field of research and development.}
}
@article{YUKSEL2021102625,
title = {Energy-aware system design for batteryless LPWAN devices in IoT applications},
journal = {Ad Hoc Networks},
volume = {122},
pages = {102625},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102625},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521001517},
author = {Mehmet Erkan Yuksel and Huseyin Fidan},
keywords = {Internet of Things, LPWAN, Embedded systems, Solar energy, Energy harvesting, Supercapacitor, Dynamic power management},
abstract = {Interconnected LPWAN devices, which create the IoT, are usually powered by batteries that significantly limit their operational lifetime. The main disadvantage of batteries is that they must be periodically/manually replaced with new ones or recharged when they are depleted. This kind of maintenance increases the cost and restricts the large-scale deployments of these devices. Furthermore, wireless communication between distributed devices and gateways (or base stations) consumes a significant amount of energy, even more, if data has to be sent to a distance of several kilometers. When considering the limitations of battery power and long operating life, alternative energy sources, energy harvesting techniques, and power management strategies are required for LPWAN IoT devices to operate seamlessly and efficiently. Therefore, the development of energy-efficient solutions for such devices is a crucial issue. In this study, we designed and implemented an energy-aware system model to operate LPWAN IoT devices that have multiple wireless communication technologies (Wi-Fi, dual-mode Bluetooth, LoRa, SigFox, LTE-M) batteryless and maximize their operational lifetime in the IoT environment. We designed an energy harvesting system that couples a solar panel with a supercapacitor to achieve self-sustainability in a heterogeneous short-and long-range network and improve energy efficiency. We developed a power-aware software running on a MicroPython-enabled embedded operating system to manage the device power consumption by exploiting the power modes of the system hardware components. We performed a simulation based on a probabilistic sensing model to evaluate how the proposed method influences the overall energy efficiency of the LPWAN IoT network. In our experimental study and simulation, we demonstrated our system model saved energy in the solar-powered supercapacitor-operated LPWAN IoT device, and observed that the device operated well with low-power consumption without any performance degradation.}
}
@article{DAMAJ2020102949,
title = {An analytical framework for high-speed hardware particle swarm optimization},
journal = {Microprocessors and Microsystems},
volume = {72},
pages = {102949},
year = {2020},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2019.102949},
url = {https://www.sciencedirect.com/science/article/pii/S0141933119300407},
author = {Issam Damaj and Mohamed Elshafei and Mohammed El-Abd and Mehmet Emin Aydin},
keywords = {Particle swarm optimization, Hardware, Software, Performance, Analysis, Gate arrays},
abstract = {Engineering optimization techniques are computationally intensive and can challenge implementations on tightly-constrained embedded systems. Particle Swarm Optimization (PSO) is a well-known bio-inspired algorithm that is adopted in various applications, such as, transportation, robotics, energy, etc. In this paper, a high-speed PSO hardware processor is developed with focus on outperforming similar state-of-the-art implementations. In addition, the investigation comprises the development of an analytical framework that captures wide characteristics of optimization algorithm implementations, in hardware and software, using key simple and combined heterogeneous indicators. The framework proposes a combined Optimization Fitness Indicator that can classify the performance of PSO implementations when targeting different evaluation functions. The two targeted processing systems are Field Programmable Gate Arrays for hardware implementations and a high-end multi-core computer for software implementations. The investigation confirms the successful development of a PSO processor with appealing performance characteristics that outperforms recently presented implementations. The proposed hardware implementation attains 23,300 improvement ratio of execution times with an elliptic evaluation function. In addition, a speedup of 1777 times is achieved with a Shifted Schwefels function. Indeed, the developed framework successfully classifies PSO implementations according to multiple and heterogeneous properties for a variety of benchmark functions.}
}
@article{DUO2021100387,
title = {Robust 3D trajectory and power design in probabilistic LoS channel for UAV-enabled cooperative jamming},
journal = {Vehicular Communications},
volume = {32},
pages = {100387},
year = {2021},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2021.100387},
url = {https://www.sciencedirect.com/science/article/pii/S2214209621000565},
author = {Bin Duo and Hao Hu and Yilian Li and Yanmei Hu and Xing Zhu},
keywords = {UAV communication, Physical-layer security, Cooperative jamming, Probabilistic LoS channel, Trajectory design, Power control},
abstract = {This paper proposes a mobile unmanned aerial vehicle (UAV)-enabled jamming scheme under the probabilistic line-of-sight (LoS) channel model to improve the secrecy of ground wiretap channels in urban areas, where a friendly UAV is deployed to cooperatively transmit jamming signals to confuse the suspicious ground eavesdroppers. Our goal is to maximize the average (expected) secrecy rate by jointly optimizing the user scheduling, the source's transmit power, the UAV's jamming power and its three-dimensional (3D) trajectory for a given flight time. Since the expected secrecy rate is highly complicated with respect to the 3D UAV trajectory, we derive a more tractable lower bound for it. Nevertheless, the resulting optimization problem is still non-convex and difficult to solve optimally due to the imperfect location information of the eavesdroppers. To tackle such an intractable problem, we first derive a worst-case (expected) secrecy rate, and then we propose an efficient iterative algorithm to obtain a suboptimal solution to it by applying the block coordinate descent (BCD) and successive convex approximation (SCA) techniques. Simulation results show that the proposed algorithm under the probabilistic LoS channel model significantly outperforms various benchmark algorithms.}
}
@article{MEIDANI2013267,
title = {Multiscale Markov models with random transitions for energy demand management},
journal = {Energy and Buildings},
volume = {61},
pages = {267-274},
year = {2013},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2013.02.020},
url = {https://www.sciencedirect.com/science/article/pii/S0378778813000960},
author = {Hadi Meidani and Roger Ghanem},
keywords = {Markov chain, Random transition matrices, Demand management, Smart Grid, Uncertainty quantification},
abstract = {A stochastic model is proposed for fluctuations in electricity demand that are associated with individual user's consumption choices. Electricity consumption is modeled as a function of social activities of consumers. The dynamics of these activities are modeled as a Markov chain. Markov models are simplified models that capture the stochasticity to the unmodeled dynamics typically attributed to white noise disturbances. Additional uncertainties are also accrued in the process of calibrating the transition rates of these chains from finite samples. In this paper, these uncertainties are accounted for by considering random transition matrices. Such formalism can also reflect the fluctuations in the environment in which the chain evolves. We also discuss a third interpretation where uncertain transitions, in a multiscale setting, reflect the fine-resolution information that is lost in the process of state aggregation. As numerical demonstration, we study the activity modeling of a heterogeneous population. Activity uncertainties are propagated onto the energy demand. Demand uncertainties, in turn, are propagated onto a global performance metric. Such uncertainty management framework bridges between the actual drivers of the energy consumption and the system health. Subsequent decisions can be robustly supported based on the results of the quantitative model proposed in this paper.}
}
@article{ZHAO201955,
title = {Towards dependable and trustworthy outsourced computing: A comprehensive survey and tutorial},
journal = {Journal of Network and Computer Applications},
volume = {131},
pages = {55-65},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.01.021},
url = {https://www.sciencedirect.com/science/article/pii/S108480451930030X},
author = {Minghao Zhao and Chengyu Hu and Xiangfu Song and Chuan Zhao},
keywords = {Cloud computing security, Outsourced computing, Verifiability, Privacy},
abstract = {Cloud computing provides the clients with diversified services in a flexible manner. Recently, the cloud platforms have been the basic underling-support for The IoT and mobile computing. The client outsources data storage or computation overhead to the cloud, which accordingly yields a new computing paradigm – the outsourced computing. In such a scenario, the clients hope to acquire the service quality, and wish to not leak their sensitive data to the cloud service provider. Thus, the trustworthy (verifiability) and privacy has been a hot issue for outsourced computing. In this survey, we systematically present the cryptographic methods for ensuring verifiability and privacy. We first describe the research advancement in verifiable computing and the cryptographic primitives for privacy-preserving techniques; and then, taking outsourcing cryptographic operations as an example, to show how them primitives can be integrated to achieve a dependable and privacy-preserving outsourced computing scheme. This paper bridges the gap between the theoretical cryptographic research and engineering secure cloud computing systems.}
}
@article{YI2018571,
title = {An improved NSGA-III algorithm with adaptive mutation operator for Big Data optimization problems},
journal = {Future Generation Computer Systems},
volume = {88},
pages = {571-585},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18306137},
author = {Jiao-Hong Yi and Suash Deb and Junyu Dong and Amir H. Alavi and Gai-Ge Wang},
keywords = {Big Data optimization, Evolutionary multi-objective optimization, NSGA-III, Mutation operator, Adaptive operators},
abstract = {One of the major challenges of solving Big Data optimization problems via traditional multi-objective evolutionary algorithms (MOEAs) is their high computational costs. This issue has been efficiently tackled by non-dominated sorting genetic algorithm, the third version, (NSGA-III). On the other hand, a concern about the NSGA-III algorithm is that it uses a fixed rate for mutation operator. To cope with this issue, this study introduces an adaptive mutation operator to enhance the performance of the standard NSGA-III algorithm. The proposed adaptive mutation operator strategy is evaluated using three crossover operators of NSGA-III including simulated binary crossover (SBX), uniform crossover (UC) and single point crossover (SI). Subsequently, three improved NSGA-III algorithms (NSGA-III SBXAM, NSGA-III SIAM, and NSGA-III UCAM) are developed. These enhanced algorithms are then implemented to solve a number of Big Data optimization problems. Experimental results indicate that NSGA-III with UC and adaptive mutation operator outperforms the other NSGA-III algorithms.}
}
@article{AMODU2019101938,
title = {A primer on design aspects, recent advances, and challenges in cellular device-to-device communication},
journal = {Ad Hoc Networks},
volume = {94},
pages = {101938},
year = {2019},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2019.101938},
url = {https://www.sciencedirect.com/science/article/pii/S1570870519301891},
author = {Oluwatosin Ahmed Amodu and Mohamed Othman and Nor Kamariah Noordin and Idawaty Ahmad},
keywords = {D2D, Interference, Metrics, Mode selection, Power control, Resource allocation},
abstract = {Device-to-Device (D2D) communication is one of the technologies on the spotlight for enhancing the cellular network performance towards the fifth generation wireless systems. It has diverse potentials to cater for both critical and non-critical applications. For example, timely information dissemination can be achieved during disasters using D2D communication. Also, content sharing and real-time applications can be effectively facilitated. Recently, new applications and technologies are beginning to embrace D2D to further improve their performance in terms of spectral efficiency, latency, and energy efficiency. However, this is not bereft of technical challenges due to the peculiar limitations of traditional D2D communication such as interference. In this paper, we focus on techniques for managing these challenges with regards to mode selection, power control, and resource allocation. As compared with other contemporary works on this subject, we discuss these issues in line with some of the most recent research trends. In addition, we compile pertinent design considerations of D2D discussed in literature while extracting new patterns to familiarize readers with applications, models, methods and metrics studied lately. Furthermore, we highlight and classify some of the key challenges of D2D communication with respect to current and future generation cellular technologies, giving a comprehensive outlook of new research problems recently identified in this area.}
}
@article{WU2017265,
title = {Measuring signal fluctuations in gait rhythm time series of patients with Parkinson's disease using entropy parameters},
journal = {Biomedical Signal Processing and Control},
volume = {31},
pages = {265-271},
year = {2017},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2016.08.022},
url = {https://www.sciencedirect.com/science/article/pii/S1746809416301239},
author = {Yunfeng Wu and Pinnan Chen and Xin Luo and Meihong Wu and Lifang Liao and Shanshan Yang and Rangaraj M. Rangayyan},
keywords = {Approximate entropy, Gait analysis, Generalized linear regression analysis, Parkinson's disease, Signal turns count, Stride time, Symbolic entropy},
abstract = {Gait rhythm disturbances due to abnormal strides indicate the degenerative mobility regulation of motor neurons affected by Parkinson's disease (PD). The aim of this work is to compute the approximate entropy (ApEn), normalized symbolic entropy (NSE), and signal turns count (STC) parameters for the measurements of stride fluctuations in PD. Generalized linear regression analysis (GLRA) and support vector machine (SVM) techniques were employed to implement nonlinear gait pattern classifications. The classification performance was evaluated in terms of overall accuracy, sensitivity, specificity, precision, Matthews correlation coefficient (MCC), and area under the receiver operating characteristic (ROC) curve. Our experimental results indicated that the ApEn, NSE, and STC parameters computed from the stride series of PD patients were all significantly larger (Wilcoxon rank-sum test: p<0.01) than those of healthy control subjects. Based on the distinct features of ApEn, NSE, and STC, the SVM provided an accuracy rate of 84.48% and MCC of 0.7107, which are better than those of the GLRA (accuracy: 82.76%, MCC: 0.6552). The SVM and GLRA methods were able to distinguish PD gait patterns from healthy control cases with area of 0.9049 (SVM sensitivity: 0.7241, specificity: 0.9655) and 0.9037 (GLRA sensitivity: 0.8276, specificity: 0.8276) under the ROC curve, respectively, which are better or comparable with the classification results achieved by the other popular pattern classification methods.}
}
@article{FOX201848,
title = {The semantics of populations: A city indicator perspective},
journal = {Journal of Web Semantics},
volume = {48},
pages = {48-65},
year = {2018},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2018.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S1570826818300015},
author = {Mark S. Fox},
keywords = {Population semantics, Ontology, City indicators, Consistency checking},
abstract = {This paper addresses the question of how to represent the semantics of populations. This question is unusual in the sense that statistics is directly concerned with the definition of populations but is essentially silent on the representation of population definitions from a data modeling perspective. The motivation for this work is the development of ontologies for the representation of city indicator definitions. A city indicator measures the performance of a city in areas such as education, transportation and the environment. The definitions of city indicators rely on definitions for populations of people, built form, events, activities, and sensor measurements. This paper provides a model for representing membership extent, temporal extent, spatial extent, and measurement of populations. It demonstrates the approach by representing the definitions of city indicators as defined by ISO 37120, the interpretation of these definitions by cities, and their comparison to ascertain whether a city’s interpretation is consistent with the standard.}
}
@article{ALTAF201993,
title = {Trust models of internet of smart things: A survey, open issues, and future directions},
journal = {Journal of Network and Computer Applications},
volume = {137},
pages = {93-111},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.02.024},
url = {https://www.sciencedirect.com/science/article/pii/S1084804519300839},
author = {Ayesha Altaf and Haider Abbas and Faiza Iqbal and Abdelouahid Derhab},
keywords = {IoT, Trust models, Attacks, Security, Malicious, Trust, Smart},
abstract = {Internet of Things (IoT) is a rapidly growing field which provides seamless connectivity to physical objects to make them part of smart environment. In order to fully utilize the potential power of these connected objects of IoT, trust existence among these objects is essential. Traditional security measures are not enough to provide the comprehensive security to this smart world. Trust is used to mitigate the risk of uncertainty while connecting nodes to the internet. Different trust models for IoT environment have been proposed. However, these have not completely mapped with the uncertain and dynamic environment of smart IoT. This paper presents a comprehensive overview of existing surveys on trust models of IoT. It provides classification of Trust Related Attacks (TRA) and comparison of existing trust models with respect to TRA and Function Requirements (FR) of IoT. The aim of this comparison is to summarize the FR of IoT which must be considered while designing Trust Management System (TMS). Furthermore, this survey categorizes and compares existing trust models with respect to their resiliency against TRA, including: attack on node, attack on service, and attack on communication path. The paper expands on current open issues and identifies possible future research directions to address them. Finally, a conceptual framework has been proposed which shows the minimum requirements to make a successful trust model for smart IoT environment. Precisely, this study will help the reader to understand the vulnerabilities in existing IoT trust models and will direct towards future work to propose new models which can cater all possible and highlighted threats.}
}
@article{AUER2022103316,
title = {Towards blockchain-IoT based shared mobility: Car-sharing and leasing as a case study},
journal = {Journal of Network and Computer Applications},
volume = {200},
pages = {103316},
year = {2022},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103316},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521003015},
author = {Sophia Auer and Sophia Nagler and Somnath Mazumdar and Raghava Rao Mukkamala},
keywords = {Blockchain, Car-sharing, Car-leasing, Distributed ledger technologies, Hyperledger fabric, Internet-of-things, Shared mobility},
abstract = {The shared mobility concept is seen as disruptive and transformative for the automotive industry. Shared mobility is changing the way we choose our travel mode, from just owning a car to e-hailing, car-sharing, and other relevant mobility solutions. There is a growing interest of car manufacturers (original equipment manufacturers or OEMs) in car-sharing as an expansion strategy. Similarly, blockchain technology is seen as another disruptive technology, which can potentially change how the data is stored and accessible via its immutable, transparent, and trustworthy features. Motivated by these two current trends, this paper aims to explore how blockchain and IoT technologies together can drive shared mobility forward. We have presented a high-level architecture for a blockchain-IoT-based platform for promoting shared mobility combining car-sharing and car-leasing. We also demonstrated a prototype implemented from the OEM’s point of view by developing a blockchain-IoT-based platform streamlining car-sharing and leasing processes by taking into consideration of primary stakeholders (such as OEMs, a peer-to-peer car-sharing provider, leasing company and insurance provider as well as public authorities). This work also demonstrates that the design of such an integrated platform depends on the right balance between the key design principles (such as security and privacy, authenticity, traceability and reliability, scalability, and interoperability) in the context of car-sharing platforms.}
}
@article{VILELA2019379,
title = {Performance evaluation of a Fog-assisted IoT solution for e-Health applications},
journal = {Future Generation Computer Systems},
volume = {97},
pages = {379-386},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.02.055},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18323458},
author = {Pedro H. Vilela and Joel J.P.C. Rodrigues and Petar Solic and Kashif Saleem and Vasco Furtado},
keywords = {Cloud computing, Edge computing, Fog computing, Healthcare, Internet of Things},
abstract = {Cloud Computing has been a predominant approach for the development of Internet of Things (IoT) solutions. However, to meet the requirements of real-time and latency-sensitive applications in healthcare, a new computing paradigm that follows a Cloud computing approach, called Fog Computing, demonstrates to be an effective tool by extending the Cloud resources to the edge of the network. This work studies the contribution of the Fog Computing paradigm applied to healthcare, highlighting its main benefits regarding latency, network usage, and power consumption. Based on these parameters, a Fog-assisted health monitoring system is proposed and its performance evaluation and demonstration is carried out. The results demonstrates the potential enhancement of this approach to minimise data traffic in the core of the network because data is analysed locally and, also, enhancing security on health information that can be kept locally, enhancing data security and providing better insights of patient’s health status.}
}
@article{GARCIAVALLS201883,
title = {Introducing the new paradigm of Social Dispersed Computing: Applications, Technologies and Challenges},
journal = {Journal of Systems Architecture},
volume = {91},
pages = {83-102},
year = {2018},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2018.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S1383762118301036},
author = {Marisol García-Valls and Abhishek Dubey and Vicent Botti},
keywords = {Social dispersed computing, IoT, Fog Computing, Cloud Computing, Dispersed Computing, Social Computing, Edge Computing, Distributed computing, Cyber physical systems, Real time, Middleware, Virtualization, Containers, Microservices, Distributed transactions, Blockchain, Multi agent systems, Distributed coordination, Complex event processing, Networking},
abstract = {If last decade viewed computational services as a utilitythen surely this decade has transformed computation into a commodity. Computation is now progressively integrated into the physical networks in a seamless way that enables cyber-physical systems (CPS) and the Internet of Things (IoT) meet their latency requirements. Similar to the concept of “platform as a service” or “software as a service”, both cloudlets and fog computing have found their own use cases. Edge devices (that we call end or user devices for disambiguation) play the role of personal computers, dedicated to a user and to a set of correlated applications. In this new scenario, the boundaries between the network node, the sensor, and the actuator are blurring, driven primarily by the computation power of IoT nodes like single board computers and the smartphones. The bigger data generated in this type of networks needs clever, scalable, and possibly decentralized computing solutions that can scale independently as required. Any node can be seen as part of a graph, with the capacity to serve as a computing or network router node, or both. Complex applications can possibly be distributed over this graph or network of nodes to improve the overall performance like the amount of data processed over time. In this paper, we identify this new computing paradigm that we call Social Dispersed Computing, analyzing key themes in it that includes a new outlook on its relation to agent based applications. We architect this new paradigm by providing supportive application examples that include next generation electrical energy distribution networks, next generation mobility services for transportation, and applications for distributed analysis and identification of non-recurring traffic congestion in cities. The paper analyzes the existing computing paradigms (e.g., cloud, fog, edge, mobile edge, social, etc.), solving the ambiguity of their definitions; and analyzes and discusses the relevant foundational software technologies, the remaining challenges, and research opportunities.}
}
@article{ARAFEH2021769,
title = {Ontology based recommender system using social network data},
journal = {Future Generation Computer Systems},
volume = {115},
pages = {769-779},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.09.030},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20305963},
author = {Mohamad Arafeh and Paolo Ceravolo and Azzam Mourad and Ernesto Damiani and Emanuele Bellini},
keywords = {Social network, Data miner, Big data, Data analysis, Data sampling, Ontology, Recommender system},
abstract = {Online Social Network (OSN) is considered a key source of information for real-time decision making. However, several constraints lead to decreasing the amount of information that a researcher can have while increasing the time of social network mining procedures. In this context, this paper proposes a new framework for sampling Online Social Network (OSN). Domain knowledge is used to define tailored strategies that can decrease the budget and time required for mining while increasing the recall. An ontology supports our filtering layer in evaluating the relatedness of nodes. Our approach demonstrates that the same mechanism can be advanced to prompt recommendations to users. Our test cases and experimental results emphasize the importance of the strategy definition step in our social miner and the application of ontologies on the knowledge graph in the domain of recommendation analysis.}
}
@article{BOUBICHE2019352,
title = {Mobile crowd sensing – Taxonomy, applications, challenges, and solutions},
journal = {Computers in Human Behavior},
volume = {101},
pages = {352-370},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2018.10.028},
url = {https://www.sciencedirect.com/science/article/pii/S0747563218305181},
author = {Djallel Eddine Boubiche and Muhammad Imran and Aneela Maqsood and Muhammad Shoaib},
keywords = {Mobile crowd sensing, Multifacted infrastructural and human-powered applications, Social and behavioral applications, Large-scale sensing, Communication, Computing},
abstract = {Recently, mobile crowd sensing (MCS) is captivating growing attention because of their suitability for enormous range of new types of context-aware applications and services. This is attributed to the fact that modern smartphones are equipped with unprecedented sensing, computing, and communication capabilities that allow them to perform more complex tasks besides their inherent calling features. Despite a number of merits, MCS confronts new challenges due to network dynamics, the huge volume of data, sensing task coordination, and the user privacy problems. In this paper, a comprehensive review of MCS is presented. First, we highlight the distinguishing features and potential advantages of MCS compared to conventional sensor networks. Then, a taxonomy of MCS is devised based on sensing scale, level of user involvement and responsiveness, sampling rate, and underlying network infrastructure. Afterward, we categorize and classify prominent applications of MCS in environmental, infrastructure, social, and behavioral domains. The core architecture of MCS is also described. Finally, we describe the potential advantages, determine and reiterate the open research challenges of MCS and illustrate possible solutions.}
}
@article{SADOUGHI2020103383,
title = {Internet of things in medicine: A systematic mapping study},
journal = {Journal of Biomedical Informatics},
volume = {103},
pages = {103383},
year = {2020},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2020.103383},
url = {https://www.sciencedirect.com/science/article/pii/S1532046420300101},
author = {Farahnaz Sadoughi and Ali Behmanesh and Nasrin Sayfouri},
keywords = {IoT, Internet of things, Medicine, Healthcare, Medical IoT, Systematic mapping review},
abstract = {Context
The current studies on IoT in healthcare have reviewed the uses of this technology in a combination of healthcare domains, including nursing, rehabilitation sciences, ambient assisted living (AAL), medicine, etc. However, no review study has scrutinized IoT advances exclusively in medicine irrespective of other healthcare domains.
Objectives
The purpose of the current study was to identify and map the current IoT developments in medicine through providing graphical/tabular classifications on the current experimental and practical IoT information in medicine, the involved medical sub-fields, the locations of IoT use in medicine, and the bibliometric information about IoT research articles.
Methods
In this systematic mapping study, the studies published between 2000 and 2018 in major online scientific databases, including IEEE Xplore, Web of Science, Scopus, and PubMed were screened. A total of 3679 papers were found from which 89 papers were finally selected based on specific inclusion/exclusion criteria.
Results
While the majority of medical IoT studies were experimental and prototyping in nature, they generally reported that home was the most popular place for medical IoT applications. It was also found that neurology, cardiology, and psychiatry/psychology were the medical sub-fields receiving the most IoT attention. Bibliometric analysis showed that IEEE Internet of Things Journal has published the most influential IoT articles. India, China and the United States were found to be the most involved countries in medical IoT research.
Conclusions
Although IoT has not yet been employed in some medical sub-fields, recent substantial surge in the number of medical IoT studies will most likely lead to the engagement of more medical sub-fields in the years to come. IoT literature also shows that the ambiguity of assigning a variety of terms to IoT, namely system, platform, device, tool, etc., and the interchangeable uses of these terms require a taxonomy study to investigate the precise definition of these terms. Other areas of research have also been mentioned at the end of this article.}
}
@article{RIBEIRONAVARRETE2021120681,
title = {Towards a new era of mass data collection: Assessing pandemic surveillance technologies to preserve user privacy},
journal = {Technological Forecasting and Social Change},
volume = {167},
pages = {120681},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.120681},
url = {https://www.sciencedirect.com/science/article/pii/S004016252100113X},
author = {Samuel Ribeiro-Navarrete and Jose Ramon Saura and Daniel Palacios-Marqués},
keywords = {Mass data-collection, COVID-19, User privacy, Data management, Mobile devices},
abstract = {Controlling the coronavirus pandemic is triggering a cross-border strategy by which national governments attempt to control the spread of the COVID-19 pandemic. A response based on sharing facts about millions of private movements and a call to study information behavior during the global health crisis has been advised worldwide. The present study aims to identify the technologies to control the COVID-19 and future pandemics with massive data collection from users’ mobile devices. This research undertakes a Systematic Literature Review (SLR) of the studies about the currently available methods, strategies, and actions to collect and analyze data from users’ mobile devices. In a total of 76 relevant studies, 13 technologies that are classified based on the following aspect of data and data management have been identified: (1) security; (2) destruction; (3) voluntary access; (4) time span; and (5) storage. In addition, in order to understand how these technologies can affect user privacy, 25 data points that these technologies could have access to if installed through mobile applications have been detected. The paper concludes with a discussion of important theoretical and practical implications of preserving user privacy and curbing COVID-19 infections in the global public health emergency situation.}
}
@article{VERDEGAY2015219,
title = {Progress on Fuzzy Mathematical Programming: A personal perspective},
journal = {Fuzzy Sets and Systems},
volume = {281},
pages = {219-226},
year = {2015},
note = {Special Issue Celebrating the 50th Anniversary of Fuzzy Sets},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2015.08.023},
url = {https://www.sciencedirect.com/science/article/pii/S0165011415004054},
author = {José Luis Verdegay},
keywords = {Fuzzy Linear Programming, Fuzzy numbers, Soft computing},
abstract = {Fuzzy Linear Programming is among the best and most studied topics in the Fuzzy Sets and Systems area. In this paper, the author describes the main developments, results and solution methods achieved in this topic throughout the last 35 years, from a personal point of view. Short descriptions on different Fuzzy Linear Programming problems are provided and future research lines are briefly pointed out.}
}
@article{GOTHAWAL2019565,
title = {Intrusion Detection for Enhancing RPL Security},
journal = {Procedia Computer Science},
volume = {165},
pages = {565-572},
year = {2019},
note = {2nd International Conference on Recent Trends in Advanced Computing ICRTAC -DISRUP - TIV INNOVATION , 2019 November 11-12, 2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.01.051},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920300594},
author = {Deepali Bankatsingh Gothawal and S.V. Nagaraj},
keywords = {IoT, Secure RPL, IDS, Routing performance},
abstract = {Internet of things is a new paradigm that connects the internet to the physical objects of different domain viz. home automation, human health services, and industrial process automation and environmental monitoring. It is deeply presented in our daily activities through various devices. The devices connected with the internet bring many benefits but simultaneously bringing the security issues also. For protecting the network and information systems the intrusion detection system is an important tool. However traditional techniques used for intrusion detection are not sufficient to protect the network consists of specific characteristics like constraint resourced devices and specific protocol stacks. In this paper, we proposed an intrusion detection system for RPL (Routing Protocol for Low power and lossy networks) which is focused on WSN and constrained resources. Proposed IDS follows detection of an attack, IDS placement strategy, and validation process.}
}
@article{FORD2020111902,
title = {Are we seeing clearly? The need for aligned vision and supporting strategies to deliver net-zero electricity systems},
journal = {Energy Policy},
volume = {147},
pages = {111902},
year = {2020},
issn = {0301-4215},
doi = {https://doi.org/10.1016/j.enpol.2020.111902},
url = {https://www.sciencedirect.com/science/article/pii/S0301421520306157},
author = {Rebecca Ford and Jeffrey Hardy},
keywords = {Renewable energy, Smart grids, Socio-technical energy transition, Delphi study, Energy vision, Net-zero energy},
abstract = {This paper explores the trends, step changes and innovations that could impact the integration of renewable energy into electricity systems, explores interventions that may be required, and identifies key areas for policy makers to consider. A Delphi approach is used to collect, synthesise, and seek consensus across expert viewpoints. Over sixty experts across a range of geographies including the US, Europe, New-Zealand, Australia, Africa, India and China participated. They identified 26 trends, 20 step changes, and 26 innovations that could lead to major shifts in the design, operation, or management of electricity systems. Findings suggest that key challenges are not technological. Instead they are with delivering an aligned vision, supported by institutional structures, to incentivise, facilitate, and de-risk the delivery of a completely different type of energy system. There is a clear role for government and policy to provide a future energy vision and steer on strategic issues to deliver it; to create space for new actors and business models aligned with this vision; and to create an environment where research, development, demonstration and deployment can promote technologies, system integration and business model innovation at a rate commensurate with delivering net-zero electricity systems.}
}
@article{SODHRO2019308,
title = {Mobile edge computing based QoS optimization in medical healthcare applications},
journal = {International Journal of Information Management},
volume = {45},
pages = {308-318},
year = {2019},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2018.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0268401218302275},
author = {Ali Hassan Sodhro and Zongwei Luo and Arun Kumar Sangaiah and Sung Wook Baik},
keywords = {Mobile edge computing, Medical healthcare, QoS, Window-based rate control algorithm, BSA},
abstract = {Emerging trends in mobile edge computing for developing the efficient healthcare application such as, remote monitoring of the patients with central electronics clouds (e-Clouds) and their increasing voluminous multimedia have caught the attention of everyone in industry and academia. So, clear visualization, big sensing level, and better quality of service (QoS) is the foremost priority. This paper proposes the window-based Rate Control Algorithm (w-RCA) to optimize the medical quality of service (m-QoS) in the mobile edge computing based healthcare by considering the network parameters for instance, peak-to-mean ratio (PMR), standard deviation (Std.dev), delay and jitter during 8 min medical video stream named “Navigation to the Uterine Horn, transection of the horn and re-anastomosis’ transmission over 5 G networks. The performance of the proposed w-RCA is evaluated and compared with the conventional battery smoothing algorithm (BSA) and Baseline by using MPEG-4 encoder for optimizing m-QoS at the source or the server side. The experimental results demonstrate that the w-RCA outperforms the BSA and Baseline by optimizing QoS in remote healthcare application i.e., Tele-surgery. Besides, it is observed and analyzed that w-RCA produces better and effective results at small buffer and window sizes unlike BSA and Baseline by adopting large buffer size during QoS optimization.}
}
@article{ZHU2021,
title = {Adaptive offloading and scheduling algorithm for big data based mobile edge computing},
journal = {Neurocomputing},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.03.141},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221016416},
author = {Xiaoping Zhu and Yi Xiao},
keywords = {Mobile edge computing, Big data, Business public opinion, Resource allocation},
abstract = {Big data will cause the system for business public opinion to be overburdened, and dynamic changes in computing resources will cause tasks to be delayed. To end the situation, this study assigns non-fixed execution time to each task node based on the task soft deadline and task constraints and solves the problem of difficult task scheduling caused by task dependency constraints. Aiming at the problem of task delay caused by dynamic changes of computing resources, this paper proposes an adaptive offloading and scheduling algorithm for dependent tasks in the mobile edge computing environment. This study takes the economic efficiency analysis system as an example and uses the resource allocation management algorithm based on linked lists and edge servers to study the communication resource allocation management of the economic efficiency analysis system. In addition, this study designs experiments to perform performance analysis of the algorithm proposed by this study. The research results show that the proposed algorithm has an obvious effect.}
}
@article{FIROUZI202124,
title = {Distributed-Reasoning for Task Scheduling through Distributed Internet of Things Controller},
journal = {Procedia Computer Science},
volume = {184},
pages = {24-32},
year = {2021},
note = {The 12th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 4th International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921006268},
author = {Ramin Firouzi and Rahim Rahmani and Theo Kanter},
keywords = {Internet of Things (IoT), edge computing, reasoning, fuzzy controller, abductive reasoning},
abstract = {The adoption of distributed reasoning through ubiquitous instrumentation in the distributed Internet of Things (IoT) leads to outstanding improvements in real-time monitoring, optimization, fault tolerance, traffic, healthcare, etc. Using a ubiquitous controller to interconnect devices in the IoT is still in the embryonic stage. However, it has the potential to create distributed-intelligent IoT solutions that are more efficient and secure than centric intelligence. It is essential to take a new direction to design a distributed intelligent controller for task scheduling that can firstly dynamically interact with a smart environment in efficient real-time data processing and secondly respond to flexible changes. To address these issues, we outline a two-level intelligence scheme that leverages edge computing to improve distributed IoT. The edge scheme shifts the capability of streaming processing from the cloud to edge devices to alleviate latency, support better reliable streaming analytics, and improve smart IoT applications’ performance. In this work, to enable better, reliable, and flexible streaming analytics and overcome the data uncertainties, we proposed an IoT gateway controller that provides low-level intelligence by using a fuzzy abductive reasoner. Numerical simulations support the feasibility of our proposed approaches.}
}
@article{TRAN2021102844,
title = {Integrating blockchain and Internet of Things systems: A systematic review on objectives and designs},
journal = {Journal of Network and Computer Applications},
volume = {173},
pages = {102844},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102844},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520303118},
author = {Nguyen Khoi Tran and M. {Ali Babar} and Jonathan Boan},
keywords = {Blockchain, Distributed ledger, Smart contract, Web of things, Internet of Things, Systematic review},
abstract = {Recent years have witnessed the emergence of the Internet of Things (IoT) systems that incorporate blockchain (BC) elements in their architecture. Due to discrepancies between the requirements of IoT systems and the characteristics of BC networks, the motivations and design of these blockchain-enabled IoT systems (BC-IoT) are not only intriguing from a research perspective but also invaluable in practice. This paper presents an inductive study of the “why” and “how” of BC-IoT systems through a Systematic Literature Review of 120 peer-reviewed studies. To capture the diverse nature of BC-IoT integration, we proposed and applied a multi-perspective framework to analyse the existing systems. Regarding their motivations, we studied the improvement objectives and technical problems that drive the integration of BC. Regarding the design, we captured the position of BC within IoT systems as well as the content and processes that IoT systems offload to BC. As these dimensions are not mutually exclusive, they constitute a rich and multi-angle view of BC-IoT integration. Based on these findings, we defined 10 archetypes of BC-IoT systems that embody the core patterns of usage and configuration of BC in IoT systems.}
}
@article{SANCHEZCARRILLO2021126675,
title = {Embracing higher education leadership in sustainability: A systematic review},
journal = {Journal of Cleaner Production},
volume = {298},
pages = {126675},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.126675},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621008957},
author = {J.C. Sanchez-Carrillo and M.A. Cadarso and M.A. Tobarra},
keywords = {Higher education, Higher education institutions, Sustainability, Innovation, Systematic review, PRISMA},
abstract = {Education has long been praised for its economic benefits, which stem from the developed technical skills and improved health conditions it promotes. Nonetheless, improving the quality of education, including sustainability, has become a policy focus since the Tbilisi Declaration and, more recently, in the Sustainable Development Goals. How to increase the contribution of higher education to sustainability is the subject of a robust debate, not only in terms of graduates’ competencies but also in its linkages to society at large. The objective of the paper is to identify the main concerns and proposed strategies in recent literature on this topic to elucidate how to overcome the gap between the actions and desires of international institutions and stakeholders. A systematic review of the literature in the last five years supported with the PRISMA workflow and a check of natural processing language was undertaken. Five main topics were identified, including economic effects from higher education, social impacts, pedagogical-related issues, higher education institutions’ environmental behaviour, and their structural challenges when implementing sustainability. The analysis indicated that institutions have focused on environmental measures but have paid scant attention to society, their communities, collaboration with other institutions, changes in the training of managers and lecturers and the proper assessment of internal structures that drive the commitment of institutions and education to embrace sustainability. Drawing from the literature, a set of five strategies is recommended to lessen the reported problems and further embrace sustainability in higher education. Hence, innovation in management, planning, openness, training of stakeholders in sustainability, negotiation, and building multipartner networks seem to be the key drivers for adopting sustainability.}
}
@article{KATSIKEAS2021100431,
title = {Research communities in cyber security: A comprehensive literature review},
journal = {Computer Science Review},
volume = {42},
pages = {100431},
year = {2021},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2021.100431},
url = {https://www.sciencedirect.com/science/article/pii/S157401372100071X},
author = {Sotirios Katsikeas and Pontus Johnson and Mathias Ekstedt and Robert Lagerström},
keywords = {Security, Clustering, Community, Systematic literature review},
abstract = {In order to provide a coherent overview of cyber security research, the Scopus academic abstract and citation database was mined to create a citation graph of 98,373 authors active in the field between 1949 and early 2020. The Louvain community detection algorithm was applied to the graph in order to identify existing research communities. The analysis discovered twelve top-level communities: access control, authentication, biometrics, cryptography (I & II), cyber–physical systems, information hiding, intrusion detection, malwares, quantum cryptography, sensor networks, and usable security. These top-level communities were in turn composed of a total of 80 sub-communities. The analysis results are presented for each community in descriptive text, sub-community graphs, and tables with, for example, the most-cited papers and authors. A comparison between the detected communities and topical areas defined by other related work, is also presented, demonstrating a greater researcher emphasis on cryptography, quantum cryptography, information hiding and biometrics, at the expense of laws and regulation, risk management and governance, and security software lifecycle.}
}
@article{YAN2020110625,
title = {A new probabilistic frequency-domain approach for influence line extraction from static transmissibility measurements under unknown moving loads},
journal = {Engineering Structures},
volume = {216},
pages = {110625},
year = {2020},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2020.110625},
url = {https://www.sciencedirect.com/science/article/pii/S0141029620305228},
author = {Wang-Ji Yan and Ka-Veng Yuen},
keywords = {Influence line, Bayesian analysis, Moving loads, Transmissibility, Structural health monitoring, Bridge},
abstract = {On the basis of the amazing theoretical finding that there is equivalence between the static transmissibility subjected to moving loads and the ratio of two influence lines in the frequency domain, a new approach is proposed to extract the influence lines for a beam-like structure under moving loads. To accommodate the uncertainties involved in the measurements as well as modelling error, the relationship between response measurements and the Fourier transform of influence lines is embedded in the framework of Bayesian inference with the aid of complex-valued probabilistic model of prediction error. The formulas are presented for closed-form transformation between the solutions of FFT coefficients and those of inverse FFT coefficients. Analytical solutions of the Most Probable Values (MPVs) as well as posterior uncertainties of the influence lines in both frequency domain and spatial domain are derived. Two applications are conducted to verify the efficiency and accuracy of the fast Bayesian scheme. It is shown that the new approach can be realized by avoiding the ill-poseness nature of inverse problem. Due to the introduction of the concept of static transmissibility, given that the reference influence line is known in advance, this method possesses an obvious advantage in avoiding using the knowledge of the moving loads. As a frequency-domain approach, it can reduce the computational complexity of influence line extraction by avoiding complicated matrix manipulation.}
}
@article{ZENG2020102697,
title = {Integrating Internet media into urban flooding susceptibility assessment: A case study in China},
journal = {Cities},
volume = {101},
pages = {102697},
year = {2020},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2020.102697},
url = {https://www.sciencedirect.com/science/article/pii/S0264275118310989},
author = {Zhongping Zeng and Jinyu Lan and Abdur Rahim Hamidi and Shangjun Zou},
keywords = {Citizen science, Internet-based media, Urban flooding susceptibility assessment, Wuhan, Urban resilience, Sustainability},
abstract = {This study demonstrates the value of the public and of media observations (i.e. ‘citizen science’) for the modeling and understanding of the predisposing factors of urban flooding as a contribution to flooding hazard assessment. The 2016 Wuhan flood in the center of China utilized observations of non-scientists' from Internet media to capture the spatial distribution of urban flooding. Various sources in online news, blogs, bbs, and governmental websites were included. Independent flood-related factors such as rainfall, wetlands degradation, elevation, land use and land cover, curvature, slope, and normalized difference vegetation index were integrated into a logistic regression model to produce a susceptibility map. The feasibility and accuracy of this model was evaluated via comparison with official inundation maps and shortcomings of previous drainage system design. The accuracy assessment by receiver operating characteristics curve analysis estimated a success rate of 95.4%. This result shows that the data from mainstream media and public observations provide accurate and comparable information on flood occurrence at the urban scale. The assessment can be used to plan and design preventative drainage strategies for decision-makers. Finally, the limitations of Internet media as a new data resource for flooding risk assessment and future directions are discussed.}
}
@article{ATZORI2019200,
title = {SDN&NFV contribution to IoT objects virtualization},
journal = {Computer Networks},
volume = {149},
pages = {200-212},
year = {2019},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618312933},
author = {L. Atzori and J.L. Bellido and R. Bolla and G. Genovese and A. Iera and A. Jara and C. Lombardo and G. Morabito},
keywords = {Internet of Things, Network functions virtualization, Virtual Object, Mobile Edge Computing},
abstract = {The Internet of Things paradigm will certainly be one of the main drivers of the tomorrow's 5th generation (5G) wireless networks. In order to support the algorithms required for real time exchange and analysis of great amounts of data among the involved smart devices, Virtual Objects (VO) have become a key component to improve the objects energy management efficiency, as well as to address heterogeneity and scalability issues. Following the research trend of exploiting on-demand cloud computing resources to augment the processing and storage capabilities of IoT devices, this paper addresses the design of a novel infrastructure and paradigm to support the deployment of new personal IoT services inside the infrastructure provider premises. The goal is to bring cloud-computing services much closer to the end-users and to be able to replace physical IoT devices with their “Virtual Images”. Among other benefits, this approach will ensure a longer lifetime to IoT constrained devices and enable the inclusion of new protocols making the development of logic and the configuration of IoT smart application environment technology-agnostic. To achieve this goal, we have developed an open-source software platform that exploits OpenStack APIs and leverages a web interface providing all the functionality typically available in a home gateway through the OpenWRT Linux distribution. Results show this approach brings a manifest reduction in the amount of data transmitted, with benefits in terms of reduced workload and power consumption as well as extended device lifetime.}
}
@article{TEMESVARI2019600,
title = {Review of Mobile Communication and the 5G in Manufacturing},
journal = {Procedia Manufacturing},
volume = {32},
pages = {600-612},
year = {2019},
note = {12th International Conference Interdisciplinarity in Engineering, INTER-ENG 2018, 4–5 October 2018, Tirgu Mures, Romania},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2019.02.259},
url = {https://www.sciencedirect.com/science/article/pii/S235197891930294X},
author = {Zsolt Marcell Temesvári and Dóra Maros and Péter Kádár},
keywords = {Mobile communication, Indoor systems, 5G, manufacturing, Innovation},
abstract = {This article intends to demonstrate the importance of cutting-edge technologies in providing mobile coverage in factories and in industrial buildings. The current paper examines indoor and outdoor radio network systems and investigates already operating mobile networks, as well as the 5G, which is currently in the state of standardisation [1]. Furthermore, building on the available data transfer rates, current article - relying on the standardisation process – estimates the preference of the 5G within manufacturing. In the world of IoT (Internet of Things) [2], M2M (Machine-to-Machine Communication) [3] and Smart Factories [4], the available mobile networks most likely will not be able to handle the high traffic load sufficiently [5]. The article seeks to answer whether the development of new mobile technologies will be able to support the Industry 4.0 revolution for Smart Factories and manufacturers [6].}
}
@article{GULERIA2021102473,
title = {An enhanced energy proficient clustering (EEPC) algorithm for relay selection in heterogeneous WSNs},
journal = {Ad Hoc Networks},
volume = {116},
pages = {102473},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102473},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521000408},
author = {Kalpna Guleria and Anil Kumar Verma and Nitin Goyal and Ajay Kumar Sharma and Abderrahim Benslimane and Aman Singh},
keywords = {Clustering, Cluster head, Enhanced energy proficient clustering (EEPC), Power consumption, Sensor data fusion},
abstract = {The recent advancements in Wireless Sensor Networks (WSNs) have brought attention to the field of sensor tracking events. Habitat monitoring is considered as one of the most important applications of WSNs, which ensures wildlife conservation. Researchers have proposed various solutions to select the optimal path in the field of sensor tracking. However, energy dissipation of sensor nodes and fault tolerance during data transformation is still one of the major challenges of the WSN environment in dynamic scenarios. In this paper, an Enhanced Energy Proficient Clustering (EEPC) is proposed to reduce the energy consumption of the entire sensor nodes in the field of tracking events. The network is created with both fixed and mobile nodes. Initially, fixed nodes broadcast information, and mobile nodes select the cluster head from fixed nodes. The mobile nodes select their cluster head (CH) based on their associated placement and energy level. Mobile sensor nodes (SNs) transmit data to the CH. It introduces the concept of finding relay nodes, which are fixed nodes. The EEPC algorithm selects the relay nodes based on their velocity and location by calculating particle fitness value. The selected intermediate relay nodes transmit the collected information to the Base Station (BS) using the sensor data fusion technique. The link fault of nodes could be predicted based on the deviation value. The simulation results show that the proposed approach points out progress with reference to various performance metrics. The proposed work minimizes the energy depletion and enhances the network lifetime compared to other existing protocols.}
}
@article{LAI2018166,
title = {Quantifying place: Analyzing the drivers of pedestrian activity in dense urban environments},
journal = {Landscape and Urban Planning},
volume = {180},
pages = {166-178},
year = {2018},
issn = {0169-2046},
doi = {https://doi.org/10.1016/j.landurbplan.2018.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0169204618308491},
author = {Yuan Lai and Constantine E. Kontokosta},
keywords = {Pedestrian mobility, Walkability, Urban planning, Urban computing, Machine learning, Urban data},
abstract = {Understanding pedestrian behavior is critical for many aspects of city planning, design, and management, including transportation, public health, emergency response, and economic development. This study bridges in-situ observations of pedestrian activity and urban computing by integrating high-resolution, large-scale, and heterogeneous urban datasets and analyzing both fixed attributes of the urban landscape (e.g. physical and transit infrastructure) with dynamic environmental and socio-psychological factors, such as weather, air quality, and perceived crime risk. We use local pedestrian count data collected by the New York City (NYC) Department of Transportation (DOT) and an extensive array of open datasets from NYC to test how pedestrian volumes relate to land use, building density, streetscape quality, transportation infrastructure, and other factors typically associated with urban walkability. We quantify, classify, and analyze place dynamics, including contextual and situational factors that influence pedestrian activity at high spatial–temporal resolution. The quantification process measures the urban context by extracting rich, yet initially fragmented and siloed, urban data for individual geolocations. Based on these features, we then construct contextual indicators by selecting and combining features relevant to pedestrian activity, and develop a typology of place to support the generalizability of our analysis. Finally, we use multivariate regression models with panel-corrected standard errors to estimate how specific contextual features and time-varying situational indicators impact pedestrian activity across time of day, day of the week, season, and year. The results provide insights into the key drivers of local pedestrian activity and highlight the importance accounting for the immediate urban environment and socio-spatial dynamics in pedestrian behavior modeling.}
}
@article{FATTORUSO2015927,
title = {Optimal Sensors Placement for Flood Forecasting Modelling},
journal = {Procedia Engineering},
volume = {119},
pages = {927-936},
year = {2015},
note = {Computing and Control for the Water Industry (CCWI2015) Sharing the best practice in water management},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2015.08.971},
url = {https://www.sciencedirect.com/science/article/pii/S1877705815026417},
author = {Grazia Fattoruso and Annalisa Agresta and Guido Guarnieri and Bruno Lanza and Antonio Buonanno and Mario Molinara and Claudio Marrocco and Saverio {De Vito} and Francesco Tortorella and Girolamo Di Francia},
keywords = {Sampling design, model calibration, hydro-rain gauges, hydrological modelling, flooding forecasting},
abstract = {Numerical models are instrumental to more effective flood forecasting and managementservices though they suffer from numerous uncertaintysources. An effective model calibration is hence essential. In this research work,a methodology of optimal sampling design has been investigated and developed forwater drainage networks. Optimal hydrometer sensors locationsalong the Amato River (South Italy)have been defined by optimizing a two-objective function that maximizes the calibrated model accuracy and minimizesthe total metering cost. This problem has been solved by using an enumerative search solution, run on the ENEA/CRESCO HPC infrastructure, evaluating the exact Pareto-front byefficient computational time.}
}
@article{WENG2018116,
title = {Mining urban passengers’ travel patterns from incomplete data with use cases},
journal = {Computer Networks},
volume = {134},
pages = {116-126},
year = {2018},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.01.048},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618300574},
author = {Xiaoxiong Weng and Yongxin Liu and Houbing Song and Shushen Yao and Pengfei Zhang},
keywords = {Data mining, Public transit system, Transit demands, Urban analysis, Closed transit chains},
abstract = {The rapid development of the Internet of Things (IoT) and Intelligent and Connected Transportation Systems (ICTS) are making our city smarter and greener. For large cities with millions of population, their public transit systems are of great significance to mitigating the road congestion along with reducing the emission of greenhouse gases. One critical problem transit authorities encounter is that they can not clearly understand the actual behavioral preference and travel demand of their passengers, worse even, nowadays, the passively collected data from IoT devices do not guarantee the integrity of information and make it more difficult. To address these problems, in this research, we first propose a novel framework to derive passengers’ closed transit chains along with their home and work locations from incomplete travel records using an information enrichment and probabilistic inference approach. We then leverage both evaluation and volunteers’ records to evaluate the usability and theoretical boundaries of our methods. We finally apply our proposed framework to mine a series of useful information about the city and behavioral preferences of our passengers. Our proposed methods are applicable to mining individuals’ behavioral patterns from sparsely collected crowdsourcing data in future.}
}
@article{ZHANG2018107,
title = {A sensor-based wrist pulse signal processing and lung cancer recognition},
journal = {Journal of Biomedical Informatics},
volume = {79},
pages = {107-116},
year = {2018},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2018.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S153204641830011X},
author = {Zhichao Zhang and Yuan Zhang and Lina Yao and Houbing Song and Anton Kos},
keywords = {Lung cancer recognition, Pulse signal processing and analysis, Iterative sliding window (ISW), Feature extraction, Jin’s pulse diagnosis (JPD), Cubic support vector machine (CSVM)},
abstract = {Pulse diagnosis is an efficient method in traditional Chinese medicine for detecting the health status of a person in a non-invasive and convenient way. Jin’s pulse diagnosis (JPD) is a very efficient recent development that is gradually recognized and well validated by the medical community in recent years. However, no acceptable results have been achieved for lung cancer recognition in the field of biomedical signal processing using JPD. More so, there is no standard JPD pulse feature defined with respect to pulse signals. Our work is designed mainly for care giving service conveniently at home to the people having lung cancer by proposing a novel wrist pulse signal processing method, having an insight from JPD. We developed an iterative slide window (ISW) algorithm to segment the de-noised signal into single periods. We analyzed the characteristics of the segmented pulse waveform and for the first time summarized 26 features to classify the pulse waveforms of healthy individuals and lung cancer patients using a cubic support vector machine (CSVM). The result achieved by the proposed method is found to be 78.13% accurate.}
}
@article{LI2020988,
title = {A lightweight and aggregated system for indoor/outdoor detection using smart devices},
journal = {Future Generation Computer Systems},
volume = {107},
pages = {988-997},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.05.028},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X1730506X},
author = {Shengnan Li and Zheng Qin and Houbing Song and Chengxiang Si and Bo Sun and Xiao Yang and Renwei Zhang},
abstract = {Location-based service (LBS) has aroused general interest in both industrial and academic fields. Various scenarios require different localization techniques. Outdoor localization usually needs GPS as the core means and draws support from other sensors or methods. When the situation comes to indoor localization, WiFi received signal strength (RSS), channel state information (CSI), and bluetooth form the mainstream trends. However, there is an obvious gap between these two localization architectures. In this study, we devise an “IOS” (I ndoor, O utdoor, and S emi-open) detection system. For the lightweight need, a WiFi-based sub-detector is implemented. Using only WiFi sensor and a weak learner, the sub detector is easy to use and energy saving. For the precision demand, an aggregated IOS detector based on a semi-CRF (semi-Markov conditional random fields) algorithm is designed. The attribute of semi-CRF uncovers the interdependency between IOS states, so that it guarantees the accuracy of the detection. The evaluation results show that IOS detector can achieve an over 96% accuracy in tested environments. This detection technique holds the potential to realize the seamless localization from indoor to outdoor, and vice versa.}
}
@article{CLARKE2018677,
title = {The information infrastructures of 1985 and 2018: The sociotechnical context of computer law & security},
journal = {Computer Law & Security Review},
volume = {34},
number = {4},
pages = {677-700},
year = {2018},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2018.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0267364918301870},
author = {Roger Clarke and Marcus Wigan},
keywords = {Infrastructural resilience, Consumer rights, Human rights, Accountability, Income distribution, Societal and political resilience},
abstract = {This article identifies key features of the sociotechnical contexts of computer law and security at the times of this journal's establishment in 1985, and of its 200th Issue in 2018. The infrastructural elements of devices, communications, data and actuator technologies are considered first. Social actors as individuals, and in groups, communities, societies and polities, together with organisations and economies, are then interleaved with those technical elements. This provides a basis for appreciation of the very different challenges that confront us now in comparison with the early years of post-industrialism.}
}
@article{RR2018686,
title = {Market Clearing Mechanism Considering Congestion under Deregulated Power System},
journal = {Procedia Computer Science},
volume = {143},
pages = {686-693},
year = {2018},
note = {8th International Conference on Advances in Computing & Communications (ICACC-2018)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.10.447},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918321458},
author = {Lekshmi R.R. and S. Swathy and B. Lakshmi and N. {Vamsi Sai} and V. {Suraj Vijaykumar}},
keywords = {Congestion management, deregulated power system, poolco market},
abstract = {Deregulation in power industry involves restructuring of rules and regulations, set up by the government. The new scenario is brought into practice mainly as a result of privatization, together with the encouragement of innovation of new technology. These factors are expected to reduce the cost of electrical energy. Deregulation creates a platform called as power market where electricity is traded as a commodity. The power market can be single buyer, bilateral or poolco model. Under single buyer model, the market is cleared in a pool by conducting single sided auction among suppliers, for each time slot, for a predicted demand. Bilateral model allows suppliers and buyers to enter into contract for an amount of power during a time period. Under poolco model, the market is cleared by performing double sided auction that involves both suppliers and buyers. Once the market is cleared, market clearing price, in-merit suppliers and buyers with their allotted power, power flow through transmission line between areas are determined. However, the scheduling of power is not coordinated with transmission planning. This results in transmission congestion. One of the methods to negate congestion is to split the market at the predicted congestion bottleneck. This paper presents a real time market clearing hardware model that accepts auction data and clears the market considering transmission congestion. The proposed model uses raspberry pi board that performs market clearing based on offers and bids accepted from a created webpage. The transmission congestion is managed by splitting the market at the predicted congestion bottleneck. The effectiveness of the proposed model is tested on three area deregulated power system.}
}
@article{BELLO2021103441,
title = {Cloud computing in construction industry: Use cases, benefits and challenges},
journal = {Automation in Construction},
volume = {122},
pages = {103441},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103441},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520310219},
author = {Sururah A. Bello and Lukumon O. Oyedele and Olugbenga O. Akinade and Muhammad Bilal and Juan Manuel {Davila Delgado} and Lukman A. Akanbi and Anuoluwapo O. Ajayi and Hakeem A. Owolabi},
keywords = {Cloud computing, Emerging technologies, Construction industry, Future trends},
abstract = {Cloud computing technologies have revolutionised several industries for several years. Although the construction industry is well placed to leverage these technologies for competitive and operational advantage, the diffusion of the technologies in the industry follows a steep curve. This study therefore highlights the current contributions and use cases of cloud computing in construction practices. As such, a systematic review was carried out using ninety-two (92) peer-reviewed publications, published between 2009 and 2019. A key highlight of the findings is that cloud computing is an innovation delivery enabler for other emerging technologies (building information modelling, internet of things, virtual reality, augmented reality, big data analytics) in the construction industry. As such, this paper brings to the fore, current and future application areas of cloud computing in the construction industry. The paper also identifies barriers to broader adoption of cloud computing in the construction industry and discusses strategies for overcoming these barriers.}
}
@article{LI2022126591,
title = {A force-driven model for passenger evacuation in bus fires},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {589},
pages = {126591},
year = {2022},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2021.126591},
url = {https://www.sciencedirect.com/science/article/pii/S037843712100861X},
author = {Zhenning Li and Chengzhong Xu and Zilin Bian},
keywords = {Human evacuation, Bus fires, Smoothed particle hydrodynamics, Human motion},
abstract = {A generic evacuation model is developed based on the behavioral characteristics of passengers during bus fires. Inspired by hydrodynamic mechanisms, the proposed particle-based force-driven model is built using force analysis of evacuees and analogs the movement of people as fluid motion. Several modules are developed to characterize evacuees’ preferences for varying exits, aggregated behavior of groups, and effects of driver. The Smoothed Particle Hydrodynamics (SPH) methods are applied to solve the proposed model using smoothed kernel functions. Experiments are conducted to calibrate and validate the proposed model based on observed evacuees’ behavioral characteristics, such as evacuation time, evacuation speed under different scenarios in terms of bus capacity, and the interaction between evacuees. The results of the study will contribute to a better understanding of bus evacuation options, improved design of bus vehicles to cope with internal fires, and the development of appropriate policies and regulations for bus passenger evacuation in response to fires. The proposed method can also be readily applied to other related fields with minor modifications.}
}
@article{KADAVERUGU2021100912,
title = {Improving accuracy in simulation of urban wind flows by dynamic downscaling WRF with OpenFOAM},
journal = {Urban Climate},
volume = {38},
pages = {100912},
year = {2021},
issn = {2212-0955},
doi = {https://doi.org/10.1016/j.uclim.2021.100912},
url = {https://www.sciencedirect.com/science/article/pii/S2212095521001425},
author = {Rakesh Kadaverugu and Vigna Purohit and Chandrasekhar Matli and Rajesh Biniwale},
keywords = {Dynamic downscaling, OpenFOAM, Surface wind, Urban micro-climate, Urban canopy model, WRF model, CFD model},
abstract = {Managing urban air systems is now on top priority. The local wind flow at the building scale is governed by the urban morphology, which is difficult to be captured by the parameterizations of the regional scale weather models. In this study, we dynamically downscaled the 1 km resolution wind flow simulated by the WRF-UCM (Weather Research and Forecasting with Urban Canopy Model) to the building scale (<10 m), by integrating it with the OpenFOAM (Open Field Operation and Manipulation, OF) computational fluid dynamics model (WRF-UCM + OF). The Reynolds Averaged Navier Stokes k-ε turbulence model has been used with a steady-state solver in the OF. Momentum sink due to vegetation has been accounted for by Darcy-Forchheimer model. The model simulated hourly 10-m wind speed and direction in a 1 km2 area were evaluated with the measured values during January 11–18, 2018 over Nagpur City, India. The results show that WRF-UCM + OF has captured the wind direction more accurately than the WRF-UCM. The WRF-UCM + OF simulated wind speed has significantly low normalized mean bias (NMB = −0.002) and low normalized mean gross error (NMGE = 0.588) when compared with that of the WRF-UCM model (NMB = 1.083 and NMGE = 1.216).}
}
@article{MOSAAD2019101469,
title = {Optimal PI controller of DVR to enhance the performance of hybrid power system feeding a remote area in Egypt},
journal = {Sustainable Cities and Society},
volume = {47},
pages = {101469},
year = {2019},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2019.101469},
url = {https://www.sciencedirect.com/science/article/pii/S2210670718320195},
author = {Mohamed I. Mosaad and M. Osama {Abed El-Raouf} and Mahmoud A. Al-Ahmar and Fahmy M. Bendary},
keywords = {Cuckoo search (CS), Dynamic voltage restorer (DVR), Fuel cell, Hybrid system, Photovoltaic (PV), Wind turbine},
abstract = {This article proposes optimal PI controllers of Dynamic Voltage Restorer (DVR) to enhance the performance of stand-alone hybrid renewable energy system that is feeding a new community located in Egypt. The hybrid system includes three renewable energy sources, namely, solar PV cells, wind turbines based permanent magnet synchronous generator and fuel cells. These three sources are connected to a common DC link by three boost converters, one for each source. The common DC link is integrated to the AC loads via DC/AC inverter. The optimal size of the three proposed renewable sources is obtained using the HOMER software package. The main contribution of this study is designing optimal PI controller for DVR for enhancing the performance of a hybrid PV-wind-fuel cell. Two PI controllers are used to regulate the IGBT pulses of the voltage source inverter (VSI) driving DVR by adjusting the D-Q axes voltage signals. The D-Q axis components of the load voltage represent the inputs to the two PI controllers respectively. While the D-Q axis voltage signals driving the IGBT pulses of the DVR-VSI IGBT are the outputs of the two PI controllers respectively. A Cuckoo Search (CS), as an optimization technique is used for determining the optimal PI control parameters used to drive the DVR at different operating conditions. To validate the effectiveness of the DVR based PI-CS control, four test scenarios are investigated includes (three phase fault, sag, swell and unbalance voltage conditions). The enhancement of the system performance is achieved through improving the voltage, the current and the power waveforms for each source, improving the dynamic performance of the wind turbine generator and keeping the continuous operation of the three sources during faulty conditions. The proposed system is modeled using MATLAB/Simulink.}
}
@article{ALAM2019100,
title = {Bio-inspired smog sensing model for wireless sensor networks based on intracellular signalling},
journal = {Information Fusion},
volume = {49},
pages = {100-119},
year = {2019},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2018.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S1566253517306218},
author = {Sahabul Alam and Debashis De},
keywords = {Wireless sensor network, Intracellular signalling, Smog sensing model},
abstract = {The progression of wireless sensor networks has been formulated a new orientation of research particularly in the monitoring and surveillance areas. Smog pollution is a threat throughout the world presently. Smog affects on public along with plants life. This article proposes a wireless sensor network based smog sensing model for a city by mimicking of biological intracellular signalling. The proposed model is designed and simulated using QualNet 7.1. The several performance features like energy consumption, signals transmission, data transmission of AODV, Bellman–Ford and IERP routing protocols have been evaluated through the proposed model. The simulation result shows that the AODV routing protocol is at least 18.73% and utmost 6.14% energy efficient than Bellman–Ford and IERP routing protocol subsequently. Finally, the merits of the proposed model have been addressed.}
}
@article{CAMPANA201775,
title = {Recommender Systems for Online and Mobile Social Networks: A survey},
journal = {Online Social Networks and Media},
volume = {3-4},
pages = {75-97},
year = {2017},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2017.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S2468696417300885},
author = {Mattia G. Campana and Franca Delmastro},
keywords = {Recommender Systems, Online Social Networks, Mobile Social Networks},
abstract = {Recommender Systems (RS) currently represent a fundamental tool in online services, especially with the advent of Online Social Networks (OSN). In this case, users generate huge amounts of contents and they can be quickly overloaded by useless information. At the same time, social media represent an important source of information to characterize contents and users’ interests. RS can exploit this information to further personalize suggestions and improve the recommendation process. In this paper we present a survey of Recommender Systems designed and implemented for Online and Mobile Social Networks, highlighting how the use of social context information improves the recommendation task, and how standard algorithms must be enhanced and optimized to run in a fully distributed environment, as opportunistic networks. We describe advantages and drawbacks of these systems in terms of algorithms, target domains, evaluation metrics and performance evaluations. Eventually, we present some open research challenges in this area.}
}
@article{LIN2016241,
title = {The distributed system for inverted multi-index visual retrieval},
journal = {Neurocomputing},
volume = {215},
pages = {241-249},
year = {2016},
note = {SI: Stereo Data},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.11.131},
url = {https://www.sciencedirect.com/science/article/pii/S0925231216306427},
author = {Xianming Lin and Yunhang Shen and Ling Cai and Rongrong Ji},
keywords = {Distributed inverted multi-index, APC-PQ, Visual retrieval},
abstract = {With the explosive growth of visual databases, it is infeasible to maintain the huge indexing structures within the memory of a single server. In this paper, a distributed visual retrieval system based on inverted multi-index is proposed to generate a huge codebook with very low memory consumption and time cost. In order to improve the performance of product quantization, a vector space decomposition strategy is performed by affinity propagation clustering. In the meantime, a distributed framework is introduced to inverted multi-index to improve the time efficiency. Our works are validated on the large scale database of INRIA Holidays and Flickr 1M. The results of our experiments indicate that the performance of PQ is greatly improved and the visual retrieval system is speeded up at comparable precision.}
}
@article{MARGARA201424,
title = {Streaming the Web: Reasoning over dynamic data},
journal = {Journal of Web Semantics},
volume = {25},
pages = {24-44},
year = {2014},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2014.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S1570826814000067},
author = {Alessandro Margara and Jacopo Urbani and Frank {van Harmelen} and Henri Bal},
keywords = {Semantic Web, Stream reasoning, Survey, Stream processing, Complex Event Processing},
abstract = {In the last few years a new research area, called stream reasoning, emerged to bridge the gap between reasoning and stream processing. While current reasoning approaches are designed to work on mainly static data, the Web is, on the other hand, extremely dynamic: information is frequently changed and updated, and new data is continuously generated from a huge number of sources, often at high rate. In other words, fresh information is constantly made available in the form of streams of new data and updates. Despite some promising investigations in the area, stream reasoning is still in its infancy, both from the perspective of models and theories development, and from the perspective of systems and tools design and implementation. The aim of this paper is threefold: (i) we identify the requirements coming from different application scenarios, and we isolate the problems they pose; (ii) we survey existing approaches and proposals in the area of stream reasoning, highlighting their strengths and limitations; (iii) we draw a research agenda to guide the future research and development of stream reasoning. In doing so, we also analyze related research fields to extract algorithms, models, techniques, and solutions that could be useful in the area of stream reasoning.}
}
@article{ALIELDIN20183103,
title = {Trust prediction in online social rating networks},
journal = {Ain Shams Engineering Journal},
volume = {9},
number = {4},
pages = {3103-3112},
year = {2018},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2018.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S2090447918300418},
author = {Amr M.T. Ali-Eldin},
keywords = {Online social rating networks, Trust prediction, Trust propagation, Malicious recommendations},
abstract = {Previous research on trust prediction in online social rating networks focused on users’ history of interactions in evaluating the reputation of other users, service providers or products. Nevertheless, these approaches still suffer from malicious or inconsistent recommendations where the prediction problem turns out to be rather difficult. In this paper, we take up the challenge of coming up with a better solution by introducing a new global trust computation model that makes use of the recommendations made by what we call trusted parties in weighing users ratings. These entities gain higher reputation levels compared to others. Further, a sampling approach is proposed to capture new developments or changes during runtime based on a trust propagation technique. The proposed techniques are applied on the Epinion.com dataset. Empirical work shows the effectiveness of the proposed techniques in trust prediction compared to related work.}
}
@article{TROISI2020538,
title = {Growth hacking: Insights on data-driven decision-making from three firms},
journal = {Industrial Marketing Management},
volume = {90},
pages = {538-557},
year = {2020},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2019.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0019850118308496},
author = {Orlando Troisi and Gennaro Maione and Mara Grimaldi and Francesca Loia},
keywords = {Business-to-business (B2B), High-tech companies, Big data analytics, Cognitive computing, Marketing decisions, Growth hacking marketing, Action research},
abstract = {Theoretical background
The work explores how Big Data analysis can reshape marketing decision-making in B2B sector. Deriving from Data-Driven Decision-Making (DDDM) approach, the Growth Hacking model is employed to investigate the role of cognitive computing and big data analytics in redefining business processes.
Purpose
The main objectives of the study are: 1) to assess how a data-driven orientation to the use of big data analytics and cognitive computing can reframe marketing decisions in B2B segment; 2) to explore whether the adoption Growth Hacking can be helpful in exploiting the opportunities offered by big data analytics and cognitive computing in B2B marketing.
Methodology
The paper is based on Action Research (AR) methodology that permits researchers to participate actively in the observation of businesses and to examine how decisions are undertaken and managed over time.
Results
The main findings allow identifying the most common strategies and tactics employed in three companies operating in different B2B sectors to exploit the opportunities offered by cognitive computing and big data analytics according to a data-driven marketing approach. Based on the application of the Growth Hacking model, the tools of analytics and the main objectives, outcomes and implications on marketing decision-making are revealed.
Originality
The identification of the main objectives and outcomes produced across the three dimensions of the Growth Hacking model (data analysis, marketing and programming) can help academics and practitioners to understand the main levers to attain marketing goals, such as the enhancement of relationship with customers (CRM), continuous learning and development of new products and potential innovation.}
}
@article{CAI2021107910,
title = {Binary searching iterative algorithm for generating test cases to cover paths},
journal = {Applied Soft Computing},
volume = {113},
pages = {107910},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107910},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621008322},
author = {Gaocheng Cai and Qinghua Su and Zhongbo Hu},
keywords = {Automated test case generation, Binary searching iterative algorithm, Dimensional relevance of test cases, Path coverage},
abstract = {Similar paths are usually covered by similar test cases, which is one of the characteristics of automated test case generation for path coverage. Based on this characteristic, this paper proposes a novel search-based algorithm for generating test cases to satisfy path coverage criterion, called binary searching iterative algorithm. The proposed algorithm first selects an uncovered path as a target path, which is most similar to the path covered by a discovered test case. Then it performs a binary search in both the left and right regions of each element of the discovered test case under the guidance of a fitness function for the target path. Binary searching iterative algorithm can quickly find undiscovered test case covering the target path because of making full use of the characteristic of automated test case generation for path coverage. Experimental studies on six fog computing benchmark programs and six natural language processing benchmark programs show that the proposed algorithm can achieve the highest path coverage for all the twelve benchmark programs, and the average number of test cases obtained by the proposed algorithm is significantly less than those obtained by a number of state-of-the-art algorithms for eleven out of the twelve benchmark programs. Moreover, binary searching iterative algorithm is more appropriate for ALBD-based fitness function than BD-based fitness function.}
}
@article{SCHIPOR201943,
title = {Euphoria: A Scalable, event-driven architecture for designing interactions across heterogeneous devices in smart environments},
journal = {Information and Software Technology},
volume = {109},
pages = {43-59},
year = {2019},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2019.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0950584919300096},
author = {Ovidiu-Andrei Schipor and Radu-Daniel Vatavu and Jean Vanderdonckt},
keywords = {Context-aware computing, Mobile computing, Wearable computing, Multi-device interaction, Smart environments, Smart spaces, Software architecture},
abstract = {Context: From personal mobile and wearable devices to public ambient displays, our digital ecosystem has been growing with a large variety of smart sensors and devices that can capture and deliver insightful data to connected applications, creating thus the need for new software architectures to enable fluent and flexible interactions in such smart environments. Objective: We introduce Euphoria, a new software architecture design and implementation that enables easy prototyping, deployment, and evaluation of adaptable and flexible interactions across heterogeneous devices in smart environments. Method: We designed Euphoria by following the requirements of the ISO/IEC 25010:2011 standard on Software Quality Requirements and Evaluation applied to the specific context of smart environments. Results: To demonstrate the adaptability and flexibility of Euphoria, we describe three application scenarios for contexts of use involving multiple users, multiple input/output devices, and various types of smart environments, as follows: (1) wearable user interfaces and whole-body gesture input for interacting with public ambient displays, (2) multi-device interactions in physical-digital spaces, and (3) interactions on smartwatches for a connected car application scenario. We also perform a technical evaluation of Euphoria regarding the main factors responsible for the magnitudes of the request-response times for producing, broadcasting, and consuming messages inside the architecture. We deliver the source code of Euphoria free to download and use for research purposes. Conclusion: By introducing Euphoria and discussing its applicability, we hope to foster advances and developments in new software architecture initiatives for our increasingly complex smart environments, but also to readily support implementations of novel interactive systems and applications for smart environments of all kinds.}
}
@article{ZHANG2021114729,
title = {Strategies for the efficient estimation of soil organic matter in salt-affected soils through Vis-NIR spectroscopy: Optimal band combination algorithm and spectral degradation},
journal = {Geoderma},
volume = {382},
pages = {114729},
year = {2021},
issn = {0016-7061},
doi = {https://doi.org/10.1016/j.geoderma.2020.114729},
url = {https://www.sciencedirect.com/science/article/pii/S0016706119325479},
author = {Zipeng Zhang and Jianli Ding and Chuanmei Zhu and Jingzhe Wang and Guolin Ma and Xiangyu Ge and Zhenshan Li and Lijing Han},
keywords = {Laboratory Vis-NIR spectra, Spectral configuration, Principal component analysis, Optimal spectral variable, Partial least-squares-support vector machine},
abstract = {Visible and near-infrared (Vis-NIR) spectroscopy is a cost-effective technique for alternative soil physical and chemical analyses for estimating soil properties. The optimal band combination algorithm is an effective method of extracting spectral variables by considering the interaction information between wavebands, but for laboratory Vis-NIR spectral data, this method is susceptible to the “dimensional curse”. Here, we hypothesized that properly degrading the spectral configuration (i.e., decreasing the number of spectral bands and coarsening the spectral resolution) can improve the computational efficiency without affecting the prediction accuracy. To test this hypothesis, we constructed six degraded spectral configurations from an initial spectral database (i.e., consisting of 2001 spectral bands acquired with a portable ASD spectroradiometer) with a reduction in the number of spectral bands from 2001 to 19, a coarsened spectral resolution from 3 to 100 nm, and a spectral sampling interval equal to the spectral resolution (i.e., uniform interval sampling). In this study, the databases consisted of 255 soil samples collected from the Ebinur Lake area in Northwest China. The relationship between the soil organic matter (SOM) and the spectra was established using a partial least-squares-support vector machine (PLS-SVM) through two strategies: one is in accordance with the different salinity levels, and the other involves applying the optimal band combination algorithm from each spectral configuration. The results indicated that the soil salinity had a strong negative influence on the performance of the SOM models (R2cv, 0.46–0.81). However, the optimal band combination algorithm can improve the sensitivity (R2pre, 0.36–0.65) of spectral information and the SOM. Overall, the prediction accuracy obtained through the optimal band combination algorithm was generally superior to that from full-spectrum data. The prediction performance of the optimal band combination algorithm was accurate (R2pre ≥ 0.85) and stable (RPIQ pre, ~3.20), with a spectral resolution between 3 and 20 nm (i.e., the number of spectral bands decreased from 2001 to 99). Considering the accuracy and time-consuming nature of this approach, the combination of a 20 nm spectral resolution and an optimal band combination algorithm was the most effective method. In summary, this research will guide future studies in transforming hyperspectral datasets into parsimonious representations and uses the optimal band combination algorithm efficiently to determine the informative variable. Furthermore, the optimal band combination algorithm has broad application prospects in soil Vis-NIR spectroscopy and other fields of spectroscopy.}
}
@article{OJUTKANGAS2022102283,
title = {A deep dive into the birth process of linking 6G and the UN SDGs},
journal = {Telecommunications Policy},
volume = {46},
number = {1},
pages = {102283},
year = {2022},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2021.102283},
url = {https://www.sciencedirect.com/science/article/pii/S0308596121001877},
author = {Kirsi Ojutkangas and Elina Rossi and Marja Matinmikko-Blue},
keywords = {5G, 6G, Sustainability, UN SDG},
abstract = {United Nations Sustainable Development Goals (UN SDGs) are becoming an increasingly important theme for researchers in multiple fields to investigate. In this paper, we look at how a group of 40 experts from academia and the mobile communications industry identified ways in which future 6th generation (6G) mobile communications is linked with the UN SDGs while writing a white paper on the topic. In this paper, building on the methodology of critical participatory action research, we look into the detailed operations of the expert group, offer a new way to look at the 6G development process guided by the UN SDGs and describe the linking process for the UN SDGs and 6G in a way that may guide other researchers in similar endeavors. We also present initial outcomes of the linking process that led to the white paper published in 2020 (Matinmikko-Blue et al., 2020). The aim of this research is to identify and formulate a process to recognise the connection between UN SDGs and 6G.}
}
@article{KAMINSKYY2021107402,
title = {Dendrograms-based disclosure method for evaluating cluster analysis in the IoT domain},
journal = {Computers & Industrial Engineering},
volume = {158},
pages = {107402},
year = {2021},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2021.107402},
url = {https://www.sciencedirect.com/science/article/pii/S0360835221003065},
author = {Roman Kaminskyy and Nataliya Shakhovska and Natalia Kryvinska and Muhammad Younas},
keywords = {Clustering, Dengrogdam disclourse, Quality of clustering, 3D visualization, Data mining, Quality of grouping},
abstract = {The Internet of Things (IoT) generates huge amount of data at an extremely fast pace. Thus, it is important to classify such data objects into different groups or clusters in order to gain some valuable insights from data. This paper aims to develop a dendrograms-based method for 3D visualization of hierarchical clustering for multidimensional data which can be collected from IoT devices and open databases. This method is built on hierarchical clustering algorithm which is simple and efficient. It presents areas of the selected clusters and their objects on a plane, according to the coordinates defined by the open dendrogram. It defines rules for visualization of the dendrogram and allows to find the nature of clusters. The paper also proposes quantitative indicators of localization of objects and evaluation of clusters being formed. The proposed method is evaluated using IoT-based dataset prepared in two different forms. The proposed method significantly improves the quality of visualization and evaluation of cluster analysis results. It is also efficient as the time complexity is significantly less for factorial analysis.}
}
@article{YUAN2019228,
title = {Dimensionality reduction by collaborative preserving Fisher discriminant analysis},
journal = {Neurocomputing},
volume = {356},
pages = {228-243},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219306551},
author = {Ming-Dong Yuan and Da-Zheng Feng and Ya Shi and Wen-Juan Liu},
keywords = {Graph embedding, Discriminant analysis, Dimensionality reduction, Collaborative representation, Regularized least square},
abstract = {Sparse representation-based classifier (SRC) and collaborative representation-based classifier (CRC) are two commonly used classifiers. There has been pointed out that the utilization of all the training samples in representing a query sample (i.e. the least square part), which reflects the collaborative representation mechanism of SRC and CRC, is more important than the norm constraint on the coding coefficients for classification. From this perspective, both SRC and CRC can be viewed as collaborative representation (CR) but with different norm (i.e. L1 and L2) constraints on the coding coefficients. In this paper, two collaborative preserving Fisher discriminant analysis approaches are proposed for linear dimensionality reduction, in which both the local geometric information hidden in the CR coefficients and the global discriminant information inherited from Fisher/linear discriminant analysis (FDA/LDA) are effectively fused. Specifically, a datum adaptive graph is first built via CR with L1 or L2 norm constraint (corresponding to L1CPFDA and L2CPFDA, respectively), and then incorporated into the LDA framework to seek a powerful projection subspace with analytic solution. Both theoretical and experimental analysis of L1CPFDA and L2CPFDA show that they can best preserve the collaborative reconstruction relationship of the data and discriminate samples of different classes as well. Moreover, LDA is a special case of L1CPFDA and L2CPFDA and the available number of projection directions of them are twice that of LDA empirically. Experimental results on ORL, AR and FERET face databases and COIL-20 object database demonstrate their effectiveness, especially in low dimensions and small training sample size.}
}
@article{GUNAWAN2014566,
title = {Optimal Averaging Time for Predicting Traffic Velocity Using Floating Car Data Technique for Advanced Traveler Information System},
journal = {Procedia - Social and Behavioral Sciences},
volume = {138},
pages = {566-575},
year = {2014},
note = {The 9th International Conference on Traffic and Transportation Studies (ICTTS 2014)},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.07.240},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814041603},
author = {Fergyanto E. Gunawan and Fajar Yoseph Chandra},
keywords = {Intelligent Transportation Systems (ITS), Advanced Traveler Information Systems (ATIS), Floating Car Data, Optimal Averaging Time Interval, Ergodicity},
abstract = {Many metropolitan cities are facing the problem of traffic congestion in large scale and high frequency. The congestion can be lessening by employing Intelligent Transportation Systems (ITS) including Advanced Traveler Information Systems (ATIS). ITS systems have been demonstrated and implemented in few advanced countries. For an example, the technology of Electronic Toll Collection (ETC) in Japan has completely eliminated the traffic congestion ahead of toll gates and has reduced CO2 emission by 130000 ton-per-year. Recently, an ATIS system so called Floating Car Data (FCD) technique has received many attentions due to its cost-effectiveness and wide coverage in comparison to traditional systems in providing real-time traffic information. The success of the technique is made possible with the existing and vast coverage of the wireless network and information technology. In regard to FCD technique, although many publications have discussed various issues, none has elaborated the traffic data discrepancy between that provided by the FCD technique and the actual traffic data. This paper discusses the issue and demonstrates that there is an optimum averaging time interval in the FCD technique such that the data recorded by a probe vehicle can reasonably predict the traffic data. The analysis is based on experimental data recorded by Sugiyama et al. (2008) where 22 vehicles were deployed to establish a platoon of vehicles moving in a circular road having 230 m perimeter length. Various averaging time intervals are studied, and one that provides the best estimate of the traffic flow is selected as the optimum averaging time interval.}
}
@article{FENG2020341,
title = {Privacy-preserving computation in cyber-physical-social systems: A survey of the state-of-the-art and perspectives},
journal = {Information Sciences},
volume = {527},
pages = {341-355},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2019.07.036},
url = {https://www.sciencedirect.com/science/article/pii/S0020025519306437},
author = {Jun Feng and Laurence T. Yang and Nicholaus J. Gati and Xia Xie and Benard S. Gavuna},
keywords = {Cyber-physical-social systems, Privacy preserving, Tensor computation, Big data, Cloud computing},
abstract = {Cyber-physical-social systems (CPSSs) are leading digital revolutions in academia, industry and government. Due to the rise of big data analytics, tensor computations are currently used in CPSSs. With the increasing popularity of cloud computing or fog computing, big data in CPSSs are usually sent to clouds or fogs for computations. Recently, some studies about privacy-preserving computation have been conducted to address security concerns which enable data analysis and processing in cloud or fog environments in a privacy-preserving way. To fully understand the state-of-the-art advances and discover the research directions of this field, in this survey, both previous and current privacy-preserving schemes are comprehensively reviewed and studied. In addition, a novel privacy-preserving tensor computation framework, a case study, and several future research directions are presented for CPSSs.}
}
@article{ALHINAI2020101851,
title = {Disaster management digitally transformed: Exploring the impact and key determinants from the UK national disaster management experience},
journal = {International Journal of Disaster Risk Reduction},
volume = {51},
pages = {101851},
year = {2020},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2020.101851},
url = {https://www.sciencedirect.com/science/article/pii/S2212420920313534},
author = {Yousuf Salim AlHinai},
keywords = {Disaster risk reduction, Disaster and crisis management, Digital transformation, Technology innovation, Adoption, TOE Framework, Sendai},
abstract = {With the increasing social and economic devastation caused by disasters around the world, the international community and country-level National Disaster Management (NDM) authorities have placed improving their ways to mitigate, prepare for, respond to, and recover from disasters as a top priority. Technological advancements and the 4th Industrial Revolution are critical tools to help achieve this. However, they also present many challenges to traditional NDM systems by altering the fundamental operational, organizational, and social dynamics of conventional disaster management. Currently, there is a lack of research that studies these aspects beyond technology and examines the impact of digital transformation on the full life cycle of disaster management on the national level. Therefore, this research fills this gap by integrating interdisciplinary concepts from different research fields including Disaster Management, Information Systems, and Business Management to understand the impact and determinants of digital transformation in NDM systems. To achieve this, the research uses the Technology-Organization-Environment (TOE) framework and conducts semi-structured interviews with UK NDM experts. The results show that the impact of digital transformation on NDM is profound, paradoxical, multi-directional, and driven by a multitude of driving forces. This research makes many significant contributions to research and practice. Theoretically, this research expands the TOE framework beyond its original underpinnings by uncovering a new set of disaster-context determinants. It also presents an innovative Layered Cake FAST (Foundations-Approach-Strategy-Technology) Model that offers a unique roadmap for NDM on how to handle its digital transformation journey. Practically, the research presents several sets of useful expert-recommended actions.}
}
@article{M201918,
title = {Publish/subscribe based multi-tier edge computational model in Internet of Things for latency reduction},
journal = {Journal of Parallel and Distributed Computing},
volume = {127},
pages = {18-27},
year = {2019},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2019.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0743731519300152},
author = {Veeramanikandan M. and Suresh Sankaranarayanan},
keywords = {MQTT, Internet of Things, Latency, Multi-tier Fog computational model, Fog computing, Remote broker, PVFOG simulator, Service latency, Transmission latency},
abstract = {Most of the Internet of Things (IoT) applications are time sensitive and require low latency, as a millisecond delay can affect a huge production in the machine-dependent environment. Due to the rapid growth of the internet connected devices, it is very difficult to handle this huge processing load in the Cloud and traffic in the network. Data communication protocols in vogue are based on IoT devices connected to Cloud. But with the introduction of edge/Fog computing in IoT where all processing happens at the edge, there is a need to revisit the existing IoT protocols. The existing protocols were not designed with edge/Fog computing in mind. The most predominantly used IoT protocol is Message Queue Telemetry Transport (MQTT) protocol which is based on publish/subscribe model. This paper proposes software-defined multi-tier edge computing model by modifying the existing MQTT protocol for edge computing with a remote broker in Fog node and main broker in Cloud. A mathematical model is proposed towards computing the performance metrics of the proposed system. The performance of the proposed system is been compared with the traditional MQTT based IoT model. Python-Virtual Fog (PVFOG) simulator has been used to measure the performance in terms of service latency, transmission latency, processing latency, and packet send to Cloud. The experimental results show that the proposed system outperformed the traditional MQTT based IoT Model.}
}
@article{GUSMINI2017656,
title = {Reputation evaluation of georeferenced data for crowd-sensed applications},
journal = {Procedia Computer Science},
volume = {109},
pages = {656-663},
year = {2017},
note = {8th International Conference on Ambient Systems, Networks and Technologies, ANT-2017 and the 7th International Conference on Sustainable Energy Information Technology, SEIT 2017, 16-19 May 2017, Madeira, Portugal},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.05.372},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917310414},
author = {Marco Gusmini and Nafaâ Jabeur and Roula Karam and Michele Melchiori and Chiara Renso},
keywords = {Social Sensors, Reputation Evaluation, Volunteered Geographic Information, Mobile Crowdsourcing, Tourism Planning},
abstract = {Abstract:
Volunteered Geographic Information (VGI) is a process where individuals, supported by enabling technologies, behave like physical sensors to harvest georeferenced content in their surroundings. The value of this, typically heterogeneous, content has been recognized by both researchers and organizations. However, in order to be fruitfully used in various VGI-based types of application reliability and quality of particular VGI content (i.e., Points of Interest) have to be assessed. This evaluation can be based on reputation scores that summarize users’ experiences with the specific content. Following this direction, our contribution provides, primarily, a new comprehensive model and a multi-layer architecture for reputation evaluation aimed to assess quality of VGI content. Secondly, we demonstrate the relevance of adopting such a framework through an applicative scenario for recommending touristic itineraries.}
}
@article{CHEN2020102078,
title = {Big data management in healthcare: Adoption challenges and implications},
journal = {International Journal of Information Management},
volume = {53},
pages = {102078},
year = {2020},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2020.102078},
url = {https://www.sciencedirect.com/science/article/pii/S026840121830937X},
author = {Peng-Ting Chen and Chia-Li Lin and Wan-Ning Wu},
keywords = {Healthcare information system, Medical big data, Organizational barrier, Adoption strategy, Multiple Criteria Decision Making (MCDM)},
abstract = {The computerized healthcare information system has undergone tremendous advancements in the previous two decades. Medical institutions are paying further attention to the replacement of traditional approaches that can no longer handle the increasing amount of patient data. In recent years, the healthcare information system based on big data has been growing rapidly and is being adapted to medical information to derive important health trends and support timely preventive care. This research aims to evaluate organization-driven barriers in implementing a healthcare information system based on big data. It adopts the analytic network process approach to determine the aspect weight and applies VlseKriterijumska Optimizacija I Kzompromisno Resenje (VIKOR) to conclude a highly appropriate strategy for overcoming such barriers. The proposed model can provide hospital managers with forecasts and implications that facilitate the withdrawal of organizational barriers when adopting the healthcare information system based on big data into their healthcare service system. Results can provide benefits for increasing the effectiveness and quality of the healthcare information system based on big data in the healthcare industry. Therefore, by understanding the sequence of the importance of resistance factors, managers can formulate efficient strategies to solve problems with appropriate priorities.}
}
@article{GUIZZARDI20211049,
title = {Big data from dynamic pricing: A smart approach to tourism demand forecasting},
journal = {International Journal of Forecasting},
volume = {37},
number = {3},
pages = {1049-1060},
year = {2021},
issn = {0169-2070},
doi = {https://doi.org/10.1016/j.ijforecast.2020.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0169207020301825},
author = {Andrea Guizzardi and Flavio Maria Emanuele Pons and Giovanni Angelini and Ercolino Ranieri},
keywords = {Regional forecasting, Daily forecasting, Leading indicator, Advance booking, Dynamic pricing, Hotelier’s expectations about tourism demand},
abstract = {Suppliers of tourist services continuously generate big data on ask prices. We suggest using this information, in the form of a price index, to forecast the occupation rates for virtually any time-space frame, provided that there are a sufficient number of decision makers “sharing” their pricing strategies on the web. Our approach guarantees great transparency and replicability, as big data from OTAs do not depend on search interfaces and can facilitate intelligent interactions between the territory and its inhabitants, thus providing a starting point for a smart decision-making process. We show that it is possible to obtain a noticeable increase in the forecasting performance by including the proposed leading indicator (price index) into the set of explanatory variables, even with very simple model specifications. Our findings offer a new research direction in the field of tourism demand forecasting leveraging on big data from the supply side.}
}
@article{WEINBERG2015615,
title = {Internet of Things: Convenience vs. privacy and secrecy},
journal = {Business Horizons},
volume = {58},
number = {6},
pages = {615-624},
year = {2015},
note = {SPECIAL ISSUE: THE MAGIC OF SECRETS},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2015.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S0007681315000865},
author = {Bruce D. Weinberg and George R. Milne and Yana G. Andonova and Fatima M. Hajjat},
keywords = {Internet of Things, Machine to machine, Web 2.0. privacy, Humanness, Human experience},
abstract = {In this article we introduce the Internet of Things to the broad managerial community and explore one of its central tensions: convenience vs. privacy and secrecy. We clarify the ways in which IoT differs from Web 2.0 and then highlight opportunities, challenges, and managerial guidance. In addition, we explore the prominent issue of privacy and secrecy. Due to substantial increases in amounts of consumer-related data and their accessibility as well as potential tradeoffs in benefits associated with IoT and in properties of humanness associated with the consumer experience, the managerial issue of privacy is elevated to a level never before realized—perhaps on par with, or worthy of inclusion as an element of, the classic marketing mix.}
}
@article{BARVE2021102189,
title = {EXPPO: EXecution Performance Profiling and Optimization for CPS Co-simulation-as-a-Service},
journal = {Journal of Systems Architecture},
volume = {118},
pages = {102189},
year = {2021},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2021.102189},
url = {https://www.sciencedirect.com/science/article/pii/S138376212100134X},
author = {Yogesh D. Barve and Himanshu Neema and Zhuangwei Kang and Harsh Vardhan and Hongyang Sun and Aniruddha Gokhale},
keywords = {Resource management, Cyber–physical systems, Distributed simulation, Cloud computing, Latency-sensitive, Performance, Gang scheduling},
abstract = {A co-simulation may comprise several heterogeneous federates with diverse spatial and temporal execution characteristics. In an iterative time-stepped simulation, a federation exhibits the Bulk Synchronous Parallel (BSP) computation paradigm in which all federates perform local operations and synchronize with their peers before proceeding to the next round of computation. In this context, the lowest performing (i.e., slowest) federate dictates the progression of the federation logical time. One challenge in co-simulation is performance profiling for individual federates and entire federations. The computational resource assignment to the federates can have a large impact on federation performance. Furthermore, a federation may comprise federates located on different physical machines as is the case for cloud and edge computing environments. As such, distributed profiling and resource assignment to the federation is a major challenge for operationalizing the co-simulation execution at scale. This paper presents the Execution Performance Profiling and Optimization (EXPPO) methodology, which addresses these challenges by using execution performance profiling at each simulation execution step and for every federate in a federation. EXPPO uses profiling to learn performance models for each federate, and uses these models in its federation resource recommendation tool to solve an optimization problem that improves the execution performance of the co-simulation. Using an experimental testbed, the efficacy of EXPPO is validated to show the benefits of performance profiling and resource assignment in improving the execution runtimes of co-simulations while also minimizing the execution cost.}
}
@article{LIMA202223,
title = {On some classes of nullnorms and h-pseudo homogeneity},
journal = {Fuzzy Sets and Systems},
volume = {427},
pages = {23-36},
year = {2022},
note = {Aggregation Operations},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2020.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0165011420304747},
author = {Lucélia Lima and Benjamin Bedregal and Marcus Rocha and Aitor Castillo-Lopez and Javier Fernandez and Humberto Bustince},
keywords = {T-norms, T-conorms, Nullnorms, Pseudo-homogeneity},
abstract = {Nullnorms are aggregation functions which generalize t-norms and t-conorms. For each nullnorm there exists an annihilator element such that, below it, the function behaves like a t-conorm, and, above it, like a t-norm. In this paper, we study some classes of nullnorms which naturally arise from well known classes of t-norms and t-conorms, such as idempotent, Archimedean, cancellative, positive and nilpotent t-norms and t-conorms. We also present the concept of h-pseudo-homogeneous nullnorm and we study when these classes of nullnorms fullfill it.}
}
@article{LEE2020101482,
title = {Are pictures worth a thousand words? The effect of information presentation type on citizen perceptions of government websites},
journal = {Government Information Quarterly},
volume = {37},
number = {3},
pages = {101482},
year = {2020},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2020.101482},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X19304186},
author = {Taejun (David) Lee and Seulki Lee-Geiller and Byung-Kwan Lee},
keywords = {Information behavior, Information processing, Information overload, E-government, Open government data},
abstract = {With the increasing disclosure of public information and government data through information and communication technologies, along with the considerable privately generated data now available online, individuals have access to a huge volume of information. This “disintermediation” of (i.e., greater direct access to) public information may improve transparency and facilitate citizen engagement, but it may also overwhelm citizens not only with too much information but also by requiring them to take responsibility for gathering, assembling, and processing information. Despite the importance of effective information processing to successful use of available information, existing studies have not yet fully integrated this consideration into research on citizen use of e-government and open government data. Based on information processing theory—according to which individuals have a finite information processing capacity, which is affected not only by the quantity and quality of information but also by one's preferences for how information is presented—this study examined the effects of information presentation type (infographic versus text) on perceived information overload, along with the consequent effect of information overload on perceived website usefulness. We also investigated whether individual information processing propensity (visual or verbal) moderated the effect of information presentation type on perceived information overload. Our results showed that textual information tended to cause greater information overload, especially for those with a propensity for visual information processing, and that higher information overload was associated with a lower perception of website usefulness. Moreover, individual information propensity moderated the effect of information type on perceived information overload; people with visual information processing propensity were more strongly affected by the presentation of textual information. We discuss the implications of our findings for improving the communication of policy information through government websites.}
}
@article{HENTATI2020103451,
title = {Comprehensive survey of UAVs communication networks},
journal = {Computer Standards & Interfaces},
volume = {72},
pages = {103451},
year = {2020},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2020.103451},
url = {https://www.sciencedirect.com/science/article/pii/S0920548919303411},
author = {Aicha Idriss Hentati and Lamia Chaari Fourati},
keywords = {UAV networks, Drones, Networking models, Multi-UAVs systems, Non-Orthogonal Multiple Access (NOMA)},
abstract = {Recently, technologies related to Unmanned Aerial Vehicle (UAV) are growing rapidly particularly sensors, networking, and processing technologies. Accordingly, governments and industry have heavily invested in the studies of UAVs and improvingtheir performances for reliable and secure deployments. The design methods and the investigation of UAVs systems have progressed from mono-UAV uses to multi-UAVs and cooperative UAVs systems that need a high level of coordination and collaboration to perform tasks which require new networking models, approaches, and mechanisms for highly mobile nodes involving many complex parameters and constraints. In this context, this paper provides more details and offers a thorough investigation concerning UAV communication protocols, networking systems, architectures, and applications. In addition, we discuss UAV solutions as well as highlighting important technical challenges and open research issues requiring further studies and R&D work.}
}
@article{FUMANALIDOCIN202025,
title = {Community detection and social network analysis based on the Italian wars of the 15th century},
journal = {Future Generation Computer Systems},
volume = {113},
pages = {25-40},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.06.030},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20305057},
author = {J. Fumanal-Idocin and A. Alonso-Betanzos and O. Cordón and H. Bustince and M. Minárová},
keywords = {Social network, Community detection, Human social behaviour, Simulation, Multi-agent systems},
abstract = {In this contribution we study social network modelling by using human interaction as a basis. To do so, we propose a new set of functions, affinities, designed to capture the nature of the local interactions among each pair of actors in a network. By using these functions, we develop a new community detection algorithm, the Borgia Clustering, where communities naturally arise from the multi-agent interaction in the network. We also discuss the effects of size and scale for communities regarding this case, as well as how we cope with the additional complexity present when big communities arise. Finally, we compare our community detection solution with other representative algorithms, finding favourable results.}
}
@article{SHINDE2021108598,
title = {A network operator-biased approach for multi-service network function placement in a 5G network slicing architecture},
journal = {Computer Networks},
volume = {201},
pages = {108598},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108598},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621004989},
author = {Swapnil Sadashiv Shinde and Dania Marabissi and Daniele Tarchi},
keywords = {5G, Network slicing, Edge Computing, Network function placement, Genetic Algorithms},
abstract = {The 5G communication standard is characterized by an increased softwarization, allowing a higher flexibility able to cope with different requirements and services. In particular, Network Function Virtualization (NFV) is a recently introduced technology that enables a software implementation of different network functions exploiting virtualization techniques, hence, enabling their flexible deployment upon system requirements. Boosted by NFV, the concept of network slicing is gaining great attention in 5G networks. The idea is that physical communication and computing resources are sliced in multiple end-to-end logical networks, each one tailored to best support a specific service. The advantages of NFV, in the network slicing context, are even more evident in distributed computing environments, such as the edge-to-cloud continuum, recently introduced for enabling a flexible deployment of multiple functions. In particular, thanks to the introduction of cloud-native technologies, based on the usage of containerization and microservice technologies, the virtual network functions (VNFs) deployment and their orchestration is an easy operation, allowing the on-the-fly network configuration. Gaining from the NFV, Network Slicing and Edge-to-Cloud continuum paradigms, we propose a new network function allocation problem for multi-service 5G networks, able to deploy network functions on a distributed computing environment depending on the service requests. The proposed approach jointly considers Radio Access Network (RAN) and Core Network (CN) functions and, differently from other approaches, introduces an option able to bias the function placement depending on the service requirements, allowing a fast-and-easy operator-side deployment of the network functions. We propose to solve the problem through a Genetic Algorithm able to approach the optimal solution but with reduced complexity and execution time. The performance is compared with two other heuristic algorithms and with an exhaustive search algorithm, introduced as benchmarks, showing the benefits of the selected solution in terms of performance, flexibility and complexity.}
}
@article{RASTIVEIS2020149,
title = {Automated extraction of lane markings from mobile LiDAR point clouds based on fuzzy inference},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {160},
pages = {149-166},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0924271619302977},
author = {Heidar Rastiveis and Alireza Shams and Wayne A. Sarasua and Jonathan Li},
keywords = {Mobile LiDAR, Road lane markings, Point cloud, Fuzzy inference system},
abstract = {Mobile LiDAR systems (MLS) are rapid and accurate technologies for acquiring three-dimensional (3D) point clouds that can be used to generate 3D models of road environments. Because manual extraction of desirable features such as road traffic signs, trees, and pavement markings from these point clouds is tedious and time-consuming, automatic information extraction of these objects is desirable. This paper proposes a novel automatic method to extract pavement lane markings (LMs) using point attributes associated with the MLS point cloud based on fuzzy inference. The proposed method begins with dividing the MLS point cloud into a number of small sections (e.g. tiles) along the route. After initial filtering of non-ground points, each section is vertically aligned. Next, a number of candidate LM areas are detected using a Hough Transform (HT) algorithm and considering a buffer area around each line. The points inside each area are divided into “probable-LM” and “non-LM” clusters. After extracting geometric and radiometric descriptors for the “probable-LM” clusters and analyzing them in a fuzzy inference system, true-LM clusters are eventually detected. Finally, the extracted points are enhanced and transformed back to their original position. The efficiency of the method was tested on two different point cloud datasets along 15.6 km and 9.5 km roadway corridors. Comparing the LMs extracted using the algorithm with the manually extracted LMs, 88% of the LM lines were successfully extracted in both datasets.}
}
@article{BERRUETA2018286,
title = {A comprehensive model for lithium-ion batteries: From the physical principles to an electrical model},
journal = {Energy},
volume = {144},
pages = {286-300},
year = {2018},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2017.11.154},
url = {https://www.sciencedirect.com/science/article/pii/S0360544217320121},
author = {Alberto Berrueta and Andoni Urtasun and Alfredo Ursúa and Pablo Sanchis},
keywords = {Li-ion battery, Equivalent circuit model, Equivalent electric circuit, Storage system, Electrical microgrid},
abstract = {The growing interest in e-mobility and the increasing installation of renewable energy-based systems are leading to rapid improvements in lithium-ion batteries. In this context, battery manufacturers and engineers require advanced models in order to study battery performance accurately. A number of Li-ion battery models are based on the representation of physical phenomena by electrochemical equations. Although providing detailed physics-based information, these models cannot take into account all the phenomena for a whole battery, given the high complexity of the equations. Other models are based on equivalent circuits and are easier to design and use. However, they fail to relate these circuit parameters to physical properties. In order to take the best of both modeling techniques, we propose an equivalent circuit model which keeps a straight correlation between its parameters and the battery electrochemical principles. Consequently, this model has the required simplicity to be used in the simulation of a whole battery, while providing the depth of detail needed to identify physical phenomena. Moreover, due to its high accuracy, it can be used in a wide range of environments, as shown in the experimental validations carried out in the final section of this paper.}
}
@article{ALVAREZ2020101242,
title = {Mobile music recommendations for runners based on location and emotions: The DJ-Running system},
journal = {Pervasive and Mobile Computing},
volume = {67},
pages = {101242},
year = {2020},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2020.101242},
url = {https://www.sciencedirect.com/science/article/pii/S1574119220300948},
author = {P. Álvarez and F.J. Zarazaga-Soria and S. Baldassarri},
keywords = {Context-aware applications and services, Music recommendation, Emotions, Geodata integration, Running},
abstract = {Music can produce a positive effect in runners’ motivation and performance. Nevertheless, these effects vary depending on the user’s location, the emotions that she/he feels at each moment or the type of training session. In this paper, a context and emotion-aware system for the recommendation and playing of Spotify songs is presented. It consists in a location-based mobile application that interacts with a novel emotional wearable and a recommendation service that predicts the next song to be recommended. These predictions are performed by an intelligent system that combines artificial intelligent techniques with geodata and emotionally-annotated music. A wide variety of location-based services and music services available in Internet have been integrated into the recommender in order to support the decision-making process in a real environment. The final solution has been customized to be tested in the city of Zaragoza.}
}
@article{LONGO2019106876,
title = {Accurate occupancy estimation with WiFi and bluetooth/BLE packet capture},
journal = {Computer Networks},
volume = {163},
pages = {106876},
year = {2019},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2019.106876},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618313045},
author = {Edoardo Longo and Alessandro E.C. Redondi and Matteo Cesana},
keywords = {Occupancy estimation, Wi-Fi, Bluetooth/BLE},
abstract = {The capillary spread of personal devices equipped with wireless communication capabilities has enabled a series of high level services which build on capturing and processing the data packets emitted by such devices. In this paper we tackle the problem of exploiting such a methodology to perform occupancy estimation, i.e., understanding how many people are present in a specific place, an information which is valuable in many scenarios (HVAC and lighting system control, building energy optimisation, allocation and reservation of spaces, etc.). Traditional systems for occupancy estimation rely either on environmental sensors (CO2, temperature, humidity) or video cameras, which both have drawbacks: the former have generally low accuracy, while the latter require high setup and maintenance costs. In this paper we depart from such traditional approaches and propose a cheap and accurate occupancy estimation system based on the capture of both Wi-Fi and Bluetooth or Bluetooth Low Energy management frames transmitted from users’ devices. The system, implemented on low-cost hardware, leverages a supervised learning model to adapt to different spaces and transmits estimated occupancy information to a web-based dashboard. Experimental results in both indoor and outdoor uncontrolled scenarios demonstrate the validity of the proposed solution.}
}
@article{SELLAMI2020102732,
title = {On the use of big data frameworks for big service composition},
journal = {Journal of Network and Computer Applications},
volume = {166},
pages = {102732},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102732},
url = {https://www.sciencedirect.com/science/article/pii/S108480452030206X},
author = {Mokhtar Sellami and Haithem Mezni and Mohand Said Hacid},
keywords = {Big data, Big service, Big service composition, Quality of big services, Fuzzy RCA, Spark},
abstract = {Over the last years, big data has emerged as a new paradigm for the processing and analysis of massive volumes of data. Big data processing has been combined with service and cloud computing, leading to a new class of services called “Big Services”. In this new model, services can be seen as an abstract layer that hides the complexity of the processed big data. To meet users' complex and heterogeneous needs in the era of big data, service reuse is a natural and efficient means that helps orchestrating available services' operations, to provide customer on-demand big services. However different from traditional Web service composition, composing big services refers to the reuse of, not only existing high-quality services, but also high-quality data sources, while taking into account their security constraints (e.g., data provenance, threat level and data leakage). Moreover, composing heterogeneous and large-scale data-centric services faces several challenges, apart from security risks, such as the big services' high execution time and the incompatibility between providers' policies across multiple domains and clouds. Aiming to solve the above issues, we propose a scalable approach for big service composition, which considers not only the quality of reused services (QoS), but also the quality of their consumed data sources (QoD). Since the correct representation of big services requirements is the first step towards an effective composition, we first propose a quality model for big services and we quantify the data breaches using L-Severity metrics. Then to facilitate processing and mining big services' related information during composition, we exploit the strong mathematical foundation of fuzzy Relational Concept Analysis (fuzzy RCA) to build the big services' repository as a lattice family. We also used fuzzy RCA to cluster services and data sources based on various criteria, including their quality levels, their domains, and the relationships between them. Finally, we define algorithms that parse the lattice family to select and compose high-quality and secure big services in a parallel fashion. The proposed method, which is implemented on top of Spark big data framework, is compared with two existing approaches, and experimental studies proved the effectiveness of our big service composition approach in terms of QoD-aware composition, scalability, and security breaches.}
}
@article{YUAN2021108189,
title = {Heating energy-saving potentials in HVAC system of swimming halls: A review},
journal = {Building and Environment},
volume = {205},
pages = {108189},
year = {2021},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2021.108189},
url = {https://www.sciencedirect.com/science/article/pii/S0360132321005904},
author = {Xiaolei Yuan and Zhisen Chen and Yumin Liang and Yiqun Pan and Juha Jokisalo and Risto Kosonen},
keywords = {Swimming halls, Heating energy system, Energy efficiency and saving, Solar energy utilization, Waste heat recovery, Demand response},
abstract = {Swimming halls (SHs), which belong to special building sector, are easily overlooked as significant energy users and carbon producers. The demands of heat (e.g., pool water heating, domestic hot water, space and supply air heating) and electricity (e.g., Saunas, pool pumping and ventilation) in SHs are both very high, which indicates the high energy saving potentials. This paper comprehensively introduced and summarized the energy-saving potentials mainly for the heating system in SHs. After briefly introducing the global energy and building energy backgrounds, the energy system of SHs was firstly introduced, including its energy use and breakdown, ventilation demand, and heat losses. Then, renewable and sustainable energy sources applied in SHs were reviewed, especially solar energy application in terms of individual solar-assisted heating and hybrid solar-assisted heat pump systems, while geothermal and biomass and other energy applications were also introduced briefly. Furthermore, building energy management (BEM) strategies were introduced and summarized comprehensively, including waste heat utilization, prediction of energy demand and consumption, control and optimization of HVAC system, and demand response potentials of both electricity and district heat. In the discussion part, the recommendations of high-efficient or energy-saving technologies in SHs were given as well as the future development. Finally, suggestions were given for achieving energy efficiency and carbon reduction in SHs via using renewable energy sources (especially solar energy), optimizing the energy and HVAC systems, possible waste heat recoveries, and applying demand response of energy. In addition, establishing feasible and comprehensive energy indexes to evaluate energy use in SHs is also essential in the future.}
}
@article{LU2018120,
title = {GreenBDT: Renewable-aware scheduling of bulk data transfers for geo-distributed sustainable datacenters},
journal = {Sustainable Computing: Informatics and Systems},
volume = {20},
pages = {120-129},
year = {2018},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2018.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2210537917302962},
author = {Xingjian Lu and Dongxu Jiang and Gaoqi He and Huiqun Yu},
keywords = {Renewable energy, Bulk data transfer, Geo-distributed, Sustainable datacenters},
abstract = {The fast proliferation of cloud computing promotes the rapid growth of datacenters. More and more cloud service providers use geo-distributed green datacenters to support the expanding scale of cloud applications as well as minimize the carbon footprint. In such a geo-distributed green datacenter system, a basic and urgent demand is inter-datacenter bulk data transfer that is usually used for periodic data backup, software distribution, virtual machines cloning, etc. Though many existing research efforts have been made to build green datacenters or provide optimal scheduling for inter-datacenter bulk data transfers separately, still the goal for optimal scheduling of inter-green-datacenter bulk data transfers is being underachieved. This is an important problem, especially when an increasing number of geo-distributed datacenters are powered by renewable energy for reducing energy cost and protecting environment. In this paper, we study the problem of maximizing renewable energy use and minimizing grid energy cost for bulk data transfers between sustainable and green datacenters. We model this problem and propose a heuristic method to solve it. The proposed method is the first to explicitly address the green energy use maximization and grid energy cost minimization problem of inter-green-datacenter bulk data transfers for green and sustainable datacenters in the multi-electricity market environment. Extensive evaluations with real-life network topology, available wind power, and electricity prices show that our method can maximize renewable energy use and bring more energy cost savings over existing bulk data transfer strategies.}
}
@article{ARIZA202114,
title = {IoT architecture for adaptation to transient devices},
journal = {Journal of Parallel and Distributed Computing},
volume = {148},
pages = {14-30},
year = {2021},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2020.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0743731520303737},
author = {Jairo Ariza and Kelly Garcés and Nicolás Cardozo and Juan Pablo Rodríguez Sánchez and Fernando Jiménez Vargas},
keywords = {Internet of Things, Instance matching, Transient systems, Dynamic adaptation},
abstract = {IoT environments are continuously changing. Changes may come from the service, connectivity, or physical layers of the IoT architecture. Therefore, to function appropriately, the system needs to dynamically adapt to its environment. In previous work, we posited eight challenges to foster adaptation through all architecture layers of IoT systems. In this paper, we address the challenges to manage the inclusion of new devices and devices’ transient connection, by means of dynamic adaptations incorporated into our proposed software architecture for adaptive IoT systems. To manage dynamic adaptations, we extend the reference IoT architecture with our specialized components. In particular, we use (1) ontologies and instances to represent the domain knowledge; (2) a matching algorithm to pair services and IoT devices, taking into account their functional requirements, quality attributes and sensors properties; and (3) a match update algorithm used whenever sensors become (un)available. We evaluate the effectiveness of our solution with respect to the accuracy of matching services and IoT devices, and the response to environment changes.}
}
@article{KALOGRIDIS2015854,
title = {Privacy and incongruence-focused disaggregation of water consumption data in real time},
journal = {Procedia Engineering},
volume = {119},
pages = {854-863},
year = {2015},
note = {Computing and Control for the Water Industry (CCWI2015) Sharing the best practice in water management},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2015.08.950},
url = {https://www.sciencedirect.com/science/article/pii/S187770581502620X},
author = {Georgios Kalogridis and Tim Farnham and James Wilcox and Mohammed Faies},
keywords = {Water privacy, disaggregation, anomaly detection, privacy preserving data mining, complex event processor},
abstract = {While fixture-level disaggregation of water data has a number of applications in decision support systems, it also gives rise to data privacy risks. This paper presents a system of algorithms that identify and detect water activity events, and then analyse disag- gregated information to distinguish between privacy-sensitive behaviour and incongruent data due to technical faults or leakages. The process running in real-time is implemented within the Complex Event Processor (CEP) of WSO2 and the ICeWater project. Results provide insights of future directions in theoretical aspects of disaggregation, privacy and CEP system implementation.}
}
@article{RIBEIRO2022107323,
title = {Benefits of energy recovery from the undesirable components of electric signals in electric power systems},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {138},
pages = {107323},
year = {2022},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2021.107323},
url = {https://www.sciencedirect.com/science/article/pii/S0142061521005627},
author = {Moisés V. Ribeiro and Victor Fernandes and Henrique L.M. Monteiro and Nathan Cravo and Edimar J. {de Oliveira} and H. {Vincent Poor} and P.F. Ribeiro},
keywords = {Waste-to-energy, Energy recovery, Power quality, Energy efficiency, Electric signals, Electric power systems, Nonlinear load, Cross power spectral density},
abstract = {This paper introduces an analytical framework for analyzing the benefits of using the waste-to-energy concept to improve power quality and energy efficiency in electric power systems. In this framework, closed-form expressions for evaluating the analytic cross-power spectral density between voltage and current signals are introduced to quantify the wasted energy associated with undesirable components of electric signals that result from the interaction between nonlinear loads and electric power systems. These expressions demonstrate the existing relationship between the analytic cross-power spectral density and the well-known complex power, which is widely used in electric power systems. In the sequel, it is shown that these expressions allow the introduction of the so-called Passive Filtering Energy Recovery, which aims to recover the wasted energy from the undesirable components of electric signals. Numerical results show that the Passive Filtering Energy Recovery, which relies on the waste-to-energy concept, can improve power quality and energy efficiency in the Brazilian and worldwide electric power systems.}
}
@article{TSENG2020107486,
title = {Reliable broadcast with trusted nodes: Energy reduction, resilience, and speed},
journal = {Computer Networks},
volume = {182},
pages = {107486},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107486},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620311579},
author = {Lewis Tseng and Yingjian Wu and Haochen Pan and Moayad Aloqaily and Azzedine Boukerche},
keywords = {Reliable broadcast, Trust, Certified propagation algorithm, Tight condition, Hardness result},
abstract = {Broadcast is an important primitive in large-scale distributed systems. One application is to enable reliable and efficient communication in large-scale networks such as sensor networks and Internet-of-Things. There is a rich study on achieving reliable broadcast under various kind of failures. In this paper, we use the notion of “trust” to improve the performance of reliable broadcast. We focus on Certified Propagation Algorithm (CPA), one of the simple algorithms that does not rely on a cryptographic infrastructure and has a proven guarantee on resilience (number of node failures tolerated). Specifically, the paper has two main contributions: (i) A new algorithm Trust-CPA – which integrates CPA with trusted nodes – has been proposed and shown to increase the resilience from the original CPA, and (ii) Natural optimization problems related to Trust-CPA have been proposed and studied as well. First, we study the location to place trusted nodes to reduce power consumption while maintaining the same level of resilience. Second, we study two optimizations problems on finding out which set of nodes to “trustify” to increase resilience and reduce speed. For the speed-related optimization problem, we present a greedy heuristic algorithm, and its efficacy has been examined using simulation. We show that our algorithm performs relatively well in geometric random graphs, an appropriate model for large-scale wireless sensor networks.}
}
@article{WANG2021100362,
title = {Blockchain technology in the energy sector: From basic research to real world applications},
journal = {Computer Science Review},
volume = {39},
pages = {100362},
year = {2021},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2021.100362},
url = {https://www.sciencedirect.com/science/article/pii/S1574013721000022},
author = {Qiang Wang and Rongrong Li and Lina Zhan},
keywords = {Blockchain technology, Energy, Decentralized, Bibliometric analysis, Application},
abstract = {The decentralized blockchain technology has been increasingly recognized as a game changer for all centralized things, including traditional centralized energy. Meanwhile, the energy sector has been undergoing transformation from a traditional centralized energy supply system to a distributed energy resource. This work is aimed to explore what the decentralized blockchain technology means to the changing energy sector from the perspectives of basic research and real world applications. After introducing the background information of the blockchain technology, this work investigates the number of publications, subject categories, research areas, cooperation network, research hotspots by combining the bibliometric technique and visual analysis. And then, real-world application cases corresponding to research hotspots are offered. The key findings are as follows: (i) the basic research on the blockchain technology in the energy sector is growing rapidly over time, which means that blockchain energy is a rising research field. (ii) China, a developing country, leads the basic research of blockchain in the energy sector in terms of the total number of publications, institutions and highly cited papers, and cooperative relationship. (iii) keyword hotspot analysis and keyword trend analysis indicate the future research directions of blockchain technology in the energy sector: the decentralized energy market, micro grid, smart grid, energy internet, smart contract, peer-to-peer, renewable energy and electric vehicle. (iv) The real-world application cases are mainly concentrated in the developed countries, especially in the United States, the European Union and Australia. There are relatively few typical application cases in developing countries, which is sharply different from the results of basic research. This work could serve to stimulate meaningful discussion from basic research to real-world applications of blockchain technology in the energy sector.}
}
@article{PU2022102541,
title = {Lightweight Sybil Attack Detection in IoT based on Bloom Filter and Physical Unclonable Function},
journal = {Computers & Security},
volume = {113},
pages = {102541},
year = {2022},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2021.102541},
url = {https://www.sciencedirect.com/science/article/pii/S0167404821003655},
author = {Cong Pu and Kim-Kwang Raymond Choo},
keywords = {Sybil attack, Lightweight detection, Bloom filter, Physical unclonable function, IoT},
abstract = {Routing protocols play an important role in the communication and information distribution within an Internet of Things (IoT) system. RPL is one such popular routing protocol for IoT devices and systems. However, security in RPL is an afterthought, and it does not meet the demands of today’s complex cyberthreat landscape. Focusing on sybil attack detection in RPL-based IoT, we first propose a lightweight Bloom filter and physical unclonable function (PUF) based sybil attack detection mechanism (hereafter referred to as liteSAD). Our approach is designed to minimize memory cost as well as detection latency, without affecting the detection accuracy. Specifically, in liteSAD, Destination-Oriented Directed Acyclic Graph (DODAG) root generates a Bloom filter array through hashing each legitimate node’s identifier and PUF response, and distributes it through a new packet named BF-DAO. Upon receiving the BF-DAO packet, each legitimate node retrieves the Bloom filter array, updates its local copy, and employs it to detect sybil attack. We also propose a probabilistic DIO reply mechanism (i.e., proDIO) to reduce the number of broadcasted DIO packets in response to attack DIS packets. We investigate the setting of Bloom filter parameters that minimize the probability of false positive and time complexity while meeting the requirement of memory constraints in IoT devices. We also evaluate the performance of our mechanism liteSAD+proDIO through extensive simulation experiments, where the results demonstrate that liteSAD+proDIO can provide better performance in terms of detection rate, detection latency, miss detection rate, DIO Trickle timer, number of broadcasted DIO packets, and energy consumption. In summary, our major contributions are twofold: (i) the comprehensive analysis of RPL routing protocol, Trickle algorithm, and the impact of sybil attack; and (ii) the proposal of lightweight Bloom filter and PUF based sybil attack detection mechanism.}
}
@article{DONTHU2021102307,
title = {Forty years of the International Journal of Information Management: A bibliometric analysis},
journal = {International Journal of Information Management},
volume = {57},
pages = {102307},
year = {2021},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2020.102307},
url = {https://www.sciencedirect.com/science/article/pii/S0268401220315061},
author = {Naveen Donthu and Satish Kumar and Nitesh Pandey and Prashant Gupta},
keywords = {Bibliometric analysis, International Journal of Information Management, Performance analysis, Science mapping, Negative binomial regression, Citation analysis},
abstract = {In 2019, the International Journal of Information Management (IJIM) celebrated its 40th year of publication. This study commemorates this event by presenting a retrospect of the journal. Using a range of bibliometric tools, we find that the journal has grown impressively in terms of publication and citation. The contributions come from all over the world, but the majority are from Europe and the United States. The journal has mostly published empirical articles, with its authors dominantly using quantitative methodology. Further, the culture of collaboration has increased among authors over the years. The journal publishes on a number of including managing information systems, information technologies and their application in business, technology acceptance among consumers, using information systems for decision making, social perspectives on knowledge management, and information research from the social science perspective. Regression analysis reveals that article attributes such as article order, methodology, presence of authors from Europe, number of references, number of keywords, and abstract length have a significant association with the citations. Finally, we find that conceptual and review articles have a positive association with citations.}
}
@article{BRESCIANI2021102347,
title = {Using big data for co-innovation processes: Mapping the field of data-driven innovation, proposing theoretical developments and providing a research agenda},
journal = {International Journal of Information Management},
volume = {60},
pages = {102347},
year = {2021},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2021.102347},
url = {https://www.sciencedirect.com/science/article/pii/S0268401221000402},
author = {Stefano Bresciani and Francesco Ciampi and Francesco Meli and Alberto Ferraris},
keywords = {Big data, Co-innovation, Open innovation, Bibliometric analysis, Literature review},
abstract = {This is the first systematic literature review concerning the interconnections between big data (BD) and co-innovation. It uses BD as a common perspective of analysis as well as a concept aggregating different research streams (open innovation, co-creation and collaborative innovation). The review is based on the results of a bibliographic coupling analysis performed with 51 peer-reviewed papers published before the end of 2019. Three thematic clusters were discovered, which respectively focused on BD as a knowledge creation enabler within co-innovation contexts, BD as a driver of co-innovation processes based on customer engagement, and the impact of BD on co-innovation within service ecosystems. The paper theoretically argues that the use of BD, in addition to enhancing intentional and direct collaborative innovation processes, allows the development of passive and unintentional co-innovation that can be implemented through indirect relationships between the collaborative actors. This study also makes eleven unique research propositions concerning further theoretical developments and managerial implementations in the field of BD-driven co-innovation.}
}
@article{UNAL2021433,
title = {A secure and efficient Internet of Things cloud encryption scheme with forensics investigation compatibility based on identity-based encryption},
journal = {Future Generation Computer Systems},
volume = {125},
pages = {433-445},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.06.050},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21002454},
author = {Devrim Unal and Abdulla Al-Ali and Ferhat Ozgur Catak and Mohammad Hammoudeh},
keywords = {Type-3 pairings, Cloud security, Encryption-as-a-Service, Identity-based cryptography},
abstract = {Data security is a challenge for end-users of cloud services as the users have no control over their data once it is transmitted to the cloud. A potentially corrupt cloud service provider can obtain the end-users’ data. Conventional PKI-based solutions are insufficient for large-scale cloud systems, considering efficiency, scalability, and security. In large-scale cloud systems, the key management requirements include scalable encryption, authentication, and non-repudiation services, as well as the ability to share files with different users and data recovery when the user keys of encrypted data are not accessible. Further requirements in cloud systems include the ability to provide the means for digital forensic investigations on encrypted data. Once data on the cloud is encrypted with a user’s key it becomes impossible to access by forensic investigation teams. In this regard, distributing the trust of key management into multiple authorities is desirable. In the literature, there is no available secure cloud storage system with secure and efficient Type-3 pairings, supporting Encryption-as-a-Service (EaaS) and multiple Public Key Generators (PKGs). This paper proposes an efficient Identity-based cryptography (IBC) architecture for secure cloud storage, named Secure Cloud Storage System (SCSS), which supports distributed key management and encryption mechanisms and support for multiple PKGs. During forensic investigations, the legal authorities will be able to use the multiple PKG mechanism for data access, while an account locking mechanism prevents a single authority to access user data due to trust distribution. We also demonstrate that, the IBC scheme used in SCSS has better performance compared to similar schemes in the literature. For the security levels of 128-bits and above, SCSS has better scalability compared to existing schemes, with respect to encryption and decryption operations. Since the decryption operation is frequently needed for forensic analysis, the improved scalability results in a streamlined forensic investigation process on the encrypted data in the cloud.}
}
@article{RAJASEKARAN2019565,
title = {Autonomous monitoring in healthcare environment: Reward-based energy charging mechanism for IoMT wireless sensing nodes},
journal = {Future Generation Computer Systems},
volume = {98},
pages = {565-576},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.01.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18326347},
author = {Manikandan Rajasekaran and Abdulsalam Yassine and M. Shamim Hossain and Mohammed F. Alhamid and Mohsen Guizani},
keywords = {Internet of Medical Things (IoMT), Autonomous sensor nodes, Energy charging, Healthcare, Reward-based protocol},
abstract = {The Internet of Medical Things (IoMT) is an essential paradigm for ubiquitous monitoring in healthcare environments. The IoMT system collects data (e.g. temperature, hazardous contamination, light intensity, room and patient status, etc.) from connected medical devices and sensor nodes to a central or distributed computer network. In order for these devices and sensor nodes to continue operating, they must be charged with sufficient energy at all times. In this paper, we propose an IoMT system that employs autonomous mobile chargers, which is equipped with wireless energy transfer technology, to support sensor nodes recharging requests. In this model, the mobile charger must distribute the energy among the sensor nodes so that their operation is not interrupted. This is challenging because the mobile charger carries limited amount of energy that may not be sufficient to satisfy all recharging requests. In this paper, we propose a reward-based energy charging decision mechanism that allows mobile chargers and sensor nodes to coordinate the charging process. The proposed reward-based mechanism utilizes the Analytical Hierarchy Process (AHP) for fair distribution of energy among the nodes. This paper presents the theoretical analysis of the model and the simulation experiments. Our results show that the proposed model can support a larger number of active nodes with less energy compared to conventional first come first served methods. Also the coverage utility of sensor nodes is much higher using our method compared to the on-demand recharging request schemes found in existing studies.}
}
@article{SHARIFI2018799,
title = {Urban carbon mapping: Towards a standardized framework},
journal = {Energy Procedia},
volume = {152},
pages = {799-808},
year = {2018},
note = {Cleaner Energy for Cleaner Cities},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2018.09.193},
url = {https://www.sciencedirect.com/science/article/pii/S1876610218307379},
author = {Ayyoob Sharifi and Yihan Wu and Dararat Khamchiangta and Takahiro Yoshida and Yoshiki Yamagata},
keywords = {Urban carbon mapping, local climate zones, local energy zones, mitigation, Bangkok, Shanghai, Tokyo},
abstract = {Cities are responsible for a large share of global energy consumption and CO2 emissions. Significant reduction of urban energy consumption and CO2 emissions is essential for meeting the ambitious climate stabilization targets. This hinges on having adequate understanding of the patterns and trends of emissions. It is essential to create datasets of cities emissions and utilize mapping techniques to inform planners and decision makers about the dynamics of urban carbon emissions. Due to the openness of cities and issues related to availability and accessibility of urban energy consumption data, this is a challenging task. It is critical to develop consistent methods for mapping emissions. Such methods and frameworks should enable cities to map their emissions with minimum data requirements. They should also be applicable to different cities across the world. As a preliminary effort, this study introduces a framework for synthesizing building and transport energy consumption data with the Local Climate Zones (LCZs) classification system. Drawing on preliminary results from applying the framework to Bangkok, Shanghai, and Tokyo, we explain how this approach can provide opportunities for standardizing urban carbon accounting. The paper concludes with suggestions for improving granularity and accuracy of emissions accounting. The concept of Local Energy Zones (LEZs) is introduced and is suggested to be used as a potentially suitable concept for analysing CO2 emissions dynamics of cities.}
}
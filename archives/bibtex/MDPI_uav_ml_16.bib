
@Article{earth2040060,
AUTHOR = {Contreras, Diana and Wilkinson, Sean and James, Philip},
TITLE = {Earthquake Reconnaissance Data Sources, a Literature Review},
JOURNAL = {Earth},
VOLUME = {2},
YEAR = {2021},
NUMBER = {4},
PAGES = {1006--1037},
URL = {https://www.mdpi.com/2673-4834/2/4/60},
ISSN = {2673-4834},
ABSTRACT = {Earthquakes are one of the most catastrophic natural phenomena. After an earthquake, earthquake reconnaissance enables effective recovery by collecting data on building damage and other impacts. This paper aims to identify state-of-the-art data sources for building damage assessment and provide guidance for more efficient data collection. We have reviewed 39 articles that indicate the sources used by different authors to collect data related to damage and post-disaster recovery progress after earthquakes between 2014 and 2021. The current data collection methods have been grouped into seven categories: fieldwork or ground surveys, omnidirectional imagery (OD), terrestrial laser scanning (TLS), remote sensing (RS), crowdsourcing platforms, social media (SM) and closed-circuit television videos (CCTV). The selection of a particular data source or collection technique for earthquake reconnaissance includes different criteria depending on what questions are to be answered by these data. We conclude that modern reconnaissance missions cannot rely on a single data source. Different data sources should complement each other, validate collected data or systematically quantify the damage. The recent increase in the number of crowdsourcing and SM platforms used to source earthquake reconnaissance data demonstrates that this is likely to become an increasingly important data source.},
DOI = {10.3390/earth2040060}
}



@Article{machines9120304,
AUTHOR = {Zhang, Houzhong and Yang, Xiangtian and Liang, Jiasheng and Xu, Xing and Sun, Xiaoqiang},
TITLE = {GPS Path Tracking Control of Military Unmanned Vehicle Based on Preview Variable Universe Fuzzy Sliding Mode Control},
JOURNAL = {Machines},
VOLUME = {9},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {304},
URL = {https://www.mdpi.com/2075-1702/9/12/304},
ISSN = {2075-1702},
ABSTRACT = {In the process of the continuous development and improvement of modern military systems, military unmanned vehicles play an important role in field reconnaissance and strategic deployment. In this paper, the precise tracking algorithm of a military unmanned vehicle, based on GPS navigation, is studied. Firstly, the optimal preview point is obtained according to the data points of a differential GPS signal. Secondly, the pure tracking algorithm is used to calculate the demand steering angle, and a variable universe fuzzy sliding mode controller is designed to control the lateral motion of the vehicle, which is verified by the joint simulation platform of Simulink and CarSim, under multiple working conditions. Finally, the actual vehicle is verified by using the Autobox platform. The results show that the lateral motion control of path tracking designed in this paper can achieve an accurate and effective control effect, and has real-time performance for engineering applications.},
DOI = {10.3390/machines9120304}
}



@Article{su132312951,
AUTHOR = {Iqbal, Kamran and Munawar, Hafiz Suliman and Inam, Hina and Qayyum, Siddra},
TITLE = {Promoting Customer Loyalty and Satisfaction in Financial Institutions through Technology Integration: The Roles of Service Quality, Awareness, and Perceptions},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {12951},
URL = {https://www.mdpi.com/2071-1050/13/23/12951},
ISSN = {2071-1050},
ABSTRACT = {This study examines the effects of quality of service, product awareness, and perceptions among customers of Islamic financial institutions (IFIs) on customer loyalty through technology integration using customer satisfaction as a mediator. A well-structured, comprehensive questionnaire was developed and data were collected from 203 respondents who were customers of six IFIs in Pakistan and had at least 2 years of experience in dealing confiorm this is correct with these IFIs. A total of 171 accurate responses were received from the respondents. Ten hypotheses were developed and statistically verified using regression and correlation analytical techniques. The results reveal that the quality of customer services and awareness of IFIs had a direct and positive relationship with customer loyalty, which in turn was mediated by customer satisfaction. Perceptions about IFIs had a direct positive relation with customer satisfaction. However, the relation of perceptions and quality of service with customer loyalty and satisfaction in financial institutions through technology integration was found to be insignificant, even in the presence of customer satisfaction as a mediator.},
DOI = {10.3390/su132312951}
}



@Article{electronics10232893,
AUTHOR = {Kakhani, Nafiseh and Mokhtarzade, Mehdi and Valadan Zoej, Mohammad Javad},
TITLE = {Deep Learning Spatial-Spectral Classification of Remote Sensing Images by Applying Morphology-Based Differential Extinction Profile (DEP)},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {2893},
URL = {https://www.mdpi.com/2079-9292/10/23/2893},
ISSN = {2079-9292},
ABSTRACT = {Since the technology of remote sensing has been improved recently, the spatial resolution of satellite images is getting finer. This enables us to precisely analyze the small complex objects in a scene through remote sensing images. Thus, the need to develop new, efficient algorithms like spatial-spectral classification methods is growing. One of the most successful approaches is based on extinction profile (EP), which can extract contextual information from remote sensing data. Moreover, deep learning classifiers have drawn attention in the remote sensing community in the past few years. Recent progress has shown the effectiveness of deep learning at solving different problems, particularly segmentation tasks. This paper proposes a novel approach based on a new concept, which is differential extinction profile (DEP). DEP makes it possible to have an input feature vector with both spectral and spatial information. The input vector is then fed into a proposed straightforward deep-learning-based classifier to produce a thematic map. The approach is carried out on two different urban datasets from Pleiades and World-View 2 satellites. In order to prove the capabilities of the suggested approach, we compare the final results to the results of other classification strategies with different input vectors and various types of common classifiers, such as support vector machine (SVM) and random forests (RF). It can be concluded that the proposed approach is significantly improved in terms of three kinds of criteria, which are overall accuracy, Kappa coefficient, and total disagreement.},
DOI = {10.3390/electronics10232893}
}



@Article{s21237790,
AUTHOR = {Chen, Hang and Zhang, Weiguo and Yan, Danghui},
TITLE = {Learning Geometry Information of Target for Visual Object Tracking with Siamese Networks},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7790},
URL = {https://www.mdpi.com/1424-8220/21/23/7790},
PubMedID = {34883790},
ISSN = {1424-8220},
ABSTRACT = {Recently, Siamese architecture has been widely used in the field of visual tracking, and has achieved great success. Most Siamese network based trackers aggregate the target information of two branches by cross-correlation. However, since the location of the sampling points in the search feature area is pre-fixed in cross-correlation operation, these trackers suffer from either background noise influence or missing foreground information. Moreover, the cross-correlation between the template and the search area neglects the geometry information of the target. In this paper, we propose a Siamese deformable cross-correlation network to model the geometric structure of target and improve the performance of visual tracking. We propose to learn an offset field end-to-end in cross-correlation. With the guidance of the offset field, the sampling in the search image area can adapt to the deformation of the target, and realize the modeling of the geometric structure of the target. We further propose an online classification sub-network to model the variation of target appearance and enhance the robustness of the tracker. Extensive experiments are conducted on four challenging benchmarks, including OTB2015, VOT2018, VOT2019 and UAV123. The results demonstrate that our tracker achieves state-of-the-art performance.},
DOI = {10.3390/s21237790}
}



@Article{rs13234742,
AUTHOR = {Gawehn, Matthijs and de Vries, Sierd and Aarninkhof, Stefan},
TITLE = {A Self-Adaptive Method for Mapping Coastal Bathymetry On-The-Fly from Wave Field Video},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4742},
URL = {https://www.mdpi.com/2072-4292/13/23/4742},
ISSN = {2072-4292},
ABSTRACT = {Mapping coastal bathymetry from remote sensing becomes increasingly more attractive for the coastal community. It is facilitated by a rising availability of drone and satellite data, advances in data science, and an open-source mindset. Coastal bathymetry, but also wave directions, celerity and near-surface currents can simultaneously be derived from aerial video of a wave field. However, the required video processing is usually extensive, requires skilled supervision, and is tailored to a fieldsite. This study proposes a video-processing algorithm that resolves these issues. It automatically adapts to the video data and continuously returns mapping updates and thereby aims to make wave-based remote sensing more inclusive to the coastal community. The code architecture for the first time includes the dynamic mode decomposition (DMD) to reduce the data complexity of wavefield video. The DMD is paired with loss-functions to handle spectral noise and a novel spectral storage system and Kalman filter to achieve fast converging measurements. The algorithm is showcased for fieldsites in the USA, the UK, the Netherlands, and Australia. The performance with respect to mapping bathymetry was validated using ground truth data. It was demonstrated that merely 32 s of video footage is needed for a first mapping update with average depth errors of 0.9&ndash;2.6 m. These further reduced to 0.5&ndash;1.4 m as the videos continued and more mapping updates were returned. Simultaneously, coherent maps for wave direction and celerity were achieved as well as maps of local near-surface currents. The algorithm is capable of mapping the coastal parameters on-the-fly and thereby offers analysis of video feeds, such as from drones or operational camera installations. Hence, the innovative application of analysis techniques like the DMD enables both accurate and unprecedentedly fast coastal reconnaissance. The source code and data of this article are openly available.},
DOI = {10.3390/rs13234742}
}



@Article{rs13234735,
AUTHOR = {Appeltans, Simon and Apolo-Apolo, Orly Enrique and Rodríguez-Vázquez, Jaime Nolasco and Pérez-Ruiz, Manuel and Pieters, Jan and Mouazen, Abdul M.},
TITLE = {The Automation of Hyperspectral Training Library Construction: A Case Study for Wheat and Potato Crops},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4735},
URL = {https://www.mdpi.com/2072-4292/13/23/4735},
ISSN = {2072-4292},
ABSTRACT = {The potential of hyperspectral measurements for early disease detection has been investigated by many experts over the last 5 years. One of the difficulties is obtaining enough data for training and building a hyperspectral training library. When the goal is to detect disease at a previsible stage, before the pathogen has manifested either its first symptoms or in the area surrounding the existing symptoms, it is impossible to objectively delineate the regions of interest containing the previsible pathogen growth from the areas without the pathogen growth. To overcome this, we propose an image labelling and segmentation algorithm that is able to (a) more objectively label the visible symptoms for the construction of a training library and (b) extend this labelling to the pre-visible symptoms. This algorithm is used to create hyperspectral training libraries for late blight disease (Phytophthora infestans) in potatoes and two types of leaf rust (Puccinia triticina and Puccinia striiformis) in wheat. The model training accuracies were compared between the automatic labelling algorithm and the classic visual delineation of regions of interest using a logistic regression machine learning approach. The modelling accuracies of the automatically labelled datasets were higher than those of the manually labelled ones for both potatoes and wheat, at 98.80% for P. infestans in potato, 97.69% for P. striiformis in soft wheat, and 96.66% for P. triticina in durum wheat.},
DOI = {10.3390/rs13234735}
}



@Article{rs13234750,
AUTHOR = {Chen, Jianchang and Chen, Yiming and Liu, Zhengjun},
TITLE = {Classification of Typical Tree Species in Laser Point Cloud Based on Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4750},
URL = {https://www.mdpi.com/2072-4292/13/23/4750},
ISSN = {2072-4292},
ABSTRACT = {We propose the Point Cloud Tree Species Classification Network (PCTSCN) to overcome challenges in classifying tree species from laser data with deep learning methods. The network is mainly composed of two parts: a sampling component in the early stage and a feature extraction component in the later stage. We used geometric sampling to extract regions with local features from the tree contours since these tend to be species-specific. Then we used an improved Farthest Point Sampling method to extract the features from a global perspective. We input the intensity of the tree point cloud as a dimensional feature and spatial information into the neural network and mapped it to higher dimensions for feature extraction. We used the data obtained by Terrestrial Laser Scanning (TLS) and Unmanned Aerial Vehicle Laser Scanning (UAVLS) to conduct tree species classification experiments of white birch and larch. The experimental results showed that in both the TLS and UAVLS datasets, the input tree point cloud density and the highest feature dimensionality of the mapping had an impact on the classification accuracy of the tree species. When the single tree sample obtained by TLS consisted of 1024 points and the highest dimension of the network mapping was 512, the classification accuracy of the trained model reached 96%. For the individual tree samples obtained by UAVLS, which consisted of 2048 points and had the highest dimension of the network mapping of 1024, the classification accuracy of the trained model reached 92%. TLS data tree species classification accuracy of PCTSCN was improved by 2&ndash;9% compared with other models using the same point density, amount of data and highest feature dimension. The classification accuracy of tree species obtained by UAVLS was up to 8% higher. We propose PCTSCN to provide a new strategy for the intelligent classification of forest tree species.},
DOI = {10.3390/rs13234750}
}



@Article{rs13234751,
AUTHOR = {Wang, Jionghua and Luo, Haowen and Li, Wenyu and Huang, Bo},
TITLE = {Building Function Mapping Using Multisource Geospatial Big Data: A Case Study in Shenzhen, China},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4751},
URL = {https://www.mdpi.com/2072-4292/13/23/4751},
ISSN = {2072-4292},
ABSTRACT = {Building function labelling plays an important role in understanding human activities inside buildings. This study develops a method of function label classification using integrated features derived from remote sensing and crowdsensing data with an extreme gradient boosting tree (XGBoost). The classification framework is verified based on a dataset from Shenzhen, China. An extended label system for six building types (residential, commercial, office, industrial, public facilities, and others) was applied, and various social functions were considered. The overall classification accuracies were 88.15% (kappa index = 0.72) and 85.56% (kappa index = 0.69). The importance of features was evaluated using the occurrence frequency of features at decision nodes. In the six-category classification system, the basic building attributes (22.99%) and POIs (46.74%) contributed most to the classification process; moreover, the building footprint (7.40%) and distance to roads (11.76%) also made notable contributions. The result shows that it is feasible to extract building environments from POI labels and building footprint geometry with a dimensional reduction model using an autoencoder. Additionally, crowdsensing data (e.g., POI and distance to roads) will become increasingly important as classification tasks become more complicated and the importance of basic building attributes declines.},
DOI = {10.3390/rs13234751}
}



@Article{math9233006,
AUTHOR = {Yang, Junqiang and Tang, Wenbing and Ding, Zuohua},
TITLE = {Long-Term Target Tracking of UAVs Based on Kernelized Correlation Filter},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {3006},
URL = {https://www.mdpi.com/2227-7390/9/23/3006},
ISSN = {2227-7390},
ABSTRACT = {During the target tracking process of unmanned aerial vehicles (UAVs), the target may disappear from view or be fully occluded by other objects, resulting in tracking failure. Therefore, determining how to identify tracking failure and re-detect the target is the key to the long-term target tracking of UAVs. Kernelized correlation filter (KCF) has been very popular for its satisfactory speed and accuracy since it was proposed. It is very suitable for UAV target tracking systems with high real-time requirements. However, it cannot detect tracking failure, so it is not suitable for long-term target tracking. Based on the above research, we propose an improved KCF to match long-term target tracking requirements. Firstly, we introduce a confidence mechanism to evaluate the target tracking results to determine the status of target tracking. Secondly, the tracking model update strategy is designed to make the model suffer from less background information interference, thereby improving the robustness of the algorithm. Finally, the Normalized Cross Correlation (NCC) template matching is used to make a regional proposal first, and then the tracking model is used for target re-detection. Then, we successfully apply the algorithm to the UAV system. The system uses binocular cameras to estimate the target position accurately, and we design a control method to keep the target in the UAV&rsquo;s field of view. Our algorithm has achieved the best results in both short-term and long-term evaluations of experiments on tracking benchmarks, which proves that the algorithm is superior to the baseline algorithm and has quite good performance. Outdoor experiments show that the developed UAV system can achieve long-term, autonomous target tracking.},
DOI = {10.3390/math9233006}
}



@Article{drones5040140,
AUTHOR = {Taddia, Yuri and Corbau, Corinne and Buoninsegni, Joana and Simeoni, Umberto and Pellegrinelli, Alberto},
TITLE = {UAV Approach for Detecting Plastic Marine Debris on the Beach: A Case Study in the Po River Delta (Italy)},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {140},
URL = {https://www.mdpi.com/2504-446X/5/4/140},
ISSN = {2504-446X},
ABSTRACT = {Anthropogenic marine debris (AMD) represent a global threat for aquatic environments. It is important to locate and monitor the distribution and presence of macroplastics along beaches to prevent degradation into microplastics (MP), which are potentially more harmful and more difficult to remove. UAV imaging represents a quick method for acquiring pictures with a ground spatial resolution of a few centimeters. In this work, we investigate strategies for AMD mapping on beaches with different ground resolutions and with elevation and multispectral data in support of RGB orthomosaics. Operators with varying levels of expertise and knowledge of the coastal environment map the AMD on four to five transects manually, using a range of photogrammetric tools. The initial survey was repeated after one year; in both surveys, beach litter was collected and further analyzed in the laboratory. Operators assign three levels of confidence when recognizing and describing AMD. Preliminary validation of results shows that items identified with high confidence were almost always classified properly. Approaching the detected items in terms of surface instead of a simple count increased the percentage of mapped litter significantly when compared to those collected. Multispectral data in near-infrared (NIR) wavelengths and digital surface models (DSMs) did not significantly improve the efficiency of manual mapping, even if vegetation features were removed using NDVI maps. In conclusion, this research shows that a good solution for performing beach AMD mapping can be represented by using RGB imagery with a spatial resolution of about 200 pix/m for detecting macroplastics and, in particular, focusing on the largest items. From the point of view of assessing and monitoring potential sources of MP, this approach is not only feasible but also quick, practical, and sustainable.},
DOI = {10.3390/drones5040140}
}



@Article{su132312980,
AUTHOR = {Wang, Zhenhua and Zhang, Xinyue and Li, Jing and Luan, Kuifeng},
TITLE = {A YOLO-Based Target Detection Model for Offshore Unmanned Aerial Vehicle Data},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {12980},
URL = {https://www.mdpi.com/2071-1050/13/23/12980},
ISSN = {2071-1050},
ABSTRACT = {Target detection in offshore unmanned aerial vehicle data is still a challenge due to the complex characteristics of targets, such as multi-sizes, alterable orientation, and complex backgrounds. Herein, a YOLO-based detection model (YOLO-D) was proposed for target detection in offshore unmanned aerial vehicle data. Based on the YOLOv3 network, the residual module was improved by establishing dense connections and adding a dual-attention mechanism (CBAM) to enhance the use of features and global information. Then, the loss function of the YOLO-D model was added to the weight coefficients to increase detection accuracy for small-size targets. Finally, the feature pyramid network (FPN) was replaced by the secondary recursive feature pyramid network to reduce the impacts of a complicated environment. Taking the car, boat, and deposit near the coastline as the targets, the proposed YOLO-D model was compared against other models, including the faster R-CNN, SSD, YOLOv3, and YOLOv5, to evaluate its detection performance. The results showed that the evaluation metrics of the YOLO-D model, including precision (Pr), recall (Re), average precision (AP), and the mean of average precision (mAP), had the highest values. The mAP of the YOLO-D model increased by 37.95%, 39.44%, 28.46%, and 5.08% compared to the faster R-CNN, SSD, YOLOv3, and YOLOv5, respectively. The AP of the car, boat, and deposit reached 96.24%, 93.70%, and 96.79% respectively. Moreover, the YOLO-D model had a higher detection accuracy than other models, especially in the detection of small-size targets. Collectively, the proposed YOLO-D model is a suitable model for target detection in offshore unmanned aerial vehicle data.},
DOI = {10.3390/su132312980}
}



@Article{rs13234757,
AUTHOR = {Sekrecka, Aleksandra},
TITLE = {Application of the XBoost Regressor for an A Priori Prediction of UAV Image Quality},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4757},
URL = {https://www.mdpi.com/2072-4292/13/23/4757},
ISSN = {2072-4292},
ABSTRACT = {In general, the quality of imagery from Unmanned Aerial Vehicles (UAVs) is evaluated after the flight, and then a decision is made on the further value and use of the acquired data. In this paper, an a priori (preflight) image quality prediction methodology is proposed to estimate the preflight image quality and to avoid unfavourable flights, which is extremely important from a time and cost management point of view. The XBoost Regressor model and cross-validation were used for machine learning of the model and image quality prediction. The model was learned on a rich database of real-world images acquired from UAVs under conditions varying in both sensor type, UAV type, exposure parameters, weather, topography, and land cover. Radiometric quality indices (SNR, Entropy, PIQE, NIQE, BRISQUE, and NRPBM) were calculated for each image to train and test the model and to assess the accuracy of image quality prediction. Different variants of preflight parameter knowledge were considered in the study. The proposed methodology offers the possibility of predicting image quality with high accuracy. The correlation coefficient between the actual and predicted image quality, depending on the number of parameters known a priori, ranged from 0.90 to 0.96. The methodology was designed for data acquired from a UAV. Similar prediction accuracy is expected for other low-altitude or close-range photogrammetric data.},
DOI = {10.3390/rs13234757}
}



@Article{telecom2040027,
AUTHOR = {Singh, Simran and Kumbhar, Abhaykumar and Güvenç, İsmail and Sichitiu, Mihail L.},
TITLE = {Intelligent Interference Management in UAV-Based HetNets},
JOURNAL = {Telecom},
VOLUME = {2},
YEAR = {2021},
NUMBER = {4},
PAGES = {472--488},
URL = {https://www.mdpi.com/2673-4001/2/4/27},
ISSN = {2673-4001},
ABSTRACT = {Unmanned aerial vehicles (UAVs) can play a key role in meeting certain demands of cellular networks. UAVs can be used not only as user equipment (UE) in cellular networks but also as mobile base stations (BSs) wherein they can either augment conventional BSs by adapting their position to serve the changing traffic and connectivity demands or temporarily replace BSs that are damaged due to natural disasters. The flexibility of UAVs allows them to provide coverage to UEs in hot-spots, at cell-edges, in coverage holes, or regions with scarce cellular infrastructure. In this work, we study how UAV locations and other cellular parameters may be optimized in such scenarios to maximize the spectral efficiency (SE) of the network. We compare the performance of machine learning (ML) techniques with conventional optimization approaches. We found that, on an average, a double deep Q learning approach can achieve 93.46% of the optimal median SE and 95.83% of the optimal mean SE. A simple greedy approach, which tunes the parameters of each BS and UAV independently, performed very well in all the cases that we tested. These computationally efficient approaches can be utilized to enhance the network performance in existing cellular networks.},
DOI = {10.3390/telecom2040027}
}



@Article{rs13234759,
AUTHOR = {Kim, Junwoo and Kim, Hwisong and Jeon, Hyungyun and Jeong, Seung-Hwan and Song, Juyoung and Vadivel, Suresh Krishnan Palanisamy and Kim, Duk-jin},
TITLE = {Synergistic Use of Geospatial Data for Water Body Extraction from Sentinel-1 Images for Operational Flood Monitoring across Southeast Asia Using Deep Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4759},
URL = {https://www.mdpi.com/2072-4292/13/23/4759},
ISSN = {2072-4292},
ABSTRACT = {Deep learning is a promising method for image classification, including satellite images acquired by various sensors. However, the synergistic use of geospatial data for water body extraction from Sentinel-1 data using deep learning and the applicability of existing deep learning models have not been thoroughly tested for operational flood monitoring. Here, we present a novel water body extraction model based on a deep neural network that exploits Sentinel-1 data and flood-related geospatial datasets. For the model, the U-Net was customised and optimised to utilise Sentinel-1 data and other flood-related geospatial data, including digital elevation model (DEM), Slope, Aspect, Profile Curvature (PC), Topographic Wetness Index (TWI), Terrain Ruggedness Index (TRI), and Buffer for the Southeast Asia region. Testing and validation of the water body extraction model was applied to three Sentinel-1 images for Vietnam, Myanmar, and Bangladesh. By segmenting 384 Sentinel-1 images, model performance and segmentation accuracy for all of the 128 cases that the combination of stacked layers had determined were evaluated following the types of combined input layers. Of the 128 cases, 31 cases showed improvement in Overall Accuracy (OA), and 19 cases showed improvement in both averaged intersection over union (IOU) and F1 score for the three Sentinel-1 images segmented for water body extraction. The averaged OA, IOU, and F1 scores of the &lsquo;Sentinel-1 VV&rsquo; band are 95.77, 80.35, and 88.85, respectively, whereas those of &lsquo;band combination VV, Slope, PC, and TRI&rsquo; are 96.73, 85.42, and 92.08, showing improvement by exploiting geospatial data. Such improvement was further verified with water body extraction results for the Chindwin river basin, and quantitative analysis of &lsquo;band combination VV, Slope, PC, and TRI&rsquo; showed an improvement of the F1 score by 7.68 percent compared to the segmentation output of the &lsquo;Sentinel-1 VV&rsquo; band. Through this research, it was demonstrated that the accuracy of deep learning-based water body extraction from Sentinel-1 images can be improved up to 7.68 percent by employing geospatial data. To the best of our knowledge, this is the first work of research that demonstrates the synergistic use of geospatial data in deep learning-based water body extraction over wide areas. It is anticipated that the results of this research could be a valuable reference when deep neural networks are applied for satellite image segmentation for operational flood monitoring and when geospatial layers are employed to improve the accuracy of deep learning-based image segmentation.},
DOI = {10.3390/rs13234759}
}



@Article{s21237829,
AUTHOR = {Pina, Rafael and Tibebu, Haileleol and Hook, Joosep and De Silva, Varuna and Kondoz, Ahmet},
TITLE = {Overcoming Challenges of Applying Reinforcement Learning for Intelligent Vehicle Control},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7829},
URL = {https://www.mdpi.com/1424-8220/21/23/7829},
PubMedID = {34883832},
ISSN = {1424-8220},
ABSTRACT = {Reinforcement learning (RL) is a booming area in artificial intelligence. The applications of RL are endless nowadays, ranging from fields such as medicine or finance to manufacturing or the gaming industry. Although multiple works argue that RL can be key to a great part of intelligent vehicle control related problems, there are many practical problems that need to be addressed, such as safety related problems that can result from non-optimal training in RL. For instance, for an RL agent to be effective it should first cover all the situations during training that it may face later. This is often difficult when applied to the real-world. In this work we investigate the impact of RL applied to the context of intelligent vehicle control. We analyse the implications of RL in path planning tasks and we discuss two possible approaches to overcome the gap between the theorical developments of RL and its practical applications. Specifically, firstly this paper discusses the role of Curriculum Learning (CL) to structure the learning process of intelligent vehicle control in a gradual way. The results show how CL can play an important role in training agents in such context. Secondly, we discuss a method of transferring RL policies from simulation to reality in order to make the agent experience situations in simulation, so it knows how to react to them in reality. For that, we use Arduino Y&uacute;n controlled robots as our platforms. The results enhance the effectiveness of the presented approach and show how RL policies can be transferred from simulation to reality even when the platforms are resource limited.},
DOI = {10.3390/s21237829}
}



@Article{aerospace8120363,
AUTHOR = {Elmeseiry, Nourhan and Alshaer, Nancy and Ismail, Tawfik},
TITLE = {A Detailed Survey and Future Directions of Unmanned Aerial Vehicles (UAVs) with Potential Applications},
JOURNAL = {Aerospace},
VOLUME = {8},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {363},
URL = {https://www.mdpi.com/2226-4310/8/12/363},
ISSN = {2226-4310},
ABSTRACT = {Recently, unmanned aerial vehicles (UAVs), also known as drones, have gained widespread interest in civilian and military applications, which has led to the development of novel UAVs that can perform various operations. UAVs are aircraft that can fly without the need of a human pilot onboard, meaning they can fly either autonomously or be remotely piloted. They can be equipped with multiple sensors, including cameras, inertial measurement units (IMUs), LiDAR, and GPS, to collect and transmit data in real time. Due to the demand for UAVs in various applications such as precision agriculture, search and rescue, wireless communications, and surveillance, several types of UAVs have been invented with different specifications for their size, weight, range and endurance, engine type, and configuration. Because of this variety, the design process and analysis are based on the type of UAV, with the availability of several control techniques that could be used to improve the flight of the UAV in order to avoid obstacles and potential collisions, as well as find the shortest path to save the battery life with the support of optimization techniques. However, UAVs face several challenges in order to fly smoothly, including collision avoidance, battery life, and intruders. This review paper presents UAVs&rsquo; classification, control applications, and future directions in industry and research interest. For the design process, fabrication, and analysis, various control approaches are discussed in detail. Furthermore, the challenges for UAVs, including battery charging, collision avoidance, and security, are also presented and discussed.},
DOI = {10.3390/aerospace8120363}
}



@Article{buildings11120579,
AUTHOR = {Amândio, Margarida and Parente, Manuel and Neves, José and Fonseca, Paulo},
TITLE = {Integration of Smart Pavement Data with Decision Support Systems: A Systematic Review},
JOURNAL = {Buildings},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {579},
URL = {https://www.mdpi.com/2075-5309/11/12/579},
ISSN = {2075-5309},
ABSTRACT = {Nowadays, pavement management systems (PMS) are mainly based on monitoring processes that have been established for a long time, and strongly depend on acquired experience. However, with the emergence of smart technologies, such as internet of things and artificial intelligence, PMS could be improved by applying these new smart technologies to their decision support systems, not just by updating their data collection methodologies, but also their data analysis tools. The application of these smart technologies to the field of pavement monitoring and condition evaluation will undoubtedly contribute to more efficient, less costly, safer, and environmentally friendly methodologies. Thus, the main drive of the present work is to provide insight for the development of future decision support systems for smart pavement management by conducting a systematic literature review of the developed works that apply smart technologies to this field. The conclusions drawn from the analysis allowed for the identification of a series of future direction recommendations for researchers. In fact, future PMS should tend to be capable of collecting and analyzing data at different levels, both externally at the surface or inside the pavement, as well as to detect and predict all types of functional and structural flaws and defects.},
DOI = {10.3390/buildings11120579}
}



@Article{electronics10232915,
AUTHOR = {Sadique, Joarder Jafor and Ullah, Shaikh Enayet and Raad, Raad and Islam, Md. Rabiul and Rahman, Md. Mahbubar and Kouzani, Abbas Z. and Mahmud, M. A. Parvez},
TITLE = {Gyre Precoding and T-Transformation-Based GFDM System for UAV-Aided mMTC Network},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {2915},
URL = {https://www.mdpi.com/2079-9292/10/23/2915},
ISSN = {2079-9292},
ABSTRACT = {In this paper, an unmanned aerial vehicle (UAV)-aided multi-antenna configured downlink mmWave cooperative generalized frequency division multiplexing (GFDM) system is proposed. To provide physical layer security (PLS), a 3D controlled Lorenz mapping system is introduced. Furthermore, the combination of T-transformation spreading codes, walsh Hadamard transform, and discrete Fourier transform (DFT) techniques are integrated with a novel linear multi-user multiple-input multiple-output (MU-MIMO) gyre precoding (GP) for multi-user interference reduction. Furthermore, concatenated channel-coding with multi-user beamforming weighting-aided maximum-likelihood and zero forcing (ZF) signal detection schemes for an improved bit error rate (BER) are also used. The system is then simulated with a single base station (BS), eight massive machine-type communications (mMTC) users, and two UAV relay stations (RSs). Numerical results reveal the robustness of the proposed system in terms of PLS and an achievable ergodic rate with signal-to-interference-plus-noise ratio (SINR) under the implementation of T-transformation scheme. By incorporating the 3D mobility model, brownian perturbations of the UAVs are also analyzed. An out-of-band (OOB) reduction of 320 dB with an improved BER of 1&times;10&minus;4 in 16-QAM for a signal-to-noise ratio, Eb/N0, of 20 dB is achieved.},
DOI = {10.3390/electronics10232915}
}



@Article{electronics10232918,
AUTHOR = {Mohamed, Nader and Al-Jaroodi, Jameela and Lazarova-Molnar, Sanja and Jawhar, Imad},
TITLE = {Applications of Integrated IoT-Fog-Cloud Systems to Smart Cities: A Survey},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {2918},
URL = {https://www.mdpi.com/2079-9292/10/23/2918},
ISSN = {2079-9292},
ABSTRACT = {Several cities have recently moved towards becoming smart cities for better services and quality of life for residents and visitors, with: optimized resource utilization; increased environmental protection; enhanced infrastructure operations and maintenance; and strong safety and security measures. Smart cities depend on deploying current and new technologies and different optimization methods to enhance services and performance in their different sectors. Some of the technologies assisting smart city applications are the Internet of Things (IoT), fog computing, and cloud computing. Integrating these three to serve one system (we will refer to it as integrated IoT-fog-cloud system (iIFC)) creates an advanced platform to develop and operate various types of smart city applications. This platform will allow applications to use the best features from the IoT devices, fog nodes, and cloud services to deliver best capabilities and performance. Utilizing this powerful platform will provide many opportunities for enhancing and optimizing applications in energy, transportation, healthcare, and other areas. In this paper we survey various applications of iIFCs for smart cities. We identify different common issues associated with utilizing iIFCs for smart city applications. These issues arise due to the characteristics of iIFCs on the one side and the requirements of different smart city applications on the other. In addition, we outline the main requirements to effectively utilize iIFCs for smart city applications. These requirements are related to optimization, networking, and security.},
DOI = {10.3390/electronics10232918}
}



@Article{app112311193,
AUTHOR = {Yang, Yuting and Mei, Gang},
TITLE = {Deep Transfer Learning Approach for Identifying Slope Surface Cracks},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {11193},
URL = {https://www.mdpi.com/2076-3417/11/23/11193},
ISSN = {2076-3417},
ABSTRACT = {Geohazards such as landslides, which are often accompanied by surface cracks, have caused great harm to public safety and property. If these surface cracks could be identified in time, this would be of great significance for the monitoring and early warning of geohazards. Currently, the most common method for crack identification is manual detection, which has low efficiency and accuracy. In this paper, a deep transfer learning approach is proposed to effectively and efficiently identify slope surface cracks for the sake of fast monitoring and early warning of geohazards, such as landslides. The essential idea is to employ transfer learning by training (a) a large sample dataset of concrete cracks and (b) a small sample dataset of soil and rock masses&rsquo; cracks. In the proposed approach, (1) pretrained crack identification models are constructed based on a large sample dataset of concrete cracks; (2) refined crack identification models are further constructed based on a small sample dataset of soil and rock masses&rsquo; cracks. The proposed approach could be applied to conduct UAV surveys on high and steep slopes to provide monitoring and early warning of landslides to ensure the safety of people and property.},
DOI = {10.3390/app112311193}
}



@Article{agriculture11121190,
AUTHOR = {Fang, Lifa and Wu, Yanqiang and Li, Yuhua and Guo, Hongen and Zhang, Hua and Wang, Xiaoyu and Xi, Rui and Hou, Jialin},
TITLE = {Using Channel and Network Layer Pruning Based on Deep Learning for Real-Time Detection of Ginger Images},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1190},
URL = {https://www.mdpi.com/2077-0472/11/12/1190},
ISSN = {2077-0472},
ABSTRACT = {Consistent ginger shoot orientation helps to ensure consistent ginger emergence and meet shading requirements. YOLO v3 is used to recognize ginger images in response to the current ginger seeder&rsquo;s difficulty in meeting the above agronomic problems. However, it is not suitable for direct application on edge computing devices due to its high computational cost. To make the network more compact and to address the problems of low detection accuracy and long inference time, this study proposes an improved YOLO v3 model, in which some redundant channels and network layers are pruned to achieve real-time determination of ginger shoots and seeds. The test results showed that the pruned model reduced its model size by 87.2% and improved the detection speed by 85%. Meanwhile, its mean average precision (mAP) reached 98.0% for ginger shoots and seeds, only 0.1% lower than the model before pruning. Moreover, after deploying the model to the Jetson Nano, the test results showed that its mAP was 97.94%, the recognition accuracy could reach 96.7%, and detection speed could reach 20 frames&middot;s&minus;1. The results showed that the proposed method was feasible for real-time and accurate detection of ginger images, providing a solid foundation for automatic and accurate ginger seeding.},
DOI = {10.3390/agriculture11121190}
}



@Article{s21237855,
AUTHOR = {Amrallah, Amr and Mohamed, Ehab Mahmoud and Tran, Gia Khanh and Sakaguchi, Kei},
TITLE = {Enhanced Dynamic Spectrum Access in UAV Wireless Networks for Post-Disaster Area Surveillance System: A Multi-Player Multi-Armed Bandit Approach},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7855},
URL = {https://www.mdpi.com/1424-8220/21/23/7855},
PubMedID = {34883856},
ISSN = {1424-8220},
ABSTRACT = {Modern wireless networks are notorious for being very dense, uncoordinated, and selfish, especially with greedy user needs. This leads to a critical scarcity problem in spectrum resources. The Dynamic Spectrum Access system (DSA) is considered a promising solution for this scarcity problem. With the aid of Unmanned Aerial Vehicles (UAVs), a post-disaster surveillance system is implemented using Cognitive Radio Network (CRN). UAVs are distributed in the disaster area to capture live images of the damaged area and send them to the disaster management center. CRN enables UAVs to utilize a portion of the spectrum of the Electronic Toll Collection (ETC) gates operating in the same area. In this paper, a joint transmission power selection, data-rate maximization, and interference mitigation problem is addressed. Considering all these conflicting parameters, this problem is investigated as a budget-constrained multi-player multi-armed bandit (MAB) problem. The whole process is done in a decentralized manner, where no information is exchanged between UAVs. To achieve this, two power-budget-aware PBA-MAB) algorithms, namely upper confidence bound (PBA-UCB (MAB) algorithm and Thompson sampling (PBA-TS) algorithm, were proposed to realize the selection of the transmission power value efficiently. The proposed PBA-MAB algorithms show outstanding performance over random power value selection in terms of achievable data rate.},
DOI = {10.3390/s21237855}
}



@Article{w13233349,
AUTHOR = {Merlino, Silvia and Paterni, Marco and Locritani, Marina and Andriolo, Umberto and Gonçalves, Gil and Massetti, Luciano},
TITLE = {Citizen Science for Marine Litter Detection and Classification on Unmanned Aerial Vehicle Images},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {3349},
URL = {https://www.mdpi.com/2073-4441/13/23/3349},
ISSN = {2073-4441},
ABSTRACT = {Unmanned aerial vehicles (UAV, aka drones) are being used for mapping macro-litter in the environment. As drone images require a manual processing task for detecting marine litter, it is of interest to evaluate the accuracy of non-expert citizen science operators (CSO) in performing this task. Students from Italian secondary schools (in this work, the CSO) were invited to identify, mark, and classify stranded litter items on a UAV orthophoto collected on an Italian beach. A specific training program and working tools were developed for the aim. The comparison with the standard in situ visual census survey returned a general underestimation (50%) of items. However, marine litter bulk categorisation was fairly in agreement with the in situ survey, especially for sources classification. The concordance level among CSO ranged between 60% and 91%, depending on the item properties considered (type, material, and colour). As the assessment accuracy was in line with previous works developed by experts, remote detection of marine litter on UAV images can be improved through citizen science programs, upon an appropriate training plan and provision of specific tools.},
DOI = {10.3390/w13233349}
}



@Article{app112311234,
AUTHOR = {Yeom, Seokwon},
TITLE = {Long Distance Moving Vehicle Tracking with a Multirotor Based on IMM-Directional Track Association},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {11234},
URL = {https://www.mdpi.com/2076-3417/11/23/11234},
ISSN = {2076-3417},
ABSTRACT = {The multirotor has the capability to capture distant objects. Because the computing resources of the multirotor are limited, efficiency is an important factor to consider. In this paper, multiple target tracking with a multirotor at a long distance (~400 m) is addressed; the interacting multiple model (IMM) estimator combined with the directional track-to-track association (abbreviated as track association) is proposed. The previous work of the Kalman estimator with the track association approach is extended to the IMM estimator with the directional track association. The IMM estimator can handle multiple targets with various maneuvers. The track association scheme is modified in consideration of the direction of the target movement. The overall system is composed of moving object detection for measurement generation and multiple target tracking for state estimation. The moving object detection consists of frame-to-frame subtraction of three-color layers and thresholding, morphological operation, and false alarm removing based on the object size and shape properties. The centroid of the detected object is input into the next tracking stage. The track is initialized using the difference between two nearest points measured in consecutive frames. The measurement nearest to the state prediction is used to update the state of the target for measurement-to-track association. The directional track association tests both the hypothesis and the maximum deviation between the displacement and directions of two tracks followed by track selection, fusion, and termination. In the experiment, a multirotor flying at an altitude of 400 m captured 55 moving vehicles around a highway interchange for about 20 s. The tracking performance is evaluated for the IMMs using constant velocity (CV) and constant acceleration (CA) motion models. The IMM-CA with the directional track association scheme outperforms other methods with an average total track life of 91.7% and an average mean track life of 84.2%.},
DOI = {10.3390/app112311234}
}



@Article{app112311229,
AUTHOR = {Park, Sung-Sik and Tran, Van-Than and Lee, Dong-Eun},
TITLE = {Application of Various YOLO Models for Computer Vision-Based Real-Time Pothole Detection},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {11229},
URL = {https://www.mdpi.com/2076-3417/11/23/11229},
ISSN = {2076-3417},
ABSTRACT = {Pothole repair is one of the paramount tasks in road maintenance. Effective road surface monitoring is an ongoing challenge to the management agency. The current pothole detection, which is conducted image processing with a manual operation, is labour-intensive and time-consuming. Computer vision offers a mean to automate its visual inspection process using digital imaging, hence, identifying potholes from a series of images. The goal of this study is to apply different YOLO models for pothole detection. Three state-of-the-art object detection frameworks (i.e., YOLOv4, YOLOv4-tiny, and YOLOv5s) are experimented to measure their performance involved in real-time responsiveness and detection accuracy using the image set. The image set is identified by running the deep convolutional neural network (CNN) on several deep learning pothole detectors. After collecting a set of 665 images in 720 &times; 720 pixels resolution that captures various types of potholes on different road surface conditions, the set is divided into training, testing, and validation subsets. A mean average precision at 50% Intersection-over-Union threshold (mAP_0.5) is used to measure the performance of models. The study result shows that the mAP_0.5 of YOLOv4, YOLOv4-tiny, and YOLOv5s are 77.7%, 78.7%, and 74.8%, respectively. It confirms that the YOLOv4-tiny is the best fit model for pothole detection.},
DOI = {10.3390/app112311229}
}



@Article{rs13234803,
AUTHOR = {Ojogbane, Sani Success and Mansor, Shattri and Kalantar, Bahareh and Khuzaimah, Zailani Bin and Shafri, Helmi Zulhaidi Mohd and Ueda, Naonori},
TITLE = {Automated Building Detection from Airborne LiDAR and Very High-Resolution Aerial Imagery with Deep Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4803},
URL = {https://www.mdpi.com/2072-4292/13/23/4803},
ISSN = {2072-4292},
ABSTRACT = {The detection of buildings in the city is essential in several geospatial domains and for decision-making regarding intelligence for city planning, tax collection, project management, revenue generation, and smart cities, among other areas. In the past, the classical approach used for building detection was by using the imagery and it entailed human&ndash;computer interaction, which was a daunting proposition. To tackle this task, a novel network based on an end-to-end deep learning framework is proposed to detect and classify buildings features. The proposed CNN has three parallel stream channels: the first is the high-resolution aerial imagery, while the second stream is the digital surface model (DSM). The third was fixed on extracting deep features using the fusion of channel one and channel two, respectively. Furthermore, the channel has eight group convolution blocks of 2D convolution with three max-pooling layers. The proposed model&rsquo;s efficiency and dependability were tested on three different categories of complex urban building structures in the study area. Then, morphological operations were applied to the extracted building footprints to increase the uniformity of the building boundaries and produce improved building perimeters. Thus, our approach bridges a significant gap in detecting building objects in diverse environments; the overall accuracy (OA) and kappa coefficient of the proposed method are greater than 80% and 0.605, respectively. The findings support the proposed framework and methodologies&rsquo; efficacy and effectiveness at extracting buildings from complex environments.},
DOI = {10.3390/rs13234803}
}



@Article{s21237889,
AUTHOR = {Sott, Michele Kremer and Nascimento, Leandro da Silva and Foguesatto, Cristian Rogério and Furstenau, Leonardo B. and Faccin, Kadígia and Zawislak, Paulo Antônio and Mellado, Bruce and Kong, Jude Dzevela and Bragazzi, Nicola Luigi},
TITLE = {A Bibliometric Network Analysis of Recent Publications on Digital Agriculture to Depict Strategic Themes and Evolution Structure},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7889},
URL = {https://www.mdpi.com/1424-8220/21/23/7889},
PubMedID = {34883903},
ISSN = {1424-8220},
ABSTRACT = {The agriculture sector is one of the backbones of many countries&rsquo; economies. Its processes have been changing to enable technology adoption to increase productivity, quality, and sustainable development. In this research, we present a scientific mapping of the adoption of precision techniques and breakthrough technologies in agriculture, so-called Digital Agriculture. To do this, we used 4694 documents from the Web of Science database to perform a Bibliometric Performance and Network Analysis of the literature using SciMAT software with the support of the PICOC protocol. Our findings presented 22 strategic themes related to Digital Agriculture, such as Internet of Things (IoT), Unmanned Aerial Vehicles (UAV) and Climate-smart Agriculture (CSA), among others. The thematic network structure of the nine most important clusters (motor themes) was presented and an in-depth discussion was performed. The thematic evolution map provides a broad perspective of how the field has evolved over time from 1994 to 2020. In addition, our results discuss the main challenges and opportunities for research and practice in the field of study. Our findings provide a comprehensive overview of the main themes related to Digital Agriculture. These results show the main subjects analyzed on this topic and provide a basis for insights for future research.},
DOI = {10.3390/s21237889}
}



@Article{logistics5040084,
AUTHOR = {Abideen, Ahmed Zainul and Sundram, Veera Pandiyan Kaliani and Pyeman, Jaafar and Othman, Abdul Kadir and Sorooshian, Shahryar},
TITLE = {Digital Twin Integrated Reinforced Learning in Supply Chain and Logistics},
JOURNAL = {Logistics},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {84},
URL = {https://www.mdpi.com/2305-6290/5/4/84},
ISSN = {2305-6290},
ABSTRACT = {Background: As the Internet of Things (IoT) has become more prevalent in recent years, digital twins have attracted a lot of attention. A digital twin is a virtual representation that replicates a physical object or process over a period of time. These tools directly assist in reducing the manufacturing and supply chain lead time to produce a lean, flexible, and smart production and supply chain setting. Recently, reinforced machine learning has been introduced in production and logistics systems to build prescriptive decision support platforms to create a combination of lean, smart, and agile production setup. Therefore, there is a need to cumulatively arrange and systematize the past research done in this area to get a better understanding of the current trend and future research directions from the perspective of Industry 4.0. Methods: Strict keyword selection, search strategy, and exclusion criteria were applied in the Scopus database (2010 to 2021) to systematize the literature. Results: The findings are snowballed as a systematic review and later the final data set has been conducted to understand the intensity and relevance of research work done in different subsections related to the context of the research agenda proposed. Conclusion: A framework for data-driven digital twin generation and reinforced learning has been proposed at the end of the paper along with a research paradigm.},
DOI = {10.3390/logistics5040084}
}



@Article{rs13234811,
AUTHOR = {Štroner, Martin and Urban, Rudolf and Línková, Lenka},
TITLE = {A New Method for UAV Lidar Precision Testing Used for the Evaluation of an Affordable DJI ZENMUSE L1 Scanner},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4811},
URL = {https://www.mdpi.com/2072-4292/13/23/4811},
ISSN = {2072-4292},
ABSTRACT = {Lately, affordable unmanned aerial vehicle (UAV)-lidar systems have started to appear on the market, highlighting the need for methods facilitating proper verification of their accuracy. However, the dense point cloud produced by such systems makes the identification of individual points that could be used as reference points difficult. In this paper, we propose such a method utilizing accurately georeferenced targets covered with high-reflectivity foil, which can be easily extracted from the cloud; their centers can be determined and used for the calculation of the systematic shift of the lidar point cloud. Subsequently, the lidar point cloud is cleaned of such systematic shift and compared with a dense SfM point cloud, thus yielding the residual accuracy. We successfully applied this method to the evaluation of an affordable DJI ZENMUSE L1 scanner mounted on the UAV DJI Matrice 300 and found that the accuracies of this system (3.5 cm in all directions after removal of the global georeferencing error) are better than manufacturer-declared values (10/5 cm horizontal/vertical). However, evaluation of the color information revealed a relatively high (approx. 0.2 m) systematic shift.},
DOI = {10.3390/rs13234811}
}



@Article{s21237888,
AUTHOR = {Lo, Li-Yu and Yiu, Chi Hao and Tang, Yu and Yang, An-Shik and Li, Boyang and Wen, Chih-Yung},
TITLE = {Dynamic Object Tracking on Autonomous UAV System for Surveillance Applications},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7888},
URL = {https://www.mdpi.com/1424-8220/21/23/7888},
PubMedID = {34883913},
ISSN = {1424-8220},
ABSTRACT = {The ever-burgeoning growth of autonomous unmanned aerial vehicles (UAVs) has demonstrated a promising platform for utilization in real-world applications. In particular, a UAV equipped with a vision system could be leveraged for surveillance applications. This paper proposes a learning-based UAV system for achieving autonomous surveillance, in which the UAV can be of assistance in autonomously detecting, tracking, and following a target object without human intervention. Specifically, we adopted the YOLOv4-Tiny algorithm for semantic object detection and then consolidated it with a 3D object pose estimation method and Kalman filter to enhance the perception performance. In addition, UAV path planning for a surveillance maneuver is integrated to complete the fully autonomous system. The perception module is assessed on a quadrotor UAV, while the whole system is validated through flight experiments. The experiment results verified the robustness, effectiveness, and reliability of the autonomous object tracking UAV system in performing surveillance tasks. The source code is released to the research community for future reference.},
DOI = {10.3390/s21237888}
}



@Article{rs13234839,
AUTHOR = {Zheng, Lianming and Lin, Rui and Wang, Xuemei and Chen, Weihua},
TITLE = {The Development and Application of Machine Learning in Atmospheric Environment Studies},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4839},
URL = {https://www.mdpi.com/2072-4292/13/23/4839},
ISSN = {2072-4292},
ABSTRACT = {Machine learning (ML) plays an important role in atmospheric environment prediction, having been widely applied in atmospheric science with significant progress in algorithms and hardware. In this paper, we present a brief overview of the development of ML models as well as their application to atmospheric environment studies. ML model performance is then compared based on the main air pollutants (i.e., PM2.5, O3, and NO2) and model type. Moreover, we identify the key driving variables for ML models in predicting particulate matter (PM) pollutants by quantitative statistics. Additionally, a case study for wet nitrogen deposition estimation is carried out based on ML models. Finally, the prospects of ML for atmospheric prediction are discussed.},
DOI = {10.3390/rs13234839}
}



@Article{rs13234844,
AUTHOR = {Shin, Jisun and Lee, Jong-Seok and Jang, Lee-Hyun and Lim, Jinwook and Khim, Boo-Keun and Jo, Young-Heon},
TITLE = {Sargassum Detection Using Machine Learning Models: A Case Study with the First 6 Months of GOCI-II Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4844},
URL = {https://www.mdpi.com/2072-4292/13/23/4844},
ISSN = {2072-4292},
ABSTRACT = {A record-breaking agglomeration of Sargassum was packed along the northern Jeju coast in Korea in 2021, and laborers suffered from removing them from the beach. If remote sensing can be used to detect the locations at which Sargassum accumulated in a timely and accurate manner, we could remove them before their arrival and reduce the damage caused by Sargassum. This study aims to detect Sargassum distribution on the coast of Jeju Island using the Geostationary KOMPSAT 2B (GK2B) Geostationary Ocean Color Imager-II (GOCI-II) imagery that was launched in February 2020, with measurements available since October 2020. For this, we used GOCI-II imagery during the first 6 months and machine learning models including Fine Tree, a Fine Gaussian support vector machine (SVM), and Gentle adaptive boosting (GentleBoost). We trained the models with the GOCI-II Rayleigh-corrected reflectance (RhoC) image and a ground truth map extracted from high-resolution images as input and output, respectively. Qualitative and quantitative assessments were carried out using the three machine learning models and traditional methods such as Sargassum indexes. We found that GentleBoost showed a lower false positive (6.2%) and a high F-measure level (0.82), and a more appropriate Sargassum distribution compared to other methods. The application of the machine learning model to GOCI-II images in various atmospheric conditions is therefore considered successful for mapping Sargassum extent quickly, enabling reduction of laborers&rsquo; efforts to remove them.},
DOI = {10.3390/rs13234844}
}



@Article{ijms222312912,
AUTHOR = {Hou, Quancan and Wan, Xiangyuan},
TITLE = {Epigenome and Epitranscriptome: Potential Resources for Crop Improvement},
JOURNAL = {International Journal of Molecular Sciences},
VOLUME = {22},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {12912},
URL = {https://www.mdpi.com/1422-0067/22/23/12912},
PubMedID = {34884725},
ISSN = {1422-0067},
ABSTRACT = {Crop breeding faces the challenge of increasing food demand, especially under climatic changes. Conventional breeding has relied on genetic diversity by combining alleles to obtain desired traits. In recent years, research on epigenetics and epitranscriptomics has shown that epigenetic and epitranscriptomic diversity provides additional sources for crop breeding and harnessing epigenetic and epitranscriptomic regulation through biotechnologies has great potential for crop improvement. Here, we review epigenome and epitranscriptome variations during plant development and in response to environmental stress as well as the available sources for epiallele formation. We also discuss the possible strategies for applying epialleles and epitranscriptome engineering in crop breeding.},
DOI = {10.3390/ijms222312912}
}



@Article{electronics10232977,
AUTHOR = {Li, Yan and Zhao, Mengyu and Zhang, Huazhi and Yang, Fuling and Wang, Suyu},
TITLE = {An Interactive Self-Learning Game and Evolutionary Approach Based on Non-Cooperative Equilibrium},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {2977},
URL = {https://www.mdpi.com/2079-9292/10/23/2977},
ISSN = {2079-9292},
ABSTRACT = {Most current studies on multi-agent evolution based on deep learning take a cooperative equilibrium strategy, while interactive self-learning is not always considered. An interactive self-learning game and evolution method based on non-cooperative equilibrium (ISGE-NCE) is proposed to take the benefits of both game theory and interactive learning for multi-agent confrontation evolution. A generative adversarial network (GAN) is designed combining with multi-agent interactive self-learning, and the non-cooperative equilibrium strategy is well adopted within the framework of interactive self-learning, aiming for high evolution efficiency and interest. For assessment, three typical multi-agent confrontation experiments are designed and conducted. The results show that, first, in terms of training speed, the ISGE-NCE produces a training convergence rate of at least 46.3% higher than that of the method without considering interactive self-learning. Second, the evolution rate of the interference and detection agents reaches 60% and 80%, respectively, after training by using our method. In the three different experiment scenarios, compared with the DDPG, our ISGE-NCE method improves the multi-agent evolution effectiveness by 43.4%, 50%, and 20%, respectively, with low training costs. The performances demonstrate the significant superiority of our ISGE-NCE method in swarm intelligence.},
DOI = {10.3390/electronics10232977}
}



@Article{rs13234853,
AUTHOR = {Wei, Dawei and Xi, Ning and Ma, Jianfeng and He, Lei},
TITLE = {UAV-Assisted Privacy-Preserving Online Computation Offloading for Internet of Things},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4853},
URL = {https://www.mdpi.com/2072-4292/13/23/4853},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle (UAV) plays a more and more important role in Internet of Things (IoT) for remote sensing and device interconnecting. Due to the limitation of computing capacity and energy, the UAV cannot handle complex tasks. Recently, computation offloading provides a promising way for the UAV to handle complex tasks by deep reinforcement learning (DRL)-based methods. However, existing DRL-based computation offloading methods merely protect usage pattern privacy and location privacy. In this paper, we consider a new privacy issue in UAV-assisted IoT, namely computation offloading preference leakage, which lacks through study. To cope with this issue, we propose a novel privacy-preserving online computation offloading method for UAV-assisted IoT. Our method integrates the differential privacy mechanism into deep reinforcement learning (DRL), which can protect UAV&rsquo;s offloading preference. We provide the formal analysis on security and utility loss of our method. Extensive real-world experiments are conducted. Results demonstrate that, compared with baseline methods, our method can learn cost-efficient computation offloading policy without preference leakage and a priori knowledge of the wireless channel model.},
DOI = {10.3390/rs13234853}
}



@Article{land10121316,
AUTHOR = {Saad, Felipe and Biswas, Sumalika and Huang, Qiongyu and Corte, Ana Paula Dalla and Coraiola, Márcio and Macey, Sarah and Carlucci, Marcos Bergmann and Leimgruber, Peter},
TITLE = {Detectability of the Critically Endangered Araucaria angustifolia Tree Using Worldview-2 Images, Google Earth Engine and UAV-LiDAR},
JOURNAL = {Land},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1316},
URL = {https://www.mdpi.com/2073-445X/10/12/1316},
ISSN = {2073-445X},
ABSTRACT = {The Brazilian Atlantic Forest is a global biodiversity hotspot and has been extensively mapped using satellite remote sensing. However, past mapping focused on overall forest cover without consideration of keystone plant resources such as Araucaria angustifolia.&nbsp;A. angustifolia is a critically endangered coniferous tree that is essential for supporting overall biodiversity in the Atlantic Forest. A. angustifolia&rsquo;s distribution has declined dramatically because of overexploitation and land-use changes. Accurate detection and rapid assessments of the distribution and abundance of this species are urgently needed. We compared two approaches for mapping Araucaria angustifolia across two scales (stand vs. individual tree) at three study sites in Brazil. The first approach used Worldview-2 images and Random Forest in Google Earth Engine to detect A. angustifolia at the stand level, with an accuracy of &gt;90% across all three study sites. The second approach relied on object identification using UAV-LiDAR and successfully mapped individual trees (producer&rsquo;s/user&rsquo;s accuracy = 94%/64%) at one study site. Both approaches can be employed in tandem to map remaining stands and to determine the exact location of A. angustifolia trees. Each approach has its own strengths and weaknesses, and we discuss their adoptability by managers to inform conservation of A. angustifolia.},
DOI = {10.3390/land10121316}
}



@Article{app112311335,
AUTHOR = {Grzelczak, Maciej and Duch, Piotr},
TITLE = {Deep Reinforcement Learning Algorithms for Path Planning Domain in Grid-like Environment},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {11335},
URL = {https://www.mdpi.com/2076-3417/11/23/11335},
ISSN = {2076-3417},
ABSTRACT = {Recently, more and more solutions have utilised artificial intelligence approaches in order to enhance or optimise processes to achieve greater sustainability. One of the most pressing issues is the emissions caused by cars; in this paper, the problem of optimising the route of delivery cars is tackled. In this paper, the applicability of the deep reinforcement learning algorithms with regards to the aforementioned problem is tested on a simulation game designed and implemented to pose various challenges such as constant change of delivery locations. The algorithms chosen for this task are Advantage Actor-Critic (A2C) with and without Proximal Policy Optimisation (PPO). These novel and advanced reinforcement learning algorithms have yet not been utilised in similar scenarios. The differences in performance and learning process of those are visualised and discussed. It is demonstrated that both of those algorithms present a slow but steady learning curve, which is an expected effect of reinforcement learning algorithms, leading to a conclusion that the algorithms would discover an optimal policy with an adequately long learning process. Additionally, the benefits of the Proximal Policy Optimisation algorithm are proven by the enhanced learning curve with comparison to the Advantage Actor-Critic approach, as the learning process is characterised by faster growth with a significantly smaller variation. Finally, the applicability of such algorithms in the described scenarios is discussed, alongside the possible improvements and future work.},
DOI = {10.3390/app112311335}
}



@Article{fi13120306,
AUTHOR = {Dirir, Ahmed and Ignatious, Henry and Elsayed, Hesham and Khan, Manzoor and Adib, Mohammed and Mahmoud, Anas and Al-Gunaid, Moatasem},
TITLE = {An Advanced Deep Learning Approach for Multi-Object Counting in Urban Vehicular Environments},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {306},
URL = {https://www.mdpi.com/1999-5903/13/12/306},
ISSN = {1999-5903},
ABSTRACT = {Object counting is an active research area that gained more attention in the past few years. In smart cities, vehicle counting plays a crucial role in urban planning and management of the Intelligent Transportation Systems (ITS). Several approaches have been proposed in the literature to address this problem. However, the resulting detection accuracy is still not adequate. This paper proposes an efficient approach that uses deep learning concepts and correlation filters for multi-object counting and tracking. The performance of the proposed system is evaluated using a dataset consisting of 16 videos with different features to examine the impact of object density, image quality, angle of view, and speed of motion towards system accuracy. Performance evaluation exhibits promising results in normal traffic scenarios and adverse weather conditions. Moreover, the proposed approach outperforms the performance of two recent approaches from the literature.},
DOI = {10.3390/fi13120306}
}



@Article{agronomy11122446,
AUTHOR = {Ge, Haixiao and Ma, Fei and Li, Zhenwang and Du, Changwen},
TITLE = {Global Sensitivity Analysis for CERES-Rice Model under Different Cultivars and Specific-Stage Variations of Climate Parameters},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2446},
URL = {https://www.mdpi.com/2073-4395/11/12/2446},
ISSN = {2073-4395},
ABSTRACT = {Global sensitivity analysis (SA) has become an efficient way to identify the most influential parameters on model results. However, the effects of cultivar variation and specific-stage variations of climate conditions on model outputs still remain unclear. In this study, 30 indica hybrid rice cultivars were simulated in the CERES-Rice model; then the Sobol&rsquo; method was used to perform a global SA on 16 investigated parameters for three model outputs (anthesis day, maturity day, and yield). In addition, we also compared the differences in the sensitivity results under four specific-stage variations (vegetative phase, panicle-formation phase, ripening phase, and the whole growth season) of climate conditions. The results indicated that (1) parameter Tavg, G4, and P2O are the most influential parameters for all model outputs across cultivars during the whole growth season; (2) under the vegetative-phase variation of climate parameters; the variability of model outputs is mainly controlled by parameter P2O and Tavg; (3) under the panicle-formation-phase or ripening-phase variation of climate parameters, parameter P2O was the dominant variable for all model outputs; (4) parameter PORM had a considerable effect (the total sensitivity index, STi; STi&gt;0.05) on yield regardless of the various specific-stage variations of the climate parameters. Findings obtained from this study will contribute to understanding the comprehensive effects of crop parameters on model outputs under different cultivars and specific-stage variations of climate conditions.},
DOI = {10.3390/agronomy11122446}
}



@Article{ijgi10120805,
AUTHOR = {Fang, Xuan and Li, Jincheng and Zhu, Ying and Cao, Jianjun and Na, Jiaming and Jiang, Sheng and Ding, Hu},
TITLE = {OBIA-Based Extraction of Artificial Terrace Damages in the Loess Plateau of China from UAV Photogrammetry},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {805},
URL = {https://www.mdpi.com/2220-9964/10/12/805},
ISSN = {2220-9964},
ABSTRACT = {Terraces, which are typical artificial landforms found around world, are of great importance for agricultural production and soil and water conservation. However, due to the lack of maintenance, terrace damages often occur and affect the local flow process, which will influence soil erosion. Automatic high-accuracy mapping of terrace damages is the basis of monitoring and related studies. Researchers have achieved artificial terrace damage mapping mainly via manual field investigation, but an automatic method is still lacking. In this study, given the success of high-resolution unmanned aerial vehicle (UAV) photogrammetry and object-based image analysis (OBIA) for image processing tasks, an integrated framework based on OBIA and UAV photogrammetry is proposed for terrace damage mapping. The Pujiawa terrace in the Loess Plateau of China was selected as the study area. Firstly, the segmentation process was optimised by considering the spectral features and the terrains and corresponding textures obtained from high-resolution images and digital surface models. The feature selection was implemented via correlation analysis, and the optimised segmentation parameter was achieved using the estimation of scale parameter algorithm. Then, a supervised k-nearest neighbourhood classifier was used to identify the terrace damages in the segmented objects, and additional geometric features at the object level were considered for classification. The comparison with the ground truth, as delineated by the image and field survey, showed that proposed classification can be adequately performed. The F-measures of extraction on three terrace damages were 92.07% (terrace sinkhole), 81.95% (ridge sinkhole), and 85.17% (collapse), and the Kappa coefficient was 85.34%. Finally, the potential application and spatial distribution of the terrace damages in this study were determined. We believe that this work can provide a credible framework for mapping terrace damages in the Loess Plateau of China.},
DOI = {10.3390/ijgi10120805}
}



@Article{rs13234875,
AUTHOR = {Acción, Álvaro and Argüello, Francisco and Heras, Dora B.},
TITLE = {A New Multispectral Data Augmentation Technique Based on Data Imputation},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4875},
URL = {https://www.mdpi.com/2072-4292/13/23/4875},
ISSN = {2072-4292},
ABSTRACT = {Deep Learning (DL) has been recently introduced into the hyperspectral and multispectral image classification landscape. Despite the success of DL in the remote sensing field, DL models are computationally intensive due to the large number of parameters they need to learn. The high density of information present in remote sensing imagery with high spectral resolution can make the application of DL models to large scenes challenging. Methods such as patch-based classification require large amounts of data to be processed during the training and prediction stages, which translates into long processing times and high energy consumption. One of the solutions to decrease the computational cost of these models is to perform segment-based classification. Segment-based classification schemes can significantly decrease training and prediction times, and also offer advantages over simply reducing the size of the training datasets by randomly sampling training data. The lack of a large enough number of samples can, however, pose an additional challenge, causing these models to not generalize properly. Data augmentation methods are used to generate new synthetic samples based on existing data to increase the classification performance. In this work, we propose a new data augmentation scheme using data imputation and matrix completion methods for segment-based classification. The proposal has been validated using two high-resolution multispectral datasets from the literature. The results obtained show that the proposed approach successfully increases the classification performance across all the scenes tested and that data imputation methods applied to multispectral imagery are a valid means to perform data augmentation. A comparison of classification accuracy between different imputation methods applied to the proposed scheme was also carried out.},
DOI = {10.3390/rs13234875}
}



@Article{ijgi10120813,
AUTHOR = {de Carvalho, Osmar Luiz Ferreira and de Moura, Rebeca dos Santos and de Albuquerque, Anesmar Olino and de Bem, Pablo Pozzobon and de Castro Pereira, Rubens and Weigang, Li and Borges, Dibio Leandro and Guimarães, Renato Fontes and Gomes, Roberto Arnaldo Trancoso and de Carvalho Júnior, Osmar Abílio},
TITLE = {Instance Segmentation for Governmental Inspection of Small Touristic Infrastructure in Beach Zones Using Multispectral High-Resolution WorldView-3 Imagery},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {813},
URL = {https://www.mdpi.com/2220-9964/10/12/813},
ISSN = {2220-9964},
ABSTRACT = {Misappropriation of public lands is an ongoing government concern. In Brazil, the beach zone is public property, but many private establishments use it for economic purposes, requiring constant inspection. Among the undue targets, the individual mapping of straw beach umbrellas (SBUs) attached to the sand is a great challenge due to their small size, high presence, and agglutinated appearance. This study aims to automatically detect and count SBUs on public beaches using high-resolution images and instance segmentation, obtaining pixel-wise semantic information and individual object detection. This study is the first instance segmentation application on coastal areas and the first using WorldView-3 (WV-3) images. We used the Mask-RCNN with some modifications: (a) multispectral input for the WorldView3 imagery (eight channels), (b) improved the sliding window algorithm for large image classification, and (c) comparison of different image resizing ratios to improve small object detection since the SBUs are small objects (&lt;322 pixels) even using high-resolution images (31 cm). The accuracy analysis used standard COCO metrics considering the original image and three scale ratios (2&times;, 4&times;, and 8&times; resolution increase). The average precision (AP) results increased proportionally to the image resolution: 30.49% (original image), 48.24% (2&times;), 53.45% (4&times;), and 58.11% (8&times;). The 8&times; model presented 94% AP50, classifying nearly all SBUs correctly. Moreover, the improved sliding window approach enables the classification of large areas providing automatic counting and estimating the size of the objects, proving to be effective for inspecting large coastal areas and providing insightful information for public managers. This remote sensing application impacts the inspection cost, tribute, and environmental conditions.},
DOI = {10.3390/ijgi10120813}
}



@Article{buildings11120602,
AUTHOR = {Hammad, Ahmed W. A. and da Costa, Bruno B. F. and Soares, Carlos A. P. and Haddad, Assed N.},
TITLE = {The Use of Unmanned Aerial Vehicles for Dynamic Site Layout Planning in Large-Scale Construction Projects},
JOURNAL = {Buildings},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {602},
URL = {https://www.mdpi.com/2075-5309/11/12/602},
ISSN = {2075-5309},
ABSTRACT = {Construction sites are increasingly complex, and their layout have an impact on productivity, safety, and efficiency of construction operations. Dynamic site layout planning (DSLP) considers the adjustment of construction facilities on-site, on an evolving basis, allowing the relocation of temporary facilities according to the stages of the project. The main objective of this study is to develop a framework for integrating unmanned aerial vehicles (UAVs) and their capacity for effective photogrammetry with site layout planning optimisation and Building Information Modelling (BIM) for automating site layout planning in large construction projects. The mathematical model proposed is based on a mixed integer programming (MIP) model, which was employed to validate the framework on a realistic case study provided by an industry partner. Allocation constraints were formulated to ensure the placement of the facilities in feasible regions. Using information from the UAV, several parameters could be considered, including proximity to access ways, distances between the facilities, and suitability of locations. Based on the proposed framework, a layout was developed for each stage of the project, adapting the location of temporary facilities according to current progress on-site. As a result, the use of space was optimised, and internal transport costs were progressively reduced.},
DOI = {10.3390/buildings11120602}
}



@Article{rs13234880,
AUTHOR = {Chen, Jundong and Sasaki, Jun},
TITLE = {Mapping of Subtidal and Intertidal Seagrass Meadows via Application of the Feature Pyramid Network to Unmanned Aerial Vehicle Orthophotos},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4880},
URL = {https://www.mdpi.com/2072-4292/13/23/4880},
ISSN = {2072-4292},
ABSTRACT = {Seagrass meadows are one of the blue carbon ecosystems that continue to decline worldwide. Frequent mapping is essential to monitor seagrass meadows for understanding change processes including seasonal variations and influences of meteorological and oceanic events such as typhoons and cyclones. Such mapping approaches may also enhance seagrass blue carbon strategy and management practices. Although unmanned aerial vehicle (UAV) aerial photography has been widely conducted for this purpose, there have been challenges in mapping accuracy, efficiency, and applicability to subtidal water meadows. In this study, a novel method was developed for mapping subtidal and intertidal seagrass meadows to overcome such challenges. Ground truth seagrass orthophotos in four seasons were created from the Futtsu tidal flat of Tokyo Bay, Japan, using vertical and oblique UAV photography. The feature pyramid network (FPN) was first applied for automated seagrass classification by adjusting the spatial resolution and normalization parameters and by considering the combinations of seasonal input data sets. The FPN classification results ensured high performance with the validation metrics of 0.957 overall accuracy (OA), 0.895 precision, 0.942 recall, 0.918 F1-score, and 0.848 IoU, which outperformed the conventional U-Net results. The FPN classification results highlighted seasonal variations in seagrass meadows, exhibiting an extension from winter to summer and demonstrating a decline from summer to autumn. Recovery of the meadows was also detected after the occurrence of Typhoon No. 19 in October 2019, a phenomenon which mainly happened before summer 2020.},
DOI = {10.3390/rs13234880}
}



@Article{app112311396,
AUTHOR = {Pal, Mayur and Palevičius, Paulius and Landauskas, Mantas and Orinaitė, Ugnė and Timofejeva, Inga and Ragulskis, Minvydas},
TITLE = {An Overview of Challenges Associated with Automatic Detection of Concrete Cracks in the Presence of Shadows},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {11396},
URL = {https://www.mdpi.com/2076-3417/11/23/11396},
ISSN = {2076-3417},
ABSTRACT = {Detection and assessment of cracks in civil engineering structures such as roads, bridges, dams and pipelines are crucial tasks for maintaining the safety and cost-effectiveness of those concrete structures. With the recent advances in machine learning, the development of ANN- and CNN-based algorithms has become a popular approach for the automated detection and identification of concrete cracks. However, most of the proposed models are trained on images taken in ideal conditions and are only capable of achieving high accuracy when applied to the concrete images devoid of irregular illumination conditions, shadows, shading, blemishes, etc. An overview of challenges related to the automatic detection of concrete cracks in the presence of shadows is presented in this paper. In particular, difficulties associated with the application of deep learning-based methods for the classification of concrete images with shadows are demonstrated. Moreover, the limitations of the shadow removal techniques for the improvement of the crack detection accuracy are discussed.},
DOI = {10.3390/app112311396}
}



@Article{rs13234889,
AUTHOR = {Velasquez-Camacho, Luisa and Cardil, Adrián and Mohan, Midhun and Etxegarai, Maddi and Anzaldi, Gabriel and de-Miguel, Sergio},
TITLE = {Remotely Sensed Tree Characterization in Urban Areas: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4889},
URL = {https://www.mdpi.com/2072-4292/13/23/4889},
ISSN = {2072-4292},
ABSTRACT = {Urban trees and forests provide multiple ecosystem services (ES), including temperature regulation, carbon sequestration, and biodiversity. Interest in ES has increased amongst policymakers, scientists, and citizens given the extent and growth of urbanized areas globally. However, the methods and techniques used to properly assess biodiversity and ES provided by vegetation in urban environments, at large scales, are insufficient. Individual tree identification and characterization are some of the most critical issues used to evaluate urban biodiversity and ES, given the complex spatial distribution of vegetation in urban areas and the scarcity or complete lack of systematized urban tree inventories at large scales, e.g., at the regional or national levels. This often limits our knowledge on their contributions toward shaping biodiversity and ES in urban areas worldwide. This paper provides an analysis of the state-of-the-art studies and was carried out based on a systematic review of 48 scientific papers published during the last five years (2016&ndash;2020), related to urban tree and greenery characterization, remote sensing techniques for tree identification, processing methods, and data analysis to classify and segment trees. In particular, we focused on urban tree and forest characterization using remotely sensed data and identified frontiers in scientific knowledge that may be expanded with new developments in the near future. We found advantages and limitations associated with both data sources and processing methods, from which we drew recommendations for further development of tree inventory and characterization in urban forestry science. Finally, a critical discussion on the current state of the methods, as well as on the challenges and directions for future research, is presented.},
DOI = {10.3390/rs13234889}
}



@Article{engproc2021009030,
AUTHOR = {Kateris, Dimitrios and Kalaitzidis, Damianos and Moysiadis, Vasileios and Tagarakis, Aristotelis C. and Bochtis, Dionysis},
TITLE = {Weed Mapping in Vineyards Using RGB-D Perception},
JOURNAL = {Engineering Proceedings},
VOLUME = {9},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {30},
URL = {https://www.mdpi.com/2673-4591/9/1/30},
ISSN = {2673-4591},
ABSTRACT = {Weed management is one of the major challenges in viticulture, as long as weeds can cause significant yield losses and severe competition to the cultivations. In this direction, the development of an automated procedure for weed monitoring will provide useful data for understanding their management practices. In this work, a new image-based technique was developed in order to provide maps based on weeds&rsquo; height at the inter-row path of the vineyards. The developed algorithms were tested in many datasets from vineyards with different levels of weed development. The results show that the proposed technique gives promising results in various field conditions.},
DOI = {10.3390/engproc2021009030}
}



@Article{agronomy11122458,
AUTHOR = {Crimaldi, Mariano and Cartenì, Fabrizio and Giannino, Francesco},
TITLE = {VISmaF: Synthetic Tree for Immersive Virtual Visualization in Smart Farming. Part I: Scientific Background Review and Model Proposal},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2458},
URL = {https://www.mdpi.com/2073-4395/11/12/2458},
ISSN = {2073-4395},
ABSTRACT = {Computer-Generated Imagery (CGI) has received increasing interest in both research and the entertainment industry. Recent advancements in computer graphics allowed researchers and companies to create large-scale virtual environments with growing resolution and complexity. Among the different applications, the generation of biological assets is a relevant task that implies challenges due to the extreme complexity associated with natural structures. An example is represented by trees, whose composition made by thousands of leaves, branches, branchlets, and stems with oriented directions is hard to be modeled. Realistic 3D models of trees can be exploited for a wide range of applications including decision-making support, visualization of ecosystem changes over time, and for simple visualization purposes. In this review, we give an overview of the most common approaches used to generate 3D tree models, discussing both methodologies and available commercial software. We focus on strategies for modeling and rendering of plants, highlighting their accordance or not with botanical knowledge and biological models. We also present a proof of concept to link biological models and 3D rendering engines through Ordinary Differential Equations.},
DOI = {10.3390/agronomy11122458}
}



@Article{agriculture11121216,
AUTHOR = {Huang, Mingfeng and Xu, Guoqin and Li, Junyu and Huang, Jianping},
TITLE = {A Method for Segmenting Disease Lesions of Maize Leaves in Real Time Using Attention YOLACT++},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1216},
URL = {https://www.mdpi.com/2077-0472/11/12/1216},
ISSN = {2077-0472},
ABSTRACT = {Northern leaf blight (NLB) is a serious disease in maize which leads to significant yield losses. Automatic and accurate methods of quantifying disease are crucial for disease identification and quantitative assessment of severity. Leaf images collected with natural backgrounds pose a great challenge to the segmentation of disease lesions. To address these problems, we propose an image segmentation method based on YOLACT++ with an attention module for segmenting disease lesions of maize leaves in natural conditions in order to improve the accuracy and real-time ability of lesion segmentation. The attention module is equipped on the output of the ResNet-101 backbone and the output of the FPN. The experimental results demonstrate that the proposed method improves segmentation accuracy compared with the state-of-the-art disease lesion-segmentation methods. The proposed method achieved 98.71% maize leaf lesion segmentation precision, a comprehensive evaluation index of 98.36%, and a mean Intersection over Union of 84.91%; the average processing time of a single image was about 31.5 ms. The results show that the proposed method allows for the automatic and accurate quantitative assessment of crop disease severity in natural conditions.},
DOI = {10.3390/agriculture11121216}
}



@Article{ijgi10120817,
AUTHOR = {Ouyang, Zhihong and Xue, Lei and Ding, Feng and Li, Da},
TITLE = {PSOTSC: A Global-Oriented Trajectory Segmentation and Compression Algorithm Based on Swarm Intelligence},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {817},
URL = {https://www.mdpi.com/2220-9964/10/12/817},
ISSN = {2220-9964},
ABSTRACT = {Linear approximate segmentation and data compression of moving target spatio-temporal trajectory can reduce data storage pressure and improve the efficiency of target motion pattern mining. High quality segmentation and compression need to accurately select and store as few points as possible that can reflect the characteristics of the original trajectory, while the existing methods still have room for improvement in segmentation accuracy, reduction of compression rate and simplification of algorithm parameter setting. A trajectory segmentation and compression algorithm based on particle swarm optimization is proposed. First, the trajectory segmentation problem is transformed into a global intelligent optimization problem of segmented feature points, which makes the selection of segmented points more accurate; then, a particle update strategy combining neighborhood adjustment and random jump is established to improve the efficiency of segmentation and compression. Through experiments on a real data set and a maneuvering target simulation trajectory set, the results show that compared with the existing typical methods, this method has advantages in segmentation accuracy and compression rate.},
DOI = {10.3390/ijgi10120817}
}



@Article{s21238081,
AUTHOR = {Jhung, Junekyo and Kim, Shiho},
TITLE = {Behind-The-Scenes (BTS): Wiper-Occlusion Canceling for Advanced Driver Assistance Systems in Adverse Rain Environments},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {8081},
URL = {https://www.mdpi.com/1424-8220/21/23/8081},
PubMedID = {34884085},
ISSN = {1424-8220},
ABSTRACT = {Driving in an adverse rain environment is a crucial challenge for vision-based advanced driver assistance systems (ADAS) in the automotive industry. The vehicle windshield wiper removes adherent raindrops that cause distorted images from in-vehicle frontal view cameras, but, additionally, it causes an occlusion that can hinder visibility at the same time. The wiper-occlusion causes erroneous judgments by vision-based applications and endangers safety. This study proposes behind-the-scenes (BTS) that detects and removes wiper-occlusion in real-time image inputs under rainy weather conditions. The pixel-wise wiper masks are detected by high-pass filtering to predict the optical flow of a sequential image pair. We fine-tuned a deep learning-based optical flow model with a synthesized dataset, which was generated with pseudo-ground truth wiper masks and flows using auto-labeling with acquired real rainy images. A typical optical flow dataset with static synthetic objects is synthesized with real fast-moving objects to enhance data diversity. We annotated wiper masks and scenes as detection ground truths from the collected real images for evaluation. BTS outperforms by achieving a 0.962 SSIM and 91.6% F1 score in wiper mask detection and 88.3% F1 score in wiper image detection. Consequently, BTS enhanced the performance of vision-based image restoration and object detection applications by canceling occlusions and demonstrated it potential role in improving ADAS under rainy weather conditions.},
DOI = {10.3390/s21238081}
}



@Article{math9233117,
AUTHOR = {Herich, Dušan and Vaščák, Ján and Zolotová, Iveta and Brecko, Alexander},
TITLE = {Automatic Path Planning Offloading Mechanism in Edge-Enabled Environments},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {3117},
URL = {https://www.mdpi.com/2227-7390/9/23/3117},
ISSN = {2227-7390},
ABSTRACT = {The utilization of edge-enabled cloud computing in unmanned aerial vehicles has facilitated advances in autonomous control by employing computationally intensive algorithms frequently related to traversal among different locations in an environment. A significant problem remains in designing an effective strategy to offload tasks from the edge to the cloud. This work focuses on creating such a strategy by employing a network evaluation method built on the mean opinion score metrics in concoction with machine learning algorithms for path length prediction to assess computational complexity and classification models to perform an offloading decision on the data provided by both network metrics and solution depth prediction. The proposed system is applied to the A* path planning algorithm, and the presented results demonstrate up to 94% accuracy in offloading decisions.},
DOI = {10.3390/math9233117}
}



@Article{rs13234902,
AUTHOR = {Chen, Guanzhou and Tan, Xiaoliang and Guo, Beibei and Zhu, Kun and Liao, Puyun and Wang, Tong and Wang, Qing and Zhang, Xiaodong},
TITLE = {SDFCNv2: An Improved FCN Framework for Remote Sensing Images Semantic Segmentation},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4902},
URL = {https://www.mdpi.com/2072-4292/13/23/4902},
ISSN = {2072-4292},
ABSTRACT = {Semantic segmentation is a fundamental task in remote sensing image analysis (RSIA). Fully convolutional networks (FCNs) have achieved state-of-the-art performance in the task of semantic segmentation of natural scene images. However, due to distinctive differences between natural scene images and remotely-sensed (RS) images, FCN-based semantic segmentation methods from the field of computer vision cannot achieve promising performances on RS images without modifications. In previous work, we proposed an RS image semantic segmentation framework SDFCNv1, combined with a majority voting postprocessing method. Nevertheless, it still has some drawbacks, such as small receptive field and large number of parameters. In this paper, we propose an improved semantic segmentation framework SDFCNv2 based on SDFCNv1, to conduct optimal semantic segmentation on RS images. We first construct a novel FCN model with hybrid basic convolutional (HBC) blocks and spatial-channel-fusion squeeze-and-excitation (SCFSE) modules, which occupies a larger receptive field and fewer network model parameters. We also put forward a data augmentation method based on spectral-specific stochastic-gamma-transform-based (SSSGT-based) during the model training process to improve generalizability of our model. Besides, we design a mask-weighted voting decision fusion postprocessing algorithm for image segmentation on overlarge RS images. We conducted several comparative experiments on two public datasets and a real surveying and mapping dataset. Extensive experimental results demonstrate that compared with the SDFCNv1 framework, our SDFCNv2 framework can increase the mIoU metric by up to 5.22% while only using about half of parameters.},
DOI = {10.3390/rs13234902}
}



@Article{rs13234903,
AUTHOR = {Niedzielski, Tomasz and Jurecka, Mirosława and Miziński, Bartłomiej and Pawul, Wojciech and Motyl, Tomasz},
TITLE = {First Successful Rescue of a Lost Person Using the Human Detection System: A Case Study from Beskid Niski (SE Poland)},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4903},
URL = {https://www.mdpi.com/2072-4292/13/23/4903},
ISSN = {2072-4292},
ABSTRACT = {Recent advances in search and rescue methods include the use of unmanned aerial vehicles (UAVs), to carry out aerial monitoring of terrains to spot lost individuals. To date, such searches have been conducted by human observers who view UAV-acquired videos or images. Alternatively, lost persons may be detected by automated algorithms. Although some algorithms are implemented in software to support search and rescue activities, no successful rescue case using automated human detectors has been reported on thus far in the scientific literature. This paper presents a report from a search and rescue mission carried out by Bieszczady Mountain Rescue Service near the village of Cergowa in SE Poland, where a 65-year-old man was rescued after being detected via use of SARUAV software. This software uses convolutional neural networks to automatically locate people in close-range nadir aerial images. The missing man, who suffered from Alzheimer&rsquo;s disease (as well as a stroke the previous day) spent more than 24 h in open terrain. SARUAV software was allocated to support the search, and its task was to process 782 nadir and near-nadir JPG images collected during four photogrammetric flights. After 4 h 31 min of the analysis, the system successfully detected the missing person and provided his coordinates (uploading 121 photos from a flight over a lost person; image processing and verification of hits lasted 5 min 48 s). The presented case study proves that the use of an UAV assisted by SARUAV software may quicken the search mission.},
DOI = {10.3390/rs13234903}
}



@Article{rs13234907,
AUTHOR = {Collins, Adam M. and Geheran, Matthew P. and Hesser, Tyler J. and Bak, Andrew Spicer and Brodie, Katherine L. and Farthing, Matthew W.},
TITLE = {Development of a Fully Convolutional Neural Network to Derive Surf-Zone Bathymetry from Close-Range Imagery of Waves in Duck, NC},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4907},
URL = {https://www.mdpi.com/2072-4292/13/23/4907},
ISSN = {2072-4292},
ABSTRACT = {Timely observations of nearshore water depths are important for a variety of coastal research and management topics, yet this information is expensive to collect using in situ survey methods. Remote methods to estimate bathymetry from imagery include using either ratios of multi-spectral reflectance bands or inversions from wave processes. Multi-spectral methods work best in waters with low turbidity, and wave-speed-based methods work best when wave breaking is minimal. In this work, we build on the wave-based inversion approaches, by exploring the use of a fully convolutional neural network (FCNN) to infer nearshore bathymetry from imagery of the sea surface and local wave statistics. We apply transfer learning to adapt a CNN originally trained on synthetic imagery generated from a Boussinesq numerical wave model to utilize tower-based imagery collected in Duck, North Carolina, at the U.S. Army Engineer Research and Development Center&rsquo;s Field Research Facility. We train the model on sea-surface imagery, wave conditions, and associated surveyed bathymetry using three years of observations, including times with significant wave breaking in the surf zone. This is the first time, to the authors&rsquo; knowledge, an FCNN has been successfully applied to infer bathymetry from surf-zone sea-surface imagery. Model results from a separate one-year test period generally show good agreement with survey-derived bathymetry (0.37 m root-mean-squared error, with a max depth of 6.7 m) under diverse wave conditions with wave heights up to 3.5 m. Bathymetry results quantify nearshore bathymetric evolution including bar migration and transitions between single- and double-barred morphologies. We observe that bathymetry estimates are most accurate when time-averaged input images feature visible wave breaking and/or individual images display wave crests. An investigation of activation maps, which show neuron activity on a layer-by-layer basis, suggests that the model is responsive to visible coherent wave structures in the input images.},
DOI = {10.3390/rs13234907}
}



@Article{agronomy11122465,
AUTHOR = {Lai, Joon-Keat and Lin, Wen-Shin},
TITLE = {Real-Time Detection of Rice Growth Phase Transition for Panicle Nitrogen Application Timing Assessment},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2465},
URL = {https://www.mdpi.com/2073-4395/11/12/2465},
ISSN = {2073-4395},
ABSTRACT = {Nitrogen (N) topdressing at the early reproductive phase (ER) is beneficial for rice yield. However, the ER overlaps with the late vegetative phase (LV) and is, thus, difficult to be recognized by human observation. Therefore, this study aimed to establish a high-temporal-resolution approach to determine the LV and ER via hyperspectral proximal sensing. Firstly, this research measured the leaf cover area (LCA), leaf dry weight (LDW), chlorophyll content (SPAD), leaf N content (LNC), and leaf N accumulation (LNA) to investigate the physical and physiological changes of the rice plant during growth phase transition. It could be summarized that the LCA would be maximally extended before ER, the leaf growth would be retarded after LV, and leaves turned from green to yellowish-green resulting from N translocation. These phenomena were expected to be detected by the hyperspectral sensor. In order to capture the variation of spectral information while eliminating redundant hyperspectral wavelengths, feature extraction (FE) and feature selection (FS) were conducted to reduce the data dimension. Meanwhile, the implications of the features were also inferenced. Three principal components, which correlated with the rice plant&rsquo;s physical and physiological traits, were extracted for subsequent modeling. On the aspect of FS, 402, 432, 579, and 696 nm were selected as the predictors. The 402 nm wavelength significantly correlated with leaf cover area to some extent (p &lt; 0.09), and 432 nm had no significant correlation with all of the measured plant traits (p &gt; 0.10). The 579 nm and 696 nm wavelengths were negatively correlated with SPAD and LNC (p &lt; 0.001). In addition, 696 nm was also negatively correlated with LNA (p &lt; 0.05). Finally, the logistic regression, random forest (RF), and support vector machine (SVM) algorithms were adopted to solve the binary classification problem. The result showed that the feature extraction-based logistic regression (FE-logistic) and support vector machine (FE-SVM) were competent for growth phase discrimination (accuracy &gt; 0.80). Nonetheless, taking the detrimental effects of applying N at LV into consideration, the feature extraction-based support vector machine (FE-SVM) was more appropriate for the timing assessment of panicle fertilizer application (sensitivity &gt; 0.90; specificity &gt; 0.80; precision &gt; 0.80).},
DOI = {10.3390/agronomy11122465}
}



@Article{geosciences11120495,
AUTHOR = {Harmouzi, Hasnaa and Schlögel, Romy and Jurchescu, Marta and Havenith, Hans-Balder},
TITLE = {Landslide Susceptibility Mapping in the Vrancea-Buz&#259;u Seismic Region, Southeast Romania},
JOURNAL = {Geosciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {495},
URL = {https://www.mdpi.com/2076-3263/11/12/495},
ISSN = {2076-3263},
ABSTRACT = {This study presents the results of a landslide susceptibility analysis applied to the Vrancea-Buz&#259;u seismogenic region in the Carpathian Mountains, Romania. The target area is affected by a large diversity of landslide processes. Slopes are made-up of various types of rocks, climatic conditions can be classified as wet, and the area is a seismically active one. All this contributes to the observed high landslide hazard. The paper analyses the spatial component of the landslide hazard affecting the target area, the regional landslide susceptibility. First, an existing landslide inventory was completed to cover a wider area for the landslide susceptibility analysis. Second, two types of methods are applied, a purely statistical technique, based on correlations between landslide occurrence and local conditions, as well as the simplified spatial process-based Newmark Displacement analysis. Landslide susceptibility maps have been produced by applying both methods, the second one also allowing us to simulate different scenarios, based on various soil saturation rates and seismic inputs. Furthermore, landslide susceptibility was computed both for the landslide source and runout zones&mdash;the first providing information about areas where landslides are preferentially triggered and the second indicating where landslides preferentially move along the slope and accumulate. The analysis showed that any of the different methods applied produces reliable maps of landslide susceptibility. However, uncertainties were also outlined as validation is insufficient, especially in the northern area, where only a few landslides could be mapped due to the intense vegetation cover.},
DOI = {10.3390/geosciences11120495}
}



@Article{rs13234912,
AUTHOR = {Yu, Yang and Ma, Yong and Mei, Xiaoguang and Fan, Fan and Huang, Jun and Ma, Jiayi},
TITLE = {A Spatial-Spectral Feature Descriptor for Hyperspectral Image Matching},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4912},
URL = {https://www.mdpi.com/2072-4292/13/23/4912},
ISSN = {2072-4292},
ABSTRACT = {Hyperspectral Images (HSIs) have been utilized in many fields which contain spatial and spectral features of objects simultaneously. Hyperspectral image matching is a fundamental and critical problem in a wide range of HSI applications. Feature descriptors for grayscale image matching are well studied, but few descriptors are elaborately designed for HSI matching. HSI descriptors, which should have made good use of the spectral feature, are essential in HSI matching tasks. Therefore, this paper presents a descriptor for HSI matching, called HOSG-SIFT, which ensembles spectral features with spatial features of objects. First, we obtain the grayscale image by dimensional reduction from HSI and apply it to extract keypoints and descriptors of spatial features. Second, the descriptors of spectral features are designed based on the histogram of the spectral gradient (HOSG), which effectively preserves the physical significance of the spectral profile. Third, we concatenate the spatial descriptors and spectral descriptors with the same weights into a new descriptor and apply it for HSI matching. Experimental results demonstrate that the proposed HOSG-SIFT performs superior against traditional feature descriptors.},
DOI = {10.3390/rs13234912}
}



@Article{f12121697,
AUTHOR = {Li, Hui and Hu, Baoxin and Li, Qian and Jing, Linhai},
TITLE = {CNN-Based Individual Tree Species Classification Using High-Resolution Satellite Imagery and Airborne LiDAR Data},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1697},
URL = {https://www.mdpi.com/1999-4907/12/12/1697},
ISSN = {1999-4907},
ABSTRACT = {Deep learning (DL) has shown promising performances in various remote sensing applications as a powerful tool. To explore the great potential of DL in improving the accuracy of individual tree species (ITS) classification, four convolutional neural network models (ResNet-18, ResNet-34, ResNet-50, and DenseNet-40) were employed to classify four tree species using the combined high-resolution satellite imagery and airborne LiDAR data. A total of 1503 samples of four tree species, including maple, pine, locust, and spruce, were used in the experiments. When both WorldView-2 and airborne LiDAR data were used, the overall accuracies (OA) obtained by ResNet-18, ResNet-34, ResNet-50, and DenseNet-40 were 90.9%, 89.1%, 89.1%, and 86.9%, respectively. The OA of ResNet-18 was increased by 4.0% and 1.8% compared with random forest (86.7%) and support vector machine (89.1%), respectively. The experimental results demonstrated that the size of input images impacted on the classification accuracy of ResNet-18. It is suggested that the input size of ResNet models can be determined according to the maximum size of all tree crown sample images. The use of LiDAR intensity image was helpful in improving the accuracies of ITS classification and atmospheric correction is unnecessary when both pansharpened WorldView-2 images and airborne LiDAR data were used.},
DOI = {10.3390/f12121697}
}




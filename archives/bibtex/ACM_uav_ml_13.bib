@inproceedings{10.1145/3399205.3399224,
author = {Youssef, Rissouni and Aniss, Moumen and Jamal, Chao},
title = {Machine Learning and Deep Learning in Remote Sensing and Urban Application: A Systematic Review and Meta-Analysis},
year = {2020},
isbn = {9781450375788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3399205.3399224},
doi = {10.1145/3399205.3399224},
abstract = {Machine learning (ML) and the latest deep learning (DL) algorithms have been widely used lately in remotely sensed data analysis. Urban management has also made such developments in artificial intelligence (AI) techniques, but not with the same degree of commitment as another major, mainly because machine learning and deep learning are still considered to be complex and consuming in terms of material resources, and data. Nevertheless, ML and DL could be more effective, especially in the development of management strategies and new scenarios. In this paper, we present a literature review of selected studies, including a statistical review of 188 articles that applied ML and DL to remote sensing and urban applications between 1994 and 2020. This review represents practically a comprehensive coverage of applications and technologies in this field, from data preparation to results mapping.},
booktitle = {Proceedings of the 4th Edition of International Conference on Geo-IT and Water Resources 2020, Geo-IT and Water Resources 2020},
articleno = {18},
numpages = {5},
keywords = {Remote Sensing, Urban applications, Deep Learning, Machine learning},
location = {Al-Hoceima, Morocco},
series = {GEOIT4W-2020}
}

@inbook{10.1145/3384419.3430459,
author = {Harada, Koji and Arai, Ismail and Kashihara, Shigeru and Fujikawa, Kazutoshi},
title = {A Performance Investigation of Thermal Infrared Camera and Optical Camera for Searching Victims with an Unmanned Aerial Vehicle: Poster Abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3384419.3430459},
abstract = {In search and rescue (SAR) operation, the potential of Unmanned Aerial Vehicles (UAVs) gathers great attention. Existing studies have made various experiments to find victims by a UAVs with a single sensor, e.g., one of an optical camera, a thermal infrared camera, and a radio wave signal. However, the experimental environments are limited to show the performance of the sensor. Since there are various SAR missions, it is difficult to choose the best sensor for all environments. Then, to enhance the UAV performance, we need to consider multiple sensors to find a victim efficiently. In the paper, we investigate optical camera and thermal infrared camera for finding a victim helpfully. In the investigation, we observed the differences between their images by distance and brightness to find a human.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {647–648},
numpages = {2}
}

@inproceedings{10.1145/3386415.3387080,
author = {Song, Qiang and Wu, Yonghuan and Liu, Zhenlan},
title = {An Overview of Deep Learning in Power Production},
year = {2019},
isbn = {9781450372930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3386415.3387080},
doi = {10.1145/3386415.3387080},
abstract = {With the deepening of global information and rapid development of technology, the public pay more attention to the value of massive data and constantly explore the internal relationship between data. The researchers try to serve economic and people's life with data. As a national basic industry, electric power plays an important role in economic and social development. Under the background of energy conservation and emission reduction policies, we are badly need to mine data value of electric power to improve the stability of electric power operation. This paper focuses on the combination of deep learning with power production, introduces the current research progress of deep learning and the scenario of deep learning in electric power. Based on the findings, this paper has proposed some future research directions.},
booktitle = {Proceedings of the 2nd International Conference on Information Technologies and Electrical Engineering},
articleno = {133},
numpages = {4},
keywords = {Load forecasting, Image recognition, Deep learning, Power production},
location = {Zhuzhou, Hunan, China},
series = {ICITEE-2019}
}

@inbook{10.1145/3468218.3469049,
author = {Pawlak, Jered and Li, Yuchen and Price, Joshua and Wright, Matthew and Al Shamaileh, Khair and Niyaz, Quamar and Devabhaktuni, Vijay},
title = {A Machine Learning Approach for Detecting and Classifying Jamming Attacks Against OFDM-Based UAVs},
year = {2021},
isbn = {9781450385619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3468218.3469049},
abstract = {In this paper, a machine learning (ML) approach is proposed to detect and classify jamming attacks on unmanned aerial vehicles (UAVs). Four attack types are implemented using software-defined radio (SDR); namely, barrage, single-tone, successive-pulse, and protocol-aware jamming. Each type is launched against a drone that uses orthogonal frequency division multiplexing (OFDM) communication to qualitatively analyze its impacts considering jamming range, complexity, and severity. Then, an SDR is utilized in proximity to the drone and in systematic testing scenarios to record the radiometric parameters before and after each attack is launched. Signal-to-noise ratio (SNR), energy threshold, and several OFDM parameters are exploited as features and fed to six ML algorithms to explore and enable autonomous jamming detection/classification. The algorithms are quantitatively evaluated with metrics including detection and false alarm rates to evaluate the received signals and facilitate efficient decision-making for improved reception integrity and reliability. The resulting ML approach detects and classifies jamming with an accuracy of 92.2% and a false-alarm rate of 1.35%.},
booktitle = {Proceedings of the 3rd ACM Workshop on Wireless Security and Machine Learning},
pages = {1–6},
numpages = {6}
}

@inproceedings{10.1145/3131672.3136986,
author = {Amarasinghe, Akarshani and Suduwella, Chathura and Elvitigala, Charith and Niroshan, Lasith and Amaraweera, Rangana Jayashanka and Gunawardana, Kasun and Kumarasinghe, Prabash and De Zoysa, Kasun and Keppetiyagama, Chamath},
title = {A Machine Learning Approach for Identifying Mosquito Breeding Sites via Drone Images},
year = {2017},
isbn = {9781450354592},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3131672.3136986},
doi = {10.1145/3131672.3136986},
abstract = {Dengue is one of the deadly and fast spreading diseases in Sri Lanka. The female Aedes mosquito is the dengue vector and these mosquitoes breed in clear and non-flowing water. The Public Health Inspectors (PHIs) are tasked with detecting and eliminating such water collection areas.However, they face the problem of detecting potential breeding sites in hard-to-reach areas. With the technological development, the drones come as one of the most cost effective unmanned vehicles to access the places that a man cannot access.This paper presents a novel approach for identifying mosquito breeding areas via drone images through the distinct coloration of those areas by applying the Histogram of Oriented Gradients (HOG) algorithm. Using the HOG algorithm, we detect potential water retention areas using drone images.},
booktitle = {Proceedings of the 15th ACM Conference on Embedded Network Sensor Systems},
articleno = {68},
numpages = {2},
keywords = {Mosquito Breeding Sites, Drone Systems, Dengue},
location = {Delft, Netherlands},
series = {SenSys '17}
}

@inproceedings{10.1145/3460426.3463666,
author = {Akhyar, Fityanul and Lin, Chih-Yang and Kathiresan, Gugan S.},
title = {A Beneficial Dual Transformation Approach for Deep Learning Networks Used in Steel Surface Defect Detection},
year = {2021},
isbn = {9781450384636},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3460426.3463666},
doi = {10.1145/3460426.3463666},
abstract = {Steel surface defect detection represents a challenging task in real-world practical object detection. Based on our observations, there are two critical problems which create this challenge: the tiny size, and vagueness of the defects. To solve these problems, this study a proposes a deep learning-based defect detection system that uses automatic dual transformation in the end-to-end network. First, the original training images in RGB are transformed into the HSV color model to re-arrange the difference in color distribution. Second, the feature maps are upsampled using bilinear interpolation to maintain the smaller resolution. The latest and state-of-the-art object detection model, High-Resolution Network (HRNet) is utilized in this system, with initial transformation performed via data augmentation. Afterward, the output of the backbone stage is applied to the second transformation. According to the experimental results, the proposed approach increases the accuracy of the detection of class 1 Severstal steel surface defects by 3.6% versus the baseline.},
booktitle = {Proceedings of the 2021 International Conference on Multimedia Retrieval},
pages = {619–622},
numpages = {4},
keywords = {RGB to HSV, bilinear interpolation, high-resolution network, defect detection system},
location = {Taipei, Taiwan},
series = {ICMR '21}
}

@inproceedings{10.1145/3369457.3369509,
author = {Lochner, Martin and Duenser, Andreas and Sarker, Shouvojit},
title = {Trust and Cognitive Load in Semi-Automated UAV Operation},
year = {2019},
isbn = {9781450376969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3369457.3369509},
doi = {10.1145/3369457.3369509},
abstract = {Trust in automation is an essential precursor to system adoption and use. Given the emerging wave of autonomous systems available for public consumption and the resources devoted to this trend, it's important to understand trust, and how to measure it. Further, the level of performance demonstrated by a system can affect trust in that system. As such, proper design of an autonomous system can be facilitated by measuring trust in such systems. Rather than relying only on traditional methods of measuring trust, such as pen and paper, or behavioural markers, this work extends previous research by investigating psycho-physiological markers for trust, using Galvanic Skin Response (GSR) and machine learning. We induced high vs. low trust states in amateur unmanned aerial vehicle (UAV) operators, and manipulated the automation level of the UAV. We collected workload and trust ratings during and after flying a UAV. Despite moderate results with traditional metrics (NASA TLX, and the System Trust Scale), we were able to classify trust states based on the GSR data with 80% accuracy. This research forms part of our ongoing work on developing a model for the relation between automation, and user trust and cognitive load.},
booktitle = {Proceedings of the 31st Australian Conference on Human-Computer-Interaction},
pages = {437–441},
numpages = {5},
keywords = {autonomous systems, cognitive load, automation, Trust, UAV, GSR, psycho-physiology, galvanic skin response},
location = {Fremantle, WA, Australia},
series = {OZCHI'19}
}

@inbook{10.1145/3324884.3418908,
author = {Gao, Han and Xu, Yi and Liu, Xiao and Xu, Jia and Chen, Tianxiang and Zhou, Bowen and Li, Rui and Li, Xuejun},
title = {Edge4Sys: A Device-Edge Collaborative Framework for MEC Based Smart Systems},
year = {2020},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3324884.3418908},
abstract = {At present, most of the smart systems are based on cloud computing, and massive data generated at the smart end device will need to be transferred to the cloud where AI models are deployed. Therefore, a big challenge for smart system engineers is that cloud based smart systems often face issues such as network congestion and high latency. In recent years, mobile edge computing (MEC) is becoming a promising solution which supports computation-intensive tasks such as deep learning through computation offloading to the servers located at the local network edge. To take full advantage of MEC, an effective collaboration between the end device and the edge server is essential. In this paper, as an initial investigation, we propose Edge4Sys, a Device-Edge Collaborative Framework for MEC based Smart System. Specifically, we employ the deep learning based user identification process in a MEC-based UAV (Unmanned Aerial Vehicle) delivery system as a case study to demonstrate the effectiveness of the proposed framework which can significantly reduce the network traffic and the response time.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1252–1254},
numpages = {3}
}

@inbook{10.1145/3474085.3477934,
author = {Liao, Yuqing and Li, Xinke and Tong, Zekun and Zhao, Yabang and Lim, Andrew and Kuang, Zhenzhong and Midoglu, Cise},
title = {Reproducibility Companion Paper: Campus3D: A Photogrammetry Point Cloud Benchmark for Outdoor Scene Hierarchical Understanding},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3474085.3477934},
abstract = {This companion paper is to support the replication of paper "Campus3D: A Photogrammetry Point Cloud Benchmark for Outdoor Scene Hierarchical Understanding", which was presented at ACM Multimedia 2020. The supported paper's main purpose was to provide a photogrammetry point cloud-based dataset with hierarchical multilabels to facilitate the area of 3D deep learning. Based on this provided dataset and source code, in this work, we build a complete package to reimplement the proposed methods and experiments (i.e., the hierarchical learning framework and the benchmarks of the hierarchical semantic segmentation task). Specifically, this paper contains the technical details of the package, including file structure, dataset preparation, installation package, and the conduction of the experiment. We also present the replicated experiment results and indicate our contributions to the original implementation.},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {3610–3614},
numpages = {5}
}

@inproceedings{10.1145/3356395.3365671,
author = {Klerings, Alina and Tang, Shiming and Chen, ZhiQiang},
title = {Structuralizing Disaster-Scene Data through Auto-Captioning},
year = {2019},
isbn = {9781450369541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3356395.3365671},
doi = {10.1145/3356395.3365671},
abstract = {Disaster-scene images documenting the magnitude and effects of natural disasters nowadays can be easily collected through crowdsourcing aided by mobile technologies (e.g., smartphones or drones). One challenging issue that confronts the first-responders who desire the use of such data is the non-structured nature of these crowdsourced images. Among other techniques, one natural way is to structuralize disaster-scene images through captioning. Through captioning, their imagery contents are augmented by descriptive captions that further enable more effective search and query (S&amp;Q). This work presents a preliminary test by exploiting an end-to-end deep learning framework with a linked CNN-LSTM architecture. Demonstration of the results and quantitative evaluation are presented that showcase the validity of the proposed concept.},
booktitle = {Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Advances on Resilient and Intelligent Cities},
pages = {29–32},
numpages = {4},
keywords = {Autonomous caption, Disaster resilience, Disaster scenes, Deep learning},
location = {Chicago, IL, USA},
series = {ARIC'19}
}

@inbook{10.1145/3324884.3415294,
author = {Xu, Jia and Liu, Xiao and Li, Xuejun and Zhang, Lei and Yang, Yun},
title = {EXPRESS: An Energy-Efficient and Secure Framework for Mobile Edge Computing and Blockchain Based Smart Systems},
year = {2020},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3324884.3415294},
abstract = {As most smart systems such as smart logistic and smart manufacturing are delay sensitive, the current mainstream cloud computing based system architecture is facing the critical issue of high latency over the Internet. Meanwhile, as huge amount of data is generated by smart devices with limited battery and computing power, the increasing demand for energy-efficient machine learning and secure data communication at the network edge has become a hurdle to the success of smart systems. To address these challenges with using smart UAV (Unmanned Aerial Vehicle) delivery system as an example, we propose EXPRESS, a novel energy-efficient and secure framework based on mobile edge computing and blockchain technologies. We focus on computation and data (resource) management which are two of the most prominent components in this framework. The effectiveness of the EXPRESS framework is demonstrated through the implementation of a real-world UAV delivery system. As an open-source framework, EXPRESS can help researchers implement their own prototypes and test their computation and data management strategies in different smart systems. The demo video can be found at https://youtu.be/r3U1iU8tSmk.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1283–1286},
numpages = {4}
}

@inproceedings{10.1145/3283207.3283211,
author = {Huang, Hai and Burger, Patrick and Schmitz, Matthias and Roth, Lukas and W\"{u}nsche, Hans-Joachim and Mayer, Helmut},
title = {Driving in Unknown Areas: From UAV Images to Map for Autonomous Vehicles},
year = {2018},
isbn = {9781450360371},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3283207.3283211},
doi = {10.1145/3283207.3283211},
abstract = {Along with the rapid development of autonomous vehicles and driving assistance systems, suitable maps have been intensively studied in recent years. Besides the improvement of conventional maps, new types such as high-density (HD) maps, have been introduced to provide comprehensive detailed information particularly for autonomous driving. In the areas which are not or not well covered by these maps, however, the autonomous vehicles are basically on their own. I.e., besides GNSS signals, they have to rely solely on the onboard sensors with local measurements. In this paper, we present an alternative pipeline for map generation from UAV imagery. A map particularly suitable for autonomous driving is derived from the 3D scene reconstructed from high-resolution images. In addition to basic geometry and semantic features, the map contains abstract vertical landmarks for fast and accurate positioning and path planning, elevation as well as slope information for driving, and trafficability information for different types of vehicles in off-road areas. The potential of the proposed approach is demonstrated based on the results of an experiment.},
booktitle = {Proceedings of the 11th ACM SIGSPATIAL International Workshop on Computational Transportation Science},
pages = {39–42},
numpages = {4},
keywords = {OSM, Scene analysis, Map construction, Autonomous driving, 3D reconstruction},
location = {Seattle, WA, USA},
series = {IWCTS'18}
}

@inproceedings{10.1145/3428757.3429149,
author = {Binlashram, Arwa and Bouricha, Hajer and Hsairi, Lobna and Al Ahmadi, Haneen},
title = {A New Multi-Agents System Based on Blockchain for Prediction Anomaly from System Logs},
year = {2020},
isbn = {9781450389228},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3428757.3429149},
doi = {10.1145/3428757.3429149},
abstract = {The execution traces generated by an application contain information that the developers believed would be useful in debugging or monitoring the application, it contains application states and significant events at various critical points that help them gain insight into failures and identify and predict potential problems before they occur. Despite the ubiquity of these traces universally in almost all computer systems, they are rarely exploited because they are not readily machine-parsable. In this paper, we propose a Multi-Agents approach for prediction process using Blockchain technology, which allows automatically analysis of execution traces and detects early warning signals for system failure prediction during executing. The proposed prediction approach is constructed using a four-layer Multi-Agents system architecture. The proposed prediction approach performance is based on data prepossessing and supervised learning algorithms for prediction. Blockchain was used to coordinate collaboration between agents, and to synchronize prediction between agents and the administrators. We validated our approach by applying it to real-world distributed systems, where we predicted problems before they occurred with high accuracy. In this paper we will focus on the Architecture of our prediction approach.},
booktitle = {Proceedings of the 22nd International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {467–471},
numpages = {5},
keywords = {Execution traces, Blockchain technology, Prediction, Agents, Multi-Agents system, Machine learning},
location = {Chiang Mai, Thailand},
series = {iiWAS '20}
}

@inproceedings{10.1145/3469877.3490574,
author = {Zhang, Hao and Zhang, Qi and Nguyen, Phuong Anh and Lee, Victor C. S. and Chan, Antoni},
title = {Chinese White Dolphin Detection in the Wild},
year = {2021},
isbn = {9781450386074},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3469877.3490574},
doi = {10.1145/3469877.3490574},
abstract = {For ecological protection of the ocean, biologists usually conduct line-transect vessel surveys to measure sea species’ population density within their habitat (such as dolphins). However, sea species observation via vessel surveys consumes a lot of manpower resources and is more challenging compared to observing common objects, due to the scarcity of the object in the wild, tiny-size of the objects, and similar-sized distracter objects (e.g., floating trash). To reduce the human experts’ workload and improve the observation accuracy, in this paper, we develop a practical system to detect Chinese White Dolphins in the wild automatically. First, we construct a dataset named Dolphin-14k with more than 2.6k dolphin instances. To improve the dataset annotation efficiency caused by the rarity of dolphins, we design an interactive dolphin box annotation strategy to annotate sparse dolphin instances in long videos efficiently. Second, we compare the performance and efficiency of three off-the-shelf object detection algorithms, including Faster-RCNN, FCOS, and YoloV5, on the Dolphin-14k dataset and pick YoloV5 as the detector, where a new category (Distracter) is added to the model training to reject the false positives. Finally, we incorporate the dolphin detector into a system prototype, which detects dolphins in video frames at 100.99 FPS per GPU with high accuracy (i.e., 90.95 mAP@0.5). },
booktitle = {ACM Multimedia Asia},
articleno = {44},
numpages = {5},
keywords = {detection system, datasets, neural networks, dolphin detection},
location = {Gold Coast, Australia},
series = {MMAsia '21}
}

@inproceedings{10.1145/3056540.3076204,
author = {Bakalos, Nikolaos G. and Bonazountas, Marc and Tsiakos, Valantis and Hadjipanos, Vasilis},
title = {Providing Certified Paths for Safe Port Operation: The e-Mariner Paradigm},
year = {2017},
isbn = {9781450352277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3056540.3076204},
doi = {10.1145/3056540.3076204},
abstract = {In this paper we describe a system that utilizes supervised machine learning over GNSS PVT data to produce "safe" paths for maritime port operations. By using meta-knowledge describing the behavior of mobile objects based on specific criteria, and also extend this to address sections of trajectories, we aim at certifying},
booktitle = {Proceedings of the 10th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {331–334},
numpages = {4},
keywords = {supervised machine learning safe port operations, classification of EGNSS data, Safe paths, maritime ITS, maritime port operations},
location = {Island of Rhodes, Greece},
series = {PETRA '17}
}

@inproceedings{10.1145/3469877.3493698,
author = {Ghandeharizadeh, Shahram},
title = {Holodeck: Immersive 3D Displays Using Swarms of Flying Light Specks [Extended Abstract]},
year = {2021},
isbn = {9781450386074},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3469877.3493698},
doi = {10.1145/3469877.3493698},
abstract = { Unmanned Aerial Vehicles (UAVs) have moved beyond a platform for hobbyists to enable environmental monitoring, journalism, film industry, search and rescue, package delivery, and entertainment. This paper describes 3D displays using swarms of flying light specks, FLSs. An FLS is a small (hundreds of micrometers in size) UAV with one or more light sources to generate different colors and textures with adjustable brightness. A synchronized swarm of FLSs renders an illumination in a pre-specified 3D volume, an FLS display. An FLS display provides true depth, enabling a user to perceive a scene more completely by analyzing its illumination from different angles. An FLS display may either be non-immersive or immersive. Both will support 3D acoustics. Non-immersive FLS displays may be the size of a 1980’s computer monitor, enabling a surgical team to observe and control micro robots performing heart surgery inside a patient’s body. Immersive FLS displays may be the size of a room, enabling users to interact with objects, e.g., a rock, a teapot. An object with behavior will be constructed using FLS-matters. FLS-matter will enable a user to touch and manipulate an object, e.g., a user may pick up a teapot or throw a rock. An immersive and interactive FLS display will approximate Star Trek’s holodeck. A successful realization of the research ideas presented in this paper will provide fundamental insights into implementing a holodeck using swarms of FLSs. A holodeck will transform the future of human communication and perception, and how we interact with information and data. It will revolutionize the future of how we work, learn, play and entertain, receive medical care, and socialize.},
booktitle = {ACM Multimedia Asia},
articleno = {67},
numpages = {7},
location = {Gold Coast, Australia},
series = {MMAsia '21}
}

@inproceedings{10.1145/3396864.3399704,
author = {Flores, Huber and Zuniga, Agustin and Motlagh, Naser Hossein and Liyanage, Mohan and Passananti, Monica and Tarkoma, Sasu and Youssef, Moustafa and Nurmi, Petteri},
title = {PENGUIN: Aquatic Plastic Pollution Sensing Using AUVs},
year = {2020},
isbn = {9781450380102},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3396864.3399704},
doi = {10.1145/3396864.3399704},
abstract = {Underwater plastic pollution is a significant global concern, affecting everything from marine ecosystems to climate change and even human health. Currently, obtaining accurate information about aquatic plastic pollutants at high spatial and temporal resolution is difficult as existing methods are laborious (e.g., dive surveys), restricted to a subset of plastics (e.g., aerial imaging for floating debris), have limited resolution (e.g., beach surveys), or are unsuited for aquatic environments (e.g., wireless sensing or Fourier-transform infrared spectroscopy). We propose PENGUIN, a work-in-progress AUV-based solution for identifying and classifying aquatic plastic pollutants. PENGUIN has been designed as the first system that can both recognize pollutants and classify them according to specifics of the material. We present the overall design of PENGUIN, introducing the different components of the architecture, and presenting current status of development. We also present results of plastic classification experiments using optical sensing, demonstrating that simple PPG sensors provide a low-cost and energy-efficient solution for classifying different plastics. Our solution can easily monitor larger underwater areas than what current techniques offer while at the same time capturing a wider range of pollutants.},
booktitle = {Proceedings of the 6th ACM Workshop on Micro Aerial Vehicle Networks, Systems, and Applications},
articleno = {5},
numpages = {6},
keywords = {autonomous underwater vehicles, plastic detection, marine pollution, pervasive sensing, AUV, plastic pollution, plastic classification, multi-drone, UAV, unmanned vehicles},
location = {Toronto, Ontario, Canada},
series = {DroNet '20}
}

@inbook{10.1145/3382507.3418861,
author = {Katsakioris, Miltiadis Marios and Konstas, Ioannis and Mignotte, Pierre Yves and Hastie, Helen},
title = {ROSMI: A Multimodal Corpus for Map-Based Instruction-Giving},
year = {2020},
isbn = {9781450375818},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3382507.3418861},
abstract = {We present the publicly-available Robot Open Street Map Instructions (ROSMI) corpus: a rich multimodal dataset of map and natural language instruction pairs that was collected via crowdsourcing. The goal of this corpus is to aid in the advancement of state-of-the-art visual-dialogue tasks, including reference resolution and robot-instruction understanding. The domain described here concerns robots and autonomous systems being used for inspection and emergency response. The ROSMI corpus is unique in that it captures interaction grounded in map-based visual stimuli that is both human-readable but also contains rich metadata that is needed to plan and deploy robots and autonomous systems, thus facilitating human-robot teaming.},
booktitle = {Proceedings of the 2020 International Conference on Multimodal Interaction},
pages = {680–684},
numpages = {5}
}

@inproceedings{10.1145/3356999.3365468,
author = {Vatsavai, Ranga Raju and Ramachandra, Bharathkumar and Chen, Zexi and Jernigan, John},
title = {GeoEdge: A Real-Time Analytics Framework for Geospatial Applications},
year = {2019},
isbn = {9781450369664},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3356999.3365468},
doi = {10.1145/3356999.3365468},
abstract = {In many real-world applications, data looses its value if its not analyzed in real-time. Examples include natural disasters, crop disease identification and bioterrorism, traffic monitoring, monitoring human activities and public places, gas pipeline monitoring for leaks. Edge computing refers to pushing computing power to the edge of the network or bringing it closer to the sensors. We envision that an integrated framework (sensors + edge computers + analytics) allows near realtime analytics at the edge, which is critical for first responders to national security agencies alike. In addition to the generation of real-time actionable knowledge, edge computing allows compressing/reducing big geospatial data that need to be transmitted to centralized cloud or data centers. In this study, we present the vision behind geoEdge, and show feasibility results using feature extraction and unsupervised learning on an edge computing device.},
booktitle = {Proceedings of the 8th ACM SIGSPATIAL International Workshop on Analytics for Big Geospatial Data},
articleno = {2},
numpages = {4},
keywords = {remote sensing, real-time actionable knowledge, edge computing},
location = {Chicago, Illinois},
series = {BigSpatial '19}
}

@inproceedings{10.1145/2996913.2996931,
author = {Wiener, Patrick and Stein, Manuel and Seebacher, Daniel and Bruns, Julian and Frank, Matthias and Simko, Viliam and Zander, Stefan and Nimis, Jens},
title = {BigGIS: A Continuous Refinement Approach to Master Heterogeneity and Uncertainty in Spatio-Temporal Big Data (Vision Paper)},
year = {2016},
isbn = {9781450345897},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2996913.2996931},
doi = {10.1145/2996913.2996931},
abstract = {Geographic information systems (GIS) are important for decision support based on spatial data. Due to technical and economical progress an ever increasing number of data sources are available leading to a rapidly growing fast and unreliable amount of data that can be beneficial (1) in the approximation of multivariate and causal predictions of future values as well as (2) in robust and proactive decision-making processes. However, today's GIS are not designed for such big data demands and require new methodologies to effectively model uncertainty and generate meaningful knowledge. As a consequence, we introduce BigGIS, a predictive and prescriptive spatio-temporal analytics platform, that symbiotically combines big data analytics, semantic web technologies and visual analytics methodologies. We present a novel continuous refinement model and show future challenges as an intermediate result of a collaborative research project into big data methodologies for spatio-temporal analysis and design for a big data enabled GIS.},
booktitle = {Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems},
articleno = {8},
numpages = {4},
keywords = {data architecture, knowledge generation, big data analytics},
location = {Burlingame, California},
series = {SIGSPACIAL '16}
}

@inproceedings{10.1145/3495535.3495539,
author = {Shishkov, Boris and Branzov, Todor and Ivanova, Krassimira and Verbraeck, Alexander},
title = {Using Drones for Resilience: A System of Systems Perspective},
year = {2021},
isbn = {9781450390187},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3495535.3495539},
doi = {10.1145/3495535.3495539},
abstract = {Disruptive Events (DE), such as disasters, virus outbreaks, and military conflicts, are often hugely affecting human life, and works featuring resilience against DE are receiving much attention. A key priority in this regard is the effective monitoring of the affected systems' state after a DE has occurred. Earlier work shows relevant strengths of drone technology for that purpose. In this paper, we take a functional perspective of this technology, for the sake of considering monitoring services and addressing DE. We conceptualize those services and provide explicit insight as it concerns the alignment between user needs and technological (drone-specific) solutions. Further, we zoom in, considering adaptation features, sensing features, and data analytics features accordingly. Finally, we present our general implementation vision that puts drones in a system-of-systems perspective. Since this is work-in-progress, validation is left for future research.},
booktitle = {10th International Conference on Telecommunications and Remote Sensing},
pages = {19–25},
numpages = {7},
keywords = {Resilience, Disruptive events, Societal impact, Drone technology},
location = {Virtual Conference, Bulgaria},
series = {ICTRS '21}
}

@inproceedings{10.1145/2755567.2755570,
author = {Galster, Matthias},
title = {Software Reference Architectures: Related Architectural Concepts and Challenges},
year = {2015},
isbn = {9781450334457},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2755567.2755570},
doi = {10.1145/2755567.2755570},
abstract = {Software reference architectures provide guidance when designing systems for particular application or technology domains. In this paper we contribute a better understanding of developing and using reference architectures: First, we relate the concept of software reference architecture to other architectural concepts to help engineers better understand the relationships between software development artifacts. Second, we discuss several high-level (and mostly non-technical) challenges related to the design and use of software reference architectures. These challenges can be used a) to formulate research problems for future work, and b) to define software product and development scenarios in which reference architectures may be difficult to apply. Finally, we explore application domains that may benefit from established reference architectures, including concrete challenges related to reference architectures in these domains.},
booktitle = {Proceedings of the 1st International Workshop on Exploring Component-Based Techniques for Constructing Reference Architectures},
pages = {5–8},
numpages = {4},
keywords = {challenges, architectural concepts, software reference architecture, frameworks},
location = {Montr\'{e}al, QC, Canada},
series = {CobRA '15}
}

@inproceedings{10.1145/3209280.3229112,
author = {Percy, Isabelle and Balinsky, Alexander and Balinsky, Helen and Simske, Steve},
title = {Text Mining and Recommender Systems for Predictive Policing},
year = {2018},
isbn = {9781450357692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3209280.3229112},
doi = {10.1145/3209280.3229112},
abstract = {We present some results from a joint project between HP Labs, Cardiff University and Dyfed Powys Police on predictive policing. Applications of the various techniques from recommender systems and text mining to the problem of crime patterns recognition are demonstrated. Our main idea is to consider crime records for different regions and time period as a corpus of text documents with words being crime types. We apply tools from NLP and text documents classifications to analyse different regions in time and space. We evaluate performance of several measures of similarity for texts and documents clustering algorithms.},
booktitle = {Proceedings of the ACM Symposium on Document Engineering 2018},
articleno = {15},
numpages = {4},
keywords = {Measure of similarity, TF-IDF, silhouette score, clustering, affinity propagation},
location = {Halifax, NS, Canada},
series = {DocEng '18}
}

@inbook{10.1145/3434074.3447220,
author = {Teh, Nicholas and Hu, Shuyue and Soh, Harold},
title = {A Theoretical Framework for Large-Scale Human-Robot Interaction with Groups of Learning Agents},
year = {2021},
isbn = {9781450382908},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3434074.3447220},
abstract = {Recent advances in robot capabilities have led to a growing consensus that robots will eventually be deployed at scale across numerous application domains. An important open question is how humans and robots will adapt to one another over time. In this paper, we introduce the model-based Theoretical Human-Robot Scenarios (THuS) framework, capable of elucidating the interactions between large groups of humans and learning robots. We formally establish THuS, and consider its application to a human-robot variant of the n-player coordination game, demonstrating the power of the theoretical framework as a tool to qualitatively understand and quantitatively compare HRI scenarios that involve different agent types. We also discuss the framework's limitations and potential. Our work provides the HRI community with a versatile tool that permits first-cut insights into large-scale HRI scenarios that are too costly or challenging to carry out in simulations or in the real-world.},
booktitle = {Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {489–493},
numpages = {5}
}


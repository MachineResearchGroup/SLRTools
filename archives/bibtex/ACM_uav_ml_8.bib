@article{10.1145/2687926,
author = {Treacy Solovey, Erin and Afergan, Daniel and Peck, Evan M. and Hincks, Samuel W. and Jacob, Robert J. K.},
title = {Designing Implicit Interfaces for Physiological Computing: Guidelines and Lessons Learned Using FNIRS},
year = {2015},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {6},
issn = {1073-0516},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2687926},
doi = {10.1145/2687926},
abstract = {A growing body of recent work has shown the feasibility of brain and body sensors as input to interactive systems. However, the interaction techniques and design decisions for their effective use are not well defined. We present a conceptual framework for considering implicit input from the brain, along with design principles and patterns we have developed from our work. We also describe a series of controlled, offline studies that lay the foundation for our work with functional near-infrared spectroscopy (fNIRS) neuroimaging, as well as our real-time platform that serves as a testbed for exploring brain-based adaptive interaction techniques. Finally, we present case studies illustrating the principles and patterns for effective use of brain data in human--computer interaction. We focus on signals coming from the brain, but these principles apply broadly to other sensor data and in domains such as aviation, education, medicine, driving, and anything involving multitasking or varying cognitive workload.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = {jan},
articleno = {35},
numpages = {27},
keywords = {implicit interfaces, Brain--computer interfaces, physiological computing}
}

@inproceedings{10.5555/3330299.3330333,
author = {Bonache-Seco, J. A. and Lopez-Orozco, J. A. and Portas, Eva Besada and Mart\'{\i}n, Jos\'{e} L. Risco},
title = {Adaptive Event Driven Framework for Real Time Multi-Agent Missions},
year = {2018},
isbn = {9781538650486},
publisher = {IEEE Press},
abstract = {A Ground Control Station (GCS) is an essential element to supervise and control autonomous vehicles performing complex missions in real time. In the new era of Internet of Things, where systems are highly connected, these missions demand enormous amounts of computational power to correctly manage the coordination of all the vehicles involved. In this scope, the set of Unmanned Vehicles (UVs) included in the mission must achieve more difficult tasks everyday. As a consequence, the development of a robust, reusable and adaptable GCS framework to allow a single operator to monitor and control a team of heterogeneous agents raises a number of research and engineering challenges. In this paper we introduce an adaptive event-driven framework specially designed for GCSs involved in heterogeneous multi-agent missions that takes advantage of two features: 1) it allows the GCS to add or remove both actual or simulated agents in real time, changing the number or types of monitored agents, and 2) from a software design perspective, the graphical user interface dynamically changes its view in order to minimize operators fatigue and mental workload, facilitating the success of the mission in such complex environments. We also show one of the tests performed with the adaptive framework, where after observing how a real UV deployed in a water surface performs successfully a set of previously planned trajectories, we will see how a simulated UV joins the mission in order to fulfill a leader-follower maneuver.},
booktitle = {Proceedings of the 22nd International Symposium on Distributed Simulation and Real Time Applications},
pages = {255–262},
numpages = {8},
keywords = {adaptive graphics user interface, ground control station, event-driven architecture, mental workload},
location = {Madrid, Spain},
series = {DS-RT '18}
}

@inproceedings{10.1145/3278721.3278768,
author = {Wagner, Alan R.},
title = {An Autonomous Architecture That Protects the Right to Privacy},
year = {2018},
isbn = {9781450360128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3278721.3278768},
doi = {10.1145/3278721.3278768},
abstract = {The advent and widespread adoption of wearable cameras and autonomous robots raises important issues related to privacy. The mobile cameras on these systems record and may re-transmit enormous amounts of video data that can then be used to identify, track, and characterize the behavior of the general populous. This paper presents a preliminary computational architecture designed to preserve specific types of privacy over a video stream by identifying categories of individuals, places, and things that require higher than normal privacy protection. This paper describes the architecture as a whole as well as preliminary results testing aspects of the system. Our intention is to implement and test the system on ground robots and small UAVs and demonstrate that the system can provide selective low-level masking or deletion of data requiring higher privacy protection.},
booktitle = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {330–334},
numpages = {5},
keywords = {perception, architecture, privacy},
location = {New Orleans, LA, USA},
series = {AIES '18}
}

@article{10.1145/3394052,
author = {Zhang, Ruqing and Guo, Jiafeng and Fan, Yixing and Lan, Yanyan and Cheng, Xueqi},
title = {Dual-Factor Generation Model for Conversation},
year = {2020},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {3},
issn = {1046-8188},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3394052},
doi = {10.1145/3394052},
abstract = {The conversation task is usually formulated as a conditional generation problem, i.e., to generate a natural and meaningful response given the input utterance. Generally speaking, this formulation is apparently based on an oversimplified assumption that the response is solely dependent on the input utterance. It ignores the subjective factor of the responder, e.g., his/her emotion or knowledge state, which is a major factor that affects the response in practice. Without explicitly differentiating such subjective factor behind the response, existing generation models can only learn the general shape of conversations, leading to the blandness problem of the response. Moreover, there is no intervention mechanism within the existing generation process, since the response is fully decided by the input utterance. In this work, we propose to view the conversation task as a dual-factor generation problem, including an objective factor denoting the input utterance and a subjective factor denoting the responder state. We extend the existing neural sequence-to-sequence (Seq2Seq) model to accommodate the responder state modeling. We introduce two types of responder state, i.e., discrete and continuous state, to model emotion state and topic preference state, respectively. We show that with our dual-factor generation model, we can not only better fit the conversation data, but also actively control the generation of the response with respect to sentiment or topic specificity.},
journal = {ACM Trans. Inf. Syst.},
month = {jun},
articleno = {31},
numpages = {31},
keywords = {responder state modeling, Conversation, dual-factor generation}
}

@inproceedings{10.1145/3207677.3278088,
author = {Lou, Gewei and Yang, Wenjing},
title = {Formation Control and Collision Avoidance of Multi-Agent System with Switching Communication Topology},
year = {2018},
isbn = {9781450365123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3207677.3278088},
doi = {10.1145/3207677.3278088},
abstract = {In this study1, formation control and collision avoidance problem of multi-agent system with switching communication topology has been researched. Due to changes in the communication topology, collision between agents may occur during the course of formation, especially when the distance between agents is very close. Therefore, we have proposed a stable and effective formation control law with collision avoidance capability for the multi-agent system. It is assumed that the topology graph is directed and switching. Besides, the agent is modeled as a single integrator. Our formation control law is the combination of a consensus-based formation control method and a collision avoidance algorithm. The collision avoidance algorithm is adopted based on the artificial potential field (APF) method. In addition, we have adapted the potential function to ensure connectivity. The convergence is guaranteed even in the simultaneous execution of the consensus-based controller and the collision avoidance algorithm. And also, all agents can converge to the desired position rapidly. Some simulations have shown the validation of our scheme.},
booktitle = {Proceedings of the 2nd International Conference on Computer Science and Application Engineering},
articleno = {47},
numpages = {6},
keywords = {graph theory, Formation control, consensus, collision avoidance},
location = {Hohhot, China},
series = {CSAE '18}
}

@article{10.1109/TNET.2020.2981504,
author = {Xie, Ning and Ou-Yang, Le and Liu, Alex X.},
title = {Spectrum Sharing in MmWave Cellular Networks Using Clustering Algorithms},
year = {2020},
issue_date = {June 2020},
publisher = {IEEE Press},
volume = {28},
number = {3},
issn = {1063-6692},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/TNET.2020.2981504},
doi = {10.1109/TNET.2020.2981504},
abstract = {This paper concerns the problem of spectrum sharing in mmWave cellular networks, where multiple network operators are granted access to the same spectrum resources. Prior spectrum sharing schemes for mmWave cellular networks have two limitations: high coordination overhead and high computational complexity. In this paper, we propose two spectrum sharing schemes for the mobile scenario and the stationary scenario, respectively. In the mobile scenario, we propose a Spectrum sharing scheme using Clustering Algorithms to find the Optimal Positions of Mobile BSes (SCA-OPM). In the stationary scenario, we propose a Spectrum sharing scheme using Clustering Algorithms to Select the most appropriate Subset from all BSes (SCA-SSB). Moreover, for each newly-arriving mobile terminal (MT), we propose two online spectrum sharing schemes based on our SCA-OPM scheme and SCA-SSB scheme, which effectively saves the overall overhead and complexity. Our experimental results show that the SCA-OPM scheme has the best performance, while the SCA-SSB scheme has the same performance as that of the prior scheme but with lower overhead and lower complexity. When the MT density is 200 MTs/km<sup>2</sup>, for the sum-rate with 10<sup>-2</sup> bits/s/Hz, the performance gap between the SCA-OPM scheme and the remaining schemes achieves about 19 dB. Moreover, our online schemes have the same performance as those of their counterpart schemes but with lower overhead and lower complexity for the scenario of a few newly-arriving MTs.},
journal = {IEEE/ACM Trans. Netw.},
month = {jun},
pages = {1378–1390},
numpages = {13}
}

@inproceedings{10.1145/3215525.3215536,
author = {Lima, Rolif and Das, Kaushik},
title = {Localizing a Depth Measuring Sensor In Flood Scenario},
year = {2018},
isbn = {9781450358439},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3215525.3215536},
doi = {10.1145/3215525.3215536},
abstract = {In this work we propose a system architecture to aid the rescue team in a flood affected region to effectively conduct the rescue operations. We focus on developing a method to localize a set of randomly distributed sensors which are capable of measuring the water depth. The underlying application of this method resides in building a water depth map of the flood affected region which can be used by the rescue team. Since the depth map building is location dependent task, it is critical to know the sensor position along with the measurements it provides. Under the constraints imposed on the sensor design, we propose a localization algorithm which uses the received signal strength (RSS) to localize the sensor. A brief information about the desired sensor requirements and its design is discussed first, followed by the detailed mechanism to localize the same with the use of support vector regression (SVR).},
booktitle = {Proceedings of the 1st International Workshop on Internet of People, Assistive Robots and Things},
pages = {49–54},
numpages = {6},
keywords = {Localization, Received Signal Strength, Support Vector Regression},
location = {Munich, Germany},
series = {IoPARTS'18}
}

@article{10.1145/2980763,
author = {Xu, Ye and Koren, Israel and Krishna, C. Mani},
title = {AdaFT: A Framework for Adaptive Fault Tolerance for Cyber-Physical Systems},
year = {2017},
issue_date = {August 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3},
issn = {1539-9087},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2980763},
doi = {10.1145/2980763},
abstract = {Cyber-physical systems (CPS) frequently have to use massive redundancy to meet application requirements for high reliability. While such redundancy is required, it can be activated adaptively, based on the current state of the controlled plant. Most of the time, the plant is in a state that allows for a lower level of fault tolerance. Avoiding the continuous deployment of massive fault tolerance will greatly reduce the workload of the CPS, and lower the operating temperature of the cyber sub-system, thus increasing its reliability. In this article, we extend our prior research by demonstrating a software simulation framework Adaptive Fault Tolerance (AdaFT) that can automatically generate the sub-spaces within which our adaptive fault tolerance can be applied. We also show the theoretical benefits of AdaFT and its actual implementation in several real-world CPSs.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {mar},
articleno = {79},
numpages = {25},
keywords = {processor thermal reliability, cyber-physical system, Fault tolerance}
}

@inproceedings{10.1145/3368756.3369005,
author = {Bentalha, Badr and Hmioui, Aziz and Alla, Lhoussaine},
title = {The Digitalization of the Supply Chain Management of Service Companies: A Prospective Approach},
year = {2019},
isbn = {9781450362894},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3368756.3369005},
doi = {10.1145/3368756.3369005},
abstract = {Supply Chain Management (SCM) was born and developed first in an industrial context. In the field of services, little research has addressed the issue of the company's SCM. According to [1] "service logistics is an approach that stabilizes and guarantees the continuity of flows: it is then oriented more towards the service provided than towards reducing traffic costs". The SCM of services is of increasing interest to companies facing strong competition, market globalization and rapid changes in information and communication technologies. This evolution has led to a rapid integration of new digital practices in this field.So, how is the digitalization of the SCM of service companies looking today and what will be the future trends? On the one hand, with the help of the literature review, we seek to identify the concept of the SCM in services and its specificities, then that of digitization of the SCM and its organizational dimension. On the other hand, we are attempting a prospective approach to the current practices and digitalization prospects of the service company's SCM.},
booktitle = {Proceedings of the 4th International Conference on Smart City Applications},
articleno = {29},
numpages = {8},
keywords = {supply chain, SCM, digital, prospective approach, service company},
location = {Casablanca, Morocco},
series = {SCA '19}
}

@inproceedings{10.1145/3300061.3345442,
author = {Zhang, Diana and Wang, Jingxian and Jang, Junsu and Zhang, Junbo and Kumar, Swarun},
title = {On the Feasibility of Wi-Fi Based Material Sensing},
year = {2019},
isbn = {9781450361699},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3300061.3345442},
doi = {10.1145/3300061.3345442},
abstract = {Wireless sensing has demonstrated the potential of using Wi-Fi signals to track people and objects, even behind walls.Yet, prior work in this space aims to merely detect the presence of objects around corners, rather than their type. In this paper, we explore the feasibility of the following re-search question: ?Can commodity Wi-Fi radios detect both the location and type of moving objects around them?". We present IntuWition, a complementary sensing system that can sense the location and type of material of objects in the environment, including those out of line-of-sight. It achieves this by sensing wireless signals reflected off surrounding objects using commodity Wi-Fi radios, whose signals penetrate walls and occlusions. At the core of IntuWition is the idea that different materials reflect and scatter polarized waves in different ways. We build upon ideas from RADAR Polarimetry to detect the material of objects across spatial locations, despite mobility of the sensing device and the hardware non-idealities of commodity Wi-Fi radios. A detailed feasibility study reveals an average accuracy of 95% in line-of-sight and 92% in non-line-of-sight in classifying five types of materials:copper, aluminum, plywood, birch, and human. Finally, we present a proof-of-concept application of our system on an autonomous UAV that uses its onboard Wi-Fi radios to sense whether an occlusion is a person versus another UAV.},
booktitle = {The 25th Annual International Conference on Mobile Computing and Networking},
articleno = {41},
numpages = {16},
keywords = {wifi, wireless sensing, mobile systems, polarimetry},
location = {Los Cabos, Mexico},
series = {MobiCom '19}
}

@inproceedings{10.1145/3184558.3186242,
author = {Imran, Muhammad and Castillo, Carlos and Diaz, Fernando and Vieweg, Sarah},
title = {Processing Social Media Messages in Mass Emergency: Survey Summary},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3184558.3186242},
doi = {10.1145/3184558.3186242},
abstract = {Millions of people use social media to share information during disasters and mass emergencies. Information available on social media, particularly in the early hours of an event when few other sources are available, can be extremely valuable for emergency responders and decision makers, helping them gain situational awareness and plan relief efforts. Processing social media content to obtain such information involves solving multiple challenges, including parsing brief and informal messages, handling information overload, and prioritizing different types of information. These challenges can be mapped to information processing operations such as filtering, classifying, ranking, aggregating, extracting, and summarizing. This work highlights these challenges and presents state of the art computational techniques to deal with social media messages, focusing on their application to crisis scenarios.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {507–511},
numpages = {5},
keywords = {disaster response, social media, emergency management},
location = {Lyon, France},
series = {WWW '18}
}

@article{10.1145/3400051.3400055,
author = {Eftelioglu, Emre and Shekhar, Shashi and Hudson, James and Joppa, Lucas and Baru, Chaitanya and Janeja, Vandana},
title = {Data Science for Earth: An Earth Day Report},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {1},
issn = {1931-0145},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3400051.3400055},
doi = {10.1145/3400051.3400055},
abstract = {At the 25th ACM SIGKDD conference on Knowledge and Data Discovery (KDD), a special Earth Day symposium was held to bring together thought leaders in academia, indus- try and government to discuss opportunities for data science to help meet the challenges facing our planet Earth. The all-day event showcased some examples of data-intensive re- search being done to study Earth-related phenomena. A key goal of the symposium was to raise awareness about the unique challenges that Earth-related datasets pose for data mining. The Earth Day website can be found at https://www. kdd.org/kdd2019/special-days/earth-day.},
journal = {SIGKDD Explor. Newsl.},
month = {may},
pages = {4–7},
numpages = {4},
keywords = {climate change, urbanization, food- energy-water nexus, geospatial data science, earth, sustainability}
}

@inproceedings{10.1145/3447587.3447597,
author = {Xi, Runping and wang, Sisi and Liu, Yue and Wang, Zhao},
title = {Individual Identification Method of Leopard in Multiple Scenarios},
year = {2021},
isbn = {9781450389105},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3447587.3447597},
doi = {10.1145/3447587.3447597},
abstract = {Individual identification of rare animals in different scenarios helps to accurately grasp the number and scale of animal populations, so as to formulate appropriate protection measures and policies, which are beneficial to maintaining human ecological balance and sustainable development. In this paper, we study the individual identification methods of leopard in multiple scenes, obtain the leopard image data through various channels such as zoos and protected areas, and construct a dataset, which obtains 28,751 images of leopard. In order to extract more fine-grained features of the leopard, Res2net was added to the network, at the same time, the self-attention mechanism was added to improve the global correlation. A R2NMGN method based on the self-attention mechanism was proposed. The experimental results show that the method proposed in this paper is significantly better than other methods in individual recognition of leopard.},
booktitle = {2021 The 4th International Conference on Image and Graphics Processing},
pages = {65–72},
numpages = {8},
keywords = {leopard, R2NMGN, attention mechanism, Individual identification},
location = {Sanya, China},
series = {ICIGP 2021}
}

@inproceedings{10.1145/3086439.3086445,
author = {Bouvry, Pascal and Chaumette, Serge and Danoy, Gr\'{e}goire and Guerrini, Gilles and Jurquet, Gilles and Kuwertz, Achim and M\"{u}ller, Wilmuth and Rosalie, Martin and Sander, Jennifer and Segor, Florian},
title = {ASIMUT Project: Aid to SItuation Management Based on MUltimodal, MUltiUAVs, MUltilevel Acquisition Techniques},
year = {2017},
isbn = {9781450349604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3086439.3086445},
doi = {10.1145/3086439.3086445},
abstract = {This document summarizes the activities and results of the ASIMUT project (Aid to SItuation Management based on MUltimodal, MUltiUAVs, MUltilevel acquisition Techniques) carried out by the consortium composed of Thales, Fraunhofer IOSB, Fly-n-Sense, University of Bordeaux and University of Luxembourg. Funded by the European Defence Agency (EDA), the objectives of the ASIMUT project are to design, implement and validate algorithms that will allow the efficient usage of autonomous swarms of Unmanned Aerial Vehicles (UAVs) for surveillance missions.},
booktitle = {Proceedings of the 3rd Workshop on Micro Aerial Vehicle Networks, Systems, and Applications},
pages = {17–20},
numpages = {4},
keywords = {high level data fusion, automatic processing and detection, smart mission management, multilevel UAV swarm, mobility management, decisional autonomy},
location = {Niagara Falls, New York, USA},
series = {DroNet '17}
}

@inproceedings{10.1145/2908961.2931678,
author = {Plachkov, Alex and Abielmona, Rami and Harb, Moufid and Falcon, Rafael and Inkpen, Diana and Groza, Voicu and Petriu, Emil},
title = {Automatic Course of Action Generation Using Soft Data for Maritime Domain Awareness},
year = {2016},
isbn = {9781450343237},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2908961.2931678},
doi = {10.1145/2908961.2931678},
abstract = {Information Fusion (IF) systems have long exploited data provided by hard (physics-based) sensors with the aspiration of making sense of the environment they are monitoring. In recent times, the IF community has recognized the potential of utilizing data generated by people, also known as soft data. In this study, we demonstrate how course of action (CoA) generation, one of the key elements of Level 3 High-Level Information Fusion and a vital component for security and defense decision support systems, can be augmented using soft (human-derived) data for improved mission effectiveness. This conceptualization is validated through an elaborate experiment situated in the maritime world. To the best of the authors' knowledge, this is the first study to apply soft data to automatic CoA generation in the maritime domain.},
booktitle = {Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion},
pages = {1071–1078},
numpages = {8},
keywords = {high-level information fusion, decision support systems, soft data, course of action recommendation, multicriteria decision making},
location = {Denver, Colorado, USA},
series = {GECCO '16 Companion}
}

@inproceedings{10.1145/3281151.3281161,
author = {Weingart, Troy and Graham, Paul and Christman, Del and Weingart, Austin},
title = {Using Virtual Reality to Control Swarms of Autonomous Agents},
year = {2018},
isbn = {9781450360029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3281151.3281161},
doi = {10.1145/3281151.3281161},
abstract = {Current two dimensional methods of controlling large numbers of small unmanned aerial systems (sUAS) have limitations such as a human's ability to track, efficiently control, and keep situational awareness on large numbers of sUASs. The 2017 DARPA-sponsored Service Academies Swarm Challenge inspired research producing novel command and control techniques that utilize a virtual reality (VR) environment and a multimodal interface. A swarm commander using this approach can select one sUAS, a sub-swarm, or even the entire swarm and assign that grouping a behavior to be carried out autonomously. This immersive VR environment improves situational awareness, optimizes command and control actions, reduces commander's task load, and ultimately provides a significant advantage over approaches that rely on traditional techniques.},
booktitle = {Proceedings of the 20th International Conference on Multimodal Interaction: Adjunct},
articleno = {10},
numpages = {4},
keywords = {sUAS, small unmanned aerial systems, multimodal, virtual reality, swarm, autonomy, unmanned aerial vehicles, command and control},
location = {Boulder, Colorado},
series = {ICMI '18}
}

@article{10.1145/3437479.3437489,
author = {Dugdale, Julie and Moghaddam, Mahyar T. and Muccini, Henry},
title = {IoT4Emergency: Internet of Things for Emergency Management},
year = {2021},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0163-5948},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3437479.3437489},
doi = {10.1145/3437479.3437489},
abstract = {The increasing natural and man-induced disasters such as res, earthquakes, oods, hurricanes, overcrowding, or pandemic viruses endanger human lives. Hence, designing infrastructures to handle those possible crises has become an ever-increasing need. The Internet of Things (IoT) has changed our approach to safety systems by connecting sensors and providing real-time data to managers, rescuers, and endangered people. IoT systems can monitor and react to progressive disasters, people's movements and their behavioral patterns. The community faces challenges in using IoT for crises management: i) how to take advantage of technological advancements and deal with IoT resources installation issues? ii) what environmental contexts should be considered while designing IoT-based emergency handling systems? iii) how should system design comply with various levels of real-time requirements? This paper reports on the results of the First International Workshop on Internet of Things for Emergency Management (IoT4Emergency 2020), which speci cally focuses on challenges and envisioned solutions in using smart connected systems to handle disasters.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jan},
pages = {33–36},
numpages = {4},
keywords = {cps, detection, iot, natural hazards, crisis, emergency, risk}
}

@article{10.1145/2983925,
author = {Rosenfeld, Ariel and Kraus, Sarit},
title = {Providing Arguments in Discussions on the Basis of the Prediction of Human Argumentative Behavior},
year = {2016},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
issn = {2160-6455},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2983925},
doi = {10.1145/2983925},
abstract = {Argumentative discussion is a highly demanding task. In order to help people in such discussions, this article provides an innovative methodology for developing agents that can support people in argumentative discussions by proposing possible arguments. By gathering and analyzing human argumentative behavior from more than 1000 human study participants, we show that the prediction of human argumentative behavior using Machine Learning (ML) is possible and useful in designing argument provision agents. This paper first demonstrates that ML techniques can achieve up to 76% accuracy when predicting people’s top three argument choices given a partial discussion. We further show that well-established Argumentation Theory is not a good predictor of people’s choice of arguments. Then, we present 9 argument provision agents, which we empirically evaluate using hundreds of human study participants. We show that the Predictive and Relevance-Based Heuristic agent (PRH), which uses ML prediction with a heuristic that estimates the relevance of possible arguments to the current state of the discussion, results in significantly higher levels of satisfaction among study participants compared with the other evaluated agents. These other agents propose arguments based on Argumentation Theory; propose predicted arguments without the heuristics or with only the heuristics; or use Transfer Learning methods. Our findings also show that people use the PRH agents proposed arguments significantly more often than those proposed by the other agents.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = {dec},
articleno = {30},
numpages = {33},
keywords = {Argumentation, advising agents, human argumentation, automated advice, prediction}
}

@article{10.1145/2688494.2688495,
title = {Abstracts: Online Supplements Volume 13, Number 1s Volume 13, Number 2s Volume 13, Number 3s Volume 13, Number 4s Volume 13, Number 5s},
year = {2014},
issue_date = {November 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {1539-9087},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2688494.2688495},
doi = {10.1145/2688494.2688495},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {dec},
articleno = {99},
numpages = {57}
}

@inproceedings{10.1145/3194104.3194109,
author = {Feldt, Robert and de Oliveira Neto, Francisco G. and Torkar, Richard},
title = {Ways of Applying Artificial Intelligence in Software Engineering},
year = {2018},
isbn = {9781450357234},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3194104.3194109},
doi = {10.1145/3194104.3194109},
abstract = {As Artificial Intelligence (AI) techniques become more powerful and easier to use they are increasingly deployed as key components of modern software systems. While this enables new functionality and often allows better adaptation to user needs it also creates additional problems for software engineers and exposes companies to new risks. Some work has been done to better understand the interaction between Software Engineering and AI but we lack methods to classify ways of applying AI in software systems and to analyse and understand the risks this poses. Only by doing so can we devise tools and solutions to help mitigate them. This paper presents the AI in SE Application Levels (AI-SEAL) taxonomy that categorises applications according to their point of application, the type of AI technology used and the automation level allowed. We show the usefulness of this taxonomy by classifying 15 papers from previous editions of the RAISE workshop. Results show that the taxonomy allows classification of distinct AI applications and provides insights concerning the risks associated with them. We argue that this will be important for companies in deciding how to apply AI in their software applications and to create strategies for its use.},
booktitle = {Proceedings of the 6th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering},
pages = {35–41},
numpages = {7},
keywords = {artificial intelligence, software engineering, taxonomy},
location = {Gothenburg, Sweden},
series = {RAISE '18}
}

@article{10.1145/3343855,
author = {Yin, Yafeng and Xie, Lei and Gu, Tao and Lu, Yijia and Lu, Sanglu},
title = {AirContour: Building Contour-Based Model for In-Air Writing Gesture Recognition},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {1550-4859},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3343855},
doi = {10.1145/3343855},
abstract = {Recognizing in-air hand gestures will benefit a wide range of applications such as sign-language recognition, remote control with hand gestures, and “writing” in the air as a new way of text input. This article presents AirContour, which focuses on in-air writing gesture recognition with a wrist-worn device. We propose a novel contour-based gesture model that converts human gestures to contours in 3D space and then recognizes the contours as characters. Different from 2D contours, the 3D contours may have the problems such as contour distortion caused by different viewing angles, contour difference caused by different writing directions, and the contour distribution across different planes. To address the above problem, we introduce Principal Component Analysis (PCA) to detect the principal/writing plane in 3D space, and then tune the projected 2D contour in the principal plane through reversing, rotating, and normalizing operations, to make the 2D contour in right orientation and normalized size under a uniform view. After that, we propose both an online approach, AC-Vec, and an offline approach, AC-CNN, for character recognition. The experimental results show that AC-Vec achieves an accuracy of 91.6% and AC-CNN achieves an accuracy of 94.3% for gesture/character recognition, both outperforming the existing approaches.},
journal = {ACM Trans. Sen. Netw.},
month = {oct},
articleno = {44},
numpages = {25},
keywords = {principal component analysis (PCA), AirContour, contour-based gesture model, gesture recognition, in-air writing}
}

@inproceedings{10.5555/3398761.3398837,
author = {Kla\v{s}ka, David and Ku\v{c}era, Anton\'{\i}n and \v{R}eh\'{a}k, Vojt\v{e}ch},
title = {Adversarial Patrolling with Drones},
year = {2020},
isbn = {9781450375184},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {We investigate adversarial patrolling where the Defender is an autonomous device with a limited energy resource (e.g., a drone). Every eligible Defender's policy must prevent draining the energy resource before arriving to a refill station, and this constraint substantially complicates the problem of computing an efficient Defender's policy. Furthermore, the existing infinite-horizon models assume&nbsp;Attackers with unbounded patience&nbsp;willing to wait arbitrarily long for a good attack opportunity. We show this assumption is inappropriate in the setting with drones because here the expected waiting time for an optimal attack opportunity can be extremely large. To overcome this problem, we introduce a new concept of an impatient Attacker, and design a polynomial time algorithm for computing a Defender's policy achieving protection close to the optimal value against an impatient Attacker. Since our algorithm can quickly evaluate the protection achievable for various topologies of refill stations, we can also optimize their displacement. We implement the algorithm and demonstrate its functionality on instances of realistic size.},
booktitle = {Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {629–637},
numpages = {9},
keywords = {single and multi-agent planning and scheduling, patrolling games},
location = {Auckland, New Zealand},
series = {AAMAS '20}
}

@inproceedings{10.1145/3501409.3501523,
author = {Lv, Hui and Chen, Xiaolong},
title = {Research and Implementation of Forest Fire Smoke Detection Based on ResNet Transfer Learning},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3501409.3501523},
doi = {10.1145/3501409.3501523},
abstract = {Frequent forest fires damage the ecological environment and affect people's lives. Early monitoring of forest fire can significantly reduce the damage. Many methods have proposed by researchers for fire detection, but most of them are based on traditional image feature extraction. In the paper, we present a forest fire detection approach based on ResNet-18 transfer learning which can be used to train a model with a smaller dataset. First, image preprocessing methods were used to enlarge the dataset, which include random cropping and random erase. Secondly, the pre-trained ResNet-18 model is fine-tuned using the target train set. Experiments shows that the fine-tuned ResNet-18 model can effectively recognize the fire or smoke in the image, which got the accuracy of 94.33% on test set. Also, image preprocessing which contains random cropping and random erase can improve the performance of the fine-tuned ResNet-18 model.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {630–635},
numpages = {6},
keywords = {ResNet-18 transfer learning, Image preprocess, Forest fire smoke},
location = {Xiamen, China},
series = {EITCE 2021}
}

@inproceedings{10.5555/3108414.3108417,
author = {Singh, Shweta and Lu, Shan and Kokar, Mieczyslaw M. and Kogut, Paul A. and Martin, Lockheed},
title = {Detection and Classification of Emergent Behaviors Using Multi-Agent Simulation Framework (WIP)},
year = {2017},
isbn = {9781510840300},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {In recent years the concept of emergence has captured significant attention in the field of complex systems. However, the inability to predict and control emergent phenomena prevents us from exploring its full potential. The research effort in this paper focuses on exploring emergent behaviors by proposing a framework for analysis of systems that exhibit such behaviors. The framework provides a platform for simulating and analyzing behaviors in multi-agent system, including detection and classification of emergence into different types. In this paper, we follow the classification of emergent behaviors according to Fromm's taxonomy. In addition, the paper presents a scenario implementation using swarms of Unmanned Aerial Vehicles (UAVs) to demonstrate the applicability of the proposed approach. Since this is a part of on-going research, future direction is also discussed.},
booktitle = {Proceedings of the Symposium on Modeling and Simulation of Complexity in Intelligent, Adaptive and Autonomous Systems},
articleno = {3},
numpages = {8},
keywords = {unmanned aerial vehicles (UAVs), emergence, agent-based modeling, swarming, OWL},
location = {Virginia Beach, Virginia},
series = {MSCIAAS '17}
}

@inproceedings{10.5555/2693848.2694039,
author = {Davis, Ericson R. and Johnson, Christopher D. and Levin, David J. and Morowitz, Rachel C. and Peterson, David K. and Pouy, Michael R. and Volovoi, Vitali},
title = {Aligning Wildfire Management Resourcing Decisions with Operational Needs},
year = {2014},
publisher = {IEEE Press},
abstract = {A hierarchical modeling and simulation (M&amp;S) framework can help federal agencies integrate the myriad business resourcing decisions they face as unmanned aerospace vehicle (UAV) systems are deployed within their federally authorized charters. An integrated M&amp;S method offers a pragmatic approach to leveraging the power of analytical techniques and coping with the complex support requirements of modern macrosystems. In this paper, we demonstrate the benefits of incorporating several agent-based modeling (ABM) enhancements for UAV route planning into a hierarchical M&amp;S structure.},
booktitle = {Proceedings of the 2014 Winter Simulation Conference},
pages = {1493–1504},
numpages = {12},
location = {Savannah, Georgia},
series = {WSC '14}
}

@article{10.1145/3300150.3300156,
author = {Kelley, Dean},
title = {Technical Report Column},
year = {2018},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {4},
issn = {0163-5700},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3300150.3300156},
doi = {10.1145/3300150.3300156},
abstract = {Welcome to the Technical Reports Column. If your institution publishes technical reports that you'd like to have included here, please contact me at the email address above.},
journal = {SIGACT News},
month = {dec},
pages = {17–27},
numpages = {11}
}

@article{10.1145/3457588.3457594,
author = {Kelley, Dean},
title = {Technical Report Column},
year = {2021},
issue_date = {March 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {1},
issn = {0163-5700},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3457588.3457594},
doi = {10.1145/3457588.3457594},
abstract = {Welcome to the Technical Reports Column. If your institution publishes technical reports that you'd like to have included here, please contact me at the email address above.},
journal = {SIGACT News},
month = {mar},
pages = {25–35},
numpages = {11}
}

@article{10.1145/2629593,
author = {Basha, Elizabeth and Jurdak, Raja and Rus, Daniela},
title = {In-Network Distributed Solar Current Prediction},
year = {2015},
issue_date = {February 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {2},
issn = {1550-4859},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2629593},
doi = {10.1145/2629593},
abstract = {Long-term sensor network deployments demand careful power management. While managing power requires understanding the amount of energy harvestable from the local environment, current solar prediction methods rely only on recent local history, which makes them susceptible to high variability. In this article, we present a model and algorithms for distributed solar current prediction based on multiple linear regression to predict future solar current based on local, in situ climatic and solar measurements. These algorithms leverage spatial information from neighbors and adapt to the changing local conditions not captured by global climatic information. We implement these algorithms on our Fleck platform and run a 7-week-long experiment validating our work. In analyzing our results from this experiment, we determined that computing our model requires an increased energy expenditure of 4.5mJ over simpler models (on the order of 10-7% of the harvested energy) to gain a prediction improvement of 39.7%.},
journal = {ACM Trans. Sen. Netw.},
month = {dec},
articleno = {23},
numpages = {28},
keywords = {prediction, sensor network, Solar current, energy management}
}

@inproceedings{10.1145/3341568.3342111,
author = {Mirri, Silvia and Prandi, Catia and Salomoni, Paola},
title = {Human-Drone Interaction: State of the Art, Open Issues and Challenges},
year = {2019},
isbn = {9781450368797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3341568.3342111},
doi = {10.1145/3341568.3342111},
abstract = {In the evolution of the Human-Computer Interaction discipline, it is interesting to evaluate the users' experience within the interaction between users and a specific category of robots, which are characterized by peculiar features: the unmanned aerial vehicles (UAVs). Drones are becoming more and more diffused, being used with different purposes. Hence, the interaction with these devices is getting common and here we aim at investigating how they can be exploited by means of different users' interfaces and with different interaction mechanisms.In this paper, we present a review of the state of the art in the context of the human-drone interaction, so as to study and discuss the main open issues and challenges currently highlighted and reported in research projects and papers available in the current literature.},
booktitle = {Proceedings of the ACM SIGCOMM 2019 Workshop on Mobile AirGround Edge Computing, Systems, Networks, and Applications},
pages = {43–48},
numpages = {6},
keywords = {HCI, UAVs, Human-Drone Interaction, Drones},
location = {Beijing, China},
series = {MAGESys'19}
}

@article{10.1145/3444815.3444821,
author = {Kelley, Dean},
title = {Technical Report Column},
year = {2021},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0163-5700},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3444815.3444821},
doi = {10.1145/3444815.3444821},
abstract = {Welcome to the Technical Reports Column. If your institution publishes technical reports that you'd like to have included here, please contact me at the email address above.},
journal = {SIGACT News},
month = {jan},
pages = {18–29},
numpages = {12}
}

@inproceedings{10.1145/3501409.3501595,
author = {Zhao, Di and Jiang, Shuai and Wang, Wei and Zhang, Jing and Luan, Rui-Peng},
title = {Domain Named Entity Recognition and Applications in Test and Evaluation},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3501409.3501595},
doi = {10.1145/3501409.3501595},
abstract = {A great amount of information in Test and Evaluation (T&amp;E) is presented in the form of multi-source heterogeneous data such as performance test, combat trial and during-service assessment. Despite the existence of numerous and well-versed Domain Named Entity Recognition (DNER) methods in the general field, it still remains scarcely resourced. In this paper we survey novel methods that have recently been introduced for such DNER tasks. In addition, we construct the dataset for further NER tasks in the field of Test and Evaluation. Finally, our work lays the cornerstone for the development of subsequent NER in this field.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1043–1049},
numpages = {7},
keywords = {DNER, NER, Test and Evaluation},
location = {Xiamen, China},
series = {EITCE 2021}
}

@inproceedings{10.1145/3369740.3369793,
author = {Ramisetty, Rajeswara Rao and Qu, Chengyi and Aktar, Rumana and Wang, Songjie and Calyam, Prasad and Palaniappan, Kannappan},
title = {Dynamic Computation Off-Loading and Control Based on Occlusion Detection in Drone Video Analytics},
year = {2020},
isbn = {9781450377515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3369740.3369793},
doi = {10.1145/3369740.3369793},
abstract = {Unmanned Aerial Vehicles (UAVs) or drones equipped with cameras are extensively used in different scenarios such as surveillance of hazardous locations, disaster response and crime fighting. The related video streaming/analytics requires real-time drone-to-Ground Control Station (GCS) communication and computation co-ordination for desired user Quality of Experience (QoE). In situations where the quality of the video can be affected by occlusions (e.g., image distortion, frame stalling) due to network bottlenecks, there is a need to dynamically make decisions on the computation offloading and networking protocols in order to properly handle the video data for real world application purposes. In this paper, we propose a novel function-centric computing approach that helps a user to perform drone video analytics to assess a wide-area scene to chart a plan of action. Our approach involves handling network impairments affecting the switching between high resolution/low resolution video capture, or change of camera direction for assessment of the scene effectively. It also features a novel video quality enhancing algorithm based on occlusion-detection that adapts to video impairments related to image distortion and frame stalling. Our experiment results from a realistic testbed show that our approach can efficiently choose the suitable networking protocols (i.e., TCP/HTTP, UDP/RTP, QUIC) and orchestrate both the camera control on the drone, and the computation off-loading of the video analytics over limited edge computing resources. The performance improvements for computation off-loading involving our video quality enhancing algorithm are shown for different network conditions in terms of occlusion rate and processing times.},
booktitle = {Proceedings of the 21st International Conference on Distributed Computing and Networking},
articleno = {28},
numpages = {10},
keywords = {Multimedia networking protocols, Computation off-loading, Network management, Drone video analytics, Occlusion detection},
location = {Kolkata, India},
series = {ICDCN 2020}
}

@inproceedings{10.1145/3448891.3448958,
author = {Xie, Rong},
title = {Starling Swarm Algorithm: An Approach to Autonomous Coordination of Intensive Agents},
year = {2020},
isbn = {9781450388405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3448891.3448958},
doi = {10.1145/3448891.3448958},
abstract = {For the Swarm Coordination Problem (SCP), traditional control strategies met some limitations like difficult model parameter adjustment and week coordination effeteness etc. Some PSO and its improvement algorithms did not present good coordination effects, particularly for the applications of intensive agents. Therefore, we specifically designed a novel Starling Swarm Algorithm (SSA) from the latest research findings of coordination mechanism of starling flock, like local perception, self-adaptation, centerless self-organization and self-adaptation. We designed the SSA combining with local perception, safe avoidance, example selection and decision evolution. In the paper, we also presented 9 basic rules that agent group should follow which reflect the essence of group coordination well. To evaluate coordination effect, we defined convergence coefficient to quantify coordination in the paper. Based on it, we carried out our experiments from parameter analysis, efficiency and effectiveness under different situations and presented our results of changes of convergence coefficient and comparison of SSA with classical PSO. In cases of different agent numbers, we obtained the results of number of iterations for implementing task, respectively, which showed that our algorithm was more efficient than PSO. For effectiveness analysis, simulations of effects of group coordination under various conditions of no obstacle, multiple obstacles and intruder were also presented in the paper.},
booktitle = {MobiQuitous 2020 - 17th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
pages = {10–17},
numpages = {8},
keywords = {Local perception, Example selection, Intensive Agents (IAs), Starling Swarm Algorithm (SSA), Decision evolution, Safe avoidance, Swarm Coordination Problem (SCP)},
location = {Darmstadt, Germany},
series = {MobiQuitous '20}
}

@inbook{10.1145/3434581.3434669,
author = {Yang, Borui and Fu, Guicui and Wan, Bo and Wang, Ye},
title = {Diagnosis and Prediction of Bearing Fault Using EEMD and CNN},
year = {2020},
isbn = {9781450375764},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3434581.3434669},
abstract = {Rolling bearing is a very essential component of the industrial machinery. The bearing fault could cause a significant loss. Therefore, it is necessary to perform fault diagnosis and prediction on the bearing. This paper combines Ensemble Empirical Mode Decomposition (EEMD), Singular Value Decomposition (SVD) difference spectrum de-noising, and the convolutional neural network (CNN) to realize the diagnosis and prediction of bearing faults. EEMD is used to extract features, and SVD difference spectrum de-noising is used to denoise the decomposed signals. The reconstructed vibration signals are then fed into CNN to realize fault diagnosis. Further, by analyzing the output of the softmax layer after the input of testing sets, the prediction of bearing fault can be realized. The bearing vibration signals are used to perform diagnosis. And we use partial samples of bearing fault full-period data to retrain CNN for prediction. In this paper, these methods successfully lead to bearing fault diagnosis with high accuracy and early bearing fault prediction.},
booktitle = {Proceedings of the 2020 International Conference on Aviation Safety and Information Technology},
pages = {282–289},
numpages = {8}
}

@inproceedings{10.5555/2772879.2773261,
author = {Salisbury, Elliot and Stein, Sebastian and Ramchurn, Sarvapali},
title = {Real-Time Opinion Aggregation Methods for Crowd Robotics},
year = {2015},
isbn = {9781450334136},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Unmanned Aerial Vehicles (UAVs) are increasingly becoming instrumental to many commercial applications, such as transportation and maintenance. However, these applications require exibility, understanding of natural language, and comprehension of video streams that cannot currently be automated and instead require the intelligence of a skilled human pilot. While having one pilot individually supervising a UAV is not scalable, the machine intelligence, especially vision, required to operate a UAV is still inadequate. Hence, in this paper, we consider the use of crowd robotics to harness a real-time crowd to orientate a UAV in an unknown environment. In particular, we present two novel real-time crowd input aggregation methods. To evaluate these methods, we develop a new testbed for crowd robotics, called CrowdDrone, that allows us to evaluate crowd robotic systems in a variety of scenarios. Using this platform, we benchmark our real-time aggregation methods with crowds hired from Amazon Mechanical Turk and show that our techniques outperform the current state-of-the-art aggregation methods, enabling a robotic agent to travel faster across a fixed distance, and with more precision. Furthermore, our aggregation methods are shown to be significantly more effective in dynamic scenarios.},
booktitle = {Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
pages = {841–849},
numpages = {9},
keywords = {crowdsourcing, crowd robotics, real-time crowd control, real-time human computation},
location = {Istanbul, Turkey},
series = {AAMAS '15}
}

@inproceedings{10.1145/1878537.1878579,
author = {Ng, Luke and Hubbard, Paul and O'Young, Siu},
title = {Simulation of Fully Autonomous Control of Unmanned Air Vehicles for Maritime Surveillance},
year = {2010},
isbn = {9781450300698},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/1878537.1878579},
doi = {10.1145/1878537.1878579},
abstract = {As the usage of unmanned systems become more prevalent, defence departments around the world are looking for new modes of human-system interaction that increase the level of autonomy of the vehicle, while maintaining operator control and trust. Defence R&amp;D Canada is currently engaged in a research program on the simulation of Unmanned Aerial Vehicles (UAVs) and methods to increase autonomous capabilities.In this paper we describe a sensor-based reactive control system for a UAV which can perform a mission autonomously. The primary sensor is machine vision, however, the focus on this paper is that of implementing reactive control for UAV autonomy. The mission, safety and contingency planning are accomplished through a set of prioritized parallel controllers to produce a composite emergent control action. The parallel controllers are implemented using finite state machines and state diagrams. The development and evaluation of this autonomous controller is conducted on an engineering simulator being constructed at Defence R&amp;D Canada in Ottawa. The design and evaluation mission is an end-phase interception mission for maritime surveillance. Simulation trials are presented demonstrating the ability of UAV to adapt to varying situations.},
booktitle = {Proceedings of the 2010 Spring Simulation Multiconference},
articleno = {40},
numpages = {9},
keywords = {finite state machines, autonomous systems, reactive control, robotics, unmanned air vehicles},
location = {Orlando, Florida},
series = {SpringSim '10}
}

@article{10.1145/3341570,
author = {Yoon, Hyung-Jin and Widdowson, Christopher and Marinho, Thiago and Wang, Ranxiao Frances and Hovakimyan, Naira},
title = {Socially Aware Path Planning for a Flying Robot in Close Proximity of Humans},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
issn = {2378-962X},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3341570},
doi = {10.1145/3341570},
abstract = {In this article, we present a preliminary motion planning framework for a cyber-physical system consisting of a human and a flying robot in vicinity. The motion planning of the flying robot takes into account the human’s safety perception. We aim to determine a parametric model for the human’s safety perception based on test data. We use virtual reality as a safe testing environment to collect safety perception data reflected on galvanic skin response (GSR) from the test subjects experiencing a flying robot in their vicinity. The GSR signal contains both meaningful information driven by the interaction with the robot and also disturbances from unknown factors. To address the issue, we use two parametric models to approximate the GSR data: (1) a function of the robot’s position and velocity and (2) a random distribution. Intuitively, we need to choose the more likely model given the data. When GSR is statistically independent of the flying robot, then the random distribution should be selected instead of the function of the robot’s position and velocity. We implement the intuitive idea under the framework of hidden Markov model (HMM) estimation. As a result, the proposed HMM-based model improves the likelihood compared to the Gaussian noise model, which does not make a distinction between relevant and irrelevant samples due to unknown factors. We also present a numerical optimal path planning method that considers the safety perception model while ensuring spatial separation from the obstacle despite the time discretization. Optimal paths generated using the proposed model result in a reasonably safe distance from the human. In contrast, the trajectories generated by the standard regression model with the Gaussian noise assumption, without consideration of unknown factors, have undesirable shapes.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = {sep},
articleno = {41},
numpages = {24},
keywords = {Human-robot interaction, optimal path planning, hidden Markov model}
}

@inproceedings{10.1145/2818346.2820741,
author = {Iqbal, Asif and Busso, Carlos and Gans, Nicholas R.},
title = {Adjacent Vehicle Collision Warning System Using Image Sensor and Inertial Measurement Unit},
year = {2015},
isbn = {9781450339124},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2818346.2820741},
doi = {10.1145/2818346.2820741},
abstract = {Advanced driver assistance systems are the newest addition to vehicular technology. Such systems use a wide array of sensors to provide a superior driving experience. Vehicle safety and driver alert are important parts of these system. This paper proposes a driver alert system to prevent and mitigate adjacent vehicle collisions by proving warning information of on-road vehicles and possible collisions. A dynamic Bayesian network (DBN) is utilized to fuse multiple sensors to provide driver awareness. It detects oncoming adjacent vehicles and gathers ego vehicle motion characteristics using an on-board camera and inertial measurement unit (IMU). A histogram of oriented gradient feature based classifier is used to detect any adjacent vehicles. Vehicles front-rear end and side faces were considered in training the classifier. Ego vehicles heading, speed and acceleration are captured from the IMU and feed into the DBN. The network parameters were learned from data via expectation maximization(EM) algorithm. The DBN is designed to provide two type of warning to the driver, a cautionary warning and a brake alert for possible collision with other vehicles. Experiments were completed on multiple public databases, demonstrating successful warnings and brake alerts in most situations.},
booktitle = {Proceedings of the 2015 ACM on International Conference on Multimodal Interaction},
pages = {291–298},
numpages = {8},
keywords = {expectation maximization, dynamic bayesian network, vehicle detection, inertial measurement unit, driver assistance system},
location = {Seattle, Washington, USA},
series = {ICMI '15}
}

@article{10.1145/2723871,
author = {Johnson, Taylor T. and Bak, Stanley and Caccamo, Marco and Sha, Lui},
title = {Real-Time Reachability for Verified Simplex Design},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {1539-9087},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2723871},
doi = {10.1145/2723871},
abstract = {The Simplex architecture ensures the safe use of an unverifiable complex/smart controller by using it in conjunction with a verified safety controller and verified supervisory controller (switching logic). This architecture enables the safe use of smart, high-performance, untrusted, and complex control algorithms to enable autonomy without requiring the smart controllers to be formally verified or certified. Simplex incorporates a supervisory controller that will take over control from the unverified complex/smart controller if it misbehaves and use a safety controller. The supervisory controller should (1) guarantee that the system never enters an unsafe state (safety), but should also (2) use the complex/smart controller as much as possible (minimize conservatism). The problem of precisely and correctly defining the switching logic of the supervisory controller has previously been considered either using a control-theoretic optimization approach or through an offline hybrid-systems reachability computation. In this work, we show that a combined online/offline approach that uses aspects of the two earlier methods, along with a real-time reachability computation, also maintains safety, but with significantly less conservatism, allowing the complex controller to be used more frequently. We demonstrate the advantages of this unified approach on a saturated inverted pendulum system, in which the verifiable region of attraction is over twice as large compared to the earlier approach. Additionally, to validate the claims that the real-time reachability approach may be implemented on embedded platforms, we have ported and conducted embedded hardware studies using both ARM processors and Atmel AVR microcontrollers. This is the first ever demonstration of a hybrid-systems reachability computation in real time on actual embedded platforms, which required addressing significant technical challenges.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {feb},
articleno = {26},
numpages = {27},
keywords = {cyber-physical systems, Formal verification, hybrid systems}
}

@article{10.1145/3486616,
author = {Ebrahimi, Zahra and Klar, Dennis and Ekhtiyar, Mohammad Aasim and Kumar, Akash},
title = {Plasticine: A Cross-Layer Approximation Methodology for Multi-Kernel Applications through Minimally Biased, High-Throughput, and Energy-Efficient SIMD Soft Multiplier-Divider},
year = {2021},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {2},
issn = {1084-4309},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3486616},
doi = {10.1145/3486616},
abstract = {The rapid evolution of error-resilient programs intertwined with their quest for high throughput has motivated the use of Single Instruction, Multiple Data (SIMD) components in Field-Programmable Gate Arrays (FPGAs). Particularly, to exploit the error-resiliency of such applications, Cross-layer approximation paradigm has recently gained traction, the ultimate goal of which is to efficiently exploit approximation potentials across layers of abstraction. From circuit- to application-level, valuable studies have proposed various approximation techniques, albeit linked to four drawbacks: First, most of approximate multipliers and dividers operate only in SISD mode. Second, imprecise units are often substituted, merely in a single kernel of a multi-kernel application, with an end-to-end analysis in Quality of Results (QoR) and not in the gained performance. Third, state-of-the-art (SoA) strategies neglect the fact that each kernel contributes differently to the end-to-end QoR and performance metrics. Therefore, they lack in adopting a generic methodology for adjusting the approximation knobs to maximize performance gains for a user-defined quality constraint. Finally, multi-level techniques lack in being efficiently supported, from application-, to architecture-, to circuit-level, in a cohesive cross-layer hierarchy.In this article, we propose Plasticine, a cross-layer methodology for multi-kernel applications, which addresses the aforementioned challenges by efficiently utilizing the synergistic effects of a chain of techniques across layers of abstraction. To this end, we propose an application sensitivity analysis and a heuristic that tailor the precision at constituent kernels of the application by finding the most tolerable degree of approximations for each of consecutive kernels, while also satisfying the ultimate user-defined QoR. The chain of approximations is also effectively enabled in a cross-layer hierarchy, from application- to architecture- to circuit-level, through the plasticity of SIMD multiplier-dividers, each supporting dynamic precision variability along with hybrid functionality. The end-to-end evaluations of Plasticine&nbsp; on three multi-kernel applications employed in bio-signal processing, image processing, and moving object tracking for Unmanned Air Vehicles (UAV) demonstrate 41%–64%, 39%–62%, and 70%–86% improvements in area, latency, and Area-Delay-Product (ADP), respectively, over 32-bit fixed precision, with negligible loss in QoR. To springboard future research in reconfigurable and approximate computing communities, our implementations will be available and open-sourced at https://cfaed.tu-dresden.de/pd-downloads.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {nov},
articleno = {16},
numpages = {33},
keywords = {energy-efficiency, bio-signal processing, Mitchell’s algorithm, high-throughput, Single instruction multiple data, image processing, hybrid multiplier-divider, unmanned air vehicles}
}

@article{10.1145/3214283,
author = {Ruiz, Carlos and Pan, Shijia and Bannis, Adeola and Chen, Xinlei and Joe-Wong, Carlee and Noh, Hae Young and Zhang, Pei},
title = {IDrone: Robust Drone Identification through Motion Actuation Feedback},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {2},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3214283},
doi = {10.1145/3214283},
abstract = {Swarms of Unmanned Aerial Vehicles (drones) could provide great benefit when used for disaster response and indoor search and rescue scenarios. In these harsh environments where GPS availability cannot be ensured, prior work often relies on cameras for control and localization. This creates the challenge of identifying each drone, i.e., finding the association between each physical ID (such as their radio address) and their visual ID (such as an object tracker output). To address this problem, prior work relies on visual cues such as LEDs or colored markers to provide unique information for identification. However, these methods often increase deployment difficulty, are sensitive to environmental changes, not robust to distance and might require hardware changes.In this paper, we present IDrone, a robust physical drone identification system through motion matching and actuation feedback. The intuition is to (1) identify each drone by matching the motion detected through their inertial sensors and from an external camera, and (2) control the drones so they move in unique patterns that allow for fast identification, while minimizing the risk of collision involved in controlling drones with uncertain identification. To validate our approach, we conduct both simulation and real experimentation with autonomous drones for the simplified case of a stationary Spotter (powerful drone equipped with the camera). Overall, our initial results show that our approach offers a great tradeoff between fast identification and small collision probability. In particular, IDrone achieves faster identification time than safety-based baseline actuation (one-at-a-time), and significantly higher survival rate compared to fast, non-safety-based baseline actuation (random motion).},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {jul},
articleno = {80},
numpages = {22},
keywords = {physical actuation, multi-modal sensing, UAV swarm, camera, object identification}
}

@inproceedings{10.1145/3191442.3191447,
author = {Liu, Xiaofei and Yang, Tao and Li, Jing and Wang, Miao and Zhang, Yanning},
title = {Rapid Ground Car Detection on Aerial Infrared Images},
year = {2018},
isbn = {9781450363679},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3191442.3191447},
doi = {10.1145/3191442.3191447},
abstract = {With extensive applications of unmanned aircraft vehicle and infrared imagery's particular characteristic, ground car detections using infrared aerial images have been gradually applied to intelligent video surveillance. However, the aerial infrared images are always low-resolution and fuzzy, ground car detection is subjected to pose variations, view changes as well as surrounding radiations, this inevitably poses many challenges to detection task. In this paper, we present a novel approach toward ground car detection on infrared images via an end to end regressive neural network, other than background segmentation or foreground extraction. The main works of our research can be divided into three parts: (1) A unique aerial moving platform is built to collect a large amount of infrared images. It is achieved by assembling the DJI M-100 UAV and the FLTR TAU2 infrared sensor; (2) An aerial infrared car data set is unprecedentedly constructed. It is can be used for the following researches in this field; (3) A ground car detection model is trained. It can work in the moving and stationary cars in some severe environments. We test it on some low-resolution infrared images in a typical urban complicated environment and compare it with a state-of-the-art method. Experimental results demonstrate that the proposed approach instantly detects cars while keeping a low leak and false alarm ratio.},
booktitle = {Proceedings of the 2018 International Conference on Image and Graphics Processing},
pages = {33–37},
numpages = {5},
keywords = {End to end regressive neural network, Aerial infrared imagery, Rapid ground car detection, Unmanned aircraft vehicle},
location = {Hong Kong, Hong Kong},
series = {ICIGP 2018}
}

@inproceedings{10.1145/3372047.3372085,
author = {Du, Linlin and Huang, Yuhong and Tang, Yuhua and Huang, Da},
title = {A Distributed Control Method Based on Neighbor Reward for Robot Swarm},
year = {2019},
isbn = {9781450376228},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3372047.3372085},
doi = {10.1145/3372047.3372085},
abstract = {Real-time control strategy development remains challenging in the field of controlling multi-robot system. Due to frequent and massive interactions among robots, it is hard to implement a real-time control strategy in the multi-robot system. This phenomenon further limits the development of multi-robot application which adopts the real-time control strategy. To deal with above challenges, this paper proposes a decentralized control policy for multi-robot to avoid collision in an unknown environment. This policy adopts reward value to measure robots' motion and states. With reward value, robots can determine which neighbor robot to communicate with and to learn from, which decreases the interaction cost incurred in the multi-robot system. By the reward, the control strategy of each robot can be optimized through learning from its neighbors. Comparative experiments are conducted in a simulator to evaluate the effectiveness of our policy.},
booktitle = {Proceedings of the 2019 The 2nd International Conference on Robotics, Control and Automation Engineering},
pages = {17–22},
numpages = {6},
keywords = {Swarm robotics, Self-organization, Multi-robot systems},
location = {Lanzhou, China},
series = {RCAE 2019}
}

@inproceedings{10.1145/3469213.3470349,
author = {Yan, Jishuang and Hao, Yingguang},
title = {Recognition Method of Electrical Components Based on Improved YOLOv3},
year = {2021},
isbn = {9781450390200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3469213.3470349},
doi = {10.1145/3469213.3470349},
booktitle = {2021 2nd International Conference on Artificial Intelligence and Information Systems},
articleno = {146},
numpages = {5},
location = {Chongqing, China},
series = {ICAIIS 2021}
}

@inproceedings{10.1145/3490035.3490298,
author = {Nageli, Vinayak and Gorthi, Rama Krishna Sai Subrahmanyam and Jamal, Arshad},
title = {SiamRPN++D: Improved SiamRPN++ Using Cascaded Detector Sensing},
year = {2021},
isbn = {9781450375962},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3490035.3490298},
doi = {10.1145/3490035.3490298},
abstract = {This paper presents a novel and robust long-term tracking algorithm to address continuous target tracking problems. The continuous target tracking demands handling of correct re-initialization of the lost target when it reappears. The main limitation of the currently popular Siamese class of deep trackers is their inability to re-initialize a target when it is lost for sufficiently long duration or when it re-appears at a location away from the lost location. Most of the Siamese class of deep trackers search for the lost targets in a limited region, close to where it disappears. Hence, they fail in automated re-initialization, tracking resumption and maintaining track after long-term occlusion or tracker-loss. This puts a serious impediment on the current state-of-the-art deep tracker frameworks for many real applications. Here, we propose integration of a lightweight and efficient Cascaded Classifier based detection mechanism with the Siamese trackers for re-initialization of the target. While the proposed approach is generic and applicable to all Siamese class of deep trackers, we have taken SiamRPN++ as a base tracker to illustrate the effectiveness of our tracking framework. The proposition enables Cascaded Classifier based detector to adaptively direct the search region for the base tracker. Extensive experimental results on the well known tracking benchmark datasets such as UAV123, VOT2019, VOT2016, VOT2018 and VOT2018-LT show that the proposed integration significantly improves the performance of the base tracker under occlusion and tracker-loss scenarios. Further, the proposed tracker improves the precision by 1.71% and the recall by 13.98% over the base tracker for the long-term tracking on the VOT2018-LT dataset.},
booktitle = {Proceedings of the Twelfth Indian Conference on Computer Vision, Graphics and Image Processing},
articleno = {39},
numpages = {9},
keywords = {cascaded ensemble classifier detector, re-detection, long-term tracking, visual tracking},
location = {Jodhpur, India},
series = {ICVGIP '21}
}

@inproceedings{10.1145/3341016.3341025,
author = {Natarajan, Abhiram and Bharat, Keshav and Kaustubh, Guru Rajesh and N., Sai Praveen P. and Moharir, Minal and Srinath, N. K. and Subramanya, K. N.},
title = {An Approach to Real Time Parking Management Using Computer Vision},
year = {2019},
isbn = {9781450363228},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3341016.3341025},
doi = {10.1145/3341016.3341025},
abstract = {Automating vehicle statistics provides vital information that can be used in predicting the flow of traffic. Object detection based systems that use computer vision have produced drastic improvements in results over a sensor based approach. The methodology proposed in the paper follows an approach to perform this operation in real time and is currently being used in estimating the density of parking spaces, amongst other applications. The paper describes a 4 layer architecture for parking management which involves a HAAR based frame extraction from live video feed followed by a YOLOv2(You Only Look Once) deep neural network approach that supports real time detection of vehicles. The third layer emphasizes on the use of a mechanism that measures the number of vehicles entering a parking space by following the path traced by the centroid which is followed by a number plate recognition system that can retrace mishappenings to their source. The detection system developed using this model has been extensively tested on real time traffic in Bangalore and has generated accuracies close to 95% with video data that has been cross verified manually, making it much more effective than sensor based models.},
booktitle = {Proceedings of the 2nd International Conference on Control and Computer Vision},
pages = {18–22},
numpages = {5},
keywords = {Intelligent Transport Systems, Traffic Statistics, Parking Automation, Vehicle Detection, Real Time Object Detection, Computer Vision},
location = {Jeju, Republic of Korea},
series = {ICCCV 2019}
}

@inproceedings{10.1145/3387304.3387305,
author = {Ang, Wee Kiong and Teo, Wei Shun and Yakimenko, Oleg},
title = {Enabling an EO-Sensor-Based Capability to Detect and Track Multiple Moving Threats Onboard SUAS Operating in Cluttered Environments},
year = {2019},
isbn = {9781450372527},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3387304.3387305},
doi = {10.1145/3387304.3387305},
abstract = {In an increasingly complex environment for manned and unmanned traffic, technological advancements are thought to be able to provide alerts of the incoming threats autonomously and in a timely manner. This paper explores feasibility of integration of computer vision onboard a small unmanned aerial system (sUAS) to detect and track multiple moving ground and aerial targets in the electro-optical (EO) sensor field of view. Towards this objective, the paper discusses the essence of the multiple moving targets detection (MMTD) algorithm that has been developed and tested off line already, and then proceeds with an analysis of two candidate sUAS platforms to host and run the MMTD algorithm in real time from the standpoint of hardware and software architecture design and applicability. It further continues with a description of a series of tests that were conducted progressively to assess and evaluate the overall concept with multiple sUAS and unmanned ground vehicles representing the cluttered operational environments. These tests proved the MMTD algorithm to be successful in detecting and tracking multiple moving targets, thus laying a foundation for future research on implementation of the developed techniques for autonomous vision-based collision-free operations. The paper also discusses certain hardware and software compatibility issues revealed during this study.},
booktitle = {Proceedings of the 2019 2nd International Conference on Control and Robot Technology},
pages = {115–124},
numpages = {10},
keywords = {cluttered environment, situation awareness, optical flow, motion detection, unmanned aerial system, computer vision, electro-optical sensor},
location = {Jeju, Republic of Korea},
series = {ICCRT 2019}
}

@article{10.1145/3190579,
author = {Bertino, Elisa and Jahanshahi, Mohammad R.},
title = {Adaptive and Cost-Effective Collection of High-Quality Data for Critical Infrastructure and Emergency Management in Smart Cities—Framework and Challenges},
year = {2018},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
issn = {1936-1955},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3190579},
doi = {10.1145/3190579},
journal = {J. Data and Information Quality},
month = {may},
articleno = {1},
numpages = {6},
keywords = {device swarms, Civil engineering, edge computing}
}

@inproceedings{10.5555/3306127.3332121,
author = {St-Onge, David and Varadharajan, Vivek-Shankar and Beltrame, Giovanni},
title = {Tangible Robotic Fleet Control},
year = {2019},
isbn = {9781450363099},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {The use of multi-robot teams for field missions is increasing in number and scope, requiring command and control interfaces to be adapted to the operator's needs. Instead of working on interaction modalities that emerge from the engineering realm (screen, gestures or voice), we look at how the humanitarian and military logistics teams collaborate: using physical maps. In this demo, we present our command center, which consists of a swarm of small tabletop robots used to visualize and control a fleet of flying robots. To ensure the scalabilty and robustness of our control system, we leverage decentralized behaviors written in a swarm-specific programming language. We set an example scenario, where the operator must command the fleet to search an area for simulated features of interest using the tabletop robots over a map. The actions of the operator send the flying robots to individual waypoint targets. Meanwhile, the command center monitors the operator: if he is not alone, he may lack focus, and the fleet thus switches to an autonomous deployment mode until the operator's full attention is back.},
booktitle = {Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {2387–2389},
numpages = {3},
keywords = {aerial swarm systems, tangible interface, swarm interaction},
location = {Montreal QC, Canada},
series = {AAMAS '19}
}

@inproceedings{10.1145/3299869.3324955,
author = {Haynes, Brandon and Mazumdar, Amrita and Balazinska, Magdalena and Ceze, Luis and Cheung, Alvin},
title = {Visual Road: A Video Data Management Benchmark},
year = {2019},
isbn = {9781450356435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3299869.3324955},
doi = {10.1145/3299869.3324955},
abstract = {Recently, video database management systems (VDBMSs) have re-emerged as an active area of research and development. To accelerate innovation in this area, we present Visual Road, a benchmark that evaluates the performance of these systems. Visual Road comes with a data generator and a suite of queries over cameras positioned within a simulated metropolitan environment. Visual Road's video data is automatically generated with a high degree of realism, and annotated using a modern simulation and visualization engine. This allows for VDBMS performance evaluation while scaling up the size of the input data. Visual Road is designed to evaluate a broad variety of VDBMSs: real-time systems, systems for longitudinal analytical queries, systems processing traditional videos, and systems designed for 360 videos. We use the benchmark to evaluate three recent VDBMSs both in capabilities and performance.},
booktitle = {Proceedings of the 2019 International Conference on Management of Data},
pages = {972–987},
numpages = {16},
keywords = {multimedia databases, virtual reality video, benchmarking and performance evaluation, video data management},
location = {Amsterdam, Netherlands},
series = {SIGMOD '19}
}



@Article{rs12223809,
AUTHOR = {Hassanzadeh, Amirhossein and Murphy, Sean P. and Pethybridge, Sarah J. and van Aardt, Jan},
TITLE = {Growth Stage Classification and Harvest Scheduling of Snap Bean Using Hyperspectral Sensing: A Greenhouse Study},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3809},
URL = {https://www.mdpi.com/2072-4292/12/22/3809},
ISSN = {2072-4292},
ABSTRACT = {The agricultural industry suffers from a significant amount of food waste, some of which originates from an inability to apply site-specific management at the farm-level. Snap bean, a broad-acre crop that covers hundreds of thousands of acres across the USA, is not exempt from this need for informed, within-field, and spatially-explicit management approaches. This study aimed to assess the utility of machine learning algorithms for growth stage and pod maturity classification of snap bean (cv. Huntington), as well as detecting and discriminating spectral and biophysical features that lead to accurate classification results. Four major growth stages and six main sieve size pod maturity levels were evaluated for growth stage and pod maturity classification, respectively. A point-based in situ spectroradiometer in the visible-near-infrared and shortwave-infrared domains (VNIR-SWIR; 400&ndash;2500 nm) was used and the radiance values were converted to reflectance to normalize for any illumination change between samples. After preprocessing the raw data, we approached pod maturity assessment with multi-class classification and growth stage determination with binary and multi-class classification methods. Results from the growth stage assessment via the binary method exhibited accuracies ranging from 90&ndash;98%, with the best mathematical enhancement method being the continuum-removal approach. The growth stage multi-class classification method used raw reflectance data and identified a pair of wavelengths, 493 nm and 640 nm, in two basic transforms (ratio and normalized difference), yielding high accuracies (~79%). Pod maturity assessment detected narrow-band wavelengths in the VIS and SWIR region, separating between not ready-to-harvest and ready-to-harvest scenarios with classification measures at the ~78% level by using continuum-removed spectra. Our work is a best-case scenario, i.e., we consider it a stepping-stone to understanding snap bean harvest maturity assessment via hyperspectral sensing at a scalable level (i.e., airborne systems). Future work involves transferring the concepts to unmanned aerial system (UAS) field experiments and validating whether or not a simple multispectral camera, mounted on a UAS, could incorporate &lt; 10 spectral bands to meet the need of both growth stage and pod maturity classification in snap bean production.},
DOI = {10.3390/rs12223809}
}



@Article{rs12223831,
AUTHOR = {Ludwig, Marvin and M. Runge, Christian and Friess, Nicolas and Koch, Tiziana L. and Richter, Sebastian and Seyfried, Simon and Wraase, Luise and Lobo, Agustin and Sebastià, M.-Teresa and Reudenbach, Christoph and Nauss, Thomas},
TITLE = {Quality Assessment of Photogrammetric Methods—A Workflow for Reproducible UAS Orthomosaics},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3831},
URL = {https://www.mdpi.com/2072-4292/12/22/3831},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial systems (UAS) are cost-effective, flexible and offer a wide range of applications. If equipped with optical sensors, orthophotos with very high spatial resolution can be retrieved using photogrammetric processing. The use of these images in multi-temporal analysis and the combination with spatial data imposes high demands on their spatial accuracy. This georeferencing accuracy of UAS orthomosaics is generally expressed as the checkpoint error. However, the checkpoint error alone gives no information about the reproducibility of the photogrammetrical compilation of orthomosaics. This study optimizes the geolocation of UAS orthomosaics time series and evaluates their reproducibility. A correlation analysis of repeatedly computed orthomosaics with identical parameters revealed a reproducibility of 99% in a grassland and 75% in a forest area. Between time steps, the corresponding positional errors of digitized objects lie between 0.07 m in the grassland and 0.3 m in the forest canopy. The novel methods were integrated into a processing workflow to enhance the traceability and increase the quality of UAS remote sensing.},
DOI = {10.3390/rs12223831}
}



@Article{rs12223834,
AUTHOR = {Xia, Junshi and Yokoya, Naoto and Pham, Tien Dat},
TITLE = {Probabilistic Mangrove Species Mapping with Multiple-Source Remote-Sensing Datasets Using Label Distribution Learning in Xuan Thuy National Park, Vietnam},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3834},
URL = {https://www.mdpi.com/2072-4292/12/22/3834},
ISSN = {2072-4292},
ABSTRACT = {Mangrove forests play an important role in maintaining water quality, mitigating climate change impacts, and providing a wide range of ecosystem services. Effective identification of mangrove species using remote-sensing images remains a challenge. The combinations of multi-source remote-sensing datasets (with different spectral/spatial resolution) are beneficial to the improvement of mangrove tree species discrimination. In this paper, various combinations of remote-sensing datasets including Sentinel-1 dual-polarimetric synthetic aperture radar (SAR), Sentinel-2 multispectral, and Gaofen-3 full-polarimetric SAR data were used to classify the mangrove communities in Xuan Thuy National Park, Vietnam. The mixture of mangrove communities consisting of small and shrub mangrove patches is generally difficult to separate using low/medium spatial resolution. To alleviate this problem, we propose to use label distribution learning (LDL) to provide the probabilistic mapping of tree species, including Sonneratia caseolaris (SC), Kandelia obovata (KO), Aegiceras corniculatum (AC), Rhizophora stylosa (RS), and Avicennia marina (AM). The experimental results show that the best classification performance was achieved by an integration of Sentinel-2 and Gaofen-3 datasets, demonstrating that full-polarimetric Gaofen-3 data is superior to the dual-polarimetric Sentinel-1 data for mapping mangrove tree species in the tropics.},
DOI = {10.3390/rs12223834}
}



@Article{rs12223840,
AUTHOR = {Lukin, Vladimir and Vasilyeva, Irina and Krivenko, Sergey and Li, Fangfang and Abramov, Sergey and Rubel, Oleksii and Vozel, Benoit and Chehdi, Kacem and Egiazarian, Karen},
TITLE = {Lossy Compression of Multichannel Remote Sensing Images with Quality Control},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3840},
URL = {https://www.mdpi.com/2072-4292/12/22/3840},
ISSN = {2072-4292},
ABSTRACT = {Lossy compression is widely used to decrease the size of multichannel remote sensing data. Alongside this positive effect, lossy compression may lead to a negative outcome as making worse image classification. Thus, if possible, lossy compression should be carried out carefully, controlling the quality of compressed images. In this paper, a dependence between classification accuracy of maximum likelihood and neural network classifiers applied to three-channel test and real-life images and quality of compressed images characterized by standard and visual quality metrics is studied. The following is demonstrated. First, a classification accuracy starts to decrease faster when image quality due to compression ratio increasing reaches a distortion visibility threshold. Second, the classes with a wider distribution of features start to &ldquo;take pixels&rdquo; from classes with narrower distributions of features. Third, a classification accuracy might depend essentially on the training methodology, i.e., whether features are determined from original data or compressed images. Finally, the drawbacks of pixel-wise classification are shown and some recommendations on how to improve classification accuracy are given.},
DOI = {10.3390/rs12223840}
}



@Article{rs12223839,
AUTHOR = {Tian, Xiaomin and Chen, Long and Zhang, Xiaoli and Chen, Erxue},
TITLE = {Improved Prototypical Network Model for Forest Species Classification in Complex Stand},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3839},
URL = {https://www.mdpi.com/2072-4292/12/22/3839},
ISSN = {2072-4292},
ABSTRACT = {Deep learning has become an effective method for hyperspectral image classification. However, the high band correlation and data volume associated with airborne hyperspectral images, and the insufficiency of training samples, present challenges to the application of deep learning in airborne image classification. Prototypical networks are practical deep learning networks that have demonstrated effectiveness in handling small-sample classification. In this study, an improved prototypical network is proposed (by adding L2 regularization to the convolutional layer and dropout to the maximum pooling layer) to address the problem of overfitting in small-sample classification. The proposed network has an optimal sample window for classification, and the window size is related to the area and distribution of the study area. After performing dimensionality reduction using principal component analysis, the time required for training using hyperspectral images shortened significantly, and the test accuracy increased drastically. Furthermore, when the size of the sample window was 27 &times; 27 after dimensionality reduction, the overall accuracy of forest species classification was 98.53%, and the Kappa coefficient was 0.9838. Therefore, by using an improved prototypical network with a sample window of an appropriate size, the network yielded desirable classification results, thereby demonstrating its suitability for the fine classification and mapping of tree species.},
DOI = {10.3390/rs12223839}
}



@Article{f11121239,
AUTHOR = {Scharvogel, Daniel and Brandmeier, Melanie and Weis, Manuel},
TITLE = {A Deep Learning Approach for Calamity Assessment Using Sentinel-2 Data},
JOURNAL = {Forests},
VOLUME = {11},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {1239},
URL = {https://www.mdpi.com/1999-4907/11/12/1239},
ISSN = {1999-4907},
ABSTRACT = {The number of severe storm events has increased in recent decades due to climate change. These storms are one of the main causes for timber loss in European forests and damaged areas are prone to further degradation by, for example, bark beetle infestations. Usually, manual mapping of damaged areas based on aerial photographs is conducted by forest departments. This is very time-consuming and therefore automatic detection of windthrows based on active and passive remote sensing data is an ongoing research topic. In this study we evaluated state-of-the-art Convolutional Neural Networks (CNNs) in combination with Geographic Information Systems (GIS) for calamity assessment. The study area is in in the northern part of Hesse (Germany) and was covered by twelve Sentinel-2 scenes from 2018. Labels of damaged areas from the Friedericke storm (18 January 2018) were provided by HessenForst. We conducted several experiments based on a custom U-Net setup to derive the optimal architecture and input data as well as to assess the transferability of the model. Results highlight the possibility to detect damaged forest areas using Sentinel-2 data. Using a binary classification, accuracies of more than 92% were achieved with an Intersection over Union (IoU) score of 46.6%. The proposed workflow was integrated into ArcGIS and is suitable for fast detection of damaged areas directly after a storm and for disaster management but is limited by the deca-meter spatial resolution of the Sentinel-2 data.},
DOI = {10.3390/f11121239}
}



@Article{rs12233849,
AUTHOR = {Kolosov, Kirill and Miller, Alexander and Miller, Boris},
TITLE = {Robust Data Fusion of UAV Navigation Measurements with Application to the Landing System},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {3849},
URL = {https://www.mdpi.com/2072-4292/12/23/3849},
ISSN = {2072-4292},
ABSTRACT = {To perform precise approach and landing concerning an aircraft in automatic mode, local airfield-based landing systems are used. For joint processing of measurements of the onboard inertial navigation systems (INS), altimeters and local landing systems, the Kalman filter is usually used. The application of the quadratic criterion in the Kalman filter entails the well-known problem of high sensitivity of the estimate to anomalous measurement errors. During the automatic approach phase, abnormal navigation errors can lead to disaster, so the data fusion algorithm must automatically identify and isolate abnormal measurements. This paper presents a recurrent filtering algorithm that is resistant to anomalous errors in measurements and considers its application in the data fusion problem for landing system measurements with onboard sensor measurements&mdash;INS and altimeters. The robustness of the estimate is achieved through the combined use of the least modulus method and the Kalman filter. To detect and isolate failures the chi-square criterion is used. It makes possible the customization of the algorithm in accordance with the requirements for false alarm probability and the alarm missing probability. Testing results of the robust filtering algorithm are given both for synthesized data and for real measurements.},
DOI = {10.3390/rs12233849}
}



@Article{w12123300,
AUTHOR = {Elsayed, Salah and Hussein, Hend and Moghanm, Farahat S. and Khedher, Khaled M. and Eid, Ebrahem M. and Gad, Mohamed},
TITLE = {Application of Irrigation Water Quality Indices and Multivariate Statistical Techniques for Surface Water Quality Assessments in the Northern Nile Delta, Egypt},
JOURNAL = {Water},
VOLUME = {12},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {3300},
URL = {https://www.mdpi.com/2073-4441/12/12/3300},
ISSN = {2073-4441},
ABSTRACT = {Under sustainable development conditions, the water quality of irrigation systems is a complex issue which involves the combined effects of several surface water management parameters. Therefore, this work aims to enhance the surface water quality assessment and geochemical controlling mechanisms and to assess the validation of surface water networks for irrigation using six Water Quality Indices (WQIs) supported by multivariate modelling techniques, such as Principal Component Regression (PCR), Support Vector Machine Regression (SVMR) and Stepwise Multiple Linear Regression (SMLR). A total of 110 surface water samples from a network of surface water cannels during the summers of 2018 and 2019 were collected for this research and standard analytical techniques were used to measure 21 physical and chemical parameters. The physicochemical properties revealed that the major ions concentrations were reported in the following order: Ca2+ &gt; Na+ &gt; Mg2+ &gt; K+ and alkalinity &gt; SO42&minus; &gt; Cl&minus; &gt; NO3&minus; &gt; F&minus;. The trace elements concentrations were reported in the following order: Fe &gt; Mn &gt; B &gt; Cr &gt; Pb &gt; Ni &gt; Cu &gt; Zn &gt; Cd. The surface water belongs to the Ca2+-Mg2+-HCO3&minus; and Ca2+-Mg2+-Cl&minus;-SO42&minus; water types, under a stress of silicate weathering and reverse ion exchange process. The computation of WQI values across two years revealed that 82% of samples represent a high class and the remaining 18% constitute a medium class of water quality for irrigation use with respect to the Irrigation Water Quality (IWQ) value, while the Sodium Percentage (Na%) values across two years indicated that 96% of samples fell into in a healthy class and 4% fell into in a permissible class for irrigation. In addition, the Sodium Absorption Ratio (SAR), Permeability Index (PI), Kelley Index (KI) and Residual Sodium Carbonate (RSC) values revealed that all surface water samples were appropriate for irrigation use. The PCR and SVMR indicated accurate and robust models that predict the six WQIs in both datasets of the calibration (Cal.) and validation (Val.), with R2 values varying from 0.48 to 0.99. The SMLR presented estimated the six WQIs well, with an R2 value that ranged from 0.66 to 0.99. In conclusion, WQIs and multivariate statistical analyses are effective and applicable for assessing the surface water quality. The PCR, SVMR and SMLR models provided robust and reliable estimates of the different indices and showed the highest R2 and the highest slopes values close to 1.00, as well as minimum values of RMSE in all models.},
DOI = {10.3390/w12123300}
}



@Article{rs12233855,
AUTHOR = {Tseng, Chun-Wei and Song, Cheng-En and Wang, Su-Fen and Chen, Yi-Chin and Tu, Jien-Yi and Yang, Ci-Jian and Chuang, Chih-Wei},
TITLE = {Application of High-Resolution Radar Rain Data to the Predictive Analysis of Landslide Susceptibility under Climate Change in the Laonong Watershed, Taiwan},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {3855},
URL = {https://www.mdpi.com/2072-4292/12/23/3855},
ISSN = {2072-4292},
ABSTRACT = {Extreme rainfall has caused severe road damage and landslide disasters in mountainous areas. Rainfall forecasting derived from remote sensing data has been widely adopted for disaster prevention and early warning as a trend in recent years. By integrating high-resolution radar rain data, for example, the QPESUMS (quantitative precipitation estimation and segregation using multiple sensors) system provides a great opportunity to establish the extreme climate-based landslide susceptibility model, which would be helpful in the prevention of hillslope disasters under climate change. QPESUMS was adopted to obtain spatio-temporal rainfall patterns, and further, multi-temporal landslide inventories (2003&ndash;2018) would integrate with other explanatory factors and therefore, we can establish the logistic regression method for prediction of landslide susceptibility sites in the Laonong River watershed, which was devastated by Typhoon Morakot in 2009. Simulations of landslide susceptibility under the critical rainfall (300, 600, and 900 mm) were designed to verify the model&rsquo;s sensitivity. Due to the orographic effect, rainfall was concentrated at the low mountainous and middle elevation areas in the southern Laonong River watershed. Landslide change analysis indicates that the landslide ratio increased from 1.5% to 7.0% after Typhoon Morakot in 2009. Subsequently, the landslide ratio fluctuated between 3.5% and 4.5% after 2012, which indicates that the recovery of landslide areas is still in progress. The validation results showed that the calibrated model of 2005 is preferred in the general period, with an accuracy of 78%. For extreme rainfall typhoons, the calibrated model of 2009 would perform better (72%). This study presented that the integration of multi-temporal landslide inventories in a logistic regression model is capable of predicting rainfall-triggered landslide risk under climate change.},
DOI = {10.3390/rs12233855}
}



@Article{a13120308,
AUTHOR = {Nguyen Duc, Duy and Tran Huu, Thong and Nananukul, Narameth},
TITLE = {A Dynamic Route-Planning System Based on Industry 4.0 Technology},
JOURNAL = {Algorithms},
VOLUME = {13},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {308},
URL = {https://www.mdpi.com/1999-4893/13/12/308},
ISSN = {1999-4893},
ABSTRACT = {Due to the availability of Industry 4.0 technology, the application of big data analytics to automated systems is possible. The distribution of products between warehouses or within a warehouse is an area that can benefit from automation based on Industry 4.0 technology. In this paper, the focus was on developing a dynamic route-planning system for automated guided vehicles within a warehouse. A dynamic routing problem with real-time obstacles was considered in this research. A key problem in this research area is the lack of a real-time route-planning algorithm that is suitable for the implementation on automated guided vehicles with limited computing resources. An optimization model, as well as machine learning methodologies for determining an operational route for the problem, is proposed. An internal layout of the warehouse of a large consumer product distributor was used to test the performance of the methodologies. A simulation environment based on Gazebo was developed and used for testing the implementation of the route-planning system. Computational results show that the proposed machine learning methodologies were able to generate routes with testing accuracy of up to 98% for a practical internal layout of a warehouse with 18 storage racks and 67 path segments. Managerial insights into how the machine learning configuration affects the prediction accuracy are also provided.},
DOI = {10.3390/a13120308}
}



@Article{robotics9040100,
AUTHOR = {Roy, Raphaëlle N. and Drougard, Nicolas and Gateau, Thibault and Dehais, Frédéric and Chanel, Caroline P. C.},
TITLE = {How Can Physiological Computing Benefit Human-Robot Interaction?},
JOURNAL = {Robotics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {4},
ARTICLE-NUMBER = {100},
URL = {https://www.mdpi.com/2218-6581/9/4/100},
ISSN = {2218-6581},
ABSTRACT = {As systems grow more automatized, the human operator is all too often overlooked. Although human-robot interaction (HRI) can be quite demanding in terms of cognitive resources, the mental states (MS) of the operators are not yet taken into account by existing systems. As humans are no providential agents, this lack can lead to hazardous situations. The growing number of neurophysiology and machine learning tools now allows for efficient operators&rsquo; MS monitoring. Sending feedback on MS in a closed-loop solution is therefore at hand. Involving a consistent automated planning technique to handle such a process could be a significant asset. This perspective article was meant to provide the reader with a synthesis of the significant literature with a view to implementing systems that adapt to the operator&rsquo;s MS to improve human-robot operations&rsquo; safety and performance. First of all, the need for this approach is detailed regarding remote operation, an example of HRI. Then, several MS identified as crucial for this type of HRI are defined, along with relevant electrophysiological markers. A focus is made on prime degraded MS linked to time-on-task and task demands, as well as collateral MS linked to system outputs (i.e., feedback and alarms). Lastly, the principle of symbiotic HRI is detailed and one solution is proposed to include the operator state vector into the system using a mixed-initiative decisional framework to drive such an interaction.},
DOI = {10.3390/robotics9040100}
}



@Article{mti4040083,
AUTHOR = {Krassanakis, Vassilios and Kesidis, Anastasios L.},
TITLE = {MatMouse: A Mouse Movements Tracking and Analysis Toolbox for Visual Search Experiments},
JOURNAL = {Multimodal Technologies and Interaction},
VOLUME = {4},
YEAR = {2020},
NUMBER = {4},
ARTICLE-NUMBER = {83},
URL = {https://www.mdpi.com/2414-4088/4/4/83},
ISSN = {2414-4088},
ABSTRACT = {The present study introduces a new MATLAB toolbox, called MatMouse, suitable for the performance of experimental studies based on mouse movements tracking and analysis. MatMouse supports the implementation of task-based visual search experiments. The proposed toolbox provides specific functions which can be utilized for the experimental building and mouse tracking processes, the analysis of the recorded data in specific metrics, the production of related visualizations, as well as for the generation of statistical grayscale heatmaps which could serve as an objective ground truth product. MatMouse can be executed as a standalone package or integrated in existing MATLAB scripts and/or toolboxes. In order to highlight the functionalities of the introduced toolbox, a complete case study example is presented. MatMouse is freely distributed to the scientific community under the third version of GNU General Public License (GPL v3) on GitHub platform.},
DOI = {10.3390/mti4040083}
}



@Article{f11121252,
AUTHOR = {Zhou, Xiaocheng and Wang, Wenjun and Di, Liping and Lu, Lin and Guo, Liying},
TITLE = {Estimation of Tree Height by Combining Low Density Airborne LiDAR Data and Images Using the 3D Tree Model: A Case Study in a Subtropical Forest in China},
JOURNAL = {Forests},
VOLUME = {11},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {1252},
URL = {https://www.mdpi.com/1999-4907/11/12/1252},
ISSN = {1999-4907},
ABSTRACT = {In general, low density airborne LiDAR (Light Detection and Ranging) data are typically used to obtain the average height of forest trees. If the data could be used to obtain the tree height at the single tree level, it would greatly extend the usage of the data. Since the tree top position is often missed by the low density LiDAR pulse point, the estimated forest tree height at the single tree level is generally lower than the actual tree height when low density LiDAR data are used for the estimation. To resolve this problem, in this paper, a modified approach based on three-dimensional (3D) parameter tree model was adopted to reconstruct the tree height at the single tree level by combining the characteristics of high resolution remote sensing images and low density airborne LiDAR data. The approach was applied to two coniferous forest plots in the subtropical forest region, Fujian Province, China. The following conclusions were reached after analyzing the results: The marker-controlled watershed segmentation method is able to effectively extract the crown profile from sub meter-level resolution images without the aid of the height information of LiDAR data. The adaptive local maximum method satisfies the need for detecting the vertex of a single tree crown. The improved following-valley approach is available for estimating the tree crown diameter. The 3D parameter tree model, which can take advantage of low-density airborne LiDAR data and high resolution images, is feasible for improving the estimation accuracy of the tree height. Compared to the tree height results from only using the low density LiDAR data, this approach can achieve higher estimation accuracy. The accuracy of the tree height estimation at the single tree level for two test areas was more than 80%, and the average estimation error of the tree height was 0.7 m. The modified approach based on the three-dimensional parameter tree model can effectively increase the estimation accuracy of individual tree height by combining the characteristics of high resolution remote sensing images and low density airborne LiDAR data.},
DOI = {10.3390/f11121252}
}



@Article{rs12233877,
AUTHOR = {Aharon, Shlomi and Peleg, Zvi and Argaman, Eli and Ben-David, Roi and Lati, Ran N.},
TITLE = {Image-Based High-Throughput Phenotyping of Cereals Early Vigor and Weed-Competitiveness Traits},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {3877},
URL = {https://www.mdpi.com/2072-4292/12/23/3877},
ISSN = {2072-4292},
ABSTRACT = {Cereals grains are the prime component of the human diet worldwide. To promote food security and sustainability, new approaches to non-chemical weed control are needed. Early vigor cultivars with enhanced weed-competitiveness ability are a potential tool, nonetheless, the introduction of such trait in breeding may be a long and labor-intensive process. Here, two image-driven plant phenotyping methods were evaluated to facilitate effective and accurate selection for early vigor in cereals. For that purpose, two triticale genotypes differentiating in vigor and growth rate early in the season were selected as model plants: X-1010 (high) and Triticale1 (low). Two modeling approaches, 2-D and 3-D, were applied on the plants offering an evaluation of various morphological growth parameters for the triticale canopy development, under controlled and field conditions. The morphological advantage of X-1010 was observed only at the initial growth stages, which was reflected by significantly higher growth parameter values compared to the Triticale1 genotype. Both modeling approaches were sensitive enough to detect phenotypic differences in growth as early as 21 days after sowing. All growth parameters indicated a faster early growth of X-1010. However, the 2-D related parameter [projected shoot area (PSA)] is the most available one that can be extracted via end user-friendly imaging equipment. PSA provided adequate indication for the triticale early growth under weed-competition conditions and for the improved weed-competition ability. The adequate phenotyping ability for early growth and competition was robust under controlled and field conditions. PSA can be extracted from close and remote sensing platforms, thus, facilitate high throughput screening. Overall, the results of this study may improve cereal breeding for early vigor and weed-competitiveness.},
DOI = {10.3390/rs12233877}
}



@Article{s20236780,
AUTHOR = {Fu, Yanhua and Xie, Hongfei and Mao, Yachun and Ren, Tao and Xiao, Dong},
TITLE = {Copper Content Inversion of Copper Ore Based on Reflectance Spectra and the VTELM Algorithm},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {6780},
URL = {https://www.mdpi.com/1424-8220/20/23/6780},
ISSN = {1424-8220},
ABSTRACT = {Copper is an important national resource, which is widely used in various sectors of the national economy. The traditional detection of copper content in copper ore has the disadvantages of being time-consuming and high cost. Due to the many drawbacks of traditional detection methods, this paper proposes a new method for detecting copper content in copper ore, that is, through the spectral information of copper ore content detection method. First of all, we use chemical methods to analyze the copper content in a batch of copper ores, and accurately obtain the copper content in those ores. Then we do spectrometric tests on this batch of copper ore, and get accurate spectral data of copper ore. Based on the data obtained, we propose a new two hidden layer extreme learning machine algorithm with variable hidden layer nodes and use the regularization standard to constrain the extreme learning machine. Finally, the prediction model of copper content in copper ore is established by using the algorithm. Experiments show that this method of detecting copper ore content using spectral information is completely feasible, and the algorithm proposed in this paper can detect the copper content in copper ores faster and more accurately.},
DOI = {10.3390/s20236780}
}



@Article{rs12233892,
AUTHOR = {Egli, Sebastian and Höpke, Martin},
TITLE = {CNN-Based Tree Species Classification Using High Resolution RGB Image Data from Automated UAV Observations},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {3892},
URL = {https://www.mdpi.com/2072-4292/12/23/3892},
ISSN = {2072-4292},
ABSTRACT = {Data on the distribution of tree species are often requested by forest managers, inventory agencies, foresters as well as private and municipal forest owners. However, the automated detection of tree species based on passive remote sensing data from aerial surveys is still not sufficiently developed to achieve reliable results independent of the phenological stage, time of day, season, tree vitality and prevailing atmospheric conditions. Here, we introduce a novel tree species classification approach based on high resolution RGB image data gathered during automated UAV flights that overcomes these insufficiencies. For the classification task, a computationally lightweight convolutional neural network (CNN) was designed. We show that with the chosen CNN model architecture, average classification accuracies of 92% can be reached independently of the illumination conditions and the phenological stages of four different tree species. We also show that a minimal ground sampling density of 1.6 cm/px is needed for the classification model to be able to make use of the spatial-structural information in the data. Finally, to demonstrate the applicability of the presented approach to derive spatially explicit tree species information, a gridded product is generated that yields an average classification accuracy of 88%.},
DOI = {10.3390/rs12233892}
}



@Article{rs12233897,
AUTHOR = {Rossi, Lorenzo and Mammi, Irene and Pelliccia, Filippo},
TITLE = {UAV-Derived Multispectral Bathymetry},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {3897},
URL = {https://www.mdpi.com/2072-4292/12/23/3897},
ISSN = {2072-4292},
ABSTRACT = {Bathymetry is considered an important component in marine applications as several coastal erosion monitoring and engineering projects are carried out in this field. It is traditionally acquired via shipboard echo sounding, but nowadays, multispectral satellite imagery is also commonly applied using different remote sensing-based algorithms. Satellite-Derived Bathymetry (SDB) relates the surface reflectance of shallow coastal waters to the depth of the water column. The present study shows the results of the application of Stumpf and Lyzenga algorithms to derive the bathymetry for a small area using an Unmanned Aerial Vehicle (UAV), also known as a drone, equipped with a multispectral camera acquiring images in the same WorldView-2 satellite sensor spectral bands. A hydrographic Multibeam Echosounder survey was performed in the same period in order to validate the method&rsquo;s results and accuracy. The study area was approximately 0.5 km2 and located in Tuscany (Italy). Because of the high percentage of water in the images, a new methodology was also implemented for producing a georeferenced orthophoto mosaic. UAV multispectral images were processed to retrieve bathymetric data for testing different band combinations and evaluating the accuracy as a function of the density and quantity of sea bottom control points. Our results indicate that UAV-Derived Bathymetry (UDB) permits an accuracy of about 20 cm to be obtained in bathymetric mapping in shallow waters, minimizing operative expenses and giving the possibility to program a coastal monitoring surveying activity. The full sea bottom coverage obtained using this methodology permits detailed Digital Elevation Models (DEMs) comparable to a Multibeam Echosounder survey, and can also be applied in very shallow waters, where the traditional hydrographic approach requires hard fieldwork and presents operational limits.},
DOI = {10.3390/rs12233897}
}



@Article{sym12121965,
AUTHOR = {Zhu, Juncai and Wang, Zhizhong and Wang, Songwei and Chen, Shuli},
TITLE = {Moving Object Detection Based on Background Compensation and Deep Learning},
JOURNAL = {Symmetry},
VOLUME = {12},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {1965},
URL = {https://www.mdpi.com/2073-8994/12/12/1965},
ISSN = {2073-8994},
ABSTRACT = {Detecting moving objects in a video sequence is an important problem in many vision-based applications. In particular, detecting moving objects when the camera is moving is a difficult problem. In this study, we propose a symmetric method for detecting moving objects in the presence of a dynamic background. First, a background compensation method is used to detect the proposed region of motion. Next, in order to accurately locate the moving objects, we propose a convolutional neural network-based method called YOLOv3-SOD for detecting all objects in the image, which is lightweight and specifically designed for small objects. Finally, the moving objects are determined by fusing the results obtained by motion detection and object detection. Missed detections are recalled according to the temporal and spatial information in adjacent frames. A dataset is not currently available specifically for moving object detection and recognition, and thus, we have released the MDR105 dataset comprising three classes with 105 videos. Our experiments demonstrated that the proposed algorithm can accurately detect moving objects in various scenarios with good overall performance.},
DOI = {10.3390/sym12121965}
}



@Article{s20236819,
AUTHOR = {Alfano, Brigida and Barretta, Luigi and Del Giudice, Antonio and De Vito, Saverio and Di Francia, Girolamo and Esposito, Elena and Formisano, Fabrizio and Massera, Ettore and Miglietta, Maria Lucia and Polichetti, Tiziana},
TITLE = {A Review of Low-Cost Particulate Matter Sensors from the Developers’ Perspectives},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {6819},
URL = {https://www.mdpi.com/1424-8220/20/23/6819},
ISSN = {1424-8220},
ABSTRACT = {The concerns related to particulate matter&rsquo;s health effects alongside the increasing demands from citizens for more participatory, timely, and diffused air quality monitoring actions have resulted in increasing scientific and industrial interest in low-cost particulate matter sensors (LCPMS). In the present paper, we discuss 50 LCPMS models, a number that is particularly meaningful when compared to the much smaller number of models described in other recent reviews on the same topic. After illustrating the basic definitions related to particulate matter (PM) and its measurements according to international regulations, the device&rsquo;s operating principle is presented, focusing on a discussion of the several characterization methodologies proposed by various research groups, both in the lab and in the field, along with their possible limitations. We present an extensive review of the LCPMS currently available on the market, their electronic characteristics, and their applications in published literature and from specific tests. Most of the reviewed LCPMS can accurately monitor PM changes in the environment and exhibit good performances with accuracy that, in some conditions, can reach R2 values up to 0.99. However, such results strongly depend on whether the device is calibrated or not (using a reference method) in the operative environment; if not, R2 values lower than 0.5 are observed.},
DOI = {10.3390/s20236819}
}



@Article{rs12233920,
AUTHOR = {Noor Azmi, Aiman Nabilah and Bejo, Siti Khairunniza and Jahari, Mahirah and Muharam, Farrah Melissa and Yule, Ian and Husin, Nur Azuan},
TITLE = {Early Detection of Ganoderma boninense in Oil Palm Seedlings Using Support Vector Machines},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {3920},
URL = {https://www.mdpi.com/2072-4292/12/23/3920},
ISSN = {2072-4292},
ABSTRACT = {Ganodermaboninense (G. boninense) is a fungus that causes one of the most destructive diseases in oil palm plantations in Southeast Asia called basal stem rot (BSR), resulting in annual losses of up to USD 500 million. The G. boninense infects both mature trees and seedlings. The current practice of detection still depends on manual inspection by a human expert every two weeks. This study aimed to detect early G. boninense infections using visible-near infrared (VIS-NIR) hyperspectral images where there are no BSR symptoms present. Twenty-eight samples of oil palm seedlings at five months old were used whereby 15 of them were inoculated with the G. boninense pathogen. Five months later, spectral reflectance oil palm leaflets taken from fronds 1 (F1) and 2 (F2) were obtained from the VIS-NIR hyperspectral images. The significant bands were identified based on the high separation between uninoculated (U) and inoculated (I) seedlings. The results indicate that the differences were evidently seen in the NIR spectrum. The bands were later used as input parameters for the development of Support Vector Machine (SVM) classification models, and these bands were optimized according to the classification accuracy achieved by the classifiers. It was observed that the U and I seedlings were excellently classified with 100% accuracy using 35 bands and 18 bands of F1. However, the combination of F1 and F2 (F12) gave better accuracy than F2 and almost similar to F1 for specific classifiers. This finding will provide an advantage when using aerial images where there is no need to separate F1 and F2 during the data pre-processing stage.},
DOI = {10.3390/rs12233920}
}



@Article{rs12233925,
AUTHOR = {Pilaš, Ivan and Gašparović, Mateo and Novkinić, Alan and Klobučar, Damir},
TITLE = {Mapping of the Canopy Openings in Mixed Beech–Fir Forest at Sentinel-2 Subpixel Level Using UAV and Machine Learning Approach},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {3925},
URL = {https://www.mdpi.com/2072-4292/12/23/3925},
ISSN = {2072-4292},
ABSTRACT = {The presented study demonstrates a bi-sensor approach suitable for rapid and precise up-to-date mapping of forest canopy gaps for the larger spatial extent. The approach makes use of Unmanned Aerial Vehicle (UAV) red, green and blue (RGB) images on smaller areas for highly precise forest canopy mask creation. Sentinel-2 was used as a scaling platform for transferring information from the UAV to a wider spatial extent. Various approaches to an improvement in the predictive performance were examined: (I) the highest R2 of the single satellite index was 0.57, (II) the highest R2 using multiple features obtained from the single-date, S-2 image was 0.624, and (III) the highest R2 on the multitemporal set of S-2 images was 0.697. Satellite indices such as Atmospherically Resistant Vegetation Index (ARVI), Infrared Percentage Vegetation Index (IPVI), Normalized Difference Index (NDI45), Pigment-Specific Simple Ratio Index (PSSRa), Modified Chlorophyll Absorption Ratio Index (MCARI), Color Index (CI), Redness Index (RI), and Normalized Difference Turbidity Index (NDTI) were the dominant predictors in most of the Machine Learning (ML) algorithms. The more complex ML algorithms such as the Support Vector Machines (SVM), Random Forest (RF), Stochastic Gradient Boosting (GBM), Extreme Gradient Boosting (XGBoost), and Catboost that provided the best performance on the training set exhibited weaker generalization capabilities. Therefore, a simpler and more robust Elastic Net (ENET) algorithm was chosen for the final map creation.},
DOI = {10.3390/rs12233925}
}



@Article{rs12233926,
AUTHOR = {Deur, Martina and Gašparović, Mateo and Balenović, Ivan},
TITLE = {Tree Species Classification in Mixed Deciduous Forests Using Very High Spatial Resolution Satellite Imagery and Machine Learning Methods},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {3926},
URL = {https://www.mdpi.com/2072-4292/12/23/3926},
ISSN = {2072-4292},
ABSTRACT = {Spatially explicit information on tree species composition is important for both the forest management and conservation sectors. In combination with machine learning algorithms, very high-resolution satellite imagery may provide an effective solution to reduce the need for labor-intensive and time-consuming field-based surveys. In this study, we evaluated the possibility of using multispectral WorldView-3 (WV-3) satellite imagery for the classification of three main tree species (Quercus robur L., Carpinus betulus L., and Alnus glutinosa (L.) Geartn.) in a lowland, mixed deciduous forest in central Croatia. The pixel-based supervised classification was performed using two machine learning algorithms: random forest (RF) and support vector machine (SVM). Additionally, the contribution of gray level cooccurrence matrix (GLCM) texture features from WV-3 imagery in tree species classification was evaluated. Principal component analysis confirmed GLCM variance to be the most significant texture feature. Of the 373 visually interpreted reference polygons, 237 were used as training polygons and 136 were used as validation polygons. The validation results show relatively high overall accuracy (85%) for tree species classification based solely on WV-3 spectral characteristics and the RF classification approach. As expected, an improvement in classification accuracy was achieved by a combination of spectral and textural features. With the additional use of GLCM variance, the overall accuracy improved by 10% and 7% for RF and SVM classification approaches, respectively.},
DOI = {10.3390/rs12233926}
}



@Article{rs12233933,
AUTHOR = {Tridawati, Anggun and Wikantika, Ketut and Susantoro, Tri Muji and Harto, Agung Budi and Darmawan, Soni and Yayusman, Lissa Fajri and Ghazali, Mochamad Firman},
TITLE = {Mapping the Distribution of Coffee Plantations from Multi-Resolution, Multi-Temporal, and Multi-Sensor Data Using a Random Forest Algorithm},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {3933},
URL = {https://www.mdpi.com/2072-4292/12/23/3933},
ISSN = {2072-4292},
ABSTRACT = {Indonesia is the world&rsquo;s fourth largest coffee producer. Coffee plantations cover 1.2 million ha of the country with a production of 500 kg/ha. However, information regarding the distribution of coffee plantations in Indonesia is limited. This study aimed to assess the accuracy of classification model and determine its important variables for mapping coffee plantations. The model obtained 29 variables which derived from the integration of multi-resolution, multi-temporal, and multi-sensor remote sensing data, namely, pan-sharpened GeoEye-1, multi-temporal Sentinel 2, and DEMNAS. Applying a random forest algorithm (tree = 1000, mtry = all variables, minimum node size: 6), this model achieved overall accuracy, kappa statistics, producer accuracy, and user accuracy of 79.333%, 0.774, 92.000%, and 90.790%, respectively. In addition, 12 most important variables achieved overall accuracy, kappa statistics, producer accuracy, and user accuracy 79.333%, 0.774, 91.333%, and 84.570%, respectively. Our results indicate that random forest algorithm is efficient in mapping coffee plantations in an agroforestry system.},
DOI = {10.3390/rs12233933}
}



@Article{s20236896,
AUTHOR = {Buzzy, Michael and Thesma, Vaishnavi and Davoodi, Mohammadreza and Mohammadpour Velni, Javad},
TITLE = {Real-Time Plant Leaf Counting Using Deep Object Detection Networks},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {6896},
URL = {https://www.mdpi.com/1424-8220/20/23/6896},
ISSN = {1424-8220},
ABSTRACT = {The use of deep neural networks (DNNs) in plant phenotyping has recently received considerable attention. By using DNNs, valuable insights into plant traits can be readily achieved. While these networks have made considerable advances in plant phenotyping, the results are processed too slowly to allow for real-time decision-making. Therefore, being able to perform plant phenotyping computations in real-time has become a critical part of precision agriculture and agricultural informatics. In this work, we utilize state-of-the-art object detection networks to accurately detect, count, and localize plant leaves in real-time. Our work includes the creation of an annotated dataset of Arabidopsis plants captured using Cannon Rebel XS camera. These images and annotations have been complied and made publicly available. This dataset is then fed into a Tiny-YOLOv3 network for training. The Tiny-YOLOv3 network is then able to converge and accurately perform real-time localization and counting of the leaves. We also create a simple robotics platform based on an Android phone and iRobot create2 to demonstrate the real-time capabilities of the network in the greenhouse. Additionally, a performance comparison is conducted between Tiny-YOLOv3 and Faster R-CNN. Unlike Tiny-YOLOv3, which is a single network that does localization and identification in a single pass, the Faster R-CNN network requires two steps to do localization and identification. While with Tiny-YOLOv3, inference time, F1 Score, and false positive rate (FPR) are improved compared to Faster R-CNN, other measures such as difference in count (DiC) and AP are worsened. Specifically, for our implementation of Tiny-YOLOv3, the inference time is under 0.01 s, the F1 Score is over 0.94, and the FPR is around 24%. Last, transfer learning using Tiny-YOLOv3 to detect larger leaves on a model trained only on smaller leaves is implemented. The main contributions of the paper are in creating dataset (shared with the research community), as well as the trained Tiny-YOLOv3 network for leaf localization and counting.},
DOI = {10.3390/s20236896}
}



@Article{app10238641,
AUTHOR = {Ye, Xuan and Luo, Lan and Hou, Li and Duan, Yang and Wu, Yang},
TITLE = {Laser Ablation Manipulator Coverage Path Planning Method Based on an Improved Ant Colony Algorithm},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {8641},
URL = {https://www.mdpi.com/2076-3417/10/23/8641},
ISSN = {2076-3417},
ABSTRACT = {Coverage path planning on a complex free-form surface is a representative problem that has been steadily investigated in path planning and automatic control. However, most methods do not consider many optimisation conditions and cannot deal with complex surfaces, closed surfaces, and the intersection of multiple surfaces. In this study, a novel and efficient coverage path-planning method is proposed that considers trajectory optimisation information and uses point cloud data for environmental modelling. First, the point cloud data are denoised and simplified. Then, the path points are converted into the rotation angle of each joint of the manipulator. A mathematical model dedicated to energy consumption, processing time, and path smoothness as optimisation objectives is developed, and an improved ant colony algorithm is used to solve this problem. Two measures are proposed to prevent the algorithm from being trapped in a local optimum, thereby improving the global search ability of the algorithm. The standard test results indicate that the improved algorithm performs better than the ant colony algorithm and the max&ndash;min ant system. The numerical simulation results reveal that compared with the point cloud slicing technique, the proposed method can obtain a more efficient path. The laser ablation de-rusting experiment results specify the utility of the proposed approach.},
DOI = {10.3390/app10238641}
}



@Article{a13120323,
AUTHOR = {Fernandez, Stephanie Alvarez and Carvalho, Marcelo M. and Silva, Daniel G.},
TITLE = {A Hybrid Metaheuristic Algorithm for the Efficient Placement of UAVs},
JOURNAL = {Algorithms},
VOLUME = {13},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {323},
URL = {https://www.mdpi.com/1999-4893/13/12/323},
ISSN = {1999-4893},
ABSTRACT = {This work addresses the problem of using Unmanned Aerial Vehicles (UAV) to deploy a wireless aerial relay communications infrastructure for stations scattered on the ground. In our problem, every station in the network must be assigned to a single UAV, which is responsible for handling all data transfer on behalf of the stations that are assigned to it. Consequently, the placement of UAVs is key to achieving both network coverage and the maximization of the aggregate link capacities between UAVs and stations, and among the UAVs themselves. Because the complexity of this problem increases significantly with the number of stations to cover, for a given fixed number p of available UAVs, we model it as a single allocation p-hub median optimization problem, and we propose a hybrid metaheuristic algorithm to solve it. A series of numerical experiments illustrate the efficiency of the proposed algorithm against traditional optimization tools, which achieves high-quality results in very short time intervals, thus making it an attractive solution for real-world application scenarios.},
DOI = {10.3390/a13120323}
}



@Article{s20236934,
AUTHOR = {Hardie, Marcus},
TITLE = {Review of Novel and Emerging Proximal Soil Moisture Sensors for Use in Agriculture},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {6934},
URL = {https://www.mdpi.com/1424-8220/20/23/6934},
ISSN = {1424-8220},
ABSTRACT = {The measurement of soil moisture in agriculture is currently dominated by a small number of sensors, the use of which is greatly limited by their small sampling volume, high cost, need for close soil&ndash;sensor contact, and poor performance in saline, vertic and stony soils. This review was undertaken to explore the plethora of novel and emerging soil moisture sensors, and evaluate their potential use in agriculture. The review found that improvements to existing techniques over the last two decades are limited, and largely restricted to frequency domain reflectometry approaches. However, a broad range of new, novel and emerging means of measuring soil moisture were identified including, actively heated fiber optics (AHFO), high capacity tensiometers, paired acoustic / radio / seismic transceiver approaches, microwave-based approaches, radio frequency identification (RFID), hydrogels and seismoelectric approaches. Excitement over this range of potential new technologies is however tempered by the observation that most of these technologies are at early stages of development, and that few of these techniques have been adequately evaluated in situ agricultural soils.},
DOI = {10.3390/s20236934}
}



@Article{s20236936,
AUTHOR = {Balaniuk, Remis and Isupova, Olga and Reece, Steven},
TITLE = {Mining and Tailings Dam Detection in Satellite Imagery Using Deep Learning},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {6936},
URL = {https://www.mdpi.com/1424-8220/20/23/6936},
ISSN = {1424-8220},
ABSTRACT = {This work explores the combination of free cloud computing, free open-source software, and deep learning methods to analyze a real, large-scale problem: the automatic country-wide identification and classification of surface mines and mining tailings dams in Brazil. Locations of officially registered mines and dams were obtained from the Brazilian government open data resource. Multispectral Sentinel-2 satellite imagery, obtained and processed at the Google Earth Engine platform, was used to train and test deep neural networks using the TensorFlow 2 application programming interface (API) and Google Colaboratory (Colab) platform. Fully convolutional neural networks were used in an innovative way to search for unregistered ore mines and tailing dams in large areas of the Brazilian territory. The efficacy of the approach is demonstrated by the discovery of 263 mines that do not have an official mining concession. This exploratory work highlights the potential of a set of new technologies, freely available, for the construction of low cost data science tools that have high social impact. At the same time, it discusses and seeks to suggest practical solutions for the complex and serious problem of illegal mining and the proliferation of tailings dams, which pose high risks to the population and the environment, especially in developing countries.},
DOI = {10.3390/s20236936}
}



@Article{rs12233980,
AUTHOR = {Psomiadis, Emmanouil and Diakakis, Michalis and Soulis, Konstantinos X.},
TITLE = {Combining SAR and Optical Earth Observation with Hydraulic Simulation for Flood Mapping and Impact Assessment},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {3980},
URL = {https://www.mdpi.com/2072-4292/12/23/3980},
ISSN = {2072-4292},
ABSTRACT = {Timely mapping, measuring and impact assessment of flood events are crucial for the coordination of flood relief efforts and the elaboration of flood management and risk mitigation plans. However, this task is often challenging and time consuming with traditional land-based techniques. In this study, Sentinel-1 radar and Landsat images were utilized in collaboration with hydraulic modelling to obtain flood characteristics and land use/cover (LULC), and to assess flood impact in agricultural areas. Furthermore, indirect estimation of the recurrence interval of a flood event in a poorly gauged catchment was attempted by combining remote sensing (RS) and hydraulic modelling. To this end, a major flood event that occurred in Sperchios river catchment, in Central Greece, which is characterized by extensive farming activity was used as a case study. The synergistic usage of multitemporal RS products and hydraulic modelling has allowed the estimation of flood characteristics, such as extent, inundation depth, peak discharge, recurrence interval and inundation duration, providing valuable information for flood impact estimation and the future examination of flood hazard in poorly gauged basins. The capabilities of the ESA Sentinel-1 mission, which provides improved spatial and temporal analysis, allowing thus the mapping of the extent and temporal dynamics of flood events more accurately and independently from the weather conditions, were also highlighted. Both radar and optical data processing methods, i.e., thresholding, image differencing and water index calculation, provided similar and satisfactory results. Conclusively, multitemporal RS data and hydraulic modelling, with the selected techniques, can provide timely and useful flood observations during and right after flood disasters, applicable in a large part of the world where instrumental hydrological data are scarce and when an apace survey of the condition and information about temporal dynamics in the influenced region is crucial. However, future missions that will reduce further revisiting times will be valuable in this endeavor.},
DOI = {10.3390/rs12233980}
}



@Article{s20236953,
AUTHOR = {Mondal, Sabyasachi and Tsourdos, Antonios},
TITLE = {Autonomous Addition of Agents to an Existing Group Using Genetic Algorithm},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {6953},
URL = {https://www.mdpi.com/1424-8220/20/23/6953},
ISSN = {1424-8220},
ABSTRACT = {This paper presents an idea of how new agents can be added autonomously to a group of existing agents without changing the existing communication topology among them. Autonomous agent addition to existing Multi-Agent Systems (MASs) can give a strategic advantage during the execution of a critical beyond visual line-of-sight (BVLOS) mission. The addition of the agent essentially means that new connections with existing agents are established. It is obvious that the consensus control energy increases as the number of agent increases considering a specific consensus protocol. The objective of this work is to establish the new connections in a way such that the consensus energy increase due to the new agents is minimal. The updated topology, including new connections, must contain a spanning tree to maintain the stability of the MASs network. The updated optimal topology is obtained by solving minimum additional consensus control energy using the Two-Dimensional Genetic Algorithm. The results obtained are convincing.},
DOI = {10.3390/s20236953}
}



@Article{s20236957,
AUTHOR = {Mao, Kai and Zhu, Qiuming and Song, Maozhong and Hua, Boyu and Zhong, Weizhi and Ye, Xijuan},
TITLE = {A Geometry-Based Beamforming Channel Model for UAV mmWave Communications},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {6957},
URL = {https://www.mdpi.com/1424-8220/20/23/6957},
ISSN = {1424-8220},
ABSTRACT = {Considering the three-dimensional (3D) trajectory, 3D antenna array, and 3D beamforming of unmanned aerial vehicle (UAV), a novel non-stationary millimeter wave (mmWave) geometry-based stochastic model for UAV to vehicle communication channels is proposed. Based on the analysis results of measured and ray tracing simulation data of UAV mmWave communication links, the proposed parametric channel model is constructed by a line-of-sight path, a ground specular path, and two strongest single-bounce paths. Meanwhile, a new parameter computation method is also developed, which is divided into the deterministic (or geometry-based) part and the random (or empirical) part. The simulated power delay profile and power angle profile demonstrate that the statistical properties of proposed channel model are time-variant with respect to the scattering scenarios, positions and beam direction. Moreover, the simulation results of autocorrelation functions fit well with the theoretical ones as well as the measured ones.},
DOI = {10.3390/s20236957}
}



@Article{electronics9122076,
AUTHOR = {Mariscal-Harana, Jorge and Alarcón, Víctor and González, Fidel and Calvente, Juan José and Pérez-Grau, Francisco Javier and Viguria, Antidio and Ollero, Aníbal},
TITLE = {Audio-Based Aircraft Detection System for Safe RPAS BVLOS Operations},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {2076},
URL = {https://www.mdpi.com/2079-9292/9/12/2076},
ISSN = {2079-9292},
ABSTRACT = {For the Remotely Piloted Aircraft Systems (RPAS) market to continue its current growth rate, cost-effective &lsquo;Detect and Avoid&rsquo; systems that enable safe beyond visual line of sight (BVLOS) operations are critical. We propose an audio-based &lsquo;Detect and Avoid&rsquo; system, composed of microphones and an embedded computer, which performs real-time inferences using a sound event detection (SED) deep learning model. Two state-of-the-art SED models, YAMNet and VGGish, are fine-tuned using our dataset of aircraft sounds and their performances are compared for a wide range of configurations. YAMNet, whose MobileNet architecture is designed for embedded applications, outperformed VGGish both in terms of aircraft detection and computational performance. YAMNet&rsquo;s optimal configuration, with &gt;70% true positive rate and precision, results from combining data augmentation and undersampling with the highest available inference frequency (i.e., 10 Hz). While our proposed &lsquo;Detect and Avoid&rsquo; system already allows the detection of small aircraft from sound in real time, additional testing using multiple aircraft types is required. Finally, a larger training dataset, sensor fusion, or remote computations on cloud-based services could further improve system performance.},
DOI = {10.3390/electronics9122076}
}



@Article{rs12233986,
AUTHOR = {Hsu, Astrid J. and Kumagai, Joy and Favoretto, Fabio and Dorian, John and Guerrero Martinez, Benigno and Aburto-Oropeza, Octavio},
TITLE = {Driven by Drones: Improving Mangrove Extent Maps Using High-Resolution Remote Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {3986},
URL = {https://www.mdpi.com/2072-4292/12/23/3986},
ISSN = {2072-4292},
ABSTRACT = {This study investigated how different remote sensing techniques can be combined to accurately monitor mangroves. In this paper, we present a framework to use drone imagery to calculate correction factors which can improve the accuracy of satellite-based mangrove extent. We focus on semi-arid dwarf mangroves of Baja California Sur, Mexico, where the mangroves tend to be stunted in height and found in small patches, as well as larger forests. Using a DJI Phantom 4 Pro, we imaged mangroves and labeled the extent by manual classification in QGIS. Using ArcGIS, we compared satellite-based mangrove extent maps from Global Mangrove Watch (GMW) in 2016 and Mexico&rsquo;s national government agency (National Commission for the Knowledge and Use of Biodiversity, CONABIO) in 2015, with extent maps generated from in situ drone studies in 2018 and 2019. We found that satellite-based extent maps generally overestimated mangrove coverage compared to that of drone-based maps. To correct this overestimation, we developed a method to derive correction factors for GMW mangrove extent. These correction factors correspond to specific pixel patterns generated from a convolution analysis and mangrove coverage defined from drone imagery. We validated our model by using repeated k-fold cross-validation, producing an accuracy of 98.3% &plusmn; 2.1%. Overall, drones and satellites are complementary tools, and the rise of machine learning can help stakeholders further leverage the strengths of the two tools, to better monitor mangroves for local, national, and international management.},
DOI = {10.3390/rs12233986}
}



@Article{ijgi9120728,
AUTHOR = {Zhou, Dongbo and Liu, Shuangjian and Yu, Jie and Li, Hao},
TITLE = {A High-Resolution Spatial and Time-Series Labeled Unmanned Aerial Vehicle Image Dataset for Middle-Season Rice},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {9},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {728},
URL = {https://www.mdpi.com/2220-9964/9/12/728},
ISSN = {2220-9964},
ABSTRACT = {The existing remote sensing image datasets target the identification of objects, features, or man-made targets but lack the ability to provide the date and spatial information for the same feature in the time-series images. The spatial and temporal information is important for machine learning methods so that networks can be trained to support precision classification, particularly for agricultural applications of specific crops with distinct phenological growth stages. In this paper, we built a high-resolution unmanned aerial vehicle (UAV) image dataset for middle-season rice. We scheduled the UAV data acquisition in five villages of Hubei Province for three years, including 11 or 13 growing stages in each year that were accompanied by the annual agricultural surveying business. We investigated the accuracy of the vector maps for each field block and the precise information regarding the crops in the field by surveying each village and periodically arranging the UAV flight tasks on a weekly basis during the phenological stages. Subsequently, we developed a method to generate the samples automatically. Finally, we built a high-resolution UAV image dataset, including over 500,000 samples with the location and phenological growth stage information, and employed the imagery dataset in several machine learning algorithms for classification. We performed two exams to test our dataset. First, we used four classical deep learning networks for the fine classification of spatial and temporal information. Second, we used typical models to test the land cover on our dataset and compared this with the UCMerced Land Use Dataset and RSSCN7 Dataset. The results showed that the proposed image dataset supported typical deep learning networks in the classification task to identify the location and time of middle-season rice and achieved high accuracy with the public image dataset.},
DOI = {10.3390/ijgi9120728}
}



@Article{rs12234003,
AUTHOR = {Li, Yansheng and Chen, Ruixian and Zhang, Yongjun and Zhang, Mi and Chen, Ling},
TITLE = {Multi-Label Remote Sensing Image Scene Classification by Combining a Convolutional Neural Network and a Graph Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {4003},
URL = {https://www.mdpi.com/2072-4292/12/23/4003},
ISSN = {2072-4292},
ABSTRACT = {As one of the fundamental tasks in remote sensing (RS) image understanding, multi-label remote sensing image scene classification (MLRSSC) is attracting increasing research interest. Human beings can easily perform MLRSSC by examining the visual elements contained in the scene and the spatio-topological relationships of these visual elements. However, most of existing methods are limited by only perceiving visual elements but disregarding the spatio-topological relationships of visual elements. With this consideration, this paper proposes a novel deep learning-based MLRSSC framework by combining convolutional neural network (CNN) and graph neural network (GNN), which is termed the MLRSSC-CNN-GNN. Specifically, the CNN is employed to learn the perception ability of visual elements in the scene and generate the high-level appearance features. Based on the trained CNN, one scene graph for each scene is further constructed, where nodes of the graph are represented by superpixel regions of the scene. To fully mine the spatio-topological relationships of the scene graph, the multi-layer-integration graph attention network (GAT) model is proposed to address MLRSSC, where the GAT is one of the latest developments in GNN. Extensive experiments on two public MLRSSC datasets show that the proposed MLRSSC-CNN-GNN can obtain superior performance compared with the state-of-the-art methods.},
DOI = {10.3390/rs12234003}
}



@Article{app10238754,
AUTHOR = {Sultan, Wajeeha and Anjum, Nadeem and Stansfield, Mark and Ramzan, Naeem},
TITLE = {Hybrid Local and Global Deep-Learning Architecture for Salient-Object Detection},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {8754},
URL = {https://www.mdpi.com/2076-3417/10/23/8754},
ISSN = {2076-3417},
ABSTRACT = {Salient-object detection is a fundamental and the most challenging problem in computer vision. This paper focuses on the detection of salient objects, especially in low-contrast images. To this end, a hybrid deep-learning architecture is proposed where features are extracted on both the local and global level. These features are then integrated to extract the exact boundary of the object of interest in an image. Experimentation was performed on five standard datasets, and results were compared with state-of-the-art approaches. Both qualitative and quantitative analyses showed the robustness of the proposed architecture.},
DOI = {10.3390/app10238754}
}



@Article{agronomy10121926,
AUTHOR = {Lyu, Hong-Kun and Yun, Sanghun and Choi, Byeongdae},
TITLE = {Machine Learning Feature Extraction Based on Binary Pixel Quantification Using Low-Resolution Images for Application of Unmanned Ground Vehicles in Apple Orchards},
JOURNAL = {Agronomy},
VOLUME = {10},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {1926},
URL = {https://www.mdpi.com/2073-4395/10/12/1926},
ISSN = {2073-4395},
ABSTRACT = {Deep learning and machine learning (ML) technologies have been implemented in various applications, and various agriculture technologies are being developed based on image-based object recognition technology. We propose an orchard environment free space recognition technology suitable for developing small-scale agricultural unmanned ground vehicle (UGV) autonomous mobile equipment using a low-cost lightweight processor. We designed an algorithm to minimize the amount of input data to be processed by the ML algorithm through low-resolution grayscale images and image binarization. In addition, we propose an ML feature extraction method based on binary pixel quantification that can be applied to an ML classifier to detect free space for autonomous movement of UGVs from binary images. Here, the ML feature is extracted by detecting the local-lowest points in segments of a binarized image and by defining 33 variables, including local-lowest points, to detect the bottom of a tree trunk. We trained six ML models to select a suitable ML model for trunk bottom detection among various ML models, and we analyzed and compared the performance of the trained models. The ensemble model demonstrated the best performance, and a test was performed using this ML model to detect apple tree trunks from 100 new images. Experimental results indicate that it is possible to recognize free space in an apple orchard environment by learning using approximately 100 low-resolution grayscale images.},
DOI = {10.3390/agronomy10121926}
}



@Article{electronics9122091,
AUTHOR = {Wolf, Ádám and Troll, Péter and Romeder-Finger, Stefan and Archenti, Andreas and Széll, Károly and Galambos, Péter},
TITLE = {A Benchmark of Popular Indoor 3D Reconstruction Technologies: Comparison of ARCore and RTAB-Map},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {2091},
URL = {https://www.mdpi.com/2079-9292/9/12/2091},
ISSN = {2079-9292},
ABSTRACT = {The fast evolution in computational and sensor technologies brings previously niche solutions to a wider userbase. As such, 3D reconstruction technologies are reaching new use-cases in scientific and everyday areas where they were not present before. Cost-effective and easy-to-use solutions include camera-based 3D scanning techniques, such as photogrammetry. This paper provides an overview of the available solutions and discusses in detail the depth-image based Real-time Appearance-based Mapping (RTAB-Map) technique as well as a smartphone-based solution that utilises ARCore, the Augmented Reality (AR) framework of Google. To qualitatively compare the two 3D reconstruction technologies, a simple length measurement-based method was applied with a purpose-designed reference object. The captured data were then analysed by a processing algorithm. In addition to the experimental results, specific case studies are briefly discussed, evaluating the applicability based on the capabilities of the technologies. As such, the paper presents the use-case of interior surveying in an automated laboratory as well as an example for using the discussed techniques for landmark surveying. The major findings are that point clouds created with these technologies provide a direction- and shape-accurate model, but those contain mesh continuity errors, and the estimated scale factor has a large standard deviation.},
DOI = {10.3390/electronics9122091}
}



@Article{rs12244010,
AUTHOR = {Liu, Xiang and Liu, Huiyu and Datta, Pawanjeet and Frey, Julian and Koch, Barbara},
TITLE = {Mapping an Invasive Plant Spartina alterniflora by Combining an Ensemble One-Class Classification Algorithm with a Phenological NDVI Time-Series Analysis Approach in Middle Coast of Jiangsu, China},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4010},
URL = {https://www.mdpi.com/2072-4292/12/24/4010},
ISSN = {2072-4292},
ABSTRACT = {Spartina alterniflora (S. alterniflora) is one of the worst plant invaders in the coastal wetlands of China. Accurate and repeatable mapping of S. alterniflora invasion is essential to develop cost-effective management strategies for conserving native biodiversity. Traditional remote-sensing-based mapping methods require a lot of fieldwork for sample collection. Moreover, our ability to detect this invasive species is still limited because of poor spectral separability between S. alterniflora and its co-dominant native plants. Therefore, we proposed a novel scheme that uses an ensemble one-class classifier (EOCC) in combination with phenological Normalized Difference Vegetation Index (NDVI) time-series analysis (TSA) to detect S. alterniflora. We evaluated the performance of the EOCC algorithm in two scenarios, i.e., single-scene analysis (SSA) and NDVI-TSA in the core zones of Yancheng National Natural Reserve (YNNR). Meanwhile, a fully supervised classifier support vector machine (SVM) was tested in the two scenarios for comparison. With these scenarios, the crucial phenological stages and the advantage of phenological NDVI-TSA in S. alterniflora recognition were also investigated. Results indicated the EOCC using only positive training data performed similarly well with the SVM trained on complete training data in the YNNR. Moreover, the EOCC algorithm presented a more robust transferability with notably higher classification accuracy than the SVM when being transferred to a second site, without a second training. Furthermore, when combined with the phenological NDVI-TSA, the EOCC algorithm presented more balanced sensitivity&ndash;specificity result, showing slightly better transferability than it performed in the best phenological stage (i.e., senescence stage of November). The achieved results (overall accuracy (OA), Kappa, and true skill statistic (TSS) were 92.92%, 0.843, and 0.834 for the YNNR, and OA, Kappa, and TSS were 90.94%, 0.815, and 0.825 for transferability to the non-training site) suggest that our detection scheme has a high potential for the mapping of S. alterniflora across different areas, and the EOCC algorithm can be a viable alternative to traditional supervised classification method for invasive plant detection.},
DOI = {10.3390/rs12244010}
}



@Article{en13246496,
AUTHOR = {Pierdicca, Roberto and Paolanti, Marina and Felicetti, Andrea and Piccinini, Fabio and Zingaretti, Primo},
TITLE = {Automatic Faults Detection of Photovoltaic Farms: solAIr, a Deep Learning-Based System for Thermal Images},
JOURNAL = {Energies},
VOLUME = {13},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {6496},
URL = {https://www.mdpi.com/1996-1073/13/24/6496},
ISSN = {1996-1073},
ABSTRACT = {Renewable energy sources will represent the only alternative to limit fossil fuel usage and pollution. For this reason, photovoltaic (PV) power plants represent one of the main systems adopted to produce clean energy. Monitoring the state of health of a system is fundamental. However, these techniques are time demanding, cause stops to the energy generation, and often require laboratory instrumentation, thus being not cost-effective for frequent inspections. Moreover, PV plants are often located in inaccessible places, making any intervention dangerous. In this paper, we propose solAIr, an artificial intelligence system based on deep learning for anomaly cells detection in photovoltaic images obtained from unmanned aerial vehicles equipped with a thermal infrared sensor. The proposed anomaly cells detection system is based on the mask region-based convolutional neural network (Mask R-CNN) architecture, adopted because it simultaneously performs object detection and instance segmentation, making it useful for the automated inspection task. The proposed system is trained and evaluated on the photovoltaic thermal images dataset, a publicly available dataset collected for this work. Furthermore, the performances of three state-of-art deep neural networks, (DNNs) including UNet, FPNet and LinkNet, are compared and evaluated. Results show the effectiveness and the suitability of the proposed approach in terms of intersection over union (IoU) and the Dice coefficient.},
DOI = {10.3390/en13246496}
}



@Article{s20247061,
AUTHOR = {Yang, Zhao and Tang, Rong and Bao, Jie and Lu, Jiahuan and Zhang, Zhijie},
TITLE = {A Real-Time Trajectory Prediction Method of Small-Scale Quadrotors Based on GPS Data and Neural Network},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {7061},
URL = {https://www.mdpi.com/1424-8220/20/24/7061},
ISSN = {1424-8220},
ABSTRACT = {This paper proposes a real-time trajectory prediction method for quadrotors based on a bidirectional gated recurrent unit model. Historical trajectory data of ten types of quadrotors were obtained. The bidirectional gated recurrent units were constructed and utilized to learn the historic data. The prediction results were compared with the traditional gated recurrent unit method to test its prediction performance. The efficiency of the proposed algorithm was investigated by comparing the training loss and training time. The results over the testing datasets showed that the proposed model produced better prediction results than the baseline models for all scenarios of the testing datasets. It was also found that the proposed model can converge to a stable state faster than the traditional gated recurrent unit model. Moreover, various types of training samples were applied and compared. With the same randomly selected test datasets, the performance of the prediction model can be improved by selecting the historical trajectory samples of the quadrotors close to the weight or volume of the target quadrotor for training. In addition, the performance of stable trajectory samples is significantly better than that with unstable trajectory segments with a frequent change of speed and direction with large angles.},
DOI = {10.3390/s20247061}
}



@Article{s20247071,
AUTHOR = {Kashiyama, Takehiro and Sobue, Hideaki and Sekimoto, Yoshihide},
TITLE = {Sky Monitoring System for Flying Object Detection Using 4K Resolution Camera},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {7071},
URL = {https://www.mdpi.com/1424-8220/20/24/7071},
ISSN = {1424-8220},
ABSTRACT = {The use of drones and other unmanned aerial vehicles has expanded rapidly in recent years. These devices are expected to enter practical use in various fields, such as taking measurements through aerial photography and transporting small and lightweight objects. Simultaneously, concerns over these devices being misused for terrorism or other criminal activities have increased. In response, several sensor systems have been developed to monitor drone flights. In particular, with the recent progress of deep neural network technology, the monitoring of systems using image processing has been proposed. This study developed a monitoring system for flying objects using a 4K camera and a state-of-the-art convolutional neural network model to achieve real-time processing. We installed a monitoring system in a high-rise building in an urban area during this study and evaluated the precision with which it could detect flying objects at different distances under different weather conditions. The results obtained provide important information for determining the accuracy of monitoring systems with image processing in practice.},
DOI = {10.3390/s20247071}
}



@Article{rs12244040,
AUTHOR = {Xu, Ke and Zhang, Jingchao and Li, Huaimin and Cao, Weixing and Zhu, Yan and Jiang, Xiaoping and Ni, Jun},
TITLE = {Spectrum- and RGB-D-Based Image Fusion for the Prediction of Nitrogen Accumulation in Wheat},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4040},
URL = {https://www.mdpi.com/2072-4292/12/24/4040},
ISSN = {2072-4292},
ABSTRACT = {The accurate estimation of nitrogen accumulation is of great significance to nitrogen fertilizer management in wheat production. To overcome the shortcomings of spectral technology, which ignores the anisotropy of canopy structure when predicting the nitrogen accumulation in wheat, resulting in low accuracy and unstable prediction results, we propose a method for predicting wheat nitrogen accumulation based on the fusion of spectral and canopy structure features. After depth images are repaired using a hole-filling algorithm, RGB images and depth images are fused through IHS transformation, and textural features of the fused images are then extracted in order to express the three-dimensional structural information of the canopy. The fused images contain depth information of the canopy, which breaks through the limitation of extracting canopy structure features from a two-dimensional image. By comparing the experimental results of multiple regression analyses and BP neural networks, we found that the characteristics of the canopy structure effectively compensated for the model prediction of nitrogen accumulation based only on spectral characteristics. Our prediction model displayed better accuracy and stability, with prediction accuracy values (R2) based on BP neural network for the leaf layer nitrogen accumulation (LNA) and shoot nitrogen accumulation (SNA) during a full growth period of 0.74 and 0.73, respectively, and corresponding relative root mean square errors (RRMSEs) of 40.13% and 35.73%.},
DOI = {10.3390/rs12244040}
}



@Article{ijgi9120739,
AUTHOR = {Boente, Carlos and Salgado, Lorena and Romero-Macías, Emilio and Colina, Arturo and López-Sánchez, Carlos A. and Gallego, José Luis R.},
TITLE = {Correlation between Geochemical and Multispectral Patterns in an Area Severely Contaminated by Former Hg-As Mining},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {9},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {739},
URL = {https://www.mdpi.com/2220-9964/9/12/739},
ISSN = {2220-9964},
ABSTRACT = {In the context of soil pollution, plants suffer stress when exposed to extreme concentrations of potentially toxic elements (PTEs). The alterations to the plants caused by such stressors can be monitored by multispectral imagery in the form of vegetation indices, which can inform pollution management strategies. Here we combined geochemistry and remote sensing techniques to offer a preliminary soil pollution assessment of a vast abandoned spoil heap in the surroundings of La Soterra&ntilde;a mining site (Asturias, Spain). To study the soil distribution of the PTEs over time, twenty-seven soil samples were randomly collected downstream of and around the main spoil heap. Furthermore, the area was covered by an unmanned aerial vehicle (UAV) carrying a high-resolution multispectral camera with four bands (red, green, red-edge and near infrared). Multielement analysis revealed mercury and arsenic as principal pollutants. Two indices (from a database containing up to 55 indices) offered a proper correlation with the concentration of PTEs. These were: CARI2, presenting a Pearson Coefficient (PC) of 0.89 for concentrations &gt;200 mg/kg of As; and NDVIg, PC of &minus;0.67 for &gt;40 mg/kg of Hg. The combined approach helps prediction of those areas susceptible to greatest pollution, thus reducing the costs of geochemical campaigns.},
DOI = {10.3390/ijgi9120739}
}



@Article{a13120333,
AUTHOR = {Celis, Raúl de and Solano, Pablo and Cadarso, Luis},
TITLE = {Applying Neural Networks in Aerial Vehicle Guidance to Simplify Navigation Systems},
JOURNAL = {Algorithms},
VOLUME = {13},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {333},
URL = {https://www.mdpi.com/1999-4893/13/12/333},
ISSN = {1999-4893},
ABSTRACT = {The Guidance, Navigation and Control (GNC) of air and space vehicles has been one of the spearheads of research in the aerospace field in recent times. Using Global Navigation Satellite Systems (GNSS) and inertial navigation systems, accuracy may be detached from range. However, these sensor-based GNC systems may cause significant errors in determining attitude and position. These effects can be ameliorated using additional sensors, independent of cumulative errors. The quadrant photodetector semiactive laser is a good candidate for such a purpose. However, GNC systems&rsquo; development and construction costs are high. Reducing costs, while maintaining safety and accuracy standards, is key for development in aerospace engineering. Advanced algorithms for getting such standards while eliminating sensors are cornerstone. The development and application of machine learning techniques to GNC poses an innovative path for reducing complexity and costs. Here, a new nonlinear hybridization algorithm, which is based on neural networks, to estimate the gravity vector is presented. Using a neural network means that once it is trained, the physical-mathematical foundations of flight are not relevant; it is the network that returns dynamics to be fed to the GNC algorithm. The gravity vector, which can be accurately predicted, is used to determine vehicle attitude without calling for gyroscopes. Nonlinear simulations based on real flight dynamics are used to train the neural networks. Then, the approach is tested and simulated together with a GNC system. Monte Carlo analysis is conducted to determine performance when uncertainty arises. Simulation results prove that the performance of the presented approach is robust and precise in a six-degree-of-freedom simulation environment.},
DOI = {10.3390/a13120333}
}



@Article{w12123488,
AUTHOR = {Son, Geunsoo and Kim, Dongsu and Kim, Young Do and Lyu, Siwan and Kim, Soojeong},
TITLE = {A Forecasting Method for Harmful Algal Bloom(HAB)-Prone Regions Allowing Preemptive Countermeasures Based only on Acoustic Doppler Current Profiler Measurements in a Large River},
JOURNAL = {Water},
VOLUME = {12},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {3488},
URL = {https://www.mdpi.com/2073-4441/12/12/3488},
ISSN = {2073-4441},
ABSTRACT = {Harmful algal blooms (HABs) have been recognized as a serious problem for aquatic ecosystems and a threat to drinking water systems. The proposed method aimed to develop a practical and rapid countermeasure, enabling preemptive responses to massive algal blooms, through which prior to the algal bloom season we can identify HAB-prone regions based on estimations of where harmful algae initiates and develops significantly. The HAB-prone regions were derived from temperature, depth, flow velocity, and sediment concentration data based only on acoustic Doppler current profilers (ADCPs) without relying further on supplementary data collection, such as the water quality. For HAB-prone regions, we employed hot-spot analysis using K-means clustering and the Getis-Ord G*, in conjunction with the spatial autocorrelation of Moran&rsquo;s I and the local index of spatial association (LISA). The validation of the derived HAB-prone regions was conducted for ADCP measurements located at the downstream of Nam and Nakdong River confluence, South Korea, which preceded three months of algal bloom season monitored by unmanned aerial vehicles (UAVs). The visual inspection demonstrated that the comparison resulted in an acceptable range of agreement and consistency between the predicted HAB-prone regions and actual UAV-based observations of actual algal blooms.},
DOI = {10.3390/w12123488}
}



@Article{jimaging6120137,
AUTHOR = {Bhuiyan, Md Abul Ehsan and Witharana, Chandi and Liljedahl, Anna K.},
TITLE = {Use of Very High Spatial Resolution Commercial Satellite Imagery and Deep Learning to Automatically Map Ice-Wedge Polygons across Tundra Vegetation Types},
JOURNAL = {Journal of Imaging},
VOLUME = {6},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {137},
URL = {https://www.mdpi.com/2313-433X/6/12/137},
ISSN = {2313-433X},
ABSTRACT = {We developed a high-throughput mapping workflow, which centers on deep learning (DL) convolutional neural network (CNN) algorithms on high-performance distributed computing resources, to automatically characterize ice-wedge polygons (IWPs) from sub-meter resolution commercial satellite imagery. We applied a region-based CNN object instance segmentation algorithm, namely the Mask R-CNN, to automatically detect and classify IWPs in North Slope of Alaska. The central goal of our study was to systematically expound the DLCNN model interoperability across varying tundra types (sedge, tussock sedge, and non-tussock sedge) and image scene complexities to refine the understanding of opportunities and challenges for regional-scale mapping applications. We corroborated quantitative error statistics along with detailed visual inspections to gauge the IWP detection accuracies. We found promising model performances (detection accuracies: 89% to 96% and classification accuracies: 94% to 97%) for all candidate image scenes with varying tundra types. The mapping workflow discerned the IWPs by exhibiting low absolute mean relative error (AMRE) values (0.17&ndash;0.23). Results further suggest the importance of increasing the variability of training samples when practicing transfer-learning strategy to map IWPs across heterogeneous tundra cover types. Overall, our findings demonstrate the robust performances of IWPs mapping workflow in multiple tundra landscapes.},
DOI = {10.3390/jimaging6120137}
}



@Article{ijgi9120743,
AUTHOR = {Murtiyoso, Arnadi and Veriandi, Mirza and Suwardhi, Deni and Soeksmantono, Budhy and Harto, Agung Budi},
TITLE = {Automatic Workflow for Roof Extraction and Generation of 3D CityGML Models from Low-Cost UAV Image-Derived Point Clouds},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {9},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {743},
URL = {https://www.mdpi.com/2220-9964/9/12/743},
ISSN = {2220-9964},
ABSTRACT = {Developments in UAV sensors and platforms in recent decades have stimulated an upsurge in its application for 3D mapping. The relatively low-cost nature of UAVs combined with the use of revolutionary photogrammetric algorithms, such as dense image matching, has made it a strong competitor to aerial lidar mapping. However, in the context of 3D city mapping, further 3D modeling is required to generate 3D city models which is often performed manually using, e.g., photogrammetric stereoplotting. The aim of the paper was to try to implement an algorithmic approach to building point cloud segmentation, from which an automated workflow for the generation of roof planes will also be presented. 3D models of buildings are then created using the roofs’ planes as a base, therefore satisfying the requirements for a Level of Detail (LoD) 2 in the CityGML paradigm. Consequently, the paper attempts to create an automated workflow starting from UAV-derived point clouds to LoD 2-compatible 3D model. Results show that the rule-based segmentation approach presented in this paper works well with the additional advantage of instance segmentation and automatic semantic attribute annotation, while the 3D modeling algorithm performs well for low to medium complexity roofs. The proposed workflow can therefore be implemented for simple roofs with a relatively low number of planar surfaces. Furthermore, the automated approach to the 3D modeling process also helps to maintain the geometric requirements of CityGML such as 3D polygon coplanarity vis-à-vis manual stereoplotting.},
DOI = {10.3390/ijgi9120743}
}



@Article{rs12244070,
AUTHOR = {Ellsäßer, Florian and Röll, Alexander and Ahongshangbam, Joyson and Waite, Pierre-André and Hendrayanto and Schuldt, Bernhard and Hölscher, Dirk},
TITLE = {Predicting Tree Sap Flux and Stomatal Conductance from Drone-Recorded Surface Temperatures in a Mixed Agroforestry System—A Machine Learning Approach},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4070},
URL = {https://www.mdpi.com/2072-4292/12/24/4070},
ISSN = {2072-4292},
ABSTRACT = {Plant transpiration is a key element in the hydrological cycle. Widely used methods for its assessment comprise sap flux techniques for whole-plant transpiration and porometry for leaf stomatal conductance. Recently emerging approaches based on surface temperatures and a wide range of machine learning techniques offer new possibilities to quantify transpiration. The focus of this study was to predict sap flux and leaf stomatal conductance based on drone-recorded and meteorological data and compare these predictions with in-situ measured transpiration. To build the prediction models, we applied classical statistical approaches and machine learning algorithms. The field work was conducted in an oil palm agroforest in lowland Sumatra. Random forest predictions yielded the highest congruence with measured sap flux (r2 = 0.87 for trees and r2 = 0.58 for palms) and confidence intervals for intercept and slope of a Passing-Bablok regression suggest interchangeability of the methods. Differences in model performance are indicated when predicting different tree species. Predictions for stomatal conductance were less congruent for all prediction methods, likely due to spatial and temporal offsets of the measurements. Overall, the applied drone and modelling scheme predicts whole-plant transpiration with high accuracy. We conclude that there is large potential in machine learning approaches for ecological applications such as predicting transpiration.},
DOI = {10.3390/rs12244070}
}



@Article{rs12244080,
AUTHOR = {Kavats, Olena and Khramov, Dmitriy and Sergieieva, Kateryna and Vasyliev, Volodymyr},
TITLE = {Monitoring of Sugarcane Harvest in Brazil Based on Optical and SAR Data},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4080},
URL = {https://www.mdpi.com/2072-4292/12/24/4080},
ISSN = {2072-4292},
ABSTRACT = {The algorithms for determining sugarcane harvest dates are proposed; the algorithms allow the ability to monitor large areas and are based on the publicly available Synthetic Aperture Radar (SAR) and optical satellite data. Algorithm 1 uses the NDVI (Normalized Difference Vegetation Index) time series derived from Sentinel-2 data. Sharp and continuous decrease in the NDVI values is the main sign of sugarcane harvest. The NDVI time series allows the ability to determine most harvest dates. The best estimates of the sugarcane areas harvested per month have been obtained from March to August 2018 when cloudy pixel percentage is less than 45% of the image area. Algorithm 2 of the harvest monitoring uses the coherence time series derived from Sentinel-1 Single Look Complex (SLC) images and optical satellite data. Low coherence, demonstrating sharp growth upon the harvest completion, corresponds to the harvest period. The NDVI time series trends were used to refine the algorithm. It is supposed that the descending NDVI trend corresponds to harvest. The algorithms were used to identify the harvest dates and calculate the harvested areas of the reference sample of 574 sugarcane parcels with a total area of 3745 ha in the state of S&atilde;o Paulo, Brazil. The harvested areas identified by visual interpretation coincide with the optical-data algorithm (algorithm 1) by 97%; the coincidence with the algorithm based on SAR and optical data (algorithm 2) is 90%. The main practical applications of the algorithms are harvest monitoring and identification of the harvested fields to estimate the harvested area.},
DOI = {10.3390/rs12244080}
}



@Article{f11121324,
AUTHOR = {Peng, Xi and Zhao, Anjiu and Chen, Yongfu and Chen, Qiao and Liu, Haodong and Wang, Juan and Li, Huayu},
TITLE = {Comparison of Modeling Algorithms for Forest Canopy Structures Based on UAV-LiDAR: A Case Study in Tropical China},
JOURNAL = {Forests},
VOLUME = {11},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {1324},
URL = {https://www.mdpi.com/1999-4907/11/12/1324},
ISSN = {1999-4907},
ABSTRACT = {Knowledge of forest structure is vital for sustainable forest management decisions. Terrestrial laser scanning cannot describe the canopy trees in a large area, and it is unclear whether unmanned aerial vehicle-light detection and ranging (UAV-LiDAR) data have the ability to capture the forest canopy structural parameters in tropical forests. In this study, we estimated five forest canopy structures (stand density (N), basic area (G), above-ground biomass (AGB), Lorey&rsquo;s mean height (HL), and under-crown height (hT)) with four modeling algorithms (linear regression (LR), bagged tree (BT), support vector regression (SVR), and random forest (RF)) based on UAV-LiDAR data and 60 sample plot data from tropical forests in Hainan and determined the optimal algorithms for the five canopy structures by comparing the performance of the four algorithms. First, we defined the canopy tree as a tree with a height &ge;70% HL. Then, UAV-LiDAR metrics were calculated, and the LiDAR metrics were screened by recursive feature elimination (RFE). Finally, a prediction model of the five forest canopy structural parameters was established by the four algorithms, and the results were compared. The metrics&rsquo; screening results show that the most important LiDAR indexes for estimating HL, AGB, and hT are the leaf area index and some height metrics, while the most important indexes for estimating N and G are the kurtosis of heights and the coefficient of variation of height. The relative root mean squared error (rRMSE) of five structure parameters showed the following: when modeling HL, the rRMSEs (10.60%&ndash;12.05%) obtained by the four algorithms showed little difference; when N was modeled, BT, RF, and SVR had lower rRMSEs (26.76%&ndash;27.44%); when G was modeled, the rRMSEs of RF and SVR (15.37%&ndash;15.87%) were lower; when hT was modeled, BT, RF, and SVR had lower rRMSEs (10.24%&ndash;11.07%); when AGB was modeled, RF had the lowest rRMSE (26.75%). Our results will help facilitate choosing LiDAR indexes and modeling algorithms for tropical forest resource inventories.},
DOI = {10.3390/f11121324}
}



@Article{s20247176,
AUTHOR = {Gou, Huabei and Guo, Xiao and Lou, Wenjie and Ou, Jiajun and Yuan, Jiace},
TITLE = {Path Following Control for Underactuated Airships with Magnitude and Rate Saturation},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {7176},
URL = {https://www.mdpi.com/1424-8220/20/24/7176},
ISSN = {1424-8220},
ABSTRACT = {This paper proposes a reinforcement learning (RL) based path following strategy for underactuated airships with magnitude and rate saturation. The Markov decision process (MDP) model for the control problem is established. Then an error bounded line-of-sight (LOS) guidance law is investigated to restrain the state space. Subsequently, a proximal policy optimization (PPO) algorithm is employed to approximate the optimal action policy through trial and error. Since the optimal action policy is generated from the action space, the magnitude and rate saturation can be avoided. The simulation results, involving circular, general, broken-line, and anti-wind path following tasks, demonstrate that the proposed control scheme can transfer to new tasks without adaptation, and possesses satisfying real-time performance and robustness.},
DOI = {10.3390/s20247176}
}



@Article{rs12244091,
AUTHOR = {Hussain, Nazar and Farooque, Aitazaz A. and Schumann, Arnold W. and McKenzie-Gopsill, Andrew and Esau, Travis and Abbas, Farhat and Acharya, Bishnu and Zaman, Qamar},
TITLE = {Design and Development of a Smart Variable Rate Sprayer Using Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4091},
URL = {https://www.mdpi.com/2072-4292/12/24/4091},
ISSN = {2072-4292},
ABSTRACT = {The uniform application (UA) of agrochemicals results in the over-application of harmful chemicals, increases crop input costs, and deteriorates the environment when compared with variable rate application (VA). A smart variable rate sprayer (SVRS) was designed, developed, and tested using deep learning (DL) for VA application of agrochemicals. Real-time testing of the SVRS took place for detecting and spraying and/or skipping lambsquarters weed and early blight infected and healthy potato plants. About 24,000 images were collected from potato fields in Prince Edward Island and New Brunswick under varying sunny, cloudy, and partly cloudy conditions and processed/trained using YOLOv3 and tiny-YOLOv3 models. Due to faster performance, the tiny-YOLOv3 was chosen to deploy in SVRS. A laboratory experiment was designed under factorial arrangements, where the two spraying techniques (UA and VA) and the three weather conditions (cloudy, partly cloudy, and sunny) were the two independent variables with spray volume consumption as a response variable. The experimental treatments had six repetitions in a 2 × 3 factorial design. Results of the two-way ANOVA showed a significant effect of spraying application techniques on volume consumption of spraying liquid (p-value &lt; 0.05). There was no significant effect of weather conditions and interactions between the two independent variables on volume consumption during weeds and simulated diseased plant detection experiments (p-value &gt; 0.05). The SVRS was able to save 42 and 43% spraying liquid during weeds and simulated diseased plant detection experiments, respectively. Water sensitive papers’ analysis showed the applicability of SVRS for VA with &gt;40% savings of spraying liquid by SVRS when compared with UA. Field applications of this technique would reduce the crop input costs and the environmental risks in conditions (weed and disease) like experimental testing.},
DOI = {10.3390/rs12244091}
}



@Article{rs12244097,
AUTHOR = {Hamilton, Dale and Levandovsky, Enoch and Hamilton, Nicholas},
TITLE = {Mapping Burn Extent of Large Wildland Fires from Satellite Imagery Using Machine Learning Trained from Localized Hyperspatial Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4097},
URL = {https://www.mdpi.com/2072-4292/12/24/4097},
ISSN = {2072-4292},
ABSTRACT = {Wildfires burn 4&ndash;10 million acres annually across the United States and wildland fire related damages and suppression costs have exceeded $13 billion for a single year. High-intensity wildfires contribute to post-fire erosion, degraded wildlife habitat, and loss of timber resources. Accurate and temporally adequate assessment of the effects of wildland fire on the environment is critical to improving the of wildland fire as a tool for restoring ecosystem resilience. Sensor miniaturization and small unmanned aircraft systems (sUAS) provide affordable, on-demand monitoring of wildland fire effects at a much finer spatial resolution than is possible with satellite imagery. The use of sUAS would allow researchers to obtain data with more detail at a much lower initial cost. Unfortunately, current regulatory and technical constraints prohibit the acquisition of imagery using sUAS for the entire extent of large fires. This research examined the use of sUAS imagery to train and validate burn severity and extent mapping of large wildland fires from various satellite images. Despite the lower resolution of the satellite image, the research utilized the advantages of satellite imagery such as global coverage, low cost, temporal stability, and spectral extent while leveraging the higher resolution of hyperspatial sUAS imagery for training and validating the mapping analytics.},
DOI = {10.3390/rs12244097}
}



@Article{f11121338,
AUTHOR = {Bianchi, Simone and Myllymaki, Mari and Siipilehto, Jouni and Salminen, Hannu and Hynynen, Jari and Valkonen, Sauli},
TITLE = {Comparison of Spatially and Nonspatially Explicit Nonlinear Mixed Effects Models for Norway Spruce Individual Tree Growth under Single-Tree Selection},
JOURNAL = {Forests},
VOLUME = {11},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {1338},
URL = {https://www.mdpi.com/1999-4907/11/12/1338},
ISSN = {1999-4907},
ABSTRACT = {Background and Objectives: Continuous cover forestry is of increasing importance, but operational forest growth models are still lacking. The debate is especially open if more complex spatial approaches would provide a worthwhile increase in accuracy. Our objective was to compare a nonspatial versus a spatial approach for individual Norway spruce tree growth models under single-tree selection cutting. Materials and Methods: We calibrated nonlinear mixed models using data from a long-term experiment in Finland (20 stands with 3538 individual trees for 10,238 growth measurements). We compared the use of nonspatial versus spatial predictors to describe the competitive pressure and its release after cutting. The models were compared in terms of Akaike Information Criteria (AIC), root mean square error (RMSE), and mean absolute bias (MAB), both with the training data and after cross-validation with a leave-one-out method at stand level. Results: Even though the spatial model had a lower AIC than the nonspatial model, RMSE and MAB of the two models were similar. Both models tended to underpredict growth for the highest observed values when the tree-level random effects were not used. After cross-validation, the aggregated predictions at stand level well represented the observations in both models. For most of the predictors, the use of values based on trees&rsquo; height rather than trees&rsquo; diameter improved the fit. After single-tree selection cutting, trees had a growth boost both in the first and second five-year period after cutting, however, with different predicted intensity in the two models. Conclusions: Under the research framework here considered, the spatial modeling approach was not more accurate than the nonspatial one. Regarding the single-tree selection cutting, an intervention regime spaced no more than 15 years apart seems necessary to sustain the individual tree growth. However, the model&rsquo;s fixed effect parts were not able to capture the high growth of the few fastest-growing trees, and a proper estimation of site potential is needed for uneven-aged stands.},
DOI = {10.3390/f11121338}
}



@Article{rs12244118,
AUTHOR = {Wang, Nan and Xue, Jie and Peng, Jie and Biswas, Asim and He, Yong and Shi, Zhou},
TITLE = {Integrating Remote Sensing and Landscape Characteristics to Estimate Soil Salinity Using Machine Learning Methods: A Case Study from Southern Xinjiang, China},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4118},
URL = {https://www.mdpi.com/2072-4292/12/24/4118},
ISSN = {2072-4292},
ABSTRACT = {Soil salinization, one of the most severe global land degradation problems, leads to the loss of arable land and declines in crop yields. Monitoring the distribution of salinized soil and degree of salinization is critical for management, remediation, and utilization of salinized soil; however, there is a lack of thorough assessment of various data sources including remote sensing and landscape characteristics for estimating soil salinity in arid and semi-arid areas. The overall goal of this study was to develop a framework for estimating soil salinity in diverse landscapes by fusing information from satellite images, landscape characteristics, and appropriate machine learning models. To explore the spatial distribution of soil salinity in southern Xinjiang, China, as a case study, we obtained 151 soil samples in a field campaign, which were analyzed in laboratory for soil electrical conductivity. A total of 35 indices including remote sensing classifiers (11), terrain attributes (3), vegetation spectral indices (8), and salinity spectral indices (13) were calculated or derived and correlated with soil salinity. Nine were used to model and estimate soil salinity using four predictive modelling approaches: partial least squares regression (PLSR), convolutional neural network (CNN), support vector machine (SVM) learning, and random forest (RF). Testing datasets were divided into vegetation-covered and bare soil samples and were used for accuracy assessment. The RF model was the best regression model in this study, with R2 = 0.75, and was most effective in revealing the spatial characteristics of salt distribution. Importance analysis and path modeling of independent variables indicated that environmental factors and soil salinity indices including digital elevation model (DEM), B10, and green atmospherically resistant vegetation index (GARI) showed the strongest contribution in soil salinity estimation. This showed a great promise in the measurement and monitoring of soil salinity in arid and semi-arid areas from the integration of remote sensing, landscape characteristics, and using machine learning model.},
DOI = {10.3390/rs12244118}
}



@Article{app10249013,
AUTHOR = {Manrique Escobar, Camilo Andrés and Pappalardo, Carmine Maria and Guida, Domenico},
TITLE = {A Parametric Study of a Deep Reinforcement Learning Control System Applied to the Swing-Up Problem of the Cart-Pole},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {9013},
URL = {https://www.mdpi.com/2076-3417/10/24/9013},
ISSN = {2076-3417},
ABSTRACT = {In this investigation, the nonlinear swing-up problem associated with the cart-pole system modeled as a multibody dynamical system is solved by developing a deep Reinforcement Learning (RL) controller. Furthermore, the sensitivity analysis of the deep RL controller applied to the cart-pole swing-up problem is carried out. To this end, the influence of modifying the physical properties of the system and the presence of dry friction forces are analyzed employing the cumulative reward during the task. Extreme limits for the modifications of the parameters are determined to prove that the neural network architecture employed in this work features enough learning capability to handle the task under modifications as high as 90% on the pendulum mass, as well as a 100% increment on the cart mass. As expected, the presence of dry friction greatly affects the performance of the controller. However, a post-training of the agent in the modified environment takes only thirty-nine episodes to find the optimal control policy, resulting in a promising path for further developments of robust controllers.},
DOI = {10.3390/app10249013}
}



@Article{s20247239,
AUTHOR = {Hacohen, Shlomi and Medina, Oded and Grinshpoun, Tal and Shvalb, Nir},
TITLE = {Improved GNSS Localization and Byzantine Detection in UAV Swarms},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {7239},
URL = {https://www.mdpi.com/1424-8220/20/24/7239},
ISSN = {1424-8220},
ABSTRACT = {Many tasks performed by swarms of unmanned aerial vehicles require localization. In many cases, the sensors that take part in the localization process suffer from inherent measurement errors. This problem is amplified when disruptions are added, either endogenously through Byzantine failures of agents within the swarm, or exogenously by some external source, such as a GNSS jammer. In this paper, we first introduce an improved localization method based on distance observation. Then, we devise schemes for detecting Byzantine agents, in scenarios of endogenous disruptions, and for detecting a disrupted area, in case the source of the problem is exogenous. Finally, we apply pool testing techniques to reduce the communication traffic and the computation time of our schemes. The optimal pool size should be chosen carefully, as very small or very large pools may impair the ability to identify the source/s of disruption. A set of simulated experiments demonstrates the effectiveness of our proposed methods, which enable reliable error estimation even amid disruptions. This work is the first, to the best of our knowledge, that embeds identification of endogenous and exogenous disruptions into the localization process.},
DOI = {10.3390/s20247239}
}



@Article{s20247245,
AUTHOR = {Shi, Chenqi and Niu, Xinyv and Li, Tao and Li, Sen and Huang, Chanjuan and Niu, Qiang},
TITLE = {Exploring Fast Fingerprint Construction Algorithm for Unmodulated Visible Light Indoor Localization},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {7245},
URL = {https://www.mdpi.com/1424-8220/20/24/7245},
ISSN = {1424-8220},
ABSTRACT = {The study of visible light indoor position has received considerable attention. The visible light indoor position has problems such as deployment difficulty and high cost. In our system, we propose a new fingerprint construction algorithm to simplify visible light indoor position. This method can realize the rapid construction of a visible fingerprint database and prove that the fingerprint database can be used repeatedly in different environments. We proved the theoretical feasibility of this method through theoretical derivation. We carried out extensive experiments in two classic real indoor environments. Experimental results show that reverse fingerprinting can be achieved. In 95% of cases, the positioning accuracy can be guaranteed to be less than 10 cm.},
DOI = {10.3390/s20247245}
}



@Article{rs12244135,
AUTHOR = {Rajendran, Ganesh B. and Kumarasamy, Uma M. and Zarro, Chiara and Divakarachari, Parameshachari B. and Ullo, Silvia L.},
TITLE = {Land-Use and Land-Cover Classification Using a Human Group-Based Particle Swarm Optimization Algorithm with an LSTM Classifier on Hybrid Pre-Processing Remote-Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4135},
URL = {https://www.mdpi.com/2072-4292/12/24/4135},
ISSN = {2072-4292},
ABSTRACT = {Land-use and land-cover (LULC) classification using remote sensing imagery plays a vital role in many environment modeling and land-use inventories. In this study, a hybrid feature optimization algorithm along with a deep learning classifier is proposed to improve the performance of LULC classification, helping to predict wildlife habitat, deteriorating environmental quality, haphazard elements, etc. LULC classification is assessed using Sat 4, Sat 6 and Eurosat datasets. After the selection of remote-sensing images, normalization and histogram equalization methods are used to improve the quality of the images. Then, a hybrid optimization is accomplished by using the local Gabor binary pattern histogram sequence (LGBPHS), the histogram of oriented gradient (HOG) and Haralick texture features, for the feature extraction from the selected images. The benefits of this hybrid optimization are a high discriminative power and invariance to color and grayscale images. Next, a human group-based particle swarm optimization (PSO) algorithm is applied to select the optimal features, whose benefits are a fast convergence rate and ease of implementation. After selecting the optimal feature values, a long short-term memory (LSTM) network is utilized to classify the LULC classes. Experimental results showed that the human group-based PSO algorithm with a LSTM classifier effectively well differentiates the LULC classes in terms of classification accuracy, recall and precision. A maximum improvement of 6.03% on Sat 4 and 7.17% on Sat 6 in LULC classification is reached when the proposed human group-based PSO with LSTM is compared to individual LSTM, PSO with LSTM, and Human Group Optimization (HGO) with LSTM. Moreover, an improvement of 2.56% in accuracy is achieved, compared to the existing models, GoogleNet, Visual Geometric Group (VGG), AlexNet, ConvNet, when the proposed method is applied.},
DOI = {10.3390/rs12244135}
}



@Article{agronomy10121989,
AUTHOR = {Armenta-Medina, Dagoberto and Ramirez-delReal, Tania A. and Villanueva-Vásquez, Daniel and Mejia-Aguirre, Cristian},
TITLE = {Trends on Advanced Information and Communication Technologies for Improving Agricultural Productivities: A Bibliometric Analysis},
JOURNAL = {Agronomy},
VOLUME = {10},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {1989},
URL = {https://www.mdpi.com/2073-4395/10/12/1989},
ISSN = {2073-4395},
ABSTRACT = {In this work, an exhaustive revision is given of the literature associated with advanced information and communication technologies in agriculture within a window of 25 years using bibliometric tools enabled to detect of the main actors, structure, and dynamics in the scientific papers. The main findings are a trend of growth in the dynamics of publications associated with advanced information and communication technologies in agriculture productivity. Another assertion is that countries, like the USA, China, and Brazil, stand out in many publications due to allocating more resources to research, development, and agricultural productivity. In addition, the collaboration networks between countries are frequently in regions with closer cultural and idiomatic ties; additionally, terms&rsquo; occurrence are obtained with Louvain algorithm predominating four clusters: precision agriculture, smart agriculture, remote sensing, and climate smart agriculture. Finally, the thematic-map characterization with Callon&rsquo;s density and centrality is applied in three periods. The first period of thematic analysis shows a transition in detecting the variability of a nutrient, such as nitrogen, through the help of immature georeferenced techniques, towards greater remote sensing involvement. In the transition from the second to the third stage, the maturation of technologies, such as unmanned aerial vehicles, wireless sensor networks, and the machine learning area, is observed.},
DOI = {10.3390/agronomy10121989}
}



@Article{app10249051,
AUTHOR = {Wonsick, Murphy and Padir, Taskin},
TITLE = {A Systematic Review of Virtual Reality Interfaces for Controlling and Interacting with Robots},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {9051},
URL = {https://www.mdpi.com/2076-3417/10/24/9051},
ISSN = {2076-3417},
ABSTRACT = {There is a significant amount of synergy between virtual reality (VR) and the field of robotics. However, it has only been in approximately the past five years that commercial immersive VR devices have been available to developers. This new availability has led to a rapid increase in research using VR devices in the field of robotics, especially in the development of VR interfaces for operating robots. In this paper, we present a systematic review on VR interfaces for robot operation that utilize commercially available immersive VR devices. A total of 41 papers published between 2016&ndash;2020 were collected for review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Papers are discussed and categorized into five categories: (1) Visualization, which focuses on displaying data or information to operators; (2) Robot Control and Planning, which focuses on connecting human input or movement to robot movement; (3) Interaction, which focuses on the development of new interaction techniques and/or identifying best interaction practices; (4) Usability, which focuses on user experiences of VR interfaces; and (5) Infrastructure, which focuses on system architectures or software to support connecting VR and robots for interface development. Additionally, we provide future directions to continue development in VR interfaces for operating robots.},
DOI = {10.3390/app10249051}
}



@Article{jsan9040059,
AUTHOR = {De Vita, Fabrizio and Bruneo, Dario},
TITLE = {Leveraging Stack4Things for Federated Learning in Intelligent Cyber Physical Systems},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {9},
YEAR = {2020},
NUMBER = {4},
ARTICLE-NUMBER = {59},
URL = {https://www.mdpi.com/2224-2708/9/4/59},
ISSN = {2224-2708},
ABSTRACT = {During the last decade, the Internet of Things acted as catalyst for the big data phenomenon. As result, modern edge devices can access a huge amount of data that can be exploited to build useful services. In such a context, artificial intelligence has a key role to develop intelligent systems (e.g., intelligent cyber physical systems) that create a connecting bridge with the physical world. However, as time goes by, machine and deep learning applications are becoming more complex, requiring increasing amounts of data and training time, which makes the use of centralized approaches unsuitable. Federated learning is an emerging paradigm which enables the cooperation of edge devices to learn a shared model (while keeping private their training data), thereby abating the training time. Although federated learning is a promising technique, its implementation is difficult and brings a lot of challenges. In this paper, we present an extension of Stack4Things, a cloud platform developed in our department; leveraging its functionalities, we enabled the deployment of federated learning on edge devices without caring their heterogeneity. Experimental results show a comparison with a centralized approach and demonstrate the effectiveness of the proposed approach in terms of both training time and model accuracy.},
DOI = {10.3390/jsan9040059}
}



@Article{electronics9122178,
AUTHOR = {Lee, Hojun and Kang, Minhee and Song, Jaein and Hwang, Keeyeon},
TITLE = {The Detection of Black Ice Accidents for Preventative Automated Vehicles Using Convolutional Neural Networks},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {2178},
URL = {https://www.mdpi.com/2079-9292/9/12/2178},
ISSN = {2079-9292},
ABSTRACT = {Automated Vehicles (AVs) are expected to dramatically reduce traffic accidents that have occurred when using human driving vehicles (HVs). However, despite the rapid development of AVs, accidents involving AVs can occur even in ideal situations. Therefore, in order to enhance their safety, &ldquo;preventive design&rdquo; for accidents is continuously required. Accordingly, the &ldquo;preventive design&rdquo; that prevents accidents in advance is continuously required to enhance the safety of AVs. Specially, black ice with characteristics that are difficult to identify with the naked eye&mdash;the main cause of major accidents in winter vehicles&mdash;is expected to cause serious injuries in the era of AVs, and measures are needed to prevent them. Therefore, this study presents a Convolutional Neural Network (CNN)-based black ice detection plan to prevent traffic accidents of AVs caused by black ice. Due to the characteristic of black ice that is formed only in a certain environment, we augmented image data and learned road environment images. Tests showed that the proposed CNN model detected black ice with 96% accuracy and reproducibility. It is expected that the CNN model for black ice detection proposed in this study will contribute to improving the safety of AVs and prevent black ice accidents in advance.},
DOI = {10.3390/electronics9122178}
}



@Article{rs12244148,
AUTHOR = {Emanuele, Pontoglio and Nives, Grasso and Andrea, Cagninei and Carlo, Camporeale and Paolo, Dabove and Andrea Maria, Lingua},
TITLE = {Bathymetric Detection of Fluvial Environments through UASs and Machine Learning Systems},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4148},
URL = {https://www.mdpi.com/2072-4292/12/24/4148},
ISSN = {2072-4292},
ABSTRACT = {In recent decades, photogrammetric and machine learning technologies have become essential for a better understanding of environmental and anthropic issues. The present work aims to respond one of the most topical problems in environmental photogrammetry, i.e., the automatic classification of dense point clouds using the machine learning (ML) technology for the refraction correction on the fluvial water table. The applied methodology for the acquisition of multiple photogrammetric flights was made through UAV drones, also in RTK configuration, for various locations along the Orco River, sited in Piedmont (Italy) and georeferenced with GNSS&mdash;RTK topographic method. The authors considered five topographic fluvial cross-sections to set the correction methodology. The automatic classification in ML has found a valid identification of different patterns (Water, Gravel bars, Vegetation, and Ground classes), in specific hydraulic and geomatic conditions. The obtained results about the automatic classification and refraction reduction led us the definition of a new procedure, with precise conditions of validity.},
DOI = {10.3390/rs12244148}
}



@Article{rs12244149,
AUTHOR = {Samarin, Maxim and Zweifel, Lauren and Roth, Volker and Alewell, Christine},
TITLE = {Identifying Soil Erosion Processes in Alpine Grasslands on Aerial Imagery with a U-Net Convolutional Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4149},
URL = {https://www.mdpi.com/2072-4292/12/24/4149},
ISSN = {2072-4292},
ABSTRACT = {Erosion in alpine grasslands is a major threat to ecosystem services of alpine soils. Natural causes for the occurrence of soil erosion are steep topography and prevailing climate conditions in combination with soil fragility. To increase our understanding of ongoing erosion processes and support sustainable land-use management, there is a need to acquire detailed information on spatial occurrence and temporal trends. Existing approaches to identify these trends are typically laborious, have lack of transferability to other regions, and are consequently only applicable to smaller regions. In order to overcome these limitations and create a sophisticated erosion monitoring tool capable of large-scale analysis, we developed a model based on U-Net, a fully convolutional neural network, to map different erosion processes on high-resolution aerial images (RGB, 0.25&ndash;0.5 m). U-Net was trained on a high-quality data set consisting of labeled erosion sites mapped with object-based image analysis (OBIA) for the Urseren Valley (Central Swiss Alps) for five aerial images (16 year period). We used the U-Net model to map the same study area and conduct quality assessments based on a held-out test region and a temporal transferability test on new images. Erosion classes are assigned according to their type (shallow landslide and sites with reduced vegetation affected by sheet erosion) or land-use impacts (livestock trails and larger management affected areas). We show that results obtained by OBIA and U-Net follow similar linear trends for the 16 year study period, exhibiting increases in total degraded area of 167% and 201%, respectively. Segmentations of eroded sites are generally in good agreement, but also display method-specific differences, which lead to an overall precision of 73%, a recall of 84%, and a F1-score of 78%. Our results show that U-Net is transferable to spatially (within our study area) and temporally unseen data (data from new years) and is therefore a method suitable to efficiently and successfully capture the temporal trends and spatial heterogeneity of degradation in alpine grasslands. Additionally, U-Net is a powerful and robust tool to map erosion sites in a predictive manner utilising large amounts of new aerial imagery.},
DOI = {10.3390/rs12244149}
}



@Article{rs12244143,
AUTHOR = {Hassanijalilian, Oveis and Igathinathane, C. and Bajwa, Sreekala and Nowatzki, John},
TITLE = {Rating Iron Deficiency in Soybean Using Image Processing and Decision-Tree Based Models},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4143},
URL = {https://www.mdpi.com/2072-4292/12/24/4143},
ISSN = {2072-4292},
ABSTRACT = {The most efficient way of soybean (Glycine max (L.) Merrill) iron deficiency chlorosis (IDC) management is to select a tolerant cultivar suitable for the specific growing condition. These cultivars are selected by field experts based on IDC visual ratings. However, this visual rating method is laborious, expensive, time-consuming, subjective, and impractical on larger scales. Therefore, a modern digital image-based method using tree-based machine learning classifier models for rating soybean IDC at plot-scale was developed. Data were collected from soybean IDC cultivar trial plots. Images were processed with MATLAB and corrected for light intensity by using a standard color board in the image. The three machine learning models used in this study were decision tree (DT), random forest (RF), and adaptive boosting (AdaBoost). Calculated indices from images, such as dark green color index (DGCI), canopy size, and pixel counts into DGCI ranges and IDC visual scoring were used as input and target variables to train these models. Metrics such as precision, recall, and f1-score were used to assess the performance of the classifier models. Among all three models, AdaBoost had the best performance (average f1-score = 0.75) followed by RF and DT the least. Therefore, a ready-to-use methodology of image processing with AdaBoost model for soybean IDC rating was recommended. The developed method can be easily adapted to smartphone applications or scaled-up using images from aerial platforms.},
DOI = {10.3390/rs12244143}
}



@Article{s20247315,
AUTHOR = {Li, Wenlong and Xue, Pengfei and Liu, Chenli and Yan, Hepiao and Zhu, Gaofeng and Cao, Yapeng},
TITLE = {Monitoring and Landscape Dynamic Analysis of Alpine Wetland Area Based on Multiple Algorithms: A Case Study of Zoige Plateau},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {7315},
URL = {https://www.mdpi.com/1424-8220/20/24/7315},
ISSN = {1424-8220},
ABSTRACT = {As an important part of the wetland ecosystem, alpine wetland is not only one of the most important ecological water conservation areas in the Qinghai&ndash;Tibet Plateau region, but is also an effective regulator of the local climate. In this study, using three machine learning algorithms to extract wetland, we employ the landscape ecological index to quantitatively analyze the evolution of landscape patterns and grey correlation to analyze the driving factors of Zoige wetland landscape pattern change from 1995 to 2020. The following results were obtained. (1) The random forest algorithm (RF) performs best when dealing with high-dimensional data, and the accuracy of the decision tree algorithm (DT) is better. The performance of the RF and DT is better than that of the support vector machine algorithm. (2) The alpine wetland in the study area was degraded from 1995 to 2015, whereas wetland area began to increase after 2015. (3) The results of landscape analysis show the decrease in wetland area from 1995 to 2005 was mainly due to the fragmentation of larger patches into many small patches and loss of the original small patches, while the 2005 to 2015 decrease was caused by the loss of many middle patches and the decrease in large patches from the edge to the middle. The 2015 to 2020 increase is due to an increase in the number of smaller patches and recovery of original wetland area. (4) The grey correlation degree further shows that precipitation and evaporation are the main factors leading to the change in the landscape pattern of Zoige alpine wetland. The results are of great significance to the long-term monitoring of the Zoige wetland ecosystem.},
DOI = {10.3390/s20247315}
}



@Article{s20247321,
AUTHOR = {Oh, Donggeun and Han, Junghee},
TITLE = {Fisheye-Based Smart Control System for Autonomous UAV Operation},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {7321},
URL = {https://www.mdpi.com/1424-8220/20/24/7321},
ISSN = {1424-8220},
ABSTRACT = {Recently, as UAVs (unmanned aerial vehicles) have become smaller and higher-performance, they play a very important role in the Internet of Things (IoT). Especially, UAVs are currently used not only in military fields but also in various private sectors such as IT, agriculture, logistics, construction, etc. The range is further expected to increase. Drone-related techniques need to evolve along with this change. In particular, there is a need for the development of an autonomous system in which a drone can determine and accomplish its mission even in the absence of remote control from a GCS (Ground Control Station). Responding to such requirements, there have been various studies and algorithms developed for autonomous flight systems. Especially, many ML-based (Machine-Learning-based) methods have been proposed for autonomous path finding. Unlike other studies, the proposed mechanism could enable autonomous drone path finding over a large target area without size limitations, one of the challenges of ML-based autonomous flight or driving in the real world. Specifically, we devised Multi-Layer HVIN (Hierarchical VIN) methods that increase the area applicable to autonomous flight by overlaying multiple layers. To further improve this, we developed Fisheye HVIN, which applied an adaptive map compression ratio according to the drone’s location. We also built an autonomous flight training and verification platform. Through the proposed simulation platform, it is possible to train ML-based path planning algorithms in a realistic environment that takes into account the physical characteristics of UAV movements.},
DOI = {10.3390/s20247321}
}



@Article{s20247332,
AUTHOR = {Mawrence, Raphael and Munniks, Sandra and Valente, João},
TITLE = {Calibration of Electrochemical Sensors for Nitrogen Dioxide Gas Detection Using Unmanned Aerial Vehicles},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {7332},
URL = {https://www.mdpi.com/1424-8220/20/24/7332},
ISSN = {1424-8220},
ABSTRACT = {For years, urban air quality networks have been set up by private organizations and governments to monitor toxic gases like NO2. However, these networks can be very expensive to maintain, so their distribution is usually widely spaced, leaving gaps in the spatial resolution of the resulting air quality data. Recently, electrochemical sensors and their integration with unmanned aerial vehicles (UAVs) have attempted to fill these gaps through various experiments, none of which have considered the influence of a UAV when calibrating the sensors. Accordingly, this research attempts to improve the reliability of NO2 measurements detected from electrochemical sensors while on board an UAV by introducing rotor speed as part of the calibration model. This is done using a DJI Matrice 100 quadcopter and Alphasense sensors, which are calibrated using regression calculations in different environments. This produces a predictive r-squared up to 0.97. The sensors are then calibrated with rotor speed as an additional variable while on board the UAV and flown in a series of flights to evaluate the performance of the model, which produces a predictive r-squared up to 0.80. This methodological approach can be used to obtain more reliable NO2 measurements in future outdoor experiments that include electrochemical sensor integration with UAV&rsquo;s.},
DOI = {10.3390/s20247332}
}



@Article{rs12244176,
AUTHOR = {Queiroz, Gustavo Lopes and McDermid, Gregory J. and Rahman, Mir Mustafizur and Linke, Julia},
TITLE = {The Forest Line Mapper: A Semi-Automated Tool for Mapping Linear Disturbances in Forests},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4176},
URL = {https://www.mdpi.com/2072-4292/12/24/4176},
ISSN = {2072-4292},
ABSTRACT = {Forest land-use planning and restoration requires effective tools for mapping and attributing linear disturbances such as roads, trails, and asset corridors over large areas. Most existing linear-feature databases are generated by heads-up digitizing. While suitable for cartographic purposes, these datasets often lack the fine spatial details and multiple attributes required for more demanding analytical applications. To address this need, we developed the Forest Line Mapper (FLM), a semi-automated software tool for mapping and attributing linear features using LiDAR-derived canopy height models. Accuracy assessments conducted in the boreal forest of Alberta, Canada showed that the FLM reliably predicts both the center line (polyline) and footprint (extent polygons) of a variety of linear-feature types including roads, pipelines, seismic lines, and power lines. Our analysis showed that FLM outputs were consistently more accurate than publicly available datasets produced by human photo-interpreters, and that the tool can be reliably deployed across large application areas. In addition to accurately delineating linear features, the FLM generates a variety of spatial attributes associated with line geometry and vegetation characteristics from input canopy height data. Our statistical evaluation indicates that spatial attributes generated by the FLM may be useful for studying and classifying linear features based on disturbance type and ground conditions. The FLM is open-source and freely available and is aimed to assist researchers and land managers working in forested environments everywhere.},
DOI = {10.3390/rs12244176}
}



@Article{agriculture10120653,
AUTHOR = {Bolfe, Édson Luis and Jorge, Lúcio André de Castro and Sanches, Ieda Del’Arco and Luchiari Júnior, Ariovaldo and da Costa, Cinthia Cabral and Victoria, Daniel de Castro and Inamasu, Ricardo Yassushi and Grego, Célia Regina and Ferreira, Victor Rodrigues and Ramirez, Andrea Restrepo},
TITLE = {Precision and Digital Agriculture: Adoption of Technologies and Perception of Brazilian Farmers},
JOURNAL = {Agriculture},
VOLUME = {10},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {653},
URL = {https://www.mdpi.com/2077-0472/10/12/653},
ISSN = {2077-0472},
ABSTRACT = {The rapid population growth has driven the demand for more food, fiber, energy, and water, which is associated to an increase in the need to use natural resources in a more sustainable way. The use of precision agriculture machinery and equipment since the 1990s has provided important productive gains and maximized the use of agricultural inputs. The growing connectivity in the rural environment, in addition to its greater integration with data from sensor systems, remote sensors, equipment, and smartphones have paved the way for new concepts from the so-called Agriculture 4.0 or Digital Agriculture. This article presents the results of a survey carried out with 504 Brazilian farmers about the digital technologies in use, as well as current and future applications, perceived benefits, and challenges. The questionnaire was prepared, organized, and made available to the public through the online platform LimeSurvey and was available from 17 April to 2 June 2020. The primary data obtained for each question previously defined were consolidated and analyzed statistically. The results indicate that 84% of the interviewed farmers use at least one digital technology in their production system that differs according to technological complexity level. The main perceived benefit refers to the perception of increased productivity and the main challenges are the acquisition costs of machines, equipment, software, and connectivity. It is also noteworthy that 95% of farmers would like to learn more about new technologies to strengthen the agricultural development in their properties.},
DOI = {10.3390/agriculture10120653}
}



@Article{s21010014,
AUTHOR = {Dong, Mei and Wu, Hongyu and Hu, Hui and Azzam, Rafig and Zhang, Liang and Zheng, Zengrong and Gong, Xiaonan},
TITLE = {Deformation Prediction of Unstable Slopes Based on Real-Time Monitoring and DeepAR Model},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {14},
URL = {https://www.mdpi.com/1424-8220/21/1/14},
ISSN = {1424-8220},
ABSTRACT = {With increased urbanization, accidents related to slope instability are frequently encountered in construction sites. The deformation and failure mechanism of a landslide is a complex dynamic process, which seriously threatens people&rsquo;s lives and property. Currently, prediction and early warning of a landslide can be effectively performed by using Internet of Things (IoT) technology to monitor the landslide deformation in real time and an artificial intelligence algorithm to predict the deformation trend. However, if a slope failure occurs during the construction period, the builders and decision-makers find it challenging to effectively apply IoT technology to monitor the emergency and assist in proposing treatment measures. Moreover, for projects during operation (e.g., a motorway in a mountainous area), no recognized artificial intelligence algorithm exists that can forecast the deformation of steep slopes using the huge data obtained from monitoring devices. In this context, this paper introduces a real-time wireless monitoring system with multiple sensors for retrieving high-frequency overall data that can describe the deformation feature of steep slopes. The system was installed in the Qili connecting line of a motorway in Zhejiang Province, China, to provide a technical support for the design and implementation of safety solutions for the steep slopes. Most of the devices were retained to monitor the slopes even after construction. The machine learning Probabilistic Forecasting with Autoregressive Recurrent Networks (DeepAR) model based on time series and probabilistic forecasting was introduced into the project to predict the slope displacement. The predictive accuracy of the DeepAR model was verified by the mean absolute error, the root mean square error and the goodness of fit. This study demonstrates that the presented monitoring system and the introduced predictive model had good safety control ability during construction and good prediction accuracy during operation. The proposed approach will be helpful to assess the safety of excavated slopes before constructing new infrastructures.},
DOI = {10.3390/s21010014}
}



@Article{rs13010027,
AUTHOR = {Alhaqbani, Amjaad and Kurdi, Heba and Youcef-Toumi, Kamal},
TITLE = {Fish-Inspired Task Allocation Algorithm for Multiple Unmanned Aerial Vehicles in Search and Rescue Missions},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {27},
URL = {https://www.mdpi.com/2072-4292/13/1/27},
ISSN = {2072-4292},
ABSTRACT = {The challenge concerning the optimal allocation of tasks across multiple unmanned aerial vehicles (multi-UAVs) has significantly spurred research interest due to its contribution to the success of various fleet missions. This challenge becomes more complex in time-constrained missions, particularly if they are conducted in hostile environments, such as search and rescue (SAR) missions. In this study, a novel fish-inspired algorithm for multi-UAV missions (FIAM) for task allocation is proposed, which was inspired by the adaptive schooling and foraging behaviors of fish. FIAM shows that UAVs in an SAR mission can be similarly programmed to aggregate in groups to swiftly survey disaster areas and rescue-discovered survivors. FIAM&rsquo;s performance was compared with three long-standing multi-UAV task allocation (MUTA) paradigms, namely, opportunistic task allocation scheme (OTA), auction-based scheme, and ant-colony optimization (ACO). Furthermore, the proposed algorithm was also compared with the recently proposed locust-inspired algorithm for MUTA problem (LIAM). The experimental results demonstrated FIAM&rsquo;s abilities to maintain a steady running time and a decreasing mean rescue time with a substantially increasing percentage of rescued survivors. For instance, FIAM successfully rescued 100% of the survivors with merely 16 UAVs, for scenarios of no more than eight survivors, whereas LIAM, Auction, ACO and OTA rescued a maximum of 75%, 50%, 35% and 35%, respectively, for the same scenarios. This superiority of FIAM performance was maintained under a different fleet size and number of survivors, demonstrating the approach&rsquo;s flexibility and scalability.},
DOI = {10.3390/rs13010027}
}



@Article{agronomy11010011,
AUTHOR = {Cruz Ulloa, Christyan and Krus, Anne and Barrientos, Antonio and Del Cerro, Jaime and Valero, Constantino},
TITLE = {Robotic Fertilisation Using Localisation Systems Based on Point Clouds in Strip-Cropping Fields},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {11},
URL = {https://www.mdpi.com/2073-4395/11/1/11},
ISSN = {2073-4395},
ABSTRACT = {The use of robotic systems in organic farming has taken on a leading role in recent years; the Sureveg CORE Organic Cofund ERA-Net project seeks to evaluate the benefits of strip-cropping to produce organic vegetables. This includes, among other objectives, the development of a robotic tool that facilitates the automation of the fertilisation process, allowing the individual treatment (at the plant level). In organic production, the slower nutrient release of the used fertilisers poses additional difficulties, as a tardy detection of deficiencies can no longer be corrected. To improve the detection, as well as counter the additional labour stemming from the strip-cropping configuration, an integrated robotic tool is proposed to detect individual crop deficiencies and react on a single-crop basis. For the development of this proof-of-concept, one of the main objectives of this work is implementing a robust localisation method within the vegetative environment based on point clouds, through the generation of general point cloud maps (G-PC) and local point cloud maps (L-PC) of a crop row. The plants&rsquo; geometric characteristics were extracted from the G-PC as a framework in which the robot&rsquo;s positioning is defined. Through the processing of real-time lidar data, the L-PC is then defined and compared to the predefined reference system previously deduced. Both subsystems are integrated with ROS (Robot Operating System), alongside motion planning, and an inverse kinematics CCD (Cyclic Coordinate Descent) solver, among others. Tests were performed using a simulated environment of the crop row developed in Gazebo, followed by actual measurements in a strip-cropping field. During real-time data-acquisition, the localisation error is reduced from 13 mm to 11 mm within the first 120 cm of measurement. The encountered real-time geometric characteristics were found to coincide with those in the G-PC to an extend of 98.6%.},
DOI = {10.3390/agronomy11010011}
}



@Article{rs13010039,
AUTHOR = {Carvalho, Osmar Luiz Ferreira de and de Carvalho Júnior, Osmar Abílio and Albuquerque, Anesmar Olino de and Bem, Pablo Pozzobon de and Silva, Cristiano Rosa and Ferreira, Pedro Henrique Guimarães and Moura, Rebeca dos Santos de and Gomes, Roberto Arnaldo Trancoso and Guimarães, Renato Fontes and Borges, Díbio Leandro},
TITLE = {Instance Segmentation for Large, Multi-Channel Remote Sensing Imagery Using Mask-RCNN and a Mosaicking Approach},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {39},
URL = {https://www.mdpi.com/2072-4292/13/1/39},
ISSN = {2072-4292},
ABSTRACT = {Instance segmentation is the state-of-the-art in object detection, and there are numerous applications in remote sensing data where these algorithms can produce significant results. Nevertheless, one of the main problems is that most algorithms use Red, Green, and Blue (RGB) images, whereas Satellite images often present more channels that can be crucial to improve performance. Therefore, the present work brings three contributions: (a) conversion system from ground truth polygon data into the Creating Common Object in Context (COCO) annotation format; (b) Detectron2 software source code adaptation and application on multi-channel imagery; and (c) large scene image mosaicking. We applied the procedure in a Center Pivot Irrigation System (CPIS) dataset with ground truth produced by the Brazilian National Water Agency (ANA) and Landsat-8 Operational Land Imager (OLI) imagery (7 channels with 30-m resolution). Center pivots are a modern irrigation system technique with massive growth potential in Brazil and other world areas. The round shapes with different textures, colors, and spectral behaviors make it appropriate to use Deep Learning instance segmentation. We trained the model using 512 &times; 512-pixel sized patches using seven different backbone structures (ResNet50- Feature Pyramid Network (FPN), Resnet50-DC5, ResNet50-C4, Resnet101-FPN, Resnet101-DC5, ResNet101-FPN, and ResNeXt101-FPN). The model evaluation used standard COCO metrics (Average Precision (AP), AP50, AP75, APsmall, APmedium, and AR100). ResNeXt101-FPN had the best results, with a 3% advantage over the second-best model (ResNet101-FPN). We also compared the ResNeXt101-FPN model in the seven-channel and RGB imagery, where the multi-channel model had a 3% advantage, demonstrating great improvement using a larger number of channels. This research is also the first with a mosaicking algorithm using instance segmentation models, where we tested in a 1536 &times; 1536-pixel image using a non-max suppression sorted by area method. The proposed methodology is innovative and suitable for many other remote sensing problems and medical imagery that often present more channels.},
DOI = {10.3390/rs13010039}
}



@Article{rs13010052,
AUTHOR = {Maung, Win Sithu and Sasaki, Jun},
TITLE = {Assessing the Natural Recovery of Mangroves after Human Disturbance Using Neural Network Classification and Sentinel-2 Imagery in Wunbaik Mangrove Forest, Myanmar},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {52},
URL = {https://www.mdpi.com/2072-4292/13/1/52},
ISSN = {2072-4292},
ABSTRACT = {In this study, we examined the natural recovery of mangroves in abandoned shrimp ponds located in the Wunbaik Mangrove Forest (WMF) in Myanmar using artificial neural network (ANN) classification and a change detection approach with Sentinel-2 satellite images. In 2020, we conducted various experiments related to mangrove classification by tuning input features and hyper-parameters. The selected ANN model was used with a transfer learning approach to predict the mangrove distribution in 2015. Changes were detected using classification results from 2015 and 2020. Naturally recovering mangroves were identified by extracting the change detection results of three abandoned shrimp ponds selected during field investigation. The proposed method yielded an overall accuracy of 95.98%, a kappa coefficient of 0.92, mangrove and non-mangrove precisions of 0.95 and 0.98, respectively, recalls of 0.96, and F1 scores of 0.96 for the 2020 classification. For the 2015 prediction, transfer learning improved model performance, resulting in an overall accuracy of 97.20%, a kappa coefficient of 0.94, mangrove and non-mangrove precisions of 0.98 and 0.96, respectively, recalls of 0.98 and 0.97, and F1 scores of 0.96. The change detection results showed that mangrove forests in the WMF slightly decreased between 2015 and 2020. Naturally recovering mangroves were detected at approximately 50% of each abandoned site within a short abandonment period. This study demonstrates that the ANN method using Sentinel-2 imagery and topographic and canopy height data can produce reliable results for mangrove classification. The natural recovery of mangroves presents a valuable opportunity for mangrove rehabilitation at human-disturbed sites in the WMF.},
DOI = {10.3390/rs13010052}
}



@Article{rs13010054,
AUTHOR = {Biffi, Leonardo Josoé and Mitishita, Edson and Liesenberg, Veraldo and Santos, Anderson Aparecido dos and Gonçalves, Diogo Nunes and Estrabis, Nayara Vasconcelos and Silva, Jonathan de Andrade and Osco, Lucas Prado and Ramos, Ana Paula Marques and Centeno, Jorge Antonio Silva and Schimalski, Marcos Benedito and Rufato, Leo and Neto, Sílvio Luís Rafaeli and Marcato Junior, José and Gonçalves, Wesley Nunes},
TITLE = {ATSS Deep Learning-Based Approach to Detect Apple Fruits},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {54},
URL = {https://www.mdpi.com/2072-4292/13/1/54},
ISSN = {2072-4292},
ABSTRACT = {In recent years, many agriculture-related problems have been evaluated with the integration of artificial intelligence techniques and remote sensing systems. Specifically, in fruit detection problems, several recent works were developed using Deep Learning (DL) methods applied in images acquired in different acquisition levels. However, the increasing use of anti-hail plastic net cover in commercial orchards highlights the importance of terrestrial remote sensing systems. Apples are one of the most highly-challenging fruits to be detected in images, mainly because of the target occlusion problem occurrence. Additionally, the introduction of high-density apple tree orchards makes the identification of single fruits a real challenge. To support farmers to detect apple fruits efficiently, this paper presents an approach based on the Adaptive Training Sample Selection (ATSS) deep learning method applied to close-range and low-cost terrestrial RGB images. The correct identification supports apple production forecasting and gives local producers a better idea of forthcoming management practices. The main advantage of the ATSS method is that only the center point of the objects is labeled, which is much more practicable and realistic than bounding-box annotations in heavily dense fruit orchards. Additionally, we evaluated other object detection methods such as RetinaNet, Libra Regions with Convolutional Neural Network (R-CNN), Cascade R-CNN, Faster R-CNN, Feature Selective Anchor-Free (FSAF), and High-Resolution Network (HRNet). The study area is a highly-dense apple orchard consisting of Fuji Suprema apple fruits (Malus domestica Borkh) located in a smallholder farm in the state of Santa Catarina (southern Brazil). A total of 398 terrestrial images were taken nearly perpendicularly in front of the trees by a professional camera, assuring both a good vertical coverage of the apple trees in terms of heights and overlapping between picture frames. After, the high-resolution RGB images were divided into several patches for helping the detection of small and/or occluded apples. A total of 3119, 840, and 2010 patches were used for training, validation, and testing, respectively. Moreover, the proposed method&rsquo;s generalization capability was assessed by applying simulated image corruptions to the test set images with different severity levels, including noise, blurs, weather, and digital processing. Experiments were also conducted by varying the bounding box size (80, 100, 120, 140, 160, and 180 pixels) in the image original for the proposed approach. Our results showed that the ATSS-based method slightly outperformed all other deep learning methods, between 2.4% and 0.3%. Also, we verified that the best result was obtained with a bounding box size of 160 &times; 160 pixels. The proposed method was robust regarding most of the corruption, except for snow, frost, and fog weather conditions. Finally, a benchmark of the reported dataset is also generated and publicly available.},
DOI = {10.3390/rs13010054}
}



@Article{rs13010068,
AUTHOR = {Pineda, Mónica and Barón, Matilde and Pérez-Bueno, María-Luisa},
TITLE = {Thermal Imaging for Plant Stress Detection and Phenotyping},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {68},
URL = {https://www.mdpi.com/2072-4292/13/1/68},
ISSN = {2072-4292},
ABSTRACT = {In the last few years, large efforts have been made to develop new methods to optimize stress detection in crop fields. Thus, plant phenotyping based on imaging techniques has become an essential tool in agriculture. In particular, leaf temperature is a valuable indicator of the physiological status of plants, responding to both biotic and abiotic stressors. Often combined with other imaging sensors and data-mining techniques, thermography is crucial in the implementation of a more automatized, precise and sustainable agriculture. However, thermal data need some corrections related to the environmental and measuring conditions in order to achieve a correct interpretation of the data. This review focuses on the state of the art of thermography applied to the detection of biotic stress. The work will also revise the most important abiotic stress factors affecting the measurements as well as practical issues that need to be considered in order to implement this technique, particularly at the field scale.},
DOI = {10.3390/rs13010068}
}



@Article{s21010118,
AUTHOR = {Wittstruck, Lucas and Kühling, Insa and Trautz, Dieter and Kohlbrecher, Maik and Jarmer, Thomas},
TITLE = {UAV-Based RGB Imagery for Hokkaido Pumpkin (Cucurbita max.) Detection and Yield Estimation},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {118},
URL = {https://www.mdpi.com/1424-8220/21/1/118},
ISSN = {1424-8220},
ABSTRACT = {Pumpkins are economically and nutritionally valuable vegetables with increasing popularity and acreage across Europe. Successful commercialization, however, require detailed pre-harvest information about number and weight of the fruits. To get a non-destructive and cost-effective yield estimation, we developed an image processing methodology for high-resolution RGB data from Unmanned aerial vehicle (UAV) and applied this on a Hokkaido pumpkin farmer&rsquo;s field in North-western Germany. The methodology was implemented in the programming language Python and comprised several steps, including image pre-processing, pixel-based image classification, classification post-processing for single fruit detection, and fruit size and weight quantification. To derive the weight from two-dimensional imagery, we calculated elliptical spheroids from lengths of diameters and heights. The performance of this processes was evaluated by comparison with manually harvested ground-truth samples and cross-checked for misclassification from randomly selected test objects. Errors in classification and fruit geometry could be successfully reduced based on the described processing steps. Additionally, different lighting conditions, as well as shadows, in the image data could be compensated by the proposed methodology. The results revealed a satisfactory detection of 95% (error rate of 5%) from the field sample, as well as a reliable volume and weight estimation with Pearson&rsquo;s correlation coefficients of 0.83 and 0.84, respectively, from the described ellipsoid approach. The yield was estimated with 1.51 kg m&minus;2 corresponding to an average individual fruit weight of 1100 g and an average number of 1.37 pumpkins per m2. Moreover, spatial distribution of aggregated fruit densities and weights were calculated to assess in-field optimization potential for agronomic management as demonstrated between a shaded edge compared to the rest of the field. The proposed approach provides the Hokkaido producer useful information for more targeted pre-harvest marketing strategies, since most food retailers request homogeneous lots within prescribed size or weight classes.},
DOI = {10.3390/s21010118}
}



@Article{electronics10010027,
AUTHOR = {Mun, Hyunsu and Lee, Youngseok},
TITLE = {Internet Traffic Classification with Federated Learning},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {27},
URL = {https://www.mdpi.com/2079-9292/10/1/27},
ISSN = {2079-9292},
ABSTRACT = {As Internet traffic classification is a typical problem for ISPs or mobile carriers, there have been a lot of studies based on statistical packet header information, deep packet inspection, or machine learning. Due to recent advances in end-to-end encryption and dynamic port policies, machine or deep learning has been an essential key to improve the accuracy of packet classification. In addition, ISPs or mobile carriers should carefully deal with the privacy issue while collecting user packets for accounting or security. The recent development of distributed machine learning, called federated learning, collaboratively carries out machine learning jobs on the clients without uploading data to a central server. Although federated learning provides an on-device learning framework towards user privacy protection, its feasibility and performance of Internet traffic classification have not been fully examined. In this paper, we propose a federated-learning traffic classification protocol (FLIC), which can achieve an accuracy comparable to centralized deep learning for Internet application identification without privacy leakage. FLIC can classify new applications on-the-fly when a participant joins in learning with a new application, which has not been done in previous works. By implementing the prototype of FLIC clients and a server with TensorFlow, the clients gather packets, perform the on-device training job and exchange the training results with the FLIC server. In addition, we demonstrate that federated learning-based packet classification achieves an accuracy of 88% under non-independent and identically distributed (non-IID) traffic across clients. When a new application that can be classified dynamically as a client participates in learning was added, an accuracy of 92% was achieved.},
DOI = {10.3390/electronics10010027}
}



@Article{f12010038,
AUTHOR = {Shrestha, Maryada and Broadbent, Eben N. and Vogel, Jason G.},
TITLE = {Using GatorEye UAV-Borne LiDAR to Quantify the Spatial and Temporal Effects of a Prescribed Fire on Understory Height and Biomass in a Pine Savanna},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {38},
URL = {https://www.mdpi.com/1999-4907/12/1/38},
ISSN = {1999-4907},
ABSTRACT = {In the pine savannas of the southeastern United States, prescribed fire is commonly used to manipulate understory structure and composition. Understory characteristics have traditionally been monitored with field sampling; however, remote sensing could provide rapid, spatially explicit monitoring of understory dynamics. We contrasted pre- vs. post-fire understory characteristics collected with fixed area plots with estimates from high-density LiDAR point clouds collected using the unmanned aerial vehicle (UAV)-borne GatorEye system. Measuring within 1 &times; 1 m field plots (n = 20), we found average understory height ranged from 0.17&ndash;1.26 m and biomass from 0.26&ndash;4.86 Mg C ha&minus;1 before the fire (May 2018), and five months after the fire (November 2018), height ranged from 0.11&ndash;1.09 m and biomass from 0.04&ndash;3.03 Mg C ha&minus;1. Understory heights estimated with LiDAR were significantly correlated with plot height measurements (R2 = 0.576, p &le; 0.001). Understory biomass was correlated with in situ heights (R2 = 0.579, p &le; 0.001) and LiDAR heights (R2 = 0.507, p &le; 0.001). The biomass estimates made with either height measurement did not differ for the measurement plots (p = 0.263). However, for the larger research area, the understory biomass estimated with the LiDAR indicated a smaller difference after the burn (~12.7% biomass reduction) than observed with in situ measurements (~16% biomass reduction). The two approaches likely differed because the research area&rsquo;s spatial variability was not captured by the in-situ measurements (0.2% of the research area measured) versus the wall-to-wall coverage provided by LiDAR. The additional benefit of having spatially explicit measurements with LiDAR, and its ease of use, make it a promising tool for land managers wanting greater spatial and temporal resolution in tracking understory biomass and its response to prescribed fire.},
DOI = {10.3390/f12010038}
}



@Article{e23010056,
AUTHOR = {Niu, Haoyu and Wei, Jiamin and Chen, YangQuan},
TITLE = {Optimal Randomness for Stochastic Configuration Network (SCN) with Heavy-Tailed Distributions},
JOURNAL = {Entropy},
VOLUME = {23},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {56},
URL = {https://www.mdpi.com/1099-4300/23/1/56},
PubMedID = {33396383},
ISSN = {1099-4300},
ABSTRACT = {Stochastic Configuration Network (SCN) has a powerful capability for regression and classification analysis. Traditionally, it is quite challenging to correctly determine an appropriate architecture for a neural network so that the trained model can achieve excellent performance for both learning and generalization. Compared with the known randomized learning algorithms for single hidden layer feed-forward neural networks, such as Randomized Radial Basis Function (RBF) Networks and Random Vector Functional-link (RVFL), the SCN randomly assigns the input weights and biases of the hidden nodes in a supervisory mechanism. Since the parameters in the hidden layers are randomly generated in uniform distribution, hypothetically, there is optimal randomness. Heavy-tailed distribution has shown optimal randomness in an unknown environment for finding some targets. Therefore, in this research, the authors used heavy-tailed distributions to randomly initialize weights and biases to see if the new SCN models can achieve better performance than the original SCN. Heavy-tailed distributions, such as L&eacute;vy distribution, Cauchy distribution, and Weibull distribution, have been used. Since some mixed distributions show heavy-tailed properties, the mixed Gaussian and Laplace distributions were also studied in this research work. Experimental results showed improved performance for SCN with heavy-tailed distributions. For the regression model, SCN-L&eacute;vy, SCN-Mixture, SCN-Cauchy, and SCN-Weibull used less hidden nodes to achieve similar performance with SCN. For the classification model, SCN-Mixture, SCN-L&eacute;vy, and SCN-Cauchy have higher test accuracy of 91.5%, 91.7% and 92.4%, respectively. Both are higher than the test accuracy of the original SCN.},
DOI = {10.3390/e23010056}
}



@Article{agriculture11010022,
AUTHOR = {Rahman, Mohammad Fatin Fatihur and Fan, Shurui and Zhang, Yan and Chen, Lei},
TITLE = {A Comparative Study on Application of Unmanned Aerial Vehicle Systems in Agriculture},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {22},
URL = {https://www.mdpi.com/2077-0472/11/1/22},
ISSN = {2077-0472},
ABSTRACT = {Presently in agriculture, there is much ample scope for drone and UAS (Unmanned Aircraft System) development. Because of their low cost and small size, these devices have the ability to help many developing countries with economic prosperity. The entire aggregation of financial investments in the agricultural area has increased appreciably in recent years. Sooth to say, agriculture remains a massive part of the world&rsquo;s commercial growth, and due to some complications, the agriculture fields withstand massive losses. Pets and destructive insects seem to be the primary reasons for certain degenerative diseases. It minimizes the potential productivity of the crops. For increasing the quality of the plants, fertilizers and pesticides are appropriately applied. Using UAVs (Unmanned Aerial Vehicles) for spraying pesticides and fertilizing materials is an exuberant contraption. It adequately reduces the rate of health dilemma and the number of workers, which is quite an impressive landmark. Willing producers are also adopting UAVs in agriculture to soil and field analysis, seed sowing, lessen the time and costs correlated with crop scouting, and field mapping. It is rapid, and it can sensibly diminish a farmer&rsquo;s workload, which is significantly a part of the agricultural revolution. This article aims to proportionally represent the concept of agricultural purposed UAV clear to the neophytes. First, this paper outlines the harmonic framework of the agricultural UAV, and then it abundantly illustrates the methods and materials. Finally, the article portrays the outcome.},
DOI = {10.3390/agriculture11010022}
}



@Article{rs13010123,
AUTHOR = {Guo, Anting and Huang, Wenjiang and Dong, Yingying and Ye, Huichun and Ma, Huiqin and Liu, Bo and Wu, Wenbin and Ren, Yu and Ruan, Chao and Geng, Yun},
TITLE = {Wheat Yellow Rust Detection Using UAV-Based Hyperspectral Technology},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {123},
URL = {https://www.mdpi.com/2072-4292/13/1/123},
ISSN = {2072-4292},
ABSTRACT = {Yellow rust is a worldwide disease that poses a serious threat to the safety of wheat production. Numerous studies on near-surface hyperspectral remote sensing at the leaf scale have achieved good results for disease monitoring. The next step is to monitor the disease at the field scale, which is of great significance for disease control. In our study, an unmanned aerial vehicle (UAV) equipped with a hyperspectral sensor was used to obtain hyperspectral images at the field scale. Vegetation indices (VIs) and texture features (TFs) extracted from the UAV-based hyperspectral images and their combination were used to establish partial least-squares regression (PLSR)-based disease monitoring models in different infection periods. In addition, we resampled the original images with 1.2 cm spatial resolution to images with different spatial resolutions (3 cm, 5 cm, 7 cm, 10 cm, 15 cm, and 20 cm) to evaluate the effect of spatial resolution on disease monitoring accuracy. The findings showed that the VI-based model had the highest monitoring accuracy (R2 = 0.75) in the mid-infection period. The TF-based model could be used to monitor yellow rust at the field scale and obtained the highest R2 in the mid- and late-infection periods (0.65 and 0.82, respectively). The VI-TF-based models had the highest accuracy in each infection period and outperformed the VI-based or TF-based models. The spatial resolution had a negligible influence on the VI-based monitoring accuracy, but significantly influenced the TF-based monitoring accuracy. Furthermore, the optimal spatial resolution for monitoring yellow rust using the VI-TF-based model in each infection period was 10 cm. The findings provide a reference for accurate disease monitoring using UAV hyperspectral images.},
DOI = {10.3390/rs13010123}
}



@Article{geosciences11010021,
AUTHOR = {Zolkos, Scott and Fiske, Greg and Windholz, Tiffany and Duran, Gabriel and Yang, Zhiqiang and Olenchenko, Vladimir and Faguet, Alexey and Natali, Susan M.},
TITLE = {Detecting and Mapping Gas Emission Craters on the Yamal and Gydan Peninsulas, Western Siberia},
JOURNAL = {Geosciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {21},
URL = {https://www.mdpi.com/2076-3263/11/1/21},
ISSN = {2076-3263},
ABSTRACT = {Rapid climate warming at northern high latitudes is driving geomorphic changes across the permafrost zone. In the Yamal and Gydan peninsulas in western Siberia, subterranean accumulation of methane beneath or within ice-rich permafrost can create mounds at the land surface. Once over-pressurized by methane, these mounds can explode and eject frozen ground, forming a gas emission crater (GEC). While GECs pose a hazard to human populations and infrastructure, only a small number have been identified in the Yamal and Gydan peninsulas, where the regional distribution and frequency of GECs and other types of land surface change are relatively unconstrained. To understand the distribution of landscape change within 327,000 km2 of the Yamal-Gydan region, we developed a semi-automated multivariate change detection algorithm using satellite-derived surface reflectance, elevation, and water extent in the Google Earth Engine cloud computing platform. We found that 5% of the landscape changed from 1984 to 2017. The algorithm detected all seven GECs reported in the scientific literature and three new GEC-like features, and further revealed that retrogressive thaw slumps were more abundant than GECs. Our methodology can be refined to detect and better understand diverse types of land surface change and potentially mitigate risks across the northern permafrost zone.},
DOI = {10.3390/geosciences11010021}
}



@Article{s21010231,
AUTHOR = {Jiang, Weiheng and Wu, Xiaogang and Wang, Yimou and Chen, Bolin and Feng, Wenjiang and Jin, Yi},
TITLE = {Time–Frequency-Analysis-Based Blind Modulation Classification for Multiple-Antenna Systems},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {231},
URL = {https://www.mdpi.com/1424-8220/21/1/231},
PubMedID = {33401416},
ISSN = {1424-8220},
ABSTRACT = {Blind modulation classification is an important step in implementing cognitive radio networks. The multiple-input multiple-output (MIMO) technique is widely used in military and civil communication systems. Due to the lack of prior information about channel parameters and the overlapping of signals in MIMO systems, the traditional likelihood-based and feature-based approaches cannot be applied in these scenarios directly. Hence, in this paper, to resolve the problem of blind modulation classification in MIMO systems, the time&ndash;frequency analysis method based on the windowed short-time Fourier transform was used to analyze the time&ndash;frequency characteristics of time-domain modulated signals. Then, the extracted time&ndash;frequency characteristics are converted into red&ndash;green&ndash;blue (RGB) spectrogram images, and the convolutional neural network based on transfer learning was applied to classify the modulation types according to the RGB spectrogram images. Finally, a decision fusion module was used to fuse the classification results of all the receiving antennas. Through simulations, we analyzed the classification performance at different signal-to-noise ratios (SNRs); the results indicate that, for the single-input single-output (SISO) network, our proposed scheme can achieve 92.37% and 99.12% average classification accuracy at SNRs of &minus;4 and 10 dB, respectively. For the MIMO network, our scheme achieves 80.42% and 87.92% average classification accuracy at &minus;4 and 10 dB, respectively. The proposed method greatly improves the accuracy of modulation classification in MIMO networks.},
DOI = {10.3390/s21010231}
}



@Article{land10010029,
AUTHOR = {Papp, Levente and van Leeuwen, Boudewijn and Szilassi, Péter and Tobak, Zalán and Szatmári, József and Árvai, Mátyás and Mészáros, János and Pásztor, László},
TITLE = {Monitoring Invasive Plant Species Using Hyperspectral Remote Sensing Data},
JOURNAL = {Land},
VOLUME = {10},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {29},
URL = {https://www.mdpi.com/2073-445X/10/1/29},
ISSN = {2073-445X},
ABSTRACT = {The species richness and biodiversity of vegetation in Hungary are increasingly threatened by invasive plant species brought in from other continents and foreign ecosystems. These invasive plant species have spread aggressively in the natural and semi-natural habitats of Europe. Common milkweed (Asclepias syriaca) is one of the species that pose the greatest ecological menace. Therefore, the primary purpose of the present study is to map and monitor the spread of common milkweed, the most common invasive plant species in Europe. Furthermore, the possibilities to detect and validate this special invasive plant by analyzing hyperspectral remote sensing data were investigated. In combination with field reference data, high-resolution hyperspectral aerial images acquired by an unmanned aerial vehicle (UAV) platform in 138 spectral bands in areas infected by common milkweed were examined. Then, support vector machine (SVM) and artificial neural network (ANN) classification algorithms were applied to the highly accurate field reference data. As a result, common milkweed individuals were distinguished in hyperspectral images, achieving an overall accuracy of 92.95% in the case of supervised SVM classification. Using the ANN model, an overall accuracy of 99.61% was achieved. To evaluate the proposed approach, two experimental tests were conducted, and in both cases, we managed to distinguish the individual specimens within the large variety of spreading invasive species in a study area of 2 ha, based on centimeter spatial resolution hyperspectral UAV imagery.},
DOI = {10.3390/land10010029}
}



@Article{app11010361,
AUTHOR = {Magu, Georgiana and Lucaciu, Radu and Isar, Alexandru},
TITLE = {Improving the Targets’ Trajectories Estimated by an Automotive RADAR Sensor Using Polynomial Fitting},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {361},
URL = {https://www.mdpi.com/2076-3417/11/1/361},
ISSN = {2076-3417},
ABSTRACT = {A way to reduce the uncertainty at the output of a Kalman filter embedded into a tracker connected to an automotive RADAR sensor consists of the adaptive selection of parameters during the tracking process. Different informed strategies for automatically tuning the tracker&rsquo;s parameters and to jointly learn the parameters and state/output sequence using: expectation maximization; optimization approaches, including the simplex algorithm; coordinate descent; genetic algorithms; nonlinear programming using finite differencing to estimate the gradient; Bayesian optimization and reinforcement learning; automatically tuning hyper-parameters in the least squares, were already proposed. We develop here a different semi-blind post-processing approach, which is faster and more robust. Starting from the conjecture that the trajectory is polynomial in Cartesian coordinates, our method supposes to fit the data obtained at the output of the tracker to a polynomial. We highlight, by simulations, the improvement of the estimated trajectory&rsquo;s accuracy using the polynomial fitting for single and multiple targets. We propose a new polynomial fitting method based on wavelets in two steps: denoising and polynomial part extraction, which compares favorably with the classical polynomial fitting method. The effect of the proposed post-processing methods is visible, the accuracy of targets&rsquo; trajectories estimations being hardly increased.},
DOI = {10.3390/app11010361}
}



@Article{drones5010004,
AUTHOR = {Flores, Donovan and González-Hernández, Iván and Lozano, Rogelio and Vazquez-Nicolas, Jesus Manuel and Hernandez Toral, Jorge Luis},
TITLE = {Automated Agave Detection and Counting Using a Convolutional Neural Network and Unmanned Aerial Systems},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {4},
URL = {https://www.mdpi.com/2504-446X/5/1/4},
ISSN = {2504-446X},
ABSTRACT = {We present an automatic agave detection method for counting plants based on aerial data from a UAV (Unmanned Aerial Vehicle). Our objective is to autonomously count the number of agave plants in an area to aid management of the yield. An orthomosaic is obtained from agave plantations, which is then used to create a database. This database is in turn used to train a Convolutional Neural Network (CNN). The proposed method is based on computer image processing, and the CNN increases the detection performance of the approach. The main contribution of the present paper is to propose a method for agave plant detection with a high level of precision. In order to test the proposed method in a real agave plantation, we develop a UAV platform, which is equipped with several sensors to reach accurate counting. Therefore, our prototype can safely track a desired path to detect and count agave plants. For comparison purposes, we perform the same application using a simpler algorithm. The result shows that our proposed algorithm has better performance reaching an F1 score of 0.96 as opposed to 0.57 for the Haar algorithm. The obtained experimental results suggest that the proposed algorithm is robust and has considerable potential to help farmers manage agave agroecosystems.},
DOI = {10.3390/drones5010004}
}



@Article{rs13010127,
AUTHOR = {Yeh, Chia-Cheng and Chang, Yang-Lang and Alkhaleefah, Mohammad and Hsu, Pai-Hui and Eng, Weiyong and Koo, Voon-Chet and Huang, Bormin and Chang, Lena},
TITLE = {YOLOv3-Based Matching Approach for Roof Region Detection from Drone Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {127},
URL = {https://www.mdpi.com/2072-4292/13/1/127},
ISSN = {2072-4292},
ABSTRACT = {Due to the large data volume, the UAV image stitching and matching suffers from high computational cost. The traditional feature extraction algorithms&mdash;such as Scale-Invariant Feature Transform (SIFT), Speeded Up Robust Features (SURF), and Oriented FAST Rotated BRIEF (ORB)&mdash;require heavy computation to extract and describe features in high-resolution UAV images. To overcome this issue, You Only Look Once version 3 (YOLOv3) combined with the traditional feature point matching algorithms is utilized to extract descriptive features from the drone dataset of residential areas for roof detection. Unlike the traditional feature extraction algorithms, YOLOv3 performs the feature extraction solely on the proposed candidate regions instead of the entire image, thus the complexity of the image matching is reduced significantly. Then, all the extracted features are fed into Structural Similarity Index Measure (SSIM) to identify the corresponding roof region pair between consecutive image sequences. In addition, the candidate corresponding roof pair by our architecture serves as the coarse matching region pair and limits the search range of features matching to only the detected roof region. This further improves the feature matching consistency and reduces the chances of wrong feature matching. Analytical results show that the proposed method is 13&times; faster than the traditional image matching methods with comparable performance.},
DOI = {10.3390/rs13010127}
}



@Article{s21010256,
AUTHOR = {Han, Pengfei and Mei, Han and Liu, Di and Zeng, Ning and Tang, Xiao and Wang, Yinghong and Pan, Yuepeng},
TITLE = {Calibrations of Low-Cost Air Pollution Monitoring Sensors for CO, NO2, O3, and SO2},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {256},
URL = {https://www.mdpi.com/1424-8220/21/1/256},
PubMedID = {33401737},
ISSN = {1424-8220},
ABSTRACT = {Pollutant gases, such as CO, NO2, O3, and SO2 affect human health, and low-cost sensors are an important complement to regulatory-grade instruments in pollutant monitoring. Previous studies focused on one or several species, while comprehensive assessments of multiple sensors remain limited. We conducted a 12-month field evaluation of four Alphasense sensors in Beijing and used single linear regression (SLR), multiple linear regression (MLR), random forest regressor (RFR), and neural network (long short-term memory (LSTM)) methods to calibrate and validate the measurements with nearby reference measurements from national monitoring stations. For performances, CO &gt; O3 &gt; NO2 &gt; SO2 for the coefficient of determination (R2) and root mean square error (RMSE). The MLR did not increase the R2 after considering the temperature and relative humidity influences compared with the SLR (with R2 remaining at approximately 0.6 for O3 and 0.4 for NO2). However, the RFR and LSTM models significantly increased the O3, NO2, and SO2 performances, with the R2 increasing from 0.3&ndash;0.5 to &gt;0.7 for O3 and NO2, and the RMSE decreasing from 20.4 to 13.2 ppb for NO2. For the SLR, there were relatively larger biases, while the LSTMs maintained a close mean relative bias of approximately zero (e.g., &lt;5% for O3 and NO2), indicating that these sensors combined with the LSTMs are suitable for hot spot detection. We highlight that the performance of LSTM is better than that of random forest and linear methods. This study assessed four electrochemical air quality sensors and different calibration models, and the methodology and results can benefit assessments of other low-cost sensors.},
DOI = {10.3390/s21010256}
}



@Article{rs13010132,
AUTHOR = {Zhou, Ning and Lau, Lawrence and Bai, Ruibin and Moore, Terry},
TITLE = {A Genetic Optimization Resampling Based Particle Filtering Algorithm for Indoor Target Tracking},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {132},
URL = {https://www.mdpi.com/2072-4292/13/1/132},
ISSN = {2072-4292},
ABSTRACT = {In indoor target tracking based on wireless sensor networks, the particle filtering algorithm has been widely used because of its outstanding performance in coping with highly non-linear problems. Resampling is generally required to address the inherent particle degeneracy problem in the particle filter. However, traditional resampling methods cause the problem of particle impoverishment. This problem degrades positioning accuracy and robustness and sometimes may even result in filtering divergence and tracking failure. In order to mitigate the particle impoverishment and improve positioning accuracy, this paper proposes an improved genetic optimization based resampling method. This resampling method optimizes the distribution of resampled particles by the five operators, i.e., selection, roughening, classification, crossover, and mutation. The proposed resampling method is then integrated into the particle filtering framework to form a genetic optimization resampling based particle filtering (GORPF) algorithm. The performance of the GORPF algorithm is tested by a one-dimensional tracking simulation and a three-dimensional indoor tracking experiment. Both test results show that with the aid of the proposed resampling method, the GORPF has better robustness against particle impoverishment and achieves better positioning accuracy than several existing target tracking algorithms. Moreover, the GORPF algorithm owns an affordable computation load for real-time applications.},
DOI = {10.3390/rs13010132}
}



@Article{s21010301,
AUTHOR = {Panagiotidis, Dimitrios and Abdollahnejad, Azadeh and Slavík, Martin},
TITLE = {Assessment of Stem Volume on Plots Using Terrestrial Laser Scanner: A Precision Forestry Application},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {301},
URL = {https://www.mdpi.com/1424-8220/21/1/301},
PubMedID = {33466269},
ISSN = {1424-8220},
ABSTRACT = {Timber volume is an important asset, not only as an ecological component, but also as a key source of present and future revenues, which requires precise estimates. We used the Trimble TX8 survey-grade terrestrial laser scanner (TLS) to create a detailed 3D point cloud for extracting total tree height and diameter at breast height (1.3 m; DBH). We compared two different methods to accurately estimate total tree heights: the first method was based on a modified version of the local maxima algorithm for treetop detection, &ldquo;HTTD&rdquo;, and for the second method we used the centers of stem cross-sections at stump height (30 cm), &ldquo;HTSP&rdquo;. DBH was estimated by a computationally robust algebraic circle-fitting algorithm through hierarchical cluster analysis (HCA). This study aimed to assess the accuracy of these descriptors for evaluating total stem volume by comparing the results with the reference tree measurements. The difference between the estimated total stem volume from HTTD and measured stems was 2.732 m3 for European oak and 2.971 m3 for Norway spruce; differences between the estimated volume from HTSP and measured stems was 1.228 m3 and 2.006 m3 for European oak and Norway spruce, respectively. The coefficient of determination indicated a strong relationship between the measured and estimated total stem volumes from both height estimation methods with an R2 = 0.89 for HTTD and R2 = 0.87 for HTSP for European oak, and R2 = 0.98 for both HTTD and HTSP for Norway spruce. Our study has demonstrated the feasibility of finer-resolution remote sensing data for semi-automatic stem volumetric modeling of small-scale studies with high accuracy as a potential advancement in precision forestry.},
DOI = {10.3390/s21010301}
}



@Article{rs13010147,
AUTHOR = {De Swaef, Tom and Maes, Wouter H. and Aper, Jonas and Baert, Joost and Cougnon, Mathias and Reheul, Dirk and Steppe, Kathy and Roldán-Ruiz, Isabel and Lootens, Peter},
TITLE = {Applying RGB- and Thermal-Based Vegetation Indices from UAVs for High-Throughput Field Phenotyping of Drought Tolerance in Forage Grasses},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {147},
URL = {https://www.mdpi.com/2072-4292/13/1/147},
ISSN = {2072-4292},
ABSTRACT = {The persistence and productivity of forage grasses, important sources for feed production, are threatened by climate change-induced drought. Breeding programs are in search of new drought tolerant forage grass varieties, but those programs still rely on time-consuming and less consistent visual scoring by breeders. In this study, we evaluate whether Unmanned Aerial Vehicle (UAV) based remote sensing can complement or replace this visual breeder score. A field experiment was set up to test the drought tolerance of genotypes from three common forage types of two different species: Festuca arundinacea, diploid Lolium perenne and tetraploid Lolium perenne. Drought stress was imposed by using mobile rainout shelters. UAV flights with RGB and thermal sensors were conducted at five time points during the experiment. Visual-based indices from different colour spaces were selected that were closely correlated to the breeder score. Furthermore, several indices, in particular H and NDLab, from the HSV (Hue Saturation Value) and CIELab (Commission Internationale de l&rsquo;&eacute;clairage) colour space, respectively, displayed a broad-sense heritability that was as high or higher than the visual breeder score, making these indices highly suited for high-throughput field phenotyping applications that can complement or even replace the breeder score. The thermal-based Crop Water Stress Index CWSI provided complementary information to visual-based indices, enabling the analysis of differences in ecophysiological mechanisms for coping with reduced water availability between species and ploidy levels. All species/types displayed variation in drought stress tolerance, which confirms that there is sufficient variation for selection within these groups of grasses. Our results confirmed the better drought tolerance potential of Festuca arundinacea, but also showed which Lolium perenne genotypes are more tolerant.},
DOI = {10.3390/rs13010147}
}



@Article{rs13020162,
AUTHOR = {Qin, Jun and Wang, Biao and Wu, Yanlan and Lu, Qi and Zhu, Haochen},
TITLE = {Identifying Pine Wood Nematode Disease Using UAV Images and Deep Learning Algorithms},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {162},
URL = {https://www.mdpi.com/2072-4292/13/2/162},
ISSN = {2072-4292},
ABSTRACT = {Pine nematode is a highly contagious disease that causes great damage to the world&rsquo;s pine forest resources. Timely and accurate identification of pine nematode disease can help to control it. At present, there are few research on pine nematode disease identification, and it is difficult to accurately identify and locate nematode disease in a single pine by existing methods. This paper proposes a new network, SCANet (spatial-context-attention network), to identify pine nematode disease based on unmanned aerial vehicle (UAV) multi-spectral remote sensing images. In this method, a spatial information retention module is designed to reduce the loss of spatial information; it preserves the shallow features of pine nematode disease and expands the receptive field to enhance the extraction of deep features through a context information module. SCANet reached an overall accuracy of 79% and a precision and recall of around 0.86, and 0.91, respectively. In addition, 55 disease points among 59 known disease points were identified, which is better than other methods (DeepLab V3+, DenseNet, and HRNet). This paper presents a fast, precise, and practical method for identifying nematode disease and provides reliable technical support for the surveillance and control of pine wood nematode disease.},
DOI = {10.3390/rs13020162}
}



@Article{s21020343,
AUTHOR = {Bjerge, Kim and Nielsen, Jakob Bonde and Sepstrup, Martin Videbæk and Helsing-Nielsen, Flemming and Høye, Toke Thomas},
TITLE = {An Automated Light Trap to Monitor Moths (Lepidoptera) Using Computer Vision-Based Tracking and Deep Learning},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {343},
URL = {https://www.mdpi.com/1424-8220/21/2/343},
PubMedID = {33419136},
ISSN = {1424-8220},
ABSTRACT = {Insect monitoring methods are typically very time-consuming and involve substantial investment in species identification following manual trapping in the field. Insect traps are often only serviced weekly, resulting in low temporal resolution of the monitoring data, which hampers the ecological interpretation. This paper presents a portable computer vision system capable of attracting and detecting live insects. More specifically, the paper proposes detection and classification of species by recording images of live individuals attracted to a light trap. An Automated Moth Trap (AMT) with multiple light sources and a camera was designed to attract and monitor live insects during twilight and night hours. A computer vision algorithm referred to as Moth Classification and Counting (MCC), based on deep learning analysis of the captured images, tracked and counted the number of insects and identified moth species. Observations over 48 nights resulted in the capture of more than 250,000 images with an average of 5675 images per night. A customized convolutional neural network was trained on 2000 labeled images of live moths represented by eight different classes, achieving a high validation F1-score of 0.93. The algorithm measured an average classification and tracking F1-score of 0.71 and a tracking detection rate of 0.79. Overall, the proposed computer vision system and algorithm showed promising results as a low-cost solution for non-destructive and automatic monitoring of moths.},
DOI = {10.3390/s21020343}
}



@Article{ijgi10010018,
AUTHOR = {Doukari, Michaela and Katsanevakis, Stelios and Soulakellis, Nikolaos and Topouzelis, Konstantinos},
TITLE = {The Effect of Environmental Conditions on the Quality of UAS Orthophoto-Maps in the Coastal Environment},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {18},
URL = {https://www.mdpi.com/2220-9964/10/1/18},
ISSN = {2220-9964},
ABSTRACT = {Marine conservation and management require detailed and accurate habitat mapping, which is usually produced by collecting data using remote sensing methods. In recent years, unmanned aerial systems (UAS) are used for marine data acquisition, as they provide detailed and reliable information through very high-resolution orthophoto-maps. However, as for all remotely sensed data, it is important to study and understand the accuracy and reliability of the produced maps. In this study, the effect of different environmental conditions on the quality of UAS orthophoto-maps was examined through a positional and thematic accuracy assessment. Selected objects on the orthophoto-maps were also assessed as to their position, shape, and extent. The accuracy assessment results showed significant errors in the different maps and objects. The accuracy of the classified images varied between 2.1% and 27%. Seagrasses were under-classified, while the mixed substrate class was overclassified when environmental conditions were not optimal. The highest misclassifications were caused due to sunglint presence in combination with a rough sea-surface. A change detection workflow resulted in detecting misclassifications of up to 45%, on orthophoto-maps that had been generated under non-optimal environmental conditions. The results confirmed the importance of optimal conditions for the acquisition of reliable marine information using UAS.},
DOI = {10.3390/ijgi10010018}
}



@Article{robotics10010012,
AUTHOR = {Lim, Yixiang and Pongsakornsathien, Nichakorn and Gardi, Alessandro and Sabatini, Roberto and Kistan, Trevor and Ezer, Neta and Bursch, Daniel J.},
TITLE = {Adaptive Human-Robot Interactions for Multiple Unmanned Aerial Vehicles},
JOURNAL = {Robotics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {12},
URL = {https://www.mdpi.com/2218-6581/10/1/12},
ISSN = {2218-6581},
ABSTRACT = {Advances in unmanned aircraft systems (UAS) have paved the way for progressively higher levels of intelligence and autonomy, supporting new modes of operation, such as the one-to-many (OTM) concept, where a single human operator is responsible for monitoring and coordinating the tasks of multiple unmanned aerial vehicles (UAVs). This paper presents the development and evaluation of cognitive human-machine interfaces and interactions (CHMI2) supporting adaptive automation in OTM applications. A CHMI2 system comprises a network of neurophysiological sensors and machine-learning based models for inferring user cognitive states, as well as the adaptation engine containing a set of transition logics for control/display functions and discrete autonomy levels. Models of the user&rsquo;s cognitive states are trained on past performance and neurophysiological data during an offline calibration phase, and subsequently used in the online adaptation phase for real-time inference of these cognitive states. To investigate adaptive automation in OTM applications, a scenario involving bushfire detection was developed where a single human operator is responsible for tasking multiple UAV platforms to search for and localize bushfires over a wide area. We present the architecture and design of the UAS simulation environment that was developed, together with various human-machine interface (HMI) formats and functions, to evaluate the CHMI2 system&rsquo;s feasibility through human-in-the-loop (HITL) experiments. The CHMI2 module was subsequently integrated into the simulation environment, providing the sensing, inference, and adaptation capabilities needed to realise adaptive automation. HITL experiments were performed to verify the CHMI2 module&rsquo;s functionalities in the offline calibration and online adaptation phases. In particular, results from the online adaptation phase showed that the system was able to support real-time inference and human-machine interface and interaction (HMI2) adaptation. However, the accuracy of the inferred workload was variable across the different participants (with a root mean squared error (RMSE) ranging from 0.2 to 0.6), partly due to the reduced number of neurophysiological features available as real-time inputs and also due to limited training stages in the offline calibration phase. To improve the performance of the system, future work will investigate the use of alternative machine learning techniques, additional neurophysiological input features, and a more extensive training stage.},
DOI = {10.3390/robotics10010012}
}



@Article{su13020503,
AUTHOR = {Zhao, Rongkun and Li, Yuechen and Ma, Mingguo},
TITLE = {Mapping Paddy Rice with Satellite Remote Sensing: A Review},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {503},
URL = {https://www.mdpi.com/2071-1050/13/2/503},
ISSN = {2071-1050},
ABSTRACT = {Paddy rice is a staple food of three billion people in the world. Timely and accurate estimation of the paddy rice planting area and paddy rice yield can provide valuable information for the government, planners and decision makers to formulate policies. This article reviews the existing paddy rice mapping methods presented in the literature since 2010, classifies these methods, and analyzes and summarizes the basic principles, advantages and disadvantages of these methods. According to the data sources used, the methods are divided into three categories: (I) Optical mapping methods based on remote sensing; (II) Mapping methods based on microwave remote sensing; and (III) Mapping methods based on the integration of optical and microwave remote sensing. We found that the optical remote sensing data sources are mainly MODIS, Landsat, and Sentinel-2, and the emergence of Sentinel-1 data has promoted research on radar mapping methods for paddy rice. Multisource data integration further enhances the accuracy of paddy rice mapping. The best methods are phenology algorithms, paddy rice mapping combined with machine learning, and multisource data integration. Innovative methods include the time series similarity method, threshold method combined with mathematical models, and object-oriented image classification. With the development of computer technology and the establishment of cloud computing platforms, opportunities are provided for obtaining large-scale high-resolution rice maps. Multisource data integration, paddy rice mapping under different planting systems and the connection with global changes are the focus of future development priorities.},
DOI = {10.3390/su13020503}
}



@Article{rs13020183,
AUTHOR = {Avtar, Ram and Singh, Deepak and Umarhadi, Deha Agus and Yunus, Ali P. and Misra, Prakhar and Desai, Pranav N. and Kouser, Asma and Kurniawan, Tonni Agustiono and Phanindra, KBVN},
TITLE = {Impact of COVID-19 Lockdown on the Fisheries Sector: A Case Study from Three Harbors in Western India},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {183},
URL = {https://www.mdpi.com/2072-4292/13/2/183},
ISSN = {2072-4292},
ABSTRACT = {The COVID-19 related lockdowns have brought the planet to a standstill. It has severely shrunk the global economy in the year 2020, including India. The blue economy and especially the small-scale fisheries sector in India have dwindled due to disruptions in the fish catch, market, and supply chain. This research presents the applicability of satellite data to monitor the impact of COVID-19 related lockdown on the Indian fisheries sector. Three harbors namely Mangrol, Veraval, and Vankbara situated on the north-western coast of India were selected in this study based on characteristics like harbor&rsquo;s age, administrative control, and availability of cloud-free satellite images. To analyze the impact of COVID in the fisheries sector, we utilized high-resolution PlanetScope data for monitoring and comparison of &ldquo;area under fishing boats&rdquo; during the pre-lockdown, lockdown, and post-lockdown phases. A support vector machine (SVM) classification algorithm was used to identify the area under the boats. The classification results were complemented with socio-economic data and ground-level information for understanding the impact of the pandemic on the three sites. During the peak of the lockdown, it was found that the &ldquo;area under fishing boats&rdquo; near the docks and those parked on the land area increased by 483%, 189%, and 826% at Mangrol, Veraval, and Vanakbara harbor, respectively. After phase-I of lockdown, the number of parked vessels decreased, yet those already moved out to the land area were not returned until the south-west monsoon was over. A quarter of the annual production is estimated to be lost at the three harbors due to lockdown. Our last observation (September 2020) result shows that regular fishing activity has already been re-established in all three locations. PlanetScope data with daily revisit time has a higher potential to be used in the future and can help policymakers in making informed decisions vis-&agrave;-vis the fishing industry during an emergency situation like COVID-19.},
DOI = {10.3390/rs13020183}
}



@Article{en14020294,
AUTHOR = {Kulsinskas, Andrius and Durdevic, Petar and Ortiz-Arroyo, Daniel},
TITLE = {Internal Wind Turbine Blade Inspections Using UAVs: Analysis and Design Issues},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {294},
URL = {https://www.mdpi.com/1996-1073/14/2/294},
ISSN = {1996-1073},
ABSTRACT = {Interior and exterior wind turbine blade inspections are necessary to extend the lifetime of wind turbine generators. The use of unmanned vehicles is an alternative to exterior wind turbine blade inspections performed by technicians that require the use of cranes and ropes. Interior wind turbine blade inspections are even more challenging due to the confined spaces, lack of illumination, and the presence of potentially harmful internal structural components. Additionally, the cost of manned interior wind turbine blade inspections is a major limiting factor. This paper analyses all aspects of the viability of using manually controlled or autonomous aerial vehicles for interior wind turbine blade inspections. We discuss why the size, weight, and flight time of a vehicle, in addition to the structure of the wind turbine blade, are the main limiting factors in performing internal blade inspections. We also describe the design issues that must be considered to provide autonomy to unmanned vehicles and the control system, the sensors that can be used, and introduce some of the algorithms for localization, obstacle avoidance and path planning that are best suited for the task. Lastly, we briefly describe which non-destructive test instrumentation can be used for the purpose.},
DOI = {10.3390/en14020294}
}



@Article{app11020543,
AUTHOR = {Zhang, Tianxiang and Su, Jinya and Xu, Zhiyong and Luo, Yulin and Li, Jiangyun},
TITLE = {Sentinel-2 Satellite Imagery for Urban Land Cover Classification by Optimized Random Forest Classifier},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {543},
URL = {https://www.mdpi.com/2076-3417/11/2/543},
ISSN = {2076-3417},
ABSTRACT = {Land cover classification is able to reflect the potential natural and social process in urban development, providing vital information to stakeholders. Recent solutions on land cover classification are generally addressed by remotely sensed imagery and supervised classification methods. However, a high-performance classifier is desirable but challenging due to the existence of model hyperparameters. Conventional approaches generally rely on manual tuning, which is time-consuming and far from satisfying. Therefore, this work aims to propose a systematic method to automatically tune the hyperparameters by Bayesian parameter optimization for the random forest classifier. The recently launched Sentinel-2A/B satellites are drawn to provide the remote sensing imageries for land cover classification case study in Beijing, China, which have the best spectral/spatial resolutions among the freely available satellites. The improved random forest with Bayesian parameter optimization is compared against the support vector machine (SVM) and random forest (RF) with default hyperparameters by discriminating five land cover classes including building, tree, road, water, and crop field. Comparative experimental results show that the optimized RF classifier outperforms the conventional SVM and the RF with default hyperparameters in terms of accuracy, precision, and recall. The effects of band/feature number and the band usefulness are also assessed. It is envisaged that the improved classifier for Sentinel-2 satellite image processing can find a wide range of applications where high-resolution satellite imagery classification is applicable.},
DOI = {10.3390/app11020543}
}



@Article{s21020395,
AUTHOR = {Wei, Ziang and Fernandes, Henrique and Herrmann, Hans-Georg and Tarpani, Jose Ricardo and Osman, Ahmad},
TITLE = {A Deep Learning Method for the Impact Damage Segmentation of Curve-Shaped CFRP Specimens Inspected by Infrared Thermography},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {395},
URL = {https://www.mdpi.com/1424-8220/21/2/395},
PubMedID = {33429939},
ISSN = {1424-8220},
ABSTRACT = {Advanced materials such as continuous carbon fiber-reinforced thermoplastic (CFRP) laminates are commonly used in many industries, mainly because of their strength, stiffness to weight ratio, toughness, weldability, and repairability. Structural components working in harsh environments such as satellites are permanently exposed to some sort of damage during their lifetimes. To detect and characterize these damages, non-destructive testing and evaluation techniques are essential tools, especially for composite materials. In this study, artificial intelligence was applied in combination with infrared thermography to detected and segment impact damage on curved laminates that were previously submitted to a severe thermal stress cycles and subsequent ballistic impacts. Segmentation was performed on both mid-wave and long-wave infrared sequences obtained simultaneously during pulsed thermography experiments by means of a deep neural network. A deep neural network was trained for each wavelength. Both networks generated satisfactory results. The model trained with mid-wave images achieved an F1-score of 92.74% and the model trained with long-wave images achieved an F1-score of 87.39%.},
DOI = {10.3390/s21020395}
}



@Article{s21020399,
AUTHOR = {Mongay Batalla, Jordi and Mavromoustakis, Constandinos X. and Mastorakis, George and Markakis, Evangelos K. and Pallis, Evangelos and Wichary, Tomasz and Krawiec, Piotr and Lekston, Przemysław},
TITLE = {On Analyzing Routing Selection for Aerial Autonomous Vehicles Connected to Mobile Network},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {399},
URL = {https://www.mdpi.com/1424-8220/21/2/399},
PubMedID = {33430000},
ISSN = {1424-8220},
ABSTRACT = {This paper proposes a two-phase algorithm for multi-criteria selection of packet forwarding in unmanned aerial vehicles (UAV), which communicate with the control station through commercial mobile network. The selection of proper data forwarding in the two radio link: From UAV to the antenna and from the antenna to the control station, are independent but subject to constrains. The proposed approach is independent of the intra-domain forwarding, so it may be useful for a number of different scenarios of Unmanned Aerial Vehicles connectivity (e.g., a swarm of drones). In the implementation developed in this paper, the connection is served by three different mobile network operators in order to ensure reliable connectivity. The proposed algorithm makes use of Machine Learning tools that are properly trained for predicting the behavior of the link connectivity during the flight duration. The results presented in the last section validate the algorithm and the training process of the machines.},
DOI = {10.3390/s21020399}
}



@Article{rs13020197,
AUTHOR = {Dirscherl, Mariel and Dietz, Andreas J. and Kneisel, Christof and Kuenzer, Claudia},
TITLE = {A Novel Method for Automated Supraglacial Lake Mapping in Antarctica Using Sentinel-1 SAR Imagery and Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {197},
URL = {https://www.mdpi.com/2072-4292/13/2/197},
ISSN = {2072-4292},
ABSTRACT = {Supraglacial meltwater accumulation on ice sheets can be a main driver for accelerated ice discharge, mass loss, and global sea-level-rise. With further increasing surface air temperatures, meltwater-induced hydrofracturing, basal sliding, or surface thinning will cumulate and most likely trigger unprecedented ice mass loss on the Greenland and Antarctic ice sheets. While the Greenland surface hydrological network as well as its impacts on ice dynamics and mass balance has been studied in much detail, Antarctic supraglacial lakes remain understudied with a circum-Antarctic record of their spatio-temporal development entirely lacking. This study provides the first automated supraglacial lake extent mapping method using Sentinel-1 synthetic aperture radar (SAR) imagery over Antarctica and complements the developed optical Sentinel-2 supraglacial lake detection algorithm presented in our companion paper. In detail, we propose the use of a modified U-Net for semantic segmentation of supraglacial lakes in single-polarized Sentinel-1 imagery. The convolutional neural network (CNN) is implemented with residual connections for optimized performance as well as an Atrous Spatial Pyramid Pooling (ASPP) module for multiscale feature extraction. The algorithm is trained on 21,200 Sentinel-1 image patches and evaluated in ten spatially or temporally independent test acquisitions. In addition, George VI Ice Shelf is analyzed for intra-annual lake dynamics throughout austral summer 2019/2020 and a decision-level fused Sentinel-1 and Sentinel-2 maximum lake extent mapping product is presented for January 2020 revealing a more complete supraglacial lake coverage (~770 km2) than the individual single-sensor products. Classification results confirm the reliability of the proposed workflow with an average Kappa coefficient of 0.925 and a F1-score of 93.0% for the supraglacial water class across all test regions. Furthermore, the algorithm is applied in an additional test region covering supraglacial lakes on the Greenland ice sheet which further highlights the potential for spatio-temporal transferability. Future work involves the integration of more training data as well as intra-annual analyses of supraglacial lake occurrence across the whole continent and with focus on supraglacial lake development throughout a summer melt season and into Antarctic winter.},
DOI = {10.3390/rs13020197}
}



@Article{f12010066,
AUTHOR = {Korznikov, Kirill A. and Kislov, Dmitry E. and Altman, Jan and Doležal, Jiří and Vozmishcheva, Anna S. and Krestov, Pavel V.},
TITLE = {Using U-Net-Like Deep Convolutional Neural Networks for Precise Tree Recognition in Very High Resolution RGB (Red, Green, Blue) Satellite Images},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {66},
URL = {https://www.mdpi.com/1999-4907/12/1/66},
ISSN = {1999-4907},
ABSTRACT = {Very high resolution satellite imageries provide an excellent foundation for precise mapping of plant communities and even single plants. We aim to perform individual tree recognition on the basis of very high resolution RGB (red, green, blue) satellite images using deep learning approaches for northern temperate mixed forests in the Primorsky Region of the Russian Far East. We used a pansharpened satellite RGB image by GeoEye-1 with a spatial resolution of 0.46 m/pixel, obtained in late April 2019. We parametrized the standard U-Net convolutional neural network (CNN) and trained it in manually delineated satellite images to solve the satellite image segmentation problem. For comparison purposes, we also applied standard pixel-based classification algorithms, such as random forest, k-nearest neighbor classifier, naive Bayes classifier, and quadratic discrimination. Pattern-specific features based on grey level co-occurrence matrices (GLCM) were computed to improve the recognition ability of standard machine learning methods. The U-Net-like CNN allowed us to obtain precise recognition of Mongolian poplar (Populus suaveolens Fisch. ex Loudon s.l.) and evergreen coniferous trees (Abies holophylla Maxim., Pinus koraiensis Siebold &amp; Zucc.). We were able to distinguish species belonging to either poplar or coniferous groups but were unable to separate species within the same group (i.e. A. holophylla and P. koraiensis were not distinguishable). The accuracy of recognition was estimated by several metrics and exceeded values obtained for standard machine learning approaches. In contrast to pixel-based recognition algorithms, the U-Net-like CNN does not lead to an increase in false-positive decisions when facing green-colored objects that are similar to trees. By means of U-Net-like CNN, we obtained a mean accuracy score of up to 0.96 in our computational experiments. The U-Net-like CNN recognizes tree crowns not as a set of pixels with known RGB intensities but as spatial objects with a specific geometry and pattern. This CNN&rsquo;s specific feature excludes misclassifications related to objects of similar colors as objects of interest. We highlight that utilization of satellite images obtained within the suitable phenological season is of high importance for successful tree recognition. The suitability of the phenological season is conceptualized as a group of conditions providing highlighting objects of interest over other components of vegetation cover. In our case, the use of satellite images captured in mid-spring allowed us to recognize evergreen fir and pine trees as the first class of objects (&ldquo;conifers&rdquo;) and poplars as the second class, which were in a leafless state among other deciduous tree species.},
DOI = {10.3390/f12010066}
}



@Article{rs13020216,
AUTHOR = {Wang, Yutang and Wang, Jia and Chang, Shuping and Sun, Lu and An, Likun and Chen, Yuhan and Xu, Jiangqi},
TITLE = {Classification of Street Tree Species Using UAV Tilt Photogrammetry},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {216},
URL = {https://www.mdpi.com/2072-4292/13/2/216},
ISSN = {2072-4292},
ABSTRACT = {As an important component of the urban ecosystem, street trees have made an outstanding contribution to alleviating urban environmental pollution. Accurately extracting tree characteristics and species information can facilitate the monitoring and management of street trees, as well as aiding landscaping and studies of urban ecology. In this study, we selected the suburban areas of Beijing and Zhangjiakou and investigated six representative street tree species using unmanned aerial vehicle (UAV) tilt photogrammetry. We extracted five tree attributes and four combined attribute parameters and used four types of commonly-used machine learning classification algorithms as classifiers for tree species classification. The results show that random forest (RF), support vector machine (SVM), and back propagation (BP) neural network provide better classification results when using combined parameters for tree species classification, compared with those using individual tree attributes alone; however, the K-nearest neighbor (KNN) algorithm produced the opposite results. The best combination for classification is the BP neural network using combined attributes, with a classification precision of 89.1% and F-measure of 0.872, and we conclude that this approach best meets the requirements of street tree surveys. The results also demonstrate that optical UAV tilt photogrammetry combined with a machine learning classification algorithm is a low-cost, high-efficiency, and high-precision method for tree species classification.},
DOI = {10.3390/rs13020216}
}



@Article{jmse9010065,
AUTHOR = {Xu, Jin and Pan, Xinxiang and Jia, Baozhu and Wu, Xuerui and Liu, Peng and Li, Bo},
TITLE = {Oil Spill Detection Using LBP Feature and K-Means Clustering in Shipborne Radar Image},
JOURNAL = {Journal of Marine Science and Engineering},
VOLUME = {9},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {65},
URL = {https://www.mdpi.com/2077-1312/9/1/65},
ISSN = {2077-1312},
ABSTRACT = {Oil spill accidents have seriously harmed the marine environment. Effective oil spill monitoring can provide strong scientific and technological support for emergency response of law enforcement departments. Shipborne radar can be used to monitor oil spills immediately after the accident. In this paper, the original shipborne radar image collected by the teaching-practice ship Yukun of Dalian Maritime University during the oil spill accident of Dalian on 16 July 2010 was taken as the research data, and an oil spill detection method was proposed by using LBP texture feature and K-means algorithm. First, Laplacian operator, Otsu algorithm, and mean filter were used to suppress the co-frequency interference noises and high brightness pixels. Then the gray intensity correction matrix was used to reduce image nonuniformity. Next, using LBP texture feature and K-means clustering algorithm, the effective oil spill regions were extracted. Finally, the adaptive threshold was applied to identify the oil films. This method can automatically detect oil spills in shipborne radar image. It can provide a guarantee for real-time monitoring of oil spill accidents.},
DOI = {10.3390/jmse9010065}
}



@Article{w13020147,
AUTHOR = {Moeini, Mohammadreza and Shojaeizadeh, Ali and Geza, Mengistu},
TITLE = {Supervised Machine Learning for Estimation of Total Suspended Solids in Urban Watersheds},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {147},
URL = {https://www.mdpi.com/2073-4441/13/2/147},
ISSN = {2073-4441},
ABSTRACT = {Machine Learning (ML) algorithms provide an alternative for the prediction of pollutant concentration. We compared eight ML algorithms (Linear Regression (LR), uniform weighting k-Nearest Neighbor (UW-kNN), variable weighting k-Nearest Neighbor (VW-kNN), Support Vector Regression (SVR), Artificial Neural Network (ANN), Regression Tree (RT), Random Forest (RF), and Adaptive Boosting (AdB)) to evaluate the feasibility of ML approaches for estimation of Total Suspended Solids (TSS) using the national stormwater quality database. Six factors were used as features to train the algorithms with TSS concentration as the target parameter: Drainage area, land use, percent of imperviousness, rainfall depth, runoff volume, and antecedent dry days. Comparisons among the ML methods demonstrated a higher degree of variability in model performance, with the coefficient of determination (R2) and Nash&ndash;Sutcliffe (NSE) values ranging from 0.15 to 0.77. The Root Mean Square (RMSE) values ranged from 110 mg/L to 220 mg/L. The best fit was obtained using the AdB and RF models, with R2 values of 0.77 and 0.74 in the training step and 0.67 and 0.64 in the prediction step. The NSE values were 0.76 and 0.72 in the training step and 0.67 and 0.62 in the prediction step. The predictions from AdB were sensitive to all six factors. However, the sensitivity level was variable.},
DOI = {10.3390/w13020147}
}



@Article{ijgi10010022,
AUTHOR = {Yu, Tong and Wu, Wenjin and Gong, Chen and Li, Xinwu},
TITLE = {Residual Multi-Attention Classification Network for A Forest Dominated Tropical Landscape Using High-Resolution Remote Sensing Imagery},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {22},
URL = {https://www.mdpi.com/2220-9964/10/1/22},
ISSN = {2220-9964},
ABSTRACT = {Tropical forests are of vital importance for maintaining biodiversity, regulating climate and material cycles while facing deforestation, agricultural reclamation, and managing various pressures. Remote sensing (RS) can support effective monitoring and mapping approaches for tropical forests, and to facilitate this we propose a deep neural network with an encoder&ndash;decoder architecture here to classify tropical forests and their environment. To deal with the complexity of tropical landscapes, this method utilizes a multi-scale convolution neural network (CNN) to expand the receptive field and extract multi-scale features. The model refines the features with several attention modules and fuses them through an upsampling module. A two-stage training strategy is proposed to alleviate misclassifications caused by sample imbalances. A joint loss function based on cross-entropy loss and the generalized Dice loss is applied in the first stage, and the second stage used the focal loss to fine-tune the weights. As a case study, we use Hainan tropical reserves to test the performance of this model. Compared with four state-of-the-art (SOTA) semantic segmentation networks, our network achieves the best performance with two Hainan datasets (mean intersection over union (MIoU) percentages of 85.78% and 82.85%). We also apply the new model to classify a public true color dataset which has 17 semantic classes and obtain results with an 83.75% MIoU. This further demonstrates the applicability and potential of this model in complex classification tasks.},
DOI = {10.3390/ijgi10010022}
}



@Article{f12010076,
AUTHOR = {Guo, Yahui and Zeng, Jing and Wu, Wenxiang and Hu, Shunqiang and Liu, Guangxu and Wu, Linsheng and Bryant, Christopher Robin},
TITLE = {Spatial and Temporal Changes in Vegetation in the Ruoergai Region, China},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {76},
URL = {https://www.mdpi.com/1999-4907/12/1/76},
ISSN = {1999-4907},
ABSTRACT = {Timely monitoring of the changes in coverage and growth conditions of vegetation (forest, grass) is very important for preserving the regional and global ecological environment. Vegetation information is mainly reflected by its spectral characteristics, namely, differences and changes in green plant leaves and vegetation canopies in remote sensing domains. The normalized difference vegetation index (NDVI) is commonly used to describe the dynamic changes in vegetation, but the NDVI sequence is not long enough to support the exploration of dynamic changes due to many reasons, such as changes in remote sensing sensors. Thus, the NDVI from different sensors should be scientifically combined using logical methods. In this study, the Global Inventory Modeling and Mapping Studies (GIMMS) NDVI from the Advanced Very High Resolution Radiometer (AVHRR) and Moderate-resolution Imaging Spectroradiometer (MODIS) NDVI are combined using the Savitzky&ndash;Golay (SG) method and then utilized to investigate the temporal and spatial changes in the vegetation of the Ruoergai wetland area (RWA). The dynamic spatial and temporal changes and trends of the NDVI sequence in the RWA are analyzed to evaluate and monitor the growth conditions of vegetation in this region. In regard to annual changes, the average annual NDVI shows an overall increasing trend in this region during the past three decades, with a linear trend coefficient of 0.013/10a, indicating that the vegetation coverage has been continuously improving. In regard to seasonal changes, the linear trend coefficients of NDVI are 0.020, 0.021, 0.004, and 0.004/10a for spring, summer, autumn, and winter, respectively. The linear regression coefficient between the gross domestic product (GDP) and NDVI is also calculated, and the coefficients are 0.0024, 0.0015, and 0.0020, with coefficients of determination (R2) of 0.453, 0.463, and 0.444 for Aba, Ruoergai, and Hongyuan, respectively. Thus, the positive correlation coefficients between the GDP and the growth of NDVI may indicate that increased societal development promotes vegetation in some respects by resulting in the planting of more trees or the promotion of tree protection activities. Through the analysis of the temporal and spatial NDVI, it can be assessed that the vegetation coverage is relatively large and the growth condition of vegetation in this region is good overall.},
DOI = {10.3390/f12010076}
}



@Article{rs13020232,
AUTHOR = {Canata, Tatiana Fernanda and Wei, Marcelo Chan Fu and Maldaner, Leonardo Felipe and Molin, José Paulo},
TITLE = {Sugarcane Yield Mapping Using High-Resolution Imagery Data and Machine Learning Technique},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {232},
URL = {https://www.mdpi.com/2072-4292/13/2/232},
ISSN = {2072-4292},
ABSTRACT = {Yield maps provide essential information to guide precision agriculture (PA) practices. Yet, on-board yield monitoring for sugarcane can be challenging. At the same time, orbital images have been widely used for indirect crop yield estimation for many crops like wheat, corn, and rice, but not for sugarcane. Due to this, the objective of this study is to explore the potential of multi-temporal imagery data as an alternative for sugarcane yield mapping. The study was based on developing predictive sugarcane yield models integrating time-series orbital imaging and a machine learning technique. A commercial sugarcane site was selected, and Sentinel-2 images were acquired from the beginning of the ratoon sprouting until harvesting of two consecutive cropping seasons. The predictive yield models RF (Random forest) and MLR (Multiple Linear Regression) were developed using orbital images and yield maps generated by a commercial sensor-system on harvesting. Original yield data were filtered and interpolated with the same spatial resolution of the orbital images. The entire dataset was divided into training and testing datasets. Spectral bands, especially the near-infrared at tillering crop stage showed greater contribution to predicting sugarcane yield than the use of derived spectral vegetation indices. The Root Mean Squared Error (RMSE) obtained for the RF regression based on multiple spectral bands was 4.63 Mg ha&minus;1 with an R2 of 0.70 for the testing dataset. Overall, the RF regression had better performance than the MLR to predict sugarcane yield.},
DOI = {10.3390/rs13020232}
}



@Article{rs13020233,
AUTHOR = {Vuorinne, Ilja and Heiskanen, Janne and Pellikka, Petri K. E.},
TITLE = {Assessing Leaf Biomass of Agave sisalana Using Sentinel-2 Vegetation Indices},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {233},
URL = {https://www.mdpi.com/2072-4292/13/2/233},
ISSN = {2072-4292},
ABSTRACT = {Biomass is a principal variable in crop monitoring and management and in assessing carbon cycling. Remote sensing combined with field measurements can be used to estimate biomass over large areas. This study assessed leaf biomass of Agave sisalana (sisal), a perennial crop whose leaves are grown for fibre production in tropical and subtropical regions. Furthermore, the residue from fibre production can be used to produce bioenergy through anaerobic digestion. First, biomass was estimated for 58 field plots using an allometric approach. Then, Sentinel-2 multispectral satellite imagery was used to model biomass in an 8851-ha plantation in semi-arid south-eastern Kenya. Generalised Additive Models were employed to explore how well biomass was explained by various spectral vegetation indices (VIs). The highest performance (explained deviance = 76%, RMSE = 5.15 Mg ha&minus;1) was achieved with ratio and normalised difference VIs based on the green (R560), red-edge (R740 and R783), and near-infrared (R865) spectral bands. Heterogeneity of ground vegetation and resulting background effects seemed to limit model performance. The best performing VI (R740/R783) was used to predict plantation biomass that ranged from 0 to 46.7 Mg ha&minus;1 (mean biomass 10.6 Mg ha&minus;1). The modelling showed that multispectral data are suitable for assessing sisal leaf biomass at the plantation level and in individual blocks. Although these results demonstrate the value of Sentinel-2 red-edge bands at 20-m resolution, the difference from the best model based on green and near-infrared bands at 10-m resolution was rather small.},
DOI = {10.3390/rs13020233}
}



@Article{bdcc5010002,
AUTHOR = {Fenu, Gianni and Malloci, Francesca Maridina},
TITLE = {Forecasting Plant and Crop Disease: An Explorative Study on Current Algorithms},
JOURNAL = {Big Data and Cognitive Computing},
VOLUME = {5},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {2},
URL = {https://www.mdpi.com/2504-2289/5/1/2},
ISSN = {2504-2289},
ABSTRACT = {Every year, plant diseases cause a significant loss of valuable food crops around the world. The plant and crop disease management practice implemented in order to mitigate damages have changed considerably. Today, through the application of new information and communication technologies, it is possible to predict the onset or change in the severity of diseases using modern big data analysis techniques. In this paper, we present an analysis and classification of research studies conducted over the past decade that forecast the onset of disease at a pre-symptomatic stage (i.e., symptoms not visible to the naked eye) or at an early stage. We examine the specific approaches and methods adopted, pre-processing techniques and data used, performance metrics, and expected results, highlighting the issues encountered. The results of the study reveal that this practice is still in its infancy and that many barriers need to be overcome.},
DOI = {10.3390/bdcc5010002}
}



@Article{rs13020239,
AUTHOR = {Shao, Zhenfeng and Zhou, Zifan and Huang, Xiao and Zhang, Ya},
TITLE = {MRENet: Simultaneous Extraction of Road Surface and Road Centerline in Complex Urban Scenes from Very High-Resolution Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {239},
URL = {https://www.mdpi.com/2072-4292/13/2/239},
ISSN = {2072-4292},
ABSTRACT = {Automatic extraction of the road surface and road centerline from very high-resolution (VHR) remote sensing images has always been a challenging task in the field of feature extraction. Most existing road datasets are based on data with simple and clear backgrounds under ideal conditions, such as images derived from Google Earth. Therefore, the studies on road surface extraction and road centerline extraction under complex scenes are insufficient. Meanwhile, most existing efforts addressed these two tasks separately, without considering the possible joint extraction of road surface and centerline. With the introduction of multitask convolutional neural network models, it is possible to carry out these two tasks simultaneously by facilitating information sharing within a multitask deep learning model. In this study, we first design a challenging dataset using remote sensing images from the GF-2 satellite. The dataset contains complex road scenes with manually annotated images. We then propose a two-task and end-to-end convolution neural network, termed Multitask Road-related Extraction Network (MRENet), for road surface extraction and road centerline extraction. We take features extracted from the road as the condition of centerline extraction, and the information transmission and parameter sharing between the two tasks compensate for the potential problem of insufficient road centerline samples. In the network design, we use atrous convolutions and a pyramid scene parsing pooling module (PSP pooling), aiming to expand the network receptive field, integrate multilevel features, and obtain more abundant information. In addition, we use a weighted binary cross-entropy function to alleviate the background imbalance problem. Experimental results show that the proposed algorithm outperforms several comparative methods in the aspects of classification precision and visual interpretation.},
DOI = {10.3390/rs13020239}
}



@Article{s21020509,
AUTHOR = {Basan, Elena and Basan, Alexandr and Nekrasov, Alexey and Fidge, Colin and Gamec, Ján and Gamcová, Mária},
TITLE = {A Self-Diagnosis Method for Detecting UAV Cyber Attacks Based on Analysis of Parameter Changes},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {509},
URL = {https://www.mdpi.com/1424-8220/21/2/509},
PubMedID = {33450837},
ISSN = {1424-8220},
ABSTRACT = {We consider how to protect Unmanned Aerial Vehicles (UAVs) from Global Positioning System (GPS) spoofing attacks to provide safe navigation. The Global Navigation Satellite System (GNSS) is widely used for locating drones and is by far the most popular navigation solution. This is because of the simplicity and relatively low cost of this technology, as well as the accuracy of the transmitted coordinates. Nevertheless, there are many security threats to GPS navigation. These are primarily related to the nature of the GPS signal, as an intruder can jam and spoof the GPS signal. We discuss methods of protection against this type of attack and have developed an experimental stand and conducted scenarios of attacks on a drone&rsquo;s GPS system. Data from the UAV&rsquo;s flight log were collected and analyzed in order to see the attack&rsquo;s impact on sensor readings. From this we identify a new method for detecting UAV anomalies by analyzing changes in internal parameters of the UAV. This self-diagnosis method allows a UAV to independently assess the presence of changes in its own subsystems indicative of cyber attacks.},
DOI = {10.3390/s21020509}
}



@Article{s21020507,
AUTHOR = {Wang, Le and Xiang, Lirong and Tang, Lie and Jiang, Huanyu},
TITLE = {A Convolutional Neural Network-Based Method for Corn Stand Counting in the Field},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {507},
URL = {https://www.mdpi.com/1424-8220/21/2/507},
PubMedID = {33450839},
ISSN = {1424-8220},
ABSTRACT = {Accurate corn stand count in the field at early season is of great interest to corn breeders and plant geneticists. However, the commonly used manual counting method is time consuming, laborious, and prone to error. Nowadays, unmanned aerial vehicles (UAV) tend to be a popular base for plant-image-collecting platforms. However, detecting corn stands in the field is a challenging task, primarily because of camera motion, leaf fluttering caused by wind, shadows of plants caused by direct sunlight, and the complex soil background. As for the UAV system, there are mainly two limitations for early seedling detection and counting. First, flying height cannot ensure a high resolution for small objects. It is especially difficult to detect early corn seedlings at around one week after planting, because the plants are small and difficult to differentiate from the background. Second, the battery life and payload of UAV systems cannot support long-duration online counting work. In this research project, we developed an automated, robust, and high-throughput method for corn stand counting based on color images extracted from video clips. A pipeline developed based on the YoloV3 network and Kalman filter was used to count corn seedlings online. The results demonstrate that our method is accurate and reliable for stand counting, achieving an accuracy of over 98% at growth stages V2 and V3 (vegetative stages with two and three visible collars) with an average frame rate of 47 frames per second (FPS). This pipeline can also be mounted easily on manned cart, tractor, or field robotic systems for online corn counting.},
DOI = {10.3390/s21020507}
}



@Article{rs13020260,
AUTHOR = {Nguyen, Ha Trang and Lopez Caceres, Maximo Larry and Moritake, Koma and Kentsch, Sarah and Shu, Hase and Diez, Yago},
TITLE = {Individual Sick Fir Tree (Abies mariesii) Identification in Insect Infested Forests by Means of UAV Images and Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {260},
URL = {https://www.mdpi.com/2072-4292/13/2/260},
ISSN = {2072-4292},
ABSTRACT = {Insect outbreaks are a recurrent natural phenomenon in forest ecosystems expected to increase due to climate change. Recent advances in Unmanned Aerial Vehicles (UAV) and Deep Learning (DL) Networks provide us with tools to monitor them. In this study we used nine orthomosaics and normalized Digital Surface Models (nDSM) to detect and classify healthy and sick Maries fir trees as well as deciduous trees. This study aims at automatically classifying treetops by means of a novel computer vision treetops detection algorithm and the adaptation of existing DL architectures. Considering detection alone, the accuracy results showed 85.70% success. In terms of detection and classification, we were able to detect/classify correctly 78.59% of all tree classes (39.64% for sick fir). However, with data augmentation, detection/classification percentage of the sick fir class rose to 73.01% at the cost of the result accuracy of all tree classes that dropped 63.57%. The implementation of UAV, computer vision and DL techniques contribute to the development of a new approach to evaluate the impact of insect outbreaks in forest.},
DOI = {10.3390/rs13020260}
}



@Article{electronics10020169,
AUTHOR = {Hashima, Sherief and ElHalawany, Basem M. and Hatano, Kohei and Wu, Kaishun and Mohamed, Ehab Mahmoud},
TITLE = {Leveraging Machine-Learning for D2D Communications in 5G/Beyond 5G Networks},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {169},
URL = {https://www.mdpi.com/2079-9292/10/2/169},
ISSN = {2079-9292},
ABSTRACT = {Device-to-device (D2D) communication is a promising paradigm for the fifth generation (5G) and beyond 5G (B5G) networks. Although D2D communication provides several benefits, including limited interference, energy efficiency, reduced delay, and network overhead, it faces a lot of technical challenges such as network architecture, and neighbor discovery, etc. The complexity of configuring D2D links and managing their interference, especially when using millimeter-wave (mmWave), inspire researchers to leverage different machine-learning (ML) techniques to address these problems towards boosting the performance of D2D networks. In this paper, a comprehensive survey about recent research activities on D2D networks will be explored with putting more emphasis on utilizing mmWave and ML methods. After exploring existing D2D research directions accompanied with their existing conventional solutions, we will show how different ML techniques can be applied to enhance the D2D networks performance over using conventional ways. Then, still open research directions in ML applications on D2D networks will be investigated including their essential needs. A case study of applying multi-armed bandit (MAB) as an efficient online ML tool to enhance the performance of neighbor discovery and selection (NDS) in mmWave D2D networks will be presented. This case study will put emphasis on the high potency of using ML solutions over using the conventional non-ML based methods for highly improving the average throughput performance of mmWave NDS.},
DOI = {10.3390/electronics10020169}
}



@Article{aerospace8010018,
AUTHOR = {Wada, Daichi and Araujo-Estrada, Sergio A. and Windsor, Shane},
TITLE = {Unmanned Aerial Vehicle Pitch Control Using Deep Reinforcement Learning with Discrete Actions in Wind Tunnel Test},
JOURNAL = {Aerospace},
VOLUME = {8},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {18},
URL = {https://www.mdpi.com/2226-4310/8/1/18},
ISSN = {2226-4310},
ABSTRACT = {Deep reinforcement learning is a promising method for training a nonlinear attitude controller for fixed-wing unmanned aerial vehicles. Until now, proof-of-concept studies have demonstrated successful attitude control in simulation. However, detailed experimental investigations have not yet been conducted. This study applied deep reinforcement learning for one-degree-of-freedom pitch control in wind tunnel tests with the aim of gaining practical understandings of attitude control application. Three controllers with different discrete action choices, that is, elevator angles, were designed. The controllers with larger action rates exhibited better performance in terms of following angle-of-attack commands. The root mean square errors for tracking angle-of-attack commands decreased from 3.42&deg; to 1.99&deg; as the maximum action rate increased from 10&deg;/s to 50&deg;/s. The comparison between experimental and simulation results showed that the controller with a smaller action rate experienced the friction effect, and the controllers with larger action rates experienced fluctuating behaviors in elevator maneuvers owing to delay. The investigation of the effect of friction and delay on pitch control highlighted the importance of conducting experiments to understand actual control performances, specifically when the controllers were trained with a low-fidelity model.},
DOI = {10.3390/aerospace8010018}
}



@Article{brainsci11010106,
AUTHOR = {Andreu-Perez, Ana R. and Kiani, Mehrin and Andreu-Perez, Javier and Reddy, Pratusha and Andreu-Abela, Jaime and Pinto, Maria and Izzetoglu, Kurtulus},
TITLE = {Single-Trial Recognition of Video Gamer’s Expertise from Brain Haemodynamic and Facial Emotion Responses},
JOURNAL = {Brain Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {106},
URL = {https://www.mdpi.com/2076-3425/11/1/106},
PubMedID = {33466787},
ISSN = {2076-3425},
ABSTRACT = {With an increase in consumer demand of video gaming entertainment, the game industry is exploring novel ways of game interaction such as providing direct interfaces between the game and the gamers&rsquo; cognitive or affective responses. In this work, gamer&rsquo;s brain activity has been imaged using functional near infrared spectroscopy (fNIRS) whilst they watch video of a video game (League of Legends) they play. A video of the face of the participants is also recorded for each of a total of 15 trials where a trial is defined as watching a gameplay video. From the data collected, i.e., gamer&rsquo;s fNIRS data in combination with emotional state estimation from gamer&rsquo;s facial expressions, the expertise level of the gamers has been decoded per trial in a multi-modal framework comprising of unsupervised deep feature learning and classification by state-of-the-art models. The best tri-class classification accuracy is obtained using a cascade of random convolutional kernel transform (ROCKET) feature extraction method and deep classifier at 91.44%. This is the first work that aims at decoding expertise level of gamers using non-restrictive and portable technologies for brain imaging, and emotional state recognition derived from gamers&rsquo; facial expressions. This work has profound implications for novel designs of future human interactions with video games and brain-controlled games.},
DOI = {10.3390/brainsci11010106}
}



@Article{rs13020278,
AUTHOR = {Zheng, Qiong and Ye, Huichun and Huang, Wenjiang and Dong, Yingying and Jiang, Hao and Wang, Chongyang and Li, Dan and Wang, Li and Chen, Shuisen},
TITLE = {Integrating Spectral Information and Meteorological Data to Monitor Wheat Yellow Rust at a Regional Scale: A Case Study},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {278},
URL = {https://www.mdpi.com/2072-4292/13/2/278},
ISSN = {2072-4292},
ABSTRACT = {Wheat yellow rust has a severe impact on wheat production and threatens food security in China; as such, an effective monitoring method is necessary at the regional scale. We propose a model for yellow rust monitoring based on Sentinel-2 multispectral images and a series of two-stage vegetation indices and meteorological data. Sensitive spectral vegetation indices (single- and two-stage indices) and meteorological features for wheat yellow rust discrimination were selected using the random forest method. Wheat yellow rust monitoring models were established using three different classification methods: linear discriminant analysis (LDA), support vector machine (SVM), and artificial neural network (ANN). The results show that models based on two-stage indices (i.e., those calculated using images from two different days) significantly outperform single-stage index models (i.e., those calculated using an image from a single day), the overall accuracy improved from 63.2% to 78.9%. The classification accuracies of models combining a vegetation index with meteorological feature are higher than those of pure vegetation index models. Among them, the model based on two-stage vegetation indices and meteorological features performs best, with a classification accuracy exceeding 73.7%. The SVM algorithm performed best for wheat yellow rust monitoring among the three algorithms; its classification accuracy (84.2%) was ~10.5% and 5.3% greater than those of LDA and ANN, respectively. Combined with crop growth and environmental information, our model has great potential for monitoring wheat yellow rust at a regional scale. Future work will focus on regional-scale monitoring and forecasting of crop disease.},
DOI = {10.3390/rs13020278}
}



@Article{urbansci5010008,
AUTHOR = {Raheem, Dele and Dayoub, Moammar and Birech, Rhoda and Nakiyemba, Alice},
TITLE = {The Contribution of Cereal Grains to Food Security and Sustainability in Africa: Potential Application of UAV in Ghana, Nigeria, Uganda, and Namibia},
JOURNAL = {Urban Science},
VOLUME = {5},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {8},
URL = {https://www.mdpi.com/2413-8851/5/1/8},
ISSN = {2413-8851},
ABSTRACT = {Africa is a net importer of food, especially cereal grains, despite the importance of agriculture in the continent. The agricultural growth in Africa has been undermined by low investment in agriculture, poor infrastructure, high population growth rate, and low adoption of technologies. The agri-food value chain in many African countries will benefit from the adoption of appropriate technologies that are available in the digital landscape to leverage the agricultural sector, make it more attractive to the teeming youth population, and to reverse rural-urban migration. Attention to indigenous cereal grains and other crops that are grown locally and processed into different local foods would ensure food security. However, the availability of these crops in the market is often reduced due to damage before harvest by pests and predators leading to economic losses for farmers. In this article, we review the literature from a multidisciplinary perspective on the relevance of African indigenous food grains to food security in general and we highlight the potential application of drones to increase the yield of cereal grains in three regions of the continent&mdash;eastern, western, and southern Africa.},
DOI = {10.3390/urbansci5010008}
}



@Article{su13020766,
AUTHOR = {Ma, Yongfeng and Gu, Xin and Yu, Ya’nan and Khattakc, Aemal J. and Chen, Shuyan and Tang, Kun},
TITLE = {Identification of Contributing Factors for Driver’s Perceptual Bias of Aggressive Driving in China},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {766},
URL = {https://www.mdpi.com/2071-1050/13/2/766},
ISSN = {2071-1050},
ABSTRACT = {Aggressive driving is common across the world. While most aggressive driving is conscious, some aggressive driving behavior may be unconscious on part of motor vehicle drivers. Perceptual bias of aggressive driving behavior is one of the main causes of traffic accidents. This paper focuses on identifying impact factors related to aggressive driving perceptual bias. Questionnaire data from 690 drivers, collected from a drivers&rsquo; retraining course administered by the Traffic Management Bureau in Nanjing, China, were used to collect drivers&rsquo; socioeconomic characteristics, personality traits, and external environment data. Actual penalty points were considered as an objective indicator and Gaussian mixture model (GMM) was used to cluster an objective indicator into different levels. The driving anger expression (DAX) was used to measure drivers&rsquo; self-assessment of aggressive driving behavior and then to identify perceptual biases. Then a binary logistic model was estimated to explore the influence of different factors on drivers&rsquo; perceptual bias of aggressive driving behavior. Results showed that bus drivers were less likely to have perceptual bias of aggressive driving behavior. Truck drivers, drivers with an extraversion characteristic, and drivers who have dissatisfaction with road infrastructure and actual work were likely to have a perceptual bias. The findings are potentially beneficial for proposing targeted countermeasures to identify dangerous drivers and improve drivers&rsquo; safety awareness.},
DOI = {10.3390/su13020766}
}



@Article{rs13020283,
AUTHOR = {Zhang, Junzhe and Guo, Wei and Zhou, Bo and Okin, Gregory S.},
TITLE = {Drone-Based Remote Sensing for Research on Wind Erosion in Drylands: Possible Applications},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {283},
URL = {https://www.mdpi.com/2072-4292/13/2/283},
ISSN = {2072-4292},
ABSTRACT = {With rapid innovations in drone, camera, and 3D photogrammetry, drone-based remote sensing can accurately and efficiently provide ultra-high resolution imagery and digital surface model (DSM) at a landscape scale. Several studies have been conducted using drone-based remote sensing to quantitatively assess the impacts of wind erosion on the vegetation communities and landforms in drylands. In this study, first, five difficulties in conducting wind erosion research through data collection from fieldwork are summarized: insufficient samples, spatial displacement with auxiliary datasets, missing volumetric information, a unidirectional view, and spatially inexplicit input. Then, five possible applications&mdash;to provide a reliable and valid sample set, to mitigate the spatial offset, to monitor soil elevation change, to evaluate the directional property of land cover, and to make spatially explicit input for ecological models&mdash;of drone-based remote sensing products are suggested. To sum up, drone-based remote sensing has become a useful method to research wind erosion in drylands, and can solve the issues caused by using data collected from fieldwork. For wind erosion research in drylands, we suggest that a drone-based remote sensing product should be used as a complement to field measurements.},
DOI = {10.3390/rs13020283}
}



@Article{s21020581,
AUTHOR = {Zhang, Xiaomin and Zhao, Zhiyao and Wang, Zhaoyang and Wang, Xiaoyi},
TITLE = {Fault Detection and Identification Method for Quadcopter Based on Airframe Vibration Signals},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {581},
URL = {https://www.mdpi.com/1424-8220/21/2/581},
PubMedID = {33467463},
ISSN = {1424-8220},
ABSTRACT = {Quadcopters are widely used in a variety of military and civilian mission scenarios. Real-time online detection of the abnormal state of the quadcopter is vital to the safety of aircraft. Existing data-driven fault detection methods generally usually require numerous sensors to collect data. However, quadcopter airframe space is limited. A large number of sensors cannot be loaded, meaning that it is difficult to use additional sensors to capture fault signals for quadcopters. In this paper, without additional sensors, a Fault Detection and Identification (FDI) method for quadcopter blades based on airframe vibration signals is proposed using the airborne acceleration sensor. This method integrates multi-axis data information and effectively detects and identifies quadcopter blade faults through Long and Short-Term Memory (LSTM) network models. Through flight experiments, the quadcopter triaxial accelerometer data are collected for airframe vibration signals at first. Then, the wavelet packet decomposition method is employed to extract data features, and the standard deviations of the wavelet packet coefficients are employed to form the feature vector. Finally, the LSTM-based FDI model is constructed for quadcopter blade FDI. The results show that the method can effectively detect and identify quadcopter blade faults with a better FDI performance and a higher model accuracy compared with the Back Propagation (BP) neural network-based FDI model.},
DOI = {10.3390/s21020581}
}



@Article{rs13020290,
AUTHOR = {Hamilton, Dale A. and Brothers, Kamden L. and Jones, Samuel D. and Colwell, Jason and Winters, Jacob},
TITLE = {Wildland Fire Tree Mortality Mapping from Hyperspatial Imagery Using Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {290},
URL = {https://www.mdpi.com/2072-4292/13/2/290},
ISSN = {2072-4292},
ABSTRACT = {The use of imagery from small unmanned aircraft systems (sUAS) has enabled the production of more accurate data about the effects of wildland fire, enabling land managers to make more informed decisions. The ability to detect trees in hyperspatial imagery enables the calculation of canopy cover. A comparison of hyperspatial post-fire canopy cover and pre-fire canopy cover from sources such as the LANDFIRE project enables the calculation of tree mortality, which is a major indicator of burn severity. A mask region-based convolutional neural network was trained to classify trees as groups of pixels from a hyperspatial orthomosaic acquired with a small unmanned aircraft system. The tree classification is summarized at 30 m, resulting in a canopy cover raster. A post-fire canopy cover is then compared to LANDFIRE canopy cover preceding the fire, calculating how much the canopy was reduced due to the fire. Canopy reduction allows the mapping of burn severity while also identifying where surface, passive crown, and active crown fire occurred within the burn perimeter. Canopy cover mapped through this effort was lower than the LANDFIRE Canopy Cover product, which literature indicated is typically over reported. Assessment of canopy reduction mapping on a wildland fire reflects observations made both from ground truthing efforts as well as observations made of the associated hyperspatial sUAS orthomosaic.},
DOI = {10.3390/rs13020290}
}



@Article{rs13020289,
AUTHOR = {Debella-Gilo, Misganu and Gjertsen, Arnt Kristian},
TITLE = {Mapping Seasonal Agricultural Land Use Types Using Deep Learning on Sentinel-2 Image Time Series},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {289},
URL = {https://www.mdpi.com/2072-4292/13/2/289},
ISSN = {2072-4292},
ABSTRACT = {The size and location of agricultural fields that are in active use and the type of use during the growing season are among the vital information that is needed for the careful planning and forecasting of agricultural production at national and regional scales. In areas where such data are not readily available, an independent seasonal monitoring method is needed. Remote sensing is a widely used tool to map land use types, although there are some limitations that can partly be circumvented by using, among others, multiple observations, careful feature selection and appropriate analysis methods. Here, we used Sentinel-2 satellite image time series (SITS) over the land area of Norway to map three agricultural land use classes: cereal crops, fodder crops (grass) and unused areas. The Multilayer Perceptron (MLP) and two variants of the Convolutional Neural Network (CNN), are implemented on SITS data of four different temporal resolutions. These enabled us to compare twelve model-dataset combinations to identify the model-dataset combination that results in the most accurate predictions. The CNN is implemented in the spectral and temporal dimensions instead of the conventional spatial dimension. Rather than using existing deep learning architectures, an autotuning procedure is implemented so that the model hyperparameters are empirically optimized during the training. The results obtained on held-out test data show that up to 94% overall accuracy and 90% Cohen&rsquo;s Kappa can be obtained when the 2D CNN is applied on the SITS data with a temporal resolution of 7 days. This is closely followed by the 1D CNN on the same dataset. However, the latter performs better than the former in predicting data outside the training set. It is further observed that cereal is predicted with the highest accuracy, followed by grass. Predicting the unused areas has been found to be difficult as there is no distinct surface condition that is common for all unused areas.},
DOI = {10.3390/rs13020289}
}



@Article{rs13020291,
AUTHOR = {Fernández-Lozano, Javier and Sanz-Ablanedo, Enoc},
TITLE = {Unraveling the Morphological Constraints on Roman Gold Mining Hydraulic Infrastructure in NW Spain. A UAV-Derived Photogrammetric and Multispectral Approach},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {291},
URL = {https://www.mdpi.com/2072-4292/13/2/291},
ISSN = {2072-4292},
ABSTRACT = {The province of Le&oacute;n preserves a unique hydraulic infrastructure 1200 km-long, used for the exploitation of auriferous deposits in Roman times. It represents the most extensive waterworks in Europe and is one of the best-preserved examples of mining heritage in Antiquity. In this work, three mining exploitation sectors (upper, middle, and lower) characterized by channels and leats developed in different geological materials were examined, using Unmanned Aerial Vehicles (UAVs). A multi-approach based on a comparison of photogrammetric and multispectral data improved the identification and description of the hydraulic network. Comparison with traditional orthoimages and LiDAR data suggests that UAV-derived multispectral images are of great interest in areas where these sets of data have low resolution or areas that are densely covered by vegetation. The results showed that the size of the channel box and its width were factors that do not depend exclusively on the available water resources, as previously suggested, but also on the geological and hydraulic conditioning factors that intervene in each sector. Additionally, the detailed study allowed the establishment of a water sheet maximum height that was much lower than previously thought. All in all, these inferences might help researchers develop new strategies for mapping the Roman mining infrastructure and establishing the importance of geological inheritance on the construction of the hydraulic system that led the Romans to the accomplishment of the largest mining infrastructure ever known in Europe.},
DOI = {10.3390/rs13020291}
}



@Article{rs13020308,
AUTHOR = {Biney, James Kobina Mensah and Saberioon, Mohammadmehdi and Borůvka, Luboš and Houška, Jakub and Vašát, Radim and Chapman Agyeman, Prince and Coblinski, João Augusto and Klement, Aleš},
TITLE = {Exploring the Suitability of UAS-Based Multispectral Images for Estimating Soil Organic Carbon: Comparison with Proximal Soil Sensing and Spaceborne Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {308},
URL = {https://www.mdpi.com/2072-4292/13/2/308},
ISSN = {2072-4292},
ABSTRACT = {Soil organic carbon (SOC) is a variable of vital environmental significance in terms of soil quality and function, global food security, and climate change mitigation. Estimation of its content and prediction accuracy on a broader scale remain crucial. Although, spectroscopy under proximal sensing remains one of the best approaches to accurately predict SOC, however, spectroscopy limitation to estimate SOC on a larger spatial scale remains a concern. Therefore, for an efficient quantification of SOC content, faster and less costly techniques are needed, recent studies have suggested the use of remote sensing approaches. The primary aim of this research was to evaluate and compare the capabilities of small Unmanned Aircraft Systems (UAS) for monitoring and estimation of SOC with those obtained from spaceborne (Sentinel-2) and proximal soil sensing (field spectroscopy measurements) on an agricultural field low in SOC content. Nine calculated spectral indices were added to the remote sensing approaches (UAS and Sentinel-2) to enhance their predictive accuracy. Modeling was carried out using various bands/wavelength (UAS (6), Sentinel-2 (9)) and the calculated spectral indices were used as independent variables to generate soil prediction models using five-fold cross-validation built using random forest (RF) and support vector machine regression (SVMR). The correlation regarding SOC and the selected indices and bands/wavelengths was determined prior to the prediction. Our results revealed that the selected spectral indices slightly influenced the output of UAS compared to Sentinel-2 dataset as the latter had only one index correlated with SOC. For prediction, the models built on UAS data had a better accuracy with RF than the two other data used. However, using SVMR, the field spectral prediction models achieved a better overall result for the entire study (log(1/R), RPD = 1.40; R2CV = 0.48; RPIQ = 1.65; RMSEPCV = 0.24), followed by UAS and then Sentinel-2, respectively. This study has shown that UAS imagery can be exploited efficiently using spectral indices.},
DOI = {10.3390/rs13020308}
}



@Article{agronomy11010174,
AUTHOR = {Li, Haolu and Wang, Guojie and Dong, Zhen and Wei, Xikun and Wu, Mengjuan and Song, Huihui and Amankwah, Solomon Obiri Yeboah},
TITLE = {Identifying Cotton Fields from Remote Sensing Images Using Multiple Deep Learning Networks},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {174},
URL = {https://www.mdpi.com/2073-4395/11/1/174},
ISSN = {2073-4395},
ABSTRACT = {Remote sensing imageries processed through empirical and deterministic approaches help predict multiple agronomic traits throughout the growing season. Accurate identification of cotton crop from remotely sensed imageries is a significant task in precision agriculture. This study aims to utilize a deep learning-based framework for cotton crop field identification with Gaofen-1 (GF-1) high-resolution (16 m) imageries in Wei-Ku region, China. An optimized model for the pixel-wise multidimensional densely connected convolutional neural network (DenseNet) was used. Four widely-used classic convolutional neural networks (CNNs), including ResNet, VGG, SegNet, and DeepLab v3+, were also used for accuracy assessment. The results infer that DenseNet can identify cotton crop features within a relatively shorter time about 5 h for training convergence. The model performance was examined by multiple indicators (P, F1, R, and mIou) produced through the confusion matrix, and the derived cotton fields were then visualized. The DenseNet model has illustrated considerable improvements in comparison with the preceding mainstream models. The results showed that the retrieval precision was 0.948, F1 score was 0.953, and mIou was 0.911. Furthermore, its performance is relatively better in discriminating cotton crop fields&rsquo; fine structures when clouds, mountain shadows, and urban built up.},
DOI = {10.3390/agronomy11010174}
}



@Article{s21020638,
AUTHOR = {Ni, Ming and Wang, Hongjie and Liu, Xudong and Liao, Yilin and Fu, Lin and Wu, Qianqian and Mu, Jiong and Chen, Xiaoyan and Li, Jun},
TITLE = {Design of Variable Spray System for Plant Protection UAV Based on CFD Simulation and Regression Analysis},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {638},
URL = {https://www.mdpi.com/1424-8220/21/2/638},
PubMedID = {33477600},
ISSN = {1424-8220},
ABSTRACT = {Multi-rotor unmanned aerial vehicles (UAVs) for plant protection are widely used in China&rsquo;s agricultural production. However, spray droplets often drift and distribute nonuniformly, thereby harming its utilization and the environment. A variable spray system is designed, discussed, and verified to solve this problem. The distribution characteristics of droplet deposition under different spray states (flight state, environment state, nozzle state) are obtained through computational fluid dynamics simulation. In the verification experiment, the wind velocity error of most sample points is less than 1 m/s, and the deposition ratio error is less than 10%, indicating that the simulation is reliable. A simulation data set is used to train support vector regression and back propagation neural network with multiple parameters. An optimal regression model with the root mean square error of 6.5% is selected. The UAV offset and nozzle flow of the variable spray system can be obtained in accordance with the current spray state by multi-sensor fusion and the predicted deposition distribution characteristics. The farmland experiment shows that the deposition volume error between the prediction and experiment is within 30%, thereby proving the effectiveness of the system. This article provides a reference for the improvement of UAV intelligent spray system.},
DOI = {10.3390/s21020638}
}



@Article{ijgi10010039,
AUTHOR = {Zhou, Kai and Xie, Yan and Gao, Zhan and Miao, Fang and Zhang, Lei},
TITLE = {FuNet: A Novel Road Extraction Network with Fusion of Location Data and Remote Sensing Imagery},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {39},
URL = {https://www.mdpi.com/2220-9964/10/1/39},
ISSN = {2220-9964},
ABSTRACT = {Road semantic segmentation is unique and difficult. Road extraction from remote sensing imagery often produce fragmented road segments leading to road network disconnection due to the occlusion of trees, buildings, shadows, cloud, etc. In this paper, we propose a novel fusion network (FuNet) with fusion of remote sensing imagery and location data, which plays an important role of location data in road connectivity reasoning. A universal iteration reinforcement (IteR) module is embedded into FuNet to enhance the ability of network learning. We designed the IteR formula to repeatedly integrate original information and prediction information and designed the reinforcement loss function to control the accuracy of road prediction output. Another contribution of this paper is the use of histogram equalization data pre-processing to enhance image contrast and improve the accuracy by nearly 1%. We take the excellent D-LinkNet as the backbone network, designing experiments based on the open dataset. The experiment result shows that our method improves over the compared advanced road extraction methods, which not only increases the accuracy of road extraction, but also improves the road topological connectivity.},
DOI = {10.3390/ijgi10010039}
}



@Article{ijgi10010041,
AUTHOR = {Kadhim, Israa and Abed, Fanar M.},
TITLE = {The Potential of LiDAR and UAV-Photogrammetric Data Analysis to Interpret Archaeological Sites: A Case Study of Chun Castle in South-West England},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {41},
URL = {https://www.mdpi.com/2220-9964/10/1/41},
ISSN = {2220-9964},
ABSTRACT = {With the increasing demands to use remote sensing approaches, such as aerial photography, satellite imagery, and LiDAR in archaeological applications, there is still a limited number of studies assessing the differences between remote sensing methods in extracting new archaeological finds. Therefore, this work aims to critically compare two types of fine-scale remotely sensed data: LiDAR and an Unmanned Aerial Vehicle (UAV) derived Structure from Motion (SfM) photogrammetry. To achieve this, aerial imagery and airborne LiDAR datasets of Chun Castle were acquired, processed, analyzed, and interpreted. Chun Castle is one of the most remarkable ancient sites in Cornwall County (Southwest England) that had not been surveyed and explored by non-destructive techniques. The work outlines the approaches that were applied to the remotely sensed data to reveal potential remains: Visualization methods (e.g., hillshade and slope raster images), ISODATA clustering, and Support Vector Machine (SVM) algorithms. The results display various archaeological remains within the study site that have been successfully identified. Applying multiple methods and algorithms have successfully improved our understanding of spatial attributes within the landscape. The outcomes demonstrate how raster derivable from inexpensive approaches can be used to identify archaeological remains and hidden monuments, which have the possibility to revolutionize archaeological understanding.},
DOI = {10.3390/ijgi10010041}
}



@Article{ijerph18020830,
AUTHOR = {Huang, Xiameng and Song, Yanqing and Hu, Xuan},
TITLE = {Deploying Spatial Data for Coastal Community Resilience: A Review from the Managerial Perspective},
JOURNAL = {International Journal of Environmental Research and Public Health},
VOLUME = {18},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {830},
URL = {https://www.mdpi.com/1660-4601/18/2/830},
PubMedID = {33478056},
ISSN = {1660-4601},
ABSTRACT = {The use of spatial data for coastal community resilience applications has diversified as a consequence of the increasing availability of data, and extensive development in data processing. However, the true value of spatial data is not fully exploited as a result of lacking scientific managerial models that incorporate spatial data into decision-making. This article synthesizes the cross-disciplinary literature review on deploying spatial data for coastal community resilience from the managerial perspective. It systematically reviews research addressing the topic of deploying spatial data for coastal resilience operations from the earliest available to 1999. The review uses 142 studies to address three research questions: (1) What kind of data can be obtained for coastal resilience situational awareness? (2) What outcomes have spatial data attributed to coastal resilience applications? and (3) What are the missing pieces (gaps) in connecting the spatial data with coastal resilience applications? In addressing these research questions, the authors review articles based on three dimensions including the availability of spatial data, the availability of applications, and limitations. Based on the findings of the analysis, the authors conclude that the managerial perspective of deploying spatial data in coastal hazards are understudies, and outline problem formulation, mission prioritization, and information salience as an agenda for future research.},
DOI = {10.3390/ijerph18020830}
}



@Article{electronics10030222,
AUTHOR = {Zhao, Baigan and Huang, Yingping and Wei, Hongjian and Hu, Xing},
TITLE = {Ego-Motion Estimation Using Recurrent Convolutional Neural Networks through Optical Flow Learning},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {222},
URL = {https://www.mdpi.com/2079-9292/10/3/222},
ISSN = {2079-9292},
ABSTRACT = {Visual odometry (VO) refers to incremental estimation of the motion state of an agent (e.g., vehicle and robot) by using image information, and is a key component of modern localization and navigation systems. Addressing the monocular VO problem, this paper presents a novel end-to-end network for estimation of camera ego-motion. The network learns the latent subspace of optical flow (OF) and models sequential dynamics so that the motion estimation is constrained by the relations between sequential images. We compute the OF field of consecutive images and extract the latent OF representation in a self-encoding manner. A Recurrent Neural Network is then followed to examine the OF changes, i.e., to conduct sequential learning. The extracted sequential OF subspace is used to compute the regression of the 6-dimensional pose vector. We derive three models with different network structures and different training schemes: LS-CNN-VO, LS-AE-VO, and LS-RCNN-VO. Particularly, we separately train the encoder in an unsupervised manner. By this means, we avoid non-convergence during the training of the whole network and allow more generalized and effective feature representation. Substantial experiments have been conducted on KITTI and Malaga datasets, and the results demonstrate that our LS-RCNN-VO outperforms the existing learning-based VO approaches.},
DOI = {10.3390/electronics10030222}
}



@Article{rs13030345,
AUTHOR = {Šećerov, Ivan and Popov, Srđan and Sladojević, Srđan and Milin, Dragana and Lazić, Lazar and Milošević, Dragan and Arsenović, Daniela and Savić, Stevan},
TITLE = {Achieving High Reliability in Data Acquisition},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {345},
URL = {https://www.mdpi.com/2072-4292/13/3/345},
ISSN = {2072-4292},
ABSTRACT = {An urban environment defines a specific micro-climate which directly affects the quality of life in urbanized areas and often has a negative impact on urban populations. Phenomena like urban heat and surface heat islands are direct products of an urban lifestyle. Urban meteorological networks (UMNs) are a tool that can help to better understand and analyze the current situation and make the right decisions about future urban development. Deployed to monitor and record different objects and their states inside urban areas, UMNs build a long-term meteorological data time series database. The most commonly used systems for achieving this goal include wireless sensor networks (WSNs). This paper presents a combined experience in deploying three different WSN systems. During seven years of research in this field, the authors have recognized the importance of data reliability in data acquisition. More importantly, due to the lack of research addressing the reliability of the data received from WSNs by the core segment of the server (processes used in receiving, validating, parsing, and storing data into a database instance), the received data are used in scientific studies without questioning their reliability. To determine the possibility of shifting information provided by the data measured from sensor networks before it is stored in a desired form of database, this paper proposes a highly reliable socket server model. The model is built with high reliability and performance in mind and it includes three major processes, which use a combination of signals and control messages to pass information about their states. A case study is performed using high-end hardware, running a Linux operating system stressed to its limits. Repetition testing revealed inconsistency in the information provided by the operating system to the application layer, which could lead to the loss of information about short-term and rarely occurring monitored objects. The results lead to the conclusion that there is a clear need for a higher level of data reliability in the process of data acquisition by UMNs. The proposed socket server should fill this gap within the server&rsquo;s core segment.},
DOI = {10.3390/rs13030345}
}



@Article{s21030694,
AUTHOR = {Sahal, Radhya and Alsamhi, Saeed H. and Breslin, John G. and Ali, Muhammad Intizar},
TITLE = {Industry 4.0 towards Forestry 4.0: Fire Detection Use Case},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {694},
URL = {https://www.mdpi.com/1424-8220/21/3/694},
PubMedID = {33498450},
ISSN = {1424-8220},
ABSTRACT = {Forestry 4.0 is inspired by the Industry 4.0 concept, which plays a vital role in the next industrial generation revolution. It is ushering in a new era for efficient and sustainable forest management. Environmental sustainability and climate change are related challenges to promote sustainable forest management of natural resources. Internet of Forest Things (IoFT) is an emerging technology that helps manage forest sustainability and protect forest from hazards via distributing smart devices for gathering data stream during monitoring and detecting fire. Stream processing is a well-known research area, and recently, it has gained a further significance due to the emergence of IoFT devices. Distributed stream processing platforms have emerged, e.g., Apache Flink, Storm, and Spark, etc. Querying windowing is the heart of any stream-processing platform which splits infinite data stream into chunks of finite data to execute a query. Dynamic query window-based processing can reduce the reporting time in case of missing and delayed events caused by data drift.In this paper, we present a novel dynamic mechanism to recommend the optimal window size and type based on the dynamic context of IoFT application. In particular, we designed a dynamic window selector for stream queries considering input stream data characteristics, application workload and resource constraints to recommend the optimal stream query window configuration. A research gap on the likelihood of adopting smart IoFT devices in environmental sustainability indicates a lack of empirical studies to pursue forest sustainability, i.e., sustainable forestry applications. So, we focus on forest fire management and detection as a use case of Forestry 4.0, one of the dynamic environmental management challenges, i.e., climate change, to deliver sustainable forestry goals. According to the dynamic window selector&rsquo;s experimental results, end-to-end latency time for the reported fire alerts has been reduced by dynamical adaptation of window size with IoFT stream rate changes.},
DOI = {10.3390/s21030694}
}



@Article{rs13030352,
AUTHOR = {Neuville, Romain and Bates, Jordan Steven and Jonard, François},
TITLE = {Estimating Forest Structure from UAV-Mounted LiDAR Point Cloud Using Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {352},
URL = {https://www.mdpi.com/2072-4292/13/3/352},
ISSN = {2072-4292},
ABSTRACT = {Monitoring the structure of forest stands is of high importance for forest managers to help them in maintaining ecosystem services. For that purpose, Unmanned Aerial Vehicles (UAVs) open new prospects, especially in combination with Light Detection and Ranging (LiDAR) technology. Indeed, the shorter distance from the Earth&rsquo;s surface significantly increases the point density beneath the canopy, thus offering new possibilities for the extraction of the underlying semantics. For example, tree stems can now be captured with sufficient detail, which is a gateway to accurately locating trees and directly retrieving metrics&mdash;e.g., the Diameter at Breast Height (DBH). Current practices usually require numerous site-specific parameters, which may preclude their use when applied beyond their initial application context. To overcome this shortcoming, the machine learning Hierarchical Density-Based Spatial Clustering of Application of Noise (HDBSCAN) clustering algorithm was further improved and implemented to segment tree stems. Afterwards, Principal Component Analysis (PCA) was applied to extract tree stem orientation for subsequent DBH estimation. This workflow was then validated using LiDAR point clouds collected in a temperate deciduous closed-canopy forest stand during the leaf-on and leaf-off seasons, along with multiple scanning angle ranges. The results show that the proposed methodology can correctly detect up to 82% of tree stems (with a precision of 98%) during the leaf-off season and have a Maximum Scanning Angle Range (MSAR) of 75 degrees, without having to set up any site-specific parameters for the segmentation procedure. In the future, our method could then minimize the omission and commission errors when initially detecting trees, along with assisting further tree metrics retrieval. Finally, this research shows that, under the study conditions, the point density within an approximately 1.3-meter height above the ground remains low within closed-canopy forest stands even during the leaf-off season, thus restricting the accurate estimation of the DBH. As a result, autonomous UAVs that can both fly above and under the canopy provide a clear opportunity to achieve this purpose.},
DOI = {10.3390/rs13030352}
}



@Article{rs13030356,
AUTHOR = {Zhu, Bingxue and Chen, Shengbo and Cao, Yijing and Xu, Zhengyuan and Yu, Yan and Han, Cheng},
TITLE = {A Regional Maize Yield Hierarchical Linear Model Combining Landsat 8 Vegetative Indices and Meteorological Data: Case Study in Jilin Province},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {356},
URL = {https://www.mdpi.com/2072-4292/13/3/356},
ISSN = {2072-4292},
ABSTRACT = {The use of satellite remote sensing could effectively predict maize yield. However, many statistical prediction models using remote sensing data cannot extend to the regional scale without considering the regional climate. This paper first introduced the hierarchical linear modeling (HLM) method to solve maize-yield prediction problems over years and regions. The normalized difference vegetation index (NDVI), calculated by the spectrum of the Landsat 8 operational land imager (OLI), and meteorological data were introduced as input parameters in the maize-yield prediction model proposed in this paper. We built models using 100 samples from 10 areas, and used 101 other samples from 34 areas to evaluate the model&rsquo;s performance in Jilin province. HLM provided higher accuracy with an adjusted determination coefficient equal to 0.75, root mean square error (RMSEV) equal to 0.94 t/ha, and normalized RMSEV equal to 9.79%. Results showed that the HLM approach outperformed linear regression (LR) and multiple LR (MLR) methods. The HLM method based on the Landsat 8 OLI NDVI and meteorological data could flexibly adjust in different regional climatic conditions. They had higher spatiotemporal expansibility than that of widely used yield estimation models (e.g., LR and MLR). This is helpful for the accurate management of maize fields.},
DOI = {10.3390/rs13030356}
}



@Article{land10020095,
AUTHOR = {Waseem, Liaqat Ali and Khokhar, Malik Abid Hussain and Naqvi, Syed Ali Asad and Hussain, Dostdar and Javed, Zahoor Hussain and Awan, Hisham Bin Hafeez},
TITLE = {Influence of Urban Sprawl on Microclimate of Abbottabad, Pakistan},
JOURNAL = {Land},
VOLUME = {10},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {95},
URL = {https://www.mdpi.com/2073-445X/10/2/95},
ISSN = {2073-445X},
ABSTRACT = {Urban centers are expanding rapidly due to quickly-increasing population which results in microclimate change due to lack of urban planning. Factors like degradation of green areas, trees, and vegetation are defining a new regime of urban environment giving rise to a lack of drinking water and lowering water tables. Consequently, unplanned urban sprawl with all its varied facets is having adverse impacts on the environment. Rapid variations in some of its climatic factors in the immediate vicinity are alarming and need to redress at war footings. This paper is an endeavor to present a hypothesis that urban sprawl plays a vital role in impacting and the influencing the microclimate of the city or the area. In this research, geospatial approaches were adopted to identify urban sprawl. Rise in land surface temperature (LST) for the last 25 years (from 1990 to 2016) has been highlighted using Landsat (5 TM, 7 ETM+ and 8 TIRS) satellite images. Weather data collected from Meteorological Department is used to identify temperature rising trends. Result of the research clearly indicates that rapid urban sprawl has adverse impacts on microclimate by increasing LST. Built-up area has been changed from 178 to 477 sq. km within the years of 1990 to 2016. Vegetated area has decreased from 770 to 602 sq. km. Water areas have been decreased from 524 to 360 sq. km within the span of last 26 years. The bare land has increased from 494 sq. km to 742 sq. km. LST in winters has risen from 17 &deg;C to 23 &deg;C and at times shot up to 31 &deg;C, which is alarming. Annual mean air temperature increased by 3 &deg;C to 4 &deg;C from the 1980s to 2016. During summers, the average air temperature rose to a startling 33 &deg;C from 28 &deg;C and LST has had a steady rise from 28.4 &deg;C to 35 &deg;C. The alarming urban sprawl in relation to temperature rise warrants measures which are required to plan the urban planning, forestation, and ecological measures to mitigate the disastrous trends which may result in flash floods, landslides, soil erosion and sediment transport endangering downstream reservoirs, water quality and depletion in ground water table in the valley.},
DOI = {10.3390/land10020095}
}



@Article{drones5010008,
AUTHOR = {Butcher, Paul A. and Colefax, Andrew P. and Gorkin, Robert A. and Kajiura, Stephen M. and López, Naima A. and Mourier, Johann and Purcell, Cormac R. and Skomal, Gregory B. and Tucker, James P. and Walsh, Andrew J. and Williamson, Jane E. and Raoult, Vincent},
TITLE = {The Drone Revolution of Shark Science: A Review},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {8},
URL = {https://www.mdpi.com/2504-446X/5/1/8},
ISSN = {2504-446X},
ABSTRACT = {Over the past decade, drones have become a popular tool for wildlife management and research. Drones have shown significant value for animals that were often difficult or dangerous to study using traditional survey methods. In the past five years drone technology has become commonplace for shark research with their use above, and more recently, below the water helping to minimise knowledge gaps about these cryptic species. Drones have enhanced our understanding of shark behaviour and are critically important tools, not only due to the importance and conservation of the animals in the ecosystem, but to also help minimise dangerous encounters with humans. To provide some guidance for their future use in relation to sharks, this review provides an overview of how drones are currently used with critical context for shark monitoring. We show how drones have been used to fill knowledge gaps around fundamental shark behaviours or movements, social interactions, and predation across multiple species and scenarios. We further detail the advancement in technology across sensors, automation, and artificial intelligence that are improving our abilities in data collection and analysis and opening opportunities for shark-related beach safety. An investigation of the shark-based research potential for underwater drones (ROV/AUV) is also provided. Finally, this review provides baseline observations that have been pioneered for shark research and recommendations for how drones might be used to enhance our knowledge in the future.},
DOI = {10.3390/drones5010008}
}



@Article{s21030742,
AUTHOR = {Nguyen, Canh and Sagan, Vasit and Maimaitiyiming, Matthew and Maimaitijiang, Maitiniyazi and Bhadra, Sourav and Kwasniewski, Misha T.},
TITLE = {Early Detection of Plant Viral Disease Using Hyperspectral Imaging and Deep Learning},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {742},
URL = {https://www.mdpi.com/1424-8220/21/3/742},
PubMedID = {33499335},
ISSN = {1424-8220},
ABSTRACT = {Early detection of grapevine viral diseases is critical for early interventions in order to prevent the disease from spreading to the entire vineyard. Hyperspectral remote sensing can potentially detect and quantify viral diseases in a nondestructive manner. This study utilized hyperspectral imagery at the plant level to identify and classify grapevines inoculated with the newly discovered DNA virus grapevine vein-clearing virus (GVCV) at the early asymptomatic stages. An experiment was set up at a test site at South Farm Research Center, Columbia, MO, USA (38.92 N, &minus;92.28 W), with two grapevine groups, namely healthy and GVCV-infected, while other conditions were controlled. Images of each vine were captured by a SPECIM IQ 400&ndash;1000 nm hyperspectral sensor (Oulu, Finland). Hyperspectral images were calibrated and preprocessed to retain only grapevine pixels. A statistical approach was employed to discriminate two reflectance spectra patterns between healthy and GVCV vines. Disease-centric vegetation indices (VIs) were established and explored in terms of their importance to the classification power. Pixel-wise (spectral features) classification was performed in parallel with image-wise (joint spatial&ndash;spectral features) classification within a framework involving deep learning architectures and traditional machine learning. The results showed that: (1) the discriminative wavelength regions included the 900&ndash;940 nm range in the near-infrared (NIR) region in vines 30 days after sowing (DAS) and the entire visual (VIS) region of 400&ndash;700 nm in vines 90 DAS; (2) the normalized pheophytization index (NPQI), fluorescence ratio index 1 (FRI1), plant senescence reflectance index (PSRI), anthocyanin index (AntGitelson), and water stress and canopy temperature (WSCT) measures were the most discriminative indices; (3) the support vector machine (SVM) was effective in VI-wise classification with smaller feature spaces, while the RF classifier performed better in pixel-wise and image-wise classification with larger feature spaces; and (4) the automated 3D convolutional neural network (3D-CNN) feature extractor provided promising results over the 2D convolutional neural network (2D-CNN) in learning features from hyperspectral data cubes with a limited number of samples.},
DOI = {10.3390/s21030742}
}



@Article{s21030750,
AUTHOR = {Garrido, Iván and Erazo-Aux, Jorge and Lagüela, Susana and Sfarra, Stefano and Ibarra-Castanedo, Clemente and Pivarčiová, Elena and Gargiulo, Gianfranco and Maldague, Xavier and Arias, Pedro},
TITLE = {Introduction of Deep Learning in Thermographic Monitoring of Cultural Heritage and Improvement by Automatic Thermogram Pre-Processing Algorithms},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {750},
URL = {https://www.mdpi.com/1424-8220/21/3/750},
PubMedID = {33499344},
ISSN = {1424-8220},
ABSTRACT = {The monitoring of heritage objects is necessary due to their continuous deterioration over time. Therefore, the joint use of the most up-to-date inspection techniques with the most innovative data processing algorithms plays an important role to apply the required prevention and conservation tasks in each case study. InfraRed Thermography (IRT) is one of the most used Non-Destructive Testing (NDT) techniques in the cultural heritage field due to its advantages in the analysis of delicate objects (i.e., undisturbed, non-contact and fast inspection of large surfaces) and its continuous evolution in both the acquisition and the processing of the data acquired. Despite the good qualitative and quantitative results obtained so far, the lack of automation in the IRT data interpretation predominates, with few automatic analyses that are limited to specific conditions and the technology of the thermographic camera. Deep Learning (DL) is a data processor with a versatile solution for highly automated analysis. Then, this paper introduces the latest state-of-the-art DL model for instance segmentation, Mask Region-Convolution Neural Network (Mask R-CNN), for the automatic detection and segmentation of the position and area of different surface and subsurface defects, respectively, in two different artistic objects belonging to the same family: Marquetry. For that, active IRT experiments are applied to each marquetry. The thermal image sequences acquired are used as input dataset in the Mask R-CNN learning process. Previously, two automatic thermal image pre-processing algorithms based on thermal fundamentals are applied to the acquired data in order to improve the contrast between defective and sound areas. Good detection and segmentation results are obtained regarding state-of-the-art IRT data processing algorithms, which experience difficulty in identifying the deepest defects in the tests. In addition, the performance of the Mask R-CNN is improved by the prior application of the proposed pre-processing algorithms.},
DOI = {10.3390/s21030750}
}



@Article{f12020131,
AUTHOR = {Chen, Xinxin and Jiang, Kang and Zhu, Yushi and Wang, Xiangjun and Yun, Ting},
TITLE = {Individual Tree Crown Segmentation Directly from UAV-Borne LiDAR Data Using the PointNet of Deep Learning},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {131},
URL = {https://www.mdpi.com/1999-4907/12/2/131},
ISSN = {1999-4907},
ABSTRACT = {Accurate individual tree crown (ITC) segmentation from scanned point clouds is a fundamental task in forest biomass monitoring and forest ecology management. Light detection and ranging (LiDAR) as a mainstream tool for forest survey is advancing the pattern of forest data acquisition. In this study, we performed a novel deep learning framework directly processing the forest point clouds belonging to the four forest types (i.e., the nursery base, the monastery garden, the mixed forest, and the defoliated forest) to realize the ITC segmentation. The specific steps of our approach were as follows: first, a voxelization strategy was conducted to subdivide the collected point clouds with various tree species from various forest types into many voxels. These voxels containing point clouds were taken as training samples for the PointNet deep learning framework to identify the tree crowns at the voxel scale. Second, based on the initial segmentation results, we used the height-related gradient information to accurately depict the boundaries of each tree crown. Meanwhile, the retrieved tree crown breadths of individual trees were compared with field measurements to verify the effectiveness of our approach. Among the four forest types, our results revealed the best performance for the nursery base (tree crown detection rate r = 0.90; crown breadth estimation R2 &gt; 0.94 and root mean squared error (RMSE) &lt; 0.2m). A sound performance was also achieved for the monastery garden and mixed forest, which had complex forest structures, complicated intersections of branches and different building types, with r = 0.85, R2 &gt; 0.88 and RMSE &lt; 0.6 m for the monastery garden and r = 0.80, R2 &gt; 0.85 and RMSE &lt; 0.8 m for the mixed forest. For the fourth forest plot type with the distribution of crown defoliation across the woodland, we achieved the performance with r = 0.82, R2 &gt; 0.79 and RMSE &lt; 0.7 m. Our method presents a robust framework inspired by the deep learning technology and computer graphics theory that solves the ITC segmentation problem and retrieves forest parameters under various forest conditions.},
DOI = {10.3390/f12020131}
}



@Article{jlpea11010007,
AUTHOR = {Sahoo, Siva Satyendra and Ranjbar, Behnaz and Kumar, Akash},
TITLE = {Reliability-Aware Resource Management in Multi-/Many-Core Systems: A Perspective Paper},
JOURNAL = {Journal of Low Power Electronics and Applications},
VOLUME = {11},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {7},
URL = {https://www.mdpi.com/2079-9268/11/1/7},
ISSN = {2079-9268},
ABSTRACT = {With the advancement of technology scaling, multi/many-core platforms are getting more attention in embedded systems due to the ever-increasing performance requirements and power efficiency. This feature size scaling, along with architectural innovations, has dramatically exacerbated the rate of manufacturing defects and physical fault-rates. As a result, in addition to providing high parallelism, such hardware platforms have introduced increasing unreliability into the system. Such systems need to be well designed to ensure long-term and application-specific reliability, especially in mixed-criticality systems, where incorrect execution of applications may cause catastrophic consequences. However, the optimal allocation of applications/tasks on multi/many-core platforms is an increasingly complex problem. Therefore, reliability-aware resource management is crucial while ensuring the application-specific Quality-of-Service (QoS) requirements and optimizing other system-level performance goals. This article presents a survey of recent works that focus on reliability-aware resource management in multi-/many-core systems. We first present an overview of reliability in electronic systems, associated fault models and the various system models used in related research. Then, we present recent published articles primarily focusing on aspects such as application-specific reliability optimization, mixed-criticality awareness, and hardware resource heterogeneity. To underscore the techniques’ differences, we classify them based on the design space exploration. In the end, we briefly discuss the upcoming trends and open challenges within the domain of reliability-aware resource management for future research.},
DOI = {10.3390/jlpea11010007}
}



@Article{s21030830,
AUTHOR = {Dias Santana, Guilherme Marcel and Cristo, Rogers Silva de and Lucas Jaquie Castelo Branco, Kalinka Regina},
TITLE = {Integrating Cognitive Radio with Unmanned Aerial Vehicles: An Overview},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {830},
URL = {https://www.mdpi.com/1424-8220/21/3/830},
PubMedID = {33513689},
ISSN = {1424-8220},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) demand technologies so they can not only fly autonomously, but also communicate with base stations, flight controllers, computers, devices, or even other UAVs. Still, UAVs usually operate within unlicensed spectrum bands, competing against the increasing number of mobile devices and other wireless networks. Combining UAVs with Cognitive Radio (CR) may increase their general communication performance, thus allowing them to execute missions where the conventional UAVs face limitations. CR provides a smart wireless communication which, instead of using a transmission frequency defined in the hardware, uses software transmission. CR smartly uses free transmission channels and/or chooses them according to application&rsquo;s requirements. Moreover, CR is considered a key enabler for deploying technologies that require high connectivity, such as Smart Cities, 5G, Internet of Things (IoT), and the Internet of Flying Things (IoFT). This paper presents an overview on the field of CR for UAV communications and its state-of-the-art, testbed alternatives for real data experiments, as well as specifications to build a simple and low-cost testbed, and indicates key opportunities and future challenges in the field.},
DOI = {10.3390/s21030830}
}



@Article{f12020147,
AUTHOR = {Li, Hao and Shi, Qingdong and Wan, Yanbo and Shi, Haobo and Imin, Bilal},
TITLE = {Using Sentinel-2 Images to Map the Populus euphratica Distribution Based on the Spectral Difference Acquired at the Key Phenological Stage},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {147},
URL = {https://www.mdpi.com/1999-4907/12/2/147},
ISSN = {1999-4907},
ABSTRACT = {Populus euphratica is an important tree species in desert ecosystems. The protection and restoration of natural Populus euphratica forests requires accurate positioning information. The use of Sentinel-2 images to map the Populus euphratica distribution at a large scale faces challenges associated with discriminating between Populus euphratica and Tamarix chinensis. To address this problem, this study selected the Daliyabuyi Oasis in the hinterland of the Taklimakan Desert as the study site and sought to distinguish Populus euphratica from Tamarix chinensis. First, we determined the peak spectral difference period (optimal time window) between Populus euphratica and Tamarix chinensis within monthly Sentinel-2 time-series images. Then, an appropriate vegetation index was selected to represent the spectral difference between Populus euphratica and Tamarix chinensis within the key phenological stage. Finally, the maximum entropy method was used to automatically determine the threshold to map the Populus euphratica distribution. The results indicated that the period from 22 April to 1 May was the optimal time window for mapping the Populus euphratica distribution in the Daliyabuyi Oasis. The combination of the inverted red-edge chlorophyll index (IRECI) and the maximum entropy method can effectively distinguish Populus euphratica from Tamarix chinensis. The user&rsquo;s accuracy of the Populus euphratica distribution extraction from single-data Sentinel-2 images acquired within the optimal time window was 0.83, the producer&rsquo;s accuracy was 0.72, and the F1-score was 0.77. This study verified the feasibility of mapping Populus euphratica distribution based on Sentinel-2 images, and analyzed the validity of exploiting spectral differences within the key phenological stage from a single-data image to distinguish between the two species. The results can be used to extract the distribution of Populus euphratica and serve as an auxiliary variable for other plant classification methods, providing a reference for the extraction and classification of desert plants.},
DOI = {10.3390/f12020147}
}



@Article{rs13030440,
AUTHOR = {Zhang, Haiming and Wang, Mingchang and Wang, Fengyan and Yang, Guodong and Zhang, Ying and Jia, Junqian and Wang, Siqi},
TITLE = {A Novel Squeeze-and-Excitation W-Net for 2D and 3D Building Change Detection with Multi-Source and Multi-Feature Remote Sensing Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {440},
URL = {https://www.mdpi.com/2072-4292/13/3/440},
ISSN = {2072-4292},
ABSTRACT = {Building Change Detection (BCD) is one of the core issues in earth observation and has received extensive attention in recent years. With the rapid development of earth observation technology, the data source of remote sensing change detection is continuously enriched, which provides the possibility to describe the spatial details of the ground objects more finely and to characterize the ground objects with multiple perspectives and levels. However, due to the different physical mechanisms of multi-source remote sensing data, BCD based on heterogeneous data is a challenge. Previous studies mostly focused on the BCD of homogeneous remote sensing data, while the use of multi-source remote sensing data and considering multiple features to conduct 2D and 3D BCD research is sporadic. In this article, we propose a novel and general squeeze-and-excitation W-Net, which is developed from U-Net and SE-Net. Its unique advantage is that it can not only be used for BCD of homogeneous and heterogeneous remote sensing data respectively but also can input both homogeneous and heterogeneous remote sensing data for 2D or 3D BCD by relying on its bidirectional symmetric end-to-end network architecture. Moreover, from a unique perspective, we use image features that are stable in performance and less affected by radiation differences and temporal changes. We innovatively introduced the squeeze-and-excitation module to explicitly model the interdependence between feature channels so that the response between the feature channels is adaptively recalibrated to improve the information mining ability and detection accuracy of the model. As far as we know, this is the first proposed network architecture that can simultaneously use multi-source and multi-feature remote sensing data for 2D and 3D BCD. The experimental results in two 2D data sets and two challenging 3D data sets demonstrate that the promising performances of the squeeze-and-excitation W-Net outperform several traditional and state-of-the-art approaches. Moreover, both visual and quantitative analyses of the experimental results demonstrate competitive performance in the proposed network. This demonstrates that the proposed network and method are practical, physically justified, and have great potential application value in large-scale 2D and 3D BCD and qualitative and quantitative research.},
DOI = {10.3390/rs13030440}
}



@Article{rs13030439,
AUTHOR = {Avtar, Ram and Kouser, Asma and Kumar, Ashwani and Singh, Deepak and Misra, Prakhar and Gupta, Ankita and Yunus, Ali P. and Kumar, Pankaj and Johnson, Brian Alan and Dasgupta, Rajarshi and Sahu, Netrananda and Besse Rimba, Andi},
TITLE = {Remote Sensing for International Peace and Security: Its Role and Implications},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {439},
URL = {https://www.mdpi.com/2072-4292/13/3/439},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing technology has seen a massive rise in popularity over the last two decades, becoming an integral part of our lives. Space-based satellite technologies facilitated access to the inaccessible terrains, helped humanitarian teams, support complex emergencies, and contributed to monitoring and verifying conflict zones. The scoping phase of this review investigated the utility of the role of remote sensing application to complement international peace and security activities owing to their ability to provide objective near real-time insights at the ground level. The first part of this review looks into the major research concepts and implementation of remote sensing-based techniques for international peace and security applications and presented a meta-analysis on how advanced sensor capabilities can support various aspects of peace and security. With key examples, we demonstrated how this technology assemblage enacts multiple versions of peace and security: for refugee relief operations, in armed conflicts monitoring, tracking acts of genocide, providing evidence in courts of law, and assessing contravention in human rights. The second part of this review anticipates future challenges that can hinder the applicative capabilities of remote sensing in peace and security. Varying types of sensors pose discrepancies in image classifications and issues like cost, resolution, and difficulty of ground-truth in conflict areas. With emerging technologies and sufficient secondary resources available, remote sensing plays a vital operational tool in conflict-affected areas by supporting an extensive diversity in public policy actions for peacekeeping processes.},
DOI = {10.3390/rs13030439}
}



@Article{rs13030441,
AUTHOR = {Fu, Han and Fu, Bihong and Shi, Pilong},
TITLE = {An Improved Segmentation Method for Automatic Mapping of Cone Karst from Remote Sensing Data Based on DeepLab V3+ Model},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {441},
URL = {https://www.mdpi.com/2072-4292/13/3/441},
ISSN = {2072-4292},
ABSTRACT = {The South China Karst, a United Nations Educational, Scientific and Cultural Organization (UNESCO) natural heritage site, is one of the world&rsquo;s most spectacular examples of humid tropical to subtropical karst landscapes. The Libo cone karst in the southern Guizhou Province is considered as the world reference site for these types of karst, forming a distinctive and beautiful landscape. Geomorphic information and spatial distribution of cone karst is essential for conservation and management for Libo heritage site. In this study, a deep learning (DL) method based on DeepLab V3+ network was proposed to document the cone karst landscape in Libo by multi-source data, including optical remote sensing images and digital elevation model (DEM) data. The training samples were generated by using Landsat remote sensing images and their combination with satellite derived DEM data. Each group of training dataset contains 898 samples. The input module of DeepLab V3+ network was improved to accept four-channel input data, i.e., combination of Landsat RGB images and DEM data. Our results suggest that the mean intersection over union (MIoU) using the four-channel data as training samples by a new DL-based pixel-level image segmentation approach is the highest, which can reach 95.5%. The proposed method can accomplish automatic extraction of cone karst landscape by self-learning of deep neural network, and therefore it can also provide a powerful and automatic tool for documenting other type of geological landscapes worldwide.},
DOI = {10.3390/rs13030441}
}



@Article{jsan10010007,
AUTHOR = {Benbarrad, Tajeddine and Salhaoui, Marouane and Kenitar, Soukaina Bakhat and Arioua, Mounir},
TITLE = {Intelligent Machine Vision Model for Defective Product Inspection Based on Machine Learning},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {10},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {7},
URL = {https://www.mdpi.com/2224-2708/10/1/7},
ISSN = {2224-2708},
ABSTRACT = {Quality control is one of the industrial tasks most susceptible to be improved by implementing technological innovations. As an innovative technology, machine vision enables reliable and fast 24/7 inspections and helps producers to improve the efficiency of manufacturing operations. The accessible data by vision equipment will be used to identify and report defective products, understand the causes of deficiencies and allow rapid and efficient intervention in smart factories. From this perspective, the proposed machine vision model in this paper combines the identification of defective products and the continuous improvement of manufacturing processes by predicting the most suitable parameters of production processes to obtain a defect-free item. The suggested model exploits all generated data by various integrated technologies in the manufacturing chain, thus meeting the requirements of quality management in the context of Industry 4.0, based on predictive analysis to identify patterns in data and suggest corrective actions to ensure product quality. In addition, a comparative study between several machine learning algorithms, both for product classification and process improvement models, is performed in order to evaluate the designed system. The results of this study show that the proposed model largely meets the requirements for the proper implementation of these techniques.},
DOI = {10.3390/jsan10010007}
}



@Article{rs13030457,
AUTHOR = {Zhou, Xixuan and Yang, Liao and Wang, Weisheng and Chen, Baili},
TITLE = {UAV Data as an Alternative to Field Sampling to Monitor Vineyards Using Machine Learning Based on UAV/Sentinel-2 Data Fusion},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {457},
URL = {https://www.mdpi.com/2072-4292/13/3/457},
ISSN = {2072-4292},
ABSTRACT = {Pests and diseases affect the yield and quality of grapes directly and engender noteworthy economic losses. Diagnosing &ldquo;lesions&rdquo; on vines as soon as possible and dynamically monitoring symptoms caused by pests and diseases at a larger scale are essential to pest control. This study has appraised the capabilities of high-resolution unmanned aerial vehicle (UAV) data as an alternative to manual field sampling to obtain sampling canopy sets and to supplement satellite-based monitoring using machine learning models including partial least squared regression (PLSR), support vector regression (SVR), random forest regression (RFR), and extreme learning regression (ELR) with a new activation function. UAV data were acquired from two flights in Turpan to determine disease severity (DS) and disease incidence (DI) and compared with field visual assessments. The UAV-derived canopy structure including canopy height (CH) and vegetation fraction cover (VFC), as well as satellite-based spectral features calculated from Sentinel-2A/B data were analyzed to evaluate the potential of UAV data to replace manual sampling data and predict DI. It was found that SVR slightly outperformed the other methods with a root mean square error (RMSE) of 1.89%. Moreover, the combination of canopy structure (CS) and vegetation index (VIs) improved prediction accuracy compared with single-type features (RMSEcs of 2.86% and RMSEVIs of 1.93%). This study tested the ability of UAV sampling to replace manual sampling on a large scale and introduced opportunities and challenges of fusing different features to monitor vineyards using machine learning. Within this framework, disease incidence can be estimated efficiently and accurately for larger area monitoring operation.},
DOI = {10.3390/rs13030457}
}



@Article{s21030877,
AUTHOR = {Liu, Jian and Xu, Youshuan and Li, Henghui and Guo, Jiao},
TITLE = {Soil Moisture Retrieval in Farmland Areas with Sentinel Multi-Source Data Based on Regression Convolutional Neural Networks},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {877},
URL = {https://www.mdpi.com/1424-8220/21/3/877},
PubMedID = {33525486},
ISSN = {1424-8220},
ABSTRACT = {As an important component of the earth ecosystem, soil moisture monitoring is of great significance in the fields of crop growth monitoring, crop yield estimation, variable irrigation, and other related applications. In order to mitigate or eliminate the impacts of sparse vegetation covers in farmland areas, this study combines multi-source remote sensing data from Sentinel-1 radar and Sentinel-2 optical satellites to quantitatively retrieve soil moisture content. Firstly, a traditional Oh model was applied to estimate soil moisture content after removing vegetation influence by a water cloud model. Secondly, support vector regression (SVR) and generalized regression neural network (GRNN) models were used to establish the relationships between various remote sensing features and real soil moisture. Finally, a regression convolutional neural network (CNNR) model is constructed to extract deep-level features of remote sensing data to increase soil moisture retrieval accuracy. In addition, polarimetric decomposition features for real Sentinel-1 PolSAR data are also included in the construction of inversion models. Based on the established soil moisture retrieval models, this study analyzes the influence of each input feature on the inversion accuracy in detail. The experimental results show that the optimal combination of R2 and root mean square error (RMSE) for SVR is 0.7619 and 0.0257 cm3/cm3, respectively. The optimal combination of R2 and RMSE for GRNN is 0.7098 and 0.0264 cm3/cm3, respectively. Especially, the CNNR model with optimal feature combination can generate inversion results with the highest accuracy, whose R2 and RMSE reach up to 0.8947 and 0.0208 cm3/cm3, respectively. Compared to other methods, the proposed algorithm improves the accuracy of soil moisture retrieval from synthetic aperture radar (SAR) and optical data. Furthermore, after adding polarization decomposition features, the R2 of CNNR is raised by 0.1524 and the RMSE of CNNR decreased by 0.0019 cm3/cm3 on average, which means that the addition of polarimetric decomposition features effectively improves the accuracy of soil moisture retrieval results.},
DOI = {10.3390/s21030877}
}



@Article{rs13030458,
AUTHOR = {Milne, Sol and Martin, Julien G. A. and Reynolds, Glen and Vairappan, Charles S. and Slade, Eleanor M. and Brodie, Jedediah F. and Wich, Serge A. and Williamson, Nicola and Burslem, David F. R. P.},
TITLE = {Drivers of Bornean Orangutan Distribution across a Multiple-Use Tropical Landscape},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {458},
URL = {https://www.mdpi.com/2072-4292/13/3/458},
ISSN = {2072-4292},
ABSTRACT = {Logging and conversion of tropical forests in Southeast Asia have resulted in the expansion of landscapes containing a mosaic of habitats that may vary in their ability to sustain local biodiversity. However, the complexity of these landscapes makes it difficult to assess abundance and distribution of some species using ground-based surveys alone. Here, we deployed a combination of ground-transects and aerial surveys to determine drivers of the critically endangered Bornean Orangutan (Pongo pygmaeus morio) distribution across a large multiple-use landscape in Sabah, Malaysian Borneo. Ground-transects and aerial surveys using drones were conducted for orangutan nests and hemi-epiphytic strangler fig trees (Ficus spp.) (an important food resource) in 48 survey areas across 76 km2, within a study landscape of 261 km2. Orangutan nest count data were fitted to models accounting for variation in land use, above-ground carbon density (ACD, a surrogate for forest quality), strangler fig density, and elevation (between 117 and 675 m). Orangutan nest counts were significantly higher in all land uses possessing natural forest cover, regardless of degradation status, than in monoculture plantations. Within these natural forests, nest counts increased with higher ACD and strangler fig density, but not with elevation. In logged forest (ACD 14–150 Mg ha−1), strangler fig density had a significant, positive relationship with orangutan nest counts, but this relationship disappeared in a forest with higher carbon content (ACD 150–209 Mg ha−1). Based on an area-to-area comparison, orangutan nest counts from ground transects were higher than from counts derived from aerial surveys, but this did not constitute a statistically significant difference. Although the difference in nest counts was not significantly different, this analysis indicates that both methods under-sample the total number of nests present within a given area. Aerial surveys are, therefore, a useful method for assessing the orangutan habitat use over large areas. However, the under-estimation of nest counts by both methods suggests that a small number of ground surveys should be retained in future surveys using this technique, particularly in areas with dense understory vegetation. This study shows that even highly degraded forests may be a suitable orangutan habitat as long as strangler fig trees remain intact after areas of forest are logged. Enrichment planting of strangler figs may, therefore, be a valuable tool for orangutan conservation in these landscapes.},
DOI = {10.3390/rs13030458}
}



@Article{rs13030461,
AUTHOR = {Croce, Valeria and Caroti, Gabriella and De Luca, Livio and Jacquot, Kévin and Piemonte, Andrea and Véron, Philippe},
TITLE = {From the Semantic Point Cloud to Heritage-Building Information Modeling: A Semiautomatic Approach Exploiting Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {461},
URL = {https://www.mdpi.com/2072-4292/13/3/461},
ISSN = {2072-4292},
ABSTRACT = {This work presents a semi-automatic approach to the 3D reconstruction of Heritage-Building Information Models from point clouds based on machine learning techniques. The use of digital information systems leveraging on three-dimensional (3D) representations in architectural heritage documentation and analysis is ever increasing. For the creation of such repositories, reality-based surveying techniques, such as photogrammetry and laser scanning, allow the fast collection of reliable digital replicas of the study objects in the form of point clouds. Besides, their output is raw and unstructured, and the transition to intelligible and semantic 3D representations is still a scarcely automated and time-consuming process requiring considerable human intervention. More refined methods for 3D data interpretation of heritage point clouds are therefore sought after. In tackling these issues, the proposed approach relies on (i) the application of machine learning techniques to semantically label 3D heritage data by identification of relevant geometric, radiometric and intensity features, and (ii) the use of the annotated data to streamline the construction of Heritage-Building Information Modeling (H-BIM) systems, where purely geometric information derived from surveying is associated with semantic descriptors on heritage documentation and management. The &ldquo;Grand-Ducal Cloister&rdquo; dataset, related to the emblematic case study of the Pisa Charterhouse, is discussed.},
DOI = {10.3390/rs13030461}
}



@Article{agriengineering3010003,
AUTHOR = {Astaoui, Ghizlane and Dadaiss, Jamal Eddine and Sebari, Imane and Benmansour, Samir and Mohamed, Ettarid},
TITLE = {Mapping Wheat Dry Matter and Nitrogen Content Dynamics and Estimation of Wheat Yield Using UAV Multispectral Imagery Machine Learning and a Variety-Based Approach: Case Study of Morocco},
JOURNAL = {AgriEngineering},
VOLUME = {3},
YEAR = {2021},
NUMBER = {1},
PAGES = {29--49},
URL = {https://www.mdpi.com/2624-7402/3/1/3},
ISSN = {2624-7402},
ABSTRACT = {Our work aims to monitor wheat crop using a variety-based approach by taking into consideration four different phenological stages of wheat crop development. In addition to highlighting the contribution of Red-Edge vegetation indices in mapping wheat dry matter and nitrogen content dynamics, as well as using Random Forest regressor in the estimation of wheat yield, dry matter and nitrogen uptake relying on UAV (Unmanned Aerial Vehicle) multispectral imagery. The study was conducted on an experimental platform with 12 wheat varieties located in Sidi Slimane (Morocco). Several flight missions were conducted using eBee UAV with MultiSpec4C camera according to phenological growth stages of wheat. The proposed methodology is subdivided into two approaches, the first aims to find the most suitable vegetation index for wheat’s biophysical parameters estimation and the second to establish a global model regardless of the varieties to estimate the biophysical parameters of wheat: Dry matter and nitrogen uptake. The two approaches were conducted according to six main steps: (1) UAV flight missions and in-situ data acquisition during four phenological stages of wheat development, (2) Processing of UAV multispectral images which enabled us to elaborate the vegetation indices maps (RTVI, MTVI2, NDVI, NDRE, GNDVI, GNDRE, SR-RE et SR-NIR), (3) Automatic extraction of plots by Object-based image analysis approach and creating a spatial database combining the spectral information and wheat’s biophysical parameters, (4) Monitoring wheat growth by generating dry biomass and wheat’s nitrogen uptake model using exponential, polynomial and linear regression for each variety this step resumes the varietal approach, (5) Engendering a global model employing both linear regression and Random Forest technique, (6) Wheat yield estimation. The proposed method has allowed to predict from 1 up to 21% difference between actual and estimated yield when using both RTVI index and Random Forest technique as well as mapping wheat’s dry biomass and nitrogen uptake along with the nitrogen nutrition index (NNI) and therefore facilitate a careful monitoring of the health and the growth of wheat crop. Nevertheless, some wheat varieties have shown a significant difference in yield between 2.6 and 3.3 t/ha.},
DOI = {10.3390/agriengineering3010003}
}



@Article{rs13030469,
AUTHOR = {Cai, Zhanzhang and Junttila, Sofia and Holst, Jutta and Jin, Hongxiao and Ardö, Jonas and Ibrom, Andreas and Peichl, Matthias and Mölder, Meelis and Jönsson, Per and Rinne, Janne and Karamihalaki, Maria and Eklundh, Lars},
TITLE = {Modelling Daily Gross Primary Productivity with Sentinel-2 Data in the Nordic Region–Comparison with Data from MODIS},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {469},
URL = {https://www.mdpi.com/2072-4292/13/3/469},
ISSN = {2072-4292},
ABSTRACT = {The high-resolution Sentinel-2 data potentially enable the estimation of gross primary productivity (GPP) at finer spatial resolution by better capturing the spatial variation in a heterogeneous landscapes. This study investigates the potential of 10 m resolution reflectance from the Sentinel-2 Multispectral Instrument to improve the accuracy of GPP estimation across Nordic vegetation types, compared with the 250 m and 500 m resolution reflectance from the Moderate Resolution Imaging Spectroradiometer (MODIS). We applied linear regression models with inputs of two-band enhanced vegetation index (EVI2) derived from Sentinel-2 and MODIS reflectance, respectively, together with various environmental drivers to estimate daily GPP at eight Nordic eddy covariance (EC) flux tower sites. Compared with the GPP from EC measurements, the accuracies of modelled GPP were generally high (R2 = 0.84 for Sentinel-2; R2 = 0.83 for MODIS), and the differences between Sentinel-2 and MODIS were minimal. This demonstrates the general consistency in GPP estimates based on the two satellite sensor systems at the Nordic regional scale. On the other hand, the model accuracy did not improve by using the higher spatial-resolution Sentinel-2 data. More analyses of different model formulations, more tests of remotely sensed indices and biophysical parameters, and analyses across a wider range of geographical locations and times will be required to achieve improved GPP estimations from Sentinel-2 satellite data.},
DOI = {10.3390/rs13030469}
}



@Article{rs13030472,
AUTHOR = {Chen, Yang and Liu, Guanlan and Xu, Yaming and Pan, Pai and Xing, Yin},
TITLE = {PointNet++ Network Architecture with Individual Point Level and Global Features on Centroid for ALS Point Cloud Classification},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {472},
URL = {https://www.mdpi.com/2072-4292/13/3/472},
ISSN = {2072-4292},
ABSTRACT = {Airborne laser scanning (ALS) point cloud has been widely used in the fields of ground powerline surveying, forest monitoring, urban modeling, and so on because of the great convenience it brings to people&rsquo;s daily life. However, the sparsity and uneven distribution of point clouds increases the difficulty of setting uniform parameters for semantic classification. The PointNet++ network is an end-to-end learning network for irregular point data and highly robust to small perturbations of input points along with corruption. It eliminates the need to calculate costly handcrafted features and provides a new paradigm for 3D understanding. However, each local region in the output is abstracted by its centroid and local feature that encodes the centroid&rsquo;s neighborhood. The feature learned on the centroid point may not contain relevant information of itself for random sampling, especially in large-scale neighborhood balls. Moreover, the centroid point&rsquo;s global-level information in each sample layer is also not marked. Therefore, this study proposed a modified PointNet++ network architecture which concentrates the point-level and global features on the centroid point towards the local features to facilitate classification. The proposed approach also utilizes a modified Focal Loss function to solve the extremely uneven category distribution on ALS point clouds. An elevation- and distance-based interpolation method is also proposed for the objects in ALS point clouds which exhibit discrepancies in elevation distributions. The experiments on the Vaihingen dataset of the International Society for Photogrammetry and Remote Sensing and the GML(B) 3D dataset demonstrate that the proposed method which provides additional contextual information to support classification achieves high accuracy with simple discriminative models and new state-of-the-art performance in power line categories.},
DOI = {10.3390/rs13030472}
}



@Article{app11031240,
AUTHOR = {Casas, Roberto and Hermosa, Arturo and Marco, Álvaro and Blanco, Teresa and Zarazaga-Soria, Francisco Javier},
TITLE = {Real-Time Extensive Livestock Monitoring Using LPWAN Smart Wearable and Infrastructure},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {1240},
URL = {https://www.mdpi.com/2076-3417/11/3/1240},
ISSN = {2076-3417},
ABSTRACT = {Extensive unsupervised livestock farming is a habitual technique in many places around the globe. Animal release can be done for months, in large areas and with different species packing and behaving very differently. Nevertheless, the farmer’s needs are similar: where livestock is (and where has been) and how healthy they are. The geographical areas involved usually have difficult access with harsh orography and lack of communications infrastructure. This paper presents the design of a solution for extensive livestock monitoring in these areas. Our proposal is based in a wearable equipped with inertial sensors, global positioning system and wireless communications; and a Low-Power Wide Area Network infrastructure that can run with and without internet connection. Using adaptive analysis and data compression, we provide real-time monitoring and logging of cattle’s position and activities. Hardware and firmware design achieve very low energy consumption allowing months of battery life. We have thoroughly tested the devices in different laboratory setups and evaluated the system performance in real scenarios in the mountains and in the forest.},
DOI = {10.3390/app11031240}
}



@Article{rs13030476,
AUTHOR = {D’hont, Barbara and Calders, Kim and Bartholomeus, Harm and Whiteside, Tim and Bartolo, Renee and Levick, Shaun and Krishna Moorthy, Sruthi M. and Terryn, Louise and Verbeeck, Hans},
TITLE = {Characterising Termite Mounds in a Tropical Savanna with UAV Laser Scanning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {476},
URL = {https://www.mdpi.com/2072-4292/13/3/476},
ISSN = {2072-4292},
ABSTRACT = {Termite mounds are found over vast areas in northern Australia, delivering essential ecosystem services, such as enhancing nutrient cycling and promoting biodiversity. Currently, the detection of termite mounds over large areas requires airborne laser scanning (ALS) or high-resolution satellite data, which lack precise information on termite mound shape and size. For detailed structural measurements, we generally rely on time-consuming field assessments that can only cover a limited area. In this study, we explore if unmanned aerial vehicle (UAV)-based observations can serve as a precise and scalable tool for termite mound detection and morphological characterisation. We collected a unique data set of terrestrial laser scanning (TLS) and UAV laser scanning (UAV-LS) point clouds of a woodland savanna site in Litchfield National Park (Australia). We developed an algorithm that uses several empirical parameters for the semi-automated detection of termite mounds from UAV-LS and used the TLS data set (1 ha) for benchmarking. We detected 81% and 72% of the termite mounds in the high resolution (1800 points m&minus;2) and low resolution (680 points m&minus;2) UAV-LS data, respectively, resulting in an average detection of eight mounds per hectare. Additionally, we successfully extracted information about mound height and volume from the UAV-LS data. The high resolution data set resulted in more accurate estimates; however, there is a trade-off between area and detectability when choosing the required resolution for termite mound detection Our results indicate that UAV-LS data can be rapidly acquired and used to monitor and map termite mounds over relatively large areas with higher spatial detail compared to airborne and spaceborne remote sensing.},
DOI = {10.3390/rs13030476}
}



@Article{computation9020012,
AUTHOR = {Maltezos, Evangelos and Douklias, Athanasios and Dadoukis, Aris and Misichroni, Fay and Karagiannidis, Lazaros and Antonopoulos, Markos and Voulgary, Katerina and Ouzounoglou, Eleftherios and Amditis, Angelos},
TITLE = {The INUS Platform: A Modular Solution for Object Detection and Tracking from UAVs and Terrestrial Surveillance Assets},
JOURNAL = {Computation},
VOLUME = {9},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {12},
URL = {https://www.mdpi.com/2079-3197/9/2/12},
ISSN = {2079-3197},
ABSTRACT = {Situational awareness is a critical aspect of the decision-making process in emergency response and civil protection and requires the availability of up-to-date information on the current situation. In this context, the related research should not only encompass developing innovative single solutions for (real-time) data collection, but also on the aspect of transforming data into information so that the latter can be considered as a basis for action and decision making. Unmanned systems (UxV) as data acquisition platforms and autonomous or semi-autonomous measurement instruments have become attractive for many applications in emergency operations. This paper proposes a multipurpose situational awareness platform by exploiting advanced on-board processing capabilities and efficient computer vision, image processing, and machine learning techniques. The main pillars of the proposed platform are: (1) a modular architecture that exploits unmanned aerial vehicle (UAV) and terrestrial assets; (2) deployment of on-board data capturing and processing; (3) provision of geolocalized object detection and tracking events; and (4) a user-friendly operational interface for standalone deployment and seamless integration with external systems. Experimental results are provided using RGB and thermal video datasets and applying novel object detection and tracking algorithms. The results show the utility and the potential of the proposed platform, and future directions for extension and optimization are presented.},
DOI = {10.3390/computation9020012}
}



@Article{s21030927,
AUTHOR = {Carramiñana, David and Campaña, Iván and Bergesio, Luca and Bernardos, Ana M. and Besada, Juan A.},
TITLE = {Sensors and Communication Simulation for Unmanned Traffic Management},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {927},
URL = {https://www.mdpi.com/1424-8220/21/3/927},
PubMedID = {33573192},
ISSN = {1424-8220},
ABSTRACT = {Unmanned traffic management (UTM) systems will become a key enabler to the future drone market ecosystem, enabling the safe concurrent operation of both manned and unmanned aircrafts. Currently, these systems are usually tested by performing real scenarios that are costly, limited, hardly scalable, and poorly repeatable. As a solution, in this paper we propose an agent-based simulation platform, implemented through a micro service architecture, which may simulate UTM information sources, such as flight plans, telemetry messages, or tracks from a surveillance network. The final objective of this simulator is to use these information streams to perform a system-level evaluation of UTM systems both in the pre-flight and in-flight stages. The proposed platform, with a focus on simulation of communications and sensors, allows to model UTM actors&rsquo; behaviors and their interactions. In addition, it also considers the manual definition of events to simulate unexpected behaviors/events (contingencies), such as communications failures or pilots&rsquo; actions. In order to validate our architecture, we implemented a simulator that considers the following actors: drones, pilots, ground control stations, surveillance networks, and communications networks. This platform enables the simulation of the drone trajectory and control, the C2 (command and control) link, drone detection by surveillance sensors, and the communication of all agents by means of a mobile communications network. Our results show that it is possible to truthfully recreate complex scenarios using this simulator, mitigating the disadvantages of real testbeds.},
DOI = {10.3390/s21030927}
}



@Article{min11020148,
AUTHOR = {Jung, Dahee and Choi, Yosoon},
TITLE = {Systematic Review of Machine Learning Applications in Mining: Exploration, Exploitation, and Reclamation},
JOURNAL = {Minerals},
VOLUME = {11},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {148},
URL = {https://www.mdpi.com/2075-163X/11/2/148},
ISSN = {2075-163X},
ABSTRACT = {Recent developments in smart mining technology have enabled the production, collection, and sharing of a large amount of data in real time. Therefore, research employing machine learning (ML) that utilizes these data is being actively conducted in the mining industry. In this study, we reviewed 109 research papers, published over the past decade, that discuss ML techniques for mineral exploration, exploitation, and mine reclamation. Research trends, ML models, and evaluation methods primarily discussed in the 109 papers were systematically analyzed. The results demonstrated that ML studies have been actively conducted in the mining industry since 2018, mostly for mineral exploration. Among the ML models, support vector machine was utilized the most, followed by deep learning models. The ML models were evaluated mostly in terms of their root mean square error and coefficient of determination.},
DOI = {10.3390/min11020148}
}



@Article{rs13030504,
AUTHOR = {Yang, Wanting and Zhang, Xianfeng and Luo, Peng},
TITLE = {Transferability of Convolutional Neural Network Models for Identifying Damaged Buildings Due to Earthquake},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {504},
URL = {https://www.mdpi.com/2072-4292/13/3/504},
ISSN = {2072-4292},
ABSTRACT = {The collapse of buildings caused by earthquakes can lead to a large loss of life and property. Rapid assessment of building damage with remote sensing image data can support emergency rescues. However, current studies indicate that only a limited sample set can usually be obtained from remote sensing images immediately following an earthquake. Consequently, the difficulty in preparing sufficient training samples constrains the generalization of the model in the identification of earthquake-damaged buildings. To produce a deep learning network model with strong generalization, this study adjusted four Convolutional Neural Network (CNN) models for extracting damaged building information and compared their performance. A sample dataset of damaged buildings was constructed by using multiple disaster images retrieved from the xBD dataset. Using satellite and aerial remote sensing data obtained after the 2008 Wenchuan earthquake, we examined the geographic and data transferability of the deep network model pre-trained on the xBD dataset. The result shows that the network model pre-trained with samples generated from multiple disaster remote sensing images can extract accurately collapsed building information from satellite remote sensing data. Among the adjusted CNN models tested in the study, the adjusted DenseNet121 was the most robust. Transfer learning solved the problem of poor adaptability of the network model to remote sensing images acquired by different platforms and could identify disaster-damaged buildings properly. These results provide a solution to the rapid extraction of earthquake-damaged building information based on a deep learning network model.},
DOI = {10.3390/rs13030504}
}



@Article{rs13030507,
AUTHOR = {Muumbe, Tasiyiwa Priscilla and Baade, Jussi and Singh, Jenia and Schmullius, Christiane and Thau, Christian},
TITLE = {Terrestrial Laser Scanning for Vegetation Analyses with a Special Focus on Savannas},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {507},
URL = {https://www.mdpi.com/2072-4292/13/3/507},
ISSN = {2072-4292},
ABSTRACT = {Savannas are heterogeneous ecosystems, composed of varied spatial combinations and proportions of woody and herbaceous vegetation. Most field-based inventory and remote sensing methods fail to account for the lower stratum vegetation (i.e., shrubs and grasses), and are thus underrepresenting the carbon storage potential of savanna ecosystems. For detailed analyses at the local scale, Terrestrial Laser Scanning (TLS) has proven to be a promising remote sensing technology over the past decade. Accordingly, several review articles already exist on the use of TLS for characterizing 3D vegetation structure. However, a gap exists on the spatial concentrations of TLS studies according to biome for accurate vegetation structure estimation. A comprehensive review was conducted through a meta-analysis of 113 relevant research articles using 18 attributes. The review covered a range of aspects, including the global distribution of TLS studies, parameters retrieved from TLS point clouds and retrieval methods. The review also examined the relationship between the TLS retrieval method and the overall accuracy in parameter extraction. To date, TLS has mainly been used to characterize vegetation in temperate, boreal/taiga and tropical forests, with only little emphasis on savannas. TLS studies in the savanna focused on the extraction of very few vegetation parameters (e.g., DBH and height) and did not consider the shrub contribution to the overall Above Ground Biomass (AGB). Future work should therefore focus on developing new and adjusting existing algorithms for vegetation parameter extraction in the savanna biome, improving predictive AGB models through 3D reconstructions of savanna trees and shrubs as well as quantifying AGB change through the application of multi-temporal TLS. The integration of data from various sources and platforms e.g., TLS with airborne LiDAR is recommended for improved vegetation parameter extraction (including AGB) at larger spatial scales. The review highlights the huge potential of TLS for accurate savanna vegetation extraction by discussing TLS opportunities, challenges and potential future research in the savanna biome.},
DOI = {10.3390/rs13030507}
}



@Article{jsan10010011,
AUTHOR = {Taha, Abd-Elhamid M.},
TITLE = {Quality of Experience in 6G Networks: Outlook and Challenges},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {10},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {11},
URL = {https://www.mdpi.com/2224-2708/10/1/11},
ISSN = {2224-2708},
ABSTRACT = {In this paper, we discuss the critical characteristics of user experience in sixth generation (6G) cellular networks. We first describe cellular networks’ evolution through 5G and then discuss the enabling technologies and projected services in 6G networks. We note that these networks are markedly centered around expanded intelligence, end-to-end resource and topology synchronization, and the intrinsic support to low-latency, high-bandwidth communication. These capabilities make context-rich, cyberphysical user experiences viable. It thereby becomes necessary to define and identify the role of quality of experience in 6G networks, especially when it comes to network management. We elaborate on these expected challenges and allude to viable opportunities in emerging technologies.},
DOI = {10.3390/jsan10010011}
}



@Article{s21030956,
AUTHOR = {Sassu, Alberto and Gambella, Filippo and Ghiani, Luca and Mercenaro, Luca and Caria, Maria and Pazzona, Antonio Luigi},
TITLE = {Advances in Unmanned Aerial System Remote Sensing for Precision Viticulture},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {956},
URL = {https://www.mdpi.com/1424-8220/21/3/956},
PubMedID = {33535445},
ISSN = {1424-8220},
ABSTRACT = {New technologies for management, monitoring, and control of spatio-temporal crop variability in precision viticulture scenarios are numerous. Remote sensing relies on sensors able to provide useful data for the improvement of management efficiency and the optimization of inputs. unmanned aerial systems (UASs) are the newest and most versatile tools, characterized by high precision and accuracy, flexibility, and low operating costs. The work aims at providing a complete overview of the application of UASs in precision viticulture, focusing on the different application purposes, the applied equipment, the potential of technologies combined with UASs for identifying vineyards’ variability. The review discusses the potential of UASs in viticulture by distinguishing five areas of application: rows segmentation and crop features detection techniques; vineyard variability monitoring; estimation of row area and volume; disease detection; vigor and prescription maps creation. Technological innovation and low purchase costs make UASs the core tools for decision support in the customary use by winegrowers. The ability of the systems to respond to the current demands for the acquisition of digital technologies in agricultural fields makes UASs a candidate to play an increasingly important role in future scenarios of viticulture application.},
DOI = {10.3390/s21030956}
}



@Article{s21030974,
AUTHOR = {Rahman, Ehab Ur and Zhang, Yihong and Ahmad, Sohail and Ahmad, Hafiz Ishfaq and Jobaer, Sayed},
TITLE = {Autonomous Vision-Based Primary Distribution Systems Porcelain Insulators Inspection Using UAVs},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {974},
URL = {https://www.mdpi.com/1424-8220/21/3/974},
PubMedID = {33540500},
ISSN = {1424-8220},
ABSTRACT = {The early detection of damaged (partially broken) outdoor insulators in primary distribution systems is of paramount importance for continuous electricity supply and public safety. Unmanned aerial vehicles (UAVs) present a safer, autonomous, and efficient way to examine the power system components without closing the power distribution system. In this work, a novel dataset is designed by capturing real images using UAVs and manually generated images collected to overcome the data insufficiency problem. A deep Laplacian pyramid-based super-resolution network is implemented to reconstruct high-resolution training images. To improve the visibility of low-light images, a low-light image enhancement technique is used for the robust exposure correction of the training images. A different fine-tuning strategy is implemented for fine-tuning the object detection model to increase detection accuracy for the specific faulty insulators. Several flight path strategies are proposed to overcome the shuttering effect of insulators, along with providing a less complex and time- and energy-efficient approach for capturing a video stream of the power system components. The performance of different object detection models is presented for selecting the most suitable one for fine-tuning on the specific faulty insulator dataset. For the detection of damaged insulators, our proposed method achieved an F1-score of 0.81 and 0.77 on two different datasets and presents a simple and more efficient flight strategy. Our approach is based on real aerial inspection of in-service porcelain insulators by extensive evaluation of several video sequences showing robust fault recognition and diagnostic capabilities. Our approach is demonstrated on data acquired by a drone in Swat, Pakistan.},
DOI = {10.3390/s21030974}
}



@Article{drones5010012,
AUTHOR = {Oleksyn, Semonn and Tosetto, Louise and Raoult, Vincent and Joyce, Karen E. and Williamson, Jane E.},
TITLE = {Going Batty: The Challenges and Opportunities of Using Drones to Monitor the Behaviour and Habitat Use of Rays},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {12},
URL = {https://www.mdpi.com/2504-446X/5/1/12},
ISSN = {2504-446X},
ABSTRACT = {The way an animal behaves in its habitat provides insight into its ecological role. As such, collecting robust, accurate datasets in a time-efficient manner is an ever-present pressure for the field of behavioural ecology. Faced with the shortcomings and physical limitations of traditional ground-based data collection techniques, particularly in marine studies, drones offer a low-cost and efficient approach for collecting data in a range of coastal environments. Despite drones being widely used to monitor a range of marine animals, they currently remain underutilised in ray research. The innovative application of drones in environmental and ecological studies has presented novel opportunities in animal observation and habitat assessment, although this emerging field faces substantial challenges. As we consider the possibility to monitor rays using drones, we face challenges related to local aviation regulations, the weather and environment, as well as sensor and platform limitations. Promising solutions continue to be developed, however, growing the potential for drone-based monitoring of behaviour and habitat use of rays. While the barriers to enter this field may appear daunting for researchers with little experience with drones, the technology is becoming increasingly accessible, helping ray researchers obtain a wide range of highly useful data.},
DOI = {10.3390/drones5010012}
}



@Article{safety7010011,
AUTHOR = {Papaioannou, Panagiotis and Papadopoulos, Efthymis and Nikolaidou, Anastasia and Politis, Ioannis and Basbas, Socrates and Kountouri, Eleni},
TITLE = {Dilemma Zone: Modeling Drivers’ Decision at Signalized Intersections against Aggressiveness and Other Factors Using UAV Technology},
JOURNAL = {Safety},
VOLUME = {7},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {11},
URL = {https://www.mdpi.com/2313-576X/7/1/11},
ISSN = {2313-576X},
ABSTRACT = {Intersection safety and drivers’ behavior are strongly interrelated, especially when the latter are located in dilemma zone. This paper explores, among others, the main factors affecting driver behavior, such as distance to stop line, approaching speed and acceleration/deceleration, and two additional factors, namely, driver’s aggressiveness and driver’s relative position at the onset of the yellow signal. Field data were collected using unmanned aerial vehicle (UAV) technology. Two binary choice models were developed, the first relying on observed data and the latter enriched by the latent factor drivers’ aggressiveness and the vehicles’ relative position. Drivers were classified to aggressive and non-aggressive ones using a latent class model that combined approaching speed and acceleration/deceleration data. Drivers were further grouped according to their expected reaction/decision to stop or cross the intersection in relation to their relative position. Both models equally explain drivers’ decisions adequately, but the second one offers additional explanatory power attributed to aggressiveness. Being able to identify the level of aggressiveness among the drivers enables the calculation of the probability that drivers will cross the intersection even if caught in a dilemma zone or in a zone in which the obvious decision is to stop. Such findings can be valuable when designing a signalized intersection and the traffic time settings, as well as the posted speed limit.},
DOI = {10.3390/safety7010011}
}



@Article{s21041051,
AUTHOR = {Marques, Luís and Vale, Alberto and Vaz, Pedro},
TITLE = {State-of-the-Art Mobile Radiation Detection Systems for Different Scenarios},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1051},
URL = {https://www.mdpi.com/1424-8220/21/4/1051},
PubMedID = {33557104},
ISSN = {1424-8220},
ABSTRACT = {In the last decade, the development of more compact and lightweight radiation detection systems led to their application in handheld and small unmanned systems, particularly air-based platforms. Examples of improvements are: the use of silicon photomultiplier-based scintillators, new scintillating crystals, compact dual-mode detectors (gamma/neutron), data fusion, mobile sensor networks, cooperative detection and search. Gamma cameras and dual-particle cameras are increasingly being used for source location. This study reviews and discusses the research advancements in the field of gamma-ray and neutron measurements using mobile radiation detection systems since the Fukushima nuclear accident. Four scenarios are considered: radiological and nuclear accidents and emergencies; illicit traffic of special nuclear materials and radioactive materials; nuclear, accelerator, targets, and irradiation facilities; and naturally occurring radioactive materials monitoring-related activities. The work presented in this paper aims to: compile and review information on the radiation detection systems, contextual sensors and platforms used for each scenario; assess their advantages and limitations, looking prospectively to new research and challenges in the field; and support the decision making of national radioprotection agencies and response teams in respect to adequate detection system for each scenario. For that, an extensive literature review was conducted.},
DOI = {10.3390/s21041051}
}



@Article{app11041403,
AUTHOR = {Kamarudin, Mohd Hider and Ismail, Zool Hilmi and Saidi, Noor Baity},
TITLE = {Deep Learning Sensor Fusion in Plant Water Stress Assessment: A Comprehensive Review},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1403},
URL = {https://www.mdpi.com/2076-3417/11/4/1403},
ISSN = {2076-3417},
ABSTRACT = {Water stress is one of the major challenges to food security, causing a significant economic loss for the nation as well for growers. Accurate assessment of water stress will enhance agricultural productivity through optimization of plant water usage, maximizing plant breeding strategies, and preventing forest wildfire for better ecosystem management. Recent advancements in sensor technologies have enabled high-throughput, non-contact, and cost-efficient plant water stress assessment through intelligence system modeling. The advanced deep learning sensor fusion technique has been reported to improve the performance of the machine learning application for processing the collected sensory data. This paper extensively reviews the state-of-the-art methods for plant water stress assessment that utilized the deep learning sensor fusion approach in their application, together with future prospects and challenges of the application domain. Notably, 37 deep learning solutions fell under six main areas, namely soil moisture estimation, soil water modelling, evapotranspiration estimation, evapotranspiration forecasting, plant water status estimation and plant water stress identification. Basically, there are eight deep learning solutions compiled for the 3D-dimensional data and plant varieties challenge, including unbalanced data that occurred due to isohydric plants, and the effect of variations that occur within the same species but cultivated from different locations.},
DOI = {10.3390/app11041403}
}



@Article{s21041076,
AUTHOR = {Yan, Peng and Jia, Tao and Bai, Chengchao},
TITLE = {Searching and Tracking an Unknown Number of Targets: A Learning-Based Method Enhanced with Maps Merging},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1076},
URL = {https://www.mdpi.com/1424-8220/21/4/1076},
PubMedID = {33557359},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles (UAVs) have been widely used in search and rescue (SAR) missions due to their high flexibility. A key problem in SAR missions is to search and track moving targets in an area of interest. In this paper, we focus on the problem of Cooperative Multi-UAV Observation of Multiple Moving Targets (CMUOMMT). In contrast to the existing literature, we not only optimize the average observation rate of the discovered targets, but we also emphasize the fairness of the observation of the discovered targets and the continuous exploration of the undiscovered targets, under the assumption that the total number of targets is unknown. To achieve this objective, a deep reinforcement learning (DRL)-based method is proposed under the Partially Observable Markov Decision Process (POMDP) framework, where each UAV maintains four observation history maps, and maps from different UAVs within a communication range can be merged to enhance UAVs’ awareness of the environment. A deep convolutional neural network (CNN) is used to process the merged maps and generate the control commands to UAVs. The simulation results show that our policy can enable UAVs to balance between giving the discovered targets a fair observation and exploring the search region compared with other methods.},
DOI = {10.3390/s21041076}
}



@Article{s21041108,
AUTHOR = {Melo, Aurelio G. and Pinto, Milena F. and Marcato, Andre L. M. and Honório, Leonardo M. and Coelho, Fabrício O.},
TITLE = {Dynamic Optimization and Heuristics Based Online Coverage Path Planning in 3D Environment for UAVs},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1108},
URL = {https://www.mdpi.com/1424-8220/21/4/1108},
PubMedID = {33562647},
ISSN = {1424-8220},
ABSTRACT = {Path planning is one of the most important issues in the robotics field, being applied in many domains ranging from aerospace technology and military tasks to manufacturing and agriculture. Path planning is a branch of autonomous navigation. In autonomous navigation, dynamic decisions about the path have to be taken while the robot moves towards its goal. Among the navigation area, an important class of problems is Coverage Path Planning (CPP). The CPP technique is associated with determining a collision-free path that passes through all viewpoints in a specific area. This paper presents a method to perform CPP in 3D environment for Unmanned Aerial Vehicles (UAVs) applications, namely 3D dynamic for CPP applications (3DD-CPP). The proposed method can be deployed in an unknown environment through a combination of linear optimization and heuristics. A model to estimate cost matrices accounting for UAV power usage is proposed and evaluated for a few different flight speeds. As linear optimization methods can be computationally demanding to be used on-board a UAV, this work also proposes a distributed execution of the algorithm through fog-edge computing. Results showed that 3DD-CPP had a good performance in both local execution and fog-edge for different simulated scenarios. The proposed heuristic is capable of re-optimization, enabling execution in environments with local knowledge of the environments.},
DOI = {10.3390/s21041108}
}



@Article{plants10020310,
AUTHOR = {Solovchenko, Alexei and Dorokhov, Alexei and Shurygin, Boris and Nikolenko, Alexandr and Velichko, Vitaly and Smirnov, Igor and Khort, Dmitriy and Aksenov, Aleksandr and Kuzin, Andrey},
TITLE = {Linking Tissue Damage to Hyperspectral Reflectance for Non-Invasive Monitoring of Apple Fruit in Orchards},
JOURNAL = {Plants},
VOLUME = {10},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {310},
URL = {https://www.mdpi.com/2223-7747/10/2/310},
PubMedID = {33562864},
ISSN = {2223-7747},
ABSTRACT = {Reflected light carries ample information about the biochemical composition, tissue architecture, and physiological condition of plants. Recent technical progress has paved the way for affordable imaging hyperspectrometers (IH) providing spatially resolved spectral information on plants on different levels, from individual plant organs to communities. The extraction of sensible information from hyperspectral images is difficult due to inherent complexity of plant tissue and canopy optics, especially when recorded under ambient sunlight. We report on the changes in hyperspectral reflectance accompanying the accumulation of anthocyanins in healthy apple (cultivars Ligol, Gala, Golden Delicious) fruits as well as in fruits affected by pigment breakdown during sunscald development and phytopathogen attacks. The measurements made outdoors with a snapshot IH were compared with traditional “point-type” reflectance measured with a spectrophotometer under controlled illumination conditions. The spectra captured by the IH were suitable for processing using the approaches previously developed for “point-type” apple fruit and leaf reflectance spectra. The validity of this approach was tested by constructing a novel index mBRI (modified browning reflectance index) for detection of tissue damages on the background of the anthocyanin absorption. The index was suggested in the form of mBRI = (R640−1 + R800−1) − R678−1. Difficulties of the interpretation of fruit hyperspectral reflectance images recorded in situ are discussed with possible implications for plant physiology and precision horticulture practices.},
DOI = {10.3390/plants10020310}
}



@Article{rs13040582,
AUTHOR = {Bolch, Erik A. and Hestir, Erin L. and Khanna, Shruti},
TITLE = {Performance and Feasibility of Drone-Mounted Imaging Spectroscopy for Invasive Aquatic Vegetation Detection},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {582},
URL = {https://www.mdpi.com/2072-4292/13/4/582},
ISSN = {2072-4292},
ABSTRACT = {Invasive plants are non-native species that can spread rapidly, leading to detrimental economic, ecological, or environmental impact. In aquatic systems such as the Sacramento-San Joaquin River Delta in California, USA, management agencies use manned aerial vehicles (MAV) imaging spectroscopy missions to map and track annual changes in invasive aquatic plants. Advances in unmanned aerial vehicles (UAV) and sensor miniaturization are enabling higher spatial resolution species mapping, which is promising for early detection of invasions before they spread over larger areas. This study compared maps made from UAV-based imaging spectroscopy with the manned airborne imaging spectroscopy-derived maps that are currently produced for monitoring invasive aquatic plants in the Sacramento-San Joaquin Delta. Concurrent imagery was collected using the MAV mounted HyMap sensor and the UAV mounted Nano-Hyperspec at a wetland study site and classification maps generated using random forest models were compared. Classification accuracies were comparable between the Nano- and HyMap-derived maps, with the Nano-derived map having a slightly higher overall accuracy. Additionally, the higher resolution of the Nano imagery allowed detection of patches of water hyacinth present in the study site that the HyMap could not. However, it would not be feasible to operate the Nano as a replacement to HyMap at scale despite its improved detection capabilities due to the high costs associated with overcoming area coverage limitations. Overall, UAV-based imaging spectroscopy provides comparable or improved capability, and we suggest it could be used to supplement existing monitoring programs by focusing on target areas of high ecologic or economic priority.},
DOI = {10.3390/rs13040582}
}



@Article{rs13040579,
AUTHOR = {Jiang, Xueqin and Fang, Shenghui and Huang, Xia and Liu, Yanghua and Guo, Linlin},
TITLE = {Rice Mapping and Growth Monitoring Based on Time Series GF-6 Images and Red-Edge Bands},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {579},
URL = {https://www.mdpi.com/2072-4292/13/4/579},
ISSN = {2072-4292},
ABSTRACT = {Accurate rice mapping and growth monitoring are of great significance for ensuring food security and agricultural sustainable development. Remote sensing (RS), as an efficient observation technology, is expected to be useful for rice mapping and growth monitoring. Due to the fragmented distribution of paddy fields and the undulating terrain in Southern China, it is very difficult in rice mapping. Moreover, there are many crops with the same growth period as rice, resulting in low accuracy of rice mapping. We proposed a red-edge decision tree (REDT) method based on the combination of time series GF-6 images and red-edge bands to solve this problem. The red-edge integral and red-edge vegetation index integral were computed by using two red-edge bands derived from GF-6 images to construct the REDT. Meanwhile, the conventional method based on time series normalized difference vegetation index (NDVI), normalized difference water index (NDWI), enhanced vegetation index (EVI) (NNE) was employed to compare the effectiveness of rice mapping. The results indicated that the overall accuracy and Kappa coefficient of REDT ranged from 91%–94% and 0.82–0.87, improving about 7% and 0.15 compared with the NNE method. This proved that the proposed technology was able to efficiently solve the problem of rice mapping on a large scale and regions with fragmented landscapes. Additionally, two red-edge bands of GF-6 images were applied to monitor rice growth. It concluded that the two red-edge bands played different roles in rice growth monitoring. The red-edge bands of GF-6 images were superior in rice mapping and growth monitoring. Further study needs to develop more vegetation indices (VIs) related to the red-edge to make the best use of red-edge characteristics in precision agriculture.},
DOI = {10.3390/rs13040579}
}



@Article{rs13040586,
AUTHOR = {Praticò, Salvatore and Solano, Francesco and Di Fazio, Salvatore and Modica, Giuseppe},
TITLE = {Machine Learning Classification of Mediterranean Forest Habitats in Google Earth Engine Based on Seasonal Sentinel-2 Time-Series and Input Image Composition Optimisation},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {586},
URL = {https://www.mdpi.com/2072-4292/13/4/586},
ISSN = {2072-4292},
ABSTRACT = {The sustainable management of natural heritage is presently considered a global strategic issue. Owing to the ever-growing availability of free data and software, remote sensing (RS) techniques have been primarily used to map, analyse, and monitor natural resources for conservation purposes. The need to adopt multi-scale and multi-temporal approaches to detect different phenological aspects of different vegetation types and species has also emerged. The time-series composite image approach allows for capturing much of the spectral variability, but presents some criticalities (e.g., time-consuming research, downloading data, and the required storage space). To overcome these issues, the Google Earth engine (GEE) has been proposed, a free cloud-based computational platform that allows users to access and process remotely sensed data at petabyte scales. The application was tested in a natural protected area in Calabria (South Italy), which is particularly representative of the Mediterranean mountain forest environment. In the research, random forest (RF), support vector machine (SVM), and classification and regression tree (CART) algorithms were used to perform supervised pixel-based classification based on the use of Sentinel-2 images. A process to select the best input image (seasonal composition strategies, statistical operators, band composition, and derived vegetation indices (VIs) information) for classification was implemented. A set of accuracy indicators, including overall accuracy (OA) and multi-class F-score (Fm), were computed to assess the results of the different classifications. GEE proved to be a reliable and powerful tool for the classification process. The best results (OA = 0.88 and Fm = 0.88) were achieved using RF with the summer image composite, adding three VIs (NDVI, EVI, and NBR) to the Sentinel-2 bands. SVM and RF produced OAs of 0.83 and 0.80, respectively.},
DOI = {10.3390/rs13040586}
}



@Article{rs13040584,
AUTHOR = {Zhu, Linglong and Zhang, Yonghong and Wang, Jiangeng and Tian, Wei and Liu, Qi and Ma, Guangyi and Kan, Xi and Chu, Ya},
TITLE = {Downscaling Snow Depth Mapping by Fusion of Microwave and Optical Remote-Sensing Data Based on Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {584},
URL = {https://www.mdpi.com/2072-4292/13/4/584},
ISSN = {2072-4292},
ABSTRACT = {Accurate high spatial resolution snow depth mapping in arid and semi-arid regions is of great importance for snow disaster assessment and hydrological modeling. However, due to the complex topography and low spatial-resolution microwave remote-sensing data, the existing snow depth datasets have large errors and uncertainty, and actual spatiotemporal heterogeneity of snow depth cannot be effectively detected. This paper proposed a deep learning approach based on downscaling snow depth retrieval by fusion of satellite remote-sensing data with multiple spatial scales and diverse characteristics. The (Fengyun-3 Microwave Radiation Imager) FY-3 MWRI data were downscaled to 500 m resolution to match Moderate-resolution Imaging Spectroradiometer (MODIS) snow cover, meteorological and geographic data. A deep neural network was constructed to capture detailed spectral and radiation signals and trained to retrieve the higher spatial resolution snow depth from the aforementioned input data and ground observation. Verified by in situ measurements, downscaled snow depth has the lowest root mean square error (RMSE) and mean absolute error (MAE) (8.16 cm, 4.73 cm respectively) among Environmental and Ecological Science Data Center for West China Snow Depth (WESTDC_SD, 9.38 cm and 5.36 cm), the Microwave Radiation Imager (MWRI) Ascend Snow Depth (MWRI_A_SD, 9.45 cm and 5.49 cm) and MWRI Descend Snow Depth (MWRI_D_SD, 10.55 cm and 6.13 cm) in the study area. Meanwhile, downscaled snow depth could provide more detailed information in spatial distribution, which has been used to analyze the decrease of retrieval accuracy by various topography factors.},
DOI = {10.3390/rs13040584}
}



@Article{aerospace8020044,
AUTHOR = {Uzun, Mevlut and Demirezen, Mustafa Umut and Inalhan, Gokhan},
TITLE = {Physics Guided Deep Learning for Data-Driven Aircraft Fuel Consumption Modeling},
JOURNAL = {Aerospace},
VOLUME = {8},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {44},
URL = {https://www.mdpi.com/2226-4310/8/2/44},
ISSN = {2226-4310},
ABSTRACT = {This paper presents a physics-guided deep neural network framework to estimate fuel consumption of an aircraft. The framework aims to improve data-driven models’ consistency in flight regimes that are not covered by data. In particular, we guide the neural network with the equations that represent fuel flow dynamics. In addition to the empirical error, we embed this physical knowledge as several extra loss terms. Results show that our proposed model accomplishes correct predictions on the labeled test set, as well as assuring physical consistency in unseen flight regimes. The results indicate that our model, while being applicable to the aircraft’s complete flight envelope, yields lower fuel consumption error measures compared to the model-based approaches and other supervised learning techniques utilizing the same training data sets. In addition, our deep learning model produces fuel consumption trends similar to the BADA4 aircraft performance model, which is widely utilized in real-world operations, in unseen and untrained flight regimes. In contrast, the other supervised learning techniques fail to produce meaningful results. Overall, the proposed methodology enhances the explainability of data-driven models without deteriorating accuracy.},
DOI = {10.3390/aerospace8020044}
}



@Article{rs13040598,
AUTHOR = {Wasonga, Daniel O. and Yaw, Afrane and Kleemola, Jouko and Alakukku, Laura and Mäkelä, Pirjo S.A.},
TITLE = {Red-Green-Blue and Multispectral Imaging as Potential Tools for Estimating Growth and Nutritional Performance of Cassava under Deficit Irrigation and Potassium Fertigation},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {598},
URL = {https://www.mdpi.com/2072-4292/13/4/598},
ISSN = {2072-4292},
ABSTRACT = {Cassava has high energy value and rich nutritional content, yet its productivity in the tropics is seriously constrained by abiotic stresses such as water deficit and low potassium (K) nutrition. Systems that allow evaluation of genotypes in the field and greenhouse for nondestructive estimation of plant performance would be useful means for monitoring the health of plants for crop-management decisions. We investigated whether the red–green–blue (RGB) and multispectral images could be used to detect the previsual effects of water deficit and low K in cassava, and whether the crop quality changes due to low moisture and low K could be observed from the images. Pot experiments were conducted with cassava cuttings. The experimental design was a split-plot arranged in a completely randomized design. Treatments were three irrigation doses split into various K rates. Plant images were captured beginning 30 days after planting (DAP) and ended at 90 DAP when plants were harvested. Results show that biomass, chlorophyll, and net photosynthesis were estimated with the highest accuracy (R2 = 0.90), followed by leaf area (R2 = 0.76). Starch, energy, carotenoid, and cyanide were also estimated satisfactorily (R2 &gt; 0.80), although cyanide showed negative regression coefficients. All mineral elements showed lower estimation accuracy (R2 = 0.14–0.48) and exhibited weak associations with the spectral indices. Use of the normalized difference vegetation index (NDVI), green area (GA), and simple ratio (SR) indices allowed better estimation of growth and key nutritional traits. Irrigation dose 30% of pot capacity enriched with 0.01 mM K reduced most index values but increased the crop senescence index (CSI). Increasing K to 16 mM over the irrigation doses resulted in high index values, but low CSI. The findings indicate that RGB and multispectral imaging can provide indirect measurements of growth and key nutritional traits in cassava. Hence, they can be used as a tool in various breeding programs to facilitate cultivar evaluation and support management decisions to avert stress, such as the decision to irrigate or apply fertilizers.},
DOI = {10.3390/rs13040598}
}



@Article{rs13040599,
AUTHOR = {Battaglia, Michael J. and Banks, Sarah and Behnamian, Amir and Bourgeau-Chavez, Laura and Brisco, Brian and Corcoran, Jennifer and Chen, Zhaohua and Huberty, Brian and Klassen, James and Knight, Joseph and Morin, Paul and Murnaghan, Kevin and Pelletier, Keith and White, Lori},
TITLE = {Multi-Source EO for Dynamic Wetland Mapping and Monitoring in the Great Lakes Basin},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {599},
URL = {https://www.mdpi.com/2072-4292/13/4/599},
ISSN = {2072-4292},
ABSTRACT = {Wetland managers, citizens and government leaders are observing rapid changes in coastal wetlands and associated habitats around the Great Lakes Basin due to human activity and climate variability. SAR and optical satellite sensors offer cost effective management tools that can be used to monitor wetlands over time, covering large areas like the Great Lakes and providing information to those making management and policy decisions. In this paper we describe ongoing efforts to monitor dynamic changes in wetland vegetation, surface water extent, and water level change. Included are assessments of simulated Radarsat Constellation Mission data to determine feasibility of continued monitoring into the future. Results show that integration of data from multiple sensors is most effective for monitoring coastal wetlands in the Great Lakes region. While products developed using methods described in this article provide valuable management tools, more effort is needed to reach the goal of establishing a dynamic, near-real-time, remote sensing-based monitoring program for the basin.},
DOI = {10.3390/rs13040599}
}



@Article{su13041821,
AUTHOR = {Islam, Nahina and Rashid, Md Mamunur and Pasandideh, Faezeh and Ray, Biplob and Moore, Steven and Kadel, Rajan},
TITLE = {A Review of Applications and Communication Technologies for Internet of Things (IoT) and Unmanned Aerial Vehicle (UAV) Based Sustainable Smart Farming},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1821},
URL = {https://www.mdpi.com/2071-1050/13/4/1821},
ISSN = {2071-1050},
ABSTRACT = {To reach the goal of sustainable agriculture, smart farming is taking advantage of the Unmanned Aerial Vehicles (UAVs) and Internet of Things (IoT) paradigm. These smart farms are designed to be run by interconnected devices and vehicles. Some enormous potentials can be achieved by the integration of different IoT technologies to achieve automated operations with minimum supervision. This paper outlines some major applications of IoT and UAV in smart farming, explores the communication technologies, network functionalities and connectivity requirements for Smart farming. The connectivity limitations of smart agriculture and it’s solutions are analysed with two case studies. In case study-1, we propose and evaluate meshed Long Range Wide Area Network (LoRaWAN) gateways to address connectivity limitations of Smart Farming. While in case study-2, we explore satellite communication systems to provide connectivity to smart farms in remote areas of Australia. Finally, we conclude the paper by identifying future research challenges on this topic and outlining directions to address those challenges.},
DOI = {10.3390/su13041821}
}



@Article{telecom2010005,
AUTHOR = {Kakamoukas, Georgios and Sarigiannidis, Panagiotis and Maropoulos, Andreas and Lagkas, Thomas and Zaralis, Konstantinos and Karaiskou, Chrysoula},
TITLE = {Towards Climate Smart Farming—A Reference Architecture for Integrated Farming Systems},
JOURNAL = {Telecom},
VOLUME = {2},
YEAR = {2021},
NUMBER = {1},
PAGES = {52--74},
URL = {https://www.mdpi.com/2673-4001/2/1/5},
ISSN = {2673-4001},
ABSTRACT = {Climate change is emerging as a major threat to farming, food security and the livelihoods of millions of people across the world. Agriculture is strongly affected by climate change due to increasing temperatures, water shortage, heavy rainfall and variations in the frequency and intensity of excessive climatic events such as floods and droughts. Farmers need to adapt to climate change by developing advanced and sophisticated farming systems instead of simply farming at lower intensity and occupying more land. Integrated agricultural systems constitute a promising solution, as they can lower reliance on external inputs, enhance nutrient cycling and increase natural resource use efficiency. In this context, the concept of Climate-Smart Agriculture (CSA) emerged as a promising solution to secure the resources for the growing world population under climate change conditions. This work proposes a CSA architecture for fostering and supporting integrated agricultural systems, such as Mixed Farming Systems (MFS), by facilitating the design, the deployment and the management of crop–livestock-=forestry combinations towards sustainable, efficient and climate resilient agricultural systems. Propelled by cutting-edge technology solutions in data collection and processing, along with fully autonomous monitoring systems, e.g., smart sensors and unmanned aerial vehicles (UAVs), the proposed architecture called MiFarm-CSA, aims to foster core interactions among animals, forests and crops, while mitigating the high complexity of these interactions, through a novel conceptual framework.},
DOI = {10.3390/telecom2010005}
}



@Article{agronomy11020306,
AUTHOR = {Loiskandl, Willibald and Nolz, Reinhard},
TITLE = {Requirements for Sustainable Irrigated Agriculture},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {306},
URL = {https://www.mdpi.com/2073-4395/11/2/306},
ISSN = {2073-4395},
ABSTRACT = {The aim of this review is to present a holistic view on irrigation with respect to local environmental and social conditions. Future irrigation development is addressed with a focus on sustainable development. However, technical irrigation aspects are included and references are provided for further reading and completeness. An irrigation intervention is always a combination of feasible technical, social and environmental aspects. This review provides an overview of the various fields of expertise involved in irrigation interventions and contributes to cross-discipline discussions and understanding. The selected cases demonstrate the bias of human developments and they serve to raise awareness of the impact of human interventions. The practical examples refer mainly to the authors’ project experiences and were selected so as to support pathways for sustainable irrigation development. Placing modern irrigation in relation to sustainable development goals needs a sophisticated holistic approach.},
DOI = {10.3390/agronomy11020306}
}



@Article{ai2010004,
AUTHOR = {Espejo-Garcia, Borja and Malounas, Ioannis and Vali, Eleanna and Fountas, Spyros},
TITLE = {Testing the Suitability of Automated Machine Learning for Weeds Identification},
JOURNAL = {AI},
VOLUME = {2},
YEAR = {2021},
NUMBER = {1},
PAGES = {34--47},
URL = {https://www.mdpi.com/2673-2688/2/1/4},
ISSN = {2673-2688},
ABSTRACT = {In the past years, several machine-learning-based techniques have arisen for providing effective crop protection. For instance, deep neural networks have been used to identify different types of weeds under different real-world conditions. However, these techniques usually require extensive involvement of experts working iteratively in the development of the most suitable machine learning system. To support this task and save resources, a new technique called Automated Machine Learning has started being studied. In this work, a complete open-source Automated Machine Learning system was evaluated with two different datasets, (i) The Early Crop Weeds dataset and (ii) the Plant Seedlings dataset, covering the weeds identification problem. Different configurations, such as the use of plant segmentation, the use of classifier ensembles instead of Softmax and training with noisy data, have been compared. The results showed promising performances of 93.8% and 90.74% F1 score depending on the dataset used. These performances were aligned with other related works in AutoML, but they are far from machine-learning-based systems manually fine-tuned by human experts. From these results, it can be concluded that finding a balance between manual expert work and Automated Machine Learning will be an interesting path to work in order to increase the efficiency in plant protection.},
DOI = {10.3390/ai2010004}
}



@Article{rs13040625,
AUTHOR = {Neumann, Carsten and Schindhelm, Anne and Müller, Jörg and Weiss, Gabriele and Liu, Anna and Itzerott, Sibylle},
TITLE = {The Regenerative Potential of Managed Calluna Heathlands—Revealing Optical and Structural Traits for Predicting Recovery Dynamics},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {625},
URL = {https://www.mdpi.com/2072-4292/13/4/625},
ISSN = {2072-4292},
ABSTRACT = {The potential of vegetation recovery through resprouting of plant tissue from buds after the removal of aboveground biomass is a key resilience strategy for populations under abrupt environmental change. Resprouting leads to fast regeneration, particularly after the implementation of mechanical mowing as part of active management for promoting open habitats. We investigated whether recovery dynamics of resprouting and the threat of habitat conversion can be predicted by optical and structural stand traits derived from drone imagery in a protected heathland area. We conducted multivariate regression for variable selection and random forest regression for predictive modeling using 50 spectral predictors, textural features and height parameters to quantify Calluna resprouting and grass invasion in before-mowing images that were related to vegetation recovery in after-mowing imagery. The study reveals that Calluna resprouting can be explained by significant optical predictors of mainly green reflectance in parental individuals. In contrast, grass encroachment is identified by structural canopy properties that indicate before-mowing grass interpenetration as starting points for after-mowing dispersal. We prove the concept of trait propagation through time providing significant derivates for a low-cost drone system. It can be utilized to build drone-based decision support systems for evaluating consequences and requirements of habitat management practice.},
DOI = {10.3390/rs13040625}
}



@Article{rs13040633,
AUTHOR = {Zhang, Xiuwei and Zhou, Yang and Jin, Jiaojiao and Wang, Yafei and Fan, Minhao and Wang, Ning and Zhang, Yanning},
TITLE = {ICENETv2: A Fine-Grained River Ice Semantic Segmentation Network Based on UAV Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {633},
URL = {https://www.mdpi.com/2072-4292/13/4/633},
ISSN = {2072-4292},
ABSTRACT = {Accurate ice segmentation is one of the most crucial techniques for intelligent ice monitoring. Compared with ice segmentation, it can provide more information for ice situation analysis, change trend prediction, and so on. Therefore, the study of ice segmentation has important practical significance. In this study, we focused on fine-grained river ice segmentation using unmanned aerial vehicle (UAV) images. This has the following difficulties: (1) The scale of river ice varies greatly in different images and even in the same image; (2) the same kind of river ice differs greatly in color, shape, texture, size, and so on; and (3) the appearances of different kinds of river ice sometimes appear similar due to the complex formation and change procedure. Therefore, to perform this study, the NWPU_YRCC2 dataset was built, in which all UAV images were collected in the Ningxia–Inner Mongolia reach of the Yellow River. Then, a novel semantic segmentation method based on deep convolution neural network, named ICENETv2, is proposed. To achieve multiscale accurate prediction, we design a multilevel features fusion framework, in which multi-scale high-level semantic features and lower-level finer features are effectively fused. Additionally, a dual attention module is adopted to highlight distinguishable characteristics, and a learnable up-sampling strategy is further used to improve the segmentation accuracy of the details. Experiments show that ICENETv2 achieves the state-of-the-art on the NWPU_YRCC2 dataset. Finally, our ICENETv2 is also applied to solve a realistic problem, calculating drift ice cover density, which is one of the most important factors to predict the freeze-up data of the river. The results demonstrate that the performance of ICENETv2 meets the actual application demand.},
DOI = {10.3390/rs13040633}
}



@Article{rs13040659,
AUTHOR = {Yuval, Matan and Alonso, Iñigo and Eyal, Gal and Tchernov, Dan and Loya, Yossi and Murillo, Ana C. and Treibitz, Tali},
TITLE = {Repeatable Semantic Reef-Mapping through Photogrammetry and Label-Augmentation},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {659},
URL = {https://www.mdpi.com/2072-4292/13/4/659},
ISSN = {2072-4292},
ABSTRACT = {In an endeavor to study natural systems at multiple spatial and taxonomic resolutions, there is an urgent need for automated, high-throughput frameworks that can handle plethora of information. The coalescence of remote-sensing, computer-vision, and deep-learning elicits a new era in ecological research. However, in complex systems, such as marine-benthic habitats, key ecological processes still remain enigmatic due to the lack of cross-scale automated approaches (mms to kms) for community structure analysis. We address this gap by working towards scalable and comprehensive photogrammetric surveys, tackling the profound challenges of full semantic segmentation and 3D grid definition. Full semantic segmentation (where every pixel is classified) is extremely labour-intensive and difficult to achieve using manual labeling. We propose using label-augmentation, i.e., propagation of sparse manual labels, to accelerate the task of full segmentation of photomosaics. Photomosaics are synthetic images generated from a projected point-of-view of a 3D model. In the lack of navigation sensors (e.g., a diver-held camera), it is difficult to repeatably determine the slope-angle of a 3D map. We show this is especially important in complex topographical settings, prevalent in coral-reefs. Specifically, we evaluate our approach on benthic habitats, in three different environments in the challenging underwater domain. Our approach for label-augmentation shows human-level accuracy in full segmentation of photomosaics using labeling as sparse as 0.1%, evaluated on several ecological measures. Moreover, we found that grid definition using a leveler improves the consistency in community-metrics obtained due to occlusions and topology (angle and distance between objects), and that we were able to standardise the 3D transformation with two percent error in size measurements. By significantly easing the annotation process for full segmentation and standardizing the 3D grid definition we present a semantic mapping methodology enabling change-detection, which is practical, swift, and cost-effective. Our workflow enables repeatable surveys without permanent markers and specialized mapping gear, useful for research and monitoring, and our code is available online. Additionally, we release the Benthos data-set, fully manually labeled photomosaics from three oceanic environments with over 4500 segmented objects useful for research in computer-vision and marine ecology.},
DOI = {10.3390/rs13040659}
}



@Article{f12020216,
AUTHOR = {Luo, Mi and Wang, Yifu and Xie, Yunhong and Zhou, Lai and Qiao, Jingjing and Qiu, Siyu and Sun, Yujun},
TITLE = {Combination of Feature Selection and CatBoost for Prediction: The First Application to the Estimation of Aboveground Biomass},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {216},
URL = {https://www.mdpi.com/1999-4907/12/2/216},
ISSN = {1999-4907},
ABSTRACT = {Increasing numbers of explanatory variables tend to result in information redundancy and “dimensional disaster” in the quantitative remote sensing of forest aboveground biomass (AGB). Feature selection of model factors is an effective method for improving the accuracy of AGB estimates. Machine learning algorithms are also widely used in AGB estimation, although little research has addressed the use of the categorical boosting algorithm (CatBoost) for AGB estimation. Both feature selection and regression for AGB estimation models are typically performed with the same machine learning algorithm, but there is no evidence to suggest that this is the best method. Therefore, the present study focuses on evaluating the performance of the CatBoost algorithm for AGB estimation and comparing the performance of different combinations of feature selection methods and machine learning algorithms. AGB estimation models of four forest types were developed based on Landsat OLI data using three feature selection methods (recursive feature elimination (RFE), variable selection using random forests (VSURF), and least absolute shrinkage and selection operator (LASSO)) and three machine learning algorithms (random forest regression (RFR), extreme gradient boosting (XGBoost), and categorical boosting (CatBoost)). Feature selection had a significant influence on AGB estimation. RFE preserved the most informative features for AGB estimation and was superior to VSURF and LASSO. In addition, CatBoost improved the accuracy of the AGB estimation models compared with RFR and XGBoost. AGB estimation models using RFE for feature selection and CatBoost as the regression algorithm achieved the highest accuracy, with root mean square errors (RMSEs) of 26.54 Mg/ha for coniferous forest, 24.67 Mg/ha for broad-leaved forest, 22.62 Mg/ha for mixed forests, and 25.77 Mg/ha for all forests. The combination of RFE and CatBoost had better performance than the VSURF–RFR combination in which random forests were used for both feature selection and regression, indicating that feature selection and regression performed by a single machine learning algorithm may not always ensure optimal AGB estimation. It is promising to extending the application of new machine learning algorithms and feature selection methods to improve the accuracy of AGB estimates.},
DOI = {10.3390/f12020216}
}



@Article{rs13040681,
AUTHOR = {Morell-Monzó, Sergio and Sebastiá-Frasquet, María-Teresa and Estornell, Javier},
TITLE = {Land Use Classification of VHR Images for Mapping Small-Sized Abandoned Citrus Plots by Using Spectral and Textural Information},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {681},
URL = {https://www.mdpi.com/2072-4292/13/4/681},
ISSN = {2072-4292},
ABSTRACT = {Agricultural land abandonment is an increasing problem in Europe. The Comunitat Valenciana Region (Spain) is one of the most important citrus producers in Europe suffering this problem. This region characterizes by small sized citrus plots and high spatial fragmentation which makes necessary to use Very High-Resolution images to detect abandoned plots. In this paper spectral and Gray Level Co-Occurrence Matrix (GLCM)-based textural information derived from the Normalized Difference Vegetation Index (NDVI) are used to map abandoned citrus plots in Oliva municipality (eastern Spain). The proposed methodology is based on three general steps: (a) extraction of spectral and textural features from the image, (b) pixel-based classification of the image using the Random Forest algorithm, and (c) assignment of a single value per plot by majority voting. The best results were obtained when extracting the texture features with a 9 × 9 window size and the Random Forest model showed convergence around 100 decision trees. Cross-validation of the model showed an overall accuracy of the pixel-based classification of 87% and an overall accuracy of the plot-based classification of 95%. All the variables used are statistically significant for the classification, however the most important were contrast, dissimilarity, NIR band (720 nm), and blue band (620 nm). According to our results, 31% of the plots classified as citrus in Oliva by current methodology are abandoned. This is very important to avoid overestimating crop yield calculations by public administrations. The model was applied successfully outside the main study area (Oliva municipality); with a slightly lower accuracy (92%). This research provides a new approach to map small agricultural plots, especially to detect land abandonment in woody evergreen crops that have been little studied until now.},
DOI = {10.3390/rs13040681}
}



@Article{ai2010006,
AUTHOR = {Whitmire, Christopher D. and Vance, Jonathan M. and Rasheed, Hend K. and Missaoui, Ali and Rasheed, Khaled M. and Maier, Frederick W.},
TITLE = {Using Machine Learning and Feature Selection for Alfalfa Yield Prediction},
JOURNAL = {AI},
VOLUME = {2},
YEAR = {2021},
NUMBER = {1},
PAGES = {71--88},
URL = {https://www.mdpi.com/2673-2688/2/1/6},
ISSN = {2673-2688},
ABSTRACT = {Predicting alfalfa biomass and crop yield for livestock feed is important to the daily lives of virtually everyone, and many features of data from this domain combined with corresponding weather data can be used to train machine learning models for yield prediction. In this work, we used yield data of different alfalfa varieties from multiple years in Kentucky and Georgia, and we compared the impact of different feature selection methods on machine learning (ML) models trained to predict alfalfa yield. Linear regression, regression trees, support vector machines, neural networks, Bayesian regression, and nearest neighbors were all developed with cross validation. The features used included weather data, historical yield data, and the sown date. The feature selection methods that were compared included a correlation-based method, the ReliefF method, and a wrapper method. We found that the best method was the correlation-based method, and the feature set it found consisted of the Julian day of the harvest, the number of days between the sown and harvest dates, cumulative solar radiation since the previous harvest, and cumulative rainfall since the previous harvest. Using these features, the k-nearest neighbor and random forest methods achieved an average R value over 0.95, and average mean absolute error less than 200 lbs./acre. Our top R2 of 0.90 beats a previous work’s best R2 of 0.87. Our primary contribution is the demonstration that ML, with feature selection, shows promise in predicting crop yields even on simple datasets with a handful of features, and that reporting accuracies in R and R2 offers an intuitive way to compare results among various crops.},
DOI = {10.3390/ai2010006}
}



@Article{plants10020374,
AUTHOR = {Aranguren, Marta and Castellón, Ander and Aizpurua, Ana},
TITLE = {Wheat Grain Protein Content under Mediterranean Conditions Measured with Chlorophyll Meter},
JOURNAL = {Plants},
VOLUME = {10},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {374},
URL = {https://www.mdpi.com/2223-7747/10/2/374},
PubMedID = {33672001},
ISSN = {2223-7747},
ABSTRACT = {Adequate N fertilisation is crucial to increase the grain protein content (GPC) values in wheat. The recommended level of GPC needed to achieve high-quality bread-making flour should be higher than 12.5%. However, it is difficult to ensure the GPC values that the crop will achieve because N in grain is derived from two different sources: N remobilized into the grain from N accumulated in the pre-anthesis period, and N absorbed from the soil in the post-anthesis period. This study aimed to (i) evaluate the effect of the application of N on the rate of stem elongation (GS30) when farmyard manures are applied as initial fertilisers on GPC and on the chlorophyll meter (CM) values at mid-anthesis (GS65), (ii) establish a relationship between the CM values at GS65 and GPC, and (iii) determine a minimum CM value at GS65 to obtain GPC values above 12.5%. Three field trials were performed in three consecutive growing seasons, and different N fertilisation doses were applied. Readings using the CM Yara N-TesterTM were taken at GS65. The type of initial fertiliser did not affect the GPC and CM values. Generally, the greater the N application at GS30 is, the higher the GPC and CM values are. CM values can help to estimate GPC values only when yields are below 8000 kg ha−1. Additionally, CM values at GS65 should be higher than 700 to achieve high-quality bread-making flour (12.5%) at such yield levels. These results will allow farmers and cooperatives to make better decisions regarding late-nitrogen fertilisation and wheat sales.},
DOI = {10.3390/plants10020374}
}



@Article{rs13040705,
AUTHOR = {Kopačková-Strnadová, Veronika and Koucká, Lucie and Jelének, Jan and Lhotáková, Zuzana and Oulehle, Filip},
TITLE = {Canopy Top, Height and Photosynthetic Pigment Estimation Using Parrot Sequoia Multispectral Imagery and the Unmanned Aerial Vehicle (UAV)},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {705},
URL = {https://www.mdpi.com/2072-4292/13/4/705},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing is one of the modern methods that have significantly developed over the last two decades and, nowadays, it provides a new means for forest monitoring. High spatial and temporal resolutions are demanded for the accurate and timely monitoring of forests. In this study, multi-spectral Unmanned Aerial Vehicle (UAV) images were used to estimate canopy parameters (definition of crown extent, top, and height, as well as photosynthetic pigment contents). The UAV images in Green, Red, Red-Edge, and Near infrared (NIR) bands were acquired by Parrot Sequoia camera over selected sites in two small catchments (Czech Republic) covered dominantly by Norway spruce monocultures. Individual tree extents, together with tree tops and heights, were derived from the Canopy Height Model (CHM). In addition, the following were tested: (i) to what extent can the linear relationship be established between selected vegetation indexes (Normalized Difference Vegetation Index (NDVI) and NDVIred edge) derived for individual trees and the corresponding ground truth (e.g., biochemically assessed needle photosynthetic pigment contents) and (ii) whether needle age selection as a ground truth and crown light conditions affect the validity of linear models. The results of the conducted statistical analysis show that the two vegetation indexes (NDVI and NDVIred edge) tested here have the potential to assess photosynthetic pigments in Norway spruce forests at a semi-quantitative level; however, the needle-age selection as a ground truth was revealed to be a very important factor. The only usable results were obtained for linear models when using the second year needle pigment contents as a ground truth. On the other hand, the illumination conditions of the crown proved to have very little effect on the model’s validity. No study was found to directly compare these results conducted on coniferous forest stands. This shows that there is a further need for studies dealing with a quantitative estimation of the biochemical variables of nature coniferous forests when employing spectral data that were acquired by the UAV platform at a very high spatial resolution.},
DOI = {10.3390/rs13040705}
}



@Article{s21041386,
AUTHOR = {Liu, Feng and Dai, Shuling and Zhao, Yongjia},
TITLE = {Learning to Have a Civil Aircraft Take Off under Crosswind Conditions by Reinforcement Learning with Multimodal Data and Preprocessing Data},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1386},
URL = {https://www.mdpi.com/1424-8220/21/4/1386},
PubMedID = {33669479},
ISSN = {1424-8220},
ABSTRACT = {Autopilot technology in the field of aviation has developed over many years. However, it is difficult for an autopilot system to autonomously operate a civil aircraft under bad weather conditions. In this paper, we present a reinforcement learning (RL) algorithm using multimodal data and preprocessing data to have a civil aircraft take off autonomously under crosswind conditions. The multimodal data include the common flight status and visual information. The preprocessing is a new design that maps some flight data by nonlinear functions based on the general flight dynamics before these data are fed into the RL model. Extensive experiments under different crosswind conditions with a professional flight simulator demonstrate that the proposed method can effectively control a civil aircraft to take off under various crosswind conditions and achieve better performance than trials without visual information or preprocessing data.},
DOI = {10.3390/s21041386}
}



@Article{rs13040733,
AUTHOR = {Gao, Bowen and Chen, Ninghua and Blaschke, Thomas and Wu, Chase Q. and Chen, Jianyu and Xu, Yaochen and Yang, Xiaoping and Du, Zhenhong},
TITLE = {Automated Characterization of Yardangs Using Deep Convolutional Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {733},
URL = {https://www.mdpi.com/2072-4292/13/4/733},
ISSN = {2072-4292},
ABSTRACT = {The morphological characteristics of yardangs are the direct evidence that reveals the wind and fluvial erosion for lacustrine sediments in arid areas. These features can be critical indicators in reconstructing local wind directions and environment conditions. Thus, the fast and accurate extraction of yardangs is key to studying their regional distribution and evolution process. However, the existing automated methods to characterize yardangs are of limited generalization that may only be feasible for specific types of yardangs in certain areas. Deep learning methods, which are superior in representation learning, provide potential solutions for mapping yardangs with complex and variable features. In this study, we apply Mask region-based convolutional neural networks (Mask R-CNN) to automatically delineate and classify yardangs using very high spatial resolution images from Google Earth. The yardang field in the Qaidam Basin, northwestern China is selected to conduct the experiments and the method yields mean average precisions of 0.869 and 0.671 for intersection of union (IoU) thresholds of 0.5 and 0.75, respectively. The manual validation results on images of additional study sites show an overall detection accuracy of 74%, while more than 90% of the detected yardangs can be correctly classified and delineated. We then conclude that Mask R-CNN is a robust model to characterize multi-scale yardangs of various types and allows for the research of the morphological and evolutionary aspects of aeolian landform.},
DOI = {10.3390/rs13040733}
}



@Article{jsan10010015,
AUTHOR = {Blekos, Kostas and Tsakas, Anastasios and Xouris, Christos and Evdokidis, Ioannis and Alexandropoulos, Dimitris and Alexakos, Christos and Katakis, Sofoklis and Makedonas, Andreas and Theoharatos, Christos and Lalos, Aris},
TITLE = {Analysis, Modeling and Multi-Spectral Sensing for the Predictive Management of Verticillium Wilt in Olive Groves},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {10},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {15},
URL = {https://www.mdpi.com/2224-2708/10/1/15},
ISSN = {2224-2708},
ABSTRACT = {The intensification and expansion in the cultivation of olives have contributed to the significant spread of Verticillium wilt, which is the most important fungal problem affecting olive trees. Recent studies confirm that practices such as the use of innovative natural minerals (Zeoshell ZF1) and the application of beneficial microorganisms (Micosat F BS WP) restore health in infected trees. However, for their efficient implementation the above methodologies require the marking of trees in the early stages of infestation—a task that is impractical with traditional means (manual labor) but also very difficult, as early stages are difficult to perceive with the naked eye. In this paper, we present the results of the My Olive Grove Coach (MyOGC) project, which used multispectral imaging from unmanned aerial vehicles to develop an olive grove monitoring system based on the autonomous and automatic processing of the multispectral images using computer vision and machine learning techniques. The goal of the system is to monitor and assess the health of olive groves, help in the prediction of Verticillium wilt spread and implement a decision support system that guides the farmer/agronomist.},
DOI = {10.3390/jsan10010015}
}



@Article{rs13040767,
AUTHOR = {Przewoźna, Patrycja and Hawryło, Paweł and Zięba-Kulawik, Karolina and Inglot, Adam and Mączka, Krzysztof and Wężyk, Piotr and Matczak, Piotr},
TITLE = {Use of Bi-Temporal ALS Point Clouds for Tree Removal Detection on Private Property in Racibórz, Poland},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {767},
URL = {https://www.mdpi.com/2072-4292/13/4/767},
ISSN = {2072-4292},
ABSTRACT = {Trees growing on private property have become an essential part of urban green policies. In many places, restrictions are imposed on tree removal on private property. However, monitoring compliance of these regulations appears difficult due to a lack of reference data and public administration capacity. We assessed the impact of the temporary suspension of mandatory permits on tree removal, which was in force in 2017 in Poland, on the change in urban tree cover (UTC) in the case of the municipality of Racibórz. The bi-temporal airborne laser scanning (ALS) point clouds (2011 and 2017) and administrative records on tree removal permits were used for analyzing the changes of UTC in the period of 2011–2017. The results show increased tree removal at a time when the mandatory permit was suspended. Moreover, it appeared that most trees on private properties were removed without obtaining permission when it was obligatory. The method based on LiDAR we proposed allows for monitoring green areas, including private properties.},
DOI = {10.3390/rs13040767}
}




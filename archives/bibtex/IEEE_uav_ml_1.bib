@INPROCEEDINGS{8625222,
author={Gómez-Avila, Javier and López-Franco, Carlos and Alanis, Alma Y. and Arana-Daniel, Nancy},
booktitle={2018 IEEE Latin American Conference on Computational Intelligence (LA-CCI)}, title={Control of Quadrotor using a Neural Network based PID},
year={2018},
volume={},
number={},
pages={1-6},
abstract={The control of Unmanned Aerial Vehicles (UAV) is an important task in mobile robotics because of its extensive use and the advantages over other kind of mobile robots like ground vehicles. In this paper, a PID controller for a quadrotor based on an Artificial Neural Network (ANN) is proposed. The neural network can handle the limitations of the PID when controlling complex non linear systems. The neural network consists in a single neuron with three inputs and their weights represent the gains of the PID (Kp, Ki and Kd). Simulations and experiments with a Quanser Qball-X4 are presented.},
keywords={Rotors;Biological neural networks;Cameras;Conferences;Computational intelligence;Trajectory;Quadrotor;PID controller;Artificial Neural Network},
doi={10.1109/LA-CCI.2018.8625222},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8787707,
author={Yang, Qingkai and Pan, Yunlong and Zhou, Bo and Fang, Hao},
booktitle={2019 34rd Youth Academic Annual Conference of Chinese Association of Automation (YAC)}, title={Planar formation control using tensegrity structures and experiments},
year={2019},
volume={},
number={},
pages={307-311},
abstract={This paper presents a framework on how to achieve prescribed planar formations using the concept of tensegrity structures. Given a group of robots with desired formation shape, we first design the underlying interaction topology based on the Polygon Theorem, yielding a super stable structure along with the robots' configuration. Then some basic control laws are introduced for mobile robots to model the interplay relationship between the neighbouring nodes in a self-equilibrated tensegrity structure. To fully validate the effectiveness of the tensegrity-motivated formation control strategy, we carry out not only numerical simulations but also experiments on two types of mobile robot platforms, wheeled mobile robots and unmanned aerial vehicles (UAVs).},
keywords={Production;Predictive models;Neural networks;Prediction algorithms;Training;Energy efficiency;Petrochemicals;formation control;distributed control;multiagent systems;tensegrity structure},
doi={10.1109/YAC.2019.8787707},
ISSN={},
month={June},}
@INPROCEEDINGS{9119685,
author={Xiang, Li and Xiaoqin, Liu and Qi, Shi},
booktitle={2020 IEEE 3rd International Conference on Electronics Technology (ICET)}, title={Dynamic Acceleration Compensation for Attitude and Heading Reference System Based on Recurrent Neural Network},
year={2020},
volume={},
number={},
pages={212-216},
abstract={Tri-axial magnetometer, accelerometer, as well as gyroscope are commonly used in attitude and heading reference systems (AHRS) to provide three dimensional attitude information for unmanned aerial vehicles (UAV) and other carriers. But the attitude algorithms for AHRS are vulnerable to the external acceleration. To solve this problem, a novel attitude algorithm based on recurrent neural network (RNN) is introduced. Compared to the existing methods, the proposed algorithm shows better robustness against the external acceleration in the experiment on AHRS, and can ensure dynamic attitude accuracy.},
keywords={Recurrent neural networks;Three-dimensional displays;Magnetometers;Heuristic algorithms;Conferences;Estimation;Autonomous aerial vehicles;attitude estimation;magnetometer;accelerometer;external acceleration;recurrent neural network},
doi={10.1109/ICET49382.2020.9119685},
ISSN={},
month={May},}
@ARTICLE{8812718,
author={Liu, An-An and Xiang, Shu and Nie, Wei-Zhi and Song, Dan},
journal={IEEE Access}, title={End-to-End Visual Domain Adaptation Network for Cross-Domain 3D CPS Data Retrieval},
year={2019},
volume={7},
number={},
pages={118630-118638},
abstract={3D CPS (Cyber Physical System) data has been widely generated and utilized for multiple applications, e.g. autonomous driving, unmanned aerial vehicle and so on. For large-scale 3D CPS data analysis, 3D object retrieval plays a significant role for urban perception. In this paper, we propose an end-to-end domain adaptation framework for cross-domain 3D objects retrieval (C3DOR-Net), which learns a joint embedding space for 3D objects from different domains in an end-to-end manner. Specifically, we focus on the unsupervised case when 3D objects in the target domain are unlabeled. To better encode a 3D object, the proposed method learns multi-view visual features in a data-driven manner for 3D object representation. Then, the domain adaptation strategy is implemented to benefit both domain alignment and final classification. Specifically, an center-based discriminative feature learning method enables the domain invariant features with better intra-class compactness and inter-class separability. C3DOR-Net can achieve remarkable retrieval performances by maximizing the inter-class divergence and minimizing the intra-class divergence. We evaluate our method on two cross-domain protocols: 1) CAD-to-CAD object retrieval on two popular 3D datasets (NTU and PSB) in three designed cross-domain scenarios; 2) SHREC'19 monocular image based 3D object retrieval. Experimental results demonstrate that our method can significantly boost the cross-domain retrieval performances.},
keywords={Three-dimensional displays;Solid modeling;Visualization;Feature extraction;Two dimensional displays;Deep learning;Licenses;3D object retrieval;cross-domain learning;unsupervised domain adaptation},
doi={10.1109/ACCESS.2019.2937377},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7051621,
author={Blondel, Paul and Potelle, Alex and Pégard, Claude and Lozano, Rogelio},
booktitle={2014 IEEE Visual Communications and Image Processing Conference}, title={Fast and viewpoint robust human detection in uncluttered environments},
year={2014},
volume={},
number={},
pages={522-525},
abstract={Human detection is a very popular field of computer vision. Few works propose a solution for detecting people whatever the camera's viewpoint such as for UAV applications. In this context even state-of-the-art detectors can fail to detect people. We found that the Integral Channel Features detector (ICF) is inoperant in such a context. In this paper, we propose an approach to still benefit from the assets of the ICF while considerably extending the angular robustness during the detection. The main contributions of this work are: a new framework based on the Cluster Boosting Tree and the ICF detector for viewpoint robust human detection; a new training dataset for taking into account the human shape modifications occuring when the pitch angle of the camera changes. We showed that our detector (the PRD) is superior to the ICF for detecting people from complex viewpoints in uncluttered environments and that the computation time of the detector is real-time compatible.},
keywords={Detectors;Training;Robustness;Cameras;Feature extraction;Shape;Visualization;human detection;machine learning;multi-viewpoint;viewpoint robust;supervised training},
doi={10.1109/VCIP.2014.7051621},
ISSN={},
month={Dec},}
@ARTICLE{9440901,
author={Ng, Hoi-Fung and Zhang, Guohao and Hsu, Li-Ta},
journal={IEEE Sensors Journal}, title={Robust GNSS Shadow Matching for Smartphones in Urban Canyons},
year={2021},
volume={21},
number={16},
pages={18307-18317},
abstract={GNSS is being widely used in different applications in navigation. However, GNSS positioning is greatly challenged by notorious multipath effects and non-line-of-sight (NLOS) receptions. The signal blockage and reflection by buildings cause these effects. In other words, the more urbanized the city is, the more challenge on the GNSS positioning. The conventional multipath mitigation approaches, such as the sophisticated design of GNSS receiver correlator, can efficiently mitigate the most of multipath effects. However, it has less capability against NLOS reception, potentially leading to several tens of positioning errors. Therefore, the 3D mapping aided (3DMA) GNSS positioning is introduced to exclude or even use the NLOS signal. Shadow matching is to make use of the similarity between building geometry and satellite visibility to improve the positioning performance. This paper introduces a machine learning intelligent classifier with features to distinguish LOS and NLOS. With the NLOS reception classification, the positioning accuracy of shadow matching can be increased. In addition, this paper develops several indicators to label the unreliable solution of shadow matching. These indicators are to examine the complexity of the surrounding environment, which is the key factor relating to the proposed shadow matching performance. Several designed experiments were done in Hong Kong to evaluate the proposed method. With the intelligent classifier, the average positioning accuracy is about 15m and 6m on 2D and the across-street direction, respectively. Simultaneously, the reliability evaluation rules can exclude unreliable epoch and improve the positioning results, especially on smartphone data.},
keywords={Satellites;Buildings;Global navigation satellite system;Three-dimensional displays;Solid modeling;Reliability;Urban areas;GNSS;navigation;smartphone;3D building model;urban canyons;multipath and NLOS},
doi={10.1109/JSEN.2021.3083801},
ISSN={1558-1748},
month={Aug},}
@ARTICLE{8684798,
author={Jian, Lihua and Li, Zhen and Yang, Xiaomin and Wu, Wei and Ahmad, Awais and Jeon, Gwanggil},
journal={IEEE Consumer Electronics Magazine}, title={Combining Unmanned Aerial Vehicles With Artificial-Intelligence Technology for Traffic-Congestion Recognition: Electronic Eyes in the Skies to Spot Clogged Roads},
year={2019},
volume={8},
number={3},
pages={81-86},
abstract={Unmanned aerial vehicles (UAVs) are gradually becoming useful and common. In the consumer electronics (CE) category, unmanned systems have changed the way monitoring by air is conducted in such fields as transportation, the environment, and emergency rescue. This article examines how UAVs combined with artificial-intelligence (AI) technology are used for recognizing traffic congestion. Congested roadways cause traffic delays, which wastes fuel, adds to pollution, and invites road rage. Society can benefit from technologies that help recognize and relieve traffic congestion. We present a practical framework for using UAVs to recognize traffic problems. According to this framework, images of traffic scenes are first captured by a UAV system based on route-planning technology. Then the aerial images are further processed by using convolutional neural networks (CNNs). Finally, the output is transferred to a traffic management center.},
keywords={Feature extraction;Monitoring;Unmanned aerial vehicles;Cameras;Consumer electronics;Traffic congestion;Image recognition},
doi={10.1109/MCE.2019.2892286},
ISSN={2162-2256},
month={May},}
@INPROCEEDINGS{9658653,
author={Distefano, Joseph P. and Manjunatha, Hemanth and Chowdhury, Souma and Dantu, Karthik and Doermann, David and Esfahani, Ehsan T.},
booktitle={2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, title={Using Physiological Information to Classify Task Difficulty in Human-Swarm Interaction},
year={2021},
volume={},
number={},
pages={1198-1203},
abstract={Human-swarm interaction has recently gained attention due to its plethora of new applications in disaster relief, surveillance, rescue, and exploration. However, if the task difficulty increases, the performance of the human operator decreases, thereby decreasing the overall efficacy of the human-swarm team. Thus, it is critical to identify the task difficulty and adaptively allocate the task to the human operator to maintain optimal performance. In this direction, we study the classification of task difficulty in a human-swarm interaction experiment performing a target search mission. The human may control platoons of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) to search a partially observable environment during the target search mission. The mission complexity is increased by introducing adversarial teams that humans may only see when the environment is explored. While the human is completing the mission, their brain activity is recorded using an electroencephalogram (EEG), which is used to classify the task difficulty. We have used two different approaches for classification: A feature-based approach using coherence values as input and a deep learning-based approach using raw EEG as input. Both approaches can classify the task difficulty well above the chance. The results showed the importance of the occipital lobe (O1 and O2) coherence feature with the other brain regions. Moreover, we also study individual differences (expert vs. novice) in the classification results. The analysis revealed that the temporal lobe in experts (T4 and T3) is predominant for task difficulty classification compared with novices.},
keywords={Deep learning;Support vector machines;Temporal lobe;Visualization;Coherence;Feature extraction;Electroencephalography},
doi={10.1109/SMC52423.2021.9658653},
ISSN={2577-1655},
month={Oct},}
@ARTICLE{8949363,
author={Chen, Steven W. and Nardari, Guilherme V. and Lee, Elijah S. and Qu, Chao and Liu, Xu and Romero, Roseli Ap. Francelin and Kumar, Vijay},
journal={IEEE Robotics and Automation Letters}, title={SLOAM: Semantic Lidar Odometry and Mapping for Forest Inventory},
year={2020},
volume={5},
number={2},
pages={612-619},
abstract={This letter describes an end-to-end pipeline for tree diameter estimation based on semantic segmentation and lidar odometry and mapping. Accurate mapping of this type of environment is challenging since the ground and the trees are surrounded by leaves, thorns and vines, and the sensor typically experiences extreme motion. We propose a semantic feature based pose optimization that simultaneously refines the tree models while estimating the robot pose. The pipeline utilizes a custom virtual reality tool for labeling 3D scans that is used to train a semantic segmentation network. The masked point cloud is used to compute a trellis graph that identifies individual instances and extracts relevant features that are used by the SLAM module. We show that traditional lidar and image based methods fail in the forest environment on both Unmanned Aerial Vehicle (UAV) and hand-carry systems, while our method is more robust, scalable, and automatically generates tree diameter estimations.},
keywords={Laser radar;Vegetation;Forestry;Semantics;Three-dimensional displays;Estimation;Unmanned aerial vehicles;Robotics in agriculture and forestry;SLAM;deep learning in robotics and automation;virtual reality and interfaces},
doi={10.1109/LRA.2019.2963823},
ISSN={2377-3766},
month={April},}
@INPROCEEDINGS{8324593,
author={Yang, Liang and Li, Bing and Li, Wei and Liu, Zhaoming and Yang, Guoyong and Xiao, Jizhong},
booktitle={2017 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, title={A robotic system towards concrete structure spalling and crack database},
year={2017},
volume={},
number={},
pages={1276-1281},
abstract={Concrete spalling and crack inspection is a labor intensive and routine task. However, it plays an important role in structure health monitoring (SHM) of civil infrastructures. Autonomous inspection with robots has been regarded as one of the best ways to reduce both error and cost. This paper presents an automated approach using Unmanned Aerial Vehicle(UAV) and towards a Concrete Structure Spalling and Crack database (CSSC), which is by far the first released database for deep learning inspection. We aim locate the spalling and crack regions to assist 3D registration and visualization. For deep inspection, we provide a complete procedure of data searching, labeling, training, and post processing. We further present a visual Simultaneously Localization and Mapping(SLAM) approach for localization and reconstruction. Comparative experiments and field tests are illustrated, results show that we can achieve an accuracy over 70% for field tests, and more than 93% accuracy with CSSC database.},
keywords={Inspection;Databases;Concrete;Training;Three-dimensional displays;Labeling;Robots},
doi={10.1109/ROBIO.2017.8324593},
ISSN={},
month={Dec},}
@ARTICLE{9615105,
author={Zhang, Ke and Si, Dingxin and Wang, Wei and Cao, Jiayu and Zhang, Yan},
journal={IEEE Wireless Communications}, title={Transfer Learning for Distributed Intelligence in Aerial Edge Networks},
year={2021},
volume={28},
number={5},
pages={74-81},
abstract={Unmanned aerial vehicle (UAV)-enabled edge computing is a promising paradigm to provide task offloading service for computation-intensive applications. Catering for highly dynamic edge networks, learning agents are placed on the UAVs to perceive environmental changes and adjust edge service strategies. These multiple agents build distributed intelligence in edge service scheduling. However, the agents, which independently learn service strategies from scratch, always cost high computing resources, cause extra delays, and bring a critical challenge to UAVs' service efficiency. To address this challenge, we propose a transfer learning empowered aerial edge network (AEN), which uses multi-agent machine learning to draw optimal service strategies, while leveraging transfer learning to share and reuse knowledge between the UAVs for saving resource costs and reducing training latency. Furthermore, we develop efficient transfer learning schemes where the edge resources are optimally scheduled for knowledge sharing and task offloading. Numerical results indicate that the proposed schemes maximize edge service utility while significantly improving machine learning efficiency.},
keywords={Knowledge engineering;Training;Costs;Processor scheduling;Transfer learning;Learning (artificial intelligence);Unmanned aerial vehicles},
doi={10.1109/MWC.011.2100061},
ISSN={1558-0687},
month={October},}
@INPROCEEDINGS{9658603,
author={Li, Tianqi and Krakow, Lucas W. and Gopalswamy, Swaminathan},
booktitle={2021 IEEE Conference on Control Technology and Applications (CCTA)}, title={Optimizing Consensus-based Multi-target Tracking with Multiagent Rollout Control Policies},
year={2021},
volume={},
number={},
pages={131-137},
abstract={This paper considers a multiagent, connected, robotic fleet where the primary functionality of the agents is sensing. A distributed multi-sensor control strategy maximizes the value of the collective sensing capability of the fleet, using an information-driven approach. Each agent individually performs sensor processing (Kalman Filtering and Joint Probabilistic Data Association) to identify trajectories (and associated distributions). Using communication with neighbors, the agent enhances the prediction of the trajectories by a Consensus of Information approach that iteratively calculates the Kullback-Leibler average of trajectory distributions, which enables the calculation of the collective information for the fleet. The dynamics of the agents, the evolution of the identified trajectories for each agent, and the dynamics of individual observed objects are captured as a Partially Observable Markov Decision Process (POMDP). Using this POMDP and applying rollout with receding horizon control, an optimized non-myopic control policy that maximizes the collective fleet information value is synthesized. Simulations are presented for a scenario with three heterogeneous UAVs performing coordinated target tracking that illustrate the proposed methodology and compare the centralized approach with a contemporary sequential multiagent distributed decision technique.},
keywords={Measurement;Target tracking;Terminology;Veins;Robot kinematics;Reinforcement learning;Robot sensing systems;multiagent rollout;target tracking;multisensor system;information-driven;POMDP},
doi={10.1109/CCTA48906.2021.9658603},
ISSN={2768-0770},
month={Aug},}
@ARTICLE{9072517,
author={Dahmane, Mohamed and Alam, Jahangir and St-Charles, Pierre-Luc and Lalonde, Marc and Heffner, Kevin and Foucher, Samuel},
journal={IEEE Transactions on Affective Computing}, title={A Multimodal Non-Intrusive Stress Monitoring from the Pleasure-Arousal Emotional Dimensions},
year={2020},
volume={},
number={},
pages={1-1},
abstract={With the increasing development of advanced unmanned aerial vehicles (UAVs), communication between operators and these intelligent systems is becoming more stressful. For the safety of UAV flights, automatic psychological stress detection is becoming a key research topic for successful missions. Stress can be reliably estimated via some biological markers which are not appropriate in many cases of human-machine-interaction setups. In this paper, we propose a non-intrusive deep learning-based stress level estimation approach. The goal is to identify the region where the operator's emotional state projects in the space defined by the latent dimensional emotions of arousal and valence since the stress region is well delimited in this space. The proposed multimodal approach uses sequential temporal CNN and LSTM with an Attention Weighted Average layer in the vision modality. As a second modality, we investigate local and global descriptors such as Mel-frequency cepstral coefficients, i-vector embeddings as well as Fisher-vector encodings. The multimodal-fusion approach uses a strategy referred to as "late-fusion" that involves the combination of unimodal model outputs as inputs of the decision engine. Since we have to deal with more naturalistic behavior in operator-machine interaction contexts, the One minute Gradual Emotion Challenge dataset was used for predictive model validation.},
keywords={Stress;Feature extraction;Unmanned aerial vehicles;Psychology;Visualization;Monitoring;Face;Operator state monitoring;emotion analysis;continuous emotions;stress monitoring;face analysis;deep learning;feature representation},
doi={10.1109/TAFFC.2020.2988455},
ISSN={1949-3045},
month={},}
@ARTICLE{9020017,
author={Li, Youyou and Melgani, Farid and He, Binbin},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={CSVM Architectures for Pixel-Wise Object Detection in High-Resolution Remote Sensing Images},
year={2020},
volume={58},
number={9},
pages={6059-6070},
abstract={Detecting objects becomes an increasingly important task in very high resolution (VHR) remote sensing imagery analysis. With the development of GPU-computing capability, a growing number of deep convolutional neural networks (CNNs) have been designed to address the object detection challenge. However, compared with CPU, GPU is much more costly. Therefore, GPU-based methods are less attractive in practical applications. In this article, we propose a CPU-based method that is based on convolutional support vector machines (CSVMs) to address the object detection challenge in VHR images. Experiments are conducted on three VHR and two unmanned aerial vehicle (UAV) data sets with very limited training data. Results show that the proposed CSVM achieves competitive performance compared to U-Net which is an efficient CNN-based model designed for small training data sets.},
keywords={Object detection;Convolution;Remote sensing;Feature extraction;Training;Image resolution;Support vector machines;Convolutional neural network (CNN);convolutional support vector machine (CSVM);object detection;remote sensing;very high resolution (VHR)},
doi={10.1109/TGRS.2020.2972289},
ISSN={1558-0644},
month={Sep.},}
@INPROCEEDINGS{5979706,
author={Guizilini, Vitor and Ramos, Fabio},
booktitle={2011 IEEE International Conference on Robotics and Automation}, title={Visual odometry learning for unmanned aerial vehicles},
year={2011},
volume={},
number={},
pages={6213-6220},
abstract={This paper addresses the problem of using visual information to estimate vehicle motion (a.k.a. visual odometry) from a machine learning perspective. The vast majority of current visual odometry algorithms are heavily based on geometry, using a calibrated camera model to recover relative translation (up to scale) and rotation by tracking image features over time. Our method eliminates the need for a parametric model by jointly learning how image structure and vehicle dynamics affect camera motion. This is achieved with a Gaussian Process extension, called Coupled GP, which is trained in a supervised manner to infer the underlying function mapping optical flow to relative translation and rotation. Matched image features parameters are used as inputs and linear and angular velocities are the outputs in our non-linear multi-task regression problem. We show here that it is possible, using a single uncalibrated camera and establishing a first-order temporal dependency between frames, to jointly estimate not only a full 6 DoF motion (along with a full covariance matrix) but also relative scale, a non-trivial problem in monocular configurations. Experiments were performed with imagery collected with an unmanned aerial vehicle (UAV) flying over a deserted area at speeds of 100-120 km/h and altitudes of 80-100 m, a scenario that constitutes a challenge for traditional visual odometry estimators.},
keywords={Visualization;Training;Cameras;Covariance matrix;Vehicles;Optical sensors},
doi={10.1109/ICRA.2011.5979706},
ISSN={1050-4729},
month={May},}
@INPROCEEDINGS{7759731,
author={Grabe, Volker and Nuske, Stephen T.},
booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Long distance visual ground-based signaling for unmanned aerial vehicles},
year={2016},
volume={},
number={},
pages={4976-4983},
abstract={We present a long-range visual signal detection system that is suitable for an unmanned aerial vehicle to find an optical signal released at a desired landing site for the purposes of cargo delivery or rescue situations where radio signals or other communication systems are not available or the wind conditions at the landing site need to be signaled. The challenge here is to have a signal and detection system that works from long range (> 1000m) amongst ground clutter during various seasonal conditions on passive imagery. We use a smoke-grenade as a ground signal, which has the advantageous properties of being easy to carry by ground crews because of its light weight and small size, but when released has a long visual signaling range. We employ a camera system on the UAV with a visual texture feature extraction approach in a machine learning framework to classify image patches as `signal' or `background'. We study conventional approaches and develop a visual feature descriptor that can better differentiate the appearance of the visual signal under varying conditions and, when used to train a random-forest classifier, outperforms commonly used feature descriptors. The system was rigorously and quantitatively evaluated on data collected from a camera mounted on a helicopter and flown towards a plume of signal smoke over a variety of seasons, ground conditions, weather conditions, and environments. Our system was capable of detecting the smoke cloud with both precision and recall rates greater than 0.95 from ranges between 1000m and 1500m. Further, we develop a method to estimate wind orientation and approximate wind strength by assessing the shape of the smoke signal. We present a preliminary evaluation of the wind estimation in conditions with different wind intensities and orientations relative to the approach direction.},
keywords={Visualization;Helicopters;Image segmentation;Cameras;Image color analysis;Feature extraction;Histograms},
doi={10.1109/IROS.2016.7759731},
ISSN={2153-0866},
month={Oct},}
@INPROCEEDINGS{9671314,
author={Safavi, Farshad and Chowdhury, Tashnim and Rahnemoonfar, Maryam},
booktitle={2021 IEEE International Conference on Big Data (Big Data)}, title={Comparative Study Between Real-Time and Non-Real-Time Segmentation Models on Flooding Events},
year={2021},
volume={},
number={},
pages={4199-4207},
abstract={Scene understanding of aerial imagery is essential for proper emergency response during catastrophic events such as hurricanes, earthquakes, and floods. Unmanned Aerial Vehicles (UAVs) capture aerial images and analyze the context by passing images into a semantic segmentation model for monitoring damaged areas. However, the state-of-the-art semantic segmentation models are mainly trained and evaluated on ground-based datasets such as Cityscapes, MS-COCO, and CamVid, unsuitable for aerial image segmentations. For example, extracted features from objects in aerial perspective are distinct from objects on the ground view. Hence, neural networks cannot properly segment an aerial scene, especially on deformed or damaged objects during disasters. This research analyzes current semantic segmentation models to explore the feasibility of applying these models for emergency response during catastrophic events. We compare the performance of real-time semantic segmentation models with non-real-time counterparts constrained by aerial images under adversarial settings. Furthermore, we train several models on the FloodNet dataset, containing UAV images captured after Hurricane Harvey, and benchmark their execution on special classes such as flooded-buildings vs. non-flooded buildings or flooded-roads vs. non-flooded roads. In this research, real-time UNet-MobileNetV3 yields 59.3% test mIoU while non-real-time PSPNet [1] attains 79.7% test mIoU on the FloodNet, demonstrating the trade-off between accuracy and efficiency in the segmentation models.},
keywords={Image segmentation;Analytical models;Semantics;Big Data;Emergency services;Autonomous aerial vehicles;Feature extraction;Computer Vision;Deep Learning;Convolutional Neural Network(CNN);Aerial Image Segmentation;Real-Time Semantic Segmentation},
doi={10.1109/BigData52589.2021.9671314},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7500873,
author={Nakamura, Takuma and Haviland, Stephen and Bershadsky, Dmitry and Magree, Daniel and Johnson, Eric N.},
booktitle={2016 IEEE Aerospace Conference}, title={Vision-based closed-loop tracking using micro air vehicles},
year={2016},
volume={},
number={},
pages={1-12},
abstract={This paper describes the target detection and tracking architecture used by the Georgia Tech Aerial Robotics team for the American Helicopter Society (AHS) Micro Aerial Vehicle (MAV) challenge. The vision system described enables vision-aided navigation with additional abilities such as target detection and tracking all performed onboard the vehicles computer. The author suggests a robust target tracking method that does not solely depend on the image obtained from a camera, but also utilizes the other sensor outputs and runs a target location estimator. The machine learning based target identification method uses Haar-like classifiers to extract the target candidate points. The raw measurements are plugged into multiple Extended Kalman Filters (EKFs). The statistical test (Z-test) is used to bound the measurement, and solve the corresponding problem. Using Multiple EKFs allows us not only to optimally estimate the target location, but also to use the information as one of the criteria to evaluate the tracking performance. The MAV utilizes performance-based criteria that determine whether or not to initiate a maneuver such as hover or land over/on the target. The performance criteria are closed in the loop which allows the system to determine at any time whether or not to continue with the maneuver. For Vision-aided Inertial Navigation System (VINS), a corner Harris algorithm finds the feature points, and we track them using the statistical knowledge. The feature point locations are integrated in Bierman Thornton extended Kalman Filter (BTEKF) with Inertial Measurement Unit (IMU) and sonar sensor outputs to generate vehicle states: position, velocity, attitude, accelerometer and gyroscope biases. A 6-degrees-of-freedom quadrotor flight simulator is developed to test the suggested method. This paper provides the simulation results of the vision-based maneuvers: hovering over the target, and landing on the target. In addition to the simulation results, flight tests have been conducted to show and validate the system performance. The 500 gram Georgia Tech Quadrotor (GtQ)-Mini, was used for the flight tests. All processing is done onboard the vehicle and it is able to operate without human interaction. Both of the simulation and flight test results show the effectiveness of the suggested method. This system and vehicle were used for the AHS 2015 MAV Student Challenge where the GPS-denied closed-loop target search is required. The vehicle successfully found the ground target, and landed on the desired location. This paper shares the data obtained from the competition.},
keywords={Vehicles;Cameras;Target tracking;Feature extraction;Detectors;Object detection;Simulation},
doi={10.1109/AERO.2016.7500873},
ISSN={},
month={March},}
@ARTICLE{8119717,
author={Genc, Hasan and Zu, Yazhou and Chin, Ting-Wu and Halpern, Matthew and Reddi, Vijay Janapa},
journal={IEEE Micro}, title={Flying IoT: Toward Low-Power Vision in the Sky},
year={2017},
volume={37},
number={6},
pages={40-51},
abstract={The Internet of Things (IoT) is rapidly enabling applications in many different fields by embedding itself into the physical world. Many potential IoT devices require some level of machine learning or cognitive capability to be truly effective, but the high computational complexity of cognitive algorithms makes them unsuitable for low-power IoT processors. To understand the design challenges of cognitive IoT devices, the authors study a cognitive drone application in a design space called Flying IoT. They find that the computing capability provided by typical drone processors falls far short of satisfying the real-time performance requirements of their application. To improve their processor's performance on the edge while maintaining its low power consumption and small form factor, the authors propose a sensor-cloud architecture in which data collection is done at the edge and data processing is offloaded to the cloud. Their sensor-cloud architecture can process complex convolution neural network models nearly in real time with software optimizations such as downsampling and compression, while consuming less power than state-of-the art embedded processors such as the Jetson TX1.},
keywords={Drones;Performance evaluation;Real-time systems;Object detection;Graphics processing units;Internet of Things;drone;object detection;real time;low power;sensor-cloud},
doi={10.1109/MM.2017.4241339},
ISSN={1937-4143},
month={November},}
@ARTICLE{8853333,
author={Lu, Xiankai and Ma, Chao and Ni, Bingbing and Yang, Xiaokang},
journal={IEEE Transactions on Circuits and Systems for Video Technology}, title={Adaptive Region Proposal With Channel Regularization for Robust Object Tracking},
year={2021},
volume={31},
number={4},
pages={1268-1282},
abstract={In this paper, we propose an adaptive region proposal scheme with feature channel regularization to facilitate robust object tracking. We consider tracking as a linear regression problem and an ensemble of correlation filters is trained on-line to distinguish the foreground target from the background. Further, we integrate adaptively learned region proposals into an enhanced two-stream tracking framework based on correlation filters. For the tracking stream, we learn two-stage cascade correlation filters on deep convolutional features to ensure competitive tracking performance. For the detection stream, we employ adaptive region proposals, which are effective in recovering target objects from tracking failures caused by heavy occlusion or out-of-view movement. In contrast to traditional tracking-by-detection methods using random samples or sliding windows, we perform target re-detection over adaptively learned region proposals. Since region proposals naturally take the objectness information into account, we show that the proposed adaptive region proposals can handle the challenging scale estimation problem as well. In addition, we observe the channel redundancy and noisy of feature representation, especially for the convolutional features. Thus, we apply a channel regularization to the correlation filter learning. Extensive experimental validations on OTB, VOT and UAV-123 datasets demonstrate that the proposed method performs favorably against state-of-the-art tracking algorithms.},
keywords={Target tracking;Correlation;Proposals;Visualization;Estimation;Object tracking;Adaptive region proposals;channel regularization;correlation filters;robust object tracking},
doi={10.1109/TCSVT.2019.2944654},
ISSN={1558-2205},
month={April},}
@INPROCEEDINGS{9670517,
author={Panigrahy, Satyajit and Karmakar, Subrata and Sahoo, Rakesh},
booktitle={2021 IEEE 5th International Conference on Condition Assessment Techniques in Electrical Systems (CATCON)}, title={Transfer Learning based Condition Assessment of High Voltage Insulator: A Comparative Analysis},
year={2021},
volume={},
number={},
pages={145-150},
abstract={Routine inspection of a power line insulator system for early problem detection and maintenance is required for the effective transmission of electrical power to customers. Unlike the traditional manual inspection methods such as foot patrol, helicopter assisted methods, flying and climbing robots are time consuming, dangerous, labor intensive, and expensive. This work primarily focused on the insulator image classification of the Chinese Power Line Insulator Dataset (CPLID). Convolutional Neural Network (CNN) and pre-trained neural networks with different optimizers like Adam, Adamax, Adagrad, Adadelta, Nadam, Ftrl, and RMSprop were used to find out the best combination of CNN and pre-trained neural network with the optimizer to provide robust performance and higher accuracy. Finally, CNN with Adamax optimizer provided overall accuracy of 95.27% and the pre-trained CNN Densenet 201 with Adam optimizer gave overall accuracy of 100%. In the automated inspection of transmission line insulators, the deployment of UAVs and deep learning algorithms can be a useful starting point for many researchers throughout the world.},
keywords={Power transmission lines;Neural networks;Transfer learning;Manuals;Inspection;Maintenance engineering;Insulators;Polymeric Insulator;Image Classification;Convolutional Neural Network (CNN);Transfer Learning},
doi={10.1109/CATCON52335.2021.9670517},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8430922,
author={Elnaggar, Mahmoud and Bezzo, Nicola},
booktitle={2018 Annual American Control Conference (ACC)}, title={An IRL Approach for Cyber-Physical Attack Intention Prediction and Recovery},
year={2018},
volume={},
number={},
pages={222-227},
abstract={Modern autonomous cyber-physical systems have been demonstrated to be vulnerable to cyber-attacks like sensor spoofing in which an attacker stealthily compromises sensor readings to hijack the system toward undesired and possibly hazardous states. The majority of security techniques developed today are, however, reactive and concerned with detection and interdiction of attacks without considering predicting the intention of the attack. To deal with such problem, we propose a Bayesian Inverse Reinforcement Learning technique that leverages the history of sensor data and control inputs to predict the goal of sensor spoofing attacks, determine which sensors are compromised, and recover the system. We also propose an active exploration framework to improve the convergence rate of the intention inference before reaching undesired states. The proposed approach is validated with simulation results on a quadrotor unmanned aerial vehicle navigation case study.},
keywords={Robot sensing systems;Learning (artificial intelligence);Unmanned aerial vehicles;Bayes methods;Global Positioning System;Task analysis},
doi={10.23919/ACC.2018.8430922},
ISSN={2378-5861},
month={June},}
@ARTICLE{9485123,
author={Dai, Zhiyong and Yi, Jianjun and Zhang, Hanmo and Wang, Danwei and Huang, Xiaoci and Ma, Chao},
journal={IEEE Geoscience and Remote Sensing Letters}, title={CODNet: A Center and Orientation Detection Network for Power Line Following Navigation},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={Recently, intelligent unmanned aerial vehicles (UAVs) have shown great advantages of flexibility and productivity in power line inspection, wherein robust detection of power lines from aerial images for automatic power line following navigation is required. However, identifying power lines accurately from a cluttered background is challenging due to the limited resolution of onboard cameras and the noisy environment. In this letter, we propose a novel power line detection method, denoted by CODNet, for the application of UAV navigation. Unlike existing works, the proposed method can extract features of power lines from cluttered backgrounds automatically and predict centers and orientations of power lines in the scene simultaneously. Besides, we introduce a new clustering method to summarize the average location and orientation of detected power lines as a guide for the automatic navigation of UAVs. Finally, experimental results demonstrate both the effectiveness and the superiority of the CODNet.},
keywords={Navigation;Feature extraction;Kernel;Inspection;Unmanned aerial vehicles;Heating systems;Image edge detection;Convolutional neural networks;power line detection},
doi={10.1109/LGRS.2021.3092399},
ISSN={1558-0571},
month={},}
@ARTICLE{9171419,
author={Cubuktepe, Murat and Jansen, Nils and Alshiekh, Mohammed and Topcu, Ufuk},
journal={IEEE Transactions on Automatic Control}, title={Synthesis of Provably Correct Autonomy Protocols for Shared Control},
year={2021},
volume={66},
number={7},
pages={3251-3258},
abstract={We synthesize shared control protocols subject to probabilistic temporal logic specifications. Specifically, we develop a framework in which a human and an autonomy protocol can issue commands to carry out a certain task. We blend these commands into a joint input to a robot. We model the interaction between the human and the robot as a Markov decision process representing the shared control scenario. Using inverse reinforcement learning, we obtain an abstraction of the human's behavior. We use randomized strategies to account for randomness in human's decisions, caused by factors such as the complexity of the task specifications or imperfect interfaces. We design the autonomy protocol to ensure that the resulting robot behavior satisfies given safety and performance specifications in probabilistic temporal logic. Additionally, the resulting strategies generate behavior as similar to the behavior induced by the human's commands as possible. We solve the underlying problem efficiently using quasiconvex programming. Case studies involving autonomous wheelchair navigation and unmanned aerial vehicle mission planning showcase the applicability of our approach.},
keywords={Protocols;Task analysis;Wheelchairs;Markov processes;Probabilistic logic;Mobile robots;Human-robot interaction;Markov processes;optimization;robotics},
doi={10.1109/TAC.2020.3018029},
ISSN={1558-2523},
month={July},}
@INPROCEEDINGS{6735236,
author={Straub, Jeremy and Kim, Eunjin},
booktitle={2013 IEEE 25th International Conference on Tools with Artificial Intelligence}, title={Characterization of Extended and Simplified Intelligent Water Drop (SIWD) Approaches and Their Comparison to the Intelligent Water Drop (IWD) Approach},
year={2013},
volume={},
number={},
pages={101-107},
abstract={This paper presents a simplified approach to performing the Intelligent Water Drops (IWD) process. This approach is designed to be comparatively lightweight while approximating the results of the full IWD process. The Simplified Intelligent Water Drops (SIWD) approach is specifically designed for applications where IWD must be run in a computationally limited environment (such as on a robot, UAV or small spacecraft) or where performance speed must be maximized for time sensitive applications. The SWID approach is described and compared and contracted to the base IWD approach.},
keywords={Sediments;Equations;Mathematical model;Soil;Space vehicles;Robots;Decision making;Intelligent Water Drop;Swarm Intelligence;AI Decision Making},
doi={10.1109/ICTAI.2013.25},
ISSN={2375-0197},
month={Nov},}
@INPROCEEDINGS{9648399,
author={Agarwal, Akshay and Ratha, Nalini and Vatsa, Mayank and Singh, Richa},
booktitle={2021 IEEE International Workshop on Information Forensics and Security (WIFS)}, title={Impact of Super-Resolution and Human Identification in Drone Surveillance},
year={2021},
volume={},
number={},
pages={1-6},
abstract={In the scene of large crowd gatherings and challenging visiting places such as rough hills and high glass buildings, acquisition of the images through normal cameras is difficult and next to impossible. In all such scenarios, the drone becomes a useful acquisition sensor to capture the detailed information of the scene and the objects present there. With the rapid development of consumer unmanned aerial vehicles (UAV) or drones, the utilization of these devices became extremely easy. The popular use-case of the drones can be seen for the surveillance to identify any possible threats in the large crowd gathering and recognize the different individuals present in the crowd. However, the images captured using the drones are generally taken from a significant distance to avoid any collision; hence these images generally suffer in quality such as low resolution, motion blur, and other environmental factors. The impact of these artifacts has been seen in the face recognition performance using several machine learning algorithms on large-scale drone databases namely Drone SURF. In this research, we intend to tackle the above artifacts by looking at the problem from the perspective of super-resolution of low-quality images. We have studied state-of-the-art (SOTA) super-resolution algorithms and see whether current methods are capable of handling the challenges of drone images. Apart from that, we have also evaluated another SOTA deep network developed for object detection for human segmentation in drone images. The proposed research provides interesting findings highlighting the limitations of existing works from the perspective of handling drone images. We would like the readers to go through the paper to find out the current limitations and possible future directions in drone image surveillance.},
keywords={Machine learning algorithms;Face recognition;Surveillance;Superresolution;Object detection;Autonomous aerial vehicles;Environmental factors;Drone recognition;Low resolution;Super resolution;Face identification;Surveillance;Security},
doi={10.1109/WIFS53200.2021.9648399},
ISSN={2157-4774},
month={Dec},}
@ARTICLE{7590013,
author={Shi, Haobin and Li, Xuesi and Hwang, Kao-Shing and Pan, Wei and Xu, Genjiu},
journal={IEEE Transactions on Industrial Informatics}, title={Decoupled Visual Servoing With Fuzzy Q-Learning},
year={2018},
volume={14},
number={1},
pages={241-252},
abstract={The objective of visual servoing aims to control an object's motion with visual feedbacks and becomes popular recently. Problems of complex modeling and instability always exist in visual servoing methods. Moreover, there are few research works on selection of the servoing gain in image-based visual servoing (IBVS) methods. This paper proposes an IBVS method with Q-Learning, where the learning rate is adjusted by a fuzzy system. Meanwhile, a synthetic preprocess is introduced to perform feature extraction. The extraction method is actually a combination of a color-based recognition algorithm and an improved contour-based recognition algorithm. For dealing with underactuated dynamics of the unmanned aerial vehicles (UAVs), a decoupled controller is designed, where the velocity and attitude are decoupled through attenuating the effects of underactuation in roll and pitch and two independent servoing gains, for linear and angular motion servoing, respectively, are designed in place of single servoing gain in traditional methods. For further improvement in convergence and stability, a reinforcement learning method, Q-Learning, is taken for adaptive servoing gain adjustment. The Q-Learning is composed of two independent learning agents for adjusting two serving gains, respectively. In order to improve the performance of the Q-Learning, a fuzzy-based method is proposed for tuning the learning rate. The results of simulations and experiments on control of UAVs demonstrate that the proposed method has better properties in stability and convergence than the competing methods.},
keywords={Unmanned aerial vehicles;Feature extraction;Visual servoing;Cameras;Visualization;Vehicle dynamics;Convergence;Fuzzy control;underactuated dynamic system;unmanned aerial vehicles;visual servoing; $Q$ -Learning},
doi={10.1109/TII.2016.2617464},
ISSN={1941-0050},
month={Jan},}
@ARTICLE{8961915,
author={Hong, Tao and Zhao, Weiting and Liu, Rongke and Kadoch, Michel},
journal={IEEE Wireless Communications}, title={Space-Air-Ground IoT Network and Related Key Technologies},
year={2020},
volume={27},
number={2},
pages={96-104},
abstract={The integration of multidimensional networks such as space, air and ground is the future trend of the IoT. In this article, we introduce the SAG IoT network paradigm, including its composition and network architecture. Network slicing, the core 5G technology, will be applied to the SAG IoT network. The wide use of mmWave and UAVs is to produce many new scenarios, and it is necessary to study the effects of UAVs on mmWave channels in these new scenarios. In addition, mmWave imaging technology can provide a basis for this research. Machine learning is an important new technology that can be widely used in the SAG IoT. Simulation and measurement are both important means of evaluating the performance of communication systems. To cope with the emerging new applications and technologies, a cloud-based modular simulation system is introduced for 5G and future IoTs; this system is characterized by high efficiency, flexible configuration and high precision.},
keywords={Internet of Things;5G mobile communication;Satellites;Solid modeling;Three-dimensional displays;Network slicing},
doi={10.1109/MWC.001.1900186},
ISSN={1558-0687},
month={April},}
@INPROCEEDINGS{9602397,
author={Zhu, Liang and Xiao, Anshan and Chi, Xiaoming and Wang, Guolong and Li, Mingjun and Gao, Shaohua and Ma, Ming and Zhang, He and Zhu, Shengjie and Jiang, Ming},
booktitle={2021 33rd Chinese Control and Decision Conference (CCDC)}, title={Research on Intelligent Identification and Quantitative Detection of Gas Leakage in Open Space},
year={2021},
volume={},
number={},
pages={1973-1978},
abstract={Leakage is accident, leakage is emission. The accurate detection of gas leakage in open space will help enterprises to detect the leakage as early as possible, reducing the loss and impact of safety and environmental protection. Firstly, this paper introduces the current situation of gas leakage detection technology in the open space, and the principle of quantum cascade lasers detection technology, comparing the different technologies of open path Fourier transform infrared spectrometry, solar occultation flux, tunable diode laser absorption spectroscopy, optic gas image and so on. Then, according to the technical advantages of open path quantum cascade lasers, combined with the characterization analysis of gas type, a three-layer neural network intelligent recognition model is designed by taking the specific wavelength spectrum absorption detection value as the input and the material type as the output, 2480 groups of sample data were used to train and verify the detection accuracy. The results show that the accuracy rate of leakage gas identification is more than 98%, and the quantitative detection error is less than 8%. Finally, the paper describes an open space application test based on an unmanned aerial vehicle platform, with a horizontal distance of 150 meters and a vertical height of 30 meters, which provides a new method for rapid identification and quantitative detection of gas leakage in open space.},
keywords={Meters;Space vehicles;Spectroscopy;Analytical models;Absorption;Neural networks;Autonomous aerial vehicles;Open Space;Gas Leakage;Quantum Cascade Laser;Intelligent Identification;Quantitative Detection},
doi={10.1109/CCDC52312.2021.9602397},
ISSN={1948-9447},
month={May},}
@INPROCEEDINGS{9616227,
author={Papaioannidis, Christos and Makrygiannis, Dimitrios and Mademlis, Ioannis and Pitas, Ioannis},
booktitle={2021 29th European Signal Processing Conference (EUSIPCO)}, title={Learning Fast and Robust Gesture Recognition},
year={2021},
volume={},
number={},
pages={761-765},
abstract={Autonomous Unmanned Aerial Vehicles (UAVs, or drones) are being increasingly employed to assist in many tasks, typically in collaboration with humans. Since most drones are equipped with RGB cameras, a typical way of visual interaction is through human hand gestures. Thus, this paper examines a common, two-stage algorithmic framework for gesture recognition, suitable for execution on any camera-equipped UAV with embedded AI capabilities. First, a fast 2D human body pose estimation Deep Neural Network (DNN) extracts 2D skeleton information from the input video frames. Then, these per-frame skeletons that have been computed over a temporal window are fed to a separate classifier, which outputs the final gesture prediction. However, no exhaustive quantitative comparisons have been conducted up to now in order to specify the best-performing algorithmic ingredients in the context of this framework. Therefore, we investigated and experimentally evaluated various possibilities for 2D skeleton information utilization, as well as for gesture classification itself, in order to identify the ideal combination for optimal efficiency. Using the empirically best approach, we achieved increased gesture recognition performance on two challenging datasets, when compared to competing relevant methods, at a runtime advantage on embedded AI compute hardware.},
keywords={Runtime;Pose estimation;Signal processing algorithms;Gesture recognition;Streaming media;Prediction algorithms;Skeleton;Gesture recognition;Autonomous drones;Human Robot Interaction;Deep Neural Networks;Human pose estimation},
doi={10.23919/EUSIPCO54536.2021.9616227},
ISSN={2076-1465},
month={Aug},}
@INPROCEEDINGS{9663512,
author={Didari, Hamid and Taghirad, Hamid D. and Shokri, Parnia and Ghofrani, Fatemeh},
booktitle={2021 9th RSI International Conference on Robotics and Mechatronics (ICRoM)}, title={GVPS: Global Visual Position System for Drones},
year={2021},
volume={},
number={},
pages={30-36},
abstract={Drones are contributing significantly to transportation, rescue, commercial, and safety purposes through their rapid technology development. Operating in an unknown outdoor environment is a stringent requirement in these applications, while usually Global Positioning System (GPS) is exploited to determine the global position of the drone. However, relying on an external input source is not a secure solution due to the hijacking possibilities. To tackle this problem, a positioning system that is independent of any external signals is proposed in this paper. This is accomplished in two steps of relative position estimation and global position derivation. First, the relative position of a UAV is estimated by a monocular camera. Since the estimated relative position has an unknown scale, an extended Kalman filter (EKF) is employed to fuse IMU data to that of the relative position. Next, the global position of UAV is derived by using satellite images in addition to the estimated relative position. The proposed algorithm is implemented on a custom made drone equipped with a Jetson TX2 GPU. Experimental results verify the effectiveness of the online implementation of the proposed algorithm in practice.},
keywords={Visualization;Satellites;Rural areas;Estimation;Transportation;Cameras;Real-time systems;Localization;Deep Learning;Kalman Filter;Drones;Global Positioning},
doi={10.1109/ICRoM54204.2021.9663512},
ISSN={2572-6889},
month={Nov},}
@ARTICLE{9519668,
author={Haroun, Fathi Mahdi Elsiddig and Deros, Siti Noratiqah Mohamad and Din, Norashidah Md},
journal={IEEE Access}, title={Detection and Monitoring of Power Line Corridor From Satellite Imagery Using RetinaNet and K-Mean Clustering},
year={2021},
volume={9},
number={},
pages={116720-116730},
abstract={Monitoring of electrical transmission towers (TTs) is required to maintain the integrity of power lines. One major challenge is monitoring vegetation encroachment that can cause power interruption. Most of the current monitoring techniques use unmanned aerial vehicles (UAV) and airborne photography as an observation medium. However, these methods are expensive and not practical for monitoring wide areas. In this paper, we introduced a new method for monitoring the power line corridor from satellite imagery. The proposed method consists of two stages. In the first stage, we used the existing state-of-the-art RetinaNet deep learning (DL) model to detect the locations of the TTs from satellite imagery. A routing algorithm has been developed to create a path between every adjacent detected TT. In addition to the routing algorithm, a corridor identification algorithm has been established for extracting the power line corridor area. In the second stage, the k-mean clustering algorithm has been used to highlight the VE regions within the power line corridor area after converting the target satellite image into hue, saturation, and value (HSV) color space. The proposed monitoring system was able to detect TTs from satellite imagery with a mean average precision (mAP) of 72.45% for an Intersection of Union (IoU) threshold of 0.5 and 85.21% for IoU threshold of 0.3. Also, the monitoring system was able to successfully discriminate high- and low-density vegetation regions within the power line corridor area.},
keywords={Satellites;Monitoring;Vegetation mapping;Training;Classification algorithms;Power transmission lines;Clustering algorithms;Deep learning;K-mean;satellite images;transmission tower detection},
doi={10.1109/ACCESS.2021.3106550},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9647507,
author={Sunduijav, Chinzorig and Hardt, Wolfram and Bayasgalan, Zagdkhorol},
booktitle={2021 XV International Scientific-Technical Conference on Actual Problems Of Electronic Instrument Engineering (APEIE)}, title={Image Processing of Insulator and Vibration Damper by YOLO Algorithm},
year={2021},
volume={},
number={},
pages={375-379},
abstract={Image processing is widely used in many fields, including electronics, computer science, energy, construction, medicine, and self-driving cars. Deep learning based object detection methods have also evolved to detect in real-time. Depending on the nature of the object or image to be processed, the performance of image processing methods will vary from application to application. Therefore, researchers test different types of algorithms in each case and compare performance results. The study aims to detect and report selected objects, such as insulators and vibration dampers. This video was recorded by using an UAV in a power transmission line. The research aims to identify the insulator from the input data processed by image processing, create an image database, and then report the visible physical damages. This study summarizes the results of a study in which video insulators and vibration dampers were detected using the DL youonly look once algorithm.},
keywords={Vibrations;Training;Power transmission lines;Image processing;Object detection;Detectors;Insulators;deep learning;yolov4;object detection;insulator;vibration damper},
doi={10.1109/APEIE52976.2021.9647507},
ISSN={2473-8573},
month={Nov},}
@ARTICLE{9086010,
author={Chamola, Vinay and Hassija, Vikas and Gupta, Vatsal and Guizani, Mohsen},
journal={IEEE Access}, title={A Comprehensive Review of the COVID-19 Pandemic and the Role of IoT, Drones, AI, Blockchain, and 5G in Managing its Impact},
year={2020},
volume={8},
number={},
pages={90225-90265},
abstract={The unprecedented outbreak of the 2019 novel coronavirus, termed as COVID-19 by the World Health Organization (WHO), has placed numerous governments around the world in a precarious position. The impact of the COVID-19 outbreak, earlier witnessed by the citizens of China alone, has now become a matter of grave concern for virtually every country in the world. The scarcity of resources to endure the COVID-19 outbreak combined with the fear of overburdened healthcare systems has forced a majority of these countries into a state of partial or complete lockdown. The number of laboratory-confirmed coronavirus cases has been increasing at an alarming rate throughout the world, with reportedly more than 3 million confirmed cases as of 30 April 2020. Adding to these woes, numerous false reports, misinformation, and unsolicited fears in regards to coronavirus, are being circulated regularly since the outbreak of the COVID-19. In response to such acts, we draw on various reliable sources to present a detailed review of all the major aspects associated with the COVID-19 pandemic. In addition to the direct health implications associated with the outbreak of COVID-19, this study highlights its impact on the global economy. In drawing things to a close, we explore the use of technologies such as the Internet of Things (IoT), Unmanned Aerial Vehicles (UAVs), blockchain, Artificial Intelligence (AI), and 5G, among others, to help mitigate the impact of COVID-19 outbreak.},
keywords={COVID-19;Viruses (medical);Pandemics;Artificial intelligence;Blockchain;5G mobile communication;Coronavirus;COVID-19;pandemic;transmission stages;global economic impact;UAVs for disaster management;Blockchain;IoMT applications;IoT;AI;5G},
doi={10.1109/ACCESS.2020.2992341},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7806891,
author={Leonov, A.V.},
booktitle={2016 13th International Scientific-Technical Conference on Actual Problems of Electronics Instrument Engineering (APEIE)}, title={Modeling of bio-inspired algorithms AntHocNet and BeeAdHoc for Flying Ad Hoc Networks (FANETS)},
year={2016},
volume={03},
number={},
pages={1-1},
abstract={Due to versatility, flexibility and fairly small operating costs, the use of small unmanned aerial vehicles (UAVs) groups provides new opportunities for civil application. FANET (Flying Ad Hoc Network), similar to mobile peer-to-peer networks MANET and vehicular peer-to-peer networks VANET represents a special type of peer-to-peer ad hoc network based on UAVs. FANETs are characterized by high nodes mobility, dynamically-changing topology and movement in 3D-space. To organize multi-UAV network one needs to use special routing algorithms developed due to their specific features. The article gives a short overview of the existing FANET algorithms, as well as of the algorithms based on the swarm intelligence (of the ant and bee colonies). The experimental analysis was conducted, that proved the possibility of efficient application of bio-inspired algorithms. The analysis was performed on protocols AntHocNet and BeeAdHoc, simulating the behavior of bees and ants in wildlife, to solve the routing problems in FANETs.},
keywords={FANET;Routing Protocols;Network Simulation;AntHocNet;BeeAdHoc},
doi={10.1109/APEIE.2016.7806891},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9448970,
author={Madelkhanova, Aida and Becvar, Zdenek},
booktitle={2021 IEEE 93rd Vehicular Technology Conference (VTC2021-Spring)}, title={Optimization of Cell Individual Offset for Handover of Flying Base Station},
year={2021},
volume={},
number={},
pages={1-7},
abstract={Flying base stations (FlyBSs) mounted on unmanned aerial vehicles (UAVs) are widely used in mobile networks to improve a coverage and/or quality of service for users. To ensure a seamless mobility of the FlyBSs among the static base stations (SBSs), an efficient handover mechanism is required. In this paper, we develop a novel handover mechanism determining the serving SBS for the FlyBS in order to increase the sum capacity of the users served by the FlyBS. We propose to dynamically optimize the handover by adjusting the cell individual offset of the SBS via Q-learning. The results show that the Q-learning converges promptly and the proposed approach increases the users capacity (by up to 18%) and their satisfaction with required minimum capacity (by up to 20%) comparing to state-of-the-art algorithms.},
keywords={Base stations;Vehicular and wireless technologies;Heuristic algorithms;Conferences;Quality of service;Handover;Unmanned aerial vehicles;Flying base station;handover;cell individual offset;reinforcement learning},
doi={10.1109/VTC2021-Spring51267.2021.9448970},
ISSN={2577-2465},
month={April},}
@ARTICLE{9599638,
author={Wang, Yuntao and Su, Zhou and Zhang, Ning and Fang, Dongfeng},
journal={IEEE Wireless Communications}, title={Disaster Relief Wireless Networks: Challenges and Solutions},
year={2021},
volume={28},
number={5},
pages={148-155},
abstract={Reliable and flexible emergency networks are of paramount essence for disaster relief during or after the event of disasters due to the destruction or lack of terrestrial communication infrastructures. Thanks to fast deployment and flexible mobilities, unmanned aerial vehicles (UAVs) emerge as a promising paradigm to efficiently establish emergency networks and perform immediate disaster relief tasks in affected areas. However, in such UAV-assisted disaster relief networks (UDRNs), the limited onboard batteries and computational capacities of UAVs hinder them from performing computation-intensive missions. Moreover, critical security vulnerabilities arise in data transmission among UAVs owing to the untrusted environment, open communication channels, and unreliable misbehavior tracing. To this end, this article investigates UDRNs based on blockchain and machine learning to achieve secure and efficient data transmission. Specifically, we first present a lightweight blockchain-enabled collaborative aerial-ground networking framework to safeguard data delivery under disasters, where a credit-based delegated proof-of-stake consensus protocol is further devised to enhance consensus efficiency while promoting UAVs' honest behaviors. In addition, by harnessing the idle computing power of ground vehicles (referred to as vehicular fog computing), a novel reinforcement learning-based algorithm is developed to intelligently offload UAVs' computation missions to the moving vehicles in the dynamic environment. Experimental results demonstrate that the proposed framework outperforms the existing approaches, in terms of consensus security, user utility, task latency, and energy consumption. Finally, future research directions in this emerging area are discussed.},
keywords={Task analysis;Land vehicles;Data communication;Blockchains;Road traffic;Reliability;Relays},
doi={10.1109/MWC.101.2000518},
ISSN={1558-0687},
month={October},}
@INPROCEEDINGS{9307102,
author={Nogueira Alves, Adson and Ferreira, Murillo Augusto S. and Colombini, Esther Luna and da Silva Simões, Alexandre},
booktitle={2020 Latin American Robotics Symposium (LARS), 2020 Brazilian Symposium on Robotics (SBR) and 2020 Workshop on Robotics in Education (WRE)}, title={An Evolutionary Algorithm for Quadcopter Trajectory Optimization in Aerial Challenges},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Machine learning methods have been widely employed in robotics over the years, and recent developments in machine learning have completely re-shaped problem-solving in the area. Indeed, if we consider multi-objective planning, these models' optimization and learning capabilities can derive more robust strategies. Inspired by the species natural selection mechanism, Evolutionary Algorithms (EA) are among the best known computational approaches available for this purpose. In this scenario, this work proposed an EA model developed to find the best travel trajectory for a quadcopter in the “Desafio Petrobras” challenge. In the challenge, a set of landing platforms that the robot has to visit are displaced in the 3D-space. To find the best trajectory possible, we optimize an EA over a low-level control that can take the quadcopter from point A to B. We vary our fitness function to support more complex decisions. The software-in-the-loop technique was applied for a simulated quadrotor in the Coppelia simulated environment. The proposed approach has shown the capability to generate short trajectories while considering variables like UAV dynamics and energy consumption.},
keywords={Trajectory;Statistics;Sociology;Genetics;Genetic algorithms;Vehicle dynamics;Unmanned aerial vehicles},
doi={10.1109/LARS/SBR/WRE51543.2020.9307102},
ISSN={2643-685X},
month={Nov},}
@INPROCEEDINGS{7868418,
author={Ricardo, Shawn and Bein, Doina and Panagadan, Anand},
booktitle={2017 IEEE 7th Annual Computing and Communication Workshop and Conference (CCWC)}, title={Low-cost, real-time obstacle avoidance for mobile robots},
year={2017},
volume={},
number={},
pages={1-7},
abstract={The goal of this project1 is to advance the field of automation and robotics by utilizing recently-released, low-cost sensors and microprocessors to develop a mechanism that provides depth-perception and autonomous obstacle avoidance in a plug-and-play fashion. We describe the essential hardware components that can enable such a low-cost solution and an algorithm to avoid static obstacles present in the environment. The mechanism utilizes a novel single-point LIDAR module that affords more robustness and invariance than popular approaches, such as Neural Networks and Stereo. When this hardware is coupled with the proposed efficient obstacle avoidance algorithm, this mechanism is able to accurately represent environments through point clouds and construct obstacle-free paths to a destination, in a small timeframe. A prototype mechanism has been installed on a quadcopter for visualization on how actual implementation may take place2. We describe experimental results based on this prototype.},
keywords={Sensors;Laser radar;Robots;Hardware;Collision avoidance;Three-dimensional displays;Algorithm design and analysis;Lidar;path planning;quadcopter;UAV;microcontroller},
doi={10.1109/CCWC.2017.7868418},
ISSN={},
month={Jan},}
@ARTICLE{9323029,
author={Okulski, Michał and Ławryńczuk, Maciej},
journal={IEEE Access}, title={A Novel Neural Network Model Applied to Modeling of a Tandem-Wing Quadplane Drone},
year={2021},
volume={9},
number={},
pages={14159-14178},
abstract={This research focuses on modeling one of the Quadplane flight phases: a hover state, similar to a regular Quadcopter hovering. The process is highly non-linear, and additionally, there are more phenomena to take into account - it is related to air turbulence around the wings and the fuselage. This work thoroughly studies the effectiveness of various types of neural networks to model the drone using the data recorded from real free-flight experiments. Finally, we introduce a novel type of neural-based model: the Feature-Sequence-To-Sequence (fseq2seq) Recurrent Neural Network Model. The new Model has interesting features: the input-data-driven initialization of RNN's internal states and a simplification of the input layer (significant reduction of used neurons' weights). We demonstrate that the new network outperforms all classic model types.},
keywords={Drones;Brushless motors;Data models;Propellers;Propulsion;Atmospheric modeling;Solid modeling;Drone;neural model;neural network;quadplane;quad-plane;recurrent neural network;system identification;UAV},
doi={10.1109/ACCESS.2021.3051878},
ISSN={2169-3536},
month={},}
@ARTICLE{8740879,
author={Liu, Mushuang and Wan, Yan and Lewis, Frank L.},
journal={IEEE Control Systems Letters}, title={Adaptive Optimal Decision in Multi-Agent Random Switching Systems},
year={2020},
volume={4},
number={2},
pages={265-270},
abstract={Random switching models have been widely used in areas of communication, physics and aerospace, to capture the random movement patterns of mobile agents. In this letter, we study the optimal decision-making problem for multi-agent systems governed by random switching dynamics. In particular, we develop a novel online optimal control solution that integrates the reinforcement learning (RL) with an effective uncertainty sampling method, called multivariate probabilistic collocation method (MPCM), to adaptively find the optimal policies for agents of randomly switching mobility. We also develop a novel estimator that integrates the unscented Kalman filter (UKF) and MPCM to provide online estimation solutions for these agents. Efficiency and accuracy of the proposed solutions are analyzed. A concrete communication and antenna control co-design problem for a multi-UAV network is studied in the end to illustrate and validate the results.},
keywords={Switches;Optimal control;Uncertainty;Switching systems;Random variables;Turning;Adaptive systems;Random switching systems;learning control;nonlinear estimation},
doi={10.1109/LCSYS.2019.2923915},
ISSN={2475-1456},
month={April},}
@INPROCEEDINGS{8122126,
author={Gibson, David and Campbell, Neill},
booktitle={2017 Conference on Design and Architectures for Signal and Image Processing (DASIP)}, title={Adaptive space-time structural coherence for selective imaging},
year={2017},
volume={},
number={},
pages={1-6},
abstract={In this paper we present a novel close-to-sensor computational camera design. The hardware can be configured for a wide range of autonomous applications such as industrial inspection, binocular/stereo robotic vision, UAV navigation/control and biological vision analogues. Close coupling of the image sensor with computation, motor control and motion sensors enables low latency responses to changes in the visual field. An image processing pipeline that detects and processes regions containing space-time structural coherence, in order to reduce the transmission of redundant pixel data and stabilise selective imaging, is introduced. The pipeline is designed to exploit close-to-sensor processing of regions-of-interest (ROI) adaptively captured at high temporal rates (up to 1000 ROI/s) and at multiple spatial and temporal resolutions. Space-time structurally coherent macro blocks are detected using a novel temporal block matching approach; the high temporal sampling rate allows a monotonicity constraint to be enforced to efficiently assess confidence of matches. The robustness of the sparse motion estimation approach is demonstrated in comparison to a state-of-the-art optical flow algorithm and optimal Baysian grid-based filtering. A description of how the system can generate unsupervised training data for higher level multiple instance or deep learning systems is discussed.},
keywords={Spatial resolution;Image sensors;Motion estimation;Sensors;Visualization;Pipelines;Close-to-sensor processing;low latency processing;feature analysis;sub-pixel tracking},
doi={10.1109/DASIP.2017.8122126},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9150737,
author={Wang, Zixuan and Zhao, Zhicheng and Su, Fei},
booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Real-time Tracking with Stabilized Frame},
year={2020},
volume={},
number={},
pages={4431-4438},
abstract={Deep learning methods have dramatically increased tracking accuracy benefitting from exquisite features extractor. Among these methods, siamese-based tracker performs well. However, in case of camera shaking, the objects are easily to be lost because of no consideration of camera judder, and the position of each pixel changes drastically between frames. In particular, the tracking performance would degrade dramatically in case that the target is small and moving fast, such as UAV tracking. In this paper, the S-Siam framework is proposed to deal with this problem and improves the performance of real-time tracking. Through stabilizing each frame by estimating where the object is going to move, the camera is adjusted adaptively to keep the object in its original position. Experimental results on the VOT2018 dataset show that the proposed method obtained an EAO score 0.449, and achieved 10% robustness improvement compared with existing three trackers, i.e., SiamFC, SiamMask and SiamRPN++, which demonstrates the effectiveness of the proposed algorithm.},
keywords={Target tracking;Cameras;Real-time systems;Robustness;Object tracking;Streaming media},
doi={10.1109/CVPRW50498.2020.00522},
ISSN={2160-7516},
month={June},}
@INPROCEEDINGS{8816557,
author={Zhang, Haoxin and Liu, Biao and Shen, Chuangyun and Zhou, Haibo and Liu, Shucheng},
booktitle={2019 IEEE International Conference on Mechatronics and Automation (ICMA)}, title={Research on V-SLAM Methods},
year={2019},
volume={},
number={},
pages={1055-1060},
abstract={With the development of intelligent mobile robots, SLAM, especially V-SLAM, as the basic technology of robot localization and navigation, has the advantages of strong adaptability, high precision and strong intelligence compared with the traditional localization technology. It is widely used in smart devices such as unmanned aerial vehicle, automatic driving and sweeping robots. According to different implementation methods, the visual SLAM is divided into: filter V-SLAM based on probability model, key frame BA-based V-SLAM using nonlinear optimization theory, direct tracking of V-SLAM under the assumption of luminosity invariance, space occupying V-SLAM that focuses on building three-dimensional dense maps. This paper focuses on representative systems of various V-SLAMs and gives their respective applicable scenarios and characteristics. Finally, this article forecasts the development of V-SLAM combining with multi-information fusion technology, semantic deep and learning technology.},
keywords={Simultaneous localization and mapping;Cameras;Optimization;Real-time systems;Navigation;V-SLAM;Filter;Key frame;Direct method;Space occupation},
doi={10.1109/ICMA.2019.8816557},
ISSN={2152-744X},
month={Aug},}
@INPROCEEDINGS{8803262,
author={Mandal, Murari and Shah, Manal and Meena, Prashant and Vipparthi, Santosh Kumar},
booktitle={2019 IEEE International Conference on Image Processing (ICIP)}, title={SSSDET: Simple Short and Shallow Network for Resource Efficient Vehicle Detection in Aerial Scenes},
year={2019},
volume={},
number={},
pages={3098-3102},
abstract={Detection of small-sized targets is of paramount importance in many aerial vision-based applications. The commonly deployed low cost unmanned aerial vehicles (UAVs) for aerial scene analysis are highly resource constrained in nature. In this paper we propose a simple short and shallow network (SSSDet) to robustly detect and classify small-sized vehicles in aerial scenes. The proposed SSSDet is up to 4× faster, requires 4.4× less FLOPs, has 30× less parameters, requires 31× less memory space and provides better accuracy in comparison to existing state-of-the-art detectors. Thus, it is more suitable for hardware implementation in real-time applications. We also created a new airborne image dataset (ABD) by annotating 1396 new objects in 79 aerial images for our experiments. The effectiveness of the proposed method is validated on the existing VEDAI, DLR-3K, DOTA and Combined dataset. The SSSDet outperforms state-of-the-art detectors in term of accuracy, speed, compute and memory efficiency.},
keywords={Detectors;Feature extraction;Vehicle detection;Memory management;Object detection;Convolution;Computational modeling;aerial scene;vehicle detection;deep learning;real-time;remote sensing},
doi={10.1109/ICIP.2019.8803262},
ISSN={2381-8549},
month={Sep.},}
@INPROCEEDINGS{9488948,
author={Perumalla, Subhadra and Chatterjee, Santanu and Kumar, A.P. Siva},
booktitle={2021 6th International Conference on Communication and Electronics Systems (ICCES)}, title={Block Chain-based access control and intrusion detection system in IoD},
year={2021},
volume={},
number={},
pages={511-518},
abstract={The Internet of Drones (IoD), a layered network, has attracted more attention among the research community due to its wide range of applications, such as packet transmission, rescue operations, traffic surveillance, and so on. Various drones known as Unmanned Aerial Vehicles (UAVs) are deployed in various flying zones to transmit important information to the Ground station server (GSS). Hence, secure transmission is the major challenging aspect of IoD. Hence, this paper introduces a novel technique for secure transmission in IoD by effective blockchain-assisted access control and intrusion detection approach using the newly devised Deep Neuro-Fuzzy Network system. Typically, Blockchain-based access control consists of mainly four phases, like pre-deployment, registration, authentication, and access control phase for transferring the crucial information in the IoD environment. Besides, intrusion in IoD is detected using the proposed Deep Neuro-Fuzzy Network. However, the proposed approach achieved a minimum delay of 1.253, a maximum precision rate of 88.375, and a maximum recall measure of 89.263 while considering the Neptune attack.},
keywords={Access control;Performance evaluation;Intrusion detection;Authentication;Traffic control;Fuzzy neural networks;Throughput;Intrusion Detection System (IDS);Blockchain Network;Internet of Drones (IoD);Deep Neuro-Fuzzy Network;Access control},
doi={10.1109/ICCES51350.2021.9488948},
ISSN={},
month={July},}
@INPROCEEDINGS{9327306,
author={Zhang, Tianlin and Zhang, Hui and Li, Hongwen and Zhong, Hang and Tang, Xunhao and Wang, Yaonan},
booktitle={2020 Chinese Automation Congress (CAC)}, title={CatchIt: Large-scale Grasping combined with Preliminary and Precise Localization method for Aerial Manipulator},
year={2020},
volume={},
number={},
pages={4792-4798},
abstract={Grasping objects in a large-scale area has been investigated extensively for mobile robots. But for unmanned aerial manipulator(UAM), this is still a challenging task. In order to solve the problem of accurate grasping in a large-scale area, we propose a novel detection and control framework for UAM, which consists of two stages: preliminary localization and precise localization. At the preliminary localization stage, the RGB-D sensor mounted on the end-effector of the manipulator scans to obtain the point cloud surrounding the UAM. By bringing the known target shape and processed point cloud parameters into our proposed loss function, we select the highest priority area as the best potential region proposal, which can help the UAM to screen out the target for precise localization from the obtained point cloud. At precise localization stage, after UAM reaches the best potential region, the RGB-D sensor mounted on the drone uses the deep object pose estimation(DOPE) to estimate the 6D pose of the target. Through independently compensating for the disturbance of the UAV and manipulator, the UAM can accurately grasp the target with the estimated 6D pose. To evaluate the performance of the UAM, we conducted experiments in four different scenes. Experimental results demonstrate that the UAM can grasp the target with an average success rate of 83.4% for the large-scale scene. The above results prove the feasibility and robustness of the framework. The code is available at https://github.com/skywoodsz/CatchIt.},
keywords={Three-dimensional displays;Ions;Manipulators;Cameras;Neural networks;Location awareness;Grasping},
doi={10.1109/CAC51589.2020.9327306},
ISSN={2688-0938},
month={Nov},}
@INPROCEEDINGS{9481007,
author={Concea, Andreea and Nitescu, Tudor and Ichim, Loretta and Popescu, Dan},
booktitle={2021 23rd International Conference on Control Systems and Computer Science (CSCS)}, title={Texture Analysis for Images with Forested Areas},
year={2021},
volume={},
number={},
pages={197-202},
abstract={The information on the structure of the forest has been of high interest for a long time, being related to the possibilities of maximizing the wood production in the conditions of ensuring ecological stability, but also of detecting and preventing illegal deforestation. The main objective of this paper is the texture analysis of forested areas from remote images, obtained by UAV. The forested area will be highlighted by separating it from the rest (background image). To achieve this goal, efficient texture features will be used such as: fractal dimension, lacunarity, LBP histogram, mean intensity and contrast. The obtained accuracy of 90.5% is a good result in the conditions of some real images.},
keywords={Computer science;Image segmentation;Histograms;Neural networks;Forestry;Production;Parallel processing;forested areas;image classification;image segmentation;texture analysis;texture features},
doi={10.1109/CSCS52396.2021.00039},
ISSN={2379-0482},
month={May},}
@ARTICLE{9257056,
author={Nowak, Martin and Beninati, Anthony and Douard, Nicolas and Giakos, George C.},
journal={IEEE Instrumentation Measurement Magazine}, title={Polarimetric dynamic vision sensor p(DVS) principles},
year={2020},
volume={23},
number={8},
pages={18-23},
abstract={This contribution relates to the activities of the TC-19 on “Imaging Signals and Systems.” In a rapidly changing global economy, experiencing an unparalleled integration of science and technology, the development of efficient imaging systems is of extreme significance. The scope of TC-19 is to exchange and disseminate knowledge as well as bridge multidisciplinary areas leading to the creation of new knowledge and establish global collaborative multidisciplinary opportunities by tightening collaborations among government, industry, academia, and healthcare industry. The Committee explores a variety of computer vision and visualization systems spanning from medical imaging to defense, industry, and consumer electronics. These imaging systems use statistical or sophisticated artificial algorithms and require the integration of several technological and computational disciplines, such as detector physics and phenomenology, calibration, metrology, data acquisition, data analysis, image processing, feature extraction, and classification. Often, coexisting competing design requirements and trade-off introduce significant challenges to the design of imaging technologies. For instance, Autonomous Vehicles (AV)s, Unmanned Aerial Vehicles (UAV)s, Unmanned Underwater Vehicle (UUV)s, microsatellites, nanosatellites, and picosatellites for defense and civilian applications are characteristic examples with trade-off between design requirements for high performance imaging and maintaining low-power consumption, high-data transmission, low storage and memory, and reduced payload. To address these competing design challenges, TC-19 introduced the polarimetric neuromorphic vision principles which blend bioinspired principles such as human cognition with the vision of certain arthropods, and aquatic biological species.},
keywords={Neural networks;Voltage control;Vision sensors;Feature extraction;Neuromorphics;Image reconstruction},
doi={10.1109/MIM.2020.9257056},
ISSN={1941-0123},
month={Nov},}
@INPROCEEDINGS{8119222,
author={Lo, Chi and Su, Yu-Yi and Lee, Chun-Yi and Chang, Shih-Chieh},
booktitle={2017 IEEE International Conference on Computer Design (ICCD)}, title={A Dynamic Deep Neural Network Design for Efficient Workload Allocation in Edge Computing},
year={2017},
volume={},
number={},
pages={273-280},
abstract={Unreliable communication channels and limited computing resources at the edge end are two primary constraints of battery-powered movable devices, such as autonomous robots and unmanned aerial vehicles (UAVs). The impact is especially severe for those performing deep neural network (DNN) computations. With increasing demand for accuracy, the trend in modern DNN designs is the use of cascaded modularized layers. Implementing a deep network at the edge increases computational workloads and resource occupancy, leading to an increase in battery drain. Using a shallow network and offloading workloads to backbone servers, however, incur significant latency overheads caused by unstable communication channels. Hence, dynamic DNN design techniques for efficient workload allocation are urgently required to manage the amount of workload transmissions while achieving the required accuracy. In this paper, we explore the use of authentic operation (AO) unit and dynamic network structure to enhance DNNs. The AO unit defines a set of stochastic threshold values for different DNN output classes and determines at runtime if an input has to be transferred to backbone servers for further analysis. The dynamic network structure adjusts its depth according to channel availability. Experiments have been comprehensively performed on several well-known DNN models and datasets. Our results show that, on an average, the proposed techniques are able to reduce the amount of transmissions by up to 17% compared to previous methods under the same accuracy requirement.},
keywords={Servers;Image edge detection;Vehicle dynamics;Neural networks;Communication channels;Resource management;Performance evaluation;Deep neural network;workload allocation;edge computing;authentic operation;dynamic network structure},
doi={10.1109/ICCD.2017.49},
ISSN={1063-6404},
month={Nov},}
@INPROCEEDINGS{8967885,
author={Windrim, Lloyd and Bryson, Mitch},
booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Forest Tree Detection and Segmentation using High Resolution Airborne LiDAR},
year={2019},
volume={},
number={},
pages={3898-3904},
abstract={This paper presents an autonomous approach to tree detection and segmentation from high resolution airborne LiDAR pointclouds, such as those collected from a UAV, that utilises region-based CNN and 3D-CNN deep learning algorithms. Trees are first detected in 2D before individual trees are further characterised in 3D. If the number of training examples for a site is low, it is shown to be beneficial to transfer a segmentation network learnt from a different site with more training data and fine-tune it. The algorithm was validated using airborne laser scanning over two different commercial pine plantations. The results show that the proposed approach performs favourably in comparison to other methods for tree detection and segmentation.},
keywords={},
doi={10.1109/IROS40897.2019.8967885},
ISSN={2153-0866},
month={Nov},}
@INPROCEEDINGS{8354281,
author={Vidal, Rosaura G. and Banerjee, Sreya and Grm, Klemen and Struc, Vitomir and Scheirer, Walter J.},
booktitle={2018 IEEE Winter Conference on Applications of Computer Vision (WACV)}, title={UG^2: A Video Benchmark for Assessing the Impact of Image Restoration and Enhancement on Automatic Visual Recognition},
year={2018},
volume={},
number={},
pages={1597-1606},
abstract={Advances in image restoration and enhancement techniques have led to discussion about how such algorithms can be applied as a pre-processing step to improve automatic visual recognition. In principle, techniques like deblurring and super-resolution should yield improvements by de-emphasizing noise and increasing signal in an input image. But the historically divergent goals of computational photography and visual recognition communities have created a significant need for more work in this direction. To facilitate new research, we introduce a new benchmark dataset called UG2, which contains three difficult real-world scenarios: uncontrolled videos taken by UAVs and manned gliders, as well as controlled videos taken on the ground. Over 150,000 annotated frames for hundreds of ImageNet classes are available, which are used for baseline experiments that assess the impact of known and unknown image artifacts and other conditions on common deep learning-based object classification approaches. Further, current image restoration and enhancement techniques are evaluated by determining whether or not they improve baseline classification performance. Results show that there is plenty of room for algorithmic innovation, making this dataset a useful tool going forward.},
keywords={Image restoration;Image resolution;Image recognition;Visualization;Object recognition;Benchmark testing;Photography},
doi={10.1109/WACV.2018.00177},
ISSN={},
month={March},}
@INPROCEEDINGS{8265456,
author={Costea, Dragos and Marcu, Alina and Leordeanu, Marius and Slusanschi, Emil},
booktitle={2017 IEEE International Conference on Computer Vision Workshops (ICCVW)}, title={Creating Roadmaps in Aerial Images with Generative Adversarial Networks and Smoothing-Based Optimization},
year={2017},
volume={},
number={},
pages={2100-2109},
abstract={Recognizing roads and intersections in aerial images is a challenging problem in computer vision with many real world applications, such as localization and navigation for unmanned aerial vehicles (UAVs). The problem is currently gaining momentum in computer vision and is still far from being solved. While recent approaches have greatly improved due to the advances in deep learning, they provide only pixel-level semantic segmentations. In this paper, we argue that roads and intersections should be recognized at the higher semantic level of road graphs - with roads being edges that connect nodes. Towards this goal we present a method consisting of two stages. During the first stage, we detect roads and intersections with a novel, dual-hop generative adversarial network (DH-GAN) that segments images at the level of pixels. At the second stage, given the pixelwise road segmentation, we find its best covering road graph by applying a smoothing-based graph optimization procedure. Our approach is able to outperform recent published methods and baselines on a large dataset with European roads.},
keywords={Roads;Image segmentation;Optimization;Gallium nitride;Image edge detection;Generators},
doi={10.1109/ICCVW.2017.246},
ISSN={2473-9944},
month={Oct},}
@ARTICLE{9415623,
author={Nguyen, Dinh C. and Ding, Ming and Pathirana, Pubudu N. and Seneviratne, Aruna and Li, Jun and Vincent Poor, H.},
journal={IEEE Communications Surveys Tutorials}, title={Federated Learning for Internet of Things: A Comprehensive Survey},
year={2021},
volume={23},
number={3},
pages={1622-1658},
abstract={The Internet of Things (IoT) is penetrating many facets of our daily life with the proliferation of intelligent services and applications empowered by artificial intelligence (AI). Traditionally, AI techniques require centralized data collection and processing that may not be feasible in realistic application scenarios due to the high scalability of modern IoT networks and growing data privacy concerns. Federated Learning (FL) has emerged as a distributed collaborative AI approach that can enable many intelligent IoT applications, by allowing for AI training at distributed IoT devices without the need for data sharing. In this article, we provide a comprehensive survey of the emerging applications of FL in IoT networks, beginning from an introduction to the recent advances in FL and IoT to a discussion of their integration. Particularly, we explore and analyze the potential of FL for enabling a wide range of IoT services, including IoT data sharing, data offloading and caching, attack detection, localization, mobile crowdsensing, and IoT privacy and security. We then provide an extensive survey of the use of FL in various key IoT applications such as smart healthcare, smart transportation, Unmanned Aerial Vehicles (UAVs), smart cities, and smart industry. The important lessons learned from this review of the FL-IoT services and applications are also highlighted. We complete this survey by highlighting the current challenges and possible directions for future research in this booming area.},
keywords={Internet of Things;Data privacy;Training;Data models;Computational modeling;Medical services;Computer architecture;Federated learning;Internet of Things;artificial intelligence;machine learning;privacy},
doi={10.1109/COMST.2021.3075439},
ISSN={1553-877X},
month={thirdquarter},}
@INPROCEEDINGS{8278309,
author={Li, Jiankun and Ding, Wenrui and Li, Hongguang and Liu, Chunlei},
booktitle={2017 IEEE International Conference on Unmanned Systems (ICUS)}, title={Semantic segmentation for high-resolution aerial imagery using multi-skip network and Markov random fields},
year={2017},
volume={},
number={},
pages={12-17},
abstract={Semantic segmentation for aerial imagery is a significant work for remote sensing applications especially for unmanned aerial vehicles (UAVs). In recent years, with the success of deep learning methods, convolutional neural network (CNN) based model plays an important role in both image classification and segmentation. However, due to the presence of small objects in the imagery and imbalance of classes distribution, the pixel-wise semantic segmentation remains a challenge for high-resolution remote sensing imagery. In this paper, a novel CNN based semantic segmentation method is proposed to solve the mentioned problem. To provide more context information for the decoding stage, multi-scale skip connections are designed to feed the pooling layers output from encoding stage to the decoding part. Inception modules are also used to replace the convolutional layers providing multi-scale reception areas. Finally, to enhance the result visually, we re-correct the result basing on prediction confidence in post processing procedure, and then a Markov random fields model is built to refine the label map using simulated annealing algorithm. Experiments on Vaihingen dataset show accuracy improvement on overall performance and car class segmentations.},
keywords={Vegetation;Automobiles;Indexes;Markov random fields;Simulated annealing;Buildings;semantic segmentation;convolutional neural network;Markov random fields;remote sensing;unmanned aerial vehicles},
doi={10.1109/ICUS.2017.8278309},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8866322,
author={Wang, Hao and Yang, Guodong and Li, En and Tian, Yunong and Zhao, Meng and Liang, Zize},
booktitle={2019 Chinese Control Conference (CCC)}, title={High-Voltage Power Transmission Tower Detection Based on Faster R-CNN and YOLO-V3},
year={2019},
volume={},
number={},
pages={8750-8755},
abstract={The power transmission mainly depends on overhead transmission infrastructures, such as towers and lines. Automatic inspection by robots or UAVs for the power transmission infrastructures is an essential way to ensure the safety of power transmission. Automatic detection and classification of the power towers is the prerequisite for automatic inspection. This paper compares two state-of-art deep learning methods to realize the high-voltage power transmission tower detection. We build the dedicated dataset of the power towers for multi-object detection, including data collection, preprocessing and annotation. After that, the models of YOLO-v3 and Faster R-CNN are used to solve multi-object detection on our dataset. The performances of the two models are evaluated under different indicators. It is verified that Faster R-CNN has a better detection performance in accuracy. However, the detection speed of YOLO-V3 model is faster and can be used in real-time detection.},
keywords={Poles and towers;Inspection;Feature extraction;Object detection;Training;Proposals;object detection;images acquisition;power tower detection;Faster R-CNN;YOLO-V3},
doi={10.23919/ChiCC.2019.8866322},
ISSN={1934-1768},
month={July},}
@ARTICLE{8979375,
author={Ezeme, Okwudili M. and Azim, Akramul and Mahmoud, Qusay H.},
journal={IEEE Transactions on Emerging Topics in Computing}, title={PESKEA: Anomaly Detection Framework for Profiling Kernel Event Attributes in Embedded Systems},
year={2021},
volume={9},
number={2},
pages={957-971},
abstract={In the software development life cycle, we use the execution traces of a given application to examine the behavior of the software when an error occurs or to monitor the software performance and compliance. However, this type of application trace analysis focuses on checking the performance of the software against its design goals. Conversely, the operating system (OS) sits between the application and the hardware, and traces logged from this layer capture the behavior of the embedded system and not just the application. Hence, an analysis of the kernel events captures the system-wide performance of the embedded system. Consequently, we present a feature-based anomaly detection framework called PESKEA, which exploits the statistical variance of the features in the execution traces of an embedded OS to perform trace classification, and subsequently, anomaly detection. We test PESKEA with two public datasets we refer to as Dataset I and Dataset II. On Dataset I, PESKEA results show a 3 to 6 percent improvement in the true positive rate (TPR) of Dataset I compared to the previous work tested on this dataset, and scores between 88.37 to 100 percent in Dataset II. We hope to test PESKEA on non-UAV embedded control application datasets in future work.},
keywords={Anomaly detection;Embedded systems;Feature extraction;Monitoring;Kernel;Hardware;Context modeling;anomaly detection framework;embedded operating system;machine learning},
doi={10.1109/TETC.2020.2971251},
ISSN={2168-6750},
month={April},}
@INPROCEEDINGS{9073885,
author={Plastiras, George and Siddiqui, Shahid and Kyrkou, Christos and Theocharides, Theocharis},
booktitle={2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS)}, title={Efficient Embedded Deep Neural-Network-based Object Detection Via Joint Quantization and Tiling},
year={2020},
volume={},
number={},
pages={6-10},
abstract={Embedded visual AI is a growing trend in applications requiring low latency, real-time decision support, increased robustness and security. Visual object detection, a key task in visual data analytics, has enjoyed significant improvements in terms of capabilities and accuracy due to the emergence of Convolutional Neural Networks (CNNs). However, such complex paradigms require heavy computational resources that prevent their deployment on resource-constrained devices, and in particular, impose significant constraints in possible hardware accelerators geared towards such applications. In this work therefore, we investigate how a combination of techniques can lead to efficient visual AI pipelines for resource-constrained object detection. In particular we leverage an efficient search strategy based on a combination of pre-processing mechanisms, that reduce the processing demands of deep network as a counter measure for potential accuracy reduction caused by quantization. The proposed approach enables the detection of objects in higher resolution frames using quantized models, while maintaining the accuracy of full-precision CNN-based object detectors. We illustrate the impact on the accuracy and average processing time using quantization techniques and different tiling approaches on efficient object detection architectures; as a case study, we focus on Unmanned-Aerial- Vehicles (UAVs). Through the proposed methodology, hardware accelerator demands are thereby reduced, leading to both performance benefits and associated power savings.},
keywords={Quantization (signal);Detectors;Object detection;Visualization;Image resolution;Real-time systems;Pipelines},
doi={10.1109/AICAS48895.2020.9073885},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8323849,
author={Van Dinh, Dzung and Yoon, Byeong-Nam and Le, Hung Ngoc and Nguyen, Uy Quoc and Dang Phan, Khoa and Dinh Pham, Lam},
booktitle={2018 20th International Conference on Advanced Communication Technology (ICACT)}, title={ICT enabling technologies for smart cities},
year={2018},
volume={},
number={},
pages={1-2},
abstract={A smart city adjusts its social, business, and natural needs, improving the assets it has accessible. Information and Communications Technology (ICT) for shrewd urban areas is to give city answers for encourage an improvement and manageability of a city for the advantage of its population, its economy, and the greater ecosystem in the city. It is to gauge a keen city as far as the enhancements in personal satisfaction and monetary prosperity that are accomplished through applying ICT innovations to design, outline, fabricate, and work the city foundation. In smart city applications, the initial phase in the information's voyage through the application is its gathering by the diverse advancements conveyed all through the city. This paper surveys data acquisition technologies such as Sensor Networks, MANETs, Unmanned Aerial Vehicles (UAVs), Vehicular Ad hoc Networks (VANETs), Internet of Things (IoT), Software-Defined Networking (SDN), Network Functions Virtualization (NFV), 5G. Next, it demonstrates information processing technologies, for example, Cloud Platform, IoT Platform, Big Data Platform, Machine Learning, Deep Learning, and IoT Analytics. Encouraging data spread between various nodes is vital to savvy city acknowledgment. Last, because of the presence of various types of end users (e.g., residents, organizations, government offices, and so forth.) requiring distinctive levels of nature of management, the paper exhibits a proposed testbed solution and recent associated experiments.},
keywords={IoT;SDN;NFV;5G;Cloud Platform;IoT Platform;Big Data Platform;IoT Analytics},
doi={10.23919/ICACT.2018.8323849},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8323480,
author={Van Dzung, Dinh},
booktitle={2018 20th International Conference on Advanced Communication Technology (ICACT)}, title={Tutorial: Smart cities activities in Vietnam and review of ICT enabling technologies},
year={2018},
volume={},
number={},
pages={xxvii-xxix},
abstract={This tutorial reports recent activities for deploying smart cities ICT solutions for major cites in Vietnam such as HCM city, Danang an Hanoi. It also presents a survey of data acquisition technologies such as Sensor Networks, MANETs, Unmanned Aerial Vehicles (UAVs), Vehicular Ad hoc Networks (VANETs), Internet of Things (IoT), Software-Defined Networking (SDN), Network Functions Virtualization (NFV), 5G. Next, it demonstrates information processing technologies,: for example, Cloud Platform, IoT Platform, Big Data Platform, Machine Learning, Deep Learning, and IoT Analytics.},
keywords={},
doi={10.23919/ICACT.2018.8323480},
ISSN={},
month={Feb},}
@ARTICLE{9364688,
author={Westfechtel, Thomas and Ohno, Kazunori and Akegawa, Tetsu and Yamada, Kento and Neto, Ranulfo Plutarco Bezerra and Kojima, Shotaro and Suzuki, Taro and Komatsu, Tomohiro and Shibata, Yukinori and Asano, Kimitaka and Nagatani, Keji and Miyamoto, Naoto and Suzuki, Takahiro and Harada, Tatsuya and Tadokoro, Satoshi},
journal={IEEE Robotics and Automation Letters}, title={Semantic Mapping of Construction Site From Multiple Daily Airborne LiDAR Data},
year={2021},
volume={6},
number={2},
pages={3073-3080},
abstract={Semantic maps are an important tool to provide robots with high-level knowledge about the environment, enabling them to better react to and interact with their surroundings. However, as a single measurement of the environment is solely a snapshot of a specific time, it does not necessarily reflect the underlying semantics. In this work, we propose a method to create a semantic map of a construction site by fusing multiple daily data. The construction site is measured by an unmanned aerial vehicle (UAV) equipped with a LiDAR. We extract clusters above ground level from the measurements and classify them using either a random forest or a deep learning based classifier. Furthermore, we combine the classification results of several measurements to generalize the classification of the single measurements and create a general semantic map of the working site. We measured two construction fields for our evaluation. The classification models can achieve an average intersection over union (IoU) score of 69.2% during classification on the Sanbongi field, which is used for training, validation and testing and an IoU score of 49.16% on a hold-out testing field. In a final step, we show how the semantic map can be employed to suggest a parking spot for a dump truck, and in addition, show that the semantic map can be utilized to improve path planning inside the construction site.},
keywords={Semantics;Robots;Three-dimensional displays;Image segmentation;Laser radar;Random forests;Data mining;Field robots;robotics and automation in construction;semantic scene understanding},
doi={10.1109/LRA.2021.3062606},
ISSN={2377-3766},
month={April},}
@INPROCEEDINGS{9607701,
author={Aslahishahri, Masoomeh and Stanley, Kevin G. and Duddu, Hema and Shirtliffe, Steve and Vail, Sally and Bett, Kirstin and Pozniak, Curtis and Stavness, Ian},
booktitle={2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}, title={From RGB to NIR: Predicting of near infrared reflectance from visible spectrum aerial images of crops},
year={2021},
volume={},
number={},
pages={1312-1322},
abstract={Near infrared spectroscopy (NIR) provides rich information in agricultural operations and experiments to determine crop parameters which are not visible to the human eye. Collecting the NIR spectral band requires a multispectral camera which is typically more expensive and has lower resolution than a comparable RGB camera. We investigate image-to-image translation as a means to generate an NIR spectral band from an RGB image alone in aerial crop imagery. Aerial images were captured via a multispectral sensor mounted on an unmanned aerial vehicle (UAV) flown over canola, lentil, dry bean, and wheat breeding trials. A software workflow was created to preprocess raw aerial images creating a dataset suitable for training and evaluating deep learning based band inferencing algorithms. Two different experiments including in-domain and out-of-domain experiments over different crop types in our dataset were conducted to evaluate efficacy in an agricultural context.},
keywords={Reflectivity;Training;Spectroscopy;Software algorithms;Crops;Cameras;Radiometry},
doi={10.1109/ICCVW54120.2021.00152},
ISSN={2473-9944},
month={Oct},}
@ARTICLE{9383811,
author={Wang, Xinyu and Luo, Zhaozhi and Li, Wenqing and Hu, Xin and Zhang, Liangpei and Zhong, Yanfei},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={A Self-Supervised Denoising Network for Satellite-Airborne-Ground Hyperspectral Imagery},
year={2022},
volume={60},
number={},
pages={1-16},
abstract={Hyperspectral images (HSIs) are inevitably corrupted with various types of noise, which seriously degrades the data quality and usability. Denoising is an essential preprocessing task of HSI processing. Recently, benefiting from the great learning ability of deep learning, convolutional neural network (CNN) denoisers have obtained state-of-the-art performances for Gaussian noise removal. However, one central problem remains largely unsolved: how to deal with the complicated noise in the real-world HSIs, especially when a paired training data set is unavailable. In this article, a self-supervised hyperspectral image denoising network (SHDN) is proposed, which consists of a noise estimator and a CNN denoiser. Rather than defining a complex noise model to generate training pairs on the clean HSIs, a self-supervised training scheme is first proposed by considering the noisy HSI itself as the training data. Through the noise estimator, the realistic noise samples can be extracted and combined with the clean bands to make up the training pairs. In addition, to jointly restore the target noisy band and to maintain the spectral consistency, a flexible multi-to-single band convolutional network is designed, where the noisy band and the neighboring bands are jointly aggregated via multiscale contextualized dilated blocks and the spectral–spatial convolutional unit. Experiments on HSIs from spaceborne, airborne, unmanned aerial vehicle (UAV)-borne, and ground-based data sets demonstrate the applicability and the generalization of SHDN in the real scenarios. Additionally, the usability of the noisy bands and the suitability of the SHDN framework in the subsequent applications are verified in the land-cover mapping experiments.},
keywords={Noise reduction;Noise measurement;Training;Hyperspectral imaging;Data models;Solid modeling;Gaussian noise;Deep convolutional neural network (CNN);hyperspectral remote sensing image;mixed noise removal;self-supervised training},
doi={10.1109/TGRS.2021.3064429},
ISSN={1558-0644},
month={},}
@ARTICLE{9187552,
author={Sun, Ying and Zhang, Xinchang and Huang, Jianfeng and Wang, Haiying and Xin, Qinchuan},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Fine-Grained Building Change Detection From Very High-Spatial-Resolution Remote Sensing Images Based on Deep Multitask Learning},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={Building change detection from very high-spatial-resolution (VHR) remote sensing images has gained increasing popularity in a variety of applications, such as urban planning and damage assessment. Detecting fine-grained “from–to” changes (change transition from one land cover type to another) of buildings from the VHR images is still challenging as multitemporal representation is complicated. Recently, fully convolutional neural networks (FCNs) have been proven to be capable of feature extraction and semantic segmentation of VHR images, but its ability in change detection is untested and unknown. In this letter, we leverage the semantic segmentation of buildings as an auxiliary source of information for the fine-grained “from–to” change detection. A deep multitask learning framework for change detection (MTL-CD) is proposed for detecting building changes from the VHR images. MTL-CD adopts the encoder–decoder architecture and solves the main task of change detection and the auxiliary tasks of semantic segmentation simultaneously. Accordingly, the change detection loss function is constrained by the auxiliary semantic segmentation tasks and enables the back-propagation of the building footprints’ detection errors for the improvement of change detection. A building change detection data set named the Guangzhou data set is also developed for model evaluation, in which the bitemporal R–G–B images were collected by airplane (2009) and unmanned aerial vehicle (UAV, 2019) with different flight heights. Experiments on the Guangzhou data set demonstrate that the MTL-CD method effectively detects fine-grained “from–to” changes and outperforms the postclassification methods and the direct change detection methods.},
keywords={Task analysis;Buildings;Semantics;Feature extraction;Image segmentation;Remote sensing;Architecture;Building changes;deep multitask learning;fine-grained change detection;fully convolutional neural network (FCN);semantic segmentation},
doi={10.1109/LGRS.2020.3018858},
ISSN={1558-0571},
month={},}
@ARTICLE{9362227,
author={Sun, Haijiang and Liu, Qiaoyuan and Wang, Jiacheng and Ren, Jinchang and Wu, Yanfeng and Zhao, Huimin and Li, Huakang},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Fusion of Infrared and Visible Images for Remote Detection of Low-Altitude Slow-Speed Small Targets},
year={2021},
volume={14},
number={},
pages={2971-2983},
abstract={Detection of the low-altitude and slow-speed small (LSS) targets is one of the most popular research topics in remote sensing. Despite of a few existing approaches, there is still an accuracy gap for satisfying the practical needs. As the LSS targets are too small to extract useful features, deep learning based algorithms can hardly be used. To this end, we propose in this article an effective strategy for determining the region of interest, using a multiscale layered image fusion method to extract the most representative information for LSS-target detection. In addition, an improved self-balanced sensitivity segment model is proposed to detect the fused LSS target, which can further improve both the detection accuracy and the computational efficiency. We conduct extensive ablation studies to validate the efficacy of the proposed LSS-target detection method on three public datasets and three self-collected datasets. The superior performance over the state of the arts has fully demonstrated the efficacy of the proposed approach.},
keywords={Object detection;Feature extraction;Image segmentation;Image fusion;Sensitivity;Meteorology;Lighting;Background subtraction;image fusion;low-altitude and slow-speed small (LSS) target detection;saliency detection},
doi={10.1109/JSTARS.2021.3061496},
ISSN={2151-1535},
month={},}
@INPROCEEDINGS{8866155,
author={Chen, Lushen and Yang, Qiang and Yan, Wenjun},
booktitle={2019 Chinese Control Conference (CCC)}, title={Generative Adversarial Network based Data Augmentation for PV Module Defect Pattern Analysis},
year={2019},
volume={},
number={},
pages={8422-8427},
abstract={In order to solve the problem of insufficient defective images of photovoltaic (PV) modules, more advanced image augmentation technique is required to augment the available dataset. This paper proposed a mixed model consisting of Wasserstein generative adversarial network (WGAN) and a method judging convergence, which based on the PV module defective images obtained by unmanned aerial vehicles (UAVs). The performance of the adopted WGAN is validated in comparison with two existing models through extensive experiments. In addition, the generated images are evaluated by the convolutional neural network (CNN) classifier as a supplementary dataset for the model training process. The numerical result demonstrates the feasibility of the generated images in data augmentation.},
keywords={Feature extraction;Training;Kernel;Photovoltaic systems;Convolution;Generators;mixed model;PV module defects;Wasserstein generative adversarial networks;kernel maximum mean discrepancy},
doi={10.23919/ChiCC.2019.8866155},
ISSN={1934-1768},
month={July},}
@ARTICLE{9288901,
author={Wang, Yufeng and Ding, Wenrui and Zhang, Ruiqian and Li, Hongguang},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Boundary-Aware Multitask Learning for Remote Sensing Imagery},
year={2021},
volume={14},
number={},
pages={951-963},
abstract={Semantic segmentation and height estimation play fundamental roles in the scene understanding of remote sensing images with their wide variety of aerial applications. Recently, deep convolutional neural networks (DCNNs) have achieved state-of-the-art performance in both tasks. However, DCNN-based methods learn to accumulate contextual information over large receptive fields while lose the local detailed information, resulting in blurry object boundaries. The complicated ground object distribution and low interclass variance further aggravate the difficulty in generating accurate predictions. To address the above-mentioned issues, we propose a novel boundary-aware multitask learning (BAMTL) framework to perform three tasks, semantic segmentation, height estimation, and boundary detection, within a unified model. The boundary detection is employed as an auxiliary task to regularize the other two master tasks at both the feature space and output space. We present a boundary attentive module to build the cross-task interaction for master tasks, which enforce the networks to filter out the confident area and focus on learning the high-frequency details. We then introduce a boundary regularized loss term to further refine the prediction maps to be locally consistent while preserving boundary structures. With these formulations, our model improves the performance of both segmentation and height tasks, especially along the boundaries. Experimental results on two publicly available remote sensing datasets demonstrate that the proposed approach performs favorably against the state-of-the-art methods.},
keywords={Task analysis;Remote sensing;Semantics;Image segmentation;Estimation;Feature extraction;Earth;Boundary regularization (BR);convolutional neural network (CNN);height estimation;multitask learning (MTL);remote sensing imagery (RSI);scene understanding;semantic segmentation},
doi={10.1109/JSTARS.2020.3043442},
ISSN={2151-1535},
month={},}
@INPROCEEDINGS{9013564,
author={Taleb, Tarik and Bensalem, Djamel Eddine and Laghrissi, Abdelquoddouss},
booktitle={2019 IEEE Global Communications Conference (GLOBECOM)}, title={Smart Service-Oriented Clustering for Dynamic Slice Configuration},
year={2019},
volume={},
number={},
pages={1-6},
abstract={The fifth generation (5G) and beyond wireless networks are foreseen to operate in a fully automated manner, in order to fulfill the promise of ultra-short latency, meet the exponentially increasing resource requirements, and offer the quality of experience (QoE) expected from end- users. Among the ingredients involved in such environments, network slicing enables the creation of logical networks tailored to support specific application demands (i.e., service level agreement SLA, quality of service QoS, etc.) on top of physical infrastructure. This creates the need for mechanisms that can collect spatiotemporal information on users' service consumption, and identify meaningful insights and patterns, leveraging machinelearning techniques. In this vein, our paper proposes a framework dubbed "SOCL" for the Service Oriented CLustering, analysis and profiling of users (i.e., humans, sensors, etc.) when consuming enhanced Mobile BroadBand (eMBB) applications, internet of things (IoT) services, and unmanned aerial vehicles services (UAVs). SOCL relies mainly on the realistic network simulation framework "network slice planner" (NSP), and two clustering methods namely K-means and hierarchical clustering. The obtained results showcase interesting features, highlighting the benefit of the proposed framework.},
keywords={5G mobile communication;Social network services;Sensors;Clustering methods;Cloud computing;Streaming media;Instant messaging},
doi={10.1109/GLOBECOM38437.2019.9013564},
ISSN={2576-6813},
month={Dec},}
@INPROCEEDINGS{8986281,
author={Tsuyama, Masahiko and Oki, Takuro and Kobayashi, Shingo and Aoki, Risako and Miyamoto, Ryusuke and Yomo, Hiroyuki and Hara, Shinsuke},
booktitle={2019 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)}, title={Embedded Implementation of Human Detection Using Only Color Features on the NVIDIA Xavier},
year={2019},
volume={},
number={},
pages={1-2},
abstract={The authors are developing a novel vital sensing system for real-time exercises using image-assisted routing (IAR), which requires the accurate detection of humans wearing sensor nodes in aerial images captured by a camera mounted on an UAV for sensor localization. To achieve real-time human detection for IAR, this paper proposes the embedded implementation of an accurate human detection scheme, which is constructed with informed filters using only color features and can achieve higher accuracy than deep learning for sports scenes. The experimental results for the actual aerial images of a sports scene revealed that our implementation on the NVIDIA Jetson Xavier board could process a 3840×2160 imaae in annroximatelv 44.93 ms.},
keywords={Human detection;edge computing;informed-filters;NVIDIA Jetson Xavier},
doi={10.1109/ISPACS48206.2019.8986281},
ISSN={2642-3529},
month={Dec},}
@ARTICLE{9360811,
author={Nawaz, Syed Junaid and Sharma, Shree Krishna and Mansoor, Babar and Patwary, Mohammad N. and Khan, Noor M.},
journal={IEEE Access}, title={Non-Coherent and Backscatter Communications: Enabling Ultra-Massive Connectivity in 6G Wireless Networks},
year={2021},
volume={9},
number={},
pages={38144-38186},
abstract={With the commencement of the 5th generation (5G) of wireless networks, researchers around the globe have started paying their attention to the imminent challenges that may emerge in the beyond 5G (B5G) era. Various revolutionary technologies and innovative services are offered in 5G networks, which, along with many principal advantages, are anticipated to bring a boom in the number of connected wireless devices and the types of use-cases that may cause the scarcity of network resources. These challenges partly emerged with the advent of massive machine-type communications (mMTC) services, require extensive research innovations to sustain the evolution towards enhanced-mMTC (e-mMTC) with the scalable network cost in 6th generation (6G) wireless networks. Towards delivering the anticipated massive connectivity requirements with optimal energy and spectral efficiency besides low hardware cost, this paper presents an enabling framework for 6G networks, which utilizes two emerging technologies, namely, non-coherent communications and backscatter communications (BsC). Recognizing the coherence between these technologies for their joint potential of delivering e-mMTC services in the B5G era, a comprehensive review of their state-of-the-art is conducted. The joint scope of non-coherent and BsC with other emerging 6G technologies is also identified, where the reviewed technologies include unmanned aerial vehicles (UAVs)-assisted communications, visible light communications (VLC), quantum-assisted communications, reconfigurable large intelligent surfaces (RLIS), non-orthogonal multiple access (NOMA), and machine learning (ML)-aided intelligent networks. Subsequently, the scope of these enabling technologies for different device types (e.g., UAVs, body implants, etc), service types (e.g., e-mMTC), and optimization parameters (e.g., spectrum, energy, cost) is analyzed. Finally, in the context of the proposed non-coherent and BsCs based framework for e-mMTCs, some promising future research directions and open research challenges are highlighted.},
keywords={6G mobile communication;NOMA;5G mobile communication;Wireless networks;Physical layer;Visible light communication;Backscatter;5G;6G;B5G;backscatter;IoT;mMTC;non-coherent},
doi={10.1109/ACCESS.2021.3061499},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9249561,
author={Kakamoukas, Georgios and Sarigiannidis, Panagiotis and Moscholios, Ioannis},
booktitle={2020 12th International Symposium on Communication Systems, Networks and Digital Signal Processing (CSNDSP)}, title={Towards Protecting Agriculture from Exogenous and Endogenous Factors: An Holistic Architecture},
year={2020},
volume={},
number={},
pages={1-4},
abstract={An holistic architecture that fosters the application of Smart Farming (SF) in the context of agriculture is proposed in this paper. The proposed architecture exploits the benefits of Internet of Things (IoT), by utilizing a) Wireless Sensor Networks (WSN) for real time monitoring and b) Unmanned Aerial Vehicles (UAVs) / flying Ad-hoc Networks (FANETs) for macroscopic monitoring of the field and inspecting the crops using multispectral cameras. The aggregated data coming from the monitoring process feed the cloud infrastructure, where Machine Learning (ML) and Computer Vision (CV) techniques are applied in order to protect plants from exogenous (e.g., pests) and endogenous (e.g., diseases) factors.},
keywords={Wireless sensor networks;Computer architecture;Ad hoc networks;Unmanned aerial vehicles;Real-time systems;Internet of Things;Monitoring;unmanned aerial vehicles;smart farming;flying ad-hoc networks;wireless sensor networks;plant protection},
doi={10.1109/CSNDSP49049.2020.9249561},
ISSN={},
month={July},}
@ARTICLE{9652086,
author={Liao, Haijun and Wang, Zhao and Zhou, Zhenyu and Wang, Yang and Zhang, Hui and Mumtaz, Shahid and Guizani, Mohsen},
journal={IEEE Journal of Selected Topics in Signal Processing}, title={Blockchain and Semi-Distributed Learning-Based Secure and Low-Latency Computation Offloading in Space-Air-Ground-Integrated Power IoT},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Power systems impose stringent security and delay requirements on computation offloading, which cannot be satisfied by existing power Internet of Things (PIoT) networks. In this paper, we tackle this challenge by combining blockchain, space-air-ground integrated PIoT (SAG-PIoT) and machine learning. Low earth orbit (LEO) satellites assist in broadcasting consensus message to reduce the block creation delay, and unmanned aerial vehicles (UAVs) provide flexible coverage enhancement. Specifically, we propose a Blockchain and semi-distributed leaRning-based secure and low-latency electromAgnetic interferenCe-awarE computation offloading algorithm (BRACE) to minimize the total queuing delay under the long-term security constraint. First, task offloading is decoupled from computational resource allocation by Lyapunov optimization. Second, the task offloading problem is solved by the proposed federated deep actor-critic-based electromagnetic interference-aware task offloading algorithm (FDAC-EMI). Finally, the resource allocation problem is solved by smooth approximation and Lagrange optimization. Simulation results verify that BRACE achieves superior delay and security performance.},
keywords={Task analysis;Servers;Security;Delays;Computational modeling;Blockchains;Electromagnetic interference;Space-air-ground-integrated power IoT (SAGPIoT);computation offloading;blockchain;semi-distributed learning;electromagnetic interference awareness},
doi={10.1109/JSTSP.2021.3135751},
ISSN={1941-0484},
month={},}
@INPROCEEDINGS{8323850,
author={Van Dinh, Dzung and Yoon, Byeong-Nam and Le, Hung Ngoc and Nguyen, Uy Quoc and Dang Phan, Khoa and Dinh Pham, Lam},
booktitle={2018 20th International Conference on Advanced Communication Technology (ICACT)}, title={ICT enabling technologies for smart cities},
year={2018},
volume={},
number={},
pages={606-611},
abstract={A smart city adjusts its social, business, and natural needs, improving the assets it has accessible. Information and Communications Technology (ICT) for shrewd urban areas is to give city answers for encourage an improvement and manageability of a city for the advantage of its population, its economy, and the greater ecosystem in the city. It is to gauge a keen city as far as the enhancements in personal satisfaction and monetary prosperity that are accomplished through applying ICT innovations to design, outline, fabricate, and work the city foundation. In smart city applications, the initial phase in the information's voyage through the application is its gathering by the diverse advancements conveyed all through the city. This paper surveys data acquisition technologies such as Sensor Networks, MANETs, Unmanned Aerial Vehicles (UAVs), Vehicular Ad hoc Networks (VANETs), Internet of Things (IoT), Software-Defined Networking (SDN), Network Functions Virtualization (NFV), 5G. Next, it demonstrates information processing technologies, for example, Cloud Platform, IoT Platform, Big Data Platform, Machine Learning, Deep Learning, and IoT Analytics. Encouraging data spread between various nodes is vital to savvy city acknowledgment. Last, because of the presence of various types of end users (e.g., residents, organizations, government offices, and so forth.) requiring distinctive levels of nature of management, the paper exhibits a proposed testbed solution and recent associated experiments.},
keywords={Wireless sensor networks;Cloud computing;Smart cities;5G mobile communication;Network function virtualization;Virtualization;IoT;SDN;NFV;5G;Cloud Platform;IoT Platform;Big Data Platform;IoT Analytics},
doi={10.23919/ICACT.2018.8323850},
ISSN={},
month={Feb},}
@INPROCEEDINGS{9155522,
author={Rashid, Md Tahmid and Zhang, Daniel Yue and Wang, Dong},
booktitle={IEEE INFOCOM 2020 - IEEE Conference on Computer Communications}, title={SocialDrone: An Integrated Social Media and Drone Sensing System for Reliable Disaster Response},
year={2020},
volume={},
number={},
pages={218-227},
abstract={Social media sensing has emerged as a new disaster response application paradigm to collect real-time observations from online social media users about the disaster status. Due to the noisy nature of social media data, the task of identifying trustworthy information (referred to as "truth discovery") has been a crucial task in social media sensing. However, existing truth discovery solutions often fall short of providing accurate results in disaster response applications due to the spread of misinformation and difficulty of an efficient verification in such scenarios. In this paper, we present SocialDrone, a novel closed-loop social-physical active sensing framework that integrates social media and unmanned aerial vehicles (UAVs) for reliable disaster response applications. In SocialDrone, signals emitted from the social media are distilled to drive the drones to target areas to verify the emergency events. The verification results are then taken back to improve the sensing and distillation process on social media. The SocialDrone framework introduces several unique challenges: i) how to drive the drones using the unreliable social media signals? ii) How to ensure the system is adaptive to the high dynamics from both the physical world and social media? iii) How to incorporate real-world constraints (e.g., the deadlines of events, limited number of drones) into the framework? The SocialDrone addresses these challenges by building a novel integrated social-physical sensing system that leverages techniques from game theory, constrained optimization, and reinforcement learning. The evaluation results on a real-world disaster response application show that SocialDrone significantly outperforms state-of-the-art truth discovery schemes and drone-only solutions by providing more effective disaster response.},
keywords={Social network services;Sensors;Drones;Reliability;Task analysis;Real-time systems;Fires},
doi={10.1109/INFOCOM41043.2020.9155522},
ISSN={2641-9874},
month={July},}
@ARTICLE{8976241,
author={Wang, Wuwei and Zhang, Ke and Lv, Meibo and Wang, Jingyu},
journal={IEEE Transactions on Cybernetics}, title={Hierarchical Spatiotemporal Context-Aware Correlation Filters for Visual Tracking},
year={2021},
volume={51},
number={12},
pages={6066-6079},
abstract={Discriminative correlation filters (DCF)-based trackers have been increasingly applied to visual tracking due to their high precision while running at high frame rates. However, most recent DCF-based methods solely concentrate on learning the correlation filter with spatial information and thus do not have sufficient descriptive power to discriminate the target from the background in the complex circumstances, such as full occlusion (OCC) and rapid target variation. In this article, we introduce a novel tracking framework that exploits the relationship between the target and its spatiotemporal context to improve tracking accuracy and robustness. Especially, we present our spatiotemporal context model in a hierarchical way, where each layer of the context pyramid is a spatial correlation filter learned from different temporal instances. For gaining an accurate spatiotemporal model, we propose an optimization fusion approach that can adaptively and efficiently learn the effect of each hierarchical layer and exploit these multiple temporal levels of correlation filters for visual tracking. Moreover, an adaptive model update strategy for correlation filters is introduced into the framework to dynamically select proper hierarchical layers, which boosts the temporal diversity of the target appearance, while radically reduces the number of model parameters and guarantees the real-time performance of the tracking method. The experimental results show that, with conventional handcrafted features, our tracker achieves the best success rates among available state-of-the-art trackers with handcrafted features, and provides state-of-the-art performance comparable to those of deep-learning-based trackers on OTB-2013, OTB-2015, VOT-2016, and UAV-20L benchmarks but runs significantly faster than deep trackers.},
keywords={Target tracking;Visualization;Spatiotemporal phenomena;Adaptation models;Training data;Discriminative correlation filter (DCF);hierarchical spatiotemporal context (HSTC);online model update;visual tracking},
doi={10.1109/TCYB.2020.2964757},
ISSN={2168-2275},
month={Dec},}
@INPROCEEDINGS{8453948,
author={Prokhorenkov, Dmitry and Panfilov, Petr},
booktitle={2018 IEEE 20th Conference on Business Informatics (CBI)}, title={Notice of Violation of IEEE Publication Principles: Discovery of Technology Trends from Patent Data on the Basis of Predictive Analytics},
year={2018},
volume={02},
number={},
pages={148-152},
abstract={Companies are increasingly paying close attention to the IP portfolio, which is a key competitive advantage, so patents and patent applications, as well as analysis and identification of future trends, become one of the important and strategic components of a business strategy. We argue that the problems of identifying and predicting trends or entities, as well as the search for technical features, can be solved with the help of easily accessible Big Data technologies, machine learning and predictive analytics, thereby offering an effective plan for development and progress. The purpose of this study is twofold, the first is an identification of technological trends, the second is an identification of application areas and/or that are most promising in terms of technology development and investment. The research was based on methods of clustering, processing of large text files and search queries in patent databases. The suggested approach is considered on the basis of experimental data in the field of moving connected UAVs and passive acoustic ecology control.},
keywords={},
doi={10.1109/CBI.2018.10062},
ISSN={2378-1971},
month={July},}
@INPROCEEDINGS{8578284,
author={Sironi, Amos and Brambilla, Manuele and Bourdis, Nicolas and Lagorce, Xavier and Benosman, Ryad},
booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, title={HATS: Histograms of Averaged Time Surfaces for Robust Event-Based Object Classification},
year={2018},
volume={},
number={},
pages={1731-1740},
abstract={Event-based cameras have recently drawn the attention of the Computer Vision community thanks to their advantages in terms of high temporal resolution, low power consumption and high dynamic range, compared to traditional frame-based cameras. These properties make event-based cameras an ideal choice for autonomous vehicles, robot navigation or UAV vision, among others. However, the accuracy of event-based object classification algorithms, which is of crucial importance for any reliable system working in real-world conditions, is still far behind their frame-based counterparts. Two main reasons for this performance gap are: 1. The lack of effective low-level representations and architectures for event-based object classification and 2. The absence of large real-world event-based datasets. In this paper we address both problems. First, we introduce a novel event-based feature representation together with a new machine learning architecture. Compared to previous approaches, we use local memory units to efficiently leverage past temporal information and build a robust event-based representation. Second, we release the first large real-world event-based dataset for object classification. We compare our method to the state-of-the-art with extensive experiments, showing better classification performance and real-time computation.},
keywords={Cameras;Computer architecture;Computer vision;Feature extraction;Robot vision systems;Standards;Detectors},
doi={10.1109/CVPR.2018.00186},
ISSN={2575-7075},
month={June},}
@ARTICLE{9513316,
author={Flak, Przemysław},
journal={IEEE Access}, title={Drone Detection Sensor With Continuous 2.4 GHz ISM Band Coverage Based on Cost-Effective SDR Platform},
year={2021},
volume={9},
number={},
pages={114574-114586},
abstract={The development of Unmanned Aerial Vehicles (UAVs), commonly referred to as drones, has introduced revolutionary changes in many areas over the past few years. However, aside from opening new possibilities, the usage of drones in an irresponsible and dangerous manner leads to many hazardous incidents. This paper presents a drone detection sensor with a continuous 2.400 GHz-2.483 GHz operational frequency range for detection methods based on passive radio frequency imaging techniques. The implementation based on Software Defined Radio (SDR) and Field Programmable Logic Array (FPGA) hardware that overcomes the 40 MHz real-time bandwidth limit of other popular SDRs is presented utilizing low-cost off-the-shelf components. Furthermore, a hardware realization of the signal processing chain for specific detection algorithms is proposed to minimize the throughput between SDR and the companion computer and offload software computations. The device validation is made in a laboratory and real-life scenario and presented in relation to the sensor used in other works. In addition to the increased real-time bandwidth, the measurements show a 9 dB reduction in detection sensitivity compared to the reference receiver, in line with the analog RF front-end specifications. The final analysis demonstrates the proposed device’s relevance as a sensor for obtaining machine learning datasets and as a part of a final anti-drone system.},
keywords={Drones;Radio frequency;Software;Field programmable gate arrays;Bandwidth;Hardware;Universal Serial Bus;Drones;field programmable gate array;software defined radio;surveillance;unmanned aerial vehicles},
doi={10.1109/ACCESS.2021.3104738},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9066161,
author={Romero, Daniel and Leus, Geert},
booktitle={2019 15th International Conference on Mobile Ad-Hoc and Sensor Networks (MSN)}, title={Non-Cooperative Aerial Base Station Placement via Stochastic Optimization},
year={2019},
volume={},
number={},
pages={131-136},
abstract={Autonomous unmanned aerial vehicles (UAVs) with on-board base station equipment can potentially provide connectivity in areas where the terrestrial infrastructure is overloaded, damaged, or absent. Use cases comprise emergency response, wildfire suppression, surveillance, and cellular communications in crowded events to name a few. A central problem to enable this technology is to place such aerial base stations (AirBSs) in locations that approximately optimize the relevant communication metrics. To alleviate the limitations of existing algorithms, which require intensive and reliable communications among AirBSs or between the AirBSs and a central controller, this paper leverages stochastic optimization and machine learning techniques to put forth an adaptive and decentralized algorithm for AirBS placement without inter-AirBS cooperation or communication. The approach relies on a smart design of the network utility function and on a stochastic gradient ascent iteration that can be evaluated with information available in practical scenarios. To complement the theoretical convergence properties, a simulation study corroborates the effectiveness of the proposed scheme.},
keywords={Optimization;Base stations;Atmospheric modeling;Quality of service;Stochastic processes;Real-time systems;Measurement;aerial communications;unmanned aerial vehicles;aerial base stations;stochastic optimization;stochastic gradient;autonomous aerial vehicles},
doi={10.1109/MSN48538.2019.00036},
ISSN={},
month={Dec},}
@ARTICLE{9020292,
author={Li, Zan and Ding, Zhiguo and Shi, Jia and Saad, Walid and Yang, Lie-Liang},
journal={China Communications}, title={Guest editorial: Artificial intelligence (AI)-driven spectrum management},
year={2020},
volume={17},
number={2},
pages={iii-v},
abstract={Recent advances in communication and networking technologies are leading to a plethora of novel wireless services that range from unmanned aerial vehicle (UAV) communication to smart cognitive networks and massive Internet of Things (IoT) systems. Enabling these emerging applications over the fifth generation (5G) of wireless cellular systems requires meeting numerous challenges pertaining to spectrum sharing and management. In fact, most 5G applications will be highly reliant on intelligent spectrum management techniques, which should adapt to dynamic network environments while also guaranteeing high reliability and high quality-of-experience (QoE). In this context, the use of artificial intelligence (AI) techniques that include deep learning, convolutional neural networks, and reinforcement learning, among many others, is expected to play a very important role in paving the way towards truly AI-driven spectrum management, thus enabling tomorrow's smart city services. Therefore, it has become imperative to investigate and apply AI techniques to solve emerging spectrum management problems in various wireless networks. This includes leveraging AI to address a wide range of wireless networking challenges ranging from network management to dynamic spectrum sharing and resource management.},
keywords={},
doi={10.23919/JCC.2020.9020292},
ISSN={1673-5447},
month={Feb},}
@ARTICLE{9566520,
author={Chen, Wanshi and Demirkol, Ilker and Mostafa, Miraj and Perotti, Alberto},
journal={IEEE Communications Magazine}, title={Series Editorial: Mobile Communications and Networks},
year={2021},
volume={59},
number={9},
pages={50-50},
abstract={One of the most exciting aspects of mobile networks is their continuing expansion into new application domains, which is made possible by incorporating upfront technologies, by evolving toward new architectures and making available new cutting-edge features. This issue of the Mobile Communications and Networks Series offers a collection of interesting contributions on different subjects: security aspects of wireless localization, Quality of Service (QoS) in Vehicle-to-Everything (V2X) communication, retail delivery by Unmanned Aerial Vehicles (UAV), and distributed machine learning in mobile networks. The articles show the impressive advances of the mobile communication technology.},
keywords={Special issues and sections;Mobile communications;Network systems},
doi={10.1109/MCOM.2021.9566520},
ISSN={1558-1896},
month={Sep.},}
@INPROCEEDINGS{7208614,
author={},
booktitle={2015 IEEE Symposium on Computational Intelligence for Security and Defense Applications (CISDA)}, title={[Front cover]},
year={2015},
volume={},
number={},
pages={1-1},
abstract={The following topics are dealt with: swarm intelligence; real-time asset allocation; UAV; sensor resource management; dynamic asset allocation; neuromemristive echo state networks; speech-emotion recognition; memristor crossbar array; cognitive radio decision making; automatic signal classification techniques; software defined radios; CMOS analog neuron; neural networks; mobile ad-hoc networks; wireless OFDM systems; secure systems; machine learning; and ZigBee devices.},
keywords={},
doi={10.1109/CISDA.2015.7208614},
ISSN={2329-6275},
month={May},}
@INPROCEEDINGS{7368734,
author={},
booktitle={2015 First International Conference on New Technologies of Information and Communication (NTIC)}, title={[Front cover]},
year={2015},
volume={},
number={},
pages={c1-c1},
abstract={The following topics are dealt with: MANET; target tracking; VANET; V2V communication; packet load enhancement; ad hoc routing protocol simulation; VolP traffic support; mobile ad hoc networks; path planning; fixed wing UAV formation; ARTI taxonomy; cyber-attack framework; enhancement optimized MAC protocol; block design multichannel MAC protocol; WSN; PAPR reduction; STBC MIMO-OFDM systems; 4G wireless communications; PTS scheme; SCADA open protocol PUR 2.4; smart walk mechanism; unstructured mobile P2P networks; BLE-based data collection system; Finger-Knuckle-print identification; SVM classifier; optimal object-oriented image classification; MLLH approach; image denoising algorithm; multireprsentation palmprint image; automatic personnel identification; optimized audio watermarking scheme; swarm intelligence; speech synthesis; Arabic language; model transformation; time-extended multirobot task allocation problem; Web applications; model-based approach; Chi-Square test; heuristic search; metamorphic malware detection; materialized view definition; semantic Web service; content-based dermoscopic image retrieval; and fuzzy labeled transitions system.},
keywords={},
doi={10.1109/NTIC.2015.7368734},
ISSN={},
month={Nov},}
@INPROCEEDINGS{6363367,
author={},
booktitle={2012 Brazilian Robotics Symposium and Latin American Robotics Symposium}, title={[Title page i]},
year={2012},
volume={},
number={},
pages={i-i},
abstract={The following topics are dealt with: reinforcement learning; navigation; artificial vision; robot programming; inverse robot kinematics; grid mapping; visual SLAM; quadricopter; robotic communication; cooperative robots; swarm formation; multi-robot routing; indoor navigation; outdoor navigation; inverted pendulum mobile robots; face recognition; UAV trajectory planning; rehabilitation and assistive robot; robot soccer; obstacle avoidance; helicopter navigation; leader-follower formation; robotic wheelchair; swarm intelligence; humanoid robots; and BIBOT.},
keywords={},
doi={10.1109/SBR-LARS.2012.1},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6161540,
author={},
booktitle={2011 50th IEEE Conference on Decision and Control and European Control Conference}, title={Content list of 50th IEEE conference on decision and control and European control conference},
year={2011},
volume={},
number={},
pages={1-158},
abstract={The following topics are dealt with: system identification; customer side control; customer side management; fault detection; reinforcement learning; networked control system; game theory; optimal control; nonlinear system stability; adaptive control system; discrete event system; switched system; linear system; predictive control; distributed parameter system; robust control; robotics; stochastic system; autonomous system; decision making; electrical machine control; time-varying system; cooperative control; smart grid integration; Kalman filtering; integrated vehicle dynamics; event-triggered control; unmanned aerial vehicle delay system; distribution-retail level cyber enabled demand management; communication system control; Lyapunov method; fuzzy system; sampled data control; H infinity control; and sliding mode control.},
keywords={},
doi={10.1109/CDC.2011.6161540},
ISSN={0743-1546},
month={Dec},}
@INPROCEEDINGS{5705921,
author={},
booktitle={2010 IEEE International Conference on Computational Intelligence and Computing Research}, title={[Title page]},
year={2010},
volume={},
number={},
pages={i-i},
abstract={The following topics are dealt with: orthogonal code; fault tolerant wormhole routing; consensus clustering algorithm; routing protocol; image processing; evolutionary computation; cryptographic solution; unmanned aerial vehicle; biometrics; blind speech separation; power system load forecasting; energy efficiency; fuzzy logic controller design; soft computing; neural network; language identification; wireless sensor network; word segmentation; machine learning; speed control; semantic Web and patient diagnosis.},
keywords={},
doi={10.1109/ICCIC.2010.5705921},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7849607,
author={},
booktitle={2016 6th International Conference on System Engineering and Technology (ICSET)}, title={[Front cover]},
year={2016},
volume={},
number={},
pages={c1-c1},
abstract={The following topics are dealt with: secure instant messaging; Android; cloud-based application; data compression; Internet of Things; neural network; machine learning; unmanned aerial vehicle; public key infrastructure; optimization; flood monitoring; hidden Markov model; e -learning; traffic conditions visualization; humanoid robot; and support vector machine.},
keywords={},
doi={10.1109/ICSEngT.2016.7849607},
ISSN={2470-640X},
month={Oct},}
@INPROCEEDINGS{7859658,
author={},
booktitle={2016 International Conference on Intelligent Control Power and Instrumentation (ICICPI)}, title={[Front cover]},
year={2016},
volume={},
number={},
pages={1-1},
abstract={The following topics are dealt with: parametric robust control; electromagnetic levitation system; multi-objective controller; MIMO coupled tank system; heavy symmetric chaotic unknown gyroscope; MQRBVSC; position control; DC motor system; periodic reference input tracking; data driven paradigm; self-tuning fuzzy PID controller; inverted pendulum; crane mode operation; h-infinity robust controller; DC servo motor system; randomized algorithm; robust controller design; controller servo speed control system; human-computer interaction; intelligent control; unmanned aerial vehicle; Internet of Things: polyphenol content; NIR spectroscopy; tea samples classification; SVM; machine learning component; e-tongue; ECG waveform synthesis; real time heart rate detection; PPG signal; SVD based tea quality prediction; electronic tongue signal; voice recognition based wireless room automation system; electric stress analysis; QCM; sensor tomatoes; routing protocols; MANET; semi-empirical optimization; vertical channel doping profile; field effect transistor; classifier fusion; spectral data; patient health monitoring system; mathematical morphology aided enhancement; T2-weighted brain MRI images; portable galvanic skin response acquisition and analysis system; FIS incorporated microcontroller based MCB; discrete mode AGC; restructured power system; P-I controller; governor dead-band nonlinearity; power-factor-correction boost converter; nonlinear dynamics; CHP based DG; radial distribution network; off-line voltage security assessment power transmission systems; UVSI artificial neural network; dynamic state estimation solution; PMUs; medium voltage cable termination; electric stress analysis; DWT based fault detection; BPNN based fault detection; HVAC transmission line; smart grids; FPGA-based design; DTC regenerative braking control; induction motor drive; SCT based deadbeat control; power system stability improvement; time delay compensation; PMDC motor; backward arc length approach; reduced switch topology based harmonic current compensator; rural autonomous grid; AHP method; SSSC device; modern combined cycle power plant; LED based lighting system; hybrid PSO-ACO algorithm; economic load dispatch problem small scale power system; in-hop cooperative relays; trajectory-based forwarding; dense wireless sensor networks; bluetooth based sophisticated home automation system; smartphone; cross-correlation based feature extraction; EMG signals; neuro-muscular disease classification; secure DSSS multiuser detection; improved node localization algorithm; anisotropic wireless sensor networks; advanced transaction models; flow-through exception handling; attack sensor; ball mouse encoder wheel; lower limb exoskeleton; induction motor; cross -correlation analysis based features; novel vision system; baggage localization; traffic sign detection and classification and colour feature.},
keywords={},
doi={10.1109/ICICPI.2016.7859658},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6643813,
author={},
booktitle={2013 5th International Conference on Intelligent Human-Machine Systems and Cybernetics}, title={[Copyright notice]},
year={2013},
volume={1},
number={},
pages={iv-iv},
abstract={The following topics are dealt with: laser ranging; target tracking; nonlinear inverted pendulum system; human motion reconstruction; high voltage switch cabinet; distribution network; software simulation experiment platform; robust H-infinite control; manipulators; QC-LDPC codes; image processing; fuzzy beliefs; data mining; cloud environment; genetic algorithm; training system; glowworm swarm optimization algorithm; path planning; unmanned aerial vehicle; neural networks; robots; fuzzy sets; object tracking; combat simulation; image encryption; micro-inverters; unmanned helicopter; human walking; pattern clustering; blood pressure measurement; wireless HART networks; and cyber-physical system.},
keywords={},
doi={10.1109/IHMSC.2013.3},
ISSN={},
month={Aug},}
@INPROCEEDINGS{7560548,
author={},
booktitle={2016 IEEE Information Technology, Networking, Electronic and Automation Control Conference}, title={Table of contents},
year={2016},
volume={},
number={},
pages={1-16},
abstract={The following topics are dealt with: MANET; radar signal processing; unmanned aerial vehicle; cloud computing; support vector machines; neural networks; cryptography; adaptive control; PID control; mobile robots; image processing; fuzzy control; power control; load forecasting; power grid; VANET; sliding mode control; LTE; MIMO communication; routing protocols; predictive control; neurocontrollers; wireless sensor networks; smart meters.},
keywords={},
doi={10.1109/ITNEC.2016.7560548},
ISSN={},
month={May},}
@ARTICLE{8633298,
author={},
journal={China Communications}, title={Artificial intelligence (AI)-driven spectrum management},
year={2019},
volume={16},
number={1},
pages={1-2},
abstract={Recent advances in communication and networking technologies are leading to a plethora of novel wireless services that range from unmanned aerial vehicle (UAV) communication to smart cognitive networks and massive Internet of Things (IoT) systems. Enabling these emerging applications over the fifth generation (5G) of wireless cellular systems requires meeting numerous challenges pertaining to spectrum sharing and management. In fact, most 5G applications will be highly reliant on intelligent spectrum management techniques, which should adapt to dynamic network environments while also guaranteeing high reliability and high quality-of-experience (QoE). In this context, the use of artificial intelligence (AI) techniques that include deep learning, convolutional neural networks, and reinforcement learning, among many others, is expected to play a very important role in paving the way towards truly AI-driven spectrum management, thus enabling tomorrow's smart city services. Therefore, it has become imperative to investigate and apply AI techniques to solve emerging spectrum management problems in various wireless networks. This includes leveraging AI to address a wide range of wireless networking challenges ranging from network management to dynamic spectrum sharing and resource management.},
keywords={},
doi={},
ISSN={1673-5447},
month={Jan},}
@ARTICLE{8734175,
author={},
journal={China Communications}, title={Call for papers — feature topic, vol. 16, No. 10, 2019},
year={2019},
volume={16},
number={5},
pages={1-1},
abstract={Recent advances in communication and networking technologies are leading to a plethora of novel wireless services that range from unmanned aerial vehicle (UAV) communication to smart cognitive networks and massive Internet of Things (IoT) systems. Enabling these emerging applications over the fifth generation (5G) of wireless cellular systems requires meeting numerous challenges pertaining to spectrum sharing and management. In fact, most 5G applications will be highly reliant on intelligent spectrum management techniques, which should adapt to dynamic network environments while also guaranteeing high reliability and high quality-of-experience (QoE). In this context, the use of artificial intelligence (AI) techniques that include deep learning, convolutional neural networks, and reinforcement learning, among many others, is expected to play a very important role in paving the way towards truly AI-driven spectrum management, thus enabling tomorrow's smart city services. Therefore, it has become imperative to investigate and apply AI techniques to solve emerging spectrum management problems in various wireless networks. This includes leveraging AI to address a wide range of wireless networking challenges ranging from network management to dynamic spectrum sharing and resource management.},
keywords={},
doi={},
ISSN={1673-5447},
month={May},}
@INPROCEEDINGS{7862986,
author={},
booktitle={2016 International Conference on Computer, Control, Informatics and its Applications (IC3INA)}, title={[Front cover]},
year={2016},
volume={},
number={},
pages={c1-c1},
abstract={The following topics are dealt with: Wi-Fi based temperature monitoring system; Kalman filter implementation; multiple robots visual SLAM; speed detection; image processing; vehicle classification; lane categorization; Stratix V DE5-Net FPGA board; high performance computing; discrete-time model-based controller; Bayesian Twitter-based prediction;timing estimation; normalized 4-th order moment; OFDM-based cognitive radio systems; software size measurement; knowledge management portal; scene text detection; IEEE 802.11n; IEEE 802.11ac; distributed order-up-to inventory management; uncertain demand-system modelling; predictor-based dynamic soft VSC; time-delay systems; magnitude-constrained input signal; heart rate prediction; cycling cadence; feedforward neural network; computer vision; autonomous UAV; spatial co-location pattern discovery; multiple neighborhood relationship function; Kansei based interface design analysis; open source e-learning system; high education; asset management system functionality; bitcoin platform; multi-label classification; deep belief networks; virtual screening; multi-target drug; cancer subtype identification; deep learning approach; fault-tolerant control; nonlinear systems; projection optimization; compressive sensing framework; industrial control system security-malware botnet detection; AUV high-precision path following control system; PD-controller; anomaly detection; computational optimization; violent scenes detection; educational institution DNS network traffic; circle detection; Hough transform; Mexican hat filter; multilink manipulators; super-symmetric particle classication; noise labelling; role-based programming; adaptive IoT applications; smart dog feeder design; DSS01 COBIT5; part-of-speech tagging; Bahasa Indonesia; 2D spatial interpolation; water quality parameter distribution; XQuery evaluation; SLIM+; advanced-simple lightweight and intuitive multicast protocol and MANET.},
keywords={},
doi={10.1109/IC3INA.2016.7862986},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7008079,
author={},
booktitle={2014 International Conference on Digital Image Computing: Techniques and Applications (DICTA)}, title={List of papers},
year={2014},
volume={},
number={},
pages={1-4},
abstract={The following topics are dealt with: Gaussian mixture model; depth map coding; high-precision image registration; quantization based watermarking approach; DCE-MRI prostate sequences; rank minimization; nuclear-norm minimization; CT reconstruction; medical image retrieval; sensor data fusion; moving object recognition; image-set based face recognition; image fusion; hyperspherical clustering; crowd event detection; video watermarking scheme; 3D planar patch reconstruction; distant object detection; pedestrian lane detection; reflective feature detection; image sequences; partial fingerprint matching; railway level crossing event detection; human action recognition; breast cancer magnetic resonance imaging; HEVC video coding; target detection; image registration; low-contrast infrared ship image segmentation; fuzzy inference system; 2D human pose tracking; skeleton representation; crowd behavior recognition; convolutional neural network; automatic aerial imagery analysis; regression Web testing; landmark detector system; multiresolution frontal faces; automatic building footprint extraction; LIDAR point cloud data; image quality evaluation index; supervised latent Dirichlet allocation models; activity representation; nonrigid 3D multimodal image registration algorithm; discriminative key pose extraction; multiple feature distance preserving model; saliency detection; automatic UAV forced landing site detection; machine learning; HEp-2 cell image clustering; robust visual tracking; infrared ship target image smoothing; and unsupervised image classification.},
keywords={},
doi={10.1109/DICTA.2014.7008079},
ISSN={},
month={Nov},}
@INPROCEEDINGS{7828270,
author={},
booktitle={2016 VI Brazilian Symposium on Computing Systems Engineering (SBESC)}, title={[Title page i]},
year={2016},
volume={},
number={},
pages={i-i},
abstract={The following topics are dealt with: non-convex optimization; UAV; augmented reality; virtual machines; Android business applications; machine learning; multiprocessors; programming languages; operating systems; FPGA-based embedded systems; wireless sensor networks; crowdsourcing; mobile devices; and LTE networks.},
keywords={},
doi={10.1109/SBESC.2016.001},
ISSN={2324-7894},
month={Nov},}
@INPROCEEDINGS{7065432,
author={},
booktitle={2014 The 1st International Conference on Information Technology, Computer, and Electrical Engineering}, title={Cover},
year={2014},
volume={},
number={},
pages={c1-c1},
abstract={The following topics are dealt with: DRAM; SoC architecture; wireless sensor network; robot manipulators; UAV navigation system; image processing; machine learning; cryptography; power systems; routing protocols.},
keywords={},
doi={10.1109/ICITACEE.2014.7065432},
ISSN={},
month={Nov},}
@INPROCEEDINGS{6731613,
author={},
booktitle={2013 International Conference on Control Communication and Computing (ICCC)}, title={Table of contents},
year={2013},
volume={},
number={},
pages={1-9},
abstract={The following topics are dealt with: observers; fault detection; nonlinear systems; support vector machines; object recognition; feedback control; UAV; image retrieval; neural networks; soft computing; color image enhancement; power saving; wireless ad hoc networks; optimal control; information retrieval; induction motor drive; microstrip patch antenna; medical images; EEG; human brain MRI; closed loop control; vehicle detection; target tracking; robots; MIMO systems; image watermarking; compressed sensing; antenna pointing system; and voice forgery detection.},
keywords={},
doi={10.1109/ICCC.2013.6731613},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8126817,
author={},
booktitle={2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)}, title={Table of contents},
year={2017},
volume={},
number={},
pages={xv-clii},
abstract={The following topics are dealt with: band selection; numerical weather modelling and data assimilation; land use applications; cross track and along track InSAR methods; multisatellite cross-track interferometry; companion SAR missions; change detection in hyperspectral and multispectral images; change detection in SAR images; spectral unmixing techniques; microwave radiometer calibration; synthetic aperture microwave radiometers; optical sensor calibration and applications; active/passive snow and ice; sea ice; emerging industry remote sensing activities; intelligence for big geospatial data; ocean surface wind; ocean surface current and wave; international spaceborne imaging spectroscopy missions; SAR and InSAR methods; calibration and validation of space-borne imaging and radiometer systems; advanced remote sensing instrumentation and its applications; target detection and unmixing of hyperspectral images; high resolution classification methods; data reduction methods; SAR image segmentation; multisource data classification; forest monitoring applications; deep networks for detection and recognition; ship and road detection; TANDEM-X; differential SAR interferometry applications; SAR data processing and DEM; polarimetric techniques; bistatic SAR; VHR images; image time series; wetlands remote sensing; IEEE GRSS data fusion; microwave remote sensing; radio frequency interference; LIDAR processing; NASA SNOWEX campaign; ocean remote sensing; radar and thermal data for urban monitoring; SMOS soil moisture; hydrologic applications; remote sensing for energy applications; urban and peri-urban area mapping; road and traffic detection; ship, vessel and spill detection; advanced microwave instruments; clustering and unsupervised methods; kernel-based classification; deep and convolutional neural networks; spatial feature detection and extraction; object detection and recognition; SAR speckle filtering; SAR moving target imaging; SAR image formation and compressive sensing; Advanced Land Observing Satellite-2 mission; Global Navigation Satellite System Reflectometry Spaceborne Missions; global precipitation measurement instruments and algorithms; small satellite technology; joint polar satellite system; ice sheets and glaciers; forest monitoring; vegetation; optical radiometry; ocean salinity; ocean temperature; coastal impacts; Latin America activities in remote sensing; global scale spectroscopy; ground-based sensing; estimation and regression applications; GNSS-R Sensors; agriculture applications; wind and precipitation radar; atmospheric sounding and ionospheric effects; geoscience remote sensing; geo energy; minerals; clouds and precipitation; POLSAR classification; GPR system; land cover dynamics; pansharpening techniques; COSMO-SKYMED; RADARSAT-2; COPERNICUS SENTINEL-1 MISSION; geographic information science; water management; GCOM status; topography;geology; geomorphology; flooding; inland waters; biomass and monitoring; tomography and 3D mapping; UAV and airborne platforms; aerosols and atmospheric chemistry; data management, policy decisions and education.},
keywords={},
doi={10.1109/IGARSS.2017.8126817},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{7985742,
author={},
booktitle={2017 3rd IEEE International Conference on Cybernetics (CYBCONF)}, title={Table of contents},
year={2017},
volume={},
number={},
pages={1-6},
abstract={The following topics are dealt with: face identification; SDN; robot vision; video classification; multi-agent systems; information security management system; electric vehicle charging stations; LTI MIMO discrete-time systems; personal health indicators; UAV swarm target tracking; hybrid cyber-physical systems; online feature selection; interactive multimedia system; 3D virtual objects selection; neural networks; microfluidics chip production; face biometrics; palmprint multimodal biometrics; mobile visualization platform; agriculture; pointillistic art; human gender classification; protein structure prediction; PPI network; spectral-spatial hyperspectral image destriping; object tracking; crowd preference mining; ELM-based privacy preserving protocol; smart tourism destinations; dynamic firmware updates; virtual reality; bioinformatics; drug repositioning; image enhancement; and phishing Web sites.},
keywords={},
doi={10.1109/CYBConf.2017.7985742},
ISSN={},
month={June},}
@INPROCEEDINGS{7813190,
author={},
booktitle={2016 Pattern Recognition Association of South Africa and Robotics and Mechatronics International Conference (PRASA-RobMech)}, title={[Title page]},
year={2016},
volume={},
number={},
pages={1-1},
abstract={The following topics are dealt with: HMM-based child speech synthesis; Afrikaans speech synthesis; optical character recognition; statistical machine translation; computer vision; push-broom Lidar; extreme learning machine; automatic pain recognition; defocus deblurring; noncontact access control; moving object tracking; adaptive skin detection; text detection; convolutional neural networks; low default credit scoring; offline signature verification; data classification; DDoS attacks; textual anomaly detection; spam detection; social media; mobile robot path planning; robot programming; educational robots; 2D laser range finder; thermal power generation scheduling; fuzzy logic control; MANETS; flexible robot arm flatness based control; reflex assisted walking; multifunctional robotic walker; modular electric automatic guided vehicles; robotic endoscope; fixed-wing aircraft landing; quadrotor acceleration-based control; and tethered quadrotor UAV landing.},
keywords={},
doi={10.1109/RoboMech.2016.7813190},
ISSN={},
month={Nov},}

@Article{s19092048,
AUTHOR = {Barth√©lemy, Johan and Verstaevel, Nicolas and Forehead, Hugh and Perez, Pascal},
TITLE = {Edge-Computing Video Analytics for Real-Time Traffic Monitoring in a Smart City},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {2048},
URL = {https://www.mdpi.com/1424-8220/19/9/2048},
ISSN = {1424-8220},
ABSTRACT = {The increasing development of urban centers brings serious challenges for traffic management. In this paper, we introduce a smart visual sensor, developed for a pilot project taking place in the Australian city of Liverpool (NSW). The project&rsquo;s aim was to design and evaluate an edge-computing device using computer vision and deep neural networks to track in real-time multi-modal transportation while ensuring citizens&rsquo; privacy. The performance of the sensor was evaluated on a town center dataset. We also introduce the interoperable Agnosticity framework designed to collect, store and access data from multiple sensors, with results from two real-world experiments.},
DOI = {10.3390/s19092048}
}



@Article{s19092059,
AUTHOR = {Gao, Kai and Han, Farong and Dong, Pingping and Xiong, Naixue and Du, Ronghua},
TITLE = {Connected Vehicle as a Mobile Sensor for Real Time Queue Length at Signalized Intersections},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {2059},
URL = {https://www.mdpi.com/1424-8220/19/9/2059},
ISSN = {1424-8220},
ABSTRACT = {With the development of intelligent transportation system (ITS) and vehicle to X (V2X), the connected vehicle is capable of sensing a great deal of useful traffic information, such as queue length at intersections. Aiming to solve the problem of existing models&rsquo; complexity and information redundancy, this paper proposes a queue length sensing model based on V2X technology, which consists of two sub-models based on shockwave sensing and back propagation (BP) neural network sensing. First, the model obtains state information of the connected vehicles and analyzes the formation process of the queue, and then it calculates the velocity of the shockwave to predict the queue length of the subsequent unconnected vehicles. Then, the neural network is trained with historical connected vehicle data, and a sub-model based on the BP neural network is established to predict the real-time queue length. Finally, the final queue length at the intersection is determined by combining the sub-models by variable weight. Simulation results show that the sensing accuracy of the combined model is proportional to the penetration rate of connected vehicles, and sensing of queue length can be achieved even in low penetration rate environments. In mixed traffic environments of connected vehicles and unconnected vehicles, the queuing length sensing model proposed in this paper has higher performance than the probability distribution (PD) model when the penetration rate is low, and it has an almost equivalent performance with higher penetration rate while the penetration rate is not needed. The proposed sensing model is more applicable for mixed traffic scenarios with much looser conditions.},
DOI = {10.3390/s19092059}
}



@Article{app9091837,
AUTHOR = {Huang, Li-Shing and Su, Jui-Yuan and Pao, Tsang-Long},
TITLE = {A Context Aware Smart Classroom Architecture for Smart Campuses},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1837},
URL = {https://www.mdpi.com/2076-3417/9/9/1837},
ISSN = {2076-3417},
ABSTRACT = {The Smart campus is a concept of an education institute using technologies, such as information systems, internet of things (IoT), and context-aware computing, to support learning, teaching, and administrative activities. Classrooms are important building blocks of a school campus. Therefore, a feasible architecture for building and running smart classrooms is essential for a smart campus. However, most studies related to the smart classroom are focused on studying or addressing particular technical or educational issues, such as networking, AI applications, lecture quality, and user responses to technology. In this study, an architecture for building and running context-aware smart classrooms is proposed. The proposed architecture consists of three parts including a prototype of a context-aware smart classroom, a model for technology integration, and supporting measures for the operation of smart classrooms in this architecture. The classroom prototype was designed based on our study results and a smart classroom project in Ming Chuan University (MCU). The integration model was a layered model uses Raspberry Pi in the bottom layer of the model to integrate underlying technologies and provide application interfaces to the higher layer applications for the ease of building context-aware smart classroom applications. As a result, application interfaces were implemented using Raspberry Pi based on the proposed technology integration model, and a context-aware energy-saving smart classroom application was implemented based on the proposed classroom prototype and the implemented web application interface. The result shows that, in terms of technology, the proposed architecture is feasible for building context-aware smart classrooms in smart campuses.},
DOI = {10.3390/app9091837}
}



@Article{s19092079,
AUTHOR = {Liao, Longlong and Li, Kenli and Yang, Canqun and Liu, Jie},
TITLE = {Low-Cost Image Compressive Sensing with Multiple Measurement Rates for Object Detection},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {2079},
URL = {https://www.mdpi.com/1424-8220/19/9/2079},
ISSN = {1424-8220},
ABSTRACT = {When measurement rates grow, most Compressive Sensing (CS) methods suffer from an increase in overheads of transmission and storage of CS measurements, while reconstruction quality degrades appreciably when measurement rates reduce. To solve these problems in real scenarios such as large-scale distributed surveillance systems, we propose a low-cost image CS approach called MRCS for object detection. It predicts key objects using the proposed MYOLO3 detector, and then samples the regions of the key objects as well as other regions using multiple measurement rates to reduce the size of sampled CS measurements. It also stores and transmits half-precision CS measurements to further reduce the required transmission bandwidth and storage space. Comprehensive evaluations demonstrate that MYOLO3 is a smaller and improved object detector for resource-limited hardware devices such as surveillance cameras and aerial drones. They also suggest that MRCS significantly reduces the required transmission bandwidth and storage space by declining the size of CS measurements, e.g., mean Compression Ratios (mCR) achieves 1.43&ndash;22.92 on the VOC-pbc dataset. Notably, MRCS further reduces the size of CS measurements by half-precision representations. Subsequently, the required transmission bandwidth and storage space are reduced by one half as compared to the counterparts represented with single-precision floats. Moreover, it also substantially enhances the usability of object detection on reconstructed images with half-precision CS measurements and multiple measurement rates as compared to its counterpart, using a single low measurement rate.},
DOI = {10.3390/s19092079}
}



@Article{s19092194,
AUTHOR = {Shen, Leixian and Zhang, Qingyun and Pang, Jiayi and Xu, He and Li, Peng and Xue, Donghui},
TITLE = {ANTspin: Efficient Absolute Localization Method of RFID Tags via Spinning Antenna},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {2194},
URL = {https://www.mdpi.com/1424-8220/19/9/2194},
ISSN = {1424-8220},
ABSTRACT = {The Global Positioning System (GPS) has been widely applied in outdoor positioning, but it cannot meet the accuracy requirements of indoor positioning. Comprising an important part of the Internet of Things perception layer, Radio Frequency Identification (RFID) plays an important role in indoor positioning. We propose a novel localization scheme aiming at the defects of existing RFID localization technology in localization accuracy and deployment cost, called ANTspin: Efficient Absolute Localization Method of RFID Tags via Spinning Antenna, which introduces a rotary table in the experiment. The reader antenna is fixed on the rotary table to continuously collect dynamic data. When compared with static acquisition, there is more information for localization. After that, the relative incident angle and distance between tags and the antenna can be analyzed for localization with characteristics of Received Signal Strength Indication (RSSI) data. We implement ANTspin using COTS RFID devices and the experimental results show that it achieves a mean accuracy of 9.34 cm in 2D and mean accuracy of 13.01 cm in three-dimensions (3D) with high efficiency and low deployment cost.},
DOI = {10.3390/s19092194}
}



@Article{s19092206,
AUTHOR = {Aqib, Muhammad and Mehmood, Rashid and Alzahrani, Ahmed and Katib, Iyad and Albeshri, Aiiad and Altowaijri, Saleh M.},
TITLE = {Smarter Traffic Prediction Using Big Data, In-Memory Computing, Deep Learning and GPUs},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {2206},
URL = {https://www.mdpi.com/1424-8220/19/9/2206},
ISSN = {1424-8220},
ABSTRACT = {Road transportation is the backbone of modern economies, albeit it annually costs     1.25     million deaths and trillions of dollars to the global economy, and damages public health and the environment. Deep learning is among the leading-edge methods used for transportation-related predictions, however, the existing works are in their infancy, and fall short in multiple respects, including the use of datasets with limited sizes and scopes, and insufficient depth of the deep learning studies. This paper provides a novel and comprehensive approach toward large-scale, faster, and real-time traffic prediction by bringing four complementary cutting-edge technologies together: big data, deep learning, in-memory computing, and Graphics Processing Units (GPUs). We trained deep networks using over 11 years of data provided by the California Department of Transportation (Caltrans), the largest dataset that has been used in deep learning studies. Several combinations of the input attributes of the data along with various network configurations of the deep learning models were investigated for training and prediction purposes. The use of the pre-trained model for real-time prediction was explored. The paper contributes novel deep learning models, algorithms, implementation, analytics methodology, and software tool for smart cities, big data, high performance computing, and their convergence.},
DOI = {10.3390/s19092206}
}



@Article{su11102736,
AUTHOR = {Aqib, Muhammad and Mehmood, Rashid and Alzahrani, Ahmed and Katib, Iyad and Albeshri, Aiiad and Altowaijri, Saleh M.},
TITLE = {Rapid Transit Systems: Smarter Urban Planning Using Big Data, In-Memory Computing, Deep Learning, and GPUs},
JOURNAL = {Sustainability},
VOLUME = {11},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {2736},
URL = {https://www.mdpi.com/2071-1050/11/10/2736},
ISSN = {2071-1050},
ABSTRACT = {Rapid transit systems or metros are a popular choice for high-capacity public transport in urban areas due to several advantages including safety, dependability, speed, cost, and lower risk of accidents. Existing studies on metros have not considered appropriate holistic urban transport models and integrated use of cutting-edge technologies. This paper proposes a comprehensive approach toward large-scale and faster prediction of metro system characteristics by employing the integration of four leading-edge technologies: big data, deep learning, in-memory computing, and Graphics Processing Units (GPUs). Using London Metro as a case study, and the Rolling Origin and Destination Survey (RODS) (real) dataset, we predict the number of passengers for six time intervals (a) using various access transport modes to reach the train stations (buses, walking, etc.); (b) using various egress modes to travel from the metro station to their next points of interest (PoIs); (c) traveling between different origin-destination (OD) pairs of stations; and (d) against the distance between the OD stations. The prediction allows better spatiotemporal planning of the whole urban transport system, including the metro subsystem, and its various access and egress modes. The paper contributes novel deep learning models, algorithms, implementation, analytics methodology, and software tool for analysis of metro systems.},
DOI = {10.3390/su11102736}
}



@Article{s19102266,
AUTHOR = {Sideris, Nikolaos and Bardis, Georgios and Voulodimos, Athanasios and Miaoulis, Georgios and Ghazanfarpour, Djamchid},
TITLE = {Using Random Forests on Real-World City Data for Urban Planning in a Visual Semantic Decision Support System},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {2266},
URL = {https://www.mdpi.com/1424-8220/19/10/2266},
ISSN = {1424-8220},
ABSTRACT = {The constantly increasing amount and availability of urban data derived from varying sources leads to an assortment of challenges that include, among others, the consolidation, visualization, and maximal exploitation prospects of the aforementioned data. A preeminent problem affecting urban planning is the appropriate choice of location to host a particular activity (either commercial or common welfare service) or the correct use of an existing building or empty space. In this paper, we propose an approach to address these challenges availed with machine learning techniques. The proposed system combines, fuses, and merges various types of data from different sources, encodes them using a novel semantic model that can capture and utilize both low-level geometric information and higher level semantic information and subsequently feeds them to the random forests classifier, as well as other supervised machine learning models for comparisons. Our experimental evaluation on multiple real-world data sets comparing the performance of several classifiers (including Feedforward Neural Networks, Support Vector Machines, Bag of Decision Trees, k-Nearest Neighbors and Na&iuml;ve Bayes), indicated the superiority of Random Forests in terms of the examined performance metrics (Accuracy, Specificity, Precision, Recall, F-measure and G-mean).},
DOI = {10.3390/s19102266}
}



@Article{su11102848,
AUTHOR = {Matijosaitiene, Irina and McDowald, Anthony and Juneja, Vishal},
TITLE = {Predicting Safe Parking Spaces: A Machine Learning Approach to Geospatial Urban and Crime Data},
JOURNAL = {Sustainability},
VOLUME = {11},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {2848},
URL = {https://www.mdpi.com/2071-1050/11/10/2848},
ISSN = {2071-1050},
ABSTRACT = {This research aims to identify spatial and time patterns of theft in Manhattan, NY, to reveal urban factors that contribute to thefts from motor vehicles and to build a prediction model for thefts. Methods include time series and hot spot analysis, linear regression, elastic-net, Support vector machines SVM with radial and linear kernels, decision tree, bagged CART, random forest, and stochastic gradient boosting. Machine learning methods reveal that linear models perform better on our data (linear regression, elastic-net), specifying that a higher number of subway entrances, graffiti, and restaurants on streets contribute to higher theft rates from motor vehicles. Although the prediction model for thefts meets almost all assumptions (five of six), its accuracy is 77%, suggesting that there are other undiscovered factors making a contribution to the generation of thefts. As an output demonstrating final results, the application prototype for searching safer parking in Manhattan, NY based on the prediction model, has been developed.},
DOI = {10.3390/su11102848}
}



@Article{en12101957,
AUTHOR = {Suryadevara, Nagender Kumar and Biswal, Gyan Ranjan},
TITLE = {Smart Plugs: Paradigms and Applications in the Smart City-and-Smart Grid},
JOURNAL = {Energies},
VOLUME = {12},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {1957},
URL = {https://www.mdpi.com/1996-1073/12/10/1957},
ISSN = {1996-1073},
ABSTRACT = {In the current energy ecosystem, the need for a Hybrid Appliance Load Monitoring System (HALMS) to establish a smarter grid and energy infrastructure is undeniable. The increasing popularity of the Internet of Things (IoT) has suddenly pushed the demand for smart and connected devices. This review introduces the term smart plug as a device that uses IoT for establishing HALMS. These smart plugs are a handy solution to make the so-called &lsquo;dumb&rsquo; devices smart. The strategy of smart plugs to enhance the energy management experience in connected spaces is presented. This study extensively highlights the current smart plug technologies and the relevant activities and limitations that need to overcome the requirements of HALMS.},
DOI = {10.3390/en12101957}
}



@Article{pr7050310,
AUTHOR = {Petro»ôanu, Dana-Mihaela},
TITLE = {Designing, Developing and Validating a Forecasting Method for the Month Ahead Hourly Electricity Consumption in the Case of Medium Industrial Consumers},
JOURNAL = {Processes},
VOLUME = {7},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {310},
URL = {https://www.mdpi.com/2227-9717/7/5/310},
ISSN = {2227-9717},
ABSTRACT = {An accurate forecast of the electricity consumption is particularly important to both consumers and system operators. The purpose of this study is to develop a forecasting method that provides such an accurate forecast of the month-ahead hourly electricity consumption in the case of medium industrial consumers, therefore assuring an intelligent energy management and an efficient economic scheduling of their resources, having the possibility to negotiate in advance appropriate billing tariffs relying on accurate hourly forecasts, in the same time facilitating an optimal energy management for the dispatch operator. The forecasting method consists of developing first non-linear autoregressive, with exogenous inputs (NARX) artificial neural networks (ANNs) in order to forecast an initial daily electricity consumption, a forecast that is being further processed with custom developed long short-term memory (LSTM) neural networks with exogenous variables support in order to refine the daily forecast as to achieve an accurate hourly forecasted consumed electricity for the whole month-ahead. The obtained experimental results (highlighted also through a very good value of 0.0244 for the root mean square error performance metric, obtained when forecasting the month-ahead hourly electricity consumption and comparing it with the real consumption), the validation of the developed forecasting method, the comparison of the method with other forecasting approaches from the scientific literature substantiate the fact that the proposed approach manages to fill a gap in the current body of knowledge consisting of the need of a high-accuracy forecasting method for the month-ahead hourly electricity consumption in the case of medium industrial consumers. The developed forecasting method targets medium industrial consumers, but, due to its accuracy, it can also be a useful tool for promoting innovative business models with regard to industrial consumers willing to produce a part of their own electricity using renewable energy resources, benefiting from reduced production costs and reliable electricity prices.},
DOI = {10.3390/pr7050310}
}



@Article{su11102970,
AUTHOR = {Nam, KiJeon and Ifaei, Pouya and Heo, Sungku and Rhee, Gahee and Lee, Seungchul and Yoo, ChangKyoo},
TITLE = {An Efficient Burst Detection and Isolation Monitoring System for Water Distribution Networks Using Multivariate Statistical Techniques},
JOURNAL = {Sustainability},
VOLUME = {11},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {2970},
URL = {https://www.mdpi.com/2071-1050/11/10/2970},
ISSN = {2071-1050},
ABSTRACT = {Detection and isolation of burst locations in water distribution networks (WDN) are challenging problems in urban management because burst events cause considerable economic, social, and environmental losses. In the present study, a novel monitoring and sensor placement approach is proposed for rapid and robust burst detection. Accordingly, a hybrid principal component analysis (PCA) and standardized exponential weighted moving average (EWMA) system is proposed for WDN monitoring and management. In addition, the optimal sensor configuration is obtained using PCA, k-means clustering, and a sensitivity analysis considering the diurnal patterns and the noises of pressure and flowrate data in the WDN. The proposed system is applied to a branched WDN, and the results are compared to those obtained with conventional monitoring systems. The results show that the proposed system detected the burst occurrence regardless of noise size with a detection rate of 93%. Compared to conventional systems, the isolation ratio improved by 10%, indicating that the bursts were isolated more accurately. In addition, the corresponding sensor configuration was 40% less expensive than the conventional systems.},
DOI = {10.3390/su11102970}
}



@Article{s19102388,
AUTHOR = {S√°nchez-Medina, Javier J. and Guerra-Montenegro, Juan Antonio and S√°nchez-Rodr√≠guez, David and Alonso-Gonz√°lez, Itziar G. and Navarro-Mesa, Juan L.},
TITLE = {Data Stream Mining Applied to Maximum Wind Forecasting in the Canary Islands},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {2388},
URL = {https://www.mdpi.com/1424-8220/19/10/2388},
ISSN = {1424-8220},
ABSTRACT = {The Canary Islands are a well known tourist destination with generally stable and clement weather conditions. However, occasionally extreme weather conditions occur, which although very unusual, may cause severe damage to the local economy. The ViMetRi-MAC EU funded project has among its goals, managing climate-change-associated risks. The Spanish National Meteorology Agency (AEMET) has a network of weather stations across the eight Canary Islands. Using data from those stations, we propose a novel methodology for the prediction of maximum wind speed in order to trigger an early alert for extreme weather conditions. The methodology proposed has the added value of using an innovative kind of machine learning that is based on the data stream mining paradigm. This type of machine learning system relies on two important features: models are learned incrementally and adaptively. That means the learner tunes the models gradually and endlessly as new observations are received and also modifies it when there is concept drift (statistical instability), in the modeled phenomenon. The results presented seem to prove that this data stream mining approach is a good fit for this kind of problem, clearly improving the results obtained with the accumulative non-adaptive version of the methodology.},
DOI = {10.3390/s19102388}
}



@Article{ijgi8060243,
AUTHOR = {Han, Yong and Wang, Shukang and Ren, Yibin and Wang, Cheng and Gao, Peng and Chen, Ge},
TITLE = {Predicting Station-Level Short-Term Passenger Flow in a Citywide Metro Network Using Spatiotemporal Graph Convolutional Neural Networks},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {8},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {243},
URL = {https://www.mdpi.com/2220-9964/8/6/243},
ISSN = {2220-9964},
ABSTRACT = {Predicting the passenger flow of metro networks is of great importance for traffic management and public safety. However, such predictions are very challenging, as passenger flow is affected by complex spatial dependencies (nearby and distant) and temporal dependencies (recent and periodic). In this paper, we propose a novel deep-learning-based approach, named STGCNNmetro (spatiotemporal graph convolutional neural networks for metro), to collectively predict two types of passenger flow volumes&mdash;inflow and outflow&mdash;in each metro station of a city. Specifically, instead of representing metro stations by grids and employing conventional convolutional neural networks (CNNs) to capture spatiotemporal dependencies, STGCNNmetro transforms the city metro network to a graph and makes predictions using graph convolutional neural networks (GCNNs). First, we apply stereogram graph convolution operations to seamlessly capture the irregular spatiotemporal dependencies along the metro network. Second, a deep structure composed of GCNNs is constructed to capture the distant spatiotemporal dependencies at the citywide level. Finally, we integrate three temporal patterns (recent, daily, and weekly) and fuse the spatiotemporal dependencies captured from these patterns to form the final prediction values. The STGCNNmetro model is an end-to-end framework which can accept raw passenger flow-volume data, automatically capture the effective features of the citywide metro network, and output predictions. We test this model by predicting the short-term passenger flow volume in the citywide metro network of Shanghai, China. Experiments show that the STGCNNmetro model outperforms seven well-known baseline models (LSVR, PCA-kNN, NMF-kNN, Bayesian, MLR, M-CNN, and LSTM). We additionally explore the sensitivity of the model to its parameters and discuss the distribution of prediction errors.},
DOI = {10.3390/ijgi8060243}
}



@Article{rs11111265,
AUTHOR = {Kuang, Li and Yan, Xuejin and Tan, Xianhan and Li, Shuqi and Yang, Xiaoxian},
TITLE = {Predicting Taxi Demand Based on 3D Convolutional Neural Network and Multi-task Learning},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1265},
URL = {https://www.mdpi.com/2072-4292/11/11/1265},
ISSN = {2072-4292},
ABSTRACT = {Taxi demand can be divided into pick-up demand and drop-off demand, which are firmly related to human&rsquo;s travel habits. Accurately predicting taxi demand is of great significance to passengers, drivers, ride-hailing platforms and urban managers. Most of the existing studies only forecast the taxi demand for pick-up and separate the interaction between spatial correlation and temporal correlation. In this paper, we first analyze the historical data and select three highly relevant parts for each time interval, namely closeness, period and trend. We then construct a multi-task learning component and extract the common spatiotemporal feature by treating the taxi pick-up prediction task and drop-off prediction task as two related tasks. With the aim of fusing spatiotemporal features of historical data, we conduct feature embedding by attention-based long short-term memory (LSTM) and capture the correlation between taxi pick-up and drop-off with 3D ResNet. Finally, we combine external factors to simultaneously predict the taxi demand for pick-up and drop-off in the next time interval. Experiments conducted on real datasets in Chengdu present the effectiveness of the proposed method and show better performance in comparison with state-of-the-art models.},
DOI = {10.3390/rs11111265}
}



@Article{electronics8060602,
AUTHOR = {Kurdi, Heba and Alsalamah, Shada and Alatawi, Asma and Alfaraj, Sara and Altoaimy, Lina and Ahmed, Syed Hassan},
TITLE = {HealthyBroker: A Trustworthy Blockchain-Based Multi-Cloud Broker for Patient-Centered eHealth Services},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {602},
URL = {https://www.mdpi.com/2079-9292/8/6/602},
ISSN = {2079-9292},
ABSTRACT = {Delivering electronic health care (eHealth) services across multi-cloud providers to implement patient-centric care demands a trustworthy brokering architecture. Specifically, such an architecture should aggregate relevant medical information to allow informed decision-making. It should also ensure that this information is complete and authentic and that no one has tampered with it. Brokers deployed in eHealth services may fall short of meeting such criteria due to two key behaviors. The first involves violating international health-data protection laws by allowing user anonymity and limiting user access rights. Second, brokers claiming to provide trustworthy transactions between interested parties usually rely on user feedback, an approach vulnerable to manipulation by malicious users. This paper addresses these data security and trust challenges by proposing HealthyBroker, a novel, trust-building brokering architecture for multiple cloud environments. This architecture is designed specifically for patient-centric cloud eHealth services. It enables care-team members to complete eHealth transactions securely and access relevant patient data on a &ldquo;need-to-know&rdquo; basis in compliance with data-protection laws. HealthyBroker also protects against potential malicious behavior by assessing the trust relationship and tracking it using a neutral, tamper-proof, distributed blockchain ledger. Trust is assessed based on two strategies. First, all transactions and user feedback are tracked and audited in a distributed ledger for transparency. Second, only feedback coming from trustworthy parties is taken into consideration. HealthyBroker was tested in a simulated eHealth multi-cloud environment. The test produced better results than a benchmark algorithm in terms of data accuracy, service time, and the reliability of feedback received as measured by three malicious behavior models (na&iuml;ve, feedback isolated, and feedback collective). These results demonstrate that HealthyBroker can provide care teams with a trustworthy, transparent ecosystem that can facilitate information sharing and well-informed decisions for patient-centric care.},
DOI = {10.3390/electronics8060602}
}



@Article{s19112472,
AUTHOR = {Ullah, Fath U Min and Ullah, Amin and Muhammad, Khan and Haq, Ijaz Ul and Baik, Sung Wook},
TITLE = {Violence Detection Using Spatiotemporal Features with 3D Convolutional Neural Network},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2472},
URL = {https://www.mdpi.com/1424-8220/19/11/2472},
ISSN = {1424-8220},
ABSTRACT = {The worldwide utilization of surveillance cameras in smart cities has enabled researchers to analyze a gigantic volume of data to ensure automatic monitoring. An enhanced security system in smart cities, schools, hospitals, and other surveillance domains is mandatory for the detection of violent or abnormal activities to avoid any casualties which could cause social, economic, and ecological damages. Automatic detection of violence for quick actions is very significant and can efficiently assist the concerned departments. In this paper, we propose a triple-staged end-to-end deep learning violence detection framework. First, persons are detected in the surveillance video stream using a light-weight convolutional neural network (CNN) model to reduce and overcome the voluminous processing of useless frames. Second, a sequence of 16 frames with detected persons is passed to 3D CNN, where the spatiotemporal features of these sequences are extracted and fed to the Softmax classifier. Furthermore, we optimized the 3D CNN model using an open visual inference and neural networks optimization toolkit developed by Intel, which converts the trained model into intermediate representation and adjusts it for optimal execution at the end platform for the final prediction of violent activity. After detection of a violent activity, an alert is transmitted to the nearest police station or security department to take prompt preventive actions. We found that our proposed method outperforms the existing state-of-the-art methods for different benchmark datasets.},
DOI = {10.3390/s19112472}
}



@Article{electronics8060607,
AUTHOR = {Najm, Ihab Ahmed and Hamoud, Alaa Khalaf and Lloret, Jaime and Bosch, Ignacio},
TITLE = {Machine Learning Prediction Approach to Enhance Congestion Control in 5G IoT Environment},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {607},
URL = {https://www.mdpi.com/2079-9292/8/6/607},
ISSN = {2079-9292},
ABSTRACT = {The 5G network is a next-generation wireless form of communication and the latest mobile technology. In practice, 5G utilizes the Internet of Things (IoT) to work in high-traffic networks with multiple nodes/sensors in an attempt to transmit their packets to a destination simultaneously, which is a characteristic of IoT applications. Due to this, 5G offers vast bandwidth, low delay, and extremely high data transfer speed. Thus, 5G presents opportunities and motivations for utilizing next-generation protocols, especially the stream control transmission protocol (SCTP). However, the congestion control mechanisms of the conventional SCTP negatively influence overall performance. Moreover, existing mechanisms contribute to reduce 5G and IoT performance. Thus, a new machine learning model based on a decision tree (DT) algorithm is proposed in this study to predict optimal enhancement of congestion control in the wireless sensors of 5G IoT networks. The model was implemented on a training dataset to determine the optimal parametric setting in a 5G environment. The dataset was used to train the machine learning model and enable the prediction of optimal alternatives that can enhance the performance of the congestion control approach. The DT approach can be used for other functions, especially prediction and classification. DT algorithms provide graphs that can be used by any user to understand the prediction approach. The DT C4.5 provided promising results, with more than 92% precision and recall.},
DOI = {10.3390/electronics8060607}
}



@Article{info10060189,
AUTHOR = {Nichiforov, Cristina and Stamatescu, Grigore and Stamatescu, Iulia and FƒÉgƒÉrƒÉ≈üan, Ioana},
TITLE = {Evaluation of Sequence-Learning Models for Large-Commercial-Building Load Forecasting},
JOURNAL = {Information},
VOLUME = {10},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {189},
URL = {https://www.mdpi.com/2078-2489/10/6/189},
ISSN = {2078-2489},
ABSTRACT = {Buildings play a critical role in the stability and resilience of modern smart grids, leading to a refocusing of large-scale energy-management strategies from the supply side to the consumer side. When buildings integrate local renewable-energy generation in the form of renewable-energy resources, they become prosumers, and this adds more complexity to the operation of interconnected complex energy systems. A class of methods of modelling the energy-consumption patterns of the building have recently emerged as black-box input&ndash;output approaches with the ability to capture underlying consumption trends. These make use and require large quantities of quality data produced by nondeterministic processes underlying energy consumption. We present an application of a class of neural networks, namely, deep-learning techniques for time-series sequence modelling, with the goal of accurate and reliable building energy-load forecasting. Recurrent Neural Network implementation uses Long Short-Term Memory layers in increasing density of nodes to quantify prediction accuracy. The case study is illustrated on four university buildings from temperate climates over one year of operation using a reference benchmarking dataset that allows replicable results. The obtained results are discussed in terms of accuracy metrics and computational and network architecture aspects, and are considered suitable for further use in future in situ energy management at the building and neighborhood levels.},
DOI = {10.3390/info10060189}
}



@Article{en12112122,
AUTHOR = {Xue, Guixiang and Pan, Yu and Lin, Tao and Song, Jiancai and Qi, Chengying and Wang, Zhipan},
TITLE = {District Heating Load Prediction Algorithm Based on Feature Fusion LSTM Model},
JOURNAL = {Energies},
VOLUME = {12},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2122},
URL = {https://www.mdpi.com/1996-1073/12/11/2122},
ISSN = {1996-1073},
ABSTRACT = {The smart district heating system (SDHS) is an important element of the construction of smart cities in Northern China; it plays a significant role in meeting heating requirements and green energy saving in winter. Various Internet of Things (IoT) sensors and wireless transmission technologies are applied to monitor data in real-time and to form a historical database. The accurate prediction of heating loads based on massive historical datasets is the necessary condition and key basis for formulating an optimal heating control strategy in the SDHS, which contributes to the reduction in the consumption of energy and the improvement in the energy dispatching efficiency and accuracy. In order to achieve the high prediction accuracy of SDHS and to improve the representation ability of multi-time-scale features, a novel short-term heating load prediction algorithm based on a feature fusion long short-term memory (LSTM) model (FFLSTM) is proposed. Three characteristics, namely proximity, periodicity, and trend, are found after analyzing the heating load data from the aspect of the hourly time dimension. In order to comprehensively utilize the data&rsquo;s intrinsic characteristics, three LSTM models are employed to make separate predictions, and, then, the prediction results based on internal features and other external features at the corresponding moments are imported into the high-level LSTM model for fusion processing, which brings a more accurate prediction result of the heating load. Detailed comparisons between the proposed FFLSTM algorithm and the-state-of-art algorithms are conducted in this paper. The experimental results show that the proposed FFLSTM algorithm outperforms others and can obtain a higher prediction accuracy. Furthermore, the impact of selecting different parameters of the FFLSTM model is also studied thoroughly.},
DOI = {10.3390/en12112122}
}



@Article{app9112302,
AUTHOR = {Choi, Inkyu and Bae, Soo Hyun and Kim, Nam Soo},
TITLE = {Deep Convolutional Neural Network with Structured Prediction for Weakly Supervised Audio Event Detection},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2302},
URL = {https://www.mdpi.com/2076-3417/9/11/2302},
ISSN = {2076-3417},
ABSTRACT = {Audio event detection (AED) is a task of recognizing the types of audio events in an audio stream and estimating their temporal positions. AED is typically based on fully supervised approaches, requiring strong labels including both the presence and temporal position of each audio event. However, fully supervised datasets are not easily available due to the heavy cost of human annotation. Recently, weakly supervised approaches for AED have been proposed, utilizing large scale datasets with weak labels including only the occurrence of events in recordings. In this work, we introduce a deep convolutional neural network (CNN) model called DSNet based on densely connected convolution networks (DenseNets) and squeeze-and-excitation networks (SENets) for weakly supervised training of AED. DSNet alleviates the vanishing-gradient problem and strengthens feature propagation and models interdependencies between channels. We also propose a structured prediction method for weakly supervised AED. We apply a recurrent neural network (RNN) based framework and a prediction smoothness cost function to consider long-term contextual information with reduced error propagation. In post-processing, conditional random fields (CRFs) are applied to take into account the dependency between segments and delineate the borders of audio events precisely. We evaluated our proposed models on the DCASE 2017 task 4 dataset and obtained state-of-the-art results on both audio tagging and event detection tasks.},
DOI = {10.3390/app9112302}
}



@Article{su11113155,
AUTHOR = {Min, Kyunghun and Yoon, Moonyoung and Furuya, Katsunori},
TITLE = {A Comparison of a Smart City‚Äôs Trends in Urban Planning before and after 2016 through Keyword Network Analysis},
JOURNAL = {Sustainability},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {3155},
URL = {https://www.mdpi.com/2071-1050/11/11/3155},
ISSN = {2071-1050},
ABSTRACT = {The aim of this study was to explore the keywords related to smart city concepts, and to understand their flow. This research used a keyword network analysis by collecting keywords from papers published on the web from Scopus, which is an international scholarly papers engine. The data were collected from before and after 2016, and since the amount of data has been growing rapidly after global agreements such as the United Nations&rsquo; Sustainable Development Goals (SDGs) in 2015, we attempted to focus on adjacent years of publication. In order to understand the flow of research, we conducted a central analysis, which is widely used in quantitative research relating to social network analysis, and performed cluster analysis to identify relationships with related research. The results of the analysis are represented in the form of network maps, and the role of each keyword was clarified based on these network maps. In addition, the overall flow explained the change of flow through discarded and emerging keywords, and the relationships with related fields were explained through cluster analysis. The findings could serve as a basis for policymakers, urban managers, and researchers seeking a comprehensive understanding of the smart city concept in urban planning areas.},
DOI = {10.3390/su11113155}
}



@Article{app9112308,
AUTHOR = {Lee, Juyong and Kim, Daeyoub and Lee, Jihoon},
TITLE = {ZONE-Based Multi-Access Edge Computing Scheme for User Device Mobility Management},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2308},
URL = {https://www.mdpi.com/2076-3417/9/11/2308},
ISSN = {2076-3417},
ABSTRACT = {Recently, new mobile applications and services have appeared thanks to the rapid development of mobile devices and mobile network technology. Cloud computing has played an important role over the past decades, providing powerful computing capabilities and high-capacity storage space to efficiently deliver these mobile services to mobile users. Nevertheless, existing cloud computing delegates computing to a cloud server located at a relatively long distance, resulting in significant delays due to additional time to return processing results from a cloud server. These unnecessary delays are inconvenient for mobile users because they are not suitable for applications that require a real-time service environment. To cope with these problems, a new computing concept called Multi-Access Edge Computing (MEC) has emerged. Instead of sending all requests to the central cloud to handle mobile users&rsquo; requests, the MEC brings computing power and storage resources to the edge of the mobile network. It enables the mobile user device to run the real-time applications that are sensitive to latency to meet the strict requirements. However, there is a lack of research on the efficient utilization of computing resources and mobility support when mobile users move in the MEC environment. In this paper, we propose the MEC-based mobility management scheme that arranges MEC server (MECS) as the concept of Zone so that mobile users can continue to receive content and use server resources efficiently even when they move. The results show that the proposed scheme reduce the average service delay compared to the existing MEC scheme. In addition, the proposed scheme outperforms the existing MEC scheme because mobile users can continuously receive services, even when they move frequently.},
DOI = {10.3390/app9112308}
}



@Article{info10060203,
AUTHOR = {Long, Jun and Sun, Wuqing and Yang, Zhan and Raymond, Osolo Ian},
TITLE = {Asymmetric Residual Neural Network for Accurate Human Activity Recognition},
JOURNAL = {Information},
VOLUME = {10},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {203},
URL = {https://www.mdpi.com/2078-2489/10/6/203},
ISSN = {2078-2489},
ABSTRACT = {Human activity recognition (HAR) using deep neural networks has become a hot topic in human&ndash;computer interaction. Machines can effectively identify human naturalistic activities by learning from a large collection of sensor data. Activity recognition is not only an interesting research problem but also has many real-world practical applications. Based on the success of residual networks in achieving a high level of aesthetic representation of automatic learning, we propose a novel asymmetric residual network, named ARN. ARN is implemented using two identical path frameworks consisting of (1) a short time window, which is used to capture spatial features, and (2) a long time window, which is used to capture fine temporal features. The long time window path can be made very lightweight by reducing its channel capacity, while still being able to learn useful temporal representations for activity recognition. In this paper, we mainly focus on proposing a new model to improve the accuracy of HAR. In order to demonstrate the effectiveness of the ARN model, we carried out extensive experiments on benchmark datasets (i.e., OPPORTUNITY, UniMiB-SHAR) and compared the results with some conventional and state-of-the-art learning-based methods. We discuss the influence of networks parameters on performance to provide insights about its optimization. Results from our experiments show that ARN is effective in recognizing human activities via wearable datasets.},
DOI = {10.3390/info10060203}
}



@Article{bdcc3020032,
AUTHOR = {Ajah, Ifeyinwa Angela and Nweke, Henry Friday},
TITLE = {Big Data and Business Analytics: Trends, Platforms, Success Factors and Applications},
JOURNAL = {Big Data and Cognitive Computing},
VOLUME = {3},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {32},
URL = {https://www.mdpi.com/2504-2289/3/2/32},
ISSN = {2504-2289},
ABSTRACT = {Big data and business analytics are trends that are positively impacting the business world. Past researches show that data generated in the modern world is huge and growing exponentially. These include structured and unstructured data that flood organizations daily. Unstructured data constitute the majority of the world&rsquo;s digital data and these include text files, web, and social media posts, emails, images, audio, movies, etc. The unstructured data cannot be managed in the traditional relational database management system (RDBMS). Therefore, data proliferation requires a rethinking of techniques for capturing, storing, and processing the data. This is the role big data has come to play. This paper, therefore, is aimed at increasing the attention of organizations and researchers to various applications and benefits of big data technology. The paper reviews and discusses, the recent trends, opportunities and pitfalls of big data and how it has enabled organizations to create successful business strategies and remain competitive, based on available literature. Furthermore, the review presents the various applications of big data and business analytics, data sources generated in these applications and their key characteristics. Finally, the review not only outlines the challenges for successful implementation of big data projects but also highlights the current open research directions of big data analytics that require further consideration. The reviewed areas of big data suggest that good management and manipulation of the large data sets using the techniques and tools of big data can deliver actionable insights that create business values.},
DOI = {10.3390/bdcc3020032}
}



@Article{s19122691,
AUTHOR = {Liu, Yao and Zhou, Hongjing and Huang, Jiawei},
TITLE = {OCA-MAC: A Cooperative TDMA-Based MAC Protocol for Vehicular Ad Hoc Networks},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {2691},
URL = {https://www.mdpi.com/1424-8220/19/12/2691},
ISSN = {1424-8220},
ABSTRACT = {Cooperative communication is an effective method of improving the transmission performance for vehicular ad hoc networks. However, the rapid movement of vehicles leads to frequent changes in network topology and reduces the probability of successful data transmission on the medium access control (MAC) layer. In this paper, we propose an Optimal Cooperative Ad hoc MAC protocol (OCA-MAC) based on time division multiple access (TDMA). OCA-MAC utilizes multiple cooperative nodes to forward data, so as to improve the probability of successful data transmission. It chooses cooperative nodes according to direct successful transmission probability, communication range between potential helper node and destination node, and available time slot. Meanwhile, in order to avoid excessive transmission redundancy caused by multiple cooperative forwarding, the optimal number of cooperative forwarding nodes is obtained through analysis of a probabilistic model. Simulation results show that OCA-MAC improves the successful data transmission rate and reduces the number of transmission times and transmission delay compared to the multichannel TDMA MAC protocol (VeMAC) and the cooperative ad hoc MAC protocol (CAH-MAC).},
DOI = {10.3390/s19122691}
}



@Article{ijerph16122133,
AUTHOR = {Qian, Fei and Chen, Li and Li, Jun and Ding, Chao and Chen, Xianfu and Wang, Jian},
TITLE = {Direct Prediction of the Toxic Gas Diffusion Rule in a Real Environment Based on LSTM},
JOURNAL = {International Journal of Environmental Research and Public Health},
VOLUME = {16},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {2133},
URL = {https://www.mdpi.com/1660-4601/16/12/2133},
PubMedID = {31212880},
ISSN = {1660-4601},
ABSTRACT = {Predicting the diffusion rule of toxic gas plays a distinctly important role in emergency capability assessment and rescue work. Among diffusion prediction models, the traditional artificial neural network has exhibited excellent performance not only in prediction accuracy but also in calculation time. Nevertheless, with the continuous development of deep learning and data science, some new prediction models based on deep learning algorithms have been shown to be more advantageous because their structure can better discover internal laws and external connections between input data and output data. The long short-term memory (LSTM) network is a kind of deep learning neural network that has demonstrated outstanding achievements in many prediction fields. This paper applies the LSTM network directly to the prediction of toxic gas diffusion and uses the Project Prairie Grass dataset to conduct experiments. Compared with the Gaussian diffusion model, support vector machine (SVM) model, and back propagation (BP) network model, the LSTM model of deep learning has higher prediction accuracy (especially for the prediction at the point of high concentration values) while avoiding the occurrence of negative concentration values and overfitting problems found in traditional artificial neural network models.},
DOI = {10.3390/ijerph16122133}
}



@Article{rs11121453,
AUTHOR = {Zhang, Shanxin and Wang, Cheng and Lin, Lili and Wen, Chenglu and Yang, Chenhui and Zhang, Zhemin and Li, Jonathan},
TITLE = {Automated Visual Recognizability Evaluation of Traffic Sign Based on 3D LiDAR Point Clouds},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {1453},
URL = {https://www.mdpi.com/2072-4292/11/12/1453},
ISSN = {2072-4292},
ABSTRACT = {Maintaining the high visual recognizability of traffic signs for traffic safety is a key matter for road network management. Mobile Laser Scanning (MLS) systems provide efficient way of 3D measurement over large-scale traffic environment. This paper presents a quantitative visual recognizability evaluation method for traffic signs in large-scale traffic environment based on traffic recognition theory and MLS 3D point clouds. We first propose the Visibility Evaluation Model (VEM) to quantitatively describe the visibility of traffic sign from any given viewpoint, then we proposed the concept of visual recognizability field and Traffic Sign Visual Recognizability Evaluation Model (TSVREM) to measure the visual recognizability of a traffic sign. Finally, we present an automatic TSVREM calculation algorithm for MLS 3D point clouds. Experimental results on real MLS 3D point clouds show that the proposed method is feasible and efficient.},
DOI = {10.3390/rs11121453}
}



@Article{app9122560,
AUTHOR = {Kim, Yunkon and Huh, Eui-Nam},
TITLE = {EDCrammer: An Efficient Caching Rate-Control Algorithm for Streaming Data on Resource-Limited Edge Nodes},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {2560},
URL = {https://www.mdpi.com/2076-3417/9/12/2560},
ISSN = {2076-3417},
ABSTRACT = {This paper explores data caching as a key factor of edge computing. State-of-the-art research of data caching on edge nodes mainly considers reactive and proactive caching, and machine learning based caching, which could be a heavy task for edge nodes. However, edge nodes usually have relatively lower computing resources than cloud datacenters as those are geo-distributed from the administrator. Therefore, a caching algorithm should be lightweight for saving computing resources on edge nodes. In addition, the data caching should be agile because it has to support high-quality services on edge nodes. Accordingly, this paper proposes a lightweight, agile caching algorithm, EDCrammer (Efficient Data Crammer), which performs agile operations to control caching rate for streaming data by using the enhanced PID (Proportional-Integral-Differential) controller. Experimental results using this lightweight, agile caching algorithm show its significant value in each scenario. In four common scenarios, the desired cache utilization was reached in 1.1 s on average and then maintained within a 4&ndash;7% deviation. The cache hit ratio is about 96%, and the optimal cache capacity is around 1.5 MB. Thus, EDCrammer can help distribute the streaming data traffic to the edge nodes, mitigate the uplink load on the central cloud, and ultimately provide users with high-quality video services. We also hope that EDCrammer can improve overall service quality in 5G environment, Augmented Reality/Virtual Reality (AR/VR), Intelligent Transportation System (ITS), Internet of Things (IoT), etc.},
DOI = {10.3390/app9122560}
}



@Article{su11133499,
AUTHOR = {Jung, Se-Hoon and Huh, Jun-Ho},
TITLE = {A Novel on Transmission Line Tower Big Data Analysis Model Using Altered K-means and ADQL},
JOURNAL = {Sustainability},
VOLUME = {11},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {3499},
URL = {https://www.mdpi.com/2071-1050/11/13/3499},
ISSN = {2071-1050},
ABSTRACT = {This study sought to propose a big data analysis and prediction model for transmission line tower outliers to assess when something is wrong with transmission line tower big data based on deep reinforcement learning. The model enables choosing automatic cluster K values based on non-labeled sensor big data. It also allows measuring the distance of action between data inside a cluster with the Q-value representing network output in the altered transmission line tower big data clustering algorithm containing transmission line tower outliers and old Deep Q Network. Specifically, this study performed principal component analysis to categorize transmission line tower data and proposed an automatic initial central point approach through standard normal distribution. It also proposed the A-Deep Q-Learning algorithm altered from the deep Q-Learning algorithm to explore policies based on the experiences of clustered data learning. It can be used to perform transmission line tower outlier data learning based on the distance of data within a cluster. The performance evaluation results show that the proposed model recorded an approximately 2.29%~4.19% higher prediction rate and around 0.8% ~ 4.3% higher accuracy rate compared to the old transmission line tower big data analysis model.},
DOI = {10.3390/su11133499}
}




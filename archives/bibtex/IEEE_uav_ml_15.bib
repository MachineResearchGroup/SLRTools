@ARTICLE{9117104,
author={Bouhamed, Omar and Ghazzai, Hakim and Besbes, Hichem and Massoud, Yehia},
journal={IEEE Access}, title={A UAV-Assisted Data Collection for Wireless Sensor Networks: Autonomous Navigation and Scheduling},
year={2020},
volume={8},
number={},
pages={110446-110460},
abstract={Nowadays, Wireless Sensor Networks (WSNs) are playing a vital and sustainable role in many verticals touching different aspects of our lives including civil, public, and military applications. WSNs majorly consist of a few to several sensor nodes, that are connected to each other via wireless communication links and require real-time or delayed data transfer. In this paper, we propose an autonomous Unmanned Aerial Vehicle (UAV)-enabled data gathering mechanism for delay-tolerant WSN applications. The objective is to employ a self-trained UAV as a flying mobile unit collecting data from ground sensor nodes spatially distributed in a given geographical area during a predefined period of time. In this approach, two Reinforcement Learning (RL) approaches, specifically Deep Deterministic Gradient Decent (DDPG) and Q-learning (QL) algorithms, are jointly employed to train the UAV to understand the environment and provide effective scheduling to accomplish its data collection mission. The DDPG is used to autonomously decide the best trajectory to adopt in an obstacle-constrained environment, while the QL is developed to determine the order of nodes to visit such that the data collection time is minimized. The schedule is obtained while considering the limited battery capacity of the flying unit, its need to return the charging station, the time windows of data acquisition, and the priority of certain sensor nodes. Customized reward functions are designed for each RL model and, through numerical simulations, we investigate their training performances. We also analyze the behavior of the autonomous UAV for different selected scenarios and corroborate the ability of the proposed approach in performing effective data collection. A comparison with the deterministic optimal solution is provided to validate the performance of the learning-based approach.},
keywords={Data collection;Wireless sensor networks;Batteries;Navigation;Unmanned aerial vehicles;Wireless communication;Real-time systems;Internet-of-Things;data gathering;reinforcement learning;scheduling;unmanned aerial vehicles},
doi={10.1109/ACCESS.2020.3002538},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9607741,
author={Alvey, Brendan and Anderson, Derek T. and Buck, Andrew and Deardorff, Matthew and Scott, Grant and Keller, James M.},
booktitle={2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}, title={Simulated Photorealistic Deep Learning Framework and Workflows to Accelerate Computer Vision and Unmanned Aerial Vehicle Research},
year={2021},
volume={},
number={},
pages={3882-3891},
abstract={Deep learning (DL) is producing state-of-the-art results in a number of unmanned aerial vehicle (UAV) tasks from low level signal processing to object detection, 3D mapping, tracking, fusion, autonomy, control, and beyond. However, barriers exist. For example, most DL algorithms re-quire big data, but supervised ground truth is a bottle-neck, fueling topics like self-supervised learning. While it is well-known that hardware and data augmentation plays a significant role in performance, it is not well understood which data augmentations or what real data need be collected. Furthermore, existing datasets do not have sufficient ground truth nor variety to support adequate con-trolled experimental research into understanding and mitigating limitations in DL algorithms, models, data, and biases. In this article, we address the combination of photo-realistic simulation, open source libraries, and high quality content (models, materials, and environments) to develop workflows to mitigate the above challenges and accelerate DL-enabled computer vision research. Herein, examples are provided relative to data collection, detection, passive ranging, and human-robot teaming. Online video tutorials are also provided at https://github.com/MizzouINDFUL/UEUAVSim.},
keywords={Deep learning;Computer vision;Three-dimensional displays;Computational modeling;Signal processing algorithms;Tutorials;Object detection},
doi={10.1109/ICCVW54120.2021.00435},
ISSN={2473-9944},
month={Oct},}
@INPROCEEDINGS{9580253,
author={Sha, Deshuang and Zhao, Rui},
booktitle={2021 IEEE/CIC International Conference on Communications in China (ICCC)}, title={DRL-based Task Offloading and Resource Allocation in Multi-UAV-MEC Network with SDN},
year={2021},
volume={},
number={},
pages={595-600},
abstract={Mobile edge computing (MEC) is applied to 5G communication to meet the needs of large-scale data communication. Unmanned aerial vehicle (UAV) can be used as air base station to provide edge computing services for users in remote areas. In this paper, we consider a multi- UAV enabled MEC (i.e., Multi-UAV-MEC) network, where software defined network (SDN) is adopted to improve the quality of services (QoS) for all users, and we study the problem of task offloading and resource allocation. In the proposed network, UAV s act as MEC servers to provide computation offloading services for ground equipments (GEs), and a SDN controller is responsible for collecting network global information and providing offloading decision and resource allocation strategy for all GEs and UAV s. We aim to minimize the weighted sum of the task processing delay and energy consumption in the network, and the above problem is a mixed-integer and non-convex problem. To address this challenge, we transform the problem into a MDP, and propose a deep reinforcement learning (DRL)-based algorithm. The SDN controller is considered as a agent to learn the optimal offloading and resource allocation strategy. Simulation results show that the proposed DRL-based algorithm can achieve better performance than other baseline algorithms under different conditions.},
keywords={Costs;Simulation;Reinforcement learning;Quality of service;Transforms;Germanium;Unmanned aerial vehicles;Mobile edge computing;unmanned aerial vehicle;software defined network;deep reinforcement learning},
doi={10.1109/ICCC52777.2021.9580253},
ISSN={2377-8644},
month={July},}
@ARTICLE{8246580,
author={Xiao, Liang and Lu, Xiaozhen and Xu, Dongjin and Tang, Yuliang and Wang, Lei and Zhuang, Weihua},
journal={IEEE Transactions on Vehicular Technology}, title={UAV Relay in VANETs Against Smart Jamming With Reinforcement Learning},
year={2018},
volume={67},
number={5},
pages={4087-4097},
abstract={Frequency hopping-based antijamming techniques are not always applicable in vehicular ad hoc networks (VANETs) due to the high mobility of onboard units (OBUs) and the large-scale network topology. In this paper, we use unmanned aerial vehicles (UAVs) to relay the message of an OBU and improve the communication performance of VANETs against smart jammers that observe the ongoing OBU and UAV communication status and even induce the UAV to use a specific relay strategy and then attack it accordingly. More specifically, the UAV relays the OBU message to another roadside unit (RSU) with a better radio transmission condition if the serving RSU is heavily jammed or interfered. The interactions between a UAV and a smart jammer are formulated as an antijamming UAV relay game, in which the UAV decides whether or not to relay the OBU message to another RSU, and the jammer observes the UAV and the VANET strategy and chooses the jamming power accordingly. The Nash equilibria of the UAV relay game are derived to reveal how the optimal UAV relay strategy depends on the transmit cost and the UAV channel model. A hotbooting policy hill climbing-based UAV relay strategy is proposed to help the VANET resist jamming in the dynamic game without being aware of the VANET model and the jamming model. Simulation results show that the proposed relay strategy can efficiently reduce the bit error rate of the OBU message and thus increase the utility of the VANET compared with a Q-learning-based scheme.},
keywords={Jamming;Relays;Unmanned aerial vehicles;Games;Vehicular ad hoc networks;Mobile communication;Interference;VANET;jamming;reinforcement learning;game theory;unmanned aerial vehicles},
doi={10.1109/TVT.2018.2789466},
ISSN={1939-9359},
month={May},}
@ARTICLE{8854903,
author={Li, Kai and Ni, Wei and Tovar, Eduardo and Jamalipour, Abbas},
journal={IEEE Transactions on Vehicular Technology}, title={On-Board Deep Q-Network for UAV-Assisted Online Power Transfer and Data Collection},
year={2019},
volume={68},
number={12},
pages={12215-12226},
abstract={Unmanned Aerial Vehicles (UAVs) with Microwave Power Transfer (MPT) capability provide a practical means to deploy a large number of wireless powered sensing devices into areas with no access to persistent power supplies. The UAV can charge the sensing devices remotely and harvest their data. A key challenge is online MPT and data collection in the presence of on-board control of a UAV (e.g., patrolling velocity) for preventing battery drainage and data queue overflow of the devices, while up-to-date knowledge on battery level and data queue of the devices is not available at the UAV. In this paper, an on-board deep Q-network is developed to minimize the overall data packet loss of the sensing devices, by optimally deciding the device to be charged and interrogated for data collection, and the instantaneous patrolling velocity of the UAV. Specifically, we formulate a Markov Decision Process (MDP) with the states of battery level and data queue length of devices, channel conditions, and waypoints given the trajectory of the UAV; and solve it optimally with Q-learning. Furthermore, we propose the on-board deep Q-network that enlarges the state space of the MDP, and a deep reinforcement learning based scheduling algorithm that asymptotically derives the optimal solution online, even when the UAV has only outdated knowledge on the MDP states. Numerical results demonstrate that our deep reinforcement learning algorithm reduces the packet loss by at least 69.2%, as compared to existing non-learning greedy algorithms.},
keywords={Trajectory;Batteries;Data collection;Wireless communication;Wireless sensor networks;Resource management;Sensors;Unmanned aerial vehicle;microwave power transfer;online resource allocation;deep reinforcement learning;Markov decision process},
doi={10.1109/TVT.2019.2945037},
ISSN={1939-9359},
month={Dec},}
@ARTICLE{9385412,
author={Zhang, Tiankui and Lei, Jiayi and Liu, Yuanwei and Feng, Chunyan and Nallanathan, Arumugam},
journal={IEEE Transactions on Green Communications and Networking}, title={Trajectory Optimization for UAV Emergency Communication With Limited User Equipment Energy: A Safe-DQN Approach},
year={2021},
volume={5},
number={3},
pages={1236-1247},
abstract={In post-disaster scenarios, it is challenging to provide reliable and flexible emergency communications, especially when the mobile infrastructure is seriously damaged. This article investigates the unmanned aerial vehicle (UAV)-based emergency communication networks, in which UAV is used as a mobile aerial base station for collecting information from ground users in affected areas. Due to the breakdown of ground power system after disasters, the available energy of affected user equipment (UE) is limited. Meanwhile, with the complex geographical conditions after disasters, there are obstacles affecting the flight of UAV. Aiming at maximizing the uplink throughput of UAV networks during the flying time, we formulate the UAV trajectory optimization problem considering UE energy limitation and location of obstacles. Since the constraint on UE energy is dynamic and long-term cumulative, it is hard to be solved directly. We transform the problem into a constrained Markov decision-making process (CMDP) with UAV as agent. To tackle the CMDP, we propose a safe-deep-Q-network (safe-DQN)-based UAV trajectory design algorithm, where the UAV learns to selects the optimal action in reasonable policy sets. Simulation results reveal that: 1) the uplink throughput of the proposed algorithm converges within multiple iterations and 2) compared with the benchmark algorithms, the proposed algorithm performs better in terms of uplink throughput and UE energy efficiency, achieving a good trade-off between UE energy consumption and uplink throughput.},
keywords={Unmanned aerial vehicles;Trajectory;Communication networks;Uplink;Throughput;Wireless communication;Markov processes;Constrained Markov decision-making process;emergency communication;trajectory design;deep reinforcement learning},
doi={10.1109/TGCN.2021.3068333},
ISSN={2473-2400},
month={Sep.},}
@INPROCEEDINGS{9066133,
author={Liu, Bo and Zhang, Yue and Fu, Shupo and Liu, Xuan},
booktitle={2019 15th International Conference on Mobile Ad-Hoc and Sensor Networks (MSN)}, title={Reduce UAV Coverage Energy Consumption through Actor-Critic Algorithm},
year={2019},
volume={},
number={},
pages={332-337},
abstract={Unmanned aerial vehicles (UAVs) are powerful tools for several applications like transportation and observation. The main reason is the enormous capabilities of such aerial vehicles in terms of mobility, autonomy, communication and processing power at a relatively low-cost. In recent years, due to the continuous development of UAV technology, it has broad prospects in regional coverage application. However, in practical applications, it is very difficult to get an actual mathematical model because of the limited data obtained. Therefore, we chose to use reinforcement learning to solve this problem. In this paper, we form a rule by Reinforcement Learning to cover the coverage of UAVs. We mainly solve two problems: (1) Reduce UAV energy consumption by reducing UAV action times. (2) Solve the huge problem of the dimension space of the value function by using the Actor-Critic algorithm. We compare our method with the traditional coverage method, the result shows that the UAV using the reinforcement learning model consumes less energy often when the same coverage area is completed.},
keywords={Learning (artificial intelligence);Task analysis;Mathematical model;Drones;Robots;Energy consumption;Reinforcement Learning;UAV;coverage;energy},
doi={10.1109/MSN48538.2019.00069},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9604698,
author={Ozkan, Zehra and Bayhan, Erdem and Namdar, Mustafa and Basgumus, Arif},
booktitle={2021 5th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)}, title={Object Detection and Recognition of Unmanned Aerial Vehicles Using Raspberry Pi Platform},
year={2021},
volume={},
number={},
pages={467-472},
abstract={In this study, the methods of deep learningbased detection and recognition of threats, evaluated in terms of military and defense industry, using Raspberry Pi platform by unmanned aerial vehicles (UAV) are presented. In the proposed approach, firstly, the training for machine learning on the objects is carried out using convolutional neural networks, which is one of the deep learning algorithms. By choosing the Faster-RCNN and SSD MobileNet V2 architectures of the deep learning method, it is aimed to compare the achievements of the accuracy at the end of the training. In order to be used in the training and testing stages of the recommended methods, data sets containing images selected from different weather, land conditions and different time periods of the day are determined. The model for the detection and recognition of the threatening elements is trained, using 3948 images. Then, the trained model was transferred to the Raspberry Pi 4 Model B electronic board. The method of detecting and recognizing the objects is tested with military operation images and records taken by the UAVs via Raspberry Pi Camera V2 module. While an accuracy rate of %91 has been achieved in the Faster-RCNN architecture in object detection and recognition, this rate has been observed as %88 in the SSD MobileNet V2 architecture.},
keywords={Training;Deep learning;Image recognition;Machine learning algorithms;Defense industry;Object detection;Unmanned aerial vehicles;Faster-RCNN;UAV;machine learning;object recognition;object detection;Raspberry Pi;SSD MobileNet V2},
doi={10.1109/ISMSIT52890.2021.9604698},
ISSN={},
month={Oct},}
@ARTICLE{9372298,
author={Feriani, Amal and Hossain, Ekram},
journal={IEEE Communications Surveys Tutorials}, title={Single and Multi-Agent Deep Reinforcement Learning for AI-Enabled Wireless Networks: A Tutorial},
year={2021},
volume={23},
number={2},
pages={1226-1252},
abstract={Deep Reinforcement Learning (DRL) has recently witnessed significant advances that have led to multiple successes in solving sequential decision-making problems in various domains, particularly in wireless communications. The next generation of wireless networks is expected to provide scalable, low-latency, ultra-reliable services empowered by the application of data-driven Artificial Intelligence (AI). The key enabling technologies of future wireless networks, such as intelligent meta-surfaces, aerial networks, and AI at the edge, involve more than one agent which motivates the importance of multi-agent learning techniques. Furthermore, cooperation is central to establishing self-organizing, self-sustaining, and decentralized networks. In this context, this tutorial focuses on the role of DRL with an emphasis on deep Multi-Agent Reinforcement Learning (MARL) for AI-enabled wireless networks. The first part of this paper will present a clear overview of the mathematical frameworks for single-agent RL and MARL. The main idea of this work is to motivate the application of RL beyond the model-free perspective which was extensively adopted in recent years. Thus, we provide a selective description of RL algorithms such as Model-Based RL (MBRL) and cooperative MARL and we highlight their potential applications in future wireless networks. Finally, we overview the state-of-the-art of MARL in fields such as Mobile Edge Computing (MEC), Unmanned Aerial Vehicles (UAV) networks, and cell-free massive MIMO, and identify promising future research directions. We expect this tutorial to stimulate more research endeavors to build scalable and decentralized systems based on MARL.},
keywords={Tutorials;Wireless networks;Games;Computational modeling;Training;5G mobile communication;Reinforcement learning;AI-enabled wireless networks;deep reinforcement learning (DRL);multi-agent reinforcement learning (MARL);model-based reinforcement learning (MBRL);decentralized networks},
doi={10.1109/COMST.2021.3063822},
ISSN={1553-877X},
month={Secondquarter},}
@INPROCEEDINGS{9200951,
author={Martinez-Alpiste, Ignacio and Golcarenarenji, Gelayol and Wang, Qi and Alcaraz Calero, Jose M.},
booktitle={2020 European Conference on Networks and Communications (EuCNC)}, title={Altitude-Adaptive and Cost-Effective Object Recognition in an Integrated Smartphone and UAV System},
year={2020},
volume={},
number={},
pages={316-320},
abstract={Human Search and Rescue (SAR) tasks are mission-critical and take place in the wild, and thus solutions require timely and accurate human detection on a highly portable platform. This paper proposes a novel lightweight and practical SAR system that meets those demanding requirements by running optimised machine learning in a smartphone, interoperable with Unmanned Aerial Vehicles (UAV) that provides live video feed. In particular, the proposed approach significantly extends a standard machine learning algorithm to achieve adaptive object recognition in response to changing altitudes to accelerate the speed of finding missing people and eliminate redundant computing. Our approach achieved 91.02% of accuracy and real-time speed on a smartphone that hosts the machine learning platform and the new algorithm. This proposed system is highly portable, cost-effective, fast with high accuracy suitable for UAV applications.},
keywords={Unmanned aerial vehicles;Object detection;Detectors;Machine learning;Europe;Internet of Things;Task analysis;UAV;Machine learning;Deep learning;SAR missions;YOLOv3},
doi={10.1109/EuCNC48522.2020.9200951},
ISSN={2575-4912},
month={June},}
@INPROCEEDINGS{9274972,
author={Zhen, Chen and De-rong, Chen and Jiu-lu, Gong},
booktitle={2020 3rd International Conference on Unmanned Systems (ICUS)}, title={A Deep Learning Based Distributed Compressive Video Sensing Reconstruction Algorithm for Small Reconnaissance UAV},
year={2020},
volume={},
number={},
pages={668-672},
abstract={Distributed compressive video sensing (DCVS) is an effective method for small reconnaissance Unmanned Aerial Vehicle(UAV) to obtain high-quality videos on the battlefield. However, the existing reconstruction algorithms based on deep learning fail to make full use of the temporal correlation of videos, resulting in low reconstruction quality. In this paper, a measurement information compensation network called MCINet is used to compensate for the information in non-key frame measurements with the help of key frame measurements before initial recovery. At joint reconstruction stage, a neural network with autoencoder mix with recurrent neural network (RNN) structure called ECLDNet which makes full use of high-quality key frames is adopted, the encoder extracts temporal-spatial features from key and non-key frames, the RNN uses features of key frame to compensate for missing details in non-key frame features, the decoder reconstructs images in a symmetrical way with encoder. Experimental results indicate that our model can get an additional performance gain of more than 1.5 dB peak signal-noise ratio (PSNR) without any changes at the encoding end. The reconstruction runtime of our model increases slightly, but is still much less than iterative reconstruction algorithms due to the non-iterative nature of deep learning.},
keywords={Image reconstruction;Feature extraction;Image quality;Correlation;Convolution;Decoding;Reconnaissance;small reconnaissance UAV;distributed compressive video sensing;deep learning;temporal correlation},
doi={10.1109/ICUS50048.2020.9274972},
ISSN={},
month={Nov},}
@ARTICLE{9585312,
author={Yuan, Tingting and Rothenberg, Christian Esteve and Obraczka, Katia and Barakat, Chadi and Turletti, Thierry},
journal={IEEE Transactions on Network and Service Management}, title={Harnessing UAVs for Fair 5G Bandwidth Allocation in Vehicular Communication via Deep Reinforcement Learning},
year={2021},
volume={18},
number={4},
pages={4063-4074},
abstract={Terrestrial infrastructure-based wireless networks do not always guarantee their resources will be shared uniformly by nodes in vehicular networks. This is due mainly to the uneven and dynamic geographical distribution of vehicles and path loss effects. In this paper, we leverage multiple fifth-generation (5G) unmanned aerial vehicles (UAVs) to enhance fairness in network resource allocation among vehicles by positioning UAVs on-demand as “flying communication infrastructure”. We propose a deep reinforcement learning (DRL) approach to determine UAVs’ position to improve network resource allocation fairness and efficiency while considering the UAVs’ flying range, communication range, and energy constraints. We use a parametric fairness function to attain a number of resource allocation objectives ranging from maximizing the total throughput of vehicles, maximizing minimum throughput, and achieving proportional bandwidth allocation. Simulation results show that the proposed DRL approach to UAV positioning can improve network resource allocation according to the targeted fairness objective.},
keywords={5G mobile communication;Wireless networks;Simulation;Reinforcement learning;Channel allocation;Autonomous aerial vehicles;Throughput;Unmanned aerial vehicles (UAV);fifth-generation (5G);fairness;deep reinforcement learning (DRL)},
doi={10.1109/TNSM.2021.3122505},
ISSN={1932-4537},
month={Dec},}
@INPROCEEDINGS{9259811,
author={Ates, Ugurkan},
booktitle={2020 Innovations in Intelligent Systems and Applications Conference (ASYU)}, title={Long-Term Planning with Deep Reinforcement Learning on Autonomous Drones},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this paper, we study a long-term planning scenario that is based on drone racing competitions held in real life. We conducted this experiment on a framework created for “Game of Drones: Drone Racing Competition” at NeurIPS 2019. The racing environment was created using Microsoft's AirSim Drone Racing Lab. We have trained a reinforcement learning agent, simulated quadrotor in our case, with the Policy Proximal Optimization (PPO) algorithm. After training process it was successfully able to compete against another simulated quadrotor that was running a classical path planning algorithm. Agent observations consist of data from IMU sensors, GPS coordinates of drone obtained through simulation and opponent drone GPS information. Using opponent drone GPS information during training helps dealing with complex state spaces which serves as expert guidance. This approach allows efficient and stable training process. Our work fits into Clought's level 10 UAV autonomy categorization. All experiments performed in this paper can be found and reproduced with code at our GitHub repository.},
keywords={Drones;Task analysis;Training;Robots;Planning;Reinforcement learning;Neural networks;Deep Reinforcement Learning;Path Planning;Machine Learning;Drone Racing},
doi={10.1109/ASYU50717.2020.9259811},
ISSN={},
month={Oct},}
@ARTICLE{9499090,
author={Moon, SungTae and Youn, Wonkeun and Bang, Hyochoong},
journal={IEEE Sensors Journal}, title={Novel Deep-Learning-Aided Multimodal Target Tracking},
year={2021},
volume={21},
number={18},
pages={20730-20739},
abstract={Existing interacting multiple models (IMMs) are limited by the time delay in responding to system model jumps due to the nature of the soft hand-off algorithm that interacts among subfilters. To address this issue, a novel method for deep-learning-aided localization of a multimodel system is proposed in this paper. The main contribution of the proposed algorithm is that a mode estimation network based on a bidirectional long short-term memory network (BiLSTM) is newly proposed to quickly and accurately estimate the multimodal system mode, which minimizes the delay. In addition, a federated Kalman filter with a selective reinitialization algorithm from the proposed BiLSTM is proposed for better estimation of multimodal systems. Simulation and flight test results of a UAV demonstrate that the proposed algorithm yields better localization performance than the conventional IMM algorithm because the proposed mode estimation network has fast and accurate mode detection.},
keywords={Estimation;Sensors;Kalman filters;Adaptation models;Target tracking;Location awareness;Heuristic algorithms;Bidirectional long short-term memory;deep learning;interacting multiple model;Kalman filter;localization;unmanned aerial vehicle},
doi={10.1109/JSEN.2021.3100588},
ISSN={1558-1748},
month={Sep.},}
@ARTICLE{9328118,
author={Fu, Jiangmeng and Che, Gaofeng},
journal={IEEE Access}, title={Fusion Fault Diagnosis Model for Six-Rotor UAVs Based on Conformal Fourier Transform and Improved Self-Organizing Feature Map},
year={2021},
volume={9},
number={},
pages={14422-14436},
abstract={If the fault sources can be located in a timely and accurate manner when an unmanned aerial vehicle (UAV) has an early minor fault, a major accident can be avoided. In light of the early fault of the six-rotor UAV motors, this paper proposes a fusion fault diagnosis model based on Conformal Fourier Transform (CFT) and the improved Self-Organizing Feature Map (SOM) neural network. Firstly, to overcome the weakening of UAV fault information caused by external interference and solve the problem that the non-uniform distribution of the collected flight data affects the accuracy of the frequency domain processing, on the basis of changing the processing method of the Fourier integral kernel and using high-order numerical integration, an improved Conformal Fourier Transform (CFT) algorithm optimized by spectrum refinement strategy is proposed. Then this algorithm is used to further intensify the main features and build a clear fault state in a cycle processing method. Secondly, an improved SOM neural network is designed. We use the unweighted average distance (UPGMA) of the agglomerative hierarchical clustering algorithm to detect the clustering areas of each pattern category of the data samples, and the weight vectors of different clustering areas are used to randomly initialize the connection weights of SOM network, thereby improving the clustering speed and convergence effect. On this basis, CFT algorithm is integrated into the improved SOM network to realize the multi-module collaboration strategy and finally form a new fusion fault diagnosis model.},
keywords={Fault diagnosis;Neural networks;Self-organizing feature maps;Interpolation;Feature extraction;Clustering algorithms;Deep learning;CFT algorithm;improved SOM network;main feature intensification;hierarchical clustering;fault diagnosis},
doi={10.1109/ACCESS.2021.3052317},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9259777,
author={Kantue, Paulin and Pedro, Jimoh Olarewaju},
booktitle={2020 24th International Conference on System Theory, Control and Computing (ICSTCC)}, title={Integrated Fault Detection and Diagnosis of an Unmanned Aerial Vehicle using Time Difference of Arrival},
year={2020},
volume={},
number={},
pages={336-342},
abstract={An integrated approach to the fault detection and diagnosis (FDD) of an unmanned aerial vehicle is presented. A novel approach using the Time Difference Of Arrival (TDOA) principle has been developed to detect, isolate and identify an incipient fault condition in the rotor dynamics. The requirements of a reconfigurable controller (RC) has been taken into account through the real-time implementation of a continuous forward algorithm (CFA) with a golden section search (GSS) combined with a meta-heuristic global optimization technique. The training and testing data for Radial Basis Function Neural Networks (RBF-NN) learning and prediction were supplied in discrete-time and its integration capacity validated through a Hardware-in-the-loop simulation (HILS) using a Teensy 3.6 microcontroller. The Pseudo real-time desktop simulation showed that the FDD algorithm was able to detect and isolate an incipient rotor fault and supply the RC a post-fault model and associated fault uncertainties. This method showed robustness towards prediction errors (bias and variance) and can be used in an integrated fault-tolerant control framework.},
keywords={Fault detection;Time difference of arrival;Uncertainty;Fault tolerant systems;Fault tolerance;Artificial neural networks;Pulse width modulation;fault detection and diagnosis;Unmanned Systems;rotor dynamics;radial basis functions;incipient fault;time difference of arrival},
doi={10.1109/ICSTCC50638.2020.9259777},
ISSN={2372-1618},
month={Oct},}
@ARTICLE{8413083,
author={Liu, Jiajie and Wang, Weiping and Wang, Tao and Shu, Zhe and Li, Xiaobo},
journal={IEEE Access}, title={A Motif-Based Rescue Mission Planning Method for UAV Swarms Usingan Improved PICEA},
year={2018},
volume={6},
number={},
pages={40778-40791},
abstract={Affected by the rescue environment and the unmanned aerial vehicle(UAV) communication technology, communication among UAVs is greatly restricted. How to do rescue mission planning for UAV swarms underlimited communication has become a difficult problem. This paper proposes a motif-based mission planning model which generates amiss ion planning strategy as a task priority execution order is inputted. The choice of mission planning strategy turns to be the choice of a task priority execution order which is a many-objective optimization problem. Permutation and combination of task priority execution order contribute to the generation of mass feasible task planning strategies. The increase in the number of tasks leads to the explosion of the amount of calculation. We enhance preference-inspired co-evolutionary algorithm with goal vectors (PICEA-g) by using the K-means clustering method in the step of offspring selection to select out next-generation goal vectors. The proposed algorithm, calledk-PICEA-g is applied in the optimization processminimizing, simultaneously, the mission completion time, the total number of changed connections, and the averagenumber of used UAVs through changing the priority execution order oftasks. As an example of application, we apply the improvedPICEA-g to optimize the execution order of a set of tasks,achieving a set of non-dominated solutions from which the decisionmaker can select the most adequate one. By experiments, thefeasibility and effectiveness of this algorithm are validated.},
keywords={Planning;Task analysis;Unmanned aerial vehicles;Mathematical model;Optimization;Clustering algorithms;Evolutionary computation;Rescue mission planning;UAV swarm;motif;MDLS;optimization;K-means clustering;k-PICEA-g},
doi={10.1109/ACCESS.2018.2857503},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9013626,
author={Zhang, Qianqian and Saad, Walid and Bennis, Mehdi},
booktitle={2019 IEEE Global Communications Conference (GLOBECOM)}, title={Reflections in the Sky: Millimeter Wave Communication with UAV-Carried Intelligent Reflectors},
year={2019},
volume={},
number={},
pages={1-6},
abstract={In this paper, a novel approach that uses an unmanned aerial vehicle (UAV)-carried intelligent reflector (IR) is proposed to enhance the performance of millimeter wave (mmW) networks. In particular, the UAV-IR is used to intelligently reflect mmW beamforming signals from a base station towards a mobile outdoor user, while harvesting energy from mmW signals to power the IR. To maintain a line-of-sight (LOS) channel, a reinforcement learning (RL) approach, based on Q- learning and neural networks, is proposed to model the propagation environment, such that the location and reflection coefficient of the UAV-IR can be optimized to maximize the downlink transmission capacity. Simulation results show a significant advantage for using a UAV-IR over a static IR, in terms of the average data rate and the achievable downlink LOS probability. The results also show that the RL-based deployment of the UAV-IR further improves the network performance, relative to a scheme without learning.},
keywords={Downlink;Array signal processing;Radio frequency;Wireless communication;Antennas;Signal to noise ratio;Coherence},
doi={10.1109/GLOBECOM38437.2019.9013626},
ISSN={2576-6813},
month={Dec},}
@INPROCEEDINGS{9401360,
author={Torres-Tello, Julio and Ko, Seok-Bum},
booktitle={2021 IEEE International Symposium on Circuits and Systems (ISCAS)}, title={Identifying Useful Features in Multispectral Images with Deep Learning for Optimizing Wheat Yield Prediction},
year={2021},
volume={},
number={},
pages={1-5},
abstract={Since unmanned aerial vehicles have been utilized in plant phenotyping, they have revolutionarily improved its accuracy. In this paper, we introduce a deep learning based approach for optimizing the yield prediction process of spring wheat (triticum aestivum), using multispectral images. We assessed both the temporal features to find the most valuable time to take images, as well as the contribution of spectral bands. We processed full stage multispectral images from four site-years (two sites during two years) of a wheat breeding project, and determined the prediction accuracy of the image-based predicted yields and compared them to the harvested yields taken in the field. The results compared the wheat images throughout the season and validated the most crucial flying times for acquiring images were at late-heading, late-flowering, dough-development, and harvesting stages. The two most useful colour-bands for yield prediction were red and red-edge. We found that removing these bands significantly decreased the prediction correctness. The results of this research could be a tool for the development of more efficient sensors and strategies for data collection in plant phenotyping.},
keywords={Deep learning;Training;Vegetation mapping;Predictive models;Data collection;Unmanned aerial vehicles;Springs;deep learning;convolutional neural networks;artificial vision;UAV;wheat yield prediction;plant phenotyping},
doi={10.1109/ISCAS51556.2021.9401360},
ISSN={2158-1525},
month={May},}
@INPROCEEDINGS{9162899,
author={Mukherjee, Mithun and Kumar, Vikas and Lat, Ankit and Guo, Mian and Matam, Rakesh and Lv, Yunrong},
booktitle={IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, title={Distributed Deep Learning-based Task Offloading for UAV-enabled Mobile Edge Computing},
year={2020},
volume={},
number={},
pages={1208-1212},
abstract={Unmanned Aerial Vehicle (UAV)-enabled mobile edge computing (MEC) is considered to offer computational capabilities to the resource-constraints end-users. In this paper, we study the task offloading strategy in UAV-enabled MEC systems, where end-users offload the computation-intensive tasks to the UAV to minimize the overall cost in terms of the weighted delay and energy consumption. The end-users either process the task by itself or offload the tasks to the UAV that acts as a computing access point. However, due to the computation bottleneck and limited channel capacity between UAV and the end-users, it becomes a challenging issue to offload the entire tasks to the UAV. Thus, to find the optimal offloading decision for the tasks generated by the end-users, we build a distributed deep neural network (DNN). In the proposed distributed DNN model, we train multiple DNNs in the same training instance, and finally, for validation, we select the DNN that gives the least training loss. For faster convergence of the training process, we use the optimal generated offloading decision using a Quadratically Constrained Linear Program (QCLP) with Semidefinite Relaxation (SDR). The extensive simulation results show that the offloading decision produced by the trained DNN can achieve near-optimal performance with numerous system parameter settings.},
keywords={Task analysis;Training;Delays;Energy consumption;Unmanned aerial vehicles;Distributed databases;Optimization},
doi={10.1109/INFOCOMWKSHPS50562.2020.9162899},
ISSN={},
month={July},}
@ARTICLE{8612916,
author={Keneni, Blen M. and Kaur, Devinder and Al Bataineh, Ali and Devabhaktuni, Vijaya K. and Javaid, Ahmad Y. and Zaientz, Jack D. and Marinier, Robert P.},
journal={IEEE Access}, title={Evolving Rule-Based Explainable Artificial Intelligence for Unmanned Aerial Vehicles},
year={2019},
volume={7},
number={},
pages={17001-17016},
abstract={In this paper, an explainable intelligence model that gives the logic behind the decisions unmanned aerial vehicle (UAV) makes when it is on a predefined mission and chooses to deviate from its designated path is developed. The explainable model is on a visual platform in the format of if-then rules derived from the Sugeno-type fuzzy inference model. The model is tested using the data recorded from three different missions. In each mission, adverse weather, conditions and enemy locations are introduced at random locations along the path of the mission. There are two phases to the model development. In the first phase, the Mamdani fuzzy model is used to create rules to steer the UAV along the designated mission and the rules of engagement when it encounters weather and enemy locations along and near its chosen mission. The data are gathered as UAV traverses on each mission. In the second phase, the data gathered from these missions are used to create a reverse model using a Sugeno-type fuzzy inference system based on the subtractive clustering in the data. The model has seven inputs (time, x-coordinate, y-coordinate, heading direction, engage in attack, continue mission, and steer UAV) and two outputs (weather conditions and distance from the enemy). This model predicts the outputs regarding the weather conditions and enemy positions whenever UAV deviates from the predefined path. The model is optimized with respect to the number of rules and prediction accuracy by adjusting subtractive clustering parameters. The model is then fine-tuned with ANFIS. The final model has six rules and root mean square error value that is less than 0.05. Furthermore, to check the robustness of the model, the Gaussian random noise is added to a UAV path, and the prediction accuracy is validated.},
keywords={Fuzzy logic;Unmanned aerial vehicles;Predictive models;Machine learning;Data models;Fuzzy sets;Atmospheric modeling;Explainable artificial intelligence (XAI);fuzzy logic;ANFIS;unmanned aerial vehicle (UAV);subtractive clustering},
doi={10.1109/ACCESS.2019.2893141},
ISSN={2169-3536},
month={},}
@ARTICLE{9406961,
author={Zhao, Rui and Xia, Junjuan and Zhao, Zichao and Lai, Shiwei and Fan, Lisheng and Li, Dong},
journal={IEEE Transactions on Green Communications and Networking}, title={Green MEC Networks Design Under UAV Attack: A Deep Reinforcement Learning Approach},
year={2021},
volume={5},
number={3},
pages={1248-1258},
abstract={In this paper, we propose a novel optimization framework for a secure and green mobile edge computing (MEC) network, through a deep reinforcement learning approach, where the secure data transmission is threatened by the unmanned aerial vehicle (UAV). To alleviate the local burden on the computation, some computational tasks can be offloaded to the computational access points (CAPs), at the cost of price, transmission latency and energy consumption. By jointly reducing the price, latency and energy consumption, we propose a novel optimization framework for the secure MEC network, based on the deep reinforcement learning. Specifically, we firstly employ several optimization criteria, where criterion I minimizes the linear combination of price, latency and energy consumption, criterion II minimizes the price with the constrained latency and energy consumption, criterion III minimizes the latency with the constrained price and energy consumption, while criterion IV minimizes the energy consumption with the constrained price and latency. For each criterion, we then propose an optimization framework which can dynamically adjust the task offloading ratio and bandwidth allocation ratio simultaneously, where a novel feature extraction network is proposed to improve the training effect. Simulation results are finally demonstrated to verify the effective of the proposed optimization framework.},
keywords={Energy consumption;Task analysis;Optimization;Unmanned aerial vehicles;Mobile handsets;Computational modeling;Security;MEC;UAV;latency;energy consumption;optimization},
doi={10.1109/TGCN.2021.3073939},
ISSN={2473-2400},
month={Sep.},}
@ARTICLE{9385103,
author={Nie, Wei and Han, Zhi-Chao and Zhou, Mu and Xie, Liang-Bo and Jiang, Qing},
journal={IEEE Sensors Journal}, title={UAV Detection and Identification Based on WiFi Signal and RF Fingerprint},
year={2021},
volume={21},
number={12},
pages={13540-13550},
abstract={The security threats caused by the popularity of Unmanned Aerial Vehicles (UAVs) have received much attention. In this paper, a UAV detection and identification system based on WiFi signal and radio frequency (RF) fingerprint is proposed. The system firstly conducts UAV detection and after the UAV is detected, fractal dimension (FD), axially integrated bispectra (AIB), and square integrated bispectra (SIB) are extracted as UAV RF fingerprints due to their applicability and reliability. Furthermore, we propose weighted AIB and SIB fingerprints to identify UAVs. Since the high dimensionality of AIB and SIB features, the principal component analysis (PCA) algorithm is applied to reduce the dimensionality of these two features. Then the neighborhood component analysis (NCA) algorithm is utilized to weight the dimensions of the two features, AIB and SIB. The extracted UAV fingerprints are stored as training data and test data, respectively. Finally, machine learning algorithms are utilized to identify UAVs. The identification results are as follows: In the indoor scenario, the average identification accuracy of three features (FD, AIB, SIB) are 100%, 97.23%, and 96.11%, respectively. In outdoor scenario, the identification accuracy of three features are 100%, 95.00%, and 93.50%, respectively.},
keywords={Feature extraction;Unmanned aerial vehicles;Radio frequency;Wavelet transforms;Wireless fidelity;Sensors;Machine learning algorithms;Unmanned aerial vehicles (UAVs);RF fingerprint;UAV detection and identification;fractal dimension (FD);bispectrum},
doi={10.1109/JSEN.2021.3068444},
ISSN={1558-1748},
month={June},}
@ARTICLE{8908690,
author={Wan, Shuo and Lu, Jiaxun and Fan, Pingyi and Letaief, Khaled B.},
journal={IEEE Internet of Things Journal}, title={Toward Big Data Processing in IoT: Path Planning and Resource Management of UAV Base Stations in Mobile-Edge Computing System},
year={2020},
volume={7},
number={7},
pages={5995-6009},
abstract={Heavy data load and wide cover range have always been crucial problems for big data processing in Internet of Things (IoT). Recently, mobile-edge computing (MEC) and unmanned aerial vehicle base stations (UAV-BSs) have emerged as promising techniques in IoT. In this article, we propose a three-layer online data processing network based on the MEC technique. On the bottom layer, raw data are generated by distributed sensors with local information. Upon them, UAV-BSs are deployed as moving MEC servers, which collect data and conduct initial steps of data processing. On top of them, a center cloud receives processed results and conducts further evaluation. For online processing requirements, the edge nodes should stabilize delay to ensure data freshness. Furthermore, limited onboard energy poses constraints to edge processing capability. In this article, we propose an online edge processing scheduling algorithm based on Lyapunov optimization. In cases of low data rate, it tends to reduce edge processor frequency for saving energy. In the presence of a high data rate, it will smartly allocate bandwidth for edge data offloading. Meanwhile, hovering UAV-BSs bring a large and flexible service coverage, which results in a path planning issue. In this article, we also consider this problem and apply deep reinforcement learning to develop an online path planning algorithm. Taking observations of around environment as an input, a CNN network is trained to predict action rewards. By simulations, we validate its effectiveness in enhancing service coverage. The result will contribute to big data processing in future IoT.},
keywords={Cloud computing;Internet of Things;Base stations;Distributed databases;Sensors;Big Data;Big data;deep reinforcement learning;edge computing;Internet of Things (IoT);online data processing},
doi={10.1109/JIOT.2019.2954825},
ISSN={2327-4662},
month={July},}
@INPROCEEDINGS{7745630,
author={Yue Liu and Jun Yong and Liang Liu and Jinlong Zhao and Zongyu Li},
booktitle={2016 4th International Conference on Applied Robotics for the Power Industry (CARPI)}, title={The method of insulator recognition based on deep learning},
year={2016},
volume={},
number={},
pages={1-5},
abstract={The insulator is an import part of transmission line, and the defects detection of insulator rely deeply on the insulators' position. Traditional methods about insulator recognition task are depend on color features and geometric features, those methods would be influenced by lots of factors, such as illumination and background in result getting poor generalization ability. In this paper, we propose a method to recognize insulator based on deep learning algorithm. Firstly, we construct the training dataset which includes insulator, background and tower three categories. Secondly, we initialize the convolution neural networks as a six-level network, and adjust training parameters to train the model. Lastly, the trained model is used to predict the candidate insulator position. With the help of non-maximum suppression algorithm and line fitting method, we can get the exactly location of insulator. The experiment results on UAV dataset show the proposed method can effective localize the insulator and improve generalization ability significantly.},
keywords={Insulators;Training;Feature extraction;Power transmission lines;Convolution;Image color analysis;Fitting;Least squares approximations;Machine learning;Object detection;Transmission lines},
doi={10.1109/CARPI.2016.7745630},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9356016,
author={Sadhu, Vidyasagar and Sun, Chuanneng and Karimian, Arman and Tron, Roberto and Pompili, Dario},
booktitle={2020 IEEE 17th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)}, title={Aerial-DeepSearch: Distributed Multi-Agent Deep Reinforcement Learning for Search Missions},
year={2020},
volume={},
number={},
pages={165-173},
abstract={Search and Rescue (SAR) is an important part of several applications of national and social interest. Existing solutions for search missions in both terrestrial and aerial domains are mostly limited to single agent and specific environments; however, search missions can significantly benefit from the use of multiple agents that can quickly adapt to new environments. In this paper, we propose a framework based on Multi-Agent Deep Reinforcement Learning (MADRL) that realizes the actor-critic framework in a distributed manner for coordinating multiple Unmanned Aerial Vehicles (UAVs) in the exploration of unknown regions. One of the original aspects of our work is that the actors represent simulated or actual UAVs exploring the environment in parallel instead of traditional computer threads. Also, we propose addition of Long Short Term Memory (LSTM) neural network layers to the actor and critic architectures to handle imperfect communication and partial observability scenarios. The proposed approach has been evaluated in a grid world and has been compared against other competing algorithms such as Multi-Agent Q-Learning, Multi-Agent Deep Q-Learning to show its advantages. More generally, our approach could be extended to image-based/continuous action space environments as well.},
keywords={Instruction sets;Neural networks;Reinforcement learning;Unmanned aerial vehicles;Sensor systems;Observability;Long short term memory;Multi-Agent Deep Reinforcement Learning;Search and Rescue;Drones;wireless communication},
doi={10.1109/MASS50613.2020.00030},
ISSN={2155-6814},
month={Dec},}
@INPROCEEDINGS{9045498,
author={Yang, Ming Der and Tseng, Hsin Hung and Hsu, Yu Chun and Tseng, Wei Chen},
booktitle={2020 IEEE 17th Annual Consumer Communications Networking Conference (CCNC)}, title={Real-time Crop Classification Using Edge Computing and Deep Learning},
year={2020},
volume={},
number={},
pages={1-4},
abstract={In recent years, edge computing and deep learning have been successfully performed processing and classification tasks in a variety of fields including agriculture. Therefore, this research aims to use unmanned aerial vehicle (UAV) for agriculture applications with integrating edge computing and deep learning techniques. This research experiment was carried out in the NCHU Experimental Farm. The DJI Matrice 100 drone with ASUS Tinker Board S embedded system, which connects a Logitech C925e webcam to capture images are used in this study. The ASUS Tinker Board S runs a folder monitoring program and sends images over the 4G LTE network to the backend server whenever new images are captured and stored. The backend server runs a pre-trained image semantic segmentation model and provides image inference service. The image inference results with the associated segmented image will be sent to the mobile device of the drone controller, and a dynamic flight control action can be triggered. The image semantic segmentation model adopts SegNet network architecture. For a comparison purpose, another network architecture, FCN-AlexNet, was also trained and validated. The preliminary results show SegNet outperformed FCN-AlexNet in image semantic segmentation tasks in terms of the evaluation between training and validation. The average inference speed of the semantic image segmentation model is 0.7s with segmentation identification accuracy is 89%. The promising results shed light on many agriculture applications, such as crop growth condition assessment, fertilizer management, and yield prediction. Additionally, this research provides possible solutions for the labor shortage issue of agriculture which is a common challenge in an aging community like Taiwan and many countries worldwide.},
keywords={Deep learning;Training;Image segmentation;Embedded systems;Convolution;Semantics;Crops;edge computing;deep learning;agriculture applications},
doi={10.1109/CCNC46108.2020.9045498},
ISSN={2331-9860},
month={Jan},}
@INPROCEEDINGS{8791701,
author={S., Girisha and M.M., Manohara Pai and Verma, Ujjwal and Pai, Radhika M.},
booktitle={2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)}, title={Semantic Segmentation of UAV Aerial Videos using Convolutional Neural Networks},
year={2019},
volume={},
number={},
pages={21-27},
abstract={Semantic segmentation of complex aerial videos enables a better understanding of scene and context. This enhances the performance of automated video processing techniques like anomaly detection, object detection, event detection and other applications. But, there is a limited study of semantic segmentation in aerial videos due to non-availability of the relevant dataset. To address this, an aerial video dataset is captured using DJI Phantom 3 professional drone and is annotated manually. In addition, the proposed research work investigates the performance of semantic segmentation algorithms for aerial videos implemented using Fully Convolution Networks (FCN) and U-net architectures. In this study, two classes (greenery, road) are considered for semantic segmentation. It is observed that both architectures perform competitively on the aerial videos of Unmanned Aerial Vehicle (UAV) with a pixel accuracy of 89.7% and 87.31% respectively.},
keywords={Semantics;Videos;Image segmentation;Roads;Feature extraction;Histograms;Object detection;Semantic Segmentation;Aerial Videos;Convolutional neural Networks;U-Net;FCN},
doi={10.1109/AIKE.2019.00012},
ISSN={},
month={June},}
@INPROCEEDINGS{9554952,
author={Zuo, Yihao and Yang, Junli and Zhu, Zihao and Li, Ruizhe and Zhou, Yuhan and Zheng, Yutong},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Real-Time Semantic Segmentation of Aerial Videos Based on Bilateral Segmentation Network},
year={2021},
volume={},
number={},
pages={2763-2766},
abstract={In recent years, deep learning algorithms have been widely used in semantic segmentation of aerial images. However, most of the current research in this field focus on images but not videos. In this paper, we address the problem of real-time aerial video semantic segmentation with BiSeNet[1]. Since BiSeNet is originally proposed for semantic segmentation of natural city scene images, we need a corresponding dataset to ensure the effect of transfer learning when applying it to aerial video segmentation. Therefore, we build a UAV streetscape sequence dataset (USSD) to fill the vacancy of dataset in this field and facilitate our research. Evaluation on USSD shows that BiSeNet outperforms other state-of-the-art methods. It achieves 79.26% mIoU and 93.37% OA with speed of 148.7 FPS on NVIDIA Tesla V100 for a 1920x1080 frame size input aerial video, which satisfies the demand of aerial video semantic segmentation with a competitive balance of accuracy and speed. The aerial video semantic segmentation results are provided at Our Repository.},
keywords={Deep learning;Image segmentation;Visualization;Semantics;Urban areas;Transfer learning;Geoscience and remote sensing;Real-time Aerial Video Semantic Segmentation;High-resolution Aerial Imagery;Deep Learning},
doi={10.1109/IGARSS47720.2021.9554952},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9323613,
author={Wu, Haolin and Nie, Gaozhong and Fan, Xiwei},
booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, title={Classification of Building Structure Types Using UAV Optical Images},
year={2020},
volume={},
number={},
pages={1193-1196},
abstract={It is well know that for the same intensity areas, the buildings with different structure types can show different vulnerabilities. Thus, building structure type is one the key parameters for rapid estimation of casualties and injuries after earthquake, which is vital for emergency response and rescue. To estimate building structure types, the buildings are firstly extracted based on the spectrum, texture, and height information of UAV visible images. Then, the structure type of individual extracted buildings is classified using convolution neural network. To evaluate the accuracy of the proposed method, the images of Xuyi county, Huai'an City, Jiangsu Province are acquired using a small rotorcraft UAV. The results show that the user accuracy and cartography accuracy are 80.69% and 78.42%, respectively.},
keywords={Buildings;Earthquakes;Convolution;Feature extraction;Remote sensing;Image reconstruction;Training;Building classification;building structure type;UAV;deep learning;convolution neural network},
doi={10.1109/IGARSS39084.2020.9323613},
ISSN={2153-7003},
month={Sep.},}
@INPROCEEDINGS{8479091,
author={Bitye Dimithe, Cedric Olivier and Reid, Christopher and Samata, Biswanath},
booktitle={SoutheastCon 2018}, title={Offboard Machine Learning Through Edge Computing for Robotic Applications},
year={2018},
volume={},
number={},
pages={1-7},
abstract={The paper presents a study on offboard machine learning through edge computing for robotic applications. Edge or `fog' computing is being pursued as a supplement to cloud computing to provide the computing resources near the `edge' where it is needed most. In this paper a framework of such an edge computing system is presented for robotic applications. The system consists of a recent machine learning platform (Jetson TX2) integrated within a heterogeneous robotic environment of UAVs and mobile robots operated through robot operating system (ROS). The UAVs and the mobile robots are equipped with cameras for providing visual feedback of the surrounding to the main processor (Jetson TX2) for image processing and object classification. The UAVs and the robots have their individual local processors capable enough to handle local processing of other sensor data and providing interface for transmitting images to and receiving identification results from the offboard processor. The system has been developed around ROS which provides the communication between hardware and system drivers for UAVs and mobile robots. The effectiveness of the approach is demonstrated using a UAV and a mobile robot to send images to the offboard process to identify a moving person and receive commands to follow him. The mobile robot follows the person and the UAV action is simulated using a simulator with parameters of a physical UAV.},
keywords={Handheld computers;Convolutional neural networks;Edge computing;Machine learning;Operating systems;Publishing;Erbium;convolutional neural network;edge computing;machine learning;offboard processing;robot operating system;You Only Look Once (YOLO)},
doi={10.1109/SECON.2018.8479091},
ISSN={1558-058X},
month={April},}
@INPROCEEDINGS{8519012,
author={Kellenberger, Benjamin and Marcos, Diego and Courty, Nicolas and Tuia, Devis},
booktitle={IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium}, title={Detecting Animals in Repeated UAV Image Acquisitions by Matching CNN Activations with Optimal Transport},
year={2018},
volume={},
number={},
pages={3643-3646},
abstract={Repeated animal censuses are crucial for wildlife parks to ensure ecological equilibriums. They are increasingly conducted using images generated by Unmanned Aerial Vehicles (UAVs), often coupled to semi-automatic object detection methods. Such methods have shown great progress also thanks to the employment of Convolutional Neural Networks (CNNs), but even the best models trained on the data acquired in one year struggle predicting animal abundances in subsequent campaigns due to the inherent shift between the datasets. In this paper we adapt a CNN-based animal detector to a follow-up UAV dataset by employing an unsupervised domain adaptation method based on Optimal Transport. We show how to infer updated labels from the source dataset by means of an ensemble of bootstraps. Our method increases the precision compared to the unmodified CNN, while not requiring additional labels from the target set.},
keywords={Feature extraction;Detectors;Unmanned aerial vehicles;Couplings;Wildlife;Livestock estimation;Unmanned Aerial Vehicle (UAV);Domain Adaptation;Optimal Transport;Convolutional Neural Network (CNN)},
doi={10.1109/IGARSS.2018.8519012},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{8675566,
author={Yang, Bowon and Matson, Eric T. and Smith, Anthony H. and Dietz, J. Eric and Gallagher, John C.},
booktitle={2019 Third IEEE International Conference on Robotic Computing (IRC)}, title={UAV Detection System with Multiple Acoustic Nodes Using Machine Learning Models},
year={2019},
volume={},
number={},
pages={493-498},
abstract={Class 1 unmanned aerial vehicles (UAVs), known as drones, have become popular and accessible, which makes them tools for malicious purposes. As a result, there is an increasing demand for an effective defense system that can detect UAVs. In this paper, a UAV detection system with multiple acoustic nodes using machine learning models is proposed along with an empirically optimized configuration of the nodes for deployment. Features including Mel-frequency cepstral coefficients (MFCC) and short-time Fourier transform (STFT) were used for training. Support vector machines (SVM) and convolutional neural networks (CNN) were trained with the data collected in person. Experiments were done to evaluate models' ability to find the path of the UAV that was flying. Sensing nodes were placed in four different configurations and the best of test set was chosen which maximizes the detection range without blind spots. STFT-SVM model showed the best performance and a semi-circle formation with 75 meters distance between a node and the protected area is found to be the optimized configuration.},
keywords={Unmanned aerial vehicles;Radar tracking;Machine learning;Mel frequency cepstral coefficient;Laser radar;Support vector machines;CUAV;machine learning},
doi={10.1109/IRC.2019.00103},
ISSN={},
month={Feb},}
@ARTICLE{9154460,
author={Bai, Tong and Pan, Cunhua and Wang, Jingjing and Deng, Yansha and Elkashlan, Maged and Nallanathan, Arumugam and Hanzo, Lajos},
journal={IEEE Internet of Things Journal}, title={Dynamic Aerial Base Station Placement for Minimum-Delay Communications},
year={2021},
volume={8},
number={3},
pages={1623-1635},
abstract={Queuing delay is of essential importance in the Internet-of-Things scenarios where the buffer sizes of devices are limited. The existing cross-layer research contributions aiming at minimizing the queuing delay usually rely on either transmit power control or dynamic spectrum allocation. Bearing in mind that the transmission throughput is dependent on the distance between the transmitter and the receiver, in this context we exploit the agility of the unmanned-aerial-vehicle (UAV)-mounted base stations (BSs) for proactively adjusting the aerial BS (ABS)’s placement in accordance with wireless teletraffic dynamics. Specifically, we formulate a minimum-delay ABS placement problem for UAV-enabled networks, subject to realistic constraints on the ABS’s battery life and velocity. Its solutions are technically realized under three different assumptions in regard to the wireless teletraffic dynamics. The backward induction technique is invoked for both the scenario where the full knowledge of the wireless teletraffic dynamics is available, and for the case where only their statistical knowledge is available. In contrast, a reinforcement learning aided approach is invoked for the case when neither the exact number of arriving packets nor that of their statistical knowledge is available. The numerical results demonstrate that our proposed algorithms are capable of improving the system’s performance compared to the benchmark schemes in terms of both the average delay and of the buffer overflow probability.},
keywords={Wireless communication;Delays;Throughput;Vehicle dynamics;Base stations;Heuristic algorithms;Resource management;Delay optimal;dynamic programming;Markov decision process (MDP);reinforcement learning;unmanned aerial vehicle (UAV)},
doi={10.1109/JIOT.2020.3013752},
ISSN={2327-4662},
month={Feb},}
@INPROCEEDINGS{8089913,
author={Bin, Fang and XiaoFeng, Feng and Shuo, Xu},
booktitle={2017 10th International Conference on Intelligent Computation Technology and Automation (ICICTA)}, title={Research on Cooperative Collision Avoidance Problem of Multiple UAV Based on Reinforcement Learning},
year={2017},
volume={},
number={},
pages={103-109},
abstract={To solve the problem of multi-UAV collision avoidance, propose the solution framework of multi-UAV collision avoidance based on the reinforcement learning. Firstly, four elements of state space, action space, the environment model and return value in the multi UAV cooperative collision avoidance problem were analyzed in depth. For the environment model, modeling it from two aspects of the UAV dynamic model and multi UAV relative distance calculation model; for the reward calculation, analyzing it from three aspects of the effect of collision avoidance, pre route deviation and maneuver execution cost. Then, proposing the multi UAV cooperative collision avoidance control algorithm based on the reinforcement learning. The experiment results show that the algorithm can effectively realize multi UAV coordination collision avoidance, control decision time is about 100 milliseconds, and the algorithm has practical feasibility.},
keywords={Collision avoidance;Atmospheric modeling;Analytical models;Security;Aerospace electronics;Predictive models;UAV;Collision Avoidance;Reinforcement Learning},
doi={10.1109/ICICTA.2017.30},
ISSN={},
month={Oct},}
@ARTICLE{9655514,
author={Han, Chen and Liu, Aijun and An, Kang and Wang, Haichao and Zheng, Gan and Chatzinotas, Symeon and Huo, Liangyu and Tong, Xinhai},
journal={IEEE Transactions on Vehicular Technology}, title={Satellite-assisted UAV Trajectory Control in Hostile Jamming Environments},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Satellite and unmanned aerial vehicle (UAV) networks have been introduced as enhanced approach to provide dynamic control, massive connections and global coverage for future wireless communication systems. This paper considers a coordinated satellite-UAV communication system, where the UAV performs the environmental reconnaissance task with the assistance of satellite in a hostile jamming environment. To fulfill this task, the UAV needs to realize autonomous trajectory control and upload the collected data to the satellite. With the aid of the uploading data, the satellite builds the environment situation map integrating the beam quality, jamming status, and traffic distribution. Accordingly, we propose a closed-loop anti-jamming dynamic trajectory optimization approach, which is divided into three stages. Firstly, an intentional trajectory planning is made according to the limited prior information and preset points. Secondly, the flight control between two preset points is formulated as a Markov decision process, and a reinforcement learning (RL) based automatic flying control algorithm is proposed to explore the unknown hostile environment and realize autonomous and precise trajectory control. Thirdly, based on the collected data during the UAV's flight, the satellite utilizes an environment situation estimating algorithm to build an environment situation map, which is used to reselect the preset points for the first stage and provide better initialization for the RL process in the second stage. Simulation results verify the validity and superiority of the proposed approach.},
keywords={Trajectory;Satellites;Jamming;Autonomous aerial vehicles;Task analysis;Reconnaissance;Vehicle dynamics;Jamming;Satellite-UAV coordination communication;Trajectory optimization;Reinforcement learning;Graph theory},
doi={10.1109/TVT.2021.3136187},
ISSN={1939-9359},
month={},}
@ARTICLE{9203900,
author={Xiao, Jinsheng and Zhang, Shuhao and Dai, Yuan and Jiang, Zhijun and Yi, Benshun and Xu, Chuan},
journal={IEEE Journal on Miniaturization for Air and Space Systems}, title={Multiclass Object Detection in UAV Images Based on Rotation Region Network},
year={2020},
volume={1},
number={3},
pages={188-196},
abstract={The object detection in UAV application is a challenging task due to the diversity of target scales, variation of views, and complex backgrounds. To solve several challenges, including dense objects, objects with arbitrary orientation, and diversity of aspect ratios, this article proposes an end-to-end object detection method based on the convolutional neural network. In this article, the feature extraction performance is enhanced by utilizing a deep residual neural network. Multiscale feature maps are obtained through fusion with different convolutional layers, thus combining the high-level semantic information and low-level detail information. A rotation region proposal network is adopted to generate rotated regions, which makes the bounding box sensitive to dense objects in aerial images. Meanwhile, the RoIAlign is used and a convolution layer is appended in the classification stage, and focal loss is used in the classification stage. The proposed method focuses on arbitrary-oriented and dense objects in UAV images. After a comprehensive evaluation with several state-of-the-art object detection algorithms, the proposed method is proved to be effective to detect multiclass artificial objects in aerial images. Extensive experiments are conducted on the DOTA, VEDAI, and the VisDrone UAV image datasets, which demonstrate that the proposed method can obtain discriminative features through the improved multiscale feature extraction and the rotating region network. The results on the above datasets show that our method obtains gains in mean average precision compared with several state-of-the-art methods.},
keywords={Feature extraction;Object detection;Convolutional neural networks;Deep learning;Deep learning;object detection;rotation region proposal network;UAV images},
doi={10.1109/JMASS.2020.3025970},
ISSN={2576-3164},
month={Dec},}
@INPROCEEDINGS{9606384,
author={Bhandarkar, Adhitya Bantwal and Jayaweera, Sudharman K},
booktitle={2021 17th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)}, title={Optimal Trajectory Learning for UAV-Mounted Mobile Base Stations using RL and Greedy Algorithms},
year={2021},
volume={},
number={},
pages={13-18},
abstract={This paper designs Artificial Intelligence (AI) method, to determine an optimal trajectory for an Unmanned Aerial Vehicle (UAV) mounted mobile base station to maximize its coverage of distinct users. Determining such an optimal trajectory for arbitrarily distributed users over an area is, in general, difficult and there is no closed-form solution. Since the users are arbitrarily located the method must adapt accordingly. To accomplish this, the problem is formulated in a way that is compatible with Reinforcement Learning (RL) and two AI approaches are designed to learn an optimal trajectory. The first uses Deep Reinforcement Learning (DRL) implemented with a Deep Q-Network (DQN) while the second is a reward-based greedy algorithm. It is shown that these new algorithms significantly outperform the state-of-the-art previously proposed deep learning based approaches. Moreover, the simple AI-based greedy approach is shown to perform close to the DQN-aided DRL algorithm at a much lower computational complexity at least in the type of scenarios considered in this paper.},
keywords={Greedy algorithms;Wireless communication;Deep learning;Base stations;Reinforcement learning;Unmanned aerial vehicles;Trajectory;Deep Q-Network (DQN);Deep Reinforcement Learning (DRL);optimal trajectory learning;Unmanned Aerial Vehicles (UAVs);wireless user coverage;greedy algorithm},
doi={10.1109/WiMob52687.2021.9606384},
ISSN={2160-4894},
month={Oct},}
@ARTICLE{8674587,
author={Koushik, A.M. and Hu, Fei and Kumar, Sunil},
journal={IEEE Transactions on Cognitive Communications and Networking}, title={Deep ${Q}$ -Learning-Based Node Positioning for Throughput-Optimal Communications in Dynamic UAV Swarm Network},
year={2019},
volume={5},
number={3},
pages={554-566},
abstract={In this paper, we study the communication-oriented unmanned air vehicle (UAV) placement issue in a typical manned-and-unmanned (MUM) airborne network. The MUM network consists of a few powerful aircraft nodes in the higher layer and high-density UAVs in the lower layer. While the aircraft network is relatively stable, the UAVs can form different swarm network topologies. Some UAVs are selected as gateway nodes to aggregate the received UAV data and send to a nearby aircraft which acts as a control node for the UAVs in a swarm. Assume a source UAV has data to be sent to its gateway node by using a route which may have broken links. Our goal is to guide the position of one or more relay UAVs to make up for the broken wireless links under the dynamic swarm topology. The placement of the relay node is determined by both traffic quality-of-service (QoS) requirements and the link conditions. We design a new queueing model, called multi-hop priority queue, to analyze the achievable QoS performance through multi-hop queue-to-queue accumulation modeling. To handle dynamic swarm topology and time-varying link conditions, we design a deep Q-learning (DQN) model to determine the optimal link between two UAV nodes, and then use an optimization algorithm to locally fine-tune the position of the UAV node to optimize the overall network performance. The DQN-based UAV link selection is computed in the powerful aircraft (control node) which maintains the graphs of the swarm topology, where the optimization is implemented at the UAV. Our simulation results validate the throughput efficiency of our DQN-based UAV positioning scheme.},
keywords={Relays;Unmanned aerial vehicles;Logic gates;Quality of service;Optimization;Interference;Topology;UAV swarming;deep Q-learning network (DQN);deep learning;relay placement;multi-hop queueing model;manned-and-unmanned (MUM) network},
doi={10.1109/TCCN.2019.2907520},
ISSN={2332-7731},
month={Sep.},}
@INPROCEEDINGS{9522771,
author={Pirvu, Mihai and Robu, Victor and Licaret, Vlad and Costea, Dragos and Marcu, Alina and Slusanschi, Emil and Sukthankar, Rahul and Leordeanu, Marius},
booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Depth distillation: unsupervised metric depth estimation for UAVs by finding consensus between kinematics, optical flow and deep learning},
year={2021},
volume={},
number={},
pages={3209-3217},
abstract={Estimating precise metric depth is an essential task for UAV navigation, which is very difficult to learn unsupervised without access to odometry. At the same time, depth recovery from kinematics and optical flow is mathematically precise, but less numerically stable and robust, especially in the focus of expansion areas. We propose a model that combines the analytical, vision-with-odometry approach, with deep unsupervised learning, into a single formulation for metric depth estimation, which is both fast and accurate. The two pathways – analytical and data-driven – form a robust ensemble, which provides supervisory signal to a single deep net that distills the consensus between scene geometry, pose, kinematics, camera intrinsics and the input RGB. The distilled net has low runtime and memory costs, being suitable for embedded devices. We validate our results against an off-the-shelf SfM-based solution. We also introduce a new real-world dataset of almost 20 minutes of continuous UAV flight, on which we demonstrate better accuracy and capabilities than the deep learning and analytical approaches.},
keywords={Measurement;Deep learning;Training;Geometry;Pipelines;Estimation;Kinematics},
doi={10.1109/CVPRW53098.2021.00359},
ISSN={2160-7516},
month={June},}
@ARTICLE{9210077,
author={Zhang, Hongming and Hanzo, Lajos},
journal={IEEE Transactions on Vehicular Technology}, title={Federated Learning Assisted Multi-UAV Networks},
year={2020},
volume={69},
number={11},
pages={14104-14109},
abstract={Unmanned aerial vehicles (UAVs) have been recognized as a promising technology to be used in a wide range of civilian, public and military applications. However, given their limited payload and flight time, multiple UAVs may have to be harnessed for accomplishing complex high-level tasks, where a control center can be employed for coordinating their actions. In this article, we consider image classification tasks in UAV-aided exploration scenarios, where the coordination of multiple UAVs is implemented by a ground fusion center (GFC) positioned in a strategic, but inaccessible location, such as a mountain top, where recharging the battery is uneconomical or may even be infeasible. On-board cameras are carried by each UAV and then, federated learning (FL) is invoked for reducing the communication cost between the UAVs and the GFC, and the computational complexity imposed on the GFC. In our proposed FL-aided classification approach, initially local training is performed by each UAV based on the locally collected images to create a local model. Then, each UAV sends its locally acquired model to the GFC via a fading wireless channel, where a global model is generated, which is then fed back to each UAV for the next round of their local training. In order to further minimize the computational complexity imposed on the GFC by the UAVs, weighted zero-forcing (WZF) transmit precoding (TPC) is used at each UAV based on realistic imperfect channel state information (CSI). The system performance attained is evaluated by simulations, showing that the proposed system is capable of attaining a high classification accuracy at relatively low communication cost.},
keywords={Task analysis;Training;Unmanned aerial vehicles;Computational modeling;Cameras;Wireless communication;Fading channels;Federated learning;unmanned aerial vehicle;multi-class classification;convolutional neural network;deep learning;imperfect CSI},
doi={10.1109/TVT.2020.3028011},
ISSN={1939-9359},
month={Nov},}
@INPROCEEDINGS{8421797,
author={Badwan, Mohammad and Tutunji, Tarek A.},
booktitle={2018 19th International Conference on Research and Education in Mechatronics (REM)}, title={System Identification for Bixler3 Unmanned Aerial Vehicle},
year={2018},
volume={},
number={},
pages={93-98},
abstract={Experimental flight data for a fixed-wing Unmanned Arial Vehicle (UAV) are used to identify and build a Multi-Input Multi-Output (MIMO) mathematical model. The model has four inputs (aileron, elevator, rudder, and throttle) and 12-state outputs (angular positions and velocities; linear positions and velocities). The identification model is based on Nonlinear Auto-Regressive Exogenous (NARX) model within a Feed-forward Neural Network (FNN) structure. Bixler3 UAV is used as a case study, where flight data is gathered during all flight stages: takeoff, flying and landing. The data is then processed and used to train the NARX-FNN model. The model is tested with a different set of flight data gathered from another Bixler3, flying at a different route. Simulation results validate the methodology used as the developed model was able to follow the response of the measured 12-state outputs with minimal error.},
keywords={Mathematical model;Atmospheric modeling;Aircraft;Data models;Unmanned aerial vehicles;Aerodynamics;Training;System Identification;Artificial Neural Networks;Auto-Regressive Models;Unmanned Aerial Vehicles},
doi={10.1109/REM.2018.8421797},
ISSN={},
month={June},}
@ARTICLE{9560131,
author={Ayyad, Abdulla and Chehadeh, Mohamad and Silva, Pedro Henrique and Wahbah, Mohamad and Hay, Oussama Abdul and Boiko, Igor and Zweiri, Yahya},
journal={IEEE Transactions on Control Systems Technology}, title={Multirotors From Takeoff to Real-Time Full Identification Using the Modified Relay Feedback Test and Deep Neural Networks},
year={2021},
volume={},
number={},
pages={1-17},
abstract={Low-cost real-time identification of multirotor unmanned aerial vehicle (UAV) dynamics is an active area of research supported by the surge in demand and emerging application domains. Such real-time identification capabilities shorten development time and cost, making UAVs' technology more accessible, and enable a wide variety of advanced applications. In this article, we present a novel comprehensive approach, called DNN-MRFT, for real-time identification and tuning of multirotor UAVs using the modified relay feedback test (MRFT) and deep neural networks (DNNs). The main contribution is the development of a generalized framework for the application of DNN-MRFT to higher order systems. One of the notable advantages of DNN-MRFT is the exact estimation of identified process gain, which mitigates the inaccuracies introduced due to the use of the describing function method in approximating the response of Lure's systems. A secondary contribution is a generalized controller based on DNN-MRFT that takes off a UAV with unknown dynamics and identifies the inner loops dynamics in-flight. Using the developed framework, DNN-MRFT is sequentially applied to the outer translational loops of the UAV utilizing in-flight results obtained for the inner attitude loops. DNN-MRFT takes on average 15 s to get the full knowledge of multirotor UAV dynamics, and without any further tuning or calibration, the UAV would be able to pass through a vertical window and accurately follow trajectories achieving state-of-the-art performance. Such demonstrated accuracy, speed, and robustness of identification pushes the limits of state of the art in real-time identification of UAVs.},
keywords={Unmanned aerial vehicles;Tuning;Adaptation models;Real-time systems;Relays;Vehicle dynamics;Deep learning;Learning systems;multirotor;process control;sliding mode control;system identification;unmanned aerial vehicles (UAVs).},
doi={10.1109/TCST.2021.3114265},
ISSN={1558-0865},
month={},}
@INPROCEEDINGS{8308815,
author={Sineglazov, V.M. and Chumachenko, O.I. and Gorbatiuk, V.S.},
booktitle={2017 IEEE 4th International Conference Actual Problems of Unmanned Aerial Vehicles Developments (APUAVD)}, title={A new approach in cluster analysis},
year={2017},
volume={},
number={},
pages={223-226},
abstract={A new clustering approach that is capable of finding clusters that are separated by some complex hypersurface is proposed. The approach can be useful for performing analysis of big amounts of unlabeled images that can be nowadays easily gathered, in particular by using unmanned aerial vehicle with mounted cameras. The approach is based on “softening” the initial clustering criterion and then using nonlinear optimization to find the optimal hypersurface that separates clusters.},
keywords={Clustering algorithms;Neurons;Approximation algorithms;Optimization;Self-organizing feature maps;Unmanned aerial vehicles;Conferences;unmanned aerial vehicle;soft clustering;nonlinear optimization;artificial neural networks},
doi={10.1109/APUAVD.2017.8308815},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8453449,
author={Polvara, Riccardo and Patacchiola, Massimiliano and Sharma, Sanjay and Wan, Jian and Manning, Andrew and Sutton, Robert and Cangelosi, Angelo},
booktitle={2018 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Toward End-to-End Control for UAV Autonomous Landing via Deep Reinforcement Learning},
year={2018},
volume={},
number={},
pages={115-123},
abstract={The autonomous landing of an unmanned aerial vehicle (UAV) is still an open problem. Previous work focused on the use of hand-crafted geometric features and sensor-data fusion for identifying a fiducial marker and guide the UAV toward it. In this article we propose a method based on deep reinforcement learning that only requires low-resolution images coming from a down looking camera in order to drive the vehicle. The proposed approach is based on a hierarchy of Deep Q-Networks (DQNs) that are used as high-end control policy for the navigation in different phases. We implemented various technical solutions, such as the combination of vanilla and double DQNs trained using a form of prioritized buffer replay that separates experiences in multiple containers. The optimal control policy is learned without any human supervision, providing the agent with a sparse reward feedback indicating the success or failure of the landing. The results show that the quadrotor can autonomously land on a large variety of simulated environments and with relevant noise, proving that the underline DQNs are able to generalise effectively on unseen scenarios. Furthermore, it was proved that in some conditions the network outperformed human pilots.},
keywords={Cameras;Sensors;Drones;Kernel;Task analysis;Global Positioning System},
doi={10.1109/ICUAS.2018.8453449},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{9196947,
author={Walter, Viktor and Vrba, Matouš and Saska, Martin},
booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)}, title={On training datasets for machine learning-based visual relative localization of micro-scale UAVs},
year={2020},
volume={},
number={},
pages={10674-10680},
abstract={By leveraging our relative Micro-scale Unmanned Aerial Vehicle localization sensor UVDAR, we generated an automatically annotated dataset MIDGARD, which the community is invited to use for training and testing their machine learning systems for the detection and localization of Microscale Unmanned Aerial Vehicles (MAVs) by other MAVs. Furthermore, we provide our system as a mechanism for rapidly generating custom annotated datasets specifically tailored for the needs of a given application. The recent literature is rich in applications of machine learning methods in automation and robotics. One particular subset of these methods is visual object detection and localization, using means such as Convolutional Neural Networks, which nowadays enable objects to be detected and classified with previously inconceivable precision and reliability. Most of these applications, however, rely on a carefully crafted training dataset of annotated camera footage. These must contain the objects of interest in environments similar to those where the detector is expected to operate. Notably, the positions of the objects must be provided in annotations. For non-laboratory settings, the construction of such datasets requires many man-hours of manual annotation, which is especially the case for use onboard Micro-scale Unmanned Aerial Vehicles. In this paper, we are providing for the community a practical alternative to that kind of approach.},
keywords={Cameras;Training;Observers;Visualization;Image color analysis;Global navigation satellite system;Position measurement},
doi={10.1109/ICRA40945.2020.9196947},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{8664767,
author={Zheng, Yutong and Xie, Hongwei},
booktitle={2018 International Conference on Sensing,Diagnostics, Prognostics, and Control (SDPC)}, title={Review on Neural Network Identification for Maneuvering UAVs},
year={2018},
volume={},
number={},
pages={339-346},
abstract={Unmanned Aerial Vehicles (UAV) need high mobility in performing military tasks. In this paper, we summarized the UAVs identification methods based on neural network, which takes the characteristics of strong nonlinearity and coupling into consideration. These methods provide some feasible approaches for identifying small maneuvering UAVs. Maneuvering UAV systems are required to be identified more quickly and accurately. In recent years, improvements in many aspects bring new development opportunities to identify maneuvering UAV systems, such as the increase of sampling rate of sensors, the development of computational fluid dynamics (CFD) and embedded technology, the widespread use of deep learning in control area and the rise of neural network chips. We are expected to get more precise maneuvering UAV models based on neural network identification methods with the help of more preeminent software and more advanced hardware.},
keywords={Neural networks;Atmospheric modeling;Aerodynamics;Aircraft;Computational modeling;Mathematical model;Wind tunnels;neural network identification;UAV;maneuvering flight;system identification},
doi={10.1109/SDPC.2018.8664767},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9621115,
author={Masood, Arooj and Nguyen, The-Vi and Truong, Thanh Phung and Cho, Sungrae},
booktitle={2021 International Conference on Information and Communication Technology Convergence (ICTC)}, title={Content Caching in HAP-Assisted Multi-UAV Networks Using Hierarchical Federated Learning},
year={2021},
volume={},
number={},
pages={1160-1162},
abstract={High and low altitude platforms are expected to become an important component in current access infrastructure design to improve the radio access capability and support on-demand edge services. Caching popular contents at edge such as unmanned aerial vehicles (UAVs), can meet the requirements of mobile users that have the same content requirements, without duplicate transmissions through the backhaul links. Therefore, content access delay can be significantly reduced. In this paper, we propose an intelligent and collaborative popularity prediction method for content caching in high altitude platform (HAP)-assisted multi-UAV networks supported with a hierarchical federated learning algorithm. In this way, the proposed method also preserves the privacy of the contents of mobile users. Simulation results show that the proposed method achieves good prediction accuracy by reducing the prediction error significantly.},
keywords={Deep learning;Privacy;Simulation;Predictive models;Collaborative work;Prediction algorithms;Delays;Content caching;Multi-UAVs networks;Federated learning;Deep learning},
doi={10.1109/ICTC52510.2021.9621115},
ISSN={2162-1233},
month={Oct},}
@INPROCEEDINGS{9217127,
author={Scazzoli, Davide and Magarini, Maurizio and Reggiani, Luca and Moullec, Yannick Le and Mahtab Alam, Muhammad},
booktitle={2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications}, title={A Deep Learning Approach for LoS/NLoS Identification via PRACH in UAV-assisted Public Safety Networks},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The high mobility of Unmanned Aerial Vehicles (UAVs) and their capability to rapidly deploy Aerial Base Stations (ABS) in areas where the terrestrial network becomes unavailable is a key enabler for Public Safety Networks. In our work we introduce a model in order to identify Line of Sight (LoS) and Non-Line of Sight (NLoS) conditions for User Equipments (UEs) that attempt a connection to an ABS through the Physical Random Access Channel (PRACH) based on Convolutional Neural Networks (CNNs). Our method limits the number of antennas employed with respect to other methods that were developed for traditional approaches, while achieving higher than 80% accuracy for SNR of -20 dB. Finally, we study the impact of UAV's height on the accuracy of our method and we compare it with typical computationally efficient methods based on the delay spread with and without the aid of beamforming.},
keywords={Signal to noise ratio;Delays;Estimation;Channel estimation;Indexes;Support vector machines;Channel models;Public Safety Network (PSN);Localization;Convolutional Neural Networks (CNNa);Non Line of Sight (NLoS)},
doi={10.1109/PIMRC48278.2020.9217127},
ISSN={2166-9589},
month={Aug},}
@ARTICLE{9254093,
author={Peng, Haixia and Shen, Xuemin},
journal={IEEE Journal on Selected Areas in Communications}, title={Multi-Agent Reinforcement Learning Based Resource Management in MEC- and UAV-Assisted Vehicular Networks},
year={2021},
volume={39},
number={1},
pages={131-141},
abstract={In this paper, we investigate multi-dimensional resource management for unmanned aerial vehicles (UAVs) assisted vehicular networks. To efficiently provide on-demand resource access, the macro eNodeB and UAV, both mounted with multi-access edge computing (MEC) servers, cooperatively make association decisions and allocate proper amounts of resources to vehicles. Since there is no central controller, we formulate the resource allocation at the MEC servers as a distributive optimization problem to maximize the number of offloaded tasks while satisfying their heterogeneous quality-of-service (QoS) requirements, and then solve it with a multi-agent deep deterministic policy gradient (MADDPG)-based method. Through centrally training the MADDPG model offline, the MEC servers, acting as learning agents, then can rapidly make vehicle association and resource allocation decisions during the online execution stage. From our simulation results, the MADDPG-based method can converge within 200 training episodes, comparable to the single-agent DDPG (SADDPG)-based one. Moreover, the proposed MADDPG-based resource management scheme can achieve higher delay/QoS satisfaction ratios than the SADDPG-based and random schemes.},
keywords={Servers;Task analysis;Resource management;Delays;Unmanned aerial vehicles;Quality of service;Wireless communication;Vehicular networks;multi-access edge computing;unmanned aerial vehicle;multi-dimensional resource management;multi-agent DDPG},
doi={10.1109/JSAC.2020.3036962},
ISSN={1558-0008},
month={Jan},}
@INPROCEEDINGS{9413316,
author={G¨ozen, Derya and Ozer, Sedat},
booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, title={Visual Object Tracking in Drone Images with Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={10082-10089},
abstract={There is an increasing demand on utilizing camera equipped drones and their applications in many domains varying from agriculture to entertainment and from sports events to surveillance. In such drone applications, an essential and a common task is tracking an object of interest visually. Drone (or UAV) images have different properties when compared to the ground taken (natural) images and those differences introduce additional complexities to the existing object trackers to be directly applied on drone applications. Some important differences among those complexities include (i) smaller object sizes to be tracked and (ii) different orientations and viewing angles yielding different texture and features to be observed. Therefore, new algorithms trained on drone images are needed for the drone-based applications. In this paper, we introduce a deep reinforcement learning (RL) based single object tracker that tracks an object of interest in drone images by estimating a series of actions to find the location of the object in the next frame. This is the first work introducing a single object tracker using a deep RL-based technique for drone images. Our proposed solution introduces a novel reward function that aims to reduce the total number of actions taken to estimate the object's location in the next frame and also introduces a different backbone network to be used on low resolution images. Additionally, we introduce a set of new actions into the action library to better deal with the above-mentioned complexities. We compare our proposed solutions to a state of the art tracking algorithm from the recent literature and demonstrate up to 3.87 % improvement in precision and 3.6% improvement in IoU values on the VisDrone2019 data set. We also provide additional results on OTB-100 data set and show up to 3.15% improvement in precision on the OTB-100 data set when compared to the same previous state of the art algorithm. Lastly, we analyze the ability to handle some of the challenges faced during tracking, including but not limited to occlusion, deformation, and scale variation for our proposed solutions.},
keywords={Visualization;Target tracking;Reinforcement learning;Cameras;Video surveillance;Complexity theory;Object tracking;Object Tracking;Visual Object Tracking;Deep Reinforcement Learning;Aerial Images;UAV videos},
doi={10.1109/ICPR48806.2021.9413316},
ISSN={1051-4651},
month={Jan},}
@INPROCEEDINGS{8997565,
author={Luo, Kai and Zhu, Guibin and Liu, Xuanni and Liu, Hao and Zhang, He},
booktitle={2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)}, title={Uav in fog identification based on simplified model},
year={2019},
volume={1},
number={},
pages={444-450},
abstract={The identification of low-altitude and low-speed the unmanned aerial vehicle (Uav) is a popular problem in the field of computer vision. The traditional identification method can solve most problems, but there are blind spots for low-altitude Uav. By contrast, the deep learning can better solve this problem, but the effect of CNN and other methods is poor in the case of fog. In order to solve this problem, we will apply CNN to dehaze the image. At the same time, for the sake of our subsequent recognition model is more accurate, more real-time, we put forward on the basis of the residual model, using the different sizes of convolution kernels, combining the Inception block and MobileNet[1] network. Our proposed model maintain the better identify accurate rate, increasing our recognition speed. Therefore, this paper aims to train multi-scale convolution model, which can effectively identify low-altitude and slow-speed Uav in fog. Experimental results show that this method is feasible.},
keywords={Convolution;Training;Kernel;Object recognition;Target tracking;Covariance matrices;Computational modeling;Uav identification;Image dehazing},
doi={10.1109/IAEAC47372.2019.8997565},
ISSN={2381-0947},
month={Dec},}
@ARTICLE{9446301,
author={Zhou, Longyu and Leng, Supeng and Liu, Qiang and Wang, Qing},
journal={IEEE Internet of Things Journal}, title={Intelligent UAV Swarm Cooperation for Multiple Targets Tracking},
year={2022},
volume={9},
number={1},
pages={743-754},
abstract={With the advantages of easy deployment and flexible usage, unmanned aerial vehicle (UAV) has advanced the multitarget tracking (MTT) applications. The UAV-MTT system has great potentials to execute dull, dangerous, and critical missions for frontier defense and security. A key challenge in UAV-MTT is how to coordinate multiple UAVs to track diverse invading targets accurately and consecutively. In this article, we propose a UAV swarm-based cooperative tracking architecture to systematically improve the UAV tracking performance. We design an intelligent UAV swarm-based cooperative algorithm for consecutive target tracking and physical collision avoidance. Moreover, we design an efficient cooperative algorithm to predict the trajectory of invading targets accurately. Our simulation results demonstrate that the swarm behaviors stay stable in realistic scenarios with perturbing obstacles. Compared with state-of-the-art solutions, such as the matched deep $Q$ -network, our algorithms can increase tracking accuracy by 60%, reduce tracking delay by 23%, and achieve physical collision-avoidance during the tracking process.},
keywords={Target tracking;Sensors;Task analysis;Trajectory;Unmanned aerial vehicles;Computational modeling;Prediction algorithms;Mobile target tracking;prediction;scheduling;unmanned-aerial-vehicle (UAV) swarm intelligence (SI)},
doi={10.1109/JIOT.2021.3085673},
ISSN={2327-4662},
month={Jan},}
@INPROCEEDINGS{9148776,
author={Zeng, Tengchan and Semiari, Omid and Mozaffari, Mohammad and Chen, Mingzhe and Saad, Walid and Bennis, Mehdi},
booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)}, title={Federated Learning in the Sky: Joint Power Allocation and Scheduling with UAV Swarms},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicle (UAV) swarms must exploit machine learning (ML) in order to execute various tasks ranging from coordinated trajectory planning to cooperative target recognition. However, due to the lack of continuous connections between the UAV swarm and ground base stations (BSs), using centralized ML will be challenging, particularly when dealing with a large volume of data. In this paper, a novel framework is proposed to implement distributed federated learning (FL) algorithms within a UAV swarm that consists of a leading UAV and several following UAVs. Each following UAV trains a local FL model based on its collected data and then sends this trained local model to the leading UAV who will aggregate the received models, generate a global FL model, and transmit it to followers over the intra-swarm network. To identify how wireless factors, like fading, transmission delay, and UAV antenna angle deviations resulting from wind and mechanical vibrations, impact the performance of FL, a rigorous convergence analysis for FL is performed. Then, a joint power allocation and scheduling design is proposed to optimize the convergence rate of FL while taking into account the energy consumption during convergence and the delay requirement imposed by the swarm's control system. Simulation results validate the effectiveness of the FL convergence analysis and show that the joint design strategy can reduce the number of communication rounds needed for convergence by as much as 35% compared with the baseline design.},
keywords={Convergence;Data models;Unmanned aerial vehicles;Uplink;Wireless communication;Task analysis;Delays},
doi={10.1109/ICC40277.2020.9148776},
ISSN={1938-1883},
month={June},}
@INPROCEEDINGS{9014055,
author={Cao, Yang and Zhang, Lin and Liang, Ying-Chang},
booktitle={2019 IEEE Global Communications Conference (GLOBECOM)}, title={Deep Reinforcement Learning for Channel and Power Allocation in UAV-enabled IoT Systems},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicles (UAVs) have recently been proposed as moving base stations to collect data from ground IoT nodes in remote areas. Since IoT nodes are normally battery-limited, energy efficiency is an important metric in IoT systems. In order to improve energy efficiency in UAV-enabled IoT systems, it is necessary to allocate both channels and transmit power properly for IoT nodes. Motivated by the superior performance of deep reinforcement learning (DRL) in decision-making tasks, we propose a DRL-based channel and power allocation framework in a UAV-enabled IoT system. With the proposed framework, the UAV-BS is able to intelligently allocate both channels and transmit power for uplink transmissions of IoT nodes to maximize the minimum energy-efficiency among all the IoT nodes. Simulation results validate the effectiveness of the proposed algorithm and show its superiority over the- state-of-the-arts.},
keywords={Resource management;Uplink;Machine learning;Unmanned aerial vehicles;Optimization;Measurement;Data models},
doi={10.1109/GLOBECOM38437.2019.9014055},
ISSN={2576-6813},
month={Dec},}
@INPROCEEDINGS{9160198,
author={Saetchnikov, Ivan and Skakun, Victor and Tcherniavskaia, Elina},
booktitle={2020 IEEE 7th International Workshop on Metrology for AeroSpace (MetroAeroSpace)}, title={Pattern recognition on aerospace images using deep neural networks},
year={2020},
volume={},
number={},
pages={336-340},
abstract={Pattern recognition is one of the most important tasks in aerospace image processing. Various methods based on convolutional neural networks attain state-of-the-art accuracy; however, their effectiveness on exact images is influenced by the chosen architecture and its training parameters.This work present methods based on convolutional neural networks for pattern recognition on the aerospace images. A possibility for objects segmentation into ten classes is demonstrated on example of the multispectral images from the World View 3 satellite. Four networks with different architectures were built, trained and optimized parametrically based on the auto-encoder neural networks. Segmentation results has been analyzed by means of three parameters: training Jacard Index, testing Jacard Index and weight numbers. The positive impact of the properly selected shearing augmentation on extension of a small marked dataset is discussed. The influence of the nonequilibrium classes on the segmentation accuracy and how to account this feature during training of deep neural networks is pointing out.},
keywords={Convolution;Image segmentation;Neural networks;Task analysis;Training;Indexes;Satellites;convolutional neural network;deep learning;unmanned aerial vehicle;pattern recognition;segmentation;autoencoder;aerospace image},
doi={10.1109/MetroAeroSpace48742.2020.9160198},
ISSN={2575-7490},
month={June},}
@ARTICLE{8789448,
author={Zhang, Guanyu and Li, Yuan and Xu, Xinhai and Dai, Huadong},
journal={IEEE Access}, title={Efficient Training Techniques for Multi-Agent Reinforcement Learning in Combat Tasks},
year={2019},
volume={7},
number={},
pages={109301-109310},
abstract={Multi-agent combat scenarios often appear in many real-time strategy games. Efficient learning for such scenarios is an indispensable step towards general artificial intelligence. Multi-agent reinforcement learning (MARL) algorithms have attracted much interests, but few of them have been shown effective for such scenarios. Most of previous research is focused on revising the learning mechanism of MARL algorithms, for example, trying different types of neural networks. The study of training techniques for improving the performance of MARL algorithms has not been paid much attention. In this paper we propose three efficient training techniques for a multi-agent combat problem which is originated from an unmanned aerial vehicle (UAV) combat scenario. The first one is the scenario-transfer training, which utilizes the experience obtained in simpler combat tasks to assist the training for complex tasks. The next one is the self-play training, which can continuously improve the performance by iteratively training agents and their counterparts. Finally, we consider using combat rules to assist the training, which is named as the rule-coupled training. We combine the three training techniques with two popular multi-agent reinforcement learning methods, multi-agent deep q-learning and multi-agent deep deterministic policy gradient (proposed by Open AI in 2017), respectively. The results show that both the converging speed and the performance of the two methods are significantly improved through the three training techniques.},
keywords={Training;Task analysis;Reinforcement learning;Games;Green products;Neural networks;Acceleration;Scenario-transfer training;self-play training;rule-coupled training},
doi={10.1109/ACCESS.2019.2933454},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9605371,
author={Charles, Camargo P. and Kim, Pedro Henrique Corrêa and de Almeida, Aline Gabriel and Do Nascimentok, Eduardo Vieira and Da Rocha, Lidia Gianne Souza and Vivaldini, Kelen Cristiane Teixeira},
booktitle={2021 Latin American Robotics Symposium (LARS), 2021 Brazilian Symposium on Robotics (SBR), and 2021 Workshop on Robotics in Education (WRE)}, title={Detection of invasive vegetation through UAV and Deep Learning},
year={2021},
volume={},
number={},
pages={114-119},
abstract={Species originating from one biome are often irregularly introduced into other biomes by accident. This event configures a biological invasion, which can cause irreversible adverse impacts on biodiversity and affect economic productivity in sectors such as fisheries, forestry, and agriculture. Furthermore, many species are vectors of human diseases, making biological invasions a significant problem. In Brazil, monitoring becomes very complex, with many closed forests, such as the mountain regions and other places with difficult accessibility, and demands many resources to maintain it, whether human or financial. Remotely and autonomously detecting invasive vegetation in large or complicated physical access areas can positively impact conservation work. Governments can take concrete actions to favor the environment through this monitoring and avoid irreversible damage to the ecosystem. Therefore, this paper proposes the classification of images using Deep Learning algorithms to detect the invasive species Hedychium Coronarium. We will capture the photos by remote sensing through UAVs (Unmanned Aerial Vehicles).},
keywords={Deep learning;Productivity;Neural networks;Government;Vegetation mapping;Forestry;Unmanned aerial vehicles;Unmanned Aerial Vehicles;Deep Learning;Artificial Neural Networks (ANNs);U-Net},
doi={10.1109/LARS/SBR/WRE54079.2021.9605371},
ISSN={2643-685X},
month={Oct},}
@INPROCEEDINGS{8396807,
author={Khan, Arbaaz and Hebert, Martial},
booktitle={2018 IEEE Aerospace Conference}, title={Learning safe recovery trajectories with deep neural networks for unmanned aerial vehicles},
year={2018},
volume={},
number={},
pages={1-9},
abstract={Unmanned vehicles that use vision sensors for perception to aid autonomous flight are a highly popular area of research. However, these systems are often prone to failures that are often hard to model. Previous work has focused on using deep learning to detect these failures. In this work, we build on these failure detection systems and develop a pipeline that learns to identify the correct trajectory to execute that restores the vision system and the unmanned vehicle to a safe state. The key challenge with using a deep learning pipeline for this problem is the limited amount of training data available from a real world system. Ideally one requires millions of data points to sufficiently train a model from scratch. However, this is not feasible for an unmanned aerial vehicle. The dataset we operate with is limited to 400-500 points. To sufficiently learn from such a small dataset we leverage the idea of transfer learning and non linear dimensionality reduction. We deploy our pipeline on an unmanned aerial vehicle flying autonomously through outdoor clutter (in a GPS denied environment) and show that we are able to achieve long durations of safe autonomous flight.},
keywords={Neurons;Biological neural networks;Trajectory;Safety;Machine learning;Cameras;Unmanned aerial vehicles},
doi={10.1109/AERO.2018.8396807},
ISSN={},
month={March},}
@ARTICLE{8641422,
author={Challita, Ursula and Ferdowsi, Aidin and Chen, Mingzhe and Saad, Walid},
journal={IEEE Wireless Communications}, title={Machine Learning for Wireless Connectivity and Security of Cellular-Connected UAVs},
year={2019},
volume={26},
number={1},
pages={28-35},
abstract={Cellular-connected UAVs will inevitably be integrated into future cellular networks as new aerial mobile users. Providing cellular connectivity to UAVs will enable a myriad of applications ranging from online video streaming to medical delivery. However, to enable reliable wireless connectivity for the UAVs as well as secure operation, various challenges need to be addressed such as interference management, mobility management and handover, cyber-physical attacks, and authentication. In this article, the goal is to expose the wireless and security challenges that arise in the context of UAV-based delivery systems, UAV-based real-time multimedia streaming, and UAV-enabled intelligent transportation systems. To address such challenges, ANN-based solution schemes are introduced. The introduced approaches enable UAVs to adaptively exploit wireless system resources while guaranteeing secure operation in real time. Preliminary simulation results show the benefits of the introduced solutions for each of the aforementioned cellular-connected UAV application use cases.},
keywords={Wireless communication;Communication system security;Security;Real-time systems;Machine learning;Streaming media},
doi={10.1109/MWC.2018.1800155},
ISSN={1558-0687},
month={February},}
@INPROCEEDINGS{9317405,
author={Li, Siqi and Liu, Biyuan and Chen, Huaixin and Huang, Zhou},
booktitle={2020 17th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)}, title={A Domain Adaptation Method for Object Detection in UAV Based on Semi-Supervised Learning},
year={2020},
volume={},
number={},
pages={138-141},
abstract={In recent years, the objects detection algorithm of deep learning neural network has been widely used in scene monitoring fields such as intelligent transportation and ground observation. But scene changes always happen caused by the seasons and the ground feature cover change, which makes the training sample (source domain) different from the application scene (target domain), and causes the original effective model to generate a lot of false alarms. This paper proposes a domain adaptation algorithm for Unmanned Aerial Vehicle (UAV) objects detection based on semi-supervised learning. Firstly applying the source domain model on target domain to generate pseudo-labels for semi-supervised learning, during fine-tuning the model with Pseudo-Label, the scale-aware loss is introduced to suppress false alarms in abnormal scale, which realize the domain adaptability of network model migration from source domain to target domain. Experiments on our dataset for monitoring ground objects show that: the proposed method avoids the catastrophic forgetting caused by the direct domain adaptation method without denoising, and maintains the target detection rate of the network model in different scenarios.},
keywords={Adaptation models;Object detection;Entropy;Training;Semisupervised learning;Computer vision;Data models;Objects detection in UAV;Scene change;Semi-supervised learning;Scale-aware loss;Domain adaptation},
doi={10.1109/ICCWAMTIP51612.2020.9317405},
ISSN={2576-8964},
month={Dec},}
@INPROCEEDINGS{9312252,
author={Fang, Wang and Yue, Liu and Dandan, Cui},
booktitle={2020 International Conference on Internet of Things and Intelligent Applications (ITIA)}, title={Classification system study of soybean leaf disease based on deep learning},
year={2020},
volume={},
number={},
pages={1-5},
abstract={Accurate and automatic identification of leaf diseases can help farmers to formulate early response actions to reduce economic losses. A deep learning-based classification system against soybean leaf disease was proposed in this paper. The dataset was derived from multi-blade real crop images taken directly by small UAVs at different time periods and under different illumination conditions. First, for the collected leaf images, SLIC method was used to segment the image of plant leaves by classification system. Then, fine-tuning and transfer learning strategies was adopted to expand training of deep neural networks, as well as data enlargement and Dropout techniques were used to avoid over-fitting. Finally, test results of real data sets are presented quantitatively and qualitatively by means of visualization. The results showed that the classification accuracy can be as high as 99.04% when using Inception-v3 combined with 75% fine-tune parameter strategy.},
keywords={Diseases;Image segmentation;Visualization;Training;Agriculture;Deep learning;Computational modeling;intelligent agriculture;deep learning;soybean leaf disease;fine-tune;dropout},
doi={10.1109/ITIA50152.2020.9312252},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8587021,
author={Vlahović, Nataša and Ilić, Nemanja and Stanković, Miloš},
booktitle={2018 14th Symposium on Neural Networks and Applications (NEUREL)}, title={Deep Learning in Video Stabilization Homography Estimation},
year={2018},
volume={},
number={},
pages={1-5},
abstract={The main goal of digital video stabilization algorithms is to remove unwanted motion from a video sequence. The undesired motion is typically present in videos recorded by hand-held cameras, by cameras mounted on some moving platform (vehicle, boat, Unmanned Aerial Vehicle), or by stationary cameras under severe wind conditions. In this paper, the motion estimation step in video stabilization is performed in a novel way using deep learning homography matrix estimation. Convolutional Neural Network (CNN) takes two grayscale images as inputs, and produces a six degree of freedom affine transformation matrix that maps the pixels from the first image to the second one. After obtaining the homography transformation using a trained CNN, Kalman filter is used to separate the intentional from unintentional motion and calculate the final motion compensation transformation, stabilizing the video sequence.},
keywords={Training;Cameras;Estimation;Kalman filters;Motion estimation;Streaming media;Deep learning;Affine transformation;Video stabilization;Neural networks;Kalman filter;Homography estimation},
doi={10.1109/NEUREL.2018.8587021},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9043101,
author={Ehara, Kakeru and Aljehani, Maher and Yokemura, Taketoshi and Inoue, Masahiro},
booktitle={2020 IEEE International Conference on Consumer Electronics (ICCE)}, title={Individual Status Recognition System Assisted by UAV in Post-Disaster},
year={2020},
volume={},
number={},
pages={1-3},
abstract={When natural disasters occur, there is a possibility of having many injured people in the disaster area. In the meanwhile, rescue teams have to aid these injured individuals as fast as possible. In this study, we proposed a recognition system of individual status to help rescue teams. Employing Unmanned Aerial Vehicles (UAVs) system after disaster occurrence gives many advantages. For instance, a UAV can cover a wide area and provide aerial photographs in a short period. This study aims to classify whether an individual status is standing, sitting, or lying on the ground by using supervised machine learning. Experiments revealed that the system is able to recognize all three types of individual status with an accuracy of 95.6%. Moreover, the authors confirmed the usefulness of using a UAV to recognize individuals in the post-disaster scenario.},
keywords={Deep learning;Image recognition;Conferences;Autonomous aerial vehicles;Feature extraction;Data models;Consumer electronics;Unmanned Aerial Vehicles;status recognition;disaster response;rescue missions;deep learning;image processing},
doi={10.1109/ICCE46568.2020.9043101},
ISSN={2158-4001},
month={Jan},}
@INPROCEEDINGS{8373497,
author={Zahran, S. and Moussa, A. and El-Sheimy, N.},
booktitle={2018 IEEE/ION Position, Location and Navigation Symposium (PLANS)}, title={Enhanced UAV navigation in GNSS denied environment using repeated dynamics pattern recognition},
year={2018},
volume={},
number={},
pages={1135-1142},
abstract={This paper presents an innovative approach to enhance the navigation of UAVs in GNSS denied environments. Considering the limited space, power, and size of small UAVs, the proposed approach does not require any sensors on the UAV. The typical repeated dynamic patterns of such UAVs are related to the actuators to offer a useful information for estimating the UAV navigation states. Machine learning (ML) classifier has been employed to detect these repeated dynamic patterns, then according to the detected pattern, an appropriate constraint/update is utilized to enhance the navigation solution through EKF to obtain a better estimate of the UAV states. Different test scenarios where conducted to verify the ability of the proposed approach to aid the INS solution during GNSS signal outages. The solution after fusing the Vheicle Model (VM) is enhaced by 98% compared to low cost stand-alone IMU solution.},
keywords={Mathematical model;Global navigation satellite system;Vehicle dynamics;Unmanned aerial vehicles;Sensors;Covariance matrices;Extended Kalman Filter (EKF);vehicle modeling (VM);machine learning (ML);classification;Global Navigation Satellite System (GNSS);Inertial Measurement Unit (IMU);Unmanned Aerial Vehicles (UAVs)},
doi={10.1109/PLANS.2018.8373497},
ISSN={2153-3598},
month={April},}
@INPROCEEDINGS{8659470,
author={Funahashi, Isana and Umeki, Yo and Yoshida, Taichi and Iwahashi, Masahiro},
booktitle={2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, title={Safety-level Estimation of Aerial Images based on Convolutional Neural Network for Emergency Landing of Unmanned Aerial Vehicle},
year={2018},
volume={},
number={},
pages={886-890},
abstract={We propose an estimation method for the safety-level of local regions in aerial images for the emergency landing of Unmanned Aerial Vehicles (UAVs) based on Convolutional Neural Networks (CNNs), and introduce a new definition of safe areas and a new dataset. The estimation methods calculate scores of the safety-level for each region, and based on the results, the landing system detects safe areas where UAVs land without injuring humans, animals, buildings, artifacts, and themselves. Previous methods generally define natural flat regions, such as grass, lawn, soil and sand areas, as safe. However, if the flat regions are small and adjoin undesirable objects, the definition is dangerous and has the possibility of the injuring. Therefore, we introduce new definition to avoid the above complicated regions, and produce the dataset. Based on the dataset, we propose a CNN model to estimate scores of the safety-level. The proposed model can use various local and global features, and consider the environment of a target region. Hence, the proposed method estimates safe regions without the complicated ones, and then has better scores in the precision than the state-of-the-art method in experiments.},
keywords={Estimation;Feature extraction;Training;Unmanned aerial vehicles;Safety;Buildings;Soil},
doi={10.23919/APSIPA.2018.8659470},
ISSN={2640-0103},
month={Nov},}
@INPROCEEDINGS{9051099,
author={Kim, Bobae and Jang, Beomhee and Lee, Donggeon and Im, Sungbin},
booktitle={2020 International Conference on Electronics, Information, and Communication (ICEIC)}, title={CNN-based UAV Detection with Short Time Fourier Transformed Acoustic Features},
year={2020},
volume={},
number={},
pages={1-3},
abstract={In this study, CNN (Convolutional Neural Network) is applied to the UAV detection, which is expanding its application in various fields, to compare the detection performance of the UAV against the noise of a small fan and the drum. In this study, the drum sound and the small fan sound are collected and compared with the UAV's hovering acoustic signal data. We evaluate the detection performance by using CNN for the features obtained by applying short-time Fourier transform to the samples. In the experiment, the UAV detection rate against the acoustic signal of the small fan is 99.74 % and the false detection rate is 0.39 %. For the drum sound, the detection rate is 99.98 % and the false detection rate is 0.20 %.},
keywords={Training;Fans;Time-frequency analysis;Fourier transforms;Propellers;Signal processing;Feature extraction;UAV;Detection;STFT;CNN;Deep Learning},
doi={10.1109/ICEIC49074.2020.9051099},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9550261,
author={Zhu, Kangrui and Zong, Qun and Zhang, Ruilong},
booktitle={2021 40th Chinese Control Conference (CCC)}, title={Real-time Virtual Simulation Platform for Multi-UVA hunting target using Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={4978-4983},
abstract={As being one of the most useful flying objects, quadrotor UAVs are gradually being applied to the military field in the form of "swarms". However, an urgent problem is how to improve the intelligence of UAV with low cost. In this paper, we propose a hunting scenario for multi-UAV in an urban environment. Firstly, We build the game model of multi-UAV hunting target and design the reward function. Secondly, we introduce an improved multi-agent deep deterministic policy gradient (MADDPG) to against an game AI target. Then, we build a virtual platform to simulate the urban combat environment based on the Unity3D game engine. The ML-Agents Toolkit is used to develop a real-time simulation data interface to achieve low-cost model training. Finally, simulation results from Python and virtual environment can demonstrate the effectiveness of the proposed hunting scenario.},
keywords={Training;Three-dimensional displays;Simulation;Urban areas;Virtual environments;Games;Reinforcement learning;Multi-UAV;Hunting mission;MADDPG;Real-time virtual simulation platform},
doi={10.23919/CCC52363.2021.9550261},
ISSN={1934-1768},
month={July},}
@INPROCEEDINGS{8285387,
author={Nguyen, Hung The and Garratt, Matthew and Bui, Lam Thu and Abbass, Hussein},
booktitle={2017 IEEE Symposium Series on Computational Intelligence (SSCI)}, title={Supervised deep actor network for imitation learning in a ground-air UAV-UGVs coordination task},
year={2017},
volume={},
number={},
pages={1-8},
abstract={Ground-Air coordination is a very complex environment for a machine learning algorithm. We focus on the case where an Unmanned Aerial Vehicle (UAV) needs to support a group of Unmanned Ground Vehicles (UGVs). The UAV is required to broadcast an image that contains all UGVs, thus, offering a bird-eye-view on the group as a whole. The source of complexity in this task is twofold. First, coordination needs to occur without communication between the UAV and UGVs. Second, the ability of the UAV to sense the UGVs is coupled with the ability of the UAV to learn how to track laterally the UGVs and adapt its vertical position so that the images of the UGVs are appropriately spaced within the camera field of view. In this paper, we propose using the Deep Actor Network component of an Actor-Critic Deep Reinforcement Learning architecture as a supervised learner. The advantage of this approach is that it offers a step towards autonomous learning whereby the full Actor-Critic model can be utilized in the future. Human demonstrations are collected for the deep Actor network to learn from. The system is built using the Gazebo Simulator, Robot Operating System, and the OpenAI Gym. We show that the proposed setup is able to train the UAV to follow the UGVs while maintaining all UGVs within camera range in situations where UGVs are performing complex maneuvers.},
keywords={Task analysis;Cameras;Unmanned aerial vehicles;Neural networks;Manifolds;Mathematical model;Land vehicles;Deep neural network;Gazebo;Ground-Air Interaction;OpenAI Gym;Human Demonstrations;Learning by Imitation;ROS;UAV;UGV},
doi={10.1109/SSCI.2017.8285387},
ISSN={},
month={Nov},}
@ARTICLE{9362177,
author={Garcia, Jorge Alberto Bañuelos and Younes, Ahmad Bani},
journal={IEEE Transactions on Aerospace and Electronic Systems}, title={Real-Time Navigation for Drogue-Type Autonomous Aerial Refueling Using Vision-Based Deep Learning Detection},
year={2021},
volume={57},
number={4},
pages={2225-2246},
abstract={This article develops a deep learning object detector to provide accurate six-degree-of-freedom (DoF) information of the drogue relative to a monocular camera onboard a flying unmanned aerial vehicle. An object detector helps to provide the needed information for an autonomous vehicle to dock and refuel without the need for human intervention. This object detector can detect eight different beacons by training on 8746 images of a mock drogue. Once these beacons were detected, a nonlinear least squares algorithm that uses the collinearity equations as a system model takes the beacon's location on the captured image to provide an accurate six-DoF navigation solution. These navigation solutions from the object detector were evaluated on multiple metrics and then compared to navigation solutions provided by a VICON motion tracking system. Finally, Monte Carlo analysis, using the collinearity equations as a system model, evaluates an object detector's performance with various noise levels.},
keywords={Detectors;Aircraft navigation;Aircraft;Mathematical model;Measurement;Object detection;Feature extraction;Attitude estimation;detection algorithms;high-order nonlinear least squares methods;image processing;inference algorithms;machine learning algorithms;Monte Carlo methods;neural networks;object detection;pose estimation;position and attitude determination},
doi={10.1109/TAES.2021.3061807},
ISSN={1557-9603},
month={Aug},}
@ARTICLE{9475451,
author={Ni, Wenjun and Wu, Di and Ma, Xiaoping},
journal={IEEE Access}, title={Energy-Optimal Flight Strategy for Solar-Powered Aircraft Using Reinforcement Learning With Discrete Actions},
year={2021},
volume={9},
number={},
pages={95317-95334},
abstract={The low efficiency of photovoltaic cells limits the energy absorption of high-altitude long-endurance (HALE) solar-powered unmanned aircraft vehicles (UAVs), which dramatically weakens the capacity for long-endurance missions. Therefore, finding a method to extend the flight duration with finite solar energy drives extensive research. The present work introduces a method that applies a deep reinforcement learning (DRL) framework to generate an energy-optimized flight strategy for HALE solar-powered aircraft. The neural network controller is designed to realize autonomous flight navigation by giving commands of thrust, attack angle, and bank angle. A mission area with a radius of 5 km is assumed to test the RL controller performance. The simulation results show that the RL controller leads to a 28 % increase in the battery SoC after a 24-hour flight, which indicates that a controller based on the RL framework might be a potential method for solving the solar-powered UAV trajectory planning problem. Aiming to explore the applicability of the RL controller, a sustained flight test is implemented. The results show that a 39-day endurance flight is achieved by the RL controller, which is 50% higher than the base case with a steady flight trajectory.},
keywords={Aircraft;Aerospace control;Reinforcement learning;Atmospheric modeling;Aircraft navigation;Solar energy;Optimization;High-altitude long-endurance aircraft;flight strategy optimization;automatic navigation;reinforcement learning;photovoltaic cell},
doi={10.1109/ACCESS.2021.3095224},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9641207,
author={Ding, Yuanxue and Qu, Yanchen and Zhang, Qing and Tong, Jiahui and Yang, Xianhui and Sun, Jianfeng},
booktitle={2021 IEEE International Conference on Unmanned Systems (ICUS)}, title={Research on UAV Detection Technology of Gm-APD Lidar Based on YOLO Model},
year={2021},
volume={},
number={},
pages={105-109},
abstract={In recent years, unmanned aerial vehicle (UAV) technology has developed rapidly, which plays an important role in both military and civil fields. While it brings convenience to all walks of life, there are also a lot of security problems. Therefore, it is necessary to study anti-UAV technology, but the detection of UAV is an important basis of anti-UAV technology. In this paper, by combining the three-dimensional range profile collected by Gm-APD (Geiger mode Avalanche Photo Diode) lidar with the deep learning method, a UAV detection method based on the improved YOLOv3 (You Only Look Once v3) network is proposed. Firstly, the data of UAV in low altitude real scene is collected by Gm-APD lidar, and range profile information is generated. Then, the YOLOv3 network is improved, and the SPP module can be added to combine the local features of the target with the global features to improve the detection accuracy. It is suitable for the detection of UAVs. Finally, the trajectory of the UAV is drawn based on the distance information. The experimental results show that the improved method can effectively detect UAV targets, and is better than the previous method, YOLOv3-Tiny method and YOLOv4 method. The farthest detection distance is 238m, the detection speed is fast, and the purpose of real-time detection and positioning can be achieved. Therefore, this method can be applied to anti-UAV technology and has important research significance.},
keywords={Deep learning;Laser radar;Conferences;Object detection;Autonomous aerial vehicles;Feature extraction;Real-time systems;target detection;UAV;anti-UAV technology;deep learning;YOLOv3},
doi={10.1109/ICUS52573.2021.9641207},
ISSN={},
month={Oct},}
@ARTICLE{9674904,
author={Wittstruck, Lucas and Jarmer, Thomas and Trautz, Dieter and Waske, Björn},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Estimating LAI from Winter Wheat using UAV Data and CNNs},
year={2022},
volume={},
number={},
pages={1-1},
abstract={With the advent of high-resolution unmanned aerial vehicle (UAV) data and advancing methods of deep learning, new opportunities have emerged in remote sensing to assess biophysical plant parameters. In this study, we investigated the potential of UAV-borne RGB data and convolutional neural networks (CNNs) to estimate the leaf area index (LAI) of winter wheat during two cropping seasons. In this context, spectral RGB and geometric plant information based on a normalized surface model (nDSM) were used as input variables. The results of the study demonstrated the suitability of optical UAV data and CNNs for LAI estimation of winter wheat at different growth stages and under various lightning conditions. The combination of RGB data and plant structures provided the best overall prediction accuracy (r2 = 0.83) compared to the models with only one input source (RGB: r2 = 0.58, nDSM: r2 = 0.75). Especially the estimation of low and high LAI values was improved using the complementary image information. Moreover, the results showed that the CNN models outperformed two classical machine learning approaches in terms of accuracy.},
keywords={Biological system modeling;Estimation;Crops;Convolutional neural networks;Predictive models;Data models;Training;convolutional neural network (CNN);deep learning;drones;leaf area index;low-cost sensor;plant parameters;regression;remote sensing},
doi={10.1109/LGRS.2022.3141497},
ISSN={1558-0571},
month={},}
@INPROCEEDINGS{9231595,
author={Romero, Daniel and Shrestha, Raju and Teganya, Yves and Chepuri, Sundeep Prabhakar},
booktitle={2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP)}, title={Aerial Spectrum Surveying: Radio Map Estimation with Autonomous UAVs},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Radio maps are emerging as a popular means to endow next-generation wireless communications with situational awareness. In particular, radio maps are expected to play a central role in unmanned aerial vehicle (UAV) communications since they can be used to determine interference or channel gain at a spatial location where a UAV has not been before. Existing methods for radio map estimation utilize measurements collected by sensors whose locations cannot be controlled. In contrast, this paper proposes a scheme in which a UAV collects measurements along a trajectory. This trajectory is designed to obtain accurate estimates of the target radio map in a short time operation. The route planning algorithm relies on a map uncertainty metric to collect measurements at those locations where they are more informative. An online Bayesian learning algorithm is developed to update the map estimate and uncertainty metric every time a new measurement is collected, which enables real-time operation.},
keywords={Measurement uncertainty;Unmanned aerial vehicles;Uncertainty;Complexity theory;Measurement;Estimation;Time measurement;Radio maps;UAV communications;online estimation;route planning;active learning},
doi={10.1109/MLSP49062.2020.9231595},
ISSN={1551-2541},
month={Sep.},}
@INPROCEEDINGS{5486961,
author={Pang Rui},
booktitle={2010 2nd International Conference on Advanced Computer Control}, title={Multi-UAV formation maneuvering control based on Q-Learning fuzzy controller},
year={2010},
volume={4},
number={},
pages={252-257},
abstract={On the basis of the relative motion relations of the formation flight, UAV longitudinal and lateral fuzzy controllers are designed to solve the multi-UAV formation control problem. The relative positions between adjacent UAVs are controlled to meet the desired commands and performance requirements. Q-Learning method, which is one kind of reinforcement learning, is used to tune the corresponding parameters in output membership functions of fuzzy controller. This auto-tuning avoids the complexity of manual tuning with expert experience and eliminates the steady state errors. Also, different conditions including coordinative turning, tense-loose shape changing, shape sequence changing and collision avoiding are simulated with the formation control methodology, which is comprised of centralized decision and decentralized control. The results prove the correctness of control method and formation control strategy under the circumstances of different formation maneuvering demands.},
keywords={Fuzzy control;Unmanned aerial vehicles;Shape control;Automatic control;Motion control;Learning;Adaptive control;Nonlinear control systems;Programmable control;Linear feedback control systems;Reinforcement learning;Q-learning;fuzzy control;UAVs;Formation Flight;Maneuvering},
doi={10.1109/ICACC.2010.5486961},
ISSN={},
month={March},}
@INPROCEEDINGS{9230971,
author={Sabrina, Fariza and Sohail, Shaleeza and Thakur, Sweta and Azad, Salahuddin and Wasimi, Saleh},
booktitle={2020 IEEE Region 10 Symposium (TENSYMP)}, title={Use of Deep Learning Approach on UAV imagery to Detect Mistletoe Infestation},
year={2020},
volume={},
number={},
pages={556-559},
abstract={Mistletoe infestation reduces crop yield and degrades crop quality through depletion of nutrients and moisture from host plants. Timely detection of such infestation is critical for crop growers but a difficult task to perform. Published literature on such research is scarce especially for automated detection of mistletoe infestations, which can assist farmers in taking timely and effective measures. This paper reviews existing literature on mistletoe and other infestation detection through machine learning techniques. Moreover, the paper presents a deep learning-based architecture along with image pre-processing techniques, and a training method that could be used for detection of mistletoe. The experimental studies using the proposed framework are currently in-progress where aerial images of plants are to be taken from UAVs (Unmanned Aerial Vehicles).},
keywords={Feature extraction;Diseases;Vegetation;Training;Agriculture;Hyperspectral imaging;Task analysis;Mistletoe infestation;deep learning},
doi={10.1109/TENSYMP50017.2020.9230971},
ISSN={2642-6102},
month={June},}
@ARTICLE{9020018,
author={Zhang, Xiaoming and Ali, Mohsin},
journal={IEEE Access}, title={A Bean Optimization-Based Cooperation Method for Target Searching by Swarm UAVs in Unknown Environments},
year={2020},
volume={8},
number={},
pages={43850-43862},
abstract={This paper studies the target searching problem using swarms of unmanned aerial vehicles (UAVs) in unknown environments which information is unknown to the UAVs, other than features they detect through their sensors. Effective decision and control methods are required for UAVs that consider their limitations and characteristics when confronted with target searching problems. A cooperative target searching method is proposed for swarm UAVs based on an improved bean optimization algorithm (BOA) called Robot Bean Optimization Algorithm (RBOA). Compared with conventional BOAs used for optimal computation, RBOA has two main modifications for the cooperative control of swarm robots: 1) it accounts for the free motion space of individual UAVs using a Thiessen polygon; and 2) it adds a free space search mechanism to improve the efficiency of target searching. Based on the above improvements, and by integrating a multi-phase search mechanism and scheduling control strategy, a swarm UAV collaborative search simulation platform is built for experimental purposes. The results obtained from search simulations show that the RBOA can outperform adaptive robotic particle swarm optimization (A-RPSO) in target searches in complex and unknown environments, especially with fewer evolutionary generations and smaller numbers of robots. The RBOA, which is inspired by plant population evolutionary patterns, has fast and effective search capabilities, distributed collaborative interaction, and emergent swarm intelligence. It provides new ideas and support for research into the control of swarm UAVs and swarm robots.},
keywords={Sociology;Statistics;Optimization;Particle swarm optimization;Robot kinematics;Task analysis;Swarm intelligence;cooperation;swarm UAVs;BOA;target search},
doi={10.1109/ACCESS.2020.2977499},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9183625,
author={Sarkar, Sayani and Totaro, Michael W. and Kumar, Ashok},
booktitle={2020 16th International Conference on Distributed Computing in Sensor Systems (DCOSS)}, title={An Intelligent Framework for Prediction of a UAV’s Flight Time},
year={2020},
volume={},
number={},
pages={328-332},
abstract={The success of an unmanned aerial vehicle's (UAVs) or drone's mission is contingent upon planning, command, control, tasking, and communications. Drone-mounted payloads impact UAV flight time. Depending upon the payload, flight times may vary. As such, it is important to know beforehand the expected flight time of a drone, in order to ensure a successful flight. Currently, there are no methods or algorithms for calculating or predicting a drone's flight time that takes into account varying payloads. Manufacturers' technical manuals usually provide only the best-case predictions of UAV flight time; these assume no additional mounted items (e.g., onboard wireless sensor modules, cameras, etc.). In this paper, we describe an empirical study of UAV flight events, and propose regression and deep learning (DL)-based methods to predict accurately the flight time of UAVs. Our methods take onto account both the payload weight and energy dissipation from the onboard battery. The payloads used in our study include gimbal-mounted RGB/thermal cameras, as well as onboard computers. It is expected that this work will provide important guidance to researchers and planners of UAVs.},
keywords={Payloads;Drones;Cameras;Batteries;Correlation;Computers;Unmanned aerial vehicles;onboard cameras;onboard computers;payload’s current;dataset;statistical testing;regression analysis;deep learning model},
doi={10.1109/DCOSS49796.2020.00058},
ISSN={2325-2944},
month={May},}
@ARTICLE{9656563,
author={Alos, Ahmad and Dahrouj, Zouhair},
journal={IEEE Aerospace and Electronic Systems Magazine}, title={Using MLSTM and Multi-output Convolutional LSTM Algorithms for Detecting Anomalous Patterns in Streamed Data of Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={1-1},
abstract={In this paper, we present a comparative study of two existing deep learning tools that are used in a novel way to detect anomalies in the streamed data of the Unmanned Aerial Vehicle (UAV). Detecting anomalies is very vital to predict potential faults that are caused by hardware and software faults and may prevent the UAV from hazardous accidents. Therefore, we suggest using Multiple Long Short-Term Memory (MLSTM) and Multi-Output Convolutional LSTM to detect anomalies in UAV data. LSTM networks attracted many researchers in several domains, as it is a useful tool for learning dynamic temporal patterns and long-range dependencies in sequential data, which cannot be achieved using traditional neural networks. However, utilizing multiple LSTM networks would result in too much redundancy. The redundancy issue can be solved by incorporating one Convolutional LSTM (ConvLSTM) network with multiple outputs. The ConvLSTM is suitable for analyzing multivariate temporal data; due to its convolutional architecture and the advantage of preserving the benefits of the LSTM networks. We evaluated and compared the two approaches using well-known indicators such as the Detection Rate, the False Alarm Rate, the Precision, and the F.score indicators. The two methods exhibited promising results in predicting different types of faults, for instance (sensor-impulse and sensor-cut). However, the multi-output ConvLSTM was faster in training and testing phases, and its results were superior in predicting (sensor-stuck and sensor-drift) faults.},
keywords={Logic gates;Autonomous aerial vehicles;Anomaly detection;Computer architecture;Prediction algorithms;Memory management;Data models;Anomaly Detection;Convolutional LSTM;Deep Learning;Fault Detection;LSTM;Machine learning;Neural networks;Sliding window;UAV},
doi={10.1109/MAES.2021.3053108},
ISSN={1557-959X},
month={},}
@INPROCEEDINGS{9463292,
author={Yang, Xudong},
booktitle={2021 2nd International Conference on Computing and Data Science (CDS)}, title={Reinforcement Learning for Multi-Robot System: A Review},
year={2021},
volume={},
number={},
pages={203-213},
abstract={The optimization control of multi-robot systems based on Reinforcement Learning is the frontier field of Robotics and distributed Artificial Intelligence in recent years. Multi-robot systems have the characteristics of distribution, heterogeneity, and high-dimensional spatial continuity, which makes the research of reinforcement learning for multi-robot systems face a series of challenges. This paper reviews the challenges in four practical problems of the multi-robot system which are distributed collaborative driving of multiple vehicles, mobile sensing robot team, multi-robot collaborative monitoring, and multi-UAV cooperative task planning and the latest solutions of them. Methods based on Deep Reinforcement Learning and Multi-Agent Reinforcement Learning are also described. This review may be useful to guide researchers and technologists from the industry in their choice of better cope with the multi-robot system's problems.},
keywords={Service robots;Collaboration;Reinforcement learning;Robot sensing systems;Sensors;Planning;Multi-robot systems;deep reinforcement learning;multi-agent reinforcement learning;multi-robot system},
doi={10.1109/CDS52072.2021.00043},
ISSN={},
month={Jan},}
@ARTICLE{9411810,
author={Lahmeri, Mohamed-Amine and Kishk, Mustafa A. and Alouini, Mohamed-Slim},
journal={IEEE Open Journal of the Communications Society}, title={Artificial Intelligence for UAV-Enabled Wireless Networks: A Survey},
year={2021},
volume={2},
number={},
pages={1015-1040},
abstract={Unmanned aerial vehicles (UAVs) are considered as one of the promising technologies for the next-generation wireless communication networks. Their mobility and their ability to establish line of sight (LOS) links with the users made them key solutions for many potential applications. In the same vein, artificial intelligence (AI) is growing rapidly nowadays and has been very successful, particularly due to the massive amount of the available data. As a result, a significant part of the research community has started to integrate intelligence at the core of UAVs networks by applying AI algorithms in solving several problems in relation to drones. In this article, we provide a comprehensive overview of some potential applications of AI in UAV-based networks. We also highlight the limits of the existing works and outline some potential future applications of AI for UAVs networks.},
keywords={Task analysis;Drones;Tutorials;Collaborative work;Reinforcement learning;Classification algorithms;Training;Artificial intelligence;deep learning;federated learning;machine learning;reinforcement learning;UAVs},
doi={10.1109/OJCOMS.2021.3075201},
ISSN={2644-125X},
month={},}
@INPROCEEDINGS{9326776,
author={Rao, Yinglu and Ma, Sile and Xing, Jinhao and Zhang, Heng and Ma, Xiaojing},
booktitle={2020 Chinese Automation Congress (CAC)}, title={Real time vision-based autonomous precision landing system for UAV airborne processor},
year={2020},
volume={},
number={},
pages={532-537},
abstract={Autonomous precision landing of unmanned aerial vehicle can be widely used in ocean inspection, mine inspection and other industries. Vision based autonomous precision landing research can be used in global positioning system (GPS) denied area with low cost and high accuracy which has become a hot research spot. Previous vision-based methods cannot cope with complex environmental changes while landing and can not achieve real time in airborne processor. A lightweight detection model named Myolo is designed to detect landmark. Fast contour optimization algorithm is proposed to further enhance location results. Experimental results show that Myolo can achieve 16.1 FPS which is 23 times faster than faster-RCNN and 5 times faster than yolo. After using fast local contour optimization algorithm, Myolo's position accuracy is increased to 4.2 pixel, 12.5% higher than yolo and 50.6% higher than tiny-yolo. Myolo can significantly outperforms state-of-the-art object detection model in terms of both accuracy and speed in complex landing environment.},
keywords={Optimization;Convolution;Drones;Image edge detection;Real-time systems;Prediction algorithms;Global Positioning System;Unmanned aerial vehicle;Autonomous precision landing;Deep learning;Vision-based},
doi={10.1109/CAC51589.2020.9326776},
ISSN={2688-0938},
month={Nov},}
@INPROCEEDINGS{9498835,
author={Gao, Haitao and Mu, Junsheng and Jing, Xiaojun and Yang, Yuzhou},
booktitle={2021 International Wireless Communications and Mobile Computing (IWCMC)}, title={UAV Control Signal Detection based on Convolution Neural Network},
year={2021},
volume={},
number={},
pages={581-585},
abstract={In this paper, an Unmanned Aerial Vehicles (UAV) control signal detection scheme is proposed with Convolutional Neural Network (CNN). More specifically, the sampled signal images of UAV control signal are considered to train the classical LeNet network under various signal-to-noise ratios (SNR). The simulation experiments state that the detection performance of UAV control signal is greatly improved. In addition, the conclusion is drawn that the increase in signal image size helps to improve the detection performance.},
keywords={Wireless communication;Convolution;Computational modeling;Neural networks;Unmanned aerial vehicles;Convolutional neural networks;Computational complexity;UAV;CNN;frequency hopping signal},
doi={10.1109/IWCMC51323.2021.9498835},
ISSN={2376-6506},
month={June},}
@INPROCEEDINGS{6244278,
author={Qian Zhengxiang and Tang Liang and Zhang Bin and Wang Xiaozhong},
booktitle={2012 24th Chinese Control and Decision Conference (CCDC)}, title={Design and simulation of a self-repairing flight control system for UAV},
year={2012},
volume={},
number={},
pages={1732-1736},
abstract={A self-repairing flight control system based on neural network direct inverse control is proposed to reconfigure the control law in order to restore the control of the damaged UAV. Considering the nonlinear and coupling property of the damaged UAV system, the architecture of neural network is chosen to establish the inverse system of the damaged system for linearization and decoupling. Then PID feedback control is introduced to improve the performance of the inverse system. Theoretical analysis and simulation results show that this control system can be used to restore the control of the damaged UAV when the traditional control fails.},
keywords={Artificial neural networks;Control systems;Biological neural networks;Aerospace control;Training;Computer architecture;UAV;self-repairing;neural network;direct inverse control},
doi={10.1109/CCDC.2012.6244278},
ISSN={1948-9447},
month={May},}
@INPROCEEDINGS{8921178,
author={Zhang, Shuang and Zhang, Xuming and Zhang, Aizhu and Fu, Hang and Cheng, Ji and Huang, Hui and Sun, Genyun and Zhang, Li and Yao, Yanjuan},
booktitle={2019 10th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)}, title={Fusion Of Low-And High-Level Features For Uav Hyperspectral Image Classification},
year={2019},
volume={},
number={},
pages={1-4},
abstract={Different from the traditional satellite remote sensing imagery, the high-spatial and high-spectral imagery captured by Unmanned Aerial Vehicle (UAV) platform is able to provide valuable information of land surface. In this paper, a novel method is proposed for effective and efficient land-use mapping for the UAV hyperspectral images. In this method, Principal Component Analysis (PCA) was first performed and the output is used in all feature extraction steps. Then, the Extended Multi-Attribute Profiles (EMAPs) were used for extract the spatial information and stacked with spectral features into a vector as low-level features. To improve the classification performance, a Convolutional Neural Network (CNN) were applied to extract high-level features. Specifically, a support vector machine (SVM)-based decision fusion strategy is proposed to achieve comprehensive utilization of the low-and high-level features. The classification results obtained by the proposed method showed significant improvement when in comparison with the classifier only used single level features.},
keywords={Feature extraction;Hyperspectral imaging;Support vector machines;Kernel;Convolutional neural networks;UAV hyperspectral images;land-use mapping;low-level features;high-level features;decision fusion},
doi={10.1109/WHISPERS.2019.8921178},
ISSN={2158-6276},
month={Sep.},}
@ARTICLE{9316169,
author={Javadi, Saleh and Dahl, Mattias and Pettersson, Mats I.},
journal={IEEE Access}, title={Vehicle Detection in Aerial Images Based on 3D Depth Maps and Deep Neural Networks},
year={2021},
volume={9},
number={},
pages={8381-8391},
abstract={Object detection in aerial images, particularly of vehicles, is highly important in remote sensing applications including traffic management, urban planning, parking space utilization, surveillance, and search and rescue. In this article, we investigate the ability of three-dimensional (3D) feature maps to improve the performance of deep neural network (DNN) for vehicle detection. First, we propose a DNN based on YOLOv3 with various base networks, including DarkNet-53, SqueezeNet, MobileNet-v2, and DenseNet-201. We assessed the base networks and their performance in combination with YOLOv3 on efficiency, processing time, and the memory that each architecture required. In the second part, 3D depth maps were generated using pairs of aerial images and their parallax displacement. Next, a fully connected neural network (fcNN) was trained on 3D feature maps of trucks, semi-trailers and trailers. A cascade of these networks was then proposed to detect vehicles in aerial images. Upon the DNN detecting a region, coordinates and confidence levels were used to extract the corresponding 3D features. The fcNN used 3D features as the input to improve the DNN performance. The data set used in this work was acquired from numerous flights of an unmanned aerial vehicle (UAV) across two industrial harbors over two years. The experimental results show that 3D features improved the precision of DNNs from 88.23 % to 96.43 % and from 97.10 % to 100 % when using DNN confidence thresholds of 0.01 and 0.05, respectively. Accordingly, the proposed system was able to successfully remove 72.22 % to 100 % of false positives from the DNN outputs. These results indicate the importance of 3D features utilization to improve object detection in aerial images for future research.},
keywords={Feature extraction;Three-dimensional displays;Detectors;Neural networks;Unmanned aerial vehicles;Training data;Object detection;Convolutional neural networks;3D depth maps;object detection;aerial images},
doi={10.1109/ACCESS.2021.3049741},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7553921,
author={Wang, Ya and Zhang, Hongbin and Han, Dongfei},
booktitle={2016 35th Chinese Control Conference (CCC)}, title={Neural network adaptive inverse model control method for quadrotor UAV},
year={2016},
volume={},
number={},
pages={3653-3658},
abstract={For the highly nonlinear, strong coupling and underactuated, an effective controller for quadrotor unmanned aerial vehicle (UAV) is not easy to obtain, especially in conditions of the parameters variations and external disturbance. In this paper, an adaptive inverse model control method (AIMCM) is proposed for this plant. Two BP networks are used in control system to achieve the model identification and control. Both offline trained and online learned are used to ensure the fast learning and the robustness. The convergence of the learning algorithm is proved based on Lyapunov function. At last, a quadrotor UAV control simulation based on the full model shows the superiority and robustness of the control system.},
keywords={Unmanned aerial vehicles;Adaptation models;Control systems;Biological neural networks;Robustness;Neurons;Quadrotor UAV;adaptive inverse model control method;BP neural network},
doi={10.1109/ChiCC.2016.7553921},
ISSN={1934-1768},
month={July},}
@ARTICLE{9383091,
author={Li, Ting and Liu, Wei and Zeng, Zhiwen and Xiong, N. N.},
journal={IEEE Internet of Things Journal}, title={DRLR: A Deep Reinforcement Learning based Recruitment Scheme for Massive Data Collections in 6G-based IoT networks},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Recently, rapid deployment on fifth-generation (5G) networks has brought great opportunities for the enabling data-intensive applications, and brings an extending expectation on the developments of 6G. A basic requirement to develop 6G networks is to reach data with low latency, low cost and high coverage in smart IoT. Therefore, this paper proposes a novel machine learning based approach to collect data from multiple sensor devices by cooperation between vehicle and UAV in IoT. Firstly, genetic algorithm is utilized to select vehicular collectors to collect massive data from sensor devices, which aims to maximize coverage ratio and to minimize employment cost. Secondly, we design a novel Deep Reinforcement Learning (DRL)-based route policy to plan collection routes of UAVs with constrain energy, which simplifies the network model, accelerates training speeds and realizes dynamic planning of flight paths. The optimal collection route of an UAV is a series of outputs based on the proposed DRL-based route policy. Finally, our extensive experiments demonstrate that the proposed scheme can comprehensively improve the coverage ratio of massive data collections and reduce collection costs in smart IoT for the future 6G networks.},
keywords={Data collection;6G mobile communication;Internet of Things;Genetic algorithms;Unmanned aerial vehicles;Optimization;Reinforcement learning;6G;deep reinforcement learning;massive data collections;vehicle;unmanned aerial vehicles.},
doi={10.1109/JIOT.2021.3067904},
ISSN={2327-4662},
month={},}
@ARTICLE{9473012,
author={Chen, Yu-Jia and Liao, Kai-Min and Ku, Meng-Lin and Tso, Fung Po and Chen, Guan-Yi},
journal={IEEE Transactions on Vehicular Technology}, title={Multi-Agent Reinforcement Learning Based 3D Trajectory Design in Aerial-Terrestrial Wireless Caching Networks},
year={2021},
volume={70},
number={8},
pages={8201-8215},
abstract={This paper investigates a dynamic 3D trajectory design of multiple cache-enabled unmanned aerial vehicles (UAVs) in a wireless device-to-device (D2D) caching network with the goal of maximizing the long-term network throughput. By storing popular content at the nearby mobile user devices, D2D caching is an efficient method to improve network throughput and alleviate backhaul burden. With the attractive features of high mobility and flexible deployment, UAVs have recently attracted significant attention as cache-enabled flying base stations. The use of cache-enabled UAVs opens up the possibility of tracking the mobility pattern of the corresponding users and serving them under limited cache storage capacity. However, it is challenging to determine the optimal UAV trajectory due to the dynamic environment with frequently changing network topology and the coexistence of aerial and terrestrial caching nodes. In response, we propose a novel multi-agent reinforcement learning based framework to determine the optimal 3D trajectory of each UAV in a distributed manner without a central coordinator. In the proposed method, multiple UAVs can cooperatively make flight decisions by sharing the gained experiences within a certain proximity to each other. Simulation results reveal that our algorithm outperforms the traditional single- and multi-agent Q-learning algorithms. This work confirms the feasibility and effectiveness of cache-enabled UAVs which serve as an important complement to terrestrial D2D caching nodes.},
keywords={Trajectory;Device-to-device communication;Wireless communication;Cache storage;Wireless sensor networks;Unmanned aerial vehicles;Throughput;Unmanned aerial vehicles (UAVs);trajectory design;wireless caching;multi-agent reinforcement learning},
doi={10.1109/TVT.2021.3094273},
ISSN={1939-9359},
month={Aug},}
@INPROCEEDINGS{9367389,
author={Zhong, Ruikang and Liu, Xiao and Liu, Yuanwei and Chen, Yue},
booktitle={2020 IEEE Globecom Workshops (GC Wkshps}, title={NOMA in UAV-aided cellular offloading: A machine learning approach},
year={2020},
volume={},
number={},
pages={1-6},
abstract={A novel framework is proposed for cellular offloading with the aid of multiple unmanned aerial vehicles (UAVs), while non-orthogonal multiple access (NOMA) technique is employed at each UAV to further improve the spectrum efficiency of the wireless network. The optimization problem of joint three-dimensional (3D) trajectory design and power allocation is formulated for maximizing the throughput. In an effort to solve this pertinent dynamic problem, a K-means based clustering algorithm is first adopted for periodically partitioning users. Afterward, a mutual deep Q-network (MDQN) algorithm is proposed to jointly determine the optimal 3D trajectory and power allocation of UAVs. In contrast to the conventional deep Q-network (DQN) algorithm, the MDQN algorithm enables the experience of multi-agent to be input into a shared neural network to shorten the training time with the assistance of state abstraction. Numerical results demonstrate that: 1) the proposed MDQN algorithm has a faster convergence rate than the conventional DQN algorithm in the multi-agent case; 2) The achievable sum rate of the NOMA enhanced UAV network is 23% superior to the case of orthogonal multiple access (OMA); 3) By designing the optimal 3D trajectory of UAVs with the aid of the MDON algorithm, the sum rate of the network enjoys 142% and 56% gains than that of invoking the circular trajectory and the 2D trajectory, respectively.},
keywords={NOMA;Three-dimensional displays;Heuristic algorithms;Clustering algorithms;Unmanned aerial vehicles;Trajectory;Partitioning algorithms},
doi={10.1109/GCWkshps50303.2020.9367389},
ISSN={},
month={Dec},}
@ARTICLE{9124708,
author={Li, Lixin and Ren, Huan and Cheng, Qianqian and Xue, Kaiyuan and Chen, Wei and Debbah, Mérouane and Han, Zhu},
journal={IEEE Transactions on Wireless Communications}, title={Millimeter-Wave Networking in the Sky: A Machine Learning and Mean Field Game Approach for Joint Beamforming and Beam-Steering},
year={2020},
volume={19},
number={10},
pages={6393-6408},
abstract={In unmanned aerial vehicle (UAV)-assisted massive multi-input multi-output (MIMO) millimeter-wave (mmWave) networks, beam-steering guarantees reliable and steady connection between flying base stations and ground users with the challenge of strict angular deviation. In this paper, we investigate a joint optimization problem of beamforming and beam-steering in the multi-UAV mmWave networks, considering line-of-sight (LoS) communication for UAVs. For the hybrid beamforming optimization of massive MIMO mmWave, we propose a hybrid beamforming scheme based on the cross-entropy estimation with the robustness algorithm inspired by machine learning, which aims to optimize the hybrid precoding matrix. For the beam-steering optimization, we propose a novel mean field game (MFG)-based massive MIMO angle control scheme to model the optimal mmWave channel optimization problem between UAVs and ground users. In addition, when dealing with the problem of initial sensitivity and difficulty to solve the partial differential equations in the MFG, we utilize reinforcement learning to achieve the mean field equilibrium, which is described as the mean field learning game algorithm. Finally, a joint beamforming and beam-steering optimization algorithm is proposed to maximize the system sum-rate. Simulation results show the significant improvements in sum-rate, energy efficiency, and spectral efficiency, which verify the effectiveness of the proposed algorithm.},
keywords={Array signal processing;Optimization;Games;Millimeter wave communication;Interference;Wireless communication;Machine learning;mmWave network;beamforming;beam-steering;machine learning;mean field game;reinforcement learning},
doi={10.1109/TWC.2020.3003284},
ISSN={1558-2248},
month={Oct},}
@INPROCEEDINGS{8761775,
author={Ke, Yongning and Gao, Hui and Xu, Wenjun and Li, Lixin and Guo, Li and Feng, Zhiyong},
booktitle={ICC 2019 - 2019 IEEE International Conference on Communications (ICC)}, title={Position Prediction Based Fast Beam Tracking Scheme for Multi-User UAV-mmWave Communications},
year={2019},
volume={},
number={},
pages={1-7},
abstract={Unmanned aerial vehicle (UAV) millimeter-wave (mmWave) communication is emerging as a promising technique for future networks with flexible network topology and ultra-high data transmission rate. Within such full-dimensionally dynamic mmWave network, beam-tracking is challenging and critical, especially when all the UAVs are in motion for some collaborative tasks that require high-quality communications. In this paper, we propose a fast beam tracking scheme, which is built on an efficient position prediction of multiple moving UAVs. In particular, a Gaussian process based machine learning scheme is proposed to achieve fast and accurate UAV position prediction with quantifiable positional uncertainty. Based on the prediction results, the beam-tracking can be confined within some specific spatial regions centered on the predicted UAV positions. In contrast to the full-space searching based scheme, our proposed position prediction based beam tracking requires little system overhead and thus achieves high net spectrum efficiency. Moreover, we also propose a practical communication protocol embedding our beam-tracking scheme, which monitors the channel evolution and triggers the UAV position prediction for beam-tracking, transmit-receive beam pair selection and data transmission. Simulation results validate the advantages of our scheme over the existing works.},
keywords={Training;Unmanned aerial vehicles;Tracking;Array signal processing;Millimeter wave communication;Maintenance engineering;Millimeter wave technology},
doi={10.1109/ICC.2019.8761775},
ISSN={1938-1883},
month={May},}
@INPROCEEDINGS{8407158,
author={Xia, Chen and Yudi, Ai},
booktitle={2018 Chinese Control And Decision Conference (CCDC)}, title={Multi — UAV path planning based on improved neural network},
year={2018},
volume={},
number={},
pages={354-359},
abstract={Aiming at the problem of multi-UAV path planning in three - dimensional environment, a fast path planning method is designed by using the improved neural network algorithm. According to the distance between the UAV and the threat, when the UAV is not in the threat area, the method of taking large step is adopted to achieve the purpose of rapid generation of the path. When the UAV is inside the threat area, the method of taking the adjustable step size is used to achieve the fine search path. The UAV rapid out of the threat is achieved by combining with the dynamic adjustable step size and neural network and using the adaptive learning factors, and using the attack revenue and cost function to establish the revenue function, the strategy should be taken is given through the revenue. The simulation results show that the algorithm proposed in this paper not only guarantees the safety of UAV to bypass the threat, but also the better path is obtained and the best decision-making strategy is found.},
keywords={multiple unmanned aerial vehicle (multi-UAV);path planning;neural networks;adjustable step size},
doi={10.1109/CCDC.2018.8407158},
ISSN={1948-9447},
month={June},}
@ARTICLE{9220821,
author={Zhang, Qianqian and Saad, Walid and Bennis, Mehdi and Lu, Xing and Debbah, Mérouane and Zuo, Wangda},
journal={IEEE Transactions on Wireless Communications}, title={Predictive Deployment of UAV Base Stations in Wireless Networks: Machine Learning Meets Contract Theory},
year={2021},
volume={20},
number={1},
pages={637-652},
abstract={In this paper, a novel framework is proposed to enable a predictive deployment of unmanned aerial vehicles (UAVs) as temporary base stations (BSs) to complement ground cellular systems in face of downlink traffic overload. First, a novel learning approach, based on the weighted expectation maximization (WEM) algorithm, is proposed to estimate the user distribution and the downlink traffic demand. Next, to guarantee a truthful information exchange between the BS and UAVs, using the framework of contract theory, an offload contract is developed, and the sufficient and necessary conditions for having a feasible contract are analytically derived. Subsequently, an optimization problem is formulated to deploy an optimal UAV onto the hotspot area in a way that the utility of the overloaded BS is maximized. Simulation results show that the proposed WEM approach yields a prediction error of around 10%. Compared with the expectation maximization and k-mean approaches, the WEM method shows a significant advantage on the prediction accuracy, as the traffic load in the cellular system becomes spatially uneven. Furthermore, compared with two event-driven deployment schemes based on the closest-distance and maximal-energy metrics, the proposed predictive approach enables UAV operators to provide efficient communication service for hotspot users in terms of the downlink capacity, energy consumption and service delay. Simulation results also show that the proposed method significantly improves the revenues of both the BS and UAV networks, compared with two baseline schemes.},
keywords={Downlink;Contracts;Wireless communication;Unmanned aerial vehicles;Cellular networks;Prediction algorithms;Simulation;Cellular networks;UAV deployment;traffic prediction;contract theory},
doi={10.1109/TWC.2020.3027624},
ISSN={1558-2248},
month={Jan},}
@INPROCEEDINGS{9500477,
author={Ding, Ruijin and Gao, Feifei and Yang, Guanghua and Shen, Xuemin Sherman},
booktitle={ICC 2021 - IEEE International Conference on Communications}, title={Air-Ground Coordination Communication by Multi-Agent Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={1-6},
abstract={In this paper, we investigate an air-ground coordination communication system where ground users (GUs) access suitable UAV base stations (UAV-BSs) to maximize their own throughput and UAV-BSs design their trajectories to maximize the total throughput and keep GU fairness. Note that the action space of GUs is discrete, and UAV-BSs’ action space is continuous. To deal with the hybrid action space, we propose a multi-agent deep reinforcement learning (MADRL) approach, named AG-PMADDPG (air-ground probabilistic multi-agent deep deterministic policy gradient), where GUs transform the discrete actions to continuous action probabilities, and then sample actions according to the probabilities. The proposed method enable the users make decisions based on their local information, which is beneficial for user privacy. Simulation results demonstrate that AG-PMADDPG can outperform the benchmark algorithms in terms of fairness and throughput.},
keywords={Privacy;Simulation;System performance;Reinforcement learning;Transforms;Benchmark testing;Throughput},
doi={10.1109/ICC42927.2021.9500477},
ISSN={1938-1883},
month={June},}
@ARTICLE{8302546,
author={Fan, Zhun and Lu, Jiewei and Gong, Maoguo and Xie, Honghui and Goodman, Erik D.},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Automatic Tobacco Plant Detection in UAV Images via Deep Neural Networks},
year={2018},
volume={11},
number={3},
pages={876-887},
abstract={Tobacco plant detection plays an important role in the management of tobacco planting. In this paper, a new algorithm based on deep neural networks is proposed to detect tobacco plants in images captured by unmanned aerial vehicles (UAVs) (called UAV images). These UAV images are characterized by a very high spatial resolution (35 mm), and consequently contain an extremely high level of detail for the development of automatic detection algorithms. The proposed algorithm consists of three stages. In the first stage, a number of candidate tobacco plant regions are extracted from UAV images with the morphological operations and watershed segmentation. Each candidate region contains a tobacco plant or a nontobacco plant. In the second stage, a deep convolutional neural network is built and trained with the purpose of classifying the candidate regions as tobacco plant regions or nontobacco plant regions. In the third stage, postprocessing is performed to further remove the nontobacco plant regions. The proposed algorithm is evaluated on a UAV image dataset. The experimental results show that the proposed algorithm performs well on the detection of tobacco plants in UAV images.},
keywords={Neural networks;Image segmentation;Unmanned aerial vehicles;Image color analysis;Remote sensing;Spatial resolution;Classification algorithms;Convolutional neural network (CNN);detection;tobacco plants;unmanned aerial vehicles (UAVs)},
doi={10.1109/JSTARS.2018.2793849},
ISSN={2151-1535},
month={March},}
@ARTICLE{9453811,
author={Yang, Helin and Zhao, Jun and Xiong, Zehui and Lam, Kwok-Yan and Sun, Sumei and Xiao, Liang},
journal={IEEE Journal on Selected Areas in Communications}, title={Privacy-Preserving Federated Learning for UAV-Enabled Networks: Learning-Based Joint Scheduling and Resource Management},
year={2021},
volume={39},
number={10},
pages={3144-3159},
abstract={Unmanned aerial vehicles (UAVs) are capable of serving as flying base stations (BSs) for supporting data collection, machine learning (ML) model training, and wireless communications. However, due to the privacy concerns of devices and limited computation or communication resource of UAVs, it is impractical to send raw data of devices to UAV servers for model training. Moreover, due to the dynamic channel condition and heterogeneous computing capacity of devices in UAV-enabled networks, the reliability and efficiency of data sharing require to be further improved. In this paper, we develop an asynchronous federated learning (AFL) framework for multi-UAV-enabled networks, which can provide asynchronous distributed computing by enabling model training locally without transmitting raw sensitive data to UAV servers. The device selection strategy is also introduced into the AFL framework to keep the low-quality devices from affecting the learning efficiency and accuracy. Moreover, we propose an asynchronous advantage actor-critic (A3C) based joint device selection, UAVs placement, and resource management algorithm to enhance the federated convergence speed and accuracy. Simulation results demonstrate that our proposed framework and algorithm achieve higher learning accuracy and faster federated execution time compared to other existing solutions.},
keywords={Computational modeling;Servers;Wireless networks;Data models;Resource management;Training;Heuristic algorithms;Unmanned aerial vehicle;data sharing;asynchronous federated learning;scheduling;resource management;asynchronous advantage actor-critic},
doi={10.1109/JSAC.2021.3088655},
ISSN={1558-0008},
month={Oct},}
@INPROCEEDINGS{9491661,
author={Bouguettaya, Abdelmalek and Zarzour, Hafed and Kechida, Ahmed and Mohammed Taberkit, Amine},
booktitle={2021 International Conference on Information Technology (ICIT)}, title={Recent Advances on UAV and Deep Learning for Early Crop Diseases Identification: A Short Review},
year={2021},
volume={},
number={},
pages={334-339},
abstract={The different crop diseases are a serious threat resulting in significant yield losses, where their effective monitoring and accurate early identification techniques are considered crucial to ensure stable and reliable crop productivity and food security. The traditional methods often rely on human expert-based inspection of disease symptoms, which could be effective for small crop fields. However, they require a very long time and great physical effort to cover large crops resulting in very high miss detection rates. Recent innovative advances in remote sensing technologies and computer vision techniques are considered an effective way to solve such problems. To this end, in this paper, we focus on the recent advances in Unmanned Aerial Vehicle platforms and deep learning-based computer vision algorithms to identify crop diseases at their early stage to improve food production.},
keywords={Productivity;Deep learning;Computer vision;Agriculture;Unmanned aerial vehicles;Classification algorithms;Reliability;Crop Disease Detection;Unmanned Aerial Vehicles;Deep Learning;Food Security;Precision Agriculture},
doi={10.1109/ICIT52682.2021.9491661},
ISSN={},
month={July},}
@ARTICLE{9541164,
author={Jackson, Derek and Belakaria, Syrine and Cao, Yue and Doppa, Janardhan Rao and Lu, Xiaonan},
journal={IEEE Transactions on Transportation Electrification}, title={Machine Learning Enabled Design Automation and Multi-Objective Optimization for Electric Transportation Power Systems},
year={2021},
volume={},
number={},
pages={1-1},
abstract={This paper presents an automated design and optimization framework for electric transportation power systems (ETPS), enabled by machine learning (ML). The use of physical models, simulations, and optimization methods can greatly aid the engineering design process. However, when considering the optimal co-design of multiple inter-dependent subsystems that span multiple physical domains, such model-based simulations can be computationally expensive, and traditional metaheuristic optimization methods can be unreliable. Bayesian optimization (BO), a ML framework, paves one feasible pathway to realize an efficient design process practically. However, current state-of-the-art BO algorithms are non-compatible or perform poorly when applied to system-level ETPS design with multiple objectives and constraints. This paper proposes a novel BO algorithm referred to as Max-value Entropy Search for Multi-objective Optimization with Constraints (MESMOC) to solve multi-objective optimization (MOO) problems with black-box constraints that can only be evaluated through design simulations. After full presentation of the algorithm, MESMOC is applied to a realistic ETPS design case using a heavy-duty electric vertical-takeoff-landing (eVTOL) urban aerial vehicle (UAV) power system. Two MOO experimental trials show a drastic reduction in the number of design simulations to discover a high-quality Pareto front. In Trial 1, MESMOC uncovered the entire Pareto front while only requiring to explore ~4% of the design space. With expanded design parameters and a larger design space in Trial 2, a near-complete but high-quality Pareto front was uncovered. Both trials compared MESMOC to the popular genetic algorithm NSGA-II and another BO algorithm PESMOC, showing superior performance.},
keywords={Optimization;Computational modeling;Transportation;Mathematical model;Heuristic algorithms;Search problems;Machine learning;Electric Transportation;Power System Design;Model-based Design;Multi-Objective Optimization;Design Automation;Machine Learning;Bayesian Optimization;Aviation;UAV},
doi={10.1109/TTE.2021.3113958},
ISSN={2332-7782},
month={},}
@INPROCEEDINGS{8886040,
author={Rydén, Henrik and Redhwan, Sakib Bin and Lin, Xingqin},
booktitle={2019 IEEE Wireless Communications and Networking Conference (WCNC)}, title={Rogue Drone Detection: A Machine Learning Approach},
year={2019},
volume={},
number={},
pages={1-6},
abstract={The emerging, practical and observed issue of how to detect rogue drones carrying terrestrial user equipment (UE) on mobile networks is addressed in this paper. This issue has drawn much attention since the rogue drones may generate excessive interference to mobile networks and may not be allowed by regulations in some regions. In this paper, we propose a novel machine learning approach to identify the rogue drones in mobile networks based on radio measurements. We apply two classification machine learning models, Logistic Regression, and Decision Tree, using features from radio measurements to identify the rogue drones. Simulation results show that the proposed machine learning solutions can achieve high rogue drone detection rate for high altitudes while not mis-classifying regular ground based UEs as rogue drone UEs.},
keywords={Drones;Machine learning;Computational modeling;Predictive models;Training;Decision trees;Long Term Evolution;Drone;Unmanned aerial vehicle;Machine learning;Radio access network},
doi={10.1109/WCNC.2019.8886040},
ISSN={1558-2612},
month={April},}
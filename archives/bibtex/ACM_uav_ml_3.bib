@inproceedings{10.1145/3421558.3421571,
author = {Zhu, Kaojin and Han, Bing},
title = {MLEDet: Vehicle Detection in UAV Images},
year = {2020},
isbn = {9781450388412},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3421558.3421571},
doi = {10.1145/3421558.3421571},
abstract = {Unmanned Aerial Vehicles (UAV) have become popular in many applications. In this paper, we focus on the vehicle detection in UAV images. Compared with generic object detection, the vehicle detection in UAV images is more challenging, which contain a large amount of small objects and complex backgrounds. We propose E-Dnet by enhancing feature maps to obtain the semantic information of small objects. Multi-level feature maps are utilized to adapt various sizes of vehicles. Moreover, there is an inequality between confidence score and intersection-over-union. Then, IoU-Guided Loss is proposed to handle the inequality. In addition, we construct a vehicle detection dataset named VUVD, which is based on UAV images collected from various road conditions in the city. In particular, our method achieves start-of-the-art performance on our VUVD dataset and VisDrone2018-vehicle dataset.},
booktitle = {2020 2nd International Conference on Image Processing and Machine Vision},
pages = {79–86},
numpages = {8},
keywords = {Vehicle detection, Small objects, UAV images},
location = {Bangkok, Thailand},
series = {IPMV 2020}
}

@inproceedings{10.5555/3395101.3395114,
author = {Hadiwardoyo, Seilendria A. and Calafate, Carlos T. and Cano, Juan-Carlos and Krinkin, Kirill and Klionskiy, Dmitry and Hern\'{a}ndez-Orallo, Enrique and Manzoni, Pietro},
title = {Optimizing UAV-to-Car Communications in 3D Environments through Dynamic UAV Positioning},
year = {2019},
isbn = {9781728129235},
publisher = {IEEE Press},
abstract = {Unmanned Aerial Vehicles (UAVs) can act as relays in areas with limited infrastructure to support car-to-car communications. Prior studies on UAV-to-car communications showed that the irregularity of the terrains has a significant impact on link quality. Thus, in this paper, we propose a positioning technique that relies on Particle Swarm Optimization (PSO) to optimize the positioning of a UAV in the vehicular environment by considering the irregularities of the terrains that might hinder Line-of-Sight (LOS) conditions. The proposed technique takes into account the path loss caused by the terrains. Simulation results show that the optimization algorithm allows us to determine the best position for the deployed UAVs throughout time by considering the movement of the cars, and also accounting for adjustments in terms of flight altitude. In particular, the latter is adjusted by considering the position of the cars on the ground and the profile of surrounding terrains to determine potential communications blockages, while respecting international regulations regarding flight altitude restrictions.},
booktitle = {Proceedings of the 23rd IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
pages = {67–74},
numpages = {8},
keywords = {PSO, dynamic positioning, ITS, simulation, UAV},
location = {Cosenza, Italy},
series = {DS-RT '19}
}

@inproceedings{10.1145/3349801.3349809,
author = {Plastiras, George and Kyrkou, Christos and Theocharides, Theocharis},
title = {EdgeNet: Balancing Accuracy and Performance for Edge-Based Convolutional Neural Network Object Detectors},
year = {2019},
isbn = {9781450371896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3349801.3349809},
doi = {10.1145/3349801.3349809},
abstract = {Visual intelligence at the edge is becoming a growing necessity for low latency applications and situations where real-time decision is vital. Object detection, the first step in visual data analytics, has enjoyed significant improvements in terms of state-of-the-art accuracy due to the emergence of Convolutional Neural Networks (CNNs) and Deep Learning. However, such complex paradigms intrude increasing computational demands and hence prevent their deployment on resource-constrained devices. In this work, we propose a hierarchical framework that enables to detect objects in high-resolution video frames, and maintain the accuracy of state-of-the-art CNN-based object detectors while outperforming existing works in terms of processing speed when targeting a low-power embedded processor using an intelligent data reduction mechanism. Moreover, a use-case for pedestrian detection from Unmanned-Areal-Vehicle (UAV) is presented showing the impact that the proposed approach has on sensitivity, average processing time and power consumption when is implemented on different platforms. Using the proposed selection process our framework manages to reduce the processed data by 100x leading to under 4W power consumption on different edge devices.},
booktitle = {Proceedings of the 13th International Conference on Distributed Smart Cameras},
articleno = {8},
numpages = {6},
keywords = {Aerial Cameras, Convolutional Neural Networks, Object Detection, Pedestrian Detection},
location = {Trento, Italy},
series = {ICDSC 2019}
}

@inproceedings{10.1145/2756755.2756760,
author = {Pereira, Eloi and Krainer, Clemens and da Silva, Pedro Marques and Kirsch, Christoph M. and Sengupta, Raja},
title = {A Runtime System for Logical-Space Programming},
year = {2015},
isbn = {9781450335959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2756755.2756760},
doi = {10.1145/2756755.2756760},
abstract = {In this paper we introduce logical-space programming, a spatial computing paradigm where programs have access to a logical space model, i.e., names and explicit relations over such names, while the runtime system is in charge of manipulating the physical space. Mobile devices such as autonomous vehicles are equipped with sensors and actuators that provide means for computation to react upon spatial information and produce effects over the environment. The spatial behavior of these systems is commonly specified at the physical level, e.g., GPS coordinates. This puts the responsibility for the correct specification of spatial behaviors in the hands of the programmer. We propose a new paradigm named logical-space programming, where the programmer specifies the spatial behavior at a logical level while the runtime system is in charge of managing the physical behaviors. We provide a brief explanation of the logical-space computing semantics and describe a logical-space runtime system using bigraphs as logical models and bigActors as computing entities. The physical entities are modeled as polygons in a geometrical space. We demonstrate the use of logical-space programming for specifying and controlling the spatial behaviors of vehicles and sensors performing an environmental monitoring mission. The field test consisted of an Unmanned Aerial Vehicle and GPS drifters used to survey an area supposedly affected by illegal bilge dumping.},
booktitle = {Proceedings of the Second International Workshop on the Swarm at the Edge of the Cloud},
pages = {28–33},
numpages = {6},
keywords = {spatial computing, robotics, mobile},
location = {Seattle, Washington},
series = {SWEC '15}
}

@inproceedings{10.1145/3477084.3484952,
author = {Prathiba, Sahaya Beni and Raja, Gunasekaran and Anbalagan, Sudha and Narayanan, Renuka and Venkata Karthik, K. Bhavani},
title = {SOSChain: Self Optimizing Streamchain for Last-Mile 6G UAV-Truck Networks},
year = {2021},
isbn = {9781450387019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3477084.3484952},
doi = {10.1145/3477084.3484952},
abstract = {Global climate change has led to a steep rise in natural disasters. In these times, it is essential to provide emergency last-mile delivery to disaster-affected populations using connected delivery trucks; however, this gives rise to several challenges. There is an unpredictable demand for resources and the need for fault-tolerant path planning in case the trucks are subjected to attack or breakdowns. There is also the need to track resources to ensure no theft or maldistribution during critical situations. To achieve these objectives, we use a hybrid UAV-Truck architecture for last-mile relief distribution. To increase the delivery operation's robustness, we propose a Self-Optimizing StreamChain (SOSChain) that tracks and controls the status of trucks and their onboard resources. During failure scenarios, the use of information in the SOSChain enables other vehicles to optimally re-route and redistribute resources from damaged vehicles. Extensive simulation shows that SOSChain achieves over 25% improvement in throughput and up to 50% reduction in ordering latency compared to StreamChain approach in a simulated disaster environment with up to 50% vehicle failure rate.},
booktitle = {Proceedings of the 1st Workshop on Artificial Intelligence and Blockchain Technologies for Smart Cities with 6G},
pages = {19–24},
numpages = {6},
keywords = {blockchain, streamchain, deep reinforcement learning, 6G, last-mile relief},
location = {New Orleans, Louisiana},
series = {6G-ABS '21}
}

@inproceedings{10.1145/3331453.3362046,
author = {Li, Bo and Liang, Shiyang and Tian, Linyu and Chen, Daqing},
title = {Intelligent Aircraft Maneuvering Decision Based on CNN},
year = {2019},
isbn = {9781450362948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3331453.3362046},
doi = {10.1145/3331453.3362046},
abstract = {Aiming at the maneuvering decision of aircraft in air combat, an intelligent maneuvering decision model based on convolutional neural network(CNN) is proposed in this paper. Firstly, the situation data, maneuvering decision variables and evaluation indexs are given, and a CNN model that can realize intelligent maneuvering decision is established. Then, according to the evaluation indexes, the structure and parameters of the CNN model are adjusted through the simulation experiments to improve the accuracy and robustness of the maneuvering decision. After that, the validity of the intelligent maneuvering decision model proposed in this paper is verified through comparative experiments that the CNN model can make stable maneuvering decisions with high accuracy. Finally, the flight path in an air combat process is presented.},
booktitle = {Proceedings of the 3rd International Conference on Computer Science and Application Engineering},
articleno = {138},
numpages = {5},
keywords = {Intelligent air combat, Convolutional neural network, Maneuvering decision, Deep learning},
location = {Sanya, China},
series = {CSAE 2019}
}

@inproceedings{10.1145/2908961.2931679,
author = {Cekmez, Ugur and Ozsiginan, Mustafa and Sahingoz, Ozgur Koray},
title = {Multi-UAV Path Planning with Parallel Genetic Algorithms on CUDA Architecture},
year = {2016},
isbn = {9781450343237},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2908961.2931679},
doi = {10.1145/2908961.2931679},
abstract = {In recent years, the use of Unmanned Aerial Vehicles (UAVs) has grown quickly due to its low cost and easily programming for autonomous path following for accomplishing different types of missions. Due to the numerous advantages of multi-UAVs, when comparing with a single powerful one, to perform reconnaissance, monitoring, detection and surveying missions the use of multi-UAVs is generally preferred. While the number of control points and the number of UAVs are increased, the complexity of the problem also increases. This paper presents a solution to the problem of minimum time coverage of ground areas using a number of UAVs. The solution is divided into two parts: Firstly the area is partitioned with K-means clustering and then the problem is solved in each cluster with parallel genetic algorithm approach on CUDA architecture. To illustrate the methodology, the paper presents the experimental results obtained with a multi-UAV system, which has a different number of control points. The results showed the proposed approach produces efficient solutions for these type NP-Hard problems of homeland security applications like wide-area surveillance and site security by using multiple UAVs.},
booktitle = {Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion},
pages = {1079–1086},
numpages = {8},
keywords = {k-means clustering, parallel evolutionary algorithms, multi-uav path planning, 2-opt, genetic algorithms},
location = {Denver, Colorado, USA},
series = {GECCO '16 Companion}
}

@inbook{10.1145/3479243.3487300,
author = {Liu, Hantao and He, Ying and Yu, F. Richard and James, Jeremy},
title = {Flexi-Compression: A Flexible Model Compression Method for Autonomous Driving},
year = {2021},
isbn = {9781450390811},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3479243.3487300},
abstract = {Benefiting from the rapid development of convolutional neural networks, computer vision-based autonomous driving technologies are gradually being deployed in vehicles. However, these neural networks typically have a large number of parameters and extremely high computational cost, making them difficult to deploy in autonomous vehicles with limited storage and computational power. In this paper, we propose an innovative model compression approach to compress convolutional neural networks in autonomous driving algorithms, which we call Flexi-Compression. Flexi-Compression first modifies the model structure by replacing the traditional convolutional layers with our proposed Flexi-CP module, thus reducing the computation of the convolutional layers. Then, we leverage knowledge distillation to enable the compressed model to quickly acquire the knowledge of the original model. In addition, we use a Flexi-Batch Normalization layer to prune the model and finally further reduce the model size by model quantization. We compress the VGG-16 network using our proposed model compression algorithm, which is a commonly used backbone network in autonomous driving algorithms. On the CIFAR-10 dataset, our compression method can reduce the parameters of the VGG-16 network by 86% and the computation by 87% with 4% loss of accuracy. To verify the effectiveness of our compression algorithm in real-world applications, we also compress an autonomous driving algorithm and achieve excellent performance.},
booktitle = {Proceedings of the 11th ACM Symposium on Design and Analysis of Intelligent Vehicular Networks and Applications},
pages = {19–26},
numpages = {8}
}

@inproceedings{10.1145/3494885.3494947,
author = {Li, Linrun and Qin, Zhangjian and Zhang, Qin},
title = {Landslide Recognition Based on the Improved U-Net},
year = {2021},
isbn = {9781450390675},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3494885.3494947},
doi = {10.1145/3494885.3494947},
abstract = {Landslide is one of the most frequent geological disasters in the world, which causes a huge loss every year and seriously threatens the safety of people's life and property. Rapid and accurate landslide recognition can reduce losses and improve the efficiency of disaster prevention and mitigation. The traditional landslide recognition methods require a large amount of human and financial resources, which is extremely inefficient. In order to improve the recognition efficiency, this paper works out an improved U-net structure for automatic recognition of landslides. Parts of the feature extraction network of the original U-net structure are optimized into Resnet50 in the improved U-net structure, and an attention mechanism is added to enhance its ability to extract features, which significantly improves the accuracy of landslide recognition. The method in this paper is tested and verified on a large-scale landslide event in western Sichuan, China. The experimental results prove that the improved U-net structure increases the mIoU indicator to 80.66% and the mPA to 92.14%. Compared with the traditional method, the improved U-net model is able to recognize the landslide areas quickly and accurately, which proves its effectiveness and feasibility.},
booktitle = {2021 4th International Conference on Computer Science and Software Engineering (CSSE 2021)},
pages = {338–345},
numpages = {8},
keywords = {residual network, landslide recognition, attention mechanism, deep learning, remote sensing, U-net},
location = {Singapore, Singapore},
series = {CSSE 2021}
}

@inproceedings{10.1145/3501409.3501674,
author = {Chen, YunFei and Chen, Xingwu and Chen, Lingfeng and He, Dongwei and Zheng, Jishi and Xu, Chao and Lin, Yang and Liu, Lisang},
title = {UAV Lightweight Object Detection Based on the Improved YOLO Algorithm},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3501409.3501674},
doi = {10.1145/3501409.3501674},
abstract = {Aiming at the characteristics of small objects in low-altitude images, special shooting angles, and variable shooting angles of unmanned aerial vehicles (UAVs), this paper proposes a structural innovation based on the YOLOv5-MobileNetv3Small network model. It transplants the MobileNetv3 network structure and improves the BackBone network structure to solve the problem of inference high-pixel images taking up too much memory for low-power edge computing nodes. The improved YOLO algorithm uses the Visdrone2019-DET dataset to train the network model and uses the Jetson NX edge computing platform on the UAV to process 1920*1080 video streams for testing. The memory usage of the optimized YOLOv5-MobileNetv3Small network model can be reduced by 72.4%.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1502–1506},
numpages = {5},
keywords = {object detection, edge computing, lightweight, YOLO, UAV},
location = {Xiamen, China},
series = {EITCE 2021}
}

@article{10.1145/3464943,
author = {Boubrima, Ahmed and Knightly, Edward W.},
title = {Robust Environmental Sensing Using UAVs},
year = {2021},
issue_date = {November 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {2691-1914},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3464943},
doi = {10.1145/3464943},
abstract = {In this article, we first investigate the quality of aerial air pollution measurements and characterize the main error sources of drone-mounted gas sensors. To that end, we build ASTRO+, an aerial-ground pollution monitoring platform, and use it to collect a comprehensive dataset of both aerial and reference air pollution measurements. We show that the dynamic airflow caused by drones affects temperature and humidity levels of the ambient air, which then affect the measurement quality of gas sensors. Then, in the second part of this article, we leverage the effects of weather conditions on pollution measurements’ quality in order to design an unmanned aerial vehicle mission planning algorithm that adapts the trajectory of the drones while taking into account the quality of aerial measurements. We evaluate our mission planning approach based on a Volatile Organic Compound pollution dataset and show a high-performance improvement that is maintained even when pollution dynamics are high.},
journal = {ACM Trans. Internet Things},
month = {jul},
articleno = {25},
numpages = {20},
keywords = {experimental evaluation, air pollution mapping, Unmanned aerial vehicles (UAVs), multi-factor non-homogeneous sensing errors, robust mission planning}
}

@inproceedings{10.1145/3268866.3268886,
author = {Yeboah, Yao and Yanguang, Cai and Wu, Wei and He, Shuai},
title = {Autonomous Indoor Robot Navigation via Siamese Deep Convolutional Neural Network},
year = {2018},
isbn = {9781450365246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3268866.3268886},
doi = {10.1145/3268866.3268886},
abstract = {The vast majority of indoor navigation algorithms either rely on manual scene augmentation and labelling or exploit multi-sensor fusion techniques in achieving simultaneous localization and mapping (SLAM), leading to high computational costs, hardware complexities and robustness deficiencies. This paper proposes an efficient and robust deep learning-based indoor navigation framework for robots. Firstly, we put forward an end-to-end trainable siamese deep convolutional neural network (DCNN) which decomposes navigation into orientation and localization in one branch, while achieving semantic scene mapping in another. In mitigating the computational costs associated with DCNNs, the proposed model design shares a significant amount of convolutional operations between the two branches, streamlining the model and optimizing for efficiency in terms of memory and inference latency. Secondly, a transfer learning regime is explored in demonstrating how such siamese DCNNs can be efficiently trained for high convergence rates without extensive manual dataset labelling. The resulting siamese framework combines semantic scene understanding with orientation estimation towards predicting collision-free and optimal navigation paths. Experimental results demonstrate that the proposed framework achieves accurate and efficient navigation and outperforms existing "navigation-by-classification" variants.},
booktitle = {Proceedings of the 2018 International Conference on Artificial Intelligence and Pattern Recognition},
pages = {113–119},
numpages = {7},
keywords = {Semantic segmentation, Indoor navigation, Siamese network, Deep Convolutional Neural Networks (DCNN)},
location = {Beijing, China},
series = {AIPR 2018}
}

@inproceedings{10.1145/3443467.3443805,
author = {Lv, XiaoLi and Ni, HongXia},
title = {Smart Fault Detection and Monitoring of Power Line by Drones},
year = {2020},
isbn = {9781450387811},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3443467.3443805},
doi = {10.1145/3443467.3443805},
abstract = {In this paper, we introduce a novel automatic power line inspection system based on automatic vision. This system uses UAV inspection as the main inspection method, optical images as the main data source, and deep learning as the backbone of data analysis. To facilitate the implementation of the system, we solve three major challenges of deep learning in vision-based power line inspection: (i) lack of training data; (ii) class imbalance; (iii) detection of small parts and faults. First, we create four medium-sized datasets for training component detection and classification models. Next, we apply a series of effective data enhancement techniques to balance the unbalanced classes. Finally, we propose a multi-stage component detection and classification method based on a single-shot multi-box detector and a deep residual network to detect small components and faults. The results show that the proposed system can quickly and accurately detect common failures of power line components, including the lack of a top cover, cracks on the rod and cross arm, woodpecker damage to the rod, and rot on the cross arm. Field tests show that our system has broad prospects in the Smart monitoring and inspection of power line components and the valuable addition of smart grids.},
booktitle = {Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering},
pages = {501–505},
numpages = {5},
keywords = {vision-based power line inspection, deep learning, Drones, power line inspection, smart grids, Smart monitoring},
location = {Xiamen, China},
series = {EITCE 2020}
}

@inproceedings{10.1145/3341069.3342968,
author = {Liu, Chang and Xie, Wenjun and Zhang, Peng and Guo, Qing and Ding, Doujian},
title = {Multi-UAVs Cooperative Coverage Reconnaissance with Neural Network and Genetic Algorithm},
year = {2019},
isbn = {9781450371858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3341069.3342968},
doi = {10.1145/3341069.3342968},
abstract = {Aiming at the problem of multi-UAVs cooperative coverage reconnaissance mission planning, a planning method combining neural network and genetic algorithm is proposed. Firstly, the relative position relationship between multiple UAVs, the position relationship between each UAV and the boundary of the target area and the motion performance of each UAV are taken as inputs of the neural network, and the output is rough path of each UAV. Then, the weights and thresholds of neural network are optimized by using genetic algorithm, and the optimal paths of multi-UAVs cooperative regional reconnaissance is solved. The simulation results show that the method can not only enable UAVs to learn reconnaissance rules autonomously, but also plan the cooperative reconnaissance paths of each UAV, achieve effective coverage of the target area, and have good reconnaissance efficiency.},
booktitle = {Proceedings of the 2019 3rd High Performance Computing and Cluster Technologies Conference},
pages = {81–86},
numpages = {6},
keywords = {genetic algorithm, cooperation, UAV, neural network, mission planning},
location = {Guangzhou, China},
series = {HPCCT 2019}
}

@inproceedings{10.5555/3451906.3451932,
author = {Wubben, Jamie and Aznar, Pablo and Fabra, Francisco and Calafate, Carlos T. and Cano, Juan-Carlos and Manzoni, Pietro},
title = {Toward Secure, Efficient, and Seamless Reconfiguration of UAV Swarm Formations},
year = {2020},
publisher = {IEEE Press},
abstract = {Unmanned Aerial vehicles (UAVs) have gained a lot of interest over the last years due to the many fields of potential application. Nowadays, researchers are becoming interested in groups of UAVs working together. The collaborations between UAVs open a wide field of opportunities, because they are typically able to do more sophisticated tasks than a single UAV. However, collaboration between multiple UAVs is still a complex task, and significant challenges need to be addressed before their mainstream adoption. For instance, the automatic reconfiguration of a swarm can be used to adapt the swarm to changing application demands to solve a task in a more efficient and effective manner. However, the chances of collision become high if reconfiguration is not carefully planned. In this work we propose an approach to allow changing the shape of a UAV formation during flight through a computational inexpensive method that is able to decrease collision chances significantly. During the experiments we tested different reconfiguration events that are prone to collisions. Results have shown that our approach maintains a safe distance (greater than 5 meters) between the UAVs, while keeping the time overhead limited to a few tenths of a second. Furthermore, scalability tests have proven that our approach can handle the reconfiguration of at least 25 UAVs simultaneously.},
booktitle = {Proceedings of the IEEE/ACM 24th International Symposium on Distributed Simulation and Real Time Applications},
pages = {175–181},
numpages = {7},
keywords = {swarm formations, swarm reconfiguration, UAV},
location = {Prague, Czech Republic},
series = {DS-RT '20}
}

@article{10.1109/TNET.2021.3051663,
author = {Bae, Jeongmin and Lee, Joohyun and Chong, Song},
title = {Learning to Schedule Network Resources Throughput and Delay Optimally Using Q<sup>+</sup>-Learning},
year = {2021},
issue_date = {April 2021},
publisher = {IEEE Press},
volume = {29},
number = {2},
issn = {1063-6692},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/TNET.2021.3051663},
doi = {10.1109/TNET.2021.3051663},
abstract = {As network architecture becomes complex and the user requirement gets diverse, the role of efficient network resource management becomes more important. However, existing throughput-optimal scheduling algorithms such as the max-weight algorithm suffer from poor delay performance. In this paper, we present reinforcement learning-based network scheduling algorithms for a single-hop downlink scenario which achieve throughput-optimality and converge to minimal delay. To this end, we first formulate the network optimization problem as a Markov decision process (MDP) problem. Then, we introduce a new state-action value function called <inline-formula> <tex-math notation="LaTeX">$Q^{+}$ </tex-math></inline-formula><italic>-function</italic> and develop a reinforcement learning algorithm called <inline-formula> <tex-math notation="LaTeX">$Q^{+}$ </tex-math></inline-formula> <italic>-learning</italic> with UCB (Upper Confidence Bound) exploration which guarantees small performance loss during a learning process. We also derive an upper bound of the sample complexity in our algorithm, which is more efficient than the best known bound from Q-learning with UCB exploration by a factor of <inline-formula> <tex-math notation="LaTeX">$gamma ^{2}$ </tex-math></inline-formula> where <inline-formula> <tex-math notation="LaTeX">$gamma $ </tex-math></inline-formula> is the discount factor of the MDP problem. Finally, via simulation, we verify that our algorithm shows a delay reduction of up to 40.8% compared to the max-weight algorithm over various scenarios. We also show that the Q<sup>+</sup>-learning with UCB exploration converges to an <inline-formula> <tex-math notation="LaTeX">$epsilon $ </tex-math></inline-formula>-optimal policy 10 times faster than Q-learning with UCB.},
journal = {IEEE/ACM Trans. Netw.},
month = {apr},
pages = {750–763},
numpages = {14}
}

@inproceedings{10.5555/3320516.3320691,
author = {Blasch, Erik},
title = {DDDAS Advantages from High-Dimensional Simulation},
year = {2018},
isbn = {978153866570},
publisher = {IEEE Press},
abstract = {Dynamic Data Driven Applications Systems (DDDAS) is a systems design framework that focuses on integrating high-dimensional physical model simulations, run-time measurements, statistical methods, and computation architectures. One of the foremost DDDAS successes was scientific theory assessment of natural disasters such as wild fire monitoring and volcanic plume detection. Monitoring the atmosphere with DDDAS principles has evolved into domain methods for space awareness, unmanned aerial vehicle (UAV) design, and biomedical applications. Recent efforts reflect the digital age of information management architecture design such as multimedia analysis, power grid control, and biohealth concerns. Underlying a majority of DDDAS developments are advances in sensor design, information filtering, and computational systems. The paper provides a motivation, explanation, and literature review of DDDAS.},
booktitle = {Proceedings of the 2018 Winter Simulation Conference},
pages = {1418–1429},
numpages = {12},
location = {Gothenburg, Sweden},
series = {WSC '18}
}

@article{10.1145/3382756,
author = {Faraci, Giuseppe and Grasso, Christian and Schembra, Giovanni},
title = {Fog in the Clouds: UAVs to Provide Edge Computing to IoT Devices},
year = {2020},
issue_date = {August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {3},
issn = {1533-5399},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3382756},
doi = {10.1145/3382756},
abstract = {Internet of Things (IoT) has emerged as a huge paradigm shift by connecting a versatile and massive collection of smart objects to the Internet, coming to play an important role in our daily lives. Data produced by IoT devices can generate a number of computational tasks that cannot be executed locally on the IoT devices. The most common solution is offloading these tasks to external devices with higher computational and storage capabilities, usually provided by centralized servers in remote clouds or on the edge by using the fog computing paradigm. Nevertheless, in some IoT scenarios there are remote or challenging areas where it is difficult to connect an IoT network to a fog platform with appropriate links, especially if IoT devices produce a lot of data that require processing in real-time. To this purpose, in this article, we propose to use unmanned aerial vehicles (UAVs) as fog nodes. Although this idea is not new, this is the first work that considers power consumption of the computing element installed on board UAVs, which is crucial, since it may influence flight mission duration. A System Controller (SC) is in charge of deciding the number of active CPUs at runtime by maximizing an objective function weighing power consumption, job loss probability, and processing latency. Reinforcement Learning (RL) is used to support SC in its decisions. A numerical analysis is carried out in a use case to show how to use the model introduced in the article to decide the computation power of the computing element in terms of number of available CPUs and CPU clock speed, and evaluate the achieved performance gain of the proposed framework.},
journal = {ACM Trans. Internet Technol.},
month = {aug},
articleno = {26},
numpages = {26},
keywords = {Reinforcement Learning, fog computing, performance evaluation, Internet of Things, energy efficiency}
}

@inproceedings{10.1145/3341620.3341628,
author = {Bi, Haixia and Xue, Yong and Merritt, Patrick and Windmill, Chris and Davis, Bradley},
title = {A Heterogeneous and Interactive Big Earth Data Framework},
year = {2019},
isbn = {9781450360913},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3341620.3341628},
doi = {10.1145/3341620.3341628},
abstract = {The dramatic development of Earth observation techniques leads to an explosion of Earth data. However, the increase of the Earth data size and their heterogeneity bring significant challenges to the storage, processing and visualization of the big Earth data. To address the problems caused by the huge Earth data-sets, a heterogeneous and interactive big Earth data framework is proposed in this paper, integrating raster-vector data cloud storage, data processing based on workflow and machine learning techniques and real-time rendering and interactive visualization. The framework provides a theoretical reference for future implementations of the system.},
booktitle = {Proceedings of the 2019 International Conference on Big Data Engineering},
pages = {85–91},
numpages = {7},
keywords = {interactive data visualization, workow, heterogeneous data storage, Big Earth data, machine learning},
location = {Hong Kong, Hong Kong},
series = {BDE 2019}
}

@article{10.1145/3308897.3308964,
author = {Li, Rui and Zhang, Chaoyun and Patras, Paul and Stanica, Razvan and Valois, Fabrice},
title = {Learning Driven Mobility Control of Airborne Base Stations in Emergency Networks},
year = {2019},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {3},
issn = {0163-5999},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3308897.3308964},
doi = {10.1145/3308897.3308964},
abstract = {Mobile base stations mounted on unmanned aerial vehicles (UAVs) provide viable wireless coverage solutions in challenging landscapes and conditions, where cellular/WiFi infrastructure is unavailable. Operating multiple such airborne base stations, to ensure reliable user connectivity, demands intelligent control of UAV movements, as poor signal strength and user outage can be catastrophic to mission critical scenarios. In this paper, we propose a deep reinforcement learning based solution to tackle the challenges of base stations mobility control. We design an Asynchronous Advantage Actor-Critic (A3C) algorithm that employs a custom reward function, which incorporates SINR and outage events information, and seeks to provide mobile user coverage with the highest possible signal quality. Preliminary results reveal that our solution converges after 4\texttimes{}105 steps of training, after which it outperforms a benchmark gradientbased alternative, as we attain 5dB higher median SINR during an entire test mission of 10,000 steps.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jan},
pages = {163–166},
numpages = {4},
keywords = {mobility control, emergency networks, airborne base stations, ai in networks, deep reinforcement learning}
}

@inproceedings{10.1145/3441110.3441149,
author = {Stabernack, Benno and Steinert, Fritjof},
title = {Architecture of a Low Latency H.264/AVC Video Codec for Robust ML Based Image Classification},
year = {2021},
isbn = {9781450389013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3441110.3441149},
doi = {10.1145/3441110.3441149},
abstract = { The use of neural networks represents the state of the art in the area of image classification. A large number of different networks are available for this purpose, which, appropriately trained, permit a high level of classification accuracy. Typically, these networks are applied to uncompressed image data, since a corresponding training was also carried out using image data of similar high quality. However, if image data contains image errors, the classification accuracy generally deteriorates drastically. This applies in particular to coding artifacts that arise from image and video compression. Typical application scenarios for this are narrowband transmission channels for which video coding is required but a subsequent classification is to be carried out on the receiver side. In this paper we present a special H.264/AVC-based video codec that allows certain regions of a picture to be coded with constant picture quality in order to allow a stable and robust classification using neural networks, whereas the remaining image regions will be coded using constant bit rate. We have combined this feature with the ability to run with lowest latency properties, which is usually also required in remote control applications scenarios. The codec has been implemented as a fully hardwired HD capable hardware architecture which is suitable for Field Programmable Gate Arrays.},
booktitle = {Workshop on Design and Architectures for Signal and Image Processing (14th Edition)},
pages = {1–9},
numpages = {9},
keywords = {ROI, AVC, Codec, H.264, FPGA, Machine Learning, Inference, Low Latency},
location = {Budapest, Hungary},
series = {DASIP '21}
}

@inproceedings{10.1145/3444370.3444592,
author = {Tong, Yingyi and Dong, Wenhan and Zhai, Chenfei},
title = {Multi-UAV Collaborative Online Obstacle Avoidance Track Planning},
year = {2020},
isbn = {9781450387828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3444370.3444592},
doi = {10.1145/3444370.3444592},
abstract = {Aiming at the problem of online cooperative flight trajectory planning for multiple UAVs, a curvilinear trajectory planning method based on velocity obstacle method is proposed. The three-dimensional model of mission planning battlefield is established by using satellite elevation data. An improved Pythagorean Hodograph (PH) curve trajectory planning method is proposed for the problem of curvature constraint in UAV track planning. By introducing the adaptive chaos optimization strategy into the estimation distribution algorithm, an estimation distribution algorithm based on adaptive chaos optimization (AC-EDA) is presented to avoid blind trial and error of curve programming parameters. The improved particle sedimentation method is used to extend the two-dimensional trajectory to three-dimensional space, and the principle of the velocity obstacle method is combined with the PH curve planning method to find a suitable insertion point when facing the threat of a dynamic target, and realize the combination of curved trajectory planning and obstacle avoidance behavior.},
booktitle = {Proceedings of the 2020 International Conference on Cyberspace Innovation of Advanced Technologies},
pages = {324–329},
numpages = {6},
keywords = {Obstacle Avoidance, Speed obstacle method, Pythagorean Hodograph curve method, Trajectory planning},
location = {Guangzhou, China},
series = {CIAT 2020}
}

@inproceedings{10.1145/3289602.3293915,
author = {Chen, Yao and He, Jiong and Zhang, Xiaofan and Hao, Cong and Chen, Deming},
title = {Cloud-DNN: An Open Framework for Mapping DNN Models to Cloud FPGAs},
year = {2019},
isbn = {9781450361378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3289602.3293915},
doi = {10.1145/3289602.3293915},
abstract = {The efficacy and effectiveness of Convolutional Neural Networks (CNNs) have been proven in a wide range of machine learning applications. However, the high computational complexity of CNNs presents a critical challenge towards their broader adoption in real-time and power-efficient scenarios. FPGAs are poised to take a significant role for high-performance and energy-efficient computation of CNNs for both mobile (e.g., UAVs, self-driving cars, and IoT devices) and cloud computing domains. However, implementing an effective CNN system onto FPGAs efficiently remains problematic. The current cloud-based FPGAs with unique design constraints and architectural characteristics further increase the challenges. To address these challenges, we propose a novel open-source automated tool chain called Cloud-DNN. Our tool chain takes trained CNN models specified in Caffe as input, performs a set of transformations, and maps the model to a cloud-based FPGA. Cloud-DNN can significantly improve the overall design productivity of CNNs on FPGAs while satisfying the emergent computational requirements. Our design provides an alternative solution compared to other cloud-based options (e.g., GPUs or TPUs) while offering flexible, and high performance DNN inferences. The unique features of Cloud-DNN include the optimizations with cloud-platform characteristics and the support of easier and streamlined implementation. Experimental results demonstrate up to 104.55x performance improvement when compared to CPU implementation and comparable usability, flexibility, and strong quality compared to other state-of-the-art DNN inference implementations on standalone FPGAs.},
booktitle = {Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
pages = {73–82},
numpages = {10},
keywords = {reconfiguration, high-level synthesis, dnn accelerator, cloud computing, fpga, neural network},
location = {Seaside, CA, USA},
series = {FPGA '19}
}

@article{10.1145/3360050,
author = {Grigorev, Aleksei and Liu, Shaohui and Tian, Zhihong and Xiong, Jianxin and Rho, Seungmin and Feng, Jiang},
title = {Delving Deeper in Drone-Based Person Re-Id by Employing Deep Decision Forest and Attributes Fusion},
year = {2020},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1s},
issn = {1551-6857},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3360050},
doi = {10.1145/3360050},
abstract = {Deep learning has revolutionized the field of computer vision and image processing. Its ability to extract the compact image representation has taken the person re-identification (re-id) problem to a new level. However, in most cases, researchers are focused on developing new approaches to extract more fruitful image representation and use it in the re-id task. The extra information about images is rarely taken into account because the traditional person re-id datasets usually do not have it. Nevertheless, the research in multimodal machine learning has demonstrated that the utilization of the information from different sources leads to better performance. In this work, we demonstrate how a person re-id problem can benefit from the utilization of multimodal data. We have used the UAV drone to collect and label the new person re-id dataset, which is composed of pedestrian images and its attributes. We have manually annotated this dataset with attributes, and in contrast to the recent research, we do not use the deep network to classify them. Instead, we employ the continuous bag-of-words model to extract the word embeddings from text descriptions and fuse it with features extracted from images. Then the deep neural decision forest is used for pedestrians classification. The extensive experiments on the collected dataset demonstrate the effectiveness of the proposed model.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = {apr},
articleno = {25},
numpages = {15},
keywords = {re-id, drones, CBOW, neural networks, attributes, neural decision forest, Datasets, word2vec}
}

@inbook{10.1145/3457388.3458809,
author = {Lin, Na and Zhao, Qi and Zhao, Liang},
title = {Intelligent UAV-Aided Controller Placement Scheme for Software-Defined Vehicular Networks},
year = {2021},
isbn = {9781450384049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3457388.3458809},
abstract = {Recently, researchers have used long short-term memory (LSTM) networks and the bi-directional long short-term memory (Bi-LSTM) networks to process sequence data sets such as vehicle positions in software-defined vehicular networks (SDVN). In this paper, we present a three-component intelligent UAV-aided controller placement scheme (CPP) for SDVN. First, we use Bi-LSTM to model the real-time position of vehicles (traffic flow). Second, we implement a dynamic scheme to place controllers and UAVs (DCUPE) in the network based on the predicted flow. Third, in order to collect real-time traffic information and manage the network, we compute trajectories for the UAVs from real-time Bi-LSTM predictions of vehicle positions and an adaptive artificial bee colony algorithm for the traveling salesman problem (IDABC-TSP). We evaluate our proposed design as a function of energy cost, communication delay, and packet delivery ratio. Our experimental results show the effectiveness of our scheme on real geographical topologies.},
booktitle = {Proceedings of the 18th ACM International Conference on Computing Frontiers},
pages = {38–44},
numpages = {7}
}

@inproceedings{10.1145/3264746.3264791,
author = {Suh, Sae-Han and Jhang, Ji-Eun and Won, Kwanghee and Shin, Sung-Y. and Sung, Chang Oan},
title = {Development of Vegetation Mapping with Deep Convolutional Neural Network},
year = {2018},
isbn = {9781450358859},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3264746.3264791},
doi = {10.1145/3264746.3264791},
abstract = {The Precision Agriculture (PA) plays a crucial part in the agricultural industry about improving the decision-making process. It aims to optimally allocate the resources to maintain the sustainable productivity of farmland and reduce the use of chemical compounds. [17] However, the on-site inspection of vegetations often falls to researchers' trained eye and experience, when it deals with the identification of the non-crop vegetations. Deep Convolution Neural Network (CNN) can be deployed to mitigate the cost of manual classification. Although CNN outperforms the other traditional classifiers, such as Support Vector Machine, it is still in question whether CNN can be deployable in an industrial environment. In this paper, we conducted a study on the feasibility of CNN for Vegetation Mapping on lawn inspection for weeds. We would like to study the possibility of expanding the concept to the on-site, near realtime, crop site inspections, by evaluating the generated results.},
booktitle = {Proceedings of the 2018 Conference on Research in Adaptive and Convergent Systems},
pages = {53–58},
numpages = {6},
keywords = {residual network (ResNet), object classification, convolutional neural network (CNN), remote-sensing (RS), precision agriculture (PA), visual geometry group (VGG), computer vision (CV)},
location = {Honolulu, Hawaii},
series = {RACS '18}
}

@inproceedings{10.1145/3349341.3349462,
author = {Hu, Xiaodong and Zhang, Peng and Xiao, Yi},
title = {Military Object Detection Based on Optimal Gabor Filtering and Deep Feature Pyramid Network},
year = {2019},
isbn = {9781450371506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3349341.3349462},
doi = {10.1145/3349341.3349462},
abstract = {Military object detection technology plays an important role in realizing the informatization and intelligence of military equipment, but the complex environment and scarce sample data of military objects also become the difficulties of detection. This paper proposes a detection framework of military objects based on optimal Gabor filtering and deep feature pyramid networks. At first, we combine the texture characteristics of military objects with the requirements of detection tasks and proposed the Fine Region Proposal Network (FRPN). A set of Gabor filter is designed and screened in this scheme, we construct the optimal Gabor filter Banks by analyzing the image energy after Gabor transformation of some images in the dataset, shorting the time of feature extraction and reducing the amount of calculation. Then, the Renyi threshold segmentation method is adopted to obtain the region proposals. Finally, the Highly Utilized Feature Pyramid Networks (HU-FPN) is proposed to improve the detection effect of small objects. A bottom-up and a top-down feature pyramid is constructed in the stage. Through transverse connection and integration of features at various scales, the feature expression of small objects is enriched and the detection problem of small objects is effectively solved. The experimental results show that the method proposed in this paper has prominent advantages in accuracy, effectiveness and small object detection when compared with the state-of-the-art method, which can create good conditions for the realization of rapid and accurate detection of military objects and precise strike under military background.},
booktitle = {Proceedings of the 2019 International Conference on Artificial Intelligence and Computer Science},
pages = {524–530},
numpages = {7},
keywords = {Deep Learning, Feature Extraction, Gabor Filter, Military Object, Feature Pyramid},
location = {Wuhan, Hubei, China},
series = {AICS 2019}
}

@inproceedings{10.1145/3301293.3302365,
author = {George, Shilpa and Wang, Junjue and Bala, Mihir and Eiszler, Thomas and Pillai, Padmanabhan and Satyanarayanan, Mahadev},
title = {Towards Drone-Sourced Live Video Analytics for the Construction Industry},
year = {2019},
isbn = {9781450362733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3301293.3302365},
doi = {10.1145/3301293.3302365},
abstract = {This paper investigates the use of drones for live inspection in the construction industry. The key technical challenge is the real-time registration of the drone video feed to the architectural plan. We present and evaluate three different approaches for registration and propose an edge-based prototype using visual features. Our evaluations show that GPS alone is not sufficient for accurate registration, but with visual features, accuracies within ten centimeters can be achieved.},
booktitle = {Proceedings of the 20th International Workshop on Mobile Computing Systems and Applications},
pages = {3–8},
numpages = {6},
keywords = {unmanned aerial vehicle, computer vision, drone, image registration, image localization, edge computing, mobile computing},
location = {Santa Cruz, CA, USA},
series = {HotMobile '19}
}

@inproceedings{10.1145/3038884.3038891,
author = {Elhamer, Zineb and Meftah, Boudjelal},
title = {Aggregation as a Simple Seed for Collective Decision},
year = {2016},
isbn = {9781450348768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3038884.3038891},
doi = {10.1145/3038884.3038891},
abstract = {For Artificial Intelligence, nature is offering abundant sources of inspiration in the form of collective behaviours, performed by myriads of living creatures, ranging from the microscopic bacteria, to the macroscopic herds of mammals, schools of fish and bird flocks, not to mention social insects, from which the newly established field of Swarm Intelligence borrows it's name.Decentralized animal collectives rely in their decision-making mechanisms on self-organizing principles which they have their applications into the control and optimization mechanisms in Computer Science; They foster the design of newly robust and adaptive optimization and coordination algorithms of multi-agent systems.The goal of this work is to investigate a self-organising behaviour attributed to cockroaches, called aggregation and ascertain through computer simulations whether aggregation can lead the group of cockroaches to collectively choose a shelter among more than two shelters. Garnier et al. [7] had carried a similar work with two aggregation shelters only. In this paper, we investigate the aggregation behaviour based on the hybrid model and ascertain through simulations whether it can lead the group of cockroaches to collectively choose a shelter among more than two shelters.Simulations are based on a hybrid model of two previously and separately devised self-organizing models, which are: Jeanson et al.[2] behavioural model that describes the individual behaviours of cockroaches in a stochastic framework and Couzin et al.[4] model on animal's movements in a three-dimensional space.},
booktitle = {Proceedings of the Mediterranean Conference on Pattern Recognition and Artificial Intelligence},
pages = {39–43},
numpages = {5},
keywords = {collective decision-making, collective intelligence, Self-Organisation, aggregation, decentralised control, swarm intelligence},
location = {Tebessa, Algeria},
series = {MedPRAI-2016}
}

@inproceedings{10.1145/3368756.3369085,
author = {Priya, M. Deva and Balamurugan, A. and Dhivyaprabha, E. and Vignesh, R. and Varthan, L. R. Vishnu},
title = {Intelligent Navigation System for Emergency Vehicles},
year = {2019},
isbn = {9781450362894},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3368756.3369085},
doi = {10.1145/3368756.3369085},
abstract = {Self-Driving Vehicle (SDV) is a promising technology that will establish its predominance in the near future. As the vehicles are autonomous, humans will experience a hassle-free travel. Autonomy abolishes disasters due to driver's negligence. The main challenge is to provide an unobstructed path to Emergency Vehicles (EVs). In this paper, the EVs are identified using Deep Learning (DL) based algorithms. Though they are driven by Neural Networks (NNs), there are some situations in which they have to mimic a human. SDVs should be incorporated with the knowledge of a fast approaching EV. The ability to perceive and respond is addressed in this paper.},
booktitle = {Proceedings of the 4th International Conference on Smart City Applications},
articleno = {98},
numpages = {8},
keywords = {convolutional neural network (CNN), self-driving vehicle (SDV), fast region-based convolutional network method (fast R-CNN), emergency vehicle (EV)},
location = {Casablanca, Morocco},
series = {SCA '19}
}

@inproceedings{10.1145/3377930.3389843,
author = {Qiu, Huanneng and Garratt, Matthew and Howard, David and Anavatti, Sreenatha},
title = {Towards Crossing the Reality Gap with Evolved Plastic Neurocontrollers},
year = {2020},
isbn = {9781450371285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3377930.3389843},
doi = {10.1145/3377930.3389843},
abstract = {A critical issue in evolutionary robotics is the transfer of controllers learned in simulation to reality. This is especially the case for small Unmanned Aerial Vehicles (UAVs), as the platforms are highly dynamic and susceptible to breakage. Previous approaches often require simulation models with a high level of accuracy, otherwise significant errors may arise when the well-designed controller is being deployed onto the targeted platform. Here we try to overcome the transfer problem from a different perspective, by designing a spiking neurocontroller which uses synaptic plasticity to cross the reality gap via online adaptation. Through a set of experiments we show that the evolved plastic spiking controller can maintain its functionality by self-adapting to model changes that take place after evolutionary training, and consequently exhibit better performance than its non-plastic counterpart.},
booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference},
pages = {130–138},
numpages = {9},
keywords = {neuroevolution, hebbian plasticity, evolutionary robotics, spiking neural networks, UAV control},
location = {Canc\'{u}n, Mexico},
series = {GECCO '20}
}

@inbook{10.1145/3411764.3445115,
author = {Moon, Hee-Seung and Seo, Jiwon},
title = {Optimal Action-Based or User Prediction-Based Haptic Guidance: Can You Do Even Better?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3411764.3445115},
abstract = { The recently advanced robotics technology enables robots to assist users in their daily lives. Haptic guidance (HG) improves users’ task performance through physical interaction between robots and users. It can be classified into optimal action-based HG (OAHG), which assists users with an optimal action, and user prediction-based HG (UPHG), which assists users with their next predicted action. This study aims to understand the difference between OAHG and UPHG and propose a combined HG (CombHG) that achieves optimal performance by complementing each HG type, which has important implications for HG design. We propose implementation methods for each HG type using deep learning-based approaches. A user study (n=20) in a haptic task environment indicated that UPHG induces better subjective evaluations, such as naturalness and comfort, than OAHG. In addition, the CombHG that we proposed further decreases the disagreement between the user intention and HG, without reducing the objective and subjective scores.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {281},
numpages = {12}
}

@article{10.1145/3373647,
author = {Huang, Xiaohui and He, Pan and Rangarajan, Anand and Ranka, Sanjay},
title = {Intelligent Intersection: Two-Stream Convolutional Networks for Real-Time Near-Accident Detection in Traffic Video},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
issn = {2374-0353},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3373647},
doi = {10.1145/3373647},
abstract = {Camera-based systems are increasingly used for collecting information on intersections and arterials. Unlike loop controllers that can generally be only used for detection and movement of vehicles, cameras can provide rich information about the traffic behavior. Vision-based frameworks for multiple-object detection, object tracking, and near-miss detection have been developed to derive this information. However, much of this work currently addresses processing videos offline. In this article, we propose an integrated two-stream convolutional networks architecture that performs real-time detection, tracking, and near-accident detection of road users in traffic video data. The two-stream model consists of a spatial stream network for object detection and a temporal stream network to leverage motion features for multiple-object tracking. We detect near-accidents by incorporating appearance features and motion features from these two networks. Further, we demonstrate that our approaches can be executed in real-time and at a frame rate that is higher than the video frame rate on a variety of videos collected from fisheye and overhead cameras.},
journal = {ACM Trans. Spatial Algorithms Syst.},
month = {jan},
articleno = {10},
numpages = {28},
keywords = {convolutional neural networks, Intelligent transportation systems, ITS, near-accident detection, multiple-object tracking}
}

@inproceedings{10.5555/3408352.3408479,
author = {Carre\'{o}n, Nadir A. and Gilbreath, Allison and Lysecky, Roman},
title = {Statistical Time-Based Intrusion Detection in Embedded Systems},
year = {2020},
isbn = {9783981926347},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {This paper presents a statistical method based on cumulative distribution functions (CDF) to analyze an embedded system's behavior to detect anomalous and malicious executions behaviors. The proposed method analyzes the internal timing of the system by monitoring individual operations and sequences of operations, wherein the timing of operations is decomposed into multiple timing subcomponents. Creating the normal model of the system utilizing the internal timing adds resilience to zero-day attacks, and mimicry malware. The combination of CDF-based statistical analysis and timing subcomponents enable both higher detection rates and lower false positives rates. We demonstrate the effectiveness of the approach and compare to several state-of-the-art malware detection methods using two embedded systems benchmarks, namely a network connected pacemaker and an unmanned aerial vehicle, utilizing seven different malware.},
booktitle = {Proceedings of the 23rd Conference on Design, Automation and Test in Europe},
pages = {562–567},
numpages = {6},
keywords = {anomaly-based detection, embedded systems security, runtime intrusion detection, timing-based detection},
location = {Grenoble, France},
series = {DATE '20}
}

@inproceedings{10.5555/3213227.3213228,
author = {ZHOU, Xin and Wang, Weiping and Wang, Tao and Li, Xiaobo},
title = {Patrolling Task Planning for the Multi-Layer Multi-Agent System Based on Sequential Allocation Method},
year = {2018},
isbn = {9781510860179},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {The unmanned aerial vehicle (UAV) swarm has developed rapidly in recent years, especially the UAV swarm with sensors which is becoming common means of achieving situational awareness. In this paper, we develop a scalable, online and myopic algorithm for the multi-layer multi-agent system continuously patrolling problem. The main goal of the multi-agent system is to collect information as much as possible. We formulate this problem as Partially Observable Markov Decision Process (POMDP). The algorithm includes information dimensionality reduction representation, inter-layer information interaction, online heuristic function and sequential allocation method, which effectively improve the collected information and reduces the computational complexity. In addition, as the layer increases, this algorithm can guarantee the patrolling performance of the multi-agent system without increasing the computational complexity for each sub-leader. Finally, the empirical analysis shows that our algorithm has many advantages, which has theoretical and practical significance.},
booktitle = {Proceedings of the Symposium on Modeling and Simulation of Complexity in Intelligent, Adaptive and Autonomous Systems},
articleno = {1},
numpages = {12},
keywords = {information dimensionality reduction representation, online heuristic function, POMDP, multi-agent system, sequential allocation method},
location = {Baltimore, Maryland},
series = {MSCIAAS '18}
}

@inproceedings{10.1145/3487075.3487143,
author = {Xu, Shicheng and Liu, Sihan and He, Guangyu},
title = {A Method of Federated Learning Based on Blockchain},
year = {2021},
isbn = {9781450389853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3487075.3487143},
doi = {10.1145/3487075.3487143},
abstract = {Currently many enterprises face issues regarding insufficient data collection samples and data recording dimensions, thus it's hard to make efficient predictions. Since it is limited by the requirement of protecting privacy and trade secrets, data can't be effectively shared among enterprises. Federated learning is an effective method to solve this problem, but there are some performance bottlenecks, information security issues and data trust issues still existed, which need to be improved in combination with other advanced technologies to meet the practical requirements. This paper combines the blockchain technology with federated learning technology, and uses decentralized blockchain system to replace the traditional centralized federated learning architecture. We adopt training method of updating models to achieve machine learning. In this way, we can avoid transmission of intermediate computing data and achieve mechanism of node access, model evaluation, motivation and audit with combination of block chain. In terms of the algorithm, the horizontal federated learning adopts the integrated learning algorithm, and the vertical federated learning adopts the deep learning algorithm. It will be described in detail below.},
booktitle = {The 5th International Conference on Computer Science and Application Engineering},
articleno = {68},
numpages = {8},
keywords = {Machine learning, Federated learning, Random forest, Neural network, Blockchain},
location = {Sanya, China},
series = {CSAE 2021}
}

@inproceedings{10.1145/3446999.3447023,
author = {Liu, Yuanzhu and Ding, Zhiming and Cao, Yang and Chang, Mengmeng},
title = {Multi-Scale Feature Fusion UAV Image Object Detection Method Based on Dilated Convolution and Attention Mechanism},
year = {2020},
isbn = {9781450388559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3446999.3447023},
doi = {10.1145/3446999.3447023},
abstract = {Due to the influence of the shooting angle of view and the flight height, the images taken by UAV often have complex backgrounds and contain a large number of small and unevenly distributed objects. In order to solve the problem that it is difficult to accurately locate and recognize small objects in UAV images under complex backgrounds, this paper proposes an multi-scale feature fusion algorithm D-A-FS SSD (Dilated-Attention-Feature Fusion SSD) based on the combination of dilated convolution and attention mechanism. In the process of feature extraction, the receptive field of the feature is expanded through the dilated convolution, which improves the network's feature expression of object distribution and scale difference information. And a attention network is used in our method to effectively suppresse the background information. In the multi-scale detection stage, our method fuses the low-level feature map responsible for detecting small objects with the high-level feature map which have much higher semantic information to improve the recognition accuracy of small objects. Experimental results show that our method effectively improves the accuracy of UAV image object detection.},
booktitle = {2020 The 8th International Conference on Information Technology: IoT and Smart City},
pages = {125–132},
numpages = {8},
keywords = {Attention mechanism, Multi-scale detection, Dilated convolution, Feature fusion},
location = {Xi'an, China},
series = {ICIT 2020}
}

@inproceedings{10.1145/3417313.3429385,
author = {Dey, Swarnava and Dutta, Jeet},
title = {A Low Footprint Automatic Speech Recognition System For Resource Constrained Edge Devices},
year = {2020},
isbn = {9781450381345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3417313.3429385},
doi = {10.1145/3417313.3429385},
abstract = {Deep Learning (DL) has been instrumental in pushing artificial intelligence (AI)/ machine learning (ML) algorithms to edge of the network. It allows building AI/ML algorithms for computer vision, speech processing, and other timeseries analytics tasks with limited domain knowledge. As there is no mechanism to control the representations learned from a large dataset, it becomes hard to predict whether a very small DL model can learn the proper dependencies needed for a particular problem at hand.With speech recognition capability becoming important in several Internet of Things (IoT) devices, we propose an explainable AI-based methodology to build small DL models for speech recognition by controlling the representations learned by a model under a hard size constraint.We enhance the architecture of a state of the art sequence transduction model to allow the tuning of accuracy vs. model size trade-off. Using these techniques we achieve a reduction in model size and latency by a factor of 10 and 6 respectively, with only 4loss compared to the embedded implementation of a well known ASR.},
booktitle = {Proceedings of the 2nd International Workshop on Challenges in Artificial Intelligence and Machine Learning for Internet of Things},
pages = {48–54},
numpages = {7},
keywords = {explainable ai, streaming ASR, interpretable ai, streaming dataset, RNN-T, data augmentation, speech recognition, model reduction},
location = {Virtual Event, Japan},
series = {AIChallengeIoT '20}
}

@inproceedings{10.1145/3416011.3424749,
author = {Poorzare, Reza and Calveras, Anna},
title = {Open Trends On TCP Performance Over Urban 5G MmWave Networks},
year = {2020},
isbn = {9781450381185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3416011.3424749},
doi = {10.1145/3416011.3424749},
abstract = {The 5G (fifth-generation) mobile networks, especially by exploiting higher bandwidth in the mmWave (millimeter wave) spectrum, is the leading candidate to be used as the coming generation for ubiquitous networks. The vast available bandwidth in mmWave can satisfy the high data rate and low latency expectations from 5G networks in order to provide new services and use cases. Although 5G mmWave networks come up with innovative and robust services, they suffer from a drawback. As the frequency rises, the penetration power and coverage area of the network decreases, so it results in having discontinuous communication between a base station and a user. This intermittent characteristic is caused due to an existing obstacle such as a car or a building on the communication path that can hurdle the establishment of a transmission, which is called NLoS (Non-Line of Sight) state. NLoS states can degrade the functionality of the network and prevent from having seamless connectivity by forcing fluctuations in the network's channels. The reason for this shortcoming is because of the susceptibility of high frequencies to the blockage that can be generated by obstacles. The intense negative effect of having a blockage in the network is on an end-to-end communication when other layers protocols such as the transport layer widely used protocol TCP (Transmission Control Protocol) are used. Having frequent disconnections in the network impairs the TCP's functionality with inducing congestion states and preventing it from achieving higher performance. In this paper, we present the performance evaluation and analysis of TCP in different situations in an urban area and find out how various conditions can affect the performance of the protocol. The simulation results indicate that conventional TCPs are not adequate enough to be exploited in 5G mmWave networks. For having them functioning in their full potential, some modifications should be made in order to adapt them to 5G mmWave networks. Some ML (Machine Learning) techniques such as Neural Networks and Reinforcement Learning can be deployed as the key enablers to network performance improvement.},
booktitle = {Proceedings of the 17th ACM Symposium on Performance Evaluation of Wireless Ad Hoc, Sensor, &amp; Ubiquitous Networks},
pages = {85–92},
numpages = {8},
keywords = {end-to-end communication, 5G, TCP, mmWave},
location = {Alicante, Spain},
series = {PE-WASUN '20}
}

@inproceedings{10.1145/1830483.1830692,
author = {Salichon, Max and Tumer, Kagan},
title = {A Neuro-Evolutionary Approach to Micro Aerial Vehicle Control},
year = {2010},
isbn = {9781450300728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/1830483.1830692},
doi = {10.1145/1830483.1830692},
abstract = {Applying classical control methods to Micro Aerial Vehicles (MAVs) is a difficult process due to the complexity of the control laws with fast and highly non-linear dynamics. Such methods rely heavily on difficult to obtain models and are particularly ill-suited to the stochastic and dynamic environments in which MAVs operate. Instead, in this paper, we focus on a neuro-evolutionary method that learns to map MAV states (position, velocity) to MAV actions (e.g., actuator position). Our results show significant improvements in response times to minor altitude and heading corrections over a traditional PID controller. In addition, we show that the MAV response to maintaining altitude in the presence of wind gusts improves by a factor of five. Similarly, we show that the MAV response to maintaining heading in the presence of turbulence improves by factors of three.},
booktitle = {Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation},
pages = {1123–1130},
numpages = {8},
keywords = {control, evolution, learning},
location = {Portland, Oregon, USA},
series = {GECCO '10}
}

@inproceedings{10.1145/3243394.3243692,
author = {Plastiras, George and Kyrkou, Christos and Theocharides, Theocharis},
title = {Efficient ConvNet-Based Object Detection for Unmanned Aerial Vehicles by Selective Tile Processing},
year = {2018},
isbn = {9781450365116},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3243394.3243692},
doi = {10.1145/3243394.3243692},
abstract = {Many applications utilizing Unmanned Aerial Vehicles (UAVs) require the use of computer vision algorithms to analyze the information captured from their on-board camera. Recent advances in deep learning have made it possible to use single-shot Convolutional Neural Network (CNN) detection algorithms that process the input image to detect various objects of interest. To keep the computational demands low these neural networks typically operate on small image sizes which, however, makes it difficult to detect small objects. This is further emphasized when considering UAVs equipped with cameras where due to the viewing range, objects tend to appear relatively small. This paper therefore, explores the trade-offs involved when maintaining the resolution of the objects of interest by extracting smaller patches (tiles) from the larger input image and processing them using a neural network. Specifically, we introduce an attention mechanism to focus on detecting objects only in some of the tiles and a memory mechanism to keep track of information for tiles that are not processed. Through the analysis of different methods and experiments we show that by carefully selecting which tiles to process we can considerably improve the detection accuracy while maintaining comparable performance to CNNs that resize and process a single image which makes the proposed approach suitable for UAV applications.},
booktitle = {Proceedings of the 12th International Conference on Distributed Smart Cameras},
articleno = {3},
numpages = {6},
keywords = {Convolutional Neural Networks, Pedestrian Detection, Object Detection, Aerial Cameras},
location = {Eindhoven, Netherlands},
series = {ICDSC '18}
}

@article{10.1145/3418205,
author = {Garg, Prateek and Chakravarthy, Anirudh Srinivasan and Mandal, Murari and Narang, Pratik and Chamola, Vinay and Guizani, Mohsen},
title = {ISDNet: AI-Enabled Instance Segmentation of Aerial Scenes for Smart Cities},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3},
issn = {1533-5399},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3418205},
doi = {10.1145/3418205},
abstract = {Aerial scenes captured by UAVs have immense potential in IoT applications related to urban surveillance, road and building segmentation, land cover classification, and so on, which are necessary for the evolution of smart cities. The advancements in deep learning have greatly enhanced visual understanding, but the domain of aerial vision remains largely unexplored. Aerial images pose many unique challenges for performing proper scene parsing such as high-resolution data, small-scaled objects, a large number of objects in the camera view, dense clustering of objects, background clutter, and so on, which greatly hinder the performance of the existing deep learning methods. In this work, we propose ISDNet (Instance Segmentation and Detection Network), a novel network to perform instance segmentation and object detection on visual data captured by UAVs. This work enables aerial image analytics for various needs in a smart city. In particular, we use dilated convolutions to generate improved spatial context, leading to better discrimination between foreground and background features. The proposed network efficiently reuses the segment-mask features by propagating them from early stages using residual connections. Furthermore, ISDNet makes use of effective anchors to accommodate varying object scales and sizes. The proposed method obtains state-of-the-art results in the aerial context.},
journal = {ACM Trans. Internet Technol.},
month = {aug},
articleno = {66},
numpages = {18},
keywords = {UAVs, deep learning, Smart cities, object detection, instance segmentation, aerial scenes}
}

@inproceedings{10.1145/3349625.3355437,
author = {Apostolopoulos, Pavlos Athanasios and Torres, Marcos and Tsiropoulou, Eirini Eleni},
title = {Satisfaction-Aware Data Offloading in Surveillance Systems},
year = {2019},
isbn = {9781450369336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3349625.3355437},
doi = {10.1145/3349625.3355437},
abstract = {In this paper, we exploit the capabilities of Fully Autonomous Aerial Systems' (FAAS) and the Mobile Edge Computing (MEC) to introduce a novel data offloading framework and support the energy and time efficient video processing in surveillance systems based on game theory in satisfaction form. A surveillance system is introduced consisting of Areas of Interest (AoIs), where a MEC server is associated with each AoI, and a FAAS is flying above the AoIs to collectively support the IP cameras' computing demands. Each IP camera adopts a utility function capturing its Quality of Service (QoS) considering the experienced time and energy overhead to offload and process its data either remotely or locally. A non-cooperative game among the cameras is formulated to determine the amount of offloading data to the MEC server and/or the FAAS. The novel concept of Satisfaction Equilibrium (SE) is introduced where the IP cameras satisfy their minimum QoS prerequisites instead of maximizing their performance by wasting additional system resources. A distributed learning algorithm determines the IP cameras' stable data offloading, while a reinforcement learning algorithm determines the FAAS's movement among the AoIs exploiting the accuracy, timeliness, and certainty of the collected data by the IP cameras per AoI. The performance evaluation of the proposed framework is achieved via modeling and simulation.},
booktitle = {Proceedings of the 14th Workshop on Challenged Networks},
pages = {21–26},
numpages = {6},
keywords = {mobile edge computing, satisfaction games, reinforcement learning, surveillance systems},
location = {Los Cabos, Mexico},
series = {CHANTS'19}
}

@inproceedings{10.1145/2979779.2979875,
author = {Kaur, Ramandeep and Singla, Sanjay},
title = {Classification of Plant Leaf Diseases Using Gradient and Texture Feature},
year = {2016},
isbn = {9781450342131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2979779.2979875},
doi = {10.1145/2979779.2979875},
abstract = {This paper presents a new technique of classification of Plant Leaf Disease (Potato Late Blight) using gradient and texture features and Artificial Neural Networks. This technique uses Artificial Neural Networks to Segment an Image which is initially segmented using unsupervised Fuzzy-C-means Clustering Algorithm. In this proposed approach decorrelation extending is utilized to enhance the shading contrasts as a part of the information pictures. At that point Fuzzy C-mean bunching is connected to portion the sickness influenced region which additionally incorporate foundation with same shading attributes. At last we propose to utilize the neural system based way to deal with group the malady influenced locales from the comparable shading textured foundation. The results of our work are promising.},
booktitle = {Proceedings of the International Conference on Advances in Information Communication Technology &amp; Computing},
articleno = {96},
numpages = {7},
keywords = {ANN, Plant Leaf Disease, Classification},
location = {Bikaner, India},
series = {AICTC '16}
}

@article{10.1007/s00165-021-00543-6,
author = {Yang, Zhibin and Bao, Yang and Yang, Yongqiang and Huang, Zhiqiu and Bodeveix, Jean-Paul and Filali, Mamoun and Gu, Zonghua},
title = {Exploiting Augmented Intelligence in the Modeling of Safety-Critical Autonomous Systems},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {3},
issn = {0934-5043},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1007/s00165-021-00543-6},
doi = {10.1007/s00165-021-00543-6},
abstract = {Machine learning (ML) is used increasingly in safety-critical
systems to provide more complex autonomy to make the system to do
decisions by itself in uncertain environments. Using ML to learn
system features is fundamentally different from manually
implementing them in conventional components written in source code.
In this paper, we make a first step towards exploring
the architecture modeling of safety-critical autonomous systems
which are composed of conventional components and ML components,
based on natural language requirements. Firstly, augmented
intelligence for restricted natural language requirement
modeling is proposed. In that, several AI technologies such as
natural language processing and clustering are used to recommend
candidate terms to the glossary, as well as machine learning is used
to predict the category of requirements. The glossary including data
dictionary and domain glossary and the category of requirements will
be used in the restricted natural language requirement specification
method RNLReq, which is equipped with a set of restriction rules and
templates to structure and restrict the way how users document
requirements. Secondly, automatic generation of SysML architecture
models from the RNLReq requirement specifications is presented.
Thirdly, the prototype tool is implemented based on Papyrus.
Finally,  it presents the evaluation of the proposed
approach using an industrial autonomous guidance, navigation and
control case study.},
journal = {Form. Asp. Comput.},
month = {jun},
pages = {343–384},
numpages = {42},
keywords = {Machine learning, SysML, Augmented intelligence, Restricted natural language requirements, Safety-critical autonomous system, Natural language processing}
}

@inproceedings{10.1145/3190645.3190690,
author = {Mihail, Radu P. and Cook, Wesley I. and Griffin, Brandi M. and Uyeno, Theodore A. and Anderson, Corey D.},
title = {Vegetation Density Estimation in the Wild},
year = {2018},
isbn = {9781450356961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3190645.3190690},
doi = {10.1145/3190645.3190690},
abstract = {Remote sensing has revolutionized the efficiency of vegetation mapping, but such techniques remain impractical for mapping some types of flora over relatively limited spatial extents. We propose a deep-learning based framework for automated detection and planar mapping of an epiphytic plant in a forest from geotagged static imagery using inexpensive cameras. Our pipeline consists of two steps: segmentation and spatial distribution estimation. We evaluate several segmentation methods on a novel dataset of roughly 375 outdoor images with per-pixel labels indicating the presence of Spanish moss. We also evaluate the accuracy of the spatial distribution estimates with respect to field measurements by ecologists for Spanish moss.},
booktitle = {Proceedings of the ACMSE 2018 Conference},
articleno = {9},
numpages = {7},
keywords = {machine vision, segmentation, deep learning, in the wild, plants},
location = {Richmond, Kentucky},
series = {ACMSE '18}
}

@inproceedings{10.1145/3343031.3350933,
author = {Zhang, Haotian and Wang, Gaoang and Lei, Zhichao and Hwang, Jenq-Neng},
title = {Eye in the Sky: Drone-Based Object Tracking and 3D Localization},
year = {2019},
isbn = {9781450368896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3343031.3350933},
doi = {10.1145/3343031.3350933},
abstract = {Drones, or general UAVs, equipped with a single camera have been widely deployed to a broad range of applications, such as aerial photography, fast goods delivery and most importantly, surveillance. Despite the great progress achieved in computer vision algorithms, these algorithms are not usually optimized for dealing with images or video sequences acquired by drones, due to various challenges such as occlusion, fast camera motion and pose variation. In this paper, a drone-based multi-object tracking and 3D localization scheme is proposed based on the deep learning based object detection. We first combine a multi-object tracking method called TrackletNet Tracker (TNT) which utilizes temporal and appearance information to track detected objects located on the ground for UAV applications. Then, we are also able to localize the tracked ground objects based on the group plane estimated from the Multi-View Stereo technique. The system deployed on the drone can not only detect and track the objects in a scene, but can also localize their 3D coordinates in meters with respect to the drone camera. The experiments have proved our tracker can reliably handle most of the detected objects captured by drones and achieve favorable 3D localization performance when compared with the state-of-the-art methods.},
booktitle = {Proceedings of the 27th ACM International Conference on Multimedia},
pages = {899–907},
numpages = {9},
keywords = {ground plane, 3d localization, multi-object tracking, drone},
location = {Nice, France},
series = {MM '19}
}

@inproceedings{10.1145/3377049.3377052,
author = {Gomes, Dipta and Saif, A. F. M. Saifuddin and Nandi, Dip},
title = {Robust Underwater Object Detection with Autonomous Underwater Vehicle: A Comprehensive Study},
year = {2020},
isbn = {9781450377782},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3377049.3377052},
doi = {10.1145/3377049.3377052},
abstract = {Underwater Object Detection had been one of the most challenging research fields of Computer Vision and Image Processing. Before Computer Vision techniques were used for underwater imaging, all the tasks associated with object detection had to be done manually by marine scientists making the task one of the most tedious and error prone. For this case, Underwater Autonomous Vehicles (UAV) has been developed to capture real time videos for specific object detection. Using different hardware improvements and using many varied forms of algorithms, classification of objects, mainly living objects had been carried with different AUVs and high-resolution cameras. Conventional object detection methods of Computer Vision fail to provide accurate detection results due to some challenges faced underwater. For such reasons, object detection underwater needs to be robust, real time and fast also being accurate, for which deep learning approaches are introduced. In this paper, all the works here all the trending underwater object detection techniques are discussed in details and a comprehensive comparative study is carried out.},
booktitle = {Proceedings of the International Conference on Computing Advancements},
articleno = {17},
numpages = {10},
keywords = {Underwater Object Detection, Image Enhancement, Image Processing and Underwater Autonomous Vehicle, Deep Learning},
location = {Dhaka, Bangladesh},
series = {ICCA 2020}
}

@inproceedings{10.1145/2820716.2820723,
author = {Wang, Wei and Shi, Haoshan and Huang, Pengyu and Wu, Fuping and Fang, Dingyi and Chen, Xiaojiang and Yin, Xiaoyan},
title = {An Efficient Variable Dimension PSO Algorithm for Mobile Node Tour Planning in WSN},
year = {2015},
isbn = {9781450338424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2820716.2820723},
doi = {10.1145/2820716.2820723},
abstract = {Recent advances in unmanned aerial vehicle (UAV) and wireless charging technologies have made it practical to introduce a mobile node into Wireless Sensor Networks (WSN). This mobile node with sink ability or charging equipment on it can travel around the entire network to gather data from isolate sensor nodes or charge the nodes wirelessly. This can help with the large scale WSN to be connected or keep working for a long time without replacing batteries. For the mobile node, routing design is an important problem. We can regard this problem as a special case of traveling salesman problem with neighborhoods (TSPN), which is NP-hard. In this paper, we propose a novel routing design algorithm base on Variable Dimensions Particle Swarm Optimization (VD-PSO). In this algorithm, every particle is a feasible solution of TSPN. Every dimension of the particle is the coordinates of a rendezvous point (the point where mobile node stay to gather data or charge the nodes). And the dimensionality is right the number of the rendezvous point. With the evolutionary method of the particles, we can derive the best route of the mobile node. Simulation results show that our scheme has fast convergence speed, and the result is quite approximate to the optimal solution.},
booktitle = {Proceedings of the 1st Workshop on Context Sensing and Activity Recognition},
pages = {47–52},
numpages = {6},
keywords = {traveling salesman problem with neighborhoods, wireless sensor networks, variable dimensions particle swarm optimization, mobile node},
location = {Seoul, South Korea},
series = {CSAR '15}
}

@inproceedings{10.1145/3465481.3470478,
author = {Siniosoglou, Ilias and Argyriou, Vasileios and Bibi, Stamatia and Lagkas, Thomas and Sarigiannidis, Panagiotis},
title = {Unsupervised Ethical Equity Evaluation of Adversarial Federated Networks},
year = {2021},
isbn = {9781450390514},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3465481.3470478},
doi = {10.1145/3465481.3470478},
abstract = { While the technology of Deep Learning (DL) is a powerful tool when properly trained for image analysis and classification applications, some factors for its optimization rely solely on the training data and their environment. In an effort to tackle the problem of knowledge bias created during the training process of a Deep Neural Network (DNN) and specifically Adversarial Networks for image augmentation, this work presents an entirely unsupervised methodology for discovering the unfairness level of Deep Learning (DL) models and in extend, its wrongly accumulated or biased classes. Fdi, the proposed evaluation metric for quantizing the level of unfairness of a model is introduced, along with the method of weighting the model’s knowledge and producing its weakest aspects in a data-agnostic way.},
booktitle = {The 16th International Conference on Availability, Reliability and Security},
articleno = {123},
numpages = {6},
keywords = {Fairness, Adversarial networks, Image classification, Federated Learning, Image synthesis},
location = {Vienna, Austria},
series = {ARES 2021}
}


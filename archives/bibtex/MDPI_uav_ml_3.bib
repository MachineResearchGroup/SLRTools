
@Article{s21134408,
AUTHOR = {Salehi Hikouei, Iman and Kim, S. Sonny and Mishra, Deepak R.},
TITLE = {Machine-Learning Classification of Soil Bulk Density in Salt Marsh Environments},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4408},
URL = {https://www.mdpi.com/1424-8220/21/13/4408},
PubMedID = {34199102},
ISSN = {1424-8220},
ABSTRACT = {Remotely sensed data from both in situ and satellite platforms in visible, near-infrared, and shortwave infrared (VNIR–SWIR, 400–2500 nm) regions have been widely used to characterize and model soil properties in a direct, cost-effective, and rapid manner at different scales. In this study, we assess the performance of machine-learning algorithms including random forest (RF), extreme gradient boosting machines (XGBoost), and support vector machines (SVM) to model salt marsh soil bulk density using multispectral remote-sensing data from the Landsat-7 Enhanced Thematic Mapper Plus (ETM+) platform. To our knowledge, use of remote-sensing data for estimating salt marsh soil bulk density at the vegetation rooting zone has not been investigated before. Our study reveals that blue (band 1; 450–520 nm) and NIR (band 4; 770–900 nm) bands of Landsat-7 ETM+ ranked as the most important spectral features for bulk density prediction by XGBoost and RF, respectively. According to XGBoost, band 1 and band 4 had relative importance of around 41% and 39%, respectively. We tested two soil bulk density classes in order to differentiate salt marshes in terms of their capability to support vegetation that grows in either low (0.032 to 0.752 g/cm3) or high (0.752 g/cm3 to 1.893 g/cm3) bulk density areas. XGBoost produced a higher classification accuracy (88%) compared to RF (87%) and SVM (86%), although discrepancies in accuracy between these models were small (&lt;2%). XGBoost correctly classified 178 out of 186 soil samples labeled as low bulk density and 37 out of 62 soil samples labeled as high bulk density. We conclude that remote-sensing-based machine-learning models can be a valuable tool for ecologists and engineers to map the soil bulk density in wetlands to select suitable sites for effective restoration and successful re-establishment practices.},
DOI = {10.3390/s21134408}
}



@Article{s21134417,
AUTHOR = {Ukaegbu, Uchechi F. and Tartibu, Lagouge K. and Okwu, Modestus O. and Olayode, Isaac O.},
TITLE = {Development of a Light-Weight Unmanned Aerial Vehicle for Precision Agriculture},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4417},
URL = {https://www.mdpi.com/1424-8220/21/13/4417},
PubMedID = {34203187},
ISSN = {1424-8220},
ABSTRACT = {This paper describes the development of a modular unmanned aerial vehicle for the detection and eradication of weeds on farmland. Precision agriculture entails solving the problem of poor agricultural yield due to competition for nutrients by weeds and provides a faster approach to eliminating the problematic weeds using emerging technologies. This research has addressed the aforementioned problem. A quadcopter was built, and components were assembled with light-weight materials. The system consists of the electric motor, electronic speed controller, propellers, frame, lithium polymer (li-po) battery, flight controller, a global positioning system (GPS), and receiver. A sprayer module which consists of a relay, Raspberry Pi 3, spray pump, 12 V DC source, water hose, and the tank was built. It operated in such a way that when a weed is detected based on the deep learning algorithms deployed on the Raspberry Pi, general purpose input/output (GPIO) 17 or GPIO 18 (of the Raspberry Pi) were activated to supply 3.3 V, which turned on a DC relay to spray herbicides accordingly. The sprayer module was mounted on the quadcopter and from the test-running operation conducted, broadleaf and grass weeds were accurately detected and the spraying of herbicides according to the weed type occurred in less than a second.},
DOI = {10.3390/s21134417}
}



@Article{rs13132520,
AUTHOR = {Ma, Dongdong and Rehman, Tanzeel U. and Zhang, Libo and Maki, Hideki and Tuinstra, Mitchell R. and Jin, Jian},
TITLE = {Modeling of Environmental Impacts on Aerial Hyperspectral Images for Corn Plant Phenotyping},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2520},
URL = {https://www.mdpi.com/2072-4292/13/13/2520},
ISSN = {2072-4292},
ABSTRACT = {Aerial imaging technologies have been widely applied in agricultural plant remote sensing. However, an as yet unexplored challenge with field imaging is that the environmental conditions, such as sun angle, cloud coverage, temperature, and so on, can significantly alter plant appearance and thus affect the imaging sensor’s accuracy toward extracting plant feature measurements. These image alterations result from the complicated interaction between the real-time environments and plants. Analysis of these impacts requires continuous monitoring of the changes through various environmental conditions, which has been difficult with current aerial remote sensing systems. This paper aimed to propose a modeling method to comprehensively understand and model the environmental influences on hyperspectral imaging data. In 2019, a fixed hyperspectral imaging gantry was constructed in Purdue University’s research farm, and over 8000 repetitive images of the same corn field were taken with a 2.5 min interval for 31 days. Time-tagged local environment data, including solar zenith angle, solar irradiation, temperature, wind speed, and so on, were also recorded during the imaging time. The images were processed for phenotyping data, and the time series decomposition method was applied to extract the phenotyping data variation caused by the changing environments. An artificial neural network (ANN) was then built to model the relationship between the phenotyping data variation and environmental changes. The ANN model was able to accurately predict the environmental effects in remote sensing results, and thus could be used to effectively eliminate the environment-induced variation in the phenotyping features. The test of the normalized difference vegetation index (NDVI) calculated from the hyperspectral images showed that variance in NDVI was reduced by 79%. A similar performance was confirmed with the relative water content (RWC) predictions. Therefore, this modeling method shows great potential for application in aerial remote sensing applications in agriculture, to significantly improve the imaging quality by effectively eliminating the effects from the changing environmental conditions.},
DOI = {10.3390/rs13132520}
}



@Article{s21134418,
AUTHOR = {Zhang, Ying and Sun, Jingyi and Qiu, Rudong and Liu, Huilan and Zhang, Xi and Xuan, Jiabin},
TITLE = {Spatial Scale Effect of a Typical Polarized Remote Sensor on Detecting Ground Objects},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4418},
URL = {https://www.mdpi.com/1424-8220/21/13/4418},
PubMedID = {34203266},
ISSN = {1424-8220},
ABSTRACT = {For polarized remote sensors, the polarization images of ground objects acquired at different spatial scales will be different due to the spatial heterogeneity of the ground object targets and the limitation of imaging resolution. In this paper, the quantitative inversion problem of a typical polarized remote sensor at different spatial scales was studied. Firstly, the surface roughness of coatings was inversed based on the polarized bidirectional reflectance distribution function (pBRDF) model according to their polarization images at different distances. A linear-mixed pixel model was used to make a preliminary correction of the spatial scale effect. Secondly, the super-resolution image reconstruction of the polarization imager was realized based on the projection onto convex sets (POCS) method. Then, images with different resolutions at a fixed distance were obtained by utilizing this super-resolution image reconstruction method and the optimal spatial scale under the scene can be acquired by using information entropy as an evaluation indicator. Finally, the experimental results showed that the roughness inversion of coatings has the highest accuracy in the optimal spatial scale. It has been proved that our proposed method can provide a reliable way to reduce the spatial effect of the polarized remote sensor and to improve the inversion accuracy.},
DOI = {10.3390/s21134418}
}



@Article{agriculture11070600,
AUTHOR = {Murphy, Darren J. and Murphy, Michael D. and O’Brien, Bernadette and O’Donovan, Michael},
TITLE = {A Review of Precision Technologies for Optimising Pasture Measurement on Irish Grassland},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {600},
URL = {https://www.mdpi.com/2077-0472/11/7/600},
ISSN = {2077-0472},
ABSTRACT = {The development of precision grass measurement technologies is of vital importance to securing the future sustainability of pasture-based livestock production systems. There is potential to increase grassland production in a sustainable manner by achieving a more precise measurement of pasture quantity and quality. This review presents an overview of the most recent seminal research pertaining to the development of precision grass measurement technologies. One of the main obstacles to precision grass measurement, sward heterogeneity, is discussed along with optimal sampling techniques to address this issue. The limitations of conventional grass measurement techniques are outlined and alternative new terrestrial, proximal, and remote sensing technologies are presented. The possibilities of automating grass measurement and reducing labour costs are hypothesised and the development of holistic online grassland management systems that may facilitate these goals are further outlined.},
DOI = {10.3390/agriculture11070600}
}



@Article{rs13132524,
AUTHOR = {Chen, Ziyi and Li, Dilong and Fan, Wentao and Guan, Haiyan and Wang, Cheng and Li, Jonathan},
TITLE = {Self-Attention in Reconstruction Bias U-Net for Semantic Segmentation of Building Rooftops in Optical Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2524},
URL = {https://www.mdpi.com/2072-4292/13/13/2524},
ISSN = {2072-4292},
ABSTRACT = {Deep learning models have brought great breakthroughs in building extraction from high-resolution optical remote-sensing images. Among recent research, the self-attention module has called up a storm in many fields, including building extraction. However, most current deep learning models loading with the self-attention module still lose sight of the reconstruction bias’s effectiveness. Through tipping the balance between the abilities of encoding and decoding, i.e., making the decoding network be much more complex than the encoding network, the semantic segmentation ability will be reinforced. To remedy the research weakness in combing self-attention and reconstruction-bias modules for building extraction, this paper presents a U-Net architecture that combines self-attention and reconstruction-bias modules. In the encoding part, a self-attention module is added to learn the attention weights of the inputs. Through the self-attention module, the network will pay more attention to positions where there may be salient regions. In the decoding part, multiple large convolutional up-sampling operations are used for increasing the reconstruction ability. We test our model on two open available datasets: the WHU and Massachusetts Building datasets. We achieve IoU scores of 89.39% and 73.49% for the WHU and Massachusetts Building datasets, respectively. Compared with several recently famous semantic segmentation methods and representative building extraction methods, our method’s results are satisfactory.},
DOI = {10.3390/rs13132524}
}



@Article{jsan10030042,
AUTHOR = {Al-Nuaimi, Mohammed and Wibowo, Sapto and Qu, Hongyang and Aitken, Jonathan and Veres, Sandor},
TITLE = {Hybrid Verification Technique for Decision-Making of Self-Driving Vehicles},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {10},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {42},
URL = {https://www.mdpi.com/2224-2708/10/3/42},
ISSN = {2224-2708},
ABSTRACT = {The evolution of driving technology has recently progressed from active safety features and ADAS systems to fully sensor-guided autonomous driving. Bringing such a vehicle to market requires not only simulation and testing but formal verification to account for all possible traffic scenarios. A new verification approach, which combines the use of two well-known model checkers: model checker for multi-agent systems (MCMAS) and probabilistic model checker (PRISM), is presented for this purpose. The overall structure of our autonomous vehicle (AV) system consists of: (1) A perception system of sensors that feeds data into (2) a rational agent (RA) based on a belief–desire–intention (BDI) architecture, which uses a model of the environment and is connected to the RA for verification of decision-making, and (3) a feedback control systems for following a self-planned path. MCMAS is used to check the consistency and stability of the BDI agent logic during design-time. PRISM is used to provide the RA with the probability of success while it decides to take action during run-time operation. This allows the RA to select movements of the highest probability of success from several generated alternatives. This framework has been tested on a new AV software platform built using the robot operating system (ROS) and virtual reality (VR) Gazebo Simulator. It also includes a parking lot scenario to test the feasibility of this approach in a realistic environment. A practical implementation of the AV system was also carried out on the experimental testbed.},
DOI = {10.3390/jsan10030042}
}



@Article{s21134442,
AUTHOR = {Niu, Zijie and Deng, Juntao and Zhang, Xu and Zhang, Jun and Pan, Shijia and Mu, Haotian},
TITLE = {Identifying the Branch of Kiwifruit Based on Unmanned Aerial Vehicle (UAV) Images Using Deep Learning Method},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4442},
URL = {https://www.mdpi.com/1424-8220/21/13/4442},
PubMedID = {34209571},
ISSN = {1424-8220},
ABSTRACT = {It is important to obtain accurate information about kiwifruit vines to monitoring their physiological states and undertake precise orchard operations. However, because vines are small and cling to trellises, and have branches laying on the ground, numerous challenges exist in the acquisition of accurate data for kiwifruit vines. In this paper, a kiwifruit canopy distribution prediction model is proposed on the basis of low-altitude unmanned aerial vehicle (UAV) images and deep learning techniques. First, the location of the kiwifruit plants and vine distribution are extracted from high-precision images collected by UAV. The canopy gradient distribution maps with different noise reduction and distribution effects are generated by modifying the threshold and sampling size using the resampling normalization method. The results showed that the accuracies of the vine segmentation using PSPnet, support vector machine, and random forest classification were 71.2%, 85.8%, and 75.26%, respectively. However, the segmentation image obtained using depth semantic segmentation had a higher signal-to-noise ratio and was closer to the real situation. The average intersection over union of the deep semantic segmentation was more than or equal to 80% in distribution maps, whereas, in traditional machine learning, the average intersection was between 20% and 60%. This indicates the proposed model can quickly extract the vine distribution and plant position, and is thus able to perform dynamic monitoring of orchards to provide real-time operation guidance.},
DOI = {10.3390/s21134442}
}



@Article{app11136022,
AUTHOR = {Sanchez-Anguix, Victor and Tunalı, Okan and Aydoğan, Reyhan and Julian, Vicente},
TITLE = {Can Social Agents Efficiently Perform in Automated Negotiation?},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {6022},
URL = {https://www.mdpi.com/2076-3417/11/13/6022},
ISSN = {2076-3417},
ABSTRACT = {In the last few years, we witnessed a growing body of literature about automated negotiation. Mainly, negotiating agents are either purely self-driven by maximizing their utility function or by assuming a cooperative stance by all parties involved in the negotiation. We argue that, while optimizing one’s utility function is essential, agents in a society should not ignore the opponent’s utility in the final agreement to improve the agent’s long-term perspectives in the system. This article aims to show whether it is possible to design a social agent (i.e., one that aims to optimize both sides’ utility functions) while performing efficiently in an agent society. Accordingly, we propose a social agent supported by a portfolio of strategies, a novel tit-for-tat concession mechanism, and a frequency-based opponent modeling mechanism capable of adapting its behavior according to the opponent’s behavior and the state of the negotiation. The results show that the proposed social agent not only maximizes social metrics such as the distance to the Nash bargaining point or the Kalai point but also is shown to be a pure and mixed equilibrium strategy in some realistic agent societies.},
DOI = {10.3390/app11136022}
}



@Article{f12070856,
AUTHOR = {Hyyppä, Juha and Yu, Xiaowei and Hakala, Teemu and Kaartinen, Harri and Kukko, Antero and Hyyti, Heikki and Muhojoki, Jesse and Hyyppä, Eric},
TITLE = {Under-Canopy UAV Laser Scanning Providing Canopy Height and Stem Volume Accurately},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {856},
URL = {https://www.mdpi.com/1999-4907/12/7/856},
ISSN = {1999-4907},
ABSTRACT = {The automation of forest field reference data collection has been an intensive research objective for laser scanning scientists ever since the invention of terrestrial laser scanning more than two decades ago. In this study, we demonstrated that an under-canopy UAV laser scanning system utilizing a rotating laser scanner can alone provide accurate estimates of canopy height and stem volume for the majority of trees in a boreal forest. We mounted a rotating laser scanner based on a Velodyne VLP-16 sensor onboard a manually piloted UAV. The UAV was commanded with the help of a live video feed from the onboard camera. Since the system was based on a rotating laser scanner providing varying view angles, all important elements such as treetops, branches, trunks, and ground could be recorded with laser hits. In an experiment including two different forest structures, namely sparse and obstructed canopy, we showed that our system can measure the heights of individual trees with a bias of −20 cm and a standard error of 40 cm in the sparse forest and with a bias of −65 cm and a standard error of 1 m in the obstructed forest. The accuracy of the obtained tree height estimates was equivalent to airborne above-canopy UAV surveys conducted in similar forest conditions or even at the same sites. The higher underestimation and higher inaccuracy in the obstructed site can be attributed to three trees with a height exceeding 25 m and the reduced point density of these tree tops due to occlusion and the limited ranging capacity of the scanner. Additionally, we used our system to estimate the stem volumes of individual trees with a standard error at the level of 10%. This level of error is equivalent to the error obtained when merging above-canopy UAV laser scanner data with terrestrial point cloud data. The results show that we do not necessarily need a combination of terrestrial point clouds and point clouds collected using above-canopy UAV systems in order to accurately estimate the heights and the volumes of individual trees in reference data collection.},
DOI = {10.3390/f12070856}
}



@Article{s21134447,
AUTHOR = {Shin, Jisun and Jo, Young-Heon and Ryu, Joo-Hyung and Khim, Boo-Keun and Kim, Soo Mee},
TITLE = {High Spatial-Resolution Red Tide Detection in the Southern Coast of Korea Using U-Net from PlanetScope Imagery},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4447},
URL = {https://www.mdpi.com/1424-8220/21/13/4447},
PubMedID = {34209710},
ISSN = {1424-8220},
ABSTRACT = {Red tides caused by Margalefidinium polykrikoides occur continuously along the southern coast of Korea, where there are many aquaculture cages, and therefore, prompt monitoring of bloom water is required to prevent considerable damage. Satellite-based ocean-color sensors are widely used for detecting red tide blooms, but their low spatial resolution restricts coastal observations. Contrarily, terrestrial sensors with a high spatial resolution are good candidate sensors, despite the lack of spectral resolution and bands for red tide detection. In this study, we developed a U-Net deep learning model for detecting M. polykrikoides blooms along the southern coast of Korea from PlanetScope imagery with a high spatial resolution of 3 m. The U-Net model was trained with four different datasets that were constructed with randomly or non-randomly chosen patches consisting of different ratios of red tide and non-red tide pixels. The qualitative and quantitative assessments of the conventional red tide index (RTI) and four U-Net models suggest that the U-Net model, which was trained with a dataset of non-randomly chosen patches including non-red tide patches, outperformed RTI in terms of sensitivity, precision, and F-measure level, accounting for an increase of 19.84%, 44.84%, and 28.52%, respectively. The M. polykrikoides map derived from U-Net provides the most reasonable red tide patterns in all water areas. Combining high spatial resolution images and deep learning approaches represents a good solution for the monitoring of red tides over coastal regions.},
DOI = {10.3390/s21134447}
}



@Article{rs13132546,
AUTHOR = {Guo, Xinyi and Fu, Bihong and Du, Jie and Shi, Pilong and Chen, Qingyu and Zhang, Wenyuan},
TITLE = {Applicability of Susceptibility Model for Rock and Loess Earthquake Landslides in the Eastern Tibetan Plateau},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2546},
URL = {https://www.mdpi.com/2072-4292/13/13/2546},
ISSN = {2072-4292},
ABSTRACT = {It is crucial to explore a suitable landslide susceptibility model with an excellent prediction capability for rapid evaluation and disaster relief in seismic regions with different lithological features. In this study, we selected two typical seismic events, the Jiuzhaigou and Minxian earthquakes, which occurred in the Alpine karst and loess regions, respectively. Eight influencing factors and five models were chosen to calculate the susceptibility of landslide, including the information (I) model, certainty factor (CF) model, logistic regression (LR) model, I + LR coupling model, and CF + LR coupling model. Then, the accuracy and the landslide susceptibility distribution of these models were assessed by the area under curve (AUC) and distribution criteria. Finally, the model with high accuracy and good applicability for the rock landslide or loess landslide regions was optimized. Our results showed that the accuracy of the coupling model is higher than that of the single models. Except for the LR model, the landslide susceptibility distribution for the above-mentioned models is consistent with universal cognition. The coupling models are generally better than their single models. Among them, the I + LR model can obtain the best comprehensive results for assessing the distribution and accuracy of both rock and loess landslide susceptibility, which is helpful for disaster relief and policy-making, and it can also provide useful scientific data for post-seismic reconstruction and restoration.},
DOI = {10.3390/rs13132546}
}



@Article{rs13132548,
AUTHOR = {Habibi, Luthfan Nur and Watanabe, Tomoya and Matsui, Tsutomu and Tanaka, Takashi S. T.},
TITLE = {Machine Learning Techniques to Predict Soybean Plant Density Using UAV and Satellite-Based Remote Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2548},
URL = {https://www.mdpi.com/2072-4292/13/13/2548},
ISSN = {2072-4292},
ABSTRACT = {The plant density of soybean is a critical factor affecting plant canopy structure and yield. Predicting the spatial variability of plant density would be valuable for improving agronomic practices. The objective of this study was to develop a model for plant density measurement using several data sets with different spatial resolutions, including unmanned aerial vehicle (UAV) imagery, PlanetScope satellite imagery, and climate data. The model establishment process includes (1) performing the high-throughput measurement of actual plant density from UAV imagery with the You Only Look Once version 3 (YOLOv3) object detection algorithm, which was further treated as a response variable of the estimation models in the next step, and (2) developing regression models to estimate plant density in the extended areas using various combinations of predictors derived from PlanetScope imagery and climate data. Our results showed that the YOLOv3 model can accurately measure actual soybean plant density from UAV imagery data with a root mean square error (RMSE) value of 0.96 plants m−2. Furthermore, the two regression models, partial least squares and random forest (RF), successfully expanded the plant density prediction areas with RMSE values ranging from 1.78 to 3.67 plant m−2. Model improvement was conducted using the variable importance feature in RF, which improved prediction accuracy with an RMSE value of 1.72 plant m−2. These results demonstrated that the established model had an acceptable prediction accuracy for estimating plant density. Although the model could not often evaluate the within-field spatial variability of soybean plant density, the predicted values were sufficient for informing the field-specific status.},
DOI = {10.3390/rs13132548}
}



@Article{s21134451,
AUTHOR = {Cheng, Lei and Tan, Xiyue and Yao, Dong and Xu, Wenxia and Wu, Huaiyu and Chen, Yang},
TITLE = {A Fishery Water Quality Monitoring and Prediction Evaluation System for Floating UAV Based on Time Series},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4451},
URL = {https://www.mdpi.com/1424-8220/21/13/4451},
PubMedID = {34209936},
ISSN = {1424-8220},
ABSTRACT = {In recent years, fishery has developed rapidly. For the vital interests of the majority of fishermen, this paper makes full use of Internet of Things and air–water amphibious UAV technology to provide an integrated system that can meet the requirements of fishery water quality monitoring and prediction evaluation. To monitor target water quality in real time, the water quality monitoring of the system is mainly completed by a six-rotor floating UAV that carries water quality sensors. The GPRS module is then used to realize remote data transmission. The prediction of water quality transmission data is mainly realized by the algorithm of time series comprehensive analysis. The evaluation rules are determined according to the water quality evaluation standards to evaluate the predicted water quality data. Finally, the feasibility of the system is proved through experiments. The results show that the system can effectively evaluate fishery water quality under different weather conditions. The prediction accuracy of the pH, dissolved oxygen content, and ammonia nitrogen content of fishery water quality can reach 99%, 98%, and 99% on sunny days, and reach 92%, 98%, and 91% on rainy days.},
DOI = {10.3390/s21134451}
}



@Article{su13137309,
AUTHOR = {Giray, Görkem and Catal, Cagatay},
TITLE = {Design of a Data Management Reference Architecture for Sustainable Agriculture},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {7309},
URL = {https://www.mdpi.com/2071-1050/13/13/7309},
ISSN = {2071-1050},
ABSTRACT = {Effective and efficient data management is crucial for smart farming and precision agriculture. To realize operational efficiency, full automation, and high productivity in agricultural systems, different kinds of data are collected from operational systems using different sensors, stored in different systems, and processed using advanced techniques, such as machine learning and deep learning. Due to the complexity of data management operations, a data management reference architecture is required. While there are different initiatives to design data management reference architectures, a data management reference architecture for sustainable agriculture is missing. In this study, we follow domain scoping, domain modeling, and reference architecture design stages to design the reference architecture for sustainable agriculture. Four case studies were performed to demonstrate the applicability of the reference architecture. This study shows that the proposed data management reference architecture is practical and effective for sustainable agriculture.},
DOI = {10.3390/su13137309}
}



@Article{app11136079,
AUTHOR = {Elgamoudi, Abulasad and Benzerrouk, Hamza and Elango, G. Arul and Landry, René},
TITLE = {A Survey for Recent Techniques and Algorithms of Geolocation and Target Tracking in Wireless and Satellite Systems},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {6079},
URL = {https://www.mdpi.com/2076-3417/11/13/6079},
ISSN = {2076-3417},
ABSTRACT = {A single Radio-Frequency Interference (RFI) is a disturbance source of modern wireless systems depending on Global Navigation Satellite Systems (GNSS) and Satellite Communication (SatCom). In particular, significant applications such as aeronautics and satellite communication can be severely affected by intentional and unintentional interference, which are unmitigated. The matter requires finding a radical and effective solution to overcome this problem. The methods used for overcoming the RFI include interference detection, interference classification, interference geolocation, tracking and interference mitigation. RFI source geolocation and tracking methodology gained universal attention from numerous researchers, specialists, and scientists. In the last decade, various conventional techniques and algorithms have been adopted in geolocation and target tracking in civil and military operations. Previous conventional techniques did not address the challenges and demand for novel algorithms. Hence there is a necessity for focussing on the issues associated with this. This survey introduces a review of various conventional geolocation techniques, current orientations, and state-of-the-art techniques and highlights some approaches and algorithms employed in wireless and satellite systems for geolocation and target tracking that may be extremely beneficial. In addition, a comparison between different conventional geolocation techniques has been revealed, and the comparisons between various approaches and algorithms of geolocation and target tracking have been addressed, including H∞ and Kalman Filtering versions that have been implemented and investigated by authors.},
DOI = {10.3390/app11136079}
}



@Article{rs13132555,
AUTHOR = {Yoosefzadeh-Najafabadi, Mohsen and Tulpan, Dan and Eskandari, Milad},
TITLE = {Using Hybrid Artificial Intelligence and Evolutionary Optimization Algorithms for Estimating Soybean Yield and Fresh Biomass Using Hyperspectral Vegetation Indices},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2555},
URL = {https://www.mdpi.com/2072-4292/13/13/2555},
ISSN = {2072-4292},
ABSTRACT = {Recent advanced high-throughput field phenotyping combined with sophisticated big data analysis methods have provided plant breeders with unprecedented tools for a better prediction of important agronomic traits, such as yield and fresh biomass (FBIO), at early growth stages. This study aimed to demonstrate the potential use of 35 selected hyperspectral vegetation indices (HVI), collected at the R5 growth stage, for predicting soybean seed yield and FBIO. Two artificial intelligence algorithms, ensemble-bagging (EB) and deep neural network (DNN), were used to predict soybean seed yield and FBIO using HVI. Considering HVI as input variables, the coefficients of determination (R2) of 0.76 and 0.77 for yield and 0.91 and 0.89 for FBIO were obtained using DNN and EB, respectively. In this study, we also used hybrid DNN-SPEA2 to estimate the optimum HVI values in soybeans with maximized yield and FBIO productions. In addition, to identify the most informative HVI in predicting yield and FBIO, the feature recursive elimination wrapper method was used and the top ranking HVI were determined to be associated with red, 670 nm and near-infrared, 800 nm, regions. Overall, this study introduced hybrid DNN-SPEA2 as a robust mathematical tool for optimizing and using informative HVI for estimating soybean seed yield and FBIO at early growth stages, which can be employed by soybean breeders for discriminating superior genotypes in large breeding populations.},
DOI = {10.3390/rs13132555}
}



@Article{s21134489,
AUTHOR = {Matin, Sahar S. and Pradhan, Biswajeet},
TITLE = {Earthquake-Induced Building-Damage Mapping Using Explainable AI (XAI)},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4489},
URL = {https://www.mdpi.com/1424-8220/21/13/4489},
PubMedID = {34209169},
ISSN = {1424-8220},
ABSTRACT = {Building-damage mapping using remote sensing images plays a critical role in providing quick and accurate information for the first responders after major earthquakes. In recent years, there has been an increasing interest in generating post-earthquake building-damage maps automatically using different artificial intelligence (AI)-based frameworks. These frameworks in this domain are promising, yet not reliable for several reasons, including but not limited to the site-specific design of the methods, the lack of transparency in the AI-model, the lack of quality in the labelled image, and the use of irrelevant descriptor features in building the AI-model. Using explainable AI (XAI) can lead us to gain insight into identifying these limitations and therefore, to modify the training dataset and the model accordingly. This paper proposes the use of SHAP (Shapley additive explanation) to interpret the outputs of a multilayer perceptron (MLP)—a machine learning model—and analyse the impact of each feature descriptor included in the model for building-damage assessment to examine the reliability of the model. In this study, a post-event satellite image from the 2018 Palu earthquake was used. The results show that MLP can classify the collapsed and non-collapsed buildings with an overall accuracy of 84% after removing the redundant features. Further, spectral features are found to be more important than texture features in distinguishing the collapsed and non-collapsed buildings. Finally, we argue that constructing an explainable model would help to understand the model’s decision to classify the buildings as collapsed and non-collapsed and open avenues to build a transferable AI model.},
DOI = {10.3390/s21134489}
}



@Article{rs13132565,
AUTHOR = {Ghorbanian, Arsalan and Zaghian, Soheil and Asiyabi, Reza Mohammadi and Amani, Meisam and Mohammadzadeh, Ali and Jamali, Sadegh},
TITLE = {Mangrove Ecosystem Mapping Using Sentinel-1 and Sentinel-2 Satellite Images and Random Forest Algorithm in Google Earth Engine},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2565},
URL = {https://www.mdpi.com/2072-4292/13/13/2565},
ISSN = {2072-4292},
ABSTRACT = {Mangroves are among the most productive ecosystems in existence, with many ecological benefits. Therefore, generating accurate thematic maps from mangrove ecosystems is crucial for protecting, conserving, and reforestation planning for these valuable natural resources. In this paper, Sentinel-1 and Sentinel-2 satellite images were used in synergy to produce a detailed mangrove ecosystem map of the Hara protected area, Qeshm, Iran, at 10 m spatial resolution within the Google Earth Engine (GEE) cloud computing platform. In this regard, 86 Sentinel-1 and 41 Sentinel-2 data, acquired in 2019, were employed to generate seasonal optical and synthetic aperture radar (SAR) features. Afterward, seasonal features were inserted into a pixel-based random forest (RF) classifier, resulting in an accurate mangrove ecosystem map with average overall accuracy (OA) and Kappa coefficient (KC) of 93.23% and 0.92, respectively, wherein all classes (except aerial roots) achieved high producer and user accuracies of over 90%. Furthermore, comprehensive quantitative and qualitative assessments were performed to investigate the robustness of the proposed approach, and the accurate and stable results achieved through cross-validation and consistency checks confirmed its robustness and applicability. It was revealed that seasonal features and the integration of multi-source remote sensing data contributed towards obtaining a more reliable mangrove ecosystem map. The proposed approach relies on a straightforward yet effective workflow for mangrove ecosystem mapping, with a high rate of automation that can be easily implemented for frequent and precise mapping in other parts of the world. Overall, the proposed workflow can further improve the conservation and sustainable management of these valuable natural resources.},
DOI = {10.3390/rs13132565}
}



@Article{agriculture11070617,
AUTHOR = {Bansal, Prakhar and Kumar, Rahul and Kumar, Somesh},
TITLE = {Disease Detection in Apple Leaves Using Deep Convolutional Neural Network},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {617},
URL = {https://www.mdpi.com/2077-0472/11/7/617},
ISSN = {2077-0472},
ABSTRACT = {The automatic detection of diseases in plants is necessary, as it reduces the tedious work of monitoring large farms and it will detect the disease at an early stage of its occurrence to minimize further degradation of plants. Besides the decline of plant health, a country’s economy is highly affected by this scenario due to lower production. The current approach to identify diseases by an expert is slow and non-optimal for large farms. Our proposed model is an ensemble of pre-trained DenseNet121, EfficientNetB7, and EfficientNet NoisyStudent, which aims to classify leaves of apple trees into one of the following categories: healthy, apple scab, apple cedar rust, and multiple diseases, using its images. Various Image Augmentation techniques are included in this research to increase the dataset size, and subsequentially, the model’s accuracy increases. Our proposed model achieves an accuracy of 96.25% on the validation dataset. The proposed model can identify leaves with multiple diseases with 90% accuracy. Our proposed model achieved a good performance on different metrics and can be deployed in the agricultural domain to identify plant health accurately and timely.},
DOI = {10.3390/agriculture11070617}
}



@Article{app11136112,
AUTHOR = {Mbiydzenyuy, Gideon and Nowaczyk, Sławomir and Knutsson, Håkan and Vanhoudt, Dirk and Brage, Jens and Calikus, Ece},
TITLE = {Opportunities for Machine Learning in District Heating},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {6112},
URL = {https://www.mdpi.com/2076-3417/11/13/6112},
ISSN = {2076-3417},
ABSTRACT = {The district heating (DH) industry is facing an important transformation towards more efficient networks that utilise significantly lower water temperatures to distribute the heat. This change requires taking advantage of new technologies, and Machine Learning (ML) is a popular direction. In the last decade, we have witnessed an extreme growth in the number of published research papers that focus on applying ML techniques to the DH domain. However, based on our experience in the field, and an extensive review of the state-of-the-art, we perceive a mismatch between the most popular research directions, such as forecasting, and the challenges faced by the DH industry. In this work, we present our findings, explain and demonstrate the key gaps between the two communities and suggest a road-map ahead towards increasing the impact of ML research in the DH industry.},
DOI = {10.3390/app11136112}
}



@Article{rs13132567,
AUTHOR = {Oh, Sungchan and Lee, Da-Young and Gongora-Canul, Carlos and Ashapure, Akash and Carpenter, Joshua and Cruz, A. P. and Fernandez-Campos, Mariela and Lane, Brenden Z. and Telenko, Darcy E. P. and Jung, Jinha and Cruz, C. D.},
TITLE = {Tar Spot Disease Quantification Using Unmanned Aircraft Systems (UAS) Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2567},
URL = {https://www.mdpi.com/2072-4292/13/13/2567},
ISSN = {2072-4292},
ABSTRACT = {Tar spot is a foliar disease of corn characterized by fungal fruiting bodies that resemble tar spots. The disease emerged in the U.S. in 2015, and severe outbreaks in 2018 caused an economic impact on corn yields throughout the Midwest. Adequate epidemiological surveillance and disease quantification are necessary to develop immediate and long-term management strategies. This study presents a measurement framework that evaluates the disease severity of tar spot using unmanned aircraft systems (UAS)-based plant phenotyping and regression techniques. UAS-based plant phenotypic information, such as canopy cover, canopy volume, and vegetation indices, were used as explanatory variables. Visual estimations of disease severity were performed by expert plant pathologists per experiment plot basis and used as response variables. Three regression methods, namely ordinary least squares (OLS), support vector regression (SVR), and multilayer perceptron (MLP), were used to determine an optimal regression method for UAS-based tar spot measurement. The cross-validation results showed that the regression model based on MLP provides the highest accuracy of disease measurements. By training and testing the model with spatially separated datasets, the proposed regression model achieved a Lin’s concordance correlation coefficient (ρc) of 0.82 and a root mean square error (RMSE) of 6.42. This study demonstrated that we could use the proposed UAS-based method for the disease quantification of tar spot, which shows a gradual spectral response as the disease develops.},
DOI = {10.3390/rs13132567}
}



@Article{s21134511,
AUTHOR = {Bauer, Martin and Sanchez, Luis and Song, JaeSeung},
TITLE = {IoT-Enabled Smart Cities: Evolution and Outlook},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4511},
URL = {https://www.mdpi.com/1424-8220/21/13/4511},
PubMedID = {34209436},
ISSN = {1424-8220},
ABSTRACT = {For the last decade the Smart City concept has been under development, fostered by the growing urbanization of the world’s population and the need to handle the challenges that such a scenario raises. During this time many Smart City projects have been executed–some as proof-of-concept, but a growing number resulting in permanent, production-level deployments, improving the operation of the city and the quality of life of its citizens. Thus, Smart Cities are still a highly relevant paradigm which needs further development before it reaches its full potential and provides robust and resilient solutions. In this paper, the focus is set on the Internet of Things (IoT) as an enabling technology for the Smart City. In this sense, the paper reviews the current landscape of IoT-enabled Smart Cities, surveying relevant experiences and city initiatives that have embedded IoT within their city services and how they have generated an impact. The paper discusses the key technologies that have been developed and how they are contributing to the realization of the Smart City. Moreover, it presents some challenges that remain open ahead of us and which are the initiatives and technologies that are under development to tackle them.},
DOI = {10.3390/s21134511}
}



@Article{info12070272,
AUTHOR = {Ackerson, Joseph M. and Dave, Rushit and Seliya, Naeem},
TITLE = {Applications of Recurrent Neural Network for Biometric Authentication &amp; Anomaly Detection},
JOURNAL = {Information},
VOLUME = {12},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {272},
URL = {https://www.mdpi.com/2078-2489/12/7/272},
ISSN = {2078-2489},
ABSTRACT = {Recurrent Neural Networks are powerful machine learning frameworks that allow for data to be saved and referenced in a temporal sequence. This opens many new possibilities in fields such as handwriting analysis and speech recognition. This paper seeks to explore current research being conducted on RNNs in four very important areas, being biometric authentication, expression recognition, anomaly detection, and applications to aircraft. This paper reviews the methodologies, purpose, results, and the benefits and drawbacks of each proposed method below. These various methodologies all focus on how they can leverage distinct RNN architectures such as the popular Long Short-Term Memory (LSTM) RNN or a Deep-Residual RNN. This paper also examines which frameworks work best in certain situations, and the advantages and disadvantages of each proposed model.},
DOI = {10.3390/info12070272}
}



@Article{telecom2030017,
AUTHOR = {Pourroostaei Ardakani, Saeid and Cheshmehzangi, Ali},
TITLE = {Reinforcement Learning-Enabled UAV Itinerary Planning for Remote Sensing Applications in Smart Farming},
JOURNAL = {Telecom},
VOLUME = {2},
YEAR = {2021},
NUMBER = {3},
PAGES = {255--270},
URL = {https://www.mdpi.com/2673-4001/2/3/17},
ISSN = {2673-4001},
ABSTRACT = {UAV path planning for remote sensing aims to find the best-fitted routes to complete a data collection mission. UAVs plan the routes and move through them to remotely collect environmental data from particular target zones by using sensory devices such as cameras. Route planning may utilize machine learning techniques to autonomously find/select cost-effective and/or best-fitted routes and achieve optimized results including: minimized data collection delay, reduced UAV power consumption, decreased flight traversed distance and maximized number of collected data samples. This paper utilizes a reinforcement learning technique (location and energy-aware Q-learning) to plan UAV routes for remote sensing in smart farms. Through this, the UAV avoids heuristically or blindly moving throughout a farm, but this takes the benefits of environment exploration–exploitation to explore the farm and find the shortest and most cost-effective paths into target locations with interesting data samples to collect. According to the simulation results, utilizing the Q-learning technique increases data collection robustness and reduces UAV resource consumption (e.g., power), traversed paths, and remote sensing latency as compared to two well-known benchmarks, IEMF and TBID, especially if the target locations are dense and crowded in a farm.},
DOI = {10.3390/telecom2030017}
}



@Article{math9131541,
AUTHOR = {Korchagin, Sergey and Romanova, Ekaterina and Serdechnyy, Denis and Nikitin, Petr and Dolgov, Vitaliy and Feklin, Vadim},
TITLE = {Mathematical Modeling of Layered Nanocomposite of Fractal Structure},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {1541},
URL = {https://www.mdpi.com/2227-7390/9/13/1541},
ISSN = {2227-7390},
ABSTRACT = {A model of a layered hierarchically constructed composite is presented, the structure of which demonstrates the properties of similarity at different scales. For the proposed model of the composite, fractal analysis was carried out, including an assessment of the permissible range of scales, calculation of fractal capacity, Hausdorff and Minkovsky dimensions, calculation of the Hurst exponent. The maximum and minimum sizes at which fractal properties are observed are investigated, and a quantitative assessment of the complexity of the proposed model is carried out. A software package is developed that allows calculating the fractal characteristics of hierarchically constructed composite media. A qualitative analysis of the calculated fractal characteristics is carried out.},
DOI = {10.3390/math9131541}
}



@Article{aerospace8070179,
AUTHOR = {Swinney, Carolyn J. and Woods, John C.},
TITLE = {The Effect of Real-World Interference on CNN Feature Extraction and Machine Learning Classification of Unmanned Aerial Systems},
JOURNAL = {Aerospace},
VOLUME = {8},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {179},
URL = {https://www.mdpi.com/2226-4310/8/7/179},
ISSN = {2226-4310},
ABSTRACT = {Small unmanned aerial systems (UASs) present many potential solutions and enhancements to industry today but equally pose a significant security challenge. We only need to look at the levels of disruption caused by UASs at airports in recent years. The accuracy of UAS detection and classification systems based on radio frequency (RF) signals can be hindered by other interfering signals present in the same frequency band, such as Bluetooth and Wi-Fi devices. In this paper, we evaluate the effect of real-world interference from Bluetooth and Wi-Fi signals concurrently on convolutional neural network (CNN) feature extraction and machine learning classification of UASs. We assess multiple UASs that operate using different transmission systems: Wi-Fi, Lightbridge 2.0, OcuSync 1.0, OcuSync 2.0 and the recently released OcuSync 3.0. We consider 7 popular UASs, evaluating 2 class UAS detection, 8 class UAS type classification and 21 class UAS flight mode classification. Our results show that the process of CNN feature extraction using transfer learning and machine learning classification is fairly robust in the presence of real-world interference. We also show that UASs that are operating using the same transmission system can be distinguished. In the presence of interference from both Bluetooth and Wi-Fi signals, our results show 100% accuracy for UAV detection (2 classes), 98.1% (+/−0.4%) for UAV type classification (8 classes) and 95.4% (+/−0.3%) for UAV flight mode classification (21 classes).},
DOI = {10.3390/aerospace8070179}
}



@Article{math9131542,
AUTHOR = {Xie, Xuelin and Shen, Jingfang},
TITLE = {Waterlogging Resistance Evaluation Index and Photosynthesis Characteristics Selection: Using Machine Learning Methods to Judge Poplar’s Waterlogging Resistance},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {1542},
URL = {https://www.mdpi.com/2227-7390/9/13/1542},
ISSN = {2227-7390},
ABSTRACT = {Flood disasters are the major natural disaster that affects the growth of agriculture and forestry crops. Due to rapid growth and strong waterlogging resistance characteristics, many studies have explained the waterlogging resistance mechanism of poplar from different perspectives. However, there is no accurate method to define the evaluation index of waterlogging resistance. In addition, there is also a lack of research on predicting the waterlogging resistance of poplars. Based on the changes of poplar biomass and seedling height, the evaluation index of poplar resistance to waterlogging was well determined, and the characteristics of photosynthesis were used to predict the waterlogging resistance of poplars. First, four methods of hierarchical clustering, lasso, stepwise regression and all-subsets regression were used to extract the photosynthesis characteristics. After that, the support vector regression model of poplar resistance to waterlogging was established by using the characteristic parameters of photosynthesis. Finally, the results show that the SVR model based on Stepwise regression and Lasso method has high precision. On the test set, the coefficient of determination (R2) was 0.8581 and 0.8492, the mean square error (MSE) was 0.0104 and 0.0341, and the mean relative error (MRE) was 9.78% and 9.85%, respectively. Therefore, using the characteristic parameters of photosynthesis to predict the waterlogging resistance of poplars is feasible.},
DOI = {10.3390/math9131542}
}



@Article{rs13132588,
AUTHOR = {Wang, Zhihao and Brenning, Alexander},
TITLE = {Active-Learning Approaches for Landslide Mapping Using Support Vector Machines},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2588},
URL = {https://www.mdpi.com/2072-4292/13/13/2588},
ISSN = {2072-4292},
ABSTRACT = {Ex post landslide mapping for emergency response and ex ante landslide susceptibility modelling for hazard mitigation are two important application scenarios that require the development of accurate, yet cost-effective spatial landslide models. However, the manual labelling of instances for training machine learning models is time-consuming given the data requirements of flexible data-driven algorithms and the small percentage of area covered by landslides. Active learning aims to reduce labelling costs by selecting more informative instances. In this study, two common active-learning strategies, uncertainty sampling and query by committee, are combined with the support vector machine (SVM), a state-of-the-art machine-learning technique, in a landslide mapping case study in order to assess their possible benefits compared to simple random sampling of training locations. By selecting more “informative” instances, the SVMs with active learning based on uncertainty sampling outperformed both random sampling and query-by-committee strategies when considering mean AUROC (area under the receiver operating characteristic curve) as performance measure. Uncertainty sampling also produced more stable performances with a smaller AUROC standard deviation across repetitions. In conclusion, under limited data conditions, uncertainty sampling reduces the amount of expert time needed by selecting more informative instances for SVM training. We therefore recommend incorporating active learning with uncertainty sampling into interactive landslide modelling workflows, especially in emergency response settings, but also in landslide susceptibility modelling.},
DOI = {10.3390/rs13132588}
}



@Article{s21134542,
AUTHOR = {Kaczorowska, Monika and Karczmarek, Paweł and Plechawska-Wójcik, Małgorzata and Tokovarov, Mikhail},
TITLE = {On the Improvement of Eye Tracking-Based Cognitive Workload Estimation Using Aggregation Functions},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4542},
URL = {https://www.mdpi.com/1424-8220/21/13/4542},
PubMedID = {34283098},
ISSN = {1424-8220},
ABSTRACT = {Cognitive workload, being a quantitative measure of mental effort, draws significant interest of researchers, as it allows to monitor the state of mental fatigue. Estimation of cognitive workload becomes especially important for job positions requiring outstanding engagement and responsibility, e.g., air-traffic dispatchers, pilots, car or train drivers. Cognitive workload estimation finds its applications also in the field of education material preparation. It allows to monitor the difficulty degree for specific tasks enabling to adjust the level of education materials to typical abilities of students. In this study, we present the results of research conducted with the goal of examining the influence of various fuzzy or non-fuzzy aggregation functions upon the quality of cognitive workload estimation. Various classic machine learning models were successfully applied to the problem. The results of extensive in-depth experiments with over 2000 aggregation operators shows the applicability of the approach based on the aggregation functions. Moreover, the approach based on aggregation process allows for further improvement of classification results. A wide range of aggregation functions is considered and the results suggest that the combination of classical machine learning models and aggregation methods allows to achieve high quality of cognitive workload level recognition preserving low computational cost.},
DOI = {10.3390/s21134542}
}



@Article{rs13132591,
AUTHOR = {Maxwell, Aaron E. and Warner, Timothy A. and Guillén, Luis Andrés},
TITLE = {Accuracy Assessment in Convolutional Neural Network-Based Deep Learning Remote Sensing Studies—Part 2: Recommendations and Best Practices},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2591},
URL = {https://www.mdpi.com/2072-4292/13/13/2591},
ISSN = {2072-4292},
ABSTRACT = {Convolutional neural network (CNN)-based deep learning (DL) has a wide variety of applications in the geospatial and remote sensing (RS) sciences, and consequently has been a focus of many recent studies. However, a review of accuracy assessment methods used in recently published RS DL studies, focusing on scene classification, object detection, semantic segmentation, and instance segmentation, indicates that RS DL papers appear to follow an accuracy assessment approach that diverges from that of traditional RS studies. Papers reporting on RS DL studies have largely abandoned traditional RS accuracy assessment terminology; they rarely reported a complete confusion matrix; and sampling designs and analysis protocols generally did not provide a population-based confusion matrix, in which the table entries are estimates of the probabilities of occurrence of the mapped landscape. These issues indicate the need for the RS community to develop guidance on best practices for accuracy assessment for CNN-based DL thematic mapping and object detection. As a first step in that process, we explore key issues, including the observation that accuracy assessments should not be biased by the CNN-based training and inference processes that rely on image chips. Furthermore, accuracy assessments should be consistent with prior recommendations and standards in the field, should support the estimation of a population confusion matrix, and should allow for assessment of model generalization. This paper draws from our review of the RS DL literature and the rich record of traditional remote sensing accuracy assessment research while considering the unique nature of CNN-based deep learning to propose accuracy assessment best practices that use appropriate sampling methods, training and validation data partitioning, assessment metrics, and reporting standards.},
DOI = {10.3390/rs13132591}
}



@Article{rs13132592,
AUTHOR = {Liu, Xiaobang and Liang, Shunlin and Li, Bing and Ma, Han and He, Tao},
TITLE = {Mapping 30 m Fractional Forest Cover over China’s Three-North Region from Landsat-8 Data Using Ensemble Machine Learning Methods},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2592},
URL = {https://www.mdpi.com/2072-4292/13/13/2592},
ISSN = {2072-4292},
ABSTRACT = {The accurate monitoring of forest cover and its changes are essential for environmental change research, but current satellite products for forest coverage carry many uncertainties. This study used 30-m Landsat-8 data, and aggregated 1-m GaoFen-2 (GF-2) satellite images to construct the training samples and used multiple machine learning algorithms (MLAs) to estimate the fractional forest cover (FFC) in China’s Three North Region (TNR). In this study, multiple MLAs were merged to construct stacked generalization (SG) models based on the idea of SG, and the performances of the MLAs in the FFC estimation were evaluated. The results of the 10-fold cross-validation showed that all non-linear algorithms had a good performance, with an R2 value of greater than 0.8 and a root-mean square error (RMSE) of less than 0.05. In the bagging ensemble, the random forest (RF) (R2 = 0.993, RMSE = 0.020) model performed the best and in the boosting ensemble, the light gradient boosted machine (LGBM) (R2 = 0.992, RMSE = 0.022) performed the best. Although the evaluation index of the RF is slightly better than that of the LGBM, the independent validation results show that the two models have similar performances. The model evaluation results of the independent datasets showed that, in the SG model, the performance of the SG(LGBM) (R2 = 0.991, RMSE = 0.034) was better than that of the single or non-ensemble model. Comparing the FFC estimates of our model with those of existing datasets showed that our model exhibited more forest spatial distribution details and higher accuracy in complex landscapes. Overall, in this study, the method of using high-resolution remote sensing (RS) images to extract samples for FFC estimation is feasible. Our results demonstrate the potential of the ensemble MLAs to map the FFC. The research results also show that among many MALs, the RF algorithm is the most suitable algorithm for estimating FFC, which provides a reference for future research.},
DOI = {10.3390/rs13132592}
}



@Article{horticulturae7070176,
AUTHOR = {Duarte-Carvajalino, Julio Martin and Silva-Arero, Elías Alexander and Góez-Vinasco, Gerardo Antonio and Torres-Delgado, Laura Marcela and Ocampo-Paez, Oscar Dubán and Castaño-Marín, Angela María},
TITLE = {Estimation of Water Stress in Potato Plants Using Hyperspectral Imagery and Machine Learning Algorithms},
JOURNAL = {Horticulturae},
VOLUME = {7},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {176},
URL = {https://www.mdpi.com/2311-7524/7/7/176},
ISSN = {2311-7524},
ABSTRACT = {This work presents quantitative detection of water stress and estimation of the water stress level: none, light, moderate, and severe on potato crops. We use hyperspectral imagery and state of the art machine learning algorithms: random decision forest, multilayer perceptron, convolutional neural networks, support vector machines, extreme gradient boost, and AdaBoost. The detection and estimation of water stress in potato crops is carried out on two different phenological stages of the plants: tubers differentiation and maximum tuberization. The machine learning algorithms are trained with a small subset of each hyperspectral image corresponding to the plant canopy. The results are improved using majority voting to classify all the canopy pixels in the hyperspectral images. The results indicate that both detection of water stress and estimation of the level of water stress can be obtained with good accuracy, improved further by majority voting. The importance of each band of the hyperspectral images in the classification of the images is assessed by random forest and extreme gradient boost, which are the machine learning algorithms that perform best overall on both phenological stages and detection and estimation of water stress in potato crops.},
DOI = {10.3390/horticulturae7070176}
}



@Article{rs13132596,
AUTHOR = {Mohan, Midhun and Richardson, Gabriella and Gopan, Gopika and Aghai, Matthew Mehdi and Bajaj, Shaurya and Galgamuwa, G. A. Pabodha and Vastaranta, Mikko and Arachchige, Pavithra S. Pitumpe and Amorós, Lot and Corte, Ana Paula Dalla and de-Miguel, Sergio and Leite, Rodrigo Vieira and Kganyago, Mahlatse and Broadbent, Eben North and Doaemo, Willie and Shorab, Mohammed Abdullah Bin and Cardil, Adrian},
TITLE = {UAV-Supported Forest Regeneration: Current Trends, Challenges and Implications},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2596},
URL = {https://www.mdpi.com/2072-4292/13/13/2596},
ISSN = {2072-4292},
ABSTRACT = {Replanting trees helps with avoiding desertification, reducing the chances of soil erosion and flooding, minimizing the risks of zoonotic disease outbreaks, and providing ecosystem services and livelihood to the indigenous people, in addition to sequestering carbon dioxide for mitigating climate change. Consequently, it is important to explore new methods and technologies that are aiming to upscale and fast-track afforestation and reforestation (A/R) endeavors, given that many of the current tree planting strategies are not cost effective over large landscapes, and suffer from constraints associated with time, energy, manpower, and nursery-based seedling production. UAV (unmanned aerial vehicle)-supported seed sowing (UAVsSS) can promote rapid A/R in a safe, cost-effective, fast and environmentally friendly manner, if performed correctly, even in otherwise unsafe and/or inaccessible terrains, supplementing the overall manual planting efforts globally. In this study, we reviewed the recent literature on UAVsSS, to analyze the current status of the technology. Primary UAVsSS applications were found to be in areas of post-wildfire reforestation, mangrove restoration, forest restoration after degradation, weed eradication, and desert greening. Nonetheless, low survival rates of the seeds, future forest diversity, weather limitations, financial constraints, and seed-firing accuracy concerns were determined as major challenges to operationalization. Based on our literature survey and qualitative analysis, twelve recommendations—ranging from the need for publishing germination results to linking UAVsSS operations with carbon offset markets—are provided for the advancement of UAVsSS applications.},
DOI = {10.3390/rs13132596}
}



@Article{s21134549,
AUTHOR = {Hussein, Burhan Rashid and Malik, Owais Ahmed and Ong, Wee-Hong and Slik, Johan Willem Frederik},
TITLE = {Automated Extraction of Phenotypic Leaf Traits of Individual Intact Herbarium Leaves from Herbarium Specimen Images Using Deep Learning Based Semantic Segmentation},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4549},
URL = {https://www.mdpi.com/1424-8220/21/13/4549},
PubMedID = {34283110},
ISSN = {1424-8220},
ABSTRACT = {With the increase in the digitization efforts of herbarium collections worldwide, dataset repositories such as iDigBio and GBIF now have hundreds of thousands of herbarium sheet images ready for exploration. Although this serves as a new source of plant leaves data, herbarium datasets have an inherent challenge to deal with the sheets containing other non-plant objects such as color charts, barcodes, and labels. Even for the plant part itself, a combination of different overlapping, damaged, and intact individual leaves exist together with other plant organs such as stems and fruits, which increases the complexity of leaf trait extraction and analysis. Focusing on segmentation and trait extraction on individual intact herbarium leaves, this study proposes a pipeline consisting of deep learning semantic segmentation model (DeepLabv3+), connected component analysis, and a single-leaf classifier trained on binary images to automate the extraction of an intact individual leaf with phenotypic traits. The proposed method achieved a higher F1-score for both the in-house dataset (96%) and on a publicly available herbarium dataset (93%) compared to object detection-based approaches including Faster R-CNN and YOLOv5. Furthermore, using the proposed approach, the phenotypic measurements extracted from the segmented individual leaves were closer to the ground truth measurements, which suggests the importance of the segmentation process in handling background noise. Compared to the object detection-based approaches, the proposed method showed a promising direction toward an autonomous tool for the extraction of individual leaves together with their trait data directly from herbarium specimen images.},
DOI = {10.3390/s21134549}
}



@Article{rs13132598,
AUTHOR = {Li, Jian and Chen, Baozhang},
TITLE = {Optimal Solar Zenith Angle Definition for Combined Landsat-8 and Sentinel-2A/2B Data Angular Normalization Using Machine Learning Methods},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2598},
URL = {https://www.mdpi.com/2072-4292/13/13/2598},
ISSN = {2072-4292},
ABSTRACT = {Data from Landsat-8 and Sentinel-2A/2B are often combined for terrestrial monitoring because of their similar spectral bands. The bidirectional reflectance distribution function (BRDF) effect has been observed in both Landsat-8 and Sentinel-2A/2B reflectance data. However, there is currently no definition of solar zenith angle (θsz) that is suitable for the normalization of the BRDF-adjusted reflectance from the three sensors’ combined data. This paper describes the use of four machine learning (ML) models to predict a global θsz that is suitable for the normalization of bidirectional reflectance from the combined data in 2018. The observed θsz collected globally, and the three locations in the Democratic Republic of Congo (26.622°E, 0.356°N), Texas in the USA (99.406°W 30.751°N), and Finland (25.194°E, 61.653°N), are chosen to compare the performance of the ML models. At a global scale, the ML models of Support Vector Regression (SVR), Multi-Layer Perception (MLP), and Gaussian Process Regression (GPR) exhibit comparably good performance to that of polynomial regression, considering center latitude as the input to predict the global θsz. GPR achieves the best overall performance considering the center latitude and acquisition time as inputs, with a root mean square error (RMSE) of 1.390°, a mean absolute error (MAE) of 0.689°, and a coefficient of determination (R2) of 0.994. SVR shows an RMSE of 1.396°, an MAE of 0.638°, and an R2 of 0.994, following GPR. For a specific location, the SVR and GPR models have higher accuracy than the polynomial regression, with GPR exhibiting the best performance, when center latitude and acquisition time are considered as inputs. GPR is recommended for predicting the global θsz using the three sensors’ combined data.},
DOI = {10.3390/rs13132598}
}



@Article{rs13132606,
AUTHOR = {Francos, Nicolas and Romano, Nunzio and Nasta, Paolo and Zeng, Yijian and Szabó, Brigitta and Manfreda, Salvatore and Ciraolo, Giuseppe and Mészáros, János and Zhuang, Ruodan and Su, Bob and Ben-Dor, Eyal},
TITLE = {Mapping Water Infiltration Rate Using Ground and UAV Hyperspectral Data: A Case Study of Alento, Italy},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2606},
URL = {https://www.mdpi.com/2072-4292/13/13/2606},
ISSN = {2072-4292},
ABSTRACT = {Water infiltration rate (WIR) into the soil profile was investigated through a comprehensive study harnessing spectral information of the soil surface. As soil spectroscopy provides invaluable information on soil attributes, and as WIR is a soil surface-dependent property, field spectroscopy may model WIR better than traditional laboratory spectral measurements. This is because sampling for the latter disrupts the soil-surface status. A field soil spectral library (FSSL), consisting of 114 samples with different textures from six different sites over the Mediterranean basin, combined with traditional laboratory spectral measurements, was created. Next, partial least squares regression analysis was conducted on the spectral and WIR data in different soil texture groups, showing better performance of the field spectral observations compared to traditional laboratory spectroscopy. Moreover, several quantitative spectral properties were lost due to the sampling procedure, and separating the samples according to texture gave higher accuracies. Although the visible near-infrared–shortwave infrared (VNIR–SWIR) spectral region provided better accuracy, we resampled the spectral data to the resolution of a Cubert hyperspectral sensor (VNIR). This hyperspectral sensor was then assembled on an unmanned aerial vehicle (UAV) to apply one selected spectral-based model to the UAV data and map the WIR in a semi-vegetated area within the Alento catchment, Italy. Comprehensive spectral and WIR ground-truth measurements were carried out simultaneously with the UAV–Cubert sensor flight. The results were satisfactorily validated on the ground using field samples, followed by a spatial uncertainty analysis, concluding that the UAV with hyperspectral remote sensing can be used to map soil surface-related soil properties.},
DOI = {10.3390/rs13132606}
}



@Article{agronomy11071363,
AUTHOR = {Bahrami, Hazhir and Homayouni, Saeid and Safari, Abdolreza and Mirzaei, Sayeh and Mahdianpari, Masoud and Reisi-Gahrouei, Omid},
TITLE = {Deep Learning-Based Estimation of Crop Biophysical Parameters Using Multi-Source and Multi-Temporal Remote Sensing Observations},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1363},
URL = {https://www.mdpi.com/2073-4395/11/7/1363},
ISSN = {2073-4395},
ABSTRACT = {Remote sensing data are considered as one of the primary data sources for precise agriculture. Several studies have demonstrated the excellent capability of radar and optical imagery for crop mapping and biophysical parameter estimation. This paper aims at modeling the crop biophysical parameters, e.g., Leaf Area Index (LAI) and biomass, using a combination of radar and optical Earth observations. We extracted several radar features from polarimetric Synthetic Aperture Radar (SAR) data and Vegetation Indices (VIs) from optical images to model crops’ LAI and dry biomass. Then, the mutual correlations between these features and Random Forest feature importance were calculated. We considered two scenarios to estimate crop parameters. First, Machine Learning (ML) algorithms, e.g., Support Vector Regression (SVR), Random Forest (RF), Gradient Boosting (GB), and Extreme Gradient Boosting (XGB), were utilized to estimate two crop biophysical parameters. To this end, crops’ dry biomass and LAI were estimated using three input data; (1) SAR polarimetric features; (2) spectral VIs; (3) integrating both SAR and optical features. Second, a deep artificial neural network was created. These input data were fed to the mentioned algorithms and evaluated using the in-situ measurements. These observations of three cash crops, including soybean, corn, and canola, have been collected over Manitoba, Canada, during the Soil Moisture Active Validation Experimental 2012 (SMAPVEX-12) campaign. The results showed that GB and XGB have great potential in parameter estimation and remarkably improved accuracy. Our results also demonstrated a significant improvement in the dry biomass and LAI estimation compared to the previous studies. For LAI, the validation Root Mean Square Error (RMSE) was reported as 0.557 m2/m2 for canola using GB, and 0.298 m2/m2 for corn using GB, 0.233 m2/m2 for soybean using XGB. RMSE was reported for dry biomass as 26.29 g/m2 for canola utilizing SVR, 57.97 g/m2 for corn using RF, and 5.00 g/m2 for soybean using GB. The results revealed that the deep artificial neural network had a better potential to estimate crop parameters than the ML algorithms.},
DOI = {10.3390/agronomy11071363}
}



@Article{rs13132622,
AUTHOR = {Wang, Haozhou and Duan, Yulin and Shi, Yun and Kato, Yoichiro and Ninomiya, Seishi and Guo, Wei},
TITLE = {EasyIDP: A Python Package for Intermediate Data Processing in UAV-Based Plant Phenotyping},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2622},
URL = {https://www.mdpi.com/2072-4292/13/13/2622},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle (UAV) and structure from motion (SfM) photogrammetry techniques are widely used for field-based, high-throughput plant phenotyping nowadays, but some of the intermediate processes throughout the workflow remain manual. For example, geographic information system (GIS) software is used to manually assess the 2D/3D field reconstruction quality and cropping region of interests (ROIs) from the whole field. In addition, extracting phenotypic traits from raw UAV images is more competitive than directly from the digital orthomosaic (DOM). Currently, no easy-to-use tools are available to implement previous tasks for commonly used commercial SfM software, such as Pix4D and Agisoft Metashape. Hence, an open source software package called easy intermediate data processor (EasyIDP; MIT license) was developed to decrease the workload in intermediate data processing mentioned above. The functions of the proposed package include (1) an ROI cropping module, assisting in reconstruction quality assessment and cropping ROIs from the whole field, and (2) an ROI reversing module, projecting ROIs to relative raw images. The result showed that both cropping and reversing modules work as expected. Moreover, the effects of ROI height selection and reversed ROI position on raw images to reverse calculation were discussed. This tool shows great potential for decreasing workload in data annotation for machine learning applications.},
DOI = {10.3390/rs13132622}
}



@Article{rs13132627,
AUTHOR = {Moura, Marks Melo and de Oliveira, Luiz Eduardo Soares and Sanquetta, Carlos Roberto and Bastos, Alexis and Mohan, Midhun and Corte, Ana Paula Dalla},
TITLE = {Towards Amazon Forest Restoration: Automatic Detection of Species from UAV Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2627},
URL = {https://www.mdpi.com/2072-4292/13/13/2627},
ISSN = {2072-4292},
ABSTRACT = {Precise assessments of forest species’ composition help analyze biodiversity patterns, estimate wood stocks, and improve carbon stock estimates. Therefore, the objective of this work was to evaluate the use of high-resolution images obtained from Unmanned Aerial Vehicle (UAV) for the identification of forest species in areas of forest regeneration in the Amazon. For this purpose, convolutional neural networks (CNN) were trained using the Keras–Tensorflow package with the faster_rcnn_inception_v2_pets model. Samples of six forest species were used to train CNN. From these, attempts were made with the number of thresholds, which is the cutoff value of the function; any value below this output is considered 0, and values above are treated as an output 1; that is, values above the value stipulated in the Threshold are considered as identified species. The results showed that the reduction in the threshold decreases the accuracy of identification, as well as the overlap of the polygons of species identification. However, in comparison with the data collected in the field, it was observed that there exists a high correlation between the trees identified by the CNN and those observed in the plots. The statistical metrics used to validate the classification results showed that CNN are able to identify species with accuracy above 90%. Based on our results, which demonstrate good accuracy and precision in the identification of species, we conclude that convolutional neural networks are an effective tool in classifying objects from UAV images.},
DOI = {10.3390/rs13132627}
}



@Article{rs13132631,
AUTHOR = {Grybas, Heather and Congalton, Russell G.},
TITLE = {A Comparison of Multi-Temporal RGB and Multispectral UAS Imagery for Tree Species Classification in Heterogeneous New Hampshire Forests},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2631},
URL = {https://www.mdpi.com/2072-4292/13/13/2631},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial systems (UASs) have recently become an affordable means to map forests at the species level, but research into the performance of different classification methodologies and sensors is necessary so users can make informed choices that maximize accuracy. This study investigated whether multi-temporal UAS data improved the classified accuracy of 14 species examined the optimal time-window for data collection, and compared the performance of a consumer-grade RGB sensor to that of a multispectral sensor. A time series of UAS data was collected from early spring to mid-summer and a sequence of mono-temporal and multi-temporal classifications were carried out. Kappa comparisons were conducted to ascertain whether the multi-temporal classifications significantly improved accuracy and whether there were significant differences between the RGB and multispectral classifications. The multi-temporal classification approach significantly improved accuracy; however, there was no significant benefit when more than three dates were used. Mid- to late spring imagery produced the highest accuracies, potentially due to high spectral heterogeneity between species and homogeneity within species during this time. The RGB sensor exhibited significantly higher accuracies, probably due to the blue band, which was found to be very important for classification accuracy and lacking in the multispectral sensor employed here.},
DOI = {10.3390/rs13132631}
}



@Article{electronics10131605,
AUTHOR = {Kathen, Micaela Jara Ten and Flores, Isabel Jurado and Reina, Daniel Gutiérrez},
TITLE = {An Informative Path Planner for a Swarm of ASVs Based on an Enhanced PSO with Gaussian Surrogate Model Components Intended for Water Monitoring Applications},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {1605},
URL = {https://www.mdpi.com/2079-9292/10/13/1605},
ISSN = {2079-9292},
ABSTRACT = {Controlling the water quality of water supplies has always been a critical challenge, and water resource monitoring has become a need in recent years. Manual monitoring is not recommended in the case of large water surfaces for a variety of reasons, including expense and time consumption. In the last few years, researchers have proposed the use of autonomous vehicles for monitoring tasks. Fleets or swarms of vehicles can be deployed to conduct water resource explorations by using path planning techniques to guide the movements of each vehicle. The main idea of this work is the development of a monitoring system for Ypacarai Lake, where a fleet of autonomous surface vehicles will be guided by an improved particle swarm optimization based on the Gaussian process as a surrogate model. The purpose of using the surrogate model is to model water quality parameter behavior and to guide the movements of the vehicles toward areas where samples have not yet been collected; these areas are considered areas with high uncertainty or unexplored areas and areas with high contamination levels of the lake. The results show that the proposed approach, namely the enhanced GP-based PSO, balances appropriately the exploration and exploitation of the surface of Ypacarai Lake. In addition, the proposed approach has been compared with other techniques like the original particle swarm optimization and the particle swarm optimization with Gaussian process uncertainty component in a simulated Ypacarai Lake environment. The obtained results demonstrate the superiority of the proposed enhanced GP-based PSO in terms of mean square error with respect to the other techniques.},
DOI = {10.3390/electronics10131605}
}



@Article{app11136207,
AUTHOR = {Wei, Jiangang and Chen, Gang and Huang, Jizhuo and Xu, Li and Yang, Yan and Wang, Jun and Sadick, Abdul-Manan},
TITLE = {BIM and GIS Applications in Bridge Projects: A Critical Review},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {6207},
URL = {https://www.mdpi.com/2076-3417/11/13/6207},
ISSN = {2076-3417},
ABSTRACT = {In recent years, interest in BIM and GIS applications in civil engineering has been growing. For bridge engineering, BIM/GIS applications such as simulation, visualization, and secondary development have been used to assist practitioners in managing bridge construction and decision-making, including selection of bridge location maintenance decisions. In situ 3D modelling of existing bridges with detailed images from UAV camera has allowed engineers to conduct remote condition assessments of bridges and decide on required maintenance actions. Several studies have investigated the applications of BIM/GIS technology on bridge projects. However, there has been limited focus on reviewing the outcomes of these studies to identify the limitations of BIM and GIS applications on bridge projects. Therefore, the aim of this study was to review the research on BIM/GIS technology applications in bridge projects over the last decade. Using a systematic review process, a total of 90 publications that met the inclusion criteria were reviewed in this study. The review identified the state-of-the-art methods of BIM and GIS applications, respectively, at the planning and design, construction, and operation and maintenance phases of bridge projects. However, the findings point to segregated application of BIM and GIS at all phases of bridge projects. The findings of this study will contribute to guiding practitioners in selecting appropriate BIM and GIS technologies for different aspects of bridge projects.},
DOI = {10.3390/app11136207}
}



@Article{rs13132639,
AUTHOR = {Gautam, Deepak and Ostendorf, Bertram and Pagay, Vinay},
TITLE = {Estimation of Grapevine Crop Coefficient Using a Multispectral Camera on an Unmanned Aerial Vehicle},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2639},
URL = {https://www.mdpi.com/2072-4292/13/13/2639},
ISSN = {2072-4292},
ABSTRACT = {Crop water status and irrigation requirements are of great importance to the horticultural industry due to changing climatic conditions leading to high evaporative demands, drought and water scarcity in semi-arid and arid regions worldwide. Irrigation scheduling strategies based on evapotranspiration (ET), such as regulated deficit irrigation, requires the estimation of seasonal crop coefficients (kc). The ET-driven irrigation decisions for grapevines rely on the sampling of several kc values from each irrigation zone. Here, we present an unmanned aerial vehicle (UAV)-based technique to estimate kc at the single vine level in order to capture the spatial variability of water requirements in a commercial vineyard located in South Australia. A UAV carrying a multispectral sensor is used to extract the spectral, as well as the structural, information of Cabernet Sauvignon grapevines. The spectral and structural information, acquired at the various phenological stages of the vine through two seasons, is used to model kc using univariate (simple linear), multivariate (generalised linear and additive) and machine learning (convolution neural network and random forest) model frameworks. The structural information (e.g., canopy top view area) had the strongest correlation with kc throughout the season (p ≤ 0.001; Pearson R = 0.56), while the spectral indices (e.g., normalised indices) turned less-sensitive post véraison—the onset of ripening in grapes. Combining structural and spectral information improved the model’s performance. Among the investigated predictive models, the random forest predicted kc with the highest accuracy (R2: 0.675, root mean square error: 0.062, and mean absolute error: 0.047). This UAV-based approach improves the precision of irrigation by capturing the spatial variability of kc within a vineyard. Combined with an energy balance model, the water needs of a vineyard can be computed on a weekly or sub-weekly basis for precision irrigation. The UAV-based characterisation of kc can further enhance the water management and irrigation zoning by matching the infrastructure with the spatial variability of the irrigation demand.},
DOI = {10.3390/rs13132639}
}



@Article{su13137497,
AUTHOR = {Wang, Hao and Ren, Yaxin and Meng, Zhijun},
TITLE = {A Farm Management Information System for Semi-Supervised Path Planning and Autonomous Vehicle Control},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {7497},
URL = {https://www.mdpi.com/2071-1050/13/13/7497},
ISSN = {2071-1050},
ABSTRACT = {This paper presents a farm management information system targeting improvements in the ease of use and sustainability of robot farming systems. The system integrates the functionalities of field survey, path planning, monitoring, and controlling agricultural vehicles in real time. Firstly, a Grabcut-based semi-supervised field registration method is proposed for arable field detection from the orthoimage taken by the drone with an RGB camera. It partitions a complex field into simple geometric entities with simple user interaction. The average Mean Intersection over Union is about 0.95 when the field size ranges from 2.74 ha to 5.06 ha. In addition, a desktop software and a web application are developed as the entity of an FMIS. Compared to existing FMISs, this system provides more advanced features in robot farming, while providing simpler user interaction and better results. It allows clients to invoke web services and receive responses independent of programming language and platforms. Moreover, the system is compatible with other services, users, and devices following the open-source access protocol. We have evaluated the system by controlling 5 robot tractors with a 2 Hz communication frequency. The communication protocols will be publicly available to protentional users.},
DOI = {10.3390/su13137497}
}



@Article{app11136220,
AUTHOR = {Cacace, Jonathan and Orozco-Soto, Santos M. and Suarez, Alejandro and Caballero, Alvaro and Orsag, Matko and Bogdan, Stjepan and Vasiljevic, Goran and Ebeid, Emad and Rodriguez, Jose Alberto Acosta and Ollero, Anibal},
TITLE = {Safe Local Aerial Manipulation for the Installation of Devices on Power Lines: AERIAL-CORE First Year Results and Designs},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {6220},
URL = {https://www.mdpi.com/2076-3417/11/13/6220},
ISSN = {2076-3417},
ABSTRACT = {The power grid is an essential infrastructure in any country, comprising thousands of kilometers of power lines that require periodic inspection and maintenance, carried out nowadays by human operators in risky conditions. To increase safety and reduce time and cost with respect to conventional solutions involving manned helicopters and heavy vehicles, the AERIAL-CORE project proposes the development of aerial robots capable of performing aerial manipulation operations to assist human operators in power lines inspection and maintenance, allowing the installation of devices, such as bird flight diverters or electrical spacers, and the fast delivery and retrieval of tools. This manuscript describes the goals and functionalities to be developed for safe local aerial manipulation, presenting the preliminary designs and experimental results obtained in the first year of the project.},
DOI = {10.3390/app11136220}
}



@Article{s21134618,
AUTHOR = {Oliveira, Francisco and Luís, Miguel and Sargento, Susana},
TITLE = {Machine Learning for the Dynamic Positioning of UAVs for Extended Connectivity},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4618},
URL = {https://www.mdpi.com/1424-8220/21/13/4618},
PubMedID = {34283165},
ISSN = {1424-8220},
ABSTRACT = {Unmanned Aerial Vehicle (UAV) networks are an emerging technology, useful not only for the military, but also for public and civil purposes. Their versatility provides advantages in situations where an existing network cannot support all requirements of its users, either because of an exceptionally big number of users, or because of the failure of one or more ground base stations. Networks of UAVs can reinforce these cellular networks where needed, redirecting the traffic to available ground stations. Using machine learning algorithms to predict overloaded traffic areas, we propose a UAV positioning algorithm responsible for determining suitable positions for the UAVs, with the objective of a more balanced redistribution of traffic, to avoid saturated base stations and decrease the number of users without a connection. The tests performed with real data of user connections through base stations show that, in less restrictive network conditions, the algorithm to dynamically place the UAVs performs significantly better than in more restrictive conditions, reducing significantly the number of users without a connection. We also conclude that the accuracy of the prediction is a very important factor, not only in the reduction of users without a connection, but also on the number of UAVs deployed.},
DOI = {10.3390/s21134618}
}



@Article{su13147547,
AUTHOR = {Munawar, Hafiz Suliman and Ullah, Fahim and Qayyum, Siddra and Khan, Sara Imran and Mojtahedi, Mohammad},
TITLE = {UAVs in Disaster Management: Application of Integrated Aerial Imagery and Convolutional Neural Network for Flood Detection},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {7547},
URL = {https://www.mdpi.com/2071-1050/13/14/7547},
ISSN = {2071-1050},
ABSTRACT = {Floods have been a major cause of destruction, instigating fatalities and massive damage to the infrastructure and overall economy of the affected country. Flood-related devastation results in the loss of homes, buildings, and critical infrastructure, leaving no means of communication or travel for the people stuck in such disasters. Thus, it is essential to develop systems that can detect floods in a region to provide timely aid and relief to stranded people, save their livelihoods, homes, and buildings, and protect key city infrastructure. Flood prediction and warning systems have been implemented in developed countries, but the manufacturing cost of such systems is too high for developing countries. Remote sensing, satellite imagery, global positioning system, and geographical information systems are currently used for flood detection to assess the flood-related damages. These techniques use neural networks, machine learning, or deep learning methods. However, unmanned aerial vehicles (UAVs) coupled with convolution neural networks have not been explored in these contexts to instigate a swift disaster management response to minimize damage to infrastructure. Accordingly, this paper uses UAV-based aerial imagery as a flood detection method based on Convolutional Neural Network (CNN) to extract flood-related features from the images of the disaster zone. This method is effective in assessing the damage to local infrastructures in the disaster zones. The study area is based on a flood-prone region of the Indus River in Pakistan, where both pre-and post-disaster images are collected through UAVs. For the training phase, 2150 image patches are created by resizing and cropping the source images. These patches in the training dataset train the CNN model to detect and extract the regions where a flood-related change has occurred. The model is tested against both pre-and post-disaster images to validate it, which has positive flood detection results with an accuracy of 91%. Disaster management organizations can use this model to assess the damages to critical city infrastructure and other assets worldwide to instigate proper disaster responses and minimize the damages. This can help with the smart governance of the cities where all emergent disasters are addressed promptly.},
DOI = {10.3390/su13147547}
}



@Article{rs13142658,
AUTHOR = {Jozdani, Shahab and Chen, Dongmei and Chen, Wenjun and Leblanc, Sylvain G. and Prévost, Christian and Lovitt, Julie and He, Liming and Johnson, Brian A.},
TITLE = {Leveraging Deep Neural Networks to Map Caribou Lichen in High-Resolution Satellite Images Based on a Small-Scale, Noisy UAV-Derived Map},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2658},
URL = {https://www.mdpi.com/2072-4292/13/14/2658},
ISSN = {2072-4292},
ABSTRACT = {Lichen is an important food source for caribou in Canada. Lichen mapping using remote sensing (RS) images could be a challenging task, however, as lichens generally appear in unevenly distributed, small patches, and could resemble surficial features. Moreover, collecting lichen labeled data (reference data) is expensive, which restricts the application of many robust supervised classification models that generally demand a large quantity of labeled data. The goal of this study was to investigate the potential of using a very-high-spatial resolution (1-cm) lichen map of a small sample site (e.g., generated based on a single UAV scene and using field data) to train a subsequent classifier to map caribou lichen over a much larger area (~0.04 km2 vs. ~195 km2) and a lower spatial resolution image (in this case, a 50-cm WorldView-2 image). The limited labeled data from the sample site were also partially noisy due to spatial and temporal mismatching issues. For this, we deployed a recently proposed Teacher-Student semi-supervised learning (SSL) approach (based on U-Net and U-Net++ networks) involving unlabeled data to assist with improving the model performance. Our experiments showed that it was possible to scale-up the UAV-derived lichen map to the WorldView-2 scale with reasonable accuracy (overall accuracy of 85.28% and F1-socre of 84.38%) without collecting any samples directly in the WorldView-2 scene. We also found that our noisy labels were partially beneficial to the SSL robustness because they improved the false positive rate compared to the use of a cleaner training set directly collected within the same area in the WorldView-2 image. As a result, this research opens new insights into how current very high-resolution, small-scale caribou lichen maps can be used for generating more accurate large-scale caribou lichen maps from high-resolution satellite imagery.},
DOI = {10.3390/rs13142658}
}



@Article{rs13142663,
AUTHOR = {Chen, Chuanfa and Guo, Jiaojiao and Wu, Huiming and Li, Yanyan and Shi, Bo},
TITLE = {Performance Comparison of Filtering Algorithms for High-Density Airborne LiDAR Point Clouds over Complex LandScapes},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2663},
URL = {https://www.mdpi.com/2072-4292/13/14/2663},
ISSN = {2072-4292},
ABSTRACT = {Airborne light detection and ranging (LiDAR) technology has become the mainstream data source in geosciences and environmental sciences. Point cloud filtering is a prerequisite for almost all LiDAR-based applications. However, it is challenging to select a suitable filtering algorithm for handling high-density point clouds over complex landscapes. Therefore, to determine an appropriate filter on a specific environment, this paper comparatively assessed the performance of five representative filtering algorithms on six study sites with different terrain characteristics, where three plots are located in urban areas and three in forest areas. The representative filtering methods include simple morphological filter (SMRF), multiresolution hierarchical filter (MHF), slope-based filter (SBF), progressive TIN densification (PTD) and segmentation-based filter (SegBF). Results demonstrate that SMRF performs the best in urban areas, and compared to MHF, SBF, PTD and SegBF, the total error of SMRF is reduced by 1.38%, 48.21%, 48.25% and 31.03%, respectively. MHF outperforms the others in forest areas, and compared to SMRF, SBF, PTD and SegBF, the total error of MHF is reduced by 1.98%, 35.87%, 45.11% and 9.42%, respectively. Moreover, both SMRF and MHF keep a good balance between type I and II errors, which makes the produced DEMs much similar to the references. Overall, SMRF and MHF are recommended for urban and forest areas, respectively, and MHF averagely performs slightly better than SMRF on all areas with respect to kappa coefficient.},
DOI = {10.3390/rs13142663}
}



@Article{rs13142665,
AUTHOR = {Mirzazade, Ali and Popescu, Cosmin and Blanksvärd, Thomas and Täljsten, Björn},
TITLE = {Workflow for Off-Site Bridge Inspection Using Automatic Damage Detection-Case Study of the Pahtajokk Bridge},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2665},
URL = {https://www.mdpi.com/2072-4292/13/14/2665},
ISSN = {2072-4292},
ABSTRACT = {For the inspection of structures, particularly bridges, it is becoming common to replace humans with autonomous systems that use unmanned aerial vehicles (UAV). In this paper, a framework for autonomous bridge inspection using a UAV is proposed with a four-step workflow: (a) data acquisition with an efficient UAV flight path, (b) computer vision comprising training, testing and validation of convolutional neural networks (ConvNets), (c) point cloud generation using intelligent hierarchical dense structure from motion (DSfM), and (d) damage quantification. This workflow starts with planning the most efficient flight path that allows for capturing of the minimum number of images required to achieve the maximum accuracy for the desired defect size, then followed by bridge and damage recognition. Three types of autonomous detection are used: masking the background of the images, detecting areas of potential damage, and pixel-wise damage segmentation. Detection of bridge components by masking extraneous parts of the image, such as vegetation, sky, roads or rivers, can improve the 3D reconstruction in the feature detection and matching stages. In addition, detecting damaged areas involves the UAV capturing close-range images of these critical regions, and damage segmentation facilitates damage quantification using 2D images. By application of DSfM, a denser and more accurate point cloud can be generated for these detected areas, and aligned to the overall point cloud to create a digital model of the bridge. Then, this generated point cloud is evaluated in terms of outlier noise, and surface deviation. Finally, damage that has been detected is quantified and verified, based on the point cloud generated using the Terrestrial Laser Scanning (TLS) method. The results indicate this workflow for autonomous bridge inspection has potential.},
DOI = {10.3390/rs13142665}
}



@Article{s21144654,
AUTHOR = {Łabędź, Piotr and Skabek, Krzysztof and Ozimek, Paweł and Nytko, Mateusz},
TITLE = {Histogram Adjustment of Images for Improving Photogrammetric Reconstruction},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {4654},
URL = {https://www.mdpi.com/1424-8220/21/14/4654},
PubMedID = {34300393},
ISSN = {1424-8220},
ABSTRACT = {The accuracy of photogrammetric reconstruction depends largely on the acquisition conditions and on the quality of input photographs. This paper proposes methods of improving raster images that increase photogrammetric reconstruction accuracy. These methods are based on modifying color image histograms. Special emphasis was placed on the selection of channels of the RGB and CIE L*a*b* color models for further improvement of the reconstruction process. A methodology was proposed for assessing the quality of reconstruction based on premade reference models using positional statistics. The analysis of the influence of image enhancement on reconstruction was carried out for various types of objects. The proposed methods can significantly improve the quality of reconstruction. The superiority of methods based on the luminance channel of the L*a*b* model was demonstrated. Our studies indicated high efficiency of the histogram equalization method (HE), although these results were not highly distinctive for all performed tests.},
DOI = {10.3390/s21144654}
}



@Article{agronomy11071378,
AUTHOR = {Wu, Lifeng and Han, Xiaowei and Islam, Shahidul and Zhai, Shengnan and Zhao, Hui and Zhang, Guoshun and Cui, Gangzhu and Zhang, Feng and Han, Wenliang and You, Xiaosheng and Ju, Zhengchun and Lv, Peng and Zhou, Jiangming and Gao, Qi and Cui, Baoming and Wu, Yanfang and Yang, Zhichao and Liu, Qier and Yang, Fan and Zhang, Jingjuan and Liu, Hang},
TITLE = {Effects of Sowing Mode on Lodging Resistance and Grain Yield in Winter Wheat},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1378},
URL = {https://www.mdpi.com/2073-4395/11/7/1378},
ISSN = {2073-4395},
ABSTRACT = {For improving lodging resistance and increasing grain yield in wheat in the Yellow-Huai River Basin in China, different sowing modes have been investigated. Conventionally, the small-flat-plot sowing mode has been adopted in wheat cultivation. However, this sowing mode leads to heavy lodging and low land use efficiency. In this study, a new sowing mode, high-low-plot sowing mode with two more rows sowed on the high plot, was investigated. Two cultivars, Hengguan 35 and Jimai 44 were used for two seasonal field experiments from 2018 to 2020. The results showed that grain yield improved with the high-low sowing mode by as much as 25% since more spikes per unit area were observed concomitant with reduced stem lodging. The grain yield increase was mainly due to the enhanced spike number per m2, while the lodging resistance was improved through the lowered plant height and the center of gravity height. This research proves that the high-low-plot sowing mode is an improved sowing mode for producing greater grain yield with better lodging resistance in the wheat production area in northern China.},
DOI = {10.3390/agronomy11071378}
}



@Article{rs13142678,
AUTHOR = {Ge, Haixiao and Ma, Fei and Li, Zhenwang and Tan, Zhengzheng and Du, Changwen},
TITLE = {Improved Accuracy of Phenological Detection in Rice Breeding by Using Ensemble Models of Machine Learning Based on UAV-RGB Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2678},
URL = {https://www.mdpi.com/2072-4292/13/14/2678},
ISSN = {2072-4292},
ABSTRACT = {Accurate and timely detection of phenology at plot scale in rice breeding trails is crucial for understanding the heterogeneity of varieties and guiding field management. Traditionally, remote sensing studies of phenology detection have heavily relied on the time-series vegetation index (VI) data. However, the methodology based on time-series VI data was often limited by the temporal resolution. In this study, three types of ensemble models including hard voting (majority voting), soft voting (weighted majority voting) and model stacking, were proposed to identify the principal phenological stages of rice based on unmanned aerial vehicle (UAV) RGB imagery. These ensemble models combined RGB-VIs, color space (e.g., RGB and HSV) and textures derived from UAV-RGB imagery, and five machine learning algorithms (random forest; k-nearest neighbors; Gaussian naïve Bayes; support vector machine and logistic regression) as base models to estimate phenological stages in rice breeding. The phenological estimation models were trained on the dataset of late-maturity cultivars and tested independently on the dataset of early-medium-maturity cultivars. The results indicated that all ensemble models outperform individual machine learning models in all datasets. The soft voting strategy provided the best performance for identifying phenology with the overall accuracy of 90% and 93%, and the mean F1-scores of 0.79 and 0.81, respectively, in calibration and validation datasets, which meant that the overall accuracy and mean F1-scores improved by 5% and 7%, respectively, in comparison with those of the best individual model (GNB), tested in this study. Therefore, the ensemble models demonstrated great potential in improving the accuracy of phenology detection in rice breeding.},
DOI = {10.3390/rs13142678}
}



@Article{rs13142670,
AUTHOR = {Herzig, Paul and Borrmann, Peter and Knauer, Uwe and Klück, Hans-Christian and Kilias, David and Seiffert, Udo and Pillen, Klaus and Maurer, Andreas},
TITLE = {Evaluation of RGB and Multispectral Unmanned Aerial Vehicle (UAV) Imagery for High-Throughput Phenotyping and Yield Prediction in Barley Breeding},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2670},
URL = {https://www.mdpi.com/2072-4292/13/14/2670},
ISSN = {2072-4292},
ABSTRACT = {With advances in plant genomics, plant phenotyping has become a new bottleneck in plant breeding and the need for reliable high-throughput plant phenotyping techniques has emerged. In the face of future climatic challenges, it does not seem appropriate to continue to solely select for grain yield and a few agronomically important traits. Therefore, new sensor-based high-throughput phenotyping has been increasingly used in plant breeding research, with the potential to provide non-destructive, objective and continuous plant characterization that reveals the formation of the final grain yield and provides insights into the physiology of the plant during the growth phase. In this context, we present the comparison of two sensor systems, Red-Green-Blue (RGB) and multispectral cameras, attached to unmanned aerial vehicles (UAV), and investigate their suitability for yield prediction using different modelling approaches in a segregating barley introgression population at three environments with weekly data collection during the entire vegetation period. In addition to vegetation indices, morphological traits such as canopy height, vegetation cover and growth dynamics traits were used for yield prediction. Repeatability analyses and genotype association studies of sensor-based traits were compared with reference values from ground-based phenotyping to test the use of conventional and new traits for barley breeding. The relative height estimation of the canopy by UAV achieved high precision (up to r = 0.93) and repeatability (up to R2 = 0.98). In addition, we found a great overlap of detected significant genotypes between the reference heights and sensor-based heights. The yield prediction accuracy of both sensor systems was at the same level and reached a maximum prediction accuracy of r2 = 0.82 with a continuous increase in precision throughout the entire vegetation period. Due to the lower costs and the consumer-friendly handling of image acquisition and processing, the RGB imagery seems to be more suitable for yield prediction in this study.},
DOI = {10.3390/rs13142670}
}



@Article{rs13142683,
AUTHOR = {Liu, Zhi and Yang, Shuyuan and Feng, Zhixi and Gao, Quanwei and Wang, Min},
TITLE = {Fast SAR Autofocus Based on Ensemble Convolutional Extreme Learning Machine},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2683},
URL = {https://www.mdpi.com/2072-4292/13/14/2683},
ISSN = {2072-4292},
ABSTRACT = {Inaccurate Synthetic Aperture Radar (SAR) navigation information will lead to unknown phase errors in SAR data. Uncompensated phase errors can blur the SAR images. Autofocus is a technique that can automatically estimate phase errors from data. However, existing autofocus algorithms either have poor focusing quality or a slow focusing speed. In this paper, an ensemble learning-based autofocus method is proposed. Convolutional Extreme Learning Machine (CELM) is constructed and utilized to estimate the phase error. However, the performance of a single CELM is poor. To overcome this, a novel, metric-based combination strategy is proposed, combining multiple CELMs to further improve the estimation accuracy. The proposed model is trained with the classical bagging-based ensemble learning method. The training and testing process is non-iterative and fast. Experimental results conducted on real SAR data show that the proposed method has a good trade-off between focusing quality and speed.},
DOI = {10.3390/rs13142683}
}



@Article{su13147662,
AUTHOR = {Zhang, Jingyi and Liu, Jiaxin and Chen, Yaqi and Feng, Xiaochun and Sun, Zilai},
TITLE = {Knowledge Mapping of Machine Learning Approaches Applied in Agricultural Management—A Scientometric Review with CiteSpace},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {7662},
URL = {https://www.mdpi.com/2071-1050/13/14/7662},
ISSN = {2071-1050},
ABSTRACT = {With the continuous development of the Internet of Things, artificial intelligence, big data technology, and intelligent agriculture have become hot topics in agricultural science and technology research. Machine learning is one of the core topics in artificial intelligence, and its application has penetrated every aspect of human social life. In modern agricultural intelligent management and decision making, machine learning plays an important role in crop classification, crop disease and insect pest prediction, agricultural product price prediction, and other aspects of management and decision-making processes in agriculture. To detect and recognize the latest research developing features in a quantitative and visual way, and based on machine learning methods in agricultural management, the authors of this paper used CiteSpace bibliometric methods to analyze relevant studies on the development process and hot spots. High-value references, productive authors, country and institution distributions, journal visualizations, research topics, and emerging trends were reviewed and analyzed. According to the keyword visualization and high-value references, machine learning approaches focus on sustainable agriculture, water resources, remote sensing, and machine learning methods. The research mainly focuses on six topics: learning technology, land environment, reference evapotranspiration, decision support systems for river geography, soil management, and winter wheat, while learning technology has been the most popular in recent years.},
DOI = {10.3390/su13147662}
}



@Article{rs13142705,
AUTHOR = {Mhango, Joseph K. and Harris, Edwin W. and Green, Richard and Monaghan, James M.},
TITLE = {Mapping Potato Plant Density Variation Using Aerial Imagery and Deep Learning Techniques for Precision Agriculture},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2705},
URL = {https://www.mdpi.com/2072-4292/13/14/2705},
ISSN = {2072-4292},
ABSTRACT = {In potato (Solanum tuberosum) production, the number of tubers harvested and their sizes are related to the plant population. Field maps of the spatial variation in plant density can therefore provide a decision support tool for spatially variable harvest timing to optimize tuber sizes by allowing densely populated management zones more tuber-bulking time. Computer vision has been proposed to enumerate plant numbers using images from unmanned aerial vehicles (UAV) but inaccurate predictions in images of merged canopies remains a challenge. Some research has been done on individual potato plant bounding box prediction but there is currently no information on the spatial structure of plant density that these models may reveal and its relationship with potato yield quality attributes. In this study, the Faster Region-based Convolutional Neural Network (FRCNN) framework was used to produce a plant detection model and estimate plant densities across a UAV orthomosaic. Using aerial images of 2 mm ground sampling distance (GSD) collected from potatoes at 40 days after planting, the FRCNN model was trained to an average precision (aP) of 0.78 on unseen testing data. The model was then used to generate predictions on quadrants imposed on orthorectified rasters captured at 14 and 18 days after emergence. After spatially interpolating the plant densities, the resultant surfaces were highly correlated to manually-determined plant density (R2 = 0.80). Further correlations were observed with tuber number (r = 0.54 at Butter Hill; r = 0.53 at Horse Foxhole), marketable tuber weight per plant (r = −0.57 at Buttery Hill; r = −0.56 at Horse Foxhole) and the normalized difference vegetation index (r = 0.61). These results show that accurate two-dimensional maps of plant density can be constructed from UAV imagery with high correlation to important yield components, despite the loss of accuracy of FRCNN models in partially merged canopies.},
DOI = {10.3390/rs13142705}
}



@Article{rs13142706,
AUTHOR = {Huang, Shenjin and Han, Wenting and Chen, Haipeng and Li, Guang and Tang, Jiandong},
TITLE = {Recognizing Zucchinis Intercropped with Sunflowers in UAV Visible Images Using an Improved Method Based on OCRNet},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2706},
URL = {https://www.mdpi.com/2072-4292/13/14/2706},
ISSN = {2072-4292},
ABSTRACT = {An improved semantic segmentation method based on object contextual representations network (OCRNet) is proposed to accurately identify zucchinis intercropped with sunflowers from unmanned aerial vehicle (UAV) visible images taken over Hetao Irrigation District, Inner Mongolia, China. The proposed method improves on the performance of OCRNet in two respects. First, based on the object region context extraction structure of the OCRNet, a branch that uses the channel attention module was added in parallel to rationally use channel feature maps with different weights and reduce the noise of invalid channel features. Secondly, Lovász-Softmax loss was introduced to improve the accuracy of the object region representation in the OCRNet and optimize the final segmentation result at the object level. We compared the proposed method with extant advanced semantic segmentation methods (PSPNet, DeepLabV3+, DNLNet, and OCRNet) in two test areas to test its effectiveness. The results showed that the proposed method achieved the best semantic segmentation effect in the two test areas. More specifically, our method performed better in processing image details, segmenting field edges, and identifying intercropping fields. The proposed method has significant advantages for crop classification and intercropping recognition based on UAV visible images, and these advantages are more substantive in object-level evaluation metrics (mIoU and intercropping IoU).},
DOI = {10.3390/rs13142706}
}



@Article{land10070723,
AUTHOR = {Kelm, Kathrine and Antos, Sarah and McLaren, Robin},
TITLE = {Applying the FFP Approach to Wider Land Management Functions},
JOURNAL = {Land},
VOLUME = {10},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {723},
URL = {https://www.mdpi.com/2073-445X/10/7/723},
ISSN = {2073-445X},
ABSTRACT = {The initial focus of implementing the Fit-for-Purpose Land Administration (FFPLA) methodology was to address the significant, global security of tenure divide. We argue that this land tenure methodology is proving successful in scaling up the provision of security of tenure for developing countries. The increasing adoption of the FFPLA methodology has also opened opportunities and provided flexibility for the innovative use of emerging technologies to accelerate the global roll out of security of tenure, such as the use of autonomous drones and machine learning techniques applied to image analysis. Despite wider adoption of participatory approaches to the recording of land tenure, similar FFP solutions for the other components of land administration services (land value, land use and land development) and land management functions are still evolving. This article therefore explores how the FFP approach can be applied to this wider set of land administration services and land management functions. A case study methodology, using three case studies, is used to determine if the case study approaches meet the FFP criteria. The focus is on the urban environment, drawing mostly from experiences and case studies in the Urban, Disaster Risk Management, Resilience &amp; Land Global Practice of the World Bank. These opportunities for the wider application of the FFP approach and associated principles are being triggered by the innovative use of emerging new data capture technology developments. The paper examines the innovative use of these emerging technologies to identify a common set of data capture techniques and geospatial data that can be shared across a range of urban land administration and management activities. Finally, the paper discusses how individual land projects could be integrated into a more holistic land administration and management program approach and deliver a significant set of socio-economic benefits more quickly. It is found that the FFP approach can be more widely adopted across land administration and land management and in many cases can share a common set of geospatial data. The authors argue that the wider adoption and integration of these new, innovative FFP urban management approaches will require a significant cultural, professional, and institutional change from all stakeholders. Future work will explore more deeply these institutional weaknesses, which will provide a basis for guidance to the World Bank and similar institutions.},
DOI = {10.3390/land10070723}
}



@Article{atmos12070894,
AUTHOR = {Jiang, Feng and Han, Xingyu and Zhang, Wenya and Chen, Guici},
TITLE = {Atmospheric PM2.5 Prediction Using DeepAR Optimized by Sparrow Search Algorithm with Opposition-Based and Fitness-Based Learning},
JOURNAL = {Atmosphere},
VOLUME = {12},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {894},
URL = {https://www.mdpi.com/2073-4433/12/7/894},
ISSN = {2073-4433},
ABSTRACT = {There is an important significance for human health in predicting atmospheric concentration precisely. However, due to the complexity and influence of contingency, atmospheric concentration prediction is a challenging topic. In this paper, we propose a novel hybrid learning method to make point and interval predictions of PM2.5 concentration simultaneously. Firstly, we optimize Sparrow Search Algorithm (SSA) by opposition-based learning, fitness-based learning, and Lévy flight. The experiments show that the improved Sparrow Search Algorithm (FOSSA) outperforms SSA-based algorithms. In addition, the improved Sparrow Search Algorithm (FOSSA) is employed to optimize the initial weights of probabilistic forecasting model with autoregressive recurrent network (DeepAR). Then, the FOSSA–DeepAR learning method is utilized to achieve the point prediction and interval prediction of PM2.5 concentration in Beijing, China. The performance of FOSSA–DeepAR is compared with other hybrid models and a single DeepAR model. Furthermore, hourly data of PM2.5 and O3 concentration in Taian of China, O3 concentration in Beijing, China are used to verify the effectiveness and robustness of the proposed FOSSA–DeepAR learning method. Finally, the empirical results illustrate that the proposed FOSSA–DeepAR learning model can achieve more efficient and accurate predictions in both interval and point prediction.},
DOI = {10.3390/atmos12070894}
}



@Article{rs13142721,
AUTHOR = {Li, Guang and Han, Wenting and Huang, Shenjin and Ma, Weitong and Ma, Qian and Cui, Xin},
TITLE = {Extraction of Sunflower Lodging Information Based on UAV Multi-Spectral Remote Sensing and Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2721},
URL = {https://www.mdpi.com/2072-4292/13/14/2721},
ISSN = {2072-4292},
ABSTRACT = {The rapid and accurate identification of sunflower lodging is important for the assessment of damage to sunflower crops. To develop a fast and accurate method of extraction of information on sunflower lodging, this study improves the inputs to SegNet and U-Net to render them suitable for multi-band image processing. Random forest and two improved deep learning methods are combined with RGB, RGB + NIR, RGB + red-edge, and RGB + NIR + red-edge bands of multi-spectral images captured by a UAV (unmanned aerial vehicle) to construct 12 models to extract information on sunflower lodging. These models are then combined with the method used to ignore edge-related information to predict sunflower lodging. The results of experiments show that the deep learning methods were superior to the random forest method in terms of the obtained lodging information and accuracy. The predictive accuracy of the model constructed by using a combination of SegNet and RGB + NIR had the highest overall accuracy of 88.23%. Adding NIR to RGB improved the accuracy of extraction of the lodging information whereas adding red-edge reduced it. An overlay analysis of the results for the lodging area shows that the extraction error was mainly caused by the failure of the model to recognize lodging in mixed areas and low-coverage areas. The predictive accuracy of information on sunflower lodging when edge-related information was ignored was about 2% higher than that obtained by using the direct splicing method.},
DOI = {10.3390/rs13142721}
}



@Article{f12070902,
AUTHOR = {Theofanous, Nikos and Chrysafis, Irene and Mallinis, Giorgos and Domakinis, Christos and Verde, Natalia and Siahalou, Sofia},
TITLE = {Aboveground Biomass Estimation in Short Rotation Forest Plantations in Northern Greece Using ESA’s Sentinel Medium-High Resolution Multispectral and Radar Imaging Missions},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {902},
URL = {https://www.mdpi.com/1999-4907/12/7/902},
ISSN = {1999-4907},
ABSTRACT = {Plantations of fast-growing forest species such as black locust (Robinia Pseudoacacia) can contribute to energy transformation, mitigate industrial pollution, and restore degraded, marginal land. In this study, the synergistic use of Sentinel-2 and Sentinel-1 time series data is explored for modeling aboveground biomass (AGB) in black locust short-rotation plantations in northeastern Greece. Optimal modeling dates and EO sensor data are also identified through the analysis. Random forest (RF) models were originally developed using monthly Sentinel-2 spectral indices, while, progressively, monthly Sentinel-1 bands were incorporated in the statistical analysis. The highest accuracy was observed for the models generated using Sentinel-2 August composites (R2 = 0.52). The inclusion of Sentinel-1 bands in the spectral indices’ models had a negligible effect on modeling accuracy during the leaf-on period. The correlation and comparative performance of the spectral indices in terms of pairwise correlation with AGB varied among the phenophases of the forest plantations. Overall, the field-measured AGB in the forest plantations plots presented a higher correlation with the optical Sentinel-2 images. The synergy of Sentinel-1 and Sentinel-2 data proved to be a non-efficient approach for improving forest biomass RF models throughout the year within the geographical and environmental context of our study.},
DOI = {10.3390/f12070902}
}



@Article{s21144738,
AUTHOR = {Abdollahi, Abolfazl and Pradhan, Biswajeet},
TITLE = {Urban Vegetation Mapping from Aerial Imagery Using Explainable AI (XAI)},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {4738},
URL = {https://www.mdpi.com/1424-8220/21/14/4738},
PubMedID = {34300478},
ISSN = {1424-8220},
ABSTRACT = {Urban vegetation mapping is critical in many applications, i.e., preserving biodiversity, maintaining ecological balance, and minimizing the urban heat island effect. It is still challenging to extract accurate vegetation covers from aerial imagery using traditional classification approaches, because urban vegetation categories have complex spatial structures and similar spectral properties. Deep neural networks (DNNs) have shown a significant improvement in remote sensing image classification outcomes during the last few years. These methods are promising in this domain, yet unreliable for various reasons, such as the use of irrelevant descriptor features in the building of the models and lack of quality in the labeled image. Explainable AI (XAI) can help us gain insight into these limits and, as a result, adjust the training dataset and model as needed. Thus, in this work, we explain how an explanation model called Shapley additive explanations (SHAP) can be utilized for interpreting the output of the DNN model that is designed for classifying vegetation covers. We want to not only produce high-quality vegetation maps, but also rank the input parameters and select appropriate features for classification. Therefore, we test our method on vegetation mapping from aerial imagery based on spectral and textural features. Texture features can help overcome the limitations of poor spectral resolution in aerial imagery for vegetation mapping. The model was capable of obtaining an overall accuracy (OA) of 94.44% for vegetation cover mapping. The conclusions derived from SHAP plots demonstrate the high contribution of features, such as Hue, Brightness, GLCM_Dissimilarity, GLCM_Homogeneity, and GLCM_Mean to the output of the proposed model for vegetation mapping. Therefore, the study indicates that existing vegetation mapping strategies based only on spectral characteristics are insufficient to appropriately classify vegetation covers.},
DOI = {10.3390/s21144738}
}



@Article{ijgi10070482,
AUTHOR = {Xing, Zhizhong and Zhao, Shuanfeng and Guo, Wei and Guo, Xiaojun and Wang, Yuan},
TITLE = {Processing Laser Point Cloud in Fully Mechanized Mining Face Based on DGCNN},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {482},
URL = {https://www.mdpi.com/2220-9964/10/7/482},
ISSN = {2220-9964},
ABSTRACT = {Point cloud data can accurately and intuitively reflect the spatial relationship between the coal wall and underground fully mechanized mining equipment. However, the indirect method of point cloud feature extraction based on deep neural networks will lose some of the spatial information of the point cloud, while the direct method will lose some of the local information of the point cloud. Therefore, we propose the use of dynamic graph convolution neural network (DGCNN) to extract the geometric features of the sphere in the point cloud of the fully mechanized mining face (FMMF) in order to obtain the position of the sphere (marker) in the point cloud of the FMMF, thus providing a direct basis for the subsequent transformation of the FMMF coordinates to the national geodetic coordinates with the sphere as the intermediate medium. Firstly, we completed the production of a diversity sphere point cloud (training set) and an FMMF point cloud (test set). Secondly, we further improved the DGCNN to enhance the effect of extracting the geometric features of the sphere in the FMMF. Finally, we compared the effect of the improved DGCNN with that of PointNet and PointNet++. The results show the correctness and feasibility of using DGCNN to extract the geometric features of point clouds in the FMMF and provide a new method for the feature extraction of point clouds in the FMMF. At the same time, the results provide a direct early guarantee for analyzing the point cloud data of the FMMF under the national geodetic coordinate system in the future. This can provide an effective basis for the straightening and inclining adjustment of scraper conveyors, and it is of great significance for the transparent, unmanned, and intelligent mining of the FMMF.},
DOI = {10.3390/ijgi10070482}
}



@Article{rs13142742,
AUTHOR = {Liu, Chong and Huang, Huabing and Hui, Fengming and Zhang, Ziqian and Cheng, Xiao},
TITLE = {Fine-Resolution Mapping of Pan-Arctic Lake Ice-Off Phenology Based on Dense Sentinel-2 Time Series Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2742},
URL = {https://www.mdpi.com/2072-4292/13/14/2742},
ISSN = {2072-4292},
ABSTRACT = {The timing of lake ice-off regulates biotic and abiotic processes in Arctic ecosystems. Due to the coarse spatial and temporal resolution of available satellite data, previous studies mainly focused on lake-scale investigations of melting/freezing, hindering the detection of subtle patterns within heterogeneous landscapes. To fill this knowledge gap, we developed a new approach for fine-resolution mapping of Pan-Arctic lake ice-off phenology. Using the Scene Classification Layer data derived from dense Sentinel-2 time series images, we estimated the pixel-by-pixel ice break-up end date information by seeking the transition time point when the pixel is completely free of ice. Applying this approach on the Google Earth Engine platform, we mapped the spatial distribution of the break-up end date for 45,532 lakes across the entire Arctic (except for Greenland) for the year 2019. The evaluation results suggested that our estimations matched well with both in situ measurements and an existing lake ice phenology product. Based on the generated map, we estimated that the average break-up end time of Pan-Arctic lakes is 172 ± 13.4 (measured in day of year) for the year 2019. The mapped lake ice-off phenology exhibits a latitudinal gradient, with a linear slope of 1.02 days per degree from 55°N onward. We also demonstrated the importance of lake and landscape characteristics in affecting spring lake ice melting. The proposed approach offers new possibilities for monitoring the seasonal Arctic lake ice freeze–thaw cycle, benefiting the ongoing efforts of combating and adapting to climate change.},
DOI = {10.3390/rs13142742}
}



@Article{rs13142751,
AUTHOR = {Wengert, Matthias and Piepho, Hans-Peter and Astor, Thomas and Graß, Rüdiger and Wijesingha, Jayan and Wachendorf, Michael},
TITLE = {Assessing Spatial Variability of Barley Whole Crop Biomass Yield and Leaf Area Index in Silvoarable Agroforestry Systems Using UAV-Borne Remote Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2751},
URL = {https://www.mdpi.com/2072-4292/13/14/2751},
ISSN = {2072-4292},
ABSTRACT = {Agroforestry systems (AFS) can provide positive ecosystem services while at the same time stabilizing yields under increasingly common drought conditions. The effect of distance to trees in alley cropping AFS on yield-related crop parameters has predominantly been studied using point data from transects. Unmanned aerial vehicles (UAVs) offer a novel possibility to map plant traits with high spatial resolution and coverage. In the present study, UAV-borne red, green, blue (RGB) and multispectral imagery was utilized for the prediction of whole crop dry biomass yield (DM) and leaf area index (LAI) of barley at three different conventionally managed silvoarable alley cropping agroforestry sites located in Germany. DM and LAI were modelled using random forest regression models with good accuracies (DM: R² 0.62, nRMSEp 14.9%, LAI: R² 0.92, nRMSEp 7.1%). Important variables for prediction included normalized reflectance, vegetation indices, texture and plant height. Maps were produced from model predictions for spatial analysis, showing significant effects of distance to trees on DM and LAI. Spatial patterns differed greatly between the sampled sites and suggested management and soil effects overriding tree effects across large portions of 96 m wide crop alleys, thus questioning alleged impacts of AFS tree rows on yield distribution in intensively managed barley populations. Models based on UAV-borne imagery proved to be a valuable novel tool for prediction of DM and LAI at high accuracies, revealing spatial variability in AFS with high spatial resolution and coverage.},
DOI = {10.3390/rs13142751}
}



@Article{rs13142755,
AUTHOR = {Fang, Peng and Yan, Nana and Wei, Panpan and Zhao, Yifan and Zhang, Xiwang},
TITLE = {Aboveground Biomass Mapping of Crops Supported by Improved CASA Model and Sentinel-2 Multispectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2755},
URL = {https://www.mdpi.com/2072-4292/13/14/2755},
ISSN = {2072-4292},
ABSTRACT = {The net primary productivity (NPP) and aboveground biomass mapping of crops based on remote sensing technology are not only conducive to understanding the growth and development of crops but can also be used to monitor timely agricultural information, thereby providing effective decision making for agricultural production management. To solve the saturation problem of the NDVI in the aboveground biomass mapping of crops, the original CASA model was improved using narrow-band red-edge information, which is sensitive to vegetation chlorophyll variation, and the fraction of photosynthetically active radiation (FPAR), NPP, and aboveground biomass of winter wheat and maize were mapped in the main growing seasons. Moreover, in this study, we deeply analyzed the seasonal change trends of crops’ biophysical parameters in terms of the NDVI, FPAR, actual light use efficiency (LUE), and their influence on aboveground biomass. Finally, to analyze the uncertainty of the aboveground biomass mapping of crops, we further discussed the inversion differences of FPAR with different vegetation indices. The results demonstrated that the inversion accuracies of the FPAR of the red-edge normalized vegetation index (NDVIred-edge) and red-edge simple ratio vegetation index (SRred-edge) were higher than those of the original CASA model. Compared with the reference data, the accuracy of aboveground biomass estimated by the improved CASA model was 0.73 and 0.70, respectively, which was 0.21 and 0.13 higher than that of the original CASA model. In addition, the analysis of the FPAR inversions of different vegetation indices showed that the inversion accuracies of the red-edge vegetation indices NDVIred-edge and SRred-edge were higher than those of the other vegetation indices, which confirmed that the vegetation indices involving red-edge information can more effectively retrieve FPAR and aboveground biomass of crops.},
DOI = {10.3390/rs13142755}
}



@Article{f12070914,
AUTHOR = {Ahmad, Adeel and Gilani, Hammad and Ahmad, Sajid Rashid},
TITLE = {Forest Aboveground Biomass Estimation and Mapping through High-Resolution Optical Satellite Imagery—A Literature Review},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {914},
URL = {https://www.mdpi.com/1999-4907/12/7/914},
ISSN = {1999-4907},
ABSTRACT = {This paper provides a comprehensive literature review on forest aboveground biomass (AGB) estimation and mapping through high-resolution optical satellite imagery (≤5 m spatial resolution). Based on the literature review, 44 peer-reviewed journal articles were published in 15 years (2004–2019). Twenty-one studies were conducted in Asia, eight in North America and Africa, five in South America, and four in Europe. This review article gives a glance at the published methodologies for AGB prediction modeling and validation. The literature review suggested that, along with the integration of other sensors, QuickBird, WorldView-2, and IKONOS satellite images were most widely used for AGB estimations, with higher estimation accuracies. All studies were grouped into six satellite-derived independent variables, including tree crown, image textures, tree shadow fraction, canopy height, vegetation indices, and multiple variables. Using these satellite-derived independent variables, most of the studies used linear regression (41%), while 30% used linear multiple regression and 18% used non-linear (machine learning) regression, while very few (11%) studies used non-linear (multiple and exponential) regression for estimating AGB. In the context of global forest AGB estimations and monitoring, the advantages, strengths, and limitations were discussed to achieve better accuracy and transparency towards the performance-based payment mechanism of the REDD+ program. Apart from technical limitations, we realized that very few studies talked about real-time monitoring of AGB or quantifying AGB change, a dimension that needs exploration.},
DOI = {10.3390/f12070914}
}



@Article{rs13142763,
AUTHOR = {Salum, Rafaela B. and Robinson, Sharon A. and Rogers, Kerrylee},
TITLE = {A Validated and Accurate Method for Quantifying and Extrapolating Mangrove Above-Ground Biomass Using LiDAR Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2763},
URL = {https://www.mdpi.com/2072-4292/13/14/2763},
ISSN = {2072-4292},
ABSTRACT = {LiDAR data and derived canopy height models can provide useful information about mangrove tree heights that assist with quantifying mangrove above-ground biomass. This study presents a validated method for quantifying mangrove heights using LiDAR data and calibrating this against plot-based estimates of above-ground biomass. This approach was initially validated for the mangroves of Darwin Harbour, in Northern Australia, which are structurally complex and have high species diversity. Established relationships were then extrapolated to the nearby West Alligator River, which provided the opportunity to quantify biomass at a remote location where intensive fieldwork was limited. Relationships between LiDAR-derived mangrove heights and mean tree height per plot were highly robust for Ceriops tagal, Rhizophora stylosa and Sonneratia alba (r2 = 0.84–0.94, RMSE = 0.03–0.91 m; RMSE% = 0.07%–11.27%), and validated well against an independent dataset. Additionally, relationships between the derived canopy height model and field-based estimates of above-ground biomass were also robust and validated (r2 = 0.73–0.90, RMSE = 141.4 kg–1098.58 kg, RMSE% of 22.94–39.31%). Species-specific estimates of tree density per plot were applied in order to align biomass of individual trees with the resolution of the canopy height model. The total above-ground biomass at Darwin Harbour was estimated at 120 t ha−1 and comparisons with prior estimates of mangrove above-ground biomass confirmed the accuracy of this assessment. To establish whether accurate and validated relationships could be extrapolated elsewhere, the established relationships were applied to a LiDAR-derived canopy height model at nearby West Alligator River. Above-ground biomass derived from extrapolated relationships was estimated at 206 t ha−1, which compared well with prior biomass estimates, confirming that this approach can be extrapolated to remote locations, providing the mangrove forests are biogeographically similar. The validated method presented in this study can be used for reporting mangrove carbon storage under national obligations, and is useful for quantifying carbon within various markets.},
DOI = {10.3390/rs13142763}
}



@Article{agronomy11071409,
AUTHOR = {Anderson, Nicholas Todd and Walsh, Kerry Brian and Wulfsohn, Dvoralai},
TITLE = {Technologies for Forecasting Tree Fruit Load and Harvest Timing—From Ground, Sky and Time},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1409},
URL = {https://www.mdpi.com/2073-4395/11/7/1409},
ISSN = {2073-4395},
ABSTRACT = {The management and marketing of fruit requires data on expected numbers, size, quality and timing. Current practice estimates orchard fruit load based on the qualitative assessment of fruit number per tree and historical orchard yield, or manually counting a subsample of trees. This review considers technological aids assisting these estimates, in terms of: (i) improving sampling strategies by the number of units to be counted and their selection; (ii) machine vision for the direct measurement of fruit number and size on the canopy; (iii) aerial or satellite imagery for the acquisition of information on tree structural parameters and spectral indices, with the indirect assessment of fruit load; (iv) models extrapolating historical yield data with knowledge of tree management and climate parameters, and (v) technologies relevant to the estimation of harvest timing such as heat units and the proximal sensing of fruit maturity attributes. Machine vision is currently dominating research outputs on fruit load estimation, while the improvement of sampling strategies has potential for a widespread impact. Techniques based on tree parameters and modeling offer scalability, but tree crops are complicated (perennialism). The use of machine vision for flowering estimates, fruit sizing, external quality evaluation is also considered. The potential synergies between technologies are highlighted.},
DOI = {10.3390/agronomy11071409}
}



@Article{rs13142776,
AUTHOR = {Li, Yong and Shao, Zhenfeng and Huang, Xiao and Cai, Bowen and Peng, Song},
TITLE = {Meta-FSEO: A Meta-Learning Fast Adaptation with Self-Supervised Embedding Optimization for Few-Shot Remote Sensing Scene Classification},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2776},
URL = {https://www.mdpi.com/2072-4292/13/14/2776},
ISSN = {2072-4292},
ABSTRACT = {The performance of deep learning is heavily influenced by the size of the learning samples, whose labeling process is time consuming and laborious. Deep learning algorithms typically assume that the training and prediction data are independent and uniformly distributed, which is rarely the case given the attributes and properties of different data sources. In remote sensing images, representations of urban land surfaces can vary across regions and by season, demanding rapid generalization of these surfaces in remote sensing data. In this study, we propose Meta-FSEO, a novel model for improving the performance of few-shot remote sensing scene classification in varying urban scenes. The proposed Meta-FSEO model deploys self-supervised embedding optimization for adaptive generalization in new tasks such as classifying features in new urban regions that have never been encountered during the training phase, thus balancing the requirements for feature classification tasks between multiple images collected at different times and places. We also created a loss function by weighting the contrast losses and cross-entropy losses. The proposed Meta-FSEO demonstrates a great generalization capability in remote sensing scene classification among different cities. In a five-way one-shot classification experiment with the Sentinel-1/2 Multi-Spectral (SEN12MS) dataset, the accuracy reached 63.08%. In a five-way five-shot experiment on the same dataset, the accuracy reached 74.29%. These results indicated that the proposed Meta-FSEO model outperformed both the transfer learning-based algorithm and two popular meta-learning-based methods, i.e., MAML and Meta-SGD.},
DOI = {10.3390/rs13142776}
}



@Article{rs13142778,
AUTHOR = {Lai, Zhengchao and Liu, Fei and Guo, Shangwei and Meng, Xiantong and Han, Shaokun and Li, Wenhao},
TITLE = {Onboard Real-Time Dense Reconstruction in Large Terrain Scene Using Embedded UAV Platform},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2778},
URL = {https://www.mdpi.com/2072-4292/13/14/2778},
ISSN = {2072-4292},
ABSTRACT = {Using unmanned aerial vehicles (UAVs) for remote sensing has the advantages of high flexibility, convenient operation, low cost, and wide application range. It fills the need for rapid acquisition of high-resolution aerial images in modern photogrammetry applications. Due to the insufficient parallaxes and the computation-intensive process, dense real-time reconstruction for large terrain scenes is a considerable challenge. To address these problems, we proposed a novel SLAM-based MVS (Multi-View-Stereo) approach, which can incrementally generate a dense 3D (three-dimensional) model of the terrain by using the continuous image stream during the flight. The pipeline of the proposed methodology starts with pose estimation based on SLAM algorithm. The tracked frames were then selected by a novel scene-adaptive keyframe selection method to construct a sliding window frame-set. This was followed by depth estimation using a flexible search domain approach, which can improve accuracy without increasing the iterate time or memory consumption. The whole system proposed in this study was implemented on the embedded GPU based on an UAV platform. We proposed a highly parallel and memory-efficient CUDA-based depth computing architecture, enabling the system to achieve good real-time performance. The evaluation experiments were carried out in both simulation and real-world environments. A virtual large terrain scene was built using the Gazebo simulator. The simulated UAV equipped with an RGB-D camera was used to obtain synthetic evaluation datasets, which were divided by flight altitudes (800-, 1000-, 1200 m) and terrain height difference (100-, 200-, 300 m). In addition, the system has been extensively tested on various types of real scenes. Comparison with commercial 3D reconstruction software is carried out to evaluate the precision in real-world data. According to the results on the synthetic datasets, over 93.462% of the estimation with absolute error distance of less then 0.9%. In the real-world dataset captured at 800 m flight height, more than 81.27% of our estimated point cloud are less then 5 m difference with the results of Photoscan. All evaluation experiments show that the proposed approach outperforms the state-of-the-art ones in terms of accuracy and efficiency.},
DOI = {10.3390/rs13142778}
}



@Article{su13147902,
AUTHOR = {Alqahtani, Fahad K. and El Qasaby, Ahmed R. and Abotaleb, Ibrahim S.},
TITLE = {Urban Development and Sustainable Utilization: Challenges and Solutions},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {7902},
URL = {https://www.mdpi.com/2071-1050/13/14/7902},
ISSN = {2071-1050},
ABSTRACT = {Many countries are contemplating a smart sustainable approach to the next generation of cities. However, there are many obstacles to achieve this objective, such as planning and implementing sustainable dimensions. The aim of this study is to (1) investigate the level of importance of the different sustainable dimensions in Riyadh and (2) distinguish the effect of two proposed solutions on dimensions for a smart approach to rank the proposed solutions based on their level of impact in Riyadh. In this study, the sustainability dimensions are six main measurable criteria that include Smart Economy, Smart Mobility, Smart Environment, Smart People, Smart Governance, and Smart Living. The research also utilized a multi-step methodology that involved an expert-based survey and fuzzy analytic hierarchy process (F-AHP) to assess the performance indices of components for a smart method in Riyadh and evaluate the proposed solutions, namely, the construction of a metro network to link all of Riyadh to align with the government objective for 2030, and encouraging the construction of smart buildings through Leadership in Energy and Environmental Design (LEED) certification. The results show that Smart People, Smart Mobility, and Smart Living were the three most important sustainable indices for Riyadh. Furthermore, the results of the proposed construction projects illustrate that both projects had the same impact on five of the six sustainable indices, but that the metro project had a significantly higher impact on one of the indices. The study is also envisaged to aid decision-makers in prioritizing the upcoming public construction projects. Finally, this is the first study of its kind to address ranking real public construction projects in terms of sustainable development.},
DOI = {10.3390/su13147902}
}



@Article{rs13142780,
AUTHOR = {Shukla, Shivang and Tiddeman, Bernard and Miles, Helen C.},
TITLE = {A Wide Area Multiview Static Crowd Estimation System Using UAV and 3D Training Simulator},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2780},
URL = {https://www.mdpi.com/2072-4292/13/14/2780},
ISSN = {2072-4292},
ABSTRACT = {Crowd size estimation is a challenging problem, especially when the crowd is spread over a significant geographical area. It has applications in monitoring of rallies and demonstrations and in calculating the assistance requirements in humanitarian disasters. Therefore, accomplishing a crowd surveillance system for large crowds constitutes a significant issue. UAV-based techniques are an appealing choice for crowd estimation over a large region, but they present a variety of interesting challenges, such as integrating per-frame estimates through a video without counting individuals twice. Large quantities of annotated training data are required to design, train, and test such a system. In this paper, we have first reviewed several crowd estimation techniques, existing crowd simulators and data sets available for crowd analysis. Later, we have described a simulation system to provide such data, avoiding the need for tedious and error-prone manual annotation. Then, we have evaluated synthetic video from the simulator using various existing single-frame crowd estimation techniques. Our findings show that the simulated data can be used to train and test crowd estimation, thereby providing a suitable platform to develop such techniques. We also propose an automated UAV-based 3D crowd estimation system that can be used for approximately static or slow-moving crowds, such as public events, political rallies, and natural or man-made disasters. We evaluate the results by applying our new framework to a variety of scenarios with varying crowd sizes. The proposed system gives promising results using widely accepted metrics including MAE, RMSE, Precision, Recall, and F1 score to validate the results.},
DOI = {10.3390/rs13142780}
}



@Article{su13147925,
AUTHOR = {Munawar, Hafiz Suliman and Hammad, Ahmed W. A. and Waller, S. Travis and Thaheem, Muhammad Jamaluddin and Shrestha, Asheem},
TITLE = {An Integrated Approach for Post-Disaster Flood Management Via the Use of Cutting-Edge Technologies and UAVs: A Review},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {7925},
URL = {https://www.mdpi.com/2071-1050/13/14/7925},
ISSN = {2071-1050},
ABSTRACT = {Rapid advances that improve flood management have facilitated the disaster response by providing first aid services, finding safe routes, maintaining communication and developing flood maps. Different technologies such as image processing, satellite imagery, synthetic imagery and integrated approaches have been extensively analysed in the literature for disaster operations. There is a need to review cutting-edge technologies for flood management. This paper presents a review of the latest advancements in the flood management domain based on image processing, artificial intelligence and integrated approaches with a focus on post-disaster. It answers the following research questions: (1) What are the latest developments in image processing for flood management in a post-disaster scenario? (2) What are the latest techniques for flood management based on artificial intelligence in a post-disaster scenario? (3) What are the existing gaps in the selected technologies for post-disaster? (4) How can the authorities improve the existing post-disaster management operation with cutting-edge technologies? A novel framework has been proposed to optimise flood management with the application of a holistic approach.},
DOI = {10.3390/su13147925}
}



@Article{rs13142789,
AUTHOR = {Chemisky, Bertrand and Menna, Fabio and Nocerino, Erica and Drap, Pierre},
TITLE = {Underwater Survey for Oil and Gas Industry: A Review of Close Range Optical Methods},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2789},
URL = {https://www.mdpi.com/2072-4292/13/14/2789},
ISSN = {2072-4292},
ABSTRACT = {In both the industrial and scientific fields, the need for very high-resolution cartographic data is constantly increasing. With the aging of offshore subsea assets, it is very important to plan and maintain the longevity of structures, equipment, and systems. Inspection, maintenance, and repair (IMR) of subsea structures are key components of an overall integrity management system that aims to reduce the risk of failure and extend the life of installations. The acquisition of very detailed data during the inspection phase is a technological challenge, especially since offshore installations are sometimes deployed in extreme conditions (e.g., depth, hydrodynamics, visibility). After a review of high resolution mapping techniques for underwater environment, this article will focus on optical sensors that can satisfy the requirements of the offshore industry by assessing their relevance and degree of maturity. These requirements concern the resolution and accuracy but also cost, ease of implementation, and qualification. With the evolution of embedded computing resources, in-vehicle optical survey solutions are becoming increasingly important in the landscape of large-scale mapping solutions and more and more off-the-shelf systems are now available. The issues raised in this review are mainly related to the qualification of the results produced by optical systems and their limitations to cover all the needs expressed by the oil and gas industry field. Interesting qualification works of these solutions are presented in this paper as well as the use of online processing tools such as visual odometry or VSLAM to guide the data acquisition and pre-qualified survey. Finally, it seems interesting to combine acoustic and optical technologies in order to extend the field of application of these methods to low visibility conditions, which remains one of the main limiting factors in the generalization of the use of optical sensors in high resolution underwater cartography applications.},
DOI = {10.3390/rs13142789}
}



@Article{s21144845,
AUTHOR = {Li, Jingbo and Li, Changchun and Fei, Shuaipeng and Ma, Chunyan and Chen, Weinan and Ding, Fan and Wang, Yilin and Li, Yacong and Shi, Jinjin and Xiao, Zhen},
TITLE = {Wheat Ear Recognition Based on RetinaNet and Transfer Learning},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {4845},
URL = {https://www.mdpi.com/1424-8220/21/14/4845},
PubMedID = {34300585},
ISSN = {1424-8220},
ABSTRACT = {The number of wheat ears is an essential indicator for wheat production and yield estimation, but accurately obtaining wheat ears requires expensive manual cost and labor time. Meanwhile, the characteristics of wheat ears provide less information, and the color is consistent with the background, which can be challenging to obtain the number of wheat ears required. In this paper, the performance of Faster regions with convolutional neural networks (Faster R-CNN) and RetinaNet to predict the number of wheat ears for wheat at different growth stages under different conditions is investigated. The results show that using the Global WHEAT dataset for recognition, the RetinaNet method, and the Faster R-CNN method achieve an average accuracy of 0.82 and 0.72, with the RetinaNet method obtaining the highest recognition accuracy. Secondly, using the collected image data for recognition, the R2 of RetinaNet and Faster R-CNN after transfer learning is 0.9722 and 0.8702, respectively, indicating that the recognition accuracy of the RetinaNet method is higher on different data sets. We also tested wheat ears at both the filling and maturity stages; our proposed method has proven to be very robust (the R2 is above 90). This study provides technical support and a reference for automatic wheat ear recognition and yield estimation.},
DOI = {10.3390/s21144845}
}



@Article{drones5030061,
AUTHOR = {Messina, Gaetano and Praticò, Salvatore and Badagliacca, Giuseppe and Di Fazio, Salvatore and Monti, Michele and Modica, Giuseppe},
TITLE = {Monitoring Onion Crop “Cipolla Rossa di Tropea Calabria IGP” Growth and Yield Response to Varying Nitrogen Fertilizer Application Rates Using UAV Imagery},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {61},
URL = {https://www.mdpi.com/2504-446X/5/3/61},
ISSN = {2504-446X},
ABSTRACT = {Remote sensing (RS) platforms such as unmanned aerial vehicles (UAVs) represent an essential source of information in precision agriculture (PA) as they are able to provide images on a daily basis and at a very high resolution. In this framework, this study aims to identify the optimal level of nitrogen (N)-based nutrients for improved productivity in an onion field of “Cipolla Rossa di Tropea” (Tropea red onion). Following an experiment that involved the arrangement of nine plots in the onion field in a randomized complete block design (RCBD), with three replications, three different levels of N fertilization were compared: N150 (150 kg N ha−1), N180 (180 kg N ha−1), and e N210 (210 kg N ha−1). The crop cycle was monitored using multispectral (MS) UAV imagery, producing vigor maps and taking into account the yield of data. The soil-adjusted vegetation index (SAVI) was used to monitor the vigor of the crop. In addition, the coverage’s class onion was spatially identified using geographical object-based image classification (GEOBIA), observing differences in SAVI values obtained in plots subjected to differentiated N fertilizer treatment. The information retrieved from the analysis of soil properties (electrical conductivity, ammonium and nitrate nitrogen), yield performance and mean SAVI index data from each field plot showed significant relationships between the different indicators investigated. A higher onion yield was evident in plot N180, in which SAVI values were higher based on the production data.},
DOI = {10.3390/drones5030061}
}



@Article{rs13142792,
AUTHOR = {Jiang, Fugen and Chen, Chuanshi and Li, Chengjie and Kutia, Mykola and Sun, Hua},
TITLE = {A Novel Spatial Simulation Method for Mapping the Urban Forest Carbon Density in Southern China by the Google Earth Engine},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2792},
URL = {https://www.mdpi.com/2072-4292/13/14/2792},
ISSN = {2072-4292},
ABSTRACT = {Urban forest is an important component of terrestrial ecosystems and is highly related to global climate change. However, because of complex city landscapes, deriving the spatial distribution of urban forest carbon density and conducting accuracy assessments are difficult. This study proposes a novel spatial simulation method, optimized geographically weighted logarithm regression (OGWLR), using Landsat 8 data acquired by the Google Earth Engine (GEE) and field survey data to map the forest carbon density of Shenzhen city in southern China. To verify the effectiveness of the novel method, multiple linear regression (MLR), k-nearest neighbors (kNN), random forest (RF) and geographically weighted regression (GWR) models were established for comparison. The results showed that OGWLR achieved the highest coefficient of determination (R2 = 0.54) and the lowest root mean square error (RMSE = 13.28 Mg/ha) among all estimation models. In addition, OGWLR achieved a more consistent spatial distribution of carbon density with the actual situation. The carbon density of the forests in the study area was large in the central and western regions and coastal areas and small in the building and road areas. Therefore, this method can provide a new reference for urban forest carbon density estimation and mapping.},
DOI = {10.3390/rs13142792}
}



@Article{rs13142794,
AUTHOR = {Ran, Shuhao and Gao, Xianjun and Yang, Yuanwei and Li, Shaohua and Zhang, Guangbin and Wang, Ping},
TITLE = {Building Multi-Feature Fusion Refined Network for Building Extraction from High-Resolution Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2794},
URL = {https://www.mdpi.com/2072-4292/13/14/2794},
ISSN = {2072-4292},
ABSTRACT = {Deep learning approaches have been widely used in building automatic extraction tasks and have made great progress in recent years. However, the missing detection and wrong detection causing by spectrum confusion is still a great challenge. The existing fully convolutional networks (FCNs) cannot effectively distinguish whether the feature differences are from one building or the building and its adjacent non-building objects. In order to overcome the limitations, a building multi-feature fusion refined network (BMFR-Net) was presented in this paper to extract buildings accurately and completely. BMFR-Net is based on an encoding and decoding structure, mainly consisting of two parts: the continuous atrous convolution pyramid (CACP) module and the multiscale output fusion constraint (MOFC) structure. The CACP module is positioned at the end of the contracting path and it effectively minimizes the loss of effective information in multiscale feature extraction and fusion by using parallel continuous small-scale atrous convolution. To improve the ability to aggregate semantic information from the context, the MOFC structure performs predictive output at each stage of the expanding path and integrates the results into the network. Furthermore, the multilevel joint weighted loss function effectively updates parameters well away from the output layer, enhancing the learning capacity of the network for low-level abstract features. The experimental results demonstrate that the proposed BMFR-Net outperforms the other five state-of-the-art approaches in both visual interpretation and quantitative evaluation.},
DOI = {10.3390/rs13142794}
}



@Article{rs13142796,
AUTHOR = {Vandendaele, Bastien and Fournier, Richard A. and Vepakomma, Udayalakshmi and Pelletier, Gaetan and Lejeune, Philippe and Martin-Ducup, Olivier},
TITLE = {Estimation of Northern Hardwood Forest Inventory Attributes Using UAV Laser Scanning (ULS): Transferability of Laser Scanning Methods and Comparison of Automated Approaches at the Tree- and Stand-Level},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2796},
URL = {https://www.mdpi.com/2072-4292/13/14/2796},
ISSN = {2072-4292},
ABSTRACT = {UAV laser scanning (ULS) has the potential to support forest operations since it provides high-density data with flexible operational conditions. This study examined the use of ULS systems to estimate several tree attributes from an uneven-aged northern hardwood stand. We investigated: (1) the transferability of raster-based and bottom-up point cloud-based individual tree detection (ITD) algorithms to ULS data; and (2) automated approaches to the retrieval of tree-level (i.e., height, crown diameter (CD), DBH) and stand-level (i.e., tree count, basal area (BA), DBH-distribution) forest inventory attributes. These objectives were studied under leaf-on and leaf-off canopy conditions. Results achieved from ULS data were cross-compared with ALS and TLS to better understand the potential and challenges faced by different laser scanning systems and methodological approaches in hardwood forest environments. The best results that characterized individual trees from ULS data were achieved under leaf-off conditions using a point cloud-based bottom-up ITD. The latter outperformed the raster-based ITD, improving the accuracy of tree detection (from 50% to 71%), crown delineation (from R2 = 0.29 to R2 = 0.61), and prediction of tree DBH (from R2 = 0.36 to R2 = 0.67), when compared with values that were estimated from reference TLS data. Major improvements were observed for the detection of trees in the lower canopy layer (from 9% with raster-based ITD to 51% with point cloud-based ITD) and in the intermediate canopy layer (from 24% with raster-based ITD to 59% with point cloud-based ITD). Under leaf-on conditions, LiDAR data from aerial systems include substantial signal occlusion incurred by the upper canopy. Under these conditions, the raster-based ITD was unable to detect low-level canopy trees (from 5% to 15% of trees detected from lower and intermediate canopy layers, respectively), resulting in a tree detection rate of about 40% for both ULS and ALS data. The cylinder-fitting method used to estimate tree DBH under leaf-off conditions did not meet inventory standards when compared to TLS DBH, resulting in RMSE = 7.4 cm, Bias = 3.1 cm, and R2 = 0.75. Yet, it yielded more accurate estimates of the BA (+3.5%) and DBH-distribution of the stand than did allometric models −12.9%), when compared with in situ field measurements. Results suggest that the use of bottom-up ITD on high-density ULS data from leaf-off hardwood forest leads to promising results when estimating trees and stand attributes, which opens up new possibilities for supporting forest inventories and operations.},
DOI = {10.3390/rs13142796}
}



@Article{f12070943,
AUTHOR = {Vásquez, Felipe and Cravero, Ania and Castro, Manuel and Acevedo, Patricio},
TITLE = {Decision Support System Development of Wildland Fire: A Systematic Mapping},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {943},
URL = {https://www.mdpi.com/1999-4907/12/7/943},
ISSN = {1999-4907},
ABSTRACT = {Wildland fires have been a rising problem on the worldwide level, generating ecological and economic losses. Specifically, between wildland fire types, uncontrolled fires are critical due to the potential damage to the ecosystem and their effects on the soil, and, in the last decade, different technologies have been applied to fight them. Selecting a specific technology and Decision Support Systems (DSS) is fundamental, since the results and validity of this could drastically oscillate according to the different environmental and geographic factors of the terrain to be studied. Given the above, a systematic mapping was realized, with the purpose of recognizing the most-used DSS and context where they have been applied. One hundred and eighty-three studies were found that used different types of DSS to solve problems of detection, prediction, prevention, monitoring, simulation, administration, and access to routes. The concepts key to the type of solution are related to the use or development of systems or Information and Communication Technologies (ICT) in the computer science area. Although the use of BA and Big Data has increased in recent years, there are still many challenges to face, such as staff training, the friendly environment of DSS, and real-time decision-making.},
DOI = {10.3390/f12070943}
}



@Article{rs13142822,
AUTHOR = {Lin, Zhe and Guo, Wenxuan},
TITLE = {Cotton Stand Counting from Unmanned Aerial System Imagery Using MobileNet and CenterNet Deep Learning Models},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2822},
URL = {https://www.mdpi.com/2072-4292/13/14/2822},
ISSN = {2072-4292},
ABSTRACT = {An accurate stand count is a prerequisite to determining the emergence rate, assessing seedling vigor, and facilitating site-specific management for optimal crop production. Traditional manual counting methods in stand assessment are labor intensive and time consuming for large-scale breeding programs or production field operations. This study aimed to apply two deep learning models, the MobileNet and CenterNet, to detect and count cotton plants at the seedling stage with unmanned aerial system (UAS) images. These models were trained with two datasets containing 400 and 900 images with variations in plant size and soil background brightness. The performance of these models was assessed with two testing datasets of different dimensions, testing dataset 1 with 300 by 400 pixels and testing dataset 2 with 250 by 1200 pixels. The model validation results showed that the mean average precision (mAP) and average recall (AR) were 79% and 73% for the CenterNet model, and 86% and 72% for the MobileNet model with 900 training images. The accuracy of cotton plant detection and counting was higher with testing dataset 1 for both CenterNet and MobileNet models. The results showed that the CenterNet model had a better overall performance for cotton plant detection and counting with 900 training images. The results also indicated that more training images are required when applying object detection models on images with different dimensions from training datasets. The mean absolute percentage error (MAPE), coefficient of determination (R2), and the root mean squared error (RMSE) values of the cotton plant counting were 0.07%, 0.98 and 0.37, respectively, with testing dataset 1 for the CenterNet model with 900 training images. Both MobileNet and CenterNet models have the potential to accurately and timely detect and count cotton plants based on high-resolution UAS images at the seedling stage. This study provides valuable information for selecting the right deep learning tools and the appropriate number of training images for object detection projects in agricultural applications.},
DOI = {10.3390/rs13142822}
}



@Article{rs13142827,
AUTHOR = {Hu, Pengcheng and Chapman, Scott C. and Jin, Huidong and Guo, Yan and Zheng, Bangyou},
TITLE = {Comparison of Modelling Strategies to Estimate Phenotypic Values from an Unmanned Aerial Vehicle with Spectral and Temporal Vegetation Indexes},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2827},
URL = {https://www.mdpi.com/2072-4292/13/14/2827},
ISSN = {2072-4292},
ABSTRACT = {Aboveground dry weight (AGDW) and leaf area index (LAI) are indicators of crop growth status and grain yield as affected by interactions of genotype, environment, and management. Unmanned aerial vehicle (UAV) based remote sensing provides cost-effective and non-destructive methods for the high-throughput phenotyping of crop traits (e.g., AGDW and LAI) through the integration of UAV-derived vegetation indexes (VIs) with statistical models. However, the effects of different modelling strategies that use different dataset compositions of explanatory variables (i.e., combinations of sources and temporal combinations of the VI datasets) on estimates of AGDW and LAI have rarely been evaluated. In this study, we evaluated the effects of three sources of VIs (visible, spectral, and combined) and three types of temporal combinations of the VI datasets (mono-, multi-, and full-temporal) on estimates of AGDW and LAI. The VIs were derived from visible (RGB) and multi-spectral imageries, which were acquired by a UAV-based platform over a wheat trial at five sampling dates before flowering. Partial least squares regression models were built with different modelling strategies to estimate AGDW and LAI at each prediction date. The results showed that models built with the three sources of mono-temporal VIs obtained similar performances for estimating AGDW (RRMSE = 11.86% to 15.80% for visible, 10.25% to 16.70% for spectral, and 10.25% to 16.70% for combined VIs) and LAI (RRMSE = 13.30% to 22.56% for visible, 12.04% to 22.85% for spectral, and 13.45% to 22.85% for combined VIs) across prediction dates. Mono-temporal models built with visible VIs outperformed the other two sources of VIs in general. Models built with mono-temporal VIs generally obtained better estimates than models with multi- and full-temporal VIs. The results suggested that the use of UAV-derived visible VIs can be an alternative to multi-spectral VIs for high-throughput and in-season estimates of AGDW and LAI. The combination of modelling strategies that used mono-temporal datasets and a self-calibration method demonstrated the potential for in-season estimates of AGDW and LAI (RRMSE normally less than 15%) in breeding or agronomy trials.},
DOI = {10.3390/rs13142827}
}



@Article{s21144901,
AUTHOR = {Setlak, Lucjan and Kowalik, Rafał},
TITLE = {Study and Analysis of Interference Signals of the LTE System of the GNSS Receiver},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {4901},
URL = {https://www.mdpi.com/1424-8220/21/14/4901},
PubMedID = {34300639},
ISSN = {1424-8220},
ABSTRACT = {Sometimes, it is impossible to conduct tests with the use of the GNSS system, or the obtained results of the measurements made differ significantly from the predicted accuracy. The most common cause of the problems (external factors, faulty results) are interference disturbances from other radio telecommunication systems. The subject of this paper is to conduct research, the essence of which is an in-depth analysis in the field of elimination of LTE interference signals of the GNSS receiver, that is based on the developed effective methods on counteracting the phenomenon of interference signals coming from this system and transmitted on the same frequency. Interference signals are signals transmitted in the GNSS operating band, and unwanted signals may cause incorrect processing of the information provided to the end-user about his position, speed, and current time. This article presents methods of identifying and detecting interference signals, with particular emphasis on methods based on spatial processing of signals transmitted by the LTE system. A comparative analysis of the methods of detecting an unwanted signal was made in terms of their effectiveness and complexity of their implementation. Moreover, the concept of a new comprehensive anti-interference solution was proposed. It includes, among others, information on the various stages of GNSS signal processing in the proposed system, in relation to the algorithms used in traditional GNSS receivers. The final part of the article presents the obtained research results and the resulting significant observations and practical conclusions.},
DOI = {10.3390/s21144901}
}



@Article{rs13142830,
AUTHOR = {Fernández-Novales, Juan and Saiz-Rubio, Verónica and Barrio, Ignacio and Rovira-Más, Francisco and Cuenca-Cuenca, Andrés and Santos Alves, Fernando and Valente, Joana and Tardaguila, Javier and Diago, María Paz},
TITLE = {Monitoring and Mapping Vineyard Water Status Using Non-Invasive Technologies by a Ground Robot},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2830},
URL = {https://www.mdpi.com/2072-4292/13/14/2830},
ISSN = {2072-4292},
ABSTRACT = {There is a growing need to provide support and applicable tools to farmers and the agro-industry in order to move from their traditional water status monitoring and high-water-demand cropping and irrigation practices to modern, more precise, reduced-demand systems and technologies. In precision viticulture, very few approaches with ground robots have served as moving platforms for carrying non-invasive sensors to deliver field maps that help growers in decision making. The goal of this work is to demonstrate the capability of the VineScout (developed in the context of a H2020 EU project), a ground robot designed to assess and map vineyard water status using thermal infrared radiometry in commercial vineyards. The trials were carried out in Douro Superior (Portugal) under different irrigation treatments during seasons 2019 and 2020. Grapevines of Vitis vinifera L. Touriga Nacional were monitored at different timings of the day using leaf water potential (Ψl) as reference indicators of plant water status. Grapevines’ canopy temperature (Tc) values, recorded with an infrared radiometer, as well as data acquired with an environmental sensor (Tair, RH, and AP) and NDVI measurements collected with a multispectral sensor were automatically saved in the computer of the autonomous robot to assess and map the spatial variability of a commercial vineyard water status. Calibration and prediction models were performed using Partial Least Squares (PLS) regression. The best prediction models for grapevine water status yielded a determination coefficient of cross-validation (r2cv) of 0.57 in the morning time and a r2cv of 0.42 in the midday. The root mean square error of cross-validation (RMSEcv) was 0.191 MPa and 0.139 MPa at morning and midday, respectively. Spatial–temporal variation maps were developed at two different times of the day to illustrate the capability to monitor the grapevine water status in order to reduce the consumption of water, implementing appropriate irrigation strategies and increase the efficiency in the real time vineyard management. The promising outcomes gathered with the VineScout using different sensors based on thermography, multispectral imaging and environmental data disclose the need for further studies considering new variables related with the plant water status, and more grapevine cultivars, seasons and locations to improve the accuracy, robustness and reliability of the predictive models, in the context of precision and sustainable viticulture.},
DOI = {10.3390/rs13142830}
}



@Article{agronomy11071435,
AUTHOR = {Che’Ya, Nik Norasma and Dunwoody, Ernest and Gupta, Madan},
TITLE = {Assessment of Weed Classification Using Hyperspectral Reflectance and Optimal Multispectral UAV Imagery},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1435},
URL = {https://www.mdpi.com/2073-4395/11/7/1435},
ISSN = {2073-4395},
ABSTRACT = {Weeds compete with crops and are hard to differentiate and identify due to their similarities in color, shape, and size. In this study, the weed species present in sorghum (sorghum bicolor (L.) Moench) fields, such as amaranth (Amaranthus macrocarpus), pigweed (Portulaca oleracea), mallow weed (Malva sp.), nutgrass (Cyperus rotundus), liver seed grass (Urochoa panicoides), and Bellive (Ipomea plebeian), were discriminated using hyperspectral data and were detected and analyzed using multispectral images. Discriminant analysis (DA) was used to identify the most significant spectral bands in order to discriminate weeds from sorghum using hyperspectral data. The results demonstrated good separation accuracy for Amaranthus macrocarpus, Urochoa panicoides, Malva sp., Cyperus rotundus, and Sorghum bicolor (L.) Moench at 440, 560, 680, 710, 720, and 850 nm. Later, the multispectral images of these six bands were collected to detect weeds in the sorghum crop fields using object-based image analysis (OBIA). The results showed that the differences between sorghum and weed species were detectable using the six selected bands, with data collected using an unmanned aerial vehicle. Here, the highest spatial resolution had the highest accuracy for weed detection. It was concluded that each weed was successfully discriminated using hyperspectral data and was detectable using multispectral data with higher spatial resolution.},
DOI = {10.3390/agronomy11071435}
}



@Article{electronics10141737,
AUTHOR = {Lee, Wooseop and Kang, Min-Hee and Song, Jaein and Hwang, Keeyeon},
TITLE = {The Design of Preventive Automated Driving Systems Based on Convolutional Neural Network},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {1737},
URL = {https://www.mdpi.com/2079-9292/10/14/1737},
ISSN = {2079-9292},
ABSTRACT = {As automated vehicles have been considered one of the important trends in intelligent transportation systems, various research is being conducted to enhance their safety. In particular, the importance of technologies for the design of preventive automated driving systems, such as detection of surrounding objects and estimation of distance between vehicles. Object detection is mainly performed through cameras and LiDAR, but due to the cost and limits of LiDAR’s recognition distance, the need to improve Camera recognition technique, which is relatively convenient for commercialization, is increasing. This study learned convolutional neural network (CNN)-based faster regions with CNN (Faster R-CNN) and You Only Look Once (YOLO) V2 to improve the recognition techniques of vehicle-mounted monocular cameras for the design of preventive automated driving systems, recognizing surrounding vehicles in black box highway driving videos and estimating distances from surrounding vehicles through more suitable models for automated driving systems. Moreover, we learned the PASCAL visual object classes (VOC) dataset for model comparison. Faster R-CNN showed similar accuracy, with a mean average precision (mAP) of 76.4 to YOLO with a mAP of 78.6, but with a Frame Per Second (FPS) of 5, showing slower processing speed than YOLO V2 with an FPS of 40, and a Faster R-CNN, which we had difficulty detecting. As a result, YOLO V2, which shows better performance in accuracy and processing speed, was determined to be a more suitable model for automated driving systems, further progressing in estimating the distance between vehicles. For distance estimation, we conducted coordinate value conversion through camera calibration and perspective transform, set the threshold to 0.7, and performed object detection and distance estimation, showing more than 80% accuracy for near-distance vehicles. Through this study, it is believed that it will be able to help prevent accidents in automated vehicles, and it is expected that additional research will provide various accident prevention alternatives such as calculating and securing appropriate safety distances, depending on the vehicle types.},
DOI = {10.3390/electronics10141737}
}



@Article{rs13142833,
AUTHOR = {Wei, Xing and Johnson, Marcela A. and Langston, David B. and Mehl, Hillary L. and Li, Song},
TITLE = {Identifying Optimal Wavelengths as Disease Signatures Using Hyperspectral Sensor and Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2833},
URL = {https://www.mdpi.com/2072-4292/13/14/2833},
ISSN = {2072-4292},
ABSTRACT = {Hyperspectral sensors combined with machine learning are increasingly utilized in agricultural crop systems for diverse applications, including plant disease detection. This study was designed to identify the most important wavelengths to discriminate between healthy and diseased peanut (Arachis hypogaea L.) plants infected with Athelia rolfsii, the causal agent of peanut stem rot, using in-situ spectroscopy and machine learning. In greenhouse experiments, daily measurements were conducted to inspect disease symptoms visually and to collect spectral reflectance of peanut leaves on lateral stems of plants mock-inoculated and inoculated with A. rolfsii. Spectrum files were categorized into five classes based on foliar wilting symptoms. Five feature selection methods were compared to select the top 10 ranked wavelengths with and without a custom minimum distance of 20 nm. Recursive feature elimination methods outperformed the chi-square and SelectFromModel methods. Adding the minimum distance of 20 nm into the top selected wavelengths improved classification performance. Wavelengths of 501–505, 690–694, 763 and 884 nm were repeatedly selected by two or more feature selection methods. These selected wavelengths can be applied in designing optical sensors for automated stem rot detection in peanut fields. The machine-learning-based methodology can be adapted to identify spectral signatures of disease in other plant-pathogen systems.},
DOI = {10.3390/rs13142833}
}



@Article{s21144929,
AUTHOR = {Hallee, Mitchell J. and Napolitano, Rebecca K. and Reinhart, Wesley F. and Glisic, Branko},
TITLE = {Crack Detection in Images of Masonry Using CNNs},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {4929},
URL = {https://www.mdpi.com/1424-8220/21/14/4929},
PubMedID = {34300668},
ISSN = {1424-8220},
ABSTRACT = {While there is a significant body of research on crack detection by computer vision methods in concrete and asphalt, less attention has been given to masonry. We train a convolutional neural network (CNN) on images of brick walls built in a laboratory environment and test its ability to detect cracks in images of brick-and-mortar structures both in the laboratory and on real-world images taken from the internet. We also compare the performance of the CNN to a variety of simpler classifiers operating on handcrafted features. We find that the CNN performed better on the domain adaptation from laboratory to real-world images than these simple models. However, we also find that performance is significantly better in performing the reverse domain adaptation task, where the simple classifiers are trained on real-world images and tested on the laboratory images. This work demonstrates the ability to detect cracks in images of masonry using a variety of machine learning methods and provides guidance for improving the reliability of such models when performing domain adaptation for crack detection in masonry.},
DOI = {10.3390/s21144929}
}



@Article{electronics10141744,
AUTHOR = {Wazirali, Raniyah and Ahmad, Rami and Al-Amayreh, Ahmed and Al-Madi, Mohammad and Khalifeh, Ala’},
TITLE = {Secure Watermarking Schemes and Their Approaches in the IoT Technology: An Overview},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {1744},
URL = {https://www.mdpi.com/2079-9292/10/14/1744},
ISSN = {2079-9292},
ABSTRACT = {Information security is considered one of the most important issues in various infrastructures related to the field of data communication where most of the modern studies focus on finding effective and low-weight secure approaches. Digital watermarking is a trend in security techniques that hides data by using data embedding and data extraction processes. Watermarking technology is integrated into different frames without adding an overheard as in the conventional encryption. Therefore, it is efficient to be used in data encryption for applications that run over limited resources such as the Internet of Things (IoT). In this paper, different digital watermarking algorithms and approaches are presented. Additionally, watermarking requirements and challenges are illustrated in detail. Moreover, the common architecture of the watermarking system is described. Furthermore, IoT technology and its challenges are highlighted. Finally, the paper provides the motivations, objectives and applications of the recent secure watermarking techniques in IoT and summarises them into one table. In addition, the paper highlights the potential to apply the modified watermark algorithms to secure IoT networks.},
DOI = {10.3390/electronics10141744}
}



@Article{electronics10151748,
AUTHOR = {Wei, Baoquan and Zuo, Yong and Liu, Yande and Luo, Wei and Wen, Kaiyun and Deng, Fangming},
TITLE = {Novel MOA Fault Detection Technology Based on Small Sample Infrared Image},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {1748},
URL = {https://www.mdpi.com/2079-9292/10/15/1748},
ISSN = {2079-9292},
ABSTRACT = {This paper proposes a novel metal oxide arrester (MOA) fault detection technology based on a small sample infrared image. The research is carried out from the detection process and data enhancement. A lightweight MOA identification and location algorithm is designed at the edge, which can not only reduce the amount of data uploaded, but also reduce the search space of cloud algorithm. In order to improve the accuracy and generalization ability of the defect detection model under the condition of small samples, a multi-model fusion detection algorithm is proposed. Different features of the image are extracted by multiple convolutional neural networks, and then multiple classifiers are trained. Finally, the weighted voting strategy is used for fault diagnosis. In addition, the extended model of fault samples is constructed by transfer learning and deep convolutional generative adversarial networks (DCGAN) to solve the problem of unbalanced training data sets. The experimental results show that the proposed method can realize the accurate location of arrester under the condition of small samples, and after the data expansion, the recognition rate of arrester anomalies can be improved from 83% to 85%, showing high effectiveness and reliability.},
DOI = {10.3390/electronics10151748}
}



@Article{rs13152849,
AUTHOR = {Zhu, Zheng and Bao, Tengfei and Hu, Yuhan and Gong, Jian},
TITLE = {A Novel Method for Fast Positioning of Non-Standardized Ground Control Points in Drone Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2849},
URL = {https://www.mdpi.com/2072-4292/13/15/2849},
ISSN = {2072-4292},
ABSTRACT = {Positioning the pixels of ground control points (GCPs) in drone images is an issue of great concern in the field of drone photogrammetry. The current mainstream automatic approaches are based on standardized markers, such as circular coded targets and point coded targets. There is no denying that introducing standardized markers improves the efficiency of positioning GCP pixels. However, the low flexibility leads to some drawbacks, such as the heavy logistical input in placing and maintaining GCP markers. Especially as drone photogrammetry steps into the era of large scenes, the logistical input in maintaining GCP markers becomes much more costly. This paper proposes a novel positioning method applicable for non-standardized GCPs. Firstly, regions of interest (ROIs) are extracted from drone images with stereovision technologies. Secondly, the quality of ROIs is evaluated using image entropy, and then the outliers are filtered by an adjusted boxplot. Thirdly, pixels of interest are searched with a corner detector, and the precise imagery coordinates are obtained by subpixel optimization. Finally, the verification was carried out in an urban scene, and the results show that this method has good applicability to the GCPs on road traffic signs, and the accuracy rate is over 95%.},
DOI = {10.3390/rs13152849}
}



@Article{agriculture11080687,
AUTHOR = {Mesa, Armacheska Rivero and Chiang, John Y.},
TITLE = {Multi-Input Deep Learning Model with RGB and Hyperspectral Imaging for Banana Grading},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {687},
URL = {https://www.mdpi.com/2077-0472/11/8/687},
ISSN = {2077-0472},
ABSTRACT = {Grading is a vital process during the postharvest of horticultural products as it dramatically affects consumer preference and satisfaction when goods reach the market. Manual grading is time-consuming, uneconomical, and potentially destructive. A non-invasive automated system for export-quality banana tiers was developed, which utilized RGB, hyperspectral imaging, and deep learning techniques. A real dataset of pre-classified banana tiers based on quality and size (Class 1 for export quality bananas, Class 2 for the local market, and Class 3 for defective fruits) was utilized using international standards. The multi-input model achieved an excellent overall accuracy of 98.45% using only a minimal number of samples compared to other methods in the literature. The model was able to incorporate both external and internal properties of the fruit. The size of the banana was used as a feature for grade classification as well as other morphological features using RGB imaging, while reflectance values that offer valuable information and have shown a high correlation with the internal features of fruits were obtained through hyperspectral imaging. This study highlighted the combined strengths of RGB and hyperspectral imaging in grading bananas, and this can serve as a paradigm for grading other horticultural crops. The fast-processing time of the multi-input model developed can be advantageous when it comes to actual farm postharvest processes.},
DOI = {10.3390/agriculture11080687}
}



@Article{su13158170,
AUTHOR = {Chedea, Veronica Sanda and Drăgulinescu , Ana-Maria and Tomoiagă , Liliana Lucia and Bălăceanu, Cristina and Iliescu , Maria Lucia},
TITLE = {Climate Change and Internet of Things Technologies—Sustainable Premises of Extending the Culture of the Amurg Cultivar in Transylvania—A Use Case for Târnave Vineyard},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {8170},
URL = {https://www.mdpi.com/2071-1050/13/15/8170},
ISSN = {2071-1050},
ABSTRACT = {Known for its dry and semi-dry white wine, the Târnave vineyard located in central Transylvania is challenged by the current climate change, which has resulted in an increase of the period of active vegetation by approximately 15–20 days, the average annual temperature by 1–1.5 °C and also the amount of useful temperatures (useful thermal balance for the grapevine). Furthermore, the frost periods have been reduced. Transylvania is an important Romanian region for grapevine cultivation. In this context, one can use the climatic changes to expand their wine assortment by cultivating an autochthonous grapevine variety called Amurg. Amurg is a red grape cultivar homologated at SCDVV Blaj, which also homologated 7 cultivars and 11 clones. Because viticulture depends on the stability of meteorological and hydrological parameters of the growing area, its foundations are challenged by climate change. Grapevine production is a long time investment, taking at least five years before the freshly planted vines produce the desired quality berries. We propose the implementation of a climate change-based precision viticulture turn-key solution for environmental monitoring in the Târnave vineyard. This solution aims to evaluate the grapevine’s micro-climate to extend the sustainable cultivation of the Amurg red grapes cultivar in Transylvania with the final goal of obtaining Protected Designation of Origin (PDO) rosé and red wines from this region. Worldwide, the changing conditions from the existing climate (a 30-year average), used in the past hundred years to dictate local standards, such as new and erratic trends of temperature and humidity regimes, late spring freezes, early fall frosts, storms, heatwaves, droughts, area wildfires, and insect infestations, would create dynamic problems for all farmers to thrive. These conditions will make it challenging to predict shifts in each of the components of seasonal weather conditions. Our proposed system also aims to give a solution that can be adapted to other vineyards as well.},
DOI = {10.3390/su13158170}
}



@Article{rs13152870,
AUTHOR = {Civico, Riccardo and Ricci, Tullio and Scarlato, Piergiorgio and Andronico, Daniele and Cantarero, Massimo and Carr, Brett B. and De Beni, Emanuela and Del Bello, Elisabetta and Johnson, Jeffrey B. and Kueppers, Ulrich and Pizzimenti, Luca and Schmid, Markus and Strehlow, Karen and Taddeucci, Jacopo},
TITLE = {Unoccupied Aircraft Systems (UASs) Reveal the Morphological Changes at Stromboli Volcano (Italy) before, between, and after the 3 July and 28 August 2019 Paroxysmal Eruptions},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2870},
URL = {https://www.mdpi.com/2072-4292/13/15/2870},
ISSN = {2072-4292},
ABSTRACT = {In July and August 2019, two paroxysmal eruptions dramatically changed the morphology of the crater terrace that hosts the active vents of Stromboli volcano (Italy). Here, we document these morphological changes, by using 2259 UAS-derived photographs from eight surveys and Structure-from-Motion (SfM) photogrammetric techniques, resulting in 3D point clouds, orthomosaics, and digital surface models (DSMs) with resolution ranging from 8.1 to 12.4 cm/pixel. We focus on the morphological evolution of volcanic features and volume changes in the crater terrace and the upper part of the underlying slope (Sciara del Fuoco). We identify both crater terrace and lava field variations, with vents shifting up to 47 m and the accumulation of tephra deposits. The maximum elevation changes related to the two paroxysmal eruptions (in between May and September 2019) range from +41.4 to −26.4 m at the lava field and N crater area, respectively. Throughout September 2018–June 2020, the total volume change in the surveyed area was +447,335 m3. Despite Stromboli being one of the best-studied volcanoes worldwide, the UAS-based photogrammetry products of this study provide unprecedented high spatiotemporal resolution observations of its entire summit area, in a period when volcanic activity made the classic field inspections and helicopter overflights too risky. Routinely applied UAS operations represent an effective and evolving tool for volcanic hazard assessment and to support decision-makers involved in volcanic surveillance and civil protection operations.},
DOI = {10.3390/rs13152870}
}



@Article{electronics10151758,
AUTHOR = {Yang, Shangyi and Sun, Chao and Kim, Youngok},
TITLE = {Indoor 3D Localization Scheme Based on BLE Signal Fingerprinting and 1D Convolutional Neural Network},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {1758},
URL = {https://www.mdpi.com/2079-9292/10/15/1758},
ISSN = {2079-9292},
ABSTRACT = {Indoor localization schemes have significant potential for use in location-based services in areas such as smart factories, mixed reality, and indoor navigation. In particular, received signal strength (RSS)-based fingerprinting is used widely, given its simplicity and low hardware requirements. However, most studies tend to focus on estimating the 2D position of the target. Moreover, it is known that the fingerprinting scheme is computationally costly, and its positioning accuracy is readily affected by random fluctuations in the RSS values caused by fading and the multipath effect. We propose an indoor 3D localization scheme based on both fingerprinting and a 1D convolutional neural network (CNN). Instead of using the conventional fingerprint matching method, we transform the 3D positioning problem into a classification problem and use the 1D CNN model with the RSS time-series data from Bluetooth low-energy beacons for classification. By using the 1D CNN with the time-series data from multiple beacons, the inherent drawback of RSS-based fingerprinting, namely, its susceptibility to noise and randomness, is overcome, resulting in enhanced positioning accuracy. To evaluate the proposed scheme, we developed a 3D positioning system and performed comprehensive tests, whose results confirmed that the scheme significantly outperforms the conventional common spatial pattern classification algorithm.},
DOI = {10.3390/electronics10151758}
}



@Article{agronomy11081458,
AUTHOR = {Ammar, Adel and Koubaa, Anis and Benjdira, Bilel},
TITLE = {Deep-Learning-Based Automated Palm Tree Counting and Geolocation in Large Farms from Aerial Geotagged Images},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1458},
URL = {https://www.mdpi.com/2073-4395/11/8/1458},
ISSN = {2073-4395},
ABSTRACT = {In this paper, we propose an original deep learning framework for the automated counting and geolocation of palm trees from aerial images using convolutional neural networks. For this purpose, we collected aerial images from two different regions in Saudi Arabia, using two DJI drones, and we built a dataset of around 11,000 instances of palm trees. Then, we applied several recent convolutional neural network models (Faster R-CNN, YOLOv3, YOLOv4, and EfficientDet) to detect palms and other trees, and we conducted a complete comparative evaluation in terms of average precision and inference speed. YOLOv4 and EfficientDet-D5 yielded the best trade-off between accuracy and speed (up to 99% mean average precision and 7.4 FPS). Furthermore, using the geotagged metadata of aerial images, we used photogrammetry concepts and distance corrections to automatically detect the geographical location of detected palm trees. This geolocation technique was tested on two different types of drones (DJI Mavic Pro and Phantom 4 pro) and was assessed to provide an average geolocation accuracy that attains 1.6 m. This GPS tagging allows us to uniquely identify palm trees and count their number from a series of drone images, while correctly dealing with the issue of image overlapping. Moreover, this innovative combination between deep learning object detection and geolocalization can be generalized to any other objects in UAV images.},
DOI = {10.3390/agronomy11081458}
}



@Article{app11156745,
AUTHOR = {Díez-Pastor, José Francisco and Latorre-Carmona, Pedro and Garrido-Labrador, José Luis and Ramírez-Sanz, José Miguel and Rodríguez, Juan J.},
TITLE = {Experimental Assessment of Feature Extraction Techniques Applied to the Identification of Properties of Common Objects, Using a Radar System},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {6745},
URL = {https://www.mdpi.com/2076-3417/11/15/6745},
ISSN = {2076-3417},
ABSTRACT = {Radar technology has evolved considerably in the last few decades. There are many areas where radar systems are applied, including air traffic control in airports, ocean surveillance, and research systems, to cite a few. Other types of sensors have recently appeared, which allow tracking sub-millimeter motion with high speed and accuracy rates. These millimeter-wave radars are giving rise to myriad new applications, from the recognition of the material close objects are made, to the recognition of hand gestures. They have also been recently used to identify how a person interacts with digital devices through the physical environment (Tangible User Interfaces, TUIs). In this case, the radar is used to detect the orientation, movement, or distance from the objects to the user’s hands or the digital device. This paper presents a thoughtful comparative analysis of different feature extraction techniques and classification strategies applied on a series of datasets that cover problems such as the identification of materials, element counting, or determining the orientation and distance of objects to the sensor. The results outperform previous works using these datasets, especially when the accuracy was lowest, showing the benefits feature extraction techniques have on classification performance.},
DOI = {10.3390/app11156745}
}



@Article{geosciences11080305,
AUTHOR = {Karantanellis, Efstratios and Marinos, Vassilis and Vassilakis, Emmanuel and Hölbling, Daniel},
TITLE = {Evaluation of Machine Learning Algorithms for Object-Based Mapping of Landslide Zones Using UAV Data},
JOURNAL = {Geosciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {305},
URL = {https://www.mdpi.com/2076-3263/11/8/305},
ISSN = {2076-3263},
ABSTRACT = {Landslides are a critical geological phenomenon with devastating and catastrophic consequences. With the recent advancements in the geoinformation domain, landslide documentation and inventorization can be achieved with automated workflows using aerial platforms such as unmanned aerial vehicles (UAVs). As a result, ultra-high-resolution datasets are available for analysis at low operational costs. In this study, different segmentation and classification approaches were utilized for object-based landslide mapping. An integrated object-based image analysis (OBIA) workflow is presented incorporating orthophotomosaics and digital surface models (DSMs) with expert-based and machine learning (ML) algorithms. For segmentation, trial and error tests and the Estimation of Scale Parameter 2 (ESP 2) tool were implemented for the evaluation of different scale parameters. For classification, machine learning algorithms (K- Nearest Neighbor, Decision Tree, and Random Forest) were assessed with the inclusion of spectral, spatial, and contextual characteristics. For the ML classification of landslide zones, 60% of the reference segments have been used for training and 40% for validation of the models. The quality metrics of Precision, Recall, and F1 were implemented to evaluate the models’ performance under the different segmentation configurations. Results highlight higher performances for landslide mapping when DSM information was integrated. Hence, the configuration of spectral and DSM layers with the RF classifier resulted in the highest classification agreement with an F1 value of 0.85.},
DOI = {10.3390/geosciences11080305}
}



@Article{min11080798,
AUTHOR = {Isheyskiy, Valentin and Martinyskin, Evgeny and Smirnov, Sergey and Vasilyev, Anton and Knyazev, Kirill and Fatyanov, Timur},
TITLE = {Specifics of MWD Data Collection and Verification during Formation of Training Datasets},
JOURNAL = {Minerals},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {798},
URL = {https://www.mdpi.com/2075-163X/11/8/798},
ISSN = {2075-163X},
ABSTRACT = {This paper presents a structured analysis in the area of measurement while drilling (MWD) data processing and verification methods, as well as describes the main nuances and certain specifics of “clean” data selection in order to build a “parent” training database for subsequent use in machine learning algorithms. The main purpose of the authors is to create a trainable machine learning algorithm, which, based on the available “clean” input data associated with specific conditions, could correlate, process and select parameters obtained from the drilling rig and use them for further estimation of various rock characteristics, prediction of optimal drilling and blasting parameters, and blasting results. The paper is a continuation of a series of publications devoted to the prospects of using MWD technology for the quality management of drilling and blasting operations at mining enterprises.},
DOI = {10.3390/min11080798}
}



@Article{rs13152881,
AUTHOR = {Karami, Azam and Quijano, Karoll and Crawford, Melba},
TITLE = {Advancing Tassel Detection and Counting: Annotation and Algorithms},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2881},
URL = {https://www.mdpi.com/2072-4292/13/15/2881},
ISSN = {2072-4292},
ABSTRACT = {Tassel counts provide valuable information related to flowering and yield prediction in maize, but are expensive and time-consuming to acquire via traditional manual approaches. High-resolution RGB imagery acquired by unmanned aerial vehicles (UAVs), coupled with advanced machine learning approaches, including deep learning (DL), provides a new capability for monitoring flowering. In this article, three state-of-the-art DL techniques, CenterNet based on point annotation, task-aware spatial disentanglement (TSD), and detecting objects with recursive feature pyramids and switchable atrous convolution (DetectoRS) based on bounding box annotation, are modified to improve their performance for this application and evaluated for tassel detection relative to Tasselnetv2+. The dataset for the experiments is comprised of RGB images of maize tassels from plant breeding experiments, which vary in size, complexity, and overlap. Results show that the point annotations are more accurate and simpler to acquire than the bounding boxes, and bounding box-based approaches are more sensitive to the size of the bounding boxes and background than point-based approaches. Overall, CenterNet has high accuracy in comparison to the other techniques, but DetectoRS can better detect early-stage tassels. The results for these experiments were more robust than Tasselnetv2+, which is sensitive to the number of tassels in the image.},
DOI = {10.3390/rs13152881}
}



@Article{rs13152885,
AUTHOR = {Li, Mei and Li, Zengyuan and Liu, Qingwang and Chen, Erxue},
TITLE = {Comparison of Coniferous Plantation Heights Using Unmanned Aerial Vehicle (UAV) Laser Scanning and Stereo Photogrammetry},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2885},
URL = {https://www.mdpi.com/2072-4292/13/15/2885},
ISSN = {2072-4292},
ABSTRACT = {Plantation forests play a critical role in forest products and ecosystems. Unmanned aerial vehicle (UAV) remote sensing has become a promising technology in forest related applications. The stand heights will reflect the growth and competition of individual trees in plantation. UAV laser scanning (ULS) and UAV stereo photogrammetry (USP) can both be used to estimate stand heights using different algorithms. Thus, this study aimed to deeply explore the variations of four kinds of stand heights including mean height, Lorey’s height, dominated height, and median height of coniferous plantations using different models based on ULS and USP data. In addition, the impacts of thinned point density of 30 pts to 10 pts, 5 pts, 1 pts, and 0.8 pts/m2 were also analyzed. Forest stand heights were estimated from ULS and USP data metrics by linear regression and the prediction accuracy was assessed by 10-fold cross validation. The results showed that the prediction accuracy of the stand heights using metrics from USP was basically as good as that of ULS. Lorey’s height had the highest prediction accuracy, followed by dominated height, mean height, and median height. The correlation between height percentiles metrics from ULS and USP increased with the increased height. Different stand heights had their corresponding best height percentiles as variables based on stand height characteristics. Furthermore, canopy height model (CHM)-based metrics performed slightly better than normalized point cloud (NPC)-based metrics. The USP was not able to extract exact terrain information in a continuous coniferous plantation for forest canopy cover (CC) over 0.49. The combination of USP and terrain from ULS can be used to estimate forest stand heights with high accuracy. In addition, the estimation accuracy of each forest stand height was slightly affected by point density, which can also be ignored.},
DOI = {10.3390/rs13152885}
}



@Article{drones5030066,
AUTHOR = {Walambe, Rahee and Marathe, Aboli and Kotecha, Ketan},
TITLE = {Multiscale Object Detection from Drone Imagery Using Ensemble Transfer Learning},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {66},
URL = {https://www.mdpi.com/2504-446X/5/3/66},
ISSN = {2504-446X},
ABSTRACT = {Object detection in uncrewed aerial vehicle (UAV) images has been a longstanding challenge in the field of computer vision. Specifically, object detection in drone images is a complex task due to objects of various scales such as humans, buildings, water bodies, and hills. In this paper, we present an implementation of ensemble transfer learning to enhance the performance of the base models for multiscale object detection in drone imagery. Combined with a test-time augmentation pipeline, the algorithm combines different models and applies voting strategies to detect objects of various scales in UAV images. The data augmentation also presents a solution to the deficiency of drone image datasets. We experimented with two specific datasets in the open domain: the VisDrone dataset and the AU-AIR Dataset. Our approach is more practical and efficient due to the use of transfer learning and two-level voting strategy ensemble instead of training custom models on entire datasets. The experimentation shows significant improvement in the mAP for both VisDrone and AU-AIR datasets by employing the ensemble transfer learning method. Furthermore, the utilization of voting strategies further increases the 3reliability of the ensemble as the end-user can select and trace the effects of the mechanism for bounding box predictions.},
DOI = {10.3390/drones5030066}
}



@Article{rs13152899,
AUTHOR = {El Serafy, Ghada Y.H. and Schaeffer, Blake A. and Neely, Merrie-Beth and Spinosa, Anna and Odermatt, Daniel and Weathers, Kathleen C. and Baracchini, Theo and Bouffard, Damien and Carvalho, Laurence and Conmy, Robyn N. and Keukelaere, Liesbeth De and Hunter, Peter D. and Jamet, Cédric and Joehnk, Klaus D. and Johnston, John M. and Knudby, Anders and Minaudo, Camille and Pahlevan, Nima and Reusen, Ils and Rose, Kevin C. and Schalles, John and Tzortziou, Maria},
TITLE = {Integrating Inland and Coastal Water Quality Data for Actionable Knowledge},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2899},
URL = {https://www.mdpi.com/2072-4292/13/15/2899},
ISSN = {2072-4292},
ABSTRACT = {Water quality measures for inland and coastal waters are available as discrete samples from professional and volunteer water quality monitoring programs and higher-frequency, near-continuous data from automated in situ sensors. Water quality parameters also are estimated from model outputs and remote sensing. The integration of these data, via data assimilation, can result in a more holistic characterization of these highly dynamic ecosystems, and consequently improve water resource management. It is becoming common to see combinations of these data applied to answer relevant scientific questions. Yet, methods for scaling water quality data across regions and beyond, to provide actionable knowledge for stakeholders, have emerged only recently, particularly with the availability of satellite data now providing global coverage at high spatial resolution. In this paper, data sources and existing data integration frameworks are reviewed to give an overview of the present status and identify the gaps in existing frameworks. We propose an integration framework to provide information to user communities through the the Group on Earth Observations (GEO) AquaWatch Initiative. This aims to develop and build the global capacity and utility of water quality data, products, and information to support equitable and inclusive access for water resource management, policy and decision making.},
DOI = {10.3390/rs13152899}
}



@Article{rs13152912,
AUTHOR = {Wang, Jingrui and Wang, Shuqing and Zou, Dongxiao and Chen, Huimin and Zhong, Run and Li, Hanliang and Zhou, Wei and Yan, Kai},
TITLE = {Social Network and Bibliometric Analysis of Unmanned Aerial Vehicle Remote Sensing Applications from 2010 to 2021},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2912},
URL = {https://www.mdpi.com/2072-4292/13/15/2912},
ISSN = {2072-4292},
ABSTRACT = {Unmanned Aerial Vehicle (UAV) Remote sensing (RS) has unique advantages over traditional satellite RS, including convenience, high resolution, affordability and fast acquisition speed, making it widely used in many fields. To provide an overview of the development of UAV RS applications during the past decade, we screened related publications from the Web of Science core database from 2010 to 2021, built co-author networks, a discipline interaction network, a keywords timeline view, a co-citation cluster, and detected burst citations using bibliometrics and social network analysis. Our results show that: (1) The number of UAV RS publications had an increasing trend, with explosive growth in the past five years. The number of papers published by China and the United States (US) is far ahead in this field; (2) The US has currently the greatest influence in this field through the largest number of international cooperations. Cooperation is mainly concentrated in countries and institutions with a large number of publications but is not widely distributed. (3) The application of UAV RS involves multiple interdisciplinary subjects, among which “Environmental Science and Ecology” ranks first; (4) Future research trends of UAV RS are expected to be related to artificial intelligence (e.g., artificial neural networks-based research). This paper provides a scientific basis and guidance for future developments of UAV RS applications, which can help the research community to better grasp the developments of this field.},
DOI = {10.3390/rs13152912}
}



@Article{rs13152914,
AUTHOR = {Cruz-Ramos, Clara and Garcia-Salgado, Beatriz P. and Reyes-Reyes, Rogelio and Ponomaryov, Volodymyr and Sadovnychiy, Sergiy},
TITLE = {Gabor Features Extraction and Land-Cover Classification of Urban Hyperspectral Images for Remote Sensing Applications},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2914},
URL = {https://www.mdpi.com/2072-4292/13/15/2914},
ISSN = {2072-4292},
ABSTRACT = {The principles of the transform stage of the extract, transform and load (ETL) process can be applied to index the data in functional structures for the decision-making inherent in an urban remote sensing application. This work proposes a method that can be utilised as an organisation stage by reducing the data dimension with Gabor texture features extracted from grey-scale representations of the Hue, Saturation and Value (HSV) colour space and the Normalised Difference Vegetation Index (NDVI). Additionally, the texture features are reduced using the Linear Discriminant Analysis (LDA) method. Afterwards, an Artificial Neural Network (ANN) is employed to classify the data and build a tick data matrix indexed by the belonging class of the observations, which could be retrieved for further analysis according to the class selected to explore. The proposed method is compared in terms of classification rates, reduction efficiency and training time against the utilisation of other grey-scale representations and classifiers. This method compresses up to 87% of the original features and achieves similar classification results to non-reduced features but at a higher training time.},
DOI = {10.3390/rs13152914}
}



@Article{rs13152917,
AUTHOR = {Wei, Lifei and Wang, Kun and Lu, Qikai and Liang, Yajing and Li, Haibo and Wang, Zhengxiang and Wang, Run and Cao, Liqin},
TITLE = {Crops Fine Classification in Airborne Hyperspectral Imagery Based on Multi-Feature Fusion and Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2917},
URL = {https://www.mdpi.com/2072-4292/13/15/2917},
ISSN = {2072-4292},
ABSTRACT = {Hyperspectral imagery has been widely used in precision agriculture due to its rich spectral characteristics. With the rapid development of remote sensing technology, the airborne hyperspectral imagery shows detailed spatial information and temporal flexibility, which open a new way to accurate agricultural monitoring. To extract crop types from the airborne hyperspectral images, we propose a fine classification method based on multi-feature fusion and deep learning. In this research, the morphological profiles, GLCM texture and endmember abundance features are leveraged to exploit the spatial information of the hyperspectral imagery. Then, the multiple spatial information is fused with the original spectral information to generate classification result by using the deep neural network with conditional random field (DNN+CRF) model. Specifically, the deep neural network (DNN) is a deep recognition model which can extract depth features and mine the potential information of data. As a discriminant model, conditional random field (CRF) considers both spatial and contextual information to reduce the misclassification noises while keeping the object boundaries. Moreover, three multiple feature fusion approaches, namely feature stacking, decision fusion and probability fusion, are taken into account. In the experiments, two airborne hyperspectral remote sensing datasets (Honghu dataset and Xiong’an dataset) are used. The experimental results show that the classification performance of the proposed method is satisfactory, where the salt and pepper noise is decreased, and the boundary of the ground object is preserved.},
DOI = {10.3390/rs13152917}
}



@Article{rs13152918,
AUTHOR = {Banerjee, Bikram P. and Sharma, Vikas and Spangenberg, German and Kant, Surya},
TITLE = {Machine Learning Regression Analysis for Estimation of Crop Emergence Using Multispectral UAV Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2918},
URL = {https://www.mdpi.com/2072-4292/13/15/2918},
ISSN = {2072-4292},
ABSTRACT = {Optimal crop emergence is an important trait in crop breeding for genotypic screening and for achieving potential growth and yield. Emergence is conventionally quantified manually by counting the sub-sections of field plots or scoring; these are less reliable, laborious and inefficient. Remote sensing technology is being increasingly used for high-throughput estimation of agronomic traits in field crops. This study developed a method for estimating wheat seedlings using multispectral images captured from an unmanned aerial vehicle. A machine learning regression (MLR) analysis was used by combining spectral and morphological information extracted from the multispectral images. The approach was tested on diverse wheat genotypes varying in seedling emergence. In this study, three supervised MLR models including regression trees, support vector regression and Gaussian process regression (GPR) were evaluated for estimating wheat seedling emergence. The GPR model was the most effective compared to the other methods, with R2 = 0.86, RMSE = 4.07 and MAE = 3.21 when correlated to the manual seedling count. In addition, imagery data collected at multiple flight altitudes and different wheat growth stages suggested that 10 m altitude and 20 days after sowing were desirable for optimal spatial resolution and image analysis. The method is deployable on larger field trials and other crops for effective and reliable seedling emergence estimates.},
DOI = {10.3390/rs13152918}
}



@Article{agronomy11081480,
AUTHOR = {Liu, Jizhan and Abbas, Irfan and Noor, Rana Shahzad},
TITLE = {Development of Deep Learning-Based Variable Rate Agrochemical Spraying System for Targeted Weeds Control in Strawberry Crop},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1480},
URL = {https://www.mdpi.com/2073-4395/11/8/1480},
ISSN = {2073-4395},
ABSTRACT = {Agrochemical application is an important tool in the agricultural industry for the protection of crops. Agrochemical application with conventional sprayers results in the waste of applied agrochemicals, which not only increases financial losses but also contaminates the environment. Targeted agrochemical sprayers using smart control systems can substantially decrease the chemical input, weed control cost, and destructive environmental contamination. A variable rate spraying system was developed using deep learning methods for the development of new models to classify weeds and to accurately spray on desired weeds target. Laboratory and field experiments were conducted to assess the sprayer performance for weed classification and precise spraying of the target weeds using three classification CNNs (Convolutional Neural Networks) models. The DCNNs models (AlexNet, VGG-16, and GoogleNet) were trained using a dataset containing a total of 12,443 images captured from the strawberry field (4200 images with spotted spurge, 4265 images with Shepherd’s purse, and 4178 strawberry plants). The VGG-16 model attained higher values of precision, recall and F1-score as compared to AlexNet and GoogleNet. Additionally VGG-16 model recorded higher percentage of completely sprayed weeds target (CS = 93%) values. Overall in all experiments, VGG-16 performed better than AlexNet and GoogleNet for real-time weeds target classification and precision spraying. The experiments results revealed that the Sprayer performance decreased with the increase of sprayer traveling speed above 3 km/h. Experimental results recommended that the sprayer with the VGG-16 model can achieve high performance that makes it more ideal for a real-time spraying application. It is concluded that the advanced variable rate spraying system has the potential for spot application of agrochemicals to control weeds in a strawberry field. It can reduce the crop input costs and the environmental pollution risks.},
DOI = {10.3390/agronomy11081480}
}



@Article{rs13152937,
AUTHOR = {Zeng, Linglin and Peng, Guozhang and Meng, Ran and Man, Jianguo and Li, Weibo and Xu, Binyuan and Lv, Zhengang and Sun, Rui},
TITLE = {Wheat Yield Prediction Based on Unmanned Aerial Vehicles-Collected Red–Green–Blue Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2937},
URL = {https://www.mdpi.com/2072-4292/13/15/2937},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicles-collected (UAVs) digital red–green–blue (RGB) images provided a cost-effective method for precision agriculture applications regarding yield prediction. This study aims to fully explore the potential of UAV-collected RGB images in yield prediction of winter wheat by comparing it to multi-source observations, including thermal, structure, volumetric metrics, and ground-observed leaf area index (LAI) and chlorophyll content under the same level or across different levels of nitrogen fertilization. Color indices are vegetation indices calculated by the vegetation reflectance at visible bands (i.e., red, green, and blue) derived from RGB images. The results showed that some of the color indices collected at the jointing, flowering, and early maturity stages had high correlation (R2 = 0.76–0.93) with wheat grain yield. They gave the highest prediction power (R2 = 0.92–0.93) under four levels of nitrogen fertilization at the flowering stage. In contrast, the other measurements including canopy temperature, volumetric metrics, and ground-observed chlorophyll content showed lower correlation (R2 = 0.52–0.85) to grain yield. In addition, thermal information as well as volumetric metrics generally had little contribution to the improvement of grain yield prediction when combining them with color indices derived from digital images. Especially, LAI had inferior performance to color indices in grain yield prediction within the same level of nitrogen fertilization at the flowering stage (R2 = 0.00–0.40 and R2 = 0.55–0.68), and color indices provided slightly better prediction of yield than LAI at the flowering stage (R2 = 0.93, RMSE = 32.18 g/m2 and R2 = 0.89, RMSE = 39.82 g/m2) under all levels of nitrogen fertilization. This study highlights the capabilities of color indices in wheat yield prediction across genotypes, which also indicates the potential of precision agriculture application using many other flexible, affordable, and easy-to-handle devices such as mobile phones and near surface digital cameras in the future.},
DOI = {10.3390/rs13152937}
}



@Article{jmse9080806,
AUTHOR = {Ru, Jingyu and Yu, Shuangjiang and Wu, Hao and Li, Yuhan and Wu, Chengdong and Jia, Zixi and Xu, Hongli},
TITLE = {A Multi-AUV Path Planning System Based on the Omni-Directional Sensing Ability},
JOURNAL = {Journal of Marine Science and Engineering},
VOLUME = {9},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {806},
URL = {https://www.mdpi.com/2077-1312/9/8/806},
ISSN = {2077-1312},
ABSTRACT = {Following the development of autonomous underwater vehicles (AUVs), multiple trajectory-based submarine target information collection constitutes one of the key technologies that significantly influence underwater information collection ability and deployment efficiency. In this paper, we propose an underwater information collection AUV, O-AUV, that can perceive the omnidirectional area and could detect a larger area than the traditional AUV. A 3D sensing model for the O-AUV is proposed to describe the complex underwater information collection spaces. Thereafter, a cube-based environment model involving candidate observation point calculation methods are suggested to adapt the O-AUV model. A voyage cost map is also built according to the multi-AUV path planning for a common submarine mission that must traverse numerous mission targets in complex environments through the R-Dijkstra algorithm. Specifically, the voyage planning problem is solved through a critical algorithm called ANSGA (accelerated NSGA-II algorithm), which in turn, is developed by modifying the non-dominated sorting genetic algorithm (NSGA-II) to accelerate the optimization rate for the Pareto solution. Experiments are carried out in MATLAB, and the results verify the validity of the proposed O-AUV+ANSGA algorithm framework.},
DOI = {10.3390/jmse9080806}
}



@Article{agriculture11080707,
AUTHOR = {Lu, Jinzhu and Tan, Lijuan and Jiang, Huanyu},
TITLE = {Review on Convolutional Neural Network (CNN) Applied to Plant Leaf Disease Classification},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {707},
URL = {https://www.mdpi.com/2077-0472/11/8/707},
ISSN = {2077-0472},
ABSTRACT = {Crop production can be greatly reduced due to various diseases, which seriously endangers food security. Thus, detecting plant diseases accurately is necessary and urgent. Traditional classification methods, such as naked-eye observation and laboratory tests, have many limitations, such as being time consuming and subjective. Currently, deep learning (DL) methods, especially those based on convolutional neural network (CNN), have gained widespread application in plant disease classification. They have solved or partially solved the problems of traditional classification methods and represent state-of-the-art technology in this field. In this work, we reviewed the latest CNN networks pertinent to plant leaf disease classification. We summarized DL principles involved in plant disease classification. Additionally, we summarized the main problems and corresponding solutions of CNN used for plant disease classification. Furthermore, we discussed the future development direction in plant disease classification.},
DOI = {10.3390/agriculture11080707}
}



@Article{atmos12080962,
AUTHOR = {Phan, Phamchimai and Chen, Nengcheng and Xu, Lei and Dao, Duy Minh and Dang, Dinhkha},
TITLE = {NDVI Variation and Yield Prediction in Growing Season: A Case Study with Tea in Tanuyen Vietnam},
JOURNAL = {Atmosphere},
VOLUME = {12},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {962},
URL = {https://www.mdpi.com/2073-4433/12/8/962},
ISSN = {2073-4433},
ABSTRACT = {Tea is one of the most significant cash crops and plays an important role in economic development and poverty reduction. On the other hand, tea is an optimal choice in the extreme weather conditions of Tanuyen Laichau, Vietnam. In our study, the NDVI variation of tea in the growing season from 2009 to 2018 was showed by calculating NDVI trend and the Mann-Kendall analysis to assess trends in the time series. Support Vector Machine (SVM) and Random Forest (RF) model were used for predicting tea yield. The NDVI of tea showed an increasing trend with a slope from −0.001–0.001 (88.9% of the total area), a slope from 0.001–0.002 (11.1% of the total area) and a growing rate of 0.00075/year. The response of tea NDVI to almost climatic factor in a one-month time lag is higher than the current month. The tea yield was estimated with higher accuracy in the RF model. Among the input variables, we detected that the role of Tmean and NDVI is stronger than other variables when squared with each of the independent variables into input data.},
DOI = {10.3390/atmos12080962}
}



@Article{rs13152948,
AUTHOR = {Fernández, Claudio I. and Leblon, Brigitte and Wang, Jinfei and Haddadi, Ata and Wang, Keri},
TITLE = {Detecting Infected Cucumber Plants with Close-Range Multispectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2948},
URL = {https://www.mdpi.com/2072-4292/13/15/2948},
ISSN = {2072-4292},
ABSTRACT = {This study used close-range multispectral imagery over cucumber plants inside a commercial greenhouse to detect powdery mildew due to Podosphaera xanthii. It was collected using a MicaSense® RedEdge camera at 1.5 m over the top of the plant. Image registration was performed using Speeded-Up Robust Features (SURF) with an affine geometric transformation. The image background was removed using a binary mask created with the aligned NIR band of each image, and the illumination was corrected using Cheng et al.’s algorithm. Different features were computed, including RGB, image reflectance values, and several vegetation indices. For each feature, a fine Gaussian Support Vector Machines algorithm was trained and validated to classify healthy and infected pixels. The data set to train and validate the SVM was composed of 1000 healthy and 1000 infected pixels, split 70–30% into training and validation datasets, respectively. The overall validation accuracy was 89, 73, 82, 51, and 48%, respectively, for blue, green, red, red-edge, and NIR band image. With the RGB images, we obtained an overall validation accuracy of 89%, while the best vegetation index image was the PMVI-2 image which produced an overall accuracy of 81%. Using the five bands together, overall accuracy dropped from 99% in the training to 57% in the validation dataset. While the results of this work are promising, further research should be considered to increase the number of images to achieve better training and validation datasets.},
DOI = {10.3390/rs13152948}
}



@Article{rs13152956,
AUTHOR = {Wang, Li and Chen, Shuisen and Li, Dan and Wang, Chongyang and Jiang, Hao and Zheng, Qiong and Peng, Zhiping},
TITLE = {Estimation of Paddy Rice Nitrogen Content and Accumulation Both at Leaf and Plant Levels from UAV Hyperspectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2956},
URL = {https://www.mdpi.com/2072-4292/13/15/2956},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing-based mapping of crop nitrogen (N) status is beneficial for precision N management over large geographic regions. Both leaf/canopy level nitrogen content and accumulation are valuable for crop nutrient diagnosis. However, previous studies mainly focused on leaf nitrogen content (LNC) estimation. The effects of growth stages on the modeling accuracy have not been widely discussed. This study aimed to estimate different paddy rice N traits—LNC, plant nitrogen content (PNC), leaf nitrogen accumulation (LNA) and plant nitrogen accumulation (PNA)—from unmanned aerial vehicle (UAV)-based hyperspectral images. Additionally, the effects of the growth stage were evaluated. Univariate regression models on vegetation indices (VIs), the traditional multivariate calibration method, partial least squares regression (PLSR) and modern machine learning (ML) methods, including artificial neural network (ANN), random forest (RF), and support vector machine (SVM), were evaluated both over the whole growing season and in each single growth stage (including the tillering, jointing, booting and heading growth stages). The results indicate that the correlation between the four nitrogen traits and the other three biochemical traits—leaf chlorophyll content, canopy chlorophyll content and aboveground biomass—are affected by the growth stage. Within a single growth stage, the performance of selected VIs is relatively constant. For the full-growth-stage models, the performance of the VI-based models is more diverse. For the full-growth-stage models, the transformed chlorophyll absorption in the reflectance index/optimized soil-adjusted vegetation index (TCARI/OSAVI) performs best for LNC, PNC and PNA estimation, while the three band vegetation index (TBVITian) performs best for LNA estimation. There are no obvious patterns regarding which method performs the best of the PLSR, ANN, RF and SVM in either the growth-stage-specific or full-growth-stage models. For the growth-stage-specific models, a lower mean relative error (MRE) and higher R2 can be acquired at the tillering and jointing growth stages. The PLSR and ML methods yield obviously better estimation accuracy for the full-growth-stage models than the VI-based models. For the growth-stage-specific models, the performance of VI-based models seems optimal and cannot be obviously surpassed. These results suggest that building linear regression models on VIs for paddy rice nitrogen traits estimation is still a reasonable choice when only a single growth stage is involved. However, when multiple growth stages are involved or missing the phenology information, using PLSR or ML methods is a better option.},
DOI = {10.3390/rs13152956}
}



@Article{rs13152965,
AUTHOR = {Ghaffarian, Saman and Valente, João and van der Voort, Mariska and Tekinerdogan, Bedir},
TITLE = {Effect of Attention Mechanism in Deep Learning-Based Remote Sensing Image Processing: A Systematic Literature Review},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2965},
URL = {https://www.mdpi.com/2072-4292/13/15/2965},
ISSN = {2072-4292},
ABSTRACT = {Machine learning, particularly deep learning (DL), has become a central and state-of-the-art method for several computer vision applications and remote sensing (RS) image processing. Researchers are continually trying to improve the performance of the DL methods by developing new architectural designs of the networks and/or developing new techniques, such as attention mechanisms. Since the attention mechanism has been proposed, regardless of its type, it has been increasingly used for diverse RS applications to improve the performances of the existing DL methods. However, these methods are scattered over different studies impeding the selection and application of the feasible approaches. This study provides an overview of the developed attention mechanisms and how to integrate them with different deep learning neural network architectures. In addition, it aims to investigate the effect of the attention mechanism on deep learning-based RS image processing. We identified and analyzed the advances in the corresponding attention mechanism-based deep learning (At-DL) methods. A systematic literature review was performed to identify the trends in publications, publishers, improved DL methods, data types used, attention types used, overall accuracies achieved using At-DL methods, and extracted the current research directions, weaknesses, and open problems to provide insights and recommendations for future studies. For this, five main research questions were formulated to extract the required data and information from the literature. Furthermore, we categorized the papers regarding the addressed RS image processing tasks (e.g., image classification, object detection, and change detection) and discussed the results within each group. In total, 270 papers were retrieved, of which 176 papers were selected according to the defined exclusion criteria for further analysis and detailed review. The results reveal that most of the papers reported an increase in overall accuracy when using the attention mechanism within the DL methods for image classification, image segmentation, change detection, and object detection using remote sensing images.},
DOI = {10.3390/rs13152965}
}



@Article{ijgi10080511,
AUTHOR = {Xulu, Sifiso and Mbatha, Nkanyiso and Peerbhay, Kabir},
TITLE = {Burned Area Mapping over the Southern Cape Forestry Region, South Africa Using Sentinel Data within GEE Cloud Platform},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {511},
URL = {https://www.mdpi.com/2220-9964/10/8/511},
ISSN = {2220-9964},
ABSTRACT = {Planted forests in South Africa have been affected by an increasing number of economically damaging fires over the past four decades. They constitute a major threat to the forestry industry and account for over 80% of the country’s commercial timber losses. Forest fires are more frequent and severe during the drier drought conditions that are typical in South Africa. For proper forest management, accurate detection and mapping of burned areas are required, yet the exercise is difficult to perform in the field because of time and expense. Now that ready-to-use satellite data are freely accessible in the cloud-based Google Earth Engine (GEE), in this study, we exploit the Sentinel-2-derived differenced normalized burned ratio (dNBR) to characterize burn severity areas, and also track carbon monoxide (CO) plumes using Sentinel-5 following a wildfire that broke over the southeastern coast of the Western Cape province in late October 2018. The results showed that 37.4% of the area was severely burned, and much of it occurred in forested land in the studied area. This was followed by 24.7% of the area that was burned at a moderate-high level. About 15.9% had moderate-low burned severity, whereas 21.9% was slightly burned. Random forests classifier was adopted to separate burned class from unburned and achieved an overall accuracy of over 97%. The most important variables in the classification included texture, NBR, and the NIR bands. The CO signal sharply increased during fire outbreaks and marked the intensity of black carbon over the affected area. Our study contributes to the understanding of forest fire in the dynamics over the Southern Cape forestry landscape. Furthermore, it also demonstrates the usefulness of Sentinel-5 for monitoring CO. Taken together, the Sentinel satellites and GEE offer an effective tool for mapping fires, even in data-poor countries.},
DOI = {10.3390/ijgi10080511}
}



@Article{rs13152971,
AUTHOR = {Fraser, Benjamin T. and Congalton, Russell G.},
TITLE = {Estimating Primary Forest Attributes and Rare Community Characteristics Using Unmanned Aerial Systems (UAS): An Enrichment of Conventional Forest Inventories},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2971},
URL = {https://www.mdpi.com/2072-4292/13/15/2971},
ISSN = {2072-4292},
ABSTRACT = {The techniques for conducting forest inventories have been established over centuries of land management and conservation. In recent decades, however, compelling new tools and methodologies in remote sensing, computer vision, and data science have offered innovative pathways for enhancing the effectiveness and comprehension of these sampling designs. Now with the aid of Unmanned Aerial Systems (UAS) and advanced image processing techniques, we have never been closer to mapping forests at field-based inventory scales. Our research, conducted in New Hampshire on complex mixed-species forests, used natural color UAS imagery for estimating individual tree diameters (diameter at breast height (dbh)) as well as stand level estimates of Basal Area per Hectare (BA/ha), Quadratic Mean Diameter (QMD), Trees per Hectare (TPH), and a Stand Density Index (SDI) using digital photogrammetry. To strengthen our understanding of these forests, we also assessed the proficiency of the UAS to map the presence of large trees (i.e., &gt;40 cm in diameter). We assessed the proficiency of UAS digital photogrammetry for identifying large trees in two ways: (1) using the UAS estimated dbh and the 40 cm size threshold and (2) using a random forest supervised classification and a combination of spectral, textural, and geometric features. Our UAS-based estimates of tree diameter reported an average error of 19.7% to 33.7%. At the stand level, BA/ha and QMD were overestimated by 42.18% and 62.09%, respectively, while TPH and SDI were underestimated by 45.58% and 3.34%. When considering only stands larger than 9 ha however, the overestimation of BA/ha at the stand level dropped to 14.629%. The overall classification of large trees, using the random forest supervised classification achieved an overall accuracy of 85%. The efficiency and effectiveness of these methods offer local land managers the opportunity to better understand their forested ecosystems. Future research into individual tree crown detection and delineation, especially for co-dominant or suppressed trees, will further support these efforts.},
DOI = {10.3390/rs13152971}
}



@Article{s21155110,
AUTHOR = {Placidi, Pisana and Morbidelli, Renato and Fortunati, Diego and Papini, Nicola and Gobbi, Francesco and Scorzoni, Andrea},
TITLE = {Monitoring Soil and Ambient Parameters in the IoT Precision Agriculture Scenario: An Original Modeling Approach Dedicated to Low-Cost Soil Water Content Sensors},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {5110},
URL = {https://www.mdpi.com/1424-8220/21/15/5110},
PubMedID = {34372355},
ISSN = {1424-8220},
ABSTRACT = {A low power wireless sensor network based on LoRaWAN protocol was designed with a focus on the IoT low-cost Precision Agriculture applications, such as greenhouse sensing and actuation. All subsystems used in this research are designed by using commercial components and free or open-source software libraries. The whole system was implemented to demonstrate the feasibility of a modular system built with cheap off-the-shelf components, including sensors. The experimental outputs were collected and stored in a database managed by a virtual machine running in a cloud service. The collected data can be visualized in real time by the user with a graphical interface. The reliability of the whole system was proven during a continued experiment with two natural soils, Loamy Sand and Silty Loam. Regarding soil parameters, the system performance has been compared with that of a reference sensor from Sentek. Measurements highlighted a good agreement for the temperature within the supposed accuracy of the adopted sensors and a non-constant sensitivity for the low-cost volumetric water contents (VWC) sensor. Finally, for the low-cost VWC sensor we implemented a novel procedure to optimize the parameters of the non-linear fitting equation correlating its analog voltage output with the reference VWC.},
DOI = {10.3390/s21155110}
}



@Article{s21155132,
AUTHOR = {Kuo, Ping-Huan and Lin, Ssu-Ting and Hu, Jun and Huang, Chiou-Jye},
TITLE = {Multi-Sensor Context-Aware Based Chatbot Model: An Application of Humanoid Companion Robot},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {5132},
URL = {https://www.mdpi.com/1424-8220/21/15/5132},
PubMedID = {34372368},
ISSN = {1424-8220},
ABSTRACT = {In aspect of the natural language processing field, previous studies have generally analyzed sound signals and provided related responses. However, in various conversation scenarios, image information is still vital. Without the image information, misunderstanding may occur, and lead to wrong responses. In order to address this problem, this study proposes a recurrent neural network (RNNs) based multi-sensor context-aware chatbot technology. The proposed chatbot model incorporates image information with sound signals and gives appropriate responses to the user. In order to improve the performance of the proposed model, the long short-term memory (LSTM) structure is replaced by gated recurrent unit (GRU). Moreover, a VGG16 model is also chosen for a feature extractor for the image information. The experimental results demonstrate that the integrative technology of sound and image information, which are obtained by the image sensor and sound sensor in a companion robot, is helpful for the chatbot model proposed in this study. The feasibility of the proposed technology was also confirmed in the experiment.},
DOI = {10.3390/s21155132}
}



@Article{rs13152986,
AUTHOR = {Li, Xin and Xu, Feng and Xia, Runliang and Lyu, Xin and Gao, Hongmin and Tong, Yao},
TITLE = {Hybridizing Cross-Level Contextual and Attentive Representations for Remote Sensing Imagery Semantic Segmentation},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2986},
URL = {https://www.mdpi.com/2072-4292/13/15/2986},
ISSN = {2072-4292},
ABSTRACT = {Semantic segmentation of remote sensing imagery is a fundamental task in intelligent interpretation. Since deep convolutional neural networks (DCNNs) performed considerable insight in learning implicit representations from data, numerous works in recent years have transferred the DCNN-based model to remote sensing data analysis. However, the wide-range observation areas, complex and diverse objects and illumination and imaging angle influence the pixels easily confused, leading to undesirable results. Therefore, a remote sensing imagery semantic segmentation neural network, named HCANet, is proposed to generate representative and discriminative representations for dense predictions. HCANet hybridizes cross-level contextual and attentive representations to emphasize the distinguishability of learned features. First of all, a cross-level contextual representation module (CCRM) is devised to exploit and harness the superpixel contextual information. Moreover, a hybrid representation enhancement module (HREM) is designed to fuse cross-level contextual and self-attentive representations flexibly. Furthermore, the decoder incorporates DUpsampling operation to boost the efficiency losslessly. The extensive experiments are implemented on the Vaihingen and Potsdam benchmarks. In addition, the results indicate that HCANet achieves excellent performance on overall accuracy and mean intersection over union. In addition, the ablation study further verifies the superiority of CCRM.},
DOI = {10.3390/rs13152986}
}



@Article{app11157013,
AUTHOR = {Junejo, Aisha Zahid and Hashmani, Manzoor Ahmed and Memon, Mehak Maqbool},
TITLE = {Empirical Evaluation of Privacy Efficiency in Blockchain Networks: Review and Open Challenges},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {7013},
URL = {https://www.mdpi.com/2076-3417/11/15/7013},
ISSN = {2076-3417},
ABSTRACT = {With the widespread of blockchain technology, preserving the anonymity and confidentiality of transactions have become crucial. An enormous portion of blockchain research is dedicated to the design and development of privacy protocols but not much has been achieved for proper assessment of these solutions. To mitigate the gap, we have first comprehensively classified the existing solutions based on blockchain fundamental building blocks (i.e., smart contracts, cryptography, and hashing). Next, we investigated the evaluation criteria used for validating these techniques. The findings depict that the majority of privacy solutions are validated based on computing resources i.e., memory, time, storage, throughput, etc., only, which is not sufficient. Hence, we have additionally identified and presented various other factors that strengthen or weaken blockchain privacy. Based on those factors, we have formulated an evaluation framework to analyze the efficiency of blockchain privacy solutions. Further, we have introduced a concept of privacy precision that is a quantifiable measure to empirically assess privacy efficiency in blockchains. The calculation of privacy precision will be based on the effectiveness and strength of various privacy protecting attributes of a solution and the associated risks. Finally, we conclude the paper with some open research challenges and future directions. Our study can serve as a benchmark for empirical assessment of blockchain privacy.},
DOI = {10.3390/app11157013}
}



@Article{ijgi10080513,
AUTHOR = {Zare Naghadehi, Saeid and Asadi, Milad and Maleki, Mohammad and Tavakkoli-Sabour, Seyed-Mohammad and Van Genderen, John Lodewijk and Saleh, Samira-Sadat},
TITLE = {Prediction of Urban Area Expansion with Implementation of MLC, SAM and SVMs’ Classifiers Incorporating Artificial Neural Network Using Landsat Data},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {513},
URL = {https://www.mdpi.com/2220-9964/10/8/513},
ISSN = {2220-9964},
ABSTRACT = {A reliable land cover (LC) map is essential for planners, as missing proper land cover maps may deviate a project. This study is focusing on land cover classification and prediction using three well known classifiers and remote sensing data. Maximum Likelihood classifier (MLC), Spectral Angle Mapper (SAM), and Support Vector Machines (SVMs) algorithms are used as the representatives for parametric, non-parametric and subpixel capable methods for change detection and change prediction of Urmia City (Iran) and its suburbs. Landsat images of 2000, 2010, and 2020 have been used to provide land cover information. The results demonstrated 0.93–0.94 overall accuracies for MLC and SVMs’ algorithms, but it was around 0.79 for the SAM algorithm. The MLC performed slightly better than SVMs’ classifier. Cellular Automata Artificial neural network method was used to predict land cover changes. Overall accuracy of MLC was higher than others at about 0.94 accuracy, although, SVMs were slightly more accurate for large area segments. Land cover maps were predicted for 2030, which demonstrate the city’s expansion from 5500 ha in 2000 to more than 9000 ha in 2030.},
DOI = {10.3390/ijgi10080513}
}



@Article{rs13153001,
AUTHOR = {Yang, Kaili and Gong, Yan and Fang, Shenghui and Duan, Bo and Yuan, Ningge and Peng, Yi and Wu, Xianting and Zhu, Renshan},
TITLE = {Combining Spectral and Texture Features of UAV Images for the Remote Estimation of Rice LAI throughout the Entire Growing Season},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {3001},
URL = {https://www.mdpi.com/2072-4292/13/15/3001},
ISSN = {2072-4292},
ABSTRACT = {Leaf area index (LAI) estimation is very important, and not only for canopy structure analysis and yield prediction. The unmanned aerial vehicle (UAV) serves as a promising solution for LAI estimation due to its great applicability and flexibility. At present, vegetation index (VI) is still the most widely used method in LAI estimation because of its fast speed and simple calculation. However, VI only reflects the spectral information and ignores the texture information of images, so it is difficult to adapt to the unique and complex morphological changes of rice in different growth stages. In this study we put forward a novel method by combining the texture information derived from the local binary pattern and variance features (LBP and VAR) with the spectral information based on VI to improve the estimation accuracy of rice LAI throughout the entire growing season. The multitemporal images of two study areas located in Hainan and Hubei were acquired by a 12-band camera, and the main typical bands for constituting VIs such as green, red, red edge, and near-infrared were selected to analyze their changes in spectrum and texture during the entire growing season. After the mathematical combination of plot-level spectrum and texture values, new indices were constructed to estimate rice LAI. Comparing the corresponding VI, the new indices were all less sensitive to the appearance of panicles and slightly weakened the saturation issue. The coefficient of determination (R2) can be improved for all tested VIs throughout the entire growing season. The results showed that the combination of spectral and texture features exhibited a better predictive ability than VI for estimating rice LAI. This method only utilized the texture and spectral information of the UAV image itself, which is fast, easy to operate, does not need manual intervention, and can be a low-cost method for monitoring crop growth.},
DOI = {10.3390/rs13153001}
}



@Article{coatings11080913,
AUTHOR = {Siang, Teng Wei and Firdaus Akbar, Muhammad and Nihad Jawad, Ghassan and Yee, Tan Shin and Mohd Sazali, Mohd Ilyas Sobirin},
TITLE = {A Past, Present, and Prospective Review on Microwave Nondestructive Evaluation of Composite Coatings},
JOURNAL = {Coatings},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {913},
URL = {https://www.mdpi.com/2079-6412/11/8/913},
ISSN = {2079-6412},
ABSTRACT = {Recent years have witnessed an increase in the use of composite coatings for numerous applications, including aerospace, aircraft, and maritime vessels. These materials owe this popularity surge to the superior strength, weight, stiffness, and electrical insulation they exhibit over conventional substances, such as metals. The growing demand for such materials is accompanied by the inevitable need for fast, accurate, and affordable nondestructive testing techniques to reveal any possible defects within the coatings or any defects under coating. However, typical nondestructive testing (NDT) techniques such as ultrasonic testing (UT), infrared thermography (IRT), eddy current testing (ECT), and laser shearography (LS) have failed to provide successful results when inspecting composite coatings. Consequently, microwave NDT techniques have emerged to compensate for the shortcomings of traditional NDT approaches. Numerous microwave NDT methods have been reported for composite coatings inspection. Although existing microwave NDT methods have shown successful inspection of composite coatings, they often face several challenges, such as low spatial image quality and extensive data interpretation. Nevertheless, many of these limitations can be addressed by utilizing microwave NDT techniques with modern technologies such as soft computing. Artificially intelligent techniques have greatly enhanced the reliability and accuracy of microwave NDT techniques. This paper reviews various traditional NDT techniques and their limitations in inspecting composite coatings. In addition, the article includes a detailed review of several microwave NDT techniques and their benefits in evaluating composite coatings. The paper also highlights the advantages of using the recently reported microwave NDT approaches employing artificial intelligence approaches. This review demonstrates that microwave NDT techniques in conjunction with artificial intelligence approaches have excellent prospects for further enhancing composite coatings inspection and assessment efficiency. The review aimed to provide the reader with a comprehensive overview of most NDT techniques used for composite materials alongside their most salient features.},
DOI = {10.3390/coatings11080913}
}



@Article{w13152080,
AUTHOR = {Wang, Yang and Tian, Yongzhong and Cao, Yan},
TITLE = {Dam Siting: A Review},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2080},
URL = {https://www.mdpi.com/2073-4441/13/15/2080},
ISSN = {2073-4441},
ABSTRACT = {Dams can effectively regulate the spatial and temporal distribution of water resources, where the rationality of dam siting determines whether the role of dams can be effectively performed. This paper reviews the research literature on dam siting in the past 20 years, discusses the methods used for dam siting, focuses on the factors influencing dam siting, and assesses the impact of different dam functions on siting factors. The results show the following: (1) Existing siting methods can be categorized into three types—namely, GIS/RS-based siting, MCDM- and MCDM-GIS-based siting, and machine learning-based siting. GIS/RS emphasizes the ability to capture and analyze data, MCDM has the advantage of weighing the importance of the relationship between multiple factors, and machine learning methods have a strong ability to learn and process complex data. (2) Site selection factors vary greatly, depending on the function of the dam. For dams with irrigation and water supply as the main purpose, the site selection is more focused on the evaluation of water quality. For dams with power generation as the main purpose, the hydrological factors characterizing the power generation potential are the most important. For dams with flood control as the main purpose, the topography and geological conditions are more important. (3) The integration of different siting methods and the siting of new functional dams in the existing research is not sufficient. Future research should focus on the integration of different methods and disciplines, in order to explore the siting of new types of dams.},
DOI = {10.3390/w13152080}
}



@Article{s21155183,
AUTHOR = {Motroni, Andrea and Buffi, Alice and Nepa, Paolo and Pesi, Mario and Congi, Antonio},
TITLE = {An Action Classification Method for Forklift Monitoring in Industry 4.0 Scenarios},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {5183},
URL = {https://www.mdpi.com/1424-8220/21/15/5183},
PubMedID = {34372420},
ISSN = {1424-8220},
ABSTRACT = {The I-READ 4.0 project is aimed at developing an integrated and autonomous Cyber-Physical System for automatic management of very large warehouses with a high-stock rotation index. Thanks to a network of Radio Frequency Identification (RFID) readers operating in the Ultra-High-Frequency (UHF) band, both fixed and mobile, it is possible to implement an efficient management of assets and forklifts operating in an indoor scenario. A key component to accomplish this goal is the UHF-RFID Smart Gate, which consists of a checkpoint infrastructure based on RFID technology to identify forklifts and their direction of transit. This paper presents the implementation of a UHF-RFID Smart Gate with a single reader antenna with asymmetrical deployment, thus allowing the correct action classification with reduced infrastructure complexity and cost. The action classification method exploits the signal phase backscattered by RFID tags placed on the forklifts. The performance and the method capabilities are demonstrated through an on-site demonstrator in a real warehouse.},
DOI = {10.3390/s21155183}
}



@Article{agronomy11081542,
AUTHOR = {Wang, Hao and Lyu, Suxing and Ren, Yaxin},
TITLE = {Paddy Rice Imagery Dataset for Panicle Segmentation},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1542},
URL = {https://www.mdpi.com/2073-4395/11/8/1542},
ISSN = {2073-4395},
ABSTRACT = {Accurate panicle identification is a key step in rice-field phenotyping. Deep learning methods based on high-spatial-resolution images provide a high-throughput and accurate solution of panicle segmentation. Panicle segmentation tasks require costly annotations to train an accurate and robust deep learning model. However, few public datasets are available for rice-panicle phenotyping. We present a semi-supervised deep learning model training process, which greatly assists the annotation and refinement of training datasets. The model learns the panicle features with limited annotations and localizes more positive samples in the datasets, without further interaction. After the dataset refinement, the number of annotations increased by 40.6%. In addition, we trained and tested modern deep learning models to show how the dataset is beneficial to both detection and segmentation tasks. Results of our comparison experiments can inspire others in dataset preparation and model selection.},
DOI = {10.3390/agronomy11081542}
}



@Article{ijms22158266,
AUTHOR = {Kim, Minsu and Lee, Chaewon and Hong, Subin and Kim, Song Lim and Baek, Jeong-Ho and Kim, Kyung-Hwan},
TITLE = {High-Throughput Phenotyping Methods for Breeding Drought-Tolerant Crops},
JOURNAL = {International Journal of Molecular Sciences},
VOLUME = {22},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {8266},
URL = {https://www.mdpi.com/1422-0067/22/15/8266},
PubMedID = {34361030},
ISSN = {1422-0067},
ABSTRACT = {Drought is a main factor limiting crop yields. Modern agricultural technologies such as irrigation systems, ground mulching, and rainwater storage can prevent drought, but these are only temporary solutions. Understanding the physiological, biochemical, and molecular reactions of plants to drought stress is therefore urgent. The recent rapid development of genomics tools has led to an increasing interest in phenomics, i.e., the study of phenotypic plant traits. Among phenomic strategies, high-throughput phenotyping (HTP) is attracting increasing attention as a way to address the bottlenecks of genomic and phenomic studies. HTP provides researchers a non-destructive and non-invasive method yet accurate in analyzing large-scale phenotypic data. This review describes plant responses to drought stress and introduces HTP methods that can detect changes in plant phenotypes in response to drought.},
DOI = {10.3390/ijms22158266}
}



@Article{rs13153024,
AUTHOR = {Ma, Huiqin and Huang, Wenjiang and Dong, Yingying and Liu, Linyi and Guo, Anting},
TITLE = {Using UAV-Based Hyperspectral Imagery to Detect Winter Wheat Fusarium Head Blight},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {3024},
URL = {https://www.mdpi.com/2072-4292/13/15/3024},
ISSN = {2072-4292},
ABSTRACT = {Fusarium head blight (FHB) is a major winter wheat disease in China. The accurate and timely detection of wheat FHB is vital to scientific field management. By combining three types of spectral features, namely, spectral bands (SBs), vegetation indices (VIs), and wavelet features (WFs), in this study, we explore the potential of using hyperspectral imagery obtained from an unmanned aerial vehicle (UAV), to detect wheat FHB. First, during the wheat filling period, two UAV-based hyperspectral images were acquired. SBs, VIs, and WFs that were sensitive to wheat FHB were extracted and optimized from the two images. Subsequently, a field-scale wheat FHB detection model was formulated, based on the optimal spectral feature combination of SBs, VIs, and WFs (SBs + VIs + WFs), using a support vector machine. Two commonly used data normalization algorithms were utilized before the construction of the model. The single WFs, and the spectral feature combination of optimal SBs and VIs (SBs + VIs), were respectively used to formulate models for comparison and testing. The results showed that the detection model based on the normalized SBs + VIs + WFs, using min–max normalization algorithm, achieved the highest R2 of 0.88 and the lowest RMSE of 2.68% among the three models. Our results suggest that UAV-based hyperspectral imaging technology is promising for the field-scale detection of wheat FHB. Combining traditional SBs and VIs with WFs can improve the detection accuracy of wheat FHB effectively.},
DOI = {10.3390/rs13153024}
}



@Article{su13158600,
AUTHOR = {Sharma, Meenakshi and Kaushik, Prashant and Chawade, Aakash},
TITLE = {Frontiers in the Solicitation of Machine Learning Approaches in Vegetable Science Research},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {8600},
URL = {https://www.mdpi.com/2071-1050/13/15/8600},
ISSN = {2071-1050},
ABSTRACT = {Along with essential nutrients and trace elements, vegetables provide raw materials for the food processing industry. Despite this, plant diseases and unfavorable weather patterns continue to threaten the delicate balance between vegetable production and consumption. It is critical to utilize machine learning (ML) in this setting because it provides context for decision-making related to breeding goals. Cutting-edge technologies for crop genome sequencing and phenotyping, combined with advances in computer science, are currently fueling a revolution in vegetable science and technology. Additionally, various ML techniques such as prediction, classification, and clustering are frequently used to forecast vegetable crop production in the field. In the vegetable seed industry, machine learning algorithms are used to assess seed quality before germination and have the potential to improve vegetable production with desired features significantly; whereas, in plant disease detection and management, the ML approaches can improve decision-support systems that assist in converting massive amounts of data into valuable recommendations. On similar lines, in vegetable breeding, ML approaches are helpful in predicting treatment results, such as what will happen if a gene is silenced. Furthermore, ML approaches can be a saviour to insufficient coverage and noisy data generated using various omics platforms. This article examines ML models in the field of vegetable sciences, which encompasses breeding, biotechnology, and genome sequencing.},
DOI = {10.3390/su13158600}
}



@Article{ma14154316,
AUTHOR = {Emad, Diaa and Fanni, Mohamed A. and Mohamed, Abdelfatah M. and Yoshida, Shigeo},
TITLE = {Low-Computational-Cost Technique for Modeling Macro Fiber Composite Piezoelectric Actuators Using Finite Element Method},
JOURNAL = {Materials},
VOLUME = {14},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {4316},
URL = {https://www.mdpi.com/1996-1944/14/15/4316},
PubMedID = {34361514},
ISSN = {1996-1944},
ABSTRACT = {The large number of interdigitated electrodes (IDEs) in a macro fiber composite (MFC) piezoelectric actuator dictates using a very fine finite element (FE) mesh that requires extremely large computational costs, especially with a large number of actuators. The situation becomes infeasible if repeated finite element simulations are required, as in control tasks. In this paper, an efficient technique is proposed for modeling MFC using a finite element method. The proposed technique replaces the MFC actuator with an equivalent simple monolithic piezoceramic actuator using two electrodes only, which dramatically reduces the computational costs. The proposed technique was proven theoretically since it generates the same electric field, strain, and displacement as the physical MFC. Then, it was validated with the detailed FE model using the actual number of IDEs, as well as with experimental tests using triaxial rosette strain gauges. The computational costs for the simplified model compared with the detailed model were dramatically reduced by about 74% for memory usage, 99% for result file size, and 98.6% for computational time. Furthermore, the experimental results successfully verified the proposed technique with good consistency. To show the effectiveness of the proposed technique, it was used to simulate a morphing wing covered almost entirely by MFCs with low computational cost.},
DOI = {10.3390/ma14154316}
}



@Article{app11157148,
AUTHOR = {Endale, Bedada and Tullu, Abera and Shi, Hayoung and Kang, Beom-Soo},
TITLE = {Robust Approach to Supervised Deep Neural Network Training for Real-Time Object Classification in Cluttered Indoor Environment},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {7148},
URL = {https://www.mdpi.com/2076-3417/11/15/7148},
ISSN = {2076-3417},
ABSTRACT = {Unmanned aerial vehicles (UAVs) are being widely utilized for various missions: in both civilian and military sectors. Many of these missions demand UAVs to acquire artificial intelligence about the environments they are navigating in. This perception can be realized by training a computing machine to classify objects in the environment. One of the well known machine training approaches is supervised deep learning, which enables a machine to classify objects. However, supervised deep learning comes with huge sacrifice in terms of time and computational resources. Collecting big input data, pre-training processes, such as labeling training data, and the need for a high performance computer for training are some of the challenges that supervised deep learning poses. To address these setbacks, this study proposes mission specific input data augmentation techniques and the design of light-weight deep neural network architecture that is capable of real-time object classification. Semi-direct visual odometry (SVO) data of augmented images are used to train the network for object classification. Ten classes of 10,000 different images in each class were used as input data where 80% were for training the network and the remaining 20% were used for network validation. For the optimization of the designed deep neural network, a sequential gradient descent algorithm was implemented. This algorithm has the advantage of handling redundancy in the data more efficiently than other algorithms.},
DOI = {10.3390/app11157148}
}



@Article{app11157151,
AUTHOR = {Hu, Yijun and Shen, Jingfang and Qi, Yonghao},
TITLE = {Estimation of Rice Biomass at Different Growth Stages by Using Fractal Dimension in Image Processing},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {7151},
URL = {https://www.mdpi.com/2076-3417/11/15/7151},
ISSN = {2076-3417},
ABSTRACT = {Rice has long served as the staple food in Asia, and the cultivation of high-yield rice crops draws increasing attention from academic researchers. The prediction of rice growth condition by image features realizes nondestructive prediction and it has great implications for smart agriculture. We found a special image parameter called the fractal dimension that can improve the effect of the prediction model. As an important geometric feature, the fractal dimension could be calculated from the image, but it is rarely used in the field of rice growth prediction. In this paper, we attempt to combine the fractal dimension with traditional rice image features to improve the effect of the model. The thresholding method is used to transform the cropped rice image into binary image, and the box-counting method is used to calculate the fractal dimension of the image. The correlation coefficients are calculated to select the characteristics with a strong correlation with biomass. The prediction models of dry weight, fresh weight and plant height of rice are established by using random forest, support vector regression and linear regression. By evaluating the prediction effect of the model, it can be concluded that the fractal dimension can improve the prediction effect of the model. Among the models obtained by the three methods, the multiple linear regression model has the best comprehensive effect, with the dry weight prediction model R2 reaching 0.8697, the fresh weight prediction model R2 reaching 0.8631 and the plant height prediction model R2 reaching 0.9196. The model established in this paper has a fine effect and has a certain guiding significance in rice research.},
DOI = {10.3390/app11157151}
}



@Article{drones5030073,
AUTHOR = {Doukari, Michaela and Batsaris, Marios and Topouzelis, Konstantinos},
TITLE = {UASea: A Data Acquisition Toolbox for Improving Marine Habitat Mapping},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {73},
URL = {https://www.mdpi.com/2504-446X/5/3/73},
ISSN = {2504-446X},
ABSTRACT = {Unmanned aerial systems (UAS) are widely used in the acquisition of high-resolution information in the marine environment. Although the potential applications of UAS in marine habitat mapping are constantly increasing, many limitations need to be overcome—most of which are related to the prevalent environmental conditions—to reach efficient UAS surveys. The knowledge of the UAS limitations in marine data acquisition and the examination of the optimal flight conditions led to the development of the UASea toolbox. This study presents the UASea, a data acquisition toolbox that is developed for efficient UAS surveys in the marine environment. The UASea uses weather forecast data (i.e., wind speed, cloud cover, precipitation probability, etc.) and adaptive thresholds in a ruleset that calculates the optimal flight times in a day for the acquisition of reliable marine imagery using UAS in a given day. The toolbox provides hourly positive and negative suggestions, based on optimal or non-optimal survey conditions in a day, calculated according to the ruleset calculations. We acquired UAS images in optimal and non-optimal conditions and estimated their quality using an image quality equation. The image quality estimates are based on the criteria of sunglint presence, sea surface texture, water turbidity, and image naturalness. The overall image quality estimates were highly correlated with the suggestions of the toolbox, with a correlation coefficient of −0.84. The validation showed that 40% of the toolbox suggestions were a positive match to the images with higher quality. Therefore, we propose the optimal flight times to acquire reliable and accurate UAS imagery in the coastal environment through the UASea. The UASea contributes to proper flight planning and efficient UAS surveys by providing valuable information for mapping, monitoring, and management of the marine environment, which can be used globally in research and marine applications.},
DOI = {10.3390/drones5030073}
}



@Article{electronics10151864,
AUTHOR = {Sheu, Ming-Hwa and Jhang, Yu-Syuan and Morsalin, S M Salahuddin and Huang, Yao-Fong and Sun, Chi-Chia and Lai, Shin-Chi},
TITLE = {UAV Object Tracking Application Based on Patch Color Group Feature on Embedded System},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {1864},
URL = {https://www.mdpi.com/2079-9292/10/15/1864},
ISSN = {2079-9292},
ABSTRACT = {The discriminative object tracking system for unmanned aerial vehicles (UAVs) is widely used in numerous applications. While an ample amount of research has been carried out in this domain, implementing a low computational cost algorithm on a UAV onboard embedded system is still challenging. To address this issue, we propose a low computational complexity discriminative object tracking system for UAVs approach using the patch color group feature (PCGF) framework in this work. The tracking object is separated into several non-overlapping local image patches then the features are extracted into the PCGFs, which consist of the Gaussian mixture model (GMM). The object location is calculated by the similar PCGFs comparison from the previous frame and current frame. The background PCGFs of the object are removed by four directions feature scanning and dynamic threshold comparison, which improve the performance accuracy. In the terms of speed execution, the proposed algorithm accomplished 32.5 frames per second (FPS) on the x64 CPU platform without a GPU accelerator and 17 FPS in Raspberry Pi 4. Therefore, this work could be considered as a good solution for achieving a low computational complexity PCGF algorithm on a UAV onboard embedded system to improve flight times.},
DOI = {10.3390/electronics10151864}
}



@Article{agronomy11081554,
AUTHOR = {Lee, Dong-Ho and Kim, Hyeon-Jin and Park, Jong-Hwa},
TITLE = {UAV, a Farm Map, and Machine Learning Technology Convergence Classification Method of a Corn Cultivation Area},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1554},
URL = {https://www.mdpi.com/2073-4395/11/8/1554},
ISSN = {2073-4395},
ABSTRACT = {South Korea’s agriculture is characterized by a mixture of various cultivated crops. In such an agricultural environment, convergence technology for ICT (information, communications, and technology) and AI (artificial intelligence) as well as agriculture is required to classify objects and predict yields. In general, the classification of paddy fields and field boundaries takes a lot of time and effort. The Farm Map was developed to clearly demarcate and classify the boundaries of paddy fields and fields in Korea. Therefore, this study tried to minimize the time and effort required to divide paddy fields and fields through the application of the Farm Map. To improve the fact that UAV image processing for a wide area requires a lot of time and effort to classify objects, we suggest a method for optimizing cultivated crop recognition. This study aimed to evaluate the applicability and effectiveness of machine learning classification techniques using a Farm Map in object-based mapping of agricultural land using unmanned aerial vehicles (UAVs). In this study, the advanced function selection method for object classification is to improve classification accuracy by using two types of classifiers, support vector machine (SVM) and random forest (RF). As a result of classification by applying a Farm Map-based SVM algorithm to wide-area UAV images, producer’s accuracy (PA) was 81.68%, user’s accuracy (UA) was 75.09%, the Kappa coefficient was 0.77, and the F-measure was 0.78. The results of classification by the Farm Map-based RF algorithm were as follows: PA of 96.58%, UA of 92.27%, a Kappa coefficient of 0.94, and the F-measure of 0.94. In the cultivation environment in which various crops were mixed, the corn cultivation area was estimated to be 96.54 ha by SVM, showing an accuracy of 90.27%. RF provided an estimate of 98.77 ha and showed an accuracy of 92.36%, which was higher than that of SVM. As a result of using the Farm Map for the object-based classification method, the agricultural land classification showed a higher efficiency in terms of time than the existing object classification method. Most importantly, it was confirmed that the efficiency of data processing can be increased by minimizing the possibility of misclassification in the obtained results. The obtained results confirmed that rapid and reliable analysis is possible when the cultivated area of crops is identified using UAV images, a Farm Map, and machine learning.},
DOI = {10.3390/agronomy11081554}
}



@Article{agriculture11080740,
AUTHOR = {Ghajar, Shayan and Tracy, Benjamin},
TITLE = {Proximal Sensing in Grasslands and Pastures},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {740},
URL = {https://www.mdpi.com/2077-0472/11/8/740},
ISSN = {2077-0472},
ABSTRACT = {Reliable measures of biomass, species composition, nitrogen status, and nutritive value provide important indicators of the status of pastures and rangelands, allowing managers to make informed decisions. Traditional methods of sample collection necessitate significant investments in time and labor. Proximal sensing technologies have the potential to collect more data with a smaller investment in time and labor. However, methods and protocols for conducting pasture assessments with proximal sensors are still in development, equipment and software vary considerably, and the accuracy and utility of these assessments differ between methods and sites. This review summarizes the methods currently being developed to assess pastures and rangelands worldwide and discusses these emerging technologies in the context of diffusion of innovation theory.},
DOI = {10.3390/agriculture11080740}
}



@Article{agronomy11081557,
AUTHOR = {Santana, Lucas Santos and Ferraz, Gabriel Araújo e Silva and Teodoro, Alberdan José da Silva and Santana, Mozarte Santos and Rossi, Giuseppe and Palchetti, Enrico},
TITLE = {Advances in Precision Coffee Growing Research: A Bibliometric Review},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1557},
URL = {https://www.mdpi.com/2073-4395/11/8/1557},
ISSN = {2073-4395},
ABSTRACT = {Precision coffee-growing technologies contribute to increased yield, operational efficiency, and final product quality. In addition, they strengthen coffee growing in the global agricultural scenario, which makes this activity increasingly competitive. Scientific research is essential for technological development and offering security regarding its application. For relevant research identification, bibliometric revision methods expose the best studies and their relationships with countries and authors, providing a complete map of research directions. This study identified the main contributions and contributors to academic research generation about precision coffee growing from 2000 to 2021. Bibliometric analysis was performed in VOSViewer software from the referential bases Scopus and Web of Science that identified 150 articles. Based on the number of citations, publications about precision coffee-growing showed Brazilian institutions at the top of the list, and Brazil’s close relationships with North American and South African institutions. Geostatistical analysis, remote sensing and spatial variability mapping of cultivation areas were used in most experimental research. A trend in research exploring machine learning technologies and autonomous systems was evident. The identification of the main agents of scientific development in precision coffee growing contributes to objective advances in the development and application of new management systems. Overall, this analysis represents wide precision coffee growing research providing valuable information for farmers, policymakers, and researchers.},
DOI = {10.3390/agronomy11081557}
}



@Article{rs13163073,
AUTHOR = {Bai, Xueyuan and Li, Zhenhai and Li, Wei and Zhao, Yu and Li, Meixuan and Chen, Hongyan and Wei, Shaochong and Jiang, Yuanmao and Yang, Guijun and Zhu, Xicun},
TITLE = {Comparison of Machine-Learning and CASA Models for Predicting Apple Fruit Yields from Time-Series Planet Imageries},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3073},
URL = {https://www.mdpi.com/2072-4292/13/16/3073},
ISSN = {2072-4292},
ABSTRACT = {Apple (Malus domestica Borkh. cv. “Fuji”), an important cash crop, is widely consumed around the world. Accurately predicting preharvest apple fruit yields is critical for planting policy making and agricultural management. This study attempted to explore an effective approach for predicting apple fruit yields based on time-series remote sensing data. In this study, time-series vegetation indices (VIs) were derived from Planet images and analyzed to further construct an accumulated VI (∑VIs)-based random forest (RF∑VI) model and a Carnegie–Ames–Stanford approach (CASA) model for predicting apple fruit yields. The results showed that (1) ∑NDVI was the optimal predictor to construct an RF model for apple fruit yield, and the R2, RMSE, and RPD values of the RF∑NDVI model reached 0.71, 16.40 kg/tree, and 1.83, respectively. (2) The maximum light use efficiency was determined to be 0.499 g C/MJ, and the CASASR model (R2 = 0.57, RMSE = 19.61 kg/tree, and RPD = 1.53) performed better than the CASANDVI model and the CASAAverage model (R2, RMSE, and RPD = 0.56, 24.47 kg/tree, 1.22 and 0.57, 20.82 kg/tree, 1.44, respectively). (3) This study compared the yield prediction accuracies obtained by the models using the same dataset, and the RF∑NDVI model (RPD = 1.83) showed a better performance in predicting apple fruit yields than the CASASR model (RPD = 1.53). The results obtained from this study indicated the potential of the RF∑NDVI model based on time-series Planet images to accurately predict apple fruit yields. The models could provide spatial and quantitative information of apple fruit yield, which would be valuable for agronomists to predict regional apple production to inform and develop national planting policies, agricultural management, and export strategies.},
DOI = {10.3390/rs13163073}
}



@Article{s21165293,
AUTHOR = {Pikalov, Simon and Azaria, Elisha and Sonnenberg, Shaya and Ben-Moshe, Boaz and Azaria, Amos},
TITLE = {Vision-Less Sensing for Autonomous Micro-Drones},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5293},
URL = {https://www.mdpi.com/1424-8220/21/16/5293},
PubMedID = {34450742},
ISSN = {1424-8220},
ABSTRACT = {This work presents a concept of intelligent vision-less micro-drones, which are motivated by flying animals such as insects, birds, and bats. The presented micro-drone (named BAT: Blind Autonomous Tiny-drone) can perform bio-inspired complex tasks without the use of cameras. The BAT uses LIDARs and self-emitted optical-flow in order to perform obstacle avoiding and maze-solving. The controlling algorithms were implemented on an onboard micro-controller, allowing the BAT to be fully autonomous. We further present a method for using the information collected by the drone to generate a detailed mapping of the environment. A complete model of the BAT was implemented and tested using several scenarios both in simulation and field experiments, in which it was able to explore and map complex building autonomously even in total darkness.},
DOI = {10.3390/s21165293}
}



@Article{rs13163088,
AUTHOR = {Wolf, Stefan and Sommer, Lars and Schumann, Arne},
TITLE = {FastAER Det: Fast Aerial Embedded Real-Time Detection},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3088},
URL = {https://www.mdpi.com/2072-4292/13/16/3088},
ISSN = {2072-4292},
ABSTRACT = {Automated detection of objects in aerial imagery is the basis for many applications, such as search and rescue operations, activity monitoring or mapping. However, in many cases it is beneficial to employ a detector on-board of the aerial platform in order to avoid latencies, make basic decisions within the platform and save transmission bandwidth. In this work, we address the task of designing such an on-board aerial object detector, which meets certain requirements in accuracy, inference speed and power consumption. For this, we first outline a generally applicable design process for such on-board methods and then follow this process to develop our own set of models for the task. Specifically, we first optimize a baseline model with regards to accuracy while not increasing runtime. We then propose a fast detection head to significantly improve runtime at little cost in accuracy. Finally, we discuss several aspects to consider during deployment and in the runtime environment. Our resulting four models that operate at 15, 30, 60 and 90 FPS on an embedded Jetson AGX device are published for future benchmarking and comparison by the community.},
DOI = {10.3390/rs13163088}
}



@Article{rs13163095,
AUTHOR = {Zhao, Jianqing and Zhang, Xiaohu and Yan, Jiawei and Qiu, Xiaolei and Yao, Xia and Tian, Yongchao and Zhu, Yan and Cao, Weixing},
TITLE = {A Wheat Spike Detection Method in UAV Images Based on Improved YOLOv5},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3095},
URL = {https://www.mdpi.com/2072-4292/13/16/3095},
ISSN = {2072-4292},
ABSTRACT = {Deep-learning-based object detection algorithms have significantly improved the performance of wheat spike detection. However, UAV images crowned with small-sized, highly dense, and overlapping spikes cause the accuracy to decrease for detection. This paper proposes an improved YOLOv5 (You Look Only Once)-based method to detect wheat spikes accurately in UAV images and solve spike error detection and miss detection caused by occlusion conditions. The proposed method introduces data cleaning and data augmentation to improve the generalization ability of the detection network. The network is rebuilt by adding a microscale detection layer, setting prior anchor boxes, and adapting the confidence loss function of the detection layer based on the IoU (Intersection over Union). These refinements improve the feature extraction for small-sized wheat spikes and lead to better detection accuracy. With the confidence weights, the detection boxes in multiresolution images are fused to increase the accuracy under occlusion conditions. The result shows that the proposed method is better than the existing object detection algorithms, such as Faster RCNN, Single Shot MultiBox Detector (SSD), RetinaNet, and standard YOLOv5. The average accuracy (AP) of wheat spike detection in UAV images is 94.1%, which is 10.8% higher than the standard YOLOv5. Thus, the proposed method is a practical way to handle the spike detection in complex field scenarios and provide technical references for field-level wheat phenotype monitoring.},
DOI = {10.3390/rs13163095}
}



@Article{rs13163100,
AUTHOR = {Qi, Guanghui and Chang, Chunyan and Yang, Wei and Gao, Peng and Zhao, Gengxing},
TITLE = {Soil Salinity Inversion in Coastal Corn Planting Areas by the Satellite-UAV-Ground Integration Approach},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3100},
URL = {https://www.mdpi.com/2072-4292/13/16/3100},
ISSN = {2072-4292},
ABSTRACT = {Soil salinization is a significant factor affecting corn growth in coastal areas. How to use multi-source remote sensing data to achieve the target of rapid, efficient and accurate soil salinity monitoring in a large area is worth further study. In this research, using Kenli District of the Yellow River Delta as study area, the inversion of soil salinity in a corn planting area was carried out based on the integration of ground imaging hyperspectral, unmanned aerial vehicles (UAV) multispectral and Sentinel-2A satellite multispectral images. The UAV and ground images were fused, and the partial least squares inversion model was constructed by the fused UAV image. Then, inversion model was scaled up to the satellite by the TsHARP method, and finally, the accuracy of the satellite-UAV-ground inversion model and results was verified. The results show that the band fusion of UAV and ground images effectively enrich the spectral information of the UAV image. The accuracy of the inversion model constructed based on the fused UAV images was improved. The inversion results of soil salinity based on the integration of satellite-UAV-ground were highly consistent with the measured soil salinity (R2 = 0.716 and RMSE = 0.727), and the inversion model had excellent universal applicability. This research integrated the advantages of multi-source data to establish a unified satellite-UAV-ground model, which improved the ability of large-scale remote sensing data to finely indicate soil salinity.},
DOI = {10.3390/rs13163100}
}



@Article{min11080846,
AUTHOR = {Sinaice, Brian Bino and Owada, Narihiro and Saadat, Mahdi and Toriya, Hisatoshi and Inagaki, Fumiaki and Bagai, Zibisani and Kawamura, Youhei},
TITLE = {Coupling NCA Dimensionality Reduction with Machine Learning in Multispectral Rock Classification Problems},
JOURNAL = {Minerals},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {846},
URL = {https://www.mdpi.com/2075-163X/11/8/846},
ISSN = {2075-163X},
ABSTRACT = {Though multitudes of industries depend on the mining industry for resources, this industry has taken hits in terms of declining mineral ore grades and its current use of traditional, time-consuming and computationally costly rock and mineral identification methods. Therefore, this paper proposes integrating Hyperspectral Imaging, Neighbourhood Component Analysis (NCA) and Machine Learning (ML) as a combined system that can identify rocks and minerals. Modestly put, hyperspectral imaging gathers electromagnetic signatures of the rocks in hundreds of spectral bands. However, this data suffers from what is termed the ‘dimensionality curse’, which led to our employment of NCA as a dimensionality reduction technique. NCA, in turn, highlights the most discriminant feature bands, number of which being dependent on the intended application(s) of this system. Our envisioned application is rock and mineral classification via unmanned aerial vehicle (UAV) drone technology. In this study, we performed a 204-hyperspectral to 5-band multispectral reduction, because current production drones are limited to five multispectral bands sensors. Based on these bands, we applied ML to identify and classify rocks, thereby proving our hypothesis, reducing computational costs, attaining an ML classification accuracy of 71%, and demonstrating the potential mining industry optimisations attainable through this integrated system.},
DOI = {10.3390/min11080846}
}



@Article{make3030033,
AUTHOR = {Sejr, Jonas Herskind and Schneider-Kamp, Peter and Ayoub, Naeem},
TITLE = {Surrogate Object Detection Explainer (SODEx) with YOLOv4 and LIME},
JOURNAL = {Machine Learning and Knowledge Extraction},
VOLUME = {3},
YEAR = {2021},
NUMBER = {3},
PAGES = {662--671},
URL = {https://www.mdpi.com/2504-4990/3/3/33},
ISSN = {2504-4990},
ABSTRACT = {Due to impressive performance, deep neural networks for object detection in images have become a prevalent choice. Given the complexity of the neural network models used, users of these algorithms are typically given no hint as to how the objects were found. It remains, for example, unclear whether an object is detected based on what it looks like or based on the context in which it is located. We have developed an algorithm, Surrogate Object Detection Explainer (SODEx), that can explain any object detection algorithm using any classification explainer. We evaluate SODEx qualitatively and quantitatively by detecting objects in the COCO dataset with YOLOv4 and explaining these detections with LIME. This empirical evaluation does not only demonstrate the value of explainable object detection, it also provides valuable insights into how YOLOv4 detects objects.},
DOI = {10.3390/make3030033}
}



@Article{app11167240,
AUTHOR = {Jembre, Yalew Zelalem and Nugroho, Yuniarto Wimbo and Khan, Muhammad Toaha Raza and Attique, Muhammad and Paul, Rajib and Shah, Syed Hassan Ahmed and Kim, Beomjoon},
TITLE = {Evaluation of Reinforcement and Deep Learning Algorithms in Controlling Unmanned Aerial Vehicles},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {7240},
URL = {https://www.mdpi.com/2076-3417/11/16/7240},
ISSN = {2076-3417},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) are abundantly becoming a part of society, which is a trend that is expected to grow even further. The quadrotor is one of the drone technologies that is applicable in many sectors and in both military and civilian activities, with some applications requiring autonomous flight. However, stability, path planning, and control remain significant challenges in autonomous quadrotor flights. Traditional control algorithms, such as proportional-integral-derivative (PID), have deficiencies, especially in tuning. Recently, machine learning has received great attention in flying UAVs to desired positions autonomously. In this work, we configure the quadrotor to fly autonomously by using agents (the machine learning schemes being used to fly the quadrotor autonomously) to learn about the virtual physical environment. The quadrotor will fly from an initial to a desired position. When the agent brings the quadrotor closer to the desired position, it is rewarded; otherwise, it is punished. Two reinforcement learning models, Q-learning and SARSA, and a deep learning deep Q-network network are used as agents. The simulation is conducted by integrating the robot operating system (ROS) and Gazebo, which allowed for the implementation of the learning algorithms and the physical environment, respectively. The result has shown that the Deep Q-network network with Adadelta optimizer is the best setting to fly the quadrotor from the initial to desired position.},
DOI = {10.3390/app11167240}
}



@Article{s21165316,
AUTHOR = {Qin, Yongming and Kumon, Makoto and Furukawa, Tomonari},
TITLE = {Estimation of a Human-Maneuvered Target Incorporating Human Intention},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5316},
URL = {https://www.mdpi.com/1424-8220/21/16/5316},
PubMedID = {34450757},
ISSN = {1424-8220},
ABSTRACT = {This paper presents a new approach for estimating the motion state of a target that is maneuvered by an unknown human from observations. To improve the estimation accuracy, the proposed approach associates the recurring motion behaviors with human intentions, and models the association as an intention-pattern model. The human intentions relate to labels of continuous states; the motion patterns characterize the change of continuous states. In the preprocessing, an Interacting Multiple Model (IMM) estimation technique is used to infer the intentions and extract motions, which eventually construct the intention-pattern model. Once the intention-pattern model has been constructed, the proposed approach incorporate the intention-pattern model to estimation using any state estimator including Kalman filter. The proposed approach not only estimates the mean using the human intention more accurately but also updates the covariance using the human intention more precisely. The performance of the proposed approach was investigated through the estimation of a human-maneuvered multirotor. The result of the application has first indicated the effectiveness of the proposed approach for constructing the intention-pattern model. The ability of the proposed approach in state estimation over the conventional technique without intention incorporation has then been demonstrated.},
DOI = {10.3390/s21165316}
}



@Article{s21165323,
AUTHOR = {Kim, Yongsu and Kang, Hyoeun and Suryanto, Naufal and Larasati, Harashta Tatimma and Mukaroh, Afifatul and Kim, Howon},
TITLE = {Extended Spatially Localized Perturbation GAN (eSLP-GAN) for Robust Adversarial Camouflage Patches},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5323},
URL = {https://www.mdpi.com/1424-8220/21/16/5323},
PubMedID = {34450763},
ISSN = {1424-8220},
ABSTRACT = {Deep neural networks (DNNs), especially those used in computer vision, are highly vulnerable to adversarial attacks, such as adversarial perturbations and adversarial patches. Adversarial patches, often considered more appropriate for a real-world attack, are attached to the target object or its surroundings to deceive the target system. However, most previous research employed adversarial patches that are conspicuous to human vision, making them easy to identify and counter. Previously, the spatially localized perturbation GAN (SLP-GAN) was proposed, in which the perturbation was only added to the most representative area of the input images, creating a spatially localized adversarial camouflage patch that excels in terms of visual fidelity and is, therefore, difficult to detect by human vision. In this study, the use of the method called eSLP-GAN was extended to deceive classifiers and object detection systems. Specifically, the loss function was modified for greater compatibility with an object-detection model attack and to increase robustness in the real world. Furthermore, the applicability of the proposed method was tested on the CARLA simulator for a more authentic real-world attack scenario.},
DOI = {10.3390/s21165323}
}



@Article{rs13163105,
AUTHOR = {Yu, Jody and Wang, Jinfei and Leblon, Brigitte},
TITLE = {Evaluation of Soil Properties, Topographic Metrics, Plant Height, and Unmanned Aerial Vehicle Multispectral Imagery Using Machine Learning Methods to Estimate Canopy Nitrogen Weight in Corn},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3105},
URL = {https://www.mdpi.com/2072-4292/13/16/3105},
ISSN = {2072-4292},
ABSTRACT = {Management of nitrogen (N) fertilizers is an important agricultural practice and field of research to minimize environmental impacts and the cost of production. To apply N fertilizer at the right rate, time, and place depends on the crop type, desired yield, and field conditions. The objective of this study is to use Unmanned Aerial Vehicle (UAV) multispectral imagery, vegetation indices (VI), crop height, field topographic metrics, and soil properties to predict canopy nitrogen weight (g/m2) of a corn field in southwestern Ontario, Canada. Random Forests (RF) and support vector regression (SVR) models were evaluated for canopy nitrogen weight prediction from 29 variables. RF consistently had better performance than SVR, and the top-performing validation model was RF using 15 selected height, spectral, and topographic variables with an R2 of 0.73 and Root Mean Square Error (RMSE) of 2.21 g/m2. Of the model’s 15 variables, crop height was the most important predictor, followed by 10 VIs, three MicaSense band reflectance mosaics (blue, red, and green), and topographic profile curvature. The model information can be used to improve field nitrogen prediction, leading to more effective and efficient N fertilizer management.},
DOI = {10.3390/rs13163105}
}



@Article{s21165326,
AUTHOR = {Ramalingam, Balakrishnan and Tun, Thein and Mohan, Rajesh Elara and Gómez, Braulio Félix and Cheng, Ruoxi and Balakrishnan, Selvasundari and Mohan Rayaguru, Madan and Hayat, Abdullah Aamir},
TITLE = {AI Enabled IoRT Framework for Rodent Activity Monitoring in a False Ceiling Environment},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5326},
URL = {https://www.mdpi.com/1424-8220/21/16/5326},
PubMedID = {34450767},
ISSN = {1424-8220},
ABSTRACT = {Routine rodent inspection is essential to curbing rat-borne diseases and infrastructure damages within the built environment. Rodents find false ceilings to be a perfect spot to seek shelter and construct their habitats. However, a manual false ceiling inspection for rodents is laborious and risky. This work presents an AI-enabled IoRT framework for rodent activity monitoring inside a false ceiling using an in-house developed robot called “Falcon”. The IoRT serves as a bridge between the users and the robots, through which seamless information sharing takes place. The shared images by the robots are inspected through a Faster RCNN ResNet 101 object detection algorithm, which is used to automatically detect the signs of rodent inside a false ceiling. The efficiency of the rodent activity detection algorithm was tested in a real-world false ceiling environment, and detection accuracy was evaluated with the standard performance metrics. The experimental results indicate that the algorithm detects rodent signs and 3D-printed rodents with a good confidence level.},
DOI = {10.3390/s21165326}
}



@Article{su13168807,
AUTHOR = {Bakó, Gábor and Molnár, Zsolt and Bakk, Lilla and Horváth, Ferenc and Fehér, Luca and Ábrám, Örs and Morvai, Edina and Biro, Csaba and Pápay, Gergely and Fűrész, Attila and Penksza, Károly and Pácsonyi, Diána and Demény, Krisztina and Juhász, Erika and Dékány, Dorottya and Csernyava, Lili and Illés, Gábor and Molnár, András},
TITLE = {Toward a High Spatial Resolution Aerial Monitoring Network for Nature Conservation—How Can Remote Sensing Help Protect Natural Areas?},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {8807},
URL = {https://www.mdpi.com/2071-1050/13/16/8807},
ISSN = {2071-1050},
ABSTRACT = {Aerial surveys have always significantly contributed to the accurate mapping of certain geographical phenomena. Remote sensing opened up new perspectives in nature monitoring with state-of-the-art technical solutions using modern onboard recording equipment. We developed the technical background and the methodology that supports detailed and cost-effective monitoring of a network of natural areas, thereby detecting temporal changes in the spatial pattern of land cover, species, biodiversity, and other natural features. In this article, we share our experiences of the technical background, geometric accuracy and results of comparisons with selected Copernicus Land Monitoring products and an Ecosystem Map based on the testing of our methodology at 25 sites in Hungary. We combined a high-spatial-resolution aerial remote sensing service with field studies to support an efficient nature conservation monitoring network at 25 permanent sites. By analyzing annually (or more frequently) orthophotos taken with a range of 0.5–5 cm spatial resolution and 3D surface models of aerial surveys, it is possible to map the upper canopy of vegetation species. Furthermore, it allows us to accurately follow the changes in the dynamics at the forest edge and upper canopy, or the changes in species’ dominance in meadows. Additionally, spatial data obtained from aerial surveys and field studies can expand the knowledge base of the High-Resolution Aerial Monitoring Network (HRAMN) and support conservation and restoration management. A well-conducted high-resolution survey can reveal the impacts of land interventions and habitat regeneration. By building the HRAMN network, nature conservation could have an up-to-date database that could prompt legal processes, establish protection designation procedures and make environmental habitat management more cost-effective. Landscape protection could also utilize the services of HRAMN in planning and risk reduction interventions through more reliable inputs to environmental models.},
DOI = {10.3390/su13168807}
}



@Article{w13162163,
AUTHOR = {Chao, Zhenhua and Fang, Xuan and Na, Jiaming and Che, Mingliang},
TITLE = {A Collaborative Sensing System for Farmland Water Conservancy Project Maintenance through Integrating Satellite, Aerial, and Ground Observations},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {2163},
URL = {https://www.mdpi.com/2073-4441/13/16/2163},
ISSN = {2073-4441},
ABSTRACT = {More and more attention has been paid to farmland water conservancy project (FWCP) maintenance in China, which can reallocate water resources in a more rational and efficient manner. Compared with the traditional survey such as field survey, FWCP maintenance can be improved efficiently with geospatial technology. To improve the level of FWCP maintenance in China, a collaborative sensing system framework by integrating satellite, aerial, and ground remote sensing is put forward. The structure of the system framework includes three sections, namely the data acquisition, the operational work, and the application and service. Through the construction and operation of such collaborative sensing system, it will break through the limitation of any single remote sensing platform and provide all-around and real-time information on FWCP. The collaborative monitoring schemes for the designed FWCP maintenance can engage ditch riders to maintain more effectively, which will enable them to communicate more specifically with smallholders in the process of irrigation. Only when ditch riders and farmers are fully involved, irrigation efficiency will be improved. Furthermore, the collaborative sensing system needs feasible standards for multi-source remote sensing data processing and intelligent information extraction such as data fusion, data assimilation, and data mining. In a way, this will promote the application of remote sensing in the field of agricultural irrigation and water saving. On the whole, it will be helpful to improve the traditional maintenance problems and is also the guarantee for establishing a long-term scientific management mechanism of FWCP maintenance in developing countries, especially in China.},
DOI = {10.3390/w13162163}
}



@Article{rs13163136,
AUTHOR = {Tait, Leigh W. and Orchard, Shane and Schiel, David R.},
TITLE = {Missing the Forest and the Trees: Utility, Limits and Caveats for Drone Imaging of Coastal Marine Ecosystems},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3136},
URL = {https://www.mdpi.com/2072-4292/13/16/3136},
ISSN = {2072-4292},
ABSTRACT = {Coastal marine ecosystems are under stress, yet actionable information about the cumulative effects of human impacts has eluded ecologists. Habitat-forming seaweeds in temperate regions provide myriad irreplaceable ecosystem services, but they are increasingly at risk of local and regional extinction from extreme climatic events and the cumulative impacts of land-use change and extractive activities. Informing appropriate management strategies to reduce the impacts of stressors requires comprehensive knowledge of species diversity, abundance and distributions. Remote sensing undoubtedly provides answers, but collecting imagery at appropriate resolution and spatial extent, and then accurately and precisely validating these datasets is not straightforward. Comprehensive and long-running monitoring of rocky reefs exist globally but are often limited to a small subset of reef platforms readily accessible to in-situ studies. Key vulnerable habitat-forming seaweeds are often not well-assessed by traditional in-situ methods, nor are they well-captured by passive remote sensing by satellites. Here we describe the utility of drone-based methods for monitoring and detecting key rocky intertidal habitat types, the limitations and caveats of these methods, and suggest a standardised workflow for achieving consistent results that will fulfil the needs of managers for conservation efforts.},
DOI = {10.3390/rs13163136}
}



@Article{ani11082345,
AUTHOR = {Monteiro, António and Santos, Sérgio and Gonçalves, Pedro},
TITLE = {Precision Agriculture for Crop and Livestock Farming—Brief Review},
JOURNAL = {Animals},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2345},
URL = {https://www.mdpi.com/2076-2615/11/8/2345},
PubMedID = {34438802},
ISSN = {2076-2615},
ABSTRACT = {In the last few decades, agriculture has played an important role in the worldwide economy. The need to produce more food for a rapidly growing population is creating pressure on crop and animal production and a negative impact to the environment. On the other hand, smart farming technologies are becoming increasingly common in modern agriculture to assist in optimizing agricultural and livestock production and minimizing the wastes and costs. Precision agriculture (PA) is a technology-enabled, data-driven approach to farming management that observes, measures, and analyzes the needs of individual fields and crops. Precision livestock farming (PLF), relying on the automatic monitoring of individual animals, is used for animal growth, milk production, and the detection of diseases as well as to monitor animal behavior and their physical environment, among others. This study aims to briefly review recent scientific and technological trends in PA and their application in crop and livestock farming, serving as a simple research guide for the researcher and farmer in the application of technology to agriculture. The development and operation of PA applications involve several steps and techniques that need to be investigated further to make the developed systems accurate and implementable in commercial environments.},
DOI = {10.3390/ani11082345}
}



@Article{rs13163145,
AUTHOR = {Singh, Sarvesh Kumar and Banerjee, Bikram Pratap and Raval, Simit},
TITLE = {Three-Dimensional Unique-Identifier-Based Automated Georeferencing and Coregistration of Point Clouds in Underground Mines},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3145},
URL = {https://www.mdpi.com/2072-4292/13/16/3145},
ISSN = {2072-4292},
ABSTRACT = {Spatially referenced and geometrically accurate laser scans are essential for mapping and monitoring applications in underground mines to ensure safe and smooth operation. However, obtaining an absolute 3D map in an underground mine environment is challenging using laser scanning due to the unavailability of global navigation satellite system (GNSS) signals. Consequently, applications that require georeferenced point cloud or coregistered multitemporal point clouds such as detecting changes, monitoring deformations, tracking mine logistics, measuring roadway convergence rate and evaluating construction performance become challenging. Current mapping practices largely include a manual selection of discernable reference points in laser scans for georeferencing and coregistration which is often time-consuming, arduous and error-prone. Moreover, challenges in obtaining a sensor positioning framework, the presence of structurally symmetric layouts and highly repetitive features (such as roof bolts) makes the multitemporal scans difficult to georeference and coregister. This study aims at overcoming these practical challenges through development of three-dimensional unique identifiers (3DUIDs) and a 3D registration (3DReG) workflow. Field testing of the developed approach in an underground coal mine has been found effective with an accuracy of 1.76 m in georeferencing and 0.16 m in coregistration for a scan length of 850 m. Additionally, automatic extraction of mine roadway profile has been demonstrated using 3DUID which is often a compliant and operational requirement for mitigating roadway related hazards that includes roadway convergence rate, roof/rock falls, floor heaves and vehicle clearance for collision avoidance. Potential applications of 3DUID include roadway profile extraction, guided automation, sensor calibration, reference targets for a routine survey and deformation monitoring.},
DOI = {10.3390/rs13163145}
}



@Article{rs13163146,
AUTHOR = {Chen, Dong and Li, Jing and Di, Shaoning and Peethambaran, Jiju and Xiang, Guiqiu and Wan, Lincheng and Li, Xianghong},
TITLE = {Critical Points Extraction from Building Façades by Analyzing Gradient Structure Tensor},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3146},
URL = {https://www.mdpi.com/2072-4292/13/16/3146},
ISSN = {2072-4292},
ABSTRACT = {This paper proposes a building façade contouring method from LiDAR (Light Detection and Ranging) scans and photogrammetric point clouds. To this end, we calculate the confidence property at multiple scales for an individual point cloud to measure the point cloud’s quality. The confidence property is utilized in the definition of the gradient for each point. We encode the individual point gradient structure tensor, whose eigenvalues reflect the gradient variations in the local neighborhood areas. The critical point clouds representing the building façade and rooftop (if, of course, such rooftops exist) contours are then extracted by jointly analyzing dual-thresholds of the gradient and gradient structure tensor. Based on the requirements of compact representation, the initial obtained critical points are finally downsampled, thereby achieving a tradeoff between the accurate geometry and abstract representation at a reasonable level. Various experiments using representative buildings in Semantic3D benchmark and other ubiquitous point clouds from ALS DublinCity and Dutch AHN3 datasets, MLS TerraMobilita/iQmulus 3D urban analysis benchmark, UAV-based photogrammetric dataset, and GeoSLAM ZEB-HORIZON scans have shown that the proposed method generates building contours that are accurate, lightweight, and robust to ubiquitous point clouds. Two comparison experiments also prove the superiority of the proposed method in terms of topological correctness, geometric accuracy, and representation compactness.},
DOI = {10.3390/rs13163146}
}



@Article{s21165365,
AUTHOR = {Ma, Yue and Rose, Francis and Wong, Leslie and Vien, Benjamin Steven and Kuen, Thomas and Rajic, Nik and Kodikara, Jayantha and Chiu, Wingkong},
TITLE = {Detection of Defects in Geomembranes Using Quasi-Active Infrared Thermography},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5365},
URL = {https://www.mdpi.com/1424-8220/21/16/5365},
PubMedID = {34450812},
ISSN = {1424-8220},
ABSTRACT = {High-density polyethylene geomembranes are employed as covers for the sewage treatment lagoons at Melbourne Water Corporation’s Western Treatment Plant, to harvest the biogas produced during anaerobic degradation, which is then used to generate electricity. Due to its size, inspecting the cover for defects, particularly subsurface defects, can be challenging, as well as the potential for the underside of the membrane to come into contact with different substrates, viz. liquid sewage, scum (consolidated solid matter), and biogas. This paper presents the application of a novel quasi-active thermography inspection method for subsurface defect detection in the geomembrane. The proposed approach utilises ambient sunlight as the input thermal energy and cloud shading as the trigger for thermal transients. Outdoor laboratory-scale experiments were conducted to study the proposed inspection technique. A pyranometer was used to measure the intensity of solar radiation, and an infrared thermal camera was used to measure the surface temperature of the geomembrane. The measured temperature profile was analysed using three different algorithms for thermal transient analysis, based on (i) the cooling constant from Newton’s law of cooling, (ii) the peak value of the logarithmic second derivative, and (iii) a frame subtraction method. The outcomes from each algorithm were examined and compared. The results show that, while each algorithm has some limitations, when used in combination the three algorithms could be used to distinguish between different substrates and to determine the presence of subsurface defects.},
DOI = {10.3390/s21165365}
}



@Article{rs13163150,
AUTHOR = {Jovanović, Dušan and Gavrilović, Milan and Sladić, Dubravka and Radulović, Aleksandra and Govedarica, Miro},
TITLE = {Building Change Detection Method to Support Register of Identified Changes on Buildings},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3150},
URL = {https://www.mdpi.com/2072-4292/13/16/3150},
ISSN = {2072-4292},
ABSTRACT = {Based on a newly adopted “Rulebook on the records of identified changes on buildings in Serbia” (2020) that regulates the content, establishment, maintenance and use of records on identified changes on buildings, it is expected that the geodetic-cadastral information system will be extended with these records. The records contain data on determined changes of buildings in relation to the reference epoch of aerial or satellite imagery, namely data on buildings: (1) that are not registered in the real estate cadastre; (2) which are registered in the real estate cadastre, and have been changed in terms of the dimensions in relation to the data registered in the real estate cadastre; (3) which are registered in the real estate cadastre, but are removed on the ground. For this purpose, the LADM-based cadastral data model for Serbia is extended to include records on identified changes on buildings. In the year 2020, Republic Geodetic Authority commenced a new satellite acquisition for the purpose of restoration of official buildings registry, as part of a World Bank project for improving land administration in Serbia. Using this satellite imagery and existing cadastral data, we propose a method based on comparison of object-based and pixel-based image analysis approaches to automatically detect newly built, changed or demolished buildings and import these data into extended cadastral records. Our results, using only VHR images containing only RGB and NIR bands, showed object identification accuracy ranging from 84% to 88%, with kappa statistic from 89% to 96%. The accuracy of obtained results is satisfactory for the purpose of developing a register of changes on buildings to keep cadastral records up to date and to support activities related to legalization of illegal buildings, etc.},
DOI = {10.3390/rs13163150}
}



@Article{ijgi10080536,
AUTHOR = {Castro Noblejas, Hugo and Sortino Barrionuevo, Juan Francisco and Gumiel Muñoz, Darío and Mérida Rodríguez, Matías Francisco},
TITLE = {A Methodological Proposal for the Analysis of Lighting the House Building Façades},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {536},
URL = {https://www.mdpi.com/2220-9964/10/8/536},
ISSN = {2220-9964},
ABSTRACT = {Natural lighting is a fundamental element in the habitability of dwellings. However, it is still difficult to calculate its effect on the façades of the buildings in detail, due to the morphological complexity of the property itself, as well as the environment that surrounds it. This study provides a methodological proposal that uses pre-existing open data to extrude buildings by using a GIS procedure. Based on three selected real estate properties with different characteristics in the city of Marbella (Spain), the hours of sunlight received by each building’s façade are calculated, taking into account the digital land model and the digital surface model of the area. The results confirm the usefulness of the method to measure and analyze differences in luminosity between buildings with similar urban characteristics and their surroundings, as well as to record the differences in luminosity between floors and the orientations of the same building at several heights. The methodological proposal opens a path for many applications related to energy efficiency, housing conditions, and property valuation.},
DOI = {10.3390/ijgi10080536}
}



@Article{s21165407,
AUTHOR = {Košťák, Milan and Slabý, Antonín},
TITLE = {Designing a Simple Fiducial Marker for Localization in Spatial Scenes Using Neural Networks},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5407},
URL = {https://www.mdpi.com/1424-8220/21/16/5407},
PubMedID = {34450848},
ISSN = {1424-8220},
ABSTRACT = {The paper describes the process of designing a simple fiducial marker. The marker is meant for use in augmented reality applications. Unlike other systems, it does not encode any information, but it can be used for obtaining the position, rotation, relative size, and projective transformation. Also, the system works well with motion blur and is resistant to the marker’s imperfections, which could theoretically be drawn only by hand. Previous systems put constraints on colors that need to be used to form the marker. The proposed system works with any saturated color, leading to better blending with the surrounding environment. The marker’s final shape is a rectangular area of a solid color with three lines of a different color going from the center to three corners of the rectangle. Precise detection can be achieved using neural networks, given that the training set is very varied and well designed. A detailed literature review was performed, and no such system was found. Therefore, the proposed design is novel for localization in the spatial scene. The testing proved that the system works well both indoor and outdoor, and the detections are precise.},
DOI = {10.3390/s21165407}
}



@Article{drones5030078,
AUTHOR = {Song, Yang and Wang, Jinfei and Shan, Bo},
TITLE = {Estimation of Winter Wheat Yield from UAV-Based Multi-Temporal Imagery Using Crop Allometric Relationship and SAFY Model},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {78},
URL = {https://www.mdpi.com/2504-446X/5/3/78},
ISSN = {2504-446X},
ABSTRACT = {Crop yield prediction and estimation play essential roles in the precision crop management system. The Simple Algorithm for Yield Estimation (SAFY) has been applied to Unmanned Aerial Vehicle (UAV)-based data to provide high spatial yield prediction and estimation for winter wheat. However, this crop model relies on the relationship between crop leaf weight and biomass, which only considers the contribution of leaves on the final biomass and yield calculation. This study developed the modified SAFY-height model by incorporating an allometric relationship between ground-based measured crop height and biomass. A piecewise linear regression model is used to establish the relationship between crop height and biomass. The parameters of the modified SAFY-height model are calibrated using ground measurements. Then, the calibrated modified SAFY-height model is applied on the UAV-based photogrammetric point cloud derived crop height and effective leaf area index (LAIe) maps to predict winter wheat yield. The growing accumulated temperature turning points of an allometric relationship between crop height and biomass is 712 °C. The modified SAFY-height model, relative to traditional SAFY, provided more accurate yield estimation for areas with LAI higher than 1.01 m2/m2. The RMSE and RRMSE are improved by 3.3% and 0.5%, respectively.},
DOI = {10.3390/drones5030078}
}



@Article{s21165418,
AUTHOR = {Passos, João and Lopes, Sérgio Ivan and Clemente, Filipe Manuel and Moreira, Pedro Miguel and Rico-González, Markel and Bezerra, Pedro and Rodrigues, Luís Paulo},
TITLE = {Wearables and Internet of Things (IoT) Technologies for Fitness Assessment: A Systematic Review},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5418},
URL = {https://www.mdpi.com/1424-8220/21/16/5418},
PubMedID = {34450860},
ISSN = {1424-8220},
ABSTRACT = {Wearable and Internet of Things (IoT) technologies in sports open a new era in athlete’s training, not only for performance monitoring and evaluation but also for fitness assessment. These technologies rely on sensor systems that collect, process and transmit relevant data, such as biomarkers and/or other performance indicators that are crucial to evaluate the evolution of the athlete’s condition, and therefore potentiate their performance. This work aims to identify and summarize recent studies that have used wearables and IoT technologies and discuss its applicability for fitness assessment. A systematic review of electronic databases (WOS, CCC, DIIDW, KJD, MEDLINE, RSCI, SCIELO, IEEEXplore, PubMed, SPORTDiscus, Cochrane and Web of Science) was undertaken according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. From the 280 studies initially identified, 20 were fully examined in terms of hardware and software and their applicability for fitness assessment. Results have shown that wearable and IoT technologies have been used in sports not only for fitness assessment but also for monitoring the athlete’s internal and external workloads, employing physiological status monitoring and activity recognition and tracking techniques. However, the maturity level of such technologies is still low, particularly with the need for the acquisition of more—and more effective—biomarkers regarding the athlete’s internal workload, which limits its wider adoption by the sports community.},
DOI = {10.3390/s21165418}
}



@Article{agriculture11080766,
AUTHOR = {Haider, Tazeem and Farid, Muhammad Shahid and Mahmood, Rashid and Ilyas, Areeba and Khan, Muhammad Hassan and Haider, Sakeena Tul-Ain and Chaudhry, Muhammad Hamid and Gul, Mehreen},
TITLE = {A Computer-Vision-Based Approach for Nitrogen Content Estimation in Plant Leaves},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {766},
URL = {https://www.mdpi.com/2077-0472/11/8/766},
ISSN = {2077-0472},
ABSTRACT = {Nitrogen is an essential nutrient element required for optimum crop growth and yield. If a specific amount of nitrogen is not applied to crops, their yield is affected. Estimation of nitrogen level in crops is momentous to decide the nitrogen fertilization in crops. The amount of nitrogen in crops is measured through different techniques, including visual inspection of leaf color and texture and by laboratory analysis of plant leaves. Laboratory analysis-based techniques are more accurate than visual inspection, but they are costly, time-consuming, and require skilled laboratorian and precise equipment. Therefore, computer-based systems are required to estimate the amount of nitrogen in field crops. In this paper, a computer vision-based solution is introduced to solve this problem as well as to help farmers by providing an easier, cheaper, and faster approach for measuring nitrogen deficiency in crops. The system takes an image of the crop leaf as input and estimates the amount of nitrogen in it. The image is captured by placing the leaf on a specially designed slate that contains the reference green and yellow colors for that crop. The proposed algorithm automatically extracts the leaf from the image and computes its color similarity with the reference colors. In particular, we define a green color value (GCV) index from this analysis, which serves as a nitrogen indicator. We also present an evaluation of different color distance models to find a model able to accurately capture the color differences. The performance of the proposed system is evaluated on a Spinacia oleracea dataset. The results of the proposed system and laboratory analysis are highly correlated, which shows the effectiveness of the proposed system.},
DOI = {10.3390/agriculture11080766}
}



@Article{rs13163188,
AUTHOR = {Takechi, Hitoshi and Aragaki, Shunsuke and Irie, Mitsuteru},
TITLE = {Differentiation of River Sediments Fractions in UAV Aerial Images by Convolution Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3188},
URL = {https://www.mdpi.com/2072-4292/13/16/3188},
ISSN = {2072-4292},
ABSTRACT = {Riverbed material has multiple functions in river ecosystems, such as habitats, feeding grounds, spawning grounds, and shelters for aquatic organisms, and particle size of riverbed material reflects the tractive force of the channel flow. Therefore, regular surveys of riverbed material are conducted for environmental protection and river flood control projects. The field method is the most conventional riverbed material survey. However, conventional surveys of particle size of riverbed material require much labor, time, and cost to collect material on site. Furthermore, its spatial representativeness is also a problem because of the limited survey area against a wide riverbank. As a further solution to these problems, in this study, we tried an automatic classification of riverbed conditions using aerial photography with an unmanned aerial vehicle (UAV) and image recognition with artificial intelligence (AI) to improve survey efficiency. Due to using AI for image processing, a large number of images can be handled regardless of whether they are of fine or coarse particles. We tried a classification of aerial riverbed images that have the difference of particle size characteristics with a convolutional neural network (CNN). GoogLeNet, Alexnet, VGG-16 and ResNet, the common pre-trained networks, were retrained to perform the new task with the 70 riverbed images using transfer learning. Among the networks tested, GoogleNet showed the best performance for this study. The overall accuracy of the image classification reached 95.4%. On the other hand, it was supposed that shadows of the gravels caused the error of the classification. The network retrained with the images taken in the uniform temporal period gives higher accuracy for classifying the images taken in the same period as the training data. The results suggest the potential of evaluating riverbed materials using aerial photography with UAV and image recognition with CNN.},
DOI = {10.3390/rs13163188}
}



@Article{rs13163190,
AUTHOR = {Li, Kai-Yun and Burnside, Niall G. and de Lima, Raul Sampaio and Peciña, Miguel Villoslada and Sepp, Karli and Cabral Pinheiro, Victor Henrique and de Lima, Bruno Rucy Carneiro Alves and Yang, Ming-Der and Vain, Ants and Sepp, Kalev},
TITLE = {An Automated Machine Learning Framework in Unmanned Aircraft Systems: New Insights into Agricultural Management Practices Recognition Approaches},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3190},
URL = {https://www.mdpi.com/2072-4292/13/16/3190},
ISSN = {2072-4292},
ABSTRACT = {The recent trend of automated machine learning (AutoML) has been driving further significant technological innovation in the application of artificial intelligence from its automated algorithm selection and hyperparameter optimization of the deployable pipeline model for unraveling substance problems. However, a current knowledge gap lies in the integration of AutoML technology and unmanned aircraft systems (UAS) within image-based data classification tasks. Therefore, we employed a state-of-the-art (SOTA) and completely open-source AutoML framework, Auto-sklearn, which was constructed based on one of the most widely used ML systems: Scikit-learn. It was combined with two novel AutoML visualization tools to focus particularly on the recognition and adoption of UAS-derived multispectral vegetation indices (VI) data across a diverse range of agricultural management practices (AMP). These include soil tillage methods (STM), cultivation methods (CM), and manure application (MA), and are under the four-crop combination fields (i.e., red clover-grass mixture, spring wheat, pea-oat mixture, and spring barley). Furthermore, they have currently not been efficiently examined and accessible parameters in UAS applications are absent for them. We conducted the comparison of AutoML performance using three other common machine learning classifiers, namely Random Forest (RF), support vector machine (SVM), and artificial neural network (ANN). The results showed AutoML achieved the highest overall classification accuracy numbers after 1200 s of calculation. RF yielded the second-best classification accuracy, and SVM and ANN were revealed to be less capable among some of the given datasets. Regarding the classification of AMPs, the best recognized period for data capture occurred in the crop vegetative growth stage (in May). The results demonstrated that CM yielded the best performance in terms of classification, followed by MA and STM. Our framework presents new insights into plant–environment interactions with capable classification capabilities. It further illustrated the automatic system would become an important tool in furthering the understanding for future sustainable smart farming and field-based crop phenotyping research across a diverse range of agricultural environmental assessment and management applications.},
DOI = {10.3390/rs13163190}
}



@Article{rs13163191,
AUTHOR = {Ezzy, Haitham and Charter, Motti and Bonfante, Antonello and Brook, Anna},
TITLE = {How the Small Object Detection via Machine Learning and UAS-Based Remote-Sensing Imagery Can Support the Achievement of SDG2: A Case Study of Vole Burrows},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3191},
URL = {https://www.mdpi.com/2072-4292/13/16/3191},
ISSN = {2072-4292},
ABSTRACT = {Small mammals, and particularly rodents, are common inhabitants of farmlands, where they play key roles in the ecosystem, but when overabundant, they can be major pests, able to reduce crop production and farmers’ incomes, with tangible effects on the achievement of Sustainable Development Goals no 2 (SDG2, Zero Hunger) of the United Nations. Farmers do not currently have a standardized, accurate method of detecting the presence, abundance, and locations of rodents in their fields, and hence do not have environmentally efficient methods of rodent control able to promote sustainable agriculture oriented to reduce the environmental impacts of cultivation. New developments in unmanned aerial system (UAS) platforms and sensor technology facilitate cost-effective data collection through simultaneous multimodal data collection approaches at very high spatial resolutions in environmental and agricultural contexts. Object detection from remote-sensing images has been an active research topic over the last decade. With recent increases in computational resources and data availability, deep learning-based object detection methods are beginning to play an important role in advancing remote-sensing commercial and scientific applications. However, the performance of current detectors on various UAS-based datasets, including multimodal spatial and physical datasets, remains limited in terms of small object detection. In particular, the ability to quickly detect small objects from a large observed scene (at field scale) is still an open question. In this paper, we compare the efficiencies of applying one- and two-stage detector models to a single UAS-based image and a processed (via Pix4D mapper photogrammetric program) UAS-based orthophoto product to detect rodent burrows, for agriculture/environmental applications as to support farmer activities in the achievements of SDG2. Our results indicate that the use of multimodal data from low-cost UASs within a self-training YOLOv3 model can provide relatively accurate and robust detection for small objects (mAP of 0.86 and an F1-score of 93.39%), and can deliver valuable insights for field management with high spatial precision able to reduce the environmental costs of crop production in the direction of precision agriculture management.},
DOI = {10.3390/rs13163191}
}



@Article{rs13163198,
AUTHOR = {Wei, Hsiang-En and Grafton, Miles and Bretherton, Michael and Irwin, Matthew and Sandoval, Eduardo},
TITLE = {Evaluation of Point Hyperspectral Reflectance and Multivariate Regression Models for Grapevine Water Status Estimation},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3198},
URL = {https://www.mdpi.com/2072-4292/13/16/3198},
ISSN = {2072-4292},
ABSTRACT = {Monitoring and management of plant water status over the critical period between flowering and veraison, plays a significant role in producing grapes of premium quality. Hyperspectral spectroscopy has been widely studied in precision farming, including for the prediction of grapevine water status. However, these studies were presented based on various combinations of transformed spectral data, feature selection methods, and regression models. To evaluate the performance of different modeling pipelines for estimating grapevine water status, a study spanning the critical period was carried out in two commercial vineyards at Martinborough, New Zealand. The modeling used six hyperspectral data groups (raw reflectance, first derivative reflectance, second derivative reflectance, continuum removal variables, simple ratio indices, and vegetation indices), two variable selection methods (Spearman correlation and recursive feature elimination based on cross-validation), an ensemble of selected variables, and three regression models (partial least squares regression, random forest regression, and support vector regression). Stem water potential (used as a proxy for vine water status) was measured by a pressure bomb. Hyperspectral reflectance was undertaken by a handheld spectroradiometer. The results show that the best predictive performance was achieved by applying partial least squares regression to simple ratio indices (R2 = 0.85; RMSE = 110 kPa). Models trained with an ensemble of selected variables comprising multicombination of transformed data and variable selection approaches outperformed those fitted using single combinations. Although larger data sizes are needed for further testing, this study compares 38 modeling pipelines and presents the best combination of procedures for estimating vine water status. This may lead to the provision of rapid estimation of vine water status in a nondestructive manner and highlights the possibility of applying hyperspectral data to precision irrigation in vineyards.},
DOI = {10.3390/rs13163198}
}



@Article{rs13163207,
AUTHOR = {Feng, Shuai and Cao, Yingli and Xu, Tongyu and Yu, Fenghua and Zhao, Dongxue and Zhang, Guosheng},
TITLE = {Rice Leaf Blast Classification Method Based on Fused Features and One-Dimensional Deep Convolutional Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3207},
URL = {https://www.mdpi.com/2072-4292/13/16/3207},
ISSN = {2072-4292},
ABSTRACT = {Rice leaf blast, which is seriously affecting the yield and quality of rice around the world, is a fungal disease that easily develops under high temperature and humidity conditions. Therefore, the use of accurate and non-destructive diagnostic methods is important for rice production management. Hyperspectral imaging technology is a type of crop disease identification method with great potential. However, a large amount of redundant information mixed in hyperspectral data makes it more difficult to establish an efficient disease classification model. At the same time, the difficulty and small scale of agricultural hyperspectral imaging data acquisition has resulted in unrepresentative features being acquired. Therefore, the focus of this study was to determine the best classification features and classification models for the five disease classes of leaf blast in order to improve the accuracy of grading the disease. First, the hyperspectral imaging data were pre-processed in order to extract rice leaf samples of five disease classes, and the number of samples was increased by data augmentation methods. Secondly, spectral feature wavelengths, vegetation indices and texture features were obtained based on the amplified sample data. Thirdly, seven one-dimensional deep convolutional neural networks (DCNN) models were constructed based on spectral feature wavelengths, vegetation indices, texture features and their fusion features. Finally, the model in this paper was compared and analyzed with the Inception V3, ZF-Net, TextCNN and bidirectional gated recurrent unit (BiGRU); support vector machine (SVM); and extreme learning machine (ELM) models in order to determine the best classification features and classification models for different disease classes of leaf blast. The results showed that the classification model constructed using fused features was significantly better than the model constructed with a single feature in terms of accuracy in grading the degree of leaf blast disease. The best performance was achieved with the combination of the successive projections algorithm (SPA) selected feature wavelengths and texture features (TFs). The modeling results also show that the DCNN model provides better classification capability for disease classification than the Inception V3, ZF-Net, TextCNN, BiGRU, SVM and ELM classification models. The SPA + TFs-DCNN achieved the best classification accuracy with an overall accuracy (OA) and Kappa of 98.58% and 98.22%, respectively. In terms of the classification of the specific different disease classes, the F1-scores for diseases of classes 0, 1 and 2 were all 100%, while the F1-scores for diseases of classes 4 and 5 were 96.48% and 96.68%, respectively. This study provides a new method for the identification and classification of rice leaf blast and a research basis for assessing the extent of the disease in the field.},
DOI = {10.3390/rs13163207}
}



@Article{a14080239,
AUTHOR = {Song, Zhenyu and Yan, Xuemei and Zhao, Lvxing and Fan, Luyi and Tang, Cheng and Ji, Junkai},
TITLE = {Adaptive Self-Scaling Brain-Storm Optimization via a Chaotic Search Mechanism},
JOURNAL = {Algorithms},
VOLUME = {14},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {239},
URL = {https://www.mdpi.com/1999-4893/14/8/239},
ISSN = {1999-4893},
ABSTRACT = {Brain-storm optimization (BSO), which is a population-based optimization algorithm, exhibits a poor search performance, premature convergence, and a high probability of falling into local optima. To address these problems, we developed the adaptive mechanism-based BSO (ABSO) algorithm based on the chaotic local search in this study. The adjustment of the search space using the local search method based on an adaptive self-scaling mechanism balances the global search and local development performance of the ABSO algorithm, effectively preventing the algorithm from falling into local optima and improving its convergence accuracy. To verify the stability and effectiveness of the proposed ABSO algorithm, the performance was tested using 29 benchmark test functions, and the mean and standard deviation were compared with those of five other optimization algorithms. The results showed that ABSO outperforms the other algorithms in terms of stability and convergence accuracy. In addition, the performance of ABSO was further verified through a nonparametric statistical test.},
DOI = {10.3390/a14080239}
}



@Article{plants10081672,
AUTHOR = {Lazare, Silit and Cohen, Yafit and Goldshtein, Eitan and Yermiyahu, Uri and Ben-Gal, Alon and Dag, Arnon},
TITLE = {Rootstock-Dependent Response of Hass Avocado to Salt Stress},
JOURNAL = {Plants},
VOLUME = {10},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1672},
URL = {https://www.mdpi.com/2223-7747/10/8/1672},
PubMedID = {34451717},
ISSN = {2223-7747},
ABSTRACT = {Salt stress is a major limiting factor in avocado (Persea americana) cultivation, exacerbated by global trends towards scarcity of high-quality water for irrigation. Israeli avocado orchards have been irrigated with relatively high-salinity recycled municipal wastewater for over three decades, over which time rootstocks were selected for salt-tolerance. This study’s objective was to evaluate the physiological salt response of avocado as a function of the rootstock. We irrigated fruit-bearing ‘Hass’ trees grafted on 20 different local and introduced rootstocks with water high in salts (electrical conductivity of 1.4–1.5 dS/m). The selected rootstocks represent a wide range of genetic backgrounds, propagation methods, and horticultural characteristics. We investigated tree physiology and development during two years of salt exposure by measuring Cl and Na leaf concentrations, leaf osmolality, visible damages, trunk circumference, LAI, CO2 assimilation, stomatal conductance, spectral reflectance, stem water potential, trichomes density, and yield. We found a significant effect of the rootstocks on stress indicators, vegetative and reproductive development, leaf morphogenesis and photosynthesis rates. The most salt-sensitive rootstocks were VC 840, Dusa, and VC 802, while the least sensitive were VC 159, VC 140, and VC 152. We conclude that the rootstock strongly influences avocado tree response to salinity exposure in terms of physiology, anatomy, and development.},
DOI = {10.3390/plants10081672}
}



@Article{infrastructures6080115,
AUTHOR = {Munawar, Hafiz Suliman and Hammad, Ahmed W. A. and Haddad, Assed and Soares, Carlos Alberto Pereira and Waller, S. Travis},
TITLE = {Image-Based Crack Detection Methods: A Review},
JOURNAL = {Infrastructures},
VOLUME = {6},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {115},
URL = {https://www.mdpi.com/2412-3811/6/8/115},
ISSN = {2412-3811},
ABSTRACT = {Annually, millions of dollars are spent to carry out defect detection in key infrastructure including roads, bridges, and buildings. The aftermath of natural disasters like floods and earthquakes leads to severe damage to the urban infrastructure. Maintenance operations that follow for the damaged infrastructure often involve a visual inspection and assessment of their state to ensure their functional and physical integrity. Such damage may appear in the form of minor or major cracks, which gradually spread, leading to ultimate collapse or destruction of the structure. Crack detection is a very laborious task if performed via manual visual inspection. Many infrastructure elements need to be checked regularly and it is therefore not feasible as it will require significant human resources. This may also result in cases where cracks go undetected. A need, therefore, exists for performing automatic defect detection in infrastructure to ensure its effectiveness and reliability. Using image processing techniques, the captured or scanned images of the infrastructure parts can be analyzed to identify any possible defects. Apart from image processing, machine learning methods are being increasingly applied to ensure better performance outcomes and robustness in crack detection. This paper provides a review of image-based crack detection techniques which implement image processing and/or machine learning. A total of 30 research articles have been collected for the review which is published in top tier journals and conferences in the past decade. A comprehensive analysis and comparison of these methods are performed to highlight the most promising automated approaches for crack detection.},
DOI = {10.3390/infrastructures6080115}
}



@Article{rs13163234,
AUTHOR = {Cao, Jingwei and Song, Chuanxue and Song, Shixin and Xiao, Feng and Zhang, Xu and Liu, Zhiyang and Ang, Marcelo H.},
TITLE = {Robust Object Tracking Algorithm for Autonomous Vehicles in Complex Scenes},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3234},
URL = {https://www.mdpi.com/2072-4292/13/16/3234},
ISSN = {2072-4292},
ABSTRACT = {Object tracking is an essential aspect of environmental perception technology for autonomous vehicles. The existing object tracking algorithms can only be applied well to simple scenes. When the scenes become complex, the algorithms have poor tracking performance and insufficient robustness, and the problems of tracking drift and object loss are prone to occur. Therefore, a robust object tracking algorithm for autonomous vehicles in complex scenes is proposed. Firstly, we study the Siam-FC network and related algorithms, and analyze the problems that need to be addressed in object tracking. Secondly, the construction of a double-template Siamese network model based on multi-feature fusion is described, as is the use of the improved MobileNet V2 as the feature extraction backbone network, and the attention mechanism and template online update mechanism are introduced. Finally, relevant experiments were carried out based on public datasets and actual driving videos, with the aim of fully testing the tracking performance of the proposed algorithm on different objects in a variety of complex scenes. The results showed that, compared with other algorithms, the proposed algorithm had high tracking accuracy and speed, demonstrated stronger robustness and anti-interference abilities, and could still accurately track the object in real time without the introduction of complex structures. This algorithm can be effectively applied in intelligent vehicle driving assistance, and it will help to promote the further development and improvement of computer vision technology in the field of environmental perception.},
DOI = {10.3390/rs13163234}
}



@Article{electronics10161965,
AUTHOR = {Bhatia, Jyoti and Dayal, Aveen and Jha, Ajit and Vishvakarma, Santosh Kumar and Joshi, Soumya and Srinivas, M. B. and Yalavarthy, Phaneendra K. and Kumar, Abhinav and Lalitha, V. and Koorapati, Sagar and Cenkeramaddi, Linga Reddy},
TITLE = {Classification of Targets Using Statistical Features from Range FFT of mmWave FMCW Radars},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {1965},
URL = {https://www.mdpi.com/2079-9292/10/16/1965},
ISSN = {2079-9292},
ABSTRACT = {Radars with mmWave frequency modulated continuous wave (FMCW) technology accurately estimate the range and velocity of targets in their field of view (FoV). The targeted angle of arrival (AoA) estimation can be improved by increasing receiving antennas or by using multiple-input multiple-output (MIMO). However, obtaining target features such as target type remains challenging. In this paper, we present a novel target classification method based on machine learning and features extracted from a range fast Fourier transform (FFT) profile by using mmWave FMCW radars operating in the frequency range of 77–81 GHz. The measurements are carried out in a variety of realistic situations, including pedestrian, automotive, and unmanned aerial vehicle (UAV) (also known as drone). Peak, width, area, variance, and range are collected from range FFT profile peaks and fed into a machine learning model. In order to evaluate the performance, various light weight classification machine learning models such as logistic regression, Naive Bayes, support vector machine (SVM), and lightweight gradient boosting machine (GBM) are used. We demonstrate our findings by using outdoor measurements and achieve a classification accuracy of 95.6% by using LightGBM. The proposed method will be extremely useful in a wide range of applications, including cost-effective and dependable ground station traffic management and control systems for autonomous operations, and advanced driver-assistance systems (ADAS). The presented classification technique extends the potential of mmWave FMCW radar beyond the detection of range, velocity, and AoA to classification. mmWave FMCW radars will be more robust in computer vision, visual perception, and fully autonomous ground control and traffic management cyber-physical systems as a result of the added new feature.},
DOI = {10.3390/electronics10161965}
}



@Article{rs13163240,
AUTHOR = {Zhang, Guangzong and Wu, Mengquan and Wei, Juan and He, Yufang and Niu, Lifeng and Li, Hanyu and Xu, Guochang},
TITLE = {Adaptive Threshold Model in Google Earth Engine: A Case Study of Ulva prolifera Extraction in the South Yellow Sea, China},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3240},
URL = {https://www.mdpi.com/2072-4292/13/16/3240},
ISSN = {2072-4292},
ABSTRACT = {An outbreak of Ulva prolifera poses a massive threat to coastal ecology in the Southern Yellow Sea, China (SYS). It is a necessity to extract its area and monitor its development accurately. At present, Ulva prolifera monitoring by remote sensing imagery is mostly based on a fixed threshold or artificial visual interpretation for threshold selection, which has large errors. In this paper, an adaptive threshold model based on Google Earth Engine (GEE) is proposed and applied to extract U. prolifera in the SYS. The model first applies the Floating Algae Index (FAI) or Normalized Difference Vegetation Index (NDVI) algorithm on the preprocessed remote sensing images and then uses the Canny Edge Filter and Otsu threshold segmentation algorithm to extract the threshold automatically. The model is applied to Landsat8/OLI and Sentinel-2/MSI images, and the confusion matrix and cross-sensor comparison are used to evaluate the accuracy and applicability of the model. The verification results show that the model extraction of U. prolifera based on the FAI algorithm has higher accuracy (R2 = 0.99, RMSE = 5.64) and better robustness. However, when the average cloud cover is more than 70% in the image (based on the statistical results of multi-year cloud cover information), the model based on the NDVI algorithm has better applicability and can extract the algae distributed at the edge of the cloud. When the model uses the FAI algorithm, it is named FAI-COM (model based on FAI, the Canny Edge Filter, and Otsu thresholding). And when the model uses the NDVI algorithm, it is named NDVI-COM (model based on NDVI, the Canny Edge Filter, and Otsu thresholding). Therefore, the final extraction results are generated by supplementing NDVI-COM results on the basis of FAI-COM extraction results in this paper. The F1-score of U. prolifera extracted results is above 0.85. The spatiotemporal distribution of U. prolifera in the South Yellow Sea from 2016 to 2020 is obtained through the model calculation. Overall, the coverage area of U. prolifera shows a decreasing trend over the five years. It is found that the delay in recovery time of Porphyra yezoensis culture facilities in the Northern Jiangsu Shoal and the manual salvage and cleaning-up of U. prolifera in May are among the reasons for the smaller interannual scale of algae in 2017 and 2018.},
DOI = {10.3390/rs13163240}
}



@Article{rs13163241,
AUTHOR = {Hassanzadeh, Amirhossein and Zhang, Fei and van Aardt, Jan and Murphy, Sean P. and Pethybridge, Sarah J.},
TITLE = {Broadacre Crop Yield Estimation Using Imaging Spectroscopy from Unmanned Aerial Systems (UAS): A Field-Based Case Study with Snap Bean},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3241},
URL = {https://www.mdpi.com/2072-4292/13/16/3241},
ISSN = {2072-4292},
ABSTRACT = {Accurate, precise, and timely estimation of crop yield is key to a grower’s ability to proactively manage crop growth and predict harvest logistics. Such yield predictions typically are based on multi-parametric models and in-situ sampling. Here we investigate the extension of a greenhouse study, to low-altitude unmanned aerial systems (UAS). Our principal objective was to investigate snap bean crop (Phaseolus vulgaris) yield using imaging spectroscopy (hyperspectral imaging) in the visible to near-infrared (VNIR; 400–1000 nm) region via UAS. We aimed to solve the problem of crop yield modelling by identifying spectral features explaining yield and evaluating the best time period for accurate yield prediction, early in time. We introduced a Python library, named Jostar, for spectral feature selection. Embedded in Jostar, we proposed a new ranking method for selected features that reaches an agreement between multiple optimization models. Moreover, we implemented a well-known denoising algorithm for the spectral data used in this study. This study benefited from two years of remotely sensed data, captured at multiple instances over the summers of 2019 and 2020, with 24 plots and 18 plots, respectively. Two harvest stage models, early and late harvest, were assessed at two different locations in upstate New York, USA. Six varieties of snap bean were quantified using two components of yield, pod weight and seed length. We used two different vegetation detection algorithms. the Red-Edge Normalized Difference Vegetation Index (RENDVI) and Spectral Angle Mapper (SAM), to subset the fields into vegetation vs. non-vegetation pixels. Partial least squares regression (PLSR) was used as the regression model. Among nine different optimization models embedded in Jostar, we selected the Genetic Algorithm (GA), Ant Colony Optimization (ACO), Simulated Annealing (SA), and Particle Swarm Optimization (PSO) and their resulting joint ranking. The findings show that pod weight can be explained with a high coefficient of determination (R2 = 0.78–0.93) and low root-mean-square error (RMSE = 940–1369 kg/ha) for two years of data. Seed length yield assessment resulted in higher accuracies (R2 = 0.83–0.98) and lower errors (RMSE = 4.245–6.018 mm). Among optimization models used, ACO and SA outperformed others and the SAM vegetation detection approach showed improved results when compared to the RENDVI approach when dense canopies were being examined. Wavelengths at 450, 500, 520, 650, 700, and 760 nm, were identified in almost all data sets and harvest stage models used. The period between 44–55 days after planting (DAP) the optimal time period for yield assessment. Future work should involve transferring the learned concepts to a multispectral system, for eventual operational use; further attention should also be paid to seed length as a ground truth data collection technique, since this yield indicator is far more rapid and straightforward.},
DOI = {10.3390/rs13163241}
}



@Article{electronics10161970,
AUTHOR = {Ansart, Antoine and Juang, Jyh-Ching and Ramachandran, Karthi Gilari},
TITLE = {Robust Formation Maintenance Methods under General Topology Pursuit of Multi-Agents Systems},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {1970},
URL = {https://www.mdpi.com/2079-9292/10/16/1970},
ISSN = {2079-9292},
ABSTRACT = {In this article, methods of formation maintenance for a group of autonomous agents under ageneral topology scheme are discussed. Unlike rendezvous or geometric formation, general topology pursuit allows the group of agents to autonomously form trochoid patterns, which are useful in civilian and military applications. However, this type of topology is established by designing a marginally stable system that may be sensitive to parameter variations. To account for this drawback of stability, linear fixed-gains are turned into a dynamical version in this paper. By implementing a disturbance observer controller, systems are shown to maintain their formation despite the disturbances or uncertainties. Comparison in the effectiveness of the presented method with model reference adaptive control and integral sliding mode control under the uncertainties of the gains is also conducted. The capabilities of controllers are demonstrated and supported through simulations.},
DOI = {10.3390/electronics10161970}
}



@Article{agronomy11081626,
AUTHOR = {Li, Guan-Sin and Wu, Dong-Hong and Su, Yuan-Chih and Kuo, Bo-Jein and Yang, Ming-Der and Lai, Ming-Hsin and Lu, Hsiu-Ying and Yang, Chin-Ying},
TITLE = {Prediction of Plant Nutrition State of Rice under Water-Saving Cultivation and Panicle Fertilization Application Decision Making},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1626},
URL = {https://www.mdpi.com/2073-4395/11/8/1626},
ISSN = {2073-4395},
ABSTRACT = {Rice is a staple food crop in Asia. The rice farming industry has been influenced by global urbanization, rapid industrialization, and climate change. A combination of precise agricultural and smart water management systems to investigate the nutrition state in rice is important. Results indicated that plant nitrogen and chlorophyll content at the maximum tillering stage were significantly influenced by the interaction between water and fertilizer. The normalized difference vegetation index (NDVI) and normalized difference red edge (NDRE), obtained from the multispectral images captured by a UAV, exhibited the highest positive correlations (0.83 and 0.82) with plant nitrogen content at the maximum tillering stage. The leave-one-out cross-validation method was used for validation, and a final plant nitrogen content prediction model was obtained. A regression function constructed using a nitrogen nutrition index and the difference in field cumulative nitrogen had favorable variation explanatory power, and its adjusted coefficient of determination was 0.91. We provided a flow chart showing how the nutrition state of rice can be predicted with the vegetation indices obtained from UAV image analysis. Differences in field cumulative nitrogen can be further used to diagnose the demand of nitrogen topdressing during the panicle initiation stage. Thus, farmers can be provided with precise panicle fertilization strategies for rice fields.},
DOI = {10.3390/agronomy11081626}
}



@Article{s21165516,
AUTHOR = {Schäfer, Matthias and Strohmeier, Martin and Leonardi, Mauro and Lenders, Vincent},
TITLE = {LocaRDS: A Localization Reference Data Set},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5516},
URL = {https://www.mdpi.com/1424-8220/21/16/5516},
PubMedID = {34450957},
ISSN = {1424-8220},
ABSTRACT = {The use of wireless signals for the purposes of localization enables a host of applications relating to the determination and verification of the positions of network participants ranging from radar to satellite navigation. Consequently, this has been a longstanding interest of theoretical and practical research in mobile networks and many solutions have been proposed in the scientific literature. However, it is hard to assess the performance of these in the real world and, more importantly, to compare their advantages and disadvantages in a controlled scientific manner. With this work, we attempt to improve the current state of art methodology in localization research and to place it on a solid scientific grounding for future investigations. Concretely, we developed LocaRDS, an open reference data set of real-world crowdsourced flight data featuring more than 222 million measurements from over 50 million transmissions recorded by 323 sensors. We demonstrate how we can verify the quality of LocaRDS measurements so that it can be used to test, analyze and directly compare different localization methods. Finally, we provide an example implementation for the aircraft localization problem and a discussion of possible metrics for use with LocaRDS.},
DOI = {10.3390/s21165516}
}



@Article{ijgi10080556,
AUTHOR = {Shen, Shengyu and Chen, Jiasheng and Zhang, Shaoyi and Cheng, Dongbing and Wang, Zhigang and Zhang, Tong},
TITLE = {Deep Fusion of DOM and DSM Features for Benggang Discovery},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {556},
URL = {https://www.mdpi.com/2220-9964/10/8/556},
ISSN = {2220-9964},
ABSTRACT = {Benggang is a typical erosional landform in southern and southeastern China. Since benggang poses significant risks to local ecological environments and economic infrastructure, it is vital to accurately detect benggang-eroded areas. Relying only on remote sensing imagery for benggang detection cannot produce satisfactory results. In this study, we propose integrating high-resolution Digital Orthophoto Map (DOM) and Digital Surface Model (DSM) data for efficient and automatic benggang discovery. The fusion of complementary rich information hidden in both DOM and DSM data is realized by a two-stream convolutional neural network (CNN), which integrates aggregated terrain and activation image features that are both extracted by supervised deep learning. We aggregate local low-level geomorphic features via a supervised diffusion-convolutional embedding branch for expressive representations of benggang terrain variations. Activation image features are obtained from an image-oriented convolutional neural network branch. The two sources of information (DOM and DSM) are fused via a gated neural network, which learns the most discriminative features for the detection of benggang. The evaluation of a challenging benggang dataset demonstrates that our method exceeds several baselines, even with limited training examples. The results show that the fusion of DOM and DSM data is beneficial for benggang detection via supervised convolutional and deep fusion networks.},
DOI = {10.3390/ijgi10080556}
}



@Article{app11167550,
AUTHOR = {Tina, Giuseppe Marco and Ventura, Cristina and Ferlito, Sergio and De Vito, Saverio},
TITLE = {A State-of-Art-Review on Machine-Learning Based Methods for PV},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {7550},
URL = {https://www.mdpi.com/2076-3417/11/16/7550},
ISSN = {2076-3417},
ABSTRACT = {In the current era, Artificial Intelligence (AI) is becoming increasingly pervasive with applications in several applicative fields effectively changing our daily life. In this scenario, machine learning (ML), a subset of AI techniques, provides machines with the ability to programmatically learn from data to model a system while adapting to new situations as they learn more by data they are ingesting (on-line training). During the last several years, many papers have been published concerning ML applications in the field of solar systems. This paper presents the state of the art ML models applied in solar energy’s forecasting field i.e., for solar irradiance and power production forecasting (both point and interval or probabilistic forecasting), electricity price forecasting and energy demand forecasting. Other applications of ML into the photovoltaic (PV) field taken into account are the modelling of PV modules, PV design parameter extraction, tracking the maximum power point (MPP), PV systems efficiency optimization, PV/Thermal (PV/T) and Concentrating PV (CPV) system design parameters’ optimization and efficiency improvement, anomaly detection and energy management of PV’s storage systems. While many review papers already exist in this regard, they are usually focused only on one specific topic, while in this paper are gathered all the most relevant applications of ML for solar systems in many different fields. The paper gives an overview of the most recent and promising applications of machine learning used in the field of photovoltaic systems.},
DOI = {10.3390/app11167550}
}



@Article{drones5030079,
AUTHOR = {Parra, Lorena and Mostaza-Colado, David and Yousfi, Salima and Marin, Jose F. and Mauri, Pedro V. and Lloret, Jaime},
TITLE = {Drone RGB Images as a Reliable Information Source to Determine Legumes Establishment Success},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {79},
URL = {https://www.mdpi.com/2504-446X/5/3/79},
ISSN = {2504-446X},
ABSTRACT = {The use of drones in agriculture is becoming a valuable tool for crop monitoring. There are some critical moments for crop success; the establishment is one of those. In this paper, we present an initial approximation of a methodology that uses RGB images gathered from drones to evaluate the establishment success in legumes based on matrixes operations. Our aim is to provide a method that can be implemented in low-cost nodes with relatively low computational capacity. An index (B1/B2) is used for estimating the percentage of green biomass to evaluate the establishment success. In the study, we include three zones with different establishment success (high, regular, and low) and two species (chickpea and lentils). We evaluate data usability after applying aggregation techniques, which reduces the picture’s size to improve long-term storage. We test cell sizes from 1 to 10 pixels. This technique is tested with images gathered in production fields with intercropping at 4, 8, and 12 m relative height to find the optimal aggregation for each flying height. Our results indicate that images captured at 4 m with a cell size of 5, at 8 m with a cell size of 3, and 12 m without aggregation can be used to determine the establishment success. Comparing the storage requirements, the combination that minimises the data size while maintaining its usability is the image at 8 m with a cell size of 3. Finally, we show the use of generated information with an artificial neural network to classify the data. The dataset was split into a training dataset and a verification dataset. The classification of the verification dataset offered 83% of the cases as well classified. The proposed tool can be used in the future to compare the establishment success of different legume varieties or species.},
DOI = {10.3390/drones5030079}
}



@Article{heritage4030107,
AUTHOR = {Hurst, Stance and Johnson, Eileen and Cunningham, Doug and Fernandez-Cespedes, Glenn},
TITLE = {Aerial Photogrammetry in the American West: Documenting the Construction of Cattle Water Tanks by Texas Cowboys},
JOURNAL = {Heritage},
VOLUME = {4},
YEAR = {2021},
NUMBER = {3},
PAGES = {1899--1911},
URL = {https://www.mdpi.com/2571-9408/4/3/107},
ISSN = {2571-9408},
ABSTRACT = {Aerial photogrammetry is increasingly being used to discover, document, and interpret the cultural heritage of landscapes. Information on the constructed cultural heritage left behind by the first cattle ranchers in the American West is being lost as the land is transformed and modified, and stewardship of the land changes across generations. An unmanned aerial vehicle (UAV) has been used in this research to record and interpret two surface water cattle tanks constructed by Texas cowboys in the mid-1880s. Similar size rocks have been used and placed in a similar pattern across the walls of both tanks. This similarity suggests both tanks were constructed at the same time. This research also demonstrates that UAV photogrammetry can be used to rapidly record and analyze the constructed cultural heritage of American West cowboys.},
DOI = {10.3390/heritage4030107}
}



@Article{rs13163262,
AUTHOR = {Soubry, Irini and Doan, Thuy and Chu, Thuan and Guo, Xulin},
TITLE = {A Systematic Review on the Integration of Remote Sensing and GIS to Forest and Grassland Ecosystem Health Attributes, Indicators, and Measures},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3262},
URL = {https://www.mdpi.com/2072-4292/13/16/3262},
ISSN = {2072-4292},
ABSTRACT = {It is important to protect forest and grassland ecosystems because they are ecologically rich and provide numerous ecosystem services. Upscaling monitoring from local to global scale is imperative in reaching this goal. The SDG Agenda does not include indicators that directly quantify ecosystem health. Remote sensing and Geographic Information Systems (GIS) can bridge the gap for large-scale ecosystem health assessment. We systematically reviewed field-based and remote-based measures of ecosystem health for forests and grasslands, identified the most important ones and provided an overview on remote sensing and GIS-based measures. We included 163 English language studies within terrestrial non-tropical biomes and used a pre-defined classification system to extract ecological stressors and attributes, collected corresponding indicators, measures, and proxy values. We found that the main ecological attributes of each ecosystem contribute differently in the literature, and that almost half of the examined studies used remote sensing to estimate indicators. The major stressor for forests was “climate change”, followed by “insect infestation”; for grasslands it was “grazing”, followed by “climate change”. “Biotic interactions, composition, and structure” was the most important ecological attribute for both ecosystems. “Fire disturbance” was the second most important for forests, while for grasslands it was “soil chemistry and structure”. Less than a fifth of studies used vegetation indices; NDVI was the most common. There are monitoring inconsistencies from the broad range of indicators and measures. Therefore, we recommend a standardized field, GIS, and remote sensing-based approach to monitor ecosystem health and integrity and facilitate land managers and policy-makers.},
DOI = {10.3390/rs13163262}
}



@Article{rs13163263,
AUTHOR = {Liu, Zhijie and Guo, Pengju and Liu, Heng and Fan, Pan and Zeng, Pengzong and Liu, Xiangyang and Feng, Ce and Wang, Wang and Yang, Fuzeng},
TITLE = {Gradient Boosting Estimation of the Leaf Area Index of Apple Orchards in UAV Remote Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3263},
URL = {https://www.mdpi.com/2072-4292/13/16/3263},
ISSN = {2072-4292},
ABSTRACT = {The leaf area index (LAI) is a key parameter for describing the canopy structure of apple trees. This index is also employed in evaluating the amount of pesticide sprayed per unit volume of apple trees. Hence, numerous manual and automatic methods have been explored for LAI estimation. In this work, the leaf area indices for different types of apple trees are obtained in terms of multispectral remote-sensing data collected with an unmanned aerial vehicle (UAV), along with simultaneous measurements of apple orchards. The proposed approach was tested on apple trees of the “Fuji”, “Golden Delicious”, and “Ruixue” types, which were planted in the Apple Experimental Station of the Northwest Agriculture and Forestry University in Baishui County, Shaanxi Province, China. Five vegetation indices of strong correlation with the apple leaf area index were selected and used to train models of support vector regression (SVR) and gradient-boosting decision trees (GBDT) for predicting the leaf area index of apple trees. The best model was selected based on the metrics of the coefficient of determination (R2) and the root-mean-square error (RMSE). The experimental results showed that the gradient-boosting decision tree model achieved the best performance with an R2 of 0.846, an RMSE of 0.356, and a spatial efficiency (SPAEF) of 0.57. This demonstrates the feasibility of our approach for fast and accurate remote-sensing-based estimation of the leaf area index of apple trees.},
DOI = {10.3390/rs13163263}
}



@Article{s21165554,
AUTHOR = {Pal, Shantanu and Mukhopadhyay, Subhas and Suryadevara, Nagender},
TITLE = {Development and Progress in Sensors and Technologies for Human Emotion Recognition},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5554},
URL = {https://www.mdpi.com/1424-8220/21/16/5554},
PubMedID = {34451002},
ISSN = {1424-8220},
ABSTRACT = {With the advancement of human-computer interaction, robotics, and especially humanoid robots, there is an increasing trend for human-to-human communications over online platforms (e.g., zoom). This has become more significant in recent years due to the Covid-19 pandemic situation. The increased use of online platforms for communication signifies the need to build efficient and more interactive human emotion recognition systems. In a human emotion recognition system, the physiological signals of human beings are collected, analyzed, and processed with the help of dedicated learning techniques and algorithms. With the proliferation of emerging technologies, e.g., the Internet of Things (IoT), future Internet, and artificial intelligence, there is a high demand for building scalable, robust, efficient, and trustworthy human recognition systems. In this paper, we present the development and progress in sensors and technologies to detect human emotions. We review the state-of-the-art sensors used for human emotion recognition and different types of activity monitoring. We present the design challenges and provide practical references of such human emotion recognition systems in the real world. Finally, we discuss the current trends in applications and explore the future research directions to address issues, e.g., scalability, security, trust, privacy, transparency, and decentralization.},
DOI = {10.3390/s21165554}
}



@Article{rs13163272,
AUTHOR = {Ivošević, Bojana and Lugonja, Predrag and Brdar, Sanja and Radulović, Mirjana and Vujić, Ante and Valente, João},
TITLE = {UAV-Based Land Cover Classification for Hoverfly (Diptera: Syrphidae) Habitat Condition Assessment: A Case Study on Mt. Stara Planina (Serbia)},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3272},
URL = {https://www.mdpi.com/2072-4292/13/16/3272},
ISSN = {2072-4292},
ABSTRACT = {Habitat degradation, mostly caused by human impact, is one of the key drivers of biodiversity loss. This is a global problem, causing a decline in the number of pollinators, such as hoverflies. In the process of digitalizing ecological studies in Serbia, remote-sensing-based land cover classification has become a key component for both current and future research. Object-based land cover classification, using machine learning algorithms of very high resolution (VHR) imagery acquired by an unmanned aerial vehicle (UAV) was carried out in three different study sites on Mt. Stara Planina, Eastern Serbia. UAV land cover classified maps with seven land cover classes (trees, shrubs, meadows, road, water, agricultural land, and forest patches) were studied. Moreover, three different classification algorithms—support vector machine (SVM), random forest (RF), and k-NN (k-nearest neighbors)—were compared. This study shows that the random forest classifier performs better with respect to the other classifiers in all three study sites, with overall accuracy values ranging from 0.87 to 0.96. The overall results are robust to changes in labeling ground truth subsets. The obtained UAV land cover classified maps were compared with the Map of the Natural Vegetation of Europe (EPNV) and used to quantify habitat degradation and assess hoverfly species richness. It was concluded that the percentage of habitat degradation is primarily caused by anthropogenic pressure, thus affecting the richness of hoverfly species in the study sites. In order to enable research reproducibility, the datasets used in this study are made available in a public repository.},
DOI = {10.3390/rs13163272}
}



@Article{rs13163276,
AUTHOR = {Ulhaq, Anwaar and Adams, Peter and Cox, Tarnya E. and Khan, Asim and Low, Tom and Paul, Manoranjan},
TITLE = {Automated Detection of Animals in Low-Resolution Airborne Thermal Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3276},
URL = {https://www.mdpi.com/2072-4292/13/16/3276},
ISSN = {2072-4292},
ABSTRACT = {Detecting animals to estimate abundance can be difficult, particularly when the habitat is dense or the target animals are fossorial. The recent surge in the use of thermal imagers in ecology and their use in animal detections can increase the accuracy of population estimates and improve the subsequent implementation of management programs. However, the use of thermal imagers results in many hours of captured flight videos which require manual review for confirmation of species detection and identification. Therefore, the perceived cost and efficiency trade-off often restricts the use of these systems. Additionally, for many off-the-shelf systems, the exported imagery can be quite low resolution (&lt;9 Hz), increasing the difficulty of using automated detections algorithms to streamline the review process. This paper presents an animal species detection system that utilises the cost-effectiveness of these lower resolution thermal imagers while harnessing the power of transfer learning and an enhanced small object detection algorithm. We have proposed a distant object detection algorithm named Distant-YOLO (D-YOLO) that utilises YOLO (You Only Look Once) and improves its training and structure for the automated detection of target objects in thermal imagery. We trained our system on thermal imaging data of rabbits, their active warrens, feral pigs, and kangaroos collected by thermal imaging researchers in New South Wales and Western Australia. This work will enhance the visual analysis of animal species while performing well on low, medium and high-resolution thermal imagery.},
DOI = {10.3390/rs13163276}
}



@Article{ai2030023,
AUTHOR = {Xue, Zhihan and Gonsalves, Tad},
TITLE = {Vision Based Drone Obstacle Avoidance by Deep Reinforcement Learning},
JOURNAL = {AI},
VOLUME = {2},
YEAR = {2021},
NUMBER = {3},
PAGES = {366--380},
URL = {https://www.mdpi.com/2673-2688/2/3/23},
ISSN = {2673-2688},
ABSTRACT = {Research on autonomous obstacle avoidance of drones has recently received widespread attention from researchers. Among them, an increasing number of researchers are using machine learning to train drones. These studies typically adopt supervised learning or reinforcement learning to train the networks. Supervised learning has a disadvantage in that it takes a significant amount of time to build the datasets, because it is difficult to cover the complex and changeable drone flight environment in a single dataset. Reinforcement learning can overcome this problem by using drones to learn data in the environment. However, the current research results based on reinforcement learning are mainly focused on discrete action spaces. In this way, the movement of drones lacks precision and has somewhat unnatural flying behavior. This study aims to use the soft-actor-critic algorithm to train a drone to perform autonomous obstacle avoidance in continuous action space using only the image data. The algorithm is trained and tested in a simulation environment built by Airsim. The results show that our algorithm enables the UAV to avoid obstacles in the training environment only by inputting the depth map. Moreover, it also has a higher obstacle avoidance rate in the reconfigured environment without retraining.},
DOI = {10.3390/ai2030023}
}



@Article{en14165131,
AUTHOR = {Martins, Leandro do C. and Tordecilla, Rafael D. and Castaneda, Juliana and Juan, Angel A. and Faulin, Javier},
TITLE = {Electric Vehicle Routing, Arc Routing, and Team Orienteering Problems in Sustainable Transportation},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5131},
URL = {https://www.mdpi.com/1996-1073/14/16/5131},
ISSN = {1996-1073},
ABSTRACT = {The increasing use of electric vehicles in road and air transportation, especially in last-mile delivery and city mobility, raises new operational challenges due to the limited capacity of electric batteries. These limitations impose additional driving range constraints when optimizing the distribution and mobility plans. During the last years, several researchers from the Computer Science, Artificial Intelligence, and Operations Research communities have been developing optimization, simulation, and machine learning approaches that aim at generating efficient and sustainable routing plans for hybrid fleets, including both electric and internal combustion engine vehicles. After contextualizing the relevance of electric vehicles in promoting sustainable transportation practices, this paper reviews the existing work in the field of electric vehicle routing problems. In particular, we focus on articles related to the well-known vehicle routing, arc routing, and team orienteering problems. The review is followed by numerical examples that illustrate the gains that can be obtained by employing optimization methods in the aforementioned field. Finally, several research opportunities are highlighted.},
DOI = {10.3390/en14165131}
}



@Article{en14165129,
AUTHOR = {Junaid, Muhammad and Shaikh, Asadullah and Hassan, Mahmood Ul and Alghamdi, Abdullah and Rajab, Khairan and Al Reshan, Mana Saleh and Alkinani, Monagi},
TITLE = {Smart Agriculture Cloud Using AI Based Techniques},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {5129},
URL = {https://www.mdpi.com/1996-1073/14/16/5129},
ISSN = {1996-1073},
ABSTRACT = {This research proposes a generic smart cloud-based system in order to accommodate multiple scenarios where agriculture farms using Internet of Things (IoTs) need to be monitored remotely. The real-time and stored data are analyzed by specialists and farmers. The cloud acts as a central digital data store where information is collected from diverse sources in huge volumes and variety, such as audio, video, image, text, and digital maps. Artificial Intelligence (AI) based machine learning models such as Support Vector Machine (SVM), which is one of many classification types, are used to accurately classify the data. The classified data are assigned to the virtual machines where these data are processed and finally available to the end-users via underlying datacenters. This processed form of digital information is then used by the farmers to improve their farming skills and to update them as pre-disaster recovery for smart agri-food. Furthermore, it will provide general and specific information about international markets relating to their crops. This proposed system discovers the feasibility of the developed digital agri-farm using IoT-based cloud and provides solutions to problems. Overall, the approach works well and achieved performance efficiency in terms of execution time by 14%, throughput time by 5%, overhead time by 9%, and energy efficiency by 13.2% in the presence of competing smart farming baselines.},
DOI = {10.3390/en14165129}
}



@Article{rs13163288,
AUTHOR = {Bai, Ling and Li, Yinguo and Cen, Ming and Hu, Fangchao},
TITLE = {3D Instance Segmentation and Object Detection Framework Based on the Fusion of Lidar Remote Sensing and Optical Image Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3288},
URL = {https://www.mdpi.com/2072-4292/13/16/3288},
ISSN = {2072-4292},
ABSTRACT = {Since single sensor and high-density point cloud data processing have certain direct processing limitations in urban traffic scenarios, this paper proposes a 3D instance segmentation and object detection framework for urban transportation scenes based on the fusion of Lidar remote sensing technology and optical image sensing technology. Firstly, multi-source and multi-mode data pre-fusion and alignment of Lidar and camera sensor data are effectively carried out, and then a unique and innovative network of stereo regional proposal selective search-driven DAGNN is constructed. Finally, using the multi-dimensional information interaction, three-dimensional point clouds with multi-features and unique concave-convex geometric characteristics are instance over-segmented and clustered by the hypervoxel storage in the remarkable octree and growing voxels. Finally, the positioning and semantic information of significant 3D object detection in this paper are visualized by multi-dimensional mapping of the boundary box. The experimental results validate the effectiveness of the proposed framework with excellent feedback for small objects, object stacking, and object occlusion. It can be a remediable or alternative plan to a single sensor and provide an essential theoretical and application basis for remote sensing, autonomous driving, environment modeling, autonomous navigation, and path planning under the V2X intelligent network space– ground integration in the future.},
DOI = {10.3390/rs13163288}
}



@Article{sym13081537,
AUTHOR = {Zhu, Zixiong and Xie, Nianhao and Zong, Kang and Chen, Lei},
TITLE = {Building a Connected Communication Network for UAV Clusters Using DE-MADDPG},
JOURNAL = {Symmetry},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1537},
URL = {https://www.mdpi.com/2073-8994/13/8/1537},
ISSN = {2073-8994},
ABSTRACT = {Clusters of unmanned aerial vehicles (UAVs) are often used to perform complex tasks. In such clusters, the reliability of the communication network connecting the UAVs is an essential factor in their collective efficiency. Due to the complex wireless environment, however, communication malfunctions within the cluster are likely during the flight of UAVs. In such cases, it is important to control the cluster and rebuild the connected network. The asymmetry of the cluster topology also increases the complexity of the control mechanisms. The traditional control methods based on cluster consistency often rely on the motion information of the neighboring UAVs. The motion information, however, may become unavailable because of the interrupted communications. UAV control algorithms based on deep reinforcement learning have achieved outstanding results in many fields. Here, we propose a cluster control method based on the Decomposed Multi-Agent Deep Deterministic Policy Gradient (DE-MADDPG) to rebuild a communication network for UAV clusters. The DE-MADDPG improves the framework of the traditional multi-agent deep deterministic policy gradient (MADDPG) algorithm by decomposing the reward function. We further introduce the reward reshaping function to facilitate the convergence of the algorithm in sparse reward environments. To address the instability of the state-space in the reinforcement learning framework, we also propose the notion of the virtual leader–follower model. Extensive simulations show that the success rate of the DE-MADDPG is higher than that of the MADDPG algorithm, confirming the effectiveness of the proposed method.},
DOI = {10.3390/sym13081537}
}



@Article{app11167665,
AUTHOR = {Jabba, Daladier and Acevedo, Pedro},
TITLE = {ViTool-BC: Visualization Tool Based on Cooja Simulator for WSN},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {7665},
URL = {https://www.mdpi.com/2076-3417/11/16/7665},
ISSN = {2076-3417},
ABSTRACT = {Evaluation and monitoring of wireless sensor networks (WSN) and the parameters defining their operations and design, such as energy consumption, latency, and stability, is a complex task due to interaction with real devices. For greater control of these variables, the use of simulators arises as an alternative. Cooja is a WSN simulator/emulator which handles the devices’ controllers and multiple communication protocol implementations, such as RPL (RPL is one of the most used protocol in IoT). However, Cooja does not consider either the implementation of an energy model (it has infinite energy consumption) nor the visual behavior of the topology construction, although these aspects are crucial for effective network analysis and decision taking. This paper presents the design and the implementation of ViTool-BC, a software built on top of Cooja, which allows the creation of different energy estimation models and also to visualize in real time the behavior of WSN topology construction. In addition, ViTool-BC offers a heat map of energy consumption traces. Therefore, this tool helps researchers to monitor in real time the topology construction, node disconnection, and battery depletion, aspects to be considered in the analysis of the available routing protocols in Cooja.},
DOI = {10.3390/app11167665}
}



@Article{rs13163303,
AUTHOR = {Anderson, Connor J. and Heins, Daniel and Pelletier, Keith C. and Bohnen, Julia L. and Knight, Joseph F.},
TITLE = {Mapping Invasive Phragmites australis Using Unoccupied Aircraft System Imagery, Canopy Height Models, and Synthetic Aperture Radar},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3303},
URL = {https://www.mdpi.com/2072-4292/13/16/3303},
ISSN = {2072-4292},
ABSTRACT = {Invasive plant species are an increasing worldwide threat both ecologically and financially. Knowing the location of these invasive plant infestations is the first step in their control. Surveying for invasive Phragmites australis is particularly challenging due to limited accessibility in wetland environments. Unoccupied aircraft systems (UAS) are a popular choice for invasive species management due to their ability to survey challenging environments and their high spatial and temporal resolution. This study tested the utility of three-band (i.e., red, green, and blue; RGB) UAS imagery for mapping Phragmites in the St. Louis River Estuary in Minnesota, U.S.A. and Saginaw Bay in Michigan, U.S.A. Iterative object-based image analysis techniques were used to identify two classes, Phragmites and Not Phragmites. Additionally, the effectiveness of canopy height models (CHMs) created from two data types, UAS imagery and commercial satellite stereo retrievals, and the RADARSAT-2 horizontal-horizontal (HH) polarization were tested for Phragmites identification. The highest overall classification accuracy of 90% was achieved when pairing the UAS imagery with a UAS-derived CHM. Producer’s accuracy for the Phragmites class ranged from 3 to 76%, and the user’s accuracies were above 90%. The Not Phragmites class had user’s and producer’s accuracies above 88%. Inclusion of the RADARSAT-2 HH polarization caused a slight reduction in classification accuracy. Commercial satellite stereo retrievals increased commission errors due to decreased spatial resolution and vertical accuracy. The lowest classification accuracy was seen when using only the RGB UAS imagery. UAS are promising for Phragmites identification, but the imagery should be used in conjunction with a CHM.},
DOI = {10.3390/rs13163303}
}



@Article{app11167687,
AUTHOR = {Huang, Jie and Tian, Guoqing and Zhang, Jiancheng and Chen, Yutao},
TITLE = {On Unmanned Aerial Vehicles Light Show Systems: Algorithms, Software and Hardware},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {7687},
URL = {https://www.mdpi.com/2076-3417/11/16/7687},
ISSN = {2076-3417},
ABSTRACT = {Unmanned aerial vehicle (UAV) light shows (UAV-LS) have a wow factor due to their advantages in terms of environment friendliness and controllability compared to traditional fireworks. In this paper, a UAV-LS system is developed including a collision-free formation transformation trajectory planning algorithm, a software package that facilitates animation design and real-time monitoring and control, and hardware design and realization. In particular, a dynamic task assignment algorithm based on graph theory is proposed to reduce the impact of UAV collision avoidance on task assignment and the frequency of task assignment in the formation transformation. In addition, the software package consists of an animation interface for formation drawing and 3D animation simulation, which helps the monitoring and control of UAVs through a real-time monitoring application. The developed UAV-LS system hardware consists of subsystems of decision-making, real-time kinematic (RTK) global positioning system (GPS), wireless communication, and UAV platforms. Outdoor experiments using six quadrotors are performed and details of implementations of high-accuracy positioning, communication, and computation are presented. Results show that the developed UAV-LS system can successfully complete a light show and the proposed task assignment algorithm performs better than traditional static ones.},
DOI = {10.3390/app11167687}
}



@Article{rs13163314,
AUTHOR = {Migas-Mazur, Robert and Kycko, Marlena and Zwijacz-Kozica, Tomasz and Zagajewski, Bogdan},
TITLE = {Assessment of Sentinel-2 Images, Support Vector Machines and Change Detection Algorithms for Bark Beetle Outbreaks Mapping in the Tatra Mountains},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3314},
URL = {https://www.mdpi.com/2072-4292/13/16/3314},
ISSN = {2072-4292},
ABSTRACT = {Cambiophagous insects, fires and windthrow cause significant forest disturbances, generating ecological changes and economical losses. The bark beetle (Ips typographus L.), inhabiting coniferous forests and eliminating weakened trees, plays a key role in posing a threat to tree stands, which are dominated by Norway spruce (Picea abies) and covers a large part of mountain areas, as well as the lowlands of Northern, Central and Eastern Europe. Due to the dynamics of the phenomena taking place, the EU recommends constant monitoring of forests in terms of large-area disturbances and factors affecting tree stands’ susceptibility to destruction. The right tools for this are multispectral satellite images, which regularly and free of charge provide up-to-date information on changes in the environment. The aim of this study was to develop a method of identifying disturbances of spruce stands, including the identification of bark beetle outbreaks. Sentinel 2 images from 2015–2018 were used for this purpose; the reference data were high-resolution aerial images, satellite WorldView 2, as well as field verification data. Support Vector Machines (SVM) distinguished six classes: deciduous forests, coniferous forests, grasslands, rocks, snags (dieback of standing trees) and cuts/windthrow. Remote sensing vegetation indices, Multivariate Alteration Detection (MAD), Multivariate Alteration Detection/Maximum Autocorrelation Factor (MAD/MAF), iteratively re-weighted Multivariate Alteration Detection (iMAD) and trained SVM signatures from another year, stacked band rasters allowed us to identify: (1) no changes; (2) dieback of standing trees; (3) logging or falling down of trees. The overall accuracy of the SVM classification oscillated between 97–99%; it was observed that in 2015–2018, as a result of the windthrow and bark beetle outbreaks and the consequences of those natural disturbances (e.g., sanitary cuts), approximately 62.5 km2 of coniferous stands (29%) died in the studied area of the Tatra Mountains.},
DOI = {10.3390/rs13163314}
}



@Article{app11167716,
AUTHOR = {Maraveas, Chrysanthos and Loukatos, Dimitrios and Bartzanas, Thomas and Arvanitis, Konstantinos G.},
TITLE = {Applications of Artificial Intelligence in Fire Safety of Agricultural Structures},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {7716},
URL = {https://www.mdpi.com/2076-3417/11/16/7716},
ISSN = {2076-3417},
ABSTRACT = {Artificial intelligence applications in fire safety of agricultural structures have practical economic and technological benefits on commercial agriculture. The FAO estimates that wildfires result in at least USD 1 billion in agriculture-related losses due to the destruction of livestock pasture, destruction of agricultural buildings, premature death of farm animals, and general disruption of agricultural activities. Even though artificial neural networks (ANNs), genetic algorithms (GAs), probabilistic neural networks (PNNs), and adaptive neurofuzzy inference systems (ANFISs), among others, have proven useful in fire prevention, their application is limited in real farm environments. Most farms rely on traditional/non-technology-based methods of fire prevention. The case for AI in agricultural fire prevention is grounded on the accuracy and reliability of computer simulations in smoke movement analysis, risk assessment, and postfire analysis. In addition, such technologies can be coupled with next-generation fire-retardant materials such as intumescent coatings with a polymer binder, blowing agent, carbon donor, and acid donor. Future prospects for AI in agriculture transcend basic fire safety to encompass Society 5.0, energy systems in smart cities, UAV monitoring, Agriculture 4.0, and decentralized energy. However, critical challenges must be overcome, including the health and safety aspects, cost, and reliability. In brief, AI offers unlimited potential in the prevention of fire hazards in farms, but the existing body of knowledge is inadequate.},
DOI = {10.3390/app11167716}
}




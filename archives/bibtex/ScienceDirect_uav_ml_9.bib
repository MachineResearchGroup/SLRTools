@article{SONG201928,
title = {Solar-sail trajectory design for multiple near-Earth asteroid exploration based on deep neural networks},
journal = {Aerospace Science and Technology},
volume = {91},
pages = {28-40},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.04.056},
url = {https://www.sciencedirect.com/science/article/pii/S1270963819301476},
author = {Yu Song and Shengping Gong},
keywords = {Solar sail, Near-Earth asteroid, Deep learning, Deep neural network, Monte Carlo Tree Search, Sequence planning},
abstract = {In the preliminary trajectory design of the multi-target rendezvous problem, a model that can quickly estimate the cost of the orbital transfer is essential. The estimation of the transfer time using solar sails between two arbitrary orbits is difficult and usually requires to solve an optimal control problem. Inspired by the successful applications of the deep neural networks in nonlinear regression, this work explores the possibility and effectiveness of mapping the transfer time for solar sails from the orbital characteristics using the deep neural networks. Furthermore, the Monte Carlo Tree Search method is investigated and used to search the optimal sequence considering a multi-asteroid exploration problem. The obtained sequences from preliminary design will be solved and verified by sequentially solving the optimal control problem. Two examples of different application backgrounds validate the effectiveness of the proposed approach.}
}
@article{GHOMMAM2020105887,
title = {Relay manoeuvre based fixed-time synchronized tracking control for UAV transport system},
journal = {Aerospace Science and Technology},
volume = {103},
pages = {105887},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.105887},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820305691},
author = {Jawhar Ghommam and Maarouf Saad and Steve Wright and Quan Min Zhu},
keywords = {Quadrotor aerial vehicle, Fixed-time synchronized tracking control, Finite-time observer, Parcel transport},
abstract = {In this paper, we address the problem of parcel distribution with Unmanned Aerial Vehicles and propose a new Aerial Transport System (ATS) that uses drone relays to enable effective parcel delivery to its destination. In particular, a leader-follower synchronization technique scheme is presented for drone rendezvous and consists of forcing one drone (leader) to be above the other (follower) for parcel relay. In this scenario, no assumptions on the availability of a dynamic model for the leader drone are made, only its position and attitude are available for feedback to the follower drone. Considering the effect of unknown variation of the parcel load, a finite-time tracking control algorithm via output-feedback is designed for the follower drone while guaranteeing that the input constraints for the drones are satisfied. To conquer the challenge faced with the underactuation property of the drone, a decoupling method is adopted in order to view the drone UAV as a cascade structure of two fully actuated subsystems. A fixed-time sliding mode surface is therefore utilized in the control procedure of the attitude tracking of the drone to cope with the disturbances and model uncertainties. Rigorous theoretical analysis is provided to prove that the tracking error of the closed-loop system converge in a finite time. Simulation results are given to demonstrate the effectiveness of the proposed control strategy.}
}
@article{ZHANG2021170,
title = {An adaptive Gaussian mixture method for nonlinear uncertainty propagation in neural networks},
journal = {Neurocomputing},
volume = {458},
pages = {170-183},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221009024},
author = {Bin Zhang and Yung C. Shin},
keywords = {Neural networks, Nonlinear uncertainty propagation, Gaussian mixture model, Dynamic systems},
abstract = {Using neural networks to address data-driven problems often entails dealing with uncertainties. However, the propagation of uncertainty through a network’s nonlinear layers is usually a bottleneck, since the existing techniques designed to transmit Gaussian distributions via moment estimation are not capable of predicting non-Gaussian distributions. In this study, a Gaussian-mixture-based uncertainty propagation scheme is proposed for neural networks. Given that any input uncertainty can be characterized as a Gaussian mixture with a finite number of components, the developed scheme actively examines each mixture component and adaptively split those whose fidelity in representing uncertainty is deteriorated by the network’s nonlinear activation layers. A Kullback–Leibler criterion that directly measures the nonlinearity-induced non-Gaussianity in post-activation distributions is derived to trigger splitting and a set of high-precision Gaussian splitting libraries is established. Four uncertainty propagation examples on dynamic systems and data-driven applications are demonstrated, in all of which the developed scheme exhibited exemplary fidelity and efficiency in predicting the evolution of non-Gaussian distributions through both recurrent and multi-layer neural networks.}
}
@article{MODICA2020105500,
title = {Monitoring the vegetation vigor in heterogeneous citrus and olive orchards. A multiscale object-based approach to extract trees’ crowns from UAV multispectral imagery},
journal = {Computers and Electronics in Agriculture},
volume = {175},
pages = {105500},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105500},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920303045},
author = {Giuseppe Modica and Gaetano Messina and Giandomenico {De Luca} and Vincenzo Fiozzo and Salvatore Praticò},
keywords = {Multispectral unmanned aerial vehicles (UAVs) imagery, Multiresolution segmentation, Precision Agriculture (PA), Spectral Vegetation Indices (VIs), Geographic object-based image analysis (GEOBIA), Vigor maps},
abstract = {Precision agriculture (PA) constitutes one of the most critical sectors of remote sensing applications that allow obtaining spatial segmentation and within-field variability information from field crops. In the last decade, an increasing source of information is provided by unmanned aerial vehicle (UAVs) platforms, mainly equipped with optical multispectral cameras, to map, monitor, and analyze, temporal and spatial variations of vegetation using ad hoc spectral vegetation indices (VIs). Considering the centimeter or sub-centimeter spatial resolution of UAV imagery, the geographic object-based image analysis (GEOBIA) approach, is becoming prevalent in UAV remote sensing applications. In the present paper, we propose a quick and reliable semi-automatic workflow implemented to process multispectral UAV imagery and aimed at the detection and extraction of olive and citrus trees’ crowns to obtain vigor maps in the framework of PA. We focused our attention on the choice of GEOBIA data input and parameters, taking into consideration its replicability and reliability in the case of heterogeneous tree orchards. The heterogeneity concerns the different tree plantation distances and composition, different crop management (irrigation, pruning, weeding), and different tree age, height, and crown diameters. The proposed GEOBIA workflow was implemented in the eCognition Developer 9.5, coupling the use of multispectral and topographic information surveyed using the Tetracam µ-MCA06 snap multispectral camera at 4 cm of ground sample distance (GSD). Three different study sites in heterogeneous citrus (Bergamot and Clementine) and olive orchards located in the Calabria region (Italy) were provided. Multiresolution segmentation was implemented using spectral and topographic band layers and optimized by applying a trial-and-error approach. The classification step was implemented as process-tree and based on a rule set algorithm, therefore easily adaptable and replicable to other datasets. Decision variables for image classification were spectral vegetation indices (NDVI, SAVI, CVI) and topographic layers (DSM and CHM). Vigor maps were based on NDVI and NDRE and allowed to highlight those areas with low vegetative vigor. The accuracy assessment was based on a per-pixel approach and computed through the F-score (F). The obtained results are promising, considering that the resulting accuracy was high, with F-score ranging from 0.85 to 0.91 for olive and bergamot, respectively. Our proposed workflow, which has proved effective in datasets of different complexity, finds its strong point is the speed of execution and on its repeatability to other different crops with few adjustments. It appears worth of interest to highlights that it requests a working day of two good skilled operators in geomatics and computer image processing, from the on-field data collection to the obtaining of vigor maps.}
}
@article{XIE2020105731,
title = {A review on plant high-throughput phenotyping traits using UAV-based sensors},
journal = {Computers and Electronics in Agriculture},
volume = {178},
pages = {105731},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105731},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919320046},
author = {Chuanqi Xie and Ce Yang},
keywords = {Unmanned aerial system (UAS), Sensors, Plant, Phenotyping, Traits},
abstract = {The current methods of phenotyping for breeding lines require a lot of time, labor and cost. In recent years, unmanned aerial system (UAS) has paved the way for the development of field high-throughput phenotyping for crops rapidly. Different sensors such as regular RGB camera (Red, Green and Blue), multispectral imaging camera (several wavebands), hyperspectral imaging camera (hundreds and even thousands of wavebands), thermal imaging sensor and light detection and ranging (LiDAR) sensor can be placed on unmanned aerial vehicle (UAV) to collect remote sensing data in field-scale trials. Based on this technique, the plant traits (e.g., yield, biomass, height, and leaf area index) can be estimated non-destructively, which is critical for high-throughput phenotyping in agriculture. Compared with ground vehicle-based sensors, UAS can increase throughput and frequency for phenotyping. It is low-cost and could provide high-resolution images compared with satellite-based technique. Based upon the phenotypic traits, those crops with high yield and strong stress resistance (e.g., disease resistance and salt resistance) can be selected, which could finally improve the production. This paper talked about the plant high-throughput phenotyping traits based on the sensors on the UAV. Also, the challenges and obstacles of UAV (e.g., flight safety, flight altitude, flight time, and sensor accuracy) were analyzed. In order to provide the updated information of the relationships between remote sensing information taken from UAV and plant phenotyping traits, we summarized the sensors, plants and traits reported in previous research articles. As a result, the review can be very useful for researchers to use appropriate UAV-based sensors to carry out plant phenotyping experiments, and for farmers to use this advanced technology in managing agricultural production.}
}
@article{LI2019272,
title = {Wavelet transform based modulation classification for 5G and UAV communication in multipath fading channel},
journal = {Physical Communication},
volume = {34},
pages = {272-282},
year = {2019},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2018.12.019},
url = {https://www.sciencedirect.com/science/article/pii/S1874490718304221},
author = {Wenwen Li and Zheng Dou and Lin Qi and Chengzhuo Shi},
keywords = {Multipath, Modulation classification, Wavelet transform, 5G, UAV},
abstract = {Nowadays, fifth generation (5G) network and unmanned aerial vehicle (UAV) are more and more important in the civil and military field. Only communicating correctly in 5G network and between UAVs, they can play a role in real world. Modulation classification is the premise to ensure communication in 5G network and between UAVs correctly. However, the effects of multipath fading always exists in the 5G communication environment and UAV communication channel, which leads to severe modulation classification performance and communication performance degradation. In order to resolve this problem, we proposed a novel modulation classification algorithm that can classify signals without priori information in multipath channel. The proposed algorithm makes the mean, variance, skewness and kurtosis of wavelet transform as the feature set, then uses principal component analysis (PCA) for feature subset selection, in the end neural network is used as classifier to classify signals. The simulation results show that the proposed algorithm can achieve the much better classification accuracy than the existing methods in multipath fading channels.}
}
@article{ZHANG2018371,
title = {A novel phase angle-encoded fruit fly optimization algorithm with mutation adaptation mechanism applied to UAV path planning},
journal = {Applied Soft Computing},
volume = {70},
pages = {371-388},
year = {2018},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2018.05.030},
url = {https://www.sciencedirect.com/science/article/pii/S156849461830303X},
author = {Xiangyin Zhang and Xingyang Lu and Songmin Jia and Xiuzhi Li},
keywords = {Path planning, Fruit fly optimization algorithm (FOA), B-Spline curve, Unmanned aerial vehicles (UAVs)},
abstract = {This paper proposed an improved version of fruit fly optimization (FOA) to solve the unmanned aerial vehicle (UAV) path planning problem. The improved algorithm combines the phase angle-encoded and mutation adaptation mechanisms into the basic FOA and is referred to as θ-MAFOA. Mutation adaptation mechanism is adopted to enhance the balance of FOA in terms of the exploitation and exploration ability, while phase angle-based encoded strategy for fruit fly locations helps to achieve the high performance in the convergence process. Then, the proposed θ-MAFOA is used to find the optimal flight path for UAV in the complex three-dimensional (3D) terrain environments with various ground defense weapons. B-Spline curve that connects the start and target points is employed to represent a smooth path. Several performance criteria and constraints are taken into consideration to evaluate the cost of UAV paths. Numerical experiments are carried out on various test scenarios and the results show the proposed θ-MAFOA is superior to the basic and other two modified versions of FOA, and also more powerful than several existing state-of-the-art optimization algorithms.}
}
@article{REGO2016234,
title = {Suspended Load Path Tracking by a Tilt-rotor UAV**This work was supported by the Brazilian agencies CNPq, CAPES, and FAPEMIG.},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {32},
pages = {234-239},
year = {2016},
note = {Cyber-Physical & Human-Systems CPHS 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.12.220},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316328920},
author = {Brenner S. Rego and Guilherme V. Raffo},
keywords = {Tilt-rotor UAV, Load Transportation, Path Tracking Control, State Estimation},
abstract = {Abstract:
This paper deals with the load transportation problem by a tilt-rotor unmanned aerial vehicle. Most approaches address the subject by formulating the system dynamics from the UAV's point of view, with the load's behavior described with respect to it. Difficulties arise if control tasks are given for the load, since the suspended load coordinates do not appear explicitly in the mathematical formulation. A novel approach is proposed, based on the formulation of the system dynamics using position and orientation of the load as generalized coordinates. The equations of motion are developed in detail, yielding a highly coupled state-space representation. It is shown that linear techniques are sufficient for path tracking of the load at low accelerations, even when subject to external disturbances and incomplete, noisy information about the state vector is available. Simulation results are presented in order to validate the proposed approach.}
}
@article{AKBAR2021107950,
title = {NOMA and 5G emerging technologies: A survey on issues and solution techniques},
journal = {Computer Networks},
volume = {190},
pages = {107950},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.107950},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621000888},
author = {Aamina Akbar and Sobia Jangsher and Farrukh A. Bhatti},
keywords = {NOMA, 5G, Optimization, Game theory, Graph theory, Machine learning, Matching theory, Analytical techniques},
abstract = {Power Domain Non-Orthogonal Multiple Access (PD-NOMA) is a potential technology for the next generation of cellular networks. Compared to classical orthogonal multiple access (OMA) techniques, PD-NOMA leverages the distinct channel gains of users for multiplexing different signals in a single resource block (time, frequency, code) in power domain. This results in higher spectral efficiency, improved user fairness, better cell-edge throughput, increased reliability and connectivity and low-latency. The flexible combination of PD-NOMA with existing and emerging technologies such as heterogeneous networks (HetNets), multiple-input multiple-output (MIMO), massive MIMO, cooperative communication, cognitive radios (CRs), millimeter wave communication, simultaneous wireless information and power transfer (SWIPT), visible light communication (VLC), mobile edge computing (MEC), intelligent reflecting surfaces (IRS), unmanned aerial vehicles (UAVs), underwater communication etc., is expected to cause further enhancements in performance. Existing survey papers on NOMA mainly focus on its concept, comparison, issues and analysis without any categorization of different techniques to solve the issues related to it. This survey paper highlights the main issues and constraints of resource allocation, signaling, practical implementation and security aspects of NOMA and its integration with 5G and upcoming wireless technologies. Various solutions have been proposed in the literature that involve optimization, analytical, game theory, matching theory, graph theory and machine learning (ML) techniques. We present an in-depth analysis and comparison of these solutions with key insights emphasizing the feasibility and applicability for a qualitative analysis. We finally identify promising future research directions and challenges in the context of PD-NOMA’s application to the existing 5G and next generation wireless networks.}
}
@article{CEREN202136,
title = {PALO bounds for reinforcement learning in partially observable stochastic games},
journal = {Neurocomputing},
volume = {420},
pages = {36-56},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.08.054},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220313345},
author = {Roi Ceren and Keyang He and Prashant Doshi and Bikramjit Banerjee},
keywords = {Multiagent systems, Reinforcement learning, POMDP, POSG},
abstract = {A partially observable stochastic game (POSG) is a general model for multiagent decision making under uncertainty. Perkins’ Monte Carlo exploring starts for partially observable Markov decision process (POMDP) (MCES-P) integrates Monte Carlo exploring starts (MCES) into a local search of the policy space to offer an elegant template for model-free reinforcement learning in POSGs. However, multiagent reinforcement learning in POSGs is tremendously more complex than in single agent settings due to the heterogeneity of agents and discrepancy of their goals. In this article, we generalize reinforcement learning under partial observability to self-interested and cooperative multiagent settings under the POSG umbrella. We present three new templates for multiagent reinforcement learning in POSGs. MCES for interactive POMDP (MCESIP) extends MCES-P by maintaining predictions of the other agent’s actions based on dynamic beliefs over models. MCES for multiagent POMDP (MCES-MP) generalizes MCES-P to the canonical multiagent POMDP framework, with a single policy mapping joint observations of all agents to joint actions. Finally, MCES for factored-reward multiagent POMDP (MCES-FMP) has each agent individually mapping joint observations to their own action. We use probabilistic approximate locally optimal (PALO) bounds to analyze sample complexity, thereby instantiating these templates to PALO learning. We promote sample efficiency by including a policy space pruning technique and evaluate the approaches on six benchmark domains as well as compare with the state-of-the-art techniques, which demonstrates that MCES-IP and MCES-FMP yield improved policies with fewer samples compared to the previous baselines.}
}
@article{SONG2020137519,
title = {Estimating reed loss caused by Locusta migratoria manilensis using UAV-based hyperspectral data},
journal = {Science of The Total Environment},
volume = {719},
pages = {137519},
year = {2020},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2020.137519},
url = {https://www.sciencedirect.com/science/article/pii/S0048969720310305},
author = {Peilin Song and Xiaomei Zheng and Yingying Li and Kangyu Zhang and Jingfeng Huang and Hongmei Li and Huijuan Zhang and Li Liu and Chuanwen Wei and Lamin R. Mansaray and Duzhi Wang and Xiumei Wang},
keywords = {Locust damage monitoring, Loss estimation model, Unmanned aerial vehicle (UAV), Hyperspectral measurement, Reed},
abstract = {Locusta migratoria manilensis has caused major damage to vegetation and crops. Quantitative evaluation studies of vegetation loss estimation from locust damage have seldom been found in traditional satellite-remote-sensing-based research due to insufficient temporal-spatial resolution available from most current satellite-based observations. We used remote sensing data acquired from an unmanned aerial vehicle (UAV) over a simulated Locusta migratoria manilensis damage experiment on a reed (Phragmites australis) canopy in Kenli District, China during July 2017. The experiment was conducted on 72 reed plots, and included three damage duration treatments with each treatment including six locust density levels. To establish the appropriate loss estimation models after locust damage, a hyperspectral imager was mounted on a UAV to collect reed canopy spectra. Loss components of six vegetation indices (RVI, NDVI, SAVI, MSAVI, GNDVI, and IPVI) and two “red edge” parameters (Dr and SDr) were used for constructing the loss estimation models. Results showed that: (1) Among the six selected vegetation indices, loss components of NDVI, MSAVI, and GNDVI were more sensitive to the variation of dry weight loss of reed green leaves and produced smaller estimation errors during the model test process, with RMSEs ranging from 8.8 to 9.1 g/m;. (2) Corresponding model test results based on loss components of the two selected red edge parameters yielded RMSEs of 27.5 g/m2 and 26.1 g/m2 for Dr and SDr respectively, suggesting an inferior performance of red edge parameters compared with vegetation indices for reed loss estimation. These results demonstrate the great potential of UAV-based loss estimation models for evaluating and quantifying degree of locust damage in an efficient and quantitative manner. The methodology has promise for being transferred to satellite remote sensing data in the future for better monitoring of locust damage of larger geographical areas.}
}
@article{ZOHDI2021113446,
title = {A digital twin framework for machine learning optimization of aerial fire fighting and pilot safety},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {373},
pages = {113446},
year = {2021},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2020.113446},
url = {https://www.sciencedirect.com/science/article/pii/S0045782520306319},
author = {T.I. Zohdi},
keywords = {Aerial fire-fighting, Fire retardants, Optimization, Machine-learning},
abstract = {The objective of this work is to model and simulate aerial drops of fire retardants in dangerous fire environments. Specifically, the work develops a computational framework for a model problem combining: •[1.] A meshless discrete element component that tracks the trajectory of released airborne materials from a controlled aircraft, ranging from retardant powders to encapsulated packets, subjected to prevailing wind velocities and fire-driven updrafts.•[2.] A Machine Learning Algorithm (MLA) to rapidly ascertain the optimal aircraft (unmanned or manned) dynamics to maximize the fire-retardant release effectiveness (released material usage and target impact). The framework is designed to enable Digital Twin type technologies, i.e. digital replicas that run in real time with the physical system. However, it is also designed to run at much faster rates, in order to enable MLA’s to optimize the planning, by running quickly on laptops and mobile systems. The overall guiding motivation is to provide a useful tool to enable rapid flight-path planning for aerial first-responders in real-time and to train pilots. Numerical examples are provided to illustrate the process.}
}
@article{WANG2018262,
title = {Flight Safety Strategy Analysis of the Plant Protection UAV},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {17},
pages = {262-267},
year = {2018},
note = {6th IFAC Conference on Bio-Robotics BIOROBOTICS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.08.170},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318312886},
author = {Shubo Wang and Yu Han and Jian Chen and Nanan Du and Yue Pan and Guangqi Wang and Zichao Zhang and Yongjun Zheng},
keywords = {plant protection UAV, flight safety, failure degree, flight fault, safety technology},
abstract = {With the popularization of the concept of plant protection unmanned aerial vehicle (UAV) and the popularity of plant protection UAV, the requirement of flight safety is becoming higher and higher. Because of the difference of operating environments and operation requirements, compared to others areas of UAV, the focus of the research of flight safety of plant protection UAV is also different. Therefore, it is necessary to carry out the research of flight safety of plant protection UAV. This paper first puts forward the relevant models and theoretical formulas for the two kinds of flight safety hazards in plant protection UAV, and provides theoretical support for safety design of plant protection UAV; Then the failure degree of plant protection UAV is further divided; Finally, the existing plant protection UAV faults and flight safety technologies are analyzed at present, which provide reference for development of flight safety of plant protection UAV.}
}
@article{SARASAN2020105251,
title = {Mapping burial mounds based on UAV-derived data in the Suusamyr Plateau, Kyrgyzstan},
journal = {Journal of Archaeological Science},
volume = {123},
pages = {105251},
year = {2020},
issn = {0305-4403},
doi = {https://doi.org/10.1016/j.jas.2020.105251},
url = {https://www.sciencedirect.com/science/article/pii/S0305440320301722},
author = {Adriana Sărășan and Adrian-Cristian Ardelean and Andrei Bălărie and Ruben Wehrheim and Kubatbek Tabaldiev and Kunbolot Akmatov},
keywords = {Unmanned aerial vehicle, Digital surface model, Geomorphons, Object based image analysis, Burial mounds, Suusamyr plateau},
abstract = {Located in the northern part of the Tian Shan Mountains, at an average elevation of over 2200 m.a.s.l., the Suusamyr Plateau is home to numerous archaeological sites. Nonetheless, there is little to no information available regarding the spatial characteristics and preservation conditions of these complex burial grounds. During the recent years, unmanned aerial vehicles (UAVs) have offered the possibility of fast acquisition of high-resolution images that facilitate the identification and documentation of archaeological sites and features. Given these advantages over 1500 ha (29 individual sites) were investigated within the Suusamyr Plateau, using a DJI Phantom 4 Pro quadcopter. Based on the UAV derived dataset, over 600 burial mounds were identified via manual mapping. However, as this is a time consuming and subjective process, a new method that integrates the multi-scale topographic analysis and the geomorphons approach is introduced here for the semi-automated extraction of burial mounds. Following an object-based image analysis (OBIA) routine, the proposed methodology was developed within a single site (T1), while the transferability degree of the final model was subsequently assessed within two other investigated sites (T2, T3). The accuracy of the obtained model was determined using the F1-Score (harmonic mean of precision and recall). The highest detection rate of 100% was achieved for test site T2, while the lowest value of 87.5% was obtained for site T3.}
}
@article{LIU2017317,
title = {Robust nonlinear control approach to nontrivial maneuvers and obstacle avoidance for quadrotor UAV under disturbances},
journal = {Robotics and Autonomous Systems},
volume = {98},
pages = {317-332},
year = {2017},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2017.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S0921889017301756},
author = {Yuyi Liu and Sujit Rajappa and Jan Maximilian Montenbruck and Paolo Stegagno and Heinrich Bülthoff and Frank Allgöwer and Andreas Zell},
keywords = {Aerial robotics, Unmanned Aerial Vehicles, Robust control, Nonlinear observer, Obstacle avoidance},
abstract = {In this paper, we present an onboard robust nonlinear control approach for quadrotor Unmanned Aerial Vehicles (UAVs) in the environments with disturbances and obstacles. The complete framework consists of an attitude controller based on the solution of global output regulation problems for SO(3), a backstepping-like position controller, a 6-dimensional wrench observer to estimate the unknown force and torque disturbances, and an online trajectory planner based on a model predictive control method with obstacle avoiding constraints. We prove the strong convergence properties of the proposed method both in theory and via real-robot experiments. The control approach is onboard implemented on a quadrotor UAV, and has been validated through intensive experiments and compared with other nonlinear control methods for waypoint navigation and large-tilted path following tasks in the presence of external disturbances, e.g. wind gusts. The presented approach has also been evaluated in the scenarios with randomly located obstacles.}
}
@article{WU2019,
title = {Modeling and sliding mode-based attitude tracking control of a quadrotor UAV with time-varying mass},
journal = {ISA Transactions},
year = {2019},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2019.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S0019057819303544},
author = {Xiwei Wu and Bing Xiao and Yaohong Qu},
keywords = {Quadrotor, Time-varying mass, Attitude tracking, Sliding mode control},
abstract = {In the practical applications, the mass of a quadrotor unmanned aerial vehicle (UAV) would be time-varying. This time-varying mass will deteriorate the control performance of UAV. To solve this challenge, the mathematical modeling problem of a quadrotor UAV with time-varying mass is first investigated in this paper. The nonlinear dynamics describing the six-degrees-of-freedom full motion is established. Based on the established model, taking attitude tracking control problem into consideration, a robust control scheme is then designed via the sliding mode control theory. Applying the developed proposed approach, the desired trajectory is followed with the attitude tracking error asymptotically stabilized. The proposed controller has the capability of rejecting the external disturbance and the uncertainties induced by the time-varying mass. The feasibility of the established model and the effectiveness of the presented control approach are validated through a simulation study.}
}
@article{SAIDMOHAMED2021971,
title = {Smart farming for improving agricultural management},
journal = {The Egyptian Journal of Remote Sensing and Space Science},
volume = {24},
number = {3, Part 2},
pages = {971-981},
year = {2021},
issn = {1110-9823},
doi = {https://doi.org/10.1016/j.ejrs.2021.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S1110982321000582},
author = {Elsayed {Said Mohamed} and AA. Belal and Sameh {Kotb Abd-Elmabod} and Mohammed A El-Shirbeny and A. Gad and Mohamed B Zahran},
keywords = {IoT, Smart Agriculture, 5G, Decision support systems, Smart sensing},
abstract = {The food shortage and the population growth are the most challenges facing sustainable development worldwide. Advanced technologies such as artificial intelligence (AI), the Internet of Things (IoT), and the mobile internet can provide realistic solutions to the challenges that are facing the world. Therefore, this work focuses on the new approaches regarding smart farming (SF) from 2019 to 2021, where the work illustrates the data gathering, transmission, storage, analysis, and also, suitable solutions. IoT is one of the essential pillars in smart systems, as it connects sensor devices to perform various basic tasks. The smart irrigation system included those sensors for monitoring water level, irrigation efficiency, climate, etc. Smart irrigation is based on smart controllers and sensors as well as some mathematical relations. In addition, this work illustrated the application of unmanned aerial vehicles (UAV) and robots, where they can be achieved several functions such as harvesting, seedling, weed detection, irrigation, spraying of agricultural pests, livestock applications, etc. real-time using IoT, artificial intelligence (AI), deep learning (DL), machine learning (ML) and wireless communications. Moreover, this work demonstrates the importance of using a 5G mobile network in developing smart systems, as it leads to high-speed data transfer, up to 20 Gbps, and can link a large number of devices per square kilometer. Although the applications of smart farming in developing countries are facing several challenges, this work highlighted some approaches the smart farming. In addition, the implementation of Smart Decision Support Systems (SDSS) in developing countries supports the real-time analysis, mapping of soil characteristics and also helps to make proper decision management. Finally, smart agriculture in developing countries needs more support from governments at the small farms and the private sector.}
}
@article{COLONNESE2019101872,
title = {Q-SQUARE: A Q-learning approach to provide a QoE aware UAV flight path in cellular networks},
journal = {Ad Hoc Networks},
volume = {91},
pages = {101872},
year = {2019},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2019.101872},
url = {https://www.sciencedirect.com/science/article/pii/S1570870518309508},
author = {Stefania Colonnese and Francesca Cuomo and Giulio Pagliari and Luca Chiaraviglio},
keywords = {UAVs, Cellular networks, Quality of experience, Q-learning},
abstract = {This paper deals with the adoption of Unmanned Aerial Vehicles (UAVs) as mobile Base Stations providing video streaming services within a cellular macro area. We devise a Q-learning based UAV flight planning algorithm aimed at improving the Quality of Experience (QoE) of video users. Specifically, the proposed algorithm, herein denoted as Q-SQUARE, leverages the well-established Q-learning algorithm by introducing a reward related to a key QoE metric that is the video segment delay. The Q-SQUARE algorithm also accounts for different UAV recharging stations being available in the covered area. The performance analysis, as a function of the number of UAVs and recharging stations, show that Q-SQUARE identifies the UAV flight paths, i.e. specific space-time allocation of the available bandwidth resources, that definitely improve the QoE of the streaming services.}
}
@article{LIU2020255,
title = {MiniNet: An extremely lightweight convolutional neural network for real-time unsupervised monocular depth estimation},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {166},
pages = {255-267},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620301544},
author = {Jun Liu and Qing Li and Rui Cao and Wenming Tang and Guoping Qiu},
keywords = {Monocular depth estimation, Convolutional neural network, Unsupervised learning, Lightweight, Real-time},
abstract = {Predicting depth from a single image is an attractive research topic since it provides one more dimension of information to enable machines to better perceive the world. Recently, deep learning has emerged as an effective approach to monocular depth estimation. As obtaining labeled data is costly, there is a recent trend to move from supervised learning to unsupervised learning to obtain monocular depth. However, most unsupervised learning methods capable of achieving high depth prediction accuracy will require a deep network architecture which will be too heavy and complex to run on embedded devices with limited storage and memory spaces. To address this issue, we propose a new powerful network with a recurrent module to achieve the capability of a deep network while at the same time maintaining an extremely lightweight size for real-time high performance unsupervised monocular depth prediction from video sequences. Besides, a novel efficient upsample block is proposed to fuse the features from the associated encoder layer and recover the spatial size of features with the small number of model parameters. We validate the effectiveness of our approach via extensive experiments on the KITTI dataset. Our new model can run at a speed of about 110 frames per second (fps) on a single GPU, 37 fps on a single CPU, and 2 fps on a Raspberry Pi 3. Moreover, it achieves higher depth accuracy with nearly 33 times fewer model parameters than state-of-the-art models. To the best of our knowledge, this work is the first extremely lightweight neural network trained on monocular video sequences for real-time unsupervised monocular depth estimation, which opens up the possibility of implementing deep learning-based real-time unsupervised monocular depth prediction on low-cost embedded devices.}
}
@article{ALVAREZMONTOYA2020106526,
title = {In-flight and wireless damage detection in a UAV composite wing using fiber optic sensors and strain field pattern recognition},
journal = {Mechanical Systems and Signal Processing},
volume = {136},
pages = {106526},
year = {2020},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2019.106526},
url = {https://www.sciencedirect.com/science/article/pii/S0888327019307472},
author = {Joham Alvarez-Montoya and Alejandro Carvajal-Castrillón and Julián Sierra-Pérez},
keywords = {Structural health monitoring, Damage detection, Composite materials, Aerospace structures, Machine learning, Remote sensing},
abstract = {Aiming to provide more efficient, lightweight structures, composite materials are being extensively used in aerospace vehicles. As the failure mechanisms of these materials are complex, damage detection becomes challenging, requiring advanced techniques for assessing structural integrity and maintaining aircraft safety. In this context, Structural Health Monitoring (SHM) seeks for integrating sensors into the structures in a way that Nondestructive Testing (NDT) is implemented continuously. One promising approach is to use Fiber Optic Sensors (FOS) to acquire strain signals, taking advantages of their capabilities over conventional sensors. Despite several works have developed Health and Usage Monitoring Systems (HUMS) using FOS for performing in-flight SHM in aircraft structures, automatic damage detection using the acquired signals has not been achieved in a robust way against environmental and operational variability, in all flight stages or considering different types of damages. In this work, a HUMS was developed and implemented in an Unmanned Aerial Vehicle (UAV) based on 20 Fiber Bragg Gratings (FBGs) embedded into the composite front spar of the aircraft’s wing, a miniaturized data acquisition subsystem for gathering strain signals and a wireless transmission subsystem for remote sensing. The HUMS was tested in 16 flights, six of them were carried out with the pristine structure and the remaining after inducing different artificial damages. The in-flight data were used to validate a previously developed damage detection methodology based on strain field pattern recognition, or strain mapping, which utilizes machine learning algorithms, specifically a Self-Organizing Map (SOM)-based procedure for clustering operational conditions and Principal Component Analysis (PCA) in conjunction with damage indices for final classification. The performance of the damage detection demonstrated a highest accuracy of 0.981 and a highest F1 score of 0.978. As a main contribution, this work implements in-flight strain monitoring, remote sensing and automatic damage detection in an operating composite aircraft structure.}
}
@article{KIM2021109419,
title = {Utilizing machine learning for detecting flowering in mid-range digital repeat photography},
journal = {Ecological Modelling},
volume = {440},
pages = {109419},
year = {2021},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2020.109419},
url = {https://www.sciencedirect.com/science/article/pii/S0304380020304774},
author = {Tae Kyung Kim and Sukyung Kim and Myoungsoo Won and Jong-Hwan Lim and Sukhee Yoon and Keunchang Jang and Kye-Han Lee and Yeong Dae Park and Hyun Seok Kim},
abstract = {The responses of plants to climate change are typically reflected in the changes in leaf and flowering phenology. By exploiting the strength and simplicity of repeated digital photography and color indices, a majority of the phenological studies have been successful at investigating leaf phenology, while flowering phenology is rarely studied using the automatic capture and analysis of repeated photography. In this study, we trained and tested 5 different pretrained Convolutional Neural Network (CNN) algorithms to detect flowering events from images of white colored flowering trees and analyzed the possible factors that can affect the performance of the models. We collected images from the web and processed the images into a binary classification dataset in which a positive label indicated a tree in bloom. We also installed time-lapse cameras and captured images to validate the performances of the models in the real-world. Regarding the CNN architectures, the VGG16, ResNet50, ResNet101, MobileNet, and NASNet models were adopted, and the model weights were pretrained using the ImageNet-1000 dataset. After 20 epochs of training with 16,005 images, all of the models were successfully trained, reaching over 98% test accuracy, and 4 models reached over 99% test accuracy. All the models also showed accurate and stable performances in detecting flowering in time-series datasets with a minor inconstancy at the beginning of the flowering stages. Overall, the NASNet model showed the best performance in both the test dataset and the time-series datasets. A detailed analysis of the performance revealed that the models were especially prone to misclassify images with small relative flowering areas and were affected by the number of samples in the training dataset. We concluded that the preprocessing of the images and the size of the training dataset are essential for the high performance of the models compared to the architecture of the individual models. Furthermore, in addition to the need for a larger dataset, the proper resolution is required to successfully detect flowering from repeated photography, and most current phenological networks do not meet this condition. We suggest that mid-range photography combined with CNN algorithms can be a legitimate approach to properly accumulate and automatically process the data for studying flowering phenology.}
}
@article{QIAO2019318,
title = {Individual Cattle Identification Using a Deep Learning Based Framework⁎⁎The authors acknowledge the support of the Meat Livestock Australia Donor Company through the project: Objective, robust, real-time animal welfare measures for the Australian red meat industry.},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {30},
pages = {318-323},
year = {2019},
note = {6th IFAC Conference on Sensing, Control and Automation Technologies for Agriculture AGRICONTROL 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.558},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319324772},
author = {Yongliang Qiao and Daobilige Su and He Kong and Salah Sukkarieh and Sabrina Lomax and Cameron Clark},
keywords = {Cattle identification, deep learning, LSTM, CNN, precision livestock farming},
abstract = {Individual cattle identification is required for precision livestock farming. Current methods for individual cattle identification requires either visual, or unique radio frequency, ear tags. We propose a deep learning based framework to identify beef cattle using image sequences unifying the advantages of both CNN (Convolutional Neural Network) and LSTM (Long Short-Term Memory) network methods. A CNN network was used (Inception-V3) to extract features from a rear-view cattle video dataset and these extracted features were then used to train an LSTM model to capture temporal information and identify each individual animal. A total of 516 rear- view videos of 41 cattle at three time points separated by one month were collected. Our method achieved an accuracy of 88% and 91% for 15-frame and 20-frame video length, respectively. Our approach outperformed the framework that only uses CNN (identification accuracy 57%). Our framework will now be further improved using additional data before integrating the system into on-farm management processes.}
}
@article{BHATTACHARYA2021102589,
title = {Deep learning and medical image processing for coronavirus (COVID-19) pandemic: A survey},
journal = {Sustainable Cities and Society},
volume = {65},
pages = {102589},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102589},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720308076},
author = {Sweta Bhattacharya and Praveen Kumar {Reddy Maddikunta} and Quoc-Viet Pham and Thippa Reddy Gadekallu and Siva Rama {Krishnan S} and Chiranji Lal Chowdhary and Mamoun Alazab and Md. {Jalil Piran}},
keywords = {Artificial intelligence (AI), Big data, Coronavirus pandemic, COVID-19, Epidemic outbreak, Deep learning, Medical image processing},
abstract = {Since December 2019, the coronavirus disease (COVID-19) outbreak has caused many death cases and affected all sectors of human life. With gradual progression of time, COVID-19 was declared by the world health organization (WHO) as an outbreak, which has imposed a heavy burden on almost all countries, especially ones with weaker health systems and ones with slow responses. In the field of healthcare, deep learning has been implemented in many applications, e.g., diabetic retinopathy detection, lung nodule classification, fetal localization, and thyroid diagnosis. Numerous sources of medical images (e.g., X-ray, CT, and MRI) make deep learning a great technique to combat the COVID-19 outbreak. Motivated by this fact, a large number of research works have been proposed and developed for the initial months of 2020. In this paper, we first focus on summarizing the state-of-the-art research works related to deep learning applications for COVID-19 medical image processing. Then, we provide an overview of deep learning and its applications to healthcare found in the last decade. Next, three use cases in China, Korea, and Canada are also presented to show deep learning applications for COVID-19 medical image processing. Finally, we discuss several challenges and issues related to deep learning implementations for COVID-19 medical image processing, which are expected to drive further studies in controlling the outbreak and controlling the crisis, which results in smart healthy cities.}
}
@article{KOK2021106546,
title = {Support Vector Machine in Precision Agriculture: A review},
journal = {Computers and Electronics in Agriculture},
volume = {191},
pages = {106546},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106546},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921005639},
author = {Zhi Hong Kok and Abdul Rashid {Mohamed Shariff} and Meftah Salem M. Alfatni and Siti Khairunniza-Bejo},
keywords = {Support vector machine, Precision agriculture, Machine learning comparison, Deep learning, Crop cover classification},
abstract = {The Support Vector Machine (SVM) is a Machine Learning (ML) algorithm which may be used for acquiring solutions towards better crop management. The applications of SVM in precision agriculture (PA) are compared by identifying its interactions with variables, comparing its model performance, highlighting its strengths and weaknesses, as well as suggestions for improvements. From the perspective of six ML applications in PA, we confirmed features which may benefit the model in general (e.g. feature selection) or specific applications (e.g. phenology). SVM was found to outperform most models, with an inconclusive comparison with Random Forest (RF) and inferior to Deep Learning (DL). To our knowledge, this review highlights and summarizes recently renewed efforts of improving SVM performance in PA through its integration with DL, which is believed to be an upcoming trend for ML model development in modern PA.}
}
@article{ZHANG2021107405,
title = {Chaotic neural network algorithm with competitive learning for global optimization},
journal = {Knowledge-Based Systems},
volume = {231},
pages = {107405},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107405},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121006675},
author = {Yiying Zhang},
keywords = {Artificial neural networks, Neural network algorithm, Global optimization, Chaos theory},
abstract = {Neural network algorithm (NNA) is one of the newest proposed metaheuristic algorithms. NNA has strong global search ability due to the unique structure of artificial neural networks. Further, NNA is an algorithm without any effort for fine tuning initial parameters. Thus, it is very easy for NNA to solve different types of optimization problems. However, when used for solving complex optimization problems, slow convergence and premature convergence are its drawbacks. To overcome the two drawbacks, this work presents an improved NNA, namely chaotic neural network algorithm with competitive learning (CCLNNA), for global optimization. In CCLNNA, population is first divided into excellent subpopulation and common subpopulation according to the built competitive mechanism. Then, to balance exploration and exploitation of CCLNNA, excellent subpopulation is optimized by the designed transfer operator while common subpopulation is updated by the combination of the designed bias operator and transfer operator. Besides, chaos theory is introduced to increase the chance of CCLNNA to escape from the local optimum. To investigate the effectiveness of the improved strategies, CCLNNA is first used to solve the well-known CEC 2014 test suite with 30 benchmark functions. Then it is employed for solving three constrained real-world engineering design problems. Experimental results reveal that the improved strategies introduced to NNA can significantly improve the optimization performance of NNA and CCLNNA is a very powerful algorithm in solving complex optimization problems with multimodal properties by comparing with the other competitive algorithms.}
}
@article{ZHANG2021112575,
title = {Deep-learning-based burned area mapping using the synergy of Sentinel-1&2 data},
journal = {Remote Sensing of Environment},
volume = {264},
pages = {112575},
year = {2021},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112575},
url = {https://www.sciencedirect.com/science/article/pii/S0034425721002959},
author = {Qi Zhang and Linlin Ge and Ruiheng Zhang and Graciela Isabel Metternicht and Zheyuan Du and Jianming Kuang and Min Xu},
keywords = {Burned area mapping, Sentinel-1, Sentinel-2, Siamese self-attention, Deep learning},
abstract = {Around 350 million hectares of land are affected by wildfires every year influencing the health of ecosystems and leaving a trail of destruction. Accurate information over burned areas (BA) is essential for governments and communities to prioritize recovery actions. Prior research over the past decades has established the potentials and limitations of space-borne earth observation for mapping BA over large geographic areas at various scales. The operational deployment of Sentinel-1 and Sentinel-2 constellations significantly improved the quality and quantity of the imagery from the microwave (C-band) and optical regions on the spectrum. Based on that, this study set to investigate whether the existing coarse BA products can be further improved by the synergy of optical surface reflectance (SR), radar backscatter coefficient (BS), and/or radar interferometric coherence (COR) data with higher spatial resolutions. A Siamese Self-Attention (SSA) classification strategy is proposed for the multi-sensor BA mapping and a multi-source dataset is constructed at the object level for the training and testing. Results are analyzed by test sites, feature sources, and classification strategies to appraise the improvements achieved by the proposed method.}
}
@article{KOTZE20201664,
title = {Training Neural Networks for Plant Estimation, Control and Disturbance Rejection},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {1664-1670},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.2228},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320328871},
author = {Henry Kotzé and Herman Kamper and Hendrik W. Jordaan},
keywords = {Neural, fuzzy adaptive control, Adaptive observer design, Nonlinear adaptive control},
abstract = {Neural networks are used in control systems to combat difficulties which nonlinear and linear controllers struggle to compensate for, such as environmental and model uncertainties. Neural networks have shown promising results as controllers or estimators of these uncertainties. However, few studies expand on important aspects on using and training a neural network, such as the dataset, input and output pairs, and the training of the different controllers and estimators. In this paper, a dataset used for neural controllers and estimators are presented which contains more complexity than that of the expected test environment. The training of different neural controllers and estimators are presented: estimators for the forward dynamics and disturbances, a feedback controller, a feedback linearisation controller and a disturbance rejection controller. For each neural component, the input and output pairs are presented with results of them performing in a test environment. From these results it was evident that through the use of the proposed dataset and training method the neural networks succeeded in fulfilling its role in the control architectures.}
}
@article{BARNAWI2021119,
title = {Artificial intelligence-enabled Internet of Things-based system for COVID-19 screening using aerial thermal imaging},
journal = {Future Generation Computer Systems},
volume = {124},
pages = {119-132},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.05.019},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21001692},
author = {Ahmed Barnawi and Prateek Chhikara and Rajkumar Tekchandani and Neeraj Kumar and Bander Alzahrani},
keywords = {Computer vision, COVID-19, Face recognition, Object detection, Thermal imaging, Unmanned aerial vehicles},
abstract = {Internet of Things (IoT) has recently brought an influential research and analysis platform in a broad diversity of academic and industrial disciplines, particularly in healthcare. The IoT revolution is reshaping current healthcare practices by consolidating technological, economic, and social views. Since December 2019, the spreading of COVID-19 across the world has impacted the world’s economy. IoT technology integrated with Artificial Intelligence (AI) can help to address COVID-19. UAVs equipped with IoT devices can collect raw data that demands computing and analysis to make intelligent decision without human intervention. To mitigate the effect of COVID-19, in this paper, we propose an IoT-UAV-based scheme to collect raw data using onboard thermal sensors. The thermal image captured from the thermal camera is used to determine the potential people in the image (of the massive crowd in a city), which may have COVID-19, based on the temperature recorded. An efficient hybrid approach for a face recognition system is proposed to detect the people in the image having high body temperature from infrared images captured in a real-time scenario. Also, a face mask detection scheme is introduced, which detects whether a person has a mask on the face or not. The schemes’ performance evaluation is done using various machine learning and deep learning classifiers. We use the edge computing infrastructure (onboard sensors and actuators) for data processing to reduce the response time for real-time analytics and prediction. The proposed scheme has an average accuracy of  99.5% using various performance evaluation metrics indicating its practical applicability in real-time scenarios.}
}
@article{DEEBAK2020102,
title = {A smart lightweight privacy preservation scheme for IoT-based UAV communication systems},
journal = {Computer Communications},
volume = {162},
pages = {102-117},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420319034},
author = {B.D. Deebak and Fadi Al-Turjman},
keywords = {Unmanned aerial vehicle, Internet of drone, Authentication, Session-key agreement, Privacy-preserving},
abstract = {Unmanned Aerial Vehicle (UAV) has extensively been practiced in the military and civilian surveillance systems that access sensitive data over the cellular networks. However, channel insecurity and battery limitation may not protect the aerial coverage area. Thus, sensitive information gathered through aerial vehicles causes security threats. To manage the security issues, Smart Internet of Drone (S-IoD) have been evolved to use Intelligent Personal Assistant (IPA) as a software agent while monitoring and observing areas of interest. The current state-of-the-art technologies provide ubiquitous communication to enable several Internet of Things (IoT) paradigms. It achieves a feature of a decision support system that allows the smart interaction and communication between real-time entities. IPA offers smart interaction with other smart real-time entities to gain the user’s knowledge and awareness. This paper presents an S-IoD framework for a UAV environment that independently collects sensible information. In order to reduce the computation cost of the authentication protocol, a lightweight privacy-preserving scheme (L-PPS) is introduced. The proposed L-PPS is constructive to provide the robustness between the IoT devices with a valid authentication period. To demonstrate the security and performance efficiencies, the formal verification was performed using a verification tool, Scyther, and a random oracle model. In addition, the proposed L-PPS introduces a secret token and dynamic user authentication to speed up the authentication process between the communication entities. Importantly, the authentication session of L-PPS does not use any complex cryptographic operations, whereby it has less computation and communication costs to meet the standard constraints of surveillance systems. Moreover, the obtained simulation analysis proves that the proposed L-PPS achieves better quality metrics than other authentication schemes in the literature.}
}
@article{WEI20131949,
title = {An Operation-Time Simulation Framework for UAV Swarm Configuration and Mission Planning},
journal = {Procedia Computer Science},
volume = {18},
pages = {1949-1958},
year = {2013},
note = {2013 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.05.364},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913005073},
author = {Yi Wei and M. Brian Blake and Gregory R. Madey},
keywords = {DDDAS, UAV Swarm, Mission Planning, Simulation Framework},
abstract = {In recent years, Unmanned Aerial Vehicles (UAV), have been increasingly utilized by both military and civilian organizations because they are less expensive, provide greater flexibilities and remove the need for on-board pilot support. Largely due to their utility and increased capabilities, in the near future, swarms of UAVs will replace single UAV use. Efficient control of swarms opens a set of new challenges, such as automatic UAV coordination, efficient swarm monitoring and dynamic mission planning. In this paper, we investigate the problem of dynamic mission planning for a UAV swarm. A centralized-distributed hybrid control framework is proposed for mission assignment and scheduling. The Dynamic Data Driven Application System (DDDAS) principles are applied to the framework so that it can adapt to the changing nature of the environment and the missions. A prototype simulation program is implemented as a proof-of- concept of the framework. Experimentation with the framework suggests the effectiveness of swarm control for several mission planning mechanisms.}
}
@article{ZHANG2020107434,
title = {Image fusion employing adaptive spectral-spatial gradient sparse regularization in UAV remote sensing},
journal = {Signal Processing},
volume = {170},
pages = {107434},
year = {2020},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2019.107434},
url = {https://www.sciencedirect.com/science/article/pii/S0165168419304864},
author = {Mengliang Zhang and Song Li and Feng Yu and Xin Tian},
keywords = {Image fusion, Adaptive spectral-spatial, Sparse regularization, Vegetation index},
abstract = {Unmanned aerial vehicle (UAV) remote sensing has been widely used in vegetation phenotypes and precision agriculture. The fusion of UAV multispectral and panchromatic images has considerable research value. For example, an accurate vegetation index can be obtained. However, large geometrical distortions are observed in UAV images, contributing to the insufficiency of existing fusion algorithms. Spectrum consistency, which indicates that changes in spectral direction are always a smooth function, is investigated in this paper to solve the above problem. Spatial adaptivity is also introduced to reduce spectral distortion in the fusion process. Based on the two aspects, a multispectral and panchromatic image fusion model employing adaptive spectral-spatial gradient sparse regularization is proposed for UAV remote sensing. The separable approximation and augmented Lagrangian methods are employed to optimize this model. In the experiments, the proposed method is firstly compared with other state-of-the-art fusion algorithms, and good performance is verified by UAV datasets in terms of visual effect and objective quality analysis. Secondly, the fusion algorithm is applied in the application of a vegetation phenotype. The experiments finally demonstrate that accurate vegetation indices can be generated by adopting the proposed algorithm. This finding proves the substantial research value of the proposed algorithm in UAV remote sensing.}
}
@article{PENG2020124821,
title = {A novel optimal bipartite consensus control scheme for unknown multi-agent systems via model-free reinforcement learning},
journal = {Applied Mathematics and Computation},
volume = {369},
pages = {124821},
year = {2020},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2019.124821},
url = {https://www.sciencedirect.com/science/article/pii/S0096300319308136},
author = {Zhinan Peng and Jiangping Hu and Kaibo Shi and Rui Luo and Rui Huang and Bijoy Kumar Ghosh and Jiuke Huang},
keywords = {Optimal bipartite consensus control, Multi-agent systems, Coopetition network, Model-free, Reinforcement learning},
abstract = {In this paper, the optimal bipartite consensus control (OBCC) problem is investigated for unknown multi-agent systems (MASs) with coopetition networks. A novel distributed OBCC scheme is proposed based on model-free reinforcement learning method to achieve OBCC, where the agent’s dynamics are no longer required. First, The coopetition networks are applied to establish the cooperative and competitive interactions among agents, and then the OBCC problem is formulated by introducing local neighbor bipartite consensus errors and performance index functions (PIFs) for each agent. Second, in order to obtain the OBCC laws, a policy iteration algorithm (PIA) is employed to learn the solutions to discrete-time (DT) Hamilton-Jacobi-Bellman (HJB) equations. Third, to implement the proposed methods, we adopt a data-driven actor-critic-based neural networks (NNs) framework to approximate the control laws and the PIFs, respectively, in an online learning manner. Finally, some simulation results are given to demonstrate the effectiveness of the developed approaches.}
}
@article{MUTIS2020103237,
title = {Real-time space occupancy sensing and human motion analysis using deep learning for indoor air quality control},
journal = {Automation in Construction},
volume = {116},
pages = {103237},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103237},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519307630},
author = {Ivan Mutis and Abhijeet Ambekar and Virat Joshi},
keywords = {Motion analysis, Occupancy sensing, Pose estimation, Indoor air quality control, Space-use analysis},
abstract = {This study proposed a novel indoor air quality control methodology that uses occupancy sensing and motion recognition techniques in combination with human motion analysis. The automated occupancy sensing systems that are most prevalent today analyze either environmental conditions (i.e., room temperature or data from entities in the room, such as states of electronic devices) to make human occupancy predictions. Since little emphasis is placed on observing humans directly, the estimations of these sensing systems are often inaccurate. Erroneous occupancy estimation leads to poor control of building resources such as HVAC (Heating, Ventilation, and Air-conditioning) and lighting systems. To address this issue, the paper puts forth a lean, vision-based system that estimates the number of occupants and recognizes their activities using the stacked history of unconstrained non-deterministic human movements over transient intervals. The system implements a multi-stream deep neural network to identify human activities and uses the YOLO V3 deep neural network for object detection to estimate occupancy count in a room. The study uses a publicly available action recognition dataset – NADA – to train the neural networks and experiment with a variety of video classification techniques to achieve higher accuracies.}
}
@article{SUN2021345,
title = {Analyzing the Short-Term Dependency in Ultra-High Magnetic Response Systems - Modeling Sequential Data with Non-Recurrent Neural Networks},
journal = {Procedia Computer Science},
volume = {185},
pages = {345-352},
year = {2021},
note = {Big Data, IoT, and AI for a Smarter Future},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.05.044},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921011297},
author = {Jieming Sun and Lichun Li},
keywords = {Sequential Data, Dynamic Systems, Observability, Neural Networks},
abstract = {Recurrent neural network (RNN) is a popular modeling choice for sequential data. However, empirical experience shows RNNs are often difficult and time-consuming to tune and customize. It drives practitioners to replace RNNs with non-recurrent neural networks which presented comparable performances in some cases. The success of using non-recurrent neural networks to model sequential data indicates the short-term dependency among sequential data. In this paper, we systematically analyze the short-term dependency in ultra-high magnetic response systems (UHMR) with partial system knowledge based on the observability criterion of the dynamic systems. Moreover, we show that the sequential data in the UHMR system only have 2-step dependency. This result indicates that any consecutive three steps in an experiment form a datum to train a feed-forward neural network (FFNN). Therefore, sufficient data can be collected within a small number of experiments. Based on the analysis, we train a feed-forward neural network to model the UHMR system based on the sequential data from four experiments. Through proper data pre-processing, the FFNN model can predict the system performance with bounded mean absolute error.}
}
@article{JOHANSEN202028,
title = {Mapping the condition of macadamia tree crops using multi-spectral UAV and WorldView-3 imagery},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {165},
pages = {28-40},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.04.017},
url = {https://www.sciencedirect.com/science/article/pii/S092427162030112X},
author = {Kasper Johansen and Qibin Duan and Yu-Hsuan Tu and Chris Searle and Dan Wu and Stuart Phinn and Andrew Robson and Matthew F. McCabe},
keywords = {UAV, WorldView-3, High spatial resolution, Macadamia, Tree condition, Random forest},
abstract = {Australia is one of the world’s largest producers of macadamia nuts. As macadamia trees can take up to 15 years to mature and produce maximum yield, it is important to optimize tree condition. Field based assessment of macadamia tree condition is time-consuming and often inconsistent. Using remotely sensed imagery may allow for faster, more extensive, and more consistent assessment of macadamia tree condition. To identify individual macadamia tree crowns, high spatial resolution imagery is required. Hence, the objective of this work was to develop and test an approach to map the condition of individual macadamia tree crowns using both multi-spectral Unmanned Aerial Vehicle (UAV) and WorldView-3 imagery for different macadamia varieties and three different sites located near Bundaberg, Australia. A random forest classifier, based on all available spectral bands and selected vegetation indices was used to predict five condition categories, ranging from excellent (category 1) to poor (category 5). Various combinations of the developed models were tested between the three sites and over time. The results showed that the multi-spectral WorldView-3 imagery produced the lowest out of bag (OOB) classification errors in most cases. However, for both the UAV and the WorldView-3 imagery, more than 98.5% of predicted macadamia condition categories were either correctly mapped or offset by a single category out of the five condition categories (excellent, good, moderate, fair and poor) for trees of the same variety and at one point in time. Multi-temporally, the WorldView-3 imagery performed better than the UAV data for predicting the condition of the same macadamia tree variety. Applying a model from one site to another site with the same macadamia tree variety produced OOB classification between 31.20 and 42.74%, but with >98.63% of trees predicted within a single condition category. Importantly, models trained based on one type of macadamia tree variety could not be successfully applied to a site with another variety. The developed classification models may be used as a decision and management support tool for the macadamia industry to inform management practices and improve on-demand irrigation, fertilization, and pest inspection at the individual tree level.}
}
@article{AO2021,
title = {Automatic segmentation of stem and leaf components and individual maize plants in field terrestrial LiDAR data using convolutional neural networks},
journal = {The Crop Journal},
year = {2021},
issn = {2214-5141},
doi = {https://doi.org/10.1016/j.cj.2021.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S2214514121002191},
author = {Zurui Ao and Fangfang Wu and Saihan Hu and Ying Sun and Yanjun Su and Qinghua Guo and Qinchuan Xin},
keywords = {Terrestrial LiDAR, Phenotype, Organ segmentation, Convolutional neural networks},
abstract = {High-throughput maize phenotyping at both organ and plant levels plays a key role in molecular breeding for increasing crop yields. Although the rapid development of light detection and ranging (LiDAR) provides a new way to characterize three-dimensional (3D) plant structure, there is a need to develop robust algorithms for extracting 3D phenotypic traits from LiDAR data to assist in gene identification and selection. Accurate 3D phenotyping in field environments remains challenging, owing to difficulties in segmentation of organs and individual plants in field terrestrial LiDAR data. We describe a two-stage method that combines both convolutional neural networks (CNNs) and morphological characteristics to segment stems and leaves of individual maize plants in field environments. It initially extracts stem points using the PointCNN model and obtains stem instances by fitting 3D cylinders to the points. It then segments the field LiDAR point cloud into individual plants using local point densities and 3D morphological structures of maize plants. The method was tested using 40 samples from field observations and showed high accuracy in the segmentation of both organs (F-score =0.8207) and plants (F-score =0.9909). The effectiveness of terrestrial LiDAR for phenotyping at organ (including leaf area and stem position) and individual plant (including individual height and crown width) levels in field environments was evaluated. The accuracies of derived stem position (position error =0.0141 m), plant height (R2 >0.99), crown width (R2 >0.90), and leaf area (R2 >0.85) allow investigating plant structural and functional phenotypes in a high-throughput way. This CNN-based solution overcomes the major challenges in organ-level phenotypic trait extraction associated with the organ segmentation, and potentially contributes to studies of plant phenomics and precision agriculture.}
}
@article{MUKHERJEE2019102461,
title = {A survey of unmanned aerial sensing solutions in precision agriculture},
journal = {Journal of Network and Computer Applications},
volume = {148},
pages = {102461},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.102461},
url = {https://www.sciencedirect.com/science/article/pii/S1084804519303212},
author = {Anandarup Mukherjee and Sudip Misra and Narendra Singh Raghuwanshi},
keywords = {Unmanned aerial vehicles, UAV sensors, UAV classification, UAV architectures, Precision agriculture, Crop-stress, Vegetation index},
abstract = {We attribute the gain in popularity of Unmanned Aerial Vehicles (UAV), Platforms and Systems (UAS) to its ease of operation, versatility, and risk-free piloting. The primary UAV application domain has expanded from recreational and military flights to include scientific surveys and agriculture. The popularity of UAVs in scientific data gathering and applications, especially the use of small multi-rotor UAVs is quite widespread. These portable multi-rotor UAVs are portable, low-cost, highly maneuverable, and easy to handle. These features make such UAVs attractive to scientists and researchers worldwide. There has been a sudden spurt of UAV use in niche domains such as agriculture. Agriculturalists are choosing UAV-based field operations and remote sensing over the time-tested satellite-based ones, especially for local-scale and high spatiotemporal resolution imagery. In this survey, we explore various UAV application areas, types, sensors, research domains, and deployment architectures. We provide comparisons between various UAV types, sensing technologies (UAV, WSN, satellites), UAV architectures, and their utility in precision agriculture. Finally, we outline the challenges and the future scope of such UAV-based solutions for precision agriculture.}
}
@article{GORRIZ2020237,
title = {Artificial intelligence within the interplay between natural and artificial computation: Advances in data science, trends and applications},
journal = {Neurocomputing},
volume = {410},
pages = {237-270},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.05.078},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220309292},
author = {Juan M. Górriz and Javier Ramírez and Andrés Ortíz and Francisco J. Martínez-Murcia and Fermin Segovia and John Suckling and Matthew Leming and Yu-Dong Zhang and Jose Ramón Álvarez-Sánchez and Guido Bologna and Paula Bonomini and Fernando E. Casado and David Charte and Francisco Charte and Ricardo Contreras and Alfredo Cuesta-Infante and Richard J. Duro and Antonio Fernández-Caballero and Eduardo Fernández-Jover and Pedro Gómez-Vilda and Manuel Graña and Francisco Herrera and Roberto Iglesias and Anna Lekova and Javier {de Lope} and Ezequiel López-Rubio and Rafael Martínez-Tomás and Miguel A. Molina-Cabello and Antonio S. Montemayor and Paulo Novais and Daniel Palacios-Alonso and Juan J. Pantrigo and Bryson R. Payne and Félix {de la Paz López} and María Angélica Pinninghoff and Mariano Rincón and José Santos and Karl Thurnhofer-Hemsi and Athanasios Tsanas and Ramiro Varela and Jose M. Ferrández},
keywords = {Artificial intelligence (AI), Machine learning, Deep learning, Reinforcement learning, Evolutionary computation, Ontologies, Artificial neural networks (ANNs), Big data, Robotics, Neuroscience, Human–machine interaction, Virtual reality, Emotion recognition, Computational neuroethology, Autism, Dyslexia, Alzheimer, Parkinson, Glaucoma, AI for social well-being},
abstract = {Artificial intelligence and all its supporting tools, e.g. machine and deep learning in computational intelligence-based systems, are rebuilding our society (economy, education, life-style, etc.) and promising a new era for the social welfare state. In this paper we summarize recent advances in data science and artificial intelligence within the interplay between natural and artificial computation. A review of recent works published in the latter field and the state the art are summarized in a comprehensive and self-contained way to provide a baseline framework for the international community in artificial intelligence. Moreover, this paper aims to provide a complete analysis and some relevant discussions of the current trends and insights within several theoretical and application fields covered in the essay, from theoretical models in artificial intelligence and machine learning to the most prospective applications in robotics, neuroscience, brain computer interfaces, medicine and society, in general.}
}
@article{SALDANAOCHOA201953,
title = {A framework for the management of agricultural resources with automated aerial imagery detection},
journal = {Computers and Electronics in Agriculture},
volume = {162},
pages = {53-69},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.03.028},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918315096},
author = {Karla {Saldana Ochoa} and Zifeng Guo},
keywords = {Trees detection, Street segmentation, Agriculture, Machine learning, CNN, UAV},
abstract = {The acquisition of data through remote sensing represents a significant advantage in agriculture, as it allows researchers to perform faster and cheaper inspections over large areas. Currently, extensive researches have been done on technical solutions that can benefit simultaneously from both: vast amounts of raw data (big data) extracted from satellite images and Unmanned Aerial Vehicle (UAV) and novel algorithms in Machine Learning for image processing. In this experiment, we provide an approach that fulfills the necessities of rapid food security, assessment, planning, exploitation, and management of agricultural resources by introducing a pipeline for the automatic localization and classification of four types of fruit trees (coconut, banana, mango, and papaya) and the segmentation of roads in the Kingdom of Tonga, using high-resolution aerial imagery (0.04 m). We used two supervised deep convolutional neural network (CNN): the first, to localize and classify trees (localization) and the second, to mask the streets from the aerial imagery for transportation purposes (semantic segmentation). Additionally, we propose auxiliary methods to determine the density of groupings of each of these trees species, based on the detection results from the localization task and render it in Density Maps that allow comprehending the condition of the agriculture site quickly. Ultimately, we introduce a method to optimize the harvesting of fruits, based on specific sceneries, such as maximum time, path length, and location of warehouses and security points.}
}
@article{SHAHINFAR2020101085,
title = {“How many images do I need?” Understanding how sample size per class affects deep learning model performance metrics for balanced designs in autonomous wildlife monitoring},
journal = {Ecological Informatics},
volume = {57},
pages = {101085},
year = {2020},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2020.101085},
url = {https://www.sciencedirect.com/science/article/pii/S1574954120300352},
author = {Saleh Shahinfar and Paul Meek and Greg Falzon},
keywords = {Camera traps, Deep learning, Ecological informatics, Generalised additive models, Learning curves, Predictive modelling, Wildlife},
abstract = {Deep learning (DL) algorithms are the state of the art in automated classification of wildlife camera trap images. The challenge is that the ecologist cannot know in advance how many images per species they need to collect for model training in order to achieve their desired classification accuracy. In fact there is limited empirical evidence in the context of camera trapping to demonstrate that increasing sample size will lead to improved accuracy. In this study we explore in depth the issues of deep learning model performance for progressively increasing per class (species) sample sizes. We also provide ecologists with an approximation formula to estimate how many images per animal species they need for certain accuracy level a priori. This will help ecologists for optimal allocation of resources, work and efficient study design. In order to investigate the effect of number of training images; seven training sets with 10, 20, 50, 150, 500, 1000 images per class were designed. Six deep learning architectures namely ResNet-18, ResNet-50, ResNet-152, DnsNet-121, DnsNet-161, and DnsNet-201 were trained and tested on a common exclusive testing set of 250 images per class. The whole experiment was repeated on three similar datasets from Australia, Africa and North America and the results were compared. Simple regression equations for use by practitioners to approximate model performance metrics are provided. Generalizes additive models (GAM) are shown to be effective in modelling DL performance metrics based on the number of training images per class, tuning scheme and dataset. Overall, our trained models classified images with 0.94 accuracy (ACC), 0.73 precision (PRC), 0.72 true positive rate (TPR), and 0.03 false positive rate (FPR). Variation in model performance metrics among datasets, species and deep learning architectures exist and are shown distinctively in the discussion section. The ordinary least squares regression models explained 57%, 54%, 52%, and 34% of expected variation of ACC, PRC, TPR, and FPR according to number of images available for training. Generalised additive models explained 77%, 69%, 70%, and 53% of deviance for ACC, PRC, TPR, and FPR respectively. Predictive models were developed linking number of training images per class, model, dataset to performance metrics. The ordinary least squares regression and Generalised additive models developed provides a practical toolbox to estimate model performance with respect to different numbers of training images.}
}
@article{ZAIDI202153,
title = {Internet of Flying Things (IoFT): A Survey},
journal = {Computer Communications},
volume = {165},
pages = {53-74},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.10.023},
url = {https://www.sciencedirect.com/science/article/pii/S014036642031971X},
author = {Sofiane Zaidi and Mohammed Atiquzzaman and Carlos T. Calafate},
keywords = {Internet of Flying Things, Unmanned Aerial Vehicle, Unmanned Artifact System, Internet of Things, Flying Ad-hoc NETwork},
abstract = {Unmanned Aerial Vehicles (UAVs) have recently received significant attention by the civilian and military community, mostly due to the fast growth of UAV technologies supported by wireless communications and networking. UAVs can be used to improve the efficiency and performance of the Internet of Things (IoT) in terms of connectivity, coverage, reliability, stability, etc. In particular, to support IoT applications in an efficient manner, UAVs should be organized as a Flying Ad-hoc NETwork (FANET). FANET is a subclass of Mobile Ad-hoc Network (MANET) where nodes are Unmanned Artifact Systems (UAS). However, the deployment of UAVs in IoT is limited by several constraints, such as limited resource capacity of UAVs and ground devices, signal collision and interference, intermittent availability of the IoT infrastructure, etc. In the Internet of Flying Things (IoFT) literature, there are no survey or study that exhaustively covers and discusses all key concepts and recent works on IoFT. In this paper a comprehensive survey on the IoFT is presented, covering the state of the art in flying things with a focus on IoFT. A taxonomy of related literature on IoFT is proposed, including a classification, description and comparative study of different work on IoFT. Furthermore, the paper presents IoFT applications, IoFT challenges and future perspectives. This survey aims to provide the basic concepts and a complete overview of the recent studies on IoFT for the scientific researchers.}
}
@article{YIN2021104326,
title = {Hybrid metaheuristic multi-layer reinforcement learning approach for two-level energy management strategy framework of multi-microgrid systems},
journal = {Engineering Applications of Artificial Intelligence},
volume = {104},
pages = {104326},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104326},
url = {https://www.sciencedirect.com/science/article/pii/S0952197621001743},
author = {Linfei Yin and Shengyuan Li},
keywords = {Energy management, Combined cooling, Heating and power multi-microgrid system, Weighted delayed deep deterministic policy gradient, Power adjustment network, Genetic algorithm},
abstract = {This study builds a two-level energy management strategy framework for decentralized autonomy of microgrids and optimal coordinated operation of a multi-microgrid system. To reduce the operational cost of a combined cooling, heating and power multi-microgrid system with uncertain information and to improve the accuracy of load demand prediction, a hybrid metaheuristic multi-layer reinforcement learning algorithm is proposed for the framework of a multi-microgrid system. The proposed method is composed of a weighted delayed deep deterministic policy gradient algorithm, power adjustment network, and a genetic algorithm. At the first level, the microgrid operators utilize weighted delayed deep deterministic policy gradient algorithm with power adjustment network to optimize their operational strategies; at the second level, the distribution system operator employs a genetic algorithm to adjust its operational decision-making for minimizing the operational cost of the multi-microgrid system, reducing the peak-to-average ratios and power fluctuations at the points of common coupling. The data privacy of the parties in the multi-microgrid system is protected as each entity in the system does not have direct access to other entities’ information during the decision-making process. Numerical simulation results show that the proposed weighted delayed deep deterministic policy gradient algorithm with power adjustment network can rapidly obtain high-quality deterministic approximate optimal solution for economic dispatch of the microgrid. The framework proposed in this study achieves decentralized autonomy of microgrids, reduces the operational cost of the multi-microgrid system with incomplete or uncertain information, and indirectly improves the accuracy of load demands prediction at the points of common coupling.}
}
@article{XI2021106506,
title = {Evaluation of dimensionality reduction methods for individual tree crown delineation using instance segmentation network and UAV multispectral imagery in urban forest},
journal = {Computers and Electronics in Agriculture},
volume = {191},
pages = {106506},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106506},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921005238},
author = {Xiangshu Xi and Kai Xia and Yinhui Yang and Xiaochen Du and Hailin Feng},
keywords = {Dimensionality reduction, Individual tree crown delineation, Instance segmentation, Multispectral imagery},
abstract = {The diversity of features in urban forest poses challenges to the task of delineation individual tree crowns. Multispectral image helps to improve the accuracy of individual tree crown delineation. It is necessary to reduce the dimensionality of multispectral images, but which dimensionality reduction method is suitable for the individual tree crown task based on deep learning still needs further research. In this study, four dimensionality reduction methods (principal component analysis, independent component analysis, optimum index factor, standard false color composite) were used to reduce the dimensionality of multispectral images. The images after dimensionality reduction were made as dataset for network training. Two instance segmentation networks (BlendMask, Mask R-CNN) were used to delineate the ginkgo tree crowns of UAV multispectral images after dimensionality reduction in urban. The effect of dimensionality reduction methods on two networks was evaluated in detail. The result of experiments presented that the standard false color composite method obtained the best value with 60.0% in average precision, 95.3% in average precision (Intersection over Union = 0.5) and 70.8% in average recall. The feature extraction methods (principal component analysis, independent component analysis) showed a good performance in the simple plot, but failed in the dense plot. The band selection methods (optimum index factor, standard false color composite) were more stable than the feature extraction methods in both plots. This article provides an important reference for related researchers on the choice of dimensionality reduction methods.}
}
@article{SLIUSAR20221,
title = {Drone technology in municipal solid waste management and landfilling: A comprehensive review},
journal = {Waste Management},
volume = {139},
pages = {1-16},
year = {2022},
issn = {0956-053X},
doi = {https://doi.org/10.1016/j.wasman.2021.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0956053X21006516},
author = {Natalia Sliusar and Timofey Filkin and Marion Huber-Humer and Marco Ritzkowski},
keywords = {Aerial photo imagery, Unmanned aerial vehicles, Landfill, Dumps, Waste disposal sites},
abstract = {The paper discusses the experience of using unmanned aerial vehicles (UAV) in the management of municipal solid waste landfills and dumpsites. Although the use of drones at waste disposal sites (WDS) has a more than ten-year history, the active application of these technologies has increased in the last 3–4 years. The paper analyzes scientific publications of 2010–2021 (July) and identifies the main WDS management task groups for which the solution of UAV can be used. It illustrates that most of the research is devoted to studying spatial and volumetric characteristics of landfills, which is connected with the practical needs. About a quarter of the publications focus on monitoring the emissions of landfill gas or its individual components, mainly methane. Issues of a comprehensive assessment of the technological and environmental safety of landfills and dumps are covered in the scientific literature fragmentarily and insufficiently. At the same time, the current level of technologies for collecting and processing remote sensing air data (UAV, sensors for aerial imagery, software for photogrammetric processing of aerial imagery data, geographic information systems (GIS)) makes it possible to identify and assess many environmental effects of landfills and dumps and to monitor compliance with the standards for the landfills operation, which could bring management of these facilities to a fundamentally different level. Promising areas of further research in the field of UAV application at WDS are indicated: development of processes for automatic interpretation of aerial imagery materials; product analysis of photogrammetric data processing in a GIS environment, etc.}
}
@article{ZHOU2021199,
title = {A newly bio-inspired path planning algorithm for autonomous obstacle avoidance of UAV},
journal = {Chinese Journal of Aeronautics},
volume = {34},
number = {9},
pages = {199-209},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.12.018},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120305719},
author = {Yaoming ZHOU and Yu SU and Anhuan XIE and Lingyu KONG},
keywords = {Obstacle avoidance, Path planning, Plant growth, ROS, UAV},
abstract = {In this paper, a bio-inspired path planning algorithm in 3D space is proposed. The algorithm imitates the basic mechanisms of plant growth, including phototropism, negative geotropism and branching. The algorithm proposed in this paper solves the dynamic obstacle avoidance path planning problem of Unmanned Aerial Vehicle (UAV) in the case of unknown environment maps. Compared with other path planning algorithms, the algorithm has the advantages of fast path planning speed and fewer route points, and can achieve the effect of low delay real-time path planning. The feasibility of the algorithm is verified in the Gazebo simulator based on the Robot Operating System (ROS) platform. Finally, an actual UAV autonomous obstacle avoidance path planning experimental platform is built, and a UAV obstacle avoidance path planning flight test is carried out based on this actual environment.}
}
@article{TAN2022107264,
title = {Anti-saturation adaptive fault-tolerant control with fixed-time prescribed performance for UAV under AOA asymmetric constraint},
journal = {Aerospace Science and Technology},
volume = {120},
pages = {107264},
year = {2022},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107264},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821007744},
author = {Jian Tan and Yanfei Dong and Pengyuan Shao and Gaomin Qu},
keywords = {Prescribed performance, Fixed-time control, Actuator faults, Control input saturation, AOA asymmetric constraint},
abstract = {This paper presents an anti-saturation adaptive fault-tolerant control scheme with fixed-time prescribed performance for the longitudinal model of fixed wing UAV under actuator faults, control input saturation, angle of attack (AOA) asymmetric constraint and uncertainties. First, by introducing equivalent error transformation technique, the error transformed models of the altitude and airspeed tracking subsystems are strictly constructed. Second, asymmetric saturation function, auxiliary system and barrier Lyapunov function (BLF) are incorporated to guarantee AOA maintain in the asymmetric constraint. Then, neural network approximation structures are combined with adaptive robust terms to handle the lumped disturbances. Furthermore, Nussbaum-type gain technique is adopted to deal with the unknown time-varying parameter arising from input saturation and actuator faults. According to the stability analysis, the altitude and airspeed tracking errors evolve strictly inside the fixed-time performance envelops, while the AOA remains in asymmetric constraint and all signals in closed-loop system are uniformly ultimately bounded. Finally, numerical simulation is presented to verify the effectiveness and superiority of proposed control scheme.}
}
@article{SONG202219,
title = {Monitoring leaf phenology in moist tropical forests by applying a superpixel-based deep learning method to time-series images of tree canopies},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {183},
pages = {19-33},
year = {2022},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.10.023},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621002914},
author = {Guangqin Song and Shengbiao Wu and Calvin K.F. Lee and Shawn P. Serbin and Brett T. Wolfe and Michael K. Ng and Kim S. Ely and Marc Bogonovich and Jing Wang and Ziyu Lin and Scott Saleska and Bruce W. Nelson and Alistair Rogers and Jin Wu},
keywords = {Residual Networks, Semantic segmentation, Proximate remote sensing, Leaf quantity, Leaf quality, Green Chromatic Coordinate, Tropical forests, Phenocam},
abstract = {Tropical leaf phenology—particularly its variability at the tree-crown scale—dominates the seasonality of carbon and water fluxes. However, given enormous species diversity, accurate means of monitoring leaf phenology in tropical forests is still lacking. Time series of the Green Chromatic Coordinate (GCC) metric derived from tower-based red–greenblue (RGB) phenocams have been widely used to monitor leaf phenology in temperate forests, but its application in the tropics remains problematic. To improve monitoring of tropical phenology, we explored the use of a deep learning model (i.e. superpixel-based Residual Networks 50, SP-ResNet50) to automatically differentiate leaves from non-leaves in phenocam images and to derive leaf fraction at the tree-crown scale. To evaluate our model, we used a year of data from six phenocams in two contrasting forests in Panama. We first built a comprehensive library of leaf and non-leaf pixels across various acquisition times, exposure conditions and specific phenocams. We then divided this library into training and testing components. We evaluated the model at three levels: 1) superpixel level with a testing set, 2) crown level by comparing the model-derived leaf fractions with those derived using image-specific supervised classification, and 3) temporally using all daily images to assess the diurnal stability of the model-derived leaf fraction. Finally, we compared the model-derived leaf fraction phenology with leaf phenology derived from GCC. Our results show that: 1) the SP-ResNet50 model accurately differentiates leaves from non-leaves (overall accuracy of 93%) and is robust across all three levels of evaluations; 2) the model accurately quantifies leaf fraction phenology across tree-crowns and forest ecosystems; and 3) the combined use of leaf fraction and GCC helps infer the timing of leaf emergence, maturation and senescence, critical information for modeling photosynthetic seasonality of tropical forests. Collectively, this study offers an improved means for automated tropical phenology monitoring using phenocams.}
}
@article{LI2013230,
title = {A Software Scheme for UAV's Safe Landing Area Discovery},
journal = {AASRI Procedia},
volume = {4},
pages = {230-235},
year = {2013},
note = {2013 AASRI Conference on Intelligent Systems and Control},
issn = {2212-6716},
doi = {https://doi.org/10.1016/j.aasri.2013.10.035},
url = {https://www.sciencedirect.com/science/article/pii/S221267161300036X},
author = {Xiaoming Li},
keywords = {UAV, landing area discovery, machine learning, computer vision},
abstract = {This paper proposes a software processing scheme for small-sized UAV in its landing area discovery using its single onboard camera and machine learning algorithms. The two-stage processing procedure was proposed. In first stage a similarity based textured area identification method was adopted to find the possible landing areas. Afterwards, in second stage, these results were refined and evaluated by using some machine learning algorithms. The UAV can then take use of these results as its emergency landing target options. The software scheme we designed implemented the whole process but still allow the developers to embed their own algorithms to make better results. Our preliminary research has disclosed that this software and application are useful and can provide great convenience and efficiency.}
}
@article{SRINIVASAN2021598,
title = {Fast Multi-Robot Motion Planning via Imitation Learning of Mixed-Integer Programs},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {20},
pages = {598-604},
year = {2021},
note = {Modeling, Estimation and Control Conference MECC 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.11.237},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321022813},
author = {Mohit Srinivasan and Ankush Chakrabarty and Rien Quirynen and Nobuyuki Yoshikawa and Toshisada Mariyama and Stefano Di Cairano},
keywords = {Machine Learning, Path Planning, Motion Control, Optimal Control},
abstract = {We propose a centralized multi-robot motion planning approach that leverages machine learning and mixed-integer programming (MIP). We train a neural network to imitate optimal MIP solutions and, during execution, the trajectories predicted by the network are used to fix most of the integer variables, resulting in a significantly reduced MIP or even a convex program. If the obtained trajectories are feasible, i.e., collision-free and reaching the goal, they can be used as they are or further refined towards optimality. Since maximizing the likelihood of feasibility is not the standard goal of imitation learning, we propose several techniques aimed at increasing such likelihood. Simulation results show the reduced computational burden associated with the proposed framework and the similarity with the optimal MIP solutions.}
}
@article{ZHOU2020101170,
title = {Intuitive robot teleoperation for civil engineering operations with virtual reality and deep learning scene reconstruction},
journal = {Advanced Engineering Informatics},
volume = {46},
pages = {101170},
year = {2020},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2020.101170},
url = {https://www.sciencedirect.com/science/article/pii/S1474034620301415},
author = {Tianyu Zhou and Qi Zhu and Jing Du},
keywords = {Robot, Teleoperation, Virtual reality, Scene reconstruction, Deep learning},
abstract = {Robotic teleoperation, i.e., manipulating remote robotic systems at a distance, has gained its popularity in various industrial applications, including construction operations. The key to a successful teleoperation robot system is the delicate design of the human-robot interface that helps strengthen the human operator’s situational awareness. Traditional human-robot interface for robotic teleoperation is usually based on imagery data (e.g., video streaming), causing the limited field of view (FOV) and increased cognitive burden for processing additional spatial information. As a result, 3D scene reconstruction methods based on point cloud models captured by scanning technologies (e.g., depth camera and LiDAR) have been explored to provide immersive and intuitive feedback to the human operator. Despite the added benefits of applying reconstructed 3D scenes in telerobotic systems, challenges still present. Most 3D reconstruction methods utilize raw point cloud data due to the difficulty of real-time model rendering. The significant size of point cloud data makes the processing and transfer between robots and human operators difficult and slow. In addition, most reconstructed point cloud models do not contain physical properties such as weight and colliders. A more enriched control mechanism based on physics engine simulations is impossible. This paper presents an intelligent robot teleoperation interface that collects, processes, transfers, and reconstructs the immersive scene model of the workspace in Virtual Reality (VR) and enables intuitive robot controls accordingly. The proposed system, Telerobotic Operation based on Auto-reconstructed Remote Scene (TOARS), utilizes a deep learning algorithm to automatically detect objects in the captured scene, along with their physical properties, based on the point cloud data. The processed information is then transferred to the game engine where rendered virtual objects replace the original point cloud models in the VR environment. TOARS is expected to significantly improve the efficiency of 3D scene reconstruction and situational awareness of human operators in robotic teleoperation.}
}
@article{HUANG2020107333,
title = {A hybrid machine-learning model to estimate potential debris-flow volumes},
journal = {Geomorphology},
volume = {367},
pages = {107333},
year = {2020},
issn = {0169-555X},
doi = {https://doi.org/10.1016/j.geomorph.2020.107333},
url = {https://www.sciencedirect.com/science/article/pii/S0169555X20303068},
author = {Jian Huang and Tristram C. Hales and Runqiu Huang and Nengpan Ju and Qiao Li and Yin Huang},
keywords = {Debris flow, Machine-learning model, Estimated volume, Prediction},
abstract = {Empirical-statistical models of debris-flow are challenging to implement in environments where sedimentary and hydrologic triggering processes change through time, such as after a large earthquake. The flexible and adaptive statistical methods provided by machine learning algorithms may improve the quality of debris flow predictions where triggering conditions and the nature of sediment that can bulk flows varies with time. We developed a hybrid machine-learning model of future debris-flow volumes using a dataset of measured debris-flow volumes from 60 catchments that generated post-Wenchuan Earthquake (Mw 7.9) debris flows. We input topographic variables (catchment area, topographic relief, channel length, distance from seismic fault, and average channel gradient) and the total volume of co-seismic landslide debris into the PSO-ELM_AdaBoost machine-learning model, created by combining Extreme learning machine (ELM), particle swarm optimization (PSO) and adaptive boosting machine learning algorithm (AdaBoost). The model was trained and tested using post-2008 Mw 7.9 Wenchuan Earthquake debris flows, then applied to understand potential volumes of post-earthquake debris flows associated with other regional earthquakes (2013 Mw 6.6 Lushan Earthquake, 2010 Mw 6.9 Yushu Earthquake). We compared the PSO-ELM_Adaboost method with different machine learning methods, including back-propagation neural network (BPNN), support vector machine (SVM), ELM, PSO-ELM. The Comparative analysis demonstrated that the PSO-ELM_Adaboost method has a higher statistical validity and prediction accuracy with a mean absolute percentage error (MAPE) less than 0.10. The prediction accuracy of debris-flow volumes trigged by other earthquakes decreases to 0.11–0.16 (absolute percentage error), suggesting that once calibrated for a region this method can be applied to other regional earthquakes. This model may be useful for engineering design to mitigate the risk of large post-earthquake debris flows.}
}
@article{YU202142,
title = {An integrated rice panicle phenotyping method based on X-ray and RGB scanning and deep learning},
journal = {The Crop Journal},
volume = {9},
number = {1},
pages = {42-56},
year = {2021},
issn = {2214-5141},
doi = {https://doi.org/10.1016/j.cj.2020.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S2214514120301094},
author = {Lejun Yu and Jiawei Shi and Chenglong Huang and Lingfeng Duan and Di Wu and Debao Fu and Changyin Wu and Lizhong Xiong and Wanneng Yang and Qian Liu},
keywords = {Rice (), Panicle traits, RGB imaging, X-ray scanning, Faster R-CNN},
abstract = {Rice panicle phenotyping is required in rice breeding for high yield and grain quality. To fully evaluate spikelet and kernel traits without threshing and hulling, using X-ray and RGB scanning, we developed an integrated rice panicle phenotyping system and a corresponding image analysis pipeline. We compared five methods of counting spikelets and found that Faster R-CNN achieved high accuracy (R2 of 0.99) and speed. Faster R-CNN was also applied to indica and japonica classification and achieved 91% accuracy. The proposed integrated panicle phenotyping method offers benefit for rice functional genetics and breeding.}
}
@article{GAN20202501,
title = {Reinforcement Learning Based Anti-Jamming Schedule in Cyber-Physical Systems},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {2501-2506},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.221},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320304924},
author = {Ruimeng Gan and Yue Xiao and Jinliang Shao and Heng Zhang and Wei {Xing Zheng}},
keywords = {Cyber-physical systems (CPSs), reinforcement learning, cognitive radio, softmax method},
abstract = {In this paper, the security issue of cyber-physical systems is investigated, where the observation data is transmitted from a sensor to an estimator through wireless channels disturbed by an attacker. The failure of this data transmission occurs, when the sensor accesses the channel that happens to be attacked by the jammer. Since the system performance measured by the estimation error depends on whether the data transmission is a success, the problem of selecting the channel to alleviate the attack effect is studied. Moreover, the state of each channel is time-variant due to various factors, such as path loss and shadowing. Motivated by energy conservation, the problem of selecting the channel with the best state is also considered. With the help of cognitive radio technique, the sensor has the ability of selecting a sequence of channels dynamically. Based on this, the problem of selecting the channel is resolved by means of reinforcement learning to jointly avoid the attack and enjoy the channel with the best state. A corresponding algorithm is presented to obtain the sequence of channels for the sensor, and its effectiveness is proved analytically. Numerical simulations further verify the derived results.}
}
@article{LI2019174,
title = {Multi-LUTs method for canopy nitrogen density estimation in winter wheat by field and UAV hyperspectral},
journal = {Computers and Electronics in Agriculture},
volume = {162},
pages = {174-182},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918309402},
author = {Zhenhai Li and Zhenhong Li and David Fairbairn and Na Li and Bo Xu and Haikuan Feng and Guijun Yang},
keywords = {Canopy nitrogen density, Look up table, Unmanned aerial vehicle platforms, Hyperspectral image, Winter wheat},
abstract = {Unmanned aerial vehicle (UAV) based hyperspectral images linked to a radiative transfer model can provide a promising approach for high throughput monitoring of plant nitrogen (N) status. In this study, multiple lookup tables (Multi-LUTs), each LUT corresponding to one growth stage, were constructed based on the N-PROSAIL model, a radiative transfer model, and LUT size was optimized for improving computing efficiency. The objective is to use the constructed Multi-LUTs for estimating canopy N density (CND) in winter wheat. Results suggest that Multi-LUTs of leaf area index, leaf N density and two spectral indices (MSR and MCARI/MTVI2) in winter wheat demonstrate good performance of CND estimation; and LUTs with the optimal size of 6000 rows can yield good accuracy. The R2 and nRMSE values of the regression relationship between estimated and measured CND were 0.83 and 0.23 from field hyperspectral data, and 0.69 and 0.27 from UAV based hyperspectral imagery during the 2014–2015 growing season. CND by Multi-LUTs method was also accurately estimated from field hyperspectral data during the 2013–2014 growing season, with R2 and nRMSE values of 0.74 and 0.26. The estimation accuracy of CND based UAV data was a slightly lower than based field data. The resultant thematic CND map accurately exhibits CND variability at varying spatial and temporal scales. Results from this study confirmed the potential of combining UAV based hyperspectral imagery and physical optics approach for estimating CND in winter wheat.}
}
@article{OZKAN2021108015,
title = {Optimization of the distance-constrained multi-based multi-UAV routing problem with simulated annealing and local search-based matheuristic to detect forest fires: The case of Turkey},
journal = {Applied Soft Computing},
volume = {113},
pages = {108015},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.108015},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621009376},
author = {Omer Ozkan},
keywords = {Forest monitoring, Forest fire, Fire detection, UAV routing, Matheuristic, Simulated annealing, Local search},
abstract = {Forests cover nearly a third of the Earth’s land area, and they are a key factor for all life on Earth, but unfortunately, forest fires are the greatest danger to their presence. The wildfires jeopardize general wellbeing, security, and require high levels of government resources. They also lead to noteworthy debasement of nature, property loss, and high rates of human death and injury. This paper proposes an algorithm to use and route unmanned aerial vehicles (UAVs) to mitigate forest fire risks. The developed matheuristic algorithm hybridizes simulated annealing and local search metaheuristics with an integer linear programming model. The mathematical model was developed to solve the distance-constrained multi-based multi-UAV routing problem, and because of the complexity of the problem, the generated metaheuristics helps the model to find better solutions. The effectiveness of the proposed matheuristic is tested with a real-life case study for Turkey and is also compared with a genetic algorithm. The Turkish State Meteorological Service generates forest fire-risk maps countrywide every day to predict fire risks 3 days later by using meteorological data. These maps are used to generate the risky regions to be visited by the UAVs, and the existing airports are considered for the UAVs to take off and land. The algorithm is coded using MATLAB and ILOG. The metaheuristics are designed with problem-based operators, and their parameters are tuned by experiments. Computational results demonstrate the effectiveness of the algorithm and the hybridization procedures. Results demonstrate that the CPU times for the methods are acceptable.}
}
@article{TRIANTAFYLLIDOU201865,
title = {Fast Deep Convolutional Face Detection in the Wild Exploiting Hard Sample Mining},
journal = {Big Data Research},
volume = {11},
pages = {65-76},
year = {2018},
note = {Selected papers from the 2nd INNS Conference on Big Data: Big Data & Neural Networks},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2017.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S2214579617300096},
author = {Danai Triantafyllidou and Paraskevi Nousi and Anastasios Tefas},
keywords = {Deep learning, Convolutional Neural Networks, Face detection},
abstract = {Face detection constitutes a key visual information analysis task in Machine Learning. The rise of Big Data has resulted in the accumulation of a massive volume of visual data which requires proper and fast analysis. Deep Learning methods are powerful approaches towards this task as training with large amounts of data exhibiting high variability has been shown to significantly enhance their effectiveness, but often requires expensive computations and leads to models of high complexity. When the objective is to analyze visual content in massive datasets, the complexity of the model becomes crucial to the success of the model. In this paper, a lightweight deep Convolutional Neural Network (CNN) is introduced for the purpose of face detection, designed with a view to minimize training and testing time, and outperforms previously published deep convolutional networks in this task, in terms of both effectiveness and efficiency. To train this lightweight deep network without compromising its efficiency, a new training method of progressive positive and hard negative sample mining is introduced and shown to drastically improve training speed and accuracy. Additionally, a separate deep network was trained to detect individual facial features and a model that combines the outputs of the two networks was created and evaluated. Both methods are capable of detecting faces under severe occlusion and unconstrained pose variation and meet the difficulties of large scale real-world, real-time face detection, and are suitable for deployment even in mobile environments such as Unmanned Aerial Vehicles (UAVs).}
}
@article{NEMER2020215,
title = {A game theoretic approach of deployment a multiple UAVs for optimal coverage},
journal = {Transportation Research Part A: Policy and Practice},
volume = {140},
pages = {215-230},
year = {2020},
issn = {0965-8564},
doi = {https://doi.org/10.1016/j.tra.2020.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0965856420306881},
author = {Ibrahim A. Nemer and Tarek R. Sheltami and Ashraf S. Mahmoud},
keywords = {UAV networks, Intelligent transport systems, Line of sight, Potential games, Nash equilibrium, Optimal coverage},
abstract = {In this paper, a game-theoretical autonomous decision-making approach for efficient deployment of unmanned aerial vehicles (UAVs) in a multi-level and multi-dimensional assisted network is analyzed. The UAVs have directional antennas that work as wireless stations, which provide the best coverage for multiple ground mobile/fixed users. In general, UAVs work in a cooperative manner for achieving the suitable deployment with the optimal coverage values for the candidate region. In this paper, a game theory concept is used and the payoff function for each UAV is defined based on the coverage probability value, which depends on the altitude and the characteristic of antennas in the UAVs. We introduce a mathematical formulation for evaluating the payoff values based on a set of actions for each UAV, and the Nash equilibrium for this kind of game. This approach works in an intelligent way based on the interactions between the UAVs and their neighbors in a connected network and it might work even in harsh environments. In order to minimize interference, the UAVs’ altitudes are adjusted based on the antennas and other deployment requirements (i.e. search and surveillance purposes) by using the minimum number of UAVs to cover the candidate geographical region. The simulation results show that the proposed approach achieves the maximum coverage value, converges fast with the environmental changes based on the power levels, and robust for failure scenarios. Finally, we compare our approach against one of the traditional approaches called Collaborative Visual Area Coverage Approach (CVACA) based on uniform coverage quality. The simulation results show that the game approach outperforms the traditional approach in term of the coverage value and the computational time.}
}
@article{HAMMAM2020331,
title = {Real-time multiple spatiotemporal action localization and prediction approach using deep learning},
journal = {Neural Networks},
volume = {128},
pages = {331-344},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301878},
author = {Ahmed Ali Hammam and Mona M. Soliman and Aboul Ella Hassanien},
keywords = {Deep learning, Action localization, Action prediction, Spatiotemporal, YOLO network, Optical flow},
abstract = {Detecting the locations of multiple actions in videos and classifying them in real-time are challenging problems termed ”action localization and prediction” problem. Convolutional neural networks (ConvNets) have achieved great success for action localization and prediction in still images. A major advance occurred when the AlexNet architecture was introduced in the ImageNet competition. ConvNets have since achieved state-of-the-art performances across a wide variety of machine vision tasks, including object detection, image segmentation, image classification, facial recognition, human pose estimation, and tracking. However, few works exist that address action localization and prediction in videos. The current action localization research primarily focuses on the classification of temporally trimmed videos in which only one action occurs per frame. Moreover, nearly all the current approaches work only offline and are too slow to be useful in real-world environments. In this work, we propose a fast and accurate deep-learning approach to perform real-time action localization and prediction. The proposed approach uses convolutional neural networks to localize multiple actions and predict their classes in real time. This approach starts by using appearance and motion detection networks (known as ”you only look once” (YOLO) networks) to localize and classify actions from RGB frames and optical flow frames using a two-stream model. We then propose a fusion step that increases the localization accuracy of the proposed approach. Moreover, we generate an action tube based on frame level detection. The frame by frame processing introduces an early action detection and prediction with top performance in terms of detection speed and precision. The experimental results demonstrate this superiority of our proposed approach in terms of both processing time and accuracy compared to recent offline and online action localization and prediction approaches on the challenging UCF-101-24 and J-HMDB-21 benchmarks.}
}
@article{RAMIREZATENCIA2020113708,
title = {A revision on multi-criteria decision making methods for multi-UAV mission planning support},
journal = {Expert Systems with Applications},
volume = {160},
pages = {113708},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113708},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420305327},
author = {Cristian Ramirez-Atencia and Victor Rodriguez-Fernandez and David Camacho},
keywords = {Unmanned aerial vehicles, Mission planning, Multi-criteria decision making, Fuzzy methods},
abstract = {Over the last decade, Unmanned Aerial Vehicles (UAVs) have been extensively used in many commercial applications due to their manageability and risk avoidance. One of the main problems considered is the mission planning for multiple UAVs, where a solution plan must be found satisfying the different constraints of the problem. This problem has multiple variables that must be optimized simultaneously, such as the makespan, the cost of the mission or the risk. Therefore, the problem has a lot of possible optimal solutions, and the operator must select the final solution to be executed among them. In order to reduce the workload of the operator in this decision process, a Decision Support System (DSS) becomes necessary. In this work, a DSS consisting of ranking and filtering systems, which order and reduce the optimal solutions, has been designed. With regard to the ranking system, a wide range of Multi-Criteria Decision Making (MCDM) methods, including some fuzzy MCDM, are compared on a multi-UAV mission planning scenario, in order to study which method could fit better in a multi-UAV decision support system. Expert operators have evaluated the solutions returned, and the results show, on the one hand, that fuzzy methods generally achieve better average scores, and on the other, that all of the tested methods perform better when the preferences of the operators are biased towards a specific variable, and worse when their preferences are balanced. For the filtering system, a similarity function based on the proximity of the solutions has been designed, and on top of that, a threshold is tuned empirically to decide how to filter solutions without losing much of the hypervolume of the space of solutions.}
}
@article{COOPER2019179,
title = {Object-based correction of LiDAR DEMs using RTK-GPS data and machine learning modeling in the coastal Everglades},
journal = {Environmental Modelling & Software},
volume = {112},
pages = {179-191},
year = {2019},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2018.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1364815218306406},
author = {Hannah M. Cooper and Caiyun Zhang and Stephen E. Davis and Tiffany G. Troxler},
keywords = {LiDAR, Object-based image analysis, Machine learning, Monte Carlo, DEMs, Coastal wetlands},
abstract = {Light Detection and Ranging (LiDAR) Digital Elevation Models (DEMs) are frequently applied in modeling coastal environments. We present an object-based correction approach for accurate and precise DEMs by integrating LiDAR point data, aerial imagery, and Real Time Kinematic-Global Positioning Systems. Four machine learning techniques (Random Forest, Support Vector Machine, k-Nearest Neighbor, and Artificial Neural Network) were compared with the commonly used bias-correction method. The Random Forest object-based model produced best predictions for two study areas: Nine Mile (Mean Bias Error (MBE) reduced 0.18 to −0.02 m, Root Mean Square Error (RMSE) reduced 0.22 to 0.08 m) and Flamingo (MBE reduced 0.17 to 0.02 m, RMSE reduced 0.24 to 0.10 m). A Monte Carlo model was developed to combine errors into the object-based machine learning corrected DEMs, and uncertainty maps spatially revealed the likelihood of error. The object-based correction approach provides an attractive alternative to the bias-correction method.}
}
@article{YU2019227,
title = {UAV-aided localization algorithm with relay for train-mounted mobile terminals},
journal = {Physical Communication},
volume = {34},
pages = {227-234},
year = {2019},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2019.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S1874490718305913},
author = {Tianyi Yu and Junhui Zhao and Yi Gong},
keywords = {Complex environment, UAV-aided, Coordinates divided, Velocity difference, Step-by-step positioning},
abstract = {In some complex environment, the train and the base station (BS) cannot connect directly. And the train-mounted mobile terminals cannot receive global positioning system (GPS) signals because of the shadow of the train shells. To address this issue, an unmanned aerial vehicle (UAV) aided localization algorithm with relay is proposed in this paper, which consists of four steps: coordinates dividing, step-by-step positioning, coupling and results comparison. The proposed method transforms the complex in-train environment into a traditional indoor scene to avoid the influence of non-line-of-sight (NLOS). It locates the absolute position of the train in a wireless sensor network (WSN) unit composed of nodes installed on UAVs. In addition, aiming at reducing the distance-measuring errors caused by velocity difference between the train and the UAV, an error compensation factor is carried out in received signal strength indicator (RSSI). Based on the simulation results, we find that the proposed method is more accurate working in confined space where GPS signals cannot be captured. Compared with traditional methods, it can also correct the velocity difference errors. The positioning system achieves a mean positioning accuracy of 2.13m.}
}
@article{ROTTONDI2021107644,
title = {Scheduling of emergency tasks for multiservice UAVs in post-disaster scenarios},
journal = {Computer Networks},
volume = {184},
pages = {107644},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107644},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620312639},
author = {Cristina Rottondi and Francesco Malandrino and Andrea Bianco and Carla Fabiana Chiasserini and Ioannis Stavrakakis},
keywords = {Unmanned Aerial Vehicles, Post-emergency monitoring, Fleet area coverage, Parcel delivery},
abstract = {Single-task UAVs are increasingly being employed to carry out surveillance, parcel delivery, communication support, and other specific tasks. When the geographical area of operation of single-task missions is common, e.g., in post-disaster recovery scenarios, it is more efficient to have multiple tasks carried out as part of a single UAV mission. In these scenarios, the UAVs’ equipment and mission plan must be carefully selected to minimize the carried load and overall resource consumption. In this paper, we investigate the joint planning of multitask missions leveraging a fleet of UAVs equipped with a standard set of accessories enabling heterogeneous tasks. To this end, an optimization problem is formulated yielding the optimal joint planning and deriving the resulting quality of the delivered tasks. In addition, two heuristic solutions are developed for large-scale environments to cope with the increased complexity of the optimization framework. The joint planning is applied to a specific scenario of a flood in the San Francisco area. Results show the effectiveness of the proposed heuristic solutions, which provide good performance and allow for drastic savings in the computational time required to plan the UAVs’ trajectories with respect to the optimal approach, thus enabling prompt reaction to the emergency events.}
}
@article{RUSYADIRAMLI2021100088,
title = {Hybrid MAC Protocol for UAV-Assisted Data Gathering in a Wireless Sensor Network},
journal = {Internet of Things},
volume = {14},
pages = {100088},
year = {2021},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2019.100088},
url = {https://www.sciencedirect.com/science/article/pii/S2542660519301106},
author = {Muhammad {Rusyadi Ramli} and Jae-Min Lee and Dong-Seong Kim},
keywords = {Hybrid, MAC protcol, UAV, Wireless sensor networks, Data gathering},
abstract = {A wireless sensor network (WSN) that deploys an unmanned aerial vehicle (UAV) for the data gathering process differs from the common WSN system. In a UAV-WSN, the sensor nodes have a limited time to communicate with the UAV. Thus, the sensor nodes have to contend with each other to transmit their data to the UAV within a short amount of time. The fairness among the contended nodes is degraded, which affects the network performance in terms of throughput and packet delivery ratio (PDR). To overcome this issue, an effective protocol that can maintain or increase fairness among nodes is needed. This paper proposes a novel protocol named HP-MAC which is a hybrid medium access control (MAC) protocol for data gathering in a UAV-WSN. This proposed scheme works by setting the UAV to periodically send a beacon frame to sensor nodes in order to inform its presence, then each sensor node that receives the beacon frame contends to send a registration frame to the UAV. A second beacon frame then transmitted by the UAV to the registered nodes regarding their transmission schedule. HP-MAC uses CSMA/CA during the registration process of the sensor nodes and allocates the registered sensor nodes time slots in the data gathering process. The time-slot scheme is used to determine the transmission schedule of each sensor based on their priority during the registration process. The results show that the proposed MAC protocol achieved fairness while enhancing network performance in terms of PDR and throughput.}
}
@article{GUO2021122,
title = {Damage identification of wind turbine blades with deep convolutional neural networks},
journal = {Renewable Energy},
volume = {174},
pages = {122-133},
year = {2021},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2021.04.040},
url = {https://www.sciencedirect.com/science/article/pii/S0960148121005589},
author = {Jihong Guo and Chao Liu and Jinfeng Cao and Dongxiang Jiang},
keywords = {Wind turbine blade, Defects detection, Deep learning, Haar-like features, Object detection},
abstract = {Online early detection of surface damages on blades is critical for the safety of wind turbines, which could avoid catastrophic failures, minimize downtime, and enhance the reliability of the system. Monitoring the health status of blades is attracting more and more attention including on-site cameras and mobile cameras by drones and crawling robots. To deploy fast and efficient damage detection methods from image data, this work presents a hierarchical identification framework for wind turbine blades, which consists of a Haar-AdaBoost step for region proposal and a convolutional neural network (CNN) classifier for damage detection and fault diagnosis. Case studies are carried out on real data set collected from an eastern China wind farm. Results show that (i) the proposed framework can detect and identify the blade damages and outperforms other schemes include SVM and VGG16 models, (ii) sensitive analysis is conducted to validate the robustness of proposed method under limited data conditions, (iii) the proposed scheme is faster than one-step CNN method that directly classifying raw data.}
}
@article{DENHOF20191166,
title = {Automatic Optical Surface Inspection of Wind Turbine Rotor Blades using Convolutional Neural Networks},
journal = {Procedia CIRP},
volume = {81},
pages = {1166-1170},
year = {2019},
note = {52nd CIRP Conference on Manufacturing Systems (CMS), Ljubljana, Slovenia, June 12-14, 2019},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2019.03.286},
url = {https://www.sciencedirect.com/science/article/pii/S2212827119305918},
author = {Dimitri Denhof and Benjamin Staar and Michael Lütjen and Michael Freitag},
keywords = {Convolutional neural network, Deep learning, Optical surface Inspection, Wind turbine rotor blade},
abstract = {The operation of wind turbines includes the regular surface inspection of their rotor blades. This leads to considerable downtimes and expenses due to the manual inspection process. A possible solution is the automation of this process by using drones or robots. In this article, we present a key component for such an approach by automating the visual surface inspection with convolutional neural networks (CNN). We provide insights into CNN model selection based on available hardware and training data. We further show that all CNN models reach over 96 % median classification accuracy with the best model, ResNet50, reaching 97.4 %.}
}
@article{SIERRA201870,
title = {Modelling engineering systems using analytical and neural techniques: Hybridization},
journal = {Neurocomputing},
volume = {271},
pages = {70-83},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2016.11.099},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217312250},
author = {J. Enrique Sierra and Matilde Santos},
keywords = {Identification, Adaptive neural networks, Neuro-fuzzy, Parametric techniques, Hybridization, Unmanned aerial vehicles (UAV)},
abstract = {From real input/output data, different control-oriented models of a quadrotor unmanned aerial vehicle (UAV) are obtained by applying different identification methods. Parametric techniques, neural networks, neuro-fuzzy inference systems, and the hybridization of some of them are applied. The identified models are analyzed and compared in the time and frequency domains. We conclude that the hybridization of analytical and intelligent techniques is a good choice to model of complex systems while keeping a good balance between accuracy and computational cost. In addition, off-line trained neural networks and adaptive networks with on-line learning are analyzed, and their advantages and disadvantages regarding modelling are presented. The influence of the partition of the training and validation dataset on the model error is also discussed.}
}
@article{GUO2021107596,
title = {Reinforcement learning enabled dynamic bidding strategy for instant delivery trading},
journal = {Computers & Industrial Engineering},
volume = {160},
pages = {107596},
year = {2021},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2021.107596},
url = {https://www.sciencedirect.com/science/article/pii/S0360835221005003},
author = {Chaojie Guo and Russell G. Thompson and Greg Foliente and Xiaoshuai Peng},
keywords = {Instant delivery, Sequential auctions, Reinforcement Learning, Bidding strategies},
abstract = {Due to the great potential to enable collaboration and improve consolidation, auctions have been identified as a possible effective option to improve the efficiency of instant delivery. Instant delivery markets are complex and dynamic systems influenced by highly random demand. Conventional bidding strategies require perfect market information and cannot be adjusted effectively according to the evolution of requests. To address this problem, this paper proposes an auction-based trading platform to enable freight transportation procurement and develops a Reinforcement Learning (RL) enabled dynamic bidding strategy to optimize carrier’s behavior in sequential auctions. In the RL enabled dynamic bidding strategy, three RL algorithms, including Q-learning, Deep Q Network and experience replay based Q-learning are used to improve carrier’s bidding ability. The simulation results demonstrate that compared with the conventional bidding strategy, the RL enabled dynamic bidding strategies with any of the three RL algorithms can help carrier secure more auctions and gain more profit in a competitive marketplace. In addition, the advantages of the RL enabled dynamic bidding strategies are more obvious and the performance is more stable in more uncertain market environments.}
}
@article{XU202012103,
title = {Model-Free Optimization Scheme for Efficiency Improvement of Wind Farm Using Decentralized Reinforcement Learning⁎⁎This work was supported by the National Natural Science Foundation of China under Grants 61722307 and 5191101838.},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {12103-12108},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.767},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320310910},
author = {Zhiwei Xu and Hua Geng and Bing Chu and Menghao Qian and Ni Tan},
keywords = {Wind farm, power optimization, model-free approach, decentralized control, Q learning method},
abstract = {Wake interactions caused by the complex wakes between the turbines within a wind farm have significant adverse effect on the total power generation of the wind farm. To mitigate the effect of wake interactions and optimize the total power output of wind farm, this paper proposes a model-free control scheme using reinforcement learning by developing a decentralized Q learning method. The proposed approach guarantees that the output power of wind farm converges to the optimal total power under different wind conditions, and further ensures the gradual changes of control variables of wind turbines and thus avoids the unexpected sharp drop of the power generation performance of wind farm. Simulation results are provided to demonstrate the effectiveness of the proposed method.}
}
@article{BAYAR2019670,
title = {A novel study for the estimation of crack propagation in concrete using machine learning algorithms},
journal = {Construction and Building Materials},
volume = {215},
pages = {670-685},
year = {2019},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2019.04.227},
url = {https://www.sciencedirect.com/science/article/pii/S0950061819311110},
author = {Gökhan Bayar and Turhan Bilir},
keywords = {Automation, Concrete, Crack propagation, Digital image analysis, Estimation, Sustainability},
abstract = {In this study, the crack pattern and propagation in a random concrete surface has been examined using machine learning algorithm called voronoi diagrams. A random photo of a concrete crack located on the surface is taken from a common source and the crack dimensions and directions have been measured. After then, the crack has been divided into 12 parts to evaluate the machine learning algorithm’s capability for estimating the crack pattern including its direction. Consequently, it has been shown that this novel technique is precise, quick, cheap and useful for monitoring and estimating crack propagation on concrete surfaces. Besides, it has great potential for not only cement and concrete industries and also for many different industries in the means of automation, sustainability, safety, cost and time savings for observing and estimating crack propagations or other properties of materials.}
}
@article{GAI201812,
title = {Optimal resource allocation using reinforcement learning for IoT content-centric services},
journal = {Applied Soft Computing},
volume = {70},
pages = {12-21},
year = {2018},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2018.03.056},
url = {https://www.sciencedirect.com/science/article/pii/S1568494618302540},
author = {Keke Gai and Meikang Qiu},
keywords = {Reinforcement learning, Resource allocation, Content-centric, Internet-of-Things, Smart computing},
abstract = {The exponential growing rate of the networking technologies has led to a dramatical large scope of the connected computing environment. Internet-of-Things (IoT) is considered an alternative for obtaining high performance by the enhanced capabilities in system controls, resource allocations, data exchanges, and flexible adoptions. However, current IoT is encountering the bottleneck of the resource allocation due to the mismatching networking service quality and complicated service offering environments. This paper concentrates on the issue of resource allocations in IoT and utilizes the satisfactory level of Quality of Experience (QoE) to achieve intelligent content-centric services. A novel approach is proposed by this work, which utilizes the mechanism of Reinforcement Learning (RL) to obtain high accurate QoE in resource allocations. Two RL-based algorithms have been proposed for cost mapping tables creations and optimal resource allocations. Our experiment evaluations have assessed the efficiency of implementing the proposed approach.}
}
@article{ERDELJ201772,
title = {Wireless Sensor Networks and Multi-UAV systems for natural disaster management},
journal = {Computer Networks},
volume = {124},
pages = {72-86},
year = {2017},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2017.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S1389128617302220},
author = {Milan Erdelj and Michał Król and Enrico Natalizio},
keywords = {Wireless Sensor Networks, Unmanned Aerial Vehicles, Natural disasters},
abstract = {This work identifies the role of Wireless Sensor Networks (WSN) and Unmanned Aerial Vehicles (UAV) in the context of natural disaster management. Main applications of systems involving WSN and UAV are classified according to the disaster management phase, and a review of relevant research activities is provided along with the research and development challenges that still remain unsolved. The main objectives of this work are to present technical results useful to improve the wellbeing of people, and push the state of the art one step forward in the definition of a complete disaster management system.}
}
@article{PURTA20132018,
title = {A Testbed for Investigating the UAV Swarm Command and Control Problem Using DDDAS},
journal = {Procedia Computer Science},
volume = {18},
pages = {2018-2027},
year = {2013},
note = {2013 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.05.371},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913005140},
author = {R. Purta and M. Dobski and A. Jaworski and G. Madey},
keywords = {UAVs, swarm, DDDAS, mission planning, command and control},
abstract = {Unmanned Aerial Vehicles (UAVs) may become the future of military aviation as technology advances, especially sensors and miniaturization techniques. Currently, however, UAVs are controlled individually and require many resources, including ground-based pilots, to function. In our project, we attempt to explore how to remedy this using a Dynamic Data-Driven Application System (DDDAS) to control a group, or swarm, of UAVs. DDDAS takes real data and injects it into a running simulation, as well as allowing the running simulation to influence what real data is gathered, and as such is an ideal system to control real UAVs. We describe here how we created a testbed system that allowed two simulations to communicate data to one another using DDDAS principles, as well as the beginnings of incorporating commercially-available UAVs into the system.}
}
@article{LI2019165,
title = {Cache-aided multi-hop UAV-relaying networks},
journal = {Physical Communication},
volume = {33},
pages = {165-171},
year = {2019},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2018.12.016},
url = {https://www.sciencedirect.com/science/article/pii/S1874490718304373},
author = {Xia Li and Kaiping Chen and Hanxu Hou and Lei Deng and Qingfeng Zhou},
keywords = {UAV relay, Outage probability, SER, Transmit power},
abstract = {In this work, we study unmanned aerial vehicle (UAV) relaying networks with multi-hop, where one source communicates with one destination through the help of L relay hops. Cache is employed at the relay nodes nearby the destination. Then the destination can acquire the data directly through the cache instead of communicating with the source. For the multi-hop relaying networks with cache, we not only analyze the transmission performance of the considered system by deriving the analytical expressions for the outage probability as well as symbol error rate (SER), but also provide the asymptotic outage probability and SER, in the large region of transmit power. The proposed caching method is proved by simulation and numerical results, and validates that the usage of cache can provide ultra-reliable and low-latency communications for UAV systems.}
}
@article{MIAO2021109097,
title = {Magnetic anomaly detection based on fast convergence wavelet artificial neural network in the aeromagnetic field},
journal = {Measurement},
volume = {176},
pages = {109097},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.109097},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121001275},
author = {Cunxiao Miao and Qi Dong and Min Hao and Chune Wang and Jianguo Cao},
keywords = {Aeromagnetic survey, SNR, Fast convergence wavelet artificial neural network, Orthogonal basis functions (OBFs), Error convergence rate},
abstract = {The orthogonal basis functions (OBFs) detector is a detection method widely used in the aerial magnetic measurement. However, OBFs detector works ineffectively under non-Gaussian noise and colored noise. This paper proposes an OBFs detector based on fast convergence wavelet artificial neural network (FC-W-ANN), which can detect abnormal magnetic signals under low SNR. First, the magnetic anomaly signal is modelled. Then, the learning rate is corrected by the iterative error convergence rate under the stability of the network. Finally, the improved network is combined with the OBFs detector to detect magnetic abnormal signals. From the simulation and experimental results, the reconstructed signal of the new method has a higher SNR (SNR = 10.01) compared with OBFs (SNR = -0.21) and OBFs based on the wavelet artificial neural network (W-ANN; SNR = 9.59). Furthermore, the statistical methods are used to analyze FC-W-ANN and W-ANN, showing that FC-W-ANN has higher training accuracy and better stability.}
}
@article{TEMPA2021,
title = {UAV technique to localize landslide susceptibility and mitigation proposal: A case of Rinchending Goenpa landslide in Bhutan},
journal = {Natural Hazards Research},
year = {2021},
issn = {2666-5921},
doi = {https://doi.org/10.1016/j.nhres.2021.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666592121000317},
author = {Karma Tempa and Kinley Peljor and Sangay Wangdi and Rupesh Ghalley and Kelzang Jamtsho and Samir Ghalley and Pratima Pradhan},
keywords = {UAV, GIS, Landslide susceptibility, Site investigation, Mitigation, Bhutan},
abstract = {Natural hazards such as landslides impose very high risks to the community and infrastructures. To mitigate such risk, proper long-term engineering solutions are must. Several studies conducted in the past proposed countermeasures on many occasions. Despite such interventions, the Rinchending Goenpa area still suffers high vulnerability to landslide hazard which continues every monsoon. To assess landslide characteristics in detail, we performed landslide susceptibility mapping using the unmanned aerial vehicle (UAV) technique and conducted a site investigation. High-resolution digital elevation model (DEM) was generated with the site-specific aerial photographs and processed in Agisoft PhotoScan to developed thematic layers in geographical information system (GIS) software. We implemented a multi-influencing factor (MIF) for deriving the influence of landslide conditioning factors and developed a landslide susceptibility map (LSM) using the weighted overlay method (WOM). The landslide conditioning factors include slope, elevation, aspect, topographical wetness index (TWI), and normalized difference vegetation index (NDVI). According to LSM, the areal coverage of landslide susceptibility of study area reveals 2.41% in very low susceptibility, 37.14% in low susceptibility, with highest in moderate susceptibility zone of 49.55% followed by 10.60% in high susceptibility zone, and 0.30% in the very high susceptible zone. Based on the zonal distribution of LSM, and considering findings from several other site investigation such as geophysical survey, the performance of existing countermeasures, soil characteristics, and footprint of last landslide occurrences, we proposed mitigation measures under each zone to provide long-term solutions.}
}
@article{LI2021107103,
title = {An explainable ensemble feedforward method with Gaussian convolutional filter},
journal = {Knowledge-Based Systems},
volume = {225},
pages = {107103},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107103},
url = {https://www.sciencedirect.com/science/article/pii/S095070512100366X},
author = {Jingchen Li and Haobin Shi and Kao-Shing Hwang},
keywords = {Explainable artificial intelligence, Medical image processing, Shapely additive explanation},
abstract = {The emerging deep learning technologies are leading to a new wave of artificial intelligence, but in some critical applications such as medical image processing, deep learning is inapplicable due to the lack of interpretation, which is essential for a critical application. This work develops an explainable feedforward model with Gaussian kernels, in which the Gaussian mixture model is leveraged to extract representative features. To make the error within the allowable range, we calculate the lower bound of the number of samples through the Chebyshev inequality. In the training processing, we discuss both the deterministic and stochastic feature representations, and investigate the performance of them and the ensemble model. Additionally, we use Shapely additive explanations to analyze the experiment results. The proposed method is interpretable, so it can replace the deep neural network by working with shallow machine learning technologies, such as the Support Vector Machine and Random Forest. We compare our method with baseline methods on Brain Tumor and Mitosis dataset. The experimental results show our method outperforms the RAM (Recurrent Attention Model), VGG19 (Visual Geometry Group 19), LeNET-5, and Explainable Prediction Framework while having strong interpretability.}
}
@article{TIAN2020111745,
title = {Development of spectral-phenological features for deep learning to understand Spartina alterniflora invasion},
journal = {Remote Sensing of Environment},
volume = {242},
pages = {111745},
year = {2020},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2020.111745},
url = {https://www.sciencedirect.com/science/article/pii/S0034425720301152},
author = {Jinyan Tian and Le Wang and Dameng Yin and Xiaojuan Li and Chunyuan Diao and Huili Gong and Chen Shi and Massimo Menenti and Yong Ge and Sheng Nie and Yang Ou and Xiaonan Song and Xiaomeng Liu},
keywords = {Cloudy coastal zone, Invasive species, Phenology, Google earth engine, Remote sensing big data, Deep learning},
abstract = {Invasive Spartina alterniflora (S. alterniflora), a native riparian species in the U.S. Gulf of Mexico, has led to serious degradation to the ecosystem and biodiversity as well as economic losses since it was introduced to China in 1979. Although multi-temporal remote sensing offers unique capability to monitor S. alterniflora over large areas and long time periods, three major hurdle exist: (1) in the coastal zone where S. alterniflora occupies, frequent cloud coverage reduces the number of available images that can be used; (2) prominent spectral variations exist within the S. alterniflora due to phonological variations; (3) poor spectral separability between S. alterniflora and its co-dominant native species is often presented in the territories where S. alterniflora intruded in. To articulate these questions, we proposed a new pixel-based phenological feature composite method (Ppf-CM) based on Google Earth Engine. The Ppf-CM method was brainstormed to battle the aforementioned three hurdles as the basic unit for extracting phonological feature is individual pixel in lieu of an entire image scene. With the Ppf-CM-derived phenological feature as inputs, we took a step further to investigate the performance of the latest deep learning method as opposed to that of the conventional support vector machine (SVM); Lastly, we strive to understand how S. alterniflora has changed its spatial distribution in the Beibu Gulf of China from 1995 to 2017. As a result, we found (1) the developed Ppf-CM method can mitigate the phonological variation and augment the spectral separability between S. alterniflora and the background species regardless of the significant cloud coverage in the study area; (2) deep learning, compared to SVM, presented better potentials for incorporating the new phenological features generated from the Ppf-CM method; and (3) for the first time, we discovered a S. alterniflora invasion outbreak occurred during 1996–2001.}
}
@article{YAN201923,
title = {Improving the estimation of fractional vegetation cover from UAV RGB imagery by colour unmixing},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {158},
pages = {23-34},
year = {2019},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S092427161930228X},
author = {Guangjian Yan and Linyuan Li and André Coy and Xihan Mu and Shengbo Chen and Donghui Xie and Wuming Zhang and Qingfeng Shen and Hongmin Zhou},
keywords = {Fractional vegetation cover (FVC), RGB images, Unmanned aerial vehicle (UAV), Mixed pixels, Colour mixture analysis (CMA), Endmember variability},
abstract = {Remote sensing via unmanned aerial vehicles (UAVs) is becoming a very important tool for augmenting traditional spaceborne and airborne remote sensing techniques. Commercial RGB cameras are often the payload on UAVs, because they are inexpensive, easy to operate and require little data processing. RGB images are increasingly being used for mapping of fractional vegetation cover (FVC). However, the presence of significantly mixed pixels in close-range RGB images prevents the accurate estimation of FVC. Even where pixel unmixing is applied, limited quantitative spectral information and colour variability within these images could lead to profound errors and uncertainties. This paper proposes a colour mixture analysis (CMA) method based on the Hue-Saturation-Value (HSV) colour space to alleviate the above-mentioned concerns, thereby improving the accuracy and efficiency of FVC estimation from UAV-captured RGB images. First, the a priori colour information of the pure vegetation and background endmembers are extracted from the Hue channel of the UAV proximal sensing images, obviating ground-based image capture and the attendant cost and inconvenience. Second, the relationship between the probability distribution of mixed pixels and that of the two endmembers is estimated. Finally, we estimate FVC from UAV remote sensing images with a maximum a posteriori parameter (MAP) estimator. Two UAV-captured RGB image datasets and a synthetic RGB image dataset were used to test the new method. CMA was compared with three other FVC estimation algorithms, namely, FCLS, HAGFVC and LAB2. The FVC estimates by CMA were found to be highly accurate, with root mean squared errors (RMSE) of less than 0.007 and mean absolute error (MAE) of less than 0.01 for both field datasets. The accuracy was shown to be superior to that of all three algorithms. A comprehensive analysis of the estimation accuracy under various spatial resolutions and vegetation cover levels was conducted using both field and synthetic datasets. Results show that the CMA method can robustly and accurately estimate FVC across the full range of vegetation coverage and various resolutions. Uncertainty and sensitivity analysis of colour variability due to heterogeneity and shadow were also tested. Overall, CMA was shown to be robust to variation in colour and illumination.}
}
@article{WANG2017380,
title = {Drogue detection for autonomous aerial refueling based on convolutional neural networks},
journal = {Chinese Journal of Aeronautics},
volume = {30},
number = {1},
pages = {380-390},
year = {2017},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2016.12.022},
url = {https://www.sciencedirect.com/science/article/pii/S1000936116302412},
author = {Xufeng Wang and Xinmin Dong and Xingwei Kong and Jianmin Li and Bo Zhang},
keywords = {Autonomous aerial refueling, Computer vision, Convolutional neural networks, Deep learning, Drogue detection},
abstract = {Drogue detection is a fundamental issue during the close docking phase of autonomous aerial refueling (AAR). To cope with this issue, a novel and effective method based on deep learning with convolutional neural networks (CNNs) is proposed. In order to ensure its robustness and wide application, a deep learning dataset of images was prepared by utilizing real data of “Probe and Drogue” aerial refueling, which contains diverse drogues in various environmental conditions without artificial features placed on the drogues. By employing deep learning ideas and graphics processing units (GPUs), a model for drogue detection using a Caffe deep learning framework with CNNs was designed to ensure the method’s accuracy and real-time performance. Experiments were conducted to demonstrate the effectiveness of the proposed method, and results based on real AAR data compare its performance to other methods, validating the accuracy, speed, and robustness of its drogue detection ability.}
}
@article{ALTURJMAN2020519,
title = {UAVs assessment in software-defined IoT networks: An overview},
journal = {Computer Communications},
volume = {150},
pages = {519-536},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419307637},
author = {Fadi Al-Turjman and Mohammad Abujubbeh and Arman Malekloo and Leonardo Mostarda},
keywords = {Internet of Things, Software defined networking, Drones, Performance assessment},
abstract = {The technological advancements in the ubiquitous IoT era and the ever-growing desire of communities to enforce smart cities with security and safety of user data as their priority, mini Unmanned Aerial Vehicles (UAVs), or drones, are perceived as a tool for raising living standards by meeting the requirements of societies. Traditionally in UAV communication links, meshed ad hoc networks were among the first options of connectivity. However, the increased demand for deploying multi-UAV networks necessitates the development of a more robust and more secure networking infrastructure. In this regard, Software-Defined Networking (SDN) paradigm has proved to be the better alternative for multi-UAV communication since it can offer flexible services for management and control owing to its unique features such as decoupling control from UAVs and network programmability. Therefore, in this paper, we provide an overview of drone applications in SDN-enabled Drone Base Stations (DBS), surveillance monitoring and emergency networks, and review the performance assessment techniques and the associated cybersecurity aspects in these applications. Moreover, future research directions, after a thorough analysis of the literature, is presented in this paper. Through the development of an innovative and multifaceted drone performance-assessment framework with the primal concerns, that are meeting user-defined requirements and the provision of secure and reliable services, it is, therefore, necessary to advance in IoT-enabled spaces. We believe the present work is a step in the right direction, and it is essential for fastening the movement toward UAV-enabled smart cities.}
}
@article{RAMONSORIA202077,
title = {Grasp Planning and Visual Servoing for an Outdoors Aerial Dual Manipulator},
journal = {Engineering},
volume = {6},
number = {1},
pages = {77-88},
year = {2020},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2019.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S2095809919308653},
author = {Pablo Ramon-Soria and Begoña C. Arrue and Anibal Ollero},
keywords = {Aerial manipulation, Grasp planning, Visual servoing},
abstract = {This paper describes a system for grasping known objects with unmanned aerial vehicles (UAVs) provided with dual manipulators using an RGB-D camera. Aerial manipulation remains a very challenging task. This paper covers three principal aspects for this task: object detection and pose estimation, grasp planning, and in-flight grasp execution. First, an artificial neural network (ANN) is used to obtain clues regarding the object’s position. Next, an alignment algorithm is used to obtain the object’s six-dimensional (6D) pose, which is filtered with an extended Kalman filter. A three-dimensional (3D) model of the object is then used to estimate an arranged list of good grasps for the aerial manipulator. The results from the detection algorithm—that is, the object’s pose—are used to update the trajectories of the arms toward the object. If the target poses are not reachable due to the UAV’s oscillations, the algorithm switches to the next feasible grasp. This paper introduces the overall methodology, and provides the experimental results of both simulation and real experiments for each module, in addition to a video showing the results.}
}
@article{TAN2021103881,
title = {Automatic inspection data collection of building surface based on BIM and UAV},
journal = {Automation in Construction},
volume = {131},
pages = {103881},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103881},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521003320},
author = {Yi Tan and Silin Li and Hailong Liu and Penglu Chen and Zhixiang Zhou},
keywords = {BIM, Building inspection, GA, UAV},
abstract = {Conventional high-rise building surface inspection is usually inefficient and requires the inspectors to work at heights with high risk. Unmanned aerial vehicles (UAVs) carrying optical or thermal cameras are currently widely utilized as an effective tool for inspection. The UAV-based data collection, especially for unreachable inspection areas, is the basis of unmanned inspection of building surface. In addition, building information modeling (BIM) with rich geometric and semantic information can also be instrumental in building surface inspection. Therefore, this paper presented an automatic inspection method of building surface, especially for the inspection data collection, by integrating UAV and BIM. To minimize the length of UAV flight while collecting complete and high-quality image data considering the limited endurance capability, the coverage path planning problem is solved using genetic algorithm (GA). The required inspection areas are obtained from the BIM model of the target building to be inspected. To further enhance the automation of building surface inspection, the optimized UAV flight mission parameters are rapidly calculated based on the BIM model and proposed algorithm. A real office building in Shenzhen University campus is used to validate the presented automatic method. The quality of the collected inspection images using the UAV with optimized flight mission are evaluated. The results show that this method leads to time-efficient, accurate, and high-quality inspection data collection for building surface.}
}
@article{WAN2020108096,
title = {Grain yield prediction of rice using multi-temporal UAV-based RGB and multispectral images and model transfer – a case study of small farmlands in the South of China},
journal = {Agricultural and Forest Meteorology},
volume = {291},
pages = {108096},
year = {2020},
issn = {0168-1923},
doi = {https://doi.org/10.1016/j.agrformet.2020.108096},
url = {https://www.sciencedirect.com/science/article/pii/S0168192320301982},
author = {Liang Wan and Haiyan Cen and Jiangpeng Zhu and Jiafei Zhang and Yueming Zhu and Dawei Sun and Xiaoyue Du and Li Zhai and Haiyong Weng and Yijian Li and Xiaoran Li and Yidan Bao and Jianyao Shou and Yong He},
keywords = {Unmanned aerial vehicle (UAV), Data fusion, Model transfer, Vegetation indices (VIs), Canopy structural information, Grain yield},
abstract = {Timely and accurate crop monitoring and yield forecasting before harvesting are valuable for precision management, policy and decision making, and marketing. The aim of this study is to explore the potential of fusing spectral and structural information extracted from the unmanned aerial vehicle (UAV)-based images in the whole growth period of rice to improve the grain yield prediction. A UAV platform carrying RGB and multispectral cameras was employed to collect high spatial resolution images of the rice crop under different nitrogen treatments over two years. The vegetation indices (VIs), canopy height and canopy coverage were extracted from UAV-based images, which were then used to develop random forest prediction models for grain yield. Among all of the investigated VIs, it was found that normalized difference yellowness index (NDYI) was the most useful index to monitor the changes in leaf chlorophyll content as well as the leaf greenness during the whole growth period. Meanwhile, the VIs provided a comparable prediction of grain yield to field-measured aboveground biomass and leaf chlorophyll content. Fusion of the multi-temporal normalized difference vegetation index (NDVI), NDYI, canopy height and canopy coverage achieved the best prediction of grain yield with a determination coefficient of 0.85 and 0.83, and relative root mean square error of 3.56% and 2.75% in 2017 and 2018, respectively, which outperformed the results in the reported studies. The initial heading stage was the optimal growth stage for the prediction of grain yield. Furthermore, the robustness of prediction model developed from the dataset in 2017 was validated by an external dataset from 2018 using model transfer. These findings demonstrate that the proposed approach can improve the prediction accuracy of grain yield as well as achieve an efficient monitoring of crop growth.}
}
@article{MORAIS2021115387,
title = {Estimating soil organic carbon of sown biodiverse permanent pastures in Portugal using near infrared spectral data and artificial neural networks},
journal = {Geoderma},
volume = {404},
pages = {115387},
year = {2021},
issn = {0016-7061},
doi = {https://doi.org/10.1016/j.geoderma.2021.115387},
url = {https://www.sciencedirect.com/science/article/pii/S0016706121004675},
author = {Tiago G. Morais and Camila Tufik and Ana E. Rato and Nuno R. Rodrigues and Ivo Gama and Marjan Jongen and João Serrano and David Fangueiro and Tiago Domingos and Ricardo F.M. Teixeira},
keywords = {Soil organic matter, Grassland, Spectroscopy, Machine learning, Sentinel-2},
abstract = {Grasslands in Portugal are key managed ecosystems, supporting and providing a diverse number of ecosystem services. Here, we developed a procedure for rapid estimation of soil organic carbon (SOC) in soil samples of sown biodiverse permanent pastures rich in legumes (SBP) in Portugal. We combined laboratory NIR spectral data analysis with artificial neural networks (ANN) to estimate the SOC content of SBP soil samples. To train and test the ANN, we used more than 340 soil samples collected in the 0–20 cm topsoil layer from three farms in 2018 and 2019 and two other farms in 2019 only. The number of bands of the spectra (800–2778 nm) was reduced using two different approaches: (a) aggregation to Sentinel-2 (S2) bands using the average reflectance within each bandwidths; and (b) principal component analysis (PCA). For the S2 approach, we considered the six S2 bands that overlap with the spectral range of the instrument used. For the PCA approach, we considered the five first principal components. Additional covariates were used for prediction, including weather and terrain attributes, e.g. accumulated precipitation, average temperature, elevation, and slope. To test for transferability of the models to different farms, we used an eight-fold leave-one-out cross-validation approach to calculate estimation errors. Each fold is a unique combination of farm and year and is used to assess the model's performance calibrated from the seven other folds. The ANN was able to estimate both low and high SOC contents without systematic errors and with similar estimation errors for both full and reduced spectral data approaches. The average root mean squared error (RMSE) for the S2 approach was 1.95 g kg−1 (0.45 – 2.33 g kg−1 depending on the hold-out fold) and for the PCA approach was 1.81 g kg−1 (0.74 – 2.42 g kg−1) (compared to the average SOC content of 12 g kg−1). These RMSE values were similar to the RMSE obtained using the full spectra, suggesting that the original spectral resolution could be reduced without losing information. These results suggest the potential for using remotely sensed data to estimate the variation of SOC content for SBP. They are a first step towards developing algorithms that can alleviate the cost and time of soil sampling and chemical SOC laboratory analysis through indirect estimation.}
}
@article{SANCHEZFERNANDEZMELLADO2021694,
title = {On the use of Machine Learning and Evidence Theory to improve collision risk management},
journal = {Acta Astronautica},
volume = {181},
pages = {694-706},
year = {2021},
issn = {0094-5765},
doi = {https://doi.org/10.1016/j.actaastro.2020.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0094576520304914},
author = {Luis {Sánchez Fernández-Mellado} and Massimiliano Vasile},
keywords = {Space Traffic Management, Machine Learning, Evidence Theory, Collision probability, Probability dilution},
abstract = {This paper presents an element of an Artificial Intelligence (AI) system to assist operators with the management of traffic in orbit. The system is based on a classification of collision events using Dempster–Shaffer’s theory of Evidence (DSt). DSt is proposed to capture and quantify the epistemic uncertainty in the estimation of the Probability of Collision (PC). By capturing the epistemic uncertainty in the calculation of PC, we mitigate the paradoxical Dilution of Probability that affects the usual definition of this quantity. This phenomenon gives the counterintuitive idea that the lower the amount of information available to the operators, the smaller the probability of collision. This lack of information corresponds to an uncertainty that is epistemic in nature. Furthermore, when different sources provide contradictory information, the level of epistemic uncertainty in the calculation of PC can lead to a false confidence in the likelihood of a collision with either an undesirable increase in the number of collision avoidance manoeuvres or an equally undesirable number of false negative. In order to make the classification automatic and provide continuous decision support to operators, we investigated the use of different Machine Learning techniques and identified the algorithm of choice to deliver the correct classification of collision events. We first considered a classification where the Belief and Plausibility in the correctness of the PC were used as additional classification criteria. Then we tested a second classification method that avoids the direct computation of Belief and Plausibility but retains the same added information on the credibility of the PC. Results suggest that Machine Learning can be effectively used in conjunction with DSt to provide decision support to operators and render the conjunction and collision analysis automatic.}
}
@article{KAKALETSIS2021116484,
title = {Multiview vision-based human crowd localization for UAV fleet flight safety},
journal = {Signal Processing: Image Communication},
volume = {99},
pages = {116484},
year = {2021},
issn = {0923-5965},
doi = {https://doi.org/10.1016/j.image.2021.116484},
url = {https://www.sciencedirect.com/science/article/pii/S0923596521002356},
author = {Efstratios Kakaletsis and Ioannis Mademlis and Nikos Nikolaidis and Ioannis Pitas},
keywords = {Crowd detection, Drone vision, Image processing, Autonomous drones, Multiview fusion},
abstract = {This paper presents a centralized, vision-based method for robust, on-the-fly 3D localization and mapping of human crowds in large-scale outdoor environments, assuming their independent visual detection on the camera feed of multiple UAVs. The proposed method aims at enhancing vision-assisted human crowd avoidance, in line with common UAV safety regulations, since the resulting 3D crowd annotations may be employed by other algorithms for on-line mission/path replanning during deployment of a UAV fleet. Initially, 2D crowd heatmaps are assumed to be derived per video frame on-board each UAV separately, using deep neural human crowd detectors, which indicate the probability of each pixel depicting a human crowd. The UAV-mounted cameras are assumed to be covering the same large-scale outdoor area over time. The heatmaps of each time instance are transmitted to a central computer and back-projected onto the common 3D terrain/map of the navigation environment, utilizing the intrinsic and extrinsic camera parameters. The projected crowd heatmaps derived from the different drones/cameras are fused by exploiting a Bayesian filtering approach that favors newer crowd observations over older ones. Thus, during flight, an area is marked as crowded (therefore, a no-fly zone) if all, or most, individual UAV-mounted visual detectors have recently and confidently indicated crowd existence on it. In order to calculate prior probabilities for Bayesian fusion, the method also proposes and exploits a simple, but efficient image processing-based algorithm for identifying flat terrain areas (under the assumption that people do not gather on highly curved or inclined terrain), relying on a priori available ground elevation data for the mapped area. Evaluation on both synthetic and real-world multiview video sequences depicting human crowds in outdoor environments verifies the effectiveness of the proposed method.}
}
@article{ZHANG2020112875,
title = {A reinforcement learning based approach for on-line adaptive parameter extraction of photovoltaic array models},
journal = {Energy Conversion and Management},
volume = {214},
pages = {112875},
year = {2020},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2020.112875},
url = {https://www.sciencedirect.com/science/article/pii/S0196890420304131},
author = {Jingwei Zhang and Yongjie Liu and Yuanliang Li and Kun Ding and Li Feng and Xihui Chen and Xiang Chen and Jiabing Wu},
keywords = {Reinforcement learning, On-line adaptive extraction, PV array, Parameter extraction, Mathematical model},
abstract = {At present, most methods for the fault detection and diagnosis (FDD) of the photovoltaic (PV) array strongly rely on comparing the on-line measured electrical parameters with the modeled reference ones, which are challenging the on-line accuracy and time cost of the parameter extraction for modeling the current-voltage (I-V) curves of the PV array. In this paper, a reinforcement learning (RL) based approach for on-line adaptive parameter extraction of PV array models is proposed. The model parameters, including the ideality factor, series and shunt resistance, and the compensated irradiance for the uncalibrated pyranometer, are extracted. Corresponding environmental states, actions, rewards, and the entire framework for the on-line adaptive parameter extraction are reasonably designed and investigated. The annual experimental results verify that the proposed RL-based approach can obtain higher on-line accuracy for modeling the I-V curve of PV array with fast extraction speed, compared with the conventional meta-heuristic-based approach and the analytical approach for parameter extraction. The annual experimental results reveal that the proposed approach can guarantee the 50% probability for obtaining the root mean square error (RMSE) less than 0.1, and 90% probability for obtaining the RMSE less than 0.25. The average computational time cost of the proposed approach is approximate 38.12 ms. In addition, the annual trend of extracted model parameters is analyzed. The annual results also show that the series and shunt resistance have the inverse seasonal trend. Besides, the measurement error of the pyranometer can be identified statistically. The proposed RL-based approach can also be integrated with the presented on-line FDD method, which realizes the on-line training of RL agents and the FDD of PV array simultaneously.}
}
@article{CHEN2020429,
title = {Data-driven and deep learning-based detection and diagnosis of incipient faults with application to electrical traction systems},
journal = {Neurocomputing},
volume = {396},
pages = {429-437},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.07.103},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219304552},
author = {Hongtian Chen and Bin Jiang and Tianyi Zhang and Ningyun Lu},
keywords = {Incipient faults, Fault detection and diagnosis (FDD), Electrical drive systems, Canonical correlation analysis (CCA), Convolutional neural network (CNN)},
abstract = {Incipient faults in electrical drive systems will evolve into faults or failures as time goes on. Successful detection and diagnosis of incipient faults can not only improve the safety and reliability but also provide optimal maintenance instructions for electrical drive systems. In this paper, an integration strategy of data-driven and deep learning-based method is proposed to deal with incipient faults. The salient advantages of the proposed method can be summarized as: (1) The moving average technique is firstly introduced into the canonical correlation analysis (CCA) framework, which makes the new residual signals more sensitive to incipient faults than the traditional CCA-based method; (2) Based on the defined residual signals, the new test statistics cooperating closely with Kullback–Leibler divergence (KLD) are proposed from the probability viewpoint, which can greatly improve the fault detectability; (3) It is of high computational efficiency because the estimation of probability density functions of residual signals is skilly avoided; (4) Based on the new developed test statistics, the fault matrices are defined and regarded as the input of convolutional neural network (CNN) whose feature extraction ability is highly improved compared with the traditional method, which helps to accurately diagnose of incipient faults; (5) The proposed method can be implemented without any priori knowledge on system information. Theoretical analysis and three sets of experiments on a practical electrical drive system demonstrate the effectiveness of the proposed method.}
}
@article{BANERJEE2021103297,
title = {Report on UG2+ challenge Track 1: Assessing algorithms to improve video object detection and classification from unconstrained mobility platforms},
journal = {Computer Vision and Image Understanding},
volume = {213},
pages = {103297},
year = {2021},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2021.103297},
url = {https://www.sciencedirect.com/science/article/pii/S1077314221001417},
author = {Sreya Banerjee and Rosaura G. VidalMata and Zhangyang Wang and Walter J. Scheirer},
keywords = {Computational photography, Object recognition, Object detection, Evaluation protocols, Deep learning},
abstract = {How can we effectively engineer a computer vision system that is able to interpret videos from unconstrained mobility platforms like UAVs? One promising option is to make use of image restoration and enhancement algorithms from the area of computational photography to improve the quality of the underlying frames in a way that also improves automatic visual recognition. Along these lines, exploratory work is needed to find out which image pre-processing algorithms, in combination with the strongest features and supervised machine learning approaches, are good candidates for difficult scenarios like motion blur, weather, and mis-focus — all common artifacts in UAV acquired images. This paper summarizes the protocols and results of Track 1 of the UG2+ Challenge held in conjunction with IEEE/CVF CVPR 2019. The challenge looked at two separate problems: (1) object detection improvement in video, and (2) object classification improvement in video. The challenge made use of new protocols for the UG2 (UAV, Glider, Ground) dataset, which is an established benchmark for assessing the interplay between image restoration and enhancement and visual recognition. In total, 16 algorithms were submitted by academic and corporate teams, and a detailed analysis of them is reported here.}
}
@article{FONSECAALVES2021502,
title = {Automatic fault classification in photovoltaic modules using Convolutional Neural Networks},
journal = {Renewable Energy},
volume = {179},
pages = {502-516},
year = {2021},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2021.07.070},
url = {https://www.sciencedirect.com/science/article/pii/S0960148121010752},
author = {Ricardo Henrique {Fonseca Alves} and Getúlio Antero de {Deus Júnior} and Enes Gonçalves Marra and Rodrigo Pinto Lemos},
keywords = {Solar energy, Convolutional neural network, Fault classification, Thermography, Data augmentation},
abstract = {Photovoltaic (PV) power systems have a significant potential to reduce greenhouse gases and diversify the electricity generation mix. Faults and damages that cause energy losses are common during either the fabrication or lifetime of PV modules. The development of automatic and reliable techniques to identify and classify faults in PV modules can help to improve the reliability and performance of PV systems and reduce operation and maintenance costs. A combination of infrared thermography and machine learning methods has been proven effective in the automatic detection of faults in large-scale PV plants. However, so far, few studies have assessed the challenges and efficiency of these methods applied to the classification of different defect classes in PV modules. In this study, we investigate the effect of data augmentation techniques to increase the performance of our proposed convolutional neural network (CNNs) to classify anomalies, between up to eleven different classes, in PV modules through thermographic images in an unbalanced dataset. Confusion matrices are used to investigate the high within- and between-class variation in different classes, which can be a challenge when creating an automatic tool to classify a large range of defects in PV plants. Through a cross-validation method, the CNN's testing accuracy was estimated as 92.5% for the detection of anomalies in PV modules and 78.85% to classify defects for eight selected classes.}
}
@article{HE2021112731,
title = {Integration of multi-scale remote sensing data for reindeer lichen fractional cover mapping in Eastern Canada},
journal = {Remote Sensing of Environment},
volume = {267},
pages = {112731},
year = {2021},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112731},
url = {https://www.sciencedirect.com/science/article/pii/S003442572100451X},
author = {Liming He and Wenjun Chen and Sylvain G. Leblanc and Julie Lovitt and André Arsenault and Isabelle Schmelzer and Robert H. Fraser and Rasim Latifovic and Lixin Sun and Christian Prévost and H. Peter White and Darren Pouliot},
keywords = {Lichen fractional cover, Landsat, Mapping, Deep learning, Multi-scale, Machine learning},
abstract = {Reindeer lichens (Cladonia spp.) are an essential food source for caribou especially during winter. They can also be a valuable indicator for ecosystem health and climate change. Inventory of lichen abundance at regional scales is required to assess availability within caribou ranges, and assess potential declines from natural and anthropogenic disturbances. Previous studies have mapped lichen cover and volume using remote sensing, but these efforts were often constrained by the limited availability of ground truth information needed for model calibration and validation. In this study, we leveraged unoccupied aerial vehicle (UAV) surveys and WorldView (WV) satellite scenes in a nested upscaling approach in order to expand the number of training samples at the 30 m Landsat resolution. These were used to develop machine learning models to map fractional reindeer lichen cover in Eastern Canada. We found that the best correlation between UAV and WV derived lichen coverages exists at an optimal scale that is slightly larger than 30 m and varies with landscape type and observation geometry. Based on training data from UAV-calibrated lichen coverage from WV data, a neural network model with simple structure achieved a root mean square error (RMSE) = 0.09, a mean absolute error (MAE) = 0.07 and R2 = 0.79 for mapping fractional lichen cover from Landsat without the use of ancillary data. We then applied our model and Landsat data to produce a lichen fractional cover map for the Red Wine Mountain caribou herd range in Labrador, NL and the Manicouagan caribou herd range in Québec. Validation against domain-averaged lichen cover in eight UAV survey sites suggests an accuracy with RMSE = 0.04, MAE = 0.03 and R2 = 0.62 for low lichen cover. Compared to aggregated lichen cover at 30 m from UAV surveys, map accuracy decreases to RMSE = 0.09, MAE = 0.06, and R2 = 0.49, partially due to registration error between UAV and Landsat images. Our study demonstrates that upscaling of lichen cover from UAV data to Landsat via an intermediate image scale is an effective regional-scale mapping approach.}
}
@article{WANG2015206,
title = {A data driven approach for detection and isolation of anomalies in a group of UAVs},
journal = {Chinese Journal of Aeronautics},
volume = {28},
number = {1},
pages = {206-213},
year = {2015},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2014.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1000936114002027},
author = {Yin Wang and Daobo Wang and Jianhong Wang},
keywords = {Combinatorial optimization, Fault detection, Gradient methods, Model identification, Unmanned aerial vehicle},
abstract = {The use of groups of unmanned aerial vehicles (UAVs) has greatly expanded UAV’s capabilities in a variety of applications, such as surveillance, searching and mapping. As the UAVs are operated as a team, it is important to detect and isolate the occurrence of anomalous aircraft in order to avoid collisions and other risks that would affect the safety of the team. In this paper, we present a data-driven approach to detect and isolate abnormal aircraft within a team of formatted flying aerial vehicles, which removes the requirements for the prior knowledge of the underlying dynamic model in conventional model-based fault detection algorithms. Based on the assumption that normal behaviored UAVs should share similar (dynamic) model parameters, we propose to firstly identify the model parameters for each aircraft of the team based on a sequence of input and output data pairs, and this is achieved by a novel sparse optimization technique. The fault states of the UAVs would be detected and isolated in the second step by identifying the change of model parameters. Simulation results have demonstrated the efficiency and flexibility of the proposed approach.}
}
@article{KIM2019117,
title = {Deep Neural Network-Based Feedback Control for Dynamic Soaring of Unpowered Aircraft *⁎This work was supported by the R&D Program in Aerospace Parts and Materials (10066055) through the Korea Evaluation Institute of Industrial Technology funded by the Ministry of Trade, Industry, and Energy, Republic of Korea.},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {12},
pages = {117-121},
year = {2019},
note = {21st IFAC Symposium on Automatic Control in Aerospace ACA 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.11.079},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319310158},
author = {Seong-hun Kim and Jihoon Lee and Seungyun Jung and Hanna Lee and Youdan Kim},
keywords = {Trajectory planning, Optimal trajectory, Neural networks, Intelligent control, State feedback},
abstract = {Dynamic soaring is a bio-inspired maneuver to harvest energy from the wind gradient, which allows albatrosses to fly across the ocean without flapping their wings. Although the underlying dynamics is well-known, which can be represented as a fixed-wing aircraft, the mechanism or the control law that successively extracts energy from the unforeseen wind gradient remains in question. In this study, a deep neural network architecture and a feedback control law for the dynamic soaring maneuver are proposed based on the investigation of the mechanical energy extraction mechanism. To train the neural network, a bunch of data composed of state and control pairs is generated via trajectory optimization, which is slightly modified to deal with the problem considered in this study. Numerical result shows that the trained network-based feedback control law can perform the dynamic soaring maneuver in various wind profiles.}
}
@article{NING2019100717,
title = {Multi-UAVs trajectory and mission cooperative planning based on the Markov model},
journal = {Physical Communication},
volume = {35},
pages = {100717},
year = {2019},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2019.100717},
url = {https://www.sciencedirect.com/science/article/pii/S1874490719300266},
author = {Qian Ning and Guiping Tao and Bingcai Chen and Yinjie Lei and Hua Yan and Chengping Zhao},
keywords = {Collaborative mission planning, Trajectory planning, Survival state, Markov model, Meta-heuristic search algorithms},
abstract = {As the environment of the battlefield is increasingly complex, single UAV (Unmanned Aerial Vehicle) has trouble in carrying out missions, which requires the cooperation of multiple UAVs. However, search space is very large and search targets are distributed sparsely, and making mission planning and route planning simultaneously is also an NP (Non-Deterministic Polynomial Problems) problem, which makes it extremely difficult in mission planning. Recently, meta-heuristic search algorithms widely used in multi-UAVs collaborative mission planning are difficult to find reliable initial solutions and limit the convergence speed. Aiming at this problem, to take plenty of constraints and performance planning targets in multi-UAV cooperative mission planning problems into full consideration. This paper proposes a two-layer mission planning model based on the simulated annealing algorithm and tabu search algorithm, which solves multi-objectives, Multi-aircraft mission planning problems. This paper combined the five-state Markov chain model with the mission planning model to determine the optimal mission planning scheme by judging the survival state probability of the flight platform. Finally, the simulation results show that this method can greatly improve the survivability of the drone while ensuring optimal mission planning.}
}
@article{SOHAIL2022100426,
title = {A Cat Swarm Optimization based transmission power minimization for an aerial NOMA communication system},
journal = {Vehicular Communications},
volume = {33},
pages = {100426},
year = {2022},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2021.100426},
url = {https://www.sciencedirect.com/science/article/pii/S2214209621000954},
author = {Muhammad Farhan Sohail and Chee Yen Leow and SeungHwan Won},
keywords = {Base Station (BS), Cat Swarm Optimization (CSO), Energy efficiency, Non-Orthogonal Multiple Access (NOMA), Unmanned Aerial Vehicle (UAV), User pairing},
abstract = {This article underlines the inclusion of Non-Orthogonal Multiple Access (NOMA) aerial network nodes to rapidly serve a mass deployment of devices in the next-generation networks. The analysis of an aerial NOMA deployment is conducted considering the objective of minimization of the required transmission power in comparison to an aerial deployment employing Orthogonal Multiple Access (OMA). The findings of the study highlight the inter-dependency among the considered optimization variables of user pairing, altitude, and power allocation as well as stress the implication of their joint optimization for improved performance of the aerial NOMA system. The formulated mixed-integer non-linear programming problem is solved utilizing a joint optimization technique. Meanwhile, the employment of Cat Swarm Optimization (CSO) framework for NOMA user pairing optimization marks the first work of its kind in the literature. Subsequently, the altitude of the NOMA Unmanned Aerial Vehicle Base Station (UAV-BS) is computed using tools of convex optimization. The obtained results of the proposed methodology solved iteratively substantiate the better performance of NOMA compared to an equivalent OMA UAV-BS deployment. Subsequently, the presented results demonstrate the efficacy of the proposed CSO approach in reducing the required transmission power as well as the operating altitude attributed to lower flying energy consumption of the UAV-BS compared to random and particle swarm optimization based user pairing techniques.}
}
@article{LALOUANI2021109,
title = {Countering radiometric signature exploitation using adversarial machine learning based protocol switching},
journal = {Computer Communications},
volume = {174},
pages = {109-121},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421001432},
author = {Wassila Lalouani and Mohamed Younis and Uthman Baroudi},
keywords = {Radiometric signature, RF fingerprinting, Traffic analysis, Distributed beamforming, Adversarial machine learning},
abstract = {A Radiometric signature refers to transceiver specific features that are caused by variations in the manufacturing process even for the same circuit design. While such a radiometric signature constitutes a fingerprint that can be exploited for device authentication, it is a threat to privacy. Particularly, in the realm of wireless networks, an adversary may exploit radio frequency (RF) fingerprinting to identify devices and conduct traffic analysis in order to uncover the topology and categorize the role of various nodes. In this paper, we show how an adversary could employ RF fingerprinting to distinguish among nodes and bypass the provisioned anonymity protection in the network. We analyze the accuracy of RF fingerprinting and highlight how the accuracy affects the success of adversary attacks. To counter such a threat, we propose a novel methodology that requires no hardware changes to the radio transceiver and the associated host device. Our methodology is based on coordinated switching among preset link-layer and physical-layer communication protocols. For the latter, we particularly exploit distributed beamforming. We employ adversarial machine learning to select the protocol configuration for each transmission so that the accuracy of the RF fingerprinting diminishes. We demonstrate the effectiveness of our scheme through simulation and prototype experiments.}
}
@article{WANG20209399,
title = {The problem of reliable design of vector-field path following in the presence of uncertain course dynamics ⁎⁎This work was partly supported by the Fundamental Research Funds for the Central Universities grant no. 4007019109 (RECONSTRUCT), and by the special guiding funds “double first-class” grant no. 4007019201. S. Farì was with TU Delft and is now with German Aerospace Center. (corresponding author: S. Baldi)},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {9399-9404},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.2409},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320330913},
author = {Ximan Wang and Spandan Roy and Stefano Farì and Simone Baldi},
keywords = {Fixed-wing Unmanned Aerial Vehicles, guidance navigation, control, uncertain course dynamics, reliable design, software-in-the loop UAV simulator},
abstract = {Reliable guidance of fixed-wing Unmanned Aerial Vehicles (UAVs) is challenging, as their high maneuverability exposes them to several dynamical changes and parametric uncertainties. Reliability of state-of-the-art guidance methods is often at stake, as these methods heavily rely on precise UAV course dynamics, assumed in a decoupled first-order form with known time constant. To improve reliability of guidance for fixed-wing UAVs, this work proposes a novel vector field law that can handle uncertain course time constant and state-dependent uncertainty in the course dynamics arising from coupling. Stability is studied in the Lyapunov framework, while reliability of the proposed method is tested on a software-in-the loop UAV simulator. The simulations show that, in the presence of such uncertainty, the proposed method outperforms the standard vector field approaches.}
}
@article{HOU2019102599,
title = {Image anomaly detection for IoT equipment based on deep learning},
journal = {Journal of Visual Communication and Image Representation},
volume = {64},
pages = {102599},
year = {2019},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2019.102599},
url = {https://www.sciencedirect.com/science/article/pii/S1047320319302202},
author = {Rui Hou and MingMing Pan and YunHao Zhao and Yang Yang},
keywords = {Operating environment monitoring, Image anomaly detection, Deep learning},
abstract = {Intelligent power grid systems is the trend of power development, since traditional methods of manually monitoring power equipment have been unable to meet the requirements of power systems. When an abnormal situation occurs in the operating environment, most monitoring devices cannot be quickly and accurately identified, which may have serious consequences. Aiming at the above problems, in this paper, we propose an anomaly detection algorithm for the monitoring environment of power IoT equipment operating environment based on deep learning from the perspective of personnel identification and fire smoke detection. The multi-stream CNN-based remote monitoring image personnel detection method and the deep convolutional neural network-based fire smoke detection method have achieved good results in personnel identification and fire smoke detection in the power equipment operating environment monitoring image, respectively. This provides a reference for monitoring image anomaly detection.}
}
@article{ROVIRA201789,
title = {Reinforcement Learning as a tool to make people move to a specific location in Immersive Virtual Reality},
journal = {International Journal of Human-Computer Studies},
volume = {98},
pages = {89-94},
year = {2017},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2016.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S1071581916301513},
author = {Aitor Rovira and Mel Slater},
keywords = {Immersive Virtual Reality, Reinforcement Learning},
abstract = {This paper describes the use of Reinforcement Learning in Immersive Virtual Reality to make a person move to a specific location in a virtual environment. Reinforcement Learning is a sub-area of Machine Learning in which an active entity called an agent interacts with its environment and learns how to act in order to achieve a pre-determined goal. The Reinforcement Learning had no prior model of behaviour and the participants no prior knowledge that their task was to move to and stay in a specific place. The participants were placed in a virtual environment where they had to avoid collisions with virtual projectiles. Following each projectile the agent analysed the movement made by the participant to determine paths of future projectiles in order to increase the chance of driving participants to the goal position and make them stay there as long as possible. The experiment was carried out with 30 participants, 10 were guided towards the leftmost part of the environment, 10 to the rightmost area, and 10 were used as control group where the projectiles were shot randomly throughout the game. Our results show that people tended to stay close to the target area in both the Left and Right conditions, but not in the Random condition.}
}
@article{MESHCHERYAKOV201914,
title = {An application of swarm of quadcopters for searching operations},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {25},
pages = {14-18},
year = {2019},
note = {19th IFAC Conference on Technology, Culture and International Stability TECIS 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.438},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319323468},
author = {R.V. Meshcheryakov and P.M. Trefilov and A.V. Chekhov and S.A.K Diane and K.D. Rusakov and E.A. Lesiv and M.A. Kolodochka and K.O. Shchukin and A.K. Novoselskiy and E. Goncharova},
keywords = {skiptracing, searching for missing persons, UAV, human detection, quadcopter, swarm, drone},
abstract = {The search and rescue (SAR) operations belong to urgent types of work. One of their tasks is saving people under challenging conditions (including emergency or natural disasters). Currently, professional salvors, volunteers and air assets are most often engaged in these operations. However, such an approach has its disadvantages: wide coverage of areas requires a large number of people, and helicopters engagement (or other types of SAR aircraft) results in a heavy financial cost. Thus, the need for researching other ways for carrying out SAR operations emerges; these new approaches may reduce their cost and time frame, simultaneously saving the quality of SAR operations. This article considers the ability of using a swarm of UAVs (unmanned aerial vehicles) for skiptracing (searching for missing persons). We give the analysis of existing decisions and offer the concept. The advantages of the proposed concept and algorithm of proceeding are described below.}
}
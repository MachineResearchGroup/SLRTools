@inproceedings{10.1145/3417312.3431826,
author = {Diao, Donghui and Wang, Xin and Yang, Chao and Wang, Yue and Ma, Jianfeng},
title = {GPS Spoofing Detection via SNR},
year = {2020},
isbn = {9781450381338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3417312.3431826},
doi = {10.1145/3417312.3431826},
abstract = {Nowadays, the use of GPS has penetrated everyone's daily life, so the safety of GPS signals has threatened all of us. Since the portable GPS spoof was proposed at the Black Hat Conference, the cost and threshold of GPS spoofing have also been getting lower and lower. However, many strategies for anti-GPS spoofing may need to add new hardware equipment or require powerful computing power. We aim to use the smallest possible cost to complete the purpose of GPS spoofing detection. In this article, we have designed There are many different detection schemes, and their detection delay and accuracy are different. To prove their feasibility, we did a real experiment. We evaluated the performance of the system based on the experiment, and the results show that the system accuracy is as high as 98%.},
booktitle = {Proceedings of the 1st ACM International Workshop on Security and Safety for Intelligent Cyber-Physical Systems},
pages = {1–5},
numpages = {5},
keywords = {spoofing, GPS, SNR, detection},
location = {Virtual Event, Japan},
series = {SecICPS '20}
}

@inbook{10.1145/3412841.3442060,
author = {Yar, Ghulam Nabi Ahmad Hassan and Noor-ul-Hassan, Abu-Bakar and Siddiqui, Hanzla},
title = {Real-Time Shallow Water Image Retrieval and Enhancement for Low-Cost Unmanned Underwater Vehicle Using Raspberry Pi},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3412841.3442060},
abstract = {Unmanned Underwater Vehicles (UUV) operated underwater without any human interference. UUVs can be used for many purposed i.e. exploration or spying. They have several designs and each one can be used for a specific purpose. Main problem that limits the functionality of UUV is poor image quality. Reason behind this poor image quality is scattering and wavelength absorption. Purpose of this paper is to propose an electrical assembly design of low-cost UUV. In order to carry out this work use of Raspberry-Pi is proposed which is a small computer own it's own. It can be used to enhance image quality and detect objects along with color detection. For controlling the propellers in accordance to any hindrance, pulse width modulation(PWM) GPIO pins are used. GPIO pins are also used to attach sensors. For enhancement of images python 3 was used and different image enhancement methods were tested on basis of execution time per frame. In the end, best model is selected which is more suitable on basis of execution time and image enhancement. In order to transmit the images from UUV to base computer wi-fi module of Raspberry pi is used.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {1891–1899},
numpages = {9}
}

@inbook{10.1145/3341105.3373974,
author = {Cornejo Lupa, Maria A. and Ticona-Herrera, Regina P. and Cardinale, Yudith and Barrios-Aranibar, Dennis},
title = {A Categorization of Simultaneous Localization and Mapping Knowledge for Mobile Robots},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3341105.3373974},
abstract = {Autonomous robots are playing important roles in academic, technological, and scientific activities. Thus, their behavior is getting more complex. The main tasks of autonomous robots include mapping an environment and localize themselves. These tasks comprise the Simultaneous Localization and Mapping (SLAM) problem. Representation of the SLAM knowledge (e.g., robot characteristics, environment information, mapping and location information), with a standard and well-defined model, provides the base to develop efficient and interoperable solutions. However, as far as we know, there is not a common classification of such knowledge. Many existing works based on Semantic Web, have formulated ontologies to model information related to only some SLAM aspects, without a standard arrangement. In this paper, we propose a categorization of the knowledge managed in SLAM, based on existing ontologies and SLAM principles. We also classify recent and popular ontologies according to our proposed categories and highlight the lessons to learn from existing solutions.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {956–963},
numpages = {8}
}

@inproceedings{10.1109/MICRO.2018.00077,
author = {Boroujerdian, Behzad and Genc, Hasan and Krishnan, Srivatsan and Cui, Wenzhi and Faust, Aleksandra and Reddi, Vijay Janapa},
title = {MAVBench: Micro Aerial Vehicle Benchmarking},
year = {2018},
isbn = {9781538662403},
publisher = {IEEE Press},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/MICRO.2018.00077},
doi = {10.1109/MICRO.2018.00077},
abstract = {Unmanned Aerial Vehicles (UAVs) are getting closer to becoming ubiquitous in everyday life. Among them, Micro Aerial Vehicles (MAVs) have seen an outburst of attention recently, specifically in the area with a demand for autonomy. A key challenge standing in the way of making MAVs autonomous is that researchers lack the comprehensive understanding of how performance, power, and computational bottlenecks affect MAV applications. MAVs must operate under a stringent power budget, which severely limits their flight endurance time. As such, there is a need for new tools, benchmarks, and methodologies to foster the systematic development of autonomous MAVs. In this paper, we introduce the "MAVBench" framework which consists of a closed-loop simulator and an end-to-end application benchmark suite. A closed-loop simulation platform is needed to probe and understand the intra-system (application data flow) and inter-system (system and environment) interactions in MAV applications to pinpoint bottlenecks and identify opportunities for hardware and software co-design and optimization. In addition to the simulator, MAVBench provides a benchmark suite, the first of its kind, consisting of a variety of MAV applications designed to enable computer architects to perform characterization and develop future aerial computing systems. Using our open source, end-to-end experimental platform, we uncover a hidden, and thus far unexpected compute to total system energy relationship in MAVs. Furthermore, we explore the role of compute by presenting three case studies targeting performance, energy and reliability. These studies confirm that an efficient system design can improve MAV's battery consumption by up to 1.8X.},
booktitle = {Proceedings of the 51st Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {894–907},
numpages = {14},
location = {Fukuoka, Japan},
series = {MICRO-51}
}

@inproceedings{10.1145/3381427.3381429,
author = {Nunez-Yanez, Jose and Nikov, Kris and Eder, Kerstin and Hosseinabady, Mohammad},
title = {Run-Time Power Modelling in Embedded GPUs with Dynamic Voltage and Frequency Scaling},
year = {2020},
isbn = {9781450375450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3381427.3381429},
doi = {10.1145/3381427.3381429},
abstract = {This paper investigates the application of a robust CPU-based power modelling methodology that performs an automatic search of explanatory events derived from performance counters to embedded GPUs. A 64-bit Tegra TX1 SoC is configured with DVFS enabled and multiple CUDA benchmarks are used to train and test models optimized for each frequency and voltage point. These optimized models are then compared with a simpler unified model that uses a single set of model coefficients for all frequency and voltage points of interest. To obtain this unified model, a number of experiments are conducted to extract information on idle, clock and static power to derive power usage from a single reference equation. The results show that the unified model offers competitive accuracy with an average 5% error with four explanatory variables on the test data set and it is capable to correctly predict the impact of voltage, frequency and temperature on power consumption. This model could be used to replace direct power measurements when these are not available due to hardware limitations or worst-case analysis in emulation platforms.},
booktitle = {Proceedings of the 11th Workshop on Parallel Programming and Run-Time Management Techniques for Many-Core Architectures / 9th Workshop on Design Tools and Architectures for Multicore Embedded Computing Platforms},
articleno = {2},
numpages = {6},
keywords = {DVFS, GPU power modelling, Embedded GPU, Heterogeneous architecture, multiple linear regression},
location = {Bologna, Italy},
series = {PARMA-DITAM'2020}
}

@inbook{10.1145/3474085.3479237,
author = {Kang, Zhaodong and Li, Jianing and Zhu, Lin and Tian, Yonghong},
title = {Retinomorphic Sensing: A Novel Paradigm for Future Multimedia Computing},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3474085.3479237},
abstract = {Conventional frame-based cameras for multimedia computing have encountered important challenges in high-speed and extreme light scenarios. However, how to design a novel paradigm for visual perception that overcomes the disadvantages of conventional cameras still remains an open issue. In this paper, we propose a novel solution, namely retinomorphic sensing, which integrates fovea-like and peripheral-like sampling mechanisms to generate asynchronous visual streams using a unified representation as the retina does. Technically, our encoder incorporates an interaction controller to switch flexibly between dynamic and static sensing. Then, the decoder effectively extracts dynamic events for machine vision and reconstructs visual textures for human vision. The results show that our strategy enables it to sense dynamic events and visual textures meanwhile reduce data redundancy. We further build a prototype hybrid camera system to verify this strategy on vision tasks such as image reconstruction and object detection. We believe that this novel paradigm will provide insight into future multimedia computing. The code can be available at https://github.com/acmmm2021-bni-retinomorphic/retinomorphic-sensing.},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {144–152},
numpages = {9}
}

@inproceedings{10.1145/3458473.3458821,
author = {Yen, Alex and Flowers, Bryse and Luo, Wenshan and Nagesh, Nitish and Tueller, Peter and Kastner, Ryan and Pannuto, Pat},
title = {A UCSD View on Replication and Reproducibility for CPS &amp; IoT},
year = {2021},
isbn = {9781450384391},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3458473.3458821},
doi = {10.1145/3458473.3458821},
abstract = {Reproducibility and replicability (R&amp;R) are important for research. Many communities are beginning efforts to reward, incentivize, and highlight projects as a motive to adopt R&amp;R practices. This is clearly a good direction - we should all aim to make our research sound, replicable, and reproducible. Yet, this involves a lot of effort to document, debug, and generally make the systems that we build more usable. Interfacing with the Physical world and building custom Things exacerbates these challenges. Therein lies the dilemma: how does the CPS/IoT community reward and incentivize R&amp;R efforts? This paper looks into the question of R&amp;R in CPS/IoT. We survey efforts in other fields spanning computing to healthcare and highlight similarities and differences to CPS/IoT. We then discuss several exemplar CPS/IoT projects related to UCSD's research and highlight the R&amp;R efforts in these projects, the potential ways that they could be improved, and best practices. We finish with recommendations and insights for R&amp;R tailored to the CPS/IoT community.},
booktitle = {Proceedings of the Workshop on Benchmarking Cyber-Physical Systems and Internet of Things},
pages = {20–25},
numpages = {6},
keywords = {reproducibility, replication, open science},
location = {Nashville, Tennessee},
series = {CPS-IoTBench '21}
}

@inproceedings{10.5555/3398761.3398956,
author = {Bernardini, Sara and Jovan, Ferdian and Jiang, Zhengyi and Watson, Simon and Weightman, Andrew and Moradi, Peiman and Richardson, Tom and Sadeghian, Rasoul and Sareh, Sina},
title = {A Multi-Robot Platform for the Autonomous Operation and Maintenance of Offshore Wind Farms},
year = {2020},
isbn = {9781450375184},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {With the increasing scale of offshore wind farm development, maintaining farms efficiently and safely becomes a necessity. The length of turbine downtime and the logistics for human technician transfer make up a significant proportion of the operation and maintenance (O&amp;M) costs. To reduce such costs, future O&amp;M infrastructures will increasingly rely on offshore autonomous robotic solutions that are capable of co-managing wind farms with human operators located onshore. In particular, unmanned aerial vehicles, autonomous surface vessels, and crawling robots are expected to play important roles not only to bring down costs but also to significantly reduce the health and safety risks by assisting (or replacing) human operators in performing the most hazardous tasks. This paper portrays a visionary view in which heterogeneous robotic assets, underpinned by AI agent technology, coordinate their behavior to autonomously inspect, maintain and repair offshore wind farms over long periods of time and unstable weather conditions. They cooperate with onshore human operators, who supervise the mission at a distance, via the use of shared deliberation techniques. We highlight several challenging research directions in this context and offer ambitious ideas to tackle them as well as initial solutions.},
booktitle = {Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {1696–1700},
numpages = {5},
keywords = {wind farms, multi-agency, explainability, extreme environments, robotics, ai planning, autonomy},
location = {Auckland, New Zealand},
series = {AAMAS '20}
}

@inproceedings{10.1145/3341620.3341623,
author = {Ma, RuiXin and Xu, Peng and Li, LiLi and Wang, Chuang},
title = {Hotspot Detection in Social Media Based on Improved Strategy Clustering},
year = {2019},
isbn = {9781450360913},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3341620.3341623},
doi = {10.1145/3341620.3341623},
abstract = {With the rapid growth of social media platform, hotspot detection has become an increasing important issue in the We media era. As for researchers, the emergence of all kinds of public opinion crises is one of the greatest challenges. In order to make a response to public opinion precisely, a more effective approach for hotspot detection is necessary. Clustering algorithm is one of the best choices for distinguishing hotspots. However, the existing methods still need some improvement in filtering data and calculating text similarity. Therefore, we propose a method which combines the two strategies to improve the performance of clustering algorithm for hotspot detection. One strategy is message importance which is used for measuring the value of information from social media. The other strategy is an improved text similarity based on feature words which is applied to solve sparse vector from the short texts. Through improving the accuracy of clustering, we can obtain more accurate hotspots. We validate the proposed method is feasible through the experiment based on the datasets from Weibo online.},
booktitle = {Proceedings of the 2019 International Conference on Big Data Engineering},
pages = {10–15},
numpages = {6},
keywords = {clustering algorithms, hotspot detection, social media, text similarity},
location = {Hong Kong, Hong Kong},
series = {BDE 2019}
}

@inproceedings{10.1145/3123024.3123193,
author = {Mauriello, Matthew Louis},
title = {Scalable Methods and Tools to Support Thermographic Data Collection and Analysis for Energy Audits},
year = {2017},
isbn = {9781450351904},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3123024.3123193},
doi = {10.1145/3123024.3123193},
abstract = {Buildings consume 41% of energy produced in the US and contribute an increasing portion of total carbon dioxide emissions---40% in 2009 compared to 33% in 1980 [9]. One factor contributing to these issues is building age. Residential buildings, for example, constitute 95% of all buildings in the US and are on average over 50 years old [23]; most of these buildings were constructed using energy inefficient designs and their materials have degraded over time. Moreover, the US Department of Energy has set a goal of reducing housing energy use by up to 70% [18]. To meet this goal, renovations and retrofits of existing building stock has become a pressing need. One effective practice for motivating these improvements is energy auditing, which has seen a resurgence of interest in recent years [20].},
booktitle = {Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers},
pages = {360–364},
numpages = {5},
keywords = {thermography, energy efficiency, sensor kits, sustainable HCI, mobile devices, support tools, formative inquiry},
location = {Maui, Hawaii},
series = {UbiComp '17}
}

@inbook{10.1145/3386164.3389091,
author = {Aoki, Risako and Oki, Takuro and Yokokawa, Hiro and Miyamoto, Ryusuke},
title = {A Computationally Efficient Tracking Scheme for Localization of Soccer Players in an Aerial Video Sequence},
year = {2019},
isbn = {9781450376617},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3386164.3389091},
abstract = {The authors attempted to construct a novel sensor networking system that estimates locations of sensor nodes as locations of humans wearing them via image processing. In this application, computationally efficient human localization is indispensable because the operation should be executed on embedded systems. To actualize human localization at a lower computational cost, this study proposes a novel tracking scheme using only detection results. Experimental results using the computer graphics (CG) dataset that was created using player locations of an actual soccer game showed that the proposed scheme outperformed existing schemes implemented in the OpenCV library.},
booktitle = {Proceedings of the 2019 3rd International Symposium on Computer Science and Intelligent Control},
articleno = {13},
numpages = {6}
}

@inproceedings{10.1145/3220511.3220519,
author = {Tsagaris, Apostolos and Trigkas, Dimitrios},
title = {Mobile Gesture Recognition},
year = {2018},
isbn = {9781450363815},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3220511.3220519},
doi = {10.1145/3220511.3220519},
abstract = {This paper presents a methodology for a real time mobile gesture recognition system. It presents a new kind of Human - Machine interaction through mobile devices (microcontroller) and without the use of typical computer system. With the help of real time gesture recognition technologies and by using camera signal processing (web) the interaction with robotics and mechatronics systems in general can be achieved. The gestures will be continuously followed and can be directly mapped with commands of mechatronic systems such as start moving, stop moving, forward moving, backward moving etc. The proposed methodology relies on the finger gesture data acquisition, hand segmentation, fingertips localization/ identification and high-level feature extraction.},
booktitle = {Proceedings of the International Conference on Machine Vision and Applications},
pages = {13–17},
numpages = {5},
keywords = {mobile systems, Machine vision, gesture recognition},
location = {Singapore, Singapore},
series = {ICMVA 2018}
}

@article{10.1145/3005716,
author = {Shen, Zhaoyan and He, Zhijian and Li, Shuai and Wang, Qixin and Shao, Zili},
title = {A Multi-Quadcopter Cooperative Cyber-Physical System for Timely Air Pollution Localization},
year = {2017},
issue_date = {August 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3},
issn = {1539-9087},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3005716},
doi = {10.1145/3005716},
abstract = {We propose a cyber-physical system of unmanned quadcopters to locate air pollution sources in a timely manner. The system consists of a physical part and a cyber part. The physical part includes unmanned quadcopters equipped with multiple sensors. The cyber part carries out control laws. We simplify the control laws by decoupling the quadcopters’ horizontal-plane motion control from vertical motion control. To control the quadcopter’s horizontal-plane motions, we propose a controller that combines pollutant dynamics with quadcopter physics. To control the quadcopter’s vertical motions, we adopt an anti-windup proportional-integral (PI) controller. We further extend the horizontal-plane control laws from a single quadcopter to multiple quadcopters. The multi-quadcopter control laws are distributed and convergent. We implement a prototype quadcopter and carry out experiments to verify the vertical control laws. We also carry out simulations to evaluate the horizontal-plane control laws. With quadcopter parameters set commensurate with our prototype implementation’s, our simulations show that the control laws can drive quadcopters to locate pollution source(s) in a timely way.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {apr},
articleno = {70},
numpages = {23},
keywords = {Cyber-physical system, multi-quadcopter, pollutant dynamics, air pollution source, control laws}
}

@inproceedings{10.1109/ICSE.2019.00029,
author = {He, Zhijian and Chen, Yao and Huang, Enyan and Wang, Qixin and Pei, Yu and Yuan, Haidong},
title = {A System Identification Based Oracle for Control-CPS Software Fault Localization},
year = {2019},
publisher = {IEEE Press},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/ICSE.2019.00029},
doi = {10.1109/ICSE.2019.00029},
abstract = {Control-CPS software fault localization (SFL, aka bug localization) is of critical importance as bugs may cause major failures, even injuries/deaths. To locate the bugs in control-CPSs, SFL tools often demand many labeled ("correct"/"incorrect") source code execution traces as inputs. To label the correctness of these traces, we must judge the corresponding control-CPS physical trajectories' correctness. However, unlike discrete outputs, the boundaries between correct and incorrect physical trajectories are often vague. The mechanism (aka oracle) to judge the physical trajectories' correctness thus becomes a major challenge. So far, the ad hoc practice of "human oracles" is still widely used, whose qualities heavily depend on the human experts' expertise and availability. This paper proposes an oracle based on the well adopted autoregressive system identification (AR-SI). With proven success for controlling black-box physical systems, AR-SI is adapted by us to identify the buggy control-CPS as a black-box. We use this identification result as an oracle to judge the control-CPS's behaviors, and propose a methodology to prepare traces for control-CPS debugging. Comprehensive evaluations on classic control-CPSs with injected real-life and artificial bugs show that our proposed approach significantly outperforms the human oracle approach in SFL accuracy (recall) and latency, and in oracle false positive/negative rates. Our approach also helps discover a new real-life bug in a consumer-grade control-CPS.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {116–127},
numpages = {12},
keywords = {debug, testing, cyber-physical system, oracle},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/3397166.3413467,
author = {Ucar, Seyhan and Higuchi, Takamasa and Wang, Chang-Heng and Deveaux, Duncan and H\"{a}rri, J\'{e}r\^{o}me and Altintas, Onur},
title = {Vehicular Knowledge Networking and Application to Risk Reasoning},
year = {2020},
isbn = {9781450380157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3397166.3413467},
doi = {10.1145/3397166.3413467},
abstract = {Vehicles are expected to generate and consume an increasing amount of data, but how to perform risk reasoning over relevant data is still not yet solved. Location, time of day and driver behavior change the risk dynamically and make risk assessment challenging. This paper introduces a new paradigm, transferring information from raw sensed data to knowledge and explores the knowledge of risk reasoning through vehicular maneuver conflicts. In particular, we conduct a simulation study to analyze the driving data and extract the knowledge of risky road users and risky locations. We use knowledge to facilitate reduced volume and share it through a Vehicular Knowledge Network (VKN) for better traffic planning and safer driving.},
booktitle = {Proceedings of the Twenty-First International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing},
pages = {351–356},
numpages = {6},
keywords = {vehicular knowledge networking, knowledge, risk reasoning},
location = {Virtual Event, USA},
series = {Mobihoc '20}
}

@article{10.1145/2882966,
author = {Anagnostopoulos, Christos and Hadjiefthymiades, Stathes and Kolomvatsos, Kostas},
title = {Accurate, Dynamic, and Distributed Localization of Phenomena for Mobile Sensor Networks},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {1550-4859},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2882966},
doi = {10.1145/2882966},
abstract = {We present a robust, dynamic scheme for the automatic self-deployment and relocation of mobile sensor nodes (e.g., unmanned ground vehicles, robots) around areas where phenomena take place. Our scheme aims (i) to sense environmental contextual parameters and accurately capture the spatiotemporal evolution of a certain phenomenon (e.g., fire, air contamination) and (ii) to fully automate the deployment process by letting nodes relocate, self-organize (and self-reorganize), and optimally cover the focus area. Our intention is to “opportunistically” modify the previous placement of nodes to attain high-quality phenomenon monitoring. The required intelligence is fully distributed within the mobile sensor network so the deployment algorithm is executed incrementally by different nodes. The presented algorithm adopts the Particle Swarm Optimization technique, which yields very promising results as reported in the article (performance assessment). Our findings show that the proposed algorithm captures a certain phenomenon with very high accuracy while maintaining the networkwide energy expenditure at low levels. Random occurrences of similar phenomena put stress upon the algorithm which manages to react promptly and efficiently manage the available sensing resources in the broader setting.},
journal = {ACM Trans. Sen. Netw.},
month = {apr},
articleno = {9},
numpages = {59},
keywords = {Mobile sensor networks, phenomenon localization, particle swarm optimization, computational intelligence, self-reorganization, automatic node deployment}
}

@inproceedings{10.5555/3306127.3332104,
author = {Bondi, Elizabeth and Oh, Hoon and Xu, Haifeng and Fang, Fei and Dilkina, Bistra and Tambe, Milind},
title = {Using Game Theory in Real Time in the Real World: A Conservation Case Study},
year = {2019},
isbn = {9781450363099},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {In the real world, real-time data are now widely available, especially in security domains. Security cameras, aerial imagery, and even social media keep defenders informed when protecting important events, locations, and people. Further, advances in artificial intelligence have led to tools that can interpret these data automatically. Game theoretic models, for example, have shown great success in security. However, most of them ignore real-time information. In this paper, we demonstrate the potential to use real-time information from imagery to better inform our decisions in game theoretic models for security. As a concrete example, a conservation group called Air Shepherd uses conservation drones equipped with thermal infrared cameras to locate poachers at night and alert park rangers. They have also used lights aboard the drones, or signaled, to warn poachers of their presence, which often deters the poachers. We propose a system that (i) allocates drones and humans strategically throughout a protected area, (ii) detects poachers in the thermal infrared videos recorded by the conservation drones flying through the protected area in the predetermined location, and (iii) recommends moving to the location and/or signaling to the poacher that a patroller is nearby depending on real-time detections. View the demonstration: http://bit.ly/aamas19-demo-bondi-et-al.},
booktitle = {Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {2336–2338},
numpages = {3},
keywords = {uncertainty, computational sustainability, security games, unmanned aerial vehicles, sensors},
location = {Montreal QC, Canada},
series = {AAMAS '19}
}

@inproceedings{10.1145/3439961.3439987,
author = {J\'{u}nior, Luiz Cavamura and Belgamo, Anderson and Mendon\c{c}a, Vin\'{\i}cius Rafael Lobo de and Vincenzi, Auri Marcelo Rizzo},
title = {WarningsFIX: A Recommendation System for Prioritizing Warnings Generated by Automated Static Analyzers},
year = {2020},
isbn = {9781450389235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3439961.3439987},
doi = {10.1145/3439961.3439987},
abstract = { Recommendation systems try to guide the users in carrying out a task providing them with useful information about it. Considering the context of software development, programs are ever-increasing, making it difficult to conduct a detailed verification and validation. Automated static analyzers help to detect possible faults on software products earlier and quickly but, in general, the issue maybe a false-positive warning. In this sense, this work presents and evaluates a recommendation system, called WarningsFIX (WFX), which combines several static analyzers aim at: i) Expand the possible fault domain approached by each static analysis tool increasing the range of warnings types covered, allowing the concentration of a higher number of true-positive warnings. ii) Establish different prioritization strategies of warnings aiming at suggesting for reviewers first analyze the ones with a higher chance of being true-positive. WFX organizes the warnings information via treemaps considering four levels of abstraction: program, package, class, and line. The nodes of the treemap on each level may be classified by three different prioritization strategies based on the number of warnings, the number of tools, and the suspicions rate. The use of these strategies enables the reviewer to handle the set of warnings in a coordinated way depending on the cost and time constraint available. We perform a feasibility study to evaluate the WFX effectiveness whose results shown that: i) WFX was able to improve the results obtained from combined static analyzers to 44% of the analyzed programs, concentrating for them a greater number of true-positives. ii) WFX, depending on the adopted prioritization strategy, improved from 67.5% to 55% the ranking of lines with real bugs when compared with the list of warnings provided by the automated static analyzers without the WFX support.},
booktitle = {19th Brazilian Symposium on Software Quality},
articleno = {26},
numpages = {10},
keywords = {static analysis, WarningsFix, software visualization, warnings prioritization, recommendation system},
location = {S\~{a}o Lu\'{\i}s, Brazil},
series = {SBQS'20}
}

@article{10.1145/3441692,
author = {Huang, Huawei and Kong, Wei and Zhou, Sicong and Zheng, Zibin and Guo, Song},
title = {A Survey of State-of-the-Art on Blockchains: Theories, Modelings, and Tools},
year = {2021},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3441692},
doi = {10.1145/3441692},
abstract = {To draw a roadmap of current research activities of the blockchain community, we first conduct a brief overview of state-of-the-art blockchain surveys published in the past 5 years. We found that those surveys are basically studying the blockchain-based applications, such as blockchain-assisted Internet of Things (IoT), business applications, security-enabled solutions, and many other applications in diverse fields. However, we think that a comprehensive survey toward the essentials of blockchains by exploiting the state-of-the-art theoretical modelings, analytic models, and useful experiment tools is still missing. To fill this gap, we perform a thorough survey by identifying and classifying the most recent high-quality research outputs that are closely related to the theoretical findings and essential mechanisms of blockchain systems and networks. Several promising open issues are also summarized for future research directions. We hope this survey can serve as a useful guideline for researchers, engineers, and educators about the cutting-edge development of blockchains in the perspectives of theories, modelings, and tools.},
journal = {ACM Comput. Surv.},
month = {mar},
articleno = {44},
numpages = {42},
keywords = {Blockchain, analytic models, experiment tools, theoretical modelings}
}

@article{10.1145/3378026,
author = {Li, Yonggang and Liu, Chunping and Ji, Yi and Gong, Shengrong and Xu, Haibao},
title = {Spatio-Temporal Deep Residual Network with Hierarchical Attentions for Video Event Recognition},
year = {2020},
issue_date = {April 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2s},
issn = {1551-6857},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3378026},
doi = {10.1145/3378026},
abstract = {Event recognition in surveillance video has gained extensive attention from the computer vision community. This process still faces enormous challenges due to the tiny inter-class variations that are caused by various facets, such as severe occlusion, cluttered backgrounds, and so forth. To address these issues, we propose a spatio-temporal deep residual network with hierarchical attentions (STDRN-HA) for video event recognition. In the first attention layer, the ResNet fully connected feature guides the Faster R-CNN feature to generate object-based attention (O-attention) for target objects. In the second attention layer, the O-attention further guides the ResNet convolutional feature to yield the holistic attention (H-attention) in order to perceive more details of the occluded objects and the global background. In the third attention layer, the attention maps use the deep features to obtain the attention-enhanced features. Then, the attention-enhanced features are input into a deep residual recurrent network, which is used to mine more event clues from videos. Furthermore, an optimized loss function named softmax-RC is designed, which embeds the residual block regularization and center loss to solve the vanishing gradient in a deep network and enlarge the distance between inter-classes. We also build a temporal branch to exploit the long- and short-term motion information. The final results are obtained by fusing the outputs of the spatial and temporal streams. Experiments on the four realistic video datasets, CCV, VIRAT 1.0, VIRAT 2.0, and HMDB51, demonstrate that the proposed method has good performance and achieves state-of-the-art results.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = {jun},
articleno = {62},
numpages = {21},
keywords = {surveillance video, deep residual recurrent network, spatio-temporal, hierarchical attention, Event recognition}
}

@inproceedings{10.1145/3371049.3371065,
author = {Foster, Marc and Agcayazi, Tarik and Agcayazi, Talha and Wu, Tianfu and Gruen, Margaret and Roberts, David L. and Bozkurt, Alper},
title = {Preliminary Evaluation of Dog-Drone Technological Interfaces: Challenges and Opportunities},
year = {2019},
isbn = {9781450376938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3371049.3371065},
doi = {10.1145/3371049.3371065},
abstract = {In many of the applications involving working canines, such as search and rescue operations and agriculture, drones are increasing in ubiquity. There has been some recent focus on training dogs to follow or interact with drones in such applications. From the Animal Computer Interaction (ACI) perspective, drones have the potential to monitor the dog's welfare when handlers are not in close proximity in such harsh environments. Our on going work has focused on canine welfare through the use of on-body sensors for monitoring behavior, physiology, and the micro-environment dogs are in. We have also used these technologies to explore computer-assisted training of canines and more recently included drones to complement these to assess the macro-environment dogs are working in. This work discusses the challenges and opportunities we learned during our efforts to include drones for computer-assisted interactions with working dogs. We focus on the enabling technology and it's implications for ACI when dogs and drones work together.},
booktitle = {Proceedings of the Sixth International Conference on Animal-Computer Interaction},
articleno = {16},
numpages = {5},
keywords = {wearable EKG, activity level, animal-computer interaction, ACI, dog-drone interaction, computer vision},
location = {Haifa, Israel},
series = {ACI'19}
}

@article{10.1145/3486612,
author = {Bu, Tiancong and Yan, Kaige and Tan, Jingweijia},
title = {Towards Fine-Grained Online Adaptive Approximation Control for Dense SLAM on Embedded GPUs},
year = {2021},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {2},
issn = {1084-4309},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3486612},
doi = {10.1145/3486612},
abstract = {Dense SLAM is an important application on an embedded environment. However, embedded platforms usually fail to provide enough computation resources for high-accuracy real-time dense SLAM, even with high-parallelism architecture such as GPUs. To tackle this problem, one solution is to design proper approximation techniques for dense SLAM on embedded GPUs. In this work, we propose two novel approximation techniques, critical data identification and redundant branch elimination. We also analyze the error characteristics of the other two techniques—loop skipping and thread approximation. Then, we propose SLaPP, an online adaptive approximation controller, which aims to control the error to be under an acceptable threshold. The evaluation shows SLaPP can achieve 2.0\texttimes{} performance speedup and 30% energy saving on average compared to the case without approximation.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {nov},
articleno = {11},
numpages = {19},
keywords = {embedded GPUs, Approximate computing, online adaptive control, dense SLAM}
}

@inproceedings{10.1145/2632856.2632949,
author = {Teng, Xiuhua and Cao, Liujuan and Wang, Cheng and Chen, Ziyi},
title = {Vehicle Detection from Remote Sensing Image Based on Superpixel Segmentation and Image Enhancement},
year = {2014},
isbn = {9781450328104},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2632856.2632949},
doi = {10.1145/2632856.2632949},
abstract = {Automatic vehicle detection from high-resolution remote sensing image is a challenging topic. While there have been some studies on this topic in recent years, a fast and robust approach is yet to be found, especially when facing the scenario of low color contrast. In this paper, a new vehicle detection approach is proposed. First, superpixel-based segmentation is used to identify potential vehicle regions to speed up the detection and improve the accuracy. Then, an image enhancement method is also proposed, which greatly improves the segmentation results. Support vector machine is used to classification with features extracted by HOG descriptor. According to the experiments, by combining with superpixel segmentation and the image enhancement, the speed of the vehicle detection is improved with approximately an order of magnitude. Also, in case of low contrast remote sensing images, the detection accuracy can be also greatly improved, with much less false positives and false negatives.},
booktitle = {Proceedings of International Conference on Internet Multimedia Computing and Service},
pages = {140–143},
numpages = {4},
keywords = {SVM, HOG, Vehicle Detection, Superpixel, Image Sharpening},
location = {Xiamen, China},
series = {ICIMCS '14}
}

@inproceedings{10.1145/3450550.3465349,
author = {Serpiva, Valerii and Karmanova, Ekaterina and Fedoseev, Aleksey and Perminov, Stepan and Tsetserukou, Dzmitry},
title = {DronePaint: Swarm Light Painting with DNN-Based Gesture Recognition},
year = {2021},
isbn = {9781450383646},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3450550.3465349},
doi = {10.1145/3450550.3465349},
abstract = {We propose a novel human-swarm interaction system, allowing the user to directly control a swarm of drones in a complex environment through trajectory drawing with a hand gesture interface based on the DNN-based gesture recognition. The developed CV-based system allows the user to control the swarm behavior without additional devices through human gestures and motions in real-time, providing convenient tools to change the swarm’s shape and formation. The two types of interaction were proposed and implemented to adjust the swarm hierarchy: trajectory drawing and free-form trajectory generation control. The experimental results revealed a high accuracy of the gesture recognition system (99.75%), allowing the user to achieve relatively high precision of the trajectory drawing (mean error of 5.6 cm in comparison to 3.1 cm by mouse drawing) over the three evaluated trajectory patterns. The proposed system can be potentially applied in complex environment exploration, spray painting using drones, and interactive drone shows, allowing users to create their own art objects by drone swarms. },
booktitle = {ACM SIGGRAPH 2021 Emerging Technologies},
articleno = {6},
numpages = {4},
keywords = {Light Painting, Deep Neural Network, Gesture Recognition, Human-Drone Interaction},
location = {Virtual Event, USA},
series = {SIGGRAPH '21}
}

@inproceedings{10.5555/3398761.3398799,
author = {Dann, Michael and Thangarajah, John and Yao, Yuan and Logan, Brian},
title = {Intention-Aware Multiagent Scheduling},
year = {2020},
isbn = {9781450375184},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {The Belief Desire Intention (BDI) model of agency is a popular and mature paradigm for designing and implementing multiagent systems. There are several agent implementation platforms that follow the BDI model. In BDI systems, the agents typically have to pursue multiple goals, and often concurrently. The way in which the agents commit to achieving their goals forms their intentions. There has been much work on scheduling the intentions of agents. However, most of this work has focused on scheduling the intentions of a single agent with no awareness and consideration of other agents that may be operating in the same environment. They schedule the intentions of the single-agent in order to maximise the total number of goals achieved. In this work, we investigate techniques for scheduling the intentions of an agent in a multiagent setting, where an agent is aware (or partially aware) of the intentions of other agents in the environment. We use a Monte Carlo Tree Search (MCTS) based approach and show that our intention-aware scheduler generates better outcomes in cooperative, neutral (selfish) and adversarial settings than the state-of-the-art schedulers that do not consider other agents' intentions.},
booktitle = {Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {285–293},
numpages = {9},
keywords = {intention scheduling, multiagent scheduling, goal reasoning},
location = {Auckland, New Zealand},
series = {AAMAS '20}
}

@inbook{10.1145/3474085.3475315,
author = {Fan, Chenyou and Hu, Junjie and Huang, Jianwei},
title = {Few-Shot Multi-Agent Perception},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3474085.3475315},
abstract = {We study few-shot learning (FSL) under multi-agent scenarios, in which participating agents only have local scarce labeled data and need to collaborate to predict query data labels. Though each of the agents, such as drones and robots, has minimal communication and computation capability, we aim at designing coordination schemes such that they can collectively perceive the environment accurately and efficiently. We propose a novel metric-based multi-agent FSL framework which has three main components: an efficient communication mechanism that propagates compact and fine-grained query feature maps from query agents to support agents; an asymmetric attention mechanism that computes region-level attention weights between query and support feature maps; and a metric-learning module which calculates the image-level relevance between query and support data fast and accurately. Through analysis and extensive numerical studies, we demonstrate that our approach can save communication and computation costs and significantly improve performance in both visual and acoustic perception tasks such as face identification, semantic segmentation, and sound genre recognition.},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {1712–1720},
numpages = {9}
}

@inproceedings{10.1109/SEAMS.2017.7,
author = {Moreno, Gabriel A. and Strichman, Ofer and Chaki, Sagar and Vaisman, Radislav},
title = {Decision-Making with Cross-Entropy for Self-Adaptation},
year = {2017},
isbn = {9781538615508},
publisher = {IEEE Press},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/SEAMS.2017.7},
doi = {10.1109/SEAMS.2017.7},
abstract = {Approaches to decision-making in self-adaptive systems are increasingly becoming more effective at managing the target system by taking into account more elements of the decision problem that were previously ignored. These approaches have to solve complex optimization problems at run time, and even though they have been shown to be suitable for different kinds of systems, their time complexity can make them excessively slow for systems that have a large adaptation-relevant state space, or that require a tight control loop driven by fast decisions. In this paper we present an approach to speed up complex proactive latency-aware self-adaptation decisions, using the cross-entropy (CE) method for combinatorial optimization. The CE method is an any-time algorithm based on random sampling from the solution space, and is not guaranteed to find an optimal solution. Nevertheless, our experiments using two very different systems show that in practice it finds solutions that are close to optimum even when its running time is restricted to a fraction of a second, attaining speedups of up to 40 times over the previous fastest solution approach.},
booktitle = {Proceedings of the 12th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {90–101},
numpages = {12},
keywords = {optimization, decision-making, cross-entropy method, self-adaptive systems},
location = {Buenos Aires, Argentina},
series = {SEAMS '17}
}

@inproceedings{10.1145/3312614.3312643,
author = {Kouloumpris, Andreas and Theocharides, Theocharis and Michael, Maria K.},
title = {Metis: Optimal Task Allocation Framework for the Edge/Hub/Cloud Paradigm},
year = {2019},
isbn = {9781450366403},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3312614.3312643},
doi = {10.1145/3312614.3312643},
abstract = {Increased demands for real-time decision support and data analytics facilitate the need of performing significant computing away from the cloud and onto the IoT devices. In this paper, we propose Metis, a mathematical programming based framework, able to deliver an optimal task allocation when targeting a specific performance metric. Metis is currently suitable for systems which consist of an edge node, an intermediate node and the cloud infrastructure, but can be expanded to multi-Edge/Hub systems. Evaluation results using a real-life use-case scenario demonstrate that Metis provides the optimal task allocation by minimizing the overall latency of the system while taking into consideration the application's specific requirements and resource constraints of each computational unit.},
booktitle = {Proceedings of the International Conference on Omni-Layer Intelligent Systems},
pages = {128–133},
numpages = {6},
keywords = {Optimal Task Allocation, Edge-Hub-Cloud Paradigm, Real-life use-case Scenario, Mathematical Programming},
location = {Crete, Greece},
series = {COINS '19}
}

@inproceedings{10.1145/3322276.3322318,
author = {Robb, David A. and Lopes, Jos\'{e} and Padilla, Stefano and Laskov, Atanas and Chiyah Garcia, Francisco J. and Liu, Xingkun and Scharff Willners, Jonatan and Valeyrie, Nicolas and Lohan, Katrin and Lane, David and Patron, Pedro and Petillot, Yvan and Chantler, Mike J. and Hastie, Helen},
title = {Exploring Interaction with Remote Autonomous Systems Using Conversational Agents},
year = {2019},
isbn = {9781450358507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3322276.3322318},
doi = {10.1145/3322276.3322318},
abstract = {Autonomous vehicles and robots are increasingly being deployed to remote, dangerous environments in the energy sector, search and rescue and the military. As a result, there is a need for humans to interact with these robots to monitor their tasks, such as inspecting and repairing offshore wind-turbines. Conversational Agents can improve situation awareness and transparency, while being a hands-free medium to communicate key information quickly and succinctly. As part of our user-centered design of such systems, we conducted an in-depth immersive qualitative study of twelve marine research scientists and engineers, interacting with a prototype Conversational Agent. Our results expose insights into the appropriate content and style for the natural language interaction and, from this study, we derive nine design recommendations to inform future Conversational Agent design for remote autonomous systems.},
booktitle = {Proceedings of the 2019 on Designing Interactive Systems Conference},
pages = {1543–1556},
numpages = {14},
keywords = {trust, remote autonomous systems, multimodal interfaces, natural language interfaces, explainable ai, transparency},
location = {San Diego, CA, USA},
series = {DIS '19}
}

@inproceedings{10.1145/3229434.3229443,
author = {Mauriello, Matthew Louis and McNally, Brenna and Buntain, Cody and Bagalkotkar, Sapna and Kushnir, Samuel and Froehlich, Jon E.},
title = {A Large-Scale Analysis of YouTube Videos Depicting Everyday Thermal Camera Use},
year = {2018},
isbn = {9781450358989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3229434.3229443},
doi = {10.1145/3229434.3229443},
abstract = {The emergence of low-cost thermographic cameras for mobile devices provides users with new practical and creative prospects. While recent work has investigated how novices use thermal cameras for energy auditing tasks in structured activities, open questions remain about "in the wild" use and the challenges or opportunities therein. To study these issues, we analyzed 1,000 YouTube videos depicting everyday uses of thermal cameras by non-professional, novice users. We coded the videos by content area, identified whether common misconceptions regarding thermography were present, and analyzed questions within the comment threads. To complement this analysis, we conducted an online survey of the YouTube content creators to better understand user behaviors and motivations. Our findings characterize common thermographic use cases, extend discussions surrounding the challenges novices encounter, and have implications for the design of future thermographic systems and tools.},
booktitle = {Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services},
articleno = {37},
numpages = {12},
keywords = {social media, sustainable HCI, thermal cameras, user-generated content, thermography, OSNs, YouTube},
location = {Barcelona, Spain},
series = {MobileHCI '18}
}

@inproceedings{10.1145/3012258.3012276,
author = {Cui, Zhe and Lu, Wenkai and Liu, Jinlin},
title = {Real-Time Industrial Vision System for Automatic Product Surface Inspection},
year = {2016},
isbn = {9781450347617},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3012258.3012276},
doi = {10.1145/3012258.3012276},
abstract = {Product surface inspection plays a significant role in industrial aspects. Large industrial manufacturing requires such inspection procedure of high speed and accuracy at a fairly reasonable cost, which is precisely the demand automatic surface inspection systems are applied to meet. In this paper, we have constructed a vision system prototype employing image processing and pattern recognition approaches to classify those defective products automatically. Our algorithm first collects products images, then send them to preprocess. After that, we implement pattern extraction based on Fourier-Mellin transform, and classify the product patterns based on principle component analysis as well as support vector regression. The prototype has proven itself reliable through reaching accuracy of more than 90%.},
booktitle = {Proceedings of the 2016 8th International Conference on Information Management and Engineering},
pages = {93–97},
numpages = {5},
keywords = {pattern recognition, industrial vision, surface inspection, image processing},
location = {Istanbul, Turkey},
series = {ICIME 2016}
}

@inproceedings{10.1145/3302505.3310067,
author = {Zhang, Daniel (Yue) and Rashid, Tahmid and Li, Xukun and Vance, Nathan and Wang, Dong},
title = {HeteroEdge: Taming the Heterogeneity of Edge Computing System in Social Sensing},
year = {2019},
isbn = {9781450362832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3302505.3310067},
doi = {10.1145/3302505.3310067},
abstract = {Social sensing has emerged as a new sensing application paradigm where measurements about the physical world are collected from humans or devices on their behalf. The advent of edge computing pushes the frontier of computation, service, and data along the cloud-to-IoT continuum. The merge of these two technical trends (referred to as Social Sensing based Edge Computing or SSEC) generates a set of new research challenges. One critical issue in SSEC is the heterogeneity of the edge where the edge devices owned by human sensors often have diversified computational power, runtime environments, network interfaces, and hardware equipment. Such heterogeneity poses significant challenges in the resource management of SSEC systems. Examples include masking the pronounced heterogeneity across diverse platforms, allocating interdependent tasks with complex requirements on devices with different resources, and adapting to the dynamic and diversified context of the edge devices. In this paper, we develop a new resource management framework, HeteroEdge, to address the heterogeneity of SSEC by 1) providing a uniform interface to abstract the device details (hardware, operating system, CPU); and 2) effectively allocating the social sensing tasks to the heterogeneous edge devices. We implemented HeteroEdge on a real-world edge computing testbed that consists of heterogeneous edge devices (Jetson TX2, TK1, Raspberry Pi3, and personal computer). Evaluations based on two real-world social sensing applications show that the HeteroEdge achieved up to 42% decrease in end-to-end delay for the application and 22% more energy savings compared to the state-of-the-art baselines.},
booktitle = {Proceedings of the International Conference on Internet of Things Design and Implementation},
pages = {37–48},
numpages = {12},
keywords = {social sensing, edge computing, resource management, heterogeneity, supply chain},
location = {Montreal, Quebec, Canada},
series = {IoTDI '19}
}

@inproceedings{10.1145/1878537.1878592,
author = {Stagl, Kevin C.},
title = {A Path Forward: Advancing the Science of UxV Operations &amp; Training},
year = {2010},
isbn = {9781450300698},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/1878537.1878592},
doi = {10.1145/1878537.1878592},
abstract = {Overseas Contingency Operations (OCO), shifting geopolitical alliances and technological advances are driving the U.S. military to invoke new concepts of warfare such as joint, coalition and network centric warfare. These concepts are realized in modern political confrontations where multinational coalition partners and governmental agencies routinely rely on UxV vehicle and sensor operators to swiftly support joint operations in multiple, concurrent foreign theaters. In fact, the Department of Defense (DoD) allocated $3.5B just for Unmanned Aircraft Systems (UASs) in 2009; nearly 10% of the total budget for all aircraft procurements.},
booktitle = {Proceedings of the 2010 Spring Simulation Multiconference},
articleno = {53},
numpages = {5},
location = {Orlando, Florida},
series = {SpringSim '10}
}

@inproceedings{10.1145/3359996.3364239,
author = {Dissanayake, Vipula and Elvitigala, Don Samitha and Zhang, Haimo and Weerasinghe, Chamod and Nanayakkara, Suranga},
title = {CompRate: Power Efficient Heart Rate and Heart Rate Variability Monitoring on Smart Wearables},
year = {2019},
isbn = {9781450370011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3359996.3364239},
doi = {10.1145/3359996.3364239},
abstract = {Currently, smartwatches are equipped with Photoplethysmography (PPG) sensors to measure Heart Rate (HR) and Heart Rate Variability (HRV). However, PPG sensors consume considerably high energy, making it impractical to monitor HR &amp; HRV continuously for an extended period. Utilising low power accelerometers to estimate HR has been broadly discussed in previous decades. Inspired by prior work, we introduce CompRate, an alternative method to measure HR continuously for an extended period in low-intensity physical activities. CompRate model calibrated for individual users only has an average performance of Root Mean Squared Error (RMSE) 1.58 Beats Per Minute (BPM). Further, CompRate used 3.75 times less energy compared to the built-in PPG sensor. We also demonstrate that CompRate model can be extended to predict HRV. We will demonstrate CompRate in several application scenarios: self-awareness of fatigue and just-in-time interruption while driving; enabling teachers to be aware of students’ mental effort during a learning activity; and the broadcasting of the location of live victims in a disaster situation.},
booktitle = {25th ACM Symposium on Virtual Reality Software and Technology},
articleno = {16},
numpages = {8},
keywords = {Low Power, Heart Rate, Inferring Stress, Accelerometer, Heart Rate Variability, Photoplethysmography},
location = {Parramatta, NSW, Australia},
series = {VRST '19}
}

@article{10.1145/3243157.3243168,
author = {Calyam, Prasad and Ricart, Glenn},
title = {Research and Infrastructure Challenges for Applications and Services in the Year 2021},
year = {2018},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {3},
issn = {0146-4833},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3243157.3243168},
doi = {10.1145/3243157.3243168},
abstract = {The Applications and Services in the Year 2021 workshop was successfully organized on January 27--28, 2016 in Washington DC through funding support from the National Science Foundation (NSF). The goal of the workshop was to foster discussions that bring together applications researchers in multidisciplinary areas, and developers/operators of research infrastructures at both national, regional, university and city levels. Discussions were organized to identify grand challenge applications and obtain the community voice and consensus on the key issues relating to applications and services that might be delivered by advanced infrastructures in the decade beginning in 2020. The timing and organization for the workshop is significant because today's digital infrastructure is undergoing deep technological changes and new paradigms are rapidly taking shape in both the core and edge domains that pose fundamental challenges. The key outcomes of the discussions were targeted to enhance the quality of peoples' lives while addressing important national priorities, leveraging today's cutting edge applications such as the Internet of Things, Big Data Analytics, Robotics, The Industrial Internet, and Immersive Virtual/Augmented Reality. This report summarizes the workshop efforts to bring together diverse groups for delivering targeted short/long talks, sharing latest advances, and identifying gaps that exist in the community for 'research' and 'infrastructure' needs that require future NSF funding.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = {jul},
articleno = {11},
numpages = {5}
}

@inproceedings{10.5555/3237383.3237425,
author = {Alqahtani, Sarra and Riley, Ian and Taylor, Samuel and Gamble, Rose and Mailler, Roger},
title = {MTL Robustness for Path Planning with A*},
year = {2018},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Maintaining the safety of an autonomous drone while it executes a mission is a primary concern in presence of fixed and mobile enemies. Path planning using A* fails to deliver a feasible, safe plan when a drone has resource limitations in such environments. Enhancing A* with constraint optimization techniques may improve outcomes, but significantly increases path determination time. We define Robust A* (RA*) that introduces the use of a safety margin to maximize the robustness of the drone to meet mission requirements while managing resource restrictions. We rely on a theory of robustness based on Metric Temporal Logic (MTL) as applied to offline verification and online control of hybrid systems. By satisfying the predefined MTL constraints, RA* dynamically defines a safety margin between the drone and an enemy, while constraining the margin size given the drone's resources. The safety margin creates a robust neighborhood around the dynamically generated path. The robust neighborhood holds all valid trajectories within the current world state. When the world state changes, RA* first examines the robust neighborhood to find a valid trajectory before initiating the path re-planning. We evaluate RA* using the Rassim simulator. The results show that the algorithm generates faster and safer paths than the classical A* in the presence of moving enemies..},
booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {247–255},
numpages = {9},
keywords = {robustness, path planning, metric temporal logic, a*},
location = {Stockholm, Sweden},
series = {AAMAS '18}
}

@article{10.1109/TNET.2018.2878287,
author = {Chowdhery, Aakanksha and Jamieson, Kyle},
title = {Aerial Channel Prediction and User Scheduling in Mobile Drone Hotspots},
year = {2018},
issue_date = {December 2018},
publisher = {IEEE Press},
volume = {26},
number = {6},
issn = {1063-6692},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/TNET.2018.2878287},
doi = {10.1109/TNET.2018.2878287},
abstract = {In this paper, we investigate the aerial wireless channel, where a moving drone is deployed to stream content to a set of mobile clients on the ground over a small cell size. Experimental traces collected over more than twenty flights with multiple clients suggest that drone mobility in lateral or vertical path leads to time-selective and frequency-selective wireless channel for a low-altitude drone. The resulting aerial wireless channel can be predicted reasonably well when we model the channel based on the constructive and destructive interference patterns between the line-of-sight path and other propagation paths via nearby reflectors. We propose a novel channel prediction approach to predict the subcarrier SNRs for all clients as drone moves and a novel scheduling approach to select the subset of clients that maximize the network utility using the predicted SNRs. We have implemented the proposed approach on a commodity 802.11n chipset and evaluated in the field over twenty flights, each serving up to 17 live clients. Experiments demonstrate, for the first time, the feasibility of tracking and predicting the aerial Wi-Fi channel, resulting in up to a 56% increase in overall throughput as compared to the conventional 802.11n hotspot, while maintaining fairness across clients.},
journal = {IEEE/ACM Trans. Netw.},
month = {dec},
pages = {2679–2692},
numpages = {14}
}

@article{10.1145/3306346.3322942,
author = {Dong, Siyan and Xu, Kai and Zhou, Qiang and Tagliasacchi, Andrea and Xin, Shiqing and Nie\ss{}ner, Matthias and Chen, Baoquan},
title = {Multi-Robot Collaborative Dense Scene Reconstruction},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {4},
issn = {0730-0301},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3306346.3322942},
doi = {10.1145/3306346.3322942},
abstract = {We present an autonomous scanning approach which allows multiple robots to perform collaborative scanning for dense 3D reconstruction of unknown indoor scenes. Our method plans scanning paths for several robots, allowing them to efficiently coordinate with each other such that the collective scanning coverage and reconstruction quality is maximized while the overall scanning effort is minimized. To this end, we define the problem as a dynamic task assignment and introduce a novel formulation based on Optimal Mass Transport (OMT). Given the currently scanned scene, a set of task views are extracted to cover scene regions which are either unknown or uncertain. These task views are assigned to the robots based on the OMT optimization. We then compute for each robot a smooth path over its assigned tasks by solving an approximate traveling salesman problem. In order to showcase our algorithm, we implement a multi-robot auto-scanning system. Since our method is computationally efficient, we can easily run it in real time on commodity hardware, and combine it with online RGB-D reconstruction approaches. In our results, we show several real-world examples of large indoor environments; in addition, we build a benchmark with a series of carefully designed metrics for quantitatively evaluating multi-robot autoscanning. Overall, we are able to demonstrate high-quality scanning results with respect to reconstruction quality and scanning efficiency, which significantly outperforms existing multi-robot exploration systems.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {84},
numpages = {16},
keywords = {autonomous scene reconstruction, multi-robot, optimal mass transport, collaborative reconstruction}
}

@inproceedings{10.1145/2063576.2063721,
author = {Li, Hui and Bhowmick, Sourav S. and Sun, Aixin},
title = {CASINO: Towards Conformity-Aware Social Influence Analysis in Online Social Networks},
year = {2011},
isbn = {9781450307178},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2063576.2063721},
doi = {10.1145/2063576.2063721},
abstract = {Social influence analysis in online social networks is the study of people's influence by analyzing the social interactions between individuals. There have been increasing research efforts to understand the influence propagation phenomenon due to its importance to information dissemination among others. Despite the progress achieved by state-of-the-art social influence analysis techniques, a key limitation of these techniques is that they only utilize positive interactions (e.g., agreement, trust) between individuals, ignoring two equally important factors, namely, negative relationships (e.g., distrust, disagreement) between individuals and conformity of people, which refers to a person's inclination to be influenced. In this paper, we propose a novel algorithm CASINO (Conformity-Aware Social INfluence cOmputation) to study the interplay between influence and conformity of each individual. Given a social network, CASINO first extracts a set of topic-based subgraphs where each subgraph depicts the social interactions associated with a specific topic. Then it optionally labels the edges (relationships) between individuals with positive or negative signs. Finally, it computes the influence and conformity indices of each individual in each signed topic-based subgraph. Our empirical study with several real-world social networks demonstrates superior effectiveness and accuracy of CASINO compared to state-of-the-art methods. Furthermore, we revealed several interesting characteristics of "influentials" and "conformers" in these networks.},
booktitle = {Proceedings of the 20th ACM International Conference on Information and Knowledge Management},
pages = {1007–1012},
numpages = {6},
keywords = {topic-based subgraphs, signed edge, influence, social networks, twitter, conformity},
location = {Glasgow, Scotland, UK},
series = {CIKM '11}
}

@inproceedings{10.1145/3325693.3325704,
author = {Lv, Zhi and Wang, ZhongFeng and Lv, Yi and Yuan, MingZhe},
title = {An AirSea Manta-Ray Robot in 5G OGCE},
year = {2019},
isbn = {9781450362467},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3325693.3325704},
doi = {10.1145/3325693.3325704},
abstract = {Based on the fifth generation of mobile communication (5G), 5G open grid computing environment (5G OGCE), in order to realize the exploitation and utilization of marine resources and energy, this paper presents an air and sea robot, which can fly and dive in the sea and air at the same time, and it is called an air and sea (air-sea) Manta Ray robot. Its purpose is to carry out resources and energy exploitation and development under the support of 5G OGCE, and perform the tasks of different air and sea operation areas: (1) quickly implement underwater operations, operate in the underwater operation area during long voyage, monitor deep-sea oil exploitation, exploitation and utilization of seabed resources and energy, seabed rare earth and combustible ice mining and ocean current power generation; (2) fly over the ocean during long voyage to track the migration of Marine organisms and Marine migratory birds; (3) build manned air-sea vehicle that can act as the personnel and material transfer machine for the undersea space station. When undersea mining is carried out, it can complete adaptive control, and monitor the work of undersea underwater equipment. (4) Perform work and assignments in a large area of underwater and above water, as well as over the sea, in a swarm working mode and distributed working mode. By using the control-cloud architecture in 5G OGCE, the exploitation of seabed resources and the production of submarine intelligent factories centered on the submarine space station can be realized.},
booktitle = {Proceedings of the 2019 2nd International Conference on Service Robotics Technologies},
pages = {63–67},
numpages = {5},
keywords = {underwater smart factory, air-sea manta-ray robot, robotics, 5G control-cloud, distributed artificial intelligence (Distributed AI), software architecture and engineering, underwater space station, 5G open grid computing environment (5G OGCE)},
location = {Beijing, China},
series = {ICSRT 2019}
}

@inproceedings{10.1145/3061639.3062201,
author = {Di Mauro, Alfio and Conti, Francesco and Benini, Luca},
title = {An Ultra-Low Power Address-Event Sensor Interface for Energy-Proportional Time-to-Information Extraction},
year = {2017},
isbn = {9781450349277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3061639.3062201},
doi = {10.1145/3061639.3062201},
abstract = {Internet-of-Things devices need sensors with low power footprint and capable of producing semantically rich data. Promising candidates are spiking sensors that use asynchronous Address-Event Representation (AER) carrying information within inter-spike times. To minimize the overhead of coupling AER sensors with off-the-shelf microcontrollers, we propose an FPGA-based methodology that i) tags the AER spikes with timestamps to make them carriable by standard interfaces (e.g. I2S, SPI); ii) uses a recursively divided clock generated on-chip by a pausable ring-oscillator, to reduce power while keeping accuracy above 97% on timestamps. We prototyped our methodology on a IGLOOnano AGLN250 FPGA, consuming less than 4.5mW under a 550kevt/s spike rate (i.e. a noisy environment), and down to 50uW in absence of spikes.},
booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},
articleno = {75},
numpages = {6},
location = {Austin, TX, USA},
series = {DAC '17}
}

@inproceedings{10.1145/3014812.3014868,
author = {Woodley, Alan and Chappell, Timothy and Geva, Shlomo and Nayak, Richi},
title = {Using Web Services to Fuse Remote Sensing and Multimedia Data Repositories},
year = {2017},
isbn = {9781450347686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3014812.3014868},
doi = {10.1145/3014812.3014868},
abstract = {Remote sensing data is becoming readily available on the Web. However, remote sensing data is not as widely used as other web data. Here, we explore how a fusion of remote sensing data with web paradigms and data would benefit the remote sensing community. We present a framework to achieve this fusion which extends on previous research by: 1) being generic, so that it can be used in any situation; 2) automatic, so that it requires almost no input from the user, and 3) archival, allowing access to decades of remote sensing and web information. We demonstrate our framework with a proof-of-concept prototype.},
booktitle = {Proceedings of the Australasian Computer Science Week Multiconference},
articleno = {54},
numpages = {8},
keywords = {remote sensing, text retrieval, data fusion, web services},
location = {Geelong, Australia},
series = {ACSW '17}
}

@article{10.1145/2379799.2379803,
author = {Liang, Jinling and Wang, Zidong and Shen, Bo and Liu, Xiaohui},
title = {Distributed State Estimation in Sensor Networks with Randomly Occurring Nonlinearities Subject to Time Delays},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
issn = {1550-4859},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2379799.2379803},
doi = {10.1145/2379799.2379803},
abstract = {This article is concerned with a new distributed state estimation problem for a class of dynamical systems in sensor networks. The target plant is described by a set of differential equations disturbed by a Brownian motion and randomly occurring nonlinearities (RONs) subject to time delays. The RONs are investigated here to reflect network-induced randomly occurring regulation of the delayed states on the current ones. Through available measurement output transmitted from the sensors, a distributed state estimator is designed to estimate the states of the target system, where each sensor can communicate with the neighboring sensors according to the given topology by means of a directed graph. The state estimation is carried out in a distributed way and is therefore applicable to online application. By resorting to the Lyapunov functional combined with stochastic analysis techniques, several delay-dependent criteria are established that not only ensure the estimation error to be globally asymptotically stable in the mean square, but also guarantee the existence of the desired estimator gains that can then be explicitly expressed when certain matrix inequalities are solved. A numerical example is given to verify the designed distributed state estimators.},
journal = {ACM Trans. Sen. Netw.},
month = {nov},
articleno = {4},
numpages = {18},
keywords = {stability in the mean square, distributed state estimation, time delays, dynamical system, Sensor network, randomly occurring nonlinearity (RON)}
}

@article{10.1145/3478513.3480483,
author = {Zhang, Han and Yao, Yucong and Xie, Ke and Fu, Chi-Wing and Zhang, Hao and Huang, Hui},
title = {Continuous Aerial Path Planning for 3D Urban Scene Reconstruction},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {6},
issn = {0730-0301},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3478513.3480483},
doi = {10.1145/3478513.3480483},
abstract = {We introduce the first path-oriented drone trajectory planning algorithm, which performs continuous (i.e., dense) image acquisition along an aerial path and explicitly factors path quality into an optimization along with scene reconstruction quality. Specifically, our method takes as input a rough 3D scene proxy and produces a drone trajectory and image capturing setup, which efficiently yields a high-quality reconstruction of the 3D scene based on three optimization objectives: one to maximize the amount of 3D scene information that can be acquired along the entirety of the trajectory, another to optimize the scene capturing efficiency by maximizing the scene information that can be acquired per unit length along the aerial path, and the last one to minimize the total turning angles along the aerial path, so as to reduce the number of sharp turns. Our search scheme is based on the rapidly-exploring random tree framework, resulting in a final trajectory as a single path through the search tree. Unlike state-of-the-art works, our joint optimization for view selection and path planning is performed in a single step. We comprehensively evaluate our method not only on benchmark virtual datasets as in existing works but also on several large-scale real urban scenes. We demonstrate that the continuous paths optimized by our method can effectively reduce onsite acquisition cost using drones, while achieving high-fidelity 3D reconstruction, compared to existing planning methods and oblique photography, a mature and popular industry solution.},
journal = {ACM Trans. Graph.},
month = {dec},
articleno = {225},
numpages = {15},
keywords = {rapidly-exploring random trees, urban scene reconstruction, information gain, aerial path planning}
}

@inproceedings{10.1145/3302506.3310396,
author = {Demetri, Silvia and Z\'{u}\~{n}iga, Marco and Picco, Gian Pietro and Kuipers, Fernando and Bruzzone, Lorenzo and Telkamp, Thomas},
title = {Automated Estimation of Link Quality for LoRa: A Remote Sensing Approach},
year = {2019},
isbn = {9781450362849},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3302506.3310396},
doi = {10.1145/3302506.3310396},
abstract = {Many research and industrial communities are betting on LoRa to provide reliable, long-range communication for the Internet of Things. This new radio technology, however, provides widely heterogeneous coverage; a LoRa link may span hundreds of meters or tens of kilometers, depending on the surrounding environment. This high variability is not captured by popular channel models for LoRa, and on-site measurements---a common alternative---are impractical due to the large geographical areas involved.We propose a novel, automated approach to estimate the coverage of LoRa gateways prior to deployment and without on-site measurements. We achieve this goal by combining free, readily-available multispectral images from remote sensing with the right channel model. Our processing toolchain automatically classifies the type of environment (e.g., buildings, trees, or open fields) traversed by a link, with high accuracy (&gt;90%) and spatial resolution (10X10m2). We use this information to explain the attenuation observed in experiments. As signal attenuation is not well captured by popular channel models, we focus on the Okumura-Hata empirical model, hitherto largely unexplored for LoRa, and show that i) it yields estimates very close to our observations, and ii) we can use our toolchain to automatically select and configure its parameters. A validation on 8,000+ samples from a real dataset shows that our automated approach predicts the expected signal power within a ~10dBm error, against the 20--40dBm of popular channel models.},
booktitle = {Proceedings of the 18th International Conference on Information Processing in Sensor Networks},
pages = {145–156},
numpages = {12},
keywords = {LPWAN, multispectral images, LoRa, link quality, remote sensing},
location = {Montreal, Quebec, Canada},
series = {IPSN '19}
}

@inproceedings{10.1145/3172944.3172946,
author = {Penney, Sean and Dodge, Jonathan and Hilderbrand, Claudia and Anderson, Andrew and Simpson, Logan and Burnett, Margaret},
title = {Toward Foraging for Understanding of StarCraft Agents: An Empirical Study},
year = {2018},
isbn = {9781450349451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3172944.3172946},
doi = {10.1145/3172944.3172946},
abstract = {Assessing and understanding intelligent agents is a difficult task for users that lack an AI background. A relatively new area, called "Explainable AI," is emerging to help address this problem, but little is known about how users would forage through information an explanation system might offer. To inform the development of Explainable AI systems, we conducted a formative study -- using the lens of Information Foraging Theory -- into how experienced users foraged in the domain of StarCraft to assess an agent. Our results showed that participants faced difficult foraging problems. These foraging problems caused participants to entirely miss events that were important to them, reluctantly choose to ignore actions they did not want to ignore, and bear high cognitive, navigation, and information costs to access the information they needed.},
booktitle = {23rd International Conference on Intelligent User Interfaces},
pages = {225–237},
numpages = {13},
keywords = {starcraft, intelligent agents, explainable ai, intelligibility, information foraging, content analysis, video games},
location = {Tokyo, Japan},
series = {IUI '18}
}

@inproceedings{10.1145/3208806.3208816,
author = {Discher, S\"{o}ren and Richter, Rico and D\"{o}llner, J\"{u}rgen},
title = {A Scalable WebGL-Based Approach for Visualizing Massive 3D Point Clouds Using Semantics-Dependent Rendering Techniques},
year = {2018},
isbn = {9781450358002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3208806.3208816},
doi = {10.1145/3208806.3208816},
abstract = {3D point cloud technology facilitates the automated and highly detailed digital acquisition of real-world environments such as assets, sites, cities, and countries; the acquired 3D point clouds represent an essential category of geodata used in a variety of geoinformation applications and systems. In this paper, we present a web-based system for the interactive and collaborative exploration and inspection of arbitrary large 3D point clouds. Our approach is based on standard WebGL on the client side and is able to render 3D point clouds with billions of points. It uses spatial data structures and level-of-detail representations to manage the 3D point cloud data and to deploy out-of-core and web-based rendering concepts. By providing functionality for both, thin-client and thick-client applications, the system scales for client devices that are vastly different in computing capabilities. Different 3D point-based rendering techniques and post-processing effects are provided to enable task-specific and data-specific filtering and highlighting, e.g., based on per-point surface categories or temporal information. A set of interaction techniques allows users to collaboratively work with the data, e.g., by measuring distances and areas, by annotating, or by selecting and extracting data subsets. Additional value is provided by the system's ability to display additional, context-providing geodata alongside 3D point clouds and to integrate task-specific processing and analysis operations. We have evaluated the presented techniques and the prototype system with different data sets from aerial, mobile, and terrestrial acquisition campaigns with up to 120 billion points to show their practicality and feasibility.},
booktitle = {Proceedings of the 23rd International ACM Conference on 3D Web Technology},
articleno = {19},
numpages = {9},
keywords = {3D point clouds, point-based rendering, web-based rendering},
location = {Pozna\'{n}, Poland},
series = {Web3D '18}
}

@inproceedings{10.1145/3313237.3313297,
author = {He, Chenyuan and Wan, Yan and Xie, Junfei},
title = {Spatiotemporal Scenario Data-Driven Decision for the Path Planning of Multiple UASs},
year = {2019},
isbn = {9781450367035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3313237.3313297},
doi = {10.1145/3313237.3313297},
abstract = {Modern systems operate in spaiotemporally evolving environments, and similar spatiotemporal scenarios are likely to be tied with similar decision solutions. This paper develops a spatiotemporal scenario data-driven decision solution for the path planning of multiple unmanned aircraft systems (UASs) in wind fields. The solution utilities offline operations, online operations and sptaiotemporal scenario data queries to provide an efficient path planning decision for multiple UASs. The solution features the use of similarity between spatiotemporal scenarios to retrieve offline decisions as the initial solution for online fine tuning, which significantly shortens the online decision time. A fast query algorithm that exploits the correlation of spatiotemporal scenarios is utilized in the decision framework to quickly retrieve the best offline decisions. The solution is demonstrated using simulation studies, and can be utilized in other decision applications where spaiotemporal environments play a crucial role in the decision process and the allowed decision time window is short.},
booktitle = {Proceedings of the Fourth Workshop on International Science of Smart City Operations and Platforms Engineering},
pages = {7–12},
numpages = {6},
keywords = {data driven decision-making, UAS traffic management, UAS path planning, query, spatiotemporal scenario data},
location = {Montreal, Quebec, Canada},
series = {SCOPE '19}
}

@inproceedings{10.1145/3443467.3443833,
author = {Tian, Ye and Pei, Huaxin and Zhang, Yi},
title = {A Strategy for Making Lane-Change Decision Based on Improved Driving Risk Field and BP Neural Network},
year = {2020},
isbn = {9781450387811},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3443467.3443833},
doi = {10.1145/3443467.3443833},
abstract = {In the Intelligent Transportation System (ITS), the driving safety of intelligent connected vehicles is a focal point and the hot topic. In the face of the increasingly complex road traffic environment, in order to assess the driving risk in real time and accurately, we propose an improved driving risk field with ellipse modification formula. Compared with the existing research, the improved model can take into account the safety differences in different directions of the road. On this foundation, a strategy for making lane-change decision based on back propagation (BP) neural network is proposed. The experiment results based on 'Mirror Traffic' data set show that the method is accurate, reliable and feasible for making lane-change decision, which further verifies the feasibility of the improved driving risk field.},
booktitle = {Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering},
pages = {669–675},
numpages = {7},
keywords = {Driving risk field, 'Mirror Traffic' data set, BP neural network, Driving safety, Lane-change decision},
location = {Xiamen, China},
series = {EITCE 2020}
}

@inproceedings{10.1145/3067695.3076081,
author = {Garcia, Dennis and Lugo, Anthony Erb and Hemberg, Erik and O'Reilly, Una-May},
title = {Investigating Coevolutionary Archive Based Genetic Algorithms on Cyber Defense Networks},
year = {2017},
isbn = {9781450349390},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3067695.3076081},
doi = {10.1145/3067695.3076081},
abstract = {We introduce a new cybersecurity project named RIVALS. RIVALS will assist in developing network defense strategies through modeling adversarial network attack and defense dynamics. RIVALS will focus on peer-to-peer networks and use coevolutionary algorithms. In this contribution, we describe RIVALS' current suite of coevolutionary algorithms that use archiving to maintain progressive exploration and that support different solution concepts as fitness metrics. We compare and contrast their effectiveness by executing a standard coevolutionary benchmark (Compare-on-one) and RIVALS simulations on 3 different network topologies. Currently, we model denial of service (DOS) attack strategies by the attacker selecting one or more network servers to disable for some duration. Defenders can choose one of three different network routing protocols: shortest path, flooding and a peer-to-peer ring overlay to try to maintain their performance. Attack completion and resource cost minimization serve as attacker objectives. Mission completion and resource cost minimization are the reciprocal defender objectives. Our experiments show that existing algorithms either sacrifice execution speed or forgo the assurance of consistent results. rIPCA, our adaptation of a known coevolutionary algorithm named IPC A, is able to more consistently produce high quality results, albeit without IPCA's guarantees for results with monotonically increasing performance, without sacrificing speed.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1455–1462},
numpages = {8},
keywords = {network, genetic algorithms, coevolution, evolutionary algorithms, cybersecurity},
location = {Berlin, Germany},
series = {GECCO '17}
}


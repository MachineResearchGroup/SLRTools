TY  - EJOU
AU  - Kung, Chien-Chun
TI  - Study on Consulting Air Combat Simulation of Cluster UAV Based on Mixed Parallel Computing Framework of Graphics Processing Unit
T2  - Electronics

PY  - 2018
VL  - 7
IS  - 9
SN  - 2079-9292

AB  - This paper combines matrix game theory with negotiating theory and uses U-solution to study the framework of the consulting air combat of UAV cluster. The processes to determine the optimal strategy in this paper follow three points: first, the UAV cluster are grouped into fleets; second, the best paring for the joint operations of the fleet member with the enemy fleet members are calculated; thirdly, consultations within the fleet are conducted to discuss the problems of optimal tactic, roles of main/assistance, and situational assessment within the fleet. In order to improve the computing efficiency of the framework, this article explores the use of the NVIDIA graphics processor programmed through MATLAB mixed C++/CUDA toolkit to accelerate the calculations of equations of motion of unmanned aerial vehicles, the prediction of superiority values and U values, computations of consultation, the evaluation of situational assessment and the optimal strategies. The effectiveness evaluation of GPGPU and CPU can be observed by the simulation results. When the number of team air combat is small, the CPU alone has better efficiency; however, when the number of air combat clusters exceeds 6 to 6, the architecture presented in this article can provide higher performance improvements and run faster than optimized CPU-only code.
KW  - GPGPU
KW  - MATLAB/CUDA
KW  - matrix game
KW  - consulting air combat
KW  - UAV cluster
KW  - maneuver decision-making
DO  - 10.3390/electronics7090160
ER  -
TY  - EJOU
AU  - Jafari, Mohammad
AU  - Xu, Hao
TI  - Intelligent Control for Unmanned Aerial Systems with System Uncertainties and Disturbances Using Artificial Neural Network
T2  - Drones

PY  - 2018
VL  - 2
IS  - 3
SN  - 2504-446X

AB  - Stabilizing the Unmanned Aircraft Systems (UAS) under complex environment including system uncertainties, unknown noise and/or disturbance is so challenging. Therefore, this paper proposes an adaptive neural network based intelligent control method to overcome these challenges. Based on a class of artificial neural network, named Radial Basis Function (RBF) networks an adaptive neural network controller is designed. To handle the unknown dynamics and uncertainties in the system, firstly, we develop a neural network based identifier. Then, a neural network based controller is generated based on both the identified model of the system and the linear or nonlinear controller. To ensure the stability of the system during its online training phase, the linear or nonlinear controller is utilized. The learning capability of the proposed intelligent controller makes it a promising approach to take system uncertainties, noises and/or disturbances into account. The satisfactory performance of the proposed intelligent controller is validated based on the computer based simulation results of a benchmark UAS with system uncertainties and disturbances, such as wind gusts disturbance.
KW  - Unmanned Aircraft Systems (UAS)
KW  - artificial neural network
KW  - intelligent control
KW  - adaptive control
DO  - 10.3390/drones2030030
ER  -
TY  - EJOU
AU  - Lee, Jungshin
AU  - Bang, Hyochoong
TI  - A Robust Terrain Aided Navigation Using the Rao-Blackwellized Particle Filter Trained by Long Short-Term Memory Networks
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 9
SN  - 1424-8220

AB  - Terrain-aided navigation (TAN) is a technology that estimates the position of the vehicle by comparing the altitude measured by an altimeter and height from the digital elevation model (DEM). The particle filter (PF)-based TAN has been commonly used to obtain stable real-time navigation solutions in cases where the unmanned aerial vehicle (UAV) operates at a high altitude. Even though TAN performs well on rough and unique terrains, its performance degrades in flat and repetitive terrains. In particular, in the case of PF-based TAN, there has been no verified technique for deciding its terrain validity. Therefore, this study designed a Rao-Blackwellized PF (RBPF)-based TAN, used long short-term memory (LSTM) networks to endure flat and repetitive terrains, and trained the noise covariances and measurement model of RBPF. LSTM is a modified recurrent neural network (RNN), which is an artificial neural network that recognizes patterns from time series data. Using this, this study tuned the noise covariances and measurement model of RBPF to minimize the navigation errors in various flight trajectories. This paper designed a TAN algorithm based on combining RBPF and LSTM and confirmed that it can enable a more precise navigation performance than conventional RBPF based TAN through simulations.
KW  - terrain-aided navigation (TAN)
KW  - Rao-Blackwellized particle filter (RBPF)
KW  - long short-term memory (LSTM)
KW  - terrain validity check
KW  - digital elevation model (DEM)
KW  - inertial navigation system (INS)
DO  - 10.3390/s18092886
ER  -
TY  - EJOU
AU  - Ullah, Fahim
AU  - Sepasgozar, Samad M. E.
AU  - Wang, Changxin
TI  - A Systematic Review of Smart Real Estate Technology: Drivers of, and Barriers to, the Use of Digital Disruptive Technologies and Online Platforms
T2  - Sustainability

PY  - 2018
VL  - 10
IS  - 9
SN  - 2071-1050

AB  - Real estate needs to improve its adoption of disruptive technologies to move from traditional to smart real estate (SRE). This study reviews the adoption of disruptive technologies in real estate. It covers the applications of nine such technologies, hereby referred to as the Big9. These are: drones, the internet of things (IoT), clouds, software as a service (SaaS), big data, 3D scanning, wearable technologies, virtual and augmented realities (VR and AR), and artificial intelligence (AI) and robotics. The Big9 are examined in terms of their application to real estate and how they can furnish consumers with the kind of information that can avert regrets. The review is based on 213 published articles. The compiled results show the state of each technology&rsquo;s practice and usage in real estate. This review also surveys dissemination mechanisms, including smartphone technology, websites and social media-based online platforms, as well as the core components of SRE: sustainability, innovative technology and user centredness. It identifies four key real estate stakeholders&mdash;consumers, agents and associations, government and regulatory authorities, and complementary industries&mdash;and their needs, such as buying or selling property, profits, taxes, business and/or other factors. Interactions between these stakeholders are highlighted, and the specific needs that various technologies address are tabulated in the form of a what, who and how analysis to highlight the impact that the technologies have on key stakeholders. Finally, stakeholder needs as identified in the previous steps are matched theoretically with six extensions of the traditionally accepted technology adoption model (TAM), paving the way for a smoother transition to technology-based benefits for consumers. The findings pertinent to the Big9 technologies in the form of opportunities, potential losses and exploitation levels (OPLEL) analyses highlight the potential utilisation of each technology for addressing consumers&rsquo; needs and minimizing their regrets. Additionally, the tabulated findings in the form of what, how and who links the Big9 technologies to core consumers&rsquo; needs and provides a list of resources needed to ensure proper information dissemination to the stakeholders. Such high-quality information can bridge the gap between real estate consumers and other stakeholders and raise the state of the industry to a level where its consumers have fewer or no regrets. The study, being the first to explore real estate technologies, is limited by the number of research publications on the SRE technologies that has been compensated through incorporation of online reports.
KW  - smart real estate (SRE)
KW  - smart real estate management (SREM)
KW  - real estate technologies
KW  - Big9 disruptive technologies
KW  - online technology dissemination platforms
KW  - technology adoption
KW  - decision regrets
DO  - 10.3390/su10093142
ER  -
TY  - EJOU
AU  - Sa, Inkyu
AU  - Popović, Marija
AU  - Khanna, Raghav
AU  - Chen, Zetao
AU  - Lottes, Philipp
AU  - Liebisch, Frank
AU  - Nieto, Juan
AU  - Stachniss, Cyrill
AU  - Walter, Achim
AU  - Siegwart, Roland
TI  - WeedMap: A Large-Scale Semantic Weed Mapping Framework Using Aerial Multispectral Imaging and Deep Neural Network for Precision Farming
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - The ability to automatically monitor agricultural fields is an important capability in precision farming, enabling steps towards more sustainable agriculture. Precise, high-resolution monitoring is a key prerequisite for targeted intervention and the selective application of agro-chemicals. The main goal of this paper is developing a novel crop/weed segmentation and mapping framework that processes multispectral images obtained from an unmanned aerial vehicle (UAV) using a deep neural network (DNN). Most studies on crop/weed semantic segmentation only consider single images for processing and classification. Images taken by UAVs often cover only a few hundred square meters with either color only or color and near-infrared (NIR) channels. Although a map can be generated by processing single segmented images incrementally, this requires additional complex information fusion techniques which struggle to handle high fidelity maps due to their computational costs and problems in ensuring global consistency. Moreover, computing a single large and accurate vegetation map (e.g., crop/weed) using a DNN is non-trivial due to difficulties arising from: (1) limited ground sample distances (GSDs) in high-altitude datasets, (2) sacrificed resolution resulting from downsampling high-fidelity images, and (3) multispectral image alignment. To address these issues, we adopt a stand sliding window approach that operates on only small portions of multispectral orthomosaic maps (tiles), which are channel-wise aligned and calibrated radiometrically across the entire map. We define the tile size to be the same as that of the DNN input to avoid resolution loss. Compared to our baseline model (i.e., SegNet with 3 channel RGB (red, green, and blue) inputs) yielding an area under the curve (AUC) of [background=0.607, crop=0.681, weed=0.576], our proposed model with 9 input channels achieves [0.839, 0.863, 0.782]. Additionally, we provide an extensive analysis of 20 trained models, both qualitatively and quantitatively, in order to evaluate the effects of varying input channels and tunable network hyperparameters. Furthermore, we release a large sugar beet/weed aerial dataset with expertly guided annotations for further research in the fields of remote sensing, precision agriculture, and agricultural robotics.
KW  - precision farming
KW  - weed management
KW  - multispectral imaging
KW  - semantic segmentation
KW  - deep neural network
KW  - unmanned aerial vehicle
KW  - remote sensing
DO  - 10.3390/rs10091423
ER  -
TY  - EJOU
AU  - Choi, Jongseong
AU  - Yeum, Chul M.
AU  - Dyke, Shirley J.
AU  - Jahanshahi, Mohammad R.
TI  - Computer-Aided Approach for Rapid Post-Event Visual Evaluation of a Building Façade
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 9
SN  - 1424-8220

AB  - After a disaster strikes an urban area, damage to the fa&ccedil;ades of a building may produce dangerous falling hazards that jeopardize pedestrians and vehicles. Thus, building fa&ccedil;ades must be rapidly inspected to prevent potential loss of life and property damage. Harnessing the capacity to use new vision sensors and associated sensing platforms, such as unmanned aerial vehicles (UAVs) would expedite this process and alleviate spatial and temporal limitations typically associated with human-based inspection in high-rise buildings. In this paper, we have developed an approach to perform rapid and accurate visual inspection of building fa&ccedil;ades using images collected from UAVs. An orthophoto corresponding to any reasonably flat region on the building (e.g., a fa&ccedil;ade or building side) is automatically constructed using a structure-from-motion (SfM) technique, followed by image stitching and blending. Based on the geometric relationship between the collected images and the constructed orthophoto, high-resolution region-of-interest are automatically extracted from the collected images, enabling efficient visual inspection. We successfully demonstrate the capabilities of the technique using an abandoned building of which a fa&ccedil;ade has damaged building components (e.g., window panes or external drainage pipes).
KW  - post-event visual evaluation
KW  - image localization
KW  - orthophoto generation
KW  - unmanned aerial vehicle
DO  - 10.3390/s18093017
ER  -
TY  - EJOU
AU  - Kose, Utku
TI  - An Ant-Lion Optimizer-Trained Artificial Neural Network System for Chaotic Electroencephalogram (EEG) Prediction
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 9
SN  - 2076-3417

AB  - The prediction of future events based on available time series measurements is a relevant research area specifically for healthcare, such as prognostics and assessments of intervention applications. A measure of brain dynamics, electroencephalogram time series, are routinely analyzed to obtain information about current, as well as future, mental states, and to detect and diagnose diseases or environmental factors. Due to their chaotic nature, electroencephalogram time series require specialized techniques for effective prediction. The objective of this study was to introduce a hybrid system developed by artificial intelligence techniques to deal with electroencephalogram time series. Both artificial neural networks and the ant-lion optimizer, which is a recent intelligent optimization technique, were employed to comprehend the related system and perform some prediction applications over electroencephalogram time series. According to the obtained findings, the system can successfully predict the future states of target time series and it even outperforms some other hybrid artificial neural network-based systems and alternative time series prediction approaches from the literature.
KW  - artificial neural networks
KW  - ant-lion optimizer
KW  - time series prediction
KW  - electroencephalogram
KW  - healthcare
KW  - chaotic time series
KW  - artificial intelligence
DO  - 10.3390/app8091613
ER  -
TY  - EJOU
AU  - Cui, Zhaoyu
AU  - Kerekes, John P.
TI  - Potential of Red Edge Spectral Bands in Future Landsat Satellites on Agroecosystem Canopy Green Leaf Area Index Retrieval
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - Vegetation biophysical parameter retrieval is an important earth remote sensing system application. In this paper, we studied the potential impact of the addition of new spectral bands in the red edge region in future Landsat satellites on agroecosystem canopy green leaf area index (LAI) retrieval. The test data were simulated from SPARC &lsquo;03 field campaign HyMap hyperspectral data. Three retrieval approaches were tested: empirical regression based on vegetation index, physical model-based look-up-table (LUT) inversion, and machine learning. The results of all three approaches showed that a potential new spectral band located between the Landsat-8 Operational Land Imager (OLI) red and NIR bands slightly improved the agroecosystem green LAI retrieval accuracy (R2 of 0.787 vs. 0.810 for vegetation index approach, 0.806 vs. 0.828 for LUT inversion approach, and 0.925 vs. 0.933 for machine learning approach). The results of this work are consistent with the conclusions from previous research on the value of Sentinel-2 red edge bands for agricultural green LAI retrieval.
KW  - Landsat
KW  - red edge band
KW  - leaf area index
KW  - vegetation indices
KW  - look-up-table inversion
DO  - 10.3390/rs10091458
ER  -
TY  - EJOU
AU  - Xu, Yongyang
AU  - Xie, Zhong
AU  - Feng, Yaxing
AU  - Chen, Zhanlong
TI  - Road Extraction from High-Resolution Remote Sensing Imagery Using Deep Learning
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - The road network plays an important role in the modern traffic system; as development occurs, the road structure changes frequently. Owing to the advancements in the field of high-resolution remote sensing, and the success of semantic segmentation success using deep learning in computer version, extracting the road network from high-resolution remote sensing imagery is becoming increasingly popular, and has become a new tool to update the geospatial database. Considering that the training dataset of the deep convolutional neural network will be clipped to a fixed size, which lead to the roads run through each sample, and that different kinds of road types have different widths, this work provides a segmentation model that was designed based on densely connected convolutional networks (DenseNet) and introduces the local and global attention units. The aim of this work is to propose a novel road extraction method that can efficiently extract the road network from remote sensing imagery with local and global information. A dataset from Google Earth was used to validate the method, and experiments showed that the proposed deep convolutional neural network can extract the road network accurately and effectively. This method also achieves a harmonic mean of precision and recall higher than other machine learning and deep learning methods.
KW  - road network extraction
KW  - deep learning
KW  - pyramid attention
KW  - global attention
KW  - high resolution
DO  - 10.3390/rs10091461
ER  -
TY  - EJOU
AU  - Xavier, Shereen S.
AU  - Coffin, Alisa W.
AU  - Olson, Dawn M.
AU  - Schmidt, Jason M.
TI  - Remotely Estimating Beneficial Arthropod Populations: Implications of a Low-Cost Small Unmanned Aerial System
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - Studies show that agricultural land requires investment in the habitat management of non-cropped areas to support healthy beneficial arthropods and the ecosystem services they provide. In a previous small plot study, we manually counted blooms over the season, and found that plots providing greater numbers of flowers supported significantly higher pollinator populations over that of spontaneous weed plots. Here, we examined the potential of deploying an inexpensive small unmanned aerial vehicle (UAV) as a tool to remotely estimate floral resources and corresponding pollinator populations. Data were collected from previously established native wildflower plots in 19 locations on the University of Georgia experimental farms in South Georgia, USA. A UAV equipped with a lightweight digital camera was deployed to capture images of the flowers during the months of June and September 2017. Supervised image classification using a geographic information system (GIS) was carried out on the acquired images, and classified images were used to evaluate the floral area. The floral area obtained from the images positively correlated with the floral counts gathered from the quadrat samples. Furthermore, the floral area derived from imagery significantly predicted pollinator populations, with a positive correlation indicating that plots with greater area of blooming flowers contained higher numbers of pollinators.
KW  - UAV floral detection
KW  - image classification
KW  - floral provisioning
KW  - habitat management
KW  - pollinators
KW  - agricultural buffers
KW  - floral area
KW  - long term agroecosystem research (LTAR)
DO  - 10.3390/rs10091485
ER  -
TY  - EJOU
AU  - Pinheiro Lisboa, Izaias
AU  - Melo Damian, Júnior
AU  - Roberto Cherubin, Maurício
AU  - Silva Barros, Pedro P.
AU  - Ricardo Fiorio, Peterson
AU  - Cerri, Carlos C.
AU  - Eduardo Pellegrino Cerri, Carlos
TI  - Prediction of Sugarcane Yield Based on NDVI and Concentration of Leaf-Tissue Nutrients in Fields Managed with Straw Removal
T2  - Agronomy

PY  - 2018
VL  - 8
IS  - 9
SN  - 2073-4395

AB  - The total or partial removal of sugarcane (Saccharum spp. L.) straw for bioenergy production may deplete soil quality and consequently affect negatively crop yield. Plants with lower yield potential may present lower concentration of leaf-tissue nutrients, which in turn changes light reflectance of canopy in different wavelengths. Therefore, vegetation indexes, such as the normalized difference vegetation index (NDVI) associated with concentration of leaf-tissue nutrients could be a useful tool for monitoring potential sugarcane yield changes under straw management. Two sites in S&atilde;o Paulo state, Brazil were utilized to evaluate the potential of NDVI for monitoring sugarcane yield changes imposed by different straw removal rates. The treatments were established with 0%, 25%, 50%, and 100% straw removal. The data used for the NDVI calculation was obtained using satellite images (CBERS-4) and hyperspectral sensor (FieldSpec Spectroradiometer, Malvern Panalytical, Almelo, Netherlands). Besides sugarcane yield, the concentration of the leaf-tissue nutrients (N, P, K, Ca, and S) were also determined. The NDVI efficiently predicted sugarcane yield under different rates of straw removal, with the highest performance achieved with NDVI derived from satellite images than hyperspectral sensor. In addition, leaf-tissue N and P concentrations were also important parameters to compose the prediction models of sugarcane yield. A prediction model approach based on data of NDVI and leaf-tissue nutrient concentrations may help the Brazilian sugarcane sector to monitor crop yield changes in areas intensively managed for bioenergy production.
KW  - crop residue management
KW  - remote sensing
KW  - satellite images
KW  - hyperspectral sensor
KW  - vegetation index
KW  - yield monitoring
DO  - 10.3390/agronomy8090196
ER  -
TY  - EJOU
AU  - Palace, Michael
AU  - Herrick, Christina
AU  - DelGreco, Jessica
AU  - Finnell, Daniel
AU  - Garnello, Anthony J.
AU  - McCalley, Carmody
AU  - McArthur, Kellen
AU  - Sullivan, Franklin
AU  - Varner, Ruth K.
TI  - Determining Subarctic Peatland Vegetation Using an Unmanned Aerial System (UAS)
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - Rising global temperatures tied to increases in greenhouse gas emissions are impacting high latitude regions, leading to changes in vegetation composition and feedbacks to climate through increased methane (CH4) emissions. In subarctic peatlands, permafrost collapse has led to shifts in vegetation species on landscape scales with high spatial heterogeneity. Our goal was to provide a baseline for vegetation distribution related to permafrost collapse and changes in biogeochemical processes. We collected unmanned aerial system (UAS) imagery at Stordalen Mire, Abisko, Sweden to classify vegetation cover types. A series of digital image processing routines were used to generate texture attributes within the image for the purpose of characterizing vegetative cover types. An artificial neural network (ANN) was developed to classify the image. The ANN used all texture variables and color bands (three spectral bands and six metrics) to generate a probability map for each of the eight cover classes. We used the highest probability for a class at each pixel to designate the cover type in the final map. Our overall misclassification rate was 32%, while omission and commission error by class ranged from 0% to 50%. We found that within our area of interest, cover classes most indicative of underlying permafrost (hummock and tall shrub) comprised 43.9% percent of the landscape. Our effort showed the capability of an ANN applied to UAS high-resolution imagery to develop a classification that focuses on vegetation types associated with permafrost status and therefore potentially changes in greenhouse gas exchange. We also used a method to examine the multiple probabilities representing cover class prediction at the pixel level to examine model confusion. UAS image collection can be inexpensive and a repeatable avenue to determine vegetation change at high latitudes, which can further be used to estimate and scale corresponding changes in CH4 emissions.
KW  - unmanned aerial system (UAS)
KW  - artificial neural network
KW  - mire vegetation
KW  - Stordalen
KW  - tundra
KW  - drone
KW  - classification
DO  - 10.3390/rs10091498
ER  -
TY  - EJOU
AU  - Chen, Lin
AU  - Ren, Chunying
AU  - Zhang, Bai
AU  - Wang, Zongming
AU  - Xi, Yanbiao
TI  - Estimation of Forest Above-Ground Biomass by Geographically Weighted Regression and Machine Learning with Sentinel Imagery
T2  - Forests

PY  - 2018
VL  - 9
IS  - 10
SN  - 1999-4907

AB  - Accurate forest above-ground biomass (AGB) is crucial for sustaining forest management and mitigating climate change to support REDD+ (reducing emissions from deforestation and forest degradation, plus the sustainable management of forests, and the conservation and enhancement of forest carbon stocks) processes. Recently launched Sentinel imagery offers a new opportunity for forest AGB mapping and monitoring. In this study, texture characteristics and backscatter coefficients of Sentinel-1, in addition to multispectral bands, vegetation indices, and biophysical variables of Sentinal-2, based on 56 measured AGB samples in the center of the Changbai Mountains, China, were used to develop biomass prediction models through geographically weighted regression (GWR) and machine learning (ML) algorithms, such as the artificial neural network (ANN), support vector machine for regression (SVR), and random forest (RF). The results showed that texture characteristics and vegetation biophysical variables were the most important predictors. SVR was the best method for predicting and mapping the patterns of AGB in the study site with limited samples, whose mean error, mean absolute error, root mean square error, and correlation coefficient were 4 &times; 10&minus;3, 0.07, 0.08 Mg&middot;ha&minus;1, and 1, respectively. Predicted values of AGB from four models ranged from 11.80 to 324.12 Mg&middot;ha&minus;1, and those for broadleaved deciduous forests were the most accurate, while those for AGB above 160 Mg&middot;ha&minus;1 were the least accurate. The study demonstrated encouraging results in forest AGB mapping of the normal vegetated area using the freely accessible and high-resolution Sentinel imagery, based on ML techniques.
KW  - sentinel imagery
KW  - above-ground biomass
KW  - predictive mapping
KW  - machine learning
KW  - geographically weighted regression
DO  - 10.3390/f9100582
ER  -
TY  - EJOU
AU  - Theron, Andre
AU  - Engelbrecht, Jeanine
TI  - The Role of Earth Observation, with a Focus on SAR Interferometry, for Sinkhole Hazard Assessment
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - Sinkholes are global phenomena with significant consequences on the natural- and built environment. Significant efforts have been devoted to the assessment of sinkhole hazards to predict the spatial and temporal occurrence of future sinkholes as well as to detect small-scale deformation prior to collapse. Sinkhole hazard maps are created by considering the distribution of past sinkholes in conjunction with their geomorphic features, controlling conditions and triggering mechanisms. Quantitative risk assessment then involves the statistical analysis of sinkhole events in relation to these conditions with the aim of identifying high risk areas. Remote sensing techniques contribute to the field of sinkhole hazard assessment by providing tools for the population of sinkhole inventories and lend themselves to the monitoring of precursory deformation prior to sinkhole development. In this paper, we outline the background to sinkhole formation and sinkhole hazard assessment. We provide a review of earth observation techniques, both for the compilation of sinkhole inventories as well as the monitoring of precursors to sinkhole development. We discuss the advantages and limitations of these approaches and conclude by highlighting the potential role of radar interferometry in the early detection of sinkhole-induced instability resulting in a potential decrease in the risk to human lives and infrastructure by enabling proactive remediation.
KW  - sinkholes
KW  - geohazard
KW  - inventory
KW  - monitoring
KW  - prediction
KW  - SAR interferometry
DO  - 10.3390/rs10101506
ER  -
TY  - EJOU
AU  - Duarte-Carvajalino, Julio M.
AU  - Alzate, Diego F.
AU  - Ramirez, Andrés A.
AU  - Santa-Sepulveda, Juan D.
AU  - Fajardo-Rojas, Alexandra E.
AU  - Soto-Suárez, Mauricio
TI  - Evaluating Late Blight Severity in Potato Crops Using Unmanned Aerial Vehicles and Machine Learning Algorithms
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - This work presents quantitative prediction of severity of the disease caused by Phytophthora infestans in potato crops using machine learning algorithms such as multilayer perceptron, deep learning convolutional neural networks, support vector regression, and random forests. The machine learning algorithms are trained using datasets extracted from multispectral data captured at the canopy level with an unmanned aerial vehicle, carrying an inexpensive digital camera. The results indicate that deep learning convolutional neural networks, random forests and multilayer perceptron using band differences can predict the level of Phytophthora infestans affectation on potato crops with acceptable accuracy.
KW  - UAV
KW  - remote sensing
KW  - Phytophthora infestans
KW  - multispectral
KW  - neural networks
KW  - deep learning
DO  - 10.3390/rs10101513
ER  -
TY  - EJOU
AU  - Pflanz, Michael
AU  - Nordmeyer, Henning
AU  - Schirrmann, Michael
TI  - Weed Mapping with UAS Imagery and a Bag of Visual Words Based Image Classifier
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - Weed detection with aerial images is a great challenge to generate field maps for site-specific plant protection application. The requirements might be met with low altitude flights of unmanned aerial vehicles (UAV), to provide adequate ground resolutions for differentiating even single weeds accurately. The following study proposed and tested an image classifier based on a Bag of Visual Words (BoVW) framework for mapping weed species, using a small unmanned aircraft system (UAS) with a commercial camera on board, at low flying altitudes. The image classifier was trained with support vector machines after building a visual dictionary of local features from many collected UAS images. A window-based processing of the models was used for mapping the weed occurrences in the UAS imagery. The UAS flight campaign was carried out over a weed infested wheat field, and images were acquired between a 1 and 6 m flight altitude. From the UAS images, 25,452 weed plants were annotated on species level, along with wheat and soil as background classes for training and validation of the models. The results showed that the BoVW model allowed the discrimination of single plants with high accuracy for Matricaria recutita L. (88.60%), Papaver rhoeas L. (89.08%), Viola arvensis M. (87.93%), and winter wheat (94.09%), within the generated maps. Regarding site specific weed control, the classified UAS images would enable the selection of the right herbicide based on the distribution of the predicted weed species.
KW  - low altitude UAS flights
KW  - weed mapping
KW  - bag of visual words
KW  - object based image classification
DO  - 10.3390/rs10101530
ER  -
TY  - EJOU
AU  - Ma, Lingfei
AU  - Li, Ying
AU  - Li, Jonathan
AU  - Wang, Cheng
AU  - Wang, Ruisheng
AU  - Chapman, Michael A.
TI  - Mobile Laser Scanned Point-Clouds for Road Object Detection and Extraction: A Review
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - The mobile laser scanning (MLS) technique has attracted considerable attention for providing high-density, high-accuracy, unstructured, three-dimensional (3D) geo-referenced point-cloud coverage of the road environment. Recently, there has been an increasing number of applications of MLS in the detection and extraction of urban objects. This paper presents a systematic review of existing MLS related literature. This paper consists of three parts. Part 1 presents a brief overview of the state-of-the-art commercial MLS systems. Part 2 provides a detailed analysis of on-road and off-road information inventory methods, including the detection and extraction of on-road objects (e.g., road surface, road markings, driving lines, and road crack) and off-road objects (e.g., pole-like objects and power lines). Part 3 presents a refined integrated analysis of challenges and future trends. Our review shows that MLS technology is well proven in urban object detection and extraction, since the improvement of hardware and software accelerate the efficiency and accuracy of data collection and processing. When compared to other review papers focusing on MLS applications, we review the state-of-the-art road object detection and extraction methods using MLS data and discuss their performance and applicability. The main contribution of this review demonstrates that the MLS systems are suitable for supporting road asset inventory, ITS-related applications, high-definition maps, and other highly accurate localization services.
KW  - mobile laser scanning (MLS)
KW  - point cloud
KW  - road surface
KW  - road marking
KW  - driving line
KW  - road crack
KW  - traffic sign
KW  - street light
KW  - tree
KW  - power line
KW  - deep learning
DO  - 10.3390/rs10101531
ER  -
TY  - EJOU
AU  - Ren, Zijun
AU  - Fu, Wenxing
AU  - Zhu, Supeng
AU  - Yan, Binbin
AU  - Yan, Jie
TI  - Bio-Inspired Neural Adaptive Control of a Small Unmanned Aerial Vehicle Based on Airflow Sensors
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 10
SN  - 1424-8220

AB  - Inspired by the exceptional flight ability of birds and insects, a bio-inspired neural adaptive flight control structure of a small unmanned aerial vehicle was presented. Eight pressure sensors were elaborately installed in the leading-edge area of the forward wing. A back propagation neural network was trained to predict the aerodynamic moment based on pressure measurements. The network model was trained, validated, and tested. An adaptive controller was designed based on a radial basis function neural network. The new adaptive laws guaranteed the boundedness of the adaptive parameters. The closed-loop stability was analyzed via Lyapunov theory. The simulation results demonstrated the robustness of the bio-inspired flight control system when subjected to measurement noise, parametric uncertainties, and external disturbance.
KW  - UAV
KW  - bio-inspired flight control
KW  - neural network
KW  - pressure sensor
DO  - 10.3390/s18103233
ER  -
TY  - EJOU
AU  - Marin, Iuliana
AU  - Vasilateanu, Andrei
AU  - Molnar, Arthur-Jozsef
AU  - Bocicor, Maria I.
AU  - Cuesta-Frau, David
AU  - Molina-Picó, Antonio
AU  - Goga, Nicolae
TI  - i-Light—Intelligent Luminaire Based Platform for Home Monitoring and Assisted Living
T2  - Electronics

PY  - 2018
VL  - 7
IS  - 10
SN  - 2079-9292

AB  - We present i-Light, a cyber-physical platform that aims to help older adults to live safely within their own homes. The system is the result of an international research project funded by the European Union and is comprised of a custom developed wireless sensor network together with software services that provide continuous monitoring, reporting and real-time alerting capabilities. The principal innovation proposed within the project regards implementation of the hardware components in the form of intelligent luminaires with inbuilt sensing and communication capabilities. Custom luminaires provide indoor localisation and environment sensing, are cost-effective and are designed to replace the lighting infrastructure of the deployment location without prior mapping or fingerprinting. We evaluate the system within a home and show that it achieves localisation accuracy sufficient for room-level detection. We present the communication infrastructure, and detail how the software services can be configured and used for visualisation, reporting and real-time alerting.
KW  - ambient assisted living
KW  - intelligent luminaires
KW  - wireless sensor network
KW  - indoor localisation
KW  - indoor monitoring
DO  - 10.3390/electronics7100220
ER  -
TY  - EJOU
AU  - Wang, Jingkai
AU  - Huo, Linsheng
AU  - Liu, Chunguang
AU  - Peng, Yuanchen
AU  - Song, Gangbing
TI  - Feasibility Study of Real-Time Monitoring of Pin Connection Wear Using Acoustic Emission
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 10
SN  - 2076-3417

AB  - Pin connections are one of the most important connecting forms and they have been widely used in engineering fields. In its service, pin connections are subject to wear, and it will be beneficial if the health condition of pin connections can be monitored in real time. In this paper, an acoustic emission (AE)-based method was developed to monitor wear degree of low rotational speed pin connections in real time in a nondestructive way. Most pin connections are operated at low rotational speed. To facilitate the research, an experimental apparatus to accelerate the wear test of low rotational speed pin connections was designed and fabricated. The piezoceramic AE sensor was mounted on the test apparatus in a nondestructive way, and it was capable of real-time monitoring. Accelerated wear tests of low rotational speed pin connections were conducted. To verify the results of the AE technique, a VHX-600E digital (from Keyence, Osaka, Japan) microscope was applied to observe the micrographs of the tested pins. The experimental results show that AE activity existed throughout the entire wear process, and it was the most prominent in the serious wear phase. The wear degree of the pin connections can be reflected qualitatively by the signal strength and the accumulative signal strength of the AE signals. In addition, two different wear forms can be distinguished by comparing the signal strength values of all specimens. Micrographs of all specimens confirm these results, and determine that the two wear forms include adhesive wear and abrasive wear. Furthermore, AE results demonstrated that adhesive wear is the main mode of wear for the low rotational speed pin connections, and the signal strength of the adhesive wear is around 190 times larger than that of abrasive wear. This feasibility study demonstrated that the developed acoustic emission technique can be utilized in the wear monitoring of pin connections in real time in a nondestructive way.
KW  - piezoceramic
KW  - acoustic emission (AE)
KW  - pin connections
KW  - monitoring of pin connections
KW  - wear form
KW  - adhesive wear
KW  - abrasive wear
DO  - 10.3390/app8101775
ER  -
TY  - EJOU
AU  - Huang, Huasheng
AU  - Deng, Jizhong
AU  - Lan, Yubin
AU  - Yang, Aqing
AU  - Deng, Xiaoling
AU  - Wen, Sheng
AU  - Zhang, Huihui
AU  - Zhang, Yali
TI  - Accurate Weed Mapping and Prescription Map Generation Based on Fully Convolutional Networks Using UAV Imagery
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 10
SN  - 1424-8220

AB  - Chemical control is necessary in order to control weed infestation and to ensure a rice yield. However, excessive use of herbicides has caused serious agronomic and environmental problems. Site specific weed management (SSWM) recommends an appropriate dose of herbicides according to the weed coverage, which may reduce the use of herbicides while enhancing their chemical effects. In the context of SSWM, the weed cover map and prescription map must be generated in order to carry out the accurate spraying. In this paper, high resolution unmanned aerial vehicle (UAV) imagery were captured over a rice field. Different workflows were evaluated to generate the weed cover map for the whole field. Fully convolutional networks (FCN) was applied for a pixel-level classification. Theoretical analysis and practical evaluation were carried out to seek for an architecture improvement and performance boost. A chessboard segmentation process was used to build the grid framework of the prescription map. The experimental results showed that the overall accuracy and mean intersection over union (mean IU) for weed mapping using FCN-4s were 0.9196 and 0.8473, and the total time (including the data collection and data processing) required to generate the weed cover map for the entire field (50 &times; 60 m) was less than half an hour. Different weed thresholds (0.00&ndash;0.25, with an interval of 0.05) were used for the prescription map generation. High accuracies (above 0.94) were observed for all of the threshold values, and the relevant herbicide saving ranged from 58.3% to 70.8%. All of the experimental results demonstrated that the method used in this work has the potential to produce an accurate weed cover map and prescription map in SSWM applications.
KW  - UAV
KW  - semantic labeling
KW  - FCN
KW  - weed mapping
KW  - prescription map
DO  - 10.3390/s18103299
ER  -
TY  - EJOU
AU  - Zhang, Han-ye
AU  - Lin, Wei-ming
AU  - Chen, Ai-xia
TI  - Path Planning for the Mobile Robot: A Review
T2  - Symmetry

PY  - 2018
VL  - 10
IS  - 10
SN  - 2073-8994

AB  - Good path planning technology of mobile robot can not only save a lot of time, but also reduce the wear and capital investment of mobile robot. Several methodologies have been proposed and reported in the literature for the path planning of mobile robot. Although these methodologies do not guarantee an optimal solution, they have been successfully applied in their works. The purpose of this paper is to review the modeling, optimization criteria and solution algorithms for the path planning of mobile robot. The survey shows GA (genetic algorithm), PSO (particle swarm optimization algorithm), APF (artificial potential field), and ACO (ant colony optimization algorithm) are the most used approaches to solve the path planning of mobile robot. Finally, future research is discussed which could provide reference for the path planning of mobile robot.
KW  - path planning
KW  - mobile robot
KW  - environmental modeling
KW  - optimization criteria
KW  - path search
DO  - 10.3390/sym10100450
ER  -
TY  - EJOU
AU  - Tayara, Hilal
AU  - Chong, Kil T.
TI  - Object Detection in Very High-Resolution Aerial Images Using One-Stage Densely Connected Feature Pyramid Network
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 10
SN  - 1424-8220

AB  - Object detection in very high-resolution (VHR) aerial images is an essential step for a wide range of applications such as military applications, urban planning, and environmental management. Still, it is a challenging task due to the different scales and appearances of the objects. On the other hand, object detection task in VHR aerial images has improved remarkably in recent years due to the achieved advances in convolution neural networks (CNN). Most of the proposed methods depend on a two-stage approach, namely: a region proposal stage and a classification stage such as Faster R-CNN. Even though two-stage approaches outperform the traditional methods, their optimization is not easy and they are not suitable for real-time applications. In this paper, a uniform one-stage model for object detection in VHR aerial images has been proposed. In order to tackle the challenge of different scales, a densely connected feature pyramid network has been proposed by which high-level multi-scale semantic feature maps with high-quality information are prepared for object detection. This work has been evaluated on two publicly available datasets and outperformed the current state-of-the-art results on both in terms of mean average precision (mAP) and computation time.
KW  - Aerial images
KW  - convolution neural network (CNN)
KW  - deep learning
KW  - feature pyramid network
KW  - focal loss
KW  - object detection
DO  - 10.3390/s18103341
ER  -
TY  - EJOU
AU  - Zhao, Qingxia
AU  - Wang, Fei
AU  - Zhao, Jun
AU  - Zhou, Jingjing
AU  - Yu, Shichuan
AU  - Zhao, Zhong
TI  - Estimating Forest Canopy Cover in Black Locust (Robinia pseudoacacia L.) Plantations on the Loess Plateau Using Random Forest
T2  - Forests

PY  - 2018
VL  - 9
IS  - 10
SN  - 1999-4907

AB  - The forest canopy is the medium for energy and mass exchange between forest ecosystems and the atmosphere. Remote sensing techniques are more efficient and appropriate for estimating forest canopy cover (CC) than traditional methods, especially at large scales. In this study, we evaluated the CC of black locust plantations on the Loess Plateau using random forest (RF) regression models. The models were established using the relationships between digital hemispherical photograph (DHP) field data and variables that were calculated from satellite images. Three types of variables were calculated from the satellite data: spectral variables calculated from a multispectral image, textural variables calculated from a panchromatic image (Tpan) with a 15 &times; 15 window size, and textural variables calculated from spectral variables (TB+VIs) with a 9 &times; 9 window size. We compared different mtry and ntree values to find the most suitable parameters for the RF models. The results indicated that the RF model of spectral variables explained 57% (root mean square error (RMSE) = 0.06) of the variability in the field CC data. The soil-adjusted vegetation index (SAVI) and enhanced vegetation index (EVI) were more important than other spectral variables. The RF model of Tpan obtained higher accuracy (R2 = 0.69, RMSE = 0.05) than the spectral variables, and the grey level co-occurrence matrix-based texture measure&mdash;Correlation (COR) was the most important variable for Tpan. The most accurate model was obtained from the TB+VIs (R2 = 0.79, RMSE = 0.05), which combined spectral and textural information, thus providing a significant improvement in estimating CC. This model provided an effective approach for detecting the CC of black locust plantations on the Loess Plateau.
KW  - canopy cover (CC)
KW  - spectral
KW  - texture
KW  - digital hemispherical photograph (DHP)
KW  - random forest (RF)
KW  - gray level co-occurrence matrix (GLCM)
DO  - 10.3390/f9100623
ER  -
TY  - EJOU
AU  - Chen, Hongyi
AU  - Zhang, Fan
AU  - Tang, Bo
AU  - Yin, Qiang
AU  - Sun, Xian
TI  - Slim and Efficient Neural Network Design for Resource-Constrained SAR Target Recognition
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - Deep convolutional neural networks (CNN) have been recently applied to synthetic aperture radar (SAR) for automatic target recognition (ATR) and have achieved state-of-the-art results with significantly improved recognition performance. However, the training period of deep CNN is long, and the size of the network is huge, sometimes reaching hundreds of megabytes. These two factors of deep CNN hinders its practical implementation and deployment in real-time SAR platforms that are typically resource-constrained. To address this challenge, this paper presents three strategies of network compression and acceleration to decrease computing and memory resource dependencies while maintaining a competitive accuracy. First, we introduce a new weight-based network pruning and adaptive architecture squeezing method to reduce the network storage and the time of inference and training process, meanwhile maintain a balance between compression ratio and classification accuracy. Then we employ weight quantization and coding to compress the network storage space. Due to the fact that the amount of calculation is mainly reflected in the convolution layer, a fast approach for pruned convolutional layers is proposed to reduce the number of multiplication by exploiting the sparsity in the activation inputs and weights. Experimental results show that the convolutional neural networks for SAR-ATR can be compressed by     40 &times;     without loss of accuracy, and the number of multiplication can be reduced by     15 &times;    . Combining these strategies, we can easily load the network in resource-constrained platforms, speed up the inference process to get the results in real-time or even retrain a more suitable network with new image data in a specific situation.
KW  - deep learning
KW  - synthetic aperture radar (SAR)
KW  - automatic target recognition (ATR)
KW  - model compression
KW  - fast algorithm
DO  - 10.3390/rs10101618
ER  -
TY  - EJOU
AU  - Nguyen, Ngoc P.
AU  - Hong, Sung K.
TI  - Sliding Mode Thau Observer for Actuator Fault Diagnosis of Quadcopter UAVs
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 10
SN  - 2076-3417

AB  - Fault diagnosis (FD) is one of the main roles of fault-tolerant control (FTC) systems. An FD should not only identify the presence of a fault, but also quantify its magnitude and location. In this work, we present a robust fault diagnosis method for quadcopter unmanned aerial vehicle (UAV) actuator faults. The state equation of the quadcopter UAV is examined as a nonlinear system. An adaptive sliding mode Thau observer (ASMTO) method is proposed to estimate the fault magnitude through an adaptive algorithm. We then obtain the design matrices and parameters using the linear matrix inequalities (LMI) technique. Finally, experimental results are presented to show the advantages of the proposed algorithm. Unlike previous research on quadcopter UAV FD systems, our study is based on ASMTO and can, therefore, determine the time variability of a fault in the presence of external disturbances.
KW  - fault diagnosis
KW  - quadcopter UAV
KW  - fault-tolerant control
KW  - sliding mode observer
KW  - Thau observer
DO  - 10.3390/app8101893
ER  -
TY  - EJOU
AU  - Feng, Yi
AU  - Zhang, Cong
AU  - Baek, Stanley
AU  - Rawashdeh, Samir
AU  - Mohammadi, Alireza
TI  - Autonomous Landing of a UAV on a Moving Platform Using Model Predictive Control
T2  - Drones

PY  - 2018
VL  - 2
IS  - 4
SN  - 2504-446X

AB  - Developing methods for autonomous landing of an unmanned aerial vehicle (UAV) on a mobile platform has been an active area of research over the past decade, as it offers an attractive solution for cases where rapid deployment and recovery of a fleet of UAVs, continuous flight tasks, extended operational ranges, and mobile recharging stations are desired. In this work, we present a new autonomous landing method that can be implemented on micro UAVs that require high-bandwidth feedback control loops for safe landing under various uncertainties and wind disturbances. We present our system architecture, including dynamic modeling of the UAV with a gimbaled camera, implementation of a Kalman filter for optimal localization of the mobile platform, and development of model predictive control (MPC), for guidance of UAVs. We demonstrate autonomous landing with an error of less than 37 cm from the center of a mobile platform traveling at a speed of up to 12 m/s under the condition of noisy measurements and wind disturbances.
KW  - quadcopter
KW  - drone
KW  - Kalman filter
KW  - vision-based guidance system
KW  - autonomous vehicle
KW  - unmanned aerial vehicle
KW  - model predictive control
KW  - aerospace control
DO  - 10.3390/drones2040034
ER  -
TY  - EJOU
AU  - Kim, Byunghyun
AU  - Cho, Soojin
TI  - Automated Vision-Based Detection of Cracks on Concrete Surfaces Using a Deep Learning Technique
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 10
SN  - 1424-8220

AB  - At present, a number of computer vision-based crack detection techniques have been developed to efficiently inspect and manage a large number of structures. However, these techniques have not replaced visual inspection, as they have been developed under near-ideal conditions and not in an on-site environment. This article proposes an automated detection technique for crack morphology on concrete surface under an on-site environment based on convolutional neural networks (CNNs). A well-known CNN, AlexNet is trained for crack detection with images scraped from the Internet. The training set is divided into five classes involving cracks, intact surfaces, two types of similar patterns of cracks, and plants. A comparative study evaluates the successfulness of the detailed surface categorization. A probability map is developed using a softmax layer value to add robustness to sliding window detection and a parametric study was carried out to determine its threshold. The applicability of the proposed method is evaluated on images taken from the field and real-time video frames taken using an unmanned aerial vehicle. The evaluation results confirm the high adoptability of the proposed method for crack inspection in an on-site environment.
KW  - crack
KW  - deep learning
KW  - convolutional neural networks
KW  - AlexNet
KW  - unmanned aerial vehicle
DO  - 10.3390/s18103452
ER  -
TY  - EJOU
AU  - Zhan, Tianming
AU  - Sun, Le
AU  - Xu, Yang
AU  - Yang, Guowei
AU  - Zhang, Yan
AU  - Wu, Zebin
TI  - Hyperspectral Classification via Superpixel Kernel Learning-Based Low Rank Representation
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - High dimensional image classification is a fundamental technique for information retrieval from hyperspectral remote sensing data. However, data quality is readily affected by the atmosphere and noise in the imaging process, which makes it difficult to achieve good classification performance. In this paper, multiple kernel learning-based low rank representation at superpixel level (Sp_MKL_LRR) is proposed to improve the classification accuracy for hyperspectral images. Superpixels are generated first from the hyperspectral image to reduce noise effect and form homogeneous regions. An optimal superpixel kernel parameter is then selected by the kernel matrix using a multiple kernel learning framework. Finally, a kernel low rank representation is applied to classify the hyperspectral image. The proposed method offers two advantages. (1) The global correlation constraint is exploited by the low rank representation, while the local neighborhood information is extracted as the superpixel kernel adaptively learns the high-dimensional manifold features of the samples in each class; (2) It can meet the challenges of multiscale feature learning and adaptive parameter determination in the conventional kernel methods. Experimental results on several hyperspectral image datasets demonstrate that the proposed method outperforms several state-of-the-art classifiers tested in terms of overall accuracy, average accuracy, and kappa statistic.
KW  - hyperspectral image
KW  - classification
KW  - superpixel kernel
KW  - multiple kernel learning
KW  - low rank representation
DO  - 10.3390/rs10101639
ER  -
TY  - EJOU
AU  - Guillen-Perez, Antonio
AU  - Cano, Maria-Dolores
TI  - Flying Ad Hoc Networks: A New Domain for Network Communications
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 10
SN  - 1424-8220

AB  - The advent of flying ad hoc networks (FANETs) has opened an opportunity to create new added-value services. Even though it is clear that these networks share common features with its predecessors, e.g., with mobile ad hoc networks and with vehicular ad hoc networks, there are several unique characteristics that make FANETs different. These distinctive features impose a series of guidelines to be considered for its successful deployment. Particularly, the use of FANETs for telecommunication services presents demanding challenges in terms of quality of service, energy efficiency, scalability, and adaptability. The proper use of models in research activities will undoubtedly assist to solve those challenges. Therefore, in this paper, we review mobility, positioning, and propagation models proposed for FANETs in the related scientific literature. A common limitation that affects these three topics is the lack of studies evaluating the influence that the unmanned aerial vehicles (UAV) may have in the on-board/embedded communication devices, usually just assuming isotropic or omnidirectional radiation patterns. For this reason, we also investigate in this work the radiation pattern of an 802.11 n/ac (WiFi) device embedded in a UAV working on both the 2.4 and 5 GHz bands. Our findings show that the impact of the UAV is not negligible, representing up to a 10 dB drop for some angles of the communication links.
KW  - drone
KW  - unmanned aerial vehicle (UAV)
KW  - flying ad hoc network (FANET)
KW  - mobility models
KW  - positioning algorithms
KW  - propagation models
KW  - radiation pattern
KW  - WiFi
DO  - 10.3390/s18103571
ER  -
TY  - EJOU
AU  - Mozgeris, Gintautas
AU  - Juodkienė, Vytautė
AU  - Jonikavičius, Donatas
AU  - Straigytė, Lina
AU  - Gadal, Sébastien
AU  - Ouerghemmi, Walid
TI  - Ultra-Light Aircraft-Based Hyperspectral and Colour-Infrared Imaging to Identify Deciduous Tree Species in an Urban Environment
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - One may consider the application of remote sensing as a trade-off between the imaging platforms, sensors, and data gathering and processing techniques. This study addresses the potential of hyperspectral imaging using ultra-light aircraft for vegetation species mapping in an urban environment, exploring both the engineering and scientific aspects related to imaging platform design and image classification methods. An imaging system based on simultaneous use of Rikola frame format hyperspectral and Nikon D800E adopted colour infrared cameras installed onboard a Bekas X32 manned ultra-light aircraft is introduced. Two test imaging flight missions were conducted in July of 2015 and September of 2016 over a 4000 ha area in Kaunas City, Lithuania. Sixteen and 64 spectral bands in 2015 and 2016, respectively, in a spectral range of 500&ndash;900 nm were recorded with colour infrared images. Three research questions were explored assessing the identification of six deciduous tree species: (1) Pre-treatment of spectral features for classification, (2) testing five conventional machine learning classifiers, and (3) fusion of hyperspectral and colour infrared images. Classification performance was assessed by applying leave-one-out cross-validation at the individual crown level and using as a reference at least 100 field inventoried trees for each species. The best-performing classification algorithm&mdash;multilayer perceptron, using all spectral properties extracted from the hyperspectral images&mdash;resulted in a moderate classification accuracy. The overall classification accuracy was 63%, Cohen&rsquo;s Kappa was 0.54, and the species-specific classification accuracies were in the range of 51&ndash;72%. Hyperspectral images resulted in significantly better tree species classification ability than the colour infrared images and simultaneous use of spectral properties extracted from hyperspectral and colour infrared images improved slightly the accuracy over the 2015 image. Even though classifications using hyperspectral data cubes of 64 bands resulted in relatively larger accuracies than with 16 bands, classification error matrices were not statistically different. Alternative imaging platforms (like an unmanned aerial vehicle and a Cessna 172 aircraft) and settings of the flights were discussed using simulated imaging projects assuming the same study area and field of application. Ultra-light aircraft-based hyperspectral and colour-infrared imaging was considered to be a technically and economically sound solution for urban green space inventories to facilitate tree mapping, characterization, and monitoring.
KW  - hyperspectral
KW  - colour infrared
KW  - ultra-light aircraft
KW  - urban trees
KW  - classification
DO  - 10.3390/rs10101668
ER  -
TY  - EJOU
AU  - Muñoz, Paul
AU  - Orellana-Alvear, Johanna
AU  - Willems, Patrick
AU  - Célleri, Rolando
TI  - Flash-Flood Forecasting in an Andean Mountain Catchment—Development of a Step-Wise Methodology Based on the Random Forest Algorithm
T2  - Water

PY  - 2018
VL  - 10
IS  - 11
SN  - 2073-4441

AB  - Flash-flood forecasting has emerged worldwide due to the catastrophic socio-economic impacts this hazard might cause and the expected increase of its frequency in the future. In mountain catchments, precipitation-runoff forecasts are limited by the intrinsic complexity of the processes involved, particularly its high rainfall variability. While process-based models are hard to implement, there is a potential to use the random forest algorithm due to its simplicity, robustness and capacity to deal with complex data structures. Here a step-wise methodology is proposed to derive parsimonious models accounting for both hydrological functioning of the catchment (e.g., input data, representation of antecedent moisture conditions) and random forest procedures (e.g., sensitivity analyses, dimension reduction, optimal input composition). The methodology was applied to develop short-term prediction models of varying time duration (4, 8, 12, 18 and 24 h) for a catchment representative of the Ecuadorian Andes. Results show that the derived parsimonious models can reach validation efficiencies (Nash-Sutcliffe coefficient) from 0.761 (4-h) to 0.384 (24-h) for optimal inputs composed only by features accounting for 80% of the model&rsquo;s outcome variance. Improvement in the prediction of extreme peak flows was demonstrated (extreme value analysis) by including precipitation information in contrast to the use of pure autoregressive models.
KW  - flash-flood
KW  - precipitation-runoff
KW  - forecasting
KW  - lag analysis
KW  - random forest
KW  - machine learning
DO  - 10.3390/w10111519
ER  -
TY  - EJOU
AU  - Bah, M D.
AU  - Hafiane, Adel
AU  - Canals, Raphael
TI  - Deep Learning with Unsupervised Data Labeling for Weed Detection in Line Crops in UAV Images
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 11
SN  - 2072-4292

AB  - In recent years, weeds have been responsible for most agricultural yield losses. To deal with this threat, farmers resort to spraying the fields uniformly with herbicides. This method not only requires huge quantities of herbicides but impacts the environment and human health. One way to reduce the cost and environmental impact is to allocate the right doses of herbicide to the right place and at the right time (precision agriculture). Nowadays, unmanned aerial vehicles (UAVs) are becoming an interesting acquisition system for weed localization and management due to their ability to obtain images of the entire agricultural field with a very high spatial resolution and at a low cost. However, despite significant advances in UAV acquisition systems, the automatic detection of weeds remains a challenging problem because of their strong similarity to the crops. Recently, a deep learning approach has shown impressive results in different complex classification problems. However, this approach needs a certain amount of training data, and creating large agricultural datasets with pixel-level annotations by an expert is an extremely time-consuming task. In this paper, we propose a novel fully automatic learning method using convolutional neuronal networks (CNNs) with an unsupervised training dataset collection for weed detection from UAV images. The proposed method comprises three main phases. First, we automatically detect the crop rows and use them to identify the inter-row weeds. In the second phase, inter-row weeds are used to constitute the training dataset. Finally, we perform CNNs on this dataset to build a model able to detect the crop and the weeds in the images. The results obtained are comparable to those of traditional supervised training data labeling, with differences in accuracy of 1.5% in the spinach field and 6% in the bean field.
KW  - weed detection
KW  - deep learning
KW  - unmanned aerial vehicle
KW  - image processing
KW  - precision agriculture
KW  - crop line detection
DO  - 10.3390/rs10111690
ER  -
TY  - EJOU
AU  - Sawalmeh, Ahmad
AU  - Othman, Noor S.
AU  - Shakhatreh, Hazim
TI  - Efficient Deployment of Multi-UAVs in Massively Crowded Events
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 11
SN  - 1424-8220

AB  - In this paper, the efficient 3D placement of UAV as an aerial base station in providing wireless coverage for users in a small and large coverage area is investigated. In the case of providing wireless coverage for outdoor and indoor users in a small area, the Particle Swarm Optimization (PSO) and K-means with Ternary Search (KTS) algorithms are invoked to find an efficient 3D location of a single UAV with the objective of minimizing its required transmit power. It was observed that a single UAV at the 3D location found using the PSO algorithm requires less transmit power, by a factor of 1/5 compared to that when using the KTS algorithm. In the case of providing wireless coverage for users in three different shapes of a large coverage area, namely square, rectangle and circular regions, the problems of finding an efficient placement of multiple UAVs equipped with a directional antenna are formulated with the objective to maximize the coverage area and coverage density using the Circle Packing Theory (CPT). Then, the UAV efficient altitude placement is formulated with the objective of minimizing its required transmit power. It is observed that the large number of UAVs does not necessarily result in the maximum coverage density. Based on the simulation results, the deployment of 16, 19 and 26 UAVs is capable of providing the maximum coverage density of 78.5%, 82.5% and 80.3% for the case of a square region with the dimensions of 2 km &times; 2 km, a rectangle region with the dimensions of 6 km &times; 1.8 km and a circular region with the radius of 1.125 km, respectively. These observations are obtained when the UAVs are located at the optimum altitude, where the required transmit power for each UAV is reasonably small.
KW  - Unmanned Aerial Vehicles (UAVs)
KW  - path loss model
KW  - Particle Swarm Optimization (PSO)
KW  - K-means algorithm
KW  - ternary search algorithm
KW  - Circle Packing Theory (CPT)
DO  - 10.3390/s18113640
ER  -
TY  - EJOU
AU  - Zhang, Xianbing
AU  - Liu, Guoqing
AU  - Yang, Chaojie
AU  - Wu, Jiang
TI  - Research on Air Confrontation Maneuver Decision-Making Method Based on Reinforcement Learning
T2  - Electronics

PY  - 2018
VL  - 7
IS  - 11
SN  - 2079-9292

AB  - With the development of information technology, the degree of intelligence in air confrontation is increasing, and the demand for automated intelligent decision-making systems is becoming more intense. Based on the characteristics of over-the-horizon air confrontation, this paper constructs a super-horizon air confrontation training environment, which includes aircraft model modeling, air confrontation scene design, enemy aircraft strategy design, and reward and punishment signal design. In order to improve the efficiency of the reinforcement learning algorithm for the exploration of strategy space, this paper proposes a heuristic Q-Network method that integrates expert experience, and uses expert experience as a heuristic signal to guide the search process. At the same time, heuristic exploration and random exploration are combined. Aiming at the over-the-horizon air confrontation maneuver decision problem, the heuristic Q-Network method is adopted to train the neural network model in the over-the-horizon air confrontation training environment. Through continuous interaction with the environment, self-learning of the air confrontation maneuver strategy is realized. The efficiency of the heuristic Q-Network method and effectiveness of the air confrontation maneuver strategy are verified by simulation experiments.
KW  - over-the-horizon air confrontation
KW  - maneuver decision
KW  - Q-Network
KW  - heuristic exploration
KW  - reinforcement learning
DO  - 10.3390/electronics7110279
ER  -
TY  - EJOU
AU  - Bouaddi, Sahar
AU  - Fernández-García, Aránzazu
AU  - Sansom, Chris
AU  - Sarasua, Jon A.
AU  - Wolfertstetter, Fabian
AU  - Bouzekri, Hicham
AU  - Sutter, Florian
AU  - Azpitarte, Itiziar
TI  - A Review of Conventional and Innovative- Sustainable Methods for Cleaning Reflectors in Concentrating Solar Power Plants
T2  - Sustainability

PY  - 2018
VL  - 10
IS  - 11
SN  - 2071-1050

AB  - The severe soiling of reflectors deployed in arid and semi arid locations decreases their reflectance and drives down the yield of the concentrating solar power (CSP) plants. To alleviate this issue, various sets of methods are available. The operation and maintenance (O&amp;M) staff should opt for sustainable cleaning methods that are safe and environmentally friendly. To restore high reflectance, the cleaning vehicles of CSP plants must adapt to the constraints of each technology and to the layout of reflectors in the solar field. Water based methods are currently the most commonly used in CSP plants but they are not sustainable due to water scarcity and high soiling rates. The recovery and reuse of washing water can compensate for these methods and make them a more reasonable option for mediterranean and desert environments. Dry methods, on the other hand, are gaining more attraction as they are more suitable for desert regions. Some of these methods rely on ultrasonic wave or vibration for detaching the dust bonding from the reflectors surface, while other methods, known as preventive methods, focus on reducing the soiling by modifying the reflectors surface and incorporating self cleaning features using special coatings. Since the CSP plants operators aim to achieve the highest profit by minimizing the cost of cleaning while maintaining a high reflectance, optimizing the cleaning parameters and strategies is of great interest. This work presents the conventional water-based methods that are currently used in CSP plants in addition to sustainable alternative methods for dust removal and soiling prevention. Also, the cleaning effectiveness, the environmental impacts and the economic aspects of each technology are discussed.
KW  - sustainable cleaning
KW  - CSP reflectors
KW  - soiling
KW  - dust removal
KW  - mirror washing
DO  - 10.3390/su10113937
ER  -
TY  - EJOU
AU  - Zhang, Pengbin
AU  - Ke, Yinghai
AU  - Zhang, Zhenxin
AU  - Wang, Mingli
AU  - Li, Peng
AU  - Zhang, Shuangyue
TI  - Urban Land Use and Land Cover Classification Using Novel Deep Learning Models Based on High Spatial Resolution Satellite Imagery
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 11
SN  - 1424-8220

AB  - Urban land cover and land use mapping plays an important role in urban planning and management. In this paper, novel multi-scale deep learning models, namely ASPP-Unet and ResASPP-Unet are proposed for urban land cover classification based on very high resolution (VHR) satellite imagery. The proposed ASPP-Unet model consists of a contracting path which extracts the high-level features, and an expansive path, which up-samples the features to create a high-resolution output. The atrous spatial pyramid pooling (ASPP) technique is utilized in the bottom layer in order to incorporate multi-scale deep features into a discriminative feature. The ResASPP-Unet model further improves the architecture by replacing each layer with residual unit. The models were trained and tested based on WorldView-2 (WV2) and WorldView-3 (WV3) imageries over the city of Beijing. Model parameters including layer depth and the number of initial feature maps (IFMs) as well as the input image bands were evaluated in terms of their impact on the model performances. It is shown that the ResASPP-Unet model with 11 layers and 64 IFMs based on 8-band WV2 imagery produced the highest classification accuracy (87.1% for WV2 imagery and 84.0% for WV3 imagery). The ASPP-Unet model with the same parameter setting produced slightly lower accuracy, with overall accuracy of 85.2% for WV2 imagery and 83.2% for WV3 imagery. Overall, the proposed models outperformed the state-of-the-art models, e.g., U-Net, convolutional neural network (CNN) and Support Vector Machine (SVM) model over both WV2 and WV3 images, and yielded robust and efficient urban land cover classification results.
KW  - urban land cover classification
KW  - high spatial resolution satellite imagery
KW  - deep learning
KW  - U-Net
KW  - CNN
DO  - 10.3390/s18113717
ER  -
TY  - EJOU
AU  - Kuffer, Monika
AU  - Wang, Jiong
AU  - Nagenborg, Michael
AU  - Pfeffer, Karin
AU  - Kohli, Divyani
AU  - Sliuzas, Richard
AU  - Persello, Claudio
TI  - The Scope of Earth-Observation to Improve the Consistency of the SDG Slum Indicator
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 11
SN  - 2220-9964

AB  - The continuous increase in deprived living conditions in many cities of the Global South contradicts efforts to make cities inclusive, safe, resilient, and sustainable places. Using examples of Asian, African, and Latin American cities, this study shows the scope and limits of earth observation (EO)-based mapping of deprived living conditions in support of providing consistent global information for the SDG indicator 11.1.1 “proportion of urban population living in slums, informal settlements or inadequate housing”. At the technical level, we compare several EO-based methods and imagery for mapping deprived living conditions, discussing their ability to map such areas including differences in terms of accuracy and performance at the city scale. At the operational level, we compare available municipal maps showing identified deprived areas with the spatial extent of morphological mapped areas of deprived living conditions (using EO) at the city scale, discussing the reasons for inconsistencies between municipal and EO-based maps. We provide an outlook on how EO-based mapping of deprived living conditions could contribute to a global spatial information base to support targeting of deprived living conditions in support of the SDG Goal 11.1.1 indicator, when uncertainties and ethical considerations on data provision are well addressed.
KW  - deprived living conditions
KW  - slum
KW  - informal settlement
KW  - inadequate housing
KW  - Sustainable Development Goals (SDGs)
KW  - remote sensing
KW  - global urban data
KW  - uncertainties
KW  - geo-ethics
DO  - 10.3390/ijgi7110428
ER  -
TY  - EJOU
AU  - Valentino, Rico
AU  - Jung, Woo-Sung
AU  - Ko, Young-Bae
TI  - A Design and Simulation of the Opportunistic Computation Offloading with Learning-Based Prediction for Unmanned Aerial Vehicle (UAV) Clustering Networks
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 11
SN  - 1424-8220

AB  - Drones have recently become extremely popular, especially in military and civilian applications. Examples of drone utilization include reconnaissance, surveillance, and packet delivery. As time has passed, drones’ tasks have become larger and more complex. As a result, swarms or clusters of drones are preferred, because they offer more coverage, flexibility, and reliability. However, drone systems have limited computing power and energy resources, which means that sometimes it is difficult for drones to finish their tasks on schedule. A solution to this is required so that drone clusters can complete their work faster. One possible solution is an offloading scheme between drone clusters. In this study, we propose an opportunistic computational offloading system, which allows for a drone cluster with a high intensity task to borrow computing resources opportunistically from other nearby drone clusters. We design an artificial neural network-based response time prediction module for deciding whether it is faster to finish tasks by offloading them to other drone clusters. The offloading scheme is conducted only if the predicted offloading response time is smaller than the local computing time. Through simulation results, we show that our proposed scheme can decrease the response time of drone clusters through an opportunistic offloading process.
KW  - drone cluster
KW  - computation offloading
KW  - neural network
KW  - wireless communication
DO  - 10.3390/s18113751
ER  -
TY  - EJOU
AU  - Tsiropoulou, Eirini E.
AU  - Kousis, George
AU  - Thanou, Athina
AU  - Lykourentzou, Ioanna
AU  - Papavassiliou, Symeon
TI  - Quality of Experience in Cyber-Physical Social Systems Based on Reinforcement Learning and Game Theory
T2  - Future Internet

PY  - 2018
VL  - 10
IS  - 11
SN  - 1999-5903

AB  - This paper addresses the problem of museum visitors&rsquo; Quality of Experience (QoE) optimization by viewing and treating the museum environment as a cyber-physical social system. To achieve this goal, we harness visitors&rsquo; internal ability to intelligently sense their environment and make choices that improve their QoE in terms of which the museum touring option is the best for them and how much time to spend on their visit. We model the museum setting as a distributed non-cooperative game where visitors selfishly maximize their own QoE. In this setting, we formulate the problem of Recommendation Selection and Visiting Time Management (RSVTM) and propose a two-stage distributed algorithm based on game theory and reinforcement learning, which learns from visitor behavior to make on-the-fly recommendation selections that maximize visitor QoE. The proposed framework enables autonomic visitor-centric management in a personalized manner and enables visitors themselves to decide on the best visiting strategies. Experimental results evaluating the performance of the proposed RSVTM algorithm under realistic simulation conditions indicate the high operational effectiveness and superior performance when compared to other recommendation approaches. Our results constitute a practical alternative for museums and exhibition spaces meant to enhance visitor QoE in a flexible, efficient, and cost-effective manner.
KW  - quality of experience
KW  - congestion
KW  - reinforcement learning
KW  - time management
KW  - game theory
KW  - personalization and recommendation
DO  - 10.3390/fi10110108
ER  -
TY  - EJOU
AU  - Galatas, Athanasios
AU  - Hassanin, Hany
AU  - Zweiri, Yahya
AU  - Seneviratne, Lakmal
TI  - Additive Manufactured Sandwich Composite/ABS Parts for Unmanned Aerial Vehicle Applications
T2  - Polymers

PY  - 2018
VL  - 10
IS  - 11
SN  - 2073-4360

AB  - Fused deposition modelling (FDM) is one of most popular 3D printing techniques of thermoplastic polymers. Nonetheless, the poor mechanical strength of FDM parts restricts the use of this technology in functional parts of many applications such as unmanned aerial vehicles (UAVs) where lightweight, high strength, and stiffness are required. In the present paper, the fabrication process of low-density acrylonitrile butadiene styrenecarbon (ABS) with carbon fibre reinforced polymer (CFRP) sandwich layers for UAV structure is proposed to improve the poor mechanical strength and elastic modulus of printed ABS. The composite sandwich structures retains FDM advantages for rapid making of complex geometries, while only requires simple post-processing steps to improve the mechanical properties. Artificial neural network (ANN) was used to investigate the influence of the core density and number of CFRP layers on the mechanical properties. The results showed an improvement of specific strength and elastic modulus with increasing the number of CFRP. The specific strength of the samples improved from 20 to 145 KN&middot;m/kg while the Young&rsquo;s modulus increased from 0.63 to 10.1 GPa when laminating the samples with CFRP layers. On the other hand, the core density had no significant effect on both specific strength and elastic modulus. A case study was undertaken by applying the CFRP/ABS/CFRP sandwich structure using the proposed method to manufacture improved dual-tilting clamps of a quadcopter UAV.
KW  - FDM
KW  - composite
KW  - sandwich structure
KW  - CFRP
KW  - neural network
KW  - UAV
DO  - 10.3390/polym10111262
ER  -
TY  - EJOU
AU  - Wang, Xiaohong
AU  - Guo, Hongzhou
AU  - Wang, Jingbin
AU  - Wang, Lizhi
TI  - Predicting the Health Status of an Unmanned Aerial Vehicles Data-Link System Based on a Bayesian Network
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 11
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) require data-link system to link ground data terminals to the real-time controls of each UAV. Consequently, the ability to predict the health status of a UAV data-link system is vital for safe and efficient operations. The performance of a UAV data-link system is affected by the health status of both the hardware and UAV data-links. This paper proposes a method for predicting the health state of a UAV data-link system based on a Bayesian network fusion of information about potential hardware device failures and link failures. Our model employs the Bayesian network to describe the information and uncertainty associated with a complex multi-level system. To predict the health status of the UAV data-link, we use the health status information about the root node equipment with various life characteristics along with the health status of the links as affected by the bit error rate. In order to test the validity of the model, we tested its prediction of the health of a multi-level solar-powered unmanned aerial vehicle data-link system and the result shows that the method can quantitatively predict the health status of the solar-powered UAV data-link system. The results can provide guidance for improving the reliability of UAV data-link system and lay a foundation for predicting the health status of a UAV data-link system accurately.
KW  - UAV data-link system
KW  - Bayesian networks
KW  - health status prediction
KW  - networking mode
KW  - bit error rate
DO  - 10.3390/s18113916
ER  -
TY  - EJOU
AU  - Boonpook, Wuttichai
AU  - Tan, Yumin
AU  - Ye, Yinghua
AU  - Torteeka, Peerapong
AU  - Torsri, Kritanai
AU  - Dong, Shengxian
TI  - A Deep Learning Approach on Building Detection from Unmanned Aerial Vehicle-Based Images in Riverbank Monitoring
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 11
SN  - 1424-8220

AB  - Buildings along riverbanks are likely to be affected by rising water levels, therefore the acquisition of accurate building information has great importance not only for riverbank environmental protection but also for dealing with emergency cases like flooding. UAV-based photographs are flexible and cloud-free compared to satellite images and can provide very high-resolution images up to centimeter level, while there exist great challenges in quickly and accurately detecting and extracting building from UAV images because there are usually too many details and distortions on UAV images. In this paper, a deep learning (DL)-based approach is proposed for more accurately extracting building information, in which the network architecture, SegNet, is used in the semantic segmentation after the network training on a completely labeled UAV image dataset covering multi-dimension urban settlement appearances along a riverbank area in Chongqing. The experiment results show that an excellent performance has been obtained in the detection of buildings from untrained locations with an average overall accuracy more than 90%. To verify the generality and advantage of the proposed method, the procedure is further evaluated by training and testing with another two open standard datasets which have a variety of building patterns and styles, and the final overall accuracies of building extraction are more than 93% and 95%, respectively.
KW  - building extraction
KW  - UAV dataset
KW  - deep learning
KW  - river bank monitoring
DO  - 10.3390/s18113921
ER  -
TY  - EJOU
AU  - Zhang, Yihong
AU  - Yang, Yijin
AU  - Zhou, Wuneng
AU  - Shi, Lifeng
AU  - Li, Demin
TI  - Motion-Aware Correlation Filters for Online Visual Tracking
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 11
SN  - 1424-8220

AB  - The discriminative correlation filters-based methods struggle deal with the problem of fast motion and heavy occlusion, the problem can severely degrade the performance of trackers, ultimately leading to tracking failures. In this paper, a novel Motion-Aware Correlation Filters (MACF) framework is proposed for online visual object tracking, where a motion-aware strategy based on joint instantaneous motion estimation Kalman filters is integrated into the Discriminative Correlation Filters (DCFs). The proposed motion-aware strategy is used to predict the possible region and scale of the target in the current frame by utilizing the previous estimated 3D motion information. Obviously, this strategy can prevent model drift caused by fast motion. On the base of the predicted region and scale, the MACF detects the position and scale of the target by using the DCFs-based method in the current frame. Furthermore, an adaptive model updating strategy is proposed to address the problem of corrupted models caused by occlusions, where the learning rate is determined by the confidence of the response map. The extensive experiments on popular Object Tracking Benchmark OTB-100, OTB-50 and unmanned aerial vehicles (UAV) video have demonstrated that the proposed MACF tracker performs better than most of the state-of-the-art trackers and achieves a high real-time performance. In addition, the proposed approach can be integrated easily and flexibly into other visual tracking algorithms.
KW  - visual tracking
KW  - correlation filters
KW  - motion-aware
KW  - adaptive update strategy
KW  - confidence response map
DO  - 10.3390/s18113937
ER  -
TY  - EJOU
AU  - Csillik, Ovidiu
AU  - Cherbini, John
AU  - Johnson, Robert
AU  - Lyons, Andy
AU  - Kelly, Maggi
TI  - Identification of Citrus Trees from Unmanned Aerial Vehicle Imagery Using Convolutional Neural Networks
T2  - Drones

PY  - 2018
VL  - 2
IS  - 4
SN  - 2504-446X

AB  - Remote sensing is important to precision agriculture and the spatial resolution provided by Unmanned Aerial Vehicles (UAVs) is revolutionizing precision agriculture workflows for measurement crop condition and yields over the growing season, for identifying and monitoring weeds and other applications. Monitoring of individual trees for growth, fruit production and pest and disease occurrence remains a high research priority and the delineation of each tree using automated means as an alternative to manual delineation would be useful for long-term farm management. In this paper, we detected citrus and other crop trees from UAV images using a simple convolutional neural network (CNN) algorithm, followed by a classification refinement using superpixels derived from a Simple Linear Iterative Clustering (SLIC) algorithm. The workflow performed well in a relatively complex agricultural environment (multiple targets, multiple size trees and ages, etc.) achieving high accuracy (overall accuracy = 96.24%, Precision (positive predictive value) = 94.59%, Recall (sensitivity) = 97.94%). To our knowledge, this is the first time a CNN has been used with UAV multi-spectral imagery to focus on citrus trees. More of these individual cases are needed to develop standard automated workflows to help agricultural managers better incorporate large volumes of high resolution UAV imagery into agricultural management operations.
KW  - CNN
KW  - deep learning
KW  - superpixels
KW  - precision agriculture
KW  - UAS
KW  - feature extraction
KW  - citrus
KW  - tree identification
DO  - 10.3390/drones2040039
ER  -
TY  - EJOU
AU  - Rahman, Muhammad M.
AU  - Robson, Andrew
AU  - Bristow, Mila
TI  - Exploring the Potential of High Resolution WorldView-3 Imagery for Estimating Yield of Mango
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Pre-harvest yield estimation of mango fruit is important for the optimization of inputs and other resources on the farm. Current industry practice of visual counting the fruit on a small number of trees for yield forecasting can be highly inaccurate due to the spatial variability, especially if the trees selected do not represent the entire crop. Therefore, this study evaluated the potential of high resolution WorldView-3 (WV3) satellite imagery to estimate yield of mango by integrating both geometric (tree crown area) and optical (spectral vegetation indices) data using artificial neural network (ANN) model. WV3 images were acquired in 2016&ndash;2017 and 2017&ndash;2018 growing seasons at the early fruit stage from three orchards in Acacia Hills region, Northern Territory, Australia. Stratified sampling technique (SST) was applied to select 18 trees from each orchard and subsequently ground truthed for yield (kg&middot;tree&minus;1) and fruit number per tree. For each sampled tree, spectral reflectance data and tree crown area (TCA) was extracted from WV3 imagery. The TCA was identified as the most important predictor of both fruit yield (kg&middot;tree&minus;1) and fruit number, followed by NDVI red-edge band when all trees from three orchards in two growing seasons were combined. The results of all sampled trees from three orchards in two growing seasons using ANN model produced a strong correlation (R2 = 0.70 and 0.68 for total fruit yield (kg&middot;tree&minus;1) and fruit number respectively), which suggest that the model can be obtained to predict yield on a regional level. On orchard level also the ANN model produced a high correlation when both growing seasons were combined. However, the model developed in one season could not be applied in another season due to the influence of seasonal variation and canopy condition. Using the relationship derived from the measured yield parameters against combined VIs and TCA data, the total fruit yield (t&middot;ha&minus;1) and fruit number were estimated for each orchard, produced 7% under estimation to less than 1% over estimation. The accuracy of the findings showed the potential of WV3 imagery to better predict the yield parameters than the current practice across the mango industry as well as to quantify lost yield as a result of delayed harvest.
KW  - WorldView-3 (WV3)
KW  - Mango (Mangifera indica)
KW  - tree crown area
KW  - yield prediction
DO  - 10.3390/rs10121866
ER  -
TY  - EJOU
AU  - Song, Chunlin
AU  - Wei, Changzhu
AU  - Yang, Feng
AU  - Cui, Naigang
TI  - High-Order Sliding Mode-Based Fixed-Time Active Disturbance Rejection Control for Quadrotor Attitude System
T2  - Electronics

PY  - 2018
VL  - 7
IS  - 12
SN  - 2079-9292

AB  - This article presents a fixed-time active disturbance rejection control approach for the attitude control problem of quadrotor unmanned aerial vehicle in the presence of dynamic wind, mass eccentricity and an actuator fault. The control scheme applies the feedback linearization technique and enhances the performance of the traditional active disturbance rejection control (ADRC) based on the fixed-time high-order sliding mode method. A switching-type uniformly convergent differentiator is used to improve the extended state observer for estimating and attenuating the lumped disturbance more accurately. A multivariable high-order sliding mode feedback law is derived to achieve fixed time convergence. The timely convergence of the designed extended state observer and the feedback law is proved theoretically. Mathematical simulations with detailed actuator models and real time experiments are performed to demonstrate the robustness and practicability of the proposed control scheme.
KW  - quadrotor
KW  - ADRC
KW  - fixed-time extended state observer (FTESO)
KW  - high-order sliding mode
KW  - wind disturbance
KW  - actuator fault
KW  - mass eccentricity
DO  - 10.3390/electronics7120357
ER  -
TY  - EJOU
AU  - Morales, Giorgio
AU  - Kemper, Guillermo
AU  - Sevillano, Grace
AU  - Arteaga, Daniel
AU  - Ortega, Ivan
AU  - Telles, Joel
TI  - Automatic Segmentation of Mauritia flexuosa in Unmanned Aerial Vehicle (UAV) Imagery Using Deep Learning
T2  - Forests

PY  - 2018
VL  - 9
IS  - 12
SN  - 1999-4907

AB  - One of the most important ecosystems in the Amazon rainforest is the Mauritia flexuosa swamp or “aguajal”. However, deforestation of its dominant species, the Mauritia flexuosa palm, also known as “aguaje”, is a common issue, and conservation is poorly monitored because of the difficult access to these swamps. The contribution of this paper is twofold: the presentation of a dataset called MauFlex, and the proposal of a segmentation and measurement method for areas covered in Mauritia flexuosa palms using high-resolution aerial images acquired by UAVs. The method performs a semantic segmentation of Mauritia flexuosa using an end-to-end trainable Convolutional Neural Network (CNN) based on the Deeplab v3+ architecture. Images were acquired under different environment and light conditions using three different RGB cameras. The MauFlex dataset was created from these images and it consists of 25,248 image patches of     512 × 512     pixels and their respective ground truth masks. The results over the test set achieved an accuracy of 98.143%, specificity of 96.599%, and sensitivity of 95.556%. It is shown that our method is able not only to detect full-grown isolated Mauritia flexuosa palms, but also young palms or palms partially covered by other types of vegetation.
KW  - Mauritia flexuosa
KW  - semantic segmentation
KW  - end-to-end learning
KW  - convolutional neural network
KW  - forest inventory
DO  - 10.3390/f9120736
ER  -
TY  - EJOU
AU  - Zhang, Bin
AU  - Wang, Cunpeng
AU  - Shen, Yonglin
AU  - Liu, Yueyan
TI  - Fully Connected Conditional Random Fields for High-Resolution Remote Sensing Land Use/Land Cover Classification with Convolutional Neural Networks
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - The interpretation of land use and land cover (LULC) is an important issue in the fields of high-resolution remote sensing (RS) image processing and land resource management. Fully training a new or existing convolutional neural network (CNN) architecture for LULC classification requires a large amount of remote sensing images. Thus, fine-tuning a pre-trained CNN for LULC detection is required. To improve the classification accuracy for high resolution remote sensing images, it is necessary to use another feature descriptor and to adopt a classifier for post-processing. A fully connected conditional random fields (FC-CRF), to use the fine-tuned CNN layers, spectral features, and fully connected pairwise potentials, is proposed for image classification of high-resolution remote sensing images. First, an existing CNN model is adopted, and the parameters of CNN are fine-tuned by training datasets. Then, the probabilities of image pixels belong to each class type are calculated. Second, we consider the spectral features and digital surface model (DSM) and combined with a support vector machine (SVM) classifier, the probabilities belong to each LULC class type are determined. Combined with the probabilities achieved by the fine-tuned CNN, new feature descriptors are built. Finally, FC-CRF are introduced to produce the classification results, whereas the unary potentials are achieved by the new feature descriptors and SVM classifier, and the pairwise potentials are achieved by the three-band RS imagery and DSM. Experimental results show that the proposed classification scheme achieves good performance when the total accuracy is about 85%.
KW  - remote sensing
KW  - image classification
KW  - fully connected conditional random fields (FC-CRF)
KW  - convolutional neural networks (CNN)
DO  - 10.3390/rs10121889
ER  -
TY  - EJOU
AU  - Griffith, David C.
AU  - Hay, Geoffrey J.
TI  - Integrating GEOBIA, Machine Learning, and Volunteered Geographic Information to Map Vegetation over Rooftops
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 12
SN  - 2220-9964

AB  - The objective of this study is to evaluate operational methods for creating a particular type of urban vegetation map—one focused on vegetation over rooftops (VOR), specifically trees that extend over urban residential buildings. A key constraint was the use of passive remote sensing data only. To achieve this, we (1) conduct a review of the urban remote sensing vegetation classification literature, and we then (2) discuss methods to derive a detailed map of VOR for a study area in Calgary, Alberta, Canada from a late season, high-resolution airborne orthomosaic based on an integration of Geographic Object-Based Image Analysis (GEOBIA), pre-classification filtering of image-objects using Volunteered Geographic Information (VGI), and a machine learning classifier. Pre-classification filtering lowered the computational burden of classification by reducing the number of input objects by 14%. Accuracy assessment results show that, despite the presence of senescing vegetation with low vegetation index values and deep shadows, classification using a small number of image-object spectral attributes as classification features (n = 9) had similar overall accuracy (88.5%) to a much more complex classification (91.8%) comprising a comprehensive set of spectral, texture, and spatial attributes as classification features (n = 86). This research provides an example of the very specific questions answerable about precise urban locations using a combination of high-resolution passive imagery and freely available VGI data. It highlights the benefits of pre-classification filtering and the judicious selection of features from image-object attributes to reduce processing load without sacrificing classification accuracy.
KW  - GEOBIA
KW  - vegetation over rooftops
KW  - machine learning
DO  - 10.3390/ijgi7120462
ER  -
TY  - EJOU
AU  - Kalacska, Margaret
AU  - Lucanus, Oliver
AU  - Sousa, Leandro
AU  - Vieira, Thiago
AU  - Arroyo-Mora, Juan P.
TI  - Freshwater Fish Habitat Complexity Mapping Using Above and Underwater Structure-From-Motion Photogrammetry
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Substrate complexity is strongly related to biodiversity in aquatic habitats. We illustrate a novel framework, based on Structure-from-Motion photogrammetry (SfM) and Multi-View Stereo (MVS) photogrammetry, to quantify habitat complexity in freshwater ecosystems from Unmanned Aerial Vehicle (UAV) and underwater photography. We analysed sites in the Xingu river basin, Brazil, to reconstruct the 3D structure of the substrate and identify and map habitat classes important for maintaining fish assemblage biodiversity. From the digital models we calculated habitat complexity metrics including rugosity, slope and 3D fractal dimension. The UAV based SfM-MVS products were generated at a ground sampling distance (GSD) of 1.20&ndash;2.38 cm while the underwater photography produced a GSD of 1 mm. Our results show how these products provide spatially explicit complexity metrics, which are more comprehensive than conventional arbitrary cross sections. Shallow neural network classification of SfM-MVS products of substrate exposed in the dry season resulted in high accuracies across classes. UAV and underwater SfM-MVS is robust for quantifying freshwater habitat classes and complexity and should be chosen whenever possible over conventional methods (e.g., chain-and-tape) because of the repeatability, scalability and multi-dimensional nature of the products. The SfM-MVS products can be used to identify high priority freshwater sectors for conservation, species occurrences and diversity studies to provide a broader indication for overall fish species diversity and provide repeatability for monitoring change over time.
KW  - Brazil
KW  - fractal dimension
KW  - neural network
KW  - river
KW  - rugosity
KW  - UAV
KW  - underwater
KW  - Xingu river
DO  - 10.3390/rs10121912
ER  -
TY  - EJOU
AU  - Zhang, Yujie
AU  - Liu, Liansheng
AU  - Peng, Yu
AU  - Liu, Datong
TI  - An Electro-Mechanical Actuator Motor Voltage Estimation Method with a Feature-Aided Kalman Filter
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 12
SN  - 1424-8220

AB  - Electro-Mechanical Actuators (EMA) have attracted growing attention with their increasing incorporation in More Electric Aircraft. The performance degradation assessment of EMA needs to be studied, in which EMA motor voltage is an essential parameter, to ensure its reliability and safety of EMA. However, deviation exists between motor voltage monitoring data and real motor voltage due to electromagnetic interference. To reduce the deviation, EMA motor voltage estimation generally requires an accurate voltage state equation which is difficult to obtain due to the complexity of EMA. To address this problem, a Feature-aided Kalman Filter (FAKF) method is proposed, in which the state equation is substituted by a physical model of current and voltage. Consequently, voltage state data can be obtained through current monitoring data and a current&ndash;voltage model. Furthermore, voltage estimation can be implemented by utilizing voltage state data and voltage monitoring data. To validate the effectiveness of the FAKF-based estimation method, experiments have been conducted based on the published data set from NASA&rsquo;s Flyable Electro-Mechanical Actuator (FLEA) test stand. The experiment results demonstrate that the proposed method has good performance in EMA motor voltage estimation.
KW  - electro-mechanical actuator
KW  - performance degradation
KW  - voltage estimation
KW  - feature-aided Kalman filter
DO  - 10.3390/s18124190
ER  -
TY  - EJOU
AU  - Fairley, Iain
AU  - Mendzil, Anouska
AU  - Togneri, Michael
AU  - Reeve, Dominic E.
TI  - The Use of Unmanned Aerial Systems to Map Intertidal Sediment
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - This paper describes a new methodology to map intertidal sediment using a commercially available unmanned aerial system (UAS). A fixed-wing UAS was flown with both thermal and multispectral cameras over three study sites comprising of sandy and muddy areas. Thermal signatures of sediment type were not observable in the recorded data and therefore only the multispectral results were used in the sediment classification. The multispectral camera consisted of a Red&ndash;Green&ndash;Blue (RGB) camera and four multispectral sensors covering the green, red, red edge and near-infrared bands. Statistically significant correlations (&gt;99%) were noted between the multispectral reflectance and both moisture content and median grain size. The best correlation against median grain size was found with the near-infrared band. Three classification methodologies were tested to split the intertidal area into sand and mud: k-means clustering, artificial neural networks, and the random forest approach. Classification methodologies were tested with nine input subsets of the available data channels, including transforming the RGB colorspace to the Hue&ndash;Saturation&ndash;Value (HSV) colorspace. The classification approach that gave the best performance, based on the j-index, was when an artificial neural network was utilized with near-infrared reflectance and HSV color as input data. Classification performance ranged from good to excellent, with values of Youden&rsquo;s j-index ranging from 0.6 to 0.97 depending on flight date and site.
KW  - intertidal
KW  - sediment
KW  - unmanned aerial systems
KW  - multispectral
KW  - artificial neural network
KW  - environmental impact assessment
DO  - 10.3390/rs10121918
ER  -
TY  - EJOU
AU  - Fu, Kun
AU  - Li, Yang
AU  - Sun, Hao
AU  - Yang, Xue
AU  - Xu, Guangluan
AU  - Li, Yuting
AU  - Sun, Xian
TI  - A Ship Rotation Detection Model in Remote Sensing Images Based on Feature Fusion Pyramid Network and Deep Reinforcement Learning
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Ship detection plays an important role in automatic remote sensing image interpretation. The scale difference, large aspect ratio of ship, complex remote sensing image background and ship dense parking scene make the detection task difficult. To handle the challenging problems above, we propose a ship rotation detection model based on a Feature Fusion Pyramid Network and deep reinforcement learning (FFPN-RL) in this paper. The detection network can efficiently generate the inclined rectangular box for ship. First, we propose the Feature Fusion Pyramid Network (FFPN) that strengthens the reuse of different scales features, and FFPN can extract the low level location and high level semantic information that has an important impact on multi-scale ship detection and precise location of dense parking ships. Second, in order to get accurate ship angle information, we apply deep reinforcement learning to the inclined ship detection task for the first time. In addition, we put forward prior policy guidance and a long-term training method to train an angle prediction agent constructed through a dueling structure Q network, which is able to iteratively and accurately obtain the ship angle. In addition, we design soft rotation non-maximum suppression to reduce the missed ship detection while suppressing the redundant detection boxes. We carry out detailed experiments on the remote sensing ship image dataset, and the experiments validate that our FFPN-RL ship detection model has efficient detection performance.
KW  - ship detection
KW  - deep reinforcement learning
KW  - convolution neural network
KW  - feature map fusion
DO  - 10.3390/rs10121922
ER  -
TY  - EJOU
AU  - Levitan, Nathaniel
AU  - Gross, Barry
TI  - Utilizing Collocated Crop Growth Model Simulations to Train Agronomic Satellite Retrieval Algorithms
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Due to its worldwide coverage and high revisit time, satellite-based remote sensing provides the ability to monitor in-season crop state variables and yields globally. In this study, we presented a novel approach to training agronomic satellite retrieval algorithms by utilizing collocated crop growth model simulations and solar-reflective satellite measurements. Specifically, we showed that bidirectional long short-term memory networks (BLSTMs) can be trained to predict the in-season state variables and yields of Agricultural Production Systems sIMulator (APSIM) maize crop growth model simulations from collocated Moderate Resolution Imaging Spectroradiometer (MODIS) 500-m satellite measurements over the United States Corn Belt at a regional scale. We evaluated the performance of the BLSTMs through both k-fold cross validation and comparison to regional scale ground-truth yields and phenology. Using k-fold cross validation, we showed that three distinct in-season maize state variables (leaf area index, aboveground biomass, and specific leaf area) can be retrieved with cross-validated R2 values ranging from 0.4 to 0.8 for significant portions of the season. Several other plant, soil, and phenological in-season state variables were also evaluated in the study for their retrievability via k-fold cross validation. In addition, by comparing to survey-based United State Department of Agriculture (USDA) ground truth data, we showed that the BLSTMs are able to predict actual county-level yields with R2 values between 0.45 and 0.6 and actual state-level phenological dates (emergence, silking, and maturity) with R2 values between 0.75 and 0.85. We believe that a potential application of this methodology is to develop satellite products to monitor in-season field-scale crop growth on a global scale by reproducing the methodology with field-scale crop growth model simulations (utilizing farmer-recorded field-scale agromanagement data) and collocated high-resolution satellite data (fused with moderate-resolution satellite data).
KW  - crop growth models
KW  - MODIS
KW  - BLSTMs
DO  - 10.3390/rs10121968
ER  -
TY  - EJOU
AU  - Wang, Sheng
AU  - Garcia, Monica
AU  - Ibrom, Andreas
AU  - Jakobsen, Jakob
AU  - Josef Köppl, Christian
AU  - Mallick, Kaniska
AU  - Looms, Majken C.
AU  - Bauer-Gottwein, Peter
TI  - Mapping Root-Zone Soil Moisture Using a Temperature–Vegetation Triangle Approach with an Unmanned Aerial System: Incorporating Surface Roughness from Structure from Motion
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - High resolution root-zone soil moisture (SM) maps are important for understanding the spatial variability of water availability in agriculture, ecosystems research and water resources management. Unmanned Aerial Systems (UAS) can flexibly monitor land surfaces with thermal and optical imagery at very high spatial resolution (meter level, VHR) for most weather conditions. We modified the temperature&ndash;vegetation triangle approach to transfer it from satellite to UAS remote sensing. To consider the effects of the limited coverage of UAS mapping, theoretical dry/wet edges were introduced. The new method was tested on a bioenergy willow short rotation coppice site during growing seasons of 2016 and 2017. We demonstrated that by incorporating surface roughness parameters from the structure-from-motion in the interpretation of the measured land surface-atmosphere temperature gradients, the estimates of SM significantly improved. The correlation coefficient between estimated and measured SM increased from not significant to 0.69 and the root mean square deviation decreased from 0.045 m3∙m&minus;3 to 0.025 m3∙m&minus;3 when considering temporal dynamics of surface roughness in the approach. The estimated SM correlated better with in-situ root-zone SM (15&ndash;30 cm) than with surface SM (0&ndash;5 cm) which is an important advantage over alternative remote sensing methods to estimate SM. The optimal spatial resolution of the triangle approach was found to be around 1.5 m, i.e. similar to the length scale of tree-crowns. This study highlights the importance of considering the 3-D fine scale canopy structure, when addressing the links between surface temperature and SM patterns via surface energy balances. Our methodology can be applied to operationally monitor VHR root-zone SM from UAS in agricultural and natural ecosystems.
KW  - Thermal and optical remote sensing
KW  - Tree height
KW  - Very high spatial resolution
KW  - Surface energy balance
KW  - Unmanned Arial Systems (UAS)
DO  - 10.3390/rs10121978
ER  -
TY  - EJOU
AU  - She, Ying
AU  - Ehsani, Reza
AU  - Robbins, James
AU  - Nahún Leiva, Josué
AU  - Owen, Jim
TI  - Applications of High-Resolution Imaging for Open Field Container Nursery Counting
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Frequent inventory data of container nurseries is needed by growers to ensure proper management and marketing strategies. In this paper, inventory data are estimated from aerial images. Since there are thousands of nursery species, it is difficult to find a generic classification algorithm for all cases. In this paper, the development of classification methods was confined to three representative categories: green foliage, yellow foliage, and flowering plants. Vegetation index thresholding and the support vector machine (SVM) were used for classification. Classification accuracies greater than 97% were obtained for each case. Based on the classification results, an algorithm based on canopy area mapping was built for counting. The effects of flight altitude, container spacing, and ground cover type were evaluated. Results showed that container spacing and interaction of container spacing with ground cover type have a significant effect on counting accuracy. To mimic the practical shipping and moving process, incomplete blocks with different voids were created. Results showed that the more plants removed from the block, the higher the accuracy. The developed algorithm was tested on irregular- or regular-shaped plants and plants with and without flowers to test the stability of the algorithm, and accuracies greater than 94% were obtained.
KW  - image processing
KW  - container nursery
KW  - inventory management
KW  - counting
KW  - overlap separation
DO  - 10.3390/rs10122018
ER  -
TY  - EJOU
AU  - Lu, Chunyan
AU  - Liu, Jinfu
AU  - Jia, Mingming
AU  - Liu, Mingyue
AU  - Man, Weidong
AU  - Fu, Weiwei
AU  - Zhong, Lianxiu
AU  - Lin, Xiaoqing
AU  - Su, Ying
AU  - Gao, Yibin
TI  - Dynamic Analysis of Mangrove Forests Based on an Optimal Segmentation Scale Model and Multi-Seasonal Images in Quanzhou Bay, China
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Mangrove forests are important coastal ecosystems and are crucial for the equilibrium of the global carbon cycle. Monitoring and mapping of mangrove forests are essential for framing knowledge-based conservation policies and funding decisions by governments and managers. The purpose of this study was to monitor mangrove forest dynamics in the Quanzhou Bay Estuary Wetland Nature Reserve. To achieve this goal, we compared and analyzed the spectral discrimination among mangrove forests, mudflats and Spartina using multi-seasonal Landsat images from 1990, 1997, 2005, 2010, and 2017. We identified the spatio-temporal distribution of mangrove forests by combining an optimal segmentation scale model based on object-oriented classification, decision tree and visual interpretation. In addition, mangrove forest dynamics were determined by combining the annual land change area, centroid migration and overlay analysis. The results showed that there were advantages in the approaches used in this study for monitoring mangrove forests. From 1990 to 2017, the extent of mangrove forests increased by 2.48 km2, which was mostly converted from mudflats and Spartina. Environmental threats including climate change and sea-level rise, aquaculture development and Spartina invasion, pose potential and direct threats to the existence and expansion of mangrove forests. However, the implementation of reforestation projects and Spartina control plays a substantial role in the expansion of mangrove forests. It has been demonstrated that conservation activities can be beneficial for the restoration and succession of mangrove forests. This study provides an example of how the application of an optimal segmentation scale model and multi-seasonal images to mangrove forest monitoring can facilitate government policies that ensure the effective protection of mangrove forests.
KW  - mangrove forests
KW  - object-oriented classification
KW  - optimal segmentation scale model
KW  - multi-seasonal image
KW  - Quanzhou Bay
KW  - remote sensing dynamic monitoring
DO  - 10.3390/rs10122020
ER  -
TY  - EJOU
AU  - Zheng, Hengbiao
AU  - Li, Wei
AU  - Jiang, Jiale
AU  - Liu, Yong
AU  - Cheng, Tao
AU  - Tian, Yongchao
AU  - Zhu, Yan
AU  - Cao, Weixing
AU  - Zhang, Yu
AU  - Yao, Xia
TI  - A Comparative Assessment of Different Modeling Algorithms for Estimating Leaf Nitrogen Content in Winter Wheat Using Multispectral Images from an Unmanned Aerial Vehicle
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV)-based remote sensing (RS) possesses the significant advantage of being able to efficiently collect images for precision agricultural applications. Although numerous methods have been proposed to monitor crop nitrogen (N) status in recent decades, just how to utilize an appropriate modeling algorithm to estimate crop leaf N content (LNC) remains poorly understood, especially based on UAV multispectral imagery. A comparative assessment of different modeling algorithms (i.e., simple and non-parametric modeling algorithms alongside the physical model retrieval method) for winter wheat LNC estimation is presented in this study. Experiments were conducted over two consecutive years and involved different winter wheat varieties, N rates, and planting densities. A five-band multispectral camera (i.e., 490 nm, 550 nm, 671 nm, 700 nm, and 800 nm) was mounted on a UAV to acquire canopy images across five critical growth stages. The results of this study showed that the best-performing vegetation index (VI) was the modified renormalized difference VI (RDVI), which had a determination coefficient (R2) of 0.73 and a root mean square error (RMSE) of 0.38. This method was also characterized by a high processing speed (0.03 s) for model calibration and validation. Among the 13 non-parametric modeling algorithms evaluated here, the random forest (RF) approach performed best, characterized by R2 and RMSE values of 0.79 and 0.33, respectively. This method also had the advantage of full optical spectrum utilization and enabled flexible, non-linear fitting with a fast processing speed (2.3 s). Compared to the other two methods assessed here, the use of a look up table (LUT)-based radiative transfer model (RTM) remained challenging with regard to LNC estimation because of low prediction accuracy (i.e., an R2 value of 0.62 and an RMSE value of 0.46) and slow processing speed. The RF approach is a fast and accurate technique for N estimation based on UAV multispectral imagery.
KW  - UAV
KW  - multispectral imagery
KW  - LNC
KW  - vegetation index
KW  - non-parametric regression
KW  - radiative transfer model
DO  - 10.3390/rs10122026
ER  -
TY  - EJOU
AU  - Jiang, Wentao
AU  - Li, Jingwei
AU  - Yao, Xinli
AU  - Forsberg, Erik
AU  - He, Sailing
TI  - Fluorescence Hyperspectral Imaging of Oil Samples and Its Quantitative Applications in Component Analysis and Thickness Estimation
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 12
SN  - 1424-8220

AB  - The fast response and analysis of oil spill accidents is important but remains challenging. Here, a compact fluorescence hyperspectral system based on a grating-prism structure able to perform component analysis of oil as well as make a quantitative estimation of oil film thickness is developed. The spectrometer spectral range is 366&ndash;814 nm with a spectral resolution of 1 nm. The feasibility of the spectrometer system is demonstrated by determining the composition of three types of crude oil and various mixtures of them. The relationship between the oil film thickness and the fluorescent hyperspectral intensity is furthermore investigated and found to be linear, which demonstrates the feasibility of using the fluorescence data to quantitatively measure oil film thickness. Capable of oil identification, distribution analysis, and oil film thickness detection, the fluorescence hyperspectral imaging system presented is promising for use during oil spill accidents by mounting it on, e.g., an unmanned aerial vehicle.
KW  - fluorescence hyperspectral imaging
KW  - oil detection
KW  - principal component analysis
KW  - K-means clustering
DO  - 10.3390/s18124415
ER  -
TY  - EJOU
AU  - Li, Jiaojiao
AU  - Xi, Bobo
AU  - Du, Qian
AU  - Song, Rui
AU  - Li, Yunsong
AU  - Ren, Guangbo
TI  - Deep Kernel Extreme-Learning Machine for the Spectral–Spatial Classification of Hyperspectral Imagery
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Extreme-learning machines (ELM) have attracted significant attention in hyperspectral image classification due to their extremely fast and simple training structure. However, their shallow architecture may not be capable of further improving classification accuracy. Recently, deep-learning-based algorithms have focused on deep feature extraction. In this paper, a deep neural network-based kernel extreme-learning machine (KELM) is proposed. Furthermore, an excellent spatial guided filter with first-principal component (GFFPC) is also proposed for spatial feature enhancement. Consequently, a new classification framework derived from the deep KELM network and GFFPC is presented to generate deep spectral and spatial features. Experimental results demonstrate that the proposed framework outperforms some state-of-the-art algorithms with very low cost, which can be used for real-time processes.
KW  - hyperspectral classification
KW  - deep layer
KW  - kernel-based ELM
KW  - spectral and spatial features
DO  - 10.3390/rs10122036
ER  -
TY  - EJOU
AU  - Chen, Qi
AU  - Tian, Wenfeng
AU  - Chen, Wuwei
AU  - Ahmed, Qadeer
AU  - Wu, Yanming
TI  - Model-Based Fault Diagnosis of an Anti-Lock Braking System via Structural Analysis
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 12
SN  - 1424-8220

AB  - The anti-lock braking system (ABS) is an essential part in ensuring safe driving in vehicles. The Security of onboard safety systems is very important. In order to monitor the functions of ABS and avoid any malfunction, a model-based methodology with respect to structural analysis is employed in this paper to achieve an efficient fault detection and identification (FDI) system design. The analysis involves five essential steps of SA applied to ABS, which includes critical faults analysis, fault modelling, fault detectability analysis and fault isolability analysis, Minimal Structural Over-determined (MSO) sets selection, and MSO-based residual design. In terms of the four faults in the ABS, they are evaluated to be detectable through performing a structural representation and making the Dulmage-Mendelsohn decomposition with respect to the fault modelling, and then they are proved to be isolable based on the fault isolability matrix via SA. After that, four corresponding residuals are generated directly by a series of suggested equation combinations resulting from four MSO sets. The results generated by numerical simulations show that the proposed FDI system can detect and isolate all the injected faults, which is consistent with the theoretical analysis by SA, and also eventually validated by experimental testing on the vehicle (EcoCAR2) ABS.
KW  - fault detection and identification
KW  - anti-lock braking system
KW  - model-based
KW  - structural analysis
KW  - residual design
DO  - 10.3390/s18124468
ER  -
TY  - EJOU
AU  - Zhao, Caidan
AU  - Chen, Caiyun
AU  - He, Zeping
AU  - Wu, Zhiqiang
TI  - Application of Auxiliary Classifier Wasserstein Generative Adversarial Networks in Wireless Signal Classification of Illegal Unmanned Aerial Vehicles
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 12
SN  - 2076-3417

AB  - Recently, many studies have reported on image synthesis based on Generative Adversarial Networks (GAN). However, the use of GAN does not provide much attention on the signal classification problem. In the context of using wireless signals to classify illegal Unmanned Aerial Vehicles (UAVs), this paper explores the feasibility of using GAN to improve the training datasets and obtain a better classification model, thereby improving the accuracy of classification. First, we use the generative model of GAN to generate a large datasets, which does not need manual annotation. At the same time, the discriminative model of GAN is improved to classify the types of signals based on the loss function of the discriminative model. Finally, this model can be used to the outdoor environment and obtain a real-time illegal UAVs signal classification system. Our experiments confirmed that the improvements on the Auxiliary Classifier Generative Adversarial Networks (AC-GANs) by limited datasets achieve excellent results. The recognition rate can reach more than 95% in the indoor environment, and this method is also applicable in the outdoor environment. Moreover, based on the theory of Wasserstein GANs (WGAN) and AC-GANs, a more robust Auxiliary Classifier Wasserstein GANs (AC-WGANs) model is obtained, which is suitable for multi-class UAVs. Through the combination of AC-WGANs and Universal Software Radio Peripheral (USRP) B210 software defined radio (SDR) platform, a real-time UAVs signal classification system is also implemented.
KW  - GAN
KW  - AC-WGANs
KW  - wireless signals
KW  - classify model
KW  - USRP
DO  - 10.3390/app8122664
ER  -
TY  - EJOU
AU  - Guo, Hao
AU  - Wei, Guo
AU  - An, Jubai
TI  - Dark Spot Detection in SAR Images of Oil Spill Using Segnet
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 12
SN  - 2076-3417

AB  - Damping Bragg scattering from the ocean surface is the basic underlying principle of synthetic aperture radar (SAR) oil slick detection, and they produce dark spots on SAR images. Dark spot detection is the first step in oil spill detection, which affects the accuracy of oil spill detection. However, some natural phenomena (such as waves, ocean currents, and low wind belts, as well as human factors) may change the backscatter intensity on the surface of the sea, resulting in uneven intensity, high noise, and blurred boundaries of oil slicks or lookalikes. In this paper, Segnet is used as a semantic segmentation model to detect dark spots in oil spill areas. The proposed method is applied to a data set of 4200 from five original SAR images of an oil spill. The effectiveness of the method is demonstrated through the comparison with fully convolutional networks (FCN), an initiator of semantic segmentation models, and some other segmentation methods. It is here observed that the proposed method can not only accurately identify the dark spots in SAR images, but also show a higher robustness under high noise and fuzzy boundary conditions.
KW  - image segmentation
KW  - deep learning
KW  - synthetic aperture radar (SAR)
KW  - oil slicks
KW  - segnet
DO  - 10.3390/app8122670
ER  -
TY  - EJOU
AU  - Huang, Lingcao
AU  - Liu, Lin
AU  - Jiang, Liming
AU  - Zhang, Tingjun
TI  - Automatic Mapping of Thermokarst Landforms from Remote Sensing Images Using Deep Learning: A Case Study in the Northeastern Tibetan Plateau
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Thawing of ice-rich permafrost causes thermokarst landforms on the ground surface. Obtaining the distribution of thermokarst landforms is a prerequisite for understanding permafrost degradation and carbon exchange at local and regional scales. However, because of their diverse types and characteristics, it is challenging to map thermokarst landforms from remote sensing images. We conducted a case study towards automatically mapping a type of thermokarst landforms (i.e., thermo-erosion gullies) in a local area in the northeastern Tibetan Plateau from high-resolution images by the use of deep learning. In particular, we applied the DeepLab algorithm (based on Convolutional Neural Networks) to a 0.15-m-resolution Digital Orthophoto Map (created using aerial photographs taken by an Unmanned Aerial Vehicle). Here, we document the detailed processing flow with key steps including preparing training data, fine-tuning, inference, and post-processing. Validating against the field measurements and manual digitizing results, we obtained an F1 score of 0.74 (precision is 0.59 and recall is 1.0), showing that the proposed method can effectively map small and irregular thermokarst landforms. It is potentially viable to apply the designed method to mapping diverse thermokarst landforms in a larger area where high-resolution images and training data are available.
KW  - DeepLab
KW  - permafrost degradation
KW  - semantic segmentation
KW  - thermokarst landforms
KW  - thermo-erosion gullies
KW  - Tibetan Plateau
KW  - Unmanned Aerial Vehicle Images
DO  - 10.3390/rs10122067
ER  -
TY  - EJOU
AU  - Rançon, Florian
AU  - Bombrun, Lionel
AU  - Keresztes, Barna
AU  - Germain, Christian
TI  - Comparison of SIFT Encoded and Deep Learning Features for the Classification and Detection of Esca Disease in Bordeaux Vineyards
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Grapevine wood fungal diseases such as esca are among the biggest threats in vineyards nowadays. The lack of very efficient preventive (best results using commercial products report 20% efficiency) and curative means induces huge economic losses. The study presented in this paper is centered around the in-field detection of foliar esca symptoms during summer, exhibiting a typical &ldquo;striped&rdquo; pattern. Indeed, in-field disease detection has shown great potential for commercial applications and has been successfully used for other agricultural needs such as yield estimation. Differentiation with foliar symptoms caused by other diseases or abiotic stresses was also considered. Two vineyards from the Bordeaux region (France, Aquitaine) were chosen as the basis for the experiment. Pictures of diseased and healthy vine plants were acquired during summer 2017 and labeled at the leaf scale, resulting in a patch database of around 6000 images (224 &times; 224 pixels) divided into red cultivar and white cultivar samples. Then, we tackled the classification part of the problem comparing state-of-the-art SIFT encoding and pre-trained deep learning feature extractors for the classification of database patches. In the best case, 91% overall accuracy was obtained using deep features extracted from MobileNet network trained on ImageNet database, demonstrating the efficiency of simple transfer learning approaches without the need to design an ad-hoc specific feature extractor. The third part aimed at disease detection (using bounding boxes) within full plant images. For this purpose, we integrated the deep learning base network within a &ldquo;one-step&rdquo; detection network (RetinaNet), allowing us to perform detection queries in real time (approximately six frames per second on GPU). Recall/Precision (RP) and Average Precision (AP) metrics then allowed us to evaluate the performance of the network on a 91-image (plants) validation database. Overall, 90% precision for a 40% recall was obtained while best esca AP was about 70%. Good correlation between annotated and detected symptomatic surface per plant was also obtained, meaning slightly symptomatic plants can be efficiently separated from severely attacked plants.
KW  - proximal sensing
KW  - disease detection
KW  - grapevine trunk disease
KW  - esca
KW  - SIFT
KW  - deep learning
DO  - 10.3390/rs11010001
ER  -
TY  - EJOU
AU  - Wang, Kepu
AU  - Wang, Tiejun
AU  - Liu, Xuehua
TI  - A Review: Individual Tree Species Classification Using Integrated Airborne LiDAR and Optical Imagery with a Focus on the Urban Environment
T2  - Forests

PY  - 2019
VL  - 10
IS  - 1
SN  - 1999-4907

AB  - With the significant progress of urbanization, cities and towns are suffering from air pollution, heat island effects, and other environmental problems. Urban vegetation, especially trees, plays a significant role in solving these ecological problems. To maximize services provided by vegetation, urban tree species should be properly selected and optimally arranged. Therefore, accurate classification of tree species in urban environments has become a major issue. In this paper, we reviewed the potential of light detection and ranging (LiDAR) data to improve the accuracy of urban tree species classification. In detail, we reviewed the studies using LiDAR data in urban tree species mapping, especially studies where LiDAR data was fused with optical imagery, through classification accuracy comparison, general workflow extraction, and discussion and summarizing of the specific contribution of LiDAR. It is concluded that combining LiDAR data in urban tree species identification could achieve better classification accuracy than using either dataset individually, and that such improvements are mainly due to finer segmentation, shadowing effect reduction, and refinement of classification rules based on LiDAR. Furthermore, some suggestions are given to improve the classification accuracy on a finer and larger species level, while also aiming to maintain classification costs.
KW  - LiDAR
KW  - optical imagery
KW  - tree species classification
KW  - urban forests
DO  - 10.3390/f10010001
ER  -
TY  - EJOU
AU  - Chen, Yuyun
AU  - Li, Longwei
AU  - Lu, Dengsheng
AU  - Li, Dengqiu
TI  - Exploring Bamboo Forest Aboveground Biomass Estimation Using Sentinel-2 Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Bamboo forests, due to rapid growth and short harvest rotation, play an important role in carbon cycling and local economic development. Accurate estimation of bamboo forest aboveground biomass (AGB) has garnered increasing attention during the past two decades. However, remote sensing-based AGB estimation for bamboo forests is challenging due to poor understanding of the mechanisms between bamboo forest growth characteristics and remote sensing data. The objective of this research is to examine the remote sensing characteristics of on-year and off-year bamboo forests at different dates and their AGB estimation performance. This research used multiple Sentinel-2 data to explore AGB estimation of bamboo forests in Zhejiang Province, China, by taking into account the unique characteristics of on-year and off-year bamboo forest growth features. Combining field survey data and Sentinel-2 spectral responses (spectral bands and vegetation indices) and textural images, random forest was used to identify key variables for AGB estimation. The results show that (1) the on-year and off-year bamboo forests have considerably different spectral signatures, especially in the wavelengths between red edge 2 and near-infrared wavelength (NIR2) (740&ndash;865 nm), making it possible to separate on-year and off-year bamboo forests; (2) on-year bamboo forests have similar spectral signatures although AGB increases from as small as 40 Mgha&minus;1 to as high as 90 Mgha&minus;1, implying that optical sensor data cannot effectively model on-year bamboo AGB; (3) off-year bamboo AGB has significant relationships with red and shortwave infrared (SWIR) spectral bands in the April image and with red edge 2 in the July image, but the AGB saturation problem yields poor estimation accuracy; (4) stratification considerably improved off-year bamboo AGB estimation but not on-year, non-stratification using the April image is recommended; and (5) Sentinel-2 data cannot solve the bamboo AGB data saturation problem when AGB is greater than 70 Mgha&minus;1, similar to other optical sensor data such as Landsat. More research should be conducted in the future to integrate multiple sources&mdash;remotely sensed data (e.g., lidar, optical sensor data) and ancillary data (e.g., soil, topography)&mdash;into AGB modeling to improve the estimation. The use of very high spatial resolution images that can effectively extract tree density information may improve bamboo AGB estimation and yield new insights.
KW  - bamboo forests
KW  - on-year and off-year
KW  - aboveground biomass
KW  - random forest
KW  - Sentinel-2
DO  - 10.3390/rs11010007
ER  -
TY  - EJOU
AU  - Luo, Dong
AU  - Li, Yuanyuan
AU  - Li, Junnan
AU  - Lim, Kok-Sing
AU  - Nazal, Nurul A.
AU  - Ahmad, Harith
TI  - A Recent Progress of Steel Bar Corrosion Diagnostic Techniques in RC Structures
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 1
SN  - 1424-8220

AB  - Corrosion of steel bar is one of key factors undermining reinforced concrete (RC) structures in a harsh environment. This paper attempts to review the non-destructive procedures from the aspect of the corrosion measurement techniques, especially their advantages and limitations. Systematical classification of diagnostic methods is carried out to determine any probable corrosion issues before the structures become severe, and helps choose the suitable method according to different construction features. Furthermore, the three electrochemical factors method is introduced to inspire researchers to combine various techniques to improve corrosion evaluation accuracy. The recommendations for future work are summarized, in conclusion.
KW  - corrosion of steel bar (CSB)
KW  - corrosion rate
KW  - corrosion current density
KW  - physical methods
KW  - electrochemical methods
DO  - 10.3390/s19010034
ER  -
TY  - EJOU
AU  - Wang, Yuhao
AU  - Liang, Binxiu
AU  - Ding, Meng
AU  - Li, Jiangyun
TI  - Dense Semantic Labeling with Atrous Spatial Pyramid Pooling and Decoder for High-Resolution Remote Sensing Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Dense semantic labeling is significant in high-resolution remote sensing imagery research and it has been widely used in land-use analysis and environment protection. With the recent success of fully convolutional networks (FCN), various types of network architectures have largely improved performance. Among them, atrous spatial pyramid pooling (ASPP) and encoder-decoder are two successful ones. The former structure is able to extract multi-scale contextual information and multiple effective field-of-view, while the latter structure can recover the spatial information to obtain sharper object boundaries. In this study, we propose a more efficient fully convolutional network by combining the advantages from both structures. Our model utilizes the deep residual network (ResNet) followed by ASPP as the encoder and combines two scales of high-level features with corresponding low-level features as the decoder at the upsampling stage. We further develop a multi-scale loss function to enhance the learning procedure. In the postprocessing, a novel superpixel-based dense conditional random field is employed to refine the predictions. We evaluate the proposed method on the Potsdam and Vaihingen datasets and the experimental results demonstrate that our method performs better than other machine learning or deep learning methods. Compared with the state-of-the-art DeepLab_v3+ our model gains 0.4% and 0.6% improvements in overall accuracy on these two datasets respectively.
KW  - remote sensing imagery
KW  - dense semantic labeling
KW  - fully convolutional networks
KW  - atrous spatial pyramid pooling
KW  - encoder-decoder
KW  - superpixel-based DenseCRF
DO  - 10.3390/rs11010020
ER  -
TY  - EJOU
AU  - Bae, Dae H.
AU  - Kim, Jae W.
AU  - Heo, Jae-Pil
TI  - Content-Aware Focal Plane Selection and Proposals for Object Tracking on Plenoptic Image Sequences
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 1
SN  - 1424-8220

AB  - Object tracking is a fundamental problem in computer vision since it is required in many practical applications including video-based surveillance and autonomous vehicles. One of the most challenging scenarios in the problem is when the target object is partially or even fully occluded by other objects. In such cases, most of existing trackers can fail in their task while the object is invisible. Recently, a few techniques have been proposed to tackle the occlusion problem by performing the tracking on plenoptic image sequences. Although they have shown promising results based on the refocusing capability of plenoptic images, there is still room for improvement. In this paper, we propose a novel focus index selection algorithm to identify an optimal focal plane where the tracking should be performed. To determine an optimal focus index, we use a focus measure to find maximally focused plane and a visual similarity to capture the plane where the target object is visible, and its appearance is distinguishably clear. We further use the selected focus index to generate proposals. Since the optimal focus index allows us to estimate the distance between the camera and the target object, we can more accurately guess the scale changes of the object in the image plane. Our proposal algorithm also takes the trajectory of the target object into account. We extensively evaluate our proposed techniques on three plenoptic image sequences by comparing them against the prior tracking methods specialized to the plenoptic image sequences. In experiments, our method provides higher accuracy and robustness over the prior art, and those results confirm that the merits of our proposed algorithms.
KW  - plenoptic imaging technique
KW  - object tracking
KW  - bounding box proposal
KW  - content-based image matching
DO  - 10.3390/s19010048
ER  -
TY  - EJOU
AU  - Shin, Jisun
AU  - Kim, Keunyong
AU  - Son, Young B.
AU  - Ryu, Joo-Hyung
TI  - Synergistic Effect of Multi-Sensor Data on the Detection of Margalefidinium polykrikoides in the South Sea of Korea
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Since 1995, Margalefidinium polykrikoides blooms have occurred frequently in the waters around the Korean peninsula. In the South Sea of Korea (SSK), large-scale M. polykrikoides blooms form offshore and are often transported to the coast, where they gradually accumulate. The objective of this study was to investigate the synergistic effect of multi-sensor data for identifying M. polykrikoides blooms in the SSK from July 2018 to August 2018. We found that the Spectral Shape values calculated from in situ spectra and M. polykrikoides cell abundances in the SSK were highly correlated. Comparing red tide spectra from near-coincident multi-sensor data, remote-sensing reflectance (Rrs) spectra were similar to the spectra of in situ measurements from blue to green wavelengths. Rrs true-color composite images and Spectral Shape images of each sensor showed a clear pattern of M. polykrikoides patches, although there were some limitations for detecting red tide patches in coastal areas. We confirmed the complementarity of red tide data extracted from each sensor using an integrated red tide map. Statistical assessment showed that the sensitivity of red tide detection increased when multi-sensor data were used rather than single-sensor data. These results provide useful information for the application of multi-sensor for red tide detection.
KW  - harmful algal blooms
KW  - Margalefidinium polykrikoides
KW  - the South Sea of Korea
KW  - multi-sensor
KW  - Geostationary Ocean Color Imager
KW  - Sentinel
KW  - Landsat
DO  - 10.3390/rs11010036
ER  -
TY  - EJOU
AU  - Mahdianpari, Masoud
AU  - Salehi, Bahram
AU  - Mohammadimanesh, Fariba
AU  - Homayouni, Saeid
AU  - Gill, Eric
TI  - The First Wetland Inventory Map of Newfoundland at a Spatial Resolution of 10 m Using Sentinel-1 and Sentinel-2 Data on the Google Earth Engine Cloud Computing Platform
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Wetlands are one of the most important ecosystems that provide a desirable habitat for a great variety of flora and fauna. Wetland mapping and modeling using Earth Observation (EO) data are essential for natural resource management at both regional and national levels. However, accurate wetland mapping is challenging, especially on a large scale, given their heterogeneous and fragmented landscape, as well as the spectral similarity of differing wetland classes. Currently, precise, consistent, and comprehensive wetland inventories on a national- or provincial-scale are lacking globally, with most studies focused on the generation of local-scale maps from limited remote sensing data. Leveraging the Google Earth Engine (GEE) computational power and the availability of high spatial resolution remote sensing data collected by Copernicus Sentinels, this study introduces the first detailed, provincial-scale wetland inventory map of one of the richest Canadian provinces in terms of wetland extent. In particular, multi-year summer Synthetic Aperture Radar (SAR) Sentinel-1 and optical Sentinel-2 data composites were used to identify the spatial distribution of five wetland and three non-wetland classes on the Island of Newfoundland, covering an approximate area of 106,000 km2. The classification results were evaluated using both pixel-based and object-based random forest (RF) classifications implemented on the GEE platform. The results revealed the superiority of the object-based approach relative to the pixel-based classification for wetland mapping. Although the classification using multi-year optical data was more accurate compared to that of SAR, the inclusion of both types of data significantly improved the classification accuracies of wetland classes. In particular, an overall accuracy of 88.37% and a Kappa coefficient of 0.85 were achieved with the multi-year summer SAR/optical composite using an object-based RF classification, wherein all wetland and non-wetland classes were correctly identified with accuracies beyond 70% and 90%, respectively. The results suggest a paradigm-shift from standard static products and approaches toward generating more dynamic, on-demand, large-scale wetland coverage maps through advanced cloud computing resources that simplify access to and processing of the “Geo Big Data.” In addition, the resulting ever-demanding inventory map of Newfoundland is of great interest to and can be used by many stakeholders, including federal and provincial governments, municipalities, NGOs, and environmental consultants to name a few.
KW  - wetland
KW  - Google Earth Engine
KW  - Sentinel-1
KW  - Sentinel-2
KW  - random forest
KW  - cloud computing
KW  - geo-big data
DO  - 10.3390/rs11010043
ER  -
TY  - EJOU
AU  - Moskalenko, Viacheslav
AU  - Moskalenko, Alona
AU  - Korobov, Artem
AU  - Semashko, Viktor
TI  - The Model and Training Algorithm of Compact Drone Autonomous Visual Navigation System
T2  - Data

PY  - 2019
VL  - 4
IS  - 1
SN  - 2306-5729

AB  - Trainable visual navigation systems based on deep learning demonstrate potential for robustness of onboard camera parameters and challenging environment. However, a deep model requires substantial computational resources and large labelled training sets for successful training. Implementation of the autonomous navigation and training-based fast adaptation to the new environment for a compact drone is a complicated task. The article describes an original model and training algorithms adapted to the limited volume of labelled training set and constrained computational resource. This model consists of a convolutional neural network for visual feature extraction, extreme-learning machine for estimating the position displacement and boosted information-extreme classifier for obstacle prediction. To perform unsupervised training of the convolution filters with a growing sparse-coding neural gas algorithm, supervised learning algorithms to construct the decision rules with simulated annealing search algorithm used for finetuning are proposed. The use of complex criterion for parameter optimization of the feature extractor model is considered. The resulting approach performs better trajectory reconstruction than the well-known ORB-SLAM. In particular, for sequence 7 from the KITTI dataset, the translation error is reduced by nearly 65.6% under the frame rate 10 frame per second. Besides, testing on the independent TUM sequence shot outdoors produces a translation error not exceeding 6% and a rotation error not exceeding 3.68 degrees per 100 m. Testing was carried out on the Raspberry Pi 3+ single-board computer.
KW  - navigation
KW  - visual odometry
KW  - convolutional neural network
KW  - neural gas
KW  - information criterion
KW  - extreme learning
DO  - 10.3390/data4010004
ER  -
TY  - EJOU
AU  - Nguyen, Ngoc P.
AU  - Hong, Sung K.
TI  - Fault-Tolerant Control of Quadcopter UAVs Using Robust Adaptive Sliding Mode Approach
T2  - Energies

PY  - 2019
VL  - 12
IS  - 1
SN  - 1996-1073

AB  - In this paper, a fault-tolerant control method is proposed for quadcopter unmanned aerial vehicles (UAV) to account for system uncertainties and actuator faults. A mathematical model of the quadcopter UAV is first introduced when faults occur in actuators. A normal adaptive sliding mode control (NASMC) approach is proposed as a baseline controller to handle the chattering problem and system uncertainties, which does not require information of the upper bound. To improve the performance of the NASMC scheme, radial basis function neural networks are combined with an adaptive scheme to make a quick compensation in presence of system uncertainties and actuator faults. The Lyapunov theory is applied to verify the stability of the proposed methods. The effectiveness of modified ASMC algorithm is compared with that of NASMC using numerical examples under different faulty conditions.
KW  - fault diagnosis
KW  - quadcopter UAV
KW  - fault tolerant control
KW  - radial basic function
KW  - adaptive sliding mode control
DO  - 10.3390/en12010095
ER  -
TY  - EJOU
AU  - Navarro, José A.
AU  - Algeet, Nur
AU  - Fernández-Landa, Alfredo
AU  - Esteban, Jessica
AU  - Rodríguez-Noriega, Pablo
AU  - Guillén-Climent, María L.
TI  - Integration of UAV, Sentinel-1, and Sentinel-2 Data for Mangrove Plantation Aboveground Biomass Monitoring in Senegal
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Due to the increasing importance of mangroves in climate change mitigation projects, more accurate and cost-effective aboveground biomass (AGB) monitoring methods are required. However, field measurements of AGB may be a challenge because of their remote location and the difficulty to walk in these areas. This study is based on the Livelihoods Fund Oceanium project that monitors 10,000 ha of mangrove plantations. In a first step, the possibility of replacing traditional field measurements of sample plots in a young mangrove plantation by a semiautomatic processing of UAV-based photogrammetric point clouds was assessed. In a second step, Sentinel-1 radar and Sentinel-2 optical imagery were used as auxiliary information to estimate AGB and its variance for the entire study area under a model-assisted framework. AGB was measured using UAV imagery in a total of 95 sample plots. UAV plot data was used in combination with non-parametric support vector regression (SVR) models for the estimation of the study area AGB using model-assisted estimators. Purely UAV-based AGB estimates and their associated standard error (SE) were compared with model-assisted estimates using (1) Sentinel-1, (2) Sentinel-2, and (3) a combination of Sentinel-1 and Sentinel-2 data as auxiliary information. The validation of the UAV-based individual tree height and crown diameter measurements showed a root mean square error (RMSE) of 0.21 m and 0.32 m, respectively. Relative efficiency of the three model-assisted scenarios ranged between 1.61 and 2.15. Although all SVR models improved the efficiency of the monitoring over UAV-based estimates, the best results were achieved when a combination of Sentinel-1 and Sentinel-2 data was used. Results indicated that the methodology used in this research can provide accurate and cost-effective estimates of AGB in young mangrove plantations.
KW  - digital aerial photogrammetry
KW  - SAR
KW  - model-assisted
KW  - biomass estimation
KW  - Copernicus
KW  - unmanned aerial vehicles
DO  - 10.3390/rs11010077
ER  -
TY  - EJOU
AU  - Andriolo, Umberto
AU  - Sánchez-García, Elena
AU  - Taborda, Rui
TI  - Operational Use of Surfcam Online Streaming Images for Coastal Morphodynamic Studies
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Coastal video monitoring has been proven to be a valuable shore-based remote-sensing technique to study coastal processes, as it offers the possibility of high-frequency, continuous and autonomous observations of the coastal area. However, the installation of a video systems infrastructure requires economical and technical efforts, along with being often limited by logistical constraints. This study presents methodological approaches to exploit &ldquo;surfcam&rdquo; internet streamed images for quantitative scientific studies. Two different methodologies to collect the required ground control points (GCPs), both during fieldwork and using web tools freely available are presented, in order to establish a rigorous geometric connection between terrestrial and image spaces. The application of an image projector tool allowed the estimation of the unknown camera parameters necessary to georectify the online streamed images. Three photogrammetric procedures are shown, distinct both in the design of the computational steps and in number of GCPs available to solve the spatial resection system. Results showed the feasibility of the methodologies to generate accurate rectified planar images, with the best horizontal projection accuracy of 1.3 m compatible with that required for a quantitative analysis of coastal processes. The presented methodologies can turn &ldquo;surfcam&rdquo; infrastructures and any online streaming beach cam, into fully remote shore-based observational systems, fostering the use of these freely available images for the study of nearshore morphodynamics.
KW  - video
KW  - photogrammetry
KW  - nearshore
KW  - coastal morphodynamics
KW  - beach
DO  - 10.3390/rs11010078
ER  -
TY  - EJOU
AU  - Zhang, YuYing
AU  - Thenkabail, Prasad S.
AU  - Wang, Peng
TI  - A Bibliometric Profile of the Remote Sensing Open Access Journal Published by MDPI between 2009 and 2018
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Remote Sensing Open Access Journal (RS OAJ) is an international leading journal in the field of remote sensing science and technology. It was first published in the year 2009 and is currently celebrating tenth year of publications. In this research, a bibliometric analysis of RS OAJ was conducted based on 5588 articles published during the 10-year (2009&ndash;2018) time-period. The bibliometric analysis includes a comprehensive set of indicators such as dynamics and trends of publications, journal impact factor, total cites, eigenfactor score, normalized eigenfactor, CiteScore, h-index, h-classic publications, most productive countries (or territories) and institutions, co-authorship collaboration about countries (territories), research themes, citation impact of co-occurrences keywords, intellectual structure, and knowledge commutation. We found that publications of RS OAJ presented an exponential growth in the past ten years. From 2010 to 2017 (for which complete years data were available), the h-index of RS OAJ is 67. From 2009&ndash;2018, RS OAJ includes publications from 129 countries (or territories) and 3826 institutions. The leading nations contributing articles, based on 2009&ndash;2018 data, and listed based on ranking were: China, United States, Germany, Italy, France, Spain, Canada, England, Australia, Netherlands, Japan, Switzerland and Austria. The leading institutions, also for the same period and listed based on ranking were: Chinese Academy of Sciences, Wuhan University, University of Chinese Academy of Sciences, Beijing Normal University, The university of Maryland, National Aeronautics and Space Administration, National Oceanic and Atmospheric Administration, China University of Geosciences, United States Geological Survey, German Aerospace Centre, University of Twente, and California Institute of Technology. For the year 2017, RS OAJ had an impressive journal impact factor of 3.4060, a CiteScore of 4.03, eigenfactor score of 0.0342, and normalized eigenfactor score of 3.99. In addition, based on 2009&ndash;2018, data co-word analysis determined that &ldquo;remote sensing&rdquo;, &ldquo;MODIS&rdquo;, &ldquo;Landsat&rdquo;, &ldquo;LiDAR&rdquo; and &ldquo;NDVI&rdquo; are the high-frequency of author keywords co-occurrence in RS OAJ. The main themes of RS OAJ are multi-spectral and hyperspectral remote sensing, LiDAR scanning and forestry remote sensing monitoring, MODIS and LAI data applications, Remote sensing applications and Synthetic Aperture Radar (SAR). Through author keywords citation impact analysis, we find the most influential keyword is Unmanned Aerial Vehicle (UAV), followed, forestry, Normalized Difference Vegetation Index (NDVI), terrestrial laser scanning, airborne laser scanning, forestry inventory, urban heat island, monitoring, agriculture, and laser scanning. By analyzing the intellectual structure of RS OAJ, we identify the main reference publications and find that the themes are about Random Forests, MODIS vegetation indices and image analysis, etc. RS OAJ ranks first in cited journals and third in citing, this indicates that RS OAJ has the internal knowledge flow. Our results will bring more benefits to scholars, researchers and graduate students, who hopes to get a quick overview of the RS OAJ. And this article will also be the starting point for communication between scholars and practitioners. Finally, this paper proposed a nuanced h-index (nh-index) to measure productivity and intellectual contribution of authors by considering h-index based on whether the one is first, second, third, or nth author. This nuanced approach to determining h-index of authors is powerful indicator of an academician&rsquo;s productivity and intellectual contribution.
KW  - bibliometric
KW  - citation impact
KW  - remote sensing
KW  - research theme
KW  - scientific journals evaluation
DO  - 10.3390/rs11010091
ER  -
TY  - EJOU
AU  - Hernandez-Santin, Lorna
AU  - Rudge, Mitchel L.
AU  - Bartolo, Renee E.
AU  - Erskine, Peter D.
TI  - Identifying Species and Monitoring Understorey from UAS-Derived Data: A Literature Review and Future Directions
T2  - Drones

PY  - 2019
VL  - 3
IS  - 1
SN  - 2504-446X

AB  - Understorey vegetation plays an important role in many ecosystems, yet identifying and monitoring understorey vegetation through remote sensing has proved a challenge for researchers and land managers because understorey plants tend to be small, spatially and spectrally similar, and are often blocked by the overstorey. The emergence of Unmanned Aerial Systems (UAS) is revolutionising how vegetation is measured, and may allow us to measure understorey species where traditional remote sensing previously could not. The goal of this paper was to review current literature and assess the current capability of UAS to identify and monitor understorey vegetation. From the literature, we focused on the technical attributes that limit the ability to monitor understorey vegetation&mdash;specifically (1) spatial resolution, (2) spectral sensitivity, (3) spatial extent, and (4) temporal frequency at which a sensor acquires data. We found that UAS have provided improved levels of spatial resolution, with authors reporting successful classifications of understorey vegetation at resolutions of between 3 mm and 200 mm. Species discrimination can be achieved by targeting flights to correspond with phenological events to allow the detection of species-specific differences. We provide recommendations as to how UAS attributes can be tailored to help identify and monitor understorey species.
KW  - UAV
KW  - drone
KW  - sub-canopy
KW  - understory
KW  - vegetation
KW  - remote sensing
KW  - spatial resolution
KW  - spectral sensitivity
KW  - spatial extent
KW  - temporal frequency
DO  - 10.3390/drones3010009
ER  -
TY  - EJOU
AU  - Ayhan, Bulent
AU  - Kwan, Chiman
AU  - Budavari, Bence
AU  - Larkin, Jude
AU  - Gribben, David
TI  - Preflight Contingency Planning Approach for Fixed Wing UAVs with Engine Failure in the Presence of Winds
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 2
SN  - 1424-8220

AB  - Preflight contingency planning that utilizes wind forecast in path planning can be highly beneficial to unmanned aerial vehicles (UAV) operators in preventing a possible mishap of the UAV. This especially becomes more important if the UAV has an engine failure resulting in the loss of all its thrust. Wind becomes a significant factor in determining reachability of the emergency landing site in a contingency like this. The preflight contingency plans can guide the UAV operators about how to glide the aircraft to the designated emergency landing site to make a safe landing. The need for a preflight or in-flight contingency plan is even more obvious in the case of a communication loss between the UAV operator and UAV since the UAV will then need to make the forced landing autonomously without the operator. In this paper, we introduce a preflight contingency planning approach that automates the forced landing path generation process for UAVs with engine failure. The contingency path generation aims true reachability to the emergency landing site by including the final approach part of the path in forecast wind conditions. In the contingency path generation, no-fly zones that could be in the area are accounted for and the contingency flight paths do not pass through them. If no plans can be found that fulfill reachability in the presence of no-fly zones, only then, as a last resort, the no-fly zone avoidance rule is relaxed. The contingency path generation utilizes hourly forecast wind data from National Oceanic and Atmospheric Administration for the geographical area of interest and time of the flight. Different from past works, we use trochoidal paths instead of Dubins curves and incorporate wind as a parameter in the contingency path design.
KW  - contingency planning
KW  - automated landing
KW  - forced landing
KW  - path generation
KW  - wind forecast
KW  - UAV
DO  - 10.3390/s19020227
ER  -
TY  - EJOU
AU  - Shiu, Yi-Shiang
AU  - Chuang, Yung-Chung
TI  - Yield Estimation of Paddy Rice Based on Satellite Imagery: Comparison of Global and Local Regression Models
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 2
SN  - 2072-4292

AB  - Precisely estimating the yield of paddy rice is crucial for national food security and development evaluation. Rice yield estimation based on satellite imagery is usually performed with global regression models; however, estimation errors may occur because the spatial variation is not considered. Therefore, this study proposed an approach estimating paddy rice yield based on global and local regression models. In our study area, the overall per-field data might not available because it took lots of time and manpower as well as resources. Therefore, we gathered and accumulated 26 to 63 ground survey sample fields, accounting for about 0.05% of the total cultivated areas, as the training samples for our regression models. To demonstrate whether the spatial autocorrelation or spatial heterogeneity exists and dominates the estimation, global models including the ordinary least squares (OLS), support vector regression (SVR), and the local model geographically weighted regression (GWR) were used to build the yield estimation models. We obtained the representative independent variables, including 4 original bands, 11 vegetation indices, and 32 texture indices, from SPOT-7 multispectral satellite imagery. To determine the optimal variable combination, feature selection based on the Pearson correlation was used for all of the regression models. The case study in Central Taiwan rendered that the error rate was between 0.06% and 13.22%. Through feature selection, the GWR model&rsquo;s performance was more relatively stable than the OLS model and nonlinear SVR model for yield estimation. Where the GWR model considers the spatial autocorrelation and spatial heterogeneity of the relationships between the yield and the independent variables, the OLS and nonlinear SVR models lack this feature; this led to the rice yield estimation of GWR in this study be more stable than those of the other two models.
KW  - yield estimation
KW  - geographically weighted regression
KW  - support vector regression
KW  - vegetation indices
KW  - grey-level co-occurrence matrix
DO  - 10.3390/rs11020111
ER  -
TY  - EJOU
AU  - Esmaeili, Farid
AU  - Ebadi, Hamid
AU  - Saadatseresht, Mohammad
AU  - Kalantary, Farzin
TI  - Application of UAV Photogrammetry in Displacement Measurement of the Soil Nail Walls Using Local Features and CPDA Method
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 1
SN  - 2220-9964

AB  - The high cost of land across urban areas has made the excavation a typical practice to construct multiple underground stories. Various methods have been used to restrain the excavated walls and keep them from a possible collapse, including nailing and anchorage. The excavated wall monitoring, especially during the drilling and restraining operations, is necessary for preventing the risk of such incidents as an excavated wall collapse. In the present research, an unmanned aerial vehicle (UAV) photogrammetry-based algorithm was proposed for accurate, fast and low-cost monitoring of excavated walls. Different stages of the proposed methodology included design of the UAV photogrammetry network for optimal imaging, local feature extraction from the acquired images, a special optimal matching method and finally, displacement estimation through a combined adjustment method. Results of implementations showed that, using the proposed methodology, one can achieve a precision of &plusmn;7 mm in positioning local features on the excavated walls. Moreover, the wall displacement could be measured at an accuracy of &plusmn;1 cm. Having high flexibility, easy implementation, low cost and fast pace; the proposed methodology provides an appropriate alternative to micro-geodesic procedures and the use of instrumentations for excavated wall displacement monitoring.
KW  - UAV photogrammetry
KW  - Close range photogrammetry
KW  - Local features
KW  - Soil Nail Wall
KW  - Measurement of deformation
KW  - Network design
DO  - 10.3390/ijgi8010025
ER  -
TY  - EJOU
AU  - Zhuo, Xiangyu
AU  - Fraundorfer, Friedrich
AU  - Kurz, Franz
AU  - Reinartz, Peter
TI  - Automatic Annotation of Airborne Images by Label Propagation Based on a Bayesian-CRF Model
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 2
SN  - 2072-4292

AB  - The tremendous advances in deep neural networks have demonstrated the superiority of deep learning techniques for applications such as object recognition or image classification. Nevertheless, deep learning-based methods usually require a large amount of training data, which mainly comes from manual annotation and is quite labor-intensive. In order to reduce the amount of manual work required for generating enough training data, we hereby propose to leverage existing labeled data to generate image annotations automatically. Specifically, the pixel labels are firstly transferred from one image modality to another image modality via geometric transformation to create initial image annotations, and then additional information (e.g., height measurements) is incorporated for Bayesian inference to update the labeling beliefs. Finally, the updated label assignments are optimized with a fully connected conditional random field (CRF), yielding refined labeling for all pixels in the image. The proposed approach is tested on two different scenarios, i.e., (1) label propagation from annotated aerial imagery to unmanned aerial vehicle (UAV) imagery and (2) label propagation from map database to aerial imagery. In each scenario, the refined image labels are used as pseudo-ground truth data for training a convolutional neural network (CNN). Results demonstrate that our model is able to produce accurate label assignments even around complex object boundaries; besides, the generated image labels can be effectively leveraged for training CNNs and achieve comparable classification accuracy as manual image annotations, more specifically, the per-class classification accuracy of the networks trained by the manual image annotations and the generated image labels have a difference within     &plusmn; 5 %    .
KW  - automatic image annotation
KW  - label propagation
KW  - Conditional Random Field (CRF)
KW  - Convolutional Neural Network (CNN)
DO  - 10.3390/rs11020145
ER  -
TY  - EJOU
AU  - Giernacki, Wojciech
AU  - Horla, Dariusz
AU  - Báča, Tomáš
AU  - Saska, Martin
TI  - Real-Time Model-Free Minimum-Seeking Autotuning Method for Unmanned Aerial Vehicle Controllers Based on Fibonacci-Search Algorithm
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 2
SN  - 1424-8220

AB  - The paper presents a novel autotuning approach for finding locally-best parameters of controllers on board of unmanned aerial vehicles (UAVs). The controller tuning is performed fully autonomously during flight on the basis of predefined ranges of controller parameters. Required controller properties may be simply interpreted by a cost function, which is involved in the optimization process. For example, the sum of absolute values of the tracking error samples or performance indices, including weighed functions of control signal samples, can be penalized to achieve very precise position control, if required. The proposed method relies on an optimization procedure using Fibonacci-search technique fitted into bootstrap sequences, enabling one to obtain a global minimizer for a unimodal cost function. The approach is characterized by low computational complexity and does not require any UAV dynamics model (just periodical measurements from basic onboard sensors) to obtain proper tuning of a controller. In addition to the theoretical background of the method, an experimental verification in real-world outdoor conditions is provided. The experiments have demonstrated a high robustness of the method to in-environment disturbances, such as wind, and its easy deployability.
KW  - UAV
KW  - auto-tuning
KW  - extremum-seeking control
KW  - iterative learning
KW  - optimization
DO  - 10.3390/s19020312
ER  -
TY  - EJOU
AU  - Gao, Pengbo
AU  - Zhang, Yan
AU  - Zhang, Linhuan
AU  - Noguchi, Ryozo
AU  - Ahamed, Tofael
TI  - Development of a Recognition System for Spraying Areas from Unmanned Aerial Vehicles Using a Machine Learning Approach
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 2
SN  - 1424-8220

AB  - Unmanned aerial vehicle (UAV)-based spraying systems have recently become important for the precision application of pesticides, using machine learning approaches. Therefore, the objective of this research was to develop a machine learning system that has the advantages of high computational speed and good accuracy for recognizing spray and non-spray areas for UAV-based sprayers. A machine learning system was developed by using the mutual subspace method (MSM) for images collected from a UAV. Two target lands: agricultural croplands and orchard areas, were considered in building two classifiers for distinguishing spray and non-spray areas. The field experiments were conducted in target areas to train and test the system by using a commercial UAV (DJI Phantom 3 Pro) with an onboard 4K camera. The images were collected from low (5 m) and high (15 m) altitudes for croplands and orchards, respectively. The recognition system was divided into offline and online systems. In the offline recognition system, 74.4% accuracy was obtained for the classifiers in recognizing spray and non-spray areas for croplands. In the case of orchards, the average classifier recognition accuracy of spray and non-spray areas was 77%. On the other hand, the online recognition system performance had an average accuracy of 65.1% for croplands, and 75.1% for orchards. The computational time for the online recognition system was minimal, with an average of 0.0031 s for classifier recognition. The developed machine learning system had an average recognition accuracy of 70%, which can be implemented in an autonomous UAV spray system for recognizing spray and non-spray areas for real-time applications.
KW  - precision agriculture
KW  - recognition system
KW  - image classifiers
KW  - machine learning system
KW  - mutual subspace method
DO  - 10.3390/s19020313
ER  -
TY  - EJOU
AU  - Xie, Zhuli
AU  - Chen, Yaoliang
AU  - Lu, Dengsheng
AU  - Li, Guiying
AU  - Chen, Erxue
TI  - Classification of Land Cover, Forest, and Tree Species Classes with ZiYuan-3 Multispectral and Stereo Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 2
SN  - 2072-4292

AB  - The global availability of high spatial resolution images makes mapping tree species distribution possible for better management of forest resources. Previous research mainly focused on mapping single tree species, but information about the spatial distribution of all kinds of trees, especially plantations, is often required. This research aims to identify suitable variables and algorithms for classifying land cover, forest, and tree species. Bi-temporal ZiYuan-3 multispectral and stereo images were used. Spectral responses and textures from multispectral imagery, canopy height features from bi-temporal stereo imagery, and slope and elevation from the stereo-derived digital surface model data were examined through comparative analysis of six classification algorithms including maximum likelihood classifier (MLC), k-nearest neighbor (kNN), decision tree (DT), random forest (RF), artificial neural network (ANN), and support vector machine (SVM). The results showed that use of multiple source data&mdash;spectral bands, vegetation indices, textures, and topographic factors&mdash;considerably improved land-cover and forest classification accuracies compared to spectral bands alone, which the highest overall accuracy of 84.5% for land cover classes was from the SVM, and, of 89.2% for forest classes, was from the MLC. The combination of leaf-on and leaf-off seasonal images further improved classification accuracies by 7.8% to 15.0% for land cover classes and by 6.0% to 11.8% for forest classes compared to single season spectral image. The combination of multiple source data also improved land cover classification by 3.7% to 15.5% and forest classification by 1.0% to 12.7% compared to the spectral image alone. MLC provided better land-cover and forest classification accuracies than machine learning algorithms when spectral data alone were used. However, some machine learning approaches such as RF and SVM provided better performance than MLC when multiple data sources were used. Further addition of canopy height features into multiple source data had no or limited effects in improving land-cover or forest classification, but improved classification accuracies of some tree species such as birch and Mongolia scotch pine. Considering tree species classification, Chinese pine, Mongolia scotch pine, red pine, aspen and elm, and other broadleaf trees as having classification accuracies of over 92%, and larch and birch have relatively low accuracies of 87.3% and 84.5%. However, these high classification accuracies are from different data sources and classification algorithms, and no one classification algorithm provided the best accuracy for all tree species classes. This research implies the same data source and the classification algorithm cannot provide the best classification results for different land cover classes. It is necessary to develop a comprehensive classification procedure using an expert-based approach or hierarchical-based classification approach that can employ specific data variables and algorithm for each tree species class.
KW  - tree species
KW  - classification
KW  - ZiYuan-3
KW  - stereo image
KW  - machine learning
DO  - 10.3390/rs11020164
ER  -
TY  - EJOU
AU  - Liu, Wei
AU  - Cheng, Dayu
AU  - Yin, Pengcheng
AU  - Yang, Mengyuan
AU  - Li, Erzhu
AU  - Xie, Meng
AU  - Zhang, Lianpeng
TI  - Small Manhole Cover Detection in Remote Sensing Imagery with Deep Convolutional Neural Networks
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 1
SN  - 2220-9964

AB  - With the development of remote sensing technology and the advent of high-resolution images, obtaining data has become increasingly convenient. However, the acquisition of small manhole cover information still has shortcomings including low efficiency of manual surveying and high leakage rate. Recently, deep learning models, especially deep convolutional neural networks (DCNNs), have proven to be effective at object detection. However, several challenges limit the applications of DCNN in manhole cover object detection using remote sensing imagery: (1) Manhole cover objects often appear at different scales in remotely sensed images and DCNNs&rsquo; fixed receptive field cannot match the scale variability of such objects; (2) Manhole cover objects in large-scale remotely-sensed images are relatively small in size and densely packed, while DCNNs have poor localization performance when applied to such objects. To address these problems, we propose an effective method for detecting manhole cover objects in remotely-sensed images. First, we redesign the feature extractor by adopting the visual geometry group (VGG), which can increase the variety of receptive field size. Then, detection is performed using two sub-networks: a multi-scale output network (MON) for manhole cover object-like edge generation from several intermediate layers whose receptive fields match different object scales and a multi-level convolution matching network (M-CMN) for object detection based on fused feature maps, which combines several feature maps that enable small and densely packed manhole cover objects to produce a stronger response. The results show that our method is more accurate than existing methods at detecting manhole covers in remotely-sensed images.
KW  - manhole cover
KW  - remote sensing images
KW  - object detection
KW  - deep convolutional neural networks
DO  - 10.3390/ijgi8010049
ER  -
TY  - EJOU
AU  - Ghorbanzadeh, Omid
AU  - Blaschke, Thomas
AU  - Gholamnia, Khalil
AU  - Meena, Sansar R.
AU  - Tiede, Dirk
AU  - Aryal, Jagannath
TI  - Evaluation of Different Machine Learning Methods and Deep-Learning Convolutional Neural Networks for Landslide Detection
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 2
SN  - 2072-4292

AB  - There is a growing demand for detailed and accurate landslide maps and inventories around the globe, but particularly in hazard-prone regions such as the Himalayas. Most standard mapping methods require expert knowledge, supervision and fieldwork. In this study, we use optical data from the Rapid Eye satellite and topographic factors to analyze the potential of machine learning methods, i.e., artificial neural network (ANN), support vector machines (SVM) and random forest (RF), and different deep-learning convolution neural networks (CNNs) for landslide detection. We use two training zones and one test zone to independently evaluate the performance of different methods in the highly landslide-prone Rasuwa district in Nepal. Twenty different maps are created using ANN, SVM and RF and different CNN instantiations and are compared against the results of extensive fieldwork through a mean intersection-over-union (mIOU) and other common metrics. This accuracy assessment yields the best result of 78.26% mIOU for a small window size CNN, which uses spectral information only. The additional information from a 5 m digital elevation model helps to discriminate between human settlements and landslides but does not improve the overall classification accuracy. CNNs do not automatically outperform ANN, SVM and RF, although this is sometimes claimed. Rather, the performance of CNNs strongly depends on their design, i.e., layer depth, input window sizes and training strategies. Here, we conclude that the CNN method is still in its infancy as most researchers will either use predefined parameters in solutions like Google TensorFlow or will apply different settings in a trial-and-error manner. Nevertheless, deep-learning can improve landslide mapping in the future if the effects of the different designs are better understood, enough training samples exist, and the effects of augmentation strategies to artificially increase the number of existing samples are better understood.
KW  - deep-learning
KW  - convolution neural networks (CNNs)
KW  - artificial neural network
KW  - RapidEye
KW  - landslide mapping
KW  - mean intersection-over-union (mIOU)
DO  - 10.3390/rs11020196
ER  -
TY  - EJOU
AU  - Pham, Tien D.
AU  - Yokoya, Naoto
AU  - Bui, Dieu T.
AU  - Yoshino, Kunihiko
AU  - Friess, Daniel A.
TI  - Remote Sensing Approaches for Monitoring Mangrove Species, Structure, and Biomass: Opportunities and Challenges
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - The mangrove ecosystem plays a vital role in the global carbon cycle, by reducing greenhouse gas emissions and mitigating the impacts of climate change. However, mangroves have been lost worldwide, resulting in substantial carbon stock losses. Additionally, some aspects of the mangrove ecosystem remain poorly characterized compared to other forest ecosystems due to practical difficulties in measuring and monitoring mangrove biomass and their carbon stocks. Without a quantitative method for effectively monitoring biophysical parameters and carbon stocks in mangroves, robust policies and actions for sustainably conserving mangroves in the context of climate change mitigation and adaptation are more difficult. In this context, remote sensing provides an important tool for monitoring mangroves and identifying attributes such as species, biomass, and carbon stocks. A wide range of studies is based on optical imagery (aerial photography, multispectral, and hyperspectral) and synthetic aperture radar (SAR) data. Remote sensing approaches have been proven effective for mapping mangrove species, estimating their biomass, and assessing changes in their extent. This review provides an overview of the techniques that are currently being used to map various attributes of mangroves, summarizes the studies that have been undertaken since 2010 on a variety of remote sensing applications for monitoring mangroves, and addresses the limitations of these studies. We see several key future directions for the potential use of remote sensing techniques combined with machine learning techniques for mapping mangrove areas and species, and evaluating their biomass and carbon stocks.
KW  - mangrove species
KW  - mapping
KW  - biomass
KW  - blue carbon
KW  - machine learning
KW  - REDD+
DO  - 10.3390/rs11030230
ER  -
TY  - EJOU
AU  - Burgués, Javier
AU  - Hernández, Victor
AU  - Lilienthal, Achim J.
AU  - Marco, Santiago
TI  - Smelling Nano Aerial Vehicle for Gas Source Localization and Mapping
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 3
SN  - 1424-8220

AB  - This paper describes the development and validation of the currently smallest aerial platform with olfaction capabilities. The developed Smelling Nano Aerial Vehicle (SNAV) is based on a lightweight commercial nano-quadcopter (27 g) equipped with a custom gas sensing board that can host up to two in situ metal oxide semiconductor (MOX) gas sensors. Due to its small form-factor, the SNAV is not a hazard for humans, enabling its use in public areas or inside buildings. It can autonomously carry out gas sensing missions of hazardous environments inaccessible to terrestrial robots and bigger drones, for example searching for victims and hazardous gas leaks inside pockets that form within the wreckage of collapsed buildings in the aftermath of an earthquake or explosion. The first contribution of this work is assessing the impact of the nano-propellers on the MOX sensor signals at different distances to a gas source. A second contribution is adapting the ‘bout’ detection algorithm, proposed by Schmuker et al. (2016) to extract specific features from the derivative of the MOX sensor response, for real-time operation. The third and main contribution is the experimental validation of the SNAV for gas source localization (GSL) and mapping in a large indoor environment (160 m2) with a gas source placed in challenging positions for the drone, for example hidden in the ceiling of the room or inside a power outlet box. Two GSL strategies are compared, one based on the instantaneous gas sensor response and the other one based on the bout frequency. From the measurements collected (in motion) along a predefined sweeping path we built (in less than 3 min) a 3D map of the gas distribution and identified the most likely source location. Using the bout frequency yielded on average a higher localization accuracy than using the instantaneous gas sensor response (1.38 m versus 2.05 m error), however accurate tuning of an additional parameter (the noise threshold) is required in the former case. The main conclusion of this paper is that a nano-drone has the potential to perform gas sensing tasks in complex environments.
KW  - robotics
KW  - signal processing
KW  - electronics
KW  - gas source localization
KW  - gas distribution mapping
KW  - gas sensors
KW  - drone
KW  - UAV
KW  - MOX sensor
KW  - quadcopter
DO  - 10.3390/s19030478
ER  -
TY  - EJOU
AU  - Rasti, Pejman
AU  - Ahmad, Ali
AU  - Samiei, Salma
AU  - Belin, Etienne
AU  - Rousseau, David
TI  - Supervised Image Classification by Scattering Transform with Application to Weed Detection in Culture Crops of High Density
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - In this article, we assess the interest of the recently introduced multiscale scattering transform for texture classification applied for the first time in plant science. Scattering transform is shown to outperform monoscale approaches (gray-level co-occurrence matrix, local binary patterns) but also multiscale approaches (wavelet decomposition) which do not include combinatory steps. The regime in which scatter transform also outperforms a standard CNN architecture in terms of data-set size is evaluated (    10 4     instances). An approach on how to optimally design the scatter transform based on energy contrast is provided. This is illustrated on the hard and open problem of weed detection in culture crops of high density from the top view in intensity images. An annotated synthetic data-set available under the form of a data challenge and a simulator are proposed for reproducible science. Scatter transform only trained on synthetic data shows an accuracy of     85 %     when tested on real data.
KW  - weed detection
KW  - scatter transform
KW  - deep learning
KW  - machine-learning classification
KW  - annotation
KW  - synthetic data
KW  - local binary pattern
DO  - 10.3390/rs11030249
ER  -
TY  - EJOU
AU  - Xu, Zheng
AU  - Luo, Haibo
AU  - Hui, Bin
AU  - Chang, Zheng
TI  - Siamese Tracking from Single Point Initialization
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 3
SN  - 1424-8220

AB  - Recently, we have been concerned with locating and tracking vehicles in aerial videos. Vehicles in aerial videos usually have small sizes due to use of cameras from a remote distance. However, most of the current methods use a fixed bounding box region as the input of tracking. For the purpose of target locating and tracking in our system, detecting the contour of the target is utilized and can help with improving the accuracy of target tracking, because a shape-adaptive template segmented by object contour contains the most useful information and the least background for object tracking. In this paper, we propose a new start-up of tracking by clicking on the target, and implement the whole tracking process by modifying and combining a contour detection network and a fully convolutional Siamese tracking network. The experimental results show that our algorithm has significantly improved tracking accuracy compared to the state-of-the-art regarding vehicle images in both OTB100 and DARPA datasets. We propose utilizing our method in real time tracking and guidance systems.
KW  - object tracking
KW  - contour detection
KW  - Siamese network
KW  - deep learning
DO  - 10.3390/s19030514
ER  -
TY  - EJOU
AU  - Qing, Xinlin
AU  - Li, Wenzhuo
AU  - Wang, Yishou
AU  - Sun, Hu
TI  - Piezoelectric Transducer-Based Structural Health Monitoring for Aircraft Applications
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 3
SN  - 1424-8220

AB  - Structural health monitoring (SHM) is being widely evaluated by the aerospace industry as a method to improve the safety and reliability of aircraft structures and also reduce operational cost. Built-in sensor networks on an aircraft structure can provide crucial information regarding the condition, damage state and/or service environment of the structure. Among the various types of transducers used for SHM, piezoelectric materials are widely used because they can be employed as either actuators or sensors due to their piezoelectric effect and vice versa. This paper provides a brief overview of piezoelectric transducer-based SHM system technology developed for aircraft applications in the past two decades. The requirements for practical implementation and use of structural health monitoring systems in aircraft application are then introduced. State-of-the-art techniques for solving some practical issues, such as sensor network integration, scalability to large structures, reliability and effect of environmental conditions, robust damage detection and quantification are discussed. Development trend of SHM technology is also discussed.
KW  - structural health monitoring
KW  - piezoelectric transducer
KW  - sensor network
KW  - damage detection
KW  - aircraft
DO  - 10.3390/s19030545
ER  -
TY  - EJOU
AU  - Xu, Ziyao
AU  - Lian, Jijian
AU  - Bin, Lingling
AU  - Hua, Kaixun
AU  - Xu, Kui
AU  - Chan, Hoi Y.
TI  - Water Price Prediction for Increasing Market Efficiency Using Random Forest Regression: A Case Study in the Western United States
T2  - Water

PY  - 2019
VL  - 11
IS  - 2
SN  - 2073-4441

AB  - The existence of water markets establishes water prices, promoting trading of water from low- to high-valued uses. However, market participants can face uncertainty when asking and offering prices because water rights are heterogeneous, resulting in inefficiency of the market. This paper proposes three random forest regression models (RFR) to predict water price in the western United States: a full variable set model and two reduced ones with optimal numbers of variables using a backward variable elimination (BVE) approach. Transactions of 12 semiarid states, from 1987 to 2009, and a dataset containing various predictors, were assembled. Multiple replications of k-fold cross-validation were applied to assess the model performance and their generalizability was tested on unused data. The importance of price influencing factors was then analyzed based on two plausible variable importance rankings. Results show that the RFR models have good predictive power for water price. They outperform a baseline model without leading to overfitting. Also, the higher degree of accuracy of the reduced models is insignificant, reflecting the robustness of RFR to including lower informative variables. This study suggests that, due to its ability to automatically learn from and make predictions on data, RFR-based models can aid water market participants in making more efficient decisions.
KW  - water market
KW  - water price prediction
KW  - market efficiency
KW  - random forest regression
KW  - machine learning
DO  - 10.3390/w11020228
ER  -
TY  - EJOU
AU  - Wu, Ruidong
AU  - Liu, Bing
AU  - Fu, Ping
AU  - Li, Junbao
AU  - Feng, Shou
TI  - An Accelerator Architecture of Changeable-Dimension Matrix Computing Method for SVM
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 2
SN  - 2079-9292

AB  - Matrix multiplication is a critical time-consuming processing step in many machine learning applications. Due to the diversity of practical applications, the matrix dimensions are generally not fixed. However, most matrix calculation methods, based on field programmable gate array (FPGA) currently use fixed matrix dimensions, which limit the flexibility of machine learning algorithms in a FPGA. The bottleneck lies in the limited FPGA resources. Therefore, this paper proposes an accelerator architecture for matrix computing method with changeable dimensions. Multi-matrix synchronous calculation concept allows matrix data to be processed continuously, which improves the parallel computing characteristics of FPGA and optimizes the computational efficiency. This paper tests matrix multiplication using support vector machine (SVM) algorithm to verify the performance of proposed architecture on the ZYNQ platform. The experimental results show that, compared to the software processing method, the proposed architecture increases the performance by 21.18 times with 9947 dimensions. The dimension is changeable with a maximum value of 2,097,151, without changing hardware design. This method is also applicable to matrix multiplication processing with other machine learning algorithms.
KW  - changeable-dimension matrix computing
KW  - field programmable gate array (FPGA)
KW  - support vector machine (SVM)
KW  - ZYNQ
DO  - 10.3390/electronics8020143
ER  -
TY  - EJOU
AU  - Fu, Yongyong
AU  - Liu, Kunkun
AU  - Shen, Zhangquan
AU  - Deng, Jinsong
AU  - Gan, Muye
AU  - Liu, Xinguo
AU  - Lu, Dongming
AU  - Wang, Ke
TI  - Mapping Impervious Surfaces in Town–Rural Transition Belts Using China’s GF-2 Imagery and Object-Based Deep CNNs
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - Impervious surfaces play an important role in urban planning and sustainable environmental management. High-spatial-resolution (HSR) images containing pure pixels have significant potential for the detailed delineation of land surfaces. However, due to high intraclass variability and low interclass distance, the mapping and monitoring of impervious surfaces in complex town&ndash;rural areas using HSR images remains a challenge. The fully convolutional network (FCN) model, a variant of convolution neural networks (CNNs), recently achieved state-of-the-art performance in HSR image classification applications. However, due to the inherent nature of FCN processing, it is challenging for an FCN to precisely capture the detailed information of classification targets. To solve this problem, we propose an object-based deep CNN framework that integrates object-based image analysis (OBIA) with deep CNNs to accurately extract and estimate impervious surfaces. Specifically, we also adopted two widely used transfer learning technologies to expedite the training of deep CNNs. Finally, we compare our approach with conventional OBIA classification and state-of-the-art FCN-based methods, such as FCN-8s and the U-Net methods. Both of these FCN-based methods are well designed for pixel-wise classification applications and have achieved great success. Our results show that the proposed approach effectively identified impervious surfaces, with 93.9% overall accuracy. Compared with the existing methods, i.e., OBIA, FCN-8s and U-Net methods, it shows that our method achieves obviously improvement in accuracy. Our findings also suggest that the classification performance of our proposed method is related to training strategy, indicating that significantly higher accuracy can be achieved through transfer learning by fine-tuning rather than feature extraction. Our approach for the automatic extraction and mapping of impervious surfaces also lays a solid foundation for intelligent monitoring and the management of land use and land cover.
KW  - transfer learning
KW  - remote sensing
KW  - deep learning
KW  - object-based image analysis (OBIA)
DO  - 10.3390/rs11030280
ER  -
TY  - EJOU
AU  - Gebremedhin, Alem
AU  - Badenhorst, Pieter E.
AU  - Wang, Junping
AU  - Spangenberg, German C.
AU  - Smith, Kevin F.
TI  - Prospects for Measurement of Dry Matter Yield in Forage Breeding Programs Using Sensor Technologies
T2  - Agronomy

PY  - 2019
VL  - 9
IS  - 2
SN  - 2073-4395

AB  - Increasing the yield of perennial forage crops remains a crucial factor underpinning the profitability of grazing industries, and therefore is a priority for breeding programs. Breeding for high dry matter yield (DMY) in forage crops is likely to be enhanced with the development of genomic selection (GS) strategies. However, realising the full potential of GS will require an increase in the amount of phenotypic data and the rate at which it is collected. Therefore, phenotyping remains a critical bottleneck in the implementation of GS in forage species. Assessments of DMY in forage crop breeding include visual scores, sample clipping and mowing of plots, which are often costly and time-consuming. New ground- and aerial-based platforms equipped with advanced sensors offer opportunities for fast, nondestructive and low-cost, high-throughput phenotyping (HTP) of plant growth, development and yield in a field environment. The workflow of image acquisition, processing and analysis are reviewed. The &ldquo;big data&rdquo; challenges, proposed storage and management techniques, development of advanced statistical tools and methods for incorporating the HTP into forage breeding systems are also reviewed. Initial results where these techniques have been applied to forages have been promising but further research and development is required to adapt them to forage breeding situations, particularly with respect to the management of large data sets and the integration of information from spaced plants to sward plots. However, realizing the potential of sensor technologies combined with GS leads to greater rates of genetic gain in forages.
KW  - forage dry matter yield
KW  - high-throughput phenotyping
KW  - automation
KW  - imaging and image analysis
DO  - 10.3390/agronomy9020065
ER  -
TY  - EJOU
AU  - Tan, Juan
AU  - Fan, Yonghua
AU  - Yan, Pengpeng
AU  - Wang, Chun
AU  - Feng, Hao
TI  - Sliding Mode Fault Tolerant Control for Unmanned Aerial Vehicle with Sensor and Actuator Faults
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 3
SN  - 1424-8220

AB  - The unmanned aerial vehicle (UAV) has been developing rapidly recently, and the safety and the reliability of the UAV are significant to the mission execution and the life of UAV. Sensor and actuator failures of a UAV are one of the most common malfunctions, threating the safety and life of the UAV. Fault-tolerant control technology is an effective method to improve the reliability and safety of UAV, which also contributes to vehicle health management (VHM). This paper deals with the sliding mode fault-tolerant control of the UAV, considering the failures of sensor and actuator. Firstly, a terminal sliding surface is designed to ensure the state of the system on the sliding mode surface throughout the control process based on the simplified coupling dynamic model. Then, the sliding mode control (SMC) method combined with the RBF neural network algorithm is used to design the parameters of the sliding mode controller, and with this, the efficiency of the design process is improved and system chattering is minimized. Finally, the Simulink simulations are carried out using a fault tolerance controller under the conditions where accelerometer sensor, gyroscope sensor or actuator failures is assumed. The results show that the proposed control strategy is quite an effective method for the control of UAVs with accelerometer sensor, gyroscope sensor or actuator failures.
KW  - unmanned aerial vehicle (UAV)
KW  - sensor faults
KW  - actuator faults
KW  - fault-tolerant control
KW  - sliding mode control (SMC)
DO  - 10.3390/s19030643
ER  -
TY  - EJOU
AU  - Salamí, Esther
AU  - Gallardo, Antonia
AU  - Skorobogatov, Georgy
AU  - Barrado, Cristina
TI  - On-the-Fly Olive Tree Counting Using a UAS and Cloud Services
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - Unmanned aerial systems (UAS) are becoming a common tool for aerial sensing applications. Nevertheless, sensed data need further processing before becoming useful information. This processing requires large computing power and time before delivery. In this paper, we present a parallel architecture that includes an unmanned aerial vehicle (UAV), a small embedded computer on board, a communication link to the Internet, and a cloud service with the aim to provide useful real-time information directly to the end-users. The potential of parallelism as a solution in remote sensing has not been addressed for a distributed architecture that includes the UAV processors. The architecture is demonstrated for a specific problem: the counting of olive trees in a crop field where the trees are regularly spaced from each other. During the flight, the embedded computer is able to process individual images on board the UAV and provide the total count. The tree counting algorithm obtains an     F 1     score of     99.09 %     for a sequence of ten images with 332 olive trees. The detected trees are geolocated and can be visualized on the Internet seconds after the take-off of the flight, with no further processing required. This is a use case to demonstrate near real-time results obtained from UAS usage. Other more complex UAS applications, such as tree inventories, search and rescue, fire detection, or stock breeding, can potentially benefit from this architecture and obtain faster outcomes, accessible while the UAV is still on flight.
KW  - UAS
KW  - UAV
KW  - image segmentation
KW  - tree counting
KW  - distributed services
KW  - cloud computing
DO  - 10.3390/rs11030316
ER  -
TY  - EJOU
AU  - Al-Kaff, Abdulla
AU  - Gómez-Silva, María J.
AU  - Moreno, Francisco M.
AU  - de la Escalera, Arturo
AU  - Armingol, José M.
TI  - An Appearance-Based Tracking Algorithm for Aerial Search and Rescue Purposes
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 3
SN  - 1424-8220

AB  - The automation of the Wilderness Search and Rescue (WiSAR) task aims for high levels of understanding of various scenery. In addition, working in unfriendly and complex environments may cause a time delay in the operation and consequently put human lives at stake. In order to address this problem, Unmanned Aerial Vehicles (UAVs), which provide potential support to the conventional methods, are used. These vehicles are provided with reliable human detection and tracking algorithms; in order to be able to find and track the bodies of the victims in complex environments, and a robust control system to maintain safe distances from the detected bodies. In this paper, a human detection based on the color and depth data captured from onboard sensors is proposed. Moreover, the proposal of computing data association from the skeleton pose and a visual appearance measurement allows the tracking of multiple people with invariance to the scale, translation and rotation of the point of view with respect to the target objects. The system has been validated with real and simulation experiments, and the obtained results show the ability to track multiple individuals even after long-term disappearances. Furthermore, the simulations present the robustness of the implemented reactive control system as a promising tool for assisting the pilot to perform approaching maneuvers in a safe and smooth manner.
KW  - multi-object tracking
KW  - UAV
KW  - rescue
KW  - reactive control
DO  - 10.3390/s19030652
ER  -
TY  - EJOU
AU  - Ba, Rui
AU  - Song, Weiguo
AU  - Li, Xiaolian
AU  - Xie, Zixi
AU  - Lo, Siuming
TI  - Integration of Multiple Spectral Indices and a Neural Network for Burned Area Mapping Based on MODIS Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - Since wildfires have occurred frequently in recent years, accurate burned area mapping is required for wildfire severity assessment and burned land reconstruction. Satellite remote sensing is an effective technology that can provide valuable information for wildfire assessment. However, the common approaches based on using a single satellite image to promptly detect the burned areas have low accuracy and limited applicability. This paper develops a new burned area mapping method that surpasses the detection accuracy of previous methods, while still using a single Moderate Resolution Imaging Spectroradiometer (MODIS) sensor image. The key innovation is integrating optimal spectral indices and a neural network algorithm. We used the traditional empirical formula method, multi-threshold method and visual interpretation method to extract the sample sets of five typical types (burned area, vegetation, cloud, bare soil, and cloud shadow) from the MODIS data of several wildfires in the American states of Nevada, Washington and California in 2016. Afterward, the separability index M was adopted to assess the capacity of seven spectral bands and 13 spectral indices to distinguish the burned area from four unburned land cover types. Based on the separability analysis between the burned area and unburned areas, the spectral indices with an M value higher than 1.0 were employed to generate the training sample sets that were assessed to have an overall accuracy of 98.68% and Kappa coefficient of 97.46%. Finally, we utilized a back-propagation neural network (BPNN) to learn the spectral differences of different types from the training sample sets and obtain the output burned area map. The proposed method was applied to three wildfire cases in the American states of Idaho, Nevada and Oregon in 2017. A comparison of detection results between the new MODIS-based burned area map and the reference burned area map compiled from Landsat-8 Operational Land Imager (OLI) data indicates that the proposed method can effectively exploit the spectral characteristics of various land cover types. Also, this new method can achieve higher accuracy with the reduction of commission error (CE, &gt;10%) and omission error (OE, &gt;6%) compared to the traditional empirical formula method. The new burned area mapping method could help managers and the public perform more effective wildfire assessments and emergency management.
KW  - MODIS
KW  - burned area
KW  - spectral indices
KW  - neural network
DO  - 10.3390/rs11030326
ER  -
TY  - EJOU
AU  - Zhang, Siqi
AU  - Chen, Hui
AU  - Fu, Yang
AU  - Niu, Huihui
AU  - Yang, Yi
AU  - Zhang, Boxiong
TI  - Fractional Vegetation Cover Estimation of Different Vegetation Types in the Qaidam Basin
T2  - Sustainability

PY  - 2019
VL  - 11
IS  - 3
SN  - 2071-1050

AB  - The estimation of fractional vegetation cover (FVC) by using remote sensing images has become feasible. Based on Landsat8-OLI images and field data obtained from an unmanned aerial vehicle, we established an empirical model (EM) and a pixel decomposition model (PDM) of FVC in the desert vegetation region, steppe vegetation region, meadow vegetation region and mixed vegetation region (the three vegetation region types) of the Qaidam Basin, and the inversion accuracies of the models were compared. The results show the following: (1) Vegetation classification inversion (VCI) provides a promising approach for FVC estimation. The accuracy of FVC by VCI was obviously better than that achieved using vegetation mixed inversion (VMI); (2) Differences were observed in the FVC estimation between VCI and VMI by the EM in areas with relatively high-density vegetation cover (FVC &gt; 60%). The FVC in some parts of steppe region in the basin was slightly overestimated by VMI of the EM; 3) VCI estimated by the PDM resulted in lower inversion values for extremely low-density vegetation cover (FVC &le; 10%) and higher inversion values for high-density vegetation cover (FVC &gt; 80%). The FVC inversion was underestimated by the PDM in steppe and meadow regions with FVC &gt; 15% in the basin. The application of VCI in different models can provide new ideas for the sustainable study of vegetation in arid regions.
KW  - fractional vegetation cover
KW  - empirical model
KW  - pixel decomposition model
KW  - accuracy evaluation
DO  - 10.3390/su11030864
ER  -
TY  - EJOU
AU  - Huang, Huasheng
AU  - Deng, Jizhong
AU  - Lan, Yubin
AU  - Yang, Aqing
AU  - Zhang, Lei
AU  - Wen, Sheng
AU  - Zhang, Huihui
AU  - Zhang, Yali
AU  - Deng, Yusen
TI  - Detection of Helminthosporium Leaf Blotch Disease Based on UAV Imagery
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 3
SN  - 2076-3417

AB  - Helminthosporium leaf blotch (HLB) is a serious disease of wheat causing yield reduction globally. Usually, HLB disease is controlled by uniform chemical spraying, which is adopted by most farmers. However, increased use of chemical controls have caused agronomic and environmental problems. To solve these problems, an accurate spraying system must be applied. In this case, the disease detection over the whole field can provide decision support information for the spraying machines. The objective of this paper is to evaluate the potential of unmanned aerial vehicle (UAV) remote sensing for HLB detection. In this work, the UAV imagery acquisition and ground investigation were conducted in Central China on April 22th, 2017. Four disease categories (normal, light, medium, and heavy) were established based on different severity degrees. A convolutional neural network (CNN) was proposed for HLB disease classification. The experiments on data preprocessing, classification, and hyper-parameters tuning were conducted. The overall accuracy and standard error of the CNN method was 91.43% and 0.83%, which outperformed other methods in terms of accuracy and stabilization. Especially for the detection of the diseased samples, the CNN method significantly outperformed others. Experimental results showed that the HLB infected areas and healthy areas can be precisely discriminated based on UAV remote sensing data, indicating that UAV remote sensing can be proposed as an efficient tool for HLB disease detection.
KW  - UAV imagery
KW  - remote sensing
KW  - Helminthosporium leaf blotch
KW  - convolution neural network
KW  - SVM
DO  - 10.3390/app9030558
ER  -
TY  - EJOU
AU  - Chen, Chaoyue
AU  - Gong, Weiguo
AU  - Chen, Yongliang
AU  - Li, Weihong
TI  - Object Detection in Remote Sensing Images Based on a Scene-Contextual Feature Pyramid Network
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - Object detection has attracted increasing attention in the field of remote sensing image analysis. Complex backgrounds, vertical views, and variations in target kind and size in remote sensing images make object detection a challenging task. In this work, considering that the types of objects are often closely related to the scene in which they are located, we propose a convolutional neural network (CNN) by combining scene-contextual information for object detection. Specifically, we put forward the scene-contextual feature pyramid network (SCFPN), which aims to strengthen the relationship between the target and the scene and solve problems resulting from variations in target size. Additionally, to improve the capability of feature extraction, the network is constructed by repeating a building aggregated residual block. This block increases the receptive field, which can extract richer information for targets and achieve excellent performance with respect to small object detection. Moreover, to improve the proposed model performance, we use group normalization, which divides the channels into groups and computes the mean and variance for normalization within each group, to solve the limitation of the batch normalization. The proposed method is validated on a public and challenging dataset. The experimental results demonstrate that our proposed method outperforms other state-of-the-art object detection models.
KW  - convolutional neural network (CNN)
KW  - object detection
KW  - remote sensing images
KW  - scene-contextual feature pyramid network (SCFPN)
DO  - 10.3390/rs11030339
ER  -
TY  - EJOU
AU  - Jorge, Vitor A. M.
AU  - Granada, Roger
AU  - Maidana, Renan G.
AU  - Jurak, Darlan A.
AU  - Heck, Guilherme
AU  - Negreiros, Alvaro P. F.
AU  - dos Santos, Davi H.
AU  - Gonçalves, Luiz M. G.
AU  - Amory, Alexandre M.
TI  - A Survey on Unmanned Surface Vehicles for Disaster Robotics: Main Challenges and Directions
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 3
SN  - 1424-8220

AB  - Disaster robotics has become a research area in its own right, with several reported cases of successful robot deployment in actual disaster scenarios. Most of these disaster deployments use aerial, ground, or underwater robotic platforms. However, the research involving autonomous boats or Unmanned Surface Vehicles (USVs) for Disaster Management (DM) is currently spread across several publications, with varying degrees of depth, and focusing on more than one unmanned vehicle&mdash;usually under the umbrella of Unmanned Marine Vessels (UMV). Therefore, the current importance of USVs for the DM process in its different phases is not clear. This paper presents the first comprehensive survey about the applications and roles of USVs for DM, as far as we know. This work demonstrates that there are few current deployments in disaster scenarios, with most of the research in the area focusing on the technological aspects of USV hardware and software, such as Guidance Navigation and Control, and not focusing on their actual importance for DM. Finally, to guide future research, this paper also summarizes our own contributions, the lessons learned, guidelines, and research gaps.
KW  - survey
KW  - disaster management
KW  - unmanned surface vehicle
KW  - USV
KW  - unmanned surface craft
KW  - USC
KW  - autonomous surface craft
KW  - ASC
KW  - autonomous boat
KW  - disaster robotics
KW  - floods
KW  - landslides
KW  - hurricanes
KW  - tsunamis
KW  - hazard
KW  - search and rescue
DO  - 10.3390/s19030702
ER  -
TY  - EJOU
AU  - Wang, Li
AU  - Chang, Qingrui
AU  - Li, Fenling
AU  - Yan, Lin
AU  - Huang, Yong
AU  - Wang, Qi
AU  - Luo, Lili
TI  - Effects of Growth Stage Development on Paddy Rice Leaf Area Index Prediction Models
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - A in situ hyperspectral dataset containing multiple growth stages over multiple growing seasons was used to build paddy rice leaf area index (LAI) estimation models with a special focus on the effects of paddy rice growth stage development. The univariate regression method applied to the vegetation index (VI), the traditional multivariate calibration method of partial least squares regression (PLSR), and modern machine learning methods such as support vector regression (SVR), random forests (RF), and artificial neural networks (ANN) based on the original and first-derivative hyperspectral data were evaluated in this study for paddy rice LAI estimation. All the models were built on the whole growing season and on each separate vegetative, reproductive and ripening growth stage of paddy rice separately. To ensure a fair comparison, the models of the whole growing season were also validated on data for each separate growth stage of the standalone validation dataset. Moreover, the optimal band pairs for calculating narrowband difference vegetative index (DVI), normalized difference vegetation index (NDVI) and simple ratio vegetation index (SR) were determined for the whole growing season and for each separate growth stage separately. The results showed that for both the whole growing season and for each single growth stage, the red-edge and near-infrared band pairs are optimal for formulating the narrowband DVI, NDVI and SR. Among the four multivariate calibration methods, SVR and RF yielded more accurate results than the other two methods. The SVR and RF models built on first-derivative spectra provided more accurate results than the corresponding models on the original spectra for both whole growing season models and separate growth stage models. Comparing the prediction accuracy based on the whole growing season revealed that the RF and SVR models showed an advantage over the VI models. However, comparing the prediction accuracy based on each growth stage separately showed that the VI models provided more accurate results for the vegetative growth stages. The SVR and RF models provided more accurate results for the ripening growth stage. However, the whole growing season RF model on first-derivative spectra could provide reasonable accuracy for each single growth stage.
KW  - LAI
KW  - paddy rice
KW  - hyperspectral
KW  - machine learning
KW  - vegetation index
KW  - growth stage
DO  - 10.3390/rs11030361
ER  -
TY  - EJOU
AU  - Aydin, Burchan
AU  - Selvi, Emre
AU  - Tao, Jian
AU  - Starek, Michael J.
TI  - Use of Fire-Extinguishing Balls for a Conceptual System of Drone-Assisted Wildfire Fighting
T2  - Drones

PY  - 2019
VL  - 3
IS  - 1
SN  - 2504-446X

AB  - This paper examines the potential use of fire extinguishing balls as part of a proposed system, where drone and remote-sensing technologies are utilized cooperatively as a supplement to traditional firefighting methods. The proposed system consists of (1) scouting unmanned aircraft system (UAS) to detect spot fires and monitor the risk of wildfire approaching a building, fence, and/or firefighting crew via remote sensing, (2) communication UAS to establish and extend the communication channel between scouting UAS and fire-fighting UAS, and (3) a fire-fighting UAS autonomously traveling to the waypoints to drop fire extinguishing balls (environmental friendly, heat activated suppressants). This concept is under development through a transdisciplinary multi-institutional project. The scope of this paper encloses general illustration of this design, and the experiments conducted so far to evaluate fire extinguishing balls. The results of the experiments show that smaller size fire extinguishing balls available in the global marketplace attached to drones might not be effective in aiding in building fires (unless there are open windows in the buildings already). On the contrary, results show that even the smaller size fire extinguishing balls might be effective in extinguishing short grass fires (around 0.5 kg size ball extinguished a circle of 1-meter of short grass). This finding guided the authors towards wildfire fighting rather than building fires. The paper also demonstrates building of heavy payload drones (around 15 kg payload), and the progress of development of an apparatus carrying fire-extinguishing balls attachable to drones.
KW  - drones
KW  - unmanned aircraft system (UAS)
KW  - fire extinguishing balls
KW  - remote sensing
KW  - wildfires
DO  - 10.3390/drones3010017
ER  -
TY  - EJOU
AU  - Stateczny, Andrzej
AU  - Kazimierski, Witold
AU  - Burdziakowski, Paweł
AU  - Motyl, Weronika
AU  - Wisniewska, Marta
TI  - Shore Construction Detection by Automotive Radar for the Needs of Autonomous Surface Vehicle Navigation
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 2
SN  - 2220-9964

AB  - Autonomous surface vehicles (ASVs) are becoming more and more popular for performing hydrographic and navigational tasks. One of the key aspects of autonomous navigation is the need to avoid collisions with other objects, including shore structures. During a mission, an ASV should be able to automatically detect obstacles and perform suitable maneuvers. This situation also arises in near-coastal areas, where shore structures like berths or moored vessels can be encountered. On the other hand, detection of coastal structures may also be helpful for berthing operations. An ASV can be launched and moored automatically only if it can detect obstacles in its vicinity. One commonly used method for target detection by ASVs involves the use of laser rangefinders. The main disadvantage of this approach is that such systems perform poorly in conditions with bad visibility, such as in fog or heavy rain. Therefore, alternative methods need to be sought. An innovative approach to this task is presented in this paper, which describes the use of automotive three-dimensional radar on a floating platform. The goal of the study was to assess target detection possibilities based on a comparison with photogrammetric images obtained by an unmanned aerial vehicle (UAV). The scenarios considered focused on analyzing the possibility of detecting shore structures like berths, wooden jetties, and small houses, as well as natural objects like trees or other kinds of vegetation. The recording from the radar was integrated into a single complex radar image of shore targets. It was then compared with an orthophotomap prepared from AUV camera pictures, as well as with a map based on traditional land surveys. The possibility and accuracy of detection for various types of shore structure were statistically assessed. The results show good potential for the proposed approach&mdash;in general, objects can be detected using the radar&mdash;although there is a need for development of further signal processing algorithms.
KW  - radar
KW  - autonomous surface vehicles
KW  - navigation
DO  - 10.3390/ijgi8020080
ER  -
TY  - EJOU
AU  - Kwak, Geun-Ho
AU  - Park, No-Wook
TI  - Impact of Texture Information on Crop Classification with Machine Learning and UAV Images
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 4
SN  - 2076-3417

AB  - Unmanned aerial vehicle (UAV) images that can provide thematic information at much higher spatial and temporal resolutions than satellite images have great potential in crop classification. Due to the ultra-high spatial resolution of UAV images, spatial contextual information such as texture is often used for crop classification. From a data availability viewpoint, it is not always possible to acquire time-series UAV images due to limited accessibility to the study area. Thus, it is necessary to improve classification performance for situations when a single or minimum number of UAV images are available for crop classification. In this study, we investigate the potential of gray-level co-occurrence matrix (GLCM)-based texture information for crop classification with time-series UAV images and machine learning classifiers including random forest and support vector machine. In particular, the impact of combining texture and spectral information on the classification performance is evaluated for cases that use only one UAV image or multi-temporal images as input. A case study of crop classification in Anbandegi of Korea was conducted for the above comparisons. The best classification accuracy was achieved when multi-temporal UAV images which can fully account for the growth cycles of crops were combined with GLCM-based texture features. However, the impact of the utilization of texture information was not significant. In contrast, when one August UAV image was used for crop classification, the utilization of texture information significantly affected the classification performance. Classification using texture features extracted from GLCM with larger kernel size significantly improved classification accuracy, an improvement of 7.72%p in overall accuracy for the support vector machine classifier, compared with classification based solely on spectral information. These results indicate the usefulness of texture information for classification of ultra-high-spatial-resolution UAV images, particularly when acquisition of time-series UAV images is difficult and only one UAV image is used for crop classification.
KW  - unmanned aerial vehicle
KW  - texture
KW  - gray-level co-occurrence matrix
KW  - machine learning
KW  - crop
DO  - 10.3390/app9040643
ER  -
TY  - EJOU
AU  - Giernacki, Wojciech
TI  - Iterative Learning Method for In-Flight Auto-Tuning of UAV Controllers Based on Basic Sensory Information
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 4
SN  - 2076-3417

AB  - With an increasing number of multirotor unmanned aerial vehicles (UAVs), solutions supporting the improvement in their precision of operation and safety of autonomous flights are gaining importance. They are particularly crucial in transportation tasks, where control systems are required to provide a stable and controllable flight in various environmental conditions, especially after changing the total mass of the UAV (by adding extra load). In the paper, the problem of using only available basic sensory information for fast, locally best, iterative real-time auto-tuning of parameters of fixed-gain altitude controllers is considered. The machine learning method proposed for this purpose is based on a modified zero-order optimization algorithm (golden-search algorithm) and bootstrapping technique. It has been validated in numerous simulations and real-world experiments in terms of its effectiveness in such aspects as: the impact of environmental disturbances (wind gusts); flight with change in mass; and change of sensory information sources in the auto-tuning procedure. The main advantage of the proposed method is that for the trajectory primitives repeatedly followed by an UAV (for programmed controller gains), the method effectively minimizes the selected performance index (cost function). Such a performance index might, e.g., express indirect requirements about tracking quality and energy expenditure. In the paper, a comprehensive description of the method, as well as a wide discussion of the results obtained from experiments conducted in the AeroLab for a low-cost UAV (Bebop 2), are included. The results have confirmed high efficiency of the method at the expected, low computational complexity.
KW  - UAV
KW  - auto-tuning
KW  - machine learning
KW  - iterative learning
KW  - extremum-seeking
KW  - altitude controller
DO  - 10.3390/app9040648
ER  -
TY  - EJOU
AU  - Cheng, Qiao
AU  - Wang, Xiangke
AU  - Yang, Jian
AU  - Shen, Lincheng
TI  - Automated Enemy Avoidance of Unmanned Aerial Vehicles Based on Reinforcement Learning
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 4
SN  - 2076-3417

AB  - This paper focuses on one of the collision avoidance scenarios for unmanned aerial vehicles (UAVs), where the UAV needs to avoid collision with the enemy UAV during its flying path to the goal point. Such a type of problem is defined as the enemy avoidance problem in this paper. To deal with this problem, a learning based framework is proposed. Under this framework, the enemy avoidance problem is formulated as a Markov Decision Process (MDP), and the maneuver policies for the UAV are learned based on a temporal-difference reinforcement learning method called Sarsa. To handle the enemy avoidance problem in continuous state space, the Cerebellar Model Arithmetic Computer (CMAC) function approximation technique is embodied in the proposed framework. Furthermore, a hardware-in-the-loop (HITL) simulation environment is established. Simulation results show that the UAV agent can learn a satisfying policy under the proposed framework. Comparing with the random policy and the fixed-rule policy, the learned policy can achieve a far higher possibility in reaching the goal point without colliding with the enemy UAV.
KW  - enemy avoidance
KW  - reinforcement learning
KW  - decision making
KW  - hardware-in-the-loop simulation
KW  - unmanned aerial vehicles
DO  - 10.3390/app9040669
ER  -
TY  - EJOU
AU  - Ancin-Murguzur, Francisco J.
AU  - Taff, Gregory
AU  - Davids, Corine
AU  - Tømmervik, Hans
AU  - Mølmann, Jørgen
AU  - Jørgensen, Marit
TI  - Yield Estimates by a Two-Step Approach Using Hyperspectral Methods in Grasslands at High Latitudes
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 4
SN  - 2072-4292

AB  - Ruminant fodder production in agricultural lands in latitudes above the Arctic Circle is constrained by short and hectic growing seasons with a 24-hour photoperiod and low growth temperatures. The use of remote sensing to measure crop production at high latitudes is hindered by intrinsic challenges, such as a low sun elevation angle and a coastal climate with high humidity, which influences the spectral signatures of the sampled vegetation. We used a portable spectrometer (ASD FieldSpec 3) to assess spectra of grass crops and found that when applying multivariate models to the hyperspectral datasets, results show significant predictability of yields (R2 &gt; 0.55, root mean squared error (RMSE) &lt; 180), even when captured under sub-optimal conditions. These results are consistent both in the full spectral range of the spectrometer (350&ndash;2500 nm) and in the 350&ndash;900 nm spectral range, which is a region more robust against air moisture. Sentinel-2A simulations resulted in moderately robust models that could be used in qualitative assessments of field productivity. In addition, simulation of the upcoming hyperspectral EnMap satellite bands showed its potential applicability to measure yields in northern latitudes both in the full spectral range of the satellite (420&ndash;2450 nm) with similar performance as the Sentinel-2A satellite and in the 420&ndash;900 nm range with a comparable reliability to the portable spectrometer. The combination of EnMap and Sentinel-2A to detect fields with low productivity and portable spectrometers to identify the fields or specific regions of fields with the lowest production can help optimize the management of fodder production in high latitudes.
KW  - remote sensing
KW  - partial least squares (PLS)
KW  - yield
KW  - crop
KW  - grass
KW  - EnMap
KW  - Arctic agriculture
DO  - 10.3390/rs11040400
ER  -
TY  - EJOU
AU  - Wang, Lanfei
AU  - Kan, Jiangming
AU  - Guo, Jun
AU  - Wang, Chao
TI  - 3D Path Planning for the Ground Robot with Improved Ant Colony Optimization
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 4
SN  - 1424-8220

AB  - Path planning is a fundamental issue in the aspect of robot navigation. As robots work in 3D environments, it is meaningful to study 3D path planning. To solve general problems of easily falling into local optimum and long search times in 3D path planning based on the ant colony algorithm, we proposed an improved the pheromone update and a heuristic function by introducing a safety value. We also designed two methods to calculate safety values. Concerning the path search, we designed a search mode combining the plane and visual fields and limited the search range of the robot. With regard to the deadlock problem, we adopted a 3D deadlock-free mechanism to enable ants to get out of the predicaments. With respect to simulations, we used a number of 3D terrains to carry out simulations and set different starting and end points in each terrain under the same external settings. According to the results of the improved ant colony algorithm and the basic ant colony algorithm, paths planned by the improved ant colony algorithm can effectively avoid obstacles, and their trajectories are smoother than that of the basic ant colony algorithm. The shortest path length is reduced by 8.164%, on average, compared with the results of the basic ant colony algorithm. We also compared the results of two methods for calculating safety values under the same terrain and external settings. Results show that by calculating the safety value in the environmental modeling stage in advance, and invoking the safety value directly in the path planning stage, the average running time is reduced by 91.56%, compared with calculating the safety value while path planning.
KW  - ground robot
KW  - path planning
KW  - ant colony optimization
KW  - 3D space
DO  - 10.3390/s19040815
ER  -
TY  - EJOU
AU  - Ampatzidis, Yiannis
AU  - Partel, Victor
TI  - UAV-Based High Throughput Phenotyping in Citrus Utilizing Multispectral Imaging and Artificial Intelligence
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 4
SN  - 2072-4292

AB  - Traditional plant breeding evaluation methods are time-consuming, labor-intensive, and costly. Accurate and rapid phenotypic trait data acquisition and analysis can improve genomic selection and accelerate cultivar development. In this work, a technique for data acquisition and image processing was developed utilizing small unmanned aerial vehicles (UAVs), multispectral imaging, and deep learning convolutional neural networks to evaluate phenotypic characteristics on citrus crops. This low-cost and automated high-throughput phenotyping technique utilizes artificial intelligence (AI) and machine learning (ML) to: (i) detect, count, and geolocate trees and tree gaps; (ii) categorize trees based on their canopy size; (iii) develop individual tree health indices; and (iv) evaluate citrus varieties and rootstocks. The proposed remote sensing technique was able to detect and count citrus trees in a grove of 4,931 trees, with precision and recall of 99.9% and 99.7%, respectively, estimate their canopy size with overall accuracy of 85.5%, and detect, count, and geolocate tree gaps with a precision and recall of 100% and 94.6%, respectively. This UAV-based technique provides a consistent, more direct, cost-effective, and rapid method to evaluate phenotypic characteristics of citrus varieties and rootstocks.
KW  - UAV
KW  - artificial intelligence
KW  - machine learning
KW  - smart agriculture
KW  - precision agriculture
KW  - neural networks
KW  - deep learning
DO  - 10.3390/rs11040410
ER  -
TY  - EJOU
AU  - Yan, Lei
AU  - Cao, Suzhi
AU  - Gong, Yongsheng
AU  - Han, Hao
AU  - Wei, Junyong
AU  - Zhao, Yi
AU  - Yang, Shuling
TI  - SatEC: A 5G Satellite Edge Computing Framework Based on Microservice Architecture
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 4
SN  - 1424-8220

AB  - As outlined in the 3Gpp Release 16, 5G satellite access is important for 5G network development in the future. A terrestrial-satellite network integrated with 5G has the characteristics of low delay, high bandwidth, and ubiquitous coverage. A few researchers have proposed integrated schemes for such a network; however, these schemes do not consider the possibility of achieving optimization of the delay characteristic by changing the computing mode of the 5G satellite network. We propose a 5G satellite edge computing framework (5GsatEC), which aims to reduce delay and expand network coverage. This framework consists of embedded hardware platforms and edge computing microservices in satellites. To increase the flexibility of the framework in complex scenarios, we unify the resource management of the central processing unit (CPU), graphics processing unit (GPU), and field-programmable gate array (FPGA); we divide the services into three types: system services, basic services, and user services. In order to verify the performance of the framework, we carried out a series of experiments. The results show that 5GsatEC has a broader coverage than the ground 5G network. The results also show that 5GsatEC has lower delay, a lower packet loss rate, and lower bandwidth consumption than the 5G satellite network.
KW  - edge computing
KW  - on-board data processing
KW  - microservices
KW  - Integrated Terrestrial-Satellite Networks
DO  - 10.3390/s19040831
ER  -
TY  - EJOU
AU  - Pasqualotto, Nieves
AU  - Delegido, Jesús
AU  - Van Wittenberghe, Shari
AU  - Rinaldi, Michele
AU  - Moreno, José
TI  - Multi-Crop Green LAI Estimation with a New Simple Sentinel-2 LAI Index (SeLI)
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 4
SN  - 1424-8220

AB  - The spatial quantification of green leaf area index (LAIgreen), the total green photosynthetically active leaf area per ground area, is a crucial biophysical variable for agroecosystem monitoring. The Sentinel-2 mission is with (1) a temporal resolution lower than a week, (2) a spatial resolution of up to 10 m, and (3) narrow bands in the red and red-edge region, a highly promising mission for agricultural monitoring. The aim of this work is to define an easy implementable LAIgreen index for the Sentinel-2 mission. Two large and independent multi-crop datasets of in situ collected LAIgreen measurements were used. Commonly used LAIgreen indices applied on the Sentinel-2 10 m &times; 10 m pixel resulted in a validation R2 lower than 0.6. By calculating all Sentinel-2 band combinations to identify high correlation and physical basis with LAIgreen, the new Sentinel-2 LAIgreen Index (SeLI) was defined. SeLI is a normalized index that uses the 705 nm and 865 nm centered bands, exploiting the red-edge region for low-saturating absorption sensitivity to photosynthetic vegetation. A R2 of 0.708 (root mean squared error (RMSE) = 0.67) and a R2 of 0.732 (RMSE = 0.69) were obtained with a linear fitting for the calibration and validation datasets, respectively, outperforming established indices. Sentinel-2 LAIgreen maps are presented.
KW  - crops
KW  - leaf area index
KW  - vegetation indices
KW  - remote sensing
KW  - Sentinel-2
KW  - red-edge
DO  - 10.3390/s19040904
ER  -
TY  - EJOU
AU  - Sanchez-Gonzalez, Pedro-Luis
AU  - Díaz-Gutiérrez, David
AU  - Leo, Teresa J.
AU  - Núñez-Rivas, Luis R.
TI  - Toward Digitalization of Maritime Transport?
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 4
SN  - 1424-8220

AB  - Although maritime transport is the backbone of world commerce, its digitalization lags significantly behind when we consider some basic facts. This work verifies the state-of-the-art as it currently applies to eight digital domains: Autonomous vehicles and robotics; artificial intelligence; big data; virtual reality, augmented and mixed reality; internet of things; the cloud and edge computing; digital security; and 3D printing and additive engineering. It also provides insight into each of the three sectors into which this industry has been divided: Ship design and shipbuilding; shipping; and ports. The work, based on a systematic literature review, demonstrates that there are domains on which almost no formal study has been done thus far and concludes that there are major areas that require attention in terms of research. It also illustrates the increasing interest on the subject, arising from the necessity of raising the maritime transport industry to the same level of digitalization as other industries.
KW  - additive engineering
KW  - artificial intelligence
KW  - big data
KW  - cloud computing
KW  - digitalization
KW  - internet of things
KW  - maritime transport
KW  - robotics
KW  - virtual reality
DO  - 10.3390/s19040926
ER  -
TY  - EJOU
AU  - Liu, Zheng
AU  - Abbaszadeh, Shiva
TI  - Double Q-Learning for Radiation Source Detection
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 4
SN  - 1424-8220

AB  - Anomalous radiation source detection in urban environments is challenging due to the complex nature of background radiation. When a suspicious area is determined, a radiation survey is usually carried out to search for anomalous radiation sources. To locate the source with high accuracy and in a short time, different survey approaches have been studied such as scanning the area with fixed survey paths and data-driven approaches that update the survey path on the fly with newly acquired measurements. In this work, we propose reinforcement learning as a data-driven approach to conduct radiation detection tasks with no human intervention. A simulated radiation environment is constructed, and a convolutional neural network-based double Q-learning algorithm is built and tested for radiation source detection tasks. Simulation results show that the double Q-learning algorithm can reliably navigate the detector and reduce the searching time by at least 44% compared with traditional uniform search methods and gradient search methods.
KW  - reinforcement learning
KW  - radiation detection
KW  - source searching
DO  - 10.3390/s19040960
ER  -
TY  - EJOU
AU  - Madokoro, Hirokazu
AU  - Sato, Kazuhito
AU  - Shimoi, Nobuhiro
TI  - Vision-Based Indoor Scene Recognition from Time-Series Aerial Images Obtained Using a MAV Mounted Monocular Camera
T2  - Drones

PY  - 2019
VL  - 3
IS  - 1
SN  - 2504-446X

AB  - This paper presents a vision-based indoor scene recognition method from aerial time-series images obtained using a micro air vehicle (MAV). The proposed method comprises two procedures: a codebook feature description procedure, and a recognition procedure using category maps. For the former procedure, codebooks are created automatically as visual words using self-organizing maps (SOMs) after extracting part-based local features using a part-based descriptor from time-series scene images. For the latter procedure, category maps are created using counter propagation networks (CPNs) with the extraction of category boundaries using a unified distance matrix (U-Matrix). Using category maps, topologies of image features are mapped into a low-dimensional space based on competitive and neighborhood learning. We obtained aerial time-series image datasets of five sets for two flight routes: a round flight route and a zigzag flight route. The experimentally obtained results with leave-one-out cross-validation (LOOCV) revealed respective mean recognition accuracies for the round flight datasets (RFDs) and zigzag flight datasets (ZFDs) of 71.7% and 65.5% for 10 zones. The category maps addressed the complexity of scenes because of segmented categories. Although extraction results of category boundaries using U-Matrix were partially discontinuous, we obtained comprehensive category boundaries that segment scenes into several categories.
KW  - category maps
KW  - counter propagation networks
KW  - leave-one-out cross-validation
KW  - micro air vehicles
KW  - self-organizing maps
KW  - unified distance matrix
DO  - 10.3390/drones3010022
ER  -
TY  - EJOU
AU  - Hrabia, Christopher-Eyk
AU  - Hessler, Axel
AU  - Xu, Yuan
AU  - Seibert, Jacob
AU  - Brehmer, Jan
AU  - Albayrak, Sahin
TI  - EffFeu Project: Towards Mission-Guided Application of Drones in Safety and Security Environments
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 4
SN  - 1424-8220

AB  - The number of unmanned aerial system (UAS) applications for supporting rescue forces is growing in recent years. Nevertheless, the analysis of sensed information and control of unmanned aerial vehicle (UAV) creates an enormous psychological and emotional load for the involved humans especially in critical and hectic situations. The introduced research project EffFeu (Efficient Operation of Unmanned Aerial Vehicle for Industrial Firefighters) especially focuses on a holistic integration of UAS in the daily work of industrial firefighters. This is done by enabling autonomous mission-guided control on top of the presented overall system architecture, goal-oriented high-level task control, comprehensive localisation process combining several approaches to enable the transition from and to GNSS-supported and GNSS-denied environments, as well as a deep-learning based object recognition of relevant entities. This work describes the concepts, current stage, and first evaluation results of the research project.
KW  - decisional autonomy
KW  - decision-making
KW  - planning
KW  - object recognition
KW  - deep learning
KW  - GNSS-denied localisation
DO  - 10.3390/s19040973
ER  -
TY  - EJOU
AU  - Mohammadimanesh, Fariba
AU  - Salehi, Bahram
AU  - Mahdianpari, Masoud
AU  - Brisco, Brian
AU  - Gill, Eric
TI  - Full and Simulated Compact Polarimetry SAR Responses to Canadian Wetlands: Separability Analysis and Classification
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 5
SN  - 2072-4292

AB  - Detailed information on spatial distribution of wetland classes is crucial for monitoring this important productive ecosystem using advanced remote sensing tools and data. Although the potential of full- and dual-polarimetric (FP and DP) Synthetic Aperture Radar (SAR) data for wetland classification has been well examined, the capability of compact polarimetric (CP) SAR data has not yet been thoroughly investigated. This is of great significance, since the upcoming RADARSAT Constellation Mission (RCM), which will soon be the main source of SAR observations in Canada, will have CP mode as one of its main SAR configurations. This also highlights the necessity to fully exploit such important Earth Observation (EO) data by examining the similarities and dissimilarities between FP and CP SAR data for wetland mapping. Accordingly, this study examines and compares the discrimination capability of extracted features from FP and simulated CP SAR data between pairs of wetland classes. In particular, 13 FP and 22 simulated CP SAR features are extracted from RADARSAT-2 data to determine their discrimination capabilities both qualitatively and quantitatively in three wetland sites, located in Newfoundland and Labrador, Canada. Seven of 13 FP and 15 of 22 CP SAR features are found to be the most discriminant, as they indicate an excellent separability for at least one pair of wetland classes. The overall accuracies of 87.89%, 80.67%, and 84.07% are achieved using the CP SAR data for the three wetland sites (Avalon, Deer Lake, and Gros Morne, respectively) in this study. Although these accuracies are lower than those of FP SAR data, they confirm the potential of CP SAR data for wetland mapping as accuracies exceed 80% in all three sites. The CP SAR data collected by RCM will significantly contribute to the efforts ongoing of conservation strategies for wetlands and monitoring changes, especially on large scales, as they have both wider swath coverage and improved temporal resolution compared to those of RADARSAT-2.
KW  - wetland classification
KW  - RADARSAT-2
KW  - compact-polarimetry
KW  - RADARSAT Constellation Mission
KW  - RCM
KW  - Earth Observation
DO  - 10.3390/rs11050516
ER  -
TY  - EJOU
AU  - Wen, Sheng
AU  - Zhang, Quanyong
AU  - Yin, Xuanchun
AU  - Lan, Yubin
AU  - Zhang, Jiantao
AU  - Ge, Yufeng
TI  - Design of Plant Protection UAV Variable Spray System Based on Neural Networks
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 5
SN  - 1424-8220

AB  - Recently, unmanned aerial vehicles (UAVs) have rapidly emerged as a new technology in the fields of plant protection and pest control in China. Based on existing variable spray research, a plant protection UAV variable spray system integrating neural network based decision making is designed. Using the existing data on plant protection UAV operations, combined with artificial neural network (ANN) technology, an error back propagation (BP) neural network model between the factors affecting droplet deposition is trained. The factors affecting droplet deposition include ambient temperature, ambient humidity, wind speed, flight speed, flight altitude, propeller pitch, nozzles pitch and prescription value. Subsequently, the BP neural network model is combined with variable rate spray control for plant protection UAVs, and real-time information is collected by multi-sensor. The deposition rate is determined by the neural network model, and the flow rate of the spray system is regulated according to the predicted deposition amount. The amount of droplet deposition can meet the prescription requirement. The results show that the training variance of the ANN is 0.003, and thus, the model is stable and reliable. The outdoor tests show that the error between the predicted droplet deposition and actual droplet deposition is less than 20%. The ratio of droplet deposition to prescription value in each unit is approximately equal, and a variable spray operation under different conditions is realized.
KW  - UAV
KW  - BP neural network
KW  - droplet deposition
KW  - variable spray
DO  - 10.3390/s19051112
ER  -
TY  - EJOU
AU  - Carl, Christin
AU  - Lehmann, Jan R. K.
AU  - Landgraf, Dirk
AU  - Pretzsch, Hans
TI  - Robinia pseudoacacia L. in Short Rotation Coppice: Seed and Stump Shoot Reproduction as well as UAS-based Spreading Analysis
T2  - Forests

PY  - 2019
VL  - 10
IS  - 3
SN  - 1999-4907

AB  - Varying reproduction strategies are an important trait that tree species need in order both to survive and to spread. Black locust is able to reproduce via seeds, stump shoots, and root suckers. However, little research has been conducted on the reproduction and spreading of black locust in short rotation coppices. This research study focused on seed germination, stump shoot resprout, and spreading by root suckering of black locust in ten short rotation coppices in Germany. Seed experiments and sample plots were analyzed for the study. Spreading was detected and measured with unmanned aerial system (UAS)-based images and classification technology&mdash;object-based image analysis (OBIA). Additionally, the classification of single UAS images was tested by applying a convolutional neural network (CNN), a deep learning model. The analyses showed that seed germination increases with increasing warm-cold variety and scarification. Moreover, it was found that the number of shoots per stump decreases as shoot age increases. Furthermore, spreading increases with greater light availability and decreasing tillage. The OBIA and CNN image analysis technologies achieved 97% and 99.5% accuracy for black locust classification in UAS images. All in all, the three reproduction strategies of black locust in short rotation coppices differ with regards to initialization, intensity, and growth performance, but all play a role in the survival and spreading of black locust.
KW  - Robinia pseudoacacia L.
KW  - reproduction
KW  - spreading
KW  - short rotation coppice
KW  - unmanned aerial system (UAS)
KW  - object-based image analysis (OBIA)
KW  - convolutional neural network (CNN)
DO  - 10.3390/f10030235
ER  -
TY  - EJOU
AU  - Gao, Lin
AU  - Song, Weidong
AU  - Dai, Jiguang
AU  - Chen, Yang
TI  - Road Extraction from High-Resolution Remote Sensing Imagery Using Refined Deep Residual Convolutional Neural Network
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 5
SN  - 2072-4292

AB  - Road extraction is one of the most significant tasks for modern transportation systems. This task is normally difficult due to complex backgrounds such as rural roads that have heterogeneous appearances with large intraclass and low interclass variations and urban roads that are covered by vehicles, pedestrians and the shadows of surrounding trees or buildings. In this paper, we propose a novel method for extracting roads from optical satellite images using a refined deep residual convolutional neural network (RDRCNN) with a postprocessing stage. RDRCNN consists of a residual connected unit (RCU) and a dilated perception unit (DPU). The RDRCNN structure is symmetric to generate the outputs of the same size. A math morphology and a tensor voting algorithm are used to improve RDRCNN performance during postprocessing. Experiments are conducted on two datasets of high-resolution images to demonstrate the performance of the proposed network architectures, and the results of the proposed architectures are compared with those of other network architectures. The results demonstrate the effective performance of the proposed method for extracting roads from a complex scene.
KW  - refined deep residual convolutional neural network
KW  - road extraction
KW  - remote sensing
KW  - tensor voting
KW  - math morphology
KW  - high-resolution imagery
DO  - 10.3390/rs11050552
ER  -
TY  - EJOU
AU  - Su, Wei
AU  - Huang, Jianxi
AU  - Liu, Desheng
AU  - Zhang, Mingzheng
TI  - Retrieving Corn Canopy Leaf Area Index from Multitemporal Landsat Imagery and Terrestrial LiDAR Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 5
SN  - 2072-4292

AB  - Leaf angle is a critical structural parameter for retrieving canopy leaf area index (LAI) using the PROSAIL model. However, the traditional method using default leaf angle distribution in the PROSAIL model does not capture the phenological dynamics of canopy growth. This study presents a LAI retrieval method for corn canopies using PROSAIL model with leaf angle distribution functions referred from terrestrial laser scanning points at four phenological stages during the growing season. Specifically, four inferred maximum-probability leaf angles were used in the Campbell ellipsoid leaf angle distribution function of PROSAIL. A Lookup table (LUT) is generated by running the PROSAIL model with inferred leaf angles, and the cost function is minimized to retrieve LAI. The results show that the leaf angle distribution functions are different for the corn plants at different phenological growing stages, and the incorporation of derived specific corn leaf angle distribution functions distribute the improvement of LAI retrieval using the PROSAIL model. This validation is done using in-situ LAI measurements and MODIS LAI in Baoding City, Hebei Province, China, and compared with the LAI retrieved using default leaf angle distribution function at the same time. The root-mean-square error (RMSE) between the retrieved LAI on 4 September 2014, using the modified PROSAIL model and the in-situ measured LAI was 0.31 m2/m2, with a strong and significant correlation (R2 = 0.82, residual range = 0 to 0.6 m2/m2, p &lt; 0.001). Comparatively, the accuracy of LAI retrieved results using default leaf angle distribution is lower, the RMSE of which is 0.56 with R2 = 0.76 and residual range = 0 to 1.0 m2/m2, p &lt; 0.001. This validation reveals that the introduction of inferred leaf angle distributions from TLS data points can improve the LAI retrieval accuracy using the PROSAIL model. Moreover, the comparations of LAI retrieval results on 10 July, 26 July, 19 August and 4 September with default and inferred corn leaf angle distribution functions are all compared with MODIS LAI products in the whole study area. This validation reveals that improvement exists in a wide spatial range and temporal range. All the comparisons demonstrate the potential of the modified PROSAIL model for retrieving corn canopy LAI from Landsat imagery by inferring leaf orientation from terrestrial laser scanning data.
KW  - leaf area index retrieval
KW  - leaf angle distribution function
KW  - PROSAIL model
KW  - terrestrial LiDAR
KW  - corn
DO  - 10.3390/rs11050572
ER  -
TY  - EJOU
AU  - Samaniego, Franklin
AU  - Sanchis, Javier
AU  - García-Nieto, Sergio
AU  - Simarro, Raúl
TI  - Recursive Rewarding Modified Adaptive Cell Decomposition (RR-MACD): A Dynamic Path Planning Algorithm for UAVs
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 3
SN  - 2079-9292

AB  - A relevant task in unmanned aerial vehicles (UAV) flight is path planning in     3 D     environments. This task must be completed using the least possible computing time. The aim of this article is to combine methodologies to optimise the task in time and offer a complete     3 D     trajectory. The flight environment will be considered as a     3 D     adaptive discrete mesh, where grids are created with minimal refinement in the search for collision-free spaces. The proposed path planning algorithm for UAV saves computational time and memory resources compared with classical techniques. With the construction of the discrete meshing, a cost response methodology is applied as a discrete deterministic finite automaton (DDFA). A set of optimal partial responses, calculated recursively, indicates the collision-free spaces in the final path for the UAV flight.
KW  - UAV
KW  - path planning
KW  - adaptive discrete mesh
KW  - octree
DO  - 10.3390/electronics8030306
ER  -
TY  - EJOU
AU  - Liu, Han
AU  - Dahlgren, Randy A.
AU  - Larsen, Royce E.
AU  - Devine, Scott M.
AU  - Roche, Leslie M.
AU  - O’ Geen, Anthony T.
AU  - Wong, Andy J.Y.
AU  - Covello, Sarah
AU  - Jin, Yufang
TI  - Estimating Rangeland Forage Production Using Remote Sensing Data from a Small Unmanned Aerial System (sUAS) and PlanetScope Satellite
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 5
SN  - 2072-4292

AB  - Rangelands cover ~23 million hectares and support a $3.4 billion annual cattle industry in California. Large variations in forage production from year to year and across the landscape make grazing management difficult. We here developed optimized methods to map high-resolution forage production using multispectral remote sensing imagery. We conducted monthly flights using a Small Unmanned Aerial System (sUAS) in 2017 and 2018 over a 10-ha deferred grazing rangeland. Daily maps of NDVI at 30-cm resolution were first derived by fusing monthly 30-cm sUAS imagery and more frequent 3-m PlanetScope satellite observations. We estimated aboveground net primary production as a product of absorbed photosynthetically active radiation (APAR) derived from NDVI and light use efficiency (LUE), optimized as a function of topography and climate stressors. The estimated forage production agreed well with field measurements having a R2 of 0.80 and RMSE of 542 kg/ha. Cumulative NDVI and APAR were less correlated with measured biomass (     R 2      = 0.68). Daily forage production maps captured similar seasonal and spatial patterns compared to field-based biomass measurements. Our study demonstrated the utility of aerial and satellite remote sensing technology in supporting adaptive rangeland management, especially during an era of climatic extremes, by providing spatially explicit and near-real-time forage production estimates.
KW  - Drone
KW  - MicaSense RedEdge
KW  - Commercial satellite
KW  - Light use efficiency
KW  - Data fusion
KW  - Rangeland
KW  - Aboveground biomass
KW  - Environmental stress
DO  - 10.3390/rs11050595
ER  -
TY  - EJOU
AU  - Feng, Lei
AU  - Wu, Weikang
AU  - Wang, Junmin
AU  - Zhang, Chu
AU  - Zhao, Yiying
AU  - Zhu, Susu
AU  - He, Yong
TI  - Wind Field Distribution of Multi-rotor UAV and Its Influence on Spectral Information Acquisition of Rice Canopies
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Unmanned aerial vehicles (UAV) are widely used as remote sensing platforms to effectively monitor agricultural conditions. The wind field generated by the rotors in low-altitude operations will cause the deformation of rice crops, and may affect the acquisition of the true spectral information. In this study, a low-altitude UAV remote sensing simulation platform and a triple-direction wind field wireless sensor network system were built to explore the wind field distribution law. Combined with the multi-spectral images of the rice canopy, the influence of wind field on the spectral information acquisition was analyzed through variance and regression analysis. The results showed that the Z-direction wind field of UAV rotors dominated along three directions (X, Y, and Z). The coefficient of determination (R2) of three linear regression models for Normalized Difference Vegetation Index (NDVI), Ratio Vegetation Index (RVI), and Canopy Coverage Rate (CCR) was 0.782, 0.749, and 0.527, respectively. Therefore, the multi-rotor UAV wind field had an impact on the spectral information acquisition of rice canopy, and this influence could eventually affect the assessment of rice growth status. The models established in this study could provide a reference for the revised model of spectral indices, and offer guidance for the actual operations of low-altitude multi-rotor UAV.
KW  - multi-rotor UAV
KW  - wind-field distribution
KW  - triple-direction wind field wireless sensor network
KW  - multispectral information
DO  - 10.3390/rs11060602
ER  -
TY  - EJOU
AU  - Asadi, Khashayar
AU  - Chen, Pengyu
AU  - Han, Kevin
AU  - Wu, Tianfu
AU  - Lobaton, Edgar
TI  - LNSNet: Lightweight Navigable Space Segmentation for Autonomous Robots on Construction Sites
T2  - Data

PY  - 2019
VL  - 4
IS  - 1
SN  - 2306-5729

AB  - An autonomous robot that can monitor a construction site should be able to be can contextually detect its surrounding environment by recognizing objects and making decisions based on its observation. Pixel-wise semantic segmentation in real-time is vital to building an autonomous and mobile robot. However, the learning models&rsquo; size and high memory usage associated with real-time segmentation are the main challenges for mobile robotics systems that have limited computing resources. To overcome these challenges, this paper presents an efficient semantic segmentation method named LNSNet (lightweight navigable space segmentation network) that can run on embedded platforms to determine navigable space in real-time. The core of model architecture is a new block based on separable convolution which compresses the parameters of present residual block meanwhile maintaining the accuracy and performance. LNSNet is faster, has fewer parameters and less model size, while provides similar accuracy compared to existing models. A new pixel-level annotated dataset for real-time and mobile navigable space segmentation in construction environments has been constructed for the proposed method. The results demonstrate the effectiveness and efficiency that are necessary for the future development of the autonomous robotics systems.
KW  - efficient real-time segmentation
KW  - embedded platform
KW  - autonomous navigation in construction
KW  - autonomous data collection
DO  - 10.3390/data4010040
ER  -
TY  - EJOU
AU  - Zhang, Chengming
AU  - Han, Yingjuan
AU  - Li, Feng
AU  - Gao, Shuai
AU  - Song, Dejuan
AU  - Zhao, Hui
AU  - Fan, Keqi
AU  - Zhang, Ya’nan
TI  - A New CNN-Bayesian Model for Extracting Improved Winter Wheat Spatial Distribution from GF-2 imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - When the spatial distribution of winter wheat is extracted from high-resolution remote sensing imagery using convolutional neural networks (CNN), field edge results are usually rough, resulting in lowered overall accuracy. This study proposed a new per-pixel classification model using CNN and Bayesian models (CNN-Bayesian model) for improved extraction accuracy. In this model, a feature extractor generates a feature vector for each pixel, an encoder transforms the feature vector of each pixel into a category-code vector, and a two-level classifier uses the difference between elements of category-probability vectors as the confidence value to perform per-pixel classifications. The first level is used to determine the category of a pixel with high confidence, and the second level is an improved Bayesian model used to determine the category of low-confidence pixels. The CNN-Bayesian model was trained and tested on Gaofen 2 satellite images. Compared to existing models, our approach produced an improvement in overall accuracy, the overall accuracy of SegNet, DeepLab, VGG-Ex, and CNN-Bayesian was 0.791, 0.852, 0.892, and 0.946, respectively. Thus, this approach can produce superior results when winter wheat spatial distribution is extracted from satellite imagery.
KW  - winter wheat
KW  - convolutional neural network
KW  - Visual Geometry Group Network
KW  - Bayesian model
KW  - per-pixel classification
KW  - high-resolution remote sensing imager
KW  - Gaofen 2 image
DO  - 10.3390/rs11060619
ER  -
TY  - EJOU
AU  - Tang, Shixi
AU  - Gu, Jinan
AU  - Tang, Keming
AU  - Zou, Rong
AU  - Sun, Xiaohong
AU  - Uddin, Saad
TI  - A Fault-Signal-Based Generalizing Remaining Useful Life Prognostics Method for Wheel Hub Bearings
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 6
SN  - 2076-3417

AB  - The goal of this work is to improve the generalization of remaining useful life (RUL) prognostics for wheel hub bearings. The traditional life prognostics methods assume that the data used in RUL prognostics is composed of one specific fatigue damage type, the data used in RUL prognostics is accurate, and the RUL prognostics are conducted in the short term. Due to which, a generalizing RUL prognostics method is designed based on fault signal data. Firstly, the fault signal model is designed with the signal in a complex and mutative environment. Then, the generalizing RUL prognostics method is designed based on the fault signal model. Lastly, the simplified solution of the generalizing RUL prognostics method is deduced. The experimental results show that the proposed method gained good accuracies for RUL prognostics for all the amplitude, energy, and kurtosis features with fatigue damage types. The proposed method can process inaccurate fault signals with different kinds of noise in the actual working environment, and it can be conducted in the long term. Therefore, the RUL prognostics method has a good generalization.
KW  - data-driven method
KW  - remaining useful life prognostics
KW  - fault signal analysis
KW  - grey system
KW  - differential hydrological grey method
KW  - wheel hub bearings
DO  - 10.3390/app9061080
ER  -
TY  - EJOU
AU  - Javed, Waqas
AU  - Chen, Dong
AU  - Farrag, Mohamed E.
AU  - Xu, Yan
TI  - System Configuration, Fault Detection, Location, Isolation and Restoration: A Review on LVDC Microgrid Protections
T2  - Energies

PY  - 2019
VL  - 12
IS  - 6
SN  - 1996-1073

AB  - Low voltage direct current (LVDC) distribution has gained the significant interest of research due to the advancements in power conversion technologies. However, the use of converters has given rise to several technical issues regarding their protections and controls of such devices under faulty conditions. Post-fault behaviour of converter-fed LVDC system involves both active converter control and passive circuit transient of similar time scale, which makes the protection for LVDC distribution significantly different and more challenging than low voltage AC. These protection and operational issues have handicapped the practical applications of DC distribution. This paper presents state-of-the-art protection schemes developed for DC Microgrids. With a close look at practical limitations such as the dependency on modelling accuracy, requirement on communications and so forth, a comprehensive evaluation is carried out on those system approaches in terms of system configurations, fault detection, location, isolation and restoration.
KW  - DC Microgrids
KW  - DC faults
KW  - DC protection
KW  - circuit breakers
DO  - 10.3390/en12061001
ER  -
TY  - EJOU
AU  - Safonova, Anastasiia
AU  - Tabik, Siham
AU  - Alcaraz-Segura, Domingo
AU  - Rubtsov, Alexey
AU  - Maglinets, Yuriy
AU  - Herrera, Francisco
TI  - Detection of Fir Trees (Abies sibirica) Damaged by the Bark Beetle in Unmanned Aerial Vehicle Images with Deep Learning
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Invasion of the Polygraphus proximus Blandford bark beetle causes catastrophic damage to forests with firs (Abies sibirica Ledeb) in Russia, especially in Central Siberia. Determining tree damage stage based on the shape, texture and colour of tree crown in unmanned aerial vehicle (UAV) images could help to assess forest health in a faster and cheaper way. However, this task is challenging since (i) fir trees at different damage stages coexist and overlap in the canopy, (ii) the distribution of fir trees in nature is irregular and hence distinguishing between different crowns is hard, even for the human eye. Motivated by the latest advances in computer vision and machine learning, this work proposes a two-stage solution: In a first stage, we built a detection strategy that finds the regions of the input UAV image that are more likely to contain a crown, in the second stage, we developed a new convolutional neural network (CNN) architecture that predicts the fir tree damage stage in each candidate region. Our experiments show that the proposed approach shows satisfactory results on UAV Red, Green, Blue (RGB) images of forest areas in the state nature reserve “Stolby” (Krasnoyarsk, Russia).
KW  - multi-class classification
KW  - drone
KW  - aerial photography
KW  - Siberian fir
KW  - Siberia
KW  - deep-learning
KW  - convolutional neural networks
KW  - forest health
DO  - 10.3390/rs11060643
ER  -
TY  - EJOU
AU  - Wei, Jie
AU  - Hao, Yanpeng
AU  - Fu, Yuan
AU  - Yang, Lin
AU  - Gan, Jiulin
AU  - Yang, Zhongmin
TI  - Detection of Glaze Icing Load and Temperature of Composite Insulators Using Fiber Bragg Grating
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 6
SN  - 1424-8220

AB  - Conventional methods for the online monitoring of icing conditions of composite insulators suffer from difficulties. To solve this issue, a novel method is first proposed to detect glaze icing load via embedding three optical fibers with fiber Bragg gratings (FBGs) into a 10 kV composite insulator. Specifically, FBG temperature compensation sensors were packaged in ceramic tubes to solve strain and temperature cross-sensitivity. Temperature effect experiments and simulated glaze icing load experiments were performed to verify the feasibility of the proposed method. The results show that temperature sensitivities of all FBGs are identical (i.e., 10.68 pm/&deg;C), which achieves a simultaneous measurement of temperature and strain. In addition, the proposed method can detect glaze icing load of the composite insulator above 0.5 N (i.e., 15% of icicle bridged degree) in the laboratory.
KW  - glaze icing detection
KW  - fiber Bragg grating (FBG)
KW  - composite insulator with embedded FBG
KW  - simultaneous measurement of temperature and strain
DO  - 10.3390/s19061321
ER  -
TY  - EJOU
AU  - Li, Yundong
AU  - Hu, Wei
AU  - Dong, Han
AU  - Zhang, Xueyan
TI  - Building Damage Detection from Post-Event Aerial Imagery Using Single Shot Multibox Detector
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 6
SN  - 2076-3417

AB  - Using aerial cameras, satellite remote sensing or unmanned aerial vehicles (UAV) equipped with cameras can facilitate search and rescue tasks after disasters. The traditional manual interpretation of huge aerial images is inefficient and could be replaced by machine learning-based methods combined with image processing techniques. Given the development of machine learning, researchers find that convolutional neural networks can effectively extract features from images. Some target detection methods based on deep learning, such as the single-shot multibox detector (SSD) algorithm, can achieve better results than traditional methods. However, the impressive performance of machine learning-based methods results from the numerous labeled samples. Given the complexity of post-disaster scenarios, obtaining many samples in the aftermath of disasters is difficult. To address this issue, a damaged building assessment method using SSD with pretraining and data augmentation is proposed in the current study and highlights the following aspects. (1) Objects can be detected and classified into undamaged buildings, damaged buildings, and ruins. (2) A convolution auto-encoder (CAE) that consists of VGG16 is constructed and trained using unlabeled post-disaster images. As a transfer learning strategy, the weights of the SSD model are initialized using the weights of the CAE counterpart. (3) Data augmentation strategies, such as image mirroring, rotation, Gaussian blur, and Gaussian noise processing, are utilized to augment the training data set. As a case study, aerial images of Hurricane Sandy in 2012 were maximized to validate the proposed method&rsquo;s effectiveness. Experiments show that the pretraining strategy can improve of 10% in terms of overall accuracy compared with the SSD trained from scratch. These experiments also demonstrate that using data augmentation strategies can improve mAP and mF1 by 72% and 20%, respectively. Finally, the experiment is further verified by another dataset of Hurricane Irma, and it is concluded that the paper method is feasible.
KW  - building damage assessment
KW  - post-event
KW  - deep learning
KW  - SSD
KW  - convolutional autoencoder
DO  - 10.3390/app9061128
ER  -
TY  - EJOU
AU  - Wen, Xudong
AU  - Liu, Chunwu
AU  - Huang, Zhiping
AU  - Su, Shaojing
AU  - Guo, Xiaojun
AU  - Zuo, Zhen
AU  - Qu, Hao
TI  - A First-Order Differential Data Processing Method for Accuracy Improvement of Complementary Filtering in Micro-UAV Attitude Estimation
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 6
SN  - 1424-8220

AB  - There are many algorithms that can be used to fuse sensor data. The complementary filtering algorithm has low computational complexity and good real-time performance characteristics. It is very suitable for attitude estimation of small unmanned aerial vehicles (micro-UAVs) equipped with low-cost inertial measurement units (IMUs). However, its low attitude estimation accuracy severely limits its applications. Though, many methods have been proposed by researchers to improve attitude estimation accuracy of complementary filtering algorithms, there are few studies that aim to improve it from the data processing aspect. In this paper, a real-time first-order differential data processing algorithm is proposed for gyroscope data, and an adaptive adjustment strategy is designed for the parameters in the algorithm. Besides, the differential-nonlinear complementary filtering (D-NCF) algorithm is proposed by combine the first-order differential data processing algorithm with the basic nonlinear complementary filtering (NCF) algorithm. The experimental results show that the first-order differential data processing algorithm can effectively correct the gyroscope data, and the Root Mean Square Error (RMSE) of attitude estimation of the D-NCF algorithm is smaller than when the NCF algorithm is used. The RMSE of the roll angle decreases from 1.1653 to 0.5093, that of the pitch angle decreases from 2.9638 to 1.5542, and that of the yaw angle decreases from 0.9398 to 0.6827. In general, the attitude estimation accuracy of D-NCF algorithm is higher than that of the NCF algorithm.
KW  - attitude estimation
KW  - nonlinear complementary filtering (NCF)
KW  - sensor fusion
KW  - micro-UAV
KW  - data processing
DO  - 10.3390/s19061340
ER  -
TY  - EJOU
AU  - Surový, Peter
AU  - Kuželka, Karel
TI  - Acquisition of Forest Attributes for Decision Support at the Forest Enterprise Level Using Remote-Sensing Techniques—A Review
T2  - Forests

PY  - 2019
VL  - 10
IS  - 3
SN  - 1999-4907

AB  - In recent decades, remote sensing techniques and the associated hardware and software have made substantial improvements. With satellite images that can obtain sub-meter spatial resolution, and new hardware, particularly unmanned aerial vehicles and systems, there are many emerging opportunities for improved data acquisition, including variable temporal and spectral resolutions. Combined with the evolution of techniques for aerial remote sensing, such as full wave laser scanners, hyperspectral scanners, and aerial radar sensors, the potential to incorporate this new data in forest management is enormous. Here we provide an overview of the current state-of-the-art remote sensing techniques for large forest areas thousands or tens of thousands of hectares. We examined modern remote sensing techniques used to obtain forest data that are directly applicable to decision making issues, and we provided a general overview of the types of data that can be obtained using remote sensing. The most easily accessible forest variable described in many works is stand or tree height, followed by other inventory variables like basal area, tree number, diameters, and volume, which are crucial in decision making process, especially for thinning and harvest planning, and timber transport optimization. Information about zonation and species composition are often described as more difficult to assess; however, this information usually is not required on annual basis. Counts of studies on forest health show an increasing trend in the last years, mostly in context of availability of new sensors as well as increased forest vulnerability caused by climate change; by virtue to modern sensors interesting methods were developed for detection of stressed or damaged trees. Unexpectedly few works focus on regeneration and seedlings evaluation; though regenerated stands should be regularly monitored in order to maintain forest cover sustainability.
KW  - remote sensing
KW  - forest enterprise
KW  - forest attributes
KW  - forest health
KW  - satellite imagery
KW  - aerial imagery
KW  - aerial laser scanner
KW  - unmanned aerial vehicles (UAV)
DO  - 10.3390/f10030273
ER  -
TY  - EJOU
AU  - Darvishzadeh, Roshanak
AU  - Wang, Tiejun
AU  - Skidmore, Andrew
AU  - Vrieling, Anton
AU  - O’Connor, Brian
AU  - Gara, Tawanda W.
AU  - Ens, Bruno J.
AU  - Paganini, Marc
TI  - Analysis of Sentinel-2 and RapidEye for Retrieval of Leaf Area Index in a Saltmarsh Using a Radiative Transfer Model
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - The Sentinel satellite fleet of the Copernicus Programme offers new potential to map and monitor plant traits at fine spatial and temporal resolutions. Among these traits, leaf area index (LAI) is a crucial indicator of vegetation growth and an essential variable in biodiversity studies. Numerous studies have shown that the radiative transfer approach has been a successful method to retrieve LAI from remote-sensing data. However, the suitability and adaptability of this approach largely depend on the type of remote-sensing data, vegetation cover and the ecosystem studied. Saltmarshes are important wetland ecosystems threatened by sea level rise among other human- and animal-induced changes. Therefore, monitoring their vegetation status is crucial for their conservation, yet few LAI assessments exist for these ecosystems. In this study, the retrieval of LAI in a saltmarsh ecosystem is examined using Sentinel-2 and RapidEye data through inversion of the PROSAIL radiative transfer model. Field measurements of LAI and some other plant traits were obtained during two succeeding field campaigns in July 2015 and 2016 on the saltmarsh of Schiermonnikoog, a barrier island of the Netherlands. RapidEye (2015) and Sentinel-2 (2016) data were acquired concurrent to the time of the field campaigns. The broadly employed PROSAIL model was inverted using two look-up tables (LUTs) generated in the spectral band’s settings of the two sensors and in which each contained 500,000 records. Different solutions from the LUTs, as well as, different Sentinel-2 spectral subsets were considered to examine the LAI retrieval. Our results showed that generally the LAI retrieved from Sentinel-2 had higher accuracy compared to RapidEye-retrieved LAI. Utilising the mean of the first 10 best solutions from the LUTs resulted in higher R2 (0.51 and 0.59) and lower normalised root means square error (NRMSE) (0.24 and 0.16) for both RapidEye and Sentinel-2 data respectively. Among different Sentinel-2 spectral subsets, the one comprised of the four near-infrared (NIR) and shortwave infrared (SWIR) spectral bands resulted in higher estimation accuracy (R2 = 0.44, NRMSE = 0.21) in comparison to using other studied spectral subsets. The results demonstrated the feasibility of broadband multispectral sensors, particularly Sentinel-2 for retrieval of LAI in the saltmarsh ecosystem via inversion of PROSAIL. Our results highlight the importance of proper parameterisation of radiative transfer models and capacity of Sentinel-2 spectral range and resolution, with impending high-quality global observation aptitude, for retrieval of plant traits at a global scale.
KW  - Sentinel-2
KW  - RapidEye
KW  - leaf area index (LAI)
KW  - saltmarsh
KW  - PROSAIL
KW  - Look Up Table
DO  - 10.3390/rs11060671
ER  -
TY  - EJOU
AU  - Lim, Joongbin
AU  - Kim, Kyoung-Min
AU  - Jin, Ri
TI  - Tree Species Classification Using Hyperion and Sentinel-2 Data with Machine Learning in South Korea and China
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 3
SN  - 2220-9964

AB  - Remote sensing (RS) has been used to monitor inaccessible regions. It is considered a useful technique for deriving important environmental information from inaccessible regions, especially North Korea. In this study, we aim to develop a tree species classification model based on RS and machine learning techniques, which can be utilized for classification in North Korea. Two study sites were chosen, the Korea National Arboretum (KNA) in South Korea and Mt. Baekdu (MTB; a.k.a., Mt. Changbai in Chinese) in China, located in the border area between North Korea and China, and tree species classifications were examined in both regions. As a preliminary step in developing a classification algorithm that can be applied in North Korea, common coniferous species at both study sites, Korean pine (Pinus koraiensis) and Japanese larch (Larix kaempferi), were chosen as targets for investigation. Hyperion data have been used for tree species classification due to the abundant spectral information acquired from across more than 200 spectral bands (i.e., hyperspectral satellite data). However, it is impossible to acquire recent Hyperion data because the satellite ceased operation in 2017. Recently, Sentinel-2 satellite multispectral imagery has been used in tree species classification. Thus, it is necessary to compare these two kinds of satellite data to determine the possibility of reliably classifying species. Therefore, Hyperion and Sentinel-2 data were employed, along with machine learning techniques, such as random forests (RFs) and support vector machines (SVMs), to classify tree species. Three questions were answered, showing that: (1) RF and SVM are well established in the hyperspectral imagery for tree species classification, (2) Sentinel-2 data can be used to classify tree species with RF and SVM algorithms instead of Hyperion data, and (3) training data that were built in the KNA cannot be used for the tree classification of MTB. Random forests and SVMs showed overall accuracies of 0.60 and 0.51 and kappa values of 0.20 and 0.00, respectively. Moreover, combined training data from the KNA and MTB showed high classification accuracies in both regions; RF and SVM values exhibited accuracies of 0.99 and 0.97 and kappa values of 0.98 and 0.95, respectively.
KW  - hyperspectral image
KW  - random forest
KW  - support vector machine
KW  - texture feature
KW  - image spectroscopy
DO  - 10.3390/ijgi8030150
ER  -
TY  - EJOU
AU  - Angelopoulou, Theodora
AU  - Tziolas, Nikolaos
AU  - Balafoutis, Athanasios
AU  - Zalidis, George
AU  - Bochtis, Dionysis
TI  - Remote Sensing Techniques for Soil Organic Carbon Estimation: A Review
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Towards the need for sustainable development, remote sensing (RS) techniques in the Visible-Near Infrared&ndash;Shortwave Infrared (VNIR&ndash;SWIR, 400&ndash;2500 nm) region could assist in a more direct, cost-effective and rapid manner to estimate important indicators for soil monitoring purposes. Soil reflectance spectroscopy has been applied in various domains apart from laboratory conditions, e.g., sensors mounted on satellites, aircrafts and Unmanned Aerial Systems. The aim of this review is to illustrate the research made for soil organic carbon estimation, with the use of RS techniques, reporting the methodology and results of each study. It also aims to provide a comprehensive introduction in soil spectroscopy for those who are less conversant with the subject. In total, 28 journal articles were selected and further analysed. It was observed that prediction accuracy reduces from Unmanned Aerial Systems (UASs) to satellite platforms, though advances in machine learning techniques could further assist in the generation of better calibration models. There are some challenges concerning atmospheric, radiometric and geometric corrections, vegetation cover, soil moisture and roughness that still need to be addressed. The advantages and disadvantages of each approach are highlighted and future considerations are also discussed at the end.
KW  - soil spectroscopy
KW  - soil organic carbon
KW  - VNIR–SWIR
KW  - machine learning
KW  - earth observation
DO  - 10.3390/rs11060676
ER  -
TY  - EJOU
AU  - Qu, Yuquan
AU  - Zhu, Zhongli
AU  - Chai, Linna
AU  - Liu, Shaomin
AU  - Montzka, Carsten
AU  - Liu, Jin
AU  - Yang, Xiaofan
AU  - Lu, Zheng
AU  - Jin, Rui
AU  - Li, Xiang
AU  - Guo, Zhixia
AU  - Zheng, Jie
TI  - Rebuilding a Microwave Soil Moisture Product Using Random Forest Adopting AMSR-E/AMSR2 Brightness Temperature and SMAP over the Qinghai–Tibet Plateau, China
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Time series of soil moisture (SM) data in the Qinghai&ndash;Tibet plateau (QTP) covering a period longer than one decade are important for understanding the dynamics of land surface&ndash;atmosphere feedbacks in the global climate system. However, most existing SM products have a relatively short time series or show low performance over the challenging terrain of the QTP. In order to improve the spaceborne monitoring in this area, this study presents a random forest (RF) method to rebuild a high-accuracy SM product over the QTP from 19 June 2002 to 31 March 2015 by adopting the advanced microwave scanning radiometer for earth observing system (AMSR-E), and the advanced microwave scanning radiometer 2 (AMSR2), and tracking brightness temperatures with latitude and longitude using the International Geosphere&ndash;Biospheres Programme (IGBP) classification data, the digital elevation model (DEM) and the day of the year (DOY) as spatial predictors. Brightness temperature products (from frequencies 10.7 GHz, 18.7 GHz and 36.5 GHz) of AMSR2 were used to train the random forest model on two years of Soil Moisture Active Passive (SMAP) SM data. The simulated SM values were compared with third year SMAP data and in situ stations. The results show that the RF model has high reliability as compared to SMAP, with a high correlation (R = 0.95) and low values of root mean square error (RMSE = 0.03 m3/m3) and mean absolute percent error (MAPE = 19%). Moreover, the random forest soil moisture (RFSM) results agree well with the data from five in situ networks, with mean values of R = 0.75, RMSE = 0.06 m3/m3, and bias = &minus;0.03 m3/m3 over the whole year and R = 0.70, RMSE = 0.07 m3/m3, and bias = &minus;0.05 m3/m3 during the unfrozen seasons. In order to test its performance throughout the whole region of QTP, the three-cornered hat (TCH) method based on removing common signals from observations and then calculating the uncertainties is applied. The results indicate that RFSM has the smallest relative error in 56% of the region, and it performs best relative to the Japan Aerospace Exploration Agency (JAXA), Global Land Data Assimilation System (GLDAS), and European Space Agency&rsquo;s Climate Change Initiative (ESA CCI) project. The spatial distribution shows that RFSM has a similar spatial trend as GLDAS and ESA CCI, but RFSM exhibits a more distinct spatial distribution and responds to precipitation more effectively than GLDAS and ESA CCI. Moreover, a trend analysis shows that the temporal variation of RFSM agrees well with precipitation and LST (land surface temperature), with a dry trend in most regions of QTP and a wet trend in few north, southeast and southwest regions of QTP. In conclusion, a spatiotemporally continuous SM product with a high accuracy over the QTP was obtained.
KW  - soil moisture
KW  - random forest
KW  - Qinghai–Tibet plateau
KW  - SMAP
KW  - AMSR-E
KW  - AMSR2
DO  - 10.3390/rs11060683
ER  -
TY  - EJOU
AU  - Liu, Shengjie
AU  - Qi, Zhixin
AU  - Li, Xia
AU  - Yeh, Anthony G.
TI  - Integration of Convolutional Neural Networks and Object-Based Post-Classification Refinement for Land Use and Land Cover Mapping with Optical and SAR Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Object-based image analysis (OBIA) has been widely used for land use and land cover (LULC) mapping using optical and synthetic aperture radar (SAR) images because it can utilize spatial information, reduce the effect of salt and pepper, and delineate LULC boundaries. With recent advances in machine learning, convolutional neural networks (CNNs) have become state-of-the-art algorithms. However, CNNs cannot be easily integrated with OBIA because the processing unit of CNNs is a rectangular image, whereas that of OBIA is an irregular image object. To obtain object-based thematic maps, this study developed a new method that integrates object-based post-classification refinement (OBPR) and CNNs for LULC mapping using Sentinel optical and SAR data. After producing the classification map by CNN, each image object was labeled with the most frequent land cover category of its pixels. The proposed method was tested on the optical-SAR Sentinel Guangzhou dataset with 10 m spatial resolution, the optical-SAR Zhuhai-Macau local climate zones (LCZ) dataset with 100 m spatial resolution, and a hyperspectral benchmark the University of Pavia with 1.3 m spatial resolution. It outperformed OBIA support vector machine (SVM) and random forest (RF). SVM and RF could benefit more from the combined use of optical and SAR data compared with CNN, whereas spatial information learned by CNN was very effective for classification. With the ability to extract spatial features and maintain object boundaries, the proposed method considerably improved the classification accuracy of urban ground targets. It achieved overall accuracy (OA) of 95.33% for the Sentinel Guangzhou dataset, OA of 77.64% for the Zhuhai-Macau LCZ dataset, and OA of 95.70% for the University of Pavia dataset with only 10 labeled samples per class.
KW  - object-based post-classification refinement (OBPR)
KW  - convolutional neural network (CNN)
KW  - synthetic aperture radar (SAR)
KW  - land use and land cover
KW  - object-based image analysis (OBIA)
DO  - 10.3390/rs11060690
ER  -
TY  - EJOU
AU  - Wu, Jintao
AU  - Yang, Guijun
AU  - Yang, Xiaodong
AU  - Xu, Bo
AU  - Han, Liang
AU  - Zhu, Yaohui
TI  - Automatic Counting of in situ Rice Seedlings from UAV Images Based on a Deep Fully Convolutional Neural Network
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - The number of rice seedlings in the field is one of the main agronomic components for determining rice yield. This counting task, however, is still mainly performed using human vision rather than computer vision and is thus cumbersome and time-consuming. A fast and accurate alternative method of acquiring such data may contribute to monitoring the efficiency of crop management practices, to earlier estimations of rice yield, and as a phenotyping trait in breeding programs. In this paper, we propose an efficient method that uses computer vision to accurately count rice seedlings in a digital image. First, an unmanned aerial vehicle (UAV) equipped with red-green-blue (RGB) cameras was used to acquire field images at the seedling stage. Next, we use a regression network (Basic Network) inspired by a deep fully convolutional neural network to regress the density map and estimate the number of rice seedlings for a given UAV image. Finally, an improved version of the Basic Network, the Combined Network, is also proposed to further improve counting accuracy. To explore the efficacy of the proposed method, a novel rice seedling counting (RSC) dataset was built, which consisted of 40 images (where the number of seedlings varied between 3732 and 16,173) and corresponding manually-dotted annotations. The results demonstrated high average accuracy (higher than 93%) between counts according to the proposed method and manual (UAV image-based) rice seedling counts, and very good performance, with a high coefficient of determination (R2) (around 0.94). In conclusion, the results indicate that the proposed method is an efficient alternative for large-scale counting of rice seedlings, and offers a new opportunity for yield estimation. The RSC dataset and source code are available online.
KW  - rice seedlings
KW  - object counting
KW  - computer vision
KW  - deep learning
KW  - fully convolutional neural networks
DO  - 10.3390/rs11060691
ER  -
TY  - EJOU
AU  - Mcilwaine, Ben
AU  - Casado, Monica R.
AU  - Leinster, Paul
TI  - Using 1st Derivative Reflectance Signatures within a Remote Sensing Framework to Identify Macroalgae in Marine Environments
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Macroalgae blooms (MABs) are a global natural hazard that are likely to increase in occurrence with climate change and increased agricultural runoff. MABs can cause major issues for indigenous species, fish farms, nuclear power stations, and tourism activities. This project focuses on the impacts of MABs on the operations of a British nuclear power station. However, the outputs and findings are also of relevance to other coastal operators with similar problems. Through the provision of an early-warning detection system for MABs, it should be possible to minimize the damaging effects and possibly avoid them altogether. Current methods based on satellite imagery cannot be used to detect low-density mobile vegetation at various water depths. This work is the first step towards providing a system that can warn a coastal operator 6&ndash;8 h prior to a marine ingress event. A fundamental component of such a warning system is the spectral reflectance properties of the problematic macroalgae species. This is necessary to optimize the detection capability for the problematic macroalgae in the marine environment. We measured the reflectance signatures of eight species of macroalgae that we sampled in the vicinity of the power station. Only wavelengths below 900 nm (700 nm for similarity percentage (SIMPER)) were analyzed, building on current methodologies. We then derived 1st derivative spectra of these eight sampled species. A multifaceted univariate and multivariate approach was used to visualize the spectral reflectance, and an analysis of similarities (ANOSIM) provided a species-level discrimination rate of 85% for all possible pairwise comparisons. A SIMPER analysis was used to detect wavebands that consistently contributed to the simultaneous discrimination of all eight sampled macroalgae species to both a group level (535&ndash;570 nm), and to a species level (570&ndash;590 nm). Sampling locations were confirmed using a fixed-wing unmanned aerial vehicle (UAV), with the collected imagery being used to produce a single orthographic image via standard photogrammetric processes. The waveband found to contribute consistently to group-level discrimination has previously been found to be associated with photosynthetic pigmentation, whereas the species-level discriminatory waveband did not share this association. This suggests that the photosynthetic pigments were not spectrally diverse enough to successfully distinguish all eight species. We suggest that future work should investigate a Charge-Coupled Device (CCD)-based sensor using the wavebands highlighted above. This should facilitate the development of a regional-scale early-warning MAB detection system using UAVs, and help inform optimum sensor filter selection.
KW  - macroalgae
KW  - reflectance
KW  - 1st derivative
KW  - species discrimination
KW  - unmanned aerial vehicle
KW  - nuclear power station
DO  - 10.3390/rs11060704
ER  -
TY  - EJOU
AU  - Windrim, Lloyd
AU  - Bryson, Mitch
AU  - McLean, Michael
AU  - Randle, Jeremy
AU  - Stone, Christine
TI  - Automated Mapping of Woody Debris over Harvested Forest Plantations Using UAVs, High-Resolution Imagery, and Machine Learning
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Surveying of woody debris left over from harvesting operations on managed forests is an important step in monitoring site quality, managing the extraction of residues and reconciling differences in pre-harvest inventories and actual timber yields. Traditional methods for post-harvest survey involving manual assessment of debris on the ground over small sample plots are labor-intensive, time-consuming, and do not scale well to heterogeneous landscapes. In this paper, we propose and evaluate new automated methods for the collection and interpretation of high-resolution, Unmanned Aerial Vehicle (UAV)-borne imagery over post-harvested forests for estimating quantities of fine and coarse woody debris. Using high-resolution, geo-registered color mosaics generated from UAV-borne images, we develop manual and automated processing methods for detecting, segmenting and counting both fine and coarse woody debris, including tree stumps, exploiting state-of-the-art machine learning and image processing techniques. Results are presented using imagery over a post-harvested compartment in a Pinus radiata plantation and demonstrate the capacity for both manual image annotations and automated image processing to accurately detect and quantify coarse woody debris and stumps left over after harvest, providing a cost-effective and scalable survey method for forest managers.
KW  - Unmanned Aerial Vehicles (UAVs)
KW  - computer vision
KW  - forestry
KW  - Coarse Woody Debris (CWD)
KW  - Convolutional Neural Networks (CNNs)
DO  - 10.3390/rs11060733
ER  -
TY  - EJOU
AU  - Hu, Jie
AU  - Peng, Jie
AU  - Zhou, Yin
AU  - Xu, Dongyun
AU  - Zhao, Ruiying
AU  - Jiang, Qingsong
AU  - Fu, Tingting
AU  - Wang, Fei
AU  - Shi, Zhou
TI  - Quantitative Estimation of Soil Salinity Using UAV-Borne Hyperspectral and Satellite Multispectral Images
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 7
SN  - 2072-4292

AB  - Soil salinization is a global issue resulting in soil degradation, arable land loss and ecological environmental deterioration. Over the decades, multispectral and hyperspectral remote sensing have enabled efficient and cost-effective monitoring of salt-affected soils. However, the potential of hyperspectral sensors installed on an unmanned aerial vehicle (UAV) to estimate and map soil salinity has not been thoroughly explored. This study quantitatively characterized and estimated field-scale soil salinity using an electromagnetic induction (EMI) equipment and a hyperspectral camera installed on a UAV platform. In addition, 30 soil samples (0~20 cm) were collected in each field for the lab measurements of electrical conductivity. First, the apparent electrical conductivity (ECa) values measured by EMI were calibrated using the lab measured electrical conductivity derived from soil samples based on empirical line method. Second, the soil salinity was quantitatively estimated using the random forest (RF) regression method based on the reflectance factors of UAV hyperspectral images and satellite multispectral data. The performance of models was assessed by Lin&rsquo;s concordance coefficient (CC), ratio of performance to deviation (RPD), and root mean square error (RMSE). Finally, the soil salinity of three study fields with different land cover were mapped. The results showed that bare land (field A) exhibited the most severe salinity, followed by dense vegetation area (field C) and sparse vegetation area (field B). The predictive models using UAV data outperformed those derived from GF-2 data with lower RMSE, higher CC and RPD values, and the most accurate UAV-derived model was developed using 62 hyperspectral bands of the image of the field A with the RMSE, CC, and RPD values of 1.40 dS m&minus;1, 0.94, and 2.98, respectively. Our results indicated that UAV-borne hyperspectral imager is a useful tool for field-scale soil salinity monitoring and mapping. With the help of the EMI technique, quantitative estimation of surface soil salinity is critical to decision-making in arid land management and saline soil reclamation.
KW  - soil salinity
KW  - unmanned aerial vehicle
KW  - hyperspectral imager
KW  - random forest regression
KW  - electromagnetic induction
DO  - 10.3390/rs11070736
ER  -
TY  - EJOU
AU  - Maimaitiyiming, Matthew
AU  - Sagan, Vasit
AU  - Sidike, Paheding
AU  - Kwasniewski, Misha T.
TI  - Dual Activation Function-Based Extreme Learning Machine (ELM) for Estimating Grapevine Berry Yield and Quality
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 7
SN  - 2072-4292

AB  - Reliable assessment of grapevine productivity is a destructive and time-consuming process. In addition, the mixed effects of grapevine water status and scion-rootstock interactions on grapevine productivity are not always linear. Despite the potential opportunity of applying remote sensing and machine learning techniques to predict plant traits, there are still limitations to previously studied techniques for vine productivity due to the complexity of the system not being adequately modeled. During the 2014 and 2015 growing seasons, hyperspectral reflectance spectra were collected using a handheld spectroradiometer in a vineyard designed to investigate the effects of irrigation level (0%, 50%, and 100%) and rootstocks (1103 Paulsen, 3309 Couderc, SO4 and Chambourcin) on vine productivity. To assess vine productivity, it is necessary to measure factors related to fruit ripeness and not just yield, as an over cropped vine may produce high-yield but poor-quality fruit. Therefore, yield, Total Soluble Solids (TSS), Titratable Acidity (TA) and the ratio TSS/TA (maturation index, IMAD) were measured. A total of 20 vegetation indices were calculated from hyperspectral data and used as input for predictive model calibration. Prediction performance of linear/nonlinear multiple regression methods and Weighted Regularized Extreme Learning Machine (WRELM) were compared with our newly developed WRELM-TanhRe. The developed method is based on two activation functions: hyperbolic tangent (Tanh) and rectified linear unit (ReLU). The results revealed that WRELM and WRELM-TanhRe outperformed the widely used multiple regression methods when model performance was tested with an independent validation dataset. WRELM-TanhRe produced the highest prediction accuracy for all the berry yield and quality parameters (R2 of 0.522&ndash;0.682 and RMSE of 2&ndash;15%), except for TA, which was predicted best with WRELM (R2 of 0.545 and RMSE of 6%). The results demonstrate the value of combining hyperspectral remote sensing and machine learning methods for improving of berry yield and quality prediction.
KW  - grapevine productivity
KW  - hyperspectral reflectance
KW  - stress
KW  - rootstock
KW  - vegetation indices
KW  - WRELM-TanhRe
KW  - neural network
KW  - activation function
DO  - 10.3390/rs11070740
ER  -
TY  - EJOU
AU  - Gebrehiwot, Asmamaw
AU  - Hashemi-Beni, Leila
AU  - Thompson, Gary
AU  - Kordjamshidi, Parisa
AU  - Langan, Thomas E.
TI  - Deep Convolutional Neural Network for Flood Extent Mapping Using Unmanned Aerial Vehicles Data
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 7
SN  - 1424-8220

AB  - Flooding is one of the leading threats of natural disasters to human life and property, especially in densely populated urban areas. Rapid and precise extraction of the flooded areas is key to supporting emergency-response planning and providing damage assessment in both spatial and temporal measurements. Unmanned Aerial Vehicles (UAV) technology has recently been recognized as an efficient photogrammetry data acquisition platform to quickly deliver high-resolution imagery because of its cost-effectiveness, ability to fly at lower altitudes, and ability to enter a hazardous area. Different image classification methods including SVM (Support Vector Machine) have been used for flood extent mapping. In recent years, there has been a significant improvement in remote sensing image classification using Convolutional Neural Networks (CNNs). CNNs have demonstrated excellent performance on various tasks including image classification, feature extraction, and segmentation. CNNs can learn features automatically from large datasets through the organization of multi-layers of neurons and have the ability to implement nonlinear decision functions. This study investigates the potential of CNN approaches to extract flooded areas from UAV imagery. A VGG-based fully convolutional network (FCN-16s) was used in this research. The model was fine-tuned and a k-fold cross-validation was applied to estimate the performance of the model on the new UAV imagery dataset. This approach allowed FCN-16s to be trained on the datasets that contained only one hundred training samples, and resulted in a highly accurate classification. Confusion matrix was calculated to estimate the accuracy of the proposed method. The image segmentation results obtained from FCN-16s were compared from the results obtained from FCN-8s, FCN-32s and SVMs. Experimental results showed that the FCNs could extract flooded areas precisely from UAV images compared to the traditional classifiers such as SVMs. The classification accuracy achieved by FCN-16s, FCN-8s, FCN-32s, and SVM for the water class was 97.52%, 97.8%, 94.20% and 89%, respectively.
KW  - remote sensing
KW  - convolutional neural networks
KW  - floodplain mapping
KW  - fully convolutional network
KW  - unmanned aerial vehicles
KW  - geospatial data processing
DO  - 10.3390/s19071486
ER  -
TY  - EJOU
AU  - Zhao, Zhenbing
AU  - Zhen, Zhen
AU  - Zhang, Lei
AU  - Qi, Yincheng
AU  - Kong, Yinghui
AU  - Zhang, Ke
TI  - Insulator Detection Method in Inspection Image Based on Improved Faster R-CNN
T2  - Energies

PY  - 2019
VL  - 12
IS  - 7
SN  - 1996-1073

AB  - The detection of insulators in power transmission and transformation inspection images is the basis for insulator state detection and fault diagnosis in thereafter. Aiming at the detection of insulators with different aspect ratios and scales and ones with mutual occlusion, a method of insulator inspection image based on the improved faster region-convolutional neural network (R-CNN) is put forward in this paper. By constructing a power transmission and transformation insulation equipment detection dataset and fine-tuning the faster R-CNN model, the anchor generation method and non-maximum suppression (NMS) in the region proposal network (RPN) of the faster R-CNN model were improved, thus realizing a better detection of insulators. The experimental results show that the average precision (AP) value of the faster R-CNN model was increased to 0.818 with the improved anchor generation method under the VGG-16 Net. In addition, the detection effect of different aspect ratios and different scales of insulators in the inspection images was improved significantly, and the occlusion of insulators could be effectively distinguished and detected using the improved NMS.
KW  - insulator
KW  - Faster R-CNN
KW  - object detection
KW  - RPN
KW  - deep learning
DO  - 10.3390/en12071204
ER  -
TY  - EJOU
AU  - Farlik, Jan
AU  - Kratky, Miroslav
AU  - Casar, Josef
AU  - Stary, Vadim
TI  - Multispectral Detection of Commercial Unmanned Aerial Vehicles
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 7
SN  - 1424-8220

AB  - The fight against unmanned vehicles is nothing new; however, especially with the arrival of new technologies that are easily accessible for the wider population, new problems are arising. The deployment of small unmanned aerial vehicles (UAVs) by paramilitary organizations during conflicts around the world has become a reality, non-lethal &ldquo;paparazzi&rdquo; actions have become a common practice, and it is only a matter of time until the population faces lethal attacks. The basic prerequisite for direct defense against attacking UAVs is their detection. The authors of this paper analysed the possibility of detecting flying aircraft in several different electro-magnetic spectrum bands. Firstly, methods based on calculations and simulations were chosen, and experiments in laboratories and measurements of the exterior were subsequently performed. As a result, values of the radar cross section (RCS), the noise level, the surface temperature, and optical as well as acoustic traces of tested devices were quantified. The outputs obtained from calculated, simulated, and experimentally detected values were found via UAV detection distances using specific sensors working in corresponding parts of the frequency spectrum.
KW  - air defense
KW  - reconnaissance
KW  - detection
KW  - unmanned aerial vehicle
KW  - air threat
KW  - terrorism
KW  - drone
DO  - 10.3390/s19071517
ER  -
TY  - EJOU
AU  - Li, Yangyang
AU  - Wang, Ximing
AU  - Liu, Dianxiong
AU  - Guo, Qiuju
AU  - Liu, Xin
AU  - Zhang, Jie
AU  - Xu, Yitao
TI  - On the Performance of Deep Reinforcement Learning-Based Anti-Jamming Method Confronting Intelligent Jammer
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 7
SN  - 2076-3417

AB  - With the development of access technologies and artificial intelligence, a deep reinforcement learning (DRL) algorithm is proposed into channel accessing and anti-jamming. Assuming the jamming modes are sweeping, comb, dynamic and statistic, the DRL-based method through training can almost perfectly avoid jamming signal and communicate successfully. Instead, in this paper, from the perspective of jammers, we investigate the performance of a DRL-based anti-jamming method. First of all, we design an intelligent jamming method based on reinforcement learning to combat the DRL-based user. Then, we theoretically analyze the condition when the DRL-based anti-jamming algorithm cannot converge, and provide the proof. Finally, in order to investigate the performance of DRL-based method, various scenarios where users with different communicating modes combat jammers with different jamming modes are compared. As the simulation results show, the theoretical analysis is verified, and the proposed RL-based jamming can effectively restrict the performance of DRL-based anti-jamming method.
KW  - deep reinforcement learning
KW  - Q-learning
KW  - intelligent anti-jamming
KW  - intelligent jamming
DO  - 10.3390/app9071361
ER  -
TY  - EJOU
AU  - Ostovar, Ahmad
AU  - Talbot, Bruce
AU  - Puliti, Stefano
AU  - Astrup, Rasmus
AU  - Ringdahl, Ola
TI  - Detection and Classification of Root and Butt-Rot (RBR) in Stumps of Norway Spruce Using RGB Images and Machine Learning
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 7
SN  - 1424-8220

AB  - Root and butt-rot (RBR) has a significant impact on both the material and economic outcome of timber harvesting, and therewith on the individual forest owner and collectively on the forest and wood processing industries. An accurate recording of the presence of RBR during timber harvesting would enable a mapping of the location and extent of the problem, providing a basis for evaluating spread in a climate anticipated to enhance pathogenic growth in the future. Therefore, a system to automatically identify and detect the presence of RBR would constitute an important contribution to addressing the problem without increasing workload complexity for the machine operator. In this study, we developed and evaluated an approach based on RGB images to automatically detect tree stumps and classify them as to the absence or presence of rot. Furthermore, since knowledge of the extent of RBR is valuable in categorizing logs, we also classify stumps into three classes of infestation; rot = 0%, 0% &lt; rot &lt; 50% and rot &ge; 50%. In this work we used deep-learning approaches and conventional machine-learning algorithms for detection and classification tasks. The results showed that tree stumps were detected with precision rate of 95% and recall of 80%. Using only the correct output (TP) of the stump detector, stumps without and with RBR were correctly classified with accuracy of 83.5% and 77.5%, respectively. Classifying rot into three classes resulted in 79.4%, 72.4%, and 74.1% accuracy for stumps with rot = 0%, 0% &lt; rot &lt; 50%, and rot &ge; 50%, respectively. With some modifications, the developed algorithm could be used either during the harvesting operation to detect RBR regions on the tree stumps or as an RBR detector for post-harvest assessment of tree stumps and logs.
KW  - deep learning
KW  - forest harvesting
KW  - tree stumps
KW  - automatic detection and classification
DO  - 10.3390/s19071579
ER  -
TY  - EJOU
AU  - Azabi, Yousef
AU  - Savvaris, Al
AU  - Kipouros, Timoleon
TI  - Artificial Intelligence to Enhance Aerodynamic Shape Optimisation of the Aegis UAV
T2  - Machine Learning and Knowledge Extraction

PY  - 2019
VL  - 1
IS  - 2
SN  - 2504-4990

AB  - This article presents an optimisation framework that uses stochastic multi-objective optimisation, combined with an Artificial Neural Network (ANN), and describes its application to the aerodynamic design of aircraft shapes. The framework uses the Multi-Objective Particle Swarm Optimisation (MOPSO) algorithm and the obtained results confirm that the proposed technique provides highly optimal solutions in less computational time than other approaches to the same design problem. The main idea was to focus computational effort on worthwhile design solutions rather than exploring and evaluating all possible solutions in the design space. It is shown that the number of valid solutions obtained using ANN-MOPSO compared to MOPSO for 3000 evaluations grew from 529 to 1006 (90% improvement) with a penalty of only 8.3% (11 min) in computational time. It is demonstrated that including an ANN, the ANN-MOPSO with 3000 evaluations produced a larger number of valid solutions than the MOPSO with 5500 evaluations, and in 33% less computational time (64 min). This is taken as confirmation of the potential power of ANNs when applied to this type of design problem.
KW  - machine learning
KW  - data visualization
KW  - Multi-Objective Particle Swarm Optimisation
KW  - Multi-Objective Tabu Search
KW  - nimrod/tool
KW  - parallel coordinates
KW  - Athena Vortex Lattice
DO  - 10.3390/make1020033
ER  -
TY  - EJOU
AU  - Hong, Suk-Ju
AU  - Han, Yunhyeok
AU  - Kim, Sang-Yeon
AU  - Lee, Ah-Yeong
AU  - Kim, Ghiseok
TI  - Application of Deep-Learning Methods to Bird Detection Using Unmanned Aerial Vehicle Imagery
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 7
SN  - 1424-8220

AB  - Wild birds are monitored with the important objectives of identifying their habitats and estimating the size of their populations. Especially in the case of migratory bird, they are significantly recorded during specific periods of time to forecast any possible spread of animal disease such as avian influenza. This study led to the construction of deep-learning-based object-detection models with the aid of aerial photographs collected by an unmanned aerial vehicle (UAV). The dataset containing the aerial photographs includes diverse images of birds in various bird habitats and in the vicinity of lakes and on farmland. In addition, aerial images of bird decoys are captured to achieve various bird patterns and more accurate bird information. Bird detection models such as Faster Region-based Convolutional Neural Network (R-CNN), Region-based Fully Convolutional Network (R-FCN), Single Shot MultiBox Detector (SSD), Retinanet, and You Only Look Once (YOLO) were created and the performance of all models was estimated by comparing their computing speed and average precision. The test results show Faster R-CNN to be the most accurate and YOLO to be the fastest among the models. The combined results demonstrate that the use of deep-learning-based detection methods in combination with UAV aerial imagery is fairly suitable for bird detection in various environments.
KW  - deep learning
KW  - convolutional neural networks
KW  - unmanned aerial vehicle
KW  - bird detection
DO  - 10.3390/s19071651
ER  -
TY  - EJOU
AU  - Liao, Jianshang
AU  - Wang, Liguo
TI  - Hyperspectral Image Classification Based on Fusion of Curvature Filter and Domain Transform Recursive Filter
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 7
SN  - 2072-4292

AB  - In recent decades, in order to enhance the performance of hyperspectral image classification, the spatial information of hyperspectral image obtained by various methods has become a research hotspot. For this work, it proposes a new classification method based on the fusion of two spatial information, which will be classified by a large margin distribution machine (LDM). First, the spatial texture information is extracted from the top of the principal component analysis for hyperspectral images by a curvature filter (CF). Second, the spatial correlation information of a hyperspectral image is completed by using domain transform recursive filter (DTRF). Last, the spatial texture information and correlation information are fused to be classified with LDM. The experimental results of hyperspectral images classification demonstrate that the proposed curvature filter and domain transform recursive filter with LDM(CFDTRF-LDM) method is superior to other classification methods.
KW  - hyperspectral image
KW  - classification
KW  - curvature filter
KW  - domain transform recursive filter
KW  - large margin distribution machine
DO  - 10.3390/rs11070833
ER  -
TY  - EJOU
AU  - Mao, Huihui
AU  - Meng, Jihua
AU  - Ji, Fujiang
AU  - Zhang, Qiankun
AU  - Fang, Huiting
TI  - Comparison of Machine Learning Regression Algorithms for Cotton Leaf Area Index Retrieval Using Sentinel-2 Spectral Bands
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 7
SN  - 2076-3417

AB  - Leaf area index (LAI) is a crucial crop biophysical parameter that has been widely used in a variety of fields. Five state-of-the-art machine learning regression algorithms (MLRAs), namely, artificial neural network (ANN), support vector regression (SVR), Gaussian process regression (GPR), random forest (RF) and gradient boosting regression tree (GBRT), have been used in the retrieval of cotton LAI with Sentinel-2 spectral bands. The performances of the five machine learning models are compared for better applications of MLRAs in remote sensing, since challenging problems remain in the selection of MLRAs for crop LAI retrieval, as well as the decision as to the optimal number for the training sample size and spectral bands to different MLRAs. A comprehensive evaluation was employed with respect to model accuracy, computational efficiency, sensitivity to training sample size and sensitivity to spectral bands. We conducted the comparison of five MLRAs in an agricultural area of Northwest China over three cotton seasons with the corresponding field campaigns for modeling and validation. Results show that the GBRT model outperforms the other models with respect to model accuracy in average (       R 2   &macr;      = 0.854,       R M S E  &macr;      = 0.674 and       M A E  &macr;      = 0.456). SVR achieves the best performance in computational efficiency, which means it is fast to train, and to validate that it has great potentials to deliver near-real-time operational products for crop management. As for sensitivity to training sample size, GBRT behaves as the most robust model, and provides the best model accuracy on the average among the variations of training sample size, compared with other models (       R 2   &macr;      = 0.884,       R M S E  &macr;      = 0.615 and       M A E  &macr;      = 0.452). Spectral bands sensitivity analysis with dCor (distance correlation), combined with the backward elimination approach, indicates that SVR, GPR and RF provide relatively robust performance to the spectral bands, while ANN outperforms the other models in terms of model accuracy on the average among the reduction of spectral bands (       R 2   &macr;      = 0.881,       R M S E  &macr;      = 0.625 and       M A E  &macr;      = 0.480). A comprehensive evaluation indicates that GBRT is an appealing alternative for cotton LAI retrieval, except for its computational efficiency. Despite the different performance of the ML models, all models exhibited considerable potential for cotton LAI retrieval, which could offer accurate crop parameters information timely and accurately for crop fields management and agricultural production decisions.
KW  - leaf area index (LAI)
KW  - machine learning
KW  - Sentinel-2
KW  - sensitivity analysis
KW  - training sample size
KW  - spectral bands
DO  - 10.3390/app9071459
ER  -
TY  - EJOU
AU  - Khan, Nabeel
AU  - Martini, Maria G.
TI  - Bandwidth Modeling of Silicon Retinas for Next Generation Visual Sensor Networks
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 8
SN  - 1424-8220

AB  - Silicon retinas, also known as Dynamic Vision Sensors (DVS) or event-based visual sensors, have shown great advantages in terms of low power consumption, low bandwidth, wide dynamic range and very high temporal resolution. Owing to such advantages as compared to conventional vision sensors, DVS devices are gaining more and more attention in various applications such as drone surveillance, robotics, high-speed motion photography, etc. The output of such sensors is a sequence of events rather than a series of frames as for classical cameras. Estimating the data rate of the stream of events associated with such sensors is needed for the appropriate design of transmission systems involving such sensors. In this work, we propose to consider information about the scene content and sensor speed to support such estimation, and we identify suitable metrics to quantify the complexity of the scene for this purpose. According to the results of this study, the event rate shows an exponential relationship with the metric associated with the complexity of the scene and linear relationships with the speed of the sensor. Based on these results, we propose a two-parameter model for the dependency of the event rate on scene complexity and sensor speed. The model achieves a prediction accuracy of approximately 88.4% for the outdoor environment along with the overall prediction performance of approximately 84%.
KW  - neuromorphic engineering
KW  - dynamic and active-pixel vision sensor
KW  - scene complexity
KW  - neuromorphic event rate
KW  - gradient approximation
KW  - scene texture
KW  - Sobel
KW  - Roberts
KW  - Prewitt
DO  - 10.3390/s19081751
ER  -
TY  - EJOU
AU  - Wu, Qing
AU  - Shen, Xudong
AU  - Jin, Yuanzhe
AU  - Chen, Zeyu
AU  - Li, Shuai
AU  - Khan, Ameer H.
AU  - Chen, Dechao
TI  - Intelligent Beetle Antennae Search for UAV Sensing and Avoidance of Obstacles
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 8
SN  - 1424-8220

AB  - Based on a bio-heuristic algorithm, this paper proposes a novel path planner called obstacle avoidance beetle antennae search (OABAS) algorithm, which is applied to the global path planning of unmanned aerial vehicles (UAVs). Compared with the previous bio-heuristic algorithms, the algorithm proposed in this paper has advantages of a wide search range and breakneck search speed, which resolves the contradictory requirements of the high computational complexity of the bio-heuristic algorithm and real-time path planning of UAVs. Besides, the constraints used by the proposed algorithm satisfy various characteristics of the path, such as shorter path length, maximum allowed turning angle, and obstacle avoidance. Ignoring the z-axis optimization by combining with the minimum threat surface (MTS), the resultant path meets the requirements of efficiency and safety. The effectiveness of the algorithm is substantiated by applying the proposed path planning algorithm on the UAVs. Moreover, comparisons with other existing algorithms further demonstrate the superiority of the proposed OABAS algorithm.
KW  - UAVs
KW  - path planning
KW  - obstacle avoidance
KW  - MTS
KW  - optimization algorithms
DO  - 10.3390/s19081758
ER  -
TY  - EJOU
AU  - Zhang, Hehu
AU  - Wang, Xiushan
AU  - Chen, Ying
AU  - Jiang, Guoqiang
AU  - Lin, Shifeng
TI  - Research on Vision-Based Navigation for Plant Protection UAV under the Near Color Background
T2  - Symmetry

PY  - 2019
VL  - 11
IS  - 4
SN  - 2073-8994

AB  - GPS (Global Positioning System) navigation in agriculture is facing many challenges, such as weak signals in orchards and the high cost for small plots of farmland. With the reduction of camera cost and the emergence of excellent visual algorithms, visual navigation can solve the above problems. Visual navigation is a navigation technology that uses cameras to sense environmental information as the basis of an aircraft flight. It is mainly divided into five parts: Image acquisition, landmark recognition, route planning, flight control, and obstacle avoidance. Here, landmarks are plant canopy, buildings, mountains, and rivers, with unique geographical characteristics in a place. During visual navigation, landmark location and route tracking are key links. When there are significant color-differences (for example, the differences among red, green, and blue) between a landmark and the background, the landmark can be recognized based on classical visual algorithms. However, in the case of non-significant color-differences (for example, the differences between dark green and vivid green) between a landmark and the background, there are no robust and high-precision methods for landmark identification. In view of the above problem, visual navigation in a maize field is studied. First, the block recognition method based on fine-tuned Inception-V3 is developed; then, the maize canopy landmark is recognized based on the above method; finally, local navigation lines are extracted from the landmarks based on the maize canopy grayscale gradient law. The results show that the accuracy is 0.9501. When the block number is 256, the block recognition method achieves the best segmentation. The average segmentation quality is 0.87, and time is 0.251 s. This study suggests that stable visual semantic navigation can be achieved under the near color background. It will be an important reference for the navigation of plant protection UAV (Unmanned Aerial Vehicle).
KW  - landmark location
KW  - route tracking
KW  - inception-V3
KW  - visual navigation
KW  - grayscale gradient law
DO  - 10.3390/sym11040533
ER  -
TY  - EJOU
AU  - Guo, Qiang
AU  - Yu, Xin
AU  - Ruan, Guoqing
TI  - LPI Radar Waveform Recognition Based on Deep Convolutional Neural Network Transfer Learning
T2  - Symmetry

PY  - 2019
VL  - 11
IS  - 4
SN  - 2073-8994

AB  - Low Probability of Intercept (LPI) radar waveform recognition is not only an important branch of the electronic reconnaissance field, but also an important means to obtain non-cooperative radar information. To solve the problems of LPI radar waveform recognition rate, difficult feature extraction and large number of samples needed, an automatic classification and recognition system based on Choi-Williams distribution (CWD) and depth convolution neural network migration learning is proposed in this paper. First, the system performs CWD time-frequency transform on the LPI radar waveform to obtain a 2-D time-frequency image. Then the system preprocesses the original time-frequency image. In addition, then the system sends the pre-processed image to the pre-training model (Inception-v3 or ResNet-152) of the deep convolution network for feature extraction. Finally, the extracted features are sent to a Support Vector Machine (SVM) classifier to realize offline training and online recognition of radar waveforms. The simulation results show that the overall recognition rate of the eight LPI radar signals (LFM, BPSK, Costas, Frank, and T1&ndash;T4) of the ResNet-152-SVM system reaches 97.8%, and the overall recognition rate of the Inception-v3-SVM system reaches 96.2% when the SNR is &minus;2 dB.
KW  - Low Probability of Intercept
KW  - CWD time-frequency analysis
KW  - Inception-v3
KW  - ResNet-152
KW  - transfer learning
DO  - 10.3390/sym11040540
ER  -
TY  - EJOU
AU  - Buchaillot, Ma. L.
AU  - Gracia-Romero, Adrian
AU  - Vergara-Diaz, Omar
AU  - Zaman-Allah, Mainassara A.
AU  - Tarekegne, Amsal
AU  - Cairns, Jill E.
AU  - Prasanna, Boddupalli M.
AU  - Araus, Jose L.
AU  - Kefauver, Shawn C.
TI  - Evaluating Maize Genotype Performance under Low Nitrogen Conditions Using RGB UAV Phenotyping Techniques
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 8
SN  - 1424-8220

AB  - Maize is the most cultivated cereal in Africa in terms of land area and production, but low soil nitrogen availability often constrains yields. Developing new maize varieties with high and reliable yields using traditional crop breeding techniques in field conditions can be slow and costly. Remote sensing has become an important tool in the modernization of field-based high-throughput plant phenotyping (HTPP), providing faster gains towards the improvement of yield potential and adaptation to abiotic and biotic limiting conditions. We evaluated the performance of a set of remote sensing indices derived from red&ndash;green&ndash;blue (RGB) images along with field-based multispectral normalized difference vegetation index (NDVI) and leaf chlorophyll content (SPAD values) as phenotypic traits for assessing maize performance under managed low-nitrogen conditions. HTPP measurements were conducted from the ground and from an unmanned aerial vehicle (UAV). For the ground-level RGB indices, the strongest correlations to yield were observed with hue, greener green area (GGA), and a newly developed RGB HTPP index, NDLab (normalized difference Commission Internationale de I&acute;Edairage (CIE)Lab index), while GGA and crop senescence index (CSI) correlated better with grain yield from the UAV. Regarding ground sensors, SPAD exhibited the closest correlation with grain yield, notably increasing in its correlation when measured in the vegetative stage. Additionally, we evaluated how different HTPP indices contributed to the explanation of yield in combination with agronomic data, such as anthesis silking interval (ASI), anthesis date (AD), and plant height (PH). Multivariate regression models, including RGB indices (R2 &gt; 0.60), outperformed other models using only agronomic parameters or field sensors (R2 &gt; 0.50), reinforcing RGB HTPP&rsquo;s potential to improve yield assessments. Finally, we compared the low-N results to the same panel of 64 maize genotypes grown under optimal conditions, noting that only 11% of the total genotypes appeared in the highest yield producing quartile for both trials. Furthermore, we calculated the grain yield loss index (GYLI) for each genotype, which showed a large range of variability, suggesting that low-N performance is not necessarily exclusive of high productivity in optimal conditions.
KW  - maize
KW  - nitrogen
KW  - phenotyping
KW  - remote sensing
KW  - Africa
KW  - RGB
KW  - UAV
KW  - CIELab
DO  - 10.3390/s19081815
ER  -
TY  - EJOU
AU  - Swinfield, Tom
AU  - Lindsell, Jeremy A.
AU  - Williams, Jonathan V.
AU  - Harrison, Rhett D.
AU  - Agustiono
AU  - Habibi
AU  - Gemita, Elva
AU  - Schönlieb, Carola B.
AU  - Coomes, David A.
TI  - Accurate Measurement of Tropical Forest Canopy Heights and Aboveground Carbon Using Structure From Motion
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 8
SN  - 2072-4292

AB  - Unmanned aerial vehicles are increasingly used to monitor forests. Three-dimensional models of tropical rainforest canopies can be constructed from overlapping photos using Structure from Motion (SfM), but it is often impossible to map the ground elevation directly from such data because canopy gaps are rare in rainforests. Without knowledge of the terrain elevation, it is, thus, difficult to accurately measure the canopy height or forest properties, including the recovery stage and aboveground carbon density. Working in an Indonesian ecosystem restoration landscape, we assessed how well SfM derived the estimates of the canopy height and aboveground carbon density compared with those from an airborne laser scanning (also known as LiDAR) benchmark. SfM systematically underestimated the canopy height with a mean bias of approximately 5 m. The linear models suggested that the bias increased quadratically with the top-of-canopy height for short, even-aged, stands but linearly for tall, structurally complex canopies (&gt;10 m). The predictions based on the simple linear model were closely correlated to the field-measured heights when the approach was applied to an independent survey in a different location (    R 2     = 67% and RMSE = 1.85 m), but a negative bias of 0.89 m remained, suggesting the need to refine the model parameters with additional training data. Models that included the metrics of canopy complexity were less biased but with a reduced     R 2    . The inclusion of ground control points (GCPs) was found to be important in accurately registering SfM measurements in space, which is essential if the survey requirement is to produce small-scale restoration interventions or to track changes through time. However, at the scale of several hectares, the top-of-canopy height and above-ground carbon density estimates from SfM and LiDAR were very similar even without GCPs. The ability to produce accurate top-of-canopy height and carbon stock measurements from SfM is game changing for forest managers and restoration practitioners, providing the means to make rapid, low-cost surveys over hundreds of hectares without the need for LiDAR.
KW  - UAV
KW  - structure from motion
KW  - tropical forest
KW  - canopy height
KW  - aboveground carbon
KW  - biomass
DO  - 10.3390/rs11080928
ER  -
TY  - EJOU
AU  - Nilwong, Sivapong
AU  - Hossain, Delowar
AU  - Kaneko, Shin-ichiro
AU  - Capi, Genci
TI  - Deep Learning-Based Landmark Detection for Mobile Robot Outdoor Localization
T2  - Machines

PY  - 2019
VL  - 7
IS  - 2
SN  - 2075-1702

AB  - Outdoor mobile robot applications generally implement Global Positioning Systems (GPS) for localization tasks. However, GPS accuracy in outdoor localization has less accuracy in different environmental conditions. This paper presents two outdoor localization methods based on deep learning and landmark detection. The first localization method is based on the Faster Regional-Convolutional Neural Network (Faster R-CNN) landmark detection in the captured image. Then, a feedforward neural network (FFNN) is trained to determine robot location coordinates and compass orientation from detected landmarks. The second localization employs a single convolutional neural network (CNN) to determine location and compass orientation from the whole image. The dataset consists of images, geolocation data and labeled bounding boxes to train and test two proposed localization methods. Results are illustrated with absolute errors from the comparisons between localization results and reference geolocation data in the dataset. The experimental results pointed both presented localization methods to be promising alternatives to GPS for outdoor localization.
KW  - outdoor localization
KW  - deep learning
KW  - landmark detection
KW  - Faster R-CNN
KW  - CNN
DO  - 10.3390/machines7020025
ER  -
TY  - EJOU
AU  - Habyarimana, Ephrem
AU  - Piccard, Isabelle
AU  - Catellani, Marcello
AU  - De Franceschi, Paolo
AU  - Dall’Agata, Michela
TI  - Towards Predictive Modeling of Sorghum Biomass Yields Using Fraction of Absorbed Photosynthetically Active Radiation Derived from Sentinel-2 Satellite Imagery and Supervised Machine Learning Techniques
T2  - Agronomy

PY  - 2019
VL  - 9
IS  - 4
SN  - 2073-4395

AB  - Sorghum crop is grown under tropical and temperate latitudes for several purposes including production of health promoting food from the kernel and forage and biofuels from aboveground biomass. One of the concerns of policy-makers and sorghum growers is to cost-effectively predict biomass yields early during the cropping season to improve biomass and biofuel management. The objective of this study was to investigate if Sentinel-2 satellite images could be used to predict within-season biomass sorghum yields in the Mediterranean region. Thirteen machine learning algorithms were tested on fortnightly Sentinel-2A and Sentinel-2B estimates of the fraction of Absorbed Photosynthetically Active Radiation (fAPAR) in combination with in situ aboveground biomass yields from demonstrative fields in Italy. A gradient boosting algorithm implementing the xgbtree method was the best predictive model as it was satisfactorily implemented anywhere from May to July. The best prediction time was the month of May followed by May&ndash;June and May&ndash;July. To the best of our knowledge, this work represents the first time Sentinel-2-derived fAPAR is used in sorghum biomass predictive modeling. The results from this study will help farmers improve their sorghum biomass business operations and policy-makers and extension services improve energy planning and avoid energy-related crises.
KW  - sorghum biomass
KW  - prediction modeling
KW  - machine learning
KW  - fAPAR
KW  - Sentinel-2 satellite imagery
KW  - big data technology
KW  - remote sensing
DO  - 10.3390/agronomy9040203
ER  -
TY  - EJOU
AU  - Guo, Yahui
AU  - Wu, Wenxiang
AU  - Du, Mingzhu
AU  - Bryant, Christopher R.
AU  - Li, Yong
AU  - Wang, Yuyi
AU  - Huang, Han
TI  - Assessing Potential Climate Change Impacts and Adaptive Measures on Rice Yields: The Case of Zhejiang Province in China
T2  - Sustainability

PY  - 2019
VL  - 11
IS  - 8
SN  - 2071-1050

AB  - Increasing temperatures, greater carbon dioxide concentrations, and changes in related climatic variables will continue to affect the growth and yields of agricultural crops. Rice (Oryza sativa L.) is extremely vulnerable to these climatic changes. Therefore, investigating the degree to which climate changes could influence rice yields and what effective adaptive strategies could be taken to mitigate the potential adverse impacts is of vital importance. In this article, the impacts of climate change on rice yields in Zhejiang province, China, were simulated under the Representative Concentration Pathway (RCP) 4.5 and 8.5 scenarios. The impacts of climate change, with and without CO2 fertilization effects, were evaluated and the three most effective adaptive measures were examined. Compared with the yield for the baseline time of 1981&ndash;2010, the simulated average yields of all cultivars were inevitably projected to decrease under both RCPs when the CO2 fertilization effects were not considered during the three periods of the 2020s (2011&ndash;2040), 2050s (2041&ndash;2070), and 2080s (2071&ndash;2099), respectively. Declines in rice yields were able to be alleviated when the CO2 fertilization effects were accounted for, but the yields were still lower than those of the baseline. Therefore, the three adaptive measures of advancing planting dates, switching to high-temperature-tolerant cultivars, and breeding new cultivars were simulated. The results indicated that adaptive measures could effectively mitigate the adverse effects of climate change. Although the simulation had uncertainties and limitations, the results provide useful insights into the potential impacts of climate change in Zhejiang province while also proposing adaptive measures.
KW  - Impact and adaptation simulation
KW  - climate change
KW  - CERES-Rice model
KW  - rice yield
DO  - 10.3390/su11082372
ER  -
TY  - EJOU
AU  - Barbedo, Jayme G.
TI  - A Review on the Use of Unmanned Aerial Vehicles and Imaging Sensors for Monitoring and Assessing Plant Stresses
T2  - Drones

PY  - 2019
VL  - 3
IS  - 2
SN  - 2504-446X

AB  - Unmanned aerial vehicles (UAVs) are becoming a valuable tool to collect data in a variety of contexts. Their use in agriculture is particularly suitable, as those areas are often vast, making ground scouting difficult, and sparsely populated, which means that injury and privacy risks are not as important as in urban settings. Indeed, the use of UAVs for monitoring and assessing crops, orchards, and forests has been growing steadily during the last decade, especially for the management of stresses such as water, diseases, nutrition deficiencies, and pests. This article presents a critical overview of the main advancements on the subject, focusing on the strategies that have been used to extract the information contained in the images captured during the flights. Based on the information found in more than 100 published articles and on our own research, a discussion is provided regarding the challenges that have already been overcome and the main research gaps that still remain, together with some suggestions for future research.
KW  - drone
KW  - UAV
KW  - UAS
KW  - precision agriculture
KW  - stress
KW  - crop
KW  - orchard
DO  - 10.3390/drones3020040
ER  -
TY  - EJOU
AU  - Xu, Jing
AU  - Dong, Jinhui
AU  - Li, Hongnan
AU  - Zhang, Chunwei
AU  - Ho, Siu C.
TI  - Looseness Monitoring of Bolted Spherical Joint Connection Using Electro-Mechanical Impedance Technique and BP Neural Networks
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 8
SN  - 1424-8220

AB  - The bolted spherical joint (BSJ) has wide applications in various space grid structures. The bar and the bolted sphere are connected by the high-strength bolt inside the joint. High-strength bolt is invisible outside the joint, which causes the difficulty in monitoring the bolt looseness. Moreover, the bolt looseness leads to the reduction of the local stiffness and bearing capacity for the structure. In this regard, this study used the electro-mechanical impedance (EMI) technique and back propagation neural networks (BPNNs) to monitor the bolt looseness inside the BSJ. Therefore, a space grid specimen having bolted spherical joints and tubular bars was considered for experimental evaluation. Different torques levels were applied on the sleeve to represent different looseness degrees of joint connection. As the torque levels increased, the looseness degrees of joint connection increased correspondingly. The lead zirconate titanate (PZT) patch was used and integrated with the tubular bar due to its strong piezoelectric effect. The root-mean-square deviation (RMSD) of the conductance signatures for the PZT patch were used as the looseness-monitoring indexes. Taking RMSD values of sub-frequency bands and the looseness degrees as inputs and outputs respectively, the BPNNs were trained and tested in twenty repeated experiments. The experimental results show that the formation of the bolt looseness can be detected according to the changes of looseness-monitoring indexes, and the degree of bolt looseness by the trained BPNNs. Overall, this research demonstrates that the proposed structural health monitoring (SHM) technique is feasible for monitoring the looseness of bolted spherical connection in space grid structures.
KW  - structural health monitoring (SHM)
KW  - space grid structures
KW  - electro-mechanical impedance (EMI)
KW  - back propagation neural networks (BPNNs)
KW  - bolted spherical joint (BSJ)
KW  - Bolt looseness damage
DO  - 10.3390/s19081906
ER  -
TY  - EJOU
AU  - Pham, Tien D.
AU  - Xia, Junshi
AU  - Ha, Nam T.
AU  - Bui, Dieu T.
AU  - Le, Nga N.
AU  - Tekeuchi, Wataru
TI  - A Review of Remote Sensing Approaches for Monitoring Blue Carbon Ecosystems: Mangroves, Seagrassesand Salt Marshes during 2010–2018
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 8
SN  - 1424-8220

AB  - Blue carbon (BC) ecosystems are an important coastal resource, as they provide a range of goods and services to the environment. They play a vital role in the global carbon cycle by reducing greenhouse gas emissions and mitigating the impacts of climate change. However, there has been a large reduction in the global BC ecosystems due to their conversion to agriculture and aquaculture, overexploitation, and removal for human settlements. Effectively monitoring BC ecosystems at large scales remains a challenge owing to practical difficulties in monitoring and the time-consuming field measurement approaches used. As a result, sensible policies and actions for the sustainability and conservation of BC ecosystems can be hard to implement. In this context, remote sensing provides a useful tool for mapping and monitoring BC ecosystems faster and at larger scales. Numerous studies have been carried out on various sensors based on optical imagery, synthetic aperture radar (SAR), light detection and ranging (LiDAR), aerial photographs (APs), and multispectral data. Remote sensing-based approaches have been proven effective for mapping and monitoring BC ecosystems by a large number of studies. However, to the best of our knowledge, this is the first comprehensive review on the applications of remote sensing techniques for mapping and monitoring BC ecosystems. The main goal of this review is to provide an overview and summary of the key studies undertaken from 2010 onwards on remote sensing applications for mapping and monitoring BC ecosystems. Our review showed that optical imagery, such as multispectral and hyper-spectral data, is the most common for mapping BC ecosystems, while the Landsat time-series are the most widely-used data for monitoring their changes on larger scales. We investigate the limitations of current studies and suggest several key aspects for future applications of remote sensing combined with state-of-the-art machine learning techniques for mapping coastal vegetation and monitoring their extents and changes.
KW  - coastal ecosystems
KW  - remote sensing
KW  - blue carbon
KW  - mangroves
KW  - seagrasses
KW  - salt marshes
DO  - 10.3390/s19081933
ER  -
TY  - EJOU
AU  - El Gmili, Nada
AU  - Mjahed, Mostafa
AU  - El Kari, Abdeljalil
AU  - Ayad, Hassan
TI  - Particle Swarm Optimization and Cuckoo Search-Based Approaches for Quadrotor Control and Trajectory Tracking
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 8
SN  - 2076-3417

AB  - This paper explores the full control of a quadrotor Unmanned Aerial Vehicles (UAVs) by exploiting the nature-inspired algorithms of Particle Swarm Optimization (PSO), Cuckoo Search (CS), and the cooperative Particle Swarm Optimization-Cuckoo Search (PSO-CS). The proposed PSO-CS algorithm combines the ability of social thinking in PSO with the local search capability in CS, which helps to overcome the problem of low convergence speed of CS. First, the quadrotor dynamic modeling is defined using Newton-Euler formalism. Second, PID (Proportional, Integral, and Derivative) controllers are optimized by using the intelligent proposed approaches and the classical method of Reference Model (RM) for quadrotor full control. Finally, simulation results prove that PSO and PSO-CS are more efficient in tuning of optimal parameters for the quadrotor control. Indeed, the ability of PSO and PSO-CS to track the imposed trajectories is well seen from 3D path tracking simulations and even in presence of wind disturbances.
KW  - control
KW  - quadrotor
KW  - nonlinear
KW  - PSO
KW  - particle swarm optimization
KW  - cuckoo search
DO  - 10.3390/app9081719
ER  -
TY  - EJOU
AU  - Carvajal-Ramírez, Fernando
AU  - Marques da Silva, José R.
AU  - Agüera-Vega, Francisco
AU  - Martínez-Carricondo, Patricio
AU  - Serrano, João
AU  - Moral, Francisco J.
TI  - Evaluation of Fire Severity Indices Based on Pre- and Post-Fire Multispectral Imagery Sensed from UAV
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - Fire severity is a key factor for management of post-fire vegetation regeneration strategies because it quantifies the impact of fire, describing the amount of damage. Several indices have been developed for estimation of fire severity based on terrestrial observation by satellite imagery. In order to avoid the implicit limitations of this kind of data, this work employed an Unmanned Aerial Vehicle (UAV) carrying a high-resolution multispectral sensor including green, red, near-infrared, and red edge bands. Flights were carried out pre- and post-controlled fire in a Mediterranean forest. The products obtained from the UAV-photogrammetric projects based on the Structure from Motion (SfM) algorithm were a Digital Surface Model (DSM) and multispectral images orthorectified in both periods and co-registered in the same absolute coordinate system to find the temporal differences (d) between pre- and post-fire values of the Excess Green Index (EGI), Normalized Difference Vegetation Index (NDVI), and Normalized Difference Red Edge (NDRE) index. The differences of indices (dEGI, dNDVI, and dNDRE) were reclassified into fire severity classes, which were compared with the reference data identified through the in situ fire damage location and Artificial Neural Network classification. Applying an error matrix analysis to the three difference of indices, the overall Kappa accuracies of the severity maps were 0.411, 0.563, and 0.211 and the Cramer&rsquo;s Value statistics were 0.411, 0.582, and 0.269 for dEGI, dNDVI, and dNDRE, respectively. The chi-square test, used to compare the average of each severity class, determined that there were no significant differences between the three severity maps, with a 95% confidence level. It was concluded that dNDVI was the index that best estimated the fire severity according to the UAV flight conditions and sensor specifications.
KW  - Fire Severity
KW  - UAV
KW  - Multispectral Imagery
DO  - 10.3390/rs11090993
ER  -
TY  - EJOU
AU  - Sun, Guibin
AU  - Zhou, Rui
AU  - Di, Bin
AU  - Dong, Zhuoning
AU  - Wang, Yingxun
TI  - A Novel Cooperative Path Planning for Multi-robot Persistent Coverage with Obstacles and Coverage Period Constraints
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 9
SN  - 1424-8220

AB  - In this paper, a multi-robot persistent coverage of the region of interest is considered, where persistent coverage and cooperative coverage are addressed simultaneously. Previous works have mainly concentrated on the paths that allow for repeated coverage, but ignored the coverage period requirements of each sub-region. In contrast, this paper presents a combinatorial approach for path planning, which aims to cover mission domains with different task periods while guaranteeing both obstacle avoidance and minimizing the number of robots used. The algorithm first deploys the sensors in the region to satisfy coverage requirements with minimum cost. Then it solves the travelling salesman problem to obtain the frame of the closed path. Finally, the approach partitions the closed path into the fewest segments under the coverage period constraints, and it generates the closed route for each robot on the basis of portioned segments of the closed path. Therefore, each robot can circumnavigate one closed route to cover the different task areas completely and persistently. The numerical simulations show that the proposed approach is feasible to implement the cooperative coverage in consideration of obstacles and coverage period constraints, and the number of robots used is also minimized.
KW  - multi-robot
KW  - cooperative coverage
KW  - persistent coverage
KW  - path planning
KW  - coverage period constraints
KW  - obstacle avoidance
DO  - 10.3390/s19091994
ER  -
TY  - EJOU
AU  - Li, Zhen
AU  - Zan, Qijie
AU  - Yang, Qiong
AU  - Zhu, Dehuang
AU  - Chen, Youjun
AU  - Yu, Shixiao
TI  - Remote Estimation of Mangrove Aboveground Carbon Stock at the Species Level Using a Low-Cost Unmanned Aerial Vehicle System
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - There is ongoing interest in developing remote sensing technology to map and monitor the spatial distribution and carbon stock of mangrove forests. Previous research has demonstrated that the relationship between remote sensing derived parameters and aboveground carbon (AGC) stock varies for different species types. However, the coarse spatial resolution of satellite images has restricted the estimated AGC accuracy, especially at the individual species level. Recently, the availability of unmanned aerial vehicles (UAVs) has provided an operationally efficient approach to map the distribution of species and accurately estimate AGC stock at a fine scale in mangrove areas. In this study, we estimated mangrove AGC in the core area of northern Shenzhen Bay, South China, using four kinds of variables, including species type, canopy height metrics, vegetation indices, and texture features, derived from a low-cost UAV system. Three machine-learning algorithm models, including Random Forest (RF), Support Vector Regression (SVR), and Artificial Neural Network (ANN), were compared in this study, where a 10-fold cross-validation was used to evaluate each model&rsquo;s effectiveness. The results showed that a model that used all four type of variables, which were based on the RF algorithm, provided better AGC estimates (R2 = 0.81, relative RMSE (rRMSE) = 0.20, relative MAE (rMAE) = 0.14). The average predicted AGC from this model was 93.0 &plusmn; 24.3 Mg C ha&minus;1, and the total estimated AGC was 7903.2 Mg for the mangrove forests. The species-based model had better performance than the considered canopy-height-based model for AGC estimation, and mangrove species was the most important variable among all the considered input variables; the mean height (Hmean) the second most important variable. Additionally, the RF algorithms showed better performance in terms of mangrove AGC estimation than the SVR and ANN algorithms. Overall, a low-cost UAV system with a digital camera has the potential to enable satisfactory predictions of AGC in areas of homogenous mangrove forests.
KW  - mangrove forests
KW  - aboveground carbon stocks (AGC)
KW  - Unmanned Aerial Vehicles (UAV)
KW  - high spatial resolution orthoimages
KW  - species type
KW  - canopy height model (CHM)
DO  - 10.3390/rs11091018
ER  -
TY  - EJOU
AU  - Quirós Vargas, Juan J.
AU  - Zhang, Chongyuan
AU  - Smitchger, Jamin A.
AU  - McGee, Rebecca J.
AU  - Sankaran, Sindhuja
TI  - Phenotyping of Plant Biomass and Performance Traits Using Remote Sensing Techniques in Pea (Pisum sativum, L.)
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 9
SN  - 1424-8220

AB  - Field pea cultivars are constantly improved through breeding programs to enhance biotic and abiotic stress tolerance and increase seed yield potential. In pea breeding, the Above Ground Biomass (AGBM) is assessed due to its influence on seed yield, canopy closure, and weed suppression. It is also the primary yield component for peas used as a cover crop and/or grazing. Measuring AGBM is destructive and labor-intensive process. Sensor-based phenotyping of such traits can greatly enhance crop breeding efficiency. In this research, high resolution RGB and multispectral images acquired with unmanned aerial systems were used to assess phenotypes in spring and winter pea breeding plots. The Green Red Vegetation Index (GRVI), Normalized Difference Vegetation Index (NDVI), Normalized Difference Red Edge Index (NDRE), plot volume, canopy height, and canopy coverage were extracted from RGB and multispectral information at five imaging times (between 365 to 1948 accumulated degree days/ADD after 1 May) in four winter field pea experiments and at three imaging times (between 1231 to 1648 ADD) in one spring field pea experiment. The image features were compared to ground-truth data including AGBM, lodging, leaf type, days to 50% flowering, days to physiological maturity, number of the first reproductive node, and seed yield. In two of the winter pea experiments, a strong correlation between image features and seed yield was observed at 1268 ADD (flowering). An increase in correlation between image features with the phenological traits such as days to 50% flowering and days to physiological maturity was observed at about 1725 ADD in these winter pea experiments. In the spring pea experiment, the plot volume estimated from images was highly correlated with ground truth canopy height (r = 0.83) at 1231 ADD. In two other winter pea experiments and the spring pea experiment, the GRVI and NDVI features were significantly correlated with AGBM at flowering. When selected image features were used to develop a least absolute shrinkage and selection operator model for AGBM estimation, the correlation coefficient between the actual and predicted AGBM was 0.60 and 0.84 in the winter and spring pea experiments, respectively. A SPOT-6 satellite image (1.5 m resolution) was also evaluated for its applicability to assess biomass and seed yield. The image features extracted from satellite imagery showed significant correlation with seed yield in two winter field pea experiments, however, the trend was not consistent. In summary, the study supports the potential of using unmanned aerial system-based imaging techniques to estimate biomass and crop performance in pea breeding programs.
KW  - crop monitoring
KW  - prediction model
KW  - satellite imagery
KW  - vegetation indices
KW  - crop surface model
DO  - 10.3390/s19092031
ER  -
TY  - EJOU
AU  - Li, Weijia
AU  - He, Conghui
AU  - Fu, Haohuan
AU  - Zheng, Juepeng
AU  - Dong, Runmin
AU  - Xia, Maocai
AU  - Yu, Le
AU  - Luk, Wayne
TI  - A Real-Time Tree Crown Detection Approach for Large-Scale Remote Sensing Images on FPGAs
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - The on-board real-time tree crown detection from high-resolution remote sensing images is beneficial for avoiding the delay between data acquisition and processing, reducing the quantity of data transmission from the satellite to the ground, monitoring the growing condition of individual trees, and discovering the damage of trees as early as possible, etc. Existing high performance platform based tree crown detection studies either focus on processing images in a small size or suffer from high power consumption or slow processing speed. In this paper, we propose the first FPGA-based real-time tree crown detection approach for large-scale satellite images. A pipelined-friendly and resource-economic tree crown detection algorithm (PF-TCD) is designed through reconstructing and modifying the workflow of the original algorithm into three computational kernels on FPGAs. Compared with the well-optimized software implementation of the original algorithm on an Intel 12-core CPU, our proposed PF-TCD obtains the speedup of 18.75 times for a satellite image with a size of 12,188 &times; 12,576 pixels without reducing the detection accuracy. The image processing time for the large-scale remote sensing image is only 0.33 s, which satisfies the requirements of the on-board real-time data processing on satellites.
KW  - tree crown detection
KW  - high-resolution satellite images
KW  - field-programmable gate array (FPGA)
KW  - real-time processing
DO  - 10.3390/rs11091025
ER  -
TY  - EJOU
AU  - Tyralis, Hristos
AU  - Papacharalampous, Georgia
AU  - Langousis, Andreas
TI  - A Brief Review of Random Forests for Water Scientists and Practitioners and Their Recent History in Water Resources
T2  - Water

PY  - 2019
VL  - 11
IS  - 5
SN  - 2073-4441

AB  - Random forests (RF) is a supervised machine learning algorithm, which has recently started to gain prominence in water resources applications. However, existing applications are generally restricted to the implementation of Breiman&rsquo;s original algorithm for regression and classification problems, while numerous developments could be also useful in solving diverse practical problems in the water sector. Here we popularize RF and their variants for the practicing water scientist, and discuss related concepts and techniques, which have received less attention from the water science and hydrologic communities. In doing so, we review RF applications in water resources, highlight the potential of the original algorithm and its variants, and assess the degree of RF exploitation in a diverse range of applications. Relevant implementations of random forests, as well as related concepts and techniques in the R programming language, are also covered.
KW  - classification
KW  - data-driven
KW  - hydrological modeling
KW  - hydrology
KW  - machine learning
KW  - prediction
KW  - quantile regression forests
KW  - supervised learning
KW  - variable importance metrics
DO  - 10.3390/w11050910
ER  -
TY  - EJOU
AU  - Dorafshan, Sattar
AU  - Thomas, Robert J.
AU  - Maguire, Marc
TI  - Benchmarking Image Processing Algorithms for Unmanned Aerial System-Assisted Crack Detection in Concrete Structures
T2  - Infrastructures

PY  - 2019
VL  - 4
IS  - 2
SN  - 2412-3811

AB  - This paper summarizes the results of traditional image processing algorithms for detection of defects in concrete using images taken by Unmanned Aerial Systems (UASs). Such algorithms are useful for improving the accuracy of crack detection during autonomous inspection of bridges and other structures, and they have yet to be compared and evaluated on a dataset of concrete images taken by UAS. The authors created a generic image processing algorithm for crack detection, which included the major steps of filter design, edge detection, image enhancement, and segmentation, designed to uniformly compare different edge detectors. Edge detection was carried out by six filters in the spatial (Roberts, Prewitt, Sobel, and Laplacian of Gaussian) and frequency (Butterworth and Gaussian) domains. These algorithms were applied to fifty images each of defected and sound concrete. Performances of the six filters were compared in terms of accuracy, precision, minimum detectable crack width, computational time, and noise-to-signal ratio. In general, frequency domain techniques were slower than spatial domain methods because of the computational intensity of the Fourier and inverse Fourier transformations used to move between spatial and frequency domains. Frequency domain methods also produced noisier images than spatial domain methods. Crack detection in the spatial domain using the Laplacian of Gaussian filter proved to be the fastest, most accurate, and most precise method, and it resulted in the finest detectable crack width. The Laplacian of Gaussian filter in spatial domain is recommended for future applications of real-time crack detection using UAS.
KW  - structural condition assessment
KW  - concrete structures
KW  - unmanned aerial systems
KW  - crack detection
KW  - image processing
KW  - noncontact methods
DO  - 10.3390/infrastructures4020019
ER  -
TY  - EJOU
AU  - He, Haiqing
AU  - Zhou, Junchao
AU  - Chen, Min
AU  - Chen, Ting
AU  - Li, Dajun
AU  - Cheng, Penggen
TI  - Building Extraction from UAV Images Jointly Using 6D-SLIC and Multiscale Siamese Convolutional Networks
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - Automatic building extraction using a single data type, either 2D remotely-sensed images or light detection and ranging 3D point clouds, remains insufficient to accurately delineate building outlines for automatic mapping, despite active research in this area and the significant progress which has been achieved in the past decade. This paper presents an effective approach to extracting buildings from Unmanned Aerial Vehicle (UAV) images through the incorporation of superpixel segmentation and semantic recognition. A framework for building extraction is constructed by jointly using an improved Simple Linear Iterative Clustering (SLIC) algorithm and Multiscale Siamese Convolutional Networks (MSCNs). The SLIC algorithm, improved by additionally imposing a digital surface model for superpixel segmentation, namely 6D-SLIC, is suited for building boundary detection under building and image backgrounds with similar radiometric signatures. The proposed MSCNs, including a feature learning network and a binary decision network, are used to automatically learn a multiscale hierarchical feature representation and detect building objects under various complex backgrounds. In addition, a gamma-transform green leaf index is proposed to truncate vegetation superpixels for further processing to improve the robustness and efficiency of building detection, the Douglas&ndash;Peucker algorithm and iterative optimization are used to eliminate jagged details generated from small structures as a result of superpixel segmentation. In the experiments, the UAV datasets, including many buildings in urban and rural areas with irregular shapes and different heights and that are obscured by trees, are collected to evaluate the proposed method. The experimental results based on the qualitative and quantitative measures confirm the effectiveness and high accuracy of the proposed framework relative to the digitized results. The proposed framework performs better than state-of-the-art building extraction methods, given its higher values of recall, precision, and intersection over Union (IoU).
KW  - building extraction
KW  - simple linear iterative clustering (SLIC)
KW  - multiscale Siamese convolutional networks (MSCNs)
KW  - binary decision network
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/rs11091040
ER  -
TY  - EJOU
AU  - Hakdaoui, Sofia
AU  - Emran, Anas
AU  - Pradhan, Biswajeet
AU  - Lee, Chang-Wook
AU  - Nguemhe Fils, Salomon C.
TI  - A Collaborative Change Detection Approach on Multi-Sensor Spatial Imagery for Desert Wetland Monitoring after a Flash Flood in Southern Morocco
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - This study aims to present a technique that combines multi-sensor spatial data to monitor wetland areas after a flash-flood event in a Saharan arid region. To extract the most efficient information, seven satellite images (radar and optical) taken before and after the event were used. To achieve the objectives, this study used Sentinel-1 data to discriminate water body and soil roughness, and optical data to monitor the soil moisture after the event. The proposed method combines two approaches: one based on spectral processing, and the other based on categorical processing. The first step was to extract four spectral indices and utilize change vector analysis on multispectral diachronic images from three MSI Sentinel-2 images and two Landsat-8 OLI images acquired before and after the event. The second step was performed using pattern classification techniques, namely, linear classifiers based on support vector machines (SVM) with Gaussian kernels. The results of these two approaches were fused to generate a collaborative wetland change map. The application of co-registration and supervised classification based on textural and intensity information from Radar Sentinel-1 images taken before and after the event completes this work. The results obtained demonstrate the importance of the complementarity of multi-sensor images and a multi-approach methodology to better monitor changes to a wetland area after a flash-flood disaster.
KW  - categorical processing
KW  - collaborative change detection
KW  - remote sensing
KW  - GIS
KW  - wet land monitoring
KW  - Morocco
DO  - 10.3390/rs11091042
ER  -
TY  - EJOU
AU  - Li, Zhiwei
AU  - Lu, Yu
AU  - Shi, Yun
AU  - Wang, Zengguang
AU  - Qiao, Wenxin
AU  - Liu, Yicen
TI  - A Dyna-Q-Based Solution for UAV Networks Against Smart Jamming Attacks
T2  - Symmetry

PY  - 2019
VL  - 11
IS  - 5
SN  - 2073-8994

AB  - Unmanned aerial vehicle (UAV) networks have a wide range of applications, such as in the Internet of Things (IoT), 5G communications, and so forth. However, the communications between UAVs and UAVs to ground control stations mainly use radio channels, and therefore these communications are vulnerable to cyberattacks. With the advent of software-defined radio (SDR), smart attacks that can flexibly select attack strategies according to the defender&rsquo;s state information are gradually attracting the attention of researchers and potential attackers of UAV networks. The smart attack can even induce the defender to take a specific defense strategy, causing even greater damage. Inspired by symmetrical thinking, a solution using a software-defined network (SDN) to combat software-defined radio was proposed. We propose a network architecture which uses dual controllers, including a UAV flight controller and SDN controller, to achieve collaborative decision-making. Built on the top of the SDN, the state information of the whole network converges quickly and is fitted to an environment model used to develop an improved Dyna-Q-based reinforcement learning algorithm. The improved algorithm integrates the power allocation and track planning of UAVs into a unified action space. The simulation data showed that the proposed communication solution can effectively avoid smart jamming attacks and has faster learning efficiency and higher convergence performance than the compared algorithms.
KW  - UAV networks
KW  - SDN
KW  - reinforcement learning
KW  - Dyna-Q
KW  - IoT
KW  - cyberattacks
DO  - 10.3390/sym11050617
ER  -
TY  - EJOU
AU  - Jia, Heming
AU  - Xing, Zhikai
AU  - Song, Wenlong
TI  - Three Dimensional Pulse Coupled Neural Network Based on Hybrid Optimization Algorithm for Oil Pollution Image Segmentation
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - This paper proposes a three dimensional pulse coupled neural network (3DPCNN) image segmentation method based on a hybrid seagull optimization algorithm (HSOA) to solve the oil pollution image. The image of oil pollution is taken by the unmanned aerial vehicle (UAV) in the oil field area. The UAV is good at shooting the ground area, but its ability to identify the oil pollution area is poor. In order to solve this problem, a 3DPCNN-HSOA algorithm is proposed to segment the oil pollution image, and the oil pollution area is segmented to identify the dirty oil area and improve the inspection of environmental pollution. The 3DPCNN image segmentation method has simple structure and good segmentation effect, but it has many parameters and poor segmentation effect for complex oil images. Therefore, we apply HSOA algorithm to optimize the parameters of 3DPCNN algorithm, so as to improve the segmentation accuracy and solve the segmentation of oil pollution images. The experimental results show that the 3DPCNN-HSOA model can separate the oil pollution area from the complex background.
KW  - oil pollution image segmentation
KW  - 3DPCNN
KW  - seagull optimization algorithm
KW  - thermal exchange optimization
DO  - 10.3390/rs11091046
ER  -
TY  - EJOU
AU  - Guimarães, Tainá T.
AU  - Veronez, Maurício R.
AU  - Koste, Emilie C.
AU  - Souza, Eniuce M.
AU  - Brum, Diego
AU  - Gonzaga, Luiz
AU  - Mauad, Frederico F.
TI  - Evaluation of Regression Analysis and Neural Networks to Predict Total Suspended Solids in Water Bodies from Unmanned Aerial Vehicle Images
T2  - Sustainability

PY  - 2019
VL  - 11
IS  - 9
SN  - 2071-1050

AB  - The concentration of suspended solids in water is one of the quality parameters that can be recovered using remote sensing data. This paper investigates the data obtained using a sensor coupled to an unmanned aerial vehicle (UAV) in order to estimate the concentration of suspended solids in a lake in southern Brazil based on the relation of spectral images and limnological data. The water samples underwent laboratory analysis to determine the concentration of total suspended solids (TSS). The images obtained using the UAV were orthorectified and georeferenced so that the values referring to the near, green, and blue infrared channels were collected at each sampling point to relate with the laboratory data. The prediction of the TSS concentration was performed using regression analysis and artificial neural networks. The obtained results were important for two main reasons. First, although regression methods have been used in remote sensing applications, they may not be adequate to capture the linear and/or non-linear relationships of interest. Second, results show that the integration of UAV in the mapping of water bodies together with the application of neural networks in the data analysis is a promising approach to predict TSS as well as their temporal and spatial variations.
KW  - suspended solids
KW  - unmanned aerial vehicle
KW  - spectral imaging
KW  - artificial neural networks
DO  - 10.3390/su11092580
ER  -
TY  - EJOU
AU  - Krenz, Juliane
AU  - Greenwood, Philip
AU  - Kuhn, Nikolaus J.
TI  - Soil Degradation Mapping in Drylands Using Unmanned Aerial Vehicle (UAV) Data
T2  - Soil Systems

PY  - 2019
VL  - 3
IS  - 2
SN  - 2571-8789

AB  - Arid and semi-arid landscapes often show a patchwork of bare and vegetated spaces. Their heterogeneous patterns can be of natural origin, but may also indicate soil degradation. This study investigates the use of unmanned aerial vehicle (UAV) imagery to identify the degradation status of soils, based on the hypothesis that vegetation cover can be used as a proxy for estimating the soils&rsquo; health status. To assess the quality of the UAV-derived products, we compare a conventional field-derived map (FM) with two modelled maps based on (i) vegetation cover (RGB map), and (ii) vegetation cover, topographic information, and a flow accumulation analysis (RGB+DEM map). All methods were able to identify areas of soil degradation but differed in the extent of classified soil degradation, with the RGB map classifying the least amount as degraded. The RGB+DEM map classified 12% more as degraded than the FM, due to the wider perspective of the UAV compared to conventional field mapping. Overall, conventional UAVs provide a valuable tool for soil mapping in heterogeneous landscapes where manual field sampling is very time consuming. Additionally, the UAVs&rsquo; planform view from a bird&rsquo;s-eye perspective can overcome the limited view from the surveyors&rsquo; (ground-based) vantage point.
KW  - erosion
KW  - landscape mapping
KW  - soil degradation
KW  - soil mapping
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/soilsystems3020033
ER  -
TY  - EJOU
AU  - Teng, Xichao
AU  - Yu, Qifeng
AU  - Luo, Jing
AU  - Wang, Gang
AU  - Zhang, Xiaohu
TI  - Aircraft Pose Estimation Based on Geometry Structure Features and Line Correspondences
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 9
SN  - 1424-8220

AB  - A robust and accurate aircraft pose estimation method is proposed in this paper. The aircraft pose reflects the flight status of the aircraft and accurate pose measurement is of great importance in many aerospace applications. This work aims to establish a universal framework to estimate the aircraft pose based on generic geometry structure features. In our method, line features are extracted to describe the structure of an aircraft in single images and the generic geometry features are exploited to form line groups for aircraft structure recognition. Parallel line clustering is utilized to detect the fuselage reference line and bilateral symmetry property of aircraft provides an important constraint for the extraction of wing edge lines under weak perspective projection. After identifying the main structure of the aircraft, a planes intersection method is used to obtain the 3D pose parameters based on the established line correspondences. Our proposed method can increase the measuring range of binocular vision sensors and has the advantage of not relying on 3D models, cooperative marks or other feature datasets. Experimental results show that our method can obtain reliable and accurate pose information of different types of aircraft.
KW  - aircraft pose estimation
KW  - wide-baseline image pairs
KW  - structure extraction
KW  - bilateral symmetry
KW  - weak perspective projection
KW  - vector analysis
KW  - line correspondences
DO  - 10.3390/s19092165
ER  -
TY  - EJOU
AU  - Rahnemoonfar, Maryam
AU  - Dobbs, Dugan
AU  - Yari, Masoud
AU  - Starek, Michael J.
TI  - DisCountNet: Discriminating and Counting Network for Real-Time Counting and Localization of Sparse Objects in High-Resolution UAV Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - Recent deep-learning counting techniques revolve around two distinct features of data&mdash;sparse data, which favors detection networks, or dense data where density map networks are used. Both techniques fail to address a third scenario, where dense objects are sparsely located. Raw aerial images represent sparse distributions of data in most situations. To address this issue, we propose a novel and exceedingly portable end-to-end model, DisCountNet, and an example dataset to test it on. DisCountNet is a two-stage network that uses theories from both detection and heat-map networks to provide a simple yet powerful design. The first stage, DiscNet, operates on the theory of coarse detection, but does so by converting a rich and high-resolution image into a sparse representation where only important information is encoded. Following this, CountNet operates on the dense regions of the sparse matrix to generate a density map, which provides fine locations and count predictions on densities of objects. Comparing the proposed network to current state-of-the-art networks, we find that we can maintain competitive performance while using a fraction of the computational complexity, resulting in a real-time solution.
KW  - deep learning
KW  - automatic counting
KW  - UAV
KW  - real-time
DO  - 10.3390/rs11091128
ER  -
TY  - EJOU
AU  - Petrellis, Nikos
TI  - Plant Disease Diagnosis for Smart Phone Applications with Extensible Set of Diseases
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 9
SN  - 2076-3417

AB  - A plant disease diagnosis method that can be implemented with the resources of a mobile phone application, that does not have to be connected to a remote server, is presented and evaluated on citrus diseases. It can be used both by amateur gardeners and by professional agriculturists for early detection of diseases. The features used are extracted from photographs of plant parts like leaves or fruits and include the color, the relative area and the number of the lesion spots. These classification features, along with additional information like weather metadata, form disease signatures that can be easily defined by the end user (e.g., an agronomist). These signatures are based on the statistical processing of a small number of representative training photographs. The extracted features of a test photograph are compared against the disease signatures in order to select the most likely disease. An important advantage of the proposed approach is that the diagnosis does not depend on the orientation, the scale or the resolution of the photograph. The experiments have been conducted under several light exposure conditions. The accuracy was experimentally measured between 70% and 99%. An acceptable accuracy higher than 90% can be achieved in most of the cases since the lesion spots can recognized interactively with high precision.
KW  - plant disease
KW  - smart phone application
KW  - image processing
KW  - classification
KW  - segmentation
KW  - citrus diseases
DO  - 10.3390/app9091952
ER  -
TY  - EJOU
AU  - Bejiga, Mesay B.
AU  - Melgani, Farid
AU  - Beraldini, Pietro
TI  - Domain Adversarial Neural Networks for Large-Scale Land Cover Classification
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 10
SN  - 2072-4292

AB  - Learning classification models require sufficiently labeled training samples, however, collecting labeled samples for every new problem is time-consuming and costly. An alternative approach is to transfer knowledge from one problem to another, which is called transfer learning. Domain adaptation (DA) is a type of transfer learning that aims to find a new latent space where the domain discrepancy between the source and the target domain is negligible. In this work, we propose an unsupervised DA technique called domain adversarial neural networks (DANNs), composed of a feature extractor, a class predictor, and domain classifier blocks, for large-scale land cover classification. Contrary to the traditional methods that perform representation and classifier learning in separate stages, DANNs combine them into a single stage, thereby learning a new representation of the input data that is both domain-invariant and discriminative. Once trained, the classifier of a DANN can be used to predict both source and target domain labels. Additionally, we also modify the domain classifier of a DANN to evaluate its suitability for multi-target domain adaptation problems. Experimental results obtained for both single and multiple target DA problems show that the proposed method provides a performance gain of up to 40%.
KW  - domain adaptation
KW  - domain adversarial neural networks
KW  - large-scale land cover classification
KW  - representation learning
DO  - 10.3390/rs11101153
ER  -
TY  - EJOU
AU  - Fuentes-Pacheco, Jorge
AU  - Torres-Olivares, Juan
AU  - Roman-Rangel, Edgar
AU  - Cervantes, Salvador
AU  - Juarez-Lopez, Porfirio
AU  - Hermosillo-Valadez, Jorge
AU  - Rendón-Mancha, Juan Manuel
TI  - Fig Plant Segmentation from Aerial Images Using a Deep Convolutional Encoder-Decoder Network
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 10
SN  - 2072-4292

AB  - Crop segmentation is an important task in Precision Agriculture, where the use of aerial robots with an on-board camera has contributed to the development of new solution alternatives. We address the problem of fig plant segmentation in top-view RGB (Red-Green-Blue) images of a crop grown under open-field difficult circumstances of complex lighting conditions and non-ideal crop maintenance practices defined by local farmers. We present a Convolutional Neural Network (CNN) with an encoder-decoder architecture that classifies each pixel as crop or non-crop using only raw colour images as input. Our approach achieves a mean accuracy of 93.85% despite the complexity of the background and a highly variable visual appearance of the leaves. We make available our CNN code to the research community, as well as the aerial image data set and a hand-made ground truth segmentation with pixel precision to facilitate the comparison among different algorithms.
KW  - convolutional neural network
KW  - crop segmentation
KW  - Ficus carica
KW  - unmanned aerial vehicles
DO  - 10.3390/rs11101157
ER  -
TY  - EJOU
AU  - Han, Jiaming
AU  - Yang, Zhong
AU  - Zhang, Qiuyan
AU  - Chen, Cong
AU  - Li, Hongchen
AU  - Lai, Shangxiang
AU  - Hu, Guoxiong
AU  - Xu, Changliang
AU  - Xu, Hao
AU  - Wang, Di
AU  - Chen, Rui
TI  - A Method of Insulator Faults Detection in Aerial Images for High-Voltage Transmission Lines Inspection
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 10
SN  - 2076-3417

AB  - Insulator faults detection is an important task for high-voltage transmission line inspection. However, current methods often suffer from the lack of accuracy and robustness. Moreover, these methods can only detect one fault in the insulator string, but cannot detect a multi-fault. In this paper, a novel method is proposed for insulator one fault and multi-fault detection in UAV-based aerial images, the backgrounds of which usually contain much complex interference. The shapes of the insulators also vary obviously due to the changes in filming angle and distance. To reduce the impact of complex interference on insulator faults detection, we make full use of the deep neural network to distinguish between insulators and background interference. First of all, plenty of insulator aerial images with manually labelled ground-truth are collected to construct a standard insulator detection dataset &lsquo;InST_detection&rsquo;. Secondly, a new convolutional network is proposed to obtain accurate insulator string positions in the aerial image. Finally, a novel fault detection method is proposed that can detect both insulator one fault and multi-fault in aerial images. Experimental results on a large number of aerial images show that our proposed method is more effective and efficient than the state-of-the-art insulator fault detection methods.
KW  - unmanned aerial vehicle
KW  - high-voltage transmission line inspection
KW  - aerial image
KW  - insulator fault detection
DO  - 10.3390/app9102009
ER  -
TY  - EJOU
AU  - Held, Philipp
AU  - Schneider von Deimling, Jens
TI  - New Feature Classes for Acoustic Habitat Mapping—A Multibeam Echosounder Point Cloud Analysis for Mapping Submerged Aquatic Vegetation (SAV)
T2  - Geosciences

PY  - 2019
VL  - 9
IS  - 5
SN  - 2076-3263

AB  - A new method for multibeam echosounder (MBES) data analysis is presented with the aim of improving habitat mapping, especially when considering submerged aquatic vegetation (SAV). MBES data were acquired with 400 kHz in 1&ndash;8 m water depth with a spatial resolution in the decimeter scale. The survey area was known to be populated with the seagrass Zostera marina and the bathymetric soundings were highly influenced by this habitat. The depth values often coincide with the canopy of the seagrass. Instead of classifying the data with a digital terrain model and the given derivatives, we derive predictive features from the native point cloud of the MBES soundings in a similar way to terrestrial LiDAR data analysis. We calculated the eigenvalues to derive nine characteristic features, which include linearity, planarity, and sphericity. The features were calculated for each sounding within a cylindrical neighborhood of 0.5 m radius and holding 88 neighboring soundings, on average, during our survey. The occurrence of seagrass was ground-truthed by divers and aerial photography. A data model was constructed and we applied a random forest machine learning supervised classification to predict between the two cases of &ldquo;seafloor&rdquo; and &ldquo;vegetation&rdquo;. Prediction by linearity, planarity, and sphericity resulted in 88.5% prediction accuracy. After constructing the higher-order eigenvalue derivatives and having the nine features available, the model resulted in 96% prediction accuracy. This study outlines for the first time that valuable feature classes can be derived from MBES point clouds&mdash;an approach that could substantially improve bathymetric measurements and habitat mapping.
KW  - habitat mapping
KW  - submerged aquatic vegetation
KW  - multibeam echosounder
KW  - point cloud
DO  - 10.3390/geosciences9050235
ER  -
TY  - EJOU
AU  - Li, Jing
AU  - Chen, Shuo
AU  - Zhang, Fangbing
AU  - Li, Erkang
AU  - Yang, Tao
AU  - Lu, Zhaoyang
TI  - An Adaptive Framework for Multi-Vehicle Ground Speed Estimation in Airborne Videos
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 10
SN  - 2072-4292

AB  - With the rapid development of unmanned aerial vehicles (UAVs), UAV-based intelligent airborne surveillance systems represented by real-time ground vehicle speed estimation have attracted wide attention from researchers. However, there are still many challenges in extracting speed information from UAV videos, including the dynamic moving background, small target size, complicated environment, and diverse scenes. In this paper, we propose a novel adaptive framework for multi-vehicle ground speed estimation in airborne videos. Firstly, we build a traffic dataset based on UAV. Then, we use the deep learning detection algorithm to detect the vehicle in the UAV field of view and obtain the trajectory in the image through the tracking-by-detection algorithm. Thereafter, we present a motion compensation method based on homography. This method obtains matching feature points by an optical flow method and eliminates the influence of the detected target to accurately calculate the homography matrix to determine the real motion trajectory in the current frame. Finally, vehicle speed is estimated based on the mapping relationship between the pixel distance and the actual distance. The method regards the actual size of the car as prior information and adaptively recovers the pixel scale by estimating the vehicle size in the image; it then calculates the vehicle speed. In order to evaluate the performance of the proposed system, we carry out a large number of experiments on the AirSim Simulation platform as well as real UAV aerial surveillance experiments. Through quantitative and qualitative analysis of the simulation results and real experiments, we verify that the proposed system has a unique ability to detect, track, and estimate the speed of ground vehicles simultaneously even with a single downward-looking camera. Additionally, the system can obtain effective and accurate speed estimation results, even in various complex scenes.
KW  - ground vehicle speed estimation
KW  - intelligent airborne video surveillance
KW  - unmanned aerial vehicle
KW  - object detection and tracking
KW  - motion compensation
DO  - 10.3390/rs11101241
ER  -
TY  - EJOU
AU  - Tan, Jin Y.
AU  - Ker, Pin J.
AU  - Lau, K. Y.
AU  - Hannan, M. A.
AU  - Tang, Shirley G.
TI  - Applications of Photonics in Agriculture Sector: A Review
T2  - Molecules

PY  - 2019
VL  - 24
IS  - 10
SN  - 1420-3049

AB  - The agricultural industry has made a tremendous contribution to the foundations of civilization. Basic essentials such as food, beverages, clothes and domestic materials are enriched by the agricultural industry. However, the traditional method in agriculture cultivation is labor-intensive and inadequate to meet the accelerating nature of human demands. This scenario raises the need to explore state-of-the-art crop cultivation and harvesting technologies. In this regard, optics and photonics technologies have proven to be effective solutions. This paper aims to present a comprehensive review of three photonic techniques, namely imaging, spectroscopy and spectral imaging, in a comparative manner for agriculture applications. Essentially, the spectral imaging technique is a robust solution which combines the benefits of both imaging and spectroscopy but faces the risk of underutilization. This review also comprehends the practicality of all three techniques by presenting existing examples in agricultural applications. Furthermore, the potential of these techniques is reviewed and critiqued by looking into agricultural activities involving palm oil, rubber, and agro-food crops. All the possible issues and challenges in implementing the photonic techniques in agriculture are given prominence with a few selective recommendations. The highlighted insights in this review will hopefully lead to an increased effort in the development of photonics applications for the future agricultural industry.
KW  - agriculture
KW  - photonics
KW  - imaging
KW  - spectral imaging
KW  - spectroscopy
DO  - 10.3390/molecules24102025
ER  -
TY  - EJOU
AU  - Wang, Mingwei
AU  - Gao, Lang
AU  - Huang, Xiaohui
AU  - Jiang, Ying
AU  - Gao, Xianjun
TI  - A Texture Classification Approach Based on the Integrated Optimization for Parameters and Features of Gabor Filter via Hybrid Ant Lion Optimizer
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 11
SN  - 2076-3417

AB  - Texture classification is an important topic for many applications in machine vision and image analysis, and Gabor filter is considered one of the most efficient tools for analyzing texture features at multiple orientations and scales. However, the parameter settings of each filter are crucial for obtaining accurate results, and they may not be adaptable to different kinds of texture features. Moreover, there is redundant information included in the process of texture feature extraction that contributes little to the classification. In this paper, a new texture classification technique is detailed. The approach is based on the integrated optimization of the parameters and features of Gabor filter, and obtaining satisfactory parameters and the best feature subset is viewed as a combinatorial optimization problem that can be solved by maximizing the objective function using hybrid ant lion optimizer (HALO). Experimental results, particularly fitness values, demonstrate that HALO is more effective than the other algorithms discussed in this paper, and the optimal parameters and features of Gabor filter are balanced between efficiency and accuracy. The method is feasible, reasonable, and can be utilized for practical applications of texture classification.
KW  - texture classification
KW  - Gabor filter
KW  - parameter optimization
KW  - feature selection
KW  - hybrid ant lion optimizer
DO  - 10.3390/app9112173
ER  -
TY  - EJOU
AU  - Wang, Hailu
AU  - Liu, Ning
AU  - Su, Zhong
AU  - Li, Qing
TI  - Research on Low-Cost Attitude Estimation for MINS/Dual-Antenna GNSS Integrated Navigation Method
T2  - Micromachines

PY  - 2019
VL  - 10
IS  - 6
SN  - 2072-666X

AB  - A high-precision navigation system is required for an unmanned vehicle, and the high-precision sensor is expensive. A low-cost, high-precision, dual-antenna Global Navigation Satellite System/Micro-electromechanical Systems-Inertial Navigation System (GNSS/MINS) combination method is proposed. The GNSS with dual antennas provides velocity, position, and attitude angle information as the measurement information is combined with the MINS. By increasing the heading angle, pitch angle, velocity, the accuracy of the integrated system is improved. The Extended Kalman Filtering (EKF) integrated algorithm simulation is designed to verify the feasibility and is realized based on the Field Programmable Gate Array and Advanced RISC Machine (ARM+FPGA) system. Static and dynamic tests were performed using the Synchronous Position, Attitude and Navigation (SPAN-CPT) as a reference system. The results show that the velocity, position, and attitude angle accuracy were improved. The yaw angle and pitch angle accuracy were 0.2&deg; Root Mean Square (RMS) and 0.3&deg; RMS, respectively. The method can be used as a navigation system for the unmanned vehicle.
KW  - Global Navigation Satellite System/Micro-electromechanical Systems-Inertial Navigation System (GNSS/MINS) integration
KW  - Low-cost
KW  - dual-antenna
KW  - Extended Kalman Filtering (EKF)
KW  - attitude
DO  - 10.3390/mi10060362
ER  -
TY  - EJOU
AU  - Andoga, Rudolf
AU  - Főző, Ladislav
AU  - Schrötter, Martin
AU  - Češkovič, Marek
AU  - Szabo, Stanislav
AU  - Bréda, Róbert
AU  - Schreiner, Michal
TI  - Intelligent Thermal Imaging-Based Diagnostics of Turbojet Engines
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 11
SN  - 2076-3417

AB  - There are only a few applications of infrared thermal imaging in aviation. In the area of turbojet engines, infrared imaging has been used to detect temperature field anomalies in order to identify structural defects in the materials of engine casings or other engine parts. In aviation applications, the evaluation of infrared images is usually performed manually by an expert. This paper deals with the design of an automatic intelligent system which evaluates the technical state and diagnoses a turbojet engine during its operation based on infrared thermal (IRT) images. A hybrid system interconnecting a self-organizing feature map and an expert system is designed for this purpose. A Kohonen neural network (the self-organizing feature map) is successfully applied to segment IRT images of a turbojet engine with high precision, and the expert system is then used to create diagnostic information from the segmented images. This paper represents a proof of concept of this hybrid system using data from a small iSTC-21v turbojet engine operating in laboratory conditions.
KW  - expert systems
KW  - infrared thermography
KW  - intelligent diagnostics
KW  - image segmentation
KW  - neural networks
KW  - thermal imaging camera
KW  - turbojet engines
DO  - 10.3390/app9112253
ER  -
TY  - EJOU
AU  - Li, Xingyu
AU  - Tang, Bo
AU  - Ball, John
AU  - Doude, Matthew
AU  - Carruth, Daniel W.
TI  - Rollover-Free Path Planning for Off-Road Autonomous Driving
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 6
SN  - 2079-9292

AB  - Perception, planning, and control are three enabling technologies to achieve autonomy in autonomous driving. In particular, planning provides vehicles with a safe and collision-free path towards their destinations, accounting for vehicle dynamics, maneuvering capabilities in the presence of obstacles, traffic rules, and road boundaries. Existing path planning algorithms can be divided into two stages: global planning and local planning. In the global planning stage, global routes and the vehicle states are determined from a digital map and the localization system. In the local planning stage, a local path can be achieved based on a global route and surrounding information obtained from sensors such as cameras and LiDARs. In this paper, we present a new local path planning method, which incorporates a vehicle&rsquo;s time-to-rollover model for off-road autonomous driving on different road profiles for a given predefined global route. The proposed local path planning algorithm uses a 3D occupancy grid and generates a series of 3D path candidates in the s-p coordinate system. The optimal path is then selected considering the total cost of safety, including obstacle avoidance, vehicle rollover prevention, and comfortability in terms of path smoothness and continuity with road unevenness. The simulation results demonstrate the effectiveness of the proposed path planning method for various types of roads, indicating its wide practical applications to off-road autonomous driving.
KW  - off-road autonomous driving
KW  - real-time path planning
KW  - vehicle rollover model
KW  - obstacle avoidance
DO  - 10.3390/electronics8060614
ER  -
TY  - EJOU
AU  - Wang, Dongliang
AU  - Shao, Quanqin
AU  - Yue, Huanyin
TI  - Surveying Wild Animals from Satellites, Manned Aircraft and Unmanned Aerial Systems (UASs): A Review
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - This article reviews studies regarding wild animal surveys based on multiple platforms, including satellites, manned aircraft, and unmanned aircraft systems (UASs), and focuses on the data used, animal detection methods, and their accuracies. We also discuss the advantages and limitations of each type of remote sensing data and highlight some new research opportunities and challenges. Submeter very-high-resolution (VHR) spaceborne imagery has potential in modeling the population dynamics of large (&gt;0.6 m) wild animals at large spatial and temporal scales, but has difficulty discerning small (&lt;0.6 m) animals at the species level, although high-resolution commercial satellites, such as WorldView-3 and -4, have been able to collect images with a ground resolution of up to 0.31 m in panchromatic mode. This situation will not change unless the satellite image resolution is greatly improved in the future. Manned aerial surveys have long been employed to capture the centimeter-scale images required for animal censuses over large areas. However, such aerial surveys are costly to implement in small areas and can cause significant disturbances to wild animals because of their noise. In contrast, UAS surveys are seen as a safe, convenient and less expensive alternative to ground-based and conventional manned aerial surveys, but most UASs can cover only small areas. The proposed use of UAS imagery in combination with VHR satellite imagery would produce critical population data for large wild animal species and colonies over large areas. The development of software systems for automatically producing image mosaics and recognizing wild animals will further improve survey efficiency.
KW  - very-high-resolution satellites
KW  - unmanned aircraft systems
KW  - wild animal surveys
KW  - remote sensing
DO  - 10.3390/rs11111308
ER  -
TY  - EJOU
AU  - Zhao, Rui
AU  - Shi, Zhenwei
AU  - Zou, Zhengxia
AU  - Zhang, Zhou
TI  - Ensemble-Based Cascaded Constrained Energy Minimization for Hyperspectral Target Detection
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - Ensemble learning is an important group of machine learning techniques that aim to enhance the nonlinearity and generalization ability of a learning system by aggregating multiple learners. We found that ensemble techniques show great potential for improving the performance of traditional hyperspectral target detection algorithms, while at present, there are few previous works have been done on this topic. To this end, we propose an Ensemble based Constrained Energy Minimization (E-CEM) detector for hyperspectral image target detection. Classical hyperspectral image target detection algorithms like Constrained Energy Minimization (CEM), matched filter (MF) and adaptive coherence/cosine estimator (ACE) are usually designed based on constrained least square regression methods or hypothesis testing methods with Gaussian distribution assumption. However, remote sensing hyperspectral data captured in a real-world environment usually shows strong nonlinearity and non-Gaussianity, which will lead to performance degradation of these classical detection algorithms. Although some hierarchical detection models are able to learn strong nonlinear discrimination of spectral data, due to the spectrum changes, these models usually suffer from the instability in detection tasks. The proposed E-CEM is designed based on the classical CEM detection algorithm. To improve both of the detection nonlinearity and generalization ability, the strategies of &ldquo;cascaded detection&rdquo;, &ldquo;random averaging&rdquo; and &ldquo;multi-scale scanning&rdquo; are specifically designed. Experiments on one synthetic hyperspectral image and two real hyperspectral images demonstrate the effectiveness of our method. E-CEM outperforms the traditional CEM detector and other state-of-the-art detection algorithms. Our code will be made publicly available.
KW  - hyperspectral image
KW  - target detection
KW  - constrained energy minimization
KW  - cascaded detection
KW  - ensemble
KW  - multi-scale scanning
DO  - 10.3390/rs11111310
ER  -
TY  - EJOU
AU  - Chen, Shichao
AU  - Liu, Ming
AU  - Lu, Fugang
AU  - Xing, Mengdao
TI  - A Target Identification Method for the Millimeter Wave Seeker via Correlation Matching and Beam Pointing
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 11
SN  - 1424-8220

AB  - Target identification is a challenging task under land backgrounds for the millimeter wave (MMW) seeker, especially under complex backgrounds. Focusing on the problem, an effective method combining correlation matching and beam pointing is proposed in this paper. In the beginning, seeker scanning for target detection is conducted in two rounds, and target information of the detected targets is stored for correlation matching. Point or body feature judgment is implemented by using high resolution range profile (HRRP). Then, the error distribution zone is constructed with the beam pointing as the origin. In the end, we identify the target by searching the one which lies in the closest error distribution from the beam pointing center. The effectiveness of the proposed method is verified by using mooring test-fly and real flight data.
KW  - target identification
KW  - correlation matching
KW  - beam pointing
KW  - millimeter wave (MMW) seeker
DO  - 10.3390/s19112530
ER  -
TY  - EJOU
AU  - Sothe, Camile
AU  - Dalponte, Michele
AU  - Almeida, Cláudia M.
AU  - Schimalski, Marcos B.
AU  - Lima, Carla L.
AU  - Liesenberg, Veraldo
AU  - Miyoshi, Gabriela T.
AU  - Tommaselli, Antonio M.
TI  - Tree Species Classification in a Highly Diverse Subtropical Forest Integrating UAV-Based Photogrammetric Point Cloud and Hyperspectral Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - The use of remote sensing data for tree species classification in tropical forests is still a challenging task, due to their high floristic and spectral diversity. In this sense, novel sensors on board of unmanned aerial vehicle (UAV) platforms are a rapidly evolving technology that provides new possibilities for tropical tree species mapping. Besides the acquisition of high spatial and spectral resolution images, UAV-hyperspectral cameras operating in frame format enable to produce 3D hyperspectral point clouds. This study investigated the use of UAV-acquired hyperspectral images and UAV-photogrammetric point cloud (PPC) for classification of 12 major tree species in a subtropical forest fragment in Southern Brazil. Different datasets containing hyperspectral visible/near-infrared (VNIR) bands, PPC features, canopy height model (CHM), and other features extracted from hyperspectral data (i.e., texture, vegetation indices-VIs, and minimum noise fraction-MNF) were tested using a support vector machine (SVM) classifier. The results showed that the use of VNIR hyperspectral bands alone reached an overall accuracy (OA) of 57% (Kappa index of 0.53). Adding PPC features to the VNIR hyperspectral bands increased the OA by 11%. The best result was achieved combining VNIR bands, PPC features, CHM, and VIs (OA of 72.4% and Kappa index of 0.70). When only the CHM was added to VNIR bands, the OA increased by 4.2%. Among the hyperspectral features, besides all the VNIR bands and the two VIs (NDVI and PSSR), the first four MNF features and the textural mean of 565 and 679 nm spectral bands were pointed out as more important to discriminate the tree species according to Jeffries&ndash;Matusita (JM) distance. The SVM method proved to be a good classifier for the tree species recognition task, even in the presence of a high number of classes and a small dataset.
KW  - tree species mapping
KW  - tropical biodiversity
KW  - imaging spectroscopy
KW  - photogrammetry
KW  - support vector machine
DO  - 10.3390/rs11111338
ER  -
TY  - EJOU
AU  - Yue, Rui
AU  - Xu, Hao
AU  - Wu, Jianqing
AU  - Sun, Renjuan
AU  - Yuan, Changwei
TI  - Data Registration with Ground Points for Roadside LiDAR Sensors
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - The Light Detection and Ranging (LiDAR) sensors are being considered as new traffic infrastructure sensors to detect road users&rsquo; trajectories for connected/autonomous vehicles and other traffic engineering applications. A LiDAR-enhanced traffic infrastructure system requires multiple LiDAR sensors around intersections, along with road segments, which can provide a seamless detection range at intersections or along arterials. Each LiDAR sensor generates cloud points of surrounding objects in a local coordinate system with the sensor at the origin, so it is necessary to integrate multiple roadside LiDAR sensors&rsquo; data into the same coordinate system. None of existing methods can integrate the data from roadside LiDAR sensors, because the extensive detection range of roadside sensors generates low-density cloud points and the alignment of roadside sensors is different from mapping scans or autonomous sensing systems. This paper presents a method to register datasets from multiple roadside LiDAR sensors. This approach innovatively integrates LiDAR datasets with 3D cloud points of road surface and 2D reference point features, so the method is abbreviated as RGP (Registration with Ground and Points). The RGP method applies optimization algorithms to identify the optimized linear coordinate transformation. This research considered the genetic algorithm (global optimization) and the hill climbing algorithm (local optimization). The performance of the RGP method and the different optimization algorithms was evaluated with field LiDAR sensors data. When the developed process can integrate data from roadside sensors, it can also register LiDAR sensors&rsquo; data on an autonomous vehicle or a robot.
KW  - data registration
KW  - Smart Traffic Infrastructure
KW  - ground points
KW  - optimization
DO  - 10.3390/rs11111354
ER  -

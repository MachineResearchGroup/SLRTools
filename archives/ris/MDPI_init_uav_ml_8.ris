TY  - EJOU
AU  - Madeira, Tiago
AU  - Oliveira, Miguel
AU  - Dias, Paulo
TI  - Enhancement of RGB-D Image Alignment Using Fiducial Markers
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 5
SN  - 1424-8220

AB  - Three-dimensional (3D) reconstruction methods generate a 3D textured model from the combination of data from several captures. As such, the geometrical transformations between these captures are required. The process of computing or refining these transformations is referred to as alignment. It is often a difficult problem to handle, in particular due to a lack of accuracy in the matching of features. We propose an optimization framework that takes advantage of fiducial markers placed in the scene. Since these markers are robustly detected, the problem of incorrect matching of features is overcome. The proposed procedure is capable of enhancing the 3D models created using consumer level RGB-D hand-held cameras, reducing visual artefacts caused by misalignments. One problem inherent to this solution is that the scene is polluted by the markers. Therefore, a tool was developed to allow their removal from the texture of the scene. Results show that our optimization framework is able to significantly reduce alignment errors between captures, which results in visually appealing reconstructions. Furthermore, the markers used to enhance the alignment are seamlessly removed from the final model texture.
KW  - computer vision
KW  - geometric optimization
KW  - camera calibration
KW  - 3D reconstruction
KW  - texture
KW  - inpainting
KW  - fiducial markers
KW  - point clouds
KW  - projection of 3D points
DO  - 10.3390/s20051497
TY  - EJOU
AU  - Zhang, Qian
AU  - Liu, Yeqi
AU  - Gong, Chuanyang
AU  - Chen, Yingyi
AU  - Yu, Huihui
TI  - Applications of Deep Learning for Dense Scenes Analysis in Agriculture: A Review
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 5
SN  - 1424-8220

AB  - Deep Learning (DL) is the state-of-the-art machine learning technology, which shows superior performance in computer vision, bioinformatics, natural language processing, and other areas. Especially as a modern image processing technology, DL has been successfully applied in various tasks, such as object detection, semantic segmentation, and scene analysis. However, with the increase of dense scenes in reality, due to severe occlusions, and small size of objects, the analysis of dense scenes becomes particularly challenging. To overcome these problems, DL recently has been increasingly applied to dense scenes and has begun to be used in dense agricultural scenes. The purpose of this review is to explore the applications of DL for dense scenes analysis in agriculture. In order to better elaborate the topic, we first describe the types of dense scenes in agriculture, as well as the challenges. Next, we introduce various popular deep neural networks used in these dense scenes. Then, the applications of these structures in various agricultural tasks are comprehensively introduced in this review, including recognition and classification, detection, counting and yield estimation. Finally, the surveyed DL applications, limitations and the future work for analysis of dense images in agriculture are summarized.
KW  - deep learning
KW  - dense scenes
KW  - agricultural application
KW  - computer vision
DO  - 10.3390/s20051520
TY  - EJOU
AU  - Sigala, Alberto
AU  - Langhals, Brent
TI  - Applications of Unmanned Aerial Systems (UAS): A Delphi Study Projecting Future UAS Missions and Relevant Challenges
T2  - Drones

PY  - 2020
VL  - 4
IS  - 1
SN  - 2504-446X

AB  - Over recent decades, the world has experienced a growing demand for and reliance upon unmanned aerial systems (UAS) to perform a broad spectrum of applications to include military operations such as surveillance/reconnaissance and strike/attack. As UAS technology matures and capabilities expand, especially with respect to increased autonomy, acquisition professionals and operational decision makers must determine how best to incorporate advanced capabilities into existing and emerging mission areas. This research seeks to predict which autonomous UAS capabilities are most likely to emerge over the next 20 years as well as the key challenges for implementation for each capability. Employing the Delphi method and relying on subject matter experts from operations, acquisitions and academia, future autonomous UAS mission areas and the corresponding level of autonomy are forecasted. The study finds consensus for a broad range of increased UAS capabilities with ever increasing levels of autonomy, but found the most promising areas for research and development to include intelligence, surveillance, and reconnaissance (ISR) mission areas and sense and avoid and data link technologies.
KW  - Unmanned Aerial Systems (UAS), autonomy
KW  - Delphi Study
KW  - challenges
KW  - future military applications
KW  - Data-Driven Decision-Making (DDDM)
DO  - 10.3390/drones4010008
TY  - EJOU
AU  - Zhao, Dan
AU  - Pang, Yong
AU  - Liu, Lijuan
AU  - Li, Zengyuan
TI  - Individual Tree Classification Using Airborne LiDAR and Hyperspectral Data in a Natural Mixed Forest of Northeast China
T2  - Forests

PY  - 2020
VL  - 11
IS  - 3
SN  - 1999-4907

AB  - This paper proposes a method to classify individual tree species groups based on individual tree segmentation and crown-level spectrum extraction (&ldquo;crown-based ITC&rdquo; for abbr.) in a natural mixed forest of Northeast China, and compares with the pixel-based classification and segment summarization results (&ldquo;pixel-based ITC&rdquo; for abbr.). Tree species is a basic factor in forest management, and it is traditionally identified by field survey. This paper aims to explore the potential of individual tree classification in a natural, needle-leaved and broadleaved mixed forest. First, individual trees were isolated, and the spectra of individual trees were then extracted. The support vector machine (SVM) and spectrum angle mapper (SAM) classifiers were applied to classify the trees species. The pixel-based classification results from hyperspectral data and LiDAR derived individual tree isolation were compared. The results showed that the crown-based ITC classified broadleaved trees better than pixel-based ITC, while the classes distribution of the crown-based ITC was closer to the survey data. This indicated that crown-based ITC performed better than pixel-based ITC. Crown-based ITC efficiently identified the classes of the dominant and sub-dominant species. Regardless of whether SVM or SAM was used, the identification consistency relative to the field observations for the class of the dominant species was greater than 90%. In contrast, the consistencies of the classes of the sub-dominant species were approximately 60%, and the overall consistency of both the SVM and SAM was greater than 70%.
KW  - individual tree classification
KW  - LiDAR
KW  - hyperspectral
KW  - SVM
KW  - natural forest
DO  - 10.3390/f11030303
TY  - EJOU
AU  - Osco, Lucas P.
AU  - Ramos, Ana P.
AU  - Faita Pinheiro, Mayara M.
AU  - Moriya, Érika A.
AU  - Imai, Nilton N.
AU  - Estrabis, Nayara
AU  - Ianczyk, Felipe
AU  - Araújo, Fábio F.
AU  - Liesenberg, Veraldo
AU  - Jorge, Lúcio A.
AU  - Li, Jonathan
AU  - Ma, Lingfei
AU  - Gonçalves, Wesley N.
AU  - Marcato Junior, José
AU  - Eduardo Creste, José
TI  - A Machine Learning Framework to Predict Nutrient Content in Valencia-Orange Leaf Hyperspectral Measurements
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - This paper presents a framework based on machine learning algorithms to predict nutrient content in leaf hyperspectral measurements. This is the first approach to evaluate macro- and micronutrient content with both machine learning and reflectance/first-derivative data. For this, citrus-leaves collected at a Valencia-orange orchard were used. Their spectral data was measured with a Fieldspec ASD FieldSpec&reg; HandHeld 2 spectroradiometer and the surface reflectance and first-derivative spectra from the spectral range of 380 to 1020 nm (640 spectral bands) was evaluated. A total of 320 spectral signatures were collected, and the leaf-nutrient content (N, P, K, Mg, S, Cu, Fe, Mn, and Zn) was associated with them. For this, 204,800 (320 &times; 640) combinations were used. The following machine learning algorithms were used in this framework: k-Nearest Neighbor (kNN), Lasso Regression, Ridge Regression, Support Vector Machine (SVM), Artificial Neural Network (ANN), Decision Tree (DT), and Random Forest (RF). The training methods were assessed based on Cross-Validation and Leave-One-Out. The Relief-F metric of the algorithms&rsquo; prediction was used to determine the most contributive wavelength or spectral region associated with each nutrient. This approach was able to return, with high predictions (R2), nutrients like N (0.912), Mg (0.832), Cu (0.861), Mn (0.898), and Zn (0.855), and, to a lesser extent, P (0.771), K (0.763), and S (0.727). These accuracies were obtained with different algorithms, but RF was the most suitable to model most of them. The results indicate that, for the Valencia-orange leaves, surface reflectance data is more suitable to predict macronutrients, while first-derivative spectra is better linked to micronutrients. A final contribution of this study is the identification of the wavelengths responsible for contributing to these predictions.
KW  - spectroscopy
KW  - proximal sensor
KW  - macronutrient
KW  - micronutrient
KW  - artificial intelligence
DO  - 10.3390/rs12060906
TY  - EJOU
AU  - Pereira-Pires, João E.
AU  - Aubard, Valentine
AU  - Ribeiro, Rita A.
AU  - Fonseca, José M.
AU  - Silva, João M. N.
AU  - Mora, André
TI  - Semi-Automatic Methodology for Fire Break Maintenance Operations Detection with Sentinel-2 Imagery and Artificial Neural Network
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - The difficult job of fighting fires and the nearly impossible task to stop a wildfire without great casualties requires an imperative implementation of proactive strategies. These strategies must decrease the number of fires, the burnt area and create better conditions for the firefighting. In this line of action, the Portuguese Institute of Nature and Forest Conservation defined a fire break network (FBN), which helps controlling wildfires. However, these fire breaks are efficient only if they are correctly maintained, which should be ensured by the local authorities and requires verification from the national authorities. This is a fastidious task since they have a large network of thousands of hectares to monitor over a full year. With the increasing quality and frequency of the Earth Observation Satellite imagery with Sentinel-2 and the definition of the FBN, a semi-automatic remote sensing methodology is proposed in this article for the detection of maintenance operations in a fire break. The proposed methodology is based on a time-series analysis, an object-based classification and a change detection process. The change detection is ensured by an artificial neural network, with reflectance bands and spectral indices as features. Additionally, an analysis of several bands and spectral indices is presented to show the behaviour of the data during a full year and in the presence of a maintenance operation. The proposed methodology achieved a relative error lower than 4% and a recall higher than 75% on the detection of maintenance operations.
KW  - remote sensing
KW  - fire break
KW  - object-based classification
KW  - change detection
KW  - wildfires
KW  - artificial neural networks
KW  - sentinel-2
DO  - 10.3390/rs12060909
TY  - EJOU
AU  - Hu, Qiong
AU  - Yang, Jingya
AU  - Xu, Baodong
AU  - Huang, Jianxi
AU  - Memon, Muhammad S.
AU  - Yin, Gaofei
AU  - Zeng, Yelu
AU  - Zhao, Jing
AU  - Liu, Ke
TI  - Evaluation of Global Decametric-Resolution LAI, FAPAR and FVC Estimates Derived from Sentinel-2 Imagery
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - Global biophysical products at decametric resolution derived from Sentinel-2 imagery have emerged as a promising dataset for fine-scale ecosystem modeling and agricultural monitoring. Evaluating uncertainties of different Sentinel-2 biophysical products over various regions and vegetation types is pivotal in the application of land surface models. In this study, we quantified the performance of Sentinel-2-derived Leaf Area Index (LAI), Fraction of Absorbed Photosynthetically Active Radiation (FAPAR), and Fractional Vegetation Cover (FVC) estimates using global ground observations with consistent measurement criteria. Our results show that the accuracy of vegetation and non-vegetated classification based on Sentinel-2 surface reflectance products is greater than 95%, which indicates the vegetation identification is favorable for the practical application of biophysical estimates, as several LAI, FAPAR, and FVC retrievals were derived for non-vegetated pixels. The rate of best retrievals is similar between LAI and FAPAR estimates, both accounting for 87% of all vegetation pixels, while it is almost 100% for FVC estimates. Additionally, the Sentinel-2 FAPAR and FVC estimates agree well with ground-measurements-derived (GMD) reference maps, whereas a large discrepancy is observed for Sentinel-2 LAI estimates by comparing with both GMD effective LAI (LAIe) and actual LAI (LAI) reference maps. Furthermore, the uncertainties of Sentinel-2 LAI, FAPAR and FVC estimates are 1.09 m2/m2, 1.14 m2/m2, 0.13 and 0.17 through comparisons to ground LAIe, LAI, FAPAR, and FVC measurements, respectively. Given the temporal difference between Sentinel-2 observations and ground measurements, Sentinel-2 LAI estimates are more consistent with LAIe than LAI values. The robustness of evaluation results can be further improved as long as more multi-temporal ground measurements across different regions are obtained. Overall, this study provides fundamental information about the performance of Sentinel-2 LAI, FAPAR, and FVC estimates, which imbues our confidence in the broad applications of these decametric products.
KW  - leaf area index (LAI)
KW  - fraction of absorbed photosynthetically active radiation (FAPAR)
KW  - fractional vegetation cover (FVC)
KW  - Sentinel-2
KW  - Evaluation
KW  - Uncertainty
DO  - 10.3390/rs12060912
TY  - EJOU
AU  - Meiforth, Jane J.
AU  - Buddenbaum, Henning
AU  - Hill, Joachim
AU  - Shepherd, James
TI  - Monitoring of Canopy Stress Symptoms in New Zealand Kauri Trees Analysed with AISA Hyperspectral Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - The endemic New Zealand kauri trees (Agathis australis) are under threat by the deadly kauri dieback disease (Phytophthora agathidicida (PA)). This study aimed to identify spectral index combinations for characterising visible stress symptoms in the kauri canopy. The analysis is based on an aerial AISA hyperspectral image mosaic and 1258 reference crowns in three study sites in the Waitakere Ranges west of Auckland. A field-based assessment scheme for canopy stress symptoms (classes 1&ndash;5) was further optimised for use with RGB aerial images. A combination of four indices with six bands in the spectral range 450&ndash;1205 nm resulted in a correlation of 0.93 (mean absolute error 0.27, RMSE 0.48) for all crown sizes. Comparable results were achieved with five indices in the 450&ndash;970 nm region. A Random Forest (RF) regression gave the most accurate predictions while a M5P regression tree performed nearly as well and a linear regression resulted in slightly lower correlations. Normalised Difference Vegetation Indices (NDVI) in the near-infrared / red spectral range were the most important index combinations, followed by indices with bands in the near-infrared spectral range from 800 to 1205 nm. A test on different crown sizes revealed that stress symptoms in smaller crowns with denser foliage are best described in combination with pigment-sensitive indices that include bands in the green and blue spectral range. A stratified approach with individual models for pre-segmented low and high forest stands improved the overall performance. The regression models were also tested in a pixel-based analysis. A manual interpretation of the resulting raster map with stress symptom patterns observed in aerial imagery indicated a good match. With bandwidths of 10 nm and a maximum number of six bands, the selected index combinations can be used for large-area monitoring on an airborne multispectral sensor. This study establishes the base for a cost-efficient, objective monitoring method for stress symptoms in kauri canopies, suitable to cover large forest areas with an airborne multispectral sensor.
KW  - hyperspectral
KW  - forest health
KW  - random forest
KW  - AISA Fenix
KW  - Waitakere ranges
KW  - New Zealand
KW  - kauri dieback disease
KW  - Phytophthora agathidicida
DO  - 10.3390/rs12060926
TY  - EJOU
AU  - Smith, Chaya
AU  - Karunaratne, Senani
AU  - Badenhorst, Pieter
AU  - Cogan, Noel
AU  - Spangenberg, German
AU  - Smith, Kevin
TI  - Machine Learning Algorithms to Predict Forage Nutritive Value of In Situ Perennial Ryegrass Plants Using Hyperspectral Canopy Reflectance Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - Nutritive value (NV) of forage is too time consuming and expensive to measure routinely in targeted breeding programs. Non-destructive spectroscopy has the potential to quickly and cheaply measure NV but requires an intermediate modelling step to interpret the spectral data. A novel machine learning technique for forage analysis, Cubist, was used to analyse canopy spectra to predict seven NV parameters, including dry matter (DM), acid detergent fibre (ADF), ash, neutral detergent fibre (NDF), in vivo dry matter digestibility (IVDMD), water soluble carbohydrates (WSC), and crude protein (CP). Perennial ryegrass (Lolium perenne) was used as the test crop. Independent validation of the developed models revealed prediction capabilities with R2 values and Lin&rsquo;s concordance values reported between 0.49 and 0.82, and 0.68 and 0.89, respectively. Informative wavelengths for the creation of predictive models were identified for the seven NV parameters. These wavelengths included regions of the electromagnetic spectrum that are usually excluded due to high background variation, however, they contain important information and utilising them to obtain meaningful signals within the background variation is an advantage for accurate models. Non-destructive field spectroscopy along with the predictive models was deployed infield to measure NV of individual ryegrass plants. A significant reduction in labour was observed. The associated increase in speed and reduction of cost makes targeting NV in commercial breeding programs now feasible.
KW  - data mining
KW  - forage
KW  - high through-put phenotyping
KW  - near infrared spectroscopy
KW  - non-destructive sampling
KW  - predictive models
KW  - lolium perenne
DO  - 10.3390/rs12060928
TY  - EJOU
AU  - Gaffey, Clare
AU  - Bhardwaj, Anshuman
TI  - Applications of Unmanned Aerial Vehicles in Cryosphere: Latest Advances and Prospects
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - Owing to usual logistic hardships related to field-based cryospheric research, remote sensing has played a significant role in understanding the frozen components of the Earth system. Conventional spaceborne or airborne remote sensing platforms have their own merits and limitations. Unmanned aerial vehicles (UAVs) have emerged as a viable and inexpensive option for studying the cryospheric components at unprecedented spatiotemporal resolutions. UAVs are adaptable to various cryospheric research needs in terms of providing flexibility with data acquisition windows, revisits, data/sensor types (multispectral, hyperspectral, microwave, thermal/night imaging, Light Detection and Ranging (LiDAR), and photogrammetric stereos), viewing angles, flying altitudes, and overlap dimensions. Thus, UAVs have the potential to act as a bridging remote sensing platform between spatially discrete in situ observations and spatially continuous but coarser and costlier spaceborne or conventional airborne remote sensing. In recent years, a number of studies using UAVs for cryospheric research have been published. However, a holistic review discussing the methodological advancements, hardware and software improvements, results, and future prospects of such cryospheric studies is completely missing. In the present scenario of rapidly changing global and regional climate, studying cryospheric changes using UAVs is bound to gain further momentum and future studies will benefit from a balanced review on this topic. Our review covers the most recent applications of UAVs within glaciology, snow, permafrost, and polar research to support the continued development of high-resolution investigations of cryosphere. We also analyze the UAV and sensor hardware, and data acquisition and processing software in terms of popularity for cryospheric applications and revisit the existing UAV flying regulations in cold regions of the world. The recent usage of UAVs outlined in 103 case studies provide expertise that future investigators should base decisions on.
KW  - UAV
KW  - unmanned aerial systems (UAS)
KW  - drone
KW  - cryosphere
KW  - arctic
KW  - polar
KW  - remote sensing
DO  - 10.3390/rs12060948
TY  - EJOU
AU  - Dong, Luofan
AU  - Du, Huaqiang
AU  - Han, Ning
AU  - Li, Xuejian
AU  - Zhu, Di’en
AU  - Mao, Fangjie
AU  - Zhang, Meng
AU  - Zheng, Junlong
AU  - Liu, Hua
AU  - Huang, Zihao
AU  - He, Shaobai
TI  - Application of Convolutional Neural Network on Lei Bamboo Above-Ground-Biomass (AGB) Estimation Using Worldview-2
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - Above-ground biomass (AGB) directly relates to the productivity of forests. Precisely, AGB mapping for regional forests based on very high resolution (VHR) imagery is widely needed for evaluation of productivity. However, the diversity of variables and algorithms and the difficulties inherent in high resolution optical imagery make it complex. In this paper, we explored the potentials of the state-of-art algorithm convolutional neural networks (CNNs), which are widely used for its high-level representation, but rarely applied for AGB estimation. Four experiments were carried out to compare the performance of CNNs and other state-of-art Machine Learning (ML) algorithms: (1) performance of CNN using bands, (2) performance of Random Forest (RF), support vector regression (SVR), artificial neural network (ANN) on bands, and vegetation indices (VIs). (3) Performance of RF, SVR, and ANN on gray-level co-occurrence matrices (GLCM), and exploratory spatial data analysis (ESDA), and (4) performance of RF, SVR, and ANN based on all combined data and ESDA+VIs. CNNs reached satisfactory results (with R2 = 0.943) even with limited input variables (i.e., only bands). In comparison, RF and SVR with elaborately designed data obtained slightly better accuracy than CNN. For examples, RF based on GLCM textures reached an R2 of 0.979 and RF based on all combined data reached a close R2 of 0.974. However, the results of ANN were much worse (with the best R2 of 0.885).
KW  - deep learning (DL)
KW  - machine learning (ML)
KW  - above ground biomass (AGB)
KW  - very high-resolution imagery
KW  - textures
DO  - 10.3390/rs12060958
TY  - EJOU
AU  - Pashaei, Mohammad
AU  - Kamangir, Hamid
AU  - Starek, Michael J.
AU  - Tissot, Philippe
TI  - Review and Evaluation of Deep Learning Architectures for Efficient Land Cover Mapping with UAS Hyper-Spatial Imagery: A Case Study Over a Wetland
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - Deep learning has already been proved as a powerful state-of-the-art technique for many image understanding tasks in computer vision and other applications including remote sensing (RS) image analysis. Unmanned aircraft systems (UASs) offer a viable and economical alternative to a conventional sensor and platform for acquiring high spatial and high temporal resolution data with high operational flexibility. Coastal wetlands are among some of the most challenging and complex ecosystems for land cover prediction and mapping tasks because land cover targets often show high intra-class and low inter-class variances. In recent years, several deep convolutional neural network (CNN) architectures have been proposed for pixel-wise image labeling, commonly called semantic image segmentation. In this paper, some of the more recent deep CNN architectures proposed for semantic image segmentation are reviewed, and each model&rsquo;s training efficiency and classification performance are evaluated by training it on a limited labeled image set. Training samples are provided using the hyper-spatial resolution UAS imagery over a wetland area and the required ground truth images are prepared by manual image labeling. Experimental results demonstrate that deep CNNs have a great potential for accurate land cover prediction task using UAS hyper-spatial resolution images. Some simple deep learning architectures perform comparable or even better than complex and very deep architectures with remarkably fewer training epochs. This performance is especially valuable when limited training samples are available, which is a common case in most RS applications.
KW  - coastal wetland
KW  - land cover mapping
KW  - semantic image segmentation
KW  - machine learning
KW  - deep learning
KW  - convolutional neural networks
KW  - transfer learning
KW  - unmanned aircraft systems
DO  - 10.3390/rs12060959
TY  - EJOU
AU  - Liu, Changyu
AU  - Huang, Xiaodong
AU  - Li, Xubing
AU  - Liang, Tiangang
TI  - MODIS Fractional Snow Cover Mapping Using Machine Learning Technology in a Mountainous Area
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - To improve the poor accuracy of the MODIS (Moderate Resolution Imaging Spectroradiometer) daily fractional snow cover product over the complex terrain of the Tibetan Plateau (RMSE = 0.30), unmanned aerial vehicle and machine learning technologies are employed to map the fractional snow cover based on MODIS over this terrain. Three machine learning models, including random forest, support vector machine, and back-propagation artificial neural network models, are trained and compared in this study. The results indicate that compared with the MODIS daily fractional snow cover product, the introduction of a highly accurate snow map acquired by unmanned aerial vehicles as a reference into machine learning models can significantly improve the MODIS fractional snow cover mapping accuracy. The random forest model shows the best accuracy among the three machine learning models, with an RMSE (root-mean-square error) of 0.23, especially over forestland and shrubland, with RMSEs of 0.13 and 0.18, respectively. Although the accuracy of the support vector machine and back-propagation artificial neural network models are worse over forestland and shrubland, their average errors are still better than that of MOD10A1. Different fractional snow cover gradients also affect the accuracy of the machine learning algorithms. Nevertheless, the random forest model remains stable in different fractional snow cover gradients and is, therefore, the best machine learning algorithm for MODIS fractional snow cover mapping in Tibetan Plateau areas with complex terrain and severely fragmented snow cover.
KW  - MODIS
KW  - fractinal snow cover
KW  - UAV
KW  - Tibetan Plateau
DO  - 10.3390/rs12060962
TY  - EJOU
AU  - Bosman, Lisa B.
AU  - Leon-Salas, Walter D.
AU  - Hutzel, William
AU  - Soto, Esteban A.
TI  - PV System Predictive Maintenance: Challenges, Current Approaches, and Opportunities
T2  - Energies

PY  - 2020
VL  - 13
IS  - 6
SN  - 1996-1073

AB  - Within the United States solar energy industry, there is a general motto of &ldquo;set it and forget it&rdquo; with solar energy. This notion is derived from much of the research and reliability studies around the photovoltaic (PV) panels themselves, not necessarily the PV system as a whole (including the inverter and other components). This implies that maintenance and regular monitoring is not needed. Yet many things can go wrong to cause the actual performance to deviate from the expected performance. If failures and/or unanticipated degradation issues go undetected, they will lead to reduced energy generation (and associated electricity credits) and/or potential loss of component warranty because of manufacturer turnover. Given the size of the problem and gaps with current solutions, the authors propose that PV system owners need an unbiased third-party off-the-shelf system-level predictive maintenance tool to optimize return-on-investment and minimize time to warranty claim in PV installations. This paper reviews the literature highlighting challenges, current approaches, and opportunities for PV predictive maintenance. The paper concludes with a call to action for establishing a collaborative agenda toward prioritizing PV predictive maintenance.
KW  - solar energy
KW  - system-level
KW  - degradation
KW  - ROI
KW  - quality assurance
KW  - responsive
KW  - third party evaluation
KW  - net-metering
KW  - grid-tied
KW  - optimization
DO  - 10.3390/en13061398
TY  - EJOU
AU  - Mohd Noor, Norzailawati
AU  - Ibrahim, Illyani
AU  - Abdullah, Alias
AU  - Abdullah, Ahmad A.
TI  - Information Fusion for Cultural Heritage Three-Dimensional Modeling of Malay Cities
T2  - ISPRS International Journal of Geo-Information

PY  - 2020
VL  - 9
IS  - 3
SN  - 2220-9964

AB  - Malaysia&rsquo;s heritage structures are facing challenges due to rapid local development and societal challenges that threaten their cultural and artistic values. Improving conservation approaches in this context is an urgent and crucial task. The application of geo-information technologies in laser scanning, photogrammetry, and geographic information systems (GISs) has significantly improved these conservation approaches. In this study, we fused drone images and range data from a laser scanner to construct a high-resolution three-dimensional GIS city model for one traditional Malay settlement located in Malaysia. The results showed that fusing photogrammetry and laser scanning can effectively capture the architectural uniqueness of Malay buildings, including specific fa&ccedil;ade geometries on walls, roofs, and motifs. The findings show that the development of various geoinformation approaches can assist with the conservation of Malay city heritage in this region.
KW  - UAV
KW  - mobile laser scanner
KW  - Malay city heritage
KW  - 3D GIS modeling
KW  - Geoinformation
DO  - 10.3390/ijgi9030177
TY  - EJOU
AU  - Kuffer, Monika
AU  - Thomson, Dana R.
AU  - Boo, Gianluca
AU  - Mahabir, Ron
AU  - Grippa, Taïs
AU  - Vanhuysse, Sabine
AU  - Engstrom, Ryan
AU  - Ndugwa, Robert
AU  - Makau, Jack
AU  - Darin, Edith
AU  - de Albuquerque, João P.
AU  - Kabaria, Caroline
TI  - The Role of Earth Observation in an Integrated Deprived Area Mapping “System” for Low-to-Middle Income Countries
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - Urbanization in the global South has been accompanied by the proliferation of vast informal and marginalized urban areas that lack access to essential services and infrastructure. UN-Habitat estimates that close to a billion people currently live in these deprived and informal urban settlements, generally grouped under the term of urban slums. Two major knowledge gaps undermine the efforts to monitor progress towards the corresponding sustainable development goal (i.e., SDG 11&mdash;Sustainable Cities and Communities). First, the data available for cities worldwide is patchy and insufficient to differentiate between the diversity of urban areas with respect to their access to essential services and their specific infrastructure needs. Second, existing approaches used to map deprived areas (i.e., aggregated household data, Earth observation (EO), and community-driven data collection) are mostly siloed, and, individually, they often lack transferability and scalability and fail to include the opinions of different interest groups. In particular, EO-based-deprived area mapping approaches are mostly top-down, with very little attention given to ground information and interaction with urban communities and stakeholders. Existing top-down methods should be complemented with bottom-up approaches to produce routinely updated, accurate, and timely deprived area maps. In this review, we first assess the strengths and limitations of existing deprived area mapping methods. We then propose an Integrated Deprived Area Mapping System (IDeAMapS) framework that leverages the strengths of EO- and community-based approaches. The proposed framework offers a way forward to map deprived areas globally, routinely, and with maximum accuracy to support SDG 11 monitoring and the needs of different interest groups.
KW  - deprived areas
KW  - slums
KW  - informal settlement
KW  - machine learning
KW  - urban remote sensing
DO  - 10.3390/rs12060982
TY  - EJOU
AU  - Mandlburger, Gottfried
AU  - Pfennigbauer, Martin
AU  - Schwarz, Roland
AU  - Flöry, Sebastian
AU  - Nussbaumer, Lukas
TI  - Concept and Performance Evaluation of a Novel UAV-Borne Topo-Bathymetric LiDAR Sensor
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - We present the sensor concept and first performance and accuracy assessment results of a novel lightweight topo-bathymetric laser scanner designed for integration on Unmanned Aerial Vehicles (UAVs), light aircraft, and helicopters. The instrument is particularly well suited for capturing river bathymetry in high spatial resolution as a consequence of (i) the low nominal flying altitude of 50&ndash;150 m above ground level resulting in a laser footprint diameter on the ground of typically 10&ndash;30 cm and (ii) the high pulse repetition rate of up to 200 kHz yielding a point density on the ground of approximately 20&ndash;50 points/m2. The instrument features online waveform processing and additionally stores the full waveform within the entire range gate for waveform analysis in post-processing. The sensor was tested in a real-world environment by acquiring data from two freshwater ponds and a 500 m section of the pre-Alpine Pielach River (Lower Austria). The captured underwater points featured a maximum penetration of two times the Secchi depth. On dry land, the 3D point clouds exhibited (i) a measurement noise in the range of 1&ndash;3 mm; (ii) a fitting precision of redundantly captured flight strips of 1 cm; and (iii) an absolute accuracy of 2&ndash;3 cm compared to terrestrially surveyed checkerboard targets. A comparison of the refraction corrected LiDAR point cloud with independent underwater checkpoints exhibited a maximum deviation of 7.8 cm and revealed a systematic depth-dependent error when using a refraction coefficient of n = 1.36 for time-of-flight correction. The bias is attributed to multi-path effects in the turbid water column (Secchi depth: 1.1 m) caused by forward scattering of the laser signal at suspended particles. Due to the high spatial resolution, good depth performance, and accuracy, the sensor shows a high potential for applications in hydrology, fluvial morphology, and hydraulic engineering, including flood simulation, sediment transport modeling, and habitat mapping.
KW  - UAV LiDAR
KW  - airborne laser bathymetry
KW  - full waveform processing
KW  - performance assessment
KW  - high resolution hydro-mapping
DO  - 10.3390/rs12060986
TY  - EJOU
AU  - Itakura, Kenta
AU  - Hosoi, Fumiki
TI  - Automatic Tree Detection from Three-Dimensional Images Reconstructed from 360° Spherical Camera Using YOLO v2
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - It is important to grasp the number and location of trees, and measure tree structure attributes, such as tree trunk diameter and height. The accurate measurement of these parameters will lead to efficient forest resource utilization, maintenance of trees in urban cities, and feasible afforestation planning in the future. Recently, light detection and ranging (LiDAR) has been receiving considerable attention, compared with conventional manual measurement techniques. However, it is difficult to use LiDAR for widespread applications, mainly because of the costs. We propose a method for tree measurement using 360&deg; spherical cameras, which takes omnidirectional images. For the structural measurement, the three-dimensional (3D) images were reconstructed using a photogrammetric approach called structure from motion. Moreover, an automatic tree detection method from the 3D images was presented. First, the trees included in the 360&deg; spherical images were detected using YOLO v2. Then, these trees were detected with the tree information obtained from the 3D images reconstructed using structure from motion algorithm. As a result, the trunk diameter and height could be accurately estimated from the 3D images. The tree detection model had an F-measure value of 0.94. This method could automatically estimate some of the structural parameters of trees and contribute to more efficient tree measurement.
KW  - automatic detection
KW  - deep learning
KW  - machine learning
KW  - spherical camera
KW  - structure from motion
KW  - three-dimensional (3D)
KW  - tree trunk diameter
KW  - tree height
KW  - YOLO
KW  - 360-degree camera
DO  - 10.3390/rs12060988
TY  - EJOU
AU  - Lei, Guangbin
AU  - Li, Ainong
AU  - Bian, Jinhu
AU  - Yan, He
AU  - Zhang, Lulu
AU  - Zhang, Zhengjian
AU  - Nan, Xi
TI  - OIC-MCE: A Practical Land Cover Mapping Approach for Limited Samples Based on Multiple Classifier Ensemble and Iterative Classification
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - Land cover samples are usually the foundation for supervised classification. Unfortunately, for land cover mapping in large areas, only limited samples can be used due to the time-consuming and labor-intensive sample collection. A novel and practical Object-oriented Iterative Classification method based on Multiple Classifiers Ensemble (OIC-MCE) was proposed in this paper. It systematically integrated object-oriented segmentation, Multiple Classifier Ensemble (MCE), and Iterative Classification (IC). In this method, the initial training samples were updated self-adaptively during the iterative processes. Based on these updated training samples, the inconsistent regions (ICR) in the classification results of the MCE method were reclassified to reduce their uncertainty. Three typical case studies in the China-Pakistan Economic Corridor (CPEC) indicate that the overall accuracy of the OIC-MCE method is significantly higher than that of the single classifier. After five iterations, the overall accuracy of the OIC-MCE approach increased by 5.58%&ndash;8.38% compared to the accuracy of the traditional MCE method. The spatial distribution of newly added training samples generated by the OIC-MCE approach was relatively uniform. It was confirmed by ten repeated experiments that the OIC-MCE approach has good stability. More importantly, even if the initial sample size reduced by 65%, the quality of the final classification result based on the proposed OIC-MCE approach would not be greatly affected. Therefore, the proposed OIC-MCE approach provides a new solution for land cover mapping with limited samples. Certainly, it is also well suited for land cover mapping with abundant samples.
KW  - land cover mapping
KW  - multiple classifier ensemble (MCE)
KW  - iterative classification (IC)
KW  - self-adaptive updating of samples
KW  - China-Pakistan economic corridor (CPEC)
KW  - remote sensing
DO  - 10.3390/rs12060987
TY  - EJOU
AU  - Deng, Dan
AU  - Li, Xingwang
AU  - Zhao, Ming
AU  - Rabie, Khaled M.
AU  - Kharel, Rupak
TI  - Deep Learning-Based Secure MIMO Communications with Imperfect CSI for Heterogeneous Networks
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 6
SN  - 1424-8220

AB  - Perfect channel state information (CSI) is required in most of the classical physical-layer security techniques, while it is difficult to obtain the ideal CSI due to the time-varying wireless fading channel. Although imperfect CSI has a great impact on the security of MIMO communications, deep learning is becoming a promising solution to handle the negative effect of imperfect CSI. In this work, we propose two types of deep learning-based secure MIMO detectors for heterogeneous networks, where the macro base station (BS) chooses the null-space eigenvectors to prevent information leakage to the femto BS. Thus, the bit error rate of the associated user is adopted as the metric to evaluate the system performance. With the help of deep convolutional neural networks (CNNs), the macro BS obtains the refined version from the imperfect CSI. Simulation results are provided to validate the proposed algorithms. The impacts of system parameters, such as the correlation factor of imperfect CSI, the normalized doppler frequency, the number of antennas is investigated in different setup scenarios. The results show that considerable performance gains can be obtained from the deep learning-based detectors compared with the classical maximum likelihood algorithm.
KW  - physical-layer security
KW  - deep learning
KW  - imperfect CSI
KW  - heterogeneous networks
KW  - channel estimation
DO  - 10.3390/s20061730
TY  - EJOU
AU  - Tomaszewski, Michał
AU  - Michalski, Paweł
AU  - Osuchowski, Jakub
TI  - Evaluation of Power Insulator Detection Efficiency with the Use of Limited Training Dataset
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 6
SN  - 2076-3417

AB  - This article presents an analysis of the effectiveness of object detection in digital images with the application of a limited quantity of input. The possibility of using a limited set of learning data was achieved by developing a detailed scenario of the task, which strictly defined the conditions of detector operation in the considered case of a convolutional neural network. The described solution utilizes known architectures of deep neural networks in the process of learning and object detection. The article presents comparisons of results from detecting the most popular deep neural networks while maintaining a limited training set composed of a specific number of selected images from diagnostic video. The analyzed input material was recorded during an inspection flight conducted along high-voltage lines. The object detector was built for a power insulator. The main contribution of the presented papier is the evidence that a limited training set (in our case, just 60 training frames) could be used for object detection, assuming an outdoor scenario with low variability of environmental conditions. The decision of which network will generate the best result for such a limited training set is not a trivial task. Conducted research suggests that the deep neural networks will achieve different levels of effectiveness depending on the amount of training data. The most beneficial results were obtained for two convolutional neural networks: the faster region-convolutional neural network (faster R-CNN) and the region-based fully convolutional network (R-FCN). Faster R-CNN reached the highest AP (average precision) at a level of 0.8 for 60 frames. The R-FCN model gained a worse AP result; however, it can be noted that the relationship between the number of input samples and the obtained results has a significantly lower influence than in the case of other CNN models, which, in the authors&rsquo; assessment, is a desired feature in the case of a limited training set.
KW  - convolutional neural network
KW  - deep neural network
KW  - insulator detection
KW  - efficiency evaluation
KW  - power system maintenance
DO  - 10.3390/app10062104
TY  - EJOU
AU  - Tmušić, Goran
AU  - Manfreda, Salvatore
AU  - Aasen, Helge
AU  - James, Mike R.
AU  - Gonçalves, Gil
AU  - Ben-Dor, Eyal
AU  - Brook, Anna
AU  - Polinova, Maria
AU  - Arranz, Jose J.
AU  - Mészáros, János
AU  - Zhuang, Ruodan
AU  - Johansen, Kasper
AU  - Malbeteau, Yoann
AU  - de Lima, Isabel P.
AU  - Davids, Corine
AU  - Herban, Sorin
AU  - McCabe, Matthew F.
TI  - Current Practices in UAS-based Environmental Monitoring
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - With the increasing role that unmanned aerial systems (UAS) are playing in data collection for environmental studies, two key challenges relate to harmonizing and providing standardized guidance for data collection, and also establishing protocols that are applicable across a broad range of environments and conditions. In this context, a network of scientists are cooperating within the framework of the Harmonious Project to develop and promote harmonized mapping strategies and disseminate operational guidance to ensure best practice for data collection and interpretation. The culmination of these efforts is summarized in the present manuscript. Through this synthesis study, we identify the many interdependencies of each step in the collection and processing chain, and outline approaches to formalize and ensure a successful workflow and product development. Given the number of environmental conditions, constraints, and variables that could possibly be explored from UAS platforms, it is impractical to provide protocols that can be applied universally under all scenarios. However, it is possible to collate and systematically order the fragmented knowledge on UAS collection and analysis to identify the best practices that can best ensure the streamlined and rigorous development of scientific products.
KW  - UAS-based mapping
KW  - environmental monitoring
KW  - effective workflow
KW  - guidelines
DO  - 10.3390/rs12061001
TY  - EJOU
AU  - Shan, Liang
AU  - Huang, Huiyun
AU  - Hong, Bo
AU  - Zhao, Jun
AU  - Wang, Daodang
AU  - Kong, Ming
TI  - Temperature Measurement Method of Flame Image Fusion with Different Exposures
T2  - Energies

PY  - 2020
VL  - 13
IS  - 6
SN  - 1996-1073

AB  - Fixed exposure will lead to underexposure or overexposure of collected flame radiation images using CCD, which has a great influence on the temperature measuring accuracy. A temperature measurement method was proposed by image fusion with multi-exposure, which can eliminate the influence of insufficient underexposure and overexposure. The approach was first to acquire a group of flame radiation images during different exposures. Then a partial region with good exposure effect in each radiation image was obtained by segmentation, with which the complete flame image can be spliced together. An experimental system was built to calibrate the temperature measurement parameters by two-color pyrometry through a blackbody furnace. The relation between exposure time and monochromatic gray level, as well as the relation between the temperature and temperature measurement coefficient were obtained. A candle flame was selected as the measuring object and the complete and accurate flame temperature distribution was acquired following our proposed method. The experimental results show that, compared with the temperature measurement using a single exposure time, our method can effectively avoid the measurement error caused by underexposure and overexposure, and improve the measurement accuracy.
KW  - image fusion
KW  - temperature measurement
KW  - exposure
KW  - flame.
DO  - 10.3390/en13061487
TY  - EJOU
AU  - Xu, Jin
AU  - Wang, Haixia
AU  - Cui, Can
AU  - Zhao, Baigang
AU  - Li, Bo
TI  - Oil Spill Monitoring of Shipborne Radar Image Features Using SVM and Local Adaptive Threshold
T2  - Algorithms

PY  - 2020
VL  - 13
IS  - 3
SN  - 1999-4893

AB  - In the case of marine accidents, monitoring marine oil spills can provide an important basis for identifying liabilities and assessing the damage. Shipborne radar can ensure large-scale, real-time monitoring, in all weather, with high-resolution. It therefore has the potential for broad applications in oil spill monitoring. Considering the original gray-scale image from the shipborne radar acquired in the case of the Dalian 7.16 oil spill accident, a complete oil spill detection method is proposed. Firstly, the co-frequency interferences and speckles in the original image are eliminated by preprocessing. Secondly, the wave information is classified using a support vector machine (SVM), and the effective wave monitoring area is generated according to the gray distribution matrix. Finally, oil spills are detected by a local adaptive threshold and displayed on an electronic chart based on geographic information system (GIS). The results show that the SVM can extract the effective wave information from the original shipborne radar image, and the local adaptive threshold method has strong applicability for oil film segmentation. This method can provide a technical basis for real-time cleaning and liability determination in oil spill accidents.
KW  - oil spill
KW  - SVM
KW  - real-time monitoring
KW  - shipborne radar
KW  - remote sensing
KW  - image processing
KW  - GIS
DO  - 10.3390/a13030069
TY  - EJOU
AU  - Zervopoulos, Alexandros
AU  - Tsipis, Athanasios
AU  - Alvanou, Aikaterini G.
AU  - Bezas, Konstantinos
AU  - Papamichail, Asterios
AU  - Vergis, Spiridon
AU  - Stylidou, Andreana
AU  - Tsoumanis, Georgios
AU  - Komianos, Vasileios
AU  - Koufoudakis, George
AU  - Oikonomou, Konstantinos
TI  - Wireless Sensor Network Synchronization for Precision Agriculture Applications
T2  - Agriculture

PY  - 2020
VL  - 10
IS  - 3
SN  - 2077-0472

AB  - The advent of Internet of Things has propelled the agricultural domain through the integration of sensory devices, capable of monitoring and wirelessly propagating information to producers; thus, they employ Wireless Sensor Networks (WSNs). These WSNs allow real time monitoring, enabling intelligent decision-making to maximize yields and minimize cost. Designing and deploying a WSN is a challenging and multivariate task, dependent on the considered environment. For example, a need for network synchronization arises in such networks to correlate acquired measurements. This work focuses on the design and installation of a WSN that is capable of facilitating the sensing aspects of smart and precision agriculture applications. A system is designed and implemented to address specific design requirements that are brought about by the considered environment. A simple synchronization scheme is described to provide time-correlated measurements using the sink node&rsquo;s clock as reference. The proposed system was installed on an olive grove to assess its effectiveness in providing a low-cost system, capable of acquiring synchronized measurements. The obtained results indicate the system&rsquo;s overall effectiveness, revealing a small but expected difference in the acquired measurements&rsquo; time correlation, caused mostly by serial transmission delays, while yielding a plethora of relevant environmental conditions.
KW  - smart agriculture
KW  - precision agriculture
KW  - internet of things
KW  - wireless sensor network
KW  - network synchronization
KW  - crop monitoring
KW  - olive grove monitoring
DO  - 10.3390/agriculture10030089
TY  - EJOU
AU  - Thonfeld, Frank
AU  - Steinbach, Stefanie
AU  - Muro, Javier
AU  - Kirimi, Fridah
TI  - Long-Term Land Use/Land Cover Change Assessment of the Kilombero Catchment in Tanzania Using Random Forest Classification and Robust Change Vector Analysis
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Information about land use/land cover (LULC) and their changes is useful for different stakeholders to assess future pathways of sustainable land use for food production as well as for nature conservation. In this study, we assess LULC changes in the Kilombero catchment in Tanzania, an important area of recent development in East Africa. LULC change is assessed in two ways: first, post-classification comparison (PCC) which allows us to directly assess changes from one LULC class to another, and second, spectral change detection. We perform LULC classification by applying random forests (RF) on sets of multitemporal metrics that account for seasonal within-class dynamics. For the spectral change detection, we make use of the robust change vector analysis (RCVA) and determine those changes that do not necessarily lead to another class. The combination of the two approaches enables us to distinguish areas that show (a) only PCC changes, (b) only spectral changes that do not affect the classification of a pixel, (c) both types of change, or (d) no changes at all. Our results reveal that only one-quarter of the catchment has not experienced any change. One-third shows both, spectral changes and LULC conversion. Changes detected with both methods predominantly occur in two major regions, one in the West of the catchment, one in the Kilombero floodplain. Both regions are important areas of food production and economic development in Tanzania. The Kilombero floodplain is a Ramsar protected area, half of which was converted to agricultural land in the past decades. Therefore, LULC monitoring is required to support sustainable land management. Relatively poor classification performances revealed several challenges during the classification process. The combined approach of PCC and RCVA allows us to detect spatial patterns of LULC change at distinct dimensions and intensities. With the assessment of additional classifier output, namely class-specific per-pixel classification probabilities and derived parameters, we account for classification uncertainty across space. We overlay the LULC change results and the spatial assessment of classification reliability to provide a thorough picture of the LULC changes taking place in the Kilombero catchment.
KW  - land-use/land-cover change
KW  - robust change vector analysis
KW  - Kilombero
KW  - wetland
KW  - food production
KW  - random forest
KW  - multitemporal metrics
KW  - Landsat
KW  - post-classification comparison
DO  - 10.3390/rs12071057
TY  - EJOU
AU  - Gibril, Mohamed Barakat A.
AU  - Kalantar, Bahareh
AU  - Al-Ruzouq, Rami
AU  - Ueda, Naonori
AU  - Saeidi, Vahideh
AU  - Shanableh, Abdallah
AU  - Mansor, Shattri
AU  - Shafri, Helmi Z. M.
TI  - Mapping Heterogeneous Urban Landscapes from the Fusion of Digital Surface Model and Unmanned Aerial Vehicle-Based Images Using Adaptive Multiscale Image Segmentation and Classification
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Considering the high-level details in an ultrahigh-spatial-resolution (UHSR) unmanned aerial vehicle (UAV) dataset, detailed mapping of heterogeneous urban landscapes is extremely challenging because of the spectral similarity between classes. In this study, adaptive hierarchical image segmentation optimization, multilevel feature selection, and multiscale (MS) supervised machine learning (ML) models were integrated to accurately generate detailed maps for heterogeneous urban areas from the fusion of the UHSR orthomosaic and digital surface model (DSM). The integrated approach commenced through a preliminary MS image segmentation parameter selection, followed by the application of three supervised ML models, namely, random forest (RF), support vector machine (SVM), and decision tree (DT). These models were implemented at the optimal MS levels to identify preliminary information, such as the optimal segmentation level(s) and relevant features, for extracting 12 land use/land cover (LULC) urban classes from the fused datasets. Using the information obtained from the first phase of the analysis, detailed MS classification was iteratively conducted to improve the classification accuracy and derive the final urban LULC maps. Two UAV-based datasets were used to develop and assess the effectiveness of the proposed framework. The hierarchical classification of the pilot study area showed that the RF was superior with an overall accuracy (OA) of 94.40% and a kappa coefficient (K) of 0.938, followed by SVM (OA = 92.50% and K = 0.917) and DT (OA = 91.60% and K = 0.908). The classification results of the second dataset revealed that SVM was superior with an OA of 94.45% and K of 0.938, followed by RF (OA = 92.46% and K = 0.916) and DT (OA = 90.46% and K = 0.893). The proposed framework exhibited an excellent potential for the detailed mapping of heterogeneous urban landscapes from the fusion of UHSR orthophoto and DSM images using various ML models.
KW  - unmanned aerial vehicle
KW  - urban LULC
KW  - GEOBIA
KW  - multiscale classification
DO  - 10.3390/rs12071081
TY  - EJOU
AU  - Zhang, Weixing
AU  - Liljedahl, Anna K.
AU  - Kanevskiy, Mikhail
AU  - Epstein, Howard E.
AU  - Jones, Benjamin M.
AU  - Jorgenson, M. T.
AU  - Kent, Kelcy
TI  - Transferability of the Deep Learning Mask R-CNN Model for Automated Mapping of Ice-Wedge Polygons in High-Resolution Satellite and UAV Images
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - State-of-the-art deep learning technology has been successfully applied to relatively small selected areas of very high spatial resolution (0.15 and 0.25 m) optical aerial imagery acquired by a fixed-wing aircraft to automatically characterize ice-wedge polygons (IWPs) in the Arctic tundra. However, any mapping of IWPs at regional to continental scales requires images acquired on different sensor platforms (particularly satellite) and a refined understanding of the performance stability of the method across sensor platforms through reliable evaluation assessments. In this study, we examined the transferability of a deep learning Mask Region-Based Convolutional Neural Network (R-CNN) model for mapping IWPs in satellite remote sensing imagery (~0.5 m) covering 272 km2 and unmanned aerial vehicle (UAV) (0.02 m) imagery covering 0.32 km2. Multi-spectral images were obtained from the WorldView-2 satellite sensor and pan-sharpened to ~0.5 m, and a 20 mp CMOS sensor camera onboard a UAV, respectively. The training dataset included 25,489 and 6022 manually delineated IWPs from satellite and fixed-wing aircraft aerial imagery near the Arctic Coastal Plain, northern Alaska. Quantitative assessments showed that individual IWPs were correctly detected at up to 72% and 70%, and delineated at up to 73% and 68% F1 score accuracy levels for satellite and UAV images, respectively. Expert-based qualitative assessments showed that IWPs were correctly detected at good (40&ndash;60%) and excellent (80&ndash;100%) accuracy levels for satellite and UAV images, respectively, and delineated at excellent (80&ndash;100%) level for both images. We found that (1) regardless of spatial resolution and spectral bands, the deep learning Mask R-CNN model effectively mapped IWPs in both remote sensing satellite and UAV images; (2) the model achieved a better accuracy in detection with finer image resolution, such as UAV imagery, yet a better accuracy in delineation with coarser image resolution, such as satellite imagery; (3) increasing the number of training data with different resolutions between the training and actual application imagery does not necessarily result in better performance of the Mask R-CNN in IWPs mapping; (4) and overall, the model underestimates the total number of IWPs particularly in terms of disjoint/incomplete IWPs.
KW  - ice-wedge polygons
KW  - Arctic
KW  - deep learning
KW  - Mask R-CNN
KW  - WorldView-2
KW  - UAV
DO  - 10.3390/rs12071085
TY  - EJOU
AU  - Dupuis, Chloé
AU  - Lejeune, Philippe
AU  - Michez, Adrien
AU  - Fayolle, Adeline
TI  - How Can Remote Sensing Help Monitor Tropical Moist Forest Degradation?—A Systematic Review
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - In the context of the climate and biodiversity crisis facing our planet, tropical forests playing a key role in global carbon flux and containing over half of Earth&rsquo;s species are important to preserve. They are today threatened by deforestation but also by forest degradation, which is more difficult to study. Here, we performed a systematic review of studies on moist tropical forest degradation using remote sensing and fitting indicators of forest resilience to perturbations. Geographical repartition, spatial extent and temporal evolution were analyzed. Indicators of compositional, structural and regeneration criteria were noted as well as remote sensing indices and metrics used. Tropical moist forest degradation is not extensively studied especially in the Congo basin and in southeast Asia. Forest structure (i.e., canopy gaps, fragmentation and biomass) is the most widely and easily measured criteria with remote sensing, while composition and regeneration are more difficult to characterize. Mixing LiDAR/Radar and optical data shows good potential as well as very high-resolution satellite data. The awaited GEDI and BIOMASS satellites data will fill the actual gap to a large extent and provide accurate structural information. LiDAR and unmanned aerial vehicles (UAVs) form a good bridge between field and satellite data. While the performance of the LiDAR is no longer to be demonstrated, particular attention should be brought to the UAV that shows great potential and could be more easily used by local communities and stakeholders.
KW  - tropical moist forest
KW  - forest degradation
KW  - remote sensing
KW  - forest degradation metrics
KW  - forest resilience
KW  - forest structure
KW  - forest composition
KW  - forest regeneration
DO  - 10.3390/rs12071087
TY  - EJOU
AU  - Tsoeleng, Lesiba T.
AU  - Odindi, John
AU  - Mhangara, Paidamwoyo
TI  - A Comparison of Two Morphological Techniques in the Classification of Urban Land Cover
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Understanding the often-heterogeneous land cover in urban areas is critical for, among other things, environmental monitoring, spatial planning, and enforcement. Recently, several earth observation satellites were developed with an enhanced spatial resolution that provides for precise and detailed representations of image objects. Morphological image analysis techniques provide useful tools for extracting spatial features from high-resolution, remotely sensed images. This study investigated the efficacy of mathematical morphological (MM) techniques in the land cover classification of a heterogeneous urban landscape using very high-resolution pan-sharpened Pleiades imagery. Specifically, the study evaluated two morphological profiles (MP) techniques (i.e., concatenation of morphological profiles (CMPs) and multi-morphological profiles (MMPs)) in the classification of a heterogeneous urban land cover. The overall accuracies for CMP were 83.14% and 83.19% over the two study areas. Similarly, the MMP overall accuracies were 84.42% and 84.08% for the two study sites. The study concluded that CMP and MMP can greatly improve the classification of heterogeneous landscapes that typify urban areas by effectively representing the structural landscape information necessary for discriminating related land cover classes. In general, similar and visually acceptable results were produced for land cover classification using either CMP or MMP image analysis techniques
KW  - land cover
KW  - urban classification
KW  - morphological image analysis
KW  - morphological profiles
KW  - satellite imagery
KW  - principal components analysis
DO  - 10.3390/rs12071089
TY  - EJOU
AU  - Papacharalampopoulos, Alexios
AU  - Giannoulis, Christos
AU  - Stavropoulos, Panos
AU  - Mourtzis, Dimitris
TI  - A Digital Twin for Automated Root-Cause Search of Production Alarms Based on KPIs Aggregated from IoT
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 7
SN  - 2076-3417

AB  - A dashboard application is proposed and developed to act as a Digital Twin that would indicate the Measured Value to be held accountable for any future failures. The current study describes a method for the exploitation of historical data that are related to production performance and aggregated from IoT, to eliciting the future behavior of the production, while indicating the measured values that are responsible for negative production performance, without training. The dashboard is implemented in the Java programming language, while information is stored into a Database that is aggregated by an Online Analytical Processing (OLAP) server. This achieves easy Key Performance Indicators (KPIs) visualization through the dashboard. Finally, indicative cases of a simulated transfer line are presented and numerical examples are given for validation and demonstration purposes. The need for human intervention is pointed out.
KW  - digital twin
KW  - decision support system
KW  - factor analysis
KW  - KPI
KW  - quantitative analysis
KW  - root-cause analysis
DO  - 10.3390/app10072377
TY  - EJOU
AU  - Gleason, Colin J.
AU  - Durand, Michael T.
TI  - Remote Sensing of River Discharge: A Review and a Framing for the Discipline
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Remote sensing of river discharge (RSQ) is a burgeoning field rife with innovation. This innovation has resulted in a highly non-cohesive subfield of hydrology advancing at a rapid pace, and as a result misconceptions, mis-citations, and confusion are apparent among authors, readers, editors, and reviewers. While the intellectually diverse subfield of RSQ practitioners can parse this confusion, the broader hydrology community views RSQ as a monolith and such confusion can be damaging. RSQ has not been comprehensively summarized over the past decade, and we believe that a summary of the recent literature has a potential to provide clarity to practitioners and general hydrologists alike. Therefore, we here summarize a broad swath of the literature, and find after our reading that the most appropriate way to summarize this literature is first by application area (into methods appropriate for gauged, semi-gauged, regionally gauged, politically ungauged, and totally ungauged basins) and next by methodology. We do not find categorizing by sensor useful, and everything from un-crewed aerial vehicles (UAVs) to satellites are considered here. Perhaps the most cogent theme to emerge from our reading is the need for context. All RSQ is employed in the service of furthering hydrologic understanding, and we argue that nearly all RSQ is useful in this pursuit provided it is properly contextualized. We argue that if authors place each new work into the correct application context, much confusion can be avoided, and we suggest a framework for such context here. Specifically, we define which RSQ techniques are and are not appropriate for ungauged basins, and further define what it means to be ‘ungauged’ in the context of RSQ. We also include political and economic realities of RSQ, as the objective of the field is sometimes to provide data purposefully cloistered by specific political decisions. This framing can enable RSQ to respond to hydrology at large with confidence and cohesion even in the face of methodological and application diversity evident within the literature. Finally, we embrace the intellectual diversity of RSQ and suggest the field is best served by a continuation of methodological proliferation rather than by a move toward orthodoxy and standardization.
KW  - remote sensing
KW  - rivers
KW  - discharge
KW  - hydrology
KW  - modelling
KW  - geomorphology
KW  - ungauged basins
DO  - 10.3390/rs12071107
TY  - EJOU
AU  - Yuzugullu, Onur
AU  - Lorenz, Frank
AU  - Fröhlich, Peter
AU  - Liebisch, Frank
TI  - Understanding Fields by Remote Sensing: Soil Zoning and Property Mapping
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Precision agriculture aims to optimize field management to increase agronomic yield, reduce environmental impact, and potentially foster soil carbon sequestration. In 2015, the Copernicus mission, with Sentinel-1 and -2, opened a new era by providing freely available high spatial and temporal resolution satellite data. Since then, many studies have been conducted to understand, monitor and improve agricultural systems. This paper presents results from the SolumScire project, focusing on the prediction of the spatial distribution of soil zones and topsoil properties, such as pH, soil organic matter (SOM) and clay content in agricultural fields through random forest algorithms. For this purpose, samples from 120 fields were investigated. The zoning and soil property prediction has an accuracy greater than 90%. This is supported by a high agreement of the derived zones with farmer&rsquo;s observations. The trained models revealed a prediction accuracy of 94%, 89% and 96% for pH, SOM and clay content, respectively. The obtained models for soil properties can support precision field management, the improvement of soil sampling and fertilization strategies, and eventually the management of soil properties such as SOM.
KW  - soil property prediction
KW  - pH
KW  - soil organic matter
KW  - soil clay content
KW  - precision agriculture
KW  - Copernicus mission
KW  - Sentinel
KW  - multi-spectral imagery
KW  - synthetic aperture radar imagery
KW  - machine learning
KW  - random forest
DO  - 10.3390/rs12071116
TY  - EJOU
AU  - Farhood, Helia
AU  - Perry, Stuart
AU  - Cheng, Eva
AU  - Kim, Juno
TI  - Enhanced 3D Point Cloud from a Light Field Image
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - The importance of three-dimensional (3D) point cloud technologies in the field of agriculture environmental research has increased in recent years. Obtaining dense and accurate 3D reconstructions of plants and urban areas provide useful information for remote sensing. In this paper, we propose a novel strategy for the enhancement of 3D point clouds from a single 4D light field (LF) image. Using a light field camera in this way creates an easy way for obtaining 3D point clouds from one snapshot and enabling diversity in monitoring and modelling applications for remote sensing. Considering an LF image and associated depth map as an input, we first apply histogram equalization and histogram stretching to enhance the separation between depth planes. We then apply multi-modal edge detection by using feature matching and fuzzy logic from the central sub-aperture LF image and the depth map. These two steps of depth map enhancement are significant parts of our novelty for this work. After combing the two previous steps and transforming the point&ndash;plane correspondence, we can obtain the 3D point cloud. We tested our method with synthetic and real world image databases. To verify the accuracy of our method, we compared our results with two different state-of-the-art algorithms. The results showed that our method can reliably mitigate noise and had the highest level of detail compared to other existing methods.
KW  - 3D point cloud
KW  - light field camera
KW  - 3D reconstruction
KW  - 3D modelling
KW  - three-dimensional data
KW  - enhanced depth map
DO  - 10.3390/rs12071125
TY  - EJOU
AU  - Lee, Seung H.
TI  - Optimization of Cold Metal Transfer-Based Wire Arc Additive Manufacturing Processes Using Gaussian Process Regression
T2  - Metals

PY  - 2020
VL  - 10
IS  - 4
SN  - 2075-4701

AB  - Wire and arc additive manufacturing (WAAM) is among the most promising additive manufacturing techniques for metals because it yields high productivity at low raw material costs. However, additional post-processing is required to remove redundant surface material from components manufactured by the WAAM process, and thus the productivity decreases. To increase productivity, multi-variable process parameters need to be optimized, including thermo-mechanical effects caused by high deposition rates. When the process is modeled, deposit shape and productivity are challenging to quantify due to uncertainty in multiple variables of the complicated WAAM process. Therefore, we modeled the WAAM process parameters, including uncertainties, using a Gaussian process regression (GPR) method, thus allowing us to develop a WAAM optimization model to improve both productivity and the quality of the deposit shape. The accuracy of the optimized output was verified through a close agreement with experimental values. The optimized deposited material had a wide effective area ratio, small height differences, and near 90&deg; deposition angle, highlighting the usefulness of the GPR model approach to deposit nearly ideal material shapes.
KW  - wire arc additive manufacturing (WAAM)
KW  - buy-to-fly ratio (BTF)
KW  - cold metal transfer (CMT)
KW  - Gaussian process regression (GPR)
KW  - parameter optimization
DO  - 10.3390/met10040461
TY  - EJOU
AU  - Torresan, Chiara
AU  - Carotenuto, Federico
AU  - Chiavetta, Ugo
AU  - Miglietta, Franco
AU  - Zaldei, Alessandro
AU  - Gioli, Beniamino
TI  - Individual Tree Crown Segmentation in Two-Layered Dense Mixed Forests from UAV LiDAR Data
T2  - Drones

PY  - 2020
VL  - 4
IS  - 2
SN  - 2504-446X

AB  - In forests with dense mixed canopies, laser scanning is often the only effective technique to acquire forest inventory attributes, rather than structure-from-motion optical methods. This study investigates the potential of laser scanner data collected with a low-cost unmanned aerial vehicle laser scanner (UAV-LS), for individual tree crown (ITC) delineation to derive forest biometric parameters, over two-layered dense mixed forest stands in central Italy. A raster-based local maxima region growing algorithm (itcLiDAR) and a point cloud-based algorithm (li2012) were applied to isolate individual tree crowns, compute height and crown area, estimate the diameter at breast height (DBH) and the above ground biomass (AGB) of individual trees. To maximize the level of detection rate, the ITC algorithm parameters were tuned varying 1350 setting combinations and matching the segmented trees with field measured trees. For each setting, the delineation accuracy was assessed by computing the detection rate, the omission and commission errors over three forest plots. Segmentation using itcLiDAR showed detection rates between 40% and 57%, while ITC delineation was successful at segmenting trees with DBH larger than 10 cm (detection rate ~78%), while failed to detect trees with smaller DBH (detection rate ~37%). The performance of li2012 was quite lower with the higher detection rate equal to 27%. Errors and goodness-of-fit between field-surveyed and flight-derived biometric parameters (AGB and tree height) were species-dependent, with higher error and lower r2 for shorter species that constitute the lowermost layer of the forest. Overall, while the application of UAV-LS to delineate tree crowns and estimate biometric parameters is satisfactory, its accuracy is affected by the presence of a multilayered and multispecies canopy that will require specific approaches and algorithms to better deal with the added complexity.
KW  - laser scanning
KW  - ITC detection algorithms
KW  - parameter calibration
KW  - itcSegment package
KW  - lidR package
KW  - detection rate
KW  - forest inventory
DO  - 10.3390/drones4020010
TY  - EJOU
AU  - Kislov, Dmitry E.
AU  - Korznikov, Kirill A.
TI  - Automatic Windthrow Detection Using Very-High-Resolution Satellite Imagery and Deep Learning
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Wind disturbances are significant phenomena in forest spatial structure and succession dynamics. They cause changes in biodiversity, impact on forest ecosystems at different spatial scales, and have a strong influence on economics and human beings. The reliable recognition and mapping of windthrow areas are of high importance from the perspective of forest management and nature conservation. Recent research in artificial intelligence and computer vision has demonstrated the incredible potential of neural networks in addressing image classification problems. The most efficient algorithms are based on artificial neural networks of nested and complex architecture (e.g., convolutional neural networks (CNNs)), which are usually referred to by a common term&mdash;deep learning. Deep learning provides powerful algorithms for the precise segmentation of remote sensing data. We developed an algorithm based on a U-Net-like CNN, which was trained to recognize windthrow areas in Kunashir Island, Russia. We used satellite imagery of very-high spatial resolution (0.5 m/pixel) as source data. We performed a grid search among 216 parameter combinations defining different U-Net-like architectures. The best parameter combination allowed us to achieve an overall accuracy for recognition of windthrow sites of up to 94% for forested landscapes by coniferous and mixed coniferous forests. We found that the false-positive decisions of our algorithm correspond to either seashore logs, which may look similar to fallen tree trunks, or leafless forest stands. While the former can be rectified by applying a forest mask, the latter requires the usage of additional information, which is not always provided by satellite imagery.
KW  - convolutional neural network
KW  - deep learning
KW  - image segmentation
KW  - machine learning
KW  - forest disturbance
KW  - windthrow
DO  - 10.3390/rs12071145
TY  - EJOU
AU  - Karballaeezadeh, Nader
AU  - Zaremotekhases, Farah
AU  - Shamshirband, Shahaboddin
AU  - Mosavi, Amir
AU  - Nabipour, Narjes
AU  - Csiba, Peter
AU  - Várkonyi-Kóczy, Annamária R.
TI  - Intelligent Road Inspection with Advanced Machine Learning; Hybrid Prediction Models for Smart Mobility and Transportation Maintenance Systems
T2  - Energies

PY  - 2020
VL  - 13
IS  - 7
SN  - 1996-1073

AB  - Prediction models in mobility and transportation maintenance systems have been dramatically improved by using machine learning methods. This paper proposes novel machine learning models for an intelligent road inspection. The traditional road inspection systems based on the pavement condition index (PCI) are often associated with the critical safety, energy and cost issues. Alternatively, the proposed models utilize surface deflection data from falling weight deflectometer (FWD) tests to predict the PCI. Machine learning methods are the single multi-layer perceptron (MLP) and radial basis function (RBF) neural networks as well as their hybrids, i.e., Levenberg&ndash;Marquardt (MLP-LM), scaled conjugate gradient (MLP-SCG), imperialist competitive (RBF-ICA), and genetic algorithms (RBF-GA). Furthermore, the committee machine intelligent systems (CMIS) method was adopted to combine the results and improve the accuracy of the modeling. The results of the analysis have been verified through using four criteria of average percent relative error (APRE), average absolute percent relative error (AAPRE), root mean square error (RMSE) and standard error (SE). The CMIS model outperforms other models with the promising results of APRE = 2.3303, AAPRE = 11.6768, RMSE = 12.0056 and SD = 0.0210.
KW  - transportation
KW  - mobility
KW  - prediction model
KW  - machine learning
KW  - pavement management
KW  - pavement condition index
KW  - highway
KW  - structural health monitoring
KW  - falling weight deflectometer
KW  - multilayer perceptron
KW  - radial basis function
KW  - artificial neural network
KW  - intelligent machine system committee
DO  - 10.3390/en13071718
TY  - EJOU
AU  - Zhou, Jingjing
AU  - Dian, Yuanyong
AU  - Wang, Xiong
AU  - Yao, Chonghuai
AU  - Jian, Yongfeng
AU  - Li, Yuan
AU  - Han, Zeming
TI  - Comparison of GF2 and SPOT6 Imagery on Canopy Cover Estimating in Northern Subtropics Forest in China
T2  - Forests

PY  - 2020
VL  - 11
IS  - 4
SN  - 1999-4907

AB  - Canopy cover is an important vegetation attribute used for many environmental applications such as defining management objectives, thinning and ecological modeling. However, the estimation of canopy cover from high spatial resolution imagery is still a difficult task due to limited spectral information and the heterogeneous pixel values of the same canopy. In this paper, we compared the capacity of two high spatial resolution sensors (SPOT6 and GF2) using three ensemble learning models (Adaptive Boosting (AdaBoost), Gradient Boosting (GDBoost), and random forest (RF)), to estimate canopy cover (CC) in a Chinese northern subtropics forest. Canopy cover across 97 plots was measured across 41 needle forest plots, 24 broadleaf forest plots, and 32 mixed forest plots. Results showed that (1) the textural features performed more importantly than spectral variables according to the number of variables in the top ten predictors in estimating canopy cover (CC) in both SPOT6 and GF2. Moreover, the vegetation indices in spectral variables had a lower relative importance value than the band reflectance variables. (2) GF2 imagery outperformed SPOT6 imagery in estimating CC when using the ensemble learning model in our data. On average across the models, the R2 was almost 0.08 higher for GF2 over SPOT6. Likewise, the average RMSE and average MAE were 0.002 and 0.01 lower in GF2 than in SPOT6. (3) The ensemble learning model showed good results in estimating CC, yet the different models performed a little differently in the results. Additionally, the GDBoost model performed the best of all the ensemble learning models with R2 = 0.92, root mean square error (RMSE) = 0.001 and mean absolute error (MAE) = 0.022.
KW  - GF2
KW  - SPOT6
KW  - high spatial resolution
KW  - canopy cover
KW  - ensemble learning model
KW  - gray level co-occurrence matrix (GLCM)
DO  - 10.3390/f11040407
TY  - EJOU
AU  - Sestras, Paul
AU  - Roșca, Sanda
AU  - Bilașco, Ștefan
AU  - Naș, Sanda
AU  - Buru, Stefan M.
AU  - Kovacs, Leontina
AU  - Spalević, Velibor
AU  - Sestras, Adriana F.
TI  - Feasibility Assessments Using Unmanned Aerial Vehicle Technology in Heritage Buildings: Rehabilitation-Restoration, Spatial Analysis and Tourism Potential Analysis
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 7
SN  - 1424-8220

AB  - The Transylvanian region of Romania is a place of rich history since ancient times, where the original natural environment around architectural heritage sites or buildings has not been severely altered by urban development. Unfortunately, many such places are left by the authorities to degrade or totally collapse for lack of funds, vision or initiatives. The current paper addresses the potential of Unmanned Aerial Vehicles (UAVs) in the assessment of a viable and feasible prospect of restoration on a 19th century mansion that belonged to a nobiliary family. UAV use is rising in many industries and has become very popular in the last decade, but for survey engineering and related domains they represent a quantum leap in technology. Integrating UAV-acquired data and structure from motion software, has enabled modern techniques to obtain useful metrics from the field, accurate photorealistic 3D models for visual inspection, structural damage analyses, architectural rehabilitation-restoration, conservation and spatial analysis of the surrounding area. In this work a socio-cultural planning and design process is explored and presented to improve the local community and inclusion in a tourist circuit based on the regional potential, as well as an evaluation of accessibility derived from a vector-raster database that highlights the central position of the cultural heritage in regards to the axis of circulation between the important metropolitan areas and the local tourist attractions. This established workflow of modern topographic and construction measurements is fully integrable into the architectural process, building information modelling, heritage conservation and reconstruction.
KW  - 3D model
KW  - accessibility study
KW  - GIS analysis
KW  - monumental heritage
KW  - point cloud
KW  - remote sensing
KW  - structure from motion (SfM)
KW  - topographical survey
DO  - 10.3390/s20072054
TY  - EJOU
AU  - Lin, Yukun
AU  - Zhu, Zhe
AU  - Guo, Wenxuan
AU  - Sun, Yazhou
AU  - Yang, Xiaoyuan
AU  - Kovalskyy, Valeriy
TI  - Continuous Monitoring of Cotton Stem Water Potential using Sentinel-2 Imagery
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Monitoring cotton status during the growing season is critical in increasing production efficiency. The water status in cotton is a key factor for yield and cotton quality. Stem water potential (SWP) is a precise indicator for assessing cotton water status. Satellite remote sensing is an effective approach for monitoring cotton growth at a large scale. The aim of this study is to estimate cotton water stress at a high temporal frequency and at a large scale. In this study, we measured midday SWP samples according to the acquisition dates of Sentinel-2 images and used them to build linear-regression-based and machine-learning-based models to estimate cotton water stress during the growing season (June to August, 2018). For the linear-regression-based method, we estimated SWP based on different Sentinel-2 spectral bands and vegetation indices, where the normalized difference index 45 (NDI45) achieved the best performance (R2 = 0.6269; RMSE = 3.6802 (-1*swp (bars))). For the machine-learning-based method, we used random forest regression to estimate SWP and received even better results (R2 = 0.6709; RMSE = 3.3742 (-1*swp (bars))). To find the best selection of input variables for the machine-learning-based approach, we tried three different data input datasets, including (1) 9 original spectral bands (e.g., blue, green, red, red edge, near infrared (NIR), and shortwave infrared (SWIR)), (2) 21 vegetation indices, and (3) a combination of original Sentinel-2 spectral bands and vegetation indices. The highest accuracy was achieved when only the original spectral bands were used. We also found the SWIR and red edge band were the most important spectral bands, and the vegetation indices based on red edge and NIR bands were particularly helpful. Finally, we applied the best approach for the linear-regression-based and the machine-learning-based methods to generate cotton water potential maps at a large scale and high temporal frequency. Results suggests that the methods developed here has the potential for continuous monitoring of SWP at large scales and the machine-learning-based method is preferred.
KW  - cotton stem water potential
KW  - linear regression
KW  - vegetation indices
KW  - machine learning
KW  - random forest
KW  - Sentinel-2
DO  - 10.3390/rs12071176
TY  - EJOU
AU  - Deng, Lu
AU  - Chu, Hong-Hu
AU  - Shi, Peng
AU  - Wang, Wei
AU  - Kong, Xuan
TI  - Region-Based CNN Method with Deformable Modules for Visually Classifying Concrete Cracks
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 7
SN  - 2076-3417

AB  - Cracks are often the most intuitive indicators for assessing the condition of in-service structures. Intelligent detection methods based on regular convolutional neural networks (CNNs) have been widely applied to the field of crack detection in recently years; however, these methods exhibit unsatisfying performance on the detection of out-of-plane cracks. To overcome this drawback, a new type of region-based CNN (R-CNN) crack detector with deformable modules is proposed in the present study. The core idea of the method is to replace the traditional regular convolution and pooling operation with a deformable convolution operation and a deformable pooling operation. The idea is implemented on three different regular detectors, namely the Faster R-CNN, region-based fully convolutional networks (R-FCN), and feature pyramid network (FPN)-based Faster R-CNN. To examine the advantages of the proposed method, the results obtained from the proposed detector and corresponding regular detectors are compared. The results show that the addition of deformable modules improves the mean average precisions (mAPs) achieved by the Faster R-CNN, R-FCN, and FPN-based Faster R-CNN for crack detection. More importantly, adding deformable modules enables these detectors to detect the out-of-plane cracks that are difficult for regular detectors to detect.
KW  - structural health monitoring (SHM)
KW  - deep learning
KW  - convolutional neural network
KW  - deformable convolution
KW  - concrete cracks
KW  - out-of-plane crack
DO  - 10.3390/app10072528
TY  - EJOU
AU  - Feng, Chuncheng
AU  - Zhang, Hua
AU  - Wang, Haoran
AU  - Wang, Shuang
AU  - Li, Yonglong
TI  - Automatic Pixel-Level Crack Detection on Dam Surface Using Deep Convolutional Network
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 7
SN  - 1424-8220

AB  - Crack detection on dam surfaces is an important task for safe inspection of hydropower stations. More and more object detection methods based on deep learning are being applied to crack detection. However, most of the methods can only achieve the classification and rough location of cracks. Pixel-level crack detection can provide more intuitive and accurate detection results for dam health assessment. To realize pixel-level crack detection, a method of crack detection on dam surface (CDDS) using deep convolution network is proposed. First, we use an unmanned aerial vehicle (UAV) to collect dam surface images along a predetermined trajectory. Second, raw images are cropped. Then crack regions are manually labelled on cropped images to create the crack dataset, and the architecture of CDDS network is designed. Finally, the CDDS network is trained, validated and tested using the crack dataset. To validate the performance of the CDDS network, the predicted results are compared with ResNet152-based, SegNet, UNet and fully convolutional network (FCN). In terms of crack segmentation, the recall, precision, F-measure and IoU are 80.45%, 80.31%, 79.16%, and 66.76%. The results on test dataset show that the CDDS network has better performance for crack detection of dam surfaces.
KW  - crack detection
KW  - dam surface
KW  - UAV
KW  - pixel-level
KW  - deep convolutional network
DO  - 10.3390/s20072069
TY  - EJOU
AU  - Kounas, Dimitrios
AU  - Voutyras, Orfefs
AU  - Palaiokrassas, Georgios
AU  - Litke, Antonios
AU  - Varvarigou, Theodora
TI  - QuietPlace: An Ultrasound-Based Proof of Location Protocol with Strong Identities
T2  - Applied System Innovation

PY  - 2020
VL  - 3
IS  - 2
SN  - 2571-5577

AB  - Location-based services are becoming extremely popular due to the widespread use of smartphones and other mobile and portable devices. These services mainly rely on the sincerity of users, who can spoof the location they report to them. For applications with higher security requirements, the user should be unable to report a location different than the real one. Proof of Location protocols provide a solution to secure localization by validating the device&rsquo;s location with the help of nearby nodes. We propose QuietPlace, a novel protocol that is based on ultrasound and provides strong identities, proving the location of the owner of a device, without exposing though their identity. QuietPlace provides unforgeable proof that is able to resist to various attacks while respecting the users&rsquo; privacy. It can work regardless of certificate authority and location-based service and is able to support trust schemas that evaluate the participants&rsquo; behavior. We implement and validate the protocol for Android devices, showing that ultrasound-based profiles offer a better performance in terms of maximum receiving distance than audible profiles, and discuss its strengths and weaknesses, making suggestions about future work.
KW  - secure localization
KW  - proof of location (PoL)
KW  - ultrasound
KW  - strong identities
KW  - location-based services (LBS)
KW  - reliability and trust
DO  - 10.3390/asi3020019
TY  - EJOU
AU  - Zhao, Zhenbing
AU  - Qi, Hongyu
AU  - Fan, Xiaoqing
AU  - Xu, Guozhi
AU  - Qi, Yincheng
AU  - Zhai, Yongjie
AU  - Zhang, Ke
TI  - Image Representation Method Based on Relative Layer Entropy for Insulator Recognition
T2  - Entropy

PY  - 2020
VL  - 22
IS  - 4
SN  - 1099-4300

AB  - Deep convolutional neural networks (DCNNs) with alternating convolutional, pooling and decimation layers are widely used in computer vision, yet current works tend to focus on deeper networks with many layers and neurons, resulting in a high computational complexity. However, the recognition task is still challenging for insufficient and uncomprehensive object appearance and training sample types such as infrared insulators. In view of this, more attention is focused on the application of a pretrained network for image feature representation, but the rules on how to select the feature representation layer are scarce. In this paper, we proposed a new concept, the layer entropy and relative layer entropy, which can be referred to as an image representation method based on relative layer entropy (IRM_RLE). It was designed to excavate the most suitable convolution layer for image recognition. First, the image was fed into an ImageNet pretrained DCNN model, and deep convolutional activations were extracted. Then, the appropriate feature layer was selected by calculating the layer entropy and relative layer entropy of each convolution layer. Finally, the number of the feature map was selected according to the importance degree and the feature maps of the convolution layer, which were vectorized and pooled by VLAD (vector of locally aggregated descriptors) coding and quantifying for final image representation. The experimental results show that the proposed approach performs competitively against previous methods across all datasets. Furthermore, for the indoor scenes and actions datasets, the proposed approach outperforms the state-of-the-art methods.
KW  - image representation
KW  - insulator recognition
KW  - deep convolutional neural networks
KW  - relative layer entropy
KW  - vector of locally aggregated descriptors
DO  - 10.3390/e22040419
TY  - EJOU
AU  - Bohak, Ciril
AU  - Slemenik, Matej
AU  - Kordež, Jaka
AU  - Marolt, Matija
TI  - Aerial LiDAR Data Augmentation for Direct Point-Cloud Visualisation
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 7
SN  - 1424-8220

AB  - Direct point-cloud visualisation is a common approach for visualising large datasets of aerial terrain LiDAR scans. However, because of the limitations of the acquisition technique, such visualisations often lack the desired visual appeal and quality, mostly because certain types of objects are incomplete or entirely missing (e.g., missing water surfaces, missing building walls and missing parts of the terrain). To improve the quality of direct LiDAR point-cloud rendering, we present a point-cloud processing pipeline that uses data fusion to augment the data with additional points on water surfaces, building walls and terrain through the use of vector maps of water surfaces and building outlines. In the last step of the pipeline, we also add colour information, and calculate point normals for illumination of individual points to make the final visualisation more visually appealing. We evaluate our approach on several parts of the Slovenian LiDAR dataset.
KW  - LiDAR
KW  - point-clouds
KW  - point-cloud visualisation
KW  - terrain reconstruction
KW  - water surface reconstruction
DO  - 10.3390/s20072089
TY  - EJOU
AU  - Mallinis, Giorgos
AU  - Chrysafis, Irene
AU  - Korakis, Georgios
AU  - Pana, Eleanna
AU  - Kyriazopoulos, Apostolos P.
TI  - A Random Forest Modelling Procedure for a Multi-Sensor Assessment of Tree Species Diversity
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Earth observation data can provide important information for tree species diversity mapping and monitoring. The relatively recent advances in remote sensing data characteristics and processing systems elevate the potential of satellite imagery for providing accurate, timely, consistent, and robust spatially explicit estimates of tree species diversity over forest ecosystems. This study was conducted in Northern Pindos National Park, the largest terrestrial park in Greece and aimed to assess the potential of four satellite sensors with different instrumental characteristics, for the estimation of tree diversity. Through field measurements, we originally quantified two diversity indices, namely the Shannon diversity index (H&rsquo;) and Simpson&rsquo;s diversity (D1). Random forest regression models were developed for associating remotely sensed spectral signal with tree species diversity within the area. The models generated from the use of the WorldView-2 image were the most accurate with a coefficient of determination of up to 0.44 for H&rsquo; and 0.37 for D1. The Sentinel-2 -based models of tree species diversity performed slightly worse, but were better than the Landsat-8 and RapidEye models. The coefficient of variation quantifying internal variability of spectral values within each plot provided little or no usage for improving the modelling accuracy. Our results suggest that very-high-spatial-resolution imagery provides the most important information for the assessment of tree species diversity in heterogeneous Mediterranean ecosystems.
KW  - biodiversity indices
KW  - Sentinel-2
KW  - Landsat-8
KW  - RapidEye
KW  - machine learning
KW  - Mediterranean forest habitats
KW  - WorldView-2
DO  - 10.3390/rs12071210
TY  - EJOU
AU  - Raza, Muhammad M.
AU  - Harding, Chris
AU  - Liebman, Matt
AU  - Leandro, Leonor F.
TI  - Exploring the Potential of High-Resolution Satellite Imagery for the Detection of Soybean Sudden Death Syndrome
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Sudden death syndrome (SDS) is one of the major yield-limiting soybean diseases in the Midwestern United States. Effective management for SDS requires accurate detection in soybean fields. Since traditional scouting methods are time-consuming, labor-intensive, and often destructive, alternative methods to monitor SDS in large soybean fields are needed. This study explores the potential of using high-resolution (3 m) PlanetScope satellite imagery for detection of SDS using the random forest classification algorithm. Image data from blue, green, red, and near-infrared (NIR) spectral bands, the calculated normalized difference vegetation index (NDVI), and crop rotation information were used to detect healthy and SDS-infected quadrats in a soybean field experiment with different rotation treatments, located in Boone County, Iowa. Datasets collected during the 2016, 2017, and 2018 soybean growing seasons were analyzed. The results indicate that spectral features, when combined with ground-based information, can detect areas in soybean plots that are at risk for disease, even before foliar symptoms develop. The classification of healthy and diseased soybean quadrats was &gt;75% accurate and the area under the receiver operating characteristic curve (AUROC) was &gt;70%. Our results indicate that high-resolution satellite imagery and random forest analyses have the potential to detect SDS in soybean fields, and that this approach may facilitate large-scale monitoring of SDS (and possibly other economically important soybean diseases). It may also be useful for guiding recommendations for site-specific management in current and future seasons.
KW  - soybean disease
KW  - sudden death syndrome
KW  - disease detection
KW  - remote sensing
KW  - PlanetScope
KW  - satellite imagery
KW  - random forest
DO  - 10.3390/rs12071213
TY  - EJOU
AU  - Chen, Zhixiong
AU  - Xiao, Nan
AU  - Han, Dongsheng
TI  - Multilevel Task Offloading and Resource Optimization of Edge Computing Networks Considering UAV Relay and Green Energy
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 7
SN  - 2076-3417

AB  - Unmanned aerial vehicle (UAV)-assisted relay mobile edge computing (MEC) network is a prominent concept, where network deployment is flexible and network coverage is wide. In scenarios such as emergency communications and low-cost coverage, optimization of offloading methods and resource utilization are important ways to improve system effectiveness due to limited terminal and UAV energy and hardware equipment. A multilevel edge computing network resource optimization model on the basis of UAV fusion that provides relay forwarding and offload services is established by considering the initial energy state of the UAV, the green energy charging function, and the reliability of computing offload. With normalized system utility function maximization as the goal, a Markov decision process algorithm meets the needs of the practical application scene and provides a flexible and effective unloading mode. This algorithm is adopted to solve the optimal offloading mode and the optimal resource utilization scheme. Simulations verify the effectiveness and reliability of the proposed multilevel offloading model. The proposed model can optimize system resource allocation and effectively improve the utility function and user experience of computing offloading systems.
KW  - Unmanned aerial vehicle (UAV)
KW  - Mobile Edge Computing (MEC) Network
KW  - green energy resources
KW  - MDP algorithm
DO  - 10.3390/app10072592
TY  - EJOU
AU  - Silveira Kupssinskü, Lucas
AU  - Thomassim Guimarães, Tainá
AU  - Menezes de Souza, Eniuce
AU  - C. Zanotta, Daniel
AU  - Roberto Veronez, Mauricio
AU  - Gonzaga, Luiz
AU  - Mauad, Frederico F.
TI  - A Method for Chlorophyll-a and Suspended Solids Prediction through Remote Sensing and Machine Learning
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 7
SN  - 1424-8220

AB  - Total Suspended Solids (TSS) and chlorophyll-a concentration are two critical parameters to monitor water quality. Since directly collecting samples for laboratory analysis can be expensive, this paper presents a methodology to estimate this information through remote sensing and Machine Learning (ML) techniques. TSS and chlorophyll-a are optically active components, therefore enabling measurement by remote sensing. Two study cases in distinct water bodies are performed, and those cases use different spatial resolution data from Sentinel-2 spectral images and unmanned aerial vehicles together with laboratory analysis data. In consonance with the methodology, supervised ML algorithms are trained to predict the concentration of TSS and chlorophyll-a. The predictions are evaluated separately in both study areas, where both TSS and chlorophyll-a models achieved R-squared values above 0.8.
KW  - chlorophyll-a
KW  - total suspended solids
KW  - remote sensing
KW  - machine learning
KW  - artificial neural networks
KW  - random forest
KW  - K nearest neighbors
KW  - water quality
DO  - 10.3390/s20072125
TY  - EJOU
AU  - Xu, Zhiqiang
AU  - Chen, Yumin
AU  - Yang, Fan
AU  - Chu, Tianyou
AU  - Zhou, Hongyan
TI  - A Postearthquake Multiple Scene Recognition Model Based on Classical SSD Method and Transfer Learning
T2  - ISPRS International Journal of Geo-Information

PY  - 2020
VL  - 9
IS  - 4
SN  - 2220-9964

AB  - The recognition of postearthquake scenes plays an important role in postearthquake rescue and reconstruction. To overcome the over-reliance on expert visual interpretation and the poor recognition performance of traditional machine learning in postearthquake scene recognition, this paper proposes a postearthquake multiple scene recognition (PEMSR) model based on the classical deep learning Single Shot MultiBox Detector (SSD) method. In this paper, a labeled postearthquake scenes dataset is constructed by segmenting acquired remote sensing images, which are classified into six categories: landslide, houses, ruins, trees, clogged and ponding. Due to the insufficiency and imbalance of the original dataset, transfer learning and a data augmentation and balancing strategy are utilized in the PEMSR model. To evaluate the PEMSR model, the evaluation metrics of precision, recall and F1 score are used in the experiment. Multiple experimental test results demonstrate that the PEMSR model shows a stronger performance in postearthquake scene recognition. The PEMSR model improves the detection accuracy of each scene compared with SSD by transfer learning and data augmentation strategy. In addition, the average detection time of the PEMSR model only needs 0.4565s, which is far less than the 8.3472s of the traditional Histogram of Oriented Gradient + Support Vector Machine (HOG+SVM) method.
KW  - earthquake disasters
KW  - scene recognition
KW  - deep learning
KW  - classical SSD method
KW  - transfer learning
DO  - 10.3390/ijgi9040238
TY  - EJOU
AU  - Murtiyoso, Arnadi
AU  - Grussenmeyer, Pierre
TI  - Virtual Disassembling of Historical Edifices: Experiments and Assessments of an Automatic Approach for Classifying Multi-Scalar Point Clouds into Architectural Elements
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 8
SN  - 1424-8220

AB  - 3D heritage documentation has seen a surge in the past decade due to developments in reality-based 3D recording techniques. Several methods such as photogrammetry and laser scanning are becoming ubiquitous amongst architects, archaeologists, surveyors, and conservators. The main result of these methods is a 3D representation of the object in the form of point clouds. However, a solely geometric point cloud is often insufficient for further analysis, monitoring, and model predicting of the heritage object. The semantic annotation of point clouds remains an interesting research topic since traditionally it requires manual labeling and therefore a lot of time and resources. This paper proposes an automated pipeline to segment and classify multi-scalar point clouds in the case of heritage object. This is done in order to perform multi-level segmentation from the scale of a historical neighborhood up until that of architectural elements, specifically pillars and beams. The proposed workflow involves an algorithmic approach in the form of a toolbox which includes various functions covering the semantic segmentation of large point clouds into smaller, more manageable and semantically labeled clusters. The first part of the workflow will explain the segmentation and semantic labeling of heritage complexes into individual buildings, while a second part will discuss the use of the same toolbox to segment the resulting buildings further into architectural elements. The toolbox was tested on several historical buildings and showed promising results. The ultimate intention of the project is to help the manual point cloud labeling, especially when confronted with the large training data requirements of machine learning-based algorithms.
KW  - heritage
KW  - 3D documentation
KW  - point cloud
KW  - automation
KW  - segmentation
KW  - classification
KW  - GIS
DO  - 10.3390/s20082161
TY  - EJOU
AU  - Pan, Xinliang
AU  - Jiang, Tao
AU  - Zhang, Zhen
AU  - Sui, Baikai
AU  - Liu, Chenxi
AU  - Zhang, Linjing
TI  - A New Method for Extracting Laver Culture Carriers Based on Inaccurate Supervised Classification with FCN-CRF
T2  - Journal of Marine Science and Engineering

PY  - 2020
VL  - 8
IS  - 4
SN  - 2077-1312

AB  - Timely monitoring of marine aquaculture has considerable significance for marine ecological protection and maritime safety and security. Considering that supervised learning needs to rely on a large number of training samples and the characteristics of intensive and regular distribution of the laver aquaculture zone, in this paper, an inaccurate supervised classification model based on fully convolutional neural network and conditional random filed (FCN-CRF) is designed for the study of a laver aquaculture zone in Lianyungang, Jiangsu Province. The proposed model can extract the aquaculture zone and calculate the area and quantity of laver aquaculture net simultaneously. The FCN is used to extract the laver aquaculture zone by roughly making the training label. Then, the CRF is used to extract the isolated laver aquaculture net with high precision. The results show that the     k a p p a     coefficient of the proposed model is 0.984, the      F 1      is 0.99, and the recognition effect is outstanding. For label production, the fault tolerance rate is high and does not affect the final classification accuracy, thereby saving more label production time. The findings provide a data basis for future aquaculture yield estimation and offshore resource planning as well as technical support for marine ecological supervision and marine traffic management.
KW  - laver culture
KW  - FCN
KW  - conditional random filed
KW  - inaccurate supervised classification
DO  - 10.3390/jmse8040274
TY  - EJOU
AU  - Šarlah, Nikolaj
AU  - Podobnikar, Tomaž
AU  - Ambrožič, Tomaž
AU  - Mušič, Branko
TI  - Application of Kinematic GPR-TPS Model with High 3D Georeference Accuracy for Underground Utility Infrastructure Mapping: A Case Study from Urban Sites in Celje, Slovenia
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 8
SN  - 2072-4292

AB  - This paper describes in detail the applicability of the developed ground-penetrating radar (GPR) model with a kinematic GPR and self-tracking (robotic) terrestrial positioning system (TPS) surveying setup (GPR-TPS model) for the acquisition, processing and visualisation of underground utility infrastructure (UUI) in a real urban environment. The integration of GPR with TPS can significantly improve the accuracy of UUI positioning in a real urban environment by means of efficient control of GPR trajectories. Two areas in the urban part of Celje in Slovenia were chosen. The accuracy of the kinematic GPR-TPS model was analysed by comparing the three-dimensional (3D) position of UUI given as reference values (true 3D position) from the officially consolidated cadastre of utility infrastructure in the Republic of Slovenia and those obtained by the GPR-TPS method. To determine the reference 3D position of the GPR antenna and UUI, the same positional and height geodetic network was used. Small unmanned aerial vehicles (UAV) were used for recording to provide a better spatial display of the results of UUI obtained with the GPR-TPS method. As demonstrated by the results, the kinematic GPR-TPS model for data acquisition can achieve an accuracy of fewer than 15 centimetres in a real urban environment.
KW  - kinematic GPR-TPS model
KW  - self-tracking terrestrial positioning system
KW  - underground utility infrastructure
KW  - unmanned aerial vehicle
KW  - horizontal accuracy
KW  - vertical accuracy
KW  - real urban environment
DO  - 10.3390/rs12081228
TY  - EJOU
AU  - Wang, Liangju
AU  - Duan, Yunhong
AU  - Zhang, Libo
AU  - Wang, Jialei
AU  - Li, Yikai
AU  - Jin, Jian
TI  - LeafScope: A Portable High-Resolution Multispectral Imager for In Vivo Imaging Soybean Leaf
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 8
SN  - 1424-8220

AB  - Portable devices for measuring plant physiological features with their isolated measuring chamber are playing an increasingly important role in plant phenotyping. However, currently available commercial devices of this type, such as soil plant analysis development (SPAD) meter and spectrometer, are dot meters that only measure a small region of the leaf, which does not perfectly represent the highly varied leaf surface. This study developed a portable and high-resolution multispectral imager (named LeafScope) to in-vivo image a whole leaf of dicotyledon plants while blocking the ambient light. The hardware system is comprised of a monochrome camera, an imaging chamber, a lightbox with different bands of light-emitting diodes (LEDs) array, and a microcontroller. During measuring, the device presses the leaf to lay it flat in the imaging chamber and acquires multiple images while alternating the LED bands within seconds in a certain order. The results of an experiment with soybean plants clearly showed the effect of nitrogen and water treatments as well as the genotype differences by the color and morphological features from image processing. We conclude that the low cost and easy to use LeafScope can provide promising imaging quality for dicotyledon plants, so it has great potential to be used in plant phenotyping.
KW  - plant phenotyping
KW  - handheld sensor
KW  - soybean leaf
KW  - multispectral imaging
KW  - high-resolution
KW  - leaf morphological features
KW  - leaf venation
DO  - 10.3390/s20082194
TY  - EJOU
AU  - Chatterjee, Sumanta
AU  - Huang, Jingyi
AU  - Hartemink, Alfred E.
TI  - Establishing an Empirical Model for Surface Soil Moisture Retrieval at the U.S. Climate Reference Network Using Sentinel-1 Backscatter and Ancillary Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 8
SN  - 2072-4292

AB  - Progress in sensor technologies has allowed real-time monitoring of soil water. It is a challenge to model soil water content based on remote sensing data. Here, we retrieved and modeled surface soil moisture (SSM) at the U.S. Climate Reference Network (USCRN) stations using Sentinel-1 backscatter data from 2016 to 2018 and ancillary data. Empirical machine learning models were established between soil water content measured at the USCRN stations with Sentinel-1 data from 2016 to 2017, the National Land Cover Dataset, terrain parameters, and Polaris soil data, and were evaluated in 2018 at the same USCRN stations. The Cubist model performed better than the multiple linear regression (MLR) and Random Forest (RF) model (R2 = 0.68 and RMSE = 0.06 m3 m-3 for validation). The Cubist model performed best in Shrub/Scrub, followed by Herbaceous and Cultivated Crops but poorly in Hay/Pasture. The success of SSM retrieval was mostly attributed to soil properties, followed by Sentinel-1 backscatter data, terrain parameters, and land cover. The approach shows the potential for retrieving SSM using Sentinel-1 data in a combination of high-resolution ancillary data across the conterminous United States (CONUS). Future work is required to improve the model performance by including more SSM network measurements, assimilating Sentinel-1 data with other microwave, optical and thermal remote sensing products. There is also a need to improve the spatial resolution and accuracy of land surface parameter products (e.g., soil properties and terrain parameters) at the regional and global scales.
KW  - remote sensing
KW  - soil moisture network
KW  - sensor synergy
KW  - data fusion
KW  - soil water conservation
KW  - ecological monitoring
DO  - 10.3390/rs12081242
TY  - EJOU
AU  - Merlino, Silvia
AU  - Paterni, Marco
AU  - Berton, Andrea
AU  - Massetti, Luciano
TI  - Unmanned Aerial Vehicles for Debris Survey in Coastal Areas: Long-Term Monitoring Programme to Study Spatial and Temporal Accumulation of the Dynamics of Beached Marine Litter
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 8
SN  - 2072-4292

AB  - Unmanned aerial vehicles (UAVs) are becoming increasingly accessible tools with widespread use as environmental monitoring systems. They can be used for anthropogenic marine debris survey, a recently growing research field. In fact, while the increasing efforts for offshore investigations lead to a considerable collection of data on this type of pollution in the open sea, there is still little knowledge of the materials deposited along the coasts and the mechanism that leads to their accumulation pattern. UAVs can be effective in bridging this gap by increasing the amount of data acquired to study coastal deposits, while also limiting the anthropogenic impact in protected areas. In this study, UAVs have been used to acquire geo-referenced RGB images in a selected zone of a protected marine area (the Migliarino, Massacciuccoli, and San Rossore park near Pisa, Italy), during a long-term (ten months) monitoring programme. A post processing system based on visual interpretation of the images allows the localization and identification of the anthropogenic marine debris within the scanned area, and the estimation of their spatial and temporal distribution in different zones of the beach. These results provide an opportunity to investigate the dynamics of accumulation over time, suggesting that our approach might be appropriate for monitoring and collecting such data in isolated, and especially in protected, areas with significant benefits for different types of stakeholders.
KW  - unmanned-aerial-vehicles
KW  - UAVs
KW  - anthropogenic-marine-debris
KW  - AMD
KW  - beached-marine-litter
KW  - BML
KW  - marine-protected-areas
KW  - MPA
KW  - ortho-photo
KW  - marine-pollution
KW  - accumulation-rate
DO  - 10.3390/rs12081260
TY  - EJOU
AU  - Lou, Peiqing
AU  - Fu, Bolin
AU  - He, Hongchang
AU  - Li, Ying
AU  - Tang, Tingyuan
AU  - Lin, Xingchen
AU  - Fan, Donglin
AU  - Gao, Ertao
TI  - An Optimized Object-Based Random Forest Algorithm for Marsh Vegetation Mapping Using High-Spatial-Resolution GF-1 and ZY-3 Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 8
SN  - 2072-4292

AB  - Discriminating marsh vegetation is critical for the rapid assessment and management of wetlands. The study area, Honghe National Nature Reserve (HNNR), a typical freshwater wetland, is located in Northeast China. This study optimized the parameters (mtry and ntrees) of an object-based random forest (RF) algorithm to improve the applicability of marsh vegetation classification. Multidimensional datasets were used as the input variables for model training, then variable selection was performed on the variables to eliminate redundancy, which improved classification efficiency and overall accuracy. Finally, the performance of a new generation of Chinese high-spatial-resolution Gaofen-1 (GF-1) and Ziyuan-3 (ZY-3) satellite images for marsh vegetation classification was evaluated using the improved object-based RF algorithm with accuracy assessment. The specific conclusions of this study are as follows: (1) Optimized object-based RF classifications consistently produced more than 70.26% overall accuracy for all scenarios of GF-1 and ZY-3 at the 95% confidence interval. The performance of ZY-3 imagery applied to marsh vegetation mapping is lower than that of GF-1 imagery due to the coarse spatial resolution. (2) Parameter optimization of the object-based RF algorithm effectively improved the stability and classification accuracy of the algorithm. After parameter adjustment, scenario 3 for GF-1 data had the highest classification accuracy of 84% (ZY-3 is 74.72%) at the 95% confidence interval. (3) The introduction of multidimensional datasets improved the overall accuracy of marsh vegetation mapping, but with many redundant variables. Using three variable selection algorithms to remove redundant variables from the multidimensional datasets effectively improved the classification efficiency and overall accuracy. The recursive feature elimination (RFE)-based variable selection algorithm had the best performance. (4) Optical spectral bands, spectral indices, mean value of green and NIR bands in textural information, DEM, TWI, compactness, max difference, and shape index are valuable variables for marsh vegetation mapping. (5) GF-1 and ZY-3 images had higher classification accuracy for forest, cropland, shrubs, and open water.
KW  - marsh vegetation mapping
KW  - random forest algorithm
KW  - parameter optimization
KW  - multidimensional datasets
KW  - variable selection
KW  - GF-1
KW  - ZY-3
KW  - Northeast China
DO  - 10.3390/rs12081270
TY  - EJOU
AU  - G. Braga, José R.
AU  - Peripato, Vinícius
AU  - Dalagnol, Ricardo
AU  - P. Ferreira, Matheus
AU  - Tarabalka, Yuliya
AU  - O. C. Aragão, Luiz E.
AU  - F. de Campos Velho, Haroldo
AU  - Shiguemori, Elcio H.
AU  - Wagner, Fabien H.
TI  - Tree Crown Delineation Algorithm Based on a Convolutional Neural Network
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 8
SN  - 2072-4292

AB  - Tropical forests concentrate the largest diversity of species on the planet and play a key role in maintaining environmental processes. Due to the importance of those forests, there is growing interest in mapping their components and getting information at an individual tree level to conduct reliable satellite-based forest inventory for biomass and species distribution qualification. Individual tree crown information could be manually gathered from high resolution satellite images; however, to achieve this task at large-scale, an algorithm to identify and delineate each tree crown individually, with high accuracy, is a prerequisite. In this study, we propose the application of a convolutional neural network&mdash;Mask R-CNN algorithm&mdash;to perform the tree crown detection and delineation. The algorithm uses very high-resolution satellite images from tropical forests. The results obtained are promising&mdash;the     R e c a l l    ,     P r e c i s i o n    , and     F 1     score values obtained were were     0.81    ,     0.91    , and     0.86    , respectively. In the study site, the total of tree crowns delineated was     59,062    . These results suggest that this algorithm can be used to assist the planning and conduction of forest inventories. As the algorithm is based on a Deep Learning approach, it can be systematically trained and used for other regions.
KW  - tree crown delineation
KW  - tropical forests
KW  - optical satellite images
KW  - deep learning
DO  - 10.3390/rs12081288
TY  - EJOU
AU  - Miyoshi, Gabriela T.
AU  - Arruda, Mauro D.
AU  - Osco, Lucas P.
AU  - Marcato Junior, José
AU  - Gonçalves, Diogo N.
AU  - Imai, Nilton N.
AU  - Tommaselli, Antonio M.
AU  - Honkavaara, Eija
AU  - Gonçalves, Wesley N.
TI  - A Novel Deep Learning Method to Identify Single Tree Species in UAV-Based Hyperspectral Images
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 8
SN  - 2072-4292

AB  - Deep neural networks are currently the focus of many remote sensing approaches related to forest management. Although they return satisfactory results in most tasks, some challenges related to hyperspectral data remain, like the curse of data dimensionality. In forested areas, another common problem is the highly-dense distribution of trees. In this paper, we propose a novel deep learning approach for hyperspectral imagery to identify single-tree species in highly-dense areas. We evaluated images with 25 spectral bands ranging from 506 to 820 nm taken over a semideciduous forest of the Brazilian Atlantic biome. We included in our network&rsquo;s architecture a band combination selection phase. This phase learns from multiple combinations between bands which contributed the most for the tree identification task. This is followed by a feature map extraction and a multi-stage model refinement of the confidence map to produce accurate results of a highly-dense target. Our method returned an f-measure, precision and recall values of 0.959, 0.973, and 0.945, respectively. The results were superior when compared with a principal component analysis (PCA) approach. Compared to other learning methods, ours estimate a combination of hyperspectral bands that most contribute to the mentioned task within the network&rsquo;s architecture. With this, the proposed method achieved state-of-the-art performance for detecting and geolocating individual tree-species in UAV-based hyperspectral images in a complex forest.
KW  - high-density object
KW  - data-reduction
KW  - band selection
KW  - convolutional neural network
KW  - tree species identification
DO  - 10.3390/rs12081294
TY  - EJOU
AU  - Zhang, Lin
AU  - Zhu, Yian
AU  - Shi, Xianchen
TI  - A Hierarchical Decision-Making Method with a Fuzzy Ant Colony Algorithm for Mission Planning of Multiple UAVs
T2  - Information

PY  - 2020
VL  - 11
IS  - 4
SN  - 2078-2489

AB  - Unmanned aerial vehicles (UAVs) received an unprecedented surge of people&rsquo;s interest worldwide in recent years. This paper investigates the specific problem of cooperative mission planning for multiple UAVs on the battlefield from a hierarchical decision-making perspective. From the view of the actual mission planning issue, the two key problems to be solved in UAV collaborative mission planning are mission allocation and route planning. In this paper, both of these problems are taken into account via a hierarchical decision-making model. Firstly, we use a target clustering algorithm to divide the original targets into target subgroups, where each target subgroup contains multiple targets. Secondly, a fuzzy ant colony algorithm is used to calculate the global path between target subgroups for a single-target group. Thirdly, a fuzzy ant colony algorithm is also used to calculate the local path between multiple targets for a single-target subgroup. After three levels of decision-making, the complete path for multiple UAVs can be obtained. In order to improve the efficiency of a collaborative task between different types of UAVs, a cooperative communication strategy is developed, which can reduce the number of UAVs performing tasks. Finally, experimental results demonstrate the effectiveness of the proposed cooperative mission planning and cooperative communication strategy for multiple UAVs.
KW  - multiple UAVs
KW  - mission planning
KW  - fuzzy ant colony algorithm
KW  - hierarchical decision-making
KW  - target clustering algorithm
DO  - 10.3390/info11040226
TY  - EJOU
AU  - Moselhi, Osama
AU  - Bardareh, Hassan
AU  - Zhu, Zhenhua
TI  - Automated Data Acquisition in Construction with Remote Sensing Technologies
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 8
SN  - 2076-3417

AB  - Near real-time tracking of construction operations and timely progress reporting are essential for effective management of construction projects. This does not only mitigate potential negative impact of schedule delays and cost overruns but also helps to improve safety on site. Such timely tracking circumvents the drawbacks of conventional methods for data acquisition, which are manual, labor-intensive, and not reliable enough for various construction purposes. To address these issues, a wide range of automated site data acquisition, including remote sensing (RS) technologies, has been introduced. This review article describes the capabilities and limitations of various scenarios employing RS enabling technologies for localization, with a focus on multi-sensor data fusion models. In particular, we have considered integration of real-time location systems (RTLSs) including GPS and UWB with other sensing technologies such as RFID, WSN, and digital imaging for their use in construction. This integrated use of technologies, along with information models (e.g., BIM models) is expected to enhance the efficiency of automated site data acquisition. It is also hoped that this review will prompt researchers to investigate fusion-based data capturing and processing.
KW  - automated data acquisition
KW  - remote sensing technologies
KW  - automated progress reporting
KW  - data fusion
KW  - tracking resources
DO  - 10.3390/app10082846
TY  - EJOU
AU  - Wang, Tianyi
AU  - Thomasson, J. A.
AU  - Yang, Chenghai
AU  - Isakeit, Thomas
AU  - Nichols, Robert L.
TI  - Automatic Classification of Cotton Root Rot Disease Based on UAV Remote Sensing
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 8
SN  - 2072-4292

AB  - Cotton root rot (CRR) is a persistent soilborne fungal disease that is devastating to cotton in the southwestern U.S. and Mexico. Research has shown that CRR can be prevented or at least mitigated by applying a fungicide at planting, but the fungicide should be applied precisely to minimize the quantity of product used and the treatment cost. The CRR-infested areas within a field are consistent from year to year, so it is possible to apply the fungicide only at locations where CRR is manifest, thus minimizing the amount of fungicide applied across the field. Previous studies have shown that remote sensing (RS) from manned aircraft is an effective means of delineating CRR-infested field areas. Applying various classification methods to moderate-resolution (1.0 m/pixel) RS images has recently become the conventional way to delineate CRR-infested areas. In this research, an unmanned aerial vehicle (UAV) was used to collect high-resolution remote sensing (RS) images in three Texas fields known to be infested with CRR. Supervised, unsupervised, and combined unsupervised classification methods were evaluated for differentiating CRR from healthy zones of cotton plants. Two new automated classification methods that take advantage of the high resolution inherent in UAV RS images were also evaluated. The results indicated that the new automated methods were up to 8.89% better than conventional classification methods in overall accuracy. One of these new methods, an automated method combining k-means segmentation and morphological opening and closing, provided the best results, with overall accuracy of 88.5% and the lowest errors of omission (11.44%) and commission (16.13%) of all methods considered.
KW  - precision agriculture
KW  - disease detection
KW  - UAV
KW  - cotton root rot
KW  - machine learning
KW  - classification
KW  - image analysis
KW  - semi-supervised
DO  - 10.3390/rs12081310
TY  - EJOU
AU  - Seo, Jihyun
AU  - Ahn, Hanse
AU  - Kim, Daewon
AU  - Lee, Sungju
AU  - Chung, Yongwha
AU  - Park, Daihee
TI  - EmbeddedPigDet—Fast and Accurate Pig Detection for Embedded Board Implementations
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 8
SN  - 2076-3417

AB  - Automated pig monitoring is an important issue in the surveillance environment of a pig farm. For a large-scale pig farm in particular, practical issues such as monitoring cost should be considered but such consideration based on low-cost embedded boards has not yet been reported. Since low-cost embedded boards have more limited computing power than typical PCs and have tradeoffs between execution speed and accuracy, achieving fast and accurate detection of individual pigs for &ldquo;on-device&rdquo; pig monitoring applications is very challenging. Therefore, in this paper, we propose a method for the fast detection of individual pigs by reducing the computational workload of 3 &times; 3 convolution in widely-used, deep learning-based object detectors. Then, in order to recover the accuracy of the &ldquo;light-weight&rdquo; deep learning-based object detector, we generate a three-channel composite image as its input image, through &ldquo;simple&rdquo; image preprocessing techniques. Our experimental results on an NVIDIA Jetson Nano embedded board show that the proposed method can improve the integrated performance of both execution speed and accuracy of widely-used, deep learning-based object detectors, by a factor of up to 8.7.
KW  - agriculture IT
KW  - computer vision
KW  - pig detection
KW  - embedded board
KW  - image preprocessing
KW  - light-weight deep learning
KW  - YOLO
KW  - TinyYOLO
DO  - 10.3390/app10082878
TY  - EJOU
AU  - Ayhan, Bulent
AU  - Kwan, Chiman
TI  - Tree, Shrub, and Grass Classification Using Only RGB Images
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 8
SN  - 2072-4292

AB  - In this work, a semantic segmentation-based deep learning method, DeepLabV3+, is applied to classify three vegetation land covers, which are tree, shrub, and grass using only three band color (RGB) images. DeepLabV3+&rsquo;s detection performance has been studied on low and high resolution datasets that both contain tree, shrub, and grass and some other land cover types. The two datasets are heavily imbalanced where shrub pixels are much fewer than tree and grass pixels. A simple weighting strategy known as median frequency weighting was incorporated into DeepLabV3+ to mitigate the data imbalance issue, which originally used uniform weights. The tree, shrub, grass classification performances are compared when all land cover types are included in the classification and also when classification is limited to the three vegetation classes with both uniform and median frequency weights. Among the three vegetation types, shrub is found to be the most challenging one to classify correctly whereas correct classification accuracy was highest for tree. It is observed that even though the median frequency weighting did not improve the overall accuracy, it resulted in better classification accuracy for the underrepresented classes such as shrub in our case and it also significantly increased the average class accuracy. The classification performance and computation time comparison of DeepLabV3+ with two other pixel-based classification methods on sampled pixels of the three vegetation classes showed that DeepLabV3+ achieves significantly higher accuracy than these methods with a trade-off for longer model training time.
KW  - deep learning
KW  - vegetation classification
KW  - imbalanced data
KW  - median frequency weighting
KW  - DeepLabV3+
DO  - 10.3390/rs12081333
TY  - EJOU
AU  - Pham, Tien D.
AU  - Yokoya, Naoto
AU  - Xia, Junshi
AU  - Ha, Nam T.
AU  - Le, Nga N.
AU  - Nguyen, Thi T.
AU  - Dao, Thi H.
AU  - Vu, Thuy T.
AU  - Pham, Tien D.
AU  - Takeuchi, Wataru
TI  - Comparison of Machine Learning Methods for Estimating Mangrove Above-Ground Biomass Using Multiple Source Remote Sensing Data in the Red River Delta Biosphere Reserve, Vietnam
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 8
SN  - 2072-4292

AB  - This study proposes a hybrid intelligence approach based on an extreme gradient boosting regression and genetic algorithm, namely, the XGBR-GA model, incorporating Sentinel-2, Sentinel-1, and ALOS-2 PALSAR-2 data to estimate the mangrove above-ground biomass (AGB), including small and shrub mangrove patches in the Red River Delta biosphere reserve across the northern coast of Vietnam. We used the novel extreme gradient boosting decision tree (XGBR) technique together with genetic algorithm (GA) optimization for feature selection to construct and verify a mangrove AGB model using data from a field survey of 105 sampling plots conducted in November and December of 2018 and incorporated the dual polarimetric (HH and HV) data of the ALOS-2 PALSAR-2 L-band and the Sentinel-2 multispectral data combined with Sentinel-1 (C-band VV and VH) data. We employed the root-mean-square error (RMSE) and coefficient of determination (R2) to evaluate the performance of the proposed model. The capability of the XGBR-GA model was assessed via a comparison with other machine-learning (ML) techniques, i.e., the CatBoost regression (CBR), gradient boosted regression tree (GBRT), support vector regression (SVR), and random forest regression (RFR) models. The XGBR-GA model yielded a promising result (R2 = 0.683, RMSE = 25.08 Mg&middot;ha&minus;1) and outperformed the four other ML models. The XGBR-GA model retrieved a mangrove AGB ranging from 17 Mg&middot;ha&minus;1 to 142 Mg&middot;ha&minus;1 (with an average of 72.47 Mg&middot;ha&minus;1). Therefore, multisource optical and synthetic aperture radar (SAR) combined with the XGBR-GA model can be used to estimate the mangrove AGB in North Vietnam. The effectiveness of the proposed method needs to be further tested and compared to other mangrove ecosystems in the tropics.
KW  - Sentinel-2
KW  - Sentinel-1
KW  - ALOS-2 PALSAR-2
KW  - mangrove
KW  - above-ground biomass
KW  - extreme gradient boosting regression
KW  - genetic algorithm
KW  - North Vietnam
DO  - 10.3390/rs12081334
TY  - EJOU
AU  - Kouhdaragh, Vahid
AU  - Verde, Francesco
AU  - Gelli, Giacinto
AU  - Abouei, Jamshid
TI  - On the Application of Machine Learning to the Design of UAV-Based 5G Radio Access Networks
T2  - Electronics

PY  - 2020
VL  - 9
IS  - 4
SN  - 2079-9292

AB  - A groundbreaking design of radio access networks (RANs) is needed to fulfill 5G traffic requirements. To this aim, a cost-effective and flexible strategy consists of complementing terrestrial RANs with unmanned aerial vehicles (UAVs). However, several problems must be solved in order to effectively deploy such UAV-based RANs (U-RANs). Indeed, due to the high complexity and heterogeneity of these networks, model-based design approaches, often relying on restrictive assumptions and constraints, exhibit severe limitation in real-world scenarios. Moreover, design of a set of appropriate protocols for such U-RANs is a highly sophisticated task. In this context, machine learning (ML) emerges as a useful tool to obtain practical and effective solutions. In this paper, we discuss why, how, and which types of ML methods are useful for designing U-RANs, by focusing in particular on supervised and reinforcement learning strategies.
KW  - 5G and beyond systems
KW  - machine learning
KW  - radio access networks
KW  - reinforcement learning
KW  - supervised learning
KW  - unmanned aerial vehicles (UAVs)
DO  - 10.3390/electronics9040689
TY  - EJOU
AU  - Alsharif, Mohammed H.
AU  - Kelechi, Anabi H.
AU  - Albreem, Mahmoud A.
AU  - Chaudhry, Shehzad A.
AU  - Zia, M. S.
AU  - Kim, Sunghwan
TI  - Sixth Generation (6G) Wireless Networks: Vision, Research Activities, Challenges and Potential Solutions
T2  - Symmetry

PY  - 2020
VL  - 12
IS  - 4
SN  - 2073-8994

AB  - The standardization activities of the fifth generation communications are clearly over and deployment has commenced globally. To sustain the competitive edge of wireless networks, industrial and academia synergy have begun to conceptualize the next generation of wireless communication systems (namely, sixth generation, (6G)) aimed at laying the foundation for the stratification of the communication needs of the 2030s. In support of this vision, this study highlights the most promising lines of research from the recent literature in common directions for the 6G project. Its core contribution involves exploring the critical issues and key potential features of 6G communications, including: (i) vision and key features; (ii) challenges and potential solutions; and (iii) research activities. These controversial research topics were profoundly examined in relation to the motivation of their various sub-domains to achieve a precise, concrete, and concise conclusion. Thus, this article will contribute significantly to opening new horizons for future research directions.
KW  - wireless networks
KW  - beyond 5G
KW  - 6G
KW  - 6G mobile communication
KW  - terahertz communications
KW  - holographic communications
KW  - terahertz spectrum
KW  - visible-light communications
DO  - 10.3390/sym12040676
TY  - EJOU
AU  - Maimaitijiang, Maitiniyazi
AU  - Sagan, Vasit
AU  - Sidike, Paheding
AU  - Daloye, Ahmad M.
AU  - Erkbol, Hasanjan
AU  - Fritschi, Felix B.
TI  - Crop Monitoring Using Satellite/UAV Data Fusion and Machine Learning
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - Non-destructive crop monitoring over large areas with high efficiency is of great significance in precision agriculture and plant phenotyping, as well as decision making with regards to grain policy and food security. The goal of this research was to assess the potential of combining canopy spectral information with canopy structure features for crop monitoring using satellite/unmanned aerial vehicle (UAV) data fusion and machine learning. Worldview-2/3 satellite data were tasked synchronized with high-resolution RGB image collection using an inexpensive unmanned aerial vehicle (UAV) at a heterogeneous soybean (Glycine max (L.) Merr.) field. Canopy spectral information (i.e., vegetation indices) was extracted from Worldview-2/3 data, and canopy structure information (i.e., canopy height and canopy cover) was derived from UAV RGB imagery. Canopy spectral and structure information and their combination were used to predict soybean leaf area index (LAI), aboveground biomass (AGB), and leaf nitrogen concentration (N) using partial least squares regression (PLSR), random forest regression (RFR), support vector regression (SVR), and extreme learning regression (ELR) with a newly proposed activation function. The results revealed that: (1) UAV imagery-derived high-resolution and detailed canopy structure features, canopy height, and canopy coverage were significant indicators for crop growth monitoring, (2) integration of satellite imagery-based rich canopy spectral information with UAV-derived canopy structural features using machine learning improved soybean AGB, LAI, and leaf N estimation on using satellite or UAV data alone, (3) adding canopy structure information to spectral features reduced background soil effect and asymptotic saturation issue to some extent and led to better model performance, (4) the ELR model with the newly proposed activated function slightly outperformed PLSR, RFR, and SVR in the prediction of AGB and LAI, while RFR provided the best result for N estimation. This study introduced opportunities and limitations of satellite/UAV data fusion using machine learning in the context of crop monitoring.
KW  - data fusion
KW  - machine learning
KW  - activation function
KW  - crop monitoring
KW  - extreme learning machine (ELM)
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/rs12091357
TY  - EJOU
AU  - Schoofs, Hilde
AU  - Delalieux, Stephanie
AU  - Deckers, Tom
AU  - Bylemans, Dany
TI  - Fire Blight Monitoring in Pear Orchards by Unmanned Airborne Vehicles (UAV) Systems Carrying Spectral Sensors
T2  - Agronomy

PY  - 2020
VL  - 10
IS  - 5
SN  - 2073-4395

AB  - Controlling fire blight in pear production areas depends strongly on regular visual inspections of pome fruit orchards, nurseries and other hosts of Erwinia amylovora. In addition, these inspections play an essential role in delineating fire blight free production areas, which has important implications for fruit export. However, visual monitoring is labor intensive and time consuming. As a potential alternative, the performance of spectral sensors on unmanned airborne vehicles (UAV) or drones was evaluated, since this allows the monitoring of larger areas compared to the current field inspections. Unlike more traditional remote sensing platforms such as manned aircrafts and satellites, UAVs offer a higher flexibility and an extremely high level of detail. In this project, a UAV platform carrying a hyperspectral COSI-cam camera was used to map a heavily infected pear orchard. The hyperspectral data were used to assess which wavebands contain information on fire blight infections. In this study, wavelengths 611 nm and 784 nm were found appropriate to detect symptoms associated with fire blight. Vegetation indices that allow to discriminate between healthy and infected trees were identified, too. This manuscript highlights the potential use of the UAV methodology in fire blight detection and remaining difficulties that still need to be overcome for the technique to become fully operational in practice.
KW  - fire blight
KW  - UAV
KW  - spectral sensors
KW  - precision agriculture
DO  - 10.3390/agronomy10050615
TY  - EJOU
AU  - Tang, Ziyang
AU  - Liu, Xiang
AU  - Chen, Hanlin
AU  - Hupy, Joseph
AU  - Yang, Baijian
TI  - Deep Learning Based Wildfire Event Object Detection from 4K Aerial Images Acquired by UAS
T2  - AI

PY  - 2020
VL  - 1
IS  - 2
SN  - 2673-2688

AB  - Unmanned Aerial Systems, hereafter referred to as UAS, are of great use in hazard events such as wildfire due to their ability to provide high-resolution video imagery over areas deemed too dangerous for manned aircraft and ground crews. This aerial perspective allows for identification of ground-based hazards such as spot fires and fire lines, and to communicate this information with fire fighting crews. Current technology relies on visual interpretation of UAS imagery, with little to no computer-assisted automatic detection. With the help of big labeled data and the significant increase of computing power, deep learning has seen great successes on object detection with fixed patterns, such as people and vehicles. However, little has been done for objects, such as spot fires, with amorphous and irregular shapes. Additional challenges arise when data are collected via UAS as high-resolution aerial images or videos; an ample solution must provide reasonable accuracy with low delays. In this paper, we examined 4K (    3840 × 2160    ) videos collected by UAS from a controlled burn and created a set of labeled video sets to be shared for public use. We introduce a coarse-to-fine framework to auto-detect wildfires that are sparse, small, and irregularly-shaped. The coarse detector adaptively selects the sub-regions that are likely to contain the objects of interest while the fine detector passes only the details of the sub-regions, rather than the entire 4K region, for further scrutiny. The proposed two-phase learning therefore greatly reduced time overhead and is capable of maintaining high accuracy. Compared against the real-time one-stage object backbone of YoloV3, the proposed methods improved the mean average precision(mAP) from     0 . 29     to     0 . 67    , with an average inference speed of 7.44 frames per second. Limitations and future work are discussed with regard to the design and the experiment results.
KW  - wildfire detection
KW  - deep learning
KW  - unmanned aerial systems
KW  - high resolution images
KW  - dataset
DO  - 10.3390/ai1020010
TY  - EJOU
AU  - Tian, Yanlin
AU  - Jia, Mingming
AU  - Wang, Zongming
AU  - Mao, Dehua
AU  - Du, Baojia
AU  - Wang, Chao
TI  - Monitoring Invasion Process of Spartina alterniflora by Seasonal Sentinel-2 Imagery and an Object-Based Random Forest Classification
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - In the late 1990s, the exotic plant Spartina alterniflora (S. alterniflora), was introduced to the Zhangjiang Estuary of China for tidal zone reclamation and protection. However, it invaded rapidly and has caused serious ecological problems. Accurate information on the seasonal invasion of S. alterniflora is vital to understand invasion pattern and mechanism, especially at a high temporal resolution. This study aimed to explore the S. alterniflora invasion process at a seasonal scale from 2016 to 2018. However, due to the uncertainties caused by periodic inundation of local tides, accurately monitoring the spatial extent of S. alterniflora is challenging. Thus, to achieve the goal and address the challenge, we firstly built a high-quality seasonal Sentinel-2 image collection by developing a new submerged S. alterniflora index (SAI) to reduce the errors caused by high tide fluctuations. Then, an object-based random forest (RF) classification method was applied to the image collection. Finally, seasonal extents of S. alterniflora were captured. Results showed that (1) the red edge bands (bands 5, 6, and 7) of Sentinel-2 imagery played critical roles in delineating submerged S. alterniflora; (2) during March 2016 to November 2018, the extent of S. alterniflora increased from 151.7 to 270.3 ha, with an annual invasion rate of 39.5 ha; (3) S. alterniflora invaded with a rate of 31.5 ha/season during growing season and 12.1 ha/season during dormant season. To our knowledge, this is the first study monitoring S. alterniflora invasion process at a seasonal scale during continuous years, discovering that S. alterniflora also expands during dormant seasons. This discovery is of great significance for understanding the invasion pattern and mechanism of S. alterniflora and will facilitate coastal biodiversity conservation efforts.
KW  - Spartina alterniflora
KW  - invasion process
KW  - growing season
KW  - dormant season
KW  - Sentinel-2 imagery
DO  - 10.3390/rs12091383
TY  - EJOU
AU  - Sikder, Aisha
AU  - Züfle, Andreas
TI  - Augmenting Geostatistics with Matrix Factorization: A Case Study for House Price Estimation
T2  - ISPRS International Journal of Geo-Information

PY  - 2020
VL  - 9
IS  - 5
SN  - 2220-9964

AB  - Singular value decomposition (SVD) is ubiquitously used in recommendation systems to estimate and predict values based on latent features obtained through matrix factorization. But, oblivious of location information, SVD has limitations in predicting variables that have strong spatial autocorrelation, such as housing prices which strongly depend on spatial properties such as the neighborhood and school districts. In this work, we build an algorithm that integrates the latent feature learning capabilities of truncated SVD with kriging, which is called SVD-Regression Kriging (SVD-RK). In doing so, we address the problem of modeling and predicting spatially autocorrelated data for recommender engines using real estate housing prices by integrating spatial statistics. We also show that SVD-RK outperforms purely latent features based solutions as well as purely spatial approaches like Geographically Weighted Regression (GWR). Our proposed algorithm, SVD-RK, integrates the results of truncated SVD as an independent variable into a regression kriging approach. We show experimentally, that latent house price patterns learned using SVD are able to improve house price predictions of ordinary kriging in areas where house prices fluctuate locally. For areas where house prices are strongly spatially autocorrelated, evident by a house pricing variogram showing that the data can be mostly explained by spatial information only, we propose to feed the results of SVD into a geographically weighted regression model to outperform the orginary kriging approach.
KW  - spatial statistics
KW  - recommender systems
KW  - singular value decomposition
KW  - universal kriging
KW  - regression kriging
DO  - 10.3390/ijgi9050288
TY  - EJOU
AU  - Huang, Yi-Qi
AU  - Zheng, Jia-Chun
AU  - Sun, Shi-Dan
AU  - Yang, Cheng-Fu
AU  - Liu, Jing
TI  - Optimized YOLOv3 Algorithm and Its Application in Traffic Flow Detections
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 9
SN  - 2076-3417

AB  - In the intelligent traffic system, real-time and accurate detections of vehicles in images and video data are very important and challenging work. Especially in situations with complex scenes, different models, and high density, it is difficult to accurately locate and classify these vehicles during traffic flows. Therefore, we propose a single-stage deep neural network YOLOv3-DL, which is based on the Tensorflow framework to improve this problem. The network structure is optimized by introducing the idea of spatial pyramid pooling, then the loss function is redefined, and a weight regularization method is introduced, for that, the real-time detections and statistics of traffic flows can be implemented effectively. The optimization algorithm we use is the DL-CAR data set for end-to-end network training and experiments with data sets under different scenarios and weathers. The analyses of experimental data show that the optimized algorithm can improve the vehicles&rsquo; detection accuracy on the test set by 3.86%. Experiments on test sets in different environments have improved the detection accuracy rate by 4.53%, indicating that the algorithm has high robustness. At the same time, the detection accuracy and speed of the investigated algorithm are higher than other algorithms, indicating that the algorithm has higher detection performance.
KW  - intelligent transportation
KW  - vehicle detection
KW  - traffic flow
KW  - loss function
KW  - YOLOv3 mode
DO  - 10.3390/app10093079
TY  - EJOU
AU  - Mazzia, Vittorio
AU  - Comba, Lorenzo
AU  - Khaliq, Aleem
AU  - Chiaberge, Marcello
AU  - Gay, Paolo
TI  - UAV and Machine Learning Based Refinement of a Satellite-Driven Vegetation Index for Precision Agriculture
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 9
SN  - 1424-8220

AB  - Precision agriculture is considered to be a fundamental approach in pursuing a low-input, high-efficiency, and sustainable kind of agriculture when performing site-specific management practices. To achieve this objective, a reliable and updated description of the local status of crops is required. Remote sensing, and in particular satellite-based imagery, proved to be a valuable tool in crop mapping, monitoring, and diseases assessment. However, freely available satellite imagery with low or moderate resolutions showed some limits in specific agricultural applications, e.g., where crops are grown by rows. Indeed, in this framework, the satellite&rsquo;s output could be biased by intra-row covering, giving inaccurate information about crop status. This paper presents a novel satellite imagery refinement framework, based on a deep learning technique which exploits information properly derived from high resolution images acquired by unmanned aerial vehicle (UAV) airborne multispectral sensors. To train the convolutional neural network, only a single UAV-driven dataset is required, making the proposed approach simple and cost-effective. A vineyard in Serralunga d&rsquo;Alba (Northern Italy) was chosen as a case study for validation purposes. Refined satellite-driven normalized difference vegetation index (NDVI) maps, acquired in four different periods during the vine growing season, were shown to better describe crop status with respect to raw datasets by correlation analysis and ANOVA. In addition, using a K-means based classifier, 3-class vineyard vigor maps were profitably derived from the NDVI maps, which are a valuable tool for growers.
KW  - precision agriculture
KW  - remote sensing
KW  - moderate resolution satellite imagery
KW  - UAV
KW  - convolutional neural network
DO  - 10.3390/s20092530
TY  - EJOU
AU  - Risbøl, Ole
AU  - Langhammer, Daniel
AU  - Schlosser Mauritsen, Esben
AU  - Seitsonen, Oula
TI  - Employment, Utilization, and Development of Airborne Laser Scanning in Fenno-Scandinavian Archaeology—A Review
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - This paper gives a presentation of how airborne laser scanning (ALS) has been adopted in archaeology in the North over the period 2005&ndash;2019. Almost two decades have passed since ALS first emerged as a potential tool to add to the archaeologist&rsquo;s toolbox. Soon after, it attracted the attention of researchers within archaeological communities engaged with remote sensing in the Fenno-Scandinavian region. The first archaeological ALS projects gave immediate good results and led to further use, research, and development through new projects that followed various tracks. The bulk of the research and development focused on studying how well-suited ALS is for identifying, mapping, and documenting archaeological features in outfield land, mainly in forested areas. The poor situation in terms of lack of information on archaeological records in outfield areas has been challenging for research and especially for cultural heritage management for a long period of time. Consequently, an obvious direction was to study how ALS-based mapping of cultural features in forests could help to improve the survey situation. This led to various statistical analyses and studies covering research questions related to for instance effects on detection success of laser pulse density, and the size and shape of the targeted features. Substantial research has also been devoted to the development and assessment of semi-automatic detection of archaeological features based on the use of algorithms. This has been studied as an alternative approach to human desk-based visual analyses and interpretations of ALS data. This approach has considerable potential for detecting sites over large regions such as the vast roadless and unbuilt wilderness regions of northern Fennoscandia, and has proven highly successful. In addition, the current review presents how ALS has been employed for monitoring purposes and for landscape studies, including how it can influence landscape understanding. Finally, the most recent advance within ALS research and development has been discussed: testing of the use of drones for data acquisition. In conclusion, aspects related to the utilization of ALS in archaeological research and cultural heritage management are summarized and discussed, together with thoughts about future perspectives.
KW  - review
KW  - remote sensing
KW  - airborne LiDAR
KW  - mapping
KW  - archaeology
KW  - Fenno-Scandinavia
DO  - 10.3390/rs12091411
TY  - EJOU
AU  - Liu, Longlong
AU  - Ma, Di
AU  - Azar, Ahmad T.
AU  - Zhu, Quanmin
TI  - Neural Computing Enhanced Parameter Estimation for Multi-Input and Multi-Output Total Non-Linear Dynamic Models
T2  - Entropy

PY  - 2020
VL  - 22
IS  - 5
SN  - 1099-4300

AB  - In this paper, a gradient descent algorithm is proposed for the parameter estimation of multi-input and multi-output (MIMO) total non-linear dynamic models. Firstly, the MIMO total non-linear model is mapped to a non-completely connected feedforward neural network, that is, the parameters of the total non-linear model are mapped to the connection weights of the neural network. Then, based on the minimization of network error, a weight-updating algorithm, that is, an estimation algorithm of model parameters, is proposed with the convergence conditions of a non-completely connected feedforward network. In further determining the variables of the model set, a method of model structure detection is proposed for selecting a group of important items from the whole variable candidate set. In order to verify the usefulness of the parameter identification process, we provide a virtual bench test example for the numerical analysis and user-friendly instructions for potential applications.
KW  - parameter estimation
KW  - total non-linear model
KW  - neural networks
KW  - neuro-computing
KW  - gradient descent algorithm
DO  - 10.3390/e22050510
TY  - EJOU
AU  - Augustauskas, Rytis
AU  - Lipnickas, Arūnas
TI  - Improved Pixel-Level Pavement-Defect Segmentation Using a Deep Autoencoder
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 9
SN  - 1424-8220

AB  - Convolutional neural networks perform impressively in complicated computer-vision image-segmentation tasks. Vision-based systems surpass humans in speed and accuracy in quality inspection tasks. Moreover, the maintenance of big infrastructures, such as roads, bridges, or buildings, is tedious and time-demanding work. In this research, we addressed pavement-quality evaluation by pixelwise defect segmentation using a U-Net deep autoencoder. Additionally, to the original neural network architecture, we utilized residual connections, atrous spatial pyramid pooling with parallel and &ldquo;Waterfall&rdquo; connections, and attention gates to perform better defect extraction. The proposed neural network configurations showed a segmentation performance improvement over U-Net with no significant computational overhead. Statistical and visual performance evaluation was taken into consideration for the model comparison. Experiments were conducted on CrackForest, Crack500, GAPs384, and mixed datasets.
KW  - CNN (Convolutional neural networks)
KW  - deep learning
KW  - pavement defects
KW  - residual connection
KW  - attention gate
KW  - atrous spatial pyramid pooling
DO  - 10.3390/s20092557
TY  - EJOU
AU  - Chen, Je-Chian
AU  - Wang, Yu-Min
TI  - Comparing Activation Functions in Modeling Shoreline Variation Using Multilayer Perceptron Neural Network
T2  - Water

PY  - 2020
VL  - 12
IS  - 5
SN  - 2073-4441

AB  - The study has modeled shoreline changes by using a multilayer perceptron (MLP) neural network with the data collected from five beaches in southern Taiwan. The data included aerial survey maps of the Forestry Bureau for years 1982, 2002, and 2006, which served as predictors, while the unmanned aerial vehicle (UAV) surveyed data of 2019 served as the respondent. The MLP was configured using five different activation functions with the aim of evaluating their significance. These functions were Identity, Tahn, Logistic, Exponential, and Sine Functions. The results have shown that the performance of an MLP model may be affected by the choice of an activation function. Logistic and the Tahn activation functions outperformed the other models, with Logistic performing best in three beaches and Tahn having the rest. These findings suggest that the application of machine learning to shoreline changes should be accompanied by an extensive evaluation of the different activation functions.
KW  - neural networks
KW  - shoreline variation
KW  - activation functions
DO  - 10.3390/w12051281
TY  - EJOU
AU  - Segarra, Joel
AU  - Buchaillot, Maria L.
AU  - Araus, Jose L.
AU  - Kefauver, Shawn C.
TI  - Remote Sensing for Precision Agriculture: Sentinel-2 Improved Features and Applications
T2  - Agronomy

PY  - 2020
VL  - 10
IS  - 5
SN  - 2073-4395

AB  - The use of satellites to monitor crops and support their management is gathering increasing attention. The improved temporal, spatial, and spectral resolution of the European Space Agency (ESA) launched Sentinel-2 A + B twin platform is paving the way to their popularization in precision agriculture. Besides the Sentinel-2 A + B constellation technical features the open-access nature of the information they generate, and the available support software are a significant improvement for agricultural monitoring. This paper was motivated by the challenges faced by researchers and agrarian institutions entering this field; it aims to frame remote sensing principles and Sentinel-2 applications in agriculture. Thus, we reviewed the features and uses of Sentinel-2 in precision agriculture, including abiotic and biotic stress detection, and agricultural management. We also compared the panoply of satellites currently in use for land remote sensing that are relevant for agriculture to the Sentinel-2 A + B constellation features. Contrasted with previous satellite image systems, the Sentinel-2 A + B twin platform has dramatically increased the capabilities for agricultural monitoring and crop management worldwide. Regarding crop stress monitoring, Sentinel-2 capacities for abiotic and biotic stresses detection represent a great step forward in many ways though not without its limitations; therefore, combinations of field data and different remote sensing techniques may still be needed. We conclude that Sentinel-2 has a wide range of useful applications in agriculture, yet still with room for further improvements. Current and future ways that Sentinel-2 can be utilized are also discussed.
KW  - Sentinel-2
KW  - remote sensing
KW  - precision agriculture
KW  - crop monitoring
DO  - 10.3390/agronomy10050641
TY  - EJOU
AU  - Silva, Vanessa S.
AU  - Silva, Carlos A.
AU  - Mohan, Midhun
AU  - Cardil, Adrián
AU  - Rex, Franciel E.
AU  - Loureiro, Gabrielle H.
AU  - Almeida, Danilo R.
AU  - Broadbent, Eben N.
AU  - Gorgens, Eric B.
AU  - Dalla Corte, Ana P.
AU  - Silva, Emanuel A.
AU  - Valbuena, Rubén
AU  - Klauberg, Carine
TI  - Combined Impact of Sample Size and Modeling Approaches for Predicting Stem Volume in Eucalyptus spp. Forest Plantations Using Field and LiDAR Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - Light Detection and Ranging (LiDAR) remote sensing has been established as one of the most promising tools for large-scale forest monitoring and mapping. Continuous advances in computational techniques, such as machine learning algorithms, have been increasingly improving our capability to model forest attributes accurately and at high spatial and temporal resolution. While there have been previous studies exploring the use of LiDAR and machine learning algorithms for forest inventory modeling, as yet, no studies have demonstrated the combined impact of sample size and different modeling techniques for predicting and mapping stem total volume in industrial Eucalyptus spp. tree plantations. This study aimed to compare the combined effects of parametric and nonparametric modeling methods for estimating volume in Eucalyptus spp. tree plantation using airborne LiDAR data while varying the reference data (sample size). The modeling techniques were compared in terms of root mean square error (RMSE), bias, and R2 with 500 simulations. The best performance was verified for the ordinary least-squares (OLS) method, which was able to provide comparable results to the traditional forest inventory approaches using only 40% (n = 63; ~0.04 plots/ha) of the total field plots, followed by the random forest (RF) algorithm with identical sample size values. This study provides solutions for increasing the industry efficiency in monitoring and managing forest plantation stem volume for the paper and pulp supply chain.
KW  - LiDAR
KW  - eucalyptus
KW  - forest attributes
KW  - machine learning
KW  - variable selection
DO  - 10.3390/rs12091438
TY  - EJOU
AU  - Cheng, Xuemin
AU  - Ren, Yong
AU  - Cheng, Kaichang
AU  - Cao, Jie
AU  - Hao, Qun
TI  - Method for Training Convolutional Neural Networks for In Situ Plankton Image Recognition and Classification Based on the Mechanisms of the Human Eye
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 9
SN  - 1424-8220

AB  - In this study, we propose a method for training convolutional neural networks to make them identify and classify images with higher classification accuracy. By combining the Cartesian and polar coordinate systems when describing the images, the method of recognition and classification for plankton images is discussed. The optimized classification and recognition networks are constructed. They are available for in situ plankton images, exploiting the advantages of both coordinate systems in the network training process. Fusing the two types of vectors and using them as the input for conventional machine learning models for classification, support vector machines (SVMs) are selected as the classifiers to combine these two features of vectors, coming from different image coordinate descriptions. The accuracy of the proposed model was markedly higher than those of the initial classical convolutional neural networks when using the in situ plankton image data, with the increases in classification accuracy and recall rate being 5.3% and 5.1% respectively. In addition, the proposed training method can improve the classification performance considerably when used on the public CIFAR-10 dataset.
KW  - cartesian and polar coordinate
KW  - classification and recognition
KW  - two features combination
KW  - mechanisms of human eye
KW  - convolutional neural network
DO  - 10.3390/s20092592
TY  - EJOU
AU  - Abdollahi, Abolfazl
AU  - Pradhan, Biswajeet
AU  - Shukla, Nagesh
AU  - Chakraborty, Subrata
AU  - Alamri, Abdullah
TI  - Deep Learning Approaches Applied to Remote Sensing Datasets for Road Extraction: A State-Of-The-Art Review
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - One of the most challenging research subjects in remote sensing is feature extraction, such as road features, from remote sensing images. Such an extraction influences multiple scenes, including map updating, traffic management, emergency tasks, road monitoring, and others. Therefore, a systematic review of deep learning techniques applied to common remote sensing benchmarks for road extraction is conducted in this study. The research is conducted based on four main types of deep learning methods, namely, the GANs model, deconvolutional networks, FCNs, and patch-based CNNs models. We also compare these various deep learning models applied to remote sensing datasets to show which method performs well in extracting road parts from high-resolution remote sensing images. Moreover, we describe future research directions and research gaps. Results indicate that the largest reported performance record is related to the deconvolutional nets applied to remote sensing images, and the F1 score metric of the generative adversarial network model, DenseNet method, and FCN-32 applied to UAV and Google Earth images are high: 96.08%, 95.72%, and 94.59%, respectively.
KW  - road extraction
KW  - common benchmarks
KW  - machine learning
KW  - deep learning
KW  - remote sensing
DO  - 10.3390/rs12091444
TY  - EJOU
AU  - Christias, Panagiotis
AU  - Daliakopoulos, Ioannis N.
AU  - Manios, Thrassyvoulos
AU  - Mocanu, Mariana
TI  - Comparison of Three Computational Approaches for Tree Crop Irrigation Decision Support
T2  - Mathematics

PY  - 2020
VL  - 8
IS  - 5
SN  - 2227-7390

AB  - This paper explores methodologies for developing intelligent automated decision systems for complex processes that contain uncertainties, thus requiring computational intelligence. Irrigation decision support systems (IDSS) promise to increase water efficiency while sustaining crop yields. Here, we explored methodologies for developing intelligent IDSS that exploit statistical, measured, and simulated data. A simple and a fuzzy multicriteria approach as well as a Decision Tree based system were analyzed. The methodologies were applied in a sample of olive tree farms of Heraklion in the island of Crete, Greece, where water resources are scarce and crop management is generally empirical. The objective is to support decision for optimal financial profit through high yield while conserving water resources through optimal irrigation schemes under various (or uncertain) intrinsic and extrinsic conditions. Crop irrigation requirements are modelled using the FAO-56 equation. The results demonstrate that the decision support based on probabilistic and fuzzy approaches point to strategies with low amounts and careful distributed water irrigation strategies. The decision tree shows that decision can be optimized by examining coexisting factors. We conclude that irrigation-based decisions can be highly assisted by methods such as decision trees given the right choice of attributes while keeping focus on the financial balance between cost and revenue.
KW  - DSS
KW  - multicriteria
KW  - fuzzy logic
KW  - decision trees
KW  - ID3
KW  - irrigation management
KW  - olive trees
DO  - 10.3390/math8050717
TY  - EJOU
AU  - Lin, Yao-Chin
AU  - Yeh, Ching-Chuan
AU  - Chen, Wei-Hung
AU  - Hsu, Kai-Yen
TI  - Implementation Criteria for Intelligent Systems in Motor Production Line Process Management
T2  - Processes

PY  - 2020
VL  - 8
IS  - 5
SN  - 2227-9717

AB  - In this study, the factors that affect the implementation of intelligent systems in motor production lines are analyzed. A motor production line located in Vietnam is used as the research object. The research methods include secondary data collection, field study, and interviews. This study demonstrates the following: firstly, the implementation of intelligent systems in motor production lines is heading toward Industry 4.0. Secondly, it is proposed that three functional systems&mdash;robot arm, image recognition, and big data analysis&mdash;can be introduced in the motor production line. This study analyzes the process involved in coil and motor production lines and attempts to combine intelligent system functions. It is expected that in the future, manpower will be reduced, production line productivity will increase, and intelligent production lines will be proposed. The factors that affect the introduction of intelligent systems in motor production lines are improved, and the importance of intelligent systems, which has been rarely considered in previous studies, is highlighted. In the implementation criteria of the intelligent system in the process management of the motor production line, this study provides some suggestions (to coil and motor assembly line) for the production process management. These suggestions can be provided as a reference for production lines that acquaint with intelligent systems.
KW  - intelligent systems
KW  - motor production lines
KW  - process management
DO  - 10.3390/pr8050537
TY  - EJOU
AU  - Adamo, Maria
AU  - Tomaselli, Valeria
AU  - Tarantino, Cristina
AU  - Vicario, Saverio
AU  - Veronico, Giuseppe
AU  - Lucas, Richard
AU  - Blonda, Palma
TI  - Knowledge-Based Classification of Grassland Ecosystem Based on Multi-Temporal WorldView-2 Data and FAO-LCCS Taxonomy
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - Grassland ecosystems can provide a variety of services for humans, such as carbon storage, food production, crop pollination and pest regulation. However, grasslands are today one of the most endangered ecosystems due to land use change, agricultural intensification, land abandonment as well as climate change. The present study explores the performance of a knowledge-driven GEOgraphic-Object&mdash;based Image Analysis (GEOBIA) learning scheme to classify Very High Resolution (VHR) images for natural grassland ecosystem mapping. The classification was applied to a Natura 2000 protected area in Southern Italy. The Food and Agricultural Organization Land Cover Classification System (FAO-LCCS) hierarchical scheme was instantiated in the learning phase of the algorithm. Four multi-temporal WorldView-2 (WV-2) images were classified by combining plant phenology and agricultural practices rules with prior-image spectral knowledge. Drawing on this knowledge, spectral bands and entropy features from one single date (Post Peak of Biomass) were firstly used for multiple-scale image segmentation into Small Objects (SO) and Large Objects (LO). Thereafter, SO were labelled by considering spectral and context-sensitive features from the whole multi-seasonal data set available together with ancillary data. Lastly, the labelled SO were overlaid to LO segments and, in turn, the latter were labelled by adopting FAO-LCCS criteria about the SOs presence dominance in each LO. Ground reference samples were used only for validating the SO and LO output maps. The knowledge driven GEOBIA classifier for SO classification obtained an OA value of 97.35% with an error of 0.04. For LO classification the value was 75.09% with an error of 0.70. At SO scale, grasslands ecosystem was classified with 92.6%, 99.9% and 96.1% of User&rsquo;s, Producer&rsquo;s Accuracy and F1-score, respectively. The findings reported indicate that the knowledge-driven approach not only can be applied for (semi)natural grasslands ecosystem mapping in vast and not accessible areas but can also reduce the costs of ground truth data acquisition. The approach used may provide different level of details (small and large objects in the scene) but also indicates how to design and validate local conservation policies.
KW  - expert knowledge
KW  - Very High Resolution (VHR)
KW  - grasslands ecosystems
KW  - object-based classification
DO  - 10.3390/rs12091447
TY  - EJOU
AU  - Gorkin, Robert
AU  - Adams, Kye
AU  - Berryman, Matthew J.
AU  - Aubin, Sam
AU  - Li, Wanqing
AU  - Davis, Andrew R.
AU  - Barthelemy, Johan
TI  - Sharkeye: Real-Time Autonomous Personal Shark Alerting via Aerial Surveillance
T2  - Drones

PY  - 2020
VL  - 4
IS  - 2
SN  - 2504-446X

AB  - While aerial shark spotting has been a standard practice for beach safety for decades, new technologies offer enhanced opportunities, ranging from drones/unmanned aerial vehicles (UAVs) that provide new viewing capabilities, to new apps that provide beachgoers with up-to-date risk analysis before entering the water. This report describes the Sharkeye platform, a first-of-its-kind project to demonstrate personal shark alerting for beachgoers in the water and on land, leveraging innovative UAV image collection, cloud-hosted machine learning detection algorithms, and reporting via smart wearables. To execute, our team developed a novel detection algorithm trained via machine learning based on aerial footage of real sharks and rays collected at local beaches, hosted and deployed the algorithm in the cloud, and integrated push alerts to beachgoers in the water via a shark app to run on smartwatches. The project was successfully trialed in the field in Kiama, Australia, with over 350 detection events recorded, followed by the alerting of multiple smartwatches simultaneously both on land and in the water, and with analysis capable of detecting shark analogues, rays, and surfers in average beach conditions, and all based on ~1 h of training data in total. Additional demonstrations showed potential of the system to enable lifeguard-swimmer communication, and the ability to create a network on demand to enable the platform. Our system was developed to provide swimmers and surfers with immediate information via smart apps, empowering lifeguards/lifesavers and beachgoers to prevent unwanted encounters with wildlife before it happens.
KW  - UAV
KW  - blimp
KW  - shark spotting
KW  - machine learning
KW  - wearables
DO  - 10.3390/drones4020018
TY  - EJOU
AU  - Sancho Martínez, Jorge
AU  - Fernández, Yadira B.
AU  - Leinster, Paul
AU  - Casado, Mónica R.
TI  - Combining Unmanned Aircraft Systems and Image Processing for Wastewater Treatment Plant Asset Inspection
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - Wastewater treatment plants are essential for preserving the water quality of freshwater and marine ecosystems. It is estimated that, in the UK, as much as 11 billion liters of wastewater are treated on a daily basis. Effective and efficient treatment of wastewater requires treatment plants to be maintained in good condition. Recent studies have highlighted the potential of unmanned aircraft systems (UASs) and image processing to be used in autonomous and automated monitoring systems. However, the combined use of UASs and image processing for wastewater treatment plant inspections has not yet been tested. This paper presents a novel image processing-UAS framework for the identification of failures in trickling filters and activated sludge facilities. The results show that the proposed framework has an accuracy of 95% in the detection of failures in activated sludge assets, with the accuracy ranging between 55% and 81% for trickling filters. These results are promising and they highlight the potential use of the technology for the inspection of wastewater treatment plants.
KW  - trickling filters
KW  - activated sludge
KW  - unmanned aircraft systems
KW  - UASs
KW  - asset inspection
KW  - wastewater treatment plants
KW  - site inspection
DO  - 10.3390/rs12091461
TY  - EJOU
AU  - Condorelli, Francesca
AU  - Rinaudo, Fulvio
AU  - Salvadore, Francesco
AU  - Tagliaventi, Stefano
TI  - A Neural Networks Approach to Detecting Lost Heritage in Historical Video
T2  - ISPRS International Journal of Geo-Information

PY  - 2020
VL  - 9
IS  - 5
SN  - 2220-9964

AB  - Documenting Cultural Heritage through the extraction of 3D measures with photogrammetry is fundamental for the conservation of the memory of the past. However, when the heritage has been lost the only way to recover this information is the use of historical images from archives. The aim of this study is to experiment with new ways to search for architectural heritage in video material and to save the effort of the operator in the archive in terms of efficiency and time. A workflow is proposed to automatically detect lost heritage in film footage using Deep Learning to find suitable images to process with photogrammetry for its 3D virtual reconstruction. The performance of the network was tested on two case studies considering different architectural scenarios, the Tour Saint Jacques which still exists for the tuning of the networks, and Les Halles to test the algorithms on a real case of an architecture which has been destroyed. Despite the poor quantity and low quality of the historical images available for the training of the network, it has been demonstrated that, with few frames, it was possible to reach the same results in terms of performance of a network trained on a large dataset. Moreover, with the introduction of new metrics based on time intervals the measure of the real time saving in terms of human effort was achieved. These findings represent an important innovation in the documentation of destroyed monuments and open new ways to recover information about the past.
KW  - machine learning
KW  - deep learning
KW  - neural networks
KW  - object detection
KW  - video processing and classification
KW  - photogrammetry
KW  - lost cultural heritage
KW  - 3D reconstruction
KW  - open source algorithms
KW  - metric quality assessment
DO  - 10.3390/ijgi9050297
TY  - EJOU
AU  - Morar, Anca
AU  - Moldoveanu, Alin
AU  - Mocanu, Irina
AU  - Moldoveanu, Florica
AU  - Radoi, Ion E.
AU  - Asavei, Victor
AU  - Gradinaru, Alexandru
AU  - Butean, Alex
TI  - A Comprehensive Survey of Indoor Localization Methods Based on Computer Vision
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 9
SN  - 1424-8220

AB  - Computer vision based indoor localization methods use either an infrastructure of static cameras to track mobile entities (e.g., people, robots) or cameras attached to the mobile entities. Methods in the first category employ object tracking, while the others map images from mobile cameras with images acquired during a configuration stage or extracted from 3D reconstructed models of the space. This paper offers an overview of the computer vision based indoor localization domain, presenting application areas, commercial tools, existing benchmarks, and other reviews. It provides a survey of indoor localization research solutions, proposing a new classification based on the configuration stage (use of known environment data), sensing devices, type of detected elements, and localization method. It groups 70 of the most recent and relevant image based indoor localization methods according to the proposed classification and discusses their advantages and drawbacks. It highlights localization methods that also offer orientation information, as this is required by an increasing number of applications of indoor localization (e.g., augmented reality).
KW  - indoor localization
KW  - computer vision
KW  - QR codes
KW  - fiducial markers
KW  - 3D reconstruction
DO  - 10.3390/s20092641
TY  - EJOU
AU  - Adam, George K.
AU  - Petrellis, Nikos
AU  - Garani, Georgia
AU  - Stylianos, Tilemachos
TI  - COTS-Based Architectural Framework for Reliable Real-Time Control Applications in Manufacturing
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 9
SN  - 2076-3417

AB  - The challenge of keeping the development and implementation of real-time control systems reliable and efficient and at the same time, low-cost and low-energy, is getting harder. This is because system designers and developers are faced with the dependability, inflexibility and often high-cost of specialized or custom-built hardware and software components. This research attempts to tackle issues such as the reliability and efficiency of real-time control systems and advance further the current state-of-the-art. For this purpose, a strong emphasis is placed on finding novel efficient solutions based on standardized and commercially available off-the-shelf hardware/software components. In this direction, this research applies credible and feasible methodologies (e.g., model-based design, component-based design, formal verification, real-time scheduling, prototyping, and validation) in an innovative enhanced way. As an important outcome, a versatile integrative design approach and architectural framework (VIDAF) is proposed, which supports the development and implementation of reliable real-time control systems and applications using commercial off-the-shelf (COTS) components. The feasibility and applicability of the proposed system&rsquo;s architecture are evaluated and validated through a system application in embedded real-time control in manufacturing. The research outcomes are expected to have a positive impact on emerging areas such as the Industrial Internet of Things (IIoT).
KW  - control systems
KW  - real-time
KW  - general-purpose
KW  - commercial off-the-shelf
KW  - hardware/software components
KW  - reliability
KW  - availability
KW  - efficiency
KW  - low-cost
DO  - 10.3390/app10093228
TY  - EJOU
AU  - Zhao, Peng
AU  - Wang, Jianzhong
AU  - Kong, Lingren
TI  - Construction and Optimization of Biconnected and Wide-Coverage Topology Based on Node Mobility
T2  - Symmetry

PY  - 2020
VL  - 12
IS  - 5
SN  - 2073-8994

AB  - Constructing a communications topology with fault tolerance and effective coverage plays an important role in wireless sensor networks. This paper is aimed at constructing and maintaining a biconnected topology, while minimizing the movement distance of the nodes and maximizing the coverage of the field of interest. First, it presents a new model with the motion constraint. If the nodes move at distance within the limit value calculated by the model, the topology is always connected, whether the neighbors of nodes are dynamic or static. Secondly, it improves the coverage strategy based on the nearest neighbor rule (NNR) and finds a rule of nodes&rsquo; spreading so that the nodes are distributed evenly and the spacing of the adjacent nodes is controllable. In addition, the nodes move only when necessary according to the added judgment conditions. Consequently, the movement distance is reduced. The simulation results prove the feasibility and effectiveness of the Localized Topology Optimized Method (LTOM) proposed by this paper. The connected indicators of the system&rsquo;s topology during implementing LTOM are consistent, and the transformation of topology by LTOM is symmetric. Compared with the other distributed algorithm, NNR, LTOM reduces the movement distance of nodes, improves the connected probability, and maximizes the coverage of the topological structures under the biconnected conditions.
KW  - biconnected topology
KW  - minimize the movement
KW  - maximize the coverage
KW  - distributed optimization
DO  - 10.3390/sym12050791
TY  - EJOU
AU  - Randazzo, Giovanni
AU  - Barreca, Giovanni
AU  - Cascio, Maria
AU  - Crupi, Antonio
AU  - Fontana, Marco
AU  - Gregorio, Francesco
AU  - Lanza, Stefania
AU  - Muzirafuti, Anselme
TI  - Analysis of Very High Spatial Resolution Images for Automatic Shoreline Extraction and Satellite-Derived Bathymetry Mapping
T2  - Geosciences

PY  - 2020
VL  - 10
IS  - 5
SN  - 2076-3263

AB  - The amount of Earth observation images available to the public has been the main source of information, helping governments and decision-makers tackling the current world&rsquo;s most pressing global challenge. However, a number of highly skilled and qualified personnel are still needed to fill the gap and help turn these data into intelligence. In addition, the accuracy of this intelligence relies on the quality of these images in times of temporal, spatial, and spectral resolution. For the purpose of contributing to the global effort aiming at monitoring natural and anthropic processes affecting coastal areas, we proposed a framework for image processing to extract the shoreline and the shallow water depth on GeoEye-1 satellite image and orthomosaic image acquired by an unmanned aerial vehicle (UAV) on the coast of San Vito Lo Capo, with image preprocessing steps involving orthorectification, atmospheric correction, pan sharpening, and binary imaging for water and non-water pixels analysis. Binary imaging analysis step was followed by automatic instantaneous shoreline extraction on a digital image and satellite-derived bathymetry (SDB) mapping on GeoEye-1 water pixels. The extraction of instantaneous shoreline was conducted automatically in ENVI software using a raster to vector (R2V) algorithm, whereas the SDB was computed in ArcGIS software using a log-band ratio method applied on the satellite image and available field data for calibration and vertical referencing. The results obtained from these very high spatial resolution images demonstrated the ability of remote sensing techniques in providing information where techniques using traditional methods present some limitations, especially due to their inability to map hard-to-reach areas and very dynamic near shoreline waters. We noticed that for the period of 5 years, the shoreline of San Vito Lo Capo sand beach migrated about 15 m inland, indicating the high dynamism of this coastal area. The bathymetric information obtained on the GeoEye-1 satellite image provided water depth until 10 m deep with R2 = 0.753. In this paper, we presented cost-effective and practical methods for automatic shoreline extraction and bathymetric mapping of shallow water, which can be adopted for the management and the monitoring of coastal areas.
KW  - remote sensing
KW  - GeoEye-1
KW  - unmanned aerial vehicle (UAV)
KW  - image processing
KW  - satellite-derived bathymetry (SDB)
KW  - binary imaging analysis
KW  - coastal erosion
KW  - pocket beach
KW  - San Vito Lo Capo
KW  - climate change
DO  - 10.3390/geosciences10050172
TY  - EJOU
AU  - Jiang, Ling
AU  - Hu, Yang
AU  - Xia, Xilin
AU  - Liang, Qiuhua
AU  - Soltoggio, Andrea
AU  - Kabir, Syed R.
TI  - A Multi-Scale Mapping Approach Based on a Deep Learning CNN Model for Reconstructing High-Resolution Urban DEMs
T2  - Water

PY  - 2020
VL  - 12
IS  - 5
SN  - 2073-4441

AB  - The scarcity of high-resolution urban digital elevation model (DEM) datasets, particularly in certain developing countries, has posed a challenge for many water-related applications such as flood risk management. A solution to address this is to develop effective approaches to reconstruct high-resolution DEMs from their low-resolution equivalents that are more widely available. However, the current high-resolution DEM reconstruction approaches mainly focus on natural topography. Few attempts have been made for urban topography, which is typically an integration of complex artificial and natural features. This study proposed a novel multi-scale mapping approach based on convolutional neural network (CNN) to deal with the complex features of urban topography and to reconstruct high-resolution urban DEMs. The proposed multi-scale CNN model was firstly trained using urban DEMs that contained topographic features at different resolutions, and then used to reconstruct the urban DEM at a specified (high) resolution from a low-resolution equivalent. A two-level accuracy assessment approach was also designed to evaluate the performance of the proposed urban DEM reconstruction method, in terms of numerical accuracy and morphological accuracy. The proposed DEM reconstruction approach was applied to a 121 km2 urbanized area in London, United Kingdom. Compared with other commonly used methods, the current CNN-based approach produced superior results, providing a cost-effective innovative method to acquire high-resolution DEMs in other data-scarce regions.
KW  - urban DEM
KW  - high resolution
KW  - deep learning
KW  - convolutional neural network
KW  - multiple scales
KW  - flood modeling
DO  - 10.3390/w12051369
TY  - EJOU
AU  - Fu, Jun
AU  - Yuan, Haikuo
AU  - Zhao, Rongqiang
AU  - Chen, Zhi
AU  - Ren, Luquan
TI  - Peeling Damage Recognition Method for Corn Ear Harvest Using RGB Image
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 10
SN  - 2076-3417

AB  - Corn ear damage caused by peeling significantly influence the output and quality of corn harvest. Ear damage recognition is the basis to adjust working parameters and to reduce damage. Image processing is attracting increasing attentions in the field of agriculture. Conventional image processing methods are difficult to be used for recognizing corn ear damage caused by peeling in field harvesting. To address the this problem, in this paper, we propose a peeling damage recognition method based on RGB image. For our method, we develop a dictionary-learning-based method to recognize corn kernels and a thresholding method to recognize ear damage regions. To obtain better performance, we also develop the corroding algorithm and the expanding algorithm for the post-processing of recognized results. The experimental results demonstrate the practicality and accuracy of the proposed method. This study could provide the theoretical basis to develop online peeling damage detection system for corn ear harvesters.
KW  - corn damage
KW  - peeling damage
KW  - recognition method
KW  - RGB image
KW  - corn ear harvest
DO  - 10.3390/app10103371
TY  - EJOU
AU  - Azimi, Mohsen
AU  - Eslamlou, Armin D.
AU  - Pekcan, Gokhan
TI  - Data-Driven Structural Health Monitoring and Damage Detection through Deep Learning: State-of-the-Art Review
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 10
SN  - 1424-8220

AB  - Data-driven methods in structural health monitoring (SHM) is gaining popularity due to recent technological advancements in sensors, as well as high-speed internet and cloud-based computation. Since the introduction of deep learning (DL) in civil engineering, particularly in SHM, this emerging and promising tool has attracted significant attention among researchers. The main goal of this paper is to review the latest publications in SHM using emerging DL-based methods and provide readers with an overall understanding of various SHM applications. After a brief introduction, an overview of various DL methods (e.g., deep neural networks, transfer learning, etc.) is presented. The procedure and application of vibration-based, vision-based monitoring, along with some of the recent technologies used for SHM, such as sensors, unmanned aerial vehicles (UAVs), etc. are discussed. The review concludes with prospects and potential limitations of DL-based methods in SHM applications.
KW  - deep learning
KW  - machine learning
KW  - structural health monitoring
KW  - crack detection
KW  - damage detection
KW  - data science
KW  - computer vision
DO  - 10.3390/s20102778
TY  - EJOU
AU  - Hong, Suk-Ju
AU  - Kim, Sang-Yeon
AU  - Kim, Eungchan
AU  - Lee, Chang-Hyup
AU  - Lee, Jung-Sup
AU  - Lee, Dong-Soo
AU  - Bang, Jiwoong
AU  - Kim, Ghiseok
TI  - Moth Detection from Pheromone Trap Images Using Deep Learning Object Detectors
T2  - Agriculture

PY  - 2020
VL  - 10
IS  - 5
SN  - 2077-0472

AB  - Diverse pheromones and pheromone-based traps, as well as images acquired from insects captured by pheromone-based traps, have been studied and developed to monitor the presence and abundance of pests and to protect plants. The purpose of this study is to construct models that detect three species of pest moths in pheromone trap images using deep learning object detection methods and compare their speed and accuracy. Moth images in pheromone traps were collected for training and evaluation of deep learning detectors. Collected images were then subjected to a labeling process that defines the ground truths of target objects for their box locations and classes. Because there were a few negative objects in the dataset, non-target insects were labeled as unknown class and images of non-target insects were added to the dataset. Moreover, data augmentation methods were applied to the training process, and parameters of detectors that were pre-trained with the COCO dataset were used as initial parameter values. Seven detectors&mdash;Faster R-CNN ResNet 101, Faster R-CNN ResNet 50, Faster R-CNN Inception v.2, R-FCN ResNet 101, Retinanet ResNet 50, Retinanet Mobile v.2, and SSD Inception v.2 were trained and evaluated. Faster R-CNN ResNet 101 detector exhibited the highest accuracy (mAP as 90.25), and seven different detector types showed different accuracy and speed. Furthermore, when unexpected insects were included in the collected images, a four-class detector with an unknown class (non-target insect) showed lower detection error than a three-class detector.
KW  - pheromone trap
KW  - pest
KW  - moth
KW  - deep learning
KW  - horticulture
KW  - insect detection
DO  - 10.3390/agriculture10050170
TY  - EJOU
AU  - Zhang, Fan
AU  - Hu, Zhenqi
AU  - Fu, Yaokun
AU  - Yang, Kun
AU  - Wu, Qunying
AU  - Feng, Zewei
TI  - A New Identification Method for Surface Cracks from UAV Images Based on Machine Learning in Coal Mining Areas
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 10
SN  - 2072-4292

AB  - Obtaining real-time, objective, and high-precision distribution information of surface cracks in mining areas is the first task for studying the development regularity of surface cracks and evaluating the risk. The complex geological environment in the mining area leads to low accuracy and efficiency of the existing extracting cracks methods from unmanned air vehicle (UAV) images. Therefore, this manuscript proposes a new identification method of surface cracks from UAV images based on machine learning in coal mining areas. First, the acquired UAV image is cut into small sub-images, and divided into four datasets according to the characteristics of background information: Bright Ground, Dark Dround, Withered Vegetation, and Green Vegetation. Then, for each dataset, a training sample is established with cracks and no cracks as labels and the RGB (red, green, and blue) three-band value of the sub-image as feature. Finally, the best machine learning algorithms, dimensionality reduction methods and image processing techniques are obtained through comparative analysis. The results show that using the V-SVM (Support vector machine with V as penalty function) machine learning algorithm, principal component analysis (PCA) to reduce the full features to 95% of the original variance, and image color enhancement by Laplace sharpening, the overall accuracy could reach 88.99%. This proves that the method proposed in this manuscript can achieve high-precision crack extraction from UAV image.
KW  - crack classification
KW  - UAV images
KW  - machine learning
DO  - 10.3390/rs12101571
TY  - EJOU
AU  - Cholula, Uriel
AU  - da Silva, Jorge A.
AU  - Marconi, Thiago
AU  - Thomasson, J. A.
AU  - Solorzano, Jorge
AU  - Enciso, Juan
TI  - Forecasting Yield and Lignocellulosic Composition of Energy Cane Using Unmanned Aerial Systems
T2  - Agronomy

PY  - 2020
VL  - 10
IS  - 5
SN  - 2073-4395

AB  - Crop monitoring and appropriate agricultural management practices of elite germplasm will enhance bioenergy&rsquo;s efficiency. Unmanned aerial systems (UAS) may be a useful tool for this purpose. The objective of this study was to assess the use of UAS with true color and multispectral imagery to predict the yield and total cellulosic content (TCC) of newly created energy cane germplasm. A trial was established in the growing season of 2016 at the Texas A&amp;M AgriLife Research Center in Weslaco, Texas, where 15 energy cane elite lines and three checks were grown on experimental plots, arranged in a complete block design and replicated four times. Four flights were executed at different growth stages in 2018, at the first ratoon crop, using two multi-rotor UAS: the DJI Phantom 4 Pro equipped with RGB camera and the DJI Matrice 100, equipped with multispectral sensor (SlantRange 3p). Canopy cover, canopy height, NDVI (Normalized Difference Vegetation Index), and ExG (Excess Green Index) were extracted from the images and used to perform a stepwise regression to obtain the yield and TCC models. The results showed a good agreement between the predicted and the measured yields (R2 = 0.88); however, a low coefficient of determination was found between the predicted and the observed TCC (R2 = 0.30). This study demonstrated the potential application of UAS to estimate energy cane yield with high accuracy, enabling plant breeders to phenotype larger populations and make selections with higher confidence.
KW  - energy cane
KW  - NDVI
KW  - ExG
KW  - yield
KW  - total cellulosic content
DO  - 10.3390/agronomy10050718
TY  - EJOU
AU  - Thompson, Laura J.
AU  - Puntel, Laila A.
TI  - Transforming Unmanned Aerial Vehicle (UAV) and Multispectral Sensor into a Practical Decision Support System for Precision Nitrogen Management in Corn
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 10
SN  - 2072-4292

AB  - Determining the optimal nitrogen (N) rate in corn remains a critical issue, mainly due to unaccounted spatial (e.g., soil properties) and temporal (e.g., weather) variability. Unmanned aerial vehicles (UAVs) equipped with multispectral sensors may provide opportunities to improve N management by the timely informing of spatially variable, in-season N applications. Here, we developed a practical decision support system (DSS) to translate spatial field characteristics and normalized difference red edge (NDRE) values into an in-season N application recommendation. On-farm strip-trials were established at three sites over two years to compare farmer&rsquo;s traditional N management to a split-application N management guided by our UAV sensor-based DSS. The proposed systems increased nitrogen use efficiency 18.3 &plusmn; 6.1 kg grain kg N&minus;1 by reducing N rates by 31 &plusmn; 6.3 kg N ha&minus;1 with no yield differences compared to the farmers&rsquo; traditional management. We identify five avenues for further improvement of the proposed DSS: definition of the initial base N rate, estimation of inputs for sensor algorithms, management zone delineation, high-resolution image normalization approach, and the threshold for triggering N application. Two virtual reference (VR) methods were compared with the high N (HN) reference strip method for normalizing high-resolution sensor data. The VR methods resulted in significantly lower sufficiency index values than those generated by the HN reference, resulting in N fertilization recommendations that were 31.4 &plusmn; 10.3 kg ha&minus;1 higher than the HN reference N fertilization recommendation. The use of small HN reference blocks in contrasting management zones may be more appropriate to translate field-scale, high-resolution imagery into in-season N recommendations. In view of a growing interest in using UAVs in commercial fields and the need to improve crop NUE, further work is needed to refine approaches for translating imagery into in-season N recommendations.
KW  - precision ag
KW  - UAV
KW  - spatial variability
KW  - NDRE
KW  - nitrogen
KW  - on-farm
KW  - corn
KW  - multispectral sensor
KW  - site-specific management
KW  - nitrogen use efficiency
DO  - 10.3390/rs12101597
TY  - EJOU
AU  - Franko, Josef
AU  - Du, Shengzhi
AU  - Kallweit, Stephan
AU  - Duelberg, Enno
AU  - Engemann, Heiko
TI  - Design of a Multi-Robot System for Wind Turbine Maintenance
T2  - Energies

PY  - 2020
VL  - 13
IS  - 10
SN  - 1996-1073

AB  - The maintenance of wind turbines is of growing importance considering the transition to renewable energy. This paper presents a multi-robot-approach for automated wind turbine maintenance including a novel climbing robot. Currently, wind turbine maintenance remains a manual task, which is monotonous, dangerous, and also physically demanding due to the large scale of wind turbines. Technical climbers are required to work at significant heights, even in bad weather conditions. Furthermore, a skilled labor force with sufficient knowledge in repairing fiber composite material is rare. Autonomous mobile systems enable the digitization of the maintenance process. They can be designed for weather-independent operations. This work contributes to the development and experimental validation of a maintenance system consisting of multiple robotic platforms for a variety of tasks, such as wind turbine tower and rotor blade service. In this work, multicopters with vision and LiDAR sensors for global inspection are used to guide slower climbing robots. Light-weight magnetic climbers with surface contact were used to analyze structure parts with non-destructive inspection methods and to locally repair smaller defects. Localization was enabled by adapting odometry for conical-shaped surfaces considering additional navigation sensors. Magnets were suitable for steel towers to clamp onto the surface. A friction-based climbing ring robot (SMART&mdash; Scanning, Monitoring, Analyzing, Repair and Transportation) completed the set-up for higher payload. The maintenance period could be extended by using weather-proofed maintenance robots. The multi-robot-system was running the Robot Operating System (ROS). Additionally, first steps towards machine learning would enable maintenance staff to use pattern classification for fault diagnosis in order to operate safely from the ground in the future.
KW  - wind turbine maintenance
KW  - climbing robot
KW  - low cost
KW  - weather independent operations
KW  - condition monitoring
KW  - odometry on wind turbines
DO  - 10.3390/en13102552
TY  - EJOU
AU  - Bahaghighat, Mahdi
AU  - Xin, Qin
AU  - Motamedi, Seyed A.
AU  - Zanjireh, Morteza M.
AU  - Vacavant, Antoine
TI  - Estimation of Wind Turbine Angular Velocity Remotely Found on Video Mining and Convolutional Neural Network
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 10
SN  - 2076-3417

AB  - Today, energy issues are more important than ever. Because of the importance of environmental concerns, clean and renewable energies such as wind power have been most welcomed globally, especially in developing countries. Worldwide development of these technologies leads to the use of intelligent systems for monitoring and maintenance purposes. Besides, deep learning as a new area of machine learning is sharply developing. Its strong performance in computer vision problems has conducted us to provide a high accuracy intelligent machine vision system based on deep learning to estimate the wind turbine angular velocity, remotely. This velocity along with other information such as pitch angle and yaw angle can be used to estimate the wind farm energy production. For this purpose, we have used SSD (Single Shot Multi-Box Detector) object detection algorithm and some specific classification methods based on DenseNet, SqueezeNet, ResNet50, and InceptionV3 models. The results indicate that the proposed system can estimate rotational speed with about     99.05 %     accuracy.
KW  - machine vision
KW  - deep learning
KW  - object detection
KW  - image classification
KW  - remote sensing
KW  - wind turbine
KW  - WTCM
KW  - angular velocity
DO  - 10.3390/app10103544
TY  - EJOU
AU  - Sagang, Le Bienfaiteur T.
AU  - Ploton, Pierre
AU  - Sonké, Bonaventure
AU  - Poilvé, Hervé
AU  - Couteron, Pierre
AU  - Barbier, Nicolas
TI  - Airborne Lidar Sampling Pivotal for Accurate Regional AGB Predictions from Multispectral Images in Forest-Savanna Landscapes
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 10
SN  - 2072-4292

AB  - Precise accounting of carbon stocks and fluxes in tropical vegetation using remote sensing approaches remains a challenging exercise, as both signal saturation and ground sampling limitations contribute to inaccurate extrapolations. Airborne LiDAR Scanning (ALS) data can be used as an intermediate level to radically increase sampling and enhance model calibration. Here we tested the potential of using ALS data for upscaling vegetation aboveground biomass (AGB) from field plots to a forest-savanna transitional landscape in the Guineo&ndash;Congolian region in Cameroon, using either a design-based approach or a model-based approach leveraging multispectral satellite imagery. Two sets of reference data were used: (1) AGB values collected from 62 0.16-ha plots distributed both in forests and savannas; and (2) an AGB map generated form ALS data. In the model-based approach, we trained Random Forest models using predictors from recent sensors of varying spectral and spatial resolutions (Spot 6/7, Landsat 8, and Sentinel 2), along with biophysical predictors derived after pre-processing into the Overland processing chain, following a forward variable selection procedure with a spatial 4-folds cross validation. The models calibrated with field plots lead to a systematic overestimation in AGB density estimates and a root mean squared prediction error (RMSPE) of up to 65 Mg.ha&minus;1 (90%), whereas calibration with ALS lead to low bias and a drop of ~30% in RMSPE (down to 43 Mg.ha&minus;1, 58%) with little effect of the satellite sensor used. Decomposing bias along the AGB density range, we show that multispectral images can (in some specific cases) be used for unbiased prediction at landscape scale on the basis of ALS-calibrated statistical models. However, our results also confirm that, whatever the spectral indices used and attention paid to sensor quality and pre-processing, the signal is not sufficient to warrant accurate pixelwise predictions, because of large relative RMSPE, especially above (200&ndash;250 t/ha). The design-based approach, for which average AGB density values were attributed to mapped land cover classes, proved to be a simple and reliable alternative (for landscape to region level estimations), when trained with dense ALS samples.
KW  - forest-savanna mosaics
KW  - AGB
KW  - Airborne LiDAR
KW  - satellite
KW  - upscaling
KW  - model-based
KW  - design-based
KW  - bias
DO  - 10.3390/rs12101637
TY  - EJOU
AU  - Deng, Xiaoling
AU  - Tong, Zejing
AU  - Lan, Yubin
AU  - Huang, Zixiao
TI  - Detection and Location of Dead Trees with Pine Wilt Disease Based on Deep Learning and UAV Remote Sensing
T2  - AgriEngineering

PY  - 2020
VL  - 2
IS  - 2
SN  - 2624-7402

AB  - Pine wilt disease causes huge economic losses to pine wood forestry because of its destructiveness and rapid spread. This paper proposes a detection and location method of pine wood nematode disease at a large scale adopting UAV (Unmanned Aerial Vehicle) remote sensing and artificial intelligence technology. The UAV remote sensing images were enhanced by computer vision tools. A Faster-RCNN (Faster Region Convolutional Neural Networks) deep learning framework based on a RPN (Region Proposal Network) network and the ResNet residual neural network were used to train the pine wilt diseased dead tree detection model. The loss function and the anchors in the RPN of the convolutional neural network were optimized. Finally, the location of pine wood nematode dead tree was conducted, which generated the geographic information on the detection results. The results show that ResNet101 performed better than VGG16 (Visual Geometry Group 16) convolutional neural network. The detection accuracy was improved and reached to about 90% after a series of optimizations to the network, meaning that the optimization methods proposed in this paper are feasible to pine wood nematode dead tree detection.
KW  - pine wilt disease
KW  - Faster-RCNN
KW  - UAV remote sensing
KW  - deep learning
KW  - geographical information
DO  - 10.3390/agriengineering2020019
TY  - EJOU
AU  - Iizuka, Kotaro
AU  - Hayakawa, Yuichi S.
AU  - Ogura, Takuro
AU  - Nakata, Yasutaka
AU  - Kosugi, Yoshiko
AU  - Yonehara, Taichiro
TI  - Integration of Multi-Sensor Data to Estimate Plot-Level Stem Volume Using Machine Learning Algorithms–Case Study of Evergreen Conifer Planted Forests in Japan
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 10
SN  - 2072-4292

AB  - The development of new methods for estimating precise forest structure parameters is essential for the quantitative evaluation of forest resources. Conventional use of satellite image data, increasing use of terrestrial laser scanning (TLS), and emerging trends in the use of unmanned aerial systems (UASs) highlight the importance of modern technologies in the realm of forest observation. Each technology has different advantages, and this work seeks to incorporate multiple satellite, TLS- and UAS-based remote sensing data sets to improve the ability to estimate forest structure parameters. In this paper, two regression analysis approaches are considered for the estimation: random forest regression (RFR) and support vector regression (SVR). To collect the dependent variable, in situ measurements of individual tree parameters (tree height and diameter at breast height (DBH)) were taken in a Japanese cypress forest using the nondestructive TLS method, which scans the forest to obtain dense and accurate point clouds under the tree canopy. Based on the TLS data, the stem volume was then computed and treated as ground truth information. Topographic and UAS information was then used to calculate various remotely sensed explanatory variables, such as canopy size, canopy cover, and tree height. Canopy cover and canopy shapes were computed via the orthoimages derived from the UAS and watershed segmentation method, respectively. Tree height was computed by combining the digital surface model (DSM) from the UAS and the digital terrain model (DTM) from the TLS data. Topographic variables were computed from the DTM. The backscattering intensity in the satellite imagery was obtained based on L-band (Advanced Land Observing Satellite-2 (ALOS-2) Phased Array type L-band Synthetic Aperture Radar-2 (PALSAR-2)) and C-band (Sentinel-1) synthetic aperture radar (SAR). All satellite (10&ndash;25 m resolution), TLS (3.4 mm resolution) and UAS (2.3&ndash;4.6 cm resolution) data were then combined, and RFR and SVR were trained; the resulting predictive powers were then compared. The RFR method yielded fitting R2 up to 0.665 and RMSE up to 66.87 m3/ha (rRMSE = 11.95%) depending on the input variables (best result with canopy height, canopy size, canopy cover, and Sentinel-1 data), and the SVR method showed fitting R2 up to 0.519 and RMSE up to 80.12 m3/ha (rRMSE = 12.67%). The RFR outperformed the SVR method, which could delineate the relationship between the variables for better model accuracy. This work has demonstrated that incorporating various remote sensing data to satellite data, especially adding finer resolution data, can provide good estimates of forest parameters at a plot level (10 by 10 m), potentially allowing advancements in precision forestry.
KW  - UAS
KW  - stem volume
KW  - TLS
KW  - SAR
KW  - random forest
KW  - support vector
KW  - multiple regression
KW  - forest
KW  - biophysical parameter
DO  - 10.3390/rs12101649
TY  - EJOU
AU  - Ciaburro, Giuseppe
AU  - Iannace, Gino
AU  - Trematerra, Amelia
TI  - Research for the Presence of Unmanned Aerial Vehicle inside Closed Environments with Acoustic Measurements
T2  - Buildings

PY  - 2020
VL  - 10
IS  - 5
SN  - 2075-5309

AB  - Small UAVs (unmanned aerial vehicle) can be used in many sectors such as the acquisition of images or the transport of objects. Small UAVs have also been used for terrorist activities or to disturb the flight of airplanes. Due to the small size and the presence of only rotating parts, drones escape traditional controls and therefore represent a danger. This paper reports a methodology for identifying the presence of small UAVs inside a closed environment by measuring the noise emitted during the flight. Acoustic measurements of the noise emitted by a drone inside a large environment (12.0 &times; 30.0 &times; 12.0 m) were performed. The noise was measured with a sound level meter placed at different distances (5, 10, and 15 m), to characterize the noise in the absence of anthropic noise. In this configuration, a typical tonal component of drone noise is highlighted at the frequency of one-third of an octave at 5000 Hz due to the rotation of the blades. This component is also present 15 m away from the source point. Subsequent measurements were performed by introducing into the environment, through a loudspeaker, the anthropogenic noise produced by the buzz of people and background music. It is possible to distinguish the typical tonal component of UAV noise at the frequency of 5000 Hz even when the level of recording of anthropogenic noise emitted by the loudspeaker is at the maximum power tested. It is therefore possible to search for the presence of small UAVs inside a specific closed environment with only acoustic measurements, paying attention to the typical frequency of noise emission equal to 5000 Hz.
KW  - UAV
KW  - frequency
KW  - acoustic measurements
KW  - noise
KW  - closed environments
DO  - 10.3390/buildings10050096
TY  - EJOU
AU  - Wei, Marcelo C.
AU  - Maldaner, Leonardo F.
AU  - Ottoni, Pedro M.
AU  - Molin, José P.
TI  - Carrot Yield Mapping: A Precision Agriculture Approach Based on Machine Learning
T2  - AI

PY  - 2020
VL  - 1
IS  - 2
SN  - 2673-2688

AB  - Carrot yield maps are an essential tool in supporting decision makers in improving their agricultural practices, but they are unconventional and not easy to obtain. The objective was to develop a method to generate a carrot yield map applying a random forest (RF) regression algorithm on a database composed of satellite spectral data and carrot ground-truth yield sampling. Georeferenced carrot yield sampling was carried out and satellite imagery was obtained during crop development. The entire dataset was split into training and test sets. The Gini index was used to find the five most important predictor variables of the model. Statistical parameters used to evaluate model performance were the root mean squared error (RMSE), coefficient of determination (R2) and mean absolute error (MAE). The five most important predictor variables were the near-infrared spectral band at 92 and 79 days after sowing (DAS), green spectral band at 50 DAS and blue spectral band at 92 and 81 DAS. The RF algorithm applied to the entire dataset presented R2, RMSE and MAE values of 0.82, 2.64 Mg ha&minus;1 and 1.74 Mg ha&minus;1, respectively. The method based on RF regression applied to a database composed of spectral bands proved to be accurate and suitable to predict carrot yield.
KW  - horticultural crops
KW  - random forest regression
KW  - remote sensing
KW  - satellite imagery
KW  - spectral bands
KW  - yield estimation
KW  - yield forecast
DO  - 10.3390/ai1020015
TY  - EJOU
AU  - Pradhan, Biswajeet
AU  - Al-Najjar, Husam A. H.
AU  - Sameen, Maher I.
AU  - Tsang, Ivor
AU  - Alamri, Abdullah M.
TI  - Unseen Land Cover Classification from High-Resolution Orthophotos Using Integration of Zero-Shot Learning and Convolutional Neural Networks
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 10
SN  - 2072-4292

AB  - Zero-shot learning (ZSL) is an approach to classify objects unseen during the training phase and shown to be useful for real-world applications, especially when there is a lack of sufficient training data. Only a limited amount of works has been carried out on ZSL, especially in the field of remote sensing. This research investigates the use of a convolutional neural network (CNN) as a feature extraction and classification method for land cover mapping using high-resolution orthophotos. In the feature extraction phase, we used a CNN model with a single convolutional layer to extract discriminative features. In the second phase, we used class attributes learned from the Word2Vec model (pre-trained by Google News) to train a second CNN model that performed class signature prediction by using both the features extracted by the first CNN and class attributes during training and only the features during prediction. We trained and tested our models on datasets collected over two subareas in the Cameron Highlands (training dataset, first test dataset) and Ipoh (second test dataset) in Malaysia. Several experiments have been conducted on the feature extraction and classification models regarding the main parameters, such as the network&rsquo;s layers and depth, number of filters, and the impact of Gaussian noise. As a result, the best models were selected using various accuracy metrics such as top-k categorical accuracy for k = [1,2,3], Recall, Precision, and F1-score. The best model for feature extraction achieved 0.953 F1-score, 0.941 precision, 0.882 recall for the training dataset and 0.904 F1-score, 0.869 precision, 0.949 recall for the first test dataset, and 0.898 F1-score, 0.870 precision, 0.838 recall for the second test dataset. The best model for classification achieved an average of 0.778 top-one, 0.890 top-two and 0.942 top-three accuracy, 0.798 F1-score, 0.766 recall and 0.838 precision for the first test dataset and 0.737 top-one, 0.906 top-two, 0.924 top-three, 0.729 F1-score, 0.676 recall and 0.790 precision for the second test dataset. The results demonstrated that the proposed ZSL is a promising tool for land cover mapping based on high-resolution photos.
KW  - land cover classification
KW  - deep-learning
KW  - CNN
KW  - Zero-Shot Learning
KW  - remote sensing
KW  - orthophotos
DO  - 10.3390/rs12101676
TY  - EJOU
AU  - Fuentes, Sigfredo
AU  - Gonzalez Viejo, Claudia
AU  - Cullen, Brendan
AU  - Tongson, Eden
AU  - Chauhan, Surinder S.
AU  - Dunshea, Frank R.
TI  - Artificial Intelligence Applied to a Robotic Dairy Farm to Model Milk Productivity and Quality based on Cow Data and Daily Environmental Parameters
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 10
SN  - 1424-8220

AB  - Increased global temperatures and climatic anomalies, such as heatwaves, as a product of climate change, are impacting the heat stress levels of farm animals. These impacts could have detrimental effects on the milk quality and productivity of dairy cows. This research used four years of data from a robotic dairy farm from 36 cows with similar heat tolerance (Model 1), and all 312 cows from the farm (Model 2). These data consisted of programmed concentrate feed and weight combined with weather parameters to develop supervised machine learning fitting models to predict milk yield, fat and protein content, and actual cow concentrate feed intake. Results showed highly accurate models, which were developed for cows with a similar genetic heat tolerance (Model 1: n = 116, 456; R = 0.87; slope = 0.76) and for all cows (Model 2: n = 665, 836; R = 0.86; slope = 0.74). Furthermore, an artificial intelligence (AI) system was proposed to increase or maintain a targeted level of milk quality by reducing heat stress that could be applied to a conventional dairy farm with minimal technology addition.
KW  - machine learning
KW  - heat stress
KW  - animal welfare
KW  - climate change
KW  - automation
DO  - 10.3390/s20102975
TY  - EJOU
AU  - Teso-Fz-Betoño, Daniel
AU  - Zulueta, Ekaitz
AU  - Sánchez-Chica, Ander
AU  - Fernandez-Gamiz, Unai
AU  - Saenz-Aguirre, Aitor
TI  - Semantic Segmentation to Develop an Indoor Navigation System for an Autonomous Mobile Robot
T2  - Mathematics

PY  - 2020
VL  - 8
IS  - 5
SN  - 2227-7390

AB  - In this study, a semantic segmentation network is presented to develop an indoor navigation system for a mobile robot. Semantic segmentation can be applied by adopting different techniques, such as a convolutional neural network (CNN). However, in the present work, a residual neural network is implemented by engaging in ResNet-18 transfer learning to distinguish between the floor, which is the navigation free space, and the walls, which are the obstacles. After the learning process, the semantic segmentation floor mask is used to implement indoor navigation and motion calculations for the autonomous mobile robot. This motion calculations are based on how much the estimated path differs from the center vertical line. The highest point is used to move the motors toward that direction. In this way, the robot can move in a real scenario by avoiding different obstacles. Finally, the results are collected by analyzing the motor duty cycle and the neural network execution time to review the robot&rsquo;s performance. Moreover, a different net comparison is made to determine other architectures&rsquo; reaction times and accuracy values.
KW  - indoor navigation
KW  - semantic segmentation
KW  - fully convolutional networks
KW  - obstacle detection
KW  - autonomous mobile robot
KW  - ResNet
KW  - Unet
KW  - Segnet
DO  - 10.3390/math8050855
TY  - EJOU
AU  - Hu, Tianyu
AU  - Zhang, YingYing
AU  - Su, Yanjun
AU  - Zheng, Yi
AU  - Lin, Guanghui
AU  - Guo, Qinghua
TI  - Mapping the Global Mangrove Forest Aboveground Biomass Using Multisource Remote Sensing Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 10
SN  - 2072-4292

AB  - Mangrove forest ecosystems are distributed at the land&ndash;sea interface in tropical and subtropical regions and play an important role in carbon cycles and biodiversity. Accurately mapping global mangrove aboveground biomass (AGB) will help us understand how mangrove ecosystems are affected by the impacts of climatic change and human activities. Light detection and ranging (LiDAR) techniques have been proven to accurately capture the three-dimensional structure of mangroves and LiDAR can estimate forest AGB with high accuracy. In this study, we produced a global mangrove forest AGB map for 2004 at a 250-m resolution by combining ground inventory data, spaceborne LiDAR, optical imagery, climate surfaces, and topographic data with random forest, a machine learning method. From the published literature and free-access datasets of mangrove biomass, we selected 342 surface observations to train and validate the mangrove AGB estimation model. Our global mangrove AGB map showed that average global mangrove AGB density was 115.23 Mg/ha, with a standard deviation of 48.89 Mg/ha. Total global AGB storage within mangrove forests was 1.52 Pg. Cross-validation with observed data demonstrated that our mangrove AGB estimates were reliable. The adjusted coefficient of determination (R2) and root-mean-square error (RMSE) were 0.48 and 75.85 Mg/ha, respectively. Our estimated global mangrove AGB storage was similar to that predicted by previous remote sensing methods, and remote sensing approaches can overcome overestimates from climate-based models. This new biomass map provides information that can help us understand the global mangrove distribution, while also serving as a baseline to monitor trends in global mangrove biomass.
KW  - mangrove
KW  - LiDAR
KW  - random forest
KW  - GLAS
KW  - aboveground biomass
DO  - 10.3390/rs12101690
TY  - EJOU
AU  - Zhang, Tuqian
TI  - Fault Recovery Path Analysis of a Software Dynamic Image Based on a Fuzzy Control Algorithm
T2  - Symmetry

PY  - 2020
VL  - 12
IS  - 6
SN  - 2073-8994

AB  - In order to improve the ability of software dynamic image fault detection, a software dynamic image fault recovery path detection algorithm based on a fuzzy control algorithm is proposed. A software dynamic image fault signal model of a software dynamic image fault was constructed by adopting an embedded feature extraction and a fuzzy control algorithm, and the dynamic image fault signal of the embedded software under the multi-load was subjected to frequency spectrum decomposition and blind source separation. The method comprises the following steps: (1) carrying out noise reduction processing on a software dynamic image fault signal by adopting a multi-dimensional wavelet decomposition method, (2) carrying out wavelet entropy feature extraction on the software dynamic image fault signal of the noise reduction output, and (3) combining the wavelet structural feature recombination method to carry out the recombination of the software dynamic image fault feature. The high-order spectral characteristic of the software dynamic image fault signal was extracted and the high-order spectral characteristic of the extracted embedded software dynamic image fault recovery path was automatically matched, and the automatic identification and detection of the fault part of the software dynamic image was realized.
KW  - fuzzy control
KW  - embedded software
KW  - dynamic image fault
KW  - fault
KW  - identification
DO  - 10.3390/sym12060897
TY  - EJOU
AU  - Mielcarek, Miłosz
AU  - Kamińska, Agnieszka
AU  - Stereńczak, Krzysztof
TI  - Digital Aerial Photogrammetry (DAP) and Airborne Laser Scanning (ALS) as Sources of Information about Tree Height: Comparisons of the Accuracy of Remote Sensing Methods for Tree Height Estimation
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 11
SN  - 2072-4292

AB  - The rapid developments in the field of digital aerial photogrammetry (DAP) in recent years have increased interest in the application of DAP data for extracting three-dimensional (3D) models of forest canopies. This technology, however, still requires further investigation to confirm its reliability in estimating forest attributes in complex forest conditions. The main purpose of this study was to evaluate the accuracy of tree height estimation based on a crown height model (CHM) generated from the difference between a DAP-derived digital surface model (DSM) and an airborne laser scanning (ALS)-derived digital terrain model (DTM). The tree heights determined based on the DAP-CHM were compared with ground-based measurements and heights obtained using ALS data only (ALS-CHM). Moreover, tree- and stand-related factors were examined to evaluate the potential influence on the obtained discrepancies between ALS- and DAP-derived heights. The obtained results indicate that the differences between the means of field-measured heights and DAP-derived heights were statistically significant. The root mean square error (RMSE) calculated in the comparison of field heights and DAP-derived heights was 1.68 m (7.34%). The results obtained for the CHM generated using only ALS data produced slightly lower errors, with RMSE = 1.25 m (5.46%) on average. Both ALS and DAP displayed the tendency to underestimate tree heights compared to those measured in the field; however, DAP produced a higher bias (1.26 m) than ALS (0.88 m). Nevertheless, DAP heights were highly correlated with the heights measured in the field (R2 = 0.95) and ALS-derived heights (R2 = 0.97). Tree species and height difference (the difference between the reference tree height and mean tree height in a sample plot) had the greatest influence on the differences between ALS- and DAP-derived heights. Our study confirms that a CHM computed based on the difference between a DAP-derived DSM and an ALS-derived DTM can be successfully used to measure the height of trees in the upper canopy layer.
KW  - DAP
KW  - ALS
KW  - CHM
KW  - tree height
KW  - forestry
KW  - photogrammetry
KW  - stereomatching
DO  - 10.3390/rs12111808
TY  - EJOU
AU  - Błaszczak-Bąk, Wioleta
AU  - Janicka, Joanna
AU  - Suchocki, Czesław
AU  - Masiero, Andrea
AU  - Sobieraj-Żłobińska, Anna
TI  - Down-Sampling of Large LiDAR Dataset in the Context of Off-Road Objects Extraction
T2  - Geosciences

PY  - 2020
VL  - 10
IS  - 6
SN  - 2076-3263

AB  - Nowadays, LiDAR (Light Detection and Ranging) is used in many fields, such as transportation. Thanks to the recent technological improvements, the current generation of LiDAR mapping instruments available on the market allows to acquire up to millions of three-dimensional (3D) points per second. On the one hand, such improvements allowed the development of LiDAR-based systems with increased productivity, enabling the quick acquisition of detailed 3D descriptions of the objects of interest. However, on the other hand, the extraction of the information of interest from such huge amount of acquired data can be quite challenging and time demanding. Motivated by such observation, this paper proposes the use of the Optimum Dataset method in order to ease and speed up the information extraction phase by significantly reducing the size of the acquired dataset while preserving (retain) the information of interest. This paper focuses on the data reduction of LiDAR datasets acquired on roads, with the goal of extraction the off-road objects. Mostly motivated by the need of mapping roads and quickly determining car position along a road, the development of efficient methods for the extraction of such kind of information is becoming a hot topic in the research community.
KW  - off-road objects
KW  - OptD method
KW  - reduction
KW  - LiDAR
DO  - 10.3390/geosciences10060219
TY  - EJOU
AU  - García-Fernández, María
AU  - Álvarez López, Yuri
AU  - De Mitri, Alessandro
AU  - Castrillo Martínez, David
AU  - Álvarez-Narciandi, Guillermo
AU  - Las-Heras Andrés, Fernando
TI  - Portable and Easily-Deployable Air-Launched GPR Scanner
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 11
SN  - 2072-4292

AB  - In recent years, Unmanned Aerial Vehicles (UAV)-based Ground Penetrating Radar (GPR) systems have been developed due to their advantages for safe and fast detection of Improvised Explosive Devices (IEDs) and landmines. The complexity of these systems requires performing extensive measurement campaigns in order to test their performance and detection capabilities. However, UAV flights are limited by weather conditions and battery autonomy. To overcome these problems, this contribution presents a portable and easily-deployable measurement setup which can be used as a testbed for the assessment of the capabilities of the airborne system. In particular, the proposed portable measurement setup replicates fairly well the conditions faced by the airborne system, which can hardly be reproduced in indoor GPR measurement facilities. Three validation examples are presented: the first two analyze the capability of the measurement setup to conduct experiments in different scenarios (loamy and sandy soils). The third example focuses on the problem of antenna phase center displacement with frequency and its impact on GPR imaging, proposing a simple technique to correct it.
KW  - ground penetrating radar
KW  - synthetic aperture radar
KW  - imaging
KW  - landmine
KW  - unmanned aerial vehicles
DO  - 10.3390/rs12111833
TY  - EJOU
AU  - Zhang, Zhao
AU  - Flores, Paulo
AU  - Igathinathane, C.
AU  - L. Naik, Dayakar
AU  - Kiran, Ravi
AU  - Ransom, Joel K.
TI  - Wheat Lodging Detection from UAS Imagery Using Machine Learning Algorithms
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 11
SN  - 2072-4292

AB  - The current mainstream approach of using manual measurements and visual inspections for crop lodging detection is inefficient, time-consuming, and subjective. An innovative method for wheat lodging detection that can overcome or alleviate these shortcomings would be welcomed. This study proposed a systematic approach for wheat lodging detection in research plots (372 experimental plots), which consisted of using unmanned aerial systems (UAS) for aerial imagery acquisition, manual field evaluation, and machine learning algorithms to detect the occurrence or not of lodging. UAS imagery was collected on three different dates (23 and 30 July 2019, and 8 August 2019) after lodging occurred. Traditional machine learning and deep learning were evaluated and compared in this study in terms of classification accuracy and standard deviation. For traditional machine learning, five types of features (i.e. gray level co-occurrence matrix, local binary pattern, Gabor, intensity, and Hu-moment) were extracted and fed into three traditional machine learning algorithms (i.e., random forest (RF), neural network, and support vector machine) for detecting lodged plots. For the datasets on each imagery collection date, the accuracies of the three algorithms were not significantly different from each other. For any of the three algorithms, accuracies on the first and last date datasets had the lowest and highest values, respectively. Incorporating standard deviation as a measurement of performance robustness, RF was determined as the most satisfactory. Regarding deep learning, three different convolutional neural networks (simple convolutional neural network, VGG-16, and GoogLeNet) were tested. For any of the single date datasets, GoogLeNet consistently had superior performance over the other two methods. Further comparisons between RF and GoogLeNet demonstrated that the detection accuracies of the two methods were not significantly different from each other (p &gt; 0.05); hence, the choice of any of the two would not affect the final detection accuracies. However, considering the fact that the average accuracy of GoogLeNet (93%) was larger than RF (91%), it was recommended to use GoogLeNet for wheat lodging detection. This research demonstrated that UAS RGB imagery, coupled with the GoogLeNet machine learning algorithm, can be a novel, reliable, objective, simple, low-cost, and effective (accuracy &gt; 90%) tool for wheat lodging detection.
KW  - precision agriculture
KW  - field crops
KW  - machine learning
KW  - deep learning
KW  - image processing
KW  - textural features
DO  - 10.3390/rs12111838
TY  - EJOU
AU  - de la Fuente Castillo, Víctor
AU  - Díaz-Álvarez, Alberto
AU  - Manso-Callejo, Miguel-Ángel
AU  - Serradilla García, Francisco
TI  - Grammar Guided Genetic Programming for Network Architecture Search and Road Detection on Aerial Orthophotography
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 11
SN  - 2076-3417

AB  - Photogrammetry involves aerial photography of the Earth&rsquo;s surface and subsequently processing the images to provide a more accurate depiction of the area (Orthophotography). It is used by the Spanish Instituto Geogr&aacute;fico Nacional to update road cartography but requires a significant amount of manual labor due to the need to perform visual inspection of all tiled images. Deep learning techniques (artificial neural networks with more than one hidden layer) can perform road detection but it is still unclear how to find the optimal network architecture. Our main goal is the automatic design of deep neural network architectures with grammar-guided genetic programming. In this kind of evolutive algorithm, all the population individuals (here candidate network architectures) are constrained to rules specified by a grammar that defines valid and useful structural patterns to guide the search process. Grammar used includes well-known complex structures (e.g., Inception-like modules) combined with a custom designed mutation operator (dynamically links the mutation probability to structural diversity). Pilot results show that the system is able to design models for road detection that obtain test accuracies similar to that reached by state-of-the-art models when evaluated over a dataset from the Spanish National Aerial Orthophotography Plan.
KW  - grammar evolution
KW  - deep learning
KW  - network architecture search
KW  - grammar-guided genetic programming
DO  - 10.3390/app10113953
TY  - EJOU
AU  - Revill, Andrew
AU  - Florence, Anna
AU  - MacArthur, Alasdair
AU  - Hoad, Stephen
AU  - Rees, Robert
AU  - Williams, Mathew
TI  - Quantifying Uncertainty and Bridging the Scaling Gap in the Retrieval of Leaf Area Index by Coupling Sentinel-2 and UAV Observations
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 11
SN  - 2072-4292

AB  - Leaf area index (LAI) estimates can inform decision-making in crop management. The European Space Agency&rsquo;s Sentinel-2 satellite, with observations in the red-edge spectral region, can monitor crops globally at sub-field spatial resolutions (10&ndash;20 m). However, satellite LAI estimates require calibration with ground measurements. Calibration is challenged by spatial heterogeneity and scale mismatches between field and satellite measurements. Unmanned Aerial Vehicles (UAVs), generating high-resolution (cm-scale) LAI estimates, provide intermediary observations that we use here to characterise uncertainty and reduce spatial scaling discrepancies between Sentinel-2 observations and field surveys. We use a novel UAV multispectral sensor that matches Sentinel-2 spectral bands, flown in conjunction with LAI ground measurements. UAV and field surveys were conducted on multiple dates&mdash;coinciding with different wheat growth stages&mdash;that corresponded to Sentinel-2 overpasses. We compared chlorophyll red-edge index (CIred-edge) maps, derived from the Sentinel-2 and UAV platforms. We used Gaussian processes regression machine learning to calibrate a UAV model for LAI, based on ground data. Using the UAV LAI, we evaluated a two-stage calibration approach for generating robust LAI estimates from Sentinel-2. The agreement between Sentinel-2 and UAV CIred-edge values increased with growth stage&mdash;R2 ranged from 0.32 (stem elongation) to 0.75 (milk development). The CIred-edge variance between the two platforms was more comparable later in the growing season due to a more homogeneous and closed wheat canopy. The single-stage Sentinel-2 LAI calibration (i.e., direct calibration from ground measurements) performed poorly (mean R2 = 0.29, mean NRMSE = 17%) when compared to the two-stage calibration using the UAV data (mean R2 = 0.88, mean NRMSE = 8%). The two-stage approach reduced both errors and biases by &gt;50%. By upscaling ground measurements and providing more representative model training samples, UAV observations provide an effective and viable means of enhancing Sentinel-2 wheat LAI retrievals. We anticipate that our UAV calibration approach to resolving spatial heterogeneity would enhance the retrieval accuracy of LAI and additional biophysical variables for other arable crop types and a broader range of vegetation cover types.
KW  - Sentinel-2
KW  - LAI retrieval
KW  - UAV multispectral data
KW  - winter wheat
KW  - Gaussian processes regression
DO  - 10.3390/rs12111843
TY  - EJOU
AU  - Zhang, Tianyao
AU  - Hu, Xiaoguang
AU  - Xiao, Jin
AU  - Zhang, Guofeng
TI  - A Machine Learning Method for Vision-Based Unmanned Aerial Vehicle Systems to Understand Unknown Environments
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 11
SN  - 1424-8220

AB  - What makes unmanned aerial vehicles (UAVs) intelligent is their capability of sensing and understanding new unknown environments. Some studies utilize computer vision algorithms like Visual Simultaneous Localization and Mapping (VSLAM) and Visual Odometry (VO) to sense the environment for pose estimation, obstacles avoidance and visual servoing. However, understanding the new environment (i.e., make the UAV recognize generic objects) is still an essential scientific problem that lacks a solution. Therefore, this paper takes a step to understand the items in an unknown environment. The aim of this research is to enable the UAV with basic understanding capability for a high-level UAV flock application in the future. Specially, firstly, the proposed understanding method combines machine learning and traditional algorithm to understand the unknown environment through RGB images; secondly, the You Only Look Once (YOLO) object detection system is integrated (based on TensorFlow) in a smartphone to perceive the position and category of 80 classes of objects in the images; thirdly, the method makes the UAV more intelligent and liberates the operator from labor; fourthly, detection accuracy and latency in working condition are quantitatively evaluated, and properties of generality (can be used in various platforms), transportability (easily deployed from one platform to another) and scalability (easily updated and maintained) for UAV flocks are qualitatively discussed. The experiments suggest that the method has enough accuracy to recognize various objects with high computational speed, and excellent properties of generality, transportability and scalability.
KW  - UAV
KW  - visual RGB
KW  - real-time
KW  - YOLOv3
KW  - color detection
KW  - object detection
KW  - machine learning system
DO  - 10.3390/s20113245
TY  - EJOU
AU  - Perroy, Ryan L.
AU  - Hughes, Marc
AU  - Keith, Lisa M.
AU  - Collier, Eszter
AU  - Sullivan, Timo
AU  - Low, Gabriel
TI  - Examining the Utility of Visible Near-Infrared and Optical Remote Sensing for the Early Detection of Rapid ‘Ōhi‘a Death
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 11
SN  - 2072-4292

AB  - The early detection of plant pathogens at the landscape scale holds great promise for better managing forest ecosystem threats. In Hawai&lsquo;i, two recently described fungal species are responsible for increasingly widespread mortality in &lsquo;ōhi&lsquo;a Metrosideros polymorpha, a foundational tree species in Hawaiian native forests. In this study, we share work from repeat laboratory and field measurements to determine if visible near-infrared and optical remote sensing can detect pre-symptomatic trees infected with these pathogens. After generating a dense time series of laboratory spectral reflectance data and red green blue (RGB) images for inoculated &lsquo;ōhi&lsquo;a seedlings, seedlings subjected to extreme drought, and control plants, we found few obvious spectral indicators that could be used for reliable pre-symptomatic detection in the inoculated seedlings, which quickly experienced complete and total wilting following stress onset. In the field, we found similar results when we collected repeat multispectral and RGB imagery over inoculated mature trees (sudden onset of symptoms with little advance warning). We found selected vegetation indices to be reliable indicators for detecting non-specific stress in &lsquo;ōhi&lsquo;a trees, but never providing more than five days prior warning relative to visual detection in the laboratory trials. Finally, we generated a sequence of linear support vector machine classification models from the laboratory data at time steps ranging from pre-treatment to late-stage stress. Overall classification accuracies increased with stress stage maturity, but poor model performance prior to stress onset and the sudden onset of symptoms in infected trees suggest that early detection of rapid &lsquo;ōhi&lsquo;a death over timescales helpful for land managers remains a challenge.
KW  - Hawai‘i
KW  - vegetation indices
KW  - Ceratocystis lukuohia
KW  - Ceratocystis huliohia
DO  - 10.3390/rs12111846
TY  - EJOU
AU  - Sang, Qianqian
AU  - Wu, Honghai
AU  - Xing, Ling
AU  - Xie, Ping
TI  - Review and Comparison of Emerging Routing Protocols in Flying Ad Hoc Networks
T2  - Symmetry

PY  - 2020
VL  - 12
IS  - 6
SN  - 2073-8994

AB  - With the development of Unmanned Air Vehicle (UAV) communication, Flying Ad Hoc Network (FANET) has become a hot research area in recent years, which is widely used in civil and military fields due to its unique advantages. FANET is a special kind of networks which are composed of UAV nodes, and can be used to implement data transfer in certain unique scenarios. To achieve reliable and robust communication among UAVs, a routing algorithm is the key factor and should be designed elaborately. Because of its importance and usefulness, this topic has attracted many researchers, and various routing protocols have also been put forward to improve the quality of data transmission in FANETs. Thus, in this paper, we give a survey on the state-of-the-art of routing protocols proposed in recent years. First, an in-depth research of the routing in FANETs recently has been brought out by absolutely differentiating them based on their routing mechanism. Then, we give a comparative analysis of each protocol based on their characteristics and service quality indicators. Finally, we propose some unsolved problems and future research directions for FANET routing.
KW  - flying ad hoc networks
KW  - data transmission
KW  - routing algorithm
KW  - survey
DO  - 10.3390/sym12060971
TY  - EJOU
AU  - Arabameri, Alireza
AU  - Asadi Nalivan, Omid
AU  - Saha, Sunil
AU  - Roy, Jagabandhu
AU  - Pradhan, Biswajeet
AU  - Tiefenbacher, John P.
AU  - Thi Ngo, Phuong T.
TI  - Novel Ensemble Approaches of Machine Learning Techniques in Modeling the Gully Erosion Susceptibility
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 11
SN  - 2072-4292

AB  - Gully erosion has become one of the major environmental issues, due to the severity of its impact in many parts of the world. Gully erosion directly and indirectly affects agriculture and infrastructural development. The Golestan Dam basin, where soil erosion and degradation are very severe problems, was selected as the study area. This research maps gully erosion susceptibility (GES) by integrating four models: maximum entropy (MaxEnt), artificial neural network (ANN), support vector machine (SVM), and general linear model (GLM). Of 1042 gully locations, 729 (70%) and 313 (30%) gully locations were used for modeling and validation purposes, respectively. Fourteen effective gully erosion conditioning factors (GECFs) were selected for spatial gully erosion modeling. Tolerance and variance inflation factors (VIFs) were used to examine the collinearity among the GECFs. The random forest (RF) model was used to assess factors&rsquo; effectiveness and significance in gully erosion modeling. An ensemble of techniques can provide more accurate results than can single, standalone models. Therefore, we compared two-, three-, and four-model ensembles (ANN-SVM, GLM-ANN, GLM-MaxEnt, GLM-SVM, MaxEnt-ANN, MaxEnt-SVM, ANN-SVM-GLM, GLM-MaxEnt-ANN, GLM-MaxEnt-SVM, MaxEnt-ANN-SVM and GLM-ANN-SVM-MaxEnt) for GES modeling. The susceptibility zones of the GESMs were classified as very-low, low, medium, high, and very-high using Jenks&rsquo; natural break classification method (NBM). Subsequently, the receiver operating characteristics (ROC) curve and the seed cell area index (SCAI) methods measured the reliability of the models. The success rate curve (SRC) and predication rate curve (PRC) and their area under the curve (AUC) values were obtained from the GES maps. The results show that the ANN model combined with two and three models are more accurate than the other combinations, but the ANN-SVM model had the highest accuracy. The rank of the others from best to worst accuracy is GLM, MaxEnt, SVM, GLM-ANN, GLM-MaxEnt, GLM-SVM, MaxEnt-ANN, MaxEnt-SVM, GLM-ANN-SVM-MaxEnt, GLM-MaxEnt-ANN, GLM-MaxEnt-SVM and MaxEnt-ANN-SVM. The resulting gully erosion susceptibility models (GESMs) are efficient and powerful and could be used to improve soil and water conservation and management.
KW  - gully erosion susceptibility
KW  - artificial neural network
KW  - support vector machine
KW  - general linear model
KW  - GIS
KW  - ensemble models
KW  - Golestan Dambasin
DO  - 10.3390/rs12111890
TY  - EJOU
AU  - Rodríguez-Puerta, Francisco
AU  - Alonso Ponce, Rafael
AU  - Pérez-Rodríguez, Fernando
AU  - Águeda, Beatriz
AU  - Martín-García, Saray
AU  - Martínez-Rodrigo, Raquel
AU  - Lizarralde, Iñigo
TI  - Comparison of Machine Learning Algorithms for Wildland-Urban Interface Fuelbreak Planning Integrating ALS and UAV-Borne LiDAR Data and Multispectral Images
T2  - Drones

PY  - 2020
VL  - 4
IS  - 2
SN  - 2504-446X

AB  - Controlling vegetation fuels around human settlements is a crucial strategy for reducing fire severity in forests, buildings and infrastructure, as well as protecting human lives. Each country has its own regulations in this respect, but they all have in common that by reducing fuel load, we in turn reduce the intensity and severity of the fire. The use of Unmanned Aerial Vehicles (UAV)-acquired data combined with other passive and active remote sensing data has the greatest performance to planning Wildland-Urban Interface (WUI) fuelbreak through machine learning algorithms. Nine remote sensing data sources (active and passive) and four supervised classification algorithms (Random Forest, Linear and Radial Support Vector Machine and Artificial Neural Networks) were tested to classify five fuel-area types. We used very high-density Light Detection and Ranging (LiDAR) data acquired by UAV (154 returns&middot;m&minus;2 and ortho-mosaic of 5-cm pixel), multispectral data from the satellites Pleiades-1B and Sentinel-2, and low-density LiDAR data acquired by Airborne Laser Scanning (ALS) (0.5 returns&middot;m&minus;2, ortho-mosaic of 25 cm pixels). Through the Variable Selection Using Random Forest (VSURF) procedure, a pre-selection of final variables was carried out to train the model. The four algorithms were compared, and it was concluded that the differences among them in overall accuracy (OA) on training datasets were negligible. Although the highest accuracy in the training step was obtained in SVML (OA=94.46%) and in testing in ANN (OA=91.91%), Random Forest was considered to be the most reliable algorithm, since it produced more consistent predictions due to the smaller differences between training and testing performance. Using a combination of Sentinel-2 and the two LiDAR data (UAV and ALS), Random Forest obtained an OA of 90.66% in training and of 91.80% in testing datasets. The differences in accuracy between the data sources used are much greater than between algorithms. LiDAR growth metrics calculated using point clouds in different dates and multispectral information from different seasons of the year are the most important variables in the classification. Our results support the essential role of UAVs in fuelbreak planning and management and thus, in the prevention of forest fires.
KW  - artificial intelligence
KW  - UAV-LiDAR
KW  - satellite imagery
KW  - large-scale LiDAR
DO  - 10.3390/drones4020021
TY  - EJOU
AU  - Miura, Hiroyuki
AU  - Aridome, Tomohiro
AU  - Matsuoka, Masashi
TI  - Deep Learning-Based Identification of Collapsed, Non-Collapsed and Blue Tarp-Covered Buildings from Post-Disaster Aerial Images
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - A methodology for the automated identification of building damage from post-disaster aerial images was developed based on convolutional neural network (CNN) and building damage inventories. The aerial images and the building damage data obtained in the 2016 Kumamoto, and the 1995 Kobe, Japan earthquakes were analyzed. Since the roofs of many moderately damaged houses are covered with blue tarps immediately after disasters, not only collapsed and non-collapsed buildings but also the buildings covered with blue tarps were identified by the proposed method. The CNN architecture developed in this study correctly classifies the building damage with the accuracy of approximately 95 % in both earthquake data. We applied the developed CNN model to aerial images in Chiba, Japan, damaged by the typhoon in September 2019. The result shows that more than 90 % of the building damage are correctly classified by the CNN model.
KW  - deep learning
KW  - building damage
KW  - aerial image
KW  - earthquake
KW  - typhoon
DO  - 10.3390/rs12121924
TY  - EJOU
AU  - Wang, Mingchang
AU  - Zhang, Haiming
AU  - Sun, Weiwei
AU  - Li, Sheng
AU  - Wang, Fengyan
AU  - Yang, Guodong
TI  - A Coarse-to-Fine Deep Learning Based Land Use Change Detection Method for High-Resolution Remote Sensing Images
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - In recent decades, high-resolution (HR) remote sensing images have shown considerable potential for providing detailed information for change detection. The traditional change detection methods based on HR remote sensing images mostly only detect a single land type or only the change range, and cannot simultaneously detect the change of all object types and pixel-level range changes in the area. To overcome this difficulty, we propose a new coarse-to-fine deep learning-based land-use change detection method. We independently created a new scene classification dataset called NS-55, and innovatively considered the adaptation relationship between the convolutional neural network (CNN) and the scene complexity by selecting the CNN that best fit the scene complexity. The CNN trained by NS-55 was used to detect the category of the scene, define the final category of the scene according to the majority voting method, and obtain the changed scene by comparison to obtain the so-called coarse change result. Then, we created a multi-scale threshold (MST) method, which is a new method for obtaining high-quality training samples. We used the high-quality samples selected by MST to train the deep belief network to obtain the pixel-level range change detection results. By mapping coarse scene changes to range changes, we could obtain fine multi-type land-use change detection results. Experiments were conducted on the Multi-temporal Scene Wuhan dataset and aerial images of a particular area of Dapeng New District, Shenzhen, where promising results were achieved by the proposed method. This demonstrates that the proposed method is practical, easy-to-implement, and the NS-55 dataset is physically justified. The proposed method has the potential to be applied in the large scale land use fine change detection problem and qualitative and quantitative research on land use/cover change based on HR remote sensing data.
KW  - coarse-to-fine
KW  - change detection
KW  - deep learning
KW  - land-use
KW  - high-resolution
DO  - 10.3390/rs12121933
TY  - EJOU
AU  - Wagle, Nimisha
AU  - Acharya, Tri D.
TI  - Past and Present Practices of Topographic Base Map Database Update in Nepal
T2  - ISPRS International Journal of Geo-Information

PY  - 2020
VL  - 9
IS  - 6
SN  - 2220-9964

AB  - Topographic Base Maps (TBMs) are those maps that portray ground relief as the form of contour lines and show planimetric details. Various other maps like geomorphological maps, contour maps, and land use planning maps are derived from topographical maps. In this constantly changing world, the update of TBMs is indispensable. In Nepal, their update and maintenance are done by the Survey Department (SD) as a national mapping agency. This paper presents the history of topographical mapping and the reasons for the lack of updates. Currently, the SD is updating the TBM database using panchromatic and multispectral images from the Zi Yuan-3 (ZY-3) satellite with a resolution of 2.1 and 5.8 m, respectively. The updated methodology includes the orthorectification of images, the pansharpening of images, field data collection, digitization, change detection, and updating, the overlay of vector data and field verification, data quality control, and printing map production. A TBM in the Dang district of Nepal is presented as casework to show the changes in the area and issues faced during the update. Though the present digitizing procedure is time-consuming and labor-intensive, the use of high-resolution imagery has made mapping accurate and has produced high-quality maps. However, audit and automation can be introduced from the experiences of other countries for accurate and frequent updates of the TBM database in Nepal.
KW  - topographic base map
KW  - national mapping agency
KW  - updates
KW  - history
KW  - ZY-3
KW  - Nepal
DO  - 10.3390/ijgi9060397
TY  - EJOU
AU  - Asokan, Anju
AU  - Anitha, J.
AU  - Ciobanu, Monica
AU  - Gabor, Andrei
AU  - Naaji, Antoanela
AU  - Hemanth, D. J.
TI  - Image Processing Techniques for Analysis of Satellite Images for Historical Maps Classification—An Overview
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 12
SN  - 2076-3417

AB  - Historical maps classification has become an important application in today&rsquo;s scenario of everchanging land boundaries. Historical map changes include the change in boundaries of cities/states, vegetation regions, water bodies and so forth. Change detection in these regions are mainly carried out via satellite images. Hence, an extensive knowledge on satellite image processing is necessary for historical map classification applications. An exhaustive analysis on the merits and demerits of many satellite image processing methods are discussed in this paper. Though several computational methods are available, different methods perform differently for the various satellite image processing applications. Wrong selection of methods will lead to inferior results for a specific application. This work highlights the methods and the suitable satellite imaging methods associated with these applications. Several comparative analyses are also performed in this work to show the suitability of several methods. This work will help support the selection of innovative solutions for the different problems associated with satellite image processing applications.
KW  - remote sensing
KW  - change detection
KW  - fusion
KW  - feature extraction
KW  - segmentation
KW  - classification
DO  - 10.3390/app10124207
TY  - EJOU
AU  - Hegarty-Craver, Meghan
AU  - Polly, Jason
AU  - O’Neil, Margaret
AU  - Ujeneza, Noel
AU  - Rineer, James
AU  - Beach, Robert H.
AU  - Lapidus, Daniel
AU  - Temple, Dorota S.
TI  - Remote Crop Mapping at Scale: Using Satellite Imagery and UAV-Acquired Data as Ground Truth
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - Timely and accurate agricultural information is needed to inform resource allocation and sustainable practices to improve food security in the developing world. Obtaining this information through traditional surveys is time consuming and labor intensive, making it difficult to collect data at the frequency and resolution needed to accurately estimate the planted areas of key crops and their distribution during the growing season. Remote sensing technologies can be leveraged to provide consistent, cost-effective, and spatially disaggregated data at high temporal frequency. In this study, we used imagery acquired from unmanned aerial vehicles to create a high-fidelity ground-truth dataset that included examples of large mono-cropped fields, small intercropped fields, and natural vegetation. The imagery was acquired in three rounds of flights at six sites in different agro-ecological zones to capture growing conditions. This dataset was used to train and test a random forest model that was implemented in Google Earth Engine for classifying cropped land using freely available Sentinel-1 and -2 data. This model achieved an overall accuracy of 83%, and a 91% accuracy for maize specifically. The model results were compared with Rwanda&rsquo;s Seasonal Agricultural Survey, which highlighted biases in the dataset including a lack of examples of mixed land cover.
KW  - Sentinel-1
KW  - Sentinel-2
KW  - UAV
KW  - Google Earth Engine
KW  - sub-Saharan Africa
DO  - 10.3390/rs12121984
TY  - EJOU
AU  - Wagner, Matthias P.
AU  - Oppelt, Natascha
TI  - Deep Learning and Adaptive Graph-Based Growing Contours for Agricultural Field Extraction
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - Field mapping and information on agricultural landscapes is of increasing importance for many applications. Monitoring schemes and national cadasters provide a rich source of information but their maintenance and regular updating is costly and labor-intensive. Automatized mapping of fields based on remote sensing imagery may aid in this task and allow for a faster and more regular observation. Although remote sensing has seen extensive use in agricultural research topics, such as plant health monitoring, crop type classification, yield prediction, and irrigation, field delineation and extraction has seen comparatively little research interest. In this study, we present a field boundary detection technique based on deep learning and a variety of image features, and combine it with the graph-based growing contours (GGC) method to extract agricultural fields in a study area in northern Germany. The boundary detection step only requires red, green, and blue (RGB) data and is therefore largely independent of the sensor used. We compare different image features based on color and luminosity information and evaluate their usefulness for the task of field boundary detection. A model based on texture metrics, gradient information, Hessian matrix eigenvalues, and local statistics showed good results with accuracies up to 88.2%, an area under the ROC curve (AUC) of up to 0.94, and F1 score of up to 0.88. The exclusive use of these universal image features may also facilitate transferability to other regions. We further present modifications to the GGC method intended to aid in upscaling of the method through process acceleration with a minimal effect on results. We combined the boundary detection results with the GGC method for field polygon extraction. Results were promising, with the new GGC version performing similarly or better than the original version while experiencing an acceleration of 1.3&times; to 2.3&times; on different subsets and input complexities. Further research may explore other applications of the GGC method outside agricultural remote sensing and field extraction.
KW  - field extraction
KW  - field boundary detection
KW  - deep learning
KW  - multilayer perceptron
KW  - active contours
KW  - growing snakes
KW  - graph-based growing contours
DO  - 10.3390/rs12121990
TY  - EJOU
AU  - Foudeh, Husam A.
AU  - Luk, Patrick
AU  - Whidborne, James
TI  - Application of Norm Optimal Iterative Learning Control to Quadrotor Unmanned Aerial Vehicle for Monitoring Overhead Power System
T2  - Energies

PY  - 2020
VL  - 13
IS  - 12
SN  - 1996-1073

AB  - Wind disturbances and noise severely affect Unmanned Aerial Vehicles (UAV) when monitoring and finding faults in overhead power lines. Accordingly, we propose repetitive learning as a new solution for the problem. In particular, the performance of Iterative Learning Control (ILC) that are based on optimal approaches are examined, namely (i) Gradient-based ILC and (ii) Norm Optimal ILC. When considering the repetitive nature of fault-finding tasks for electrical overhead power lines, this study develops, implements and evaluates optimal ILC algorithms for a UAV model. Moreover, we suggest attempting a learning gain variation on the standard optimal algorithms instead of heuristically selecting from the previous range. The results of both simulations and experiments of gradient-based norm optimal control reveal that the proposed ILC algorithm has not only contributed to good trajectory tracking, but also good convergence speed and the ability to cope with exogenous disturbances such as wind gusts.
KW  - unmanned aerial vehicles (UAVs)
KW  - quadrotor
KW  - Iterative Learning Control (ILC)
KW  - Norm Optimal ILC
KW  - gradient-based ILC
KW  - power system
KW  - inspection task
DO  - 10.3390/en13123223
TY  - EJOU
AU  - Parvaresh, Ahmad
AU  - Abrazeh, Saber
AU  - Mohseni, Saeid-Reza
AU  - Zeitouni, Meisam J.
AU  - Gheisarnejad, Meysam
AU  - Khooban, Mohammad-Hassan
TI  - A Novel Deep Learning Backstepping Controller-Based Digital Twins Technology for Pitch Angle Control of Variable Speed Wind Turbine
T2  - Designs

PY  - 2020
VL  - 4
IS  - 2
SN  - 2411-9660

AB  - This paper proposes a deep deterministic policy gradient (DDPG) based nonlinear integral backstepping (NIB) in combination with model free control (MFC) for pitch angle control of variable speed wind turbine. In particular, the controller has been presented as a digital twin (DT) concept, which is an increasingly growing method in a variety of applications. In DDPG-NIB-MFC, the pitch angle is considered as the control input that depends on the optimal rotor speed, which is usually derived from effective wind speed. The system stability according to the Lyapunov theory can be achieved by the recursive nature of the backstepping theory and the integral action has been used to compensate for the steady-state error. Moreover, due to the nonlinear characteristics of wind turbines, the MFC aims to handle the un-modeled system dynamics and disturbances. The DDPG algorithm with actor-critic structure has been added in the proposed control structure to efficiently and adaptively tune the controller parameters embedded in the NIB controller. Under this effort, a digital twin of a presented controller is defined as a real-time and probabilistic model which is implemented on the digital signal processor (DSP) computing device. To ensure the performance of the proposed approach and output behavior of the system, software-in-loop (SIL) and hardware-in-loop (HIL) testing procedures have been considered. From the simulation and implementation outcomes, it can be concluded that the proposed backstepping controller based DDPG is more effective, robust, and adaptive than the backstepping and proportional-integral (PI) controllers optimized by particle swarm optimization (PSO) in the presence of uncertainties and disturbances.
KW  - pitch angle control
KW  - DDPG algorithm
KW  - backstepping controller
KW  - digital twin (DT)
KW  - DSP
KW  - software-in-loop
KW  - hardware-in-Loop
DO  - 10.3390/designs4020015
TY  - EJOU
AU  - Panagiotou, Emmanouil
AU  - Chochlakis, Georgios
AU  - Grammatikopoulos, Lazaros
AU  - Charou, Eleni
TI  - Generating Elevation Surface from a Single RGB Remotely Sensed Image Using Deep Learning
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - Generating Digital Elevation Models (DEM) from satellite imagery or other data sources constitutes an essential tool for a plethora of applications and disciplines, ranging from 3D flight planning and simulation, autonomous driving and satellite navigation, such as GPS, to modeling water flow, precision farming and forestry. The task of extracting this 3D geometry from a given surface hitherto requires a combination of appropriately collected corresponding samples and/or specialized equipment, as inferring the elevation from single image data is out of reach for contemporary approaches. On the other hand, Artificial Intelligence (AI) and Machine Learning (ML) algorithms have experienced unprecedented growth in recent years as they can extrapolate rules in a data-driven manner and retrieve convoluted, nonlinear one-to-one mappings, such as an approximate mapping from satellite imagery to DEMs. Therefore, we propose an end-to-end Deep Learning (DL) approach to construct this mapping and to generate an absolute or relative point cloud estimation of a DEM given a single RGB satellite (Sentinel-2 imagery in this work) or drone image. The model has been readily extended to incorporate available information from the non-visible electromagnetic spectrum. Unlike existing methods, we only exploit one image for the production of the elevation data, rendering our approach less restrictive and constrained, but suboptimal compared to them at the same time. Moreover, recent advances in software and hardware allow us to make the inference and the generation extremely fast, even on moderate hardware. We deploy Conditional Generative Adversarial networks (CGAN), which are the state-of-the-art approach to image-to-image translation. We expect our work to serve as a springboard for further development in this field and to foster the integration of such methods in the process of generating, updating and analyzing DEMs.
KW  - deep learning
KW  - remote sensing
KW  - digital elevation models
KW  - generative adversarial networks
KW  - 3D point cloud
KW  - satellite imagery
KW  - drones
KW  - height maps
DO  - 10.3390/rs12122002
TY  - EJOU
AU  - Kucharczyk, Maja
AU  - Hay, Geoffrey J.
AU  - Ghaffarian, Salar
AU  - Hugenholtz, Chris H.
TI  - Geographic Object-Based Image Analysis: A Primer and Future Directions
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - Geographic object-based image analysis (GEOBIA) is a remote sensing image analysis paradigm that defines and examines image-objects: groups of neighboring pixels that represent real-world geographic objects. Recent reviews have examined methodological considerations and highlighted how GEOBIA improves upon the 30+ year pixel-based approach, particularly for H-resolution imagery. However, the literature also exposes an opportunity to improve guidance on the application of GEOBIA for novice practitioners. In this paper, we describe the theoretical foundations of GEOBIA and provide a comprehensive overview of the methodological workflow, including: (i) software-specific approaches (open-source and commercial); (ii) best practices informed by research; and (iii) the current status of methodological research. Building on this foundation, we then review recent research on the convergence of GEOBIA with deep convolutional neural networks, which we suggest is a new form of GEOBIA. Specifically, we discuss general integrative approaches and offer recommendations for future research. Overall, this paper describes the past, present, and anticipated future of GEOBIA in a novice-accessible format, while providing innovation and depth to experienced practitioners.
KW  - geographic object-based image analysis
KW  - GEOBIA
KW  - object-based image analysis
KW  - OBIA
KW  - machine learning
KW  - deep learning
KW  - convolutional neural network
KW  - CNN
KW  - GEOCNN
DO  - 10.3390/rs12122012
TY  - EJOU
AU  - Karunaratne, Senani
AU  - Thomson, Anna
AU  - Morse-McNabb, Elizabeth
AU  - Wijesingha, Jayan
AU  - Stayches, Dani
AU  - Copland, Amy
AU  - Jacobs, Joe
TI  - The Fusion of Spectral and Structural Datasets Derived from an Airborne Multispectral Sensor for Estimation of Pasture Dry Matter Yield at Paddock Scale with Time
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - This study aimed to develop empirical pasture dry matter (DM) yield prediction models using an unmanned aerial vehicle (UAV)-borne sensor at four flying altitudes. Three empirical models were developed using features generated from the multispectral sensor: Structure from Motion only (SfM), vegetation indices only (VI), and in combination (SfM+VI) within a machine learning modelling framework. Four flying altitudes were tested (25 m, 50 m, 75 m and 100 m) and based on independent model validation, combining features from SfM+VI outperformed the other models at all heights. However, the importance of SfM-based features changed with altitude, with limited importance at 25 m but at all higher altitudes SfM-based features were included in the top 10 features in a variable importance plot. Based on the independent validation results, data generated at 25 m flying altitude reported the best model performances with model accuracy of 328 kg DM/ha. In contrast, at 100 m flying altitude, the model reported an accuracy of 402 kg DM/ha which demonstrates the potential of scaling up this technology at farm scale. The spatial-temporal maps provide valuable information on pasture DM yield and DM accumulation of herbage mass over the time, supporting on-farm management decisions.
KW  - space-time model
KW  - machine learning
KW  - farmscape
KW  - digital agriculture
DO  - 10.3390/rs12122017
TY  - EJOU
AU  - Zhao, Yibo
AU  - Lei, Shaogang
AU  - Yang, Xingchen
AU  - Gong, Chuangang
AU  - Wang, Cangjiao
AU  - Cheng, Wei
AU  - Li, Heng
AU  - She, Changchao
TI  - Study on Spectral Response and Estimation of Grassland Plants Dust Retention Based on Hyperspectral Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - Accurate monitoring of plant dust retention can provide a basis for dust pollution control and environmental protection. The aims of this study were to analyze the spectral response features of grassland plants to mining dust and to predict the spatial distribution of dust retention using hyperspectral data. The dust retention content was determined by an electronic analytical balance and a leaf area meter. The leaf reflectance spectrum was measured by a handheld hyperspectral camera, and the airborne hyperspectral data were obtained using an imaging spectrometer. We analyzed the difference between the leaf spectral before and after dust removal. The sensitive spectra of dust retention on the leaf- and the canopy-scale were determined through two-dimensional correlation spectroscopy (2DCOS). The competitive adaptive reweighted sampling (CARS) algorithm was applied to select the feature bands of canopy dust retention. The estimation model of canopy dust retention was built through random forest regression (RFR), and the dust distribution map was obtained based on the airborne hyperspectral image. The results showed that dust retention enhanced the spectral reflectance of leaves in the visible wavelength but weakened the reflectance in the near-infrared wavelength. Caused by the canopy structure and multiple scattering, a slight difference in the sensitive spectra on dust retention existed between the canopy and leaves. Similarly, the sensitive spectra of leaves and the canopy were closely related to dust and plant physiological parameters. The estimation model constructed through 2DCOS-CARS-RFR showed higher precision, compared with genetic algorithm-random forest regression (GA-RFR) and simulated annealing algorithm-random forest regression (SAA-RFR). Spatially, the amount of canopy dust increased and then decreased with increasing distance from the mining area, reaching a maximum within 300&ndash;500 m. This study not only demonstrated the importance of extracting feature bands based on the response of plant physical and chemical parameters to dust, but also laid a foundation for the rapid and non-destructive monitoring of grassland plant dust retention.
KW  - mining dust
KW  - grassland plant
KW  - hyperspectral measurement
KW  - spectral analysis
KW  - estimation model
DO  - 10.3390/rs12122019
TY  - EJOU
AU  - Barbedo, Jayme G.
TI  - Detecting and Classifying Pests in Crops Using Proximal Images and Machine Learning: A Review
T2  - AI

PY  - 2020
VL  - 1
IS  - 2
SN  - 2673-2688

AB  - Pest management is among the most important activities in a farm. Monitoring all different species visually may not be effective, especially in large properties. Accordingly, considerable research effort has been spent towards the development of effective ways to remotely monitor potential infestations. A growing number of solutions combine proximal digital images with machine learning techniques, but since species and conditions associated to each study vary considerably, it is difficult to draw a realistic picture of the actual state of the art on the subject. In this context, the objectives of this article are (1) to briefly describe some of the most relevant investigations on the subject of automatic pest detection using proximal digital images and machine learning; (2) to provide a unified overview of the research carried out so far, with special emphasis to research gaps that still linger; (3) to propose some possible targets for future research.
KW  - pest monitoring
KW  - machine learning
KW  - agricultural crops
KW  - insects
DO  - 10.3390/ai1020021
TY  - EJOU
AU  - Feng, Luwei
AU  - Zhang, Zhou
AU  - Ma, Yuchi
AU  - Du, Qingyun
AU  - Williams, Parker
AU  - Drewry, Jessica
AU  - Luck, Brian
TI  - Alfalfa Yield Prediction Using UAV-Based Hyperspectral Imagery and Ensemble Learning
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - Alfalfa is a valuable and intensively produced forage crop in the United States, and the timely estimation of its yield can inform precision management decisions. However, traditional yield assessment approaches are laborious and time-consuming, and thus hinder the acquisition of timely information at the field scale. Recently, unmanned aerial vehicles (UAVs) have gained significant attention in precision agriculture due to their efficiency in data acquisition. In addition, compared with other imaging modalities, hyperspectral data can offer higher spectral fidelity for constructing narrow-band vegetation indices which are of great importance in yield modeling. In this study, we performed an in-season alfalfa yield prediction using UAV-based hyperspectral images. Specifically, we firstly extracted a large number of hyperspectral indices from the original data and performed a feature selection to reduce the data dimensionality. Then, an ensemble machine learning model was developed by combining three widely used base learners including random forest (RF), support vector regression (SVR) and K-nearest neighbors (KNN). The model performance was evaluated on experimental fields in Wisconsin. Our results showed that the ensemble model outperformed all the base learners and a coefficient of determination (R2) of 0.874 was achieved when using the selected features. In addition, we also evaluated the model adaptability on different machinery compaction treatments, and the results further demonstrate the efficacy of the proposed ensemble model.
KW  - alfalfa
KW  - yield prediction
KW  - hyperspectral
KW  - unmanned aerial vehicle (UAV)
KW  - ensemble learning
KW  - vegetation index
DO  - 10.3390/rs12122028
TY  - EJOU
AU  - Najm, Aws A.
AU  - Ibraheem, Ibraheem K.
AU  - Azar, Ahmad T.
AU  - Humaidi, Amjad J.
TI  - Genetic Optimization-Based Consensus Control of Multi-Agent 6-DoF UAV System
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 12
SN  - 1424-8220

AB  - A consensus control law is proposed for a multi-agent system of quadrotors with leader–follower communication topology for three quadrotor agents. The genetic algorithm (GA) is the proposed optimization technique to tune the consensus control parameters. The complete nonlinear model is used without any further simplifications in the simulations, while simplification in the model is used to theoretically design the controller. Different case studies and tests are done (i.e., trajectory tracking formation and switching topology) to show the effectiveness of the proposed controller. The results show good performance in all tests while achieving the consensus of the desired formations.
KW  - hybrid control system
KW  - nonlinear PID
KW  - active disturbance rejection control
KW  - quadrotor system
KW  - unmanned aerial vehicle
DO  - 10.3390/s20123576
TY  - EJOU
AU  - Kim, Junsu
AU  - Moon, Hongbin
AU  - Jung, Hosang
TI  - Drone-Based Parcel Delivery Using the Rooftops of City Buildings: Model and Solution
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 12
SN  - 2076-3417

AB  - In general, the demand for delivery cannot be fulfilled efficiently due to the excessive traffic in dense urban areas. Therefore, many innovative concepts for intelligent transportation of freight have recently been developed. One of these concepts relies on drone-based parcel delivery using rooftops of city buildings. To apply drone logistics system in cities, the operation design should be adequately prepared. In this regard, a mixed integer programming model for drone operation planning and a heuristic based on block stacking are newly proposed to provide solutions. Additionally, numerical experiments with three different problem sizes are conducted to check the feasibility of the proposed model and to assess the performance of the proposed heuristic. The experimental results show that the proposed model seems to be viable and that the developed heuristic provides very good operation plans in terms of the optimality gap and the computation time.
KW  - urban logistics
KW  - smart cities
KW  - drone
KW  - parcel delivery
DO  - 10.3390/app10124362
TY  - EJOU
AU  - Pamart, Anthony
AU  - Morlet, François
AU  - De Luca, Livio
AU  - Veron, Philippe
TI  - A Robust and Versatile Pipeline for Automatic Photogrammetric-Based Registration of Multimodal Cultural Heritage Documentation
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - Imaging techniques and Image Based-Modeling (IBM) practices in the field of Cultural Heritage (CH) studies are nowadays no longer used as one-shot applications but as various and complex scenarios involving multiple modalities; sensors, scales, spectral bands and temporalities utilized by various experts. Current use of Structure from Motion and photogrammetric methods necessitates some improvements in iterative registration to ease the growing complexity in the management of the scientific imaging applied on heritage assets. In this context, the co-registration of photo-documentation among other imaging resources is a key step in order to move towards data fusion and collaborative semantic enrichment scenarios. This paper presents the recent development of a Totally Automated Co-registration and Orientation library (TACO) based on the interoperability of open-source solutions to conduct photogrammetric-based registration. The proposed methodology addresses and solves some gaps in term of robustness and versatility in the field of incremental and global orientation of image-sets dedicated to CH practices.
KW  - close-range photogrammetry
KW  - structure from motion
KW  - MicMac
KW  - OpenMVG
KW  - data-fusion
KW  - remote-computing
KW  - multimodal imaging
KW  - cultural heritage
DO  - 10.3390/rs12122051
TY  - EJOU
AU  - Fuentes, Sigfredo
AU  - Torrico, Damir D.
AU  - Tongson, Eden
AU  - Gonzalez Viejo, Claudia
TI  - Machine Learning Modeling of Wine Sensory Profiles and Color of Vertical Vintages of Pinot Noir Based on Chemical Fingerprinting, Weather and Management Data
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 13
SN  - 1424-8220

AB  - Important wine quality traits such as sensory profile and color are the product of complex interactions between the soil, grapevine, the environment, management, and winemaking practices. Artificial intelligence (AI) and specifically machine learning (ML) could offer powerful tools to assess these complex interactions and their patterns through seasons to predict quality traits to winegrowers close to harvest and before winemaking. This study considered nine vintages (2008&ndash;2016) using near-infrared spectroscopy (NIR) of wines and corresponding weather and management information as inputs for artificial neural network (ANN) modeling of sensory profiles (Models 1 and 2 respectively). Furthermore, weather and management data were used as inputs to predict the color of wines (Model 3). Results showed high accuracy in the prediction of sensory profiles of vertical wine vintages using NIR (Model 1; R = 0.92; slope = 0.85), while better models were obtained using weather/management data for the prediction of sensory profiles (Model 2; R = 0.98; slope = 0.93) and wine color (Model 3; R = 0.99; slope = 0.98). For all models, there was no indication of overfitting as per ANN specific tests. These models may be used as powerful tools to winegrowers and winemakers close to harvest and before the winemaking process to maintain a determined wine style with high quality and acceptability by consumers.
KW  - sensory profile
KW  - chemical fingerprinting
KW  - water balance
KW  - artificial intelligence
KW  - wine color
DO  - 10.3390/s20133618
TY  - EJOU
AU  - Lee, Hwang
AU  - Wang, Jinfei
AU  - Leblon, Brigitte
TI  - Using Linear Regression, Random Forests, and Support Vector Machine with Unmanned Aerial Vehicle Multispectral Images to Predict Canopy Nitrogen Weight in Corn
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 13
SN  - 2072-4292

AB  - The optimization of crop nitrogen fertilization to accurately predict and match the nitrogen (N) supply to the crop N demand is the subject of intense research due to the environmental and economic impact of N fertilization. Excess N could seep into the water supplies around the field and cause unnecessary spending by the farmer. The drawbacks of N deficiency on crops include poor plant growth, ultimately reducing the final yield potential. The objective of this study is to use Unmanned Aerial Vehicle (UAV) multispectral imagery to predict canopy nitrogen weight (g/m2) of corn fields in south-west Ontario, Canada. Simple/multiple linear regression, Random Forests, and support vector regression (SVR) were established to predict the canopy nitrogen weight from individual multispectral bands and associated vegetation indices (VI). Random Forests using the current techniques/methodologies performed the best out of all the models tested on the validation set with an R2 of 0.85 and Root Mean Square Error (RMSE) of 4.52 g/m2. Adding more spectral variables into the model provided a marginal improvement in the accuracy, while extending the overall processing time. Random Forests provided marginally better results than SVR, but the concepts and analysis are much easier to interpret on Random Forests. Both machine learning models provided a much better accuracy than linear regression. The best model was then applied to the UAV images acquired at different dates for producing maps that show the spatial variation of canopy nitrogen weight within each field at that date.
KW  - Unmanned Aerial Vehicle (UAV)
KW  - precision agriculture
KW  - nitrogen management
KW  - machine learning
KW  - Random Forests
KW  - canopy nitrogen weight
KW  - maize
KW  - Zea mays
DO  - 10.3390/rs12132071
TY  - EJOU
AU  - Zhang, Qichen
AU  - Zhu, Meiqiang
AU  - Zou, Liang
AU  - Li, Ming
AU  - Zhang, Yong
TI  - Learning Reward Function with Matching Network for Mapless Navigation
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 13
SN  - 1424-8220

AB  - Deep reinforcement learning (DRL) has been successfully applied in mapless navigation. An important issue in DRL is to design a reward function for evaluating actions of agents. However, designing a robust and suitable reward function greatly depends on the designer&rsquo;s experience and intuition. To address this concern, we consider employing reward shaping from trajectories on similar navigation tasks without human supervision, and propose a general reward function based on matching network (MN). The MN-based reward function is able to gain the experience by pre-training through trajectories on different navigation tasks and accelerate the training speed of DRL in new tasks. The proposed reward function keeps the optimal strategy of DRL unchanged. The simulation results on two static maps show that the DRL converge with less iterations via the learned reward function than the state-of-the-art mapless navigation methods. The proposed method performs well in dynamic maps with partially moving obstacles. Even when test maps are different from training maps, the proposed strategy is able to complete the navigation tasks without additional training.
KW  - deep reinforcement learning
KW  - reward shaping
KW  - matching network
KW  - navigation
DO  - 10.3390/s20133664
TY  - EJOU
AU  - Lin, Yao-Chin
AU  - Yeh, Ching-Chuan
AU  - Chen, Wei-Hung
AU  - Liu, Wei-Chun
AU  - Wang, Jyun-Jie
TI  - The Use of Big Data for Sustainable Development in Motor Production Line Issues
T2  - Sustainability

PY  - 2020
VL  - 12
IS  - 13
SN  - 2071-1050

AB  - This study explores big data gathered from motor production lines to gain a better understanding of production line issues. Motor products from Solen Electric Company&rsquo;s motor production lines were used to predict failure points based on big data analytics, where 3606 datapoints from the company&rsquo;s testing equipment were statistically analyzed. The current study focused on secondary data and expert interview results to further define the relevant statistical dimensions. Only 14 of the original 88 detection parameters were required for monitoring the production line. The relationships between these parameters and the relevant motor components were established to indicate how an abnormal reading may be interpreted to quickly resolve an issue. Thus, a theoretical model for the monitoring of the motor production line was proposed. Further implications and practical suggestions are also offered to improve the production lines. This study explores big data analysis and smart manufacturing and demonstrates the promise of these technologies in improving production line efficiency and reducing waste to promote sustainable production goals. Big data thus constitute the core technology for advancing production lines into Industry 4.0 and promoting industry sustainability.
KW  - motor production line
KW  - manufacturing
KW  - big data
KW  - Industry 4.0
KW  - life cycle prediction
KW  - process monitoring
DO  - 10.3390/su12135323
TY  - EJOU
AU  - Ghaffarian, Saman
AU  - Rezaie Farhadabad, Ali
AU  - Kerle, Norman
TI  - Post-Disaster Recovery Monitoring with Google Earth Engine
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 13
SN  - 2076-3417

AB  - Post-disaster recovery is a complex process in terms of measuring its progress after a disaster and understanding its components and influencing factors. During this process, disaster planners and governments need reliable information to make decisions towards building the affected region back to normal (pre-disaster), or even improved, conditions. Hence, it is essential to use methods to understand the dynamics/variables of the post-disaster recovery process, and rapid and cost-effective data and tools to monitor the process. Google Earth Engine (GEE) provides free access to vast amounts of remote sensing (RS) data and a powerful computing environment in a cloud platform, making it an attractive tool to analyze earth surface data. In this study we assessed the suitability of GEE to analyze and track recovery. To do so, we employed GEE to assess the recovery process over a three-year period after Typhoon Haiyan, which struck Leyte island, in the Philippines, in 2013. We developed an approach to (i) generate cloud and shadow-free image composites from Landsat 7 and 8 satellite imagery and produce land cover classification data using the Random Forest method, and (ii) generate damage and recovery maps based on post-classification change analysis. The method produced land cover maps with accuracies &gt;88%. We used the model to produce damage and three time-step recovery maps for 62 municipalities on Leyte island. The results showed that most of the municipalities had recovered after three years in terms of returning to the pre-disaster situation based on the selected land cover change analysis. However, more analysis (e.g., functional assessment) based on detailed data (e.g., land use maps) is needed to evaluate the more complex and subtle socio-economic aspects of the recovery. The study showed that GEE has good potential for monitoring the recovery process for extensive regions. However, the most important limitation is the lack of very-high-resolution RS data that are critical to assess the process in detail, in particular in complex urban environments.
KW  - disaster
KW  - damage
KW  - recovery
KW  - monitoring
KW  - assessment
KW  - remote sensing
KW  - satellite imagery
KW  - Landsat
KW  - Google Earth Engine
KW  - Typhoon Haiyan
KW  - cloud computing
DO  - 10.3390/app10134574
TY  - EJOU
AU  - Arce, Samuel
AU  - Vernon, Cory A.
AU  - Hammond, Joshua
AU  - Newell, Valerie
AU  - Janson, Joseph
AU  - Franke, Kevin W.
AU  - Hedengren, John D.
TI  - Automated 3D Reconstruction Using Optimized View-Planning Algorithms for Iterative Development of Structure-from-Motion Models
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 13
SN  - 2072-4292

AB  - Unsupervised machine learning algorithms (clustering, genetic, and principal component analysis) automate Unmanned Aerial Vehicle (UAV) missions as well as the creation and refinement of iterative 3D photogrammetric models with a next best view (NBV) approach. The novel approach uses Structure-from-Motion (SfM) to achieve convergence to a specified orthomosaic resolution by identifying edges in the point cloud and planning cameras that &ldquo;view&rdquo; the holes identified by edges without requiring an initial model. This iterative UAV photogrammetric method successfully runs in various Microsoft AirSim environments. Simulated ground sampling distance (GSD) of models reaches as low as     3.4     cm per pixel, and generally, successive iterations improve resolution. Besides analogous application in simulated environments, a field study of a retired municipal water tank illustrates the practical application and advantages of automated UAV iterative inspection of infrastructure using     63 %     fewer photographs than a comparable manual flight with analogous density point clouds obtaining a GSD of less than 3 cm per pixel. Each iteration qualitatively increases resolution according to a logarithmic regression, reduces holes in models, and adds details to model edges.
KW  - Structure-from-Motion
KW  - Unmanned Aerial Vehicles
KW  - iterative inspection
KW  - automated inspection
KW  - multi-scale
KW  - view-planning
KW  - unsupervised machine learning
KW  - autonomous flight
KW  - iterative optimization
DO  - 10.3390/rs12132169
TY  - EJOU
AU  - Li, Yang
AU  - Huang, Dongyan
AU  - Qi, Jiangtao
AU  - Chen, Sikai
AU  - Sun, Huibin
AU  - Liu, Huili
AU  - Jia, Honglei
TI  - Feature Point Registration Model of Farmland Surface and Its Application Based on a Monocular Camera
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 13
SN  - 1424-8220

AB  - In this study, an image registration algorithm was applied to calculate the rotation angle of objects when matching images. Some commonly used image feature detection algorithms such as features from accelerated segment test (FAST), speeded up robust features (SURF) and maximally stable extremal regions (MSER) algorithms were chosen as feature extraction components. Comparing the running time and accuracy, the image registration algorithm based on SURF has better performance than the other algorithms. Accurately obtaining the roll angle is one of the key technologies to improve the positioning accuracy and operation quality of agricultural equipment. To acquire the roll angle of agriculture machinery, a roll angle acquisition model based on the image registration algorithm was built. Then, the performance of the model with a monocular camera was tested in the field. The field test showed that the average error of the rolling angle was 0.61&deg;, while the minimum error was 0.08&deg;. The field test indicated that the model could accurately obtain the attitude change trend of agricultural machinery when it was working in irregular farmlands. The model described in this paper could provide a foundation for agricultural equipment navigation and autonomous driving.
KW  - monocular camera
KW  - farmland surface
KW  - feature point registration
KW  - attitude perception
KW  - robot vision
DO  - 10.3390/s20133799
TY  - EJOU
AU  - García-Martínez, Héctor
AU  - Flores-Magdaleno, Héctor
AU  - Ascencio-Hernández, Roberto
AU  - Khalil-Gardezi, Abdul
AU  - Tijerina-Chávez, Leonardo
AU  - Mancilla-Villa, Oscar R.
AU  - Vázquez-Peña, Mario A.
TI  - Corn Grain Yield Estimation from Vegetation Indices, Canopy Cover, Plant Density, and a Neural Network Using Multispectral and RGB Images Acquired with Unmanned Aerial Vehicles
T2  - Agriculture

PY  - 2020
VL  - 10
IS  - 7
SN  - 2077-0472

AB  - Corn yields vary spatially and temporally in the plots as a result of weather, altitude, variety, plant density, available water, nutrients, and planting date; these are the main factors that influence crop yield. In this study, different multispectral and red-green-blue (RGB) vegetation indices were analyzed, as well as the digitally estimated canopy cover and plant density, in order to estimate corn grain yield using a neural network model. The relative importance of the predictor variables was also analyzed. An experiment was established with five levels of nitrogen fertilization (140, 200, 260, 320, and 380 kg/ha) and four replicates, in a completely randomized block design, resulting in 20 experimental polygons. Crop information was captured using two sensors (Parrot Sequoia_4.9, and DJI FC6310_8.8) mounted on an unmanned aerial vehicle (UAV) for two flight dates at 47 and 79 days after sowing (DAS). The correlation coefficient between the plant density, obtained through the digital count of corn plants, and the corn grain yield was 0.94; this variable was the one with the highest relative importance in the yield estimation according to Garson&rsquo;s algorithm. The canopy cover, digitally estimated, showed a correlation coefficient of 0.77 with respect to the corn grain yield, while the relative importance of this variable in the yield estimation was 0.080 and 0.093 for 47 and 79 DAS, respectively. The wide dynamic range vegetation index (WDRVI), plant density, and canopy cover showed the highest correlation coefficient and the smallest errors (R = 0.99, mean absolute error (MAE) = 0.028 t ha&minus;1, root mean square error (RMSE) = 0.125 t ha&minus;1) in the corn grain yield estimation at 47 DAS, with the WDRVI index and the density being the variables with the highest relative importance for this crop development date. For the 79 DAS flight, the combination of the normalized difference vegetation index (NDVI), normalized difference red edge (NDRE), WDRVI, excess green (EXG), triangular greenness index (TGI), and visible atmospherically resistant index (VARI), as well as plant density and canopy cover, generated the highest correlation coefficient and the smallest errors (R = 0.97, MAE = 0.249 t ha&minus;1, RMSE = 0.425 t ha&minus;1) in the corn grain yield estimation, where the density and the NDVI were the variables with the highest relative importance, with values of 0.295 and 0.184, respectively. However, the WDRVI, plant density, and canopy cover estimated the corn grain yield with acceptable precision (R = 0.96, MAE = 0.209 t ha&minus;1, RMSE = 0.449 t ha&minus;1). The generated neural network models provided a high correlation coefficient between the estimated and the observed corn grain yield, and also showed acceptable errors in the yield estimation. The spectral information registered through remote sensors mounted on unmanned aerial vehicles and its processing in vegetation indices, canopy cover, and plant density allowed the characterization and estimation of corn grain yield. Such information is very useful for decision-making and agricultural activities planning.
KW  - vegetation indices
KW  - UAV
KW  - neural network
KW  - corn plant density
KW  - corn canopy cover
KW  - yield prediction
DO  - 10.3390/agriculture10070277
TY  - EJOU
AU  - Niculescu, Simona
AU  - Boissonnat, Jean-Baptiste
AU  - Lardeux, Cédric
AU  - Roberts, Dar
AU  - Hanganu, Jenica
AU  - Billey, Antoine
AU  - Constantinescu, Adrian
AU  - Doroftei, Mihai
TI  - Synergy of High-Resolution Radar and Optical Images Satellite for Identification and Mapping of Wetland Macrophytes on the Danube Delta
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - In wetland environments, vegetation has an important role in ecological functioning. The main goal of this work was to identify an optimal combination of Sentinel-1 (S1), Sentinel-2 (S2), and Pleiades data using ground-reference data to accurately map wetland macrophytes in the Danube Delta. We tested several combinations of optical and Synthetic Aperture Radar (SAR) data rigorously at two levels. First, in order to reduce the confusion between reed (Phragmites australis (Cav.) Trin. ex Steud.) and other macrophyte communities, a time series analysis of S1 data was performed. The potential of S1 for detection of compact reed on plaur, compact reed on plaur/reed cut, open reed on plaur, pure reed, and reed on salinized soil was evaluated through time series of backscatter coefficient and coherence ratio images, calculated mainly according to the phenology of the reed. The analysis of backscattering coefficients allowed separation of reed classes that strongly overlapped. The coherence coefficient showed that C-band SAR repeat pass interferometric coherence for cut reed detection is feasible. In the second section, random forest (RF) classification was applied to the S2, Pleiades, and S1 data and in situ observations to discriminate and map reed against other aquatic macrophytes (submerged aquatic vegetation (SAV), emergent macrophytes, some floating broad-leaved and floating vegetation of delta lakes). In addition, different optical indices were included in the RF. A total of 67 classification models were made in several sensor combinations with two series of validation samples (with the reed and without reed) using both a simple and more detailed classification schema. The results showed that reed is completely discriminable compared to other macrophyte communities with all sensor combinations. In all combinations, the model-based producer’s accuracy (PA) and user’s accuracy (UA) for reed with both nomenclatures were over 90%. The diverse combinations of sensors were valuable for improving the overall classification accuracy of all of the communities of aquatic macrophytes except Myriophyllum spicatum L.
KW  - wetland vegetation
KW  - Danube Delta
KW  - backscatter coefficient
KW  - coherence ratio
KW  - stacking of times series radar and optical
KW  - random forest
DO  - 10.3390/rs12142188
TY  - EJOU
AU  - Justa, Josef
AU  - Šmídl, Václav
AU  - Hamáček, Aleš
TI  - Fast AHRS Filter for Accelerometer, Magnetometer, and Gyroscope Combination with Separated Sensor Corrections
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 14
SN  - 1424-8220

AB  - A new predictor&ndash;corrector filter for attitude and heading reference systems (AHRS) using data from an orthogonal sensor combination of three accelerometers, three magnetometers and three gyroscopes is proposed. The filter uses the predictor&mdash;corrector structure, with prediction based on gyroscopes and independent correction steps for acceleration and magnetic field sensors. We propose two variants of the filter: (i) one using mathematical operations of special orthogonal group SO(3), that are accurate for nonlinear operations, for highest possible accuracy, and (ii) one using linearization of nonlinear operations for fast evaluation. Both approaches are quaternion-based filter realizations without redundant steps. The filters are compared to state of the art methods in this field on data recorded using low-cost microelectromechanical systems (MEMS) sensors with ground truth measured by the VICON optical system. Both filters achieved better accuracy than conventional methods at lower computational cost. The recorded data with ground truth reference and the source codes of both filters are publicly available.
KW  - attitude estimation
KW  - complementary filter
KW  - gradient descent filter
KW  - sensor fusion
DO  - 10.3390/s20143824
TY  - EJOU
AU  - Savian, Francesco
AU  - Martini, Marta
AU  - Ermacora, Paolo
AU  - Paulus, Stefan
AU  - Mahlein, Anne-Katrin
TI  - Prediction of the Kiwifruit Decline Syndrome in Diseased Orchards by Remote Sensing
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - Eight years after the first record in Italy, Kiwifruit Decline (KD), a destructive disease causing root rot, has already affected more than 25% of the area under kiwifruit cultivation in Italy. Diseased plants are characterised by severe decay of the fine roots and sudden wilting of the canopy, which is only visible after the season&rsquo;s first period of heat (July&ndash;August). The swiftness of symptom appearance prevents correct timing and positioning for sampling of the disease, and is therefore a barrier to aetiological studies. The aim of this study is to test the feasibility of thermal and multispectral imaging for the detection of KD using an unsupervised classifier. Thus, RGB, multispectral and thermal data from a kiwifruit orchard, with healthy and diseased plants, were acquired simultaneously during two consecutive growing seasons (2017&ndash;2018) using an Unmanned Aerial Vehicle (UAV) platform. Data reduction was applied to the clipped areas of the multispectral and thermal data from the 2017 survey. Reduced data were then classified with two unsupervised algorithms, a K-means and a hierarchical method. The plant vigour (canopy size and presence/absence of wilted leaves) and the health shifts exhibited by asymptomatic plants between 2017 and 2018 were evaluated from RGB data via expert assessment and used as the ground truth for cluster interpretation. Multispectral data showed a high correlation with plant vigour, while temperature data demonstrated a good potential use in predicting health shifts, especially in highly vigorous plants that were asymptomatic in 2017 and became symptomatic in 2018. The accuracy of plant vigour assessment was above 73% when using multispectral data, while clustering of the temperature data allowed the prediction of disease outbreak one year in advance, with an accuracy of 71%. Based on our results, the unsupervised clustering of remote sensing data could be a reliable tool for the identification of sampling areas, and can greatly improve aetiological studies of this new disease in kiwifruit.
KW  - disease detection
KW  - outbreak prediction
KW  - sensor fusion
KW  - unsupervised clustering
KW  - multispectral imaging
KW  - thermal imaging
KW  - unmanned aerial vehicle
KW  - UAV
DO  - 10.3390/rs12142194
TY  - EJOU
AU  - McClellan, Miranda
AU  - Cervelló-Pastor, Cristina
AU  - Sallent, Sebastià
TI  - Deep Learning at the Mobile Edge: Opportunities for 5G Networks
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 14
SN  - 2076-3417

AB  - Mobile edge computing (MEC) within 5G networks brings the power of cloud computing, storage, and analysis closer to the end user. The increased speeds and reduced delay enable novel applications such as connected vehicles, large-scale IoT, video streaming, and industry robotics. Machine Learning (ML) is leveraged within mobile edge computing to predict changes in demand based on cultural events, natural disasters, or daily commute patterns, and it prepares the network by automatically scaling up network resources as needed. Together, mobile edge computing and ML enable seamless automation of network management to reduce operational costs and enhance user experience. In this paper, we discuss the state of the art for ML within mobile edge computing and the advances needed in automating adaptive resource allocation, mobility modeling, security, and energy efficiency for 5G networks.
KW  - 5G
KW  - edge network
KW  - deep learning
KW  - reinforcement learning
KW  - caching
KW  - task offloading
KW  - mobile computing
KW  - edge computing
KW  - mobile edge computing
KW  - cloud computing
KW  - network function virtualization
KW  - slicing
KW  - 5G network standardization
DO  - 10.3390/app10144735
TY  - EJOU
AU  - Liang, Chao
AU  - Shanmugam, Bharanidharan
AU  - Azam, Sami
AU  - Karim, Asif
AU  - Islam, Ashraful
AU  - Zamani, Mazdak
AU  - Kavianpour, Sanaz
AU  - Idris, Norbik B.
TI  - Intrusion Detection System for the Internet of Things Based on Blockchain and Multi-Agent Systems
T2  - Electronics

PY  - 2020
VL  - 9
IS  - 7
SN  - 2079-9292

AB  - With the popularity of Internet of Things (IoT) technology, the security of the IoT network has become an important issue. Traditional intrusion detection systems have their limitations when applied to the IoT network due to resource constraints and the complexity. This research focusses on the design, implementation and testing of an intrusion detection system which uses a hybrid placement strategy based on a multi-agent system, blockchain and deep learning algorithms. The system consists of the following modules: data collection, data management, analysis, and response. The National security lab&ndash;knowledge discovery and data mining NSL-KDD dataset is used to test the system. The results demonstrate the efficiency of deep learning algorithms when detecting attacks from the transport layer. The experiment indicates that deep learning algorithms are suitable for intrusion detection in IoT network environment.
KW  - blockchain
KW  - Internet of Things
KW  - intrusion detection system
KW  - multi-agent system
DO  - 10.3390/electronics9071120
TY  - EJOU
AU  - Kong, Weiren
AU  - Zhou, Deyun
AU  - Yang, Zhen
AU  - Zhao, Yiyang
AU  - Zhang, Kai
TI  - UAV Autonomous Aerial Combat Maneuver Strategy Generation with Observation Error Based on State-Adversarial Deep Deterministic Policy Gradient and Inverse Reinforcement Learning
T2  - Electronics

PY  - 2020
VL  - 9
IS  - 7
SN  - 2079-9292

AB  - With the development of unmanned aerial vehicle (UAV) and artificial intelligence (AI) technology, Intelligent UAV will be widely used in future autonomous aerial combat. Previous researches on autonomous aerial combat within visual range (WVR) have limitations due to simplifying assumptions, limited robustness, and ignoring sensor errors. In this paper, in order to consider the error of the aircraft sensors, we model the aerial combat WVR as a state-adversarial Markov decision process (SA-MDP), which introduce the small adversarial perturbations on state observations and these perturbations do not alter the environment directly, but can mislead the agent into making suboptimal decisions. Meanwhile, we propose a novel autonomous aerial combat maneuver strategy generation algorithm with high-performance and high-robustness based on state-adversarial deep deterministic policy gradient algorithm (SA-DDPG), which add a robustness regularizers related to an upper bound on performance loss at the actor-network. At the same time, a reward shaping method based on maximum entropy (MaxEnt) inverse reinforcement learning algorithm (IRL) is proposed to improve the aerial combat strategy generation algorithm&rsquo;s efficiency. Finally, the efficiency of the aerial combat strategy generation algorithm and the performance and robustness of the resulting aerial combat strategy is verified by simulation experiments. Our main contributions are three-fold. First, to introduce the observation errors of UAV, we are modeling air combat as SA-MDP. Second, to make the strategy network of air combat maneuver more robust in the presence of observation errors, we introduce regularizers into the policy gradient. Third, to solve the problem that air combat&rsquo;s reward function is too sparse, we use MaxEnt IRL to design a shaping reward to accelerate the convergence of SA-DDPG.
KW  - aerial combat
KW  - reinforcement learning
KW  - robustness
KW  - sensor errors
KW  - network training
KW  - UAV
DO  - 10.3390/electronics9071121
TY  - EJOU
AU  - Vitrack-Tamam, Snir
AU  - Holtzman, Lilach
AU  - Dagan, Reut
AU  - Levi, Shai
AU  - Tadmor, Yuval
AU  - Azizi, Tamir
AU  - Rabinovitz, Onn
AU  - Naor, Amos
AU  - Liran, Oded
TI  - Random Forest Algorithm Improves Detection of Physiological Activity Embedded within Reflectance Spectra Using Stomatal Conductance as a Test Case
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - Plants transpire water through their tissues in order to move nutrients and water to the cells. Transpiration includes various mechanisms, primarily stomata movement, which controls the rate of CO2 and water vapor exchange between the tissues and the atmosphere. Assessment of stomatal conductance is available for gas exchange techniques at leaf level, yet these techniques are not scalable to the whole plant let alone a large vegetation area. Hyperspectral reflectance spectroscopy, which acquires hundreds of bands in a single scan, may capture a glimpse of the crop&rsquo;s physiological activity and therefore meet the scalability challenge. In this study, classic chemometric analyses are used alongside advanced statistical learning algorithms in order to identify stomatal conductance cues in hyperspectral measurements of cotton plants experiencing a gradient of irrigation. Random forest of regression trees identified 23 wavelengths related to both structural properties of the plant as well as water content. Partial least squares regression succeeded in relating these wavelengths to stomatal conductance, but only partially (R2 &lt; 0.2). An artificial neural network algorithm reported an R2 = 0.54 with an 89% error-free performance on the same data subset. This study discusses implementation of machine learning methodologies as a benchmark for deeper analysis of spectral information, such as required when searching for plant physiology-related attenuations embedded within reflectance spectra.
KW  - remote sensing
KW  - hyperspectral
KW  - machine learning
KW  - random forest
KW  - artificial neural network
KW  - transpiration
KW  - cotton
DO  - 10.3390/rs12142213
TY  - EJOU
AU  - Gao, Zongmei
AU  - Luo, Zhongwei
AU  - Zhang, Wen
AU  - Lv, Zhenzhen
AU  - Xu, Yanlei
TI  - Deep Learning Application in Plant Stress Imaging: A Review
T2  - AgriEngineering

PY  - 2020
VL  - 2
IS  - 3
SN  - 2624-7402

AB  - Plant stress is one of major issues that cause significant economic loss for growers. The labor-intensive conventional methods for identifying the stressed plants constrain their applications. To address this issue, rapid methods are in urgent needs. Developments of advanced sensing and machine learning techniques trigger revolutions for precision agriculture based on deep learning and big data. In this paper, we reviewed the latest deep learning approaches pertinent to the image analysis of crop stress diagnosis. We compiled the current sensor tools and deep learning principles involved in plant stress phenotyping. In addition, we reviewed a variety of deep learning applications/functions with plant stress imaging, including classification, object detection, and segmentation, of which are closely intertwined. Furthermore, we summarized and discussed the current challenges and future development avenues in plant phenotyping.
KW  - deep learning
KW  - convolutional neural network
KW  - crop stress
KW  - precision phenotyping
DO  - 10.3390/agriengineering2030029
TY  - EJOU
AU  - Jamil, Sonain
AU  - Fawad
AU  - Rahman, MuhibUr
AU  - Ullah, Amin
AU  - Badnava, Salman
AU  - Forsat, Masoud
AU  - Mirjavadi, Seyed S.
TI  - Malicious UAV Detection Using Integrated Audio and Visual Features for Public Safety Applications
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 14
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) have become popular in surveillance, security, and remote monitoring. However, they also pose serious security threats to public privacy. The timely detection of a malicious drone is currently an open research issue for security provisioning companies. Recently, the problem has been addressed by a plethora of schemes. However, each plan has a limitation, such as extreme weather conditions and huge dataset requirements. In this paper, we propose a novel framework consisting of the hybrid handcrafted and deep feature to detect and localize malicious drones from their sound and image information. The respective datasets include sounds and occluded images of birds, airplanes, and thunderstorms, with variations in resolution and illumination. Various kernels of the support vector machine (SVM) are applied to classify the features. Experimental results validate the improved performance of the proposed scheme compared to other related methods.
KW  - AlexNet
KW  - feature extraction
KW  - localization
KW  - public safety
KW  - malicious drones
KW  - surveillance
DO  - 10.3390/s20143923
TY  - EJOU
AU  - Segarra, Joel
AU  - González-Torralba, Jon
AU  - Aranjuelo, Íker
AU  - Araus, Jose L.
AU  - Kefauver, Shawn C.
TI  - Estimating Wheat Grain Yield Using Sentinel-2 Imagery and Exploring Topographic Features and Rainfall Effects on Wheat Performance in Navarre, Spain
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - Reliable methods for estimating wheat grain yield before harvest could help improve farm management and, if applied on a regional level, also help identify spatial factors that influence yield. Regional grain yield can be estimated using conventional methods, but the typical process is complex and labor-intensive. Here we describe the development of a streamlined approach using publicly accessible agricultural data, field-level yield, and remote sensing data from Sentinel-2 satellite to estimate regional wheat grain yield. We validated our method on wheat croplands in Navarre in northern Spain, which features heterogeneous topography and rainfall. First, this study developed stepwise multilinear equations to estimate grain yield based on various vegetation indices, which were measured at various phenological stages in order to determine the optimal timings. Second, the most suitable model was used to estimate grain yield in wheat parcels mapped from Sentinel-2 satellite images. We used a supervised pixel-based random forest classification and the estimates were compared to government-published post-harvest yield statistics. When tested, the model achieved an R2 of 0.83 in predicting grain yield at field level. The wheat parcels were mapped with an accuracy close to 86% for both overall accuracy and compared to official statistics. Third, the validated model was used to explore potential relationships of the mapped per-parcel grain yield estimation with topographic features and rainfall by using geographically weighted regressions. Topographic features and rainfall together accounted for an average for 11 to 20% of the observed spatial variation in grain yield in Navarre. These results highlight the ability of our method for estimating wheat grain yield before harvest and determining spatial factors that influence yield at the regional scale.
KW  - remote sensing
KW  - agriculture
KW  - crop monitoring
KW  - Sentinel-2
KW  - wheat
DO  - 10.3390/rs12142278
TY  - EJOU
AU  - Iordache, Marian-Daniel
AU  - Mantas, Vasco
AU  - Baltazar, Elsa
AU  - Pauly, Klaas
AU  - Lewyckyj, Nicolas
TI  - A Machine Learning Approach to Detecting Pine Wilt Disease Using Airborne Spectral Imagery
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - Pine Wilt Disease is one of the most destructive pests affecting coniferous forests. After being infected by the harmful Bursaphelenchus xylophilus nematode, most trees die within one year. The complex spreading pattern of the disease and the tedious hard labor process of diagnosis involving field wood sampling followed by laboratory analysis call for alternative methods to detect and manage the infected areas. Remote sensing comes naturally into play owing to the possibility of covering relatively large areas and the ability to discriminate healthy from sick trees based on spectral characteristics. This paper presents the development of machine learning classification algorithms for the detection of Pine Wilt Disease in Pinus pinaster, performed in the framework of the European Commission&rsquo;s Horizon 2020 project &ldquo;Operational Forest Monitoring using Copernicus and UAV Hyperspectral Data&rdquo; (FOCUS) in two provinces of central Portugal. Five flight campaigns have been carried out in two consecutive years in order to capture a multitemporal variation of disease distribution. Classification algorithms based on a Random Forest approach were separately designed for the acquired very-high-resolution multispectral and hyperspectral data, respectively. Both algorithms achieved overall accuracies higher than 0.91 in test data. Furthermore, our study shows that the early detection of decaying trees is feasible, even before symptoms are visible in the field.
KW  - Pine Wilt Disease
KW  - remote sensing
KW  - machine learning
KW  - classification
KW  - multispectral
KW  - hyperspectral
KW  - early detection
KW  - remotely piloted aircraft systems
DO  - 10.3390/rs12142280
TY  - EJOU
AU  - Shahmoradi, Javad
AU  - Talebi, Elaheh
AU  - Roghanchi, Pedram
AU  - Hassanalian, Mostafa
TI  - A Comprehensive Review of Applications of Drone Technology in the Mining Industry
T2  - Drones

PY  - 2020
VL  - 4
IS  - 3
SN  - 2504-446X

AB  - This paper aims to provide a comprehensive review of the current state of drone technology and its applications in the mining industry. The mining industry has shown increased interest in the use of drones for routine operations. These applications include 3D mapping of the mine environment, ore control, rock discontinuities mapping, postblast rock fragmentation measurements, and tailing stability monitoring, to name a few. The article offers a review of drone types, specifications, and applications of commercially available drones for mining applications. Finally, the research needs for the design and implementation of drones for underground mining applications are discussed.
KW  - drones
KW  - remote sensing
KW  - surface mining
KW  - underground mining
KW  - abandoned mining
DO  - 10.3390/drones4030034
TY  - EJOU
AU  - Akçay, Hüseyin G.
AU  - Kabasakal, Bekir
AU  - Aksu, Duygugül
AU  - Demir, Nusret
AU  - Öz, Melih
AU  - Erdoğan, Ali
TI  - Automated Bird Counting with Deep Learning for Regional Bird Distribution Mapping
T2  - Animals

PY  - 2020
VL  - 10
IS  - 7
SN  - 2076-2615

AB  - A challenging problem in the field of avian ecology is deriving information on bird population movement trends. This necessitates the regular counting of birds which is usually not an easily-achievable task. A promising attempt towards solving the bird counting problem in a more consistent and fast way is to predict the number of birds in different regions from their photos. For this purpose, we exploit the ability of computers to learn from past data through deep learning which has been a leading sub-field of AI for image understanding. Our data source is a collection of on-ground photos taken during our long run of birding activity. We employ several state-of-the-art generic object-detection algorithms to learn to detect birds, each being a member of one of the 38 identified species, in natural scenes. The experiments revealed that computer-aided counting outperformed the manual counting with respect to both accuracy and time. As a real-world application of image-based bird counting, we prepared the spatial bird order distribution and species diversity maps of Turkey by utilizing the geographic information system (GIS) technology. Our results suggested that deep learning can assist humans in bird monitoring activities and increase citizen scientists&rsquo; participation in large-scale bird surveys.
KW  - computer vision
KW  - machine learning
KW  - deep learning
KW  - bird detection
KW  - bird counting
KW  - bird monitoring
KW  - bird population mapping
KW  - bird diversity
KW  - GIS
KW  - citizen science
DO  - 10.3390/ani10071207
TY  - EJOU
AU  - Coviello, Luca
AU  - Cristoforetti, Marco
AU  - Jurman, Giuseppe
AU  - Furlanello, Cesare
TI  - GBCNet: In-Field Grape Berries Counting for Yield Estimation by Dilated CNNs
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 14
SN  - 2076-3417

AB  - We introduce here the Grape Berries Counting Net (GBCNet), a tool for accurate fruit yield estimation from smartphone cameras, by adapting Deep Learning algorithms originally developed for crowd counting. We test GBCNet using cross-validation procedure on two original datasets CR1 and CR2 of grape pictures taken in-field before veraison. A total of 35,668 berries have been manually annotated for the task. GBCNet achieves good performances on both the seven grape varieties dataset CR1, although with a different accuracy level depending on the variety, and on the single variety dataset CR2: in particular Mean Average Error (MAE) ranges from 0.85% for Pinot Gris to 11.73% for Marzemino on CR1 and reaches 7.24% on the Teroldego CR2 dataset.
KW  - digital agriculture
KW  - grape yield estimate
KW  - berries counting
KW  - deep learning
KW  - Dilated CNN
DO  - 10.3390/app10144870
TY  - EJOU
AU  - Mohamed, Ehab M.
AU  - Hashima, Sherief
AU  - Aldosary, Abdallah
AU  - Hatano, Kohei
AU  - Abdelghany, Mahmoud A.
TI  - Gateway Selection in Millimeter Wave UAV Wireless Networks Using Multi-Player Multi-Armed Bandit
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 14
SN  - 1424-8220

AB  - Recently, unmanned aerial vehicle (UAV)-based communications gained a lot of attention due to their numerous applications, especially in rescue services in post-disaster areas where the terrestrial network is wholly malfunctioned. Multiple access/gateway UAVs are distributed to fully cover the post-disaster area as flying base stations to provide communication coverage, collect valuable information, disseminate essential instructions, etc. The access UAVs after gathering/broadcasting the necessary information should select and fly towards one of the surrounding gateways for relaying their information. In this paper, the gateway UAV selection problem is addressed. The main aim is to maximize the long-term average data rates of the UAVs relays while minimizing the flights&rsquo; battery cost, where millimeter wave links, i.e., using 30~300 GHz band, employing antenna beamforming, are used for backhauling. A tool of machine learning (ML) is exploited to address the problem as a budget-constrained multi-player multi-armed bandit (MAB) problem. In this setup, access UAVs act as the players, and the arms are the gateway UAVs, while the rewards are the average data rates of the constructed relays constrained by the battery cost of the access UAV flights. In this decentralized setting, where information is neither prior available nor exchanged among UAVs, a selfish and concurrent multi-player MAB strategy is suggested. Towards this end, three battery-aware MAB (BA-MAB) algorithms, namely upper confidence bound (UCB), Thompson sampling (TS), and the exponential weight algorithm for exploration and exploitation (EXP3), are proposed to realize gateways selection efficiently. The proposed BA-MAB-based gateway UAV selection algorithms show superior performance over approaches based on near and random selections in terms of total system rate and energy efficiency.
KW  - unmanned aerial vehicles
KW  - millimeter wave
KW  - machine learning
KW  - multi-armed bandit
DO  - 10.3390/s20143947
TY  - EJOU
AU  - Battulwar, Rushikesh
AU  - Winkelmaier, Garrett
AU  - Valencia, Jorge
AU  - Naghadehi, Masoud Z.
AU  - Peik, Bijan
AU  - Abbasi, Behrooz
AU  - Parvin, Bahram
AU  - Sattarvand, Javad
TI  - A Practical Methodology for Generating High-Resolution 3D Models of Open-Pit Slopes Using UAVs: Flight Path Planning and Optimization
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - High-resolution terrain models of open-pit mine highwalls and benches are essential in developing new automated slope monitoring systems for operational optimization. This paper presents several contributions to the field of remote sensing in surface mines providing a practical framework for generating high-resolution images using low-trim Unmanned Aerial Vehicles (UAVs). First, a novel mobile application was developed for autonomous drone flights to follow mine terrain and capture high-resolution images of the mine surface. In this article, case study is presented showcasing the ability of developed software to import area terrain, plan the flight accordingly, and finally execute the area mapping mission autonomously. Next, to model the drone&rsquo;s battery performance, empirical studies were conducted considering various flight scenarios. A multivariate linear regression model for drone power consumption was derived from experimental data. The model has also been validated using data from a test flight. Finally, a genetic algorithm for solving the problem of flight planning and optimization has been employed. The developed power consumption model was used as the fitness function in the genetic algorithm. The designed algorithm was then validated using simulation studies. It is shown that the offered path optimization can reduce the time and energy of high-resolution imagery missions by over 50%. The current work provides a practical framework for stability monitoring of open-pit highwalls while achieving required energy optimization and imagery performance.
KW  - open-pit slope monitoring
KW  - high-resolution imaging
KW  - unmanned aerial vehicle
KW  - photogrammetry
KW  - digital elevation map
KW  - genetic algorithm
KW  - path optimization
DO  - 10.3390/rs12142283
TY  - EJOU
AU  - Muhadi, Nur A.
AU  - Abdullah, Ahmad F.
AU  - Bejo, Siti K.
AU  - Mahadi, Muhammad R.
AU  - Mijic, Ana
TI  - The Use of LiDAR-Derived DEM in Flood Applications: A Review
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - Flood occurrence is increasing due to escalated urbanization and extreme climate change; hence, various studies on this issue and methods of flood monitoring and mapping are also increasing to reduce the severe impacts of flood disasters. The advancement of current technologies such as light detection and ranging (LiDAR) systems facilitated and improved flood applications. In a LiDAR system, a laser emits light that travels to the ground and reflects off objects like buildings and trees. The reflected light energy returns to the sensor, whereby the time interval is recorded. Since the conventional methods cannot produce high-resolution digital elevation model (DEM) data, which results in low accuracy of flood simulation results, LiDAR data are extensively used as an alternative. This review aims to study the potential and the applications of LiDAR-derived DEM in flood studies. It also provides insight into the operating principles of different LiDAR systems, system components, and advantages and disadvantages of each system. This paper discusses several topics relevant to flood studies from a LiDAR-derived DEM perspective. Furthermore, the challenges and future perspectives regarding DEM LiDAR data for flood mapping and assessment are also reviewed. This study demonstrates that LiDAR-derived data are useful in flood risk management, especially in the future assessment of flood-related problems.
KW  - airborne LiDAR
KW  - DEM
KW  - flood inundation
KW  - flood map
KW  - flood model
KW  - LiDAR
KW  - terrestrial LiDAR
DO  - 10.3390/rs12142308
TY  - EJOU
AU  - Broxton, Patrick D.
AU  - van Leeuwen, Willem J. D.
TI  - Structure from Motion of Multi-Angle RPAS Imagery Complements Larger-Scale Airborne Lidar Data for Cost-Effective Snow Monitoring in Mountain Forests
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - Snowmelt from mountain forests is critically important for water resources and hydropower generation. More than 75% of surface water supply originates as snowmelt in mountainous regions, such as the western U.S. Remote sensing has the potential to measure snowpack in these areas accurately. In this research, we combine light detection and ranging (lidar) from crewed aircraft (currently, the most reliable way of measuring snow depth in mountain forests) and structure from motion (SfM) remotely piloted aircraft systems (RPAS) for cost-effective multi-temporal monitoring of snowpack in mountain forests. In sparsely forested areas, both technologies give similar snow depth maps, with a comparable agreement with ground-based snow depth observations (RMSE ~10 cm). In densely forested areas, airborne lidar is better able to represent snow depth than RPAS-SfM (RMSE ~10 cm vs ~10&ndash;20 cm). In addition, we find the relationship between RPAS-SfM and previous lidar snow depth data can be used to estimate snow depth conditions outside of relatively small RPAS-SfM monitoring plots, with RMSE&rsquo;s between these observed and estimated snow depths on the order of 10&ndash;15 cm for the larger lidar coverages. This suggests that when a single airborne lidar snow survey exists, RPAS-SfM may provide useful multi-temporal snow monitoring that can estimate basin-scale snowpack, at a much lower cost than multiple airborne lidar surveys. Doing so requires a pre-existing mid-winter or peak-snowpack airborne lidar snow survey, and subsequent well-designed paired SfM and field snow surveys that accurately capture substantial snow depth variability.
KW  - snow
KW  - remotely piloted aircraft systems
KW  - structure from motion
KW  - lidar
KW  - forests
DO  - 10.3390/rs12142311
TY  - EJOU
AU  - El Mahrad, Badr
AU  - Newton, Alice
AU  - Icely, John D.
AU  - Kacimi, Ilias
AU  - Abalansa, Samuel
AU  - Snoussi, Maria
TI  - Contribution of Remote Sensing Technologies to a Holistic Coastal and Marine Environmental Management Framework: A Review
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - Coastal and marine management require the evaluation of multiple environmental threats and issues. However, there are gaps in the necessary data and poor access or dissemination of existing data in many countries around the world. This research identifies how remote sensing can contribute to filling these gaps so that environmental agencies, such as the United Nations Environmental Programme, European Environmental Agency, and International Union for Conservation of Nature, can better implement environmental directives in a cost-effective manner. Remote sensing (RS) techniques generally allow for uniform data collection, with common acquisition and reporting methods, across large areas. Furthermore, these datasets are sometimes open-source, mainly when governments finance satellite missions. Some of these data can be used in holistic, coastal and marine environmental management frameworks, such as the DAPSI(W)R(M) framework (Drivers–Activities–Pressures–State changes–Impacts (on Welfare)–Responses (as Measures), an updated version of Drivers–Pressures–State–Impact–Responses. The framework is a useful and holistic problem-structuring framework that can be used to assess the causes, consequences, and responses to change in the marine environment. Six broad classifications of remote data collection technologies are reviewed for their potential contribution to integrated marine management, including Satellite-based Remote Sensing, Aerial Remote Sensing, Unmanned Aerial Vehicles, Unmanned Surface Vehicles, Unmanned Underwater Vehicles, and Static Sensors. A significant outcome of this study is practical inputs into each component of the DAPSI(W)R(M) framework. The RS applications are not expected to be all-inclusive; rather, they provide insight into the current use of the framework as a foundation for developing further holistic resource technologies for management strategies in the future. A significant outcome of this research will deliver practical insights for integrated coastal and marine management and demonstrate the usefulness of RS to support the implementation of environmental goals, descriptors, targets, and policies, such as the Water Framework Directive, Marine Strategy Framework Directive, Ocean Health Index, and United Nations Sustainable Development Goals. Additionally, the opportunities and challenges of these technologies are discussed.
KW  - remote sensing
KW  - DPSIR
KW  - coastal and marine management
KW  - environmental policies and directives
KW  - WFD
KW  - MSFD
KW  - ocean health index
KW  - sustainable development goals
DO  - 10.3390/rs12142313
TY  - EJOU
AU  - Díez-Herrero, Andrés
AU  - Garrote, Julio
TI  - Flood Risk Analysis and Assessment, Applications and Uncertainties: A Bibliometric Review
T2  - Water

PY  - 2020
VL  - 12
IS  - 7
SN  - 2073-4441

AB  - Studies looking at flood risk analysis and assessment (FRA) reviews are not customary, and they usually approach to methodological and spatial scale issues, uncertainty, mapping or economic damage topics. However, most of these reviews provide a snapshot of the scientific state of the art of FRA that shows only a partial view, focused on a limited number of selected methods and approaches. In this paper, we apply a bibliometric analysis using the Web of Science (WoS) database to assess the historic evolution and future prospects (emerging fields of application) of FRA. The scientific production of FRA has increased considerably in the past decade. At the beginning, US researchers dominated the field, but now they have been overtaken by the Chinese. The Netherlands and Germany may be highlighted for their more complete analyses and assessments (e.g., including an uncertainty analysis of FRA results), and this can be related to the presence of competitive research groups focused on FRA. Regarding FRA fields of application, resilience analysis shows some growth in recent years while land planning, risk perception and risk warning show a slight decrease in the number of papers published. Global warming appears to dominate part of future FRA production, which affects both fluvial and coastal floods. This, together with the improvement of economic evaluation and psycho-social analysis, appear to be the main trends for the future evolution of FRA. Finally, we cannot ignore the increase in analysis using big data analysis, machine learning techniques, and remote sensing data (particularly in the case of UAV sensors data).
KW  - flood risk analysis
KW  - flood risk assessment
KW  - flood damage uncertainty
KW  - flood hazard
KW  - flood vulnerability
DO  - 10.3390/w12072050
TY  - EJOU
AU  - Yu, Ziyang
AU  - Ustin, Susan L.
AU  - Zhang, Zhongchen
AU  - Liu, Huanjun
AU  - Zhang, Xinle
AU  - Meng, Xiangtian
AU  - Cui, Yang
AU  - Guan, Haixiang
TI  - Estimation of a New Canopy Structure Parameter for Rice Using Smartphone Photography
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 14
SN  - 1424-8220

AB  - The objective of this study was to develop a low-cost method for rice growth information obtained quickly using digital images taken with smartphone. A new canopy parameter, namely, the canopy volume parameter (CVP), was proposed and developed for rice using the leaf area index (LAI) and plant height (PH). Among these parameters, the CVP was selected as an optimal parameter to characterize rice yields during the growth period. Rice canopy images were acquired with a smartphone. Image feature parameters were extracted, including the canopy cover (CC) and numerous vegetation indices (VIs), before and after image segmentation. A rice CVP prediction model in which the CC and VIs served as independent variables was established using a random forest (RF) regression algorithm. The results revealed the following. The CVP was better than the LAI and PH for predicting the final yield. And a CVP prediction model constructed according to a local modelling method for distinguishing different types of rice varieties was the most accurate (coefficient of determination (R2) = 0.92; root mean square error (RMSE) = 0.44). These findings indicate that digital images can be used to track the growth of crops over time and provide technical support for estimating rice yields.
KW  - canopy structure
KW  - digital image
KW  - image segmentation
KW  - random forest
KW  - rice
DO  - 10.3390/s20144011
TY  - EJOU
AU  - Somerville, Gayle J.
AU  - Sønderskov, Mette
AU  - Mathiassen, Solvejg K.
AU  - Metcalfe, Helen
TI  - Spatial Modelling of Within-Field Weed Populations; a Review
T2  - Agronomy

PY  - 2020
VL  - 10
IS  - 7
SN  - 2073-4395

AB  - Concerns around herbicide resistance, human risk, and the environmental impacts of current weed control strategies have led to an increasing demand for alternative weed management methods. Many new weed management strategies are under development; however, the poor availability of accurate weed maps, and a lack of confidence in the outcomes of alternative weed management strategies, has hindered their adoption. Developments in field sampling and processing, combined with spatial modelling, can support the implementation and assessment of new and more integrated weed management strategies. Our review focuses on the biological and mathematical aspects of assembling within-field weed models. We describe both static and spatio-temporal models of within-field weed distributions (including both cellular automata (CA) and non-CA models), discussing issues surrounding the spatial processes of weed dispersal and competition and the environmental and anthropogenic processes that affect weed spatial and spatio-temporal distributions. We also examine issues surrounding model uncertainty. By reviewing the current state-of-the-art in both static and temporally dynamic weed spatial modelling we highlight some of the strengths and weaknesses of current techniques, together with current and emerging areas of interest for the application of spatial models, including targeted weed treatments, economic analysis, herbicide resistance and integrated weed management, the dispersal of biocontrol agents, and invasive weed species.
KW  - spatio-temporal models
KW  - integrated weed management
KW  - weed mapping
KW  - targeted weed treatment
KW  - site specific weed management
DO  - 10.3390/agronomy10071044
TY  - EJOU
AU  - Yang, Ming-Der
AU  - Huang, Kai-Hsiang
AU  - Tsai, Hui-Ping
TI  - Integrating MNF and HHT Transformations into Artificial Neural Networks for Hyperspectral Image Classification
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - The critical issue facing hyperspectral image (HSI) classification is the imbalance between dimensionality and the number of available training samples. This study attempted to solve the issue by proposing an integrating method using minimum noise fractions (MNF) and Hilbert&ndash;Huang transform (HHT) transformations into artificial neural networks (ANNs) for HSI classification tasks. MNF and HHT function as a feature extractor and image decomposer, respectively, to minimize influences of noises and dimensionality and to maximize training sample efficiency. Experimental results using two benchmark datasets, Indian Pine (IP) and Pavia University (PaviaU) hyperspectral images, are presented. With the intention of optimizing the number of essential neurons and training samples in the ANN, 1 to 1000 neurons and four proportions of training sample were tested, and the associated classification accuracies were evaluated. For the IP dataset, the results showed a remarkable classification accuracy of 99.81% with a 30% training sample from the MNF1&ndash;14+HHT-transformed image set using 500 neurons. Additionally, a high accuracy of 97.62% using only a 5% training sample was achieved for the MNF1&ndash;14+HHT-transformed images. For the PaviaU dataset, the highest classification accuracy was 98.70% with a 30% training sample from the MNF1&ndash;14+HHT-transformed image using 800 neurons. In general, the accuracy increased as the neurons increased, and as the training samples increased. However, the accuracy improvement curve became relatively flat when more than 200 neurons were used, which revealed that using more discriminative information from transformed images can reduce the number of neurons needed to adequately describe the data as well as reducing the complexity of the ANN model. Overall, the proposed method opens new avenues in the use of MNF and HHT transformations for HSI classification with outstanding accuracy performance using an ANN.
KW  - Hilbert Huang Transform (HHT)
KW  - hyperspectral image
KW  - Minimum Noise Fraction (MNF)
KW  - Artificial Neural Networks (ANNs)
DO  - 10.3390/rs12142327
TY  - EJOU
AU  - Grulke, Nancy
AU  - Maxfield, Jason
AU  - Riggan, Phillip
AU  - Schrader-Patton, Charlie
TI  - Pre-Emptive Detection of Mature Pine Drought Stress Using Multispectral Aerial Imagery
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - Drought, ozone (O3), and nitrogen deposition (N) alter foliar pigments and tree crown structure that may be remotely detectable. Remote sensing tools are needed that pre-emptively identify trees susceptible to environmental stresses could inform forest managers in advance of tree mortality risk. Jeffrey pine, a component of the economically important and widespread western yellow pine in North America was investigated in the southern Sierra Nevada. Transpiration of mature trees differed by 20% between microsites with adequate (mesic (M)) vs. limited (xeric (X)) water availability as described in a previous study. In this study, in-the-crown morphological traits (needle chlorosis, branchlet diameter, and frequency of needle defoliators and dwarf mistletoe) were significantly correlated with aerially detected, sub-crown spectral traits (upper crown NDVI, high resolution (R), near-infrared (NIR) Scalar (inverse of NDVI) and THERM &Delta;, and the difference between upper and mid crown temperature). A classification tree model sorted trees into X and M microsites with THERM &Delta; alone (20% error), which was partially validated at a second site with only mesic trees (2% error). Random forest separated M and X site trees with additional spectra (17% error). Imagery taken once, from an aerial platform with sub-crown resolution, under the challenge of drought stress, was effective in identifying droughted trees within the context of other environmental stresses.
KW  - remote sensing
KW  - physiological drought stress
KW  - within-crown resolution
KW  - jeffrey pine
KW  - sierra nevada
KW  - thermal imagery
DO  - 10.3390/rs12142338
TY  - EJOU
AU  - Kim, Sung-Min
AU  - Choi, Yosoon
AU  - Suh, Jangwon
TI  - Applications of the Open-Source Hardware Arduino Platform in the Mining Industry: A Review
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 14
SN  - 2076-3417

AB  - In this study, applications of the Arduino platform in the mining industry were reviewed. Arduino, a representative and popular open-source hardware, can acquire information from various sensors, transmit data using communication technology, and control devices through actuators. The review was conducted by classifying previous studies into three types of Arduino applications: field monitoring systems, wearable systems, and autonomous systems. With regard to field monitoring systems, most studies in mines were classified as atmospheric or geotechnical monitoring. In wearable systems, the health status of the miner was an important consideration, in addition to the environmental conditions of the mine. Arduino can be a useful tool as an initial prototype for autonomous mine systems. Arduino has advantages in that it can be combined with various electronic products and is cost-effective. Therefore, although many studies have been conducted in the laboratory (as opposed to field tests), Arduino applications can be further expanded in the mining field in the future.
KW  - open-source hardware
KW  - Arduino
KW  - monitoring
KW  - wearable
KW  - autonomous system
DO  - 10.3390/app10145018
TY  - EJOU
AU  - Qiu, Zhengjun
AU  - Zhao, Nan
AU  - Zhou, Lei
AU  - Wang, Mengcen
AU  - Yang, Liangliang
AU  - Fang, Hui
AU  - He, Yong
AU  - Liu, Yufei
TI  - Vision-Based Moving Obstacle Detection and Tracking in Paddy Field Using Improved Yolov3 and Deep SORT
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 15
SN  - 1424-8220

AB  - Using intelligent agricultural machines in paddy fields has received great attention. An obstacle avoidance system is required with the development of agricultural machines. In order to make the machines more intelligent, detecting and tracking obstacles, especially the moving obstacles in paddy fields, is the basis of obstacle avoidance. To achieve this goal, a red, green and blue (RGB) camera and a computer were used to build a machine vision system, mounted on a transplanter. A method that combined the improved You Only Look Once version 3 (Yolov3) and deep Simple Online and Realtime Tracking (deep SORT) was used to detect and track typical moving obstacles, and figure out the center point positions of the obstacles in paddy fields. The improved Yolov3 has 23 residual blocks and upsamples only once, and has new loss calculation functions. Results showed that the improved Yolov3 obtained mean intersection over union (mIoU) score of 0.779 and was 27.3% faster in processing speed than standard Yolov3 on a self-created test dataset of moving obstacles (human and water buffalo) in paddy fields. An acceptable performance for detecting and tracking could be obtained in a real paddy field test with an average processing speed of 5&ndash;7 frames per second (FPS), which satisfies actual work demands. In future research, the proposed system could support the intelligent agriculture machines more flexible in autonomous navigation.
KW  - machine vision
KW  - deep learning
KW  - detecting and tracking
KW  - moving obstacles
KW  - paddy field
DO  - 10.3390/s20154082
TY  - EJOU
AU  - Blanco, Víctor
AU  - Blaya-Ros, Pedro J.
AU  - Castillo, Cristina
AU  - Soto-Vallés, Fulgencio
AU  - Torres-Sánchez, Roque
AU  - Domingo, Rafael
TI  - Potential of UAS-Based Remote Sensing for Estimating Tree Water Status and Yield in Sweet Cherry Trees
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 15
SN  - 2072-4292

AB  - The present work aims to assess the usefulness of five vegetation indices (VI) derived from multispectral UAS imagery to capture the effects of deficit irrigation on the canopy structure of sweet cherry trees (Prunus avium L.) in southeastern Spain. Three irrigation treatments were assayed, a control treatment and two regulated deficit irrigation treatments. Four airborne flights were carried out during two consecutive seasons; to compare the results of the remote sensing VI, the conventional and continuous water status indicators commonly used to manage sweet cherry tree irrigation were measured, including midday stem water potential (&Psi;s) and maximum daily shrinkage (MDS). Simple regression between individual VIs and &Psi;s or MDS found stronger relationships in postharvest than in preharvest. Thus, the normalized difference vegetation index (NDVI), resulted in the strongest relationship with &Psi;s (r2 = 0.67) and MDS (r2 = 0.45), followed by the normalized difference red edge (NDRE). The sensitivity analysis identified the optimal soil adjusted vegetation index (OSAVI) as the VI with the highest coefficient of variation in postharvest and the difference vegetation index (DVI) in preharvest. A new index is proposed, the transformed red range vegetation index (TRRVI), which was the only VI able to statistically identify a slight water deficit applied in preharvest. The combination of the VIs studied was used in two machine learning models, decision tree and artificial neural networks, to estimate the extra labor needed for harvesting and the sweet cherry yield.
KW  - artificial neuronal network
KW  - decision tree
KW  - DVI
KW  - NDVI
KW  - NDRE
KW  - OSAVI
KW  - water deficit
DO  - 10.3390/rs12152359
TY  - EJOU
AU  - Stepinac, Mislav
AU  - Gašparović, Mateo
TI  - A Review of Emerging Technologies for an Assessment of Safety and Seismic Vulnerability and Damage Detection of Existing Masonry Structures
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 15
SN  - 2076-3417

AB  - The construction sector has proven to be one of the slowest sectors to embrace technology&mdash;a problem that must be addressed. This problem can be quickly and efficiently addressed in certain aspects of seismic engineering: from seismic risk assessment to damage detection, as well as condition assessments existing structures before or after an earthquake. In this paper, the literature review of assessment methods and damage detection technologies for existing (mainly) masonry structures is presented. Traditional methods are briefly explained, and modern are critically discussed. Special focus is given to unmanned aerial vehicles, as well as, photogrammetry and close-range remote sensing as a technology that can complement traditional ways of assessment and give us data about a structure that is often different to obtain. Graphical interpretation of one post-earthquake case study is provided. Open challenges and opportunities of emerging technologies for faster and easier assessment of seismic safety and vulnerability are presented.
KW  - earthquake
KW  - vulnerability
KW  - unmanned aerial vehicle
KW  - damage detection
KW  - assessment
KW  - photogrammetry
KW  - close-range remote sensing
DO  - 10.3390/app10155060
TY  - EJOU
AU  - Weldon, William T.
AU  - Hupy, Joseph
TI  - Investigating Methods for Integrating Unmanned Aerial Systems in Search and Rescue Operations
T2  - Drones

PY  - 2020
VL  - 4
IS  - 3
SN  - 2504-446X

AB  - Unmanned aerial systems (UAS) are increasingly being used in search and rescue (SAR) operations to assist in the discovery of missing persons. UAS are useful to first responders in SAR operations due to rapid deployment, high data volume, and high spatial resolution data collection capabilities. Relying on traditional manual interpretation methods to find a missing person in imagery data sets containing several hundred images is both challenging and time consuming. To better find small signs of missing persons in large UAS datasets, computer assisted interpretation methods have been developed. This article presents the results of an initial evaluation of a computer assisted interpretation method tested against manual methods in a simulated SAR operation. The evaluation performed focused on using resources available to first responders performing SAR operations, specifically: RGB data, volunteers, and a commercially available software program. Results from this field test were mixed, as the traditional group discovered more objects but required more time, in man hours, to discover the objects. Further field experiments, based on the capabilities of current first responder groups, should be conducted to determine to what extent computer assisted methods are useful in SAR operations.
KW  - unmanned aerial systems
KW  - search and rescue
KW  - operations
KW  - color spectrum
KW  - aerial imagery
DO  - 10.3390/drones4030038
TY  - EJOU
AU  - Pulido, Dagoberto
AU  - Salas, Joaquín
AU  - Rös, Matthias
AU  - Puettmann, Klaus
AU  - Karaman, Sertac
TI  - Assessment of Tree Detection Methods in Multispectral Aerial Images
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 15
SN  - 2072-4292

AB  - Detecting individual trees and quantifying their biomass is crucial for carbon accounting procedures at the stand, landscape, and national levels. A significant challenge for many organizations is the amount of effort necessary to document carbon storage levels, especially in terms of human labor. To advance towards the goal of efficiently assessing the carbon content of forest, we evaluate methods to detect trees from high-resolution images taken from unoccupied aerial systems (UAS). In the process, we introduce the Digital Elevated Vegetation Model (DEVM), a representation that combines multispectral images, digital surface models, and digital terrain models. We show that the DEVM facilitates the development of refined synthetic data to detect individual trees using deep learning-based approaches. We carried out experiments in two tree fields located in different countries. Simultaneously, we perform comparisons among an array of classical and deep learning-based methods highlighting the precision and reliability of the DEVM.
KW  - tree detection
KW  - convolutional neural networks
KW  - unocuppied aerial systems
KW  - digital elevated vegetation model
KW  - synthetic data set
DO  - 10.3390/rs12152379
TY  - EJOU
AU  - Prosekov, Alexander
AU  - Kuznetsov, Alexander
AU  - Rada, Artem
AU  - Ivanova, Svetlana
TI  - Methods for Monitoring Large Terrestrial Animals in the Wild
T2  - Forests

PY  - 2020
VL  - 11
IS  - 8
SN  - 1999-4907

AB  - Reliable information about wildlife is absolutely important for making informed management decisions. The issues with the effectiveness of the control and monitoring of both large and small wild animals are relevant to assess and protect the world&rsquo;s biodiversity. Monitoring becomes part of the methods in wildlife ecology for observation, assessment, and forecasting of the human environment. World practice reveals the potential of the joint application of both proven traditional and modern technologies using specialized equipment to organize environmental control and management processes. Monitoring large terrestrial animals require an individual approach due to their low density and larger habitat. Elk/moose are such animals. This work aims to evaluate the methods for monitoring large wild animals, suitable for controlling the number of elk/moose in the framework of nature conservation activities. Using different models allows determining the population size without affecting the animals and without significant financial costs. Although, the accuracy of each model is determined by its postulates implementation and initial conditions that need statistical data. Depending on the geographical, climatic, and economic conditions in each territory, it is possible to use different tools and equipment (e.g., cameras, GPS sensors, and unmanned aerial vehicles), a flexible variation of which will allow reaching the golden mean between the desires and capabilities of researchers.
KW  - monitoring methods
KW  - large wild animals
KW  - elk
KW  - moose
KW  - hunting
KW  - unmanned aerial vehicles
DO  - 10.3390/f11080808
TY  - EJOU
AU  - Schlosser, Aletta D.
AU  - Szabó, Gergely
AU  - Bertalan, László
AU  - Varga, Zsolt
AU  - Enyedi, Péter
AU  - Szabó, Szilárd
TI  - Building Extraction Using Orthophotos and Dense Point Cloud Derived from Visual Band Aerial Imagery Based on Machine Learning and Segmentation
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 15
SN  - 2072-4292

AB  - Urban sprawl related increase of built-in areas requires reliable monitoring methods and remote sensing can be an efficient technique. Aerial surveys, with high spatial resolution, provide detailed data for building monitoring, but archive images usually have only visible bands. We aimed to reveal the efficiency of visible orthophotographs and photogrammetric dense point clouds in building detection with segmentation-based machine learning (with five algorithms) using visible bands, texture information, and spectral and morphometric indices in different variable sets. Usually random forest (RF) had the best (99.8%) and partial least squares the worst overall accuracy (~60%). We found that &gt;95% accuracy can be gained even in class level. Recursive feature elimination (RFE) was an efficient variable selection tool, its result with six variables was like when we applied all the available 31 variables. Morphometric indices had 82% producer&rsquo;s and 85% user&rsquo;s Accuracy (PA and UA, respectively) and combining them with spectral and texture indices, it had the largest contribution in the improvement. However, morphometric indices are not always available but by adding texture and spectral indices to red-green-blue (RGB) bands the PA improved with 12% and the UA with 6%. Building extraction from visual aerial surveys can be accurate, and archive images can be involved in the time series of a monitoring.
KW  - photogrammetry
KW  - RGB indices
KW  - image texture
KW  - morphometric indices
KW  - recursive feature elimination
KW  - random forest
KW  - support vector machine
KW  - multiple adaptive regression spline
KW  - partial least squares
DO  - 10.3390/rs12152397
TY  - EJOU
AU  - Pleșoianu, Alin-Ionuț
AU  - Stupariu, Mihai-Sorin
AU  - Șandric, Ionuț
AU  - Pătru-Stupariu, Ileana
AU  - Drăguț, Lucian
TI  - Individual Tree-Crown Detection and Species Classification in Very High-Resolution Remote Sensing Imagery Using a Deep Learning Ensemble Model
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 15
SN  - 2072-4292

AB  - Traditional methods for individual tree-crown (ITC) detection (image classification, segmentation, template matching, etc.) applied to very high-resolution remote sensing imagery have been shown to struggle in disparate landscape types or image resolutions due to scale problems and information complexity. Deep learning promised to overcome these shortcomings due to its superior performance and versatility, proven with reported detection rates of ~90%. However, such models still find their limits in transferability across study areas, because of different tree conditions (e.g., isolated trees vs. compact forests) and/or resolutions of the input data. This study introduces a highly replicable deep learning ensemble design for ITC detection and species classification based on the established single shot detector (SSD) model. The ensemble model design is based on varying the input data for the SSD models, coupled with a voting strategy for the output predictions. Very high-resolution unmanned aerial vehicles (UAV), aerial remote sensing imagery and elevation data are used in different combinations to test the performance of the ensemble models in three study sites with highly contrasting spatial patterns. The results show that ensemble models perform better than any single SSD model, regardless of the local tree conditions or image resolution. The detection performance and the accuracy rates improved by 3&ndash;18% with only as few as two participant single models, regardless of the study site. However, when more than two models were included, the performance of the ensemble models only improved slightly and even dropped.
KW  - tree-crown detection
KW  - deep learning
KW  - ensemble model
KW  - object detection
KW  - single shot detector
DO  - 10.3390/rs12152426
TY  - EJOU
AU  - Gad, Mohamed
AU  - Elsayed, Salah
AU  - Moghanm, Farahat S.
AU  - Almarshadi, Mohammed H.
AU  - Alshammari, Abdullah S.
AU  - Khedher, Khaled M.
AU  - Eid, Ebrahem M.
AU  - Hussein, Hend
TI  - Combining Water Quality Indices and Multivariate Modeling to Assess Surface Water Quality in the Northern Nile Delta, Egypt
T2  - Water

PY  - 2020
VL  - 12
IS  - 8
SN  - 2073-4441

AB  - Assessing surface water quality for drinking use in developing countries is important since water quality is a fundamental aspect of surface water management. This study aims to improve surface water quality assessments and their controlling mechanisms using the drinking water quality index (DWQI) and four pollution indices (PIs), which are supported by multivariate statistical analyses, such as principal component analysis, partial least squares regression (PLSR), and stepwise multiple linear regression (SMLR). Twenty-two physicochemical parameters were analyzed using standard analytical methods for 55 surface water sites in the northern Nile Delta, Egypt. The DWQI results indicated that 33% of the tested samples represented good water, and 67% of samples indicated poor to unsuitable water for drinking use. The PI results revealed that surface water samples were strongly affected by Pb and Mn and were slightly affected by Fe and Cr. The SMLR models of the DWQI and PIs, which were based on all major ions and heavy metals, provided the best estimations with R2 = 1 for the DWQI and PIs. In conclusion, integration between the DWQI and PIs is a valuable and applicable approach for the assessment of surface water quality, and the PLSR and SMLR models can be used through applications of chemometric techniques to evaluate the DWQI and PIs.
KW  - Nile Delta
KW  - PLSR model
KW  - pollution indices
KW  - SMLR model
KW  - surface water
KW  - water quality
DO  - 10.3390/w12082142
TY  - EJOU
AU  - Campos-Vargas, Carlos
AU  - Sanchez-Azofeifa, Arturo
AU  - Laakso, Kati
AU  - Marzahn, Philip
TI  - Unmanned Aerial System and Machine Learning Techniques Help to Detect Dead Woody Components in a Tropical Dry Forest
T2  - Forests

PY  - 2020
VL  - 11
IS  - 8
SN  - 1999-4907

AB  - Background and Objectives: Increased frequency and intensity of drought events are predicted to occur throughout the world because of climate change. These extreme climate events result in higher tree mortality and fraction of dead woody components, phenomena that are currently being reported worldwide as critical indicators of the impacts of climate change on forest diversity and function. In this paper, we assess the accuracy and processing times of ten machine learning (ML) techniques, applied to multispectral unmanned aerial vehicle (UAV) data to detect dead canopy woody components. Materials and Methods: This work was conducted on five secondary dry forest plots located at the Santa Rosa National Park Environmental Monitoring Super Site, Costa Rica. Results: The coverage of dead woody components at the selected secondary dry forest plots was estimated to range from 4.8% to 16.1%, with no differences between the successional stages. Of the ten ML techniques, the support vector machine with radial kernel (SVMR) and random forests (RF) provided the highest accuracies (0.982 vs. 0.98, respectively). Of these two ML algorithms, the processing time of SVMR was longer than the processing time of RF (8735.64 s vs. 989 s). Conclusions: Our results demonstrate that it is feasible to detect and quantify dead woody components, such as dead stands and fallen trees, using a combination of high-resolution UAV data and ML algorithms. Using this technology, accuracy values higher than 95% were achieved. However, it is important to account for a series of factors, such as the optimization of the tuning parameters of the ML algorithms, the environmental conditions and the time of the UAV data acquisition.
KW  - Costa Rica
KW  - forest mortality
KW  - machine learning
KW  - tropical dry forests
KW  - unmanned aerial systems
DO  - 10.3390/f11080827
TY  - EJOU
AU  - Mekhalfi, Mohamed L.
AU  - Nicolò, Carlo
AU  - Ianniello, Ivan
AU  - Calamita, Federico
AU  - Goller, Rino
AU  - Barazzuol, Maurizio
AU  - Melgani, Farid
TI  - Vision System for Automatic On-Tree Kiwifruit Counting and Yield Estimation
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 15
SN  - 1424-8220

AB  - Yield estimation is an essential preharvest practice among most large-scale farming companies, since it enables the predetermination of essential logistics to be allocated (i.e., transportation means, supplies, labor force, among others). An overestimation may thus incur further costs, whereas an underestimation entails potential crop waste. More interestingly, an accurate yield estimation enables stakeholders to better place themselves in the market. Yet, computer-aided precision farming is set to play a pivotal role in this respect. Kiwifruit represents a major produce in several countries (e.g., Italy, China, New and Zealand). However, up to date, the relevant literature remains short of a complete as well as automatic system for kiwifruit yield estimation. In this paper, we present a fully automatic and noninvasive computer vision system for kiwifruit yield estimation across a given orchard. It consists mainly of an optical sensor mounted on a minitractor that surveys the orchard of interest at a low pace. Afterwards, the acquired images are fed to a pipeline that incorporates image preprocessing, stitching, and fruit counting stages and outputs an estimated fruit count and yield estimation. Experimental results conducted on two large kiwifruit orchards confirm a high plausibility (i.e., errors of 6% and 15%) of the proposed system. The proposed yield estimation solution has been in commercial use for about 2 years. With respect to the traditional manual yield estimation carried out by kiwifruit companies, it was demonstrated to save a significant amount of time and cut down on estimation errors, especially when speaking of large-scale farming.
KW  - kiwifruit
KW  - fruit counting
KW  - yield estimation
KW  - computer vision fruit detection
DO  - 10.3390/s20154214
TY  - EJOU
AU  - Chaoui, Hicham
AU  - Yadav, Sumit
AU  - Ahmadi, Rosita S.
AU  - Bouzid, Allal E.
TI  - Adaptive Interval Type-2 Fuzzy Logic Control of a Three Degree-of-Freedom Helicopter
T2  - Robotics

PY  - 2020
VL  - 9
IS  - 3
SN  - 2218-6581

AB  - This paper combines interval type-2 fuzzy logic with adaptive control theory for the control of a three degree-of-freedom (DOF) helicopter. This strategy yields robustness to various kinds of uncertainties and guaranteed stability of the closed-loop control system. Thus, precise trajectory tracking is maintained under various operational conditions with the presence of various types of uncertainties. Unlike other controllers, the proposed controller approximates the helicopter&rsquo;s inverse dynamic model and assumes no a priori knowledge of the helicopter&rsquo;s dynamics or parameters. The proposed controller is applied to a 3-DOF helicopter model and compared against three other controllers, i.e., PID control, adaptive control, and adaptive sliding-mode control. Numerical results show its high performance and robustness under the presence of uncertainties. To better assess the performance of the control system, two quantitative tracking performance metrics are introduced, i.e., the integral of the tracking errors and the integral of the control signals. Comparative numerical results reveal the superiority of the proposed method by achieving the highest tracking accuracy with the lowest control effort.
KW  - adaptive control
KW  - 3-DOF helicopter
KW  - uncertainties
KW  - type-2 fuzzy logic
DO  - 10.3390/robotics9030059
TY  - EJOU
AU  - Ranđelović, Predrag
AU  - Đorđević, Vuk
AU  - Milić, Stanko
AU  - Balešević-Tubić, Svetlana
AU  - Petrović, Kristina
AU  - Miladinović, Jegor
AU  - Đukić, Vojin
TI  - Prediction of Soybean Plant Density Using a Machine Learning Model and Vegetation Indices Extracted from RGB Images Taken with a UAV
T2  - Agronomy

PY  - 2020
VL  - 10
IS  - 8
SN  - 2073-4395

AB  - Soybean plant density is an important factor of successful agricultural production. Due to the high number of plants per unit area, early plant overlapping and eventual plant loss, the estimation of soybean plant density in the later stages of development should enable the determination of the final plant number and reflect the state of the harvest. In order to assess soybean plant density in a digital, nondestructive, and less intense way, analysis was performed on RGB images (containing three channels: RED, GREEN, and BLUE) taken with a UAV (Unmanned Aerial Vehicle) on 66 experimental plots in 2018, and 200 experimental plots in 2019. Mean values of the R, G, and B channels were extracted for each plot, then vegetation indices (VIs) were calculated and used as predictors for the machine learning model (MLM). The model was calibrated in 2018 and validated in 2019. For validation purposes, the predicted values for the 200 experimental plots were compared with the real number of plants per unit area (m2). Model validation resulted in the correlation coefficient&mdash;R = 0.87, mean absolute error (MAE) = 6.24, and root mean square error (RMSE) = 7.47. The results of the research indicate the possibility of using the MLM, based on simple values of VIs, for the prediction of plant density in agriculture without using human labor.
KW  - soybean
KW  - machine learning
KW  - vegetation indices
KW  - UAV
KW  - RGB images
DO  - 10.3390/agronomy10081108
TY  - EJOU
AU  - Michailidis, Emmanouel T.
AU  - Potirakis, Stelios M.
AU  - Kanatas, Athanasios G.
TI  - AI-Inspired Non-Terrestrial Networks for IIoT: Review on Enabling Technologies and Applications
T2  - IoT

PY  - 2020
VL  - 1
IS  - 1
SN  - 2624-831X

AB  - During the last few years, various Industrial Internet of Things (IIoT) applications have emerged with numerous network elements interconnected using wired and wireless communication technologies and equipped with strategically placed sensors and actuators. This paper justifies why non-terrestrial networks (NTNs) will bring the IIoT vision closer to reality by providing improved data acquisition and massive connectivity to sensor fields in large and remote areas. NTNs are engineered to utilize satellites, airships, and aircrafts, which can be employed to extend the radio coverage and provide remote monitoring and sensing services. Additionally, this paper describes indicative delay-tolerant massive IIoT and delay-sensitive mission-critical IIoT applications spanning a large number of vertical markets with diverse and stringent requirements. As the heterogeneous nature of NTNs and the complex and dynamic communications scenarios lead to uncertainty and a high degree of variability, conventional wireless communication technologies cannot sufficiently support ultra-reliable and low-latency communications (URLLC) and offer ubiquitous and uninterrupted interconnectivity. In this regard, this paper sheds light on the potential role of artificial intelligence (AI) techniques, including machine learning (ML) and deep learning (DL), in the provision of challenging NTN-based IIoT services and provides a thorough review of the relevant research works. By adding intelligence and facilitating the decision-making and prediction procedures, the NTNs can effectively adapt to their surrounding environment, thus enhancing the performance of various metrics with significantly lower complexity compared to typical optimization methods.
KW  - deep learning (DL)
KW  - high-altitude platforms (HAPs)
KW  - industrial internet of things (IIoT)
KW  - machine learning (ML)
KW  - satellite networks
KW  - unmanned aerial vehicles (UAVs)
DO  - 10.3390/iot1010003
TY  - EJOU
AU  - You, Yanan
AU  - Cao, Jingyi
AU  - Zhou, Wenli
TI  - A Survey of Change Detection Methods Based on Remote Sensing Images for Multi-Source and Multi-Objective Scenarios
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 15
SN  - 2072-4292

AB  - Quantities of multi-temporal remote sensing (RS) images create favorable conditions for exploring the urban change in the long term. However, diverse multi-source features and change patterns bring challenges to the change detection in urban cases. In order to sort out the development venation of urban change detection, we make an observation of the literatures on change detection in the last five years, which focuses on the disparate multi-source RS images and multi-objective scenarios determined according to scene category. Based on the survey, a general change detection framework, including change information extraction, data fusion, and analysis of multi-objective scenarios modules, is summarized. Owing to the attributes of input RS images affect the technical selection of each module, data characteristics and application domains across different categories of RS images are discussed firstly. On this basis, not only the evolution process and relationship of the representative solutions are elaborated in the module description, through emphasizing the feasibility of fusing diverse data and the manifold application scenarios, we also advocate a complete change detection pipeline. At the end of the paper, we conclude the current development situation and put forward possible research direction of urban change detection, in the hope of providing insights to the following research.
KW  - change detection
KW  - data fusion
KW  - multi-objective scenarios
DO  - 10.3390/rs12152460
TY  - EJOU
AU  - Jia, Guifeng
AU  - Li, Wei
AU  - Meng, Junyu
AU  - Tan, Hequn
AU  - Feng, Yaoze
TI  - Non-Contact Evaluation of Pigs’ Body Temperature Incorporating Environmental Factors
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 15
SN  - 1424-8220

AB  - Internal body temperature is the gold standard for the fever of pigs, however non-contact infrared imaging technology (IRT) can only measure the skin temperature of regions of interest (ROI). Therefore, using IRT to detect the internal body temperature should be based on a correlation model between the ROI temperature and the internal temperature. When heat exchange between the ROI and the surroundings makes the ROI temperature more correlated with the environment, merely depending on the ROI to predict the internal temperature is unreliable. To ensure a high prediction accuracy, this paper investigated the influence of air temperature and humidity on ROI temperature, then built a prediction model incorporating them. The animal test includes 18 swine. IRT was employed to collect the temperatures of the backside, eye, vulva, and ear root ROIs; meanwhile, the air temperature and humidity were recorded. Body temperature prediction models incorporating environmental factors and the ROI temperature were constructed based on Back Propagate Neural Net (BPNN), Random Forest (RF), and Support Vector Regression (SVR). All three models yielded better results regarding the maximum error, minimum error, and mean square error (MSE) when the environmental factors were considered. When environmental factors were incorporated, SVR produced the best outcome, with the maximum error at 0.478 &deg;C, the minimum error at 0.124 &deg;C, and the MSE at 0.159 &deg;C. The result demonstrated the accuracy and applicability of SVR as a prediction model of pigs&prime; internal body temperature.
KW  - infrared imaging
KW  - pigs
KW  - temperature prediction model
KW  - support vector regression
DO  - 10.3390/s20154282
TY  - EJOU
AU  - Su, Wen-Hao
TI  - Advanced Machine Learning in Point Spectroscopy, RGB- and Hyperspectral-Imaging for Automatic Discriminations of Crops and Weeds: A Review
T2  - Smart Cities

PY  - 2020
VL  - 3
IS  - 3
SN  - 2624-6511

AB  - Crop productivity is readily reduced by competition from weeds. It is particularly important to control weeds early to prevent yield losses. Limited herbicide choices and increasing costs of weed management are threatening the profitability of crops. Smart agriculture can use intelligent technology to accurately measure the distribution of weeds in the field and perform weed control tasks in selected areas, which cannot only improve the effectiveness of pesticides, but also increase the economic benefits of agricultural products. The most important thing for an automatic system to remove weeds within crop rows is to utilize reliable sensing technology to achieve accurate differentiation of weeds and crops at specific locations in the field. In recent years, there have been many significant achievements involving the differentiation of crops and weeds. These studies are related to the development of rapid and non-destructive sensors, as well as the analysis methods for the data obtained. This paper presents a review of the use of three sensing methods including spectroscopy, color imaging, and hyperspectral imaging in the discrimination of crops and weeds. Several algorithms of machine learning have been employed for data analysis such as convolutional neural network (CNN), artificial neural network (ANN), and support vector machine (SVM). Successful applications include the weed detection in grain crops (such as maize, wheat, and soybean), vegetable crops (such as tomato, lettuce, and radish), and fiber crops (such as cotton) with unsupervised or supervised learning. This review gives a brief introduction into proposed sensing and machine learning methods, then provides an overview of instructive examples of these techniques for weed/crop discrimination. The discussion describes the recent progress made in the development of automated technology for accurate plant identification as well as the challenges and future prospects. It is believed that this review is of great significance to those who study automatic plant care in crops using intelligent technology.
KW  - smart farm
KW  - sensing
KW  - machine learning
KW  - plant identification
KW  - weed control
DO  - 10.3390/smartcities3030039
TY  - EJOU
AU  - Cecchetti, Riccardo
AU  - de Paulis, Francesco
AU  - Olivieri, Carlo
AU  - Orlandi, Antonio
AU  - Buecker, Markus
TI  - Effective PCB Decoupling Optimization by Combining an Iterative Genetic Algorithm and Machine Learning
T2  - Electronics

PY  - 2020
VL  - 9
IS  - 8
SN  - 2079-9292

AB  - An iterative optimization for decoupling capacitor placement on a power delivery network (PDN) is presented based on Genetic Algorithm (GA) and Artificial Neural Network (ANN). The ANN is first trained by an appropriate set of results obtained by a commercial simulator. Once the ANN is ready, it is used within an iterative GA process to place a minimum number of decoupling capacitors for minimizing the differences between the input impedance at one or more location, and the required target impedance. The combined GA&ndash;ANN process is shown to effectively provide results consistent with those obtained by a longer optimization based on commercial simulators. With the new approach the accuracy of the results remains at the same level, but the computational time is reduced by at least 30 times. Two test cases have been considered for validating the proposed approach, with the second one also being compared by experimental measurements.
KW  - machine learning
KW  - artificial neural network
KW  - decoupling capacitors
KW  - power delivery network
KW  - genetic algorithm
KW  - twin removal
KW  - binary coding
KW  - power integrity
KW  - signal integrity
DO  - 10.3390/electronics9081243
TY  - EJOU
AU  - Etxepare, Lauren
AU  - Leon, Iñigo
AU  - Sagarna, Maialen
AU  - Lizundia, Iñigo
AU  - Uranga, Eneko J.
TI  - Advanced Intervention Protocol in the Energy Rehabilitation of Heritage Buildings: A Miñones Barracks Case Study
T2  - Sustainability

PY  - 2020
VL  - 12
IS  - 15
SN  - 2071-1050

AB  - Bearing in mind that dwellings generate a high environmental impact, the aim of this research is to improve their energy efficiency. The incorporation of an insulating layer in the extrados of the building envelope is the most effective way of reducing the transmittance of a facade, eliminating thermal bridges, and optimizing its energy consumption. There is no doubt about the effectiveness of this solution in terms of thermal protection. However, this process collides with the preservation of the original composition of buildings with ornate facades. This article presents a protocol for the rehabilitation of ornate facades of historic buildings through the application of an insulating layer on the outside of the walls. The protocol shows that advanced techniques applied with an integrated approach permit compatibility between energy rehabilitation and the preservation of the original value. In addition to applying strategies of a high technological level, the protocol proposes a reflection upon a balanced intervention on ornamental elements, as well as the relationship between the degree of energy improvement of an ornate facade, and the degree of preservation of the original composition. A methodology is established that combines different avant-guard techniques and systems. These include capturing reality in 3D, the Building Information Model (BIM), monitoring, advanced manufacturing, and active and passive solution simulations.
KW  - historic building
KW  - energy efficiency
KW  - insulation
KW  - thermography
KW  - monitoring
KW  - automated photogrammetry
KW  - laser scanning
KW  - BIM
KW  - advanced manufacturing
DO  - 10.3390/su12156270
TY  - EJOU
AU  - Kim, Dong-Hyun
AU  - Go, Yong-Guk
AU  - Choi, Soo-Mi
TI  - An Aerial Mixed-Reality Environment for First-Person-View Drone Flying
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 16
SN  - 2076-3417

AB  - A drone be able to fly without colliding to preserve the surroundings and its own safety. In addition, it must also incorporate numerous features of interest for drone users. In this paper, an aerial mixed-reality environment for first-person-view drone flying is proposed to provide an immersive experience and a safe environment for drone users by creating additional virtual obstacles when flying a drone in an open area. The proposed system is effective in perceiving the depth of obstacles, and enables bidirectional interaction between real and virtual worlds using a drone equipped with a stereo camera based on human binocular vision. In addition, it synchronizes the parameters of the real and virtual cameras to effectively and naturally create virtual objects in a real space. Based on user studies that included both general and expert users, we confirm that the proposed system successfully creates a mixed-reality environment using a flying drone by quickly recognizing real objects and stably combining them with virtual objects.
KW  - aerial mixed-reality
KW  - drones
KW  - stereo cameras
KW  - first-person-view
KW  - head-mounted display
DO  - 10.3390/app10165436
TY  - EJOU
AU  - Jamil, Faisal
AU  - Iqbal, Naeem
AU  - Ahmad, Shabir
AU  - Kim, Do-Hyeun
TI  - Toward Accurate Position Estimation Using Learning to Prediction Algorithm in Indoor Navigation
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 16
SN  - 1424-8220

AB  - Internet of Things is advancing, and the augmented role of smart navigation in automating processes is at its vanguard. Smart navigation and location tracking systems are finding increasing use in the area of the mission-critical indoor scenario, logistics, medicine, and security. A demanding emerging area is an Indoor Localization due to the increased fascination towards location-based services. Numerous inertial assessments unit-based indoor localization mechanisms have been suggested in this regard. However, these methods have many shortcomings pertaining to accuracy and consistency. In this study, we propose a novel position estimation system based on learning to the prediction model to address the above challenges. The designed system consists of two modules; learning to prediction module and position estimation using sensor fusion in an indoor environment. The prediction algorithm is attached to the learning module. Moreover, the learning module continuously controls, observes, and enhances the efficiency of the prediction algorithm by evaluating the output and taking into account the exogenous factors that may have an impact on its outcome. On top of that, we reckon a situation where the prediction algorithm can be applied to anticipate the accurate gyroscope and accelerometer reading from the noisy sensor readings. In the designed system, we consider a scenario where the learning module, based on Artificial Neural Network, and Kalman filter are used as a prediction algorithm to predict the actual accelerometer and gyroscope reading from the noisy sensor reading. Moreover, to acquire data, we use the next-generation inertial measurement unit, which contains a 3-axis accelerometer and gyroscope data. Finally, for the performance and accuracy of the proposed system, we carried out numbers of experiments, and we observed that the proposed Kalman filter with learning module performed better than the traditional Kalman filter algorithm in terms of root mean square error metric.
KW  - inertial navigation system
KW  - artificial neural network
KW  - motion tracking
KW  - sensor fusion
KW  - indoor navigation system
DO  - 10.3390/s20164410
TY  - EJOU
AU  - Treiblmaier, Horst
AU  - Rejeb, Abderahman
AU  - Strebinger, Andreas
TI  - Blockchain as a Driver for Smart City Development: Application Fields and a Comprehensive Research Agenda
T2  - Smart Cities

PY  - 2020
VL  - 3
IS  - 3
SN  - 2624-6511

AB  - The term &ldquo;Smart City&rdquo; denotes a comprehensive concept to alleviate pending problems of modern urban areas which have developed into an important work field for practitioners and scholars alike. However, the question remains as to how cities can become &ldquo;smart&rdquo;. The application of information technology is generally considered a key driver in the &ldquo;smartization&rdquo; of cities. Detailed frameworks and procedures are therefore needed to guide, operationalize, and measure the implementation process as well as the impact of the respective technologies. In this paper, we discuss blockchain technology, a novel driver of technological transformation that comprises a multitude of underlying technologies and protocols, and its potential impact on smart cities. We specifically address the question of how blockchain technology may benefit the development of urban areas. Based on a comprehensive literature review, we present a framework and research propositions. We identify nine application fields of blockchain technology in the smartization of cities: (1) healthcare, (2) logistics and supply chains, (3) mobility, (4) energy, (5) administration and services, (6) e-voting, (7) factory, (8) home and (9) education. We discuss current developments in these fields, illustrate how they are affected by blockchain technology and derive propositions to guide future research endeavors.
KW  - Smart Cities
KW  - blockchain
KW  - distributed ledger technology
KW  - literature review
KW  - research agenda
KW  - research propositions
KW  - technology driver
DO  - 10.3390/smartcities3030044
TY  - EJOU
AU  - Alebele, Yeshanbele
AU  - Zhang, Xue
AU  - Wang, Wenhui
AU  - Yang, Gaoxiang
AU  - Yao, Xia
AU  - Zheng, Hengbiao
AU  - Zhu, Yan
AU  - Cao, Weixing
AU  - Cheng, Tao
TI  - Estimation of Canopy Biomass Components in Paddy Rice from Combined Optical and SAR Data Using Multi-Target Gaussian Regressor Stacking
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 16
SN  - 2072-4292

AB  - Crop biomass is a critical variable to make sound decisions about field crop monitoring activities (fertilizers and irrigation) and crop productivity forecasts. More importantly, crop biomass estimations by components are essential for crop growth monitoring as the yield formation of crops results from the accumulation and transportation of substances between different organs. Retrieval of crop biomass from synthetic aperture radar SAR or optical imagery is of paramount importance for in-season monitoring of crop growth. A combination of optical and SAR imagery can compensate for their limitations and has exhibited comparative advantages in biomass estimation. Notably, the joint estimations of biophysical parameters might be more accurate than that of an individual parameter. Previous studies have attempted to use satellite imagery to estimate aboveground biomass, but the estimation of biomass for individual organs remains a challenge. Multi-target Gaussian process regressor stacking (MGPRS), as a new machine learning method, can be suitably utilized to estimate biomass components jointly from satellite imagery data, as the model does not require a large amount of data for training and can be adjusted to the required degrees of relationship exhibited by the given data. Thus, the aim of this study was to estimate the biomass of individual organs by using MGPRS in conjunction with optical (Sentinel-2A) and SAR (Sentinel-1A) imagery. Two hybrid indices, SAR and optical multiplication vegetation index (SOMVI) and SAR and optical difference vegetation index (SODVI), have been constructed to examine their estimation performance. The hybrid vegetation indices were used as input for the MGPRS and single-target Gaussian process regression (SGPR). The accuracy of the estimation methods was analyzed by in situ measurements of aboveground biomass (AGB) and organ biomass conducted in 2018 and 2019 over the paddy rice fields of Xinghua in Jiangsu Province, China. The results showed that the combined indices (SOMVI and SODVI) performed better than those derived from either the optical or SAR data only. The best predictive accuracy was achieved by the MGPRS using SODVI as input (r2 = 0.84, RMSE = 0.4 kg/m2 for stem biomass; r2 = 0.87, RMSE = 0.16 kg/m2 for AGB). This was higher than using SOMVI as input for the MGPRS (r2 = 0.71, RMSE = 1.12 kg/m2 for stem biomass; r2 = 0.71, RMSE = 0.56 kg/m2 for AGB) or SGPR (r2 = 0.63, RMSE = 1.08 kg/m2 for stem biomass; r2 = 0.67, RMSE = 1.08 kg/m2 for AGB). Relatively, higher accuracy for leaf biomass was achieved using SOMVI (r2 = 0.83) than using SODVI (r2 = 0.73) as input for MGPRS. Our results demonstrate that the combined indices are effective by integrating SAR and optical imagery and MGPRS outperformed SGPR with the same input variable for estimating rice crop biomass. The presented workflow will improve the estimation of crops biomass components from satellite data for effective crop growth monitoring.
KW  - synthetic aperture radar
KW  - Sentinel-1
KW  - Sentinel-2
KW  - hybrid indices
KW  - image fusion
KW  - Gaussian process
DO  - 10.3390/rs12162564
TY  - EJOU
AU  - Billet, Kévin
AU  - Malinowska, Magdalena A.
AU  - Munsch, Thibaut
AU  - Unlubayir, Marianne
AU  - Adler, Sophie
AU  - Delanoue, Guillaume
AU  - Lanoue, Arnaud
TI  - Semi-Targeted Metabolomics to Validate Biomarkers of Grape Downy Mildew Infection Under Field Conditions
T2  - Plants

PY  - 2020
VL  - 9
IS  - 8
SN  - 2223-7747

AB  - Grape downy mildew is a devastating disease worldwide and new molecular phenotyping tools are required to detect metabolic changes associated to plant disease symptoms. In this purpose, we used UPLC-DAD-MS-based semi-targeted metabolomics to screen downy mildew symptomatic leaves that expressed oil spots (6 dpi, days post-infection) and necrotic lesions (15 dpi) under natural infections in the field. Leaf extract analyses enabled the identification of 47 metabolites belonging to the primary metabolism including 6 amino acids and 1 organic acid, as well as an important diversity of specialized metabolites including 9 flavonols, 11 flavan-3-ols, 3 phenolic acids, and stilbenoids with various degree of polymerization (DP) including 4 stilbenoids DP1, 8 stilbenoids DP2, and 4 stilbenoids DP3. Principal component analysis (PCA) was applied as unsupervised multivariate statistical analysis method to reveal metabolic variables that were affected by the infection status. Univariate and multivariate statistics revealed 33 and 27 metabolites as relevant infection biomarkers at 6 and 15 dpi, respectively. Correlation-based networks highlighted a general decrease of flavonoid-related metabolites, whereas stilbenoid DP1 and DP2 concentrations increased upon downy mildew infection. Stilbenoids DP3 were identified only in necrotic lesions representing late biomarkers of downy mildew infection.
KW  - grape
KW  - downy mildew
KW  - semi-targeted metabolomics
KW  - infection biomarkers
KW  - polyphenols
KW  - stilbenoids
KW  - correlation network
DO  - 10.3390/plants9081008
TY  - EJOU
AU  - Mayor, Vicente
AU  - Estepa, Rafael
AU  - Estepa, Antonio
AU  - Madinabeitia, Germán
TI  - Energy-Efficient UAVs Deployment for QoS-Guaranteed VoWiFi Service
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 16
SN  - 1424-8220

AB  - This paper formulates a new problem for the optimal placement of Unmanned Aerial Vehicles (UAVs) geared towards wireless coverage provision for Voice over WiFi (VoWiFi) service to a set of ground users confined in an open area. Our objective function is constrained by coverage and by VoIP speech quality and minimizes the ratio between the number of UAVs deployed and energy efficiency in UAVs, hence providing the layout that requires fewer UAVs per hour of service. Solutions provide the number and position of UAVs to be deployed, and are found using well-known heuristic search methods such as genetic algorithms (used for the initial deployment of UAVs), or particle swarm optimization (used for the periodical update of the positions). We examine two communication services: (a) one bidirectional VoWiFi channel per user; (b) single broadcast VoWiFi channel for announcements. For these services, we study the results obtained for an increasing number of users confined in a small area of 100 m2 as well as in a large area of 10,000 m2. Results show that the drone turnover rate is related to both users&rsquo; sparsity and the number of users served by each UAV. For the unicast service, the ratio of UAVs per hour of service tends to increase with user sparsity and the power of radio communication represents 14&ndash;16% of the total UAV energy consumption depending on ground user density. In large areas, solutions tend to locate UAVs at higher altitudes seeking increased coverage, which increases energy consumption due to hovering. However, in the VoWiFi broadcast communication service, the traffic is scarce, and solutions are mostly constrained only by coverage. This results in fewer UAVs deployed, less total power consumption (between 20% and 75%), and less sensitivity to the number of served users.
KW  - UAV
KW  - voice over IP
KW  - wireless LAN
KW  - IEEE 802.11
KW  - voice over IP over WiFi
KW  - VoWiFi
KW  - quality of service
KW  - energy
DO  - 10.3390/s20164455
TY  - EJOU
AU  - de Bem, Pablo P.
AU  - de Carvalho Júnior, Osmar A.
AU  - de Carvalho, Osmar L.
AU  - Gomes, Roberto A.
AU  - Fontes Guimarães, Renato
TI  - Performance Analysis of Deep Convolutional Autoencoders with Different Patch Sizes for Change Detection from Burnt Areas
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 16
SN  - 2072-4292

AB  - Fire is one of the primary sources of damages to natural environments globally. Estimates show that approximately 4 million km2 of land burns yearly. Studies have shown that such estimates often underestimate the real extent of burnt land, which highlights the need to find better, state-of-the-art methods to detect and classify these areas. This study aimed to analyze the use of deep convolutional Autoencoders in the classification of burnt areas, considering different sample patch sizes. A simple Autoencoder and the U-Net and ResUnet architectures were evaluated. We collected Landsat 8 OLI+ data from three scenes in four consecutive dates to detect the changes specifically in the form of burnt land. The data were sampled according to four different sampling strategies to evaluate possible performance changes related to sampling window sizes. The training stage used two scenes, while the validation stage used the remaining scene. The ground truth change mask was created using the Normalized Burn Ratio (NBR) spectral index through a thresholding approach. The classifications were evaluated according to the F1 index, Kappa index, and mean Intersection over Union (mIoU) value. Results have shown that the U-Net and ResUnet architectures offered the best classifications with average F1, Kappa, and mIoU values of approximately 0.96, representing excellent classification results. We have also verified that a sampling window size of 256 by 256 pixels offered the best results.
KW  - deep learning
KW  - CNN
KW  - classification
KW  - fire
KW  - multitemporal image
DO  - 10.3390/rs12162576
TY  - EJOU
AU  - Wei, Marcelo C.
AU  - Molin, José P.
TI  - Soybean Yield Estimation and Its Components: A Linear Regression Approach
T2  - Agriculture

PY  - 2020
VL  - 10
IS  - 8
SN  - 2077-0472

AB  - Soybean yield estimation is either based on yield monitors or agro-meteorological and satellite imagery data, but they present several limiting factors regarding on-farm decision level. Aware that machine learning approaches have been largely applied to estimate soybean yield and the availability of data regarding soybean yield and its components (number of grains (NG) and thousand grains weight (TGW)), there is an opportunity to study their relationships. The objective was to explore the relationships between soybean yield and its components, generate equations to estimate yield and evaluate its prediction accuracy. The training dataset was composed of soybean yield and its components&rsquo; data from 2010 to 2019. Linear regression models based on NG, TGW and yield were fitted on the training dataset and applied to a validation dataset composed of 58 on-field collected samples. It was found that globally TGW and NG presented weak (r = 0.50) and strong (r = 0.92) linear relationships with yield, respectively. In addition to that, applying the fitted models to the validation dataset, model based on NG presented the highest accuracy, coefficient of determination (R2) of 0.70, mean absolute error (MAE) of 639.99 kg ha&minus;1 and root mean squared error (RMSE) of 726.67 kg ha&minus;1.
KW  - hundred grains weight
KW  - machine learning
KW  - number of grains
KW  - precision agriculture
KW  - thousand grains weight
DO  - 10.3390/agriculture10080348

TY  - EJOU
AU  - Topal, Sebahattin
AU  - Erkmen, İsmet
AU  - Erkmen, Aydan M.
TI  - Towards the Robotic “Avatar”: An Extensive Survey of the Cooperation between and within Networked Mobile Sensors
T2  - Future Internet

PY  - 2010
VL  - 2
IS  - 3
SN  - 1999-5903

AB  - Cooperation between networked mobile sensors, wearable and sycophant sensor networks with parasitically sticking agents, and also having human beings involved in the loop is the “Avatarization” within the robotic research community, where all networks are connected and where you can connect/disconnect at any time to acquire data from a vast unstructured world. This paper extensively surveys the networked robotic foundations of this robotic biological “Avatar” that awaits us in the future. Cooperation between networked mobile sensors as well as cooperation of nodes within a network are becoming more robust, fault tolerant and enable adaptation of the networks to changing environment conditions. In this paper, we survey and comparatively discuss the current state of networked robotics via their critical application areas and their design characteristics. We conclude by discussing future challenges.
KW  - networked mobile robot systems
KW  - hybrid sensor networks
KW  - survey
DO  - 10.3390/fi2030363
ER  -
TY  - EJOU
AU  - Chiang, Kai-Wei
AU  - Chang, Hsiu-Wen
TI  - Intelligent Sensor Positioning and Orientation Through Constructive Neural Network-Embedded INS/GPS Integration Algorithms
T2  - Sensors

PY  - 2010
VL  - 10
IS  - 10
SN  - 1424-8220

AB  - Mobile mapping systems have been widely applied for acquiring spatial information in applications such as spatial information systems and 3D city models. Nowadays the most common technologies used for positioning and orientation of a mobile mapping system include a Global Positioning System (GPS) as the major positioning sensor and an Inertial Navigation System (INS) as the major orientation sensor. In the classical approach, the limitations of the Kalman Filter (KF) method and the overall price of multi-sensor systems have limited the popularization of most land-based mobile mapping applications. Although intelligent sensor positioning and orientation schemes consisting of Multi-layer Feed-forward Neural Networks (MFNNs), one of the most famous Artificial Neural Networks (ANNs), and KF/smoothers, have been proposed in order to enhance the performance of low cost Micro Electro Mechanical System (MEMS) INS/GPS integrated systems, the automation of the MFNN applied has not proven as easy as initially expected. Therefore, this study not only addresses the problems of insufficient automation in the conventional methodology that has been applied in MFNN-KF/smoother algorithms for INS/GPS integrated systems proposed in previous studies, but also exploits and analyzes the idea of developing alternative intelligent sensor positioning and orientation schemes that integrate various sensors in more automatic ways. The proposed schemes are implemented using one of the most famous constructive neural networks––the Cascade Correlation Neural Network (CCNNs)––to overcome the limitations of conventional techniques based on KF/smoother algorithms as well as previously developed MFNN-smoother schemes. The CCNNs applied also have the advantage of a more flexible topology compared to MFNNs. Based on the experimental data utilized the preliminary results presented in this article illustrate the effectiveness of the proposed schemes compared to smoother algorithms as well as the MFNN-smoother schemes.
KW  - GPS/INS
KW  - sensor integration
KW  - mobile mapping systems
KW  - constructive neural networks
DO  - 10.3390/s101009252
ER  -
TY  - EJOU
AU  - Liu, Zhigao
AU  - Li, Chunwen
AU  - Wu, Danchen
AU  - Dai, Wenhan
AU  - Geng, Shaobo
AU  - Ding, Qingqing
TI  - A Wireless Sensor Network Based Personnel Positioning Scheme in Coal Mines with Blind Areas
T2  - Sensors

PY  - 2010
VL  - 10
IS  - 11
SN  - 1424-8220

AB  - This paper proposes a novel personnel positioning scheme for a tunnel network with blind areas, which compared with most existing schemes offers both low-cost and high-precision. Based on the data models of tunnel networks, measurement networks and mobile miners, the global positioning method is divided into four steps: (1) calculate the real time personnel location in local areas using a location engine, and send it to the upper computer through the gateway; (2) correct any localization errors resulting from the underground tunnel environmental interference; (3) determine the global three-dimensional position by coordinate transformation; (4) estimate the personnel locations in the blind areas. A prototype system constructed to verify the positioning performance shows that the proposed positioning system has good reliability, scalability, and positioning performance. In particular, the static localization error of the positioning system is less than 2.4 m in the underground tunnel environment and the moving estimation error is below 4.5 m in the corridor environment. The system was operated continuously over three months without any failures. 
KW  - personnel global positioning
KW  - wireless sensor networks
KW  - tunnel network model
KW  - global positioning method
DO  - 10.3390/s101109891
ER  -
TY  - EJOU
AU  - Wallace, Luke
AU  - Lucieer, Arko
AU  - Watson, Christopher
AU  - Turner, Darren
TI  - Development of a UAV-LiDAR System with Application to Forest Inventory
T2  - Remote Sensing

PY  - 2012
VL  - 4
IS  - 6
SN  - 2072-4292

AB  - We present the development of a low-cost Unmanned Aerial Vehicle-Light Detecting and Ranging (UAV-LiDAR) system and an accompanying workflow to produce 3D point clouds. UAV systems provide an unrivalled combination of high temporal and spatial resolution datasets. The TerraLuma UAV-LiDAR system has been developed to take advantage of these properties and in doing so overcome some of the current limitations of the use of this technology within the forestry industry. A modified processing workflow including a novel trajectory determination algorithm fusing observations from a GPS receiver, an Inertial Measurement Unit (IMU) and a High Definition (HD) video camera is presented. The advantages of this workflow are demonstrated using a rigorous assessment of the spatial accuracy of the final point clouds. It is shown that due to the inclusion of video the horizontal accuracy of the final point cloud improves from 0.61 m to 0.34 m (RMS error assessed against ground control). The effect of the very high density point clouds (up to 62 points per m2) produced by the UAV-LiDAR system on the measurement of tree location, height and crown width are also assessed by performing repeat surveys over individual isolated trees. The standard deviation of tree height is shown to reduce from 0.26 m, when using data with a density of 8 points perm2, to 0.15mwhen the higher density data was used. Improvements in the uncertainty of the measurement of tree location, 0.80 m to 0.53 m, and crown width, 0.69 m to 0.61 m are also shown.
KW  - Unmanned Aerial Vehicles
KW  - LiDAR
KW  - MEMS IMU
KW  - Kalman Filter
KW  - sensor integration
KW  - forestry
DO  - 10.3390/rs4061519
ER  -
TY  - EJOU
AU  - Chiang, Kai-Wei
AU  - Tsai, Meng-Lun
AU  - Chu, Chien-Hsun
TI  - The Development of an UAV Borne Direct Georeferenced Photogrammetric Platform for Ground Control Point Free Applications
T2  - Sensors

PY  - 2012
VL  - 12
IS  - 7
SN  - 1424-8220

AB  - To facilitate applications such as environment detection or disaster monitoring, the development of rapid low cost systems for collecting near real time spatial information is very critical. Rapid spatial information collection has become an emerging trend for remote sensing and mapping applications. In this study, a fixed-wing Unmanned Aerial Vehicle (UAV)-based spatial information acquisition platform that can operate in Ground Control Point (GCP) free environments is developed and evaluated. The proposed UAV based photogrammetric platform has a Direct Georeferencing (DG) module that includes a low cost Micro Electro Mechanical Systems (MEMS) Inertial Navigation System (INS)/ Global Positioning System (GPS) integrated system. The DG module is able to provide GPS single frequency carrier phase measurements for differential processing to obtain sufficient positioning accuracy. All necessary calibration procedures are implemented. Ultimately, a flight test is performed to verify the positioning accuracy in DG mode without using GCPs. The preliminary results of positioning accuracy in DG mode illustrate that horizontal positioning accuracies in the x and y axes are around 5 m at 300 m flight height above the ground. The positioning accuracy of the z axis is below 10 m. Therefore, the proposed platform is relatively safe and inexpensive for collecting critical spatial information for urgent response such as disaster relief and assessment applications where GCPs are not available.
KW  - direct georeferencing
KW  - INS
KW  - GPS
KW  - UAV
DO  - 10.3390/s120709161
ER  -
TY  - EJOU
AU  - De Marina, Héctor García
AU  - Espinosa, Felipe
AU  - Santos, Carlos
TI  - Adaptive UAV Attitude Estimation Employing Unscented Kalman Filter, FOAM and Low-Cost MEMS Sensors
T2  - Sensors

PY  - 2012
VL  - 12
IS  - 7
SN  - 1424-8220

AB  - Navigation employing low cost MicroElectroMechanical Systems (MEMS) sensors in Unmanned Aerial Vehicles (UAVs) is an uprising challenge. One important part of this navigation is the right estimation of the attitude angles. Most of the existent algorithms handle the sensor readings in a fixed way, leading to large errors in different mission stages like take-off aerobatic maneuvers. This paper presents an adaptive method to estimate these angles using off-the-shelf components. This paper introduces an Attitude Heading Reference System (AHRS) based on the Unscented Kalman Filter (UKF) using the Fast Optimal Attitude Matrix (FOAM) algorithm as the observation model. The performance of the method is assessed through simulations. Moreover, field experiments are presented using a real fixed-wing UAV. The proposed low cost solution, implemented in a microcontroller, shows a satisfactory real time performance.
KW  - UAV navigation
KW  - attitude estimation
KW  - unscented Kalman filter
KW  - attitude heading reference system
KW  - fast optimal attitude matrix
DO  - 10.3390/s120709566
ER  -
TY  - EJOU
AU  - Martí, Enrique D.
AU  - Martín, David
AU  - García, Jesús
AU  - De la Escalera, Arturo
AU  - Molina, José M.
AU  - Armingol, José M.
TI  - Context-Aided Sensor Fusion for Enhanced Urban Navigation
T2  - Sensors

PY  - 2012
VL  - 12
IS  - 12
SN  - 1424-8220

AB  - The deployment of Intelligent Vehicles in urban environments requires reliable estimation of positioning for urban navigation. The inherent complexity of this kind of environments fosters the development of novel systems which should provide reliable and precise solutions to the vehicle. This article details an advanced GNSS/IMU fusion system based on a context-aided Unscented Kalman filter for navigation in urban conditions. The constrained non-linear filter is here conditioned by a contextual knowledge module which reasons about sensor quality and driving context in order to adapt it to the situation, while at the same time it carries out a continuous estimation and correction of INS drift errors. An exhaustive analysis has been carried out with available data in order to characterize the behavior of available sensors and take it into account in the developed solution. The performance is then analyzed with an extensive dataset containing representative situations. The proposed solution suits the use of fusion algorithms for deploying Intelligent Transport Systems in urban environments.
KW  - autonomous navigation
KW  - multi-sensor fusion
KW  - intelligent systems
KW  - context exploitation
KW  - urban navigation
DO  - 10.3390/s121216802
ER  -
TY  - EJOU
AU  - Lu, Feng
AU  - Huang, Jinquan
AU  - Lv, Yiqiu
TI  - Gas Path Health Monitoring for a Turbofan Engine Based on a Nonlinear Filtering Approach
T2  - Energies

PY  - 2013
VL  - 6
IS  - 1
SN  - 1996-1073

AB  - Different approaches for gas path performance estimation of dynamic systems are commonly used, the most common being the variants of the Kalman filter. The extended Kalman filter (EKF) method is a popular approach for nonlinear systems which combines the traditional Kalman filtering and linearization techniques to effectively deal with weakly nonlinear and non-Gaussian problems. Its mathematical formulation is based on the assumption that the probability density function (PDF) of the state vector can be approximated to be Gaussian. Recent investigations have focused on the particle  filter (PF) based on Monte Carlo sampling algorithms for tackling strong nonlinear and  non-Gaussian models. Considering the aircraft engine is a complicated machine, operating under a harsh environment, and polluted by complex noises, the PF might be an available way to monitor gas path health for aircraft engines. Up to this point in time a number of Kalman filtering approaches have been used for aircraft turbofan engine gas path health estimation, but the particle filters have not been used for this purpose and a systematic comparison has not been published. This paper presents gas path health monitoring based on the PF and the constrained extend Kalman particle filter (cEKPF), and then compares the estimation accuracy and computational effort of these filters to the EKF for aircraft engine performance estimation under rapid faults and general deterioration. Finally, the effects of the constraint mechanism and particle number on the cEKPF are discussed. We show in this paper that the cEKPF outperforms the EKF, PF and EKPF, and conclude that the cEKPF is the best choice for turbofan engine health monitoring.
KW  - turbofan engine
KW  - performance estimation
KW  - nonlinear filter
KW  - extended Kalman filter
KW  - particle filter
DO  - 10.3390/en6010492
ER  -
TY  - EJOU
AU  - Ouchi, Kazuo
TI  - Recent Trend and Advance of Synthetic Aperture Radar with Selected Topics
T2  - Remote Sensing

PY  - 2013
VL  - 5
IS  - 2
SN  - 2072-4292

AB  - The present article is an introductory paper in this special issue on synthetic aperture radar (SAR). A short review is presented on the recent trend and development of SAR and related techniques with selected topics, including the fields of applications, specifications of airborne and spaceborne SARs, and information contents in and interpretations of amplitude data, interferometric SAR (InSAR) data, and polarimetric SAR (PolSAR) data. The review is by no means extensive, and as such only brief summaries of of each selected topics and key references are provided. For further details, the readers are recommended to read the literature given in the references theirin.
KW  - synthetic aperture radar (SAR)
KW  - recent development
KW  - amplitude information
KW  - interferometric SAR (InSAR)
KW  - polarimetric SAR (PolSAR)
DO  - 10.3390/rs5020716
ER  -
TY  - EJOU
AU  - Qiao, Gang
AU  - Lu, Ping
AU  - Scaioni, Marco
AU  - Xu, Shuying
AU  - Tong, Xiaohua
AU  - Feng, Tiantian
AU  - Wu, Hangbin
AU  - Chen, Wen
AU  - Tian, Yixiang
AU  - Wang, Weian
AU  - Li, Rongxing
TI  - Landslide Investigation with Remote Sensing and Sensor Network: From Susceptibility Mapping and Scaled-down Simulation towards in situ Sensor Network Design
T2  - Remote Sensing

PY  - 2013
VL  - 5
IS  - 9
SN  - 2072-4292

AB  - This paper presents an integrated approach to landslide research based on  remote sensing and sensor networks. This approach is composed of three important parts:  (i) landslide susceptibility mapping using remote-sensing techniques for susceptible determination of landslide spots; (ii) scaled-down landslide simulation experiments for validation of sensor network for landslide monitoring, and (iii) in situ sensor network deployment for intensified landslide monitoring. The study site is the Taziping landslide located in Hongkou Town (Sichuan, China). The landslide features generated by landslides triggered by the 2008 Wenchuan Earthquake were first extracted by means of object-oriented methods from the remote-sensing images before and after the landslides events. On the basis of correlations derived between spatial distribution of landslides and control factors, the landslide susceptibility mapping was carried out using the Artificial Neural Network (ANN) technique. Then the Taziping landslide, located in the above mentioned study area, was taken as an example to design and implement a scaled-down landslide simulation platform in Tongji University (Shanghai, China). The landslide monitoring sensors were carefully investigated and deployed for rainfall induced landslide simulation experiments. Finally, outcomes from the simulation experiments were adopted and employed to design the future in situ sensor network in Taziping landslide site where the sensor deployment is being implemented.
KW  - landslide
KW  - sensor network
KW  - susceptibility mapping
KW  - remote sensing
DO  - 10.3390/rs5094319
ER  -
TY  - EJOU
AU  - Rodríguez-Canosa, Gonzalo
AU  - Del Cerro Giner, Jaime
AU  - Barrientos, Antonio
TI  - Detection and Tracking of Dynamic Objects by Using a Multirobot System: Application to Critical Infrastructures Surveillance
T2  - Sensors

PY  - 2014
VL  - 14
IS  - 2
SN  - 1424-8220

AB  - The detection and tracking of mobile objects (DATMO) is progressively gaining importance for security and surveillance applications. This article proposes a set of new algorithms and procedures for detecting and tracking mobile objects by robots that work collaboratively as part of a multirobot system. These surveillance algorithms are conceived of to work with data provided by long distance range sensors and are intended for highly reliable object detection in wide outdoor environments. Contrary to most common approaches, in which detection and tracking are done by an integrated procedure, the approach proposed here relies on a modular structure, in which detection and tracking are carried out independently, and the latter might accept input data from different detection algorithms. Two movement detection algorithms have been developed for the detection of dynamic objects by using both static and/or mobile robots. The solution to the overall problem is based on the use of a Kalman filter to predict the next state of each tracked object. Additionally, new tracking algorithms capable of combining dynamic objects lists coming from either one or various sources complete the solution. The complementary performance of the separated modular structure for detection and identification is evaluated and, finally, a selection of test examples discussed.
KW  - DATMO
KW  - multirobot
KW  - critical infrastructure surveillance
DO  - 10.3390/s140202911
ER  -
TY  - EJOU
AU  - Li, Xiang
AU  - Yang, Zhibo
AU  - Chen, Xuefeng
TI  - Quantitative Damage Detection and Sparse Sensor  Array Optimization of Carbon Fiber Reinforced Resin Composite Laminates for Wind Turbine Blade  Structural Health Monitoring
T2  - Sensors

PY  - 2014
VL  - 14
IS  - 4
SN  - 1424-8220

AB  - The active structural health monitoring (SHM) approach for the complex composite laminate structures of wind turbine blades (WTBs), addresses the important and complicated problem of signal noise. After illustrating the wind energy industry’s development perspectives and its crucial requirement for SHM, an improved redundant second generation wavelet transform (IRSGWT) pre-processing algorithm based on neighboring coefficients is introduced for feeble signal denoising. The method can avoid the drawbacks of conventional wavelet methods that lose information in transforms and the shortcomings of redundant second generation wavelet (RSGWT) denoising that can lead to error propagation. For large scale WTB composites, how to minimize the number of sensors while ensuring accuracy is also a key issue. A sparse sensor array optimization of composites for WTB applications is proposed that can reduce the number of transducers that must be used. Compared to a full sixteen transducer array, the optimized eight transducer configuration displays better accuracy in identifying the correct position of simulated damage (mass of load) on composite laminates with anisotropic characteristics than a non-optimized array. It can help to guarantee more flexible and qualified monitoring of the areas that more frequently suffer damage. The proposed methods are verified experimentally on specimens of carbon fiber reinforced resin composite laminates.
KW  - structural health monitoring
KW  - sensor array optimization
KW  - composite laminates
KW  - second generation wavelet
KW  - Lamb wave
KW  - wind turbine blade
DO  - 10.3390/s140407312
ER  -
TY  - EJOU
AU  - Deery, David
AU  - Jimenez-Berni, Jose
AU  - Jones, Hamlyn
AU  - Sirault, Xavier
AU  - Furbank, Robert
TI  - Proximal Remote Sensing Buggies and Potential Applications for Field-Based Phenotyping
T2  - Agronomy

PY  - 2014
VL  - 4
IS  - 3
SN  - 2073-4395

AB  - The achievements made in genomic technology in recent decades are yet to be matched by fast and accurate crop phenotyping methods. Such crop phenotyping methods are required for crop improvement efforts to meet expected demand for food and fibre in the future. This review evaluates the role of proximal remote sensing buggies for field-based phenotyping with a particular focus on the application of currently available sensor technology for large-scale field phenotyping. To illustrate the potential for the development of high throughput phenotyping techniques, a case study is presented with sample data sets obtained from a ground-based proximal remote sensing buggy mounted with the following sensors: LiDAR, RGB camera, thermal infra-red camera and imaging spectroradiometer. The development of such techniques for routine deployment in commercial-scale breeding and pre-breeding operations will require a multidisciplinary approach to leverage the recent technological advances realised in computer science, image analysis, proximal remote sensing and robotics.
KW  - LiDAR
KW  - time of flight
KW  - hyperspectral
KW  - RGB camera
KW  - thermal imaging
KW  - chlorophyll fluorescence
KW  - image analysis
KW  - data processing
KW  - field experiments
KW  - wheat
DO  - 10.3390/agronomy4030349
ER  -
TY  - EJOU
AU  - Mizuochi, Hiroki
AU  - Hiyama, Tetsuya
AU  - Ohta, Takeshi
AU  - Nasahara, Kenlo N.
TI  - Evaluation of the Surface Water Distribution in North-Central Namibia Based on MODIS and AMSR Series
T2  - Remote Sensing

PY  - 2014
VL  - 6
IS  - 8
SN  - 2072-4292

AB  - Semi-arid North-central Namibia has high potential for rice cultivation because large seasonal wetlands (oshana) form during the rainy season. Evaluating the distribution of surface water would reveal the area potentially suitable for rice cultivation. In this study, we detected the distribution of surface water with high spatial and temporal resolution by using two types of complementary satellite data: MODIS (MODerate-resolution Imaging Spectroradiometer) and AMSR-E (Advanced Microwave Scanning Radiometer–Earth Observing System), using AMSR2 after AMSR-E became unavailable. We combined the modified normalized-difference water index (MNDWI) from the MODIS data with the normalized-difference polarization index (NDPI) from the AMSR-E and AMSR2 data to determine the area of surface water. We developed a simple gap-filling method (“database unmixing”) with the two indices, thereby providing daily 500-m-resolution MNDWI maps of north-central Namibia regardless of whether the sky was clear. Moreover, through receiver-operator characteristics (ROC) analysis, we determined the threshold MNDWI  (−0.316) for wetlands. Using ROC analysis, MNDWI had moderate performance (the area under the ROC curve was 0.747), and the recognition error for seasonal wetlands and dry land was 21.2%. The threshold MNDWI let us calculate probability of water presence (PWP) maps for the rainy season and the whole year. The PWP maps revealed the total area potentially suitable for rice cultivation: 1255 km2 (1.6% of the study area).
KW  - surface water distribution
KW  - MODIS
KW  - AMSR-E
KW  - AMSR2
KW  - database unmixing
KW  - ROC analysis
DO  - 10.3390/rs6087660
ER  -
TY  - EJOU
AU  - Cao, Chuqing
AU  - Sun, Ying
TI  - Automatic Road Centerline Extraction from Imagery Using Road GPS Data
T2  - Remote Sensing

PY  - 2014
VL  - 6
IS  - 9
SN  - 2072-4292

AB  - Road centerline extraction from imagery constitutes a key element in numerous geospatial applications, which has been addressed through a variety of approaches. However, most of the existing methods are not capable of dealing with challenges such as different road shapes, complex scenes, and variable resolutions. This paper presents a novel method for road centerline extraction from imagery in a fully automatic approach that addresses the aforementioned challenges by exploiting road GPS data. The proposed method combines road color feature with road GPS data to detect road centerline seed points. After global alignment of road GPS data, a novel road centerline extraction algorithm is developed to extract each individual road centerline in local regions. Through road connection, road centerline network is generated as the final output. Extensive experiments demonstrate that our proposed method can rapidly and accurately extract road centerline from remotely sensed imagery.
KW  - road centerline extraction
KW  - road GPS data
KW  - road connection
KW  - satellite image
KW  - remote sensing
DO  - 10.3390/rs6099014
ER  -
TY  - EJOU
AU  - Pedroza, Natalie R.
AU  - MacKunis, William
AU  - Golubev, Vladimir V.
TI  - Robust Nonlinear Regulation of Limit Cycle Oscillations in UAVs Using Synthetic Jet Actuators
T2  - Robotics

PY  - 2014
VL  - 3
IS  - 4
SN  - 2218-6581

AB  - In this paper, a synthetic jet actuators (SJA)-based nonlinear robust controller is developed, which is capable of completely suppressing limit cycle oscillations (LCO) in UAV systems with parametric uncertainty in the SJA dynamics and unmodeled external disturbances. Specifically, the control law compensates for uncertainty in an input gain matrix, which results from the unknown airflow dynamics generated by the SJA. Challenges in the control design include compensation for input-multiplicative parametric uncertainty in the actuator dynamic model. The result was achieved via innovative algebraic manipulation in the error system development, along with a Lyapunov-based robust control law. A rigorous Lyapunov-based stability analysis is utilized to prove asymptotic LCO suppression, considering a detailed dynamic model of the pitching and plunging dynamics. Numerical simulation results are provided to demonstrate the robustness and practical performance of the proposed control law.
KW  - nonlinear
KW  - robust
KW  - LCO
KW  - synthetic jet actuator
DO  - 10.3390/robotics3040330
ER  -
TY  - EJOU
AU  - Salamí, Esther
AU  - Barrado, Cristina
AU  - Pastor, Enric
TI  - UAV Flight Experiments Applied to the Remote Sensing of Vegetated Areas
T2  - Remote Sensing

PY  - 2014
VL  - 6
IS  - 11
SN  - 2072-4292

AB  - The miniaturization of electronics, computers and sensors has created new opportunities for remote sensing applications. Despite the current restrictions on regulation, the use of unmanned aerial vehicles equipped with small thermal, laser or spectral sensors has emerged as a promising alternative for assisting modeling, mapping and monitoring applications in rangelands, forests and agricultural environments. This review provides an overview of recent research that has reported UAV flight experiments on the remote sensing of vegetated areas. To provide a differential trend to other reviews, this paper is not limited to crops and precision agriculture applications, but also includes forest and rangeland applications. This work follows a top-down categorization strategy and attempts to fill the gap between application requirements and the characteristics of selected tools, payloads and platforms. Furthermore, correlations between common requirements and the most frequently used solutions are highlighted.
KW  - UAV
KW  - RPAS
KW  - vegetation indices
KW  - precision agriculture
KW  - payload
DO  - 10.3390/rs61111051
ER  -
TY  - EJOU
AU  - Hung, Calvin
AU  - Xu, Zhe
AU  - Sukkarieh, Salah
TI  - Feature Learning Based Approach for Weed Classification Using High Resolution Aerial Images from a Digital Camera Mounted on a UAV
T2  - Remote Sensing

PY  - 2014
VL  - 6
IS  - 12
SN  - 2072-4292

AB  - The development of low-cost unmanned aerial vehicles (UAVs) and light weight imaging sensors has resulted in significant interest in their use for remote sensing applications. While significant attention has been paid to the collection, calibration, registration and mosaicking of data collected from small UAVs, the interpretation of these data into semantically meaningful information can still be a laborious task. A standard data collection and classification work-flow requires significant manual effort for segment size tuning, feature selection and rule-based classifier design. In this paper, we propose an alternative learning-based approach using feature learning to minimise the manual effort required. We apply this system to the classification of invasive weed species. Small UAVs are suited to this application, as they can collect data at high spatial resolutions, which is essential for the classification of small or localised weed outbreaks. In this paper, we apply feature learning to generate a bank of image filters that allows for the extraction of features that discriminate between the weeds of interest and background objects. These features are pooled to summarise the image statistics and form the input to a texton-based linear classifier that classifies an image patch as weed or background. We evaluated our approach to weed classification on three weeds of significance in Australia: water hyacinth, tropical soda apple and serrated tussock. Our results showed that collecting images at 5–10 m resulted in the highest classifier accuracy, indicated by F1 scores of up to 94%.
KW  - weed classification
KW  - UAV remote sensing
KW  - serrated tussock
KW  - tropical soda apple
KW  - water hyacinth
DO  - 10.3390/rs61212037
ER  -
TY  - EJOU
AU  - Li, Li
AU  - Dong, Jinwei
AU  - Njeudeng Tenku, Simon
AU  - Xiao, Xiangming
TI  - Mapping Oil Palm Plantations in Cameroon Using PALSAR  50-m Orthorectified Mosaic Images
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 2
SN  - 2072-4292

AB  - Oil palm plantations have expanded rapidly. Estimating either positive effects on the economy, or negative effects on the environment, requires accurate maps. In this paper, three classification algorithms (Support Vector Machine (SVM), Decision Tree and  K-Means) were explored to map oil palm plantations in Cameroon, using PALSAR 50 m Orthorectified Mosaic images and differently sized training samples. SVM had the ideal performance with overall accuracy ranging from 86% to 92% and a Kappa coefficient from 0.76 to 0.85, depending upon the training sample size (ranging from 20 to 500 pixels per class). The advantage of SVM was more obvious when the training sample size was smaller. K-Means required the user’s intervention, and thus, the accuracy depended on the level of his/her expertise and experience. For large-scale mapping of oil palm plantations, the Decision Tree algorithm outperformed both SVM and K-Means in terms of speed and performance. In addition, the decision threshold values of Decision Tree for a large training sample size agrees with the results from previous studies, which implies the possible universality of the decision threshold. If it can be verified, the Decision Tree algorithm will be an easy and robust methodology for mapping oil palm plantations.
KW  - unsupervised classification
KW  - K-Means
KW  - support vector machine
KW  - decision tree
KW  - PALSAR
KW  - oil palm
DO  - 10.3390/rs70201206
ER  -
TY  - EJOU
AU  - Roldán, Juan J.
AU  - Joossen, Guillaume
AU  - Sanz, David
AU  - Del Cerro, Jaime
AU  - Barrientos, Antonio
TI  - Mini-UAV Based Sensory System for Measuring Environmental Variables in Greenhouses
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 2
SN  - 1424-8220

AB  - This paper describes the design, construction and validation of a mobile sensory platform for greenhouse monitoring. The complete system consists of a sensory system on board a small quadrotor (i.e., a four rotor mini-UAV). The goals of this system include  taking measures of temperature, humidity, luminosity and CO2 concentration and plotting maps of these variables. These features could potentially allow for climate control, crop monitoring or failure detection (e.g., a break in a plastic cover). The sensors have been selected by considering the climate and plant growth models and the requirements for their integration onboard the quadrotor. The sensors layout and placement have been determined through a study of quadrotor aerodynamics and the influence of the airflows from its rotors. All components of the system have been developed, integrated and tested through a set of field experiments in a real greenhouse. The primary contributions of this paper are the validation of the quadrotor as a platform for measuring environmental variables and the determination of the optimal location of sensors on a quadrotor.
KW  - greenhouse
KW  - UAVs
KW  - sensory system
KW  - environmental monitoring
KW  - agriculture
KW  - robotics
DO  - 10.3390/s150203334
ER  -
TY  - EJOU
AU  - Hassan-Esfahani, Leila
AU  - Torres-Rua, Alfonso
AU  - Jensen, Austin
AU  - McKee, Mac
TI  - Assessment of Surface Soil Moisture Using High-Resolution Multi-Spectral Imagery and Artificial Neural Networks
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 3
SN  - 2072-4292

AB  - Many crop production management decisions can be informed using data from high-resolution aerial images that provide information about crop health as influenced by soil fertility and moisture. Surface soil moisture is a key component of soil water balance, which addresses water and energy exchanges at the surface/atmosphere interface; however, high-resolution remotely sensed data is rarely used to acquire soil moisture values. In this study, an artificial neural network (ANN) model was developed to quantify the effectiveness of using spectral images to estimate surface soil moisture. The model produces acceptable estimations of surface soil moisture (root mean square error (RMSE) = 2.0, mean absolute error (MAE) = 1.8, coefficient of correlation (r) = 0.88, coefficient of performance (e) = 0.75 and coefficient of determination (R2) = 0.77) by combining field measurements with inexpensive and readily available remotely sensed inputs. The spatial data (visual spectrum, near infrared, infrared/thermal) are produced by the AggieAir™ platform, which includes an unmanned aerial vehicle (UAV) that enables users to gather aerial imagery at a low price and high spatial and temporal resolutions. This study reports the development of an ANN model that translates AggieAir™ imagery into estimates of surface soil moisture for a large field irrigated by a center pivot sprinkler system.
KW  - remote sensing
KW  - high-resolution
KW  - multi-spectral
KW  - soil moisture
KW  - Artificial Neural Network
KW  - UAV
DO  - 10.3390/rs70302627
ER  -
TY  - EJOU
AU  - Li, Zhenwang
AU  - Tang, Huan
AU  - Zhang, Baohui
AU  - Yang, Guixia
AU  - Xin, Xiaoping
TI  - Evaluation and Intercomparison of MODIS and GEOV1 Global Leaf Area Index Products over Four Sites in North China
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 3
SN  - 1424-8220

AB  - This study investigated the performances of the Moderate Resolution Imaging Spectroradiometer (MODIS) and GEOLAND2 Version 1 (GEOV1) Leaf Area Index (LAI) products using ground measurements and LAI reference maps over four sites in North China for 2011–2013. The Terra + Aqua MODIS and Terra MODIS LAI retrieved by the main algorithm and GEOV1 LAI within the valid range were evaluated and intercompared using LAI reference maps to assess their uncertainty and seasonal variability The results showed that GEOV1 LAI is the most similar product with the LAI reference maps  (R2 = 0.78 and RMSE = 0.59). The MODIS products performed well for biomes with low LAI values, but considerable uncertainty arose when the LAI was larger than 3. Terra + Aqua MODIS (R2 = 0.72 and RMSE = 0.68) was slightly more accurate than Terra MODIS  (R2 = 0.57 and RMSE = 0.90) for producing slightly more successful observations. Both MODIS and GEOV1 products effectively followed the seasonal trajectory of the reference maps, and GEOV1 exhibited a smoother seasonal trajectory than MODIS. MODIS anomalies mainly occurred during summer and likely occurred because of surface reflectance uncertainty, shorter temporal resolutions and inconsistency between simulated and MODIS surface reflectances. This study suggests that further improvements of the MODIS LAI products should focus on finer algorithm inputs and improved seasonal variation modeling of MODIS observations. Future field work considering finer biome maps and better generation of LAI reference maps is still needed.
KW  - LAI
KW  - MODIS
KW  - GEOV1
KW  - evaluation
KW  - intercomparison
KW  - Validation network of Remote sensing Products in China (VRPC)
DO  - 10.3390/s150306196
ER  -
TY  - EJOU
AU  - Chiang, Kai-Wei
AU  - Tsai, Meng-Lun
AU  - Naser, El-Sheimy
AU  - Habib, Ayman
AU  - Chu, Chien-Hsun
TI  - New Calibration Method Using Low Cost MEM IMUs to Verify the Performance of UAV-Borne MMS Payloads
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 3
SN  - 1424-8220

AB  - Spatial information plays a critical role in remote sensing and mapping applications such as environment surveying and disaster monitoring. An Unmanned Aerial Vehicle (UAV)-borne mobile mapping system (MMS) can accomplish rapid spatial information acquisition under limited sky conditions with better mobility and flexibility than other means. This study proposes a long endurance Direct Geo-referencing (DG)-based fixed-wing UAV photogrammetric platform and two DG modules that each use different commercial Micro-Electro Mechanical Systems’ (MEMS) tactical grade Inertial Measurement Units (IMUs). Furthermore, this study develops a novel kinematic calibration method which includes lever arms, boresight angles and camera shutter delay to improve positioning accuracy. The new calibration method is then compared with the traditional calibration approach. The results show that the accuracy of the DG can be significantly improved by flying at a lower altitude using the new higher specification hardware. The new proposed method improves the accuracy of DG by about 20%. The preliminary results show that two-dimensional (2D) horizontal DG positioning accuracy is around 5.8 m at a flight height of 300 m using the newly designed tactical grade integrated Positioning and Orientation System (POS). The positioning accuracy in three-dimensions (3D) is less than 8 m.
KW  - UAV
KW  - IMU
KW  - GPS
KW  - MMS
KW  - DG
KW  - calibration
DO  - 10.3390/s150306560
ER  -
TY  - EJOU
AU  - Feng, Quanlong
AU  - Liu, Jiantao
AU  - Gong, Jianhua
TI  - Urban Flood Mapping Based on Unmanned Aerial Vehicle Remote Sensing and Random Forest Classifier—A Case of Yuyao, China
T2  - Water

PY  - 2015
VL  - 7
IS  - 4
SN  - 2073-4441

AB  - Flooding is a severe natural hazard, which poses a great threat to human life and property, especially in densely-populated urban areas. As one of the fastest developing fields in remote sensing applications, an unmanned aerial vehicle (UAV) can provide  high-resolution data with a great potential for fast and accurate detection of inundated areas under complex urban landscapes. In this research, optical imagery was acquired by a mini-UAV to monitor the serious urban waterlogging in Yuyao, China. Texture features derived from gray-level co-occurrence matrix were included to increase the separability of different ground objects. A Random Forest classifier, consisting of 200 decision trees, was used to extract flooded areas in the spectral-textural feature space. Confusion matrix was used to assess the accuracy of the proposed method. Results indicated the following:  (1) Random Forest showed good performance in urban flood mapping with an overall accuracy of 87.3% and a Kappa coefficient of 0.746; (2) the inclusion of texture features improved classification accuracy significantly; (3) Random Forest outperformed maximum likelihood and artificial neural network, and showed a similar performance to support vector machine. The results demonstrate that UAV can provide an ideal platform for urban flood monitoring and the proposed method shows great capability for the accurate extraction of inundated areas.
KW  - UAV
KW  - flood mapping
KW  - urban landscape
KW  - random forest
KW  - texture analysis
DO  - 10.3390/w7041437
ER  -
TY  - EJOU
AU  - Wang, Jianhua
AU  - Qin, Qiming
AU  - Zhao, Jianghua
AU  - Ye, Xin
AU  - Feng, Xiao
AU  - Qin, Xuebin
AU  - Yang, Xiucheng
TI  - Knowledge-Based Detection and Assessment of Damaged Roads Using Post-Disaster High-Resolution Remote Sensing Image
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 4
SN  - 2072-4292

AB  - Road damage detection and assessment from high-resolution remote sensing image is critical for natural disaster investigation and disaster relief. In a disaster context, the pairing of pre-disaster and post-disaster road data for change detection and assessment is difficult to achieve due to the mismatch of different data sources, especially for rural areas where the pre-disaster data (i.e., remote sensing imagery or vector map) are hard to obtain. In this study, a knowledge-based method for road damage detection and assessment solely from post-disaster high-resolution remote sensing image is proposed. The road centerline is firstly extracted based on the preset road seed points. Then, features such as road brightness, standard deviation, rectangularity, and aspect ratio are selected to form a knowledge model. Finally, under the guidance of the road centerline, the post-disaster roads are extracted and the damaged roads are detected by applying the knowledge model. In order to quantitatively assess the damage degree, damage assessment indicators with their corresponding standard of damage grade are also proposed. The newly developed method is evaluated using a WorldView-1 image over Wenchuan, China acquired three days after the earthquake on 15 May 2008. The results show that the producer’s accuracy (PA) and user’s accuracy (UA) reached about 90% and 85%, respectively, indicating that the proposed method is effective for road damage detection and assessment. This approach also significantly reduces the need for pre-disaster remote sensing data.
KW  - high-resolution remote sensing image
KW  - road centerline
KW  - knowledge model
KW  - damage detection
KW  - assessment indicator
DO  - 10.3390/rs70404948
ER  -
TY  - EJOU
AU  - Calderón, Rocío
AU  - Navas-Cortés, Juan A.
AU  - Zarco-Tejada, Pablo J.
TI  - Early Detection and Quantification of Verticillium Wilt in Olive Using Hyperspectral and Thermal Imagery over Large Areas
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 5
SN  - 2072-4292

AB  - Automatic methods for an early detection of plant diseases (i.e., visible symptoms at early stages of disease development) using remote sensing are critical for precision crop protection. Verticillium wilt (VW) of olive caused by Verticillium dahliae can be controlled only if detected at early stages of development. Linear discriminant analysis (LDA) and support vector machine (SVM) classification methods were applied to classify V. dahliae severity using remote sensing at large scale. High-resolution thermal and hyperspectral imagery were acquired with a manned platform which flew a 3000-ha commercial olive area. LDA reached an overall accuracy of 59.0% and a κ of 0.487 while SVM obtained a higher overall accuracy, 79.2% with a similar κ, 0.495. However, LDA better classified trees at initial and low severity levels, reaching accuracies of 71.4 and 75.0%, respectively, in comparison with the 14.3% and 40.6% obtained by SVM. Normalized canopy temperature, chlorophyll fluorescence, structural, xanthophyll, chlorophyll, carotenoid and disease indices were found to be the best indicators for early and advanced stage infection by VW. These results demonstrate that the methods developed in other studies at orchard scale are valid for flights in large areas comprising several olive orchards differing in soil and crop management characteristics.
KW  - Verticillium wilt
KW  - early detection
KW  - hyperspectral
KW  - thermal
KW  - support vector machine
KW  - linear discriminant analysis
DO  - 10.3390/rs70505584
ER  -
TY  - EJOU
AU  - Feng, Yibo
AU  - Li, Xisheng
AU  - Zhang, Xiaojuan
TI  - An Adaptive Compensation Algorithm for Temperature Drift of Micro-Electro-Mechanical Systems Gyroscopes Using a Strong Tracking Kalman Filter
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 5
SN  - 1424-8220

AB  - We present an adaptive algorithm for a system integrated with  micro-electro-mechanical systems (MEMS) gyroscopes and a compass to eliminate the influence from the environment, compensate the temperature drift precisely, and improve the accuracy of the MEMS gyroscope. We use a simplified drift model and changing but appropriate model parameters to implement this algorithm. The model of MEMS gyroscope temperature drift is constructed mostly on the basis of the temperature sensitivity of the gyroscope. As the state variables of a strong tracking Kalman filter (STKF), the parameters of the temperature drift model can be calculated to adapt to the environment under the support of the compass. These parameters change intelligently with the environment to maintain the precision of the MEMS gyroscope in the changing temperature. The heading error is less than 0.6° in the static temperature experiment, and also is kept in the range from 5° to −2° in the dynamic outdoor experiment. This demonstrates that the proposed algorithm exhibits strong adaptability to a changing temperature, and performs significantly better than KF and MLR to compensate the temperature drift of a gyroscope and eliminate the influence of temperature variation.
KW  - strong tracking Kalman filter
KW  - bias
KW  - compass
KW  - MEMS gyroscope
DO  - 10.3390/s150511222
ER  -
TY  - EJOU
AU  - Goodarzi, Rohollah
AU  - Mokhtarzade, Mehdi
AU  - Zoej, M. J.
TI  - A Robust Fuzzy Neural Network Model for Soil Lead Estimation from Spectral Features
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 7
SN  - 2072-4292

AB  - Soil lead content is an important parameter in environmental and industrial applications. Chemical analysis, the most commonly method for studying soil samples, are costly, however application of soil spectroscopy presents a more viable alternative.  The first step in the method is usually to extract some appropriate spectral features and then regression models are applied to these extracted features. The aim of this paper was to design an accurate and robust regression technique to estimate soil lead contents from laboratory observed spectra. Three appropriate spectral features were selected according to information from other research as well as the spectrum interpretation of field collected soil samples containing lead. These features were then applied to common Multiple Linear Regression (MLR), Partial Least Square Regression (PLSR) and Neural Network (NN) regression models. Results showed that although NN had adequate accuracy, it produced unstable results (i.e., variation of response in different runs). This problem was addressed with application of a Fuzzy Neural Network (FNN) with a least square training strategy.  In addition to the stabilized and unique response, the capability of the proposed FNN was proved in terms of regression accuracy where a Ratio of Performance to Deviation (RPD) of 8.76 was achieved for test samples.
KW  - environment
KW  - soil
KW  - lead
KW  - SVC HR 1024 Spectroradiometer
KW  - regression models
KW  - fuzzy neural network (FNN)
DO  - 10.3390/rs70708416
ER  -
TY  - EJOU
AU  - Gökçe, Fatih
AU  - Üçoluk, Göktürk
AU  - Şahin, Erol
AU  - Kalkan, Sinan
TI  - Vision-Based Detection and Distance Estimation of Micro Unmanned Aerial Vehicles
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 9
SN  - 1424-8220

AB  - Detection and distance estimation of micro unmanned aerial vehicles (mUAVs) is crucial for (i) the detection of intruder mUAVs in protected environments; (ii) sense and avoid purposes on mUAVs or on other aerial vehicles and (iii) multi-mUAV control scenarios, such as environmental monitoring, surveillance and exploration. In this article, we evaluate vision algorithms as alternatives for detection and distance estimation of mUAVs, since other sensing modalities entail certain limitations on the environment or on the distance. For this purpose, we test Haar-like features, histogram of gradients (HOG) and local binary patterns (LBP) using cascades of boosted classifiers. Cascaded boosted classifiers allow fast processing by performing detection tests at multiple stages, where only candidates passing earlier simple stages are processed at the preceding more complex stages. We also integrate a distance estimation method with our system utilizing geometric cues with support vector regressors. We evaluated each method on indoor and outdoor videos that are collected in a systematic way and also on videos having motion blur. Our experiments show that, using boosted cascaded classifiers with LBP, near real-time detection and distance estimation of mUAVs are possible in about 60 ms indoors (1032 × 778 resolution) and 150 ms outdoors (1280 × 720 resolution) per frame, with a detection rate of 0.96 F-score. However, the cascaded classifiers using Haar-like features lead to better distance estimation since they can position the bounding boxes on mUAVs more accurately. On the other hand, our time analysis yields that the cascaded classifiers using HOG train and run faster than the other algorithms.
KW  - UAV
KW  - micro UAV
KW  - vision
KW  - detection
KW  - distance estimation
KW  - cascaded classifiers
DO  - 10.3390/s150923805
ER  -
TY  - EJOU
AU  - Akcay, Ozgun
TI  - Landslide Fissure Inference Assessment by ANFIS and Logistic Regression Using UAS-Based Photogrammetry
T2  - ISPRS International Journal of Geo-Information

PY  - 2015
VL  - 4
IS  - 4
SN  - 2220-9964

AB  - Unmanned Aerial Systems (UAS) are now capable of gathering high-resolution data, therefore, landslides can be explored in detail at larger scales. In this research, 132 aerial photographs were captured, and 85,456 features were detected and matched automatically using UAS photogrammetry. The root mean square (RMS) values of the image coordinates of the Ground Control Points (GPCs) varied from 0.521 to 2.293 pixels, whereas maximum RMS values of automatically matched features was calculated as 2.921 pixels. Using the 3D point cloud, which was acquired by aerial photogrammetry, the raster datasets of the aspect, slope, and maximally stable extremal regions (MSER) detecting visual uniformity, were defined as three variables, in order to reason fissure structures on the landslide surface. In this research, an Adaptive Neuro Fuzzy Inference System (ANFIS) and a Logistic Regression (LR) were implemented using training datasets to infer fissure data appropriately. The accuracy of the predictive models was evaluated by drawing receiver operating characteristic (ROC) curves and by calculating the area under the ROC curve (AUC). The experiments exposed that high-resolution imagery is an indispensable data source to model and validate landslide fissures appropriately.
KW  - photogrammetry
KW  - fuzzy logic
KW  - landslide
KW  - fissure
KW  - orthophotos
KW  - image processing
KW  - Unmanned Aerial System (UAS)
DO  - 10.3390/ijgi4042131
ER  -
TY  - EJOU
AU  - Casado, Monica R.
AU  - Gonzalez, Rocio B.
AU  - Kriechbaumer, Thomas
AU  - Veal, Amanda
TI  - Automated Identification of River Hydromorphological Features Using UAV High Resolution Aerial Imagery
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 11
SN  - 1424-8220

AB  - European legislation is driving the development of methods for river ecosystem protection in light of concerns over water quality and ecology. Key to their success is the accurate and rapid characterisation of physical features (i.e., hydromorphology) along the river. Image pattern recognition techniques have been successfully used for this purpose. The reliability of the methodology depends on both the quality of the aerial imagery  and the pattern recognition technique used. Recent studies have proved the potential of Unmanned Aerial Vehicles (UAVs) to increase the quality of the imagery by capturing high resolution photography. Similarly, Artificial Neural Networks (ANN) have been shown to be a high precision tool for automated recognition of environmental patterns. This paper presents a UAV based framework for the identification of hydromorphological features from high resolution RGB aerial imagery using a novel classification technique based on ANNs. The framework is developed for a 1.4 km river reach along the river Dee in Wales, United Kingdom. For this purpose, a Falcon 8 octocopter was used to gather  2.5 cm resolution imagery. The results show that the accuracy of the framework is above 81%, performing particularly well at recognising vegetation. These results leverage the use of UAVs for environmental policy implementation and demonstrate the potential of ANNs and RGB imagery for high precision river monitoring and river management.
KW  - Unmanned Aerial Vehicle
KW  - photogrammetry
KW  - Artificial Neural Network
KW  - feature recognition
KW  - hydromorphology
DO  - 10.3390/s151127969
ER  -
TY  - EJOU
AU  - Li, Geng
AU  - Zhang, Pengfei
AU  - Wei, Guo
AU  - Xie, Yuanping
AU  - Yu, Xudong
AU  - Long, Xingwu
TI  - Multiple-Point Temperature Gradient Algorithm for Ring Laser Gyroscope Bias Compensation
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 12
SN  - 1424-8220

AB  - To further improve ring laser gyroscope (RLG) bias stability, a multiple-point temperature gradient algorithm is proposed for RLG bias compensation in this paper. Based on the multiple-point temperature measurement system, a complete thermo-image of the RLG block is developed. Combined with the multiple-point temperature gradients between different points of the RLG block, the particle swarm optimization algorithm is used to tune the support vector machine (SVM) parameters, and an optimized design for selecting the thermometer locations is also discussed. The experimental results validate the superiority of the introduced method and enhance the precision and generalizability in the RLG bias compensation model.
KW  - error compensation
KW  - particle swarm optimization
KW  - ring laser gyroscope
KW  - support vector machine
KW  - gradient methods
KW  - temperature sensors
KW  - temperature measurement
DO  - 10.3390/s151229777
ER  -
TY  - EJOU
AU  - Olivares-Mendez, Miguel A.
AU  - Fu, Changhong
AU  - Ludivig, Philippe
AU  - Bissyandé, Tegawendé F.
AU  - Kannan, Somasundar
AU  - Zurad, Maciej
AU  - Annaiyan, Arun
AU  - Voos, Holger
AU  - Campoy, Pascual
TI  - Towards an Autonomous Vision-Based Unmanned Aerial System against Wildlife Poachers
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 12
SN  - 1424-8220

AB  - Poaching is an illegal activity that remains out of control in many countries. Based on the 2014 report of the United Nations and Interpol, the illegal trade of global wildlife and natural resources amounts to nearly                                        $               213                                  billion every year, which is even helping to fund armed conflicts. Poaching activities around the world are further pushing many animal species on the brink of extinction. Unfortunately, the traditional methods to fight against poachers are not enough, hence the new demands for more efficient approaches. In this context, the use of new technologies on sensors and algorithms, as well as aerial platforms is crucial to face the high increase of poaching activities in the last few years. Our work is focused on the use of vision sensors on UAVs for the detection and tracking of animals and poachers, as well as the use of such sensors to control quadrotors during autonomous vehicle following and autonomous landing.
KW  - unmanned aerial vehicles
KW  - computer vision
KW  - animal tracking
KW  - face detection
KW  - vision-based control
KW  - object following
KW  - autonomous navigation
KW  - autonomous landing
KW  - anti-poaching
DO  - 10.3390/s151229861
ER  -
TY  - EJOU
AU  - Eaton, Christopher M.
AU  - Chong, Edwin K. P.
AU  - Maciejewski, Anthony A.
TI  - Multiple-Scenario Unmanned Aerial System Control: A Systems Engineering Approach and Review of Existing Control Methods
T2  - Aerospace

PY  - 2016
VL  - 3
IS  - 1
SN  - 2226-4310

AB  - The use of unmanned aerial systems (UASs) in both the public and military environments is predicted to grow significantly. As the demand for UASs grows, the availability of more robust and capable vehicles that can perform multiple mission types will be needed. In the public sector, the demand will grow for UASs to be used for agriculture, forestry, and search and rescue missions. Militaries continue to demand more UAS capabilities for diverse operations around the world. Significant research has been performed and continues to progress in the areas of autonomous UAS control. A majority of the work focuses on subsets of UAS control: path planning, autonomy, small UAS controls, and sensors. Minimal work exists on a system-level problem of multiple-scenario UAS control for integrated systems. This paper provides a high-level modular system architecture definition that is modifiable across platform types and mission requirements. A review of the current research and employment of UAS capabilities is provided to evaluate the state of the capabilities required to enable the proposed architecture.
KW  - Unmanned Aerial System (UAS)
KW  - autonomous systems
KW  - UAS control
KW  - path planning
KW  - system architecture
KW  - Multi-UAS control
KW  - collision avoidance
KW  - multi-scenario UAS control
DO  - 10.3390/aerospace3010001
ER  -
TY  - EJOU
AU  - S. R. Pappu, Venkatasubramani
AU  - Steck, James E.
AU  - Ramamurthi, Guruganesh
TI  - Turbulence Effects on Modified State Observer-Based Adaptive Control: Black Kite Micro Aerial Vehicle
T2  - Aerospace

PY  - 2016
VL  - 3
IS  - 1
SN  - 2226-4310

AB  - This paper presents the implementation of a modified state observer-based adaptive dynamic inverse controller for the Black Kite micro aerial vehicle. The pitch and velocity adaptations are computed by the modified state observer in the presence of turbulence to simulate atmospheric conditions. This state observer uses the estimation error to generate the adaptations and, hence, is more robust than model reference adaptive controllers which use modeling or tracking error. In prior work, a traditional proportional-integral-derivative control law was tested in simulation for its adaptive capability in the longitudinal dynamics of the Black Kite micro aerial vehicle. This controller tracks the altitude and velocity commands during normal conditions, but fails in the presence of both parameter uncertainties and system failures. The modified state observer-based adaptations, along with the proportional-integral-derivative controller enables tracking despite these conditions. To simulate flight of the micro aerial vehicle with turbulence, a Dryden turbulence model is included. The turbulence levels used are based on the absolute load factor experienced by the aircraft. The length scale was set to 2.0 meters with a turbulence intensity of 5.0 m/s that generates a moderate turbulence. Simulation results for various flight conditions show that the modified state observer-based adaptations were able to adapt to the uncertainties and the controller tracks the commanded altitude and velocity. The summary of results for all of the simulated test cases and the response plots of various states for typical flight cases are presented.
KW  - modified state observer
KW  - adaptive control
KW  - micro aerial vehicle
DO  - 10.3390/aerospace3010006
ER  -
TY  - EJOU
AU  - Torres-Rua, Alfonso F.
AU  - Ticlavilca, Andres M.
AU  - Bachour, Roula
AU  - McKee, Mac
TI  - Estimation of Surface Soil Moisture in Irrigated Lands by Assimilation of Landsat Vegetation Indices, Surface Energy Balance Products, and Relevance Vector Machines
T2  - Water

PY  - 2016
VL  - 8
IS  - 4
SN  - 2073-4441

AB  - Spatial surface soil moisture can be an important indicator of crop conditions on farmland, but its continuous estimation remains challenging due to coarse spatial and temporal resolution of existing remotely-sensed products. Furthermore, while preceding research on soil moisture using remote sensing (surface energy balance, weather parameters, and vegetation indices) has demonstrated a relationship between these factors and soil moisture, practical continuous spatial quantification of the latter is still unavailable for use in water and agricultural management. In this study, a methodology is presented to estimate volumetric surface soil moisture by statistical selection from potential predictors that include vegetation indices and energy balance products derived from satellite (Landsat) imagery and weather data as identified in scientific literature. This methodology employs a statistical learning machine called a Relevance Vector Machine (RVM) to identify and relate the potential predictors to soil moisture by means of stratified cross-validation and forward variable selection. Surface soil moisture measurements from irrigated agricultural fields in Central Utah in the 2012 irrigation season were used, along with weather data, Landsat vegetation indices, and energy balance products. The methodology, data collection, processing, and estimation accuracy are presented and discussed.
KW  - soil moisture
KW  - evapotranspiration
KW  - remote sensing
KW  - surface energy balance
KW  - irrigation
KW  - Relevance Vector Machines
KW  - Landsat
KW  - Data Mining
DO  - 10.3390/w8040167
ER  -
TY  - EJOU
AU  - Chuang, Yung-Chung M.
AU  - Shiu, Yi-Shiang
TI  - A Comparative Analysis of Machine Learning with WorldView-2 Pan-Sharpened Imagery for Tea Crop Mapping
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 5
SN  - 1424-8220

AB  - Tea is an important but vulnerable economic crop in East Asia, highly impacted by climate change. This study attempts to interpret tea land use/land cover (LULC) using very high resolution WorldView-2 imagery of central Taiwan with both pixel and object-based approaches. A total of 80 variables derived from each WorldView-2 band with pan-sharpening, standardization, principal components and gray level co-occurrence matrix (GLCM) texture indices transformation, were set as the input variables. For pixel-based image analysis (PBIA), 34 variables were selected, including seven principal components, 21 GLCM texture indices and six original WorldView-2 bands. Results showed that support vector machine (SVM) had the highest tea crop classification accuracy (OA = 84.70% and KIA = 0.690), followed by random forest (RF), maximum likelihood algorithm (ML), and logistic regression analysis (LR). However, the ML classifier achieved the highest classification accuracy (OA = 96.04% and KIA = 0.887) in object-based image analysis (OBIA) using only six variables. The contribution of this study is to create a new framework for accurately identifying tea crops in a subtropical region with real-time high-resolution WorldView-2 imagery without field survey, which could further aid agriculture land management and a sustainable agricultural product supply.
KW  - WorldView-2
KW  - tea crops
KW  - GLCM texture
KW  - pixel and object-based image analysis
KW  - random forest
KW  - support vector machine
DO  - 10.3390/s16050594
ER  -
TY  - EJOU
AU  - Alavi, Shamir
AU  - Arsenault, Dennis
AU  - Whitehead, Anthony
TI  - Quaternion-Based Gesture Recognition Using Wireless Wearable Motion Capture Sensors
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 5
SN  - 1424-8220

AB  - This work presents the development and implementation of a unified multi-sensor human motion capture and gesture recognition system that can distinguish between and classify six different gestures. Data was collected from eleven participants using a subset of five wireless motion sensors (inertial measurement units) attached to their arms and upper body from a complete motion capture system. We compare Support Vector Machines and Artificial Neural Networks on the same dataset under two different scenarios and evaluate the results. Our study indicates that near perfect classification accuracies are achievable for small gestures and that the speed of classification is sufficient to allow interactivity. However, such accuracies are more difficult to obtain when a participant does not participate in training, indicating that more work needs to be done in this area to create a system that can be used by the general population.
KW  - gesture recognition
KW  - wearable sensors
KW  - quaternions
KW  - pattern analysis
KW  - machine learning
KW  - support vector machines
KW  - artificial neural networks
DO  - 10.3390/s16050605
ER  -
TY  - EJOU
AU  - Minaei, Masoud
AU  - Kainz, Wolfgang
TI  - Watershed Land Cover/Land Use Mapping Using Remote Sensing and Data Mining in Gorganrood, Iran
T2  - ISPRS International Journal of Geo-Information

PY  - 2016
VL  - 5
IS  - 5
SN  - 2220-9964

AB  - The Gorganrood watershed (GW) is experiencing considerable environmental change in the form of natural hazards and erosion, as well as deforestation, cultivation and development activities. As a result of this, different types of Land Cover/Land Use (LCLU) change are taking place on an intensive level in the area. This research study investigates the LCLU conditions upstream of this watershed for the years 1972, 1986, 2000 and 2014, using Landsat MSS, TM, ETM+ and OLI/TIRS images. LCLU maps for 1972, 1986, and 2000 were produced using pixel-based classification methods. For the 2014 LCLU map, Geographic Object-Based Image Analysis (GEOBIA) in combination with the data-mining capabilities of Gini and J48 machine-learning algorithms were used. The accuracy of the maps was assessed using overall accuracy, quantity disagreement and allocation disagreement indexes. The overall accuracy ranged from 89% to 95%, quantity disagreement from 2.1% to 6.6%, and allocation disagreement from 2.1% for 2014 to 2.7% for 2000. The results of this study indicate that a significant amount of change has occurred in the region, and that this has as a consequence affected ecosystem services and human activity. This knowledge of the LCLU status in the area will help managers and decision makers to develop plans and programs aimed at effectively managing the watershed into the future.
KW  - GEOBIA
KW  - data mining
KW  - machine learning
KW  - Landsat
DO  - 10.3390/ijgi5050057
ER  -
TY  - EJOU
AU  - Ramon Soria, Pablo
AU  - Bevec, Robert
AU  - Arrue, Begoña C.
AU  - Ude, Aleš
AU  - Ollero, Aníbal
TI  - Extracting Objects for Aerial Manipulation on UAVs Using Low Cost Stereo Sensors
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 5
SN  - 1424-8220

AB  - Giving unmanned aerial vehicles (UAVs) the possibility to manipulate objects vastly extends the range of possible applications. This applies to rotary wing UAVs in particular, where their capability of hovering enables a suitable position for in-flight manipulation. Their manipulation skills must be suitable for primarily natural, partially known environments, where UAVs mostly operate. We have developed an on-board object extraction method that calculates information necessary for autonomous grasping of objects, without the need to provide the model of the object’s shape. A local map of the work-zone is generated using depth information, where object candidates are extracted by detecting areas different to our floor model. Their image projections are then evaluated using support vector machine (SVM) classification to recognize specific objects or reject bad candidates. Our method builds a sparse cloud representation of each object and calculates the object’s centroid and the dominant axis. This information is then passed to a grasping module. Our method works under the assumption that objects are static and not clustered, have visual features and the floor shape of the work-zone area is known. We used low cost cameras for creating depth information that cause noisy point clouds, but our method has proved robust enough to process this data and return accurate results.
KW  - UAV
KW  - object detection
KW  - object recognition
KW  - SVM
KW  - manipulation
DO  - 10.3390/s16050700
ER  -
TY  - EJOU
AU  - Papakonstantinou, Apostolos
AU  - Topouzelis, Konstantinos
AU  - Pavlogeorgatos, Gerasimos
TI  - Coastline Zones Identification and 3D Coastal Mapping Using UAV Spatial Data
T2  - ISPRS International Journal of Geo-Information

PY  - 2016
VL  - 5
IS  - 6
SN  - 2220-9964

AB  - Spatial data acquisition is a critical process for the identification of the coastline and coastal zones for scientists involved in the study of coastal morphology. The availability of very high-resolution digital surface models (DSMs) and orthophoto maps is of increasing interest to all scientists, especially those monitoring small variations in the earth’s surface, such as coastline morphology. In this article, we present a methodology to acquire and process high resolution data for coastal zones acquired by a vertical take off and landing (VTOL) unmanned aerial vehicle (UAV) attached to a small commercial camera. The proposed methodology integrated computer vision algorithms for 3D representation with image processing techniques for analysis. The computer vision algorithms used the structure from motion (SfM) approach while the image processing techniques used the geographic object-based image analysis (GEOBIA) with fuzzy classification. The SfM pipeline was used to construct the DSMs and orthophotos with a measurement precision in the order of centimeters. Consequently, GEOBIA was used to create objects by grouping pixels that had the same spectral characteristics together and extracting statistical features from them. The objects produced were classified by fuzzy classification using the statistical features as input. The classification output classes included beach composition (sand, rubble, and rocks) and sub-surface classes (seagrass, sand, algae, and rocks). The methodology was applied to two case studies of coastal areas with different compositions: a sandy beach with a large face and a rubble beach with a small face. Both are threatened by beach erosion and have been degraded by the action of sea storms. Results show that the coastline, which is the low limit of the swash zone, was detected successfully by both the 3D representations and the image classifications. Furthermore, several traces representing previous sea states were successfully recognized in the case of the sandy beach, while the erosion and beach crests were detected in the case of the rubble beach. The achieved level of detail of the 3D representations revealed new beach characteristics, including erosion crests, berm zones, and sand dunes. In conclusion, the UAV SfM workflow provides information in a spatial resolution that permits the study of coastal changes with confidence and provides accurate 3D visualizations of the beach zones, even for areas with complex topography. The overall results show that the presented methodology is a robust tool for the classification, 3D visualization, and mapping of coastal morphology.
KW  - UAV data acquisition
KW  - coastal mapping
KW  - structure from motion
KW  - GEOBIA
KW  - 3D geovisualization
KW  - digital surface model
DO  - 10.3390/ijgi5060075
ER  -
TY  - EJOU
AU  - Roldán, Juan J.
AU  - Garcia-Aunon, Pablo
AU  - Garzón, Mario
AU  - De León, Jorge
AU  - Del Cerro, Jaime
AU  - Barrientos, Antonio
TI  - Heterogeneous Multi-Robot System for Mapping Environmental Variables of Greenhouses
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 7
SN  - 1424-8220

AB  - The productivity of greenhouses highly depends on the environmental conditions of crops, such as temperature and humidity. The control and monitoring might need large sensor networks, and as a consequence, mobile sensory systems might be a more suitable solution. This paper describes the application of a heterogeneous robot team to monitor environmental variables of greenhouses. The multi-robot system includes both ground and aerial vehicles, looking to provide flexibility and improve performance. The multi-robot sensory system measures the temperature, humidity, luminosity and carbon dioxide concentration in the ground and at different heights. Nevertheless, these measurements can be complemented with other ones (e.g., the concentration of various gases or images of crops) without a considerable effort. Additionally, this work addresses some relevant challenges of multi-robot sensory systems, such as the mission planning and task allocation, the guidance, navigation and control of robots in greenhouses and the coordination among ground and aerial vehicles. This work has an eminently practical approach, and therefore, the system has been extensively tested both in simulations and field experiments.
KW  - robotics
KW  - UGV
KW  - UAV
KW  - multi-robot
KW  - environmental monitoring
KW  - sensory system
KW  - griculture
KW  - greenhouse
DO  - 10.3390/s16071018
ER  -
TY  - EJOU
AU  - Kim, Sungho
AU  - Song, Woo-Jin
AU  - Kim, So-Hyun
TI  - Robust Ground Target Detection by SAR and IR Sensor Fusion Using Adaboost-Based Feature Selection
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 7
SN  - 1424-8220

AB  - Long-range ground targets are difficult to detect in a noisy cluttered environment using either synthetic aperture radar (SAR) images or infrared (IR) images. SAR-based detectors can provide a high detection rate with a high false alarm rate to background scatter noise. IR-based approaches can detect hot targets but are affected strongly by the weather conditions. This paper proposes a novel target detection method by decision-level SAR and IR fusion using an Adaboost-based machine learning scheme to achieve a high detection rate and low false alarm rate. The proposed method consists of individual detection, registration, and fusion architecture. This paper presents a single framework of a SAR and IR target detection method using modified Boolean map visual theory (modBMVT) and feature-selection based fusion. Previous methods applied different algorithms to detect SAR and IR targets because of the different physical image characteristics. One method that is optimized for IR target detection produces unsuccessful results in SAR target detection. This study examined the image characteristics and proposed a unified SAR and IR target detection method by inserting a median local average filter (MLAF, pre-filter) and an asymmetric morphological closing filter (AMCF, post-filter) into the BMVT. The original BMVT was optimized to detect small infrared targets. The proposed modBMVT can remove the thermal and scatter noise by the MLAF and detect extended targets by attaching the AMCF after the BMVT. Heterogeneous SAR and IR images were registered automatically using the proposed RANdom SAmple Region Consensus (RANSARC)-based homography optimization after a brute-force correspondence search using the detected target centers and regions. The final targets were detected by feature-selection based sensor fusion using Adaboost. The proposed method showed good SAR and IR target detection performance through feature selection-based decision fusion on a synthetic database generated by OKTAL-SE.
KW  - synthetic aperture radar
KW  - infrared
KW  - target detection
KW  - sensor fusion
KW  - machine learning
KW  - feature selection
KW  - OKTAL-SE
DO  - 10.3390/s16071117
ER  -
TY  - EJOU
AU  - Rivas Casado, Monica
AU  - Ballesteros Gonzalez, Rocio
AU  - Wright, Ros
AU  - Bellamy, Pat
TI  - Quantifying the Effect of Aerial Imagery Resolution in Automated Hydromorphological River Characterisation
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 8
SN  - 2072-4292

AB  - Existing regulatory frameworks aiming to improve the quality of rivers place hydromorphology as a key factor in the assessment of hydrology, morphology and river continuity. The majority of available methods for hydromorphological characterisation rely on the identification of homogeneous areas (i.e., features) of flow, vegetation and substrate. For that purpose, aerial imagery is used to identify existing features through either visual observation or automated classification techniques. There is evidence to believe that the success in feature identification relies on the resolution of the imagery used. However, little effort has yet been made to quantify the uncertainty in feature identification associated with the resolution of the aerial imagery. This paper contributes to address this gap in knowledge by contrasting results in automated hydromorphological feature identification from unmanned aerial vehicles (UAV) aerial imagery captured at three resolutions (2.5 cm, 5 cm and 10 cm) along a 1.4 km river reach. The results show that resolution plays a key role in the accuracy and variety of features identified, with larger identification errors observed for riffles and side bars. This in turn has an impact on the ecological characterisation of the river reach. The research shows that UAV technology could be essential for unbiased hydromorphological assessment.
KW  - unmanned aerial vehicle
KW  - photogrammetry
KW  - resolution
KW  - comparison
KW  - hydromorphology
KW  - river management
DO  - 10.3390/rs8080650
ER  -
TY  - EJOU
AU  - Oyekan, John
TI  - Bio-Inspired Vision-Based Leader-Follower Formation Flying in the Presence of Delays
T2  - Robotics

PY  - 2016
VL  - 5
IS  - 3
SN  - 2218-6581

AB  - Flocking starlings at dusk are known for the mesmerizing and intricate shapes they generate, as well as how fluid these shapes change. They seem to do this effortlessly. Real-life vision-based flocking has not been achieved in micro-UAVs (micro Unmanned Aerial Vehicles) to date. Towards this goal, we make three contributions in this paper: (i) we used a computational approach to develop a bio-inspired architecture for vision-based Leader-Follower formation flying on two micro-UAVs. We believe that the minimal computational cost of the resulting algorithm makes it suitable for object detection and tracking during high-speed flocking; (ii) we show that provided delays in the control loop of a micro-UAV are below a critical value, Kalman filter-based estimation algorithms are not required to achieve Leader-Follower formation flying; (iii) unlike previous approaches, we do not use external observers, such as GPS signals or synchronized communication with flock members. These three contributions could be useful in achieving vision-based flocking in GPS-denied environments on computationally-limited agents.
KW  - bio-inspiration
KW  - flocking
KW  - vision
KW  - delays
KW  - communication
DO  - 10.3390/robotics5030018
ER  -
TY  - EJOU
AU  - Xu, Yongzheng
AU  - Yu, Guizhen
AU  - Wang, Yunpeng
AU  - Wu, Xinkai
AU  - Ma, Yalong
TI  - A Hybrid Vehicle Detection Method Based on Viola-Jones and HOG + SVM from UAV Images
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 8
SN  - 1424-8220

AB  - A new hybrid vehicle detection scheme which integrates the Viola-Jones (V-J) and linear SVM classifier with HOG feature (HOG + SVM) methods is proposed for vehicle detection from low-altitude unmanned aerial vehicle (UAV) images. As both V-J and HOG + SVM are sensitive to on-road vehicles’ in-plane rotation, the proposed scheme first adopts a roadway orientation adjustment method, which rotates each UAV image to align the roads with the horizontal direction so the original V-J or HOG + SVM method can be directly applied to achieve fast detection and high accuracy. To address the issue of descending detection speed for V-J and HOG + SVM, the proposed scheme further develops an adaptive switching strategy which sophistically integrates V-J and HOG + SVM methods based on their different descending trends of detection speed to improve detection efficiency. A comprehensive evaluation shows that the switching strategy, combined with the road orientation adjustment method, can significantly improve the efficiency and effectiveness of the vehicle detection from UAV images. The results also show that the proposed vehicle detection method is competitive compared with other existing vehicle detection methods. Furthermore, since the proposed vehicle detection method can be performed on videos captured from moving UAV platforms without the need of image registration or additional road database, it has great potentials of field applications. Future research will be focusing on expanding the current method for detecting other transportation modes such as buses, trucks, motors, bicycles, and pedestrians.
KW  - vehicle detection
KW  - unmanned aerial vehicle
KW  - Viola-Jones
KW  - HOG
KW  - road orientation
DO  - 10.3390/s16081325
ER  -
TY  - EJOU
AU  - Crommelinck, Sophie
AU  - Bennett, Rohan
AU  - Gerke, Markus
AU  - Nex, Francesco
AU  - Yang, Michael Y.
AU  - Vosselman, George
TI  - Review of Automatic Feature Extraction from High-Resolution Optical Sensor Data for UAV-Based Cadastral Mapping
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 8
SN  - 2072-4292

AB  - Unmanned Aerial Vehicles (UAVs) have emerged as a rapid, low-cost and flexible acquisition system that appears feasible for application in cadastral mapping: high-resolution imagery, acquired using UAVs, enables a new approach for defining property boundaries. However, UAV-derived data are arguably not exploited to its full potential: based on UAV data, cadastral boundaries are visually detected and manually digitized. A workflow that automatically extracts boundary features from UAV data could increase the pace of current mapping procedures. This review introduces a workflow considered applicable for automated boundary delineation from UAV data. This is done by reviewing approaches for feature extraction from various application fields and synthesizing these into a hypothetical generalized cadastral workflow. The workflow consists of preprocessing, image segmentation, line extraction, contour generation and postprocessing. The review lists example methods per workflow step—including a description, trialed implementation, and a list of case studies applying individual methods. Furthermore, accuracy assessment methods are outlined. Advantages and drawbacks of each approach are discussed in terms of their applicability on UAV data. This review can serve as a basis for future work on the implementation of most suitable methods in a UAV-based cadastral mapping workflow.
KW  - UAV Photogrammetry
KW  - optical sensors
KW  - HRSI
KW  - image segmentation
KW  - line extraction
KW  - contour generation
KW  - image analysis
KW  - OBIA
KW  - land administration
KW  - cadastral boundaries
DO  - 10.3390/rs8080689
ER  -
TY  - EJOU
AU  - Fu, Changhong
AU  - Duan, Ran
AU  - Kircali, Dogan
AU  - Kayacan, Erdal
TI  - Onboard Robust Visual Tracking for UAVs Using a Reliable Global-Local Object Model
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 9
SN  - 1424-8220

AB  - In this paper, we present a novel onboard robust visual algorithm for long-term arbitrary 2D and 3D object tracking using a reliable global-local object model for unmanned aerial vehicle (UAV) applications, e.g., autonomous tracking and chasing a moving target. The first main approach in this novel algorithm is the use of a global matching and local tracking approach. In other words, the algorithm initially finds feature correspondences in a way that an improved binary descriptor is developed for global feature matching and an iterative Lucas–Kanade optical flow algorithm is employed for local feature tracking. The second main module is the use of an efficient local geometric filter (LGF), which handles outlier feature correspondences based on a new forward-backward pairwise dissimilarity measure, thereby maintaining pairwise geometric consistency. In the proposed LGF module, a hierarchical agglomerative clustering, i.e., bottom-up aggregation, is applied using an effective single-link method. The third proposed module is a heuristic local outlier factor (to the best of our knowledge, it is utilized for the first time to deal with outlier features in a visual tracking application), which further maximizes the representation of the target object in which we formulate outlier feature detection as a binary classification problem with the output features of the LGF module. Extensive UAV flight experiments show that the proposed visual tracker achieves real-time frame rates of more than thirty-five frames per second on an i7 processor with 640 × 512 image resolution and outperforms the most popular state-of-the-art trackers favorably in terms of robustness, efficiency and accuracy.
KW  - unmanned aerial vehicle
KW  - visual object tracking
KW  - reliable global-local model
KW  - local geometric filter
KW  - local outlier factor
KW  - robust real-time performance
DO  - 10.3390/s16091406
ER  -
TY  - EJOU
AU  - Abdulridha, Jaafar
AU  - Ehsani, Reza
AU  - De Castro, Ana
TI  - Detection and Differentiation between Laurel Wilt Disease, Phytophthora Disease, and Salinity Damage Using a Hyperspectral Sensing Technique
T2  - Agriculture

PY  - 2016
VL  - 6
IS  - 4
SN  - 2077-0472

AB  - Laurel wilt (Lw) is a fatal disease. It is a vascular pathogen and is considered a major threat to the avocado industry in Florida. Many of the symptoms of Lw resemble those that are caused by other diseases or stress factors. In this study, the best wavelengths with which to discriminate plants affected by Lw from stress factors were determined and classified. Visible-near infrared (400–950 nm) spectral data from healthy trees and those with Lw, Phytophthora, or salinity damage were collected using a handheld spectroradiometer. The total number of wavelengths was averaged in two ranges: 10 nm and 40 nm. Three classification methods, stepwise discriminant (STEPDISC) analysis, multilayer perceptron (MLP), and radial basis function (RBF), were applied in the early stage of Lw infestation. The classification results obtained for MLP, with percent accuracy of classification as high as 98% were better than STEPDISC and RBF. The MLP neural network selected certain wavelengths that were crucial for correctly classifying healthy trees from those with stress trees. The results showed that there were sufficient spectral differences between laurel wilt, healthy trees, and trees that have other diseases; therefore, a remote sensing technique could diagnose Lw in the early stage of infestation.
KW  - Laurel wilt
KW  - spectroradiometer
KW  - hyperspectral classification
KW  - remote sensing
KW  - multilayer perceptron
DO  - 10.3390/agriculture6040056
ER  -
TY  - EJOU
AU  - Perea-Moreno, Alberto-Jesús
AU  - Aguilera-Ureña, María-Jesús
AU  - Meroño-De Larriva, José-Emilio
AU  - Manzano-Agugliaro, Francisco
TI  - Assessment of the Potential of UAV Video Image Analysis for Planning Irrigation Needs of Golf Courses
T2  - Water

PY  - 2016
VL  - 8
IS  - 12
SN  - 2073-4441

AB  - Golf courses can be considered as precision agriculture, as being a playing surface, their appearance is of vital importance. Areas with good weather tend to have low rainfall. Therefore, the water management of golf courses in these climates is a crucial issue due to the high water demand of turfgrass. Golf courses are rapidly transitioning to reuse water, e.g., the municipalities in the USA are providing price incentives or mandate the use of reuse water for irrigation purposes; in Europe this is mandatory. So, knowing the turfgrass surfaces of a large area can help plan the treated sewage effluent needs. Recycled water is usually of poor quality, thus it is crucial to check the real turfgrass surface in order to be able to plan the global irrigation needs using this type of water. In this way, the irrigation of golf courses does not detract from the natural water resources of the area. The aim of this paper is to propose a new methodology for analysing geometric patterns of video data acquired from UAVs (Unmanned Aerial Vehicle) using a new Hierarchical Temporal Memory (HTM) algorithm. A case study concerning maintained turfgrass, especially for golf courses, has been developed. It shows very good results, better than 98% in the confusion matrix. The results obtained in this study represent a first step toward video imagery classification. In summary, technical progress in computing power and software has shown that video imagery is one of the most promising environmental data acquisition techniques available today. This rapid classification of turfgrass can play an important role for planning water management.
KW  - water management
KW  - golf course
KW  - memory-prediction theory
KW  - object-based classification
KW  - unmanned aerial vehicle
DO  - 10.3390/w8120584
ER  -
TY  - EJOU
AU  - Ortiz, Alberto
AU  - Bonnin-Pascual, Francisco
AU  - Garcia-Fidalgo, Emilio
AU  - Company-Corcoles, Joan P.
TI  - Vision-Based Corrosion Detection Assisted by a Micro-Aerial Vehicle in a Vessel Inspection Application
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 12
SN  - 1424-8220

AB  - Vessel maintenance requires periodic visual inspection of the hull in order to detect typical defective situations of steel structures such as, among others, coating breakdown and corrosion. These inspections are typically performed by well-trained surveyors at great cost because of the need for providing access means (e.g., scaffolding and/or cherry pickers) that allow the inspector to be at arm’s reach from the structure under inspection. This paper describes a defect detection approach comprising a micro-aerial vehicle which is used to collect images from the surfaces under inspection, particularly focusing on remote areas where the surveyor has no visual access, and a coating breakdown/corrosion detector based on a three-layer feed-forward artificial neural network. As it is discussed in the paper, the success of the inspection process depends not only on the defect detection software but also on a number of assistance functions provided by the control architecture of the aerial platform, whose aim is to improve picture quality. Both aspects of the work are described along the different sections of the paper, as well as the classification performance attained.
KW  - vessel inspection
KW  - defect detection
KW  - unmanned aerial vehicle
KW  - supervised autonomy
KW  - machine learning
KW  - artificial neural network
DO  - 10.3390/s16122118
ER  -
TY  - EJOU
AU  - Du, Shouji
AU  - Zhang, Yunsheng
AU  - Qin, Rongjun
AU  - Yang, Zhihua
AU  - Zou, Zhengrong
AU  - Tang, Yuqi
AU  - Fan, Chong
TI  - Building Change Detection Using Old Aerial Images and New LiDAR Data
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 12
SN  - 2072-4292

AB  - Building change detection is important for urban area monitoring, disaster assessment and updating geo-database. 3D information derived from image dense matching or airborne light detection and ranging (LiDAR) is very effective for building change detection. However, combining 3D data from different sources is challenging, and so far few studies have focused on building change detection using both images and LiDAR data. This study proposes an automatic method to detect building changes in urban areas using aerial images and LiDAR data. First, dense image matching is carried out to obtain dense point clouds and then co-registered LiDAR point clouds using the iterative closest point (ICP) algorithm. The registered point clouds are further resampled to a raster DSM (Digital Surface Models). In a second step, height difference and grey-scale similarity are calculated as change indicators and the graph cuts method is employed to determine changes considering the contexture information. Finally, the detected results are refined by removing the non-building changes, in which a novel method based on variance of normal direction of LiDAR points is proposed to remove vegetated areas for positive building changes (newly building or taller) and nEGI (normalized Excessive Green Index) is used for negative building changes (demolish building or lower). To evaluate the proposed method, a test area covering approximately 2.1 km2 and consisting of many different types of buildings is used for the experiment. Results indicate 93% completeness with correctness of 90.2% for positive changes, while 94% completeness with correctness of 94.1% for negative changes, which demonstrate the promising performance of the proposed method.
KW  - building change detection
KW  - aerial images
KW  - LiDAR
KW  - dense matching
KW  - graph cuts
DO  - 10.3390/rs8121030
ER  -
TY  - EJOU
AU  - Ye, Fengchao
AU  - Sheng, Shouzhao
TI  - A Soft Sensor Development for the Rotational Speed Measurement of an Electric Propeller
T2  - Electronics

PY  - 2016
VL  - 5
IS  - 4
SN  - 2079-9292

AB  - In recent decades, micro air vehicles driven by electric propellers have become a hot topic, and developed quickly. The performance of the vehicles depends on the rotational speed of propellers, thus, improving the accuracy of rotational speed measurement is beneficial to the vehicle’s performance. This paper presents the development of a soft sensor for the rotational speed measurement of an electric propeller. An adaptive learning algorithm is derived for the soft sensor by using Popov hyperstability theory, based on which a one-step-delay adaptive learning algorithm is further proposed to solve the implementation problem of the soft sensor. It is important to note that only the input signal and the commutation instant of the motor are employed as inputs in the algorithm, which makes it possible to be easily implemented in real-time. The experimental test results have demonstrated the learning performance and the accuracy of the soft sensor.
KW  - soft sensor
KW  - rotational speed measurement
KW  - adaptive learning
KW  - electric propeller
KW  - micro air vehicle
DO  - 10.3390/electronics5040094
ER  -
TY  - EJOU
AU  - Cao, Chen
AU  - Xu, Peihua
AU  - Chen, Jianping
AU  - Zheng, Lianjing
AU  - Niu, Cencen
TI  - Hazard Assessment of Debris-Flow along the Baicha River in Heshigten Banner, Inner Mongolia, China
T2  - International Journal of Environmental Research and Public Health

PY  - 2017
VL  - 14
IS  - 1
SN  - 1660-4601

AB  - This study focused on a cloud model approach for considering debris-flow hazard assessment, in which the cloud model provided a model for transforming the qualitative and quantitative expressions. Additionally, the entropy method and analytical hierarchy process were united for calculating the parameters weights. The weighting method avoids the disadvantages inherent in using subjective or objective methods alone. Based on the cloud model and component weighting method, a model was established for the analysis of debris-flow hazard assessment. There are 29 debris-flow catchments around the pumped storage power station in the study area located near Zhirui (Inner Mongolia, China). Field survey data and 3S technologies were used for data collection. The results of the cloud model calculation process showed that of the 29 catchments, 25 had low debris-flow hazard assessment, three had moderate hazard assessment, and one had high hazard assessment. The widely used extenics method and field geological surveys were used to validate the proposed approach. This approach shows high potential as a useful tool for debris-flow hazard assessment analysis. Compared with other prediction methods, it avoids the randomness and fuzziness in uncertainty problems, and its prediction results are considered reasonable.
KW  - 3S technologies
KW  - cloud model
KW  - analytical hierarchy process
KW  - entropy method
DO  - 10.3390/ijerph14010030
ER  -
TY  - EJOU
AU  - Li, Weijia
AU  - Fu, Haohuan
AU  - Yu, Le
AU  - Cracknell, Arthur
TI  - Deep Learning Based Oil Palm Tree Detection and Counting for High-Resolution Remote Sensing Images
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 1
SN  - 2072-4292

AB  - Oil palm trees are important economic crops in Malaysia and other tropical areas. The number of oil palm trees in a plantation area is important information for predicting the yield of palm oil, monitoring the growing situation of palm trees and maximizing their productivity, etc. In this paper, we propose a deep learning based framework for oil palm tree detection and counting using high-resolution remote sensing images for Malaysia. Unlike previous palm tree detection studies, the trees in our study area are more crowded and their crowns often overlap. We use a number of manually interpreted samples to train and optimize the convolutional neural network (CNN), and predict labels for all the samples in an image dataset collected through the sliding window technique. Then, we merge the predicted palm coordinates corresponding to the same palm tree into one palm coordinate and obtain the final palm tree detection results. Based on our proposed method, more than 96% of the oil palm trees in our study area can be detected correctly when compared with the manually interpreted ground truth, and this is higher than the accuracies of the other three tree detection methods used in this study.
KW  - oil palm trees
KW  - deep learning
KW  - convolutional neural network (CNN)
KW  - object detection
DO  - 10.3390/rs9010022
ER  -
TY  - EJOU
AU  - Xia, Haoming
AU  - Zhao, Wei
AU  - Li, Ainong
AU  - Bian, Jinhu
AU  - Zhang, Zhengjian
TI  - Subpixel Inundation Mapping Using Landsat-8 OLI and UAV Data for a Wetland Region on the Zoige Plateau, China
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 1
SN  - 2072-4292

AB  - Wetland inundation is crucial to the survival and prosperity of fauna and flora communities in wetland ecosystems. Even small changes in surface inundation may result in a substantial impact on the wetland ecosystem characteristics and function. This study presented a novel method for wetland inundation mapping at a subpixel scale in a typical wetland region on the Zoige Plateau, northeast Tibetan Plateau, China, by combining use of an unmanned aerial vehicle (UAV) and Landsat-8 Operational Land Imager (OLI) data. A reference subpixel inundation percentage (SIP) map at a Landsat-8 OLI 30 m pixel scale was first generated using high resolution UAV data (0.16 m). The reference SIP map and Landsat-8 OLI imagery were then used to develop SIP estimation models using three different retrieval methods (Linear spectral unmixing (LSU), Artificial neural networks (ANN), and Regression tree (RT)). Based on observations from 2014, the estimation results indicated that the estimation model developed with RT method could provide the best fitting results for the mapping wetland SIP (R2 = 0.933, RMSE = 8.73%) compared to the other two methods. The proposed model with RT method was validated with observations from 2013, and the estimated SIP was highly correlated with the reference SIP, with an R2 of 0.986 and an RMSE of 9.84%. This study highlighted the value of high resolution UAV data and globally and freely available Landsat data in combination with the developed approach for monitoring finely gradual inundation change patterns in wetland ecosystems.
KW  - wetland
KW  - subpixel inundation percentage (SIP)
KW  - Landsat-8
KW  - unmanned aerial vehicle (UAV)
KW  - linear spectral unmixing (LSU)
KW  - regression tree (RT)
KW  - artificial neural networks (ANN)
KW  - Zoige Plateau
DO  - 10.3390/rs9010031
ER  -
TY  - EJOU
AU  - Ali, Zain A.
AU  - Wang, Daobo
AU  - Aamir, Muhammad
AU  - Masroor, Suhaib
TI  - Trajectory Tracking of a Tri-Rotor Aerial Vehicle Using an MRAC-Based Robust Hybrid Control Algorithm
T2  - Aerospace

PY  - 2017
VL  - 4
IS  - 1
SN  - 2226-4310

AB  - In this paper, a novel Model Reference Adaptive Control (MRAC)-based hybrid control algorithm is presented for the trajectory tracking of a tri-rotor Unmanned Aerial Vehicle (UAV). The mathematical model of the tri-rotor is based on the Newton–Euler formula, whereas the MRAC-based hybrid controller consists of Fuzzy Proportional Integral Derivative (F-PID) and Fuzzy Proportional Derivative (F-PD) controllers. MRAC is used as the main controller for the dynamics, while the parameters of the adaptive controller are fine-tuned by the F-PD controller for the altitude control subsystem and the F-PID controller for the attitude control subsystem of the UAV. The stability of the system is ensured and proven by Lyapunov stability analysis. The proposed control algorithm is tested and verified using computer simulations for the trajectory tracking of the desired path as an input. The effectiveness of our proposed algorithm is compared with F-PID and the Fuzzy Logic Controller (FLC). Our proposed controller exhibits much less steady state error, quick error convergence in the presence of disturbance or noise, and model uncertainties.
KW  - Model Reference Adaptive Control
KW  - Fuzzy Logic Controller (FLC)
KW  - trajectory tracking
KW  - tri-rotor UAV
DO  - 10.3390/aerospace4010003
ER  -
TY  - EJOU
AU  - Bejiga, Mesay B.
AU  - Zeggada, Abdallah
AU  - Nouffidj, Abdelhamid
AU  - Melgani, Farid
TI  - A Convolutional Neural Network Approach for Assisting Avalanche Search and Rescue Operations with UAV Imagery
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 2
SN  - 2072-4292

AB  - Following an avalanche, one of the factors that affect victims’ chance of survival is the speed with which they are located and dug out. Rescue teams use techniques like trained rescue dogs and electronic transceivers to locate victims. However, the resources and time required to deploy rescue teams are major bottlenecks that decrease a victim’s chance of survival. Advances in the field of Unmanned Aerial Vehicles (UAVs) have enabled the use of flying robots equipped with sensors like optical cameras to assess the damage caused by natural or manmade disasters and locate victims in the debris. In this paper, we propose assisting avalanche search and rescue (SAR) operations with UAVs fitted with vision cameras. The sequence of images of the avalanche debris captured by the UAV is processed with a pre-trained Convolutional Neural Network (CNN) to extract discriminative features. A trained linear Support Vector Machine (SVM) is integrated at the top of the CNN to detect objects of interest. Moreover, we introduce a pre-processing method to increase the detection rate and a post-processing method based on a Hidden Markov Model to improve the prediction performance of the classifier. Experimental results conducted on two different datasets at different levels of resolution show that the detection performance increases with an increase in resolution, while the computation time increases. Additionally, they also suggest that a significant decrease in processing time can be achieved thanks to the pre-processing step.
KW  - avalanche
KW  - convolutional neural network (CNN)
KW  - deep learning
KW  - hidden Markov model (HMM)
KW  - object detection
KW  - search and rescue operation
KW  - support vector machine (SVM)
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/rs9020100
ER  -
TY  - EJOU
AU  - Lausch, Angela
AU  - Erasmi, Stefan
AU  - King, Douglas J.
AU  - Magdon, Paul
AU  - Heurich, Marco
TI  - Understanding Forest Health with Remote Sensing-Part II—A Review of Approaches and Data Models
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 2
SN  - 2072-4292

AB  - Stress in forest ecosystems (FES) occurs as a result of land-use intensification, disturbances, resource limitations or unsustainable management, causing changes in forest health (FH) at various scales from the local to the global scale. Reactions to such stress depend on the phylogeny of forest species or communities and the characteristics of their impacting drivers and processes. There are many approaches to monitor indicators of FH using in-situ forest inventory and experimental studies, but they are generally limited to sample points or small areas, as well as being time- and labour-intensive. Long-term monitoring based on forest inventories provides valuable information about changes and trends of FH. However, abrupt short-term changes cannot sufficiently be assessed through in-situ forest inventories as they usually have repetition periods of multiple years. Furthermore, numerous FH indicators monitored in in-situ surveys are based on expert judgement. Remote sensing (RS) technologies offer means to monitor FH indicators in an effective, repetitive and comparative way. This paper reviews techniques that are currently used for monitoring, including close-range RS, airborne and satellite approaches. The implementation of optical, RADAR and LiDAR RS-techniques to assess spectral traits/spectral trait variations (ST/STV) is described in detail. We found that ST/STV can be used to record indicators of FH based on RS. Therefore, the ST/STV approach provides a framework to develop a standardized monitoring concept for FH indicators using RS techniques that is applicable to future monitoring programs. It is only through linking in-situ and RS approaches that we will be able to improve our understanding of the relationship between stressors, and the associated spectral responses in order to develop robust FH indicators.
KW  - spectral traits (ST)
KW  - spectral trait variations (STV)
KW  - in-situ
KW  - remote sensing (RS) approaches
KW  - plant phenomics facilities
KW  - wireless sensor networks (WSN)
KW  - RADAR
KW  - optical
KW  - LiDAR
KW  - RS models
DO  - 10.3390/rs9020129
ER  -
TY  - EJOU
AU  - Tang, Tianyu
AU  - Zhou, Shilin
AU  - Deng, Zhipeng
AU  - Zou, Huanxin
AU  - Lei, Lin
TI  - Vehicle Detection in Aerial Images Based on Region Convolutional Neural Networks and Hard Negative Example Mining
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 2
SN  - 1424-8220

AB  - Detecting vehicles in aerial imagery plays an important role in a wide range of applications. The current vehicle detection methods are mostly based on sliding-window search and handcrafted or shallow-learning-based features, having limited description capability and heavy computational costs. Recently, due to the powerful feature representations, region convolutional neural networks (CNN) based detection methods have achieved state-of-the-art performance in computer vision, especially Faster R-CNN. However, directly using it for vehicle detection in aerial images has many limitations: (1) region proposal network (RPN) in Faster R-CNN has poor performance for accurately locating small-sized vehicles, due to the relatively coarse feature maps; and (2) the classifier after RPN cannot distinguish vehicles and complex backgrounds well. In this study, an improved detection method based on Faster R-CNN is proposed in order to accomplish the two challenges mentioned above. Firstly, to improve the recall, we employ a hyper region proposal network (HRPN) to extract vehicle-like targets with a combination of hierarchical feature maps. Then, we replace the classifier after RPN by a cascade of boosted classifiers to verify the candidate regions, aiming at reducing false detection by negative example mining. We evaluate our method on the Munich vehicle dataset and the collected vehicle dataset, with improvements in accuracy and robustness compared to existing methods.
KW  - vehicle detection
KW  - hyper region proposal network
KW  - convolutional neural networks
KW  - hard negative example mining
DO  - 10.3390/s17020336
ER  -
TY  - EJOU
AU  - Alvarado, Miguel
AU  - Gonzalez, Felipe
AU  - Erskine, Peter
AU  - Cliff, David
AU  - Heuff, Darlene
TI  - A Methodology to Monitor Airborne PM10 Dust Particles Using a Small Unmanned Aerial Vehicle
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 2
SN  - 1424-8220

AB  - Throughout the process of coal extraction from surface mines, gases and particles are emitted in the form of fugitive emissions by activities such as hauling, blasting and transportation. As these emissions are diffuse in nature, estimations based upon emission factors and dispersion/advection equations need to be measured directly from the atmosphere. This paper expands upon previous research undertaken to develop a relative methodology to monitor PM10 dust particles produced by mining activities making use of small unmanned aerial vehicles (UAVs). A module sensor using a laser particle counter (OPC-N2 from Alphasense, Great Notley, Essex, UK) was tested. An aerodynamic flow experiment was undertaken to determine the position and length of a sampling probe of the sensing module. Flight tests were conducted in order to demonstrate that the sensor provided data which could be used to calculate the emission rate of a source. Emission rates are a critical variable for further predictive dispersion estimates. First, data collected by the airborne module was verified using a 5.0 m tower in which a TSI DRX 8533 (reference dust monitoring device, TSI, Shoreview, MN, USA) and a duplicate of the module sensor were installed. Second, concentration values collected by the monitoring module attached to the UAV (airborne module) obtaining a percentage error of 1.1%. Finally, emission rates from the source were calculated, with airborne data, obtaining errors as low as 1.2%. These errors are low and indicate that the readings collected with the airborne module are comparable to the TSI DRX and could be used to obtain specific emission factors from fugitive emissions for industrial activities.
KW  - PM10
KW  - monitoring
KW  - blasting
KW  - unmanned aerial vehicle (UAV)
KW  - multi-rotor UAV
KW  - optical sensor
DO  - 10.3390/s17020343
ER  -
TY  - EJOU
AU  - Popescu, Dan
AU  - Ichim, Loretta
AU  - Stoican, Florin
TI  - Unmanned Aerial Vehicle Systems for Remote Estimation of Flooded Areas Based on Complex Image Processing
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 3
SN  - 1424-8220

AB  - Floods are natural disasters which cause the most economic damage at the global level. Therefore, flood monitoring and damage estimation are very important for the population, authorities and insurance companies. The paper proposes an original solution, based on a hybrid network and complex image processing, to this problem. As first novelty, a multilevel system, with two components, terrestrial and aerial, was proposed and designed by the authors as support for image acquisition from a delimited region. The terrestrial component contains a Ground Control Station, as a coordinator at distance, which communicates via the internet with more Ground Data Terminals, as a fixed nodes network for data acquisition and communication. The aerial component contains mobile nodes—fixed wing type UAVs. In order to evaluate flood damage, two tasks must be accomplished by the network: area coverage and image processing. The second novelty of the paper consists of texture analysis in a deep neural network, taking into account new criteria for feature selection and patch classification. Color and spatial information extracted from chromatic co-occurrence matrix and mass fractal dimension were used as well. Finally, the experimental results in a real mission demonstrate the validity of the proposed methodologies and the performances of the algorithms.
KW  - unmanned aerial vehicle
KW  - path planning
KW  - flood detection
KW  - feature selection
KW  - image processing
KW  - image segmentation
KW  - texture analysis
DO  - 10.3390/s17030446
ER  -
TY  - EJOU
AU  - Nevalainen, Olli
AU  - Honkavaara, Eija
AU  - Tuominen, Sakari
AU  - Viljanen, Niko
AU  - Hakala, Teemu
AU  - Yu, Xiaowei
AU  - Hyyppä, Juha
AU  - Saari, Heikki
AU  - Pölönen, Ilkka
AU  - Imai, Nilton N.
AU  - Tommaselli, Antonio M. G.
TI  - Individual Tree Detection and Classification with UAV-Based Photogrammetric Point Clouds and Hyperspectral Imaging
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 3
SN  - 2072-4292

AB  - Small unmanned aerial vehicle (UAV) based remote sensing is a rapidly evolving technology. Novel sensors and methods are entering the market, offering completely new possibilities to carry out remote sensing tasks. Three-dimensional (3D) hyperspectral remote sensing is a novel and powerful technology that has recently become available to small UAVs. This study investigated the performance of UAV-based photogrammetry and hyperspectral imaging in individual tree detection and tree species classification in boreal forests. Eleven test sites with 4151 reference trees representing various tree species and developmental stages were collected in June 2014 using a UAV remote sensing system equipped with a frame format hyperspectral camera and an RGB camera in highly variable weather conditions. Dense point clouds were measured photogrammetrically by automatic image matching using high resolution RGB images with a 5 cm point interval. Spectral features were obtained from the hyperspectral image blocks, the large radiometric variation of which was compensated for by using a novel approach based on radiometric block adjustment with the support of in-flight irradiance observations. Spectral and 3D point cloud features were used in the classification experiment with various classifiers. The best results were obtained with Random Forest and Multilayer Perceptron (MLP) which both gave 95% overall accuracies and an F-score of 0.93. Accuracy of individual tree identification from the photogrammetric point clouds varied between 40% and 95%, depending on the characteristics of the area. Challenges in reference measurements might also have reduced these numbers. Results were promising, indicating that hyperspectral 3D remote sensing was operational from a UAV platform even in very difficult conditions. These novel methods are expected to provide a powerful tool for automating various environmental close-range remote sensing tasks in the very near future.
KW  - UAV
KW  - hyperspectral
KW  - photogrammetry
KW  - radiometry
KW  - point cloud
KW  - forest
KW  - classification
DO  - 10.3390/rs9030185
ER  -
TY  - EJOU
AU  - Adeyemi, Olutobi
AU  - Grove, Ivan
AU  - Peets, Sven
AU  - Norton, Tomas
TI  - Advanced Monitoring and Management Systems for Improving Sustainability in Precision Irrigation
T2  - Sustainability

PY  - 2017
VL  - 9
IS  - 3
SN  - 2071-1050

AB  - Globally, the irrigation of crops is the largest consumptive user of fresh water. Water scarcity is increasing worldwide, resulting in tighter regulation of its use for agriculture. This necessitates the development of irrigation practices that are more efficient in the use of water but do not compromise crop quality and yield. Precision irrigation already achieves this goal, in part. The goal of precision irrigation is to accurately supply the crop water need in a timely manner and as spatially uniformly as possible. However, to maximize the benefits of precision irrigation, additional technologies need to be enabled and incorporated into agriculture. This paper discusses how incorporating adaptive decision support systems into precision irrigation management will enable significant advances in increasing the efficiency of current irrigation approaches. From the literature review, it is found that precision irrigation can be applied in achieving the environmental goals related to sustainability. The demonstrated economic benefits of precision irrigation in field-scale crop production is however minimal. It is argued that a proper combination of soil, plant and weather sensors providing real-time data to an adaptive decision support system provides an innovative platform for improving sustainability in irrigated agriculture. The review also shows that adaptive decision support systems based on model predictive control are able to adequately account for the time-varying nature of the soil–plant–atmosphere system while considering operational limitations and agronomic objectives in arriving at optimal irrigation decisions. It is concluded that significant improvements in crop yield and water savings can be achieved by incorporating model predictive control into precision irrigation decision support tools. Further improvements in water savings can also be realized by including deficit irrigation as part of the overall irrigation management strategy. Nevertheless, future research is needed for identifying crop response to regulated water deficits, developing improved soil moisture and plant sensors, and developing self-learning crop simulation frameworks that can be applied to evaluate adaptive decision support strategies related to irrigation.
KW  - precision irrigation
KW  - adaptive decision support systems
KW  - model predictive control
KW  - crop yield
KW  - water savings
KW  - sustainability
DO  - 10.3390/su9030353
ER  -
TY  - EJOU
AU  - Cui, Huanqing
AU  - Shu, Minglei
AU  - Song, Min
AU  - Wang, Yinglong
TI  - Parameter Selection and Performance Comparison of Particle Swarm Optimization in Sensor Networks Localization
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 3
SN  - 1424-8220

AB  - Localization is a key technology in wireless sensor networks. Faced with the challenges of the sensors’ memory, computational constraints, and limited energy, particle swarm optimization has been widely applied in the localization of wireless sensor networks, demonstrating better performance than other optimization methods. In particle swarm optimization-based localization algorithms, the variants and parameters should be chosen elaborately to achieve the best performance. However, there is a lack of guidance on how to choose these variants and parameters. Further, there is no comprehensive performance comparison among particle swarm optimization algorithms. The main contribution of this paper is three-fold. First, it surveys the popular particle swarm optimization variants and particle swarm optimization-based localization algorithms for wireless sensor networks. Secondly, it presents parameter selection of nine particle swarm optimization variants and six types of swarm topologies by extensive simulations. Thirdly, it comprehensively compares the performance of these algorithms. The results show that the particle swarm optimization with constriction coefficient using ring topology outperforms other variants and swarm topologies, and it performs better than the second-order cone programming algorithm.
KW  - wireless sensor networks
KW  - particle swarm optimization
KW  - localization
KW  - parameter selection
KW  - performance comparison
DO  - 10.3390/s17030487
ER  -
TY  - EJOU
AU  - Campos-Taberner, Manuel
AU  - García-Haro, Francisco J.
AU  - Camps-Valls, Gustau
AU  - Grau-Muedra, Gonçal
AU  - Nutini, Francesco
AU  - Busetto, Lorenzo
AU  - Katsantonis, Dimitrios
AU  - Stavrakoudis, Dimitris
AU  - Minakou, Chara
AU  - Gatti, Luca
AU  - Barbieri, Massimo
AU  - Holecz, Francesco
AU  - Stroppiana, Daniela
AU  - Boschetti, Mirco
TI  - Exploitation of SAR and Optical Sentinel Data to Detect Rice Crop and Estimate Seasonal Dynamics of Leaf Area Index
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 3
SN  - 2072-4292

AB  - This paper presents and evaluates multitemporal LAI estimates derived from Sentinel-2A data on rice cultivated area identified using time series of Sentinel-1A images over the main European rice districts for the 2016 crop season. This study combines the information conveyed by Sentinel-1A and Sentinel-2A into a high-resolution LAI retrieval chain. Rice crop was detected using an operational multi-temporal rule-based algorithm, and LAI estimates were obtained by inverting the PROSAIL radiative transfer model with Gaussian process regression. Direct validation was performed with in situ LAI measurements acquired in coordinated field campaigns in three countries (Italy, Spain and Greece). Results showed high consistency between estimates and ground measurements, revealing high correlations (R2 &gt; 0.93) and good accuracies (RMSE &lt; 0.83, rRMSEm &lt; 23.6% and rRMSEr &lt; 16.6%) in all cases. Sentinel-2A estimates were compared with Landsat-8 showing high spatial consistency between estimates over the three areas. The possibility to exploit seasonally-updated crop mask exploiting Sentinel-1A data and the temporal consistency between Sentinel-2A and Landsat-7/8 LAI time series demonstrates the feasibility of deriving operationally high spatial-temporal decametric multi-sensor LAI time series useful for crop monitoring.
KW  - rice map
KW  - leaf area index (LAI)
KW  - Sentinel-1A
KW  - Sentinel-2A
KW  - Gaussian process regression
DO  - 10.3390/rs9030248
ER  -
TY  - EJOU
AU  - Song, Dongmei
AU  - Zhang, Yajie
AU  - Shan, Xinjian
AU  - Cui, Jianyong
AU  - Wu, Huisheng
TI  - “Over-Learning” Phenomenon of Wavelet Neural Networks in Remote Sensing Image Classifications with Different Entropy Error Functions
T2  - Entropy

PY  - 2017
VL  - 19
IS  - 3
SN  - 1099-4300

AB  - Artificial neural networks are widely applied for prediction, function simulation, and data classification. Among these applications, the wavelet neural network is widely used in image classification problems due to its advantages of high approximation capabilities, fault-tolerant capabilities, learning capacity, its ability to effectively overcome local minimization issues, and so on. The error function of a network is critical to determine the convergence, stability, and classification accuracy of a neural network. The selection of the error function directly determines the network’s performance. Different error functions will correspond with different minimum error values in training samples. With the decrease of network errors, the accuracy of the image classification is increased. However, if the image classification accuracy is difficult to improve upon, or is even decreased with the decreasing of the errors, then this indicates that the network has an “over-learning” phenomenon, which is closely related to the selection of the function errors. With regards to remote sensing data, it has not yet been reported whether there have been studies conducted regarding the “over-learning” phenomenon, as well as the relationship between the “over-learning” phenomenon and error functions. This study takes SAR, hyper-spectral, high-resolution, and multi-spectral images as data sources, in order to comprehensively and systematically analyze the possibility of an “over-learning” phenomenon in the remote sensing images from the aspects of image characteristics and neural network. Then, this study discusses the impact of three typical entropy error functions (NB, CE, and SH) on the “over-learning” phenomenon of a network. The experimental results show that the “over-learning” phenomenon may be caused only when there is a strong separability between the ground features, a low image complexity, a small image size, and a large number of hidden nodes. The SH entropy error function in that case will show a good “over-learning” resistance ability. However, for remote sensing image classification, the “over-learning” phenomenon will not be easily caused in most cases, due to the complexity of the image itself, and the diversity of the ground features. In that case, the NB and CE entropy error network mainly show a good stability. Therefore, a blind selection of a SH entropy error function with a high “over-learning” resistance ability from the wavelet neural network classification of the remote sensing image will only decrease the classification accuracy of the remote sensing image. It is therefore recommended to use an NB or CE entropy error function with a stable learning effect.
KW  - wavelet neural network
KW  - remote sensing image classification
KW  - over-learning
KW  - entropy error function
DO  - 10.3390/e19030101
ER  -
TY  - EJOU
AU  - Poblete-Echeverría, Carlos
AU  - Olmedo, Guillermo F.
AU  - Ingram, Ben
AU  - Bardeen, Matthew
TI  - Detection and Segmentation of Vine Canopy in Ultra-High Spatial Resolution RGB Imagery Obtained from Unmanned Aerial Vehicle (UAV): A Case Study in a Commercial Vineyard
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 3
SN  - 2072-4292

AB  - The use of Unmanned Aerial Vehicles (UAVs) in viticulture permits the capture of aerial Red-Green-Blue (RGB) images with an ultra-high spatial resolution. Recent studies have demonstrated that RGB images can be used to monitor spatial variability of vine biophysical parameters. However, for estimating these parameters, accurate and automated segmentation methods are required to extract relevant information from RGB images. Manual segmentation of aerial images is a laborious and time-consuming process. Traditional classification methods have shown satisfactory results in the segmentation of RGB images for diverse applications and surfaces, however, in the case of commercial vineyards, it is necessary to consider some particularities inherent to canopy size in the vertical trellis systems (VSP) such as shadow effect and different soil conditions in inter-rows (mixed information of soil and weeds). Therefore, the objective of this study was to compare the performance of four classification methods (K-means, Artificial Neural Networks (ANN), Random Forest (RForest) and Spectral Indices (SI)) to detect canopy in a vineyard trained on VSP. Six flights were carried out from post-flowering to harvest in a commercial vineyard cv. Carménère using a low-cost UAV equipped with a conventional RGB camera. The results show that the ANN and the simple SI method complemented with the Otsu method for thresholding presented the best performance for the detection of the vine canopy with high overall accuracy values for all study days. Spectral indices presented the best performance in the detection of Plant class (Vine canopy) with an overall accuracy of around 0.99. However, considering the performance pixel by pixel, the Spectral indices are not able to discriminate between Soil and Shadow class. The best performance in the classification of three classes (Plant, Soil, and Shadow) of vineyard RGB images, was obtained when the SI values were used as input data in trained methods (ANN and RForest), reaching overall accuracy values around 0.98 with high sensitivity values for the three classes.
KW  - precision viticulture
KW  - remote sensing
KW  - spatial variability
KW  - image analysis
KW  - random forest
KW  - artificial neural network
KW  - classification, Otsu method
DO  - 10.3390/rs9030268
ER  -
TY  - EJOU
AU  - Du, Mengmeng
AU  - Noguchi, Noboru
TI  - Monitoring of Wheat Growth Status and Mapping of Wheat Yield’s within-Field Spatial Variations Using Color Images Acquired from UAV-camera System
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 3
SN  - 2072-4292

AB  - Applications of remote sensing using unmanned aerial vehicle (UAV) in agriculture has proved to be an effective and efficient way of obtaining field information. In this study, we validated the feasibility of utilizing multi-temporal color images acquired from a low altitude UAV-camera system to monitor real-time wheat growth status and to map within-field spatial variations of wheat yield for smallholder wheat growers, which could serve as references for site-specific operations. Firstly, eight orthomosaic images covering a small winter wheat field were generated to monitor wheat growth status from heading stage to ripening stage in Hokkaido, Japan. Multi-temporal orthomosaic images indicated straightforward sense of canopy color changes and spatial variations of tiller densities. Besides, the last two orthomosaic images taken from about two weeks prior to harvesting also notified the occurrence of lodging by visual inspection, which could be used to generate navigation maps guiding drivers or autonomous harvesting vehicles to adjust operation speed according to specific lodging situations for less harvesting loss. Subsequently orthomosaic images were geo-referenced so that further study on stepwise regression analysis among nine wheat yield samples and five color vegetation indices (CVI) could be conducted, which showed that wheat yield correlated with four accumulative CVIs of visible-band difference vegetation index (VDVI), normalized green-blue difference index (NGBDI), green-red ratio index (GRRI), and excess green vegetation index (ExG), with the coefficient of determination and RMSE as 0.94 and 0.02, respectively. The average value of sampled wheat yield was 8.6 t/ha. The regression model was also validated by using leave-one-out cross validation (LOOCV) method, of which root-mean-square error of predication (RMSEP) was 0.06. Finally, based on the stepwise regression model, a map of estimated wheat yield was generated, so that within-field spatial variations of wheat yield, which was usually seen as general information on soil fertility, water potential, tiller density, etc., could be better understood for applications of site-specific or variable-rate operations. Average yield of the studied field was also calculated according to the map of wheat yield as 7.2 t/ha.
KW  - agriculture remote sensing
KW  - unmanned aerial vehicle (UAV)
KW  - precision agriculture
KW  - winter wheat
KW  - color vegetation index
KW  - wheat yield
KW  - image processing
DO  - 10.3390/rs9030289
ER  -
TY  - EJOU
AU  - Yuan, Huanhuan
AU  - Yang, Guijun
AU  - Li, Changchun
AU  - Wang, Yanjie
AU  - Liu, Jiangang
AU  - Yu, Haiyang
AU  - Feng, Haikuan
AU  - Xu, Bo
AU  - Zhao, Xiaoqing
AU  - Yang, Xiaodong
TI  - Retrieving Soybean Leaf Area Index from Unmanned Aerial Vehicle Hyperspectral Remote Sensing: Analysis of RF, ANN, and SVM Regression Models
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 4
SN  - 2072-4292

AB  - Leaf area index (LAI) is an important indicator of plant growth and yield that can be monitored by remote sensing. Several models were constructed using datasets derived from SRS and STR sampling methods to determine the optimal model for soybean (multiple strains) LAI inversion for the whole crop growth period and a single growth period. Random forest (RF), artificial neural network (ANN), and support vector machine (SVM) regression models were compared with a partial least-squares regression (PLS) model. The RF model yielded the highest precision, accuracy, and stability with V-R2, SDR2, V-RMSE, and SDRMSE values of 0.741, 0.031, 0.106, and 0.005, respectively, over the whole growth period based on STR sampling. The ANN model had the highest precision, accuracy, and stability (0.452, 0.132, 0.086, and 0.009, respectively) over a single growth phase based on STR sampling. The precision, accuracy, and stability of the RF, ANN, and SVM models were improved by inclusion of STR sampling. The RF model is suitable for estimating LAI when sample plots and variation are relatively large (i.e., the whole growth period or more than one growth period). The ANN model is more appropriate for estimating LAI when sample plots and variation are relatively low (i.e., a single growth period).
KW  - LAI retrieval
KW  - hyperspectral remote sensing
KW  - sampling method
KW  - random forests
KW  - artificial neural networks
KW  - support vector machine
DO  - 10.3390/rs9040309
ER  -
TY  - EJOU
AU  - Ammour, Nassim
AU  - Alhichri, Haikel
AU  - Bazi, Yakoub
AU  - Benjdira, Bilel
AU  - Alajlan, Naif
AU  - Zuair, Mansour
TI  - Deep Learning Approach for Car Detection in UAV Imagery
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 4
SN  - 2072-4292

AB  - This paper presents an automatic solution to the problem of detecting and counting cars in unmanned aerial vehicle (UAV) images. This is a challenging task given the very high spatial resolution of UAV images (on the order of a few centimetres) and the extremely high level of detail, which require suitable automatic analysis methods. Our proposed method begins by segmenting the input image into small homogeneous regions, which can be used as candidate locations for car detection. Next, a window is extracted around each region, and deep learning is used to mine highly descriptive features from these windows. We use a deep convolutional neural network (CNN) system that is already pre-trained on huge auxiliary data as a feature extraction tool, combined with a linear support vector machine (SVM) classifier to classify regions into “car” and “no-car” classes. The final step is devoted to a fine-tuning procedure which performs morphological dilation to smooth the detected regions and fill any holes. In addition, small isolated regions are analysed further using a few sliding rectangular windows to locate cars more accurately and remove false positives. To evaluate our method, experiments were conducted on a challenging set of real UAV images acquired over an urban area. The experimental results have proven that the proposed method outperforms the state-of-the-art methods, both in terms of accuracy and computational time.
KW  - UAV imagery
KW  - car counting
KW  - deep learning
KW  - convolutional neural networks (CNNs)
KW  - support vector machines (SVM)
KW  - mean-shift segmentation
DO  - 10.3390/rs9040312
ER  -
TY  - EJOU
AU  - Martin, R. A.
AU  - Blackburn, Landen
AU  - Pulsipher, Joshua
AU  - Franke, Kevin
AU  - Hedengren, John D.
TI  - Potential Benefits of Combining Anomaly Detection with View Planning for UAV Infrastructure Modeling
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 5
SN  - 2072-4292

AB  - This paper presents a novel method for UAV-based 3D modeling of large infrastructure objects, such as pipelines, canals and levees, that combines anomaly detection with automatic on-board 3D view planning. The study begins by assuming that anomaly detections are possible and focuses on quantifying the potential benefits of the combined method and the view planning algorithm. A simulated canal environment is constructed, and several simulated anomalies are created and marked. The algorithm is used to plan inspection flights for the anomaly locations, and simulated images from the flights are rendered and processed to construct 3D models of the locations of interest. The new flights are compared to traditional flights in terms of flight time, data collected and 3D model accuracy. When compared to a low speed, low elevation traditional flight, the proposed method is shown in simulation to decrease total flight time by up to 55%, while reducing the amount of image data to be processed by 89% and maintaining 3D model accuracy at areas of interest.
KW  - UAV
KW  - infrastructure monitoring
KW  - structure-from-motion
KW  - view planning
KW  - intrusion detection
DO  - 10.3390/rs9050434
ER  -
TY  - EJOU
AU  - Rizvi, Syed T.
AU  - Cabodi, Gianpiero
AU  - Patti, Denis
AU  - Gulzar, Muhammad M.
TI  - A General-Purpose Graphics Processing Unit (GPGPU)-Accelerated Robotic Controller Using a Low Power Mobile Platform 
T2  - Journal of Low Power Electronics and Applications

PY  - 2017
VL  - 7
IS  - 2
SN  - 2079-9268

AB  - Robotic controllers have to execute various complex independent tasks repeatedly. Massive processing power is required by the motion controllers to compute the solution of these computationally intensive algorithms. General-purpose graphics processing unit (GPGPU)-enabled mobile phones can be leveraged for acceleration of these motion controllers. Embedded GPUs can replace several dedicated computing boards by a single powerful and less power-consuming GPU. In this paper, the inverse kinematic algorithm based numeric controllers is proposed and realized using the GPGPU of a handheld mobile device. This work is the extension of a desktop GPU-accelerated robotic controller presented at DAS’16 where the comparative analysis of different sequential and concurrent controllers is discussed. First of all, the inverse kinematic algorithm is sequentially realized using Arduino-Due microcontroller and the field-programmable gate array (FPGA) is used for its parallel implementation. Execution speeds of these controllers are compared with two different GPGPU architectures (Nvidia Quadro K2200 and Nvidia Shield K1 Tablet), programmed with Compute Unified Device Architecture (CUDA) computing language. Experimental data shows that the proposed mobile platform-based scheme outperforms the FPGA by 5× and boasts a 100× speedup over the Arduino-based sequential implementation.
KW  - concurrent computing
KW  - manipulators
KW  - mobile computing
KW  - performance analysis
KW  - inverse kinematic
KW  - microcontroller
KW  - field-programmable gate array (FPGA)
KW  - general-purpose graphics processing unit (GPGPU)
DO  - 10.3390/jlpea7020010
ER  -
TY  - EJOU
AU  - Li, Hongguang
AU  - Ding, Wenrui
AU  - Cao, Xianbin
AU  - Liu, Chunlei
TI  - Image Registration and Fusion of Visible and Infrared Integrated Camera for Medium-Altitude Unmanned Aerial Vehicle Remote Sensing
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 5
SN  - 2072-4292

AB  - This study proposes a novel method for image registration and fusion via commonly used visible light and infrared integrated cameras mounted on medium-altitude unmanned aerial vehicles (UAVs).The innovation of image registration lies in three aspects. First, it reveals how complex perspective transformation can be converted to simple scale transformation and translation transformation between two sensor images under long-distance and parallel imaging conditions. Second, with the introduction of metadata, a scale calculation algorithm is designed according to spatial geometry, and a coarse translation estimation algorithm is presented based on coordinate transformation. Third, the problem of non-strictly aligned edges in precise translation estimation is solved via edge–distance field transformation. A searching algorithm based on particle swarm optimization is introduced to improve efficiency. Additionally, a new image fusion algorithm is designed based on a pulse coupled neural network and nonsubsampled contourlet transform to meet the special requirements of preserving color information, adding infrared brightness information, improving spatial resolution, and highlighting target areas for unmanned aerial vehicle (UAV) applications. A medium-altitude UAV is employed to collect datasets. The result is promising, especially in applications that involve other medium-altitude or high-altitude UAVs with similar system structures.
KW  - image registration
KW  - image fusion
KW  - UAV
KW  - metadata
KW  - visible light and infrared integrated camera
DO  - 10.3390/rs9050441
ER  -
TY  - EJOU
AU  - Calera, Alfonso
AU  - Campos, Isidro
AU  - Osann, Anna
AU  - D’Urso, Guido
AU  - Menenti, Massimo
TI  - Remote Sensing for Crop Water Management: From ET Modelling to Services for the End Users
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 5
SN  - 1424-8220

AB  - The experiences gathered during the past 30 years support the operational use of irrigation scheduling based on frequent multi-spectral image data. Currently, the operational use of dense time series of multispectral imagery at high spatial resolution makes monitoring of crop biophysical parameters feasible, capturing crop water use across the growing season, with suitable temporal and spatial resolutions. These achievements, and the availability of accurate forecasting of meteorological data, allow for precise predictions of crop water requirements with unprecedented spatial resolution. This information is greatly appreciated by the end users, i.e., professional farmers or decision-makers, and can be provided in an easy-to-use manner and in near-real-time by using the improvements achieved in web-GIS methodologies (Geographic Information Systems based on web technologies). This paper reviews the most operational and explored methods based on optical remote sensing for the assessment of crop water requirements, identifying strengths and weaknesses and proposing alternatives to advance towards full operational application of this methodology. In addition, we provide a general overview of the tools, which facilitates co-creation and collaboration with stakeholders, paying special attention to these approaches based on web-GIS tools.
KW  - crop water requirements
KW  - irrigation water requirements
KW  - crop coefficient
KW  - web-GIS
KW  - earth observation
KW  - evapotranspiration
DO  - 10.3390/s17051104
ER  -
TY  - EJOU
AU  - Zuo, Yujia
AU  - Liu, Jinghong
AU  - Bai, Guanbing
AU  - Wang, Xuan
AU  - Sun, Mingchao
TI  - Airborne Infrared and Visible Image Fusion Combined with Region Segmentation
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 5
SN  - 1424-8220

AB  - This paper proposes an infrared (IR) and visible image fusion method introducing region segmentation into the dual-tree complex wavelet transform (DTCWT) region. This method should effectively improve both the target indication and scene spectrum features of fusion images, and the target identification and tracking reliability of fusion system, on an airborne photoelectric platform. The method involves segmenting the region in an IR image by significance, and identifying the target region and the background region; then, fusing the low-frequency components in the DTCWT region according to the region segmentation result. For high-frequency components, the region weights need to be assigned by the information richness of region details to conduct fusion based on both weights and adaptive phases, and then introducing a shrinkage function to suppress noise; Finally, the fused low-frequency and high-frequency components are reconstructed to obtain the fusion image. The experimental results show that the proposed method can fully extract complementary information from the source images to obtain a fusion image with good target indication and rich information on scene details. They also give a fusion result superior to existing popular fusion methods, based on eithers subjective or objective evaluation. With good stability and high fusion accuracy, this method can meet the fusion requirements of IR-visible image fusion systems.
KW  - airborne optoelectronic platform
KW  - image fusion
KW  - image segmentation
KW  - saliency extraction
KW  - dual-tree complex wavelet transform (DTCWT)
DO  - 10.3390/s17051127
ER  -
TY  - EJOU
AU  - Wei, Chuanwen
AU  - Huang, Jingfeng
AU  - Mansaray, Lamin R.
AU  - Li, Zhenhai
AU  - Liu, Weiwei
AU  - Han, Jiahui
TI  - Estimation and Mapping of Winter Oilseed Rape LAI from High Spatial Resolution Satellite Data Based on a Hybrid Method
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 5
SN  - 2072-4292

AB  - Leaf area index (LAI) is a key input in models describing biosphere processes and has widely been used in monitoring crop growth and in yield estimation. In this study, a hybrid inversion method is developed to estimate LAI values of winter oilseed rape during growth using high spatial resolution optical satellite data covering a test site located in southeast China. Based on PROSAIL (coupling of PROSPECT and SAIL) simulation datasets, nine vegetation indices (VIs) were analyzed to identify the optimal independent variables for estimating LAI values. The optimal VIs were selected using curve fitting methods and the random forest algorithm. Hybrid inversion models were then built to determine the relationships between optimal simulated VIs and LAI values (generated by the PROSAIL model) using modeling methods, including curve fitting, k-nearest neighbor (kNN), and random forest regression (RFR). Finally, the mapping and estimation of winter oilseed rape LAI using reflectance obtained from Pleiades-1A, WorldView-3, SPOT-6, and WorldView-2 were implemented using the inversion method and the LAI estimation accuracy was validated using ground-measured datasets acquired during the 2014–2015 growing season. Our study indicates that based on the estimation results derived from different datasets, RFR is the optimal modeling algorithm amidst curve fitting and kNN with R2 &gt; 0.954 and RMSE &lt;0.218. Using the optimal VIs, the remote sensing-based mapping of winter oilseed rape LAI yielded an accuracy of R2 = 0.520 and RMSE = 0.923 (RRMSE = 93.7%). These results have demonstrated the potential operational applicability of the hybrid method proposed in this study for the mapping and retrieval of winter oilseed rape LAI values at field scales using multi-source and high spatial resolution optical remote sensing datasets. Details provided by this high resolution mapping cannot be easily discerned at coarser mapping scales and over larger spatial extents that usually employ lower resolution satellite images. Our study therefore has significant implications for field crop monitoring at local scales, providing relevant data for agronomic practices and precision agriculture.
KW  - winter oilseed rape
KW  - leaf area index
KW  - high spatial resolution
KW  - k-near neighbor
KW  - random forest
KW  - spectral vegetation index
DO  - 10.3390/rs9050488
ER  -
TY  - EJOU
AU  - Ciriza, Raquel
AU  - Sola, Ion
AU  - Albizua, Lourdes
AU  - Álvarez-Mozos, Jesús
AU  - González-Audícana, María
TI  - Automatic Detection of Uprooted Orchards Based on Orthophoto Texture Analysis
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 5
SN  - 2072-4292

AB  - Permanent crops, such as olive groves, vineyards and fruit trees, are important in European agriculture because of their spatial and economic relevance. Agricultural geographical databases (AGDBs) are commonly used by public bodies to gain knowledge of the extension covered by these crops and to manage related agricultural subsidies and inspections. However, the updating of these databases is mostly based on photointerpretation, and thus keeping this information up-to-date is very costly in terms of time and money. This paper describes a methodology for automatic detection of uprooted orchards (parcels where fruit trees have been eliminated) based on the textural classification of orthophotos with a spatial resolution of 0.25 m. The textural features used for this classification were derived from the grey level co-occurrence matrix (GLCM) and wavelet transform, and were selected through principal components (PCA) and separability analyses. Next, a Discriminant Analysis classification algorithm was used to detect uprooted orchards. Entropy, contrast and correlation were found to be the most informative textural features obtained from the co-occurrence matrix. The minimum and standard deviation in plane 3 were the selected features based on wavelet transform. The classification based on these features achieved a true positive rate (TPR) of over 80% and an accuracy (A) of over 88%. As a result, this methodology enabled reducing the number of fields to photointerpret by 60–85%, depending on the membership threshold value selected. The proposed approach could be easily adopted by different stakeholders and could increase significantly the efficiency of agricultural database updating tasks.
KW  - orchard detection
KW  - image analysis
KW  - texture feature
KW  - GLCM
KW  - wavelet transform
KW  - discriminant analysis
KW  - parcel level classification
DO  - 10.3390/rs9050492
ER  -
TY  - EJOU
AU  - Wang, Qingyong
AU  - Dai, Hong-Ning
AU  - Wang, Hao
TI  - A Smart MCDM Framework to Evaluate the Impact of Air Pollution on City Sustainability: A Case Study from China
T2  - Sustainability

PY  - 2017
VL  - 9
IS  - 6
SN  - 2071-1050

AB  - Air pollution has become one of the key environmental concerns in the urban sustainable development. It is important to evaluate the impact of air pollution on socioeconomic development since it is the prerequisite to enforce an effective prevention policy of air pollution. In this paper, we model the impact of air pollution on the urban economic development as a Multiple Criteria Decision Making (MCDM) problem. In particular, we propose a novel Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) analysis framework to evaluate multiple factors of air pollutants and economic development. Our method can overcome the drawbacks of conventional TOPSIS methods by using Bayesian regularization and the Back-Propagation (BP) neural network to optimize the weight training process. We have conducted a case study to evaluate our proposed framework.
KW  - sustainability
KW  - air pollution
KW  - Multiple Criteria Decision Making (MCDM)
KW  - TOPSIS
KW  - neural network
DO  - 10.3390/su9060911
ER  -
TY  - EJOU
AU  - Gnädinger, Friederike
AU  - Schmidhalter, Urs
TI  - Digital Counts of Maize Plants by Unmanned Aerial Vehicles (UAVs)
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 6
SN  - 2072-4292

AB  - Precision phenotyping, especially the use of image analysis, allows researchers to gain information on plant properties and plant health. Aerial image detection with unmanned aerial vehicles (UAVs) provides new opportunities in precision farming and precision phenotyping. Precision farming has created a critical need for spatial data on plant density. The plant number reflects not only the final field emergence but also allows a more precise assessment of the final yield parameters. The aim of this work is to advance UAV use and image analysis as a possible high-throughput phenotyping technique. In this study, four different maize cultivars were planted in plots with different seeding systems (in rows and equidistantly spaced) and different nitrogen fertilization levels (applied at 50, 150 and 250 kg N/ha). The experimental field, encompassing 96 plots, was overflown at a 50-m height with an octocopter equipped with a 10-megapixel camera taking a picture every 5 s. Images were recorded between BBCH 13–15 (it is a scale to identify the phenological development stage of a plant which is here the 3- to 5-leaves development stage) when the color of young leaves differs from older leaves. Close correlations up to R2 = 0.89 were found between in situ and image-based counted plants adapting a decorrelation stretch contrast enhancement procedure, which enhanced color differences in the images. On average, the error between visually and digitally counted plants was ≤5%. Ground cover, as determined by analyzing green pixels, ranged between 76% and 83% at these stages. However, the correlation between ground cover and digitally counted plants was very low. The presence of weeds and blurry effects on the images represent possible errors in counting plants. In conclusion, the final field emergence of maize can rapidly be assessed and allows more precise assessment of the final yield parameters. The use of UAVs and image processing has the potential to optimize farm management and to support field experimentation for agronomic and breeding purposes.
KW  - drone
KW  - farm management
KW  - high-throughput
KW  - maize cultivation
KW  - high-throughput phenomics
KW  - precision phenotyping
KW  - plant density
KW  - planting distance
KW  - unmanned aerial system (UAS)
DO  - 10.3390/rs9060544
ER  -
TY  - EJOU
AU  - Ampatzidis, Yiannis
AU  - De Bellis, Luigi
AU  - Luvisi, Andrea
TI  - iPathology: Robotic Applications and Management of Plants and Plant Diseases
T2  - Sustainability

PY  - 2017
VL  - 9
IS  - 6
SN  - 2071-1050

AB  - The rapid development of new technologies and the changing landscape of the online world (e.g., Internet of Things (IoT), Internet of All, cloud-based solutions) provide a unique opportunity for developing automated and robotic systems for urban farming, agriculture, and forestry. Technological advances in machine vision, global positioning systems, laser technologies, actuators, and mechatronics have enabled the development and implementation of robotic systems and intelligent technologies for precision agriculture. Herein, we present and review robotic applications on plant pathology and management, and emerging agricultural technologies for intra-urban agriculture. Greenhouse advanced management systems and technologies have been greatly developed in the last years, integrating IoT and WSN (Wireless Sensor Network). Machine learning, machine vision, and AI (Artificial Intelligence) have been utilized and applied in agriculture for automated and robotic farming. Intelligence technologies, using machine vision/learning, have been developed not only for planting, irrigation, weeding (to some extent), pruning, and harvesting, but also for plant disease detection and identification. However, plant disease detection still represents an intriguing challenge, for both abiotic and biotic stress. Many recognition methods and technologies for identifying plant disease symptoms have been successfully developed; still, the majority of them require a controlled environment for data acquisition to avoid false positives. Machine learning methods (e.g., deep and transfer learning) present promising results for improving image processing and plant symptom identification. Nevertheless, diagnostic specificity is a challenge for microorganism control and should drive the development of mechatronics and robotic solutions for disease management.
KW  - machine vision
KW  - machine learning
KW  - vertical farming systems
KW  - mechatronics
KW  - smart machines
KW  - smart city
DO  - 10.3390/su9061010
ER  -
TY  - EJOU
AU  - Stella, Alessandro
AU  - Caliendo, Gennaro
AU  - Melgani, Farid
AU  - Goller, Rino
AU  - Barazzuol, Maurizio
AU  - La Porta, Nicola
TI  - Leaf Wetness Evaluation Using Artificial Neural Network for Improving Apple Scab Fight
T2  - Environments

PY  - 2017
VL  - 4
IS  - 2
SN  - 2076-3298

AB  - Precision agriculture represents a promising technological trend in which governments and local authorities are increasingly investing. In particular, optimising the use of pesticides and having localised models of plant disease are the most important goals for the farmers of the future. The Trentino province in Italy is known as a strong national producer of apples. Apple production has to face many issues, however, among which is apple scab. This disease depends mainly on leaf wetness data typically acquired by fixed sensors. Based on the exploitation of artificial neural networks, this work aims to spatially extend the measurements of such sensors across uncovered areas (areas deprived of sensors). Achieved results have been validated comparing the apple scab risk of the same zone using either real leaf wetness data and estimated data. Thanks to the proposed method, it is possible to get the most relevant parameter of apple scab risk in places where no leaf wetness sensor is available. Moreover, our method permits having a specific risk evaluation of apple scab infection for each orchard, leading to an optimization of the use of chemical pesticides.
KW  - weather variables
KW  - unmanned aerial vehicle
KW  - potential infection
KW  - artificial neural network
KW  - precision agriculture
KW  - venturia inaequalis
KW  - plant disease
KW  - risk prediction
DO  - 10.3390/environments4020042
ER  -
TY  - EJOU
AU  - Domingues Franceschini, Marston H.
AU  - Bartholomeus, Harm
AU  - Van Apeldoorn, Dirk
AU  - Suomalainen, Juha
AU  - Kooistra, Lammert
TI  - Intercomparison of Unmanned Aerial Vehicle and Ground-Based Narrow Band Spectrometers Applied to Crop Trait Monitoring in Organic Potato Production
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 6
SN  - 1424-8220

AB  - Vegetation properties can be estimated using optical sensors, acquiring data on board of different platforms. For instance, ground-based and Unmanned Aerial Vehicle (UAV)-borne spectrometers can measure reflectance in narrow spectral bands, while different modelling approaches, like regressions fitted to vegetation indices, can relate spectra with crop traits. Although monitoring frameworks using multiple sensors can be more flexible, they may result in higher inaccuracy due to differences related to the sensors characteristics, which can affect information sampling. Also organic production systems can benefit from continuous monitoring focusing on crop management and stress detection, but few studies have evaluated applications with this objective. In this study, ground-based and UAV spectrometers were compared in the context of organic potato cultivation. Relatively accurate estimates were obtained for leaf chlorophyll (RMSE = 6.07 µg·cm−2), leaf area index (RMSE = 0.67 m2·m−2), canopy chlorophyll (RMSE = 0.24 g·m−2) and ground cover (RMSE = 5.5%) using five UAV-based data acquisitions, from 43 to 99 days after planting. These retrievals are slightly better than those derived from ground-based measurements (RMSE = 7.25 µg·cm−2, 0.85 m2·m−2, 0.28 g·m−2 and 6.8%, respectively), for the same period. Excluding observations corresponding to the first acquisition increased retrieval accuracy and made outputs more comparable between sensors, due to relatively low vegetation cover on this date. Intercomparison of vegetation indices indicated that indices based on the contrast between spectral bands in the visible and near-infrared, like OSAVI, MCARI2 and CIg provided, at certain extent, robust outputs that could be transferred between sensors. Information sampling at plot level by both sensing solutions resulted in comparable discriminative potential concerning advanced stages of late blight incidence. These results indicate that optical sensors, and their integration, have great potential for monitoring this specific organic cropping system.
KW  - hyperspectral imagery
KW  - Vis-NIR spectroscopy
KW  - organic cropping systems
KW  - vegetation indices
DO  - 10.3390/s17061428
ER  -
TY  - EJOU
AU  - Yang, Yurong
AU  - Gong, Huajun
AU  - Wang, Xinhua
AU  - Sun, Peng
TI  - Aerial Target Tracking Algorithm Based on Faster R-CNN Combined with Frame Differencing
T2  - Aerospace

PY  - 2017
VL  - 4
IS  - 2
SN  - 2226-4310

AB  - We propose a robust approach to detecting and tracking moving objects for a naval unmanned aircraft system (UAS) landing on an aircraft carrier. The frame difference algorithm follows a simple principle to achieve real-time tracking, whereas Faster Region-Convolutional Neural Network (R-CNN) performs highly precise detection and tracking characteristics. We thus combine Faster R-CNN with the frame difference method, which is demonstrated to exhibit robust and real-time detection and tracking performance. In our UAS landing experiments, two cameras placed on both sides of the runway are used to capture the moving UAS. When the UAS is captured, the joint algorithm uses frame difference to detect the moving target (UAS). As soon as the Faster R-CNN algorithm accurately detects the UAS, the detection priority is given to Faster R-CNN. In this manner, we also perform motion segmentation and object detection in the presence of changes in the environment, such as illumination variation or “walking persons”. By combining the 2 algorithms we can accurately detect and track objects with a tracking accuracy rate of up to 99% and a frame per second of up to 40 Hz. Thus, a solid foundation is laid for subsequent landing guidance.
KW  - deep learning
KW  - Faster R-CNN
KW  - UAS landing
KW  - object detection
DO  - 10.3390/aerospace4020032
ER  -
TY  - EJOU
AU  - Pau, Giovanni
AU  - Collotta, Mario
AU  - Maniscalco, Vincenzo
TI  - Bluetooth 5 Energy Management through a Fuzzy-PSO Solution for Mobile Devices of Internet of Things
T2  - Energies

PY  - 2017
VL  - 10
IS  - 7
SN  - 1996-1073

AB  - Energy efficiency is a fundamental requirement for a wireless protocol to be suitable for use within the Internet of Things. New technologies are emerging aiming at an energy-efficient communication. Among them, Bluetooth Low Energy is an appealing solution. Recently, the specifications of Bluetooth 5 have been presented with the purpose to offer significant enhancements compared to the earlier versions of the protocol. Bluetooth 5 comes with new communication modes that differ in range, speed, and energy consumption. This paper proposes a fuzzy-based solution to cope with the selection of the communication mode, among those introduced with Bluetooth 5, that allows the best energy efficiency. This communication mode, used by mobile devices, is dynamically regulated by varying the transmission power, returned as the output of a Fuzzy Logic Controller (FLC). A Particle Swarm Optimization (PSO) algorithm is presented to achieve the optimal parameters of the proposed FLC, i.e., optimizing the triangular membership functions, by varying their range, to reach the best results concerning the battery life of mobile devices. The proposed FLC is based on triangular membership functions because they represent a good trade-off between computation cost and efficiency. The paper presents a detailed description of the FLC design, a logical analysis of the PSO algorithm for the derivation of best performance conditions values, and experimental assessments, obtained through testbed scenarios.
KW  - Bluetooth low energy
KW  - Bluetooth 5
KW  - communication mode
KW  - energy efficiency
KW  - fuzzy logic controller
KW  - particle swarm optimization
DO  - 10.3390/en10070992
ER  -
TY  - EJOU
AU  - Danner, Martin
AU  - Berger, Katja
AU  - Wocher, Matthias
AU  - Mauser, Wolfram
AU  - Hank, Tobias
TI  - Retrieval of Biophysical Crop Variables from Multi-Angular Canopy Spectroscopy
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 7
SN  - 2072-4292

AB  - The future German Environmental Mapping and Analysis Program (EnMAP) mission, due to launch in late 2019, will deliver high resolution hyperspectral data from space and will thus contribute to a better monitoring of the dynamic surface of the earth. Exploiting the satellite’s ±30° across-track pointing capabilities will allow for the collection of hyperspectral time-series of homogeneous quality. Various studies have shown the possibility to retrieve geo-biophysical plant variables, like leaf area index (LAI) or leaf chlorophyll content (LCC), from narrowband observations with fixed viewing geometry by inversion of radiative transfer models (RTM). In this study we assess the capability of the well-known PROSPECT 5B + 4SAIL (Scattering by Arbitrarily Inclined Leaves) RTM to estimate these variables from off-nadir observations obtained during a field campaign with respect to EnMAP-like sun–target–sensor-geometries. A novel approach for multiple inquiries of a large look-up-table (LUT) in hierarchical steps is introduced that accounts for the varying instances of all variables of interest. Results show that anisotropic effects are strongest for early growth stages of the winter wheat canopy which influences also the retrieval of the variables. RTM inversions from off-nadir spectra lead to a decreased accuracy for the retrieval of LAI with a relative root mean squared error (rRMSE) of 18% at nadir vs. 25% (backscatter) and 24% (forward scatter) at off-nadir. For LCC estimations, however, off-nadir observations yield improvements, i.e., rRMSE (nadir) = 24% vs. rRMSE (forward scatter) = 20%. It follows that for a variable retrieval through RTM inversion, the final user will benefit from EnMAP time-series for biophysical studies regardless of the acquisition angle and will thus be able to exploit the maximum revisit capability of the mission.
KW  - EnMAP
KW  - hyperspectral
KW  - PROSAIL
KW  - multi-angle
KW  - canopy
KW  - biophysical variables
KW  - agriculture
KW  - spectroscopy
DO  - 10.3390/rs9070726
ER  -
TY  - EJOU
AU  - Tseng, Hsiao-Ting
AU  - Hwang, Hsin-Ginn
AU  - Hsu, Wei-Yen
AU  - Chou, Pei-Chin
AU  - Chang, I-Chiu
TI  - IoT-Based Image Recognition System for Smart Home-Delivered Meal Services
T2  - Symmetry

PY  - 2017
VL  - 9
IS  - 7
SN  - 2073-8994

AB  - Population ageing is an important global issue. The Taiwanese government has used various Internet of Things (IoT) applications in the “10-year long-term care program 2.0”. It is expected that the efficiency and effectiveness of long-term care services will be improved through IoT support. Home-delivered meal services for the elderly are important for home-based long-term care services. To ensure that the right meals are delivered to the right recipient at the right time, the runners need to take a picture of the meal recipient when the meal is delivered. This study uses the IoT-based image recognition system to design an integrated service to improve the management of image recognition. The core technology of this IoT-based image recognition system is statistical histogram-based k-means clustering for image segmentation. However, this method is time-consuming. Therefore, we proposed using the statistical histogram to obtain a probability density function of pixels of a figure and segmenting these with weighting for the same intensity. This aims to increase the computational performance and achieve the same results as k-means clustering. We combined histogram and k-means clustering in order to overcome the high computational cost for k-means clustering. The results indicate that the proposed method is significantly faster than k-means clustering by more than 10 times.
KW  - Internet of Things
KW  - long-term care 2.0
KW  - image segmentation
KW  - k-means clustering
KW  - histogram
DO  - 10.3390/sym9070125
ER  -
TY  - EJOU
AU  - Roldán, Juan J.
AU  - Peña-Tapia, Elena
AU  - Martín-Barrio, Andrés
AU  - Olivares-Méndez, Miguel A.
AU  - Del Cerro, Jaime
AU  - Barrientos, Antonio
TI  - Multi-Robot Interfaces and Operator Situational Awareness: Study of the Impact of Immersion and Prediction
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 8
SN  - 1424-8220

AB  - Multi-robot missions are a challenge for operators in terms of workload and situational awareness. These operators have to receive data from the robots, extract information, understand the situation properly, make decisions, generate the adequate commands, and send them to the robots. The consequences of excessive workload and lack of awareness can vary from inefficiencies to accidents. This work focuses on the study of future operator interfaces of multi-robot systems, taking into account relevant issues such as multimodal interactions, immersive devices, predictive capabilities and adaptive displays. Specifically, four interfaces have been designed and developed: a conventional, a predictive conventional, a virtual reality and a predictive virtual reality interface. The four interfaces have been validated by the performance of twenty-four operators that supervised eight multi-robot missions of fire surveillance and extinguishing. The results of the workload and situational awareness tests show that virtual reality improves the situational awareness without increasing the workload of operators, whereas the effects of predictive components are not significant and depend on their implementation.
KW  - multi-robot
KW  - operator interface
KW  - situational awareness
KW  - immersion
KW  - prediction
KW  - virtual reality
KW  - machine learning
DO  - 10.3390/s17081720
ER  -
TY  - EJOU
AU  - Jawad, Haider M.
AU  - Nordin, Rosdiadee
AU  - Gharghan, Sadik K.
AU  - Jawad, Aqeel M.
AU  - Ismail, Mahamod
TI  - Energy-Efficient Wireless Sensor Networks for Precision Agriculture: A Review
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 8
SN  - 1424-8220

AB  - Wireless sensor networks (WSNs) can be used in agriculture to provide farmers with a large amount of information. Precision agriculture (PA) is a management strategy that employs information technology to improve quality and production. Utilizing wireless sensor technologies and management tools can lead to a highly effective, green agriculture. Based on PA management, the same routine to a crop regardless of site environments can be avoided. From several perspectives, field management can improve PA, including the provision of adequate nutrients for crops and the wastage of pesticides for the effective control of weeds, pests, and diseases. This review outlines the recent applications of WSNs in agriculture research as well as classifies and compares various wireless communication protocols, the taxonomy of energy-efficient and energy harvesting techniques for WSNs that can be used in agricultural monitoring systems, and comparison between early research works on agriculture-based WSNs. The challenges and limitations of WSNs in the agricultural domain are explored, and several power reduction and agricultural management techniques for long-term monitoring are highlighted. These approaches may also increase the number of opportunities for processing Internet of Things (IoT) data.
KW  - energy-efficient
KW  - energy harvesting
KW  - precision agriculture
KW  - wireless communication technology
KW  - WSN
DO  - 10.3390/s17081781
ER  -
TY  - EJOU
AU  - Lopez-Franco, Carlos
AU  - Gomez-Avila, Javier
AU  - Alanis, Alma Y.
AU  - Arana-Daniel, Nancy
AU  - Villaseñor, Carlos
TI  - Visual Servoing for an Autonomous Hexarotor Using a Neural Network Based PID Controller
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 8
SN  - 1424-8220

AB  - In recent years, unmanned aerial vehicles (UAVs) have gained significant attention. However, we face two major drawbacks when working with UAVs: high nonlinearities and unknown position in 3D space since it is not provided with on-board sensors that can measure its position with respect to a global coordinate system. In this paper, we present a real-time implementation of a servo control, integrating vision sensors, with a neural proportional integral derivative (PID), in order to develop an hexarotor image based visual servo control (IBVS) that knows the position of the robot by using a velocity vector as a reference to control the hexarotor position. This integration requires a tight coordination between control algorithms, models of the system to be controlled, sensors, hardware and software platforms and well-defined interfaces, to allow the real-time implementation, as well as the design of different processing stages with their respective communication architecture. All of these issues and others provoke the idea that real-time implementations can be considered as a difficult task. For the purpose of showing the effectiveness of the sensor integration and control algorithm to address these issues on a high nonlinear system with noisy sensors as cameras, experiments were performed on the Asctec Firefly on-board computer, including both simulation and experimenta results.
KW  - unmanned aerial vehicle
KW  - hexarotor
KW  - visual servoing
DO  - 10.3390/s17081865
ER  -
TY  - EJOU
AU  - Sothe, Camile
AU  - Almeida, Cláudia M.
AU  - Liesenberg, Veraldo
AU  - Schimalski, Marcos B.
TI  - Evaluating Sentinel-2 and Landsat-8 Data to Map Sucessional Forest Stages in a Subtropical Forest in Southern Brazil
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 8
SN  - 2072-4292

AB  - Studies designed to discriminate different successional forest stages play a strategic role in forest management, forest policy and environmental conservation in tropical environments. The discrimination of different successional forest stages is still a challenge due to the spectral similarity among the concerned classes. Considering this, the objective of this paper was to investigate the performance of Sentinel-2 and Landsat-8 data for discriminating different successional forest stages of a patch located in a subtropical portion of the Atlantic Rain Forest in Southern Brazil with the aid of two machine learning algorithms and relying on the use of spectral reflectance data selected over two seasons and attributes thereof derived. Random Forest (RF) and Support Vector Machine (SVM) were used as classifiers with different subsets of predictor variables (multitemporal spectral reflectance, textural metrics and vegetation indices). All the experiments reached satisfactory results, with Kappa indices varying between 0.9, with Landsat-8 spectral reflectance alone and the SVM algorithm, and 0.98, with Sentinel-2 spectral reflectance alone also associated with the SVM algorithm. The Landsat-8 data had a significant increase in accuracy with the inclusion of other predictor variables in the classification process besides the pure spectral reflectance bands. The classification methods SVM and RF had similar performances in general. As to the RF method, the texture mean of the red-edge and SWIR bands were considered the most important ranked attributes for the classification of Sentinel-2 data, while attributes resulting from multitemporal bands, textural metrics of SWIR bands and vegetation indices were the most important ones in the Landsat-8 data classification.
KW  - textural features
KW  - vegetation indices
KW  - multitemporal information
KW  - random forest
KW  - support vector machine
DO  - 10.3390/rs9080838
ER  -
TY  - EJOU
AU  - Yan, Dingtian
AU  - Hu, Huosheng
TI  - Application of Augmented Reality and Robotic Technology in Broadcasting: A Survey
T2  - Robotics

PY  - 2017
VL  - 6
IS  - 3
SN  - 2218-6581

AB  - As an innovation technique, Augmented Reality (AR) has been gradually deployed in the broadcast, videography and cinematography industries. Virtual graphics generated by AR are dynamic and overlap on the surface of the environment so that the original appearance can be greatly enhanced in comparison with traditional broadcasting. In addition, AR enables broadcasters to interact with augmented virtual 3D models on a broadcasting scene in order to enhance the performance of broadcasting. Recently, advanced robotic technologies have been deployed in a camera shooting system to create a robotic cameraman so that the performance of AR broadcasting could be further improved, which is highlighted in the paper.
KW  - Keyword: Augmented Reality (AR)
KW  - AR broadcasting
KW  - AR display
KW  - AR tracking
KW  - Robotic Cameraman
DO  - 10.3390/robotics6030018
ER  -
TY  - EJOU
AU  - Alexandridis, Thomas K.
AU  - Tamouridou, Afroditi Alexandra
AU  - Pantazi, Xanthoula Eirini
AU  - Lagopodi, Anastasia L.
AU  - Kashefi, Javid
AU  - Ovakoglou, Georgios
AU  - Polychronos, Vassilios
AU  - Moshou, Dimitrios
TI  - Novelty Detection Classifiers in Weed Mapping: Silybum marianum Detection on UAV Multispectral Images
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 9
SN  - 1424-8220

AB  - In the present study, the detection and mapping of Silybum marianum (L.) Gaertn. weed using novelty detection classifiers is reported. A multispectral camera (green-red-NIR) on board a fixed wing unmanned aerial vehicle (UAV) was employed for obtaining high-resolution images. Four novelty detection classifiers were used to identify S. marianum between other vegetation in a field. The classifiers were One Class Support Vector Machine (OC-SVM), One Class Self-Organizing Maps (OC-SOM), Autoencoders and One Class Principal Component Analysis (OC-PCA). As input features to the novelty detection classifiers, the three spectral bands and texture were used. The S. marianum identification accuracy using OC-SVM reached an overall accuracy of 96%. The results show the feasibility of effective S. marianum mapping by means of novelty detection classifiers acting on multispectral UAV imagery.
KW  - weeds
KW  - UAS
KW  - RPAS
KW  - one-class
KW  - machine learning
KW  - remote sensing
KW  - geoinformatics
DO  - 10.3390/s17092007
ER  -
TY  - EJOU
AU  - Zhong, Yanfei
AU  - Jia, Tianyi
AU  - Zhao, Ji
AU  - Wang, Xinyu
AU  - Jin, Shuying
TI  - Spatial-Spectral-Emissivity Land-Cover Classification Fusing Visible and Thermal Infrared Hyperspectral Imagery
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 9
SN  - 2072-4292

AB  - High-resolution visible remote sensing imagery and thermal infrared hyperspectral imagery are potential data sources for land-cover classification. In this paper, in order to make full use of these two types of imagery, a spatial-spectral-emissivity land-cover classification method based on the fusion of visible and thermal infrared hyperspectral imagery is proposed, namely, SSECRF (spatial-spectral-emissivity land-cover classification based on conditional random fields). A spectral-spatial feature set is constructed considering the spectral variability and spatial-contextual information, to extract features from the high-resolution visible image. The emissivity is retrieved from the thermal infrared hyperspectral image by the FLAASH-IR algorithm and firstly introduced in the fusion of the visible and thermal infrared hyperspectral imagery; also, the emissivity is utilized in SSECRF, which contributes to improving the identification of man-made objects, such as roads and roofs. To complete the land-cover classification, the spatial-spectral feature set and emissivity are integrated by constructing the SSECRF energy function, which relates labels to the spatial-spectral-emissivity features, to obtain an improved classification result. The classification map performs a good result in distinguishing some certain classes, such as roads and bare soil. Also, the experimental results show that the proposed SSECRF algorithm efficiently integrates the spatial, spectral, and emissivity information and performs better than the traditional methods using raw radiance from thermal infrared hyperspectral imagery data, with a kappa value of 0.9137.
KW  - image fusion
KW  - thermal infrared hyperspectral imagery
KW  - conditional random fields
KW  - land-cover classification
KW  - emissivity
DO  - 10.3390/rs9090910
ER  -
TY  - EJOU
AU  - Kim, Hyunjun
AU  - Lee, Junhwa
AU  - Ahn, Eunjong
AU  - Cho, Soojin
AU  - Shin, Myoungsu
AU  - Sim, Sung-Han
TI  - Concrete Crack Identification Using a UAV Incorporating Hybrid Image Processing
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 9
SN  - 1424-8220

AB  - Crack assessment is an essential process in the maintenance of concrete structures. In general, concrete cracks are inspected by manual visual observation of the surface, which is intrinsically subjective as it depends on the experience of inspectors. Further, it is time-consuming, expensive, and often unsafe when inaccessible structural members are to be assessed. Unmanned aerial vehicle (UAV) technologies combined with digital image processing have recently been applied to crack assessment to overcome the drawbacks of manual visual inspection. However, identification of crack information in terms of width and length has not been fully explored in the UAV-based applications, because of the absence of distance measurement and tailored image processing. This paper presents a crack identification strategy that combines hybrid image processing with UAV technology. Equipped with a camera, an ultrasonic displacement sensor, and a WiFi module, the system provides the image of cracks and the associated working distance from a target structure on demand. The obtained information is subsequently processed by hybrid image binarization to estimate the crack width accurately while minimizing the loss of the crack length information. The proposed system has shown to successfully measure cracks thicker than 0.1 mm with the maximum length estimation error of 7.3%.
KW  - concrete structure
KW  - crack identification
KW  - digital image processing
KW  - structural health monitoring
KW  - unmanned aerial vehicle
DO  - 10.3390/s17092052
ER  -
TY  - EJOU
AU  - Huang, Yaohuan
AU  - Zhao, Chuanpeng
AU  - Yang, Haijun
AU  - Song, Xiaoyang
AU  - Chen, Jie
AU  - Li, Zhonghua
TI  - Feature Selection Solution with High Dimensionality and Low-Sample Size for Land Cover Classification in Object-Based Image Analysis
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 9
SN  - 2072-4292

AB  - Land cover information extraction through object-based image analysis (OBIA) has become an important trend in remote sensing, thanks to the increasing availability of high-resolution imagery. Segmented objects have a large number of features that cause high-dimension and low-sample size problems in the classification process. In this study, on the basis of a partial least squares generalized linear regression (PLSGLR), we propose a group corrected PLSGLR, known as G-PLSGLR, that aims to reduce the redundancy of object features for land cover identifications. Using Gaofen-2 images, the area of interest was segmented and sampled to generate small sample-size training datasets with 51 object features. The features selected by G-PLSGLR were compared against a guided regularized random forest (GRRF) in metrics of reduction rate, feature redundancy, and accuracy assessment of classification. Three indicators of overall accuracy (OA), user’s accuracy (UA), and producer’s accuracy (PA) were applied for accuracy assessment in this paper. The result shows that the G-PLSGLR achieved a reduction rate of 9.27 with a feature redundancy of 0.29, and a value of OA 90.63%. The GRRF achieved a reduction rate of 1.61 with a feature redundancy of 0.42, and a value of OA 85.56%. The PA of each land cover category was more than 95% using features selected by G-PLSGLR, while the PA ranged from 77 to 96% using features selected by GRRF. The UA of G-PLSGLR-selected features ranged from 70 to 80% except for grass land and bare land, which achieved 10% higher UA than GRRF-selected features. The G-PLSGLR method we proposed has the advantages of a large reduction rate, low feature redundancy, and high classification performance, which can be applied in OBIA-based land cover classification.
KW  - feature selection
KW  - generalized partial least squares regression
KW  - small samples
KW  - land cover
KW  - OBIA
DO  - 10.3390/rs9090939
ER  -
TY  - EJOU
AU  - Wang, Jingbin
AU  - Wang, Xiaohong
AU  - Wang, Lizhi
TI  - Modeling of BN Lifetime Prediction of a System Based on Integrated Multi-Level Information
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 9
SN  - 1424-8220

AB  - Predicting system lifetime is important to ensure safe and reliable operation of products, which requires integrated modeling based on multi-level, multi-sensor information. However, lifetime characteristics of equipment in a system are different and failure mechanisms are inter-coupled, which leads to complex logical correlations and the lack of a uniform lifetime measure. Based on a Bayesian network (BN), a lifetime prediction method for systems that combine multi-level sensor information is proposed. The method considers the correlation between accidental failures and degradation failure mechanisms, and achieves system modeling and lifetime prediction under complex logic correlations. This method is applied in the lifetime prediction of a multi-level solar-powered unmanned system, and the predicted results can provide guidance for the improvement of system reliability and for the maintenance and protection of the system.
KW  - multi-level system
KW  - lifetime prediction
KW  - Bayesian Networks
KW  - multi-sensor information integration
KW  - complex logical correlation
DO  - 10.3390/s17092123
ER  -
TY  - EJOU
AU  - Espinoza, Carlos Zúñiga
AU  - Khot, Lav R.
AU  - Sankaran, Sindhuja
AU  - Jacoby, Pete W.
TI  - High Resolution Multispectral and Thermal Remote Sensing-Based Water Stress Assessment in Subsurface Irrigated Grapevines
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 9
SN  - 2072-4292

AB  - Precision irrigation management is based on the accuracy and feasibility of sensor data assessing the plant water status. Multispectral and thermal infrared images acquired from an unmanned aerial vehicle (UAV) were analyzed to evaluate the applicability of the data in the assessment of variants of subsurface irrigation configurations. The study was carried out in a Cabernet Sauvignon orchard located near Benton City, Washington. Plants were subsurface irrigated at a 30, 60, and 90 cm depth, with 15%, 30%, and 60% irrigation of the standard irrigation level as determined by the grower in commercial production management. Half of the plots were irrigated using pulse irrigation and the other half using continuous irrigation techniques. The treatments were compared to the control plots that received standard surface irrigation at a continuous rate. The results showed differences in fruit yield when the control was compared to deficit irrigated treatments (15%, 30%, 60% of standard irrigation), while no differences were found for comparisons of the techniques (pulse, continuous) or depths of irrigation (30, 60, 90 cm). Leaf stomatal conductance of control and 60% irrigation treatments were statistically different compared to treatments receiving 30% and 15% irrigation. The normalized difference vegetation index (NDVI), green normalized difference vegetation index (GNDVI), and canopy temperature were correlated to fruit yield and leaf stomatal conductance. Significant correlations (p &lt; 0.01) were observed between NDVI, GNDVI, and canopy temperature with fruit yield (Pearson’s correlation coefficient, r = 0.68, 0.73, and −0.83, respectively), and with leaf stomatal conductance (r = 0.56, 0.65, and −0.63, respectively) at 44 days before harvest. This study demonstrates the potential of using low-altitude multispectral and thermal imagery data in the assessment of irrigation techniques and relative degree of plant water stress. In addition, results provide a feasibility analysis of our hypothesis that thermal infrared images can be used as a rapid tool to estimate leaf stomatal conductance, indicative of the spatial variation in the vineyard. This is critically important, as such data will provide a near real-time crop stress assessment for better irrigation management/scheduling in wine grape production.
KW  - deficit irrigation
KW  - normalized difference vegetation index
KW  - green normalized difference vegetation index
KW  - canopy temperature
KW  - stomatal conductance
DO  - 10.3390/rs9090961
ER  -
TY  - EJOU
AU  - Ribeiro-Gomes, Krishna
AU  - Hernández-López, David
AU  - Ortega, José F.
AU  - Ballesteros, Rocío
AU  - Poblete, Tomás
AU  - Moreno, Miguel A.
TI  - Uncooled Thermal Camera Calibration and Optimization of the Photogrammetry Process for UAV Applications in Agriculture
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 10
SN  - 1424-8220

AB  - The acquisition, processing, and interpretation of thermal images from unmanned aerial vehicles (UAVs) is becoming a useful source of information for agronomic applications because of the higher temporal and spatial resolution of these products compared with those obtained from satellites. However, due to the low load capacity of the UAV they need to mount light, uncooled thermal cameras, where the microbolometer is not stabilized to a constant temperature. This makes the camera precision low for many applications. Additionally, the low contrast of the thermal images makes the photogrammetry process inaccurate, which result in large errors in the generation of orthoimages. In this research, we propose the use of new calibration algorithms, based on neural networks, which consider the sensor temperature and the digital response of the microbolometer as input data. In addition, we evaluate the use of the Wallis filter for improving the quality of the photogrammetry process using structure from motion software. With the proposed calibration algorithm, the measurement accuracy increased from 3.55 °C with the original camera configuration to 1.37 °C. The implementation of the Wallis filter increases the number of tie-point from 58,000 to 110,000 and decreases the total positing error from 7.1 m to 1.3 m.
KW  - uncooled thermal camera calibration
KW  - microbolometer
KW  - unmanned aerial vehicle
KW  - image filtering
KW  - structure from motion
KW  - irrigation management
DO  - 10.3390/s17102173
ER  -
TY  - EJOU
AU  - Rivas Casado, Mónica
AU  - González, Rocío B.
AU  - Ortega, José F.
AU  - Leinster, Paul
AU  - Wright, Ros
TI  - Towards a Transferable UAV-Based Framework for River Hydromorphological Characterization
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 10
SN  - 1424-8220

AB  - The multiple protocols that have been developed to characterize river hydromorphology, partly in response to legislative drivers such as the European Union Water Framework Directive (EU WFD), make the comparison of results obtained in different countries challenging. Recent studies have analyzed the comparability of existing methods, with remote sensing based approaches being proposed as a potential means of harmonizing hydromorphological characterization protocols. However, the resolution achieved by remote sensing products may not be sufficient to assess some of the key hydromorphological features that are required to allow an accurate characterization. Methodologies based on high resolution aerial photography taken from Unmanned Aerial Vehicles (UAVs) have been proposed by several authors as potential approaches to overcome these limitations. Here, we explore the applicability of an existing UAV based framework for hydromorphological characterization to three different fluvial settings representing some of the distinct ecoregions defined by the WFD geographical intercalibration groups (GIGs). The framework is based on the automated recognition of hydromorphological features via tested and validated Artificial Neural Networks (ANNs). Results show that the framework is transferable to the Central-Baltic and Mediterranean GIGs with accuracies in feature identification above 70%. Accuracies of 50% are achieved when the framework is implemented in the Very Large Rivers GIG. The framework successfully identified vegetation, deep water, shallow water, riffles, side bars and shadows for the majority of the reaches. However, further algorithm development is required to ensure a wider range of features (e.g., chutes, structures and erosion) are accurately identified. This study also highlights the need to develop an objective and fit for purpose hydromorphological characterization framework to be adopted within all EU member states to facilitate comparison of results.
KW  - hydromorphology
KW  - intercalibration
KW  - unmanned aerial vehicle
KW  - photogrammetry
KW  - artificial neural network
KW  - water framework directive
DO  - 10.3390/s17102210
ER  -
TY  - EJOU
AU  - Tamouridou, Afroditi A.
AU  - Alexandridis, Thomas K.
AU  - Pantazi, Xanthoula E.
AU  - Lagopodi, Anastasia L.
AU  - Kashefi, Javid
AU  - Kasampalis, Dimitris
AU  - Kontouris, Georgios
AU  - Moshou, Dimitrios
TI  - Application of Multilayer Perceptron with Automatic Relevance Determination on Weed Mapping Using UAV Multispectral Imagery
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 10
SN  - 1424-8220

AB  - Remote sensing techniques are routinely used in plant species discrimination and of weed mapping. In the presented work, successful Silybum marianum detection and mapping using multilayer neural networks is demonstrated. A multispectral camera (green-red-near infrared) attached on a fixed wing unmanned aerial vehicle (UAV) was utilized for the acquisition of high-resolution images (0.1 m resolution). The Multilayer Perceptron with Automatic Relevance Determination (MLP-ARD) was used to identify the S. marianum among other vegetation, mostly Avena sterilis L. The three spectral bands of Red, Green, Near Infrared (NIR) and the texture layer resulting from local variance were used as input. The S. marianum identification rates using MLP-ARD reached an accuracy of 99.54%. Τhe study had an one year duration, meaning that the results are specific, although the accuracy shows the interesting potential of S. marianum mapping with MLP-ARD on multispectral UAV imagery.
KW  - remote sensing
KW  - precision agriculture
KW  - crop monitoring
KW  - data fusion
DO  - 10.3390/s17102307
ER  -
TY  - EJOU
AU  - Recoskie, Steven
AU  - Lanteigne, Eric
AU  - Gueaieb, Wail
TI  - A High-Fidelity Energy Efficient Path Planner for Unmanned Airships
T2  - Robotics

PY  - 2017
VL  - 6
IS  - 4
SN  - 2218-6581

AB  - This paper presents a comparative study on the effects of grid resolution, vehicle velocity, and wind vector fields on the trajectory planning of unmanned airships. A wavefront expansion trajectory planner that minimizes a multi-objective cost function consisting of flight time, energy consumption, and collision avoidance while respecting the differential constraints of the vehicle is presented. Trajectories are generated using a variety of test environments and flight conditions to demonstrate that the inclusion of a high terrain map resolution, a temporal vehicle velocity, and a spatial wind vector field yields significant improvements in trajectory feasibility and energy economy when compared to trajectories generated using only two of these three elements.
KW  - path planning
KW  - unmanned airship
KW  - wavefront expansion
DO  - 10.3390/robotics6040028
ER  -
TY  - EJOU
AU  - Bakr, Muhammad Abu
AU  - Lee, Sukhan
TI  - Distributed Multisensor Data Fusion under Unknown Correlation and Data Inconsistency
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 11
SN  - 1424-8220

AB  - The paradigm of multisensor data fusion has been evolved from a centralized architecture to a decentralized or distributed architecture along with the advancement in sensor and communication technologies. These days, distributed state estimation and data fusion has been widely explored in diverse fields of engineering and control due to its superior performance over the centralized one in terms of flexibility, robustness to failure and cost effectiveness in infrastructure and communication. However, distributed multisensor data fusion is not without technical challenges to overcome: namely, dealing with cross-correlation and inconsistency among state estimates and sensor data. In this paper, we review the key theories and methodologies of distributed multisensor data fusion available to date with a specific focus on handling unknown correlation and data inconsistency. We aim at providing readers with a unifying view out of individual theories and methodologies by presenting a formal analysis of their implications. Finally, several directions of future research are highlighted.
KW  - multisensor data fusion
KW  - decentralized estimation
KW  - distributed fusion
KW  - inconsistent estimates
KW  - spurious data
KW  - unknown correlation
DO  - 10.3390/s17112472
ER  -
TY  - EJOU
AU  - Poblete, Tomas
AU  - Ortega-Farías, Samuel
AU  - Moreno, Miguel A.
AU  - Bardeen, Matthew
TI  - Artificial Neural Network to Predict Vine Water Status Spatial Variability Using Multispectral Information Obtained from an Unmanned Aerial Vehicle (UAV)
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 11
SN  - 1424-8220

AB  - Water stress, which affects yield and wine quality, is often evaluated using the midday stem water potential (Ψstem). However, this measurement is acquired on a per plant basis and does not account for the assessment of vine water status spatial variability. The use of multispectral cameras mounted on unmanned aerial vehicle (UAV) is capable to capture the variability of vine water stress in a whole field scenario. It has been reported that conventional multispectral indices (CMI) that use information between 500–800 nm, do not accurately predict plant water status since they are not sensitive to water content. The objective of this study was to develop artificial neural network (ANN) models derived from multispectral images to predict the Ψstem spatial variability of a drip-irrigated Carménère vineyard in Talca, Maule Region, Chile. The coefficient of determination (R2) obtained between ANN outputs and ground-truth measurements of Ψstem were between 0.56–0.87, with the best performance observed for the model that included the bands 550, 570, 670, 700 and 800 nm. Validation analysis indicated that the ANN model could estimate Ψstem with a mean absolute error (MAE) of 0.1 MPa, root mean square error (RMSE) of 0.12 MPa, and relative error (RE) of −9.1%. For the validation of the CMI, the MAE, RMSE and RE values were between 0.26–0.27 MPa, 0.32–0.34 MPa and −24.2–25.6%, respectively.
KW  - multispectral image processing
KW  - artificial neural network
KW  - UAV
KW  - midday stem water potential
DO  - 10.3390/s17112488
ER  -
TY  - EJOU
AU  - Lv, ZhiYong
AU  - Shi, WenZhong
AU  - Zhou, XiaoCheng
AU  - Benediktsson, Jón A.
TI  - Semi-Automatic System for Land Cover Change Detection Using Bi-Temporal Remote Sensing Images
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 11
SN  - 2072-4292

AB  - Change detection is an increasingly important research topic in remote sensing application. Previous studies achieved land cover change detection (LCCD) using bi-temporal remote sensing images. However, many widely used methods detected change depending on a series of parameters, and determining parameters is time-consuming. Furthermore, numerous methods are data-dependent. Therefore, their degree of automation should be improved significantly. Three techniques, which consist of a semi-automatic change detection system, are proposed for LCCD to overcome the abovementioned drawbacks. The three techniques are as follows: (1) change magnitude image (CMI) noise reduction is based on Gaussian filter (GF), which is coupled with OTSU for reducing CMI noise automatically using an iterative optimization strategy; (2) a method based on histogram curve fitting is suggested to predict the threshold range for parameter determination; and (3) a modified region growing algorithm is built for iteratively constructing the final change detection map. The detection accuracies of the proposed system are investigated through four experiments with different bi-temporal image scenes. Compared with several widely used change detection methods, the proposed system can be applied to detect land cover change with high accuracy and flexibility. This work is an attempt to provide a change detection system that is compatible with remote sensing images with high and median-low spatial resolution.
KW  - semi-automatic change detection system
KW  - land cover change detection
KW  - remote sensing images
DO  - 10.3390/rs9111112
ER  -
TY  - EJOU
AU  - Zhang, Hongyue
AU  - Huang, Mingrui
AU  - Qing, Xiuling
AU  - Li, Guoqing
AU  - Tian, Chuanzhao
TI  - Bibliometric Analysis of Global Remote Sensing Research during 2010–2015
T2  - ISPRS International Journal of Geo-Information

PY  - 2017
VL  - 6
IS  - 11
SN  - 2220-9964

AB  - Bibliometric analysis based on the Science Citation Index Expanded published by Thomson Scientific was carried out to identify the research status and future trends of remote sensing (RS) during 2010–2015. The analysis revealed the institutional, national, spatio-temporal, and categorical patterns in remote sensing research both from the WP (whole publications) viewpoint and the HCP (highly-cited publications) viewpoint. Statistical analysis results showed that remote sensing research almost doubled during 2010–2015. Environmental sciences comprised the most attractive subject category among remote sensing research. The International Journal of Remote Sensing was the most productive journal, and Remote Sensing of Environment published the most HCP among the 31 distributed journals. The productive ranking of countries was led by the U.S. both from the WP viewpoint and the HCP viewpoint, and CAS (Chinese Academy of Sciences) was the most productive institute both from the WP viewpoint and the HCP viewpoint with lower CPP (average number of citations per paper). Keyword analysis illustrated that model and algorithm research were the key points in RS during 2010–2015. RS data including Moderate-Resolution Imaging Spectroradiometer (MODIS), Landsat, synthetic aperture radar (SAR), and LiDAR (light detection and ranging) were the most frequently adopted, but the data usage of UAVs (unmanned aerial vehicles) and small satellites will be promoted in the future. With the development of data acquisition abilities, big data issues will become the challenges and hotspots of RS research, and new algorithms will continue to emerge.
KW  - remote sensing
KW  - bibliometric analysis
KW  - WP viewpoint
KW  - HCP viewpoint
KW  - CPP
DO  - 10.3390/ijgi6110332
ER  -
TY  - EJOU
AU  - Alirezaie, Marjan
AU  - Kiselev, Andrey
AU  - Längkvist, Martin
AU  - Klügl, Franziska
AU  - Loutfi, Amy
TI  - An Ontology-Based Reasoning Framework for Querying Satellite Images for Disaster Monitoring
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 11
SN  - 1424-8220

AB  - This paper presents a framework in which satellite images are classified and augmented with additional semantic information to enable queries about what can be found on the map at a particular location, but also about paths that can be taken. This is achieved by a reasoning framework based on qualitative spatial reasoning that is able to find answers to high level queries that may vary on the current situation. This framework called SemCityMap, provides the full pipeline from enriching the raw image data with rudimentary labels to the integration of a knowledge representation and reasoning methods to user interfaces for high level querying. To illustrate the utility of SemCityMap in a disaster scenario, we use an urban environment—central Stockholm—in combination with a flood simulation. We show that the system provides useful answers to high-level queries also with respect to the current flood status. Examples of such queries concern path planning for vehicles or retrieval of safe regions such as “find all regions close to schools and far from the flooded area”. The particular advantage of our approach lies in the fact that ontological information and reasoning is explicitly integrated so that queries can be formulated in a natural way using concepts on appropriate level of abstraction, including additional constraints.
KW  - satellite imagery data
KW  - natural hazards
KW  - ontology
KW  - reasoning
KW  - path finding
DO  - 10.3390/s17112545
ER  -
TY  - EJOU
AU  - Yamamoto, Kyosuke
AU  - Togami, Takashi
AU  - Yamaguchi, Norio
TI  - Super-Resolution of Plant Disease Images for the Acceleration of Image-based Phenotyping and Vigor Diagnosis in Agriculture
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 11
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs or drones) are a very promising branch of technology, and they have been utilized in agriculture—in cooperation with image processing technologies—for phenotyping and vigor diagnosis. One of the problems in the utilization of UAVs for agricultural purposes is the limitation in flight time. It is necessary to fly at a high altitude to capture the maximum number of plants in the limited time available, but this reduces the spatial resolution of the captured images. In this study, we applied a super-resolution method to the low-resolution images of tomato diseases to recover detailed appearances, such as lesions on plant organs. We also conducted disease classification using high-resolution, low-resolution, and super-resolution images to evaluate the effectiveness of super-resolution methods in disease classification. Our results indicated that the super-resolution method outperformed conventional image scaling methods in spatial resolution enhancement of tomato disease images. The results of disease classification showed that the accuracy attained was also better by a large margin with super-resolution images than with low-resolution images. These results indicated that our approach not only recovered the information lost in low-resolution images, but also exerted a beneficial influence on further image analysis. The proposed approach will accelerate image-based phenotyping and vigor diagnosis in the field, because it not only saves time to capture images of a crop in a cultivation field but also secures the accuracy of these images for further analysis.
KW  - super-resolution
KW  - deep learning
KW  - convolutional neural network
KW  - disease classification
KW  - agriculture
DO  - 10.3390/s17112557
ER  -
TY  - EJOU
AU  - Chu, Hone-Jay
AU  - Huang, Min-Lang
AU  - Tain, Yu-Ching
AU  - Yang, Mon-Shieh
AU  - Höfle, Bernhard
TI  - Historic Low Wall Detection via Topographic Parameter Images Derived from Fine-Resolution DEM
T2  - ISPRS International Journal of Geo-Information

PY  - 2017
VL  - 6
IS  - 11
SN  - 2220-9964

AB  - Coral walls protect vegetation gardens from strong winds that sweep across Xiji Island, Taiwan Strait for half the year. Topographic parameters based on light detection and ranging (LiDAR)-based high-resolution digital elevation model (DEM) provide obvious correspondence with the expected form of landscape features. The information on slope, curvature, and openness can help identify the location of landscape features. This study applied the automatic landscape line detection to extract historic vegetable garden wall lines from a LiDAR-derived DEM. The three rapid processes used in this study included the derivation of topographic parameters, line extraction, and aggregation. The rules were extracted from a decision tree to check the line detection from multiple topographic parameters. Results show that wall line detection with multiple topographic parameter images is an alternative means of obtaining essential historic wall feature information. Multiple topographic parameters are highly related to low wall feature identification. Furthermore, the accuracy of wall feature detection is 74% compared with manual interpretation. Thus, this study provides rapid wall detection systems with multiple topographic parameters for further historic landscape management.
KW  - LiDAR-based DEM
KW  - topographic parameters
KW  - wall detection
KW  - feature identification
DO  - 10.3390/ijgi6110346
ER  -
TY  - EJOU
AU  - Tang, Tianyu
AU  - Zhou, Shilin
AU  - Deng, Zhipeng
AU  - Lei, Lin
AU  - Zou, Huanxin
TI  - Arbitrary-Oriented Vehicle Detection in Aerial Imagery with Single Convolutional Neural Networks
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 11
SN  - 2072-4292

AB  - Vehicle detection with orientation estimation in aerial images has received widespread interest as it is important for intelligent traffic management. This is a challenging task, not only because of the complex background and relatively small size of the target, but also the various orientations of vehicles in aerial images captured from the top view. The existing methods for oriented vehicle detection need several post-processing steps to generate final detection results with orientation, which are not efficient enough. Moreover, they can only get discrete orientation information for each target. In this paper, we present an end-to-end single convolutional neural network to generate arbitrarily-oriented detection results directly. Our approach, named Oriented_SSD (Single Shot MultiBox Detector, SSD), uses a set of default boxes with various scales on each feature map location to produce detection bounding boxes. Meanwhile, offsets are predicted for each default box to better match the object shape, which contain the angle parameter for oriented bounding boxes’ generation. Evaluation results on the public DLR Vehicle Aerial dataset and Vehicle Detection in Aerial Imagery (VEDAI) dataset demonstrate that our method can detect both the location and orientation of the vehicle with high accuracy and fast speed. For test images in the DLR Vehicle Aerial dataset with a size of     5616 × 3744    , our method achieves 76.1% average precision (AP) and 78.7% correct direction classification at 5.17 s on an NVIDIA GTX-1060.
KW  - arbitrary-oriented
KW  - vehicle detection
KW  - single convolutional neural networks (CNN)
KW  - aerial images
KW  - near-real-time
DO  - 10.3390/rs9111170
ER  -
TY  - EJOU
AU  - Zhong, Jiandan
AU  - Lei, Tao
AU  - Yao, Guangle
TI  - Robust Vehicle Detection in Aerial Images Based on Cascaded Convolutional Neural Networks
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 12
SN  - 1424-8220

AB  - Vehicle detection in aerial images is an important and challenging task. Traditionally, many target detection models based on sliding-window fashion were developed and achieved acceptable performance, but these models are time-consuming in the detection phase. Recently, with the great success of convolutional neural networks (CNNs) in computer vision, many state-of-the-art detectors have been designed based on deep CNNs. However, these CNN-based detectors are inefficient when applied in aerial image data due to the fact that the existing CNN-based models struggle with small-size object detection and precise localization. To improve the detection accuracy without decreasing speed, we propose a CNN-based detection model combining two independent convolutional neural networks, where the first network is applied to generate a set of vehicle-like regions from multi-feature maps of different hierarchies and scales. Because the multi-feature maps combine the advantage of the deep and shallow convolutional layer, the first network performs well on locating the small targets in aerial image data. Then, the generated candidate regions are fed into the second network for feature extraction and decision making. Comprehensive experiments are conducted on the Vehicle Detection in Aerial Imagery (VEDAI) dataset and Munich vehicle dataset. The proposed cascaded detection model yields high performance, not only in detection accuracy but also in detection speed.
KW  - vehicle detection
KW  - convolutional neural network
KW  - aerial image
KW  - deep learning
DO  - 10.3390/s17122720
ER  -
TY  - EJOU
AU  - Su, Jinya
AU  - Yi, Dewei
AU  - Liu, Cunjia
AU  - Guo, Lei
AU  - Chen, Wen-Hua
TI  - Dimension Reduction Aided Hyperspectral Image Classification with a Small-sized Training Dataset: Experimental Comparisons
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 12
SN  - 1424-8220

AB  - Hyperspectral images (HSI) provide rich information which may not be captured by other sensing technologies and therefore gradually find a wide range of applications. However, they also generate a large amount of irrelevant or redundant data for a specific task. This causes a number of issues including significantly increased computation time, complexity and scale of prediction models mapping the data to semantics (e.g., classification), and the need of a large amount of labelled data for training. Particularly, it is generally difficult and expensive for experts to acquire sufficient training samples in many applications. This paper addresses these issues by exploring a number of classical dimension reduction algorithms in machine learning communities for HSI classification. To reduce the size of training dataset, feature selection (e.g., mutual information, minimal redundancy maximal relevance) and feature extraction (e.g., Principal Component Analysis (PCA), Kernel PCA) are adopted to augment a baseline classification method, Support Vector Machine (SVM). The proposed algorithms are evaluated using a real HSI dataset. It is shown that PCA yields the most promising performance in reducing the number of features or spectral bands. It is observed that while significantly reducing the computational complexity, the proposed method can achieve better classification results over the classic SVM on a small training dataset, which makes it suitable for real-time applications or when only limited training data are available. Furthermore, it can also achieve performances similar to the classic SVM on large datasets but with much less computing time.
KW  - feature extraction/selection
KW  - image classification
KW  - Hyperspectral image
KW  - PCA
KW  - SVM
DO  - 10.3390/s17122726
ER  -
TY  - EJOU
AU  - Hou, Bowen
AU  - He, Zhangming
AU  - Zhou, Xuanying
AU  - Zhou, Haiyin
AU  - Li, Dong
AU  - Wang, Jiongqi
TI  - Maximum Correntropy Criterion Kalman Filter for α-Jerk Tracking Model with Non-Gaussian Noise
T2  - Entropy

PY  - 2017
VL  - 19
IS  - 12
SN  - 1099-4300

AB  - As one of the most critical issues for target track, 
          
            
              α
            
          
        -jerk model is an effective maneuver target track model. Non-Gaussian noises always exist in the track process, which usually lead to inconsistency and divergence of the track filter. A novel Kalman filter is derived and applied on 
          
            
              α
            
          
        -jerk tracking model to handle non-Gaussian noise. The weighted least square solution is presented and the standard Kalman filter is deduced firstly. A novel Kalman filter with the weighted least square based on the maximum correntropy criterion is deduced. The robustness of the maximum correntropy criterion is also analyzed with the influence function and compared with the Huber-based filter, and, moreover, the kernel size of Gaussian kernel plays an important role in the filter algorithm. A new adaptive kernel method is proposed in this paper to adjust the parameter in real time. Finally, simulation results indicate the validity and the efficiency of the proposed filter. The comparison study shows that the proposed filter can significantly reduce the noise influence for 
          
            
              α
            
          
        -jerk model.
KW  - Kalman filter
KW  - α-jerk model
KW  - maximum correntropy criterion
KW  - non-Gaussian noise
KW  - robustness
KW  - influence function
KW  - kernel size
DO  - 10.3390/e19120648
ER  -
TY  - EJOU
AU  - Chen, Suting
AU  - Li, Xin
AU  - Zhang, Yanyan
AU  - Feng, Rui
AU  - Zhang, Chuang
TI  - Local Deep Hashing Matching of Aerial Images Based on Relative Distance and Absolute Distance Constraints
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 12
SN  - 2072-4292

AB  - Aerial images have features of high resolution, complex background, and usually require large amounts of calculation, however, most algorithms used in matching of aerial images adopt the shallow hand-crafted features expressed as floating-point descriptors (e.g., SIFT (Scale-invariant Feature Transform), SURF (Speeded Up Robust Features)), which may suffer from poor matching speed and are not well represented in the literature. Here, we propose a novel Local Deep Hashing Matching (LDHM) method for matching of aerial images with large size and with lower complexity or fast matching speed. The basic idea of the proposed algorithm is to utilize the deep network model in the local area of the aerial images, and study the local features, as well as the hash function of the images. Firstly, according to the course overlap rate of aerial images, the algorithm extracts the local areas for matching to avoid the processing of redundant information. Secondly, a triplet network structure is proposed to mine the deep features of the patches of the local image, and the learned features are imported to the hash layer, thus obtaining the representation of a binary hash code. Thirdly, the constraints of the positive samples to the absolute distance are added on the basis of the triplet loss, a new objective function is constructed to optimize the parameters of the network and enhance the discriminating capabilities of image patch features. Finally, the obtained deep hash code of each image patch is used for the similarity comparison of the image patches in the Hamming space to complete the matching of aerial images. The proposed LDHM algorithm evaluates the UltraCam-D dataset and a set of actual aerial images, simulation result demonstrates that it may significantly outperform the state-of-the-art algorithm in terms of the efficiency and performance.
KW  - aerial matching
KW  - overlap rate
KW  - deep learning
KW  - local features
KW  - hash learning
KW  - absolute distance constraints
DO  - 10.3390/rs9121244
ER  -
TY  - EJOU
AU  - Qadir, Junaid
AU  - Sathiaseelan, Arjuna
AU  - Farooq, Umar B.
AU  - Usama, Muhammad
AU  - Imran, Muhammad A.
AU  - Shafique, Muhammad
TI  - Approximate Networking for Universal Internet Access
T2  - Future Internet

PY  - 2017
VL  - 9
IS  - 4
SN  - 1999-5903

AB  - Despite the best efforts of networking researchers and practitioners, an ideal Internet experience is inaccessible to an overwhelming majority of people the world over, mainly due to the lack of cost-efficient ways of provisioning high-performance, global Internet. In this paper, we argue that instead of an exclusive focus on a utopian goal of universally accessible “ideal networking” (in which we have a high throughput and quality of service as well as low latency and congestion), we should consider providing “approximate networking” through the adoption of context-appropriate trade-offs. In this regard, we propose to leverage the advances in the emerging trend of “approximate computing” that rely on relaxing the bounds of precise/exact computing to provide new opportunities for improving the area, power, and performance efficiency of systems by orders of magnitude by embracing output errors in resilient applications. Furthermore, we propose to extend the dimensions of approximate computing towards various knobs available at network layers. Approximate networking can be used to provision “Global Access to the Internet for All” (GAIA) in a pragmatically tiered fashion, in which different users around the world are provided a different context-appropriate (but still contextually functional) Internet experience.
KW  - universal Internet access
KW  - approximate networking
KW  - Global Access to the Internet for All (GAIA)
DO  - 10.3390/fi9040094
ER  -
TY  - EJOU
AU  - Liang, Hui
AU  - Huang, Xiaodong
AU  - Sun, Yanhua
AU  - Wang, Yunlong
AU  - Liang, Tiangang
TI  - Fractional Snow-Cover Mapping Based on MODIS and UAV Data over the Tibetan Plateau
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 12
SN  - 2072-4292

AB  - Moderate-resolution imaging spectroradiometer (MODIS) snow-cover products have relatively low accuracy over the Tibetan Plateau because of its complex terrain and shallow, fragmented snow cover. In this study, fractional snow-cover (FSC) mapping algorithms were developed using a linear regression model (LR), a linear spectral mixture analysis model (LSMA) and a back-propagation artificial neural network model (BP-ANN) based on MODIS data (version 006) and unmanned aerial vehicle (UAV) data. The accuracies of the three models were validated against Landsat 8 Operational Land Imager (OLI) snow-cover maps (Landsat 8 FSC) and compared with the MODIS global FSC product (MOD10A1 FSC, version 005) for the purpose of finding the optimal algorithm for FSC extraction for the Tibetan Plateau. The results showed that (1) the overall retrieval results of the LR and BP-ANN models based on MODIS and UAV data were relatively similar to the OLI snow-cover maps; the accuracy and stability were greatly improved, with even some reduction in errors; compared to the Landsat 8 FSC, the correlation coefficients (r) were 0.8222 and 0.8445 respectively and the root-mean-square errors (RMSEs) were 0.2304 and 0.2201, respectively. (2) The accuracy and stability of the fully constrained LSMA model using the pixel purity index (PPI) endmember extraction method based only on MODIS data suffered the worst performance of the three models; r was only 0.7921 and the RMSE was as large as 0.3485. There were some serious omission phenomena in the study area, specifically for the largest mean absolute error (MAE = 0.2755) and positive mean error (PME = 0.3411). (3) The accuracy of the MOD10A1 FSC product was much lower than that of the LR and BP-ANN models, although its accuracy slightly better that of the LSMA based on comprehensive evaluation of six accuracy indices. (4) The optimal model was the BP-ANN model with combined inputs of surface reflectivity data (R1–R7), elevation (DEM) and temperature (LST), which can easily incorporate auxiliary information (DEM and LST) on the basis of (R1–R7) during the relationship training period and can effectively improve the accuracy of snow area monitoring—it is the ideal algorithm for retrieving FSC for the Tibetan Plateau.
KW  - fractional snow-cover
KW  - MODIS
KW  - UAV
KW  - Tibetan Plateau
DO  - 10.3390/rs9121332
ER  -
TY  - EJOU
AU  - Pádua, Luís
AU  - Hruška, Jonáš
AU  - Bessa, José
AU  - Adão, Telmo
AU  - Martins, Luís M.
AU  - Gonçalves, José A.
AU  - Peres, Emanuel
AU  - Sousa, António M. R.
AU  - Castro, João P.
AU  - Sousa, Joaquim J.
TI  - Multi-Temporal Analysis of Forestry and Coastal Environments Using UASs
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 1
SN  - 2072-4292

AB  - Due to strong improvements and developments achieved in the last decade, it is clear that applied research using remote sensing technology such as unmanned aerial vehicles (UAVs) can provide a flexible, efficient, non-destructive, and non-invasive means of acquiring geoscientific data, especially aerial imagery. Simultaneously, there has been an exponential increase in the development of sensors and instruments that can be installed in UAV platforms. By combining the aforementioned factors, unmanned aerial system (UAS) setups composed of UAVs, sensors, and ground control stations, have been increasingly used for remote sensing applications, with growing potential and abilities. This paper’s overall goal is to identify advantages and challenges related to the use of UAVs for aerial imagery acquisition in forestry and coastal environments for preservation/prevention contexts. Moreover, the importance of monitoring these environments over time will be demonstrated. To achieve these goals, two case studies using UASs were conducted. The first focuses on phytosanitary problem detection and monitoring of chestnut tree health (Padrela region, Valpaços, Portugal). The acquired high-resolution imagery allowed for the identification of tree canopy cover decline by means of multi-temporal analysis. The second case study enabled the rigorous and non-evasive registry process of topographic changes that occurred in the sandspit of Cabedelo (Douro estuary, Porto, Portugal) in different time periods. The obtained results allow us to conclude that the UAS constitutes a low-cost, rigorous, and fairly autonomous form of remote sensing technology, capable of covering large geographical areas and acquiring high precision data to aid decision support systems in forestry preservation and coastal monitoring applications. Its swift evolution makes it a potential big player in remote sensing technologies today and in the near future.
KW  - multi-temporal data analysis
KW  - unmanned aerial systems
KW  - chestnut trees
KW  - coastal environments
DO  - 10.3390/rs10010024
ER  -
TY  - EJOU
AU  - Yue, Jibo
AU  - Feng, Haikuan
AU  - Yang, Guijun
AU  - Li, Zhenhai
TI  - A Comparison of Regression Techniques for Estimation of Above-Ground Winter Wheat Biomass Using Near-Surface Spectroscopy
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 1
SN  - 2072-4292

AB  - Above-ground biomass (AGB) provides a vital link between solar energy consumption and yield, so its correct estimation is crucial to accurately monitor crop growth and predict yield. In this work, we estimate AGB by using 54 vegetation indexes (e.g., Normalized Difference Vegetation Index, Soil-Adjusted Vegetation Index) and eight statistical regression techniques: artificial neural network (ANN), multivariable linear regression (MLR), decision-tree regression (DT), boosted binary regression tree (BBRT), partial least squares regression (PLSR), random forest regression (RF), support vector machine regression (SVM), and principal component regression (PCR), which are used to analyze hyperspectral data acquired by using a field spectrophotometer. The vegetation indexes (VIs) determined from the spectra were first used to train regression techniques for modeling and validation to select the best VI input, and then summed with white Gaussian noise to study how remote sensing errors affect the regression techniques. Next, the VIs were divided into groups of different sizes by using various sampling methods for modeling and validation to test the stability of the techniques. Finally, the AGB was estimated by using a leave-one-out cross validation with these powerful techniques. The results of the study demonstrate that, of the eight techniques investigated, PLSR and MLR perform best in terms of stability and are most suitable when high-accuracy and stable estimates are required from relatively few samples. In addition, RF is extremely robust against noise and is best suited to deal with repeated observations involving remote-sensing data (i.e., data affected by atmosphere, clouds, observation times, and/or sensor noise). Finally, the leave-one-out cross-validation method indicates that PLSR provides the highest accuracy (R2 = 0.89, RMSE = 1.20 t/ha, MAE = 0.90 t/ha, NRMSE = 0.07, CV (RMSE) = 0.18); thus, PLSR is best suited for works requiring high-accuracy estimation models. The results indicate that all these techniques provide impressive accuracy. The comparison and analysis provided herein thus reveals the advantages and disadvantages of the ANN, MLR, DT, BBRT, PLSR, RF, SVM, and PCR techniques and can help researchers to build efficient AGB-estimation models.
KW  - regression techniques
KW  - biomass
KW  - vegetation indexes
KW  - sampling methods
KW  - noise immunity
KW  - biomass estimation model
KW  - hyperspectral
KW  - multi-collinearity
DO  - 10.3390/rs10010066
ER  -
TY  - EJOU
AU  - Johnson, Brian A.
AU  - Jozdani, Shahab E.
TI  - Identifying Generalizable Image Segmentation Parameters for Urban Land Cover Mapping through Meta-Analysis and Regression Tree Modeling
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 1
SN  - 2072-4292

AB  - The advent of very high resolution (VHR) satellite imagery and the development of Geographic Object-Based Image Analysis (GEOBIA) have led to many new opportunities for fine-scale land cover mapping, especially in urban areas. Image segmentation is an important step in the GEOBIA framework, so great time/effort is often spent to ensure that computer-generated image segments closely match real-world objects of interest. In the remote sensing community, segmentation is frequently performed using the multiresolution segmentation (MRS) algorithm, which is tuned through three user-defined parameters (the scale, shape/color, and compactness/smoothness parameters). The scale parameter (SP) is the most important parameter and governs the average size of generated image segments. Existing automatic methods to determine suitable SPs for segmentation are scene-specific and often computationally intensive, so an approach to estimating appropriate SPs that is generalizable (i.e., not scene-specific) could speed up the GEOBIA workflow considerably. In this study, we attempted to identify generalizable SPs for five common urban land cover types (buildings, vegetation, roads, bare soil, and water) through meta-analysis and nonlinear regression tree (RT) modeling. First, we performed a literature search of recent studies that employed GEOBIA for urban land cover mapping and extracted the MRS parameters used, the image properties (i.e., spatial and radiometric resolutions), and the land cover classes mapped. Using this data extracted from the literature, we constructed RT models for each land cover class to predict suitable SP values based on the: image spatial resolution, image radiometric resolution, shape/color parameter, and compactness/smoothness parameter. Based on a visual and quantitative analysis of results, we found that for all land cover classes except water, relatively accurate SPs could be identified using our RT modeling results. The main advantage of our approach over existing SP selection approaches is that our RT model results are not scene-specific, so they can be used to quickly identify suitable SPs in other VHR images.
KW  - high spatial resolution imagery
KW  - multiresolution segmentation
KW  - object-based image analysis
KW  - GEOBIA
DO  - 10.3390/rs10010073
ER  -
TY  - EJOU
AU  - Li, Hongguang
AU  - Shi, Yang
AU  - Zhang, Baochang
AU  - Wang, Yufeng
TI  - Superpixel-Based Feature for Aerial Image Scene Recognition
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 1
SN  - 1424-8220

AB  - Image scene recognition is a core technology for many aerial remote sensing applications. Different landforms are inputted as different scenes in aerial imaging, and all landform information is regarded as valuable for aerial image scene recognition. However, the conventional features of the Bag-of-Words model are designed using local points or other related information and thus are unable to fully describe landform areas. This limitation cannot be ignored when the aim is to ensure accurate aerial scene recognition. A novel superpixel-based feature is proposed in this study to characterize aerial image scenes. Then, based on the proposed feature, a scene recognition method of the Bag-of-Words model for aerial imaging is designed. The proposed superpixel-based feature that utilizes landform information establishes top-task superpixel extraction of landforms to bottom-task expression of feature vectors. This characterization technique comprises the following steps: simple linear iterative clustering based superpixel segmentation, adaptive filter bank construction, Lie group-based feature quantification, and visual saliency model-based feature weighting. Experiments of image scene recognition are carried out using real image data captured by an unmanned aerial vehicle (UAV). The recognition accuracy of the proposed superpixel-based feature is 95.1%, which is higher than those of scene recognition algorithms based on other local features.
KW  - superpixel-based feature
KW  - image scene recognition
KW  - aerial remote sensing
DO  - 10.3390/s18010156
ER  -
TY  - EJOU
AU  - Berger, Katja
AU  - Atzberger, Clement
AU  - Danner, Martin
AU  - D’Urso, Guido
AU  - Mauser, Wolfram
AU  - Vuolo, Francesco
AU  - Hank, Tobias
TI  - Evaluation of the PROSAIL Model Capabilities for Future Hyperspectral Model Environments: A Review Study
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 1
SN  - 2072-4292

AB  - Upcoming satellite hyperspectral sensors require powerful and robust methodologies for making optimum use of the rich spectral data. This paper reviews the widely applied coupled PROSPECT and SAIL radiative transfer models (PROSAIL), regarding their suitability for the retrieval of biophysical and biochemical variables in the context of agricultural crop monitoring. Evaluation was carried out using a systematic literature review of 281 scientific publications with regard to their (i) spectral exploitation, (ii) vegetation type analyzed, (iii) variables retrieved, and (iv) choice of retrieval methods. From the analysis, current trends were derived, and problems identified and discussed. Our analysis clearly shows that the PROSAIL model is well suited for the analysis of imaging spectrometer data from future satellite missions and that the model should be integrated in appropriate software tools that are being developed in this context for agricultural applications. The review supports the decision of potential users to employ PROSAIL for their specific data analysis and provides guidelines for choosing between the diverse retrieval techniques.
KW  - PROSAIL
KW  - biophysical and biochemical variables
KW  - EnMAP sensor
KW  - model inversion
KW  - hyperspectral
KW  - leaf area index (LAI)
KW  - radiative transfer model
DO  - 10.3390/rs10010085
ER  -
TY  - EJOU
AU  - Kim, Sungho
AU  - Song, Woo-Jin
AU  - Kim, So-Hyun
TI  - Double Weight-Based SAR and Infrared Sensor Fusion for Automatic Ground Target Recognition with Deep Learning
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 1
SN  - 2072-4292

AB  - This paper presents a novel double weight-based synthetic aperture radar (SAR) and infrared (IR) sensor fusion method (DW-SIF) for automatic ground target recognition (ATR). IR-based ATR can provide accurate recognition because of its high image resolution but it is affected by the weather conditions. On the other hand, SAR-based ATR shows a low recognition rate due to the noisy low resolution but can provide consistent performance regardless of the weather conditions. The fusion of an active sensor (SAR) and a passive sensor (IR) can lead to upgraded performance. This paper proposes a doubly weighted neural network fusion scheme at the decision level. The first weight (   α   ) can measure the offline sensor confidence per target category based on the classification rate for an evaluation set. The second weight (   β   ) can measure the online sensor reliability based on the score distribution for a test target image. The LeNet architecture-based deep convolution network (14 layers) is used as an individual classifier. Doubly weighted sensor scores are fused by two types of fusion schemes, such as the sum-based linear fusion scheme (    α β    -sum) and neural network-based nonlinear fusion scheme (    α β    -NN). The experimental results confirmed the proposed linear fusion method (    α β    -sum) to have the best performance among the linear fusion schemes available (SAR-CNN, IR-CNN,    α   -sum,    β   -sum,     α β    -sum, and Bayesian fusion). In addition, the proposed nonlinear fusion method (    α β    -NN) showed superior target recognition performance to linear fusion on the OKTAL-SE-based synthetic database.
KW  - SAR
KW  - IR
KW  - fusion
KW  - double weights
KW  - linear
KW  - nonlinear
KW  - deep learning
KW  - OKTAL-SE
DO  - 10.3390/rs10010072
ER  -
TY  - EJOU
AU  - Shen, Jieliang
AU  - Su, Yan
AU  - Liang, Qing
AU  - Zhu, Xinhua
TI  - Calculation and Identification of the Aerodynamic Parameters for Small-Scaled Fixed-Wing UAVs
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 1
SN  - 1424-8220

AB  - The establishment of the Aircraft Dynamic Model (ADM) constitutes the prerequisite for the design of the navigation and control system, but the aerodynamic parameters in the model could not be readily obtained especially for small-scaled fixed-wing UAVs. In this paper, the procedure of computing the aerodynamic parameters is developed. All the longitudinal and lateral aerodynamic derivatives are firstly calculated through semi-empirical method based on the aerodynamics, rather than the wind tunnel tests or fluid dynamics software analysis. Secondly, the residuals of each derivative are proposed to be identified or estimated further via Extended Kalman Filter(EKF), with the observations of the attitude and velocity from the airborne integrated navigation system. Meanwhile, the observability of the targeted parameters is analyzed and strengthened through multiple maneuvers. Based on a small-scaled fixed-wing aircraft driven by propeller, the airborne sensors are chosen and the model of the actuators are constructed. Then, real flight tests are implemented to verify the calculation and identification process. Test results tell the rationality of the semi-empirical method and show the improvement of accuracy of ADM after the compensation of the parameters.
KW  - aerodynamic parameters
KW  - semi-empirical aerodynamic coefficient modeling
KW  - parameters identification
KW  - EKF
KW  - real flight tests
DO  - 10.3390/s18010206
ER  -
TY  - EJOU
AU  - Loggenberg, Kyle
AU  - Strever, Albert
AU  - Greyling, Berno
AU  - Poona, Nitesh
TI  - Modelling Water Stress in a Shiraz Vineyard Using Hyperspectral Imaging and Machine Learning
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 2
SN  - 2072-4292

AB  - The detection of water stress in vineyards plays an integral role in the sustainability of high-quality grapes and prevention of devastating crop loses. Hyperspectral remote sensing technologies combined with machine learning provides a practical means for modelling vineyard water stress. In this study, we applied two ensemble learners, i.e., random forest (RF) and extreme gradient boosting (XGBoost), for discriminating stressed and non-stressed Shiraz vines using terrestrial hyperspectral imaging. Additionally, we evaluated the utility of a spectral subset of wavebands, derived using RF mean decrease accuracy (MDA) and XGBoost gain. Our results show that both ensemble learners can effectively analyse the hyperspectral data. When using all wavebands (p = 176), RF produced a test accuracy of 83.3% (KHAT (kappa analysis) = 0.67), and XGBoost a test accuracy of 80.0% (KHAT = 0.6). Using the subset of wavebands (p = 18) produced slight increases in accuracy ranging from 1.7% to 5.5% for both RF and XGBoost. We further investigated the effect of smoothing the spectral data using the Savitzky-Golay filter. The results indicated that the Savitzky-Golay filter reduced model accuracies (ranging from 0.7% to 3.3%). The results demonstrate the feasibility of terrestrial hyperspectral imagery and machine learning to create a semi-automated framework for vineyard water stress modelling.
KW  - terrestrial hyperspectral imaging
KW  - vineyard
KW  - water stress
KW  - machine learning
KW  - tree-based ensemble
DO  - 10.3390/rs10020202
ER  -
TY  - EJOU
AU  - Poblete, Tomas
AU  - Ortega-Farías, Samuel
AU  - Ryu, Dongryeol
TI  - Automatic Coregistration Algorithm to Remove Canopy Shaded Pixels in UAV-Borne Thermal Images to Improve the Estimation of Crop Water Stress Index of a Drip-Irrigated Cabernet Sauvignon Vineyard
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 2
SN  - 1424-8220

AB  - Water stress caused by water scarcity has a negative impact on the wine industry. Several strategies have been implemented for optimizing water application in vineyards. In this regard, midday stem water potential (SWP) and thermal infrared (TIR) imaging for crop water stress index (CWSI) have been used to assess plant water stress on a vine-by-vine basis without considering the spatial variability. Unmanned Aerial Vehicle (UAV)-borne TIR images are used to assess the canopy temperature variability within vineyards that can be related to the vine water status. Nevertheless, when aerial TIR images are captured over canopy, internal shadow canopy pixels cannot be detected, leading to mixed information that negatively impacts the relationship between CWSI and SWP. This study proposes a methodology for automatic coregistration of thermal and multispectral images (ranging between 490 and 900 nm) obtained from a UAV to remove shadow canopy pixels using a modified scale invariant feature transformation (SIFT) computer vision algorithm and Kmeans++ clustering. Our results indicate that our proposed methodology improves the relationship between CWSI and SWP when shadow canopy pixels are removed from a drip-irrigated Cabernet Sauvignon vineyard. In particular, the coefficient of determination (R2) increased from 0.64 to 0.77. In addition, values of the root mean square error (RMSE) and standard error (SE) decreased from 0.2 to 0.1 MPa and 0.24 to 0.16 MPa, respectively. Finally, this study shows that the negative effect of shadow canopy pixels was higher in those vines with water stress compared with well-watered vines.
KW  - multispectral and thermal automatic coregistration
KW  - shadow removal
KW  - crop water stress index (CWSI)
KW  - UAV
KW  - midday stem water potential
DO  - 10.3390/s18020397
ER  -
TY  - EJOU
AU  - Zhang, Wangfei
AU  - Chen, Erxue
AU  - Li, Zengyuan
AU  - Zhao, Lei
AU  - Ji, Yongjie
AU  - Zhang, Yahong
AU  - Liu, Zhiqin
TI  - Rape (Brassica napus L.) Growth Monitoring and Mapping Based on Radarsat-2 Time-Series Data
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 2
SN  - 2072-4292

AB  - In this study, 27 polarimetric parameters were extracted from Radarsat-2 polarimetric synthetic aperture radar (SAR) at each growth stage of the rape crop. The sensitivity to growth parameters such as stem height, leaf area index (LAI), and biomass were investigated as a function of days after sowing. Based on the sensitivity analysis, five empirical regression models were compared to determine the best model for stem height, LAI, and biomass inversion. Of these five models, quadratic models had higher R2 values than other models in most cases of growth parameter inversions, but when these results were related to physical scattering mechanisms, the inversion results produced overestimation in the performance of some parameters. By contrast, linear and logarithmic models, which had lower R2 values than the quadratic models, had stable performance for growth parameter inversions, particularly in terms of their performance at each growth stage. The best biomass inversion performance was acquired by the volume component of a quadratic model, with an R2 value of 0.854 and root mean square error (RMSE) of 109.93 g m−2. The best LAI inversion was also acquired by a quadratic model, but used the radar vegetation index (Cloude), with an R2 value of 0.8706 and RMSE of 0.56 m2 m−2. Stem height was acquired by scattering angle alpha (   α   ) using a logarithmic model, with an R2 of 0.926 value and RMSE of 11.09 cm. The performances of these models were also analysed for biomass estimation at the second growth stage (P2), third growth stage (P3), and fourth growth stage (P4). The results showed that the models built at the P3 stage had better substitutability with the models built during all of the growth stages. From the mapping results, we conclude that a model built at the P3 stage can be used for rape biomass inversion, with 90% of estimation errors being less than 100 g m−2.
KW  - rape (Brassica napus L.)
KW  - monitoring
KW  - biomass
KW  - stem height
KW  - LAI
KW  - empirical regression model
KW  - inversion
DO  - 10.3390/rs10020206
ER  -
TY  - EJOU
AU  - Zhou, Rui
AU  - Sun, Jinping
AU  - Hu, Yuxin
AU  - Qi, Yaolong
TI  - Multichannel High Resolution Wide Swath SAR Imaging for Hypersonic Air Vehicle with Curved Trajectory
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 2
SN  - 1424-8220

AB  - Synthetic aperture radar (SAR) equipped on the hypersonic air vehicle in near space has many advantages over the conventional airborne SAR. However, its high-speed maneuvering characteristics with curved trajectory result in serious range migration, and exacerbate the contradiction between the high resolution and wide swath. To solve this problem, this paper establishes the imaging geometrical model matched with the flight trajectory of the hypersonic platform and the multichannel azimuth sampling model based on the displaced phase center antenna (DPCA) technology. Furthermore, based on the multichannel signal reconstruction theory, a more efficient spectrum reconstruction model using discrete Fourier transform is proposed to obtain the azimuth uniform sampling data. Due to the high complexity of the slant range model, it is difficult to deduce the processing algorithm for SAR imaging. Thus, an approximate range model is derived based on the minimax criterion, and the optimal second-order approximate coefficients of cosine function are obtained using the two-population coevolutionary algorithm. On this basis, aiming at the problem that the traditional Omega-K algorithm cannot compensate the residual phase with the difficulty of Stolt mapping along the range frequency axis, this paper proposes an Exact Transfer Function (ETF) algorithm for SAR imaging, and presents a method of range division to achieve wide swath imaging. Simulation results verify the effectiveness of the ETF imaging algorithm.
KW  - hypersonic air vehicle
KW  - azimuth multichannel sampling
KW  - DPCA
KW  - high resolution wide swath (HRWS)
KW  - ETF imaging algorithm
KW  - near space
KW  - curved trajectory
DO  - 10.3390/s18020411
ER  -
TY  - EJOU
AU  - Kycko, Marlena
AU  - Zagajewski, Bogdan
AU  - Lavender, Samantha
AU  - Romanowska, Elżbieta
AU  - Zwijacz-Kozica, Magdalena
TI  - The Impact of Tourist Traffic on the Condition and Cell Structures of Alpine Swards
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 2
SN  - 2072-4292

AB  - This research focuses on the effect of trampling on vegetation in high-mountain ecosystems through the electromagnetic spectrum’s interaction with plant pigments, cell structure, water content and other substances that have a direct impact on leaf properties. The aim of the study was to confirm with the use of fluorescence methods of variability in the state of high-mountain vegetation previously measured spectrometrically. The most heavily visited part of the High Tatras in Poland was divided into polygons and, after selecting the dominant species within alpine swards, a detailed analysis of trampled and reference patterns was performed. The Analytical Spectral Devices (ASD) FieldSpec 3/4 were used to acquire high-resolution spectral properties of plants, their fluorescence and the leaf chlorophyll content with the difference between the plant surface temperature (ts), and the air temperature (ta) as well as fraction of Absorbed Photosynthetically Active Radiation (fAPAR) used as reference data. The results show that, along tourist trails, vegetation adapts to trampling with the impact depending on the species. A lower chlorophyll value was confirmed by a decrease in fluorescence, and the cellular structures were degraded in trampled compared to reference species, with a lower leaf reflectance. In addition, at the extreme, trampling can eliminate certain species such as Luzula alpino-pilosa, for which significant changes were noted due to trampling.
KW  - High Tatras
KW  - trampling
KW  - spectroscopy
KW  - vegetation indices
KW  - fluorescence
KW  - Juncus trifidus
KW  - Agrostis rupestris
KW  - Luzula alpino-pilosa
KW  - Oreochloa disticha
KW  - Festuca picta
DO  - 10.3390/rs10020220
ER  -
TY  - EJOU
AU  - Li, Jincheng
AU  - Chen, Jie
AU  - Wang, Pengbo
AU  - Li, Chunsheng
TI  - Sensor-Oriented Path Planning for Multiregion Surveillance with a Single Lightweight UAV SAR
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 2
SN  - 1424-8220

AB  - In the surveillance of interested regions by unmanned aerial vehicle (UAV), system performance relies greatly on the motion control strategy of the UAV and the operation characteristics of the onboard sensors. This paper investigates the 2D path planning problem for the lightweight UAV synthetic aperture radar (SAR) system in an environment of multiple regions of interest (ROIs), the sizes of which are comparable to the radar swath width. Taking into account the special requirements of the SAR system on the motion of the platform, we model path planning for UAV SAR as a constrained multiobjective optimization problem (MOP). Based on the fact that the UAV route can be designed in the map image, an image-based path planner is proposed in this paper. First, the neighboring ROIs are merged by the morphological operation. Then, the parts of routes for data collection of the ROIs can be located according to the geometric features of the ROIs and the observation geometry of UAV SAR. Lastly, the route segments for ROIs surveillance are connected by a path planning algorithm named the sampling-based sparse A* search (SSAS) algorithm. Simulation experiments in real scenarios demonstrate that the proposed sensor-oriented path planner can improve the reconnaissance performance of lightweight UAV SAR greatly compared with the conventional zigzag path planner.
KW  - path planning
KW  - lightweight unmanned aerial vehicle (UAV)
KW  - synthetic aperture radar (SAR)
KW  - aerial surveillance
KW  - A* search algorithm
DO  - 10.3390/s18020548
ER  -
TY  - EJOU
AU  - De Castro, Ana I.
AU  - Torres-Sánchez, Jorge
AU  - Peña, Jose M.
AU  - Jiménez-Brenes, Francisco M.
AU  - Csillik, Ovidiu
AU  - López-Granados, Francisca
TI  - An Automatic Random Forest-OBIA Algorithm for Early Weed Mapping between and within Crop Rows Using UAV Imagery
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 2
SN  - 2072-4292

AB  - Accurate and timely detection of weeds between and within crop rows in the early growth stage is considered one of the main challenges in site-specific weed management (SSWM). In this context, a robust and innovative automatic object-based image analysis (OBIA) algorithm was developed on Unmanned Aerial Vehicle (UAV) images to design early post-emergence prescription maps. This novel algorithm makes the major contribution. The OBIA algorithm combined Digital Surface Models (DSMs), orthomosaics and machine learning techniques (Random Forest, RF). OBIA-based plant heights were accurately estimated and used as a feature in the automatic sample selection by the RF classifier; this was the second research contribution. RF randomly selected a class balanced training set, obtained the optimum features values and classified the image, requiring no manual training, making this procedure time-efficient and more accurate, since it removes errors due to a subjective manual task. The ability to discriminate weeds was significantly affected by the imagery spatial resolution and weed density, making the use of higher spatial resolution images more suitable. Finally, prescription maps for in-season post-emergence SSWM were created based on the weed maps—the third research contribution—which could help farmers in decision-making to optimize crop management by rationalization of the herbicide application. The short time involved in the process (image capture and analysis) would allow timely weed control during critical periods, crucial for preventing yield loss.
KW  - Digital Surface Model
KW  - segmentation
KW  - precision agriculture
KW  - in-season post-emergence site-specific weed control
KW  - plant height
DO  - 10.3390/rs10020285
ER  -
TY  - EJOU
AU  - Mueller, Markus S.
AU  - Jutzi, Boris
TI  - UAS Navigation with SqueezePoseNet—Accuracy Boosting for Pose Regression by Data Augmentation
T2  - Drones

PY  - 2018
VL  - 2
IS  - 1
SN  - 2504-446X

AB  - The navigation of Unmanned Aerial Vehicles (UAVs) nowadays is mostly based on Global Navigation Satellite Systems (GNSSs). Drawbacks of satellite-based navigation are failures caused by occlusions or multi-path interferences. Therefore, alternative methods have been developed in recent years. Visual navigation methods such as Visual Odometry (VO) or visual Simultaneous Localization and Mapping (SLAM) aid global navigation solutions by closing trajectory gaps or performing loop closures. However, if the trajectory estimation is interrupted or not available, a re-localization is mandatory. Furthermore, the latest research has shown promising results on pose regression in 6 Degrees of Freedom (DoF) based on Convolutional Neural Networks (CNNs). Additionally, existing navigation methods can benefit from these networks. In this article, a method for GNSS-free and fast image-based pose regression by utilizing a small Convolutional Neural Network is presented. Therefore, a small CNN (SqueezePoseNet) is utilized, transfer learning is applied and the network is tuned for pose regression. Furthermore, recent drawbacks are overcome by applying data augmentation on a training dataset utilizing simulated images. Experiments with small CNNs show promising results for GNSS-free and fast localization compared to larger networks. By training a CNN with an extended data set including simulated images, the accuracy on pose regression is improved up to 61.7% for position and up to 76.0% for rotation compared to training on a standard not-augmented data set.
KW  - convolutional neural networks
KW  - data augmentation
KW  - image-based navigation
KW  - pose estimation
DO  - 10.3390/drones2010007
ER  -
TY  - EJOU
AU  - Meng, Baoping
AU  - Gao, Jinlong
AU  - Liang, Tiangang
AU  - Cui, Xia
AU  - Ge, Jing
AU  - Yin, Jianpeng
AU  - Feng, Qisheng
AU  - Xie, Hongjie
TI  - Modeling of Alpine Grassland Cover Based on Unmanned Aerial Vehicle Technology and Multi-Factor Methods: A Case Study in the East of Tibetan Plateau, China
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 2
SN  - 2072-4292

AB  - Grassland cover and its temporal changes are key parameters in the estimation and monitoring of ecosystems and their functions, especially via remote sensing. However, the most suitable model for estimating grassland cover and the differences between models has rarely been studied in alpine meadow grasslands. In this study, field measurements of grassland cover in Gannan Prefecture, from 2014 to 2016, were acquired using unmanned aerial vehicle (UAV) technology. Single-factor parametric and multi-factor parametric/non-parametric cover inversion models were then constructed based on 14 factors related to grassland cover, and the dynamic variation of the annual maximum cover was analyzed. The results show that (1) nine out of 14 factors (longitude, latitude, elevation, the concentrations of clay and sand in the surface and bottom soils, temperature, precipitation, enhanced vegetation index (EVI) and normalized difference vegetation index (NDVI)) exert a significant effect on grassland cover in the study area. The logarithmic model based on EVI presents the best performance, with an R2 and RMSE of 0.52 and 16.96%, respectively. Single-factor grassland cover inversion models account for only 1–49% of the variation in cover during the growth season. (2) The optimum grassland cover inversion model is the artificial neural network (BP-ANN), with an R2 and RMSE of 0.72 and 13.38%, and SDs of 0.062% and 1.615%, respectively. Both the accuracy and the stability of the BP-ANN model are higher than those of the single-factor parametric models and multi-factor parametric/non-parametric models. (3) The annual maximum cover in Gannan Prefecture presents an increasing trend over 60.60% of the entire study area, while 36.54% is presently stable and 2.86% exhibits a decreasing trend.
KW  - grassland cover
KW  - unmanned aerial vehicle
KW  - multi-factor
KW  - inversion model
KW  - dynamic variation
DO  - 10.3390/rs10020320
ER  -
TY  - EJOU
AU  - Guo, Qiangliang
AU  - Xiao, Jin
AU  - Hu, Xiaoguang
TI  - New Keypoint Matching Method Using Local Convolutional Features for Power Transmission Line Icing Monitoring
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 3
SN  - 1424-8220

AB  - Power transmission line icing (PTLI) problems, which cause tremendous damage to the power grids, has drawn much attention. Existing three-dimensional measurement methods based on binocular stereo vision was recently introduced to measure the ice thickness in PTLI, but failed to meet requirements of practical applications due to inefficient keypoint matching in the complex PTLI scene. In this paper, a new keypoint matching method is proposed based on the local multi-layer convolutional neural network (CNN) features, termed Local Convolutional Features (LCFs). LCFs are deployed to extract more discriminative features than the conventional CNNs. Particularly in LCFs, a multi-layer features fusion scheme is exploited to boost the matching performance. Together with a location constraint method, the correspondence of neighboring keypoints is further refined. Our approach achieves 1.5%, 5.3%, 13.1%, 27.3% improvement in the average matching precision compared with SIFT, SURF, ORB and MatchNet on the public Middlebury dataset, and the measurement accuracy of ice thickness can reach 90.9% compared with manual measurement on the collected PTLI dataset.
KW  - power transmission line icing
KW  - keypoint matching
KW  - convolutional neural network
KW  - feature fusion
KW  - location constraint
DO  - 10.3390/s18030698
ER  -
TY  - EJOU
AU  - Zhao, Yi
AU  - Ma, Jiale
AU  - Li, Xiaohui
AU  - Zhang, Jie
TI  - Saliency Detection and Deep Learning-Based Wildfire Identification in UAV Imagery
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 3
SN  - 1424-8220

AB  - An unmanned aerial vehicle (UAV) equipped with global positioning systems (GPS) can provide direct georeferenced imagery, mapping an area with high resolution. So far, the major difficulty in wildfire image classification is the lack of unified identification marks, the fire features of color, shape, texture (smoke, flame, or both) and background can vary significantly from one scene to another. Deep learning (e.g., DCNN for Deep Convolutional Neural Network) is very effective in high-level feature learning, however, a substantial amount of training images dataset is obligatory in optimizing its weights value and coefficients. In this work, we proposed a new saliency detection algorithm for fast location and segmentation of core fire area in aerial images. As the proposed method can effectively avoid feature loss caused by direct resizing; it is used in data augmentation and formation of a standard fire image dataset ‘UAV_Fire’. A 15-layered self-learning DCNN architecture named ‘Fire_Net’ is then presented as a self-learning fire feature exactor and classifier. We evaluated different architectures and several key parameters (drop out ratio, batch size, etc.) of the DCNN model regarding its validation accuracy. The proposed architecture outperformed previous methods by achieving an overall accuracy of 98%. Furthermore, ‘Fire_Net’ guarantied an average processing speed of 41.5 ms per image for real-time wildfire inspection. To demonstrate its practical utility, Fire_Net is tested on 40 sampled images in wildfire news reports and all of them have been accurately identified.
KW  - UAV
KW  - wildfire
KW  - deep learning
KW  - saliency detection
DO  - 10.3390/s18030712
ER  -
TY  - EJOU
AU  - Czúni, László
AU  - Rashad, Metwally
TI  - Lightweight Active Object Retrieval with Weak Classifiers
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 3
SN  - 1424-8220

AB  - In the last few years, there has been a steadily growing interest in autonomous vehicles and robotic systems. While many of these agents are expected to have limited resources, these systems should be able to dynamically interact with other objects in their environment. We present an approach where lightweight sensory and processing techniques, requiring very limited memory and processing power, can be successfully applied to the task of object retrieval using sensors of different modalities. We use the Hough framework to fuse optical and orientation information of the different views of the objects. In the presented spatio-temporal perception technique, we apply active vision, where, based on the analysis of initial measurements, the direction of the next view is determined to increase the hit-rate of retrieval. The performance of the proposed methods is shown on three datasets loaded with heavy noise.
KW  - object retrieval
KW  - Hough transformation
KW  - sensor fusion
KW  - active vision
DO  - 10.3390/s18030801
ER  -
TY  - EJOU
AU  - Ridolfi, Elena
AU  - Manciola, Piergiorgio
TI  - Water Level Measurements from Drones: A Pilot Case Study at a Dam Site
T2  - Water

PY  - 2018
VL  - 10
IS  - 3
SN  - 2073-4441

AB  - Unmanned Aerial Vehicles (UAVs) are now filling in the gaps between spaceborne and ground-based observations and enhancing the spatial resolution and temporal coverage of data acquisition. In the realm of hydrological observations, UAVs play a key role in quantitatively characterizing the surface flow, allowing for remotely accessing the water body of interest. In this paper, we propose a technology that uses a sensing platform encompassing a drone and a camera to determine the water level. The images acquired by means of the sensing platform are then analyzed using the Canny method to detect the edges of water level and of Ground Control Points (GCPs) used as reference points. The water level is then retrieved from images and compared to a benchmark value obtained by a traditional device. The method is tested at four locations in an artificial lake in central Italy. Results are encouraging, as the overall mean error between estimated and true water level values is around 0.05 m. This technology is well suited to improve hydraulic modeling and thus provides reliable support to flood mitigation strategies.
KW  - water level measurement
KW  - surface hydrology
KW  - images
KW  - unmanned aerial vehicle
KW  - drone
KW  - dam
DO  - 10.3390/w10030297
ER  -
TY  - EJOU
AU  - Wei, Jian
AU  - Liu, Feng
TI  - Online Learning of Discriminative Correlation Filter Bank for Visual Tracking
T2  - Information

PY  - 2018
VL  - 9
IS  - 3
SN  - 2078-2489

AB  - Accurate visual tracking is a challenging research topic in the field of computer vision. The challenge emanates from various issues, such as target deformation, background clutter, scale variations, and occlusion. In this setting, discriminative correlation filter (DCF)-based trackers have demonstrated excellent performance in terms of speed. However, existing correlation filter-based trackers cannot handle major changes in appearance due to severe occlusions, which eventually result in the development of a bounding box for target drift tracking. In this study, we use a set of DCFs called discriminative correlation filter bank (DCFB) for visual tracking to address the key causes of object occlusion and drift in a tracking-by-detection framework. In this work, we treat thxe current location of the target frame as the center, extract several samples around the target, and perform online learning of DCFB. The sliding window then extracts numerous samples within a large radius of the area where the object in the next frame is previously located. These samples are used for the DCFB to perform correlation operation in the Fourier domain to estimate the location of the new object; the coordinates of the largest correlation scores indicate the position of the new target. The DCFB is updated according to the location of the new target. Experimental results on the quantitative and qualitative evaluations on the challenging benchmark sequences show that the proposed framework improves tracking performance compared with several state-of-the-art trackers.
KW  - correlation score
KW  - visual tracking
KW  - discriminative correlation filter bank
KW  - occlusion
DO  - 10.3390/info9030061
ER  -
TY  - EJOU
AU  - Zhang, Duona
AU  - Ding, Wenrui
AU  - Zhang, Baochang
AU  - Xie, Chunyu
AU  - Li, Hongguang
AU  - Liu, Chunhui
AU  - Han, Jungong
TI  - Automatic Modulation Classification Based on Deep Learning for Unmanned Aerial Vehicles
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 3
SN  - 1424-8220

AB  - Deep learning has recently attracted much attention due to its excellent performance in processing audio, image, and video data. However, few studies are devoted to the field of automatic modulation classification (AMC). It is one of the most well-known research topics in communication signal recognition and remains challenging for traditional methods due to complex disturbance from other sources. This paper proposes a heterogeneous deep model fusion (HDMF) method to solve the problem in a unified framework. The contributions include the following: (1) a convolutional neural network (CNN) and long short-term memory (LSTM) are combined by two different ways without prior knowledge involved; (2) a large database, including eleven types of single-carrier modulation signals with various noises as well as a fading channel, is collected with various signal-to-noise ratios (SNRs) based on a real geographical environment; and (3) experimental results demonstrate that HDMF is very capable of coping with the AMC problem, and achieves much better performance when compared with the independent network.
KW  - deep learning
KW  - automatic modulation classification
KW  - classifier fusion
KW  - convolutional neural network
KW  - long short-term memory
DO  - 10.3390/s18030924
ER  -
TY  - EJOU
AU  - Pang, Jingyue
AU  - Liu, Datong
AU  - Peng, Yu
AU  - Peng, Xiyuan
TI  - Optimize the Coverage Probability of Prediction Interval for Anomaly Detection of Sensor-Based Monitoring Series
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 4
SN  - 1424-8220

AB  - Effective anomaly detection of sensing data is essential for identifying potential system failures. Because they require no prior knowledge or accumulated labels, and provide uncertainty presentation, the probability prediction methods (e.g., Gaussian process regression (GPR) and relevance vector machine (RVM)) are especially adaptable to perform anomaly detection for sensing series. Generally, one key parameter of prediction models is coverage probability (CP), which controls the judging threshold of the testing sample and is generally set to a default value (e.g., 90% or 95%). There are few criteria to determine the optimal CP for anomaly detection. Therefore, this paper designs a graphic indicator of the receiver operating characteristic curve of prediction interval (ROC-PI) based on the definition of the ROC curve which can depict the trade-off between the PI width and PI coverage probability across a series of cut-off points. Furthermore, the Youden index is modified to assess the performance of different CPs, by the minimization of which the optimal CP is derived by the simulated annealing (SA) algorithm. Experiments conducted on two simulation datasets demonstrate the validity of the proposed method. Especially, an actual case study on sensing series from an on-orbit satellite illustrates its significant performance in practical application.
KW  - satellite
KW  - anomaly detection
KW  - coverage probability
KW  - prediction interval
KW  - Gaussian process regression
KW  - relevance vector machine
DO  - 10.3390/s18040967
ER  -
TY  - EJOU
AU  - Lee, Yoo J.
AU  - Park, Chuljin
AU  - Lee, Mi L.
TI  - Identification of a Contaminant Source Location in a River System Using Random Forest Models
T2  - Water

PY  - 2018
VL  - 10
IS  - 4
SN  - 2073-4441

AB  - We consider the problem of identifying the source location of a contaminant via analyzing changes in concentration levels observed by a sensor network in a river system. To address this problem, we propose a framework including two main steps: (i) pre-processing data; and (ii) training and testing a classification model. Specifically, we first obtain a data set presenting concentration levels of a contaminant from a simulation model, and extract numerical characteristics from the data set. Then, random forest models are generated and assessed to identify the source location of a contaminant. By using the numerical characteristics from the prior step as their inputs, the models provide outputs representing the possibility, i.e., a value between 0 and 1, of a spill event at each candidate location. The performance of the framework is tested on a part of the Altamaha river system in the state of Georgia, United States of America.
KW  - contaminant
KW  - sensor network
KW  - river system
KW  - source identification
KW  - random forest
DO  - 10.3390/w10040391
ER  -
TY  - EJOU
AU  - Kim, KeumJi
AU  - Yoon, SeongHwan
TI  - Assessment of Building Damage Risk by Natural Disasters in South Korea Using Decision Tree Analysis
T2  - Sustainability

PY  - 2018
VL  - 10
IS  - 4
SN  - 2071-1050

AB  - The purpose of this study is to identify the relationship between weather variables and buildings damaged in natural disasters. We used four datasets on building damage history and 33 weather datasets from 230 regions in South Korea in a decision tree analysis to evaluate the risk of building damage. We generated the decision tree model to determine the risk of rain, gale, and typhoon (excluding gale with less damage). Using the weight and limit values of the weather variables derived using the decision tree model, the risk of building damage was assessed for 230 regions in South Korea until 2100. The number of regions at risk of rain damage increased by more than 30% on average. Conversely, regions at risk of damage from snowfall decreased by more than 90%. The regions at risk of typhoons decreased by 57.5% on average, while those at high risk of the same increased by up to 62.5% under RCP 8.5. The results of this study are highly fluid since they are based on the uncertainty of future climate change. However, the study is meaningful because it suggests a new method for assessing disaster risk using weather indices.
KW  - building damage
KW  - climate change scenario
KW  - decision tree analysis
KW  - natural disaster
KW  - risk assessment process
DO  - 10.3390/su10041072
ER  -
TY  - EJOU
AU  - Li, He
AU  - Liu, Gaohuan
AU  - Liu, Qingsheng
AU  - Chen, Zhongxin
AU  - Huang, Chong
TI  - Retrieval of Winter Wheat Leaf Area Index from Chinese GF-1 Satellite Data Using the PROSAIL Model
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 4
SN  - 1424-8220

AB  - Leaf area index (LAI) is one of the key biophysical parameters in crop structure. The accurate quantitative estimation of crop LAI is essential to verify crop growth and health. The PROSAIL radiative transfer model (RTM) is one of the most established methods for estimating crop LAI. In this study, a look-up table (LUT) based on the PROSAIL RTM was first used to estimate winter wheat LAI from GF-1 data, which accounted for some available prior knowledge relating to the distribution of winter wheat characteristics. Next, the effects of 15 LAI-LUT strategies with reflectance bands and 10 LAI-LUT strategies with vegetation indexes on the accuracy of the winter wheat LAI retrieval with different phenological stages were evaluated against in situ LAI measurements. The results showed that the LUT strategies of LAI-GNDVI were optimal and had the highest accuracy with a root mean squared error (RMSE) value of 0.34, and a coefficient of determination (R2) of 0.61 during the elongation stages, and the LUT strategies of LAI-Green were optimal with a RMSE of 0.74, and R2 of 0.20 during the grain-filling stages. The results demonstrated that the PROSAIL RTM had great potential in winter wheat LAI inversion with GF-1 satellite data and the performance could be improved by selecting the appropriate LUT inversion strategies in different growth periods.
KW  - leaf area index
KW  - PROSAIL
KW  - look-up table
KW  - GF-1
KW  - winter wheat
DO  - 10.3390/s18041120
ER  -
TY  - EJOU
AU  - Bowkett, Mark
AU  - Thanapalan, Kary
AU  - Constant, Ewen
TI  - Failure Detection of Composites with Control System Corrective Response in Drone System Applications
T2  - Computers

PY  - 2018
VL  - 7
IS  - 2
SN  - 2073-431X

AB  - The paper describes a novel method for the detection of damage in carbon composites as used in drone frames. When damage is detected a further novel corrective response is initiated in the quadcopter flight controller to switch from a four-arm control system to a three-arm control system. This is made possible as a symmetrical frame is utilized, which allows for a balanced weight distribution between both the undamaged quadcopter and the fallback tri-copter layout. The resulting work allows for continued flight where this was not previously possible. Further developing work includes improved flight stability with the aid of an underslung load model. This is beneficial to the quadcopter as a damaged arm attached to the main body by the motor wires behaves as an underslung load. The underslung load works are also transferable in a dual master and slave drone system where the master drone transports a smaller slave drone by a tether, which acts as an underslung load.
KW  - drone system
KW  - operational safety
KW  - controller design
KW  - failure detection
KW  - printed circuit board (PCB) design
DO  - 10.3390/computers7020023
ER  -
TY  - EJOU
AU  - Polvara, Riccardo
AU  - Sharma, Sanjay
AU  - Wan, Jian
AU  - Manning, Andrew
AU  - Sutton, Robert
TI  - Vision-Based Autonomous Landing of a Quadrotor on the Perturbed Deck of an Unmanned Surface Vehicle
T2  - Drones

PY  - 2018
VL  - 2
IS  - 2
SN  - 2504-446X

AB  - Autonomous landing on the deck of an unmanned surface vehicle (USV) is still a major challenge for unmanned aerial vehicles (UAVs). In this paper, a fiducial marker is located on the platform so as to facilitate the task since it is possible to retrieve its six-degrees of freedom relative-pose in an easy way. To compensate interruption in the marker’s observations, an extended Kalman filter (EKF) estimates the current USV’s position with reference to the last known position. Validation experiments have been performed in a simulated environment under various marine conditions. The results confirmed that the EKF provides estimates accurate enough to direct the UAV in proximity of the autonomous vessel such that the marker becomes visible again. Using only the odometry and the inertial measurements for the estimation, this method is found to be applicable even under adverse weather conditions in the absence of the global positioning system.
KW  - unmanned aerial vehicle
KW  - position control
KW  - computer vision
KW  - image processing
DO  - 10.3390/drones2020015
ER  -
TY  - EJOU
AU  - Al-Saddik, Hania
AU  - Laybros, Anthony
AU  - Billiot, Bastien
AU  - Cointault, Frederic
TI  - Using Image Texture and Spectral Reflectance Analysis to Detect Yellowness and Esca in Grapevines at Leaf-Level
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 4
SN  - 2072-4292

AB  - Plant diseases are one of the main reasons behind major economic and production losses in the agricultural field. Current research activities enable large fields monitoring and plant disease detection using innovative and robust technologies. French grapevines have a reputation for producing premium quality wines, however, these major fruit crops are susceptible to many diseases, including Esca, Downy mildew, Powdery mildew, Yellowing, and many others. In this study, we focused on two main infections (Esca and Yellowing), and data were gathered from fields that were located in Aquitaine and Burgundy regions, France. Since plant diseases can be diagnosed from the properties of the leaf, we acquired both Red-Green-Blue (RGB) digital image and hyperspectral reflectance data from infected and healthy leaves. Biophysical parameters that were produced by the PROSPECT model inversion together with texture parameters compiled from the literature were deduced. Then we investigated their relationship to damage caused by Yellowing and Esca. This study examined whether spectral and textural data can identify the two diseases through the use of Neural Networks. We obtained an overall accuracy of 99% for both of the diseases when textural and spectral data are combined. These results suggest that, first, biophysical parameters present a valid dimension reduction tool that could replace the use of complete hyperspectral data. Second, remote sensing using spectral reflectance and digital images can make an overall nondestructive, rapid, cost-effective, and reproducible technique to determine diseases in grapevines with a good level of accuracy.
KW  - spectra
KW  - PROSPECT
KW  - co-occurrence matrix
KW  - biophysical parameters
KW  - texture
KW  - classification
KW  - vineyard
KW  - diseases
DO  - 10.3390/rs10040618
ER  -
TY  - EJOU
AU  - Zhuo, Xiangyu
AU  - Fraundorfer, Friedrich
AU  - Kurz, Franz
AU  - Reinartz, Peter
TI  - Optimization of OpenStreetMap Building Footprints Based on Semantic Information of Oblique UAV Images
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 4
SN  - 2072-4292

AB  - Building footprint information is vital for 3D building modeling. Traditionally, in remote sensing, building footprints are extracted and delineated from aerial imagery and/or LiDAR point cloud. Taking a different approach, this paper is dedicated to the optimization of OpenStreetMap (OSM) building footprints exploiting the contour information, which is derived from deep learning-based semantic segmentation of oblique images acquired by the Unmanned Aerial Vehicle (UAV). First, a simplified 3D building model of Level of Detail 1 (LoD 1) is initialized using the footprint information from OSM and the elevation information from Digital Surface Model (DSM). In parallel, a deep neural network for pixel-wise semantic image segmentation is trained in order to extract the building boundaries as contour evidence. Subsequently, an optimization integrating the contour evidence from multi-view images as a constraint results in a refined 3D building model with optimized footprints and height. Our method is leveraged to optimize OSM building footprints for four datasets with different building types, demonstrating robust performance for both individual buildings and multiple buildings regardless of image resolution. Finally, we compare our result with reference data from German Authority Topographic-Cartographic Information System (ATKIS). Quantitative and qualitative evaluations reveal that the original OSM building footprints have large offset, but can be significantly improved from meter level to decimeter level after optimization.
KW  - building footprint
KW  - oblique UAV images
KW  - semantic segmentation
KW  - deep neural network
DO  - 10.3390/rs10040624
ER  -
TY  - EJOU
AU  - Manfreda, Salvatore
AU  - McCabe, Matthew F.
AU  - Miller, Pauline E.
AU  - Lucas, Richard
AU  - Pajuelo Madrigal, Victor
AU  - Mallinis, Giorgos
AU  - Ben Dor, Eyal
AU  - Helman, David
AU  - Estes, Lyndon
AU  - Ciraolo, Giuseppe
AU  - Müllerová, Jana
AU  - Tauro, Flavia
AU  - De Lima, M. I.
AU  - De Lima, João L. M. P.
AU  - Maltese, Antonino
AU  - Frances, Felix
AU  - Caylor, Kelly
AU  - Kohv, Marko
AU  - Perks, Matthew
AU  - Ruiz-Pérez, Guiomar
AU  - Su, Zhongbo
AU  - Vico, Giulia
AU  - Toth, Brigitta
TI  - On the Use of Unmanned Aerial Systems for Environmental Monitoring
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 4
SN  - 2072-4292

AB  - Environmental monitoring plays a central role in diagnosing climate and management impacts on natural and agricultural systems; enhancing the understanding of hydrological processes; optimizing the allocation and distribution of water resources; and assessing, forecasting, and even preventing natural disasters. Nowadays, most monitoring and data collection systems are based upon a combination of ground-based measurements, manned airborne sensors, and satellite observations. These data are utilized in describing both small- and large-scale processes, but have spatiotemporal constraints inherent to each respective collection system. Bridging the unique spatial and temporal divides that limit current monitoring platforms is key to improving our understanding of environmental systems. In this context, Unmanned Aerial Systems (UAS) have considerable potential to radically improve environmental monitoring. UAS-mounted sensors offer an extraordinary opportunity to bridge the existing gap between field observations and traditional air- and space-borne remote sensing, by providing high spatial detail over relatively large areas in a cost-effective way and an entirely new capacity for enhanced temporal retrieval. As well as showcasing recent advances in the field, there is also a need to identify and understand the potential limitations of UAS technology. For these platforms to reach their monitoring potential, a wide spectrum of unresolved issues and application-specific challenges require focused community attention. Indeed, to leverage the full potential of UAS-based approaches, sensing technologies, measurement protocols, postprocessing techniques, retrieval algorithms, and evaluation techniques need to be harmonized. The aim of this paper is to provide an overview of the existing research and applications of UAS in natural and agricultural ecosystem monitoring in order to identify future directions, applications, developments, and challenges.
KW  - UAS
KW  - remote sensing
KW  - environmental monitoring
KW  - precision agriculture
KW  - vegetation indices
KW  - soil moisture
KW  - river monitoring
DO  - 10.3390/rs10040641
ER  -
TY  - EJOU
AU  - Krylov, Vladimir A.
AU  - Kenny, Eamonn
AU  - Dahyot, Rozenn
TI  - Automatic Discovery and Geotagging of Objects from Street View Imagery
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 5
SN  - 2072-4292

AB  - Many applications, such as autonomous navigation, urban planning, and asset monitoring, rely on the availability of accurate information about objects and their geolocations. In this paper, we propose the automatic detection and computation of the coordinates of recurring stationary objects of interest using street view imagery. Our processing pipeline relies on two fully convolutional neural networks: the first segments objects in the images, while the second estimates their distance from the camera. To geolocate all the detected objects coherently we propose a novel custom Markov random field model to estimate the objects&rsquo; geolocation. The novelty of the resulting pipeline is the combined use of monocular depth estimation and triangulation to enable automatic mapping of complex scenes with the simultaneous presence of multiple, visually similar objects of interest. We validate experimentally the effectiveness of our approach on two object classes: traffic lights and telegraph poles. The experiments report high object recall rates and position precision of approximately 2 m, which is approaching the precision of single-frequency GPS receivers.
KW  - object geolocation
KW  - object mapping
KW  - street view imagery
KW  - Markov random fields
KW  - traffic lights
KW  - telecom assets
KW  - GPS estimation
DO  - 10.3390/rs10050661
ER  -
TY  - EJOU
AU  - Na, Wongi S.
AU  - Baek, Jongdae
TI  - A Review of the Piezoelectric Electromechanical Impedance Based Structural Health Monitoring Technique for Engineering Structures
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 5
SN  - 1424-8220

AB  - The birth of smart materials such as piezoelectric (PZT) transducers has aided in revolutionizing the field of structural health monitoring (SHM) based on non-destructive testing (NDT) methods. While a relatively new NDT method known as the electromechanical (EMI) technique has been investigated for more than two decades, there are still various problems that must be solved before it is applied to real structures. The technique, which has a significant potential to contribute to the creation of one of the most effective SHM systems, involves the use of a single PZT for exciting and sensing of the host structure. In this paper, studies applied for the past decade related to the EMI technique have been reviewed to understand its trend. In addition, new concepts and ideas proposed by various authors are also surveyed, and the paper concludes with a discussion of the potential directions for future works.
KW  - structural health monitoring
KW  - piezoelectric transducers
KW  - electromechanical impedance
KW  - non-destructive testing
KW  - impedance-based health monitoring
DO  - 10.3390/s18051307
ER  -
TY  - EJOU
AU  - De Simone, Marco C.
AU  - Rivera, Zandra B.
AU  - Guida, Domenico
TI  - Obstacle Avoidance System for Unmanned Ground Vehicles by Using Ultrasonic Sensors
T2  - Machines

PY  - 2018
VL  - 6
IS  - 2
SN  - 2075-1702

AB  - Artificial intelligence is the ability of a computer to perform the functions and reasoning typical of the human mind. In its purely informatic aspect, it includes the theory and techniques for the development of algorithms that allow machines to show an intelligent ability and/or perform an intelligent activity, at least in specific areas. In particular, there are automatic learning algorithms based on the same mechanisms that are thought to be the basis of all the cognitive processes developed by the human brain. Such a powerful tool has already started to produce a new class of self-driving vehicles. With the projections of population growth that will increase until the year 2100 up to 11.2 billion, research on innovating agricultural techniques must be continued. In order to improve the efficiency regarding precision agriculture, the use of autonomous agricultural machines must become an important issue. For this reason, it was decided to test the use of the &ldquo;Neural Network Toolbox&rdquo; tool already present in MATLAB to design an artificial neural network with supervised learning suitable for classification and pattern recognition by using data collected by an ultrasonic sensor. The idea is to use such a protocol to retrofit kits for agricultural machines already present on the market.
KW  - object recognition
KW  - neural network
KW  - unmanned vehicle
KW  - MATLAB
KW  - ultrasonic sensors
DO  - 10.3390/machines6020018
ER  -
TY  - EJOU
AU  - Chen, Xi
AU  - Kopsaftopoulos, Fotis
AU  - Wu, Qi
AU  - Ren, He
AU  - Chang, Fu-Kuo
TI  - Flight State Identification of a Self-Sensing Wing via an Improved Feature Selection Method and Machine Learning Approaches
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 5
SN  - 1424-8220

AB  - In this work, a data-driven approach for identifying the flight state of a self-sensing wing structure with an embedded multi-functional sensing network is proposed. The flight state is characterized by the structural vibration signals recorded from a series of wind tunnel experiments under varying angles of attack and airspeeds. A large feature pool is created by extracting potential features from the signals covering the time domain, the frequency domain as well as the information domain. Special emphasis is given to feature selection in which a novel filter method is developed based on the combination of a modified distance evaluation algorithm and a variance inflation factor. Machine learning algorithms are then employed to establish the mapping relationship from the feature space to the practical state space. Results from two case studies demonstrate the high identification accuracy and the effectiveness of the model complexity reduction via the proposed method, thus providing new perspectives of self-awareness towards the next generation of intelligent air vehicles.
KW  - self-sensing wing
KW  - feature extraction
KW  - feature selection
KW  - flight state identification
KW  - machine learning
DO  - 10.3390/s18051379
ER  -
TY  - EJOU
AU  - Moy de Vitry, Matthew
AU  - Schindler, Konrad
AU  - Rieckermann, Jörg
AU  - Leitão, João P.
TI  - Sewer Inlet Localization in UAV Image Clouds: Improving Performance with Multiview Detection
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 5
SN  - 2072-4292

AB  - Sewer and drainage infrastructure are often not as well catalogued as they should be, considering the immense investment they represent. In this work, we present a fully automatic framework for localizing sewer inlets from image clouds captured from an unmanned aerial vehicle (UAV). The framework exploits the high image overlap of UAV imaging surveys with a multiview approach to improve detection performance. The framework uses a Viola–Jones classifier trained to detect sewer inlets in aerial images with a ground sampling distance of 3–3.5 cm/pixel. The detections are then projected into three-dimensional space where they are clustered and reclassified to discard false positives. The method is evaluated by cross-validating results from an image cloud of 252 UAV images captured over a 0.57-km2 study area with 228 sewer inlets. Compared to an equivalent single-view detector, the multiview approach improves both recall and precision, increasing average precision from 0.65 to 0.73. The source code and case study data are publicly available for reuse.
KW  - infrastructure mapping
KW  - multiview
KW  - object detection
KW  - unmanned aerial vehicle
KW  - urban drainage
KW  - asset management
DO  - 10.3390/rs10050706
ER  -
TY  - EJOU
AU  - Kamminga, Jacob
AU  - Ayele, Eyuel
AU  - Meratnia, Nirvana
AU  - Havinga, Paul
TI  - Poaching Detection Technologies—A Survey
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 5
SN  - 1424-8220

AB  - Between 1960 and 1990, 95% of the black rhino population in the world was killed. In South Africa, a rhino was killed every 8 h for its horn throughout 2016. Wild animals, rhinos and elephants, in particular, are facing an ever increasing poaching crisis. In this paper, we review poaching detection technologies that aim to save endangered species from extinction. We present requirements for effective poacher detection and identify research challenges through the survey. We describe poaching detection technologies in four domains: perimeter based, ground based, aerial based, and animal tagging based technologies. Moreover, we discuss the different types of sensor technologies that are used in intruder detection systems such as: radar, magnetic, acoustic, optic, infrared and thermal, radio frequency, motion, seismic, chemical, and animal sentinels. The ultimate long-term solution for the poaching crisis is to remove the drivers of demand by educating people in demanding countries and raising awareness of the poaching crisis. Until prevention of poaching takes effect, there will be a continuous urgent need for new (combined) approaches that take up the research challenges and provide better protection against poaching in wildlife areas.
KW  - anti-poaching
KW  - conservation
KW  - surveillance
KW  - intruder detetection
DO  - 10.3390/s18051474
ER  -
TY  - EJOU
AU  - Deng, Zhipeng
AU  - Sun, Hao
AU  - Zhou, Shilin
TI  - Semi-Supervised Ground-to-Aerial Adaptation with Heterogeneous Features Learning for Scene Classification
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 5
SN  - 2220-9964

AB  - Currently, huge quantities of remote sensing images (RSIs) are becoming available. Nevertheless, the scarcity of labeled samples hinders the semantic understanding of RSIs. Fortunately, many ground-level image datasets with detailed semantic annotations have been collected in the vision community. In this paper, we attempt to exploit the abundant labeled ground-level images to build discriminative models for overhead-view RSI classification. However, images from the ground-level and overhead view are represented by heterogeneous features with different distributions; how to effectively combine multiple features and reduce the mismatch of distributions are two key problems in this scene-model transfer task. Specifically, a semi-supervised manifold-regularized multiple-kernel-learning (SMRMKL) algorithm is proposed for solving these problems. We employ multiple kernels over several features to learn an optimal combined model automatically. Multi-kernel Maximum Mean Discrepancy (MK-MMD) is utilized to measure the data mismatch. To make use of unlabeled target samples, a manifold regularized semi-supervised learning process is incorporated into our framework. Extensive experimental results on both cross-view and aerial-to-satellite scene datasets demonstrate that: (1) SMRMKL has an appealing extension ability to effectively fuse different types of visual features; and (2) manifold regularization can improve the adaptation performance by utilizing unlabeled target samples.
KW  - remote sensing
KW  - scene classification
KW  - heterogeneous domain adaptation
KW  - cross-view
KW  - multiple kernel learning
DO  - 10.3390/ijgi7050182
ER  -
TY  - EJOU
AU  - Lee, Junghee
AU  - Im, Jungho
AU  - Kim, Kyungmin
AU  - Quackenbush, Lindi J.
TI  - Machine Learning Approaches for Estimating Forest Stand Height Using Plot-Based Observations and Airborne LiDAR Data
T2  - Forests

PY  - 2018
VL  - 9
IS  - 5
SN  - 1999-4907

AB  - Effective sustainable forest management for broad areas needs consistent country-wide forest inventory data. A stand-level inventory is appropriate as a minimum unit for local and regional forest management. South Korea currently produces a forest type map that contains only four categorical parameters. Stand height is a crucial forest attribute for understanding forest ecosystems that is currently missing and should be included in future forest type maps. Estimation of forest stand height is challenging in South Korea because stands exist in small and irregular patches on highly rugged terrain. In this study, we proposed stand height estimation models suitable for rugged terrain with highly mixed tree species. An arithmetic mean height was used as a target variable. Plot-level height estimation models were first developed using 20 descriptive statistics from airborne Light Detection and Ranging (LiDAR) data and three machine learning approaches—support vector regression (SVR), modified regression trees (RT) and random forest (RF). Two schemes (i.e., central plot-based (Scheme 1) and stand-based (Scheme 2)) for expanding from the plot level to the stand level were then investigated. The results showed varied performance metrics (i.e., coefficient of determination, root mean square error, and mean bias) by model for forest height estimation at the plot level. There was no statistically significant difference among the three mean plot height models (i.e., SVR, RT and RF) in terms of estimated heights and bias (p-values &gt; 0.05). The stand-level validation based on all tree measurements for three selected stands produced varied results by scheme and machine learning used. It implies that additional reference data should be used for a more thorough stand-level validation to identify statistically robust approaches in the future. Nonetheless, the research findings from this study can be used as a guide for estimating stand heights for forests in rugged terrain and with complex composition of tree species.
KW  - forest stand height
KW  - plot-level to stand-level expansion methods
KW  - airborne LiDAR
KW  - machine learning
DO  - 10.3390/f9050268
ER  -
TY  - EJOU
AU  - Louargant, Marine
AU  - Jones, Gawain
AU  - Faroux, Romain
AU  - Paoli, Jean-Noël
AU  - Maillot, Thibault
AU  - Gée, Christelle
AU  - Villette, Sylvain
TI  - Unsupervised Classification Algorithm for Early Weed Detection in Row-Crops by Combining Spatial and Spectral Information
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 5
SN  - 2072-4292

AB  - In agriculture, reducing herbicide use is a challenge to reduce health and environmental risks while maintaining production yield and quality. Site-specific weed management is a promising way to reach this objective but requires efficient weed detection methods. In this paper, an automatic image processing has been developed to discriminate between crop and weed pixels combining spatial and spectral information extracted from four-band multispectral images. Image data was captured at 3 m above ground, with a camera (multiSPEC 4C, AIRINOV, Paris) mounted on a pole kept manually. For each image, the field of view was approximately 4 m × 3 m and the resolution was 6 mm/pix. The row crop arrangement was first used to discriminate between some crop and weed pixels depending on their location inside or outside of crop rows. Then, these pixels were used to automatically build the training dataset concerning the multispectral features of crop and weed pixel classes. For each image, a specific training dataset was used by a supervised classifier (Support Vector Machine) to classify pixels that cannot be correctly discriminated using only the initial spatial approach. Finally, inter-row pixels were classified as weed and in-row pixels were classified as crop or weed depending on their spectral characteristics. The method was assessed on 14 images captured on maize and sugar beet fields. The contribution of the spatial, spectral and combined information was studied with respect to the classification quality. Our results show the better ability of the spatial and spectral combination algorithm to detect weeds between and within crop rows. They demonstrate the improvement of the weed detection rate and the improvement of its robustness. On all images, the mean value of the weed detection rate was 89% for spatial and spectral combination method, 79% for spatial method, and 75% for spectral method. Moreover, our work shows that the plant in-line sowing can be used to design an automatic image processing and classification algorithm to detect weed without requiring any manual data selection and labelling. Since the method required crop row identification, the method is suitable for wide-row crops and high spatial resolution images (at least 6 mm/pix).
KW  - weed detection
KW  - image processing
KW  - spatial information
KW  - multispectral information
KW  - automatic training data set generation
KW  - SVM
DO  - 10.3390/rs10050761
ER  -
TY  - EJOU
AU  - Sukhova, Ekaterina
AU  - Sukhov, Vladimir
TI  - Connection of the Photochemical Reflectance Index (PRI) with the Photosystem II Quantum Yield and Nonphotochemical Quenching Can Be Dependent on Variations of Photosynthetic Parameters among Investigated Plants: A Meta-Analysis
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 5
SN  - 2072-4292

AB  - The development of spectral methods of remote sensing, including measurement of a photochemical reflectance index (PRI), is a prospective trend in precision agriculture. There are many works which have investigated the connection between photosynthetic parameters and PRI; however, their results varied and were sometimes contradictory. For this paper, we performed a meta-analysis of works in this field. Here, only linear correlations of PRI with photosynthetic parameters—including quantum yield of photosystem II (ΔF/Fm’), nonphotochemical quenching of chlorophyll fluorescence (NPQ), and light use efficiency (LUE)—were investigated. First, it was shown that the correlations were dependent on conditions of PRI measurements (leaf or canopy; artificial light or sunlight). Second, it was shown that a minimal level of the photosynthetic stress, and the variation of this level among investigated plants, can influence the linear correlation of PRI with ΔF/Fm’ and NPQ; the effect was dependent on conditions of measurements. In contrast, the distribution of LUE among plants did not influence its correlation with PRI. Thus, the meta-analysis shows that the distribution of photosynthetic parameters among investigated plants can be an important factor that influences the efficiency of remote sensing on the basis of the PRI measurement.
KW  - light use efficiency
KW  - meta-analysis
KW  - nonphotochemical quenching
KW  - photochemical reflectance index
KW  - photosynthesis
KW  - plant
KW  - PRI
KW  - quantum yield of photosystem II
KW  - remote sensing
DO  - 10.3390/rs10050771
ER  -
TY  - EJOU
AU  - Li, Dan
AU  - Gu, Xingfa
AU  - Pang, Yong
AU  - Chen, Bowei
AU  - Liu, Luxia
TI  - Estimation of Forest Aboveground Biomass and Leaf Area Index Based on Digital Aerial Photograph Data in Northeast China
T2  - Forests

PY  - 2018
VL  - 9
IS  - 5
SN  - 1999-4907

AB  - Forest aboveground biomass (AGB) and leaf area index (LAI) are two important parameters for evaluating forest growth and health. It is of great significance to estimate AGB and LAI accurately using remote sensing technology. Considering the temporal resolution and data acquisition costs, digital aerial photographs (DAPs) from a digital camera mounted on an unmanned aerial vehicle or light, small aircraft have been widely used in forest inventory. In this study, the aerial photograph data was acquired on 5 and 9 June, 2017 by a Hasselblad60 digital camera of the CAF-LiCHy system in a Y-5 aircraft in the Mengjiagang forest farm of Northeast China, and the digital orthophoto mosaic (DOM) and photogrammetric point cloud (PPC) were generated from an aerial overlap photograph. Forest red-green-blue (RGB) vegetation indices and textural factors were extracted from the DOM. Forest vertical structure features and canopy cover were extracted from normalized PPC. Regression analysis was carried out considering only DOM data, only PPC data, and a combination of both. A recursive feature elimination (RFE) method using a random forest was used for variable selection. Four different machine-learning (ML) algorithms (random forest, k-nearest neighbor, Cubist and supporting vector machine) were used to build regression models. Experimental results showed that PPC data alone could estimate AGB, and DOM data alone could estimate LAI with relatively high accuracy. The combination of features from DOM and PPC data was the most effective, in all the experiments considered, for the estimation of AGB and LAI. The results showed that the height and coverage variables of PPC, texture mean value, and the visible differential vegetation index (VDVI) of the DOM are significantly related to the estimated AGB (R2 = 0.73, RMSE = 20 t/ha). The results also showed that the canopy cover of PPC and green red ratio index (GRRI) of DOM are the most strongly related to the estimated LAI, and the height and coverage variables of PPC, the texture mean value and visible atmospherically resistant index (VARI), and the VDVI of DOM followed (R2 = 0.79, RMSE = 0.48).
KW  - digital aerial photograph
KW  - aboveground biomass
KW  - leaf area index
KW  - photogrammetric point cloud
KW  - recursive feature elimination
KW  - machine-learning
DO  - 10.3390/f9050275
ER  -
TY  - EJOU
AU  - Liu, Xiaofei
AU  - Yang, Tao
AU  - Li, Jing
TI  - Real-Time Ground Vehicle Detection in Aerial Infrared Imagery Based on Convolutional Neural Network
T2  - Electronics

PY  - 2018
VL  - 7
IS  - 6
SN  - 2079-9292

AB  - An infrared sensor is a commonly used imaging device. Unmanned aerial vehicles, the most promising moving platform, each play a vital role in their own field, respectively. However, the two devices are seldom combined in automatic ground vehicle detection tasks. Therefore, how to make full use of them&mdash;especially in ground vehicle detection based on aerial imagery&ndash;has aroused wide academic concern. However, due to the aerial imagery&rsquo;s low-resolution and the vehicle detection&rsquo;s complexity, how to extract remarkable features and handle pose variations, view changes as well as surrounding radiation remains a challenge. In fact, these typical abstract features extracted by convolutional neural networks are more recognizable than the engineering features, and those complex conditions involved can be learned and memorized before. In this paper, a novel approach towards ground vehicle detection in aerial infrared images based on a convolutional neural network is proposed. The UAV and the infrared sensor used in this application are firstly introduced. Then, a novel aerial moving platform is built and an aerial infrared vehicle dataset is unprecedentedly constructed. We publicly release this dataset (NPU_CS_UAV_IR_DATA), which can be used for the following research in this field. Next, an end-to-end convolutional neural network is built. With large amounts of recognized features being iteratively learned, a real-time ground vehicle model is constructed. It has the unique ability to detect both the stationary vehicles and moving vehicles in real urban environments. We evaluate the proposed algorithm on some low&ndash;resolution aerial infrared images. Experiments on the NPU_CS_UAV_IR_DATA dataset demonstrate that the proposed method is effective and efficient to recognize the ground vehicles. Moreover it can accomplish the task in real-time while achieving superior performances in leak and false alarm ratio.
KW  - aerial infrared imagery
KW  - real-time ground vehicle detection
KW  - convolutional neural network
KW  - unmanned aerial vehicle
DO  - 10.3390/electronics7060078
ER  -
TY  - EJOU
AU  - Nguyen, Phong H.
AU  - Arsalan, Muhammad
AU  - Koo, Ja H.
AU  - Naqvi, Rizwan A.
AU  - Truong, Noi Q.
AU  - Park, Kang R.
TI  - LightDenseYOLO: A Fast and Accurate Marker Tracker for Autonomous UAV Landing by Visible Light Camera Sensor on Drone
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 6
SN  - 1424-8220

AB  - Autonomous landing of an unmanned aerial vehicle or a drone is a challenging problem for the robotics research community. Previous researchers have attempted to solve this problem by combining multiple sensors such as global positioning system (GPS) receivers, inertial measurement unit, and multiple camera systems. Although these approaches successfully estimate an unmanned aerial vehicle location during landing, many calibration processes are required to achieve good detection accuracy. In addition, cases where drones operate in heterogeneous areas with no GPS signal should be considered. To overcome these problems, we determined how to safely land a drone in a GPS-denied environment using our remote-marker-based tracking algorithm based on a single visible-light-camera sensor. Instead of using hand-crafted features, our algorithm includes a convolutional neural network named lightDenseYOLO to extract trained features from an input image to predict a marker&rsquo;s location by visible light camera sensor on drone. Experimental results show that our method significantly outperforms state-of-the-art object trackers both using and not using convolutional neural network in terms of both accuracy and processing time.
KW  - unmanned aerial vehicle
KW  - autonomous landing
KW  - real-time marker detection
KW  - lightDenseYOLO
KW  - visible light camera sensor on drone
DO  - 10.3390/s18061703
ER  -
TY  - EJOU
AU  - Akram, Muhammad A.
AU  - Liu, Peilin
AU  - Wang, Yuze
AU  - Qian, Jiuchao
TI  - GNSS Positioning Accuracy Enhancement Based on Robust Statistical MM Estimation Theory for Ground Vehicles in Challenging Environments
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 6
SN  - 2076-3417

AB  - Global Navigation Satellite System (GNSS) is the most reliable navigation system for location-based applications where accuracy and consistency is an essential requirement. The LSE (least squares estimator) has been used since the start of GNSS for position estimation. However; LSE is affected by outliers and errors in GNSS measurements and results in wrong user position. In this paper; we proposed a novel three-phase estimator for enhancing GNSS positioning accuracy in the presence of outliers and errors; relying upon the robust MM estimation theory. In the first phase; a subsampling process is proposed on available observations. IRWLS (iterative reweighted LS) is applied to all subsamples up to a predefined number of observations to obtain a positioning estimate and a scale factor. Secondly; IRWLS is applied up to the convergence point on a set of selected subsamples. The third phase involves the selection of optimum positioning solution having minimum scale factor. An outlier detection and exclusion process is applied on a probabilistic set of outlying observations to maintain the integrity and reliability of the position. Multiple simulated and real scenarios are tested. Results show high accuracy and reliability of the proposed algorithm in challenging environments.
KW  - multi-GNSS
KW  - GNSS navigation
KW  - LSE
KW  - IRWLS
KW  - urban canyon
KW  - outliers
KW  - MM estimation
DO  - 10.3390/app8060876
ER  -
TY  - EJOU
AU  - Zhu, Jiasong
AU  - Sun, Ke
AU  - Jia, Sen
AU  - Lin, Weidong
AU  - Hou, Xianxu
AU  - Liu, Bozhi
AU  - Qiu, Guoping
TI  - Bidirectional Long Short-Term Memory Network for Vehicle Behavior Recognition
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 6
SN  - 2072-4292

AB  - Vehicle behavior recognition is an attractive research field which is useful for many computer vision and intelligent traffic analysis tasks. This paper presents an all-in-one behavior recognition framework for moving vehicles based on the latest deep learning techniques. Unlike traditional traffic analysis methods which rely on low-resolution videos captured by road cameras, we capture 4K (    3840 × 2178    ) traffic videos at a busy road intersection of a modern megacity by flying a unmanned aerial vehicle (UAV) during the rush hours. We then manually annotate locations and types of road vehicles. The proposed method consists of the following three steps: (1) vehicle detection and type recognition based on deep neural networks; (2) vehicle tracking by data association and vehicle trajectory modeling; (3) vehicle behavior recognition by nearest neighbor search and by bidirectional long short-term memory network, respectively. This paper also presents experimental results of the proposed framework in comparison with state-of-the-art approaches on the 4K testing traffic video, which demonstrated the effectiveness and superiority of the proposed method.
KW  - unmanned aerial vehicles (UAVs)
KW  - deep neural networks
KW  - vehicle detection
KW  - vehicle tracking
KW  - behavior recognition
KW  - long short-term memory
DO  - 10.3390/rs10060887
ER  -
TY  - EJOU
AU  - Gao, Lipeng
AU  - Shi, Wenzhong
AU  - Miao, Zelang
AU  - Lv, Zhiyong
TI  - Method Based on Edge Constraint and Fast Marching for Road Centerline Extraction from Very High-Resolution Remote Sensing Images
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 6
SN  - 2072-4292

AB  - In recent decades, road extraction from very high-resolution (VHR) remote sensing images has become popular and has attracted extensive research efforts. However, the very high spatial resolution, complex urban structure, and contextual background effect of road images complicate the process of road extraction. For example, shadows, vehicles, or other objects may occlude a road located in a developed urban area. To address the problem of occlusion, this study proposes a semiautomatic approach for road extraction from VHR remote sensing images. First, guided image filtering is employed to reduce the negative effects of nonroad pixels while preserving edge smoothness. Then, an edge-constraint-based weighted fusion model is adopted to trace and refine the road centerline. An edge-constraint fast marching method, which sequentially links discrete seed points, is presented to maintain road-point connectivity. Six experiments with eight VHR remote sensing images (spatial resolution of 0.3 m/pixel to 2 m/pixel) are conducted to evaluate the efficiency and robustness of the proposed approach. Compared with state-of-the-art methods, the proposed approach presents superior extraction quality, time consumption, and seed-point requirements.
KW  - road extraction
KW  - very high-resolution image
KW  - fast marching method
KW  - semiautomatic
KW  - edge constraint
DO  - 10.3390/rs10060900
ER  -
TY  - EJOU
AU  - Kim, In-Ho
AU  - Jeon, Haemin
AU  - Baek, Seung-Chan
AU  - Hong, Won-Hwa
AU  - Jung, Hyung-Jo
TI  - Application of Crack Identification Techniques for an Aging Concrete Bridge Inspection Using an Unmanned Aerial Vehicle
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 6
SN  - 1424-8220

AB  - Bridge inspection using unmanned aerial vehicles (UAV) with high performance vision sensors has received considerable attention due to its safety and reliability. As bridges become obsolete, the number of bridges that need to be inspected increases, and they require much maintenance cost. Therefore, a bridge inspection method based on UAV with vision sensors is proposed as one of the promising strategies to maintain bridges. In this paper, a crack identification method by using a commercial UAV with a high resolution vision sensor is investigated in an aging concrete bridge. First, a point cloud-based background model is generated in the preliminary flight. Then, cracks on the structural surface are detected with the deep learning algorithm, and their thickness and length are calculated. In the deep learning method, region with convolutional neural networks (R-CNN)-based transfer learning is applied. As a result, a new network for the 384 collected crack images of 256 &times; 256 pixel resolution is generated from the pre-trained network. A field test is conducted to verify the proposed approach, and the experimental results proved that the UAV-based bridge inspection is effective at identifying and quantifying the cracks on the structures.
KW  - crack identification
KW  - deep learning
KW  - unmanned aerial vehicle (UAV)
KW  - computer vision
KW  - spatial information
DO  - 10.3390/s18061881
ER  -
TY  - EJOU
AU  - Zhou, Yi
AU  - Zhang, Rui
AU  - Wang, Shixin
AU  - Wang, Futao
TI  - Feature Selection Method Based on High-Resolution Remote Sensing Images and the Effect of Sensitive Features on Classification Accuracy
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - With the advent of high spatial resolution remote sensing imagery, numerous image features can be utilized. Applying a reasonable feature selection approach is critical to effectively reduce feature redundancy and improve the efficiency and accuracy of classification. This paper proposes a novel feature selection approach, in which ReliefF, genetic algorithm, and support vector machine (RFGASVM) are integrated to extract buildings. We adopt the ReliefF algorithm to preliminary filter high-dimensional features in the feature database. After eliminating the sorted features, the feature subset and the C and &gamma; parameters of support vector machine (SVM) are encoded into the chromosome of the genetic algorithm. A fitness function is constructed considering the sample identification accuracy, the number of selected features, and the feature cost. The proposed method was applied to high-resolution images obtained from different sensors, GF-2, BJ-2, and unmanned aerial vehicles (UAV). The confusion matrix, precision, recall and F1-score were applied to assess the accuracy. The results showed that the proposed method achieved feature reduction, and the overall accuracy (OA) was more than 85%, with Kappa coefficient values of 0.80, 0.83 and 0.85, respectively. The precision of each image was more than 85%. The time efficiency of the proposed method was two-fold greater than SVM with all the features. The RFGASVM method has the advantages of large feature reduction and high extraction performance and can be applied in feature selection.
KW  - SVM
KW  - feature selection
KW  - genetic algorithm
KW  - object-based
KW  - accuracy evaluation
DO  - 10.3390/s18072013
ER  -
TY  - EJOU
AU  - Wu, Yunpeng
AU  - Qin, Yong
AU  - Wang, Zhipeng
AU  - Jia, Limin
TI  - A UAV-Based Visual Inspection Method for Rail Surface Defects
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 7
SN  - 2076-3417

AB  - Rail surface defects seriously affect the safety of railway systems. At present, human inspection and rail vehicle inspection are the main approaches for the detection of rail surface defects. However, there are many shortcomings to these approaches, such as low efficiency, high cost, and so on. This paper presents a novel visual inspection approach based on unmanned aerial vehicle (UAV) images, and focuses on two key issues of UAV-based rail images: image enhancement and defects segmentation. With regards to the first aspect, a novel image enhancement algorithm named Local Weber-like Contrast (LWLC) is proposed to enhance rail images. The rail surface defects and backgrounds can be highlighted and homogenized under various sunlight intensity by LWLC, due to its illuminance independent, local nonlinear and other advantages. With regards to the second, a new threshold segmentation method named gray stretch maximum entropy (GSME) is presented in this paper. The proposed GSME method emphasizes gray stretch and de-noising on UAV-based rail images, and selects an optimal segmentation threshold for defects detection. Two visual comparison experiments were carried out to demonstrate the efficiency of the proposed methods. Finally, a quantitative comparison experiment shows the LWLC-GSME model achieves a recall of 93.75% for T-I defects and of 94.26% for T-II defects. Therefore, LWLC for image enhancement, in conjunction with GSME for defects segmentation, is efficient and feasible for the detection of rail surface defects based on UAV Images.
KW  - rail surface defect
KW  - UAV image
KW  - defect detection
KW  - gray stretch maximum entropy
KW  - image enhancement
KW  - defect segmentation
DO  - 10.3390/app8071028
ER  -
TY  - EJOU
AU  - Rivas, Alberto
AU  - Chamoso, Pablo
AU  - González-Briones, Alfonso
AU  - Corchado, Juan M.
TI  - Detection of Cattle Using Drones and Convolutional Neural Networks
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - Multirotor drones have been one of the most important technological advances of the last decade. Their mechanics are simple compared to other types of drones and their possibilities in flight are greater. For example, they can take-off vertically. Their capabilities have therefore brought progress to many professional activities. Moreover, advances in computing and telecommunications have also broadened the range of activities in which drones may be used. Currently, artificial intelligence and information analysis are the main areas of research in the field of computing. The case study presented in this article employed artificial intelligence techniques in the analysis of information captured by drones. More specifically, the camera installed in the drone took images which were later analyzed using Convolutional Neural Networks (CNNs) to identify the objects captured in the images. In this research, a CNN was trained to detect cattle, however the same training process could be followed to develop a CNN for the detection of any other object. This article describes the design of the platform for real-time analysis of information and its performance in the detection of cattle.
KW  - cattle detection
KW  - convolutional neural network
KW  - multirotor
KW  - drone
KW  - Unmanned Aerial Vehicle
DO  - 10.3390/s18072048
ER  -
TY  - EJOU
AU  - Guerra, Edmundo
AU  - Munguía, Rodrigo
AU  - Grau, Antoni
TI  - UAV Visual and Laser Sensors Fusion for Detection and Positioning in Industrial Applications
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - This work presents a solution to localize Unmanned Autonomous Vehicles with respect to pipes and other cylindrical elements found in inspection and maintenance tasks both in industrial and civilian infrastructures. The proposed system exploits the different features of vision and laser based sensors, combining them to obtain accurate positioning of the robot with respect to the cylindrical structures. A probabilistic (RANSAC-based) procedure is used to segment possible cylinders found in the laser scans, and this is used as a seed to accurately determine the robot position through a computer vision system. The priors obtained from the laser scan registration help to solve the problem of determining the apparent contour of the cylinders. In turn this apparent contour is used in a degenerate quadratic conic estimation, enabling to visually estimate the pose of the cylinder.
KW  - Unmanned Autonomous Vehicle
KW  - pose determination
KW  - LiDAR registration
KW  - apparent contour
DO  - 10.3390/s18072071
ER  -
TY  - EJOU
AU  - Adege, Abebe B.
AU  - Lin, Hsin-Piao
AU  - Tarekegn, Getaneh B.
AU  - Jeng, Shiann-Shiun
TI  - Applying Deep Neural Network (DNN) for Robust Indoor Localization in Multi-Building Environment
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 7
SN  - 2076-3417

AB  - In the Internet of Things (IoT) era, indoor localization plays a vital role in academia and industry. Wi-Fi is a promising scheme for indoor localization as it is easy and free of charge, even for private networks. However, Wi-Fi has signal fluctuation problems because of dynamic changes of environments and shadowing effects. In this paper, we propose to use a deep neural network (DNN) to achieve accurate localization in Wi-Fi environments. In the localization process, we primarily construct a database having all reachable received signal strengths (RSSs), and basic service set identifiers (BSSIDs). Secondly, we fill the missed RSS values using regression, and then apply linear discriminant analysis (LDA) to reduce features. Thirdly, the 5-BSSIDs having the strongest RSS values are appended with reduced RSS vector. Finally, a DNN is applied for localizing Wi-Fi users. The proposed system is evaluated in the classification and regression schemes using the python programming language. The results show that 99.15% of the localization accuracy is correctly classified. Moreover, the coordinate-based localization provides 50%, 75%, and 93.10% accuracies for errors less than 0.50 m, 0.75 m, and 0.90 m respectively. The proposed method is compared with other algorithms, and our method provides motivated results. The simulation results also show that the proposed method can robustly localize Wi-Fi users in hierarchical and complex wireless environments.
KW  - deep neural network
KW  - Internet of Things
KW  - linear discriminant analysis
KW  - Wi-Fi based indoor localization
DO  - 10.3390/app8071062
ER  -
TY  - EJOU
AU  - Huang, Huasheng
AU  - Lan, Yubin
AU  - Deng, Jizhong
AU  - Yang, Aqing
AU  - Deng, Xiaoling
AU  - Zhang, Lei
AU  - Wen, Sheng
TI  - A Semantic Labeling Approach for Accurate Weed Mapping of High Resolution UAV Imagery
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - Weed control is necessary in rice cultivation, but the excessive use of herbicide treatments has led to serious agronomic and environmental problems. Suitable site-specific weed management (SSWM) is a solution to address this problem while maintaining the rice production quality and quantity. In the context of SSWM, an accurate weed distribution map is needed to provide decision support information for herbicide treatment. UAV remote sensing offers an efficient and effective platform to monitor weeds thanks to its high spatial resolution. In this work, UAV imagery was captured in a rice field located in South China. A semantic labeling approach was adopted to generate the weed distribution maps of the UAV imagery. An ImageNet pre-trained CNN with residual framework was adapted in a fully convolutional form, and transferred to our dataset by fine-tuning. Atrous convolution was applied to extend the field of view of convolutional filters; the performance of multi-scale processing was evaluated; and a fully connected conditional random field (CRF) was applied after the CNN to further refine the spatial details. Finally, our approach was compared with the pixel-based-SVM and the classical FCN-8s. Experimental results demonstrated that our approach achieved the best performance in terms of accuracy. Especially for the detection of small weed patches in the imagery, our approach significantly outperformed other methods. The mean intersection over union (mean IU), overall accuracy, and Kappa coefficient of our method were 0.7751, 0.9445, and 0.9128, respectively. The experiments showed that our approach has high potential in accurate weed mapping of UAV imagery.
KW  - UAV
KW  - remote sensing
KW  - weed mapping
KW  - Deep Fully Convolutional Network
KW  - semantic labeling
DO  - 10.3390/s18072113
ER  -
TY  - EJOU
AU  - Buscombe, Daniel
AU  - Ritchie, Andrew C.
TI  - Landscape Classification with Deep Neural Networks
T2  - Geosciences

PY  - 2018
VL  - 8
IS  - 7
SN  - 2076-3263

AB  - The application of deep learning, specifically deep convolutional neural networks (DCNNs), to the classification of remotely-sensed imagery of natural landscapes has the potential to greatly assist in the analysis and interpretation of geomorphic processes. However, the general usefulness of deep learning applied to conventional photographic imagery at a landscape scale is, at yet, largely unproven. If DCNN-based image classification is to gain wider application and acceptance within the geoscience community, demonstrable successes need to be coupled with accessible tools to retrain deep neural networks to discriminate landforms and land uses in landscape imagery. Here, we present an efficient approach to train/apply DCNNs with/on sets of photographic images, using a powerful graphical method called a conditional random field (CRF), to generate DCNN training and testing data using minimal manual supervision. We apply the method to several sets of images of natural landscapes, acquired from satellites, aircraft, unmanned aerial vehicles, and fixed camera installations. We synthesize our findings to examine the general effectiveness of transfer learning to landscape-scale image classification. Finally, we show how DCNN predictions on small regions of images might be used in conjunction with a CRF for highly accurate pixel-level classification of images.
KW  - image classification
KW  - image segmentation
KW  - land use
KW  - land cover
KW  - landforms
KW  - deep learning
KW  - machine learning
KW  - unmanned aerial systems
KW  - aerial imagery
KW  - remote sensing
DO  - 10.3390/geosciences8070244
ER  -
TY  - EJOU
AU  - Ismail, Adiel
AU  - Bagula, Bigomokero A.
AU  - Tuyishimire, Emmanuel
TI  - Internet-Of-Things in Motion: A UAV Coalition Model for Remote Sensing in Smart Cities
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) or drones are increasingly used in cities to provide service tasks that are too dangerous, expensive or difficult for human beings. Drones are also used in cases where a task can be performed more economically and or more efficiently than if done by humans. These include remote sensing tasks where drones can be required to form coalitions by pooling their resources to meet the service requirements at different locations of interest in a city. During such coalition formation, finding the shortest path from a source to a location of interest is key to efficient service delivery. For fixed-wing UAVs, Dubins curves can be applied to find the shortest flight path. When a UAV flies to a location of interest, the angle or orientation of the UAV upon its arrival is often not important. In such a case, a simplified version of the Dubins curve consisting of two instead of three parts can be used. This paper proposes a novel model for UAV coalition and an algorithm derived from basic geometry that generates a path derived from the original Dubins curve for application in remote sensing missions of fixed-wing UAVs. The algorithm is tested by incorporating it into three cooperative coalition formation algorithms. The performance of the model is evaluated by varying the number of types of resources and the sensor ranges of the UAVs to reveal the relevance and practicality of the proposed model.
KW  - smart cities
KW  - Internet-of-Things
KW  - multi-drone task allocation
KW  - unmanned aerial vehicles
KW  - path planning
KW  - Dubins curves
KW  - particle swarm optimization
DO  - 10.3390/s18072184
ER  -
TY  - EJOU
AU  - Bachmann, Daniel
AU  - Weichert, Frank
AU  - Rinkenauer, Gerhard
TI  - Review of Three-Dimensional Human-Computer Interaction with Focus on the Leap Motion Controller
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - Modern hardware and software development has led to an evolution of user interfaces from command-line to natural user interfaces for virtual immersive environments. Gestures imitating real-world interaction tasks increasingly replace classical two-dimensional interfaces based on Windows/Icons/Menus/Pointers (WIMP) or touch metaphors. Thus, the purpose of this paper is to survey the state-of-the-art Human-Computer Interaction (HCI) techniques with a focus on the special field of three-dimensional interaction. This includes an overview of currently available interaction devices, their applications of usage and underlying methods for gesture design and recognition. Focus is on interfaces based on the Leap Motion Controller (LMC) and corresponding methods of gesture design and recognition. Further, a review of evaluation methods for the proposed natural user interfaces is given.
KW  - human-computer interaction
KW  - contact-free input devices
KW  - three-dimensional interaction
KW  - natural user interfaces
KW  - leap motion controller
DO  - 10.3390/s18072194
ER  -
TY  - EJOU
AU  - Petrellis, Nikos
TI  - A Review of Image Processing Techniques Common in Human and Plant Disease Diagnosis
T2  - Symmetry

PY  - 2018
VL  - 10
IS  - 7
SN  - 2073-8994

AB  - Image processing has been extensively used in various (human, animal, plant) disease diagnosis approaches, assisting experts to select the right treatment. It has been applied to both images captured from cameras of visible light and from equipment that captures information in invisible wavelengths (magnetic/ultrasonic sensors, microscopes, etc.). In most of the referenced diagnosis applications, the image is enhanced by various filtering methods and segmentation follows isolating the regions of interest. Classification of the input image is performed at the final stage. The disease diagnosis approaches based on these steps and the common methods are described. The features extracted from a plant/skin disease diagnosis framework developed by the author are used here to demonstrate various techniques adopted in the literature. The various metrics along with the available experimental conditions and results presented in the referenced approaches are also discussed. The accuracy achieved in the diagnosis methods that are based on image processing is often higher than 90%. The motivation for this review is to highlight the most common and efficient methods that have been employed in various disease diagnosis approaches and suggest how they can be used in similar or different applications.
KW  - image processing
KW  - disease diagnosis
KW  - plant disease
KW  - segmentation
KW  - classification
KW  - image filtering
DO  - 10.3390/sym10070270
ER  -
TY  - EJOU
AU  - De Oliveira, Diulhio C.
AU  - Wehrmeister, Marco A.
TI  - Using Deep Learning and Low-Cost RGB and Thermal Cameras to Detect Pedestrians in Aerial Images Captured by Multirotor UAV
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - The use of Unmanned Aerial Vehicles (UAV) has been increasing over the last few years in many sorts of applications due mainly to the decreasing cost of this technology. One can see the use of the UAV in several civilian applications such as surveillance and search and rescue. Automatic detection of pedestrians in aerial images is a challenging task. The computing vision system must deal with many sources of variability in the aerial images captured with the UAV, e.g., low-resolution images of pedestrians, images captured at distinct angles due to the degrees of freedom that a UAV can move, the camera platform possibly experiencing some instability while the UAV flies, among others. In this work, we created and evaluated different implementations of Pattern Recognition Systems (PRS) aiming at the automatic detection of pedestrians in aerial images captured with multirotor UAV. The main goal is to assess the feasibility and suitability of distinct PRS implementations running on top of low-cost computing platforms, e.g., single-board computers such as the Raspberry Pi or regular laptops without a GPU. For that, we used four machine learning techniques in the feature extraction and classification steps, namely Haar cascade, LBP cascade, HOG + SVM and Convolutional Neural Networks (CNN). In order to improve the system performance (especially the processing time) and also to decrease the rate of false alarms, we applied the Saliency Map (SM) and Thermal Image Processing (TIP) within the segmentation and detection steps of the PRS. The classification results show the CNN to be the best technique with 99.7% accuracy, followed by HOG + SVM with 92.3%. In situations of partial occlusion, the CNN showed 71.1% sensitivity, which can be considered a good result in comparison with the current state-of-the-art, since part of the original image data is missing. As demonstrated in the experiments, by combining TIP with CNN, the PRS can process more than two frames per second (fps), whereas the PRS that combines TIP with HOG + SVM was able to process 100 fps. It is important to mention that our experiments show that a trade-off analysis must be performed during the design of a pedestrian detection PRS. The faster implementations lead to a decrease in the PRS accuracy. For instance, by using HOG + SVM with TIP, the PRS presented the best performance results, but the obtained accuracy was 35 percentage points lower than the CNN. The obtained results indicate that the best detection technique (i.e., the CNN) requires more computational resources to decrease the PRS computation time. Therefore, this work shows and discusses the pros/cons of each technique and trade-off situations, and hence, one can use such an analysis to improve and tailor the design of a PRS to detect pedestrians in aerial images.
KW  - pedestrian detection
KW  - aerial images
KW  - Unmanned Aerial Vehicle (UAV)
KW  - thermal camera
KW  - deep learning
KW  - convolutional neural network
KW  - pattern recognition system
KW  - performance assessment
DO  - 10.3390/s18072244
ER  -
TY  - EJOU
AU  - Xiang, Xuezhi
AU  - Lv, Ning
AU  - Guo, Xinli
AU  - Wang, Shuai
AU  - El Saddik, Abdulmotaleb
TI  - Engineering Vehicles Detection Based on Modified Faster R-CNN for Power Grid Surveillance
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - Engineering vehicles intrusion detection is a key problem for the security of power grid operation, which can warn of the regional invasion and prevent external damage from architectural construction. In this paper, we propose an intelligent surveillance method based on the framework of Faster R-CNN for locating and identifying the invading engineering vehicles. In our detection task, the type of the objects is varied and the monitoring scene is large and complex. In order to solve these challenging problems, we modify the network structure of the object detection model by adjusting the position of the ROI pooling layer. The convolutional layer is added to the feature classification part to improve the accuracy of the detection model. We verify that increasing the depth of the feature classification part is effective for detecting engineering vehicles in realistic transmission lines corridors. We also collect plenty of scene images taken from the monitor site and label the objects to create a fine-tuned dataset. We train the modified deep detection model based on the technology of transfer learning and conduct training and test on the newly labeled dataset. Experimental results show that the proposed intelligent surveillance method can detect engineering vehicles with high accuracy and a low false alarm rate, which can be used for the early warning of power grid surveillance.
KW  - power grid surveillance
KW  - external damage
KW  - engineering vehicles
KW  - faster R-CNN
KW  - transfer learning
DO  - 10.3390/s18072258
ER  -
TY  - EJOU
AU  - Lausch, Angela
AU  - Borg, Erik
AU  - Bumberger, Jan
AU  - Dietrich, Peter
AU  - Heurich, Marco
AU  - Huth, Andreas
AU  - Jung, András
AU  - Klenke, Reinhard
AU  - Knapp, Sonja
AU  - Mollenhauer, Hannes
AU  - Paasche, Hendrik
AU  - Paulheim, Heiko
AU  - Pause, Marion
AU  - Schweitzer, Christian
AU  - Schmulius, Christiane
AU  - Settele, Josef
AU  - Skidmore, Andrew K.
AU  - Wegmann, Martin
AU  - Zacharias, Steffen
AU  - Kirsten, Toralf
AU  - Schaepman, Michael E.
TI  - Understanding Forest Health with Remote Sensing, Part III: Requirements for a Scalable Multi-Source Forest Health Monitoring Network Based on Data Science Approaches
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 7
SN  - 2072-4292

AB  - Forest ecosystems fulfill a whole host of ecosystem functions that are essential for life on our planet. However, an unprecedented level of anthropogenic influences is reducing the resilience and stability of our forest ecosystems as well as their ecosystem functions. The relationships between drivers, stress, and ecosystem functions in forest ecosystems are complex, multi-faceted, and often non-linear, and yet forest managers, decision makers, and politicians need to be able to make rapid decisions that are data-driven and based on short and long-term monitoring information, complex modeling, and analysis approaches. A huge number of long-standing and standardized forest health inventory approaches already exist, and are increasingly integrating remote-sensing based monitoring approaches. Unfortunately, these approaches in monitoring, data storage, analysis, prognosis, and assessment still do not satisfy the future requirements of information and digital knowledge processing of the 21st century. Therefore, this paper discusses and presents in detail five sets of requirements, including their relevance, necessity, and the possible solutions that would be necessary for establishing a feasible multi-source forest health monitoring network for the 21st century. Namely, these requirements are: (1) understanding the effects of multiple stressors on forest health; (2) using remote sensing (RS) approaches to monitor forest health; (3) coupling different monitoring approaches; (4) using data science as a bridge between complex and multidimensional big forest health (FH) data; and (5) a future multi-source forest health monitoring network. It became apparent that no existing monitoring approach, technique, model, or platform is sufficient on its own to monitor, model, forecast, or assess forest health and its resilience. In order to advance the development of a multi-source forest health monitoring network, we argue that in order to gain a better understanding of forest health in our complex world, it would be conducive to implement the concepts of data science with the components: (i) digitalization; (ii) standardization with metadata management after the FAIR (Findability, Accessibility, Interoperability, and Reusability) principles; (iii) Semantic Web; (iv) proof, trust, and uncertainties; (v) tools for data science analysis; and (vi) easy tools for scientists, data managers, and stakeholders for decision-making support.
KW  - forest health
KW  - in situ forest monitoring
KW  - remote sensing
KW  - data science
KW  - digitalization
KW  - big data
KW  - semantic web
KW  - linked open data
KW  - FAIR
KW  - multi-source forest health monitoring network
DO  - 10.3390/rs10071120
ER  -
TY  - EJOU
AU  - Gopalakrishnan, Kasthurirangan
TI  - Deep Learning in Data-Driven Pavement Image Analysis and Automated Distress Detection: A Review
T2  - Data

PY  - 2018
VL  - 3
IS  - 3
SN  - 2306-5729

AB  - Deep learning, more specifically deep convolutional neural networks, is fast becoming a popular choice for computer vision-based automated pavement distress detection. While pavement image analysis has been extensively researched over the past three decades or so, recent ground-breaking achievements of deep learning algorithms in the areas of machine translation, speech recognition, and computer vision has sparked interest in the application of deep learning to automated detection of distresses in pavement images. This paper provides a narrative review of recently published studies in this field, highlighting the current achievements and challenges. A comparison of the deep learning software frameworks, network architecture, hyper-parameters employed by each study, and crack detection performance is provided, which is expected to provide a good foundation for driving further research on this important topic in the context of smart pavement or asset management systems. The review concludes with potential avenues for future research; especially in the application of deep learning to not only detect, but also characterize the type, extent, and severity of distresses from 2D and 3D pavement images.
KW  - pavement cracking
KW  - pavement management
KW  - pavement imaging
KW  - 3D image
KW  - deep learning
KW  - TensorFlow
KW  - deep convolutional neural networks
DO  - 10.3390/data3030028
ER  -
TY  - EJOU
AU  - Chabot, Dominique
AU  - Dillon, Christopher
AU  - Shemrock, Adam
AU  - Weissflog, Nicholas
AU  - Sager, Eric P. S.
TI  - An Object-Based Image Analysis Workflow for Monitoring Shallow-Water Aquatic Vegetation in Multispectral Drone Imagery
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 8
SN  - 2220-9964

AB  - High-resolution drone aerial surveys combined with object-based image analysis are transforming our capacity to monitor and manage aquatic vegetation in an era of invasive species. To better exploit the potential of these technologies, there is a need to develop more efficient and accessible analysis workflows and focus more efforts on the distinct challenge of mapping submerged vegetation. We present a straightforward workflow developed to monitor emergent and submerged invasive water soldier (Stratiotes aloides) in shallow waters of the Trent-Severn Waterway in Ontario, Canada. The main elements of the workflow are: (1) collection of radiometrically calibrated multispectral imagery including a near-infrared band; (2) multistage segmentation of the imagery involving an initial separation of above-water from submerged features; and (3) automated classification of features with a supervised machine-learning classifier. The approach yielded excellent classification accuracy for emergent features (overall accuracy = 92%; kappa = 88%; water soldier producer&rsquo;s accuracy = 92%; user&rsquo;s accuracy = 91%) and good accuracy for submerged features (overall accuracy = 84%; kappa = 75%; water soldier producer&rsquo;s accuracy = 71%; user&rsquo;s accuracy = 84%). The workflow employs off-the-shelf graphical software tools requiring no programming or coding, and could therefore be used by anyone with basic GIS and image analysis skills for a potentially wide variety of aquatic vegetation monitoring operations.
KW  - environmental monitoring
KW  - freshwater ecosystems
KW  - OBIA
KW  - random forests
KW  - remote sensing
KW  - rivers
KW  - unmanned aircraft
KW  - UAS
KW  - UAV
KW  - wetlands
DO  - 10.3390/ijgi7080294
ER  -
TY  - EJOU
AU  - Zhou, Jianmin
AU  - Zhang, Shan
AU  - Yang, Hua
AU  - Xiao, Zhiqiang
AU  - Gao, Feng
TI  - The Retrieval of 30-m Resolution LAI from Landsat Data by Combining MODIS Products
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - Leaf area index (LAI) is a critical vegetation structural parameter in biogeochemical and biophysical ecosystems. High-resolution LAI products play an essential role in regional studies. Empirical methods, which normally use field measurements as their training samples and have been identified as the most commonly used approaches to retrieve structural parameters of vegetation from high-resolution remote-sensing data, are limited by the quality of training samples. Few efforts have been made to generate training samples from existing global LAI products. In this study, two methods (a homogeneous and pure pixel filter method (method A) and a pixel unmixing method (method B)) were developed to extract training samples from moderate-resolution imaging spectroradiometer (MODIS) surface reflectance and LAI products, and a support vector regression (SVR) algorithm trained by the samples was used to retrieve the high-resolution LAI from Landsat data at Baoding, situated in the Hebei Province in China, and Des Moines, situated in Iowa, United States. For the homogeneous and pure pixel filter method, two different sets of training samples were designed. One was composed of upscaled Landsat reflectance at the 500-m resolution and MODIS LAI products (dataset A1); the other was composed of MODIS reflectance and LAI products (dataset A2). With them, two inversion models were developed using SVR. For the pixel unmixing method, the training samples (dataset B) were extracted from unmixed MODIS surface reflectance and LAI products at 30-m resolution, and the third inversion model was obtained with them. LAI inversion results showed that good agreement with field measurements was achieved using these three inversion models. The R2 (coefficient of determination) value and the root mean square error (RMSE) value were computed to assess the results. For all tests, the R2 values are higher than 0.74 and RMSE values are less than 0.73. These tests showed that three models for the two methods combined with MODIS products can retrieve 30-m resolution LAI from Landsat data. The results of the pixel unmixing method was slightly better than that of the homogeneous and pure pixel filter method.
KW  - leaf area index
KW  - MODIS products
KW  - Landsat
KW  - high resolution
KW  - homogeneous and pure pixel filter
KW  - pixel unmixing
DO  - 10.3390/rs10081187
ER  -
TY  - EJOU
AU  - Feng, Chen-Chieh
AU  - Guo, Zhou
TI  - Automating Parameter Learning for Classifying Terrestrial LiDAR Point Cloud Using 2D Land Cover Maps
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - The automating classification of point clouds capturing urban scenes is critical for supporting applications that demand three-dimensional (3D) models. Achieving this goal, however, is met with challenges because of the varying densities of the point clouds and the complexity of the 3D data. In order to increase the level of automation in the point cloud classification, this study proposes a segment-based parameter learning method that incorporates a two-dimensional (2D) land cover map, in which a strategy of fusing the 2D land cover map and the 3D points is first adopted to create labelled samples, and a formalized procedure is then implemented to automatically learn the following parameters of point cloud classification: the optimal scale of the neighborhood for segmentation, optimal feature set, and the training classifier. It comprises four main steps, namely: (1) point cloud segmentation; (2) sample selection; (3) optimal feature set selection; and (4) point cloud classification. Three datasets containing the point cloud data were used in this study to validate the efficiency of the proposed method. The first two datasets cover two areas of the National University of Singapore (NUS) campus while the third dataset is a widely used benchmark point cloud dataset of Oakland, Pennsylvania. The classification parameters were learned from the first dataset consisting of a terrestrial laser-scanning data and a 2D land cover map, and were subsequently used to classify both of the NUS datasets. The evaluation of the classification results showed overall accuracies of 94.07% and 91.13%, respectively, indicating that the transition of the knowledge learned from one dataset to another was satisfactory. The classification of the Oakland dataset achieved an overall accuracy of 97.08%, which further verified the transferability of the proposed approach. An experiment of the point-based classification was also conducted on the first dataset and the result was compared to that of the segment-based classification. The evaluation revealed that the overall accuracy of the segment-based classification is indeed higher than that of the point-based classification, demonstrating the advantage of the segment-based approaches.
KW  - point cloud classification
KW  - 2D map
KW  - segment-based
KW  - neighborhood scale
KW  - sample selection
DO  - 10.3390/rs10081192
ER  -
TY  - EJOU
AU  - Zhang, Weixing
AU  - Witharana, Chandi
AU  - Li, Weidong
AU  - Zhang, Chuanrong
AU  - Li, Xiaojiang
AU  - Parent, Jason
TI  - Using Deep Learning to Identify Utility Poles with Crossarms and Estimate Their Locations from Google Street View Images
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 8
SN  - 1424-8220

AB  - Traditional methods of detecting and mapping utility poles are inefficient and costly because of the demand for visual interpretation with quality data sources or intense field inspection. The advent of deep learning for object detection provides an opportunity for detecting utility poles from side-view optical images. In this study, we proposed using a deep learning-based method for automatically mapping roadside utility poles with crossarms (UPCs) from Google Street View (GSV) images. The method combines the state-of-the-art DL object detection algorithm (i.e., the RetinaNet object detection algorithm) and a modified brute-force-based line-of-bearing (LOB, a LOB stands for the ray towards the location of the target [UPC at here] from the original location of the sensor [GSV mobile platform]) measurement method to estimate the locations of detected roadside UPCs from GSV. Experimental results indicate that: (1) both the average precision (AP) and the overall accuracy (OA) are around 0.78 when the intersection-over-union (IoU) threshold is greater than 0.3, based on the testing of 500 GSV images with a total number of 937 objects; and (2) around 2.6%, 47%, and 79% of estimated locations of utility poles are within 1 m, 5 m, and 10 m buffer zones, respectively, around the referenced locations of utility poles. In general, this study indicates that even in a complex background, most utility poles can be detected with the use of DL, and the LOB measurement method can estimate the locations of most UPCs.
KW  - deep learning
KW  - utility pole
KW  - infrastructure mapping
KW  - Google Street View
KW  - line-of-bearing measurement
KW  - object detection
DO  - 10.3390/s18082484
ER  -
TY  - EJOU
AU  - Dash, Jonathan P.
AU  - Pearse, Grant D.
AU  - Watt, Michael S.
TI  - UAV Multispectral Imagery Can Complement Satellite Data for Monitoring Forest Health
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - The development of methods that can accurately detect physiological stress in forest trees caused by biotic or abiotic factors is vital for ensuring productive forest systems that can meet the demands of the Earth&rsquo;s population. The emergence of new sensors and platforms presents opportunities to augment traditional practices by combining remotely-sensed data products to provide enhanced information on forest condition. We tested the sensitivity of multispectral imagery collected from time-series unmanned aerial vehicle (UAV) and satellite imagery to detect herbicide-induced stress in a carefully controlled experiment carried out in a mature Pinus radiata D. Don plantation. The results revealed that both data sources were sensitive to physiological stress in the study trees. The UAV data were more sensitive to changes at a finer spatial resolution and could detect stress down to the level of individual trees. The satellite data tested could only detect physiological stress in clusters of four or more trees. Resampling the UAV imagery to the same spatial resolution as the satellite imagery revealed that the differences in sensitivity were not solely the result of spatial resolution. Instead, vegetation indices suited to the sensor characteristics of each platform were required to optimise the detection of physiological stress from each data source. Our results define both the spatial detection threshold and the optimum vegetation indices required to implement monitoring of this forest type. A comparison between time-series datasets of different spectral indices showed that the two sensors are compatible and can be used to deliver an enhanced method for monitoring physiological stress in forest trees at various scales. We found that the higher resolution UAV imagery was more sensitive to fine-scale instances of herbicide induced physiological stress than the RapidEye imagery. Although less sensitive to smaller phenomena the satellite imagery was found to be very useful for observing trends in physiological stress over larger areas.
KW  - tree health
KW  - precision forestry
KW  - sensor fusion
KW  - RPAS
KW  - drone
KW  - RapidEye
KW  - plantation forest
KW  - radiata pine
KW  - forest management
KW  - forest productivity
DO  - 10.3390/rs10081216
ER  -
TY  - EJOU
AU  - Zhao, Qi
AU  - Zhang, Boxue
AU  - Lyu, Shuchang
AU  - Zhang, Hong
AU  - Sun, Daniel
AU  - Li, Guoqiang
AU  - Feng, Wenquan
TI  - A CNN-SIFT Hybrid Pedestrian Navigation Method Based on First-Person Vision
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - The emergence of new wearable technologies, such as action cameras and smart glasses, has driven the use of the first-person perspective in computer applications. This field is now attracting the attention and investment of researchers aiming to develop methods to process first-person vision (FPV) video. The current approaches present particular combinations of different image features and quantitative methods to accomplish specific objectives, such as object detection, activity recognition, user&ndash;machine interaction, etc. FPV-based navigation is necessary in some special areas, where Global Position System (GPS) or other radio-wave strength methods are blocked, and is especially helpful for visually impaired people. In this paper, we propose a hybrid structure with a convolutional neural network (CNN) and local image features to achieve FPV pedestrian navigation. A novel end-to-end trainable global pooling operator, called AlphaMEX, has been designed to improve the scene classification accuracy of CNNs. A scale-invariant feature transform (SIFT)-based tracking algorithm is employed for movement estimation and trajectory tracking of the person through each frame of FPV images. Experimental results demonstrate the effectiveness of the proposed method. The top-1 error rate of the proposed AlphaMEX-ResNet outperforms the original ResNet (k = 12) by 1.7% on the ImageNet dataset. The CNN-SIFT hybrid pedestrian navigation system reaches 0.57 m average absolute error, which is an adequate accuracy for pedestrian navigation. Both positions and movements can be well estimated by the proposed pedestrian navigation algorithm with a single wearable camera.
KW  - navigation
KW  - first-person vision
KW  - CNN
KW  - SIFT
KW  - movement estimation
DO  - 10.3390/rs10081229
ER  -
TY  - EJOU
AU  - Fu, Zhitao
AU  - Qin, Qianqing
AU  - Luo, Bin
AU  - Sun, Hong
AU  - Wu, Chun
TI  - HOMPC: A Local Feature Descriptor Based on the Combination of Magnitude and Phase Congruency Information for Multi-Sensor Remote Sensing Images
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - Local region description of multi-sensor images remains a challenging task in remote sensing image analysis and applications due to the non-linear radiation variations between images. This paper presents a novel descriptor based on the combination of the magnitude and phase congruency information of local regions to capture the common features of images with non-linear radiation changes. We first propose oriented phase congruency maps (PCMs) and oriented magnitude binary maps (MBMs) using the multi-oriented phase congruency and magnitude information of log-Gabor filters. The two feature vectors are then quickly constructed based on the convolved PCMs and MBMs. Finally, a dense descriptor named the histograms of oriented magnitude and phase congruency (HOMPC) is developed by combining the histograms of oriented phase congruency (HPC) and the histograms of oriented magnitude (HOM) to capture the structure and shape properties of local regions. HOMPC was evaluated with three datasets composed of multi-sensor remote sensing images obtained from unmanned ground vehicle, unmanned aerial vehicle, and satellite platforms. The descriptor performance was evaluated by recall, precision, F1-measure, and area under the precision-recall curve. The experimental results showed the advantages of the HOM and HPC combination and confirmed that HOMPC is far superior to the current state-of-the-art local feature descriptors.
KW  - multi-sensor images
KW  - log-Gabor filters
KW  - non-linear radiation variations
KW  - local feature descriptor
KW  - phase congruency and magnitude
DO  - 10.3390/rs10081234
ER  -
TY  - EJOU
AU  - Gallo, Mariano
AU  - De Luca, Giuseppina
TI  - Spatial Extension of Road Traffic Sensor Data with Artificial Neural Networks
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 8
SN  - 1424-8220

AB  - This paper proposes a method for estimating traffic flows on some links of a road network knowing the data on other links that are monitored with sensors. In this way, it is possible to obtain more information on traffic conditions without increasing the number of monitored links. The proposed method is based on artificial neural networks (ANNs), wherein the input data are the traffic flows on some monitored road links and the output data are the traffic flows on some unmonitored links. We have implemented and tested several single-layer feed-forward ANNs that differ in the number of neurons and the method of generating datasets for training. The proposed ANNs were trained with a supervised learning approach where input and output example datasets were generated through traffic simulation techniques. The proposed method was tested on a real-scale network and gave very good results if the travel demand patterns were known and used for generating example datasets, and promising results if the demand patterns were not considered in the procedure. Numerical results have underlined that the ANNs with few neurons were more effective than the ones with many neurons in this specific problem.
KW  - traffic sensors
KW  - smart roads
KW  - artificial neural networks
KW  - ITS
DO  - 10.3390/s18082640
ER  -
TY  - EJOU
AU  - Liakos, Konstantinos G.
AU  - Busato, Patrizia
AU  - Moshou, Dimitrios
AU  - Pearson, Simon
AU  - Bochtis, Dionysis
TI  - Machine Learning in Agriculture: A Review
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 8
SN  - 1424-8220

AB  - Machine learning has emerged with big data technologies and high-performance computing to create new opportunities for data intensive science in the multi-disciplinary agri-technologies domain. In this paper, we present a comprehensive review of research dedicated to applications of machine learning in agricultural production systems. The works analyzed were categorized in (a) crop management, including applications on yield prediction, disease detection, weed detection crop quality, and species recognition; (b) livestock management, including applications on animal welfare and livestock production; (c) water management; and (d) soil management. The filtering and classification of the presented articles demonstrate how agriculture will benefit from machine learning technologies. By applying machine learning to sensor data, farm management systems are evolving into real time artificial intelligence enabled programs that provide rich recommendations and insights for farmer decision support and action.
KW  - crop management
KW  - water management
KW  - soil management
KW  - livestock management
KW  - artificial intelligence
KW  - planning
KW  - precision agriculture
DO  - 10.3390/s18082674
ER  -
TY  - EJOU
AU  - Hidayat, Sarip
AU  - MATSUOKA, Masayuki
AU  - Baja, Sumbangan
AU  - Rampisela, Dorothea A.
TI  - Object-Based Image Analysis for Sago Palm Classification: The Most Important Features from High-Resolution Satellite Imagery
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - Sago palm (Metroxylon sagu) is a palm tree species originating in Indonesia. In the future, this starch-producing tree will play an important role in food security and biodiversity. Local governments have begun to emphasize the sustainable development of sago palm plantations; therefore, they require near-real-time geospatial information on palm stands. We developed a semi-automated classification scheme for mapping sago palm using machine learning within an object-based image analysis framework with Pleiades-1A imagery. In addition to spectral information, arithmetic, geometric, and textural features were employed to enhance the classification accuracy. Recursive feature elimination was applied to samples to rank the importance of 26 input features. A support vector machine (SVM) was used to perform classifications and resulted in the highest overall accuracy of 85.00% after inclusion of the eight most important features, including three spectral features, three arithmetic features, and two textural features. The SVM classifier showed normal fitting up to the eighth most important feature. According to the McNemar test results, using the top seven to 14 features provided a better classification accuracy. The significance of this research is the revelation of the most important features in recognizing sago palm among other similar tree species.
KW  - sago palm
KW  - OBIA
KW  - machine learning
KW  - textural features
KW  - image segmentation
KW  - feature selection
KW  - classification
DO  - 10.3390/rs10081319
ER  -
TY  - EJOU
AU  - Xue, Xizhe
AU  - Li, Ying
AU  - Shen, Qiang
TI  - Unmanned Aerial Vehicle Object Tracking by Correlation Filter with Adaptive Appearance Model
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 9
SN  - 1424-8220

AB  - With the increasing availability of low-cost, commercially available unmanned aerial vehicles (UAVs), visual tracking using UAVs has become more and more important due to its many new applications, including automatic navigation, obstacle avoidance, traffic monitoring, search and rescue, etc. However, real-world aerial tracking poses many challenges due to platform motion and image instability, such as aspect ratio change, viewpoint change, fast motion, scale variation and so on. In this paper, an efficient object tracking method for UAV videos is proposed to tackle these challenges. We construct the fused features to capture the gradient information and color characteristics simultaneously. Furthermore, cellular automata is introduced to update the appearance template of target accurately and sparsely. In particular, a high confidence model updating strategy is developed according to the stability function. Systematic comparative evaluations performed on the popular UAV123 dataset show the efficiency of the proposed approach.
KW  - UAV video
KW  - visual tracking
KW  - correlation filter
KW  - cellular automata
KW  - adaptive appearance model
DO  - 10.3390/s18092751
ER  -
TY  - EJOU
AU  - Hu, Jie
AU  - Wu, Zhongli
AU  - Qin, Xiongzhen
AU  - Geng, Huangzheng
AU  - Gao, Zhangbin
TI  - An Extended Kalman Filter and Back Propagation Neural Network Algorithm Positioning Method Based on Anti-lock Brake Sensor and Global Navigation Satellite System Information
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 9
SN  - 1424-8220

AB  - Telematics box (T-Box) chip-level Global Navigation Satellite System (GNSS) receiver modules usually suffer from GNSS information failure or noise in urban environments. In order to resolve this issue, this paper presents a real-time positioning method for Extended Kalman Filter (EKF) and Back Propagation Neural Network (BPNN) algorithms based on Antilock Brake System (ABS) sensor and GNSS information. Experiments were performed using an assembly in the vehicle with a T-Box. The T-Box firstly use automotive kinematical Pre-EKF to fuse the four wheel speed, yaw rate and steering wheel angle data from the ABS sensor to obtain a more accurate vehicle speed and heading angle velocity. In order to reduce the noise of the GNSS information, After-EKF fusion vehicle speed, heading angle velocity and GNSS data were used and low-noise positioning data were obtained. The heading angle speed error is extracted as target and part of low-noise positioning data were used as input for training a BPNN model. When the positioning is invalid, the well-trained BPNN corrected heading angle velocity output and vehicle speed add the synthesized relative displacement to the previous absolute position to realize a new position. With the data of high-precision real-time kinematic differential positioning equipment as the reference, the use of the dual EKF can reduce the noise range of GNSS information and concentrate good-positioning signals of the road within 5 m (i.e. the positioning status is valid). When the GNSS information was shielded (making the positioning status invalid), and the previous data was regarded as a training sample, it is found that the vehicle achieved 15 minutes position without GNSS information on the recycling line. The results indicated this new position method can reduce the vehicle positioning noise when GNSS information is valid and determine the position during long periods of invalid GNSS information.
KW  - ABS sensor
KW  - neural network
KW  - EKF
KW  - GNSS
KW  - T-Box
DO  - 10.3390/s18092753
ER  -
TY  - EJOU
AU  - Liu, Shuo
AU  - Ding, Wenrui
AU  - Liu, Chunhui
AU  - Liu, Yu
AU  - Wang, Yufeng
AU  - Li, Hongguang
TI  - ERN: Edge Loss Reinforced Semantic Segmentation Network for Remote Sensing Images
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - The semantic segmentation of remote sensing images faces two major challenges: high inter-class similarity and interference from ubiquitous shadows. In order to address these issues, we develop a novel edge loss reinforced semantic segmentation network (ERN) that leverages the spatial boundary context to reduce the semantic ambiguity. The main contributions of this paper are as follows: (1) we propose a novel end-to-end semantic segmentation network for remote sensing, which involves multiple weighted edge supervisions to retain spatial boundary information; (2) the main representations of the network are shared between the edge loss reinforced structures and semantic segmentation, which means that the ERN simultaneously achieves semantic segmentation and edge detection without significantly increasing the model complexity; and (3) we explore and discuss different ERN schemes to guide the design of future networks. Extensive experimental results on two remote sensing datasets demonstrate the effectiveness of our approach both in quantitative and qualitative evaluation. Specifically, the semantic segmentation performance in shadow-affected regions is significantly improved.
KW  - CNN
KW  - deep learning
KW  - edge loss reinforced network
KW  - remote sensing
KW  - semantic segmentation
DO  - 10.3390/rs10091339
ER  -
TY  - EJOU
AU  - Tamouridou, Afroditi A.
AU  - Pantazi, Xanthoula E.
AU  - Alexandridis, Thomas
AU  - Lagopodi, Anastasia
AU  - Kontouris, Giorgos
AU  - Moshou, Dimitrios
TI  - Spectral Identification of Disease in Weeds Using Multilayer Perceptron with Automatic Relevance Determination
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 9
SN  - 1424-8220

AB  - Microbotryum silybum, a smut fungus, is studied as an agent for the biological control of Silybum marianum (milk thistle) weed. Confirmation of the systemic infection is essential in order to assess the effectiveness of the biological control application and assist decision-making. Nonetheless, in situ diagnosis is challenging. The presently demonstrated research illustrates the identification process of systemically infected S. marianum plants by means of field spectroscopy and the multilayer perceptron/automatic relevance determination (MLP-ARD) network. Leaf spectral signatures were obtained from both healthy and infected S. marianum plants using a portable visible and near-infrared spectrometer (310&ndash;1100 nm). The MLP-ARD algorithm was applied for the recognition of the infected S. marianum plants. Pre-processed spectral signatures served as input features. The spectra pre-processing consisted of normalization, and second derivative and principal component extraction. MLP-ARD reached a high overall accuracy (90.32%) in the identification process. The research results establish the capacity of MLP-ARD to precisely identify systemically infected S. marianum weeds during their vegetative growth stage.
KW  - plant pathology
KW  - MLP-ARD
KW  - disease detection
KW  - artificial intelligence
KW  - precision agriculture
DO  - 10.3390/s18092770
ER  -
TY  - EJOU
AU  - Chen, Ting
AU  - Pennisi, Andrea
AU  - Li, Zhi
AU  - Zhang, Yanning
AU  - Sahli, Hichem
TI  - A Hierarchical Association Framework for Multi-Object Tracking in Airborne Videos
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - Multi-Object Tracking (MOT) in airborne videos is a challenging problem due to the uncertain airborne vehicle motion, vibrations of the mounted camera, unreliable detections, changes of size, appearance and motion of the moving objects and occlusions caused by the interaction between moving and static objects in the scene. To deal with these problems, this work proposes a four-stage hierarchical association framework for multiple object tracking in airborne video. The proposed framework combines Data Association-based Tracking (DAT) methods and target tracking using a compressive tracking approach, to robustly track objects in complex airborne surveillance scenes. In each association stage, different sets of tracklets and detections are associated to efficiently handle local tracklet generation, local trajectory construction, global drifting tracklet correction and global fragmented tracklet linking. Experiments with challenging airborne videos show significant tracking improvement compared to existing state-of-the-art methods.
KW  - multiple object tracking
KW  - airborne video
KW  - tracklet confidence
KW  - hierarchical association framework
DO  - 10.3390/rs10091347
ER  -

TY  - EJOU
AU  - Li, Lei
AU  - Zhang, Qin
AU  - Huang, Danfeng
TI  - A Review of Imaging Techniques for Plant Phenotyping
T2  - Sensors

PY  - 2014
VL  - 14
IS  - 11
SN  - 1424-8220

AB  - Given the rapid development of plant genomic technologies, a lack of access to plant phenotyping capabilities limits our ability to dissect the genetics of quantitative traits. Effective, high-throughput phenotyping platforms have recently been developed to  solve this problem. In high-throughput phenotyping platforms, a variety of imaging methodologies are being used to collect data for quantitative studies of complex traits related to the growth, yield and adaptation to biotic or abiotic stress (disease, insects, drought and salinity). These imaging techniques include visible imaging (machine vision), imaging spectroscopy (multispectral and hyperspectral remote sensing), thermal infrared imaging, fluorescence imaging, 3D imaging and tomographic imaging (MRT, PET and CT). This paper presents a brief review on these imaging techniques and their applications in plant phenotyping. The features used to apply these imaging techniques to plant phenotyping are described and discussed in this review.
KW  - phenotyping phenotype
KW  - fluorescence imaging
KW  - thermal infrared imaging
KW  - visible light imaging
KW  - imaging spectroscopy
KW  - three dimensional imaging
DO  - 10.3390/s141120078
ER  -
TY  - EJOU
AU  - Leitloff, Jens
AU  - Rosenbaum, Dominik
AU  - Kurz, Franz
AU  - Meynberg, Oliver
AU  - Reinartz, Peter
TI  - An Operational System for Estimating Road Traffic Information from Aerial Images
T2  - Remote Sensing

PY  - 2014
VL  - 6
IS  - 11
SN  - 2072-4292

AB  - Given that ground stationary infrastructures for traffic monitoring are barely able to handle everyday traffic volumes, there is a risk that they could fail altogether in situations arising from mass events or disasters. In this work, we present an alternative approach for traffic monitoring during disaster and mass events, which is based on an airborne optical sensor system. With this system, optical image sequences are automatically examined on board an aircraft to estimate road traffic information, such as vehicle positions, velocities and driving directions. The traffic information, estimated in real time on board, is immediately downlinked to a ground station. The airborne sensor system consists of a three-head camera system, a real-time-capable GPS/INS unit, five industrial PCs and a downlink unit. The processing chain for automatic extraction of traffic information contains modules for the synchronization of image and navigation data streams, orthorectification and vehicle detection and tracking modules. The vehicle detector is based on a combination of AdaBoost and support vector machine classifiers. Vehicle tracking relies on shape-based matching operators. The processing chain is evaluated on a large number of image sequences recorded during several campaigns, and the data quality is compared to that obtained from induction loops. In summary, we can conclude that the achieved overall quality of the traffic data extracted by the airborne system is in the range of 68% and 81%. Thus, it is comparable to data obtained from stationary ground sensor networks.
KW  - monitoring
KW  - pattern recognition
KW  - orthorectification
KW  - georeferencing
KW  - sequences
KW  - tracking
KW  - vehicle detection
DO  - 10.3390/rs61111315
ER  -
TY  - EJOU
AU  - Hung, Calvin
AU  - Xu, Zhe
AU  - Sukkarieh, Salah
TI  - Feature Learning Based Approach for Weed Classification Using High Resolution Aerial Images from a Digital Camera Mounted on a UAV
T2  - Remote Sensing

PY  - 2014
VL  - 6
IS  - 12
SN  - 2072-4292

AB  - The development of low-cost unmanned aerial vehicles (UAVs) and light weight imaging sensors has resulted in significant interest in their use for remote sensing applications. While significant attention has been paid to the collection, calibration, registration and mosaicking of data collected from small UAVs, the interpretation of these data into semantically meaningful information can still be a laborious task. A standard data collection and classification work-flow requires significant manual effort for segment size tuning, feature selection and rule-based classifier design. In this paper, we propose an alternative learning-based approach using feature learning to minimise the manual effort required. We apply this system to the classification of invasive weed species. Small UAVs are suited to this application, as they can collect data at high spatial resolutions, which is essential for the classification of small or localised weed outbreaks. In this paper, we apply feature learning to generate a bank of image filters that allows for the extraction of features that discriminate between the weeds of interest and background objects. These features are pooled to summarise the image statistics and form the input to a texton-based linear classifier that classifies an image patch as weed or background. We evaluated our approach to weed classification on three weeds of significance in Australia: water hyacinth, tropical soda apple and serrated tussock. Our results showed that collecting images at 5–10 m resulted in the highest classifier accuracy, indicated by F1 scores of up to 94%.
KW  - weed classification
KW  - UAV remote sensing
KW  - serrated tussock
KW  - tropical soda apple
KW  - water hyacinth
DO  - 10.3390/rs61212037
ER  -
TY  - EJOU
AU  - Feng, Quanlong
AU  - Liu, Jiantao
AU  - Gong, Jianhua
TI  - UAV Remote Sensing for Urban Vegetation Mapping Using Random Forest and Texture Analysis
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 1
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV) remote sensing has great potential for vegetation mapping in complex urban landscapes due to the ultra-high resolution imagery acquired at low altitudes. Because of payload capacity restrictions, off-the-shelf digital cameras are widely used on medium and small sized UAVs. The limitation of low spectral resolution in digital cameras for vegetation mapping can be reduced by incorporating texture features and robust classifiers. Random Forest has been widely used in satellite remote sensing applications, but its usage in UAV image classification has not been well documented. The objectives of this paper were to propose a hybrid method using Random Forest and texture analysis to accurately differentiate land covers of urban vegetated areas, and analyze how classification accuracy changes with texture window size. Six least correlated second-order texture measures were calculated at nine different window sizes and added to original Red-Green-Blue (RGB) images as ancillary data. A Random Forest classifier consisting of 200 decision trees was used for classification in the spectral-textural feature space. Results indicated the following: (1) Random Forest outperformed traditional Maximum Likelihood classifier and showed similar performance to object-based image analysis in urban vegetation classification; (2) the inclusion of texture features improved classification accuracy significantly; (3) classification accuracy followed an inverted U relationship with texture window size. The results demonstrate that UAV provides an efficient and ideal platform for urban vegetation mapping. The hybrid method proposed in this paper shows good performance in differentiating urban vegetation mapping. The drawbacks of off-the-shelf digital cameras can be reduced by adopting Random Forest and texture analysis at the same time.
KW  - UAV
KW  - vegetation mapping
KW  - urban landscape
KW  - random forest
KW  - texture analysis
DO  - 10.3390/rs70101074
ER  -
TY  - EJOU
AU  - Ai, Mingyao
AU  - Hu, Qingwu
AU  - Li, Jiayuan
AU  - Wang, Ming
AU  - Yuan, Hui
AU  - Wang, Shaohua
TI  - A Robust Photogrammetric Processing Method of Low-Altitude UAV Images
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 3
SN  - 2072-4292

AB  - Low-altitude Unmanned Aerial Vehicles (UAV) images which include distortion, illumination variance, and large rotation angles are facing multiple challenges of image orientation and image processing. In this paper, a robust and convenient photogrammetric approach is proposed for processing low-altitude UAV images, involving a strip management method to automatically build a standardized regional aerial triangle (AT) network, a parallel inner orientation algorithm, a ground control points (GCPs) predicting method, and an improved Scale Invariant Feature Transform (SIFT) method to produce large number of evenly distributed reliable tie points for bundle adjustment (BA). A multi-view matching approach is improved to produce Digital Surface Models (DSM) and Digital Orthophoto Maps (DOM) for 3D visualization. Experimental results show that the proposed approach is robust and feasible for photogrammetric processing of  low-altitude UAV images and 3D visualization of products.
KW  - strip auto-arrangement
KW  - BAoSIFT
KW  - dense match
KW  - digital orthophoto maps (DOM)
KW  - unmanned aerial vehicles (UAV)
DO  - 10.3390/rs70302302
ER  -
TY  - EJOU
AU  - Hassan-Esfahani, Leila
AU  - Torres-Rua, Alfonso
AU  - Jensen, Austin
AU  - McKee, Mac
TI  - Assessment of Surface Soil Moisture Using High-Resolution Multi-Spectral Imagery and Artificial Neural Networks
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 3
SN  - 2072-4292

AB  - Many crop production management decisions can be informed using data from high-resolution aerial images that provide information about crop health as influenced by soil fertility and moisture. Surface soil moisture is a key component of soil water balance, which addresses water and energy exchanges at the surface/atmosphere interface; however, high-resolution remotely sensed data is rarely used to acquire soil moisture values. In this study, an artificial neural network (ANN) model was developed to quantify the effectiveness of using spectral images to estimate surface soil moisture. The model produces acceptable estimations of surface soil moisture (root mean square error (RMSE) = 2.0, mean absolute error (MAE) = 1.8, coefficient of correlation (r) = 0.88, coefficient of performance (e) = 0.75 and coefficient of determination (R2) = 0.77) by combining field measurements with inexpensive and readily available remotely sensed inputs. The spatial data (visual spectrum, near infrared, infrared/thermal) are produced by the AggieAir™ platform, which includes an unmanned aerial vehicle (UAV) that enables users to gather aerial imagery at a low price and high spatial and temporal resolutions. This study reports the development of an ANN model that translates AggieAir™ imagery into estimates of surface soil moisture for a large field irrigated by a center pivot sprinkler system.
KW  - remote sensing
KW  - high-resolution
KW  - multi-spectral
KW  - soil moisture
KW  - Artificial Neural Network
KW  - UAV
DO  - 10.3390/rs70302627
ER  -
TY  - EJOU
AU  - Zlinszky, András
AU  - Deák, Balázs
AU  - Kania, Adam
AU  - Schroiff, Anke
AU  - Pfeifer, Norbert
TI  - Mapping Natura 2000 Habitat Conservation Status in  a Pannonic Salt Steppe with Airborne Laser Scanning
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 3
SN  - 2072-4292

AB  - Natura 2000 Habitat Conservation Status is currently evaluated based on fieldwork. However, this is proving to be unfeasible over large areas. The use of remote sensing is increasingly encouraged but covering the full range of ecological variables by such datasets and ensuring compatibility with the traditional assessment methodology has not been achieved yet. We aimed to test Airborne Laser Scanning (ALS) as a source for mapping all variables required by the local official conservation status assessment scheme and to develop  an automated method that calculates Natura 2000 conservation status at 0.5 m raster resolution for 24 km2 of Pannonic Salt Steppe habitat (code 1530). We used multi-temporal (summer and winter) ALS point clouds with full-waveform recording and a density of 10 pt/m2. Some required variables were derived from ALS product rasters; others involved vegetation classification layers calculated by machine learning and fuzzy categorization. Thresholds separating favorable and unfavorable values of each variable required by the national assessment scheme were manually calibrated from 10 plots where field-based assessment was carried out. Rasters representing positive and negative scores for each input variable were integrated in a ruleset that exactly follows the Hungarian Natura 2000 assessment scheme for grasslands. Accuracy of each parameter and the final conservation status score and category was evaluated by 10 independent assessment plots. We conclude that ALS is a suitable data source for Natura 2000 assessments in grasslands, and that the national grassland assessment scheme can successfully be used as a GIS processing model for conservation status, ensuring that the output is directly comparable with traditional field based assessments.
KW  - Natura 2000
KW  - conservation status
KW  - Airborne Laser Scanning
KW  - LiDAR
KW  - grasslands
KW  - Pannonic Salt Steppe
KW  - habitat assessment
KW  - habitat quality
DO  - 10.3390/rs70302991
ER  -
TY  - EJOU
AU  - Feng, Quanlong
AU  - Liu, Jiantao
AU  - Gong, Jianhua
TI  - Urban Flood Mapping Based on Unmanned Aerial Vehicle Remote Sensing and Random Forest Classifier—A Case of Yuyao, China
T2  - Water

PY  - 2015
VL  - 7
IS  - 4
SN  - 2073-4441

AB  - Flooding is a severe natural hazard, which poses a great threat to human life and property, especially in densely-populated urban areas. As one of the fastest developing fields in remote sensing applications, an unmanned aerial vehicle (UAV) can provide  high-resolution data with a great potential for fast and accurate detection of inundated areas under complex urban landscapes. In this research, optical imagery was acquired by a mini-UAV to monitor the serious urban waterlogging in Yuyao, China. Texture features derived from gray-level co-occurrence matrix were included to increase the separability of different ground objects. A Random Forest classifier, consisting of 200 decision trees, was used to extract flooded areas in the spectral-textural feature space. Confusion matrix was used to assess the accuracy of the proposed method. Results indicated the following:  (1) Random Forest showed good performance in urban flood mapping with an overall accuracy of 87.3% and a Kappa coefficient of 0.746; (2) the inclusion of texture features improved classification accuracy significantly; (3) Random Forest outperformed maximum likelihood and artificial neural network, and showed a similar performance to support vector machine. The results demonstrate that UAV can provide an ideal platform for urban flood monitoring and the proposed method shows great capability for the accurate extraction of inundated areas.
KW  - UAV
KW  - flood mapping
KW  - urban landscape
KW  - random forest
KW  - texture analysis
DO  - 10.3390/w7041437
ER  -
TY  - EJOU
AU  - Li, Dachuan
AU  - Li, Qing
AU  - Tang, Liangwen
AU  - Yang, Sheng
AU  - Cheng, Nong
AU  - Song, Jingyan
TI  - Invariant Observer-Based State Estimation for Micro-Aerial Vehicles in GPS-Denied Indoor Environments Using an RGB-D Camera and MEMS Inertial Sensors
T2  - Micromachines

PY  - 2015
VL  - 6
IS  - 4
SN  - 2072-666X

AB  - This paper presents a non-linear state observer-based integrated navigation scheme for estimating the attitude, position and velocity of micro aerial vehicles (MAV) operating in GPS-denied indoor environments, using the measurements from low-cost MEMS (micro electro-mechanical systems) inertial sensors and an RGB-D camera.  A robust RGB-D visual odometry (VO) approach was developed to estimate the MAV’s relative motion by extracting and matching features captured by the RGB-D camera from the environment. The state observer of the RGB-D visual-aided inertial navigation was then designed based on the invariant observer theory for systems possessing symmetries. The motion estimates from the RGB-D VO were fused with inertial and magnetic measurements from the onboard MEMS sensors via the state observer, providing the MAV with accurate estimates of its full six degree-of-freedom states. Implementations on a quadrotor MAV and indoor flight test results demonstrate that the resulting state observer is effective in estimating the MAV’s states without relying on external navigation aids such as GPS. The properties of computational efficiency and simplicity in gain tuning make the proposed invariant observer-based navigation scheme appealing for actual MAV applications in indoor environments.
KW  - integrated navigation
KW  - micro aerial vehicles (MAVs)
KW  - state observer
KW  - visual odometry (VO)
KW  - RGB-D cameras
DO  - 10.3390/mi6040487
ER  -
TY  - EJOU
AU  - Calderón, Rocío
AU  - Navas-Cortés, Juan A.
AU  - Zarco-Tejada, Pablo J.
TI  - Early Detection and Quantification of Verticillium Wilt in Olive Using Hyperspectral and Thermal Imagery over Large Areas
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 5
SN  - 2072-4292

AB  - Automatic methods for an early detection of plant diseases (i.e., visible symptoms at early stages of disease development) using remote sensing are critical for precision crop protection. Verticillium wilt (VW) of olive caused by Verticillium dahliae can be controlled only if detected at early stages of development. Linear discriminant analysis (LDA) and support vector machine (SVM) classification methods were applied to classify V. dahliae severity using remote sensing at large scale. High-resolution thermal and hyperspectral imagery were acquired with a manned platform which flew a 3000-ha commercial olive area. LDA reached an overall accuracy of 59.0% and a κ of 0.487 while SVM obtained a higher overall accuracy, 79.2% with a similar κ, 0.495. However, LDA better classified trees at initial and low severity levels, reaching accuracies of 71.4 and 75.0%, respectively, in comparison with the 14.3% and 40.6% obtained by SVM. Normalized canopy temperature, chlorophyll fluorescence, structural, xanthophyll, chlorophyll, carotenoid and disease indices were found to be the best indicators for early and advanced stage infection by VW. These results demonstrate that the methods developed in other studies at orchard scale are valid for flights in large areas comprising several olive orchards differing in soil and crop management characteristics.
KW  - Verticillium wilt
KW  - early detection
KW  - hyperspectral
KW  - thermal
KW  - support vector machine
KW  - linear discriminant analysis
DO  - 10.3390/rs70505584
ER  -
TY  - EJOU
AU  - Dronova, Iryna
TI  - Object-Based Image Analysis in Wetland Research: A Review
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 5
SN  - 2072-4292

AB  - The applications of object-based image analysis (OBIA) in remote sensing studies of wetlands have been growing over recent decades, addressing tasks from detection and delineation of wetland bodies to comprehensive analyses of within-wetland cover types and their change. Compared to pixel-based approaches, OBIA offers several important benefits to wetland analyses related to smoothing of the local noise, incorporating meaningful  non-spectral features for class separation and accounting for landscape hierarchy of wetland ecosystem organization and structure. However, there has been little discussion on whether unique challenges of wetland environments can be uniformly addressed by OBIA across different types of data, spatial scales and research objectives, and to what extent technical and conceptual aspects of this framework may themselves present challenges in a complex wetland setting. This review presents a synthesis of 73 studies that applied OBIA to different types of remote sensing data, spatial scale and research objectives. It summarizes the progress and scope of OBIA uses in wetlands, key benefits of this approach, factors related to accuracy and uncertainty in its applications and the main research needs and directions to expand the OBIA capacity in the future wetland studies. Growing demands for higher-accuracy wetland characterization at both regional and local scales together with advances in very high resolution remote sensing and novel tasks in wetland restoration monitoring will likely continue active exploration of the OBIA potential in these diverse and complex environments.
KW  - object-based image analysis (OBIA)
KW  - GEOBIA
KW  - wetland
KW  - review
KW  -  sensors
KW  - monitoring
DO  - 10.3390/rs70506380
ER  -
TY  - EJOU
AU  - Lin, Junqin
AU  - Han, Baoling
AU  - Luo, Qingsheng
TI  - Monocular-Vision-Based Autonomous Hovering for a Miniature Flying Ball
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 6
SN  - 1424-8220

AB  - This paper presents a method for detecting and controlling the autonomous hovering of a miniature flying ball (MFB) based on monocular vision. A camera is employed to estimate the three-dimensional position of the vehicle relative to the ground without auxiliary sensors, such as inertial measurement units (IMUs). An image of the ground captured by the camera mounted directly under the miniature flying ball is set as a reference. The position variations between the subsequent frames and the reference image are calculated by comparing their correspondence points. The Kalman filter is used to predict the position of the miniature flying ball to handle situations, such as a lost or wrong frame. Finally, a PID controller is designed, and the performance of the entire system is tested experimentally. The results show that the proposed method can keep the aircraft in a stable hover.
KW  - monocular-vision sensor
KW  - vision measurement
KW  - flying height detecting
KW  -  MAVs
KW  - hovering
DO  - 10.3390/s150613270
ER  -
TY  - EJOU
AU  - Hillen, Florian
AU  - Meynberg, Oliver
AU  - Höfle, Bernhard
TI  - Routing in Dense Human Crowds Using Smartphone Movement Data and Optical Aerial Imagery
T2  - ISPRS International Journal of Geo-Information

PY  - 2015
VL  - 4
IS  - 2
SN  - 2220-9964

AB  - In this paper, we propose a navigation approach for smartphones that enables visitors of major events to avoid crowded areas or narrow streets and to navigate out of dense crowds quickly. Two types of sensor data are integrated. Real-time optical images acquired and transmitted by an airborne camera system are used to compute an estimation of a crowd density map. For this purpose, a patch-based approach with a Gabor filter bank for texture classification in combination with an interest point detector and a smoothing function is applied. Furthermore, the crowd density is estimated based on location and movement speed of in situ smartphone measurements. This information allows for the enhancement of the overall crowd density layer. The composed density information is input to a least-cost routing workflow. Two possible use cases are presented, namely (i) an emergency application and (ii) a basic routing application. A prototypical implementation of the system is conducted as proof of concept. Our approach is capable of increasing the security level for major events. Visitors are able to avoid dense crowds by routing around them, while security and rescue forces are able to find the fastest way into the crowd.
KW  - geo-information fusion
KW  - aerial images
KW  - smartphone trajectories
KW  - texture classification
KW  - Gabor filter
KW  - texture classification
KW  - least-cost routing
DO  - 10.3390/ijgi4020974
ER  -
TY  - EJOU
AU  - Sun, Qian
AU  - Feng, Hao
AU  - Yan, Xueying
AU  - Zeng, Zhoumo
TI  - Recognition of a Phase-Sensitivity OTDR Sensing System Based on Morphologic Feature Extraction
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 7
SN  - 1424-8220

AB  - This paper proposes a novel feature extraction method for intrusion event recognition within a phase-sensitive optical time-domain reflectometer (Φ-OTDR) sensing system. Feature extraction of time domain signals in these systems is time-consuming and may lead to inaccuracies due to noise disturbances. The recognition accuracy and speed of current systems cannot meet the requirements of Φ-OTDR online vibration monitoring systems. In the method proposed in this paper, the time-space domain signal is used for feature extraction instead of the time domain signal. Feature vectors are obtained from morphologic features of time-space domain signals. A scatter matrix is calculated for the feature selection. Experiments show that the feature extraction method proposed in this paper can greatly improve recognition accuracies, with a lower computation time than traditional methods, i.e., a recognition accuracy of 97.8% can be achieved with a recognition time of below 1 s, making it is very suitable for Φ-OTDR system online vibration monitoring.
KW  - Φ-OTDR
KW  - morphology
KW  - feature extraction
KW  - intrusion event recognition
DO  - 10.3390/s150715179
ER  -
TY  - EJOU
AU  - Huang, Kuo-Lung
AU  - Chiu, Chung-Cheng
AU  - Chiu, Sheng-Yi
AU  - Teng, Yao-Jen
AU  - Hao, Shu-Sheng
TI  - Monocular Vision System for Fixed Altitude Flight of Unmanned Aerial Vehicles
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 7
SN  - 1424-8220

AB  - The fastest and most economical method of acquiring terrain images is aerial photography. The use of unmanned aerial vehicles (UAVs) has been investigated for this task. However, UAVs present a range of challenges such as flight altitude maintenance. This paper reports a method that combines skyline detection with a stereo vision algorithm to enable the flight altitude of UAVs to be maintained. A monocular camera is mounted on the downside of the aircraft’s nose to collect continuous ground images, and the relative altitude is obtained via a stereo vision algorithm from the velocity of the UAV. Image detection is used to obtain terrain images, and to measure the relative altitude from the ground to the UAV. The UAV flight system can be set to fly at a fixed and relatively low altitude to obtain the same resolution of ground images. A forward-looking camera is mounted on the upside of the aircraft’s nose. In combination with the skyline detection algorithm, this helps the aircraft to maintain a stable flight pattern. Experimental results show that the proposed system enables UAVs to obtain terrain images at constant resolution, and to detect the relative altitude along the flight path.
KW  - unmanned aerial vehicle (UAV)
KW  - monocular camera
KW  - stereo vision
KW  - motion vector detection
DO  - 10.3390/s150716848
ER  -
TY  - EJOU
AU  - Liu, Teng
AU  - Zou, Yuan
AU  - Liu, Dexing
AU  - Sun, Fengchun
TI  - Reinforcement Learning–Based Energy Management Strategy for a Hybrid Electric Tracked Vehicle
T2  - Energies

PY  - 2015
VL  - 8
IS  - 7
SN  - 1996-1073

AB  - This paper presents a reinforcement learning (RL)–based energy management strategy for a hybrid electric tracked vehicle. A control-oriented model of the powertrain and vehicle dynamics is first established. According to the sample information of the experimental driving schedule, statistical characteristics at various velocities are determined by extracting the transition probability matrix of the power request. Two RL-based algorithms, namely  Q-learning and Dyna algorithms, are applied to generate optimal control solutions. The two algorithms are simulated on the same driving schedule, and the simulation results are compared to clarify the merits and demerits of these algorithms. Although the Q-learning algorithm is faster (3 h) than the Dyna algorithm (7 h), its fuel consumption is 1.7% higher than that of the Dyna algorithm. Furthermore, the Dyna algorithm registers approximately the same fuel consumption as the dynamic programming–based global optimal solution.  The computational cost of the Dyna algorithm is substantially lower than that of the stochastic dynamic programming.
KW  - reinforcement learning (RL)
KW  - hybrid electric tracked vehicle (HETV)
KW  -  Q-learning algorithm
KW  - Dyna algorithm
KW  - dynamic programming (DP)
KW  - stochastic dynamic programming (SDP)
DO  - 10.3390/en8077243
ER  -
TY  - EJOU
AU  - Li, Xianju
AU  - Cheng, Xinwen
AU  - Chen, Weitao
AU  - Chen, Gang
AU  - Liu, Shengwei
TI  - Identification of Forested Landslides Using LiDar Data,  Object-based Image Analysis, and Machine Learning Algorithms
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 8
SN  - 2072-4292

AB  - For identification of forested landslides, most studies focus on knowledge-based and pixel-based analysis (PBA) of LiDar data, while few studies have examined (semi-) automated methods and object-based image analysis (OBIA). Moreover, most of them are focused on soil-covered areas with gentle hillslopes. In bedrock-covered mountains with steep and rugged terrain, it is so difficult to identify landslides that there is currently no research on whether combining semi-automated methods and OBIA with only LiDar derivatives could be more effective. In this study, a semi-automatic object-based landslide identification approach was developed and implemented in a forested area, the Three Gorges of China. Comparisons of OBIA and PBA, two different machine learning algorithms and their respective sensitivity to feature selection (FS), were first investigated. Based on the classification result, the landslide inventory was finally obtained according to (1) inclusion of holes encircled by the landslide body; (2) removal of isolated segments, and (3) delineation of closed envelope curves for landslide objects by manual digitizing operation. The proposed method achieved the following: (1) the filter features of surface roughness were first applied for calculating object features, and proved useful; (2) FS improved classification accuracy and reduced features; (3) the random forest algorithm achieved higher accuracy and was less sensitive to FS than a support vector machine; (4) compared to PBA, OBIA was more sensitive to FS, remarkably reduced computing time, and depicted more contiguous terrain segments; (5) based on the classification result with an overall accuracy of 89.11% ± 0.03%, the obtained inventory map was consistent with the referenced landslide inventory map, with a position mismatch value of 9%. The outlined approach would be helpful for forested landslide identification in steep and rugged terrain.
KW  - landslide inventory
KW  - LiDar
KW  - object-based image analysis
KW  - machine learning
KW  - the Three Gorges
DO  - 10.3390/rs70809705
ER  -
TY  - EJOU
AU  - Bradley, Justin M.
AU  - Atkins, Ella M.
TI  - Optimization and Control of Cyber-Physical Vehicle Systems
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 9
SN  - 1424-8220

AB  - A cyber-physical system (CPS) is composed of tightly-integrated computation, communication and physical elements. Medical devices, buildings, mobile devices, robots, transportation and energy systems can benefit from CPS co-design and optimization techniques. Cyber-physical vehicle systems (CPVSs) are rapidly advancing due to progress in real-time computing, control and artificial intelligence. Multidisciplinary or multi-objective design optimization maximizes CPS efficiency, capability and safety, while online regulation enables the vehicle to be responsive to disturbances, modeling errors and uncertainties. CPVS optimization occurs at design-time and at run-time. This paper surveys the run-time cooperative optimization or co-optimization of cyber and physical systems, which have historically been considered separately. A run-time CPVS is also cooperatively regulated or co-regulated when cyber and physical resources are utilized in a manner that is responsive to both cyber and physical system requirements. This paper surveys research that considers both cyber and physical resources in co-optimization and co-regulation schemes with applications to mobile robotic and vehicle systems. Time-varying sampling patterns, sensor scheduling, anytime control, feedback scheduling, task and motion planning and resource sharing are examined.
KW  - cyber-physical systems
KW  - control
KW  - real-time control
KW  - optimization
KW  - optimal control
KW  - robotics
DO  - 10.3390/s150923020
ER  -
TY  - EJOU
AU  - Mourcou, Quentin
AU  - Fleury, Anthony
AU  - Franco, Céline
AU  - Klopcic, Frédéric
AU  - Vuillerme, Nicolas
TI  - Performance Evaluation of Smartphone Inertial Sensors Measurement for Range of Motion
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 9
SN  - 1424-8220

AB  - Over the years, smartphones have become tools for scientific and clinical research. They can, for instance, be used to assess range of motion and joint angle measurement. In this paper, our aim was to determine if smartphones are reliable and accurate enough for clinical motion research. This work proposes an evaluation of different smartphone sensors performance and different manufacturer algorithm performances with the comparison to the gold standard, an industrial robotic arm with an actual standard use inertial motion unit in clinical measurement, an Xsens product. Both dynamic and static protocols were used to perform these comparisons. Root Mean Square (RMS) mean values results for static protocol are under 0.3° for the different smartphones. RMS mean values results for dynamic protocol are more prone to bias induced by Euler angle representation. Statistical results prove that there are no filter effect on results for both protocols and no hardware effect. Smartphones performance can be compared to the Xsens gold standard for clinical research.
KW  - smartphone sensing
KW  - IMU
KW  - Kalman filter
KW  - validation
DO  - 10.3390/s150923168
ER  -
TY  - EJOU
AU  - Gökçe, Fatih
AU  - Üçoluk, Göktürk
AU  - Şahin, Erol
AU  - Kalkan, Sinan
TI  - Vision-Based Detection and Distance Estimation of Micro Unmanned Aerial Vehicles
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 9
SN  - 1424-8220

AB  - Detection and distance estimation of micro unmanned aerial vehicles (mUAVs) is crucial for (i) the detection of intruder mUAVs in protected environments; (ii) sense and avoid purposes on mUAVs or on other aerial vehicles and (iii) multi-mUAV control scenarios, such as environmental monitoring, surveillance and exploration. In this article, we evaluate vision algorithms as alternatives for detection and distance estimation of mUAVs, since other sensing modalities entail certain limitations on the environment or on the distance. For this purpose, we test Haar-like features, histogram of gradients (HOG) and local binary patterns (LBP) using cascades of boosted classifiers. Cascaded boosted classifiers allow fast processing by performing detection tests at multiple stages, where only candidates passing earlier simple stages are processed at the preceding more complex stages. We also integrate a distance estimation method with our system utilizing geometric cues with support vector regressors. We evaluated each method on indoor and outdoor videos that are collected in a systematic way and also on videos having motion blur. Our experiments show that, using boosted cascaded classifiers with LBP, near real-time detection and distance estimation of mUAVs are possible in about 60 ms indoors (1032 × 778 resolution) and 150 ms outdoors (1280 × 720 resolution) per frame, with a detection rate of 0.96 F-score. However, the cascaded classifiers using Haar-like features lead to better distance estimation since they can position the bounding boxes on mUAVs more accurately. On the other hand, our time analysis yields that the cascaded classifiers using HOG train and run faster than the other algorithms.
KW  - UAV
KW  - micro UAV
KW  - vision
KW  - detection
KW  - distance estimation
KW  - cascaded classifiers
DO  - 10.3390/s150923805
ER  -
TY  - EJOU
AU  - Feng, Quanlong
AU  - Gong, Jianhua
AU  - Liu, Jiantao
AU  - Li, Yi
TI  - Flood Mapping Based on Multiple Endmember Spectral Mixture Analysis and Random Forest Classifier—The Case of Yuyao, China
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 9
SN  - 2072-4292

AB  - Remote sensing is recognized as a valuable tool for flood mapping due to its synoptic view and continuous coverage of the flooding event. This paper proposed a hybrid approach based on multiple endmember spectral analysis (MESMA) and Random Forest classifier to extract inundated areas in Yuyao City in China using medium resolution optical imagery. MESMA was adopted to tackle the mixing pixel problem induced by medium resolution data. Specifically, 35 optimal endmembers were selected to construct a total of 3111 models in the MESMA procedure to derive accurate fraction information. A multi-dimensional feature space was constructed including the normalized difference water index (NDWI), topographical parameters of height, slope, and aspect together with the fraction maps. A Random Forest classifier consisting of 200 decision trees was adopted to classify the post-flood image based on the above multi-features. Experimental results indicated that the proposed method can extract the inundated areas precisely with a classification accuracy of 94% and a Kappa index of 0.88. The inclusion of fraction information can help improve the mapping accuracy with an increase of 2.5%. Moreover, the proposed method also outperformed the maximum likelihood classifier and the NDWI thresholding method. This research provided a useful reference for flood mapping using medium resolution optical remote sensing imagery.
KW  - flood mapping
KW  - spectral mixture analysis
KW  - random forest
KW  - medium  resolution imagery
DO  - 10.3390/rs70912539
ER  -
TY  - EJOU
AU  - Akcay, Ozgun
TI  - Landslide Fissure Inference Assessment by ANFIS and Logistic Regression Using UAS-Based Photogrammetry
T2  - ISPRS International Journal of Geo-Information

PY  - 2015
VL  - 4
IS  - 4
SN  - 2220-9964

AB  - Unmanned Aerial Systems (UAS) are now capable of gathering high-resolution data, therefore, landslides can be explored in detail at larger scales. In this research, 132 aerial photographs were captured, and 85,456 features were detected and matched automatically using UAS photogrammetry. The root mean square (RMS) values of the image coordinates of the Ground Control Points (GPCs) varied from 0.521 to 2.293 pixels, whereas maximum RMS values of automatically matched features was calculated as 2.921 pixels. Using the 3D point cloud, which was acquired by aerial photogrammetry, the raster datasets of the aspect, slope, and maximally stable extremal regions (MSER) detecting visual uniformity, were defined as three variables, in order to reason fissure structures on the landslide surface. In this research, an Adaptive Neuro Fuzzy Inference System (ANFIS) and a Logistic Regression (LR) were implemented using training datasets to infer fissure data appropriately. The accuracy of the predictive models was evaluated by drawing receiver operating characteristic (ROC) curves and by calculating the area under the ROC curve (AUC). The experiments exposed that high-resolution imagery is an indispensable data source to model and validate landslide fissures appropriately.
KW  - photogrammetry
KW  - fuzzy logic
KW  - landslide
KW  - fissure
KW  - orthophotos
KW  - image processing
KW  - Unmanned Aerial System (UAS)
DO  - 10.3390/ijgi4042131
ER  -
TY  - EJOU
AU  - Casado, Monica R.
AU  - Gonzalez, Rocio B.
AU  - Kriechbaumer, Thomas
AU  - Veal, Amanda
TI  - Automated Identification of River Hydromorphological Features Using UAV High Resolution Aerial Imagery
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 11
SN  - 1424-8220

AB  - European legislation is driving the development of methods for river ecosystem protection in light of concerns over water quality and ecology. Key to their success is the accurate and rapid characterisation of physical features (i.e., hydromorphology) along the river. Image pattern recognition techniques have been successfully used for this purpose. The reliability of the methodology depends on both the quality of the aerial imagery  and the pattern recognition technique used. Recent studies have proved the potential of Unmanned Aerial Vehicles (UAVs) to increase the quality of the imagery by capturing high resolution photography. Similarly, Artificial Neural Networks (ANN) have been shown to be a high precision tool for automated recognition of environmental patterns. This paper presents a UAV based framework for the identification of hydromorphological features from high resolution RGB aerial imagery using a novel classification technique based on ANNs. The framework is developed for a 1.4 km river reach along the river Dee in Wales, United Kingdom. For this purpose, a Falcon 8 octocopter was used to gather  2.5 cm resolution imagery. The results show that the accuracy of the framework is above 81%, performing particularly well at recognising vegetation. These results leverage the use of UAVs for environmental policy implementation and demonstrate the potential of ANNs and RGB imagery for high precision river monitoring and river management.
KW  - Unmanned Aerial Vehicle
KW  - photogrammetry
KW  - Artificial Neural Network
KW  - feature recognition
KW  - hydromorphology
DO  - 10.3390/s151127969
ER  -
TY  - EJOU
AU  - Feng, Quanlong
AU  - Gong, Jianhua
AU  - Liu, Jiantao
AU  - Li, Yi
TI  - Monitoring Cropland Dynamics of the Yellow River Delta based on Multi-Temporal Landsat Imagery over 1986 to 2015
T2  - Sustainability

PY  - 2015
VL  - 7
IS  - 11
SN  - 2071-1050

AB  - Natural deltas can provide human beings with flat and fertile land to be cultivated. It is important to monitor cropland dynamics to provide policy-relevant information for regional sustainable development. This paper utilized Landsat imagery to study the cropland dynamics of the Yellow River Delta during the last three decades. Multi-temporal Landsat data were used to account for the phenological variations of different plants. Several spectral and textural features were adopted to increase the between-class separability. The robust random forest classifier was used to generate the land cover maps of the Yellow River Delta for 1986, 1995, 2005 and 2015. Experimental results indicated that the proposed methodology showed good performance with an average classification accuracy of 89.44%. The spatial-temporal analysis indicated that the cropland area increased from 467.6 km2 in 1986 to 718.5 km2 in 2015 with an average growth rate of 8.65 km2/year. The newly created croplands were mainly due to the reclamation of grassland and bare soil while the losses of croplands were due to abandoned cultivation and urban sprawl. The results demonstrate that a sustainable perspective should be adopted by the decision makers in order to simultaneously maintain food security, industrial development and ecosystem safety.
KW  - cropland
KW  - the Yellow River Delta
KW  - multi-temporal
KW  - random forest
KW  - landsat
DO  - 10.3390/su71114834
ER  -
TY  - EJOU
AU  - Näsi, Roope
AU  - Honkavaara, Eija
AU  - Lyytikäinen-Saarenmaa, Päivi
AU  - Blomqvist, Minna
AU  - Litkey, Paula
AU  - Hakala, Teemu
AU  - Viljanen, Niko
AU  - Kantola, Tuula
AU  - Tanhuanpää, Topi
AU  - Holopainen, Markus
TI  - Using UAV-Based Photogrammetry and Hyperspectral Imaging for Mapping Bark Beetle Damage at Tree-Level
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 11
SN  - 2072-4292

AB  - Low-cost, miniaturized hyperspectral imaging technology is becoming available for small unmanned aerial vehicle (UAV) platforms. This technology can be efficient in carrying out small-area inspections of anomalous reflectance characteristics of trees at a very high level of detail. Increased frequency and intensity of insect induced forest disturbance has established a new demand for effective methods suitable in mapping and monitoring tasks. In this investigation, a novel miniaturized hyperspectral frame imaging sensor operating in the wavelength range of 500–900 nm was used to identify mature Norway spruce (Picea abies L. Karst.) trees suffering from infestation, representing a different outbreak phase, by the European spruce bark beetle (Ips typographus L.). We developed a new processing method for analyzing spectral characteristic for high spatial resolution photogrammetric and hyperspectral images in forested environments, as well as for identifying individual anomalous trees. The dense point clouds, measured using image matching, enabled detection of single trees with an accuracy of 74.7%. We classified the trees into classes of healthy, infested and dead, and the results were promising. The best results for the overall accuracy were 76% (Cohen’s kappa 0.60), when using three color classes (healthy, infested, dead). For two color classes (healthy, dead), the best overall accuracy was 90% (kappa 0.80). The survey methodology based on high-resolution hyperspectral imaging will be of a high practical value for forest health management, indicating a status of bark beetle outbreak in time.
KW  - bark beetle
KW  - classification
KW  - dense matching
KW  - digital surface model
KW  - hyperspectral
KW  - insect outbreak
KW  - photogrammetry
KW  - radiometry
KW  - UAV
DO  - 10.3390/rs71115467
ER  -
TY  - EJOU
AU  - Li, Geng
AU  - Zhang, Pengfei
AU  - Wei, Guo
AU  - Xie, Yuanping
AU  - Yu, Xudong
AU  - Long, Xingwu
TI  - Multiple-Point Temperature Gradient Algorithm for Ring Laser Gyroscope Bias Compensation
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 12
SN  - 1424-8220

AB  - To further improve ring laser gyroscope (RLG) bias stability, a multiple-point temperature gradient algorithm is proposed for RLG bias compensation in this paper. Based on the multiple-point temperature measurement system, a complete thermo-image of the RLG block is developed. Combined with the multiple-point temperature gradients between different points of the RLG block, the particle swarm optimization algorithm is used to tune the support vector machine (SVM) parameters, and an optimized design for selecting the thermometer locations is also discussed. The experimental results validate the superiority of the introduced method and enhance the precision and generalizability in the RLG bias compensation model.
KW  - error compensation
KW  - particle swarm optimization
KW  - ring laser gyroscope
KW  - support vector machine
KW  - gradient methods
KW  - temperature sensors
KW  - temperature measurement
DO  - 10.3390/s151229777
ER  -
TY  - EJOU
AU  - Coppejans, Hugo H. G.
AU  - Myburgh, Herman C.
TI  - A Primer on Autonomous Aerial Vehicle Design
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 12
SN  - 1424-8220

AB  - There is a large amount of research currently being done on autonomous micro-aerial vehicles (MAV), such as quadrotor helicopters or quadcopters. The ability to create a working autonomous MAV depends mainly on integrating a simultaneous localization and mapping (SLAM) solution with the rest of the system. This paper provides an introduction for creating an autonomous MAV for enclosed environments, aimed at students and professionals alike. The standard autonomous system and MAV automation are discussed, while we focus on the core concepts of SLAM systems and trajectory planning algorithms. The advantages and disadvantages of using remote processing are evaluated, and recommendations are made regarding the viability of on-board processing. Recommendations are made regarding best practices to serve as a guideline for aspirant MAV designers.
KW  - autonomous
KW  - quadcopter
KW  - MAV
KW  - SLAM
KW  - data processing
KW  - compression
KW  - Microsoft Kinect
KW  - stereo cameras
KW  - LiDAR
DO  - 10.3390/s151229785
ER  -
TY  - EJOU
AU  - Ali, Iftikhar
AU  - Greifeneder, Felix
AU  - Stamenkovic, Jelena
AU  - Neumann, Maxim
AU  - Notarnicola, Claudia
TI  - Review of Machine Learning Approaches for Biomass and Soil Moisture Retrievals from Remote Sensing Data
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 12
SN  - 2072-4292

AB  - The enormous increase of remote sensing data from airborne and space-borne platforms, as well as ground measurements has directed the attention of scientists towards new and efficient retrieval methodologies. Of particular importance is the consideration of the large extent and the high dimensionality (spectral, temporal and spatial) of remote sensing data. Moreover, the launch of the Sentinel satellite family will increase the availability of data, especially in the temporal domain, at no cost to the users. To analyze these data and to extract relevant features, such as essential climate variables (ECV), specific methodologies need to be exploited. Among these, greater attention is devoted to machine learning methods due to their flexibility and the capability to process large number of inputs and to handle non-linear problems. The main objective of this paper is to provide a review of research that is being carried out to retrieve two critically important terrestrial biophysical quantities (vegetation biomass and soil moisture) from remote sensing data using machine learning methods.
KW  - remote sensing
KW  - soil moisture
KW  - biomass
KW  - retrieval algorithms
KW  - machine learning
KW  - artificial neural networks
KW  - SVM
KW  - regression
KW  - biophysical parameters
DO  - 10.3390/rs71215841
ER  -
TY  - EJOU
AU  - Shi, Yan
AU  - Zhang, Chao
AU  - Li, Rui
AU  - Cai, Maolin
AU  - Jia, Guanwei
TI  - Theory and Application of Magnetic Flux Leakage Pipeline Detection
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 12
SN  - 1424-8220

AB  - Magnetic flux leakage (MFL) detection is one of the most popular methods of pipeline inspection. It is a nondestructive testing technique which uses magnetic sensitive sensors to detect the magnetic leakage field of defects on both the internal and external surfaces of pipelines. This paper introduces the main principles, measurement and processing of MFL data. As the key point of a quantitative analysis of MFL detection, the identification of the leakage magnetic signal is also discussed. In addition, the advantages and disadvantages of different identification methods are analyzed. Then the paper briefly introduces the expert systems used. At the end of this paper, future developments in pipeline MFL detection are predicted.
KW  - in-line inspection
KW  - magnetic flux leakage detection
KW  - pipeline
KW  - review
DO  - 10.3390/s151229845
ER  -
TY  - EJOU
AU  - Olivares-Mendez, Miguel A.
AU  - Fu, Changhong
AU  - Ludivig, Philippe
AU  - Bissyandé, Tegawendé F.
AU  - Kannan, Somasundar
AU  - Zurad, Maciej
AU  - Annaiyan, Arun
AU  - Voos, Holger
AU  - Campoy, Pascual
TI  - Towards an Autonomous Vision-Based Unmanned Aerial System against Wildlife Poachers
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 12
SN  - 1424-8220

AB  - Poaching is an illegal activity that remains out of control in many countries. Based on the 2014 report of the United Nations and Interpol, the illegal trade of global wildlife and natural resources amounts to nearly                                        $               213                                  billion every year, which is even helping to fund armed conflicts. Poaching activities around the world are further pushing many animal species on the brink of extinction. Unfortunately, the traditional methods to fight against poachers are not enough, hence the new demands for more efficient approaches. In this context, the use of new technologies on sensors and algorithms, as well as aerial platforms is crucial to face the high increase of poaching activities in the last few years. Our work is focused on the use of vision sensors on UAVs for the detection and tracking of animals and poachers, as well as the use of such sensors to control quadrotors during autonomous vehicle following and autonomous landing.
KW  - unmanned aerial vehicles
KW  - computer vision
KW  - animal tracking
KW  - face detection
KW  - vision-based control
KW  - object following
KW  - autonomous navigation
KW  - autonomous landing
KW  - anti-poaching
DO  - 10.3390/s151229861
ER  -
TY  - EJOU
AU  - Huang, Yan
AU  - Chen, Zuoqi
AU  - Wu, Bin
AU  - Chen, Liang
AU  - Mao, Weiqing
AU  - Zhao, Feng
AU  - Wu, Jianping
AU  - Wu, Junhan
AU  - Yu, Bailang
TI  - Estimating Roof Solar Energy Potential in the Downtown Area Using a GPU-Accelerated Solar Radiation Model and Airborne LiDAR Data
T2  - Remote Sensing

PY  - 2015
VL  - 7
IS  - 12
SN  - 2072-4292

AB  - Solar energy, as a clean and renewable resource is becoming increasingly important in the global context of climate change and energy crisis. Utilization of solar energy in urban areas is of great importance in urban energy planning, environmental conservation, and sustainable development. However, available spaces for solar panel installation in cities are quite limited except for building roofs. Furthermore, complex urban 3D morphology greatly affects sunlit patterns on building roofs, especially in downtown areas, which makes the determination of roof solar energy potential a challenging task. The object of this study is to estimate the solar radiation on building roofs in an urban area in Shanghai, China, and select suitable spaces for installing solar panels that can effectively utilize solar energy. A Graphic Processing Unit (GPU)-based solar radiation model named SHORTWAVE-C simulating direct and non-direct solar radiation intensity was developed by adding the capability of considering cloud influence into the previous SHORTWAVE model. Airborne Light Detection and Ranging (LiDAR) data was used as the input of the SHORTWAVE-C model and to investigate the morphological characteristics of the study area. The results show that the SHORTWAVE-C model can accurately estimate the solar radiation intensity in a complex urban environment under cloudy conditions, and the GPU acceleration method can reduce the computation time by up to 46%. Two sites with different building densities and rooftop structures were selected to illustrate the influence of urban morphology on the solar radiation and solar illumination duration. Based on the findings, an object-based method was implemented to identify suitable places for rooftop solar panel installation that can fully utilize the solar energy potential. Our study provides useful strategic guidelines for the selection and assessment of roof solar energy potential for urban energy planning.
KW  - solar radiation
KW  - urban area
KW  - roof planes
KW  - LiDAR
KW  - GPU
DO  - 10.3390/rs71215877
ER  -
TY  - EJOU
AU  - Cai, Jia
AU  - Huang, Panfeng
AU  - Zhang, Bin
AU  - Wang, Dongke
TI  - A TSR Visual Servoing System Based on a Novel Dynamic Template Matching Method
T2  - Sensors

PY  - 2015
VL  - 15
IS  - 12
SN  - 1424-8220

AB  - The so-called Tethered Space Robot (TSR) is a novel active space debris removal system. To solve its problem of non-cooperative target recognition during short-distance rendezvous events, this paper presents a framework for a real-time visual servoing system using non-calibrated monocular-CMOS (Complementary Metal Oxide Semiconductor). When a small template is used for matching with a large scene, it always leads to mismatches, so a novel template matching algorithm to solve the problem is presented. Firstly, the novel matching algorithm uses a hollow annulus structure according to a FAST (Features from Accelerated Segment) algorithm and makes the method be rotation-invariant. Furthermore, the accumulative deviation can be decreased by the hollow structure. The matching function is composed of grey and gradient differences between template and object image, which help it reduce the effects of illumination and noises. Then, a dynamic template update strategy is designed to avoid tracking failures brought about by wrong matching or occlusion. Finally, the system synthesizes the least square integrated predictor, realizing tracking online in complex circumstances. The results of ground experiments show that the proposed algorithm can decrease the need for sophisticated computation and improves matching accuracy.
KW  - Tethered Space Robot
KW  - object recognition
KW  - template matching
KW  - visual servoing
KW  - target tracking
DO  - 10.3390/s151229884
ER  -
TY  - EJOU
AU  - Fremont, Vincent
AU  - Bui, Manh T.
AU  - Boukerroui, Djamal
AU  - Letort, Pierrick
TI  - Vision-Based People Detection System for Heavy Machine Applications
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 1
SN  - 1424-8220

AB  - This paper presents a vision-based people detection system for improving safety in heavy machines. We propose a perception system composed of a monocular fisheye camera and a LiDAR. Fisheye cameras have the advantage of a wide field-of-view, but the strong distortions that they create must be handled at the detection stage. Since people detection in fisheye images has not been well studied, we focus on investigating and quantifying the impact that strong radial distortions have on the appearance of people, and we propose approaches for handling this specificity, adapted from state-of-the-art people detection approaches. These adaptive approaches nevertheless have the drawback of high computational cost and complexity. Consequently, we also present a framework for harnessing the LiDAR modality in order to enhance the detection algorithm for different camera positions. A sequential LiDAR-based fusion architecture is used, which addresses directly the problem of reducing false detections and computational cost in an exclusively vision-based system. A heavy machine dataset was built, and different experiments were carried out to evaluate the performance of the system. The results are promising, in terms of both processing speed and performance.
KW  - heavy machines
KW  - sensor fusion
KW  - pedestrian detection
KW  - deformable part model
KW  - fisheye images
KW  - histogram of oriented gradients
DO  - 10.3390/s16010128
ER  -
TY  - EJOU
AU  - Al-Rawabdeh, Abdulla
AU  - He, Fangning
AU  - Moussa, Adel
AU  - El-Sheimy, Naser
AU  - Habib, Ayman
TI  - Using an Unmanned Aerial Vehicle-Based Digital Imaging System to Derive a 3D Point Cloud for Landslide Scarp Recognition
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 2
SN  - 2072-4292

AB  - Landslides often cause economic losses, property damage, and loss of lives. Monitoring landslides using high spatial and temporal resolution imagery and the ability to quickly identify landslide regions are the basis for emergency disaster management. This study presents a comprehensive system that uses unmanned aerial vehicles (UAVs) and Semi-Global dense Matching (SGM) techniques to identify and extract landslide scarp data. The selected study area is located along a major highway in a mountainous region in Jordan, and contains creeping landslides induced by heavy rainfall. Field observations across the slope body and a deformation analysis along the highway and existing gabions indicate that the slope is active and that scarp features across the slope will continue to open and develop new tension crack features, leading to the downward movement of rocks. The identification of landslide scarps in this study was performed via a dense 3D point cloud of topographic information generated from high-resolution images captured using a low-cost UAV and a target-based camera calibration procedure for a low-cost large-field-of-view camera. An automated approach was used to accurately detect and extract the landslide head scarps based on geomorphological factors: the ratio of normalized Eigenvalues (i.e., λ1/λ2 ≥ λ3) derived using principal component analysis, topographic surface roughness index values, and local-neighborhood slope measurements from the 3D image-based point cloud. Validation of the results was performed using root mean square error analysis and a confusion (error) matrix between manually digitized landslide scarps and the automated approaches. The experimental results using the fully automated 3D point-based analysis algorithms show that these approaches can effectively distinguish landslide scarps. The proposed algorithms can accurately identify and extract landslide scarps with centimeter-scale accuracy. In addition, the combination of UAV-based imagery, 3D scene reconstruction, and landslide scarp recognition/extraction algorithms can provide flexible and effective tool for monitoring landslide scarps and is acceptable for landslide mapping purposes.
KW  - landslides scarps
KW  - geomorphology
KW  - slope
KW  - surface roughness
KW  - Semi-Global dense matching (SGM)
KW  - unmanned aerial vehicles (UAVs)
DO  - 10.3390/rs8020095
ER  -
TY  - EJOU
AU  - Yue, Bo
AU  - Wang, Shuang
AU  - Liang, Xuefeng
AU  - Jiao, Licheng
AU  - Xu, Caijin
TI  - Joint Prior Learning for Visual Sensor Network Noisy Image Super-Resolution
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 3
SN  - 1424-8220

AB  - The visual sensor network (VSN), a new type of wireless sensor network composed of low-cost wireless camera nodes, is being applied for numerous complex visual analyses in wild environments, such as visual surveillance, object recognition, etc. However, the captured images/videos are often low resolution with noise. Such visual data cannot be directly delivered to the advanced visual analysis. In this paper, we propose a joint-prior image super-resolution (JPISR) method using expectation maximization (EM) algorithm to improve VSN image quality. Unlike conventional methods that only focus on upscaling images, JPISR alternatively solves upscaling mapping and denoising in the E-step and M-step. To meet the requirement of the M-step, we introduce a novel non-local group-sparsity image filtering method to learn the explicit prior and induce the geometric duality between images to learn the implicit prior. The EM algorithm inherently combines the explicit prior and implicit prior by joint learning. Moreover, JPISR does not rely on large external datasets for training, which is much more practical in a VSN. Extensive experiments show that JPISR outperforms five state-of-the-art methods in terms of both PSNR, SSIM and visual perception.
KW  - visual sensor network
KW  - image super-resolution
KW  - image denoising
KW  - prior learning
KW  - EM algorithm
DO  - 10.3390/s16030288
ER  -
TY  - EJOU
AU  - Vetrivel, Anand
AU  - Gerke, Markus
AU  - Kerle, Norman
AU  - Vosselman, George
TI  - Identification of Structurally Damaged Areas in Airborne Oblique Images Using a Visual-Bag-of-Words Approach
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 3
SN  - 2072-4292

AB  - Automatic post-disaster mapping of building damage using remote sensing images is an important and time-critical element of disaster management. The characteristics of remote sensing images available immediately after the disaster are not certain, since they may vary in terms of capturing platform, sensor-view, image scale, and scene complexity. Therefore, a generalized method for damage detection that is impervious to the mentioned image characteristics is desirable. This study aims to develop a method to perform grid-level damage classification of remote sensing images by detecting the damage corresponding to debris, rubble piles, and heavy spalling within a defined grid, regardless of the aforementioned image characteristics. The Visual-Bag-of-Words (BoW) is one of the most widely used and proven frameworks for image classification in the field of computer vision. The framework adopts a kind of feature representation strategy that has been shown to be more efficient for image classification—regardless of the scale and clutter—than conventional global feature representations. In this study supervised models using various radiometric descriptors (histogram of gradient orientations (HoG) and Gabor wavelets) and classifiers (SVM, Random Forests, and Adaboost) were developed for damage classification based on both BoW and conventional global feature representations, and tested with four datasets. Those vary according to the aforementioned image characteristics. The BoW framework outperformed conventional global feature representation approaches in all scenarios (i.e., for all combinations of feature descriptors, classifiers, and datasets), and produced an average accuracy of approximately 90%. Particularly encouraging was an accuracy improvement by 14% (from 77% to 91%) produced by BoW over global representation for the most complex dataset, which was used to test the generalization capability.
KW  - damage detection
KW  - feature representation
KW  - oblique airborne images
KW  - supervised learning
KW  - texture
KW  - UAV
KW  - Visual-Bag-of-Words
DO  - 10.3390/rs8030231
ER  -
TY  - EJOU
AU  - Karakizi, Christina
AU  - Oikonomou, Marios
AU  - Karantzalos, Konstantinos
TI  - Vineyard Detection and Vine Variety Discrimination from Very High Resolution Satellite Data
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 3
SN  - 2072-4292

AB  - In order to exploit remote sensing data operationally for precision agriculture applications, efficient and automated methods are required for the accurate detection of vegetation, crops and different crop varieties. To this end, we have designed, developed and evaluated an object-based classification framework towards the detection of vineyards, the vine canopy extraction and the vine variety discrimination from very high resolution multispectral data. A novel set of spectral, spatial and textural features, as well as rules, segmentation scales and a set of parameters are proposed based on object-based image analysis. The validation of the developed methodology was carried out on multitemporal WorldView-2 satellite data at four different viticulture regions in Greece. Concurrent in situ canopy reflectance observations were acquired from a portable spectroradiometer during the field campaigns. The performed quantitative evaluation indicated that the developed approach managed in all cases to detect vineyards with high completeness and correctness detection rates, i.e., over 89%. The vine canopy extraction methodology was validated with overall accuracy (OA) rates of above 96%. The quantitative evaluation regarding the vine variety discrimination task, including experiments with up to six different varieties, reached OA rates above 85% at the parcel level. The combined analysis of the experimental results with the spectral signatures from the in situ reflectance data indicated that certain vine varieties (e.g., Merlot) presented distinct spectral patterns across the VNIR spectrum.
KW  - object-based image analysis
KW  - classification
KW  - precision viticulture
KW  - spectral signatures
KW  - features
KW  - crops
DO  - 10.3390/rs8030235
ER  -
TY  - EJOU
AU  - Sun, Weiwei
AU  - Jiang, Man
AU  - Li, Weiyue
AU  - Liu, Yinnian
TI  - A Symmetric Sparse Representation Based Band Selection Method for Hyperspectral Imagery Classification
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 3
SN  - 2072-4292

AB  - A novel Symmetric Sparse Representation (SSR) method has been presented to solve the band selection problem in hyperspectral imagery (HSI) classification. The method assumes that the selected bands and the original HSI bands are sparsely represented by each other, i.e., symmetrically represented. The method formulates band selection into a famous problem of archetypal analysis and selects the representative bands by finding the archetypes in the minimal convex hull containing the HSI band points (i.e., one band corresponds to a band point in the high-dimensional feature space). Without any other parameter tuning work except the size of band subset, the SSR optimizes the band selection program using the block-coordinate descent scheme. Four state-of-the-art methods are utilized to make comparisons with the SSR on the Indian Pines and PaviaU HSI datasets. Experimental results illustrate that SSR outperforms all four methods in classification accuracies (i.e., Average Classification Accuracy (ACA) and Overall Classification Accuracy (OCA)) and three quantitative evaluation results (i.e., Average Information Entropy (AIE), Average Correlation Coefficient (ACC) and Average Relative Entropy (ARE)), whereas it takes the second shortest computational time. Therefore, the proposed SSR is a good alternative method for band selection of HSI classification in realistic applications.
KW  - symmetric sparse representation
KW  - band selection
KW  - hyperspectral imagery
KW  - classification
KW  - archetypal analysis
DO  - 10.3390/rs8030238
ER  -
TY  - EJOU
AU  - Zhang, Jian
AU  - Yang, Chenghai
AU  - Song, Huaibo
AU  - Hoffmann, Wesley C.
AU  - Zhang, Dongyan
AU  - Zhang, Guozhong
TI  - Evaluation of an Airborne Remote Sensing Platform Consisting of Two Consumer-Grade Cameras for Crop Identification
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 3
SN  - 2072-4292

AB  - Remote sensing systems based on consumer-grade cameras have been increasingly used in scientific research and remote sensing applications because of their low cost and ease of use. However, the performance of consumer-grade cameras for practical applications has not been well documented in related studies. The objective of this research was to apply three commonly-used classification methods (unsupervised, supervised, and object-based) to three-band imagery with RGB (red, green, and blue bands) and four-band imagery with RGB and near-infrared (NIR) bands to evaluate the performance of a dual-camera imaging system for crop identification. Airborne images were acquired from a cropping area in Texas and mosaicked and georeferenced. The mosaicked imagery was classified using the three classification methods to assess the usefulness of NIR imagery for crop identification and to evaluate performance differences between the object-based and pixel-based methods. Image classification and accuracy assessment showed that the additional NIR band imagery improved crop classification accuracy over the RGB imagery and that the object-based method achieved better results with additional non-spectral image features. The results from this study indicate that the airborne imaging system based on two consumer-grade cameras used in this study can be useful for crop identification and other agricultural applications.
KW  - consumer-grade camera
KW  - crop identification
KW  - RGB
KW  - near-infrared
KW  - pixel-based classification
KW  - object-based classification
DO  - 10.3390/rs8030257
ER  -
TY  - EJOU
AU  - Ma, Yalong
AU  - Wu, Xinkai
AU  - Yu, Guizhen
AU  - Xu, Yongzheng
AU  - Wang, Yunpeng
TI  - Pedestrian Detection and Tracking from Low-Resolution Unmanned Aerial Vehicle Thermal Imagery
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 4
SN  - 1424-8220

AB  - Driven by the prominent thermal signature of humans and following the growing availability of unmanned aerial vehicles (UAVs), more and more research efforts have been focusing on the detection and tracking of pedestrians using thermal infrared images recorded from UAVs. However, pedestrian detection and tracking from the thermal images obtained from UAVs pose many challenges due to the low-resolution of imagery, platform motion, image instability and the relatively small size of the objects. This research tackles these challenges by proposing a pedestrian detection and tracking system. A two-stage blob-based approach is first developed for pedestrian detection. This approach first extracts pedestrian blobs using the regional gradient feature and geometric constraints filtering and then classifies the detected blobs by using a linear Support Vector Machine (SVM) with a hybrid descriptor, which sophisticatedly combines Histogram of Oriented Gradient (HOG) and Discrete Cosine Transform (DCT) features in order to achieve accurate detection. This research further proposes an approach for pedestrian tracking. This approach employs the feature tracker with the update of detected pedestrian location to track pedestrian objects from the registered videos and extracts the motion trajectory data. The proposed detection and tracking approaches have been evaluated by multiple different datasets, and the results illustrate the effectiveness of the proposed methods. This research is expected to significantly benefit many transportation applications, such as the multimodal traffic performance measure, pedestrian behavior study and pedestrian-vehicle crash analysis. Future work will focus on using fused thermal and visual images to further improve the detection efficiency and effectiveness.
KW  - pedestrian detection
KW  - pedestrian tracking
KW  - aerial thermal image
KW  - video registration
KW  - unmanned aerial vehicle
DO  - 10.3390/s16040446
ER  -
TY  - EJOU
AU  - Zhen, Zhen
AU  - Quackenbush, Lindi J.
AU  - Zhang, Lianjun
TI  - Trends in Automatic Individual Tree Crown Detection and Delineation—Evolution of LiDAR Data
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 4
SN  - 2072-4292

AB  - Automated individual tree crown detection and delineation (ITCD) using remotely sensed data plays an increasingly significant role in efficiently, accurately, and completely monitoring forests. This paper reviews trends in ITCD research from 1990–2015 from several perspectives—data/forest type, method applied, accuracy assessment and research objective—with a focus on studies using LiDAR data. This review shows that active sources are becoming more prominent in ITCD studies. Studies using active data—LiDAR in particular—accounted for 80% of the total increase over the entire time period, those using passive data or fusion of passive and active data comprised relatively small proportions of the total increase (8% and 12%, respectively). Additionally, ITCD research has moved from incremental adaptations of algorithms developed for passive data sources to innovative approaches that take advantage of the novel characteristics of active datasets like LiDAR. These improvements make it possible to explore more complex forest conditions (e.g., closed hardwood forests, suburban/urban forests) rather than a single forest type although most published ITCD studies still focused on closed softwood (41%) or mixed forest (22%). Approximately one-third of studies applied individual tree level (30%) assessment, with only a quarter reporting more comprehensive multi-level assessment (23%). Almost one-third of studies (32%) that concentrated on forest parameter estimation based on ITCD results had no ITCD-specific evaluation. Comparison of methods continues to be complicated by both choice of reference data and assessment metric; it is imperative to establish a standardized two-level assessment framework to evaluate and compare ITCD algorithms in order to provide specific recommendations about suitable applications of particular algorithms. However, the evolution of active remotely sensed data and novel platforms implies that automated ITCD will continue to be a promising technology and an attractive research topic for both the forestry and remote sensing communities.
KW  - tree detection
KW  - crown delineation
KW  - remotely sensed data
KW  - ITCD algorithm
KW  - forest type
KW  - accuracy assessment
DO  - 10.3390/rs8040333
ER  -
TY  - EJOU
AU  - Wang, Bo
AU  - Su, Yumin
AU  - Wan, Lei
TI  - A Sea-Sky Line Detection Method for Unmanned Surface Vehicles Based on Gradient Saliency
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 4
SN  - 1424-8220

AB  - Special features in real marine environments such as cloud clutter, sea glint and weather conditions always result in various kinds of interference in optical images, which make it very difficult for unmanned surface vehicles (USVs) to detect the sea-sky line (SSL) accurately. To solve this problem a saliency-based SSL detection method is proposed. Through the computation of gradient saliency the line features of SSL are enhanced effectively, while other interference factors are relatively suppressed, and line support regions are obtained by a region growing method on gradient orientation. The SSL identification is achieved according to region contrast, line segment length and orientation features, and optimal state estimation of SSL detection is implemented by introducing a cubature Kalman filter (CKF). In the end, the proposed method is tested on a benchmark dataset from the “XL” USV in a real marine environment, and the experimental results demonstrate that the proposed method is significantly superior to other state-of-the-art methods in terms of accuracy rate and real-time performance, and its accuracy and stability are effectively improved by the CKF.
KW  - unmanned surface vehicle
KW  - sea-sky line
KW  - gradient saliency
KW  - region growing
KW  - line support region
DO  - 10.3390/s16040543
ER  -
TY  - EJOU
AU  - Chuang, Yung-Chung M.
AU  - Shiu, Yi-Shiang
TI  - A Comparative Analysis of Machine Learning with WorldView-2 Pan-Sharpened Imagery for Tea Crop Mapping
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 5
SN  - 1424-8220

AB  - Tea is an important but vulnerable economic crop in East Asia, highly impacted by climate change. This study attempts to interpret tea land use/land cover (LULC) using very high resolution WorldView-2 imagery of central Taiwan with both pixel and object-based approaches. A total of 80 variables derived from each WorldView-2 band with pan-sharpening, standardization, principal components and gray level co-occurrence matrix (GLCM) texture indices transformation, were set as the input variables. For pixel-based image analysis (PBIA), 34 variables were selected, including seven principal components, 21 GLCM texture indices and six original WorldView-2 bands. Results showed that support vector machine (SVM) had the highest tea crop classification accuracy (OA = 84.70% and KIA = 0.690), followed by random forest (RF), maximum likelihood algorithm (ML), and logistic regression analysis (LR). However, the ML classifier achieved the highest classification accuracy (OA = 96.04% and KIA = 0.887) in object-based image analysis (OBIA) using only six variables. The contribution of this study is to create a new framework for accurately identifying tea crops in a subtropical region with real-time high-resolution WorldView-2 imagery without field survey, which could further aid agriculture land management and a sustainable agricultural product supply.
KW  - WorldView-2
KW  - tea crops
KW  - GLCM texture
KW  - pixel and object-based image analysis
KW  - random forest
KW  - support vector machine
DO  - 10.3390/s16050594
ER  -
TY  - EJOU
AU  - Alavi, Shamir
AU  - Arsenault, Dennis
AU  - Whitehead, Anthony
TI  - Quaternion-Based Gesture Recognition Using Wireless Wearable Motion Capture Sensors
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 5
SN  - 1424-8220

AB  - This work presents the development and implementation of a unified multi-sensor human motion capture and gesture recognition system that can distinguish between and classify six different gestures. Data was collected from eleven participants using a subset of five wireless motion sensors (inertial measurement units) attached to their arms and upper body from a complete motion capture system. We compare Support Vector Machines and Artificial Neural Networks on the same dataset under two different scenarios and evaluate the results. Our study indicates that near perfect classification accuracies are achievable for small gestures and that the speed of classification is sufficient to allow interactivity. However, such accuracies are more difficult to obtain when a participant does not participate in training, indicating that more work needs to be done in this area to create a system that can be used by the general population.
KW  - gesture recognition
KW  - wearable sensors
KW  - quaternions
KW  - pattern analysis
KW  - machine learning
KW  - support vector machines
KW  - artificial neural networks
DO  - 10.3390/s16050605
ER  -
TY  - EJOU
AU  - Vázquez-Arellano, Manuel
AU  - Griepentrog, Hans W.
AU  - Reiser, David
AU  - Paraforos, Dimitris S.
TI  - 3-D Imaging Systems for Agricultural Applications—A Review
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 5
SN  - 1424-8220

AB  - Efficiency increase of resources through automation of agriculture requires more information about the production process, as well as process and machinery status. Sensors are necessary for monitoring the status and condition of production by recognizing the surrounding structures such as objects, field structures, natural or artificial markers, and obstacles. Currently, three dimensional (3-D) sensors are economically affordable and technologically advanced to a great extent, so a breakthrough is already possible if enough research projects are commercialized. The aim of this review paper is to investigate the state-of-the-art of 3-D vision systems in agriculture, and the role and value that only 3-D data can have to provide information about environmental structures based on the recent progress in optical 3-D sensors. The structure of this research consists of an overview of the different optical 3-D vision techniques, based on the basic principles. Afterwards, their application in agriculture are reviewed. The main focus lays on vehicle navigation, and crop and animal husbandry. The depth dimension brought by 3-D sensors provides key information that greatly facilitates the implementation of automation and robotics in agriculture.
KW  - 3-D sensors
KW  - optical triangulation
KW  - time-of-flight
KW  - interferometry
KW  - agricultural automation
KW  - agricultural robotics
DO  - 10.3390/s16050618
ER  -
TY  - EJOU
AU  - Vanegas, Fernando
AU  - Gonzalez, Felipe
TI  - Enabling UAV Navigation with Sensor and Environmental Uncertainty in Cluttered and GPS-Denied Environments
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 5
SN  - 1424-8220

AB  - Unmanned Aerial Vehicles (UAV) can navigate with low risk in obstacle-free environments using ground control stations that plan a series of GPS waypoints as a path to follow. This GPS waypoint navigation does however become dangerous in environments where the GPS signal is faulty or is only present in some places and when the airspace is filled with obstacles. UAV navigation then becomes challenging because the UAV uses other sensors, which in turn generate uncertainty about its localisation and motion systems, especially if the UAV is a low cost platform. Additional uncertainty affects the mission when the UAV goal location is only partially known and can only be discovered by exploring and detecting a target. This navigation problem is established in this research as a Partially-Observable Markov Decision Process (POMDP), so as to produce a policy that maps a set of motion commands to belief states and observations. The policy is calculated and updated on-line while flying with a newly-developed system for UAV Uncertainty-Based Navigation (UBNAV), to navigate in cluttered and GPS-denied environments using observations and executing motion commands instead of waypoints. Experimental results in both simulation and real flight tests show that the UAV finds a path on-line to a region where it can explore and detect a target without colliding with obstacles. UBNAV provides a new method and an enabling technology for scientists to implement and test UAV navigation missions with uncertainty where targets must be detected using on-line POMDP in real flight scenarios.
KW  - unmanned aircraft
KW  - UAV target detection
KW  - Partially-Observable Markov Decision Process (POMDP)
KW  - path planning
KW  - Robotic Operating System (ROS)
KW  - uncertainty
KW  - robust navigation
DO  - 10.3390/s16050666
ER  -
TY  - EJOU
AU  - Fang, Shenghui
AU  - Tang, Wenchao
AU  - Peng, Yi
AU  - Gong, Yan
AU  - Dai, Can
AU  - Chai, Ruhui
AU  - Liu, Kan
TI  - Remote Estimation of Vegetation Fraction and Flower Fraction in Oilseed Rape with Unmanned Aerial Vehicle Data
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 5
SN  - 2072-4292

AB  - This study developed an approach for remote estimation of Vegetation Fraction (VF) and Flower Fraction (FF) in oilseed rape, which is a crop species with conspicuous flowers during reproduction. Canopy reflectance in green, red, red edge and NIR bands was obtained by a camera system mounted on an unmanned aerial vehicle (UAV) when oilseed rape was in the vegetative growth and flowering stage. The relationship of several widely-used Vegetation Indices (VI) vs. VF was tested and found to be different in different phenology stages. At the same VF when oilseed rape was flowering, canopy reflectance increased in all bands, and the tested VI decreased. Therefore, two algorithms to estimate VF were calibrated respectively, one for samples during vegetative growth and the other for samples during flowering stage. The results showed that the Visible Atmospherically Resistant Index (VARIgreen) worked most accurately for estimating VF in flower-free samples with an Root Mean Square Error (RMSE) of 3.56%, while the Enhanced Vegetation Index (EVI2) was the best in flower-containing samples with an RMSE of 5.65%. Based on reflectance in green and NIR bands, a technique was developed to identify whether a sample contained flowers and then to choose automatically the appropriate algorithm for its VF estimation. During the flowering season, we also explored the potential of using canopy reflectance or VIs to estimate FF in oilseed rape. No significant correlation was observed between VI and FF when soil was visible in the sensor’s field of view. Reflectance at 550 nm worked well for FF estimation with coefficient of determination (R2) above 0.6. Our model was validated in oilseed rape planted under different nitrogen fertilization applications and in different phenology stages. The results showed that it was able to predict VF and FF accurately in oilseed rape with RMSE below 6%.
KW  - vegetation fraction
KW  - flower fraction
KW  - canopy reflectance
KW  - unmanned aerial vehicle
KW  - oilseed rape
DO  - 10.3390/rs8050416
ER  -
TY  - EJOU
AU  - Kuffer, Monika
AU  - Pfeffer, Karin
AU  - Sliuzas, Richard
TI  - Slums from Space—15 Years of Slum Mapping Using Remote Sensing
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 6
SN  - 2072-4292

AB  - The body of scientific literature on slum mapping employing remote sensing methods has increased since the availability of more very-high-resolution (VHR) sensors. This improves the ability to produce information for pro-poor policy development and to build methods capable of supporting systematic global slum monitoring required for international policy development such as the Sustainable Development Goals. This review provides an overview of slum mapping-related remote sensing publications over the period of 2000–2015 regarding four dimensions: contextual factors, physical slum characteristics, data and requirements, and slum extraction methods. The review has shown the following results. First, our contextual knowledge on the diversity of slums across the globe is limited, and slum dynamics are not well captured. Second, a more systematic exploration of physical slum characteristics is required for the development of robust image-based proxies. Third, although the latest commercial sensor technologies provide image data of less than 0.5 m spatial resolution, thereby improving object recognition in slums, the complex and diverse morphology of slums makes extraction through standard methods difficult. Fourth, successful approaches show diversity in terms of extracted information levels (area or object based), implemented indicator sets (single or large sets) and methods employed (e.g., object-based image analysis (OBIA) or machine learning). In the context of a global slum inventory, texture-based methods show good robustness across cities and imagery. Machine-learning algorithms have the highest reported accuracies and allow working with large indicator sets in a computationally efficient manner, while the upscaling of pixel-level information requires further research. For local slum mapping, OBIA approaches show good capabilities of extracting both area- and object-based information. Ultimately, establishing a more systematic relationship between higher-level image elements and slum characteristics is essential to train algorithms able to analyze variations in slum morphologies to facilitate global slum monitoring.
KW  - slums
KW  - informal areas
KW  - urban remote sensing
KW  - Global South
KW  - VHR imagery
DO  - 10.3390/rs8060455
ER  -
TY  - EJOU
AU  - Pause, Marion
AU  - Schweitzer, Christian
AU  - Rosenthal, Michael
AU  - Keuck, Vanessa
AU  - Bumberger, Jan
AU  - Dietrich, Peter
AU  - Heurich, Marco
AU  - Jung, András
AU  - Lausch, Angela
TI  - In Situ/Remote Sensing Integration to Assess Forest Health—A Review
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 6
SN  - 2072-4292

AB  - For mapping, quantifying and monitoring regional and global forest health, satellite remote sensing provides fundamental data for the observation of spatial and temporal forest patterns and processes. While new remote-sensing technologies are able to detect forest data in high quality and large quantity, operational applications are still limited by deficits of in situ verification. In situ sampling data as input is required in order to add value to physical imaging remote sensing observations and possibilities to interlink the forest health assessment with biotic and abiotic factors. Numerous methods on how to link remote sensing and in situ data have been presented in the scientific literature using e.g. empirical and physical-based models. In situ data differs in type, quality and quantity between case studies. The irregular subsets of in situ data availability limit the exploitation of available satellite remote sensing data. To achieve a broad implementation of satellite remote sensing data in forest monitoring and management, a standardization of in situ data, workflows and products is essential and necessary for user acceptance. The key focus of the review is a discussion of concept and is designed to bridge gaps of understanding between forestry and remote sensing science community. Methodological approaches for in situ/remote-sensing implementation are organized and evaluated with respect to qualifying for forest monitoring. Research gaps and recommendations for standardization of remote-sensing based products are discussed. Concluding the importance of outstanding organizational work to provide a legally accepted framework for new information products in forestry are highlighted.
KW  - remote sensing
KW  - in situ sampling
KW  - sensor networks
KW  - monitoring
KW  - standardization
KW  - forest health
KW  - sentinel satellites
KW  - Copernicus
DO  - 10.3390/rs8060471
ER  -
TY  - EJOU
AU  - Coy, André
AU  - Rankine, Dale
AU  - Taylor, Michael
AU  - Nielsen, David C.
AU  - Cohen, Jane
TI  - Increasing the Accuracy and Automation of Fractional Vegetation Cover Estimation from Digital Photographs
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 7
SN  - 2072-4292

AB  - The use of automated methods to estimate fractional vegetation cover (FVC) from digital photographs has increased in recent years given its potential to produce accurate, fast and inexpensive FVC measurements. Wide acceptance has been delayed because of the limitations in accuracy, speed, automation and generalization of these methods. This work introduces a novel technique, the Automated Canopy Estimator (ACE) that overcomes many of these challenges to produce accurate estimates of fractional vegetation cover using an unsupervised segmentation process. ACE is shown to outperform nine other segmentation algorithms, consisting of both threshold-based and machine learning approaches, in the segmentation of photographs of four different crops (oat, corn, rapeseed and flax) with an overall accuracy of 89.6%. ACE is similarly accurate (88.7%) when applied to remotely sensed corn, producing FVC estimates that are strongly correlated with ground truth values.
KW  - fractional vegetation cover
KW  - automated canopy estimation
KW  - unsupervised image segmentation
KW  - digital photographs
DO  - 10.3390/rs8070474
ER  -
TY  - EJOU
AU  - Acharya, Tri D.
AU  - Lee, Dong H.
AU  - Yang, In T.
AU  - Lee, Jae K.
TI  - Identification of Water Bodies in a Landsat 8 OLI Image Using a J48 Decision Tree
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 7
SN  - 1424-8220

AB  - Water bodies are essential to humans and other forms of life. Identification of water bodies can be useful in various ways, including estimation of water availability, demarcation of flooded regions, change detection, and so on. In past decades, Landsat satellite sensors have been used for land use classification and water body identification. Due to the introduction of a New Operational Land Imager (OLI) sensor on Landsat 8 with a high spectral resolution and improved signal-to-noise ratio, the quality of imagery sensed by Landsat 8 has improved, enabling better characterization of land cover and increased data size. Therefore, it is necessary to explore the most appropriate and practical water identification methods that take advantage of the improved image quality and use the fewest inputs based on the original OLI bands. The objective of the study is to explore the potential of a J48 decision tree (JDT) in identifying water bodies using reflectance bands from Landsat 8 OLI imagery. J48 is an open-source decision tree. The test site for the study is in the Northern Han River Basin, which is located in Gangwon province, Korea. Training data with individual bands were used to develop the JDT model and later applied to the whole study area. The performance of the model was statistically analysed using the kappa statistic and area under the curve (AUC). The results were compared with five other known water identification methods using a confusion matrix and related statistics. Almost all the methods showed high accuracy, and the JDT was successfully applied to the OLI image using only four bands, where the new additional deep blue band of OLI was found to have the third highest information gain. Thus, the JDT can be a good method for water body identification based on images with improved resolution and increased size.
KW  - Landsat 8
KW  - OLI sensor
KW  - J48 decision tree
KW  - water body identification
KW  - Gandwon-do
DO  - 10.3390/s16071075
ER  -
TY  - EJOU
AU  - Kim, Sungho
AU  - Song, Woo-Jin
AU  - Kim, So-Hyun
TI  - Robust Ground Target Detection by SAR and IR Sensor Fusion Using Adaboost-Based Feature Selection
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 7
SN  - 1424-8220

AB  - Long-range ground targets are difficult to detect in a noisy cluttered environment using either synthetic aperture radar (SAR) images or infrared (IR) images. SAR-based detectors can provide a high detection rate with a high false alarm rate to background scatter noise. IR-based approaches can detect hot targets but are affected strongly by the weather conditions. This paper proposes a novel target detection method by decision-level SAR and IR fusion using an Adaboost-based machine learning scheme to achieve a high detection rate and low false alarm rate. The proposed method consists of individual detection, registration, and fusion architecture. This paper presents a single framework of a SAR and IR target detection method using modified Boolean map visual theory (modBMVT) and feature-selection based fusion. Previous methods applied different algorithms to detect SAR and IR targets because of the different physical image characteristics. One method that is optimized for IR target detection produces unsuccessful results in SAR target detection. This study examined the image characteristics and proposed a unified SAR and IR target detection method by inserting a median local average filter (MLAF, pre-filter) and an asymmetric morphological closing filter (AMCF, post-filter) into the BMVT. The original BMVT was optimized to detect small infrared targets. The proposed modBMVT can remove the thermal and scatter noise by the MLAF and detect extended targets by attaching the AMCF after the BMVT. Heterogeneous SAR and IR images were registered automatically using the proposed RANdom SAmple Region Consensus (RANSARC)-based homography optimization after a brute-force correspondence search using the detected target centers and regions. The final targets were detected by feature-selection based sensor fusion using Adaboost. The proposed method showed good SAR and IR target detection performance through feature selection-based decision fusion on a synthetic database generated by OKTAL-SE.
KW  - synthetic aperture radar
KW  - infrared
KW  - target detection
KW  - sensor fusion
KW  - machine learning
KW  - feature selection
KW  - OKTAL-SE
DO  - 10.3390/s16071117
ER  -
TY  - EJOU
AU  - Xu, Yongzheng
AU  - Yu, Guizhen
AU  - Wang, Yunpeng
AU  - Wu, Xinkai
AU  - Ma, Yalong
TI  - A Hybrid Vehicle Detection Method Based on Viola-Jones and HOG + SVM from UAV Images
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 8
SN  - 1424-8220

AB  - A new hybrid vehicle detection scheme which integrates the Viola-Jones (V-J) and linear SVM classifier with HOG feature (HOG + SVM) methods is proposed for vehicle detection from low-altitude unmanned aerial vehicle (UAV) images. As both V-J and HOG + SVM are sensitive to on-road vehicles’ in-plane rotation, the proposed scheme first adopts a roadway orientation adjustment method, which rotates each UAV image to align the roads with the horizontal direction so the original V-J or HOG + SVM method can be directly applied to achieve fast detection and high accuracy. To address the issue of descending detection speed for V-J and HOG + SVM, the proposed scheme further develops an adaptive switching strategy which sophistically integrates V-J and HOG + SVM methods based on their different descending trends of detection speed to improve detection efficiency. A comprehensive evaluation shows that the switching strategy, combined with the road orientation adjustment method, can significantly improve the efficiency and effectiveness of the vehicle detection from UAV images. The results also show that the proposed vehicle detection method is competitive compared with other existing vehicle detection methods. Furthermore, since the proposed vehicle detection method can be performed on videos captured from moving UAV platforms without the need of image registration or additional road database, it has great potentials of field applications. Future research will be focusing on expanding the current method for detecting other transportation modes such as buses, trucks, motors, bicycles, and pedestrians.
KW  - vehicle detection
KW  - unmanned aerial vehicle
KW  - Viola-Jones
KW  - HOG
KW  - road orientation
DO  - 10.3390/s16081325
ER  -
TY  - EJOU
AU  - Crommelinck, Sophie
AU  - Bennett, Rohan
AU  - Gerke, Markus
AU  - Nex, Francesco
AU  - Yang, Michael Y.
AU  - Vosselman, George
TI  - Review of Automatic Feature Extraction from High-Resolution Optical Sensor Data for UAV-Based Cadastral Mapping
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 8
SN  - 2072-4292

AB  - Unmanned Aerial Vehicles (UAVs) have emerged as a rapid, low-cost and flexible acquisition system that appears feasible for application in cadastral mapping: high-resolution imagery, acquired using UAVs, enables a new approach for defining property boundaries. However, UAV-derived data are arguably not exploited to its full potential: based on UAV data, cadastral boundaries are visually detected and manually digitized. A workflow that automatically extracts boundary features from UAV data could increase the pace of current mapping procedures. This review introduces a workflow considered applicable for automated boundary delineation from UAV data. This is done by reviewing approaches for feature extraction from various application fields and synthesizing these into a hypothetical generalized cadastral workflow. The workflow consists of preprocessing, image segmentation, line extraction, contour generation and postprocessing. The review lists example methods per workflow step—including a description, trialed implementation, and a list of case studies applying individual methods. Furthermore, accuracy assessment methods are outlined. Advantages and drawbacks of each approach are discussed in terms of their applicability on UAV data. This review can serve as a basis for future work on the implementation of most suitable methods in a UAV-based cadastral mapping workflow.
KW  - UAV Photogrammetry
KW  - optical sensors
KW  - HRSI
KW  - image segmentation
KW  - line extraction
KW  - contour generation
KW  - image analysis
KW  - OBIA
KW  - land administration
KW  - cadastral boundaries
DO  - 10.3390/rs8080689
ER  -
TY  - EJOU
AU  - Nevalainen, Paavo
AU  - Middleton, Maarit
AU  - Sutinen, Raimo
AU  - Heikkonen, Jukka
AU  - Pahikkala, Tapio
TI  - Detecting Terrain Stoniness From Airborne Laser Scanning Data †
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 9
SN  - 2072-4292

AB  - Three methods to estimate the presence of ground surface stones from publicly available Airborne Laser Scanning (ALS) point clouds are presented. The first method approximates the local curvature by local linear multi-scale fitting, and the second method uses Discrete-Differential Gaussian curvature based on the ground surface triangulation. The third baseline method applies Laplace filtering to Digital Elevation Model (DEM) in a 2 m regular grid data. All methods produce an approximate Gaussian curvature distribution which is then vectorized and classified by logistic regression. Two training data sets consisted of 88 and 674 polygons of mass-flow deposits, respectively. The locality of the polygon samples is a sparse canopy boreal forest, where the density of ALS ground returns is sufficiently high to reveal information about terrain micro-topography. The surface stoniness of each polygon sample was categorized for supervised learning by expert observation on the site. The leave-pair-out (L2O) cross-validation of the local linear fit method results in the area under curve     A U C = 0 . 74     and     A U C = 0 . 85     on two data sets, respectively. This performance can be expected to suit real world applications such as detecting coarse-grained sediments for infrastructure construction. A wall-to-wall predictor based on the study was demonstrated.
KW  - aerial laser scan
KW  - point cloud
KW  - digital elevation model
KW  - logistic regression
KW  - stoniness
KW  - natural resources
KW  - micro-topography
KW  - Gaussian curvature
DO  - 10.3390/rs8090720
ER  -
TY  - EJOU
AU  - Fu, Changhong
AU  - Duan, Ran
AU  - Kircali, Dogan
AU  - Kayacan, Erdal
TI  - Onboard Robust Visual Tracking for UAVs Using a Reliable Global-Local Object Model
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 9
SN  - 1424-8220

AB  - In this paper, we present a novel onboard robust visual algorithm for long-term arbitrary 2D and 3D object tracking using a reliable global-local object model for unmanned aerial vehicle (UAV) applications, e.g., autonomous tracking and chasing a moving target. The first main approach in this novel algorithm is the use of a global matching and local tracking approach. In other words, the algorithm initially finds feature correspondences in a way that an improved binary descriptor is developed for global feature matching and an iterative Lucas–Kanade optical flow algorithm is employed for local feature tracking. The second main module is the use of an efficient local geometric filter (LGF), which handles outlier feature correspondences based on a new forward-backward pairwise dissimilarity measure, thereby maintaining pairwise geometric consistency. In the proposed LGF module, a hierarchical agglomerative clustering, i.e., bottom-up aggregation, is applied using an effective single-link method. The third proposed module is a heuristic local outlier factor (to the best of our knowledge, it is utilized for the first time to deal with outlier features in a visual tracking application), which further maximizes the representation of the target object in which we formulate outlier feature detection as a binary classification problem with the output features of the LGF module. Extensive UAV flight experiments show that the proposed visual tracker achieves real-time frame rates of more than thirty-five frames per second on an i7 processor with 640 × 512 image resolution and outperforms the most popular state-of-the-art trackers favorably in terms of robustness, efficiency and accuracy.
KW  - unmanned aerial vehicle
KW  - visual object tracking
KW  - reliable global-local model
KW  - local geometric filter
KW  - local outlier factor
KW  - robust real-time performance
DO  - 10.3390/s16091406
ER  -
TY  - EJOU
AU  - Houborg, Rasmus
AU  - McCabe, Matthew F.
TI  - High-Resolution NDVI from Planet’s Constellation of Earth Observing Nano-Satellites: A New Data Source for Precision Agriculture
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 9
SN  - 2072-4292

AB  - Planet Labs (“Planet”) operate the largest fleet of active nano-satellites in orbit, offering an unprecedented monitoring capacity of daily and global RGB image capture at 3–5 m resolution. However, limitations in spectral resolution and lack of accurate radiometric sensor calibration impact the utility of this rich information source. In this study, Planet’s RGB imagery was translated into a Normalized Difference Vegetation Index (NDVI): a common metric for vegetation growth and condition. Our framework employs a data mining approach to build a set of rule-based regression models that relate RGB data to atmospherically corrected Landsat-8 NDVI. The approach was evaluated over a desert agricultural landscape in Saudi Arabia where the use of near-coincident (within five days) Planet and Landsat-8 acquisitions in the training of the regression models resulted in NDVI predictabilities with an r2 of approximately 0.97 and a Mean Absolute Deviation (MAD) on the order of 0.014 (~9%). The MAD increased to 0.021 (~14%) when the Landsat NDVI training image was further away (i.e., 11–16 days) from the corrected Planet image. In these cases, the use of MODIS observations to inform on the change in NDVI occurring between overpasses was shown to significantly improve prediction accuracies. MAD levels ranged from 0.002 to 0.011 (3.9% to 9.1%) for the best performing 80% of the data. The technique is generic and extendable to any region of interest, increasing the utility of Planet’s dense time-series of RGB imagery.
KW  - planet labs
KW  - Landsat
KW  - data mining
KW  - NDVI
KW  - precision agriculture
KW  - RGB
KW  - nano-satellites
DO  - 10.3390/rs8090768
ER  -
TY  - EJOU
AU  - Fraga-Lamas, Paula
AU  - Fernández-Caramés, Tiago M.
AU  - Suárez-Albela, Manuel
AU  - Castedo, Luis
AU  - González-López, Miguel
TI  - A Review on Internet of Things for Defense and Public Safety
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 10
SN  - 1424-8220

AB  - The Internet of Things (IoT) is undeniably transforming the way that organizations communicate and organize everyday businesses and industrial procedures. Its adoption has proven well suited for sectors that manage a large number of assets and coordinate complex and distributed processes. This survey analyzes the great potential for applying IoT technologies (i.e., data-driven applications or embedded automation and intelligent adaptive systems) to revolutionize modern warfare and provide beneﬁts similar to those in industry. It identiﬁes scenarios where Defense and Public Safety (PS) could leverage better commercial IoT capabilities to deliver greater survivability to the warﬁghter or ﬁrst responders, while reducing costs and increasing operation efﬁciency and effectiveness. This article reviews the main tactical requirements and the architecture, examining gaps and shortcomings in existing IoT systems across the military ﬁeld and mission-critical scenarios. The review characterizes the open challenges for a broad deployment and presents a research roadmap for enabling an affordable IoT for defense and PS.
KW  - Internet of Things
KW  - defense and public safety
KW  - public safety responders
KW  - security
KW  - trust management
KW  - cloud computing
KW  - heterogeneous networks
KW  - wireless sensor networks
KW  - mission-critical networks
KW  - tactical environment
KW  - Machine-to-Machine communications
DO  - 10.3390/s16101644
ER  -
TY  - EJOU
AU  - Gong, Lixia
AU  - Wang, Chao
AU  - Wu, Fan
AU  - Zhang, Jingfa
AU  - Zhang, Hong
AU  - Li, Qiang
TI  - Earthquake-Induced Building Damage Detection with Post-Event Sub-Meter VHR TerraSAR-X Staring Spotlight Imagery
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 11
SN  - 2072-4292

AB  - Compared with optical sensors, Synthetic Aperture Radar (SAR) can provide important damage information due to its ability to map areas affected by earthquakes independently from weather conditions and solar illumination. In 2013, a new TerraSAR-X mode named staring spotlight (ST), whose azimuth resolution was improved to 0.24 m, was introduced for various applications. This data source made it possible to extract detailed information from individual buildings. In this paper, we present a new concept for individual building damage assessment using a post-event sub-meter very high resolution (VHR) SAR image and a building footprint map. With the building footprint map, the original footprints of buildings can be located in the SAR image. Based on the building imaging analysis of a building in the SAR image, the features in the building footprint can be extracted to identify standing and collapsed buildings. Three machine learning classifiers, including random forest (RF), support vector machine (SVM) and K-nearest neighbor (K-NN), are used in the experiments. The results show that the proposed method can obtain good overall accuracy, which is above 80% with the three classifiers. The efficiency of the proposed method is demonstrated based on samples of buildings using descending and ascending sub-meter VHR ST images, which were all acquired from the same area in old Beichuan County, China.
KW  - earthquake
KW  - damage assessment
KW  - building
KW  - Synthetic Aperture Radar
KW  - TerraSAR-X
KW  - high resolution
DO  - 10.3390/rs8110887
ER  -
TY  - EJOU
AU  - Elmoataz, Abderrahim
AU  - Lozes, François
AU  - Talbot, Hugues
TI  - Morphological PDEs on Graphs for Image Processing on Surfaces and Point Clouds
T2  - ISPRS International Journal of Geo-Information

PY  - 2016
VL  - 5
IS  - 11
SN  - 2220-9964

AB  - Partial Differential Equations (PDEs)-based morphology offers a wide range of continuous operators to address various image processing problems. Most of these operators are formulated as Hamilton–Jacobi equations or curve evolution level set and morphological flows. In our previous works, we have proposed a simple method to solve PDEs on point clouds using the framework of PdEs (Partial difference Equations) on graphs. In this paper, we propose to apply a large class of morphological-based operators on graphs for processing raw 3D point clouds and extend their applications for the processing of colored point clouds of geo-informatics 3D data. Through illustrations, we show that this simple framework can be used in the resolution of many applications for geo-informatics purposes.
KW  - generalized distance
KW  - Hamilton–Jacobi equation
KW  - weighted graphs
KW  - partial difference equations
KW  - mathematical morphology
DO  - 10.3390/ijgi5110213
ER  -
TY  - EJOU
AU  - Gong, Wenjuan
AU  - Zhang, Xuena
AU  - Gonzàlez, Jordi
AU  - Sobral, Andrews
AU  - Bouwmans, Thierry
AU  - Tu, Changhe
AU  - Zahzah, El-hadi
TI  - Human Pose Estimation from Monocular Images: A Comprehensive Survey
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 12
SN  - 1424-8220

AB  - Human pose estimation refers to the estimation of the location of body parts and how they are connected in an image. Human pose estimation from monocular images has wide applications (e.g., image indexing). Several surveys on human pose estimation can be found in the literature, but they focus on a certain category; for example, model-based approaches or human motion analysis, etc. As far as we know, an overall review of this problem domain has yet to be provided. Furthermore, recent advancements based on deep learning have brought novel algorithms for this problem. In this paper, a comprehensive survey of human pose estimation from monocular images is carried out including milestone works and recent advancements. Based on one standard pipeline for the solution of computer vision problems, this survey splits the problem into several modules: feature extraction and description, human body models, and modeling methods. Problem modeling methods are approached based on two means of categorization in this survey. One way to categorize includes top-down and bottom-up methods, and another way includes generative and discriminative methods. Considering the fact that one direct application of human pose estimation is to provide initialization for automatic video surveillance, there are additional sections for motion-related methods in all modules: motion features, motion models, and motion-based methods. Finally, the paper also collects 26 publicly available data sets for validation and provides error measurement methods that are frequently used.
KW  - human pose estimation
KW  - human body models
KW  - generative methods
KW  - discriminative methods
KW  - top-down methods
KW  - bottom-up methods
DO  - 10.3390/s16121966
ER  -
TY  - EJOU
AU  - Perea-Moreno, Alberto-Jesús
AU  - Aguilera-Ureña, María-Jesús
AU  - Meroño-De Larriva, José-Emilio
AU  - Manzano-Agugliaro, Francisco
TI  - Assessment of the Potential of UAV Video Image Analysis for Planning Irrigation Needs of Golf Courses
T2  - Water

PY  - 2016
VL  - 8
IS  - 12
SN  - 2073-4441

AB  - Golf courses can be considered as precision agriculture, as being a playing surface, their appearance is of vital importance. Areas with good weather tend to have low rainfall. Therefore, the water management of golf courses in these climates is a crucial issue due to the high water demand of turfgrass. Golf courses are rapidly transitioning to reuse water, e.g., the municipalities in the USA are providing price incentives or mandate the use of reuse water for irrigation purposes; in Europe this is mandatory. So, knowing the turfgrass surfaces of a large area can help plan the treated sewage effluent needs. Recycled water is usually of poor quality, thus it is crucial to check the real turfgrass surface in order to be able to plan the global irrigation needs using this type of water. In this way, the irrigation of golf courses does not detract from the natural water resources of the area. The aim of this paper is to propose a new methodology for analysing geometric patterns of video data acquired from UAVs (Unmanned Aerial Vehicle) using a new Hierarchical Temporal Memory (HTM) algorithm. A case study concerning maintained turfgrass, especially for golf courses, has been developed. It shows very good results, better than 98% in the confusion matrix. The results obtained in this study represent a first step toward video imagery classification. In summary, technical progress in computing power and software has shown that video imagery is one of the most promising environmental data acquisition techniques available today. This rapid classification of turfgrass can play an important role for planning water management.
KW  - water management
KW  - golf course
KW  - memory-prediction theory
KW  - object-based classification
KW  - unmanned aerial vehicle
DO  - 10.3390/w8120584
ER  -
TY  - EJOU
AU  - Ortiz, Alberto
AU  - Bonnin-Pascual, Francisco
AU  - Garcia-Fidalgo, Emilio
AU  - Company-Corcoles, Joan P.
TI  - Vision-Based Corrosion Detection Assisted by a Micro-Aerial Vehicle in a Vessel Inspection Application
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 12
SN  - 1424-8220

AB  - Vessel maintenance requires periodic visual inspection of the hull in order to detect typical defective situations of steel structures such as, among others, coating breakdown and corrosion. These inspections are typically performed by well-trained surveyors at great cost because of the need for providing access means (e.g., scaffolding and/or cherry pickers) that allow the inspector to be at arm’s reach from the structure under inspection. This paper describes a defect detection approach comprising a micro-aerial vehicle which is used to collect images from the surfaces under inspection, particularly focusing on remote areas where the surveyor has no visual access, and a coating breakdown/corrosion detector based on a three-layer feed-forward artificial neural network. As it is discussed in the paper, the success of the inspection process depends not only on the defect detection software but also on a number of assistance functions provided by the control architecture of the aerial platform, whose aim is to improve picture quality. Both aspects of the work are described along the different sections of the paper, as well as the classification performance attained.
KW  - vessel inspection
KW  - defect detection
KW  - unmanned aerial vehicle
KW  - supervised autonomy
KW  - machine learning
KW  - artificial neural network
DO  - 10.3390/s16122118
ER  -
TY  - EJOU
AU  - Tayara, Hilal
AU  - Ham, Woonchul
AU  - Chong, Kil T.
TI  - A Real-Time Marker-Based Visual Sensor Based on a FPGA and a Soft Core Processor
T2  - Sensors

PY  - 2016
VL  - 16
IS  - 12
SN  - 1424-8220

AB  - This paper introduces a real-time marker-based visual sensor architecture for mobile robot localization and navigation. A hardware acceleration architecture for post video processing system was implemented on a field-programmable gate array (FPGA). The pose calculation algorithm was implemented in a System on Chip (SoC) with an Altera Nios II soft-core processor. For every frame, single pass image segmentation and Feature Accelerated Segment Test (FAST) corner detection were used for extracting the predefined markers with known geometries in FPGA. Coplanar PosIT algorithm was implemented on the Nios II soft-core processor supplied with floating point hardware for accelerating floating point operations. Trigonometric functions have been approximated using Taylor series and cubic approximation using Lagrange polynomials. Inverse square root method has been implemented for approximating square root computations. Real time results have been achieved and pixel streams have been processed on the fly without any need to buffer the input frame for further implementation.
KW  - coplanar PosIt
KW  - FAST corner detection
KW  - FPGA
KW  - image segmentation
KW  - visual sensors
DO  - 10.3390/s16122139
ER  -
TY  - EJOU
AU  - Liu, Kai
AU  - Ding, Hu
AU  - Tang, Guoan
AU  - Na, Jiaming
AU  - Huang, Xiaoli
AU  - Xue, Zhengguang
AU  - Yang, Xin
AU  - Li, Fayuan
TI  - Detection of Catchment-Scale Gully-Affected Areas Using Unmanned Aerial Vehicle (UAV) on the Chinese Loess Plateau
T2  - ISPRS International Journal of Geo-Information

PY  - 2016
VL  - 5
IS  - 12
SN  - 2220-9964

AB  - The Chinese Loess Plateau suffers from serious gully erosion induced by natural and human causes. Gully-affected areas detection is the basic work in this region for gully erosion assessment and monitoring. For the first time, an unmanned aerial vehicle (UAV) was applied to extract gully features in this region. Two typical catchments in Changwu and Ansai were selected to represent loess tableland and loess hilly regions, respectively. A high-powered quadrocopter (md4-1000) equipped with a non-metric camera was used for image acquisition. InPho and MapMatrix were applied for semi-automatic workflow including aerial triangulation and model generation. Based on the stereo-imaging and the ground control points, the highly detailed digital elevation models (DEMs) and ortho-mosaics were generated. Subsequently, an object-based approach combined with the random forest classifier was designed to detect gully-affected areas. Two experiments were conducted to investigate the influences of segmentation strategy and feature selection. Results showed that vertical and horizontal root-mean-square errors were below 0.5 and 0.2 m, respectively, which were ideal for the Loess Plateau region. The overall extraction accuracy in Changwu and Ansai achieved was 84.62% and 86.46%, respectively, which indicated the potential of the proposed workflow for extracting gully features. This study demonstrated that UAV can bridge the gap between field measurement and satellite-based remote sensing, obtaining a balance in resolution and efficiency for catchment-scale gully erosion research.
KW  - unmanned aerial vehicle (UAV)
KW  - gully erosion
KW  - gully-affected areas
KW  - object-based image analysis
KW  - random forest
KW  - Loess Plateau
DO  - 10.3390/ijgi5120238
ER  -
TY  - EJOU
AU  - Gevaert, Caroline M.
AU  - Persello, Claudio
AU  - Vosselman, George
TI  - Optimizing Multiple Kernel Learning for the Classification of UAV Data
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 12
SN  - 2072-4292

AB  - Unmanned Aerial Vehicles (UAVs) are capable of providing high-quality orthoimagery and 3D information in the form of point clouds at a relatively low cost. Their increasing popularity stresses the necessity of understanding which algorithms are especially suited for processing the data obtained from UAVs. The features that are extracted from the point cloud and imagery have different statistical characteristics and can be considered as heterogeneous, which motivates the use of Multiple Kernel Learning (MKL) for classification problems. In this paper, we illustrate the utility of applying MKL for the classification of heterogeneous features obtained from UAV data through a case study of an informal settlement in Kigali, Rwanda. Results indicate that MKL can achieve a classification accuracy of 90.6%, a 5.2% increase over a standard single-kernel Support Vector Machine (SVM). A comparison of seven MKL methods indicates that linearly-weighted kernel combinations based on simple heuristics are competitive with respect to computationally-complex, non-linear kernel combination methods. We further underline the importance of utilizing appropriate feature grouping strategies for MKL, which has not been directly addressed in the literature, and we propose a novel, automated feature grouping method that achieves a high classification accuracy for various MKL methods.
KW  - Unmanned Aerial Vehicles (UAVs)
KW  - Support Vector Machines (SVMs)
KW  - Multiple Kernel Learning (MKL)
KW  - informal settlements
KW  - image classification
DO  - 10.3390/rs8121025
ER  -
TY  - EJOU
AU  - Lausch, Angela
AU  - Erasmi, Stefan
AU  - King, Douglas J.
AU  - Magdon, Paul
AU  - Heurich, Marco
TI  - Understanding Forest Health with Remote Sensing -Part I—A Review of Spectral Traits, Processes and Remote-Sensing Characteristics
T2  - Remote Sensing

PY  - 2016
VL  - 8
IS  - 12
SN  - 2072-4292

AB  - Anthropogenic stress and disturbance of forest ecosystems (FES) has been increasing at all scales from local to global. In rapidly changing environments, in-situ terrestrial FES monitoring approaches have made tremendous progress but they are intensive and often integrate subjective indicators for forest health (FH). Remote sensing (RS) bridges the gaps of these limitations, by monitoring indicators of FH on different spatio-temporal scales, and in a cost-effective, rapid, repetitive and objective manner. In this paper, we provide an overview of the definitions of FH, discussing the drivers, processes, stress and adaptation mechanisms of forest plants, and how we can observe FH with RS. We introduce the concept of spectral traits (ST) and spectral trait variations (STV) in the context of FH monitoring and discuss the prospects, limitations and constraints. Stress, disturbances and resource limitations can cause changes in FES taxonomic, structural and functional diversity; we provide examples how the ST/STV approach can be used for monitoring these FES characteristics. We show that RS based assessments of FH indicators using the ST/STV approach is a competent, affordable, repetitive and objective technique for monitoring. Even though the possibilities for observing the taxonomic diversity of animal species is limited with RS, the taxonomy of forest tree species can be recorded with RS, even though its accuracy is subject to certain constraints. RS has proved successful for monitoring the impacts from stress on structural and functional diversity. In particular, it has proven to be very suitable for recording the short-term dynamics of stress on FH, which cannot be cost-effectively recorded using in-situ methods. This paper gives an overview of the ST/STV approach, whereas the second paper of this series concentrates on discussing in-situ terrestrial monitoring, in-situ RS approaches and RS sensors and techniques for measuring ST/STV for FH.
KW  - forest health
KW  - forest ecosystem
KW  - earth observation
KW  - remote sensing
KW  - traits
KW  - spectral traits (ST)
KW  - spectral trait variations (STV)
KW  - non-spectral traits (N-ST)
DO  - 10.3390/rs8121029
ER  -
TY  - EJOU
AU  - Li, Weijia
AU  - Fu, Haohuan
AU  - Yu, Le
AU  - Cracknell, Arthur
TI  - Deep Learning Based Oil Palm Tree Detection and Counting for High-Resolution Remote Sensing Images
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 1
SN  - 2072-4292

AB  - Oil palm trees are important economic crops in Malaysia and other tropical areas. The number of oil palm trees in a plantation area is important information for predicting the yield of palm oil, monitoring the growing situation of palm trees and maximizing their productivity, etc. In this paper, we propose a deep learning based framework for oil palm tree detection and counting using high-resolution remote sensing images for Malaysia. Unlike previous palm tree detection studies, the trees in our study area are more crowded and their crowns often overlap. We use a number of manually interpreted samples to train and optimize the convolutional neural network (CNN), and predict labels for all the samples in an image dataset collected through the sliding window technique. Then, we merge the predicted palm coordinates corresponding to the same palm tree into one palm coordinate and obtain the final palm tree detection results. Based on our proposed method, more than 96% of the oil palm trees in our study area can be detected correctly when compared with the manually interpreted ground truth, and this is higher than the accuracies of the other three tree detection methods used in this study.
KW  - oil palm trees
KW  - deep learning
KW  - convolutional neural network (CNN)
KW  - object detection
DO  - 10.3390/rs9010022
ER  -
TY  - EJOU
AU  - Iglesias, Carla
AU  - Santos, António J.
AU  - Martínez, Javier
AU  - Pereira, Helena
AU  - Anjos, Ofélia
TI  - Influence of Heartwood on Wood Density and Pulp Properties Explained by Machine Learning Techniques
T2  - Forests

PY  - 2017
VL  - 8
IS  - 1
SN  - 1999-4907

AB  - The aim of this work is to develop a tool to predict some pulp properties e.g., pulp yield, Kappa number, ISO brightness (ISO 2470:2008), fiber length and fiber width, using the sapwood and heartwood proportion in the raw-material. For this purpose, Acacia melanoxylon trees were collected from four sites in Portugal. Percentage of sapwood and heartwood, area and the stem eccentricity (in N-S and E-W directions) were measured on transversal stem sections of A. melanoxylon R. Br. The relative position of the samples with respect to the total tree height was also considered as an input variable. Different configurations were tested until the maximum correlation coefficient was achieved. A classical mathematical technique (multiple linear regression) and machine learning methods (classification and regression trees, multi-layer perceptron and support vector machines) were tested. Classification and regression trees (CART) was the most accurate model for the prediction of pulp ISO brightness (R = 0.85). The other parameters could be predicted with fair results (R = 0.64–0.75) by CART. Hence, the proportion of heartwood and sapwood is a relevant parameter for pulping and pulp properties, and should be taken as a quality trait when assessing a pulpwood resource.
KW  - Acacia melanoxylon
KW  - heartwood
KW  - pulp properties
KW  - Multiple Linear Regression
KW  - CART
KW  - Multi-Layer Perceptron (MLP)
KW  - Support Vector Machines (SVM)
DO  - 10.3390/f8010020
ER  -
TY  - EJOU
AU  - Ramon Soria, Pablo
AU  - Arrue, Begoña C.
AU  - Ollero, Anibal
TI  - Detection, Location and Grasping Objects Using a Stereo Sensor on UAV in Outdoor Environments
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 1
SN  - 1424-8220

AB  - The article presents a vision system for the autonomous grasping of objects with Unmanned Aerial Vehicles (UAVs) in real time. Giving UAVs the capability to manipulate objects vastly extends their applications, as they are capable of accessing places that are difficult to reach or even unreachable for human beings. This work is focused on the grasping of known objects based on feature models. The system runs in an on-board computer on a UAV equipped with a stereo camera and a robotic arm. The algorithm learns a feature-based model in an offline stage, then it is used online for detection of the targeted object and estimation of its position. This feature-based model was proved to be robust to both occlusions and the presence of outliers. The use of stereo cameras improves the learning stage, providing 3D information and helping to filter features in the online stage. An experimental system was derived using a rotary-wing UAV and a small manipulator for final proof of concept. The robotic arm is designed with three degrees of freedom and is lightweight due to payload limitations of the UAV. The system has been validated with different objects, both indoors and outdoors.
KW  - UAV
KW  - grasping
KW  - outdoors
DO  - 10.3390/s17010103
ER  -
TY  - EJOU
AU  - Qiu, Linyao
AU  - Zhu, Qing
AU  - Du, Zhiqiang
AU  - Wang, Meng
AU  - Fan, Yida
TI  - An On-Demand Retrieval Method Based on Hybrid NoSQL for Multi-Layer Image Tiles in Disaster Reduction Visualization
T2  - ISPRS International Journal of Geo-Information

PY  - 2017
VL  - 6
IS  - 1
SN  - 2220-9964

AB  - Monitoring, response, mitigation and damage assessment of disasters places a wide variety of demands on the spatial and temporal resolutions of remote sensing images. Images are divided into tile pyramids by data sources or resolutions and published as independent image services for visualization. A disaster-affected area is commonly covered by multiple image layers to express hierarchical surface information, which generates a large amount of namesake tiles from different layers that overlay the same location. The traditional tile retrieval method for visualization cannot distinguish between distinct layers and traverses all image datasets for each tile query. This process produces redundant queries and invalid access that can seriously affect the visualization performance of clients, servers and network transmission. This paper proposes an on-demand retrieval method for multi-layer images and defines semantic annotations to enrich the description of each dataset. By matching visualization demands with the semantic information of datasets, this method automatically filters inappropriate layers and finds the most suitable layer for the final tile query. The design and implementation are based on a two-layer NoSQL database architecture that provides scheduling optimization and concurrent processing capability. The experimental results reflect the effectiveness and stability of the approach for multi-layer retrieval in disaster reduction visualization.
KW  - on-demand
KW  - multi-layer
KW  - semantic description
KW  - NoSQL
KW  - disaster reduction visualization
DO  - 10.3390/ijgi6010008
ER  -
TY  - EJOU
AU  - Mazumdar, Suvodeep
AU  - Wrigley, Stuart
AU  - Ciravegna, Fabio
TI  - Citizen Science and Crowdsourcing for Earth Observations: An Analysis of Stakeholder Opinions on the Present and Future
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 1
SN  - 2072-4292

AB  - The impact of Crowdsourcing and citizen science activities on academia, businesses, governance and society has been enormous. This is more prevalent today with citizens and communities collaborating with organizations, businesses and authorities to contribute in a variety of manners, starting from mere data providers to being key stakeholders in various decision-making processes. The “Crowdsourcing for observations from Satellites” project is a recently concluded study supported by demonstration projects funded by European Space Agency (ESA). The objective of the project was to investigate the different facets of how crowdsourcing and citizen science impact upon the validation, use and enhancement of Observations from Satellites (OS) products and services. This paper presents our findings in a stakeholder analysis activity involving participants who are experts in crowdsourcing, citizen science for Earth Observations. The activity identified three critical areas that needs attention by the community as well as provides suggestions to potentially help in addressing some of the challenges identified.
KW  - crowdsourcing
KW  - citizen science
KW  - stakeholder analysis
KW  - earth observations
KW  - observations from satellites
DO  - 10.3390/rs9010087
ER  -
TY  - EJOU
AU  - Bejiga, Mesay B.
AU  - Zeggada, Abdallah
AU  - Nouffidj, Abdelhamid
AU  - Melgani, Farid
TI  - A Convolutional Neural Network Approach for Assisting Avalanche Search and Rescue Operations with UAV Imagery
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 2
SN  - 2072-4292

AB  - Following an avalanche, one of the factors that affect victims’ chance of survival is the speed with which they are located and dug out. Rescue teams use techniques like trained rescue dogs and electronic transceivers to locate victims. However, the resources and time required to deploy rescue teams are major bottlenecks that decrease a victim’s chance of survival. Advances in the field of Unmanned Aerial Vehicles (UAVs) have enabled the use of flying robots equipped with sensors like optical cameras to assess the damage caused by natural or manmade disasters and locate victims in the debris. In this paper, we propose assisting avalanche search and rescue (SAR) operations with UAVs fitted with vision cameras. The sequence of images of the avalanche debris captured by the UAV is processed with a pre-trained Convolutional Neural Network (CNN) to extract discriminative features. A trained linear Support Vector Machine (SVM) is integrated at the top of the CNN to detect objects of interest. Moreover, we introduce a pre-processing method to increase the detection rate and a post-processing method based on a Hidden Markov Model to improve the prediction performance of the classifier. Experimental results conducted on two different datasets at different levels of resolution show that the detection performance increases with an increase in resolution, while the computation time increases. Additionally, they also suggest that a significant decrease in processing time can be achieved thanks to the pre-processing step.
KW  - avalanche
KW  - convolutional neural network (CNN)
KW  - deep learning
KW  - hidden Markov model (HMM)
KW  - object detection
KW  - search and rescue operation
KW  - support vector machine (SVM)
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/rs9020100
ER  -
TY  - EJOU
AU  - Sharma, Ram C.
AU  - Tateishi, Ryutaro
AU  - Hara, Keitarou
AU  - Nguyen, Hoan T.
AU  - Gharechelou, Saeid
AU  - Nguyen, Luong V.
TI  - Earthquake Damage Visualization (EDV) Technique for the Rapid Detection of Earthquake-Induced Damages Using SAR Data
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 2
SN  - 1424-8220

AB  - The damage of buildings and manmade structures, where most of human activities occur, is the major cause of casualties of from earthquakes. In this paper, an improved technique, Earthquake Damage Visualization (EDV) is presented for the rapid detection of earthquake damage using the Synthetic Aperture Radar (SAR) data. The EDV is based on the pre-seismic and co-seismic coherence change method. The normalized difference between the pre-seismic and co-seismic coherences, and vice versa, are used to calculate the forward (from pre-seismic to co-seismic) and backward (from co-seismic to pre-seismic) change parameters, respectively. The backward change parameter is added to visualize the retrospective changes caused by factors other than the earthquake. The third change-free parameter uses the average values of the pre-seismic and co-seismic coherence maps. These three change parameters were ultimately merged into the EDV as an RGB (Red, Green, and Blue) composite imagery. The EDV could visualize the earthquake damage efficiently using Horizontal transmit and Horizontal receive (HH), and Horizontal transmit and Vertical receive (HV) polarizations data from the Advanced Land Observing Satellite-2 (ALOS-2). Its performance was evaluated in the Kathmandu Valley, which was hit severely by the 2015 Nepal Earthquake. The cross-validation results showed that the EDV is more sensitive to the damaged buildings than the existing method. The EDV could be used for building damage detection in other earthquakes as well.
KW  - earthquake damage
KW  - coherence
KW  - visualization
KW  - EDV
KW  - 2015 Nepal Earthquake
KW  - ALOS-2
KW  - SAR
KW  - cross-validation
KW  - buildings
DO  - 10.3390/s17020235
ER  -
TY  - EJOU
AU  - Lausch, Angela
AU  - Erasmi, Stefan
AU  - King, Douglas J.
AU  - Magdon, Paul
AU  - Heurich, Marco
TI  - Understanding Forest Health with Remote Sensing-Part II—A Review of Approaches and Data Models
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 2
SN  - 2072-4292

AB  - Stress in forest ecosystems (FES) occurs as a result of land-use intensification, disturbances, resource limitations or unsustainable management, causing changes in forest health (FH) at various scales from the local to the global scale. Reactions to such stress depend on the phylogeny of forest species or communities and the characteristics of their impacting drivers and processes. There are many approaches to monitor indicators of FH using in-situ forest inventory and experimental studies, but they are generally limited to sample points or small areas, as well as being time- and labour-intensive. Long-term monitoring based on forest inventories provides valuable information about changes and trends of FH. However, abrupt short-term changes cannot sufficiently be assessed through in-situ forest inventories as they usually have repetition periods of multiple years. Furthermore, numerous FH indicators monitored in in-situ surveys are based on expert judgement. Remote sensing (RS) technologies offer means to monitor FH indicators in an effective, repetitive and comparative way. This paper reviews techniques that are currently used for monitoring, including close-range RS, airborne and satellite approaches. The implementation of optical, RADAR and LiDAR RS-techniques to assess spectral traits/spectral trait variations (ST/STV) is described in detail. We found that ST/STV can be used to record indicators of FH based on RS. Therefore, the ST/STV approach provides a framework to develop a standardized monitoring concept for FH indicators using RS techniques that is applicable to future monitoring programs. It is only through linking in-situ and RS approaches that we will be able to improve our understanding of the relationship between stressors, and the associated spectral responses in order to develop robust FH indicators.
KW  - spectral traits (ST)
KW  - spectral trait variations (STV)
KW  - in-situ
KW  - remote sensing (RS) approaches
KW  - plant phenomics facilities
KW  - wireless sensor networks (WSN)
KW  - RADAR
KW  - optical
KW  - LiDAR
KW  - RS models
DO  - 10.3390/rs9020129
ER  -
TY  - EJOU
AU  - Olthof, Ian
TI  - Mapping Seasonal Inundation Frequency (1985–2016) along the St-John River, New Brunswick, Canada using the Landsat Archive
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 2
SN  - 2072-4292

AB  - Extreme flood events in recent years in Canada have highlighted the need for historical information to better manage future flood risk. In this paper, a methodology to generate flood maps from Landsat to determine historical inundation frequency is presented for a region along the St-John River, New Brunswick, Canada that experiences annual springtime flooding from snowmelt and river ice. 1985–2016 Landsat data from the USGS archive were classified by combining See5 decision trees to map spectrally variable water due to spring ice and sediment, and image thresholding to map inundated floodplains. Multiple scenes representing each year were overlaid to produce seasonal time-series of spring (March–May) and summer (June–August) maximum annual water extents. Comparisons of annual surface water maps were conducted separately for each season against historical hydrometric water depth as a measure of relative springtime flood severity, and 1 m water masks from digital orthophotos were used to perform a formal accuracy assessment of summer water. Due to Landsat’s 16-day revisit time, peak flood depth was poorly related to flood extent; however, spring depth measured during Landsat acquisitions was significantly related to extent (tau = 0.6, p-value &lt; 0.001). Further, summer maps validated against 30 m water fractions scaled from 1 m water masks were over 97% accurate. Limitations with respect to the assessment of flood extent from depth, timing differences between peak flood depth and extent due to Landsat revisit time and cloud cover, and suggestions to overcome limitations through multi-sensor integration including radar are discussed.
KW  - Landsat
KW  - flood
KW  - inundation
DO  - 10.3390/rs9020143
ER  -
TY  - EJOU
AU  - Su, Lihong
AU  - Gibeaut, James
TI  - Using UAS Hyperspatial RGB Imagery for Identifying Beach Zones along the South Texas Coast
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 2
SN  - 2072-4292

AB  - Shoreline information is fundamental for understanding coastal dynamics and for implementing environmental policy. The analysis of shoreline variability usually uses a group of shoreline indicators visibly discernible in coastal imagery, such as the seaward vegetation line, wet beach/dry beach line, and instantaneous water line. These indicators partition a beach into four zones: vegetated land, dry sand or debris, wet sand, and water. Unmanned aircraft system (UAS) remote sensing that can acquire imagery with sub-decimeter pixel size provides opportunities to map these four beach zones. This paper attempts to delineate four beach zones based on UAS hyperspatial RGB (Red, Green, and Blue) imagery, namely imagery of sub-decimeter pixel size, and feature textures. Besides the RGB images, this paper also uses USGS (the United States Geological Survey) Munsell HSV (Hue, Saturation, and Value) and CIELUV (the CIE 1976 (L*, u*, v*) color space) images transformed from an RGB image. The four beach zones are identified based on the Gray Level Co-Occurrence Matrix (GLCM) and Local Binary Pattern (LBP) textures. Experiments were conducted with South Padre Island photos acquired by a Nikon D80 camera mounted on the US-16 UAS during March 2014. The results show that USGS Munsell hue can separate land and water reliably. GLCM and LBP textures can slightly improve classification accuracies by both unsupervised and supervised classification techniques. The experiments also indicate that we could reach acceptable results on different photos while using training data from another photo for site-specific UAS remote sensing. The findings imply that parallel processing of classification is feasible.
KW  - color space transformation
KW  - hyperspatial remote sensing
KW  - shoreline change
KW  - feature texture
KW  - UAS remote sensing
KW  - beach zones partition
DO  - 10.3390/rs9020159
ER  -
TY  - EJOU
AU  - Ma, Lei
AU  - Fu, Tengyu
AU  - Blaschke, Thomas
AU  - Li, Manchun
AU  - Tiede, Dirk
AU  - Zhou, Zhenjin
AU  - Ma, Xiaoxue
AU  - Chen, Deliang
TI  - Evaluation of Feature Selection Methods for Object-Based Land Cover Mapping of Unmanned Aerial Vehicle Imagery Using Random Forest and Support Vector Machine Classifiers
T2  - ISPRS International Journal of Geo-Information

PY  - 2017
VL  - 6
IS  - 2
SN  - 2220-9964

AB  - The increased feature space available in object-based classification environments (e.g., extended spectral feature sets per object, shape properties, or textural features) has a high potential of improving classifications. However, the availability of a large number of derived features per segmented object can also lead to a time-consuming and subjective process of optimizing the feature subset. The objectives of this study are to evaluate the effect of the advanced feature selection methods of popular supervised classifiers (Support Vector Machines (SVM) and Random Forest (RF)) for the example of object-based mapping of an agricultural area using Unmanned Aerial Vehicle (UAV) imagery, in order to optimize their usage for object-based agriculture pattern recognition tasks. In this study, several advanced feature selection methods were divided into both types of classifiers (SVM and RF) to conduct further evaluations using five feature-importance-evaluation methods and three feature-subset-evaluation methods. A visualization method was used to measure the change pattern of mean classification accuracy with the increase of features used, and a two-tailed t-test was used to determine the difference between two population means for both repeated ten classification accuracies. This study mainly contribute to the uncertainty analysis of feature selection for object-based classification instead of the per-pixel method. The results highlight that the RF classifier is relatively insensitive to the number of input features, even for a small training set size, whereby a negative impact of feature set size on the classification accuracy of the SVM classifier was observed. Overall, the SVM Recursive Feature Elimination (SVM-RFE) seems to be an appropriate method for both groups of classifiers, while the Correlation-based Feature Selection (CFS) is the best feature-subset-evaluation method. Most importantly, this study verified that feature selection for both classifiers is crucial for the evolving field of Object-based Image Analysis (OBIA): It is highly advisable for feature selection to be performed before object-based classification, even though an adverse impact could sometimes be observed from the wrapper methods.
KW  - classification
KW  - object-based image analysis (OBIA)
KW  - feature selection
KW  - SVM-RFE
KW  - CFS
KW  - random forest
KW  - support vector machines
KW  - high-resolution image
DO  - 10.3390/ijgi6020051
ER  -
TY  - EJOU
AU  - Crommelinck, Sophie
AU  - Bennett, Rohan
AU  - Gerke, Markus
AU  - Yang, Michael Y.
AU  - Vosselman, George
TI  - Contour Detection for UAV-Based Cadastral Mapping
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 2
SN  - 2072-4292

AB  - Unmanned aerial vehicles (UAVs) provide a flexible and low-cost solution for the acquisition of high-resolution data. The potential of high-resolution UAV imagery to create and update cadastral maps is being increasingly investigated. Existing procedures generally involve substantial fieldwork and many manual processes. Arguably, multiple parts of UAV-based cadastral mapping workflows could be automated. Specifically, as many cadastral boundaries coincide with visible boundaries, they could be extracted automatically using image analysis methods. This study investigates the transferability of gPb contour detection, a state-of-the-art computer vision method, to remotely sensed UAV images and UAV-based cadastral mapping. Results show that the approach is transferable to UAV data and automated cadastral mapping: object contours are comprehensively detected at completeness and correctness rates of up to 80%. The detection quality is optimal when the entire scene is covered with one orthoimage, due to the global optimization of gPb contour detection. However, a balance between high completeness and correctness is hard to achieve, so a combination with area-based segmentation and further object knowledge is proposed. The localization quality exhibits the usual dependency on ground resolution. The approach has the potential to accelerate the process of general boundary delineation during the creation and updating of cadastral maps.
KW  - UAV photogrammetry
KW  - remote sensing
KW  - computer vision
KW  - image segmentation
KW  - contour generation
KW  - object detection
KW  - boundary localization
KW  - cadastral boundaries
KW  - land administration
DO  - 10.3390/rs9020171
ER  -
TY  - EJOU
AU  - Nevalainen, Olli
AU  - Honkavaara, Eija
AU  - Tuominen, Sakari
AU  - Viljanen, Niko
AU  - Hakala, Teemu
AU  - Yu, Xiaowei
AU  - Hyyppä, Juha
AU  - Saari, Heikki
AU  - Pölönen, Ilkka
AU  - Imai, Nilton N.
AU  - Tommaselli, Antonio M. G.
TI  - Individual Tree Detection and Classification with UAV-Based Photogrammetric Point Clouds and Hyperspectral Imaging
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 3
SN  - 2072-4292

AB  - Small unmanned aerial vehicle (UAV) based remote sensing is a rapidly evolving technology. Novel sensors and methods are entering the market, offering completely new possibilities to carry out remote sensing tasks. Three-dimensional (3D) hyperspectral remote sensing is a novel and powerful technology that has recently become available to small UAVs. This study investigated the performance of UAV-based photogrammetry and hyperspectral imaging in individual tree detection and tree species classification in boreal forests. Eleven test sites with 4151 reference trees representing various tree species and developmental stages were collected in June 2014 using a UAV remote sensing system equipped with a frame format hyperspectral camera and an RGB camera in highly variable weather conditions. Dense point clouds were measured photogrammetrically by automatic image matching using high resolution RGB images with a 5 cm point interval. Spectral features were obtained from the hyperspectral image blocks, the large radiometric variation of which was compensated for by using a novel approach based on radiometric block adjustment with the support of in-flight irradiance observations. Spectral and 3D point cloud features were used in the classification experiment with various classifiers. The best results were obtained with Random Forest and Multilayer Perceptron (MLP) which both gave 95% overall accuracies and an F-score of 0.93. Accuracy of individual tree identification from the photogrammetric point clouds varied between 40% and 95%, depending on the characteristics of the area. Challenges in reference measurements might also have reduced these numbers. Results were promising, indicating that hyperspectral 3D remote sensing was operational from a UAV platform even in very difficult conditions. These novel methods are expected to provide a powerful tool for automating various environmental close-range remote sensing tasks in the very near future.
KW  - UAV
KW  - hyperspectral
KW  - photogrammetry
KW  - radiometry
KW  - point cloud
KW  - forest
KW  - classification
DO  - 10.3390/rs9030185
ER  -
TY  - EJOU
AU  - Adeyemi, Olutobi
AU  - Grove, Ivan
AU  - Peets, Sven
AU  - Norton, Tomas
TI  - Advanced Monitoring and Management Systems for Improving Sustainability in Precision Irrigation
T2  - Sustainability

PY  - 2017
VL  - 9
IS  - 3
SN  - 2071-1050

AB  - Globally, the irrigation of crops is the largest consumptive user of fresh water. Water scarcity is increasing worldwide, resulting in tighter regulation of its use for agriculture. This necessitates the development of irrigation practices that are more efficient in the use of water but do not compromise crop quality and yield. Precision irrigation already achieves this goal, in part. The goal of precision irrigation is to accurately supply the crop water need in a timely manner and as spatially uniformly as possible. However, to maximize the benefits of precision irrigation, additional technologies need to be enabled and incorporated into agriculture. This paper discusses how incorporating adaptive decision support systems into precision irrigation management will enable significant advances in increasing the efficiency of current irrigation approaches. From the literature review, it is found that precision irrigation can be applied in achieving the environmental goals related to sustainability. The demonstrated economic benefits of precision irrigation in field-scale crop production is however minimal. It is argued that a proper combination of soil, plant and weather sensors providing real-time data to an adaptive decision support system provides an innovative platform for improving sustainability in irrigated agriculture. The review also shows that adaptive decision support systems based on model predictive control are able to adequately account for the time-varying nature of the soil–plant–atmosphere system while considering operational limitations and agronomic objectives in arriving at optimal irrigation decisions. It is concluded that significant improvements in crop yield and water savings can be achieved by incorporating model predictive control into precision irrigation decision support tools. Further improvements in water savings can also be realized by including deficit irrigation as part of the overall irrigation management strategy. Nevertheless, future research is needed for identifying crop response to regulated water deficits, developing improved soil moisture and plant sensors, and developing self-learning crop simulation frameworks that can be applied to evaluate adaptive decision support strategies related to irrigation.
KW  - precision irrigation
KW  - adaptive decision support systems
KW  - model predictive control
KW  - crop yield
KW  - water savings
KW  - sustainability
DO  - 10.3390/su9030353
ER  -
TY  - EJOU
AU  - Poblete-Echeverría, Carlos
AU  - Olmedo, Guillermo F.
AU  - Ingram, Ben
AU  - Bardeen, Matthew
TI  - Detection and Segmentation of Vine Canopy in Ultra-High Spatial Resolution RGB Imagery Obtained from Unmanned Aerial Vehicle (UAV): A Case Study in a Commercial Vineyard
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 3
SN  - 2072-4292

AB  - The use of Unmanned Aerial Vehicles (UAVs) in viticulture permits the capture of aerial Red-Green-Blue (RGB) images with an ultra-high spatial resolution. Recent studies have demonstrated that RGB images can be used to monitor spatial variability of vine biophysical parameters. However, for estimating these parameters, accurate and automated segmentation methods are required to extract relevant information from RGB images. Manual segmentation of aerial images is a laborious and time-consuming process. Traditional classification methods have shown satisfactory results in the segmentation of RGB images for diverse applications and surfaces, however, in the case of commercial vineyards, it is necessary to consider some particularities inherent to canopy size in the vertical trellis systems (VSP) such as shadow effect and different soil conditions in inter-rows (mixed information of soil and weeds). Therefore, the objective of this study was to compare the performance of four classification methods (K-means, Artificial Neural Networks (ANN), Random Forest (RForest) and Spectral Indices (SI)) to detect canopy in a vineyard trained on VSP. Six flights were carried out from post-flowering to harvest in a commercial vineyard cv. Carménère using a low-cost UAV equipped with a conventional RGB camera. The results show that the ANN and the simple SI method complemented with the Otsu method for thresholding presented the best performance for the detection of the vine canopy with high overall accuracy values for all study days. Spectral indices presented the best performance in the detection of Plant class (Vine canopy) with an overall accuracy of around 0.99. However, considering the performance pixel by pixel, the Spectral indices are not able to discriminate between Soil and Shadow class. The best performance in the classification of three classes (Plant, Soil, and Shadow) of vineyard RGB images, was obtained when the SI values were used as input data in trained methods (ANN and RForest), reaching overall accuracy values around 0.98 with high sensitivity values for the three classes.
KW  - precision viticulture
KW  - remote sensing
KW  - spatial variability
KW  - image analysis
KW  - random forest
KW  - artificial neural network
KW  - classification, Otsu method
DO  - 10.3390/rs9030268
ER  -
TY  - EJOU
AU  - Weinmann, Martin
AU  - Weinmann, Michael
AU  - Mallet, Clément
AU  - Brédif, Mathieu
TI  - A Classification-Segmentation Framework for the Detection of Individual Trees in Dense MMS Point Cloud Data Acquired in Urban Areas
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 3
SN  - 2072-4292

AB  - In this paper, we present a novel framework for detecting individual trees in densely sampled 3D point cloud data acquired in urban areas. Given a 3D point cloud, the objective is to assign point-wise labels that are both class-aware and instance-aware, a task that is known as instance-level segmentation. To achieve this, our framework addresses two successive steps. The first step of our framework is given by the use of geometric features for a binary point-wise semantic classification with the objective of assigning semantic class labels to irregularly distributed 3D points, whereby the labels are defined as “tree points” and “other points”. The second step of our framework is given by a semantic segmentation with the objective of separating individual trees within the “tree points”. This is achieved by applying an efficient adaptation of the mean shift algorithm and a subsequent segment-based shape analysis relying on semantic rules to only retain plausible tree segments. We demonstrate the performance of our framework on a publicly available benchmark dataset, which has been acquired with a mobile mapping system in the city of Delft in the Netherlands. This dataset contains     10.13     M labeled 3D points among which     17.6    % are labeled as “tree points”. The derived results clearly reveal a semantic classification of high accuracy (up to     90.77    %) and an instance-level segmentation of high plausibility, while the simplicity, applicability and efficiency of the involved methods even allow applying the complete framework on a standard laptop computer with a reasonable processing time (less than     2.5     h).
KW  - mobile mapping systems
KW  - 3D point cloud
KW  - feature extraction
KW  - feature selection
KW  - semantic classification
KW  - semantic segmentation
KW  - instance-level segmentation
KW  - tree-like objects
DO  - 10.3390/rs9030277
ER  -
TY  - EJOU
AU  - Duan, Fuzhou
AU  - Wan, Yangchun
AU  - Deng, Lei
TI  - A Novel Approach for Coarse-to-Fine Windthrown Tree Extraction Based on Unmanned Aerial Vehicle Images
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 4
SN  - 2072-4292

AB  - Surveys of windthrown trees, resulting from hurricanes and other types of natural disasters, are an important component of agricultural insurance, forestry statistics, and ecological monitoring. Aerial images are commonly used to determine the total area or number of downed trees, but conventional methods suffer from two primary issues: misclassification of windthrown trees due to the interference from other objects or artifacts, and poor extraction resolution when trunk diameters are small. The objective of this study is to develop a coarse-to-fine extraction technique for individual windthrown trees that reduces the effects of these common flaws. The developed method was tested using UAV imagery collected over rubber plantations on Hainan Island after the Nesat typhoon in China on 19 October 2011. First, a coarse extraction of the affected area was performed by analyzing the image spectrum and textural characteristics. A thinning algorithm was then used to simplify downed trees into skeletal structures. Finally, fine extraction of individual trees was achieved using a line detection algorithm. The completeness of windthrown trees in the study area was 75.7% and the correctness was 92.5%. While similar values have been reported in other studies, they often include constraints, such as tree height. This technique is proposed to be a more feasible extraction algorithm as it is capable of achieving low commission errors across a broad range of tree heights and sizes. As such, it is a viable option for extraction of windthrown trees with a small trunk diameter.
KW  - unmanned aerial vehicle images
KW  - individual windthrown trees
KW  - random classification
KW  - Hough transform
DO  - 10.3390/rs9040306
ER  -
TY  - EJOU
AU  - Yuan, Huanhuan
AU  - Yang, Guijun
AU  - Li, Changchun
AU  - Wang, Yanjie
AU  - Liu, Jiangang
AU  - Yu, Haiyang
AU  - Feng, Haikuan
AU  - Xu, Bo
AU  - Zhao, Xiaoqing
AU  - Yang, Xiaodong
TI  - Retrieving Soybean Leaf Area Index from Unmanned Aerial Vehicle Hyperspectral Remote Sensing: Analysis of RF, ANN, and SVM Regression Models
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 4
SN  - 2072-4292

AB  - Leaf area index (LAI) is an important indicator of plant growth and yield that can be monitored by remote sensing. Several models were constructed using datasets derived from SRS and STR sampling methods to determine the optimal model for soybean (multiple strains) LAI inversion for the whole crop growth period and a single growth period. Random forest (RF), artificial neural network (ANN), and support vector machine (SVM) regression models were compared with a partial least-squares regression (PLS) model. The RF model yielded the highest precision, accuracy, and stability with V-R2, SDR2, V-RMSE, and SDRMSE values of 0.741, 0.031, 0.106, and 0.005, respectively, over the whole growth period based on STR sampling. The ANN model had the highest precision, accuracy, and stability (0.452, 0.132, 0.086, and 0.009, respectively) over a single growth phase based on STR sampling. The precision, accuracy, and stability of the RF, ANN, and SVM models were improved by inclusion of STR sampling. The RF model is suitable for estimating LAI when sample plots and variation are relatively large (i.e., the whole growth period or more than one growth period). The ANN model is more appropriate for estimating LAI when sample plots and variation are relatively low (i.e., a single growth period).
KW  - LAI retrieval
KW  - hyperspectral remote sensing
KW  - sampling method
KW  - random forests
KW  - artificial neural networks
KW  - support vector machine
DO  - 10.3390/rs9040309
ER  -
TY  - EJOU
AU  - Ammour, Nassim
AU  - Alhichri, Haikel
AU  - Bazi, Yakoub
AU  - Benjdira, Bilel
AU  - Alajlan, Naif
AU  - Zuair, Mansour
TI  - Deep Learning Approach for Car Detection in UAV Imagery
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 4
SN  - 2072-4292

AB  - This paper presents an automatic solution to the problem of detecting and counting cars in unmanned aerial vehicle (UAV) images. This is a challenging task given the very high spatial resolution of UAV images (on the order of a few centimetres) and the extremely high level of detail, which require suitable automatic analysis methods. Our proposed method begins by segmenting the input image into small homogeneous regions, which can be used as candidate locations for car detection. Next, a window is extracted around each region, and deep learning is used to mine highly descriptive features from these windows. We use a deep convolutional neural network (CNN) system that is already pre-trained on huge auxiliary data as a feature extraction tool, combined with a linear support vector machine (SVM) classifier to classify regions into “car” and “no-car” classes. The final step is devoted to a fine-tuning procedure which performs morphological dilation to smooth the detected regions and fill any holes. In addition, small isolated regions are analysed further using a few sliding rectangular windows to locate cars more accurately and remove false positives. To evaluate our method, experiments were conducted on a challenging set of real UAV images acquired over an urban area. The experimental results have proven that the proposed method outperforms the state-of-the-art methods, both in terms of accuracy and computational time.
KW  - UAV imagery
KW  - car counting
KW  - deep learning
KW  - convolutional neural networks (CNNs)
KW  - support vector machines (SVM)
KW  - mean-shift segmentation
DO  - 10.3390/rs9040312
ER  -
TY  - EJOU
AU  - Chen, Tao
AU  - Trinder, John C.
AU  - Niu, Ruiqing
TI  - Object-Oriented Landslide Mapping Using ZY-3 Satellite Imagery, Random Forest and Mathematical Morphology, for the Three-Gorges Reservoir, China
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 4
SN  - 2072-4292

AB  - Landslide mapping (LM) has recently become an important research topic in remote sensing and geohazards. The area near the Three Gorges Reservoir (TGR) along the Yangtze River in China is one of the most landslide-prone regions in the world, and the area has suffered widespread and significant landslide events in recent years. In our study, an object-oriented landslide mapping (OOLM) framework was proposed for reliable and accurate LM from ‘ZY-3’ high spatial resolution (HSR) satellite images. The framework was based on random forests (RF) and mathematical morphology (MM). RF was first applied as an object feature information reduction tool to identify the significant features for describing landslides, and it was then combined with MM to map the landslides. Three object-feature domains were extracted from the ‘ZY-3’ HSR data: layer information, texture, and geometric features. A total group of 124 features and 24 landslides were used as inputs to determine the landslide boundaries and evaluate the landslide classification accuracy. The results showed that: (1) the feature selection (FS) method had a positive influence on effective landslide mapping; (2) by dividing the data into two sets, training sets which consisted of 20% of the landslide objects (OLS) and non-landslide objects (ONLS), and test sets which consisted of the remaining 80% of the OLS and ONLS, the selected feature subsets were combined for training to obtain an overall classification accuracy of 93.3% ± 0.12% of the test sets; (3) four MM operations based on closing and opening were used to improve the performance of the RF classification. Seven accuracy evaluation indices were used to compare the accuracies of these landslide mapping methods. Finally, the landslide inventory maps were obtained. Based on its efficiency and accuracy, the proposed approach can be employed for rapid response to natural hazards in the Three Gorges area.
KW  - Landslide mapping (LM)
KW  - Random forest (RF)
KW  - ZY-3
KW  - The Three Gorges
KW  - Feature selection (FS)
DO  - 10.3390/rs9040333
ER  -
TY  - EJOU
AU  - Guo, Wei
AU  - Zheng, Bangyou
AU  - Duan, Tao
AU  - Fukatsu, Tokihiro
AU  - Chapman, Scott
AU  - Ninomiya, Seishi
TI  - EasyPCC: Benchmark Datasets and Tools for High-Throughput Measurement of the Plant Canopy Coverage Ratio under Field Conditions
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 4
SN  - 1424-8220

AB  - Understanding interactions of genotype, environment, and management under field conditions is vital for selecting new cultivars and farming systems. Image analysis is considered a robust technique in high-throughput phenotyping with non-destructive sampling. However, analysis of digital field-derived images remains challenging because of the variety of light intensities, growth environments, and developmental stages. The plant canopy coverage (PCC) ratio is an important index of crop growth and development. Here, we present a tool, EasyPCC, for effective and accurate evaluation of the ground coverage ratio from a large number of images under variable field conditions. The core algorithm of EasyPCC is based on a pixel-based segmentation method using a decision-tree-based segmentation model (DTSM). EasyPCC was developed under the MATLAB® and R languages; thus, it could be implemented in high-performance computing to handle large numbers of images following just a single model training process. This study used an experimental set of images from a paddy field to demonstrate EasyPCC, and to show the accuracy improvement possible by adjusting key points (e.g., outlier deletion and model retraining). The accuracy (R2 = 0.99) of the calculated coverage ratio was validated against a corresponding benchmark dataset. The EasyPCC source code is released under GPL license with benchmark datasets of several different crop types for algorithm development and for evaluating ground coverage ratios.
KW  - phenotyping
KW  - digital images
KW  - plant canopy coverage ratio
KW  - field image data
DO  - 10.3390/s17040798
ER  -
TY  - EJOU
AU  - Manrique, Pedro D.
AU  - Johnson, D. D.
AU  - Johnson, Neil F.
TI  - Using Competition to Control Congestion in Autonomous Drone Systems
T2  - Electronics

PY  - 2017
VL  - 6
IS  - 2
SN  - 2079-9292

AB  - With the number and variety of commercial drones and UAVs (Unmanned Aerial Vehicles) set to escalate, there will be high future demands on popular regions of airspace and communication bandwidths. This raises safety concerns and hence heightens the need for a generic quantitative understanding of the real-time dynamics of multi-drone populations. Here, we explain how a simple system design built around system-level competition, as opposed to cooperation, can be used to control and ultimately reduce the fluctuations that ordinarily arise in such congestion situations, while simultaneously keeping the on-board processing requirements minimal. These benefits naturally arise from the collective competition to choose the less crowded option, using only previous outcomes and built-in algorithms. We provide explicit closed-form formulae that are applicable to any number of airborne drones N, and which show that the necessary on-board processing increases slower than N as N increases. This design therefore offers operational advantages over traditional cooperative schemes that require drone-to-drone communications that scale like     N 2    , and also over optimization and control schemes that do not easily scale up to general N. In addition to populations of drones, the same mathematical analysis can be used to describe more complex individual drones that feature N adaptive sensor/actuator units.
KW  - complex systems
KW  - competition
KW  - modeling
KW  - dynamics
DO  - 10.3390/electronics6020031
ER  -
TY  - EJOU
AU  - Meng, Baoping
AU  - Ge, Jing
AU  - Liang, Tiangang
AU  - Yang, Shuxia
AU  - Gao, Jinglong
AU  - Feng, Qisheng
AU  - Cui, Xia
AU  - Huang, Xiaodong
AU  - Xie, Hongjie
TI  - Evaluation of Remote Sensing Inversion Error for the Above-Ground Biomass of Alpine Meadow Grassland Based on Multi-Source Satellite Data
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 4
SN  - 2072-4292

AB  - It is not yet clear whether there is any difference in using remote sensing data of different spatial resolutions and filtering methods to improve the above-ground biomass (AGB) estimation accuracy of alpine meadow grassland. In this study, field measurements of AGB and spectral data at Sangke Town, Gansu Province, China, in three years (2013–2015) are combined to construct AGB estimation models of alpine meadow grassland based on these different remotely-sensed NDVI data: MODIS, HJ-1B CCD of China and Landsat 8 OLI (denoted as NDVIMOD, NDVICCD and NDVIOLI, respectively). This study aims to investigate the estimation errors of AGB from the three satellite sensors, to examine the influence of different filtering methods on MODIS NDVI for the estimation accuracy of AGB and to evaluate the feasibility of large-scale models applied to a small area. The results showed that: (1) filtering the MODIS NDVI using the Savitzky–Golay (SG), logistic and Gaussian approaches can reduce the AGB estimation error; in particular, the SG method performs the best, with the smallest errors at both the sample plot scale (250 m × 250 m) and the entire study area (33.9% and 34.9%, respectively); (2) the optimum estimation model of grassland AGB in the study area is the exponential model based on NDVIOLI, with estimation errors of 29.1% and 30.7% at the sample plot and the study area scales, respectively; and (3) the estimation errors of grassland AGB models previously constructed at different spatial scales (the Tibetan Plateau, Gannan Prefecture and Xiahe County) are higher than those directly constructed based on the small area of this study by 11.9%–36.4% and 5.3%–29.6% at the sample plot and study area scales, respectively. This study presents an improved monitoring algorithm of alpine natural grassland AGB estimation and provides a clear direction for future improvement of the grassland AGB estimation and grassland productivity from remote sensing technology.
KW  - alpine meadow grassland
KW  - above-ground biomass
KW  - inversion model
KW  - error analysis
KW  - applicability evaluation
DO  - 10.3390/rs9040372
ER  -
TY  - EJOU
AU  - Zhuo, Xiangyu
AU  - Koch, Tobias
AU  - Kurz, Franz
AU  - Fraundorfer, Friedrich
AU  - Reinartz, Peter
TI  - Automatic UAV Image Geo-Registration by Matching UAV Images to Georeferenced Image Data
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 4
SN  - 2072-4292

AB  - Recent years have witnessed the fast development of UAVs (unmanned aerial vehicles). As an alternative to traditional image acquisition methods, UAVs bridge the gap between terrestrial and airborne photogrammetry and enable flexible acquisition of high resolution images. However, the georeferencing accuracy of UAVs is still limited by the low-performance on-board GNSS and INS. This paper investigates automatic geo-registration of an individual UAV image or UAV image blocks by matching the UAV image(s) with a previously taken georeferenced image, such as an individual aerial or satellite image with a height map attached or an aerial orthophoto with a DSM (digital surface model) attached. As the biggest challenge for matching UAV and aerial images is in the large differences in scale and rotation, we propose a novel feature matching method for nadir or slightly tilted images. The method is comprised of a dense feature detection scheme, a one-to-many matching strategy and a global geometric verification scheme. The proposed method is able to find thousands of valid matches in cases where SIFT and ASIFT fail. Those matches can be used to geo-register the whole UAV image block towards the reference image data. When the reference images offer high georeferencing accuracy, the UAV images can also be geolocalized in a global coordinate system. A series of experiments involving different scenarios was conducted to validate the proposed method. The results demonstrate that our approach achieves not only decimeter-level registration accuracy, but also comparable global accuracy as the reference images.
KW  - unmanned aerial vehicle
KW  - image registration
KW  - geo-registration
KW  - point cloud
DO  - 10.3390/rs9040376
ER  -
TY  - EJOU
AU  - Andújar, Dionisio
AU  - Dorado, José
AU  - Bengochea-Guevara, José M.
AU  - Conesa-Muñoz, Jesús
AU  - Fernández-Quintanilla, César
AU  - Ribeiro, Ángela
TI  - Influence of Wind Speed on RGB-D Images in Tree Plantations
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 4
SN  - 1424-8220

AB  - Weather conditions can affect sensors’ readings when sampling outdoors. Although sensors are usually set up covering a wide range of conditions, their operational range must be established. In recent years, depth cameras have been shown as a promising tool for plant phenotyping and other related uses. However, the use of these devices is still challenged by prevailing field conditions. Although the influence of lighting conditions on the performance of these cameras has already been established, the effect of wind is still unknown. This study establishes the associated errors when modeling some tree characteristics at different wind speeds. A system using a Kinect v2 sensor and a custom software was tested from null wind speed up to 10 m·s−1. Two tree species with contrasting architecture, poplars and plums, were used as model plants. The results showed different responses depending on tree species and wind speed. Estimations of Leaf Area (LA) and tree volume were generally more consistent at high wind speeds in plum trees. Poplars were particularly affected by wind speeds higher than 5 m·s−1. On the contrary, height measurements were more consistent for poplars than for plum trees. These results show that the use of depth cameras for tree characterization must take into consideration wind conditions in the field. In general, 5 m·s−1 (18 km·h−1) could be established as a conservative limit for good estimations.
KW  - RGB-D images
KW  - Kinect sensor limits
KW  - depth information
KW  - wind speed
KW  - woody crops
DO  - 10.3390/s17040914
ER  -
TY  - EJOU
AU  - Salamat, Babak
AU  - Tonello, Andrea M.
TI  - Stochastic Trajectory Generation Using Particle Swarm Optimization for Quadrotor Unmanned Aerial Vehicles (UAVs)
T2  - Aerospace

PY  - 2017
VL  - 4
IS  - 2
SN  - 2226-4310

AB  - The aim of this paper is to provide a realistic stochastic trajectory generation method for unmanned aerial vehicles that offers a tool for the emulation of trajectories in typical flight scenarios. Three scenarios are defined in this paper. The trajectories for these scenarios are implemented with quintic B-splines that grant smoothness in the second-order derivatives of Euler angles and accelerations. In order to tune the parameters of the quintic B-spline in the search space, a multi-objective optimization method called particle swarm optimization (PSO) is used. The proposed technique satisfies the constraints imposed by the configuration of the unmanned aerial vehicle (UAV). Further particular constraints can be introduced such as: obstacle avoidance, speed limitation, and actuator torque limitations due to the practical feasibility of the trajectories. Finally, the standard rapidly-exploring random tree (RRT*) algorithm, the standard (A*) algorithm and the genetic algorithm (GA) are simulated to make a comparison with the proposed algorithm in terms of execution time and effectiveness in finding the minimum length trajectory.
KW  - stochastic trajectory
KW  - unmanned aerial vehicle (UAV)
KW  - multi-objective optimization
KW  - obstacle avoidance
KW  - particle swarm optimization (PSO)
DO  - 10.3390/aerospace4020027
ER  -
TY  - EJOU
AU  - Ciriza, Raquel
AU  - Sola, Ion
AU  - Albizua, Lourdes
AU  - Álvarez-Mozos, Jesús
AU  - González-Audícana, María
TI  - Automatic Detection of Uprooted Orchards Based on Orthophoto Texture Analysis
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 5
SN  - 2072-4292

AB  - Permanent crops, such as olive groves, vineyards and fruit trees, are important in European agriculture because of their spatial and economic relevance. Agricultural geographical databases (AGDBs) are commonly used by public bodies to gain knowledge of the extension covered by these crops and to manage related agricultural subsidies and inspections. However, the updating of these databases is mostly based on photointerpretation, and thus keeping this information up-to-date is very costly in terms of time and money. This paper describes a methodology for automatic detection of uprooted orchards (parcels where fruit trees have been eliminated) based on the textural classification of orthophotos with a spatial resolution of 0.25 m. The textural features used for this classification were derived from the grey level co-occurrence matrix (GLCM) and wavelet transform, and were selected through principal components (PCA) and separability analyses. Next, a Discriminant Analysis classification algorithm was used to detect uprooted orchards. Entropy, contrast and correlation were found to be the most informative textural features obtained from the co-occurrence matrix. The minimum and standard deviation in plane 3 were the selected features based on wavelet transform. The classification based on these features achieved a true positive rate (TPR) of over 80% and an accuracy (A) of over 88%. As a result, this methodology enabled reducing the number of fields to photointerpret by 60–85%, depending on the membership threshold value selected. The proposed approach could be easily adopted by different stakeholders and could increase significantly the efficiency of agricultural database updating tasks.
KW  - orchard detection
KW  - image analysis
KW  - texture feature
KW  - GLCM
KW  - wavelet transform
KW  - discriminant analysis
KW  - parcel level classification
DO  - 10.3390/rs9050492
ER  -
TY  - EJOU
AU  - Li, Feimo
AU  - Li, Shuxiao
AU  - Zhu, Chengfei
AU  - Lan, Xiaosong
AU  - Chang, Hongxing
TI  - Cost-Effective Class-Imbalance Aware CNN for Vehicle Localization and Categorization in High Resolution Aerial Images
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 5
SN  - 2072-4292

AB  - Joint vehicle localization and categorization in high resolution aerial images can provide useful information for applications such as traffic flow structure analysis. To maintain sufficient features to recognize small-scaled vehicles, a regions with convolutional neural network features (R-CNN) -like detection structure is employed. In this setting, cascaded localization error can be averted by equally treating the negatives and differently typed positives as a multi-class classification task, but the problem of class-imbalance remains. To address this issue, a cost-effective network extension scheme is proposed. In it, the correlated convolution and connection costs during extension are reduced by feature map selection and bi-partite main-side network construction, which are realized with the assistance of a novel feature map class-importance measurement and a new class-imbalance sensitive main-side loss function. By using an image classification dataset established from a set of traditional real-colored aerial images with 0.13 m ground sampling distance which are taken from the height of 1000 m by an imaging system composed of non-metric cameras, the effectiveness of the proposed network extension is verified by comparing with its similarly shaped strong counter-parts. Experiments show an equivalent or better performance, while requiring the least parameter and memory overheads are required.
KW  - vehicle localization
KW  - vehicle classification
KW  - high resolution
KW  - aerial image
KW  - convolutional neural network (CNN)
KW  - class imbalance
DO  - 10.3390/rs9050494
ER  -
TY  - EJOU
AU  - Lamprecht, Sebastian
AU  - Hill, Andreas
AU  - Stoffels, Johannes
AU  - Udelhoven, Thomas
TI  - A Machine Learning Method for Co-Registration and Individual Tree Matching of Forest Inventory and Airborne Laser Scanning Data
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 5
SN  - 2072-4292

AB  - Determining the exact position of a forest inventory plot—and hence the position of the sampled trees—is often hampered by a poor Global Navigation Satellite System (GNSS) signal quality beneath the forest canopy. Inaccurate geo-references hamper the performance of models that aim to retrieve useful information from spatially high remote sensing data (e.g., species classification or timber volume estimation). This restriction is even more severe on the level of individual trees. The objective of this study was to develop a post-processing strategy to improve the positional accuracy of GNSS-measured sample-plot centers and to develop a method to automatically match trees within a terrestrial sample plot to aerial detected trees. We propose a new method which uses a random forest classifier to estimate the matching probability of each terrestrial-reference and aerial detected tree pair, which gives the opportunity to assess the reliability of the results. We investigated 133 sample plots of the Third German National Forest Inventory (BWI, 2011–2012) within the German federal state of Rhineland-Palatinate. For training and objective validation, synthetic forest stands have been modeled using the Waldplaner 2.0 software. Our method has achieved an overall accuracy of 82.7% for co-registration and 89.1% for tree matching. With our method, 60% of the investigated plots could be successfully relocated. The probabilities provided by the algorithm are an objective indicator of the reliability of a specific result which could be incorporated into quantitative models to increase the performance of forest attribute estimations.
KW  - co-registration
KW  - individual tree detection
KW  - tree matching
KW  - point set registration
KW  - machine-learning
KW  - forest inventory
DO  - 10.3390/rs9050505
ER  -
TY  - EJOU
AU  - Zhao, Hanqing
AU  - Fang, Xuan
AU  - Ding, Hu
AU  - Josef, Strobl
AU  - Xiong, Liyang
AU  - Na, Jiaming
AU  - Tang, Guoan
TI  - Extraction of Terraces on the Loess Plateau from High-Resolution DEMs and Imagery Utilizing Object-Based Image Analysis
T2  - ISPRS International Journal of Geo-Information

PY  - 2017
VL  - 6
IS  - 6
SN  - 2220-9964

AB  - Abstract: Terraces are typical artificial landforms on the Loess Plateau, with ecological functions in water and soil conservation, agricultural production, and biodiversity. Recording the spatial distribution of terraces is the basis of monitoring their extent and understanding their ecological effects. The current terrace extraction method mainly relies on high-resolution imagery, but its accuracy is limited due to vegetation coverage distorting the features of terraces in imagery. High-resolution topographic data reflecting the morphology of true terrace surfaces are needed. Terraces extraction on the Loess Plateau is challenging because of the complex terrain and diverse vegetation after the implementation of “vegetation recovery”. This study presents an automatic method of extracting terraces based on 1 m resolution digital elevation models (DEMs) and 0.3 m resolution Worldview-3 imagery as auxiliary information used for object-based image analysis (OBIA). A multi-resolution segmentation method was used where slope, positive and negative terrain index (PN), accumulative curvature slope (AC), and slope of slope (SOS) were determined as input layers for image segmentation by correlation analysis and Sheffield entropy method. The main classification features based on DEMs were chosen from the terrain features derived from terrain factors and texture features by gray-level co-occurrence matrix (GLCM) analysis; subsequently, these features were determined by the importance analysis on classification and regression tree (CART) analysis. Extraction rules based on DEMs were generated from the classification features with a total classification accuracy of 89.96%. The red band and near-infrared band of images were used to exclude construction land, which is easily confused with small-size terraces. As a result, the total classification accuracy was increased to 94%. The proposed method ensures comprehensive consideration of terrain, texture, shape, and spectrum characteristics, demonstrating huge potential in hilly-gully loess region with similarly complex terrain and diverse vegetation covers.
KW  - terraces
KW  - digital elevation model (DEM)
KW  - high-resolution imagery
KW  - object-based image analysis (OBIA)
KW  - terrain factor
KW  - terrain texture
DO  - 10.3390/ijgi6060157
ER  -
TY  - EJOU
AU  - Agapiou, Athos
AU  - Lysandrou, Vasiliki
AU  - Sarris, Apostolos
AU  - Papadopoulos, Nikos
AU  - Hadjimitsis, Diofantos G.
TI  - Fusion of Satellite Multispectral Images Based on Ground-Penetrating Radar (GPR) Data for the Investigation of Buried Concealed Archaeological Remains
T2  - Geosciences

PY  - 2017
VL  - 7
IS  - 2
SN  - 2076-3263

AB  - The paper investigates the superficial layers of an archaeological landscape based on the integration of various remote sensing techniques. It is well known in the literature that shallow depths may be rich in archeological remains, which generate different signal responses depending on the applied technique. In this study three main technologies are examined, namely ground-penetrating radar (GPR), ground spectroscopy, and multispectral satellite imagery. The study aims to propose a methodology to enhance optical remote sensing satellite images, intended for archaeological research, based on the integration of ground based and satellite datasets. For this task, a regression model between the ground spectroradiometer and GPR is established which is then projected to a high resolution sub-meter optical image. The overall methodology consists of nine steps. Beyond the acquirement of the in-situ measurements and their calibration (Steps 1–3), various regression models are examined for more than 70 different vegetation indices (Steps 4–5). The specific data analysis indicated that the red-edge position (REP) hyperspectral index was the most appropriate for developing a local fusion model between ground spectroscopy data and GPR datasets (Step 6), providing comparable results with the in situ GPR measurements (Step 7). Other vegetation indices, such as the normalized difference vegetation index (NDVI), have also been examined, providing significant correlation between the two datasets (R = 0.50). The model is then projected to a high-resolution image over the area of interest (Step 8). The proposed methodology was evaluated with a series of field data collected from the Vésztő-Mágor Tell in the eastern part of Hungary. The results were compared with in situ magnetic gradiometry measurements, indicating common interpretation results. The results were also compatible with the preliminary archaeological investigations of the area (Step 9). The overall outcomes document that fusion models between various types of remote sensing datasets frequently used to support archaeological research can further expand the current capabilities and applications for the detection of buried archaeological remains.
KW  - enhancement
KW  - fusion
KW  - ground spectroscopy
KW  - ground-penetrating radar (GPR)
KW  - GeoEye
KW  - geophysics
KW  - remote sensing archaeology
DO  - 10.3390/geosciences7020040
ER  -
TY  - EJOU
AU  - Yang, Ming-Der
AU  - Huang, Kai-Siang
AU  - Kuo, Yi-Hsuan
AU  - Tsai, Hui P.
AU  - Lin, Liang-Mao
TI  - Spatial and Spectral Hybrid Image Classification for Rice Lodging Assessment through UAV Imagery
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 6
SN  - 2072-4292

AB  - Rice lodging identification relies on manual in situ assessment and often leads to a compensation dispute in agricultural disaster assessment. Therefore, this study proposes a comprehensive and efficient classification technique for agricultural lands that entails using unmanned aerial vehicle (UAV) imagery. In addition to spectral information, digital surface model (DSM) and texture information of the images was obtained through image-based modeling and texture analysis. Moreover, single feature probability (SFP) values were computed to evaluate the contribution of spectral and spatial hybrid image information to classification accuracy. The SFP results revealed that texture information was beneficial for the classification of rice and water, DSM information was valuable for lodging and tree classification, and the combination of texture and DSM information was helpful in distinguishing between artificial surface and bare land. Furthermore, a decision tree classification model incorporating SFP values yielded optimal results, with an accuracy of 96.17% and a Kappa value of 0.941, compared with that of a maximum likelihood classification model (90.76%). The rice lodging ratio in paddies at the study site was successfully identified, with three paddies being eligible for disaster relief. The study demonstrated that the proposed spatial and spectral hybrid image classification technology is a promising tool for rice lodging assessment.
KW  - rice lodging
KW  - unmanned aerial vehicle (UAV)
KW  - image-based modeling
KW  - spectral and spatial hybrid image classification
KW  - decision tree classification
KW  - single feature probability
DO  - 10.3390/rs9060583
ER  -
TY  - EJOU
AU  - Ampatzidis, Yiannis
AU  - De Bellis, Luigi
AU  - Luvisi, Andrea
TI  - iPathology: Robotic Applications and Management of Plants and Plant Diseases
T2  - Sustainability

PY  - 2017
VL  - 9
IS  - 6
SN  - 2071-1050

AB  - The rapid development of new technologies and the changing landscape of the online world (e.g., Internet of Things (IoT), Internet of All, cloud-based solutions) provide a unique opportunity for developing automated and robotic systems for urban farming, agriculture, and forestry. Technological advances in machine vision, global positioning systems, laser technologies, actuators, and mechatronics have enabled the development and implementation of robotic systems and intelligent technologies for precision agriculture. Herein, we present and review robotic applications on plant pathology and management, and emerging agricultural technologies for intra-urban agriculture. Greenhouse advanced management systems and technologies have been greatly developed in the last years, integrating IoT and WSN (Wireless Sensor Network). Machine learning, machine vision, and AI (Artificial Intelligence) have been utilized and applied in agriculture for automated and robotic farming. Intelligence technologies, using machine vision/learning, have been developed not only for planting, irrigation, weeding (to some extent), pruning, and harvesting, but also for plant disease detection and identification. However, plant disease detection still represents an intriguing challenge, for both abiotic and biotic stress. Many recognition methods and technologies for identifying plant disease symptoms have been successfully developed; still, the majority of them require a controlled environment for data acquisition to avoid false positives. Machine learning methods (e.g., deep and transfer learning) present promising results for improving image processing and plant symptom identification. Nevertheless, diagnostic specificity is a challenge for microorganism control and should drive the development of mechatronics and robotic solutions for disease management.
KW  - machine vision
KW  - machine learning
KW  - vertical farming systems
KW  - mechatronics
KW  - smart machines
KW  - smart city
DO  - 10.3390/su9061010
ER  -
TY  - EJOU
AU  - Radovic, Matija
AU  - Adarkwa, Offei
AU  - Wang, Qiaosong
TI  - Object Recognition in Aerial Images Using Convolutional Neural Networks
T2  - Journal of Imaging

PY  - 2017
VL  - 3
IS  - 2
SN  - 2313-433X

AB  - There are numerous applications of unmanned aerial vehicles (UAVs) in the management of civil infrastructure assets. A few examples include routine bridge inspections, disaster management, power line surveillance and traffic surveying. As UAV applications become widespread, increased levels of autonomy and independent decision-making are necessary to improve the safety, efficiency, and accuracy of the devices. This paper details the procedure and parameters used for the training of convolutional neural networks (CNNs) on a set of aerial images for efficient and automated object recognition. Potential application areas in the transportation field are also highlighted. The accuracy and reliability of CNNs depend on the network’s training and the selection of operational parameters. This paper details the CNN training procedure and parameter selection. The object recognition results show that by selecting a proper set of parameters, a CNN can detect and classify objects with a high level of accuracy (97.5%) and computational efficiency. Furthermore, using a convolutional neural network implemented in the “YOLO” (“You Only Look Once”) platform, objects can be tracked, detected (“seen”), and classified (“comprehended”) from video feeds supplied by UAVs in real-time.
KW  - convolutional neural networks
KW  - Unmanned Aerial Vehicle (UAV)
KW  - object recognition and detection
DO  - 10.3390/jimaging3020021
ER  -
TY  - EJOU
AU  - Domingues Franceschini, Marston H.
AU  - Bartholomeus, Harm
AU  - Van Apeldoorn, Dirk
AU  - Suomalainen, Juha
AU  - Kooistra, Lammert
TI  - Intercomparison of Unmanned Aerial Vehicle and Ground-Based Narrow Band Spectrometers Applied to Crop Trait Monitoring in Organic Potato Production
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 6
SN  - 1424-8220

AB  - Vegetation properties can be estimated using optical sensors, acquiring data on board of different platforms. For instance, ground-based and Unmanned Aerial Vehicle (UAV)-borne spectrometers can measure reflectance in narrow spectral bands, while different modelling approaches, like regressions fitted to vegetation indices, can relate spectra with crop traits. Although monitoring frameworks using multiple sensors can be more flexible, they may result in higher inaccuracy due to differences related to the sensors characteristics, which can affect information sampling. Also organic production systems can benefit from continuous monitoring focusing on crop management and stress detection, but few studies have evaluated applications with this objective. In this study, ground-based and UAV spectrometers were compared in the context of organic potato cultivation. Relatively accurate estimates were obtained for leaf chlorophyll (RMSE = 6.07 µg·cm−2), leaf area index (RMSE = 0.67 m2·m−2), canopy chlorophyll (RMSE = 0.24 g·m−2) and ground cover (RMSE = 5.5%) using five UAV-based data acquisitions, from 43 to 99 days after planting. These retrievals are slightly better than those derived from ground-based measurements (RMSE = 7.25 µg·cm−2, 0.85 m2·m−2, 0.28 g·m−2 and 6.8%, respectively), for the same period. Excluding observations corresponding to the first acquisition increased retrieval accuracy and made outputs more comparable between sensors, due to relatively low vegetation cover on this date. Intercomparison of vegetation indices indicated that indices based on the contrast between spectral bands in the visible and near-infrared, like OSAVI, MCARI2 and CIg provided, at certain extent, robust outputs that could be transferred between sensors. Information sampling at plot level by both sensing solutions resulted in comparable discriminative potential concerning advanced stages of late blight incidence. These results indicate that optical sensors, and their integration, have great potential for monitoring this specific organic cropping system.
KW  - hyperspectral imagery
KW  - Vis-NIR spectroscopy
KW  - organic cropping systems
KW  - vegetation indices
DO  - 10.3390/s17061428
ER  -
TY  - EJOU
AU  - Yang, Yurong
AU  - Gong, Huajun
AU  - Wang, Xinhua
AU  - Sun, Peng
TI  - Aerial Target Tracking Algorithm Based on Faster R-CNN Combined with Frame Differencing
T2  - Aerospace

PY  - 2017
VL  - 4
IS  - 2
SN  - 2226-4310

AB  - We propose a robust approach to detecting and tracking moving objects for a naval unmanned aircraft system (UAS) landing on an aircraft carrier. The frame difference algorithm follows a simple principle to achieve real-time tracking, whereas Faster Region-Convolutional Neural Network (R-CNN) performs highly precise detection and tracking characteristics. We thus combine Faster R-CNN with the frame difference method, which is demonstrated to exhibit robust and real-time detection and tracking performance. In our UAS landing experiments, two cameras placed on both sides of the runway are used to capture the moving UAS. When the UAS is captured, the joint algorithm uses frame difference to detect the moving target (UAS). As soon as the Faster R-CNN algorithm accurately detects the UAS, the detection priority is given to Faster R-CNN. In this manner, we also perform motion segmentation and object detection in the presence of changes in the environment, such as illumination variation or “walking persons”. By combining the 2 algorithms we can accurately detect and track objects with a tracking accuracy rate of up to 99% and a frame per second of up to 40 Hz. Thus, a solid foundation is laid for subsequent landing guidance.
KW  - deep learning
KW  - Faster R-CNN
KW  - UAS landing
KW  - object detection
DO  - 10.3390/aerospace4020032
ER  -
TY  - EJOU
AU  - López-Fernández, Luis
AU  - Lagüela, Susana
AU  - Fernández, Jesús
AU  - González-Aguilera, Diego
TI  - Automatic Evaluation of Photovoltaic Power Stations from High-Density RGB-T 3D Point Clouds
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 6
SN  - 2072-4292

AB  - A low-cost unmanned aerial platform (UAV) equipped with RGB (Red, Green, Blue) and thermographic sensors is used for the acquisition of all the data needed for the automatic detection and evaluation of thermal pathologies on photovoltaic (PV) surfaces and geometric defects in the mounting on photovoltaic power stations. RGB imagery is used for the generation of a georeferenced 3D point cloud through digital image preprocessing, photogrammetric and computer vision algorithms. The point cloud is complemented with temperature values measured by the thermographic sensor and with intensity values derived from the RGB data in order to obtain a multidimensional product (5D: 3D geometry plus temperature and intensity on the visible spectrum). A segmentation workflow based on the proper integration of several state-of-the-art geomatic and mathematic techniques is applied to the 5D product for the detection and sizing of thermal pathologies and geometric defects in the mounting in the PV panels. It consists of a three-step segmentation procedure, involving first the geometric information, then the radiometric (RGB) information, and last the thermal data. No configuration of parameters is required. Thus, the methodology presented contributes to the automation of the inspection of PV farms, through the maximization of the exploitation of the data acquired in the different spectra (visible and thermal infrared bands). Results of the proposed workflow were compared with a ground truth generated according to currently established protocols and complemented with a topographic survey. The proposed methodology was able to detect all pathologies established by the ground truth without adding any false positives. Discrepancies in the measurement of damaged surfaces regarding established ground truth, which can reach the 5% of total panel surface for the visual inspection by an expert operator, decrease with the proposed methodology under the 2%. The geometric evaluation of the facilities presents discrepancies regarding the ground truth lower than one degree for angular parameters (azimuth and tilt) and lower than 0.05 m2 for the area of each solar panel.
KW  - 3D reconstruction
KW  - UAV
KW  - photogrammetry
KW  - computer vision
KW  - infrared thermography
KW  - point cloud
KW  - photovoltaic
KW  - solar energy
KW  - photovoltaic panel
DO  - 10.3390/rs9060631
ER  -
TY  - EJOU
AU  - Ordóñez, Celestino
AU  - Cabo, Carlos
AU  - Sanz-Ablanedo, Enoc
TI  - Automatic Detection and Classification of Pole-Like Objects for Urban Cartography Using Mobile Laser Scanning Data
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 7
SN  - 1424-8220

AB  - Mobile laser scanning (MLS) is a modern and powerful technology capable of obtaining massive point clouds of objects in a short period of time. Although this technology is nowadays being widely applied in urban cartography and 3D city modelling, it has some drawbacks that need to be avoided in order to strengthen it. One of the most important shortcomings of MLS data is concerned with the fact that it provides an unstructured dataset whose processing is very time-consuming. Consequently, there is a growing interest in developing algorithms for the automatic extraction of useful information from MLS point clouds. This work is focused on establishing a methodology and developing an algorithm to detect pole-like objects and classify them into several categories using MLS datasets. The developed procedure starts with the discretization of the point cloud by means of a voxelization, in order to simplify and reduce the processing time in the segmentation process. In turn, a heuristic segmentation algorithm was developed to detect pole-like objects in the MLS point cloud. Finally, two supervised classification algorithms, linear discriminant analysis and support vector machines, were used to distinguish between the different types of poles in the point cloud. The predictors are the principal component eigenvalues obtained from the Cartesian coordinates of the laser points, the range of the Z coordinate, and some shape-related indexes. The performance of the method was tested in an urban area with 123 poles of different categories. Very encouraging results were obtained, since the accuracy rate was over 90%.
KW  - Mobile Laser Scanner (MLS)
KW  - point cloud
KW  - pole-like objects
KW  - automatic feature detection
KW  - principal component analysis
DO  - 10.3390/s17071465
ER  -
TY  - EJOU
AU  - Knoblauch, Christoph
AU  - Watson, Conor
AU  - Berendonk, Clara
AU  - Becker, Rolf
AU  - Wrage-Mönnig, Nicole
AU  - Wichern, Florian
TI  - Relationship between Remote Sensing Data, Plant Biomass and Soil Nitrogen Dynamics in Intensively Managed Grasslands under Controlled Conditions
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 7
SN  - 1424-8220

AB  - The sustainable use of grasslands in intensive farming systems aims to optimize nitrogen (N) inputs to increase crop yields and decrease harmful losses to the environment at the same time. To achieve this, simple optical sensors may provide a non-destructive, time- and cost-effective tool for estimating plant biomass in the field, considering spatial and temporal variability. However, the plant growth and related N uptake is affected by the available N in the soil, and therefore, N mineralization and N losses. These soil N dynamics and N losses are affected by the N input and environmental conditions, and cannot easily be determined non-destructively. Therefore, the question arises: whether a relationship can be depicted between N fertilizer levels, plant biomass and N dynamics as indicated by nitrous oxide (N2O) losses and inorganic N levels. We conducted a standardized greenhouse experiment to explore the potential of spectral measurements for analyzing yield response, N mineralization and N2O emissions in a permanent grassland. Ryegrass was subjected to four mineral fertilizer input levels over 100 days (four harvests) under controlled environmental conditions. The soil temperature and moisture content were automatically monitored, and the emission rates of N2O and carbon dioxide (CO2) were detected frequently. Spectral measurements of the swards were performed directly before harvesting. The normalized difference vegetation index (NDVI) and simple ratio (SR) were moderately correlated with an increasing biomass as affected by fertilization level. Furthermore, we found a non-linear response of increasing N2O emissions to elevated fertilizer levels. Moreover, inorganic N and extractable organic N levels at the end of the experiment tended to increase with the increasing N fertilizer addition. However, microbial biomass C and CO2 efflux showed no significant differences among fertilizer treatments, reflecting no substantial changes in the soil biological pool size and the extent of the C mineralization. Neither the NDVI nor SR, nor the plant biomass, were related to cumulative N2O emissions or inorganic N at harvesting. Our results verify the usefulness of optical sensors for biomass detection, and show the difficulty in linking spectral measurements of plant traits to N processes in the soil, despite that the latter affects the former.
KW  - precision agriculture
KW  - fertilizer response
KW  - vegetation indices
KW  - nitrous oxide emission
KW  - Lolium perenne
KW  - sensor network
DO  - 10.3390/s17071483
ER  -
TY  - EJOU
AU  - Torres-Rua, Alfonso
TI  - Vicarious Calibration of sUAS Microbolometer Temperature Imagery for Estimation of Radiometric Land Surface Temperature
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 7
SN  - 1424-8220

AB  - In recent years, the availability of lightweight microbolometer thermal cameras compatible with small unmanned aerial systems (sUAS) has allowed their use in diverse scientific and management activities that require sub-meter pixel resolution. Nevertheless, as with sensors already used in temperature remote sensing (e.g., Landsat satellites), a radiance atmospheric correction is necessary to estimate land surface temperature. This is because atmospheric conditions at any sUAS flight elevation will have an adverse impact on the image accuracy, derived calculations, and study replicability using the microbolometer technology. This study presents a vicarious calibration methodology (sUAS-specific, time-specific, flight-specific, and sensor-specific) for sUAS temperature imagery traceable back to NIST-standards and current atmospheric correction methods. For this methodology, a three-year data collection campaign with a sUAS called “AggieAir”, developed at Utah State University, was performed for vineyards near Lodi, California, for flights conducted at different times (early morning, Landsat overpass, and mid-afternoon”) and seasonal conditions. From the results of this study, it was found that, despite the spectral response of microbolometer cameras (7.0 to 14.0 μm), it was possible to account for the effects of atmospheric and sUAS operational conditions, regardless of time and weather, to acquire accurate surface temperature data. In addition, it was found that the main atmospheric correction parameters (transmissivity and atmospheric radiance) significantly varied over the course of a day. These parameters fluctuated the most in early morning and partially stabilized in Landsat overpass and in mid-afternoon times. In terms of accuracy, estimated atmospheric correction parameters presented adequate statistics (confidence bounds under ±0.1 for transmissivity and ±1.2 W/m2/sr/um for atmospheric radiance, with a range of RMSE below 1.0 W/m2/sr/um) for all sUAS flights. Differences in estimated temperatures between original thermal image and the vicarious calibration procedure reported here were estimated from −5 °C to 10 °C for early morning, and from 0 to 20 °C for Landsat overpass and mid-afternoon times.
KW  - sUAS
KW  - vicarious calibration
KW  - thermal calibration
KW  - surface temperature
KW  - atmospheric correction
KW  - microbolometer cameras
KW  - thermal remote sensing
DO  - 10.3390/s17071499
ER  -
TY  - EJOU
AU  - Zeng, Chuiqing
AU  - King, Douglas J.
AU  - Richardson, Murray
AU  - Shan, Bo
TI  - Fusion of Multispectral Imagery and Spectrometer Data in UAV Remote Sensing
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 7
SN  - 2072-4292

AB  - Abstract: High spatial resolution hyperspectral data often used in precision farming applications are not available from current satellite sensors, and difficult or expensive to acquire from standard aircraft. Alternatively, in precision farming, unmanned aerial vehicles (UAVs) are emerging as lower cost and more flexible means to acquire very high resolution imagery. Miniaturized hyperspectral sensors have been developed for UAVs, but the sensors, associated hardware, and data processing software are still cost prohibitive for use by individual farmers or small remote sensing firms. This study simulated hyperspectral image data by fusing multispectral camera imagery and spectrometer data. We mounted a multispectral camera and spectrometer, both being low cost and low weight, on a standard UAV and developed procedures for their precise data alignment, followed by fusion of the spectrometer data with the image data to produce estimated spectra for all the multispectral camera image pixels. To align the data collected from the two sensors in both the time and space domains, a post-acquisition correlation-based global optimization method was used. Data fusion, to estimate hyperspectral reflectance, was implemented using several methods for comparison. Flight data from two crop sites, one being tomatoes, and the other corn and soybeans, were used to evaluate the alignment procedure and the data fusion results. The data alignment procedure resulted in a peak R2 between the spectrometer and camera data of 0.95 and 0.72, respectively, for the two test sites. The corresponding multispectral camera data for these space and time offsets were taken as the best match to a given spectrometer reading, and used in modelling to estimate hyperspectral imagery from the multispectral camera pixel data. Of the fusion approaches evaluated, principal component analysis (PCA) based models and Bayesian imputation reached a similar accuracy, and outperformed simple spline interpolation. Mean absolute error (MAE) between predicted and observed spectra was 17% relative to the mean of the observed spectra, and root mean squared error (RMSE) was 0.028. This approach to deriving estimated hyperspectral image data can be applied in a simple fashion at very low cost for crop assessment and monitoring within individual fields.
KW  - UAV
KW  - data alignment
KW  - data fusion
KW  - precision farming
KW  - spectrometer
KW  - multispectral image
DO  - 10.3390/rs9070696
ER  -
TY  - EJOU
AU  - Danner, Martin
AU  - Berger, Katja
AU  - Wocher, Matthias
AU  - Mauser, Wolfram
AU  - Hank, Tobias
TI  - Retrieval of Biophysical Crop Variables from Multi-Angular Canopy Spectroscopy
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 7
SN  - 2072-4292

AB  - The future German Environmental Mapping and Analysis Program (EnMAP) mission, due to launch in late 2019, will deliver high resolution hyperspectral data from space and will thus contribute to a better monitoring of the dynamic surface of the earth. Exploiting the satellite’s ±30° across-track pointing capabilities will allow for the collection of hyperspectral time-series of homogeneous quality. Various studies have shown the possibility to retrieve geo-biophysical plant variables, like leaf area index (LAI) or leaf chlorophyll content (LCC), from narrowband observations with fixed viewing geometry by inversion of radiative transfer models (RTM). In this study we assess the capability of the well-known PROSPECT 5B + 4SAIL (Scattering by Arbitrarily Inclined Leaves) RTM to estimate these variables from off-nadir observations obtained during a field campaign with respect to EnMAP-like sun–target–sensor-geometries. A novel approach for multiple inquiries of a large look-up-table (LUT) in hierarchical steps is introduced that accounts for the varying instances of all variables of interest. Results show that anisotropic effects are strongest for early growth stages of the winter wheat canopy which influences also the retrieval of the variables. RTM inversions from off-nadir spectra lead to a decreased accuracy for the retrieval of LAI with a relative root mean squared error (rRMSE) of 18% at nadir vs. 25% (backscatter) and 24% (forward scatter) at off-nadir. For LCC estimations, however, off-nadir observations yield improvements, i.e., rRMSE (nadir) = 24% vs. rRMSE (forward scatter) = 20%. It follows that for a variable retrieval through RTM inversion, the final user will benefit from EnMAP time-series for biophysical studies regardless of the acquisition angle and will thus be able to exploit the maximum revisit capability of the mission.
KW  - EnMAP
KW  - hyperspectral
KW  - PROSAIL
KW  - multi-angle
KW  - canopy
KW  - biophysical variables
KW  - agriculture
KW  - spectroscopy
DO  - 10.3390/rs9070726
ER  -
TY  - EJOU
AU  - Maimaitiyiming, Matthew
AU  - Ghulam, Abduwasit
AU  - Bozzolo, Arianna
AU  - Wilkins, Joseph L.
AU  - Kwasniewski, Misha T.
TI  - Early Detection of Plant Physiological Responses to Different Levels of Water Stress Using Reflectance Spectroscopy
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 7
SN  - 2072-4292

AB  - Early detection of water stress is critical for precision farming for improving crop productivity and fruit quality. To investigate varying rootstock and irrigation interactions in an open agricultural ecosystem, different irrigation treatments were implemented in a vineyard experimental site either: (i) nonirrigated (NIR); (ii) with full replacement of evapotranspiration (FIR); or (iii) intermediate irrigation (INT, 50% replacement of evapotranspiration). In the summers 2014 and 2015, we collected leaf reflectance factor spectra of the vineyard using field spectroscopy along with grapevine physiological parameters. To comprehensively analyze the field-collected hyperspectral data, various band combinations were used to calculate the normalized difference spectral index (NDSI) along with 26 various indices from the literature. Then, the relationship between the indices and plant physiological parameters were examined and the strongest relationships were determined. We found that newly-identified NDSIs always performed better than the indices from the literature, and stomatal conductance (Gs) was the plant physiological parameter that showed the highest correlation with NDSI(R603,R558) calculated using leaf reflectance factor spectra (R2 = 0.720). Additionally, the best NDSI(R685,R415) for non-photochemical quenching (NPQ) was determined (R2 = 0.681). Gs resulted in being a proxy of water stress. Therefore, the partial least squares regression (PLSR) method was utilized to develop a predictive model for Gs. Our results showed that the PLSR model was inferior to the NDSI in Gs estimation (R2 = 0.680). The variable importance in the projection (VIP) was then employed to investigate the most important wavelengths that were most effective in determining Gs. The VIP analysis confirmed that the yellow band improves the prediction ability of hyperspectral reflectance factor data in Gs estimation. The findings of this study demonstrate the potential of hyperspectral spectroscopy data in motoring plant stress response.
KW  - grapevine
KW  - water stress
KW  - stomatal conductance
KW  - leaf reflectance factor
KW  - NDSI
KW  - PLSR
DO  - 10.3390/rs9070745
ER  -
TY  - EJOU
AU  - Roldán, Juan J.
AU  - Peña-Tapia, Elena
AU  - Martín-Barrio, Andrés
AU  - Olivares-Méndez, Miguel A.
AU  - Del Cerro, Jaime
AU  - Barrientos, Antonio
TI  - Multi-Robot Interfaces and Operator Situational Awareness: Study of the Impact of Immersion and Prediction
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 8
SN  - 1424-8220

AB  - Multi-robot missions are a challenge for operators in terms of workload and situational awareness. These operators have to receive data from the robots, extract information, understand the situation properly, make decisions, generate the adequate commands, and send them to the robots. The consequences of excessive workload and lack of awareness can vary from inefficiencies to accidents. This work focuses on the study of future operator interfaces of multi-robot systems, taking into account relevant issues such as multimodal interactions, immersive devices, predictive capabilities and adaptive displays. Specifically, four interfaces have been designed and developed: a conventional, a predictive conventional, a virtual reality and a predictive virtual reality interface. The four interfaces have been validated by the performance of twenty-four operators that supervised eight multi-robot missions of fire surveillance and extinguishing. The results of the workload and situational awareness tests show that virtual reality improves the situational awareness without increasing the workload of operators, whereas the effects of predictive components are not significant and depend on their implementation.
KW  - multi-robot
KW  - operator interface
KW  - situational awareness
KW  - immersion
KW  - prediction
KW  - virtual reality
KW  - machine learning
DO  - 10.3390/s17081720
ER  -
TY  - EJOU
AU  - Wang, Yanjun
AU  - Chen, Qi
AU  - Liu, Lin
AU  - Zheng, Dunyong
AU  - Li, Chaokui
AU  - Li, Kai
TI  - Supervised Classification of Power Lines from Airborne LiDAR Data in Urban Areas
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 8
SN  - 2072-4292

AB  - Automatic extraction of power lines using airborne LiDAR (Light Detection and Ranging) data has been one of the most important topics for electric power management. However, this is very challenging over complex urban areas, where power lines are in close proximity to buildings and trees. In this paper, we presented a new, semi-automated and versatile framework that consists of four steps: (i) power line candidate point filtering, (ii) local neighborhood selection, (iii) spatial structural feature extraction, and (iv) SVM classification. We introduced the power line corridor direction for candidate point filtering and multi-scale slant cylindrical neighborhood for spatial structural features extraction. In a detailed evaluation involving seven scales and four types for local neighborhood selection, 26 structural features, and two datasets, we demonstrated that the use of multi-scale slant cylindrical neighborhood for individual 3D points significantly improved the power line classification. The experiments indicated that precision, recall and quality rate of power line classification is more than 98%, 98% and 97%, respectively. Additionally, we showed that our approach can reduce the whole processing time while achieving high accuracy.
KW  - airborne LiDAR data
KW  - power line classification
KW  - urban power line
KW  - neighborhood selection
KW  - spatial structural feature
DO  - 10.3390/rs9080771
ER  -
TY  - EJOU
AU  - Ahmed, Asmau M.
AU  - Duran, Olga
AU  - Zweiri, Yahya
AU  - Smith, Mike
TI  - Hybrid Spectral Unmixing: Using Artificial Neural Networks for Linear/Non-Linear Switching
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 8
SN  - 2072-4292

AB  - Spectral unmixing is a key process in identifying spectral signature of materials and quantifying their spatial distribution over an image. The linear model is expected to provide acceptable results when two assumptions are satisfied: (1) The mixing process should occur at macroscopic level and (2) Photons must interact with single material before reaching the sensor. However, these assumptions do not always hold and more complex nonlinear models are required. This study proposes a new hybrid method for switching between linear and nonlinear spectral unmixing of hyperspectral data based on artificial neural networks. The neural networks was trained with parameters within a window of the pixel under consideration. These parameters are computed to represent the diversity of the neighboring pixels and are based on the Spectral Angular Distance, Covariance and a non linearity parameter. The endmembers were extracted using Vertex Component Analysis while the abundances were estimated using the method identified by the neural networks (Vertex Component Analysis, Fully Constraint Least Square Method, Polynomial Post Nonlinear Mixing Model or Generalized Bilinear Model). Results show that the hybrid method performs better than each of the individual techniques with high overall accuracy, while the abundance estimation error is significantly lower than that obtained using the individual methods. Experiments on both synthetic dataset and real hyperspectral images demonstrated that the proposed hybrid switch method is efficient for solving spectral unmixing of hyperspectral images as compared to individual algorithms.
KW  - hyperspectral image
KW  - spectral unmixing
KW  - endmembers
KW  - artificial neural networks
KW  - hybrid switch method
DO  - 10.3390/rs9080775
ER  -
TY  - EJOU
AU  - Jiang, San
AU  - Jiang, Wanshou
TI  - On-Board GNSS/IMU Assisted Feature Extraction and Matching for Oblique UAV Images
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 8
SN  - 2072-4292

AB  - Feature extraction and matching is a crucial task in the fields of computer vision and photogrammetry. Even though wide researches have been reported, some issues are still existing for oblique images. This paper exploits the use of on-board GNSS/IMU (Global Navigation Satellite System/Inertial Measurement Unit) data to achieve efficient and reliable feature extraction and matching for oblique unmanned aerial vehicle (UAV) images. Firstly, rough POS (Positioning and Orientation System) is calculated for each image with cooperation of on-board GNSS/IMU data and camera installation angles, which enables image rectification and footprint calculation. Secondly, two robust strategies, including the geometric rectification and tile strategy, are considered to address the issues caused by perspective deformations and to relieve the side-effects of image down-sampling. According to the results of individual performance evaluation, four combinations of these two strategies are designed and comprehensively compared in BA (Bundle Adjustment) experiments by using a real oblique UAV dataset. The results reported in this paper demonstrate that the solution with the tiling strategy is superior to the other solutions in terms of efficiency, completeness and accuracy. For feature extraction and matching of oblique UAV images, it is proposed to combine the tiling strategy with existing workflows to achieve an efficient and reliable solution.
KW  - oblique photogrammetry
KW  - unmanned aerial vehicle
KW  - SIFT
KW  - feature matching
KW  - bundle adjustment
DO  - 10.3390/rs9080813
ER  -
TY  - EJOU
AU  - Laso Bayas, Juan C.
AU  - See, Linda
AU  - Perger, Christoph
AU  - Justice, Christina
AU  - Nakalembe, Catherine
AU  - Dempewolf, Jan
AU  - Fritz, Steffen
TI  - Validation of Automatically Generated Global and Regional Cropland Data Sets: The Case of Tanzania
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 8
SN  - 2072-4292

AB  - There is a need to validate existing global cropland maps since they are used for different purposes including agricultural monitoring and assessment. In this paper we validate three recent global products (ESA-CCI, GlobeLand30, FROM-GC) and one regional product (Tanzania Land Cover 2010 Scheme II) using a validation data set that was collected by students through the Geo-Wiki tool. The ultimate aim was to understand the usefulness of these products for agricultural monitoring. Data were collected wall-to-wall for Kilosa district and for a sample across Tanzania. The results show that the amount of and spatial extent of cropland in the different products differs considerably from 8% to 42% for Tanzania, with similar values for Kilosa district. The agreement of the validation data with the four different products varied between 36% and 54% and highlighted that cropland is overestimated by the ESA-CCI and underestimated by FROM-GC. The validation data were also analyzed for consistency between the student interpreters and also compared with a sample interpreted by five experts for quality assurance. Regarding consistency between the students, there was more than 80% agreement if one difference in cropland category was considered (e.g., between low and medium cropland) while most of the confusion with the experts was also within one category difference. In addition to the validation of current cropland products, the data set collected by the students also has potential value as a training set for improving future cropland products.
KW  - land cover
KW  - validation
KW  - cropland
KW  - Geo-Wiki
KW  - agricultural monitoring
DO  - 10.3390/rs9080815
ER  -
TY  - EJOU
AU  - Hannink, Julius
AU  - Ollenschläger, Malte
AU  - Kluge, Felix
AU  - Roth, Nils
AU  - Klucken, Jochen
AU  - Eskofier, Bjoern M.
TI  - Benchmarking Foot Trajectory Estimation Methods for Mobile Gait Analysis
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 9
SN  - 1424-8220

AB  - Mobile gait analysis systems based on inertial sensing on the shoe are applied in a wide range of applications. Especially for medical applications, they can give new insights into motor impairment in, e.g., neurodegenerative disease and help objectify patient assessment. One key component in these systems is the reconstruction of the foot trajectories from inertial data. In literature, various methods for this task have been proposed. However, performance is evaluated on a variety of datasets due to the lack of large, generally accepted benchmark datasets. This hinders a fair comparison of methods. In this work, we implement three orientation estimation and three double integration schemes for use in a foot trajectory estimation pipeline. All methods are drawn from literature and evaluated against a marker-based motion capture reference. We provide a fair comparison on the same dataset consisting of 735 strides from 16 healthy subjects. As a result, the implemented methods are ranked and we identify the most suitable processing pipeline for foot trajectory estimation in the context of mobile gait analysis.
KW  - wearable sensors
KW  - human gait
KW  - clinical gait analysis
KW  - benchmark dataset
KW  - orientation estimation
KW  - double integration
DO  - 10.3390/s17091940
ER  -
TY  - EJOU
AU  - Yan, Yiming
AU  - Tan, Zhichao
AU  - Su, Nan
AU  - Zhao, Chunhui
TI  - Building Extraction Based on an Optimized Stacked Sparse Autoencoder of Structure and Training Samples Using LIDAR DSM and Optical Images
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 9
SN  - 1424-8220

AB  - In this paper, a building extraction method is proposed based on a stacked sparse autoencoder with an optimized structure and training samples. Building extraction plays an important role in urban construction and planning. However, some negative effects will reduce the accuracy of extraction, such as exceeding resolution, bad correction and terrain influence. Data collected by multiple sensors, as light detection and ranging (LIDAR), optical sensor etc., are used to improve the extraction. Using digital surface model (DSM) obtained from LIDAR data and optical images, traditional method can improve the extraction effect to a certain extent, but there are some defects in feature extraction. Since stacked sparse autoencoder (SSAE) neural network can learn the essential characteristics of the data in depth, SSAE was employed to extract buildings from the combined DSM data and optical image. A better setting strategy of SSAE network structure is given, and an idea of setting the number and proportion of training samples for better training of SSAE was presented. The optical data and DSM were combined as input of the optimized SSAE, and after training by an optimized samples, the appropriate network structure can extract buildings with great accuracy and has good robustness.
KW  - stacked sparse autoencoder
KW  - LIDAR DSM
KW  - remote sensing image
KW  - building extraction
DO  - 10.3390/s17091957
ER  -
TY  - EJOU
AU  - Nguyen, Phong Ha
AU  - Kim, Ki Wan
AU  - Lee, Young Won
AU  - Park, Kang Ryoung
TI  - Remote Marker-Based Tracking for UAV Landing Using Visible-Light Camera Sensor
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 9
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs), which are commonly known as drones, have proved to be useful not only on the battlefields where manned flight is considered too risky or difficult, but also in everyday life purposes such as surveillance, monitoring, rescue, unmanned cargo, aerial video, and photography. More advanced drones make use of global positioning system (GPS) receivers during the navigation and control loop which allows for smart GPS features of drone navigation. However, there are problems if the drones operate in heterogeneous areas with no GPS signal, so it is important to perform research into the development of UAVs with autonomous navigation and landing guidance using computer vision. In this research, we determined how to safely land a drone in the absence of GPS signals using our remote maker-based tracking algorithm based on the visible light camera sensor. The proposed method uses a unique marker designed as a tracking target during landing procedures. Experimental results show that our method significantly outperforms state-of-the-art object trackers in terms of both accuracy and processing time, and we perform test on an embedded system in various environments.
KW  - unmanned aerial vehicle (UAV)
KW  - remote marker-based tracking
KW  - visible light camera sensor
KW  - UAV landing
DO  - 10.3390/s17091987
ER  -
TY  - EJOU
AU  - Alexandridis, Thomas K.
AU  - Tamouridou, Afroditi Alexandra
AU  - Pantazi, Xanthoula Eirini
AU  - Lagopodi, Anastasia L.
AU  - Kashefi, Javid
AU  - Ovakoglou, Georgios
AU  - Polychronos, Vassilios
AU  - Moshou, Dimitrios
TI  - Novelty Detection Classifiers in Weed Mapping: Silybum marianum Detection on UAV Multispectral Images
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 9
SN  - 1424-8220

AB  - In the present study, the detection and mapping of Silybum marianum (L.) Gaertn. weed using novelty detection classifiers is reported. A multispectral camera (green-red-NIR) on board a fixed wing unmanned aerial vehicle (UAV) was employed for obtaining high-resolution images. Four novelty detection classifiers were used to identify S. marianum between other vegetation in a field. The classifiers were One Class Support Vector Machine (OC-SVM), One Class Self-Organizing Maps (OC-SOM), Autoencoders and One Class Principal Component Analysis (OC-PCA). As input features to the novelty detection classifiers, the three spectral bands and texture were used. The S. marianum identification accuracy using OC-SVM reached an overall accuracy of 96%. The results show the feasibility of effective S. marianum mapping by means of novelty detection classifiers acting on multispectral UAV imagery.
KW  - weeds
KW  - UAS
KW  - RPAS
KW  - one-class
KW  - machine learning
KW  - remote sensing
KW  - geoinformatics
DO  - 10.3390/s17092007
ER  -
TY  - EJOU
AU  - Luo, Xianghuan
AU  - Bennett, Rohan Mark
AU  - Koeva, Mila
AU  - Lemmen, Christiaan
TI  - Investigating Semi-Automated Cadastral Boundaries Extraction from Airborne Laser Scanned Data
T2  - Land

PY  - 2017
VL  - 6
IS  - 3
SN  - 2073-445X

AB  -  Many developing countries have witnessed the urgent need of accelerating cadastral surveying processes. Previous studies found that large portions of cadastral boundaries coincide with visible physical objects, namely roads, fences, and building walls. This research explores the application of airborne laser scanning (ALS) techniques on cadastral surveys. A semi-automated workflow is developed to extract cadastral boundaries from an ALS point clouds. Firstly, a two-phased workflow was developed that focused on extracting digital representations of physical objects. In the automated extraction phase, after classifying points into semantic components, the outline of planar objects such as building roofs and road surfaces were generated by an α-shape algorithm, whilst the centerlines delineatiation approach was fitted into the lineate object—a fence. Afterwards, the extracted vector lines were edited and refined during the post-refinement phase. Secondly, we quantitatively evaluated the workflow performance by comparing results against an exiting cadastral map as reference. It was found that the workflow achieved promising results: around 80% completeness and 60% correctness on average, although the spatial accuracy is still modest. It is argued that the semi-automated extraction workflow could effectively speed up cadastral surveying, with both human resources and equipment costs being reduced
KW  - cadastral survey
KW  - boundary mapping
KW  - feature extraction
KW  - semi-automation
KW  - point cloud
DO  - 10.3390/land6030060
ER  -
TY  - EJOU
AU  - Xie, Guotao
AU  - Zhang, Xinyu
AU  - Gao, Hongbo
AU  - Qian, Lijun
AU  - Wang, Jianqiang
AU  - Ozguner, Umit
TI  - Situational Assessments Based on Uncertainty-Risk Awareness in Complex Traffic Scenarios
T2  - Sustainability

PY  - 2017
VL  - 9
IS  - 9
SN  - 2071-1050

AB  - Situational assessment (SA) is one of the key parts for the application of intelligent alternative-energy vehicles (IAVs) in the sustainable transportation. It helps IAVs understand and comprehend traffic environments better. In SA, it is crucial to be aware of uncertainty-risks, such as sensor failure or communication loss. The objective of this study is to assess traffic situations considering uncertainty-risks, including environment predicting uncertainty. According to the stochastic environment model, collision probabilities between multiple vehicles are estimated based on integrated trajectory prediction under uncertainty, which combines the physics- and maneuver-based trajectory prediction models for accurate prediction results in the long term. The SA method considers the probabilities of collision at different predicting points, the masses, and relative speeds between the possible colliding objects. In addition, risks beyond the prediction horizon are considered with the proposition of infinite risk assessments (IRAs). This method is applied and proved to assess risks regarding unexpected obstacles in traffic, sensor failure or communication loss, and imperfect detections with different sensing accuracies of the environment. The results indicate that the SA method could evaluate traffic risks under uncertainty in the dynamic traffic environment. This could help IAVs’ plan motion trajectories and make high-level decisions in uncertain environments.
KW  - intelligent alternative-energy vehicles
KW  - situational assessments
KW  - uncertainty-risk awareness
KW  - infinite risk assessments
DO  - 10.3390/su9091582
ER  -
TY  - EJOU
AU  - Zhang, Zhengnan
AU  - Cao, Lin
AU  - She, Guanghui
TI  - Estimating Forest Structural Parameters Using Canopy Metrics Derived from Airborne LiDAR Data in Subtropical Forests
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 9
SN  - 2072-4292

AB  - Accurate and timely estimation of forest structural parameters plays a key role in the management of forest resources, as well as studies on the carbon cycle and biodiversity. Light Detection and Ranging (LiDAR) is a promising active remote sensing technology capable of providing highly accurate three dimensional and wall-to-wall forest structural characteristics. In this study, we evaluated the utility of standard metrics and canopy metrics derived from airborne LiDAR data for estimating plot-level forest structural parameters individually and in combination, over a subtropical forest in Yushan forest farm, southeastern China. Standard metrics, i.e., height-based and density-based metrics, and canopy metrics extracted from canopy vertical profiles, i.e., canopy volume profile (CVP), canopy height distribution (CHD), and foliage profile (FP), were extracted from LiDAR point clouds. Then the standard metrics and canopy metrics were used for estimating forest structural parameters individually and in combination by multiple regression models, including forest type-specific (coniferous forest, broad-leaved forest, mixed forest) models and general models. Additionally, the synergy of standard metrics and canopy metrics for estimating structural parameters was evaluated using field measured data. Finally, the sensitivity of vertical and horizontal resolution of voxel size for estimating forest structural parameters was assessed. The results showed that, in general, the accuracies of forest type-specific models (Adj-R2 = 0.44–0.88) were relatively higher than general models (Adj-R2 = 0.39–0.77). For forest structural parameters, the estimation accuracies of Lorey’s mean height (Adj-R2 = 0.61–0.88) and aboveground biomass (Adj-R2 = 0.54–0.81) models were the highest, followed by volume (Adj-R2 = 0.42–0.78), DBH (Adj-R2 = 0.48–0.74), basal area (Adj-R2 = 0.41–0.69), whereas stem density (Adj-R2 = 0.39–0.64) models were relatively lower. The combination models (Adj-R2 = 0.45–0.88) had higher performance compared with models developed using standard metrics (only) (Adj-R2 = 0.42–0.84) and canopy metrics (only) (Adj-R2 = 0.39–0.83). The results also demonstrated that the optimal voxel size was 5 × 5 × 0.5 m3 for estimating most of the parameters. This study demonstrated that canopy metrics based on canopy vertical profiles can be effectively used to enhance the estimation accuracies of forest structural parameters in subtropical forests.
KW  - forest structural parameter
KW  - LiDAR
KW  - canopy metric
KW  - canopy vertical profile
KW  - subtropical forest
DO  - 10.3390/rs9090940
ER  -
TY  - EJOU
AU  - Meng, Xiaoli
AU  - Wang, Heng
AU  - Liu, Bingbing
TI  - A Robust Vehicle Localization Approach Based on GNSS/IMU/DMI/LiDAR Sensor Fusion for Autonomous Vehicles
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 9
SN  - 1424-8220

AB  - Precise and robust localization in a large-scale outdoor environment is essential for an autonomous vehicle. In order to improve the performance of the fusion of GNSS (Global Navigation Satellite System)/IMU (Inertial Measurement Unit)/DMI (Distance-Measuring Instruments), a multi-constraint fault detection approach is proposed to smooth the vehicle locations in spite of GNSS jumps. Furthermore, the lateral localization error is compensated by the point cloud-based lateral localization method proposed in this paper. Experiment results have verified the algorithms proposed in this paper, which shows that the algorithms proposed in this paper are capable of providing precise and robust vehicle localization.
KW  - sensor fusion
KW  - Unscented Kalman Filter (UKF)
KW  - vehicle localization
DO  - 10.3390/s17092140
ER  -
TY  - EJOU
AU  - Javanmardi, Mahdi
AU  - Javanmardi, Ehsan
AU  - Gu, Yanlei
AU  - Kamijo, Shunsuke
TI  - Towards High-Definition 3D Urban Mapping: Road Feature-Based Registration of Mobile Mapping Systems and Aerial Imagery
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 10
SN  - 2072-4292

AB  - Various applications have utilized a mobile mapping system (MMS) as the main 3D urban remote sensing platform. However, the accuracy and precision of the three-dimensional data acquired by an MMS is highly dependent on the performance of the vehicle’s self-localization, which is generally performed by high-end global navigation satellite system (GNSS)/inertial measurement unit (IMU) integration. However, GNSS/IMU positioning quality degrades significantly in dense urban areas with high-rise buildings, which block and reflect the satellite signals. Traditional landmark updating methods, which improve MMS accuracy by measuring ground control points (GCPs) and manually identifying those points in the data, are both labor-intensive and time-consuming. In this paper, we propose a novel and comprehensive framework for automatically georeferencing MMS data by capitalizing on road features extracted from high-resolution aerial surveillance data. The proposed framework has three key steps: (1) extracting road features from the MMS and aerial data; (2) obtaining Gaussian mixture models from the extracted aerial road features; and (3) performing registration of the MMS data to the aerial map using a dynamic sliding window and the normal distribution transform (NDT). The accuracy of the proposed framework is verified using field data, demonstrating that it is a reliable solution for high-precision urban mapping.
KW  - mobile mapping system
KW  - airborne imagery
KW  - airborne laser scanning
KW  - point cloud
KW  - lidar
KW  - urban
KW  - road marking
KW  - 3D map
KW  - landmark update
DO  - 10.3390/rs9100975
ER  -
TY  - EJOU
AU  - Ribeiro-Gomes, Krishna
AU  - Hernández-López, David
AU  - Ortega, José F.
AU  - Ballesteros, Rocío
AU  - Poblete, Tomás
AU  - Moreno, Miguel A.
TI  - Uncooled Thermal Camera Calibration and Optimization of the Photogrammetry Process for UAV Applications in Agriculture
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 10
SN  - 1424-8220

AB  - The acquisition, processing, and interpretation of thermal images from unmanned aerial vehicles (UAVs) is becoming a useful source of information for agronomic applications because of the higher temporal and spatial resolution of these products compared with those obtained from satellites. However, due to the low load capacity of the UAV they need to mount light, uncooled thermal cameras, where the microbolometer is not stabilized to a constant temperature. This makes the camera precision low for many applications. Additionally, the low contrast of the thermal images makes the photogrammetry process inaccurate, which result in large errors in the generation of orthoimages. In this research, we propose the use of new calibration algorithms, based on neural networks, which consider the sensor temperature and the digital response of the microbolometer as input data. In addition, we evaluate the use of the Wallis filter for improving the quality of the photogrammetry process using structure from motion software. With the proposed calibration algorithm, the measurement accuracy increased from 3.55 °C with the original camera configuration to 1.37 °C. The implementation of the Wallis filter increases the number of tie-point from 58,000 to 110,000 and decreases the total positing error from 7.1 m to 1.3 m.
KW  - uncooled thermal camera calibration
KW  - microbolometer
KW  - unmanned aerial vehicle
KW  - image filtering
KW  - structure from motion
KW  - irrigation management
DO  - 10.3390/s17102173
ER  -
TY  - EJOU
AU  - Sandino, Juan
AU  - Wooler, Adam
AU  - Gonzalez, Felipe
TI  - Towards the Automatic Detection of Pre-Existing Termite Mounds through UAS and Hyperspectral Imagery
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 10
SN  - 1424-8220

AB  - The increased technological developments in Unmanned Aerial Vehicles (UAVs) combined with artificial intelligence and Machine Learning (ML) approaches have opened the possibility of remote sensing of extensive areas of arid lands. In this paper, a novel approach towards the detection of termite mounds with the use of a UAV, hyperspectral imagery, ML and digital image processing is intended. A new pipeline process is proposed to detect termite mounds automatically and to reduce, consequently, detection times. For the classification stage, several ML classification algorithms’ outcomes were studied, selecting support vector machines as the best approach for their role in image classification of pre-existing termite mounds. Various test conditions were applied to the proposed algorithm, obtaining an overall accuracy of 68%. Images with satisfactory mound detection proved that the method is “resolution-dependent”. These mounds were detected regardless of their rotation and position in the aerial image. However, image distortion reduced the number of detected mounds due to the inclusion of a shape analysis method in the object detection phase, and image resolution is still determinant to obtain accurate results. Hyperspectral imagery demonstrated better capabilities to classify a huge set of materials than implementing traditional segmentation methods on RGB images only.
KW  - pre-existing termite mounds
KW  - UAV
KW  - hyperspectral camera
KW  - machine learning
KW  - image segmentation
KW  - support vector machines
DO  - 10.3390/s17102196
ER  -
TY  - EJOU
AU  - Zheng, Zhong
AU  - Zhou, Weiqi
AU  - Wang, Jia
AU  - Hu, Xiaofang
AU  - Qian, Yuguo
TI  - Sixty-Year Changes in Residential Landscapes in Beijing: A Perspective from Both the Horizontal (2D) and Vertical (3D) Dimensions
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 10
SN  - 2072-4292

AB  - Landscape changes associated with urbanization can lead to many serious ecological and environmental problems. Quantifying the vertical structure of the urban landscape and its change is important to understand its social and ecological impacts, but previous studies mainly focus on urban horizontal expansion and its impacts on land cover/land use change. This papers focuses on the residential landscape to investigate how the vertical dimension of the urban landscape (i.e., building height) change through time, and how such change is related to changes in the horizontal dimension of the landscape, using Beijing, the capital of China, as a case study. We quantified the expansion of the residential neighborhoods from 1949 to 2009, and changes in vegetation coverage, building density, and building height within these neighborhoods, using 1 m spatial resolution imagery. One-way ANOVA and correlation analysis were used to examine the relationships of building height to vegetation coverage and building density. We found: (1) The residential areas expanded rapidly and were dominated by outward growth, with much less within-city infilling. The growth rate varied greatly through time, first increasing from 1949–2004 and then decreasing from 2005–2009. The expansion direction of newly built residential neighborhoods shifted from west to north in a clockwise direction. (2) The vertical structure of residential neighborhoods changed with time and varied in space, forming a “low-high” pattern from urban central areas to the urban edges within the 5th ring road of Beijing. (3) The residential neighborhoods built in different time periods had significant differences in vegetation coverage, building density, and building height. The residential neighborhoods built in more recent years tended to have taller buildings, lower building density and lower vegetation coverage.
KW  - urban expansion
KW  - residential landscape
KW  - vertical structure
KW  - urban landscape
KW  - heterogeneity dynamics
KW  - building density
KW  - building height
KW  - urban ecology
DO  - 10.3390/rs9100992
ER  -
TY  - EJOU
AU  - Rivas Casado, Mónica
AU  - González, Rocío B.
AU  - Ortega, José F.
AU  - Leinster, Paul
AU  - Wright, Ros
TI  - Towards a Transferable UAV-Based Framework for River Hydromorphological Characterization
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 10
SN  - 1424-8220

AB  - The multiple protocols that have been developed to characterize river hydromorphology, partly in response to legislative drivers such as the European Union Water Framework Directive (EU WFD), make the comparison of results obtained in different countries challenging. Recent studies have analyzed the comparability of existing methods, with remote sensing based approaches being proposed as a potential means of harmonizing hydromorphological characterization protocols. However, the resolution achieved by remote sensing products may not be sufficient to assess some of the key hydromorphological features that are required to allow an accurate characterization. Methodologies based on high resolution aerial photography taken from Unmanned Aerial Vehicles (UAVs) have been proposed by several authors as potential approaches to overcome these limitations. Here, we explore the applicability of an existing UAV based framework for hydromorphological characterization to three different fluvial settings representing some of the distinct ecoregions defined by the WFD geographical intercalibration groups (GIGs). The framework is based on the automated recognition of hydromorphological features via tested and validated Artificial Neural Networks (ANNs). Results show that the framework is transferable to the Central-Baltic and Mediterranean GIGs with accuracies in feature identification above 70%. Accuracies of 50% are achieved when the framework is implemented in the Very Large Rivers GIG. The framework successfully identified vegetation, deep water, shallow water, riffles, side bars and shadows for the majority of the reaches. However, further algorithm development is required to ensure a wider range of features (e.g., chutes, structures and erosion) are accurately identified. This study also highlights the need to develop an objective and fit for purpose hydromorphological characterization framework to be adopted within all EU member states to facilitate comparison of results.
KW  - hydromorphology
KW  - intercalibration
KW  - unmanned aerial vehicle
KW  - photogrammetry
KW  - artificial neural network
KW  - water framework directive
DO  - 10.3390/s17102210
ER  -
TY  - EJOU
AU  - Zhang, Dan
AU  - Wei, Bin
TI  - On the Development of Learning Control for Robotic Manipulators
T2  - Robotics

PY  - 2017
VL  - 6
IS  - 4
SN  - 2218-6581

AB  - Learning control for robotic manipulators has been developed over the past decade and to the best of the authors’ knowledge, it is still in its infant development stage; the authors believe that it will become one of the most promising directions in the control area in robotic manipulators. Learning control in robotic manipulators is mainly used to address the issue that the friction at the joints of robotic mechanisms and other uncertainties may exist in the dynamic models, which are very complex and may even be impossible to model mathematically. In this paper, the authors review and discuss the learning control in robotic manipulators and some issues in learning control for robotic manipulators are also illustrated. This review is able to give a general guideline for future research in learning control for robotic manipulators.
KW  - learning control
KW  - robotic mechanisms
KW  - planning
KW  - uncertainties
KW  - development
DO  - 10.3390/robotics6040023
ER  -
TY  - EJOU
AU  - Jia, Shengyao
AU  - Li, Hongyang
AU  - Wang, Yanjie
AU  - Tong, Renyuan
AU  - Li, Qing
TI  - Hyperspectral Imaging Analysis for the Classification of Soil Types and the Determination of Soil Total Nitrogen
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 10
SN  - 1424-8220

AB  - Soil is an important environment for crop growth. Quick and accurately access to soil nutrient content information is a prerequisite for scientific fertilization. In this work, hyperspectral imaging (HSI) technology was applied for the classification of soil types and the measurement of soil total nitrogen (TN) content. A total of 183 soil samples collected from Shangyu City (People’s Republic of China), were scanned by a near-infrared hyperspectral imaging system with a wavelength range of 874–1734 nm. The soil samples belonged to three major soil types typical of this area, including paddy soil, red soil and seashore saline soil. The successive projections algorithm (SPA) method was utilized to select effective wavelengths from the full spectrum. Pattern texture features (energy, contrast, homogeneity and entropy) were extracted from the gray-scale images at the effective wavelengths. The support vector machines (SVM) and partial least squares regression (PLSR) methods were used to establish classification and prediction models, respectively. The results showed that by using the combined data sets of effective wavelengths and texture features for modelling an optimal correct classification rate of 91.8%. could be achieved. The soil samples were first classified, then the local models were established for soil TN according to soil types, which achieved better prediction results than the general models. The overall results indicated that hyperspectral imaging technology could be used for soil type classification and soil TN determination, and data fusion combining spectral and image texture information showed advantages for the classification of soil types.
KW  - hyperspectral imaging
KW  - soil type classification
KW  - total nitrogen
KW  - texture features
KW  - data fusion
DO  - 10.3390/s17102252
ER  -
TY  - EJOU
AU  - Poux, Florent
AU  - Neuville, Romain
AU  - Van Wersch, Line
AU  - Nys, Gilles-Antoine
AU  - Billen, Roland
TI  - 3D Point Clouds in Archaeology: Advances in Acquisition, Processing and Knowledge Integration Applied to Quasi-Planar Objects
T2  - Geosciences

PY  - 2017
VL  - 7
IS  - 4
SN  - 2076-3263

AB  - Digital investigations of the real world through point clouds and derivatives are changing how curators, cultural heritage researchers and archaeologists work and collaborate. To progressively aggregate expertise and enhance the working proficiency of all professionals, virtual reconstructions demand adapted tools to facilitate knowledge dissemination. However, to achieve this perceptive level, a point cloud must be semantically rich, retaining relevant information for the end user. In this paper, we review the state of the art of point cloud integration within archaeological applications, giving an overview of 3D technologies for heritage, digital exploitation and case studies showing the assimilation status within 3D GIS. Identified issues and new perspectives are addressed through a knowledge-based point cloud processing framework for multi-sensory data, and illustrated on mosaics and quasi-planar objects. A new acquisition, pre-processing, segmentation and ontology-based classification method on hybrid point clouds from both terrestrial laser scanning and dense image matching is proposed to enable reasoning for information extraction. Experiments in detection and semantic enrichment show promising results of 94% correct semantization. Then, we integrate the metadata in an archaeological smart point cloud data structure allowing spatio-semantic queries related to CIDOC-CRM. Finally, a WebGL prototype is presented that leads to efficient communication between actors by proposing optimal 3D data visualizations as a basis on which interaction can grow.
KW  - point cloud
KW  - data fusion
KW  - laser scanning
KW  - dense image-matching
KW  - feature extraction
KW  - classification
KW  - knowledge integration
KW  - cultural heritage
KW  - ontology
DO  - 10.3390/geosciences7040096
ER  -
TY  - EJOU
AU  - Bakr, Muhammad Abu
AU  - Lee, Sukhan
TI  - Distributed Multisensor Data Fusion under Unknown Correlation and Data Inconsistency
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 11
SN  - 1424-8220

AB  - The paradigm of multisensor data fusion has been evolved from a centralized architecture to a decentralized or distributed architecture along with the advancement in sensor and communication technologies. These days, distributed state estimation and data fusion has been widely explored in diverse fields of engineering and control due to its superior performance over the centralized one in terms of flexibility, robustness to failure and cost effectiveness in infrastructure and communication. However, distributed multisensor data fusion is not without technical challenges to overcome: namely, dealing with cross-correlation and inconsistency among state estimates and sensor data. In this paper, we review the key theories and methodologies of distributed multisensor data fusion available to date with a specific focus on handling unknown correlation and data inconsistency. We aim at providing readers with a unifying view out of individual theories and methodologies by presenting a formal analysis of their implications. Finally, several directions of future research are highlighted.
KW  - multisensor data fusion
KW  - decentralized estimation
KW  - distributed fusion
KW  - inconsistent estimates
KW  - spurious data
KW  - unknown correlation
DO  - 10.3390/s17112472
ER  -
TY  - EJOU
AU  - Poblete, Tomas
AU  - Ortega-Farías, Samuel
AU  - Moreno, Miguel A.
AU  - Bardeen, Matthew
TI  - Artificial Neural Network to Predict Vine Water Status Spatial Variability Using Multispectral Information Obtained from an Unmanned Aerial Vehicle (UAV)
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 11
SN  - 1424-8220

AB  - Water stress, which affects yield and wine quality, is often evaluated using the midday stem water potential (Ψstem). However, this measurement is acquired on a per plant basis and does not account for the assessment of vine water status spatial variability. The use of multispectral cameras mounted on unmanned aerial vehicle (UAV) is capable to capture the variability of vine water stress in a whole field scenario. It has been reported that conventional multispectral indices (CMI) that use information between 500–800 nm, do not accurately predict plant water status since they are not sensitive to water content. The objective of this study was to develop artificial neural network (ANN) models derived from multispectral images to predict the Ψstem spatial variability of a drip-irrigated Carménère vineyard in Talca, Maule Region, Chile. The coefficient of determination (R2) obtained between ANN outputs and ground-truth measurements of Ψstem were between 0.56–0.87, with the best performance observed for the model that included the bands 550, 570, 670, 700 and 800 nm. Validation analysis indicated that the ANN model could estimate Ψstem with a mean absolute error (MAE) of 0.1 MPa, root mean square error (RMSE) of 0.12 MPa, and relative error (RE) of −9.1%. For the validation of the CMI, the MAE, RMSE and RE values were between 0.26–0.27 MPa, 0.32–0.34 MPa and −24.2–25.6%, respectively.
KW  - multispectral image processing
KW  - artificial neural network
KW  - UAV
KW  - midday stem water potential
DO  - 10.3390/s17112488
ER  -
TY  - EJOU
AU  - Yamamoto, Kyosuke
AU  - Togami, Takashi
AU  - Yamaguchi, Norio
TI  - Super-Resolution of Plant Disease Images for the Acceleration of Image-based Phenotyping and Vigor Diagnosis in Agriculture
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 11
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs or drones) are a very promising branch of technology, and they have been utilized in agriculture—in cooperation with image processing technologies—for phenotyping and vigor diagnosis. One of the problems in the utilization of UAVs for agricultural purposes is the limitation in flight time. It is necessary to fly at a high altitude to capture the maximum number of plants in the limited time available, but this reduces the spatial resolution of the captured images. In this study, we applied a super-resolution method to the low-resolution images of tomato diseases to recover detailed appearances, such as lesions on plant organs. We also conducted disease classification using high-resolution, low-resolution, and super-resolution images to evaluate the effectiveness of super-resolution methods in disease classification. Our results indicated that the super-resolution method outperformed conventional image scaling methods in spatial resolution enhancement of tomato disease images. The results of disease classification showed that the accuracy attained was also better by a large margin with super-resolution images than with low-resolution images. These results indicated that our approach not only recovered the information lost in low-resolution images, but also exerted a beneficial influence on further image analysis. The proposed approach will accelerate image-based phenotyping and vigor diagnosis in the field, because it not only saves time to capture images of a crop in a cultivation field but also secures the accuracy of these images for further analysis.
KW  - super-resolution
KW  - deep learning
KW  - convolutional neural network
KW  - disease classification
KW  - agriculture
DO  - 10.3390/s17112557
ER  -
TY  - EJOU
AU  - Weil, Gilad
AU  - Lensky, Itamar M.
AU  - Resheff, Yehezkel S.
AU  - Levin, Noam
TI  - Optimizing the Timing of Unmanned Aerial Vehicle Image Acquisition for Applied Mapping of Woody Vegetation Species Using Feature Selection
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 11
SN  - 2072-4292

AB  - Most recent studies relating to the classification of vegetation species on the individual level use cutting-edge sensors and follow a data-driven approach, aimed at maximizing classification accuracy within a relatively small allocated area of optimal conditions. However, this approach does not incorporate cost-benefit considerations or the ability of applying the chosen methodology for applied mapping over larger areas with higher natural heterogeneity. In this study, we present a phenology-based cost-effective approach for optimizing the number and timing of unmanned aerial vehicle (UAV) imagery acquisition, based on a priori near-surface observations. A ground-placed camera was used in order to generate annual time series of nine spectral indices and three color conversions (red, green and blue to hue, saturation and value) in four different East Mediterranean sites that represent different environmental conditions. After outliers’ removal, the time series dataset represented 1852 individuals of 12 common vegetation species and annual herbaceous patches. A feature selection process was used for identifying the optimal dates for species classification in every site. The feature selection can be designed for various objectives, e.g., optimization of overall classification, discrimination between two species, or discrimination of one species from all others. In order to evaluate the a priori findings, a UAV was flown for acquiring five overhead multiband orthomosaics (five bands in the visible-near infrared range based on the five optimal dates identified in the feature selection of the near-surface time series of the previous year. An object-based classification methodology was used for the discrimination of 976 individuals of nine species and annual herbaceous patches in the UAV imagery, and resulted in an average overall accuracy of 85% and an average Kappa coefficient of 0.82. This cost-effective approach has high potential for detailed vegetation mapping, regarding the accessibility of UAV-produced time series, compared to hyper-spectral imagery with high spatial resolution which is more expensive and involves great difficulties in implementation over large areas.
KW  - vegetation species classification
KW  - near-surface observations
KW  - feature selection
KW  - unmanned aircraft vehicles
KW  - Mediterranean vegetation
DO  - 10.3390/rs9111130
ER  -
TY  - EJOU
AU  - Tang, Tianyu
AU  - Zhou, Shilin
AU  - Deng, Zhipeng
AU  - Lei, Lin
AU  - Zou, Huanxin
TI  - Arbitrary-Oriented Vehicle Detection in Aerial Imagery with Single Convolutional Neural Networks
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 11
SN  - 2072-4292

AB  - Vehicle detection with orientation estimation in aerial images has received widespread interest as it is important for intelligent traffic management. This is a challenging task, not only because of the complex background and relatively small size of the target, but also the various orientations of vehicles in aerial images captured from the top view. The existing methods for oriented vehicle detection need several post-processing steps to generate final detection results with orientation, which are not efficient enough. Moreover, they can only get discrete orientation information for each target. In this paper, we present an end-to-end single convolutional neural network to generate arbitrarily-oriented detection results directly. Our approach, named Oriented_SSD (Single Shot MultiBox Detector, SSD), uses a set of default boxes with various scales on each feature map location to produce detection bounding boxes. Meanwhile, offsets are predicted for each default box to better match the object shape, which contain the angle parameter for oriented bounding boxes’ generation. Evaluation results on the public DLR Vehicle Aerial dataset and Vehicle Detection in Aerial Imagery (VEDAI) dataset demonstrate that our method can detect both the location and orientation of the vehicle with high accuracy and fast speed. For test images in the DLR Vehicle Aerial dataset with a size of     5616 × 3744    , our method achieves 76.1% average precision (AP) and 78.7% correct direction classification at 5.17 s on an NVIDIA GTX-1060.
KW  - arbitrary-oriented
KW  - vehicle detection
KW  - single convolutional neural networks (CNN)
KW  - aerial images
KW  - near-real-time
DO  - 10.3390/rs9111170
ER  -
TY  - EJOU
AU  - Luo, Xianghuan
AU  - Bennett, Rohan
AU  - Koeva, Mila
AU  - Lemmen, Christiaan
AU  - Quadros, Nathan
TI  - Quantifying the Overlap between Cadastral and Visual Boundaries: A Case Study from Vanuatu
T2  - Urban Science

PY  - 2017
VL  - 1
IS  - 4
SN  - 2413-8851

AB  - Cadastres are argued as an essential tool to support land tenure security. Low cadastral coverage in developing countries creates a driver for innovative methods to expedite the mapping processes. As a human construct, the morphology of parcel boundaries is a diverse and complex topic: there are limited generalized rules for identifying, describing, and classifying them. This paper studies both the institutional and spatial aspects of cadastral boundaries, in order to provide more contemporary knowledge about the morphology of cadastral boundaries. This study inspects the relationship between topographic objects and general boundaries in the case context of Port Vila, Vanuatu. Statistical analysis reveals that under a dialectical error tolerance, large percentages of cadastral boundaries coincide with topographic objects. Specifically, in dense urban regions, road edges and building walls coincide with the majority of cadastral boundaries, with proportions of 49% and 35%, respectively. In suburban regions, the fence (25%), instead of buildings, plays an important role in marking a parcel border. The landscape is observed to have significant impact on parcel morphology. Therefore, constructing a map based on automatic or semi-automatic identification and classification of these features could significantly contribute to cadastral mapping in developing countries.
KW  - cadastre
KW  - general boundary
KW  - boundary morphology
KW  - automated cadastral survey
DO  - 10.3390/urbansci1040032
ER  -
TY  - EJOU
AU  - Li, Shaodan
AU  - Tang, Hong
AU  - Huang, Xin
AU  - Mao, Ting
AU  - Niu, Xiaonan
TI  - Automated Detection of Buildings from Heterogeneous VHR Satellite Images for Rapid Response to Natural Disasters
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 11
SN  - 2072-4292

AB  - In this paper, we present a novel approach for automatically detecting buildings from multiple heterogeneous and uncalibrated very high-resolution (VHR) satellite images for a rapid response to natural disasters. In the proposed method, a simple and efficient visual attention method is first used to extract built-up area candidates (BACs) from each multispectral (MS) satellite image. After this, morphological building indices (MBIs) are extracted from all the masked panchromatic (PAN) and MS images with BACs to characterize the structural features of buildings. Finally, buildings are automatically detected in a hierarchical probabilistic model by fusing the MBI and masked PAN images. The experimental results show that the proposed method is comparable to supervised classification methods in terms of recall, precision and F-value.
KW  - Chinese restaurant franchise
KW  - morphological building index
KW  - building rooftop
DO  - 10.3390/rs9111177
ER  -
TY  - EJOU
AU  - Yang, Liu
AU  - Lu, Yinzhi
AU  - Xiong, Lian
AU  - Tao, Yang
AU  - Zhong, Yuanchang
TI  - A Game Theoretic Approach for Balancing Energy Consumption in Clustered Wireless Sensor Networks
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 11
SN  - 1424-8220

AB  - Clustering is an effective topology control method in wireless sensor networks (WSNs), since it can enhance the network lifetime and scalability. To prolong the network lifetime in clustered WSNs, an efficient cluster head (CH) optimization policy is essential to distribute the energy among sensor nodes. Recently, game theory has been introduced to model clustering. Each sensor node is considered as a rational and selfish player which will play a clustering game with an equilibrium strategy. Then it decides whether to act as the CH according to this strategy for a tradeoff between providing required services and energy conservation. However, how to get the equilibrium strategy while maximizing the payoff of sensor nodes has rarely been addressed to date. In this paper, we present a game theoretic approach for balancing energy consumption in clustered WSNs. With our novel payoff function, realistic sensor behaviors can be captured well. The energy heterogeneity of nodes is considered by incorporating a penalty mechanism in the payoff function, so the nodes with more energy will compete for CHs more actively. We have obtained the Nash equilibrium (NE) strategy of the clustering game through convex optimization. Specifically, each sensor node can achieve its own maximal payoff when it makes the decision according to this strategy. Through plenty of simulations, our proposed game theoretic clustering is proved to have a good energy balancing performance and consequently the network lifetime is greatly enhanced.
KW  - wireless sensor networks (WSNs)
KW  - clustering
KW  - network lifetime
KW  - game theory
KW  - equilibrium
DO  - 10.3390/s17112654
ER  -
TY  - EJOU
AU  - Meng, Xuelian
AU  - Shang, Nan
AU  - Zhang, Xukai
AU  - Li, Chunyan
AU  - Zhao, Kaiguang
AU  - Qiu, Xiaomin
AU  - Weeks, Eddie
TI  - Photogrammetric UAV Mapping of Terrain under Dense Coastal Vegetation: An Object-Oriented Classification Ensemble Algorithm for Classification and Terrain Correction
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 11
SN  - 2072-4292

AB  - Photogrammetric UAV sees a surge in use for high-resolution mapping, but its use to map terrain under dense vegetation cover remains challenging due to a lack of exposed ground surfaces. This paper presents a novel object-oriented classification ensemble algorithm to leverage height, texture and contextual information of UAV data to improve landscape classification and terrain estimation. Its implementation incorporates multiple heuristics, such as multi-input machine learning-based classification, object-oriented ensemble, and integration of UAV and GPS surveys for terrain correction. Experiments based on a densely vegetated wetland restoration site showed classification improvement from 83.98% to 96.12% in overall accuracy and from 0.7806 to 0.947 in kappa value. Use of standard and existing UAV terrain mapping algorithms and software produced reliable digital terrain model only over exposed bare grounds (mean error = −0.019 m and RMSE = 0.035 m) but severely overestimated the terrain by ~80% of mean vegetation height in vegetated areas. The terrain correction method successfully reduced the mean error from 0.302 m to −0.002 m (RMSE from 0.342 m to 0.177 m) in low vegetation and from 1.305 m to 0.057 m (RMSE from 1.399 m to 0.550 m) in tall vegetation. Overall, this research validated a feasible solution to integrate UAV and RTK GPS for terrain mapping in densely vegetated environments. 
KW  - photogrammetric UAV
KW  - high resolution
KW  - coastal topographic mapping
KW  - wetland restoration
KW  - classification correction
KW  - terrain correction
KW  - object-oriented analysis
KW  - classification ensemble
DO  - 10.3390/rs9111187
ER  -
TY  - EJOU
AU  - Zhong, Jiandan
AU  - Lei, Tao
AU  - Yao, Guangle
TI  - Robust Vehicle Detection in Aerial Images Based on Cascaded Convolutional Neural Networks
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 12
SN  - 1424-8220

AB  - Vehicle detection in aerial images is an important and challenging task. Traditionally, many target detection models based on sliding-window fashion were developed and achieved acceptable performance, but these models are time-consuming in the detection phase. Recently, with the great success of convolutional neural networks (CNNs) in computer vision, many state-of-the-art detectors have been designed based on deep CNNs. However, these CNN-based detectors are inefficient when applied in aerial image data due to the fact that the existing CNN-based models struggle with small-size object detection and precise localization. To improve the detection accuracy without decreasing speed, we propose a CNN-based detection model combining two independent convolutional neural networks, where the first network is applied to generate a set of vehicle-like regions from multi-feature maps of different hierarchies and scales. Because the multi-feature maps combine the advantage of the deep and shallow convolutional layer, the first network performs well on locating the small targets in aerial image data. Then, the generated candidate regions are fed into the second network for feature extraction and decision making. Comprehensive experiments are conducted on the Vehicle Detection in Aerial Imagery (VEDAI) dataset and Munich vehicle dataset. The proposed cascaded detection model yields high performance, not only in detection accuracy but also in detection speed.
KW  - vehicle detection
KW  - convolutional neural network
KW  - aerial image
KW  - deep learning
DO  - 10.3390/s17122720
ER  -
TY  - EJOU
AU  - Su, Jinya
AU  - Yi, Dewei
AU  - Liu, Cunjia
AU  - Guo, Lei
AU  - Chen, Wen-Hua
TI  - Dimension Reduction Aided Hyperspectral Image Classification with a Small-sized Training Dataset: Experimental Comparisons
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 12
SN  - 1424-8220

AB  - Hyperspectral images (HSI) provide rich information which may not be captured by other sensing technologies and therefore gradually find a wide range of applications. However, they also generate a large amount of irrelevant or redundant data for a specific task. This causes a number of issues including significantly increased computation time, complexity and scale of prediction models mapping the data to semantics (e.g., classification), and the need of a large amount of labelled data for training. Particularly, it is generally difficult and expensive for experts to acquire sufficient training samples in many applications. This paper addresses these issues by exploring a number of classical dimension reduction algorithms in machine learning communities for HSI classification. To reduce the size of training dataset, feature selection (e.g., mutual information, minimal redundancy maximal relevance) and feature extraction (e.g., Principal Component Analysis (PCA), Kernel PCA) are adopted to augment a baseline classification method, Support Vector Machine (SVM). The proposed algorithms are evaluated using a real HSI dataset. It is shown that PCA yields the most promising performance in reducing the number of features or spectral bands. It is observed that while significantly reducing the computational complexity, the proposed method can achieve better classification results over the classic SVM on a small training dataset, which makes it suitable for real-time applications or when only limited training data are available. Furthermore, it can also achieve performances similar to the classic SVM on large datasets but with much less computing time.
KW  - feature extraction/selection
KW  - image classification
KW  - Hyperspectral image
KW  - PCA
KW  - SVM
DO  - 10.3390/s17122726
ER  -
TY  - EJOU
AU  - Guirado, Emilio
AU  - Tabik, Siham
AU  - Alcaraz-Segura, Domingo
AU  - Cabello, Javier
AU  - Herrera, Francisco
TI  - Deep-learning Versus OBIA for Scattered Shrub Detection with Google Earth Imagery: Ziziphus lotus as Case Study
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 12
SN  - 2072-4292

AB  - There is a growing demand for accurate high-resolution land cover maps in many fields, e.g., in land-use planning and biodiversity conservation. Developing such maps has been traditionally performed using Object-Based Image Analysis (OBIA) methods, which usually reach good accuracies, but require a high human supervision and the best configuration for one image often cannot be extrapolated to a different image. Recently, deep learning Convolutional Neural Networks (CNNs) have shown outstanding results in object recognition in computer vision and are offering promising results in land cover mapping. This paper analyzes the potential of CNN-based methods for detection of plant species of conservation concern using free high-resolution Google Earth     TM     images and provides an objective comparison with the state-of-the-art OBIA-methods. We consider as case study the detection of Ziziphus lotus shrubs, which are protected as a priority habitat under the European Union Habitats Directive. Compared to the best performing OBIA-method, the best CNN-detector achieved up to 12% better precision, up to 30% better recall and up to 20% better balance between precision and recall. Besides, the knowledge that CNNs acquired in the first image can be re-utilized in other regions, which makes the detection process very fast. A natural conclusion of this work is that including CNN-models as classifiers, e.g., ResNet-classifier, could further improve OBIA methods. The provided methodology can be systematically reproduced for other species detection using our codes available through (https://github.com/EGuirado/CNN-remotesensing).
KW  - Ziziphus lotus
KW  - plant species detection
KW  - land cover mapping
KW  - Convolutional Neural Networks (CNNs)
KW  - Object-Based Image Analysis (OBIA)
KW  - remote sensing
DO  - 10.3390/rs9121220
ER  -
TY  - EJOU
AU  - Suh, Jangwon
AU  - Kim, Sung-Min
AU  - Yi, Huiuk
AU  - Choi, Yosoon
TI  - An Overview of GIS-Based Modeling and Assessment of Mining-Induced Hazards: Soil, Water, and Forest
T2  - International Journal of Environmental Research and Public Health

PY  - 2017
VL  - 14
IS  - 12
SN  - 1660-4601

AB  - In this study, current geographic information system (GIS)-based methods and their application for the modeling and assessment of mining-induced hazards were reviewed. Various types of mining-induced hazard, including soil contamination, soil erosion, water pollution, and deforestation were considered in the discussion of the strength and role of GIS as a viable problem-solving tool in relation to mining-induced hazards. The various types of mining-induced hazard were classified into two or three subtopics according to the steps involved in the reclamation procedure, or elements of the hazard of interest. Because GIS is appropriated for the handling of geospatial data in relation to mining-induced hazards, the application and feasibility of exploiting GIS-based modeling and assessment of mining-induced hazards within the mining industry could be expanded further.
KW  - mine hazards
KW  - geographic information systems (GIS)
KW  - soil contamination
KW  - water pollution
KW  - deforestation
KW  - abandoned mine
DO  - 10.3390/ijerph14121463
ER  -
TY  - EJOU
AU  - Yu, Huai
AU  - Yang, Wen
AU  - Hua, Guang
AU  - Ru, Hui
AU  - Huang, Pingping
TI  - Change Detection Using High Resolution Remote Sensing Images Based on Active Learning and Markov Random Fields
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 12
SN  - 2072-4292

AB  - Change detection has been widely used in remote sensing, such as for disaster assessment and urban expansion detection. Although it is convenient to use unsupervised methods to detect changes from multi-temporal images, the results could be further improved. In supervised methods, heavy data labelling tasks are needed, and the sample annotation process with real categories is tedious and costly. To relieve the burden of labelling and to obtain satisfactory results, we propose an interactive change detection framework based on active learning and Markov random field (MRF). More specifically, a limited number of representative objects are found in an unsupervised way at the beginning. Then, the very limited samples are labelled as “change” or “no change” to train a simple binary classification model, i.e., a Gaussian process model. By using this model, we then select and label the most informative samples by “the easiest” sample selection strategy to update the former weak classification model until the detection results do not change notably. Finally, the maximum a posteriori (MAP) change detection is efficiently computed via the min-cut-based integer optimization algorithm. The time consuming and laborious manual labelling process can be reduced substantially, and a desirable detection result can be obtained. The experiments on several WorldView-2 images demonstrate the effectiveness of the proposed method.
KW  - high resolution remote sensing images
KW  - change detection
KW  - active learning
KW  - gaussian processes
KW  - Markov random fields
DO  - 10.3390/rs9121233
ER  -
TY  - EJOU
AU  - Chen, Suting
AU  - Li, Xin
AU  - Zhang, Yanyan
AU  - Feng, Rui
AU  - Zhang, Chuang
TI  - Local Deep Hashing Matching of Aerial Images Based on Relative Distance and Absolute Distance Constraints
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 12
SN  - 2072-4292

AB  - Aerial images have features of high resolution, complex background, and usually require large amounts of calculation, however, most algorithms used in matching of aerial images adopt the shallow hand-crafted features expressed as floating-point descriptors (e.g., SIFT (Scale-invariant Feature Transform), SURF (Speeded Up Robust Features)), which may suffer from poor matching speed and are not well represented in the literature. Here, we propose a novel Local Deep Hashing Matching (LDHM) method for matching of aerial images with large size and with lower complexity or fast matching speed. The basic idea of the proposed algorithm is to utilize the deep network model in the local area of the aerial images, and study the local features, as well as the hash function of the images. Firstly, according to the course overlap rate of aerial images, the algorithm extracts the local areas for matching to avoid the processing of redundant information. Secondly, a triplet network structure is proposed to mine the deep features of the patches of the local image, and the learned features are imported to the hash layer, thus obtaining the representation of a binary hash code. Thirdly, the constraints of the positive samples to the absolute distance are added on the basis of the triplet loss, a new objective function is constructed to optimize the parameters of the network and enhance the discriminating capabilities of image patch features. Finally, the obtained deep hash code of each image patch is used for the similarity comparison of the image patches in the Hamming space to complete the matching of aerial images. The proposed LDHM algorithm evaluates the UltraCam-D dataset and a set of actual aerial images, simulation result demonstrates that it may significantly outperform the state-of-the-art algorithm in terms of the efficiency and performance.
KW  - aerial matching
KW  - overlap rate
KW  - deep learning
KW  - local features
KW  - hash learning
KW  - absolute distance constraints
DO  - 10.3390/rs9121244
ER  -
TY  - EJOU
AU  - Castrignanò, Annamaria
AU  - Buttafuoco, Gabriele
AU  - Quarto, Ruggiero
AU  - Vitti, Carolina
AU  - Langella, Giuliano
AU  - Terribile, Fabio
AU  - Venezia, Accursio
TI  - A Combined Approach of Sensor Data Fusion and Multivariate Geostatistics for Delineation of Homogeneous Zones in an Agricultural Field
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 12
SN  - 1424-8220

AB  - To assess spatial variability at the very fine scale required by Precision Agriculture, different proximal and remote sensors have been used. They provide large amounts and different types of data which need to be combined. An integrated approach, using multivariate geostatistical data-fusion techniques and multi-source geophysical sensor data to determine simple summary scale-dependent indices, is described here. These indices can be used to delineate management zones to be submitted to differential management. Such a data fusion approach with geophysical sensors was applied in a soil of an agronomic field cropped with tomato. The synthetic regionalized factors determined, contributed to split the 3D edaphic environment into two main horizontal structures with different hydraulic properties and to disclose two main horizons in the 0–1.0-m depth with a discontinuity probably occurring between 0.40 m and 0.70 m. Comparing this partition with the soil properties measured with a shallow sampling, it was possible to verify the coherence in the topsoil between the dielectric properties and other properties more directly related to agronomic management. These results confirm the advantages of using proximal sensing as a preliminary step in the application of site-specific management. Combining disparate spatial data (data fusion) is not at all a naive problem and novel and powerful methods need to be developed.
KW  - spatial data
KW  - sensor
KW  - data fusion
KW  - change of support
KW  - geostatistics
KW  - precision agriculture
KW  - management zones
DO  - 10.3390/s17122794
ER  -
TY  - EJOU
AU  - Klosterman, Stephen
AU  - Richardson, Andrew D.
TI  - Observing Spring and Fall Phenology in a Deciduous Forest with Aerial Drone Imagery
T2  - Sensors

PY  - 2017
VL  - 17
IS  - 12
SN  - 1424-8220

AB  - Plant phenology is a sensitive indicator of the effects of global change on terrestrial ecosystems and controls the timing of key ecosystem functions including photosynthesis and transpiration. Aerial drone imagery and photogrammetric techniques promise to advance the study of phenology by enabling the creation of distortion-free orthomosaics of plant canopies at the landscape scale, but with branch-level image resolution. The main goal of this study is to determine the leaf life cycle events corresponding to phenological metrics derived from automated analyses based on color indices calculated from drone imagery. For an oak-dominated, temperate deciduous forest in the northeastern USA, we find that plant area index (PAI) correlates with a canopy greenness index during spring green-up, and a canopy redness index during autumn senescence. Additionally, greenness and redness metrics are significantly correlated with the timing of budburst and leaf expansion on individual trees in spring. However, we note that the specific color index for individual trees must be carefully chosen if new foliage in spring appears red, rather than green—which we observed for some oak trees. In autumn, both decreasing greenness and increasing redness correlate with leaf senescence. Maximum redness indicates the beginning of leaf fall, and the progression of leaf fall correlates with decreasing redness. We also find that cooler air temperature microclimates near a forest edge bordering a wetland advance the onset of senescence. These results demonstrate the use of drones for characterizing the organismic-level variability of phenology in a forested landscape and advance our understanding of which phenophase transitions correspond to color-based metrics derived from digital image analysis.
KW  - phenology
KW  - Harvard Forest
KW  - leaf color
KW  - plant area index
KW  - drone
KW  - UAV
DO  - 10.3390/s17122852
ER  -
TY  - EJOU
AU  - Nevalainen, Paavo
AU  - Salmivaara, Aura
AU  - Ala-Ilomäki, Jari
AU  - Launiainen, Samuli
AU  - Hiedanpää, Juuso
AU  - Finér, Leena
AU  - Pahikkala, Tapio
AU  - Heikkonen, Jukka
TI  - Estimating the Rut Depth by UAV Photogrammetry
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 12
SN  - 2072-4292

AB  - The rut formation during forest operations is an undesirable phenomenon. A methodology is being proposed to measure the rut depth distribution of a logging site by photogrammetric point clouds produced by unmanned aerial vehicles (UAV). The methodology includes five processing steps that aim at reducing the noise from the surrounding trees and undergrowth for identifying the trails. A canopy height model is produced to focus the point cloud on the open pathway around the forest machine trail. A triangularized ground model is formed by a point cloud filtering method. The ground model is vectorized using the histogram of directed curvatures (HOC) method to produce an overall ground visualization. Finally, a manual selection of the trails leads to an automated rut depth profile analysis. The bivariate correlation (Pearson’s r) between rut depths measured manually and by UAV photogrammetry is     r = 0.67    . The two-class accuracy a of detecting the rut depth exceeding 20 cm is     a = 0.65    . There is potential for enabling automated large-scale evaluation of the forestry areas by using autonomous drones and the process described.
KW  - micro-topography
KW  - forest harvesting
KW  - UAV
KW  - photogrammetry
KW  - micro-topography
KW  - point cloud
KW  - TIN
KW  - curvature
KW  - rut formation
DO  - 10.3390/rs9121279
ER  -
TY  - EJOU
AU  - Latif, Siddique
AU  - Qadir, Junaid
AU  - Farooq, Shahzad
AU  - Imran, Muhammad A.
TI  - How 5G Wireless (and Concomitant Technologies) Will Revolutionize Healthcare?
T2  - Future Internet

PY  - 2017
VL  - 9
IS  - 4
SN  - 1999-5903

AB  - The need to have equitable access to quality healthcare is enshrined in the United Nations (UN) Sustainable Development Goals (SDGs), which defines the developmental agenda of the UN for the next 15 years. In particular, the third SDG focuses on the need to “ensure healthy lives and promote well-being for all at all ages”. In this paper, we build the case that 5G wireless technology, along with concomitant emerging technologies (such as IoT, big data, artificial intelligence and machine learning), will transform global healthcare systems in the near future. Our optimism around 5G-enabled healthcare stems from a confluence of significant technical pushes that are already at play: apart from the availability of high-throughput low-latency wireless connectivity, other significant factors include the democratization of computing through cloud computing; the democratization of Artificial Intelligence (AI) and cognitive computing (e.g., IBM Watson); and the commoditization of data through crowdsourcing and digital exhaust. These technologies together can finally crack a dysfunctional healthcare system that has largely been impervious to technological innovations. We highlight the persistent deficiencies of the current healthcare system and then demonstrate how the 5G-enabled healthcare revolution can fix these deficiencies. We also highlight open technical research challenges, and potential pitfalls, that may hinder the development of such a 5G-enabled health revolution.
KW  - healthcare
KW  - 5G
KW  - Internet of Things
KW  - big data analytics
KW  - artificial intelligence and machine learning
DO  - 10.3390/fi9040093
ER  -
TY  - EJOU
AU  - Valiente, David
AU  - Gil, Arturo
AU  - Payá, Luis
AU  - Sebastián, Jose M.
AU  - Reinoso, Óscar
TI  - Robust Visual Localization with Dynamic Uncertainty Management in Omnidirectional SLAM
T2  - Applied Sciences

PY  - 2017
VL  - 7
IS  - 12
SN  - 2076-3417

AB  - This work presents a robust visual localization technique based on an omnidirectional monocular sensor for mobile robotics applications. We intend to overcome the non-linearities and instabilities that the camera projection systems typically introduce, which are especially relevant in catadioptric sensors. In this paper, we come up with several contributions. First, a novel strategy for the uncertainty management is developed, which accounts for a realistic visual localization technique, since it dynamically encodes the instantaneous variations and drifts on the uncertainty, by defining an information metric of the system. Secondly, an epipolar constraint adaption to the omnidirectional geometry reference is devised. Thirdly, Bayesian considerations are also implemented, in order to produce a final global metric for a consistent feature matching between images. The resulting outcomes are supported by real data experiments performed with publicly-available datasets, in order to assess the suitability of the approach and to confirm the reliability of the main contributions. Besides localization results, real visual SLAM (Simultaneous Localization and Mapping) comparison experiments with acknowledged methods are also presented, by using a public dataset and benchmark framework.
KW  - omnidirectional images
KW  - visual SLAM
KW  - visual localization
DO  - 10.3390/app7121294
ER  -
TY  - EJOU
AU  - Liang, Hui
AU  - Huang, Xiaodong
AU  - Sun, Yanhua
AU  - Wang, Yunlong
AU  - Liang, Tiangang
TI  - Fractional Snow-Cover Mapping Based on MODIS and UAV Data over the Tibetan Plateau
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 12
SN  - 2072-4292

AB  - Moderate-resolution imaging spectroradiometer (MODIS) snow-cover products have relatively low accuracy over the Tibetan Plateau because of its complex terrain and shallow, fragmented snow cover. In this study, fractional snow-cover (FSC) mapping algorithms were developed using a linear regression model (LR), a linear spectral mixture analysis model (LSMA) and a back-propagation artificial neural network model (BP-ANN) based on MODIS data (version 006) and unmanned aerial vehicle (UAV) data. The accuracies of the three models were validated against Landsat 8 Operational Land Imager (OLI) snow-cover maps (Landsat 8 FSC) and compared with the MODIS global FSC product (MOD10A1 FSC, version 005) for the purpose of finding the optimal algorithm for FSC extraction for the Tibetan Plateau. The results showed that (1) the overall retrieval results of the LR and BP-ANN models based on MODIS and UAV data were relatively similar to the OLI snow-cover maps; the accuracy and stability were greatly improved, with even some reduction in errors; compared to the Landsat 8 FSC, the correlation coefficients (r) were 0.8222 and 0.8445 respectively and the root-mean-square errors (RMSEs) were 0.2304 and 0.2201, respectively. (2) The accuracy and stability of the fully constrained LSMA model using the pixel purity index (PPI) endmember extraction method based only on MODIS data suffered the worst performance of the three models; r was only 0.7921 and the RMSE was as large as 0.3485. There were some serious omission phenomena in the study area, specifically for the largest mean absolute error (MAE = 0.2755) and positive mean error (PME = 0.3411). (3) The accuracy of the MOD10A1 FSC product was much lower than that of the LR and BP-ANN models, although its accuracy slightly better that of the LSMA based on comprehensive evaluation of six accuracy indices. (4) The optimal model was the BP-ANN model with combined inputs of surface reflectivity data (R1–R7), elevation (DEM) and temperature (LST), which can easily incorporate auxiliary information (DEM and LST) on the basis of (R1–R7) during the relationship training period and can effectively improve the accuracy of snow area monitoring—it is the ideal algorithm for retrieving FSC for the Tibetan Plateau.
KW  - fractional snow-cover
KW  - MODIS
KW  - UAV
KW  - Tibetan Plateau
DO  - 10.3390/rs9121332
ER  -
TY  - EJOU
AU  - Goldblatt, Ran
AU  - Rivera Ballesteros, Alexis
AU  - Burney, Jennifer
TI  - High Spatial Resolution Visual Band Imagery Outperforms Medium Resolution Spectral Imagery for Ecosystem Assessment in the Semi-Arid Brazilian Sertão
T2  - Remote Sensing

PY  - 2017
VL  - 9
IS  - 12
SN  - 2072-4292

AB  - Semi-arid ecosystems play a key role in global agricultural production, seasonal carbon cycle dynamics, and longer-run climate change. Because semi-arid landscapes are heterogeneous and often sparsely vegetated, repeated and large-scale ecosystem assessments of these regions have to date been impossible. Here, we assess the potential of high-spatial resolution visible band imagery for semi-arid ecosystem mapping. We use WorldView satellite imagery at 0.3–0.5 m resolution to develop a reference data set of nearly 10,000 labeled examples of three classes—trees, shrubs/grasses, and bare land—across 1000 km     2     of the semi-arid Sertão region of northeast Brazil. Using Google Earth Engine, we show that classification with low-spectral but high-spatial resolution input (WorldView) outperforms classification with the full spectral information available from Landsat 30 m resolution imagery as input. Classification with high spatial resolution input improves detection of sparse vegetation and distinction between trees and seasonal shrubs and grasses, two features which are lost at coarser spatial (but higher spectral) resolution input. Our total tree cover estimates for the study area disagree with recent estimates using other methods that may underestimate treecover because they confuse trees with seasonal vegetation (shrubs and grasses). This distinction is important for monitoring seasonal and long-run carbon cycle and ecosystem health. Our results suggest that newer remote sensing products that promise high frequency global coverage at high spatial but lower spectral resolution may offer new possibilities for direct monitoring of the world’s semi-arid ecosystems, and we provide methods that could be scaled to do so.
KW  - remote sensing
KW  - semi-arid
KW  - ecosystem assessment
KW  - land use change
KW  - image classification
KW  - seasonal vegetation
KW  - carbon cycle
KW  - Google Earth Engine
DO  - 10.3390/rs9121336
ER  -
TY  - EJOU
AU  - Thanh Noi, Phan
AU  - Kappas, Martin
TI  - Comparison of Random Forest, k-Nearest Neighbor, and Support Vector Machine Classifiers for Land Cover Classification Using Sentinel-2 Imagery
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 1
SN  - 1424-8220

AB  - In previous classification studies, three non-parametric classifiers, Random Forest (RF), k-Nearest Neighbor (kNN), and Support Vector Machine (SVM), were reported as the foremost classifiers at producing high accuracies. However, only a few studies have compared the performances of these classifiers with different training sample sizes for the same remote sensing images, particularly the Sentinel-2 Multispectral Imager (MSI). In this study, we examined and compared the performances of the RF, kNN, and SVM classifiers for land use/cover classification using Sentinel-2 image data. An area of 30 × 30 km2 within the Red River Delta of Vietnam with six land use/cover types was classified using 14 different training sample sizes, including balanced and imbalanced, from 50 to over 1250 pixels/class. All classification results showed a high overall accuracy (OA) ranging from 90% to 95%. Among the three classifiers and 14 sub-datasets, SVM produced the highest OA with the least sensitivity to the training sample sizes, followed consecutively by RF and kNN. In relation to the sample size, all three classifiers showed a similar and high OA (over 93.85%) when the training sample size was large enough, i.e., greater than 750 pixels/class or representing an area of approximately 0.25% of the total study area. The high accuracy was achieved with both imbalanced and balanced datasets.
KW  - Sentinel-2
KW  - Random Forest (RF)
KW  - Support Vector Machine (SVM)
KW  - k-Nearest Neighbor (kNN)
KW  - classification algorithms
KW  - training sample size
DO  - 10.3390/s18010018
ER  -
TY  - EJOU
AU  - Chen, Weitao
AU  - Li, Xianju
AU  - He, Haixia
AU  - Wang, Lizhe
TI  - A Review of Fine-Scale Land Use and Land Cover Classification in Open-Pit Mining Areas by Remote Sensing Techniques
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 1
SN  - 2072-4292

AB  - Over recent decades, fine-scale land use and land cover classification in open-pit mine areas (LCCMA) has become very important for understanding the influence of mining activities on the regional geo-environment, and for environmental impact assessment procedure. This research reviews advances in fine-scale LCCMA from the following aspects. Firstly, it analyzes and proposes classification thematic resolution for LCCMA. Secondly, remote sensing data sources, features, feature selection methods, and classification algorithms for LCCMA are summarized. Thirdly, three major factors that affect LCCMA are discussed: significant three-dimensional terrain features, strong LCCMA feature variability, and homogeneity of spectral-spatial features. Correspondingly, three key scientific issues that limit the accuracy of LCCMA are presented. Finally, several future research directions are discussed: (1) unitization of new sensors, particularly those with stereo survey ability; (2) procurement of sensitive features by new sensors and combinations of sensitive features using novel feature selection methods; (3) development of robust and self-adjusted classification algorithms, such as ensemble learning and deep learning for LCCMA; and (4) application of fine-scale mining information for regularity and management of mines.
KW  - land cover classification
KW  - open-pit mining area
KW  - remote sensing
KW  - review
KW  - fine-scale
DO  - 10.3390/rs10010015
ER  -
TY  - EJOU
AU  - Kim, Byeong H.
AU  - Kim, Min Y.
AU  - Chae, You S.
TI  - Background Registration-Based Adaptive Noise Filtering of LWIR/MWIR Imaging Sensors for UAV Applications
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 1
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) are equipped with optical systems including an infrared (IR) camera such as electro-optical IR (EO/IR), target acquisition and designation sights (TADS), or forward looking IR (FLIR). However, images obtained from IR cameras are subject to noise such as dead pixels, lines, and fixed pattern noise. Nonuniformity correction (NUC) is a widely employed method to reduce noise in IR images, but it has limitations in removing noise that occurs during operation. Methods have been proposed to overcome the limitations of the NUC method, such as two-point correction (TPC) and scene-based NUC (SBNUC). However, these methods still suffer from unfixed pattern noise. In this paper, a background registration-based adaptive noise filtering (BRANF) method is proposed to overcome the limitations of conventional methods. The proposed BRANF method utilizes background registration processing and robust principle component analysis (RPCA). In addition, image quality verification methods are proposed that can measure the noise filtering performance quantitatively without ground truth images. Experiments were performed for performance verification with middle wave infrared (MWIR) and long wave infrared (LWIR) images obtained from practical military optical systems. As a result, it is found that the image quality improvement rate of BRANF is 30% higher than that of conventional NUC.
KW  - UAV
KW  - LWIR/MWIR
KW  - FLIR
KW  - TADS
KW  - NUC
KW  - adaptive filtering
KW  - image quality evaluation
DO  - 10.3390/s18010060
ER  -
TY  - EJOU
AU  - Ji, Shunping
AU  - Zhang, Chi
AU  - Xu, Anjian
AU  - Shi, Yun
AU  - Duan, Yulin
TI  - 3D Convolutional Neural Networks for Crop Classification with Multi-Temporal Remote Sensing Images
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 1
SN  - 2072-4292

AB  - This study describes a novel three-dimensional (3D) convolutional neural networks (CNN) based method that automatically classifies crops from spatio-temporal remote sensing images. First, 3D kernel is designed according to the structure of multi-spectral multi-temporal remote sensing data. Secondly, the 3D CNN framework with fine-tuned parameters is designed for training 3D crop samples and learning spatio-temporal discriminative representations, with the full crop growth cycles being preserved. In addition, we introduce an active learning strategy to the CNN model to improve labelling accuracy up to a required threshold with the most efficiency. Finally, experiments are carried out to test the advantage of the 3D CNN, in comparison to the two-dimensional (2D) CNN and other conventional methods. Our experiments show that the 3D CNN is especially suitable in characterizing the dynamics of crop growth and outperformed the other mainstream methods.
KW  - 3D convolution
KW  - convolutional neural networks
KW  - crop classification
KW  - multi-temporal remote sensing images
KW  - active learning
DO  - 10.3390/rs10010075
ER  -
TY  - EJOU
AU  - Li, Hongguang
AU  - Shi, Yang
AU  - Zhang, Baochang
AU  - Wang, Yufeng
TI  - Superpixel-Based Feature for Aerial Image Scene Recognition
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 1
SN  - 1424-8220

AB  - Image scene recognition is a core technology for many aerial remote sensing applications. Different landforms are inputted as different scenes in aerial imaging, and all landform information is regarded as valuable for aerial image scene recognition. However, the conventional features of the Bag-of-Words model are designed using local points or other related information and thus are unable to fully describe landform areas. This limitation cannot be ignored when the aim is to ensure accurate aerial scene recognition. A novel superpixel-based feature is proposed in this study to characterize aerial image scenes. Then, based on the proposed feature, a scene recognition method of the Bag-of-Words model for aerial imaging is designed. The proposed superpixel-based feature that utilizes landform information establishes top-task superpixel extraction of landforms to bottom-task expression of feature vectors. This characterization technique comprises the following steps: simple linear iterative clustering based superpixel segmentation, adaptive filter bank construction, Lie group-based feature quantification, and visual saliency model-based feature weighting. Experiments of image scene recognition are carried out using real image data captured by an unmanned aerial vehicle (UAV). The recognition accuracy of the proposed superpixel-based feature is 95.1%, which is higher than those of scene recognition algorithms based on other local features.
KW  - superpixel-based feature
KW  - image scene recognition
KW  - aerial remote sensing
DO  - 10.3390/s18010156
ER  -
TY  - EJOU
AU  - Shah, Namin
AU  - Czarkowski, Dariusz
TI  - Supercapacitors in Tandem with Batteries to Prolong the Range of UGV Systems
T2  - Electronics

PY  - 2018
VL  - 7
IS  - 1
SN  - 2079-9292

AB  - The purpose of this study was to explore a novel approach to power hybridization in relation to its effectiveness in an unmanned ground vehicle (UGV). This hybridization method is modeled after the power distribution methods found in living organisms, which utilize glycogen stores and adipose tissue to optimize power and energy density strengths and weaknesses. A UGV rover was constructed with an appropriate distribution of power storage elements creating separate power buffers. The primary buffer consisted of a 10 W solar panel array and a 600 F, 5.4 V supercapacitor bank, and the secondary buffer consisted of a 3.7 V 6 Ah lithium-ion battery pack. The primary buffer provided virtually limitless charge cycles with a superior power density juxtaposed with a secondary buffer that provided superior energy density and volumetric versatility. The design of this rover is presented in this paper; it was tested under manual and autonomous modes. The rover was found to be capable of effectively operating solely on the primary power buffer in high to low luminous conditions while being able to carry out basic extravehicular activities. The rover could travel roughly 22 km without any input power on a full charge of both buffers, and could smoothly switch between its own power buffers during operation, all while transmitting live first person video (FPV) and network data. The introduction of control algorithms on the onboard microcontroller unit (MCU) was also explored in both manual and autonomous configurations. The latter integrated linear regression to intelligently manage power and locomotion based on sensory data from photoresistors.
KW  - supercapacitors
KW  - hybridization
KW  - rover
KW  - machine-learning
KW  - perturb-and-observe
KW  - solar
KW  - lithium-ion
KW  - Internet-of-Things
KW  - exploration
KW  - unmanned-ground-vehicle
DO  - 10.3390/electronics7010006
ER  -
TY  - EJOU
AU  - Li, Bo
AU  - Lecourt, Julien
AU  - Bishop, Gerard
TI  - Advances in Non-Destructive Early Assessment of Fruit Ripeness towards Defining Optimal Time of Harvest and Yield Prediction—A Review
T2  - Plants

PY  - 2018
VL  - 7
IS  - 1
SN  - 2223-7747

AB  - Global food security for the increasing world population not only requires increased sustainable production of food but a significant reduction in pre- and post-harvest waste. The timing of when a fruit is harvested is critical for reducing waste along the supply chain and increasing fruit quality for consumers. The early in-field assessment of fruit ripeness and prediction of the harvest date and yield by non-destructive technologies have the potential to revolutionize farming practices and enable the consumer to eat the tastiest and freshest fruit possible. A variety of non-destructive techniques have been applied to estimate the ripeness or maturity but not all of them are applicable for in situ (field or glasshouse) assessment. This review focuses on the non-destructive methods which are promising for, or have already been applied to, the pre-harvest in-field measurements including colorimetry, visible imaging, spectroscopy and spectroscopic imaging. Machine learning and regression models used in assessing ripeness are also discussed.
KW  - pre-harvest
KW  - ripeness
KW  - image analysis
KW  - machine learning
KW  - fruit phenotyping
DO  - 10.3390/plants7010003
ER  -
TY  - EJOU
AU  - Berger, Katja
AU  - Atzberger, Clement
AU  - Danner, Martin
AU  - D’Urso, Guido
AU  - Mauser, Wolfram
AU  - Vuolo, Francesco
AU  - Hank, Tobias
TI  - Evaluation of the PROSAIL Model Capabilities for Future Hyperspectral Model Environments: A Review Study
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 1
SN  - 2072-4292

AB  - Upcoming satellite hyperspectral sensors require powerful and robust methodologies for making optimum use of the rich spectral data. This paper reviews the widely applied coupled PROSPECT and SAIL radiative transfer models (PROSAIL), regarding their suitability for the retrieval of biophysical and biochemical variables in the context of agricultural crop monitoring. Evaluation was carried out using a systematic literature review of 281 scientific publications with regard to their (i) spectral exploitation, (ii) vegetation type analyzed, (iii) variables retrieved, and (iv) choice of retrieval methods. From the analysis, current trends were derived, and problems identified and discussed. Our analysis clearly shows that the PROSAIL model is well suited for the analysis of imaging spectrometer data from future satellite missions and that the model should be integrated in appropriate software tools that are being developed in this context for agricultural applications. The review supports the decision of potential users to employ PROSAIL for their specific data analysis and provides guidelines for choosing between the diverse retrieval techniques.
KW  - PROSAIL
KW  - biophysical and biochemical variables
KW  - EnMAP sensor
KW  - model inversion
KW  - hyperspectral
KW  - leaf area index (LAI)
KW  - radiative transfer model
DO  - 10.3390/rs10010085
ER  -
TY  - EJOU
AU  - Kim, Sungho
AU  - Song, Woo-Jin
AU  - Kim, So-Hyun
TI  - Double Weight-Based SAR and Infrared Sensor Fusion for Automatic Ground Target Recognition with Deep Learning
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 1
SN  - 2072-4292

AB  - This paper presents a novel double weight-based synthetic aperture radar (SAR) and infrared (IR) sensor fusion method (DW-SIF) for automatic ground target recognition (ATR). IR-based ATR can provide accurate recognition because of its high image resolution but it is affected by the weather conditions. On the other hand, SAR-based ATR shows a low recognition rate due to the noisy low resolution but can provide consistent performance regardless of the weather conditions. The fusion of an active sensor (SAR) and a passive sensor (IR) can lead to upgraded performance. This paper proposes a doubly weighted neural network fusion scheme at the decision level. The first weight (   α   ) can measure the offline sensor confidence per target category based on the classification rate for an evaluation set. The second weight (   β   ) can measure the online sensor reliability based on the score distribution for a test target image. The LeNet architecture-based deep convolution network (14 layers) is used as an individual classifier. Doubly weighted sensor scores are fused by two types of fusion schemes, such as the sum-based linear fusion scheme (    α β    -sum) and neural network-based nonlinear fusion scheme (    α β    -NN). The experimental results confirmed the proposed linear fusion method (    α β    -sum) to have the best performance among the linear fusion schemes available (SAR-CNN, IR-CNN,    α   -sum,    β   -sum,     α β    -sum, and Bayesian fusion). In addition, the proposed nonlinear fusion method (    α β    -NN) showed superior target recognition performance to linear fusion on the OKTAL-SE-based synthetic database.
KW  - SAR
KW  - IR
KW  - fusion
KW  - double weights
KW  - linear
KW  - nonlinear
KW  - deep learning
KW  - OKTAL-SE
DO  - 10.3390/rs10010072
ER  -
TY  - EJOU
AU  - Cao, Jingjing
AU  - Leng, Wanchun
AU  - Liu, Kai
AU  - Liu, Lin
AU  - He, Zhi
AU  - Zhu, Yuanhui
TI  - Object-Based Mangrove Species Classification Using Unmanned Aerial Vehicle Hyperspectral Images and Digital Surface Models
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 1
SN  - 2072-4292

AB  - Mangroves are one of the most important coastal wetland ecosystems, and the compositions and distributions of mangrove species are essential for conservation and restoration efforts. Many studies have explored this topic using remote sensing images that were obtained by satellite-borne and airborne sensors, which are known to be efficient for monitoring the mangrove ecosystem. With improvements in carrier platforms and sensor technology, unmanned aerial vehicles (UAVs) with high-resolution hyperspectral images in both spectral and spatial domains have been used to monitor crops, forests, and other landscapes of interest. This study aims to classify mangrove species on Qi’ao Island using object-based image analysis techniques based on UAV hyperspectral images obtained from a commercial hyperspectral imaging sensor (UHD 185) onboard a UAV platform. First, the image objects were obtained by segmenting the UAV hyperspectral image and the UAV-derived digital surface model (DSM) data. Second, spectral features, textural features, and vegetation indices (VIs) were extracted from the UAV hyperspectral image, and the UAV-derived DSM data were used to extract height information. Third, the classification and regression tree (CART) method was used to selection bands, and the correlation-based feature selection (CFS) algorithm was employed for feature reduction. Finally, the objects were classified into different mangrove species and other land covers based on their spectral and spatial characteristic differences. The classification results showed that when considering the three features (spectral features, textural features, and hyperspectral VIs), the overall classification accuracies of the two classifiers used in this paper, i.e., k-nearest neighbor (KNN) and support vector machine (SVM), were 76.12% (Kappa = 0.73) and 82.39% (Kappa = 0.801), respectively. After incorporating tree height into the classification features, the accuracy of species classification increased, and the overall classification accuracies of KNN and SVM reached 82.09% (Kappa = 0.797) and 88.66% (Kappa = 0.871), respectively. It is clear that SVM outperformed KNN for mangrove species classification. These results also suggest that height information is effective for discriminating mangrove species with similar spectral signatures, but different heights. In addition, the classification accuracy and performance of SVM can be further improved by feature reduction. The overall results provided evidence for the effectiveness and potential of UAV hyperspectral data for mangrove species identification.
KW  - mangrove species classification
KW  - unmanned aerial vehicle (UAV)
KW  - hyperspectral remote sensing
KW  - object-based image analysis (OBIA)
KW  - tree height
DO  - 10.3390/rs10010089
ER  -
TY  - EJOU
AU  - Qu, Yufu
AU  - Huang, Jianyu
AU  - Zhang, Xuan
TI  - Rapid 3D Reconstruction for Image Sequence Acquired from UAV Camera
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 1
SN  - 1424-8220

AB  - In order to reconstruct three-dimensional (3D) structures from an image sequence captured by unmanned aerial vehicles’ camera (UAVs) and improve the processing speed, we propose a rapid 3D reconstruction method that is based on an image queue, considering the continuity and relevance of UAV camera images. The proposed approach first compresses the feature points of each image into three principal component points by using the principal component analysis method. In order to select the key images suitable for 3D reconstruction, the principal component points are used to estimate the interrelationships between images. Second, these key images are inserted into a fixed-length image queue. The positions and orientations of the images are calculated, and the 3D coordinates of the feature points are estimated using weighted bundle adjustment. With this structural information, the depth maps of these images can be calculated. Next, we update the image queue by deleting some of the old images and inserting some new images into the queue, and a structural calculation of all the images can be performed by repeating the previous steps. Finally, a dense 3D point cloud can be obtained using the depth–map fusion method. The experimental results indicate that when the texture of the images is complex and the number of images exceeds 100, the proposed method can improve the calculation speed by more than a factor of four with almost no loss of precision. Furthermore, as the number of images increases, the improvement in the calculation speed will become more noticeable.
KW  - UAV camera
KW  - multi-view stereo
KW  - structure from motion
KW  - 3D reconstruction
KW  - point cloud
DO  - 10.3390/s18010225
ER  -
TY  - EJOU
AU  - Nguyen, Chuyen
AU  - Starek, Michael J.
AU  - Tissot, Philippe
AU  - Gibeaut, James
TI  - Unsupervised Clustering Method for Complexity Reduction of Terrestrial Lidar Data in Marshes
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 1
SN  - 2072-4292

AB  - Accurate characterization of marsh elevation and landcover evolution is important for coastal management and conservation. This research proposes a novel unsupervised clustering method specifically developed for segmenting dense terrestrial laser scanning (TLS) data in coastal marsh environments. The framework implements unsupervised clustering with the well-known K-means algorithm by applying an optimization to determine the “k” clusters. The fundamental idea behind this novel framework is the application of multi-scale voxel representation of 3D space to create a set of features that characterizes the local complexity and geometry of the terrain. A combination of point- and voxel-generated features are utilized to segment 3D point clouds into homogenous groups in order to study surface changes and vegetation cover. Results suggest that the combination of point and voxel features represent the dataset well. The developed method compresses millions of 3D points representing the complex marsh environment into eight distinct clusters representing different landcover: tidal flat, mangrove, low marsh to high marsh, upland, and power lines. A quantitative assessment of the automated delineation of the tidal flat areas shows acceptable results considering the proposed method is unsupervised with no training data. Clustering results based on K-means are also compared to results based on the Self Organizing Map (SOM) clustering algorithm. Results demonstrate that the developed multi-scale voxelization approach and representative feature set are transferrable to other clustering algorithms, thereby providing an unsupervised framework for intelligent scene segmentation of TLS point cloud data in marshes.
KW  - terrestrial lidar
KW  - voxelization
KW  - clustering
KW  - marsh
KW  - K-means
KW  - SOM
DO  - 10.3390/rs10010133
ER  -
TY  - EJOU
AU  - Mahabir, Ron
AU  - Croitoru, Arie
AU  - Crooks, Andrew T.
AU  - Agouris, Peggy
AU  - Stefanidis, Anthony
TI  - A Critical Review of High and Very High-Resolution Remote Sensing Approaches for Detecting and Mapping Slums: Trends, Challenges and Emerging Opportunities
T2  - Urban Science

PY  - 2018
VL  - 2
IS  - 1
SN  - 2413-8851

AB  - Slums are a global urban challenge, with less developed countries being particularly impacted. To adequately detect and map them, data is needed on their location, spatial extent and evolution. High- and very high-resolution remote sensing imagery has emerged as an important source of data in this regard. The purpose of this paper is to critically review studies that have used such data to detect and map slums. Our analysis shows that while such studies have been increasing over time, they tend to be concentrated to a few geographical areas and often focus on the use of a single approach (e.g., image texture and object-based image analysis), thus limiting generalizability to understand slums, their population, and evolution within the global context. We argue that to develop a more comprehensive framework that can be used to detect and map slums, other emerging sourcing of geospatial data should be considered (e.g., volunteer geographic information) in conjunction with growing trends and advancements in technology (e.g., geosensor networks). Through such data integration and analysis we can then create a benchmark for determining the most suitable methods for mapping slums in a given locality, thus fostering the creation of new approaches to address this challenge.
KW  - high-and very high-resolution imagery
KW  - remote sensing
KW  - slums
KW  - volunteer geographic information
KW  - geosensor networks
KW  - image analysis
DO  - 10.3390/urbansci2010008
ER  -
TY  - EJOU
AU  - Feng, Yu
AU  - Sester, Monika
TI  - Extraction of Pluvial Flood Relevant Volunteered Geographic Information (VGI) by Deep Learning from User Generated Texts and Photos
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 2
SN  - 2220-9964

AB  - In recent years, pluvial floods caused by extreme rainfall events have occurred frequently. Especially in urban areas, they lead to serious damages and endanger the citizens’ safety. Therefore, real-time information about such events is desirable. With the increasing popularity of social media platforms, such as Twitter or Instagram, information provided by voluntary users becomes a valuable source for emergency response. Many applications have been built for disaster detection and flood mapping using crowdsourcing. Most of the applications so far have merely used keyword filtering or classical language processing methods to identify disaster relevant documents based on user generated texts. As the reliability of social media information is often under criticism, the precision of information retrieval plays a significant role for further analyses. Thus, in this paper, high quality eyewitnesses of rainfall and flooding events are retrieved from social media by applying deep learning approaches on user generated texts and photos. Subsequently, events are detected through spatiotemporal clustering and visualized together with these high quality eyewitnesses in a web map application. Analyses and case studies are conducted during flooding events in Paris, London and Berlin.
KW  - social media
KW  - crowdsourcing
KW  - volunteered geographic information
KW  - multimedia information retrieval
KW  - convolutional neural network
KW  - transfer learning
KW  - word embedding
KW  - flood mapping
DO  - 10.3390/ijgi7020039
ER  -
TY  - EJOU
AU  - Axelsson, Arvid
AU  - Lindberg, Eva
AU  - Olsson, Håkan
TI  - Exploring Multispectral ALS Data for Tree Species Classification
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 2
SN  - 2072-4292

AB  - Multispectral Airborne Laser Scanning (ALS) is a new technology and its output data have not been fully explored for tree species classification purposes. The objective of this study was to investigate what type of features from multispectral ALS data (wavelengths of 1550 nm, 1064 nm and 532 nm) are best suited for tree species classification. Remote sensing data were gathered over hemi-boreal forest in southern Sweden (58°27′18.35″N, 13°39′8.03″E) on 21 July 2016. The field data consisted of 179 solitary trees from nine genera and ten species. Two new methods for feature extraction were tested and compared to features of height and intensity distributions. The features that were most important for tree species classification were intensity distribution features. Features from the upper part of the upper and outer parts of the crown were better for classification purposes than others. The best classification model was created using distribution features of both intensity and height in multispectral data, with a leave-one-out cross-validated accuracy of 76.5%. As a comparison, only structural features resulted in an highest accuracy of 43.0%. Picea abies and Pinus sylvestris had high user’s and producer’s accuracies and were not confused with any deciduous species. Tilia cordata was the deciduous species with a large sample that was most frequently confused with many other deciduous species. The results, although based on a small and special data set, suggest that multispectral ALS is a technology with great potential for tree species classification.
KW  - LiDAR
KW  - indvidual trees
KW  - ITC
KW  - spectral
DO  - 10.3390/rs10020183
ER  -
TY  - EJOU
AU  - Loggenberg, Kyle
AU  - Strever, Albert
AU  - Greyling, Berno
AU  - Poona, Nitesh
TI  - Modelling Water Stress in a Shiraz Vineyard Using Hyperspectral Imaging and Machine Learning
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 2
SN  - 2072-4292

AB  - The detection of water stress in vineyards plays an integral role in the sustainability of high-quality grapes and prevention of devastating crop loses. Hyperspectral remote sensing technologies combined with machine learning provides a practical means for modelling vineyard water stress. In this study, we applied two ensemble learners, i.e., random forest (RF) and extreme gradient boosting (XGBoost), for discriminating stressed and non-stressed Shiraz vines using terrestrial hyperspectral imaging. Additionally, we evaluated the utility of a spectral subset of wavebands, derived using RF mean decrease accuracy (MDA) and XGBoost gain. Our results show that both ensemble learners can effectively analyse the hyperspectral data. When using all wavebands (p = 176), RF produced a test accuracy of 83.3% (KHAT (kappa analysis) = 0.67), and XGBoost a test accuracy of 80.0% (KHAT = 0.6). Using the subset of wavebands (p = 18) produced slight increases in accuracy ranging from 1.7% to 5.5% for both RF and XGBoost. We further investigated the effect of smoothing the spectral data using the Savitzky-Golay filter. The results indicated that the Savitzky-Golay filter reduced model accuracies (ranging from 0.7% to 3.3%). The results demonstrate the feasibility of terrestrial hyperspectral imagery and machine learning to create a semi-automated framework for vineyard water stress modelling.
KW  - terrestrial hyperspectral imaging
KW  - vineyard
KW  - water stress
KW  - machine learning
KW  - tree-based ensemble
DO  - 10.3390/rs10020202
ER  -
TY  - EJOU
AU  - Behmann, Jan
AU  - Acebron, Kelvin
AU  - Emin, Dzhaner
AU  - Bennertz, Simon
AU  - Matsubara, Shizue
AU  - Thomas, Stefan
AU  - Bohnenkamp, David
AU  - Kuska, Matheus T.
AU  - Jussila, Jouni
AU  - Salo, Harri
AU  - Mahlein, Anne-Katrin
AU  - Rascher, Uwe
TI  - Specim IQ: Evaluation of a New, Miniaturized Handheld Hyperspectral Camera and Its Application for Plant Phenotyping and Disease Detection
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 2
SN  - 1424-8220

AB  - Hyperspectral imaging sensors are promising tools for monitoring crop plants or vegetation in different environments. Information on physiology, architecture or biochemistry of plants can be assessed non-invasively and on different scales. For instance, hyperspectral sensors are implemented for stress detection in plant phenotyping processes or in precision agriculture. Up to date, a variety of non-imaging and imaging hyperspectral sensors is available. The measuring process and the handling of most of these sensors is rather complex. Thus, during the last years the demand for sensors with easy user operability arose. The present study introduces the novel hyperspectral camera Specim IQ from Specim (Oulu, Finland). The Specim IQ is a handheld push broom system with integrated operating system and controls. Basic data handling and data analysis processes, such as pre-processing and classification routines are implemented within the camera software. This study provides an introduction into the measurement pipeline of the Specim IQ as well as a radiometric performance comparison with a well-established hyperspectral imager. Case studies for the detection of powdery mildew on barley at the canopy scale and the spectral characterization of Arabidopsis thaliana mutants grown under stressed and non-stressed conditions are presented.
KW  - hyperspectral camera
KW  - handheld
KW  - sensor evaluation
KW  - case studies
DO  - 10.3390/s18020441
ER  -
TY  - EJOU
AU  - Torres-Sospedra, Joaquín
AU  - Jiménez, Antonio R.
AU  - Moreira, Adriano
AU  - Lungenstrass, Tomás
AU  - Lu, Wei-Chung
AU  - Knauth, Stefan
AU  - Mendoza-Silva, Germán M.
AU  - Seco, Fernando
AU  - Pérez-Navarro, Antoni
AU  - Nicolau, Maria J.
AU  - Costa, António
AU  - Meneses, Filipe
AU  - Farina, Joaquín
AU  - Morales, Juan P.
AU  - Lu, Wen-Chen
AU  - Cheng, Ho-Ti
AU  - Yang, Shi-Shen
AU  - Fang, Shih-Hau
AU  - Chien, Ying-Ren
AU  - Tsao, Yu
TI  - Off-Line Evaluation of Mobile-Centric Indoor Positioning Systems: The Experiences from the 2017 IPIN Competition
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 2
SN  - 1424-8220

AB  - The development of indoor positioning solutions using smartphones is a growing activity with an enormous potential for everyday life and professional applications. The research activities on this topic concentrate on the development of new positioning solutions that are tested in specific environments under their own evaluation metrics. To explore the real positioning quality of smartphone-based solutions and their capabilities for seamlessly adapting to different scenarios, it is needed to find fair evaluation frameworks. The design of competitions using extensive pre-recorded datasets is a valid way to generate open data for comparing the different solutions created by research teams. In this paper, we discuss the details of the 2017 IPIN indoor localization competition, the different datasets created, the teams participating in the event, and the results they obtained. We compare these results with other competition-based approaches (Microsoft and Perf-loc) and on-line evaluation web sites. The lessons learned by organising these competitions and the benefits for the community are addressed along the paper. Our analysis paves the way for future developments on the standardization of evaluations and for creating a widely-adopted benchmark strategy for researchers and companies in the field.
KW  - indoor positioning and navigation
KW  - Wi-Fi fingerprinting
KW  - sensor fusion
KW  - competitions
KW  - benchmarking
DO  - 10.3390/s18020487
ER  -
TY  - EJOU
AU  - Uddin, Mohammad Ammad
AU  - Mansour, Ali
AU  - Jeune, Denis Le
AU  - Ayaz, Mohammad
AU  - Aggoune, El-Hadi M.
TI  - UAV-Assisted Dynamic Clustering of Wireless Sensor Networks for Crop Health Monitoring
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 2
SN  - 1424-8220

AB  - In this study, a crop health monitoring system is developed by using state of the art technologies including wireless sensors and Unmanned Aerial Vehicles (UAVs). Conventionally data is collected from sensor nodes either by fixed base stations or mobile sinks. Mobile sinks are considered a better choice nowadays due to their improved network coverage and energy utilization. Usually, the mobile sink is used in two ways: either it goes for random walk to find the scattered nodes and collect data, or follows a pre-defined path established by the ground network/clusters. Neither of these options is suitable in our scenario due to the factors like dynamic data collection, the strict targeted area required to be scanned, unavailability of a large number of nodes, dynamic path of the UAV, and most importantly, none of these are known in advance. The contribution of this paper is the formation of dynamic runtime clusters of field sensors by considering the above mentioned factors. Furthermore a mechanism (Bayesian classifier) is defined to select best node as cluster head. The proposed system is validated through simulation results, lab and infield experiments using concept devices. The obtained results are encouraging, especially in terms of deployment time, energy, efficiency, throughput and ease of use.
KW  - dynamic clustering
KW  - cluster head selection
KW  - IoT for agriculture
KW  - UAVs for agriculture
DO  - 10.3390/s18020555
ER  -
TY  - EJOU
AU  - De Castro, Ana I.
AU  - Torres-Sánchez, Jorge
AU  - Peña, Jose M.
AU  - Jiménez-Brenes, Francisco M.
AU  - Csillik, Ovidiu
AU  - López-Granados, Francisca
TI  - An Automatic Random Forest-OBIA Algorithm for Early Weed Mapping between and within Crop Rows Using UAV Imagery
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 2
SN  - 2072-4292

AB  - Accurate and timely detection of weeds between and within crop rows in the early growth stage is considered one of the main challenges in site-specific weed management (SSWM). In this context, a robust and innovative automatic object-based image analysis (OBIA) algorithm was developed on Unmanned Aerial Vehicle (UAV) images to design early post-emergence prescription maps. This novel algorithm makes the major contribution. The OBIA algorithm combined Digital Surface Models (DSMs), orthomosaics and machine learning techniques (Random Forest, RF). OBIA-based plant heights were accurately estimated and used as a feature in the automatic sample selection by the RF classifier; this was the second research contribution. RF randomly selected a class balanced training set, obtained the optimum features values and classified the image, requiring no manual training, making this procedure time-efficient and more accurate, since it removes errors due to a subjective manual task. The ability to discriminate weeds was significantly affected by the imagery spatial resolution and weed density, making the use of higher spatial resolution images more suitable. Finally, prescription maps for in-season post-emergence SSWM were created based on the weed maps—the third research contribution—which could help farmers in decision-making to optimize crop management by rationalization of the herbicide application. The short time involved in the process (image capture and analysis) would allow timely weed control during critical periods, crucial for preventing yield loss.
KW  - Digital Surface Model
KW  - segmentation
KW  - precision agriculture
KW  - in-season post-emergence site-specific weed control
KW  - plant height
DO  - 10.3390/rs10020285
ER  -
TY  - EJOU
AU  - Mueller, Markus S.
AU  - Jutzi, Boris
TI  - UAS Navigation with SqueezePoseNet—Accuracy Boosting for Pose Regression by Data Augmentation
T2  - Drones

PY  - 2018
VL  - 2
IS  - 1
SN  - 2504-446X

AB  - The navigation of Unmanned Aerial Vehicles (UAVs) nowadays is mostly based on Global Navigation Satellite Systems (GNSSs). Drawbacks of satellite-based navigation are failures caused by occlusions or multi-path interferences. Therefore, alternative methods have been developed in recent years. Visual navigation methods such as Visual Odometry (VO) or visual Simultaneous Localization and Mapping (SLAM) aid global navigation solutions by closing trajectory gaps or performing loop closures. However, if the trajectory estimation is interrupted or not available, a re-localization is mandatory. Furthermore, the latest research has shown promising results on pose regression in 6 Degrees of Freedom (DoF) based on Convolutional Neural Networks (CNNs). Additionally, existing navigation methods can benefit from these networks. In this article, a method for GNSS-free and fast image-based pose regression by utilizing a small Convolutional Neural Network is presented. Therefore, a small CNN (SqueezePoseNet) is utilized, transfer learning is applied and the network is tuned for pose regression. Furthermore, recent drawbacks are overcome by applying data augmentation on a training dataset utilizing simulated images. Experiments with small CNNs show promising results for GNSS-free and fast localization compared to larger networks. By training a CNN with an extended data set including simulated images, the accuracy on pose regression is improved up to 61.7% for position and up to 76.0% for rotation compared to training on a standard not-augmented data set.
KW  - convolutional neural networks
KW  - data augmentation
KW  - image-based navigation
KW  - pose estimation
DO  - 10.3390/drones2010007
ER  -
TY  - EJOU
AU  - Sherwin, Tyrone
AU  - Easte, Mikala
AU  - Chen, Andrew T.
AU  - Wang, Kevin I.
AU  - Dai, Wenbin
TI  - A Single RF Emitter-Based Indoor Navigation Method for Autonomous Service Robots
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 2
SN  - 1424-8220

AB  - Location-aware services are one of the key elements of modern intelligent applications. Numerous real-world applications such as factory automation, indoor delivery, and even search and rescue scenarios require autonomous robots to have the ability to navigate in an unknown environment and reach mobile targets with minimal or no prior infrastructure deployment. This research investigates and proposes a novel approach of dynamic target localisation using a single RF emitter, which will be used as the basis of allowing autonomous robots to navigate towards and reach a target. Through the use of multiple directional antennae, Received Signal Strength (RSS) is compared to determine the most probable direction of the targeted emitter, which is combined with the distance estimates to improve the localisation performance. The accuracy of the position estimate is further improved using a particle filter to mitigate the fluctuating nature of real-time RSS data. Based on the direction information, a motion control algorithm is proposed, using Simultaneous Localisation and Mapping (SLAM) and A* path planning to enable navigation through unknown complex environments. A number of navigation scenarios were developed in the context of factory automation applications to demonstrate and evaluate the functionality and performance of the proposed system.
KW  - autonomous service robots
KW  - industrial automation
KW  - indoor localisation
KW  - robot localisation
KW  - automated mapping
DO  - 10.3390/s18020585
ER  -
TY  - EJOU
AU  - Sandino, Juan
AU  - Gonzalez, Felipe
AU  - Mengersen, Kerrie
AU  - Gaston, Kevin J.
TI  - UAVs and Machine Learning Revolutionising Invasive Grass and Vegetation Surveys in Remote Arid Lands
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 2
SN  - 1424-8220

AB  - The monitoring of invasive grasses and vegetation in remote areas is challenging, costly, and on the ground sometimes dangerous. Satellite and manned aircraft surveys can assist but their use may be limited due to the ground sampling resolution or cloud cover. Straightforward and accurate surveillance methods are needed to quantify rates of grass invasion, offer appropriate vegetation tracking reports, and apply optimal control methods. This paper presents a pipeline process to detect and generate a pixel-wise segmentation of invasive grasses, using buffel grass (Cenchrus ciliaris) and spinifex (Triodia sp.) as examples. The process integrates unmanned aerial vehicles (UAVs) also commonly known as drones, high-resolution red, green, blue colour model (RGB) cameras, and a data processing approach based on machine learning algorithms. The methods are illustrated with data acquired in Cape Range National Park, Western Australia (WA), Australia, orthorectified in Agisoft Photoscan Pro, and processed in Python programming language, scikit-learn, and eXtreme Gradient Boosting (XGBoost) libraries. In total, 342,626 samples were extracted from the obtained data set and labelled into six classes. Segmentation results provided an individual detection rate of 97% for buffel grass and 96% for spinifex, with a global multiclass pixel-wise detection rate of 97%. Obtained results were robust against illumination changes, object rotation, occlusion, background cluttering, and floral density variation.
KW  - biosecurity
KW  - buffel grass
KW  - Cenchrus ciliaris
KW  - drones
KW  - remote surveillance
KW  - spinifex
KW  - Triodia sp.
KW  - unmanned aerial vehicles (UAV)
KW  - vegetation assessments
KW  - xgboost
DO  - 10.3390/s18020605
ER  -
TY  - EJOU
AU  - Yang, Liping
AU  - MacEachren, Alan M.
AU  - Mitra, Prasenjit
AU  - Onorati, Teresa
TI  - Visually-Enabled Active Deep Learning for (Geo) Text and Image Classification: A Review
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 2
SN  - 2220-9964

AB  - This paper investigates recent research on active learning for (geo) text and image classification, with an emphasis on methods that combine visual analytics and/or deep learning. Deep learning has attracted substantial attention across many domains of science and practice, because it can find intricate patterns in big data; but successful application of the methods requires a big set of labeled data. Active learning, which has the potential to address the data labeling challenge, has already had success in geospatial applications such as trajectory classification from movement data and (geo) text and image classification. This review is intended to be particularly relevant for extension of these methods to GISience, to support work in domains such as geographic information retrieval from text and image repositories, interpretation of spatial language, and related geo-semantics challenges. Specifically, to provide a structure for leveraging recent advances, we group the relevant work into five categories: active learning, visual analytics, active learning with visual analytics, active deep learning, plus GIScience and Remote Sensing (RS) using active learning and active deep learning. Each category is exemplified by recent influential work. Based on this framing and our systematic review of key research, we then discuss some of the main challenges of integrating active learning with visual analytics and deep learning, and point out research opportunities from technical and application perspectives—for application-based opportunities, with emphasis on those that address big data with geospatial components.
KW  - visual analytics
KW  - human-centered computing
KW  - active learning
KW  - deep learning
KW  - machine learning
KW  - multi-class classification
KW  - multi-label classification
KW  - text classification
KW  - image classification
KW  - geographic information retrieval
DO  - 10.3390/ijgi7020065
ER  -
TY  - EJOU
AU  - Meng, Baoping
AU  - Gao, Jinlong
AU  - Liang, Tiangang
AU  - Cui, Xia
AU  - Ge, Jing
AU  - Yin, Jianpeng
AU  - Feng, Qisheng
AU  - Xie, Hongjie
TI  - Modeling of Alpine Grassland Cover Based on Unmanned Aerial Vehicle Technology and Multi-Factor Methods: A Case Study in the East of Tibetan Plateau, China
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 2
SN  - 2072-4292

AB  - Grassland cover and its temporal changes are key parameters in the estimation and monitoring of ecosystems and their functions, especially via remote sensing. However, the most suitable model for estimating grassland cover and the differences between models has rarely been studied in alpine meadow grasslands. In this study, field measurements of grassland cover in Gannan Prefecture, from 2014 to 2016, were acquired using unmanned aerial vehicle (UAV) technology. Single-factor parametric and multi-factor parametric/non-parametric cover inversion models were then constructed based on 14 factors related to grassland cover, and the dynamic variation of the annual maximum cover was analyzed. The results show that (1) nine out of 14 factors (longitude, latitude, elevation, the concentrations of clay and sand in the surface and bottom soils, temperature, precipitation, enhanced vegetation index (EVI) and normalized difference vegetation index (NDVI)) exert a significant effect on grassland cover in the study area. The logarithmic model based on EVI presents the best performance, with an R2 and RMSE of 0.52 and 16.96%, respectively. Single-factor grassland cover inversion models account for only 1–49% of the variation in cover during the growth season. (2) The optimum grassland cover inversion model is the artificial neural network (BP-ANN), with an R2 and RMSE of 0.72 and 13.38%, and SDs of 0.062% and 1.615%, respectively. Both the accuracy and the stability of the BP-ANN model are higher than those of the single-factor parametric models and multi-factor parametric/non-parametric models. (3) The annual maximum cover in Gannan Prefecture presents an increasing trend over 60.60% of the entire study area, while 36.54% is presently stable and 2.86% exhibits a decreasing trend.
KW  - grassland cover
KW  - unmanned aerial vehicle
KW  - multi-factor
KW  - inversion model
KW  - dynamic variation
DO  - 10.3390/rs10020320
ER  -
TY  - EJOU
AU  - Varela, Sebastian
AU  - Dhodda, Pruthvidhar R.
AU  - Hsu, William H.
AU  - Prasad, P. V. V.
AU  - Assefa, Yared
AU  - Peralta, Nahuel R.
AU  - Griffin, Terry
AU  - Sharda, Ajay
AU  - Ferguson, Allison
AU  - Ciampitti, Ignacio A.
TI  - Early-Season Stand Count Determination in Corn via Integration of Imagery from Unmanned Aerial Systems (UAS) and Supervised Learning Techniques
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 2
SN  - 2072-4292

AB  - Corn (Zea mays L.) is one of the most sensitive crops to planting pattern and early-season uniformity. The most common method to determine number of plants is by visual inspection on the ground but this field activity becomes time-consuming, labor-intensive, biased, and may lead to less profitable decisions by farmers. The objective of this study was to develop a reliable, timely, and unbiased method for counting corn plants based on ultra-high-resolution imagery acquired from unmanned aerial systems (UAS) to automatically scout fields and applied to real field conditions. A ground sampling distance of 2.4 mm was targeted to extract information at a plant-level basis. First, an excess greenness (ExG) index was used to individualized green pixels from the background, then rows and inter-row contours were identified and extracted. A scalable training procedure was implemented using geometric descriptors as inputs of the classifier. Second, a decision tree was implemented and tested using two training modes in each site to expose the workflow to different ground conditions at the time of the aerial data acquisition. Differences in performance were due to training modes and spatial resolutions in the two sites. For an object classification task, an overall accuracy of 0.96, based on the proportion of corrected assessment of corn and non-corn objects, was obtained for local (per-site) classification, and an accuracy of 0.93 was obtained for the combined training modes. For successful model implementation, plants should have between two to three leaves when images are collected (avoiding overlapping between plants). Best workflow performance was reached at 2.4 mm resolution corresponding to 10 m of altitude (lower altitude); higher altitudes were gradually penalized. The latter was coincident with the larger number of detected green objects in the images and the effectiveness of geometry as descriptor for corn plant detection.
KW  - unmanned aerial system
KW  - supervised learning
KW  - corn
KW  - farm management
KW  - precision agriculture
DO  - 10.3390/rs10020343
ER  -
TY  - EJOU
AU  - Bashmal, Laila
AU  - Bazi, Yakoub
AU  - AlHichri, Haikel
AU  - AlRahhal, Mohamad M.
AU  - Ammour, Nassim
AU  - Alajlan, Naif
TI  - Siamese-GAN: Learning Invariant Representations for Aerial Vehicle Image Categorization
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 2
SN  - 2072-4292

AB  - In this paper, we present a new algorithm for cross-domain classification in aerial vehicle images based on generative adversarial networks (GANs). The proposed method, called Siamese-GAN, learns invariant feature representations for both labeled and unlabeled images coming from two different domains. To this end, we train in an adversarial manner a Siamese encoder–decoder architecture coupled with a discriminator network. The encoder–decoder network has the task of matching the distributions of both domains in a shared space regularized by the reconstruction ability, while the discriminator seeks to distinguish between them. After this phase, we feed the resulting encoded labeled and unlabeled features to another network composed of two fully-connected layers for training and classification, respectively. Experiments on several cross-domain datasets composed of extremely high resolution (EHR) images acquired by manned/unmanned aerial vehicles (MAV/UAV) over the cities of Vaihingen, Toronto, Potsdam, and Trento are reported and discussed.
KW  - manned/unmanned aerial vehicles (MAV/UAV)
KW  - extremely high resolution (EHR) images
KW  - distribution mismatch
KW  - generative adversarial networks (GANs)
KW  - Siamese encoder–decoder
DO  - 10.3390/rs10020351
ER  -
TY  - EJOU
AU  - Chen, Hao
AU  - Zhang, Wanchang
AU  - Gao, Huiran
AU  - Nie, Ning
TI  - Climate Change and Anthropogenic Impacts on Wetland and Agriculture in the Songnen and Sanjiang Plain, Northeast China
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 3
SN  - 2072-4292

AB  - Influences of the increasing pressure of climate change and anthropogenic activities on wetlands ecosystems and agriculture are significant around the world. This paper assessed the spatiotemporal land use and land cover changes (LULCC), especially for conversion from marshland to other LULC types (e.g., croplands) over the Songnen and Sanjiang Plain (SNP and SJP), northeast China, during the past 35 years (1980–2015). The relative role of human activities and climatic changes in terms of their impacts on wetlands and agriculture dynamics were quantitatively distinguished and evaluated in different periods based on a seven-stage LULC dataset. Our results indicated that human activities, such as population expansion and socioeconomic development, and institutional policies related to wetlands and agriculture were the main driving forces for LULCC of the SJP and SNP during the past decades, while increasing contributions of climatic changes were also found. Furthermore, as few studies have identified which geographic regions are most at risk, how the future climate changes will spatially and temporally impact wetlands and agriculture, i.e., the suitability of wetlands and agriculture distributions under different future climate change scenarios, were predicted and analyzed using a habitat distribution model (Maxent) at the pixel-scale. The present findings can provide valuable references for policy makers on regional sustainability for food security, water resource rational management, agricultural planning and wetland protection as well as restoration of the region.
KW  - wetland
KW  - agriculture
KW  - LULCC
KW  - climate change
KW  - anthropogenic activities
KW  - Maxent model
DO  - 10.3390/rs10030356
ER  -
TY  - EJOU
AU  - Puliti, Stefano
AU  - Talbot, Bruce
AU  - Astrup, Rasmus
TI  - Tree-Stump Detection, Segmentation, Classification, and Measurement Using Unmanned Aerial Vehicle (UAV) Imagery
T2  - Forests

PY  - 2018
VL  - 9
IS  - 3
SN  - 1999-4907

AB  - Unmanned aerial vehicles (UAVs) are increasingly used as tools to perform a detailed assessment of post-harvest sites. One of the potential use of UAV photogrammetric data is to obtain tree-stump information that can then be used to support more precise decisions. This study developed and tested a methodology to automatically detect, segment, classify, and measure tree-stumps. Among the potential applications for single stump data, this study assessed the possibility (1) to detect and map root- and butt-rot on the stumps using a machine learning approach, and (2) directly measure or model tree stump diameter from the UAV data. The results revealed that the tree-stumps were detected with an overall accuracy of 68–80%, and once the stump was detected, the presence of root- and butt-rot was detected with an accuracy of 82.1%. Furthermore, the root mean square error of the UAV-derived measurements or model predictions for the stump diameter was 7.5 cm and 6.4 cm, respectively, and with the former systematically under predicting the diameter by 3.3 cm. The results of this study are promising and can lead to the development of more cost-effective and comprehensive UAV post-harvest surveys.
KW  - tree-stumps
KW  - UAV
KW  - automatic detection
KW  - machine learning
KW  - root- and butt-rot
DO  - 10.3390/f9030102
ER  -
TY  - EJOU
AU  - Zhao, Yi
AU  - Ma, Jiale
AU  - Li, Xiaohui
AU  - Zhang, Jie
TI  - Saliency Detection and Deep Learning-Based Wildfire Identification in UAV Imagery
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 3
SN  - 1424-8220

AB  - An unmanned aerial vehicle (UAV) equipped with global positioning systems (GPS) can provide direct georeferenced imagery, mapping an area with high resolution. So far, the major difficulty in wildfire image classification is the lack of unified identification marks, the fire features of color, shape, texture (smoke, flame, or both) and background can vary significantly from one scene to another. Deep learning (e.g., DCNN for Deep Convolutional Neural Network) is very effective in high-level feature learning, however, a substantial amount of training images dataset is obligatory in optimizing its weights value and coefficients. In this work, we proposed a new saliency detection algorithm for fast location and segmentation of core fire area in aerial images. As the proposed method can effectively avoid feature loss caused by direct resizing; it is used in data augmentation and formation of a standard fire image dataset ‘UAV_Fire’. A 15-layered self-learning DCNN architecture named ‘Fire_Net’ is then presented as a self-learning fire feature exactor and classifier. We evaluated different architectures and several key parameters (drop out ratio, batch size, etc.) of the DCNN model regarding its validation accuracy. The proposed architecture outperformed previous methods by achieving an overall accuracy of 98%. Furthermore, ‘Fire_Net’ guarantied an average processing speed of 41.5 ms per image for real-time wildfire inspection. To demonstrate its practical utility, Fire_Net is tested on 40 sampled images in wildfire news reports and all of them have been accurately identified.
KW  - UAV
KW  - wildfire
KW  - deep learning
KW  - saliency detection
DO  - 10.3390/s18030712
ER  -
TY  - EJOU
AU  - Cao, Xiaoguang
AU  - Wang, Peng
AU  - Meng, Cai
AU  - Bai, Xiangzhi
AU  - Gong, Guoping
AU  - Liu, Miaoming
AU  - Qi, Jun
TI  - Region Based CNN for Foreign Object Debris Detection on Airfield Pavement
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 3
SN  - 1424-8220

AB  - In this paper, a novel algorithm based on convolutional neural network (CNN) is proposed to detect foreign object debris (FOD) based on optical imaging sensors. It contains two modules, the improved region proposal network (RPN) and spatial transformer network (STN) based CNN classifier. In the improved RPN, some extra select rules are designed and deployed to generate high quality candidates with fewer numbers. Moreover, the efficiency of CNN detector is significantly improved by introducing STN layer. Compared to faster R-CNN and single shot multiBox detector (SSD), the proposed algorithm achieves better result for FOD detection on airfield pavement in the experiment.
KW  - foreign object debris
KW  - object detection
KW  - convolutional neural network
KW  - vehicular imaging sensors
DO  - 10.3390/s18030737
ER  -
TY  - EJOU
AU  - Jin, Xue-Bo
AU  - Su, Ting-Li
AU  - Kong, Jian-Lei
AU  - Bai, Yu-Ting
AU  - Miao, Bei-Bei
AU  - Dou, Chao
TI  - State-of-the-Art Mobile Intelligence: Enabling Robots to Move Like Humans by Estimating Mobility with Artificial Intelligence
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 3
SN  - 2076-3417

AB  - Mobility is a significant robotic task. It is the most important function when robotics is applied to domains such as autonomous cars, home service robots, and autonomous underwater vehicles. Despite extensive research on this topic, robots still suffer from difficulties when moving in complex environments, especially in practical applications. Therefore, the ability to have enough intelligence while moving is a key issue for the success of robots. Researchers have proposed a variety of methods and algorithms, including navigation and tracking. To help readers swiftly understand the recent advances in methodology and algorithms for robot movement, we present this survey, which provides a detailed review of the existing methods of navigation and tracking. In particular, this survey features a relation-based architecture that enables readers to easily grasp the key points of mobile intelligence. We first outline the key problems in robot systems and point out the relationship among robotics, navigation, and tracking. We then illustrate navigation using different sensors and the fusion methods and detail the state estimation and tracking models for target maneuvering. Finally, we address several issues of deep learning as well as the mobile intelligence of robots as suggested future research topics. The contributions of this survey are threefold. First, we review the literature of navigation according to the applied sensors and fusion method. Second, we detail the models for target maneuvering and the existing tracking based on estimation, such as the Kalman filter and its series developed form, according to their model-construction mechanisms: linear, nonlinear, and non-Gaussian white noise. Third, we illustrate the artificial intelligence approach—especially deep learning methods—and discuss its combination with the estimation method.
KW  - mobile intelligence
KW  - navigation
KW  - tracking
KW  - Kalman filter
KW  - estimation
KW  - tracking models
KW  - interacting multiple model
KW  - adaptive model
KW  - deep learning
DO  - 10.3390/app8030379
ER  -
TY  - EJOU
AU  - Darvishi, Mehdi
AU  - Schlögel, Romy
AU  - Bruzzone, Lorenzo
AU  - Cuozzo, Giovanni
TI  - Integration of PSI, MAI, and Intensity-Based Sub-Pixel Offset Tracking Results for Landslide Monitoring with X-Band Corner Reflectors—Italian Alps (Corvara)
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 3
SN  - 2072-4292

AB  - This paper presents an analysis of the integration between interferometric and intensity-offset tracking-based SAR remote sensing for landslide hazard mitigation in the Italian Alps. Despite the advantages of Synthetic Aperture Radar Interferometry (InSAR) methods for quantifying landslide deformation, some limitations remain. The temporal decorrelation, the 1-D Line Of Sight (LOS) observation restriction, the high velocity rate and the multi-directional movement properties make it difficult to monitor accurately complex landslides in areas covered by vegetation. Therefore, complementary and integrated approaches, such as offset tracking-based techniques, are needed to overcome these InSAR limitations for monitoring ground surface deformations. As sub-pixel offset tracking is highly sensitive to data spatial resolution, the latest generations of SAR sensors, such as TerraSAR-X and COSMO-SkyMed, open interesting perspective for a more accurate hazard assessment. In this paper, we consider high-resolution X-band data acquired by the COSMO-SkyMed (CSK) constellation for Permanent Scatterers Interferometry (PSI), Multi-Aperture Interferometry (MAI) and offset tracking processing. We analyze the offset tracking techniques considering area and feature-based matching algorithms to evaluate their applicability to CSK data by improving sub-pixel offset estimations. To this end, PSI and MAI are used for extracting LOS and azimuthal displacement components. Then, four well-known area-based and five feature-based matching algorithms (taken from computer vision) are applied to 16 X-band corner reflectors. Results show that offset estimation accuracy can be considerably improved up to less than 3% of the pixel size using the combination of the different feature-based detectors and descriptors. A sensitivity analysis of these techniques applied to CSK data to monitor complex landslides in the Italian Alps provides indications on advantages and disadvantages of each of them.
KW  - landslide
KW  - corner reflector
KW  - InSAR
KW  - PSI
KW  - MAI
KW  - offset tracking
KW  - computer vision
KW  - SAR
KW  - remote sensing
DO  - 10.3390/rs10030409
ER  -
TY  - EJOU
AU  - Liu, Tao
AU  - Abd-Elrahman, Amr
TI  - An Object-Based Image Analysis Method for Enhancing Classification of Land Covers Using Fully Convolutional Networks and Multi-View Images of Small Unmanned Aerial System
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 3
SN  - 2072-4292

AB  - Fully Convolutional Networks (FCN) has shown better performance than other classifiers like Random Forest (RF), Support Vector Machine (SVM) and patch-based Deep Convolutional Neural Network (DCNN), for object-based classification using orthoimage only in previous studies; however, for further improving deep learning algorithm performance, multi-view data should be considered for training data enrichment, which has not been investigated for FCN. The present study developed a novel OBIA classification using FCN and multi-view data extracted from small Unmanned Aerial System (UAS) for mapping landcovers. Specifically, this study proposed three methods to automatically generate multi-view training samples from orthoimage training datasets to conduct multi-view object-based classification using FCN, and compared their performances with each other and also with RF, SVM, and DCNN classifiers. The first method does not consider the object surrounding information, while the other two utilized object context information. We demonstrated that all the three versions of FCN multi-view object-based classification outperformed their counterparts utilizing orthoimage data only. Furthermore, the results also showed that when multi-view training samples were prepared with consideration of object surroundings, FCN trained with these samples gave much better accuracy than FCN classification trained without context information. Similar accuracies were achieved from the two methods utilizing object surrounding information, although sample preparation was conducted using two different ways. When comparing FCN with RF, SVM, DCNN implies that FCN generally produced better accuracy than the other classifiers, regardless of using orthoimage or multi-view data.
KW  - FCN
KW  - deep learning
KW  - object-based
KW  - OBIA
KW  - UAS
KW  - multi-view data
KW  - wetland
DO  - 10.3390/rs10030457
ER  -
TY  - EJOU
AU  - Zhang, Zhen
AU  - Li, Yibing
AU  - Jin, Shanshan
AU  - Zhang, Zhaoyue
AU  - Wang, Hui
AU  - Qi, Lin
AU  - Zhou, Ruolin
TI  - Modulation Signal Recognition Based on Information Entropy and Ensemble Learning
T2  - Entropy

PY  - 2018
VL  - 20
IS  - 3
SN  - 1099-4300

AB  - In this paper, information entropy and ensemble learning based signal recognition theory and algorithms have been proposed. We have extracted 16 kinds of entropy features out of 9 types of modulated signals. The types of information entropy used are numerous, including Rényi entropy and energy entropy based on S Transform and Generalized S Transform. We have used three feature selection algorithms, including sequence forward selection (SFS), sequence forward floating selection (SFFS) and RELIEF-F to select the optimal feature subset from 16 entropy features. We use five classifiers, including k-nearest neighbor (KNN), support vector machine (SVM), Adaboost, Gradient Boosting Decision Tree (GBDT) and eXtreme Gradient Boosting (XGBoost) to classify the original feature set and the feature subsets selected by different feature selection algorithms. The simulation results show that the feature subsets selected by SFS and SFFS algorithms are the best, with a 48% increase in recognition rate over the original feature set when using KNN classifier and a 34% increase when using SVM classifier. For the other three classifiers, the original feature set can achieve the best recognition performance. The XGBoost classifier has the best recognition performance, the overall recognition rate is 97.74% and the recognition rate can reach 82% when the signal to noise ratio (SNR) is −10 dB.
KW  - entropy feature
KW  - feature selection
KW  - ensemble learning
KW  - radar
DO  - 10.3390/e20030198
ER  -
TY  - EJOU
AU  - Du, Jianping
AU  - Wang, Ding
AU  - Yu, Wanting
AU  - Yu, Hongyi
TI  - Direct Position Determination of Unknown Signals in the Presence of Multipath Propagation
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 3
SN  - 1424-8220

AB  - A novel geolocation architecture, termed “Multiple Transponders and Multiple Receivers for Multiple Emitters Positioning System (MTRE)” is proposed in this paper. Existing Direct Position Determination (DPD) methods take advantage of a rather simple channel assumption (line of sight channels with complex path attenuations) and a simplified MUltiple SIgnal Classification (MUSIC) algorithm cost function to avoid the high dimension searching. We point out that the simplified assumption and cost function reduce the positioning accuracy because of the singularity of the array manifold in a multi-path environment. We present a DPD model for unknown signals in the presence of Multi-path Propagation (MP-DPD) in this paper. MP-DPD adds non-negative real path attenuation constraints to avoid the mistake caused by the singularity of the array manifold. The Multi-path Propagation MUSIC (MP-MUSIC) method and the Active Set Algorithm (ASA) are designed to reduce the dimension of searching. A Multi-path Propagation Maximum Likelihood (MP-ML) method is proposed in addition to overcome the limitation of MP-MUSIC in the sense of a time-sensitive application. An iterative algorithm and an approach of initial value setting are given to make the MP-ML time consumption acceptable. Numerical results validate the performances improvement of MP-MUSIC and MP-ML. A closed form of the Cramér–Rao Lower Bound (CRLB) is derived as a benchmark to evaluate the performances of MP-MUSIC and MP-ML.
KW  - direct position determination
KW  - MUSIC algorithm
KW  - maximum likelihood estimation
KW  - convex QP
KW  - multi-path geolocation
KW  - active set algorithm
DO  - 10.3390/s18030892
ER  -
TY  - EJOU
AU  - Zhang, Duona
AU  - Ding, Wenrui
AU  - Zhang, Baochang
AU  - Xie, Chunyu
AU  - Li, Hongguang
AU  - Liu, Chunhui
AU  - Han, Jungong
TI  - Automatic Modulation Classification Based on Deep Learning for Unmanned Aerial Vehicles
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 3
SN  - 1424-8220

AB  - Deep learning has recently attracted much attention due to its excellent performance in processing audio, image, and video data. However, few studies are devoted to the field of automatic modulation classification (AMC). It is one of the most well-known research topics in communication signal recognition and remains challenging for traditional methods due to complex disturbance from other sources. This paper proposes a heterogeneous deep model fusion (HDMF) method to solve the problem in a unified framework. The contributions include the following: (1) a convolutional neural network (CNN) and long short-term memory (LSTM) are combined by two different ways without prior knowledge involved; (2) a large database, including eleven types of single-carrier modulation signals with various noises as well as a fading channel, is collected with various signal-to-noise ratios (SNRs) based on a real geographical environment; and (3) experimental results demonstrate that HDMF is very capable of coping with the AMC problem, and achieves much better performance when compared with the independent network.
KW  - deep learning
KW  - automatic modulation classification
KW  - classifier fusion
KW  - convolutional neural network
KW  - long short-term memory
DO  - 10.3390/s18030924
ER  -
TY  - EJOU
AU  - Wang, Rongxiao
AU  - Chen, Bin
AU  - Qiu, Sihang
AU  - Ma, Liang
AU  - Zhu, Zhengqiu
AU  - Wang, Yiping
AU  - Qiu, Xiaogang
TI  - Hazardous Source Estimation Using an Artificial Neural Network, Particle Swarm Optimization and a Simulated Annealing Algorithm
T2  - Atmosphere

PY  - 2018
VL  - 9
IS  - 4
SN  - 2073-4433

AB  - Locating and quantifying the emission source plays a significant role in the emergency management of hazardous gas leak accidents. Due to the lack of a desirable atmospheric dispersion model, current source estimation algorithms cannot meet the requirements of both accuracy and efficiency. In addition, the original optimization algorithm can hardly estimate the source accurately, because of the difficulty in balancing the local searching with the global searching. To deal with these problems, in this paper, a source estimation method is proposed using an artificial neural network (ANN), particle swarm optimization (PSO), and a simulated annealing algorithm (SA). This novel method uses numerous pre-determined scenarios to train the ANN, so that the ANN can predict dispersion accurately and efficiently. Further, the SA is applied in the PSO to improve the global searching ability. The proposed method is firstly tested by a numerical case study based on process hazard analysis software (PHAST), with analysis of receptor configuration and measurement noise. Then, the Indianapolis field case study is applied to verify the effectiveness of the proposed method in practice. Results demonstrate that the hybrid SAPSO algorithm coupled with the ANN prediction model has better performances than conventional methods in both numerical and field cases.
KW  - source estimation
KW  - atmospheric dispersion model
KW  - artificial neural network
KW  - particle swarm optimization
KW  - simulated annealing algorithm
DO  - 10.3390/atmos9040119
ER  -
TY  - EJOU
AU  - Sandino, Juan
AU  - Pegg, Geoff
AU  - Gonzalez, Felipe
AU  - Smith, Grant
TI  - Aerial Mapping of Forests Affected by Pathogens Using UAVs, Hyperspectral Sensors, and Artificial Intelligence
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 4
SN  - 1424-8220

AB  - The environmental and economic impacts of exotic fungal species on natural and plantation forests have been historically catastrophic. Recorded surveillance and control actions are challenging because they are costly, time-consuming, and hazardous in remote areas. Prolonged periods of testing and observation of site-based tests have limitations in verifying the rapid proliferation of exotic pathogens and deterioration rates in hosts. Recent remote sensing approaches have offered fast, broad-scale, and affordable surveys as well as additional indicators that can complement on-ground tests. This paper proposes a framework that consolidates site-based insights and remote sensing capabilities to detect and segment deteriorations by fungal pathogens in natural and plantation forests. This approach is illustrated with an experimentation case of myrtle rust (Austropuccinia psidii) on paperbark tea trees (Melaleuca quinquenervia) in New South Wales (NSW), Australia. The method integrates unmanned aerial vehicles (UAVs), hyperspectral image sensors, and data processing algorithms using machine learning. Imagery is acquired using a Headwall Nano-Hyperspec     ®     camera, orthorectified in Headwall SpectralView     ®    , and processed in Python programming language using eXtreme Gradient Boosting (XGBoost), Geospatial Data Abstraction Library (GDAL), and Scikit-learn third-party libraries. In total, 11,385 samples were extracted and labelled into five classes: two classes for deterioration status and three classes for background objects. Insights reveal individual detection rates of 95% for healthy trees, 97% for deteriorated trees, and a global multiclass detection rate of 97%. The methodology is versatile to be applied to additional datasets taken with different image sensors, and the processing of large datasets with freeware tools.
KW  - Austropuccinia psidii
KW  - drones
KW  - hyperspectral camera
KW  - machine learning
KW  - Melaleuca quinquenervia
KW  - myrtle rust
KW  - non-invasive assessment
KW  - paperbark
KW  - unmanned aerial vehicles (UAV)
KW  - xgboost
DO  - 10.3390/s18040944
ER  -
TY  - EJOU
AU  - Gallego, Antonio-Javier
AU  - Pertusa, Antonio
AU  - Gil, Pablo
TI  - Automatic Ship Classification from Optical Aerial Images with Convolutional Neural Networks
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 4
SN  - 2072-4292

AB  - The automatic classification of ships from aerial images is a considerable challenge. Previous works have usually applied image processing and computer vision techniques to extract meaningful features from visible spectrum images in order to use them as the input for traditional supervised classifiers. We present a method for determining if an aerial image of visible spectrum contains a ship or not. The proposed architecture is based on Convolutional Neural Networks (CNN), and it combines neural codes extracted from a CNN with a k-Nearest Neighbor method so as to improve performance. The kNN results are compared to those obtained with the CNN Softmax output. Several CNN models have been configured and evaluated in order to seek the best hyperparameters, and the most suitable setting for this task was found by using transfer learning at different levels. A new dataset (named MASATI) composed of aerial imagery with more than 6000 samples has also been created to train and evaluate our architecture. The experimentation shows a success rate of over 99% for our approach, in contrast with the 79% obtained with traditional methods in classification of ship images, also outperforming other methods based on CNNs. A dataset of images (MWPU VHR-10) used in previous works was additionally used to evaluate the proposed approach. Our best setup achieves a success ratio of 86% with these data, significantly outperforming previous state-of-the-art ship classification methods.
KW  - deep learning
KW  - aerial image classification
KW  - ships classification
KW  - maritime surveillance
KW  - optical remote sensing
KW  - convolutional neural networks
DO  - 10.3390/rs10040511
ER  -
TY  - EJOU
AU  - Kong, Xiangxiong
AU  - Li, Jian
TI  - Image Registration-Based Bolt Loosening Detection of Steel Joints
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 4
SN  - 1424-8220

AB  - Self-loosening of bolts caused by repetitive loads and vibrations is one of the common defects that can weaken the structural integrity of bolted steel joints in civil structures. Many existing approaches for detecting loosening bolts are based on physical sensors and, hence, require extensive sensor deployment, which limit their abilities to cost-effectively detect loosened bolts in a large number of steel joints. Recently, computer vision-based structural health monitoring (SHM) technologies have demonstrated great potential for damage detection due to the benefits of being low cost, easy to deploy, and contactless. In this study, we propose a vision-based non-contact bolt loosening detection method that uses a consumer-grade digital camera. Two images of the monitored steel joint are first collected during different inspection periods and then aligned through two image registration processes. If the bolt experiences rotation between inspections, it will introduce differential features in the registration errors, serving as a good indicator for bolt loosening detection. The performance and robustness of this approach have been validated through a series of experimental investigations using three laboratory setups including a gusset plate on a cross frame, a column flange, and a girder web. The bolt loosening detection results are presented for easy interpretation such that informed decisions can be made about the detected loosened bolts.
KW  - bolt loosening detection
KW  - intensity-based image registration
KW  - feature matching
KW  - structural health monitoring
KW  - structural inspection
KW  - superpixel
KW  - civil structures
KW  - steel joints
KW  - feature tracking
DO  - 10.3390/s18041000
ER  -
TY  - EJOU
AU  - Zhu, Xiaolin
AU  - Cai, Fangyi
AU  - Tian, Jiaqi
AU  - Williams, Trecia K.
TI  - Spatiotemporal Fusion of Multisource Remote Sensing Data: Literature Survey, Taxonomy, Principles, Applications, and Future Directions
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 4
SN  - 2072-4292

AB  - Satellite time series with high spatial resolution is critical for monitoring land surface dynamics in heterogeneous landscapes. Although remote sensing technologies have experienced rapid development in recent years, data acquired from a single satellite sensor are often unable to satisfy our demand. As a result, integrated use of data from different sensors has become increasingly popular in the past decade. Many spatiotemporal data fusion methods have been developed to produce synthesized images with both high spatial and temporal resolutions from two types of satellite images, frequent coarse-resolution images, and sparse fine-resolution images. These methods were designed based on different principles and strategies, and therefore show different strengths and limitations. This diversity brings difficulties for users to choose an appropriate method for their specific applications and data sets. To this end, this review paper investigates literature on current spatiotemporal data fusion methods, categorizes existing methods, discusses the principal laws underlying these methods, summarizes their potential applications, and proposes possible directions for future studies in this field.
KW  - spatiotemporal data fusion
KW  - data blending
KW  - spatial resolution
KW  - temporal resolution
KW  - satellite images
DO  - 10.3390/rs10040527
ER  -
TY  - EJOU
AU  - Baker, Fraser
AU  - Smith, Claire L.
AU  - Cavan, Gina
TI  - A Combined Approach to Classifying Land Surface Cover of Urban Domestic Gardens Using Citizen Science Data and High Resolution Image Analysis
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 4
SN  - 2072-4292

AB  - Domestic gardens are an important component of cities, contributing significantly to urban green infrastructure (GI) and its associated ecosystem services. However, domestic gardens are incredibly heterogeneous which presents challenges for quantifying their GI contribution and associated benefits for sustainable urban development. This study applies an innovative methodology that combines citizen science data with high resolution image analysis to create a garden dataset in the case study city of Manchester, UK. An online Citizen Science Survey (CSS) collected estimates of proportional coverage for 10 garden land surface types from 1031 city residents. High resolution image analysis was conducted to validate the CSS estimates, and to classify 7 land surface cover categories for all garden parcels in the city. Validation of the CSS land surface estimations revealed a mean accuracy of 76.63% (s = 15.24%), demonstrating that citizens are able to provide valid estimates of garden surface coverage proportions. An Object Based Image Analysis (OBIA) classification achieved an estimated overall accuracy of 82%, with further processing required to classify shadow objects. CSS land surface estimations were then extrapolated across the entire classification through calculation of within image class proportions, to provide the proportional coverage of 10 garden land surface types (buildings, hard impervious surfaces, hard pervious surfaces, bare soil, trees, shrubs, mown grass, rough grass, cultivated land, water) within every garden parcel in the city. The final dataset provides a better understanding of the composition of GI in domestic gardens and how this varies across the city. An average garden in Manchester has 50.23% GI, including trees (16.54%), mown grass (14.46%), shrubs (9.19%), cultivated land (7.62%), rough grass (1.97%) and water (0.45%). At the city scale, Manchester has 49.0% GI, and around one fifth (20.94%) of this GI is contained within domestic gardens. This is useful evidence to inform local urban development policies.
KW  - urban gardens
KW  - land surface cover
KW  - citizen science
KW  - land cover classification
KW  - urban green space
KW  - green infrastructure
KW  - object-based image classification
DO  - 10.3390/rs10040537
ER  -
TY  - EJOU
AU  - Li, He
AU  - Liu, Gaohuan
AU  - Liu, Qingsheng
AU  - Chen, Zhongxin
AU  - Huang, Chong
TI  - Retrieval of Winter Wheat Leaf Area Index from Chinese GF-1 Satellite Data Using the PROSAIL Model
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 4
SN  - 1424-8220

AB  - Leaf area index (LAI) is one of the key biophysical parameters in crop structure. The accurate quantitative estimation of crop LAI is essential to verify crop growth and health. The PROSAIL radiative transfer model (RTM) is one of the most established methods for estimating crop LAI. In this study, a look-up table (LUT) based on the PROSAIL RTM was first used to estimate winter wheat LAI from GF-1 data, which accounted for some available prior knowledge relating to the distribution of winter wheat characteristics. Next, the effects of 15 LAI-LUT strategies with reflectance bands and 10 LAI-LUT strategies with vegetation indexes on the accuracy of the winter wheat LAI retrieval with different phenological stages were evaluated against in situ LAI measurements. The results showed that the LUT strategies of LAI-GNDVI were optimal and had the highest accuracy with a root mean squared error (RMSE) value of 0.34, and a coefficient of determination (R2) of 0.61 during the elongation stages, and the LUT strategies of LAI-Green were optimal with a RMSE of 0.74, and R2 of 0.20 during the grain-filling stages. The results demonstrated that the PROSAIL RTM had great potential in winter wheat LAI inversion with GF-1 satellite data and the performance could be improved by selecting the appropriate LUT inversion strategies in different growth periods.
KW  - leaf area index
KW  - PROSAIL
KW  - look-up table
KW  - GF-1
KW  - winter wheat
DO  - 10.3390/s18041120
ER  -
TY  - EJOU
AU  - Dou, Zhiguo
AU  - Cui, Lijuan
AU  - Li, Jing
AU  - Zhu, Yinuo
AU  - Gao, Changjun
AU  - Pan, Xu
AU  - Lei, Yinru
AU  - Zhang, Manyin
AU  - Zhao, Xinsheng
AU  - Li, Wei
TI  - Hyperspectral Estimation of the Chlorophyll Content in Short-Term and Long-Term Restorations of Mangrove in Quanzhou Bay Estuary, China
T2  - Sustainability

PY  - 2018
VL  - 10
IS  - 4
SN  - 2071-1050

AB  - The chlorophyll content can indicate the general health of vegetation, and can be estimated from hyperspectral data. The aim of this study is to estimate the chlorophyll content of mangroves at different stages of restoration in a coastal wetland in Quanzhou, China, using proximal hyperspectral remote sensing techniques. We determine the hyperspectral reflectance of leaves from two mangrove species, Kandelia candel and Aegiceras corniculatum, from short-term and long-term restoration areas with a portable spectroradiometer. We also measure the leaf chlorophyll content (SPAD value). We use partial-least-squares stepwise regression to determine the relationships between the spectral reflectance and the chlorophyll content of the leaves, and establish two models, a full-wave-band spectrum model and a red-edge position regression model, to estimate the chlorophyll content of the mangroves. The coefficients of determination for the red-edge position model and the full-wave-band model exceed 0.72 and 0.82, respectively. The inverted chlorophyll contents are estimated more accurately for the long-term restoration mangroves than for the short-term restoration mangroves. Our results indicate that hyperspectral data can be used to estimate the chlorophyll content of mangroves at different stages of restoration, and could possibly be adapted to estimate biochemical constituents in leaves.
KW  - chlorophyll content
KW  - hyperspectral
KW  - estimation model
KW  - mangrove
DO  - 10.3390/su10041127
ER  -
TY  - EJOU
AU  - De Castro, Ana I.
AU  - Jiménez-Brenes, Francisco M.
AU  - Torres-Sánchez, Jorge
AU  - Peña, José M.
AU  - Borra-Serrano, Irene
AU  - López-Granados, Francisca
TI  - 3-D Characterization of Vineyards Using a Novel UAV Imagery-Based OBIA Procedure for Precision Viticulture Applications
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 4
SN  - 2072-4292

AB  - Precision viticulture has arisen in recent years as a new approach in grape production. It is based on assessing field spatial variability and implementing site-specific management strategies, which can require georeferenced information of the three dimensional (3D) grapevine canopy structure as one of the input data. The 3D structure of vineyard fields can be generated applying photogrammetric techniques to aerial images collected with Unmanned Aerial Vehicles (UAVs), although processing the large amount of crop data embedded in 3D models is currently a bottleneck of this technology. To solve this limitation, a novel and robust object-based image analysis (OBIA) procedure based on Digital Surface Model (DSM) was developed for 3D grapevine characterization. The significance of this work relies on the developed OBIA algorithm which is fully automatic and self-adaptive to different crop-field conditions, classifying grapevines, and row gap (missing vine plants), and computing vine dimensions without any user intervention. The results obtained in three testing fields on two different dates showed high accuracy in the classification of grapevine area and row gaps, as well as minor errors in the estimates of grapevine height. In addition, this algorithm computed the position, projected area, and volume of every grapevine in the field, which increases the potential of this UAV- and OBIA-based technology as a tool for site-specific crop management applications.
KW  - digital surface model
KW  - image classification
KW  - remote sensing
KW  - precision agriculture
KW  - low cost RGB camera
KW  - grapevine canopy mapping
KW  - site-specific treatments
DO  - 10.3390/rs10040584
ER  -
TY  - EJOU
AU  - Besada, Juan A.
AU  - Bergesio, Luca
AU  - Campaña, Iván
AU  - Vaquero-Melchor, Diego
AU  - López-Araquistain, Jaime
AU  - Bernardos, Ana M.
AU  - Casar, José R.
TI  - Drone Mission Definition and Implementation for Automated Infrastructure Inspection Using Airborne Sensors
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 4
SN  - 1424-8220

AB  - This paper describes a Mission Definition System and the automated flight process it enables to implement measurement plans for discrete infrastructure inspections using aerial platforms, and specifically multi-rotor drones. The mission definition aims at improving planning efficiency with respect to state-of-the-art waypoint-based techniques, using high-level mission definition primitives and linking them with realistic flight models to simulate the inspection in advance. It also provides flight scripts and measurement plans which can be executed by commercial drones. Its user interfaces facilitate mission definition, pre-flight 3D synthetic mission visualisation and flight evaluation. Results are delivered for a set of representative infrastructure inspection flights, showing the accuracy of the flight prediction tools in actual operations using automated flight control.
KW  - unmanned aerial vehicles
KW  - mission planning
KW  - measurement planning
KW  - human-computer interfaces
KW  - multi-rotor trajectory prediction
KW  - infrastructure inspection
DO  - 10.3390/s18041170
ER  -

TY  - EJOU
AU  - Alvarado-Robles, Gilberto
AU  - Solís-Muñoz, Francisco J.
AU  - Garduño-Ramón, Marco A.
AU  - Osornio-Ríos, Roque A.
AU  - Morales-Hernández, Luis A.
TI  - A Novel Shadow Removal Method Based upon Color Transfer and Color Tuning in UAV Imaging
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 23
SN  - 2076-3417

AB  - Through the increasing use of unmanned aerial vehicles as remote sensing tools, shadows become evident in aerial imaging; this fact, alongside the higher spatial resolution obtained by high-resolution mounted cameras, presents a challenging issue when performing different image processing tasks related to urban areas monitoring. Accordingly, the state-of-the-art reported works can correct the shadow regions, but the heterogeneity between the corrected shadow and non-shadow areas is still evident and especially noticeable in concrete and asphalt regions. The present work introduces a local color transfer methodology to shadow removal which is based on the CIE L*a*b (Lightness, a and b) color space that considers chromatic differences in urban regions, and it is followed by a color tuning using the HSV color space. The quantitative comparison was executed by using the shadow standard deviation index (SSDI), where the proposed work provided low values that improve up to 19 units regarding other tested methods. The qualitative comparison was visually realized and proved that the proposed method enhances the color correspondence without losing texture information. Quantitative and qualitative results validate the results of color correction and texture preservation accuracy of the proposed method against other published methodologies.
KW  - image shadow removal
KW  - color correction
KW  - shadow elimination
KW  - unmanned aerial vehicle
KW  - aerial imaging
KW  - remote sensing
DO  - 10.3390/app112311494
ER  -
TY  - EJOU
AU  - Yoo, Seungho
AU  - Lee, Woonghee
TI  - Federated Reinforcement Learning Based AANs with LEO Satellites and UAVs
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 23
SN  - 1424-8220

AB  - Supported by the advances in rocket technology, companies like SpaceX and Amazon competitively have entered the satellite Internet business. These companies said that they could provide Internet service sufficiently to users using their communication resources. However, the Internet service might not be provided in densely populated areas, as the satellites coverage is broad but its resource capacity is limited. To offload the traffic of the densely populated area, we present an adaptable aerial access network (AAN), composed of low-Earth orbit (LEO) satellites and federated reinforcement learning (FRL)-enabled unmanned aerial vehicles (UAVs). Using the proposed system, UAVs could operate with relatively low computation resources than centralized coverage management systems. Furthermore, by utilizing FRL, the system could continuously learn from various environments and perform better with the longer operation times. Based on our proposed design, we implemented FRL, constructed the UAV-aided AAN simulator, and evaluated the proposed system. Base on the evaluation result, we validated that the FRL enabled UAV-aided AAN could operate efficiently in densely populated areas where the satellites cannot provide sufficient Internet services, which improves network performances. In the evaluations, our proposed AAN system provided about 3.25 times more communication resources and had 5.1% lower latency than the satellite-only AAN.
KW  - aerial access network
KW  - federated reinforcement learning
KW  - low-Earth orbit satellites
KW  - pseudo-satellites
KW  - non-terrestrial network
DO  - 10.3390/s21238111
ER  -
TY  - EJOU
AU  - Al-Okby, Mohammed F.
AU  - Neubert, Sebastian
AU  - Roddelkopf, Thomas
AU  - Thurow, Kerstin
TI  - Mobile Detection and Alarming Systems for Hazardous Gases and Volatile Chemicals in Laboratories and Industrial Locations
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 23
SN  - 1424-8220

AB  - The leakage of hazardous gases and chemical vapors is considered one of the dangerous accidents that can occur in laboratories, workshops, warehouses, and industrial sites that use or store these substances. The early detection and alarming of hazardous gases and volatile chemicals are significant to keep the safety conditions for the people and life forms who are work in and live around these places. In this paper, we investigate the available mobile detection and alarming systems for toxic, hazardous gases and volatile chemicals, especially in the laboratory environment. We included papers from January 2010 to August 2021 which may have the newest used sensors technologies and system components. We identified (236) papers from Clarivate Web of Science (WoS), IEEE, ACM Library, Scopus, and PubMed. Paper selection has been done based on a fast screening of the title and abstract, then a full-text reading was applied to filter the selected papers that resulted in (42) eligible papers. The main goal of this work is to discuss the available mobile hazardous gas detection and alarming systems based on several technical details such as the used gas detection technology (simple element, integrated, smart, etc.), sensor manufacturing technology (catalytic bead, MEMS, MOX, etc.) the sensor specifications (warm-up time, lifetime, response time, precision, etc.), processor type (microprocessor, microcontroller, PLC, etc.), and type of the used communication technology (Bluetooth/BLE, Wi-Fi/RF, ZigBee/XBee, LoRa, etc.). In this review, attention will be focused on the improvement of the detection and alarming system of hazardous gases with the latest invention in sensors, processors, communication, and battery technologies.
KW  - hazardous gases
KW  - toxic gases
KW  - gas sensor
KW  - safety system
KW  - volatile organic materials (VOCs)
KW  - alarming system
KW  - internet of things (IoT)
KW  - wireless sensor networks (WSNs)
DO  - 10.3390/s21238128
ER  -
TY  - EJOU
AU  - Zhang, Huanlong
AU  - Duan, Rui
AU  - Zheng, Anping
AU  - Zhang, Jie
AU  - Li, Linwei
AU  - Wang, Fengxian
TI  - Discriminative Siamese Tracker Based on Multi-Channel-Aware and Adaptive Hierarchical Deep Features
T2  - Symmetry

PY  - 2021
VL  - 13
IS  - 12
SN  - 2073-8994

AB  - Most existing Siamese trackers mainly use a pre-trained convolutional neural network to extract target features. However, due to the weak discrimination of the target and background information of pre-trained depth features, the performance of the Siamese tracker can be significantly degraded when facing similar targets or changes in target appearance. This paper proposes a multi-channel-aware and adaptive hierarchical deep features module to enhance the discriminative ability of the tracker. Firstly, through the multi-channel-aware deep features module, the importance values of feature channels are obtained from both the target details and overall information, to identify more important feature channels. Secondly, by introducing the adaptive hierarchical deep features module, the importance of each feature layer can be determined according to the response value of each frame, so that the hierarchical features can be integrated to represent the target, which can better adapt to changes in the appearance of the target. Finally, the proposed two modules are integrated into the Siamese framework for target tracking. The Siamese network used in this paper is a two-input branch symmetric neural network with two input branches, and they share the same weights, which are widely used in the field of target tracking. Experiments on some Benchmarks show that the proposed Siamese tracker has several points of improvement compared to the baseline tracker.
KW  - target features
KW  - siamese trackers
KW  - multi-channel aware
KW  - adaptive hierarchical features
KW  - visual tracking
DO  - 10.3390/sym13122329
ER  -
TY  - EJOU
AU  - Hu, Shuang
AU  - Liu, Jin
AU  - Kang, Zhiwei
TI  - DeepLabV3+/Efficientnet Hybrid Network-Based Scene Area Judgment for the Mars Unmanned Vehicle System
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 23
SN  - 1424-8220

AB  - Due to the complexity and danger of Mars&rsquo;s environment, traditional Mars unmanned ground vehicles cannot efficiently perform Mars exploration missions. To solve this problem, the DeepLabV3+/Efficientnet hybrid network is proposed and applied to the scene area judgment for the Mars unmanned vehicle system. Firstly, DeepLabV3+ is used to extract the feature information of the Mars image due to its high accuracy. Then, the feature information is used as the input for Efficientnet, and the categories of scene areas are obtained, including safe area, report area, and dangerous area. Finally, according to three categories, the Mars unmanned vehicle system performs three operations: pass, report, and send. Experimental results show the effectiveness of the DeepLabV3+/Efficientnet hybrid network in the scene area judgment. Compared with the Efficientnet network, the accuracy of the DeepLabV3+/Efficientnet hybrid network is improved by approximately 18% and reaches 99.84%, which ensures the safety of the exploration mission for the Mars unmanned vehicle system.
KW  - hybrid neural network
KW  - UAV
KW  - feature extraction
KW  - scene area judgment
DO  - 10.3390/s21238136
ER  -
TY  - EJOU
AU  - Gadipudi, Nivesh
AU  - Elamvazuthi, Irraivan
AU  - Lu, Cheng-Kai
AU  - Paramasivam, Sivajothi
AU  - Su, Steven
TI  - WPO-Net: Windowed Pose Optimization Network for Monocular Visual Odometry Estimation
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 23
SN  - 1424-8220

AB  - Visual odometry is the process of estimating incremental localization of the camera in 3-dimensional space for autonomous driving. There have been new learning-based methods which do not require camera calibration and are robust to external noise. In this work, a new method that do not require camera calibration called the &ldquo;windowed pose optimization network&rdquo; is proposed to estimate the 6 degrees of freedom pose of a monocular camera. The architecture of the proposed network is based on supervised learning-based methods with feature encoder and pose regressor that takes multiple consecutive two grayscale image stacks at each step for training and enforces the composite pose constraints. The KITTI dataset is used to evaluate the performance of the proposed method. The proposed method yielded rotational error of 3.12 deg/100 m, and the training time is 41.32 ms, while inference time is 7.87 ms. Experiments demonstrate the competitive performance of the proposed method to other state-of-the-art related works which shows the novelty of the proposed technique.
KW  - visual odometry
KW  - pose estimation
KW  - pose optimization
KW  - deep learning
DO  - 10.3390/s21238155
ER  -
TY  - EJOU
AU  - Sipelgas, Liis
AU  - Aavaste, Age
AU  - Uiboupin, Rivo
TI  - Mapping Flood Extent and Frequency from Sentinel-1 Imagery during the Extremely Warm Winter of 2020 in Boreal Floodplains and Forests
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 23
SN  - 2072-4292

AB  - The current study presents a methodology for water mapping from Sentinel-1 (S1) data and a flood extent analysis of the three largest floodplains in Estonia. The automatic processing scheme of S1 data was set up for the mapping of open-water flooding (OWF) and flooding under vegetation (FUV). The extremely mild winter of 2019/2020 resulted in several large floods at floodplains that were detected from S1 imagery with a maximal OWF extent up to 5000 ha and maximal FUV extent up to 4500 ha. A significant correlation (r2 &gt; 0.6) between the OWF extent and the closest gauge data was obtained for inland riverbank floodplains. The outcome enabled us to define the water level at which the water exceeds the shoreline and flooding starts. However, for a coastal river delta floodplain, a lower correlation (r2 &lt; 0.34) with gauge data was obtained, and the excess of river coastline could not be related to a certain water level. At inland riverbank floodplains, the extent of FUV was three times larger compared to that of OWF. The correlation between the water level and FUV was &lt;0.51, indicating that the river water level at these test sites can be used as a proxy for forest floods. Relating conventional gauge data to S1 time series data contributes to flood risk mitigation.
KW  - Sentinel-1
KW  - flood
KW  - climate change
DO  - 10.3390/rs13234949
ER  -
TY  - EJOU
AU  - Gao, Meijing
AU  - Bai, Yang
AU  - Li, Zhilong
AU  - Li, Shiyu
AU  - Zhang, Bozhi
AU  - Chang, Qiuyue
TI  - Real-Time Jellyfish Classification and Detection Based on Improved YOLOv3 Algorithm
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 23
SN  - 1424-8220

AB  - In recent years, jellyfish outbreaks have frequently occurred in offshore areas worldwide, posing a significant threat to the marine fishery, tourism, coastal industry, and personal safety. Effective monitoring of jellyfish is a vital method to solve the above problems. However, the optical detection method for jellyfish is still in the primary stage. Therefore, this paper studies a jellyfish detection method based on convolution neural network theory and digital image processing technology. This paper studies the underwater image preprocessing algorithm because the quality of underwater images directly affects the detection results. The results show that the image quality is better after applying the three algorithms namely prior defogging, adaptive histogram equalization, and multi-scale retinal enhancement, which is more conducive to detection. We establish a data set containing seven species of jellyfishes and fish. A total of 2141 images are included in the data set. The YOLOv3 algorithm is used to detect jellyfish, and its feature extraction network Darknet53 is optimized to ensure it is conducted in real-time. In addition, we introduce label smoothing and cosine annealing learning rate methods during the training process. The experimental results show that the improved algorithms improve the detection accuracy of jellyfish on the premise of ensuring the detection speed. This paper lays a foundation for the construction of an underwater jellyfish optical imaging real-time monitoring system.
KW  - jellyfish
KW  - convolutional neural network
KW  - image processing
KW  - YOLOv3
DO  - 10.3390/s21238160
ER  -
TY  - EJOU
AU  - Liu, Ziwei
AU  - Wang, Mingchang
AU  - Wang, Fengyan
AU  - Ji, Xue
TI  - A Residual Attention and Local Context-Aware Network for Road Extraction from High-Resolution Remote Sensing Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - Extracting road information from high-resolution remote sensing images (HRI) can provide crucial geographic information for many applications. With the improvement of remote sensing image resolution, the image data contain more abundant feature information. However, this phenomenon also enhances the spatial heterogeneity between different types of roads, making it difficult to accurately discern the road and non-road regions using only spectral characteristics. To remedy the above issues, a novel residual attention and local context-aware network (RALC-Net) is proposed for extracting a complete and continuous road network from HRI. RALC-Net utilizes a dual-encoder structure to improve the feature extraction capability of the network, whose two different branches take different feature information as input data. Specifically, we construct the residual attention module using the residual connection that can integrate spatial context information and the attention mechanism, highlighting local semantics to extract local feature information of roads. The residual attention module combines the characteristics of both the residual connection and the attention mechanism to retain complete road edge information, highlight essential semantics, and enhance the generalization capability of the network model. In addition, the multi-scale dilated convolution module is used to extract multi-scale spatial receptive fields to improve the model&rsquo;s performance further. We perform experiments to verify the performance of each component of RALC-Net through the ablation study. By combining low-level features with high-level semantics, we extract road information and make comparisons with other state-of-the-art models. The experimental results show that the proposed RALC-Net has excellent feature representation ability and robust generalizability, and can extract complete road information from a complex environment.
KW  - attention mechanism
KW  - road extraction
KW  - deep learning
KW  - remote sensing
KW  - multi-scale dilated convolution
DO  - 10.3390/rs13244958
ER  -
TY  - EJOU
AU  - Wu, Tianhao
AU  - Jiang, Mingzhi
AU  - Han, Yinhui
AU  - Yuan, Zheng
AU  - Li, Xinhang
AU  - Zhang, Lin
TI  - A Traffic-Aware Federated Imitation Learning Framework for Motion Control at Unsignalized Intersections with Internet of Vehicles
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 24
SN  - 2079-9292

AB  - The wealth of data and the enhanced computation capabilities of Internet of Vehicles (IoV) enable the optimized motion control of vehicles passing through an intersection without traffic lights. However, more intersections and demands for privacy protection pose new challenges to motion control optimization. Federated Learning (FL) can protect privacy via model interaction in IoV, but traditional FL methods hardly deal with the transportation issue. To address the aforementioned issue, this study proposes a Traffic-Aware Federated Imitation learning framework for Motion Control (TAFI-MC), consisting of Vehicle Interactors (VIs), Edge Trainers (ETs), and a Cloud Aggregator (CA). An Imitation Learning (IL) algorithm is integrated into TAFI-MC to improve motion control. Furthermore, a loss-aware experience selection strategy is explored to reduce communication overhead between ETs and VIs. The experimental results show that the proposed TAFI-MC outperforms imitated rules in the respect of collision avoidance and driving comfort, and the experience selection strategy can reduce communication overheads while ensuring convergence.
KW  - federated learning
KW  - imitation learning
KW  - internet of vehicle
KW  - unsignalized intersection
DO  - 10.3390/electronics10243050
ER  -
TY  - EJOU
AU  - Bernhard, Maximilian
AU  - Schubert, Matthias
TI  - Correcting Imprecise Object Locations for Training Object Detectors in Remote Sensing Applications
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - Object detection on aerial and satellite imagery is an important tool for image analysis in remote sensing and has many areas of application. As modern object detectors require accurate annotations for training, manual and labor-intensive labeling is necessary. In situations where GPS coordinates for the objects of interest are already available, there is potential to avoid the cumbersome annotation process. Unfortunately, GPS coordinates are often not well-aligned with georectified imagery. These spatial errors can be seen as noise regarding the object locations, which may critically harm the training of object detectors and, ultimately, limit their practical applicability. To overcome this issue, we propose a co-correction technique that allows us to robustly train a neural network with noisy object locations and to transform them toward the true locations. When applied as a preprocessing step on noisy annotations, our method greatly improves the performance of existing object detectors. Our method is applicable in scenarios where the images are only annotated with points roughly indicating object locations, instead of entire bounding boxes providing precise information on the object locations and extents. We test our method on three datasets and achieve a substantial improvement (e.g., 29.6% mAP on the COWC dataset) over existing methods for noise-robust object detection.
KW  - object detection
KW  - GPS labels
KW  - spatial errors
KW  - label correction
KW  - aerial images
DO  - 10.3390/rs13244962
ER  -
TY  - EJOU
AU  - Sharma, Teena
AU  - Chehri, Abdellah
AU  - Fortier, Paul
TI  - Reconfigurable Intelligent Surfaces for 5G and beyond Wireless Communications: A Comprehensive Survey
T2  - Energies

PY  - 2021
VL  - 14
IS  - 24
SN  - 1996-1073

AB  - With possible new use cases and demanding requirements of future 5th generation (5G) and beyond cellular networks, the future of mobile communications sounds promising. However, the propagation medium has been considered a randomly acting agent between the transmitter and the receiver. With the advent of the digital age of wireless communications, the received signal quality is degrading due to the uncontrollable interactions of the transmitted radio waves with the surrounding artifacts. This paper presents a comprehensive literature review on reconfigurable intelligent surfaces (RISs) and assisted application areas. With the RIS, the network operators can control radio waves&rsquo; scattering, reflection, and refraction characteristics by resolving the harmful properties of environmental wireless propagation. Further, the RIS can effectively control the wavefront, such as amplitude, phase, frequency, and even polarization, without requiring complex encoding, decoding, or radio wave processing techniques. Motivated by technological advances, the metasurfaces, reflectarrays, phase shift, and liquid crystals are potential candidates for implementing RIS. Thus, they can be considered the front runner for realizing the 5G and beyond network. Furthermore, the current research activities in the evolving field of wireless networks operated by RIS are reviewed and discussed thoroughly. Finally, to fully explore the potential of RISs in wireless networks, the fundamental research issues to be addressed have been discussed.
KW  - meta-surfaces
KW  - 5G
KW  - line-of-sight
KW  - reconfigurable intelligent surfaces
KW  - liquid crystal
KW  - field programmable gate arrays
KW  - smart reflect-arrays
KW  - wireless communications
DO  - 10.3390/en14248219
ER  -
TY  - EJOU
AU  - Fan, Dongliang
AU  - Su, Xiaoyun
AU  - Weng, Bo
AU  - Wang, Tianshu
AU  - Yang, Feiyun
TI  - Research Progress on Remote Sensing Classification Methods for Farmland Vegetation
T2  - AgriEngineering

PY  - 2021
VL  - 3
IS  - 4
SN  - 2624-7402

AB  - Crop planting area and spatial distribution information have important practical significance for food security, global change, and sustainable agricultural development. How to efficiently and accurately identify crops in a timely manner by remote sensing in order to determine the crop planting area and its temporal&ndash;spatial dynamic change information is a core issue of monitoring crop growth and estimating regional crop yields. Based on hundreds of relevant documents from the past 25 years, in this paper, we summarize research progress in relation to farmland vegetation identification and classification by remote sensing. The classification and identification of farmland vegetation includes classification based on vegetation index, spectral bands, multi-source data fusion, artificial intelligence learning, and drone remote sensing. Representative studies of remote sensing methods are collated, the main content of each technology is summarized, and the advantages and disadvantages of each method are analyzed. Current problems related to crop remote sensing identification are then identified and future development directions are proposed.
KW  - agriculture
KW  - food security
KW  - remote sensing
KW  - farmland vegetation
KW  - identification
KW  - classification
DO  - 10.3390/agriengineering3040061
ER  -
TY  - EJOU
AU  - Kilwenge, Regina
AU  - Adewopo, Julius
AU  - Sun, Zhanli
AU  - Schut, Marc
TI  - UAV-Based Mapping of Banana Land Area for Village-Level Decision-Support in Rwanda
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - Crop monitoring is crucial to understand crop production changes, agronomic practice decision-support, pests/diseases mitigation, and developing climate change adaptation strategies. Banana, an important staple food and cash crop in East Africa, is threatened by Banana Xanthomonas Wilt (BXW) disease. Yet, there is no up-to-date information about the spatial distribution and extent of banana lands, especially in Rwanda, where banana plays a key role in food security and livelihood. Therefore, delineation of banana-cultivated lands is important to prioritize resource allocation for optimal productivity. We mapped the spatial extent of smallholder banana farmlands by acquiring and processing high-resolution (25 cm/px) multispectral unmanned aerial vehicles (UAV) imageries, across four villages in Rwanda. Georeferenced ground-truth data on different land cover classes were combined with reflectance data and vegetation indices (NDVI, GNDVI, and EVI2) and compared using pixel-based supervised multi-classifiers (support vector models-SVM, classification and regression trees-CART, and random forest&ndash;RF), based on varying ground-truth data richness. Results show that RF consistently outperformed other classifiers regardless of data richness, with overall accuracy above 95%, producer&rsquo;s/user&rsquo;s accuracies above 92%, and kappa coefficient above 0.94. Estimated banana farmland areal coverage provides concrete baseline for extension-delivery efforts in terms of targeting banana farmers relative to their scale of production, and highlights opportunity to combine UAV-derived data with machine-learning methods for rapid landcover classification.
KW  - Rwanda
KW  - banana
KW  - machine learning
KW  - UAV
KW  - remote sensing
KW  - land cover mapping
KW  - precision agriculture
KW  - food security
KW  - BXW
DO  - 10.3390/rs13244985
ER  -
TY  - EJOU
AU  - Takayama, Yusuke
AU  - Ratsamee, Photchara
AU  - Mashita, Tomohiro
TI  - Reduced Simulation: Real-to-Sim Approach toward Collision Detection in Narrowly Confined Environments
T2  - Robotics

PY  - 2021
VL  - 10
IS  - 4
SN  - 2218-6581

AB  - Recently, several deep-learning based navigation methods have been achieved because of a high quality dataset collected from high-quality simulated environments. However, the cost of creating high-quality simulated environments is high. In this paper, we present a concept of the reduced simulation, which can serve as a simplified version of a simulated environment yet be efficient enough for training deep-learning based UAV collision avoidance approaches. Our approach deals with the reality gap between a reduced simulation dataset and real world dataset and can provide a clear guideline for reduced simulation design. Our experimental result confirmed that the reduction in visual features provided by textures and lighting does not affect operating performance with the user study. Moreover, by conducting collision detection experiments, we verified that our reduced simulation outperforms the conventional cost-effective simulations in adaptation capability with respect to realistic simulation and real-world scenario.
KW  - reduced simulation
KW  - collision detection
KW  - micro aerial vehicles
DO  - 10.3390/robotics10040131
ER  -
TY  - EJOU
AU  - Layton, Oliver W.
TI  - ARTFLOW: A Fast, Biologically Inspired Neural Network that Learns Optic Flow Templates for Self-Motion Estimation
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 24
SN  - 1424-8220

AB  - Most algorithms for steering, obstacle avoidance, and moving object detection rely on accurate self-motion estimation, a problem animals solve in real time as they navigate through diverse environments. One biological solution leverages optic flow, the changing pattern of motion experienced on the eye during self-motion. Here I present ARTFLOW, a biologically inspired neural network that learns patterns in optic flow to encode the observer&rsquo;s self-motion. The network combines the fuzzy ART unsupervised learning algorithm with a hierarchical architecture based on the primate visual system. This design affords fast, local feature learning across parallel modules in each network layer. Simulations show that the network is capable of learning stable patterns from optic flow simulating self-motion through environments of varying complexity with only one epoch of training. ARTFLOW trains substantially faster and yields self-motion estimates that are far more accurate than a comparable network that relies on Hebbian learning. I show how ARTFLOW serves as a generative model to predict the optic flow that corresponds to neural activations distributed across the network.
KW  - optic flow
KW  - heading
KW  - self-motion
KW  - neural decoding
KW  - adaptive resonance theory
KW  - vision
KW  - biologically inspired
KW  - neural network
DO  - 10.3390/s21248217
ER  -
TY  - EJOU
AU  - Li, Zhipeng
AU  - Ding, Jie
AU  - Zhang, Heyu
AU  - Feng, Yiming
TI  - Classifying Individual Shrub Species in UAV Images&mdash;A Case Study of the Gobi Region of Northwest China
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - Shrublands are the main vegetation component in the Gobi region and contribute considerably to its ecosystem. Accurately classifying individual shrub vegetation species to understand their spatial distributions and to effectively monitor species diversity in the Gobi ecosystem is essential. High-resolution remote sensing data create vegetation type inventories over large areas. However, high spectral similarity between shrublands and surrounding areas remains a challenge. In this study, we provide a case study that integrates object-based image analysis (OBIA) and the random forest (RF) model to classify shrubland species automatically. The Gobi region on the southern slope of the Tian Shan Mountains in Northwest China was analyzed using readily available unmanned aerial vehicle (UAV) RGB imagery (1.5 cm spatial resolution). Different spectral and texture index images were derived from UAV RGB images as variables for species classification. Principal component analysis (PCA) extracted features from different types of variable sets (original bands, original bands + spectral indices, and original bands + spectral indices + texture indices). We tested the ability of several non-parametric decision tree models and different types of variable sets to classify shrub species. Moreover, we analyzed three main shrubland areas comprising different shrub species and compared the prediction accuracies of the optimal model in combination with different types of variable sets. We found that the RF model could generate higher accuracy compared with the other two models. The best results were obtained using a combination of the optimal variable set and the RF model with an 88.63% overall accuracy and 0.82 kappa coefficient. Integrating OBIA and RF in the species classification process provides a promising method for automatic mapping of individual shrub species in the Gobi region and can reduce the workload of individual shrub species classification.
KW  - shrub species classification
KW  - unmanned aerial vehicle
KW  - RGB image
KW  - object-based image analysis
KW  - spectral indices
KW  - texture indices
DO  - 10.3390/rs13244995
ER  -
TY  - EJOU
AU  - Al-Absi, Mohammed A.
AU  - Fu, Rui
AU  - Kim, Ki-Hwan
AU  - Lee, Young-Sil
AU  - Al-Absi, Ahmed A.
AU  - Lee, Hoon-Jae
TI  - Tracking Unmanned Aerial Vehicles Based on the Kalman Filter Considering Uncertainty and Error Aware
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 24
SN  - 2079-9292

AB  - Recently, Unmanned Aerial Vehicles (UAVs) have made significant impacts on our daily lives with the advancement of technologies and their applications. Tracking UAVs have become more important because they not only provide location-based services, but are also faced with serious security threats and vulnerabilities. UAVs are smaller in nature, move with high speed, and operate in a low-altitude environment, which makes it conceivable to track UAVs using fixed or mobile radars. Kalman Filter (KF)-based methodologies are widely used for extracting valuable trajectory information from samples composed of noisy information. As UAVs&rsquo; trajectories resemble uncertain behavior, the traditional KF-based methodologies have poor tracking accuracy. Recently, the Diffusion-Map-based KF (DMK) was introduced for modeling uncertainties in the environment without prior knowledge. However, the model has poor accuracy when operating in environments with higher noise. In order to achieve better tracking performance, this paper presents the Uncertainty and Error-Aware KF (UEAKF) for tracking UAVs. The UEAKF-based tracking method provides a good tradeoff among preceding estimate confidence and forthcoming measurement under dynamic environments; the resulting filter is robust and nonlinear in nature. The experimental results showed that the UEAKF-based UAV tracking model achieves much better Root Mean Square Error (RMSE) performance compared to the existing particle filter-based and DMK-based UAV tracking models.
KW  - Kalman filter
KW  - non-parametric filtering
KW  - security
KW  - stochastic environment
KW  - tracking
KW  - unmanned aerial vehicle
DO  - 10.3390/electronics10243067
ER  -
TY  - EJOU
AU  - Gardiner, Laura-Jayne
AU  - Krishna, Ritesh
TI  - Bluster or Lustre: Can AI Improve Crops and Plant Health?
T2  - Plants

PY  - 2021
VL  - 10
IS  - 12
SN  - 2223-7747

AB  - In a changing climate where future food security is a growing concern, researchers are exploring new methods and technologies in the effort to meet ambitious crop yield targets. The application of Artificial Intelligence (AI) including Machine Learning (ML) methods in this area has been proposed as a potential mechanism to support this. This review explores current research in the area to convey the state-of-the-art as to how AI/ML have been used to advance research, gain insights, and generally enable progress in this area. We address the question&mdash;Can AI improve crops and plant health? We further discriminate the bluster from the lustre by identifying the key challenges that AI has been shown to address, balanced with the potential issues with its usage, and the key requisites for its success. Overall, we hope to raise awareness and, as a result, promote usage, of AI related approaches where they can have appropriate impact to improve practices in agricultural and plant sciences.
KW  - AI
KW  - machine learning
KW  - crops
KW  - plant HEALTH
KW  - omics
KW  - disruptive technologies
DO  - 10.3390/plants10122707
ER  -
TY  - EJOU
AU  - Ma, Minfei
AU  - Liu, Jianhong
AU  - Liu, Mingxing
AU  - Zeng, Jingchao
AU  - Li, Yuanhui
TI  - Tree Species Classification Based on Sentinel-2 Imagery and Random Forest Classifier in the Eastern Regions of the Qilian Mountains
T2  - Forests

PY  - 2021
VL  - 12
IS  - 12
SN  - 1999-4907

AB  - Obtaining accurate forest coverage of tree species is an important basis for the rational use and protection of existing forest resources. However, most current studies have mainly focused on broad tree classification, such as coniferous vs. broadleaf tree species, and a refined tree classification with tree species information is urgently needed. Although airborne LiDAR data or unmanned aerial vehicle (UAV) images can be used to acquire tree information even at the single tree level, this method will encounter great difficulties when applied to a large area. Therefore, this study takes the eastern regions of the Qilian Mountains as an example to explore the possibility of tree species classification with satellite-derived images. We used Sentinel-2 images to classify the study area&rsquo;s major vegetation types, particularly four tree species, i.e., Sabina przewalskii (S.P.), Picea crassifolia (P.C.), Betula spp. (Betula), and Populus spp. (Populus). In addition to the spectral features, we also considered terrain and texture features in this classification. The results show that adding texture features can significantly increase the separation between tree species. The final classification result of all categories achieved an accuracy of 86.49% and a Kappa coefficient of 0.83. For trees, the classification accuracy was 90.31%, and their producer&rsquo;s accuracy (PA) and user&rsquo;s (UA) were all higher than 84.97%. We found that altitude, slope, and aspect all affected the spatial distribution of these four tree species in our study area. This study confirms the potential of Sentinel-2 images for the fine classification of tree species. Moreover, this can help monitor ecosystem biological diversity and provide references for inventory estimation.
KW  - Sentinel-2 image
KW  - random forest
KW  - tree species
KW  - vegetation classification
DO  - 10.3390/f12121736
ER  -
TY  - EJOU
AU  - Shinde, Swapnil S.
AU  - Tarchi, Daniele
TI  - Towards a Novel Air&ndash;Ground Intelligent Platform for Vehicular Networks: Technologies, Scenarios, and Challenges
T2  - Smart Cities

PY  - 2021
VL  - 4
IS  - 4
SN  - 2624-6511

AB  - Modern cities require a tighter integration with Information and Communication Technologies (ICT) for bringing new services to the citizens. The Smart City is the revolutionary paradigm aiming at integrating the ICT with the citizen life; among several urban services, transports are one of the most important in modern cities, introducing several challenges to the Smart City paradigm. In order to satisfy the stringent requirements of new vehicular applications and services, Edge Computing (EC) is one of the most promising technologies when integrated into the Vehicular Networks (VNs). EC-enabled VNs can facilitate new latency-critical and data-intensive applications and services. However, ground-based EC platforms (i.e., Road Side Units&mdash;RSUs, 5G Base Stations&mdash;5G BS) can only serve a reduced number of Vehicular Users (VUs), due to short coverage ranges and resource shortage. In the recent past, several new aerial platforms with integrated EC facilities have been deployed for achieving global connectivity. Such air-based EC platforms can complement the ground-based EC facilities for creating a futuristic VN able to deploy several new applications and services. The goal of this work is to explore the possibility of creating a novel joint air-ground EC platform within a VN architecture for helping VUs with new intelligent applications and services. By exploiting most modern technologies, with particular attention towards network softwarization, vehicular edge computing, and machine learning, we propose here three possible layered air-ground EC-enabled VN scenarios. For each of the discussed scenarios, a list of the possible challenges is considered, as well possible solutions allowing to overcome all or some of the considered challenges. A proper comparison is also done, through the use of tables, where all the proposed scenarios, and the proposed solutions, are discussed.
KW  - smart cities
KW  - vehicular networks
KW  - edge computing
KW  - machine learning
KW  - network softwarization
KW  - aerial platforms
DO  - 10.3390/smartcities4040078
ER  -
TY  - EJOU
AU  - Liao, Xinting
AU  - Lv, Shengping
AU  - Li, Denghui
AU  - Luo, Yong
AU  - Zhu, Zichun
AU  - Jiang, Cheng
TI  - YOLOv4-MN3 for PCB Surface Defect Detection
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 24
SN  - 2076-3417

AB  - Surface defect detection for printed circuit board (PCB) is indispensable for managing PCB production quality. However, automatic detection of PCB surface defects is still a challenging task because, even within the same category of surface defect, defects present great differences in morphology and pattern. Although many computer vision-based detectors have been established to handle these problems, current detectors struggle to achieve high detection accuracy, fast detection speed and low memory consumption simultaneously. To address those issues, we propose a cost-effective deep learning (DL)-based detector based on the cutting-edge YOLOv4 to detect PCB surface defect quickly and efficiently. The YOLOv4 is improved upon with respect to its backbone network and the activation function in its neck/prediction network. The improved YOLOv4 is evaluated with a customized dataset, collected from a PCB factory. The experimental results show that the improved detector achieved a high performance, scoring 98.64% on mean average precision (mAP) at 56.98 frames per second (FPS), outperforming the other compared SOTA detectors. Furthermore, the improved YOLOv4 reduced the parameter space of YOLOv4 from 63.96 M to 39.59 M and the number of multiply-accumulate operations (Madds) from 59.75 G to 26.15 G.
KW  - printed circuit board
KW  - surface defect detection
KW  - YOLOv4
KW  - MobileNetV3
DO  - 10.3390/app112411701
ER  -
TY  - EJOU
AU  - Wang, Libo
AU  - Zhang, Ce
AU  - Li, Rui
AU  - Duan, Chenxi
AU  - Meng, Xiaoliang
AU  - Atkinson, Peter M.
TI  - Scale-Aware Neural Network for Semantic Segmentation of Multi-Resolution Remote Sensing Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - Assigning geospatial objects with specific categories at the pixel level is a fundamental task in remote sensing image analysis. Along with the rapid development of sensor technologies, remotely sensed images can be captured at multiple spatial resolutions (MSR) with information content manifested at different scales. Extracting information from these MSR images represents huge opportunities for enhanced feature representation and characterisation. However, MSR images suffer from two critical issues: (1) increased scale variation of geo-objects and (2) loss of detailed information at coarse spatial resolutions. To bridge these gaps, in this paper, we propose a novel scale-aware neural network (SaNet) for the semantic segmentation of MSR remotely sensed imagery. SaNet deploys a densely connected feature network (DCFFM) module to capture high-quality multi-scale context, such that the scale variation is handled properly and the quality of segmentation is increased for both large and small objects. A spatial feature recalibration (SFRM) module was further incorporated into the network to learn intact semantic content with enhanced spatial relationships, where the negative effects of information loss are removed. The combination of DCFFM and SFRM allows SaNet to learn scale-aware feature representation, which outperforms the existing multi-scale feature representation. Extensive experiments on three semantic segmentation datasets demonstrated the effectiveness of the proposed SaNet in cross-resolution segmentation.
KW  - deep convolutional neural network
KW  - multiple spatial resolutions
KW  - remote sensing
KW  - scale-aware feature representation
KW  - semantic segmentation
DO  - 10.3390/rs13245015
ER  -
TY  - EJOU
AU  - Balestrieri, Eulalia
AU  - Daponte, Pasquale
AU  - De Vito, Luca
AU  - Picariello, Francesco
AU  - Tudosa, Ioan
TI  - Sensors and Measurements for UAV Safety: An Overview
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 24
SN  - 1424-8220

AB  - Unmanned aerial vehicles&rsquo; (UAVs) safety has gained great research interest due to the increase in the number of UAVs in circulation and their applications, which has inevitably also led to an increase in the number of accidents in which these vehicles are involved. The paper presents a classification of UAV safety solutions that can be found in the scientific literature, putting in evidence the fundamental and critical role of sensors and measurements in the field. Proposals from research on each proposed class concerning flight test procedures, in-flight solutions including soft propeller use, fault and damage detection, collision avoidance and safe landing, as well as ground solution including testing and injury and damage quantification measurements are discussed.
KW  - UAV
KW  - safety
KW  - design
KW  - testing
KW  - diagnosis
KW  - sense and avoid
KW  - sensors
KW  - challenges
DO  - 10.3390/s21248253
ER  -
TY  - EJOU
AU  - Lee, Seokwon
AU  - Ban, Inmo
AU  - Lee, Myeongjin
AU  - Jung, Yunho
AU  - Lee, Wookyung
TI  - Architecture Exploration of a Backprojection Algorithm for Real-Time Video SAR
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 24
SN  - 1424-8220

AB  - This paper explores novel architectures for fast backprojection based video synthetic aperture radar (BP-VISAR) with multiple GPUs. The video SAR frame rate is analyzed for non-overlapped and overlapped aperture modes. For the parallelization of the backprojection process, a processing data unit is defined as the phase history data or range profile data from partial synthetic-apertures divided from the full resolution target data. Considering whether full-aperture processing is performed and range compression or backprojection are parallelized on a GPU basis, we propose six distinct architectures, each having a single-stream pipeline with a single GPU. The performance of these architectures is evaluated in both non-overlapped and overlapped modes. The efficiency of the BP-VISAR architecture with sub-aperture processing in the overlapped mode is accelerated further by filling the processing gap from the idling GPU resources with multi-stream based backprojection on multiple GPUs. The frame rate of the proposed BP-VISAR architecture with sub-aperture processing is scalable with the number of GPU devices for large pixel resolution. It can generate 4096 &times; 4096 video SAR frames of 0.5 m cross-range resolution in 23.0 Hz on a single GPU and 73.5 Hz on quad GPUs.
KW  - synthetic aperture radar
KW  - SAR
KW  - video SAR
KW  - backprojection
KW  - sub-aperture processing
KW  - overlapped aperture mode
DO  - 10.3390/s21248258
ER  -
TY  - EJOU
AU  - Damaševičius, Robertas
AU  - Maskeliūnas, Rytis
TI  - Agent State Flipping Based Hybridization of Heuristic Optimization Algorithms: A Case of Bat Algorithm and Krill Herd Hybrid Algorithm
T2  - Algorithms

PY  - 2021
VL  - 14
IS  - 12
SN  - 1999-4893

AB  - This paper describes a unique meta-heuristic technique for hybridizing bio-inspired heuristic algorithms. The technique is based on altering the state of agents using a logistic probability function that is dependent on an agent&rsquo;s fitness rank. An evaluation using two bio-inspired algorithms (bat algorithm (BA) and krill herd (KH)) and 12 optimization problems (cross-in-tray, rotated hyper-ellipsoid (RHE), sphere, sum of squares, sum of different powers, McCormick, Zakharov, Rosenbrock, De Jong No. 5, Easom, Branin, and Styblinski&ndash;Tang) is presented. Furthermore, an experimental evaluation of the proposed scheme using the industrial three-bar truss design problem is presented. The experimental results demonstrate that the hybrid scheme outperformed the baseline algorithms (mean rank for the hybrid BA-KH algorithm is 1.279 vs. 1.958 for KH and 2.763 for BA).
KW  - hyper-heuristic
KW  - meta-heuristic
KW  - bio-inspired algorithms
KW  - heuristic optimization
DO  - 10.3390/a14120358
ER  -
TY  - EJOU
AU  - Kapassa, Evgenia
AU  - Themistocleous, Marinos
AU  - Christodoulou, Klitos
AU  - Iosif, Elias
TI  - Blockchain Application in Internet of Vehicles: Challenges, Contributions and Current Limitations
T2  - Future Internet

PY  - 2021
VL  - 13
IS  - 12
SN  - 1999-5903

AB  - Blockchain technology is highly coupled with cryptocurrencies; however, it provides several other potential use cases, related to energy and sustainability, Internet of Things (IoT), smart cities, smart mobility and more. Blockchain can offer security for Electric Vehicle (EV) transactions in the Internet of Vehicles (IoV) concept, allowing electricity trading to be performed in a decentralized, transparent and secure way. Additionally, blockchain provides the necessary functionalities for IoV decentralized application development, such as data exchange, personal digital identity, sharing economy and optimized charging pattern. Moreover, blockchain technology has the potential to significantly increase energy efficiency, decrease management costs and guarantee the effective use of the energy recourses. Therefore, its application in the IoV concept provides secure, autonomous and automated energy trading between EVs. While several studies on blockchain technology in smart grids have been conducted, insufficient attention has been given to conducting a detailed review and state-of-the-art analysis of blockchain application in the IoV domain. To this end, this work provides a systematic literature review of blockchain-based applications in the IoV domain. The aim is to investigate the current challenges of IoV and to highlight how blockchain characteristics can contribute to this emerging paradigm. In addition, limitations and future research directions related to the integration of blockchain technology within the IoV are discussed. To this end, this study incorporates the theoretical foundations of several research articles published in scientific publications over the previous five years, as a method of simplifying our assessment and capturing the ever-expanding blockchain area. We present a comprehensive taxonomy of blockchain-enabled applications in the IoV domain, such as privacy and security, data protection and management, vehicle management, charging optimization and P2P energy trading, based on a structured, systematic review and content analysis of the discovered literature, and we identify key trends and emerging areas for research. The contribution of this article is two-fold: (a) we highlight the limitations presented in the relevant literature, particularly the barriers of blockchain technology and how they influence its integration into the IoV and (b) we present a number of research gaps and suggest future exploratory areas.
KW  - blockchain
KW  - Internet of Vehicles
KW  - Electric Vehicles
KW  - opportunities
KW  - limitations
KW  - systematic literature review
DO  - 10.3390/fi13120313
ER  -
TY  - EJOU
AU  - Agapiou, Athos
AU  - Vionis, Athanasios
AU  - Papantoniou, Giorgos
TI  - Detection of Archaeological Surface Ceramics Using Deep Learning Image-Based Methods and Very High-Resolution UAV Imageries
T2  - Land

PY  - 2021
VL  - 10
IS  - 12
SN  - 2073-445X

AB  - Mapping surface ceramics through systematic pedestrian archaeological survey is considered a consistent method to recover the cultural biography of sites within a micro-region. Archaeologists nowadays conduct surface survey equipped with navigation devices counting, documenting, and collecting surface archaeological potsherds within a set of plotted grids. Recent advancements in unmanned aerial vehicles (UAVs) and image processing analysis can be utilised to support such surface archaeological investigations. In this study, we have implemented two different artificial intelligence image processing methods over two areas of interest near the present-day village of Kophinou in Cyprus, in the Xeros River valley. We have applied a random forest classifier through the Google Earth Engine big data cloud platform and a Single Shot Detector neural network in the ArcGIS Pro environment. For the first case study, the detection was based on red&ndash;green&ndash;blue (RGB) high-resolution orthophotos. In contrast, a multispectral camera covering both the visible and the near-infrared parts of the spectrum was used in the second area of investigation. The overall results indicate that such an approach can be used in the future as part of ongoing archaeological pedestrian surveys to detect scattered potsherds in areas of archaeological interest, even if pottery shares a very high spectral similarity with the surface.
KW  - potsherds
KW  - detection
KW  - pedestrian survey
KW  - remote sensing archaeology
KW  - single shot detector
KW  - artificial intelligence
KW  - random forest
KW  - Google Earth Engine
KW  - Cyprus
DO  - 10.3390/land10121365
ER  -
TY  - EJOU
AU  - Pan, Jiao
AU  - Li, Liang
AU  - Yamaguchi, Hiroshi
AU  - Hasegawa, Kyoko
AU  - Thufail, Fadjar I.
AU  - Brahmantara
AU  - Tanaka, Satoshi
TI  - Integrated High-Definition Visualization of Digital Archives for Borobudur Temple
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - The preservation and analysis of tangible cultural heritage sites have attracted enormous interest worldwide. Recently, establishing three-dimensional (3D) digital archives has emerged as a critical strategy for the permanent preservation and digital analysis of cultural sites. For extant parts of cultural sites, 3D scanning is widely used for efficient and accurate digitization. However, in many historical sites, many parts that have been damaged or lost by natural or artificial disasters are unavailable for 3D scanning. The remaining available data sources for these destroyed parts are photos, computer-aided design (CAD) drawings, written descriptions, etc. In this paper, we achieve an integrated digital archive of a UNESCO World Heritage site, namely, the Borobudur temple, in which buried reliefs and internal foundations are not available for 3D scanning. We introduce a digitizing framework to integrate three different kinds of data sources and to create a unified point-cloud-type digital archive. This point-based integration enables us to digitally record the entire 3D structure of the target cultural heritage site. Then, the whole site is visualized by stochastic point-based rendering (SPBR) precisely and comprehensibly. The proposed framework is widely applicable to other large-scale cultural sites.
KW  - cultural heritage
KW  - digital archive
KW  - 3D reconstruction
KW  - transparent visualization
KW  - the Borobudur temple
DO  - 10.3390/rs13245024
ER  -
TY  - EJOU
AU  - Liu, Wenjian
AU  - Li, Yanjie
AU  - Liu, Jun
AU  - Jiang, Jingmin
TI  - Estimation of Plant Height and Aboveground Biomass of Toona sinensis under Drought Stress Using RGB-D Imaging
T2  - Forests

PY  - 2021
VL  - 12
IS  - 12
SN  - 1999-4907

AB  - Rapid and accurate plant growth and biomass estimation is essential for formulating and implementing targeted forest cultivation measures. In this study, RGB-D imaging technology was used to obtain the RGB and depth imaging data for a Toona sinensis seedling canopy to estimate plant growth and aboveground biomass (AGB). Three hundred T. sinensis seedlings from 20 varieties were planted under five different drought stress treatments. The U-Net model was applied first to achieve highly accurate segmentation of plants from complex backgrounds. Simple linear regression (SLR) was used for plant height prediction, and the other three models, including multivariate linear (ML), random forest (RF) and multilayer perceptron (MLP) regression, were applied to predict the AGB and compared for optimal model selection. The results showed that the SLR model yields promising and reliable results for the prediction of plant height, with R2 and RMSE values of 0.72 and 1.89 cm, respectively. All three regression methods perform well in the prediction of AGB estimation. MLP yields the highest accuracy in predicting dry and fresh aboveground biomass compared to the other two regression models, with R2 values of 0.77 and 0.83, respectively. The combination of Gray, Green minus red (GMR) and Excess green index (ExG) was identified as the key predictor by RReliefF for predicting dry AGB. GMR was the most important in predicting fresh AGB. This study demonstrated that the merits of RGB-D and machine learning models are effective phenotyping techniques for plant height and AGB prediction, and can be used to assist dynamic responses to drought stress for breeding selection.
KW  - RGB-D imaging
KW  - Toona sinensis seedling
KW  - aboveground biomass
KW  - plant height
KW  - machine learning
DO  - 10.3390/f12121747
ER  -
TY  - EJOU
AU  - Jozdani, Shahab
AU  - Chen, Dongmei
AU  - Chen, Wenjun
AU  - Leblanc, Sylvain G.
AU  - Lovitt, Julie
AU  - He, Liming
AU  - Fraser, Robert H.
AU  - Johnson, Brian A.
TI  - Evaluating Image Normalization via GANs for Environmental Mapping: A Case Study of Lichen Mapping Using High-Resolution Satellite Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - Illumination variations in non-atmospherically corrected high-resolution satellite (HRS) images acquired at different dates/times/locations pose a major challenge for large-area environmental mapping and monitoring. This problem is exacerbated in cases where a classification model is trained only on one image (and often limited training data) but applied to other scenes without collecting additional samples from these new images. In this research, by focusing on caribou lichen mapping, we evaluated the potential of using conditional Generative Adversarial Networks (cGANs) for the normalization of WorldView-2 (WV2) images of one area to a source WV2 image of another area on which a lichen detector model was trained. In this regard, we considered an extreme case where the classifier was not fine-tuned on the normalized images. We tested two main scenarios to normalize four target WV2 images to a source 50 cm pansharpened WV2 image: (1) normalizing based only on the WV2 panchromatic band, and (2) normalizing based on the WV2 panchromatic band and Sentinel-2 surface reflectance (SR) imagery. Our experiments showed that normalizing even based only on the WV2 panchromatic band led to a significant lichen-detection accuracy improvement compared to the use of original pansharpened target images. However, we found that conditioning the cGAN on both the WV2 panchromatic band and auxiliary information (in this case, Sentinel-2 SR imagery) further improved normalization and the subsequent classification results due to adding a more invariant source of information. Our experiments showed that, using only the panchromatic band, F1-score values ranged from 54% to 88%, while using the fused panchromatic and SR, F1-score values ranged from 75% to 91%.
KW  - remote sensing
KW  - GANs
KW  - image normalization
KW  - deep learning
KW  - lichen mapping
KW  - environmental mapping
DO  - 10.3390/rs13245035
ER  -
TY  - EJOU
AU  - Yazid, Yassine
AU  - Ez-Zazi, Imad
AU  - Guerrero-González, Antonio
AU  - El Oualkadi, Ahmed
AU  - Arioua, Mounir
TI  - UAV-Enabled Mobile Edge-Computing for IoT Based on AI: A Comprehensive Review
T2  - Drones

PY  - 2021
VL  - 5
IS  - 4
SN  - 2504-446X

AB  - Unmanned aerial vehicles (UAVs) are becoming integrated into a wide range of modern IoT applications. The growing number of networked IoT devices generates a large amount of data. However, processing and memorizing this massive volume of data at local nodes have been deemed critical challenges, especially when using artificial intelligence (AI) systems to extract and exploit valuable information. In this context, mobile edge computing (MEC) has emerged as a way to bring cloud computing (CC) processes within reach of users, to address computation-intensive offloading and latency issues. This paper provides a comprehensive review of the most relevant research works related to UAV technology applications in terms of enabled or assisted MEC architectures. It details the utility of UAV-enabled MEC architecture regarding emerging IoT applications and the role of both deep learning (DL) and machine learning (ML) in meeting various limitations related to latency, task offloading, energy demand, and security. Furthermore, throughout this article, the reader gains an insight into the future of UAV-enabled MEC, the advantages and the critical challenges to be tackled when using AI.
KW  - UAVs
KW  - IoT
KW  - cloud computing
KW  - edge computing
KW  - MEC
KW  - AI
KW  - review
DO  - 10.3390/drones5040148
ER  -
TY  - EJOU
AU  - Diro, Abebe
AU  - Chilamkurti, Naveen
AU  - Nguyen, Van-Doan
AU  - Heyne, Will
TI  - A Comprehensive Study of Anomaly Detection Schemes in IoT Networks Using Machine Learning Algorithms
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 24
SN  - 1424-8220

AB  - The Internet of Things (IoT) consists of a massive number of smart devices capable of data collection, storage, processing, and communication. The adoption of the IoT has brought about tremendous innovation opportunities in industries, homes, the environment, and businesses. However, the inherent vulnerabilities of the IoT have sparked concerns for wide adoption and applications. Unlike traditional information technology (I.T.) systems, the IoT environment is challenging to secure due to resource constraints, heterogeneity, and distributed nature of the smart devices. This makes it impossible to apply host-based prevention mechanisms such as anti-malware and anti-virus. These challenges and the nature of IoT applications call for a monitoring system such as anomaly detection both at device and network levels beyond the organisational boundary. This suggests an anomaly detection system is strongly positioned to secure IoT devices better than any other security mechanism. In this paper, we aim to provide an in-depth review of existing works in developing anomaly detection solutions using machine learning for protecting an IoT system. We also indicate that blockchain-based anomaly detection systems can collaboratively learn effective machine learning models to detect anomalies.
KW  - cybersecurity
KW  - anomaly detection
KW  - the Internet of Things
KW  - machine learning
KW  - deep learning
KW  - blockchain
DO  - 10.3390/s21248320
ER  -
TY  - EJOU
AU  - Mousa, Mohammed A.
AU  - Yussof, Mustafasanie M.
AU  - Udi, Ufuoma J.
AU  - Nazri, Fadzli M.
AU  - Kamarudin, Mohd K.
AU  - Parke, Gerard A. R.
AU  - Assi, Lateef N.
AU  - Ghahari, Seyed A.
TI  - Application of Digital Image Correlation in Structural Health Monitoring of Bridge Infrastructures: A Review
T2  - Infrastructures

PY  - 2021
VL  - 6
IS  - 12
SN  - 2412-3811

AB  - A vision-based approach has been employed in Structural Health Monitoring (SHM) of bridge infrastructure. The approach has many advantages: non-contact, non-destructive, long-distance, high precision, immunity from electromagnetic interference, and multiple-target monitoring. This review aims to summarise the vision- and Digital Image Correlation (DIC)-based SHM methods for bridge infrastructure because of their strategic significance and security concerns. Four different bridge types were studied: concrete, suspension, masonry, and steel bridge. DIC applications in SHM have recently garnered attention in aiding to assess the bridges&rsquo; structural response mechanisms under loading. Different non-destructive diagnostics methods for SHM in civil infrastructure have been used; however, vision-based techniques like DIC were only developed over the last two decades, intending to facilitate damage detection in bridge systems with prompt and accurate data for efficient and sustainable operation of the bridge structure throughout its service life. Research works reviewed in this article demonstrated the DIC capability to detect damage such as cracks, spalling, and structural parameters such as deformation, strains, vibration, deflection, and rotation. In addition, the reviewed works indicated that the DIC as an efficient and reliable technique could provide sustainable monitoring solutions for different bridge infrastructures.
KW  - bridges
KW  - digital image correlation (DIC)
KW  - vision-based method
KW  - structural health monitoring (SHM)
DO  - 10.3390/infrastructures6120176
ER  -
TY  - EJOU
AU  - Pathmakumar, Thejus
AU  - Elara, Mohan R.
AU  - Gómez, Braulio F.
AU  - Ramalingam, Balakrishnan
TI  - A Reinforcement Learning Based Dirt-Exploration for Cleaning-Auditing Robot
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 24
SN  - 1424-8220

AB  - Cleaning is one of the fundamental tasks with prime importance given in our day-to-day life. Moreover, the importance of cleaning drives the research efforts towards bringing leading edge technologies, including robotics, into the cleaning domain. However, an effective method to assess the quality of cleaning is an equally important research problem to be addressed. The primary footstep towards addressing the fundamental question of &ldquo;How clean is clean&rdquo; is addressed using an autonomous cleaning-auditing robot that audits the cleanliness of a given area. This research work focuses on a novel reinforcement learning-based experience-driven dirt exploration strategy for a cleaning-auditing robot. The proposed approach uses proximal policy approximation (PPO) based on-policy learning method to generate waypoints and sampling decisions to explore the probable dirt accumulation regions in a given area. The policy network is trained in multiple environments with simulated dirt patterns. Experiment trials have been conducted to validate the trained policy in both simulated and real-world environments using an in-house developed cleaning audit robot called BELUGA.
KW  - audit robot
KW  - path planning
KW  - reinforcement learning
KW  - cleaning-auditing
DO  - 10.3390/s21248331
ER  -
TY  - EJOU
AU  - Zhu, Pengxing
AU  - Fang, Xi
TI  - Multi-UAV Cooperative Task Assignment Based on Half Random Q-Learning
T2  - Symmetry

PY  - 2021
VL  - 13
IS  - 12
SN  - 2073-8994

AB  - Unmanned aerial vehicle (UAV) clusters usually face problems such as complex environments, heterogeneous combat subjects, and realistic interference factors in the course of mission assignment. In order to reduce resource consumption and improve the task execution rate, it is very important to develop a reasonable allocation plan for the tasks. Therefore, this paper constructs a heterogeneous UAV multitask assignment model based on several realistic constraints and proposes an improved half-random Q-learning (HR Q-learning) algorithm. The algorithm is based on the Q-learning algorithm under reinforcement learning, and by changing the way the Q-learning algorithm selects the next action in the process of random exploration, the probability of obtaining an invalid action in the random case is reduced, and the exploration efficiency is improved, thus increasing the possibility of obtaining a better assignment scheme, this also ensures symmetry and synergy in the distribution process of the drones. Simulation experiments show that compared with Q-learning algorithm and other heuristic algorithms, HR Q-learning algorithm can improve the performance of task execution, including the ability to improve the rationality of task assignment, increasing the value of gains by 12.12%, this is equivalent to an average of one drone per mission saved, and higher success rate of task execution. This improvement provides a meaningful attempt for UAV task assignment.
KW  - task allocation
KW  - half-random Q-learning
KW  - UAV collaboration
KW  - random exploration
DO  - 10.3390/sym13122417
ER  -
TY  - EJOU
AU  - Yang, Shubo
AU  - Luo, Yang
AU  - Miao, Wang
AU  - Ge, Changhao
AU  - Sun, Wenjian
AU  - Luo, Chunbo
TI  - RF Signal-Based UAV Detection and Mode Classification: A Joint Feature Engineering Generator and Multi-Channel Deep Neural Network Approach
T2  - Entropy

PY  - 2021
VL  - 23
IS  - 12
SN  - 1099-4300

AB  - With the proliferation of Unmanned Aerial Vehicles (UAVs) to provide diverse critical services, such as surveillance, disaster management, and medicine delivery, the accurate detection of these small devices and the efficient classification of their flight modes are of paramount importance to guarantee their safe operation in our sky. Among the existing approaches, Radio Frequency (RF) based methods are less affected by complex environmental factors. The similarities between UAV RF signals and the diversity of frequency components make accurate detection and classification a particularly difficult task. To bridge this gap, we propose a joint Feature Engineering Generator (FEG) and Multi-Channel Deep Neural Network (MC-DNN) approach. Specifically, in FEG, data truncation and normalization separate different frequency components, the moving average filter reduces the outliers in the RF signal, and the concatenation fully exploits the details of the dataset. In addition, the multi-channel input in MC-DNN separates multiple frequency components and reduces the interference between them. A novel dataset that contains ten categories of RF signals from three types of UAVs is used to verify the effectiveness. Experiments show that the proposed method outperforms the state-of-the-art UAV detection and classification approaches in terms of 98.4% and F1 score of 98.3%.
KW  - unmanned aerial vehicles
KW  - UAV detection
KW  - UAV mode classification
KW  - Feature Engineering Generator
KW  - multi-channel deep neural network
DO  - 10.3390/e23121678
ER  -
TY  - EJOU
AU  - Zhang, Junrong
AU  - Tang, Huiming
AU  - Tannant, Dwayne D.
AU  - Lin, Chengyuan
AU  - Xia, Ding
AU  - Wang, Yankun
AU  - Wang, Qianyun
TI  - A Novel Model for Landslide Displacement Prediction Based on EDR Selection and Multi-Swarm Intelligence Optimization Algorithm
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 24
SN  - 1424-8220

AB  - With the widespread application of machine learning methods, the continuous improvement of forecast accuracy has become an important task, which is especially crucial for landslide displacement predictions. This study aimed to propose a novel prediction model to improve accuracy in landslide prediction, based on the combination of multiple new algorithms. The proposed new method includes three parts: data preparation, multi-swarm intelligence (MSI) optimization, and displacement prediction. In the data preparation, the complete ensemble empirical mode decomposition (CEEMD) is adopted to separate the trend and periodic displacements from the observed cumulative landslide displacement. The frequency component and residual component of reconstructed inducing factors that related to landslide movements are also extracted by the CEEMD and t-test, and then picked out with edit distance on real sequence (EDR) as input variables for the support vector regression (SVR) model. MSI optimization algorithms are used to optimize the SVR model in the MSI optimization; thus, six predictions models can be obtained that can be used in the displacement prediction part. Finally, the trend and periodic displacements are predicted by six optimized SVR models, respectively. The trend displacement and periodic displacement with the highest prediction accuracy are added and regarded as the final prediction result. The case study of the Shiliushubao landslide shows that the prediction results match the observed data well with an improvement in the aspect of average relative error, which indicates that the proposed model can predict landslide displacements with high precision, even when the displacements are characterized by stepped curves that under the influence of multiple time-varying factors.
KW  - landslide displacement prediction
KW  - complete ensemble empirical mode decomposition (CEEMD)
KW  - edit distance for real sequence (EDR)
KW  - multi-swarm intelligence (MSI)
KW  - support vector regression (SVR)
DO  - 10.3390/s21248352
ER  -
TY  - EJOU
AU  - Torres, Daliana L.
AU  - Turnes, Javier N.
AU  - Soto Vega, Pedro J.
AU  - Feitosa, Raul Q.
AU  - Silva, Daniel E.
AU  - Marcato Junior, Jose
AU  - Almeida, Claudio
TI  - Deforestation Detection with Fully Convolutional Networks in the Amazon Forest from Landsat-8 and Sentinel-2 Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - The availability of remote-sensing multisource data from optical-based satellite sensors has created new opportunities and challenges for forest monitoring in the Amazon Biome. In particular, change-detection analysis has emerged in recent decades to monitor forest-change dynamics, supporting some Brazilian governmental initiatives such as PRODES and DETER projects for biodiversity preservation in threatened areas. In recent years fully convolutional network architectures have witnessed numerous proposals adapted for the change-detection task. This paper comprehensively explores state-of-the-art fully convolutional networks such as U-Net, ResU-Net, SegNet, FC-DenseNet, and two DeepLabv3+ variants on monitoring deforestation in the Brazilian Amazon. The networks&rsquo; performance is evaluated experimentally in terms of Precision, Recall, F1-score, and computational load using satellite images with different spatial and spectral resolution: Landsat-8 and Sentinel-2. We also include the results of an unprecedented auditing process performed by senior specialists to visually evaluate each deforestation polygon derived from the network with the highest accuracy results for both satellites. This assessment allowed estimation of the accuracy of these networks simulating a process &ldquo;in nature&rdquo; and faithful to the PRODES methodology. We conclude that the high resolution of Sentinel-2 images improves the segmentation of deforestation polygons both quantitatively (in terms of F1-score) and qualitatively. Moreover, the study also points to the potential of the operational use of Deep Learning (DL) mapping as products to be consumed in PRODES.
KW  - Amazon biome
KW  - change detection
KW  - deep learning
KW  - fully convolutional neural networks
KW  - remote sensing
KW  - semantic segmentation
DO  - 10.3390/rs13245084
ER  -
TY  - EJOU
AU  - Raval, Divy
AU  - Hunter, Emily
AU  - Hudson, Sinclair
AU  - Damini, Anthony
AU  - Balaji, Bhashyam
TI  - Convolutional Neural Networks for Classification of Drones Using Radars
T2  - Drones

PY  - 2021
VL  - 5
IS  - 4
SN  - 2504-446X

AB  - The ability to classify drones using radar signals is a problem of great interest. In this paper, we apply convolutional neural networks (CNNs) to the Short-Time Fourier Transform (STFT) spectrograms of the simulated radar signals reflected from the drones. The drones vary in many ways that impact the STFT spectrograms, including blade length and blade rotation rates. Some of these physical parameters are captured in the Martin and Mulgrew model which was used to produce the datasets. We examine the data under X-band and W-band radar simulation scenarios and show that a CNN approach leads to an F1 score of 0.816&plusmn;0.011 when trained on data with a signal-to-noise ratio (SNR) of 10 dB. The neural network which was trained on data from an X-band radar with 2 kHz pulse repetition frequency was shown to perform better than the CNN trained on the aforementioned W-band radar. It remained robust to the drone blade pitch and its performance varied directly in a linear fashion with the SNR.
KW  - drone classification
KW  - CNN
KW  - machine learning
KW  - HERM lines
KW  - micro-Doppler
KW  - radars
DO  - 10.3390/drones5040149
ER  -
TY  - EJOU
AU  - Qin, Qiming
AU  - Wu, Zihua
AU  - Zhang, Tianyuan
AU  - Sagan, Vasit
AU  - Zhang, Zhaoxu
AU  - Zhang, Yao
AU  - Zhang, Chengye
AU  - Ren, Huazhong
AU  - Sun, Yuanheng
AU  - Xu, Wei
AU  - Zhao, Cong
TI  - Optical and Thermal Remote Sensing for Monitoring Agricultural Drought
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - By effectively observing the land surface and obtaining farmland conditions, satellite remote sensing has played an essential role in agricultural drought monitoring over past decades. Among all remote sensing techniques, optical and thermal remote sensing have the most extended history of being utilized in drought monitoring. The primary goal of this paper is to illustrate how optical and thermal remote sensing have been and will be applied in the monitoring, assessment, and prediction of agricultural drought. We group the methods into four categories: optical, thermal, optical and thermal, and multi-source. For each category, a concise explanation is given to show the inherent mechanisms. We pay special attention to solar-induced chlorophyll fluorescence, which has great potential in early drought detection. Finally, we look at the future directions of agricultural drought monitoring, including (1) early detection; (2) spatio-temporal resolution; (3) organic combination of multi-source data; and (4) smart prediction and assessment based on deep learning and cloud computing.
KW  - agricultural drought monitoring
KW  - optical remote sensing
KW  - thermal remote sensing
KW  - drought indices
KW  - solar-induced fluorescence
DO  - 10.3390/rs13245092
ER  -
TY  - EJOU
AU  - Zherdev, Denis
AU  - Zherdeva, Larisa
AU  - Agapov, Sergey
AU  - Sapozhnikov, Anton
AU  - Nikonorov, Artem
AU  - Chaplygin, Sergej
TI  - Producing Synthetic Dataset for Human Fall Detection in AR/VR Environments
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 24
SN  - 2076-3417

AB  - Human poses and the behaviour estimation for different activities in (virtual reality/augmented reality) VR/AR could have numerous beneficial applications. Human fall monitoring is especially important for elderly people and for non-typical activities with VR/AR applications. There are a lot of different approaches to improving the fidelity of fall monitoring systems through the use of novel sensors and deep learning architectures; however, there is still a lack of detail and diverse datasets for training deep learning fall detectors using monocular images. The issues with synthetic data generation based on digital human simulation were implemented and examined using the Unreal Engine. The proposed pipeline provides automatic &ldquo;playback&rdquo; of various scenarios for digital human behaviour simulation, and the result of a proposed modular pipeline for synthetic data generation of digital human interaction with the 3D environments is demonstrated in this paper. We used the generated synthetic data to train the Mask R-CNN-based segmentation of the falling person interaction area. It is shown that, by training the model with simulation data, it is possible to recognize a falling person with an accuracy of 97.6% and classify the type of person&rsquo;s interaction impact. The proposed approach also allows for covering a variety of scenarios that can have a positive effect at a deep learning training stage in other human action estimation tasks in an VR/AR environment.
KW  - modelling and simulation
KW  - depth maps
KW  - segmentation
KW  - human fall
KW  - CNN
KW  - machine learning
DO  - 10.3390/app112411938
ER  -
TY  - EJOU
AU  - Luo, Yizhi
AU  - Zeng, Zhixiong
AU  - Lu, Huazhong
AU  - Lv, Enli
TI  - Posture Detection of Individual Pigs Based on Lightweight Convolution Neural Networks and Efficient Channel-Wise Attention
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 24
SN  - 1424-8220

AB  - In this paper, a lightweight channel-wise attention model is proposed for the real-time detection of five representative pig postures: standing, lying on the belly, lying on the side, sitting, and mounting. An optimized compressed block with symmetrical structure is proposed based on model structure and parameter statistics, and the efficient channel attention modules are considered as a channel-wise mechanism to improve the model architecture.The results show that the algorithm&rsquo;s average precision in detecting standing, lying on the belly, lying on the side, sitting, and mounting is 97.7%, 95.2%, 95.7%, 87.5%, and 84.1%, respectively, and the speed of inference is around 63 ms (CPU = i7, RAM = 8G) per postures image. Compared with state-of-the-art models (ResNet50, Darknet53, CSPDarknet53, MobileNetV3-Large, and MobileNetV3-Small), the proposed model has fewer model parameters and lower computation complexity. The statistical results of the postures (with continuous 24 h monitoring) show that some pigs will eat in the early morning, and the peak of the pig&rsquo;s feeding appears after the input of new feed, which reflects the health of the pig herd for farmers.
KW  - pig postures
KW  - real-time detection
KW  - lightweight model
KW  - channel-wise attention
DO  - 10.3390/s21248369
ER  -
TY  - EJOU
AU  - Khalid, Adnan
AU  - Jaffery, Mujtaba H.
AU  - Javed, Muhammad Y.
AU  - Yousaf, Adnan
AU  - Arshad, Jehangir
AU  - Ur Rehman, Ateeq
AU  - Haider, Aun
AU  - Althobaiti, Maha M.
AU  - Shafiq, Muhammad
AU  - Hamam, Habib
TI  - Performance Analysis of Mars-Powered Descent-Based Landing in a Constrained Optimization Control Framework
T2  - Energies

PY  - 2021
VL  - 14
IS  - 24
SN  - 1996-1073

AB  - It is imperative to find new places other than Earth for the survival of human beings. Mars could be the alternative to Earth in the future for us to live. In this context, many missions have been performed to examine the planet Mars. For such missions, planetary precision landing is a major challenge for the precise landing on Mars. Mars landing consists of different phases (hypersonic entry, parachute descent, terminal descent comprising gravity turn, and powered descent). However, the focus of this work is the powered descent phase of landing. Firstly, the main objective of this study is to minimize the landing error during the powered descend landing phase. The second objective involves constrained optimization in a predictive control framework for landing at non-cooperative sites. Different control algorithms like PID and LQR have been developed for the stated problem; however, the predictive control algorithm with constraint handling&rsquo;s ability has not been explored much. This research discusses the Model Predictive Control algorithm for the powered descent phase of landing. Model Predictive Control (MPC) considers input/output constraints in the calculation of the control law and thus it is very useful for the stated problem as shown in the results. The main novelty of this work is the implementation of Explicit MPC, which gives comparatively less computational time than MPC. A comparison is done among MPC variants in terms of feasibility, constraints handling, and computational time. Moreover, other conventional control algorithms like PID and LQR are compared with the proposed predictive algorithm. These control algorithms are implemented on quadrotor UAV (which emulates the dynamics of a planetary lander) to verify the feasibility through simulations in MATLAB.
KW  - Mars landing
KW  - explicit model predictive control
KW  - unmanned aerial vehicle (UAV)
KW  - powered descent
DO  - 10.3390/en14248493
ER  -
TY  - EJOU
AU  - Laugier, Elise J.
AU  - Casana, Jesse
TI  - Integrating Satellite, UAV, and Ground-Based Remote Sensing in Archaeology: An Exploration of Pre-Modern Land Use in Northeastern Iraq
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - Satellite remote sensing is well demonstrated to be a powerful tool for investigating ancient land use in Southwest Asia. However, few regional studies have systematically integrated satellite-based observations with more intensive remote sensing technologies, such as drone-deployed multispectral sensors and ground-based geophysics, to explore off-site areas. Here, we integrate remote sensing data from a variety of sources and scales including historic aerial photographs, modern satellite imagery, drone-deployed sensors, and ground-based geophysics to explore pre-modern land use along the Upper Diyala/Sirwan River in the Kurdistan Region of Iraq. Our analysis reveals an incredible diversity of land use features, including canals, qanats, trackways, and field systems, most of which likely date to the first millennium CE, and demonstrate the potential of more intensive remote sensing methods to resolve land use features. Our results align with broader trends across ancient Southwest Asia that document the most intensive land use in the first millennium BCE through the first millennium CE. Land use features dating to the earlier Bronze Age (fourth through second millennium BCE) remain elusive and will likely require other investigative approaches.
KW  - land use
KW  - archaeology
KW  - agriculture
KW  - Mesopotamia
KW  - ancient Iraq
KW  - historic imagery
KW  - CORONA
KW  - UAVs
KW  - multispectral
KW  - magnetometry
DO  - 10.3390/rs13245119
ER  -
TY  - EJOU
AU  - Yang, Pu
AU  - Wen, Chenwan
AU  - Geng, Huilin
AU  - Liu, Peng
TI  - Intelligent Fault Diagnosis Method for Blade Damage of Quad-Rotor UAV Based on Stacked Pruning Sparse Denoising Autoencoder and Convolutional Neural Network
T2  - Machines

PY  - 2021
VL  - 9
IS  - 12
SN  - 2075-1702

AB  - This paper introduces a new intelligent fault diagnosis method based on stack pruning sparse denoising autoencoder and convolutional neural network (sPSDAE-CNN). This method processes the original input data by using a stack denoising autoencoder. Different from the traditional autoencoder, stack pruning sparse denoising autoencoder includes a fully connected autoencoding network, the features extracted from the front layer of the network are used for the operation of the subsequent layer, which means that some new connections will appear between the front and rear layers of the network, reduce the loss of information, and obtain more effective features. Firstly, a one-dimensional sliding window is introduced for data enhancement. In addition, transforming one-dimensional time-domain data into the two-dimensional gray image can further improve the deep learning (DL) ability of models. At the same time, pruning operation is introduced to improve the training efficiency and accuracy of the network. The convolutional neural network model with sPSDAE has a faster training speed, strong adaptability to noise interference signals, and can also suppress the over-fitting problem of the convolutional neural network to a certain extent. Actual experiments show that for the fault of unmanned aerial vehicle (UAV) blade damage, the sPSDAE-CNN model we use has better stability and reliable prediction accuracy than traditional convolutional neural networks. At the same time, For noise signals, better results can be obtained. The experimental results show that the sPSDAE-CNN model still has a good diagnostic accuracy rate in a high-noise environment. In the case of a signal-to-noise ratio of &minus;4, it still has an accuracy rate of 90%.
KW  - intelligent fault diagnosis
KW  - stacked pruning sparse denoising autoencoder
KW  - convolutional neural network
KW  - anti-noise
DO  - 10.3390/machines9120360
ER  -
TY  - EJOU
AU  - Kior, Anastasiia
AU  - Sukhov, Vladimir
AU  - Sukhova, Ekaterina
TI  - Application of Reflectance Indices for Remote Sensing of Plants and Revealing Actions of Stressors
T2  - Photonics

PY  - 2021
VL  - 8
IS  - 12
SN  - 2304-6732

AB  - Environmental conditions are very changeable; fluctuations in temperature, precipitation, illumination intensity, and other factors can decrease a plant productivity and crop. The remote sensing of plants under these conditions is the basis for the protection of plants and increases their survivability. This problem can be solved through measurements of plant reflectance and calculation of reflectance indices. Reflectance indices are related to the vegetation biomass, specific physiological processes, and biochemical compositions in plants; the indices can be used for both short-term and long-term plant monitoring. In our review, we considered the applications of reflectance indices in plant remote sensing. In Optical Methods and Platforms of Remote Sensing of Plants, we briefly discussed multi- and hyperspectral imaging, including descriptions of multispectral and hyperspectral cameras with different principles and their efficiency for the remote sensing of plants. In Main Reflectance Indices, we described the main reflectance indices, including vegetation, water, and pigment reflectance indices, as well as the photochemical reflectance index and its modifications. We focused on the relationships of leaf reflectance and reflectance indices to plant biomass, development, and physiological and biochemical characteristics. In Problems of Measurement and Analysis of Reflectance Indices, we discussed the methods of the correction of the reflectance indices that can be used for decreasing the influence of environmental conditions (mainly illumination, air, and soil) and plant characteristics (orientation of leaves, their thickness, and others) on their measurements and the analysis of the plant remote sensing. Additionally, the variability of plants was also considered as an important factor that influences the results of measurement and analysis.
KW  - remote sensing
KW  - multispectral imaging
KW  - hyperspectral imaging
KW  - vegetation reflectance indices
KW  - water reflectance indices
KW  - pigment reflectance indices
KW  - photochemical reflectance index
DO  - 10.3390/photonics8120582
ER  -
TY  - EJOU
AU  - Ritter, Noah
AU  - Straub, Jeremy
TI  - Implementation of Hardware-Based Expert Systems and Comparison of Their Performance to Software-Based Expert Systems
T2  - Machines

PY  - 2021
VL  - 9
IS  - 12
SN  - 2075-1702

AB  - Expert systems are a form of highly understandable artificial intelligence that allow humans to trace the decision-making processes that are used. While they are typically software implemented and use an iterative algorithm for rule-fact network processing, this is not the only possible implementation approach. This paper implements and evaluates the use of hardware-based expert systems. It shows that they work accurately and can be developed to parallel software implementations. It also compares the processing speed of software and hardware-based expert systems, showing that hardware-based systems typically operate two orders of magnitude faster than the software ones. The potential applications that hardware-based expert systems can be used for and the capabilities that they can provide are discussed.
KW  - expert systems
KW  - electronic
KW  - performance
KW  - efficacy
KW  - rule-fact network
DO  - 10.3390/machines9120361
ER  -
TY  - EJOU
AU  - Rahman, Md. M.
AU  - Szabó, György
TI  - A Geospatial Approach to Measure Social Benefits in Urban Land Use Optimization Problem
T2  - Land

PY  - 2021
VL  - 10
IS  - 12
SN  - 2073-445X

AB  - Different conflicting objectives are used in urban land use optimization problems. The maximization of social benefit is one of the important objectives in urban land use optimization problems. Many researchers have used different methods to measure social benefits in land use optimization. Studies show that there is no established method to measure social benefit in the urban land use allocation game. Against this background, this study aims to (a) identify the appropriate indicators as a measure of social benefit, and (b) propose a composite index to measure social benefit in urban land use optimization problems. Based on the literature review and expert opinion, this study identifies four indicators as a measure of social benefit. These are spatial compactness, land use compatibility, land use mix, and evenness of population distribution. Using the weighted sum approach, this study proposes a composite social benefit index (SBI) to measure social benefit in urban land use allocation/optimization problems and planning. The study suggests that spatial compactness is the most influential indicator to the SBI, but the most critical indicator is compatibility, whose 11.60% value reduction from 0.5 alters the decision of choice. Finally, the proposed method was applied in Rajshahi city in Bangladesh. The result suggests the potential of using SBI in the land use allocation problem. It is expected that the proposed social benefit index (SBI) will help the land use optimization and planning and will be helpful for decision makers.
KW  - spatial compactness
KW  - land use compatibility
KW  - land use entropy
KW  - evenness of population distribution
KW  - social benefit index
KW  - sensitivity analysis
DO  - 10.3390/land10121398
ER  -
TY  - EJOU
AU  - Zhang, Xinyu
AU  - Yuan, Yaxin
AU  - Zhu, Zequn
AU  - Ma, Qingshan
AU  - Yu, Hongyan
AU  - Li, Meng
AU  - Ma, Jianhai
AU  - Yi, Shuhua
AU  - He, Xiongzhao
AU  - Sun, Yi
TI  - Predicting the Distribution of Oxytropis ochrocephala Bunge in the Source Region of the Yellow River (China) Based on UAV Sampling Data and Species Distribution Model
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - Oxytropis ochrocephala Bunge is an herbaceous perennial poisonous weed. It severely affects the production of local animal husbandry and ecosystem stability in the source region of Yellow River (SRYR), China. To date, however, the spatiotemporal distribution of O. ochrocephala is still unclear, mainly due to lack of high-precision observation data and effective methods at a regional scale. In this study, an efficient sampling method, based on unmanned aerial vehicle (UAV), was proposed to supply basic sampling data for species distribution models (SDMs, BIOMOD in this study). A total of 3232 aerial photographs were obtained, from 2018 to 2020, in SRYR, and the potential and future distribution of O. ochrocephala were predicted by an ensemble model, consisting of six basic models of BIOMOD. The results showed that: (1) O. ochrocephala mainly distributed in the southwest, middle, and northeast of the SRYR, and the high suitable habitat of O. ochrocephala accounted for 3.19%; (2) annual precipitation and annual mean temperature were the two most important factors that affect the distribution of O. ochrocephala, with a cumulative importance of 60.45%; and (3) the distribution probability of O. ochrocephala tends to increase from now to the 2070s, while spatial distribution ranges will remain in the southwest, middle, and northeast of the SRYR. This study shows that UAVs can potentially be used to obtain the basic data for species distribution modeling; the results are both beneficial to establishing reasonable management practices and animal husbandry in alpine grassland systems.
KW  - poisonous weed
KW  - UAV
KW  - FragMAP
KW  - SDMs
KW  - BIOMOD
KW  - ensemble model
DO  - 10.3390/rs13245129
ER  -
TY  - EJOU
AU  - Zhang, Xinyue
AU  - Leng, Chengcai
AU  - Hong, Yameng
AU  - Pei, Zhao
AU  - Cheng, Irene
AU  - Basu, Anup
TI  - Multimodal Remote Sensing Image Registration Methods and Advancements: A Survey
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - With rapid advancements in remote sensing image registration algorithms, comprehensive imaging applications are no longer limited to single-modal remote sensing images. Instead, multi-modal remote sensing (MMRS) image registration has become a research focus in recent years. However, considering multi-source, multi-temporal, and multi-spectrum input introduces significant nonlinear radiation differences in MMRS images for which researchers need to develop novel solutions. At present, comprehensive reviews and analyses of MMRS image registration methods are inadequate in related fields. Thus, this paper introduces three theoretical frameworks: namely, area-based, feature-based and deep learning-based methods. We present a brief review of traditional methods and focus on more advanced methods for MMRS image registration proposed in recent years. Our review or comprehensive analysis is intended to provide researchers in related fields with advanced understanding to achieve further breakthroughs and innovations.
KW  - MMRS image registration
KW  - area-based methods
KW  - feature-based methods
KW  - deep-learning based methods
DO  - 10.3390/rs13245128
ER  -
TY  - EJOU
AU  - Queirós Pokee, Diana
AU  - Barbosa Pereira, Carina
AU  - Mösch, Lucas
AU  - Follmann, Andreas
AU  - Czaplik, Michael
TI  - Consciousness Detection on Injured Simulated Patients Using Manual and Automatic Classification via Visible and Infrared Imaging
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 24
SN  - 1424-8220

AB  - In a disaster scene, triage is a key principle for effectively rescuing injured people according to severity level. One main parameter of the used triage algorithm is the patient&rsquo;s consciousness. Unmanned aerial vehicles (UAV) have been investigated toward (semi-)automatic triage. In addition to vital parameters, such as heart and respiratory rate, UAVs should detect victims&rsquo; mobility and consciousness from the video data. This paper presents an algorithm combining deep learning with image processing techniques to detect human bodies for further (un)consciousness classification. The algorithm was tested in a 20-subject group in an outside environment with static (RGB and thermal) cameras where participants performed different limb movements in different body positions and angles between the cameras and the bodies&rsquo; longitudinal axis. The results verified that the algorithm performed better in RGB. For the most probable case of 0 degrees, RGB data obtained the following results: Mathews correlation coefficient (MMC) of 0.943, F1-score of 0.951, and precision-recall area under curve AUC (PRC) score of 0.968. For the thermal data, the MMC was 0.913, F1-score averaged 0.923, and AUC (PRC) was 0.960. Overall, the algorithm may be promising along with others for a complete contactless triage assessment in disaster events during day and night.
KW  - disaster medicine
KW  - triage
KW  - mass casualty incidents
KW  - remote imaging
KW  - infrared imaging
KW  - movement detection
KW  - image processing
KW  - visible imaging
KW  - mask R-CNN
KW  - UAV
DO  - 10.3390/s21248455
ER  -
TY  - EJOU
AU  - Pérez-González, Andrés
AU  - Benítez-Montoya, Nelson
AU  - Jaramillo-Duque, Álvaro
AU  - Cano-Quintero, Juan B.
TI  - Coverage Path Planning with Semantic Segmentation for UAV in PV Plants
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 24
SN  - 2076-3417

AB  - Solar energy is one of the most strategic energy sources for the world&rsquo;s economic development. This has caused the number of solar photovoltaic plants to increase around the world; consequently, they are installed in places where their access and manual inspection are arduous and risky tasks. Recently, the inspection of photovoltaic plants has been conducted with the use of unmanned aerial vehicles (UAV). Although the inspection with UAVs can be completed with a drone operator, where the UAV flight path is purely manual or utilizes a previously generated flight path through a ground control station (GCS). However, the path generated in the GCS has many restrictions that the operator must supply. Due to these restrictions, we present a novel way to develop a flight path automatically with coverage path planning (CPP) methods. Using a DL server to segment the region of interest (RoI) within each of the predefined PV plant images, three CPP methods were also considered and their performances were assessed with metrics. The UAV energy consumption performance in each of the CPP methods was assessed using two different UAVs and standard metrics. Six experiments were performed by varying the CPP width, and the consumption metrics were recorded in each experiment. According to the results, the most effective and efficient methods are the exact cellular decomposition boustrophedon and grid-based wavefront coverage, depending on the CPP width and the area of the PV plant. Finally, a relationship was established between the size of the photovoltaic plant area and the best UAV to perform the inspection with the appropriate CPP width. This could be an important result for low-cost inspection with UAVs, without high-resolution cameras on the UAV board, and in small plants.
KW  - deep learning (DL)
KW  - unmanned aerial vehicle (UAV)
KW  - photovoltaic (PV) plants
KW  - semantic segmentation
KW  - coverage path planning (CPP)
DO  - 10.3390/app112412093
ER  -
TY  - EJOU
AU  - Wang, Wu
AU  - Guo, Junyou
AU  - Tian, Guoqing
AU  - Chen, Yutao
AU  - Huang, Jie
TI  - Event-Triggered Intervention Framework for UAV-UGV Coordination Systems
T2  - Machines

PY  - 2021
VL  - 9
IS  - 12
SN  - 2075-1702

AB  - Air-ground coordination systems are usually composed of unmanned aerial vehicles (UAV) and unmanned ground vehicles (UGV). In such a system, UAVs can utilize their much more perceptive information to plan the path for UGVs. However, the correctness and accuracy of the planned route are often not guaranteed, and the communication and computation burdens increase with more sophisticated algorithms. This paper proposes a new type of air-ground coordination framework to enable UAVs intervention into UGVs tasks. An event-triggered mechanism in the null space behavior control (NSBC) framework is proposed to decide if an intervention is necessary and the timing of the intervention. Then, the problem of whether to accept the intervention is formulated as an integer programming problem and is solved using model predictive control (MPC). Simulation results show that the UAV can intervene in UGVs accurately and on time, and the UGVs can effectively decide whether to accept the intervention to get rid of troubles, thereby improving the intelligence of the air-ground coordination system.
KW  - air-ground coordination system
KW  - event-triggered
KW  - null space-based behavior control
KW  - model predictive control
DO  - 10.3390/machines9120371
ER  -
TY  - EJOU
AU  - Mehmood, Abid
TI  - LightAnomalyNet: A Lightweight Framework for Efficient Abnormal Behavior Detection
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 24
SN  - 1424-8220

AB  - The continuous development of intelligent video surveillance systems has increased the demand for enhanced vision-based methods of automated detection of anomalies within various behaviors found in video scenes. Several methods have appeared in the literature that detect different anomalies by using the details of motion features associated with different actions. To enable the efficient detection of anomalies, alongside characterizing the specificities involved in features related to each behavior, the model complexity leading to computational expense must be reduced. This paper provides a lightweight framework (LightAnomalyNet) comprising a convolutional neural network (CNN) that is trained using input frames obtained by a computationally cost-effective method. The proposed framework effectively represents and differentiates between normal and abnormal events. In particular, this work defines human falls, some kinds of suspicious behavior, and violent acts as abnormal activities, and discriminates them from other (normal) activities in surveillance videos. Experiments on public datasets show that LightAnomalyNet yields better performance comparative to the existing methods in terms of classification accuracy and input frames generation.
KW  - anomaly detection
KW  - behavior analysis
KW  - fall detection
KW  - violence detection
KW  - suspicious behavior detection
KW  - convolutional neural network
DO  - 10.3390/s21248501
ER  -
TY  - EJOU
AU  - Etienne, Aaron
AU  - Ahmad, Aanis
AU  - Aggarwal, Varun
AU  - Saraswat, Dharmendra
TI  - Deep Learning-Based Object Detection System for Identifying Weeds Using UAS Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - Current methods of broadcast herbicide application cause a negative environmental and economic impact. Computer vision methods, specifically those related to object detection, have been reported to aid in site-specific weed management procedures for targeted herbicide application within a field. However, a major challenge to developing a weed detection system is the requirement for a properly annotated database to differentiate between weeds and crops under field conditions. This research involved creating an annotated database of 374 red, green, and blue (RGB) color images organized into monocot and dicot weed classes. The images were acquired from corn and soybean research plots located in north-central Indiana using an unmanned aerial system (UAS) flown at 30 and 10 m heights above ground level (AGL). A total of 25,560 individual weed instances were manually annotated. The annotated database consisted of four different subsets (Training Image Sets 1&ndash;4) to train the You Only Look Once version 3 (YOLOv3) deep learning model for five separate experiments. The best results were observed with Training Image Set 4, consisting of images acquired at 10 m AGL. For monocot and dicot weeds, respectively, an average precision (AP) score of 91.48 % and 86.13% was observed at a 25% IoU threshold (AP @ T = 0.25), as well as 63.37% and 45.13% at a 50% IoU threshold (AP @ T = 0.5). This research has demonstrated a need to develop large, annotated weed databases to evaluate deep learning models for weed identification under field conditions. It also affirms the findings of other limited research studies utilizing object detection for weed identification under field conditions.
KW  - weed detection
KW  - artificial intelligence
KW  - machine learning
KW  - deep learning
KW  - object detection
KW  - UAS
DO  - 10.3390/rs13245182
ER  -
TY  - EJOU
AU  - Li, Changchun
AU  - Wang, Yilin
AU  - Ma, Chunyan
AU  - Chen, Weinan
AU  - Li, Yacong
AU  - Li, Jingbo
AU  - Ding, Fan
AU  - Xiao, Zhen
TI  - Improvement of Wheat Grain Yield Prediction Model Performance Based on Stacking Technique
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 24
SN  - 2076-3417

AB  - Crop growth and development is a dynamic and complex process, and the essence of yield formation is the continuous accumulation of photosynthetic products from multiple fertility stages. In this study, a new stacking method for integrating multiple growth stages information was proposed to improve the performance of the winter wheat grain yield (GY) prediction model. For this purpose, crop canopy hyperspectral reflectance and leaf area index (LAI) data were obtained at the jointing, flagging, anthesis and grain filling stages. In this case, 15 vegetation indices and LAI were used as input features of the elastic network to construct GY prediction models for single growth stage. Based on Stacking technique, the GY prediction results of four single growth stages were integrated to construct the ensemble learning framework. The results showed that vegetation indices coupled LAI could effectively overcome the spectral saturation phenomenon, the validated R2 of each growth stage was improved by 10%, 22.5%, 3.6% and 10%, respectively. The stacking method provided more stable information with higher prediction accuracy than the individual fertility results (R2 = 0.74), and the R2 of the model validation phase improved by 236%, 51%, 27.6%, and 12.1%, respectively. The study can provide a reference for GY prediction of other crops.
KW  - grain yield
KW  - hyperspectral vegetation index
KW  - leaf area index
KW  - elastic network
KW  - stacking technology
DO  - 10.3390/app112412164
ER  -
TY  - EJOU
AU  - Ekramirad, Nader
AU  - Khaled, Alfadhl Y.
AU  - Doyle, Lauren E.
AU  - Loeb, Julia R.
AU  - Donohue, Kevin D.
AU  - Villanueva, Raul T.
AU  - Adedeji, Akinbode A.
TI  - Nondestructive Detection of Codling Moth Infestation in Apples Using Pixel-Based NIR Hyperspectral Imaging with Machine Learning and Feature Selection
T2  - Foods

PY  - 2022
VL  - 11
IS  - 1
SN  - 2304-8158

AB  - Codling moth (CM) (Cydia pomonella L.), a devastating pest, creates a serious issue for apple production and marketing in apple-producing countries. Therefore, effective nondestructive early detection of external and internal defects in CM-infested apples could remarkably prevent postharvest losses and improve the quality of the final product. In this study, near-infrared (NIR) hyperspectral reflectance imaging in the wavelength range of 900&ndash;1700 nm was applied to detect CM infestation at the pixel level for three organic apple cultivars, namely Gala, Fuji and Granny Smith. An effective region of interest (ROI) acquisition procedure along with different machine learning and data processing methods were used to build robust and high accuracy classification models. Optimal wavelength selection was implemented using sequential stepwise selection methods to build multispectral imaging models for fast and effective classification purposes. The results showed that the infested and healthy samples were classified at pixel level with up to 97.4% total accuracy for validation dataset using a gradient tree boosting (GTB) ensemble classifier, among others. The feature selection algorithm obtained a maximum accuracy of 91.6% with only 22 selected wavelengths. These findings indicate the high potential of NIR hyperspectral imaging (HSI) in detecting and classifying latent CM infestation in apples of different cultivars.
KW  - apples
KW  - codling moth
KW  - hyperspectral imaging
KW  - near-infrared
KW  - machine learning
KW  - feature selection
DO  - 10.3390/foods11010008
ER  -
TY  - EJOU
AU  - Avola, Danilo
AU  - Cinque, Luigi
AU  - Di Mambro, Angelo
AU  - Diko, Anxhelo
AU  - Fagioli, Alessio
AU  - Foresti, Gian L.
AU  - Marini, Marco R.
AU  - Mecca, Alessio
AU  - Pannone, Daniele
TI  - Low-Altitude Aerial Video Surveillance via One-Class SVM Anomaly Detection from Textural Features in UAV Images
T2  - Information

PY  - 2022
VL  - 13
IS  - 1
SN  - 2078-2489

AB  - In recent years, small-scale Unmanned Aerial Vehicles (UAVs) have been used in many video surveillance applications, such as vehicle tracking, border control, dangerous object detection, and many others. Anomaly detection can represent a prerequisite of many of these applications thanks to its ability to identify areas and/or objects of interest without knowing them a priori. In this paper, a One-Class Support Vector Machine (OC-SVM) anomaly detector based on customized Haralick textural features for aerial video surveillance at low-altitude is presented. The use of a One-Class SVM, which is notoriously a lightweight and fast classifier, enables the implementation of real-time systems even when these are embedded in low-computational small-scale UAVs. At the same time, the use of textural features allows a vision-based system to detect micro and macro structures of an analyzed surface, thus allowing the identification of small and large anomalies, respectively. The latter aspect plays a key role in aerial video surveillance at low-altitude, i.e., 6 to 15 m, where the detection of common items, e.g., cars, is as important as the detection of little and undefined objects, e.g., Improvised Explosive Devices (IEDs). Experiments obtained on the UAV Mosaicking and Change Detection (UMCD) dataset show the effectiveness of the proposed system in terms of accuracy, precision, recall, and F1-score, where the model achieves a 100% precision, i.e., never misses an anomaly, but at the expense of a reasonable trade-off in its recall, which still manages to reach up to a 71.23% score. Moreover, when compared to classical Haralick textural features, the model obtains significantly higher performances, i.e., &asymp;20% on all metrics, further demonstrating the approach effectiveness.
KW  - anomaly detection
KW  - small-scale unmanned aerial vehicles
KW  - low-altitude flights
KW  - texture analysis
KW  - feature extraction
KW  - real-time applications
KW  - support vector machines
DO  - 10.3390/info13010002
ER  -
TY  - EJOU
AU  - Kumar, Arun
AU  - Sharma, Sharad
AU  - Singh, Aman
AU  - Alwadain, Ayed
AU  - Choi, Bong-Jun
AU  - Manual-Brenosa, Jose
AU  - Ortega-Mansilla, Arturo
AU  - Goyal, Nitin
TI  - Revolutionary Strategies Analysis and Proposed System for Future Infrastructure in Internet of Things
T2  - Sustainability

PY  - 2022
VL  - 14
IS  - 1
SN  - 2071-1050

AB  - The Internet of Things (IoT) has changed the worldwide network of people, smart devices, intelligent things, data, and information as an emergent technology. IoT development is still in its early stages, and numerous interrelated challenges must be addressed. IoT is the unifying idea of embedding everything. The Internet of Things offers a huge opportunity to improve the world&rsquo;s accessibility, integrity, availability, scalability, confidentiality, and interoperability. However, securing the Internet of Things is a difficult issue. The IoT aims to connect almost everything within the framework of a common infrastructure. This helps in controlling devices and, will allow device status to be updated everywhere and at any time. To develop technology via IoT, several critical scientific studies and inquiries have been carried out. However, many obstacles and problems remain to be tackled in order to reach IoT&rsquo;s maximum potential. These problems and concerns must be taken into consideration in different areas of the IoT, such as implementation in remote areas, threats to the system, development support, social and environmental impacts, etc. This paper reviews the current state of the art in different IoT architectures, with a focus on current technologies, applications, challenges, IoT protocols, and opportunities. As a result, a detailed taxonomy of IoT is presented here which includes interoperability, scalability, security and energy efficiency, among other things. Moreover, the significance of blockchains and big data as well as their analysis in relation to IoT, is discussed. This article aims to help readers and researchers understand the IoT and its applicability to the real world.
KW  - architecture
KW  - communication protocol
KW  - enabling technologies
KW  - interoperability
DO  - 10.3390/su14010071
ER  -
TY  - EJOU
AU  - Gong, Yiping
AU  - Zhang, Fan
AU  - Jia, Xiangyang
AU  - Mao, Zhu
AU  - Huang, Xianfeng
AU  - Li, Deren
TI  - Instance Segmentation in Very High Resolution Remote Sensing Imagery Based on Hard-to-Segment Instance Learning and Boundary Shape Analysis
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Although great success has been achieved in instance segmentation, accurate segmentation of instances remains difficult, especially at object edges. This problem is more prominent for instance segmentation in remote sensing imagery due to the diverse scales, variable illumination, smaller objects, and complex backgrounds. We find that most current instance segmentation networks do not consider the segmentation difficulty of different instances and different regions within the instance. In this paper, we study this problem and propose an ensemble method to segment instances from remote sensing images, considering the enhancement of hard-to-segment instances and instance edges. First, we apply a pixel-level Dice metric that reliably describes the segmentation quality of each instance to achieve online hard instance learning. Instances with low Dice values are studied with emphasis. Second, we generate a penalty map based on the analysis of boundary shapes to not only enhance the edges of objects but also discriminatively strengthen the edges of different shapes. That is, different areas of an object, such as internal areas, flat edges, and sharp edges, are distinguished and discriminatively weighed. Finally, the hard-to-segment instance learning and the shape-penalty map are integrated for precise instance segmentation. To evaluate the effectiveness and generalization ability of the proposed method, we train with the classic instance segmentation network Mask R-CNN and conduct experiments on two different types of remote sensing datasets: the iSAID-Reduce100 and the JKGW_WHU datasets, which have extremely different feature distributions and spatial resolutions. The comprehensive experimental results show that the proposed method improved the segmentation results by 2.78% and 1.77% in mask AP on the iSAID-Reduce100 and JKGW_WHU datasets, respectively. We also test other state-of-the-art (SOTA) methods that focus on inaccurate edges. Experiments demonstrate that our method outperforms these methods.
KW  - instance segmentation
KW  - hard-to-segment instance learning
KW  - boundary shapes analysis
KW  - remote sensing imagery
DO  - 10.3390/rs14010023
ER  -
TY  - EJOU
AU  - Feng, Ziheng
AU  - Song, Li
AU  - Duan, Jianzhao
AU  - He, Li
AU  - Zhang, Yanyan
AU  - Wei, Yongkang
AU  - Feng, Wei
TI  - Monitoring Wheat Powdery Mildew Based on Hyperspectral, Thermal Infrared, and RGB Image Data Fusion
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Powdery mildew severely affects wheat growth and yield; therefore, its effective monitoring is essential for the prevention and control of the disease and global food security. In the present study, a spectroradiometer and thermal infrared cameras were used to obtain hyperspectral signature and thermal infrared images data, and thermal infrared temperature parameters (TP) and texture features (TF) were extracted from the thermal infrared images and RGB images of wheat with powdery mildew, during the wheat flowering and filling periods. Based on the ten vegetation indices from the hyperspectral data (VI), TF and TP were integrated, and partial least square regression, random forest regression (RFR), and support vector machine regression (SVR) algorithms were used to construct a prediction model for a wheat powdery mildew disease index. According to the results, the prediction accuracy of RFR was higher than in other models, under both single data source modeling and multi-source data modeling; among the three data sources, VI was the most suitable for powdery mildew monitoring, followed by TP, and finally TF. The RFR model had stable performance in multi-source data fusion modeling (VI&amp;TP&amp;TF), and had the optimal estimation performance with 0.872 and 0.862 of R2 for calibration and validation, respectively. The application of multi-source data collaborative modeling could improve the accuracy of remote sensing monitoring of wheat powdery mildew, and facilitate the achievement of high-precision remote sensing monitoring of crop disease status.
KW  - wheat powdery mildew
KW  - machine learning
KW  - information fusion
KW  - remote sensing monitoring
DO  - 10.3390/s22010031
ER  -
TY  - EJOU
AU  - Chaschatzis, Christos
AU  - Karaiskou, Chrysoula
AU  - Mouratidis, Efstathios G.
AU  - Karagiannis, Evangelos
AU  - Sarigiannidis, Panagiotis G.
TI  - Detection and Characterization of Stressed Sweet Cherry Tissues Using Machine Learning
T2  - Drones

PY  - 2022
VL  - 6
IS  - 1
SN  - 2504-446X

AB  - Recent technological developments in the primary sector and machine learning algorithms allow the combined application of many promising solutions in precision agriculture. For example, the YOLOv5 (You Only Look Once) and ResNet Deep Learning architecture provide high-precision real-time identifications of objects. The advent of datasets from different perspectives provides multiple benefits, such as spheric view of objects, increased information, and inference results from multiple objects detection per image. However, it also raises crucial obstacles such as total identifications (ground truths) and processing concerns that can lead to devastating consequences, including false-positive detections with other erroneous conclusions or even the inability to extract results. This paper introduces experimental results from the machine learning algorithm (Yolov5) on a novel dataset based on perennial fruit crops, such as sweet cherries, aiming to enhance precision agriculture resiliency. Detection is oriented on two points of interest: (a) Infected leaves and (b) Infected branches. It is noteworthy that infected leaves or branches indicate stress, which may be due to either a stress/disease (e.g., Armillaria for sweet cherries trees, etc.) or other factors (e.g., water shortage, etc). Correspondingly, the foliage of a tree shows symptoms, while this indicates the stages of the disease.
KW  - sweet cherries trees
KW  - diseases detection
KW  - Yolov5
KW  - MACHINE LEARning
KW  - precision agriculture
KW  - ResNet
KW  - smart farming
KW  - stress detection
DO  - 10.3390/drones6010003
ER  -
TY  - EJOU
AU  - Shine, Philip
AU  - Murphy, Michael D.
TI  - Over 20 Years of Machine Learning Applications on Dairy Farms: A Comprehensive Mapping Study
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Machine learning applications are becoming more ubiquitous in dairy farming decision support applications in areas such as feeding, animal husbandry, healthcare, animal behavior, milking and resource management. Thus, the objective of this mapping study was to collate and assess studies published in journals and conference proceedings between 1999 and 2021, which applied machine learning algorithms to dairy farming-related problems to identify trends in the geographical origins of data, as well as the algorithms, features and evaluation metrics and methods used. This mapping study was carried out in line with PRISMA guidelines, with six pre-defined research questions (RQ) and a broad and unbiased search strategy that explored five databases. In total, 129 publications passed the pre-defined selection criteria, from which relevant data required to answer each RQ were extracted and analyzed. This study found that Europe (43% of studies) produced the largest number of publications (RQ1), while the largest number of articles were published in the Computers and Electronics in Agriculture journal (21%) (RQ2). The largest number of studies addressed problems related to the physiology and health of dairy cows (32%) (RQ3), while the most frequently employed feature data were derived from sensors (48%) (RQ4). The largest number of studies employed tree-based algorithms (54%) (RQ5), while RMSE (56%) (regression) and accuracy (77%) (classification) were the most frequently employed metrics used, and hold-out cross-validation (39%) was the most frequently employed evaluation method (RQ6). Since 2018, there has been more than a sevenfold increase in the number of studies that focused on the physiology and health of dairy cows, compared to almost a threefold increase in the overall number of publications, suggesting an increased focus on this subdomain. In addition, a fivefold increase in the number of publications that employed neural network algorithms was identified since 2018, in comparison to a threefold increase in the use of both tree-based algorithms and statistical regression algorithms, suggesting an increasing utilization of neural network-based algorithms.
KW  - dairy
KW  - machine learning
KW  - artificial intelligence
KW  - precision agriculture
KW  - precision livestock farming
DO  - 10.3390/s22010052
ER  -
TY  - EJOU
AU  - Huang, Heqing
AU  - Huang, Tongbin
AU  - Li, Zhen
AU  - Lyu, Shilei
AU  - Hong, Tao
TI  - Design of Citrus Fruit Detection System Based on Mobile Platform and Edge Computer Device
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Citrus fruit detection can provide technical support for fine management and yield determination of citrus orchards. Accurate detection of citrus fruits in mountain orchards is challenging because of leaf occlusion and citrus fruit mutual occlusion of different fruits. This paper presents a citrus detection task that combines UAV data collection, AI embedded device, and target detection algorithm. The system used a small unmanned aerial vehicle equipped with a camera to take full-scale pictures of citrus trees; at the same time, we extended the state-of-the-art model target detection algorithm, added the attention mechanism and adaptive fusion feature method, improved the model&rsquo;s performance; to facilitate the deployment of the model, we used the pruning method to reduce the amount of model calculation and parameters. The improved target detection algorithm is ported to the edge computing end to detect the data collected by the unmanned aerial vehicle. The experiment was performed on the self-made citrus dataset, the detection accuracy was 93.32%, and the processing speed at the edge computing device was 180 ms/frame. This method is suitable for citrus detection tasks in the mountainous orchard environment, and it can help fruit growers to estimate their yield.
KW  - citrus detection
KW  - UAV
KW  - mobile operation platforms
KW  - edge computing devices
DO  - 10.3390/s22010059
ER  -
TY  - EJOU
AU  - Koukouraki, Eftychia
AU  - Vanneschi, Leonardo
AU  - Painho, Marco
TI  - Few-Shot Learning for Post-Earthquake Urban Damage Detection
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Among natural disasters, earthquakes are recorded to have the highest rates of human loss in the past 20 years. Their unexpected nature has severe consequences on both human lives and material infrastructure, demanding urgent action to be taken. For effective emergency relief, it is necessary to gain awareness about the level of damage in the affected areas. The use of remotely sensed imagery is popular in damage assessment applications; however, it requires a considerable amount of labeled data, which are not always easy to obtain. Taking into consideration the recent developments in the fields of Machine Learning and Computer Vision, this study investigates and employs several Few-Shot Learning (FSL) strategies in order to address data insufficiency and imbalance in post-earthquake urban damage classification. While small datasets have been tested against binary classification problems, which usually divide the urban structures into collapsed and non-collapsed, the potential of limited training data in multi-class classification has not been fully explored. To tackle this gap, four models were created, following different data balancing methods, namely cost-sensitive learning, oversampling, undersampling and Prototypical Networks. After a quantitative comparison among them, the best performing model was found to be the one based on Prototypical Networks, and it was used for the creation of damage assessment maps. The contribution of this work is twofold: we show that oversampling is the most suitable data balancing method for training Deep Convolutional Neural Networks (CNN) when compared to cost-sensitive learning and undersampling, and we demonstrate the appropriateness of Prototypical Networks in the damage classification context.
KW  - few-shot learning
KW  - data balancing
KW  - image classification
KW  - remote sensing
KW  - damage assessment
KW  - imbalanced learning
DO  - 10.3390/rs14010040
ER  -
TY  - EJOU
AU  - Xia, Zhiyu
AU  - Xu, Zhengyi
AU  - Li, Dan
AU  - Wei, Jianming
TI  - A Novel Method for Source Tracking of Chemical Gas Leakage: Outlier Mutation Optimization Algorithm
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Chemical industrial parks, which act as critical infrastructures in many cities, need to be responsive to chemical gas leakage accidents. Once a chemical gas leakage accident occurs, risks of poisoning, fire, and explosion will follow. In order to meet the primary emergency response demands in chemical gas leakage accidents, source tracking technology of chemical gas leakage has been proposed and evolved. This paper proposes a novel method, Outlier Mutation Optimization (OMO) algorithm, aimed to quickly and accurately track the source of chemical gas leakage. The OMO algorithm introduces a random walk exploration mode and, based on Swarm Intelligence (SI), increases the probability of individual mutation. Compared with other optimization algorithms, the OMO algorithm has the advantages of a wider exploration range and more convergence modes. In the algorithm test session, a series of chemical gas leakage accident application examples with random parameters are first assumed based on the Gaussian plume model; next, the qualitative experiments and analysis of the OMO algorithm are conducted, based on the application example. The test results show that the OMO algorithm with default parameters has superior comprehensive performance, including the extremely high average calculation accuracy: the optimal value, which represents the error between the final objective function value obtained by the optimization algorithm and the ideal value, reaches 2.464e-15 when the number of sensors is 16; 2.356e-13 when the number of sensors is 9; and 5.694e-23 when the number of sensors is 4. There is a satisfactory calculation time: 12.743 s/50 times when the number of sensors is 16; 10.304 s/50 times when the number of sensors is 9; and 8.644 s/50 times when the number of sensors is 4. The analysis of the OMO algorithm&rsquo;s characteristic parameters proves the flexibility and robustness of this method. In addition, compared with other algorithms, the OMO algorithm can obtain an excellent leakage source tracing result in the application examples of 16, 9 and 4 sensors, and the accuracy exceeds the direct search algorithm, evolutionary algorithm, and other swarm intelligence algorithms.
KW  - Outlier Mutation Optimization algorithm
KW  - Gaussian plume model
KW  - random walk
KW  - emergency response
KW  - leakage tracking
DO  - 10.3390/s22010071
ER  -
TY  - EJOU
AU  - He, Haiqing
AU  - Yu, Jing
AU  - Cheng, Penggen
AU  - Wang, Yuqian
AU  - Zhu, Yufeng
AU  - Lin, Taiqing
AU  - Dai, Guoqiang
TI  - Automatic, Multiview, Coplanar Extraction for CityGML Building Model Texture Mapping
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Most 3D CityGML building models in street-view maps (e.g., Google, Baidu) lack texture information, which is generally used to reconstruct real-scene 3D models by photogrammetric techniques, such as unmanned aerial vehicle (UAV) mapping. However, due to its simplified building model and inaccurate location information, the commonly used photogrammetric method using a single data source cannot satisfy the requirement of texture mapping for the CityGML building model. Furthermore, a single data source usually suffers from several problems, such as object occlusion. We proposed a novel approach to achieve CityGML building model texture mapping by multiview coplanar extraction from UAV remotely sensed or terrestrial images to alleviate these problems. We utilized a deep convolutional neural network to filter out object occlusion (e.g., pedestrians, vehicles, and trees) and obtain building-texture distribution. Point-line-based features are extracted to characterize multiview coplanar textures in 2D space under the constraint of a homography matrix, and geometric topology is subsequently conducted to optimize the boundary of textures by using a strategy combining Hough-transform and iterative least-squares methods. Experimental results show that the proposed approach enables texture mapping for building fa&ccedil;ades to use 2D terrestrial images without the requirement of exterior orientation information; that is, different from the photogrammetric method, a collinear equation is not an essential part to capture texture information. In addition, the proposed approach can significantly eliminate blurred and distorted textures of building models, so it is suitable for automatic and rapid texture updates.
KW  - texture mapping
KW  - coplanar extraction
KW  - deep convolutional neural network
KW  - geometric topology
KW  - homography matrix
DO  - 10.3390/rs14010050
ER  -
TY  - EJOU
AU  - Zhang, Lianchong
AU  - Xia, Junshi
TI  - Flood Detection Using Multiple Chinese Satellite Datasets during 2020 China Summer Floods
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Multiple source satellite datasets, including the Gaofen (GF) series and Zhuhai-1 hyperspectral, are provided to detect and monitor the floods. Considering the complexity of land cover changes within the flooded areas and the different characteristics of the multi-source remote sensing dataset, we proposed a new coarse-to-fine framework for detecting floods at a large scale. Firstly, the coarse results of the water body were generated by the binary segmentation of GF-3 SAR, the water indexes of GF-1/6 multispectral, and Zhuhai-1 hyperspectral images. Secondly, the fine results were achieved by the deep neural networks with noisy-label learning. More specifically, the Unet with the T-revision is adopted as the noisy label learning method. The results demonstrated the reliability and accuracy of water mapping retrieved by the noisy learning method. Finally, the differences in flooding patterns in different regions were also revealed. We presented examples of Poyang Lake to show the results of our framework. The rapid and robust flood monitoring method proposed is of great practical significance to the dynamic monitoring of flood situations and the quantitative assessment of flood disasters based on multiple Chinese satellite datasets.
KW  - flood mapping
KW  - multiple-source
KW  - Chinese satellites
KW  - summer flood
DO  - 10.3390/rs14010051
ER  -
TY  - EJOU
AU  - Andrade, Fabio A. A.
AU  - Guedes, Ihannah P.
AU  - Carvalho, Guilherme F.
AU  - Zachi, Alessandro R. L.
AU  - Haddad, Diego B.
AU  - Almeida, Luciana F.
AU  - de Melo, Aurélio G.
AU  - Pinto, Milena F.
TI  - Unmanned Aerial Vehicles Motion Control with Fuzzy Tuning of Cascaded-PID Gains
T2  - Machines

PY  - 2022
VL  - 10
IS  - 1
SN  - 2075-1702

AB  - One of the main challenges of maneuvering an Unmanned Aerial Vehicle (UAV) to keep a stabilized flight is dealing with its fast and highly coupled nonlinear dynamics. There are several solutions in the literature, but most of them require fine-tuning of the parameters. In order to avoid the exhaustive tuning procedures, this work employs a Fuzzy Logic strategy for online tuning of the PID gains of the UAV motion controller. A Cascaded-PID scheme is proposed, in which velocity commands are calculated and sent to the flight control unit from a given target desired position (waypoint). Therefore, the flight control unit is responsible for the lower control loop. The main advantage of the proposed method is that it can be applied to any UAV without the need of its formal mathematical model. Robot Operating System (ROS) is used to integrate the proposed system and the flight control unit. The solution was evaluated through flight tests and simulations, which were conducted using Unreal Engine 4 with the Microsoft AirSim plugin. In the simulations, the proposed method is compared with the traditional Ziegler-Nichols tuning method, another Fuzzy Logic approach, and the ArduPilot built-in PID controller. The simulation results show that the proposed method, compared to the ArduPilot controller, drives the UAV to reach the desired setpoint faster. When compared to Ziegler-Nichols and another different Fuzzy Logic approach, the proposed method demonstrates to provide a faster accommodation and yield smaller errors amplitudes.
KW  - control strategy
KW  - UAV
KW  - fuzzy
KW  - PID controller
KW  - ROS
DO  - 10.3390/machines10010012
ER  -
TY  - EJOU
AU  - Li, Yuping
AU  - Quinn, Brady K.
AU  - Gielis, Johan
AU  - Li, Yirong
AU  - Shi, Peijian
TI  - Evidence That Supertriangles Exist in Nature from the Vertical Projections of Koelreuteria paniculata Fruit
T2  - Symmetry

PY  - 2022
VL  - 14
IS  - 1
SN  - 2073-8994

AB  - Many natural radial symmetrical shapes (e.g., sea stars) follow the Gielis equation (GE) or its twin equation (TGE). A supertriangle (three triangles arranged around a central polygon) represents such a shape, but no study has tested whether natural shapes can be represented as/are supertriangles or whether the GE or TGE can describe their shape. We collected 100 pieces of Koelreuteria paniculata fruit, which have a supertriangular shape, extracted the boundary coordinates for their vertical projections, and then fitted them with the GE and TGE. The adjusted root mean square errors (RMSEadj) of the two equations were always less than 0.08, and &gt;70% were less than 0.05. For 57/100 fruit projections, the GE had a lower RMSEadj than the TGE, although overall differences in the goodness of fit were non-significant. However, the TGE produces more symmetrical shapes than the GE as the two parameters controlling the extent of symmetry in it are approximately equal. This work demonstrates that natural supertriangles exist, validates the use of the GE and TGE to model their shapes, and suggests that different complex radially symmetrical shapes can be generated by the same equation, implying that different types of biological symmetry may result from the same biophysical mechanisms.
KW  - Gielis equation
KW  - goodness of fit
KW  - natural geometry
KW  - polar coordinate
KW  - radial symmetry
DO  - 10.3390/sym14010023
ER  -
TY  - EJOU
AU  - Murguia-Cozar, Alvaro
AU  - Macedo-Cruz, Antonia
AU  - Fernandez-Reynoso, Demetrio S.
AU  - Salgado Transito, Jorge A.
TI  - Recognition of Maize Phenology in Sentinel Images with Machine Learning
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - The scarcity of water for agricultural use is a serious problem that has increased due to intense droughts, poor management, and deficiencies in the distribution and application of the resource. The monitoring of crops through satellite image processing and the application of machine learning algorithms are technological strategies with which developed countries tend to implement better public policies regarding the efficient use of water. The purpose of this research was to determine the main indicators and characteristics that allow us to discriminate the phenological stages of maize crops (Zea mays L.) in Sentinel 2 satellite images through supervised classification models. The training data were obtained by monitoring cultivated plots during an agricultural cycle. Indicators and characteristics were extracted from 41 Sentinel 2 images acquired during the monitoring dates. With these images, indicators of texture, vegetation, and colour were calculated to train three supervised classifiers: linear discriminant (LD), support vector machine (SVM), and k-nearest neighbours (kNN) models. It was found that 45 of the 86 characteristics extracted contributed to maximizing the accuracy by stage of development and the overall accuracy of the trained classification models. The characteristics of the Moran&rsquo;s I local indicator of spatial association (LISA) improved the accuracy of the classifiers when applied to the L*a*b* colour model and to the near-infrared (NIR) band. The local binary pattern (LBP) increased the accuracy of the classification when applied to the red, green, blue (RGB) and NIR bands. The colour ratios, leaf area index (LAI), RGB colour model, L*a*b* colour space, LISA, and LBP extracted the most important intrinsic characteristics of maize crops with regard to classifying the phenological stages of the maize cultivation. The quadratic SVM model was the best classifier of maize crop phenology, with an overall accuracy of 82.3%.
KW  - support vector machine
KW  - local indicator of spatial association
KW  - local binary pattern
KW  - texture characteristic
KW  - colour characteristic
KW  - leaf area index
DO  - 10.3390/s22010094
ER  -
TY  - EJOU
AU  - Shakhnoza, Muksimova
AU  - Sabina, Umirzakova
AU  - Sevara, Mardieva
AU  - Cho, Young-Im
TI  - Novel Video Surveillance-Based Fire and Smoke Classification Using Attentional Feature Map in Capsule Networks
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - A fire is an extraordinary event that can damage property and have a notable effect on people&rsquo;s lives. However, the early detection of smoke and fire has been identified as a challenge in many recent studies. Therefore, different solutions have been proposed to approach the timely detection of fire events and avoid human casualties. As a solution, we used an affordable visual detection system. This method is possibly effective because early fire detection is recognized. In most developed countries, CCTV surveillance systems are installed in almost every public location to take periodic images of a specific area. Notwithstanding, cameras are used under different types of ambient light, and they experience occlusions, distortions of view, and changes in the resulting images from different camera angles and the different seasons of the year, all of which affect the accuracy of currently established models. To address these problems, we developed an approach based on an attention feature map used in a capsule network designed to classify fire and smoke locations at different distances outdoors, given only an image of a single fire and smoke as input. The proposed model was designed to solve two main limitations of the base capsule network input and the analysis of large-sized images, as well as to compensate the absence of a deep network using an attention-based approach to improve the classification of the fire and smoke results. In term of practicality, our method is comparable with prior strategies based on machine learning and deep learning methods. We trained and tested the proposed model using our datasets collected from different sources. As the results indicate, a high classification accuracy in comparison with other modern architectures was achieved. Further, the results indicate that the proposed approach is robust and stable for the classification of images from outdoor CCTV cameras with different viewpoints given the presence of smoke and fire.
KW  - capsule network
KW  - attention feature map
KW  - smoke detection
KW  - fire detection
KW  - deep learning
KW  - artificial intelligence
KW  - classification
DO  - 10.3390/s22010098
ER  -
TY  - EJOU
AU  - Wang, Jizhang
AU  - Gao, Zhiheng
AU  - Zhang, Yun
AU  - Zhou, Jing
AU  - Wu, Jianzhi
AU  - Li, Pingping
TI  - Real-Time Detection and Location of Potted Flowers Based on a ZED Camera and a YOLO V4-Tiny Deep Learning Algorithm
T2  - Horticulturae

PY  - 2022
VL  - 8
IS  - 1
SN  - 2311-7524

AB  - In order to realize the real-time and accurate detection of potted flowers on benches, in this paper we propose a method based on the ZED 2 stereo camera and the YOLO V4-Tiny deep learning algorithm for potted flower detection and location. First, an automatic detection model of flowers was established based on the YOLO V4-Tiny convolutional neural network (CNN) model, and the center points on the pixel plane of the flowers were obtained according to the prediction box. Then, the real-time 3D point cloud information obtained by the ZED 2 camera was used to calculate the actual position of the flowers. The test results showed that the mean average precision (MAP) and recall rate of the training model was 89.72% and 80%, respectively, and the real-time average detection frame rate of the model deployed under Jetson TX2 was 16 FPS. The results of the occlusion experiment showed that when the canopy overlap ratio between the two flowers is more than 10%, the recognition accuracy will be affected. The mean absolute error of the flower center location based on 3D point cloud information of the ZED 2 camera was 18.1 mm, and the maximum locating error of the flower center was 25.8 mm under different light radiation conditions. The method in this paper establishes the relationship between the detection target of flowers and the actual spatial location, which has reference significance for the machinery and automatic management of potted flowers on benches.
KW  - potted flower
KW  - ZED 2 stereo camera
KW  - detection
KW  - location
KW  - YOLO V4-Tiny
KW  - deep learning
DO  - 10.3390/horticulturae8010021
ER  -
TY  - EJOU
AU  - Munawar, Hafiz S.
AU  - Ullah, Fahim
AU  - Heravi, Amirhossein
AU  - Thaheem, Muhammad J.
AU  - Maqsoom, Ahsen
TI  - Inspecting Buildings Using Drones and Computer Vision: A Machine Learning Approach to Detect Cracks and Damages
T2  - Drones

PY  - 2022
VL  - 6
IS  - 1
SN  - 2504-446X

AB  - Manual inspection of infrastructure damages such as building cracks is difficult due to the objectivity and reliability of assessment and high demands of time and costs. This can be automated using unmanned aerial vehicles (UAVs) for aerial imagery of damages. Numerous computer vision-based approaches have been applied to address the limitations of crack detection but they have their limitations that can be overcome by using various hybrid approaches based on artificial intelligence (AI) and machine learning (ML) techniques. The convolutional neural networks (CNNs), an application of the deep learning (DL) method, display remarkable potential for automatically detecting image features such as damages and are less sensitive to image noise. A modified deep hierarchical CNN architecture has been used in this study for crack detection and damage assessment in civil infrastructures. The proposed architecture is based on 16 convolution layers and a cycle generative adversarial network (CycleGAN). For this study, the crack images were collected using UAVs and open-source images of mid to high rise buildings (five stories and above) constructed during 2000 in Sydney, Australia. Conventionally, a CNN network only utilizes the last layer of convolution. However, our proposed network is based on the utility of multiple layers. Another important component of the proposed CNN architecture is the application of guided filtering (GF) and conditional random fields (CRFs) to refine the predicted outputs to get reliable results. Benchmarking data (600 images) of Sydney-based buildings damages was used to test the proposed architecture. The proposed deep hierarchical CNN architecture produced superior performance when evaluated using five methods: GF method, Baseline (BN) method, Deep-Crack BN, Deep-Crack GF, and SegNet. Overall, the GF method outperformed all other methods as indicated by the global accuracy (0.990), class average accuracy (0.939), mean intersection of the union overall classes (IoU) (0.879), precision (0.838), recall (0.879), and F-score (0.8581) values. Overall, the proposed CNN architecture provides the advantages of reduced noise, highly integrated supervision of features, adequate learning, and aggregation of both multi-scale and multilevel features during the training procedure along with the refinement of the overall output predictions.
KW  - building damages
KW  - convolutional neural networks (CNNs)
KW  - computer vision
KW  - cracks
KW  - generative adversarial network (CycleGAN)
KW  - infrastructure inspection
KW  - infrastructure monitoring
KW  - Unmanned Aerial Vehicle (UAV)
DO  - 10.3390/drones6010005
ER  -
TY  - EJOU
AU  - Yan, Zhen
AU  - Yang, Hongyu
AU  - Li, Fan
AU  - Lin, Yi
TI  - A Deep Learning Approach for Short-Term Airport Traffic Flow Prediction
T2  - Aerospace

PY  - 2022
VL  - 9
IS  - 1
SN  - 2226-4310

AB  - Airport traffic flow prediction is a fundamental research topic in the field of air traffic flow management. Most existing works focus on the single airport traffic flow prediction with temporal dynamics but fail to consider the influence of the topological airport network. In this paper, a novel deep learning-based framework, called airport traffic flow prediction network (ATFPNet), is proposed to capture spatial-temporal dependencies of the historical airport traffic flow (departure and arrival) for the multiple-step situational (network-level) arrival flow prediction. Firstly, considering the nature of the airport distribution and the context of air transportation, a special semantic graph built on the flight schedule is applied to represent the airport network, which is the key to encoding the situational airport traffic flow into a single representation. Then, the graph convolution operator and the gated recurrent unit are combined to extract high-level transition patterns of airport traffic flow in the spatial and temporal dimensions. Finally, a real-world airport traffic flow dataset is applied to validate the effectiveness of the proposed model, and the experimental results demonstrate that the ATFPNet outperforms other baselines on different prediction horizons. Specifically, the proposed method achieves up to 17% MAE improvement compared to baselines. Based on the proposed approach, efficient traffic planning is expected to be achieved for airport management.
KW  - airport traffic flow
KW  - multiple-step situational prediction
KW  - spatial graph convolution
KW  - deep learning
KW  - spatial-temporal dependencies
DO  - 10.3390/aerospace9010011
ER  -
TY  - EJOU
AU  - Reder, Stefan
AU  - Mund, Jan-Peter
AU  - Albert, Nicole
AU  - Waßermann, Lilli
AU  - Miranda, Luis
TI  - Detection of Windthrown Tree Stems on UAV-Orthomosaics Using U-Net Convolutional Networks
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - The increasing number of severe storm events is threatening European forests. Besides the primary damages directly caused by storms, there are secondary damages such as bark beetle outbreaks and tertiary damages due to negative effects on the market. These subsequent damages can be minimized if a detailed overview of the affected area and the amount of damaged wood can be obtained quickly and included in the planning of clearance measures. The present work utilizes UAV-orthophotos and an adaptation of the U-Net architecture for the semantic segmentation and localization of windthrown stems. The network was pre-trained with generic datasets, randomly combining stems and background samples in a copy&ndash;paste augmentation, and afterwards trained with a specific dataset of a particular windthrow. The models pre-trained with generic datasets containing 10, 50 and 100 augmentations per annotated windthrown stems achieved F1-scores of 73.9% (S1Mod10), 74.3% (S1Mod50) and 75.6% (S1Mod100), outperforming the baseline model (F1-score 72.6%), which was not pre-trained. These results emphasize the applicability of the method to correctly identify windthrown trees and suggest the collection of training samples from other tree species and windthrow areas to improve the ability to generalize. Further enhancements of the network architecture are considered to improve the classification performance and to minimize the calculative costs.
KW  - natural disaster analysis
KW  - forest damage assessment
KW  - windthrow detection
KW  - deep learning
KW  - U-Net
KW  - UAV
KW  - semantic segmentation
DO  - 10.3390/rs14010075
ER  -
TY  - EJOU
AU  - Peng, Yeping
AU  - Tang, Zhen
AU  - Zhao, Genping
AU  - Cao, Guangzhong
AU  - Wu, Chao
TI  - Motion Blur Removal for Uav-Based Wind Turbine Blade Images Using Synthetic Datasets
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Unmanned air vehicle (UAV) based imaging has been an attractive technology to be used for wind turbine blades (WTBs) monitoring. In such applications, image motion blur is a challenging problem which means that motion deblurring is of great significance in the monitoring of running WTBs. However, an embarrassing fact for these applications is the lack of sufficient WTB images, which should include better pairs of sharp images and blurred images captured under the same conditions for network model training. To overcome the challenge of image pair acquisition, a training sample synthesis method is proposed. Sharp images of static WTBs were first captured, and then video sequences were prepared by running WTBs at different speeds. The blurred images were identified from the video sequences and matched to the sharp images using image difference. To expand the sample dataset, rotational motion blurs were simulated on different WTBs. Synthetic image pairs were then produced by fusing sharp images and images of simulated blurs. Finally, a total of 4000 image pairs were obtained. To conduct motion deblurring, a hybrid deblurring network integrated with DeblurGAN and DeblurGANv2 was deployed. The results show that the integration of DeblurGANv2 and Inception-ResNet-v2 provides better deblurred images, in terms of both metrics of signal-to-noise ratio (80.138) and structural similarity (0.950) than those obtained from the comparable networks of DeblurGAN and MobileNet-DeblurGANv2.
KW  - wind turbine blades
KW  - UAV
KW  - motion deblurring
KW  - training sample synthesis
KW  - end-to-end network
DO  - 10.3390/rs14010087
ER  -
TY  - EJOU
AU  - Ponce, Juan M.
AU  - Aquino, Arturo
AU  - Tejada, Diego
AU  - Al-Hadithi, Basil M.
AU  - Andújar, José M.
TI  - A Methodology for the Automated Delineation of Crop Tree Crowns from UAV-Based Aerial Imagery by Means of Morphological Image Analysis
T2  - Agronomy

PY  - 2022
VL  - 12
IS  - 1
SN  - 2073-4395

AB  - The popularisation of aerial remote sensing using unmanned aerial vehicles (UAV), has boosted the capacities of agronomists and researchers to offer farmers valuable data regarding the status of their crops. This paper describes a methodology for the automated detection and individual delineation of tree crowns in aerial representations of crop fields by means of image processing and analysis techniques, providing accurate information about plant population and canopy coverage in intensive-farming orchards with a row-based plant arrangement. To that end, after pre-processing initial aerial captures by means of photogrammetry and morphological image analysis, a resulting binary representation of the land plot surveyed is treated at connected component-level in order to separate overlapping tree crown projections. Then, those components are morphologically transformed into a set of seeds with which tree crowns are finally delineated, establishing the boundaries between them when they appear overlapped. This solution was tested on images from three different orchards, achieving semantic segmentations in which more than 94% of tree canopy-belonging pixels were correctly classified, and more than 98% of trees were successfully detected when assessing the methodology capacities for estimating the overall plant population. According to these results, the methodology represents a promising tool for automating the inventorying of plants and estimating individual tree-canopy coverage in intensive tree-based orchards.
KW  - aerial imagery
KW  - canopy cover
KW  - morphological image analysis
KW  - crop tree
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/agronomy12010043
ER  -
TY  - EJOU
AU  - Rizk, Hamada
AU  - Nishimur, Yukako
AU  - Yamaguchi, Hirozumi
AU  - Higashino, Teruo
TI  - Drone-Based Water Level Detection in Flood Disasters
T2  - International Journal of Environmental Research and Public Health

PY  - 2022
VL  - 19
IS  - 1
SN  - 1660-4601

AB  - Japan was hit by typhoon Hagibis, which came with torrential rains submerging almost eight-thousand buildings. For fast alleviation of and recovery from flood damage, a quick, broad, and accurate assessment of the damage situation is required. Image analysis provides a much more feasible alternative than on-site sensors due to their installation and maintenance costs. Nevertheless, most state-of-art research relies on only ground-level images that are inevitably limited in their field of vision. This paper presents a water level detection system based on aerial drone-based image recognition. The system applies the R-CNN learning model together with a novel labeling method on the reference objects, including houses and cars. The proposed system tackles the challenges of the limited and wild data set of flood images from the top view with data augmentation and transfer-learning overlaying Mask R-CNN for the object recognition model. Additionally, the VGG16 network is employed for water level detection purposes. We evaluated the proposed system on realistic images captured at disaster time. Preliminary results show that the system can achieve a detection accuracy of submerged objects of 73.42% with as low as only 21.43 cm error in estimating the water level.
KW  - drone-based vision
KW  - emergency recovery
KW  - flood disaster assessment
KW  - water level detection
DO  - 10.3390/ijerph19010237
ER  -
TY  - EJOU
AU  - Chang, Yeong-Hwa
AU  - Chen, Yen-Jen
AU  - Huang, Ren-Hung
AU  - Yu, Yi-Ting
TI  - Enhanced Image Captioning with Color Recognition Using Deep Learning Methods
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 1
SN  - 2076-3417

AB  - Automatically describing the content of an image is an interesting and challenging task in artificial intelligence. In this paper, an enhanced image captioning model&mdash;including object detection, color analysis, and image captioning&mdash;is proposed to automatically generate the textual descriptions of images. In an encoder&ndash;decoder model for image captioning, VGG16 is used as an encoder and an LSTM (long short-term memory) network with attention is used as a decoder. In addition, Mask R-CNN with OpenCV is used for object detection and color analysis. The integration of the image caption and color recognition is then performed to provide better descriptive details of images. Moreover, the generated textual sentence is converted into speech. The validation results illustrate that the proposed method can provide more accurate description of images.
KW  - image caption
KW  - color recognition
KW  - LSTM
KW  - object detection
DO  - 10.3390/app12010209
ER  -
TY  - EJOU
AU  - Li, Xin
AU  - Li, Tao
AU  - Chen, Ziqi
AU  - Zhang, Kaiwen
AU  - Xia, Runliang
TI  - Attentively Learning Edge Distributions for Semantic Segmentation of Remote Sensing Imagery
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Semantic segmentation has been a fundamental task in interpreting remote sensing imagery (RSI) for various downstream applications. Due to the high intra-class variants and inter-class similarities, inflexibly transferring natural image-specific networks to RSI is inadvisable. To enhance the distinguishability of learnt representations, attention modules were developed and applied to RSI, resulting in satisfactory improvements. However, these designs capture contextual information by equally handling all the pixels regardless of whether they around edges. Therefore, blurry boundaries are generated, rising high uncertainties in classifying vast adjacent pixels. Hereby, we propose an edge distribution attention module (EDA) to highlight the edge distributions of leant feature maps in a self-attentive fashion. In this module, we first formulate and model column-wise and row-wise edge attention maps based on covariance matrix analysis. Furthermore, a hybrid attention module (HAM) that emphasizes the edge distributions and position-wise dependencies is devised combing with non-local block. Consequently, a conceptually end-to-end neural network, termed as EDENet, is proposed to integrate HAM hierarchically for the detailed strengthening of multi-level representations. EDENet implicitly learns representative and discriminative features, providing available and reasonable cues for dense prediction. The experimental results evaluated on ISPRS Vaihingen, Potsdam and DeepGlobe datasets show the efficacy and superiority to the state-of-the-art methods on overall accuracy (OA) and mean intersection over union (mIoU). In addition, the ablation study further validates the effects of EDA.
KW  - semantic segmentation
KW  - remote sensing imagery
KW  - covariance matrix analysis
KW  - edge distributions
KW  - end-to-end neural network
DO  - 10.3390/rs14010102
ER  -
TY  - EJOU
AU  - Miao, Yu
AU  - Hunter, Alan
AU  - Georgilas, Ioannis
TI  - An Occupancy Mapping Method Based on K-Nearest Neighbours
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - OctoMap is an efficient probabilistic mapping framework to build occupancy maps from point clouds, representing 3D environments with cubic nodes in the octree. However, the map update policy in OctoMap has limitations. All the nodes containing points will be assigned with the same probability regardless of the points being noise, and the probability of one such node can only be increased with a single measurement. In addition, potentially occupied nodes with points inside but traversed by rays cast from the sensor to endpoints will be marked as free. To overcome these limitations in OctoMap, the current work presents a mapping method using the context of neighbouring points to update nodes containing points, with occupancy information of a point represented by the average distance from a point to its k-Nearest Neighbours. A relationship between the distance and the change in probability is defined with the Cumulative Density Function of average distances, potentially decreasing the probability of a node despite points being present inside. Experiments are conducted on 20 data sets to compare the proposed method with OctoMap. Results show that our method can achieve up to 10% improvement over the optimal performance of OctoMap.
KW  - mapping
KW  - SLAM
KW  - data sets for SLAM
DO  - 10.3390/s22010139
ER  -
TY  - EJOU
AU  - Yan, Dongchuan
AU  - Zhang, Hao
AU  - Li, Guoqing
AU  - Li, Xiangqiang
AU  - Lei, Hua
AU  - Lu, Kaixuan
AU  - Zhang, Lianchong
AU  - Zhu, Fuxiao
TI  - Improved Method to Detect the Tailings Ponds from Multispectral Remote Sensing Images Based on Faster R-CNN and Transfer Learning
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - The breaching of tailings pond dams may lead to casualties and environmental pollution; therefore, timely and accurate monitoring is an essential aspect of managing such structures and preventing accidents. Remote sensing technology is suitable for the regular extraction and monitoring of tailings pond information. However, traditional remote sensing is inefficient and unsuitable for the frequent extraction of large volumes of highly precise information. Object detection, based on deep learning, provides a solution to this problem. Most remote sensing imagery applications for tailings pond object detection using deep learning are based on computer vision, utilizing the true-color triple-band data of high spatial resolution imagery for information extraction. The advantage of remote sensing image data is their greater number of spectral bands (more than three), providing more abundant spectral information. There is a lack of research on fully harnessing multispectral band information to improve the detection precision of tailings ponds. Accordingly, using a sample dataset of tailings pond satellite images from the Gaofen-1 high-resolution Earth observation satellite, we improved the Faster R-CNN deep learning object detection model by increasing the inputs from three true-color bands to four multispectral bands. Moreover, we used the attention mechanism to recalibrate the input contributions. Subsequently, we used a step-by-step transfer learning method to improve and gradually train our model. The improved model could fully utilize the near-infrared (NIR) band information of the images to improve the precision of tailings pond detection. Compared with that of the three true-color band input models, the tailings pond detection average precision (AP) and recall notably improved in our model, with the AP increasing from 82.3% to 85.9% and recall increasing from 65.4% to 71.9%. This research could serve as a reference for using multispectral band information from remote sensing images in the construction and application of deep learning models.
KW  - tailings pond
KW  - Faster R-CNN
KW  - transfer learning
KW  - multispectral
DO  - 10.3390/rs14010103
ER  -
TY  - EJOU
AU  - Shafi, Uferah
AU  - Mumtaz, Rafia
AU  - Haq, Ihsan U.
AU  - Hafeez, Maryam
AU  - Iqbal, Naveed
AU  - Shaukat, Arslan
AU  - Zaidi, Syed M.
AU  - Mahmood, Zahid
TI  - Wheat Yellow Rust Disease Infection Type Classification Using Texture Features
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Wheat is a staple crop of Pakistan that covers almost 40% of the cultivated land and contributes almost 3% in the overall Gross Domestic Product (GDP) of Pakistan. However, due to increasing seasonal variation, it was observed that wheat is majorly affected by rust disease, particularly in rain-fed areas. Rust is considered the most harmful fungal disease for wheat, which can cause reductions of 20&ndash;30% in wheat yield. Its capability to spread rapidly over time has made its management most challenging, becoming a major threat to food security. In order to counter this threat, precise detection of wheat rust and its infection types is important for minimizing yield losses. For this purpose, we have proposed a framework for classifying wheat yellow rust infection types using machine learning techniques. First, an image dataset of different yellow rust infections was collected using mobile cameras. Six Gray Level Co-occurrence Matrix (GLCM) texture features and four Local Binary Patterns (LBP) texture features were extracted from grayscale images of the collected dataset. In order to classify wheat yellow rust disease into its three classes (healthy, resistant, and susceptible), Decision Tree, Random Forest, Light Gradient Boosting Machine (LightGBM), Extreme Gradient Boosting (XGBoost), and CatBoost were used with (i) GLCM, (ii) LBP, and (iii) combined GLCM-LBP texture features. The results indicate that CatBoost outperformed on GLCM texture features with an accuracy of 92.30%. This accuracy can be further improved by scaling up the dataset and applying deep learning models. The development of the proposed study could be useful for the agricultural community for the early detection of wheat yellow rust infection and assist in taking remedial measures to contain crop yield.
KW  - texture analysis
KW  - wheat yellow rust disease
KW  - GLCM features
KW  - feature extraction
KW  - machine learning
KW  - local binary pattern (LBP)
DO  - 10.3390/s22010146
ER  -
TY  - EJOU
AU  - Avazov, Kuldoshbay
AU  - Mukhiddinov, Mukhriddin
AU  - Makhmudov, Fazliddin
AU  - Cho, Young I.
TI  - Fire Detection Method in Smart City Environments Using a Deep-Learning-Based Approach
T2  - Electronics

PY  - 2022
VL  - 11
IS  - 1
SN  - 2079-9292

AB  - In the construction of new smart cities, traditional fire-detection systems can be replaced with vision-based systems to establish fire safety in society using emerging technologies, such as digital cameras, computer vision, artificial intelligence, and deep learning. In this study, we developed a fire detector that accurately detects even small sparks and sounds an alarm within 8 s of a fire outbreak. A novel convolutional neural network was developed to detect fire regions using an enhanced You Only Look Once (YOLO) v4network. Based on the improved YOLOv4 algorithm, we adapted the network to operate on the Banana Pi M3 board using only three layers. Initially, we examined the originalYOLOv4 approach to determine the accuracy of predictions of candidate fire regions. However, the anticipated results were not observed after several experiments involving this approach to detect fire accidents. We improved the traditional YOLOv4 network by increasing the size of the training dataset based on data augmentation techniques for the real-time monitoring of fire disasters. By modifying the network structure through automatic color augmentation, reducing parameters, etc., the proposed method successfully detected and notified the incidence of disastrous fires with a high speed and accuracy in different weather environments&mdash;sunny or cloudy, day or night. Experimental results revealed that the proposed method can be used successfully for the protection of smart cities and in monitoring fires in urban areas. Finally, we compared the performance of our method with that of recently reported fire-detection approaches employing widely used performance matrices to test the fire classification results achieved.
KW  - fire detection
KW  - smart city
KW  - YOLOv4
KW  - surveillance system
KW  - fire-like lights
DO  - 10.3390/electronics11010073
ER  -
TY  - EJOU
AU  - Kang, Cheongwoong
AU  - Park, Bumjin
AU  - Choi, Jaesik
TI  - Scheduling PID Attitude and Position Control Frequencies for Time-Optimal Quadrotor Waypoint Tracking under Unknown External Disturbances
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Recently, the use of quadrotors has increased in numerous applications, such as agriculture, rescue, transportation, inspection, and localization. Time-optimal quadrotor waypoint tracking is defined as controlling quadrotors to follow the given waypoints as quickly as possible. Although PID control is widely used for quadrotor control, it is not adaptable to environmental changes, such as various trajectories and dynamic external disturbances. In this work, we discover that adjusting PID control frequencies is necessary for adapting to environmental changes by showing that the optimal control frequencies can be different for different environments. Therefore, we suggest a method to schedule the PID position and attitude control frequencies for time-optimal quadrotor waypoint tracking. The method includes (1) a Control Frequency Agent (CFA) that finds the best control frequencies in various environments, (2) a Quadrotor Future Predictor (QFP) that predicts the next state of a quadrotor, and (3) combining the CFA and QFP for time-optimal quadrotor waypoint tracking under unknown external disturbances. The experimental results prove the effectiveness of the proposed method by showing that it reduces the travel time of a quadrotor for waypoint tracking.
KW  - waypoint tracking
KW  - external disturbance estimation
KW  - quadrotor control
KW  - reinforcement learning
KW  - deep learning
KW  - artificial intelligence
DO  - 10.3390/s22010150
ER  -
TY  - EJOU
AU  - Zhang, Di
AU  - Pan, Feng
AU  - Diao, Qi
AU  - Feng, Xiaoxue
AU  - Li, Weixing
AU  - Wang, Jiacheng
TI  - Seeding Crop Detection Framework Using Prototypical Network Method in UAV Images
T2  - Agriculture

PY  - 2022
VL  - 12
IS  - 1
SN  - 2077-0472

AB  - With the development of unmanned aerial vehicle (UAV), obtaining high-resolution aerial images has become easier. Identifying and locating specific crops from aerial images is a valuable task. The location and quantity of crops are important for agricultural insurance businesses. In this paper, the problem of locating chili seedling crops in large-field UAV images is processed. Two problems are encountered in the location process: a small number of samples and objects in UAV images are similar on a small scale, which increases the location difficulty. A detection framework based on a prototypical network to detect crops in UAV aerial images is proposed. In particular, a method of subcategory slicing is applied to solve the problem, in which objects in aerial images have similarities at a smaller scale. The detection framework is divided into two parts: training and detection. In the training process, crop images are sliced into subcategories, and then these subcategory patch images and background category images are used to train the prototype network. In the detection process, a simple linear iterative clustering superpixel segmentation method is used to generate candidate regions in the UAV image. The location method uses a prototypical network to recognize nine patch images extracted simultaneously. To train and evaluate the proposed method, we construct an evaluation dataset by collecting the images of chilies in a seedling stage by an UAV. We achieve a location accuracy of 96.46%. This study proposes a seedling crop detection framework based on few-shot learning that does not require the use of labeled boxes. It reduces the workload of manual annotation and meets the location needs of seedling crops.
KW  - chili detection
KW  - prototypical network
KW  - small-scale similarity problem
KW  - unmanned aerial vehicle images
DO  - 10.3390/agriculture12010026
ER  -
TY  - EJOU
AU  - Wang, Zixiong
AU  - Sun, Ya
AU  - Li, Chunhui
AU  - Jin, Ling
AU  - Sun, Xinguo
AU  - Liu, Xiaoli
AU  - Wang, Tianxiang
TI  - Analysis of Small and Medium&ndash;Scale River Flood Risk in Case of Exceeding Control Standard Floods Using Hydraulic Model
T2  - Water

PY  - 2022
VL  - 14
IS  - 1
SN  - 2073-4441

AB  - Exceeding control standard floods pose threats to the management of small and medium&ndash;scale rivers. Taking Fuzhouhe river as an example, this paper analyzes the submerged depth, submerged area and arrival time of river flood risk in the case of exceeding control standard floods (with return period of 20, 50, 100 and 200 years) through a coupled one&ndash; and two&ndash;dimensional hydrodynamic model, draws the flood risk maps and proposes emergency plans. The simulation results of the one&ndash;dimensional model reveal that the dikes would be at risk of overflowing for different frequencies of floods, with a higher level of risk on the left bank. The results of the coupled model demonstrate that under all scenarios, the inundation area gradually increases with time until the flood peak subsides, and the larger the flood peak, the faster the inundation area increases. The maximum submerged areas are 42.73 km2, 65.95 km2, 74.86 km2 and 82.71 km2 for four frequencies of flood, respectively. The change of submerged depth under different frequency floods shows a downward&ndash;upward&ndash;downward trend and the average submerged depth of each frequency floods is about 1.4 m. The flood risk maps of different flood frequencies are created by GIS to analyze flood arrival time, submerged area and submerged depth to plan escape routes and resettlement units. The migration distances are limited within 4 km, the average migration distance is about 2 km, the vehicle evacuation time is less than 20 min, and the walking evacuation time is set to about 70 min. It is concluded that the flood risk of small and medium&ndash;scale rivers is a dynamic change process, and dynamic flood assessment, flood warning and embankment modification scheme should be further explored.
KW  - small and medium–scale river
KW  - flood risk
KW  - submerged area
KW  - submerged depth
KW  - evacuation plan
DO  - 10.3390/w14010057
ER  -
TY  - EJOU
AU  - Čorňák, Marek
AU  - Tölgyessy, Michal
AU  - Hubinský, Peter
TI  - Innovative Collaborative Method for Interaction between a Human Operator and Robotic Manipulator Using Pointing Gestures
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 1
SN  - 2076-3417

AB  - The concept of &ldquo;Industry 4.0&rdquo; relies heavily on the utilization of collaborative robotic applications. As a result, the need for an effective, natural, and ergonomic interface arises, as more workers will be required to work with robots. Designing and implementing natural forms of human&ndash;robot interaction (HRI) is key to ensuring efficient and productive collaboration between humans and robots. This paper presents a gestural framework for controlling a collaborative robotic manipulator using pointing gestures. The core principle lies in the ability of the user to send the robot&rsquo;s end effector to the location towards, which he points to by his hand. The main idea is derived from the concept of so-called &ldquo;linear HRI&rdquo;. The framework utilizes a collaborative robotic arm UR5e and the state-of-the-art human body tracking sensor Leap Motion. The user is not required to wear any equipment. The paper describes the overview of the framework&rsquo;s core method and provides the necessary mathematical background. An experimental evaluation of the method is provided, and the main influencing factors are identified. A unique robotic collaborative workspace called Complex Collaborative HRI Workplace (COCOHRIP) was designed around the gestural framework to evaluate the method and provide the basis for the future development of HRI applications.
KW  - HRI (human–robot interaction)
KW  - Leap Motion
KW  - UR5
KW  - hand gesture recognition
KW  - pointing gestures
KW  - collaborative robotics
DO  - 10.3390/app12010258
ER  -
TY  - EJOU
AU  - Besada, Juan A.
AU  - Campaña, Ivan
AU  - Carramiñana, David
AU  - Bergesio, Luca
AU  - de Miguel, Gonzalo
TI  - Review and Simulation of Counter-UAS Sensors for Unmanned Traffic Management
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Noncollaborative surveillance of airborne UAS (Unmanned Aerial System) is a key enabler to the safe integration of UAS within a UTM (Unmanned Traffic Management) ecosystem. Thus, a wide variety of new sensors (known as Counter-UAS sensors) are being developed to provide real-time UAS tracking, ranging from radar, RF analysis and image-based detection to even sound-based sensors. This paper aims to discuss the current state-of-the art technology in this wide variety of sensors (both academically and commercially) and to propose a set of simulation models for them. Thus, the review is focused on identifying the key parameters and processes that allow modeling their performance and operation, which reflect the variety of measurement processes. The resulting simulation models are designed to help evaluate how sensors&rsquo; performances affect UTM systems, and specifically the implications in their tracking and tactical services (i.e., tactical conflicts with uncontrolled drones). The simulation models cover probabilistic detection (i.e., false alarms and probability of detection) and measurement errors, considering equipment installation (i.e., monostatic vs. multistatic configurations, passive sensing, etc.). The models were integrated in a UTM simulation platform and simulation results are included in the paper for active radars, passive radars, and acoustic sensors.
KW  - counter-UAS sensors
KW  - unmanned traffic management
KW  - review
KW  - simulation models
DO  - 10.3390/s22010189
ER  -
TY  - EJOU
AU  - Yang, Feifei
AU  - Liu, Shengping
AU  - Wang, Qiyuan
AU  - Liu, Tao
AU  - Li, Shijuan
TI  - Assessing Waterlogging Stress Level of Winter Wheat from Hyperspectral Imagery Based on Harmonic Analysis
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Frequent waterlogging disasters can have serious effects on regional ecology, food safety, and socioeconomic sustainable development. Early monitoring of waterlogging stress levels is vital for accurate production input management and reduction of crop production-related risks. In this study, a pot experiment on winter wheat was designed using three varieties and seven gradients of waterlogging stress. Hyperspectral imagery of the winter wheat canopy in the jointing stage, heading stage, flowering stage, filling stage, and maturation stage were measured and then classified. Wavebands of imaging data were screened. Waterlogging stress level was assessed by a combined harmonic analysis method, and application of this method at field scale was discussed preliminarily. Results show that compared to the k-nearest neighbor and support vector machine algorithms, the random forest algorithm is the best batch classification method for hyperspectral imagery of potted winter wheat. It can recognize waterlogging stress well in the wavebands of red absorption valley (RW: 640&ndash;680 nm), red-edge (RE: 670&ndash;737 nm), and near-infrared (NIR: 700&ndash;900 nm). In the RW region, amplitudes of the first three harmonic sub-signals (c1, c2, and c3) can be used as indexes to recognize the waterlogging stress level that each winter wheat variety undertakes. The third harmonic sub-signal amplitude c3 of the RE region is also suitable for judging stress levels of JM31 (one of the three varieties which is highly sensitive to water content). This study has important theoretical significance and practical application values related to the accurate control of waterlogging stress, and functions as a new method to monitor other types of environmental stress levels such as drought stress, freezing stress, and high-temperature stress levels.
KW  - waterlogging stress level
KW  - hyperspectral imagery
KW  - harmonic analysis
KW  - winter wheat
DO  - 10.3390/rs14010122
ER  -
TY  - EJOU
AU  - Yao, Xin
AU  - Shi, Xiaoran
AU  - Li, Yaxin
AU  - Wang, Li
AU  - Wang, Han
AU  - Ren, Shijie
AU  - Zhou, Feng
TI  - GMT-WGAN: An Adversarial Sample Expansion Method for Ground Moving Targets Classification
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - In the field of target classification, detecting a ground moving target that is easily covered in clutter has been a challenge. In addition, traditional feature extraction techniques and classification methods usually rely on strong subjective factors and prior knowledge, which affect their generalization capacity. Most existing deep-learning-based methods suffer from insufficient feature learning due to the lack of data samples, which makes it difficult for the training process to converge to a steady-state. To overcome these limitations, this paper proposes a Wasserstein generative adversarial network (WGAN) sample enhancement method for ground moving target classification (GMT-WGAN). First, the micro-Doppler characteristics of ground moving targets are analyzed. Next, a WGAN is constructed to generate effective time&ndash;frequency images of ground moving targets and thereby enrich the sample database used to train the classification network. Then, image quality evaluation indexes are introduced to evaluate the generated spectrogram samples, with an aim to verify the distribution similarity of generated and real samples. Afterward, by feeding augmented samples to the deep convolutional neural networks with good generalization capacity, the classification performance of the GMT-WGAN is improved. Finally, experiments conducted on different datasets validate the effectiveness and robustness of the proposed method.
KW  - ground moving target classification
KW  - Wasserstein generative adversarial network
KW  - deep convolutional neural network
KW  - image quality evaluation
DO  - 10.3390/rs14010123
ER  -
TY  - EJOU
AU  - Muntean, Maria V.
TI  - Multi-Agent System for Intelligent Urban Traffic Management Using Wireless Sensor Networks Data
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Intelligent traffic management is an important issue for smart cities. City councils try to implement the newest techniques and performant technologies in order to avoid traffic congestion, to optimize the use of traffic lights, to efficiently use car parking, etc. To find the best solution to this problem, Birmingham City Council decided to allow open-source predictive traffic forecasting by making the real-time datasets available. This paper proposes a multi-agent system (MAS) approach for intelligent urban traffic management in Birmingham using forecasting and classification techniques. The designed agents have the following tasks: forecast the occupancy rates for traffic flow, road junctions and car parking; classify the faults; control and monitor the entire process. The experimental results show that k-nearest neighbor forecasts with high accuracy rates for the traffic data and decision trees build the most accurate model for classifying the faults for their detection and repair in the shortest possible time. The whole learning process is coordinated by a monitoring agent in order to automate Birmingham city&rsquo;s traffic management.
KW  - multi-agent system
KW  - classification
KW  - forecasting
KW  - smart cities
KW  - urban traffic management
DO  - 10.3390/s22010208
ER  -
TY  - EJOU
AU  - Munguia, Rodrigo
AU  - Trujillo, Juan-Carlos
AU  - Guerra, Edmundo
AU  - Grau, Antoni
TI  - A Hybrid Visual-Based SLAM Architecture: Local Filter-Based SLAM with KeyFrame-Based Global Mapping
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - This work presents a hybrid visual-based SLAM architecture that aims to take advantage of the strengths of each of the two main methodologies currently available for implementing visual-based SLAM systems, while at the same time minimizing some of their drawbacks. The main idea is to implement a local SLAM process using a filter-based technique, and enable the tasks of building and maintaining a consistent global map of the environment, including the loop closure problem, to use the processes implemented using optimization-based techniques. Different variants of visual-based SLAM systems can be implemented using the proposed architecture. This work also presents the implementation case of a full monocular-based SLAM system for unmanned aerial vehicles that integrates additional sensory inputs. Experiments using real data obtained from the sensors of a quadrotor are presented to validate the feasibility of the proposed approach.
KW  - visual SLAM
KW  - filter
KW  - optimization
KW  - key-frame
KW  - hybrid
KW  - local mapping
KW  - global mapping
KW  - loop closure
DO  - 10.3390/s22010210
ER  -
TY  - EJOU
AU  - Chen, Qi
AU  - Zhang, Yuanyi
AU  - Li, Xinyuan
AU  - Tao, Pengjie
TI  - Extracting Rectified Building Footprints from Traditional Orthophotos: A New Workflow
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Deep learning techniques such as convolutional neural networks have largely improved the performance of building segmentation from remote sensing images. However, the images for building segmentation are often in the form of traditional orthophotos, where the relief displacement would cause non-negligible misalignment between the roof outline and the footprint of a building; such misalignment poses considerable challenges for extracting accurate building footprints, especially for high-rise buildings. Aiming at alleviating this problem, a new workflow is proposed for generating rectified building footprints from traditional orthophotos. We first use the facade labels, which are prepared efficiently at low cost, along with the roof labels to train a semantic segmentation network. Then, the well-trained network, which employs the state-of-the-art version of EfficientNet as backbone, extracts the roof segments and the facade segments of buildings from the input image. Finally, after clustering the classified pixels into instance-level building objects and tracing out the roof outlines, an energy function is proposed to drive the roof outline to maximally align with the building footprint; thus, the rectified footprints can be generated. The experiments on the aerial orthophotos covering a high-density residential area in Shanghai demonstrate that the proposed workflow can generate obviously more accurate building footprints than the baseline methods, especially for high-rise buildings.
KW  - image segmentation
KW  - building footprint
KW  - aerial orthophoto
KW  - relief displacement
DO  - 10.3390/s22010207
ER  -
TY  - EJOU
AU  - Gromada, Krzysztof A.
AU  - Stecz, Wojciech M.
TI  - Designing a Reliable UAV Architecture Operating in a Real Environment
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 1
SN  - 2076-3417

AB  - The article presents a method of designing a selected unmanned aerial platform flight scenario based on the principles of designing a reliable (Unmanned Aerial Vehicle) UAV architecture operating in an environment in which other platforms operate. The models and results presented relate to the medium-range aerial platform, subject to certification under the principles set out in aviation regulations. These platforms are subject to the certification process requirements, but their restrictions are not as restrictive as in the case of manned platforms. Issues related to modeling scenarios implemented by the platform in flight are discussed. The article describes the importance of Functional Hazard Analysis (FHA) and Fault Trees Analysis (FTA) of elements included in the hardware and software architecture of the system. The models in Unified Modeling Language (UML) used by the authors in the project are described, supporting the design of a reliable architecture of flying platforms. Examples of the transformations from user requirements modeled in the form of Use Cases to platform operation models based on State Machines and then to the final UAV operation algorithms are shown. Principles of designing system test plans and designing individual test cases to verify the system&rsquo;s operation in emergencies in flight are discussed. Methods of integrating flight simulators with elements of the air platform in the form of Software-in-the-Loop (SIL) models based on selected algorithms for avoiding dangerous situations have been described. The presented results are based on a practical example of an algorithm for detecting an air collision situation of two platforms.
KW  - Unmanned Aerial Vehicle (UAV)
KW  - collision avoidance
KW  - safety procedures
KW  - reliable architecture
KW  - Unified Modeling Language (UML)
DO  - 10.3390/app12010294
ER  -
TY  - EJOU
AU  - Velusamy, Parthasarathy
AU  - Rajendran, Santhosh
AU  - Mahendran, Rakesh K.
AU  - Naseer, Salman
AU  - Shafiq, Muhammad
AU  - Choi, Jin-Ghoo
TI  - Unmanned Aerial Vehicles (UAV) in Precision Agriculture: Applications and Challenges
T2  - Energies

PY  - 2022
VL  - 15
IS  - 1
SN  - 1996-1073

AB  - Agriculture is the primary source of income in developing countries like India. Agriculture accounts for 17 percent of India&rsquo;s total GDP, with almost 60 percent of the people directly or indirectly employed. While researchers and planters focus on a variety of elements to boost productivity, crop loss due to disease is one of the most serious issues they confront. Crop growth monitoring and early detection of pest infestations are still a problem. With the expansion of cultivation to wider fields, manual intervention to monitor and diagnose insect and pest infestations is becoming increasingly difficult. Failure to apply on time fertilizers and pesticides results in more crop loss and so lower output. Farmers are putting in greater effort to conserve crops, but they are failing most of the time because they are unable to adequately monitor the crops when they are infected by pests and insects. Pest infestation is also difficult to predict because it is not evenly distributed. In the recent past, modern equipment, tools, and approaches have been used to replace manual involvement. Unmanned aerial vehicles serve a critical role in crop disease surveillance and early detection in this setting. This research attempts to give a review of the most successful techniques to have precision-based crop monitoring and pest management in agriculture fields utilizing unmanned aerial vehicles (UAVs) or unmanned aircraft. The researchers&rsquo; reports on the various types of UAVs and their applications to early detection of agricultural diseases are rigorously assessed and compared. This paper also discusses the deployment of aerial, satellite, and other remote sensing technologies for disease detection, as well as their Quality of Service (QoS).
KW  - UAV
KW  - crop monitoring
KW  - pest management
KW  - remote sensing
DO  - 10.3390/en15010217
ER  -
TY  - EJOU
AU  - Basan, Elena
AU  - Basan, Alexandr
AU  - Nekrasov, Alexey
AU  - Fidge, Colin
AU  - Sushkin, Nikita
AU  - Peskova, Olga
TI  - GPS-Spoofing Attack Detection Technology for UAVs Based on Kullback&ndash;Leibler Divergence
T2  - Drones

PY  - 2022
VL  - 6
IS  - 1
SN  - 2504-446X

AB  - Here, we developed a method for detecting cyber security attacks aimed at spoofing the Global Positioning System (GPS) signal of an Unmanned Aerial Vehicle (UAV). Most methods for detecting UAV anomalies indicative of an attack use machine learning or other such methods that compare normal behavior with abnormal behavior. Such approaches require large amounts of data and significant &ldquo;training&rdquo; time to prepare and implement the system. Instead, we consider a new approach based on other mathematical methods for detecting UAV anomalies without the need to first collect a large amount of data and describe normal behavior patterns. Doing so can simplify the process of creating an anomaly detection system, which can further facilitate easier implementation of intrusion detection systems in UAVs. This article presents issues related to ensuring the information security of UAVs. Development of the GPS spoofing detection method for UAVs is then described, based on a preliminary study that made it possible to form a mathematical apparatus for solving the problem. We then explain the necessary analysis of parameters and methods of data normalization, and the analysis of the Kullback&mdash;Leibler divergence measure needed to detect anomalies in UAV systems.
KW  - UAV
KW  - GPS
KW  - vulnerabilities
KW  - anomalies
KW  - spoofing
KW  - Kullback–Leibler divergence
KW  - cyber attacks
DO  - 10.3390/drones6010008
ER  -
TY  - EJOU
AU  - Rani, Pooja
AU  - Kavita
AU  - Verma, Sahil
AU  - Kaur, Navneet
AU  - Wozniak, Marcin
AU  - Shafi, Jana
AU  - Ijaz, Muhammad F.
TI  - Robust and Secure Data Transmission Using Artificial Intelligence Techniques in Ad-Hoc Networks
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - The paper presents a new security aspect for a Mobile Ad-Hoc Network (MANET)-based IoT model using the concept of artificial intelligence. The Black Hole Attack (BHA) is considered one of the most affecting threats in the MANET in which the attacker node drops the entire data traffic and hence degrades the network performance. Therefore, it necessitates the designing of an algorithm that can protect the network from the BHA node. This article introduces Ad-hoc On-Demand Distance Vector (AODV), a new updated routing protocol that combines the advantages of the Artificial Bee Colony (ABC), Artificial Neural Network (ANN), and Support Vector Machine (SVM) techniques. The combination of the SVM with ANN is the novelty of the proposed model that helps to identify the attackers within the discovered route using the AODV routing mechanism. Here, the model is trained using ANN but the selection of training data is performed using the ABC fitness function followed by SVM. The role of ABC is to provide a better route for data transmission between the source and the destination node. The optimized route, suggested by ABC, is then passed to the SVM model along with the node&rsquo;s properties. Based on those properties ANN decides whether the node is a normal or an attacker node. The simulation analysis performed in MATLAB shows that the proposed work exhibits an improvement in terms of Packet Delivery Ratio (PDR), throughput, and delay. To validate the system efficiency, a comparative analysis is performed against the existing approaches such as Decision Tree and Random Forest that indicate that the utilization of the SVM with ANN is a beneficial step regarding the detection of BHA attackers in the MANET-based IoT networks.
KW  - MANET
KW  - AODV
KW  - Black Hole Attack (BHA)
KW  - Artificial Bee Colony algorithm
KW  - artificial neural network
DO  - 10.3390/s22010251
ER  -
TY  - EJOU
AU  - You, Jie
AU  - Zhang, Ruirui
AU  - Lee, Joonwhoan
TI  - A Deep Learning-Based Generalized System for Detecting Pine Wilt Disease Using RGB-Based UAV Images
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Pine wilt is a devastating disease that typically kills affected pine trees within a few months. In this paper, we confront the problem of detecting pine wilt disease. In the image samples that have been used for pine wilt disease detection, there is high ambiguity due to poor image resolution and the presence of &ldquo;disease-like&rdquo; objects. We therefore created a new dataset using large-sized orthophotographs collected from 32 cities, 167 regions, and 6121 pine wilt disease hotspots in South Korea. In our system, pine wilt disease was detected in two stages: n the first stage, the disease and hard negative samples were collected using a convolutional neural network. Because the diseased areas varied in size and color, and as the disease manifests differently from the early stage to the late stage, hard negative samples were further categorized into six different classes to simplify the complexity of the dataset. Then, in the second stage, we used an object detection model to localize the disease and &ldquo;disease-like&rdquo; hard negative samples. We used several image augmentation methods to boost system performance and avoid overfitting. The test process was divided into two phases: a patch-based test and a real-world test. During the patch-based test, we used the test-time augmentation method to obtain the average prediction of our system across multiple augmented samples of data, and the prediction results showed a mean average precision of 89.44% in five-fold cross validation, thus representing an increase of around 5% over the alternative system. In the real-world test, we collected 10 orthophotographs in various resolutions and areas, and our system successfully detected 711 out of 730 potential disease spots.
KW  - pine wilt disease dataset
KW  - GIS application visualization
KW  - test-time augmentation
KW  - object detection
KW  - hard negative mining
DO  - 10.3390/rs14010150
ER  -
TY  - EJOU
AU  - Sinde-González, Izar
AU  - Gómez-López, Josselyn P.
AU  - Tapia-Navarro, Stalin A.
AU  - Murgueitio, Erika
AU  - Falconí, César
AU  - Benítez, Fatima L.
AU  - Toulkeridis, Theofilos
TI  - Determining the Effects of Nanonutrient Application in Cabbage (Brassica oleracea var. capitate L.) Using Spectrometry and Biomass Estimation with UAV
T2  - Agronomy

PY  - 2022
VL  - 12
IS  - 1
SN  - 2073-4395

AB  - Geospatial technologies are presented as an alternative for the monitoring and control of crops, as demonstrated through the analysis of spectral responses (SR) of each species. In this study, it was intended to determine the effects of the application of nanonutrients (Zn and Mn) in cabbage (Brassica oleracea var. capitate L.) by analyzing the relationship between the vegetation indices (VI) NDVI, GNDVI, NGRDI, RVI, GVI, CCI RARSa and the content of chlorophyll (CC), from two trials established in the field and in the greenhouse, together with the calculation of dry biomass production in the field through the use of digital models and its further validation. The results indicated that for greenhouse experiments no significant differences were found between the VIs in the implemented treatments, rather for their phenological states. Whereas in the field assays it was evidenced that there were significant differences between the VIs for the treatments, as well as for the phenological states. The SR issued in the field allowed the evaluation of the behavior of the crop due to the application of nanonutrients, which did not occur in the greenhouse, in the same way. The SR also enabled the spectral characterization of the crop in its phenological states in the two trials. All this information was stored in a digital format, which allowed the creation of a spectral library which was published on a web server. The validation of the dry biomass allowed, by statistical analysis, the efficiency of the method used for its estimation to be confirmed.
KW  - UAV
KW  - nanonutrients
KW  - vegetation indices
KW  - spectral response
KW  - biomass
DO  - 10.3390/agronomy12010081
ER  -
TY  - EJOU
AU  - Lin, Cheng-Yu
AU  - Wang, Yi-Wen
AU  - Setiawan, Febryan
AU  - Trang, Nguyen T.
AU  - Lin, Che-Wei
TI  - Sleep Apnea Classification Algorithm Development Using a Machine-Learning Framework and Bag-of-Features Derived from Electrocardiogram Spectrograms
T2  - Journal of Clinical Medicine

PY  - 2022
VL  - 11
IS  - 1
SN  - 2077-0383

AB  - Background: Heart rate variability (HRV) and electrocardiogram (ECG)-derived respiration (EDR) have been used to detect sleep apnea (SA) for decades. The present study proposes an SA-detection algorithm using a machine-learning framework and bag-of-features (BoF) derived from an ECG spectrogram. Methods: This study was verified using overnight ECG recordings from 83 subjects with an average apnea&ndash;hypopnea index (AHI) 29.63 (/h) derived from the Physionet Apnea-ECG and National Cheng Kung University Hospital Sleep Center database. The study used signal preprocessing to filter noise and artifacts, ECG time&ndash;frequency transformation using continuous wavelet transform (CWT), BoF feature generation, machine-learning classification using support vector machine (SVM), ensemble learning (EL), k-nearest neighbor (KNN) classification, and cross-validation. The time length of the spectrogram was set as 10 and 60 s to examine the required minimum spectrogram window time length to achieve satisfactory accuracy. Specific frequency bands of 0.1&ndash;50, 8&ndash;50, 0.8&ndash;10, and 0&ndash;0.8 Hz were also extracted to generate the BoF to determine the band frequency best suited for SA detection. Results: The five-fold cross-validation accuracy using the BoF derived from the ECG spectrogram with 10 and 60 s time windows were 90.5% and 91.4% for the 0.1&ndash;50 Hz and 8&ndash;50 Hz frequency bands, respectively. Conclusion: An SA-detection algorithm utilizing BoF and a machine-learning framework was successfully developed in this study with satisfactory classification accuracy and high temporal resolution.
KW  - sleep apnea
KW  - time–frequency transformation
KW  - bag-of-features
KW  - support vector machine
KW  - k-nearest neighbor algorithm
KW  - ensemble learning
DO  - 10.3390/jcm11010192
ER  -
TY  - EJOU
AU  - Tanveer, Jawad
AU  - Haider, Amir
AU  - Ali, Rashid
AU  - Kim, Ajung
TI  - Machine Learning for Physical Layer in 5G and beyond Wireless Networks: A Survey
T2  - Electronics

PY  - 2022
VL  - 11
IS  - 1
SN  - 2079-9292

AB  - Fifth-generation (5G) technology will play a vital role in future wireless networks. The breakthrough 5G technology will unleash a massive Internet of Everything (IoE), where billions of connected devices, people, and processes will be simultaneously served. The services provided by 5G include several use cases enabled by the enhanced mobile broadband, massive machine-type communications, and ultra-reliable low-latency communication. Fifth-generation networks potentially merge multiple networks on a single platform, providing a landscape for seamless connectivity, particularly for high-mobility devices. With their enhanced speed, 5G networks are prone to various research challenges. In this context, we provide a comprehensive survey on 5G technologies that emphasize machine learning-based solutions to cope with existing and future challenges. First, we discuss 5G network architecture and outline the key performance indicators compared to the previous and upcoming network generations. Second, we discuss next-generation wireless networks and their characteristics, applications, and use cases for fast connectivity to billions of devices. Then, we confer physical layer services, functions, and issues that decrease the signal quality. We also present studies on 5G network technologies, 5G propelling trends, and architectures that help to achieve the goals of 5G. Moreover, we discuss signaling techniques for 5G massive multiple-input and multiple-output and beam-forming techniques to enhance data rates with efficient spectrum sharing. Further, we review security and privacy concerns in 5G and standard bodies&rsquo; actionable recommendations for policy makers. Finally, we also discuss emerging challenges and future directions.
KW  - 5G
KW  - B5G
KW  - wireless networks
KW  - machine learning
KW  - MIMO
KW  - physical layer
KW  - IoT
DO  - 10.3390/electronics11010121
ER  -
TY  - EJOU
AU  - Domingo, Mari C.
TI  - Power Allocation and Energy Cooperation for UAV-Enabled MmWave Networks: A Multi-Agent Deep Reinforcement Learning Approach
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Unmanned Aerial Vehicle (UAV)-assisted cellular networks over the millimeter-wave (mmWave) frequency band can meet the requirements of a high data rate and flexible coverage in next-generation communication networks. However, higher propagation loss and the use of a large number of antennas in mmWave networks give rise to high energy consumption and UAVs are constrained by their low-capacity onboard battery. Energy harvesting (EH) is a viable solution to reduce the energy cost of UAV-enabled mmWave networks. However, the random nature of renewable energy makes it challenging to maintain robust connectivity in UAV-assisted terrestrial cellular networks. Energy cooperation allows UAVs to send their excessive energy to other UAVs with reduced energy. In this paper, we propose a power allocation algorithm based on energy harvesting and energy cooperation to maximize the throughput of a UAV-assisted mmWave cellular network. Since there is channel-state uncertainty and the amount of harvested energy can be treated as a stochastic process, we propose an optimal multi-agent deep reinforcement learning algorithm (DRL) named Multi-Agent Deep Deterministic Policy Gradient (MADDPG) to solve the renewable energy resource allocation problem for throughput maximization. The simulation results show that the proposed algorithm outperforms the Random Power (RP), Maximal Power (MP) and value-based Deep Q-Learning (DQL) algorithms in terms of network throughput.
KW  - Unmanned Aerial Vehicles (UAVs)
KW  - energy harvesting
KW  - energy cooperation
KW  - power allocation
KW  - Multi-Agent Deep Reinforcement Learning (MADDPG)
DO  - 10.3390/s22010270
ER  -
TY  - EJOU
AU  - Akcay, Ozgun
AU  - Kinaci, Ahmet C.
AU  - Avsar, Emin O.
AU  - Aydar, Umut
TI  - Semantic Segmentation of High-Resolution Airborne Images with Dual-Stream DeepLabV3+
T2  - ISPRS International Journal of Geo-Information

PY  - 2022
VL  - 11
IS  - 1
SN  - 2220-9964

AB  - In geospatial applications such as urban planning and land use management, automatic detection and classification of earth objects are essential and primary subjects. When the significant semantic segmentation algorithms are considered, DeepLabV3+ stands out as a state-of-the-art CNN. Although the DeepLabV3+ model is capable of extracting multi-scale contextual information, there is still a need for multi-stream architectural approaches and different training approaches of the model that can leverage multi-modal geographic datasets. In this study, a new end-to-end dual-stream architecture that considers geospatial imagery was developed based on the DeepLabV3+ architecture. As a result, the spectral datasets other than RGB provided increments in semantic segmentation accuracies when they were used as additional channels to height information. Furthermore, both the given data augmentation and Tversky loss function which is sensitive to imbalanced data accomplished better overall accuracies. Also, it has been shown that the new dual-stream architecture using Potsdam and Vaihingen datasets produced 88.87% and 87.39% overall semantic segmentation accuracies, respectively. Eventually, it was seen that enhancement of the traditional significant semantic segmentation networks has a great potential to provide higher model performances, whereas the contribution of geospatial data as the second stream to RGB to segmentation was explicitly shown.
KW  - deep learning
KW  - semantic segmentation
KW  - photogrammetry
KW  - multi-spectral aerial imagery
KW  - digital surface model
KW  - vegetation index
KW  - land cover classification
DO  - 10.3390/ijgi11010023
ER  -
TY  - EJOU
AU  - Zhang, Xuan
AU  - Zhu, Chun
AU  - He, Manchao
AU  - Dong, Menglong
AU  - Zhang, Guangcheng
AU  - Zhang, Faming
TI  - Failure Mechanism and Long Short-Term Memory Neural Network Model for Landslide Risk Prediction
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Rockslides along a stepped failure surface have characteristics of stepped deformation characteristic and it is difficult to predict the failure time. In this study, the deformation characteristics and disaster prediction model of the Fengning granite rockslide were analyzed based on field surveys and monitoring data. To evaluate the stability, the shear strength parameters of the sliding surface were determined based on the back-propagation neural network and three-dimensional discrete element numerical method. Through the correlation analysis of deformation monitoring results with rainfall and blasting, it is shown that the landslide was triggered by excavation, rainfall, and blasting vibrations. The landslide displacement prediction model was established by using long short-term memory neural network (LSTM) based on the monitoring data, and the prediction results are compared with those using the BP model, SVM model and ARMA model. Results show that the LSTM model has strong advantages and good reliability for the stepped landslide deformation with short-term influence, and the predicted LSTM values were very consistent with the measured values, with a correlation coefficient of 0.977. Combined with the distribution characteristics of joints, the damage influence scope of the landslide was simulated by three-dimensional discrete element, which provides decision-making basis for disaster warning after slope instability. The method proposed in this paper can provide references for early warning and treatment of geological disasters.
KW  - step moving rockslide
KW  - long short-term memory neural network
KW  - joint persistence ratio
KW  - deformation forecasting
KW  - hydrodynamic action
DO  - 10.3390/rs14010166
ER  -
TY  - EJOU
AU  - Tehseen, Aqsa
AU  - Zafar, Nazir A.
AU  - Ali, Tariq
AU  - Jameel, Fatima
AU  - Alkhammash, Eman H.
TI  - Formal Modeling of IoT and Drone-Based Forest Fire Detection and Counteraction System
T2  - Electronics

PY  - 2022
VL  - 11
IS  - 1
SN  - 2079-9292

AB  - Forests are an enduring component of the natural world and perform a vital role in protecting the environment. Forests are valuable resources to control global warming and provide oxygen for the survival of human life, including wood for households. Forest fires have recently emerged as a major threat to biological processes and the ecosystem. Unfortunately, almost every year, fire damages millions of hectares of forest land due to late and inefficient detection of fire. However, it is important to identify the forest fire at the initial level before it spreads to vast areas and destroys natural resources. In this paper, a formal model of the Internet of Things (IoT) and drone-based forest fire detection and counteraction system is presented. The proposed system comprises network maintenance. Sensor deployment is on trees, the ground, and animals in the form of subnets to transmit sensed data to the control room. All subnets are connected to the control room through gateway nodes. Alarms are being used to alert human beings and animals to save their lives, which will help to initially protect them from fire. The embedded sensors collect the information and transfer it to the gateways. Drones are being used for real-time visualization of fire-affected areas and to perform actions to control fires because they play a vital role in disasters. Graph theory is used to construct an efficient model and to show the connectivity of the network. To identify failures and develop recovery procedures, the algorithm is designed through the graph-based model. The model is developed by the Vienna Development Method-Specification Language (VDM-SL), and the correctness of the model is ensured using various VDM-SL toolbox facilities.
KW  - forest fire detection
KW  - Internet of Things (IoT)
KW  - drones
KW  - failure recovery
KW  - formal specification
KW  - correctness
DO  - 10.3390/electronics11010128
ER  -
TY  - EJOU
AU  - Rodríguez-Puerta, Francisco
AU  - Gómez-García, Esteban
AU  - Martín-García, Saray
AU  - Pérez-Rodríguez, Fernando
AU  - Prada, Eva
TI  - UAV-Based LiDAR Scanning for Individual Tree Detection and Height Measurement in Young Forest Permanent Trials
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - The installation of research or permanent plots is a very common task in growth and forest yield research. At young ages, tree height is the most commonly measured variable, so the location of individuals is necessary when repeated measures are taken and if spatial analysis is required. Identifying the coordinates of individual trees and re-measuring the height of all trees is difficult and particularly costly (in time and money). The data used comes from three Pinus pinaster Ait. and three Pinus radiata D. Don plantations of 0.8 ha, with an age ranging between 2 and 5 years and mean heights between 1 and 5 m. Five individual tree detection (ITD) methods are evaluated, based on the Canopy Height Model (CHM), where the height of each tree is identified, and its crown is segmented. Three CHM resolutions are used for each method. All algorithms used for individual tree detection (ITD) tend to underestimate the number of trees. The best results are obtained with the R package, ForestTools and rLiDAR. The best CHM resolution for identifying trees was always 10 cm. We did not detect any differences in the relative error (RE) between Pinus pinaster and Pinus radiata. We found a pattern in the ITD depending on the height of the trees to be detected: the accuracy is lower when detecting trees less than 1 m high than when detecting larger trees (RE close to 12% versus 1% for taller trees). Regarding the estimation of tree height, we can conclude that the use of the CHM to estimate height tends to underestimate its value, while the use of the point cloud presents practically unbiased results. The stakeout of forestry research plots and the re-measurement of individual tree heights is an operation that can be performed by UAV-based LiDAR scanning sensors. The individual geolocation of each tree and the measurement of heights versus pole and/or hypsometer measurement is highly accurate and cost-effective, especially when tree height reaches 1&ndash;1.5 m.
KW  - UAV-based LiDAR
KW  - individual-tree detection
KW  - ForestTools
KW  - lidR
KW  - permanent plots
DO  - 10.3390/rs14010170
ER  -
TY  - EJOU
AU  - Wang, Ying
AU  - Koo, Ki-Young
TI  - Vegetation Removal on 3D Point Cloud Reconstruction of Cut-Slopes Using U-Net
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 1
SN  - 2076-3417

AB  - The 3D point cloud reconstruction from photos taken by an unmanned aerial vehicle (UAV) is a promising tool for monitoring and managing risks of cut-slopes. However, surface changes on cut-slopes are likely to be hidden by seasonal vegetation variations on the cut-slopes. This paper proposes a vegetation removal method for 3D reconstructed point clouds using (1) a 2D image segmentation deep learning model and (2) projection matrices available from photogrammetry. For a given point cloud, each 3D point of it is reprojected into the image coordinates by the projection matrices to determine if it belongs to vegetation or not using the 2D image segmentation model. The 3D points belonging to vegetation in the 2D images are deleted from the point cloud. The effort to build a 2D image segmentation model was significantly reduced by using U-Net with the dataset prepared by the colour index method complemented by manual trimming. The proposed method was applied to a cut-slope in Doam Dam in South Korea, and showed that vegetation from the two point clouds of the cut-slope at winter and summer was removed successfully. The M3C2 distance between the two vegetation-removed point clouds showed a feasibility of the proposed method as a tool to reveal actual change of cut-slopes without the effect of vegetation.
KW  - cut-slope assessment
KW  - image segmentation
KW  - colour index
KW  - U-Net
KW  - vegetation removal
DO  - 10.3390/app12010395
ER  -
TY  - EJOU
AU  - Piratelo, Paulo H.
AU  - de Azeredo, Rodrigo N.
AU  - Yamao, Eduardo M.
AU  - Bianchi Filho, Jose F.
AU  - Maidl, Gabriel
AU  - Lisboa, Felipe S.
AU  - de Jesus, Laercio P.
AU  - Penteado Neto, Renato D.
AU  - Coelho, Leandro D.
AU  - Leandro, Gideon V.
TI  - Blending Colored and Depth CNN Pipelines in an Ensemble Learning Classification Approach for Warehouse Application Using Synthetic and Real Data
T2  - Machines

PY  - 2022
VL  - 10
IS  - 1
SN  - 2075-1702

AB  - Electric companies face flow control and inventory obstacles such as reliability, outlays, and time-consuming tasks. Convolutional Neural Networks (CNNs) combined with computational vision approaches can process image classification in warehouse management applications to tackle this problem. This study uses synthetic and real images applied to CNNs to deal with classification of inventory items. The results are compared to seek the neural networks that better suit this application. The methodology consists of fine-tuning several CNNs on Red&ndash;Green&ndash;Blue (RBG) and Red&ndash;Green&ndash;Blue-Depth (RGB-D) synthetic and real datasets, using the best architecture of each domain in a blended ensemble approach. The proposed blended ensemble approach was not yet explored in such an application, using RGB and RGB-D data, from synthetic and real domains. The use of a synthetic dataset improved accuracy, precision, recall and f1-score in comparison with models trained only on the real domain. Moreover, the use of a blend of DenseNet and Resnet pipelines for colored and depth images proved to outperform accuracy, precision and f1-score performance indicators over single CNNs, achieving an accuracy measurement of 95.23%. The classification task is a real logistics engineering problem handled by computer vision and artificial intelligence, making full use of RGB and RGB-D images of synthetic and real domains, applied in an approach of blended CNN pipelines.
KW  - convolutional neural networks
KW  - warehouse management
KW  - image classification
KW  - ensemble learning
KW  - synthetic data
KW  - depth image
KW  - electrical maintenance
DO  - 10.3390/machines10010028
ER  -
TY  - EJOU
AU  - Li, Dengshan
AU  - Wang, Rujing
AU  - Chen, Peng
AU  - Xie, Chengjun
AU  - Zhou, Qiong
AU  - Jia, Xiufang
TI  - Visual Feature Learning on Video Object and Human Action Detection: A Systematic Review
T2  - Micromachines

PY  - 2022
VL  - 13
IS  - 1
SN  - 2072-666X

AB  - Video object and human action detection are applied in many fields, such as video surveillance, face recognition, etc. Video object detection includes object classification and object location within the frame. Human action recognition is the detection of human actions. Usually, video detection is more challenging than image detection, since video frames are often more blurry than images. Moreover, video detection often has other difficulties, such as video defocus, motion blur, part occlusion, etc. Nowadays, the video detection technology is able to implement real-time detection, or high-accurate detection of blurry video frames. In this paper, various video object and human action detection approaches are reviewed and discussed, many of them have performed state-of-the-art results. We mainly review and discuss the classic video detection methods with supervised learning. In addition, the frequently-used video object detection and human action recognition datasets are reviewed. Finally, a summarization of the video detection is represented, e.g., the video object and human action detection methods could be classified into frame-by-frame (frame-based) detection, extracting-key-frame detection and using-temporal-information detection; the methods of utilizing temporal information of adjacent video frames are mainly the optical flow method, Long Short-Term Memory and convolution among adjacent frames.
KW  - video object detection
KW  - human action recognition
KW  - deep learning
KW  - temporal information
KW  - optical flow
KW  - LSTM
KW  - video dataset
DO  - 10.3390/mi13010072
ER  -
TY  - EJOU
AU  - Carbonell-Rivera, Juan P.
AU  - Torralba, Jesús
AU  - Estornell, Javier
AU  - Ruiz, Luis Á.
AU  - Crespo-Peremarch, Pablo
TI  - Classification of Mediterranean Shrub Species from UAV Point Clouds
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Modelling fire behaviour in forest fires is based on meteorological, topographical, and vegetation data, including species&rsquo; type. To accurately parameterise these models, an inventory of the area of analysis with the maximum spatial and temporal resolution is required. This study investigated the use of UAV-based digital aerial photogrammetry (UAV-DAP) point clouds to classify tree and shrub species in Mediterranean forests, and this information is key for the correct generation of wildfire models. In July 2020, two test sites located in the Natural Park of Sierra Calderona (eastern Spain) were analysed, registering 1036 vegetation individuals as reference data, corresponding to 11 shrub and one tree species. Meanwhile, photogrammetric flights were carried out over the test sites, using a UAV DJI Inspire 2 equipped with a Micasense RedEdge multispectral camera. Geometrical, spectral, and neighbour-based features were obtained from the resulting point cloud generated. Using these features, points belonging to tree and shrub species were classified using several machine learning methods, i.e., Decision Trees, Extra Trees, Gradient Boosting, Random Forest, and MultiLayer Perceptron. The best results were obtained using Gradient Boosting, with a mean cross-validation accuracy of 81.7% and 91.5% for test sites 1 and 2, respectively. Once the best classifier was selected, classified points were clustered based on their geometry and tested with evaluation data, and overall accuracies of 81.9% and 96.4% were obtained for test sites 1 and 2, respectively. Results showed that the use of UAV-DAP allows the classification of Mediterranean tree and shrub species. This technique opens a wide range of possibilities, including the identification of species as a first step for further extraction of structure and fuel variables as input for wildfire behaviour models.
KW  - Unmanned Aerial Vehicles (UAV)
KW  - Digital Aerial Photogrammetry (DAP)
KW  - machine learning
KW  - deep learning
KW  - point cloud labelling
KW  - Mediterranean forest
DO  - 10.3390/rs14010199
ER  -
TY  - EJOU
AU  - Lin, Qigen
AU  - Ci, Tianyu
AU  - Wang, Leibin
AU  - Mondal, Sanjit K.
AU  - Yin, Huaxiang
AU  - Wang, Ying
TI  - Transfer Learning for Improving Seismic Building Damage Assessment
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - The rapid assessment of building damage in earthquake-stricken areas is of paramount importance for emergency response. The development of remote sensing technology has aided in deriving reliable and precise building damage assessments of extensive areas following disasters. It is well documented that convolutional neural network methods have superior performance in earthquake building damage assessment compared with traditional machine learning methods. However, deep learning models require a large number of samples, and sufficient numbers of samples are usually not available in the newly earthquake-stricken areas rapidly enough. At the same time, the historical samples inevitably differ from the new earthquake-affected areas due to the discrepancy of regional building characteristics. For this purpose, this study proposes a data transfer algorithm for evaluating the impact of a single historical training sample on the model performance. Then, beneficial samples are selected to transfer knowledge from the historical data for facilitating the calibration of the new model. Four models are designed with two earthquake damage building datasets and the performance of the models is compared and evaluated. The results show that the data transfer algorithm proposed in this work improves the reliability of the building damage assessment model significantly by filtering samples from the historical data that are suitable for the new task. The performance of the model built based on the data transfer method on the test set of new earthquakes task is approximately 8% higher in overall accuracy compared with the model trained directly with the new earthquake samples when the training data for the new task is only 10% of the historical data and is operating under the objective of four classes of building damage. The proposed data transfer algorithm has effectively enhanced the precision of the seismic building damage assessment in a data-limited context. Thus, it could be applicable to the building damage assessment of new disasters.
KW  - building damage
KW  - transfer learning
KW  - earthquake
KW  - deep learning
KW  - convolutional neural networks
DO  - 10.3390/rs14010201
ER  -
TY  - EJOU
AU  - Kamarulzaman, Aisyah M.
AU  - Wan Mohd Jaafar, Wan S.
AU  - Abdul Maulud, Khairul N.
AU  - Saad, Siti N.
AU  - Omar, Hamdan
AU  - Mohan, Midhun
TI  - Integrated Segmentation Approach with Machine Learning Classifier in Detecting and Mapping Post Selective Logging Impacts Using UAV Imagery
T2  - Forests

PY  - 2022
VL  - 13
IS  - 1
SN  - 1999-4907

AB  - Selective logging can cause significant impacts on the residual stands, affecting biodiversity and leading to environmental changes. Proper monitoring and mapping of the impacts from logging activities, such as the stumps, felled logs, roads, skid trails, and forest canopy gaps, are crucial for sustainable forest management operations. The purpose of this study is to assess the indicators of selective logging impacts by detecting the individual stumps as the main indicators, evaluating the performance of classification methods to assess the impacts and identifying forest gaps from selective logging activities. The combination of forest inventory field plots and unmanned aerial vehicle (UAV) RGB and overlapped imaged were used in this study to assess these impacts. The study area is located in Ulu Jelai Forest Reserve in the central part of Peninsular Malaysia, covering an experimental study area of 48 ha. The study involved the integration of template matching (TM), object-based image analysis (OBIA), and machine learning classification&mdash;support vector machine (SVM) and artificial neural network (ANN). Forest features and tree stumps were classified, and the canopy height model was used for detecting forest canopy gaps in the post selective logging region. Stump detection using the integration of TM and OBIA produced an accuracy of 75.8% when compared with the ground data. Forest classification using SVM and ANN methods were adopted to extract other impacts from logging activities such as skid trails, felled logs, roads and forest canopy gaps. These methods provided an overall accuracy of 85% and kappa coefficient value of 0.74 when compared with conventional classifier. The logging operation also caused an 18.6% loss of canopy cover. The result derived from this study highlights the potential use of UAVs for efficient post logging impact analysis and can be used to complement conventional forest inventory practices.
KW  - selective logging impacts
KW  - UAV
KW  - object-based image analysis
KW  - machine learning
KW  - forest classification
DO  - 10.3390/f13010048
ER  -
TY  - EJOU
AU  - Mobini, Majid
AU  - Kaddoum, Georges
AU  - Herceg, Marijan
TI  - Design of a SIMO Deep Learning-Based Chaos Shift Keying (DLCSK) Communication System
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - This paper brings forward a Deep Learning (DL)-based Chaos Shift Keying (DLCSK) demodulation scheme to promote the capabilities of existing chaos-based wireless communication systems. In coherent Chaos Shift Keying (CSK) schemes, we need synchronization of chaotic sequences, which is still practically impossible in a disturbing environment. Moreover, the conventional Differential Chaos Shift Keying (DCSK) scheme has a drawback, that for each bit, half of the bit duration is spent sending non-information bearing reference samples. To deal with this drawback, a Long Short-Term Memory (LSTM)-based receiver is trained offline, using chaotic maps through a finite number of channel realizations, and then used for classifying online modulated signals. We presented that the proposed receiver can learn different chaotic maps and estimate channels implicitly, and then retrieves the transmitted messages without any need for chaos synchronization or reference signal transmissions. Simulation results for both the AWGN and Rayleigh fading channels show a remarkable BER performance improvement compared to the conventional DCSK scheme. The proposed DLCSK system will provide opportunities for a new class of receivers by leveraging the advantages of DL, such as effective serial and parallel connectivity. A Single Input Multiple Output (SIMO) architecture of the DLCSK receiver with excellent reliability is introduced to show its capabilities. The SIMO DLCSK benefits from a DL-based channel estimation approach, which makes this architecture simpler and more efficient for applications where channel estimation is problematic, such as massive MIMO, mmWave, and cloud-based communication systems.
KW  - chaos shift keying
KW  - deep learning
KW  - LSTM
KW  - multi-antenna
DO  - 10.3390/s22010333
ER  -
TY  - EJOU
AU  - Sun, Xudong
AU  - Xia, Min
AU  - Dai, Tianfang
TI  - Controllable Fused Semantic Segmentation with Adaptive Edge Loss for Remote Sensing Parsing
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - High-resolution remote sensing images have been put into the application in remote sensing parsing. General remote sensing parsing methods based on semantic segmentation still have limitations, which include frequent neglect of tiny objects, high complexity in image understanding and sample imbalance. Therefore, a controllable fusion module (CFM) is proposed to alleviate the problem of implicit understanding of complicated categories. Moreover, an adaptive edge loss function (AEL) was proposed to alleviate the problem of the recognition of tiny objects and sample imbalance. Our proposed method combining CFM and AEL optimizes edge features and body features in a coupled mode. The verification on Potsdam and Vaihingen datasets shows that our method can significantly improve the parsing effect of satellite images in terms of mIoU and MPA.
KW  - remote sensing parsing
KW  - satellite imagery
KW  - semantic segmentation
DO  - 10.3390/rs14010207
ER  -
TY  - EJOU
AU  - Sharma, Mayuri
AU  - Nath, Keshab
AU  - Sharma, Rupam K.
AU  - Kumar, Chandan J.
AU  - Chaudhary, Ankit
TI  - Ensemble Averaging of Transfer Learning Models for Identification of Nutritional Deficiency in Rice Plant
T2  - Electronics

PY  - 2022
VL  - 11
IS  - 1
SN  - 2079-9292

AB  - Computer vision-based automation has become popular in detecting and monitoring plants&rsquo; nutrient deficiencies in recent times. The predictive model developed by various researchers were so designed that it can be used in an embedded system, keeping in mind the availability of computational resources. Nevertheless, the enormous popularity of smart phone technology has opened the door of opportunity to common farmers to have access to high computing resources. To facilitate smart phone users, this study proposes a framework of hosting high end systems in the cloud where processing can be done, and farmers can interact with the cloud-based system. With the availability of high computational power, many studies have been focused on applying convolutional Neural Networks-based Deep Learning (CNN-based DL) architectures, including Transfer learning (TL) models on agricultural research. Ensembling of various TL architectures has the potential to improve the performance of predictive models by a great extent. In this work, six TL architectures viz. InceptionV3, ResNet152V2, Xception, DenseNet201, InceptionResNetV2, and VGG19 are considered, and their various ensemble models are used to carry out the task of deficiency diagnosis in rice plants. Two publicly available datasets from Mendeley and Kaggle are used in this study. The ensemble-based architecture enhanced the highest classification accuracy to 100% from 99.17% in the Mendeley dataset, while for the Kaggle dataset; it was enhanced to 92% from 90%.
KW  - ML/DL methods
KW  - nutrient deficiency
KW  - ensemble learning
KW  - transfer learning
KW  - rice deficiency identification
DO  - 10.3390/electronics11010148
ER  -
TY  - EJOU
AU  - Amaral, Julyanne B.
AU  - Lopes, Fernando B.
AU  - Magalhães, Ana C.
AU  - Kujawa, Sebastian
AU  - Taniguchi, Carlos A.
AU  - Teixeira, Adunias D.
AU  - Lacerda, Claudivan F.
AU  - Queiroz, Thales R.
AU  - Andrade, Eunice M.
AU  - Araújo, Isabel C.
AU  - Niedbała, Gniewko
TI  - Quantifying Nutrient Content in the Leaves of Cowpea Using Remote Sensing
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 1
SN  - 2076-3417

AB  - Although hyperspectral remote sensing techniques have increasingly been used in the nutritional quantification of plants, it is important to understand whether the method shows a satisfactory response during the various phenological stages of the crop. The aim of this study was to quantify the levels of phosphorus (P), potassium (K), calcium (Ca) and zinc (Zn) in the leaves of Vigna Unguiculata (L.) Walp using spectral data obtained by a spectroradiometer. A randomised block design was used, with three treatments and twenty-five replications. The crop was evaluated at three growth stages: V4, R6 and R9. Single-band models were fitted using simple correlations. For the band ratio models, the wavelengths were selected by 2D correlation. For the models using partial least squares regression (PLSR), the stepwise method was used. The model showing the best fit was used to estimate the phosphorus content in the single-band (R&sup2; = 0.62; RMSE = 0.54 and RPD = 1.61), band ratio (R&sup2; = 0.66; RMSE = 0.65 and RPD = 1.52) and PLSR models, using data from each of the phenological stages (R&sup2; = 0.80; RMSE = 0.47 and RPD = 1.66). Accuracy in modelling leaf nutrients depends on the phenological stage, as well as the amount of data used, and is more accurate with a larger number of samples.
KW  - Vigna unguiculata
KW  - hyperspectral data
KW  - evaluating nutritional status
DO  - 10.3390/app12010458
ER  -
TY  - EJOU
AU  - Szrek, Jarosław
AU  - Jakubiak, Janusz
AU  - Zimroz, Radoslaw
TI  - A Mobile Robot-Based System for Automatic Inspection of Belt Conveyors in Mining Industry
T2  - Energies

PY  - 2022
VL  - 15
IS  - 1
SN  - 1996-1073

AB  - Mechanical systems (as belt conveyors) used in the mining industry, especially in deep underground mines, must be supervised on a regular basis. Unfortunately, they require high power and are spatially distributed over a large area. Till now, some elements of the conveyor (drive units) have been monitored 24 h/day using SCADA systems. The rest of the conveyor is inspected by maintenance staff. To minimize the presence of humans in harsh environments, we propose a mobile inspection platform based on autonomous UGV. It is equipped with various sensors, and in practice it is capable of collecting almost the same information as maintenance inspectors (RGB image, sound, gas sensor, etc.). Till now such experiments have been performed in the lab or in the mine, but the robot was controlled by the operator. In such a scenario the robot is able to record data, process them and detect, for example, an overheated idler. In this paper we will introduce the general concept of an automatic robot-based inspection for underground mining applications. A framework of how to deploy the inspection robot for automatic inspection (3D model of the tunnel, path planing, etc.) are defined and some first results from automatic inspection tested in lab conditions are presented. Differences between the planned and actual path are evaluated. We also point out some challenges for further research.
KW  - mining
KW  - belt conveyor
KW  - predictive maintenance
KW  - automatic inspection
KW  - UGV platform
KW  - autonomous mobile robot
DO  - 10.3390/en15010327
ER  -
TY  - EJOU
AU  - Chen, Tzung-Shi
AU  - Chen, Jen-Jee
AU  - Gao, Xiang-You
AU  - Chen, Tzung-Cheng
TI  - Mobile Charging Strategy for Wireless Rechargeable Sensor Networks
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - In a wireless sensor network, the sensing and data transmission for sensors will cause energy depletion, which will lead to the inability to complete the tasks. To solve this problem, wireless rechargeable sensor networks (WRSNs) have been developed to extend the lifetime of the entire network. In WRSNs, a mobile charging robot (MR) is responsible for wireless charging each sensor battery and collecting sensory data from the sensor simultaneously. Thereby, MR needs to traverse along a designed path for all sensors in the WRSNs. In this paper, dual-side charging strategies are proposed for MR traversal planning, which minimize the MR traversal path length, energy consumption, and completion time. Based on MR dual-side charging, neighboring sensors in both sides of a designated path can be wirelessly charged by MR and sensory data sent to MR simultaneously. The constructed path is based on the power diagram according to the remaining power of sensors and distances among sensors in a WRSN. While the power diagram is built, charging strategies with dual-side charging capability are determined accordingly. In addition, a clustering-based approach is proposed to improve minimizing MR moving total distance, saving charging energy and total completion time in a round. Moreover, integrated strategies that apply a clustering-based approach on the dual-side charging strategies are presented in WRSNs. The simulation results show that, no matter with or without clustering, the performances of proposed strategies outperform the baseline strategies in three respects, energy saving, total distance reduced, and completion time reduced for MR in WSRNs.
KW  - energy efficiency
KW  - mobile charging robot
KW  - traveling salesman problem
KW  - Voronoi diagram
KW  - wireless rechargeable sensor networks
DO  - 10.3390/s22010359
ER  -
TY  - EJOU
AU  - Ma, Haoyi
AU  - Acton, Scott T.
AU  - Lin, Zongli
TI  - CAT: Centerness-Aware Anchor-Free Tracker
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Accurate and robust scale estimation in visual object tracking is a challenging task. To obtain a scale estimation of the target object, most methods rely either on a multi-scale searching scheme or on refining a set of predefined anchor boxes. These methods require heuristically selected parameters, such as scale factors of the multi-scale searching scheme, or sizes and aspect ratios of the predefined candidate anchor boxes. On the contrary, a centerness-aware anchor-free tracker (CAT) is designed in this work. First, the location and scale of the target object are predicted in an anchor-free fashion by decomposing tracking into parallel classification and regression problems. The proposed anchor-free design obviates the need for hyperparameters related to the anchor boxes, making CAT more generic and flexible. Second, the proposed centerness-aware classification branch can identify the foreground from the background while predicting the normalized distance from the location within the foreground to the target center, i.e., the centerness. The proposed centerness-aware classification branch improves the tracking accuracy and robustness significantly by suppressing low-quality state estimates. The experiments show that our centerness-aware anchor-free tracker, with its appealing features, achieves salient performance in a wide variety of tracking scenarios.
KW  - visual object tracking
KW  - anchor-free
KW  - centerness
KW  - convolutional neural network
DO  - 10.3390/s22010354
ER  -
TY  - EJOU
AU  - Sun, Zhu
AU  - Guo, Xiangyu
AU  - Xu, Yang
AU  - Zhang, Songchao
AU  - Cheng, Xiaohui
AU  - Hu, Qiong
AU  - Wang, Wenxiang
AU  - Xue, Xinyu
TI  - Image Recognition of Male Oilseed Rape (Brassica napus) Plants Based on Convolutional Neural Network for UAAS Navigation Applications on Supplementary Pollination and Aerial Spraying
T2  - Agriculture

PY  - 2022
VL  - 12
IS  - 1
SN  - 2077-0472

AB  - To ensure the hybrid oilseed rape (OSR, Brassica napus) seed production, two important things are necessary, the stamen sterility on the female OSR plants and the effective pollen spread onto the pistil from the OSR male plants to the OSR female plants. The unmanned agricultural aerial system (UAAS) has developed rapidly in China. It has been used on supplementary pollination and aerial spraying during the hybrid OSR seed production. This study developed a new method to rapidly recognize the male OSR plants and extract the row center line for supporting the UAAS navigation. A male OSR plant recognition model was constructed based on the convolutional neural network (CNN). The sequence images of male OSR plants were extracted, the feature regions and points were obtained from the images through morphological and boundary process methods and horizontal segmentation, respectively. The male OSR plant image recognition accuracies of different CNN structures and segmentation sizes were discussed. The male OSR plant row center lines were fitted using the least-squares method (LSM) and Hough transform. The results showed that the segmentation algorithm could segment the male OSR plants from the complex background. The highest average recognition accuracy was 93.54%, and the minimum loss function value was 0.2059 with three convolutional layers, one fully connected layer, and a segmentation size of 40 pix &times; 40 pix. The LSM is better for center line fitting. The average recognition model accuracies of original input images were 98% and 94%, and the average root mean square errors (RMSE) of angle were 3.22&deg; and 1.36&deg; under cloudy day and sunny day lighting conditions, respectively. The results demonstrate the potential of using digital imaging technology to recognize the male OSR plant row for UAAS visual navigation on the applications of hybrid OSR supplementary pollination and aerial spraying, which would be a meaningful supplement in precision agriculture.
KW  - hybrid oilseed rape
KW  - male parent recognition
KW  - convolutional neural network
KW  - image processing
KW  - UAAS visual navigation
KW  - seed production
KW  - aerial spraying
DO  - 10.3390/agriculture12010062
ER  -
TY  - EJOU
AU  - Rehman, Amjad
AU  - Saba, Tanzila
AU  - Kashif, Muhammad
AU  - Fati, Suliman M.
AU  - Bahaj, Saeed A.
AU  - Chaudhry, Huma
TI  - A Revisit of Internet of Things Technologies for Monitoring and Control Strategies in Smart Agriculture
T2  - Agronomy

PY  - 2022
VL  - 12
IS  - 1
SN  - 2073-4395

AB  - With the rise of new technologies, such as the Internet of Things, raising the productivity of agricultural and farming activities is critical to improving yields and cost-effectiveness. IoT, in particular, can improve the efficiency of agriculture and farming processes by eliminating human intervention through automation. The fast rise of Internet of Things (IoT)-based tools has changed nearly all life sectors, including business, agriculture, surveillance, etc. These radical developments are upending traditional agricultural practices and presenting new options in the face of various obstacles. IoT aids in collecting data that is useful in the farming sector, such as changes in climatic conditions, soil fertility, amount of water required for crops, irrigation, insect and pest detection, bug location disruption of creatures to the sphere, and horticulture. IoT enables farmers to effectively use technology to monitor their forms remotely round the clock. Several sensors, including distributed WSNs (wireless sensor networks), are utilized for agricultural inspection and control, which is very important due to their exact output and utilization. In addition, cameras are utilized to keep an eye on the field from afar. The goal of this research is to evaluate smart agriculture using IoT approaches in depth. The paper demonstrates IoT applications, benefits, current obstacles, and potential solutions in smart agriculture. This smart agricultural system aims to find existing techniques that may be used to boost crop yield and save time, such as water, pesticides, irrigation, crop, and fertilizer management.
KW  - agriculture
KW  - land monitoring
KW  - control strategies
KW  - IoT
KW  - sensors
KW  - economic growth
KW  - water management and water resources
DO  - 10.3390/agronomy12010127
ER  -
TY  - EJOU
AU  - Khan, Asim
AU  - Asim, Warda
AU  - Ulhaq, Anwaar
AU  - Robinson, Randall W.
TI  - A Multiview Semantic Vegetation Index for Robust Estimation of Urban Vegetation Cover
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Urban vegetation growth is vital for developing sustainable and liveable cities in the contemporary era since it directly helps people&rsquo;s health and well-being. Estimating vegetation cover and biomass is commonly done by calculating various vegetation indices for automated urban vegetation management and monitoring. However, most of these indices fail to capture robust estimation of vegetation cover due to their inherent focus on colour attributes with limited viewpoint and ignore seasonal changes. To solve this limitation, this article proposed a novel vegetation index called the Multiview Semantic Vegetation Index (MSVI), which is robust to color, viewpoint, and seasonal variations. Moreover, it can be applied directly to RGB images. This Multiview Semantic Vegetation Index (MSVI) is based on deep semantic segmentation and multiview field coverage and can be integrated into any vegetation management platform. This index has been tested on Google Street View (GSV) imagery of Wyndham City Council, Melbourne, Australia. The experiments and training achieved an overall pixel accuracy of 89.4% and 92.4% for FCN and U-Net, respectively. Thus, the MSVI can be a helpful instrument for analysing urban forestry and vegetation biomass since it provides an accurate and reliable objective method for assessing the plant cover at street level.
KW  - multiview semantic vegetation index
KW  - urban forestry
KW  - green view index (GVI)
KW  - semantic segmentation
KW  - urban vegetation
KW  - RGB vegetation index
DO  - 10.3390/rs14010228
ER  -
TY  - EJOU
AU  - Li, Yan
AU  - Zhao, Mengyu
AU  - Zhang, Huazhi
AU  - Qu, Yuanyuan
AU  - Wang, Suyu
TI  - A Multi-Agent Motion Prediction and Tracking Method Based on Non-Cooperative Equilibrium
T2  - Mathematics

PY  - 2022
VL  - 10
IS  - 1
SN  - 2227-7390

AB  - A Multi-Agent Motion Prediction and Tracking method based on non-cooperative equilibrium (MPT-NCE) is proposed according to the fact that some multi-agent intelligent evolution methods, like the MADDPG, lack adaptability facing unfamiliar environments, and are unable to achieve multi-agent motion prediction and tracking, although they own advantages in multi-agent intelligence. Featured by a performance discrimination module using the time difference function together with a random mutation module applying predictive learning, the MPT-NCE is capable of improving the prediction and tracking ability of the agents in the intelligent game confrontation. Two groups of multi-agent prediction and tracking experiments are conducted and the results show that compared with the MADDPG method, in the aspect of prediction ability, the MPT-NCE achieves a prediction rate at more than 90%, which is 23.52% higher and increases the whole evolution efficiency by 16.89%; in the aspect of tracking ability, the MPT-NCE promotes the convergent speed by 11.76% while facilitating the target tracking by 25.85%. The proposed MPT-NCE method shows impressive environmental adaptability and prediction and tracking ability.
KW  - non-cooperative equilibrium
KW  - random mutation module
KW  - performance discrimination module
KW  - multi-agent prediction and tracking
DO  - 10.3390/math10010164
ER  -
TY  - EJOU
AU  - Chen, Weijie
AU  - Jia, Zhenhong
AU  - Yang, Jie
AU  - Kasabov, Nikola K.
TI  - Multispectral Image Enhancement Based on the Dark Channel Prior and Bilateral Fractional Differential Model
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Compared with single-band remote sensing images, multispectral images can obtain information on the same target in different bands. By combining the characteristics of each band, we can obtain clearer enhanced images; therefore, we propose a multispectral image enhancement method based on the improved dark channel prior (IDCP) and bilateral fractional differential (BFD) model to make full use of the multiband information. First, the original multispectral image is inverted to meet the prior conditions of dark channel theory. Second, according to the characteristics of multiple bands, the dark channel algorithm is improved. The RGB channels are extended to multiple channels, and the spatial domain fractional differential mask is used to optimize the transmittance estimation to make it more consistent with the dark channel hypothesis. Then, we propose a bilateral fractional differentiation algorithm that enhances the edge details of an image through the fractional differential in the spatial domain and intensity domain. Finally, we implement the inversion operation to obtain the final enhanced image. We apply the proposed IDCP_BFD method to a multispectral dataset and conduct sufficient experiments. The experimental results show the superiority of the proposed method over relative comparison methods.
KW  - multispectral image enhancement
KW  - remote sensing
KW  - dark channel prior
KW  - fractional differential
DO  - 10.3390/rs14010233
ER  -
TY  - EJOU
AU  - Chang, Ching-Wei
AU  - Lo, Li-Yu
AU  - Cheung, Hiu C.
AU  - Feng, Yurong
AU  - Yang, An-Shik
AU  - Wen, Chih-Yung
AU  - Zhou, Weifeng
TI  - Proactive Guidance for Accurate UAV Landing on a Dynamic Platform: A Visual&ndash;Inertial Approach
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - This work aimed to develop an autonomous system for unmanned aerial vehicles (UAVs) to land on moving platforms such as an automobile or a marine vessel, providing a promising solution for a long-endurance flight operation, a large mission coverage range, and a convenient recharging ground station. Unlike most state-of-the-art UAV landing frameworks that rely on UAV onboard computers and sensors, the proposed system fully depends on the computation unit situated on the ground vehicle/marine vessel to serve as a landing guidance system. Such a novel configuration can therefore lighten the burden of the UAV, and the computation power of the ground vehicle/marine vessel can be enhanced. In particular, we exploit a sensor fusion-based algorithm for the guidance system to perform UAV localization, whilst a control method based upon trajectory optimization is integrated. Indoor and outdoor experiments are conducted, and the results show that precise autonomous landing on a 43 cm &times; 43 cm platform can be performed.
KW  - UAV
KW  - VTOL
KW  - object tracking
KW  - deep learning
KW  - sensor fusion
KW  - kalman filter
KW  - autonomous landing
KW  - optimal trajectory
DO  - 10.3390/s22010404
ER  -
TY  - EJOU
AU  - Guo, Yahui
AU  - Chen, Shouzhi
AU  - Fu, Yongshuo H.
AU  - Xiao, Yi
AU  - Wu, Wenxiang
AU  - Wang, Hanxi
AU  - Beurs, Kirsten D.
TI  - Comparison of Multi-Methods for Identifying Maize Phenology Using PhenoCams
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Accurately identifying the phenology of summer maize is crucial for both cultivar breeding and fertilizer controlling in precision agriculture. In this study, daily RGB images covering the entire growth of summer maize were collected using phenocams at sites in Shangqiu (2018, 2019 and 2020) and Nanpi (2020) in China. Four phenological dates, including six leaves, booting, heading and maturity of summer maize, were pre-defined and extracted from the phenocam-based images. The spectral indices, textural indices and integrated spectral and textural indices were calculated using the improved adaptive feature-weighting method. The double logistic function, harmonic analysis of time series, Savitzky&ndash;Golay and spline interpolation were applied to filter these indices and pre-defined phenology was identified and compared with the ground observations. The results show that the DLF achieved the highest accuracy, with the coefficient of determination (R2) and the root-mean-square error (RMSE) being 0.86 and 9.32 days, respectively. The new index performed better than the single usage of spectral and textural indices, of which the R2 and RMSE were 0.92 and 9.38 days, respectively. The phenological extraction using the new index and double logistic function based on the PhenoCam data was effective and convenient, obtaining high accuracy. Therefore, it is recommended the adoption of the new index by integrating the spectral and textural indices for extracting maize phenology using PhenoCam data.
KW  - spectral and textural indices
KW  - maize phenological extraction
KW  - filtering methods
DO  - 10.3390/rs14020244
ER  -
TY  - EJOU
AU  - Liu, Yicheng
AU  - Li, Zhipeng
AU  - Zhan, Bixiong
AU  - Han, Ju
AU  - Liu, Yan
TI  - A Super-Resolution Reconstruction Driven Helmet Detection Workflow
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 2
SN  - 2076-3417

AB  - The degrading of input images due to the engineering environment decreases the performance of helmet detection models so as to prevent their application in practice. To overcome this problem, we propose an end-to-end helmet monitoring system, which implements a super-resolution (SR) reconstruction driven helmet detection workflow to detect helmets for monitoring tasks. The monitoring system consists of two modules, the super-resolution reconstruction module and the detection module. The former implements the SR algorithm to produce high-resolution images, the latter performs the helmet detection. Validations are performed on both a public dataset as well as the realistic dataset obtained from a practical construction site. The results show that the proposed system achieves a promising performance and surpasses the competing methods. It will be a promising tool for construction monitoring and is easy to be extended to corresponding tasks.
KW  - helmet detection
KW  - super-resolution reconstruction
KW  - you only look once v5 (YOLOv5)
DO  - 10.3390/app12020545
ER  -
TY  - EJOU
AU  - Huang, Linsheng
AU  - Liu, Yong
AU  - Huang, Wenjiang
AU  - Dong, Yingying
AU  - Ma, Huiqin
AU  - Wu, Kang
AU  - Guo, Anting
TI  - Combining Random Forest and XGBoost Methods in Detecting Early and Mid-Term Winter Wheat Stripe Rust Using Canopy Level Hyperspectral Measurements
T2  - Agriculture

PY  - 2022
VL  - 12
IS  - 1
SN  - 2077-0472

AB  - Appropriate modeling methods and feature selection algorithms must be selected to improve the accuracy of early and mid-term remote sensing detection of wheat stripe rust. In the current study, we explored the effectiveness of the random forest (RF) algorithm combined with the extreme gradient boosting (XGboost) method for early and mid-term wheat stripe rust detection based on the vegetation indices extracted from canopy level hyperspectral measurements. Initially, 21 vegetation indices that were related to the early and mid-term winter wheat stripe rust were calculated on the basis of canopy level hyperspectral reflectance. Subsequently, the optimal vegetation index combination for disease detection was determined using correlation analysis (CA) combined with RF algorithms. Then, the disease severity detection model of early and mid-term winter wheat stripe rust was constructed using XGBoost method based on the optimal vegetation index combination. For the evaluation and comparison of the initial results, three commonly used classification methods, namely, RF, backpropagation neural network (BPNN), and support vector machine (SVM), were utilized. The vegetation index combinations determined by the single CA algorithm were also used to construct detection models. Compared with the detection models based on the vegetation index combination obtained using the single CA algorithm, the overall accuracy of the four detection models based on the optimal vegetation index combination based on CA combined with RF algorithms increased by 16.1% (XGBoost), 9.7% (RF), 8.1% (SVM), and 8.1% (BPNN). Among the eight models, the XGBoost detection model based on the optimal vegetation index combination using CA combined with RF algorithms, CA-RF-XGBoost, achieved the highest overall accuracy of 87.1% and the highest kappa coefficient of 0.798. Our results indicate that the RF combined with XGBoost can improve the detection accuracy of early and mid-term winter wheat stripe rust effectively at canopy scale.
KW  - wheat stripe rust
KW  - hyperspectral
KW  - early and mid-term
KW  - vegetation index
KW  - random forest
KW  - extreme gradient boosting
DO  - 10.3390/agriculture12010074
ER  -
TY  - EJOU
AU  - Gao, Xin
AU  - Ram, Sundaresh
AU  - Philip, Rohit C.
AU  - Rodríguez, Jeffrey J.
AU  - Szep, Jeno
AU  - Shao, Sicong
AU  - Satam, Pratik
AU  - Pacheco, Jesús
AU  - Hariri, Salim
TI  - Selecting Post-Processing Schemes for Accurate Detection of Small Objects in Low-Resolution Wide-Area Aerial Imagery
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - In low-resolution wide-area aerial imagery, object detection algorithms are categorized as feature extraction and machine learning approaches, where the former often requires a post-processing scheme to reduce false detections and the latter demands multi-stage learning followed by post-processing. In this paper, we present an approach on how to select post-processing schemes for aerial object detection. We evaluated combinations of each of ten vehicle detection algorithms with any of seven post-processing schemes, where the best three schemes for each algorithm were determined using average F-score metric. The performance improvement is quantified using basic information retrieval metrics as well as the classification of events, activities and relationships (CLEAR) metrics. We also implemented a two-stage learning algorithm using a hundred-layer densely connected convolutional neural network for small object detection and evaluated its degree of improvement when combined with the various post-processing schemes. The highest average F-scores after post-processing are 0.902, 0.704 and 0.891 for the Tucson, Phoenix and online VEDAI datasets, respectively. The combined results prove that our enhanced three-stage post-processing scheme achieves a mean average precision (mAP) of 63.9% for feature extraction methods and 82.8% for the machine learning approach.
KW  - post-processing
KW  - vehicle detection
KW  - wide-area aerial imagery
KW  - segmentation
KW  - machine learning
DO  - 10.3390/rs14020255
ER  -
TY  - EJOU
AU  - Al-Sa’d, Mohammad
AU  - Kiranyaz, Serkan
AU  - Ahmad, Iftikhar
AU  - Sundell, Christian
AU  - Vakkuri, Matti
AU  - Gabbouj, Moncef
TI  - A Social Distance Estimation and Crowd Monitoring System for Surveillance Cameras
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - Social distancing is crucial to restrain the spread of diseases such as COVID-19, but complete adherence to safety guidelines is not guaranteed. Monitoring social distancing through mass surveillance is paramount to develop appropriate mitigation plans and exit strategies. Nevertheless, it is a labor-intensive task that is prone to human error and tainted with plausible breaches of privacy. This paper presents a privacy-preserving adaptive social distance estimation and crowd monitoring solution for camera surveillance systems. We develop a novel person localization strategy through pose estimation, build a privacy-preserving adaptive smoothing and tracking model to mitigate occlusions and noisy/missing measurements, compute inter-personal distances in the real-world coordinates, detect social distance infractions, and identify overcrowded regions in a scene. Performance evaluation is carried out by testing the system&rsquo;s ability in person detection, localization, density estimation, anomaly recognition, and high-risk areas identification. We compare the proposed system to the latest techniques and examine the performance gain delivered by the localization and smoothing/tracking algorithms. Experimental results indicate a considerable improvement, across different metrics, when utilizing the developed system. In addition, they show its potential and functionality for applications other than social distancing.
KW  - COVID-19
KW  - social distancing
KW  - video surveillance
KW  - person detection and tracking
KW  - pose estimation
KW  - crowd monitoring
DO  - 10.3390/s22020418
ER  -
TY  - EJOU
AU  - Tomita, Ko
AU  - Chew, Michael Y.
TI  - A Review of Infrared Thermography for Delamination Detection on Infrastructures and Buildings
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - This paper provides a comprehensive review on the use of infrared thermography to detect delamination on infrastructures and buildings. Approximately 200 pieces of relevant literature were evaluated, and their findings were summarized. The factors affecting the accuracy and detectability of infrared thermography were consolidated and discussed. Necessary measures to effectively capture latent defects at the early stage of delamination before crack formation were investigated. The results of this study could be used as the benchmarks for setting standardized testing criteria as well as for comparison of results for future works on the use of infrared thermography for detection of delamination on infrastructures and buildings.
KW  - infrared thermography
KW  - delamination
KW  - building
KW  - infrastructure
KW  - time window
KW  - environment
KW  - infrared camera
KW  - target object
KW  - thermal property
DO  - 10.3390/s22020423
ER  -
TY  - EJOU
AU  - Wang, Yanjun
AU  - Li, Shaochun
AU  - Teng, Fei
AU  - Lin, Yunhao
AU  - Wang, Mengjie
AU  - Cai, Hengfan
TI  - Improved Mask R-CNN for Rural Building Roof Type Recognition from UAV High-Resolution Images: A Case Study in Hunan Province, China
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Accurate roof information of buildings can be obtained from UAV high-resolution images. The large-scale accurate recognition of roof types (such as gabled, flat, hipped, complex and mono-pitched roofs) of rural buildings is crucial for rural planning and construction. At present, most UAV high-resolution optical images only have red, green and blue (RGB) band information, which aggravates the problems of inter-class similarity and intra-class variability of image features. Furthermore, the different roof types of rural buildings are complex, spatially scattered, and easily covered by vegetation, which in turn leads to the low accuracy of roof type identification by existing methods. In response to the above problems, this paper proposes a method for identifying roof types of complex rural buildings based on visible high-resolution remote sensing images from UAVs. First, the fusion of deep learning networks with different visual features is investigated to analyze the effect of the different feature combinations of the visible difference vegetation index (VDVI) and Sobel edge detection features and UAV visible images on model recognition of rural building roof types. Secondly, an improved Mask R-CNN model is proposed to learn more complex features of different types of images of building roofs by using the ResNet152 feature extraction network with migration learning. After we obtained roof type recognition results in two test areas, we evaluated the accuracy of the results using the confusion matrix and obtained the following conclusions: (1) the model with RGB images incorporating Sobel edge detection features has the highest accuracy and enables the model to recognize more and more accurately the roof types of different morphological rural buildings, and the model recognition accuracy (Kappa coefficient (KC)) compared to that of RGB images is on average improved by 0.115; (2) compared with the original Mask R-CNN, U-Net, DeeplabV3 and PSPNet deep learning models, the improved Mask R-CNN model has the highest accuracy in recognizing the roof types of rural buildings, with F1-score, KC and OA averaging 0.777, 0.821 and 0.905, respectively. The method can obtain clear and accurate profiles and types of rural building roofs, and can be extended for green roof suitability evaluation, rooftop solar potential assessment, and other building roof surveys, management and planning.
KW  - UAV high-resolution optical image
KW  - roof type recognition
KW  - VDVI
KW  - Sobel
KW  - improved Mask R-CNN
KW  - deep learning
DO  - 10.3390/rs14020265
ER  -
TY  - EJOU
AU  - Kim, Yumi
AU  - Paik, Mincheol
AU  - Kim, Bokyeong
AU  - Ko, Haneul
AU  - Kim, Seung-Yeon
TI  - Neighbor-Aware Non-Orthogonal Multiple Access Scheme for Energy Harvesting Internet of Things
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - In a non-orthogonal multiple access (NOMA) environment, an Internet of Things (IoT) device achieves a high data rate by increasing its transmission power. However, excessively high transmission power can cause an energy outage of an IoT device and have a detrimental effect on the signal-to-interference-plus-noise ratio of neighbor IoT devices. In this paper, we propose a neighbor-aware NOMA scheme (NA-NOMA) where each IoT device determines whether to transmit data to the base station and the transmission power at each time epoch in a distributed manner with the consideration of its energy level and other devices&rsquo; transmission powers. To maximize the aggregated data rate of IoT devices while keeping an acceptable average energy outage probability, a constrained stochastic game model is formulated, and the solution of the model is obtained using a best response dynamics-based algorithm. Evaluation results show that NA-NOMA can increase the average data rate up to 22% compared with a probability-based scheme while providing a sufficiently low energy outage probability (e.g., 0.05).
KW  - game theory
KW  - constrained stochastic game
KW  - energy
KW  - energy harvesting
KW  - Internet of Things (IoT)
DO  - 10.3390/s22020448
ER  -
TY  - EJOU
AU  - Wang, Yong
AU  - Zeng, Xiangqiang
AU  - Liao, Xiaohan
AU  - Zhuang, Dafang
TI  - B-FGC-Net: A Building Extraction Network from High Resolution Remote Sensing Imagery
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Deep learning (DL) shows remarkable performance in extracting buildings from high resolution remote sensing images. However, how to improve the performance of DL based methods, especially the perception of spatial information, is worth further study. For this purpose, we proposed a building extraction network with feature highlighting, global awareness, and cross level information fusion (B-FGC-Net). The residual learning and spatial attention unit are introduced in the encoder of the B-FGC-Net, which simplifies the training of deep convolutional neural networks and highlights the spatial information representation of features. The global feature information awareness module is added to capture multiscale contextual information and integrate the global semantic information. The cross level feature recalibration module is used to bridge the semantic gap between low and high level features to complete the effective fusion of cross level information. The performance of the proposed method was tested on two public building datasets and compared with classical methods, such as UNet, LinkNet, and SegNet. Experimental results demonstrate that B-FGC-Net exhibits improved profitability of accurate extraction and information integration for both small and large scale buildings. The IoU scores of B-FGC-Net on WHU and INRIA Building datasets are 90.04% and 79.31%, respectively. B-FGC-Net is an effective and recommended method for extracting buildings from high resolution remote sensing images.
KW  - deep learning
KW  - building extraction
KW  - spatial attention
KW  - global information awareness
KW  - cross level information fusion
DO  - 10.3390/rs14020269
ER  -
TY  - EJOU
AU  - Li, Mengyao
AU  - Zhang, Rui
AU  - Luo, Hongxia
AU  - Gu, Songwei
AU  - Qin, Zili
TI  - Crop Mapping in the Sanjiang Plain Using an Improved Object-Oriented Method Based on Google Earth Engine and Combined Growth Period Attributes
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - In recent years, the scale of rural land transfer has gradually expanded, and the phenomenon of non-grain-oriented cultivated land has emerged. Obtaining crop planting information is of the utmost importance to guaranteeing national food security; however, the acquisition of the spatial distribution of crops in large-scale areas often has the disadvantages of excessive calculation and low accuracy. Therefore, the IO-Growth method, which takes the growth stage every 10 days as the index and combines the spectral features of crops to refine the effective interval of conventional wavebands for object-oriented classification, was proposed. The results were as follows: (1) the IO-Growth method obtained classification results with an overall accuracy and F1 score of 0.92, and both values increased by 6.98% compared to the method applied without growth stages; (2) the IO-Growth method reduced 288 features to only 5 features, namely Sentinel-2: Red Edge1, normalized difference vegetation index, Red, short-wave infrared2, and Aerosols, on the 261st to 270th days, which greatly improved the utilization rate of the wavebands; (3) the rise of geographic data processing platforms makes it simple to complete computations with massive data in a short time. The results showed that the IO-Growth method is suitable for large-scale vegetation mapping.
KW  - crop mapping
KW  - temporal composite
KW  - object-oriented
KW  - remote sensing
KW  - Google Earth Engine
DO  - 10.3390/rs14020273
ER  -
TY  - EJOU
AU  - Anuar, Mohamed M.
AU  - Halin, Alfian A.
AU  - Perumal, Thinagaran
AU  - Kalantar, Bahareh
TI  - Aerial Imagery Paddy Seedlings Inspection Using Deep Learning
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - In recent years complex food security issues caused by climatic changes, limitations in human labour, and increasing production costs require a strategic approach in addressing problems. The emergence of artificial intelligence due to the capability of recent advances in computing architectures could become a new alternative to existing solutions. Deep learning algorithms in computer vision for image classification and object detection can facilitate the agriculture industry, especially in paddy cultivation, to alleviate human efforts in laborious, burdensome, and repetitive tasks. Optimal planting density is a crucial factor for paddy cultivation as it will influence the quality and quantity of production. There have been several studies involving planting density using computer vision and remote sensing approaches. While most of the studies have shown promising results, they have disadvantages and show room for improvement. One of the disadvantages is that the studies aim to detect and count all the paddy seedlings to determine planting density. The defective paddy seedlings&rsquo; locations are not pointed out to help farmers during the sowing process. In this work we aimed to explore several deep convolutional neural networks (DCNN) models to determine which one performs the best for defective paddy seedling detection using aerial imagery. Thus, we evaluated the accuracy, robustness, and inference latency of one- and two-stage pretrained object detectors combined with state-of-the-art feature extractors such as EfficientNet, ResNet50, and MobilenetV2 as a backbone. We also investigated the effect of transfer learning with fine-tuning on the performance of the aforementioned pretrained models. Experimental results showed that our proposed methods were capable of detecting the defective paddy rice seedlings with the highest precision and an F1-Score of 0.83 and 0.77, respectively, using a one-stage pretrained object detector called EfficientDet-D1 EficientNet.
KW  - paddy seedlings
KW  - computer vision
KW  - object detection
KW  - deep learning
KW  - convolutional neural networks
DO  - 10.3390/rs14020274
ER  -
TY  - EJOU
AU  - Abreha, Haftay G.
AU  - Hayajneh, Mohammad
AU  - Serhani, Mohamed A.
TI  - Federated Learning in Edge Computing: A Systematic Survey
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - Edge Computing (EC) is a new architecture that extends Cloud Computing (CC) services closer to data sources. EC combined with Deep Learning (DL) is a promising technology and is widely used in several applications. However, in conventional DL architectures with EC enabled, data producers must frequently send and share data with third parties, edge or cloud servers, to train their models. This architecture is often impractical due to the high bandwidth requirements, legalization, and privacy vulnerabilities. The Federated Learning (FL) concept has recently emerged as a promising solution for mitigating the problems of unwanted bandwidth loss, data privacy, and legalization. FL can co-train models across distributed clients, such as mobile phones, automobiles, hospitals, and more, through a centralized server, while maintaining data localization. FL can therefore be viewed as a stimulating factor in the EC paradigm as it enables collaborative learning and model optimization. Although the existing surveys have taken into account applications of FL in EC environments, there has not been any systematic survey discussing FL implementation and challenges in the EC paradigm. This paper aims to provide a systematic survey of the literature on the implementation of FL in EC environments with a taxonomy to identify advanced solutions and other open problems. In this survey, we review the fundamentals of EC and FL, then we review the existing related works in FL in EC. Furthermore, we describe the protocols, architecture, framework, and hardware requirements for FL implementation in the EC environment. Moreover, we discuss the applications, challenges, and related existing solutions in the edge FL. Finally, we detail two relevant case studies of applying FL in EC, and we identify open issues and potential directions for future research. We believe this survey will help researchers better understand the connection between FL and EC enabling technologies and concepts.
KW  - federated learning
KW  - edge computing
KW  - intelligent edge
KW  - edge AI
KW  - data privacy
KW  - data security
DO  - 10.3390/s22020450
ER  -
TY  - EJOU
AU  - Yang, Qun
AU  - Shen, Dejian
TI  - Learning Damage Representations with Sequence-to-Sequence Models
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - Natural hazards have caused damages to structures and economic losses worldwide. Post-hazard responses require accurate and fast damage detection and assessment. In many studies, the development of data-driven damage detection within the research community of structural health monitoring has emerged due to the advances in deep learning models. Most data-driven models for damage detection focus on classifying different damage states and hence damage states cannot be effectively quantified. To address such a deficiency in data-driven damage detection, we propose a sequence-to-sequence (Seq2Seq) model to quantify a probability of damage. The model was trained to learn damage representations with only undamaged signals and then quantify the probability of damage by feeding damaged signals into models. We tested the validity of our proposed Seq2Seq model with a signal dataset which was collected from a two-story timber building subjected to shake table tests. Our results show that our Seq2Seq model has a strong capability of distinguishing damage representations and quantifying the probability of damage in terms of highlighting the regions of interest.
KW  - structural health monitoring
KW  - damage detection
KW  - deep learning
KW  - Seq2Seq model
DO  - 10.3390/s22020452
ER  -
TY  - EJOU
AU  - Nepal, Upesh
AU  - Eslamiat, Hossein
TI  - Comparing YOLOv3, YOLOv4 and YOLOv5 for Autonomous Landing Spot Detection in Faulty UAVs
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - In-flight system failure is one of the major safety concerns in the operation of unmanned aerial vehicles (UAVs) in urban environments. To address this concern, a safety framework consisting of following three main tasks can be utilized: (1) Monitoring health of the UAV and detecting failures, (2) Finding potential safe landing spots in case a critical failure is detected in step 1, and (3) Steering the UAV to a safe landing spot found in step 2. In this paper, we specifically look at the second task, where we investigate the feasibility of utilizing object detection methods to spot safe landing spots in case the UAV suffers an in-flight failure. Particularly, we investigate different versions of the YOLO objection detection method and compare their performances for the specific application of detecting a safe landing location for a UAV that has suffered an in-flight failure. We compare the performance of YOLOv3, YOLOv4, and YOLOv5l while training them by a large aerial image dataset called DOTA in a Personal Computer (PC) and also a Companion Computer (CC). We plan to use the chosen algorithm on a CC that can be attached to a UAV, and the PC is used to verify the trends that we see between the algorithms on the CC. We confirm the feasibility of utilizing these algorithms for effective emergency landing spot detection and report their accuracy and speed for that specific application. Our investigation also shows that the YOLOv5l algorithm outperforms YOLOv4 and YOLOv3 in terms of accuracy of detection while maintaining a slightly slower inference speed.
KW  - object detection
KW  - DOTA aerial image dataset
KW  - deep learning
KW  - YOLOv3
KW  - YOLOv4
KW  - YOLOv5
KW  - unmanned aerial vehicle
KW  - UAV Safety
KW  - neural networks
DO  - 10.3390/s22020464
ER  -
TY  - EJOU
AU  - Zhang, Tao
AU  - Jiang, Xiaodong
AU  - Jiang, Linlin
AU  - Li, Xuran
AU  - Yang, Shenbin
AU  - Li, Yingxue
TI  - Hyperspectral Reflectance Characteristics of Rice Canopies under Changes in Diffuse Radiation Fraction
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - To analyze the hyperspectral reflectance characteristics of rice canopies under changes in diffuse radiation fraction, experiments using different cover materials were performed in Nanjing, China, during 2016 and 2017. Each year, two treatments with different reduction ratios of diffuse radiation fraction but with similar shading rates were set in the field experiment: In T1, total solar radiation shading rate was 14.10%, and diffuse radiation fraction was 31.09%; in T2, total solar radiation shading rate was 14.42%, and diffuse radiation fraction was 39.98%, respectively. A non-shading treatment was included as a control (CK). Canopy hyperspectral reflectance, soil and plant analyzer development (SPAD), and leaf area index (LAI) were measured under shading treatments on different days after heading. The red-edge parameters (position, &lambda;0; maximum amplitude, D&lambda;; area, &alpha;0; width, &sigma;) were calculated, as well as the area, depth, and width of three absorption bands. The location of the first absorption band appeared in the range of 553&ndash;788 nm, and the second and third absorption bands appeared in the range of 874&ndash;1257 nm. The results show that the shading treatment had a significant effect on the rice canopy&rsquo;s hyperspectral reflectance. Compared with CK, the canopy reflectance of T1 (the diffuse radiation fraction was 31.09%) and T2 (the diffuse radiation fraction was 39.98%) decreased in the visible light range (350&ndash;760 nm) and increased in the near-infrared range (800&ndash;1350 nm), while the red-edge parameters (&lambda;0, D&lambda;, &alpha;0), SPAD, and LAI increased. On the other hand, under shading treatment, the increase in diffuse radiation fraction also had a significant impact on the hyperspectral spectra of the rice canopy, especially at 14 days after heading. Compared with T1, the green peak (550 nm) of T2 reduced by 16.12%, and the average reflectance at 800&ndash;900 nm increased by 10%. Based on correlation analysis, it was found that these hyperspectral reflectance characteristics were mainly due to the increase in SPAD (2.31%) and LAI (7.62%), which also led to the increase in D&lambda; (8.70%) and &alpha;0 (13.89%). Then, the second and third absorption features of T2 were significantly different from that of T1, which suggests that the change in diffuse radiation fraction could affect the process of water vapor absorption by rice.
KW  - diffuse radiation fraction
KW  - rice
KW  - hyperspectral reflectance
DO  - 10.3390/rs14020285
ER  -
TY  - EJOU
AU  - Cira, Calimanut-Ionut
AU  - Kada, Martin
AU  - Manso-Callejo, Miguel-Ángel
AU  - Alcarria, Ramón
AU  - Bordel Sanchez, Borja
TI  - Improving Road Surface Area Extraction via Semantic Segmentation with Conditional Generative Learning for Deep Inpainting Operations
T2  - ISPRS International Journal of Geo-Information

PY  - 2022
VL  - 11
IS  - 1
SN  - 2220-9964

AB  - The road surface area extraction task is generally carried out via semantic segmentation over remotely-sensed imagery. However, this supervised learning task is often costly as it requires remote sensing images labelled at the pixel level, and the results are not always satisfactory (presence of discontinuities, overlooked connection points, or isolated road segments). On the other hand, unsupervised learning does not require labelled data and can be employed for post-processing the geometries of geospatial objects extracted via semantic segmentation. In this work, we implement a conditional Generative Adversarial Network to reconstruct road geometries via deep inpainting procedures on a new dataset containing unlabelled road samples from challenging areas present in official cartographic support from Spain. The goal is to improve the initial road representations obtained with semantic segmentation models via generative learning. The performance of the model was evaluated on unseen data by conducting a metrical comparison where a maximum Intersection over Union (IoU) score improvement of 1.3% was observed when compared to the initial semantic segmentation result. Next, we evaluated the appropriateness of applying unsupervised generative learning using a qualitative perceptual validation to identify the strengths and weaknesses of the proposed method in very complex scenarios and gain a better intuition of the model&rsquo;s behaviour when performing large-scale post-processing with generative learning and deep inpainting procedures and observed important improvements in the generated data.
KW  - conditional learning
KW  - generative adversarial network
KW  - generative learning
KW  - image inpainting
KW  - image post-processing
KW  - road extraction
KW  - unsupervised learning
DO  - 10.3390/ijgi11010043
ER  -
TY  - EJOU
AU  - Luo, Wei
AU  - Han, Wenlong
AU  - Fu, Ping
AU  - Wang, Huijuan
AU  - Zhao, Yunfeng
AU  - Liu, Ke
AU  - Liu, Yuyan
AU  - Zhao, Zihui
AU  - Zhu, Mengxu
AU  - Xu, Ruopeng
AU  - Wei, Guosheng
TI  - A Water Surface Contaminants Monitoring Method Based on Airborne Depth Reasoning
T2  - Processes

PY  - 2022
VL  - 10
IS  - 1
SN  - 2227-9717

AB  - Water surface plastic pollution turns out to be a global issue, having aroused rising attention worldwide. How to monitor water surface plastic waste in real time and accurately collect and analyze the relevant numerical data has become a hotspot in water environment research. (1) Background: Over the past few years, unmanned aerial vehicles (UAVs) have been progressively adopted to conduct studies on the monitoring of water surface plastic waste. On the whole, the monitored data are stored in the UAVS to be subsequently retrieved and analyzed, thereby probably causing the loss of real-time information and hindering the whole monitoring process from being fully automated. (2) Methods: An investigation was conducted on the relationship, function and relevant mechanism between various types of plastic waste in the water surface system. On that basis, this study built a deep learning-based lightweight water surface plastic waste detection model, which was capable of automatically detecting and locating different water surface plastic waste. Moreover, a UAV platform-based edge computing architecture was built. (3) Results: The delay of return task data and UAV energy consumption were effectively reduced, and computing and network resources were optimally allocated. (4) Conclusions: The UAV platform based on airborne depth reasoning is expected to be the mainstream means of water environment monitoring in the future.
KW  - deep learning
KW  - edge computing
KW  - machine learning
KW  - open source unmanned aerial vehicle
KW  - plastic waste detection
KW  - remote sensing
KW  - water environment protection
DO  - 10.3390/pr10010131
ER  -
TY  - EJOU
AU  - Jamali, Ali
AU  - Mahdianpari, Masoud
TI  - Swin Transformer for Complex Coastal Wetland Classification Using the Integration of Sentinel-1 and Sentinel-2 Imagery
T2  - Water

PY  - 2022
VL  - 14
IS  - 2
SN  - 2073-4441

AB  - The emergence of deep learning techniques has revolutionized the use of machine learning algorithms to classify complicated environments, notably in remote sensing. Convolutional Neural Networks (CNNs) have shown considerable promise in classifying challenging high-dimensional remote sensing data, particularly in the classification of wetlands. State-of-the-art Natural Language Processing (NLP) algorithms, on the other hand, are transformers. Despite the fact that transformers have been utilized for a few remote sensing applications, they have not been compared to other well-known CNN networks in complex wetland classification. As such, for the classification of complex coastal wetlands in the study area of Saint John city, located in New Brunswick, Canada, we modified and employed the Swin Transformer algorithm. Moreover, the developed transformer classifier results were compared with two well-known deep CNNs of AlexNet and VGG-16. In terms of average accuracy, the proposed Swin Transformer algorithm outperformed the AlexNet and VGG-16 techniques by 14.3% and 44.28%, respectively. The proposed Swin Transformer classifier obtained F-1 scores of 0.65, 0.71, 0.73, 0.78, 0.82, 0.84, and 0.84 for the recognition of coastal marsh, shrub, bog, fen, aquatic bed, forested wetland, and freshwater marsh, respectively. The results achieved in this study suggest the high capability of transformers over very deep CNN networks for the classification of complex landscapes in remote sensing.
KW  - wetland classification
KW  - swin transformer
KW  - VGG-16
KW  - AlexNet
KW  - CNN
KW  - deep convolutional neural network
KW  - New Brunswick
DO  - 10.3390/w14020178
ER  -
TY  - EJOU
AU  - Zhang, Bowen
AU  - Song, Zaixin
AU  - Zhao, Fei
AU  - Liu, Chunhua
TI  - Overview of Propulsion Systems for Unmanned Aerial Vehicles
T2  - Energies

PY  - 2022
VL  - 15
IS  - 2
SN  - 1996-1073

AB  - Unmanned Aerial Vehicle (UAV) propulsion technology is significantly related to the flight performance of UAVs, which has become one of the most important development directions of aviation. It should be noted that UAVs have three types of propulsion systems, namely the fuel, hybrid fuel-electric, and pure electric, respectively. This paper presents and discusses the classification, working principles, characteristics, and critical technologies of these three types of propulsion systems. It is helpful to establish the development framework of the UAV propulsion system and provide the essential information on electric propulsion UAVs. Additionally, future technologies and development, including the high-power density motors, converters, power supplies, are discussed for the electric propulsion UAVs. In the near future, the electric propulsion system would be widely used in UAVs. The high-power density system would become the development trend of electric UAVs. Thus, this review article provides comprehensive views and multiple comparisons of propulsion systems for UAVs.
KW  - Unmanned Aerial Vehicle (UAV)
KW  - electric aircraft
KW  - propulsion system
KW  - engines
KW  - power supply
KW  - electrified transportation
KW  - electric motor
DO  - 10.3390/en15020455
ER  -
TY  - EJOU
AU  - Samadzadegan, Farhad
AU  - Dadrass Javan, Farzaneh
AU  - Ashtari Mahini, Farnaz
AU  - Gholamshahi, Mehrnaz
TI  - Detection and Recognition of Drones Based on a Deep Convolutional Neural Network Using Visible Imagery
T2  - Aerospace

PY  - 2022
VL  - 9
IS  - 1
SN  - 2226-4310

AB  - Drones are becoming increasingly popular not only for recreational purposes but also in a variety of applications in engineering, disaster management, logistics, securing airports, and others. In addition to their useful applications, an alarming concern regarding physical infrastructure security, safety, and surveillance at airports has arisen due to the potential of their use in malicious activities. In recent years, there have been many reports of the unauthorized use of various types of drones at airports and the disruption of airline operations. To address this problem, this study proposes a novel deep learning-based method for the efficient detection and recognition of two types of drones and birds. Evaluation of the proposed approach with the prepared image dataset demonstrates better efficiency compared to existing detection systems in the literature. Furthermore, drones are often confused with birds because of their physical and behavioral similarity. The proposed method is not only able to detect the presence or absence of drones in an area but also to recognize and distinguish between two types of drones, as well as distinguish them from birds. The dataset used in this work to train the network consists of 10,000 visible images containing two types of drones as multirotors, helicopters, and also birds. The proposed deep learning method can directly detect and recognize two types of drones and distinguish them from birds with an accuracy of 83%, mAP of 84%, and IoU of 81%. The values of average recall, average accuracy, and average F1-score were also reported as 84%, 83%, and 83%, respectively, in three classes.
KW  - drone
KW  - UAV
KW  - deep learning
KW  - convolutional neural network CNN
KW  - drone image dataset
KW  - drone detection
KW  - drone recognition
DO  - 10.3390/aerospace9010031
ER  -
TY  - EJOU
AU  - Li, Chunchao
AU  - Tang, Xuebin
AU  - Shi, Lulu
AU  - Peng, Yuanxi
AU  - Tang, Yuhua
TI  - A Two-Staged Feature Extraction Method Based on Total Variation for Hyperspectral Images
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Effective feature extraction (FE) has always been the focus of hyperspectral images (HSIs). For aerial remote-sensing HSIs processing and its land cover classification, in this article, an efficient two-staged hyperspectral FE method based on total variation (TV) is proposed. In the first stage, the average fusion method was used to reduce the spectral dimension. Then, the anisotropic TV model with different regularization parameters was utilized to obtain featured blocks of different smoothness, each containing multi-scale structure information, and we stacked them as the next stage&rsquo;s input. In the second stage, equipped with singular value transformation to reduce the dimension again, we followed an isotropic TV model based on split Bregman algorithm for further detail smoothing. Finally, the feature-extracted block was fed to the support vector machine for classification experiments. The results, with three hyperspectral datasets, demonstrate that our proposed method can competitively outperform state-of-the-art methods in terms of its classification accuracy and computing time. Also, our proposed method delivers robustness and stability by comprehensive parameter analysis.
KW  - feature extraction
KW  - hyperspectral image
KW  - total variation
KW  - smoothing
DO  - 10.3390/rs14020302
ER  -
TY  - EJOU
AU  - Aldao, Enrique
AU  - González-deSantos, Luis M.
AU  - Michinel, Humberto
AU  - González-Jorge, Higinio
TI  - UAV Obstacle Avoidance Algorithm to Navigate in Dynamic Building Environments
T2  - Drones

PY  - 2022
VL  - 6
IS  - 1
SN  - 2504-446X

AB  - In this work, a real-time collision avoidance algorithm was presented for autonomous navigation in the presence of fixed and moving obstacles in building environments. The current implementation is designed for autonomous navigation between waypoints of a predefined flight trajectory that would be performed by an UAV during tasks such as inspections or construction progress monitoring. It uses a simplified geometry generated from a point cloud of the scenario. In addition, it also employs information from 3D sensors to detect and position obstacles such as people or other UAVs, which are not registered in the original cloud. If an obstacle is detected, the algorithm estimates its motion and computes an evasion path considering the geometry of the environment. The method has been successfully tested in different scenarios, offering robust results in all avoidance maneuvers. Execution times were measured, demonstrating that the algorithm is computationally feasible to be implemented onboard an UAV.
KW  - UAVs in construction
KW  - obstacle avoidance
KW  - LiDAR
KW  - optimization
KW  - non-linear programming
DO  - 10.3390/drones6010016
ER  -
TY  - EJOU
AU  - Guerrero, Graciela
AU  - da Silva, Fernando J.
AU  - Fernández-Caballero, Antonio
AU  - Pereira, António
TI  - Augmented Humanity: A Systematic Mapping Review
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - Augmented humanity (AH) is a term that has been mentioned in several research papers. However, these papers differ in their definitions of AH. The number of publications dealing with the topic of AH is represented by a growing number of publications that increase over time, being high impact factor scientific contributions. However, this terminology is used without being formally defined. The aim of this paper is to carry out a systematic mapping review of the different existing definitions of AH and its possible application areas. Publications from 2009 to 2020 were searched in Scopus, IEEE and ACM databases, using search terms &ldquo;augmented human&rdquo;, &rdquo;human augmentation&rdquo; and &ldquo;human 2.0&rdquo;. Of the 16,914 initially obtained publications, a final number of 133 was finally selected. The mapping results show a growing focus on works based on AH, with computer vision being the index term with the highest number of published articles. Other index terms are wearable computing, augmented reality, human&ndash;robot interaction, smart devices and mixed reality. In the different domains where AH is present, there are works in computer science, engineering, robotics, automation and control systems and telecommunications. This review demonstrates that it is necessary to formalize the definition of AH and also the areas of work with greater openness to the use of such concept. This is why the following definition is proposed: &ldquo;Augmented humanity is a human&ndash;computer integration technology that proposes to improve capacity and productivity by changing or increasing the normal ranges of human function through the restoration or extension of human physical, intellectual and social capabilities&rdquo;.
KW  - systematic mapping review
KW  - augmented humanity
KW  - wearable computing
KW  - mixed reality
KW  - human–robot interaction
KW  - smart devices
DO  - 10.3390/s22020514
ER  -
TY  - EJOU
AU  - Yu, Kunyong
AU  - Hao, Zhenbang
AU  - Post, Christopher J.
AU  - Mikhailova, Elena A.
AU  - Lin, Lili
AU  - Zhao, Gejin
AU  - Tian, Shangfeng
AU  - Liu, Jian
TI  - Comparison of Classical Methods and Mask R-CNN for Automatic Tree Detection and Mapping Using UAV Imagery
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Detecting and mapping individual trees accurately and automatically from remote sensing images is of great significance for precision forest management. Many algorithms, including classical methods and deep learning techniques, have been developed and applied for tree crown detection from remote sensing images. However, few studies have evaluated the accuracy of different individual tree detection (ITD) algorithms and their data and processing requirements. This study explored the accuracy of ITD using local maxima (LM) algorithm, marker-controlled watershed segmentation (MCWS), and Mask Region-based Convolutional Neural Networks (Mask R-CNN) in a young plantation forest with different test images. Manually delineated tree crowns from UAV imagery were used for accuracy assessment of the three methods, followed by an evaluation of the data processing and application requirements for three methods to detect individual trees. Overall, Mask R-CNN can best use the information in multi-band input images for detecting individual trees. The results showed that the Mask R-CNN model with the multi-band combination produced higher accuracy than the model with a single-band image, and the RGB band combination achieved the highest accuracy for ITD (F1 score = 94.68%). Moreover, the Mask R-CNN models with multi-band images are capable of providing higher accuracies for ITD than the LM and MCWS algorithms. The LM algorithm and MCWS algorithm also achieved promising accuracies for ITD when the canopy height model (CHM) was used as the test image (F1 score = 87.86% for LM algorithm, F1 score = 85.92% for MCWS algorithm). The LM and MCWS algorithms are easy to use and lower computer computational requirements, but they are unable to identify tree species and are limited by algorithm parameters, which need to be adjusted for each classification. It is highlighted that the application of deep learning with its end-to-end-learning approach is very efficient and capable of deriving the information from multi-layer images, but an additional training set is needed for model training, robust computer resources are required, and a large number of accurate training samples are necessary. This study provides valuable information for forestry practitioners to select an optimal approach for detecting individual trees.
KW  - LM algorithm
KW  - Mask R-CNN
KW  - MCWS algorithm
KW  - plantation forest
KW  - UAV imagery
DO  - 10.3390/rs14020295
ER  -
TY  - EJOU
AU  - Tursunboev, Jamshid
AU  - Kang, Yong-Sung
AU  - Huh, Sung-Bum
AU  - Lim, Dong-Woo
AU  - Kang, Jae-Mo
AU  - Jung, Heechul
TI  - Hierarchical Federated Learning for Edge-Aided Unmanned Aerial Vehicle Networks
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 2
SN  - 2076-3417

AB  - Federated learning (FL) allows UAVs to collaboratively train a globally shared machine learning model while locally preserving their private data. Recently, the FL in edge-aided unmanned aerial vehicle (UAV) networks has drawn an upsurge of research interest due to a bursting increase in heterogeneous data acquired by UAVs and the need to build the global model with privacy; however, a critical issue is how to deal with the non-independent and identically distributed (non-i.i.d.) nature of heterogeneous data while ensuring the convergence of learning. To effectively address this challenging issue, this paper proposes a novel and high-performing FL scheme, namely, the hierarchical FL algorithm, for the edge-aided UAV network, which exploits the edge servers located in base stations as intermediate aggregators with employing commonly shared data. Experiment results demonstrate that the proposed hierarchical FL algorithm outperforms several baseline FL algorithms and exhibits better convergence behavior.
KW  - unmanned aerial vehicles
KW  - edge-aided networks
KW  - federated learning
KW  - hierarchical learning
DO  - 10.3390/app12020670
ER  -
TY  - EJOU
AU  - Li, Fei
AU  - Guo, Wentai
AU  - Deng, Xiaotong
AU  - Wang, Jiamei
AU  - Ge, Liangquan
AU  - Guan, Xiaotong
TI  - A Hybrid Shuffled Frog Leaping Algorithm and Its Performance Assessment in Multi-Dimensional Symmetric Function
T2  - Symmetry

PY  - 2022
VL  - 14
IS  - 1
SN  - 2073-8994

AB  - Ensemble learning of swarm intelligence evolutionary algorithm of artificial neural network (ANN) is one of the core research directions in the field of artificial intelligence (AI). As a representative member of swarm intelligence evolutionary algorithm, shuffled frog leaping algorithm (SFLA) has the advantages of simple structure, easy implementation, short operation time, and strong global optimization ability. However, SFLA is susceptible to fall into local optimas in the face of complex and multi-dimensional symmetric function optimization, which leads to the decline of convergence accuracy. This paper proposes an improved shuffled frog leaping algorithm of threshold oscillation based on simulated annealing (SA-TO-SFLA). In this algorithm, the threshold oscillation strategy and simulated annealing strategy are introduced into the SFLA, which makes the local search behavior more diversified and the ability to escape from the local optimas stronger. By using multi-dimensional symmetric function such as drop-wave function, Schaffer function N.2, Rastrigin function, and Griewank function, two groups (i: SFLA, SA-SFLA, TO-SFLA, and SA-TO-SFLA; ii: SFLA, ISFLA, MSFLA, DSFLA, and SA-TO-SFLA) of comparative experiments are designed to analyze the convergence accuracy and convergence time. The results show that the threshold oscillation strategy has strong robustness. Moreover, compared with SFLA, the convergence accuracy of SA-TO-SFLA algorithm is significantly improved, and the median of convergence time is greatly reduced as a whole. The convergence accuracy of SFLA algorithm on these four test functions are 90%, 100%, 78%, and 92.5%, respectively, and the median of convergence time is 63.67 s, 59.71 s, 12.93 s, and 8.74 s, respectively; The convergence accuracy of SA-TO-SFLA algorithm on these four test functions is 99%, 100%, 100%, and 97.5%, respectively, and the median of convergence time is 48.64 s, 32.07 s, 24.06 s, and 3.04 s, respectively.
KW  - artificial neural network (ANN)
KW  - swarm intelligence evolutionary algorithm
KW  - shuffled frog leaping algorithm (SFLA)
KW  - multi-dimensional symmetric function
DO  - 10.3390/sym14010131
ER  -
TY  - EJOU
AU  - Hoskere, Vedhus
AU  - Narazaki, Yasutaka
AU  - Spencer, Billie F.
TI  - Physics-Based Graphics Models in 3D Synthetic Environments as Autonomous Vision-Based Inspection Testbeds
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - Manual visual inspection of civil infrastructure is high-risk, subjective, and time-consuming. The success of deep learning and the proliferation of low-cost consumer robots has spurred rapid growth in research and application of autonomous inspections. The major components of autonomous inspection include data acquisition, data processing, and decision making, which are usually studied independently. However, for robust real-world applicability, these three aspects of the overall process need to be addressed concurrently with end-to-end testing, incorporating scenarios such as variations in structure type, color, damage level, camera distance, view angle, lighting, etc. Developing real-world datasets that span all these scenarios is nearly impossible. In this paper, we propose a framework to create a virtual visual inspection testbed using 3D synthetic environments that can enable end-to-end testing of autonomous inspection strategies. To populate the 3D synthetic environment with virtual damaged buildings, we propose the use of a non-linear finite element model to inform the realistic and automated visual rendering of different damage types, the damage state, and the material textures of what are termed herein physics-based graphics models (PBGMs). To demonstrate the benefits of the autonomous inspection testbed, three experiments are conducted with models of earthquake damaged reinforced concrete buildings. First, we implement the proposed framework to generate a new large-scale annotated benchmark dataset for post-earthquake inspections of buildings termed QuakeCity. Second, we demonstrate the improved performance of deep learning models trained using the QuakeCity dataset for inference on real data. Finally, a comparison of deep learning-based damage state estimation for different data acquisition strategies is carried out. The results demonstrate the use of PBGMs as an effective testbed for the development and validation of strategies for autonomous vision-based inspections of civil infrastructure.
KW  - inspection testbeds
KW  - deep learning
KW  - computer graphics
KW  - autonomous inspections
KW  - physics-based graphics models
KW  - damage detection
DO  - 10.3390/s22020532
ER  -
TY  - EJOU
AU  - Hardy, Andy
AU  - Oakes, Gregory
AU  - Hassan, Juma
AU  - Yussuf, Yussuf
TI  - Improved Use of Drone Imagery for Malaria Vector Control through Technology-Assisted Digitizing (TAD)
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Drones have the potential to revolutionize malaria vector control initiatives through rapid and accurate mapping of potential malarial mosquito larval habitats to help direct field Larval Source Management (LSM) efforts. However, there are no clear recommendations on how these habitats can be extracted from drone imagery in an operational context. This paper compares the results of two mapping approaches: supervised image classification using machine learning and Technology-Assisted Digitising (TAD) mapping that employs a new region growing tool suitable for non-experts. These approaches were applied concurrently to drone imagery acquired at seven sites in Zanzibar, United Republic of Tanzania. Whilst the two approaches were similar in processing time, the TAD approach significantly outperformed the supervised classification approach at all sites (t = 5.1, p &lt; 0.01). Overall accuracy scores (mean overall accuracy 62%) suggest that a supervised classification approach is unsuitable for mapping potential malarial mosquito larval habitats in Zanzibar, whereas the TAD approach offers a simple and accurate (mean overall accuracy 96%) means of mapping these complex features. We recommend that this approach be used alongside targeted ground-based surveying (i.e., in areas inappropriate for drone surveying) for generating precise and accurate spatial intelligence to support operational LSM programmes.
KW  - unmanned aerial vehicles
KW  - drones
KW  - malaria
KW  - infectious diseases
KW  - hydrology
KW  - digitizing
DO  - 10.3390/rs14020317
ER  -
TY  - EJOU
AU  - Wu, Yuzhan
AU  - Li, Chenlong
AU  - Yuan, Changshun
AU  - Li, Meng
AU  - Li, Hao
TI  - Predictive Control for Small Unmanned Ground Vehicles via a Multi-Dimensional Taylor Network
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 2
SN  - 2076-3417

AB  - Tracking control of Small Unmanned Ground Vehicles (SUGVs) is easily affected by the nonlinearity and time-varying characteristics. An improved predictive control scheme based on the multi-dimensional Taylor network (MTN) is proposed for tracking control of SUGVs. First, a MTN model is used as a predictive model to construct a SUGV model and back propagation (BP) is taken as its learning algorithm. Second, the predictive control law is designed and the traditional objective function is improved to obtain a predictive objective function with a differential term. The optimal control quantity is given in real time through iterative optimization. Meanwhile, the stability of the closed-loop system is proved by the Lyapunov stability theorem. Finally, a tracking control experiment on the SUGV model is used to verify the effectiveness of the proposed scheme. For comparison, traditional MTN and Radial Basis Function (RBF) predictive control schemes are introduced. Moreover, a noise disturbance is considered. Experimental results show that the proposed scheme is effective, which ensures that the vehicle can quickly and accurately track the desired yaw velocity signal with good real-time, robustness, and convergence performance, and is superior to other comparison schemes.
KW  - multi-dimensional Taylor network
KW  - predictive control
KW  - nonlinear system
KW  - SUGV
KW  - predictive model
DO  - 10.3390/app12020682
ER  -
TY  - EJOU
AU  - Zhong, Jiwei
AU  - Xiang, Ziru
AU  - Li, Cheng
TI  - Synchronized Assessment of Bridge Structural Damage and Moving Force via Truncated Load Shape Function
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 2
SN  - 2076-3417

AB  - Moving load and structural damage assessment has always been a crucial topic in bridge health monitoring, as it helps analyze the daily operating status of bridges and provides fundamental information for bridge safety evaluation. However, most studies and research consider these issues as two separate problems. In practice, unknown moving loads and damage usually coexist and influence the bridge vibration synergically. This paper proposes an innovative synchronized assessment method that determines structural damages and moving forces simultaneously. The method firstly improves the virtual distortion method, which shifts the structural damage into external virtual forces and hence transforms the damage assessment as well as the moving force identification to a multi-force reconstruction problem. Secondly, a truncated load shape function (TLSF) technique is developed to solve the forces in the time domain. As the technique smoothens the pulse function via a limited number of TLSF, the singularity and dimension of the system matrix in the force reconstruction is largely reduced. A continuous beam and a three-dimensional truss bridge are simulated as examples. Case studies show that the method can effectively identify various speeds and numbers of moving loads, as well as different levels of structural damages. The calculation efficiency and robustness to white noise are also impressive.
KW  - structural health monitoring
KW  - moving force identification
KW  - structural damage identification
KW  - load-shape function method
KW  - virtual distortion method
DO  - 10.3390/app12020691
ER  -
TY  - EJOU
AU  - Bakar, Abu
AU  - Li, Ke
AU  - Liu, Haobo
AU  - Xu, Ziqi
AU  - Alessandrini, Marco
AU  - Wen, Dongsheng
TI  - Multi-Objective Optimization of Low Reynolds Number Airfoil Using Convolutional Neural Network and Non-Dominated Sorting Genetic Algorithm
T2  - Aerospace

PY  - 2022
VL  - 9
IS  - 1
SN  - 2226-4310

AB  - The airfoil is the prime component of flying vehicles. For low-speed flights, low Reynolds number airfoils are used. The characteristic of low Reynolds number airfoils is a laminar separation bubble and an associated drag rise. This paper presents a framework for the design of a low Reynolds number airfoil. The contributions of the proposed research are twofold. First, a convolutional neural network (CNN) is designed for the aerodynamic coefficient prediction of low Reynolds number airfoils. Data generation is discussed in detail and XFOIL is selected to obtain aerodynamic coefficients. The performance of the CNN is evaluated using different learning rate schedulers and adaptive learning rate optimizers. The trained model can predict the aerodynamic coefficients with high accuracy. Second, the trained model is used with a non-dominated sorting genetic algorithm (NSGA-II) for multi-objective optimization of the low Reynolds number airfoil at a specific angle of attack. A similar optimization is performed using NSGA-II directly calling XFOIL, to obtain the aerodynamic coefficients. The Pareto fronts of both optimizations are compared, and it is concluded that the proposed CNN can replicate the actual Pareto in considerably less time.
KW  - low Reynolds number airfoil
KW  - convolutional neural network
KW  - non-dominated sorting genetic algorithm
KW  - multi-objective optimization
KW  - Pareto front
DO  - 10.3390/aerospace9010035
ER  -
TY  - EJOU
AU  - Yuan, Dongliang
AU  - Li, Qingdang
AU  - Yang, Xiaohui
AU  - Zhang, Mingyue
AU  - Sun, Zhen
TI  - Object-Aware Adaptive Convolution Kernel Attention Mechanism in Siamese Network for Visual Tracking
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 2
SN  - 2076-3417

AB  - As a classic framework for visual object tracking, the Siamese convolutional neural network has received widespread attention from the research community. This method uses a convolutional neural network to obtain the object features and to match them with the search area features to achieve object tracking. In this work, we observe that the contribution of each convolution kernel in the convolutional neural network for object tracking tasks is different. We propose an object-aware convolution kernel attention mechanism. Based on the characteristics of each object, the convolution kernel features are dynamically weighted to improve the expression ability of object features. The experiments performed using OTB and VOT benchmark datasets show that the performance of the tracking method fused with the convolution kernel attention mechanism is significantly better compared with the original method. Moreover, the attention mechanism can also be integrated with other tracking frameworks as an independent module to improve the performance.
KW  - visual object tracking
KW  - convolution kernel attention
KW  - Siamese convolutional neural network
KW  - convolutional neural network
DO  - 10.3390/app12020716
ER  -
TY  - EJOU
AU  - Sevastopoulos, Christos
AU  - Konstantopoulos, Stasinos
AU  - Balaji, Keshav
AU  - Zaki Zadeh, Mohammad
AU  - Makedon, Fillia
TI  - A Simulated Environment for Robot Vision Experiments
T2  - Technologies

PY  - 2022
VL  - 10
IS  - 1
SN  - 2227-7080

AB  - Training on simulation data has proven invaluable in applying machine learning in robotics. However, when looking at robot vision in particular, simulated images cannot be directly used no matter how realistic the image rendering is, as many physical parameters (temperature, humidity, wear-and-tear in time) vary and affect texture and lighting in ways that cannot be encoded in the simulation. In this article we propose a different approach for extracting value from simulated environments: although neither of the trained models can be used nor are any evaluation scores expected to be the same on simulated and physical data, the conclusions drawn from simulated experiments might be valid. If this is the case, then simulated environments can be used in early-stage experimentation with different network architectures and features. This will expedite the early development phase before moving to (harder to conduct) physical experiments in order to evaluate the most promising approaches. In order to test this idea we created two simulated environments for the Unity engine, acquired simulated visual datasets, and used them to reproduce experiments originally carried out in a physical environment. The comparison of the conclusions drawn in the physical and the simulated experiments is promising regarding the validity of our approach.
KW  - robot perception
KW  - machine learning
KW  - traversability estimation
DO  - 10.3390/technologies10010007
ER  -
TY  - EJOU
AU  - Letard, Mathilde
AU  - Collin, Antoine
AU  - Corpetti, Thomas
AU  - Lague, Dimitri
AU  - Pastol, Yves
AU  - Ekelund, Anders
TI  - Classification of Land-Water Continuum Habitats Using Exclusively Airborne Topobathymetric Lidar Green Waveforms and Infrared Intensity Point Clouds
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Coastal areas host highly valuable ecosystems that are increasingly exposed to the threats of global and local changes. Monitoring their evolution at a high temporal and spatial scale is therefore crucial and mostly possible through remote sensing. This article demonstrates the relevance of topobathymetric lidar data for coastal and estuarine habitat mapping by classifying bispectral data to produce 3D maps of 21 land and sea covers at very high resolution. Green lidar full waveforms are processed to retrieve tailored features corresponding to the signature of those habitats. These features, along with infrared intensities and elevations, are used as predictors for random forest classifications, and their respective contribution to the accuracy of the results is assessed. We find that green waveform features, infrared intensities, and elevations are complimentary and yield the best classification results when used in combination. With this configuration, a classification accuracy of 90.5% is achieved for the segmentation of our dual-wavelength lidar dataset. Eventually, we produce an original mapping of a coastal site under the form of a point cloud, paving the way for 3D classification and management of land and sea covers.
KW  - topobathymetric lidar
KW  - full-waveform lidar
KW  - classification
KW  - coastal habitats
KW  - habitat mapping
DO  - 10.3390/rs14020341
ER  -
TY  - EJOU
AU  - Zhang, Ruohao
AU  - Condomines, Jean-Philippe
AU  - Lochin, Emmanuel
TI  - A Multifractal Analysis and Machine Learning Based Intrusion Detection System with an Application in a UAS/RADAR System
T2  - Drones

PY  - 2022
VL  - 6
IS  - 1
SN  - 2504-446X

AB  - The rapid development of Internet of Things (IoT) technology, together with mobile network technology, has created a never-before-seen world of interconnection, evoking research on how to make it vaster, faster, and safer. To support the ongoing fight against the malicious misuse of networks, in this paper we propose a novel algorithm called AMDES (unmanned aerial system multifractal analysis intrusion detection system) for spoofing attack detection. This novel algorithm is based on both wavelet leader multifractal analysis (WLM) and machine learning (ML) principles. In earlier research on unmanned aerial systems (UAS), intrusion detection systems (IDS) based on multifractal (MF) spectral analysis have been used to provide accurate MF spectrum estimations of network traffic. Such an estimation is then used to detect and characterize flooding anomalies that can be observed in an unmanned aerial vehicle (UAV) network. However, the previous contributions have lacked the consideration of other types of network intrusions commonly observed in UAS networks, such as the man in the middle attack (MITM). In this work, this promising methodology has been accommodated to detect a spoofing attack within a UAS. This methodology highlights a robust approach in terms of false positive performance in detecting intrusions in a UAS location reporting system.
KW  - network intrusion detection system
KW  - wavelet leader multifractal analysis
KW  - spoofing
KW  - machine learning
KW  - long-short term memory
DO  - 10.3390/drones6010021
ER  -
TY  - EJOU
AU  - Frydrych, Mateusz
AU  - Kacprzak, Grzegorz
AU  - Nowak, Paweł
TI  - Hazard Reduction in Deep Excavations Execution
T2  - Sustainability

PY  - 2022
VL  - 14
IS  - 2
SN  - 2071-1050

AB  - In this article, the authors consider a completely new approach in design, which is related to the use of previously un-adapted technologies known to bridge engineering in geotechnical issues for prestressing of diaphragm wall during deep excavations execution. The bridge technology described here is the prestressing of concrete structures. Hazards related to deep excavations and methods of digging them, such as the ceiling method and top&amp;down method, are presented. Current problems in supporting deep excavation slopes are related to the use of extensive quantities of materials (such as steel struts, ground anchors, or concrete and reinforcement steel). The authors&rsquo; method helps to achieve a higher level of sustainability, which is important in a modern approach to geotechnical engineering. The non-linear arrangements of the cables according to the occurrence of the prestressing moments for a given phase are presented. Results related to numerical analysis&mdash;showing the correctness of the method and cost optimization results, showing possible savings are presented. The article is a part of the set. In the second (already published) article titled &ldquo;Modern Methods of Diaphragm Walls Design&rdquo;, the authors present the concept of the calculation methodology for diaphragm wall design.
KW  - hazards
KW  - sustainability
KW  - deep excavations
KW  - diaphragm wall
KW  - prestressing
DO  - 10.3390/su14020868
ER  -
TY  - EJOU
AU  - Abdi, Omid
AU  - Uusitalo, Jori
AU  - Kivinen, Veli-Pekka
TI  - Logging Trail Segmentation via a Novel U-Net Convolutional Neural Network and High-Density Laser Scanning Data
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Logging trails are one of the main components of modern forestry. However, spotting the accurate locations of old logging trails through common approaches is challenging and time consuming. This study was established to develop an approach, using cutting-edge deep-learning convolutional neural networks and high-density laser scanning data, to detect logging trails in different stages of commercial thinning, in Southern Finland. We constructed a U-Net architecture, consisting of encoder and decoder paths with several convolutional layers, pooling and non-linear operations. The canopy height model (CHM), digital surface model (DSM), and digital elevation models (DEMs) were derived from the laser scanning data and were used as image datasets for training the model. The labeled dataset for the logging trails was generated from different references as well. Three forest areas were selected to test the efficiency of the algorithm that was developed for detecting logging trails. We designed 21 routes, including 390 samples of the logging trails and non-logging trails, covering all logging trails inside the stands. The results indicated that the trained U-Net using DSM (k = 0.846 and IoU = 0.867) shows superior performance over the trained model using CHM (k = 0.734 and IoU = 0.782), DEMavg (k = 0.542 and IoU = 0.667), and DEMmin (k = 0.136 and IoU = 0.155) in distinguishing logging trails from non-logging trails. Although the efficiency of the developed approach in young and mature stands that had undergone the commercial thinning is approximately perfect, it needs to be improved in old stands that have not received the second or third commercial thinning.
KW  - U-Net
KW  - high-density laser scanning
KW  - logging trails
KW  - digital surface model
KW  - canopy height model
KW  - commercial thinning
KW  - semantic segmentation
KW  - convolutional neural networks
DO  - 10.3390/rs14020349
ER  -
TY  - EJOU
AU  - Segura, David
AU  - Khatib, Emil J.
AU  - Barco, Raquel
TI  - Dynamic Packet Duplication for Industrial URLLC
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - The fifth-generation (5G) network is presented as one of the main options for Industry 4.0 connectivity. To comply with critical messages, 5G offers the Ultra-Reliable and Low latency Communications (URLLC) service category with a millisecond end-to-end delay and reduced probability of failure. There are several approaches to achieve these requirements; however, these come at a cost in terms of redundancy, particularly the solutions based on multi-connectivity, such as Packet Duplication (PD). Specifically, this paper proposes a Machine Learning (ML) method to predict whether PD is required at a specific data transmission to successfully send a URLLC message. This paper is focused on reducing the resource usage with respect to pure static PD. The concept was evaluated on a 5G simulator, comparing between single connection, static PD and PD with the proposed prediction model. The evaluation results show that the prediction model reduced the number of packets sent with PD by 81% while maintaining the same level of latency as a static PD technique, which derives from a more efficient usage of the network resources.
KW  - 5G
KW  - machine learning
KW  - prediction
KW  - Industry 4.0
KW  - URLLC
KW  - multi-connectivity
DO  - 10.3390/s22020587
ER  -
TY  - EJOU
AU  - Tuli, Esmot A.
AU  - Golam, Mohtasin
AU  - Kim, Dong-Seong
AU  - Lee, Jae-Min
TI  - Performance Enhancement of Optimized Link State Routing Protocol by Parameter Configuration for UANET
T2  - Drones

PY  - 2022
VL  - 6
IS  - 1
SN  - 2504-446X

AB  - The growing need for wireless communication has resulted in the widespread usage of unmanned aerial vehicles (UAVs) in a variety of applications. Designing a routing protocol for UAVs is paramount as well as challenging due to its dynamic attributes. The difficulty stems from features other than mobile ad hoc networks (MANET), such as aerial mobility in 3D space and frequently changing topology. This paper analyzes the performance of four topology-based routing protocols, dynamic source routing (DSR), ad hoc on-demand distance vector (AODV), geographic routing protocol (GRP), and optimized link state routing (OLSR), by using practical simulation software OPNET 14.5. Performance evaluation carries out various metrics such as throughput, delay, and data drop rate. Moreover, the performance of the OLSR routing protocol is enhanced and named &ldquo;E-OLSR&rdquo; by tuning parameters and reducing holding time. The optimized E-OLSR settings provide better performance than the conventional request for comments (RFC 3626) in the experiment, making it suitable for use in UAV ad hoc network (UANET) environments. Simulation results indicate the proposed E-OLSR outperforms the existing OLSR and achieves supremacy over other protocols mentioned in this paper.
KW  - enhanced optimized link state routing (E-OLSR)
KW  - OPNET
KW  - routing protocols
KW  - unmanned aerial vehicles (UAVs)
KW  - UAV Ad hoc network (UANET)
DO  - 10.3390/drones6010022
ER  -
TY  - EJOU
AU  - Sharma, Prakriti
AU  - Leigh, Larry
AU  - Chang, Jiyul
AU  - Maimaitijiang, Maitiniyazi
AU  - Caffé, Melanie
TI  - Above-Ground Biomass Estimation in Oats Using UAV Remote Sensing and Machine Learning
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - Current strategies for phenotyping above-ground biomass in field breeding nurseries demand significant investment in both time and labor. Unmanned aerial vehicles (UAV) can be used to derive vegetation indices (VIs) with high throughput and could provide an efficient way to predict forage yield with high accuracy. The main objective of the study is to investigate the potential of UAV-based multispectral data and machine learning approaches in the estimation of oat biomass. UAV equipped with a multispectral sensor was flown over three experimental oat fields in Volga, South Shore, and Beresford, South Dakota, USA, throughout the pre- and post-heading growth phases of oats in 2019. A variety of vegetation indices (VIs) derived from UAV-based multispectral imagery were employed to build oat biomass estimation models using four machine-learning algorithms: partial least squares (PLS), support vector machine (SVM), Artificial neural network (ANN), and random forest (RF). The results showed that several VIs derived from the UAV collected images were significantly positively correlated with dry biomass for Volga and Beresford (r = 0.2&ndash;0.65), however, in South Shore, VIs were either not significantly or weakly correlated with biomass. For Beresford, approximately 70% of the variance was explained by PLS, RF, and SVM validation models using data collected during the post-heading phase. Likewise for Volga, validation models had lower coefficient of determination (R2 = 0.20&ndash;0.25) and higher error (RMSE = 700&ndash;800 kg/ha) than training models (R2 = 0.50&ndash;0.60; RMSE = 500&ndash;690 kg/ha). In South Shore, validation models were only able to explain approx. 15&ndash;20% of the variation in biomass, which is possibly due to the insignificant correlation values between VIs and biomass. Overall, this study indicates that airborne remote sensing with machine learning has potential for above-ground biomass estimation in oat breeding nurseries. The main limitation was inconsistent accuracy in model prediction across locations. Multiple-year spectral data, along with the inclusion of textural features like crop surface model (CSM) derived height and volumetric indicators, should be considered in future studies while estimating biophysical parameters like biomass.
KW  - high throughput phenotyping
KW  - remote sensing
KW  - machine learning
KW  - UAV/drone
KW  - biomass estimation
KW  - oats
DO  - 10.3390/s22020601
ER  -
TY  - EJOU
AU  - Jing, Yafei
AU  - Ren, Yuhuan
AU  - Liu, Yalan
AU  - Wang, Dacheng
AU  - Yu, Linjun
TI  - Automatic Extraction of Damaged Houses by Earthquake Based on Improved YOLOv5: A Case Study in Yangbi
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Efficiently and automatically acquiring information on earthquake damage through remote sensing has posed great challenges because the classical methods of detecting houses damaged by destructive earthquakes are often both time consuming and low in accuracy. A series of deep-learning-based techniques have been developed and recent studies have demonstrated their high intelligence for automatic target extraction for natural and remote sensing images. For the detection of small artificial targets, current studies show that You Only Look Once (YOLO) has a good performance in aerial and Unmanned Aerial Vehicle (UAV) images. However, less work has been conducted on the extraction of damaged houses. In this study, we propose a YOLOv5s-ViT-BiFPN-based neural network for the detection of rural houses. Specifically, to enhance the feature information of damaged houses from the global information of the feature map, we introduce the Vision Transformer into the feature extraction network. Furthermore, regarding the scale differences for damaged houses in UAV images due to the changes in flying height, we apply the Bi-Directional Feature Pyramid Network (BiFPN) for multi-scale feature fusion to aggregate features with different resolutions and test the model. We took the 2021 Yangbi earthquake with a surface wave magnitude (Ms) of 6.4 in Yunan, China, as an example; the results show that the proposed model presents a better performance, with the average precision (AP) being increased by 9.31% and 1.23% compared to YOLOv3 and YOLOv5s, respectively, and a detection speed of 80 FPS, which is 2.96 times faster than YOLOv3. In addition, the transferability test for five other areas showed that the average accuracy was 91.23% and the total processing time was 4 min, while 100 min were needed for professional visual interpreters. The experimental results demonstrate that the YOLOv5s-ViT-BiFPN model can automatically detect damaged rural houses due to destructive earthquakes in UAV images with a good performance in terms of accuracy and timeliness, as well as being robust and transferable.
KW  - damaged houses
KW  - detection
KW  - orthophotos of UAV
KW  - YOLOv5s-ViT-BiFPN
KW  - Yangbi Ms6.4 earthquake
DO  - 10.3390/rs14020382
ER  -
TY  - EJOU
AU  - Howland, Matthew D.
AU  - Tamberino, Anthony
AU  - Liritzis, Ioannis
AU  - Levy, Thomas E.
TI  - Digital Deforestation: Comparing Automated Approaches to the Production of Digital Terrain Models (DTMs) in Agisoft Metashape
T2  - Quaternary

PY  - 2022
VL  - 5
IS  - 1
SN  - 2571-550X

AB  - This paper tests the suitability of automated point cloud classification tools provided by the popular image-based modeling (IBM) software package Agisoft Metashape for the generation of digital terrain models (DTMs) at moderately-vegetated archaeological sites. DTMs are often required for various forms of archaeological mapping and analysis. The suite of tools provided by Agisoft are relatively user-friendly as compared to many point cloud classification algorithms and do not require the use of additional software. Based on a case study from the Mycenaean site of Kastrouli, Greece, the mostly-automated, geometric classification tool &ldquo;Classify Ground Points&rdquo; provides the best results and produces a quality DTM that is sufficient for mapping and analysis. Each of the methods tested in this paper can likely be improved through manual editing of point cloud classification.
KW  - photogrammetry
KW  - DTM
KW  - GIS
KW  - IBM
DO  - 10.3390/quat5010005
ER  -
TY  - EJOU
AU  - Li, Zongpeng
AU  - Chen, Zhen
AU  - Cheng, Qian
AU  - Duan, Fuyi
AU  - Sui, Ruixiu
AU  - Huang, Xiuqiao
AU  - Xu, Honggang
TI  - UAV-Based Hyperspectral and Ensemble Machine Learning for Predicting Yield in Winter Wheat
T2  - Agronomy

PY  - 2022
VL  - 12
IS  - 1
SN  - 2073-4395

AB  - Winter wheat is a widely-grown cereal crop worldwide. Using growth-stage information to estimate winter wheat yields in a timely manner is essential for accurate crop management and rapid decision-making in sustainable agriculture, and to increase productivity while reducing environmental impact. UAV remote sensing is widely used in precision agriculture due to its flexibility and increased spatial and spectral resolution. Hyperspectral data are used to model crop traits because of their ability to provide continuous rich spectral information and higher spectral fidelity. In this study, hyperspectral image data of the winter wheat crop canopy at the flowering and grain-filling stages was acquired by a low-altitude unmanned aerial vehicle (UAV), and machine learning was used to predict winter wheat yields. Specifically, a large number of spectral indices were extracted from the spectral data, and three feature selection methods, recursive feature elimination (RFE), Boruta feature selection, and the Pearson correlation coefficient (PCC), were used to filter high spectral indices in order to reduce the dimensionality of the data. Four major basic learner models, (1) support vector machine (SVM), (2) Gaussian process (GP), (3) linear ridge regression (LRR), and (4) random forest (RF), were also constructed, and an ensemble machine learning model was developed by combining the four base learner models. The results showed that the SVM yield prediction model, constructed on the basis of the preferred features, performed the best among the base learner models, with an R2 between 0.62 and 0.73. The accuracy of the proposed ensemble learner model was higher than that of each base learner model; moreover, the R2 (0.78) for the yield prediction model based on Boruta&rsquo;s preferred characteristics was the highest at the grain-filling stage.
KW  - yield
KW  - feature selection
KW  - flowering
KW  - grain filling
KW  - prediction model
DO  - 10.3390/agronomy12010202
ER  -
TY  - EJOU
AU  - Shi, Yue
AU  - Han, Liangxiu
AU  - Kleerekoper, Anthony
AU  - Chang, Sheng
AU  - Hu, Tongle
TI  - Novel CropdocNet Model for Automated Potato Late Blight Disease Detection from Unmanned Aerial Vehicle-Based Hyperspectral Imagery
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - The accurate and automated diagnosis of potato late blight disease, one of the most destructive potato diseases, is critical for precision agricultural control and management. Recent advances in remote sensing and deep learning offer the opportunity to address this challenge. This study proposes a novel end-to-end deep learning model (CropdocNet) for accurate and automated late blight disease diagnosis from UAV-based hyperspectral imagery. The proposed method considers the potential disease-specific reflectance radiation variance caused by the canopy&rsquo;s structural diversity and introduces multiple capsule layers to model the part-to-whole relationship between spectral&ndash;spatial features and the target classes to represent the rotation invariance of the target classes in the feature space. We evaluate the proposed method with real UAV-based HSI data under controlled and natural field conditions. The effectiveness of the hierarchical features is quantitatively assessed and compared with the existing representative machine learning/deep learning methods on both testing and independent datasets. The experimental results show that the proposed model significantly improves accuracy when considering the hierarchical structure of spectral&ndash;spatial features, with average accuracies of 98.09% for the testing dataset and 95.75% for the independent dataset, respectively.
KW  - potato late blight
KW  - automated crop disease diagnosis
KW  - UAV-based hyperspectral imagery
KW  - deep learning
KW  - classification
DO  - 10.3390/rs14020396
ER  -
TY  - EJOU
AU  - Zhang, Fangfang
AU  - Wang, Changkun
AU  - Pan, Kai
AU  - Guo, Zhiying
AU  - Liu, Jie
AU  - Xu, Aiai
AU  - Ma, Haiyi
AU  - Pan, Xianzhang
TI  - The Simultaneous Prediction of Soil Properties and Vegetation Coverage from Vis-NIR Hyperspectral Data with a One-Dimensional Convolutional Neural Network: A Laboratory Simulation Study
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Remote sensing of land surface mostly obtains a mixture of spectral information of soil and vegetation. It is thus of great value if soil and vegetation information can be acquired simultaneously from one model. In this study, we designed a laboratory experiment to simulate land surface compositions, including various soil types with varying soil moisture and vegetation coverage. A model of a one-dimensional convolutional neural network (1DCNN) was established to simultaneously estimate soil properties (organic matter, soil moisture, clay, and sand) and vegetation coverage based on the hyperspectral data measured in the experiment. The results showed that the model achieved excellent predictions for soil properties (R2 = 0.88&ndash;0.91, RPIQ = 4.01&ndash;5.78) and vegetation coverage (R2 = 0.95, RPIQ = 7.75). Compared with the partial least-squares regression (PLSR), the prediction accuracy of 1DCNN improved 42.20%, 45.82%, 43.32%, and 36.46% in terms of the root-mean-squared error (RMSE) for predicting soil organic matter, sand, clay, and soil moisture, respectively. The improvement might be caused by the fact that the spectral preprocessing and spectral features useful for predicting soil properties were successfully identified in the 1DCNN model. For the prediction of vegetation coverage, although the prediction accuracy by 1DCNN was excellent, its performance (R2 = 0.95, RPIQ = 7.75, RMSE = 3.92%) was lower than the PLSR model (R2 = 0.98, RPIQ = 12.57, RMSE = 2.41%). These results indicate that 1DCNN can simultaneously predict soil properties and vegetation coverage. However, the factors such as surface roughness and vegetation type that could affect the prediction accuracy should be investigated in the future.
KW  - convolutional neural network
KW  - multitask learning
KW  - soil properties
KW  - vegetation coverage
DO  - 10.3390/rs14020397
ER  -
TY  - EJOU
AU  - Lu, Zhumao
AU  - Gong, Hao
AU  - Jin, Qiuheng
AU  - Hu, Qingwu
AU  - Wang, Shaohua
TI  - A Transmission Tower Tilt State Assessment Approach Based on Dense Point Cloud from UAV-Based LiDAR
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Transmission towers are easily affected by various meteorological and geological disasters. In this paper, a transmission tower tilt state assessment approach&mdash;based on high precision and dense point cloud from UAV LiDAR&mdash;was proposed. First, the transmission tower point cloud was rapidly located and extracted from the 3D point cloud obtained by UAV-LiDAR line patrol. A robust histogram local extremum extraction method with additional constraints was proposed to achieve adaptive segmentation of the tower head and tower body point cloud. Second, an accurate and efficient extraction and simplification strategy of the contour of the feature plane point cloud was proposed. The central axis of the tower was constrained by the contour of the feature plane through the four-prism structure to calculate the tilt angle of the tower and evaluate the state of the tower. Finally, the point cloud of tower head from UAV-based LiDAR was accurately matched with the designed tower head model from database, and a tower head state evaluation model based on matching offset parameters was proposed to evaluate tower head tilt state. The experimental results of simulation and measured data showed that the calculation accuracy of the tilt parameters of transmission tower body was better than 0.5 degrees, that the proposed method can effectively evaluate the risk of tower head with complex structure, and improve the rapid and mass intelligent perception level of the risk state of the transmission line tower, which has a wide prospects for application.
KW  - UAV LiDAR
KW  - point cloud
KW  - transmission tower
KW  - tilt
KW  - state assessment
DO  - 10.3390/rs14020408
ER  -
TY  - EJOU
AU  - Hung, Kuo-Ching
AU  - Lin, Meng-Chun
AU  - Lin, Sheng-Fuu
TI  - A Novel Power-Saving Reversing Camera System with Artificial Intelligence Object Detection
T2  - Electronics

PY  - 2022
VL  - 11
IS  - 2
SN  - 2079-9292

AB  - According to a study by the Insurance Institute for Highway Safety (IIHS), the driving collision rate of using only the reversing camera system is lower than that of using both the reversing camera system and the reversing radar. In this article, we implemented a reversing camera system with artificial intelligence object detection to increase the information of the reversing image. Our system consists of an image processing chip (IPC) with wide-angle image distortion correction and an image buffer controller, a low-power KL520 chip and an optimized artificial intelligence model MobileNetV2-YOLOV3-Optimized (MNYLO). The results of the experiment show the three advantages of our system. Firstly, through the image distortion correction of IPC, we can restore the distorted reversing image. Secondly, by using a public dataset and collected images of various weathers for artificial intelligence model training, our system does not need to use image algorithms that eliminate bad weathers such as rain, fog, and snow to restore polluted images. Objects can still be detected by our system in images contaminated by weather. Thirdly, compared with the AI model Tiny_YOLOV3, not only the parameters of our MNYLO have been reduced by 72.3%, the amount of calculation has been reduced by 86.4%, but the object detection rate has also been maintained and avoided sharp drops.
KW  - artificial intelligence
KW  - image distortion correction
KW  - MobileNetV2
KW  - object detection
KW  - reversing camera system
KW  - Tiny-YOLOV3
DO  - 10.3390/electronics11020282
ER  -
TY  - EJOU
AU  - Xu, Zhibo
AU  - Huang, Xiaopeng
AU  - Huang, Yuan
AU  - Sun, Haobo
AU  - Wan, Fangxin
TI  - A Real-Time Zanthoxylum Target Detection Method for an Intelligent Picking Robot under a Complex Background, Based on an Improved YOLOv5s Architecture
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - The target recognition algorithm is one of the core technologies of Zanthoxylum pepper-picking robots. However, most existing detection algorithms cannot effectively detect Zanthoxylum fruit covered by branches, leaves and other fruits in natural scenes. To improve the work efficiency and adaptability of the Zanthoxylum-picking robot in natural environments, and to recognize and detect fruits in complex environments under different lighting conditions, this paper presents a Zanthoxylum-picking-robot target detection method based on improved YOLOv5s. Firstly, an improved CBF module based on the CBH module in the backbone is raised to improve the detection accuracy. Secondly, the Specter module based on CBF is presented to replace the bottleneck CSP module, which improves the speed of detection with a lightweight structure. Finally, the Zanthoxylum fruit algorithm is checked by the improved YOLOv5 framework, and the differences in detection between YOLOv3, YOLOv4 and YOLOv5 are analyzed and evaluated. Through these improvements, the recall rate, recognition accuracy and mAP of the YOLOv5s are 4.19%, 28.7% and 14.8% higher than those of the original YOLOv5s, YOLOv3 and YOLOv4 models, respectively. Furthermore, the model is transferred to the computing platform of the robot with the cutting-edge NVIDIA Jetson TX2 device. Several experiments are implemented on the TX2, yielding an average time of inference of 0.072, with an average GPU load in 30 s of 20.11%. This method can provide technical support for pepper-picking robots to detect multiple pepper fruits in real time.
KW  - Zanthoxylum
KW  - artificial intelligence
KW  - YOLOv5
KW  - target detection
KW  - picking robot
DO  - 10.3390/s22020682
ER  -
TY  - EJOU
AU  - Paux, Etienne
AU  - Lafarge, Stéphane
AU  - Balfourier, François
AU  - Derory, Jérémy
AU  - Charmet, Gilles
AU  - Alaux, Michael
AU  - Perchet, Geoffrey
AU  - Bondoux, Marion
AU  - Baret, Frédéric
AU  - Barillot, Romain
AU  - Ravel, Catherine
AU  - Sourdille, Pierre
AU  - Le Gouis, Jacques
AU  - on behalf of the BREEDWHEAT Consortium
TI  - Breeding for Economically and Environmentally Sustainable Wheat Varieties: An Integrated Approach from Genomics to Selection
T2  - Biology

PY  - 2022
VL  - 11
IS  - 1
SN  - 2079-7737

AB  - There is currently a strong societal demand for sustainability, quality, and safety in bread wheat production. To address these challenges, new and innovative knowledge, resources, tools, and methods to facilitate breeding are needed. This starts with the development of high throughput genomic tools including single nucleotide polymorphism (SNP) arrays, high density molecular marker maps, and full genome sequences. Such powerful tools are essential to perform genome-wide association studies (GWAS), to implement genomic and phenomic selection, and to characterize the worldwide diversity. This is also useful to breeders to broaden the genetic basis of elite varieties through the introduction of novel sources of genetic diversity. Improvement in varieties particularly relies on the detection of genomic regions involved in agronomical traits including tolerance to biotic (diseases and pests) and abiotic (drought, nutrient deficiency, high temperature) stresses. When enough resolution is achieved, this can result in the identification of candidate genes that could further be characterized to identify relevant alleles. Breeding must also now be approached through in silico modeling to simulate plant development, investigate genotype &times; environment interactions, and introduce marker&ndash;trait linkage information in the models to better implement genomic selection. Breeders must be aware of new developments and the information must be made available to the world wheat community to develop new high-yielding varieties that can meet the challenge of higher wheat production in a sustainable and fluctuating agricultural context. In this review, we compiled all knowledge and tools produced during the BREEDWHEAT project to show how they may contribute to face this challenge in the coming years.
KW  - wheat
KW  - Triticum aestivum
KW  - wheat breeding
KW  - molecular tools
KW  - genomic selection
KW  - high throughput phenotyping
KW  - diversity
KW  - wheat database
DO  - 10.3390/biology11010149
ER  -
TY  - EJOU
AU  - Qi, Guanqiu
AU  - Zhang, Yuanchuan
AU  - Wang, Kunpeng
AU  - Mazur, Neal
AU  - Liu, Yang
AU  - Malaviya, Devanshi
TI  - Small Object Detection Method Based on Adaptive Spatial Parallel Convolution and Fast Multi-Scale Fusion
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - As one type of object detection, small object detection has been widely used in daily-life-related applications with many real-time requirements, such as autopilot and navigation. Although deep-learning-based object detection methods have achieved great success in recent years, they are not effective in small object detection and most of them cannot achieve real-time processing. Therefore, this paper proposes a single-stage small object detection network (SODNet) that integrates the specialized feature extraction and information fusion techniques. An adaptively spatial parallel convolution module (ASPConv) is proposed to alleviate the lack of spatial information for target objects and adaptively obtain the corresponding spatial information through multi-scale receptive fields, thereby improving the feature extraction ability. Additionally, a split-fusion sub-module (SF) is proposed to effectively reduce the time complexity of ASPConv. A fast multi-scale fusion module (FMF) is proposed to alleviate the insufficient fusion of both semantic and spatial information. FMF uses two fast upsampling operators to first unify the resolution of the multi-scale feature maps extracted by the network and then fuse them, thereby effectively improving the small object detection ability. Comparative experimental results prove that the proposed method considerably improves the accuracy of small object detection on multiple benchmark datasets and achieves a high real-time performance.
KW  - small object detection
KW  - adaptive spatial parallel convolution
KW  - multi-scale fusion
DO  - 10.3390/rs14020420
ER  -
TY  - EJOU
AU  - Savkin, Andrey V.
AU  - Verma, Satish C.
AU  - Anstee, Stuart
TI  - Optimal Navigation of an Unmanned Surface Vehicle and an Autonomous Underwater Vehicle Collaborating for Reliable Acoustic Communication with Collision Avoidance
T2  - Drones

PY  - 2022
VL  - 6
IS  - 1
SN  - 2504-446X

AB  - This paper focuses on safe navigation of an unmanned surface vehicle in proximity to a submerged autonomous underwater vehicle so as to maximise short-range, through-water data transmission while minimising the probability that the two vehicles will accidentally collide. A sliding mode navigation law is developed, and a rigorous proof of optimality of the proposed navigation law is presented. The developed navigation algorithm is relatively computationally simple and easily implementable in real time. Illustrative examples with extensive computer simulations demonstrate the effectiveness of the proposed method.
KW  - autonomous navigation
KW  - autonomous underwater vehicles
KW  - unmanned surface vehicles
KW  - AUVs
KW  - USVs
KW  - marine vehicles
KW  - cooperative control
KW  - sliding mode control
KW  - collision avoidance
KW  - acoustic communication
KW  - underwater communication
KW  - collaborating vehicles
KW  - optimal control
DO  - 10.3390/drones6010027
ER  -
TY  - EJOU
AU  - Chen, Ting
AU  - Liu, Mengni
AU  - Gao, Tao
AU  - Cheng, Peng
AU  - Mei, Shaohui
AU  - Li, Yonghui
TI  - A Fusion-Based Defogging Algorithm
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - To solve the problem that traditional dark channel is not suitable for a large sky area and can easyily distort defogged images, we propose a novel fusion-based defogging algorithm. Firstly, an improved remote sensing image segmentation algorithm is introduced to mix the dark channel. Secondly, we establish a dark-light channel fusion model to calculate the atmospheric light map. Furthermore, in order to refine the transmittance image without reducing restoration quality, the grayscale image corresponding to the original image is selected as a guide image. Meanwhile, we optimize the set value of the defogging intensity parameter &omega; in the transmission estimation formula as the value of atmospheric light. Finally, a brightness/color compensation model based on visual perception is generated for image correction. Experimental results demonstrate that the proposed algorithm achieves superior performance on UAV foggy images in both subjective and objective evaluation, which verifies the effectiveness of the proposed algorithm.
KW  - image defogging
KW  - image segmentation
KW  - mixed dark channel
KW  - light channel
KW  - image correction
DO  - 10.3390/rs14020425
ER  -
TY  - EJOU
AU  - Zhang, Shiyu
AU  - Yang, Qing
AU  - Gao, Yuchen
AU  - Gao, Dexin
TI  - Real-Time Fire Detection Method for Electric Vehicle Charging Stations Based on Machine Vision
T2  - World Electric Vehicle Journal

PY  - 2022
VL  - 13
IS  - 2
SN  - 2032-6653

AB  - During the charging process of electric vehicles (EV), the circuit inside the charger plug is connected in series, the charger input voltage does not match the rated input voltage, the temperature caused by the severe heating of the charging time is too high for too long, and other factors are very likely to trigger a fire in the vehicle charging pile. In this paper, an improved You Only Look Once v4 (YOLOv4) real-time target detection algorithm based on machine vision is proposed to monitor the site based on existing monitoring equipment, transmit live video information in real-time, expand the monitoring range, and significantly reduce the cost of use. During the experiment, the improved neural network model was trained by a homemade fire video image dataset, and a K-means clustering algorithm iwasintroduced to recalculate the anchor frame size for the specific object of flame; the existing dataset was used to perform multiple divisions by using a tenfold cross-validation algorithm, thus avoiding the selection of chance hyperparameters and models that do not have generalization ability because of special divisions. The experimental results show that the improved algorithm is fast and accurate in detecting large-size flames in real-time and small-size flames at the beginning of a fire, with a detection speed of 43 fps/s, mAP value of 91.53%, and F1 value of 0.91. Compared with YOLOv3 and YOLOv4 models, the improved model is sensitive to detecting different sizes of flames. It can suppress false alarms well in a variety of complex lighting environments. The prediction frame size fits the area where the target is located, the detection accuracy remains stable, and the comprehensive performance of the network model is significantly improved to meet the demand of real-time monitoring. It is significant for developing the EV industry and enhancing emergency response capability.
KW  - electric vehicle charging stations
KW  - machine vision
KW  - fire detection
KW  - YOLOv4
KW  - K-means clustering algorithm
DO  - 10.3390/wevj13020023
ER  -
TY  - EJOU
AU  - Wang, Jingru
AU  - Wang, Cheng
AU  - Xi, Xiaohuan
AU  - Wang, Pu
AU  - Du, Meng
AU  - Nie, Sheng
TI  - Location and Extraction of Telegraph Poles from Image Matching-Based Point Clouds
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 3
SN  - 2072-4292

AB  - The monitoring of telegraph poles as essential features supporting overhead distribution network lines is the primary subject of this work. This paper proposes a method for locating and extracting telegraph poles from an image matching-based point cloud. Firstly, the point cloud of the poles is extracted using the planar grid segmentation clustering algorithm and the connected component analysis algorithm of the region grows according to the isolated features of the poles perpendicular to the ground. Secondly, the candidate telegraph poles are located based on the suspension point of the buffer, considering that the top of the pole is connected to the power suspension line. Thirdly, the horizontal projection method of the backbone area is utilized to eliminate the interference of vegetation in the buffer area. Finally, the point cloud of the telegraph pole is extracted through the density-based spatial clustering of applications with noise (DBSCAN) algorithm. The experimental results demonstrate that the average values of Recall, Precision, and F1-score in telegraph pole detection can reach 91.09%, 90.82%, and 90.90%, respectively. The average RMSE value of location deviation is 0.51m. The average value of the F1-score in the telegraph pole extraction is 91.83%, and the average extraction time of a single pole is 0.27s. Accordingly, this method has strong adaptability to areas with lush vegetation and can automatically locate and extract the telegraph pole point cloud with high accuracy, and it can still achieve very high accuracy even under the holes in the data.
KW  - the distribution network line inspection
KW  - telegraph poles
KW  - locating
KW  - extracting
KW  - grid segmentation
KW  - connected component analysis
KW  - DBSCAN
DO  - 10.3390/rs14030433
ER  -
TY  - EJOU
AU  - Kiani, Farzad
AU  - Seyyedabbasi, Amir
AU  - Nematzadeh, Sajjad
AU  - Candan, Fuat
AU  - Çevik, Taner
AU  - Anka, Fateme A.
AU  - Randazzo, Giovanni
AU  - Lanza, Stefania
AU  - Muzirafuti, Anselme
TI  - Adaptive Metaheuristic-Based Methods for Autonomous Robot Path Planning: Sustainable Agricultural Applications
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 3
SN  - 2076-3417

AB  - The increasing need for food in recent years means that environmental protection and sustainable agriculture are necessary. For this, smart agricultural systems and autonomous robots have become widespread. One of the most significant and persistent problems related to robots is 3D path planning, which is an NP-hard problem, for mobile robots. In this paper, efficient methods are proposed by two metaheuristic algorithms (Incremental Gray Wolf Optimization (I-GWO) and Expanded Gray Wolf Optimization (Ex-GWO)). The proposed methods try to find collision-free optimal paths between two points for robots without human intervention in an acceptable time with the lowest process costs and efficient use of resources in large-scale and crowded farmlands. Thanks to the methods proposed in this study, various tasks such as tracking crops can be performed efficiently by autonomous robots. The simulations are carried out using three methods, and the obtained results are compared with each other and analyzed. The relevant results show that in the proposed methods, the mobile robots avoid the obstacles successfully and obtain the optimal path cost from source to destination. According to the simulation results, the proposed method based on the Ex-GWO algorithm has a better success rate of 55.56% in optimal path cost.
KW  - autonomous robots
KW  - remote sensing
KW  - smart agriculture
KW  - climate change
KW  - environmental protection
KW  - drone
KW  - photogrammetry
KW  - path planning
KW  - internet of things
KW  - environmental monitoring
DO  - 10.3390/app12030943
ER  -
TY  - EJOU
AU  - Cui, Xue-Zhi
AU  - Feng, Quan
AU  - Wang, Shu-Zhi
AU  - Zhang, Jian-Hua
TI  - Monocular Depth Estimation with Self-Supervised Learning for Vineyard Unmanned Agricultural Vehicle
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 3
SN  - 1424-8220

AB  - To find an economical solution to infer the depth of the surrounding environment of unmanned agricultural vehicles (UAV), a lightweight depth estimation model called MonoDA based on a convolutional neural network is proposed. A series of sequential frames from monocular videos are used to train the model. The model is composed of two subnetworks&mdash;the depth estimation subnetwork and the pose estimation subnetwork. The former is a modified version of U-Net that reduces the number of bridges, while the latter takes EfficientNet-B0 as its backbone network to extract the features of sequential frames and predict the pose transformation relations between the frames. The self-supervised strategy is adopted during the training, which means the depth information labels of frames are not needed. Instead, the adjacent frames in the image sequence and the reprojection relation of the pose are used to train the model. Subnetworks&rsquo; outputs (depth map and pose relation) are used to reconstruct the input frame, then a self-supervised loss between the reconstructed input and the original input is calculated. Finally, the loss is employed to update the parameters of the two subnetworks through the backward pass. Several experiments are conducted to evaluate the model&rsquo;s performance, and the results show that MonoDA has competitive accuracy over the KITTI raw dataset as well as our vineyard dataset. Besides, our method also possessed the advantage of non-sensitivity to color. On the computing platform of our UAV&rsquo;s environment perceptual system NVIDIA JETSON TX2, the model could run at 18.92 FPS. To sum up, our approach provides an economical solution for depth estimation by using monocular cameras, which achieves a good trade-off between accuracy and speed and can be used as a novel auxiliary depth detection paradigm for UAVs.
KW  - edge computing device
KW  - monocular depth estimation
KW  - self-supervised learning
KW  - vineyard scene
DO  - 10.3390/s22030721
ER  -
TY  - EJOU
AU  - Pang, Alexis
AU  - Chang, Melissa W.
AU  - Chen, Yang
TI  - Evaluation of Random Forests (RF) for Regional and Local-Scale Wheat Yield Prediction in Southeast Australia
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 3
SN  - 1424-8220

AB  - Wheat accounts for more than 50% of Australia&rsquo;s total grain production. The capability to generate accurate in-season yield predictions is important across all components of the agricultural value chain. The literature on wheat yield prediction has motivated the need for more novel works evaluating machine learning techniques such as random forests (RF) at multiple scales. This research applied a Random Forest Regression (RFR) technique to build regional and local-scale yield prediction models at the pixel level for three southeast Australian wheat-growing paddocks, each located in Victoria (VIC), New South Wales (NSW) and South Australia (SA) using 2018 yield maps from data supplied by collaborating farmers. Time-series Normalized Difference Vegetation Index (NDVI) data derived from Planet&rsquo;s high spatio-temporal resolution imagery, meteorological variables and yield data were used to train, test and validate the models at pixel level using Python libraries for (a) regional-scale three-paddock composite and (b) individual paddocks. The composite region-wide RF model prediction for the three paddocks performed well (R2 = 0.86, RMSE = 0.18 t ha&minus;1). RF models for individual paddocks in VIC (R2 = 0.89, RMSE = 0.15 t ha&minus;1) and NSW (R2 = 0.87, RMSE = 0.07 t ha&minus;1) performed well, but moderate performance was seen for SA (R2 = 0.45, RMSE = 0.25 t ha&minus;1). Generally, high values were underpredicted and low values overpredicted. This study demonstrated the feasibility of applying RF modeling on satellite imagery and yielded &lsquo;big data&rsquo; for regional as well as local-scale yield prediction.
KW  - wheat
KW  - yield prediction
KW  - random forests
KW  - satellite imagery
KW  - Normalized Difference Vegetation Index (NDVI)
DO  - 10.3390/s22030717
ER  -
TY  - EJOU
AU  - Çetin, Ender
AU  - Cano, Alicia
AU  - Deransy, Robin
AU  - Tres, Sergi
AU  - Barrado, Cristina
TI  - Implementing Mitigations for Improving Societal Acceptance of Urban Air Mobility
T2  - Drones

PY  - 2022
VL  - 6
IS  - 2
SN  - 2504-446X

AB  - The continuous development of technical innovations provides the opportunity to create new economic markets and a wealth of new services. However, these innovations sometimes raise concerns, notably in terms of societal, safety, and environmental impacts. This is the case for services related to the operation of unmanned aerial vehicles (UAV), which are emerging rapidly. Unmanned aerial vehicles, also called drones, date back to the first third of the twentieth century in aviation industry, when they were mostly used for military purposes. Nowadays, drones of various types and sizes are used for many purposes, such as precision agriculture, search and rescue missions, aerial photography, shipping and delivery, etc. Starting to operate in areas with low population density, drones are now looking for business in urban and suburban areas, in what is called urban air mobility (UAM). However, this rapid growth of the drone industry creates psychological fear of the unknown in some parts of society. Reducing this fear will play an important role in public acceptance of drone operations in urban areas. This paper presents the main concerns of society with regard to drone operations, as already captured in some public surveys, and proposes a list of mitigation measures to reduce these concerns. The proposed list is then analyzed, and its applicability to individual, urban, very large demonstration flights is explained, using the feedback from the CORUS-XUAM project. CORUS-XUAM will organize a set of very large drone flight demonstrations across seven European countries to investigate how to safely integrate drone operations into airspace with the support of the U-space.
KW  - drones
KW  - unmanned aerial vehicles (UAV)
KW  - social acceptance
KW  - urban air mobility (UAM)
KW  - CORUS-XUAM
DO  - 10.3390/drones6020028
ER  -
TY  - EJOU
AU  - Tao, Tao
AU  - Zheng, Hong
AU  - Yang, Jianfeng
AU  - Guo, Zhongyuan
AU  - Zhang, Yiyang
AU  - Ao, Jiahui
AU  - Chen, Yuao
AU  - Lin, Weiting
AU  - Tan, Xiao
TI  - Sound Localization and Speech Enhancement Algorithm Based on Dual-Microphone
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 3
SN  - 1424-8220

AB  - In order to simplify the complexity and reduce the cost of the microphone array, this paper proposes a dual-microphone based sound localization and speech enhancement algorithm. Based on the time delay estimation of the signal received by the dual microphones, this paper combines energy difference estimation and controllable beam response power to realize the 3D coordinate calculation of the acoustic source and dual-microphone sound localization. Based on the azimuth angle of the acoustic source and the analysis of the independent quantity of the speech signal, the separation of the speaker signal of the acoustic source is realized. On this basis, post-wiener filtering is used to amplify and suppress the voice signal of the speaker, which can help to achieve speech enhancement. Experimental results show that the dual-microphone sound localization algorithm proposed in this paper can accurately identify the sound location, and the speech enhancement algorithm is more robust and adaptable than the original algorithm.
KW  - dual-microphone array
KW  - sound localization
KW  - speech enhancement
KW  - time delay estimation
KW  - post-filtering
DO  - 10.3390/s22030715
ER  -
TY  - EJOU
AU  - Kseňak, Ľubomír
AU  - Pukanská, Katarína
AU  - Bartoš, Karol
AU  - Blišťan, Peter
TI  - Assessment of the Usability of SAR and Optical Satellite Data for Monitoring Spatio-Temporal Changes in Surface Water: Bodrog River Case Study
T2  - Water

PY  - 2022
VL  - 14
IS  - 3
SN  - 2073-4441

AB  - Mapping watercourses and their surroundings through remote sensing methods is a fast, continuous, and effective method and is a crucial tool for capturing change and possibly predicting hazards. Thanks to Synthetic Aperture Radar (SAR) technology and the ability of its backscattered and emitted radiation to penetrate the atmosphere under any conditions, this type of mapping of water surfaces is of particular importance. This paper presents the possibility of using SAR technology for long-term observations of changes in the behaviour of rivers and river systems, combined with optical multispectral images Sentinel-2. Additionally, it aims to demonstrate the suitability of satellite SAR and multispectral data implementation for mapping changes in watercourses, caused not only by their natural development but especially by inundation processes in their catchment area. Appropriate Sentinel-1 image processing evaluation procedures demonstrate that the usage of vertical-vertical (VV) type polarisation configuration is a suitable methodology for documenting water bodies, and a Lee filter is an acceptable tool for radar noise filtering. The extraction process of water surfaces is based on the determination of threshold values using the &ldquo;Otsu&rdquo; principle. Subsequently, the comparison of the results is realised by the spectral indices of water&mdash;the Normalized Difference Water Index (NDWI), Modified Normalized Difference Water Index (MNDWI), a pair of Automated Water Extraction Index (AWEI) indices, and supervised classification method Maximum Likelihood Classification (MLC). The results are numerical and graphical evaluated. In assessing the accuracy of SAR extraction, the highest values achieved in Overall Accuracy (OA) were a maximum of 98.6%. On average, the lower values were in User Accuracy (UA) with a maximum of 93.1%, where VV polarisation also dominates. However, vertical-horizontal (VH) polarisation dominates in Producer Accuracy (PA) with a maximum of 84.9%.
KW  - remote sensing
KW  - spectral indices of water
KW  - Synthetic Aperture Radar
KW  - surface water changes
DO  - 10.3390/w14030299
ER  -
TY  - EJOU
AU  - Chandrasekaran, Ganesh
AU  - Antoanela, Naaji
AU  - Andrei, Gabor
AU  - Monica, Ciobanu
AU  - Hemanth, Jude
TI  - Visual Sentiment Analysis Using Deep Learning Models with Social Media Data
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 3
SN  - 2076-3417

AB  - Analyzing the sentiments of people from social media content through text, speech, and images is becoming vital in a variety of applications. Many existing research studies on sentiment analysis rely on textual data, and similar to the sharing of text, users of social media share more photographs and videos. Compared to text, images are said to exhibit the sentiments in a much better way. So, there is an urge to build a sentiment analysis model based on images from social media. In our work, we employed different transfer learning models, including the VGG-19, ResNet50V2, and DenseNet-121 models, to perform sentiment analysis based on images. They were fine-tuned by freezing and unfreezing some of the layers, and their performance was boosted by applying regularization techniques. We used the Twitter-based images available in the Crowdflower dataset, which contains URLs of images with their sentiment polarities. Our work also presents a comparative analysis of these pre-trained models in the prediction of image sentiments on our dataset. The accuracies of our fine-tuned transfer learning models involving VGG-19, ResNet50V2, and DenseNet-121 are 0.73, 0.75, and 0.89, respectively. When compared to previous attempts at visual sentiment analysis, which used a variety of machine and deep learning techniques, our model had an improved accuracy by about 5% to 10%. According to the findings, the fine-tuned DenseNet-121 model outperformed the VGG-19 and ResNet50V2 models in image sentiment prediction.
KW  - image sentiment analysis
KW  - transfer learning
KW  - deep learning and social media
DO  - 10.3390/app12031030
ER  -
TY  - EJOU
AU  - Chen, Guang
AU  - Shang, Yi
TI  - Transformer for Tree Counting in Aerial Images
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 3
SN  - 2072-4292

AB  - The number of trees and their spatial distribution are key information for forest management. In recent years, deep learning-based approaches have been proposed and shown promising results in lowering the expensive labor cost of a forest inventory. In this paper, we propose a new efficient deep learning model called density transformer or DENT for automatic tree counting from aerial images. The architecture of DENT contains a multi-receptive field convolutional neural network to extract visual feature representation from local patches and their wide context, a transformer encoder to transfer contextual information across correlated positions, a density map generator to generate spatial distribution map of trees, and a fast tree counter to estimate the number of trees in each input image. We compare DENT with a variety of state-of-art methods, including one-stage and two-stage, anchor-based and anchor-free deep neural detectors, and different types of fully convolutional regressors for density estimation. The methods are evaluated on a new large dataset we built and an existing cross-site dataset. DENT achieves top accuracy on both datasets, significantly outperforming most of the other methods. We have released our new dataset, called Yosemite Tree Dataset, containing a 10 km2 rectangular study area with around 100k trees annotated, as a benchmark for public access.
KW  - tree counting
KW  - Yosemite
KW  - transformer
KW  - neural network
KW  - deep learning
DO  - 10.3390/rs14030476
ER  -
TY  - EJOU
AU  - Aslan, Muhammet F.
AU  - Durdu, Akif
AU  - Sabanci, Kadir
AU  - Ropelewska, Ewa
AU  - Gültekin, Seyfettin S.
TI  - A Comprehensive Survey of the Recent Studies with UAV for Precision Agriculture in Open Fields and Greenhouses
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 3
SN  - 2076-3417

AB  - The increasing world population makes it necessary to fight challenges such as climate change and to realize production efficiently and quickly. However, the minimum cost, maximum income, environmental pollution protection and the ability to save water and energy are all factors that should be taken into account in this process. The use of information and communication technologies (ICTs) in agriculture to meet all of these criteria serves the purpose of precision agriculture. As unmanned aerial vehicles (UAVs) can easily obtain real-time data, they have a great potential to address and optimize solutions to the problems faced by agriculture. Despite some limitations, such as the battery, load, weather conditions, etc., UAVs will be used frequently in agriculture in the future because of the valuable data that they obtain and their efficient applications. According to the known literature, UAVs have been carrying out tasks such as spraying, monitoring, yield estimation, weed detection, etc. In recent years, articles related to agricultural UAVs have been presented in journals with high impact factors. Most precision agriculture applications with UAVs occur in outdoor environments where GPS access is available, which provides more reliable control of the UAV in both manual and autonomous flights. On the other hand, there are almost no UAV-based applications in greenhouses where all-season crop production is available. This paper emphasizes this deficiency and provides a comprehensive review of the use of UAVs for agricultural tasks and highlights the importance of simultaneous localization and mapping (SLAM) for a UAV solution in the greenhouse.
KW  - indoor and outdoor environments
KW  - greenhouse
KW  - precision agriculture
KW  - SLAM
KW  - UAV
DO  - 10.3390/app12031047
ER  -
TY  - EJOU
AU  - Krisanski, Sean
AU  - Taskhiri, Mohammad S.
AU  - Montgomery, James
AU  - Turner, Paul
TI  - Design and Testing of a Novel Unoccupied Aircraft System for the Collection of Forest Canopy Samples
T2  - Forests

PY  - 2022
VL  - 13
IS  - 2
SN  - 1999-4907

AB  - Unoccupied Aircraft Systems (UAS) are beginning to replace conventional forest plot mensuration through their use as low-cost and powerful remote sensing tools for monitoring growth, estimating biomass, evaluating carbon stocks and detecting weeds; however, physical samples remain mostly collected through time-consuming, expensive and potentially dangerous conventional techniques. Such conventional techniques include the use of arborists to climb the trees to retrieve samples, shooting branches with firearms from the ground, canopy cranes or the use of pole-mounted saws to access lower branches. UAS hold much potential to improve the safety, efficiency, and reduce the cost of acquiring canopy samples. In this work, we describe and demonstrate four iterations of 3D printed canopy sampling UAS. This work includes detailed explanations of designs and how each iteration informed the design decisions in the subsequent iteration. The fourth iteration of the aircraft was tested for the collection of 30 canopy samples from three tree species: eucalyptus pulchella, eucalyptus globulus and acacia dealbata trees. The collection times ranged from 1 min and 23 s, up to 3 min and 41 s for more distant and challenging to capture samples. A vision for the next iteration of this design is also provided. Future work may explore the integration of advanced remote sensing techniques with UAS-based canopy sampling to progress towards a fully-automated and holistic forest information capture system.
KW  - canopy
KW  - drone
KW  - leaf
KW  - leaves
KW  - foliar
KW  - samples
KW  - sampling
KW  - Aerial robotics
KW  - UAS
KW  - UAV
DO  - 10.3390/f13020153
ER  -
TY  - EJOU
AU  - Xu, Biaoyi
AU  - Liang, Dong
AU  - Li, Ling
AU  - Quan, Rong
AU  - Zhang, Mingguang
TI  - An Effectively Finite-Tailed Updating for Multiple Object Tracking in Crowd Scenes
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 3
SN  - 2076-3417

AB  - Multiple Object Tracking (MOT) focuses on tracking all the objects in a video. Most MOT solutions follow a tracking-by-detection or a joint detection tracking paradigm to generate the object trajectories by exploiting the correlations between the detected objects in consecutive frames. However, according to our observations, considering only the correlations between the objects in the current frame and the objects in the previous frame will lead to an exponential information decay over time, thus resulting in a misidentification of the object, especially in scenes with dense crowds and occlusions. To address this problem, we propose an effectively finite-tailed updating (FTU) strategy to generate the appearance template of the object in the current frame by exploiting its local temporal context in videos. To be specific, we model the appearance template for the object in the current frame on the appearance templates of the objects in multiple earlier frames and dynamically combine them to obtain a more effective representation. Extensive experiments have been conducted, and the experimental results show that our tracker outperforms the state-of-the-art methods on MOT Challenge Benchmark. We have achieved 73.7% and 73.0% IDF1, and 46.1% and 45.0% MT on the MOT16 and MOT17 datasets, which are 0.9% and 0.7% IDFI higher, and 1.4% and 1.8% MT higher than FairMOT repsectively.
KW  - multiple object tracking
KW  - Re-ID
KW  - update mechanism
KW  - crowd scenes
DO  - 10.3390/app12031061
ER  -
TY  - EJOU
AU  - Run, Yadi
AU  - Li, Mengdi
AU  - Qin, Yaochen
AU  - Shi, Zhifang
AU  - Li, Qian
AU  - Cui, Yaoping
TI  - Dynamics of Land and Water Resources and Utilization of Cultivated Land in the Yellow River Beach Area of China
T2  - Water

PY  - 2022
VL  - 14
IS  - 3
SN  - 2073-4441

AB  - Image analysis of the Yellow River beach area since 1987 provided land use and water body patterns to support effective agricultural and environmental management. Landsat and Sentinel-2A/B images, and data from the Third National Land Survey, were used to examine the water body and land use patterns. The continuous beach land since 1987 was calculated from annual vegetation and water body indexes while that of cultivated land was extracted from the Third National Land Survey. Object-Oriented Feature Extraction was used to extract staple crops. The results showed that 58.26% of the beach area was cultivated land. Continuous beach land covered an area of 1630.98 km2 and was consisted of scattered patches that were unevenly distributed between the north and south banks of the Yellow River. The staple crop types in the beach area, winter wheat and summer corn accounted for 72.37% and 68.03% of the total cultivated land. Affected by the strategy on the Yellow River basin in China, as the ecological space and protection continue to increase, this study provides basic scientific references for the correct use of cultivated land resources and protection of the balance of soil and water resources dynamic utilization and balance of cultivated land protection and ecological protection.
KW  - Yellow River
KW  - cultivated land
KW  - Object-Oriented Feature Extraction
KW  - wheat
KW  - corn
DO  - 10.3390/w14030305
ER  -
TY  - EJOU
AU  - Yang, Qichi
AU  - Wang, Lihui
AU  - Huang, Jinliang
AU  - Lu, Lijie
AU  - Li, Yang
AU  - Du, Yun
AU  - Ling, Feng
TI  - Mapping Plant Diversity Based on Combined SENTINEL-1/2 Data&mdash;Opportunities for Subtropical Mountainous Forests
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 3
SN  - 2072-4292

AB  - Plant diversity is an important parameter in maintaining forest ecosystem services, functions and stability. Timely and accurate monitoring and evaluation of large-area wall-to-wall maps on plant diversity and its spatial heterogeneity are crucial for the conservation and management of forest resources. However, traditional botanical field surveys designed to estimate plant diversity are usually limited in their spatiotemporal resolutions. Using Sentinel-1 (S-1) and Sentinel-2 (S-2) data at high spatiotemporal scales, combined with and referenced to botanical field surveys, may be the best choice to provide accurate plant diversity distribution information over a large area. In this paper, we predicted and mapped plant diversity in a subtropical forest using 24 months of freely and openly available S-1 and S-2 images (10 m &times; 10 m) data over a large study area (15,290 km2). A total of 448 quadrats (10 m &times; 10 m) of forestry field surveys were captured in a subtropical evergreen-deciduous broad-leaved mixed forest to validate a machine learning algorithm. The objective was to link the fine Sentinel spectral and radar data to several ground-truthing plant diversity indices in the forests. The results showed that: (1) The Simpson and Shannon-Wiener diversity indices were the best predicted indices using random forest regression, with &#531;2 of around 0.65; (2) The use of S-1 radar data can enhance the accuracy of the predicted heterogeneity indices in the forests by approximately 0.2; (3) As for the mapping of Simpson and Shannon-Wiener, the overall accuracy was 67.4% and 64.2% respectively, while the texture diversity&rsquo;s overall accuracy was merely 56.8%; (4) From the evaluation and prediction map information, the Simpson, Shannon-Wiener and texture diversity values (and its confidence interval values) indicate spatial heterogeneity in pixel level. The large-area forest plant diversity indices maps add spatially explicit information to the ground-truthing data. Based on the results, we conclude that using the time-series of S-1 and S-2 radar and spectral characteristics, when coupled with limited ground-truthing data, can provide reasonable assessments of plant spatial heterogeneity and diversity across wide areas. It could also help promote forest ecosystem and resource conservation activities in the forestry sector.
KW  - sentinel-1 and -2
KW  - satellite imagery time-series
KW  - random forest
KW  - subtropical evergreen-deciduous broad-leaved mixed forest
KW  - plant diversity
DO  - 10.3390/rs14030492
ER  -
TY  - EJOU
AU  - Seydi, Seyd T.
AU  - Amani, Meisam
AU  - Ghorbanian, Arsalan
TI  - A Dual Attention Convolutional Neural Network for Crop Classification Using Time-Series Sentinel-2 Imagery
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 3
SN  - 2072-4292

AB  - Accurate and timely mapping of crop types and having reliable information about the cultivation pattern/area play a key role in various applications, including food security and sustainable agriculture management. Remote sensing (RS) has extensively been employed for crop type classification. However, accurate mapping of crop types and extents is still a challenge, especially using traditional machine learning methods. Therefore, in this study, a novel framework based on a deep convolutional neural network (CNN) and a dual attention module (DAM) and using Sentinel-2 time-series datasets was proposed to classify crops. A new DAM was implemented to extract informative deep features by taking advantage of both spectral and spatial characteristics of Sentinel-2 datasets. The spectral and spatial attention modules (AMs) were respectively applied to investigate the behavior of crops during the growing season and their neighborhood properties (e.g., textural characteristics and spatial relation to surrounding crops). The proposed network contained two streams: (1) convolution blocks for deep feature extraction and (2) several DAMs, which were employed after each convolution block. The first stream included three multi-scale residual convolution blocks, where the spectral attention blocks were mainly applied to extract deep spectral features. The second stream was built using four multi-scale convolution blocks with a spatial AM. In this study, over 200,000 samples from six different crop types (i.e., alfalfa, broad bean, wheat, barley, canola, and garden) and three non-crop classes (i.e., built-up, barren, and water) were collected to train and validate the proposed framework. The results demonstrated that the proposed method achieved high overall accuracy and a Kappa coefficient of 98.54% and 0.981, respectively. It also outperformed other state-of-the-art classification methods, including RF, XGBOOST, R-CNN, 2D-CNN, 3D-CNN, and CBAM, indicating its high potential to discriminate different crop types.
KW  - crop mapping
KW  - deep learning
KW  - convolutional neural networks (CNN)
KW  - attention modules (AM)
KW  - dual attention CNN
KW  - Sentinel-2
KW  - multi-temporal
DO  - 10.3390/rs14030498
ER  -
TY  - EJOU
AU  - Peng, Baochai
AU  - Ren, Dong
AU  - Zheng, Cheng
AU  - Lu, Anxiang
TI  - TRDet: Two-Stage Rotated Detection of Rural Buildings in Remote Sensing Images
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 3
SN  - 2072-4292

AB  - Fast and accurate acquisition of the outline of rural buildings on remote sensing images is an efficient method to monitor illegal rural buildings. The traditional object detection method produces useless background information when detecting rural buildings; the semantic segmentation method cannot accurately segment the contours between buildings; the instance segmentation method cannot obtain regular building contours. The rotated object detection methods can effectively solve the problem that the traditional artificial intelligence method cannot accurately extract the outline of buildings. However, the rotated object detection methods are easy to lose location information of small objects in advanced feature maps and are sensitive to noise. To resolve these problems, this paper proposes a two-stage rotated object detection network for rural buildings (TRDet) by using a deep feature fusion network (DFF-Net) and a pixel attention module (PAM). Specifically, TRDet first fuses low-level location and high-level semantic information through the DFF-Net and then reduces the interference of noise information to the network through the PAM. The experimental results show that the mean average precession (mAP), precision, recall rate, and F1 score of the proposed TRDet are 83.57%, 91.11%, 86.5%, and 88.74%, respectively, which outperform the R2CNN model by 15%, 15.54%, 4.01%, and 9.87%. The results demonstrate that the TRDet can achieve better detection in small rural buildings and dense rural buildings.
KW  - rotated object detection
KW  - rural buildings
KW  - feature fusion
KW  - pixel attention
DO  - 10.3390/rs14030522
ER  -
TY  - EJOU
AU  - Deng, Chao
AU  - Wang, Chung-Hung J.
AU  - Low, Kin H.
TI  - Investigation of Using Sky Openness Ratio as Predictor for Navigation Performance in Urban-like Environment to Support PBN in UTM
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 3
SN  - 1424-8220

AB  - One of the causes of positioning inaccuracies in the Unmanned Aircraft System (UAS) is navigation error. In urban environment operations, multipaths could be the dominant contributor to navigation errors. This paper presents a study on how the operation environment affects the lateral (horizontal) navigation performance when a self-built UAS is going near different types of urban obstructions in real flight tests. Selected test sites are representative of urban environments, including open carparks, flight paths obstructed by buildings along one or both sides, changing sky access when flying towards corners formed by two buildings or dead ends, and buildings with reflective glass-clad surfaces. The data was analysed to obtain the horizontal position error between Global Positioning System (GPS) position and ground truth derived from Real Time Kinematics (RTK), with considerations for (1) horizontal position uncertainty estimate (EPH) reported by the GPS receiver, (2) no. of visible satellites, and (3) percentage of sky visible (or sky openness ratio, SOR) at various altitudes along the flight paths inside the aforementioned urban environments. The investigation showed that there is no direct correlation between the measured horizontal position error and the reported EPH; thus, the EPH could not be used for the purpose of monitoring navigation performance. The investigation further concluded that there is no universal correlation between the sky openness ratio (SOR) seen by the UAS and the resulting horizontal position error, and a more complex model would need to be considered to translate 3D urban models to expected horizontal navigation uncertainty for the UAS Traffic Management (UTM) airspace.
KW  - position error
KW  - navigation
KW  - performance-based navigation (PBN)
KW  - drones
DO  - 10.3390/s22030840
ER  -
TY  - EJOU
AU  - Perk, Baris E.
AU  - Inalhan, Gokhan
TI  - Safe Motion Planning and Learning for Unmanned Aerial Systems
T2  - Aerospace

PY  - 2022
VL  - 9
IS  - 2
SN  - 2226-4310

AB  - To control unmanned aerial systems, we rarely have a perfect system model. Safe and aggressive planning is also challenging for nonlinear and under-actuated systems. Expert pilots, however, demonstrate maneuvers that are deemed at the edge of plane envelope. Inspired by biological systems, in this paper, we introduce a framework that leverages methods in the field of control theory and reinforcement learning to generate feasible, possibly aggressive, trajectories. For the control policies, Dynamic Movement Primitives (DMPs) imitate pilot-induced primitives, and DMPs are combined in parallel to generate trajectories to reach original or different goal points. The stability properties of DMPs and their overall systems are analyzed using contraction theory. For reinforcement learning, Policy Improvement with Path Integrals (PI2) was used for the maneuvers. The results in this paper show that PI2 updated policies are a feasible and parallel combination of different updated primitives transfer the learning in the contraction regions. Our proposed methodology can be used to imitate, reshape, and improve feasible, possibly aggressive, maneuvers. In addition, we can exploit trajectories generated by optimization methods, such as Model Predictive Control (MPC), and a library of maneuvers can be instantly generated. For application, 3-DOF (degrees of freedom) Helicopter and 2D-UAV (unmanned aerial vehicle) models are utilized to demonstrate the main results.
KW  - UAV
KW  - artificial intelligence
KW  - contraction theory
KW  - nonlinear control
KW  - primitives
KW  - reinforcement learning
KW  - imitation learning
KW  - maneuvers
DO  - 10.3390/aerospace9020056
ER  -
TY  - EJOU
AU  - Dai, Huatong
AU  - Chen, Pengzhan
AU  - Yang, Hui
TI  - Metalearning-Based Fault-Tolerant Control for Skid Steering Vehicles under Actuator Fault Conditions
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 3
SN  - 1424-8220

AB  - Using reinforcement learning (RL) for torque distribution of skid steering vehicles has attracted increasing attention recently. Various RL-based torque distribution methods have been proposed to deal with this classical vehicle control problem, achieving a better performance than traditional control methods. However, most RL-based methods focus only on improving the performance of skid steering vehicles, while actuator faults that may lead to unsafe conditions or catastrophic events are frequently omitted in existing control schemes. This study proposes a meta-RL-based fault-tolerant control (FTC) method to improve the tracking performance of vehicles in the case of actuator faults. Based on meta deep deterministic policy gradient (meta-DDPG), the proposed FTC method has a representative gradient-based metalearning algorithm workflow, which includes an offline stage and an online stage. In the offline stage, an experience replay buffer with various actuator faults is constructed to provide data for training the metatraining model; then, the metatrained model is used to develop an online meta-RL update method to quickly adapt its control policy to actuator fault conditions. Simulations of four scenarios demonstrate that the proposed FTC method can achieve a high performance and adapt to actuator fault conditions stably.
KW  - fault-tolerant control
KW  - skid steering vehicle
KW  - reinforcement learning (RL)
KW  - metalearning
KW  - torque distribution
DO  - 10.3390/s22030845
ER  -
